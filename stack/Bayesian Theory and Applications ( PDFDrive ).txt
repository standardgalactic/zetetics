
BAYESIAN THEORY AND APPLICATIONS

This page intentionally left blank 

Bayesian Theory and
Applications
Edited by
PAUL DAMIEN
University of Texas, Austin
PETROS DELLAPORTAS
Athens University of Economics and Business
NICHOLAS G. POLSON
University of Chicago
DAVID A . STEPHENS
McGill University
1

3
Great Clarendon Street, Oxford, ox2 6dp,
United Kingdom
Oxford University Press is a department of the University of Oxford.
It furthers the University’s objective of excellence in research, scholarship,
and education by publishing worldwide. Oxford is a registered trade mark of
Oxford University Press in the UK and in certain other countries
© Oxford University Press 2013
The moral rights of the authors have been asserted
First Edition published in 2013
Impression: 1
All rights reserved. No part of this publication may be reproduced, stored in
a retrieval system, or transmitted, in any form or by any means, without the
prior permission in writing of Oxford University Press, or as expressly permitted
by law, by licence or under terms agreed with the appropriate reprographics
rights organization. Enquiries concerning reproduction outside the scope of the
above should be sent to the Rights Department, Oxford University Press, at the
address above
You must not circulate this work in any other form
and you must impose this same condition on any acquirer
British Library Cataloguing in Publication Data
Data available
ISBN 978–0–19–969560–7
Printed in Great Britain by
CPI Group (UK) Ltd, Croydon, CR0 4YY
Links to third party websites are provided by Oxford in good faith and
for information only. Oxford disclaims any responsibility for the materials
contained in any third party website referenced in this work.

Dedication
This volume is dedicated to Sir Adrian Smith, F.R.S.

This page intentionally left blank 

Contents
Contributors
x
Introduction
xii
Part I
Exchangeability
1 Observables and models: exchangeability and the
inductive argument
3
Michael Goldstein
2 Exchangeability and its ramifications
19
A. Philip Dawid
Part II
Hierarchical Models
3 Hierarchical modelling
33
Alan E. Gelfand and Souparno Ghosh
4 Bayesian hierarchical kernel machines for nonlinear
regression and classification
50
Sounak Chakraborty, Bani K. Mallick and Malay Ghosh
5 Flexible Bayesian modelling for clustered categorical
responses in developmental toxicology
70
Athanasios Kottas and Kassandra Fronczyk
Part III
Markov Chain Monte Carlo
6 Markov chain Monte Carlo methods
87
Siddhartha Chib
7 Advances in Markov chain Monte Carlo
104
Jim E. Griffin and David A. Stephens
Part IV
Dynamic Models
8 Bayesian dynamic modelling
145
Mike West
9 Hierarchical modelling in time series: the factor
analytic approach
167
Dani Gamerman and Esther Salazar

viii
Contents
10 Dynamic and spatial modelling of block maxima extremes
183
Gabriel Huerta and Glenn A. Stark
Part V
Sequential Monte Carlo
11 Online Bayesian learning in dynamic models: an illustrative
introduction to particle methods
203
Hedibert F. Lopes and Carlos M. Carvalho
12 Semi-supervised classification of texts using particle learning
for probabilistic automata
229
Ana Paula Sales, Christopher Challis, Ryan Prenger and Daniel Merl
Part VI
Nonparametrics
13 Bayesian nonparametrics
249
Stephen G. Walker
14 Geometric weight priors and their applications
271
Ramsés H. Mena
15 Revisiting Bayesian curve fitting using multivariate
normal mixtures
297
Stephen G. Walker and George Karabatsos
Part VII
Spline Models and Copulas
16 Applications of Bayesian smoothing splines
309
Sally Wood
17 Bayesian approaches to copula modelling
336
Michael Stanley Smith
Part VIII
Model Elaboration and Prior Distributions
18 Hypothesis testing and model uncertainty
361
M. J. Bayarri and J. O. Berger
19 Proper and non-informative conjugate priors for exponential
family models
395
E. Gutiérrez-Peña and M. Mendoza
20 Bayesian model specification: heuristics and examples
409
David Draper
21 Case studies in Bayesian screening for time-varying model
structure: the partition problem
432
Zesong Liu, Jesse Windle and James G. Scott
Part IX
Regressions and Model Averaging
22 Bayesian regression structure discovery
451
Hugh A. Chipman, Edward I. George and Robert E. McCulloch

Contents
ix
23 Gibbs sampling for ordinary, robust and logistic regression
with Laplace priors
466
Robert B. Gramacy
24 Bayesian model averaging in the M-open framework
483
Merlise Clyde and Edwin S. Iversen
Part X
Finance and Actuarial Science
25 Asset allocation in finance: a Bayesian perspective
501
Eric Jacquier and Nicholas G. Polson
26 Markov chain Monte Carlo methods in corporate finance
516
Arthur Korteweg
27 Actuarial credibility theory and Bayesian statistics—the story
of a special evolution
546
Udi Makov
Part XI
Medicine and Biostatistics
28 Bayesian models in biostatistics and medicine
557
Peter Müller
29 Subgroup analysis
576
Purushottam W. Laud, Siva Sivaganesan and Peter Müller
30 Surviving fully Bayesian nonparametric regression models
593
Timothy E. Hanson and Alejandro Jara
Part XII
Inverse Problems and Applications
31 Inverse problems
619
Colin Fox, Heikki Haario and J. Andrés Christen
32 Approximate marginalization over modelling errors and
uncertainties in inverse problems
644
Jari Kaipio and Ville Kolehmainen
33 Bayesian reconstruction of particle beam phase space
673
C. Nakhleh, D. Higdon, C. K. Allen and R. Ryne
Adrian Smith’s research supervision (PhD)
687
Adrian Smith’s publications
689
Index
697

Contributors
• C. K. Allen, Oak Ridge National Laboratory
• M. J. Bayarri, Universitat de Valencia
• J. O. Berger, Duke University
• Carlos M. Carvalho, University of Texas in Austin
• Sounak Chakraborty, University of Missouri-Columbia
• Christopher Challis, Duke University
• Siddhartha Chib, Washington University
• Hugh A. Chipman, Acadia University
• J. Andrés Christen, CIMAT, Mexico
• Merlise Clyde, Duke University
• A. Philip Dawid, University of Cambridge
• David Draper, University of California in Santa Cruz
• Colin Fox, University of Auckland
• Kassandra Fronczyk, M.D. Anderson Cancer Institute
• Dani Gamerman, UFRJ, Brazil
• Alan E. Gelfand, Duke University
• Edward I. George, University of Pennsylvania
• Malay Ghosh, University of Florida
• Souparno Ghosh, Duke University
• Michael Goldstein, Durham University
• Robert B. Gramacy, University of Chicago
• Jim E. Griffin, University of Kent
• E. Gutiérrez-Peña, IIMAS, UNAM
• Heikki Haario, Lappeenranta University of Technology
• Timothy E. Hanson, University of South Carolina
• D. Higdon, Los Alamos National Laboratory
• Gabriel Huerta, Indiana University
• Edwin S. Iversen, Duke University
• Eric Jacquier, MIT
• Alejandro Jara, Pontifica Universidad Catolica de Chile

Contributors
xi
• Jari Kaipio, University of Auckland
• George Karabatsos, University of Illinois
• Ville Kolehmainen, University of Eastern Finland
• Arthur Korteweg, Stanford University
• Athanasios Kottas, University of California in Santa Cruz
• Purushottam W. Laud, Medical College of Wisconsin
• Zesong Liu, University of Texas in Austin
• Hedibert F. Lopes, University of Chicago
• Udi Makov, University of Haifa
• Bani K. Mallick, Texas A & M University
• Robert E. McCulloch, University of Chicago
• Ramsés H. Mena, IIMAS, UNAM
• M. Mendoza, ITAM
• Daniel Merl, Lawrence Livermore National Laboratory
• Peter Müller, University of Texas in Austin
• C. Nakhleh, Sandia Labs
• Nicholas G. Polson, University of Chicago
• Ryan Prenger, Lawrence Livermore National Laboratory
• R. Ryne, Lawrence Berkeley National Laboratory
• Esther Salazar, Duke University
• Ana Paula Sales, Lawrence Livermore National Laboratory
• James G. Scott, University of Texas in Austin
• Siva Sivaganesan, University of Cincinnati
• Michael Stanley Smith, Melbourne Business School
• Glenn A. Stark, University of New Mexico
• David A. Stephens, McGill University
• Stephen G. Walker, University of Kent
• Mike West, Duke University
• Jesse Windle, University of Texas in Austin
• Sally Wood, Melbourne Business School

Introduction
At the outset, we would like to thank all the authors that have contributed to this volume. This
book is dedicated to a statistician whose work in Bayesian statistics has forever changed the way
in which statistical research and practice has been and will be carried out. Adrian Smith’s accom-
plishments are documented at the end of this volume. Here, we simply note that three key ideas in
this volume—hierarchical models, Markov chain Monte Carlo and sequential Monte Carlo—that
have revolutionized Bayesian statistics are in large measure due to Adrian’s contributions. These
concepts are now ubiquitous wherever Bayesian models are used. In this volume, we have selected
broad topic areas where these ideas come into play in a significant manner. Of course these topics
are by no means exhaustive, but they serve to illustrate the impact that Adrian’s research has had on
Bayesian statistics in the last four decades or so.
When we conceived this volume, we wanted to position it somewhat differently from other
tribute volumes. To accomplish this, based on our collective experiences, we felt that some of the
basic ideas in modern Bayesian statistics with which Bayesian statisticians are familiar are foreign
to some (if not many) colleagues and practitioners in other disciplines. Therefore, we felt that a
volume that had a ‘Bayesian textbook’ flavour to it, and which also included application papers
would prove useful in spreading modern Bayesian ideas. This is the modus operandi adopted in
most of the chapters. We now discuss each part in turn.
Part I: Exchangeability Dawid and Goldstein explore the fundamental notion of Bayesian
statistics, namely exchangeability.
Part II: Hierarchical Models The first key idea in modern Bayesian statistics is hierarchical
models. Gelfand and Ghosh discuss the elementary ideas underlying such models. This is then
followed up by Chakraborty, Mallick and Ghosh, and Kottas and Fronczyk’s papers.
Part III: Markov Chain Monte Carlo The second key idea in modern Bayesian statistics is
Markov chain Monte Carlo (MCMC). Chib reviews the key MCMC approaches to implement-
ing full Bayesian analysis. Griffin and Stephens’ contribution further describes and exemplifies
advanced MCMC notions.
Part IV: Dynamic Models West describes the fundamentals of dynamic linear and nonlinear
models. Papers by Gamerman and Salazar, and Huerta and Stark elaborate on these ideas via some
novel applications.
Part V: Sequential Monte Carlo Carvalho and Lopes describe the use of SMC in a variety of
Bayesian models, which is then followed up by an applications paper by Sales, Challis, Prenger and
Merl.
Part VI: Nonparametrics Bayesian nonparametrics is embedded in the exchangeability ideas
foundinPartI.WalkerdiscussesBayesiannonparametricmodelsandarguesthattoperformproper
data analysis one must adopt nonparametric models at the outset. Two papers, one by Karabatsos
and Walker, and the second by Ména complete this part.
Part VII: Spline Models and Copulas Part VI considers Bayesian nonparametrics using
exchangeability as the basis. There are related approaches to nonparametrics but with some key

Introduction
xiii
differences. Two such classes of models are discussed in this part: Bayesian splines by Wood, and
Bayesian copulas by Smith.
PartVIII:ModelElaborationandPriorDistributionsBayarri and Berger describe the funda-
mentals of Bayesian hypothesis testing, followed by three research papers by Draper; Liu, Windle
and Scott; and Gutiérrez-Peña and Mendoza.
Part IX: Regressions and Model Averaging Chipman, George and McCulloch describe the
correct way of doing regressions. This is further elaborated on in two papers by Clyde and Iversen,
and Gramacy.
PartX:FinanceandActuarialScienceJacquierandPolsondiscusstheroleofBayesinfinancial
applications.ThisisfollowedbyacomprehensivereviewofBayesianmodelsincorporatefinanceby
Korteweg. One area where Bayesian methods are only now beginning to gain popularity is actuarial
science. Makov describes Bayesian models in this context.
Part XI: Medicine and Biostatistics It is safe to say that Bayesian methods have found most
widespread use in biostatistics and bio-informatics. Mueller details the Bayesian models in these
areas, followed by two key papers in biostatistics by Laud, Müller and Sivaganesan, and Hanson
and Jara.
PartXII:InverseProblemsandApplicationsThisisanexcitingareaofsciencewhereBayesian
methods are fast gaining in popularity. Fox, Haario and Christen provide a complete description of
Bayesian ideas in this field, followed by two practical papers: one by Kaipio and Kolehmainen, and
a second by Nakhleh, Higdon, Allen and Ryne.
Special thanks to Carlos Carvalho, Marcin Kacperczyk, Bani Mallick, Tom Shively, and Daniel
Zantedeschi for helping review some of the papers.
Finally, we would like to thank Clare Charles, Elizabeth Hannon, Keith Mansfield, Viki Mor-
timer, Subramaniam Vengatakrishnan and their colleagues at Oxford University Press for their
tireless efforts in ensuring that this book was completed in a timely and efficient manner.

This page intentionally left blank 

Part I
Exchangeability

This page intentionally left blank 

1
Observables and models:
exchangeability and the
inductive argument
michael goldstein
1.1 Introduction
W
hen quantifying uncertainty for large and complex systems, it is often considered helpful
to regard such uncertainty as being of two kinds, epistemic and aleatory. Epistemic uncer-
tainty is that which relates to our lack of knowledge, and could be reduced by receipt of further
information. Aleatory uncertainty is that which relates to intrinsic chance variation in the system,
and cannot be resolved except by direct observation. The distinction between aleatory and epis-
temic uncertainty is informal rather than precise, particularly within the view that all uncertainty
stems from a lack of knowledge and understanding. Indeed, a basic activity in much of science is
searching for explanatory structure within apparently random events, which corresponds to mov-
ing uncertainty from the aleatory to the epistemic form, where it can be better understood and,
possibly, reduced.
The aleatory/epistemic distinction has a natural counterpart in much statistical analysis, where
aleatory uncertainty is expressed through the likelihood function for the data given the population
parameters,whileepistemicuncertaintyisexpressedthroughthepriordistributionovertheparam-
eters, within the Bayesian formulation, and is treated less formally within relative frequency based
approaches. This division between uncertain model parameters and likelihoods conditional on the
values of the parameters is helpful and constructive when modelling our uncertainty about a phys-
ical system. However, as with any other form of modelling, this does raise fundamental questions
when we seek to apply the results of the model based analysis to actual real world inferences. All
that we actually observe are individual measurements of real things. The parametric forms that we
introduce to describe intrinsic chance variation are simply models whose meaning and justification
remains to be established.
Within the subjectivist approach, there is a precise answer to the question of meaning for many
statistical models. This meaning is rooted in the judgement of exchangeability. Exchangeability
allowsustoconstructparametricstatisticalmodelspurelyonthebasisoftheuncertaintystatements
that we make about observable random quantities. Indeed, in many cases, the argument shows that
we have no choice but to behave as though we consider that we are sampling from a parametric
model (the aleatory uncertainty) given the true but unknown values of some population distribu-
tion (the epistemic uncertainty). Therefore, exchangeability is the logical bedrock to a large part of

4
M. Goldstein
current statistical analysis. Beyond this, the distinction between aleatory and epistemic uncertainty
pervades so much of current scientific analysis that the notion of exchangeability is a necessary
conceptual tool to provide the underpinnings of meaning for uncertainty quantification in general
and the inductive argument, namely the reasoning from particular cases to general principles, in
particular.
Our aims in this chapter are two-fold. Firstly, we shall give an elementary and self-contained
account of the notion of exchangeability and the derivation of de Finetti’s representation theorem,
which shows how we may construct operational statistical models based strictly on our judgements
over observables. Secondly, we shall consider the relevance of this representation to real world
inferences, and introduce a second collection of exchangeability judgements which are necessary
in order that the inductive argument, when applied to inferences over models so constructed, also
has an operational real world counterpart.
1.2 Finite population sampling
Finite population sampling gives a concrete illustration of the distinction between aleatory and
epistemic uncertainty. Consider a simple version of this problem. We have a bucket, which contains
aknownlargenumber,N,ofcounters,ofwhichanunknownproportionqarered,andtheremaining
proportion (1 −q) are blue. We intend to draw a counter at random from the bucket. (Here, and
below, we use the term ‘at random’ as shorthand for the subjective judgement that each counter
currently in the bucket is equally likely to be selected at each stage.) Let Z = 1 if this draw is red,
and let Z = 0, otherwise. We are uncertain as to the value that Z will take. This uncertainty has
two components. Firstly, we do not know the value of q. This is epistemic uncertainty. It can be
quantified by consideration of what we know about the way that the population was formed, and
willbefurtherreducedifwetakesamplesfromthebucket.Differentpeoplewillhavedifferentstates
of knowledge and so their epistemic uncertainty may differ. Secondly, even if we did know q, we
still would not know the value of Z. This value would now be the realization of a Bernoulli random
variable, parameter q, and this irreducible uncertainty is aleatory. The distinction between aleatory
and epistemic uncertainty is most useful when there is a general consensus as to the representation
of aleatory uncertainty, e.g. here, to the extent that there is general agreement that the draw from
the bucket will be random, and no obvious way to impose more structure upon this variation.
Thepossiblevaluesofqareqi = i/n, i = 0, 1, . . . , N.InthesubjectiveBayesview,wemayquan-
tify our epistemic uncertainty for q by specifying our collection of probabilities pi = P(q = qi).
Therefore, we can assess our probability that Z = 1, by the law of total probability, as
P(Z = 1) =
N

i=0
piqi
(1.1)
A useful way to rewrite (1.1) is
P(Z = 1) =
 1
0
q dF(q)
(1.2)
where F is the probability measure on [0,1] which assigns probability pi to the point i/N.
Now suppose, instead, that we are going to take a random sample of size n, without replacement,
from the bucket. Let X denote the number of red counters in the sample. Epistemic uncertainty is
as before. Our aleatory uncertainty relates to the probability distribution for X if we know q, the
proportion of red counters in the bucket. This distribution is hypergeometric, so that

Observables and models
5
P(X = k|q) =
Nq
k
N(1−q)
n−k

N
n

(1.3)
Therefore, the corresponding version of (1.2) is
P(X = k) =
 1
0
Nq
k
N(1−q)
n−k

N
n

dF(q)
(1.4)
If n is small compared to N, then there is little difference between sampling with and without
replacement, and so, approximately, we can rewrite (1.3) as
P(X = k|q) ≈
n
k

qk(1 −q)(n−k)
(1.5)
so that (1.4) may be approximated as
P(X = k) ≈
 1
0
n
k

qk(1 −q)(n−k) dF(q)
(1.6)
Representation (1.6) is familiar in the Bayesian context, and is often described by saying that X has
a binomial likelihood, parameters n, q, where our prior measure for q is given by F. In the above
examples, F was a discrete measure placing probabilities on each value i/N. As N increases, it is
often helpful to approximate this discrete measure by a continuous pdf f(q), so that
P(X = k) ≈
 1
0
n
k

qk(1 −q)(n−k)f(q) dq
(1.7)
For example, most introductory treatments for Bayesian statistics deal with (1.7) by discussing the
special case where f(q) is a beta distribution, as this case has simplifying conjugacy properties.
However, in our development, it is helpful to retain the possibility that F could have any form at
all; for example F could be a mixture of discrete and continuous components if there were certain
special choices for q. (Suppose, for example, that our bucket had been chosen by a coin flip between
two buckets, for one of which we knew that q was 0.5, but we had no information about the value
for q in the other bucket.)
Asweincreasethesizeof N ascomparedton,theapproximation(1.5),andsoalso(1.6),becomes
increasingly precise. We can see this informally as (1.5) would be exact if we were sampling with
replacement, and only removing a small number of counters from a large bucket will only change
the proportion of red counters by a small amount. We can support this intuition by showing that
the right-hand side of (1.3) tends uniformly to the right-hand side of (1.5) with N; for example, the
mostextremechangetotheproportionsinthebucketistodrawallcountersofthesamecolour,and
for any N, q and n < Nq, the probability of n successes when sampling without replacement is less
than the probability when sampling with replacement, but greater than the probability for sampling
with replacement if we first remove n red counters from the bucket, so that
(q −f
1 −f )n ≤P(X = n|q) ≤qn
where f is the sampling fraction f = n/N, and so the approximation is very close for f near zero.

6
M. Goldstein
We have described this sampling problem from a Bayesian viewpoint. In the common situation
where we have a large sample, n, from a much larger population, N, most inferential approaches will
reach the same conclusion, namely that the proportion of red counters in the sample estimates the
population proportion with high accuracy. When the sampling fraction f is not small, we must take
more care in approximating the hypergeometric distribution, and if n is small, then our representa-
tion of epistemic uncertainty through F will be important. However, in all cases, the meaning of the
analysis will be clear, in the sense that there is a true but unknown population parameter q, which is,
in principle, observable, and a generally agreed aleatory description as to how the sample is drawn,
given q.
Most statistical problems lack this logical bedrock. For example, if we spin a coin repeatedly, and
wouldliketouseourobservedspinstoreviseourjudgementsaboutfuturespins,thenwemightrep-
resentouruncertaintybymeansofamodelinwhich,giventhevalueofq,the‘thetruebutunknown’
value of the probability that the spun coin will land heads, the coin spins are independent Bernoulli
variables with parameter q. This model is formally similar to the finite population problem that we
have been discussing, but with the fundamental distinction that the quantity q over which we now
expressouruncertaintyisonlyamodelquantity,whichisnotobservableeveninprincipleandlacks
even a real world definition. However, there is a bridge between such uncertainty models and the
problem of finite population sampling and this comes through the concept of exchangeability, as
we shall now describe.
1.3 Exchangeable samples
In the problem of sampling counters from the bucket that we described above, consider making
an ordered series of draws, X1, X2, . . . , XN from the bucket, without replacement, where Xi = 1
if the ith draw is red, Xi = 0 otherwise. For us, the sequence is not independent. Observing each
draw alters both the aleatory uncertainty (each time we observe a red counter, then this reduces the
proportion of red counters available for the next draw) and the epistemic uncertainty (each time
we observe a red counter, this changes our state of knowledge about the true proportion of red
counters in the bucket). However, the sequence does have certain probabilistic properties which
are important for the general account that we shall develop.
Consider first a single draw Xi. For each draw i, given the initial proportion q of red counters, the
probability of drawing a red counter is the same, namely q, as, on each draw, each individual counter
has the same probability of being selected. Therefore, eachXi has the same probability distribution,
namely Bernoulli, with parameter given by (1.2). Now consider any pair of draws, Xi, Xj. Given q,
the ith draw has probability q of being red. If the ith draw is red, then the jth draw is a random draw
from a bucket, size N −1, with qN −1 red counters. Therefore, the probability distribution of the
number of red counters in two draws is given by (1.4), for the case where n = 2, and this is true for
all pairsi ̸= j.Continuinginthis way,wehavethat theprobabilitydistributionof anycollectionof n
elements(Xi1, . . . , Xin)fromtheserieshasthesameprobabilitydistribution,howeverweselectand
permutetheindicesi1, . . . , in,asgivenby(1.4).Thisnotion,thattheprobabilitydistributionofany
collection of n of the quantities depends only on the value of n, and not on the individual quantities
selected, or the order in which they are arranged, is termed exchangeability and is fundamental to
the subjectivist representation for epistemic and aleatory uncertainty.
Whilewehaveonlydiscussedsimpletwo-valuedscalarquantitiessofar,theconceptofexchange-
ability is quite general. We make the following definition.
Definition A sequence (Y1, Y2, . . .) ofrandomvectors Yi = (Yi1, Yi2, . . . , Yim)takingvaluesinsome
space  is said to be exchangeable if the joint probability distribution of each subcollection of n
quantities (Yi1, Yi2, . . . , Yin) is the same.

Observables and models
7
In our account of picking counters from the bucket, we deduced exchangeability of the sequence
of selections from our views as to the physical description of the problem. The notion of exchange-
ability reverses the logic of this argument and allows us to deduce the structure of the problem
directly from the judgement of exchangeability. This is usually termed de Finetti’s representation
theorem for exchangeable sequences. We will introduce this representation by discussing the
example of spinning coins and then use a more general form of this argument to give the general
form for the theorem. Our account builds on the treatment in [10].
1.4 The representation theorem for exchangeable binary
sequences
Suppose that we spin a coin repeatedly. The familiar model, which treats coin spins as independent
Bernoulli random variables each with a true but unknown probability q of landing heads, lacks
an operational physical basis. However, we can retrieve a version of this model if we make the
judgement that the coin spins are exchangeable.
Let Ui = 1 if the ith spin is heads, Ui = 0 otherwise. Suppose that we view the sequence
(U1, U2 . . .) as exchangeable. To simplify our account, we will treat this sequence of coin spins as,
in principle, infinite, which we can informally interpret as saying that we are able to consider as large
anumberofspinsasweneedwhenweconstructouruncertaintyjudgementsovertheoutcomes.(If
we are restricted to a finite exchangeable sequence, then the results that we obtain will correspond
to those deducible from finite population sampling, see for example, [3].)
Consider the following thought experiment. Imagine that we have an empty bucket, and a pile
of counters, numbered, sequentially, 1 to N. Consider spinning the coin N times. We shall mark the
outcome of the ith spin on the ith counter, so each counter is either marked 1 or 0. Each counter is
added to the bucket.
As the spins are exchangeable, we must assign the same probability, q say, to the event that the
first spin is heads, i.e. that U1 = 1, as we do to the event that a randomly chosen counter from the
bucket has value 1 (as the probability that the randomly chosen counter has value 1 is the average
of the probabilities that each counter has value 1, which, by the exchangeability judgement, must all
be equal to q). Again we may make a division into a notional epistemic uncertainty as to the value
of the proportion of counters marked 1 in the bucket and an aleatory uncertainty for the value on
the single counter that we pick, given this proportion. Therefore the probability, for the randomly
selected counter in the thought experiment, can be constructed as in (1.1), by first considering the
possible values qi = i/N, i = 0, 1, . . . , N for the proportion of counters labelled 1, in the bucket,
and assigning probabilities pi to the outcomes for q as above. We have
P(U1 = 1) =
 1
0
q dFN(q)
(1.8)
in the same way, where FN assigns probability pi to point i/N.
We can extend this argument to our judgement about the outcome of n tosses in the same way.
If Wn is the number of heads in the first n spins, then our probability for observing Wn = k is the
same as the probability that we assign for this event in any sample of n spins, and so this probability
must be equal to the probability of drawing k counters labelled 1 from the bucket in n random picks,
which, by relation (1.4), is given, ∀N ≥n, as
P(Wn = k) =
 1
0
Nq
k
N(1−q)
n−k

N
n

dFN(q)
(1.9)

8
M. Goldstein
The simplest way to consider what happens as N increases is to invoke Helly’s theorem (see, for
example, [4], which also contains an insightful discussion of exchangeability) and a quite different
derivation of the exchangeability representation theorem), which states that any infinite sequence
of probability distributions GN on a bounded interval contains a subsequence which converges in
distribution to a limit, say G.
(Helly’s theorem is a consequence of the result that any infinite sequence of numbers a1, a2, . . .
on a bounded interval has a uniformly convergent subsequence. The result for number sequences
can be shown as follows, where we suppose all numbers lie in [0,1]. Divide the sequence into ten
subsequences, according to the first decimal place. At least one subsequence must be infinite. Keep
one such subsequence and discard the rest. Let b1 be the element ai1 with the smallest subscript
in this subsequence. Now divide this subsequence into ten subsequences according to the value of
the second decimal place. At least one subsequence must be infinite. Keep one such subsequence
and discard the rest. Let b2 be the element ai2 with the smallest subscript in this subsequence with
i2 > i1. Continue in this way and the sequence b1, b2, . . . converges uniformly to a limit, as all
values bj, bj+1, . . . agree in the first j decimal places, for each j. Helly’s theorem follows by repeated
applicationofthismethod.Wefirstselectaninfinitesubsequenceofprobabilitydistributionswhich
agree in the first decimal place for the probabilities that they assign to the intervals [0, 0.5) and
[0.5, 1]. From this subsequence, we select a subsequence which agrees to two decimal places for the
probability assigned to intervals [0, 0.25), [0.25, 0.5), [0.5, 0.75), [0.75, 1] and so forth. Choosing
an element from each subsequence constructed in this way, we arrive at Helly’s theorem.)
Applying Helly’s theorem to the sequence FN, there is a subsequence which converges in dis-
tribution to a limit F. Letting N tend to infinity, FN tends to F and the hypergeometric integrand
tends uniformly to the binomial, so that we have, for each k, n
P(Wn = k) =
 1
0
n
k

qk(1 −q)(n−k) dF(q)
(1.10)
(1.10) is de Finetti’s theorem for an infinite exchangeable sequence of binary outcomes, derived in
[1]. The uniqueness of the distribution F satisfying (1.10) follows as a probability distribution on a
bounded interval is uniquely determined by its moments: this is the Hausdorff moment problem
(see [4] which contains a direct derivation of the exchangeability representation theorem based
on this property). The theorem shows that the judgement of exchangeability, alone, is sufficient to
ensure that our beliefs about the sequence are just as if we consider that there is a true but unknown
quantity q given the value of which we view the sequence as a series of independent Bernoulli trials
with probability q.
The convergence of the sequence FN to F is uniform, as for any N1 < N2 < N3 we may view
FN1, FN2 respectivelyasthedistributionofqinbucketsformedbydrawsofsizeN1, N2 respectively
from a bucket formed by N3 spins of the coin, so that FN2 will be probabilistically closer than FN1
to FN3, corresponding to the intuition that there are no features of a population that are better
estimated by a small sample than by a large sample. In this way, we see that the exchangeability
representation (1.10) is really a statement about our judgements over large finite collections of coin
spins We invoke infinity simply to allow us to make a continuous approximation to the discrete
process, to any order of accuracy that we require.
Notice, in particular, that we have constructed the measure F(q) as the limit of the measures
FN(q), namely the measures for the proportion of heads, q[N] in the first N tosses. This is another
way of saying that the relative frequencies q[N] tend to a limit q in distribution. This is the subjec-
tivist formulation of the notion of limiting relative frequency. The relative frequency approach to
statistics uses the limiting relative frequency as the definition for the notion of probability but is
unable to give a proper justification for this definition, or even a satisfactory explanation as to the

Observables and models
9
way in which the limit should be understood. In contrast, the subjectivist approach constructs the
limiting relative frequency as a subjective judgement which is implied by subjective exchangeability
judgements over the sequence and deduces the limit as a necessary consequence of this judgement.
1.5 The general form for the exchangeability representation
The argument of the preceding section relates to coin spins, but it applies similarly to any infinite
random exchangeable sequence of vectors, (Y1, Y2, . . .), over a space . Just as before, we carry out
the thought experiment of constructing a bucket with N counters, where the ith counter is marked
with the value of Yi. Let QN denote the empirical distribution of the counters in the bucket, so that
QN assigns probability 1/N to the value on each counter. As the sequence Y is exchangeable, the
first value, Y1, has the same probability distribution as a draw according to the distribution QN.
Therefore, we can split up our uncertainty as to the outcome of Y1 into two parts. Firstly, we are
uncertain as to the distribution QN, and secondly, given QN, we are uncertain as to the value of the
observation Y1. Denote our probability distribution for QN by FN (so FN assigns probabilities for
all possible empirical distributions consisting of N selections from the space ). Then, analogously
to (1.8), we have, for any A1 ∈,
P(Y1 ∈A1) =

QN(A1) dFN(QN)
(1.11)
where QN(A1) is the probability assigned to A1 by the distribution QN (i.e. the proportion of the
first N outcomes that are within A1).
Now consider our probability distribution for the first n outcomes (Y1, Y2, . . . , Yn). We can
assess this distribution in two stages as above. First, we make a random choice for the empirical
distribution QN according to FN. Given the choice of QN, we now make n draws, without replace-
ment, from the bucket consisting of N counters with this empirical distribution. We can evaluate
this distribution exactly by a counting argument. If n is small compared to N, then each draw will
only change the composition of the remaining counters in the bucket by a small amount, so that the
draws will be almost independent. Therefore, we have that
P(Y1 ∈A1, . . . , Yn ∈An) ≈

QN(A1) . . . QN(An)dFN(QN)
(1.12)
As we let N increase, keeping n fixed, the exact form of the integrand in (1.12) tends uniformly to the
productintegrand.ThedistributionFN tendstoalimitingdistributionF overtheprobabilitydistri-
butionsQ overthespace.(Thedetailsofthelimitingargumentaretechnicallymorecomplicated
thanforthecoinflips,duetothegeneralityoftheformulation,buttheargumentisthesame,namely
thattheempiricaldistributionofalargesample,sizeN,fromamuchlargerpopulation,sizeM say,is
close to the population distribution, by the standard arguments of finite population sampling, and
therefore the sequence of distributions FN must converge.)
Proceeding in this way, we have the generalization of de Finetti’s result given by Hewitt and
Savage, [11], which is as follows.
Theorem Let (Y1, Y2, . . .) be an infinite exchangeable sequence of random quantities with values in .
Then there exists a probability measure F on the set of probability measures Q() on , such that,
for each n, and subsets A1, . . . , An of ,

10
M. Goldstein
P(Y1 ∈A1, . . . , Yn ∈An) =

Q(A1) . . . Q(An)dF(Q)
(1.13)
F is the limiting distribution of the empirical measure, i.e. the probability assigned to any set A by F
is given by the limit of the probability assigned to the proportion of the first N trials whose outcome
is in A.
The exchangeability representation theorem is both surprising and prosaic. It is surprising, in
the sense that the simple and natural symmetry judgement of exchangeability over observable
quantities leads to such a strong result, namely that our beliefs must be as though we considered
thatweweremakingindependentdrawsfroma‘truebutunknown’distributionQ forwhichwehad
assigned a prior measure F. This can be thought of as a version of the separation of our uncertainty
into aleatory and epistemic components. Observation of a sample Y[n] = (Y1, . . . , Yn) reduces
our uncertainty about future elements of the sequence by applying the Bayes theorem to the prior
measure F to update judgements about Q, as
P(Yi1 ∈A1, . . . , Yim ∈Am|Y[n]) =

Q(Ai1) . . . Q(Aim)dF(Q|Y[n])
(1.14)
for all subsets A1, . . . , Am of , and indices i1, . . . , im all greater than n. Increasingly large samples
tend to a ‘relative frequency limit’ eventually resolving all of our epistemic uncertainty, leaving the
unresolvable aleatory uncertainty as to the outcomes of future draws from a known distribution, a
posteriori. Compared to the conceptual confusion at the heart of traditional descriptions of statisti-
cal inference, this formulation is clear, unambiguous and logically compelling, building everything
on natural belief statements about quantities which are, in principle, observable. The theory of
exchangeability is rich and elegant and also of great practical and conceptual importance. This
article has only focused on the most basic form for the representation. A characteristic example of
the type of results that follow when we impose more structure on the exchangeability specifications
is[12]whichderivestheadditivemodelforlog-oddsinatwowaytablefromnaturalexchangeability
statementsoverrowsandcolumns.(Thediscussionfollowingthatarticlecontainssomecomments
from me on the links between this result and the types of limiting finite population representations
that we have described above.)
However, the representation theorem is also prosaic, as the population distribution is nothing
more than the outcomes of all the possible future observations in the sequence, and the division
into aleatory and epistemic components of uncertainty based on this structuring is just a partition-
ing of our judgements about such future observations. The bucket representation simply gives a
concrete form to this identification with finite population sampling, and makes clear the role of
exchangeability judgements in equating the observation of the members of the sequence with the
random samples from the bucket.
1.6 Expectation as primitive
While the exchangeability representation is highly revealing, the real world implementation of the
representation faces two difficulties, one in the construction of the representation and one in its
inferential application.
The first difficulty is implicit in the derivation that we have described for the representation
theorem. To construct the measure F in representation (1.13), we need to be able to quantify
our beliefs for the outcome of the thought experiment comprising the composition of the large
bucket with counters indexed by the vector outcomes of the first N members of the sequence.
Specifying prior beliefs over the possible choices for this collection is both scientifically difficult,

Observables and models
11
as we must consider questions at a level of detail beyond our ability to give scientifically meaning-
ful answers, and technically difficult, because of the complexity of the objects over which we are
aiming to develop a meaningful probabilistic representation. Therefore, one of the key advantages
of the exchangeability representation, namely that it provides a method for us to restrict our belief
statements to those related to observable quantities, in practice is usually unfeasible, and so the
representation is rarely used in this way.
The second difficulty is as follows. The representation theorem appears to retrieve for us the
familiar division into epistemic and aleatory uncertainties, but this division is itself based on an
epistemic judgement, which is therefore subject to revision. We aim to use relation (1.14) to update
beliefs about future outcomes given a current sample Y[n] by constructing the update F(Q|Y[n]),
and then deriving beliefs over future outcomes with respect to this distribution. However, the
meaning that we ascribe to F(Q) only holds for as long as we judge the sequence as exchangeable.
We may change this judgement at any time. Bayesian statistics describes how to make inferences
about quantities which have true but unknown values. There is no provision within the Bayesian
approach (or any other approach to inference that I know of) for making operationally meaningful
inferences about quantities which, at the time when we come to make the inference, may simply
cease to exist.
Whatweneedisbothtosimplifythespecificationrequirementsfortheexchangeabilityrepresen-
tation,sothatwemayuseitinpractice,aswellasinprinciple,andalsotosharpenourformulationfor
inferencetomakesenseoftheissuesraisedwhenwemakeconditioningstatementsoverevanescent
quantities. We may address the first issue by changing the primitive for our theory from probability
toexpectation.Toaddressthesecondissuerequiresustoaugmentourcollectionofexchangeability
specifications, in ways that we shall describe below.
Thesearelargerissuesthanwecandojusticetointhespaceofthisarticle.Allthatwewilldohere
is to sketch the key steps that we must take to establish an operational meaning for our inferences
over exchangeable quantities, building on ideas first outlined in [6] and [7].
Firstly, we shall discuss a simpler form of exchangeability, based on a different choice of primitive
for the theory. Typically, the primitive of choice for the subjectivist theory is probability, but this is
largely for historical reasons and to align the theory as closely as possible with its non-subjectivist
counterparts.However,wedohaveachoiceandwecan,instead,chooseexpectationastheprimitive
for quantifying uncertainty. With this choice, we can make as many, or as few, expectation judge-
mentsaswewish,whentreatingaproblemofuncertainty,includingasmanyprobabilitystatements
as we wish—these are simply expectation statements for the corresponding indicator variables.
However,whenprobabilityistheprimitive,wemustmakeallpossibleprobabilitystatementsbefore
we can make any expectation statements. (For this reason, expectation was de Finetti’s choice of
primitive for the theory and the work which best summarized his views, [2], is actually a theory of
expectation or, as he terms it, prevision.)
This is not an issue for non-subjectivist approaches—the probabilities all somehow exist sep-
arately from us and it is simply our task to learn about them. In the subjectivist theory, we are
much more involved. Each uncertainty is a statement that we make, expressing our best judgements
as to the likely outcomes. This is exactly the problem that we identified with the exchangeability
representation. We need to specify so many probability judgements over observable quantities
before we can construct the representation theorem that it is rarely used in this way. The theorem
is drained of much of its power by the excessive demands of the probabilistic formalism. We shall
now describe the second order version of the representation theorem, which does not suffer from
this problem.
De Finetti makes expectation primitive under the operational definition in which E(X) is the
value of x that you would choose if confronted with the penalty
L = k(X −x)2

12
M. Goldstein
where k is a constant defining the units of loss and the penalty is paid in probability currency (i.e.
tickets in a lottery with a single prize). The value of E(X) is chosen directly, as a primitive, as is
probability in the standard Bayesian account. De Finetti shows, under this definition, that E(X)
satisfies the usual properties of expectation, such as linearity. With this penalty scale, expectations
are consistent with preferences, in the sense that preferring penalty A to B is equivalent to assigning
E(A) < E(B), as expectation for the penalty is equal to the probability of the reward.
Bayes linear analysis is a version of Bayesian analysis which follows when we take expectation
as primitive; for a detailed account, see [9]. The particular features that are of concern for this
article are the practical alternative for the exchangeability representation, which can actually be
specified by judgements over observables in practice as well as in principle, and the linkage between
this representation and an operationally meaningful form of inference for the evanescent model
quantities expressed through the representation theorem. This formalism allows us to address the
twin concerns that we have raised about current approaches to statistical induction (and we know
of no alternative approach for so doing).
1.7 Second-order exchangeability representation theorem
We say that the sequence of random vectors X1, X2, . . ., where Xj = (X1j, . . . , Xrj), is
Second-Order Exchangeable (SOE), if each vector has the same mean and variance matrix and
all pairwise covariance matrices are the same, i.e. if
E(Xi) = μ, Var(Xi) = , Cov(Xi, Xj) = , ∀i ̸= j
(1.15)
Wesupposethatallquantitiesin(1.15)arefinite.Wemayseparateouruncertaintyabouteach Xi into
aleatory and epistemic components, with corresponding second order specifications, according to
the following representation theorem, derived in [5].
Theorem (Second-order exchangeability representation theorem) If X1, X2, . . . . is an infinite
Second-Order Exchangeable sequence of random vectors, then, for each i,
Xi = M(X) ⊕Ri(X)
(1.16)
where R1(X), R2(X), . . . isamutually uncorrelatedsecond-orderexchangeablesequence,eachwith
mean zero and uncorrelated with M(X).
(The notation U ⊕W expresses the condition that all of the elements of the vector U are uncorre-
lated with all of the elements of the vector W.)
The proof of the representation theorem is similar to that for the full exchangeability represen-
tation. Our thought experiment is to construct a bucket containing N counters, marking the ith
counter with the outcome for the ith case. Instead of considering the whole probability distribution
ofthecountersinthebucket,weconsiderasinglequantity,theaverageofthecountersinthebucket,
XN = (X1N, . . . , XrN) where
XN = 1
N
N

i=1
Xi
For the general exchangeability representation, we construct the population distribution from our
beliefs relating to the limit of the sample distributions. For the second order theorem, we construct

Observables and models
13
the population mean M(X) from our limiting beliefs about the sample means. We can do this
because, from the specifications (1.15), the sequence Xi is a Cauchy sequence in mean square, as
for n < m and each i,
E((Xim −Xin)2) = (1
n −1
m)(i −i)
(1.17)
where i, i are the ith diagonal terms of , . Therefore the sequence Xn tends to a limit, and
this limit is the mean quantity M(X). The properties of the sequence Ri(X) follow by evaluating
Cov(Ri(X), M(X)) as the limit of terms Cov(Xi −Xn, Xn) and checking that this limit is zero,
and similarly for Cov(Ri(X), Rj(X)).
We can formalize the construction of this limit, treating expectation as primitive, by constructing
the inner product space I(X) whose vectors are linear combinations of all of the elements Xij, with
covariance as the inner product (we identify as equivalent all quantities which differ by a constant)
and squared norm given by variance. I(X) is a pre-Hilbert space for which we may construct the
minimal closure by adding limit points for all Cauchy sequences whose limits are not already ele-
ments of the space. The inner product over limit points is equal to the limit of the inner product for
theassociatedCauchysequence.By(1.17),thesamplemeansformCauchysequences,andtherefore
our specification is consistent with the existence of such limit points, which we identify with the
elements of M(X).
The second-order exchangeability representation theorem is concerned with population mean
quantities.Itisourchoiceastowhatelementsweintroduceintoourbasevectorsandthereforewhat
we may learn about from such specifications. For example, we may want to learn about population
variation, in which case we must introduce appropriate squared terms into our base vectors, and
make exchangeability statements over the corresponding fourth-order quantities. Details as to how
to make the appropriate exchangeability specifications, the technicalities of the resulting inferences
and the inter-relationship between the adjustment of means and variances are provided in [9].
1.8 Adjusted beliefs
The inner product space described above is the fundamental geometric construct underpinning
the Bayes linear approach. The general form of this construction takes a collection U of ran-
dom quantities, with covariance inner product, and constructs the closure of the inner product
space I(U), denoted [I(U)]. For any quantity Y ∈[I(U)], the adjusted mean and variance of
Y, given a data vector D, are defined to be, respectively, the orthogonal projection of Y into the
subspace spanned by the elements of D and the orthogonal squared distance between Y and this
subspace.
The explicit form for the adjusted
expectation for a vector B given D, where
D = (D0, D1, . . . , Ds), with D0 = 1 is the linear combination aTD where a is the value of
a that you would choose if faced with the penalty
L = (B −aTD)2
It is given by
ED(B) = E(B) + Cov(B, D)(Var(D))−1(D −E(D))
(We may use an appropriate generalized inverse if Var(D) is not invertible.)

14
M. Goldstein
The adjusted variance matrix for D given D, is
VarD(B) = Var(B −ED(D))
= Var(B) −Cov(B, D)(Var(D))−1Cov(D, B)
An important special choice for the belief adjustment occurs when D comprises the indicator
functions for the elements of a partition, i.e. where each Di takes value one or zero and precisely one
elementDi willequalone.Inthiscaseadjustedexpectationisequivalenttoconditionalexpectation,
e.g. if B is the indicator for an event, then
ED(B) =

i
P(B|Di)Di
Therefore, the general inferential properties of belief adjustment that we shall describe below are
inherited by full Bayes analysis, and this offers a formal interpretation of the real world inferential
content of conditional probability arguments.
1.9 Temporal rationality
To understand how subjectivist theory can treat evanescent quantities such as population means,
we must first discuss the inferential content of the standard Bayesian argument for observable
quantities. This is a large and fundamental issue, which deserves far more space than we can give
it here, where all that we will do is to sketch the outline of what is, in my view, the heart of the
subjectivist argument.
Firstly, recall the precise meaning of a formal Bayesian inference. If A and B are both events, then
P(B) is your betting rate on B (e.g. your fair price for a ticket that pays 1 if B occurs, and pays 0
otherwise) and P(B|A) is your current ‘called off’ betting rate on B (e.g. your fair price now for
a ticket that pays 1 if B occurs, and pays 0 otherwise, if A occurs. If A doesn’t occur your price is
refunded).
This is not the same as the posterior probability that you will have for B if you find out that A
occurs. There is no obvious relationship between the called off bet and the posterior judgement at
all, and, in my view, no one has advanced an intellectually compelling argument as to why the two
concepts should be conflated. The called off bet formulation can, however, be understood within
the subjectivist theory as a model for the inference that you will make at the future time.
Models describe how system properties influence system behaviour. They involve two types of
simplification, firstly, the description of system properties and secondly the rules by which system
properties influence system behaviour. Good models capture enough features of the system that
the insight and guidance they provide is sufficient to reduce our actual uncertainty as to system
behaviour. This is valuable, provided that we do not commit the modeller’s fallacy of considering
thattheanalysisofthemodelisthesameastheanalysisofthesystem.Acrucialconditionformaking
good use of a model is to establish the relationship between the model and the actual system, as a
basis for making real world inferences.
To derive such a relationship for the Bayesian model, we must make a link between our con-
ditional judgements now and our actual future posterior judgements. This requires a meaningful
notion of ‘temporal rationality’. Our description is operational, based on preferences between ran-
dom penalties, as assessed at different time points, considered as payoffs in probability currency.
Current preferences, even when constrained by current conditional preferences given possible
future outcomes, cannot require you to hold certain future preferences; for example, you may

Observables and models
15
obtain further, hitherto unsuspected, information or insights into the problem before you come
to make your future judgements, and, always, the way in which you come to learn the information
contained in any conditioning event will convey additional information that was not part of the
formal conditioning.
These difficulties have no such force when considering whether future preferences should deter-
mine prior preferences. Suppose that you must choose between two random penalties, J and K.
For your future preferences to influence your current preferences, you must know what your future
preference will be. You have a sure preference for J over K at (future) time t, if you know now, as a
matter of logic, that at time t you will not express a strict preference for penalty K over penalty J.
Our (extremely weak) temporal consistency principle is that future sure preferences are
respected by preferences today. We call this
The temporal sure preference (TSP) principle Suppose that you have a sure
preference for J over K at (future) time t. Then you should not have a strict preference
for K over J now.
At first sight, the temporal sure preference principle seems so weak that it can never be invoked,
because we will never have a temporal sure preference. However, we actually have many such sure
preferences and these are sufficient to determine the inferential content of the Bayesian model, pro-
vided we accept the temporal sure preference principle for the problem at hand. It is an interesting
philosophical and practical question as to whether and when even this principle is too strong, but
for our purposes here it is sufficient to note that this is the weakest principle which is sufficient to
give a meaningful account of the content of a Bayesian inference. We will construct the argument
for adjusted expectation, the argument for conditional expectation following as a special case, and
then consider inference for exchangeable quantities under this formalism.
1.10 Prior inference
For a particular random vector B, suppose that you specify a current expectation E(B) and you
intendtoexpressarevisedexpectationEt(B)attimet.AsEt(B)isunknowntoyou,youmayexpress
current beliefs about this quantity. Suppose that you will observe the vector D by time t. What
information does the adjusted expectation, ED(B), offer to you now about the posterior assessment
Et(B) that you will make having observed D?
We argue as follows. For any random quantity, Z, you can specify a current expectation for
(Z −Et(Z))2. Suppose that F is any further random quantity whose value you will surely know
by time t. Suppose that you assess a current expectation for (Z −F)2. From the definition of
expectation, at future time t you will certainly prefer to receive penalty (Z −Et(Z))2 to penalty
(Z −F)2. Therefore, by temporal sure preference, you should hold this preference now, and so you
must now assign
E((Z −Et(Z))2) ≤E((Z −F)2)
(1.18)
Let D be a vector whose elements will surely be known by time t. Let I(D, Et(Y)) be the
inner product space formed by adding the elements of Et(B) to I(D). From (1.18), Et(B) is the
orthogonal projection of B into I(D, Et(B)) and ED(B) is the orthogonal projection of Et(B)
into I(D).
Therefore, the temporal sure preference principle implies that your actual posterior expectation,
Et(B), at time t when you have observed D, satisfies the following prior assessments:

16
M. Goldstein
B = Et(B) ⊕S, Et(B) = ED(B) ⊕R
(1.19)
where S, R each have, a priori, zero expectation and are uncorrelated with each other and with D.
Therefore, evaluation of ED(B) resolves some of your current uncertainty for Et(B) which
resolves some of your uncertainty for B. The actual amount of variance resolved is
Cov(B, D)(Var(D))−1Cov(D, B)
We say that ED(B) is a prior inference for Et(B), and therefore also for B. Relation (1.19) holds
whatever the context in which the future judgements will be made. Adjusted expectation may be
viewed as a model for such judgements which reduces, but does not eliminate, uncertainty about
what those judgements should be. This argument is no different than that for the relationship
between any real world quantity and a model for that quantity, except that, within a subjectivist
analysis, we can rigorously derive the basis for this relationship, under very weak, plausible and
testable assumptions.
Note that, if D represents a partition, then conditional and posterior judgements are related as
Et(B) = E(B|D) ⊕R
where
E(R|Di) = 0, ∀i
with interpretation as above.
1.11 Prior inferences for exchangeable quantities
We now extend the notion of prior inference to the model quantities arising in the second order
exchangeability representation, and thus provide an account of the inductive argument relating
inferences about the population model and inferences about members of the population. To
do this, we must first construct an operational meaning for posterior judgements over model
quantities.
Suppose that the sequence of vectors (X1, X2, . . .) is infinite SOE. Suppose that you will
observe a sample X[n] = (X1, . . . , Xn), by time t. You don’t know whether you will still consider
(Xn+1, Xn+2, . . .) to be SOE at time t. We would like to apply the posterior expectation operator
Et(.) directly to the exchangeability representation Xi = M(X) + Ri(X), by the decomposition
Et(Xi) = Et(M(X)) + Et(Ri(X)). In order to do this, we need to give a meaningful construction
forthequantityEt(M(X)).Thiscannotbedonedirectly,asbytimet theremaybenovectorM(X)
to attach the posterior expectation to.
We construct an operational meaning for Et(M(X)) by extending the thought experiment
in which we construct a bucket marked with counters corresponding to the individual Xi val-
ues. For each i > n, we additionally record, on the counter marked with Xi, the value Et(Xi), so
that each counter is marked with a vector Ui = (Xi, Et(Xi)). Let us suppose that we currently
view the sequence Ui as SOE, for i > n. This is a comparatively weak constraint. We do not
now consider that, at time t, the sequence will necessarily still be exchangeable, but we can-
not yet identify any future subsequences about which we already have reason to believe that
our future judgements will be systematically different from our judgements over the rest of the
sequence.

Observables and models
17
Therefore, we have the representation
Ui = M(U) + Ri(U)
The first half of the components of Ui consist of the elements of Xi. The remaining components
consist of the elements of Et(Xi), giving the representation
Et(Xi) = M(Et(X)) + Ri(Et(X))
For any N > n,
1
N −n
N

i=n+1
Et(Xi) = Et(
1
N −n
N

i=n+1
Xi)
(1.20)
Taking the limit, in N, of the left hand side of (1.20) gives the quantity that we identify with
M(Et(X)). The corresponding limit in N of the right hand side of (1.20) is the limit of Et(Xn),
which, as Xn tends to M(X), we equate with Et(M(X)). Therefore, we can equate Et(M(X))
with M(Et(X)). By this construction, we can identify Et(M(X)) as a quantity, derived through
natural exchangeability judgements, which has the same logical status as the quantity M(X)
itself.
Wearenowabletointegratemodelbasedassessmentsintoourpriorinferencestructure.Wehave
the following theorem.
Theorem (Priorinferencesforexchangeablemodels) Supposethat,bytimet,wewillobserveasam-
ple X[n] = (X1 . . . , Xn) from an infinite SOE sequence of vectors. Suppose, also, that the sequence
Ui = (Xi, Et(Xi)), i = n + 1, n + 2, . . . is a SOE sequence. We can construct the further vector,
Et(M(X)), which, given temporal sure preference, decomposes our judgements about any future
outcome Xj, j > n as
Xj −E(X) =
[M(X) −Et(M(X))]
(1.21)
⊕[Et(M(X)) −EX[n](M(X))]
(1.22)
⊕[EX[n](M(X)) −E(M(X))]
(1.23)
⊕[Rj(X) −Et(Rj(X))]
(1.24)
⊕[Et(Rj(X))]
(1.25)
(The orthogonal decomposition of (1.21), (1.22) and (1.23) follows by combining the construction
for(M(X), Et(M(X)),asthelimitofpartialmeansofthequantitiesUi,withtherelationship(1.19)
between each Xi, Et(Xi) and E[n](Xi), derived from TSP. The orthogonal decomposition (1.24),
(1.25) follows from TSP and the orthogonality between the two residual terms and the three mean
termsfollowsaseachcovariancebetweenanindividualresidualtermandthemeantermsmusthave
the same value, by the SOE property of the sequence, and this covariance must therefore be zero,
as the limiting average of the residual terms is equivalent to the zero random quantity.)
The above theorem shows that we may treat the vector M(X) as though it were, in principle,
observable, allowing us to decompose our current uncertainty about each Xj, j > n, into five uncor-
related components of variation, as follows.
Firstly, our epistemic uncertainty is resolved into three components. We will be uncertain about
the value of M(X), at time t, as expressed by the difference between the expectation, Et(M(X)),

18
M. Goldstein
that we will express for this quantity and the quantity itself, from (1.21). Secondly, part of our uncer-
tainty (corresponding to (1.23)) about Et(M(X)) (and thus about M(X)) will be resolved by the
adjusted expectation for M(X) given X[n], but a part corresponding to (1.22), will be unresolved.
Thirdly, this adjusted expectation given X[n] is uninformative for the uncertainty currently treated
as aleatory, namely eachRj(X), about which our future expectation will reduce variation according
to (1.25), leaving variation according to (1.24). Whether we will hold this variation to be aleatory at
time t will be a subjective judgement that can only be made at that future time.
Each term in this decomposition raises basic practical, methodological, foundational and com-
putational issues. As with the exchangeability representation itself, the prior inference theorem for
the representation should be viewed as a starting point, establishing that such a formulation for
inductive inference has a natural and operational meaning, based on the careful treatment of each
of the five components of variation that we must account for. This is a part of the much wider issue
as to the extent to which a Bayesian uncertainty analysis based on a complex scientific model may
be informative for actual judgements about the real world; see the discussion in [8].
References
[1] de Finetti, B. (1931). Funzione caratteristica di un fenomeno aleatorio. Atti della R. Academia
Nazionale dei Lincei, Serie 6. Memorie, Classe di Scienze Fisiche, Mathematice e Naturale,
4:251–299.
[2] de Finetti, B (1974, 1975). Theory of Probability, vol 1, 2, Wiley.
[3] Diaconis, P. (1977). Finite forms of de Finetti’s theorem on exchangeability, Synthese, 36,
271–281.
[4] Feller, W. (1966). An Introduction to Probability Theory and its Applications, vol II, Wiley,
New York.
[5] Goldstein, M (1986). Exchangeable belief structures, JASA, 81, 971–976.
[6] Goldstein, M. (1994). Revising exchangeable beliefs: subjectivist foundations for the induc-
tive argument, in Aspects of Uncertainty, A Tribute to D.V. Lindley, 201–222.
[7] Goldstein, M. (1997). Prior inferences for posterior judgements in Structures and Norms in
Science, M. C. D. Chiara et al., eds, Kluwer, 55–71.
[8] Goldstein,M.(2011).ExternalBayesiananalysisforcomputersimulators.InBayesianStatistics
9. Bernardo, J. M. et al., eds, Oxford University Press.
[9] Goldstein, M. and Woolf, D. (2007). Bayes Linear Statistics: Theory and Methods, Wiley.
[10] Heath, D. and Sudderth, W. (1976). de Finetti’s theorem on exchangeable variables, American
Statistician, 188–189.
[11] Hewitt, E. and Savage, L. J. (1955). Symmetric measures on Cartesian products. Transactions
of the American Mathematical Society, 80: 470–501.
[12] Lauritzen, S. L. (2003). Rasch models with exchangeable rows and columns, Bayesian Statis-
tics, 7, Bernardo, J. M. et al., eds, Oxford University Press.

2
Exchangeability and its
ramifications
a. philip dawid
2.1 Introduction
B
runo de Finetti’s concept of exchangeability [14], and its associated mathematics, form one of
the cornerstones of subjectivist Bayesian inference, providing Bayesians with a good reason to
take seriously the frequentist’s model of independent observations from a common but unknown
distribution. There is indeed a touch of magic about de Finetti’s famous theorem: assuming noth-
ing more than that our attitudes to a sequence of observations would be unchanged if they were
arranged in a different order, it pulls the frequentist model out of a hat.
There are many ways of understanding de Finetti’s theorem, and correspondingly many ways of
generalizing it. One fruitful conception emphasizes the aspect of invariance under the action of a
group: that of all finite rearrangements of the sequence of variables. This leads to generalizations in
which we deal with other groups, acting on other structures, generating different kinds of statistical
model. This chapter presents a brief survey of some of these generalizations and their applications.
It is largely a summary of work that has previously been presented elsewhere [3, 5–7, 9, 10, 12, 13].
2.2 de Finetti’s Theorem
At the purely mathematical level, de Finetti’s theorem (henceforth dFT) supplies a charac-
terization of those joint distributions P for an infinite sequence X = (X1, X2, . . .) of random
variables, all defined on the same space X0, having the property of exchangeability: for any
n = 1, 2, . . . and any permutation π of (1, 2, . . . , n), the joint distribution of the permuted
sequence (Xπ(1), Xπ(2), . . . , Xπ(n)) is exactly the same as that of the unpermuted sequence
(X1, X2, . . . , Xn). dFT shows that, for exchangeability to hold, it is necessary and sufficient that
there exist a distribution (which, to avoid confusion, we shall sometimes term a law) ν over the
space Q of distributions Q on X0, such that, for (suitably measurable) A ⊆X := X ∞
0 ,
P(X ∈A) =

Q
Q∞(X ∈A) dν(Q)
(2.1)
where Q∞is the distribution of X = (X1, X2, . . .) when the (Xi) are independent and identically
distributed, each with distribution Q. The law ν can be uniquely recovered from P as the limit, as

20
A. P. Dawid
n →∞, of the law of the empirical distribution, νn, of (X1, . . . , Xn)—see Goldstein’s chapter in
this volume [20].
For a binary sample space X0 = {0, 1}, dFT shows that any exchangeable distribution can be
obtained from the model of Bernoulli trials with probability parameter q, by mixing with respect to
aprobabilitydistributionν forq ∈[0, 1].FormoregeneralX0 themixingisoverthesetofdistribu-
tions Q on X0, which will typically be a large nonparametric class. But—important mathematical
niceties aside—the story is basically the same [21].
2.2.1 Intersubjective modelling
If your subjective joint distribution for (X1, X2, . . .) is exchangeable, you would not care if some
demon rearranged the sequence in a different order: your opinions for the rearranged sequence
would be exactly the same as they were for the original ordering. (In contrast, this would not hold
if, for example, you thought there were some sort of time trend in the original sequence.)
We can regard this exchangeability property as the natural Bayesian explication of the intuitive
concept of ‘repeated trials of the same phenomenon under constant conditions’, which forms the
basis of the frequentist approach to probability and statistics. Indeed, this Bayesian approach, start-
ing only with the very natural judgement of exchangeability as input, logically derives, via dFT, the
model of independent and identically distributed trials as output. By providing a deeper justifica-
tion for modelling assumptions that are typically—and thoughtlessly—simply taken as obvious
and not in need of deeper analysis, it thus supplies a firmer basis for frequentist statistics than is
available from that theory itself.
To expand on this point, consider a bevy of Bayesians who, while holding differing subjective
probability distributions for X, all agree on exchangeability. Then they will all agree on the rele-
vance of the independent and identically distributed model—the differences between them being
relegated to their varying choices for the prior law for the ‘parameter’ Q of the model. We can
thus justify the frequentist’s statistical model of independent and identically distributed variables
as an intersubjective model [5], conjured into existence by the simple and intuitive exchangeability
judgement: that rearranging the variables should have no effect on judgements about them. Since
thismodelcomprisesthecommonpartofeveryexchangeablejudgement,andsinceitsparameter Q
can berecovered from sufficientlyextensiveobservation, it has at least as much claim to ‘objectivity’
as any other conception of that elusive term.
2.3 Group invariance
Exchangeability of a joint distribution P over X = X ∞
0
can be restated as requiring that P be
invariant under the group of all finite permutations acting on X. dFT shows that the set of such
invariant distributions forms a convex simplex, and that the extreme points of this simplex are the
independent and identically distributed distributions—so that any member of the set has a unique
representation as a convex combination of these extreme points.
Interesting extensions of this characterization arise when we apply it to other transformation
groups, acting on sample spaces possibly other than those of infinite sequences. Thus let X be an
uncertain quantity taking values in a sample space X, let G be a group of transformations acting
on X, and let P denote the set of all distributions P for X that are invariant under G, so that
P(X ∈A) = P(gX ∈A) for all g ∈G and A ⊆X. Then P is a convex set. Let T be the set of
extremepointsofP,i.e.thosedistributionsinT thatcannotberepresentedasanon-trivialmixture
(convex combination) of distributions in P. The extension of (2.1) to this more general context is
then: for any P ∈P there exists a unique law (distribution) ν over T such that, for A ⊆X,

Exchangeability and its ramifications
21
P(X ∈A) =

T
θ(X ∈A) dν(θ).
(2.2)
Here θ ∈T is a distribution over X. A friendlier notation renames this to Pθ, reinterpreting θ as
a label for Pθ, with T the set of such labels, so yielding
P(X ∈A) =

T
Pθ(X ∈A) dν(θ).
(2.3)
The statistical interpretation of this mathematical property is as follows. Suppose You have made
a personal judgement that Your opinions would not be affected if You were to be presented with
gX (g ∈G), rather than X. Then You must act as though You entertained the statistical model P =
{Pθ : θ ∈T } for X, together with a prior distribution ν over its parameter-space T . Again, if we
consider the bevy of Bayesians all of whom agree in regarding invariance under G as appropriate, we
can justify P as the intersubjective model engendered solely by this judgement of group invariance.
At this level of generality, the sample space X need not be a set of infinite sequences, and G
need not be a permutation group. The link with frequentist understandings of modelling is then
broken—but this is to very positive effect. By no longer insisting on any connection with the idea
of ‘repeated trials of the same phenomenon under constant conditions’ this approach supplies a
justificationforstatisticalmodelbuildingthatistotallyunavailablefromthefrequentistperspective.
2.3.1 Sufficiency
An added bonus of constructing statistical models through considerations of invariance is that we
can use them to construct sufficient statistics: under suitable conditions a maximal invariant under
the action of the group will be sufficient for the associated intersubjective model [17]. Thus for
the case of exchangeability, where we observe just the first n variables (X1, . . . , Xn), the maximal
invariant under the permutation group is their order statistic—which is indeed sufficient for the
model of all independent and identically distributed distributions for the (Xi). For a binary sample
space, this reduces to the counts of 0s and 1s, which are sufficient for the Bernoulli model.
The above approach to model-building through invariance identifies the members of the inter-
subjective statistical model as the extreme points of the convex set of all invariant distributions.
Another approach [18, 25, 26] starts by specifying what are the sufficient statistics, and suitably
relating these, both algebraically and probabilistically, across different sample sizes. The set of
all distributions consistent with these properties will again be a simplex, and its extreme points
can be regarded as the associated statistical model—an extreme point model. When, as here, both
approaches are possible they lead to the same model [5].
2.4 Other symmetry groups
Staying for the moment with the infinite product sample space X = X ∞
0 , we can entertain
different groups acting on it.
2.4.1 Larger group
For a symmetry group G that contains the group of all finite permutations, the corresponding
intersubjective model would still involve independent and identically distributed variables, but
would impose additional structure on their common distribution.

22
A. P. Dawid
One such larger symmetry group is that of all finite orthogonal transformations, where,
for any n = 1, 2, . . ., and any orthogonal transformation R of Rn, the distributions of
Xn := (X1, . . . , Xn)T and of RXn are judged to be the same. It was asserted by Freedman [19] and
shownbyKingman[24]thatajointdistributionhasthispropertyifandonlyifitcanbeexpressedas
amixture,oversomelawfortheparameterφ ≥0,ofthejointdistributionsXi
i.i.d.
∼Norm(0, φ).That
is, the model of independent and identically distributed normal variables with mean 0 arises from
a judgement of rotational symmetry. With finitely many observations (X1, . . . , Xn), the maximal
invariant under this rotation group is n
i=1 X2
i , which is thus a sufficient statistic for this model.
Extendingthisresult,AdrianSmith[31]showedthattheindependentandidenticallydistributed
normal model with both parameters unconstrained arises similarly from the assumption of invari-
ance under the subgroup of finite orthogonal transformations that preserve the unit vector. The
maximal invariant is now (n
i=1 Xi, n
i=1 X2
i ), which is sufficient for this model.
2.5 Smaller group
Alternatively, we can consider ‘restricted exchangeability’, where we only require invariance under
some smaller group of permutations. Often these will respect some additional structure in the
sample space.
2.5.1 Partial exchangeability
Consider binary variables laid out in a semi-infinite two-way array: (Xij : i = 1, . . . , k;
j = 1, 2, . . .). An interpretation could be that we have a number of different coins, labelled
by i, with possibly different biases, and can toss each of them over and over, with j labelling the
toss. Then it could be appropriate to judge the problem invariant under any permutation of tosses
j of the same coin (i.e. for fixed i), but not if we permute across the coins. This is the property of
partial exchangeability [15]. The associated intersubjective statistical model has, as parameter, a
vector p ∈[0, 1]k, and then has all the (Xij) independent, with Prob(Xij = 1|p) = pi. That is, we
simply assign different probabilities to the different coins.
As an intermediate position between full and partial exchangeability, we can permit further
invariance of the problem under permutations of the label i of the coins. This might be appropriate
if the coins were taken randomly from the output of a mint whose quality control is less than
perfect, so that different coins might have different biases, but in an unsystematic way. We now
allow a potentially infinite number of such coins (so i = 1, 2, . . .), with invariance under all finite
permutations of i.
The associated intersubjective statistical model can be expressed hierarchically [6]:
1. The parameter is a distribution 	 on [0, 1].
2. Given 	, variables (Pi : i = 1, 2, . . .) are independent and identically distributed according
to 	.
3. Given (	 and) the (Pi), the Xij are independent, with
Prob(Xij = 1) = Pi.
ThemodelconditionalonthePi isthusexactlythesameasforpartialexchangeability;butnow,cor-
responding to the new assumption of exchangeability of the coins, the (Pi), which were previously
entirely arbitrary ‘fixed effects’, are themselves modelled as ‘random effects’, drawn independently
from a common distribution.

Exchangeability and its ramifications
23
2.5.2 Row–column exchangeability
In the above example the labelling j of the tosses has no objective meaning that carries across the
coins: there is, for example, no special relationship between the third toss of coin 1 and the third
toss of coin 2, and this indeed is why it can make sense to consider permuting the tosses of coin 1
while leaving those of coin 2 in place.
In other contexts there may be such correspondences of j-values across different i. Thus suppose
a number of students (labelled by i) answer a number of questions (labelled by j). Then each of i
and j has an intrinsic meaning across the levels of the other.
Insuchacasewemightwanttoconsiderbothstudentsandquestionsasseparatelyexchangeable.
That is, our attitudes to the problem are considered unchanged when we replace the array (Xij) by
Xρ(i)σ(j), where ρ and σ are arbitrary finite permutations acting respectively on i and j. Note that
such permutations preserve the integrity of individual students and questions.
Analysis of this problem is subtle. Aldous [1] showed that, for a doubly infinite array of binary
variables, the associated intersubjective statistical model can be represented hierarchically as
follows:
1. The parameter is a function F : [0, 1]2 →[0, 1].
2. Given F, generate random (Pij) in [0, 1] as
Pij = F(αi, βj)
where the αs and βs are all independent and identically distributed with the uniform distri-
bution over [0, 1].
3. Given (F and) the (Pij), generate the (Xij) independently, with
Prob(Xij = 1) = Pij.
We can regard αi as a measure of the quality of student i, and βj as a measure of the difficulty of
question j. The independent and identically distributed property reflects the assumed separate
exchangeability of students and of questions. Note that, for any joint distribution of this form,
the sets (Xij : i ∈I, j ∈J) and (Xij : i ∈I′, j ∈J′) are independent of each other whenever there
is both no overlap of students (I ∩I′ = ∅) and no overlap of questions (J ∩J′ = ∅). Such an
array is termed dissociated [27]. Moreover, any dissociated row–column exchangeable array can be
represented in the above form.
However, this representation, while appealing in many ways, is not ideal, in that different choices
forF canleadtoidenticaljointdistributionsofthe(Xij),sothattheparameterF isnotidentifiable(it
isinfactidentifiablemodulotransformationsofitsargumentsbyseparatefunctionseachpreserving
the uniform distribution [22, 23]). Also, for a finite data array, the maximal invariant under the
permutation group (which by, the general theory, is a sufficient statistic for the model) is hard to
describe.
2.5.3 Spherical matrix models
We can combine the above generalizations of exchangeability—orthogonal tranformations rather
than permutations, and two-way arrays rather than sequences. Thus suppose we have a doubly infi-
nite array (Xij) of real variables whose distribution can be regarded as spherical, i.e. the distribution
of any finite submatrix is invariant under the actions of both left- and right-multiplication by an
orthogonal matrix. Then the intersubjective model comprises those spherical distributions that

24
A. P. Dawid
are also dissociated. Moreover (assuming finite second moments), any such distribution can be
expressed in the form
Xij = λ0Uij +
∞

m=1
λmVimWmk
where the λs are non-negative real constants with λ1 ≥λ2 ≥. . . and ∞
m=1 λ2m < ∞, and all
the Us, Vs and Ws are independent Norm(0, 1) variables [1, 4]. It is rather easier to see that the
group-induced sufficient statistic, based on a finite submatrix (Xij : 1 ≤i ≤I, 1 ≤j ≤J), is the
unordered set of singular values of the matrix.
2.6 Second-order behaviour
For many purposes it is sufficient to confine attention to the joint first- and second-order moment
structure of our variables. Thus if (X1, X2, . . .) is an exchangeable sequence with finite variance,
then it is easy to see that there must exist constants μ, γ0, γ1 such that, for all i ̸= j:
E(Xi) = μ
(2.4)
var(Xi) = γ0
(2.5)
Cov(Xi, Xj) = γ1.
(2.6)
More generally, we call the sequence (Xi) second-order exchangeable if the properties (2.4)–(2.6)
hold. This is equivalent to requiring that the mean and dispersion structure of the sequence be
invariant under the group of finite permutations.
In this case, define φ1 = γ1, φ0 = γ0 −γ1. It is readily checked that var(Xn) = φ0 + φ1/n,
whence, since n can be arbitrarily large, φ0 ≥0. Also we find var(Xn −Xn) = (1 −1/n)φ1, so
that φ1 ≥0.
Now, for any real μ and φ0, φ1 ≥0, consider uncorrelated variables Z, Y1, Y2, . . ., with zero
means, and
var(Z) = φ0
var(Yi) = φ1
and define
Xi = μ + Z + Yi.
(2.7)
Then it is easy to see that the (Xi) satisfy (2.4)–(2.6). Moreover, we can recover Z as the mean
square limit of Xn −μ as n →∞, and then Yi as Xi −Z −μ. Hence an infinite sequence (Xi) is
second-order exchangeable if and only if it can be represented as in (2.7), where Z, Y1, Y2, . . . are
uncorrelatedwithzeromeansandvar(Yi)isthesameforalli.Thiscanberegardedasasecond-order
(and indeed much simpler) variant of de Finetti’s theorem: rather than the (Xi) being independent
and identically distributed, after suitable conditioning, now they are uncorrelated with constant
variance, after suitable partialling out of Z. See Goldstein [20, Section 7].
When we consider finite rather than infinite second-order exchangeable sequences, it need no
longer be true that φ0 ≥0, in which case there can be no real variable Z with var(Z) = φ0. Even
so, for computing variances of linear functions of the (Xi) we can still proceed as though we had a
representation of the form (2.7).

Exchangeability and its ramifications
25
2.7 Extension to experimental layouts
Again, we can usefully extend the above ideas to other groups, acting on structures other than
the sequence. We illustrate this here for the special case in which a number of workers, labelled
by w, each operate a number of machines, labelled by m, for a number of different runs, labelled
by r. However the theory extends straightforwardly to general distributive block structures [2, 11],
which include most of the classical experimental layouts (in particular, all simple orthogonal block
structures [28, 29]).
2.7.1 Fully random model
Let Xmwr be a measure of the quality of the rth run produced by worker w when operating machine
m. In such a case it might sometimes be reasonable for attitudes about all the (Xmwr) to be invariant
under the following permutations:
1. Permutations of r for a fixed combination of m and w—corresponding to exchangeability of
the different runs made by a given worker on a given machine.
2. Permutations of w for fixed m—corresponding to a judgement of exchangeability of the
workers with each other.
3. Permutations of m for fixed w—exchangeability of the machines one with another.
If we focus only on the dispersion structure, and assume this is invariant under the group gen-
erated by all the above permutations, then, analogous to (2.7), we obtain the following synthetic
representation:
Xmwr = μ + αm + βw + γmw + ϵmwr
(2.8)
where μ is a constant, and the other variables appearing on the right-hand side are mutually uncor-
relatedrandomvariables,alltermsinvolvingthesameGreekletterhavingthesamevariance.Aslong
as the array is infinitely extendible in all directions, these variances will all be non-negative, and the
representation (2.8) becomes a genuine equality, with the terms on the right-hand side identifiable
as mean square limits of functions of the Xs.
The ‘parameters’ of the model (2.8) are μ and the respective variances φα, φβ, φγ , φϵ of the
random terms. We can thus consider this model, where these parameters can vary freely, as the
intersubjective second-order model corresponding to the imposed symmetries. We see that our
simple symmetry assumption delivers, for free, the usual ‘random effects’ model for this layout.
We can also use the symmetries (specifically, utilizing group representation theory) to deliver
for free the appropriate decomposition of data (from a finite balanced layout) into main effects and
interactions:
Xmwr = X... + (Xm.. −X...) + (X.w. −X...) + (Xmw. −Xm.. −X.w. + X...) + (Xmwr −Xmw.)
(2.9)
(where a dot indicates an average over the range of the replaced subscript in the data). Symmetry
arguments can also be invoked to specify meaningful null hypotheses. For example, one possible
interpretationoftheassertionthatthereare‘nodifferencesbetweentheworkers’isthattheproblem
wouldremaininvariantunderthestilllargergroupthat(inadditiontopermutationsofthemachine
label m) allowed permutations of all the runs on a given machine, irrespective of whether or not
these were produced by the same worker. This delivers the model obtained from (2.8) by omitting

26
A. P. Dawid
the terms βw and γmw. It thus corresponds to the ‘null hypothesis’ φβ = φγ = 0, which in turn,
in the context of the data-decomposition (2.9), is equivalent to the equality of the mean squares
for workers, for machine–worker interaction, and for runs—thus suggesting appropriate statistical
tests. See [9] for further details.
Another use of symmetry [3] is to make predictive inferences of various kinds—for example, for
the production of a machine featuring in our experiment operated on by a new worker.
2.7.2 A mixed model
However, the symmetry approach is not just a different way of deriving and thinking about known
results. It can also lead to new perspectives, models and analyses.
Thus suppose, in the above example, we have a finite number M of machines, and, recognizing
that these are of various different kinds, are no longer willing to assume invariance under permu-
tations of the index m—while still retaining (second-order) exchangeability between workers w,
and between the runs r for any (m, w) combination. The intersubjective model generated by these
reduced symmetry assumptions is now [8]
Xmwr = μm + αmw + ϵmwr
(2.10)
where:
1. μ1, . . . , μM are arbitrary constants.
2. αmw is (αw)m, where αw is a random (M × 1) vector, with mean 0 and arbitrary (M × M)
dispersion matrix α (the same for all w).
3. ϵmwr is a real random variable, with variance φm depending on m alone.
4. The distinct vectors αw and scalars ϵmwr are all mutually uncorrelated.
In this model, the parameters are the ‘fixed effect’ machine means μ1, . . . , μM, the (M × M)
dispersionmatrixα ofthe‘randomacross-machineworkereffects’, (αw),andthewithin-machine
variances φm (m = 1, . . . , M) of the ‘random run effects’, (ϵmwr). All these quantities can be con-
sistently estimated from data on the M machines and indefinitely many workers and runs.
This model, fully justified by the symmetry assumptions from which it derives, differs from
standard formulations of the ‘mixed model’. Once again, the symmetries can be used to guide
hypothesis generation, data-analysis and predictive inference. For example, the associated data-
decomposition is
Xmwr = Xm.. + (Xmw. −Xm..) + (Xmwr −Xmw.)
where the component terms are independent, and have a special dispersion structure induced from
that of (2.10). The symmetry analysis now leads to new tests of ‘no worker effect’, and even to a test
of exchangeability between the machines (i.e. the model considered in Section 2.7.1).
2.8 Population genetics
An application of the symmetry approach to modelling arises in population genetics. We are
interested in a collection of genetic markers (loci on the genome), labelled m = 1, . . . , M. For
simplicity, we suppose each of these has two possible variants (alleles), coded 0 and 1. We can

Exchangeability and its ramifications
27
sample data from a population of individuals, which itself is divided into many subpopulations
(e.g. different ethnic groups), labelled s = 1, . . . , S. We assume random mating within each sub-
population s. For each pair (s, m) there is a gene pool, comprising all the genes (with values 0 or 1)
at marker m possessed by all the individuals in subpopulation s. We thus have an array (Xsmg) of
binary variables, where Xsmg is the allele of the gth gene within the gene pool for marker m in
subpopulation s.
Reasonable symmetry assumptions to impose on this array are:
1. Exchangeability of the genes within each gene pool (note that, because of random mating,
there is no reason to expect the relationship between the two genes comprising the genotype
ofthesameindividualtodifferinanywayfromtherelationshipbetweentwogenesbelonging
to different individuals).
2. Exchangeability of the subpopulations.
However we do not impose exchangeability of the markers.
Any joint distribution satisfying these symmetry assumptions can be represented in the follow-
ing hierarchical way:
1. Generate, by some random process, a distribution 	 over the space [0, 1]M.
2. Given 	, generate vectors (Ps) in [0, 1]M, independently from distribution 	.
3. Given
(	
and)
the
(Ps),
generate
independent
binary
variables
Xsmg
with
P(Xsmg = 1) = Psm (the m-entry of Ps).
Thus Ps describes the frequency distributions of the different markers, within subpopulation s.
Also, although it does not follow directly from symmetry, it might be reasonable from scientific
considerations (especially if the different markers are on different chromosomes) to assume that,
for a random vector P ∼	, its components (Pm) are independent (though not necessarily identi-
cally distributed). For example, we might take, for 	, a distribution in which Pm ∼β(am0, am1),
independently; then 	 is determined by the (amj) (m = 1, . . . , M; j = 0, 1). However this extra
specialization is inessential.
The intersubjective model corresponding to the assumed symmetry properties would take as
its parameter the distribution 	 (or, in the above specialization, the (amj)), and so be described
by levels 2 and 3 of the above hierarchy. The full hierarchical model of a single Bayesian would be
obtained by adding in, as level 1, a subjective prior distribution (essentially unconstrained) for 	
(or for the (amj)).
Note that in this intersubjective model, because of the random nature of Pms we will have
exchangeability, but not independence, between the genes within a common gene pool,
However, the full hierarchical model can also be deconstructed in the following, equally
valid, way. We take as our ‘parameter’ the quantities (Psm), and as our ‘model’ the final stage 3
of the hierarchy. We flesh out the hierarchy with a joint prior distribution for the (Psm),
obtained by combining levels 1 and 2 of the hierarchy. (The first stage is again essentially arbi-
trary, but the second is now not, so imposing constraints on the form of the joint ‘prior’
distribution of the (Psm).) In this description, the genes within a given gene pool are now
independent.
We thus see that it is not meaningful to ask whether or not the genes in a gene-pool are really
independent—the answer depends on a somewhat arbitrary choice we have to make as to where
to draw the line between model and prior. This realization takes some of the heat out of the appar-
ently discrepant modelling assumptions made in [16] and [30], and their application to criminal
identification by means of DNA profiling [12, 13].

28
A. P. Dawid
References
[1] Aldous,DavidJ.(1981).Representationsforpartiallyexchangeablearraysofrandomvariables.
Journal of Multivariate Analysis, 11, 581–598.
[2] Bailey, Rosemary A. (1981). Distributive block structures and their automorphisms. In Com-
binatorial Mathematics VIII (ed. K. L. McAveny), Volume 884 of Lecture Notes in Mathematics.
Springer Verlag, Berlin.
[3] Dawid, A. Philip (1977). Invariant distributions and analysis of variance models.
Biometrika, 64, 291–297.
[4] Dawid,A.Philip(1978).Extendibilityofsphericalmatrixdistributions. JournalofMultivariate
Analysis, 8, 559–566.
[5] Dawid, A. Philip (1982). Intersubjective statistical models. In Exchangeability in Probability
and Statistics (ed. G. Koch and F. Spizzichino), pp. 217–232. North-Holland Publishing Com-
pany, Amsterdam.
[6] Dawid, A. Philip (1985). Probability, symmetry and frequency. British Journal for the Philoso-
phy of Science, 36, 107–128.
[7] Dawid, A. Philip (1986). A Bayesian view of statistical modelling. In Bayesian Inference and
Decision Techniques (ed. P. K. Goel and A. Zellner), Chapter 25, pp. 391–404. Elsevier Science
Publishers B.V. (North-Holland), Amsterdam.
[8] Dawid, A. Philip (1986). Symmetry analysis of the mixed model. Research Report 53, Depart-
ment of Statistical Science, University College London.
[9] Dawid, A. Philip (1988). Symmetry models and hypotheses for structured data layouts.
Journal of the Royal Statistical Society, Series B, 50, 1–34.
[10] Dawid, A. Philip (1993). Taking prediction seriously. Bulletin of the International Statistical
Institute, 55(3), 3–13.
[11] Dawid, A. Philip (1994). Distributive block structures: Mathematical properties. Research
Report 133, Department of Statistical Science, University College London.
[12] Dawid, A. Philip (1997). Modelling issues in forensic inference. In ASA Proceedings of the Sec-
tion on Bayesian Statistical Science, pp. 182–186. American Statistical Association (Alexandria,
VA).
[13] Dawid, A. Philip and Pueschel, John (1999). Hierarchical models for DNA profiling using
heterogeneous databases (with Discussion). In Bayesian Statistics 6 (ed. J. M. Bernardo, J. O.
Berger, A. P. Dawid, and A. F. M. Smith), Oxford, pp. 187–212. Oxford University Press.
[14] de Finetti, Bruno (1937). La prévision: Ses lois logiques, ses sources subjectives. Annales de
l’Institut Henri Poincaré, 7, 1–68. English translation “Foresight: Its logical laws, its subjective
sources”, in Studies in Subjective Probability (1964) (H. E. Kyburg and H. E. Smokler, eds.),
pp. 93–158. Wiley, New York.
[15] de Finetti, Bruno (1938). Sur la condition d’équivalence partielle. In Colloque Consacré à la
Théorie des Probabilités, Volume VI, pp. 5–18. Herman et Cie, Paris.
[16] Evett, Ian W., Foreman, Lindsey A., and Weir, Bruce S. (2000). Letter to the Editor (with
responses by A. Stockmarr and B. Devlin). Biometrics, 56, 1274–1275.
[17] Farrell, Roger H. (1962). Representation of invariant measures. Illinois Journal of Mathemat-
ics, 6, 447–467.
[18] Freedman, David A. (1962). Invariants under mixing which generalize de Finetti’s theorem.
The Annals of Mathematical Statistics, 33, 916–923.
[19] Freedman, David A. (1963). Invariants under mixing which generalize de Finetti’s theorem:
Continuous time parameter. The Annals of Mathematical Statistics, 34, 1194–1216.
[20] Goldstein, Michael (2012). Observables and models: exchangeability and the inductive argu-
ment. In Bayesian Theory and Applications (P. Damien, P. Dellaportas, N. G. Polson and
D. A. Stephens, eds.), pp. 3–18. Oxford University Press, Oxford.

Exchangeability and its ramifications
29
[21] Hewitt, Edwin and Savage, Leonard J. (1955). Symmetric measures on Cartesian products.
Transactions of the American Mathematical Society, 80, 470–501.
[22] Hoover, Douglas N. (1979). Relations on probability spaces and arrays of random variables.
Preprint, Institute for Advanced Study, Princeton, New Jersey.
[23] Hoover, Douglas N. (1982). Row-column exchangeability and a generalized model
for exchangeability. In Exchangeability in Probability and Statistics (ed. G. Koch and
F. Spizzichino), pp. 281–291. North-Holland, Amsterdam.
[24] Kingman, John F. C. (1972). On random sequences with spherical symmetry. Biometrika, 59,
492–493.
[25] Lauritzen, Steffen L. (1988). Extremal Families and Systems of Sufficient Statistics. Number 49
in Lecture Notes in Statistics. Springer-Verlag, Heidelberg.
[26] Martin-Löf, Per (1974). Repetitive structures and the relation between canonical and micro-
canonical distributions in statistics and statistical mechanics. In Proceedings of Conference on
Foundational Questions in Statistical Inference (ed. O. E. Barndorff-Nielsen, P. Blæsild, and
G. Schou), Volume 1, Aarhus, pp. 271–294.
[27] McGinley, William G. and Sibson, Robin (1975). Dissociated random variables. Mathematical
Proceedings of the Cambridge Philosophical Society, 77, 185–188.
[28] Nelder,JohnA.(1965).Theanalysisofrandomizedexperimentswithorthogonalblockstruc-
ture: I. Proceedings of the Royal Society of London, Series A, 283, 147–162.
[29] Nelder,JohnA.(1965).Theanalysisofrandomizedexperimentswithorthogonalblockstruc-
ture: II. Proceedings of the Royal Society of London, Series A, 283, 163–178.
[30] Roeder, Kathryn, Escobar, Michael, Kadane, Joseph B., and Balazs, Ivan (1998). Measuring
heterogeneity in forensic databases using hierarchical Bayes models. Biometrika, 85, 269–287.
[31] Smith, Adrian F. M. (1981). On random sequences with centered spherical symmetry. Journal
of the Royal Statistical Society, Series B, 43, 208–209.

This page intentionally left blank 

Part II
Hierarchical Models

This page intentionally left blank 

3
Hierarchical modelling
alan e. gelfand and souparno ghosh
3.1 Introduction
A
s we move into the second decade of the twenty-first century, we are witnessing a dramatic
paradigm shift in the way that statisticians collaborate with researchers from other disciplines.
Disappearing are the days when the statistician was called in at the end of a project to provide
some routine data analysis and some summary displays. Now the statistician is an integral player
in a research team, helping to formulate hypotheses, identify data needs, develop suitable stochas-
tic models, and implement fitting of the resulting challenging models. Altogether, the statistician
becomessufficientlyknowledgeableinthesubjectmatterto‘walkthewalk’and‘talkthetalk’,adding
another scientific dimension to her/his skill set.
As part of this shift, there is increasing attention paid to bigger picture science, to looking at com-
plex processes with an integrative perspective and to bringing a range of knowledge to this effort.
Increasingly, we find researchers working with observational data, less with designed experiments,
recognizing that the latter can help inform about the former, but the gathering of such experiments
providesonlyonesourceofdataforlearningaboutthecomplexprocess.Otherinformationsources,
empirical, theoretical, physical, etc. will also be included in the synthesis.
The primary result of all of this is the development of a multilevel stochastic model which
attempts to incorporate the foregoing knowledge, inserting it at various levels of the modelling, as
appropriate. A key recognition in all of this is the importance of introducing uncertainty and how
to do so. That is, as always, the stochastic models are only approximations to the complex process
so error will always be introduced. Hence, in addition to the modelling challenge is the question
of where and how to introduce error. In this regard, Michael Goldstein, in his presentation at the
AFMS Conference, which motivated this volume, discussed a catalogue of such errors including:
parameter uncertainty, functional uncertainty, model uncertainty, stochastic uncertainty measure-
ment uncertainty and multiple model uncertainty.
Following the vision of Mark Berliner [8], we imagine a three-stage hierarchical specification:
First stage: [data|process, parameters]
Second stage: [process|parameters]
Third stage: [(hyper)parameters]
The simple form of this specification belies its breadth. The process component can include multi-
ple levels. It can be dynamic, it can be spatial. The data can be conditioned on whatever aspects of
the process are appropriate. The stochastic forms can be multivariate, perhaps infinite dimensional
with parametric and/or nonparametric specifications. (In this volume, see the companion piece by

34
A. E. Gelfand and S. Ghosh
Chakrabortyetal.foranexampleoftheformerandthecompanionpiecebyKottasandFronczykfor
an example of the latter.) Moreover, the range of applications to which this generic specification has
been applied runs the scientific gamut, e.g. biomedical and health sciences, economics and finance,
environment and ecology, engineering and natural science, political and social science.
In view of the above, hierarchical modelling has taken over the landscape in contemporary
stochastic modelling. Although analysis of such modelling can be attempted through non-Bayesian
approaches, working within the Bayesian paradigm enables exact inference and proper uncertainty
assessment within the given specification.
Finally,then,theobjectiveofthischapteristoprovidearepresentativereviewoftherangeofsuch
modelling. In the development, we will also note the connections to Gibbs sampling, in particular,
whyGibbssamplingandMCMCareideallysuitedtofitsuchmodels.Wealsoattempttosectionthe
paper by type of model but acknowledge that, in fact, model types are not disjoint. The overarching
building block is the notion of latent variables, e.g. random effects, missing data, labels. We will see
that these variables introduce unobservable process features which will be of interest, as well as
facilitating model-fitting. With regard to the latter, Gibbs sampling loops become natural, updating
other parameters given the values of the latent variables and then updating the latent variables given
the values of the other parameters. For instance, in modelling a complex process, we might have a
dynamic model that introduces spatial random effects, temporal autoregressive effects, with errors
in variables and which also accommodates missing data.
Inanyevent,theformatofthepaperisasfollows.InSection3.2werecallthebasicsofhierarchical
forms,includingrandomeffectsandmissingdata.Section3.3offerssomescopefortheintroduction
of other sorts of latent variables. Section 3.4 considers mixture models while Section 3.5 returns to
random effects, primarily in the context of structured dependence. Section 3.6 looks at dynamic
models while Section 3.7 considers relatively recent ideas in data fusion. We end with a brief sum-
mary in Section 3.8.
3.2 The basics
The earliest hierarchical models introduced Gaussian first and second stages [12]. Subsequently
these models have been absorbed into the widely used class of hierarchical models popularized by
RaudenbushandBryk[54].Inparticular,wecanrefertotheseasstandardhierarchicallinearmodels
with the specification:
First stage: Y |X , β ∼N(X β, Y )
Second stage: β|Z, α ∼N(Zα, β)
Third stage: α ∼N(α0, α)
This simple version assumes all s known. If not, inverse Gamma or Wishart priors are introduced
atthethirdstage.Model-fittingwithintheBayesianframeworkusingMCMCisroutine.Indeed,due
to the conjugacy, we have standard distributions for all full conditionals. Hence, we can implement
a vanilla Gibbs sampler to perform the model-fitting [39].
This class of models encompasses what is generally characterized as the study of linear models
[26]. If the first stage is changed to another member of the exponential family and connected to
the second stage through a suitable link function, we obtain a hierarchical generalized linear model
[32]. Now the conjugacy between the first and second stages is lost. Within MCMC, earlier, such
models were fitted using adaptive rejection sampling [27] due to the log concavity of the resulting
fullconditionaldistributions.Nowadays,Metropolis–Hastingsupdatingwouldmorelikelybeused
with some adaptive tuning of the acceptance rates.

Hierarchical modelling
35
In this vein, substantial effort was put into the investigation of so-called conditionally inde-
pendent hierarchical models (CIHMs). Much of this work took place in the Statistics group at
Carnegie Mellon University with model-fitting through Laplace approximation [35, 66]. This effort
preceded the entrance of Gibbs sampling and MCMC as Bayesian computation tools. Interestingly,
theapproachisnowenjoyingarevivalthroughtherecentdevelopmentofintegratednestedLaplace
approximation (INLA), led by Håvard Rue and his group at Trondheim in Norway [59].
The CIHM takes the basic form
	i[Yi|θi]	i[θi|η][η]
That is, exchangeable θi are assumed. If η is fixed, then we can fit separate models for each i. In
practice,thiswouldnotbethecaseand,withunknown η,weobservethewell-knownphenomenon
of shrinkage or borrowing strength across the is (see e.g. [19] and references therein). Evidently, the
CIHM includes the hierarchical GLM, i.e. it allows a non-Gaussian first stage.
A more elaborate extension of the CIHM is the setting of dependent ARMA time series. Here,
we model
Yit = XT
i βi +

j
φijYi,t−j +

k
θikϵi,t−k + ϵit
At the second stage, we specify exchangeable βi, φi, θi. We adopt a usual vague Gaussian prior on
β, adding constrained priors on the φs and θs (to ensure stationarity). Finally, ϵt ∼N(0, ).
3.2.1 Random effects and missing data
Arguably, the utilization of hierarchical models initially blossomed in the context of handling
random effects and missing data, using the E-M algorithm [17] for likelihood analysis and Gibbs
Sampling [24] for fully Bayesian analysis. In this subsection, we offer some elementary remarks,
first on random effects, then on missing data.
With regard to random effects, both classical and frequentist modelling supply a stochastic spec-
ification for these effects, usually assumed to be a normal distribution with an associated variance
component. These effects can be introduced at different levels of the modelling but, regardless, in
much of the literature, they are assumed to be exchangeable, in fact i.i.d. [64]. More recently, we
are seeing random effects with structured dependence in, e.g. dynamic, spatial and spatio-temporal
models (see Section 3.5).
A typical linear version with i.i.d. effects takes the following form. At the first stage,
Yij = XT
ij β + φi + ϵij.
At the second stage, β has a Gaussian prior while the φi are i.i.d. ∼N(0, σ 2
φ). The ϵij are i.i.d.
∼N(0, σ 2ϵ ). The variance components become the third stage hyperparameters, i.e. we require
prior specifications for σ 2
φ, σ2ϵ . As has been learned over recent years, care is required in these
specifications. Improper priors can lead to improper posteriors [5–7]. The frequently employed
inverse gamma priors, IG(ϵ, ϵ) for small ϵ are nearly improper and result in nearly improper pos-
teriors, as well as badly behaved MCMC in practice. A protective recommendation is an IG(1, b)
or IG(2, b). Both are far from improper; the former has no integer moments, the latter has a mean
but no variance. Evidently, we can revise the model to have a non-Gaussian first stage. Again, care
is needed with prior specifications as well as in model-fitting.

36
A. E. Gelfand and S. Ghosh
In collecting information on, e.g. individuals, we often have vectors of data with one or more
components of the components missing. It is unattractive to confine ourselves to analysing only
the complete data cases. This may discard too much data and possibly introduce bias with regard to
the ones retained. To use the individuals with missing data, we must complete them, the so-called
imputation [38]. There is by now a very substantial literature on imputation but to do a fully
model-based imputation in the Bayesian setting results in latent variables and Gibbs looping. In
this sense, the Gibbs sampler extends the E-M algorithm to provide full posterior inference rather
than an MLE with an asymptotic variance.
As a simple example, consider multivariate normal data, Yi ∼N(μi, ) where the components
of μi may have regression forms in suitable covariates. Some components of some of the Yis are
missing.Inordertoperformtheimputation,wedobasicGibbssampling:weupdatetheparameters
given values for the missing data, then update the missing data given values for the parameters.
Another standard example considers missing categorical counts within a multinomial model where
themultinomialcellprobabilitiesmightbemodelledusingsomesortofmultivariatelogitmodel[1].
For instance, some categories are aggregated/collapsed so counts for the disaggregated categories
are missing. Again, we can envision a usual Gibbs loop: update the parameters given values for all
the counts, update the missing counts given values for the parameters.
3.3 Latent variables
As noted above, latent variables are at the heart of most hierarchical modelling. Here, we provide
examples which suggest they can be envisioned beyond random effects or missing data.1 Latent
variable models customarily result in a hierarchical specification of the form [Y|Z][Z|θ][θ]. Here,
the Ys are observed, the Zs are latent and the ‘regression’ modelling is shifted to the second stage.
An elementary version of a latent variable model arises with binary data models. In particular,
the usual binary response model adopts a logit or probit link function. Illustrating with the probit,
suppose Yi ∼Bernoulli(p(Xi)) (more generally, we can have Yi ∼Bin(ni, p(Xi))). Specifically,
let −1(p(Xi)) = Xiβ with a prior on β. In fitting this model using MCMC computation, it
is awkward to sample β using the likelihood in this form. So, let us introduce Zi ∼N(Xiβ, 1).
Immediately, P(Yi = 1) = (Xiβ) = 1 −(−Xiβ) = P(Zi ≥0). Once we bring in these Zis,
we achieve a routine Gibbs sampler: update the Zs given β, y (this requires sampling from a trun-
cated normal), update β given the Zs and y (this is the usual, typically conjugate normal updating).
This approach was first articulated in the literature by Albert and Chib [2].
It is clear that this approach can be readily extended to general ordinal categorical data settings
[13, 33]. In particular, for each i, the Bernoulli trial is replaced with a multinomial trial. There is
still a latent Zi, still following say a Gaussian linear regression. Now the multinomial outcomes are
created by introducing cut points along the real line; the intervals determined by the cut points
allocate probabilities to each of the multinomial outcomes. The cut points will be random as well,
noting that, in order to identify the intercept in the regression, the smallest cut point can be taken
to be 0, without loss of generality.
Anotherroutinegeneralizationofthisapproachaccommodatescensoredortruncateddatamod-
els. As a simple illustration, suppose we observe a variable with a point mass at 0 and the remainder
of its mass spread over R+ or perhaps (0, 1]. In the first case, such data arise when studying, for
instance, daily precipitation at a location; in the second case when considering, for instance, the
1 While, in a sense, all variables we can not observe are ‘missing’, in the previous subsection we take missing
to mean some components of the data, while here they will be variables different from the data.

Hierarchical modelling
37
proportion of a particular land use classification over a region. Here, with observed Yis, we can
introduce Zis such that Yi = g(Zi) if Zi > 0, Yi = 0 if Zi ≤0, with g(·) a link function from R1 to
R+ or perhaps to (0, 1]. Then, we could model the Zi’s using say a usual Gaussian linear regression.
Another setting for latent variables is change point problems [16]. Frequently, we observe a
process over the course of time during which we would like to assess whether some sort of change
in regime has occurred. Practically speaking, this requires the notion of a ‘least’ significant change.
That is, we may be able to identify even a very small change with enough data but we will find
challenging the case where the support for the change has ‘no change’ as a boundary point.
In the change point setting two sampling scenarios can be envisioned. In the first, we have a full
set of data. Then we look, retrospectively, to try to find if change(s) occurred. In the second, we
look at the data sequentially and we try to identify change(s) as the data collection proceeds. We
illustrate with a simple version of the first scenario. Let f1(y|θ1) be the density for i.i.d. observations
beforethechangepoint,f2(y|θ2)thedensityafterthechangepoint.WithdataYi, i = 1, 2, . . . , n,let
K be the change point indicator, i.e. K ∈{1, 2, . . . , n} where K = k means change at observation,
k + 1; k = n means ‘no change’. Then, the model is
L(θ1, θ2, k; y) = 	k
i=1f1(yi|θ1)	n
i=k+1f2(yi|θ2)
Again, we have a hierarchical model, [y|k, θ1, θ2][K = k][θ1, θ2]. (Note that we do not include any
parameters in the prior for K; with only one change point, we could not hope to learn about such
parameters.) With a prior on θ1, θ2, K, we have a full model specification. Again, a simple Gibbs
sampler emerges for model fitting: update θs given k, y (so, we know exactly which observations
are assigned to which density); update k given θs and y (this is just a discrete distribution, easily
sampled). Obvious generalizations would allow the ys to be dependent [51], to have order restric-
tions on θs [70], to imagine multiple change points [29]. Also, in this version, time is discretized to
the set of times when the measurements were collected. Extension to continuous time is available
using point process models [53].
Errorsinvariablesmodels[14,23]offeranotherlatentvariablessetting.Looselystated,theobjec-
tiveistolearnabouttherelationshipbetweensayY andX.Unfortunately,X isnotobserved.Rather,
we observe say W instead of X. In some cases, W will be a version of X, subject to measurement
error, i.e. W may be Xobs while X may be Xtrue. In other cases W may be a variable (variables) that
plays the role of a surrogate for X. In any event, if we envision a joint distribution for W and X, we
may condition in either direction. If we specify a model for W|X we refer to this as a measurement
error model [11, 44], imagining W to vary around the true or desired X; if we specify a model for
X|W we refer to this as a Berkson model [44, 57]. In fact, we can imagine further errors in variables
component—perhapsweobserveZ,asurrogateforY.Altogetherwehaveahierarchicalmodelwith
latent Xs, possibly Ys. In particular, for the measurement error case, we have
	i[Zi|Yi, γ ][Yi|Xi, β][Wi|Xi, δ][Xi|α]
while for the Berkson case we have
	i[Zi|Yi, γ ][Yi|Xi, β][Xi|Wi, δ]
Typically, we will also have some validation data to inform about the components of the speci-
fication. We might have some X, Y pairs or perhaps some X, W pairs. It is noteworthy that the
measurement error version requires a model (prior) for X while the Berkson model does not. In

38
A. E. Gelfand and S. Ghosh
manyapplicationstheformerwillbemorenatural.However,insomecontexts,model-fittingisonly
feasible with the latter [4]. In any event, what is most remarkable is that, within this hierarchical
framework, using a full Bayesian specification, we can learn about the relationship between Y and
X without ever observing X (and, possibly, without observing Y as well). This reveals the power
of hierarchical modelling but, evidently, what we can learn depends upon the form of what we
specify.
3.4 Mixture models
Mixturemodelshavenowbecomeastapleofmodernstochasticmodelling[46,67].Thishasarisen
on at least two accounts: (i) their flexibility to model unknown distributional shapes and (ii) their
intuition in representing a population in terms of groups/clusters that may exist but are unidenti-
fied. Mixture models come in several flavours—parametric or nonparametric, incorporating finite,
countable or uncountable mixing. In this regard, they are sometimes referred to as classification
problems or discriminant analysis, reflecting a goal of assigning an individual to a population or
assessing whether individuals belong to the same population.
The most rudimentary finite mixture version takes the form
Y ∼
L

l=1
plfl(Y|θl).
Often the fl are normal densities, whence we obtain a normal mixture. If we assume L is specified
and we observe Yi, i = 1, 2, . . . , n, then what is latent is a label for each Yi, i.e. an indicator of which
component of the mixture Yi was drawn from. These latent labels would be such that if Li = l, then
Yi ∼fl(Y|θl).Uponintroducingtheselabellingvariables,theresultinghierarchicalmodelbecomes
	i[Yi|Li, θ][	i[Li|{pl}][θ][{pl}].
Here,θ denotesthecollectionof θl.Onceagain,Gibbssamplingisroutinetoimplement.Wecreate
a loop that updates θ, {pl} given the Ls and the data. With observations assigned to components,
this becomes the equivalent of an analysis of variance problem to learn about the θl. To update the
Lis given θ, {pl} and the data, requires sampling from an L-valued discrete distribution where, for
a given i, the mass on the ls is determined by the relative likelihood for the observed Yi, as well as
the prior on the pls (often a uniform). Hence, we obtain individual assignment probabilities as well
as global assignment weights. Richer versions introduce covariates into the θls and, possibly, into
the pls [37, 60, 71]. Further challenge is added if L is unknown with a prior specification. Now, since
the dimension of the model changes with L we may attempt reversible jump MCMC [30] to learn
about L. An alternative might be to carry out model choice across a set of Ls.
It is evident that such mixture models are not identifiable, i.e. the subscripts can be permuted
and the same mixture distribution results. This has led to substantial discussion in the literature
[47,55]withregardtointroducingidentifiabilityconstraintsorthepossibilityoffittingtheMCMC,
allowing multi-modality in the posterior in the absence of identifiability. The former path seems to
be the most widely used, with order constraints on the means, imposed in some fashion, being the
most common choice for achieving identifiability.
Next, we recall that many familiar distributional models can be developed through continuous
mixing, i.e. closed forms are achieved by virtue of conjugacy between the mixand model and the
mixing distribution. Well-known examples include scale mixing of normals to obtain t-distribu-
tions, as well as Poisson–Gamma (equivalently negative binomial) and beta-binomial models. In

Hierarchical modelling
39
some modelling situations we may seek individual level mixing variables, whence we would intro-
duce such variables as latent quantities. Again, a hierarchical model arises. An illustration is in the
case of outlier detection through the use of suitable individual level gamma mixing of normals.
Here outliers are ‘detected’ through the magnitudes of their associated mixing variables, i.e. the
heavier the posterior tails, the more we are inclined to classify the observation as an outlier. See,
e.g. [62, 68, 69].
We conclude with a brief discussion of nonparametric mixture models, illustrating with the
Dirichlet process. That is, the foregoing finite models are all parametric in the sense that they
are finite-dimensional specifications. The continuous mixture models are as well since they are
characterized by the parameters of the mixing distribution as well as, perhaps, some parameters
in the mixand distribution (that are not mixed). The so-called nonparametric setting envisions the
mixing distribution to be unknown and drawn randomly from a family of mixing distributions. In
particular, the family of all possible mixing distributions with regard to a parameter in the mixand
would be a nonparametric specification, but it is not possible to assign a distribution over this
entire family. Rather, in practice, we adopt a distribution over a subfamily of these distributions;
the Dirichlet process (DP) is one example.
The literature on the use of DP priors has been growing, primarily because they are easy to
specify, attractive to interpret and ideally suited for model-fitting within an MCMC framework.
In particular, the stickbreaking representation of the DP [61] makes it most convenient for use. Let
θ∗
1 , θ∗
2 , . . . be i.i.d. random elements independently and identically distributed according to the law
G0. G0 can be a distribution over a general probability space, allowing the θ∗s to be random objects
suchasscalars,vectors,astochasticprocessofrandomvariablesorevenadistributionitself[58].Let
q1, q2, . . . be random variables independent of the θ∗s and i.i.d. among themselves with common
distribution Beta(1, α). If we set p1 = q1, p2 = q2 (1 −q1), . . ., pk = qk
	k−1
j=1 (1 −qj), . . ., the
random probability measure defined by
G(·) =
∞

k=1
pk δθ∗
k (·)
is distributed according to a DP. So, G, which is equivalent to {pk} and {θ∗
k }, is a random
distribution.
IfweletGbethemixingdistribution,with(mixand)kernelsayf(y; θ),thentheresultingmixture
model becomes f(y; G) =

f(y; θ)G(dθ) = 
k pkf(y; θ∗
k ), i.e. f(y; G) is a countable mixture
model. Again, with G random, so is f(y : G). With data say Yi, i = 1, 2, .., n, we immediately have
the hierarchical form
	i[Yi|θi]	i[θi|G][G|G0, α][G0|ηG][ηG][α].
Here G provides the latent structure, rather than assuming the θi ∼G0. Indeed, α is a precision
parameter, reflecting how much G varies around G0.
This mixture specification allows considerable technical development [49] as well as substantial
extension [65], which we skip here. Rather, we note a few important features. First, we see that G
is almost surely discrete, though the resulting f(y; G) is not. Second, possibly paradoxical, though
this is a countable mixture problem rather than finite, there are no identifiability issues. Third, this
model allows ties, i.e. both θi and θi′ can take the value θ∗
k . This suggests the introduction of labels,
asabove,toindicatewhichθ∗wasdrawnbyeachi.Italsoclarifiesthattherewillbeclusteringforthe
Yis. However, here the clustering is of a different type. There are no component models; the values
of the θ∗don’t really mean anything. They change with iteration and would not be saved, rather, we

40
A. E. Gelfand and S. Ghosh
can only report the proportion of iterations when say Yi and Yi′ are in the same cluster, but nothing
aboutacommondistributionforthem(clarifyingwhytherearenoidentifiabilityproblems).Finally,
much can be said about fitting such models using MCMC (see, e.g. [42, 43, 52, 66]).
3.5 Random effects
Returning to the random effects setting, let us first consider individual level longitudinal data with
interest in explanation through growth curves. A natural specification would model individual level
curves centred around a population level curve. We would need the population level curve to see
average behaviour of the process; we need individual level curves in order, for example, to prescribe
individual level treatment. With parameters at each level and a third stage of hyperparameters, we
again see a hierarchical form.
More precisely, if Yij is jth measurement for ith individual, let
Yij = g(Xij, Zi, βi) + ϵij
where ϵij ∼N(0, σ 2
i ). The form for g depends upon the application. It is often linear but need not
be. We set βi = β + ηi where the ηi have mean 0 (or perhaps replace β with a regression in the
Zi). Then the βi (or the ηi) are the random effects. They provide the individual curves with β
providing the global curve. Evidently, this specification falls under the heading of a CIHM as well.
Learning with regard to any individual curve will borrow strength from the information about the
other curves.
Customarily, random effects are modelled using normality. However, they need not be i.i.d. That
is, if say the scalar ωi is associated with individual i, we need not insist that the vector, ω, of ωis,
be distributed as say, ω ∼N(0, σ2I). We can replace σ 2I with (θ) where (θ) has structured
dependence. That is, with say n individuals, we could not learn about an arbitrary positive definite
n × n matrix , but we could learn about  defined as a function of only a few parameters.
Structureddependenceisattheheartoftimeseries,spatialandspatio-temporalmodellingandis
frequentlyspecifiedthroughaGaussianprocess(GP).Here,weillustrateinthespatialsetting,envi-
sioningdataintheformY(si), i = 1, 2, . . . , n,i.e.nobservationsatndifferentspatiallocationssi.We
usually think of the si as being in R2 but this is not necessary. We could imagine three-dimensional
locationsand,moregenerally,replacinggeographicspacewithsaycovariatespace.Thistakesusinto
the now very popular world of computer models [40, 41, 45, 50]. In any event, with a GP, we need
only specify finite-dimensional (e.g. n) joint distributions with the joint dependence determined
by a valid covariance function. Customarily, the covariance function assigns stronger association to
variables that are closer to each other in geographic space. A common example is the exponential,
cov(Y(s), Y(s′)) = σ 2exp(−φ||s −s′||). With n locations, (θ)ij = σ 2exp(−φ||si −sj||).
Now, we can specify the standard univariate spatial model, incorporating spatial random effects
[3]. Let
Y(s) = xT(s)β + w(s) + ϵ(s).
Here, the residual is partitioned into two pieces: one is spatial, w(s), i.e. the w(s) are spatial random
effects and one is non-spatial, ϵ(s), i.e. the ϵ(s) are usual i.i.d. errors. w(s) is from a Gaussian
process, introducing say the stationary covariance function σ 2ρ(s −s′; φ) . ϵ(s) adds pure error
with variance τ2.
Interpretations that can be attached to ϵ(s) include: (i) a pure error term; the model is not
perfectly spatial; τ2, and σ 2 are variance components; (ii) measurement error or replication
variability causing discontinuity in spatial surface Y(s) (assuming x(s) and w(s) are continuous);

Hierarchical modelling
41
(iii) microscale structure; there may be dependence at a scale smaller than the smallest inter-lo-
cation distance but in the absence of any data to learn about such dependence, independence is
assumed.
Again, suppose we have data Y(si), i = 1, . . . , n, and let Y = (Y(s1), . . . , Y(sn))T. The above
model yields a marginal covariance matrix for Y of the form
 = σ 2R(φ) + τ2I.
with Rij = ρ(si −sj; φ). The dependence incorporated into R(φ) enables us to learn about both
variancecomponents.Setting θ = (β, σ 2, τ2, φ)T,weseethatthisisnotahigh-dimensionalprob-
lem (perhaps half a dozen components in β, three or four in ).
The likelihood is given by
Y|θ ∼N(Xβ, σ 2R(φ) + τ2I)
Typically, independent priors are chosen for the parameters,
p(θ) = p(β)p(σ 2)p(τ2)p(φ)
Commoncandidatesaremultivariatenormalforβ,andinversegammaforσ 2 andτ2.Specification
of p(φ) depends upon the choice of the correlation function, ρ; a uniform or discrete prior is
usually selected. p(β) can be ‘flat’ (improper). Care must be taken with regard to the parameters
in . First, results from [6] show that, for instance, if the prior on β, σ 2, φ is of the form
π(φ)
(σ 2)a+1
with π(·) proper, then, an improper posterior results if a = 0. This returns us to the point made
in Section 3.2 regarding the problem with using IG(ϵ, ϵ) priors for σ 2. Again, the posterior will be
nearly improper. Again, it is safer to adopt an IG(a, b) with a ≥1. A further issue is that, without
the pure error variance, τ2, with say the exponential covariance function, we can not identify both
σ 2 and φ [74]. We can only identify the product. (This is true for the more general Matérn class
of covariance functions, as well.) So an informative prior on at least one of these parameters will be
needed in order to achieve well-behaved MCMC model-fitting.
Of course, we may ask, “Where is the hierarchical modelling?” In fact, the foregoing is really a
hierarchical setup by considering a first stage likelihood conditional on the spatial random effects
w = (w(s1), . . . , w(sn)). That is, we have,
First stage: Y|θ, w ∼N(Xβ + w, τ 2I).
The Y(si) are conditionally independent given the w(si)s.
Second stage: w|σ 2, φ ∼N(0, σ 2R(φ))
Here, w provides the process model.
Third stage: priors on (β, τ 2, σ 2, φ)
With regard to model-fitting, we seek the marginal posterior p(θ|y), which is the same under
the marginal and hierarchical settings. That is, we can fit the model as f(y|θ)p(θ) or as
f(y|θ, w)p(w|θ)p(θ). Fitting the marginal model is usually computationally better behaved. We
have a lower-dimensional MCMC (no ws). Additionally, σ 2R(φ) + τ 2I will be diagonally domi-
nant, hence more stable than σ2R(φ) in terms of matrix inversion needed for sampling and likeli-
hood evaluation.

42
A. E. Gelfand and S. Ghosh
Of course, interest will be in the spatial random effects (and, in fact, in the entire spatial surface
of the ws) in order to see the pattern of spatial adjustment. We have not lost the ws with the
marginalized sampling. They are easily recovered, one-for-one with the posterior samples of θ, via
familiar composition sampling:
p(w|y) =

p(w|θ, y)p(θ|y)dθ
In practice, we might have a non-Gaussian first stage. For instance, Y(s) need not be a continuous
variable. We can imagine a binary or two-colour map, i.e. at every s there is a light bulb and a
realization of the map is a surface of 1s and 0s according to whether or not the bulb is illuminated at
s. Specific examples include: presence/absence of a species at a location; abundance of a species at
a location; was precipitation or deposition at a location measurable or not; the number of insurance
claims by residents of a single family home at s; land use classification at a location (not ordinal).
To build models, we replace the Gaussian likelihood with an appropriate exponential fam-
ily member, resulting in spatial generalized linear models [18]. The hierarchical model above
recurs:
First stage: Y(si) are conditionally independent given β and w(si) with f(y(si)|β, w(si), γ ) an
appropriate non-Gaussian likelihood such that
g(E(Y(si))) = η(si) = xT(si)β + w(si),
where η is a canonical link function (such as a logit) and γ is a dispersion parameter.
Second stage: Model w(s) as a Gaussian process (GP), as above:
w ∼N(0, σ2H(φ))
Third stage: Priors and hyperpriors according to the model specification.
Two points are worth noting here. First, we lose conjugacy between the first and second stage. We
can not marginalize over the ws. We will have to generate them in the model-fitting; we will have
to work with the hierarchical model itself. Second, it is not sensible to add a pure error term in the
specification of g. We already have the equivalent of conditional independence due to the first stage
exponential family mechanism that replaced the Gaussian choice. In fact, were we to include such
ϵs in the model, poorly behaved MCMC will ensue.
In summary, if we introduce the spatial random effects in the transformed mean, then, with con-
tinuous covariates, this encourages the means of spatial variables at proximate locations to be close
to each other. In spite of the conditional independence, marginal spatial dependence is induced
between, say, Y(s) and Y(s′), but the observed Y(s) and Y(s′) need not be close to each other. In
fact, there is no smoothness in the Y(s) surface. In different terms, our second stage modelling is
attractive for spatial explanation of the process, here in terms of the mean. It is not our intention to
achieve smoothness in the observed surface.
3.6 Dynamic models
Dynamic models have now become a standard formulation for a wide variety of processes, includ-
ing financial and environmental applications. Alternative names for them in the literature include
Kalman filters, state space models and hidden Markov models [28, 48, 56]. They introduce a first

Hierarchical modelling
43
stage (or observational model) and then a second stage (or transition model), with third stage
hyperparameters. Again, the first stage provides the data model while the second stage provides a
latentdynamicprocessmodel.See,e.g.WestandHarrison[72]forafulldevelopment.Inparticular,
there is a substantial modellling opportunity at the second stage, allowing evolution of process
variables or process parameters, in either case, driven by covariate information.
The basic dynamic model takes the form,
Yt = g(Xt, θ1) + ϵt, the observation equation
with
Xt = h(Xt−1; θ2) + ηt, the transition equation
Evidently, time t is discrete and we are putting the dynamics in the mean. We illustrate with
dynamic space–time models. Consider:
Stage 1: Measurement equation
Y (s, t) = μ (s, t) + ϵ (s, t) ; ϵ (s, t) ind
∼N

0, σ2
ϵ

.
μ (s, t) = xT (s, t) ˜β (s, t) .
˜β (s, t) = βt + β (s, t)
with
Stage 2: Transition equation
βt = βt−1 + ηt, ηt
ind
∼Np

0, η

.
β (s, t) = β (s, t −1) + w (s, t)
where w(s, t) are independent (over t) innovations of a spatial process (see, e.g., [25]). As noted
above, this specification can be connected to a linear Kalman filter [36]. Thus, Bayesian model-
fitting using the forward filter, backward sample (ffbs) algorithm [15, 21] becomes the customary
approach.
Recently, Wikle and colleagues [31, 73] have adapted these dynamic forms to the fitting of mod-
els motivated by stochastic partial differential equations (SPDEs). The approach is to discretize
time, raising the issue of sensitivity to temporal resolution as well as the fact that the limiting
dependence structure from the discrete form need not be that associated with the SPDE. Nonethe-
less, the discretized specification stands as a model in its own right, worthy of fitting to enable
inference.
In particular, there are many interesting ecological diffusions which can be applied to study the
behaviour over time (and, perhaps space) of: (i) emerging diseases such as avian flu or H1N1 flu;
(ii) exotic organisms, e.g. invasive plants and animals; (iii) the evolution of the distribution of size
or age of a species; (iv) the dynamics explaining phenomena such as transformation of landscape,
deforestation, land use classifications and urban growth.
Our objective for such processes is to forecast likely spread in space and time with associated
uncertainty. We anticipate that the evolution will be nonlinear and nonhomogeneous in space and
time, driven by explanatory covariates. We start with deterministic integro-differential equations or

44
A. E. Gelfand and S. Ghosh
withpartialdifferentialequations,raisingthequestionofhowtoadduncertainty.Looselyspeaking,
we provide theoretical models, with the data ‘varying’ around them, creating hierarchical specifica-
tions with second stage dynamics that lead us to the foregoing state space models. As remarked
above, too much simplification would be required in order to obtain analytical solutions to the
differential equations. So instead, we adopt discretization to fit models. Again, the issue is whether
wecareaboutthedeterministicPDEorwhetherweshouldjustworkwiththediscretetimeversion,
incorporating the behavioural features we want.
Hooten and Wikle [31] use data from the Breeding Bird Survey (BBS) to study the diffusion of
the Eurasian collared dove. Gridding the eastern United States, let Zit be the count in box i in year
t, let nit be the number of visits to cell i in year t and let λit be the intensity for box i in year t. Then,
assume Zit ∼Po(nitλit) with logλit = wit + ϵit. Here, the ϵit are i.i.d. (pure error or microscale
variation). The focus is on the wt; they tell the diffusion story.
More precisely, the dynamics here are associated with continuous space and discrete time,
i.e. wt(s). Without loss of generality, we take t = (1, 2, . . . , T). We simplify wt(s) to be
first-order Markov, i.e. for locations s1, s2, . . . , sn, let wt = (wt(s1), wt(s2), . . . , wt(sn))T. Then,
[wt|w0, w1, . . . , wt−1] = [wt|wt−1]. For example, we could set wt = Hwt−1 + ηt where ηt(s)
incorporates spatial structure. We have a vector AR(1) model and H is called the propagator
matrix.
How might we specify H? The choice H = I is not stationary. It leads to explosive behaviour
with no interaction across space and time. Hence, it is not realistic for most dynamic processes of
interest. The choice, H = Diag(h) where Diag(h) has diagonal elements 0 < hi < 1 avoids explo-
sive behaviour but still offers no interactions. In fact, what we seek is integro-difference equation
(IDE) dynamics over the space of locations:
wt(s) =

h(s, r; φ)wt−1(r)dr + ηt(s).
Here,hisa‘redistributionkernel’thatdeterminestherateofdiffusionandtheadvection.Ifrequired
w > 0, then we could work with
logwt(s) = log(

h(s, r; φ)wt−1(r)dr) + ηt(s).
Alternatively, we could adopt
vt(s) =

h(s, r; φ)vt−1(r)dr
and
logwt(s) = logvt(s) + ηt(s).
Various forms can be considered for h, e.g. h(s, r; φ), h(s, r; φ(r)), ht(s, r; φ). Then, discretization
of the spatial region will enable us to obtain H.
Lastly, we can reconnect to the PDE. In fact, recall the linear PDE, dw(s,t)
dt
= h(s)w(s, t). Finite
differencing yields w(s, t + t) −w(s, t) = h(s)w(s, t)t, i.e. w(s, t + 1) ≈˜h(s)w(s, t), suffering
the same limitations as above. Hence, we need more general PDEs, in particular those that diffuse
in space over time. Such PDEs can motivate IDEs, and therefore clarify H.

Hierarchical modelling
45
3.7 Data fusion
Asalastexample,wetakeupamodellingproblemindatafusion.Dataassimilationhassomehistory
in the meteorology community [34] but has only recently received serious attention in the statistics
community. In particular, let us consider the Bayesian melding model of Fuentes and Raftery [22]
which has gained considerable attention and has already been used in several applications [20, 63].
We present the model in the spatial setting, where we would be concerned with fusing a dataset
consistingofmeasurementsatmonitoringstations,sayexposuretoozoneorparticulatematter,with
the output of a computer model for that exposure. The former is quite accurate but only sparsely
available, often with missingness. The latter is uncalibrated but is available everywhere. The former
is associated with point-referenced locations, the latter is supplied for grid cells, for example 12 km
squares.
The melding or fusion model envisions a latent true exposure surface which is informed by both
the station data and the computer model data. The hierarchical model arises with the two data
sources providing the first-stage model. The latent true model provides a process specification at
the second stage, with hyperparameters at the third stage, as is familiar by now. More precisely, let
the Y(si) be the observed station data at si, let X(Bj) be the computer model output for grid cell
Bj and let Z(s) be the true exposure surface. We model the station data as a measurement error
model, i.e.
Y(si) = Z(si) + ϵ(si)
where the ϵ are a pure error specification. We model the computer output as a calibration specifi-
cation, i.e. for grid cell Bj,
X(Bj) =

Bj
(a(s) + b(s)Z(s) + δ(s))ds
where a(s) and b(s) are Gaussian processes with the δ(s)s being pure error. Here, the challenge for
the melding approach emerges. The integral for X(Bj) is stochastic because, for example, a(s) is not
a function but a realization of a stochastic process. So, the integral can not be computed explicitly;
at best we can implement a Monte Carlo integration [3]. If we have to do many of these (and, in a
practical situation we would have many grid cells), we would have an enormous number of Monte
Carlo integrations to do at each iteration of an MCMC fitting algorithm.
Finally, we have the second-stage process model, say,
Z(s) = μ(s) + η(s)
Here, the mean, μ(s), captures the large-scale structure, perhaps through covariates, perhaps
through a trend surface, while η(s) capture the small-scale structure or second-order dependence
through a GP. Again, model-fitting is challenging; Fuentes and Raftery [22] observe that they were
only able to successfully fit the model in the case that b(s) = b.
So, again, Bayesian melding has two important limitations. First, it is computationally intensive.
Since computer model outputs usually cover large spatial domains, thereby introducing a very large
number of grid cells, a very large number of stochastic integrals need to be computed. Secondly, as
proposed, it does not incorporate a temporal dimension. Given the computational burden associ-
ated with Bayesian melding in its static version, a dynamic extension is, practically, infeasible. Fully

46
A. E. Gelfand and S. Ghosh
model-based alternatives, so-called downscalers [9, 10], can address these limitations by using only
a first-stage model for the relatively sparse station data.
3.8 Summary
We have argued that hierarchical models provide the stochastic framework within which to develop
integrative process models. We have shown, with many examples, that these models typically share
a common structure. There is a first-stage data model, there is a second-stage process model that is
latent, i.e. it is endowed with a full model specification but it is unobserved, and a third stage which
incorporates prior specifications for all of the remaining parameters in the model. We have noted
that, in order to get the uncertainty right, these models should be fitted within the Bayesian frame-
work. We have also noted that fitting of these models introduces familiar Gibbs looping. Hence,
it is straightforward to envision how the MCMC model-fitting should be implemented. However,
according to the size of the dataset and the complexity of the specifications, such model-fitting can
be very challenging, perhaps infeasible. Indeed, this limitation will become more of a constraint
as we continue to seek models which stretch the limits of our computing capabilities. Hence, we
imagine a computing future built around simulation based model-fitting of these hierarchical forms
but incorporating suitable approximation. Thus, the ‘art’ will encompass both specification (with
comparison) and approximate fitting (to enable inference and comparison).
References
[1] Agresti, A. (2010). Analysis of Ordinal Categorical Data (2nd edn). Wiley, New York.
[2] Albert, J. H. and Chib, S. (1993). Bayesian analysis of binary and polychotomous response
data. Journal of the American Statistical Association, 88, 669–679.
[3] Banerjee, S., Carlin, B. P. and Gelfand, A. E. (2004). Hierarchical Modelling and Analysis for
Spatial Data. Chapman & Hall/CRC, Boca Raton.
[4] Barber, J. J., Gelfand, A. E. and Silander, J. A. (2006). Modelling map positional error to infer
true feature location. Canadian Journal of Statistics, 34, 659–676.
[5] Berger, J. O. and Strawderman, W. E. (1996). Choice of hierarchical priors: admissibility in
estimation of normal means. Annals of Statistics, 24, 931–951.
[6] Berger, J. O., De Oliveira, V. and Sans´o, B. (2001). Objective Bayesian analysis of spatially
correlated data. Journal of the American Statistical Association, 96, 1361–1374.
[7] Berger, J. O., Strawderman, W. E. and Tang, D. (2005). Posterior propriety and admissibility
of hyperpriors in normal hierarchical models. Annals of Statistics, 33, 606–646.
[8] Berliner, L. M. (1996). Hierarchical Bayesian time series models. In Maximum Entropy
and Bayesian Methods (K. Hanson and R. Silver, eds.). Kluwer Academic Publishers,
15–22.
[9] Berrocal, V. J., Gelfand, A. E. and Holland, D. M. (2010). A spatio-temporal downscaler for
output from numerical models. Journal of Agricultural, Biological and Environmental Statistics,
15, 176–197.
[10] Berrocal, V. J., Gelfand, A. E. and Holland, D. M. (2010). A bivariate space-time downscaler
under space and time misalignment, Annals of Applied Statistics, 4, 1942–1975.
[11] Berry, S. M., Carroll, R. J. and Ruppert, D. (2002). Bayesian smoothing and regression
splines for measurement error problems. Journal of the American Statistical Association, 97,
160–169.
[12] Box, G. E. P. and Tiao, G. C. (1973). Bayesian Inference in Statistical Analysis. Addison-Wesley,
Mass.

Hierarchical modelling
47
[13] Bradlow, E. T. and Zaslavsky, A. M. (1999). Hierarchical latent variable model for ordinal
data from a customer satisfaction survey with “No Answer” responses.Journal of the American
Statistical Association, 94, 43–52.
[14] Carroll, R. J., Ruppert, D. and Stefanski, L. A. (1995). Measurement Error in Nonlinear Models.
Chapman & Hall, Boca Raton, Fl.
[15] Carter, C. K. and Kohn, R. (1994). On Gibbs sampling for state space models. Biometrika, 81,
541–553.
[16] Chib, S. (1998). Estimation and comparison of multiple change-point models. Journal of
Econometrics, 86, 221–241.
[17] Dempster, A. P., Laird, N. M. and Rubin, D. B. (1977). Maximum likelihood from incomplete
data via the EM algorithm. Journal of the Royal Statistical Society, Series B, 39, 1–38.
[18] Diggle, P. J., Moyeed, R. A. and Tawn, J. A. (1998). Model-based geostatistics (with discus-
sion). Applied Statistics, 47, 299–350.
[19] Fienberg, S. E. (2011). Bayesian models and methods in public policy and government set-
tings. Statistical Science, 26, 212–226.
[20] Foley, K. M. and Fuentes, M. (2008). A statistical framework to combine multivariate spatial
data and physical models for hurricane wind prediction. Journal of Agricultural, Biological and
Environmental Statistics, 13, 37–59.
[21] Frühwirth-Schnatter, S. (1994). Data augmentation and dynamic linear models. Journal of
Time Series Analysis, 15, 183–202.
[22] Fuentes, M. and Raftery, A.E. (2005). Model evaluation and spatial interpolation by Bayesian
combination of observations with outputs from numerical models. Biometrics, 61, 36–45.
[23] Fuller, W. A. (1987). Measurement Error Models. Wiley, New York.
[24] Gelfand,A.E.andSmith,A.F.M.(1990).Sampling-basedapproachestocalculatingmarginal
densities. Journal of the American Statistical Association, 85, 398–409.
[25] Gelfand, A. E., Diggle, P. J., Fuentes, M. and Guttorp, P. (Eds.) (2010). Handbook of Spatial
Statistics. CRC Press/Chapman & Hall, Boca Raton.
[26] Gelman, A., Carlin, J. B., Stern, H. S. and Rubin, D. B. (2004). Bayesian Data Analysis (2nd
edn). Chapman & Hall/CRC, Boca Raton, FL.
[27] Gilks, W. R. and Wild, P. (1992). Adaptive rejection sampling for Gibbs sampling. Applied
Statistics, 41, 337–348.
[28] Girón, F. J. and Rojano, J. C. (1994). Bayesian Kalman filtering with elliptically contoured
errors. Biometrika, 80, 390–395.
[29] Gir´on, F. J., Moreno, E. and Casella, G. (2007). Objective Bayesian analysis of multiple
changepoints for linear models (with discussion). In Bayesian Statistics 8 (J. M. Bernardo,
M.J.Bayarri,J.O.Berger,D.Heckerman,A.F.M.SmithandM.West,eds.).OxfordUniversity
Press, London, 227–252.
[30] Green, P. (1995). Reversible jump Markov chain Monte Carlo computation and Bayesian
model determination. Biometrika, 82, 711–732.
[31] Hooten, M. V. and Wikle, C. K. (2008). A hierarchical Bayesian non-linear spatio-temporal
model for the spread of invasive species with application to the Eurasian Collared-Dove.
Environmental and Ecological Statistics, 15, 59–70.
[32] Ibrahim, J. G. and Laud, P. W. (1991). On Bayesian analysis of generalized linear models using
Jeffreys’s prior. Journal of American Stististical Association, 86, 981–986.
[33] Johnson, V. E. and Albert, J. H. (1999). Ordinal Data Modelling. Springer, New York.
[34] Kalnay, E. (2003). Atmospheric Modelling, Data Assimilation and Predictability. Cambridge
University Press.
[35] Kass, R. E. and Steffey, D. (1989). Approximate Bayesian inference in conditionally inde-
pendent hierarchical models (parametric empirical Bayes models). Journal of the American
Statistical Association, 84, 717–726.

48
A. E. Gelfand and S. Ghosh
[36] Kent, J. T. and Mardia, K. V. (2002). Modelling strategies for spatial-temporal data. In Spatial
Cluster Modelling (A. Lawson and D. Denison, eds.). Chapman & Hall, London, 214–226.
[37] Li, F., Villani, M. and Kohn, R. (2011). Modeling conditional densities using finite smooth
mixtures. In Mixtures: Estimation and Applications (K. L. Mengersen, C. P. Robert and D. M.
Titterington, eds.). John Wiley, Chichester, 123–144.
[38] Little, R. J. A. and Rubin, D. B. (1987). Statistical Analysis with Missing Data. John Wiley &
Sons, New York.
[39] Lunn, D. J., Thomas, A., Best, N. and Spiegelhalter, D. (2000). WinBUGS – A Bayesian mod-
elling framework: Concepts, structure, and extensibility. Statistics and Computing, 10, 325–337.
[40] Lynch, P. (2006). The Emergence of Numerical Weather Prediction: Richardson’s Dream.
Cambridge University Press, Cambridge.
[41] Lynch, P. (2008). The origins of computer weather prediction and climate modelling. Journal
of Computational Physics, 227, 3431–3444.
[42] MacEachern,S.andM¨uller,P.(2000).EfficientMCMCschemesforrobustmodelextensions
using encompassing Dirichlet process mixture models. In Robust Bayesian Analysis (D. Rios
Insua and F. Ruggeri, eds.). Springer-Verlag, New York, 295–315.
[43] MacEachern, S. N., Clyde, M. and Liu, J. S. (1999). Sequential importance sampling for
Nonparametric Bayes Models: The Next Generation. The Canadian Journal of Statistics, 27,
251–267.
[44] Mallick, B., Hoffman, F. O. and Carroll, R. J. (2002). Semiparametric regression modelling
with mixtures of Berkson and classical error, with application to fallout from the Nevada test
site. Biometrics, 58, 13–20.
[45] McGuffie, K. and Henderson-Sellers, A. (2005). A Climate Modelling Primer (3rd edn). John
Wiley, Chichester.
[46] McLachlan, G. J. and Peel, D. (2000). Finite Mixture Models. Wiley, New York.
[47] Mengersen,K.L.andRobert,C.P.(1996).Testingformixtures:aBayesianentropicapproach
(with discussion). In Bayesian Statistics 5 (J. O. Berger, J. M. Bernardo, A. P. Dawid, D. V.
Lindley and A. F. M. Smith, eds.). Oxford University Press, Oxford, 255–276.
[48] Minka, T. (2002). Bayesian inference in dynamic models: an overview. Technical report.
Carnegie Mellon University.
[49] Neal, R. (2000). Markov chain sampling methods for Dirichlet process mixture models.
Journal of Computational and Graphical Statistics, 9, 249–265.
[50] Oey, L.-Y., Ezer, T. and Lee, H.-C. (2005). Loop Current, rings and related circulation in the
Gulf of Mexico: A review of numerical models and future challenges. In Circulation in the
Gulf of Mexico: Observations and Models, Geophysical monograph series 161 (W. Sturges and
A. Lugo-Fernandez, eds.). AGU, Washington D.C., 31–56.
[51] Perreault, L., Parent, E., Bernier, J., Bob´oe, B. and Slivitzky, M. (2000). Retrospective
multivariate Bayesian change-point analysis: a simultaneous single change in the mean of
several hydrological sequences. Stochastic Environmental Research and Risk Assessment, 14,
243–261.
[52] Quintana, F. A. and Newton, M. A. (2000). Computational aspects of nonparametric
Bayesian analysis with applications to the modelling of multiple binary sequences. Journal
of Computational and Graphical Statistics, 9, 711–737.
[53] Raftery, A. E. (1994). Change point and change curve modelling in stochastic processes and
spatial statistics. Journal of Applied Statistical Science, 1, 403–424.
[54] Raudenbush, S. W. and Bryk, A. S. (2002). Hierarchical Linear Models (2nd edn). Sage, New-
bury Park, CA.
[55] Richardson, S. and Green, P. (1997). On Bayesian analysis of mixtures with an unknown
number of components. Journal of the Royal Statistical Society, Series B, 59, 731–792.

Hierarchical modelling
49
[56] Robert, C. P., Rydèn, T. and Titterington, D. M. (2000). Bayesian inference in hidden Markov
models through the reversible jump Markov chain Monte Carlo method. Journal of the Royal
Statistical Society, Series B, 62, 57–75.
[57] Rodrigues, J. and Bolfarine, H. (2007). Bayesian inference for an extended simple regression
measurement error model using skewed priors. Bayesian Analysis, 2, 349–364.
[58] Rodriguez,A.,Dunson,D.B.andGelfand,A.E.(2008).ThenestedDirichletprocess.Journal
of the American Statistical Association, 103, 1131–1154.
[59] Rue, H., Martino, S. and Chopin, N. (2009). Approximate Bayesian inference for latent Gaus-
sian models by using integrated nested Laplace approximation. Journal of the Royal Statistical
Society, Series B, 71, 1–35
[60] Scaccia, L. and Green, P. J. (2003). Bayesian growth curves using normal mixtures with non-
parametric weights. Journal of Computational and Graphical Statistics, 12, 308–331.
[61] Sethuraman, J. (1994). A constructive definition of Dirichlet priors. Statistica Sinica, 4,
639–650.
[62] Sharples, L. D. (1990). Identification and accommodation of outliers in general hierarchical
models. Biometrika, 77, 445–453.
[63] Smith, B. J. and Cowles, M. K. (2007). Correlating point-referenced radon and areal uranium
data arising from a common spatial process. Applied Statistics, 56, 313–526.
[64] Spiegelhalter, D. J., Thomas, A., Best, N. and Gilks, W. R. (1995). BUGS: Bayesian inference
using Gibbs sampling, Version 0.50. Technical report. Medical Research Council Biostatistics
Unit, Institute of Public Health, Cambridge University.
[65] Teh, Y. W., Jordan, M. I., Beal, M. J. and Blei, D. M. (2006). Hierarchical Dirichlet processes.
Journal of the American Statistical Association, 101, 1566–1581.
[66] Tierney, L., Kass, R. E. and Kadane, J. B. (1989). Fully exponential Laplace approximations
to expectations and variances of nonpositive functions. Journal of the American Statistical
Association, 84, 710–716.
[67] Titterington, D. M., Smith, A. F. M. and Makov, U. E. (1985). Statistical Analysis of Finite
Mixture Distributions. John Wiley, Chichester.
[68] Verdinelli, I. and Wasserman, L. (1991). Bayesian analysis of outlier problems using the Gibbs
sampler. Statistics and Computing, 1, 105–117.
[69] Wakefield, J. C., Smith, A. F. M., Racine-Poon, A. and Gelfand, A. E. (1994). Bayesian analysis
of linear and non-linear population models by using the Gibbs sampler. Applied Statistics, 43,
201–221.
[70] Wang, J. and Zivot, E. (2000). A time series model of multiple structural changes in level,
trend and variance. Journal of Business and Economic Statistics, 18, 374–386.
[71] Wang, P. M., Cockburn, I. M. and Puterman, M. L. (1998). Analysis of patent data–A
mixed-Poisson-regression-model approach. Journal of Business and Economic Statistics, 16,
27–41.
[72] West, M. and Harrison, J. (1997). Bayesian Forecasting and Dynamic Models (2nd edn).
Springer, New York.
[73] Wikle, C. K. (2003). Hierarchical Bayesian models for predicting the spread of ecological
processes. Ecology, 84, 1382–1394.
[74] Zhang, H. (2004). Inconsistent estimation and asymptotically equal interpolations in mod-
el-based geostatistics. Journal of the American Statistical Association, 99, 250–61.

4
Bayesian hierarchical
kernel machines for
nonlinear regression
and classification
sounak chakraborty, bani k. mallick
and malay ghosh
4.1 Introduction
“One machine can do the work of fifty ordinary men. No machine can do the work of one
extraordinary man.”
Elbert Hubbard
H
umans are capable of tackling extremely difficult problems without the benefit of an a priori
solution. We learn from experience, and can often transfer knowledge acquired to novel
instances or even whole new tasks. Are machines capable of similar problem-solving prowess?
Machinelearningisadirectdescendantofanolderdiscipline—statisticalmodel-fitting.Thegoalin
machinelearningistoextractusefulinformationfromacorpusofdata,bybuildinggoodprobabilis-
tic models. The particular twist behind machine learning, however, is to automate this process as
much as possible, often by using very flexible models characterized by large numbers of parameters,
andtoletthemachinetakecareoftherest.Clearly,machinelearningisdrivenbyrapidtechnological
progress in two areas: storage devices leading to large databases and datasets, and computing power
enabling the use of more complex models.
Bayesian machine learning uses probability to express all forms of uncertainty. Learning is per-
formed by simple application of the rules of probability. Results of Bayesian machine learning
are expressed in terms of a probability distribution over all unknown quantities or parameters of
the model. The probability distribution of a parameter quantifies the uncertainty of its value, and
expresses our degree of belief in the various possibilities. In contrast, the conventional frequentist
strategy takes the form of an estimator for unknown quantities or model parameters, with possibly
some optimality criterion in mind.
Current technological trends inexorably lead to data flood. More data are generated from bank-
ing, telecom and other business transactions. More data are generated from scientific experiments
in astronomy, chemistry, space exploration, biology, high-energy physics, etc. More data are created
ontheweb,especiallyintext,imageandothermultimediaformat.Forexample,Europe’sVeryLong

Bayesian hierarchical kernel machines
51
BaselineInterferometryproduces1Gigabit/secondofastronomicaldatainanobservationwindow.
Cell phone companies like AT&T handle so many calls per day that it is impossible to store all that
dataandanalysismustbedone‘onthefly’.DNAmicroarrayallowsmeasurementofgeneexpression
levels for thousands of genes simultaneously. It is extremely complex to understand the relationship
between these thousands of genes and a specific disease. To handle these massive dimensional
complex datasets kernel based machine learning techniques are some of the best available options.
Support vector machines (SVM) are machine learning approaches, originally developed by
Vapnik [27] and others who worked in this area. The SVMs are a system for efficiently training
linear learning machines in kernel induced feature space. This has gained popularity due to its
attractive, analytic and computational features, and promising empirical performance. The formu-
lation embodies the Structural Risk Minimization (SRM) principle which has been shown to be
superior to Empirical Risk Minimization (ERM), used by conventional neural networks. Wahba
[28, 29] showed that SVM methodology can be cast as a regularization problem in terms of a
reproducing kernel Hilbert space (RKHS) and hence SVMs and penalty methods, as used in the
statistical theory of nonparametric regression, have a strong interrelationship. We have a training
set {yi, xi}, i = 1, . . . , n, where yi is the response variable and xi is the vector of covariate of size
p corresponding to yi. Given the training data our goal is to find an appropriate function f(x) to
predict the responses y in the test set based on the covariates x. Sollich [21] showed that SVM can
beinterpretedasamaximumaposteriorsolutiontoinferenceproblemswithGaussianpriorsandan
appropriatelikelihoodfunctionbasedonaprobabilisticinterpretation.Intheclassificationcontext,
theyaremotivatedbythegeometricinterpretationofmaximizingthemarginofdiscrimination,and
are characterized by the use of a kernel function.
In recent years several authors have developed kernel machine models for regression and clas-
sification in the Bayesian framework. Law and Kwok [16] introduced a Bayesian formulation of
SVM for regression, but they did not carry out a full Bayesian analysis and used instead certain
approximations for the posterior. A similar remark applies to Sollich [23] who considered SVM in
the classification context. As an alternative to SVM, Tipping [25, 26] and Bishop and Tipping [3]
introduced relevance vector machines (RVMs). RVMs are suitable for both regression and classifi-
cation, and are amenable to probabilistic interpretation. However, these authors did not perform
a full Bayesian analysis. They obtained type II maximum likelihood (Good, [12]) estimates of
prior parameters, which do not provide predictive distribution of future observations. Chakraborty
et al. [6] developed full Bayesian SVM and RVM for single response and also multiple response
correlateddatasets.Forclassificationproblems,Mallicketal.[16]consideredaMarkovchainMonte
Carlo (MCMC) based full Bayesian analysis for a binary classification scheme based on the RKHS
theory, where the number of covariates was far greater than the sample size. Similarly, Chakraborty
et al. [5] has developed a RKHS based multi-class kernel machine model for high-dimensional data
and introduced a stochastic search variable selection scheme with it for variable selection.
The layout of this chapter is as follows: In Section 4.2, we describe the general regression and
classification problem under the regularization framework and discuss RKHS and its related prop-
erties. In Section 4.3, we give a detailed description of Bayesian kernel machine regression models
and the associated prior justification. In Section 4.4, we discuss the Bayesian kernel machine model
for binary classification problems. Application to several real life datasets are also discussed in
Section 4.3 and Section 4.4. Finally, some concluding remarks and future possibilities are discussed
in Section 4.5.
4.2 RKHS and its related representation properties
In a regression or a classification problem, we have a training set {yi, xi}, i = 1, . . . , n, where yi is
the response variable (continuous for regression and categorical for classification problems) and xi
is the vector of covariate of size p corresponding to yi. Given the training data our goal is to find an

52
S. Chakraborty, B. K. Mallick and M. Ghosh
appropriate function f(x) to predict the responses y in the test set based on the covariates x. This
can be viewed as a regularization problem of the form
min
f∈H
 n

i=1
L(yi, f(xi)) + λJ(f)

(4.1)
where L(y, f(x)) is a loss function, J( f ) is a penalty functional, λ > 0 is the smoothing parameter
and H is a space of functions on which J( f ) is defined. In this article, we consider H to be a repro-
ducing kernel Hilbert space (RKHS) with kernel K, and we denote it by HK. A formal definition
of RKHS in given in Aronszajn [1], Parzen [21], and Wahba [29].
When h ∈HK, f(x) = β0 + h(x) and J( f ) =∥h ∥2
HK , (4.1) becomes
min
f∈HK
 n

i=1
L(yi, f(xi)) + λ ∥h ∥2
HK

(4.2)
The estimate of h is obtained as a solution of (4.2). It can be shown that the solution is finite-
dimensional (Wahba, [28]) and leads to a representation of f (Kimeldorf and Wahba, [13]; Wahba
[29]) as
fλ(x) = β0 +
n

i=1
βiK(x, xi)
(4.3)
It is also a property of RKHS that
∥h ∥2
HK=
n

i,j=1
βiβjK(xi, xj)
(4.4)
Representation of f in the above form is of special interest to us, because in cases when the number
of covariates p is much larger than the number of data points, we effectively reduce the dimension
of covariates from p to n. To obtain the estimate of fλ we substitute (4.3) and (4.4) in (4.2) and
then minimize it with respect to β = (β0, . . . , βn) and the smoothing parameter λ. The other
parameters in kernel K may be chosen by generalized approximate cross validation (GACV).
Similarly, for multivariate regression when f(x) = (f1(x), . . . , fq(x)) is a q-tuple func-
tion we can have similar results based on RKHS as the univariate case. Here we consider
f(x) ∈	q
j=1({1} + HKj), the product space of q reproducing kernel Hilbert spaces HKj for j =
1, . . . , q. In other words, each component can be expressed as βj + hj(x) with hj ∈HKj. Unless
there is a compelling reason to believe that HKj should be different for j = 1, . . . , q, we will assume
that they are the same RKHS denoted by HK. All the results stated before hold in this framework
as well. Detailed description is provided in Chakraborty et al. [6].
Regarding the loss L(y, f(x)) as the negative of the log-likelihood, our problem is equivalent to
maximization of the penalized log-likelihood
−
n

i=1
L(yi, f(xi)) −λ ∥h ∥2
Hk
(4.5)
This duality between ‘loss’ and ‘likelihood’, particularly viewing the loss as the negative of the
log-likelihood, is referred to in the Bayesian literature as the ‘logarithmic scoring rule’ (Bernardo,

Bayesian hierarchical kernel machines
53
[2], p. 688). In Table 4.1, we summarize some popularly useful loss functions for kernel machine
models in regression and classification. List of notations used in Table 4.1:
Table 4.1 Loss functions used in kernel machine models.
Loss function name
Formula
Use
Square error loss
(y −f(x))2
RVM regression
Hinge loss
[1 −yf(x)]+
SVM binary classification
Multicategory hinge loss
L(y).[f(x) −y]+
Multiclass SVM classification
Vapnik’s ϵ-insensitive loss
|y −f(x)|ϵ
SVM regression
Multivariate ϵ-insensitive loss
∥y −f(x) ∥ϵ
Multiple response SVM regression
Multivariate quadratic loss
(y −f(x))T(y −f(x))
Multiple response RVM regression
• [a]+ = a if a > 0 and is 0 otherwise.
• f and f (multivariate) is the unknown regression function that connects the response and the covariates.
• L(y) is a J dimensional vector (for J class classification) with 0 in the jth component and 1 elsewhere when y
correspond to class j. The . denotes the Euclidean inner product.
• |y −f(x)|ϵ = 0 if |y −f(x)| ≤ϵ and |y −f(x)| −ϵ otherwise.
• In a response vector with q components, ∥y −f(x) ∥ϵ=
q
j=1
ρj|yj −f j|ϵ.
4.3 Bayesian kernel machine regression models
In this section we will discuss Bayesian kernel machine models for univariate regression problems
andsomereallifeapplications.Letusconsiderthatwehaveadataset D = {(yi, xi) : i = 1, . . . , n.},
where yi is the response variable (continuous) and xi is the p × 1 covariate vector. Let us also
assume that p ≫n implying that the number of covariates far exceeds the sample size, hence there
is an urgent need to reduce the dimension of the problem or the covariate space.
4.3.1 Hierarchical Bayes relevance vector machine
The Relevance Vector Machine (RVM) was first proposed by Tipping [25]. It is considered as a
probabilisticmodelwhosefunctionalformisequivalenttotheSVMwithaleastsquarelossfunction
(also known as LS-SVM). Here we formulate the RVM in a complete hierarchical Bayesian setup
based on the RKHS theory, as discussed in the previous section.
If we assume that f is generated from RKHS with the kernel function K(., .), using the represen-
tation theorem (4.3) we can express f as
f(xi) = β0 +
n

j=1
βjK(xi, xj|θ)
(4.6)
where K is a positive definite function of the covariates x involving some unknown parameter θ.
Hence,
yi = f(xi) + ηi = KT
i β + ηi
(4.7)

54
S. Chakraborty, B. K. Mallick and M. Ghosh
where
ηi
iid∼N(0, σ 2),
β = (β0, . . . , βn)T,
and
Ki = (1, K(xi, x1|θ), . . . , K(xi, xn|θ))T,
i = 1, . . . , n. We assign hierarchical priors to the unknown parameters β, θ and σ 2. A conjugate
prior for this model is as follows.
β|σ2 ∼Nn+1(0, σ 2D−1)
(4.8)
where D = diag(λ0, . . . , λn) is a (n + 1) × (n + 1) diagonal matrix and λ = (λ0, . . . , λn)T. λ0 is
fixed at a small value but other λs are kept unknown. We also assume that
σ2 ∼IG(γ1, γ2)
(4.9)
We further assume that
θ ∼U(aL, aU), λi
iid∼Gamma(c, d), i = 1, . . . , n
(4.10)
where U(aL, aU) is the uniform distribution over (aL, aU).
The matrix with (i, j)th element Kij = K(xi, xj|θ) is known as the kernel matrix. The usual
choices are (i) the Gaussian kernel K(xi, xj|θ) = exp{−∥xi−xj∥2
2θ
} and (ii) the polynomial kernel,
K(xi, xj|θ) = (xT
i xj + 1)θ. Both kernels contain a single parameter θ. The joint posterior distri-
bution is thus given by
π(β, λ, σ 2, θ|y) ∝
1
(2πσ 2)n/2 exp

−
n

i=1
(yi −KT
i β)2
2σ 2

(4.11)
×
1
(2π)(n+1)/2|σ 2D−1|1/2 exp(−1
2σ 2 βTDβ)
× exp(−γ2/σ2)(σ 2)−γ1−1 ×
n

i=1
exp(−dλi)λc−1
i
This distribution is complex, and implementation of the Bayesian procedure requires MCMC
sampling techniques, and in particular, the Gibbs sampling (Gelfand and Smith, [8]) and
Metropolis–Hastings (MH) algorithm (Metropolis et al., [19], Chib and Greenberg, [7]). The
Gibbs sampler generates posterior samples using the conditional densities which we describe
below.
Conditional distributions and posterior sampling of the parameters
The prior distributions in (4.8) and (4.9) are conjugate distributions for β and σ 2. The posterior
density conditional on θ, λ is Normal-Inverse-Gamma
p(β, σ 2|θ, λ) = Nn+1(β| ˜m, σ 2 ˜V)IG(σ 2| ˜γ1, ˜γ2)
(4.12)
where
˜m = (KT
0 K0 + D)−1(KT
0 y), ˜V = (KT
0 K0 + D)−1, ˜γ1 = γ1 + n/2,
and
˜γ2 = γ2 +
(yTy −˜mT ˜V ˜m). Here KT
0 = (K1, . . . , Kn).
The conditional distribution for λi given βi and σ 2 is given by
λi|βi, σ 2 ind
∼Gamma

c + 1
2, d + β2
i
2σ 2

, i = 1, . . . , n.
(4.13)

Bayesian hierarchical kernel machines
55
We use the conditional distributions for constructing a Gibbs sampler through the following steps:
Step 1. Update β and σ2 by sampling from their conditional distribution (4.12).
Step 2. Update λ by sampling from the conditional distribution (4.13) of λi in turn.
Step 3. Update of K is equivalent to the update of θ and we need a Metropolis–Hastings algo-
rithm to sample from the marginal distribution of θ. We put a uniform prior (4.10) on θ so
p(θ|y) ∝p(y|θ), the marginal likelihood of θ. Let θ∗denote the proposed change. Accept this
change with acceptance probability
α = min

1, p(y|θ∗)
p(y|θ)

(4.14)
The ratio of the marginal likelihoods in (4.14) is given by
p(y|θ∗)
p(y|θ) = | ˜V∗|1/2
| ˜V|1/2
 ˜γ2
˜γ ∗
2
 ˜γ1
(4.15)
Using the marginal posterior of θ rather the full conditional posteriors improves the mixing by a
large extent, also resulting in a much faster convergence of the chain. Stability of the chain is also
increased without compromising the mixing. This way of using the marginal distribution of θ, the
kernel parameter, for sampling, was also successfully used by Mallick et al. [18].
Intherelevancevectormachinediscussedabove,weeffectivelytrytominimizethesquarederror
loss function and use separate smoothing parameters λi for different βi. The smoothing parameters
determine the tradeoff between training accuracy and model complexity. We can also keep all
λis the same by fixing λi = λ, for all i = 1, . . . , n. This resulting approach will be referred to as
the Bayesian relevance vector machine (BRVM). The multiple smoothing parameter is also used
by Tipping [25]. By having multiple smoothing parameters over a single one we are effectively
controlling each of the regression coefficients separately, thereby introducing sparseness in the
model.
4.3.2 Hierarchical Bayes support vector machine
In this section, we show how SVM based on RKHS can be used in a complete Bayesian setup
using Vapnik’s ϵ-insensitive loss function. In the Bayesian SVM model proposed by Law and Kwok
[16] they did not carry out a full hierarchical Bayesian analysis and used instead type II maximum
likelihood to estimate the prior parameters.
The ϵ-insensitive loss function introduced by Vapnik [27] is as follows:
L(y, f(x)) = |y −f(x)|ϵ =
 0
if |y −f(x)| ≤ϵ
|y −f(x)| −ϵ otherwise
(4.16)
This loss function (Figure 4.1) ignores errors of size less than ϵ, but penalizes in a linear fashion
when the function deviates more than ϵ amount. This makes the fitting less sensitive to the out-
liers. It is interesting to note that, like other loss functions or error measures in robust regression
(Huber, [13]), Vapnik’s ϵ-insensitive loss function also has linear tails beyond ϵ. But in addition
it flattens the contributions of those cases with small residuals. To construct a hierarchical model
for regression using Vapnik’s loss function we introduce n latent variables z1, . . . , zn. Such that yis
are conditionally independent given zi. Introduction of the latent variables makes the calculations

56
S. Chakraborty, B. K. Mallick and M. Ghosh
−1
−4
−2
0
2
4
2
1
3
4
x
−4
−2
0
2
4
x
L(x)
0.00
0.05
0.10
0.15
0.20
f(x)
0
0.25
Figure 4.1 The figure on the left represents Vapnik’s ϵ-insensitive (ϵ = 1) loss function. The figure
on the right represents the corresponding likelihood.
particularly simple. The likelihood of yi conditional on zi, corresponding to Vapnik’s loss (4.16), as
suggested by Law and Kwok [16], is given by
p(yi|zi) ∝exp{−ρ|yi −zi|ϵ}, i = 1, . . . , n.
(4.17)
It can be shown that this pdf figure can be written as a mixture of a truncated Laplace distribution
and a uniform distribution as follows
p(yi|zi) =
ρ
2(1 + ϵρ)exp{−ρ|yi −zi|ϵ}
= p1(Truncated Laplace(zi, ρ)) + p2(Uniform(zi −ϵ, zi + ϵ))
(4.18)
where p1 =
1
1+ϵρ , p2 =
ϵρ
1+ϵρ . A Laplace(θ, ρ) distribution for a random variable U has pdf
proportional to exp(−ρ|u −θ|).
We connect zi with f(xi) by zi = f(xi) + ηi, where ηi are the residual random effects that
account for any unexplained source of variation not included in the model. We assume that f is
generated from RKHS. By representation (4.6) the zi are modelled as
zi = KT
i β + ηi
(4.19)
Where ηi
iid∼N(0, σ 2) and β and Ki are defined as in Section 4.3.1. We assign hierarchical priors to
the unknown parameters β, θ, ρ, σ 2, zi, λi as follows.
zi|β, σ2, θ, λ ind
∼N(KT
i β, σ 2)
(4.20)
β|σ 2, λ ∼N(0, σ 2D−1); D = diag(λ0, λ1, . . . , λn)
(4.21)
σ2 ∼IG(γ1, γ2)
(4.22)
θ ∼U(aL, aU), λi
iid∼Gamma(c, d), ρ ∼U(rL, rU)
(4.23)

Bayesian hierarchical kernel machines
57
Asymptotically, if ϵ goes to infinity, we get the uniform likelihood, but if it goes to 0 we get the usual
Laplace likelihood when ρ is fixed. So instead of keeping ϵ fixed, as in classical SVM we assigned
prior to ϵ. However we observed that the performance of SVM decayed rapidly for priors spreading
outside the range (0, 1). More detailed justifications are provided in Law and Kwok [16]. Hence we
have considered
ϵ ∼Beta(k1, k2)
(4.24)
ThisBayesianSVMmodelbearssomeanalogytotheclassicalSVMastheexponentoftheGaussian
priorforβ isequivalenttothequadraticpenaltyfunction,butwithmultiplesmoothingparameters.
The posterior is similar to the posterior for the RVM model, except now the Gaussian likelihood in
RVM is changed to Vapnik’s ϵ-insensitive loss based likelihood (4.17) as follows
π(β, λ, z, σ 2, θ, ρ, ϵ|y) ∝
ρn
2n(1 + ϵρ)n exp

−ρ
n

i=1
|yi −zi|ϵ

(4.25)
×
1
(2π)n/2(σ 2)n/2 exp

−1
2σ 2
n

i=1
(zi −KT
i β)2

×
1
(2π)(n+1)/2|σ 2D−1|1/2 exp

−1
2σ 2 βTDβ

× exp

−γ2
σ2

(σ 2)−γ1−1 ×
n

i=1
exp(−dλi)λc−1
i
× ϵk1−1(1 −ϵ)k2−1
As before, the implementation of Bayesian methods is done once again using MCMC. The condi-
tional posterior distribution of λi is exactly the same as in the RVM case given by (4.13) in Section
4.3.1. The conditional distribution for β and σ 2 is also similar to that in the previous section, except
that now y is replaced by the latent variable z in ˜m and ˜γ2 in (4.12).
The distribution of zi, conditional on y, Ki, β, θ, ρ, λ, ϵ, and z−i (z−i indicates the z vector with
theithelementremoved)doesnothaveanexplicitform.WethusresorttotheMetropolis–Hastings
(MH) algorithm with a proposal density T(z∗
i |zi) that generates moves from the current state zi to
a new state z∗
i . It is convenient to take the proposal distribution to be Gaussian with mean equal
to KT
i β and variance σ 2 (Chib and Greenberg, [7]). The proposed updates then accepted with
probabilities
δi = min

1, exp

−ρ|yi −z∗
i |ϵ

exp

−ρ|yi −zi|ϵ


(4.26)
The update of K or θ is done similarly as before using the MH algorithm. Instead of sampling from
the full marginal of θ we sample from p(θ|y, z, ρ, ϵ), the marginal posterior of θ integrating out λ,
β, σ 2. If θ∗denotes the proposed change from current θ, we accept this θ∗with probability
α = min

1, p(θ∗|z, y, ρ, ϵ)
p(θ|z, y, ρ, ϵ)

(4.27)
The ratios of the marginal posteriors are the same as in (4.15) except that y is now replaced by the
latent variable z in the expression.

58
S. Chakraborty, B. K. Mallick and M. Ghosh
The conditional distribution of ρ depending only on the latent variable z, ϵ and the data y is
given by
p(ρ|y, z, ϵ) ∝
ρn
(1 + ϵρ)n exp

−ρ
n

i=1
|yi −zi|ϵ

(4.28)
The conditional distribution of ϵ conditional on ρ, y and z is given by
p(ϵ|y, z, ρ) ∝
ρn
(1 + ϵρ)n exp

−ρϵ
n

i=1
I(|yi −zi| > ϵ)

× ϵk1−1(1 −ϵ)k2−1
(4.29)
We use the MH algorithm to generate ρ and ϵ respectively from (4.28) and (4.29) with the accep-
tance probabilities

1, p(ρ∗|y,z,ϵ)
p(ρ|y,z,ϵ)

and

1, p(ϵ∗|y,z,ρ)
p(ϵ|y,z,ρ)

.
Using the above conditional distributions, we can construct a Gibbs sampler by following the
same steps 1 to 3 as in RVM. The distributions of some of the conditionals are changed as we replace
y by the latent variable z. Three extra steps needed to generate the latent variables z, ρ and ϵ are
added as follows:
Step 4. We update each zi in turn conditional on the rest using the Metropolis step discussed
in (4.26).
Step 5. Update ρ using a Metropolis step involving (4.28).
Step 6. Update ϵ using a Metropolis step involving (4.29).
The resulting support vector machine discussed above is based on the likelihood corresponding to
Vapnik’s ϵ-insensitive loss function (4.16) with multiple smoothing parameters λi. This resulting
approach will be referred as the Bayesian support vector machine (BSVM). As in BRVM, here also
we can simplify our model by setting λi = λ for all components of β.
4.3.3 Applications
Our Bayesian RVM (BRVM) and Bayesian SVM (BSVM) are applied on two simulated datasets
and three real datasets. The three real datasets are (i) Blood sugar data (Spiegelman et al., [24]); (ii)
Gas data (Kalivas, [14]); (iii) Wheat data (Kalivas, [14]). All three real datasets are near infrared
spectroscopy data. In all datasets the number of covariates exceeds the number of available data
points in the training set. So they are all ideally large p small n scenarios. Each dataset is randomly
split into a training set and a test set for a hundred times. In the training set we keep two-thirds of
the available data and the rest of the data are kept in the test set. The ‘out of sample’ mean square
errors of prediction (MSEP) are calculated on the test set for each split. In each dataset we centre
and scale X and Y. In Table 4.2 and Table 4.3 we report the median out of sample MSEP and the
corresponding standard deviations. The lowest attained MSEP is marked in bold. For our BRVM
and BSVM models, we generate a MCMC sample of 10,000 with the first 2000 as burn in. To avoid
the issue of multimodality and MCMC being stuck at one local mode we use five independent
chains with different starting points. Final prediction is obtained after pooling samples from all
five chains. The convergence of the MCMC chains is checked by monitoring the trace plots of the
generated samples and calculating the Gelman–Rubin scale reduction factor (Gelman et al., [10],
p. 329).
Tomakeour models less sensitivetothechoiceof hyperparameters of thepriors,wehavechosen
near-diffuse but proper priors. Near-diffuse priors are proper priors but with large variance. Thus
we can guarantee the propriety of the posterior and at the same time near diffuseness introduces

Bayesian hierarchical kernel machines
59
some objectivity in our analysis objective. We have assigned a vague but proper prior to σ 2. For
λ we select the values of the hyperparameters so that the mean is kept very small around 0.001,
but the variance is large. This choice of hyperparameter produces a near diffuse proper prior for β
also. In all the examples in this paper we have used the polynomial kernel. For kernel parameter
θ we give a discrete uniform prior U{1, 2, . . . , C}. In order to examine sensitivity in the choice
of priors, we have considered several different combinations of near-diffuse but proper priors.
The prediction error remains almost the same with all such choices. Here we report the results
for two such choices (i) γ1 = 1, γ2 = 10, c = 10−8, d = 10−5, C = 5 and (ii) γ1 = 0.5, γ2 =
1, c = 10−9, d = 10−6, C = 10. In BSVM additional parameters ϵ and ρ are drawn from a large
support uniform prior. For ρ two choices of its hyperparameters are considered (i) rL = 0, rU =
100, and (ii) rL = 0, rU = 50. Choice of prior for ϵ is made such that the fitting is less sensitive to
outliers. The ϵ parameter controls the width of the ϵ-insensitive zone, used to fit the training data.
The value of ϵ can affect the number of support vectors used to construct the regression function.
The bigger ϵ, the fewer support vectors are selected. On the other hand, bigger ϵ-values results in
more‘flat’estimates.Wehavedoneasimplecross-validationforfindingouttherangeofϵ wherethe
SVM regression gives best results, and found out empirically that it works best in the range (0, 0.5).
Hence we have assigned a Beta(k1, k2) distribution to ϵ . We have tried several combinations
of (k1, k2) and the results are fairly similar. Here we report our results using (i) k1 = k2 = 1,
i.e. we put a uniform U(0, 1) prior on ϵ, and (ii) k1 = 1, k2 = 5. Law and Kwok [16] proposed
a data dependent prior on ϵ, but sampling from the posterior under their prior becomes much
more complicated. It may be noted that a better prediction accuracy can be attained by choosing
a tight prior properly centred. However if this does not hold, the prediction will be highly inac-
curate. The near-diffuse priors offer protection against this, and introduce some objectivity in our
procedure.
We compare the performance of our procedures with some of the classical procedures which
are specially equipped to handle high-dimensional regression cases. They are, partial least squares
(PLS), principal component regression (PCR), as well as classical support vector machine
(CSVM), and random forest (RF) (Breiman, [4]). The tuning parameters for all standard models
are selected by five-fold cross-validation. We used the mvr() function in R to fit the PLS and PCR
models. The CSVM model is fitted using the svm() function in R. For the CSVM models we used
both the polynomial kernel (CSVM-P) and the radial basis function kernel (CSVM-R). The RF is
fitted using the randomForest() function and 500 boosted trees.
Simulation study
Simulation1:Wesimulateavectorofcovariatesx oflengthp = 1000fromaGaussianprocess(xi ∈
(−5, 5)) with covariance function k(xr, xs) = exp
 −|xr−xs|2
2d

and d = 1.5. We jitter around the
realization from GP by adding normal noise and obtain 150 samples. Thus our feature matrix is
X150×1000. We generate β1000×1 from an Uniform[0, 1]p. The response Y is obtained by plugging
in X and β in the equation Y = Xβ + N(0, 1).
Simulation 2: Same as Simulation 1 except d = 1.
Both simulations mimic a typical high-dimensional regression problem where p ≫n. The
results from simulation studies are tabulated in Table 4.2. In both simulation studies our BSVM
model attains the lowest MSEP. In Simulation 1 the BSVM model has 7.83%, 7.16%, 2.32%, 4.23%,
3.86%, 8.47% and 10.91% lower MSEP than PLS, PCR, CSVM-P, CSVM-R and RF respectively. The
BRVM model, though, has marginally higher MSEP than BSVM but it still improves considerably
on the other standard methods. Similar results are also obtained for Simulation 2. Results under
two different prior settings are very close to each other, suggesting our model is not very sensitive
to prior choices.

60
S. Chakraborty, B. K. Mallick and M. Ghosh
Table 4.2 Simulationstudy.TherangeofcalculatedGRdiagnosticsarereportedinparenthesisinthefirst
column. Results for CSVM-P are reported for degrees 1, 2, and 3 respectively. BRVM and BSVM results are
reported under prior choice (i) and (ii).
Median MSEP
SD
Simulation 1
PLS
0.9635
0.1629
PCR
0.9575
0.1843
CSVM-P
0.91425, 0.9313, 0.9280
0.1714, 0.1736, 0.1809
CSVM-R
0.9692
0.1898
RF
0.9910
0.1875
BRVM (0.98,1.05)
0.9041, 0.9039
0.1794, 0.1769
BSVM (0.99,1.11)
0.8935, 0.8897
0.1483, 0.1521
Simulation 2
PLS
0.9727
0.1662
PCR
0.9989
0.1663
CSVM-P
0.9685, 0.9593, 0.96974
0.1641, 0.1645, 0.1642
CSVM-R
0.9797
0.1620
RF
0.9853
0.1665
BRVM (0.96,1.06)
0.9661, 0.9670
0.1458, 0.1470
BSVM (0.95,1.10)
0.9460, 0.94398
0.1524, 0.1546
Blood sugar data
Research in fluorescence based optics suggests that a less invasive measurement technique may be
able to continuously monitor glucose levels in the body of diabetics. The data presented here are
discussed in Spiegelman, Wikander, O’Neal and Coté [22]. Optical spectra are collected from an
experiment measuring photon counts for 101 wavelengths in the range 509–625 nm and n = 27.
Ourresponseistheglucoseconcentration,andthecovariatesarethedifferentphotoncountscorre-
sponding to the p = 101 wavelengths. The target is to predict accurately the glucose concentration
in the body of the diabetics in the test set on the basis of the available photon counts.
In Table 4.3 we report a comparative performance of various methods along with our BRVM
and BSVM for prediction of blood glucose concentration on the basis of median MSEP. It is clear
that our RKHS based Bayesian RVM and SVM perform much better than all other methods such
as PLS, PCR which are often used by the chemometricians. Also Bayesian RVM and SVM leads
to a better prediction than classical SVM. Introduction of multiple smoothing parameters also

Bayesian hierarchical kernel machines
61
Table 4.3 Real Data Analysis. The range of calculated GR diagnostics are reported in parenthesis in the
first column. Results for CSVM-P are reported for degrees 1, 2 and 3 respectively. BRVM and BSVM results
are reported under prior choice (i) and (ii).
Median MSEP
SD
Blood sugar data
PLS
0.5737
0.6602
PCR
0.5628
0.5419
CSVM-P
0.5848, 0.4465, 0.34122
2.6381, 6.1941, 4.1501
CSVM-R
0.3915
1.5244
RF
0.4820
0.2599
BRVM (0.94,1.02)
0.3124, 0.3148
0.7619, 0.7429
BSVM (0.97,1.08)
0.4507, 0.4500
1.7123, 1.7708
Gas data
PLS
0.2300
0.0763
PCR
0.2294
0.0602
CSVM-P
0.0771, 0.0863, 0.0990
0.0229, 0.0328, 0.0651
CSVM-R
0.3756
0.2812
RF
0.35620
0.2645
BRVM (0.95,1.02)
0.04971, 0.0488
0.0146, 0.0144
BSVM (0.98,1.16)
0.0509, 0.0506
0.0179, 0.0177
Wheat data
PLS
0.5130
0.1177
PCR
0.3912
0.0809
CSVM-P
0.6407, 0.5992, 0.5303
0.1835, 0.1891, 0.1678
CSVM-R
0.8121
0.2444
RF
0.7091
0.2182
BRVM (0.98,1.03)
0.3148, 0.3177
0.1669, 0.1650
BSVM (0.93,1.13)
0.3096, 0.3090
0.2202, 0.2230

62
S. Chakraborty, B. K. Mallick and M. Ghosh
0.6
0.8
1.0
0.4
(a)
BRVM
BSVM
BRVM
BSVM
0.00
0.10
0.20
0.00
0.05
0.10
0.15
(b)
(c)
0.0
0
1
2
3
4
0.2
0.6
0.8
1.0
0.4
0.0
0.2
20
25
15
5
0
10
Figure 4.2 Blood sugar concentration dataset. (a) Distribution of MSEP under BRVM and BSVM.
(b) Posterior distribution of the kernel parameter θ under BRVM and BSVM models. (c) Posterior
distribution of ρ.
introduces sparsity in our model, as the βis are then controlled individually. A number of these
will then be shrunk to zero introducing the sparsity. Mallick et al. [18] have also provided a nice
comparison of the benefits of a multiple smoothing parameter over a single smoothing parame-
ter in a Bayesian SVM classification model. Introducing sparsity in this way also draws similarity
with the Automatic Relevance Determination (ARD) models of Neal [20] and MacKay [17]. In
terms of performance, BRVM with multiple smoothing parameters has made an improvement of
10% to 80% in prediction accuracy over all standard methods. Apart from the improvement in
prediction accuracy, it enhances the flexibility of the model as well. In particular Bayesian BRVM
with multiple smoothing parameters has the least average MSEP. Our model is not very sensi-
tive to the choice of hyperparameters, as for both the choices we have nearly the same average
MSEP. This is true as long as we stick to the class of near-diffuse but proper priors. In Figure
4.2 we plot the posterior distributions of MSEP, θ and ρ. The posterior plots of estimated kernel
parameter θ indicate that nonlinear kernels of order 2 or 3 are required to attain the best prediction
rate.
Gas data
This dataset is obtained from Kalivas [14]. In the dataset we have NIR spectra of 60 gasoline sam-
ples, measured in 2 nm intervals from 900 nm to 1700 nm as covariates. Our response is the octane
numberofeachofthe60gasolinesamples.Sohere p = 401andn = 60.FromTable4.3 weseethat
ourBRVMandBSVMresultsinatleastafive-folddecreaseonMSEPoverPLS,PCR,CSVM-Rand
RF. In this dataset BRVM is marginally better than BSVM. The CSVM-P is the main competitor in
this data. Both BRVM and BSVM attain at least 50% lower MSEP. The prior sensitivity is also not
an issue as long as we contain ourselves in the class of near-diffuse priors.

Bayesian hierarchical kernel machines
63
Wheat data
In this dataset we focus on a calibration NIR spectra dataset of wheat from Kalivas 1997 to predict
the protein content. Here we have in total 100 (n) wheat samples. The NIR reflectance is measured
from 1100–2500 nm in 2 nm intervals. So we have p = 701 covariates. The NIR data are used to
predict protein content in the wheat samples. Measurements of protein were obtained by other
standard reference methods. The goal is to accurately predict the protein content based on the NIR
spectra data and to match it with the outcomes of the standard reference methods. In Table 4.3 we
include the MSEP using our BRVM and BSVM along with other standard techniques. Both BRVM
andBSVMreducestheMSEPoverPLS,CSVMandRFbymorethan50%.OurRKHSbasedkernel
regression model improves upon the popularly used PCR by more than 25%. In this dataset BSVM
comes out to be the overall winner.
In all simulation studies and real data analyses the calculated Gelman–Rubin scale reduction
factor is close to the desired value of one. This ensures that our MCMC has converged satisfactorily
and any inference drawn based on the MCMC will be appropriate.
4.4 Bayesian support vector machine model for binary data
For a binary classification problem, we have a training set {yi, xi}, i = 1, . . . , n, where yi is the
response variable indicating the class to which the ith observation belongs, and xi is the vector
of covariates of size p. The objective is to predict the posterior probability of belonging to one
of the classes given a set of new covariates, based on the training data. Usually the response is
coded as yi = 1 for class 1 and yi = 0 (or −1) for the other class. We utilize the training data y =
(y1, · · ·, yn)T andXT = (x1, · · ·, xn)tofitamodelp(y|x)andtouseittoobtainP(y∗= 1|y, x∗)for
afutureobservationy∗withcovariatex∗.Tosimplifythestructure,weintroducethelatentvariables
z = (z1, . . . , zn) and assume thatp(y|z) = 	n
i=1 p(yi|zi), i.e. the yi are conditionally independent
given the zi. In the next stage, the latent variables zi are modelled as zi = f(xi) + ϵi, i = 1, . . . , n,
where f ∈HK the reproducing kernel Hilbert space spanned by the kernel K(). The ϵi, is the
random residual effects, which are independent and identically distributed N(0, σ 2). Therefore,
we can construct a hierarchical model for classification as
p(yi|zi) ∝exp{−l(yi, zi)}, i = 1, . . . , n,
(4.30)
where the y1, y2, · · ·, yn are conditionally independent given z1, z2, · · ·, zn and l is any spe-
cific choice of the loss function, as explained in the previous section. We relate zi to f(xi) by
zi = f(xi) + ϵi, where the ϵi are residual random effects. It is shown by Wahba [29], that a
support vector machine can be fitted by finding β which minimizes the penalized loss func-
tion 1
2 ∥β ∥2 + Cn
i=1{1 −yif(xi)}+, where [a]+ = a if a > 0 and is 0 otherwise, C ≥0 is
a penalty term and f is the decision function.
In a Bayesian formulation, this optimization problem is equivalent to finding the posterior mode
of β, where the likelihood is given by exp[−n
i=1{1 −yif(xi)}+], while β has the N(0, CIn+1)
prior. However, in our formulation with latent variables z, we begin instead with the density
p(y|z) ∝exp

−
n

i=1
[1 −yizi]+

(4.31)
and assume independent N(f(xi), σ 2) priors for the zi.

64
S. Chakraborty, B. K. Mallick and M. Ghosh
If we use the density in (4.31), the normalizing constant may involve z. Following Sollich [23],
onemaybypassthisbyassumingadistributionfor zsuchthatthenormalizingconstantcancelsout.
If the normalized likelihood is
p(y|z) = exp

−
n

i=1
[1 −yizi]+

/c(z)
wherec(·)isthenormalizingconstant,thenchoosing p(z) ∝Q(z)c(z),thejointdistributionturns
out to be
p(y, z) ∝exp

−
n

i=1
[1 −yizi]+

Q(z)
(4.32)
as the c(·) cancels from the expression. We will take Q(z) as the product of independent normal
pdfs with means f(xi) and common variance σ 2. This method will be referred to as the Bayesian
support vector machine (BSVM) classification.
Moreover, as explained in Section 4.2, we can express f as
f(xi) = β0 +
n

j=1
βjK(xi, xj|θ)
(4.33)
where K is a positive definite function of the covariates (inputs) x and we allow some unknown
parameters θ to enrich the class of kernels.
The random latent variable zi is thus modelled as
zi = β0 +
n

j=1
βjK(xi, xj|θ) + ϵi = K′
iβ + ϵi,
(4.34)
where the ϵi are independent and identically distributed N(0, σ 2) variables, and K′
i =
(1, K(xi, x1|θ), . . . , K(xi, xn|θ)), i = 1, . . . , n.
To complete the hierarchical model, we need to assign priors to the unknown parameters β,
θ and σ2. We assign to β the Gaussian prior with mean 0 and variance σ 2D−1
∗, where D∗≡
Diag(λ1, λ, · · · , λ) is a (n + 1) × (n + 1) diagonal matrix, λ1 being fixed at a small value, but λ is
unknown. This amounts to a large variance for the intercept term. We will assign a proper uniform
prior to θ, an inverse Gamma prior to σ 2 and a Gamma prior to λ. A Gamma(α, ξ) distribution for
a random variable, say U, has probability density function proportional to exp(−ξu)uα−1, while
the reciprocal of U will then be said to have a IG(α, ξ) distribution. Our model is thus given by
p(yi|zi) ∝exp

−
n

i=1
[1 −yizi]+

zi|β, θ, σ 2 ind
∼N1(zi|K′
iβ, σ 2)
(4.35)
β, σ 2 ∼Nn+1(β|0, σ 2D−1
∗)IG(σ2|γ1, γ2)
(4.36)
θ ∼	p
q=1U(aq1, aq2)
(4.37)
λ ∼Gamma(m, c)
(4.38)
where U(aq1, aq2) is the uniform probability density function over (aq1, aq2).

Bayesian hierarchical kernel machines
65
We can extend this model using multiple smoothing parameters so that the prior for (β, σ 2) is
β, σ 2 ∼Nn+1(β|0, σ 2D−1)IG(σ 2|γ1, γ2),
(4.39)
where D is a diagonal matrix with diagonal elements λ1, . . . , λn+1. Once again, λ1 is fixed at a
small value, but all other λs are unknown. We assign independent Gamma(m, c) priors to them. Let
λ = (λ1, . . . , λn+1)′.
Conditional distributions and posterior sampling of the parameters
The prior distributions given in (4.36) are conjugate for β and σ2, whose posterior density condi-
tional on z, θ, λ is Normal-Inverse-Gamma,
p(β, σ 2|z, θ, λ) = Nn+1(β| ˜m, σ 2 ˜V)IG(σ 2| ˜γ1, ˜γ2),
(4.40)
where
˜m = (K0′K0 + D)−1(K0′z), ˜V = (K0′K0 + D)−1, ˜γ1 = γ1 + n/2, and
˜γ2 = γ2 +
1
2(z′z −˜m′ ˜V ˜m). Here K0′ = (K1, · · · , Kn), where we recall that Ki = [K(xi, x1), . . . ,
K(xi, xn)]′.
The conditional distribution for the precision parameter λi given the coefficient βi is Gamma
and is given by
p(λi|βi) = Gamma

m + 1
2, c +
1
2σ 2 βi2

, i = 2, . . . , n + 1
(4.41)
Finally, the full conditional density for zi is
p(zi|z−i, β, σ 2, θ, λ) ∝exp
⎡
⎣−l(yi, zi) −
1
2σ 2 {zi −
n

j=1
βjK(xi, xj)}2
⎤
⎦
Similarly, the full conditionals are found when λ2 = · · · = λn+1 = λ from (4.38).
WemakeuseoftheaboveconditionaldistributionsthroughaGibbssamplerthatiteratesthrough
the following steps: (i) update z; (ii) update K, β, σ 2; (iii) update λ.
For the update to z, we propose to update each zi in turn conditional on the rest. The conditional
distribution of zi does not have an explicit form; we thus resort to the Metropolis–Hastings proce-
dure with a proposal density T(z∗
i |zi) that generates moves from the current state zi to a new state
z∗
i . The proposed updates are then accepted with probabilities
α = min

1, p(yi|z∗
i )p(z∗
i |z−i, K)T(zi|z∗
i )
p(yi|zi)p(zi|z−i, K)T(z∗
i |zi)

(4.42)
We obtain p(yi|zi) from (4.31) and
p(zi|z−i, K) ∝exp{−(zi −Kiβ)2/(2σ 2)}
It is convenient to take the proposal distribution T(z∗
i |zi) to be a Gaussian with mean equal to the
old value zi and a prespecified standard deviation.
An update of K is equivalent to that of θ and the marginal distribution of θ conditional on z can
be written as
p(θ|z) ∝p(z|θ)p(θ)

66
S. Chakraborty, B. K. Mallick and M. Ghosh
The new proposal θ∗is then accepted with acceptance probability
α = min

1, p(z|θ∗)
p(z|θ)

(4.43)
The ratio of the marginal likelihoods is given by
p(z | θ∗)
p(z | θ) = | ˜V∗|1/2
| ˜V|1/2
 ˜γ2
˜γ ∗
2
 ˜γ1
(4.44)
where ˜V∗and ˜γ ∗
2 are similar to ˜V and ˜γ2 with θ∗replacing θ. Updating β, σ 2 and λ is straightfor-
ward as they are generated from standard distributions.
4.4.1 Examples
We illustrate the methodology with several examples. For all examples, five models were fitted:
(i) Bayesian support vector (BSVM) classification with a single penalty parameter; (ii) Bayesian
support vector (BSVM) classification with multiple penalty parameters. We have used the SVM
Matlab toolbox to obtain the classical SVM (SVM*) results. We obtained the RVM (Tipping, [25])
Matlab code from http://research.microsoft.com/mlp/RVM/relevance.htm. The neural network is
fitted using the nnet() function in R.
Throughout the examples, we selected γ1 and γ2 to give a tight inverse gamma prior for σ 2 with
mean 0.1. For λ we chose m and c so that the mean of the gamma distribution is small, say 10−3,
but with a large variance; aq1 and aq2, the prior parameters of θ are chosen using the x in such a
way that computation of the kernel function does not over- or underflow. We performed the data
analysis with both the Gaussian and polynomial kernels K as introduced in Section 4.3.1, and the
results showed very little difference. The results reported here are based on Gaussian kernels. In all
the examples we used a burn-in of 5000 samples, after which every 100th sample was retained in the
next50000samples.Theconvergenceandmixingofthechainwerecheckedusingtwoindependent
chains and the methods described in Gelman [9].
Benchmark comparisons
Weanalysedthreewell-knownbenchmarkdatasetsandpresenttheresultsinTable4.4.Thefirsttwo
datasets are Pima Indians diabetes and Leptograpsus crabs (Ripley, [22]). The third is Wisconsin
breast cancer data which contains ten basic features to classify two types of cancers, malignant and
benign. We split the data randomly into training/testing partitions of sizes 300 and 269, and report
average results over ten partitions. From Table 4.4, we see that all our multiple shrinkage models
perform nearly as well as the best available alternatives.
Leukemia data
The leukemia dataset was described in Golub et al. [11]. Bone marrow or peripheral blood samples
are taken from 72 patients with either myeloid leukemia (AML) or acute lymphoblastic leukemia
(ALL). Following the experimental setup of the original paper, the data are split into training and
test sets. The former consists of 38 samples, of which 27 are ALL and 11 are AML; the latter consists
of 34 samples, 20 ALL and 14 AML. The dataset contains expression levels for 7129 human genes
produced by Affymetrix high-density oligonucleotide microarrays.
We have provided our results in Table 4.5 with the modal or most frequent number of misclassi-
fication errors (the modal values) as well as the error bounds (maximum and minimum number of
misclassifications).

Bayesian hierarchical kernel machines
67
Table 4.4 Modal classification error rates and 95% credible intervals for benchmark datasets.
BSVM: Bayesian support vector machine; RVM: Relevance vector machine; SVM∗: Classical sup-
port vector machine.
Method
Ripley’s
Pima
Crabs
BSVM (single)
12.4(11.1,16.8)
21 (20,23.9)
4 (2,5)
BSVM (multiple)
8.8(8.4,11.6)
18.9 (18.3,20.6)
1 (0,4)
RVM
9.3
19.6
2
Neural Networks
N/A
22.5
3.0
SVM*
13.2
21.2
4
Table 4.5 Modal classification error rates and 95% credible intervals for Leukemia data. BSVM:
Bayesian support vector machine; RVM: Relevance vector machine; CSVM: Bayesian SVM as
proposed by Sollich [23]; SVM∗: Frequentist support vector machine.
Model
Modal misclassification error
Error bound
BSVM (single)
4
(3,7)
BSVM (multiple)
1
(0,3)
CSVM (single)
5
(3,8)
CSVM (multiple)
2
(1,6)
SVM*
4
RVM
2
Table 4.5 shows that the results produced by the multiple shrinkage models are superior to the
single precision models, as well as the classical SVM models. Although all the multiple shrinkage
models performed well, the best performer among these appears to be the Bayesian support vector
machine model.
The use of RKHS leads to a reduction in the dimension of the model, but the dimension can still
be as high as the sample size. In the Bayesian hierarchical modelling framework, due to shrinkage
priors, we obtain sparsity automatically (Tipping, [25]). Because of the presence of the unknown
parameter θ in the expression of K, this θ induces a posterior distribution for DF (rather than a
fixed value). The posterior distributions of DF for all the three multiple shrinkage models were
very similar.
4.5 Discussion
In this chapter, we have introduced Bayesian kernel based methods for regression and binary classi-
fication. Our kernel machine models can handle any large number of covariates. The regression and

68
S. Chakraborty, B. K. Mallick and M. Ghosh
classificationfunctionsarenotfixed,itisassumedtobelongtothereproducingkernelHilbertspace
or RKHS. RKHS encompasses a wide range of linear and nonlinear functions. In all the simulation
studies and real data analysis, the number of covariates (p) we had was far greater than the available
data points (n). Through our construction of the function through RKHS, the dimension of the
problem is projected from higher-dimensional (p) covariate space to lower-dimensional (n) kernel
space. Through posterior sampling our Bayesian models select the best choice of the kernel param-
eter θ. This enables our model to use multiple values of θ or a mixture of several kernels, linear and
nonlinear. Moreover, multiple shrinkage models always appear to be superior to single parameter
shrinkage models. With multiple shrinkage parameters, our Bayesian SVM model emerges as the
winner in all the examples. Bayesian SVM also has the unique ability to quantify the prediction
error, i.e. now we can have the entire posterior distribution of MSEP and can obtain a confidence
interval. Rather than having just a point predictor now we can have the full posterior predictive
probability distribution of a future observation. Bayesian kernel machine models are currently
under constant development and are an active area of study. Their usefulness is also been explored
in areas of multiple (correlated) response regression models, where the response is a vector with an
unknown correlation structure, Chakraborty et al. [6]. They have also been successfully extended
from binary classification to multiclass classification problems in high-dimensional microarray data
(Chakraborty et al. [5]). A new direction may be applying the kernel trick for survival and longitu-
dinal data with a large number of covariates. In the end we would like to view our methods as a new
probability based way of modelling and prediction in high-dimensional problems. Much of their
success and limitations will be revealed as more and more applications are made on various new
datasets.
References
[1] Aronszajn, N. (1950). Theory of reproducing kernels. Transactions of the American Mathemat-
ical Society, 68, 337–404.
[2] Bernardo, J. M. (1979). Expected information as expected utility, Annals of Statistics, 7,
686–690.
[3] Bishop, C. and Tipping, M. (2000). Variational relevance vector machines. Proceedings of the
16th Conference in Uncertainty and Artificial Intelligence (eds C. Boutilier and M. Goldszmidt).
Morgan Kauffman, San Francisco.
[4] Breiman, L. (2001). Random forests. Machine Learning, 45, 5–32.
[5] Chakraborty,S.,Ghosh,M.,Mallick,B.K.,Ghosh,D.andDoughertyE.(2007).Geneexpres-
sion-based glioma classification using hierarchical Bayesian vector machines. Sankhya, 69,
514–547.
[6] Chakraborty, S., Ghosh, M. and Mallick, B. (2011). Bayesian non-linear regression for large p
small n problems. Journal of Multivariate Analysis.
[7] Chib, S. and Greenberg, E. (1995). Understanding the Metropolis–Hastings algorithm. The
American Statistician, 49, 327–335.
[8] Gelfand, A. and Smith, A. F. M. (1990). Sampling-based approaches to calculating marginal
densities. Journal of the American Statistical Association, 85, 398–409.
[9] Gelman, A. (1996). Inference and monitoring convergences, in Markov Chain Monte Carlo
in Practice (eds Gilks, Richardson and Spiegelhalter), pp. 131–140, London: Chapman
and Hall.
[10] Gelman, A., Carlin, J., Stern, H. and Rubin, D. (2003). Bayesian Data Analysis, Chapman
and Hall.
[11] Golub, T. R., Slonim, D., Tamayo, P., Huard, C., Gaasenbeek, M., Mesirov, J., Coller, H., Loh,
M., Downing, J., Caligiuri, M., Bloomfield, C. and Lander, E. (1999). Molecular classification

Bayesian hierarchical kernel machines
69
of cancer: Class discovery and class prediction by gene expression monitoring. Science, 286,
531–537.
[12] Good, I. J. (1965). The Estimation of Probabilities. An Essay on Modern Bayesian Methods. MIT
Press, MA.
[13] Huber, P. (1964). Robust estimation of a location parameter. Annals of Mathematical Statistics,
53, 73–101.
[14] Kalivas, J. H. (1997). Two data sets of near infrared spectra. Chemometrics and Intelligent
Laboratory Systems, 37, 255–259.
[15] Kimeldorf,G.andWahba,G.(1971).SomeresultsonTchebycheffiansplinefunctions.Journal
of Mathematical Analysis and Applications, 33, 82–95.
[16] Law,M.H.andKwok,J.T.(2001).Bayesiansupportvectorregression.ProceedingsoftheEighth
International Workshop on Artificial Intelligence and Statistics (AISTATS), 239–244. Key West,
Florida, USA.
[17] MacKay, D. J. C. (1994). Bayesian non-linear modeling for the prediction competition.
ASHRAE Trans., 100(2), 1053–1062.
[18] Mallick, B. K., Ghosh, D. and Ghosh, M. (2005). Bayesian classification of tumors using gene
expression data. Journal of the Royal Statistical Society, B, 67, 219–232.
[19] Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H. and Teller, E. (1953).
Equations of state calculations by fast computing machines. Journal of Chemical Physics, 21,
1087–1092.
[20] Neal, R. M. (1996). Bayesian Learning for Neural Networks, Springer-Verlag, New York.
[21] Parzen, E. (1970). Statistical inferences on time series by RKHS methods. Proceedings of the
12th Biennial Seminar, 1–37, Canadian Mathematical Congress, Montreal, Canada.
[22] Ripley, B. D. (1996). Pattern Recognition and Neural Networks, Cambridge University Press.
[23] Sollich, P. (2001). Bayesian methods for support vector machines: evidence and predictive
class probabilities. Machine Learning, 46, 21–52.
[24] Spiegelman, C., Wikander, J., O’Neal, P. and Coté, G. L. (2002). A simple method for lin-
earizing nonlinear spectra for calibration. Chemometrics and Intelligent Laboratory Systems, 60,
197–209.
[25] Tipping, M. (2000). The relevance vector machine. Neural Information Processing Systems Vol
12, S. Solla, T. Leen and K. Muller (eds), 652–658. MIT Press, Cambridge, MA.
[26] Tipping, M. (2001). Sparse Bayesian learning and the relevance vector machine. J. Mach.
Learn. Res., 1, 211–244.
[27] Vapnik, V. N. (1995). The Nature of Statistical Learning Theory, 2nd edn. Springer: New York.
[28] Wahba, G. (1990). Spline Models for Observational Data. SIAM: Philadelphia.
[29] Wahba, G. (1999). Support vector machines, reproducing kernel Hilbert spaces and the ran-
domized GACV, in Advances in Kernel Methods, B. Schölkopf, C. Burges and A. Smola (eds),
69–88. MIT Press, Cambridge, MA.

5
Flexible Bayesian modelling
for clustered categorical
responses in developmental
toxicology
athanasios kottas and
kassandra fronczyk
5.1 Introduction
D
evelopmental toxicity studies investigate birth defects induced by toxic chemicals. In particu-
lar, under the standard Segment II developmental toxicity experiment, at each experimental
dose level, xi, i = 1, . . . , N, a number, ni, of pregnant laboratory animals (dams) are exposed to the
toxin. Dam j at dose xi has mij implants, of which the number of resorptions, that is, undeveloped
embryos or very early foetal deaths, and prenatal deaths are recorded as Rij, and the number of live
pups at birth with a certain malformation are recorded as yij. Consequently, the number of viable
foetuses for dam j at dose xi is mij −Rij. Additional continuous outcomes measured on each of the
live pups may include body weight and length.
The main objective of developmental toxicity studies is to examine the relationship between the
level of exposure to the toxin, which we generically refer to as the dose level, and the probability
of the various responses of interest. We focus on the clustered categorical endpoints of embry-
olethality,thatis,non-viablefoetuses,andfoetalmalformationforlivepups;thus,thedatastructure
comprises {(mij, Rij, yij) : i = 1, . . . , N; j = 1, . . . , ni}. The corresponding dose–response curves
are defined by the probability of the endpoints across dose levels. Also of interest is quantitative risk
assessment,whichevaluatestheprobabilitythatadverseeffectsmayoccurasaresultoftheexposure
to the substance.
Plotted in Figure 5.1 is a motivating dataset, available from the National Toxicology Program
database, from an experiment that explored the effects of diethylhexalphthalate (DEHP), a com-
monly used plasticizing agent. The left and middle panels correspond to the endpoints of a
non-viable foetus, that is, resorption or prenatal death, and malformation, that is, external, visceral
orskeletalmalformationofalivefoetus.Therightpanelplotstheproportionsofcombinednegative
outcomes, that is, adding the number of non-viable foetuses and malformations.
The number of dams is 30 for the control group, and 26, 26, 17 and 9 for doses 25, 50, 100 and 150
mg/kg ×1000. The number of implants across all dams and dose levels ranges from 4 to 18, with
25th,50thand75thpercentilesequalto11,13and14,respectively.Particularlynoteworthyisthedrop

Flexible Bayesian modelling in developmental toxicology
71
0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
50
100
150
R/m
dose mg/kg x 1000
0
50
100
150
y/(m–R)
dose mg/kg x 1000
0
50
100
150
(R+y)/m
dose mg/kg x 1000
Figure 5.1 DEHP data. In each panel, a circle corresponds to a particular dam and the size of
the circle is proportional to the number of implants. The coordinates of the circle are the dose
level and the proportion of the specific endpoint: non-viable foetuses among implants (left panel);
malformations among live pups (middle panel); combined negative outcomes among implants (right
panel).
in the proportions of malformations, and combined negative outcomes, from dose 0 to 25 mg/kg
×1000, which may correspond to a hormetic dose–response relationship. Hormesis refers to a
dose–response phenomenon characterized by favourable biological responses to low exposures
to toxins, and thus by opposite effects in small and large doses. For endpoints involving disease
incidence, such as mutation, birth defects or cancer, hormesis results in a J-shaped dose–response
curve. Although the possibility of different low dose effects is accepted, the suggestion of positive
low dose effect is debated, hence, hormesis remains a controversial concept in the toxicological
sciences [e.g. 1].
Notwithstanding the ultimate scientific conclusions, data such as those from the DEHP study
motivate our modelling framework for the dose-dependent response distributions which enables
rich inference for the implied, possibly non-monotonic, dose–response curves. Building flexible
modelling for the response distribution is easy to justify for developmental toxicology data, which
typically indicate vast departures from parametric models. This can be attributed to the inherent
heterogeneity in the data due to the clustering of individuals within a group and the variability of
the reaction of the individuals to the toxin. Note also that the typical toxicity experiment discussed
above provides information on potentially different dose–response relationships for the distinct
endpoints of embryolethality and foetal malformation, and it is thus biologically relevant to jointly
analyse the clustered responses. This stands in contrast with the prevailing data structure found in
the statistical literature, where the variables involved are the number of implants and the sum of all
negative outcomes, as in the right panel of Figure 5.1.
We develop a Bayesian nonparametric mixture model for the joint distribution of the number of
non-viable foetuses and malformations. We seek mixture modelling for response distributions that
arerelatedacrossdoseswiththelevelofdependencedrivenbythedistancebetweenthedosevalues.
To this end, we consider a dependent Dirichlet process (DDP) prior [18] for the dose-dependent
mixingdistributions.ParticularemphasisisplacedonthechoiceofthemixturekernelandtheDDP
prior formulation to ensure an increasing trend in prior expectation for the implied dose–response
curves, but without restricting prior realizations to be necessarily monotonic. This is key for the

72
A. Kottas and K. Fronczyk
model’scapacitytocapturenon-standarddose–responserelationships.Thenonparametricmixture
model structure enables flexible inference for the response distributions at any observed dose level.
Moreover, the dependence of the DDP prior across dose levels allows inference for the induced
dose–response relationships through interpolation and extrapolation over any range of dose values
of interest.
The modelling approach developed here extends work for the simpler data setting with com-
bined negative outcomes [10]. To our knowledge, the literature does not include any Bayesian non-
parametric approaches to modelling developmental toxicology data with a multicategory response
classification. A Bayesian semiparametric model for the combined negative endpoints case, based
on a product of Dirichlet process prior, was proposed by [5], and more recently extended in [19].
Examples of parametric Bayesian hierarchical models for toxicology data with discrete–continuous
outcomes include [6] and [8]. Regarding the classical literature, a Dirichlet-trinomial model is pre-
sented in [2]; [24] develop an extended Dirichlet-multinomial model with Weibull dose–response
functions;and[21]and[17]usequasi-likelihoodandgeneralizedestimatingequations,respectively,
to fit multinomial models which incorporate overdispersion.
The outline of the paper is as follows. Section 5.2 develops the DDP mixture model, including
model properties and methods for prior specification and Markov chain Monte Carlo posterior
inference. In Section 5.3, we present the application to the analysis of the DEHP data. Section 5.4
concludes with a summary.
5.2 Methods
5.2.1 The modelling approach
Under the Segment II toxicity study design, exposure occurs after implantation, and thus it is
natural to treat the number of implants as a random quantity containing no information about the
dose–response relationship. Hence, the modelling for the number of implants (m), the number
of non-viable foetuses (R), and the number of malformations (y) is decomposed to f(m, R, y) =
f(m)f(R, y | m), where only the conditional distribution f(R, y | m) will depend on dose level x.
We assume a shifted Poisson distribution for f(m) such that m ≥1, although more general distri-
butions can be readily utilized. Inference for the implant distribution is carried out separately from
inference for f(R, y | m), and is not discussed further.
To develop a flexible inference framework for risk assessment, we propose a nonparametric mix-
ture model for the dose-dependent conditional distribution of the number of non-viable foetuses
and malformations given the number of implants. Specifically, for a generic dose x,
f(R, y | m) ≡f(R, y | m; Gx) =

k(R, y | m; ϕ) dGx(ϕ)
where k(R, y | m; ϕ) is a parametric kernel, with parameters ϕ, and Gx the dose-dependent mixing
distribution. Placing a nonparametric prior on Gx results in a nonparametric mixture prior for
f(R, y | m; Gx). Nonparametric Bayesian mixture priors offer flexible modelling tools that, with
the appropriate structure, can capture the complexity inherent in the data. These models can be
viewed as extensions of finite mixture or continuous mixture models, where the random mixing
distribution is not defined with a particular parametric family of distributions.
Regarding the mixture kernel, we take k(R, y | m; γ , θ) = Bin(R; m, π(γ ))Bin(y; m −
R, π(θ)), where π(u) = exp(u)/{1 + exp(u)}, u ∈R, will be used to denote the logistic function.
Therefore, π(γ ) is the kernel probability of a non-viable foetus, and π(θ) the conditional
probability of a malformation for a live pup. This formulation of the trinomial kernel distribution

Flexible Bayesian modelling in developmental toxicology
73
is natural as it highlights the nested nature of the count responses. Moreover, the logistic trans-
formation for the Binomial probabilities is used to facilitate the formulation of the nonparametric
prior model for the collection of mixing distributions, GX = {Gx : x ∈X}, where X ⊆R+.
As discussed in the Introduction, we seek modelling for the response distributions that allow
nonparametric dependence structure across dose levels. We achieve such modelling by placing
a DDP prior on the dose-dependent mixing distributions {Gx : x ∈X}. The DDP prior arises
through extension of the Dirichlet process (DP) prior [9], the most widely used prior for mix-
ing distributions in nonparametric or semiparametric mixture models. We use DP(α, G0) to
denote the DP prior defined in terms of a parametric centring distribution G0, and precision
parameter α > 0.
To define the form of the DDP prior we use for GX , the almost sure discrete representation for
the regular DP [22] is extended to
GX (·) =
∞

l=1
ωlδηlX (·)
(5.1)
where δa denotes a point mass at a, the ηlX = {ηl(x) : x ∈X} are independent realizations
from a stochastic process G0X over X, and the weights are defined by a stickbreaking process:
ω1 = ζ1, and ωl = ζl
	l−1
r=1(1 −ζr) for l ≥2, with ζl independent from a Beta(1,α) distribution,
independently of the ηlX . A key feature of the DDP prior is that for any finite collection of dose
levels (x1, ..., xk) it induces a multivariate DP prior for the corresponding collection of mixing
distributions (Gx1, ..., Gxk). Therefore, the DDP prior model involves a countable mixture of real-
izationsfromstochasticprocessG0X withweightsmatchingthosefromthestandardDP;thisprior
structure is referred to as single-p DDP prior. Single-p DDP mixture models have been applied to
analysisofvariancesettings[4],spatialmodelling[11,15],dynamicdensityestimation[20],quantile
regression [16] and survival regression [3].
Finally, the DDP prior mixture model is given by
f(R, y | m; GX ) =

Bin(R; m, π(γ ))Bin(y; m −R, π(θ)) dGX (γ , θ), GX ∼DDP(α, G0X )
(5.2)
Here, DDP(α, G0X ) denotes the DDP prior for GX = ∞
l=1 ωlδηlX , where ηl(x) =
(γl(x), θl(x)), for x ∈X, with precision parameter α and base stochastic process G0X . We
define G0X through two independent Gaussian processes, one driving each probability of
response, each with a linear mean function, constant variance, and isotropic exponential
correlation function. Hence, to introduce notation, we assume for all l, E(γl(x) | ξ0, ξ1) = ξ0
+ ξ1x, and E(θl(x) | β0, β1) = β0 + β1x; var(γl(x) | τ2) = τ2, and var(θl(x) | σ 2) = σ 2;
corr(γl(x), γl(x′) | ρ) = exp(−ρ|x −x′|), and corr(θl(x), θl(x′) | φ) = exp(−φ|x −x′|), with
ρ > 0 and φ > 0. As discussed in the next section, this specification for G0X and, in particular,
the linear mean functions, are key for flexible inference about the dose–response relationships
implied by model (5.2). The full Bayesian model is implemented with priors on α and on the G0X
hyperparameters, ψ = (ξ0, ξ1, τ2, ρ, β0, β1, σ2, φ).
5.2.2 Dose–response relationships
Here, we study the dose–response curves implied by DDP mixture model (5.2), including the
probability of a non-viable foetus, the conditional probability of a malformation for a live pup and
a risk function that combines the two endpoints.

74
A. Kottas and K. Fronczyk
To develop the dose–response curves, it is useful to note a connection of the mixture model
with the clustered Binomial kernels with the model based on products of Bernoulli’s kernel for
the underlying binary responses. That is, for a generic dam at dose level x with m implants, let
R∗= {R∗
k : k = 1, . . . , m} be the individual non-viable foetus indicators and denote by y∗=
{y∗s : s = 1, . . . , m −m
k=1 R∗
k} the malformation indicators for the viable foetuses. Therefore,
R = m
k=1 R∗
k and y = m−
k R∗
k
s=1
y∗s . Then, a DDP mixture model for the clustered binary
responses can be formulated as
f ∗
R∗, y∗| m; GX

=

m

k=1
Bern(R∗
k ; π(γ ))
m−
k R∗
k

s=1
Bern(y∗
s ; π(θ)) dGX (γ , θ)
(5.3)
where GX is assigned the same DDP prior as the one for model (5.2). It is straightforward to show
that mixture models (5.2) and (5.3) are equivalent with regard to the distribution for (R, y) condi-
tional on m; in particular, the joint moment generating function for (m
k=1 R∗
k , m−
k R∗
k
s=1
y∗s )
under model (5.3) is equal to the joint moment generating function for (R, y) under model (5.2),
in both cases, conditioning on m. Hence, we can define the dose–response curves under the DDP
mixture model (5.2) working with probabilities of the two endpoints for a generic implant; this
involves implicit conditioning on m = 1, which we suppress in the notation below.
The first risk assessment quantity of interest is the probability of embryolethality across effective
dose levels, which is defined by
D(x) ≡pr(R∗= 1; Gx) =

π(γ ) dGx(γ , θ),
x ∈X
Risk assessment for the malformation endpoint is based on the conditional probability that a
generic pup has a malformation given that it is a viable foetus, i.e.
M(x) ≡pr(y∗= 1 | R∗= 0; Gx) = pr(R∗= 0, y∗= 1; Gx)
pr(R∗= 0; Gx)
=

{1 −π(γ )}π(θ)dGx(γ , θ)

{1 −π(γ )}dGx(γ , θ)
,
x ∈X
Moreover, a full risk function at any given dose level can be defined through the combination of the
probabilityofanon-viablefoetusandtheprobabilityofalive,malformedpup;thatis,thecombined
risk at dose level x is given by
r(x) ≡pr(R∗= 1 or y∗= 1; Gx) = pr(R∗= 0, y∗= 1; Gx) + pr(R∗= 1; Gx)
=

{1 −π(γ )}π(θ) dGx(γ , θ) +

π(γ ) dGx(γ , θ)
= 1 −

{1 −π(γ )}{1 −π(θ)} dGx(γ , θ),
x ∈X
A key aspect of the modelling approach is that it does not force a non-decreasing shape restriction
to the dose–response functions, which is the traditional assumption for more standard quantal
bioassay experiments. As discussed in the Introduction and illustrated in Section 5.3 with the
DEHPdata,themodel’scapacitytocapturenon-standard,possiblynon-monotonic,dose–response

Flexible Bayesian modelling in developmental toxicology
75
relationships is an asset of the proposed methodology. At the same time, given the relatively small
number of observed dose levels in developmental toxicity studies, some structure is needed in
the prior model in order to obtain meaningful interpolation and extrapolation posterior inference
results for the dose–response curves. Under the specific formulation of the DDP prior for mixture
model (5.2), such structure can be incorporated in the form of a non-decreasing trend in prior
expectation for the dose–response curves.
Consider first the prior expectation for the dose-dependent probability of a non-viable
foetus,
E{D(x)} = E

π(γ )dGx(γ , θ)

=

π(γ )dG0x(γ , θ) =

π(γ )dN(γ ; ξ0 + ξ1x, τ2)
that is, E{D(x)} is the expectation of the (increasing) logistic function with respect to the
N(ξ0 + ξ1x, τ2) distribution, which is stochastically ordered in x when ξ1 > 0. Hence, D(x) is
a non-decreasing function of x in prior expectation, under the ξ1 > 0 prior restriction. Similarly,
E{r(x)} = 1 −

{1 −π(γ )}{1 −π(θ)}dG0x(γ , θ)
= 1 −

{1 −π(γ )}dN(γ ; ξ0 + ξ1x, τ2)
 
{1 −π(θ)}dN(θ; β0 + β1x, σ 2)

Provided ξ1 > 0 and β1 > 0, distributions N(ξ0 + ξ1x, τ2) and N(β0 + β1x, σ 2) are
stochastically ordered in x, which implies that both

{1 −π(γ )}dN(γ ; ξ0 + ξ1x, τ2) and

{1 −π(θ)}dN(θ; β0 + β1x, σ 2) are decreasing functions of x, with values in the unit interval.
Thus, E{r(x)} is non-decreasing in x when ξ1 > 0 and β1 > 0.
Therefore, with the ξ1 > 0 and β1 > 0 prior restrictions, we can build to both the probability
of a non-viable foetus and to the combined risk function the non-decreasing trend in prior expec-
tation. Although the same argument does not extend to the conditional probability of malforma-
tion, M(x), the restriction ξ1 > 0 and β1 > 0 appears sufficient to provide the prior expectation
non-decreasing trend for all three dose–response curves. In this respect, it is useful to note that,
even though we develop inference about three dose–response relationships, there are only two
endpoints and, consequently, the model is driven at any specific dose level by a bivariate random
mixing distribution.
Note that the argument above relies on both the constant Gaussian process variances for
the two components of G0X —which ensures the stochastic ordering of the induced normal
distributions—and on the linear Gaussian process mean functions—which enables the non-de-
creasing trend through the restriction on the slope parameters. Indeed, the linear mean functions
are crucial for practicable posterior inference. As suggested by Figure 5.2, if the model is applied
using constant mean functions for the DDP prior centring Gaussian processes, that is, setting
ξ1 = β1 = 0, we should not expect practically useful results outside the observed dose levels. For
illustration, Figure 5.2 plots results from prior simulation for the embryolethality and malformation
dose–response curves, and for the combined risk function, using fixed values for α (= 1) and
ψ. In particular, (ξ1 = 0.0085, β1 = 0.12) and (ξ1 = 0.12, β1 = 0.01) in the top and middle
row, respectively. Although the relative magnitudes of ξ1 and β1 affect the rate of increase for the
different curves, in all cases with ξ1 > 0 and β1 > 0, the non-decreasing trend in prior expectation
is preserved.
Finally, smoothness properties of prior realizations for the dose–response curves relate directly
to the respective properties of the centring process G0X . For details, we refer to the arguments
in [18] and [11], extended and formalized by [12], but note briefly that the continuity of the
realizations from the two Gaussian processes that define G0X implies that as the distance
between x and x′ gets smaller, the difference between Gx and Gx′ gets smaller; moreover, it yields

76
A. Kottas and K. Fronczyk
0
20
40
60
80 100
0.0 0.4 0.8
ξ1 > 0
dose
0
20
40
60
80 100
dose
0
20
40
60
80 100
dose
D(x)
0
20
40
60
80 100
0.0 0.4 0.8
β1 > ξ1 > 0
β1 > ξ1 > 0
ξ1 > β1 > 0
ξ1 > β1 > 0
β1 = ξ1 = 0
β1 = ξ1 = 0
ξ1 > 0
ξ1 = 0
dose
M(x)
0
20
40
60
80 100
0.0 0.4 0.8
dose
r(x)
0.0 0.4 0.8
D(x)
0
20
40
60
80 100
0.0 0.4 0.8
dose
M(x)
0
20
40
60
80 100
0.0 0.4 0.8
dose
r(x)
0.0 0.4 0.8
D(x)
0
20
40
60
80 100
0.0 0.4 0.8
dose
M(x)
0
20
40
60
80 100
0.0 0.4 0.8
dose
r(x)
Figure 5.2 Prior mean and 90% interval estimates, along with five individual prior realizations, for the
three dose–response curves. See Section 5.2.2 for details.
continuous prior realizations for the three dose–response functions defined above. The practical
implication is that in prediction for the probability mass function f(R, y | m; Gx) and for the
corresponding dose–response curves, we learn more from dose levels x′ nearby x than from more
distant doses, a desirable property for distributions that are expected to evolve relatively smoothly
with the dose level.
5.2.3 Implementation details
Markov chain Monte Carlo posterior simulation
Regarding the hierarchical model formulation for the data = {(mij, Rij, yij) : i = 1, . . . , N;
j = 1, . . . , ni}, we observe that for the DEHP data (discussed in the Introduction) the dams are
labelledandrecordedinascendingnumericalorderacrossdoselevels;thatis,thesmallestidentifica-
tion number corresponds to data from the first dam at the first dose level, the first dam at the second
dose level has the next identification number, and so on. This is also the case for other datasets
available from the database of the National Toxicology Program. Therefore, to write the model for
the data, the animals are linked as a response vector across the dose levels with the conditional
independence assumption built for the replicated response vectors. Hence, the data structure and
corresponding hierarchical model are along the lines of the spatial DP [11] rather than, for instance,
the ANOVA DDP [4].
Therefore, let Rj = (R1j, . . . , RNj), and yj = (y1j, . . . , yNj) be the j-th response repli-
cates with corresponding number of implants vector mj = (m1j, . . . , mNj), for j = 1, . . . , n,
where n = maxi ni. Moreover, denote by γj ≡γj(x) = (γj(x1), . . . , γj(xN)), and θj ≡θj(x) =
(θj(x1), . . . , θj(xN)) the latent mixing vector for Rj and yj, respectively, where x = (x1, . . . , xN).
We introduce missing value indicators, sij, such that sij = 1 if the j-th response replicates at dose

Flexible Bayesian modelling in developmental toxicology
77
level i are present and sij = 0 otherwise. Note that the sij are fixed for any particular dataset. Then,
the first stage of the hierarchical model for the data can be written as
{(Rij, yij)} | {mij}, {(γj, θj)} ∼
n

j=1
N

i=1

Bin(Rij; mij, π(γj(xi)))Bin(yij; mij −Rij, π(θj(xi)))
sij
where the (γj, θj), given Gx, are i.i.d. from Gx, which follows a DP(α, G0x) prior implied by
the DDP prior for GX . In particular, G0x comprises two independent N-variate normal dis-
tributions, induced by the two Gaussian processes that define G0X ; the first normal distribu-
tion has mean vector (ξ0 + ξ1x1, . . . , ξ0 + ξ1xN)′ and covariance matrix with (i, j)-th element
Tij = τ2 exp(−ρ|xi −xj|); the mean of the second normal distribution is (β0 + β1x1, . . . , β0 +
β1xN)′ and its covariance matrix has (i, j)-th element ij = σ 2 exp(−φ|xi −xj|).
Hence, the hierarchical model for the data is a DP mixture model induced by the DDP mix-
ture prior. For Markov chain Monte Carlo posterior simulation, we use blocked Gibbs sampling
[e.g. 13], which offers relatively ready implementation and also, in our context, can easily handle
unbalanced response replicates. The approach is based on a finite truncation approximation of Gx
such that Gx ≈GLx = L
l=1 plδ(Ul(x),Zl(x)), where the weights pl arise from a truncated version of
the stickbreaking construction: p1 = V1, pl = Vl
	l−1
r=1(1 −Vr), l = 2, . . . , L −1, and pL = 1 −
L−1
l=1 pl, with the Vl i.i.d., given α, from Beta(1, α). Moreover, Ul(x) = (Ul(x1), . . . , Ul(xN)) ≡
Ul and Zl(x) = (Zl(x1), . . . , Zl(xN)) ≡Zl, with the (Ul, Zl) i.i.d., given ψ, from G0x, for
l = 1, ..., L. Hence, under the truncated version of mixing distribution Gx, (γj, θj) = (Ul, Zl)
with probability pl, and GLx ≡(p, U, Z), where p = (p1, . . . , pL), U = (U1, . . . , UL) and
Z = (Z1, . . . , ZL).
To represent the hierarchical model for the data under the DP truncation approximation, config-
urationvariablesw =(w1, . . . , wn)areintroduced,suchthatwj = lifandonlyif(γj, θj) =(Ul, Zl),
for l = 1, . . . , L and j = 1, . . . , n. Then, the model for the data can be expressed as
{(Rj, yj)} | {mj}, w, (U, Z)∼
n

j=1
N

i=1

Bin(Rij; mij, π(Uwj(xi)))Bin(yij; mij −Rij, π(Zwj(xi)))
sij
wj | p ∼
n

j=1
L

l=1
plδl(wj)
p, (U, Z) | α, ψ ∼f(p | α) ×
L

l=1
G0x(Ul, Zl | ψ)
(5.4)
where f(p | α) = αL−1pα−1
L
(1 −p1)−1{1 −(p1 + p2)}−1 × · · · × (1 −L−2
l=1 pl)−1, a spe-
cial case of the generalized Dirichlet distribution, is the prior for p, given α, induced by the
truncated stickbreaking construction. The full Bayesian model is completed with independent
hyperpriors for the DDP precision parameter α and the parameters ψ of the centring Gaus-
sian processes. Specifically, we place a gamma(aα, bα) prior on α; normal priors N(mξ, s2
ξ) and
N(mβ, s2
β) on ξ0 and β0; exponential priors Exp(bξ ) and Exp(bβ) on ξ1 and β1 to promote the
non-decreasing trend in prior expectation for the dose–response functions; inverse gamma priors
inv-gamma(aτ , bτ ) and inv-gamma(aσ , bσ ) on the variance terms τ2 and σ 2; and uniform priors
Unif(0, bρ) and Unif(0, bφ) on the range parameters ρ and φ. Prior specification is discussed
below.

78
A. Kottas and K. Fronczyk
Denote the n∗distinct values of vector w by w∗
1, . . . , w∗
n∗, and let M∗
k = |{j : wj = w∗
k}|, for
k = 1, . . . , n∗, and Ml = |{j : wj = l}|, for l = 1, . . . , L. Then, sampling from the posterior dis-
tribution p(U, Z, w, p, α, ψ | data) corresponding to model (5.4) is based on simulation from the
following posterior full conditional distributions.
The (Ul, Zl) that correspond to l /∈{w∗
k : k = 1, . . . , n∗} are sampled from G0x given its cur-
rently imputed parameters ψ. For l = w∗
k, k = 1, . . . , n∗, the posterior full conditional for Uw∗
k is
proportional to Gγ
0x(Uw∗
k | ψ) 	
{j:wj=w∗
k}
	N
i=1{Bin(Rij; mij, π(Uw∗
k (xi)))}sij, and the posterior
full conditional for Zw∗
k to Gθ
0x(Zw∗
k | ψ) 	
{j:wj=w∗
k}
	N
i=1{Bin(yij; mij −Rij, π(Zw∗
k (xi)))}sij.
Here, Gγ
0x and Gθ
0x denote the respective N-variate normal distributions arising from G0x. Each of
Uw∗
k and Zw∗
k is updated using a random-walk Metropolis–Hastings step with an N-variate normal
distribution as the proposal. The proposal covariance matrices were estimated dynamically, using
initial runs based on normal proposals with scaled identity covariance matrices.
The posterior full conditional for each wj, j = 1, . . . , n, is given by a discrete distribution with
values l = 1, . . . , L and corresponding probabilities
˜plj ∝pl
N
i=1{Bin(Rij; mij, π(Ul(xi)))Bin(yij; mij −Rij, π(Zl(xi)))}sij,
l = 1, . . . , L
The updates for parameters α and p are the same with a generic DP mixture model [14]. Finally,
the joint posterior full conditional for the hyperparameters ψ of the DDP prior centring Gaussian
processes is proportional to
p(ξ0)p(ξ1)p(τ2)p(ρ)p(β0)p(β1)p(σ 2)p(φ) ×
n∗
k=1 G0x(Uw∗
k , Zw∗
k | ψ)
where p(·) denotes the prior for each parameter. The form of G0x and the parametric priors for the
components for ψ result in normal posterior full conditionals for ξ0 and β0, and inverse gamma
full conditionals for τ2 and σ 2. We use Metropolis–Hastings updates for ξ1 and β1, and sample ρ
and φ by discretizing their bounded support.
Inference for risk assessment
The samples from the posterior distribution of model (5.4) yield the mixing distribution GLx at
all the observed dose levels through the posterior samples for (p, U, Z). To expand the inference
over any range of doses of interest, we augment the N observed dose levels with M new doses,
˜x = (˜x1, . . . , ˜xM). Now, in the prior model, the (Ul(x), Ul(˜x)) and the (Zl(x), Zl(˜x)), for
l = 1, . . . , L, are independent realizations from two independent (N + M)-variate normal distri-
butions, induced by the Gaussian processes that define G0X , with mean vectors and covariance
matrices that are of the same form as above extending x to (x, ˜x). But then, to sample from the con-
ditional posterior distributions for each of the Ul(˜x) and Zl(˜x), the additional sampling needed is
fromconditionalM-variatenormaldistributionsgiventhecurrentlyimputed(Ul, Zl),l = 1, . . . , L,
and the parameters ψ.
Using the posterior samples from model (5.4), augmented with the posterior samples
for (Ul(˜x), Zl(˜x)), l = 1, . . . , L, full inference for the response distributions and for risk
assessment through the dose–response curves can be obtained by evaluating the relevant
expressions developed in Sections 5.2.1 and 5.2.2. Under the DP truncation approximation
used for posterior simulation, the integrals are replaced with sums. For instance, for any
generic dose x0 in (x, ˜x), the posterior distribution for the probability of a non-viable
foetus arises from L
l=1 plπ(Ul(x0)), and for the combined risk function through
1 −L
l=1 pl{1 −π(Ul(x0))}{1 −π(Zl(x0))}. Moreover, for a specified number of implants

Flexible Bayesian modelling in developmental toxicology
79
m0, the conditional probability mass function for the number of malformations given R0
non-viable foetuses, is evaluated through L
l=1 ql(x0)Bin(y; m0 −R0, π(Zl(x0))), where
ql(x0) = plBin(R0; m0, π(Ul(x0)))/{L
t ptBin(R0; m0, π(Ut(x0)))}. The posterior samples can
be summarized with means and percentiles to provide posterior mean estimates and uncertainty
bands for dose–response curves and probability mass functions for the response distributions;
Section 5.3 reports such inferences for the DEHP data.
Prior specification
To specify the uniform priors for the range parameters ρ and φ, we consider the limiting case
of the DDP model with α →0+, which yields the kernel of the mixture in (5.2) as the model’s
first stage with G0X defining Gaussian process priors for the Binomial probabilities on the logistic
scale. Then, under the exponential correlation function, 3/ρ is the range of dependence, that is, the
distance between dose levels that yields correlation 0.05 for the Gaussian process realizations that
definetheprobabilityofanon-viablefoetus,and,analogously,for3/φ.Therangeisusuallyassumed
tobeafractionofthemaximuminterpointdistanceovertheindexspace.LetDmax bethemaximum
distance between observed doses. Since 3/bρ < 3/ρ, we specify bρ such that 3/bρ = rDmax for
a small r; r = 0.002 was used for the DEHP data analysis in Section 5.3 leading to a Unif(0, 10)
prior for ρ; the same uniform prior was used for φ. This approach to prior specification for ρ and
φ is conservative, in particular, the posterior distributions for ρ and φ are concentrated on values
substantially smaller than bρ and bφ.
We set the prior means for ξ0 and β0 to 0, and the shape parameters of the inverse gamma priors
for τ 2 and σ 2 to 2, implying infinite prior variance. The prior variances for ξ0 and β0, and the
prior means for ξ1, β1, τ2 and σ2 are chosen by studying the induced prior distribution for the
dose–responsecurvesdefinedinSection5.2.2.FortheDEHPdata,weplacedaN(0, 10)prioron ξ0
and β0, an exponential prior with mean b−1
ξ
= b−1
β
= 0.1 on ξ1 and β1, and an inv-gamma(2, 10)
onτ2 andσ 2.Underthispriorchoice,thepriormeansforfunctionsD(x)andM(x)havearelatively
weak increasing trend starting around 0.5, with 90% uncertainty bands that cover almost the entire
unit interval.
The DDP prior precision parameter, α, controls the number,n∗, of distinct mixture components
[e.g. 7]. In particular, for moderate to large sample sizes, a useful approximation to the prior expec-
tation E(n∗| α) is given by α log{(α + n)α−1}. This expression can be averaged over the prior for
α to obtain E(n∗), thus selecting the gamma prior parameters to agree with a guess at the expected
numberofdistinctmixturecomponents.Agamma(2, 1)priorwasusedfortheDEHPdataexample
corresponding to E(n∗) ≈5. Prior sensitivity analysis revealed robust posterior inference under
more dispersed priors.
Finally, the level L for the DP truncation approximation can be chosen using standard distri-
butional properties for the weights arising from the stickbreaking structure in (5.1). For instance,
E(L
l=1 ωl | α) = 1 −{α/(α + 1)}L, which can be averaged over the prior for α to estimate
E(L
l=1 ωl). Given a tolerance level for the approximation, this expression is solved numerically to
obtain the corresponding value L. For the analysis of the DEHP data, we used L = 50, which yields
E(L
l=1 ωl) ≈0.9999593 under the gamma(2, 1) prior for α.
5.3 Data example
We illustrate the proposed DDP mixture modelling approach with the DEHP dataset discussed in
the Introduction (Figure 5.1). It is known that plasticizers, such as the DEHP plasticizing agent,
may leak in small quantities from plastic containers with various solvents such as food or milk.

80
A. Kottas and K. Fronczyk
0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
50
100
150
probability of non-viable foetus
dose mg/kg x 1000
Pr(R*=1;Gx)
0
50
100
150
probability of malformation
dose mg/kg x 1000
Pr(Y*=1|R*=0;Gx)
0
50
100
150
combined risk
dose mg/kg x 1000
r(x;Gx)
Figure 5.3 For the DEHP data, the posterior mean (solid lines) and 90% interval bands (dashed lines)
for the risk assessment functions: probability of a non-viable foetus (left panel); conditional probability
of malformation (middle panel); combined risk (right panel).
The possibility of toxic effects from these agents has been recognized and tested in developmental
toxicitystudiessuchastheonedescribedin[23].Recallthatthetwoendpointsarenon-viablefoetus
corresponding to resorption or actual prenatal death, and malformation involving external, visceral
or skeletal malformation of a live foetus.
Figure5.3plotstheposteriormeanand90%intervalestimatesforthethreedose–responsecurves
developed in Section 5.2.2 for risk assessment. The probability of a non-viable foetus across dose
levels is a monotonically increasing function, with uncertainty bands around the posterior mean
estimate that increase with increasing dose values, consistent with the decreasing number of dams
for larger dose levels. The conditional probability of malformation, however, reveals a non-mono-
tonic behaviour at the low dose levels, and this J-shaped pattern carries over to the combined risk
which also exhibits a dip in the probability from the control through dose 25 mg/kg × 1000. The
inference for the combined risk function agrees with the estimated dose–response curve for the
combined negative outcomes version of the DEHP data, as obtained in [10] based on a DDP
Binomial mixture model. The modelling approach presented in this paper is key to uncovering
the malformation endpoint as the one that contributes to the non-monotonic, possibly hormetic,
combined dose–response relationship.
Inferenceforresponsedistributionsisillustratedwithposteriormeanand90%intervalestimates
for the probability mass function of the number of non-viable foetuses given m = 12 implants
(Figure 5.4) and the number of malformations given m = 12 implants and R = 3 non-viable foe-
tuses (Figure 5.5). Results are reported for the control group, the four effective dose levels, and a
new dose at x = 75 mg/kg × 1000. As expected, there is more uncertainty in the estimation of
the conditional response distributions for malformation. The interpolation at the new dose level
appears to be influenced more by the distribution at dose 50, which can be attributed to the larger
sample size relative to dose 100. The estimated distributions for the number of non-viable foetuses
have relatively standard shapes, whereas there is some evidence of a bimodal shape at dose 100, and
skewness in the estimated malformation distributions.

Flexible Bayesian modelling in developmental toxicology
81
0
2
4
6
8
10 12
x= 0
R
0
2
4
6
8
10 12
x= 25
R
0
2
4
6
8
10 12
x= 50
R
0
2
4
6
8
10 12
0.0
0.2
0.4
0.6
0.8
0.0
0.2
0.4
0.6
0.8
0.0
0.2
0.4
0.6
0.8
0.0
0.2
0.4
0.6
0.8
0.0
0.2
0.4
0.6
0.8
0.0
0.2
0.4
0.6
0.8
new x= 75
R
0
2
4
6
8
10 12
x= 100
R
0
2
4
6
8
10 12
x= 150
R
Figure 5.4 The posterior mean (“o”) and 90% probability bands (dashed lines) of the probability mass
functions for the number of non-viable foetuses given m = 12 implants.
0
0.0
0.2
0.4
0.6
0.0
0.2
0.4
0.6
0.0
0.2
0.4
0.6
0.0
0.2
0.4
0.6
0.0
0.2
0.4
0.6
0.0
0.2
0.4
0.6
2
4
6
8
x= 0 , R= 3
y
0
2
4
6
8
x= 25 , R= 3
y
0
2
4
6
8
x= 50 , R= 3
y
0
2
4
6
8
new x= 75 , R= 3
y
0
2
4
6
8
x= 100 , R= 3
y
0
2
4
6
8
x= 150 , R= 3
y
Figure 5.5 The posterior mean (“o”) and 90% interval bands (dashed lines) of the probability mass
functions for the number of malformations given m = 12 implants and R = 3 non-viable foetuses.

82
A. Kottas and K. Fronczyk
5.4 Summary
We have developed a Bayesian nonparametric modelling approach for risk assessment in devel-
opmental toxicity studies. The motivation for the proposed methodology is that it is critical to
modelflexiblythedose-dependentdamspecificresponsedistributionassociatedwiththeclustered
categorical outcomes of a non-viable foetus and of malformation for a live pup. The model is built
from a mixture with a product Binomial kernel, to capture the nested structure of the responses,
andadependentDirichletprocesspriorforthedose-dependentmixingdistributions.Theresulting
nonparametric DDP mixture model provides rich inference for the response distributions as well
as for the dose–response curves. Data from a toxicity experiment involving a plasticizing agent were
used to illustrate the scientifically relevant feature of the DDP mixture model with regard to esti-
mation of different dose–response relationships for different endpoints, including non-monotonic
dose–response curves.
Acknowledgements
This research is part of the PhD dissertation of Kassandra Fronczyk, completed at University of
California, Santa Cruz, and was supported in part by the National Science Foundation under award
DEB 0727543, and by a Special Research Grant awarded by the Committee on Research, University
of California, Santa Cruz.
References
[1] Calabrese, E. J. (2005). Paradigm lost, paradigm found: The re-emergence of hormesis as a
fundamental dose response model in the toxicological sciences. Environmental Pollution, 138,
378–411.
[2] Chen,J.J.,Kodell,R.L.,Howe,R.B.,andGaylor,D.W.(1991).Analysisoftrinomialresponses
from reproductive and developmental toxicity experiments. Biometrics, 47, 1049–1058.
[3] DeIorio, M., Johnson, W. O., Müller, P., and Rosner, G. L. (2009). Bayesian nonparametric
nonproportional hazards survival modeling. Biometrics, 65, 762–771.
[4] DeIorio, M., Müller, P., Rosner, G. L., and MacEachern, S. N. (2004). An ANOVA model for
dependent random measures. Journal of the American Statistical Association, 99, 205–215.
[5] Dominici, F. and Parmigiani, G. (2001). Bayesian semiparametric analysis of developmental
toxicology data. Biometrics, 57, 150–157.
[6] Dunson, D., Chen, Z., and Harry, J. (2003). A Bayesian approach for joint modeling of cluster
size and subunit-specific outcomes. Biometrics, 59, 521–530.
[7] Escobar,M.D.andWest,M.(1995).Bayesiandensityestimationandinferenceusingmixtures.
Journal of the American Statistical Association, 90, 577–588.
[8] Faes, C., Geys, H., Aerts, M., and Molenberghs, G. (2006). A hierarchical modeling approach
for risk assessment in developmental toxicity studies. Computational Statistics & Data Analy-
sis, 51, 1848–1861.
[9] Ferguson, T. S. (1973). A Bayesian analysis of some nonparametric problems. The Annals of
Statistics, 1, 209–230.
[10] Fronczyk,K.andKottas,A.(2010).ABayesiannonparametricmodelingframeworkfordevel-
opmental toxicity studies. Technical Report UCSC-SOE-10-11, University of California Santa
Cruz, Department of Applied Mathematics and Statisics.
[11] Gelfand,A.E.,Kottas,A.,andMacEachern,S.(2005).Bayesiannonparametricspatialmodel-
ingwithDirichletprocessmixing.JournaloftheAmericanStatisticalAssociation,100,1021–1035.

Flexible Bayesian modelling in developmental toxicology
83
[12] Guindani, M. and Gelfand, A. E. (2006). Smoothness properties and gradient analysis
under spatial Dirichlet process models. Methodology and Computing in Applied Probability, 8,
159–189.
[13] Ishwaran, H. and James, L. (2001). Gibbs sampling methods for stick-breaking priors. Journal
of the American Statistical Association, 96(453), 161–173.
[14] Ishwaran, H. and Zarepour, M. (2000). Markov chain Monte Carlo in approximate Dirichlet
and beta two-parameter process hierarchical models. Biometrika, 87(2), 371–390.
[15] Kottas, A., Duan, J., and Gelfand, A. E. (2008). Modeling disease incidence data with spatial
and spatio-temporal Dirichlet process mixtures. Biometrical Journal, 50, 29–42.
[16] Kottas,A.andKrnjajić,M.(2009).Bayesiansemiparametricmodellinginquantileregression.
Scandinavian Journal of Statistics, 36, 297–319.
[17] Krewski, D. and Zhu, Y. (1994). Applications of multinomial dose–response models in devel-
opmental toxicity risk assessment. Risk Analysis, 14, 613–627.
[18] MacEachern, S. N. (2000). Dependent Dirichlet processes. Technical report, Ohio State Uni-
versity, Department of Statistics.
[19] Nott, D. J. and Kuk, A. Y. C. (2009). Analysis of clustered binary data with unequal cluster
sizes:AsemiparametricBayesianapproach.JournalofAgricultural,Biological,andEnvironmen-
tal Statistics, 15, 101–118.
[20] Rodriguez, A. and ter Horst, E. (2008). Bayesian dynamic density estimation. Bayesian Anal-
ysis, 3, 339–366.
[21] Ryan, L. (1992). Quantitative risk assessment for developmental toxicity. Biometrics, 48,
163–174.
[22] Sethuraman, J. (1994). A constructive definition of Dirichlet priors. Statistica Sinica, 4,
639–650.
[23] Tyl, R. W., Jones-Price, C., Marr, M. C., and Kimmel, C. A. (1983). Teratologic evalua-
tion of diethylhexyl phthalate (cas no. 111-81-7). Final Study Report for NCTR/NTP con-
tract 222-80-2031(c), NITS PB85105674, National Technical Information Service, Springfield,
Virginia.
[24] Zhu, Y., Krewski, D., and Ross, W. H. (1994). Dose-response models for correlated multino-
mial data from developmental toxicity studies. Applied Statistics, 43, 583–598.

This page intentionally left blank 

Part III
Markov Chain Monte Carlo

This page intentionally left blank 

6
Markov chain Monte Carlo
methods
siddhartha chib
6.1 Introduction
T
he growth of Bayesian thinking and practice over the past two decades has been in large part
due to simulation-based computing methods, in particular, those based on Markov chain
Monte Carlo (MCMC) methods. Starting with [44], MCMC methods had long been used in
physics, for example, in computational statistical mechanics and quantum field theory to sample
the coordinates of a point in phase space. The interest in MCMC methods in statistics was sparked
by the paper of [23], where the Gibbs sampling method discussed in [24] was elaborated as a tool to
generatemarginaldistributionsofparametersofBayesianmodels.Workonthesemethodssincethe
Gelfand and Smith paper has been impressive. The theoretical underpinnings of MCMC methods
have been clarified. Novel inference approaches that are inherently tied to MCMC-based comput-
ing have emerged. Applications of these methods in demanding applications across an increasingly
diverse spectrum of scientific fields have become common.
MCMC sampling is a method for generating variates from a multivariate target probability dis-
tribution π∗, with support , by simulating a Markov chain whose stationary distribution is π∗.
Constructing such a chain is simpler, and in many instances the only viable strategy, compared to
classical Monte Carlo methods that deliver independent and identically distributed (iid) draws
from π∗. The fact that the variates from an MCMC simulation are correlated raises theoretical
and practical issues that are different from classical Monte Carlo sampling. For example, there
is the question about whether the effect of the starting value eventually wears off—this is the
question related to the ergodicity of the chain; how long the chain should be allowed to run
before one can suppose that the convergence to the invariant distribution has occurred—this
is the question of the size of the burn-in; how the numerical accuracy of sample averages
should be computed—this is the question of how the serial correlation in the chain should be
incorporated.
Taking care of the preceding issues is important for the proper implementation of MCMC
methods and can require considerable skill from the user when the model is high-dimensional
and complex, especially in relation to the available sample information for conducting inferences.
Nonetheless, provided the chain satisfies some weak theoretical conditions, the correlated sampled
variates (beyond a suitably defined burn-in) are a surrogate for the target distribution. These can be
used to estimate the probabilistic characteristics of π∗, just as in the case of iid draws. For example,
the quantiles of π∗can be estimated by the quantiles of the sampled variates. The marginal density

88
S. Chib
of any component can be estimated from the sample on that component, ignoring the sample on
the other components. The expectation under π∗of any integrable function can be estimated as a
sample-path average of that function.
The goal of this chapter is to provide a brief summary of MCMC methods, leaving further
details for later chapters and the textbooks of [9], [40], and [50]. In Section 6.2 we describe
the Metropolis–Hastings algorithm of [44] and its generalized version given by [30]. This is the
original MCMC algorithm, and still the most important. The presentation borrows heavily from
[54] and [12]. In Section 6.3 we consider the Gibbs sampling algorithm that arose from the work
of [6], [24], [53] and [23], the last, in particular, responsible for elucidating its relevance for gen-
eral Bayesian inference. Additional topics of importance, such as sampling with latent data, and
calculation of the marginal likelihood, are discussed in Section 6.4. Section 6.5 has concluding
remarks.
6.2 Metropolis–Hastings algorithm
Suppose that we are interested in sampling the target distribution π∗over a parameter vector θ ∈
 ⊆Rd. Let y denote the sample data. The general idea behind the M-H approach is to sample a
convenientMarkovtransitionkernelQ(θ, dθ′|y) = Pr(θ ∈dθ′|y, θ)andtomodifythistransition
kernelsothatthemodifiedtransitionkernelP(θ, dθ′|y)hasπ∗asitsuniquestationarydistribution.
Assume that both the target distribution and the transition kernels are absolutely continuous with
respect to a measure μ. For simplicity, one can suppose that μ is the Lebesgue measure. Letting π
and q denote the densities of π∗and Q wrt to μ, respectively, we have that
π∗(dθ′|y) = π(θ′|y)μ(dθ′)
and
Q(θ, dθ′|y) = q(θ, θ′|y)μ(dθ′)
The distribution Q (equivalently, the density q) is used to generate candidate values or proposal
values θ′. It is called the candidate generating density or proposal density.
In the M-H algorithm one constructs a Markov kernel P(θ, dθ′|y) from Q(θ, dθ′|y) with π∗as
the stationary distribution. A key idea is that of reversibility. A Markov transition kernelP(θ, dθ′|y)
is reversible for π∗if
π∗(dθ|y)P(θ, dθ′|y) = π∗(dθ′|y)P(θ′, dθ|y)
(6.1)
or, in terms of densities,
π(θ|y)p(θ, θ
′|y) = π(θ′|y)p(θ′, θ|y)
for all (θ, θ′) in the support of π∗. Reversibility is an important restriction because a reversible
Markov chain is automatically invariant. Invariance is the property that
π∗(dθ′|y) =


P(θ, dθ′|y)π∗(dθ|y)
(6.2)

Markov chain Monte Carlo methods
89
which means intuitively that if θ ∼π∗, then the variate θ′ drawn from the transition kernel
P(θ, dθ′|y) is also from π∗. To see that reversibility implies invariance, one simply integrates both
sides of (6.1) over θ. This leads to the invariance condition since

P(θ′, dθ|y) = 1.
We can now follow [12] where an argumentation was introduced for deriving P from Q. Suppose
one checks the reversibility condition for Q(θ, dθ′|y). Since this transition kernel was chosen for
itsconvenience,withoutnecessarilyanyconnectiontothetargetdistribution,itisunlikelytosatisfy
the reversibility condition. One possibility is that
π(θ|y)q(θ, θ′|y) > π(θ′|y)q(θ′, θ|y)
(6.3)
which means informally that the process moves from θ to θ′ too frequently and too rarely in the
reverse direction. We can correct this situation by reducing the flow from θ to θ′ by introducing
probabilities α(θ, θ′|y) and α(θ′, θ|y) of making the moves in either direction so that
π(θ|y)q(θ, θ′|y)α(θ, θ′|y) = π(θ′|y)q(θ′, θ|y)α(θ′, θ|y)
(6.4)
We now set α(θ′, θ|y) to be as high as possible, namely equal to one. Solving for α(θ, θ′|y) we
get that
α(θ, θ′|y) = π(θ′|y)
π(θ|y)
q(θ′, θ|y)
q(θ, θ′|y)
This quantity is less than one because we started from (6.3). The other possibility is that
π(θ|y)q(θ, θ′|y) < π(θ′|y)q(θ′, θ|y)
By the preceding argumentation it follows that α(θ, θ′|y) must now equal one. Therefore, on
putting the two cases together, we get that
α(θ, θ′|y) = min

1, π(θ′|y)
π(θ|y)
q(θ′, θ|y)
q(θ, θ′|y)

(6.5)
The M-H algorithm is now in place. To find the next iterate of the Markov chain given the current
value θ to θ′, we first propose a value θ′ from Q(θ, dθ′|y). With probability α(θ, θ′|y) we accept
the proposed value. If rejected, the next iterate is the current value.
Algorithm. Metropolis–Hastings
Initializethestartingvalueθ(0),andspecifytheburn-insizen0 andtherequiredMCMCsample
size G. Then, repeat the following two steps
• Sample θ′ from Q(θ(g), dθ′|y)
• Let the next iterate be
θ(g+1) =

θ′
with prob α(θ(g), θ′|y)
θ(g) with prob 1 −α(θ(g), θ′|y)
Return the draws θ(n0+1), . . . , θ(n0+G)

90
S. Chib
Itmaybenotedthatthecalculationofα doesnotrequirethenormingconstantofthetargetdensity.
Another point is that if q(θ, θ
′|y) = q(θ
′, θ|y), which is the case when the proposal is sampled
symmetrically around the current value, then
α(θ′, θ|y) = min

1, π(θ
′|y)
π(θ|y)

(6.6)
as in the original algorithm of Metropolis et al. [44].
6.2.1 Transition density of the M-H chain
An unusual aspect of the M-H algorithm is that it produces a chain in which values are repeated. As
a result, the transition density of the M-H chain PMH(θ, dθ′|y) has two components—one for the
move away from θ given by
α(θ, θ′|y)Q(θ, dθ′|y)
and one for the probability of staying at θ given by
r(θ|y) = 1 −

α(θ, θ′|y)Q(θ, dθ′|y)
In other words,
PMH(θ, dθ′|y) = α(θ, θ′|y)Q(θ, dθ′|y) + δθ(dθ′)r(θ|y)
where δθ(dθ′) is the Dirac measure, defined as equal to one whenever θ′ is equal to θ and

δθ(dθ′) = 1. It is easy to check that the integral of PMH(θ, dθ′|y) over all possible values of θ′
is one, as required.
6.2.2 MCMC convergence properties
We now digress by providing some theoretical properties related to MCMC simulations. This
discussion has implications for the implementation of MCMC algorithms and for the analysis of
theMCMCoutput.Webeginbyprovidingconditionsunderwhichthesimulatedsamplepathfrom
an MCMC simulation leads to simulation-consistent estimates of posterior moments, posterior
probabilities and other summaries of the target distribution. The definitions and results that follow
are drawn from [54]. [50] provide further useful discussion.
Theorem 1 Suppose that the Markov chain {θ(g)} is π∗-irreducible and has invariant distribution
π∗(dθ|y). Then π∗(dθ|y) is the unique invariant distribution. If the chain is π∗-irreducible,
aperiodic and the invariant distribution is proper, then for π∗-every θ(0) and all measurable
sets A
| Pr(θ(g) ∈A|y, θ(0)) −

A
π∗(dθ|y)| →0

Markov chain Monte Carlo methods
91
as g →∞. If the chain is ergodic (π∗-irreducible, aperiodic and Harris recurrent), then for all
functions h(θ) such that

 |h(θ)|π∗(dθ|y) < ∞and any initial distribution,
ˆhG = G−1
G

g=1
h(θ(g)) →


h(θ)π∗(dθ|y)dθ as G →∞, a.s
These results hold under relatively weak conditions (for example, as discussed in [54],
π∗-irreducibility of the chain is satisfied if the proposal density is everywhere positive in the sup-
port of the posterior density; it is Harris recurrent if it is π∗-irreducible, has π∗as it is unique
invariant distribution and the transition kernel is absolutely continuous with respect to π∗.
One gets a central limit theorem for sample path averages if we further assume that the chain is
uniformly ergodic.
Theorem 2 Suppose that the Markov chain {θ(g)} is uniformly ergodic and has invariant distri-
bution π∗(dθ|y). Then for functions h(θ) such that

 h(θ)2π∗(dθ|y) < ∞, and any initial
distribution, the sample average ˆhG satisfies the ergodic limit theorem
√
G

ˆhG −Eπ∗h
 d→N(0, σ 2
h )
where
Eπ∗h =


h(θ)π∗(dθ|y)
σ 2
h =
lim
G→∞GVar(ˆhG) = Varπ∗

h(θ(1))

+ 2
∞

g=2
Covπ∗

h(θ(1)), h(θ(g))

and the subscript π∗indicates that the expectations are calculated under the invariant distribu-
tion.
The next issue is how one should judge the success of the MCMC sampling strategy in estimating
Eπ∗h. One way is to compare Var(ˆhG) = σ 2
h /G, where σ 2
h is the variance that appears in Theorem
2, with the variance under (hypothetical) iid sampling. The square root of Var(ˆhG) is called the
numerical standard error. Under hypothetical iid sampling, Var(ˆhG) is given by G−1Varπ∗h(θ(1)).
Therefore,
τ2
h =
Var(ˆhG)
G−1Varπ∗h(θ(1))
=
⎧
⎨
⎩1 + 2
∞

g=1
ρhg
⎫
⎬
⎭
(6.7)
where ρhg is the sample autocorrelation at lag g. Because iid sampling produces an autocorrelation
time that is theoretically equal to one, τ2
h will be close to one when the autocorrelations are declin-
ingquicklywithlagg.Thus,thesizeofτ2
h revealstheinefficiencyoftheMCMCsamplingprocedure
relative to iid sampling. In practice, the calculation of τ2
h is based on a windowing or truncation
procedurethat amounts to adown-weighting of autocorrelations at larger lags [27, 28]. Themethod
of batch-means [49] is also used to estimate τ 2
h . First, we let Zg = h(θ(g)), g = 1, 2, . . . , G. Next,
we divide the data {Z1, Z2, . . . , ZG} into k non-overlapping batches of length m with means

92
S. Chib
Bi = m−1(Z(i−1)m+1 + . . . + Zim), i = 1, 2, . . . , k
where the batch size m is chosen to ensure that the first-order serial correlation of the batch means
is less than 0.05. The average of these batch means
¯B = 1
k
k

i=1
Bi
is of course ˆhG and the estimate of the sample variance of ¯B by standard calculations is
Var
¯B

=
1
k(k −1)
k

i=1
(Bi −¯B)2
In the batch means method, this variance estimate is taken to be the estimate of Var(ˆhG). [35] show
that it is a consistent estimate of σ2
h /G if k and m both increase with G.
6.2.3 Choice of proposal density
One significant practical problem in implementing the M-H algorithm is that there are many ways
of specifying Q(θ, dθ′|y). We present two that are popular in practice. In general, in each case we
try to ensure that the chain makes large moves through the support of the invariant distribution,
without staying at one place for many iterations.
Random walk proposals
In this version of the M-H algorithm, the proposal is drawn as
θ′ = θ + z
where z follows some symmetric distribution q such as the multivariate normal with mean of
zero and covariance matrix V. The covariance matrix has to be adjusted in pilot runs to reach
some desired acceptance rate. Values in the range of 20% to 60% have been shown to be optimal
under specific assumptions [50]. Because of the symmetry of the increment distribution, the M-H
probability of move is a function of the target density, and is given by the expression in (6.6). A
graphical view is shown in Figure 6.1. There has also been work on a more sophisticated version
of this algorithm known as the Langevin M-H random-walk algorithm. In this case, the proposal
value is generated with a drift term that is given by the first derivative of the log target density. In
particular,
θ′ = θ + c
2
∂log π(θ|y)
∂θ
+ √cz
where z is distributed as N(0, I). The tuning and efficiency of this algorithm is discussed in [51].
AlthoughtherandomwalkM-Halgorithmispopularinapplications,itisnotalwayseasytotune,
especially when the dimension of θ is large. In such cases, it can be difficult to (simultaneously)
generate large enough moves and get reasonable acceptance rates.

Markov chain Monte Carlo methods
93
π(θ|y)
q(θ, θ†|y)
current
θ(g)
θ(g)
θ†
proposal
Figure 6.1 Random-walk M-H. The two points that determine the probability of move.
Independent proposals
Another possibility is to set q(θ, θ′|y) = q(θ′|y), an independence M-H chain in the terminology of
[54]. In this case,
α(θ, θ′|y) = min

1, w(θ′|y)
w(θ|y)

where
w(θ|y) = π(θ|y)
q(θ|y)
is the ratio of the target and proposal densities. [42] showed that the resulting MCMC chain is
uniformly ergodic if w(θ|y) is uniformly bounded.
It can easily be seen from the latter expression that if the target density can be expressed as
π(θ|y) = w(θ|y)p(θ|y), where the first factor on the right is uniformly bounded and the second
factor is a density that can be directly sampled, then one can just let q(θ|y) = p(θ|y) to produce
a uniformly ergodic chain. Another way to implement independence chains is described by [11].
Under regularity conditions, the posterior density will be roughly quadratic around the posterior
modal value. Then, a proposal density that is tailored to the target can be constructed by letting
q(θ|y) = p(θ|m, V), where p is some multivariate density and the parameters of the proposal
density are
m = max
θ
log π(θ|y)
and
V = c

−∂2 log π(θ|y)
∂θ∂θ′
−1
θ= ˆθ
(6.8)
where c is a tuning parameter that (along with V) may be adjusted so that the tails of the proposal
density are thicker than those of the target.

94
S. Chib
6.2.4 Multiple-block sampling
In applications it is not usually possible to sample θ simultaneously in one block as in the basic
M-H algorithm just presented. For such cases, [30] suggested revising the components of θ one
at a time. Each of these components can then be sampled by univariate M-H steps. This strategy
can be generalized so that instead of revising one component at a time, the parameters are grouped
more coarsely and revised in blocks. To explain this idea, suppose that θ is grouped as (θ1, θ2),
with θk ∈k ⊆ℜdk. The extension to more than two blocks is straightforward. Grouping in this
way is also the hallmark of the Gibbs sampling algorithm. Often, this grouping is suggested by the
model structure itself. For example, in a regression model, one block may consist of the regression
coefficients and the other block of the error variance. The theoretical properties of this algorithm
(in particular Harris-recurrence) is examined in [52].
Now let
Q1(θ1, dθ′
1|y, θ2) ; Q2(θ2, dθ′
2|y, θ1)
denote the proposal distributions, one for each block θk. There are many ways to specify these
proposal distributions which can depend on the current value of the remaining block and on the
data. For example, the random-walk and tailored approaches can be applied. As in the single block
case, the proposed values are not necessarily accepted. The probabilities of acceptance are now
defined as
α1(θ1, θ′
1|y, θ2) = min

1, π1|2(θ′
1| y,θ2)q1(θ′
1, θ1|y, θ2)
π1|2(θ1|y,θ2)q1( θ1, θ′
1|y, θ2)

(6.9)
and
α2(θ2, θ′
2|y, θ1) = min

1, π2|1(θ′
2| y,θ1)q2(θ′
2, θ2|y, θ1)
π2|1(θ2|y, θ1)q2(θ2, θ′
2|y, θ1)

(6.10)
where
π1|2(θ1|y,θ2) and π2|1(θ2|y,θ1)
are called the full conditional densities. By Bayes’ theorem, these are proportional to the joint poste-
rior density. For instance,
π1|2(θ1|y,θ2) ∝π(θ1, θ2|y) .
Accordingly, the probabilities of move in (6.9) and (6.10) can be equivalently expressed in terms
of the kernel of the joint posterior density π(θ1, θ2|y) because the normalizing constant of
the full conditional density (the norming constant in the latter expression) cancels in forming
the ratio.
Given these ingredients, one sweep of the multiple-block algorithm is completed by updating
each block, say sequentially in fixed order, where the proposed value for each block is accepted or
rejected according to the M-H probabilities given above.

Markov chain Monte Carlo methods
95
Algorithm. Multiple-block M-H
Step 1 Given θ(g)
2
at the gth iteration, propose
θ′
1 ∼q1(θ(g)
1 , θ′
1|y, θ(g)
2 )
and move with probability
α1(θ(g)
1 , θ′
1|y, θ(g)
2 )
(otherwise stay at the current value) to produce the value θ(g+1)
1
Step 2 Given this updated value of the first block, propose
θ′
2 ∼q2(θ(g)
2 , θ′
2|y, θ(g+1)
1
)
and move with probability
α2(θ(g)
2 , θ′
2|y, θ(g+1)
1
)
(otherwise stay at the current value) to produce the value θ(g+1)
2
An illustrative schematic of these steps is given in Figure 6.2.
Given the sequential sampling of blocks, it is easy to see that the transition kernel of this Markov
chain is given by the product of the two transition kernels
P(θ, dθ′|y) = P1(θ1, dθ′
1|y, θ2)P2(θ2, dθ′
2|y, θ′
1)
(6.11)
Thistransitionkernelisobviouslynotreversiblebecausesamplinginthereverseorderneveroccurs.
It is, however, invariant. To show this, we make use of the facts that each kernel satisfies invariance,
conditioned on the value of the other block. In particular,
π∗
1|2(dθ′
1|y, θ2) =

P1(θ1, dθ′
1|y, θ2)π∗
1|2(dθ1|y, θ2)
current
q1(•|y, θ2)
θ1
(g)
θ1
(g)
θ1
†
θ1
†
θ2
(g)
θ2
(g)
θ2
†
proposal
π(θ1, θ2|y)
q2(•|y, θ1)
π(θ1, θ2|y)
current
θ1
(g+1)
proposal
Figure 6.2 Multiple-block M-H: Left panel has the target and proposal densities of the first block
and the four points that determine the probability of move; right panel has the same information for
the second block.

96
S. Chib
and
π∗
2|1(dθ′
2|y, θ
′
1) =

P2(θ2, dθ′
2|y, θ′
1)π∗
2|1(dθ2|y, θ′
1)
Following [12] one can now establish that the product kernel is invariant:
 
P1(θ1, dθ′
1|y, θ2)P2(θ2, dθ′
2|y, θ′
1)π∗(dθ1, dθ2|y)
=

P2(θ2, dθ′
2|y, θ′
1)

P1(θ1, dθ′
1|y, θ2)π∗
1|2(dθ1|y, θ2)

π∗
2 (dθ2|y)
=

P2(θ2, dθ′
2|y, θ′
1)π∗
1|2(dθ′
1|y, θ2)π∗
2 (dθ2|y)
=

P2(θ2, dθ′
2|y, θ′
1)
π∗
1 (dθ′
1|y)π∗
2|1(dθ2|y, θ
′
1)π∗
1 (dψ′
1)
π∗
2 (dθ′
2|y)
π∗
2 (dθ′
2|y)
= π∗
1 (dθ′
1|y)

P2(θ2, dθ′
2|y, θ′
1)π∗
2|1(dθ2|y, θ′
1)
= π∗
1 (dθ′
1|y) π∗
2|1(dθ′
2|y, θ′
1)
= π∗(dθ′
1, dθ′
2|y),
where the third line follows from the invariance of P1, the fourth from the Bayes theorem, the sixth
from the invariance of P2, and the last from the law of total probability. The significance of this
result is that we can take draws in succession from each of the kernels, instead of having to run each
to convergence for every value of the conditioning variable.
6.3 Gibbs sampler
The Gibbs sampler is closely related to the multiple-block M-H algorithm. Just as in that algorithm,
the parameters are sampled in blocks. The difference is that one uses the full conditional distribu-
tion of each block to update the blocks, rather than a general proposal distribution. As was orginally
advertisedby[23],thefullconditionaldistributionsinmanyBayesianmodelsareeasilyderived,and
can be sampled directly. This ease of implementation led to numerous applications of the Gibbs
sampler following the publication of that paper.
Formally, the transition kernel of the Markov chain is constructed from the set of full conditional
distributions. For instance, suppose as above that θ is grouped as (θ1, θ2). Let
π∗
1|2(dθ1|θ2, y) and π∗
2|1(dθ2|θ1, y)
denote the full conditional distributions. Suppose that these distributions can be sampled directly.
Sometimes,thestrategicinvolvementoflatentvariables canleadtoatractablesetoffullconditional
distributions, as discussed in the next section. Then, in the Gibbs algorithm, one samples the
first distribution to produce a new value of θ1. Given this new value, one then samples the second
distribution to produce a new value of θ2, and the process is repeated. The generalization to more
blocks is immediate.

Markov chain Monte Carlo methods
97
Algorithm. Gibbs sampling
In each iteration g, g = 1, . . . , n0 + G,
• Generate θ(g+1)
1
from π(θ1|y, θ(g)
2 )π1|2
• Generate θ(g+1)
2
from π(θ2|y, θ(g+1)
1
)π2|1
Return the values {θ(n0+1), θ(n0+2), ..., θ(n0+G)} .
Interestingly, one can show that the Gibbs algorithm is a particular instance of the multiple-block
M-Halgorithm.ThisrequiresshowingthattheM-Hprobabilityofacceptingablockproposedfrom
the full conditional distribution is one. In the notation of the multiple-block M-H algorithm, the
proposal densities in the Gibbs sampler are
q1(θ1, θ′
1|y, θ2) = π1|2(θ′
1|y, θ2) ,
and
q2(θ2, θ′
2|y, θ1) = π2|1(θ′
2|y, θ1) ,
Then, for the first block, from (6.9) we get
α1(θ1, θ′
1|y, θ2) = min

1, π1|2(θ′
1| y,θ2)q1(θ′
1, θ1|y, θ2)
π1|2(θ1|y,θ2)q1(θ1, θ′
1|y, θ2)

= min

1, π1|2(θ′
1| y,θ2)π1|2(θ1|y,θ2)
π1|2(θ1|y,θ2)π1|2(θ′
1|y, θ2)

= 1
Thus, a variate proposed from the full conditional density is accepted without any rejection. With
change of notation this is, of course, true for the second block as well. Thus, the updates from
the multiple-block M-H algorithm, with proposals drawn from the full conditional distributions,
correspond to those in the Gibbs sampling algorithm.
For the Gibbs sampler, the transition kernel is given by the product of the full conditional distri-
butions:
P(θ, dθ′|y) = π∗
1|2(dθ′
1|θ2, y)π∗
2|1(dθ′
2|θ′
1, y)
Invariance of this kernel can be established directly. One can also establish this fact indirectly by
appealing to the invariance of the multiple-block M-H algorithm. [32] discuss the convergence
properties of the Gibbs sampler that are independent of the selected version of the full conditional
distributions. A key requirement is that the support of the target distribution be connected.
Metropolis-within-Gibbs
In some problems, not all the full conditional distributions are tractable. In that case, the blocks
with the tractable full conditional distributions can be sampled directly and the blocks with the
intractable full conditional distributions, by an M-H step. Such an algorithm is sometimes called
the Metropolis-within-Gibbs algorithm.

98
S. Chib
6.4 Additional topics
6.4.1 Sampling with latent variables
In sampling π∗(dθ|y) it is sometimes helpful to modify the target distribution by introducing
latentvariablesorauxiliaryvariablesintothesampling.Toexplainthisidea,supposethat zarelatent
variables such that
π∗(dθ|y) =

z
π∗(dθ, dz|y)
(6.12)
where π∗(dθ, dz|y) is the modified target distribution. Then, in many cases, the conditional distri-
bution of θ (or sub components of θ) given z are easy to derive. One can now sample the modified
target distribution by (say) a multiple-block M-H algorithm to produce the sample

θ(n0+1), z(n0+1)
, . . . ,

θ(n0+G), z(n0+G)
∼π∗(dθ, dz|y)
By the usual Monte Carlo theory, the sampled draws on θ are from the distribution π∗(dθ, dz|y)
marginalized over z. But since the condition (6.12) was assumed to hold, these draws are, therefore,
from π∗(dθ|y), the desired target of interest.
Sampling of θ in this way is a powerful idea. [53] largely introduced this approach but in the con-
textnotofgenerallatentdatabutinthesettingofmissingdataproblemsandlabelledtheapproachas
data augmentation. In an early paper, [1], in the context of binary, ordinal and categorical outcomes,
show vividly the usefulness of latent variables for Bayesian inference.
Example 6.1 (Binary Categorical Data) For binary (1, 0) outcomes y, where Pr(y = 1|β) =
(x′β)andisthedistributionfunctionofthestandardnormal,theposteriordensityunder(say)
a N(β|β0, B0) prior density and n independent observations y = (y1, y2, . . . , yn) is
π

β|y

∝N(β|β0, B0)
n

i=
(x′β)yi 
1 −(x′β)
(1−yi)
which cannot be directly sampled. However, if one introduces latent data zi|β ∼N(x′
iβ, 1) such
that yi = I[zi > 0] , i ≤n, then the posterior density π

β, z|y

as shown in [1] is
π

β, z|y

∝π

β, z, y

∝N(β|β0, B0)
n

i=
N(zi|x′
iβ, 1) Pr

yi|zi, β

∝N(β|β0, B0)
n

i=
N(zi|x′
iβ, 1)

I(zi > 0)yi + I(zi < 0)1−yi

wherethetermincurlybracesisPr

yi|zi, β

.Itiseasilycheckedthattheintegralofthelatterdensity
over {zi} leads to the correct target density. Thus, this is a valid modified target density. This target
gives the right basis for developing an MCMC scheme because the full conditional distributions

Markov chain Monte Carlo methods
99
β|y, {zi} ;
{zi}|y, β
are both tractable. In particular, the distribution of β conditioned on the latent data becomes inde-
pendent of the observed data and has the same form as in the Gaussian linear regression model with
the response data given by {zi}. It is multivariate normal with mean ˆβ = B(B−1
0 β0 + n
i=1 xizi)
and variance matrix B = (B−1
0
+ n
i=1 xix′
i)−1. Next, the distribution of the latent data condi-
tioned on the data and the parameters factor into a set of n independent truncated normal distribu-
tions, with each depending on the data through yi
{zi}|y, β ∝
n

i=1
N(zi|x′
iβ, 1)

I(zi > 0)yi + I(zi < 0)1−yi

,
which are also easily sampled.
In some recent work, the idea of combining data augmentation with an expansion of the parameter
space has been explored. [41], [42] and [31] provide theory and some applications. Latent variable
augmentation is also central to the slice sampling method, for example see [18] and [45].
6.4.2 Choice of blocking
A crucial practical problem in both the multiple-block and Gibbs sampling algorithms is the com-
position of the blocks. As a general rule, sets of parameters that are highly correlated should be
combined and sampled together. Otherwise, it becomes difficult to develop proposal densities that
lead to large moves through the support of the target distribution. Beyond this advice, little in
general can be said about how parameters should be grouped in practice. In some models it may not
even be clear a priori which parameters are correlated. To deal with these difficulties, [14] propose
a version of the multiple-block M-H algorithm in which the number of blocks and the components
of the blocks are randomized in each MCMC iteration. The proposal distribution of each block is
found by tailoring.
In designing a MCMC simulation one should be cognizant of opportunities for grouping param-
eters coarsely. For example, it is possible in some cases to reduce the number of blocks by the
method of composition. For example, suppose that θ1, θ2 and θ3 denote three blocks and that
the distribution θ1|y, θ3 is tractable (i.e. can be sampled directly). Then, the blocks (θ1, θ2) can
be collapsed by first sampling θ1 from θ1|y, θ3 followed by θ2 from θ2|y, θ1, θ3. This amounts to
a two-block MCMC algorithm. In addition, if it is possible to sample (θ1, θ2) marginalized over θ3
then the number of blocks is reduced to one.
6.4.3 Estimation of density ordinates
If the full conditional densities are available, then the MCMC output can be used to estimate the
posterior marginal density functions [23, 53]. By definition, the marginal density of a particular
block θk at the point θ∗
k is
π(θ∗
k|y) =

π(θ∗
k|y, θ−k) π(θ−k|y)dθ−k
where θ−k is θ excluding θk. Provided the normalizing constant of π(θ∗
k|y, θ−k) is known, the
marginal density can be estimated by the sample average

100
S. Chib
ˆπ(θ∗
k|y) = G−1
G

g=1
π(θ∗
k|y, θ(g)
−k)
[23] refer to this as the Rao–Blackwell method because of the connections with the Rao–Blackwell
theorem in classical statistics. [10] extends this method for estimating the posterior density of θk
conditioned on one or more of the remaining blocks.
6.4.4 Comparison of models
In Bayesian statistics one is interested not just in summarizing the posterior distribution but also
in comparing competing models, each defined by its own sampling distribution and prior [7].
MCMC methods have proved enormously useful for this purpose. In one approach, models and
parameters are sampled jointly. The two leading MCMC methods in this category are the prod-
uct space method [8] and the reversible jump method of [29]. Both methods have been widely
applied.Recentapplicationsanddevelopmentsofthesemodelspacemethodsinclude[33],[19]and
[34]. Specific versions of model space methods are particularly useful for the problem of variable
selection [16, 25, 26, 35]. Another set of methods deals with the direct calculation of the model
marginal likelihood. In this category, the method of [10] is both general and easy to implement.
It provides an estimate of the marginal likelihood based on the output of the Gibbs sampling
algorithm along with an estimate of the numerical standard error. [13] extend the framework for
output from Metropolis–Hastings chains.
6.4.5 Output analysis
In implementing an MCMC method, it is important to assess the performance of the sampling
algorithmtodeterminetherateofmixingandthesizeoftheburn-in.Alargeliteratureisavailableon
this topic, for example, [17], [36], [22], [50] and [20]. In some special cases, such as the hierarchical
normal linear model, theoretical bounds on the burn-in time have been derived [37].
In practice, convergence (or more properly, lack of convergence) is assessed by empirical meth-
ods based on the sampled output, as for example those contained in the R CODA package which
has the methods of Gelman and Rubin, Yu and Mykland, Raftery and Lewis and Geweke. One can
also monitor the autocorrelation plots and the inefficiency factors. Slowly decaying correlations
indicate problems with the mixing of the chain. It is also useful in connection with M-H Markov
chains to monitor the acceptance rate of the proposal values with low rates implying ‘stickiness’ in
the sampled values and thus a slower approach to the invariant distribution.
6.5 Concluding remarks
Work on MCMC methods continues at a rapid pace. Interesting recent developments include the
particle filtering based sequential MCMC methods [2, 15, 21, 47, 48], primarily for the estimation
of nonlinear state space models, and adaptive MCMC methods [1, 2, 5, 38, 45].
Over the last 20 years, MCMC methods have played a central role in the growth of Bayesian
thinking. These methods have formed the basis for software programs such as WINBUGS and
the many Bayesian packages in R. As a result, Bayesian applications across the sciences and social
sciences have become common and the trends continue unabated.

Markov chain Monte Carlo methods
101
References
[1] Albert, J. H. and Chib, S. (1993). Bayesian analysis of binary and polychotomous response
data, Journal of the American Statistical Association, 88, 669–679.
[2] Andrieu, C., Doucet, A. and Holenstein, R. (2010). Particle Markov chain Monte Carlo meth-
ods, Journal of the Royal Statistical Society Series B – Statistical Methodology, 72, 269–342.
[3] Andrieu, C. and Moulines, E. (2006). On the ergodicity properties of some adaptive MCMC
algorithms, Annals of Applied Probability, 16, 1462–1505.
[4] Andrieu, C. and Thoms, J. (2008). A tutorial on adaptive MCMC, Statistics and Computing,
18, 343–373.
[5] Atchade, Y. F. and Rosenthal, J. S. (2005). On Adaptive Markov chain Monte Carlo Algo-
rithms, Bernoulli, 11, 815–828.
[6] Besag, J. (1974). Spatial Interaction and Statistical-analysis of Lattice Systems, Journal of the
Royal Statistical Society Series B – Methodological, 36, 192–236.
[7] Carlin, B. and Louis, T. (2008). Bayes and Empirical Bayes Methods for Data Analysis, Boca
Raton: Chapman & Hall, 3rd ed.
[8] Carlin, B. P. and Chib, S. (1995). Bayesian Model Choice via Markov Chain Monte Carlo
Methods, Journal of the Royal Statistical Society, Series B, 57, 473–484.
[9] Chen, M.-H., Shao, Q.-M. and Ibrahim, J. G. (2000). Monte Carlo Methods in Bayesian Com-
putation (Springer Series in Statistics), Springer.
[10] Chib, S. (1995). Marginal likelihood from the Gibbs output, Journal of the American Statistical
Association, 90, 1313–1321.
[11] Chib, S. and Greenberg, E. (1994). Bayes Inference in Regression Models with ARMA (p,q)
Errors, Journal of Econometrics, 64, 183–206.
[12]
(1995). Understanding the Metropolis–Hastings algorithm, The American Statistician,
49, 327–335.
[13] Chib, S. and Jeliazkov, I. (2001). Marginal likelihood from the Metropolis–Hastings output,
Journal of the American Statistical Association, 96, 270–281.
[14] Chib,S.andRamamurthy,S.(2010).TailoredrandomizedblockMCMCmethodswithappli-
cation to DSGE models, Journal of Econometrics, 155, 19–38.
[15] Chopin, N. (2004). Central limit theorem for sequential Monte Carlo methods and its appli-
cation to Bayesian inference, Annals of Statistics, 32, 2385–2411.
[16] Cottet, R., Kohn, R. J. and Nott, D. J. (2008). Variable Selection and Model Averaging in
Semiparametric Overdispersed Generalized Linear Models, Journal of the American Statistical
Association, 103, 661–671.
[17] Cowles, M. K. and Rosenthal, J. S. (1998). A Simulation Approach to Convergence Rates for
Markov chain Monte Carlo Algorithms, Statistics and Computing, 8, 115–124.
[18] Damien, P., Wakefield, J. and Walker, S. (1999). Gibbs Sampling for Bayesian Non-conjugate
and Hierarchical Models by Using Auxiliary Variables, Journal of the Royal Statistical Society
Series B – Statistical Methodology, 61, 331–344.
[19] Dellaportas, P., Friel, N. and Roberts, G. O. (2006). Bayesian Model Selection for Partially
Observed Diffusion Models, Biometrika, 93, 809–825.
[20] Fan,Y.,Brooks,S.P.andGelman,A.(2006).OutputAssessmentforMonteCarloSimulations
via the Score Statistic, Journal of Computational and Graphical Statistics, 15, 178–206.
[21] Flury, T. and Shephard, N. (2011). Bayesian Inference Based Only On Simulated Like-
lihood: Particle Filter Analysis of Dynamic Economic Models, Econometric Theory, 27,
933–956.
[22] Gamerman, D. and Lopes, H. F. (2006). Markov Chain Monte Carlo: Stochastic Simulation for
Bayesian Inference, Boca Raton: Chapman and Hall/CRC, 2nd ed.

102
S. Chib
[23] Gelfand, A. E. and Smith, A. F. (1990). Sampling-Based Approaches to Calculating Marginal
Densities, Journal of the American Statistical Association, 85, 398–409.
[24] Geman,S.andGeman,D.(1984).StochasticRelaxation,GibbsDistributionandtheBayesian
Restoration of Images, IEEE Transactions, PAMI, 6, 721–741.
[25] George, E. I. and McCulloch, R. E. (1993). Variable selection via Gibbs sampling, Journal of
the American Statistical Association, 88, 881–889.
[26]
(1997). Approaches for Bayesian variable selection, Statistica Sinica, 7, 339–373.
[27] Geweke, J. (1992). Efficient simulation from the multivariate Normal and Student-t distribu-
tions subject to linear constraints, Computing Science and Statistics: Proceedings of the Twenty-
third Symposium, 571–578.
[28] Geyer, C. J. (1992). Practical Markov chain Monte Carlo, Statistical Science, 4, 473–483.
[29] Green, P. J. (1995). Reversible Jump Markov chain Monte Carlo Computation and Bayesian
Model Determination, Biometrika, 82, 711–732.
[30] Hastings, W. K. (1970). Monte-Carlo Sampling Methods Using Markov chains and their
Applications, Biometrika, 57, 97–109.
[31] Hobert, J. P. and Marchev, D. (2008). A theoretical comparison of the data augmentation,
marginal augmentation and PX-DA algorithms, Annals of Statistics, 36, 532–554.
[32] Hobert, J. P., Robert, C. P. and Goutis, C. (1997). Connectedness conditions for the conver-
gence of the Gibbs sampler, Statistics & Probability Letters, 33, 235–240.
[33] Holmes, C. C. and Mallick, B. K. (2003). Generalized Nonlinear Modeling with Multivariate
Free-knot Regression Splines, Journal of the American Statistical Association, 98, 352–368.
[34] Jasra, A., Stephens, D. A. and Holmes, C. C. (2007). Population-based Reversible Jump
Markov chain Monte Carlo, Biometrika, 94, 787–807.
[35] Jones, G. L., Haran, M., Caffo, B. S. and Neath, R. (2006). Fixed-width Output Analysis for
Markov chain Monte Carlo, Journal of the American Statistical Association, 101, 1537–1547.
[36] Jones, G. L. and Hobert, J. P. (2001). Honest exploration of intractable probability distribu-
tions via Markov chain Monte Carlo, Statistical Science, 16, 312–334.
[37]
(2004). Sufficient burn-in for Gibbs samplers for a hierarchical random effects model,
Annals of Statistics, 32, 784–817.
[38] Keith, J. M., Kroese, D. P. and Sofronov, G. Y. (2008). Adaptive independence samplers,
Statistics and Computing, 18, 409–420.
[39] Lamnisos, D., Griffin, J. E. and Steel, M. F. J. (2009). Transdimensional Sampling Algorithms
for Bayesian Variable Selection in Classification Problems With Many More Variables Than
Observations RID B-9845-2008, Journal of Computational and Graphical Statistics, 18, 592–612.
[40] Liu, J. S. (2001). Monte Carlo Strategies in Scientific Computing, New York: Springer.
[41] Liu, J. S. and Wu, Y. N. (1999). Parameter expansion for data augmentation, Journal of the
American Statistical Association, 94, 1264–1274.
[42] Meng, X. L. and Van Dyk, D. A. (1999). Seeking efficient data augmentation schemes via
conditional and marginal augmentation, Biometrika, 86, 301–320.
[43] Mengersen, K. L. and Tweedie, R. L. (1996). Rates of convergence of the Hastings and
Metropolis algorithms, Annals of Statistics, 24, 101–121.
[44] Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H. and Teller, E. (1953).
Equations of State Calculations by Fast Computing Machines, Journal of Chemical Physics,
21, 1087–1092.
[45] Mira, A. and Tierney, L. (2002). Efficiency and Convergence Properties of Slice Samplers,
Scandinavian Journal of Statistics, 29, 1–12.
[46] Nott, D. J. and Kohn, R. (2005). Adaptive Sampling for Bayesian Variable Selection,
Biometrika, 92, 747–763.
[47] Pitt, M. K. and Shephard, N. (1999). Filtering via simulation: Auxiliary particle filters, Journal
of the American Statistical Association, 94, 590–599.

Markov chain Monte Carlo methods
103
[48] Polson, N. G., Stroud, J. R. and Muller, P. (2008). Practical filtering with sequential parameter
learning, Journal of the Royal Statistical Society Series B – Statistical Methodology, 70, 413–428.
[49] Ripley, B. D. (1987). Stochastic Simulation, New York: Wiley.
[50] Robert, C. P. and Casella, G. (2004). Monte Carlo Statistical Methods, New York: Springer.
[51] Roberts, G. O. and Rosenthal, J. S. (2001). Optimal scaling for various Metropolis–Hastings
algorithms, Statistical Science, 16, 351–367.
[52]
(2006).HarrisRecurrenceofMetropolis-within-GibbsandTrans-dimensionalMarkov
Chains, Annals of Applied Probability, 16, 2123–2139.
[53] Tanner, M. A. and Wong, W. H. (1987). The Calculation of Posterior Distributions by Data
Augmentation (with discussion), Journal of the American Statistical Association, 82, 528–550.
[54] Tierney, L. (1994). Markov Chains for Exploring Posterior Distributions (with discussion),
The Annals of Statistics, 21, 1701–1762.

7
Advances in Markov chain
Monte Carlo
jim e. griffin and david a. stephens
7.1 Introduction
7.1.1 Markov chain Monte Carlo: 1985–1995
T
he early work on Markov chain Monte Carlo (MCMC) throughout the 1980s, culminating
with the publication of [12], led to the widespread use of Bayesian statistical inference in a
broad range of application fields. The first half of the next decade saw many specific algorithmic
developments, including the extension of the simple Gibbs sampling approaches of Gelfand and
Smith to the use of the more general Metropolis–Hastings (MH) algorithm, and hybrid (mixture
kernel) approaches in applications (see [55] for a summary of key theoretical concepts). There was
also a huge growth in applications of Bayesian inference to challenging statistical problems that had
previously proved intractable due to limitations of numerical approaches to integration.
By the mid 1990s, much was known about how MCMC should be implemented for optimal
performance in standard statistical problems; see, for example, [20] for a summary of the state of
knowledge at that time. Interest turned to addressing more complicated problems, such as model
selection, and mixture problems, and a more in-depth theoretical study of classical algorithms such
as the Metropolis algorithm. Model selection remains to this day an incompletely resolved issue
in Bayesian inference, but in the mid 1990s specific focus fell on problems where a sequence of
modelswasindexedbyadiscreterandomvariable,wheremodelscorrespondingtodifferentindices
had different dimensions, mixture models with different numbers of components being a canonical
example. Research into the Metropolis algorithm led to one of the most familiar results of MCMC
folklore, The Goldilocks Principle, which relates to the optimal choice of the scale of Metropolis
proposals [49]. This result, that suggests an optimal Metropolis acceptance rate of 0.234, continues
to inform MCMC practitioners today, alerting them to the fact that they should focus on tuning
their algorithm so that the acceptance rate is neither too high nor too low. It appeals to the logic that
the MCMC kernels might be chosen in an adaptive fashion, in light of the observed performance
of the algorithm. However, the result of [49] does not strictly relate to the construction of a truly
adaptive algorithm.
In this chapter, we trace some of the key developments that further developed the underpinning
theory, and potential applications, of MCMC since the mid 1990s. In particular, we review three
main developments, namely reversible jump or transdimensional MCMC, population MCMC
methods, and adaptive MCMC.

Advances in Markov chain Monte Carlo
105
7.1.2 Notation
Following the notation introduced in the previous chapter, we initially consider the target distribu-
tion π∗over a parameter vector θ ∈ ⊆Rd derived for observed data y. Denote generic Markov
transition kernel Q(θ, dθ′|y) = Pr(θ ∈dθ′|y, θ), and modified transition kernel P(θ, dθ′|y)
whichhasπ∗asitsuniquestationarydistribution.Letπ andqdenotethedensitiesofπ∗andQ wrt
theLebesguemeasure.IntheMHalgorithmletP(θ, dθ′|y)denotethereversibleMarkovtransition
kernel derived from Q(θ, dθ′|y) with π∗as the stationary distribution. By the usual arguments, the
acceptance probability for values generated from q is
α(θ, θ′|y) = min

1, π(θ′|y)
π(θ|y)
q(θ′, θ|y)
q(θ, θ′|y)

.
UndermildconditionsonQ(., .|y),variatesgeneratedfromthisMarkovchainwithtransitionkernel
P(., .|y) form a dependent sample from π, and the ergodicity of the chain permits Monte Carlo
estimation of functionals of π.
7.2 Reversible jump MCMC
After the foundational work on MCMC theory and applications, the next principal advance in
MCMC theory was achieved by [26]. Around this time, interest in model selection via MCMC,
and Markov chain methods operating on more complex parameter spaces, had become a major
researchfield,andseveralauthorshadmadesignificantcontributionsinthisdirection. Inparticular,
the work of [27], [8] and [47] are notable. In [27] a particular continuous time Markov process, a
Langevinjumpdiffusion,isconstructedtosampletheposteriordistributioninacomplexgeometric
and image analysis setting; a similar approach is used in [47], again in an image analysis setting.
The use of a continuous time (birth–death) Markov process was, in itself, a novel contribution
to Bayesian computation, although apart from a few specific areas of application (see for example
[18, 54]), continuous time algorithms have remained under-utilized. In [8] a different approach
is adopted; a more standard discrete time MCMC algorithm is constructed on an extended state
space that encompasses all models considered simultaneously, with all parameters in all models
being updated at each iteration, with model selection achieved during the MCMC run by sampling
a discrete model index.
In the contributed Discussion of [27], Green laid out the basic construction that later formed
the content of his paper [26]. He pointed out that whereas the Gibbs sampler construction utilized
by [27] might only rarely be of use, the Metropolis–Hastings algorithm, they also suggested, could
provideageneralmechanismforjumpingbetweensubspacesofdifferentdimension.Thesuggested
general algorithm retained the reversibility and detailed balance properties of the usual MH algo-
rithm, but required certain ‘dimension-matching’ terms to account for the differences in dimension
of different subspaces.
We now study the reversible jump MCMC algorithm of [26]. Note that a formulation of MH
algorithms on general state spaces was provided by [56], which includes Green’s formulation as a
special case.
7.2.1 Reversible jump MCMC: formulation
We consider a countable collection of Bayesian models, {Mk, k = 1, 2, . . .}, where model Mk is
parameterized via parameter θk with parameter space k ⊂Rdk. We consider both the cases of

106
J. E. Griffin and D. A. Stephens
a finite collection, where we present a series of possibly non-nested models and search for the most
appropriateexplanationofthedata,andalsocasesofaninfinitecollection;thelattersituationmight
arise if the index k corresponds to a non-negative integer-valued parameter. For data y, the full
posterior can be written
π(Mk, θk|y) =
f(y|θk, Mk)p(θk|Mk)p(Mk)

j

f(y|θj, Mj)p(θj|Mj)dθj

p(Mj).
(7.1)
Our objective is to construct a Metropolis–Hastings Markov chain that is aperiodic and irreducible
on the union parameter space  = ∪kk. As usual, this requires the specification of a proposal
transition density, q(., .|y), but, in contrast to the usual fixed-dimension case, we face the difficulty
that the arguments of q are potentially of different dimensions, rendering the reversibility require-
ment difficult to meet. We now discuss the usual reversible jump solution.
At a specific iteration, suppose that the chain is in model M with parameter value θ having
dimensiond,andtheproposalistomovetomodelM′ withparametervalueθ′ havingdimensiond′.
We envisage this move as first selecting a move between models, M −→M′, and then the proposal
of a θ′ possibly dependent on the current θ. Suppose that, when in model M, the move between the
two models is selected with probability r(M, M′). To retain the possibility of a reversible proposal
mechanism, with equally dimensioned arguments to q(., .|y), so consider the introduction of col-
lections of latent variables u and v of dimension du and dv respectively, so that d + du = d′ + dv.
Theproposaldensityqisthenconsideredfortheextendedparametervectors(θ, u)and(θ′, v)such
that q((θ, u), (θ′, v)|y) is reversible; this is most easily constructed using a bijective differentiable
mapping, that is
(θ′, v) = g(θ, u)
⇐⇒
(θ, u) = h(θ′, v).
Note that standard fixed-dimension moves also fall under this general proposal procedure; for
example, for the ordinary Metropolis move, we might set
θ′ = θ + u
u ∼N(0, )
and for Metropolis–Hastings moves, we typically use a conditional generation q(θ′|θ, y) taking the
conditioning variable as a constant parameter in a suitably chosen density; the stochastic elements
u in the MH move can be thought of as the Uniform(0, 1) variates used to perform basic random
number generation from this conditional density.
To establish the acceptance probability for the reversible jump move, Green considers a ‘hybrid’
MH algorithm comprising a mixture of move types, with move indexed by m with transition
proposal Qm selected with probability rm, some of which may be trans-dimensional, but each of
which retains the detailed balance property. If ψ and ψ′ represent the latent-augmented parameter
vectors, and let the augmented posterior density be denoted
˜πm(ψ|y) = ˜πm(M, θ, u|y) = π(M, θ|y)pu(u).
Let αm(ψ, ψ′|y) denote the acceptance probability for move type m, so that for arbitrary
sets A and B

A
˜π∗
m(dψ|y)

B
αm(ψ, ψ′|y)Qm(ψ, dψ′|y) =

B
˜π∗
m(dψ′|y)

A
αm(ψ′, ψ|y)Qm(ψ′, dψ|y)

Advances in Markov chain Monte Carlo
107
which implies as usual that
αm(ψ, ψ′|y) ˜πm(ψ|y)qm(ψ, ψ′|y) = αm(ψ′, ψ|y) ˜πm(ψ′|y)qm(ψ′, ψ|y)
or, in Green’s notation
αm(ψ, ψ′|y)fm(ψ, ψ′|y) = αm(ψ′, ψ|y)fm(ψ′, ψ|y)
where fm is defined with respect to a common, symmetric measure on the product space. Consider
first the forward move; in this case fm(ψ, ψ′|y) is given by
fm(ψ, ψ′|y) = ˜πm(ψ|y)qm(ψ, ψ′|y) = π(M, θ|y)pu(u)−→r m
say. For the reverse move, to preserve symmetry, we must set
fm(ψ′, ψ|y) = ˜πm(ψ′|y)qm(ψ′, ψ|y) = π(M′, θ′|y)pv(v)
&&&&
∂(θ′, v)
∂(θ, u)
&&&& ←−r m
where the term
&&&&
∂(θ′, v)
∂(θ, u)
&&&& =
&&&&
∂g(t1, t2)
∂(θ, u)
&&&&t1=θ,t2=u
is the Jacobian associated with the bijection g : (θ, u) →(θ′, v). This term arises as in the aug-
mented posterior, we have
˜π(M′, θ′, v|y) = ˜π(M, h(θ′, v)|y)|J(θ′, v)| = ˜π(M, θ, u)|y)|J(θ, u)|−1
under the bijection; here
|J(θ′, v)| =
&&&&
∂(θ, u)
∂(θ′, v)
&&&& =
&&&&
∂(θ′, v)
∂(θ, u)
&&&&
−1
= |J(θ, u)|−1
is the Jacobian. In the expressions above, the two terms −→r m and ←−r m represent the probabilities
of choosing to make move m (from M to M′) and the probability of the reverse move (from M′ to
M). Thus, the acceptance probability for move type m is
αm((M, θ), (M′, θ′)|y) = min

1, π(M′, θ′|y)pv(v)←−r m
π(M, θ|y)pu(u)−→r m
&&&&
∂(θ′, v)
∂(θ, u)
&&&&

.
Often, these general calculations simplify, as one of u or v is a null vector. If dim(θ) < dim(θ′),
and the proposed move attempts to increase the dimension of the current model, then only the
augmenting variables u are needed to match dimension, that is, the bijection can be constructed by
setting θ′ = g(θ, v). In this case
αm((M, θ), (M′, θ′)|y) = min

1,
π(M′, θ′|y)←−r m
π(M, θ|y)pu(u)−→r m
&&&&
∂(θ′)
∂(θ, u)
&&&&

.

108
J. E. Griffin and D. A. Stephens
Conversely, if dim(θ) > dim(θ′), then only the augmenting variables v are needed, and
αm((M, θ), (M′, θ′)|y) = min

1, π(M′, θ′|y)pv(v)←−r m
π(M, θ|y)−→r m
&&&&
∂(θ′, v)
∂(θ)
&&&&

.
As pointed out by [26, p. 717], these proposal mechanisms can be generalized by allowing the
generation for u or v to depend on the values of θ or θ′ respectively. Under this generalization,
pu(u) and pv(v) are replaced by pu(u|θ) and pv(v|θ′) in the acceptance probabilities. This merely
corresponds to an alternative construction of the augmented posterior ˜π.
It is evident from the construction that each move type m comprises a pair of moves operating
in each direction between models M and M′. Thus, if move m is a move from M to M′, constructed
by generation of augmenting variables u and transformation, there should exist in our collection of
potential moves the reverse move, indexed m′, say, which utilizes the augmenting variables v, the
two moves being selected with probabilities −→r m and ←−r m.
In some situations, the reversible jump acceptance probability simplifies even further. For exam-
ple, in a move that increases dimension by du through the variables u, it may be feasible to set
the new parameters precisely equal to u, that is, the proposed parameter vector θ′ is formed by
concatenating θ and u. In this case, the Jacobian of the transformation is 1. Furthermore, it may
be possible to generate u from a prior distribution, which facilitates cancellation in the Hastings
ratio.
Example 7.1 (Nestedmodels) Letk = 1, 2, . . .indexmodelsM1, M2, . . .underconsideration,
where k represents the dimension of θk. Let the elements of θk be (θk1, . . . , θkk). Suppose that the
model specification is such that identical, independent priors are used for the components of the
parameter vector
p(θk) =
k

l=1
p0(θkl).
For a proposed move from Mj to Mk with j < k, suppose that the elements of u are generated
independently from p0, so that
pu(u) =
k−j

l=1
p0(ul),
and suppose that θk = (θl, u). Then
αj((Mj, θj), (Mk, θk)|y) = min

1,
π(Mk, θk|y)←−r j
π(Mj, θj|y)pu(u)−→r j
&&&&
∂(θk)
∂(θ, u)
&&&&

= min

1,
f(y|Mk, θk)p(θk|Mk)p(Mk)←−r j
f(y|Mj, θj)p(θj|Mj)p(Mj)pu(u)−→r j
&&&&
∂(θk)
∂(θ, u)
&&&&

= min

1, f(y|Mk, θk)p(Mk)←−r j
f(y|Mj, θj)p(Mj)−→r j


Advances in Markov chain Monte Carlo
109
as
p(θk|Mk) =
k

l=1
p0(θkl) =
⎧
⎨
⎩
j
l=1
p0(θjl)
⎫
⎬
⎭
⎧
⎨
⎩
k−j

l=1
p0(ul)
⎫
⎬
⎭= p(θj|Mj)pu(u).
For the reverse move that attempts to decrease the model complexity by moving from model k to
model j, the deterministic proposal that sets the last k −j components of θk to zero is used.
The approach described in this example can be useful in some applications, but can also lead to low
acceptance rates.
7.2.2 Reversible jump MCMC: examples
Example 7.2 (Moves between 1-d and 2-d models) Consider two models M1 and M2 with
parameters θ(1) = θ1 and θ(2) = (θ21, θ22), with all parameters taking values on R. We consider
four move types:
1. m = 1: move within Model M1,
2. m = 2: move within Model M2,
3. m = 3: move from Model M1 to Model M2,
4. m = 4: move from Model M2 to Model M1.
For the within-model moves, standard MH acceptance calculations proceed as usual. Moves 3 and
4 are a forward/reverse move pair. Clearly, if the current state of the chain is in M1, only moves 1
or 3 can be selected, and similarly for M2. We need only consider the relative magnitudes of the
reversible jump moves selection probabilities; for example, if the probability of selecting move 3 is
0.3 and the probability of selecting move 4 is 0.1, then
←−r 3
−→r 3
= 0.1
0.3
←−r 4
−→r 4
= 0.3
0.1
are the ratios that enter into the acceptance probability calculations for move types 3 and 4
respectively.
When the current state of the chain is in M1, to propose a move to M2 after selecting move 3, we
must introduce a single random variate u; suppose that u ∼Normal(0, 1), and let
θ21 = θ1 + u
θ22 = θ1 −u
⇐⇒
θ1 = θ21 + θ22
2
.
In this case the acceptance probability takes the form
α3((M1, θ1), (M2, (θ21, θ22))|y) = min

1, π(M2, (θ21, θ22)|y)
π(M1, θ1|y)φ(u)
←−r 3
−→r 3
&&&&
∂(θ21, θ22)
∂(θ1, u)
&&&&

where φ(.) is the standard normal pdf, and
&&&&
∂(θ21, θ22)
∂(θ1, u)
&&&& =
&&&&&&&&
∂θ21
∂θ1
∂θ21
∂u
∂θ22
∂θ1
∂θ22
∂u
&&&&&&&&
=
&&&&&&
1
1
1 −1
&&&&&&
= 2.

110
J. E. Griffin and D. A. Stephens
For the reverse move 4, we have
α4((M2, (θ21, θ22), (M1, θ1), )|y) = min

1, π(M1, θ1|y)φ(u)
π(M2, (θ21, θ22)|y)
←−r 4
−→r 4
&&&&
∂(θ1, u)
∂(θ21, θ22)
&&&&

where
&&&&
∂(θ1, u)
∂(θ21, θ22)
&&&& = 1
2.
Example 7.3 (Comparing nonlinear regression models) Consider two competing pharma-
cokinetic (PK) models for scalar response data y(t) measured at different time points t1, . . . , tn:
1. Model M1: one compartment, elimination only;
E[Y(t)] = A1 exp{−λ1t}
t ≥0
2. Model M2: one compartment, absorption and elimination;
E[Y(t)] = A2

exp{−λ21t} −exp{−(λ21 + λ22)t}

t ≥0
where (A1, λ1) and (A2, λ21, λ22) are positive parameters. The data are displayed in Figure 7.1.
Under an assumption of additive, heteroscedastic Normal errors, we have two competing explana-
tions for the observed data; both models can be fitted using ordinary least-squares, but model com-
parison is not straightforward as the models are nested but the nesting structure is complicated, as
werequireλ22 −→∞,thatis,aboundarypointintheparameterspace,whichleadstonon-regular
frequentist asymptotic theory. Bayesian model comparison can be carried out using Bayes factors,
but this requires numerical integration.
0
1
2
3
4
5
0.0
0.5
1.0
1.5
2.0
2.5
3.0
t
y(t)
Figure 7.1 PK data from one compartment model.

Advances in Markov chain Monte Carlo
111
For illustration, we consider a reversible jump MCMC solution. First, we use a log-scale param-
eterization and set
θ1 = (log A1, log λ1)
θ2 = (log A2, log λ21, log λ22).
We place equal prior probabilities on M1 and M2, and then place independent N(0, τ) priors on
the components of θ1 and θ2. The prior on residual error variance σ2 is inverse Gamma with
parameters 10 and 4. The ML estimates 'θ1 and 'θ2 can be computed easily, as can the Hessian
matrices'I1 and'I2; these likelihood-based results yield reasonable approximations to the posterior
distributions that can be used to produce independence MH algorithms. Specifically, at the ML
estimates for σ under the two models, we may approximate the conditional posterior for θ by the
Normal density
p(θk|'σ, y) ≏N('θk, n−1'σ 2
k 'Ik
−1).
(7.2)
On fitting using ML, the estimates of σ under the two models are found to be quite similar
(M1 : 'σ1 = 0.252, M2 : 'σ2 = 0.329).
A reversible jump MCMC algorithm can be constructed as follows: we again consider four
move types:
1. m = 1: move within M1; update θ1 from p(θ1|M1, σ, y).
2. m = 2: move within M1; update θ2 from p(θ2|M2, σ, y).
3. m = 3: move from M1 to M2; propose a new θ2, and carry out an accept/reject step.
4. m = 4: move from Model M2 to Model M1; propose a new θ1, and carry out an
accept/reject step.
with the remaining parameter σ2 being updated in a Gibbs sampler algorithm at each iteration.
Moves m = 3, 4 are a forward/reverse move pair. For move 3, several options are available; for
example, we could adopt the strategy of Example 7.1, and generate a new variate u from the prior
for the additional parameter, and then merely use the mapping
(θ11, θ12, u) −→(θ21 = θ11, θ22 = θ12, θ23 = u)
with reverse move setting θ23 = 0. This approach may be adequate, but more probably would
not facilitate good mixing across the models. A perhaps better strategy is to consider a different
augmentation, where we generate u = (u1, u2, u3) from the model in (7.2) for k = 2, and use
(θ11, θ12, u1, u2, u3) −→(θ21 = u1, θ22 = u2, θ23 = u3, v1 = θ11, v2 = θ12)
with the paired reverse move being to generate v = (v1, v2) from the model in (7.2) for k = 1. This
guarantees that the proposed value θ2 lies in a region with reasonably high posterior support under
model M2, although it does not guarantee that the move will be accepted with high probability.
In the Hastings ratio, the Jacobian of the transformation is 1, and under equal probabilities of
forward/reverse moves, we have
π(M2, θ2|y)pv(v1, v2)
π(M1, θ1|y)pu(u1, u2, u3) =
f(y|M2, θ2, σ)

3	
j=1
φ(θ2j/τ)/τ

φ2(θ11, θ12;'θ1,'I1)
f(y|M1, θ1, σ)

2	
j=1
φ(θ1j/τ)/τ

φ3(θ21, θ22, θ23;'θ2,'I2)

112
J. E. Griffin and D. A. Stephens
where τ is the prior variance for the regression parameters. The logic of this construction is that
numerically
f(y|M1, θ1, σ) ≈φ2(θ11, θ12;'θ1,'I1),
f(y|M2, θ2, σ) ≈φ3(θ21, θ22, θ23;'θ2,'I2).
A different approximation that incorporates the Normal asymptotic likelihood in equation (7.2) as
well as the Normal prior distribution for the parameters can be constructed.
The algorithm was run for 100,000 iterations. In this run with τ = 4, the chain spent about 66 %
of the time in model M1, indicating the posterior probabilities are
p(M1|y) ≈0.66,
p(M2|y) ≈0.34.
The model posterior probabilities vary with the choice of τ; this is as expected, as the model
probabilities are closely related to the marginal likelihood, or prior predictive distribution, which is
the expected value of the likelihood for the observed data with respect to the prior distribution. It
is evident from the discussion that the prior specification acts as a penalty for complexity. For illus-
tration, if τ = 1, the model probabilities change to (0.80, 0.20); if τ = 10, the model probabilities
are (0.26, 0.74).
Conditional on M1 or M2 being true, we can perform inference about the parameters of the two
models, and also reconstruct estimates and posterior credible intervals for E[Y]. Figure 7.2 displays
the reconstructed posterior intervals for the two models.
It is evident that both models are plausible explanations of the observed data, but offer poten-
tially different predictions of future responses, especially near t = 0. Note that the possible nesting
structure, incorporated by the assumption that λ22 −→∞, is not supported by the priors studied.
Finally, note that the BIC values for the two models, computed as
BICk = −2 log f(y|Mk,'θk,'σ) + dk log n
t
y(t)
Model 1
0
1
2
3
4
5
0.0
0.5
1.0
1.5
2.0
2.5
3.0
y(t)
0.0
0.5
1.0
1.5
2.0
2.5
3.0
0
1
2
3
4
5
t
Model 2
Figure 7.2 Example 7.3. Pointwise 95% credible intervals for [Y] for Model 1 (left) and Model 2
(right).

Advances in Markov chain Monte Carlo
113
where dk is the total number of parameters fitted, are 25.553 and 33.227 respectively for models 1
and 2, indicating strong support for model 1.
Example 7.4 (Finitemixturemodel) ThefinitemixturemodelwithK componentshasdensity
f(y|ω, θ, K) =
K

k=1
ωkfk(y|θk)
where θk are the parameters for component density k, and
0 < ωk < 1, ∀k
&
K

k=1
ωk = 1.
Most typically, although not exclusively, the component densities are from the same parametric
location-scale family (say Gaussian) which differ in location and scale. For independent and identi-
cally distributed data y = (y1, . . . , yn) from this model, the likelihood arising from this model does
not permit analytical calculation of the posterior distribution, so MCMC is commonly used. If K is
known, MCMC is typically implemented using a collection of auxiliary variables z1, . . . , zn, and a
completed data model
f(y, z|ω, θ, K) = Pr[Z = z]fz(y|θz)
z ∈{1, 2, . . . , K}
and a Gibbs sampler strategy updating the z and (ω, θ) from their full conditional posterior dis-
tributions. Conditional on (ω, θ), the posterior distribution for each zi is a discrete distribution
on {1, 2, . . . , K}, whereas conditional on the z, the posterior for the mixture weights ω is a density
on the K-dimensional simplex, and the posterior for the components of θk proceeds using only
those yi for which zi = k, for k = 1, . . . , K. Under a proper prior specification, the posterior is
also proper, although inference is complicated by a permutation non-identifiability in the model
specification (that is, the labels on the components may be permuted without changing the likeli-
hood). Non-identifiability issues in inference can be resolved by, say, imposing constraints on the
location parameters of the component densities, although this is not always completely satisfactory.
See [30]. Perhaps the most satisfactory solution to MCMC mixing problems induced by lack of
permutation identifiability is to introduce an independent random permutation of the component
labels to supplement each MCMC iteration.
In addition to the difficulties of standard Bayesian analysis for this model, if K is also treated
as an unknown parameter, then transdimensional MCMC is also needed; see [48] for an early
influential paper. A discrete prior on K, typically on some finite set, completes the posterior spec-
ification, and yields a posterior distribution π(K, θ(K), ω(K)|y), where θ(K) = (θK1, . . . , θKK)
and ω(K) = (ωK1, . . . , ωKK). In this model, dimension-changing moves correspond to changing
the value of K, and in order to construct an efficient and tunable MCMC algorithm, moves which
peturb K by ±1 are typically considered. For example, moves of type K −→K + 1 are termed
‘birth’ moves, and K −→K −1 are termed ‘death’ moves. The forward/reverse move pairs are
then births from K and deaths from K + 1.
We consider the case of a Normal mixture model for simplicity. If y is one-dimensional, each
component density has two parameters, so a birth/death pair requires the introduction of three
latent variables u, a new mean and variance, and also a parameter to introduce a new component
weight. If y is D-dimensional, D + D(D + 1)/2 + 1 new scalar parameters are needed, that is, a
new mean and covariance matrix, and a new component weight parameter.

114
J. E. Griffin and D. A. Stephens
• New location/scale parameters. Two strategies are used to propose a new set of location
and scale parameters; either these new parameters are generated independently of the cur-
rent model parameters from proposal distribution, or a subset of the current components is
selected and used to generate a new additional component. In the latter case, a common strat-
egy involves ‘splitting’ a currently existing component, that is, taking the mean and variance
from component k, say, and by generating latent variables u, and combining them with the
parameters θKk, using the approach described in the previous section. Perturbing a location
parameter using a Normal increment is generally straightforward and may be sufficient to
produce a reasonably functioning chain. Perturbing a scalar variance parameter is also rea-
sonably easy, but perturbing a covariance matrix is more complex, although Wishart/Inverse
Wishart generation can usually be implemented successfully in low dimensions. For example,
if Kk is the covariance matrix for a selected component k, and A is a D × D positive definite
symmetric matrix variate generated from a Wishart density, then AKk is also a positive
definite symmetric matrix, so we may use it as the covariance matrix for a newly birthed
component, and the Jacobian for this transform is straightforward to compute. The reverse
‘merge’ move can be defined using the rules outlined above.
• Newweightparameters.Generatingthecomponentweightforanewcomponentisstraight-
forward, using a random split or rescaling of the currently existing weights.
In typical mixture applications, inference about the parameter K may be of primary interest in
a given application, but perhaps more commonly the mixture model offers flexible modelling in
the presence of heterogeneity. The Normal mixture case is the most commonly studied, but other
mixtures of other parametric models have also been used.
It should be noted that MCMC computation for varying dimension mixture models is noto-
riously hard to implement successfully using single chain methods, even if the multiple modes
caused by permutation invariance can be overcome. The likelihood surface is complicated and
multi-modal, so it is easy for the chain to get trapped in local high probability regions of the parame-
ter space. To overcome this, multi-chain (or population) MCMC methods are used; see Section 7.3.
The flexible modelling of multivariate density functions using finite mixture approximations
has a long history in Bayesian inference, and has been extended to the use of nonparametric or
infinite mixture models based on the Dirichlet Process. These Bayesian nonparametric approaches
address dimension-changing issues from a different perspective, and typically through Polyá urn
schemes; they essentially utilize a similar auxiliary variable scheme, but identify the ‘clusters’ of
data having the same z value as observations from the same component mixture. A priori, the Polyá
urn facilitates a countably infinite mixture model representation, although a posteriori, in light of a
dataset of size n, a maximum of n components are supported. Working on this finite space of cluster
allocations avoids the need for dimension-changing moves.
Example 7.5 (Flexible curve-fitting via step functions) Suppose the regression relationship
between a scalar covariate x and scalar covariate y
y = g(x) + ϵ
is the focus of interest, for independent homoscedastic Normal errors {ϵ}. Typically, we seek the
prediction'y ='g(x). Suppose we seek to approximate g locally on a finite domain X by a series of
step functions:
gK(x; βK, κK) =
K

k=1
βKk1Bk(x)

Advances in Markov chain Monte Carlo
115
where (B1, . . . , BK) form a partition of X defined by a series of knots κ0, κ1, . . . , κK−1, κK so
that Bk ≡[κk−1, κk). Without loss of generality, assume X ≡[0, 1), with κ0 = 0, κK = 1. In this
step-function approximation, βK = (βK1, . . . , βKK) are the parameters defining the piecewise
constant levels of the function.
The likelihood for data (xi, yi), i = 1, . . . , n is a standard Normal likelihood
f(y|MK, βK, σ, κK) =
n

i=1
φ
yi −gK(xi; βK, κK)
σ

.
Typically, within model MK, a conjugate prior specification on (βK, σ) is used so that the marginal
likelihood f(y|MK, κK) can be computed analytically by integrating out (βK, σ). The conjugate
prior takes the form
p(βK, σ) = p(βK|σ)p(σ)
and p(βK|σ) can be chosen to be some multivariate Normal density; a suitable choice might be
to have a zero mean Gaussian process structure, where the covariance matrix depends on some
hyperparameters and κK.
A reversible jump MCMC algorithm can be constructed to explore the posterior π(MK, κK|y)
which, under the conjugate specification for (βK, σ), depends on the marginal likelihood
f(y|MK, κK), and the prior p(MK, κK). One approach to the specification of this prior is to assume
a Poisson process model for the change-in-level or jump locations of the step function. This
amounts to setting p(MK) to be a Poisson distribution with rate parameter λ say, and then within
model MK, to regard κK as the order statistics derived from a Uniform random sample on (0,1), so
that
p(κK1, . . . , κK,K−1|MK) = (K −1)!
0 < κ1 < · · · < κK,K−1 < 1.
Note that this prior depends only on the value of K and not the individual parameter values. A vari-
ant on this prior is given in [26], where a prior model based on the odd order statistics derived from
a Uniform sample of size 2K −1 is considered. This prior results in a larger expected separation
between the κ values.
Dimension-changing moves in this model correspond to the addition or removal of a knot or
knots. There are several mechanisms for doing this; a new knot can be proposed uniformly on (0,1),
or uniformly in an interval selected in light of the current knot positions. In the former case, the
reverse move corresponds to removing a knot uniformly at random from the current collection;
this forward/reverse pair corresponds to the situation in Example 7.1, where the latent augmenting
variable u is generated from the prior distribution, so the relevant terms cancel in the Hastings ratio.
Model complexity in this model is controlled by the Poisson-model hyperparameter λ, and the
covariance structure in the prior model for βK.
After the marginalized posterior π(MK, κK|y) has been sampled at each iteration, it is trivial to
sample from the conditional posterior on the remaining parameters, π(βK, σ|MK, κK, y), which
is available in closed form in the conjugate model. This then allows posterior samples of the func-
tion g(x; βK, κK) to be reconstructed. This methodology was exploited extensively for flexible
modelling in the latter half of the 1990s to perform Bayesian versions of classical machine learning
procedures such as classification and regression trees (CART), as it can be extended readily to the
case of multiple predictors. In that case, the response function is modelled as a series of constants

116
J. E. Griffin and D. A. Stephens
within hyper-rectangles defined by cut-points that partition predictor space. For a survey of the key
techniques and literature, and examples, see [10].
Example 7.6 (Flexible regression modelling and feature selection) In the extended linear
regression model, response y is modelled as a linear combination of parameters β plus error, that is
y = xβ + ϵ
(7.3)
where x = (x1, . . . , xd) is a vector of predictor values. These predictors can correspond to the
levels of a factor predictor, continuous covariates, nonlinear transforms of covariates, or functions
combining any of these terms. With a fixed predictor set, there are K = 2d models that could be
compared,and,althoughreversiblejumpMCMCcouldbeusedtoexplorethemodelspace,itisnot
strictly necessary unless the marginal likelihood f(y|Mk) is not available analytically—this might
be the case if ϵ is presumed to have a non-Normal distribution for example.
Using the basic regression model from equation (7.3), it is possible to broaden the modelling
viewpoint to encompass flexible predictors. Flexible constructions include predictors based on
splines,waveletsorotherbasisfunctions:thesepredictorsallowtheregressionfunctiontorepresent
complicated regression relationships, and typically in such models it is the prediction,'y = x'β, that
is of more interest than inference about the parameters.
To illustrate the use of reversible jump methodology in this field, consider the derived predictor,
ϕ(x), based on a truncated polynomial basis
ϕ(x) = (g(x) −κ)ν
+ =

(g(x) −κ)ν x > κ
0
x ≤κ
for some function g(.) and parameters ν, κ. The simplest version is the linear form
ϕ(x) = (x −κ)+ =

(x −κ) x > κ
0
x ≤κ
which produces a piecewise linear continuous response function.
A series of such basis functions ϕk(x), k = 1, . . . , K, with corresponding κ1, . . . , κK can be used
to form the flexible regression model
y = ϕ(x)βK + ϵ =
K

k=1
ϕk(x)βKk + ϵ
which may be augmented using standard polynomial terms, say
y = xα + ϕ(x)βK + ϵ = α0 + α1x + α2x2 +
K

k=1
ϕk(x)βKk + ϵ.
In this latter case, setting K = 0, leaving only the polynomial terms, is legitimate. This model is a
generalization of the model described in Example 7.5; the model, albeit nonlinear in x in general, is
still linear in the parameters (α, βK), so much of the previous conjugate analysis goes through as
before.

Advances in Markov chain Monte Carlo
117
Another strategy for flexible modelling is to use wavelets as the basis function set. These basis
functions have compact support, are orthogonal, and typically do not rely on the specification of
separate knot positions, as these are specified in an automatic fashion depending on the type of
wavelet used. The standard classical procedure for implementing wavelet-based models is to select
a wavelet family, which automatically specifies the discrete wavelet transform matrix W(x) such
that y = W(x)c say, where c are the estimated wavelet coefficients. The Bayesian version of this
model uses the W(x) matrix as the design matrix in a linear model; variable dimension MCMC
then proceeds to simplify this model by omitting sets of columns of this matrix.
7.2.3 Reversible jump MCMC: summary
The reversible jump MCMC algorithm introduced by Green was an important development as it
facilitated greater flexibility in Bayesian modelling. The algorithm itself relies on what are, in fact,
standard Metropolis–Hastings moves that utilize latent or auxiliary variables and an extension to
the state space on which the Markov chain operates. It is similar in spirit to the contemporaneous
approach of [8], but does not retain the auxiliaries at all steps of the algorithm as in the Carlin
and Chib method. Good mixing of the reversible jump chain can sometimes be hard to achieve
in practice without expert tuning, but the approach offers an important contribution to Bayesian
model selection.
7.3 Population MCMC
7.3.1 Motivation
In early statistical applications of MCMC, a common approach to implementation was to run
multiple (and usually short) chains independently, and to combine the samples from the chains in
order to produce posterior summaries (see for example the applications in [12]), with, on occasion,
just a single draw from the posterior being obtained from each separate chain, and more commonly,
the output from each chain being heavily thinned, so as to produce an independent Monte Carlo
sample.Insimpleapplications,shortrunscanbeeffective,asthechainquicklyreachesitsstationary
distribution, but in more complicated multi-parameter settings there is a danger that the chain
remains in its transient phase for many iterations. The multi-chain approach offers some protection
against the chain getting trapped in localized high probability regions, but it can also be considered
wasteful, as it prizes the (at equilibrium) independent draws from the target posterior above every-
thing else. Once MCMC methods came into the statistical mainstream, most practitioners realized
theutilityofsingle-chainapproaches,thatcouldbeusedeffectivelytoperformstandardMonteCarlo
calculationsusingdependentdrawsfromtheposterior,albeitatthecostofincreasedvarianceofthe
Monte Carlo estimators. The difficulty in implementing single-chain algorithms is that the chain
may not explore the entire model space effectively; the usual Metropolis–Hastings algorithm is
essentially local in nature, as proposed moves are usually highly dependent on the current value
of the chain. Therefore, the practical application of MCMC methods using single chains can be
challenging for complicated models.
An early multi-chain method, adaptive direction sampling, was devised by [21]. In this Markov
chain algorithm, a population of chains with identical target distribution f is maintained, and values
areupdatedbyproposingnewvaluesinthedirectionconnectingtworandomlyselectedpopulation

118
J. E. Griffin and D. A. Stephens
members. Specifically, in d dimensions, if the population is {x1, . . . , xN}, and xj and xk are selected
at random, a change to xj is proposed by setting
x′
j = xj + u(xj −xk)
where u is a scalar random variate drawn from the density
fU(u : xj, xk) ∝|u|d−1f(xj + u(xj −xk)).
7.3.2 Simulated annealing
An early work that was influential on the statistical MCMC literature was the paper by Geman and
Geman [15], which essentially popularized the Gibbs sampler, but which also utilized an optimiza-
tion algorithm, simulated annealing [33], which operates as follows: to minimize the non-negative
scalar function g(.) of argument x, consider the unnormalized probability density
pT(x) ∝exp

−1
T g(x)

for constant T. Simulated annealing proceeds by running a Markov chain sampling algorithm at a
decreasingsequenceofT valuesT1 > T2 > · · · ,withT1 large.AsT decreases,thefunctionpT(x)
becomes increasingly peaked around its mode. When T is large, pT(x) is relatively flat, so traversing
the support is relatively straightforward, allowing the sampled points to locate the regions of high
probability. In practice, T should be decreased slowly, so that the sampled points have sufficient
chance to become concentrated around the mode.
Although simulated annealing was devised as an optimization algorithm, the core idea of run-
ning a chain or chains at different ‘temperatures’ was subsequently used to develop multiple-chain
MCMC methods in which the chains, rather than operating in parallel, independently and under
the same transition dynamics, instead have potentially different stationary distributions, but are
allowed to interact and exchange information.
7.3.3 Parallel tempering
The key ideas in this section were developed by Geyer ([17, 19]), and form the basis of most current
implementations of population MCMC methods. Consider a collection of related unnormalized
(posterior)densitiesπ1, . . . , πN,definedforsimplicityonacommonsupportwithinRd.Consider
also a related collection of MH proposal kernels P1, . . . , PN with proposal densities q1, q2, . . . , qN
that facilitate the implementation of MCMC for each density. Assume that the usual conditions of
irreducibility and aperiodicity are met.
Consider the augmented posterior
˜π(θ1, . . . , θN) =
N

j=1
πj(θj)
(7.4)
defined on the Cartesian product of the individual parameter spaces. An MCMC algorithm con-
structed by taking a fixed cycle (or random scan) across P1, . . . , PN is irreducible and aperiodic
and has ˜π as its stationary distribution; of course, marginally, samples of θj derived from the chain
are distributed according to πj.
In addition to the usual within-chain moves, consider the following ‘exchange’ move; in addition
tothefixedscan,selecttwochainsjandkatrandomfrom{1, . . . , N},andproposetoexchangetheir

Advances in Markov chain Monte Carlo
119
values, that is, for chain j, propose to set θ′
j equal to θk, the current value in chain k, and similarly
propose θ′
k = θj. This move is then accepted with probability
α(θj, θk|y) =

1, πj(θk)πk(θj)
πj(θj)πk(θk)

This additional reversible move leaves the chain Markov on the product space, and does not affect
the stationary distribution. However, the exchange move is likely to have a low acceptance rate
unless the densities πi and πj are similar.
Combining the exchange move with temperature changing ideas inspired by simulated anneal-
ing, we have a mechanism for allowing parallel chains to exchange information in a useful fash-
ion. Suppose that in a Bayesian inference problem, the target posterior π(.) is indexed j = 1,
and that
πj(θ) ∝{π(θ)}1/Tj
say, for temperature constants 1 = T1 < T2 < · · · . Note that this construction does not necessar-
ily leave πj a proper density, so in the Bayesian setting the alternate construction
πj(θ) ≡π(θj|y) ∝{f(y|θ)}1/Tjp(θ)
which ensures that a proper distribution might be considered. Using this approach, we ensure that
if Tj and Tk are not separated by a large amount, πj and πk should be quite similar; it should be
possibletoproposeandacceptfrequentlyifk = j ± 1,say,andalthoughmovesbetweenπ1 andπN
changes might only be accepted infrequently, the temperature ‘ladder’ allows for eventual passage
of information across all chains. Applying the exchange move strategy produces an effective way
of traversing the support of the target posterior, especially in the case of multi-modal densities, as
densities that are severely multi-modal, with modes separated by low probability regions will be
considerably more uniform (although still multi-modal) in their powered form.
At convergence, the stored MCMC samples represent a sample from the augmented joint pos-
terior in equation (7.4), and consequently the samples of θ1 values are variates generated from the
corresponding marginal, that is, the target posterior.
Example 7.7 (Tempering a mixture density) Consider the two component mixture density
f(x) = 3
4φ(x + 5) + 1
4φ(x −4)
with modes at −5 and 4. The effect of the tempering is evident in Figure 7.3; the two well-sepa-
rated modes in the target (T = 1) density are linked by an intervening region of increasingly large
probability content. Thus MH moves from one modal region to the other, which are difficult when
T = 1, are much easier when T = 10.
Stochastic exchange moves
Simple deterministic exchange methods can be modified to exploit several different chains in a
single move. For example, suppose a move within chain 1 (with stationary distribution π1 ≡π,
the target posterior) is proposed as follows:

120
J. E. Griffin and D. A. Stephens
Algorithm 1 Stochastic exchange proposal
Current value of θ1 is u1
for j in 2 : N do
Propose uj from qj(uj−1, .)
end for
Propose vN from qN(uN, .)
for j in (N −1) : 1 do
Propose vj from qj+1(vj+1, .)
end for
Take v1 as final proposed value for θ′
1.
Accept θ′
1 with probability
α(θ1, θ′
1) = min

1, π1(θ′
1)
π1(θ1)q(u, v)

where q(u, v) is the Hastings ratio for the proposed move.
It is straightforward to establish that
q(u, v) =

N	
j=2
qj(vj−1, vj)

qN(vN, uN)

N−1
	
j=1
qN−j+1(uN−j+1, uN−j)


N	
j=2
qj(uj−1, uj)

qN(uN, vN)

N−1
	
j=1
qN−j+1(vN−j+1, vN−j)
.
10
5
0
−10
−5
0.00
0.05
0.10
0.15
0.20
0.25
0.30
x
f(x)
T=1
T=2
T=3
T=4
T=5
T=10
Figure 7.3 Example 7.7. Tempered mixture density with tempering parameters T = 1,2,3,4,5,10.

Advances in Markov chain Monte Carlo
121
For example, if N = 3, we have
q(u, v) = q2(v1, v2)q3(v2, v3)q3(v3, u3)q3(u3, u2)q2(u2, u1)
q2(u1, u2)q3(u2, u3)q3(u3, v3)q2(v3, v2)q3(v2, v1).
Recallthateachqj(s, t)proposesavaluet onthesamespaceass.Iftheproposaldensityissymmetric
in its arguments, as in a standard Metropolis proposal, the expression simplifies to q(u, v) = 1.
The stochastic exchange approach is similar in spirit to the path and bridge sampling approaches
to numerical integration in the computation or normalizing constants [13]. It has been used
widely in Bayesian inference (see for example [30, 43] for examples in the context of mixture
models).
Choosing the temperature values
It is clear that good choice of the number and values of the temperatures Tj is crucial to the
adequate performance of the algorithm. In general, there are few results to give guidance as to the
optimal choice for complex models where parallel tempering may be necessary. The most common
strategy adopted is equal or geometric spacing, although several formulations have been presented
suggesting alternative unequal spacing (see for example [4, 7, 19, 25],). Algorithms have also been
developedthatallowthetemperaturestovarystochasticallythroughouttheMarkovchainruns,that
is, the {Tj} are treated as parameters in a global probability model. Simulated tempering [19, 41] is a
parallel chain method that allows each Tj to vary according to stochastic updates, and allows choice
of a pseudoprior for the temperatures. This can allow favourable choices of the temperatures to be
discovered by the algorithm.
7.3.4 Evolutionary Monte Carlo
Evolutionary Monte Carlo (EMC) was introduced by [39]. It combined techniques from the lit-
erature on genetic algorithms with population Monte Carlo. A genetic algorithm is a general opti-
mization approach that maintains a diverse collection of ‘chromosomes’ (parameter vectors) and
searchesforoptimalconfigurationsbyquantifyingandupdating‘fitness’usingpseudo-evolutionary
modifications. The two basic genetic algorithm evolutionary steps acting on a set of chromosomes
x1, . . . , xN include
• Mutation. Update xj −→x′
j
• Crossover. Recombine xj and xk by exchanging a portion of each chromosome. That is, if
xj = (xj1, xj2) and xk = (xk1, xk2), set
x′
j = (xj1, xk2)
x′
k = (xk1, xj2).
These two moves, in conjunction with the Exchange move from Section 7.3.3, form the basis of
a stochastic version of the genetic algorithm, which, in line with the Metropolis–Hastings phi-
losophy, proposes new candidate chromosomes, and then accepts or rejects the proposed move
with the usual MH acceptance probability. In EMC, the chromosomes are parameter vectors in
the joint probability model from equation 7.4 formed by combining tempered marginal densities
πj, j = 1, . . . , N at temperatures Tj, j = 1, . . . , N.
It can readily be seen that stochastic versions of all three move types are reversible, and have
standard accept/reject dynamics, and the acceptance probability can be computed in a straightfor-
ward fashion. For the crossover move, this can be carried out with a deterministic proposal (hence

122
J. E. Griffin and D. A. Stephens
becoming a partial exchange move) or stochastically. To carry out a stochastic crossover move, an
adaptive direction sampling or ‘snooker’ proposal [40] may be used; this proposes a new value for
xj in the direction connecting xj and xk.
7.3.5 The Equi-energy sampler
The equi-energy sampler [34] is another population approach which utilizes other aspects of tem-
pered posterior distributions. Suppose that the target posterior is
π(θ) ∝exp {−ψ(θ)}
and that the temperature ladder is given by 1 = T1 < T2 < · · · < TN < TN+1 = ∞. Consider
also a sequence of ‘energy levels’ −∞= E1 < E2 < · · · < EN, and define the tempered distribu-
tions π1, . . . , πN by
πj(θ) ∝exp

−1
Tj
max{Ej, ψ(θ)}

j = 1, . . . , N.
Consider apartition of theparameter space B1, . . . , BN where Bj is theset Bj ≡{θ : Ej ≤ψ(θ) <
Ej+1}. The equi-energy sampler utilizes this partition to develop effective moves in the parameter
space.
Algorithm 2 Equi-energy sampler
1. Chain N: Run an MCMC algorithm to sample πN at the highest temperature; after a suitable
period, use the samples to define the initial partition,'B(N)
j
, j = 1 . . . , N.
2. After R iterations of Chain N, initiate a second chain, Chain N −1, to sample from πN−1
(whilst continuing to update Chain N) using two types of move:
• Move 1: MH move within Chain N −1 (selected with probability 1 −p),
• Move2:Equi-EnergyJumpintoChainN −1(selectedwithprobabilityp):supposethat
thecurrentvalueinChainN −1,θN−1,lieswithinpartitioncomponent'B(N)
j
say.Then
propose a value θ′
N−1 uniformly from'B(N)
j
, and accept the move with probability
α(θN−1, θ′
N−1) = min

1,
πN−1(θ′
N−1)πN(θN−1)
πN−1(θN−1)πN(θ′
N−1)

otherwise remain at the same point.
3. After a suitable period, use the samples from Chain N −1 to define a new partition,
'B(N−1)
j
, j = 1 . . . , N.
4. Repeat Steps 1 and 2, for new Chains N −2, N −3, . . . , 1 etc., allowing equi-energy jumps
between adjacent chains.
Under fairly general conditions, the equi-energy sampler can be shown to be ergodic at each
level of the temperature ladder, such that Chain j has stationary distribution πj [34]. The

Advances in Markov chain Monte Carlo
123
method is ingenious as it exploits both the temperature and location in the parameter space
information.
7.3.6 Annealed importance sampling
Inarelatedbutdistinctvein,Neal[44]developedaparallelizedversionofimportancesamplingthat
operatedusingasequenceoftempereddistributionsasinparalleltempering,andMarkovtransition
kernels qj with stationary distributions πj. Instead of performing iterative sampling and exchang-
ing information between chains, annealed importance sampling uses the tempered distributions to
produce importance sampling weights that can be used to perform Monte Carlo integration.
Suppose that πj is defined in terms of π1 ≡π, the (unnormalized) target posterior, and some
(diffuse) density pN that can be sampled in a straightforward manner, by
πj(θ) = {π1(θ)}ηj 
pN(θ)
1−ηj
forparameters1 = η1 > η2 > · · · > ηN = 0.Theannealedimportancesamplingalgorithmpro-
ceeds as follows to estimate the quantity
E[h(θ)] =

h(θ)π1(θ)dθ.
Algorithm 3 Annealed importance sampling
1. for i in 1 : M do
2.
Sample θN from πN ≡pN
3.
for j in (N −1) : 1 do
4.
Sample θj from qj+1(θj+1, .)
5.
end for
6.
Retain θi = θ1, and form the importance sampling weight
wi =
N−1

j=1
πj(θj)
πj+1(θj)
(7.5)
7. end for
8. Form the Monte Carlo estimate
'E[h(θ)] = 1
M
M

i=1
wih(θi)
Neal[44]demonstratesthatthisMonteCarloestimatorisunbiasedfortheestimated,astheimpor-
tancesamplingweightsarecorrectlydefined.Again,heusedanaugmentedstatespaceconstruction
to demonstrate this. The first important note is that, for any π with associated Markov transition
density q that has π as its invariant distribution, we have by definition of the invariance that
π(dθ) =

q(u, θ)π(du).

124
J. E. Griffin and D. A. Stephens
Now, using the importance sampling identity with importance density p
Eπ[h(θ)] =

h(θ)π(θ)dθ =
 
g(θ)q(u, θ)π(u)dudθ
=
  h(θ)π(u)
p(u)
p(u)q(u, θ)dudθ
which suggests the estimator
'Eπ[h(θ)] = 1
M
M

i=1
h(θi)π(ui)
p(ui)
where {ui} are independent draws from p(.), and {θi} are independent draws from q(ui, .) for i =
1, . . . , n. The annealed importance sampling algorithm adapts this result on the augmented space
using the augmented posterior equation (7.4). We have that the augmented density can be written
˜π(θ1, θ2, . . . , θN) = π1(θ1)
N

j=2
˜qj(θj−1, θj)
where
˜qj(x, y) = qj(y, x)πj(y)
πj(x)
is the so-called reverse transition density. The proposal density is
p(θ1, θ2, . . . , θN) = πN(θN)
N

j=2
qj(θj, θj−1)
and thus the importance weight is given by
˜p(θ1, θ2, . . . , θN)
p(θ1, θ2, . . . , θN)
which reduces to (7.5).
7.3.7 Population MCMC: summary
Population MCMC methods facilitate effective exploration of the support of complicated and
potentially multi-modal posterior distributions that single-chain methods often find difficult to
explore. Usually population MCMC relies upon a series of temperature modulated versions of the
target posterior, and on designed MH moves across the collection of Markov chains working with
each version separately, allowing for exchange of sampled values between them. In this section,
we have discussed the fixed-dimension case, but the methodology applies also to populations of
variable-dimension chains [32]. Also, population approaches with exchange of information can be
adopted in sequential Monte Carlo (see, for example, [31] for a comparison of population MCMC
and sequential Monte Carlo). For a comprehensive survey of population MCMC methods, and
other recent advances, see [38].

Advances in Markov chain Monte Carlo
125
7.4 Adaptive MCMC
7.4.1 Introduction
The Metropolis–Hastings algorithm can be used to sample from any target distribution but at the
priceofhavingtochooseaproposaldistribution.Thischoiceplaysanimportantroleindetermining
how well a sample drawn using the Metropolis–Hastings algorithm replicates the target distribu-
tion. Good choices of proposal distribution lead to algorithms which more closely replicate the
target distribution and will usually depend on the shape of the distribution. In Bayesian statistics,
the exact shape of the target distribution (the posterior distribution) will be determined by the
choice of model (including the prior distribution) and data, and so will often change from model to
model and from data to data. It would be desirable to have methods which automatically changes
the proposal distribution so that the sample is a good representation of the target distribution. Such
methods have been developed and are usually described as adaptive Markov chain Monte Carlo
methods.
The idea of adaptation is appealing but leads to serious complications in the theory underlying
non-adaptive MCMC methods. Allowing the proposal to depend on previous states stops the
chains being Markovian and the usual theory for convergence of Metropolis–Hastings algorithms
is no longer applicable. Therefore, new theory is needed to justify the use of such algorithms. An
adaptive method was developed by [22] which used regeneration times to preserve the Markov
properties. However, these methods have proved difficult to extend from their framework. An
alternative approach was pursued by [28] who developed the Adaptive Metropolis (AM) algorithm
which allows adaptation at every step of the algorithm and showed that it converges to the correct
distribution. Allowing adaptation at every step of the algorithm (which is often known as infinite
adaptation) has proved a fruitful idea. A fairly general theory has subsequently been developed
which provides conditions under which adaptive MCMC algorithms can be shown to converge
to the correct distribution. This has led to a general principle for the development of adaptive
algorithms which can be applied to the full range of posterior distributions arising from Bayesian
models.
Alternatively, a single chain can be used with the proposal at time j depending on the samples
collected before time j, θ(1), θ(2), . . . , θ(j−1). Finite adaptive algorithms allow the proposal to be
changed for the first K iteration, where it is specified before running the sampler, the same proposal
is used after K. Clearly, samples are collected after K. Infinite adaptation algorithms continue to
adapt the proposal for the whole length of the chain.
7.4.2 The Metropolis–Hastings algorithm and optimal proposals
Recall the basic Metropolis–Hastings algorithm: firstly, propose a new value θ′ from a transition
density q(θ(g), θ′|y) and calculate the acceptance probability
α(θ(g), θ′|y) = min

1, π(θ′)q(θ′, θ(g)|y)
π(θ(g))q(θ(g), θ′|y)

.
Secondly, generate a uniform random variable ug and set θ(g+1) = θ′ if u < α(θ(g), θ′|y) or
θ(g+1) = θ(g) otherwise. This guarantees that θ(1), θ(2), . . . are a sample from π under weak
conditions. This allows integrals of the form
I =

h(θ)π(θ) dθ

126
J. E. Griffin and D. A. Stephens
to be approximated by
'I = 1
G
G

g=1
h(θ(g))
since'I converges to I as G →∞. This guarantees the correctness of the approximation in the limit
but, in practice, we will only run the chain for a finite number of iterations G. The accuracy of the
approximationafterthisfiniterunwillcruciallydependonthechoiceofproposaldistribution.This
has led to interest in conditions for ‘good’ proposals.
The proposal in a Metropolis–Hastings algorithm is often chosen from a class which depends on
some tuning parameters, ζ. There are two main classes of proposal. These are:
• The Metropolis–Hastings independence sampler, where θ′ is drawn from a particular distri-
bution with parameters ζ. For example, a normal distribution with mean μ and variance ,
where ζ = (μ, ).
• The Metropolis–Hastings random walk sampler proposes θ′ = θ + ζϵ, where ϵ is drawn
from a zero mean distribution (such as a standard normal or t-distribution).
It is natural to ask whether certain choices of ζ lead to good or bad mixing of the chain. In
an independence sampler, [42] discussed the convergence of the Metropolis–Hastings indepen-
dence sampler and showed that the optimal choice of proposal density is the target density π(θ).
In practice, it will usually be impossible to sample from π(θ) (otherwise, we would just sam-
ple from π(θ) and there would be no need for MCMC), but good choices of proposal den-
sity approximate the target density as closely as possible. They showed that geometric ergodicity
depends on the approximation having heavier tails than the target distribution. There are two main
rules-of-thumb for Metropolis–Hastings random walk samplers. Firstly, [50] showed that choosing
ζ so that the average acceptance rate ¯α (which is the average of the acceptance probabilities over
theMetropolis–Hastingssampler)isequalto0.234leadstoanoptimalsamplerinhigh-dimensional
spaces. It has been shown that an average acceptance rate around this value can be optimal in many
problems. Secondly, choosing ζζT to be (2.4)2/d times the covariance of the target density, where
d is the dimension of the target, has been shown to be optimal asymptotically in p [49, 50]. [14]
showed that these results can also be useful in low-dimensional problems.
Example 7.8 A two-component mixture model
We will consider a one-dimensional two-component mixture distribution
π(θ) = 0.3 N(θ| −1, 0.22) + 0.7 N(θ|1, 0.22)
where N(θ|μ, σ 2) represents the probability density function of a normal distribution with mean
μ and variance σ2. Outputs from running the Metropolis–Hastings random walk sampler with
different values of ζ are shown in Figure 7.4. The chain with ζ = 0.8 tends to move often but
short distances. As ζ increases, the chain tends to move less often but longer distances. The best
approximation to the target distribution is provided by ζ = 1.4 (middle row). This represent a
compromise between the other values of ζ for which the chain either jumps too often (ζ = 0.8)
or too little (ν = 6). The average acceptance rate for this chain is 0.234 and shows that a chain with
this acceptance rate tends to mix well.
A useful measure of the mixing of a chain is the average squared jumped distance, which is the
expected distance between consecutive values of the Markov chain, which is given by

∥θ′ −θ ∥2 α(θ, θ′|y)q(θ, θ′|y)π(θ)dθ′dθ

Advances in Markov chain Monte Carlo
127
−2
−1
0
1
2
0
1
2
ζ=1.4
−2
−1
0
1
2
0
1
2
ζ=6
−2
−1
0
1
2
0
1
2
 (a) ζ=0.8
0
500
1000
1500
−2
0
2
ζ=1.4
0
500
1000
1500
−2
0
2
ζ=6
0
500
1000
1500
−2
0
2
 (b) ζ=0.8
Figure 7.4 Example 7.8: (a) density estimate (solid line) and target density (dotted line) and (b) the
trace plot for 1000 iterations of the Metropolis–Hastings random walk algorithm with different values
of ν.
where ∥x ∥represents the Euclidean norm. Larger values of the expected squared jumped distance
suggest that the sampler is mixing better and so the mean squared error of estimating I by ˆI will be
smaller. It can be estimated from MCMC output by
¯J = 1
G
G

g=1
∥θ(g) −θ(g−1) ∥2 .
Therelationshipbetweenζ,theaverageacceptancerate ¯α andtheaveragesquaredjumpeddistance
¯J isillustratedinFigure7.5.Theaverageacceptancerate ¯α decreasesasζ increases(Panel(a)).Panel
(b) shows that the average squared jumped distance ¯J increases for small values of ζ but reaches an
optimum when ζ is around 2 and then decreases. Small ζ is associated with small moves which are
0
5
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
(a)
0
5
0.05
0.1
0.15
0.2
0.25
0.3
(b)
0
0.2
0.4
0.05
0.1
0.15
0.2
0.25
0.3
(c)
Figure 7.5 Example 7.8: (a) The average acceptance rate as a function of ν, (b) the average squared
jumped distance as a function of ν, (c) the average squared jumped distance as a function of the
average acceptance rate.

128
J. E. Griffin and D. A. Stephens
often accepted. Larger ζ leads to larger moves, but these often tend to be rejected if ζ becomes too
large. Panel (c) shows that the average squared jumped distance is maximized by an acceptance rate
around 0.19. The results fits roughly with the rule that ¯α around 0.234 leads to the largest average
squared jumped distance ¯J of about 0.25.
7.4.3 Adaptive samplers
Inthissection,wewilllookatdifferentadaptiveMCMCalgorithms.Wewillmakeaslightchangeof
notation to emphasize that both the proposal distribution and the acceptance probability depend
onthetuningparametersζ.Theproposaldensitywillbedenotedbyqζ (θ, θ′|y)andtheacceptance
rate will be denoted by αζ (θ, θ′|y).
Adaptive Metropolis–Hastings random walk samplers
The first adaptive MCMC algorithm with infinite adaptivity was the Adaptive Metropolis (AM)
algorithm introduced by [28]. They use the idea that the algorithm will be optimal if the
variance–covariance matrix of the proposal distribution is chosen to be sd = 2.42/d times the
variance–covariance matrix of the target. An estimate of the variance–covariance matrix at itera-
tion g can be calculated using the sample covariance matrix of the previously generated samples
θ(1), . . . , θ(g−1). The sample covariance matrix may be a poor estimate when there are only a few
samples. This is addressed by defining that the variance–covariance matrix is fixed at ζ (0) for the
first g0 iterations and taking a combination of the sample covariance matrix and the identity matrix
for subsequent iterations.
Algorithm 4 Adaptive Metropolis–Hastings (AM) algorithm
1. Initializethestartingvalues θ(0) andζ (0),therequiredMCMCsamplesizeG,burn-inperiod
n0 and g0.
2. for g = 1, 2, . . . do
3.
Sample θ′ = θ(g) + ϵg where ϵg ∼N(0, ζ(g)).
4.
Let the next iterate be
θ(g+1) =

θ′
with prob αζ (g)(θ(g), θ′|y)
θ(g) with prob 1 −αζ (g)(θ(g), θ′|y)
5.
Compute
ζ (g+1) =
⎧
⎪⎪⎨
⎪⎪⎩
ζ (0)
if g ≤g0
sd
1
g−1
⎡
⎣g
j=1 θ(j)θ(j)T −
g
j=1 θ(j)g
j=1 θ(j)T
g
⎤
⎦+ sdϵId if g > g0
.
where ϵ is a small, positive constant and Id is the d-dimensional identity matrix.
6. end for
7. Return the draws θ(n0+1), . . . , θ(n0+G)
It is shown in [28] that the samples come from the target distribution and that I can be
approximated by ˆI. They also described how the covariance matrix can be calculated itera-
tively to avoid the method becoming computationally expensive. The algorithm was run on
Example 7.8 with ζ(0) = 1 and ϵ = 0.01 for 10 000 iterations. Output from the chain is
shown in Figure 7.6. The variance converges fairly quickly to the posterior standard deviation.

Advances in Markov chain Monte Carlo
129
0
5000
10000
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
(a)
0
5000
10000
1.7
1.8
1.9
2
2.1
2.2
2.3
2.4
2.5
(b)
0
5000
10000
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
(c)
Figure 7.6 Example 7.8 – output for the AM algorithm: (a) trace plot of the samples, (b) trace plot of
the standard deviation of the proposal and (c) trace plot of the average acceptance probability.
The average acceptance rate is 0.165 which is close to the optimal value of 0.19 for this example,
showing that the rule used by AM works well here.
The idea that the chain should be adapted to achieve a particular average acceptable rate ¯τ is
explored in [5]. A standard choice would be ¯τ = 0.234, since this has been shown to be optimal
in several situations. However, we have already seen in Example 7.8 that other values of ¯τ may lead
to a better performing chain. It uses iterations of the Robbins–Monro algorithm from Stochastic
Approximation which find the value ζ which solves N(ζ) = E[M(x, ζ)] = 0, where x is a random
variablewhosedistributionisunknownandM isafunction.Inourcaseζxaredrawsfromthetarget
distribution. The function that we wish to target N(ζ) = ¯α −¯τ where ¯α depends on ζ. Finding a
zero of this equation implies that we find the ζ for which ¯α = ¯τ.
Algorithm 5 Adaptive scale Metropolis–Hastings (ASM) algorithm
1. Initializethestartingvaluesθ(0) andζ(0),therequiredMCMCsamplesizeGandtheburn-in
period n0.
2. for g = 1, 2, . . . , do
3.
Sample θ′ = θ(g) + ϵg where ϵg ∼N(0, ζ (g)).
4.
Let the next iterate be
θ(g+1) =

θ′
with prob αζ (g)(θ(g), θ′|y)
θ(g) with prob 1 −αζ (g)(θ(g), θ′|y)
5.
Compute
ζ (g+1) = ρ

ζ (g) + w(g) 
αζ (g)(θ(g), θ′|y) −¯τ

.
6. end for
7. Return the draws θ(n0+1), . . . , θ(n0+G)

130
J. E. Griffin and D. A. Stephens
The function ρ is used to stabilize the algorithm and defines a range  = {σ : δL ≤σ ≤δU}
of possible values for ζ. The function ρ is designed to stop ζ moving outside  and has the
form
ρ(σ) =
⎧
⎪⎨
⎪⎩
δL if σ < δL
σ if σ ∈
δU if σ > δU.
Ideas for relaxing this condition by allowing  to grow with the iterations are discussed by [1]
and [53]. The sequence w(g) plays a crucial role in defining an algorithm for which ζ converges
to the correct value and the chain converges to the correct distribution. [5] shows that this occur
if w(g) = O(g−λ) for some constant 1/2 < λ1 ≤1. The ASM algorithm was run on Example 7.8
with w(g) = g−0.7, ζ (0) = 1 and ¯τ = 0.234 for 10 000 iterations. Output is shown in Figure 7.7.
The algorithm converges well to the target average acceptance rate of 0.234 and the associated scale
of 1.36. In this case, the choice of 0.234 is sub-optimal and the average squared jumped distance is
0.19, which is smaller than the average squared jumped distance of the AM algorithm, which was
0.24. The 0.234 value arises as a limit in the dimension of the target so it is surprising that it is not
sub-optimalinaunivariateexample.However,thisstillrepresentsagoodvalueforthisproblemand
supports the general applicability of this value.
The idea of the AM and ASM algorithms can be combined by adapting both the covariance
matrix of the proposal to the covariance matrix of the target density (as in the AM) and the scale
parameter sd in the AM algorithm to achieve an average acceptance rate of 0.234 (as in the ASM).
This is particularly useful if the target distribution is multivariate, in which case ASM is not directly
applicable.Thisideaisdiscussedby[2]and[3]andwillbereferredtoastheAdaptiveScalingwithin
0
5000 10000
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
(a)
0
5000 10000
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
(b)
0
5000 10000
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
(c)
Figure 7.7 Example 7.8 – output for the ASM algorithm: (a) trace plot of the samples, (b) trace plot
of the scale of the proposal, and (c) trace plot of the average acceptance probability.

Advances in Markov chain Monte Carlo
131
the Adaptive Metropolis–Hastings (ASWAM) algorithm. The scale tuning parameter will now be
written s(g)
d .
Algorithm 6 Adaptive scaling within the Adaptive Metropolis–Hastings (ASWAM) algorithm
1. Initialize the starting values θ(0), ζ (0) and s(0)
d , the required MCMC sample size G, burn-in
period n0 and g0.
2. for g = 1, 2, . . . do
3.
Sample θ′ = θ(g) + ϵg where ϵg ∼N(0, ζ (g)).
4.
Let the next iterate be
θ(g+1) =

θ′
with prob αζ (g)(θ(g), θ′|y)
θ(g) with prob 1 −αζ (g)(θ(g), θ′|y)
5.
Compute
s(g+1)
d
= ρ

s(g)
d
+ w(g) 
αζ (g)(θ(g), θ′|y) −¯τ

.
and
ζ (g+1) =
⎧
⎪⎪⎨
⎪⎪⎩
ζ(0)
s(g+1)
d
1
g−1
⎡
⎣g
j=1 θ(j)θ(j)T −
g
j=1 θ(j)g
j=1 θ(j)T
g
⎤
⎦
if g ≤g0
+ s(g+1)
d
ϵId
if g > g0
.
where ϵ is a small, positive constant and Id is the d-dimensional identity matrix.
6. end for
7. Return the draws θ(n0+1), . . . , θ(n0+G)
The chain will converge under the same conditions on w(g) as ASM. The ASWAM algorithm was
run on Example 7.8 with ζg = 0.1, ϵ = 0.01, w(g) = g−0.7 and τ = 0.234 for 10 000 iterations.
Figure 7.8 shows the output of the ASWAM algorithm in this case. The average acceptance rate
converges to the targeted value of 0.234. The scale finishes around 1.5, which is similar to the value
in the ASM algorithm (which is not surprising since both algorithms target the same average
acceptance rate). The scale factor associated with this is scale is around 1.5 which is far from the 2.4
value used by the AM algorithm. This example illustrates the ability of the algorithm to generate
the value of the covariance matrix and the scaling s(g)
d
which both converge to the correct values.
The ASWAM algorithm is particularly suited to sampling from multivariate target distributions,
since optimal scaling of the covariance matrix often produces a good proposal distribution. [58]
suggests an alternative form of adaptation for multivariate target distribution which avoids the
two-stage adaptation of ASWAM (adaptation of both the covariance matrix and the scaling param-
eter). The algorithm is termed the Robust Adaptive Metropolis–Hastings (RAM) algorithm and
works directly on an adaptive scale matrix (so directly generalizing [5]).

132
J. E. Griffin and D. A. Stephens
0
5000
10000
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
(a)
0
5000
10000
1
1.5
2
2.5
3
3.5
4
(b)
0
5000
10000
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
(c)
0
5000
10000
1
1.5
2
2.5
3
3.5
4
(d)
Figure 7.8 Example 7.8 – output for the ASWAM algorithm: (a) trace plot of the samples, (b) trace
plot of the scale of the proposal, (d) trace plot of the average acceptance probability, and (d) trace
plot of the scale parameter s(g)
d .
Algorithm 7 Robust adaptive Metropolis–Hastings (RAM) algorithm
1. Initializethestartingvalue θ(0) andζ(0),specifytheburn-insize n0 andtherequiredMCMC
sample size G.
2. for g = 1, 2, . . . , do
3.
Sample θ′ = θ(g) + ζ (g)ϵg where ϵg ∼f, some fixed distribution.
4.
Let the next iterate be
θ(g+1) =

θ′
with prob αζ (g)(θ(g), θ′|y)
θ(g) with prob 1 −αζ (g)(θ(g), θ′|y)
5.
Compute
ζ (g+1)ζ (g+1)T = ζ (g)

Id + w(g)(αζ (g)(θ(g), θ′|y) −¯τ)
1
∥ϵg ∥2 ϵgϵT
g

ζ (g)T
where Id is the d-dimensional identity matrix
6. end for
7. Return the draws θ(n0+1), . . . , θ(n0+G).
[58] shows that the weights w(g) must obey the condition that
∞

g=1
g−1w(g) < ∞
∞

g=1
w(g) = ∞

Advances in Markov chain Monte Carlo
133
for the algorithm to be ergodic. He also shows that the correct average acceptance rate will be
targeted if the distribution is elliptically symmetric. This algorithm is very similar to the ASM
algorithm for a one-dimension target and so we don’t produce output from Example 7.8 with this
algorithm.
Further examples
Theexampleofaunivariatemixturedistributionispotentiallychallengingbutsimulationfrommul-
tivariate target distributions is often needed in fitting Bayesian models. We will consider two exam-
ples: a bivariate mixture distribution and the posterior distribution of a logistic regression model.
Example 7.9 Bivariate mixture distribution
The univariate mixture distribution of Example 7.8 is extended to a bivariate mixture distribution
which has a density of the form
π(θ) = 0.3 N2

θ
&&&&&

−1
−1

,

0.22
0
0
0.22

+ 0.7 N2

θ
&&&&&

1
1

,

0.22
0
0
0.22

where Nd(x|μ, ) is a d-dimensional multivariate normal distribution with mean μ and vari-
ance–covariance matrix . The three algorithms suitable for multivariate target distributions (AM,
ASWAM and RAM) were run for 10 000 iterations on this example. The initial setting used for
ASWAM on Example 7.8 were used in this case. The RAM algorithm was run with w(g) = g−0.7.
All algorithms performed well and converged to the correct distribution. Some results are reported
in Table 7.1. All three algorithms lead to very similar average squared jumped distance. The average
acceptancerateis0.31,whichisbiggerthanthetargetvalueof0.234usedbybothASWAMandRAM
algorithms. This illustrates the usefulness of all three algorithms for this example. This suggests that
larger average squared jumped distances would be possible by targeting an acceptance rate between
0.24 and 0.31.
Example 7.10 Logistic regression model
The logistic regression model assumes that a binary response yi ∈{0, 1} can be related to a
p-dimensional vector of regressors xi using an intercept α and a p-dimensional parameter vector
of regression coefficients β by
yi ∼Ber(pi),
pi =
exp{ηi}
1 + exp{ηi},
ηi = α + xiβ
where Ber(p) represents the Bernoulli distribution with probability p. We assume that each regres-
sor has been centred and scaled to have sample variance 1. The model is completed by assuming
a prior for the intercept α and regression coefficients β. For illustration purposes, we will use
α ∼N(0, 10002) and β ∼N(0, 102 Ip). The target is the (p + 1)-dimensional posterior distri-
bution and the problem is challenging for MCMC methods, since the full conditional distributions
of α and β do not have a known form. The posterior distribution of α and β can also be highly
Table 7.1 Example 7.9: The average acceptance rate (¯α) and the average squared jumped distance
(¯J) for the AM, ASWAM and RAM algorithms using 10 000 iterations.
AM
ASWAM
RAM
¯α
0.31
0.24
0.25
¯J
0.036
0.036
0.035

134
J. E. Griffin and D. A. Stephens
Table 7.2 Example 7.10: The average acceptance rate (¯α) and the average squared jumped distance
(¯J) for the AM, ASWAM and RAM algorithms using 100 000 iterations.
AM
ASWAM
RAM
¯α
0.24
0.23
0.21
¯J
0.022
0.022
0.020
correlated, which suggests that a good algorithm will update α and β jointly. We will consider using
the AM, ASWAM and RAM algorithms on this target distribution. The model was fitted to data on
diabetesinPimaindians.ThisisawidelyuseddatasetwhichisavailableintheMASSpackageofthe
statistical software program R. The response is the presence or absence of diabetes in a sample of
532 subjects. There are seven risk factors for diabetes which are used as the regressors in the logistic
regression model. Further details are available from the MASS package. The results of running
the three algorithms using the same setting as Example 7.9 are shown in Table 7.2. The average
acceptance rates and average squared jumped distance are very similar across the three algorithms.
This again shows the ability of these algorithms to automatically adapt to the target distribution
Adaptive Metropolis–Hastings independence samplers
In Metropolis–Hastings independence samplers, the proposal distribution is taken to be a paramet-
ric family of distributions such as a normal or a t-distribution. The Metropolis–Hastings algorithm
will perform well if the proposal distribution is a good approximation to the target distribution. An
adaptive version of the Metropolis–Hastings independence sampler was proposed by [11]. An itera-
tive scheme is described for approximating the posterior distribution by estimating the parameters
of the chosen family of distribution (such as the mean and variance of a normal distribution). The
k-th iteration of the algorithm runs a Metropolis–Hastings independence sampler for G iterations
with the approximation used as the proposal distribution. The approximations should improve as
more approximations are calculated and a condition is described to decide when an approximation
is ‘good enough’. The MCMC sample to be used is generated conditional on a final approximation
and so the algorithm has finite adaptation.
The quality of the approximation in the tails is important for the behaviour of the chain. [42]
show that the sampler can only have geometric ergodicity if the tails of the proposal are at a slower
rate than the tails of the target distribution. This suggests that the approximation should be flexible.
A number of authors have considered a mixture of normal distributions as a flexible method for
approximatingthetargetdistribution.[1]developingtheideaof[11]intoaninfinitelyadaptivealgo-
rithm where the Kullback–Leibler distance between the target distribution and the approximation
isminimizedusinganEMalgorithm.[24]alsouseamixtureofnormaldistributionsfortheirtarget,
but use the k-harmonic mean method for estimating the mixture of normals approximation as a
faster alternative to the EM algorithm.
Adaptive Metropolis–Hastings random walk algorithms with
multimodal targets
Adaptive MCMC algorithms provide a method for finding the optimal proposal distribution from
a class of proposal distributions. However, they do not guarantee that the optimal proposal distri-
bution will have good mixing properties. This is a particular problem if the target distribution is
multi-modal. It is natural to ask the question, whether alternative methods can be developed which
avoid this poor mixing.

Advances in Markov chain Monte Carlo
135
One potential design for algorithms partitions the support of the target distribution into disjoint
regions S1, . . . , SK for which ∪K
i=1Si = θ, and allow the proposal distributions to depend on the
region containing θ(g). [9] introduced the Regional Adaptation (RAPT) algorithm and assumed
that the target distribution in each region can be well-approximated by a normal distribution. It
follows that the overall target distribution is approximated by a mixture of normal distributions.
Their preferred algorithm is the Mixed RAPT algorithm which uses the following proposal
q(θ(g), θ′|y) = (1 −β)
K

k=1
λ(i)
k qk(θ(g), θ′|y) + βqwhole(θ(g), θ′|y)
when θ(g) is in region Si and 0 < β < 1 is fixed. They allow adaptation of the λ(i)
k s, the qks and
qwhole. The qks are centred at θ(g) and have a covariance matrix which is (2.4)2/d times the covari-
ance matrix of the θ(1), . . . , θ(g) which fall in region Sk. The λ(t)
j
are adapted in the following way
λ(i)
j
=
⎧
⎪⎪⎨
⎪⎪⎩
d(i)
j
K
k=1
d(i)
k
if
K
k=1
d(i)
k
> 0
1/2
otherwise
whered(i)
k representstheaveragesquaredjumpeddistancesampled(overthecurrentsamples)from
qk when the chain was in region Si. The qwhole proposal is updated using the whole sample in the
samewayastheAMalgorithm.Thisisincludedtoprovidesomestabilityinthealgorithm.[9]show
the ergodicity of this algorithm. The Mixed RAPT algorithm assumes that the regions S1, . . . , SK
are known before simulation (or through a pilot MCMC run) which limits the applicability of the
method for general Bayesian inference. [6] extend this idea to the RAPT with Online Recursion
(RAPTOR) algorithm. This allows the regions S1, . . . , SK to also adapt in the algorithm and uses
a different method for estimation of the covariance matrix in each region.
7.4.4 Construction of adaptive algorithms
Wehavealreadyseenanumberofadaptivealgorithmswhichhavebeenshowntoconverge.Conver-
gence results for the initially developed algorithms were proved on a case-by-case basis. However,
it is natural to ask whether there are general conditions which show that adaptive algorithms work
in general. There are two issues here:
(1) What criteria should the adaptive parameter ζ be targeting? And how can we guarantee the
sequence ζ(1), ζ (2), . . . will converge to the optimal value for a generated chain?
(2) Will the chain θ(1), θ(2), . . . be ergodic, i.e. will ¯I converge to I as G →∞?
Answering these questions has been the central concern in the field. The lack of a Markovian
structure means that standard MCMC theory does not apply to this class of methods and so (2)
is hard to answer in general. Recently, there has been some success in defining general principles
for checking (1) and (2). This section will not give a detailed description of these results but rather
illustrate when these general principles can be applied to the algorithms in the previous section and
how the general ideas can be applied to develop novel algorithms.
Question (1) can generally be answered using ideas from stochastic approximation. Most con-
ditions discussed above can be expressed as expectations with respect to the target distribution
(such as the average acceptance probability). Stochastic approximation concerns the developing of

136
J. E. Griffin and D. A. Stephens
iterative methods for solving problems which consist of expectations with respect to a distribution
which is only available through sampling and some tuning parameters. In particular, the Robbins–
Monro algorithm has proved to be an important method which underlies both the AM and ASM
algorithm [2].
An important condition for establishing (2) is the idea of diminishing adaptation [1, 51]. Intu-
itively, we want the difference in the adaptive parameter ∥ζ(j+1) −ζ(j) ∥to become smaller as j
tends to infinitely. Therefore, ζ(j) will ‘settle down’ to its optimal value. All the algorithms already
described fit into this framework. The AM algorithm uses
ζ(g+1) = ζ(g) +
1
g −1
⎡
⎢⎣θ(g)θ(g)T +
g−1
j=1 θ(j) g−1
j=1 θ(j)T
g −1
−
g
j=1 θ(j) g
j=1 θ(j)T
g
−ζ (g)
⎤
⎥⎦
and the increments of ζ (g+1) are clearly getting smaller with g. The ASM algorithm uses
ζ(g+1) = ζ (g) + w(g)(α(θ(g), θ′|y) −¯τ)
since 0 < α(θ(g), θ′|y) < 1 and ¯τ is fixed then the range of increments gets smaller with g if w(g) is
a decreasing sequence (which leads to the condition that w(g) should be O(g−λ) for λ ∈(1/2, 1]).
The RAM algorithm has a similar recursion to the ASM algorithm and has diminishing adaptation
using similar arguments. The ASWAM algorithm combines the AM and ASM algorithms and so
also has diminishing adaptation. Notice that many estimates calculated using the first g iterations
of the chain will have diminishing adaptation (in a similar way to the AM algorithm). Therefore,
any method which attempts to estimate the target distribution for the chain will have diminishing
adaptation. The diminishing adaptation idea was made exact by [1] who assumed that ∥ζ (g+1) −
ζg) ∥converges to zero. [51] introduced the weaker condition that
lim
g→∞sup
θ∈
∥Qζ (g+1)(θ, θ′|y) −Qζ (g)(θ, θ′|y) ∥TV= 0,
in probability
where  is the state space of the target distribution. Notice that this condition does not assume that
ζ(g) will converge.
Once diminishing adaptation has been established, ergodicity can usually be proved, assuming
thatthechainhasuniformbehaviourforallpossibleMCMCkernels.Forexample,[51]showergod-
icity under the assumption of ‘simultaneous uniform ergodicity’, which states that for all ϵ > 0,
there exists an N(ϵ) for which
∥Qg
ζ (θ, θ′|y) −π(θ′) ∥TV≤ϵ
for all θ ∈ and all possible values of ζ. Here, Qg
ζ (θ, θ′|y) represents the distribution of the chain
after g iterations starting at θ. This says that the chain should be converging at ‘similar rates’ for any
starting point. This condition may be difficult to check in practice. They also show that the chain
is ergodic if  and ζ are finite and that the chain is ergodic for all ζ. This is a looser condition
on convergence and allows this result to be applied to most standard MCMC algorithms on finite

Advances in Markov chain Monte Carlo
137
spaces. They also show that if qζ (θ, θ′|y) is uniformly bounded on a space with finite measure and
that it is continuous with respect to θ and ζ, then the chain is ergodic. This covers many MCMC
algorithms under the condition that the state space is finite (in practice, we can assume that the
chain lives on a large compact space).
7.4.5 Metropolis-within-Gibbs
Much adaptive MCMC theory has been concerned with direct use of Metropolis–Hasting algo-
rithms on a target distribution. This ignores a large area of application for Metropolis–Hastings
algorithms in applied Bayesian work—as methods for sampling from full conditional distribu-
tion in a Gibbs sampler which have forms that cannot be easily sampled directly. This use of
Metropolis–Hastings methods leads to Metropolis-within-Gibbs algorithms and it is interesting
to ask whether these Metropolis–Hastings samplers can also be made adaptive and whether the
limit theory extends to this more elaborate use. [29] provided initial work in this direction, intro-
ducing the Single Component Adaptive Metropolis (SCAM) algorithm. Suppose that our target
distributionisd-dimensional,thenaMetropolis-within-Gibbsschemecouldbeusedtoupdateeach
dimension consecutively using a Metropolis–Hastings random walk step. The SCAM algorithm is
based on this scheme with the scale of the random walk in each dimension updated using the AM
algorithm (Algorithm 1), and so defines a d-dimensional vector of variancesζ (g) which will be used
in the update of each full conditional distribution at the g-th iteration.
Algorithm 8 Single component adaptive Metropolis (SCAM) algorithm.
1. Initializethestartingvalueθ(0) andζ (0),therequiredMCMCsamplesizeG,burn-inperiod
n0 and g0.
2. for g = 1, 2, . . . , do
3.
for Component j = 1, . . . , d do
4.
Sample θ′
j = θ(g)
j
+ ϵg,j where ϵg,j ∼N(0, ζ (g)
j
).
5.
Let the next iterate be
θ(g+1)
j
=
⎧
⎪⎨
⎪⎩
θ′
j
with prob α(j)
ζ (g)(θ(g)
j
, θ′
j|y)
θ(g)
j
with prob 1 −α(j)
ζ (g)
j
(θ(g), θ′
j|y)
6.
Compute
ζ(g+1)
j
=
⎧
⎪⎪⎨
⎪⎪⎩
ζ(0)
j
if g ≤g0
sd
1
g−1
⎡
⎣g
k=1θ(k)
j
θ(k)
j
T−
g
k=1 θ(k)
j
g
k=1 θ(k)
j
T
g
⎤
⎦+ sdϵ if g > g0
7.
where ϵ is a small, positive constant.
8.
end for
9. end for
10. Return the draws θ(n0+1), . . . , θ(n0+G)
Here, α(j)
ζ (g)(θ(g)
j
, θ′
j|y) represents the acceptance probability of a Metropolis–Hastings algorithm
applied to the j-th full conditional of the target distribution. The ergodicity of this algorithm is
established by [29] under the same conditions as the AM algorithm.

138
J. E. Griffin and D. A. Stephens
Table 7.3 Example 7.9: The average acceptance rate (¯α) and the average squared jumped distance
(¯J) for the SCAM, ASM-SCAM and ASWAM-SCAM algorithms using 100 000 iterations.
SCAM
ASM-SCAM
ASWAM-SCAM
¯α1
0.41
0.23
0.24
¯α2
0.35
0.23
0.23
¯α3
0.42
0.23
0.24
¯α4
0.40
0.23
0.24
¯α5
0.36
0.23
0.24
¯α6
0.35
0.23
0.24
¯α7
0.43
0.23
0.24
¯α8
0.34
0.23
0.24
¯J
0.083
0.063
0.063
The basic approach of the SCAM algorithm is to adapt each Metropolis random walk step
in a Gibbs sampler. This suggests that replacing the AM adaptation with a different adaptation
scheme will not effect ergodicity. [52] suggest replacing the AM algorithm by an ASM algorithm
in the SCAM algorithm and discuss its convergence. Similar arguments could also be made for
the ASWAM and RAM algorithms. The SCAM algorithm can also be extended to samplers where
somefullconditionaldistributionsaremultivariate.ThisallowsmoresophisticatedGibbssamplers
with blocking scheme to be made adaptive. Lastly, ergodicity will not be effected if some full
conditional distributions are not updated adaptively using a Metropolis–Hastings step but can be
directly sampled.
Example
We return to the logistic regression example (Example 7.10) and use the SCAM algorithm and
versions using the ASM algorithm (ASM-SCAM) and the ASWAM algorithm (ASWAM-SCAM)
in place of the AM algorithm for each dimension of the target distribution. The algorithms were
implemented using the same algorithmic parameters as Example 7.8. Table 7.3 shows some results
from running the algorithms for 100 000 iterations. All algorithms converge to the correct posterior
distribution with the ASM-SCAM and ASWAM-SCAM converging to the correct average accep-
tance rate for each full conditional distribution. The average squared jumped distance is larger for
SCAM than for the variation of SCAM that target the average acceptance probability. The average
jumped distances are quite a bit larger than for the joint updating of the regression coefficients.
7.4.6 Other forms of adaptation
We have concentrated on an adaptation algorithm where the target distribution is defined on
a subset of Rd and the scale (in a random walk proposal) or the proposal distribution (in the
Metropolis–Hasings independence sampler) is adapted. Other forms of adaptation have been
proposed in the literature. [37] considered adapting a random scan Gibbs sampler. In a random

Advances in Markov chain Monte Carlo
139
scan Gibbs sampler, one full conditional distribution is chosen to be updated at each iteration and
is chosen at random. Standard implementations of random scan Gibbs sampling choose the full
conditional distributions uniformly at random. [37] considered adapting these probabilities and
showed that the chain can be ergodic under a wide range of updating schemes for the probabilities
and Gibbs samplers.
In regression models, an important problem is variable selection where it assumed that only a
subset of the regressors is needed to accurately predict the response. Each different subset of the
regressors can be considered to be a model for the data. A standard Bayesian model for this problem
assumes a prior on the space of all possible models and a prior on the regression coefficients given
the model. The space of all models is a lattice, since each regressor is either included in the model
or excluded. Therefore, an MCMC chain for this model will run on a lattice (if the regression
coefficients can be marginalized from the posterior analytically) or on the union of subsets of Rp+1
(where p is the number of regressors). For simplicity, we consider the case where the regression
coefficients can be marginalized from the model. A standard Metropolis–Hastings algorithm [see
e.g. 16] proposes to either add a variable to the model, remove a variable from the model, or com-
bines those two moves (an addition and a deletion in the same move). This is markedly different
to the Euclidean spaces considered previously. Several authors have proposed algorithms for this
typeofposteriordistribution.[45]consideredadaptingtheprobabilitiesofincludingandexcluding
variables to the marginal posterior probability that a particular variable is included in the model.
More recently, [35] extended the standard proposal in variable selection to allow more variables
to be added, removed or swapped at each iteration and found that tuning this sampler to have
an average acceptance rate of 0.234 leads to near optimal performance in the regression problems
with many regressors. [36] considered automating the tuning of their algorithm by extending the
ASM algorithm. They found that this leads to efficient methods for variable selection in a variety of
Generalized Linear Models.
7.4.7 Summary
AdaptiveMarkovchainMonteCarlomethodshavebecomeanimportanttoolintheBayesianstatis-
tician’s toolbox. They avoid the need to manually tune random walk Metropolis–Hastings algo-
rithms or to carefully design Metropolis–Hastings independence samplers. This can be extremely
challenging if the target distribution is not low-dimensional or multiple Metropolis–Hastings steps
sitting inside a Gibbs sampler. Following the seminal work of [28], a general framework has been
developed for verifying that an adaptive algorithm will converge correctly based around the idea of
diminishingadaptation.Thisframeworkallowsthedevelopmentofalgorithmswithmultipleforms
of adaptation (such as the ASWAM and RAPT algorithms described in this chapter). This allows
statisticians flexibility in designing sampling schemes and should allow these methods to be used
creativelyinthesamewayasotherMCMCmethods.TheGraphamsoftware[57]allowssimulation
from a hierarchical model using a Metropolis-within-Gibbs framework with a range of adaptive
MCMC algorithms. Further work is still needed to apply these methods in posterior simulation of
complicated Bayesian models.
There are still plenty of future directions for application of these methods. This chapter has
concentratedonsimulationinEuclideanspaceswithalgorithmswhichtargetanaverageacceptance
rate of 0.234. An alternative approach would use directly the average squared jumped distance (or
some other measure of the mixing of the chain) to find the optimal proposal. Initial work in the
direction of using the average squared jumped distance is described by [46]. Work on non-Eu-
clidean spaces has largely been restricted to variable selection problems where the chain works on
a lattice. Other problems naturally lead themselves to adaptive algorithms. [23] consider learning
about the location of structural breaks or outliers in dynamic models.

140
J. E. Griffin and D. A. Stephens
7.5 Chapter summary and discussion
Inthischapter,wehaveoutlinedthekeytheoretical,methodologicalandalgorithmicdevelopments
that sprang from the pioneering work on the application of MCMC to Bayesian statistical infer-
ence. The first and second topics, reversible jump and population methods, rely on application
of the standard theory of MCMC, but apply the standard algorithms in an innovative fashion,
by augmenting the usual Markov chain state space to include auxiliary variables that facilitate
effective exploration of the posterior. The third topic, adaptive MCMC, required extension of the
standard theory, but allowed for the construction of ergodic chains. All three approaches rely on
more expertise on behalf of the algorithm developer than the standard algorithms, and are not
completely automatic, however, typically population and adaptive algorithms are relatively easy
to tune.
It is undoubtedly the case that the approaches discussed in this chapter equip the Bayesian statis-
tician with MCMC tools that greatly enhance the chances of effective computational inference on
a wide range of problems. The population MCMC methods from Section 7.3 dramatically increase
the computational burden, but we feel that multi-chain methods are the most reliable way to ensure
adequate posterior exploration. Adaptation can be achieved relatively cheaply, but as demonstrated
in the examples from Section 7.4, it is often extremely advantageous. The conditions outlined in
7.4.4 are often straightforward to achieve and check, rendering adaptive MCMC a very promising
approach that will become increasingly important in future applied work.
References
[1] Andrieu, C. and Moulines, E. (2006). On the ergodicity properties of some adaptive MCMC
algorithms. Ann. Appl. Prob., 16, 1462–1505.
[2] Andrieu, C. and Thoms, J. (2008). A tutorial on adaptive MCMC. Stat. Comp., 18, 343–373.
[3] Atchadé, Y. and Fort, G. (2010). Limit theorems for some adaptive MCMC algorithms with
subgeometric kernels. Bernoulli, 16, 116–154.
[4] Atchadé, Y. F., Roberts, G. O. and Rosenthal, J. S. (2011). Towards optimal scaling of
Metropolis-coupled Markov chain Monte Carlo. Stat. Comp., 21(4), 555–568.
[5] Atchadé,Y.F.andRosenthal,J.S.(2005).OnadaptiveMarkovchainMonteCarloalgorithms.
Bernoulli, 11, 815–828.
[6] Bai,Y.,Craiu,R.V.andDiNarzo,A.F.(2011).Divideandconquer:Amixture-basedapproach
to regional adaptation for MCMC. J. Comp. Graph. Stat., 20, 63–79.
[7] Behrens, G., Friel, N. and Hurn, M. (2012). Tuning tempered transitions. Stat. Comp., 22,
65–78.
[8] Carlin, B. P. and Chib, S. (1995). Bayesian model choice via Markov chain Monte Carlo. J. R.
Statist. Soc. B, 57, 473–484.
[9] Craiu, R. V., Rosenthal, J. S. and Yang, C. (2009). Learn from thy neighbor: Parallel-chain nad
regional adaptive MCMC. J. Amer. Statist. Assoc., 104, 1454–1466.
[10] Denison, D. G. T., Holmes, C. C., Mallick, B. K. and Smith, A. F. M. (2002). Bayesian Methods
for Nonlinear Classification and Regression. John Wiley.
[11] Gasemyr, J. (2003). An adaptive version of the Metropolis–Hastings algorithm with indepen-
dent proposal distribution. Scand. J. Stat., 30, 159–173.
[12] Gelfand, A. E. and Smith, A. F. M. (1990). Sampling based approaches to calculating marginal
densities. J. Amer. Statist. Assoc., 85, 398–409.
[13] Gelman, A. and Meng, X.-L. (1998). Simulating normalizing constants: From importance
sampling to bridge sampling to path sampling. Statistical Science, 13(2), 163–185.

Advances in Markov chain Monte Carlo
141
[14] Gelman, A., Roberts, G. O. and Gilks, W. R. (1996). Efficient in Metropolis jumping rules.
In Bayesian Statistics 5 (ed. A. P. David, J. O. Berger, J. M. Bernardo and A. F. M. Smith),
pp. 599–608. Oxford University Press, New York.
[15] Geman, S. and Geman, D. (1984). Stochastic relaxation, Gibbs distributions and the Bayesian
restoration of images. IEEE Trans. Patt. Anal. Mach. Intell., 6, 721–741.
[16] George,E.I.andMcCulloch,R.E.(1997).ApproachesforBayesianvariableselection,Volume7.
[17] Geyer, C. J. (1991). Monte Carlo maximum likelihood for dependent data. In Comp. Sci. and
Statis.: Proc. 23rd Symp. Interface, (ed. E. Keramidas), pp. 156–163.
[18] Geyer, C. J. and Møller, J. (1994). Simulation procedures and likelihood inference for spatial
point processes. Scand. J. Stat., 21(4), pp. 359–373.
[19] Geyer, C. J. and Thompson., E. A. (1995). Annealing Markov chain Monte Carlo with appli-
cations to ancestral inference. J. Amer. Statist. Assoc., 90, 909–920.
[20] Gilks, W. R., Richardson, S. and Spiegelhalter, D. J. (1995). Markov Chain Monte Carlo in Prac-
tice: Interdisciplinary Statistics (Chapman & Hall/CRC Interdisciplinary Statistics). Chapman
and Hall/CRC.
[21] Gilks, W. R., Roberts, G. O. and George, E. I. (1994). Adaptive direction sampling. J. R. Statist.
Soc. D (The Statistician), 43(1), pp. 179–189.
[22] Gilks, W. R., Roberts, G. O. and Sahu, S. K. (1998). Adaptive Markov chain Monte Carlo
through regeneration. J. Amer. Statist. Assoc., 93, 1045–1054.
[23] Giordani, P. and Kohn, R. (2008). Efficient Bayesian inference for multiple change-point and
mixture innovation models. J. Bus. Econ. Stat., 26, 66–77.
[24] Giordani,P.andKohn,R.(2010).AdaptiveindependentMetropolis–Hastingsbyfastestima-
tion of mixtures of normals. J. Comp. Graph. Stat., 19, 243–259.
[25] Goswami, G. and Liu, J. S. (2007). On learning strategies for evolutionary Monte Carlo. Stat.
Comp., 17(1), 23–38.
[26] Green, P. J. (1995). Reversible jump Markov chain Monte Carlo computation and Bayesian
model determination. Biometrika, 82(4), 711–732.
[27] Grenander,U.andMiller,M.(1994).Representationsofknowledgeincomplexsystems(with
discussion). J. R. Statist. Soc. B, 56(4), 549–603.
[28] Haario, H., Saksman, E. and Tamminen, J. (2001). An adaptive Metropolis algorithm.
Bernoulli, 7, 223–242.
[29] Haario, H., Saksman, E. and Tamminen, J. (2005). Componentwise adaptation for high
dimensional MCMC. Computat. Stat., 20, 265–273.
[30] Jasra, A., Holmes, C. C. and Stephens, D. A. (2005). MCMC and the label switching problem
in Bayesian mixture models. Statistical Science, 20, 50–67.
[31] Jasra,A.,Stephens,D.A.andHolmes,C.C.(2007).Onpopulation-basedsimulationforstatic
inference. Stat. Comp., 17, 263–279. 10.1007/s11222-007-9028-9.
[32] Jasra,A.,Stephens,D.A.andHolmes,C.C.(2007).Population-basedreversiblejumpMarkov
chain Monte Carlo. Biometrika, 94(4), 787–807.
[33] Kirkpatrick, S., Jr., Gelatt, C. D. and Vecchi, M. P. (1983). Optimization by simulated anneal-
ing. Science, 220, 671–680.
[34] Kou, S. C., Zhou, Q. and Wong, W. H. (2006). Equi-energy sampler with applications in
statistical inference and statistical mechanics. Ann. Stat., 34(4), pp. 1581–1619.
[35] Lamnisos, D., Griffin, J. E. and Steel, M. F. J. (2009). Transdimensional sampling algorithms
for Bayesian variable selection in classification problems with many more variables than
observations. J. Comp. Graph. Stat., 18, 592–612.
[36] Lamnisos, D., Griffin, J. E. and Steel, M. F. J. (2011). Adaptive Monte Carlo for Bayesian
variable selection in regression models. Technical Report. University of Warwick.
[37] Latuszynski, K., Robert, G. O. and Rosenthal, J. S. (2012). Adaptive Gibbs samplers and
related MCMC methods. Ann. Appl. Prob. (to appear).

142
J. E. Griffin and D. A. Stephens
[38] Liang, F., Liu, C. and Carroll, R. J. (2010). Advanced Markov Chain Monte Carlo Methods:
Learning from Past Samples. Wiley Series in Computational Statistics. John Wiley & Sons.
[39] Liang, F. M. and Wong, W. H. (2001). Real-parameter evolutionary Monte Carlo with appli-
cations to Bayesian mixture models. J. Amer. Statist. Assoc., 96(454), 653–666.
[40] Liu, J. S., Liang, F. and Wong, W. H. (2000). The multiple-try method and local optimization
in Metropolis sampling. J. Amer. Statist. Assoc., 95(449), 121–134.
[41] Marinari, E. and Parisi, G. (1992). Simulated Tempering: A New Monte Carlo Scheme. Euro-
phys. Lett., 19(6), 451.
[42] Mengersen, K. L. and Tweedie, R. L. (1996). Rates of convergence of the Hastings and
Metropolis algorithms. Ann. Stat., 24, 101–121.
[43] Neal, R. M. (1996). Sampling from multimodal distributions using tempered transitions.Stat.
Comp., 6, 353–366. 10.1007/BF00143556.
[44] Neal, R. M. (2001). Annealed importance sampling. Stat. Comp., 11(2), 125–139.
[45] Nott, D. J. and Kohn, R. (2005). Adaptive sampling for Bayesian variable selection.
Biometrika, 92, 747–763.
[46] Pasarica, C. and Gelman, A. (2010). Adaptively scaling the Metropolis algorithm using
expected squared jumped distance. Stat. Sin., 20, 343–364.
[47] Phillips, D. B. and Smith, A. F. M. (1995). Bayesian model comparison via jump diffusions. In
Markov Chain Monte Carlo in Practice, (ed. W. R. Gilks, S. R. Richardson, and D. J. Spiegelhal-
ter). Chapman and Hall, London.
[48] Richardson, S. and Green, P. J. (1997). On Bayesian Analysis of Mixtures with an Unknown
Number of Components (with discussion). J. R. Statist. Soc. B, 59(4), 731–792.
[49] Roberts, G. O., Gelman, A. and Gilks, W. R. (1997). Weak convergence and optimal scaling
of random walk Metropolis algorithms. Ann. Appl. Prob., 7, 110–120.
[50] Roberts, G. O. and Rosenthal, J. S. (2001). Optimal scaling for various Metropolis–Hastings
algorithms. Statist. Sci., 16, 351–367.
[51] Roberts, G. O. and Rosenthal, J. S. (2007). Coupling and ergodicity of adaptive MCMC.
J. Appl. Prob., 44, 458–475.
[52] Roberts, G. O. and Rosenthal, J. S. (2009). Examples of adaptive MCMC. J. Comp. Graph.
Stat., 18, 349–367.
[53] Saksman, E. and Vihola, M. (2010). On the ergodicity of the adaptive Metropolis algorithm
on unbounded domains. Ann. Appl. Prob., 20, 2178–2203.
[54] Stephens, M. (2000). Bayesian analysis of mixture models with an unknown number of
components - an alternative to reversible jump methods. Ann. Stat., 28(1), 40–74.
[55] Tierney, L. (1994). Markov chains for exploring posterior distributions. Ann. Stat., 22,
1701–1762.
[56] Tierney, L. (1998). A note on Metropolis–Hastings kernels for general state spaces. Ann. Appl.
Prob., 8(1), pp. 1–9.
[57] Vihola, M. (2010). Grapham: Graphical models with adaptive random walk Metropolis algo-
rithms. Comput. Stat. Data Anal., 54, 49–54.
[58] Vihola, M. (2012). Robust adaptive Metropolis algorithm with coerced acceptance rate. Stat.
Comp. (to appear).

Part IV
Dynamic Models

This page intentionally left blank 

8
Bayesian dynamic
modelling
mike west
8.1 Introduction
B
ayesian time series and forecasting is a very broad field and any attempt at other than a very
selective and personal overview of core and recent areas would be foolhardy. This chapter
therefore selectively notes some key models and ideas, leavened with extracts from a few time series
analysis and forecasting examples. For definitive development of core theory and methodology of
Bayesian state-space models, readers are referred to [46, 74] and might usefully read this chapter
with one or both of the texts at hand for delving much further and deeper. The latter parts of the
chapter link into and discuss a range of recent developments on specific modelling and applied
topics in exciting and challenging areas of Bayesian time series analysis.
8.2 Core model context: Dynamic linear model
8.2.1 Introduction
Much of the theory and methodology of all dynamic modelling for time series analysis and fore-
casting builds on the theoretical core of linear, Gaussian model structures: the class of univariate
normal dynamic linear models (DLMs or NDLMs). Here we extract some key elements, ideas
and highlights of the detailed modelling approach, theory of model structure and specification,
methodology and application.
Over a period of equally spaced discrete time, a univariate time series y1:n is a sample from a
DLM with p−vector state θt when
yt = xt + νt,
xt = F′
tθt,
θt = Gtθt−1 + ωt,
t = 1, 2, . . . ,
(8.1)
where: each Ft is a known regression p−vector; each Gt a p × p state transition matrix; νt is
univariate normal with zero mean; ωt is a zero-mean p−vector representing evolution noise, or
innovations; the pre-initial state θ0 has a normal prior; the sequences νt, ωt are independent and
mutually independent, and also independent of θ0. DLMs are hidden Markov models; the state
vector θt is a latent or hidden state, often containing values of underlying latent processes as well as
time-varying parameters (Chapter 4 of [74]).

146
M. West
8.2.2 Core example DLMs
Key special cases are distinguished by the choice of elements Ft, Gt. This covers effectively all
relevant dynamic linear models of fundamental theoretical and practical importance. Some key
examples that underlie much of what is applied in forecasting and time series analysis are as
follows.
Random walk in noise (Chapter 2 of [74]): p = 1, Ft = 1, Gt = 1 gives this first-order polyno-
mial model in which the state xt ≡θt1 ≡θt is the scalar local level of the time series, varying
as a random walk itself.
Local trend/polynomial DLMs (Chapter 7 of [74]): Ft = Ep = (1, 0, · · · , 0)′ and Gt = Jp, the
p × p matrix with 1s on the diagonal and super-diagonal, and zeros elsewhere, define ‘locally
smoothtrend’DLMs;elementsofθt arethelocalleveloftheunderlyingmeanoftheseries,local
gradient and change in gradient etc., each undergoing stochastic changes in time as a random
walk.
Dynamic regression (Chapter 9 of [74]): When Gt = Ip, the DLM is a time-varying regression
parameter model in which regression parameters in θt evolve in time as a random walk.
Seasonal DLMs (Chapter 8 of [74]): Ft = E2 and Gt = rH(a) where r ∈(0, 1) and
H(a) =

cos(a) sin(a)
−sin(a) cos(a)

for any angle a ∈(0, 2π) defines a dynamic damped seasonal, or cyclical, DLM of period 2π/a,
with damping factor r per unit time.
Autoregressive and time-varying autoregressive DLMs (Chapter 5 of [46]): Here Ft = Ep and Gt
depends on a p−vector φt = (φt1, . . . , φtp)′ as
Gt =
⎛
⎜⎜⎜⎜⎜⎝
φt1 φt2 φt3 · · · φtp
1
0
0 · · · 0
0
1
0 · · · 0
...
... · · ·
...
0
0
· · · 1
0
⎞
⎟⎟⎟⎟⎟⎠
,
with, typically, the evolution noise constrained as ωt = (ωt1, 0, . . . , 0)′. Now yt = xt + νt
wherext ≡θt1 andxt = 
j=1:p φtjxt−j + ωt1,atime-varyingautoregressiveprocessoforder
p, or TVAR(p). The data arise through additive noisy observations on this hidden or latent
process.
If the φtj are constant over time, xt is a standard AR(p) process; in this sense, the main class of
traditional linear time series models is a special case of the class of DLMs.
8.2.3 Time series model composition
Fundamentaltostructuringappliedmodelsistheuseofbuildingblocksascomponentsofanoverall
model—the principle of composition or superposition (Chapter 6 of [74]). DLMs do this naturally
by collecting together components: given a set of individual DLMs, the larger model is composed
by concatenating the individual component θt vectors into a longer state vector, correspondingly

Bayesian dynamic modelling
147
concatenating the individual Ft vectors, and building the associated state evolution matrix as the
block diagonal of those of the component models. For example,
F′ = (1, ft, E′
2, E′
2, E′
2),
G = block diag

1, 1, H(a1), H(a2),

φ1 φ2
1
0

(8.2)
defines the model for the signal as
xt = θt1 + θt2ft + ρt1 + ρt2 + zt
where:
• θt1 is a local level/random walk intercept varying in time;
• θt2 is a dynamic regression parameter in the regression on the univariate predic-
tor/independent variable time series ft;
• ρtj is a seasonal/periodic component of wavelength 2π/aj for j = 1, 2, with time-varying
amplitudes and phases—often an overall annual pattern in weekly or monthly data, for exam-
ple, can be represented in terms of a set of harmonics of the fundamental frequency, such as
would arise in the example here with a1 = π/6, a2 = π/3 yielding an annual cycle and a
semi-annual (six month) cycle;
• zt is an AR(2) process—a short-term correlated underlying latent process—that represents
residual structure in the time series signal not already captured by the other components.
8.2.4 Sequential learning
Sequential model specification is inherent in time series, and Bayesian learning naturally proceeds
with a sequential perspective (Chapter 4 of [46]). Under a specified normal prior for the latent
initial state θ0, the standard normal/linear sequential updates apply: at each time t −1 a ‘current’
normal posterior evolves via the evolution equation to a 1-step ahead prior distribution for the next
state θt; observing the data yt then updates that to the time t posterior, and we progress further
in time sequentially. Missing data in the time series is trivially dealt with: the prior-to-posterior
update at any time point where the observation is missing involves no change. From the early
days—in the 1950s—of so-called Kalman filtering in engineering and early applications of Bayesian
forecasting in commercial settings (Chapter 1 of [74]), this framework of closed-form sequential
updating analysis—or forward filtering of the time series—has been the centrepiece of the com-
putational machinery. Though far more complex, elaborate, nonlinear and non-normal models
are used routinely nowadays, based on advances in simulation-based computational methods, this
normal/lineartheorystillplayscentralandcriticalrolesinappliedworkandascomponentsofmore
elaborate computational methods.
8.2.5 Forecasting
Forecasting follows from the sequential model specification via computation of predictive distri-
butions. At any time t with the current normal posterior for the state θt based on data y1:t, and
any other information integrated into the analysis, we simply extrapolate by evolving the state
through the state evolution equation into the future, with implied normal predictive distributions

148
M. West
for sequences θt+1:t+k, yt+1:t+k into the future any k > 0 steps ahead. Forecasting via simulation
is also key to applied work: simulating the process into the future—to generate ‘synthetic reali-
ties’—is often a useful adjunct to the theory, as visual inspection (and perhaps formal statistical
summaries) of simulated futures can often aid in understanding aspects of model fit/misfit as
well as formally elaborating on the predictive expectations defined by the model and fit to his-
torical data; see Figures 8.2 and 8.3 for some aspects of this in the analysis of the climatological
Southern Oscillation Index (SOI) time series, discussed later in Section 8.3.2. The concept is also
illustrated in Figure 8.4 in a multivariate DLM analysis of a financial time series, discussed later in
Section 8.4.1.
8.2.6 Retrospective time series analysis
Time series analysis—investigating posterior inferences and aspects of model assessment based on
a model fitted to a fixed set of data—relies on the theory of smoothing or retrospective filtering that
overlays forward-filtering, sequential analysis. Looking back over time from a current time t, this
theory defines the revised posterior distributions for historical sequences of state vectors θt−1:t−k
for k > 0 that complement the forward analysis (Chapter 4 of [74]).
8.2.7 Completing model specification: Variance components
TheBayesiananalysisoftheDLMforappliedworkisenabledbyextensionsofnormaltheory-based
sequential analysis to incorporate learning on the observational variance parameters V(νt) and
specification of the evolution variance matrices V(ωt). For the former, analytic tractability is main-
tained in models where V(νt) = ktvt, with known variance multipliers kt, and V(ωt) = vtWt with
two variants: (i) constant, unknown vt = v (Section 4.3.2 of [46]) and (ii) time-varying obser-
vational variances in which vt follows a stochastic volatility model based on variance discount-
ing—a random walk-like model that underlies many applications where variances are expected to
be locally stable but globally varying (Section 4.3.7 of [46]). Genesis and further developments
are given in Chapter 10 of [74] and, with recent updates and new extensions, in Chapters 4,7
and 10 of [46].
Theuseofdiscountfactorstostructureevolutionvariancematriceshasbeenandremainscentral
to many applications (Chapter 6 of [74]). In models with non-trivial state vector dimension p,
we must maintain control over the specification of Wt to avoid exploding the numbers of free
parameters. In many cases, we are using Wt to reflect low levels of stochastic change in elements
of the state. When the model is structured in terms of block components via superposition as
describedabove,theWt matrix isnaturallystructuredinacorrespondingblockdiagonalform;then
the strategy of specifying these blocks in Wt using the discount factor approach is natural (Section
4.3.6 of [46]). This strategy describes the innovations for each component of the state vector
as contributing a constant stochastic ‘rate of loss of information’ per time point, and these rates
may be chosen as different for different components. In our example above, a dynamic regression
parameter might be expected to vary less rapidly over time than, perhaps, the underlying local
trend.
Central to many applications of Bayesian forecasting, especially in commercial and economic
studies, is the role of ‘open modelling’. That is, a model is often one of multiple ways of describing
a problem, and as such should be open to modification over time, as well as integration with other
formal descriptions of a forecasting problem (Chapter 1 of [74]). The role of statistical theory in
guiding changes—interventions to adapt a model at any given time based on additional informa-
tion—that maintain consistency with the model is then key. Formal sequential analysis in a DLM

Bayesian dynamic modelling
149
frameworkcanoftenmanagethisviaappropriatechangesinthevariancecomponents.Forexample,
treating a single observation as of poorer quality, or a likely outlier, can be done via an inflated
variance multiplier kt; feeding into the model new/external information that suggests increased
chances of more abrupt change in one or more components of a state vector can be done via
larger values of the corresponding elements of Wt, typically using a lower discount factor in the
specification for just that time, or times, when larger changes are anticipated. Detailed development
of a range of subjective monitoring and model adaptation methods of these forms, with examples,
are given in chapters 10–12 of [74] and throughout [43]; see also Chapter 4 of [46] and earlier
relevant papers [62, 72, 73].
8.2.8 Time series decomposition
Complementing the strategy of model construction by superposition of component DLMs is the
theory and methodology of model decomposition that is far-reaching in its utility for retrospective
timeseries analysis (Chapter 9of [74]).Originallyderivedfor theclass of time series DLMs in which
Ft = F, Gt = G are constant for all time [66–70], the theory of decompositions applies also to
time-varying models [44, 45, 47]. The context of DLM AR(p) and TVAR(p) models—alone or as
components of a larger model—is key in terms of the interest in applications in engineering and the
sciences, in particular (Chapter 5 of [46]).
Consider a DLM where one model component zt follows a TVAR(p) model. The main idea
comes from the central theoretical results that a DLM implies a decomposition of the form
zt =

j=1:C
zc
tj +

j=1:R
zr
tj
where each z∗
tj is an underlying latent process: each zr
tj is a TVAR(1) process and each zc
tj is a quasi--
cyclical time-varying process whose characteristics are effectively those of a TVAR(2) overlaid
with low levels of additive noise, and which exhibits time-varying periodicities with stochastically
varying amplitude, phase and period. In the special case of constant AR parameters, the periods of
these quasi-cyclical zc
tj processes are also constant.
This DLM decomposition theory underlies the use of these models—state-space models/
DLMs with AR and TVAR components—for problems in which we are interested in a potentially
very complicated and dynamic autocorrelation structure, and aim to explore underlying contribu-
tions to the overall signal that may exhibit periodicities of a time-varying nature. Many examples
appear in [46, 74] and references there, as well as the core papers referenced above. Figures 8.1, 8.2
and 8.3 exemplify some aspects of this in the analysis of the climatological Southern Oscillation
Index (SOI) time series of Section 3.2.
8.3 Computation and model enrichment
8.3.1 Parameter learning and batch analysis via MCMC
Overthelastcoupleofdecades,methodologyandapplicationsofBayesiantimeseriesanalysishave
massively expanded in non-Gaussian, nonlinear and more intricate conditionally linear models.
The modelling concepts and features discussed above are all central to this increasingly rich field,
while much has been driven by enabling computational methods.

150
M. West
Consider the example DLM of equation (8.2) and now suppose that V(νt) = ktv with known
weights kt but uncertain v to be estimated, and the evolution variance matrix is
Wt ≡W = block diag

τ1, τ2, τ3I2, τ4I2,

w 0
0 0

.
(8.3)
Also, write φ = (φ1, φ2)′ for the AR parameters of the latent AR(2) model component. The DLM
can be fitted using standard theory assuming the full set of model parameters μ = {v, φ, w, τ1:4}
to be known. Given these parameters, the forward filtering and smoothing based on normal/linear
theory applies.
Markov chain Monte Carlo methods naturally open the path to a complete Bayesian analysis
under any specified prior p(μ); see Chapter 15 of [74] and Section 4.5 of [46] for full details and
copious references, as well as challenging applications in Chapter 7 of [46]. Given an observed data
sequence y1:n, MCMC iteratively re-simulates parameters and states from appropriate conditional
distributions.Thisinvolvesconditionalsimulationsofelementsofμconditioningoncurrentvalues
of other parameters and a current set of states θ0:n that often break down into tractable parallel
simulators. The example above is a case in point under independent priors on φ and the variances
v, τj, w, for example.
Central to application is the forward filtering, backward sampling (FFBS—[6, 18]) algorithm
that arises naturally from the normal/linear theory of the DLM conditional on parameters μ.
This builds on the sequential, forward filtering theory to run through the data, updating poste-
rior distributions for states over time, and then steps back in time: at each point t = n, t = n −
1, . . . , t = 1, t = 0inturn,theretrospectivedistributionaltheoryofthisconditionallylinear,normal
model provides normal distributions for the states that are simulated. This builds up a sequence
{θn, θn−1, . . . , θ1, θ0} that represents a draw—sampled via composition backwards in time—from
the relevant conditional posterior p(θ0:n|μ, y1:n). The use of MCMC methods also naturally deals
with missing data in a time series; missing values are, by definition, latent variables that can be
simulated via appropriate conditional posteriors each step of the MCMC.
8.3.2 Example: SOI time series
Figures 8.1, 8.2 and 8.3 show aspects of an analysis of the climatological Southern Oscillation Index
(SOI) time series. This is a series of 540 monthly observations computed as the ‘difference of
the departure from the long-term monthly mean sea level pressures’ at Tahiti in the South Pacific
and Darwin in Northern Australia. The index is one measure of the so-called ‘El Nino-Southern
Oscillation’—aneventofcriticalimportanceandinterestinclimatologicalstudiesinrecentdecades
which is generally understood to vary periodically with a very noisy 3–6 year period of quasi-cyclic
pattern. As discussed in [24]— which also details the history of the data and prior analyses—one
of several applied interests in this data is in improved understanding of these quasi-periodici-
ties and also potential non-stationary trends, in the context of substantial levels of observational
noise.
The DLM chosen here is yt = θt1 + zt + νt where θt1 is a first-order polynomial local
level/trend and zt is an AR(12) process. The data is monthly data over the year, so the AR com-
ponent provides opportunities to identify even quite subtle longer-term (multi-year) periodici-
ties that may show quite high levels of stochastic variation over time in amplitude and phase.
Extensions to TVAR components would also allow the associated periods to vary as discussed
and referenced above. Here the model parameters include the 12-dimensional AR parameter φ
that can be converted to autoregressive roots (Section 9.5 of [74]) to explore whether the AR
componentappearstobeconsistentwithanunderlyingstationaryprocessornot,aswellastomake

Bayesian dynamic modelling
151
inferences on the periods/wavelengths of any identified quasi-periodic components. The analysis
also defines posterior inferences for the time trajectories of all latent components zr
tj and zc
tj by
applying the decomposition theory to each of the posterior simulation samples of the state vector
sequence θ0:n.
Figure 8.1 shows approximate posteriors for the moduli of the 12 latent AR roots, all very likely
positive and almost surely less than 1, indicating stationarity of zt in this model description. The
figure also shows the corresponding posterior for the wavelength of the latent process component
zc
tj having highest wavelength, indicating a dominant quasi-periodicity in the data with wavelength
between 40–70 months—a noisy ‘4-year’ phenomenon, consistent with expectations and prior
studies. Figure 8.2 shows a few posterior samples of the time trajectory of the latent trend θt1,
together with its approximate posterior mean, superimposed on the data. The inference is that of
very limited change over time in the trend in the context of other model components. This figure
also shows the data plotted together with a ‘synthetic future’ over the next three years: that is, a
single draw from the posterior predictive distribution into the future. From the viewpoint of model
fit, exploring such synthetic futures via repeat simulations studied by eye in comparison with the
data can be most informative; they also feed into formal predictive evaluations for excursions away
from (above/below) the mean, for example [24].
Additional aspects of the decomposition analysis are represented by Figure 8.3. The first frame
shows the posterior mean of the fitted AR(12) component plotted over time (labelled as ‘data’ in
the upper figure), together with the corresponding posterior mean trajectories of the three latent
quasi-cyclical components having largest inferred periods, all plotted on the same vertical scale.
Evidently, the dominant period component explains much of the structure in the AR(12) process,
the second contributing much of the additional variation at a lower wavelength (a few months).
The remaining components contribute to partitioning the noise in the series and have much lower
amplitudes. The figure also shows several posterior draws for the zt processes to give some indica-
tion of the levels of uncertainty about its form over the years.
Figure 8.1 Left frame: Approximate posterior 95% credible intervals for the moduli of the 12 latent
AR roots in the AR component of the model fitted to the SOI time series. Right frame: Approximate
posterior for the wavelength of the latent process component zc
tj with largest wavelength, indicating
a dominant quasi-periodicity in the range 40–70 months.

152
M. West
Figure 8.2 Upper frame: Scatter plot of the monthly SOI index time series superimposed on the
trajectories of the posterior mean and a few posterior samples of the underlying trend. Lower
frame: SOI time series followed by a single synthetic future—a sample from the posterior predictive
distribution over the three or fours years following the end of the data in 1995; the corresponding
sample of the predicted underlying trend is also shown.
8.3.3 Mixture model enrichment of DLMs
Mixture models have been widely used in dynamic modelling and remain a central theme in anal-
yses of structural change, approaches to modelling non-Gaussian distributions via discrete mix-
ture approximations, dealing with outlying observations, and others. Chapter 12 of [74] develops
extensive theory and methodology of two classes of dynamic mixture models, building on seminal
work by P.J. Harrison and others [23]. The first class relates to model uncertainty and learning
model structure that has its roots in both commercial forecasting and engineering control systems
applicationsofDLMsfromthe1960s.HereasetofDLMsareanalysedsequentiallyinparallel,being
regarded as competing models, and sequentially updated ‘model probabilities’ track the data-based

Bayesian dynamic modelling
153
Figure 8.3 Aspects of decomposition analysis of the SOI series. Upper frame: Posterior means
of (from the bottom up) the latent AR(12) component zt (labelled as ‘data’), followed by the three
extracted component zc
tj for j = 1, 2, 3, ordered in terms of decreasing estimated periods; all are
plotted on the same vertical scale, and the AR(12) process is the direct sum of these three and
subsidiary components. Lower frame: A few posterior samples (in grey) of the latent AR(12) process
underlying the SOI series, with the approximate posterior mean superimposed.
evidence for each relative to the others, in what is nowadays a familiar model comparison and
Bayesian model-averaging framework.
Thesecondframework—adaptivemulti-processmodels—entertainsmultiplepossiblemodelsat
each time point and aims to adaptively reweight sequentially over time; key examples are modelling
outliers and change-points in subsets of the state vector as in applications in medical monitoring,
for example [55, 56]. In the DLM of equation (8.2) with a ‘standard’ model having V(νt) = v and
evolutionvariancematrixasinequation(8.3),amulti-processextensionforoutlieraccommodation
would consider a mixture prior induced by V(νt) = ktv where, at each time t, kt may take the value
1 or, say, 100, with some probability. Similarly, allowing for a larger stochastic change in the under-
lying latent AR(2) component zt of the model would involve an extension so that the innovations

154
M. West
variance w in equation (8.3) is replaced by htw, where now ht may take the value 1 or 100, with some
probability. These multi-process models clearly lead to a combinatorial explosion of the numbers
of possible ‘model states’ as time progresses, and much attention has historically been placed on
approximating the implied unwieldy sequential analysis. In the context of MCMC methods and
batch analysis, this is resolved with simulation-based numerical approximations where the intro-
duction of indicators of mixture component membership naturally and trivially opens the path to
computation: models are reduced to conditionally linear, normal DLMs for conditional posterior
simulations of states and parameters, and then the mixture component indicators are themselves
re-simulated each step of the MCMC. Many more elaborate developments and applications appear
in, and are referenced by, [19] and Chapter 7 of [46].
AnotheruseofmixturesinDLMsistodefinedirectapproximationstonon-normaldistributions,
so enabling MCMC analysis based on conditionally normal models that they imply. One key exam-
ple is the univariate stochastic volatility model pioneered by [26, 53] which is nowadays in routine
use to define components of more elaborate dynamic models for multivariate stochastic volatility
time series approaches [1, 2, 12, 36, 37, 41]; see also Chapter 7 of [46].
8.3.4 Sequential simulation methods of analysis
A further related use of mixtures is as numerical approximations to the sequentially updated pos-
terior distributions for states in non-linear dynamic models when the conditionally linear strategy
is not available. This use of mixtures of DLMs to define adaptive sequential approximations to the
filtering analysis by ‘mixing Kalman filters’ [3, 11] has multiple forms, recently revisited with some
recent extensions in [38]. Mixture models as direct posterior approximations, and as sequences of
sequentially updated importance sampling distributions for nonlinear dynamic models were pio-
neered in [63–65], and some of the recent developments build on this.
The adaptive, sequential importance sampling methods of [65] represented an approach to
sequential simulation-based analysis developed at the same time as the approach that became
known as particle filtering [21]. Bayesian sequential analysis in state-space models using ‘clouds
of particles’ in states and model parameters, evolving the particles through evolution equations
that may be highly nonlinear and non-Gaussian, and appropriately updating weights associated
with particles to define approximate posteriors, has defined a fundamental change in numerical
methodology for time series. Particle filtering and related methods of sequential Monte Carlo
(SMC) [7, 14], including problems of parameter learning combined with filtering on dynamic
states [31], are reviewed in this book: see the chapter by H.F. Lopes and C.M. Carvalho, on Online
Bayesian learning ....
Recent methods have used variants and extensions of the so-called technique of approximate
Bayesian computation [34, 54]. Combined with other SMC methods, this seems likely to emerge
in coming years as a central approach to computational approximation for sequential analysis in
increasingly complex dynamic models; some recent studies in dynamic modelling in systems biol-
ogy [4, 35, 58] provide some initial examples using such approaches.
8.4 Multivariate time series
The basic DLM framework generalizes to multivariate time series in a number of ways, including
multivariate non-Gaussian models for time series of counts, for example [5], as well as a range of
modelclassesbasedonmulti-andmatrix-variatenormalmodels(Chapter10of[46]).Financialand
econometric applications have been key motivating areas, as touched on below, while multivariate

Bayesian dynamic modelling
155
DLMs are applied in many other fields—as diverse as experimental neuroscience [1, 27, 28, 47],
computer model emulation in engineering [30] and traffic flow forecasting [57]. Some specific
modelclassesthatareinmainstreamapplicationandunderlierecentandcurrentdevelopments—e-
specially to increasingly high-dimensional times series—are keyed out here.
8.4.1 Multivariate normal DLMs: Exchangeable time series
In modelling and forecasting a q × 1 vector times series, a so-called exchangeable time series DLM
has the form
y′t = F′tt + ν′t,
νt ∼N(0, t)
t = Gtt−1 + t, t ∼N(0, Wt, t)
(8.4)
where N(·, ·, ·) denotes a matrix normal distribution (Section 10.6 of [46]). Here the row vector
y′t follows a DLM with a matrix state t. The q × q time-varying variance matrix t determines
patterns of co-changes in observation and the latent matrix state over time. These models are
building blocks of larger (factor, hierarchical) models of increasing use in financial time series and
econometrics; see, for example, [48, 49], Chapter 16 of [74] and Chapter 10 of [46].
Modelling multivariate stochastic volatility—the evolution over time of the variance matrix
series t—is central to these multivariate extensions of DLMs. The first multivariate stochastic
volatilitymodelsbasedonvariancematrixdiscountlearning[50,51],laterdevelopedviamatrix-beta
evolution models [59, 60], and remain central to many implementations of Bayesian forecasting in
finance. Here t evolves over one time interval via a nonlinear stochastic process model involving a
matrixbetarandominnovationinducingpriorsandposteriorsofconditionalinverseWishartforms.
The conditionally conjugate structure of the exchangeable model form for {t, t}, coupled with
discount factor-based specification of the Wt evolution variance matrices, leads to a direct exten-
sion of the closed form sequential learning and retrospective sampling analysis of the univariate
case (Chapter 10 of [46]). In multiple studies, these models have proven their value in adapting
to short-term stochastic volatility fluctuations and leading to improved portfolio decisions as a
result [48].
An example analysis of a time series of q = 12 daily closing prices (FX data) of international
currenciesrelativetotheUSdollar,previouslyanalysedusingdifferentmodels(Chapter10of[46]),
generatessomesummariesincludingthoseinFigures8.4and8.5.Themodelusedhereincorporates
time-varying vector autoregressive (TV-VAR) models into the exchangeable time series structure.
With yt the logged values of the 12−vector of currency prices at time t, we take Ft to be the
37−dimensional vector having a leading 1 followed by the lagged values of all currencies over the
last three days. The dynamic autoregression naturally anticipates the lag-1 prices to be the prime
predictors of next time prices, while considering 3-day lags leads to the opportunity to integrate
‘market momentum’. Figure 8.4 selects one currency, the Japanese Yen, and plots the data together
with forecasts over the last several years. As the sequential updating analysis proceeds, forecasts on
day t for day t + 1 are made by direct simulation of the 1-step-ahead predictive distribution; each
forecast vector yt+1 is then used in themodel in order to usethesamesimulation strategy to sample
the future at time t + 2 from the current day t, and this is repeated to simulate day t + 3. Thus we
predict via the strategy of generating synthetic realities, and the figure shows a few sets of these
3-day-ahead forecasts made every day over three or four years, giving some indication of forecast
uncertainty as well as accuracy.
Figure 8.5 displays some aspects of multivariate volatility over time as inferred by the analysis.
Four images of the posterior mean of the precision matrix −1
t
at four selected time points capture

156
M. West
1/87
–5.2
–5.1
–5
–4.9
–4.8
–4.7
–4.6
–4.5
–4.4
–4.3
–4.2
JPY
1/88
1/89
1/90
1/91
1/92
month/year
1/93
1/94
1/95
Data
3-step ahead forecasts
1/96
Figure 8.4 Daily prices of the Japanese Yen in US dollars over several years in the 1980s–1990s,
followed by plots of forecasts from the multivariate TV-TVAR model with stochastic volatility fitted to
a 12-dimensional FX time series of which the Yen is one element. The shaded forecast region is
made up of 75 sets of 3-day-ahead forecasts based on the sequential analysis: on each day, the
‘current’ posterior for model states and volatility matrices is simulated to generate forecasts over the
next three days.
some flavour of time variation, while the percentage of the total variation in the posterior mean
of t explained by the first three dominant principal components at each t captures additional
aspects.
8.4.2 Multivariate normal DLMs: Dynamic latent factor
and TV-VAR models
Time-varying vector autoregressive (TV-VAR) models define a rich and flexible approach to mod-
elling multivariate structure that allows the predictive relationships among individual scalar ele-
mentsofthetimeseriestoevolveovertime.Theabovesectionhasalreadydescribedtheuseofsuch
a model within the exchangeable time series framework. Another way in which TV-VAR models
are used is to represent the dynamic evolution of a vector of latent factors underlying structure
in a higher-dimensional data series. One set of such dynamic latent factor TV-VAR models has
the form
yt = Ftθt + Btxt + νt,
νt ∼N(0, ),
xt = 
i=1:p Atixt−i + ωt, ωt ∼N(0, t).
(8.5)
Here xt is a latent k−vector state process following a TV-VAR(p) model with, typically, k << q so
that the common structure among the elements of yt is heavily driven by a far lower-dimensional
dynamic state. The set of p, q × q autoregressive coefficient matrices Ati is often time-varying with
elements modelled via, for example, sets of univariate AR(1) processes or randomwalks.Thefactor

Bayesian dynamic modelling
157
Figure 8.5 Upper frames: Images of posterior estimates of the 12 × 12 precision matrices −1
t
in
the analysis of the multivariate currency prices time series. The differences in patterns visually evident
reflect the extent and nature of changes in the volatility structure across time, as represented by the
four selected time points spaced apart by a few hundred days. Lower frame: Percentage variation
explained by the first three dominant principal components of the posterior mean of t for each
time t = 1 : n over the FX time series, illustrating the nature of variation in the contribution of the
main underlying ‘common components’ of volatility in the 12 currency price series over the ten year
period.
loadings matrix Bt maps factors to data; in some models, including prior Bayesian factor analysis
approaches [2], this will be taken as constant. The k × k dynamic covariance matrix t drives the
innovations of the state evolution, and allowing for stochastic volatility here defines an enrichment
of the TV-VAR structure. The additional component Ftθt superimposed may include dynamic
regressionandotherterms,withrelevantstateevolutionequationsforθt.Suchmodelsarereceiving
increasing use in natural science and engineering applications [15, 16, 20, 45, 46, 75] as well as in
econometrics and finance [36, 37]. Chapters 8 and 9 of [46] describe aspects of the theory and
methodology of vector AR and TVAR models, connections with latent factor modelling in studies
of multiple time series in the neurosciences, and discussion of multiple other creative applications
of specialized variants of this rich class of models. The model contains traditional DLMs, VAR
models, latent factor models as previously developed, as well as the more elaborate TV-VAR factor
forms.

158
M. West
8.5 Some recent and current developments
Among a large number of recent and currently active research areas in Bayesian time series analysis
and forecasting, a few specific modelling innovations that relate directly to the goals of addressing
analysis of increasingly high-dimensional time series and nonlinear models are keyed out.
8.5.1 Dynamic graphical and matrix models
A focus on inducing parsimony in increasingly high-dimensional, time-varying variance matrices in
dynamic models has led to the integration of Bayesian graphical modelling ideas into exchangeable
time series DLMs [9, 10]. The standard theory of Gaussian graphical models using hyper-inverse
Wishart distributions—the conjugate priors for variance matrices whose inverses −1
t
have
some off-diagonal elements at zero corresponding to an underlying conditional independence
graph[13]—rathersurprisinglyextendsdirectlytothetime-varyingcase.Themultivariatevolatility
model based on variance matrix discounting generalizes to define sequential analysis in which
the posterior distributions for the {t, t} sequences are updated in closed multivariate normal,
hyper-inverse Wishart forms. These theoretical innovations led to the development of dynamic
graphical models, coupled with learning about graphical model structures based on existing model
search methods [13, 25]. Applications in financial time series for predictive portfolio analysis show
improvements in portfolio outcomes that illustrate the practical benefits of the parsimony induced
via appropriate graphical model structuring in multivariate dynamic modelling [9, 10].
These developments have extended to contexts of matrix time series [61] for applications in
econometrics and related areas. Building on Bayesian analyses of matrix-variate normal distribu-
tions, conditional independence graphical structuring of the characterizing variance matrix param-
eters of such distributions again opens the path to parsimonious structuring of models for increas-
ingly high-dimensional problems. This is complemented by the development of a broad class of
dynamicmodelsformatrix-variatetimeserieswithinwhichstochasticelementsdefiningtimeseries
errors and structural changes over time are subject to graphical model structuring.
8.5.2 Dynamic matrix models for stochastic volatility
A number of recent innovations have aimed to define more highly structured, predictive stochastic
process models for multivariate volatility matrices t, aiming to go beyond the neutral, random
walk-like model that underlies the discounting approach. Among such approaches are multivariate
extensions of the univariate construction method inspired by MCMC [42]; the such extension
yields a class of stationary AR(1) stochastic process models for t that are reversible in time and
in which the transition distributions give conditional means of the attractive form E(t|t−1) =
S + a(t−1 −S) where a ∈(0, 1) is scalar and S an underlying mean variance matrix. This con-
structionis,however,inherentlylimitedinthatthereisnonotionofmultipleARcoefficientsforflex-
ible autocorrelation structures and the models do not allow time irreversibilty. Related approaches
directly build transition distributions p(t|t−1) as inverse-Wisharts [39, 40] or define more
empirical models representing t as an explicit function of sample covariance matrices of latent
vector AR processes [22]. These are very interesting approaches, but are somewhat difficult to work
with theoretically and model fitting is a challenge.
Recently, [32] used linear, normal AR(1) models for off-diagonal elements of the Cholesky of t
andforthelog-diagonalelements.ThisisanaturalparallelofBayesianfactormodelsformultivariate
volatility and defines an approach to building highly structured stochastic process models for time
series of dynamic variance matrices with short-term predictive potential.

Bayesian dynamic modelling
159
A related approach builds on theoretical properties of the family of inverse Wishart distributions
to define new classes of stationary, inverse Wishart autoregressive (IW-AR) models for the series of
q × q volatility matrices t [17]. One motivating goal is to maintain a defined inverse Wishart
marginal distribution for the process for interpretation. Restricting discussion to the (practically
most interesting)special caseof afirst-order model, thebasicideais to definean IW-AR(1) Markov
process directly via transition densities p(t|t−1) that are the conditionals of a joint inverse
Wishart on an augmented 2q × 2q variance matrix and whose block diagonals are t−1 and t.
This yields
t = t + ϒtt−1ϒ′
t
where the q × q random innovations matrices ϒt and t have joint matrix normal, inverse Wishart
distributions independently over time. Conditional means have the form
E(t|t−1) = S + R(t−1 −S)R′ + Ct(t−1)
where S is the mean variance matrix parameter of the stationary process, R is a q × q autore-
gressive parameter matrix and Ct(·) is a matrix naturally related to the skewness of the inverse
Wishart model. This model has the potential to embody multiple aspects of conditional depen-
dence through R as well as defining both reversible and irreversible special cases [17]. Some initial
studieshaveexploreduseofspecialcasesasmodelsforvolatilitymatricesoftheinnovationsprocess
drivingaTV-TVARmodelformultipleEEGtimeseriesfromstudiesinexperimentalneuroscience.
One small extract from an analysis of multi-channel EEG data [27] appears in Figure 8.6, showing
aspects of the estimated time trajectories of volatility for one channel along with those of time--
varying correlations from t across multiple channels. As with other models above, computational
issues for model filtering, smoothing and posterior simulation analysis require customized MCMC
and SMC methods, and represent some of the key current research challenges. The potential is
clear, however, for these approaches to define improved representations of multivariate volatility
processes of benefit when integrated into time series state space analysis.
8.5.3 Time-varying sparsity modelling
As time series dimension increases, the dimension of latent factor processes, time-varying param-
eter processes and volatility matrix processes in realistic dynamic models—such as special cases
or variants of models of equation (8.5)—evidently increase very substantially. Much current inter-
est then rests on modelling ideas that engender parsimonious structure and, in particular, on
approaches to inducing data-informed sparsity via full shrinkage to zero of (many) parameters.
Bayesian sparsity modelling ideas are well-developed in ‘static’ models, such as sparse latent factor
and regression models [8, 71], but mapping over to time series raises new challenges of defining
general approaches to dynamic sparsity. For example, with a dynamic latent factor component Btft
of equation (8.5), a zero element Bt,(i,j) in the factor loadings matrix Bt reflects lack of associa-
tion of the ith series in yt with the jth latent factor in ft. The overall sparsity pattern of Bt—with
potentially many zeros—reflects a model context in which each of the individual, univariate factor
processes impacts on a subset of the output time series, but not all, and allows for complex patterns
of cross-talk. The concept of dynamic sparsity is that these sparsity patterns will typically vary
over time, so models are needed to allow time variation in the values of elements of Bt that can
dynamically shrink completely to zero for some epochs, then reappear and evolve according to a
specific stochastic model at others. A general approach has been introduced by [36, 37], referred to
as latent threshold modelling (LTM).

160
M. West
Figure 8.6 Aspects of results of approximate fitting of a q × q dimensional IW-AR(1) model to q =
10 EEG series from [27, 47]; here t is the volatility matrix of innovations driving a TV-VAR model
for the potential fluctuations that the EEG signals represent. Upper frame: Estimated innovations
time series for one EEG series/channel, labelled chan-14. Centre frame: Several posterior sample
trajectories (grey) and approximate mean (black) for the standard deviation of channel 14. Lower
frame: Corresponding estimates of time-varying correlations of chan-14 with the other channels. Part
of the applied interest is in patterns of change over time in these measures as the EEG channels are
related spatially on the scalp of the test individual.
The basic idea of LTM for time series is to embed traditional time series model components
into a larger model that thresholds the time trajectories, setting their realized values strictly to zero
when they appear ‘small’. For example, take one scalar coefficient process βt, such as one element
of the factor loadings matrix or a single dynamic regression parameter, and begin with a traditional
evolutionmodeloftheAR(1)formβt = μ + ρ(βt−1 −μ) + ϵt.TheLTMapproachreplacesthe

Bayesian dynamic modelling
161
Figure 8.7 Examples of latent thresholding from an analysis of a three-dimensional economic time
series using a TV-VAR(2) model (data from [36]). Upper four frames: Trajectories of approximate
posterior means of 4 of the (18) latent time-varying autoregressive coefficients; the grey shading
indicates estimated time-varying posterior probabilities of zero coefficients from the LTM construction.
Lower four images: Images showing estimates of posterior probabilities (white = high, black = low)
of non-zero entries in dynamic precision matrices −1
t
modelled using an LTM extension of the
Cholesky AR(1) model [32]. The data are time series on q = 12 daily international exchange rates
(data from [46]) and the images show posterior sparsity probabilities for the 12 × 12 matrices at four
selected time points, indicating both the ability of the LTM to identify zeros as well as how the sparsity
pattern changes over time based on latent thresholding.

162
M. West
sequence β1:n with the thresholded version b1:n where bt = βtI(|βt| < τ) for each t and based on
some threshold τ. The concept is simple: the coefficient process is relevant, taking non-zero values,
only when it beats the threshold, otherwise it is deemed insignificant and shrunk to zero. Extending
MCMC analyses of multivariate DLMs to integrate the implied hierarchical model components,
now embedding mutliple latent processes underlying the actual thresholded parameter processes,
states and factors, requires substantial computational development, as detailed in [36]. The payoffs
canbemeaningful,asdemonstratedinaseriesoffinancialtimeseriesandportfoliodecisionmaking
examples in [37] where improved fit and parsimony feeds through to improvements in short-term
forecasting and realized portfolio returns.
Figure 8.7 gives some flavour of the approach in extracts from two time series analysing: a
TV-VAR(2) model of a q = 3-dimensional economic time series, and a multivariate stochastic
volatility model analysis of a q = 12-dimensional financial time series. One key attraction of the
LTMapproachisitsgenerality.SomeofthemodelcontextsaddressedviaLTMideasin[36]include
the following: (i) dynamic latent factor models; (ii) TV-VAR models, where the dynamic sparsity
arises in collections of TV-VAR coefficient matrices Ati of equation (8.5); (iii) dynamic regressions,
wheretheapproachcanberegardedasamodelfordynamicvariableselectionaswellasaparsimony
inducing strategy; and (iv) dynamic volatility modelling using extensions of the Cholesky volatility
models of [32].
8.5.4 Nonlinear dynamical systems
The recent advances in Bayesian computational methods for dynamic models have come at a
time when biotechnology and computing are also promoting significant advances in formal mod-
elling in systems biology at molecular and cellular levels. In models of temporal development of
components of gene networks and in studies of systems of cells evolving over time (and space,
e.g. [33]), increasingly complex, multivariate nonlinear mechanistic models are being expanded and
explored; these come from both the inherently stochastic biochemical modelling perspective and
from the applied mathematical side using systems of coupled (ordinary or stochastic) differential
equations [38, 76–78].
Statisticalmodeldevelopmentnaturallyinvolvesdiscrete-timerepresentationswithcomponents
that realistically reflect stochastic noise and measurement error and inherently involve multiple
underlying latent processes representing unobserved states that influence the network or cellular
system. A specific class of models has a multivariate time series y∗modelled as
yj
= xtj + νj
p(yj|xtj, )
xt+h = xt + Gh(xt, )xt + gh() + ωt,h
p(xt+h|xt, )
where the jth observation comes at real-time tj and the spacings between consecutive observations
are typically far greater than the fine time step h. Here xt represents the underlying state vector of
the systems (levels of gene or protein expression, numbers of cells, etc.),  all model parameters,
ν∗measurement error and ω∗state evolution noise. The density forms to the right indicate more
general model forms in which errors and noise may not be additive, when only partial observation
is made on the state, and so forth.
The forefront research challenges in this area include development of efficient and effective
computations for posterior inference and model comparison. Increasingly, SMC methods includ-
ing SMC/importance sampling and ABC-SMC are being explored and evaluated, with models of
increasing dimension and complexity [4, 35, 52, 58, 77]. In coming years, complex, multivariate
dynamical systems studies in biology are sure to define a major growth area for Bayesian dynamic
models and time series analysis.

Bayesian dynamic modelling
163
Acknowledgement
The author is grateful to Ioanna Manolopoulou and Emily Fox for comments on this chapter.
This work was partly supported by grant DMS-1106516 from the U.S. National Science Foundation
(NSF), and grants P50-GM081883 and RC1-AI086032 of the U.S. National Institutes of Health. Any
opinions, findings and conclusions or recommendations expressed in this work are those of the
author and do not necessarily reflect the views of the NSF or the NIH.
References
[1] Aguilar, O., Prado, R., Huerta, G. and West, M. (1999). Bayesian inference on latent structure
in time series (with discussion). In Bayesian Statistics 6 (ed. J. M. Bernardo, J. O. Berger, A. P.
Dawid and A. F. M. Smith), pp. 3–26. Oxford University Press, Oxford.
[2] Aguilar, O. and West, M. (2000). Bayesian dynamic factor models and portfolio allocation.
Journal of Business and Economic Statistics, 18, 338–357.
[3] Alspach, D. L. and Sorenson, H. W. (1972). Non-linear Bayesian estimation using Gaussian
sum approximations. IEEE Transactions on Automatic Control, AC-17, 439–448.
[4] Bonassi,F.V.,You,L.andWest,M.(2011).Bayesianlearningfrommarginaldatainbionetwork
models. Statistical Applications in Genetics & Molecular Biology, 10, Art 49.
[5] Cargnoni,C.,Müller,P.andWest,M.(1997).Bayesianforecastingofmultinationaltimeseries
through conditionally Gaussian dynamic models. Journal of the American Statistical Associa-
tion, 92, 640–647.
[6] Carter, C. K. and Kohn, R. (1994). Gibbs sampling for state space models. Biometrika, 81,
541–553.
[7] Carvalho, C. M., Johannes, M., Lopes, H. F. and Polson, N. G. (2010). Particle learning and
smoothing. Statistical Science, 25, 88–106.
[8] Carvalho, C. M., Lucas, J. E., Wang, Q., Chang, J., Nevins, J. R. and West, M. (2008). High-
dimensional sparse factor modelling – Applications in gene expression genomics. Journal of
the American Statistical Association, 103, 1438–1456.
[9] Carvalho, C. M. and West, M. (2007). Dynamic matrix-variate graphical models. Bayesian
Analysis, 2, 69–98.
[10] Carvalho,C.M.andWest,M.(2007).Dynamicmatrix-variategraphicalmodels–Asynopsis.
In Bayesian Statistics 8 (ed. J. M. Bernardo, M. J. Bayarri, J. O. Berger, A. P. Dawid, D. Hecker-
man, A. F. M. Smith and M. West), pp. 585–590. Oxford University Press, Oxford.
[11] Chen, R. and Liu, J. S. (2000). Mixture Kalman filters. Journal of the Royal Statistical Society,
Series B, 62(3), 493–508.
[12] Chib, S., Omori, Y. and Asai, M. (2009). Multivariate stochastic volatility. In Handbook of
Financial Time Series (ed. T. G. Andersen, R. A. Davis, J. P. Kreiss, and T. Mikosch), New York,
pp. 365–400. Springer-Verlag.
[13] Dobra, A., Jones, B., Hans, C., Nevins, J. R. and West, M. (2004). Sparse graphical models for
exploring gene expression data. Journal of Multivariate Analysis, 90, 196–212.
[14] Doucet,A.,deFreitas,N.andGordon,N.J.(2001).SequentialMonteCarloMethodsinPractice.
Springer-Verlag, New York.
[15] Doucet, A., Godsill, S. J. and West, M. (2000). Monte Carlo filtering and smoothing with
application to time-varying spectral estimation. Proceedings of the IEEE International Confer-
ence on Acoustics, Speech and Signal Processing, II, 701–704.
[16] Fong, W., Godsill, S. J., Doucet, A. and West, M. (2002). Monte Carlo smoothing with appli-
cation to speech enhancement. IEEE Trans. Signal Processing, 50, 438–449.

164
M. West
[17] Fox, E. B. and West, M. (2011). Autoregressive models for variance matrices: Stationary
inverse Wishart processes. Discussion Paper 11–15, Department of Statistical Science, Duke
University. Submitted for publication.
[18] Frühwirth-Schnatter, S. (1994). Data augmentation and dynamic linear models. Journal of
Time Series Analysis, 15, 183–202.
[19] Frühwirth-Schnatter, S. (2006). Finite Mixture and Markov Switching Models. Springer-Verlag,
New York.
[20] Godsill, S. J., Doucet, A. and West, M. (2004). Monte Carlo smoothing for non-linear time
series. Journal of the American Statistical Association, 99, 156–168.
[21] Gordon, N. J., Salmond, D. and Smith, A. F. M. (1993). Novel approach to nonlin-
ear/non-Gaussian Bayesian state estimation. Proc. IEE F, 140, 107–113.
[22] Gourieroux, C., Jasiak, J. and Sufana, R. (2009). The Wishart autoregressive process of mul-
tivariate stochastic volatility. Journal of Econometrics, 150, 167–181.
[23] Harrison, P. J. and Stevens, C. (1976). Bayesian forecasting (with discussion). Journal of the
Royal Statististical Society, Series B, 38, 205–247.
[24] Huerta, G. and West, M. (1999). Bayesian inference on periodicities and component spectral
structures in time series. Journal of Time Series Analysis, 20, 401–416.
[25] Jones, B., Dobra, A., Carvalho, C. M., Hans, C., Carter, C. and West, M. (2005). Experiments
in stochastic computation for high-dimensional graphical models. Statistical Science, 20,
388–400.
[26] Kim, S., Shephard, N. and Chib, S. (1998). Stochastic volatility: Likelihood inference and
comparison with ARCH models. Review of Economic Studies, 65, 361–393.
[27] Krystal, A. D., Prado, R. and West, M. (1999). New methods of time series analysis for non-
stationaryEEGdata:Eigenstructuredecompositionsoftimevaryingautoregressions.Clinical
Neurophysiology, 110, 1–10.
[28] Krystal, A. D., Zoldi, S., Prado, R., Greenside, H. S. and West, M. (1999). The spatiotemporal
dynamics of generalized tonic-clonic seizure EEG data: Relevance to the climinal practice
of electroconvulsive therapy. In Nonlinear Dynamics and Brain Functioning (ed. N. Pradhan,
P. Rapp and R. Sreenivasan). New York: Novascience.
[29] Lauritzen, S. L. (1996). Graphical Models. Clarendon Press, Oxford.
[30] Liu, F. and West, M. (2009). A dynamic modelling strategy for Bayesian computer model
emulation. Bayesian Analysis, 4, 393–412.
[31] Liu, J. and West, M. (2001). Combined parameter and state estimation in simulation-based
filtering.InSequentialMonteCarloMethodsinPractice(ed.A.Doucet,J.D.FreitasandN.Gor-
don), pp. 197–217. New York: Springer-Verlag.
[32] Lopes, H. F., McCulloch, R. E. and Tsay, R. (2010). Cholesky stochastic volatility. Technical
report, University of Chicago, Booth Business School.
[33] Manolopolou, I., Matheu, M. P., Cahalan, M. D., West, M. and Kepler, T. B. (2012). Bayesian
spatio-dynamic modelling in cell motility studies: Learning nonlinear taxic fields guiding the
immuneresponse(withinviteddiscussion).JournaloftheAmericanStatisticalAssociation,107,
doi: 10.1080/01621459.2012.655995.
[34] Marjoram, P., Molitor, J., Plagnol, V. and Tavaré, S. (2003). Markov chain Monte Carlo with-
out likelihoods. Proceedings of the National Academy of Sciences USA, 100, 15324–15328.
[35] Mukherjee, C. and West, M. (2009). Sequential Monte Carlo in model comparison: Example
in cellular dynamics in systems biology. In JSM Proceedings, Section on Bayesian Statistical
Science. Alexandria, VA: American Statistical Association, pp. 1274–1287.
[36] Nakajima, J. and West, M. (2012). Bayesian analysis of latent threshold dynamic models.
Journal of Business and Economic Statistics, to appear.
[37] Nakajima, J. and West, M. (2012). Bayesian dynamic factor models: Latent threshold
approach. Journal of Financial Econometrics, doi: 10.1093/jjfinec/nbs013.

Bayesian dynamic modelling
165
[38] Niemi, J. B. and West, M. (2010). Adaptive mixture modelling Metropolis methods for
Bayesian analysis of non-linear state-space models. Journal of Computational and Graphical
Statistics, 19, 260–280.
[39] Philipov, A. and Glickman, M. E. (2006). Factor multivariate stochastic volatility via Wishart
processes. Econometric Reviews, 25, 311–334.
[40] Philipov, A. and Glickman, M. E. (2006). Multivariate stochastic volatility via Wishart pro-
cesses. Journal of Business and Economic Statistics, 24, 313–328.
[41] Pitt, M. K. and Shephard, N. (1999). Time varying covariances: A factor stochastic volatility
approach (with discussion). In Bayesian Statistics VI (ed. J. M. Bernardo, J. O. Berger, A. P.
Dawid and A. F. M. Smith), pp. 547–570. Oxford University Press, Oxford.
[42] Pitt, M. K. and Walker, S. G. (2005). Constructing stationary time series models using auxil-
liary variables with applications. Journal of the American Statistical Association, 100, 554–564.
[43] Pole, A., West, M. and Harrison, P. J. (1994). Applied Bayesian Forecasting & Time Series Anal-
ysis. Chapman-Hall.
[44] Prado, R., Huerta, G. and West, M. (2001). Bayesian time-varying autoregressions: Theory,
methods and applications. Resenhas, 4, 405–422.
[45] Prado, R. and West, M. (1997). Exploratory modelling of multiple non-stationary time series:
Latent process structure and decompositions. In Modelling Longitudinal and Spatially Corre-
lated Data (ed. T. Gregoire), pp. 349–362. Springer-Verlag.
[46] Prado, R. and West, M. (2010). Time Series: Modeling, Computation & Inference. Chapman &
Hall/CRC Press.
[47] Prado, R., West, M. and Krystal, A. D. (2001). Multi-channel EEG analyses via dynamic
regression models with time-varying lag/lead structure. Journal of the Royal Statistical Society
(Ser. C), 50, 95–110.
[48] Quintana,J.M.,Carvalho,C.M.,Scott,J.andCostigliola,T.(2010).Futuresmarkets,Bayesian
forecasting and risk modeling. In The Handbook of Applied Bayesian Analysis (ed. A. O’Hagan
and M. West), pp. 343–365. Oxford University Press, Oxford.
[49] Quintana, J. M., Lourdes, V., Aguilar, O. and Liu, J. (2003). Global gambling. In Bayesian
Statistics 7 (ed. J. M. Bernardo, M. J. Bayarri, J. O. Berger, A. P. Dawid, D. Heckerman, A. F. M.
Smith and M. West), pp. 349–368. Oxford University Press, Oxford.
[50] Quintana, J. M. and West, M. (1987). An analysis of international exchange rates using multi-
variate DLMs. The Statistician, 36, 275–281.
[51] Quintana, J. M. and West, M. (1988). Time series analysis of compositional data. In Bayesian
Statistics 3(ed. J. M. Bernardo, M. H. DeGroot, D. V. Lindley and A. F. M. Smith), pp. 747–756.
Oxford University Press, Oxford.
[52] Secrier, M., Toni, T. and Stumpf, M. P. H. (2009). The ABC of reverse engineering biological
signalling systems. Molecular Biosystems, 5(12), 1925–1935.
[53] Shephard, N. (1994). Local scale models: State-space alternative to integrated GARCH mod-
els. Journal of Econometrics, 60, 181–202.
[54] Sisson, S. A., Fan, Y. and Tanaka, M. M. (2007). Sequential Monte Carlo without likelihoods.
Proceedings of the National Academy of Sciences USA, 104, 1760–1765.
[55] Smith, A. F. M. and West, M. (1983). Monitoring renal transplants: An application of the
multi-process Kalman filter. Biometrics, 39, 867–878.
[56] Smith,A.F.M.,West,M.,Gordon,K.,Knapp,M.S.andTrimble,I.(1983).Monitoringkidney
transplant patients. The Statistician, 32, 46–54.
[57] Tebaldi,C.,West,M.andKarr,A.F.(2002).Statisticalanalysesoffreewaytrafficflows.Journal
of Forecasting, 21, 39–68.
[58] Toni, T. and Stumpf, M. P. H. (2010). Simulation-based model selection for dynamical sys-
tems in systems and population biology. Bioinformatics, 26, 104–110.

166
M. West
[59] Uhlig, H. (1994). On singular Wishart and singular multivariate beta distributions. Annals of
Statistics, 22, 395–405.
[60] Uhlig, H. (1997). Bayesian vector autoregressions with stochastic volatility. Econometrica, 1,
59–73.
[61] Wang, H. and West, M. (2009). Bayesian analysis of matrix normal graphical models.
Biometrika, 96, 821–834.
[62] West,M.(1986).Bayesianmodelmonitoring.JournaloftheRoyalStatisticalSociety(Ser.B),48,
70–78.
[63] West, M. (1992). Modelling with mixtures (with discussion). In Bayesian Statistics 4 (ed. J. M.
Bernardo,J.O.Berger,A.P.Dawid,andA.F.M.Smith),pp.503–524.OxfordUniversityPress.
[64] West, M. (1993). Approximating posterior distributions by mixtures. Journal of the Royal
Statistical Society (Ser. B), 54, 553–568.
[65] West, M. (1993). Mixture models, Monte Carlo, Bayesian updating and dynamic models.
Computing Science and Statistics, 24, 325–333.
[66] West, M. (1995). Bayesian inference in cyclical component dynamic linear models. Journal of
the American Statistical Association, 90, 1301–1312.
[67] West,M.(1996).Bayesiantimeseries:Modelsandcomputationsfortheanalysisoftimeseries
in the physical sciences. In Maximum Entropy and Bayesian Methods 15 (ed. K. Hanson and
R. Silver), pp. 23–34. Kluwer.
[68] West, M. (1996). Some statistical issues in Palæoclimatology (with discussion). In Bayesian
Statistics 5 (ed. J. M. Bernardo, J. O. Berger, A. P. Dawid and A. F. M. Smith), pp. 461–486.
Oxford University Press.
[69] West, M. (1997). Modelling and robustness issues in Bayesian time series analysis (with
discussion). In Bayesian Robustness (ed. J. O. Berger, B. Betrò, E. Moreno, L. R. Pericchi,
F. Ruggeri, G. Salinetti and L. Wasserman), IMS Monographs, pp. 231–252. Institute for Math-
ematical Statistics.
[70] West, M. (1997). Time series decomposition. Biometrika, 84, 489–494.
[71] West, M. (2003). Bayesian factor regression models in the “large p, small n” paradigm. In
Bayesian Statistics 7 (ed. J. M. Bernardo, M. J. Bayarri, J. O. Berger, A. P. David, D. Heckerman,
A. F. M. Smith and M. West), pp. 723–732. Oxford University Press.
[72] West, M. and Harrison, P. J. (1986). Monitoring and adaptation in Bayesian forecasting mod-
els. Journal of the American Statistical Association, 81, 741–750.
[73] West, M. and Harrison, P. J. (1989). Subjective intervention in formal models. Journal of
Forecasting, 8, 33–53.
[74] West, M. and Harrison, P. J. (1997). Bayesian Forecasting & Dynamic Models (2nd edn).
Springer Verlag.
[75] West, M., Prado, R. and Krystal, A. D. (1999). Evaluation and comparison of EEG traces:
Latent structure in non-stationary time series. Journal of the American Statistical Associa-
tion, 94, 1083–1095.
[76] Wilkinson, D. J. (2006). Stochastic Modelling for Systems Biology. London: Chapman &
Hall/CRC.
[77] Wilkinson, D. J. (2011). Parameter inference for stochastic kinetic models of bacterial gene
regulation: a Bayesian approach to systems biology (with discussion). In Bayesian Statistics 9
(ed. J. M. Bernardo, M. J. Bayarri, J. O. Berger, A. P. David, D. Heckerman, A. F. M. Smith and
M. West), pp. 679–700. Oxford University Press.
[78] Yao, G., Tan, C., West, M., Nevins, J. R. and You, L. (2011). Origin of bistability underlying
mammalian cell cycle entry. Molecular Systems Biology, 7, 485.

9
Hierarchical modelling in
time series: the factor
analytic approach
dani gamerman and esther salazar
9.1 Introduction
A
drian Smith’s contribution to statistics spans across a very wide range of topics. One can single
out his relentless effort towards making the Bayesian approach to inference applicable, in
a series of computationally oriented papers with approximating methods. This effort reached its
climaxwithhislandmarkpaper[18],afterwhichMCMCmethodsbecamefamousandwidespread.
Another line of contributions was more methodological in terms of proposing new routes for
exploring more elaborate data structures. It led to another landmark paper [29]. This JRSSB dis-
cussion paper was devoted to explaining how information from different but related sources of
information could be combined in a regression framework with a hierarchical structure. This paper
was extended to the time-varying context in [16] with the use of dynamic models. One of us was
fortunate to interact with Adrian in [17], where hierarchical and dynamic models were also used to
combine information from different time series sources.
The idea of borrowing information from related sources is very powerful. It has proved to be very
useful in past decades where complex data structures have begun to be tackled, as they required
sophisticatedmodellingstrategies.Avitalelementinsuchstructuredsettingsistheabilitytoextract
from the data possible similarity patterns. This can be achieved in a number of ways, including
hierarchical modelling, non-parametric components and factor analysis.
This chapter will address the issue of combining information from a possibly large time series
with a factor analytic approach. Results obtained from this exercise are a (hopefully much) smaller
number of latent time series that represent the main features of the complete dataset of time series
originally available. Each combination of a time series and a factor gives rise to a weight or loading
that informs in which ways the different original series were combined. These loadings are useful
quantities as they allow the identification of common features and interpretation of the relationship
or correlation structure between the different series.
These concepts will be discussed and combined in a number of forms in this chapter. Special
attention will be devoted to the exploration of these ideas in the area of spatial statistics. It will
be shown that this area is not only an area of application of these ideas but is one of the main
beneficiaries of these developments. Spatial statistics is devoted to the analysis of a collection

168
D. Gamerman and E. Salazar
of processes that exhibit correlation due to their (geographic) location. The main goal there is to
appropriately capture the spatial dependence in order to be able to extrapolate information from a
few data sources to the whole region of interest. This inevitably leads to the need for parsimonious
forms for representing the correlation structure. This chapter will show how the ideas behind
dynamic factor models apply in this setting via illustrative examples with real data problems.
This chapter is organized as follows. Section 9.2 reviews the literature on factor analysis. Sec-
tion 9.3 presents some basic factor model extensions for modelling high-dimensional multivari-
ate time series. Section 9.4 describes applications of these ideas in the context of spatial analy-
sis. Section 9.5 describes how regression ideas can be incorporated into the factor model setting.
This is accomplished by enlarging the scope of the models to include explanation via covari-
ate time series. Section 9.6 draws some concluding remarks and points at possible directions for
further work.
9.2 A short review of factor analysis
Factor analysis is a useful statistical technique used widely for modelling multivariate data by a
few unobserved set of variables called latent factors. More specifically, the observed variables are
modelled as linear combinations of the latent factors plus an idiosyncratic error. In general, this
approach is applied for the following purposes: (i) dimension reduction, (ii) identifying under-
lying structures, and (iii) modelling of sparse covariance structures. From a classical point of
view, the term was first introduced in [49] and later discussed in [50], [1] and [22], among many
others. In recent years, a fully Bayesian treatment of factor models became feasible due to the
improvements in Bayesian computation, especially Markov chain Monte Carlo (MCMC) simu-
lation methods. In this context, the Bayesian specifications proposed in [21], [42] and [3] can
be mentioned.
The factor model is defined as follows
yt = βf t + ϵt,
ϵt ∼N(0, )
(9.1)
where t = 1, . . . , T, yt is an n-dimensional observational vector, β is an n × k factor loadings
matrix, f t ∼N(0, Ik) are independent k-dimensional vectors called latent factors such that k ≪
n and  = diag(σ 2
1 , . . . , σ 2n ). This model implies that, given the factors, each yt has indepen-
dentcomponentsthatarevar(yit|f t) = σ 2
i andcov(yit, yjt|f t) = 0(i ̸= j).Moreover,dependence
among components is induced by marginalizing over the distribution of the factors so yt|β,  ∼
N(0, ) where  = ββT + . Note also that independence of the factors and the idiosyncratic
terms ϵt induces independence of the observations.
Two important issues have to be mentioned at this point. The first one is regarding identifiability
problems related to the non-unique decomposition of  and the inference about the number of
factors.Manywaystohandlethisproblemcanfoundintheliterature.Basically,theideaistoimpose
constraints on β, as, for example the lower constraint defined in [21], [2] and [34]. However, in
some applications, identifiability of the factor loadings is not required, especially for covariance
matrix estimation, variable selection and prediction (see [5] for more details). This issue will be
further discussed in the next section where structured priors for β can be used. On the other
hand, uncertainty about the number of latent factors has been studied in different ways. The most
common approach was fitting the factor model for different choices of k and then using a selec-
tion criterion like AIC or BIC for model selection. [34] proposed fully Bayesian inference on the
number of factors through a reversible jump MCMC (RJMCMC) [23]. Their proposal was com-
pared with a number of other alternatives based on bridge sampling [35]. Another recent approach

Hierarchical modelling in time series
169
relies on zeroing a subset of factor loadings using variable selection priors such as binary indicator
δij [19]. Based on this idea, interesting applications can be mentioned. See [8] and [15] for gene
expression and financial modelling, respectively, are a few examples. In this chapter, we further
discuss the RJMCMC scheme as a tool for model selection.
9.3 Dynamic factor models
9.3.1 Basic definitions
Dynamic factor models (DFMs) were developed in a number of ways and have become a use-
ful tool for modelling high-dimensional multivariate time series. The core idea is to explain the
common dynamic structure of the multivariate time series through a set of common (time series)
factors. This is achieved by the introduction of flexible temporal correlation structures for the
latent factors, previously assumed to be independent. This renders the DFM capable of assess-
ing the complexity of time series data. Models along these lines were proposed in [4, 10, 13, 20,
36, 39, 45].
Earlier approaches have been primarily concerned with modelling multivariate stationary time
series considering latent factors with a time-varying mean function. In this context, in [39] was
proposed a methodology to identify the number of latent factors in a vector of stationary times
series. Specifically, temporal correlation is introduced through a k-dimensional vector that follows
an autoregressive moving average process (see [36, 4] and references therein for related ideas). For
thenonstationarycase,amethodologyforbuildingDFMfornonstationarytimeseriesinstatespace
form was proposed in [40, 41] and, more recently, a new approach that allows nonstationary factors
not necessarily driven by unit roots was introduced in [38].
In this section we focus on DFM for both stationary and nonstationary time series where the
k-dimensional latent factor f t (state vector) follows a general VARMA(p, q) representation
f t = 1f t−1 + . . . + pf t−p + ωt + 1ωt−1 + . . . + qωt−q
(9.2)
where ωt ∼N(0, ), ∀t. The latent nature of the factors makes it difficult to precisely estimate
this full model. It what follows, we will concentrate the presentation on a simplified VAR(1) ver-
sion, obtained when p = 1 and q = 0. A number of features are more clearly understood in this
setting and will be discussed below. This factor evolution is driven by the following transition
equation
f t = f t−1 + ωt,
ωt ∼N(0, )
(9.3)
where  is a symmetric k × k autoregressive coefficient matrix characterizing the dynamic evolu-
tion of the common factors and  is a k × k covariance matrix with elements λij, i, j = 1, . . . , k.
Note that  and  are not necessarily diagonal matrices so they can be defined to deal, for instance,
with seasonal components and nonstationary common factors. Equations (9.1) and (9.2) or (9.3)
define the dynamic factor model and, in a similar fashion to standard factor analysis, the latent
factors f t capture the time-varying correlation structure of the data.
Working within a Bayesian framework, some important issues related to model specification and
posterior inference can be mentioned at this point.

170
D. Gamerman and E. Salazar
Prior specification
The prior for the latent factor is given in equation (9.3) and completed by f 0 ∼N(m0, C0)
with known hyperparameters m0, C0. As was mentioned before, many specifications for  can
be considered. One possibility for the  matrix is a diagonal form with elements λi. In this
case, a typical choice of prior for the λis is independent Gamma distributions. Similar indepen-
dence assumptions can be made for the autoregressive matrix . One possibility is to consider
 = diag(γ1, . . . , γk) such that, γj ∼N(0, a) independent, for j = 1, . . . , k, for some large value
of a if one wants to represent vague prior information. If one is concerned with the possibility of
unit roots and non-stationarity, the mixture prior γj ∼πN(−1,1)(0, a) + (1 −π)δ1(γj) may be
assumed for the autoregressive coefficients, where π ∈(0, 1] and a are known hyperparameters,
N(l,u)(·, ·) denotes the normal distribution constrained to assumed values only in (l, u), δ1(γj) = 1
if γj = 1 and δj(γj) = 0 if γj ̸= 1 (see [26] for more details); for π ̸= 1, the mixture prior
allows the possibility that nonstationary factors be incorporated; if π = 1 we are in the stationary
case.
Correlated factors can also be incorporated into the DFM. One example of that is the inclusion
of h seasonal common factors to capture a possibly periodic behaviour of the time series. In that
case,  could be specified as  = diag(0, 1, . . . , h) where 0 = diag(γ0,1, . . . , γ0,k),
l =

cos(2πl/p) sin(2πl/p)
−sin(2πl/p) cos(2πl/p)

,
l = 1, . . . , h,
p is the seasonal period and h = p/2 is the maximum number of harmonics needed to capture the
seasonal behaviour of the time series, (see [54], Chapter 8, for more details). As a consequence
 = diag(0, 1, . . . , h) and each l is no longer diagonal with inverted Wishart distribution
as a prior.
Factor loadings specification
For the factor loadings one can take independent normal priors for each element of β such that
βii ∼N(0,∞)(0, b), βij ∼N(0, b) only for i > j (see [34] for more details), since identifiability
constraints impose βij = 0 for i < j. However, in practice, one may also be interested in including
conditional dependencies within the elements of yt. In order to do that, the underlying idea is
to include a flexible correlation structure into the columns of β, denoted by β(j) (j = 1, . . . , k).
In the context of spatial analysis, a number of papers have examined inducing dependencies
through β(j). For example, in [52] the columns of β are modelled as orthonormal basis func-
tions and in [6] and [44] smoothed deterministic kernels are used to build β. Alternatively,
[32] introduced a spatial DFM where the columns of the factor loadings matrix follow indepen-
dent Gaussian random fields. This idea will be discussed and illustrated in the next section for
modelling space–time data. Additional developments on factor loadings specification include, for
example, [8] and [5] for sparse factor analysis, and [30] for latent time-varying loadings, among
others.
Posterior inference
Fully Bayesian treatment of the standard and dynamic factor models via MCMC methods is
described in detail in [34] and [2], respectively. More specifically, the inference procedure is
designed for two cases: known and unknown number of factors k. Considering that the number
of factor k is known, the MCMC scheme described in [34] can easily be adapted where the com-
mon factors are jointly sampled via the well-known forward filtering backward sampling (FFBS)

Hierarchical modelling in time series
171
scheme [7, 14]. For the second case, model selection is performed by computing posterior model
probabilities (PMPs) for different choices of k. In particular, the reversible jump MCMC algorithm,
proposed/described in [32, 34] for DFM, can be used. The algorithm allows for a simple method
of calculating the PMP from preliminary MCMC runs. As mentioned in the previous references,
the Bayesian model search via RJMCMC penalizes over and under-parameterized factor models.
9.3.2 Hierarchical DFM
A common criticism in DFM is that the common latent factors are difficult to interpret. In large
n settings and for multi-level datasets, the dimension reduction of the problem may involve loss
of data structure. In this context, a hierarchical construction of the model to allow a progressive
reduction in the dimensionality as the levels becomes higher may be desired. For example, the
hierarchical construction for dynamic linear models (DLMs) proposed in [16] provides a general
framework for analysis of multivariate time series. In accordance with this idea and following the
same notation introduced in Subsection 9.3.1, the 3-level hierarchical dynamic factor model (HDFM)
can be written as
yt = β1f 1t + ϵ1t,
ϵ1t ∼N(0, 1)
(9.4)
f 1t = β2f 2t + ϵ2t,
ϵ2t ∼N(0, 2)
(9.5)
f 2t = β3f 3t + ϵ3t,
ϵ3t ∼N(0, 3)
(9.6)
f 3t = f 3,t−1 + ωt,
ωt ∼N(0, )
(9.7)
where f it, i = 1, 2, 3, are ki-dimensional vectors satisfyingk1 > k2 > k3, β1 is a n × k1 matrix, β2
and β3 are k1 × k2 and k2 × k3 matrices respectively, and  is a k3 × k3 matrix. More specifically,
eqn(9.4)representstheobservationequation,eqns(9.5)and(9.6)thestructuralequationsandeqn
(9.7)thesystemequation.Asmentionedin[16],thepreviousHDFMcanbereducedtoconsidering
only two levels/stages of hierarchy by setting β3 = Ik3 and 3 = 0, a zero matrix. Again, further
levels are easily induced but this would rarely be required.
9.3.3 Generalized DFM
The DFM can also be extended to allow for non-Gaussian observations. More specifically, the
generalized DFM (GDFM) is a hierarchical model where the first level equation (observation
equation) is given by
p(yti|ηti, ψ) = exp{ψ(ytiηti −b(ηti)) + c(yti, ψ)}
(9.8)
where ηti is the natural parameter and ψ is the dispersion parameter. The natural parameter ηti
is related to the temporal components through the link function v such that ηti = v(θti). Conse-
quently, the model is completed by specifying the following two levels of hierarchy
θt = μt + βf t
(9.9)
f t = f t−1 + ωt,
ωt ∼N(0, )
(9.10)
where θt = (θt1, . . . , θtn)T, μt is the mean level, and β,  and  have the same specifications as
the SDFM. See [53] for more details in the context of generalized DLMs.

172
D. Gamerman and E. Salazar
Full Bayesian treatment for this new class is more challenging, specifically for MCMC sampling
the common factor. In the previous cases, the full conditional distribution for joint sampling this
componentwasnormalandthuseasilysampledfromusing,forexample,theFFBS.Thisisnolonger
valid here and efficient proposal are very difficult to obtain, specially for large time series with large
T. Componentwise sampling is also very inefficient. The solution here is a compromise with this
componentsampledinblocks.Tothisend,ablocksamplingschemethatcombinestechniquessuch
as extended Kalman filter and block sampling was proposed in [31] with good performance in the
applications.
9.4 Applications to spatial statistics
In this section, we discuss some applications of the above mentioned approaches for spatial and
spatio-temporal processes.
The use of factor analysis to model multivariate spatial data has been treated in a number of
ways. Here, we focus on the case in which factor analysis is used to identify clusters or groups of
locations/regions (spatial dependence) whose temporal behaviour is driven by a set of common
dynamic latent factors (temporal dependence). In previous works, either common dynamic factors
or factor loadings matrices are restricted to be deterministic functions. Specifically, when the com-
mon factors are non-stochastic the space–time dynamic model proposed in [48] is obtained. On
the other hand, when β is defined as a deterministic function the structure proposed in [52] and
[6] is obtained.
In [32] was introduced a new class of models called the spatial dynamic factor model (SDFM),
derived from the standard DFM. More specifically, the temporal dependence is modelled by the
latent common factors and the spatial dependence is also modelled stochastically by the columns
of the factor loadings β(j). These are assumed to follow independent Gaussian processes. The role
played by the stochastic structure is to allow further flexibility to the deterministic specification,
that is restrictive by definition.
The SDFM is defined by eqns (9.1) and (9.3), where yt = (y1t, . . . , ynt)T such that yit is an
observation measured at time t and location si ∈Rd. Each column β(j) = (βj(s1), . . . , βj(sn))T
is defined as
β(j) ∼N(θj, τ2
j Rφj),
for
j = 1, .., k
(9.11)
where θj is the n-dimensional mean vector, τ2
j is the common variance of the spatial process, Rφj is
the matrix correlation function with (l, m)-element given by {Rφj}l,m = ρφj(∥sl −sm ∥), l, m =
1, . . . , n and ρφ(·) represents a spatial correlation function like exponential or Matérn specified by
the parameter φ.
As an illustration, Figure 9.1 shows a simulated SDFM with k = 2 common latent factors. Note
that the surfaces for yt are driven by the spatial behaviour of the β(j)s (j = 1, 2) weighted by the
valuesofthecommonfactors.ItisimportanttomentionthattheSDFMimpliesnonseparableforms
of the covariance function when k ⩾2. In fact, if  and  are diagonal matrices, the covariance
between two different sites at two different time indexes is given by
cov(yit, yj,t+h) =
k

l=1
λlγ h
l (1 −γ 2
k )(τ2
j ρφj + θilθjl)
That characteristic implies that the SDFM is able to model complex space–time interactions. In
contrast, when k = 1 spatial and temporal covariance functions are identified separately.

Hierarchical modelling in time series
173
−1.0
−0.5
0.0
0.5
1.0
 −0.8 
 −0.6 
 −0.6 
 −0.4 
 −0.4 
 −0.2 
 −0.2 
 0 
 0 
 0 
 0.2 
 0.2 
 0.4 
 0.4 
 0.4 
 0.4 
 0.6 
 0.8 
 0.8 
 1 
 1 
 1.2 
−4
−3
−2
−1
0
1
 −4 
 −3.5 
 −3 
 −2.5 
 −2.5 
 −2 
 −2 
 −1.5 
 −1.5 
 −1.5 
 −1 
 −1 
 −0.5 
 −0.5 
 −0.5 
 0 
 0 
 0.5 
 0.5 
 0.5 
 0.5 
 1 
 1 
0
5
10
15
20
25
30
35
−1.0
−0.5
0.0
0.5
1.0
Time
−1.0
−0.5
0.0
0.5
1.0
 −0.6 
 −0.4 
 −0.2 
 −0.2 
 −0.2 
 −0.2 
 0 
 0 
 0 
 0 
 0 
 0.2 
 0.2 
 0.2 
 0.4 
 0.4 
 0.4 
 0.6 
−1.0
−0.5
0.0
0.5
1.0
 −0.06 
 −0.05 
 −0.04 
 −0.03 
 −0.03 
 −0.02 
 −0.02 
 −0.02 
 −0.01 
 −0.01 
 −0.01 
 −0.01 
 0 
 0 
 0 
 0.01 
 0.01 
−1.0
−0.5
0.0
0.5
1.0
 −1 
 −0.8 
 −0.6 
 −0.4 
 −0.4 
 −0.2 
 −0.2 
 −0.2 
 −0.2 
 0 
 0 
 0 
 0 
 0 
 0.2 
−1.0
−0.5
0.0
0.5
1.0
 −0.8 
 −0.6 
 −0.6 
 −0.4 
 −0.4 
 −0.4 
 −0.2 
 0 
 0 
 0 
 0 
 0.2 
 0.2 
 0.2 
 0.2 
 0.4 
 0.4 
 0.4 
 0.6 
 0.8 
 0.8 
 1 
 1 
 1 
 1 
Figure 9.1 Simulated spatial dynamic 2-factor model. First row: Gaussian processes for the two
columns of β and simulated dynamic factors (time series) f t = (f1t, f2t)T for t = 1, . . . , 36. The first
factor (dashed line) has a seasonal behaviour with period p = 12. The second factor (solid line)
follows an AR process with autoregressive parameter γ22 = 0.9. Second row: yt processes following
eqn (9.1) for t = 6, 12, 18, 24.
Example 9.1 TheSDFMisusedtoexaminethespatio-temporalvariationinweeklyconcentration
levelsofnitrate(NO3)across22monitoringstationslocatedineasternUSAforT = 312weeks(1st
week of 1998 – 52nd week of 2003). The logarithm transformation was used to normalize the data
and a seasonal common factor was considered to capture the yearly periodic behaviour repeated
every 52 weeks (seasonal period). The SDFM with k = 3 regular factors and 1 seasonal factor was
compared against other models and selected for fit to the data. Also, a Matérn correlation function
is used to specify the spatial correlation structure of each β(j) (j = 1, . . . , 4) with smoothness
parameter equal to 1.
Figure 9.2 shows some posterior results of the fitted model. The four maps of the factor loadings
(estimated via Bayesian interpolation) show distinct spatial patterns across the study area. Note
that the temporal behaviour of the time series is directly related with the higher values of the
interpolated surfaces (white areas). The loadings for the second factor are higher in the western
region, specifically in some areas of Indiana, Ohio and Kentucky. This factor mimics, roughly, the
spatial pattern of the NO3 across time. Also, the results indicated that this factor is nonstationary. In
addition, Figure 9.3, panel (a) shows a plot of observed versus fitted values (considering the original
scale). The points roughly follow a straight line indicating good predictions. Panel (b) presents
interpolation results for one of the out-of-sample monitoring stations (SPD station). The NO3
interpolated values are very close to the real values, indicating the good interpolated performance
of the model. Finally, panels (c) and (d) show forecast values for the 1st and 12th weeks of 2004.
Note that the spatial pattern is almost preserved but with lowest values for the entire region for the
12th week. That behaviour is expected since high concentration levels of nitrate are expected in the
first weeks of the year.
∥
The SDFM can also be extended to allow for non-Gaussian observations. In [31] was introduced a
new class of spatio-temporal models for multivariate exponential family data, called the generalized
spatial dynamic factor model (GSDFM). In this formulation, the spatial and temporal components
are modelled via a latent factor analysis of the canonical transformation of the mean function. The
model is given by eqns (9.8)–(9.10) with the addition of the Gaussian prior (9.11) for the loadings.
Notethatthisclassofmodelalsoleadstoanonseparablespatio-temporalcovariancestructure.This
characteristic is associated with the linear predictor θt where, for k > 1, both spatial and temporal
covariance structures can not be separately identified.

174
D. Gamerman and E. Salazar
−86
−84
−82
−80
−78
−76
−74
34
36
38
40
42
44
 −1.5 
 −1 
 −0.5 
 0 
 0.5 
 1 
 1.5 
 2 
 2.5 
 3 
 3.5 
ESP
SAL
MCK
OXF
DCP
CKT
LYK
PNF
QAK
CDR
VPI
MKG
PAR
KEF
SHN
PED
PSU
ARE
BEL
CTH
WSP
CAT
+
SPD
+
BWR
−1
0
1
2
3
−86
−84
−82
−80
−78
−76
−74
34
36
38
40
42
44
 0.6 
 0.7 
 0.8 
 0.8 
 0.9 
 0.9 
 0.9 
 1 
 1 
 1 
 1 
 1.1 
 1.1 
 1.1 
 1.2 
 1.2 
 1.3 
 1.3 
 1.4 
 1.4 
 1.5 
 1.5 
 1.6 
 1.6 
 1.7 
 1.8 
ESP
SAL
MCK
OXF
DCP
CKT
LYK
PNF
QAK
CDR
VPI
MKG
PAR
KEF
SHN
PED
PSU
ARE
BEL
CTH
WSP
CAT
+
SPD
+
BWR
0.6
0.8
1
1.2
1.4
1.6
1.8
−86
−84
−82
−80
−78
−76
−74
34
36
38
40
42
44
 −1.5 
 −1 
 −0.5 
 0 
 0.5 
 0.5 
 1 
 1.5 
 2 
ESP
SAL
MCK
OXF
DCP
CKT
LYK
PNF
QAK
CDR
VPI
MKG
PAR
KEF
SHN
PED
PSU
ARE
BEL
CTH
WSP
CAT
+
SPD
+
BWR
−1
0
1
2
−86
−84
−82
−80
−78
−76
−74
34
36
38
40
42
44
 0.7 
 0.8 
 0.8 
 0.9 
 0.9 
 1 
 1 
 1.1 
 1.2 
 1.3 
 1.4 
 1.5 
 1.5 
 1.6 
 1.7 
 1.8 
ESP
SAL
MCK
OXF
DCP
CKT
LYK
PNF
QAK
CDR
VPI
MKG
PAR
KEF
SHN
PED
PSU
ARE
BEL
CTH
WSP
CAT
+
SPD
+
BWR
0.8
1
1.2
1.4
1.6
1.8
1998 1999 2000 2001 2002 2003 2004
−0.3 −0.2 −0.1
0.0
0.1
0.2
0.3
1998 1999 2000 2001 2002 2003 2004
0.4
0.6
0.8
1.0
1.2
1.4
1.6
1998 1999 2000 2001 2002 2003 2004
1998 1999 2000 2001 2002 2003 2004
−0.4 −0.3 −0.2 −0.1
0.0
0.1
0.2
0.3
−0.6 −0.4 −0.2
0.0
0.2
0.4
0.6
Figure 9.2 First row: Bayesian interpolation of the factor loadings. Values represent the range of the
posterior means. Second row: Posterior means of the factors. Solid lines represent the posterior
means and dashed lines the 95% credible intervals.
Example 9.2 We are interested in modelling daily rainfall occurrences (over 1 mm) in northern
Oceania in 2001. The data contains T = 365 binary observations measured at 19 meteorological
stations, 14 of them located in the Federated States of Micronesia and 5 in the Marshall Islands.
Figure 9.4(a) shows the study area as well as the geographic location of the stations. We aim to
identifymicroclimatesoverthestudyregionandalsofitrainprobabilitymapsforthewholeareaand
across time. In addition, two stations were left out of the analysis for interpolation purposes. The
model considered is given by eqns (9.8)–(9.10) such that yti ∼Bernoulli(pti), logistic link function
θti = log(pti/(1 −pti)), a Matérn correlation function for the specification of the factor loadings
matrixandθ(j) = μj117.TheGSDFMwasfittedconsideringk = 1, 2, 3, 4commonfactors.Com-
parisons between models are based on the PMP. In this application, the model with three common
factor shows the best results with PMP equal to 0.46.
Figure 9.5 shows the interpolated loading associated with the first, second and third factors as
well as the estimated temporal behaviour of the common factors. The spatial loadings, interpolated
viaBayesiankriging,indicateasmoothvariationindifferentdirections,especiallyforthefirstfactor.
These findings allow the recognition of microclimates, more specifically in the eastern part (around
Marshall Islands), as shown in the map for β(3). In addition, the results indicate the presence of
one nonstationary factor (2nd factor) with posterior probability pr(γ2 = 1|yT) = 0.89, where
yT = (y1, . . . , yT). Other interesting results of the model are the rain probability time series for
observed and interpolated stations, the latter interpolated via Bayesian kriging. Figure 9.4(b) shows
thosetimeseriesfortwostations,FSM13(includedintheanalysis)andMI5(leftoutoftheanalysis).
The posterior probabilities of rainfall occurrence seem to follow the general trend of the observed
binary time series. Also, for station MI5, we tested the capability of the model in handling missing
data, especifically for the days 121–170 (delimited by the vertical dashed lines). Note that the tem-
poral behaviour of the probability is mainly driven by the third factor, which is expected, given the
location of the station.
∥
An alternative specification for the factor loadings matrix can be considered for the SDFM. For
example, the discrete process convolution approach proposed in [25], or (more recently) the

Hierarchical modelling in time series
175
0
2
4
6
8
10
12
0
2
4
6
8
10
Fitted values
(a) Fitted versus observed values
(c) 2004, 1st week
(d) 2004, 12th week
(b) Interpolated values at SPD station
Observed values
Time
1998
1999
2000
2001
2002
2003
2004
0
2
4
6
8
10
−86
−84
−82
−80
−78
−76
−74
34
36
38
40
42
44
 2 
 2 
 2.5 
 2.5 
 3 
 3 
 3.5 
 3.5 
 4 
 4.5 
ESP
SAL
MCK
OXF
DCP
CKT
LYK
PNF
QAK
CDR
VPI
MKG
PAR
KEF
SHN
PED
PSU
ARE
BEL
CTH
WSP
CAT
 2 
 2 
 2.5 
 2.5 
 3 
 3 
 3.5 
 3.5 
 4 
 4.5 
ESP
SAL
MCK
OXF
DCP
CKT
LYK
PNF
QAK
CDR
VPI
MKG
PAR
KEF
SHN
PED
PSU
ARE
BEL
CTH
WSP
CAT
2
2.5
3
3.5
4
4.5
−86
−84
−82
−80
−78
−76
−74
34
36
38
40
42
44
1.8
 2 
 2 
 2.2 
 2.2 
2.4
 2.4 
 2.6 
 2.8 
 2.8 
 3 
3
 3.2
 3.2 
3.4
3.6
 3.8 
1.8
 2 
 2 
 2.2 
 2.2 
2.4
 2.4 
 2.6 
 2.8 
 2.8 
 3 
3
 3.2
 3.2 
3.4
3.6
 3.8 
ESP
SAL
MCK
OXF
DCP
CKT
LYK
PNF
QAK
CDR
VPI
MKG
PAR
KEF
SHN
PED
PSU
ARE
BEL
CTH
WSP
CAT
ESP
SAL
MCK
OXF
DCP
CKT
LYK
PNF
QAK
CDR
VPI
MKG
PAR
KEF
SHN
PED
PSU
ARE
BEL
CTH
WSP
CAT
2
2.5
3
3.5
4
4.5
Figure 9.3 (a) Plot of fitted versus observed values of NO3 for the whole period and for the 22
stations. (b) Interpolated values at SPD station left out from the sample used for fitting. Dashed lines
represent the 95% credible intervals and the symbol × the observed NO3 concentration level. (c)–(d)
Forecast values for two different weeks in 2004.
spatial model considering compact support kernels as proposed in [28]. Here, we discuss a related
approach that uses an approximate Gaussian process for β(j)s instead of deterministic kernels. This
newmodelspecificationwasrecentlyproposedin[43]forcomparingandblendingregionalclimate
model predictions. See the cited paper for more details related to the fully Bayesian treatment of the
model.
More specifically, for each yt(s) measured at time t and location s we have that
yt(s) = μt(s) + ωt(s) + ϵt(s),
ϵt(s) ∼N(0, σ2)
(9.12)
where μt(s) may represent a regression component and ωt(s) is the space–time compo-
nent that follows a Gaussian process. Many specifications can be considered for ωt(s). Here
we opted to use the modified predictive process (see [11] and the references therein), let-
ting ωt(s) = ˜ωt(s) + ˜ϵt(s), where ˜ϵt(s) ∼N(0, τ2 −v(s)TH−1v(s)) and ˜ωt(s) is represented
on a set of k basis functions Bl(s) = [v(s)TH−1]l where v(s) = τ2(ρφ(s, s∗
1), . . . , ρφ(s, s∗
k)),

176
D. Gamerman and E. Salazar
130
140
150
160
170
180
−20
−15
−10
−5
0
5
10
15
Australia
Papua
New Guinea
FSM1
FSM2
FSM3
FSM4
FSM5 FSM6
FSM7
FSM8
FSM9
FSM10
FSM11
FSM12
FSM13
MI1
MI2
MI3
MI4
+
FSM14
+
MI5
Stations
Left out stations
Study area
FSM: Federated States of Micronesia
MI: Marshall Islands
longitude
latitude
0
50
100
150
200
250
300
350
0.0
0.2
0.4
0.6
0.8
1.0
Days
0
50
100
150
200
250
300
350
0.0
0.2
0.4
0.6
0.8
1.0
Days
(a) Station and study area
(b) Posterior probability of rain
Figure 9.4 (a) Location of the monitoring stations. (b) Daily posterior probability of rainfall occurrence
at FSM13 station (above) and MI5 station(below). The latter shows the results of the spatial interpola-
tion since station MI5 was left out of the analysis for interpolation purposes. Dots are rain indicators,
solid lines are rain mean probabilities and dashed lines are 95% credibility intervals.
FSM1
FSM2
FSM3
FSM4
FSM5FSM6
FSM7
FSM8
FSM9
FSM10
FSM11
FSM12
FSM13
MI1
MI2
MI3
MI4
+
FSM14
+
MI5
−1
−0.5
0
0.5
1
FSM1
FSM2
FSM3
FSM4
FSM5FSM6
FSM7
FSM8
FSM9
FSM10
FSM11
FSM12
FSM13
MI1
MI2
MI3
MI4
+
FSM14
+
MI5
−0.5
0
0.5
1
FSM1
FSM2
FSM3
FSM4
FSM5FSM6
FSM7
FSM8
FSM9
FSM10
FSM11
FSM12
FSM13
MI1
MI2
MI3
MI4
+
FSM14
+
MI5
0
0.5
1
1.5
2
30
60
90 120 150 180 210 240 270 300 330 360
−2
−1
0
1
2
Days
30
60
90 120 150 180 210 240 270 300 330 360
−2
−1
0
1
2
3
Days
30
60
90 120 150 180 210 240 270 300 330 360
−2
−1
0
1
2
Days
Figure 9.5 First row: Bayesian interpolation of the three columns of the factor loadings matrix. Values
represent the range of the posterior means. Second row: Daily posterior means of the first, second
and third dynamic factors. Solid lines represent the posterior means and dashed lines the 95%
credible intervals.
{H}lm = τ2ρφ(s∗
l , s∗m) for l, m = 1, . . . , k and {s∗
l ; l = 1, . . . , k} a set of selected knots and is given
by ˜ωt(s) = k
l=1 Bl(s)γt,l = B(s)Tγ t.
The temporal evolution of γ t is specified as γ t ∼N(ψγ t−1, H) where ψ ∼N(−1,1)
(μψ, σψ). After a SVD decomposition of H = PPT and letting γ t = Pf t we can rewrite ˜ωt(s)
as ˜ωt(s) = B(s)TPf t = β(s)Tf t and therefore f t ∼N(ψf t−1, ) (with independent elements
given that  is a diagonal matrix).
If we conveniently rewrite eqn (9.12) in vector notation and by considering the previous specifi-
cation we have

Hierarchical modelling in time series
177
yt = μt + βf t + ˜ϵt + ϵt
f t = ψf t−1 + ωt,
ωt ∼N(0, )
The previous specification resembles the SDFM where β is an n × k matrix with k being the
number of pre-selected knots (fixed),  = diag(λ1, . . . , λk) with λ1 > . . . > λk, therefore β(1)
describes the main model of spatial variability, β(2) the second, and so on.
Finally, in the following example we describe a spatial hierarchical dynamic factor model
(SHDFM) for socio-economic multi-level measurements. The idea is to build a model-based vul-
nerability index that account for the different levels of hierarchy (for example, census tracts and
capitals). The spatial version of this model was proposed in [33] to build Uruguayan vulnerability
index at different geographical resolutions.
Example
9.3
Consider the p-dimensional vector of socio-economical variables yijt =
(yijt,1, . . . , yijt,p) at capital i (i = 1, . . . , I), census tract j (j = 1, . . . , ni) and time t. We aim to
infer vulnerability indexes at two levels of resolution: capitals (coarse level) and census tracts (fine
level). The proposed two level SHDFM can be written as
yijt = μ + βf (1)
ijt
+ ϵ(1)
ijt ,
ϵ(1)
ijt ∼N(0, )
f(1)
ijt
= θit + f (2)
ijt
+ ϵ(2)
ijt ,
ϵ(2)
ijt ∼N(0, ψ)
f (2)
it
= f (2)
i,t−1 + wit,
wit ∼N(0, τ2
i Pi)
θt = θt−1 + vt,
vt ∼N(0, δ2H)
where β = (1, β2, . . . , βp)T
(that implies a 1-factor model for the first level),  =
diag(σ2
1 , . . . , σ 2p ). Within capital i, the one dimensional factor f (1)
ijt
is decomposed as the
sum of two spatial components: θit (capital-level) and f (2)
ijt (census tract-level). Note that the f (2)
ijt ’s
are conditionally independent and the joint vector f (2)
it
= (f (2)
i1t , . . . , f (2)
init )T follows a Markovian
evolution where the system innovation wit follows a proper Gaussian Markov random field. More
specifically, Pi = (Ini + φMi)−1 where {Mi}lk = m(i)
k
if l = k and {Mi}lk = −1/d(i)
lk if sites
l and k are neighbours (denoted by l ∼k) and zero otherwise, m(i)
k = 
l∼k 1/d(i)
lk and d(i)
lk is
the Euclidean distance between centroids of regions l and k (see [51] for more details about this
construction). An additional assumption is that the θits are conditionally independent so the joint
vector θt = (θ1t, . . . , θnit)T follows a Markovian evolution where the innovation vt follows a zero
mean Gaussian process with covariance structure H driven by the Euclidean distances between
the centroids of the capitals. In this multi-level factor model, f (1)
ijt represents the vulnerability index
at the census tract level of the capital i (fine level) and θit is the capital vulnerability index (coarse
level). Note that the SHDFM takes full advantage of the multi-level data structure through the
hierarchical specification of the common factor.
∥
9.5 Regression with dynamic factor models
The ideas so far have been restricted to a single collection of time series. Even though any time
series problem can be cast in a single collection of time series, the collections usually considered
have a unified framework relating them. Typically they are measurements in a variety of settings of
the same quantity. As such, they behave like a (random) sample of time series.

178
D. Gamerman and E. Salazar
This section extends the scope of DFM beyond random samples by considering regression. The
general idea of a regression is to explain a variable by a set of covariates. In time series context,
this means explaining the behaviour of a (possibly multivariate) time series by a number of related
explanatory time series. Although the approach is quite general, it is better explained without much
loss of generality in the context of simple regression.
So from now on, we will restrict our attention to the situation where a collection of time series
forming a multivariate time series yt of a given variable is explained by another collection of time
series forming a multivariate time series xt of another given variable. This is a well-known setup
in time series, sometimes referred to as transfer response models, covered in many standard time
series books.
The idea of dimensionality reduction via factor models in the regression context is also not new
and is also related to the basic factor model setup, as expected. Considering a set of multivariate
observations yt related to another collection of observations xt at a latent level gives rise to the
structural equation model (SEM)
yt = βygt + ϵyt,
ϵyt ∼N(0, y)
xt = βxf t + ϵxt,
ϵxt ∼N(0, x)
gt = ygt + f t + εt,
εgt ∼N(0, g)
The loading matrices βx and βy play exactly the same role as in factor models. The novelty here is
the introduction of the relational matrices  and y, establishing a regression relation between the
set of variables xt and yt at a latent level. This basic SEM setup is described in detail in [46]. The
Bayesian approach to SEM is described in [37]. It is worth pointing out that the standard factor
model (9.1) is recovered after suitable concatenation of observables (xt, yt) and factors (f t, gt),
respectively.
The extension towards time series problems is not difficult to obtain following the standard
recipe of the previous sections of this chapter. Just like (9.2) establishes the dynamic of the factors
for the time series settings, in [9] was proposed the dynamics of the two sets of factors as
g(t) =
p

i=0
yigt−i +
q

j=0
jf t−j + εgt,
εgt ∼N(0, g),
f(t) =
s

j=1
xjf t−j + εft,
εft ∼N(0, f ).
HereferstothismodelasdynamicSEM.[12]castthedynamicSEMinstatespaceformandapplied
it to the analysis of environmental problems. Once again, the DFM given in (9.1)–(9.2) can be
recovered by appropriate concatenation of observables (xt, yt) and factors (f t, gt). Even more so
than in DFM, it is very hard to estimate this model in its full expression for typical applications.
The more natural simplifications can be obtained by restricting the order p, q, s of the auto- and
cross-regressions to small values, say 1 or 2. Once again, the model can be written in state-space
form by appropriately enlarging the state vector according to the order of lagged dependence of the
latent factors.
These ideas were applied to the Spatial Statistics context in [27]. Once again, the columns
of the loading matrices were assumed to follow independent Gaussian processes in order to
impose stochastic similarity between neighbouring sites. The presence of two sets of variables
introduces further possibilities beyond standard DFM. In particular, relationships between the
loading matrices βx and βy may be introduced. For example, [27] use βx as a (latent) design

Hierarchical modelling in time series
179
matrix for the mean of βy. Illustrative examples and further discussion about model specification
and evaluation is provided in [27].
9.6 Concluding remarks
This chapter was concerned with a discussion on the use of factor models in the time series context
via state space formulation. The key element of the approach is its ability to reduce the dimension-
ality in the multivariate time series context and at the same time to shed some light on the structure
of the relationship between the different time series. Our presentation has focused exclusively on
the discussion about model building. As a result, a number of other issues were not addressed. We
will briefly comment upon them now.
By far the most important item not yet discussed is prediction. Time series are primarily con-
cerned with forecasting into the future. The model-based approach of state space models followed
here enables easy calculation of the predictive distributions p(yT+h|yT), for all h. This is available
approximately after obtaining the predictive distributionp(f T+h|yT) for the latent factors and pre-
dictionscanbeapproximatedbysamples.ThisexercisewasmadeinExamples9.2and9.3.Notealso
that the prediction exercise is very similar to the kriging exercise required for spatial extrapolation,
and that was also illustrated in the examples above. Details are provided in [32].
Another important issue is generated by the large amount of possibilities rendered by these
classes of models. There are a number of options provided by the choice of the number of regular
and seasonal factors and the order of the factor dynamics. There are a few options available for
model selection including AIC, BIC and DIC. These are mostly based on model fit after some
penalization for complexity. One may also consider estimation of the number of factors in a RJM-
CMC algorithm. In this time series, we feel that model comparison should be more heavily based
on predictions rather than fit. Even more so than in the other areas of statistics, given the relevance
of prediction for the time series context. Standard practice in this area is based on cross-validation,
where a portion of the data is left out of the fit. This portion typically consists of the last observed
points to mimic the real exercise of forecasting into the future.
The description above illustrates some of the many possibilities for the use of factor models in
thetimeseriescontext.Thepresentationofspatialapplicationswasentirelyondatacollectedunder
continuous spatial variation. Similar ideas were applied to the context of discrete spatial variation
or areal data in [47]. There are a number of extensions that can be envisaged by appropriately
combining some of the model components described in this chapter. We are currently working on
some of these and will be reporting them in the near future.
Acknowledgements
D. Gamerman was supported by CNPq-Brazil and Fundação de Amparo à Pesquisa no Estado do Rio
de Janeiro (FAPERJ foundation). E. Salazar would like to thank the Department of Electrical and
Computer Engineering at Duke University for their support.
Author’s footnote
This book is very timely, right after Professor Adrian Smith’s contributions to Science earned him
a well-deserved knighthood. And we congratulate the editors for compiling this tribute.

180
D. Gamerman and E. Salazar
References
[1] Anderson, T. W. (1963). The use of factor analysis in the statistical analysis of multiple time
series. Psychometrika, 28, 1–25.
[2] Aguilar, O. and West, M. (2000). Bayesian dynamic factor models and portfolio allocation.
Journal of Business and Economic Statistics, 18, 338–357.
[3] Arminger, G. and Muthén, B. O. (1998). A Bayesian approach to nonlinear latent variable
models using the Gibbs sampler and the Metropolis–Hastings algorithm. Psychometrika, 63,
271–300.
[4] Bai, J. and Ng, S. (2002). Determining the number of factors in approximate factor models.
Econometrica, 70, 191–222.
[5] Bhattacharya,A.andDunson,D.B.(2011).SparseBayesianinfinitefactormodels. Biometrika,
98, 291–306.
[6] Calder, C. (2007). Dynamic factor process convolution models for multivariate space-time
data with application to air quality assessment. Environmental and Ecological Statistics, 14,
229–247.
[7] Carter, C. and Kohn, R. (1994). On Gibbs sampling for state space models. Biometrika, 81,
541–553.
[8] Carvalho,C.,Chang,J.,Lucas,J.,Nevins,J.,Wang,Q.andWest,M.(2008).High-dimensional
sparse factor modelling: applications in gene expression genomics. Journal of the American
Statistical Association, 103, 1438–1456.
[9] Cziráky, D. (2004). Estimation of dynamic structural equation models with latent variables.
Metodološki zvezki, 1, 185–204.
[10] Engle, R. and Watson, M. (1981). A one-factor multivariate time series model of metropolitan
wage rates. Journal of the American Statistical Association, 76, 774–781.
[11] Finley, A. O., Sang, H., Banerjee, S. and Gelfand, A. E. (2009). Improving the performance of
predictive process modelling for large datasets. Computational Statistics and Data Analysis, 53,
2873–2884.
[12] Fontanella, L., Ippoliti, L. and Valentini, P. (2007). Environmental pollution analysis by
dynamic structural equation models. Environmetrics, 18, 265–283.
[13] Forni, M., Hallin, M., Lippi, M. and Reichlin, L. (2000). The generalized dynamic
factor model: identification and estimation. The Review of Economics and Statistics, 82,
540–554.
[14] Frühwirth-Schnatter, S. (1994). Data augmentation and dynamic linear models. Journal of
Time Series Analysis, 15, 183–202.
[15] Frühwirth-Schnatter, S. and Lopes, H. F. (2010). Parsimonious Bayesian factor analysis when
the number of factors is unknown. Technical Report. The University of Chicago Booth School
of Business.
[16] Gamerman, D. and Migon, H. S. (1993). Dynamic hierarchical models. Journal of the Royal
Statistical Society, Series B, 55, 629–642.
[17] Gamerman, D. and Smith, A. F. M. (1996). Bayesian analysis of longitudinal data studies, in
Bayesian Statistics 5 (eds J. M. Bernardo et al.), Oxford University Press, Oxford, pp. 587–598.
[18] Gelfand,A.E.andSmith,A.F.M.(1990).Sampling-basedapproachestocalculatingmarginal
densities. Journal of the American Statistical Association, 85, 398–409.
[19] George, E. I. and McCulloch, R. (1993). Variable selection via Gibbs sampling. Journal of the
American Statistical Association, 88, 881–889.
[20] Geweke, J. (1977). The dynamic factor analysis of economic time series models. In Latent
Variables in Socio-Economic Models (eds. D. J. Aigner and A. S. Goldberger). North Holland:
Amsterdan, 365–383.

Hierarchical modelling in time series
181
[21] Geweke, J. F. and Zhou, G. (1996). Measuring the pricing error of the arbitrage pricing theory.
The Review of Financial Studies, 9, 557–587.
[22] Gorsuch, R. L. (1983). Factor Analysis. 2nd edition, Hillsdale: Lawrence Erlbaum Associates.
[23] Green, P. (1995). Reversible jump Markov chain Monte Carlo computation and Bayesian
model determination. Biometrika, 82, 711–732.
[24] Higdon, D. (1998). A process-convolution approach to modelling temperatures in the north
Atlantic Ocean. Environmental and Ecological Statistics, 5, 173–190.
[25] Higdon, D. (2002). Space and space-time modelling using process convolutions. In Quantita-
tive Methods for Current Environmental Issues, eds. C. Anderson, V. Barnett, P. C. Chatwin and
A. H. El-haarawi, London: Springer Verlag, pp. 37–56.
[26] Huerta, G. and West, M. (1999). Priors and component structures in autoregressive time
series models. Journal of the Royal Statistical Society, Series B, 61, 881–899.
[27] Ippoliti, L., Valentini, P. and Gamerman, D. (2012). Space-time modelling of coupled spa-
tio-temporal environmental variables. To appear in Applied Statistics.
[28] Lemos, R. T. and Sansó, B. (2009). A spatio-temporal model for mean, anomaly, and trend
fields of north Atlantic sea surface temperature. Journal of the American Statistical Association,
104, 5–25.
[29] Lindley, D. V. and Smith, A. F. M. (1972). Bayes estimates for the linear model (with discus-
sion). Journal of the Royal Statistical Society, Series B, 34, 1–41.
[30] Lopes, H. F. and Carvalho, C. M. (2007). Factor stochastic volatility with time varying
loadings and Markov switching regimes. Journal of Statistical Planning and Inference, 137,
3082–3091.
[31] Lopes,H.F.,Gamerman,D.andSalazar,E.(2011)Generalizedspatialdynamicfactoranalysis.
Computational Statistics and Data Analysis, 55, 1319–1330.
[32] Lopes, H. F., Salazar, E. and Gamerman, D. (2008). Spatial dynamic factor analysis. Bayesian
Analysis, 3(4), 759–792.
[33] Lopes, H. F., Schmidt, A. M., Salazar, E., Gomez, M. and Achkar, M. (2012) Measuring the
vulnerability of the Uruguayan population to vector-borne diseases via spatially hierarchical
factor model. To appear in Annals of Applied Statistics.
[34] Lopes, H. F. and West, M. (2004). Bayesian model assessment in factor analysis. Statistica
Sinica, 14, 41–67.
[35] Meng, X. L. and Wong, W. H. (1996). Simulating ratios of normalizing constants via a simple
identity: a theoretical exploration. Statistica Sinica, 6, 831–860.
[36] Molenaar, P. C. M. (1985). A dynamic factor model for the analysis of multivariate time series.
Psychometrika, 50, 181–202.
[37] Palomo, J., Dunson, D. B. and Bollen, K. (2007). Bayesian structural equation modelling.
Handbook of Latent Variable and Related Models, Sik-Yum Lee (editor), Elsevier.
[38] Pan, J. and Yao, Q. (2008). Modelling multiple time series via common factors. Biometrika, 95,
365–379.
[39] Peña, D. and Box, G. (1987). Identifying a simplifying structure in time series. Journal of the
American Statistical Association, 82, 836–843.
[40] Peña, D. and Poncela, P. (2004). Forecasting with nonstationary dynamic factor models.
Journal of Econometrics, 119, 291–321.
[41] Peña, D. and Poncela, P. (2006). Nonstationary dynamic factor analysis. Journal of Statistical
Planning and Inference, 136, 1237–1257.
[42] Polasek, W. (1997). Factor analysis and outliers: a Bayesian approach. Discussion paper, Uni-
versity of Basel.
[43] Salazar, E., Sansó, B., Finley, A., Hammerling, D., Steinsland, I., Wang, X. and Delamater, P.
(2011). Comparing and blending regional climate model predictions for the American south-
west. Journal of Agricultural, Biological, and Environmental Statistics, 16, 586–605.

182
D. Gamerman and E. Salazar
[44] Sansó, B., Schmidt, A. M. and Nobre, A. A. (2008). Bayesian spatio-temporal models based
on discrete convolutions. Canadian Journal of Statistics, 36, 239–258.
[45] Sargent, T. J. and Sims, C. A. (1977). Business cycle modelling without pretending to have too
much a priori economic theory. In New Methods in Business Research (ed. C. A. Sims). Federal
Reserve Bank of Minneapolis.
[46] Skrondal, A. and Rabe-Hesketh, S. (2004). Generalized Latent Variable modelling, Chapman
& Hall, Boca Raton.
[47] Strickland, C., Simpson, D., Turner, I., Denham, R. and Mengersen, K. (2010). Fast Bayesian
analysis of spatial dynamic factor models for multitemporal remotely sensed imagery. Applied
Statistics, 60, 109–124.
[48] Stroud, R., Müller, P. and Sansó, B. (2001). Dynamic models for spatiotemporal data. Journal
of the Royal Statistical Society, Series B, 63, 673–689.
[49] Thurstone, L. L. (1931). Multiple factor analysis. Psychological Review, 38(5), 406–427.
[50] Thurstone, L. L. (1947). Multiple Factor Analysis. Chicago: University of Chicago Press.
[51] Vivar, J. C. and Ferreira, M. A. R. (2009). Spatiotemporal models for Gaussian areal data.
Journal of Computational and Graphical Statistics, 18(3), 658–674.
[52] Wikle, C. K. and Cressie, N. (1999). A dimension-reduced approach to space-time Kalman
filtering. Biometrika, 86, 815–829.
[53] West, M., Harrison, P. J. and Migon, H. S. (1985). Dynamic generalized linear models and
Bayesian forecasting (with discussion). Journal of the American Statistical Association, 81,
741–750.
[54] West, M. and Harrison, J. (1997). Bayesian Forecasting and Dynamic Models, Springer,
New York.

10
Dynamic and spatial
modelling of block
maxima extremes
gabriel huerta and
glenn a. stark
10.1 Introduction
F
igure 10.1 shows the monthly maxima of precipitation at the Maíquetia-Simon Bolivar airport
near Caracas, Venezuela within the period 1960–1999. The data only considers measurements
at one site and has critical importance in extreme value analysis due to the catastrophic events
that occurred near this location at the end of the year 1999. For example [5] carefully considered
a Bayesian analysis of the annual maxima rainfall values at the same site, based on models that fully
account for parameter uncertainties and non-stationarity in the data. Furthermore [16], analysed
themonthlyrainfallmaximaofFigure10.1viadynamicregressionsasin[29],[28]andinconnection
with a climatological index known as the North Atlantic Oscillation (NAO). Here we consider these
rainfall observations as a starting point to study extreme events via the Generalized Extreme Value
(GEV) distribution. Two key questions that arise from Figure 10.1 are: (1) How do we characterize
these rainfall events? and (2) How do we assess for the non-stationary behaviour that is apparent in
the data?
10.1.1 GEV distribution and likelihood
Let ym,1, ym,2, . . . , ym,n be samples of extremes from m independent observations (i.e. block max-
ima), where m is the number of observations in each block and n is the number of blocks. For the
precipitation maxima of Figure 10.1, a uniform block size across time was considered to produce the
observations.Inapplicationsofblock-maximavaluesitistypicaltoassumethatym,i,i = 1, 2, . . . , n,
areindependentandarisefromacommonGEVdistributionasin[4]and[1].Ify ∼GEV(μ, σ, ξ),
the cumulative distribution function for y is:
H(y) = exp

−
1
1 + ξ
y −μ
σ
2−1/ξ
+

(10.1)
where −∞< μ < ∞is a location parameter, σ > 0 is a scale parameter and −∞< ξ < ∞is
a shape parameter. The + sign denotes the positive part of the argument so the support for H(y)

184
G. Huerta and G. A. Stark
Time
rainfall
1960
1970
1980
1990
2000
0
20
40
60
80
100
120
140
Figure 10.1 Monthly maxima of precipitation in Venezuela.
is given by the set {y : 1 + ξ( y−μ
σ ) > 0}. It is well known that different values of ξ imply different
tail behaviours or domains of attraction for H(y), namely Gumbel (ξ →0), Fréchet (ξ > 0) and
Weibull (ξ < 0). H(y) arises through a limiting argument for block maxima in the Extremal Type
or Fisher-Tippet theorem in [10] and also presented in [4] and [1], so if the block size is large
enough, one may assume that the observations ym,i follow a GEV distribution. Therefore, if we
drop the dependence on the block size so that yi = ym,i, the GEV log-likelihood function based on
n observations is
l(μ, σ, ξ|{yt}n
t=1) = −n log σ −(1 + 1/ξ)
n

i=1
log{1 + ξ(yi −μ)/σ}
−
n

i=1
{1 + ξ(yi −μ)/σ}−1/ξ.
(10.2)
10.1.2 Bayesian inference on the GEV
From a Bayesian point-of-view inferences on (μ, σ, ξ) can be directly obtained with Markov chain
Monte Carlo (MCMC) methods based on a Gibbs sampling approach as in [13] with embedded
Metropolis–Hastings (M-H) steps as in [15]. For instance, a prior distribution p(μ, σ, ξ) can be
induced through a trivariate normal distribution on (μ, log(σ), ξ) which includes the case of an
independence prior.
As described in [6], beta distributions for probability ratios or gamma distributions for quantile
differencecouldalternativelybeusedtoelicitp(μ, σ, ξ).Inparticular,thequantile-differencepriors
can be elicited via the 1 −p quantile of a GEV distribution which has a closed form in terms of the
three parameters, zp = μ −σ
ξ [1 −{−log(1 −p)}−ξ ].
The posterior distribution for (μ, log(σ), ξ) can be sampled with random walk proposals on
each of the parameters as presented in [4] and [1],

Dynamic and spatial modelling of extremes
185
μ
σ
ξ
Q0.95
7
8
9
10
11
8
9
10
11
0.3
0.4
0.5
0.6
0.7
50
60
70
80
90
0.0
0.2
0.4
0.6
0.0
0.2
0.4
0.6
0
1
2
3
4
5
6
0.00
0.02
0.04
0.06
Figure 10.2 Marginal posterior distribution for (μ, σ, ξ) and 95% quantile of the GEV distribution.
log(σ ∗) = log(σ (i)) + νσ ϵ1
(10.3)
μ∗= μ(i) + νμϵ2
(10.4)
ξ∗= ξ(i) + νξ ϵ3
(10.5)
where ϵj ∼N(0, 1); j = 1, 2, 3 and νσ , νμ, νξ denote the proposal tuning parameters. The pro-
posed values are accepted or rejected as iterations of the MCMC are performed. To illustrate this
method, Figure 10.2 shows histograms of posterior samples for μ, σ, ξ and z0.05 corresponding to
the data of Figure 10.1 and via this hybrid Gibbs sampling/Metropolis–Hastings method.
It is interesting to note that quantile estimation can also be achieved through the predictive
distribution,
p(yf |y) =
 ∞
−∞
 ∞
0
 ∞
−∞
f(yf |μ, σ, ξ)p(μ, σ, ξ|y)dμdσdξ
(10.6)
where yf denotes a future observation. Here f(yf |μ, σ, ξ) represents the probability den-
sity function for this future observation based on the GEV distribution and conditional to
model parameters. Through the Method of Composition it is possible to obtain samples of
yf from the predictive distribution. An empirical quantile based on these samples approxi-
mates the value y∗such that P[Yf ≤y∗|y] = 1 −p, which fully takes into account all of the
model parametric uncertainties. In fact, for the maximum monthly rainfall data of Figure 10.1,
the 99% quantile based on the predictive distribution (p = 0.01) is 162.87. On the other
hand, if the GEV distribution is fitted with Maximum Likelihood Estimation (MLE), the 99%

186
G. Huerta and G. A. Stark
quantile is estimated as 152.3. Furthermore, the posterior mean of the GEV distribution quantile,
z0.01, is 157.35.
Bayesian approaches for extreme values had been extensively studied from the beginning of
Bayesian computation with MCMC and other numerical approximations. The paper by [25] is
one of the first to illustrate the Bayesian modelling of extremes within the GEV framework. Also
[7] offers some developments of Bayesian approaches to extreme value theory with applications
to modelling areal rainfall extremes. A thorough review of the topic is offered by [6] where the
authors studied the Bayesian approach from a variety of aspects, including how priors can be
better elicited for extreme value data and how well a complete Bayesian analysis, that includes
predictive-quantile estimation, performs compared to a pure likelihood based analysis as briefly
illustrated here with the rainfall data at the Maíquetia/Simon Bolivar airport. The R-package evd-
bayes described in [26] and [27] implements the techniques in [6] including quantile-based prior
specifications and peaks-over-threshold analysis. However, the modelling described in these refer-
encesismainlyrestrictedtoconstantparametersortoparametersthatmayhavedeterministictrends
in time.
10.2 Time-varying models for the GEV distribution
10.2.1 Introduction
Toaccountforthetypeofnon-stationaritiesthatarepresentinthedataofFigure10.1,wecanimpose
a time-dependent structure on any set of parameters of the GEV distribution. Here, we emphasize
on a GEV distribution with a time-varying location parameter,
H(yt) = exp

−
1
1 + ξ
yt −μt
σ
2−1/ξ
+

,
t = 1, 2, . . . n
(10.7)
If a deterministic function is chosen to model time changes in μt, this can be expressed in a gener-
alized form as
μt = g(XTβ)
(10.8)
where g is a specific link function, β is a vector of parameters and XT is a vector of covariates that
involvestime.Inparticularμt canfollowalineartrend,μt = β0 + β1t,ahigherdegreepolynomial
such as μt = β0 + β1t + β2t2 or a trend/seasonal model, μt = β0 + β1t + β2S(t), where S(t)
represents the seasonal component. In this context, [4] discusses extensively these various models.
On the other hand, μt can be treated as a stochastic process that depends on time through a
hierarchical specification.
10.2.2 Dynamic linear model
We consider Dynamic Linear Models (DLMs) or state-space models as in [28] and [29] as our main
choice for non-stationary modelling of the location parameter of the GEV distribution. We focus
on DLMs to assess whether any short-term changes can occur in the extremal-type distribution. If
zt, t = 1, 2, . . . represents a vector of observations of dimension r at time t, following the notation
in [29], a DLM for zt is specified as,
zt = F′
t θt + vt,
vt ∼N(0, Vt)
(10.9)

Dynamic and spatial modelling of extremes
187
θt = Gt θt−1 + wt,
wt ∼N(0, Wt)
(10.10)
θ0|D0 ∼N(m0, C0)
(10.11)
where F′t is assumed to be a known (r × n) regression matrix and Gt is assumed as a known (n × n)
state matrix. Equation 10.9 defines the observation equation of the DLM and the variance of the
observation error is given by the r × r matrix Vt. Equation 10.10 is called the system or evolution
equation and Wt is the n × n variance–covariance matrix of the evolution error. The errors vt and
wt are generally assumed to be mutually independent. To obtain Bayesian inference on the state
vector of the DLM, a prior distribution on the initial state is needed and is defined by equation
10.11, where m0 defines the forecaster’s initial belief about the level θ0 and C0 is the associated
measure of uncertainty. At the lack of any true prior information, we adopt a non-informative prior
where the mean level is fixed to an arbitrary constant and C0 is given a large value. The quadruple
(Ft, Gt, Vt, Wt) characterizes completely the DLM, so different quadruples define different subsets
of the general class of DLMs. A special case of the quadruple is given by (1, 1, V, W), which is
referred to as a first-order polynomial DLM in [29].
10.2.3 DLMs and the GEV distribution
DLMs had been used by [12] and [16] for time-varying extreme value models. [12] outlines a semi
parametric approach for smoothing extremes with applications to athletic records and temperature
data. On the other hand, [16] consider DLMs for assessing dynamic trends and space–time struc-
tures for extreme values of ozone levels. Here we follow [16] and focus our presentation for the case
of a time-varying location parameter.
Let {y1, y2, . . . , yn} be independent realizations from a GEV distribution (μt, σ, ξ) conditional
onmodelparameters.Assumethatthetemporaldependencyonthelocationparameterismodelled
through a DLM as just described in 10.2.2. For this case, the GEV likelihood function is:
L({μt}n
t=1 ξ, σ| {yt}n
t=1) =
n

t=1
1
σ
1
1 + ξ
yt −μt
σ
2−(1+ 1
ξ )
+
exp

−
1
1 + ξ
yt −μt
σ
2−1
ξ
+

.
(10.12)
Assuming a first-order polynomial DLM (1, 1, V, W) on μt, we have
μt = θt + vt ,
vt ∼N(0, V)
(10.13)
θt = θt−1 + wt ,
wt ∼N(0, W)
(10.14)
In [7] the authors argue that prior eliciting in terms of quantiles or quantile differences is to be
preferred over priors on GEV parameters for constant modelling situations. Given the complex-
ities of a DLM-time-varying GEV model, we choose priors on the GEV parameters. The obser-
vational equation in 10.13 defines a prior for each μt conditional on θt and V, μt ∼N(θt, V),
t = 1, . . . , n. We adopt independent normal priors for log σ and ξ,
log σ ∼N(Mσ , Vσ ),
ξ ∼N(Mξ, Vξ )
(10.15)
For V we adopt an inverse gamma prior, V ∼IG(a, b), which provides a conditionally conju-
gate structure for this parameter. We adopt discount factors as in [29] to deal with the evolution

188
G. Huerta and G. A. Stark
variance W. The discount factor represents the change of information on state parameters from
time t −1 to time t, which in [16] has proven its use for temporal and space-time modelling of
extremes within the DLM framework.
10.2.4 MCMC for DLM-GEV distribution
The joint posterior distribution for all the model parameters, ({μt}n
t=1, ξ, σ, {θt}n
t=1, V) given the
data {yt}n
t=1 is
p({μt}n
t=1, ξ, σ, {θt}n
t=1, V|{yt}n
t=1) ∝L({μt}n
t=1 ξ, σ| {yt}n
t=1)
n

t=1
1
1
V1/2 exp

−(μt −θt)2
2 V

exp

−(θt −θt−1)2
2 W
2
exp

−(ξ −Mξ)2
2 Vξ

exp

−(log σ −Mσ )2
2 Vσ

V−(a+1) exp(−b/V)
(10.16)
Posterior draws can be obtained through full conditional draws of each parameter based on the
Metropolis or Metropolis–Hastings algorithm. For example, to draw the shape parameter ξ at
iteration i + 1,
1. Wesampleξi+1 fromanormaldistributioncentredatξi whichdefinesasymmetricproposal
distribution based on a random walk.
2. We compute α(ξi, ξi+1) = min

1 p(ξi+1)
p(ξi)

, where p(ξi+1) denotes the full conditional
posterior distribution from Equation 10.16 evaluated at the proposed value and p(ξi) is the
full conditional posterior evaluated at the previous sampled value.
3. Generate u from a U(0, 1) distribution. If u < α(ξi, ξi+1), we accept the proposed value
ξi+1 as our current point in the chain. Otherwise, we reject ξi+1 and keep the previous
point ξi.
Sampling σ and μt follows similar steps. Specifically, we draw each μt individually and use the
prior as the proposal distribution. This leads into a Metropolis ratio that exclusively depends on the
full conditional distribution of μt. More details on this sampling strategy appear in [16]. To draw
{θt}n
t=0 from its full conditional distribution, we use Forward Filtering and Backward Simulation
(FFBS) as in [2] and [11] which, as mentioned in [28], is central to MCMC implementations of
conditionally linear normal models. In our case and following Chapter 4 of [29], the state posterior
distributions conditional on all other model parameters are computed sequentially in time using
the following recursive equations. If δ denotes the DLM discount factor so that W = (1−δ)
δ
Ct−1,
and Dt represents all the information available up to time t, for t = 1, 2, . . . , n
(θt|Dt−1) = N(mt−1, Rt),
Rt = Ct−1 + W = Ct−1/δ
(μt|θt, Dt−1) = N(mt−1, Qt),
Qt = Rt + V
(θt|Dt) = N(mt, Ct),
mt = mt−1 + At(μt −mt−1) , Ct = AtV , At = Rt/Qt
(10.17)
To perform the backward simulation at time t = n, we draw θn from (θn|Dn) and draw the other
θt parameters via retrospective filtering. So for t = n −1, n −2, . . . , 0, θt is drawn conditionally on
θt+1 from a N(ht, Ht) where

Dynamic and spatial modelling of extremes
189
ht = mt + δ(θt+1 −mt),
Ht = Ct(1 −δ).
(10.18)
TheposteriorsimulationfortheDLM-GEVmodelproposedin(10.12–10.14)canbesummarized
as follows. At iteration i + 1, we
• Draw μi+1
t
|yt, μit, σ i, ξi, θit, Vi, for t = 1, . . . , n with individual Metropolis steps.
• Draw σ i+1|{yt}n
t=1, {μi+1
t
}n
t=1, σ i, ξi with a Metropolis step.
• Draw ξi+1|{yt}n
t=1, {μi+1
t
}n
t=1, σi+1, ξi with a Metropolis step.
• Draw {θi+1
t
}n
t=1|{μi+1
t
}n
t=1, Vi via FFBS as described in (10.17–10.18).
• Draw Vi+1|{μi+1
t
}n
t=1, {θi+1
t
}n
t=1 from an inverse-gamma distribution.
Figure10.3 shows theposterior mean ofμt and θt with a 95% probability interval forθt based on our
MCMCapproachfortheMaiquetíarainfalltimeserieswithadiscountfactorδ = 0.9andaburn-in
period of 30000 iterations. The estimated parameters are consistent with a notion of more intense
extremes in recent years. The changes in location parameter from the DLM-GEV are nonlinear and
remarkably different from an estimated trend based only on a deterministic line where the intercept
and slope area fitted via MLE. Furthermore, Figure 10.4 shows the posterior mean estimates of
predictive GEV quantiles for four different probability levels: 95%, 75%, 50% and 5% based on our
modellingapproachandwiththeMaiquetíaextremerainfallmeasurements.Theseestimatesappear
more constant than the parameter estimates but clearly exhibit the non-stationary behaviour and
skewness that is typically present in block maxima observations.
Time
1960
1970
1980
1990
2000
0
5
10
15
20
μt
θt
β0+β1t
Figure 10.3 Posterior mean of μt and θt. 95% probability interval for μt under the GEV-DLM for
Maiquetía rainfall data

190
G. Huerta and G. A. Stark
Time
rainfall
1960
1970
1980
1990
2000
0
20
40
60
80
100
120
140
95%
75%
50%
5%
Figure 10.4 Posterior predictive quantiles based on GEV-DLM model for Maiquetía rainfall data
10.3 A spatial GEV distribution
10.3.1 Introduction
The analysis of extremes from a spatial perspective can arise as a natural extension to the time-
varying GEV distribution-DLM models described in 10.2. The main scope of these spatial models
considers the theory and applications of Gauss Markov Random Fields (GMRFs) as described in
[21], which also discusses the connections of GRMFs to structural time series in the form of DLMs.
Here we consider output of the Penn State/NCAR mesoscale (MM5) Regional Climate Model
(RCM)whichwasdrivenbyaNCAR/DOEparallelclimatemodel.Asimilaroutputwaspreviously
analysed in [8]. The output contains extreme winter (December–January–February) precipitation
of a 20-year control run that assumes current levels of greenhouse gases and begins in 1995. The
spatial domain of the RCM includes 616 (28 × 22) grid points covering the western United States
andsouthwesternCanada.Figure10.5showsmapsoftheoutputprecipitationcorrespondingtotwo
specific years. For year 2004, the extreme values are more intense in regions covering the Pacific
coast, southwestern Canada and Arizona. Figure 10.6 shows the grid points over the spatial domain
along with twenty-five locations that were held out and treated as missing in precipitation for all 20
years to assess the predictive ability of our models.
10.3.2 Objective and Gauss Markov random fields
The goal of our analysis is to treat the RCM output as data and to develop a hierarchical model
around the GEV distribution that permits the characterization of the extremes through predic-
tive quantiles, which may assist climate modellers to evaluate the output performance of the
RCM. In this case, we are not comparing the results from our RCM analysis to real precipitation

Dynamic and spatial modelling of extremes
191
−125 −120 −115 −110 −105
35
40
45
50
Longitude
Latitude
50
100
150
Data:  Year 6
−125 −120 −115 −110 −105
35
40
45
50
Longitude
50
100
150
Data:  Year 9
Figure 10.5 Two years of extreme precipitation for the MM5 Regional Climate Model.
Locations of Data Held Out
Figure 10.6 Grid points for the Regional Climate Model output and holdout locations.

192
G. Huerta and G. A. Stark
Figure 10.7 Stencils of the precision matrix for a IGMRF second-order neighbourhood structure.
measurements arising from station or satellite data. From a modelling standpoint, GMRFs provide
a structure defined through neighbours and precision matrices that has a graphical representation
and is attractive to represent spatial relationships on high-dimensional output from climate models.
The nodes and vertices representing the graph of the GMRF correspond to points on a grid and
neighbours. If Q represents the precision matrix of the GMRF, a point (node) i is connected to a
point j or i ∼j, if and only if Qij ̸= 0. Different specifications of the matrix Q provide different
spatial structures. In particular, our models consider a precision matrix from a biharmonic difference
operator whichcorrespondstoanintrinsic(improper)GMRFasinChapter3of[21].Theschematic
of Figure 10.7 gives this second-order neighbourhood structure where the point of reference is the
node with the associated highest value and corrections are imposed for when this node is near a
boundary. The hierarchical model we propose to analyse the RCM output depends on a likelihood
based on the GEV distribution and a prior level on parameters that involve this second-order
IGMRF. For example [8] considered an IGMRF prior based on a first-order neighbourhood. A
potential advantage of the second-order prior over a first-order structure, is that it adds extra flexi-
bility to represent dependencies for localized climate phenomena like regional storms.
10.3.3 Modelling strategy
More specifically, we assume that Yst ∼GEV(μ∗st, σs, ξ); s = 1, . . . , n; t = 1, . . . , 20 are condi-
tionally independent where Yst represents precipitation from the RCM at the grid location s and
at time t. In our case, n = 616, the number of grid point locations being considered in our analysis.
Therefore the probability distribution for Yst has the form,
H(yst|μ∗
st, σs, ξ) = exp

−
1
1 + ξ
yst −μ∗st
σs
2−1/ξ
+

(10.19)
μ∗
st = μs + φt
(10.20)
so μ∗st has been additively decomposed in space and time. The scale parameter σs is allowed to vary
in space while the shape parameter ξ is kept fixed across space and time with a prior distribution

Dynamic and spatial modelling of extremes
193
(ξ −0.5) ∼Beta(9, 5) which guarantees that −0.5 < ξ < 0.5. This prior distribution was pro-
posed in [17] and has been used as a penalization term in a GEV likelihood function in low sample
size situations. This prior is not overly informative and is restricted to values that are sensible in
studies of extreme precipitation.
Furthermore, we introduce vectors to represent a spatial component for the location and scale
parameters respectively, μ = (μ1, . . . , μn), σ = (σ1, . . . , σn) and η = vec(μ, log(σ)) is a vector
that represents the concatenation of the elements in μ and the logarithm of the elements in σ. We
model η as,
η = (I2 ⊗X)B + U + ϵ,
(10.21)
ϵ ∼N(0, T ⊗In),
(10.22)
U ∼GMRF(0, θ ⊗Q),
(10.23)
T ∼Wishart(nT, VT),
(10.24)
θ ∼Wishart(nθ, Vθ),
(10.25)
B ∼N(0, τBI10).
(10.26)
For this specification both T ⊗In and θ ⊗Q are precision matrices, where Q depends on the
neighbourhood structure, ⊗represents a Kronecker product and Ik is an identity matrix of dimen-
sion k. X is a matrix of covariates with p = 5 columns including an intercept, the longitudes,
latitudes and altitudes of each grid point location and a vector indicating whether a grid point is
located over the ocean or land. We expect that these covariates account for the variability as well
as some of the spatial patterns in η. B is a 10 (2p)-dimensional vector of regression coefficients
where its first five elements are associated to μ and the second five elements to σ. B is assigned
a 10-dimensional normal prior with precision τB. The spatial properties of U are defined through
a GMRF prior which has a precision matrix θ ⊗Q. Here Q is defined through the construction
of a second-order intrinsic GMRF as described in Chapter 3 of [21] and illustrated in Figure 10.7.
The second-order precision matrix Q is not a full rank matrix, and so the GMRF prior for U is not
a proper probability distribution. Therefore, we constrain U so that (I2 ⊗E)′U = 0 where E is a
n × 3matrixwhosecolumnsaretheeigenvectorsofQ withzeroeigenvalues.Thisconstrainguaran-
tees a proper prior on U and allows us to improve on the computational efficiencies of our MCMC
simulations.
In addition, θ is a 2 × 2 positive definite matrix that we model through a Wishart prior and
provides a precision matrix for the blocks μ and σ. The term ϵ represents global variability in η
that is not captured by the model covariates. Every two elements of ϵ are modelled independently
at each grid location with a bivariate normal random variable with a 2 × 2 precision matrix T, to
whichweassignaWishartprior.Thetimetermforμ∗st,φt,followsaN(β1(t −¯t), v), t = 1, . . . , 20,
so β1 measures a potential annual shift in the GEV location parameter over the 20-year control run.
We assign flat prior distributions on both β1 and v.
10.3.4 MCMC approach
The following steps describe the ith iteration of our MCMC method to sample model parameters
and imputed values at held out locations in a Gibbs sampling scheme as in [13]. y represents the full
set of observed and inputed data and φ = (φ1, . . . , φ20).
• For a held out location s, we impute Ys,t from the GEV distribution, Y(i)
st ∼GEV(μ(i−1)
s
+
φ(i−1)
t
, σ (i−1)
s
, ξ(i−1)) for t = 1, . . . , 20.

194
G. Huerta and G. A. Stark
• We draw η(i)|y, B(i−1), U(i−1), φ(i−1), T(i−1), ξ(i−1), X via Metropolis steps for the pair of
values μ(i)
s
and log(σ (i)
s ) at each location s = 1, . . . , n where n = 616 is the number of grid
point locations.
• We use a random walk Metropolis step to draw φ(i)
t |y, η(i), ξ(i−1), β(i−1), v(i−1) for t =
1, . . . , 20.
• We draw β(i)|v(i−1), φ(i) and v(i)|β(i), φ(i) from normal and inverse-gamma distributions
respectively.
• We use a random walk Metropolis step to draw ξ(i)|y, η(i), φ(i).
• We draw B(i−1)|η(i), U(i−1), T(i−1), X from a multivariate normal with mean vector
μB = B(T(i−1) ⊗X′)(η(i) −U(i−1)) and covariance matrix B = (τBI10 + T(i−1) ⊗
X′X)−1.
• We draw Ui|η(i), T(i−1), B(i), θ(i−1), X by first generating U∗from a NC(bU, QU) where
bU = (T(i−1) ⊗In)η(i) −(T(i−1) ⊗X)B(i) and QU = (T(i−1) ⊗In) + (θ(i−1) ⊗Q).
NC designates the canonical parameterization of a GMRF as in [21]. We then correct for the
linearconstraint(I2 ⊗E)
′U = 0,viathemethodofconditioningbyKrigingasdetailedin[21],
page 37. This leads to the expression, U(i) = (I2 ⊗(In −EE
′))U∗. The matrix (I2 ⊗(In −
EE′)) is the perpendicular projection operator that projects U∗into the column space of Q.
• We draw T(i)|η(i), B(i), U(i), X from a Wishart(nT + n, (VT + C′C)−1) where C is a n × 2
matrix with columns μ(i) −XB(i)
1,...,p −U(i)
1,...,n and log(σ (i)) −XB(i)
p+1,...,2p −U(i)
n+1,...,2n,
andwheren = 616isthenumberofgridpointsandp = 5isthenumberofmodelcovariates,
including an intercept. The notation Aj,...,k with j ≤k represents the vector formed with the
consecutive entries of A starting from element j and ending in element k.
• Finally, we draw θ(i)|D, Q from a Wishart(nθ + n, (Vθ + D′QD)−1) where n = 616 and D
is a n × 2 matrix with columns formed by the vectors U(i)
1,...,n and U(i)
n+1,...,2n respectively.
10.3.5 Analysis of the RCM output
Figure 10.8 shows maps for the posterior mean estimates for the vector of location and scale param-
eters respectively based on the MCMC described in Section 10.3.4. The posterior estimates μ are
higher at most locations along the Pacific coast, from Canada to central California, as well as loca-
tions in central Arizona, suggesting that annual precipitation maxima are generally more extreme
in these areas. The estimates of σ are higher along the Pacific coast of Washington state and British
Columbia, along the Sacramento Valley of northern and central California, the coast of southern
California, and in southern Arizona. This suggests that the distribution of annual precipitation
maxima in these areas is more variable than in other areas.
Figure 10.9 shows the posterior distributions of ξ, the constant shape parameter, and of β1,
the slope of the location parameter trend. The posterior distribution of ξ has a mean of 0.063
and a standard deviation of 0.0083. This is very different compared to the prior distribution of
ξ, which is a shifted beta distribution on [−0.5, 0.5] with a mean of 0.1 and a standard deviation
of 0.12. The posterior probability that ξ > 0 is close to one, which corresponds to a Fréchet case.
However the range of values for ξ is lower than that traditionally obtained with GEV distribution
fits to real measurements of precipitation. On the other hand, the posterior distribution of β1 has a
posteriormeanof−0.016,butastandarddeviationof0.11,notshowinganyevidencethatβ1 differs
from zero. This indicates that over the 20 years of control runs for the RCM output, our statistical
model is not able to detect any deterministic time changes in the GEV location parameters. Maps
of posterior predictive quantiles of the distribution of annual precipitation maxima are shown in

Dynamic and spatial modelling of extremes
195
−125 −120 −115 −110 −105
35
40
45
50
Longitude
20
30
40
50
60
70
80
μ
−125 −120 −115 −110 −105
35
40
45
50
Longitude
5
10
15
20
25
σ
35
40
45
50
Longitude
Latitude
Longitude
5
10
15
20
25
Figure 10.8 Posterior mean estimates for μ and σ for the RCM output.
ξ
Density
0.04
0.06
0.08
0.10
0
10
20
30
40
−0.4
0.0
0.2
0.4
0
1
2
3
β1
Density
Figure 10.9 Posterior distributions for shape and slope parameters. RCM output.
Figure 10.10. These maps are based on posterior predictive samples and not on GEV quantiles
or GEV return levels. All of these quantiles are relatively high along the Pacific coast from British
Columbia through northern California, through northern and central California, and in central
Arizona. The annual precipitation maxima in these areas are higher than in other areas of the spatial
domain, but rarely, very extreme. In terms of posterior predictive evaluations, Figure 10.11 shows
histograms of samples from the posterior predictive distribution corresponding to the held-out
values of yst at four different locations. The four locations were selected from the 25 originally
held out locations and to be roughly representative of the northwest, northeast, southwest, and
southeast regions of the study area. Vertical bars show the posterior predictive median and the
0.95 posterior predictive quantile based on the predictive samples. The small vertical lines along
the x-axis show the actual 20 observed (output) values that were held out at each of the four
locations. The observations are in accordance with our predictive distribution and were computed
under the assumption of a zero-trend parameter. Similar figures were obtained for other held out

196
G. Huerta and G. A. Stark
−125
−120
−115
−110
−105
35
40
45
50
Longitude
Latitude
50
100
150
200
Posterior Predictive
 Median
−125
−120
−115
−110
−105
35
40
45
50
Longitude
Latitude
50
100
150
200
Posterior Predictive
 3rd Quartile
−125
−120
−115
−110
−105
35
40
45
50
Longitude
Latitude
50
100
150
200
Posterior Predictive
 95th Percentile
−125
−120
−115
−110
−105
35
40
45
50
Longitude
Latitude
50
100
150
200
Posterior Predictive
 99th Percentile
Figure 10.10 Posterior predictive percentiles at four levels: 50%,75%, 90% and 99% for the RCM
output.
locations. Figure 10.12 shows the posterior distributions for each of the elements in B. The first row
ofhistogramscorrespondstotheparametersassociatedwithμwhilethesecondrowcorrespondsto
σ.Thecovariatesthatappearmorerelevantarethoseassociatedwithlongitude,latitudeandrelative
positiontoocean.Thelatitudecoefficientsshowanegativechangeforboth μ andσ,indicatingthat
annual precipitation maxima become generally smaller and less variable with increasing latitude.
The longitude coefficients also show a negative change with both μ and σ, indicating that annual
precipitation maxima are generally smaller and less variable in the eastern portion of the study
area than in the western portion. The elevation coefficients indicate a positive change on μ and
σ, indicating that in general annual precipitation maxima are both more extreme and more variable
at higher elevations, however, this change is anticipated to be rather small. The coefficients for the
ocean indicator variable induce a negative change for μ and σ, so that annual precipitation maxima
are both less extreme and less variable over the ocean than over land.

Samples from Posterior Predictive Distribution
Density
0
50
100
150
200
0.000
0.015
0.030
Lat 48.5 Long −122.3
Median
0.95 Quantile
|
|
|
|
|
|
|
||
| |
|
| |
|
|| |||
Samples from Posterior Predictive Distribution
Density
0
50
100
150
200
0.000
0.015
0.030
Lat 48.3 Long −109.7
Median
0.95 Quantile
|
|
|
|
|
|
|
|
||
||
|
|
|
|
| |
||
Samples from Posterior Predictive Distribution
Density
0
50
100
150
200
0.000
0.015
0.030
Lat 34.1 Long −117.2
Median
0.95 Quantile
|
|
|
|
|
|
| ||
|
|
| |
| |
| |
|
||
Samples from Posterior Predictive Distribution
Density
0
50
100
150
200
0.000
0.015
0.030
Lat 34.4 Long −105.7
Median
0.95 Quantile
|
|
|
|
||||
|
|
| |
|
|
|
|
|
|
|
|
Figure 10.11 RCM output analysis. Predictive posterior distribution at four held out grid points.
Posterior Density of B 2
mu Latitude
Density
Posterior Density of B 3
mu Longitude
Density
Posterior Density of B 4
mu Elevation
Density
Posterior Density of B 5
mu Ocean
Density
Posterior Density of B 7
sg Latitude
Density
Posterior Density of B 8
sg Longitude
Density
Posterior Density of B 9
sg Elevation
Density
Posterior Density of B 10
sg Ocean
Density
−0.30 −0.15
0.00
−1.8
−1.6
−1.4
0.002 0.004 0.006
−20 −15 −10
−0.035
−0.025
−0.035
−0.020
0.00000 0.00015
−0.6 −0.4 −0.2
0.0
0
2
4
6
8
0
1
2
3
4
5
0
100
200
300
400
500
0.00
0.05
0.10
0.15
0
50
100
150
200
0
20
40
60
80
100
120
0
2000
4000
6000
8000
10000
12000
0
1
2
3
4
Figure 10.12 RCM output analysis. Posterior distributions for regression parameters.

198
G. Huerta and G. A. Stark
10.4 Conclusions
This chapter presents a general class of models to study extreme values based on the GEV distri-
bution and that rely on time domain and spatial latent components. These models had not been
available until recently and their implementations are now available thanks to the developments of
MCMC approaches. In particular, dynamic models as described in [29] and [28] provide a flexible
approach to deal with time-varying extremes via MCMC algorithms based on FFBS, in contrast
with the traditional deterministic parameter GEV regression models. Interesting developments in
this area had arisen from Particle Filter methods starting from the work by [12] and more recently
extended by [9], both emphasizing the analysis of the athletics dataset of [20]. In addition, [18]
present a different framework where the time dependence in extremes is modelled through AR and
MA with innovations arising from the Gumbel distribution and illustrated with extreme returns of
daily stock data. From the spatial or spatial temporal perspective, some of the main model devel-
opments for the study of extremes arose from the Bayesian hierarchical perspective with MCMC
methods initiated by [3] and also in for example, [16], [22] and [8]. As shown in this chapter,
these modelling approaches had proven their value and flexibility in the representation of extremal
phenomena from station data or from climate model output in high-dimensional situations. How-
ever, the main drawback of these approaches is that they are based on assumptions of conditional
independence which may not be adequate to represent spatial dependencies of extremes. Develop-
ments based on Copulas as in [23] and [14] and the Max stable process as in [24] through composite
likelihood methods combined with MCMC as in [19], provide some examples of the recent focus
for modelling spatial extremes from a Bayesian point-of-view.
Acknowledgements
The rainfall data at Maíquetia was kindly provided by Bruno Sansó. The RCM output data was
kindly provided by Steve Sain and Dan Cooley while the first author was visiting NCAR.
References
[1] Beirlant,J.,Goegebeur,Y.,Segers,J.andTeugels,J.(2004).StatisticsofExtremes.Wiley,Chich-
ester, England.
[2] Carter, C. K. and Kohn, R. (1994). On Gibbs sampling for state space models.
Biometrika, 81(3), 541–553.
[3] Casson, E. and Coles, S. (1999). Spatial regression models for extremes. Extremes, 1(4),
449–468.
[4] Coles, S. (2001). An Introduction to Statistical modelling of Extreme Values. Springer-Verlag,
New York, USA.
[5] Coles, S. and Pericchi, L. (2003). Anticipating catastrophes through extreme value modelling.
Journal of the Royal Statistical Society Series C, Applied Statistics, 52, 405–416.
[6] Coles, S. G. and Powell, E. A. (1996). Bayesian methods in extreme value modelling: A review
and new developments. International Statistical Review, 64(1), 119–136.
[7] Coles, S. G. and Tawn, J. A. (1996). Modelling extremes of the areal rainfall process. Journal of
Royal Statistics Society, B(58), 329–347.
[8] Cooley, D. and Sain, S. (2010). Spatial hierarchical modelling of precipitation extremes from
a regional climate model. Journal of Agricultural Biological and Environmental Statistics, 15(3),
381–402.

Dynamic and spatial modelling of extremes
199
[9] Fearnhead, P., Wyncoll, D. and Tawn, J. (2010). A sequential smoothing algorithm with linear
computational cost. Biometrika, 97(2), 447–464.
[10] Fisher, R. A. and Tippet, L. H. C. (1928). Limiting forms of the frequency distribution of the
largest or smallest member of a sample. Proceedings of the Cambridge Philosophical Society, 24,
180–190.
[11] Frühwirth-Schnatter, S. (1994). Data augmentation and dynamic linear models. Journal of
Time Series Analysis, 15, 183–202.
[12] Gaetan, C. and Grigoletto, M. (2004). Smoothing sample extremes with dynamic models.
Extremes, 7, 221–236.
[13] Gelfand,A.E.andSmith,A.F.M.(1990).Sampling-basedapproachestocalculatingmarginal
densities. Journal of the American Statistical Association, 85(410), 398–409.
[14] Ghosh, S. and Mallick, B. (2010). A hierarchical Bayesian spatio-temporal model for extreme
precipitation events. Environmetrics, 22, 192–204.
[15] Hastings, W. K. (1970). Monte Carlo sampling methods using Markov chains and their appli-
cations. Biometrika, 87, 97–109.
[16] Huerta, G. and Sansó, B. (2007). Time-varying models for extreme values. Environmental and
Ecological Statistics, 14(3), 285–299.
[17] Martins, E. and Stedinger, J. (2000). Generalized maximum-likelihood generalized extreme-
value quantile estimators for hydrologic data. Water Resources Research, 36, 737–744.
[18] Nakajima, J., Kunihama, T., Omori, T. and Früwirth-Schnatter (2012). Generalized extreme
value distribution with time-dependence using the ar and ma models in state space form.
Computational Statistics and Data Analysis, 56, 3241–3259.
[19] Ribatet, M., Cooley, D. and Davison, A. (2012). Bayesian inference for composite likelihood
models and an application to spatial extremes. Statistica Sinica, 22, 813–845.
[20] Robinson, M. E. and Tawn, J. A. (1995). Statistics for exceptional athletics records. Journal of
the Royal Statistical Society Series C, Applied Statistics, 44, 499–511.
[21] Rue, H. and Held, L. (2005). Gaussian Markov Random Fields. Chapman & Hall/CRC.
[22] Sang, H. and Gelfand, A. E. (2009). Hierarchical modelling for extreme values observed over
space and time. Environmental and Ecological Statistics, 16, 407–426.
[23] Sang, H. and Gelfand, A. E. (2010). Continuous spatial process models for spatial extreme
values. Journal of Agricultural Biological and Environmental Statistics, 15(1), 49–65.
[24] Smith, R. (1990). Max-stable processes and spatial extremes. Unpublished manuscript.
[25] Smith, R. L. and Naylor, J. C. (1988). A comparison of maximum likelihood and Bayesian
estimators for the three parameter Weibull distribution. Applied Statistics, 36, 358–369.
[26] Stephenson, A. G. (2002, September). A User’s Guide to the Evdbayes Package(Version 1.0).
http://www.maths.lancs.ac.uk/~stephena/.
[27] Stephenson, A. G. and Gilleland, E. (2005). Software for the analysis of extreme events: the
current state and future directions. Extremes, 8(3), 87–109.
[28] West, M. (2012). Bayesian dynamic modelling. In Bayesian Theory and Applications,
pp. 145–166. Oxford University Press, Oxford.
[29] West, M. and Harrison, J. (1997). Bayesian Forecasting and Dynamic Models (Second edn).
Springer-Verlag, New York.

This page intentionally left blank 

Part V
Sequential Monte Carlo

This page intentionally left blank 

11
Online Bayesian learning
in dynamic models: an
illustrative introduction
to particle methods
hedibert f. lopes and
carlos m. carvalho
11.1 Introduction
I
nthischapter,weprovideanintroductorystep-by-stepreviewofMonteCarlomethodsforfilter-
ingingeneralnonlinearandnon-Gaussiandynamicmodels,alsoknownasstate-spacemodelsor
hidden Markov models (see [60], [20], [5] and [25]). These MC methods are commonly referred
to as sequential Monte Carlo, or simply particle filters. The standard Markovian dynamic model for
observation yt is
yt ∼f(yt|xt, θ),
(11.1)
xt ∼g(xt|xt−1, θ)
(11.2)
where, for t = 1, . . . , n, xt is the latent state of the dynamic system and θ is the set of fixed param-
eters defining the system. Equation (11.1) is referred to as the observation equation that relates the
observed series yt to the state vector xt. Equation (11.2) is the state transition equation that governs
thetimeevolutionofthelatentstate.Fordidacticalreasons,weassumethroughoutthischapterthat
yt and xt are both scalars. Multidimensional extensions are, in principle, straightforward and out of
our scope.
The central problem in many state-space models, is the sequential derivation of the filtering
distribution. By Bayes’ theorem
p(xt|y1:t, θ) = f(yt|xt, θ)p(xt|y1:t−1, θ)
p(yt|y1:t−1, θ)
(11.3)
where y1:t = (y1, . . . , yt) (the same for x1:t). The problem translates, in part, to deriving the prior
distribution of the latent state xt given data up to time t −1:

204
H. F. Lopes and C. M. Carvalho
p(xt|y1:t−1, θ) =

g(xt|xt−1, θ)p(xt−1|y1:t−1, θ)dxt−1
(11.4)
Even when θ is assumed to be known, sequential inference about xt becomes analytically
intractable, except when dealing with Gaussian dynamic linear models (DLM) (detailed in Sec-
tion 11.2.1).
Most of the early contributions to the literature on the Bayesian estimation of state-space models
boils down to the design of Markov chain Monte Carlo (MCMC) schemes that iteratively sample
from states and parameters full conditional distributions:
p(x1:n|y1:n, θ) and p(θ|x1:n, y1:n).
(11.5)
Themainreferencesinclude,amongstothers,[6],[7],[23]and[24].See[45]forathoroughreview
of dynamic models.
On the one hand, MCMC methods gave researchers the means to free themselves from the
(usually unrealistic) assumptions of normality and linearity for both observation equation (11.1)
and state transition equation (11.2). On the other hand, however, they took from researchers the
ability to sequentially learn about states and parameters.
Particle filters are Monte Carlo schemes designed to sequentially approximate the densities in
equations (11.3) and (11.4) over time. The seminal bootstrap filter of Gordon, Salmond and Smith
[29], for example, uses the sampling importance resampling algorithm to first propagate particles
from time t −1, i.e. draws from p(xt−1|y1:t−1), via equation (11.4), and then to resample the
discrete set of propagated particles with weights proportional to the likelihood (Bayes’ theorem
from equation (11.3)). Sections 11.3 and 11.4 provide additional details about the bootstrap filter as
well as many other particles filters for state filtering or state and parameter learning.
The remainder of the chapter is organized as follows. Section 11.2 introduces the basic notation,
results and references for the general class of Gaussian DLMs, the AR(1) plus noise model and for
the standard stochastic volatility model with AR(1) dynamics. Particle filters for state learning with
fixed parameters (also known as pure filtering) and particle filters for state and parameter learning
are discussed in Sections 11.3 and 11.4, respectively. Section 11.5 deals with general issues, such as MC
error, sequential model checking, particle smoothing and the interaction between particle filters
and MCMC schemes.
11.2 Dynamic models
In what follows we provide basic notation and results, as well as key references, for the general class
of Gaussian DLMs, the AR(1) plus noise model and for the standard stochastic volatility model
with AR(1) dynamics.
11.2.1 Dynamic linear models
A Gaussian dynamic linear model (DLM) can be written as
yt|xt, θ ∼N(μ + F′
txt, σ 2
t )
(11.6)
xt|xt−1, θ ∼N(α + Gtxt−1, τ2
t )
(11.7)
where intercepts μ and α are added for notational reasons related to the stochastic volatility model
of Section 11.2.3. Conditionally on θ = (F1:n, G1:n, σ 2
1:n, τ2
1:n, μ, α) and assuming the initial distri-
bution (x0|y0) ∼N(m0, C0), it is straightforward to show that

Online Bayesian learning in dynamic models
205
xt|y1:t−1, θ ∼N(at, Rt)
(11.8)
yt|y1:t−1, θ ∼N(ft, Qt)
(11.9)
xt|y1:t, θ ∼N(mt, Ct)
(11.10)
for t = 1, . . . , n, where N(a, b) denotes the normal distribution with mean a and variance b. The
three densities in equations (11.8) to (11.10) are referred to as the propagation density, the predictive
density and the filtering density, respectively. In fact, the propagation and filtering densities are the
prior density of xt given y1:t−1 and the posterior density of xt given y1:t. The means and variances
of the three densities are provided by the Kalman recursions:
at = α + Gtmt−1 and Rt = GtCt−1G′
t + τ 2
t
(11.11)
ft = μ + F′
tat and Qt = F′
tRtFt + σ 2
t
(11.12)
mt = at + Atet and Ct = Rt −AtQtA′
t
(11.13)
where et = yt −ft is the prediction error and At = RtFtQ−1
t
is the Kalman gain. Two other useful
densities are the conditional and marginal smoothed densities
xt|xt+1, yt, θ ∼N(ht, Ht)
(11.14)
xt|y1:n, θ ∼N(mn
t , Cn
t )
(11.15)
where
ht = mt + Bt(xt+1 −at+1) and Ht = Ct −BtRt+1B′
t
(11.16)
mn
t = mt + Bt(mn
t+1 −at+1) and Cn
t = Ct + B2
t (Cn
t+1 −Rt+1)
(11.17)
and Bt = CtG′
t+1R−1
t+1 (see [60], Chapter 4, for additional details).
11.2.2 AR(1) plus noise model
The AR(1) plus noise model is a Gaussian DLM where the state follows a standard AR(1) process
and yt is observed with measurement error:
yt|xt, θ ∼N(xt, σ2)
(11.18)
xt|xt−1, θ ∼N(α + βxt−1, τ2)
(11.19)
Conditional on θ = (σ2, α, β, τ2), the whole state vector x1:n can be marginalized out analytically
(see (11.9)):
p(y1:n|θ) =
n

t=1
pN(yt; ft, Qt)
(11.20)
where pN(x; μ, σ 2) is the density of a normal random variable with mean μ and variance σ 2
evaluated at x. Notice that here ft and Qt are both nonlinear functions of θ. The density in equation
(11.20) is commonly known as prior predictive density or integrated likelihood.

206
H. F. Lopes and C. M. Carvalho
11.2.2.1 MC sampling from the posterior
Posterior draws from p(x1:n, θ|y1:n) can be directly and jointly obtained:
Step (i): Draw {θ(i)}N
i=1 from p(θ|y1:n) ∝p(θ)p(y1:n|θ). The likelihood p(y1:n|θ) comes
from (11.20). This can be performed by sampling importance resampling, accep-
tance–rejection algorithm or Metropolis–Hastings-type algorithms.
Step (ii): Draw x(i)
1:n from p(x1:n|θ(i), y1:n), for i = 1, . . . , N, by first computing forward
moments via equations (11.11)–(11.13) and (11.16), and then sampling backwards xt
conditional on xt+1 and yt via equations (11.14). This step is known as the forward
filtering, backward sampling (FFBS) algorithm ([7]; [23]).
Alternatively, θ from step (i) could be sampled, via a Gibbs sampler step, for instance, from
p(θ|y1:n, x1:n). In this case, iterating between steps (i) and (ii) would lead to a MCMC scheme
whose target, stationary distribution is the posterior distribution p(x1:n, θ|y1:n).
11.2.2.2 Prior specification and sufficient statistics
Assume that the prior distribution of (α, β, τ2) is decomposed into τ 2 ∼IG(ν0/2, ν0τ2
0 /2) and
(α, β)|τ2 ∼N(d0, τ2D0), for known hyperparameters ν0, τ 2
0 , d0 and D0. It follows immedi-
ately, from basic Bayesian derivations for conditionally conjugate families, that τ 2|y1:t, x1:t ∼
IG(νt/2, νtτ2t /2) and (α, β)|τ2, y1:t, x1:t ∼N(dt, τ2Dt), where
D−1
t
= D−1
t−1 + ztz′
t
D−1
t
dt = D−1
t−1dt−1 + ztxt
νt = νt−1 + 1
(11.21)
νtτ2
t = νt−1τ2
t−1 + (xt −z′
tdt)xt + (dt−1 −dt)′D−1
t−1dt−1
and zt = (1, xt)′. The relevance of these conditional conjugacy results will become apparent when
dealingwithsomeoftheparticlesfilterswithparameterlearninginSection11.4.See[52]forparticle
methods applied to AR models with structured priors.
11.2.3 SV-AR(1) model
Univariate stochastic volatility (SV) in asset price dynamics results from the movements of an
equityindexSt anditsstochasticvolatilityvt viaacontinuoustimediffusionbyaBrownianmotion:
d log St = μdt + √vtdBPt and d log vt = κ(γ −log vt)dt + τdBVt , where the parameters gov-
erning the volatility evolution are (μ, κ, γ , τ) and (BPt , BVt ) are (possibly correlated) Brownian
motions ([54], [57], [31], [33]).
Data arises in discrete time so it is natural to take an Euler discretization of the above equations.
This is then commonly referred to as the stochastic volatility autoregressive, SV-AR(1), model and is
described by the following nonlinear dynamic model:
yt|xt, θ ∼N(0, exp{xt/2})
(11.22)
xt|xt−1, θ ∼N(α + βxt−1, τ2)
(11.23)
where yt are log-returns and xt are log-variances. See [32] and [34] for the original Bayesian papers
on MCMC estimation of the above SV-AR(1) model. In addition, [41] provides an extensive

Online Bayesian learning in dynamic models
207
review of Bayesian inference in the SV-AR(1) model, as well as other univariate and multivariate SV
models.
11.2.3.1 Sampling parameters
The SV model is completed with a conjugate prior distribution for θ = (α, β, τ2), i.e. p(θ) =
p(α, β|τ2)p(τ2), where (α, β|τ2) ∼N(d0, τ2D0) and τ2 ∼IG(ν0/2, ν0τ2
0 /2), for known
hyperparameters d0, D0, ν0 and τ2
0 . Apart from the nonlinear relationship between yt and xt in
equation (11.22), notice the similarity between the above SV-AR(1) model and the AR(1) plus noise
model of section 11.2.2. Therefore, sampling (α, β, τ2) given x1:t can be done via equations (11.21).
11.2.3.2 Sampling states
Sampling from x1:t|y1:t, θ jointly is performed by a FFBS scheme introduced by [34] for the
SV-AR(1) model. They approximate the distribution of log y2t by a carefully tuned mixture of
normals with seven components. More precisely, the observation equation (11.22) is rewritten
by zt = log y2t = xt + ϵt, where ϵt = log ε2t follows a log χ2
1 distribution, a parameter-free left
skewed distribution with mean −1.27 and variance 4.94. They argue that ϵ = log χ2
1 can be well
approximated by 7
i=1 πipN(ϵt; μi, v2
i ), where
π = (0.0073, 0.10556, 0.00002, 0.04395, 0.34001, 0.24566, 0.2575)
μ = (−11.40039, −5.24321, −9.83726, 1.50746, −0.65098, 0.52478, −2.35859)
v2 = (5.79596, 2.61369, 5.17950, 0.16735, 0.64009, 0.34023, 1.26261)
Therefore,astandarddataaugmentationargumentallowsthemixtureofnormalstobetransformed
into individual normals, i.e. (ϵt|kt) ∼N(μkt, v2
kt) and Pr(kt) = qkt. Conditionally on k1:t, the SV
model can be rewritten as a standard Gaussian DLM:
(zt|xt, kt, θ) ∼N(μkt + xt, v2
kt)
(11.24)
(xt|xt−1, θ) ∼N(β0 + β1xt−1, τ2).
(11.25)
The FFBS algorithm is then used to sample from p(x1:n|y1:n, k1:n, θ). Given x1:n, kt is sampled
from {1, . . . , 7} with Pr(κt = i|zt) ∝πipN(zt; μi + xt, v2
i ), for i = 1, . . . , 7 and t = 1, . . . , n.
The above two steps, i.e. sampling parameters and sampling states, will both be very useful in the
next two sections when deriving particle filters for both state and fixed parameters.
11.3 Particle filters
Particle filters use Monte Carlo methods, mainly the sampling importance resampling (SIR), to
sequentiallyreweighandresampledrawsfromthepropagationdensity.ThenonlinearKalmanfilter
is summarized by the prior and posterior densities in equations (11.4) and (11.3):
p(xt|y1:t−1) =

g(xt|xt−1)p(xt−1|y1:t−1)dxt−1
p(xt|y1:t) ∝f(yt|xt)p(xt|y1:t−1)
where the vector of fixed parameters θ is assumed to be known and dropped from the notation,
reappearing when necessary. The following joint densities will become useful in Sections 11.3.1 and
11.3.2:

208
H. F. Lopes and C. M. Carvalho
p(xt, xt−1|y1:t−1) = g(xt|xt−1)p(xt−1|y1:t−1)
(11.26)
p(xt, xt−1|y1:t) ∝f(yt|xt)g(xt|xt−1)p(xt−1|y1:t−1).
(11.27)
Particle filters, loosely speaking, combine the sequential estimation nature of Kalman-like filters
with the flexibility for modelling of MCMC samplers, while avoiding some of their shortcomings.
On the one hand, like MCMC samplers and unlike Kalman-like filters, particle filters are designed
to allow for more flexible observational and evolutional dynamics and distributions. On the other
hand, like Kalman-like filters and unlike MCMC samplers, particle filters provide online filter-
ing and smoothing distributions of states and parameters. Advanced readers are refereed to, for
instance, [5], Chapters 7 to 9 for a more formal, theoretical discussions of sequential Monte Carlo
methods.
The goal of most particle filters is to draw a set of i.i.d. particles {x(i)
t }N
i=1 that approximates
p(xt|y1:t) by starting with a set of i.i.d. particles {x(i)
t−1}N
i=1 that approximates p(xt−1|y1:t−1). To
simplify the notation, from now on we will simply refer to ‘particles xt−1’ when describing a ‘set
of i.i.d. particles {x(i)
t−1}N
i=1’. The most popular filters are the bootstrap filter (BF), also known as
sequential importance sampling with resampling (SISR) filter, proposed by [29], and the auxiliary
particle filter (APF), also known as auxiliary SIR (ASIR) filter, proposed by [48]. We introduce
both of them in the next section along with their optimal counterparts.
11.3.1 Bootstrap filter
The bootstrap filter (BF) is the seminal and perhaps the most implemented of the particle filters.
It can be basically thought of as the repetition of the sampling importance resampling (SIR) over
time. More precisely, let p(xt−1|y1:t−1) be the posterior density of the latent state xt−1 at time
t −1. From equations (11.4) and (11.3) and Bayes’ theorem, it is easy to verify that
p(xt, xt−1|y1:t) ∝f(yt|xt)
3 45 6
2. Resample
g(xt|xt−1)p(xt−1|y1:t−1)
3
45
6
1. Propagate
.
(11.28)
In words, BF combines old particles xt−1, generated from p(xt−1|y1:t−1), and new parti-
cles xt, generated from g(xt|xt−1), so that the combined particles (xt, xt−1) are draws from
p(xt, xt−1|y1:t−1). This step is labelled ‘1. Propagate’ in the above expression. BF then resamples
the combined particles (xt, xt−1) with SIR weights proportional to the likelihood
ωt ∝f(yt|xt)g(xt|xt−1)p(xt−1|y1:t−1)
g(xt|xt−1)p(xt−1|y1:t−1)
= f(yt|xt)
(11.29)
This step is labelled ‘2. Resample’ in the above expression. These combined resampled particles
approximate p(xt−1, xt|y1:t) and, in particular, the marginal filtering density p(xt|y1:t).
11.3.1.1 Particle impoverishment
The overall SIR proposal density (the denominator of (11.29)) is q(xt, xt−1|y1:t) =
p(xt, xt−1|y1:t−1) = g(xt|xt−1)p(xt−1|y1:t−1). The particles xt
from (xt, xt−1) are, in
fact, particles from the prior density p(xt|y1:t−1). It is well known that the SIR algorithm can
perform badly when the prior is used as proposal density. The main reason is that in most cases
either the prior is too flat relative to the likelihood or vice versa. Small overlap between the
prior and the posterior leads to unbalanced weights, that is a small number of particles will have

Online Bayesian learning in dynamic models
209
dominating weights and all other particles will have negligible weights. This decrease in particle
representativeness, or particle degeneracy, is exacerbated when the SIR is carried over time.
11.3.1.2 Adapted and fully adapted BF
Instead of using the evolution density g(xt|xt−1) to propagate xt−1 to xt, one could use an
unblinded proposal, q(xt|xt−1, yt), i.e. a proposal that incorporates the information about the cur-
rentobservationyt.Thesefiltersarecommonlycalledadaptedfilters.Inthiscase,q(xt, xt−1|y1:t) =
q(xt|xt−1, yt)p(xt−1|y1:t−1) is the SIR proposal density, while the SIR weights are
ωt ∝f(yt|xt)g(xt|xt−1)p(xt−1|y1:t−1)
q(xt, xt−1|y1:t)
= f(yt|xt)g(xt|xt−1)
q(xt|xt−1, yt)
(11.30)
Fulladaptationoccurswhenoneisabletosamplefromp(xt|xt−1, yt),inwhichcasetheSIRweights
are proportional to the predictive density
ωt ∝p(yt|xt−1).
(11.31)
Even though full adaptation is rare, it can be used to guide the researcher in the selection of pro-
posal densities q(xt|xt−1, yt). The closer q(xt|xt−1, yt) is to p(xt|xt−1, yt) the better. However,
as [48] say, ‘even fully adapted particle filters do not produce iid samples from p(xt|y1:t), due to
their approximation of p(xt|y1:t−1) by a finite mixture distribution.’ The AR(1) plus noise model
of Section 11.2.2 and SV-AR(1) model of Section 11.2.3 can be implemented by fully adapted and
adapted versions of the above BF.
11.3.2 Auxiliary particle filter
[52] noticed that writing Bayes’ theorem from Equation (11.28) as
p(xt, xt−1|y1:t) ∝p(xt|xt−1, y1:t)
3
45
6
2.Propagate
p(yt|xt−1)p(xt−1|y1:t−1)
3
45
6
1.Resample
(11.32)
would lead to alternative ways of designing the SIR proposal density q(xt, xt−1|y1:t). Since
p(yt|xt−1) and p(xt|xt−1, y1:t) are usually, respectively, unavailable for pointwise evaluation and
sampling (see the discussion about fully adapted filters at the end of Section 11.3.1); they suggested
a generic proposal
q(xt−1, xt|y1:t) = g(xt|xt−1)f(yt|h(xt−1))p(xt−1|y1:t−1),
(11.33)
where h(.) is usually the expected value, median or mode of g(xt|xt−1). The SIR weights would
then be written as
wt ∝
f(yt|xt)g(xt|xt−1)p(xt−1|y1:t−1)
g(xt|xt−1)f(yt|h(xt−1))p(xt−1|y1:t−1) =
f(yt|xt)
f(yt|h(xt−1))
(11.34)
In words, APF would resample old particles xt−1 from p(xt−1|y1:t−1) with weights propor-
tional to f(yt|h(xt−1)), which take into account the new observation yt. These are usually called
the first-stage weights. This step is labelled ‘1. Resample’ in equation (11.32). Then, new parti-
cles xt are sampled from g(xt|xt−1), such that the combined particles (xt−1, xt) are draws from
q(xt−1, xt|y1:t). These combined particles are then resampled with weights given by equation

210
H. F. Lopes and C. M. Carvalho
(11.34). These are usually called the second-stage weights. This step is labelled ‘1. Propagate’ in
equation (11.32). The final, resampled combined particles approximate p(xt−1, xt|y1:t) and, in
particular, the marginal filtering density p(xt|y1:t). Comparing the above labels and their order of
operation, we call the APF a resample–sample filter, while the BF is sample–resample filter.
11.3.2.1 Fully adapted APF
The above generic APF is a partially adapted filter by construction. However, the degree of adapta-
tion depends on how close the first-stage weights f(yt|h(xt−1)) and the predictive p(yt|xt−1) are.
For general adapted first-stage weights q(xt−1|yt) and adapted resampling proposal q(xt|xt−1, yt),
the SIR weights of equation (11.34) become
wt ∝
f(yt|xt)g(xt|xt−1)
q(xt|xt−1, yt)q(xt−1|yt).
(11.35)
Similar to the fully adapted BF, the APF is fully adapted when q(xt−1|yt) = p(yt|xt−1) and
q(xt|xt−1, yt) = p(xt|xt−1, yt). In this case, the second-stage weights (equation (11.35)) are pro-
portional to one (no resampling necessary).
11.3.2.2 Local linearization
[48] suggest, for more general settings, proposal density q(xt|xt−1, yt) that are based on local
linearizationoftheobservationequationviaanextendedKalmanfilter-typeapproximationinorder
tobetterapproximatep(xt|xt−1, yt).See[17]and[30],amongstothers,foradditionalparticlefilters
and discussion on proposals based on local linear approximations.
Another class of proposals, usually more efficient when available, is based on the mixture Kalman
filters (MKF) of [11]. The MKF takes advantage of possible analytical integration of some compo-
nents of the state vector by conditioning on some other components. Such filters are commonly
referred to as Rao-Blackwellized particle filter. This is also acknowledged in [48] and many other
references. See, for instance, [16], and [18], [8].
11.3.3 Marginal likelihood
The above filters can be used to approximate p(y1:t), the marginal likelihood up to time t, as
ˆp(y1:t) =
t
j=1
ˆp(yj|y1:j−1) = 1
Nt
t
t=1
N

i=1
f(yj|x(i)
j ),
(11.36)
where xt are particles from p(xt|y1:t−1). See [12] and [14] for further details and theoretical
discussion.
11.3.4 Effective sample size
The quality of a particle filter can be measured by its ability to generate a ‘diverse’ particle
set by drawing from proposals q(xt|xt−1, yt) and reweighting with densities q(xt−1|yt). [35]
suggest using the coefficient of variation CVt = (N N
i=1(ω(i)
t
−1/N)2)1/2, where ω(i)
t
=
w(i)
t / N
j=1 w(j)
t
are normalized weights, as a simple criterion to detect the weight degeneracy
phenomenon. CVt varies between 0 (equal weights) and √N −1 (N copies of a single parti-
cle). [37] and [36] propose tracking the effective sample size Neff = N/(1 + CV2t ), which varies
between 1 (N copies of a single particle) and N (equal weights). [5] tracks the Shannon entropy

Online Bayesian learning in dynamic models
211
Ent = −N
i=1 ω(i)
t
log2 ω(i)
t , which varies between 0 (N copies of a single particle) and log2 N
(equal weights).
11.3.5 Examples
11.3.5.1 AR(1) plus noise model
From Section 11.2.2 we can easily see that, given θ, the filtering densities p(xt|y1:t) are available in
closed form and no particle filtering is necessary. However, we implement both BF and APF to this
modelandusetheexactdensitiestoassesstheirperformances.Itiseasytoseethatp(yt|xt−1)isnor-
mal with mean h(xt−1) = α + βxt−1 and variance σ 2 + τ2, while p(xt|xt−1, yt) is normal with
mean Ayt + (1 −A)h(xt−1) and variance (1 −A)τ2, where A = τ2/(τ2 + σ 2). These results
are used to implement fully adapted BF and APF, labelled here by OBF and OAPF (for optimal).
We simulate S = 50 datasets for each value of τ 2 in {0.05, 0.75, 1.0} and all with n = 100 obser-
vations; a total of 150 datasets. The other parameters are (α, β, σ 2) = (0.05, 0.95, 1.0) and x0 = 1.
The prior for x0 is N(m0, C0) where m0 = 1 and C0 = 10. We run the four filters R = 50 times,
each time based on N = 500 particles. A total of 150 × 50 × 4 = 30000 combined runs. We then
computethelogarithmofthemeansquareerroroffilterf andtimet asMSEft = S
s=1
R
r (ˆqα
sftr −
qαst)2/RS, where qαst and qα
sftr are the true and approximated αth percentile of p(xt|y1:t), for dataset
s, time period t, run r, percentile α in {5, 50, 95} and filter f in {BF, APF, OBF, OAPF}.
Figure 11.1 summarizes our findings based on log relative MSEs of APF, OBF and OAPF relative
to BF. It suggests that the optimal filters are better then their counterpart non-optimal filters. In
addition, OAPF is uniformly superior to OBF (increasingly in τ2), so favouring resampling–sam-
pling filters over sampling–resampling filters. Finally, BF is usually better than APF for small τ2/σ2
(small signal-to-noise ratio). Similar results are found when MSEs are replaced by mean absolute
errors (not shown here).
11.3.5.2 SV-AR(1) model
In this example we illustrate the performance of both the bootstrap filter and the auxiliary particle
filter for the SV-AR(1) model of Section 11.2.3. The parameter vector θ = (α, β, τ2) is assumed
known (see Section 11.4.4 for the general case where θ is also learned sequentially). Let μt =
α + βxt−1. On the one hand, the BF propagates new particles xt from N(μt, τ2), which are then
resampled with weights proportional to pN(yt; 0, ext). On the other hand, the APF resamples old
particles xt−1 with weights proportional to pN(yt; 0, eμt). New particles xt are then propagated
from N(μt, τ2) and resampled with weights proportional to pN(yt; 0, ext)/pN(yt; 0, eμt).
Potentially better proposals can be obtained. One could, for instance, use the (rough) nor-
mal approximation N(−1.27, 4.94) to log y2t presented in Section 11.2.3. This linearization
leads to first-stage weights q(xt−1|yt) = pN(zt; μt, 4.94), where zt = log y2t + 1.27, while the
resampling proposal q(xt|xt−1, yt) is normal with mean v(zt/4.94 + μt/τ2) and variance v =
1/(1/4.94 + 1/τ2). Consequently, it can be shown that the second-stage weights are proportional
to pN(yt; 0, exp{xt})/pN(zt; xt, 4.94). We call this APF filter simply APF1 in what follows.
A second example is based on [34]. They used, in a MCMC context, a first-order Taylor expan-
sion of e−xt around μt to approximate the likelihood p(yt|xt) by exp{−0.5xt(1 −y2t e−μt)} (up to
aproportionalityconstant).Inthissetting,theresamplingproposalq(xt|xt−1, yt)isN( ˜μt, τ2)with
˜μt = μt + 0.5τ2(y2t e−μt −1). First-stage weights are then q(xt−1|yt) ∝exp{−0.5τ−2[(1 +
μt)τ2y2t e−μt + μ2t −˜μ2t ]}. We call this APF filter simply APF2 in what follows.
In a third, more involving example, inspired by [34], who use a seven-component mixture of
normals to approximate log χ2
1 (see equations (11.24) and (11.25) of Section 11.2.3), we obtain a
fully adapted APF for the SV-AR(1) model. In this case, the first-stage weights are proportional to

212
H. F. Lopes and C. M. Carvalho
APF/BF
OBF/BF
OAPF/BF
−0.4
−0.3
−0.2
−0.1
0.0
0.1
5th percentile
Log relative MSE
tau2=0.05
APF/BF
OBF/BF
OAPF/BF
−0.4
−0.3
−0.2
−0.1
0.0
0.1
5th percentile
Log relative MSE
tau2=0.75
APF/BF
OBF/BF
OAPF/BF
−0.4
−0.3
−0.2
−0.1
0.0
0.1
5th percentile
Log relative MSE
tau2=1
APF/BF
OBF/BF
OAPF/BF
−1.5
−1.0
−0.5
0.0
0.5
50th percentile
Log relative MSE
tau2=0.05
APF/BF
OBF/BF
OAPF/BF
−1.5
−1.0
−0.5
0.0
0.5
50th percentile
Log relative MSE
tau2=0.75
APF/BF
OBF/BF
OAPF/BF
−1.5
−1.0
−0.5
0.0
0.5
50th percentile
Log relative MSE
tau2=1
APF/BF
OBF/BF
OAPF/BF
−0.4
−0.3
−0.2
−0.1
0.0
0.1
95th percentile
Log relative MSE
tau2=0.05
APF/BF
OBF/BF
OAPF/BF
−0.4
−0.3
−0.2
−0.1
0.0
0.1
95th percentile
Log relative MSE
tau2=0.75
APF/BF
OBF/BF
OAPF/BF
−0.4
−0.3
−0.2
−0.1
0.0
0.1
95th percentile
Log relative MSE
tau2=1
Figure 11.1 AR(1) plus noise model (pure filter). Relative mean square error performance (on the
log-scale) of the four filters across S = 50 datasets of size n = 100 and R = 50 runs of each filter.
Particle size for all filters is N = 500. Numbers below zero indicate a superior performance of the
filter relative to the bootstrap filter (BF).
7
i=1 πipN(log y2t ; μi + α + βmt−1, vi + τ2 + β2Ct−1),wheremt−1 andCt−1 aretheKalman
moments from Section 11.2.1. By integrating out both states xt and xt−1, we expect the above
weights to be flatter, more evenly balanced than the respective ones based on the BF, APF, APF1
and APF2. In addition, instead of sampling xt, we first sample κt from {1, . . . , 7} with Pr(κt = i) ∝
πiN(log y2t ; μi + α + βmt−1, vi + τ2 + β2Ct−1), for i = 1, . . . , 7, and then update mt and Ct
via equations (11.11) to (11.13) from Section 11.2.1. See the discussion in the last paragraph of Section
11.3.2. We call this APF filter simply FAAPF in what follows.
A total of n = 200 data points were simulated from α = −0.03052473, β = 0.9702, τ2 =
0.031684 and x0 = −1.024320. This is the specification used in one of the simulated exercises

Online Bayesian learning in dynamic models
213
from [48] and is chosen to mimic the time series behaviour of financial returns. We assume that
x0 ∼N(m0, C0) for m0 = −1.024320 and C0 = 1. We run the three filters for R = 50 times,
each time and each one based on N = 1000 particles. We then compute their mean absolute error,
MAE = n
t=1 |ˆqα
t,f −qαt |/n, where qαt and qα
t,f are the true and approximated αth percentile of
p(xt|y1:t), for α = (5, 50, 95) and f one of the filters.
Figure 11.2 summarizes our simulation exercise. The empirical findings suggest that the filters
perform quite similarly, with the FAAPF, followed by the BF, being uniformly better than all other
filters for all percentiles. This is probably partially due to the fact that the variability of the system
equation (τ2 = 0.02) is much smaller than that of the observation equation. Recall, from Section
11.2.3, that the variance of the log χ2
1 is around 4.94. In other words, pN(yt; 0, exp{α + βxt−1})
does not seem to be a good SIR proposal for p(yt|xt−1). On one of their simulation exercises,
[48] found similar results. They say that ‘the auxiliary particle filter is more efficient than the plain
0
50
100
150
200
0.5
1.0
1.5
Time
Standard deviations
N=100
0
50
100
150
200
0.5
1.0
1.5
Time
Standard deviations
N=1000
0
50
100
150
200
0.5
1.0
1.5
Time
Standard deviations
N=10000
BF
APF
APF1
APF2
FAAPF
0.005
0.010
0.015
0.020
5th percentile
MAE
BF
APF
APF1
APF2
FAAPF
0.005
0.010
0.015
0.020
0.025
50th percentile
MAE
BF
APF
APF1
APF2
FAAPF
0.01
0.02
0.03
0.04
0.05
0.06
95th percentile
MAE
APF/BF
APF1/BF APF2/BF FAAPF/BF
0.6
0.8
1.0
1.2
1.4
1.6
1.8
5th percentile
Relative MAE
APF/BF
APF1/BF APF2/BF FAAPF/BF
0.5
1.0
1.5
50th percentile
Relative MAE
APF/BF
APF1/BF APF2/BF FAAPF/BF
0.5
1.0
1.5
95th percentile
Relative MAE
Figure 11.2 SV-AR(1) model (pure filter). Relative mean absolute error performances. The top panels
show the trajectories of true (dark lines) and BF-based approximations (grey lines) for the αth
percentiles p(xt|yt), with α in {5, 50, 95} and particle sizes N in {100, 1000, 10 000}. True trajectories
are basically BF with N = 1 000 000 (using APF or APF1 produced the same results). The middle
panels show MAE based on R = 100 runs of each filter based on N = 1000 particles. APF1,
APF2 and FAAPF are APF with first-stage weights q(xt−1|yt) and resampling proposal q(xt|xt−1, yt)
described in Section 11.3.5. Bottom panels are relative MAE of APF, APF1, APF2 and FAAPF relative
to BF.

214
H. F. Lopes and C. M. Carvalho
particle filter, but the difference is small, reflecting the fact that for the SV model, the conditional
likelihood is not very sensitive to the state.’
11.4 Parameter learning
The particle filters introduced in Section 11.3, and illustrated in the examples of Section 11.3.5,
assumed that θ, the vector of parameters governing both evolution and observation equations
(see equations 11.1 and 11.2), is known. This was partially for didactical or pedagogical reasons and
partially to emphasize the chronological order of appearance of the filters. Sequential estimation of
fixed parameters θ is historically and notoriously difficult. Simply including θ in the particle set is
a natural but unsuccessful solution, as the absence of a state evolution implies that we will be left
with an ever-decreasing set of atoms in the particle approximation for p(θ|y1:t).
Important developments in the direction of sequentially updating p(xt, θ|y1:t), instead of simply
p(xt|y1:t, θ), have been made over the last decade and now sequential parameter learning is an
important sub-area of research within the particle filter branch. [38], [55], [21], [50] and [8] are
a good representation of the rapid developments in this area. We revisit several of these contribu-
tions here along with illustrations of their implementation in the AR(1) plus noise and SV-AR(1)
models.
11.4.1 Liu and West’s filter
[38] adapt the generic APF of Section 11.3.2 to sequentially resample and propagate particles asso-
ciated with xt and θ simultaneously. More specifically, equation (11.32) is rewritten as
p(xt, xt−1, θ|y1:t) ∝p(xt, θ|xt−1, y1:t)
3
45
6
2. Propagate
p(yt|xt−1, θ)p(xt−1, θ|y1:t−1)
3
45
6
1. Resample
.
(11.37)
Similarly to the APF’s generic proposal (equation 11.33), Liu and West resample old particles (xt, θ)
with first-stage weights proportional to p(yt|h(xt−1), m(θ)), with h(·) as before and m(θ) = aθ +
(1 −a) ¯θ. Let ˜θ and ˜xt−1 be the resampled particles. New particles θ are then propagated from the
resampled particles via N(m( ˜θ), h2V), where a2 + h2 = 1, and new particles xt are propagated
from g(xt|˜xt−1, ˜θ). The second-stage weights are proportional to p(yt|xt, θ)/p(yt|h(˜xt−1), m( ˜θ)).
The quantities ¯θ and V are, respectively, the particle approximations to E(θ|y1:t) and V(θ|y1:t).
The key idea here is the choice of the proposal q(xt, θ|xt−1, y1:t) to approximate
p(xt, θ|xt−1, y1:t).
The
proposal
q(xt, θ|xt−1, y1:t)
is
decomposed
into
two
parts:
q(xt|θ, xt−1, y1:t) = g(xt|xt−1, θ) (blind propagation) and q(θ|xt−1, y1:t), which is locally
approximated by N(m(θ), h2V). This smooth kernel density approximation ([58], [59]) literally
adds an artificial evolution to θ, as suggested in [29], but it controls the inherent over-dispersion
by locally shrinking the particles θ towards their mean ¯θ. [38] use standard discount factor ideas
from basic dynamic linear models to select the tuning constant a (or h). The constants a and h
measure, respectively, the extent of the shrinkage and the degree of over dispersion of the mixture.
The rule of thumb is to select a greater than or equal to, say, 0.99. The idea is to use the mixture
approximation to generate fresh samples from the current posterior in a attempt to avoid particle
degeneracy.
The main attraction of [38]’s filter is its generality as it can be implemented in any state-space
model. It also takes advantage of APF’s resample–propagate framework and can be considered a
benchmark in the current literature. The steps of the LW algorithm are as follows:

Online Bayesian learning in dynamic models
215
Step 1 (Resample) (˜xt−1, ˜θ) from (xt−1, θ) with weights wt ∝p(yt|h(xt−1), m(θ));
Step 2 (Propagate)
a) ˜θ to ˆθ via N(m( ˜θ), h2V);
b) ˜xt−1 to ˆx via g(xt|˜xt−1, ˆθ);
Step 3 (Resample) (xt, θ) from (ˆxt, ˆθ) with weights wt+1 ∝p(yt|ˆxt, ˆθ)/p(yt|h(˜xt−1), m( ˜θ)).
11.4.2 Storvik’s filter
Storvik (2002) [55] (see also [21]) proposes a particle filter that sequentially updates states and
parameters by focusing on the particular case where the posterior distribution of θ given x1:t and
y1:t depends on a low-dimensional set of sufficient statistics, i.e. p(θ|y1:t, x1:t) = p(θ|st), that can
be recursively and deterministically updated via st = S(st−1, xt−1, xt, yt).
We are using both models as illustrations in this chapter, i.e. the AR(1) plus noise and the
SV-AR(1) models, allow sequential parameter learning via updating a set of sufficient statistics.
Other, more general examples are the class of conditionally Gaussian DLMs and the class of dis-
crete-state dynamic models, such as hidden Markov models (HMM), change-point models and
generalized DLMs. The steps of the Storvik’s algorithm are as follows:
Step 1 (Propagate) xt−1 to ˜xt via q(xt|xt−1, θ, yt);
Step 2 (Resample) (xt−1, xt, st−1)
from
(xt−1, ˜xt, st−1)
with
weights
wt ∝
p(yt|˜xt,θ)p(˜xt|xt−1,θ)
q(˜xt|xt−1,θ,yt)
;
Step 3 (Propagate)
a) st = S(st−1, xt−1, xt, yt);
b) θ from p(θ|st).
The resampling proposal density q(xt|xt−1, θ, yt) plays the same role as it did in the BF and
the APF.
11.4.3 Particle learning
[8, 9] present methods for sequential filtering, particle learning (PL) and smoothing for a rather
general class of state space models. They extend Chen and Liu’s (2000) [11] mixture Kalman fil-
ter (MKF) methods by allowing parameter learning and utilize a resample–propagate algorithm
together with a particle set that includes state sufficient statistics. They also show via several sim-
ulation studies that PL outperforms both the LW and Storvik filters and is comparable to MCMC
samplers,evenwhenfulladaptationisconsidered.Theadvantageisevenmorepronouncedforlarge
values of n.
Let sxt denote state sufficient statistics satisfying deterministic updating rule sxt = K(sx
t−1, θ, yt),
forK(·)mimickingtheKalmanfilterrecursionsofSection11.2.1.ThestepsofagenericPLalgorithm
are as follows:
Step 1 (Resample) ( ˜θ, ˜sx
t−1, ˜st−1) from (θ, sx
t−1, st−1) with weights wt ∝p(yt|sx
t−1, θ);
Step 2 (Propagate)
a) (xt−1, xt) from p(xt−1, xt|sx
t−1, θ, yt);
b) st = S(˜st−1, xt−1, xt, yt);

216
H. F. Lopes and C. M. Carvalho
c) θ from p(θ|st);
d) sxt = K(˜sx
t−1, θ, yt).
The reason for propagating xt−1 in step (2a) above, is that in the great majority of dynamic models
used in practice, S is a function of xt−1, and possibly several other lags xt. The AR(1) plus noise
model of Section 11.2.2 and the SV-AR(1) model of Section 11.2.3 fall into this category. In addition,
it is worth mentioning that (xt−1, xt) is discarded after st is propagated.
11.4.4 Examples
We illustrate the various particle filters with parameter learning via the AR(1) plus noise model
and the SV-AR(1) model as before. Then, the SV-AR(1) model is generalized to accommodate
Student’s t errors (Section 11.4.4.3), leverage effects (Section 11.4.4.4) and Markov switching
(Section 11.4.4.5).
11.4.4.1 AR(1) plus noise model
We revisit the AR(1) plus noise model equations (11.18) and (11.19) from Section 11.2.2, but now
assumingthat(σ 2, τ2) = (1, 0.05)andthatthegoalistosequentiallyapproximatep(xt, α, β|y1:t).
The priors of (α, β) and x0 are, respectively, N(a0, τ2A0) and N(m0, C0) (see Section 11.2.2.2),
while parameter sufficient statistics st are defined by the set of equations (11.21). One dataset with
n = 100 observations is simulated from (α, β, x0) = (0.05, 0.95, 1.0). The prior hyperparameters
are (m0, C0) = (1.0, 10), a0 = (0, 1) and A0 = 2I2.
Figure 11.3 shows the true contours of p(α, β|y1:n) ∝p(α, β)p(y1:n|α, β) on a grid for the pair
(α, β) along with approximate contours (N = 1000 particles) based on a OAPF approximation
to p(y1:n|α, β) (Section 11.3.2 and equation (11.20)). In practice, when (α, β) is replaced by larger
parameter vectors, the use of grids could be replaced by a MCMC, SIR or rejection step. One can
argue that approximating p(y1:n|θ) by particle filters should be done with caution (see [47], and,
more recently, [44], for further discussion).
α
β
−0.10
−0.05
0.00
0.05
0.10
0.85
0.90
0.95
1.00
1.05
α
β
−0.10
−0.05
0.00
0.05
0.10
0.85
0.90
0.95
1.00
1.05
Figure 11.3 AR(1) plus noise model (parameter learning). Left panel: Contours of the prior distribution
p(α, β) (dashed lines) and exact contours of the posterior distribution p(α, β|y1:n) (solid lines). Right
panel: Contours of ˆp(α, β|y1:n) ∝p(α, β)ˆp(y1:n|α, β), where approximated integrated likelihood
ˆp(y1:n|α, β) is based on the OAPF of Section 11.3.2 and equation (11.20).

Online Bayesian learning in dynamic models
217
Figure 11.4 compares the performance of the LW filter (with a = 0.995) and PL to sequen-
tial (brute force) MCMC. The MCMC for this model is outlined in Section 11.2.2.1 and is
run for 2000 iterations with the second half used for posterior summaries. The LW filter
starts to show particle degeneracy around the 50th observation and moves away from the true
percentiles.
Time
α
0
20
40
60
80
100
−0.4
−0.2
0.0
0.2
0.4
0.6
MCMC
LW
PL
Time
β
0
20
40
60
80
100
0.2
0.4
0.6
0.8
1.0
1.2
1.4
Time
xt
0
20
40
60
80
100
−2
−1
0
1
2
Figure 11.4 AR(1) plus noise model (parameter learning). 5th, 50th and 95th percentiles of p(α|y1:t)
(top) and p(β|y1:t) (middle) and p(xt|y1:t) (bottom) based on MCMC, LW filter and PL. MCMC is
based on 1000 draws (after discarding the first 1000 draws). LW and PL are based on 1000 particles.

218
H. F. Lopes and C. M. Carvalho
11.4.4.2 SV-AR(1) model
We revisit the SV-AR(1) plus noise model equations (11.22) and (11.23) from Section 11.2.3, but
now assuming that (α, β|τ2), τ2 and x0 are, respectively, N(a0, τ2A0), IG(ν0/2, ν0τ2
0 /2) and
N(m0, C0). As in the illustration of Section 11.3.5.2, a total of n = 200 data points were simulated
from α = −0.03, β = 0.97, τ2 = 0.03 and x0 = −0.1. We assume, as before, that (m0, C0) =
(−0.1, 1). The other hyperparameters are a0 = (−0.03, 0.97), A0 = 1.6I2 and (ν0, τ2
0 ) =
(10, 0.04).
The LW filter is based on 500 000 particles, while PL is based on 50 000. MCMC for the model
(see Sections (11.2.3.1) and (11.2.3.2)) is implemented over time for comparison with both the LW
filter and PL. MCMC, which starts at the true values, is based on 10 000 draws after the same
numberofdrawsisdiscardedasburn-in.Figure11.5summarizestheresults.PLandMCMCproduce
fairlysimilarresults,withLWslightlyworse.NoticethatLWisbasedon10timesmoreparticlesthan
PL. We compared LW, PL and MCMC runs to a fine grid approximation of p(α, β, τ2|y1:n), with a
100-point grid for the log-volatilities xt in (−5, 2) and 50-point grids in the intervals (−0.15, 0.1),
(0.85, 1.05)and(0.01, 0.15),forα,β andτ 2,respectively.Inthiscase,bothLWandPLarebasedon
20000 particles and MCMC is based on 20000 draws after the same number of draws is discarded
as burn-in.
Figure 11.6 summarizes the R = 10 replications of LW and PL, both based on N = 10 000
particles. LW has a larger Monte Carlo error when approximating the filtering distributions for
all quantities, with particular emphasis on the volatility of the log-volatility τ2 and, consequently,
on the latent state xt. Based on this simple exercise and running our code in R, it takes about 7
and 15 minutes to run the LW filter and PL, respectively. It takes about 8 minutes to run MCMC
based on the whole time series of n = 200 observations. It takes about 13 hours to run MCMC
based on y1:t for all t ∈{1, . . . , 200}, i.e. 50 times slower than PL and 100 times slower than the
LW filter.
11.4.4.3 SV-AR(1) model with t errors
In order to illustrate particle filters’ ability to approximate the predictive density p(yt|y1:t−1) via
equation 11.36 from Section 11.3.3, we implement PL for the SV-AR(1) model and the SV-AR(1)
model with Student’s t error as in [42] on a simulated dataset with errors following tν for ν ∈
{1, 2, 4, 30}. Figure 11.7 compares the Bayes factors (in the log scale) of the tν models against nor-
mality. For instance, when the data is t1 or t2, each additional outlier makes Bayes factors support
t models more significantly. For additional discussion on sequential model comparison and model
checking via particle methods see, for instance, [8, 9] and [39].
11.4.4.4 SV-AR(1) model with leverage
[46] introduce MCMC for posterior inference in the SV-AR(1) model with leverage. More
precisely, log-volatility dynamics (equation (11.23)) is now xt|xt−1, θ ∼N(α + βxt−1 +
τρyt−1 exp{−xt−1/2}, τ2(1 −ρ2)). Negative ρ captures the increase in (log-)volatility xt that
followsadropinyt−1.Oneoftheirexamples,where(α, β, τ2, ρ) = (−0.026, 0.97, 0.0225, −0.3),
is revisited here based on n = 10 000 observations (they use only n = 1000) in order to illustrate
how asimple,genericLW filter performs relativelywell,evenwhenthesamplesizeis fairlylarge.We
use their prior specification, (β + 1)/2 ∼Beta(20, 1.5), α|β ∼N(0, (1 −β)2), ρ ∼U(−1, 1),
and τ2 ∼IG(5/2, 0.05/2), and run the LW filter based on N = 500 000 particles and tuning
parameter a = 0.995. Figure 11.8 summarizes the results. This LW filter could easily be extended
to fit the other SV models they considered, such as the SV-t model (see Section 11.4.4.3) and the
superposition models.

Online Bayesian learning in dynamic models
219
−0.15
−0.10
−0.05
0.00
0.05
0.90
0.95
1.00
LW
α
β
−0.15
−0.10
−0.05
0.00
0.05
0.02
0.04
0.06
0.08
0.10
0.12
0.14
LW
α
0.90
0.95
1.00
0.02
0.04
0.06
0.08
0.10
0.12
0.14
LW
β
τ2
τ2
τ2
τ2
τ2
τ2
−0.15
−0.10
−0.05
0.00
0.05
0.90
0.95
1.00
PL
α
β
−0.15
−0.10
−0.05
0.00
0.05
0.02
0.04
0.06
0.08
0.10
0.12
0.14
PL
α
0.90
0.95
1.00
0.02
0.04
0.06
0.08
0.10
0.12
0.14
PL
β
−0.15
−0.10
−0.05
0.00
0.05
0.90
0.95
1.00
MCMC
α
β
−0.15
−0.10
−0.05
0.00
0.05
0.02
0.04
0.06
0.08
0.10
0.12
0.14
MCMC
α
0.90
0.95
1.00
0.02
0.04
0.06
0.08
0.10
0.12
0.14
MCMC
β
−0.15
−0.10
−0.05
0.00
0.05
0
5
10
15
20
Density
α
0.90
0.95
1.00
0
5
10
15
20
25
Density
β
0.02 0.04 0.06 0.08 0.10 0.12 0.14
0
5
10
15
20
25
30
35
Density
τ
2
TRUE
LW
PL
MCMC
Figure 11.5 SV-AR(1) model (parameter learning). First three rows: True (contours) and approx-
imated (dots) joint posterior distributions: p(α, β|y1:n) (1st row), p(α, τ2|y1:n) (2nd row) and
p(β, τ2|y1:n) (3rd row). Columns are based on LW filter, PL and MCMC. Fourth row: True and
approximated marginal posterior distributions p(α|y1:n), p(β|y1:n) and p(τ2|y1:n).
11.4.4.5 SV-AR(1) model with regime switching
[10] implement the LW filter for SV-AR(1) models with regime switching, where equation (11.23)
becomes xt|xt−1, st, θ ∼N(α + βxt−1 + γ st, τ2), for γ > 0 and latent regime switching vari-
able st ∈{0, 1}. We assume, for simplicity, that st obeys a two-regime homogeneous Markov
model with Pr(st = 0|st−1 = 0) = p and Pr(st = 1|st−1 = 1) = q. The vector of fixed param-
eters is θ = (α, β, τ2, p, q) and the vector of latent states is (xt, st). We revisit their analysis of the

220
H. F. Lopes and C. M. Carvalho
LW
Time
alpha
0
50
100
150
200
−0.6
−0.4
−0.2
0.0
0.2
0.4
PL
Time
alpha
0
50
100
150
200
−0.6
−0.4
−0.2
0.0
0.2
0.4
LW
Time
beta
0
50
100
150
200
0.2
0.4
0.6
0.8
1.0
1.2
1.4
PL
Time
beta
0
50
100
150
200
0.2
0.4
0.6
0.8
1.0
1.2
1.4
LW
Time
tau2
0
50
100
150
200
0.02
0.04
0.06
0.08
0.10
0.12
0.14
PL
Time
tau2
0
50
100
150
200
0.02
0.04
0.06
0.08
0.10
0.12
0.14
LW
Time
xt
0
50
100
150
200
0.0
0.5
1.0
1.5
2.0
2.5
PL
Time
xt
0
50
100
150
200
0.0
0.5
1.0
1.5
2.0
2.5
Figure 11.6 SV-AR(1) model (parameter learning). Approximate 5th, 50th and 95th percentiles of
p(α|y1:t) (1st row), p(β|y1:t) (2nd row), p(τ2|y1:t) (3rd row) and p(xt|y1:t) (4th row) based on LW
filter (left column) and PL (right column) for R = 10 replications of both filters and 10 000 particles.

Online Bayesian learning in dynamic models
221
0
50
100
150
200
0
20
40
60
80
100
120
Time
Log Bayes factor
0
50
100
150
200
−5
0
5
10
15
Time
Log Bayes factor
0
50
100
150
200
−10
−5
0
5
Time
Log Bayes factor
0
50
100
150
200
−20
−15
−10
−5
0
Time
Log Bayes factor
Figure 11.7 SV-AR(1) model with tν error. Bayes factors (in the log scale) of fitting tν models against
normal models. The lines are t1 (solid dark line), t2 (solid grey line), t4 (dashed dark line) and t30
(dashed grey line). Thicker solid lines correspond to the true data generating models.
IBOVESPA stock index (São Paulo Stock Exchange) but with a larger dataset spanning 01/02/1997
to 08/08/2011 (n = 3612 observations). The prior hyperparameters (Section 11.2.2.2) are d0 =
(−0.25, 0.95, 0.05), D0 = 6I3, ν0 = 10 and τ2
0 = 0.05, with p ∼Beta(50, 1), q ∼Beta(1, 50),
x0 ∼N(0, 1) and s0 ∼Ber(0.1). Figure 11.9 summarizes our findings. The model with regime
switching captured the major 1997–1999 crisis listed in [11], as well as the more recent credit
crunch crisis of 2008. It also captured the sharp drop on Monday, August 8th 2011, when
the IBOVESPA (and most financial markets worldwide) suffered an 8% fall following worries
about the weak US economy and the high levels of public debt in Europe. See [40] and [52]
for further discussion and illustrations of particle methods in SV-AR(1) models with regime
switching.
11.4.4.6 SV-AR(1) model with realized volatility.
In this final illustration, we revisit [56] who estimate SV models using daily returns
and realized volatility simultaneously. Their most general model assumes that returns
y1t ∼N(0, exp{xt/2}) and that the log-volatility dynamics is xt|xt−1, θ ∼N(α + βxt−1 +

222
H. F. Lopes and C. M. Carvalho
alpha
0
2000
4000
6000
8000
10000
−0.10
−0.05
0.00
beta
0
2000
4000
6000
8000
10000
0.85
0.90
0.95
1.00
tau2
0
2000
4000
6000
8000
10000
0.02
0.04
0.06
0.08
rho
0
2000
4000
6000
8000
10000
−1.0
−0.5
0.0
0.5
Figure 11.8 SV-AR(1) model with leverage. Sequential parameter learning based on LW filter and
N = 500 000 particles.
τρy1,t−1 exp{−xt−1/2}, τ2(1 −ρ2)) (as in Section 11.4.4.4). The model is completed with
realized volatility y2t ∼N(ξ + xt, σ 2), where ξ is the bias-correction term. We use high frequency
data of the Tokyo price index (TOPIX) that what was kindly shared with us (the authors) for
this illustration. In what follows y2t is the logarithm of the scaled realized volatility based on
one-minute intraday returns when the market is open during the 10-year period from April 1st,
1996 to March 31st, 2005 (n = 2216 trading days). Therefore, the vector of static parameters of
the model is θ = (α, β, τ2, ρ, ξ, σ 2). Implementation of the LW filter is fairly simple and we
fit four models to the data: RV model, SV-AR(1) model, SV-AR(1) model with leverage and the
current model. The RV model is basically an AR(1) plus noise model, in which case ξ = 0 for
identification reasons. We label these four models RV, SV, ASV and ASV-RVC in what follows. The
number of particles is N = 100 000 and LW’s tuning parameter is a = 0.995. Figure 11.10 shows
posterior medians for time-varying standard deviations and their logarithms. The ASV model
seems to be less sensitive to extremes when compared to the SV model. One can argue that the RV
model is too adaptive when compared to the SV model. Similarly, the ASV-RVC is less sensitive to
extremes when compared to the ASV model, while being less adaptive than the RV model. These
results are corroborated by the marginal posterior densities for the models’ parameters where
the persistence parameter β and the leverage parameter ρ are smaller in the ASV-RVC model.

Online Bayesian learning in dynamic models
223
Time
Returns
−0.1
0.0
0.1
0.2
0.3
1/2/97 1/2/98 1/4/99 1/3/00 1/2/01 1/2/02 1/2/03 1/2/04 1/3/05 1/2/06 1/2/07 1/2/08 1/2/09 1/4/10 1/3/11 8/8/11
Time
Log Bayes factor
0
2
4
6
8
10
1/2/97 1/2/98 1/4/99 1/3/00 1/2/01 1/2/02 1/2/03 1/2/04 1/3/05 1/2/06 1/2/07 1/2/08 1/2/09 1/4/10 1/3/11 8/8/11
Time
Probability of being in regime 1
0.0
0.2
0.4
0.6
0.8
1.0
1/2/97 1/2/98 1/4/99 1/3/00 1/2/01 1/2/02 1/2/03 1/2/04 1/3/05 1/2/06 1/2/07 1/2/08 1/2/09 1/4/10 1/3/11 8/8/11
Figure 11.9 SV-AR(1) model with regime switching. IBOVESPA returns (top frame) from 01/02/1997
to 08/08/2011 (n = 3612 observations), Log Bayes factor (middle frame) and Pr(st = 1|y1:t) (bot-
tom frame). The LW filter is based on N = 200 000 particles.
In addition, both parameters ξ and σ 2 are away from zero, suggesting that the biased-corrected
realized volatility helps estimating daily log-volatilities xt.
11.5 Discussion
This chapter reviews many of the important advances in the particle filter literature over the last
two decades. Two relatively simple but fairly general models are used to guide the review: the
AR(1) plus noise model and the SV-AR(1) model. We aim at a broad audience of researchers and
practitioners and illustrate the benefits and the limitations of particle filters when estimating with
dynamic models where sequentially learning of latent states and fixed parameters is the primary
interest.

224
H. F. Lopes and C. M. Carvalho
Daily return
−6
−4
−2
0
2
4
6
Apr0196
Jan2098
Nov0499
Aug2101
June1103
Mar3105
Log realized volatility
−1
0
1
2
3
Apr0196
Jan2098
Nov0499
Aug2101
June1103
Mar3105
Standard deviation
0.5
1.0
1.5
2.0
2.5
Apr0196
Jan2098
Nov0499
Aug2101
June1103
Mar3105
SV
ASV
Log standard deviation
−1
0
1
2
3
Apr0196
Jan2098
Nov0499
Aug2101
June1103
Mar3105
SV
RV
Standard deviation
0.5
1.0
1.5
2.0
2.5
Apr0196
Jan2098
Nov0499
Aug2101
June1103
Mar3105
ASV
ASVRVC
Log standard deviation
−1
0
1
2
3
Apr0196
Jan2098
Nov0499
Aug2101
June1103
Mar3105
RV
ASVRVC
Figure 11.10 SV-AR(1) plus realized volatility model. Top row: Daily returns and logarithm of daily
realized volatilities. Middle and bottom rows: Posterior medians of standard deviations and their
logarithms based on four models: SV-AR(1) model (SV), SV with leverage (ASV), realized volatility
(RV) and ASV-RV combined (ASV-SRVC).
The applications of Section 11.4.4 based on several (important) stochastic volatility models were
intended to illustrate to the reader how relatively complex (despite univariate) models can be
sequentially estimated via particle filters at relatively low computational cost. They are compara-
ble in performance to the standard MCMC proposed in the references listed in each one of the
examples. It is important to emphasize that this cost increases with the dimension of both latent
state and static parameter vectors and that this is one of the leading sub areas of current theoretical
and empirical research.
There are currently several review papers, chapter and books the reader should read after becom-
ing fluent with the tools we introduce here. Amongst those are the earlier papers by [17], [2]
and [13], books by [36], [17a] and [53] and the 2002 special issue of IEEE Transactions on Signal
Processing on sequential Monte Carlo methods.
Morerecentreviewsare[4],[19],[51](chapter6)and[43].Theycarefullyorganizeandhighlight
the fast development of the field over the last decade, such as parameter learning, more efficient
particle smoothers, particle filters for highly dimensional dynamic systems and, perhaps the most
recent, interconnections between MCMC and SMC methods.

Online Bayesian learning in dynamic models
225
Many important topics and issues were left out. Particle smoothers, for instance, are becoming
a realistic alternative to MCMC in dynamic systems when the smoothed p(x1:t|y1:t), or simply
p(xt|y1:t), is the distribution of interest. See [28], [22], [15] and [3], amongst others.
The interface between PF and MCMC methods is illustrated in our examples (see, for example,
Section11.3.3andFigure11.5).HybridschemesthatcombineparticlemethodsandMCMCmethods
are abundant. [27] and [50], for instance, use MCMC steps to sample and replenish static param-
eters in dynamic systems. [1] introduce particle MCMC methods to efficiently construct proposal
distributions in high dimension via SMC methods. See also [49].
Finally, particle filters have recently received a lot of attention in estimating non-dynamic models
such as mixtures, Gaussian processes, tree models, etc. Important references are [39] and [9].
References
[1] Andrieu, C., Doucet, A. and Holenstein, R. (2010). Particle Markov chain Monte Carlo (with
discussion). Journal of the Royal Statistical Society, Series B, 72, 269–342.
[2] Arulampalam, M. S., Maskell, S., Gordon, N. and Clapp, T. (2002). A Tutorial on Particle
Filters for On-line Nonlinear/Non-Gaussian Bayesian Tracking. IEEE Transactions on Signal
Processing, 50, 174–188.
[3] Briers, M., Doucet, A. and Maskell, S. (2010). Annals of the Institute of Statistical Mathematics
Smoothing algorithms for state-space models, 6261–89.
[4] Cappé, O., Godsill, S. and Moulines, E. (2007). An overview of existing methods and
recent advances in sequential Monte Carlo. IEEE Proceedings in Signal Processing, 95,
899–924.
[5] Cappé, O., Moulines, E. and Rydén, T. (2005). Inference in Hidden Markov Models. Springer,
New York.
[6] Carlin, B. P., Polson, N. G. and Stoffer, D. S. (1992). A Monte Carlo approach to nonnor-
mal and nonlinear state-space modelling. Journal of the American Statistical Association, 87,
493–500.
[7] Carter, C. K. and Kohn, R. (1994). On Gibbs sampling for state space models. Biometrika, 81,
541–53.
[8] Carvalho, C. M., Johannes, M., Lopes, H. F. and Polson, N. (2010). Particle learning and
smoothing. Statistical Science, 25, 88–106.
[9] Carvalho, C. M., Lopes, H. F., Polson, N. and Taddy, M. (2010). Particle learning for general
mixtures. Bayesian Analysis, 5.
[10] Carvalho, C. M. and Lopes, H. F. (2007). Simulation-based sequential analysis of
Markov switching stochastic volatility models. Computational Statistics & Data Analysis, 51,
4526–4542.
[11] Chen, R. and Liu, J. S. (2000). Mixture Kalman filter. Journal of the Royal Statistical Society,
Series B, 62, 493–508.
[12] Chopin, N. (2002). A sequential particle filter method for static models. Biometrika, 89,
539–52.
[13] Crisan, D. and Doucet, A. (2002). A survey of convergence results on particle filtering meth-
ods for practitioners. IEEE Transations on Signal Processing, 50, 736–746.
[14] Del Moral, P., Doucet, A. and Jasra, A. (2006). Sequential Monte Carlo samplers. Journal of
the Royal Statistical Society, Series B, 68, 411–436.
[15] Douc, R., Garivier, E., Moulines, E. and Olsson, J. (2009). On the forward filtering backward
smoothing particle approximations of the smoothing distribution in general state space mod-
els. Annals of Applied Probability (to appear).

226
H. F. Lopes and C. M. Carvalho
[16] Douc, R., Moulines, E. and Olsson, J. (2009). Optimality of the auxiliary particle filter. Prob-
ability and Mathematical Statistics, 29, 1–28.
[17] Doucet, A., Godsill, S. J. and Andrieu, C. (2000). On sequential Monte Carlo sampling meth-
ods for Bayesian filtering. Statistics and Computing, 10, 197–208.
[17a] Doucet, A., de Freitas, N. and Gordon, N. (ed.) (2001). Sequential Monte Carlo Methods
in Practice. New York: Springer-Verlag.
[18] Doucet, A. and Johansen, A. (2008). A Note on Auxiliary Particle Filters. Statistics & Proba-
bility Letters, 78, 1498–1504.
[19] Doucet, A. and Johansen, A. (2009). A Tutorial on Particle Filtering and Smoothing: Fifteen
years Later. In D. Crisan and B. Rozovsky, editors, Handbook of Nonlinear Filtering. Oxford:
Oxford University Press.
[20] Durbin, J. and Koopman, S. J. (2001). Time Series Analysis by State Space Methods. Oxford
University Press.
[21] Fearnhead, P. (2002). Markov chain Monte Carlo, sufficient statistics and particle filter. Jour-
nal of Computational and Graphical Statistics, 11, 848–62.
[22] Fearnhead, P., Wyncoll, D. and Tawn, J. (2010). A sequential smoothing algorithm with linear
computational cost. Biometrika, 97, 447–464.
[23] Frühwirth-Schnatter, S. (1994). Data augmentation and dynamic linear models. Journal of
Time Series Analysis, 15, 183–202.
[24] Gamerman, D. (1998). Markov Chain Monte Carlo for dynamic generalized linear models.
Biometrika, 85, 215–27.
[25] Gamerman, D. and Lopes, H. F. (2006). Markov Chain Monte Carlo: Stochastic Simulation for
Bayesian Inference. Chapman & Hall/CRC.
[26] Ghysels, E., Harvey, A. C. and Renault, E. (1996). Stochastic Volatility. In C. R. Rao and
G. S. Maddala (eds) Handbook of Statistics: Statistical Methods in Finance, 119–191. (Amster-
dam: North-Holland.)
[27] Gilks, W. R. and Berzuini, C. (2001). Following a moving target-Monte Carlo inference for
dynamic Bayesian models. Journal of the Royal Statistical Society, Series B, 63, 127–46.
[28] Godsill, S. J., Doucet, A. and West, M. (2004). Monte Carlo smoothing for non-linear time
series. Journal of the American Statistical Association, 50, 438–449.
[29] Gordon, N., Salmond, D. and Smith, A. F. M. (1993). Novel approach to nonlinear/
non-Gaussian Bayesian state estimation. IEE Proceedings F. Radar Signal Process, 140,
107–113.
[30] Guo, D., Wang, X. and Chen, R. (2005). New sequential Monte Carlo methods for nonlinear
dynamic systems. Statistics and Computing, 15, 135–47.
[31] Hull, J., and White, A. (1987). The Pricing of Options on Assets with Stochastic Volatilities.
Journal of Finance, 42, 281–300.
[32] Jacquier, E., Polson, N. G. and Rossi, P. E. (1994). Bayesian analysis of stochastic volatility
models. Journal of Business and Economic Statistics, 20, 69–87.
[33] Johannes, M. and Polson, N. G. (2010). MCMC methods for continuous-time financial
econometrics, in Ait-Sahalia, Y. and Hansen, L. P. eds, Handbook of Financial Econometrics,
Volume 2. Princeton: University Press, 1–72.
[34] Kim, S., Shephard, N. and Chib, S. (1998). Stochastic Volatility: Likelihood Inference and
Comparison with ARCH Models. Review of Economic Studies, 65, 361–393.
[35] Kong, A., Liu, J. S. and Wong, W. (1994). Sequential imputation and Bayesian missing data
problems. Journal of the American Statistical Association, 89, 590–99.
[36] Liu, J. S. (2001). Monte Carlo Strategies in Scientific Computing. New York: Springer-Verlag.
[37] Liu, J. and Chen, R. (1995). Blind Deconvolution via Sequential Imputations. Journal of the
American Statistical Association, 90, 567–76.

Online Bayesian learning in dynamic models
227
[38] Liu, J. and West, M. (2001). Combined parameters and state estimation in simulation-based
filtering. In A. Doucet, N. de Freitas and N. Gordon, editors, Sequential Monte Carlo Methods
in Practice. New York: Springer-Verlag.
[39] Lopes, H. F., Carvalho, C. M., Johannes, M. and Polson, N. G. (2011). Particle learning for
sequential Bayesian computation (with discussion). In J. M. Bernardo, M. J. Bayarri, J. O.
Berger, A. P. Dawid, D. Heckerman, A. F. M. Smith and M. West, editors, Bayesian Statistics 9.
Oxford: Oxford University Press, 317–360.
[40] Lopes, H. F. and Polson, N. G. (2010). Extracting SP500 and NASDAQ volatility: The credit
crisis of 2007-2008. In A. O’Hagan and M. West, editors, The Oxford Handbook of Applied
Bayesian Analysis. Oxford: Oxford University Press, 319–42.
[41] Lopes, H. F. and Polson, N. G. (2010). Bayesian inference for stochastic volatility modelling.
InBocker,K.(Ed.)Rethinking Risk Measurement and Reporting: Uncertainty, Bayesian Analysis
and Expert Judgement, 515–551.
[42] Lopes, H. F. and Polson, N. G. (2011). Particle Learning for Fat-tailed Distributions. Working
Paper, The University of Chicago Booth School of Business.
[43] Lopes, H. F. and Tsay, R. (2011). Particle filters and Bayesian inference in financial economet-
rics. Journal of Forecasting, 30, 168–209.
[44] Malik, S. and Pitt, M. K. (2011). Particle filters for continuous likelihood evaluation and
maximisation. Journal of Econometrics (in press).
[45] Migon, H. S., Gamerman, D., Lopes, H. F. and Ferreira, M. A. R. (2005). Dynamic models. In
D. Dey, and C. R. Rao (Eds.), Handbook of Statistics, Volume 25: Bayesian Thinking, Modelling
and Computation, 553–588.
[46] Omori, Y., Chib, S., Shephard, N. and Nakajima, J. (2009). Stochastic volatility with leverage:
Fast and efficient likelihood inference. Journal of Econometrics, 140, 425–449.
[47] Pitt, M. K. (2002). Smooth particle filters for likelihood evaluation and maximisation. Tech-
nical Report Department of Economics, University of Warwick.
[48] Pitt, M. K. and Shephard, N. (1999). Filtering via simulation: Auxiliary particle filters. Journal
of the American Statistical Association, 94, 590–99.
[49] Pitt,M.K.,Silva,R.S.,Giordani,P.andKohn,R.(2012).OnsomepropertiesofMarkovchain
Monte Carlo simulation methods based on the particle filter. Journal of Econometrics, 171 (2),
134–151.
[50] Polson, N. G., Stroud, J. R. and Müller, P. (2008). Practical filtering with sequential parameter
learning. Journal of the Royal Statistical Society, Series B, 70, 413–28.
[51] Prado, R. and West, M. (2010). Time Series: Modelling, Computation and Inference. Chapman
& Hall/CRC, The Taylor Francis Group.
[52] Rios, M. P. and Lopes, H. F. (2011). Sequential parameter estimation in stochastic volatility
models. Working Paper. The University of Chicago Booth School of Business.
[53] Ristic, B., Arulampalam, S. and Gordon, N. (2004). Beyond the Kalman Filter: Particle Filters
for Tracking Applications. Artech House Radar Library.
[54] Rosenberg, B. (1972). The Behaviour of Random Variables with Nonstationary Variance and
the Distribution Of Security Prices. Working Paper No. 11, University of California, Berkeley,
Institute of Business and Economic Research, Graduate School of Business Administration,
Research Programme in Finance.
[55] Storvik, G. (2002). Particle filters for state-space models with the presence of unknown static
parameters. IEEE Transactions on Signal Processing, 50, 281–89.
[56] Takahashi, M., Omori, Y. and Watanabe, T. (2009). Estimating stochastic volatility models
using daily returns and realized volatility simultaneously. Computational Statistics and Data
Analysis, 53, 2404–2426.

228
H. F. Lopes and C. M. Carvalho
[57] Taylor, S. J. (1986). Modelling Financial Time Series. New York: John Wiley and Sons.
[58] West, M. (1993). Approximating posterior distributions by mixtures. Journal of the Royal Sta-
tistical Society, Series B, 54, 553–68.
[59] West, M. (1993). Mixture models, Monte Carlo, Bayesian updating and dynamic models.
Computing Science and Statistics, 24, 325–33.
[60] West, M. and Harrison, J. (1997). Bayesian Forecasting and Dynamic Models, 2nd Edition. New
York: Springer.

12
Semi-supervised
classification of texts
using particle learning
for probabilistic
automata
ana paula sales,
christopher challis,
ryan prenger and daniel merl
12.1 Introduction
S
omeofthekeystatisticalproblemsunderlyingmanycurrentnationalsecurityapplicationsstem
from a common need for continuously deployable, self-adapting learning systems. Tracking
and other signal processing tasks have long been the purview of dynamic Bayesian models [17] and
sequential Monte Carlo techniques [8], however it is a relatively recent development that virtually
all manner of inference tasks have been similarly relegated due to the staggering increase in data col-
lection capabilities. In particular, many classic learning problems such as classification, regression
and latent structure discovery, the inferential aspects of which were once dealt with in purely retro-
spectivefashionbymaximumlikelihoodorbatchBayesestimation,havebecometrackingproblems
of a sort as a result of the modern always-on data collection apparatus. In such settings, the target to
be tracked is the joint posterior distribution of the parameters of the underlying probability model,
for in a constant data collection setting, it can be difficult to justify model stationarity over long
or indefinite periods of observation. This is especially true for adversarial classification problems,
one example of which is spam detection, where intuitively the boundary between the positive class
and negative class is constantly evolving as the adversary improves its attack vector. Therefore any
robust solution to this type of detection problem must be similarly capable of adaptation, which is
conceptually straightforward to accomplish when the associated inference is accomplished using
sequential Monte Carlo methods.
The statistician will also recognize this as a natural setting for semisupervised learning, the statis-
tical underpinnings of which were reviewed previously in Liang, Mukherjee, and West [11]. The
salient characteristic of a semisupervised learning problem is the presence of a limited quantity

230
A. P. Sales, C. Challis, R. Prenger and D. Merl
of labelled data, and a usually much larger quantity of unlabelled data. In the context of a classi-
fication problem, the labels of course refer to the true class assignments associated with a set of
observedpredictorvariables.Effectiveapproachesforsemisupervisedlearningisanimportanttopic
of research in the national security arena due to the fact that labelled data is laboriously generated
by human analysts whose finite ground-truthing efforts must be efficiently utilized. Similarly, the
feasibility of active learning [7] for intelligent tasking of human resources is another area of active
research. Underlying both of these research areas, however, is the common need for an online
learning framework conducive to making the sort of recommendations required of active learning
and smoothly accommodating the sort of feedback obtained in a semisupervised setting.
Inthischapter,wedescribeonesuchframeworkbasedupontherecentparticlelearningalgorithm
of Carvalho et al. [5, 6], which provides sequential parameter estimation for conjugate Bayesian
models through a novel sequential Monte Carlo approach. The primary contributions of this work
are the development of a new particle learning approach for efficient online estimation of simple
text grammars as represented by probabilistic automata, and the development of a semisupervised
classification system based on a flexible class of composite mixture models. Combined, these two
components form the basis of a classification system for text-valued observations that does not
require an exchangeability assumption on the tokens within the texts (e.g. the usual ‘bag-of-words’
representation).
The remainder of this chapter is organized as follows. In Section 12.2 we present a hierarchical
model representation of a class of probabilistic automata and derive the particle learning algorithm
for obtaining parameter estimates, highlighting the computational advantages of the probabilis-
tic automata over more expressive grammars such as hidden Markov models. In Section 12.3 we
describeaframeworkforsemisupervisedtextclassificationproblemsbasedonacompositemixture
model formulation. In Section 12.4 we describe an application of the classifier to a spam detection
dataset in which we are able to accurately discriminate between spam and non-spam through
directly modelling the generative grammars as mixtures of probabilistic automata. Finally, Section
12.5 concludes with a discussion of computational considerations and future work.
12.2 Particle learning for probabilistic deterministic finite
automata
The seeming oxymoron probabilistic deterministic finite automata (PDFA) refers to a subclass of
the greater family of probabilistic automata that includes many popular state space models such
as hidden Markov models [9]. PDFA are characterized by probabilistically generated observables
but deterministic state transitions conditional on both the current state and the current observation
(Figure 12.1).
st+1
xt+1
st–1
xt–1
st
xt
Figure 12.1 State transition diagram for a probabilistic deterministic finite automaton. The observ-
ables xt follow emission distributions indexed by the underlying states st. The state transitions are
deterministic given the previous state and previous observation.

Semi-supervised classification of texts
231
PDFA have received recent attention as a possible computationally attractive substitute for
HMMs for some natural language applications. Dupont et al. provide a thorough discussion of the
connections between PDFA and HMMs, establishing PDFA to be a strict subclass of HMMs [9].
Pfauetal.recentlyintroducedtheprobabilisticdeterministicinfiniteautomaton(PDIA),aninfinite
mixture of PDFA derived via a Dirichlet process prior on the emission distribution parameters [13].
Pfau et al. demonstrated the PDIA to have predictive performance exceeding that of an HMM on
certain natural language problems.
Motivated by this favourable comparison to HMMs, in this work we consider only the fully
parametric PDFA, and proceed to derive a particle learning approach to parameter estimation.
12.2.1 Model description
Let xt denote a categorical observable at time t. The PDFA model can be written in hierarchical
model form as follows:
xt|st, θ ∼Multi(xt|1, θst)
(12.1)
st|xt−1, st−1, π ∼δπst−1,xt−1 (st)
(12.2)
πs,x|α ∼Multi(πs,x|1, α)
(12.3)
θs|γ ∼Dirichlet(θs|γ )
(12.4)
where st denotes the associated hidden state at time t, θs parameterizes the emission distribution
associated with state s, and δπs,x(st) represents the degenerate distribution with mass at πs,x. Thus
πs,x specifies the transition out of state s after emitting x. The model is completed by specifying
prior distributions for each πs,x and θs, parameterized by α and γ respectively.
The state transitions are deterministic given the previous observable and previous state. Thus, if
we assume the initial state is some known starting state, then it is wholly artificial to represent the
hiddenstatesequence,sinceeverysubsequentstateissimplyafunctionofthepreviousstateandthe
previous observable. The only parameters of the model are those θs that characterize the emission
distribution associated with each state, and the transition function, represented here as π. Finally,
if θs is assigned a prior distribution that is conjugate to the form of the emission distribution, as
we have done here with the Multinomial/Dirichlet combination, then the posterior distribution
of each θs will have a closed form and it will be possible to effectively eliminate the parameter
by integrating the likelihood with respect to this posterior. Thus we are left only with the task of
conducting inference on the transition function π.
12.2.2 Parameter estimation using PL
In this section we derive a simple but highly effective particle learning algorithm for performing
inference on the PDFA transition function π. A few preliminary remarks concerning the PDFA
setting will be helpful. Consider now the process of estimating π: at time t only πs,x for which
there was some t′ < t for which xt′ = x and st′ = s need to be defined by each particle. All other
πs,x are yet undefined, and are therefore implicitly represented by their common prior distribution
(Eqn. 12.3). We will represent by πt the set of transitions necessary to specify the state path up until
time t. Note that this includes πst−1,xt−1, but not necessarily πst,xt, as the transition from time t to
time t + 1 may yet be undefined.
As in any sequential Monte Carlo setting, our goal will be to produce samples from p(πt|xt)
throughacombinationofresamplingandpropagatingacurrentsetofposteriorsamples(‘particles’)
from p(πt−1|xt−1) (where xt denotes the vector of all observables x1, . . . , xt up to time t).

232
A. P. Sales, C. Challis, R. Prenger and D. Merl
Assume that we begin with a uniformly weighted particle approximation p(πt−1|xt−1) ≈
1
N
N
i=1 δπt−1
(i) (π) where πt−1
(i)
denotes a distinct sample from the target distribution. Upon
observing xt we have the following:
p(πt|xt) ∝p(xt|πt−1, xt−1)p(π|xt−1)
(12.5)
This is the usual sequential importance sampling setting: given a particle approximation to
p(πt−1|xt−1) we can produce a particle approximation to p(πt|xt) by adjusting the weights of
the current particles according to the posterior predictive density of xt. The general form of the
posterior predictive is as follows:
p(πt|xt) ∝p(πt, xt|xt−1)
(12.6)
= p(πst−1,xt−1|xt, πt−1)p(xt|xt−1, πt−1)p(πt−1|xt−1)
(12.7)
Thus the weight for each particle is updated in this way:
ˆwt = wt−1
p(πst−1,xt−1|xt, πt−1)p(xt|xt−1, πt−1)
φ(πst−1,xt−1|xt, πt−1)
(12.8)
where ˆwt is the unnormalized weight at time t and φ(πst−1,xt−1|xt, πt−1) is a proposal distribution
for πst−1,xt−1. The natural choice for this proposal distribution is p(πst−1,xt−1|xt, πt−1), which
informs the proposed transition by the next data point. Thus the weight update simplifies to
ˆwt = wt−1p(xt|xt−1, πt−1)
(12.9)
The particle filter then requires the tasks of computing the weight update p(xt|xt−1, πt−1), and
the proposal distribution p(πxt−1,st−1|xt, πt−1).
We consider first the form of the weight update.
p(xt|xt−1, πt−1) =

st
p(xt, st|xt−1, πt−1)
(12.10)
=

st

p(xt|st, xt−1, πt−1)p(st|xt−1, πt−1)

(12.11)
=

st

p(xt, θ|st, xt−1, πt−1)dθ

p(st|xt−1, πt−1)

(12.12)
=

st

p(xt|θ, st)p(θ|st, xt−1, πt−1)dθ

p(st|xt−1, πt−1)

(12.13)
=

st

θst,xtp(θ|st, xt−1, πt−1)dθ

p(st|xt−1, πt−1)

(12.14)
=

st
γ (t−1)
st,xt
γ (t−1)
st
p(st|xt−1, πt−1)
(12.15)

Semi-supervised classification of texts
233
whereγ (t)
s,x = γx + t
k=1 δs(sk)δx(xk)andγ (t)
s
= 
x γ (t)
s,x .Thenγ (t−1)
s,x
isthenumberoftimes
the state-symbol pair (s, x) has been observed previously, and γ (t−1)
s
is the total number of prior
visits to state st. We can make this last step because the integral in (12.14) is the expectation of θst,xt
with respect to the posterior distribution of θst updated through time t −1. This posterior is a
Dirichlet distribution due to multinomial Dirichlet conjugacy.
The proposal distribution for πst−1,xt−1 requires a straightforward application of Bayes’ rule.
p(πst−1,xt−1|xt, πt−1) ∝p(xt|xt−1, πt)p(πst−1,xt−1|xt−1, πt−1)
(12.16)
= p(xt|st, xt−1, πt)p(st|xt−1, πt−1)
(12.17)
= γ (t−1)
st,xt
γ (t−1)
st
p(st|xt−1, πt−1)
(12.18)
The first identity follows because st is determined by xt−1 and πt, and the second from the pre-
ceding development of p(xt|xt−1, πt−1). The distribution is then specified by computing (12.18)
for each st and normalizing the values. The weight update in (12.15) can now be seen to be the nor-
malizing constant of the transition proposal probabilities. This suggests the possibility of a simpler
representation of p(πt|xt). We have chosen to decompose the posterior in this way, however, in
order to generate intelligent transition proposals.
12.2.2.1 Algorithm
In the previous section we developed general forms for the propagation distribution and weight
update. These expressions simplify considerably when we consider the nature of the PDFA. Note
first that when πst−1,xt−1 is defined in πt−1, p(st|xt−1, πt−1) = 1 when st = πst−1,xt−1, and
zero otherwise. Thus Eqn. 12.15 becomes simply γ (t−1)
st,xt
/γ (t−1)
st
, and (12.18) leads us to propose
πst−1,xt−1 with probability 1.
In the case where πst−1,xt−1 remains undefined at time t −1, the transition is still represented by
the prior distribution and we have p(st|xt−1, πt−1) = αst. We can now completely specified the
filtering algorithm.
Algorithm. Particle learning for PDFA
For each time period t = 1, . . . , T:
For each particle i = 1, . . . , N (particle subscripts omitted):
(1) Update (and normalize) weights:
ˆwt =
⎧
⎪⎪⎨
⎪⎪⎩
wt−1
γ (t−1)
st,xt
γ (t−1)
st
if π(i)
xt−1,st−1 is already defined
wt−1

st
γ (t−1)
st,xt
γ (t−1)
st
αst
if π(i)
xt−1,st−1 is undefined
(12.19)
(2) Resample if necessary.
(3) Sample new transitions. If not yet defined, sample a value st for πst−1,xt−1 proportional
to γ (t−1)
st,xt
/γ (t−1)
st
.
(4) Increment γ : γ (t)
st,xt = γ (t−1)
st,xt
+ 1

234
A. P. Sales, C. Challis, R. Prenger and D. Merl
The tasks of the algorithm are simply to track the number of observations of each state/symbol
pair and calculate probabilities according to simple empirical ratios (adjusted by prior parameters).
This simplicity allows for easy implementation, fast computation and widespread applicability.
12.2.2.2 Multiple sequence inference
There are many applications in which data consist of multiple sequences that can be treated as
independently generated from the same model. The particle learning algorithm described above
can be trivially modified to include a special character ω, signalling the end of a sequence by setting
πs,ω = s0,withs0 aspecialinitialstate.Thisallowsthemodeltobetraineddifferentlywhennatural
divisions occur in the data, such as sentences in natural language.
12.3 Semisupervised classifiers using composite mixtures
In this section, we describe a simple computational framework for semisupervised learning tasks
that leverages the sequential learning capabilities represented by particle learning and related meth-
ods. Figure 12.2 demonstrates the broad aim of this type of system. Data enters the system from
the left; the underlying model can then be updated and/or the predicted dependent variables
can be computed from the observed independent variables. The augmented observation is then
considered according to various active learning criteria, and either the prediction is accepted (up
arrow) or directed to a human analyst for ground-truthing and reincorporation into the data stream
(down arrow).
The key task here lies in specifying a joint probability model on (y, x), where y is notionally
a dependent variable (e.g. ‘the label’) and x is the independent/predictor variable, such that the
parameters of p(y, x) can be efficiently learned in sequential fashion, thereby facilitating the nec-
essary feedback loop. Additionally, it will be useful if p(y, x) is specified such that both p(y|x) and
p(x)areanalyticallytractable,insofarasthesederivationsunderlieourabilitytoperformprediction
of the dependent variable. Borrowing from the literature of nonlinear regression via multivariate
Gaussian mixtures [11, 12], we now specify a flexible family of composite mixture distributions for
classification tasks with heterogeneous arrays of predictor variables.
12.3.1 Composite mixture models for classification
Let (yt, xt) denote the class label yt associated with a corresponding p-dimensional array of pre-
dictor variables xt = [xt,1, xt,2, . . . , xt,p]. Note that in general yt can be multivariate, and not nec-
essarily categorical. The usual strategy for specifying a joint probability model on a functional
response (yt) and a set of predictors (xt) involves embedding yt and xt in a common space such
that the full covariance structure can be modelled explicitly; this occurs by default in regression
via Gaussian mixtures literature, since each mixture component is parameterized by a covariance
matrix involving both response and predictors. In this application we are especially interested in
yt, xt
PL
<         >
yt, xt, E[yt|xt]
?
<                      >
Figure 12.2 Flow diagram of semisupervised PL system capable of seamless switching between
supervised updates, prediction and feedback.

Semi-supervised classification of texts
235
cases where that embedding is non-trivial due to the disparity between the nature of the response
andthevariouselementsofthepredictorarray;forexamplethesituationarisingintextclassification
isthatxt mayconsistofoneormoretextstrings,andyt isacategoricalvalue.Inordertoaccomodate
joint modelling of this type of response–predictor pair, rather than attempting to specify a common
embedding via a GLM- or copula-based approach, we instead specify a composite mixture model
(CMM) as follows:
p(yt, xt) =
K

k=1
ωkpk(yt, xt)
(12.20)
=
K

k=1
ωk
⎛
⎝
|yt|

i=1
pk(yt,i)
|xt|

j=1
pk(xt,j)
⎞
⎠
(12.21)
In the CMM, each mixture component is a composite of independent distributions for each
element of the response and predictor arrays. For text classification purposes we will be
interested in CMM consisting of different compositions of multinomial and PDFA distri-
butions, e.g. comparisons between pk(yt, xt) = Mn(yt|k,y)PDFA(xt|k,x) and pk(yt, xt) =
Mn(yt|k,y)Mn(xt|k,x) would be used to investigate the effectiveness of the order-sensitive
PDFA approach to modelling xt over a standard multinomial bag-of-words model of xt (here k,·
denotes the appropriate parameters for the given element within component k).
Although simplistic, the CMM formulation has several important properties. Firstly, it provides
a mechanism for combining multiple disparate data types into a common probability model with-
out resorting to complicated embeddings that would preclude sequential analysis. Secondly, the
independence assumption within each mixture component results in the appealing property of
analytically tractable conditional and marginal distributions, namely
p(yt|xt) =
K

k=1
ωk(xt)pk(yt)
(12.22)
p(xt) =
K

k=1
ωkpk(xt)
(12.23)
where ωk(xt) =
ωkpk(xt)
K
ℓ=1 ωℓpℓ(xt). Thirdly, although the elements of the response and predictor
arrays are independent within each mixture component, it is still possible to recover complex corre-
lations and dependencies between elements via the inclusion of a large number of mixture compo-
nents. Although there may be more parsimonious ways of modelling the joint covariance structure,
this is arguably the simplest and most generally applicable to a wide array of data types. Finally, the
within-component independence allows computation associated with component updating to be
parallelized across independent elements of the composite model.
12.3.2 Particle learning for composite mixtures
The basic particle learning algorithm for mixture models was developed in Carvalho et al. [6], and
it is a straightforward extension of those ideas to derive a particle learning approach for CMM.
Followingthenotationof[6]eachparticleiattimet ischaracterizedbyanessentialstatevectorZ(i)
t
which contains the various sufficient statistics for posterior distributions of all model parameters.
The key requirements of particle learning are that

236
A. P. Sales, C. Challis, R. Prenger and D. Merl
1. Each Z(i)
t
allows computation of the posterior predictive distribution of the complete obser-
vation p(yt+1, xt+1|Z(i)
t ),
2. Each Z(i)
t
allows sampling from the posterior distribution of sufficient statistics
p(Z(i)
t+1|Z(i)
t , yt, xt).
For mixture models, such {Z(i)
t } arise through specifying a standard Dirichlet(α) prior on mixture
weights and independent, conjugate composite priors for the model parameters of each mixture
component. The state vectors are then characterized by the sufficient statistics associated with the
parameters of mixture component conditional on a particular partition of the data amongst mixture
components.
Furthermore, by modifying the PDFA model structure to accomodate multiple independent
sequences (Section 12.2.2.2), we are able incorporate the particle propagation technique from
the PL algorithm described above into a PLCMM setting, thus producing a sequential learning
framework fully conducive to semisupervised text classification via CMM such as pk(yt, xt) =
Mn(yt|θk)PDFA(xt|πk).
12.4 Application to spam detection
The CMM involving PDFA elements as described above provides a flexible framework with poten-
tial application to a variety of domains. We now demonstrate the utility of the approach in the
context of classification of email messages into one of two categories: spam or non-spam. The task
of spam filtering poses several interesting challenges that illustrate well some of the most appealing
properties of our PLCMM approach.
Two primary aspects of spam data make spam filtering a non-trivial problem. Firstly, given the
streaming nature of email, spam filtering datasets are large and constantly increasing in size. Sec-
ondly, spammers are continuously developing new ways to evade current spam filters, such that
the distinguishing characteristics of spam messages change over time. Hence, in training a spam
filter, one is faced with an infinite stream of ever-evolving data. Together, these two properties of
email data effectively render infeasible the use of traditional batch Monte Carlo (MC) methods
for spam filtering. Batch MC methods must be trained once; as such, in order to incorporate new
data, the models must be retrained with an augmented or time shifted dataset. In contrast, particle
learning (and SMC methods, in general) allows models to be repeatedly updated with individual
observation; as such, it bypasses the issue of ever-increasing training dataset size faced by batch
MC methods. Hence, particle filtering constitutes an elegant approach to accomodate and model
this type of dynamical data.
Email text is generally composed in natural language following the rules of its grammar. As such,
adjacent words are not independent of one another. For instance, given an adjective such as ‘cold’ in
atextwritteninEnglish,onewouldexpectanounsuchas‘weather’tofollow.PDFAmodelsaccount
for this type of dependency among words by modelling both word frequency and order. This is
in contrast with commonly used approaches to spam filtering (and text classification in general),
such as multinomial factor models such as Latent Dirichlet Allocation [3]. In such models only the
frequency with which words appear in the message is modeled. By modelling both word frequency
and order, the PDFA model provides a natural representation for this type of data, without the
recursive computations required of hidden Markov models.
Another relevant consideration regarding spam filtering involves the process by which labels are
assigned to new training data. Given the large volume of incoming messages, the need for expensive
and limited human resources becomes a bottleneck in continuous model updating. The PLCMM
frameworkcanreducetheneedforhumaninterventionbyautomaticallytriagingthedataasfollows.

Semi-supervised classification of texts
237
Foreachnewmessagethatarrives,wecomputetheconditionalexpectationofthemultinomiallabel
given the observed text feature, and thus obtain predictive distribution of the label value. In cases in
whichthevarianceofthisexpectationissufficientlylow,thepredictedlabelcanbetreatedasthetrue
label of the message, and the message along with its inputed label can be used to update the model.
Only when the predicted label has sufficiently high variance is the message flagged for evaluation
by a person. This allows all incoming messages to be used for both prediction and training, with
minimal human intervention.
A final characterizing aspect of spam filtering is that misclassification costs (i.e. false positive
cost and false negative cost) should not necessarily be treated as equal. It is generally preferable
to misclassify a spam message as being a legitimate message (false positive) than to mislabel a legit-
imate message as being spam (false negative). In the PLCMM framework, these misclassification
costs can easily be incorporated into the prediction step via the use of thresholds on the posterior
probabilities that reflect this bias.
12.4.1 Description of spam data
In this application, we use the public email corpus PU1 [1].2 This corpus consists of 1099 email
messages, 481 of which are spam messages received over the course of 22 months, and 618 of which
are legitimate email messages collected over the period of 36 months. All messages in the corpus
have been preprocessed as follows. All fields of the header, except for the ‘subject’ field, have been
removed, such that each message is composed of only two parts: ‘subject’ and ‘body’. Additionally,
all attachments and html tags have been removed. Finally, the messages in the corpus are encoded
forprivacy,withuniquetokensbeingreplacedwithintegerindicesacrossallmessagesofthecorpus.
The PU1 corpus is available in four different versions, obtained by enabling or disabling a lem-
matizer and a stop-list. The lemmatizer converts words to their dictionary form, such that different
forms of the same word are grouped together and can be treated as a single term. For example,
the lemmatizer converts both ‘selling’ and ‘sale’ to ‘sell’, and both ‘good’ and ‘better’ to ‘good’. The
stop-list removes the 100 most frequent words of the British National Corpus from each message.
Herein, these four versions of the data are referred to as follows: ‘bare’ (lemmatizer disabled,
stop-list disabled), ‘lemm’ (lemmatizer enabled, stop-list disabled), ‘stop’ (lemmatizer disabled,
stop-list enabled), and ‘lemm+stop’ (lemmatizer enabled, stop-list enabled).
12.4.2 Modelling strategy
In order to train a PLCMM spam filter we need to make a number of design choices regarding both
the input data as well as several aspects of the model itself. Here we consider some of the most
relevant aspects to demonstrate model flexibility and power.
Dataconsiderations.Theprimarydesignquestionweaddressregardingthedataisthatofwhat
partsoftheemailmessagesshouldbeincludedinthemodel:subject,bodyorboth.Additionally,
we consider the benefits of processing the data with a lemmatizer and a stop-list, by comparing
results obtained using the four datasets described above in Section 12.4.1: bare, lemm, stop and
lemm+stop.
Model considerations. Many of the existing spam filters take into account only the distribu-
tion of words in the messages. By defining a CMM involving PDFA models for text-valued
features we are able to incorporate both word distribution and word order. Hence, our foremost
interest here is to assess whether including word order information into the model provides a
2 Available at: http://labs-repos.iit.demokritos.gr/skel/i-config/.

238
A. P. Sales, C. Challis, R. Prenger and D. Merl
performance improvement over using a model based only on aggregate word distributions. We
accomplishthisbycomparingthepredictiveaccuraciesofCMMsinwhichthedatafields(body
and/or subject of message) are modelled alternately with a PDFA or a multinomial distribution
(which is equivalent to a PDFA with a single state, as described in Section 12.3). In this analysis
we do not perform extensive investigation of prior sensitivity, but rather focus solely on the
impact of the number of hidden states in the PDFA and the number of components in the
composite mixture model.
12.4.3 Experimental results
HerewepresenttheresultsofperformingpredictionsonPU1datausingPDFAmodels.Allanalyses
were done via 10-fold cross-validation, where the dataset was partitioned into 10 parts, such that
nine of them were used for training and the remaining one was used for testing. We explore two
PDFA models, PDFA1 and PDFA2, which differ only in whether or not the body of the email
is included in the model. In both models the email label, y, follows a multinomial distribution.
In the PDFA1 model, the predictor variable x denotes only the email subject and is distributed
accordingtoaPDFA.Thus,inmodelPDFA1theemaildataisrepresentedbythecompositemixture
model,
pPDFA1(y, x) =
K

k=1
ωkMn(y|k,y)PDFA(x|k,x)
where once again the  terms indicate the appropriate parameter vectors for each element of the
CMM. In the PDFA2 model, the predictor variable, (x1, x2), denotes both the email subject and
the email body, with both following independent PDFAs,
pPDFA2(y, x1, x2) =
K

k=1
ωkMn(y|k,y)PDFA(x|k,x1)PDFA(x2|k,x2)
As described earlier, a simpler alternative to PDFAs is to model the subject and body of emails as
multinomial distributions. In this case, only the frequency of each word is relevant, whereas with
the PDFA both the frequency and order of words contribute to the model. In order to determine
whether including the order of words leads to an improvement in model performance, we also
consider two additional composite mixture models, Mn1 and Mn2,
pMn1(y, x) =
K

k=1
ωkMn(y|k,y)Mn(x|k,x),
pMn2(y, x1, x2) =
K

k=1
ωkMn(y|k,y)Mn(x1|k,x1)Mn(x2|k,x2),
where, as in the PDFA models, x1 denotes email subject and x2 denotes email body. Table 12.1
presents a comparison of these four models. In all models, every multinomial random variable
was given a Dirichlet prior with hyperparameter α = 0.01. All simulations were performed using
30 mixture components, 100 particles and an effective sample size-based resampling strategy
with a threshold of 75. In all PDFA elements, the maximum number of hidden states allowed
was 20.

Semi-supervised classification of texts
239
Table 12.1 Summary of models, showing the email features (email subject and email body)
included in the model, as well as their distribution. Note that when both subject and body are
included in the model, both follow the same distribution.
Model
Email subject
Email body
Subject/body distribution
Mn1
yes
no
Multinomial
Mn2
yes
yes
Multinomial
PDFA1
yes
no
PDFA
PDFA2
yes
yes
PDFA
Figures 12.3 and 12.4 summarize the results obtained with the four models, showing the ROC
curves and their corresponding AUC measurements, respectively. There are several interesting
observations to be made from these results. First and foremost, we address the primary question
of interest, which is that of whether or not the PDFA model provides a better description of the
data than a multinomial model. The short answer to this question is that it depends on the length
and complexity of the variable being modelled. Specifically, using a PDFA to model email subject
did not improve prediction performance in relation to a model using a multinomial distribution,
as can be seen by comparing models Mn1 and PDFA1 in Figures 12.3 and 12.4. These results are, in
fact, what one would expect given that email subjects are typically very short, with mean length of
approximately five words. In contrast, modelling the body of emails with PDFAs leads to substan-
tial improvements in prediction accuracy in comparison with modelling the body of emails with
multinomial distributions. Indeed, the PDFA2 model produces significantly better ROC curves
than the Mn2 model (see Figure 12.3). Once again, these results are expected since email bodies
are sufficiently long for the order of the words to be informative of the email label, with the median
email body length being over 160 words.
Perhaps the most surprising observation to be made from these results is the remarkably poor
prediction performance of model Mn2, in which both email subject and body are modelled with
multinomial distributions. This model performs worse than all other models we have tested, as can
be seen in Figure 12.3. It is peculiar to observe that moving from model Mn1 to model Mn2, that is,
simply adding a multinomial representation of the email body to a model in which the email subject
follows a multinomial distribution, leads to substantially worse prediction accuracy (with AUC
reducing from around 0.95 to around 0.55). This suggests that using a multinomial representation
oftheemailbodyisnotonlyuninformativefortheemaillabelprediction,butitisinfactdetrimental
to it, providing further validation to the usefulness of using PDFAs to model email text.
Our results also provides some insight into the impact of the different data pre-processing treat-
ments on model performance. Lemmasterization of the text did not confer any obvious improve-
ments to the performance of the classifiers. In contrast, the use of a stop-list, which removes the
100 most frequent words, led to improvements in classifier performance, both when words were
modelled with a multinomial distribution, but primarily when words were modelled with a PDFA
(see Figure 12.4). In fact, using a stop-list, regardless of whether or not a lemmasterizer was used,
resulted in the best overall AUC measurements and accentuated the improvements of PDFAs over
multinomial distributions.
Finally, we performed a parameter sensitivity analysis to determine the impact of the number of
mixture components in the particles and of the number of states in the PDFA on the prediction
performance of the PDFA1 and PDFA2 models. Figure 12.5 displays the mean AUC obtained from
10-fold cross-validation trials using the lemm+stop version of the PU1 dataset and the PDFA1

240
A. P. Sales, C. Challis, R. Prenger and D. Merl
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.4
0.8
0.0
0.4
0.8
0.0
0.4
0.8
False positive rate
True positive rate
A
0.0
0.2
0.4
0.6
0.8
1.0
False positive rate
True positive rate
B
0.0
0.2
0.4
0.6
0.8
1.0
False positive rate
True positive rate
0.0
0.4
0.8
True positive rate
C
0.0
0.2
0.4
0.6
0.8
1.0
False positive rate
D
Model
Mn1
Mn2
PDFA1
PDFA2
Figure 12.3 ROC curves for CMM-based classification on the four versions of the PU1 corpus: (A)
bare, (B) lemm, (C) lemm+stop and (D) stop. Each line represents the vertical average of the ROC
curves obtained by the 10 train–test partitions of the data used in the 10-fold cross-validation.
0.88
0.90
0.92
0.94
0.96
0.98
1.00
AUC
Model:
Mn1
Mn2
PDFA2
bare
lemm
lemm+stop
stop
Figure 12.4 Distribution of AUC measurements corresponding to the ROC curves shown in Fig-
ure 12.3. The AUC measurements for the model Mn2 are now shown here, and their mean values
were 0.5, 0.51, 0.56 and 0.69 for bare, lemm, lemm+stop and stop versions of the PU1 datasets,
respectively.

Semi-supervised classification of texts
241
2
5
10
20
25
30
Number of states (n)
40
30
20
10
7
5
3
Number of components (K)
0.017
0.02
0.014
0.021
0.017
0.018
0.012
0.02
0.012
0.018
0.016
0.016
0.014
0.015
0.018
0.015
0.013
0.015
0.015
0.012
0.013
0.017
0.021
0.017
0.018
0.02
0.012
0.018
0.01
0.022
0.019
0.015
0.016
0.013
0.02
0.016
0.011
0.017
0.016
0.019
0.017
0.028
0.93
0.95
Value
0
2
4
6
8
Color Key
and Histogram
Count
Figure 12.5 Sensitivity analysis of the number of components in the mixtures and the number of
states in the PDFA using the lemm+stop version of the PU1 dataset and including only the subject
of the email messages. The grey levels denote the mean AUC from 10 fold cross validation trial, and
the number within the cells denote one standard deviation from the mean. The grey level key to the
left provides a mapping of the grey level to AUC value, and a histogram showing the frequency with
which the values of AUC appear in the heatmap to the right.
model (results for the PDFA2 model are not shown, but are similar to the ones obtained with the
PDFA1 model). In this particular example, the best AUC values were obtained using 10 mixture
components per particle and five PDFA states. Similar AUC values were obtained with 30 mixture
componentsandtwoPDFAstates.Itissomewhatsurprisingthatthebestresultswereobtainedwith
such a small number of states. It would be interesting to investigate what words are emitted by each
state. Unfortunately, this exercise is impossible for the PU1 data which, for privacy reasons, is made
availablein an encoded format, wherewearenot ableto know what words actuallycorrespond with
codified values.
In general, all combinations of number of states and number of components led to high AUC
values, ranging from 0.92 to 0.99. These are encouraging results, suggesting that this approach is
reasonably robust to choices of number of components and number of states. Additionally, this

242
A. P. Sales, C. Challis, R. Prenger and D. Merl
observation could be particularly useful for situations where computational resources are limited;
in this scenario, one could use small numbers of components and states, and still expect reasonable
prediction accuracy.
12.5 Discussion
In recent years, interest in online learning systems has exploded as a result of the so-called ‘big data’
problem, which often precludes on computational grounds methods that require loading an entire
dataset into a computer’s memory. Online methods are by nature filters, operating on a reduced set
ofobservationsatatimeandretainingstateofmuchlowerdimensionthanthatoftheentiredata.An
effective framework for online learning is also prerequisite for active learning and semisupervised
learning tasks.
In this chapter, we have demonstrated a novel online learning system for classification of email
textsbasedonparticlelearningforcompositemixturemodelsinvolvingprobabilisticautomata.The
composite mixture structure allows specification of a joint probability model for heterogeneous
collections of independent variables without requiring complex embeddings via generalized linear
models or copula techniques. In this sense, a primary advantage of the CMM is the speed with
which new models can be instantiated simply by specifying the particular composite distribution
characterizing each mixture component. Although we have only demonstrated several such com-
posite distributions in this analysis, our software allows specification of arbitrary configurations
of exponential family distributions, thus enabling generalized classification and regression through
custom specification of heterogeneous collections of independent and dependent variables.
We have demonstrated the utility of the PL-based learning system in the context of spam detec-
tion,butthegeneralapproachisflexibleandcanbeappliedtoavastarrayofdomains,includingmul-
ticlass classification problems. One such application involves classification of newsgroup messages,
in which the goal is to correctly associate a message with the newsgroup to which it was posted. In
thistypeofapplication,aCMMclassifierservesasatypeofdatavalidationbyensuringthatmessage
content is appropriate for the particular forum. Preliminary results indicate that the same CMM
approaches involving PDFA elements demonstrated here in the context of spam will be similarly
useful. In a reduced subset of the 20 newsgroup dataset 3 consisting of five newsgroups belonging
to three subject matter categories (summarized in Table 12.2), we applied two CMMs: one in which
Table 12.2 Description of the newsgroup data subset.
Newsgroup name
Category
Train set size
Test set size
Medicine
Science
585
394
Cryptology
Science
594
395
Automobiles
Recreation
594
394
Religion_miscellanea
Religion
377
251
Atheism
Religion
480
319
3
Available at: http://people.csail.mit.edu/jrennie/20Newsgroups/.

Semi-supervised classification of texts
243
False positive rate
True positive rate
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
False positive rate
True positive rate
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
False positive rate
True positive rate
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
False positive rate
True positive rate
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
False positive rate
True positive rate
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
False positive rate
True positive rate
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
A
Model (AUC)
Mn ( 0.7387 )
PDFA ( 0.627 )
B
Model (AUC)
Mn ( 0.907 )
PDFA ( 0.9484 )
C
Model (AUC)
Mn ( 0.8023 )
PDFA ( 0.9672 )
D
Model (AUC)
Mn ( 0.8084 )
PDFA ( 0.9232 )
E
Model (AUC)
Mn ( 0.7041 )
PDFA ( 0.8742 )
Recreation (Mn)
Recreation (PDFA)
Science (Mn)
Science (PDFA)
Religion (Mn)
Religion (PDFA)
F
Figure 12.6 ROC curves for PDFA and multinomial (Mn) model used on the news group dataset
in the prediction of new group name (A–E) and subject matter category (F). The new group ROC
curves are (A) atheism, (B) automobiles, (C) cryptology, (D) medicine and (E) religion_miscellanea.

244
A. P. Sales, C. Challis, R. Prenger and D. Merl
the message text follows a PDFA and another in which it follows a multinomial distribution. The
prior parameters used in both models are the same as those described in Section 12.4.3. The results
obtained with both models are shown in Figure 12.6, in which each ROC curve characterizes the
ability of the underlying composite mixture model to correctly validate the actual newsgroup to
which the message was posted. ROC curves obtained with the PDFA model are generally superior
to those obtained with the multinomial, with the exception of group ‘atheism’. In predicting sub-
ject matter category, the PDFA model was more accurate than the Mn model for all three groups
(compare solid and dashed lines in Panel 12.6.F).
A key contribution of this work is the highly computationally efficient particle learning approach
for probabilistic deterministic finite automata. The conditionally deterministic transition structure
ofthePDFAresultsinsignificantlyreducedcomputationalrequirementsrelativetostandardhidden
Markov models, thus creating the opportunity for fast online learning, clustering and classification
of high frequency observations of order-dependent categorical sequences such as text. Future work
includes more direct investigation of the computational versus predictive tradeoff, in the context of
classification and regression tasks, of the PDFA versus comparable filtering techniques for HMMs
[2, 14]. Recent advances in online EM [4] and online variational methods [10, 16] may also have
implications for composite mixture-based classifiers, especially for extremely high frequency data
for which particle resampling produces a severe bottleneck.
It is currently an open topic for research how best to use the semisupervised learning capabil-
ities afforded by a PL-based inference framework. In this analysis, our utilization of unlabelled
data was restricted to performing prediction on the class label of the observation. Other possible
semisupervised operations include performing marginal updates in the presence of missing data,
or prioritizing labelling efforts through some measure capturing the uncertainty of the posterior
conditional label prediction (e.g. active learning). In particular, in cyber security applications such
as spam detection, there is a real need for active learning strategies suitable for adversarial classifica-
tion problems in which the class distributions are not static but actually converging as the so-called
“threat” class (e.g. spam) is deliberately made to look more and more similar to the benign class.
Accommodating the adversarial situation clearly requires modification of the modelling strategy
presented here to allow dynamic CMM, either by inclusion of discount factors iteratively applied
to the essential state vectors, or by building the dynamism directly into the mixture structure in a
manner very similar to that recently done for tree-based models in Taddy et al. [15].
Acknowledgement
This work was performed under the auspices of the U.S. Department of Energy by Lawrence
LivermoreNationalLaboratoryunderContractDE-AC52-07NA27344;Documentreleasenumber
LLNL-JRNL-513511.
References
[1] Androutsopoulos, Ion, Koutsias, John, Cb, Konstantinos V. and Spyropoulos, Constantine D.
(2000). An experimental comparison of naive Bayesian and keyword-based anti-spam filter-
ing with personal e-mail messages. In Proceedings of the 23rd annual international ACM SIGIR
conference on Research and development in information retrieval, pp. 160–167. ACM Press.
[2] Beal, Matthew, Ghahramani, Zoubin and Rasmussen, Carl (2002). The infinite hidden
Markov model. In Advances in Neural Information Processing Systems 14 (ed. T. Dietterich,
S. Becker, and Z. Ghahramani), pp. 577–584. MIT Press, Cambridge, MA.

Semi-supervised classification of texts
245
[3] Blei, D. M., Ng, A. Y. and Jordan, M. I. (2003). Latent Dirichlet allocation. Journal of Machine
Learning Research, 3, 993–1022.
[4] Cappé, Olivier (2011). Online EM algorithm for hidden Markov models. Journal of Computa-
tional and Graphical Statistics, 20(3), 728–749.
[5] Carvalho,C.,Johannes,M.,Lopes,H.andPolson,N.(2010).Particlelearningandsmoothing.
Statistical Science, 25(1), 88–106.
[6] Carvalho, C., Lopes, H., Polson, N. and Taddy, M. (2010). Particle learning for general mix-
tures. Bayesian Analysis, 5(4), 709–740.
[7] Cohn, David, Ghahramani, Zoubin and Jordan, Michael (1996). Active learning with statisti-
cal models. Journal of Artificial Intelligence Research, 4, 129–145.
[8] Doucet, Arnaud, de Freitas, Nando and Gordon, Neil (ed.) (2001). Sequential Monte Carlo
Methods in Practice. Springer.
[9] Dupont, P., Denis, F. and Esposito, Y. (2005). Links between probabilistic automata and
hiddenMarkovmodels:probabilitydistributions,learningmodels,andinductionalgorithms.
Pattern Recognition, 38, 1349–1371.
[10] Hoffman, Matthew, Blei, David and Bach, Francis (2010). Online learning for latent Dirichlet
allocation. In Advances in Neural Information Processing Systems 23 (ed. J. Lafferty, C. K. I.
Williams, J. Shawe-Taylor, R. Zemel, and A. Culotta), pp. 856–864. MIT Press, Cam-
bridge, MA.
[11] Liang, Feng, Mukherjee, Sayan and West, Mike (2007). The use of unlabeled data in predic-
tive modelling. Statistical Science, 22(2), 189–205.
[12] Müller, Peter, Erkanli, Alaattin and West, Mike (1996). Bayesian curve fitting using multivari-
ate normal mixtures. Biometrika, 83(1), 67–79.
[13] Pfau, D., Bartlett, N. and Wood, F. (2010). Probabilistic deterministic infinite automata. In
AdvancesinNeuralInformationProcessingSystems23 (ed.J.Lafferty,C.K.I.Williams,J.Shawe-
Taylor, R. Zemel, and A. Culotta), pp. 1930–1938. MIT Press, Cambridge, MA.
[14] Rodriguez, Abel (2011). On-line learning for the infinite hidden Markov model. Communica-
tions in Statistics–Simulation and Computation, 40(6), 879–893.
[15] Taddy, Matthew A., Gramacy, Robert B. and Polson, Nicholas G. (2011). Dynamic trees for
learning and design. Journal of the American Statistical Association, 106(493), 109–123.
[16] Wang, Chong, Paisley, John and Blei, David (2011). Online variational inference for the hier-
archical Dirichlet process. In Journal of Machine Learning Research Workshop and Conference
Proceedings, Volume 15, pp. 752–760.
[17] West, M. and Harrison, J. (1997). Bayesian Forecasting and Dynamic Models. Springer.

This page intentionally left blank 

Part VI
Nonparametrics

This page intentionally left blank 

13
Bayesian
nonparametrics
stephen g. walker
13.1 Introduction
B
efore talking about Bayesian nonparametrics specifically, it is worth discussing the Bayesian
approach in general. There are a number of ways of introducing Bayes and one can find them
in books such as [4]; [41]; [27]; and [37]. There are differences in the foundations, ranging from
a rigorous development using notions of rational behaviour and axioms pertaining to such, to the
mathematical formulation directly as the posterior being a product of the likelihood and prior.
There is a prevailing attitude that the foundations for Bayesian inference are resolved and prac-
titioners should now ‘just get on with it’, without trying to restructure or reformulate ideas behind
Bayesian thinking. This would be arguable were it not for the rapid advance in computation and
computer power which allows the analyst to construct and estimate models of any size. Actions
which took hold during an age when models were small,4 out of necessity, and we can refer to [6]
to see what could be achieved, may no longer be of any importance. And some actions are clearly at
odds with Bayesian thinking. This is not to denigrate, but to point out that when models are small,
one will necessarily behave differently compared to a situation where large models are available.
Let us expand on this point. I am trying to learn about something and have some current knowl-
edge. My current knowledge is encapsulated in a small model. I learn through further observation
that this small model is wrong or misguided. I must change it, whether the foundations for the
inference I am undertaking allow me to do this or not. The current knowledge (knowledge prior to
data)isbeingchangedbythedata.Thiscannotmakeanysense.Suchknowledgeshouldbeupdated,
not changed then updated, by the data, and a framework should be established from the start that
permits revisions of sufficiently large magnitude and variety. Large models, which are becoming
increasingly better understood, can meet these needs.
With small models it must be expected to change them, to consider a range of possible models,
or select a model post-data. It is necessary whether one accepts that this ‘destroys’ some aspect of
Bayes or not. My opinion is that a methodology which relies on such strategies is not Bayes; it is
something possibly close to Bayes, but lacks motivation. It is ad hoc. There is no single well-defined
representation of current knowledge. And this current knowledge must be about something that
4 For the purposes of this article, we can define a small model as one for which a number of assumptions
about the data, e.g. symmetric, unimodal, have been made, and for which there is no external supporting
evidence; a check of such assumptions would essentially be post-data.

250
S. G. Walker
exists. With a small model the only object that exists that I would be interested in learning about
is the parameter value which takes my small model closest (in some sense) to the correct model.5
I should be able to learn about this parameter because I am observing samples from this correct
model. With this outlook there is no assertion that the small model is correct; one is simply trying
to find the ‘best parameter’ one can from it. The question then is whether Bayes can be used in this
scenario.
Entertaining a number of small models, trying to find one that is adequate, or even a perfect fit,
is not satisfactory. There is, on the other hand, a proper Bayes approach of properly quantifying
uncertainty with a large model. Indeed, if all the uncertainty has been adequately expressed, it
must be an internal contradiction to then check that the data and the expressed uncertainty are
compatible.
So small models could lead to undesirable issues; large models circumvent these issues and allow
Bayes to be implemented in its purest form:
uncertainty →preliminary knowledge about the uncertainty →
observation →update knowledge
.
Bayes provides the means to do this when knowledge is represented in probabilistic form.
13.1.1 Dependent models
I want to introduce Bayesian thinking by talking about the creation of dependence. I witness an
observationandwanttousethistopredictanotheroutcome,yettobeseen.Inprobabilitylanguage,
it is necessary to construct a dependence between the two outcomes; one seen, the other yet to be
seen. This in no way implies that the outcome of one actually depends on the other; i.e. there is a
physical dependence. Consider an example. An observer is watching a time trial in a cycling event.
They have no idea what times to expect, and if it were possible they would construct a distribution
describing the time to finish. The first rider finishes and provides a time. This provides information
to the observer and they are able to revise the distribution of times. This new distribution must
depend on the first outcome for it to be a revised distribution. And no one would pretend in
reality that the times of the first and second rider physically depend on each other. The times are
independent, and there is no reason not to assume that they are identically distributed.
To make this illustration more precise, it is quite feasible to think of a process by which person
A is generating i.i.d outcomes from some machine and inviting person B to get at the distribution
from which the observations arise. Persons A and B clearly have different knowledge and person B,
needing to learn about where the samples are coming from, would be willing to set up a probability
model in which there is a dependence structure between the observations. After every sample a
new guess is made as to the distribution from which the observations arise. This must depend on
the previous outcomes. There is no long-term principle involved here. This strategy can be invoked
no matter how large the sample of outcomes is given. For any finite sample it cannot do any harm
to assume that there is an underlying density generating the observations. Nor does it make any
contribution to assume such a density does not exist. The key really being the notion that the order
of the samples has no bearing on what the guess looks like after seeing all the observations.
The upshot is that person B creates a probability model which has a dependence structure
connecting the outcomes so that learning can take place. The model is wrong, but it is very useful;
5 This idea will be developed later. I am also aware that the notion of a correct model is something with
which not all are comfortable. However, for now, I merely mention that without the notion of a correct model
it is far from clear what a Bayesian is even trying to learn about.

Bayesian nonparametrics
251
[7] expressed a similar sentiment but in a different context. For me this is the essence of Bayes:
creating dependent probabilistic models so that learning can take place. Without the dependence
there is no learning. But what are these learning models and how are they comprised? While person
B might have a sequence of guesses about where the outcomes are coming from, ultimately they do
not believe the order of observation should have any impact on the model; so the order does not
matter. When models are dependent and the order does not matter then the only selection is a
Bayesian model ([11]; [22]).
In summary, therefore, if there is no physical dependence between observations and the order
of observations is not relevant, then treating the data as i.i.d is appropriate. The Bayesian model
creates variables out of the data and makes them dependent as well, for a good reason. To do this,
there is no need to assume the data exchangeable. Neither is there any need to estimate properties
of a model, such as consistency, using the notion of the data as coming from the model. (See for
example [12], in the case of consistency.) This is unrealistic and would easily suggest the Bayesian
model is better than it really is. However, to study the model assuming the observations are i.i.d is
commonly termed the frequentist study of a Bayesian model. This is a misunderstanding.
13.1.2 Learning model
TheBayesianmodelisaboutlearning.Butlearningaboutwhat?Howdoesitstart?Oneaspectofthe
learning is a sequence of guesses as to where the next outcome is coming from. So let (X1, . . . , Xn)
denote the sample. The sequence of guesses would be denoted by
mn(x|x1, . . . , xn−1)
for n = 1, 2, . . . The conditional notation is being used to emphasize that the guess depends on
what has been seen to date. Given the symmetry, we can (as will be expanded on later) write the
predictive guess as
mn(x|x1, . . . , xn−1) =

f(x) 	(df|x1, . . . , xn−1)
where 	(df|x1, . . . , xn) is known as the posterior distribution and given by
	(df|x1, . . . , xn) =
	n
i=1 f(xi) 	(df)

 	n
i=1 f(xi) 	(df)
The starting point uses the prior distribution 	(df); i.e.
m1(x) =

f(x) 	(df)
and so one sees that the only change as the observations come in is that 	 gets updated. So we are
learning about something called f. The only interpretation for this f is that it is the density which
is generating the observations. Then it is quite clear that 	(df) would at least represent what is
known about the density generating the (Xi) based on evidence which does not include the (Xi).
So 	(df|X1, . . . , Xn) must represent what is known about f with the evidence that yielded
	(df) along with the evidence that is provided by (Xi)n
i=1. And this is Bayes. It is a simple structure
and the thinking is straightforward. It is an explicit and mathematical (using probability) evaluation
of a real learning process.

252
S. G. Walker
Symmetry and the de Finetti representation [11] would imply Bayes. It is a misunderstanding
that it is only possible to use the representation if one states the (Xi) are coming from the model
itself. Symmetry holds for guesses as well; the guesses need to be symmetric and so there is a
representation theorem for the guesses. If there is a representation theorem then there is Bayes.
It would seem that Bayes is a more robust learning mechanism than previously given credit. This
will be discussed further in Section 13.3. But at the outset, there are a couple of issues that must be
dealt with sequentially:
(i) What is 	(df) and how is it constructed?
(ii) What happens when n →∞?
13.2 Constructing the prior
Bayesian topics which have received prominence in the literature are due to the problems in how
to deal with (i). An eagerness to make 	(df) over simplistic leads to Bayesian model selection,
Bayesian model checking, Bayes factors, and other ad hoc ideas. This issue is not about how to
distribute mass within 	, which will be considered later, but rather how to get at the support of 	,
denoted by . The support requires a proper definition in terms of distances, but for now we can
just leave it as the densities 	 can generate. The choice of  can range from something very small,
almost to a point mass at a specific density, to an  which includes all possible densities.
What is the biggest problem in this setup? It must be of the following type: I construct 	(df)
and this means that 	(f ∈) = 1 for some set of densities . So it has been stated that what is
known without knowledge of the data is that the set of densities which could be generating the data
lies in . If that is what is known then that is it. How can one measure this certainty in practice?
What is the test? The test is that the model, namely  is not checked off with the data. It is clearly
an internal contradiction, and a demonstration of irrational behaviour, to specify  and then check
it. Checking it indicates that there is more uncertainty around than is being acknowledged by the
use of . If this is the case, then  needs to be enlarged to appreciate the starting uncertainty
properly.
But we cannot discount an error in judgement:  has been chosen and it becomes evident that
after seeing a large enough sequence of the (Xi), that f /∈. What now? Is this the point where we
need to throw away the simplicity and elegance of the Bayesian learning machine to accommodate
a ‘Bayesian’ who has made an error in judgement? If, for example,  is too small then it could be
quite possible that the discovery f /∈ is found.
The way to deal rigorously with the problem of an overly small  is not to have it in the first
instance, and to make it as large as needed from the onset, even if this means making it as large as
one can manage. Of course this refers to  rather than the number of parameters in the model.
There are then subsequently no concerns about  being too small. This is the simple yet powerful
message of Bayesian nonparametrics.
The typical Bayesian outlook is to start small and increase a model as and when it is deemed
necessary, heading to something of an optimal fitting model. But as we have described earlier, this
has all sorts of associated problems. Parsimony is an often cited objective; roughly speaking, if two
models fit well, pick the one with the smallest number of parameters. To me, this is simply a recipe
for underestimating uncertainty. It is an objective in direct conflict with Bayesian learning. I fail
to see how such a perfect Bayesian model could have been obtained in a purely Bayesian way. To
reiterate  is what one is looking for, which is a set of densities with particular properties or the set
of all densities. The aim for parsimony is to put all the mass on  with the minimal of parameters.
This is the critical difference of Bayes; parsimony with , rather than the data. Because Bayes starts

Bayesian nonparametrics
253
with fixed knowledge, which is , the data rearranges the mass in , the data are not to change
. Thus we need to describe how to construct 	(df) so that  is as large as needed or as large
as possible. This is not about adding more and more parameters into a model; rather it is about
achieving a large  with the minimum of fuss.
13.2.1 A popular prior
What can we get for densities on the real line? The foundational model is the mixture of Dirichlet
process model [31] and is constructed as
f(y) =

k(y|θ) dP(θ)
Here P is a mixing distribution and the original and remaining popular choice is the Dirichlet
process [16].6 This prior generates discrete random distribution functions and we will look at it in
somedetail.Tofixideas,assumeθ = (μ, λ)whereμdenotesthemeanofanormaldistributionand
σ 2 = λ−1 is the corresponding variance. So k denotes the normal density function and P denotes
a distribution function, and this is of the type
P =
∞

j=1
wj δθj
where the (wj) are weights which sum to 1; the (θj) are a set of values from (−∞, +∞) × (0, ∞);
and δθ denotes the measure with a point mass of 1 at θ. The prior distribution is assigned to (wj, θj)
and it is usual to allow the (θj) to have independent priors with the same distribution and the
weights to have a stickbreaking prior construction, so that
w1 = v1
and for
j > 1, wj = vj

l<j
(1 −vl)
andthe(vj)areindependentwithbetadistributions.Formoreonthistypeofconstruction,see[43]
and [24]. Hence, f(y) is an infinite mixture model of normal distributions. Any density function on
the real line can be arbitrarily well approximated, with respect to the L1 metric for example, by such
a mixture of normal density functions.
Clearly then, with such a prior, it is possible to avoid the need to undertake anything like model
selection. But there is still work to be done. The most notable is the problem of the choice of prior
for (vj, θj), which, if not careful, could have too influential a role in the learning process. But this
problem of the influence of where the mass is placed in  is of course not unique to nonparametric
models. To see how this issue can work in a nonparametric model we need go no further than
the Dirichlet process. Recall the stickbreaking process whereby the (vj) are independent beta(1, c)
variables, for some c > 0. If the (θj) are from the distribution function G, then for any set A we have
E(P|X1, . . . , Xn) = c G + n Pn
c + n
6 Typically, Bayesian nonparametric models resist in defining 	(df) as a probability measure but rather
describe how a random f can be taken from 	(df).

254
S. G. Walker
where Pn is the empirical distribution function. By appropriate choices of c, this posterior
expectation can clearly take any value from the empirical distribution to the prior expecta-
tion. Is this a cause for concern? But c and G have fairly straightforward roles from previous
results: so
E[P(A)] = G(A)
and
Var[P(A)] = G(A) G(Ac)
c + 1
foranysetA,andwhereAc isthecomplementsetofA.Buttherearealsoanumberofideastospecify
c based on the evaluation of Wj = 
l>j wl in terms of expectations and probabilities of outcomes.
So we can easily make use of the fact that
E(Wj) =
j
l=1
(1 −E(vl)) =

c
1 + c
j
There will then always be a way, however large the model, to be able to use knowledge about the
problem to specify key parameters in the prior, usually based on prior expectations of quantities.
Modern applications of the mixture of Dirichlet process model often assign a hyper-prior to c so as
to mitigate the strength of any specific prior choices; see [15].
There are by now many ideas for estimating the model above using sampling based approaches
which construct Markov chains with suitable stationary distributions. Such methods started with
[14] and other ideas include [32]; [33]; [36]; [47]; [39]; and [25].
But for the Dirichlet process as well as other similar models and their use in mixture models,
three issues need to be addressed. These are: identifiability and clustering; the use of the normal
distribution as a kernel; and the infinite nature of the Dirichlet process.
13.2.2 Identifiability and clustering
For any density f there are, in the popular mixture of Dirichlet process model, many ways to con-
struct the f. The basic idea is that we can achieve mass at a particular location, say θ, by having one
of the θj at this location and the appropriate weight wj. But we could also achieve this by largely
ignoring the weights, making them simple, and we can achieve a certain weight at θ by placing
an appropriate number of the (θj) close to θ. The Dirichlet process, and hence the mixture of
Dirichlet process model, is not identifiable. When it comes to estimating the density f this may not
beperceivedasaproblem,butitdoesmeanthatthenumberofmixtureswillbeoverestimatedwhen
the model uses the latter plan to construct f; see the illustrations in [47]. The problem becomes
more acute when mixture models are used for complex data structures such as regression and time
series models.
Itisfarfromeasytoresolvethisproblem.Ifoneadoptssimpleweightssuchasgeometricweights,
attractive since one removes a layer of parameters, namely the (wj), then the support  is not
diminished; see [38]. However, the estimate of the number of mixtures is not possible. An idea
for modifying the model to provide both density estimation and to estimate components is now
discussed which requires a change in kernel and model.
13.2.3 The choice of kernel
If there are mixtures in the model then it must be of interest to identify the mixtures. If the
choice of kernel is the normal density function then one can hope to identify the normal com-

Bayesian nonparametrics
255
ponents which make up the density. But this does not answer the question of number of clusters
unless one has defined a cluster by a group of the data being modelled adequately by a normal
density.
On the other hand, a unimodal density can be used to model a cluster adequately. One might
believe that a bimodal density and higher number of modes model more than one cluster. Cer-
tainly this can be safely assumed in the absence of information beyond the data. Thus it becomes
important, or at least of interest, to be able to model mixtures where the only assumption on each
component is one of unimodality. However, in the context of mixture of Dirichlet process models,
this is a difficult task. The components will already be nonparametric and to mix over these using a
Dirichlet process would lead to unfathomable complications.
13.2.4 How to include infinity?
A solution to this problem is to use a variation on the nonparametric mixture model that involves
modelling the number of components explicitly, as in [40]. So for every finite k ≥1 a finite model
is constructed as
fk(x) =
k

j=1
wjk pj(y)
where the (pj) are the components of the model. And to complete the model there would be a prior
assigned to k, and each pj would be assigned a prior which generated unimodal densities. One way
to do this is via a mixture of uniform distributions. That is,
p(y) =
∞

l=1
wl Un(y| −θl, +θl)
where the (θl) are positive. This would generate symmetric unimodal densities, and to incorporate
skewness a number of ideas are possible. [42] use an idea from [17] that involves using a uniform
component of the type
Un

y| −e−λθl, +θleλ
Hence,
fk(y) =
k

j=1
∞

l=1
wjk wlj Un(y| −e−λjθlj, +eλjθlj),
where
k

j=1
wjk = 1
and
∞

l=1
wlj = 1
Now k has the very real interpretation of being the number of clusters that can be modelled using
unimodal densities.

256
S. G. Walker
13.3 What do we want as n grows?
We also consider another point which has to do with consistency. What happens to the posterior
distributionsasthesamplesizetendstoinfinity?Thisistheusualquestion.Wecanlookatthisfrom
a slightly different perspective. My Bayesian model is learning about something, and so I identify
an object to learn about. I collect observations from a source and, using the Bayesian learning
machine, I think that, indeed, I am learning about this object. But how do I verify that this learning,
via posterior distributions, is actually taking place? I only see this issue being resolved through an
asymptotic study of the sequence of posterior distributions.
Before discussing the mathematics of consistency, it would be prudent to discuss what deter-
mines the asymptotic performance of the Bayesian model. We have already determined that the
Bayesian model is wrong in the sense that no stochastic dependence of the type arising from
exchangeability actually connects the observations. The stochastic dependence is used to construct
a learning machine. If there is no physical dependence between observations, and they come from
some identifiable similar source (such as the track cycling times described earlier), so the order of
the sequence of observations does not ultimately matter, then the outcomes (once assigned to be
randomvariables)mustbetreatedasbeingi.i.dfromsomefixedbutunknowndistributionfunction,
commonly written in the literature as F0.
Briefly,ifoneisinterestedinψ(X)andX ∼F0,thenonestudiesprobabilitiessuchasP(ψ(X) ∈
A) = F0(ψ−1(A)). If there is a possibly infinite or arbitrarily large number of such X there is no
sudden switch of the idea here to think about. Hence, the study of a Bayesian model based on the
notion of the (X1, . . . , Xn) being i.i.d from Fn
0, for any n, is not a frequentist setup; it is not even a
Bayesian setup. It is a study of a Bayesian model with the appropriate assumption of how the data
arrive.
SowhywouldaBayesianintroduceadependencestructuretotheoutcomeswheninrealitythere
is none? There is a good reason to do this. It does not then mean a Bayesian must insist the data
become dependent or assume they are dependent. The model creates a dependence for the reason
we now elaborate on further.
A Bayesian is willing to provide a sequence of guesses as to where the next outcome is coming
from. If this sequence is static, i.e. it is m(xn) for all n for some density function m(x), then there
seems little point in witnessing outcomes. So if m0(x1) is the best guess for the density of x1 then
it would change to m1(x2) once x1 has been seen. The outcome must provide information which
is helpful to the next best guess. So m1 ̸= m0 and to highlight the point that it depends on x1 we
can write m1(x2|x1). Thus, since we have seen (x1, . . . , xn−1), the best guess for xn would be of
the type mn−1(xn|x1, . . . , xn−1).
But these guesses need some structure. The rule, namely the order does not matter, must
result in
m(x1, . . . , xn) =
n

i=1
mi−1(xi|x1, . . . , xi−1)
being symmetric, in the sense that for any permutation σ on the integers (1, . . . , n),
m(xσ(1), . . . , xσ(n)) = m(x1, . . . , xn)
for any n ≥2.
The consequences of the above are well known. To reiterate, the (xi) are not dependent; the
best guesses from the Bayesian about future outcomes force a model which attracts dependencies,
given the desire to learn from experience. So m(x1, . . . , xn) can be viewed as the best guess for the

Bayesian nonparametrics
257
first n outcomes taken one-by-one. It must be symmetric and therefore the best guess model must
look like
m(x1, . . . , xn) =

n

i=1
f(xi) 	(df)
for some probability measure on a suitable and appropriate space of density functions.
This would be the model and the next outcome would be guessed as coming from
mn(xn+1|x1, . . . , xn) = m(x1, . . . , xn+1)
m(x1, . . . , xn)
and which is given by
mn(xn+1|x1, . . . , xn) =

f(xn+1) 	(df|x1, . . . , xn)
where
	(df|x1, . . . , xn) =
	n
i=1 f(xi) 	(df)

 	n
i=1 f(xi) 	(df)
All that has changed due to the observations (x1, . . . , xn) is that 	(df) has been updated into
	(df|x1, . . . , xn).
Hence, there is an important part to be played by 	(df). So what exactly is it? This much is clear:
it is expressing ideas about the location of a density function, in the sense that P(f ∈A) = 	(A)
and so on as the data arrive and 	(df) is updated. It is also clear that f refers to the density or
distribution function generating the data.
Now let us expand on 	(df) a bit more. The sequence of guesses described in Section 13.1.2 and
immediately above are precisely that, namely guesses as to the density generating the next piece
of data; there is no certainty or the need for these guesses to actually ever coincide with the true
density. For if m0(x) is to be the first best guess at the true density, which is what it is, then this tells
us exactly what thought processes need to be adopted in order to construct 	(df). The best f, call
it f ∗, once  has been decided, is the one which minimizes the Kullback–Leibler divergence [26]
betweenf andf0.7 Inthiscase,thebest	(df)istheonewithpointmassoneatf ∗.Fromthiswecan
see that one should be expressing beliefs about the location of f ∗when one is constructing 	(df).
Thismustbethecasetoensurethatm0 isthebestguess.Thus(m0, 	)formapair;m0 istobeabest
guessforthedensityf0 and,toattainthis,itmustbethat	 isconstructedwithf ∗asthetarget,since
the best 	 would be a point mass at f ∗. Of course, f ∗is a real density and therefore it is possible
to write probability statements about its location. We are now discussing ideas where we are not
differentiating between f0 ∈ or f0 /∈. If f0 ∈ then f ∗= f0. The idea of thinking in terms of
best guesses suggests that Bayes works either way, not through the Bayes theorem directly, but via
de Finetti’s representation theorem. Bayesians are asked to express uncertainty about densities, or
parameters indexing density functions. But unless one has one of them as a target in mind, then
probabilities such as 	(f ∈A) make no sense. For what is f when, as is the norm, f0 /∈? The
target is f ∗. This is what needs to be learnt about. Hence, asymptotic studies need to establish that
7 Other metrics or divergences are possible but the mathematics and the unique role the Kullback–Leibler
divergence has with Bayesian theory make it the most suitable.

258
S. G. Walker
the sequence of posterior distributions move to f ∗. In the literature this is typically done in two
parts; the first to assume f0 ∈ and the second to assume f0 /∈.
Formally, the statement is: if f(x|θ) is a model for f0(x) and π(θ) a prior for θ, then the update
π(θ|X = x) ∝f(x|θ) π(θ), with X ∼F0, is an appropriate update when interest is in learning
about the value which minimizes U(θ) = −

log f(x|θ) F0(dx). And this learning takes the pro-
cess to θ∗which minimizes U(θ); see, for example, [3] and [8].
13.4 Non-i.i.d data
Our approach is to construct nonparametric models from parametric models in the same way as in
thei.i.dcase.So,wetakeajointdensity,asitwouldariseinthenon-i.i.dcase,andconstructamixture
model from it. For example, if we have a parametric regression model with y as the dependent
variable and x as the independent variable, then we write a parametric joint density for (y, x) as
Kθ(y, x).
The nonparametric version is then given by
f(y, x) =
∞

j=1
wj Kθj(y, x)
from which the regression model is available as
f(y|x) =
∞
j=1 wj Kθj(y, x)
∞
j=1 wj Kθj(x) ,
where Kθ(x) is the marginal for x from the joint Kθ(y, x). This, and a similar idea for time series,
we believe leads to a well motivated class of nonparametric non-i.i.d models.
13.4.1 Time series
Since the work in [31], who introduced the mixture of Dirichlet process mixture model, and the
advent of Bayesian posterior inference via simulation techniques (see [14], and [45]), Bayesian
nonparametric methods have developed at a rapid pace and the Dirichlet mixture model is
one of the most popular among these methods. The models have now moved away from the
standard setup, namely i.i.d observations, to cover more complex data structures involving regres-
sion data. There are numerous works and papers over the last decade and it is therefore conve-
nient to cite the book of [23] which contains references and discussions of many nonparametric
models.
To set the notation, for the i.i.d case, assume (y1, . . . , yn) are the data. The mixture of Dirichlet
process model takes the form
f(y) =

k(y|θ) dP(θ)
where k(·|θ) is a density for all θ ∈ and P is a distribution function on . If the prior for P is
assigned as a Dirichlet process then, according to [43] we can construct

Bayesian nonparametrics
259
P =
∞

j=1
wj δθj
where the weights form a stickbreaking sequence and the (θj) are i.i.d from density function g(θ).
And so, specifically for i.i.d (vj) from a beta(1, c) density, for some c > 0, w1 = v1 and, for j > 1,
wj = vj
	
l<j(1 −vl). Other stickbreaking constructions are allowed based on alternative beta
distributions; see [24] for conditions.
Thus, the density model for the data arises as
f(y) =
∞

j=1
wj k(y|θj)
which is an infinite mixture model; see [18] for a recent review of MCMC methods to implement
these types of models.
The mixture of Dirichlet process model is now being regularly employed in regression problems.
The idea now is to model dependent variable y on regression variable x, as
f(y|x) =

k(y|θ) dPx(θ)
Here Px(θ) is similar in construction to P(θ), but the weights and locations can both depend on x.
That is
Px =
∞

j=1
wj(x) δθj(x)
Exactly how to define the (wj(x), θj(x)) suitably is an interesting problem and a number of attempts
have been tried; see [13] for a review. To some extent the complexity of how to construct these key
functions over the x–space can be avoided by modelling the joint density as a mixture model:
f(y, x) =

k(y, x|θ) dP(θ)
But in this case the correct regression model is
f(y|x) = f(y, x)
f(x) =

k(y, x|θ) dP(θ)

k(x|θ) dP(θ)
Such a model has not yet been entertained due to the difficulty of dealing with the denominator.
Perhaps one area that has not been fully exploited from a Bayesian nonparametric perspective
and which involves the Dirichlet mixture model is time series data. For ease of exposition here we
will only consider first-order time series data and models. The plan then is to construct a transition
density f(y|x) which would suitably capture the transition dynamics and then study the posterior
distribution based on the likelihood function
n

i=1
f(yi|yi−1).

260
S. G. Walker
A prior is assigned to the transition density and will be written as 	(df). This will be based on the
Dirichlet process mixture model.
The modelling of first-order time series data is also a vast area in the literature. Our aim is to
use a Bayes nonparametric mixture model to construct f(·|·); so, specifically, as with the regression
setting,
f(y|x) =

k(y|x, θ) dPx(θ),
where k(y|x, θ) is a density for every θ ∈ and Px is a probability measure that depends on x. This
type of model will be able to capture a wide class of transition functions, and the infinite-dimen-
sional aspect to the model means that any surprise or change that arises in the future will be taken
into account.
Let us start with a parametric first-order stationary time series model k(y, x|θ) which has identi-
cal marginals;
f(x|θ) =

k(y, x|θ) dy
and
f(y|θ) =

k(y, x|θ) dx.
Also, f(y|θ) is the stationary density:
f(y|θ) =

k(y|x, θ) f(x|θ) dx.
This is now ready to be extended to the nonparametric setting by taking
k(y, x) =

k(y, x|θ) dP(θ) =
∞

j=1
wj k(y, x|θj).
We can obtain the nonparametric model using the following specification for Px(θ): the stationary
density is
f(x) =

k(x|θ) dP(θ)
and the transition density is
f(y|x) =

k(y|x, θ) k(x|θ) dP(θ)

k(x|θ) dP(θ)
so
dPx(θ) =
k(x|θ) dP(θ)

k(x|θ) dP(θ).
Equivalently,
wj(x) =
wj k(x|θj)
∞
j=1 wj k(x|θj).

Bayesian nonparametrics
261
Thismodeldiffersfromrecentapproachesthathaveappearedintheliterature;seeforexample[34].
These authors took the joint density f(y, x) as
f(y, x) =

p(x) p(y) 	(dp)
where 	(dp) is a Bayesian nonparametric prior; specifically, [34] took it to be based on the Gaus-
sian process prior of [30] and [28], [29]. This model results in a nonparametric transition density
but only has a parametric stationary density, given by
f(x) =

p(x) 	(dp).
Ontheotherhandthetransitiondensityisthepredictivedensityfunctiongivenasingleobservation
from the Bayesian model, i.e.
f(y|x) =

p(y) 	(dp|x).
This can be nonparametric since the 	(dp|x) will be a probability measure that can accommo-
date two functions; one being the mean density f(x) and another to do with the variance pro-
cess, labelled τ(x), and which will be based on

p2(x)	(dp). Then f(y|x) will be a function of
(f(x), τ(x)). The current work is about obtaining nonparametric forms for both the stationary
density and the transition density.
For the new model described above, we will need to estimate the parameters of k and P. To make
this concrete we will present a particular model. Assume k(x|θ, σ 2) to be normal with mean θ and
variance σ 2 and let
P(θ) =
∞

j=1
wj δθj(θ).
We will allow the means to change with component but keep the variance the same across compo-
nents. Here the weights (wj) sum to one and the (θj) are real numbers. We will then be interested
in estimating ((wj, θj), σ). The prior for λ = σ −2 will be denoted π(λ).
Now it can be seen that the likelihood function based on a sample (y1, . . . , yn) is given by
n

i=1
∞
j=1 wj k(yi|yi−1, θj, λ) k(yi−1|θj, λ)
∞
j=1 wj k(yi−1|θj, λ)
.
This looks an insurmountable likelihood to deal with. Our aim then is to show how to undertake
Bayesian inference for this model using well designed latent variables which result in a viable latent
model.
The numerator has a common and standard technique for simplification and this is to introduce
the allocation variables (di) which lead to the latent model
n

i=1
wdi k(yi|yi−1, θdi, λ) k(yi−1|θdi, λ)
∞
j=1 wj k(yi−1|θj, λ)
.

262
S. G. Walker
Summing over the independent (di) returns the original likelihood. The issue now is to deal with
the denominator.
First we can remove the λ from each k; so define
m(y|θ, λ) = exp

−1
2λ(y −θ)2
.
Now we write the latent likelihood model as
λn/2
n

i=1
wdi m(yi|yi−1, θdi, λ) m(yi−1|θdi, λ)
∞
j=1 wj m(yi−1|θj, λ)
.
We now focus on the denominator and the term
1
∞
j=1 wj m(y|θj, λ).
Thishasbeenwrittenwithagenericy,anditissimplertoconsiderthisfirst,andthenputtheproduct
back together later.
Since the denominator is now between (0, 1) we can write it as
∞

k=0
⎡
⎣
∞

j=1
wj

1 −m(y|θj, λ)

⎤
⎦
k
.
This suggests we should introduce the latent variable k yielding the latent model
⎡
⎣
∞

j=1
wj

1 −m(y|θj, λ)

⎤
⎦
k
.
Finally, we can introduce the latent variables (zl : l = 1, . . . , k) and the latent model
k

l=1
wzl

1 −m

y|θzl, λ

.
Putting this with the latent model for the numerator, and recalling we have a ki for each i, the final
latent model is given by:
λn/2
n

i=1
wdik

yi|yi−1, θdi, λ

k

yi−1|θdi, λ

ki

l=1
wzil

1 −m

yi−1|θzil, λ

.
It is easy to see that summing over all the latent variables ((di), (ki), (zil)) over their respective
spaces returns the original likelihood.
Wearenowinapositionwherethelatentmodelissimilartostandardlatentmodelsformixtureof
Dirichlet process models; see [25]. The form above suggests that there is a solution to the problem.
Hence, we start to describe the sampling MCMC algorithm. As it stands, if we attempted to sample
the di or the zil we would face the problem that they are to be taken from the positive integers, and
it would not be possible to evaluate all the relevant probabilities. We can therefore truncate this

Bayesian nonparametrics
263
choice using ideas from [25] whereby we introduce latent variables δi and ζi which are combined
with the latent model via
1

δi < e−ξdi

eξdi
and
1

ζil < e−ξzil

eξzil.
Here ξ > 0 and its value is not a modelling issue. A discussion on its choice and its role is given in
[25]. Therefore,
P(di = j| · · · ) ∝eξj wj k(yi|yi−1, θj, λ) k(yi−1|θj, λ) 1(1 ≤j ≤Ni)
where Ni = ⌊−ξ−1 log δi⌋. Also,
P(zil = j| · · · ) ∝eξj wj

1 −m(yi−1|θj, λ)

1(1 ≤j ≤Nil)
where Nil = ⌊−ξ−1 log ζil⌋. The maximum value N = max{Ni, Nil} will then tell us exactly how
many of the (θj, wj) need to be sampled at each iteration of the MCMC algorithm. The weights are
easy to sample and the conditional for each vj is a straightforward extension of the usual mixture of
Dirichlet process model, and is given by
vj = beta
⎛
⎝1 +
n

i=1
1(di = j) +
n,ki

i=1,l=1
1(zil = j), c +
n

i=1
1(di > j) +
n,ki

i=1,l=1
1(zil > j)
⎞
⎠
These (vj) can then be transformed to get the (wj).
The (θj) are best sampled by introducing a latent variable uil for each i and l. This enters the
model via
1(uil < 1 −m(yi−1|θzil, λ)).
These are standard slice random variables; see [9]. Hence,
p(θj| · · · ) ∝π(θj)

di=j
m(yi|yi−1, θj, λ) m(yi−1|θj, λ)

zil=j

m(yi−1|θj, λ) < 1 −uil

.
The conditional for λ is given by
p(λ| · · · ) ∝λn/2
n

i=1
m(yi|yi−1, θdi, λ) m(yi−1|θdi, λ)
ki

l=1

m(yi−1|θzil, λ) < 1 −uil

.
Finally, we need to update each ki. We do this independently and so we consider a generic k with
relevant model part given by
k

l=1
wzl ψzl
where we have written ψzl = 1 −m(y|θzl, λ).

264
S. G. Walker
We deal with this apparent changing dimension part of the model using ideas in [20], which is
based on the reversible jump MCMC methodology of [21]. If we write
p(k, z1, . . . , zk) ∝
k

l=1
wzl ψzl
then we extend the model to
p(k, z1, . . . , zk, zk+1, . . .) ∝
⎧
⎨
⎩
k

l=1
wzl ψzl
⎫
⎬
⎭
∞

l=k+1
wzl.
From k we can propose a move to k + 1 with probability 1
2, or to k −1 with probability 1
2. The
probability of accepting a move to k + 1 is given by
min

1, ψzk+1

where zk+1 has been sampled from the weights (wj). On the other hand, the probability of accept-
ing a move to k −1 is given by
min

1, ψ−1
zk

.
13.4.2 Regression models
There has been a significant amount of recent research on Bayesian nonparametric regression mod-
els. This has primarily focused on developing models of the form
f(y|x) =
∞
j=1 wj(x) K(y|x, θj(x))
where K(y|x, θ) is a chosen parametric density function. The wj(x) are mixture weights that
sum to 1 at every value of the covariate vector x ∈X, and with a prior distribution on weights
{wj(x)}j=1,2,..., and atoms {θj(x)}j=1,2,..., which are an infinite collection of processes indexed by
X. Our position is that it is a very difficult task to specify these components; i.e. the wj(x) and
K(y|x, θ). There are limitless possibilities and over-fitting and un-identifiability are serious issues.
It is argued that some sort of guidance is needed in order to justify certain specifications.
An attractively simpler and intuitive approach to Bayesian nonparametric regression has been
proposed by [35]. The idea is to specify a Dirichlet Process mixture model for the joint density
f(y, x) with mixture weights and atoms independent of x. This would lead to a standard infinite
mixture model, treating the (yi, xi) as i.i.d observations. This would not be a controversial choice
for a model. In this case one would employ the likelihood function

i f(yi, xi)
as used by [35].

Bayesian nonparametrics
265
However, the aim is regression rather than modelling the (y, x) and hence the appropriate likeli-
hood function is given by

i f(yi, xi)/f(xi) =

i f(yi|xi).
To see this we simply note that there are two likelihood functions here and they are not the same.
It is also clear that for regression purposes we are interested in the conditional density f(y|x), and it
is this that should form the basis of the likelihood function.
The reason why such a simple, motivated and useful regression model has not appeared in the
literature is due to the fact that the posterior distribution has an intractable normalizing constant,
i.e. 	
i f(xi). Inference is complicated by the need to evaluate the uncomputable integrals in this
constant. It is possible to avoid this complication by proposing a modified prior distribution such
that, when combined with the correct likelihood, it yields a posterior distribution that is identical
to the posterior of the original model.
The aim here is to show that it is possible to use the correct likelihood for regression by showing
how to deal with the problem of the normalizing constant. This uses ideas recently introduced in
[48]. The details of the model and the MCMC used to estimate the model are provided in the
companion article to this paper: [49].
13.5 Consistency
We will first discuss this issue assuming i.i.d observations. If we are operating with densities, then
to confirm that Bayesian learning is about the true sampling density, we need to show that the
posterior mass accumulates in suitable neighbourhoods about f0. The appropriate metric to define
neighbourhoods is the Hellinger distance, since the mathematics is amenable to this distance.
The Hellinger distance between densities f1 and f2 is defined as
dH(f1, f2) =
 7
f1 −
7
f2
21/2
We will also use d(f1, f2) = 1
2dH(f1, f2)2 which is bounded by 1, and specifically
d(f1, f2) = 1 −
 7
f1 f2
The aim then is to find conditions on the prior 	 which ensure that
	n(Aϵ) = 	(Aϵ|X1, . . . , Xn) =

Aϵ Rn(f) 	(df)

Rn(f) 	(df) →0 a.s.
for all ϵ > 0, where
Rn(f) =
n

i=1
f(Xi)/f0(Xi)
and
Aϵ = {f : dH(f1, f2) > ϵ}

266
S. G. Walker
It was first shown in [44] that if the prior puts positive mass on all Kullback–Leibler neighbour-
hoods of f0, then the posterior is consistent with respect to the weak topology. This result does
not extend to neighbourhoods defined by the Hellinger metric since a counterexample is pro-
vided in [1]. The condition found by [51] deals with the denominator In =

Rn(f) 	(df). If
	{f : dK(f0, f) < δ} > 0 for all δ > 0, where dK(f, g) =

f log(f/g) is the Kullback–Leibler
divergence, then In > e−nc a.s. for all large n for any c > 0.
Toestablishstrongconsistency,aconditionisrequiredforthenumeratorLn =

Aϵ Rn(f) 	(df)
to ensure that Ln < e−nd a.s. for all large n for some d > 0. We can then establish posterior con-
sistency. Let us first describe the popular approaches. The basic idea is to find a sieve with certain
properties. If the sieve is denoted Fn then there are two conditions:
1. log N(Fn, dH, δ) < nd for all large n, for some d > 0 for all δ > 0. Here N(A, d, δ) denotes
the number of balls of size δ with respect to metric d to cover set A.
2. 	(Fcn) < e−nb for all large n for some b > 0.
A proof of this is provided by [19]. [2] employs a slightly different version of condition 1. which uses
a different measure of entropy. Hence, a specialist task of ‘ball counting’ is required. When counting
balls is tricky, and imprecise bounds are used in the counting, then one can anticipate that stronger
conditions on 	 are suggested than are actually required.
An approach that avoids the need to count balls or work directly with entropies is as follows:
Thereisasieveanditdoessatisfycondition1.Countingisobviated,becausethesieveisconstructed
using the prior itself. So define the sieve
Fn =

Aj : 	(Aj) > e−nb
for some b > 0, where the (Aj) are a partition of the set of densities such that two elements in the
same Aj are no more than a Hellinger distance δ apart.
This sieve does the counting automatically; specifically, the 	 does the counting, since
1 =

j
	(Aj) >

Aj∈Fn
	(Aj) > |Fn| e−nb
and so |Fn| < enb as required. Thus there is only the need to establish condition 2. for this sieve.
But
	(Fc
n) =

Aj∈Fcn
	(Aj) =

Aj∈Fcn
	(Aj)α	(Aj)1−α
for any 0 < α < 1. Hence,
	(Fc
n) < e−nαb 
j
	(Aj)1−α
and so condition 2 is satisfied when the prior satisfies

j
	(Aj)1−α < +∞

Bayesian nonparametrics
267
for some α ∈(0, 1). An alternative proof choosing α = 1
2 is available. Hence this condition is only
dealing with the prior mass on the complement of the sieve being suitably small.
One could, and should, think about the scenario when the prior does not put positive mass on
all Kullback–Leibler neighbourhoods of f0. One would have something like
	

f : dK(f0, f) < δ

> 0
onlyforallδ > δ1 forsomeδ1 > 0.Withthis,onecannowonlydemonstratethatthedenominator
In > e−nc a.s. for all large n for c > δ1. The problem now is that the numerator, which works with
the Hellinger distance, has to be bounded above by e−nd for d > δ1. But d will be connected with
a Hellinger distance and δ1 will be connected with a Kullback–Leibler divergence. Thus, it makes
sense to connect these up with a sequence of distances and these can be found in the family of α
divergences:
dα(f0, f) = α−1

1 −

f 1−α
0
fα

When α = 1
2, we recover the Hellinger distance. As α →0 we will recover the Kullback–Leibler
divergence. Working with these divergences was accomplished in [10].
13.6 Summary
Large models absorb all possible types of uncertainty that arise from data. This is pure Bayesian
inference. There is no need to entertain a large number of small models in an attempt to determine
which one performs best given the data. Statistical approaches that promote this latter idea are ad
hoc, and are not Bayes.
But as discussed in this article, large models are not an unmixed blessing. Nonetheless, the point
of Section 13.3 is that if interest is in the f ∗∈ which minimizes
U(f) = −

log f( x) F0(dx),
whereF0 denotesthetruedistributionfunction,thennotonlyisf ∗theappropriatedensitytotarget
and learn about, but the Bayes machinery indeed works. Formally, there is a motivation to update
	(df)
to
	(df|X = x) ∝f(x) 	(df)
when X ∼F0. Importantly, the mathematics demonstrated that learning is indeed about f ∗.
Thissetupisalsoquiteexplicitinlikelihood-basedinference,sinceanestimateforf wouldfollow
from approximating U(f), given a sample of size n, by
Un(f) = −n−1
n

i=1
log f(Xi)
Minimizing this yields the Maximum Likelihood Estimator. Thus the MLE is also really about
finding f ∗. The problem with acknowledging this latter fact is that properties of estimators, such
as unbiasedness, are unavailable.

268
S. G. Walker
We have discussed a certain type of large model for i.i.d data, namely the popular mixture model
based on stickbreaking processes. We then showed how this structure can be extended to cover
non-i.i.d data, such as time series and regression models. These latter extensions require the calcu-
lationofatroublesomeandunavoidablenormalizingconstantinordertodofullBayesianinference.
Using a novel combination of latent models and MCMC techniques, we showed that it is possible
to satisfactorily provide complete Bayesian inference even in the non-i.i.d case.
References
[1] Barron, A. (1988). The exponential convergence of posterior probabilities with implications
for Bayes estimators of density functions. Unpublished manuscript.
[2] Barron, A., Schervish, M. J. and Wasserman, L. (1999). The consistency of posterior distribu-
tions in nonparametric problems. Annals of Statistics, 27, 536–561.
[3] Berk,R.H.(1966).Limitingbehaviourofposteriordistributionswhenthemodelisincorrect.
Annals of Mathematical Statistics, 37, 51–58. [Corrigendum 37, 745–746.]
[4] Bernardo, J. M. and Smith, A. F. M. (1994). Bayesian Theory. Wiley.
[5] Besag, J. and Green, P. J. (1993). Spatial statistics and Bayesian computation. Journal of the
Royal Statistical Society, Series B, 55, 25–37.
[6] Box, G. E. P. and Tiao, G. C. (1973). Bayesian Inference in Statistical Analysis. Addison–Wesley.
[7] Box, G. E. P. (1980). Sampling and Bayes’ inference in scientific modelling and robustness.
Journal of the Royal Statistical Society, Series A, 143, 383–430.
[8] Bunke, O. and Milhaud, X. (1998). Asymptotic behaviour of Bayes estimates under possibly
incorrect models. Annals of Statistics, 26, 617–644.
[9] Damien, P., Wakefield, J. C. and Walker, S. G. (1999). Gibbs sampling for Bayesian
non-conjugate andhierarchicalmodelsusingauxiliaryvariables. Journal of the Royal Statistical
Society, Series B, 61, 331–344.
[10] De Blasi, P. and Walker, S. G. (2012). Bayesian asymptotics with misspecified models.
To appear in Statistica Sinica.
[11] de Finetti, B. (1937). La pr´evision: ses lois logiques, ses sources subjectives. Ann. Inst. H.
Poincar´e, 7, 1–68.
[12] Doob, J. L. (1949). Application of the theory of martingales. In Le Calcul des Probabilités et ses
Applications, Colloques Internationaux du Centre National de la Recherche Scientifique, 13,
23–37. Paris: CNRS.
[13] Dunson, D. B. (2010). Nonparametric Bayes applications to biostatistics. In Bayesian Non-
parametrics, Hjort et al. (Eds.), Cambridge University Press.
[14] Escobar, M. D. (1988). Estimating the means of several normal populations by nonparametric
estimation of the distribution of the means. Unpublished PhD dissertation, Department of
Statistics, Yale University.
[15] Escobar,M.D.andWest,M.(1995).Bayesiandensityestimationandinferenceusingmixtures.
Journal of the American Statistical Association, 90, 577–588.
[16] Ferguson, T. S. (1973). A Bayesian analysis of some nonparametric problems. Annals of Statis-
tics, 1, 209–230.
[17] Fernandez, C. and Steel, M. F. J. (1998). On Bayesian modelling of fat tails and skewness.
Journal of the American Statistical Association, 93, 359–371.
[18] Griffin, J. E. and Holmes, C. C. (2010). Computational issues arising in Bayesian nonparamet-
ric hierarchical models. In Bayesian Nonparametrics, Hjort et al. (Eds.), Cambridge University
Press.
[19] Ghosal, S., Ghosh, J. K. and Ramamoorthi, R. V. (1999). Posterior consistency of Dirichlet
mixtures in density estimation. Annals of Statistics, 27, 143–158.

Bayesian nonparametrics
269
[20] Godsill, S. J. (2001). On the relationship between Markov chain Monte Carlo methods for
model uncertainty. Journal of Computational and Graphical Statistics, 10, 230–248.
[21] Green, P. J. (1995). Reversible jump Markov chain Monte Carlo computation and Bayesian
model determination. Biometrika, 82, 711–732.
[22] Hewitt, E. and Savage, L. J. (1955). Symmetric measures on Cartesian products. Transactions
of the American Mathematical Society, 80, 470–501.
[23] Hjort, N. L., Holmes, C. C., Müller, P. and Walker, S. G. (2010). Bayesian Nonparametrics.
Cambridge University Press.
[24] Ishwaran, H. and James, L. F. (2001). Gibbs sampling methods for stick–breaking priors.
Journal of the American Statistical Association, 96, 161–173.
[25] Kalli, M., Griffin, J. E. and Walker, S. G. (2010). Slice sampling mixture models. Statistics and
Computing, 21, 93–105.
[26] Kullback, S. and Leibler, R. A. (1951). On information and sufficiency. Annals of Mathematical
Statistics, 22, 79–86.
[27] Lee, P. M. (2004). Bayesian Statistics (3rd Edition). Arnold.
[28] Lenk, P. J. (1988). The logistic normal distribution for Bayesian, nonparametric, predictive
densities. Journal of the American Statistical Association, 83, 509–516.
[29] Lenk, P. J. (1991). Towards a practicable Bayesian nonparametric density estimator.
Biometrika, 78 531–543.
[30] Leonard, T. (1978). Density estimation, stochastic processes and prior information (with
discussion). Journal of the Royal Statistical Society, Series B, 40, 113–146.
[31] Lo, A. Y. (1984). On a class of Bayesian nonparametric estimates I. Density estimates. Annals
of Statistics, 12, 351–357.
[32] MacEachern, S. N. (1994). Estimating normal means with a conjugate style Dirichlet process
prior. Communications in Statistics: Simulation and Computation, 23, 727–741.
[33] MacEachern, S. N. and Müller, P. (1998). Estimating mixture of Dirichlet process models.
Journal of Computational and Graphical Statistics, 7, 223–338.
[34] Mena, R. H. and Walker, S. G. (2005). Stationary models via a Bayesian nonparametric
approach. Journal of Time Series Analysis, 26, 789–805.
[35] Müller, P., Erkanli, A. and West, M. (1996). Bayesian curve fitting using multivariate normal
mixtures. Biometrika, 83, 67–79.
[36] Neal, R. M. (2000). Markov chain sampling methods for Dirichlet process mixture models.
Journal of Computational and Graphical Statistics, 9, 249–265.
[37] O’Hagan, A. and Forster, J. J. (2004). Bayesian Inference (2nd edition). Arnold, London.
[38] Ongaro, A. and Cattaneo, C. (2004). Discrete random probability measures: a general
framework for nonparametric Bayesian inference. Statistics and Probability Letters, 67,
33–45.
[39] Papaspiliopoulos, O. and Roberts, G. O. (2008). Retrospective Markov chain Monte Carlo
methods for Dirichlet process hierarchical models. Biometrika, 95, 169–186.
[40] Richardson, S. and Green, P. J. (1997). On Bayesian analysis of mixtures with an unknown
number of components. Journal of the Royal Statistical Society, Series B, 59, 731–758.
[41] Robert, C. P. (2001). The Bayesian Choice. Springer Texts in Statistics (2nd Edition).
[42] Rodriguez, C. E. and Walker, S. G. (2011). Bayesian nonparametric mixture modelling with
unimodal kernels. Submitted.
[43] Sethuraman, J. (1994). A constructive definition of Dirichlet priors. Statistica Sinica, 4,
639–650.
[44] Schwartz, L. (1965). On Bayes procedures. Z. Wahrsch. Verw. Gebiete, 4, 10–26.
[45] Smith, A. F. M. and Roberts, G. O. (1993). Bayesian computations via the Gibbs sampler and
related Markov chain Monte Carlo methods. Journal of the Royal Statistical Society, Series B, 55,
3–23.

270
S. G. Walker
[46] Walker, S. G. and Hjort, N. L. (2001). On Bayesian consistency. Journal of the Royal Statistical
Society, Series B, 63, 811–821.
[47] Walker, S. G. (2007). Bayesian inference via a minimisation rule. Sankhya, 68, 542–553.
[48] Walker, S. G. (2011). Posterior sampling when the normalizing constant is unknown. Commu-
nications in Statistics: Simulation and Computation, 40, 784–792.
[49] Walker, S. G. and Karabatsos, G. (2012). Revisiting Bayesian curve fitting using multivariate
normal mixtures. This book.

14
Geometric weight priors
and their applications
ramsés h. mena
14.1 Introduction
T
he introduction by Walker, Chapter 13 in this volume, stresses the importance of having a
dependent sample so that learning about the distribution generating the observations can
take place. Further, if one assumes that the nature of the phenomenon under study generates
independent and identically distributed (i.i.d.) observations, the dependence in the sample needed
for Bayesian learning reduces to exchangeability. Whether one shares the notion of a correct model
or prefers to think of the Bayesian approach as implied by assuming exchangeability among the
observations, the role of such a dependence property is apparent.
From de Finetti’s representation theorem, a set of random variables (Xi)i≥1 taking values in a
Polish space X, endowed with the Borel σ-field X , is exchangeable if and only if
P(X1 ∈A1, . . . , Xn ∈An) =

PX
n

i=1
P(Ai) Q(dP),
Ai ∈X,
(14.1)
for any n ≥1 and where PX denotes the set of probability measures on (X, X). An interpreta-
tion follows directly from (14.1); the unknown, say P, that separates the joint law of (Xi)i≥1 into
conditional i.i.d. measures is random and uniquely driven by Q. Therefore its relation to Bayesian
statistics,andtheimportanceofspecifyingsuchadistribution,Q,forarandomprobabilitymeasure
(r.p.m.) P, is evident.
There are various approaches to define r.p.m.s; namely, via extensions of finite dimensional
distributions [20, 34]; via the normalization of stochastic processes [20, 47]; through predictive
distributions [45]; or by virtue of stickbreaking constructions [30, 51], etc.
Up to date reviews are found in Walker et al. [54] and Hjort et al. [29]. Each of these construc-
tions provides a different motive, i.e. analytic, numerical, or are useful for specific applications or
in extensions to non-exchangeable contexts. The canonical example is Ferguson’s [20] Dirichlet
process, whose different constructions and representations have in part served as the gateway for
the above more general approaches. For a partition (B1, . . . , Bk) of X and a finite non-atomic
measure α > 0 on (X, X), Ferguson [20] defined the Dirichlet process (Dα) as the stochastic
process having finite-dimensional distributions (P(B1), . . . , P(Bk)) ∼Dir(α(B1), . . . , α(Bk)),
where Dir(a1, . . . , ak) denotes the Dirichlet distribution over the (k −1)-dimensional simplex.

272
R. H. Mena
Although other r.p.m.s have made an impact, the Dirichlet process is the benchmark for appli-
cations. This is perhaps due to its mathematical tractability, which is in part due to its Pólya
urn representation [7], which tells us that the DθP0 can be seen as the limit of predictive
distributions
P(Xn+1 ∈· | X1, . . . , Xn) =
θ
θ + n P0(·) +
n
θ + nPn(·),
n ≥1
(14.2)
with X1 ∼P0, P0(·) := α(·)/θ, θ := α(X) and Pn(·) := n−1 n
i=1 δXi(·). More general urn
representations typically involve complex weights which in turn are cumbersome to incorporate in
MCMC algorithms [see for instance 36]. Indeed, most constructive approaches of r.p.m.s seek to
generalize the Dirichlet process resulting in richer models, but at the same time posing additional
complications when applying or studying them.
A general approach to define a discrete r.p.m. on (X, X) is via
P(B) =
∞

i=1
wi δZi(B),
B ∈X
(14.3)
where the weights wi and locations Zi are random, i.e. 
i wi = 1 a.s., and independent of
Zi
iid∼P0, with P0 a non-atomic distribution on (X, X). This class of r.p.m.s is termed proper
species sampling models [see 45]. It follows that E[P] = P0, thus calling such a term the prior
guess at the shape of P, a key component when applying and studying (14.3).
Sethuraman [51] proved that if the weights have the following stickbreaking form
w1 = v1
and
wi = vi
i−1

j=1
(1 −vj),
i ≥2
(14.4)
with vi
iid∼Beta(1, θ), then P ∼DθP0. If instead vi
ind
∼Beta(1 −σ, θ + iσ) with θ > −σ and
σ ∈[0, 1), then one has the two parameter Poisson–Dirichlet r.p.m. [30].
Here we undertake a different rationale; instead of searching for a further generalization, we
present a simpler r.p.m. that results in a robust choice of nonparametric prior which, due to its
simplicity, turns out to be appealing for practical implementations and also is easily extendable to
the dependent processes settings. The idea centres around the following model:
Definition 14.1 Let PX be the set of probability measures on (X, X). We term a r.p.m. P ∈PX a
geometric weights prior, denoted by GWP(a, b), if
P(B) = λ
∞

i=1
(1 −λ)i−1 δZi(B),
B ∈X
(14.5)
with Zi
iid∼P0 independent of λ ∼Be(a, b), a, b > 0.
Indeed, it is a simpler object than the Dirichlet process, as its weights depend on only one Beta
random variable, instead of an infinite number. In other words, the stick is always broken with the
same Beta random variable.
Before entering the discussion about these kinds of r.p.m.s let us first review some well-known
facts about the Dirichlet process and some other nonparametric priors. This will then allow us to
grasp the main idea and the appealing features of the model in Definition 14.1.

Geometric weight priors and their applications
273
14.1.1 Disentangling the total mass parameter of the Dirichlet
process
An appealing feature of the Dirichlet process, and other r.p.m.s constructed as in (14.3), is the
almost sure discreteness [see 6]. Indeed, from (14.2), we see that P[Xi = Xj] > 0 for any i ̸= j.
This implies that X(n) := (X1, . . . , Xn) contains Kn ≤n distinct observations (X∗
1, . . . , X∗
Kn)
withcorrespondingfrequenciesNKn = (N1, . . . , NKn)suchthatKn
j=1 Nj = n.Hence,selecting
an exchangeable sample of size n driven by Dθ P0 induces a partition into groups {G1, . . . , GKn},
Gj := {i : Xi = X∗
j }, j = 1, . . . , Kn, each with probability
P[{Kn = k} ∩{N1 = n1, . . . , NKn = nk}] = θk
(θ)n
k

i=1
(ni −1)!
(14.6)
where nj = #Gj and (θ)n := θ(θ + 1) · · · (θ + n −1). Notice that Kn and NKn depend only on
the clustering structure among the Xis and not their actual values.
The support of (14.6) is in bijection with the set of partitions of a set with n elements,
[n] = {1, . . . , n}, here denoted by P[n], and whose cardinality is given by the nth Bell number,
Bn. Because of their symmetry, these probabilities, denoted by 	(n)
k (n1, . . . , nk), are known in the
literature as exchangeable partition probability functions (EPPFs), and are widely used to model
random partitions in areas such as population genetics [17], combinatorics [28], economics [2] and
excursion theory [45], among others [see also 18]. In Bayesian nonparametric inference they can be
applied to depict the clustering structure among observations in hierarchical mixture models [see
38] or to give robust solutions to species sampling problems [see 35].
Marginalizing (14.6) one obtains the prior probability on the number of distinct values
P[Kn = k] = θk
(θ)n
|s(n, k)|,
k = 1, . . . , n
(14.7)
where s(n, k) is the Stirling number of the first kind. Figure 14.1 illustrates the above probabilities,
and clearly θ is highly informative on the number of groups.
Remark 1 The total mass parameter θ corresponding to a Dirichlet process is highly informative on the
number of groups.
A popular application of discrete r.p.m.s is as building blocks in hierarchical mixture models. Fol-
lowing Lo [38], a random density can be constructed as
Yi | Xi
ind
∼f(Yi | Xi)
(14.8)
Xi | P
iid∼P
P ∼Q
where f(· | X) is typically a Lebesgue density and thus used to model continuous data. This means
that we can model a set of Y-valued observables (Yi)i≥1, through the random density
f(y) =

X
f(y | x) P(dx)
When P ∼DθP0, and using representation (14.2), Escobar [13, 14] and Escobar and West [15]
devised a MCMC algorithm for this model. [See also 4, 33, for other numerical approaches in

274
R. H. Mena
0
5
10
15
20
25
30
35
40
45
50
0.025
0.050
0.075
0.100
0.125
0.150
0.175
0.200
0.225
θ = 1
θ = 2
θ = 5
θ = 10
θ = 30
θ = 50
θ = 70
θ = 100
θ = 300
n = 50
Figure 14.1 Prior probability on the number of different species corresponding to a sample of size
50 driven by DθP0 as θ varies.
Bayesian nonparametrics.] Using representation (14.3) of a discrete r.p.m., the above model can
be seen as the infinite mixture model
f(y) =

X
f(y | x) P(dx) =
∞

i=1
wi f(y | Zi)
(14.9)
with Zi
iid∼P0. This clearly relates to the theory of mixture models used in model-based clustering
[see 3] and density estimation problems. In fact, if we are interested in the clustering among the
Yis, it seems natural to think of it as being induced by a clustering at the latent level of the Xis. In
particular, if we denote by pn ∈P[n] a given partition of X(n), and thus of Y(n), where each Yi is
i.i.d. from the random density (14.9), we can compute [see 37] the posterior probability
P(pn | Y(n)) ∝P(pn)P(Y(n) | pn)
(14.10)
where
P(pn) = 	(n)
k (n1, . . . , nk)
is the corresponding EPPF to P, e.g. expression (14.6) when P ∼DθP0, and
P(Y(n) | pn) =
k

j=1

X

i∈Gj
f(yi | xj)P0(dxj),
(14.11)
sometimes termed the clustering likelihood of Y(n) for a given partition {G1, . . . , Gk}. Although
(14.10) simplifies for specific choices of f and P0, direct evaluation through all its support, namely

Geometric weight priors and their applications
275
the subset Pk
[n] ⊂P[n] of partitions of size k, is infeasible when n is large, since a Stirling number of
the second type, Sn,k, of evaluations would be needed. Unlike the EPPF, the posterior distribution
(14.10) is no longer exchangeable due to the effect of the kernel f in the observation’s Yis when
evaluated in a particular group partition. Clearly, the problem amplifies when we are also interested
in the number of groups as we would need to compute
P[Kn = k | Y(n)] ∝

pn∈Pk
[n]
	(n)
k (n1, . . . , nk)
k

j=1

X

i∈Gj
f(yi | xj)P0(dxj),
k = 1, . . . , n.
(14.12)
Therefore, resorting to MCMC, or other kind of numerical methods, it is imperative for real appli-
cations. At the outset, building P[n]-valued Markov chains does not appear to be an easy task. But
this is implicitly done with most MCMC methods based on Pólya urn schemes [cf. 15] by keeping
track of the k and frequencies (n1, . . . , nk) at each iteration. See also Lau and Green [32] and the
references therein for other approaches.
Note that when inferring about the clustering structure of Y(n) using quantities such as (14.10)
and (14.12), the interpretation is different than that typically obtained in analyses based on finite
mixture models [cf. 48]; under this latter approach the number of clusters is explicitly identified
by the number of components in the mixture. Nonetheless, the former approach, based on the
posterior probabilities on partitions, is also ‘model based’.
Example 14.2 Consider the small dataset y =(–1.522, –1.292, –0.856, –0.104, 2.388, 3.080, 3.313,
3.415, 3.922, 4.194), i.e. n = 10 with a B10 = 115 975 possible groups and thus it is possible to
evaluate (14.10) and (14.12). Assume the hierarchical model (14.8), with P ∼DθP0,
f(· | μ, ξ) = N(· | μ, ξ−1)
and
P0(dμ, dξ) = N(μ | 0, (τ ξ)−1)Ga(ξ | α, β)dμ dξ
(14.13)
If Sj := 
i∈Gj y2
i −nj ¯y2
j /(nj + τ) and ¯yj := n−1
j

i∈Gj yi then the likelihood (14.11) becomes
k

j=1

τ
nj + τ
 1
2
βα (α + nj
2 )
(2π)
nj
2 (α)
8
β + Sj
2
9α+
nj
2
.
Figure 14.2 shows that two groups is the intuitive choice. From Table 14.1 it is clear that θ also influ-
ences the posterior clustering probabilities. When θ = 0.5 or θ = 1, the posterior mode of (14.10)
sits on p = {{y1, . . . , y4}, {y5, . . . , y10}}, with probabilities 0.522 and 0.332, respectively, whereas
whenθ = 5itsitsonp∗:= {{y1}, {y2}, {y3}, {y4}, {y5, . . . , y10}}withprobability0.0204.Tosome
extent, these observations could have been predicted since E[Kn] = n
i=1 θ/(θ + i −1), which
for θ = 0.5, θ = 1 and θ = 5 yield 2.13, 2.93 and 5.84, respectively. Thus, slightly coinciding with
the posterior results of Table 14.1. Clearly the effect of the prior could be diminished as the sample
size n increases.
Remark 2 The total mass parameter θ corresponding to a Dirichlet process strongly influences the
posterior inference on the number of groups in a nonparametric mixture model.
Remarks 1 and 2 are not new, e.g. see Escobar and West [15]. Although such effects of an informative
prior can be attenuated with other choices of r.p.m.s, such as the two-parameter Poisson–Dirichlet

276
R. H. Mena
−2
−1
0
1
2
3
4
0.0
0.5
1.0
1.5
2.0
2.5
3.0
Figure 14.2 Small data set.
Table 14.1 Exact posterior probabilities (14.12) for Kn with τ = 0.1 and α = β = 1 and different
choices of θ. Modal probabilities in bold font.
k
θ = 0.5
θ = 1
θ = 5
1
0.019469
0.00619
0.000071
2
0.37634
0.021504
3
0.312288
0.113509
4
0.067986
0.17298
0.247113
5
0.008033
0.04088
6
0.000568
0.00578
0.206592
7
0.000025
0.00051
0.090763
8
6.74 E−7 
0.00003
0.024486
9
1.03 E−8
8.38 E−7
0.003740
10+
6.85 E−11
1.12 E−8
0.000249
0.291972
0.39729
0.591630
process, or normalized generalized gamma processes [cf. 36], a similar effect still remains for their
corresponding parameters.
The total mass parameter has different interpretations in the literature, e.g. as the scale parameter
of the DθP0 that regulates the concentration mass around P0; it can be thought of as the prior
samplesize[cf.52].ItcanalsobeusedtomatchsomemomentsoflinearfunctionalsoftheDirichlet
process [cf. 55]. Furthermore, it arises in other areas such as population genetics, where it takes the
role of the mutation rate in a Wright–Fisher-type population model [cf. 17].
Remark 3 InpracticalimplementationsbasedontheDirichletprocess,thetotalmassparameterθ needs
to be incorporated in the learning process.
A technique to deal with stickbreaking priors is through truncation of representation (14.3),
PT(·) =
T

i=1
wi δZi(·),
T < ∞
(14.14)
andthusreliesonaL1 errorboundtodeterminethevalueofthetruncationpoint T.Weights(14.4)
arenot necessarilyorderedandthereforesuchabounddepends ontheir parameters.This,addedto

Geometric weight priors and their applications
277
the required randomization of θ, implies that we would also need to incorporate T in the MCMC
analysis, which is certainly neither commonly done nor an easy task.
Remark 4 Unordered random weights in species sampling models might result in truncation methods
that are highly dependent on their parameters.
We have underlined some issues of the Dirichlet process that are in part a result of the random-
ness of its weights, and which is reflected on the parameter θ. The objective of this work is to
present a somewhat easier r.p.m. that to some extent overcomes such issues. In Section 14.2 we
study the geometric weights prior as one possible simpler model. Additionally, some estimation
aspects and an intuitive derivation through a more general class of r.p.m.s are also presented. Being
a simpler object it also makes it appealing to extensions to non-exchangeable contexts; in Sec-
tion 14.3, some applications to dependent nonparametric processes are presented. In particular, its
application to building models for Bayesian nonparametric regression and to construct probability
measure-valued diffusion processes are explored. Examples illustrating the proposed models are
also presented. Some concluding remarks are deferred to Section 14.4.
14.2 Geometric weights priors
A simple inspection of representation (14.3) of a discrete r.p.m. tell us that there are two sources of
randomness, the weights and the locations. Furthermore, from Remark 3, we saw that we need to
randomize the parameters of the weights, e.g. θ if P ∼DθP0. As noted by Walker, Chapter 13 in
this volume, the lack of order in the P ∼DθP0 weights induces a non-identifiability problem. In
other words, the fact that the stickbreaking weights are not deterministically ordered means that
mass in a particular location B ∈X, i.e. P(B), can be attained by many different combinations of
weights, wis and locations Zis. This issue is clearly inherited by mixtures based on such a prior.
Hence, could one define a r.p.m. with simpler weights which makes better use of the availability of
infinite locations to attain a particular mass, and eases the identifiability issue? The answer is yes,
and is addressed below.
Instead of considering weights as in (14.4), consider
ωi := E [wi] = E
⎡
⎣vi
i−1

j=1
(1 −vj)
⎤
⎦= μi(ψ)
i−1

j=1

1 −μj(ψ)

with μi(ψ) := E[vi] and where ψ here generically denotes the parameter (or parameters) cor-
responding to the distribution of the vis. Next, assume that the vis have been chosen such that
ωi > ωi+1, that is μi+1(ψ) < μi(ψ)(1 −μi(ψ))−1 for all i. Note also that when random-
izing ψ the arguments in the right-hand side product of the above expression are no longer
independent.
For the Dirichlet process we have vi
iid∼Be(1, θ); thus, setting λ := μi(θ) = (1 + θ)−1, we
have
ωi = λ(1 −λ)i−1 :
(14.15)
geometric weights. Accordingly with the idea of randomizing θ, we could also assign a prior distri-
bution to λ, say λ ∼Be(a, b). In other words, we recover the r.p.m. given in Definition 14.1.
Note that P ∼GWP(a, b) is an almost sure discrete random probability measure and that, as
in the Dirichlet process, and other species sampling models, the probability measure P0 can be
thought of as the prior guess at the shape of P, since E[P] = P0.

278
R. H. Mena
At first sight the random probability measure provided by (14.5) can be misinterpreted as a
special case of the Dirichlet process, since the weights of the former can be obtained as in (14.4)
by letting (v1, v2, . . .) all be equal to the same realization of a Beta random variable, so that wi,
i = 1, 2, . . . are mixed geometric with Beta(a, b) as the mixing distribution. However, this proves
not to be the case. First, in the Dirichlet process case, the parameter a of the Beta distribution
is constrained to be one. And, more significantly, because the Dirichlet process, P ∼DθP0, is
characterized by the distributional equation
P d= v1δZ1 + (1 −v1)P
(14.16)
with v1 ∼Be(1, θ) and Z1 ∼P0, stochastically independent of P [cf. 51]. The same procedure
applied to P∗∼GWP(a, b) yields
P∗d= λ δZ1 + (1 −λ)P∗
(14.17)
Thecrucialdifferencebetweenthesetwocasesisthatin(14.16),Pisindependentof(v1, Z1),while
in (14.17), P∗is independent of Z1 but not of λ. Hence we are dealing with a different random
probability measure.
A key issue that arises when considering whether to use a random probability measure of type
(14.5) is whether it has full support. This could be a more relevant concern when one compares the
Dirichlet process, or other more complex r.p.m.s, with the rather simplistic r.p.m. of Definition 14.1.
The following proposition, whose proof easily follows from results in Ongaro and Cattaneo [43],
justifies the use of the proposed model for inference purposes.
Proposition 14.1 Let P be the probability distribution induced on PX by random probability
measures P ∼GWP(a, b). Then the support of P in the topology of weak convergence on PX
is given by all probability measures G ∈PX such that the support of G is included in that of P0.
Therefore, the geometric weights prior constitutes a valid alternative to the Dirichlet process in
Bayesian nonparametric applications.
14.2.1 An intuitive derivation
Walker [53] proposed an alternative method for posterior inference based on the nonparamteric
mixture model (14.8) that overcomes the infinite summation in (14.9). By augmenting (14.9)
through a latent uniform variable one can slice the corresponding infinite summation by consid-
ering the joint density
f(y, u) =
∞

i=1
I(u < wi) f(y | Zi)
(14.18)
with conditional density
f(y | u) =
1
|Au|

i∈Au
f(y | Zi),
(14.19)
where
Au := {j : u < wj}
(14.20)

Geometric weight priors and their applications
279
and |Au| := ∞
i=1 I(u < wi). Notice that given u the random set of component-indexes in the
mixture, Au, is finite, i.e. |Au| < ∞. Using this idea Walker [53] proposed a Gibbs sampler for
posterior analysis, based on the nonparametric mixture model (14.8), which avoids truncations
such as (14.14). See also Kalli et al. [31] for more efficient implementations.
Here we are interested in the conditional distribution (14.19), as it can also be used to construct
other kinds of random densities, namely
f(y | A) =
1
|A|

i∈A
f(y | Zi),
(14.21)
where A is a random finite subset of N+ and, as before, Zi
iid∼P0. This resembles the approach
undertaken in finite mixture models, but with some differences. First note that if we assume model
(14.21) for each observation, Yj, then there will be a random set Aj for each of them, whereas in the
finite mixture model approach the number of components, N, suffices for all observations. In fact
this is one of the reasons for having complex weight and location specifications in the finite mixture
approach, i.e. to build a richer model which is able to allocate the required mass in a particular loca-
tion. On the other hand, for Bayesian nonparametric mixtures such as those based on the Dirichlet
process and other discrete r.p.m.s, there are an infinite number of locations, Zis at our disposal
to allocate a particular mass; therefore the complexity in the weights modulating a r.p.m. can be
relaxed.Inparticular,notethattherandomsetAcorrespondingtotheDirichletprocessmighthave
gaps, i.e. we can have realizations of the sort of {2, 5, 10, 345, 1004}; it is not a consecutive sequence
of integers from 1 to N as it is typically for finite mixture models. In fact, having an infinite number
of locations at our disposal, we do not see a clear need to have index sets with gaps.
Hence, an idea is to consider the random set A := {1, . . . , N} so (14.21) reduces to
f(y | N) = 1
N
N

i=1
f(y | Zi)
where N is random and modelled through a distribution supported on N+, namely qN(· | λ),
where for now λ denotes a generic parameter of the chosen distribution for N.
If we write out the model by marginalizing over N then we have
f(y) =
∞

l=1
1
l
l

i=1
f(y | Zi) qN(l | λ)
which can also be written as
f(y) =
∞

i=1
ωi f(y | Zi)
(14.22)
where
ωi =
∞

l=i
qN(l | λ)
l
(14.23)
Ifwefurtherrandomizeλandassignapriorforit,e.g.λ ∼π,then(14.22)becomesamixturebased
on a species sampling model (or simply a species sampling model if we take f(· | Zi) = δZi(·)).

280
R. H. Mena
Clearly the weights (14.23) sum up to one (a.s. if λ is random) and are in decreasing order as one
sees that ωi+1 = ωi −qN(i | λ)/i.
Therefore (14.22) and (14.23) provide an alternative to the stickbreaking way of constructing
species sampling models. By changing the choice of qN(· | λ) and the prior for λ, we obtain differ-
ent r.p.m.s.
Of particular interest here is when we assume N ∼Neg-Bin(2, λ), that is
qN(l | λ) = lλ2(1 −λ)l−1 I(l ∈N+)
which, by evaluating (14.23), allows us to recover the geometric weights, that is
ωi = λ(1 −λ)i−1
Hence, the r.p.m. of Definition 14.1 can be recovered as a r.p.m. of the sort
P(B) = EqN
⎡
⎣1
N
N

i=1
δZi(B)
⎤
⎦
(14.24)
where Zi
iid∼P0, qN = Neg-Bin(2, λ) and λ ∼Be(a, b).
14.2.2 Posterior inference
Based on the construction in the previous subsection, Fuentes et al. [22] proposed an algorithm for
posterior inference under the following setting. Suppose we have a sample Y(n) := (Y1, . . . , Yn)
modelled by the nonparametric mixture model (14.8) where P follows a r.p.m. as in (14.24). Intro-
ducing a latent variable di which, given Ni, indicates where the component Yi comes from: now, we
can rewrite the nonparametric mixture model as
Yi | Z(n), di, Ni
ind
∼f(Yi | Zdi)
(14.25)
di | Ni
ind
∼U{1, . . . , Ni}
Ni
iid∼qN(· | λ)
λ ∼π,
with Zi
iid∼P0. Following [22] a Gibbs sampler algorithm, for the case qN = Neg-Bin (2, λ) and
λ ∼Be(a, b) (i.e. for a mixture model (14.8) when P ∼GMP(a, b)) reduces to sampling from
the following full conditional distributions:
f(Zj | · · · ) ∝P0(Zj)

di=j
f(yi | Zj),
for j = 1, . . . , M
(14.26)
P(di = l| · · · ) ∝f(Yi | Xl) I(l ∈{1, . . . , Ni})
P(Ni = j | · · · ) = λ(1 −λ)j−1I(j ≥di)
f(λ | · · · ) = Be

λ | a + 2n, b +
n

i=1
Ni −n

(14.27)

Geometric weight priors and their applications
281
for i = 1, . . . , n and where M = max{N1, . . . , Nn}. Clearly, the Gibbs sampler simplifies when
f and P0 form a conjugate pair.
Example 14.3
In order to illustrate the performance of the above mixture of GWP(a, b),
let us consider 240 data points coming from a mean-variance mixture of six normal distribu-
tions with weights (0.17, 0.08, 0.125, 0.2, 0.125, 0.21) and mean-variance parameters given by
(−18, 2), (−5, 1), (0, 1), (6, 1), (14, 1) and (23, 125). We assume the same kernel and prior guess
at the shape specifications as in (14.13).
Figures 14.3 and 14.4 show the dynamics of the density estimator for the first 100 iterations based
on mixtures of GWP(a, b) and on mixtures of DθP0 respectively. From Figure 14.3 we note that
theavailabilityofanunlimitednumberof Zjstorepresentaparticularclusterlocationalwaysresults
in an improvement in subsequent iterations, whereas for the Dirichlet process case, Figure 14.4, the
algorithm requires several iterations to detect a good candidate for the Zj representing a particular
location. This feature is better appreciated in the mode around −18, which can be thought as being
far from the overall mean of the data. It can also be observed at the tails of the density estimators
in Figure 14.3, where for the initial iterations a larger mass than that shown for the Dirichlet process
case is allocated.
It is probably worth mentioning that this drawback of nonparametric mixtures based on the Dirich-
let process, and also on other discrete r.p.m.s, has received considerable attention in the Bayesian
nonparametric literature, resulting in algorithms that aim to accelerate the identification of good
candidatesfortheZjsidentifyingparticularclusterlocations[seeforinstance41].However,inspite
of these efforts, this issue is not fully resolved.
Figure 14.5 shows the estimates for both the Dirichlet process and the geometric weights prior
cases after convergence. This figure also compares the true model that generated the observations;
0.02
0.04
0.06
0.08
0.10
0.12
y
Histogram and^f (y)
Dynamics of geometric model
–40
–30
–20
–10
0
10
20
30
40
50
Figure 14.3 Dynamics of the density estimator, based on the geometric weights prior, through the
first 100 iterations of the Gibbs sampler algorithm for the mean-scale mixtures dataset. The hyper-
parameters are given by (τ, α, β, a, b) = (100, 0.5, 0.5, 0.5, 0.5) and initial values Ni = 10 and di ∈
{1, . . . , 10} for all i = 1, . . . , 240.

282
R. H. Mena
0.05
0.10
0.15
0.20
0.25
y
Histogram and ^f (y)
–30
–25
–20
–10
–15
–5
0
10
5
20
15
30
25
Dynamics of MDP
Figure 14.4 Dynamics of the density estimator for the mixture of Dirichlet process through the first
100 iterations of the Gibbs sampler algorithm for the mean-scale mixtures dataset.
0.025
0.050
0.075
0.100
0.125
0.150
y
Histogram and ^f (y)
–30
–20
–25
–15
–10
–5
0
10
5
20
15
25
30
True model
Fitted geometric model
Fitted MDP model
Figure 14.5 Density estimates for the 6 modes simulated dataset based on both GWP(a, b)
and DθP0. The estimates are based on 10 000 after a burn-in period of 2000 iterations. The
hyperparameters are given by (μ, τ, α, β, a, b) = (0, 100, 0.5, 0.5, 0.5, 0.5) and Ni = 10 and di ∈
{1, . . . , 10} for all i = 1, . . . , 240.

Geometric weight priors and their applications
283
we can see both approaches are satisfactory, however the approach based on GWP(a, b) appears
to be closer to the true model.
14.3 Dependent processes based on geometric weights
priors
WenotedearlierthatthetypeofdependencedrivingBayesianstatisticsisexchangeability.However,
there are many phenomena where models with a more structured dependence are needed and
would also benefit from a nonparametric approach, e.g. regression analysis, time series analysis,
etc. This has motivated the notion of dependent nonparametric processes. The idea is to provide a
family of random probability measures linked by a suitable dependence structure, e.g. by means of
a set of covariates or a time parameter, and to use it for drawing inference on random phenomena
in appropriate frameworks, usually with the aid of simulation techniques.
When this dependence structure can be indexed via a continuous time parameter, then we are
effectively dealing with probability-measure-valued processes devised for nonparametric inference
purposes. Apart from the theoretical developments offered by the probabilistic study of measure--
valued processes, whose literature is certainly broad and well established [see for example 16], on
the statistical side this is a relatively young area and to date the most productive ideas have involved
the Dirichlet process.
Initiated in part by MacEachern [42] [see also 19] who introduced the notion of dependent
Dirichlet processes, the current literature on the topic includes, among others, De Iorio et al. [10]
who proposed a model with an ANOVA-type dependence structure, Gelfand et al. [23] who apply
the dependent Dirichlet process to spatial modelling by using a Gaussian process for the atoms,
Griffin and Steel [26] who let the dependence on the random masses be directed by a Poisson
process,Caronetal.[8]whomodelnonparametricallythenoiseinadynamiclinearmodel,Dunson
and Park [12] who construct an uncountable collection of dependent random probability measures
based on a stickbreaking procedure with kernel-based weights. See also [11], [49], [44], [50] and
[27] for other contributions.
The main idea is to construct a PX-valued stochastic process {Pz}z∈Z, which following repre-
sentation (14.3) of a random probability measure, extends to
Pz(B) =
∞

i=1
wi(z) δZi(z)(B),
B ∈X,
(14.28)
where{wi(z)}∞
i=1 and{Zi(z)}∞
i=1 areinfinitecollectionsofstochasticprocesses,indexedbyz ∈Z.
Hence the dependence structure set in the weights and locations drives the dependence relations at
the r.p.m. level. Clearly, while specifying a dependent nonparametric process, we could have both
weights and locations dependent, or just one of them.
Anaturalideawhenconstructingdependentprocessesistokeeptheirmarginalbehaviourtobea
known r.p.m., e.g. a Dirichlet process, a two-parameter Dirichlet process, a geometric weights prior,
etc.Thisiseasilydonebysettingstrictlystationaryprocesseswiththedesiredmarginaldistribution.
In what follows we will revise a couple of these examples based on geometric weights priors.
14.3.1 Covariate dependence for regression problems
A well-known problem in general regression analysis is to set a link function between observations
and covariates. A Bayesian nonparametric approach to deal with this problem is to propose depen-
dent random densities such as

284
R. H. Mena
fz(y) =

f(y | x) Pz(dx),
where {Pz}z∈Z follows a covariate dependent nonparametric process.
Fuentes et al. [21] followed this idea and proposed a dependent nonparametric process with
marginals GWP to model {Pz}z∈Z, that is
Pz(·) =
∞

i=1
λ(z)(1 −λ(z))i−1 δZi(·),
where Zi
iid∼P0 and
λ(z) =
eξ(z)
1 + eξ(z)
(14.29)
with ξ := {ξ(z)}z∈Z a Gaussian process with continuous mean μ and continuous covariance
function σ. Thus, we retain the iid locations and induce the dependence only through the simple
structure of the geometric weights.
Some z-dependence properties can be studied directly from the geometric structure of the
weights, for instance it is easy to see [see 21] that for B ∈X
corr(Pz(B), Pz′(B)) =
ρ(z, z′)
√ρ(z, z)
7
ρ(z′, z′)
(14.30)
where
ρ(z, z′) = E

λ(z)λ(z′)
1 −[1 −λ(z)][1 −λ(z′)]

When λ(z) ∼LGP(μ, σ), i.e. it follows the logistic Gaussian process (14.29), the above expres-
sion reduces to
ρ(z, z′) = E

eξ(z)+ξ(z′)
eξ(z) + eξ(z′) + eξ(z)+ξ(z′)

Hence, returning to the dependent mixture model we can write
fz(y) = λ(z)
∞

i=1
(1 −λ(z))i−1 f(y | Zi),
(14.31)
The logistic transformation (14.29) ensures that 0 < λ(z) < 1 as required for the geometric
weights prior.
Following the alternative derivation of geometric weights priors of Section 14.2.1 we can again
make use of the latent variable di to build a Gibbs sampler algorithm, which is essentially based
on the same full conditionals as in (14.40) but replacing (14.27) with the full conditional for
ξ(n) = (ξ1, . . . , ξn), ξi := ξ(zi), which can be updated component-wise via
P(ξi | ξ−i) ∝
1
(1 + eξi)Ni+1 N
⎛
⎝ξi; μi −1
cii

j̸=i
(zj −μj)cij + 1
cii
, 1
cii
⎞
⎠

Geometric weight priors and their applications
285
where μi = μ(zi) and cij is the ij-term of the precision matrix −1,  = {σ(zi, zj); i, j =
1, . . . , n}.Theabovedensityislog-concaveandthuscanbeeasilysampledviatheadaptiverejection
sampling (ARS) algorithm of Gilks and Wild [25].
Example 14.5 Consider a simulated dataset with 61 observations coming from
Yi = 0.2 z3
i + εi
where εi
iid∼N(0, 0.25) and z = (−3, −2.9, . . . , 2.9, 3). Hence assuming the dependent mixture
model (14.31), with the same kernel and prior guess at the shape specifications as in (14.13), one can
implementaMCMCalgorithm,basedonfullconditionals(14.40)withtheabovecomponent-wise
update of the logistic Gaussian process, to infer about any random functional of the form
ηz(h) =

Y
h(y) fz(y)dy
This can be done through the Rao–Blackwellized MCMC estimator
˜ηzi(h) = 1
M
M

l=1
El[h(y) | zi]
where M denotes the number of effective iterations in the MCMC. For example, one might be
interestedinthemeanfunctionalEl[y | zi] ≈μdi,whichinpracticecanbeobtainedastheupdated
mean value in the Gibbs sampler.
Figure 14.6 shows the MC estimator for the distribution of the mean functional (h(y) = y)
together with the observed data. For the corresponding Gaussian process we have set μ(z) = −|z|
and σ(zi, zj) = e−φ||zi−zj||.
Just as in the marginal GWP case, simpler weights with an infinite number of locations, seems to
be enough to allocate the required mass at a particular location. In particular, having the first and
largest weight for each covariate point, z, combined with the choice of locations seems enough for
regression purposes.
14.3.2 A nonparametric diffusion process based on geometric
weights priors
Although there are currently many examples of dependent nonparametric priors, the current sta-
tistical literature devoted to the study of continuously dependent measures is sparse. Indeed, it is of
interesttostudythiscasefromastatisticalperspectiveasitwouldallowustoexploittheflexibilityof
a Bayesian nonparametric approach while enjoying desirable properties such as Markov, reversibil-
ity,regularityofsamplepathsfortheconstructedmodel,etc.Thesefeaturesareappealinginvarious
modelling contexts and applications of stochastic processes such as finance or population genetics,
where diffusion processes are typically used to model random phenomena evolving in time.
In this section we present an approach to constructing PX-valued continuous time stochastic
processes (Pt)t≥0 [see 40] by simply introducing the time dependence through the weights, while
keeping the locations fixed (but random) over time, in the species sampling representation for the
GWP(a, b). That is, we will consider
Pt(B) = λt
∞

i=1
(1 −λt)i−1 δZi(B),
B ∈X,
(14.32)

286
R. H. Mena
Figure 14.6 MC estimator for the density of ηz(y) for a simulated dataset. The spheres represent
the observed data and the surface the Rao–Blackwellized MC estimator for ηz(y). The results are
based on 10 000 iterations of the Gibbs sampler algorithm.
with Zi
iid∼P0 and (λt)t≥0 a suitable stochastic process. In order to keep the same marginal r.p.m.
GWP(a, b), we assume (λt)t≥0 follows a strictly stationary diffusion process with Be(a, b) invari-
ant distributions. There are many choices for such a model, here we use a slight generalization of
the well-known two-type Wright–Fisher diffusion process which can be described as the solution
of the stochastic differential equation (SDE) on [0, 1] given by
dλt =
1
c
a + b −1(a −(a + b)λt)
2
dt +
:
2c
a + b −1λt(1 −λt) dBt
(14.33)
where (Bt)t≥0 is a standard Brownian motion. The typical parameterization of the two-type
Wright–Fisher with mutation SDE is found when c = (a + b −1)/2.
Definition 14.6 [40]Ageometricstickbreakingprocesswithparametersa, b, c > 0isarandomprocess
(Pt)t≥0 takingvaluesinPX definedateacht ≥0by(14.32)with(λt)t≥0 atwo-typeWright–Fisher
diffusion and P0 a nonatomic probability measure on (X, X). We denote it as GSB(a, b, c, P0).
It can be seen that the Wright–Fisher diffusion is time reversible, strictly stationary with invariant
measure Be(a, b), so an immediate question is whether some of these properties are inherited by
the GSB(a, b, c, P0) process.
Before undertaking this problem, first let us note that constructing stationary one-dimensional
diffusion processes with desired stationary distributions can be done via stochastic differential

Geometric weight priors and their applications
287
equations [see 5], however this is not entirely useful when, for estimation purposes, one needs to
keep track of an analytical form or an exact representation of the corresponding transition density.
Here we use an idea to construct continuous time Markov processes [see 39] that allows us to have a
representation of the transition density of the Wright–Fisher diffusion process. The idea starts with
a Gibbs sampler Markov process based on the joint density
f(y, x) = Po(y | φx) Ga(x | a, b)
from which we can construct a Markov process (Xt)t≥0 with Ga(a, b) marginals by the conditional
updating Yt | X0 ∼Po(φtX0) and Xt | Yt ∼Ga(a + Yt, b + φt). Indeed, such updating leads to
the transition density
p(xt | x0) =
∞

y=0
Ga(xt | a + y, b + φt)Po(y | φtx0)
(14.34)
=
e−[φt(xt+x0)+bxt]
(φt + b)−(a+1)/2 φ(a−1)/2
t
 xt
x0
 a−1
2
Ia−1

2
7
xt x0φt(φt + b)

with φt := b(ect −1)−1. It can be verified that the above transition corresponds to the solution of
a SDE given by
dXt = c
a
b −Xt

dt +
:
2c
b Xt dBt
known as the Cox–Ingersoll–Ross model for interest rates [see 9]. Therefore having a
continuous-time Markov process with Ga(a, b) invariant distribution suggests a simple
transformation of two independent copies of these to obtain a diffusion with Be(a, b) invariant
densities. That is, λt = X1t/(X1t + X2t), where (Xit)t≥0, i = 1, 2 are independent Markov
diffusion processes with Ga(a, 1) and Ga(b, 1) invariant densities respectively and transition
probabilities (14.34). In fact, it easily follows [see 39] that the transition corresponding to this
newly transformed process is given by
p(λt | λ0) =
∞

m=0
pt(m)D(λt | m, λ0)
(14.35)
where
pt(m) = (a + b)m e−m c t
m!
(1 −e−c t)a+b,
and
D(λt|m, λ0) =
m

k=0
Be(λt|a + k, b + m −k) Bin(k|m, λ0)
which again can be seen to correspond to the general class of Beta-binomial diffusion processes
given by the solution of the SDE (14.33). Also, from the Gibbs sampler type construction, it easily
follows that such a process is time reversible and has Be(a, b) stationary distributions.

288
R. H. Mena
Having established our approach for constructing the diffusion process with Be(a, b) marginal
distributions, we can go back to our question regarding the dependent nonparametric process of
Definition 14.6. Let Pg
X ⊂PX be the set of purely atomic probability measures with geometric
weights as in Definition 14.1 and denote CPg
X(X)([0, ∞)) the space of continuous functions from
[0, ∞) to Pg
X. Furthermore, for given locationsZ = {Zi}∞
i=1 define the continuous map Z(λ) =
∞
i=1 λ(1 −λ)i−1δZi.Hence,becauseofthedecreasingorderofthegeometricweightswecanset
−1 = gZ, where gZ(P) = P({Z1}) = λ and let ˜B(a, b) = Be(a, b) ◦−1
X . Therefore we can
state the following proposition whose proof can be found in Mena et al. [40].
Proposition 14.7 Let (Pt)t≥0 be a GSB(a, b, c, P0) process on Pg
X. Then (Pt)t≥0 is reversible and
stationary, with respect to ˜B(a, b), Feller process with sample paths in CPg
X(X)([0, ∞)).
In other words the stability properties of the Wright–Fisher diffusion process are inherited by the
GSB(a, b, c, P0) process at the probability measure-valued level. This is quite intuitive since the
locations(Zi)i≥1 arerandombutfixedacrosstime.Animmediateobservationwouldbethatletting
the Zis vary also leads to a more flexible model. While this is certainly true, we have two reasons
for keeping the locations fixed. On the probabilistic side this would most likely tear apart the nice
properties this process enjoys. But more importantly, on the inference side this is not even needed
in view of Proposition 14.1 and as the example below will show.
All distributional properties of a diffusion process can be explained through its infinitesimal gen-
erator, in particular for the GSB(a, b, c, P0) process the generator can be found in Mena et al. [40],
thus providing a valid alternative to other measure-valued processes found in the literature [cf. 16].
As in the previous section, interest might be on modelling a process taking values on the space of
continuous densities. For this purpose the GSB(a, b, c, P0) process can also be incorporated into
a dependent nonparametric mixture model given by
ft(y) =

f(y | x) Pt(dx) = λt

l≥1
(1 −λt)l−1 f(y | Zl)
(14.36)
withZl
iid∼P0.Infact,forasetofobservationsY(n) recordedattimes{ti}n
i=1 andmodelledthrough
the above dependent density, Mena et al. [40] proposed a Gibbs sampler algorithm based on some
slice sampler techniques that aid to overcome both the infinite summations, the one in (14.36) and
the one in the representation of the Wright–Fisher transition density (14.35). The algorithm is a bit
more demanding than those used in previous sections and so we briefly discuss it.
First, it is convenient to start by considering the part of the model related to the Wright–Fisher
diffusion (λt)t≥0. Hence to overcome the infinite summation in (14.36), we proceed as before and
introduce the latent variable di that indicates the component f(· | Zi) from which the observation
Yi comes from, namely we have the augmented observations (ti, di)n
i=1 and the model can then be
written as
di | λi ∼Geom(λi)
with λi := λti and corresponding transition density p(λi | λi−1) given as in (14.35), where t has to
be replaced by τi = ti −ti−1. Hence, to avoid the infinite summations needed for the transition
(14.35),weintroduceafurthersetoflatentvariables(ui, si, ki)n
i=1 wherebytheaugmentedtransition
density is given by

Geometric weight priors and their applications
289
p(λi, ui, si, ki | λi−1) = I(ui < g(si))pi(si)
g(si) Be(λi | a + ki, b + si −ki)Bin(ki | si, λi−1)
where g is a decreasing function with known inverse. Therefore the likelihood with the complete
data is given by
l(a, b, c) = Be(λ0 | a, b)
n

i=1
p(λi, ui, si, ki | λi−1)λi(1 −λi)si−1
Hence if, for instance, we assume independent standard exponential distributions as priors for
a, b, c,weseethatthefullconditionals,e.g. π(a | b, c, . . .) ∝l(a, b, c)e−a arelog-concaveandeasily
sampled through the ARS algorithm. For instance we have
log π(c | a, b, · · · ) =
n

i=1
{(a + b) log(1 −e−cτ i) −si c τi} −c + O
where O is a constant which does not depend on c. The full conditionals for a and b follow similarly.
The full conditional distribution for ki is given by
π(ki| . . .) ∝
si
ki

1(ki ∈{0, 1, . . . , si})
(a + ki)(b + si −ki)

λiλi−1
(1 −λi)(1 −λi−1)
ki
which is clearly easy to sample since ki can only take a finite number of values. The full conditional
for ui is simply a uniform distribution on (0, g(si)), where g is chosen for convenience, for example
g(s) = e−s or g(s) = s−2, so that g−1 is known. The benefit of this becomes apparent when we
consider the full conditional for si. This is given by
π(si| . . .) ∝pi(si)
g(si)
si
ki
 (a + b + si)
(b + si −ki){(1 −λi−1)(1 −λi)}si 1(ki ≤si ≤g−1(ui))
which by virtue of ui is restricted to a finite set. The full conditional for λi, for i ̸= 0, n, is given by
π(λi| . . .) = Beta(1 + a + ki + ki+1, di −1 + b + si + si+1 −ki −ki+1)
(14.37)
whereas
π(λ0| . . .) = Beta(a + k1, b + s1 −k1)
(14.38)
and
π(λn| . . .) = Beta(1 + a + kn, dn −1 + b + sn −kn).
(14.39)
This deals with the part of the model related to the Wright–Fisher process. For the remaining part
of the model, which, for a given observation, is given by
yi|ti, λi, Z(n) ∼
∞

l=1
λi(1 −λi)l−1f(yi|Zl).

290
R. H. Mena
We proceed as before and introduce two latent variables (si, vi) and a deterministic decreasing
sequence of numbers (ψl) for which {l : ψl > v} is a known set, such that
yi, vi, di|λi, Z(n) ∼ψ−1
di 1(vi < ψdi) λi(1 −λi)di−1 f(yi|Zdi)
Note that we slice the infinite summation again. In order to complete the Gibbs sampler for the
model we need to describe how to sample the si from their full conditionals and also the Zss.
Now,
π(di| . . .) ∝ψ−1
di λi(1 −λi)di−1 f(yi|Zdi) 1(di ∈{l : ψl > vi})
and clearly the full conditional for vi is the uniform distribution on (0, ψdi). Since {l : ψl > vi} is a
finite set this is easy to sample. Finally, we sample the Zls from
f(Zj | · · · ) ∝P0(Zj)

di=j
f(yi | Zj),
for j = 1, . . . , M
(14.40)
Note that, as before, we only need to consider a finite number of location updates (Zl)M
l=1 where
M = maxi Mi and {1, . . . , Mi} = {l : ψl > vi}. We thus have all the full conditional distributions
required to implement the Gibbs sampler needed for the estimation of model (14.36) given a
discretely observed trajectory. The following algorithm summarizes the procedure.
Algorithm.
1. Select g(·) and ψ(·) functions, e.g. g(x) = ψ(x) = e−x
2. Set initial values for:
• Wright–Fisher diffusion parameters (a0, b0, c0)
• Parameters in the kernel K and possibly in P0, e.g. θ0
• Latent variables needed to overcome infinite summations,
(u0
i , s0
i , k0
i , d0
i )n
i=1. For these an initial value for the augmented random probability
measure is also needed, e.g. M0 = 20
• Use these values to initiate λ0 = (λ0
i )n
i=0
then for j = 1, . . . , I
3. Update vj = (vj
i)n
i=0, i.e. vj
i ∼U[0, ψsj−1
i
], and compute
Mj = max Mj
i with {1, . . . , Mj
i} = {l : ψ(l) > vj
i}
4. Update λj = (λj
i)n
i=0, θj = (θj
l )M
l=1 and (uj
i, sj
i, kj
i, dj
i)n
i=1 using the corresponding full condi-
tionals
5. Update (aj, bj, cj), e.g. via ARS algorithm
The I iterations can then be used to build a Monte Carlo estimator for ft or any desired func-
tional of it.
Example 14.8 In order to illustrate how the modelling scheme described above is able to cap-
ture the dynamics of continuous time phenomena, we will consider data coming from 251 daily
observations (corresponding to a financial year) from the adjusted close quotations of the S&P 500
index during the period 03.03.2008 to 27.02.2009 (the dataset can be found at http://finance.yahoo.
com).

Geometric weight priors and their applications
291
These types of data are typically modelled through parametric diffusion processes, however,
one could argue to what extent such restrictive assumptions are justified. For example, in the case
of interest rates one could choose among many existing models, such as the Cox–Ingersoll–Ross
(CIR) diffusion, the Brennan–Schwartz diffusion or the Duffie–Kan diffusion (see Aït-Sahalia
[1]). Adopting a nonparametric approach based on measure-valued processes provides enough
flexibility to avoid such limiting assumptions.
As in our previous examples we use the kernel and prior guess at the shape specifications given
by (14.13) and concentrate on the mean functional ηt :=

y ft(y)dy, namely the evolution of the
mean, which imitate that of a one-dimensional diffusion process. Figure 14.7 shows the MCMC
estimates (heat contours) for the density process, ˆft, and the corresponding mean of the functional
¯ηt (solid line) for the S&P 500 dataset (points). For both datasets the choice of hyperparameters
was τ = 1000 and (α, β) = (10, 1). The results are based on 100 000 iterations, after a 20 000 of
burn-in (thinned each 10), enough to attain a satisfactory convergence of the sampler. Figure 14.8
shows the Markov chains corresponding to parameters (a, b) and the corresponding posterior
densities; the results corresponding to c are proportional to those corresponding to b. A standard
convergence analysis was performed, in particular the Gelman and Rubin [24] visual test and the
Raftery and Lewis [46] diagnosis test were satisfactory.
It is apparent that the probability measure-valued approach here undertaken is able to capture the
dependence induced by these datasets. Furthermore the model adapts well to drastic changes like
those observed in the S&P 500 index and typically not captured by the (parametric) diffusion
process. Note that the strict stationary and reversibility properties of the GSB(a, b, c, P0) process
Figure 14.7 MCMC density estimator for the random density process (14.36), ˆft, (heat contour),
mean of mean functional ¯ηt (solid) for the S&P 500 dataset (dots). The estimates are based on
10 000 effective iterations, drawn from 100 000 iterations thinned each 10, of the Gibbs sampler
algorithm after 20 000 iterations of burn-in.

292
R. H. Mena
0
2000
4000
6000
8000 10000 12000
0
2000
4000
6000
8000 10000 12000
1
2
3
4
5
6
a
1
2
3
4
5
6
0.0
0.2
0.4
0.6
0.8
a
5
10
15
20
b
5
10
15
20
0.0
0.1
0.2
0.3
0.4
0.5
0.6
b
Figure 14.8 MCMC iterations and posterior densities for parameters (a, b). The estimates are based
on 10 000 effective iterations, drawn from 100 000 iterations thinned each 10 iterations, of the Gibbs
sampler algorithm after 20 000 iterations of burn-in.
are at the probability measure-valued level and not at the level of observations, therefore certain
sudden changes of regime and unstable behaviours might be well captured by this model without
compromising the measure-valued stationarity property.
14.4 Discussion
We have seen that r.p.m.s with simpler weights structure are able to provide good alternatives to
more complex nonparametric priors. The key idea is that having simpler weights results in a more
efficient use of the infinite collection of locations to assign the required mass to a particular set
B ∈X. Having simpler weights also results in easier ways to estimate models and extend them to
non-exchangeable contexts, as seen in Section 14.3.
Although for simplicity we have mainly concentrated on the geometric weights case, several
generalizations are possible, for instance one could consider the expected weights corresponding to

Geometric weight priors and their applications
293
the two-parameter Poisson–Dirichlet process, i.e.with corresponding stickbreaking weights (14.4),
with vi
ind
∼Be(1 −σ, θ + iσ), which implies
ωi =
1 −σ
θ + 1 + (i −1)σ
i−1

j=1
θ + jσ
θ + 1 + (j −1)σ
and then (σ, θ) ∼π. Furthermore, using the alternative derivation in Section 14.2.1 we could have
a different choice of prior for N, e.g. N ∼Neg-Bin(r, λ) which would lead to
wl = 1
l
l + r −2
r −1

λr(1 −λ)l−1 2F1(1, l + r −1; l + 1; λ)
(14.41)
where 2F1(a, b; c; λ) denotes the Gauss hypergeometric function. Both of the above possibilities
areclearlymoregeneralthanthegeometricweightswhilekeepingtheirdecreasingfeature,however
some algorithmic modifications would be needed when randomizing their parameters.
We have also seen that from a numerical point of view having a simpler r.p.m. such as the GWP
mightleadtomoreefficientposteriorinferencesthanthoseobtainedviaothernonparametricpriors
such as the Dirichlet process. Another appealing feature of the simplicity inherent to the GWP is
that it is easily generalized to dependent nonparametric processes. This is in principle conceivable
with other more complicated r.p.m.s such as the Dirichlet process; however, keeping a canonical
construction of the resulting dependent process is not necessarily straightforward. In fact, to the
best of our knowledge, Section 14.3.2 presents the first instance of a measure-valued Markovian
process applied to model single trajectory phenomena (cf. Example 14.8).
Acknowledgements
The author wishes to thank the hospitality and support of Collegio Carlo Alberto during the
preparation of this paper. The author was also partially supported by projects CONACyT 131179
and PAPIIT IN100411.
References
[1] Aït-Sahalia, Y. (1996). Nonparametric pricing of interest rate derivative securities. Economet-
rica, 64, 527–560.
[2] Aoki, M. (2004). Modeling Aggregate Behavior and Fluctuations in Economics: Stochastic Views
of Interacting Agents. Cambridge University Press.
[3] Banfield, J. D. and Raftery, A. (1993). Model-based Gaussian and non-Gaussian clustering.
Biometrics, 49, 803–821.
[4] Berry, D. A. and Christensen, R. (1979). Empirical Bayes estimation of a binomial parameter
via mixtures of Dirichlet processes. Annals of Statistics, 7, 558–568.
[5] Bibby, M., Skovgaard, M. and Sørensen, M. (2005). Diffusion-type models with given
marginal distribution and autocorrelation function. Bernoulli, 11, 191–220.
[6] Blackwell, D. (1973). Discreteness of Ferguson selections. Annals of Statistics, 1, 356–358.
[7] Blackwell, D. and MacQueen, J. B. (1973). Ferguson distributions via Pólya urn schemes.
Annals of Statistics, 1, 353–355.

294
R. H. Mena
[8] Caron, F., Davy, M., Doucet, A., Duflos, E. and Vanheeghe, P. (2006). Bayesian inference for
dynamic models with Dirichlet process mixtures. In International Conference on Information
Fusion, pp. 1–8. Florence, Italy: INRIA-CCSd-CNRS.
[9] Cox, J. C., Ingersoll, J. E. and Ross, S. A. (1985). A theory of the term structure of interest rates.
Econometrica, 53, 385–407.
[10] De Iorio, M., Müller, P., Rosner, G. L. and MacEachern, S. N. (2004). An ANOVA model for
dependent random measures. Journal of the American Statistical Association, 99, 205–215.
[11] Dunson, D. B., Pillai, N. and Park, J. -H. (2007). Bayesian density regression. Journal of the
Royal Statistical Society. Series B, 69, 163–183.
[12] Dunson, D. B. and Park, J. -H. (2008). Kernel stick-breaking processes. Biometrika, 95,
307–323.
[13] Escobar, M. D. (1988). Estimating the means of several normal populations by nonparametric
estimation of the distribution of the means. Unpublished Ph.D. dissertation, Department of
Statistics, Yale University.
[14] Escobar, M. D. (1994). Estimating normal means with a Dirichlet process prior. Journal of the
American Statistical Association, 89, 268–277.
[15] Escobar,M.D.andWest,M.(1995).Bayesiandensityestimationandinferenceusingmixtures.
Journal of the American Statistical Association, 90, 577–588.
[16] Ethier, S. N. and Kurtz, T. G. (1986). Markov Processes: Characterization and Convergence.
Wiley Series in Probability and Mathematical Statistics. John Wiley & Sons Inc. New York.
[17] Ewens, W. (1972). The sampling theory of selectively neutral alleles. Theoretical Population
Biology, 3, 87–112.
[18] Ewens, W. J. and Tavarè, S. (1997). Multivariate Ewens distribution. In Discrete Multivariate
Distributions (eds N. S. Johnson, S. Kotz and N. Balakrishnan), Wiley, New York.
[19] Feigin, P. D. and Tweedie, R. L. (1989). Linear functionals and Markov chains associated
with Dirichlet processes. Mathematical Proceedings of the Cambridge Philosophical Society, 105,
579–585.
[20] Ferguson, T. S. (1973). A Bayesian analysis of some nonparametric problems. Annals of Statis-
tics, 1, 209–230.
[21] Fuentes-García, R., Mena, R. H. and Walker, S. G. (2009). A nonparametric dependent pro-
cess for Bayesian regression. Statistics and Probability Letters, 8, 112–119.
[22] Fuentes-García, R., Mena, R. H. and Walker, S. G. (2010). A new Bayesian nonparametric
mixture model. Communications in Statistics – Simulation and Computation, 39, 669–682.
[23] Gelfand, A. E., Kottas, A. and MacEachern, S. N. (2005). Bayesian nonparametric spatial
modeling with Dirichlet process mixing. Journal of the American Statistical Association, 100,
1021–1035.
[24] Gelman, A. and Rubin, D. (1992). Inferences from iterative simulation using multiple
sequences. Statistical Inference, 7, 457–472.
[25] Gilks, W. R. and Wild, P. (1992). Adaptive rejection sampling for Gibbs sampling. Applied
Statistics, 41, 337–348.
[26] Griffin, J. E. and Steel, M. F. J. (2006). Order-based dependent Dirichlet processes. Journal of
the American Statistical Association, 101, 179–194.
[27] Griffin, J. E. and Steel, M. F. J. (2010). Stick-breaking autoregressive processes. Journal of
Econometrics, 162, 383–396.
[28] Hansen, J. C. (1994). Order statistics for decomposable combinatorial structures. Random
Structures and Algorithms, 5, 517–533.
[29] Hjort, N., Holmes, C., Müller, P. and Walker, S. G. (2010). Bayesian Nonparametrics. Cam-
bridge University Press.
[30] Ishwaran, H. and James, L. F. (2001). Gibbs sampling methods for stick-breaking priors.
Journal of the American Statistical Association, 96, 161–173.

Geometric weight priors and their applications
295
[31] Kalli, M., Griffin, J. E. and Walker, S. G. (2011). Slice sampling mixture models. Statistics and
Computing, 21, 93–105.
[32] Lau, W. L. and Green, P. L. (2007). Bayesian model-based clustering procedures. Journal of
Computational and Graphical Statistics, 16, 526–558.
[33] Lenk, P. (1988). The logistic normal distribution for Bayesian, nonparametric, predictive
densities. Journal of the American Statistical Association, 83, 509–516.
[34] Lijoi, A., Mena, R. H. and Prünster, I. (2005). Hierarchical mixture modelling with normal-
ized inverse Gaussian priors. Journal of the American Statistical Association, 100, 1278–1291.
[35] Lijoi, A., Mena, R. H. and Prünster, I. (2007). Bayesian nonparametric estimation of the
probability of discovering new species. Biometrika, 94, 769–786.
[36] Lijoi, A., Mena, R. H. and Prünster, I. (2007). Controlling the reinforcement in Bayesian
non-parametric mixture models. Journal of the Royal Statistical Society. Series B, 69,
715–740.
[37] Lijoi, A., Prünster, I. (2010). Models beyond the Dirichlet process. In Bayesian Nonparamet-
rics (eds N. L. Hjort, C. C. Holmes, P. Müller, and S. G. Walker), Cambridge University
Press.
[38] Lo, A. Y. (1984). On a class of Bayesian nonparametric estimates: I. Density estimates. Annals
of Statistics, 12, 351–357.
[39] Mena, R. H. and Walker, S. G. (2009). On a construction of Markov models in continuous
time. METRON – International Journal of Statistics, LXVII, 303–323.
[40] Mena, R. H., Ruggiero, M. and Walker, S. G. (2011). Geometric stick-breaking processes for
continuous-time Bayesian nonparametric modeling. Journal of Statistical Planning and Infer-
ence, 141, 3217–3230.
[41] MacEachern, S. N. and Müller, P. (1998). Estimating mixtures of Dirichlet process models.
Journal of Computational and Graphical Statistics, 7, 223–238.
[42] MacEachern, S. N. (1999). Dependent nonparametric processes. In ASA Proceedings of the
Section on Bayesian Statistical Science, pp. 50–5. Alexandria, VA: American Statistical Associa-
tion.
[43] Ongaro, A. and Cattaneo, C. (2004). Discrete random probability measures: a general frame-
work for nonparametric Bayesian inference.Statistics and Probability Letters, 67, 33–45.
[44] Petrone, S., Guindani, M. and Gelfand, A. E. (2009). Hybrid Dirichlet mixture models for
functional data. Journal of the Royal Statistical Society. Series B, 71, 755–782.
[45] Pitman, J. (1996). Some developments of the Blackwell–MacQueen urn scheme. Statistics,
Probability and Game Theory. Papers in honor of David Blackwell, 30, 245–267.
[46] Raftery, A. and Lewis, S. (1992). One long run with diagnostics: Implementation strategies
for Markov chain Monte Carlo. Statistical Inference, 7, 493–497.
[47] Regazzini, E., Lijoi, A. and Prünster, I. (2003). Distributional results for means of random
measures with independent increments. Annals of Statistics, 31, 560–585.
[48] Richardson, S. and Green, P. J. (1997). On Bayesian analysis of mixtures with an unknown
number of components (with discussion). Journal of the Royal Statistical Society, Series B, 59,
731–792.
[49] Rodriguez, A. and Ter Horst, E. (2008). Bayesian dynamic density estimation. Bayesian Anal-
ysis, 3, 339–366.
[50] Rodriguez, A. and Dunson, D. (2011). Nonparametric Bayesian models through probit
stick-breaking processes. Bayesian Analysis, 6, 145–178.
[51] Sethuraman, J. (1994). A constructive definition of Dirichlet priors. Statistica Sinica, 4,
639–650.
[52] Sethuraman, J. and Tiwari, R. (1982). Convergence of Dirichlet measures and the interpreta-
tion of their parameter. Proc. Third Purdue Symp. Statist. Decision Theory and Related Topics,
(eds S. S. Gupta and J. Berger), Academic Press NY.

296
R. H. Mena
[53] Walker, S. G. (2007). Sampling the Dirichlet mixture model with slices. Communications in
Statistics – Simulation and Computation, 36, 45–54.
[54] Walker, S. G., Damien, P., Laud, P. W. and Smith, A. F. M. (1999). Bayesian nonparametric
inferenceforrandomdistributionsandrelatedfunctions.JournaloftheRoyalStatisticalSociety.
Series B, 61, 485–527.
[55] Walker, S. G. and Mallick, B. (1997). A note of the scale parameter of the Dirichlet process.
The Canadian Journal of Statistics, 25, 473–479.

15
Revisiting Bayesian
curve fitting using
multivariate normal
mixtures∗
stephen g. walker
and george karabatsos
15.1 Introduction
T
here has been a significant amount of recent research on Bayesian nonparametric regression
models. This has primarily focused on developing models of the form
f(y|x) =
∞
j=1 wj(x) K(y|x, θj(x))
where K(y|x, θ) is a chosen parametric density function, the wj(x) are mixture weights that sum to 1
ateveryvalueofthecovariatevectorx ∈X,andwithapriordistributiononweights{wj(x)}j=1,2,...
and atoms {θj(x)}j=1,2,..., that are an infinite collection of processes indexed by X. The literature
on these models has exploded even in the last few years (see for example, [13]–[15], [2]–[8],
[20], [11]).
Ourthesisisthatitisaverydifficulttasktospecifythesecomponents;i.e.thewj(x)andK(y|x, θ).
It is almost limitless in possibilities and over-fitting and un-identifiability are serious issues. There
needs to be some guide as to how to choose the components of the regression model.
An intuitive approach to Bayesian nonparametric regression was proposed by [17]. The idea is
to specify a Dirichlet process mixture model for the joint density f(y, x), with mixture weights and
atoms independent of x ([12]). This would lead to a standard infinite mixture model treating the
(yi, xi) as independent and identically distributed observations. This would not be a controversial
choice of model.
In this case one would employ the likelihood function

i f(yi, xi)
∗This research is supported by National Science Foundation grant SES-1156372.

298
S. G. Walker and G. Karabatsos
as used in [17]. However, when the aim is regression the appropriate likelihood function is
given by

i f(yi, xi)/f(xi) =

i f (yi|xi)
To see this we simply note that there are two likelihood functions here and they are not the same.
It is also clear that for regression purposes we are interested in the conditional density f(y|x) and it
is this that should form the basis of the likelihood function.
It is then possible to note, and we will see this later, that the weights wj(x) take a particular form
which has not appeared in the literature:
wj(x) =
wj K(x|θj)

j wj K(x|θj)
The reason why such a simple, motivated and useful regression model has not appeared in the
literature is due to the posterior distribution having an intractable normalizing constant. Inference
is complicated by the uncomputable integrals in the normalizing constant. Previous authors ([18],
Section 3.3) chose to avoid this complication by proposing a modified prior distribution such that,
when combined with the correct likelihood, yields a posterior distribution that is identical to the
posterior of the original model.
The aim in this paper is to show how it is possible to use the correct likelihood for regression
by describing how to deal with the problem of the normalizing constant. This uses ideas recently
introduced in [22] which shows how latent variables can be used to construct a latent model that
can be studied using Markov chain Monte Carlo (MCMC) methods. The aim is not to compare
the model with other models; we take it for granted, based on the work of [17], that the model is
going to be useful.
The layout of the paper is as follows: Section 15.2 fully describes our regression model, and the
methods for sampling the posterior distribution of the model. To obtain full posterior inference
of the model, a reversible-jump sampling algorithm ([22]) is used to deal with the uncomputable
normalizing constant. In Section 15.3 we illustrate our model through data analysis.
15.2 The regression model and modelling methods
15.2.1 The model
First we describe the model for (y, x) which is a standard Bayesian nonparametric mixture model
based on the mixture of Dirichlet process model. If we take the normal density as the kernel
density; i.e.
n(y|μj, )
so
f(y, x) =

j
wj n (y, x|μj, )
where the (wj) are stick-breaking weights, that is, wj = λj
	j−1
l=1(1 −λl), λj ∈[0, 1], for j ≥1
([21]). As mentioned, such a modelling approach was taken by [17]. However, for regression mod-
elling, the ‘correct’ likelihood function is

Revisiting Bayesian curve fitting
299
n

i=1
f(yi|xi)
Hence, given data Dn = {(xi, yi)}n
i=1, we arrive at
f(y|x) = f(y, x)
p(x) =

j n(y, x|μj, ) wj

j n(x|μxj, x) wj
(15.1)
To elaborate, the f(y, x) has a numerator as though

y
x

= n

μyj
μxj

,

σ2y
ρyx
ρyx
x

and μj = (μyj, μx,j) and
 =

σ 2y
ρyx
ρyx
x

But the likelihood does not assume that the xs are randomly generated. It is obviously a valid
likelihood since if we integrate out the (yi) we get 1. But it is strictly a regression model which
has motivation when it is acknowledged that constructing f(y|x) is problematic and guidelines are
required. Of course, if the xs are randomly generated then the model is fully motivated.
The model is completed by the specification of prior densities λj ∼ind beta(aj, bj) and μj ∼ind
πj(μj), j = 1, 2, . . ., and  ∼π(). The choice of (aj, bj) will be discussed later but we point
out now that the choice of aj = 1 and bj = b > 0 leads to the Dirichlet process. Also, a default
choice of priors for the mean and covariance matrix (μj, ) is given by a multivariate normal
and inverted-Wishart prior densities, i.e. μj ∼iid nq(μμ, μ) and  ∼iwq(ν, T), with q =
dim(y, x), with (1/{ν −q −1})T as the mean of the inverted-Wishart density.
We need the denominator of the likelihood, as it contains parameters. It would appear that we
would not be able to do inference due to the intractable nature of the denominator, but it turns out
that inference is possible by defining a suitable latent model.
If we write
f(x) = |x|−1/2
∞

j=1
wj m(x; μxj, x)
where
m(x; μxj, x) = exp

−0.5(x −μxj)⊤−1
x (x −μxj)

then we can easily note that
m(x) =
∞

j=1
wj m(x; μxj, x) < 1

300
S. G. Walker and G. Karabatsos
And this will be the key to appropriately dealing with the denominator. The idea is that for any
0 < ζ < 1 it is that
∞

k=0
(1 −ζ)k = ζ −1
Hence, we can represent the denominator at a generic x value as
|x|1/2
∞

k=0
(1 −m(x))k
and hence we can represent the 	
i f(xi) as
|x|n/2
n

i=1
ki

l=1
wdil(1 −m(xi; μxi dil, x))
For now if we sum over the dil, i.e. for each i and l ∈{1, . . . , ki}, we have dil ∈{1, 2, . . .}, then we
recover
|x|n/2
n

i=1
(1 −m(xi))ki
and if we now sum over each ki ∈{0, 1, 2, . . .} then we recover
|x|n/2
n

i=1
m−1(xi)
which is precisely
n

i=1
f −1(xi)
Specifically, after introducing latent variables (ui, uil, vil, di, dil, ki), the likelihood becomes:
|x|n/2
n

i=1
8
1

0 < ui < ξdi

wdiξ−1
di n(yi, xi; μdi, )
(15.2)
×
ki
l=1 1(0 < uil < 1 −exp[−.5(xi −μxdil)⊤−1
x (xi −μxdil)]),
× 1(0 < vil < ξdil)wdil ξ−1
dil
9
(15.3)
where 1(·) is the indicator function, and ξj is a fixed decreasing function, such as ξj = exp(−j).
This slicing strategy is to force the (di), and also the (dil) to be bounded and hence can be sampled
in a MCMC algorithm. See [10] for a discussion on the choice of (ξj). It is easy to show that
marginalizing over the latent variables yields the correct likelihood f(y|x) of the regression model,

Revisiting Bayesian curve fitting
301
asin(15.1).Importantly,thecombineduseof ξ withthelatentvariablesfacilitatesMCMCsampling
of the posterior distribution of the infinite-dimensional regression model.
15.2.2 MCMC sampling
For the regression model, an MCMC sampling algorithm is used to iteratively and repeatedly sam-
ple from its full conditional posterior distributions. Let 1N(j) be the function indicating whether
j ∈{1, . . . , N}. Given the likelihood (15.2), the full conditional posterior distributions are given
below, for i = 1, . . . , n, j = 1, . . . , N, and l = 1, . . . , ki.
π(ui| · · · ) ∝1(0 < ui < ξdi);
π(uil| · · · ) ∝1(0 < uil < 1 −exp{−.5(xi −μxdil)⊤−1
x (xi −μxdil)});
π(vil| · · · ) ∝1(0 < vil < ξdil);
π(λj| · · · ) = beta
aj + #(di = j) + #(dil = j),
bj + #(di > j) + #(dil > j)

1N(j)
Pr

di = j| · · ·

∝wjξ−1
j
n(yi, xi; μj, )1Ni(j);
Pr(dil = j| · · · ) ∝wjξ−1
j
{1 −exp[−.5(xi −μxj)⊤−1
x
(xi −μxj)]}1Nil(j);
π(μj| . . .) ∝πj(μj)1N(j)

di=j
n(yi, xi|μdi, )
×

dil=j
1

uil < 1 −exp[−.5(xi −μxdil)⊤−1
x (xi −μxdil)]

;
π(| · · · ) ∝π()|x|n/2
 n

i=1
n(yi, xi|μdi, )

×
n

i=1
ki

l=1
1

uil < 1 −exp[−.5(xi −μxdil)⊤−1
x (xi −μxdil)]

Importantly, since ξj is a decreasing function, we can define finite values of N = max[maxi Ni,
maxi,l Nil], Ni = maxj j1(0 < ui < ξj), Nil = maxj j1(0 < vil < ξj). Therefore, conditional on
latent variables (di, dil, ui, uil, vil, ki), posterior sampling proceeds as if the infinite mixture model
were a finite-dimensional model, as in [10]. All full conditionals can be easily sampled. The
nonstandard full conditional densities p(μj| . . .) are each sampled using the random-walk
Metropolis–Hastings algorithm, with normal proposal density nq(μj, diag(v1, . . . , vq)) having
variances (v1, . . . , vq) automatically adapted to achieve the desired acceptance rate of 0.44 for each
respective component of μ over MCMC iterations, using a Robbins–Monro algorithm (see [1]).
Also,whenthemodelisassignedprior ∼iwq(ν, T),thenonstandardfullconditionalposterior
density π(| · · · ) can be sampled using an independent Metropolis–Hastings algorithm, with
iwq(ν, cT) as the proposal density for some chosen constant c > 0.
The sampling of the full conditional distribution Pr(ki| · · · ) requires reversible-jump MCMC
methods ([22]), because the dimensionality of the model parameters changes with ki. In particular,
using the full set (uil, vil, dil)∞
l=1 we construct the following joint density

302
S. G. Walker and G. Karabatsos
p(ki, (uil, vil, dil)∞
l=1| · · · ) ∝
ki

l=1
1

0 < uidil < 1 −exp
1 −.5(xi −μxdil)⊤
×−1
x (xi −μxdil)
2
×
ki

l=1
1Nil(dil)1(0 < vil < ξdil) wdilξ−1
dil
×
∞

l=ki
p(ui,l+1, vi,l+1, di,l+1|uil, vil, dil),
where the last term is a product of densities, each serving as a proposal density, which could be
chosen as an independent (proposal) density:
p(ui,l+1, vi,l+1, di,l+1|uil, vil, dil) = p(ui,l+1, vi,l+1, di,l+1) = 1Nil(di,l+1)1(0 < vi,l+1 < ξdi,l+1)
×
1(0 < uidi,l+1 < 1 −exp[−.5(xi −μxdi,l+1)⊤−1
x (xi −μxdi,l+1)])
1 −exp[−.5(xi −μxdi,l+1)⊤−1
x (xi −μxdi,l+1)]
.
ThengiventhattheMCMCchainisatstateki,aproposalismadetomovetostateki + 1withprob-
ability q(ki + 1|ki), and given a sample (ui,ki+1, vi,ki+1, di,ki+1) from p(ui,ki+1, vi,ki+1, di,ki+1),
this proposal is accepted with probability
min
⎡
⎣1,
wdi,ki+1ξ−1
di,ki+1{1 −exp[−.5(xi −μxdi,ki+1)⊤−1
x (xi −μxdi,ki+1)]}
q(ki + 1|ki)/q(ki|ki + 1)
⎤
⎦
Otherwise, with probability q(ki −1|ki), a proposal is made to move to state ki −1, and this
proposal is accepted with probability
min
⎡
⎣1,
q(ki|ki −1)/q(ki −1|ki)
wdiki ξ−1
diki {1 −exp[−.5(xi −μxdiki )⊤−1
x (xi −μxdiki )]}
⎤
⎦.
Wecandefinetheproposaldistributionbyq(1|0) = 1,q(0|1) = 0,andq(k′|k) = .5for k > 0and
for all |k′ −k| = 1.
Finally, the full conditional posterior (predictive) density of Yi (i = 1, . . . , n) is:
n(μydi +
p
s=1(xsi −μxsdi)/y, 1/y),
with  = −1, following known results involving a univariate conditional distribution of a mul-
tivariate normal density. Also, the predictive accuracy of the model can proceed via the evaluation
of standardized residuals (yi −μydi)1/2
y
, i = 1, . . . , n.
To conduct MCMC sampling of the model, we wrote code in MATLAB (2011, The MathWorks,
Natick, MA).

Revisiting Bayesian curve fitting
303
15.3 Illustrations
In this section we illustrate our model through the analysis of simulated and real data. In each
illustration, we have rescaled y and each covariate xs (s = 1, . . . , p) to have mean 0 and variance
1 prior to model fitting, assigned prior densities λj ∼ind beta(1/2, 1/2 + j/2), μj ∼iid nq(0, I)
(j = 1, 2, . . .), and  ∼iwq(q + 2, I) to the parameters of the regression model, and chosen an
inverted-Wishart iwq(ν, .5T) proposal density for the independent Metropolis sampling of  in
the MCMC algorithm. Hence, a Poisson–Dirichlet (Pitman–Yor) process prior was assigned to the
mixture weights λj (e.g., [9]). Also, all results are reported on the original scale of y and x. Finally,
for each data illustration, we have estimated the regression model based on 20 000 samples of the
MCMC algorithm, long after the predictions of the model seemed to stabilize over the MCMC
iterations.WeestimatethepredictionsofthemodelfromeveryfifthMCMCsampleofitspredictive
distribution.
15.3.1 Simulation
Wefirstillustratethemodelthroughtheanalysisofasimulateddatasetwith61observations,coming
fromYi ∼n(0.2x3
i , 0.25),withx1 = −3,x2 = −2.9,. . . ,xn−1 = 2.9,xn = 3.Figure15.1presents
the simulated data, and for the model, presents the estimate of the posterior predictive mean and
interquartile range of Y conditional on each of the observed values of x. We see that the range
captures the small number of simulated data points.
15.3.2 Crime Data
Here we present an analysis of a dataset described in [16], consisting of information on urban
population percentage, the number of murder arrests, assault arrests, and rape arrests per
−3
−2
−1
0
1
2
3
−6
−4
−2
0
2
4
6
x
y
Figure 15.1 Simulated example. From the posterior predictive distribution of the model, the mean
(solid line) and interquartile range (dashed lines) of Y, conditional on values of x.

304
S. G. Walker and G. Karabatsos
100
200
300
0
5
10
15
Assault
Murder
Urban<66, Rape<20.1
40
60
80
0
5
10
Urban %
Assault<159, Rape<20.1
10
15
20
0
5
10
Rape
Assault<159, Urban<66
100
150
200
2468
10
12
Assault
Murder
Urban>=66, Rape<20.1
50
60
70
80
5
10
15
Urban %
Assault>=159, Rape<20.1
20
30
40
5
10
15
Rape
Assault>=159, Urban<66
150
200
250
5
10
15
Assault
Murder
Urban<66, Rape>=20.1
65
70
75
80
5
10
Urban %
Assault<159, Rape>=20.1
15
20
25
2468
10
Rape
Assault<159, Urban>=66
100
200
300
5
10
15
Assault
Murder
Urban>=66, Rape>=20.1
50
60
70
80
90
5
10
15
Urban %
Assault>=159, Rape>=20.1
10
20
30
40
5
10
15
Rape
Assault>=159, Urban>=66
Figure 15.2 Crime data. Estimates of the posterior predictive mean of Y, conditional on values of
the three covariates.
100 000 people, for each of the n = 50 U.S. states during the year 1973. This ‘USArrests’ dataset was
obtained from the datasets package of the R software ([19]). We treat murder rate as the dependent
variable, and the other three variables as covariates.
From the regression model, Figure 15.2 presents estimates of the posterior predictive mean of
Y, conditional on values of the three covariates. The figure shows that there is generally a positive
correlationbetweenassaultarrestsandrapearrestswithmurderarrests,andthattherearenonlinear
and interactive relationships between each of the three covariates and murder arrests. Also, an
inspection of the posterior predictive distribution of the standardized residuals revealed that there
were no outliers in the model.
15.4 Discussion
In this paper, we have developed a Bayesian nonparametric regression model which relies on a
standard Bayesian nonparametric form for the joint distribution of both the dependent and inde-
pendent variables. The regression model then is available as a conditional density which can only
be written as a ratio of two infinite-dimensional mixture models.
While this model has been acknowledged as desirable, its drawback has been the intractability
of the likelihood, specifically the denominator of the likelihood. However, recent advances in both
latent models for dealing with normalizing constants and simulation techniques linking slice sam-
pling and infinite mixture models have now rendered this model tractable.

Revisiting Bayesian curve fitting
305
References
[1] Atchadé,Y.F.andRosenthal,J.S.(2005).OnadaptiveMarkovchainMonteCarloalgorithms.
Bernoulli, 11, 815–828.
[2] Chung, Y. and Dunson, D. B. (2009). Nonparametric Bayes conditional distribution mod-
elling with variable selection. Journal of the American Statistical Association, 104, 1646–1660.
[3] DeIorio, M., Müller, P., Rosner, G. L. and MacEachern, S. N. (2004). An ANOVA model for
dependent random measures. Journal of the American Statistical Association, 99, 205–215.
[4] Dunson, D. and Park, J.-H. (2008). Kernel stick breaking processes. Biometrika, 95, 307–323.
[5] Fuentes-García, R., Mena, R. H. and Walker, S. G. (2010). A new Bayesian nonparametric
mixture model. Communications In Statistics, 39, 669–682.
[6] Gelfand, A. E., Kottas, A. and MacEachern, S. N. (2005). Bayesian nonparametric spatial
modelling with Dirichlet processes mixing. Journal of the American Statistical Association, 100,
1021–1035.
[7] Griffin, J. E. and Steel, M. F. J. (2006). Order-based dependent Dirichlet processes. Journal of
the American Statistical Association, 101, 179–194.
[8] Griffin, J. E. and Steel, M. F. J. (2010). Bayesian nonparametric modelling with the Dirichlet
process regression smoother. Statistica Sinica, 20, 1507–1527.
[9] Ishwaran, H. and James, L. F. (2001). Gibbs sampling methods for stick-breaking priors.
Journal of the American Statistical Association, 96, 161–173.
[10] Kalli, M., Griffin, J. and Walker, S. G. (2010). Slice sampling mixture models. Statistics and
Computing, 21, 93–105.
[11] Karabatsos, G. and Walker, S. G. (2011). Adaptive-modal Bayesian nonparametric regression.
Technical report, University of Illinois, Chicago.
[12] Lo, A. Y. (1984). On a class of Bayesian nonparametric estimates. Annals of Statistics, 12,
351–357.
[13] MacEachern, S. N. (1999). Dependent nonparametric processes. Proceedings of the Bayesian
Statistical Sciences Section of the American Statistical Association, 50–55.
[14] MacEachern, S. N. (2000). Dependent Dirichlet Processes. Technical report, Department of
Statistics, The Ohio State University.
[15] MacEachern,S.N.(2001).Decisiontheoreticaspectsofdependentnonparametricprocesses.
In Bayesian Methods with Applications to Science, Policy and Official Statistics (ed. E. George),
Creta, pp. 551–560. International Society for Bayesian Analysis.
[16] McNeil, D. R. (1977). Interactive Data Analysis. John Wiley, New York.
[17] Müller, P., Erkanli, A. and West, M. (1996). Bayesian curve fitting using multivariate normal
mixtures. Biometrika, 83, 67–79.
[18] Müller, P., Quintana, F. A. and Rosner, G. (2004). A method for combining inference across
related nonparametric Bayesian models. Journal of the Royal Statistical Society, Series B, 66,
735–749.
[19] R Development Core Team (2011). R: A Language and Environment for Statistical Computing.
R Foundation for Statistical Computing, Vienna, Austria.
[20] Rodriguez, A. and Dunson, D. B. (2011). Nonparametric Bayesian models through probit
stick-breaking processes. Bayesian Analysis, 6, 1–34.
[21] Sethuraman, J. (1994). A constructive definition of Dirichlet priors. Statistica Sinica, 4,
639–650.
[22] Walker, S. G. (2011). Posterior sampling when the normalizing constant is unknown. Commu-
nications in Statistics: Simulation and Computation, 40, 784–792.

This page intentionally left blank 

Part VII
Spline Models and Copulas

This page intentionally left blank 

16
Applications of Bayesian
smoothing splines
sally wood
Over the last two decades there has been an explosion in the development and application of
Bayesian smoothing techniques. The purpose of this chapter is to show how Bayesian smoothing
splines together with the data augmentation techniques of [37] and [13] can be used to address
several important practical problems. The chapter begins with a brief introduction to Bayesian
smoothing splines and then shows how they can be used in a variety of applied settings, including
medical diagnosis, climatology and astronomy.
16.1 Smoothing Splines. The basics
T
here are many ways to think about smoothing splines, [14] and [11] provide comprehensive
and clear discussions on the topic, motivated from a roughness penalty approach. In this
chapter we take a related but slightly different approach; we motivate the concept by asking what
type of prior information do we need to impose on a function, so that, given some data, an estimate
of this function will have desirable properties.
Suppose that an observation, yi, is generated from a signal g which depends upon a covariate
value, xi, plus noise, ei, so that
yi = g(xi) + ei
(16.1)
In a Bayesian context a natural estimate of a function is its posterior mean, and we would like to
select a prior for g so that this estimate has the following two properties:
1. The estimate of g is a smooth function, and
2. The prior is flexible enough to give good estimates for a large range of functions.
Choosing a parametric form for g, for example, taking g as a linear function satisfies the first require-
ment, but not the second.
One way to impose prior information on a function is to decompose the function into two
components. The first component is a polynomial of degree m −1 and the second is a Gaussian
stochastic process, which represents departures from this polynomial, see [41], and [11] for details.
One example is,

310
S. Wood
g(xi) =
m−1

k=0
αkxk
i + f(xi)
f(x) = (τ2)1/2
 x
0
(x −v)(m−1)
(m −1)!
dW(v)
(16.2)
where the notation a(m) means the mth derviative of a, W is a Wiener process with W(0) = 0,
and var(W(x)) = x. This prior states that f(x) has a normal distribution with a mean of zero
and covariance matrix m, where τ2ωmij = cov(f(xi), f(xj)) is the (i, j)th element of τ2m. The
values of ωmij for m = 1 and m = 2 are,
ωmij = x2
i (xj −xi/3)/2 for (xi ≤xj) if m = 2;
= min(xi, xj) if m = 1.
(16.3)
In (16.2) the parameter τ2 controls the curvature of f and is called a smoothing parameter. The
advantage of expressing the prior as a random function with a specific covariance structure is that
many other forms of smoothing can be similarly expressed. For example kriging can be expressed
as a smoothing spline, see [23] for details.
Iftheprioronα = (α0, . . . , αm−1)isdiffuse,forexampleα ∼N(0, cαIm),withcα →∞,then
the prior in (16.3) has the following properties:
1. There is no prior information about g and its first m −1 derivatives at x = 0 because αk =
g(k)(0) for k = 0, . . . , m −1 and the prior on α is diffuse.
2. The first m −1 derivatives of g are continuous because a Wiener process is continuous.
3. There is no prior information about the mth derivative of g, because dmg(x)/dxm =
dW(x)/dx and the first derivative of a Wiener process is infinite.
The prior in (16.2) is completed by specifying a prior for τ2, which is usually taken to be an
uninformative inverse gamma, IG(a, b), with parameters a and b. If ei in (16.1) is N(0, σ 2) and g(x)
is estimated by its posterior mean, E(g(x)|y) then, conditional on τ2 and σ2, this estimate has the
following properties:
1. The estimate is a polynomial of degree 2m −1 in each of the subintervals
(xi−1, xi), i = 2, ..., n. This result can easily be shown by noting that y = (y1, . . . yn)
and g = (g(x1), . . . , g(xn)) are jointly normal and hence
E(g(xi)|y, τ2, σ 2) = E(α0 + α1xi|y) + ωmi.

 + In
σ 2
τ2
−1
(y −E(y))
where ωmi. is a 1 × n row vector with jth entry equal to ωmij in (16.3), see [41] for a full
discussion.
2. The estimate has continuous mth derivatives throughout its range.
3. The estimate is a polynomial of order m −1 for x < x1 and x > xn.
4. If τ2 = 0, the estimate is a polynomial of order m −1, and as τ2 →∞, E(g(xi)|y) →yi.
To compute the posterior mean and variance of g(xi) unconditional on σ 2 and τ2, requires per-
forming the multidimensional integrations

Applications of Bayesian smoothing splines
311
E[g(xi)|y] =

E

g(xi)|y, σ 2, τ2
p(σ 2, τ2|y)d(σ 2, τ2)
var[g(xi)|y] = E

g(xi)2|y

−E

g(xi)|y
2
=

E

g(xi)2|y, τ2, σ 2
d(σ 2, τ2) −E

g(xi)|y
2
respectively. Estimates of E[g(xi)|y] and var[g(xi)|y] are
ˆg(xi) = 1
M
M

k=1
E
8
g(xi)|y, σ 2[k], τ2[k]9
ˆσ 2
gi = 1
M
M

k=1
E
8
g(xi)2|y, σ2[k], τ2[k]9
−ˆg(xi)2
(16.4)
where the sequence σ 2[k], τ2[k] are drawn from p(σ 2, τ2|y) using Markov chain Monte Carlo
(MCMC). A typical sampling scheme to obtain these draws proceeds along the following lines;
Sampling scheme 16.1
1. Sample g conditional on y, τ 2 and σ 2,
2. Sample τ2 conditional on g,
3. Sample σ 2 conditional on y and g.
Steps(2)and(3)arestraightforwardandalgorithmsfortheefficientsamplingofg include[4],[12],
[7] and [10].
16.1.1 Smoothing splines as linear combinations of basis functions
Anequivalentrepresentationof(16.2)istowritetheunknownfunctionf(x)asalinearcombination
of basis functions
f(x) = Xmβ
m = QmDmQ′
m and Xm = Qm
βm ∼N(0, τ2Dm)
(16.5)
where QmDmQ′m is an eigenvalue decomposition of the covariance matrix m, with Qm the matrix
of eigenvectors and Dm a diagonal matrix of eigenvalues. The columns of Xm = Qm are an orthog-
onal basis and similar to the Demmler Reinsch basis functions, see [8].8 The subscript m indicates
that different values of m will give different basis functions. The basis functions for m = 1 and
m = 2 are shown in Figure 16.1 and, as can be seen, are very similar.
The prior on the coefficients of the basis functions, βm ∼N(0, τ2Dm), states that although the
coefficients are different they have in common a distribution, which is normal with a zero mean and
a variance τ2Dm. The smoothness of the posterior mean of g(x) is determined by the variance of
8 The Demmler Reinsch basis functions are formed from the eigenvalue decomposition of the matrix,
τ2(τ2 + σ 2I)−1, which maps the data, y, to the fitted values.

312
S. Wood
0
0.2
0.4
0.6
0.8
1
0
0.01
0.02
0.03
0.04
0.05
0.06
0.07
0.08
0.09
(a)
0
0.2
0.4
0.6
0.8
1
−0.08
−0.06
−0.04
−0.02
0
0.02
0.04
0.06
0.08
0.1
(b)
0
0.2
0.4
0.6
0.8
1
−0.08
−0.06
−0.04
−0.02
0
0.02
0.04
0.06
0.08
0.1
(c)
0
0.2
0.4
0.6
0.8
1
−0.08
−0.06
−0.04
−0.02
0
0.02
0.04
0.06
0.08
0.1
(d)
Figure 16.1 Panels (a)–(d), show the 1st, 2nd, 7th, 10th basis functions respectively for m = 2
(solid) and m = 1 (dashed), for equally spaced data on the interval [0,1], with n = 500.
these coefficients; a smaller variance shrinks the coefficients closer to zero, thus giving a smoother
estimate. In the extreme if τ2 = 0, then all of the coefficients are identically zero and the posterior
mean of g(x) will be a polynomial of order 2m −1. Similarly as τ2 →∞these coefficients have
no restrictions and can lie anywhere in Rn and will therefore interpolate the data.
The value of m in the prior given by (16.2) also affects the variance of the coefficients via the
diagonal matrix Dm, and hence the smoothness of the posterior mean of g(x). In general the higher
the value of m, the more prior information is imposed on the function and its derivatives and hence
the smoother the value of E(g(x)|y) will be. Figure 16.2 plots the diagonal elements of Dm, djm
for j = 1, . . . , n against the index of the columns of Xm for m = 1 (dashed) and m = 2 (solid).
For a given value of τ2, Figure 16.2 shows that the variance of the coefficients βjm decreases as the
oscillationfrequencyofthebasisfunctionsincreases.Figure16.2alsoshowsthatthisrateofdecrease
is higher for m = 2 than m = 1 and therefore a priori we expect the estimate of a function based
on a prior with m = 1 to be less smooth than one based on a prior with m = 2.
The advantage of using the representation in (16.5) is that the model in (16.1) is linear in the
unknown parameters βm, and its posterior mean is the value of βm which maximizes the penalized
likelihood
p(β∗
m|y) ∝exp −1
2

(y −X∗mβ∗m)′(y −X∗mβ∗m)
σ 2
+ β∗′
mD∗−1
m
β∗m
τ2

where X∗m = [1n, x, . . . , xm−1, Xm], and xk = (xk
1, . . . , xkn)′ for k = 1, . . . , m −1; β∗m = (α0,
. . . , αm−1, β′m)′ and D∗m = diag(cα1′m, d′m) and dm = (d1m, . . . , dnm)′. As in Section 16.1 an

Applications of Bayesian smoothing splines
313
500
400
300
200
100
0
−25
−20
−15
−10
−5
0
5
10
Index
log(Di)
Figure 16.2 The log of the eigenvalues, log(Dim) corresponding to the index of the eigenvectors,
for m = 2 (solid) and m = 1 (dashed), for equally spaced data on the interval [0,1], with n = 500.
MCMC scheme to estimate the posterior mean X∗m × E[β∗m|y] usually proceeds along the follow-
ing lines:
Sampling scheme 16.2
1. Sample β∗
m conditional on τ2 and σ 2,
2. Sample τ 2 conditional on β∗
m,
3. Sample σ 2 conditional on β∗
m.
By representing smoothing splines as linear combinations of basis functions it becomes obvious
that smoothing splines are similar to regression splines with a knot at each observation. If n is large
then performing an eigenvalue decomposition and estimating βm is computationally infeasible.
However, truncating the number of basis functions to those eigenvectors corresponding to the
largest p eigenvalues, with p of the order n/10 works well in practice.9
Example 16.1 Modelling solar activity
This example shows how smoothing splines can be used to model solar activity for the last
350 years. Sunspots are strong concentrations of magnetic flux on the sun’s surface and appear
as dark spots on the surface. They typically last for several days, although very large ones
may live for several weeks. Sunspots have been measured by direct observation since 1610. The
sunspot number is calculated by first counting the number of sunspot groups and then the
number of individual sunspots. The sunspot number is then given by the sum of the num-
ber of individual sunspots and ten times the number of groups. The data are available at
http://solarscience.msfc.nasa.gov/greenwch/spot_num.txt and appear in Figure 16.3. Our model
for the number of sunspots is given by (16.1), where yi is the square root of the sunspot number
9 Although [17] point out that basis functions which have a small variance a priori do not necessarily have a
posterior mean which is close to 0.

314
S. Wood
and xi is the time at which the observation was recorded.10 This figure shows that the number of
sunspots has a cycle of approximately 11 years. The data were chosen because they show that the
estimate of the posterior mean E(g|y) is insensitive to the number of truncated basis functions p,
for p > n/50 even for functions with high oscillation frequency.
16.2 Extension to non-Gaussian data
The beauty of Bayesian statistics and MCMC methodology is having established estimation tech-
niques for the plain vanilla version, techniques for estimating a richer class of models can often be
achieved using data augmentation, as discussed by [37]. The purpose of data augmentation is to
facilitate MCMC schemes which perform the multidimensional integration needed to estimate the
required features of the marginal distributions, such as the posterior mean of a regression function.
The type of data augmentation depends upon the problem at hand.
For example consider n binary observations w = (w1, . . . , wn), where the goal is to estimate
Pr(wi = 1|xi) = E(wi = 1|xi). One possible model for this expected value is
E(wi|xi) = H(g(xi))
(16.6)
where H(.) is called a link function and g is some function of x. One choice for H(.) in (16.6) is the
standard normal cumulative distribution function (cdf), denoted by . Estimating {g(x)} by its
posterior mean requires a sequence of draws from p(τ, σ 2|w). If the data are Gaussian (conditional
on the covariates), then this is achieved by using Sampling schemes 16.1 or 16.2. If the data are
non-Gaussian then this sequence of draws can be obtained by using data augmentation to modify
these sampling schemes as discussed in [1].
The idea in [1] is to augment the data with a vector of latent variables y = (y1, . . . , yn), where
yi = g(xi) + ei, with ei ∼N(0, 1). These latent variables are connected to the observations by
requiring yi > 0 if wi = 1 and yi < 0 otherwise. Then
Pr(wi = 1|g(xi)) = Pr(yi > 0|g(xi)) = {g(xi)}
The posterior mean of g(xi) estimated by
{ˆg(xi)} = 1
M
M

j=1
E[{g(xi|w, y[j], τ2[j])}]
where the sequence y[j], τ2[j] j = 1, . . . , M is generated from the posterior distribution p(y, τ2|w).
The sampling scheme implemented to obtain this sequence is:
Sampling scheme 16.3
1. Sample y conditional on w and g(x),
2. Sample g(x) conditional on τ 2 and y,
3. Sample τ 2 conditional on g(x).
10 Note,datawastransformedbytakingthesquarerootsothattheerrortermin(16.1)isapproximatelyi.i.d ∼
N(0, σ2), despite that fact that it must always be positive.

Applications of Bayesian smoothing splines
315
1750
1800
1850
1900
1950
2000
0
2
4
6
8
10
12
14
16
(a)
(b)
Year
y
1750
1800
1850
1900
1950
2000
0
2
4
6
8
10
12
14
16
Year
y
Figure 16.3 Panel (a) Square root of monthly sunspot numbers from 1741 to 2010. Three estimates
of the posterior mean E(g|y), corresponding to the number of basis functions, p, equal to n, n/10 and
n/50 are also plotted but are visually indistinguishable. Panel (b) Estimate of E(g|y) (solid) together
with 95% posterior intervals (dashed) when p = n/10.

316
S. Wood
It should be noted that when the data are non-Gaussian the posterior mean is not necessarily
the same as the posterior mode and therefore estimating {g(xi)} by maximizing the penalized
likelihood as in [14] will give different results from estimating {g(xi)} by its posterior mean.
Example 16.2 Modelling the probability of a heart attack
The data augmentation technique is now applied to a dataset consisting of n = 463 observations
on the dependent variable w, which equals 1 if the subject had a heart attack and 0 if he or she did
not, and three risk factors; systolic blood pressure (BP), cholesterol ratio (CR), and age of patient
(Age). These data have been described and analysed by [16] and [45].
The aim is to model the dependency between the probability of having a heart attack and these
three risk factors in a flexible but robust manner. It is important that the method is made robust
to outliers or miscoded observations because of the impact these observations can have on the
inference regarding the effect of risk factors. To illustrate the data augmentation technique of [1]
we first describe the sampling scheme omitting outlier detection and consider a single risk factor,
CR, only. The model for the data in Figure 16.4 is
Pr(w = 1|CR) = {g(CR)}
where
g(CR) = α0 + α1CR + f(CR)
2
0.0
0.2
0.4
P(Heart AttacklCR)
0.6
0.8
1.0
4
6
8
Cholesterol Ratio
10
12
14
Figure 16.4 Plot of the incidence of heart attack versus cholestertol ratio (CR), with an estimate of
the posterior mean of {(CR)} when outlier detection is turned on (dashed) and when it is turned off
(solid). There were many coincident points, so to show the distribution of the data the values of CR
were perturbed by adding a small amount of Gaussian noise to their values. This figure was taken
from [45].

Applications of Bayesian smoothing splines
317
The estimate of the posterior mean E[{g(CR)}|w] is
{ˆg(CR)} = 1
M
M

k=1
E[{g(CR)}|w, y[k], τ[k])]
where the sequence y[k], τ2[k] is drawn from p(y[k], τ[k]|w) using Sampling scheme 16.3.
Figure 16.4, solid line, shows that the probability of a heart attack increases as cholesterol ratio
increases but drops sharply for high levels of cholesterol ratio. This sharp drop may be due to the
effect the observation (CR = 15.33, w = 0) has on the estimate of {ˆg(CR)}.
16.2.1 Robust binary nonparametric regression
To make the estimation procedure robust to outliers, data augmentation is used again. A vector
of indicator variables is introduced where, γ = (γ1, . . . , γn), and γi = 1 if an observation is an
outlier or miscoded and γi = 0 otherwise as in [39]. We assume a priori that the γi are independent
with Pr(γi = 1) = π. In this application we take π = 0.05 and find that this choice works well in
practice. The sampling scheme now becomes
Sampling scheme 16.4
1. Sample y and γ jointly conditional on w and g = (g1, . . . , gn) by drawing
(a) γ from
p(γ |w, α, f) =
n

i=1
p(γi|wi, α, f(CRi))
where
Pr(γi = 1|wi, g(CRi)) =
Pr(wi|γi = 1, g(CRi))π
Pr(wi|γi = 1, g(CRi))π + Pr(wi|γi = 0, g(CRi))(1 −π)
and then drawing
(b) y as in Sampling Scheme 16.3.
2. Sample g and τ2 as in Sampling Scheme 16.3.
Figure 16.4, dotted line, shows the estimate {ˆg(CR)} when outlier detection is turned on. As
can be seen, the sharp drop {ˆg(CR)} disappears when the procedure is made robust to outliers.
The posterior probability that the observation (CR = 15.33, w = 0) is an outlier is approximately
0.50. The method also identifies outliers which occur at low levels of cholesterol ratio. For example
the posterior probability that the observation (CR = 1.74, w = 1) is an outlier is approximately
0.75. However, the observation (CR = 1.74, w = 1) does not affect the estimate {ˆg(CR)} to the
same degree as does the observation (CR = 15.33, w = 0), even though it has a higher posterior
probability of being an outlier. This is because there are many observations for low levels of choles-
terol ratio, while data is scarce in the vicinity of the observation (CR = 15.33, w = 0). Hence the
contribution of the observation (CR = 1.74, w = 1) to the estimate is less than the contribution
made by the observation (CR = 15.33, w = 0).

318
S. Wood
16.2.2 Including other covariates
One method of including other risk factors is to assume that the effect of these risk factors on
the probability of a heart attack is additive. Although this is not as flexible as modelling the
three-dimensional surface nonparametrically, it is easy to implement and the discussion of mod-
elling high-dimensional surfaces nonparametrically is left to Section 16.4. To model the probability
of a heart attack as a function of the three risk factors, we assume that
Pr(w = 1|BP, CR, Age) = ({g(BP, CR, Age)} where,
g(BP, CR, Age) = α0 + α1BP + α2CR + α3Age + f1(BP) + f2(CR) + f3(Age)
and estimate {ˆg(BP, CR, Age)} = 1
M
M
k=1 E[{g(CR, AGE, BP|w, y[k], τ2[k])] using a similar
sampling scheme to 16.3.
Sampling scheme 16.5
1. Sample y and γ jointly conditional on w and α = (α0, α1, α2, α3) and f 1 =
(f1(BP1), . . . , f1(BPn)), f 2 = (f2(CR1), . . . , f2(CRn)) and f 3 = (f3(Age1), . . . ,
f3(Agen)), by drawing
(a) γ from p(γ |w, α, f 1, f 2, f 3) and then
(b) y from p(y|γ , w, α, f 1, f 2, f 3).
2. Sample α, f 1, f 2, and f 3 conditional on τ 2 = (τ 2
1 , τ 2
2 , τ 2
3 ) and y,
3. Sample τ2 conditional on f 1, f 2, and f 3.
Figure 16.5 shows that the probability of a heart attack increases monotonically with age and choles-
terol ratio, when outlier detection is turned on. Interestingly, the posterior probability that the
observation (CR = 15.33, w = 0) is an outlier has decreased from 0.50, reported previously, to
0.30. This is because this patient had a systolic blood pressure of only 120 and was 49 years old.
Thus after controlling for blood pressure and age, the likelihood that this observation is an outlier
decreased. Conversely, the posterior probability that the observation (CR = 1.74, w = 1) is an
outlierincreasedfrom0.75to0.86,becausethispatientwasonly20yearsoldandhadasystolicblood
pressure of 106. The plot of blood pressure is interesting, because it shows that even with outlier
detection turned on, the probability of having a heart attack increases as blood pressure decreases,
for blood pressure less than 120. This is not a smoothing artefact but rather a real feature of the data.
The graph shows a considerable number of patients who had heart attacks with a systolic blood
pressure below 120.
16.3 Using smoothing splines to estimate spectral densities
16.3.1 Introduction
In this section we show how features of a time series such as the spectral density and unknown
frequencies can be estimated simultaneously using smoothing splines together with data augmen-
tation in a hierarchical Bayesian framework. Following [5], suppose that a time series
yt = β0 + vt

Applications of Bayesian smoothing splines
319
100
–3.0
–3.4
–3.6
f(Systolic B.P.)
f(Cholesterol Ratio)
f(Age)
–3.8
–4.0
1.5
1.0
0.5
0.0
3.5
3.0
2.5
2.0
0.5
120
140
160
Systolic Blood Pressure
(b)
(a)
Cholesterol Ratio
(c)
Age
180
200
220
2
4
6
8
10
12
14
20
30
40
50
60
Figure 16.5 Heart attack data. Panels (a)–(c) are Bayesian estimates of α0 + α1BP + f1(BP) (the
effect of blood pressure), α2CR + f1(CR) (the effect of the cholesterol ratio), and α3Age + f3(Age)
(the effect of age when outlier detection is turned on (· · · ) and when it is not (—). For all three
independent variables there were many coincident points. To show the distribution of the data, we
perturbed the independent variables by adding a small amount of Gaussian noise to their values.
This figure was taken from [45].
is modelled as the sum of a signal β0 and noise vt. The noise is a zero mean stationary Gaussian pro-
cess with a spectral density given by f(ν), for −1/2 < ν ≤1/2. We assume that f(ν) is bounded
and positive. Given a realization, y = (y1, . . . , yn), the periodogram of the data at frequency ν is
In,β0(ν) = 1
n
&&&&&
n

t=1
(yt −β0) exp(−iνt)
&&&&&
2
.
In what follows, the notation for the periodogram is simplified by omitting the dependence of I on
n and β0. Let νk = k/n, for k = 0, . . . , n −1, be the Fourier frequencies. [43] showed that, under
appropriate conditions, for large n, the likelihood of y can be approximated as
p(y
&& f, β) ∝
n−1

k=0
exp

−1
2
8
log f(νk) + I(νk)/f(νk)
9
(16.7)
Let x(νk) be the log of the periodogram evaluated at the Fourier frequencies, then the representa-
tion in (16.7) suggests the log–linear model

320
S. Wood
0.20
(a)
(b)
0.10
0.0
–15
0.20
0.10
0.0
–10
–5
x
0
5
–15
–10
–5
x
0
5
Figure 16.6 Panel (a) shows the density of a log(χ2
1 ) variable (solid line) and the normal mixture
approximation (dotted line). Panel (b) shows the approximate density (solid line) and also the densities
of the normal components (broken lines)
x(νk) = log f(νk) + ϵk
(16.8)
where x(νk) = log I(νk) for k = 0, . . . , [n/2], where [n/2] is the largest integer less than or equal
to n/2, the ϵks are independent, ϵk ∼log(χ2
2 /2) for k = 1, . . . , [n/2] −1, and ϵk ∼log(χ2
1 ) for
k = 0, [n/2]. Note that in (16.7), there are only [n/2] + 1 distinct observations since the spectral
density and the periodogram are both even functions of ν. For ease of notation, in what follows, we
assume that n is even.
It is seen from (16.8) that the log spectral density can be estimated nonparametrically with the
log periodogram as the dependent variable. [40] used a frequentist approach for estimating the log
spectral density via cubic smoothing splines. This section shows how [5] used a Bayesian approach
tomodelthelogspectraldensityascubicsmoothingsplinesbyapproximatingtheerrordistribution
in (16.8) by a mixture of five normal distributions and introduced latent component indicators.11
Table 16.1 gives the weights, means, and variances of the five components in the mixture which
approximate the density of log(χ2
1 ) variable (columns 1–3) and log(χ2
2 ) variable (columns 4–6).
Figure 16.6, panel (a), shows plots of the density of a log(χ2
1) variable and its approximation, while
panel (b) shows the approximation together with the densities of the components in the mixture.
Again data augmentation is used to facilitate the estimation of g(νk) = log(f(νk)). Let γk deter-
mine the component of the mixture to which ϵk in (16.8) belongs, so that γk = j if ϵk is generated
from component j, and let γ = (γ0, . . . , γn/2)′. The prior probability of γk is given by columns 1
and 4 of Table 16.1. The γk are assumed to be independent a priori since the ϵk are independent.
Detecting signals in a time series by identifying spikes in the log periodogram has been studied
extensively, see [27] for a discussion. In [5] detecting signals in a time series is achieved by allowing
one of the components in the mixture to have a large variance and concluding that a spike occurs
at frequency νk if the indicator variable γk has a high posterior probability corresponding to the
mixture component with the large variance and the residual is positive. To this end a new mixture
of five normal densities was used to approximate the log(χ2
2 ) density, with the variance of one of
the distributions fixed to be very large and the other four components were selected so that the
approximating mixture, given in Table 16.2, has the quality of the approximation similar to that in
Table 16.1, except that it has a heavier right-hand tail.
11 [30] provide a similar Bayesian technique to estimate the spectral matrix for multivariate time series.

Applications of Bayesian smoothing splines
321
Table 16.1 Five component approximations to log(χ2
1 ) and log(χ2
2 /2)
log(χ2
1 )
log(χ2
2 /2)
probability
mean
variance
probability
mean
variance
0.13
–4.63
8.75
0.19
–2.20
1.93
0.16
–2.87
1.95
0.11
–0.80
1.01
0.23
–1.44
0.88
0.27
–0.55
0.69
0.22
–0.33
0.45
0.25
–0.035
0.60
0.25
0.76
0.41
0.18
0.48
0.29
Table 16.2 Five-component approximation to log(χ2
2 /2) with one component having a variance of
25 and prior probability 0.02.
probability
mean
variance
0.13
–2.26
3.31
0.35
–0.91
0.92
0.02
–0.69
25
0.20
–0.32
0.63
0.30
0.34
0.38
Example 16.3 Variable star data
ThetechniqueisnowdemonstratedusingobservationsonthevariablestarS.Carinae.Thereported
results are taken from [5]. S. Carinae is classified as a Mira type variable star and is located in the
constellation Carina. Carina means keel and refers to the keel of the ship of the Argonauts in Greek
mythology. A star is classified as variable if its apparent magnitude as seen from Earth changes over
time.Miratypevariablestarsarecharacterizedbyverylargepulsationswithperiodslongerthan100
days. Data are available for S Carinae from the Royal New Zealand Society of Astronomy for 1189
ten-day periods.
Eachobservationistheaverageoverthepreceding10daysandthereare40missingobservations.
Missing data are distinguished from observed data by denoting them ymis and yobs respectively.
For further details see [28]. The model for the log of the spectral density of the time series is given
by(16.8)wherethedistributionoftheerror,ϵk,ismodelledasamixtureoffivenormalswithmeans,
variances and prior probabilities given in Table 16.2. The posterior mean is,
E[g(νk)|y)] =

E[g(νk)|yobs, τ 2, ymis, f]p(f, τ2, ymis|yobs)dτ2dymisdf

322
S. Wood
and is estimated by
E[g(νk)|y)] = 1
M
M

k=1
E[g(νk)|yobs, τ2[k], y[k]
mis, f [k]]
Sampling scheme 16.6 is used to generate the sequence τ2[k], y[k]
mis, f [k] from p(τ2, ymis, f|yobs).
Sampling scheme 16.6
1. Generate ymis from p(ymis|g, yobs, β0, τ 2, γ ) and compute x = (x(ν1), . . . ,
x(νn)).
2. Generate τ 2 from p(τ 2|g)
3. Generate g from p(g|x, β0, τ 2, γ )
4. Generate γ and β0 from p(γ , β0, |ymis, yobs, g)
Figure 16.7 shows the results. Panel (a) shows the data; Panel (b) shows the log periodogram with
the missing data replaced by the Markov chain Monte Carlo estimates; Panel (c) shows the Markov
chain Monte Carlo estimate of the log spectral density of the error sequence; Panel (d) shows the
posterior probability that γk belongs to the component in the mixture with the high variance. From
panel(d)itcanbeseenthattherearethreefrequenciesatwhichthespectrumislikelytohaveaspike.
10
(a) Data
(b) Log periodogram
9
8
7
6
5
0
–5
–10
0
50
100
t
150
0.0
0.5
1.0
1.5
2.0
2.5
3.0
freq
(d) p(spike)
0.8
0.4
0.0
0.0
0.5
1.0
1.5
2.0
2.5
3.0
freq
(c) Log spectral density
0
–1
–2
–3
–4
0.0
0.5
1.0
1.5
2.0
2.5
3.0
freq
Figure 16.7 Panel (a) shows the first 150 observations on the varaible star S Carinea; Panel (b)
shows the log periodogram; Panel (c) shows the Markov chain Monte Carlo estimate of the log
spectral density of the error sequence (solid); Panel (d) shows the probabilities of a spike in the log
periodogram. This figure is taken from [5].

Applications of Bayesian smoothing splines
323
The first spike occurs at frequency ν = 0.42 and the two subsequent spikes occur at frequencies
which are multiples of ν = 0.42. The conclusion is that the time series contains a deterministic
component, as discussed in Section 16.3.1. The frequency at which the spike first occurs is called the
fundamental frequency. This value of ν = 0.42 translates into 0.0669 cycles per 10 day period. In
other words each cycle lasts 149.5 days.
16.4 Multidimensional smoothing splines
To extend the prior for g with a single covariate outlined in Section 16.1, we need to specify the prior
covariance of the unknown function in d dimensional space. For example suppose that the signal g
in (16.1) is a function of d = 2 covariates, x1 and x2, so that
yi = g(x1i, x2i) + ϵi with ϵi ∼N(0, σ2)
(16.9)
g(x1i, x2i) = α0 +
m−1

k=1
αk1xk
1i +
m−1

k=1
α2kxk
2i + f(x1i, x2i)
A prior for the covariance between f(x1i, x2i) and f(x1j, x2j), given by [42], is the thin-plate spline
prior with m = 2 and
cov{f(x1i, x2i), f(x1j, x2j)} = τ2{(xi, x2i), (xj, x2j)}.
where
{(x1i, x2i), (x1j, x2j)} = A{(x1i, x2i), (x1j, x2j)} −
3

k=1
pk(x1j, x2j)A{uk, (x1i, x2i)}
−
3

k=1
pk(x1i, x2i)A{(x1j, x2j), uk} +
3

k=1
3

l=1
pk(x1i, x2i)pl(x1j, x2j)A(uk, ul),
A{(x1i, x2i), (x1j, x2j)} = rij log(rij), rij =
;
{(x1i −x1j)2 + (x2i −x2j)2},
p1(x1, x2) = 1 −2x1 −2x2,
p2(x1, x2) = 1 −2x1,
p3(x1, x2) = 1 −2x2
u1 = (0, 0),
u2 = (1
2, 0),
u3 = (0, 2).
As can be seen the kernel  is composed of radial basis functions and M =
d+m−1
m

polynomials
of order ≤m −1. The polynomials ensure that the matrix is positive definite. Again we can write
the prior on g(x1, x2) as a linear combination of basis functions, by taking an eigenvalue decompo-
sition of  so that  = QDQ′ and letting g(x1, x2) = Xβ, where X = Q and β ∼N(0, τ2D).

324
S. Wood
50°
–50°
0°
100°
200°
Longitude
300°
0°
Latitude
Figure 16.8 Global air temperature example. Isotherms of air temperature anomalies (oC) for Decem-
ber 1993 using a single smoothing spline. This figure is taken from [46].
Example 16.4 Global air temperature anomalies
This example demonstrates how smoothing splines can be used to model spatial data,
such as global air temperature anomalies. The data were obtained from the air temperature
anomaly archive developed by Jones (1994) and available at the web site http://ingrid.ldeo.
columbia.edu/SOURCES/.JONES/.landonly.cuf/. The dataset contains monthly readings of air tem-
peratureanomaliesatvariouspointsontheglobeforDecember1993.Airtemperatureanomaliesare
the deviations from a monthly mean temperature for a given latitude and longitude. The monthly
mean temperature for a given latitude and longitude was defined to be the monthly mean tempera-
tureforthatlocationfortheperiod1950–1979.Altogether445irregularlyspacedobservationsacross
the entire globe were available for December 1993.
Let yi be the December 1993 temperature anomaly recorded at latitude x1i and longitude x2i.
The model for the data is given by (16.9) and an estimate of the posterior mean of g(x1i, x2i), is
obtained using Sampling scheme 16.2. Figure 16.8 is taken from [46] and shows the isotherms for
the model. One of the interesting features of this figure is that the isotherm fluctuations in the
northern hemisphere are more pronounced than those in the southern hemisphere, indicating that
theregressionsurfacefornorthernhemispheretemperatureanomaliesrequireslesssmoothingthan
the regression surface for southern hemisphere temperature anomalies. We return to this example
in Section 16.5 where we discuss how to obtain an estimate of a regression surface where the degree
of smoothness changes across the covariate space.
Example 16.5 Union membership
This example shows how the methodology discussed in Section 16.2 can be extended to higher
dimensions by modelling the probability of union membership as a function of three continuous
variables, years of education, wage, and age, and three dummy variables, south (1 = live in southern
regionofUSA),female(1=female),andmarried(1=married).Thedataconsistof534observations
on US workers and can be found in [3] and at http://lib.stat.cmu.edu/datasets/CPS_85_Wages.
[32] estimated the probability of union membership using a generalized additive model without
interactions.Inthisexamplethethree-dimensionalsurfaceofthecontinuouscovariatesismodelled

Applications of Bayesian smoothing splines
325
50°
–50°
0°
100°
200°
Longitude
300°
0°
Latitude
Figure 16.9 Global air temperature example. Isotherms of air temperature anomalies (oC) for Decem-
ber 1993 using a mixture of two smoothing splines. This figure is taken from [46].
using partial thin-plate spline basis functions, see [44] for details. The results suggest that this is
more appropriate than an additive model. The model is
Pr(w = 1|x) = {g(x)}
with
g(x) = αx + f(x∗)
where x=(years education, wage, age, south, female, married), x∗= (years education,wage, age),
wage is in US $/hr and age is in years. The dependent variable, w, is 1 if the worker belongs to a
union and 0 otherwise and α = (α0, α1, . . . , α6). The probabilities Pr(wi = 1|x) are estimated by
their posterior means and Sampling scheme 16.2 is used to perform the required multidimensional
integration.Figure16.10panels(a)to(c)showthejointmarginaleffectoftwocontinuouscovariates
at the mean of the third one with the dummy variables set to zero. These figures clearly show
interactions among the continuous covariates. For example, Figure 16.10 panel (a) shows that for
workers who did not finish high school (< 12 years education) the probability of belonging to a
union increases as wage increases. For workers who finished high school the probability of belong-
ingtoaunionpeaksatawageofapproximately$15/hr,whileforworkerswithtertiaryeduction(>15
years)theprobabilityofunionmembershipisinitiallyhighandthendecreaseswithincreasingwage.
Figure 16.10 panel (b) shows two modes. For workers with an average wage and who are older than
40 years, union membership peaks at 55 years, and between 8 and 10 years education (interestingly
union membership peaks again at 55 years, and 18 years education, although this peak may be due
to boundary effects). While for younger workers union membership increases as years of education
increases. Figure 16.10 panel (c) shows that for workers whose age is less than 40, the probability of
union membership initially increases with wage, before reaching a peak at a wage of about $15/hr
and then declines. For older workers this peak occurs at much lower wages, somewhere between
$5/hr and $10/hr before declining sharply.

326
S. Wood
30
(a)
(b)
(c)
25
20
15
wage
10
5
0
5
10
years.educ
15
60
55
50
45
40
age
35
30
25
20
5
10
years.educ
15
60
55
0.30
0.25
0.20
0.15
0.10
50
45
40
age
35
30
25
20
5
10
years.educ
15
Figure 16.10 Panel (a) Plot of Pr(Union Member|wage, years education) at the mean age; Panel (b)
Pr(Union Member|age, years education) at the mean wage; Panel (c) Pr(Union Member|wage, age)
at the mean years education. In all plots the dummy variables are set to zero. This figure is taken
from [44].
16.5 Locally adaptive smoothing splines
TherearemanyBayesianmethodsavailablewhichallowthedegreeofsmoothnessoftheregression
surface to change. This list includes, but it not limited to, [35], [18], and [9], who use regression
splines and model averaging to obtain locally adaptive estimates; [21], [2], and [6] who use penal-
ized splines; and [26] and [46] who use mixtures of smoothing splines. There is not enough space
to do all these methods justice, but the reader is referred to [25] for an excellent discussion of these
techniques. In this section the discussion is confined to smoothing splines and two applications of
locally adaptive smoothing splines are described using the mixture-of-splines approach presented
in [46] and [31].
Example 16.6 Modelling global temperature anomalies adaptively
To introduce the topic consider the example discussed in Section 16.4, where it was noted that the
isotherms in the northern hemisphere were more wiggly than those in the southern hemisphere. In
general it may be unrealistic to assume that temperature deviations from a historic average display
the same variability across the globe. For example, areas close to the equator or on a coast may
have less temperature variation than interior areas in the mid-latitudes. One method which allows
the smoothness of a regression surface g to change across the globe is to model g as a mixture
of J smoothing splines, where the weights in the mixture depend upon covariates. A model for
temperature anomalies across the globe, given in [46], is

Applications of Bayesian smoothing splines
327
y(x1i, x2i) = g(x1i, x2i) + ei
g(x1i, x2i) =
J

j=1
gj(x1i, x2i)πj(x1i, x2i)
πj(x1i, x2i) =
exp(ziδj)
J
k=1 exp(ziδk)
with
J

j=1
πj(x1i, x2i) = 1
(16.10)
where πj is the weight given to the jth smoothing spline. This weight depends upon covariates
zi = (1, x1i, x2i) and is modelled by a multinomial logistic regression, with regression coefficients
δ = (δ1, . . . , δJ), with δj = (δ0, δ1, δ2) for j = 1, . . . J −1 and δJ = (0, 0, 0). In the neural net-
work literature the formulation in (16.10) is known as a mixture-of-experts model (see [19] and
[20]). Each of the gj in (16.10) has the thin-plate spline prior given in (16.9) and is associated
with a smoothing parameter, τ2
j , which is defined over a local region of the covariate space, so
that a smoothing spline with a given degree of smoothness is fitted to the data that fall into each
region. The regions are allowed to overlap, such that individual data points may lie simultaneously
in multiple regions. As such the regions are said to have ‘soft’ boundaries.
The posterior mean E(g|y) is given by

E(g|y, )p(|y)d, where  = (θ1, . . . ,
θJ, δ1, δJ−1, σ 2), θj = (αj, τ2
j ) and estimated by
ˆg = 1
M
M

k=1
J

j=1
E(πjgj|y, θ[k]
j
, δ[k]
j , σ 2[k])
(16.11)
where the sequence θ[k]
1 , . . . , θ[k]
J
, δ[k]
1 , . . . , δ[k]
J−1, σ2[k] is generated from the joint posterior
distribution p(θ1, . . . , θJ, δ1, . . . , δJ−1, σ 2|y). Again data augmentation is used to generate this
sequence by defining a vector of indicator variables γ = (γ1, . . . , γn) which identifies the com-
ponent to which an observation belongs, s.t. Pr(γi = j|x) = πj(x). The sampling scheme is:
Sampling scheme 16.7
1. Sample γ conditional on y, g = (g1, . . . , gJ), and σ 2.
2. Sample δj for j = 1, . . . , J −1 conditional on γ .
3. Conditional on a partition of the data, g, τ 2
j
are sampled as in Sampling
scheme 16.2.
4. Sample σ 2 conditional on y, and g.
Proper priors must be used for the parameters of the components in mixture models, because if
no data are allocated to a component, then the parameters of that component are drawn from the
prior distribution.
The choice of the number of components in the mixture, J is not trivial. Several model selection
techniques exists such as BIC or AIC, while Reversible Jump MCMC (RJMCMC), can be used to
perform model averaging, see [15] and [29]. For this example the BIC approach of [33] was used to
select J, where the marginal likelihood p(y|J) is approximated by
p(y|J) ≈p(y| ˆθ1, . . . , ˆθJ, ˆδ1, . . . , ˆδJ−1, ˆσ 2, J)n−qj/2,
(16.12)

328
S. Wood
ˆθj and ˆδj maximize the likelihood in (16.12) and qj is the number of parameters. The quantity p(y|J)
was maximized for J = 2 and Figure 16.9 presents an estimate of g if that data are modelled by
(16.10) with J = 2. From Figure 16.9 one can see why a mixture of more than one thin-plate spline
is required. The isotherms in the southern hemisphere and the lower latitudes of the northern
hemisphere change very smoothly and show very little variation. In contrast, the isotherms in the
higher latitudes of the northern hemisphere exhibit large fluctuations. In particular, the warmer
than usual temperatures in Alaska, warmer by 10 celsius degrees, are related to the equally colder
than usual temperatures in Siberia. Comparing Figure 16.9 with Figure 16.8 it can be seen that in
order to achieve the degree of variation necessary in the northern hemisphere, extra variation is
induced in the estimate of southern hemisphere isotherms.
16.6 Modelling non-stationary time series with a mixture
of spectra
In many practical problems, time series are realizations of non-stationary random processes. In this
section the approach presented in Section 16.3.1 is extended to modelling the log spectral density for
non-stationarytimeseriesusingamixtureofafinitebutunknownnumberofindividuallogspectra.
Non-stationarity is introduced to the model by allowing the mixing weights of the individual log
spectra to change smoothly across partitions of time, thus allowing for slowly varying time series,
as well as for piecewise stationary time series.
The model presented in this section is from [31]. In this section RJMCMC is used to perform
model averaging, rather than model selection discussed in Section 16.6. This is achieved by allowing
the number of underlying individual spectra to be unknown and vary from j = 1, . . . , J. To do
this it is assumed that the time series is a Dahlhaus-locally stationary process. [24] argue that
Dahlhaus-locally stationary processes can be well approximated by piecewise stationary processes
so that if the time series is partitioned into S small non-overlapping segments, y = (y1, . . . , yS)
then each segment ys = (ys1, . . . , ynss) for s = 1, . . . , S is stationary with corresponding spectrum
fs(ν).Thelogspectrumineachsegmentgs(ν) = log(fs(ν))ismodelledasamixtureofamaximum
of R possible spectra so that
gs(ν) =
R

r=1
grs(ν) Pr(r)
(16.13)
where Pr(r) is the prior probability that the mixture contains r components, and grs(ν) is the log
of the spectral density of a mixture of r components in segment s. For a given number of mixture
components, r, and segment s, grs(ν) is modelled as
grs(ν) =
r

j=1
πjsr log(fjr(ν)
(16.14)
where fjr(ν) is the spectral density of the jth component in a mixture of r components. The prior
for log(fjr(ν)) is given by (16.3) with m = 1. The unknown weight assigned to the jth component
in segment s, is πjrs with r
j=1 πjsr = 1. Note that the spectral density fjr(ν) is common to all seg-
ments, but the weight assigned to this component spectrum varies across segments, thus allowing
thespectraldensitytochangeovertime.AsinSection16.6theπjsr aremodelledusingamultinomial
logistic regression given by (16.10).

Applications of Bayesian smoothing splines
329
In theory there are as many segments as observations, however a minimum number of observa-
tions in each segment is needed to estimate the spectral density and for the Whittle approximation
to the likelihood to hold. [31] found that using a minimum of 64 observations in each segment gave
reliable results assuming that the true local spectra have well separated peaks. It should be noted
that the parameters of the mixing function πjsr in (16.14) are of more importance than the number
of segments because these parameters control the location and rate at which the time series moves
from one stationary process to another.
The log of the spectral density in segment s, for s = 1, . . . S is estimated by its posterior mean
which is equal to
E[gs(ν)|y] =
R

r=1

E{gs(ν)|y, θr, r}p(θr|y, r)dθr Pr(r|y)
where θr = (f r(ν), τ2, δ2r ), f r(ν) = (f1r(ν), . . . , frr(ν)), τ2r = (τ2
1j, . . . , τ2rr) and is estimated by
ˆgs(ν) = 1
M
M

k=1
R

r=1
E{gs(ν)|xs(ν), θ[k]
r
, r[k]}
where xs(ν) is the periodogram of segment s and the sequence θ[k]
r
, r[k] is drawn from the joint
posteriorp(θr, r|y)usingRJMCMC.DataaugmentationisusedtofacilitatetheRJMCMCscheme,
by defining a vector of indicator variables identifying to which component a segment belongs, and
a variable, r which indicates the number of the components in the mixture. Let γrs = j if segment
s is generated by component j in a mixture of r components. The sampling scheme used to obtain
the necessary sequence of draws has two parts; a between-model move followed by a within-model
move. The number of components r is first initialized, then the sampling scheme is
Sampling scheme 16.8
1. Between model move
A new value of r is proposed, and conditional on this value, f r, τ 2
r and δr
are proposed. These proposed values are then accepted or rejected using a
Metropolis–Hastings step.
2. Within model move
Given the new value of r, the parameters specific to a model of r components
are then updated as follows.
(a) Sample γ r conditional on r, f r and δr.
(b) Sample δr conditional on r and γ r.
(c) Sample f r conditional on r, γ r and τ 2
r .
(d) Sample τ 2
r conditional on r and f r.
Example 16.7 Southern Oscillation Index (SOI)
OneareaofresearchinclimatescienceoverthelastfewdecadesistheElNiño/SouthernOscillation
(ENSO) phenomenon. ENSO is an irregular low frequency oscillation between a warm El Niño
state and a cold La Niña state. The Southern Oscillation Index (SOI) is an indicator of the ENSO
phenomenon and is calculated to be the standardized anomaly of the mean sea level pressure
difference between Tahiti and Darwin. In particular questions regarding the impact global warming
may have had on the frequency of this phenomenon have been the source of much debate, see [38],
[36] and [22].

330
S. Wood
1880
1900
1920
1940
1960
1980
2000
−50
−40
−30
−20
−10
0
10
20
30
40
Year
SOI
Figure 16.11 Monthly values of the Southern Oscillation Index (SOI) from January 1876 to April
2008.
The data, shown in Figure 16.11, are monthly values of the SOI from January 1876 to April 2008
and are available at http://www.bom.gov.au/climate/current/soihtm1.shtml.
Thedataweredividedinto24segments,eachcontaining64observations(leavingoutthefirst29
observations), and the model given by equations (16.13) and (16.14) was fitted. Figure 16.12 shows
the time-varying log spectrum for the SOI and indicates that the series is likely to be stationary
given that the spectrum remains constant for the time period. To examine the effect that the prior
for the number of components, Pr(r), might have on this finding, a number of choices for Pr(r)
were used. The choice of these priors and the posterior probability Pr(r|y) appear in Table 16.3.
Table 16.3 confirms that the series is most probably stationary, given that the modal number of
components across all priors is r = 1. This finding is in contrast to [38] who concluded that the
time series is non-stationary. There are a number of explanations for this disparity, see [31] for
details.
Interestinglyconditionalonr = 2,whichoccurredwithprobability0.25whentheuniformprior
Pr(r) = 1/4 was used, the change in the SOI spectrum occurred gradually between 1890 and 1910
and not in the 1970s as found by [38].
Example 16.8 Distinguishing between earthquakes and nuclear explosions
The second example of the model given by equations (16.13) and (16.14) relates to distinguishing
between the seismic traces of an earthquake and a mining explosion. The data are from [34] and
consist of 2048 measurements taken at a recording station in Scandinavia. The data have been anal-
ysed by several authors, and the methodology described here is taken from [31]. These particular
time series both consist of two waves, the compression wave, also known as primary or P wave,
which is the start of the series and the shear, or S wave, which arrives at the midpoint of the series.
The analysis of such seismic data is one of critical importance for monitoring a comprehensive
test-ban treaty. As argued by many authors, e.g. [34], distinguishing between the seismic traces
of earthquakes and explosions is best accomplished in the frequency domain. The goal in this
example is to estimate the time-varying spectrum of the process, in order to distinguish between
the seismic traces of explosions and earthquakes. The top panels of Figures 16.14 and 16.15 show

Applications of Bayesian smoothing splines
331
6
5.5
5
4.5
Log Power
4
3.5
0
0.5
1880
Freq
Year
1920
1960
2010
Figure 16.12 Time-varying log spectrum of the SOI index from 1876 to 2008.
1896
1916
1936
1956
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Year
Probability
Figure 16.13 Pr(γs = j|r = 2, y), for j = 1, 2, for the SOI data.

332
S. Wood
Table 16.3 Posterior probabilities of the number of components in the mixture for the SOI data as
a function of prior distribution.
Prior
Uniform
Poisson
Number of
components
P(j = k) = 0.05
λ = 1
λ = 2
λ = 5
1
0.755
0.94
0.75
0.66
2
0.241
0.06
0.24
0.33
3
0.004
0.00
0.01
0.01
4
0.000
0.00
0.00
0.00
the recorded seismic trace of the explosion and earthquake respectively, while the bottom panels
show the image plots of the time-varying log spectrum. As can be seen from Figures 16.14 and 16.15,
both time series are clearly non-stationary. The difference between the two time series is the rate
at which each moves from one locally stationary segment to the next. For the explosion data this
occurs abruptly while the seismic trace from the earthquake moves more slowly. Other differences
arethattheScomponentfortheearthquakeshowspoweratthelowfrequenciesonly,andthepower
remains strong for a long time. In contrast, the explosion shows power at higher frequencies than
theearthquake,andthepowerofthesignals(PandSwaves)doesnotlastaslongasinthecaseofthe
earthquake.
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
−0.4
−0.2
0
0.2
0.4
Time
(a)
Frequency
Time
(b)
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0.1
0.2
0.3
0.4
0.5
Figure 16.14 Earthquake data. Panel (a) seismic trace and panel (b) image plot for time-varying log
spectrum.

Applications of Bayesian smoothing splines
333
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
−0.4
−0.2
0
0.2
0.4
Time
(a)
Frequency
Time
(b)
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0.1
0.2
0.3
0.4
0.5
Figure 16.15 Explosion data. Panel (a) seismic trace and panel (b) image plot for time-varying log
spectrum.
References
[1] Albert, J. H. and Chib, S. (1993). Bayesian analysis of binary and polychotomous response
data, Journal of the American Statistical Association, 88, pp. 669–679.
[2] Baladandayuthapani, V., Mallick, B. and Carroll, R. (2005). Spatially adaptive Bayesian penal-
ized regression splines, Journal of Computational and Graphical Statistics, 14, 378–394.
[3] Berndt, E. (1991). The Practice of Econometrics: Classic and Contemporary, Addison-Wesley
Pub. Co.
[4] Carter, C. K. and Kohn, R. (1994). On Gibbs sampling for state space models, Biometrika, 81,
541–553.
[5]
(1996). Semiparametric Bayesian inference for time series with mixed spectra, J. Royal
Statist. Soc. Ser. B, 59, 255–268.
[6] Crainiceanu, C. M., Ruppert, D., Carroll, R., Joshi, A. and Goodner, B. (2007). Spatially
adaptive Bayesian penalized splines with heteroscedastic Errors, Journal of Computational and
Graphical Statistics, 16, 265–288.
[7] De Jong, P. and Shephard, N. (1995). The simulation smoother for time series models,
Biometrika, 82, 339–350.
[8] Demmler, A. and Reinsch, C. (1975). Oscillation matrices with spline smoothing, Numerische
Mathematik, 24, 375–382, 10.1007/BF01437406.
[9] Denison, D. G. T., Mallick, B. K. and Smith, A. F. M. (1998). Automatic Bayesian curve fitting,
Journal of the Royal Statistical Society: Series B (Statistical Methodology), 60, 333–350.
[10] Durbin, J. and Koopman, S. J. (2002). A simple and efficient simulation smoother for state
space time series analysis, Biometrika, 89, 603–616.
[11] Eubank, R. L. (1998). Spline Smoothing and Nonparametric Regression, New York: Marcel
Dekker.

334
S. Wood
[12] Fruhwirth-Schnatter, S. (1994). Data augmentation and dynamic linear models, Journal of
Time Series Analysis, 15, 183–202.
[13] Gelfand,A.E.andSmith,A.F.M.(1990).Sampling-basedapproachestocalculatingmarginal
densities, Journal of the American Statistical Association, 85, pp. 398–409.
[14] Green, P. and Silverman, B. (1994). Nonparametric Regression and Generalized Linear Models:
A Roughness Penalty Approach, Monographs on statistics and applied probability, Chapman
& Hall.
[15] Green, P. J. (1995). Reversible jump Markov chain Monte Carlo computation and Bayesian
model determination, Biometrika, 82, 711–732.
[16] Hastie, T. and Tibshirani, R. (1987). Generalized additive models: some applications, Journal
of the American Statistical Association, 82, pp. 371–386.
[17] Holmes, C. and Mallick, B. (2003). Perfect simulation for Bayesian curve and surface fitting,
Technical Report, Imperial College London.
[18] Holmes, C. C. and Mallick, B. K. (2001). Bayesian regression with multivariate linear splines,
Journal of the Royal Statistical Society: Series B (Statistical Methodology), 63.
[19] Jacobs, R., Jordan, M., Nowlan, S. and Hinton, G. (1991). Adaptive mixtures of local experts,
Neural Computation, 3, 79–87.
[20] Jordan, M. and Jacobs, R. (1994). Hierarchical mixtures of experts and the EM algorithm,
Neural Computation, 6, 181–214.
[21] Lang, S. and Brezger, A. (2004). Bayesian P-Splines, Journal of Computational and Graphical
Statistics, 13, 183–212.
[22] Nicholls, N. (2008). Recent trends in the seasonal and temporal behaviour of the El Niño–
Southern Oscillation, Geophysical Research Letters, 35, L19703.
[23] Nychka, D. (2000). Spatial Process Estimates as Smoothers. Smoothing and Regression.
Approaches, Computation and Application, New York: John Wiley and Sons, pp. 393–424.
[24] Ombao, H. C., Raz, J. A., von Sachs, R. and Malow, B. A. (2001). Automatic statistical anal-
ysis of bivariate nonstationary time series, Journal of the American Statistical Association, 96,
543–560.
[25] Panagiotelis, A. and Smith, M. (2008). Bayesian identification, selection and estimation of
semiparametric functions in high-dimensional additive models, Journal of Econometrics, 143,
291–316.
[26] Pintore, A., Speckman, P. and Holmes, C. (2006). Spatially adaptive smoothing splines,
Biometrika, 93, 113–125.
[27] Priestley, M. (1982). Spectral Analysis and Time Series, no. v. 1–2 in Probability and Mathemat-
ical Statistics, Academic Press.
[28] Quinn, B. G. and Thomson, P. J. (1991). Estimating the frequency of a periodic function,
Biometrika, 78, 65–74.
[29] Richardson, S. and Green, P. J. (1997). On Bayesian analysis of mixtures with an unknown
number of components (with discussion), Journal of the Royal Statistical Society: Series B
(Statistical Methodology), 59, 731–792.
[30] Rosen, O. and Stoffer D. S., (2007). Automatic estimation of multivariate spectra via smooth-
ing splines, Biometrika, 94, 335–345.
[31] Rosen, O., Stoffer, D. and Wood, S. A. (2009). Local spectral analysis via a Bayesian mixture
of smoothing splines, Journal of the American Statistical Association, 104, 249–262.
[32] Ruppert, D., Wand, M. and Carroll, R. (2003). Semiparametric Regression, Cambridge series
on Statistical and Probabilistic Mathematics, Cambridge University Press.
[33] Schwarz, G. (1978). Estimating the dimension of a model, The Annals of Statistics, 6, pp.
461–464.
[34] Shumway, R. and Stoffer, D. (2006). Time Series Analysis and its Applications with R Examples,
2nd edn, Springer.

Applications of Bayesian smoothing splines
335
[35] Smith, M. and Kohn, R. (1996). Nonparametric regression using Bayesian variable selection,
Journal of Econometrics, 75, 317–343.
[36] Solow, A. (2006). An ENSO shift revisited, Geophysical Research Letters, 33, L22602.
[37] Tanner, M. A. and Wong, W. H. (1987). The calculation of posterior distributions by data
augmentation, Journal of the American Statistical Association, 82, pp. 528–540.
[38] Trenberth, K. E. and Hoar, T. J. (1996). The 1990–1995 El Niño-Southern oscillation event:
longest on record, Geophysical Research Letters, 23, 57–60.
[39] Verdinelli, I. and Wasserman, L. (1991). Bayesian analysis of outlier problems using the Gibbs
sampler, Statistics and Computing, 1, 105–117.
[40] Wahba, G. (1980). Automatic smoothing of the log periodogram, Journal of the American
Statistical Association, 75, pp. 122–132.
[41]
(1983). Bayesian confidence intervals for the cross-validated smoothing spline, Journal
of the Royal Statistical Society B, 45, 133–150.
[42]
(1990). Spline models for observational data, CBMS-NSF regional conference series in
applied mathematics, Society for Industrial and Applied Mathematics.
[43] Whittle, P. (1957). Curve and Periodogram Smoothing, Journal of the Royal Statistical Society.
Series B (Methodological), 19, pp. 38–63.
[44] Wood, S. A., Kohn, R., Cottet, R., Jiang, W. and Tanner, M. (2008). Locally adaptive non-
parametric binary regression, Journal of Computational and Graphical Statistics, 17.
[45] Wood, S. A. and Kohn, R. J. (1998). A Bayesian approach to robust binary nonparametric
regression, Journal of the American Statistical Association, 93, pp. 203–213.
[46] Wood, S. A., Wenxin, J. and Tanner, M. (2002). Bayesian mixture of splines for spatially
adaptive nonparametric regression. Biometrika, 89, 513–528.

17
Bayesian approaches
to copula modelling
michael stanley smith
17.1 Introduction
C
opula models are now used widely in the empirical analysis of multivariate data. For exam-
ple, major areas of application include survival analysis, where much early work occurred
[15, 51], actuarial science [24], finance [42, 12, 44], marketing [18], transport studies [7, 63], medical
statistics [40, 49] and econometrics [61, 9, 53, 66]. Copula models are popular because they are
flexible tools for the modelling of complex relationships between variables in a simple manner.
They allow for the marginal distributions of data to be modelled separately in an initial step, and
then dependence between variables is captured using a copula function.
However,thedevelopmentofstatisticalinferentialmethodologyforcopulamodelshasbeenlim-
ited. Most research has either been focused on the development and properties of copula functions
(see [35] and [47] for excellent overviews), or their use in solving applied problems. Less attention
has been given to the question of how to estimate the increasing variety of copula models in an
effective manner. To date, the most popular estimation methods are full or two-stage maximum
likelihood estimation [36] and method of moments style estimators in low dimensions [28]. There
has been only limited work on developing Bayesian approaches to formulate and estimate copula
models. This is surprising, given that Bayesian methods have proven successful in both formulating
and estimating multivariate models elsewhere. The aim of this article is two-fold: (i) to introduce
contemporary copula modelling to Bayesian statisticians, and (ii) to outline the advantages of
Bayesian inference when applied to copula models. Therefore, there are two intended audiences:
(i) Bayesians who are unfamiliar with the advances and features of copula models, and (ii) users of
copula models who are unfamiliar with the advantages and features of modern Bayesian inferential
methods.
Previous Bayesian work on copula modelling includes that of Huard, Évin and Favre [33], who
suggest a method to select between different bivariate copulas, and Silva and Lopes [59] who use
Markov chain Monte Carlo (MCMC) methods to estimate low-dimensional parametric copula
functions. Gaussian copula regression models are estimated using MCMC methods in [54], [32]
and [18]. Note that adopting a Gaussian copula does not mean the data are normally distributed.
In [66] the work of [54] is extended to copulas derived by inversion from skew t distributions con-
structedbyhiddenconditioning.Methodstoestimatesocalled‘vine’copulaswithcontinuousmar-
gins using MCMC are proposed in [67] and [45, 46]. It is shown in [54] how Bayesian covariance
selection approaches can be used in Gaussian copulas, while [67] and [46] also show how Bayesian

Bayesian approaches to copula modelling
337
selection ideas can be applied to determine whether, or not, the component ‘pair-copulas’ of a vine
copulaareequaltothebivariateindependencecopula.Itisalsoshownin[67]thattheD-vinecopula
provides a natural decomposition for serial dependence. Bayesian estimation of multivariate time
series with copula-based time varying cross-sectional dependence is also considered in [4]. Last,
[64]suggestefficientBayesiandataaugmentationmethodologyfortheestimationofcopulamodels
for multivariate discrete data, or a combination of discrete and continuous data. Their approach is
for general copula functions, not just Gaussian copulas, or copulas constructed by inversion.
This article is divided into three main sections. The first provides an introduction to copula
modelling. There are a number of excellent in-depth introductions to copulas and their properties;
for example, see [35] and [47]. The purpose of this section is not to replicate any of these, but to
introduceaspectsthat areimportantinBayesiancopulamodelling. This includes anoutlineofwhat
makes copula models so useful, how copulas models can be viewed as transformations, what are
copulasconstructedbyinversionandvinecopulas,andwhytheD-vinecopulaisanattractivemodel
of serial dependence.
In the next two sections Bayesian approaches to formulating and estimating copula models are
discussed separately for multivariate continuous and discrete data. This is because copula models,
and associated methods, differ substantially in these two cases. In Section 17.3 the advantages of
using Bayesian inference over maximum likelihood for the case of continuous data are discussed.
For the Gaussian copula, a sampling scheme that can be used to evaluate the joint posterior distri-
bution of the copula and any marginal model parameters is outlined in detail. Different priors for
the correlation matrix of the Gaussian copula are considered, including priors based on a Cholseky
factorization, the partial correlations as in [54], and the conditional correlations discussed in [36]
and [19]. A new Bayesian selection approach using the latter is outlined, where the fitted copula
model is a Bayesian model average over parsimonious representations of the dependence structure.
Bayesian estimation and selection for D-vine copulas is also outlined. An interesting insight is that
Bayesianselectionofindividualpair-copulasnestsBayesianselectionoftheconditionalcorrelations
for a Gaussian copula. Bayesian estimates of popular dependence metrics from the fitted copula are
also discussed, where parameter uncertainty can be integrated out using the Monte Carlo iterates
from the sampling scheme.
As noted by [21] and [27], popular method of moments style estimators based on ranks should
not be used to estimate copula models for discrete data, making likelihood-based inference more
important. However, the likelihood function differs substantially from that in the continuous case,
and computational issues mean that maximum likelihood estimation is more difficult than in the
continuous case. An effective solution is to employ Bayesian data augmentation, as outlined for a
Gaussian copula in Section 17.4. The priors for the correlation matrix of the Gaussian copula, and
also the Bayesian selection framework, are unaffected by whether the data is discrete or continuous.
Last, it is discussed how measuring dependence in discrete data differs from that in the continuous
case.
17.2 What are copula models?
17.2.1 The basic idea
Consider initially the bivariate case with two random variables, Y1 and Y2, with marginal dis-
tribution functions F1(y1) and F2(y2), respectively. A copula model is a way of constructing
the joint distribution of (Y1, Y2). Sklar [60] shows that there always exists a bivariate function
C : [0, 1]2 →[0, 1], such that

338
M. S. Smith
F(y1, y2) = C(F1(y1), F2(y2))
The function C is itself a distribution function with uniform margins on [0, 1], and is labelled the
‘copula function’. It binds together the univariate margins F1 and F2 to produce bivariate distribu-
tion F.
If both margins F1 and F2 are continuous distribution functions, then there is a unique copula
functionCforanygivenjointdistributionfunctionF.IfeitherF1 orF2 arediscrete-valued,thenCis
not unique. However, the objective of copula modelling is not to find the copula function(s) C that
satisfy Sklar’s representation, given knowledge of F1, F2 and F. Instead, the objective is to construct
a joint distribution F from a copula function C and marginal models for F1 and F2. In this way,
copula models can be used equally for discrete or continuous data, or a combination of both.
ItisimportanttonoticethatthecopulafunctionCdoesnotdeterminethemarginaldistributions
of F, but accounts for dependence betweenY1 and Y2. For example, in the case where Y1 and Y2 are
independent, the copula function is C(u1, u2) = u1u2, so that F( y1, y2) = F1( y1)F2( y2). This
copula function is called the ‘independence copula’.
The copula model is easily generalized to m dimensions as follows. Let Y = (Y1, . . . , Ym) ∈SY
be a random vector with elements that have marginal distribution functions F1, . . . , Fm, then the
joint distribution function of Y is
F(y1, . . . , ym) = C(F1(y1), . . . , Fm(ym)) .
(17.1)
Again, the copula function C : [0, 1]m →[0, 1] is itself a distribution function for random vector
U = (U1, . . . , Um)′ with uniform margins on [0, 1]. As before, if all elements of Y are continuous
random variables, then there is a unique copula function C for any given F, but this is not the case if
oneormoreelementsarediscrete-valued.Nevertheless,equation(17.1)canstillbeusedtoconstruct
a well-defined joint distribution F, given F1, . . . , Fm and C, just as in the bivariate case.
17.2.2 Why are copula models so useful?
A key feature of the copula representation of a joint distribution is that it allows for the margins
to be modelled separately from the dependence structure. This promotes a ‘bottom-up’ modelling
strategy, where models are first developed one-by-one for each univariate margin. Dependence is
then introduced by an appropriate copula function C. Sklar’s theorem reassures that this is not an
ad-hoc approach, and that there should be at least one copula function C that correctly constructs
the joint distribution F, as long as the marginal models F1, . . . , Fm are accurate. Compare this to
a more restrictive ‘top-down’ alternative, where the joint distribution function F is selected first,
which then determines the form of the marginals. For example, if F is a multivariate t distribution
with ν degrees of freedom, then each Fj is restricted to be univariate t with common degrees of
freedom ν.
For much applied multivariate modelling, the flexibility that the bottom-up approach allows is
compelling. The marginal models can be of the same form, or completely different, including any
of the following:
(i) Parametric distributions A parametric distribution Fj(yj; θj), with parameters θj. For exam-
ple, Fj may be a t distribution with location μj, scale σj and degrees of freedom νj,
so that θj = {μj, σj, νj}. A copula model with t distributions for each margin is more
flexible than a multivariate t distribution because the level of kurtosis can differ in
each dimension [23]. For discrete data, Fj may be a negative binomial distribution with
stopping parameter rj > 0 and success parameter pj ∈(0, 1), so that θj = {rj, pj}. The

Bayesian approaches to copula modelling
339
negative binomial is a very popular model for count data that exhibit heterogeneity, and
copula models provide flexible multivariate extensions [41, 50, 18].
(ii) NonparametricdistributionsApproacheswhereeachmarginismodellednonparametrically
using the empirical distribution function (or a smoothed variant) have long been advo-
cated in the copula literature; for example, see [26], [58] and [11]. Similarly, Fj can be
modelled using Bayesian nonparametric methods; see [31] for recent accounts of these.
Alternatively, rank likelihoods can be used for each marginal model as outlined by [32]. In
all cases, copula models provide simple multivariate extensions of existing nonparametric
methods.
(iii) Regression models Univariate regression models can be used for each margin, in which case
the resulting copula model is called a ‘copula regression model’ [52, 54, 68]. The regression
coefficients βj can be pooled across margins j = 1, . . . , m, so that β1 = β2 = . . . = βm,
in which case the copula model is then an extension of the multivariate regression model.
If the regression coefficients differ for each margin, then the copula model extends the
‘seemingly unrelated regression’ model popular in econometric analysis [74].
(iv) Time series models When observations are made on a multivariate vector over time, the
marginalmodelscanbeparametrictimeseriesmodels,andcontemporaneousdependence
captured via the copula function [53, 10, 4]. Popular choices are GARCH or stochastic
volatility models for the margins. As with copula regression models, marginal parameters
can either be pooled or allowed to vary across the margin.
17.2.3 Copula functions and densities
The three conditions that C needs to meet to be an admissible copula function are listed in
[47, p. 45], and are:
(i) For every u = (u1, . . . , um) ∈[0, 1]m, C(u) = 0 if at least one element ui = 0.
(ii) If all elements of u are equal to one, except ui, then C(u) = ui.
(iii) For each a = (a1, . . . , am), b = (b1, . . . , bm) ∈[0, 1]m, such that ai ≤bi for all
i = 1, . . . , m,
bm
ambm−1
am−1 · · · b1
a1C(v) ≥0 .
Here, bkak is a differencing notation defined as
bkakC(u1, . . . , uk−1, vk, uk+1, . . . , um) =
C(u1, . . . , uk−1, bk, uk+1, . . . , um) −C(u1, . . . , uk−1, ak, uk+1, . . . , um) ,
withvk avariableofdifferencing,andv = (v1, . . . , vm).Noticethatifc(u) = ∂mC(u)/∂u1 . . . ∂um
exists, then property (iii) is equivalent to
 b1
a1
· · ·
 bm
am
c(u)du ≥0 .
Properties (i) and (iii) are satisfied if C(u) is a distribution function on [0, 1]m, while property (ii)
is satisfied if C also has uniform margins. The density function c(u) is commonly referred to as the
‘copula density’.

340
M. S. Smith
Table 17.1 Copulafunctions,densityfunctionsandmeasuresofdependencefortheFrank,Clayton
and Gumbel copulas. For the Frank copula, the function D1(φ) = 1
φ

 φ
0 t/(exp(t) −1)dt is the
Debye function; see [2; p. 998].
Frank (φ ∈(−∞, 0) ∪(0, ∞))
C(u1, u2; φ) = −1
φ log

1 + (exp(−φu1)−1)(exp(−φu2)−1)
exp(−φ)−1

c(u1, u2; φ) = φ

exp(φ(1 + u1 + u2))(exp(φ) −1)

× [exp(φ) −exp(φ(1 + u1)) −exp(φ(1 + u2)) + exp(φ(u1 + u2))]−2
τ1,2(φ) = 1 + 4
φ (D1(φ) −1), λL
1,2(φ) = λU
1,2(φ) = 0
Clayton (φ ∈(−1, ∞)\{0})
C(u1, u2; φ) = max

(u−φ
1
+ u−φ
2
−1)−1/φ, 0

c(u1, u2; φ) = max

(1 + φ)(u1u2)−1−φ 
u−φ
1
+ u−φ
2
−1
−1/φ−2
, 0

τ1,2(φ) = φ/(φ + 2), λL
1,2(φ) = 2−1/φ and λU
1,2(φ) = 0
Gumbel (φ ≥1)
C(u1, u2; φ) = exp(−(˜uφ
1 + ˜uφ
2 )1/φ) , where˜uj = −log(uj)
c(u1, u2; φ) = C(u1, u2; φ) (u1 u2)−1(˜uφ
1 + ˜uφ
2 )−2+2/φ(˜u1˜u2)φ−1
×
1
1 + (φ −1)

˜uφ
1 + ˜uφ
2
−1/φ2
τ1,2(φ) = 1 −φ−1, λL
1,2(φ) = 0 and λU
1,2(φ) = 2 −21/φ
In the vast majority of cases parametric copula functions C(u; φ), with parameters φ, are used in
applied analysis. There are a large number of choices for C, with [35] and [47] providing overviews
of a wide range of copula functions and their properties. Particularly popular in the bivariate case
are the family of Archimedean copulas; see [47; Chap. 4]. Three of the most popular Archimedean
copulas are the Frank, Clayton and Gumbel. These are listed in Table 17.1, along with their densities
and measures of dependence.
17.2.4 Constructing copulas by inversion (of Sklar’s theorem)
Beyond the bivariate case, copulas that are constructed through inversion of Sklar’s theorem are
popular; see [47, Sect. 3.1]. To derive a copula function in this way, let X = (X1, . . . , Xm) ∈SX
have distribution function G(x; φ), with parameters φ and strictly monotonic univariate marginal
distribution functions G1(x1; φ), . . . , Gm(xm; φ). By Sklar’s theorem, there always exists a copula
function C, such that
G(x; φ) = C(G1(x1; φ), . . . , Gm(xm; φ)) .
Denoting uj = Gj(xj; φ), then xj = G−1
j
(uj; φ), and substituting this into the equation above
defines a copula function:

Bayesian approaches to copula modelling
341
C(u1, . . . , um; φ) = G(G−1
1 (u1; φ), . . . , G−1
m (um; φ); φ) .
(17.2)
It is important to notice that the multivariate distribution G is only used to construct the copula
function C, and is not the distribution function of the random vector Y, which remains F as given
in equation (17.1). The parameters φ of the distribution of X are the parameters for copula func-
tion C.
Elliptical distributions are common choices for G [23], and the resulting copula functions are
collectively called ‘elliptical copulas’. The Gaussian copula [68] is the most popular of these, where
Gisthedistributionfunctionofamultivariatenormalwithzeromean,correlationmatrix andunit
variances in each dimension. In this case, φ = , G(x; φ) = m(x; ) and Gj(xj; φ) = 1(xj, 1),
with k(·; V) the distribution function of a k-dimensional N(0, V) distribution. The Gaussian
copula function is therefore
C(u1, . . . , um; φ) = m(−1
1 (u1; 1), . . . , −1
1 (um; 1); ) .
(17.3)
The restrictions on the first and second moments of X are necessary to identify the copula param-
eters  in the likelihood.
When each marginal distribution Fj is univariate normal with mean μj and variance σ 2
j , then
uj = 1(yj −μj; σ 2
j ). If a Gaussian copula is also assumed, then the copula model for Y simplifies
to a multivariate normal distribution with mean μ = (μ1, . . . , μm) and covariance matrix DD,
with D = diag(σ1, . . . , σm).
Other choices for G include a multivariate t distribution, which results in the t copula [20], or
a multivariate skew t distribution [66]. When selecting G, care has to be taken to consider any
restrictions on φ that may be necessary to identify the parameters in the likelihood.
17.2.5 Copula models as transformations
Copula modelling can be interpreted as a transformation from the domain of the data, to another
domain where the dependence is easier to model. The transformation is depicted in Figure 17.1.
If the elements of Y are continuous-valued, the transformation Yj →Uj is one-to-one, as is the
transformation Yj →Xj for inversion copulas.
The density of Y is given by
f(y) = ∂
∂yC(F1(y1), . . . , Fm(ym)) = c(u)
m

j=1
fj(yj),
(17.4)
Uj = Fj(Yj)
Xj = G−1
j
(Uj)
Variable
Y
−→
U
−→
X
Domain
SY
−→
[0, 1]m
−→
SX
Joint CDF
F(y)
−→
C(u)
−→
G(x)
Marginal CDFs
Fj(yj)
−→
Uniform
−→
Gj(xj)
Figure 17.1 Depiction of the transformation underlying a copula model. The right-hand column for
variable X is for copulas constructed by inversion only. The transformations are given in the top row
for Yj continuous-valued.

342
M. S. Smith
with u = (u1, . . . , um), uj = Fj(yj), fj(yj) =
∂
∂yj Fj(yj) and c(u) = ∂
∂uC(u).
However, when the data are discrete-valued, the probability mass function is obtained by differ-
encing the distribution function in equation (17.1), so that
pr(Y = y) = bm
ambm−1
am−1 · · · b1
a1C(v),
(17.5)
where v = (v1, . . . , vm) are indices of differencing. The upper bound bj = Fj(yj) and lower bound
aj = Fj(y−
j ) is the left-hand limit of Fj at yj, with Fj(y−
j ) = Fj(yj −1) when Yj is ordinal-valued.
In this case the transformations Yj →Uj and Yj →Xj are both one-to-many. This means that the
elements Uj|Yj = yj and Xj|Yj = yj are only known up to bounds, with
Fj(y−
j ) ≤Uj < Fj(yj) and,
G−1
j
(Fj(y−
j )) ≤Xj < G−1
j
(Fj(yj)),
for j = 1, . . . , m. Nevertheless, Y, U and X still have distribution functions F, C and G, respectively.
It is outlined later, in Section 17.4, how interpreting a copula model as a transformation allows
for the construction of Bayesian data augmentation schemes to evaluate the posterior distribution
when one or more margins are discrete.
17.2.6 Vine copulas
Muchrecentresearchinthecopulaliteraturehasfocusedonbuildingcopulasinm > 2dimensions.
One popular family of copulas are called ‘vines’, which are constructed from sequences of bivariate
copulas. Early examples of this approach are found in [34, 35], while [6] organize the different
decompositions in a systematic way. The bivariate copulas are called ‘pair-copulas’ in [1], and vines
are also known as pair-copula constructions (PCCs). Recent overviews are given by [30] and [17].
If the elements of Y are ordered in time, so that Yt is observed before Yt+1, then [67] point
out that a vine labelled ‘drawable’ by [6] (or D-vine for short) proves a natural way of characterizing
serialdependence;particularlyMarkovianserialdependence.Thiscanbemotivatedbyconsidering
the following decomposition of the density of U,
c(u) =
m

t=2
f(ut|ut−1, . . . , u1) ,
where f(u1) = 1 because the marginal distribution of u1 is uniform on [0, 1]. The idea is to build
a representation for each conditional distribution f(ut|ut−1, . . . , u1) as follows. For s < t there
always exists a density ct,s on [0, 1]2 such that
f(ut, us|ut−1, . . . , us+1) = f(ut|ut−1, . . . , us+1)f(us|ut−1, . . . , us+1)
× ct,s (F(ut|ut−1, . . . , us+1), F(us|ut−1, . . . , us+1); ut−1, . . . , us+1) .
(17.6)
Here, F(ut|ut−1, . . . , us+1) and F(us|ut−1, . . . , us+1) are conditional distribution functions of Ut
and Us, respectively. This is the theorem of Sklar applied conditional on {Ut−1, . . . , Us+1}. In a
vinecopula,ct,s isthedensityofabivariate‘pair-copula’anditissimplifiedbydroppingdependence
on (ut−1, . . . , us+1); see [30] for a discussion of why this is often a good approximation. By setting
s = 1, application of equation (17.6) gives

Bayesian approaches to copula modelling
343
f(ut|ut−1, . . . , u1) = ct,1(F(ut|ut−1, . . . , u2), F(u1|ut−1, . . . , u2))f(ut|ut−1, . . . , u2).
Denoting ut|j = F(ut|ut−1, . . . , uj) and uj|t = F(uj|ut, . . . , uj+1), for j < t,12 repeated applica-
tion of the above with s = 2, 3, . . . , t −1 leads to the following:
f(ut|ut−1, . . . , u1) =
t−1

s=1
ct,s(ut|s+1, us|t−1),
where the notation ut|t = ut, for t = 1, . . . , m. Therefore, the D-vine copula is given by
c(u) =
m

t=2
t−1

s=1
ct,s(ut|s+1, us|t−1)

(17.7)
which is a product of m(m −1)/2 pair-copula densities, and u = (u1|1, . . . , um|m). If each pair-
copula ct,s has copula parameter φt,s, then the parameter vector of the D-vine is φ = {φt,s; t =
2, . . . , m, s < t}. The hardest aspect of using the copula in equation (17.7) is the evaluation of the
argumentsofthecomponentpair-copulas.AnO(m2)recursivealgorithmfortheevaluationofthese
from u is given in [1], based on the identity in [34, p. 125]; see also Algorithm 1 in [67].13
Algorithm Evaluation of the Arguments of a D-vine
k = 1, . . . , m −1 and i = k + 1, . . . , m:
Step 1: Compute ui|i−k = hi,i−k(ui|i−k+1|ui−k|i−1; φi,i−k)
Step 2: Compute ui−k|i = hi,i−k(ui−k|i−1|ui|i−k+1; φi,i−k).
The functions ht,s(u1|u2; φt,s) =

 u1
0 ct,s(v, u2; φt,s)dv are the conditional distribution functions
for the pair-copula with density ct,s; see [1] and [67] for lists of these for some common bivariate
copulas.
Because any combination of bivariate copula functions can be employed for the pair-copulas,
the D-vine copula can be extremely flexible. Moreover, other vine copulas can be constructed using
alternative sequences of pair-copulas; see [6] and [1]. However, the D-vine at Equation (17.7) is
well-motivated when the elements of U are time-ordered.
17.2.7 Measures of dependence
Measures of dependence for copula models are discussed in [47; Chap. 5] and [35; Chap. 2]. In
general, these are marginal pairwise dependencies between elements Yi and Yj. Kendall’s tau and
Spearman’s rho are the two most popular measures of pairwise concordance, and empirical analysts
are often familiar with sample versions based on ranked data. However, when Yi and Yj are contin-
uous-valued, and Y follows the copula model at equation (17.1), the population equivalents can be
expressed as
τi,j = 4
 1
0
 1
0
CB
i,j(ui, uj)dCB
i,j(ui, uj)

−1 = 4E(CB
i,j(Ui, Uj)) −1
12 [67] denote ut|j = F(yt|yt−1, . . . , yj) and uj|t = F(yj|yt, . . . , yj+1) for Y1, . . . , Ym continuous random
variables. However, this can be shown to be equivalent to the definition of ut|j and uj|t employed here.
13 The algorithm here corrects a minor subscript typographical error in the algorithm in [67].

344
M. S. Smith
and
ρS
i,j = 12
 1
0
 1
0
uiujdCB
i,j(ui, uj) −3 = 12E(UiUj) −3 .
(17.8)
In the above expressions, CB
i,j is the distribution function of (Ui, Uj) and is a bivariate margin of
the m-dimensional copula function C. For some copulas CB
i,j can be computed in closed form, but
for others this is not possible. Similarly, the expectations in the expressions for τi,j and ρS
i,j can
sometimes be computed in closed form, but for other choices of copulas they are computable only
numerically, or by Monte Carlo simulation. Within a Bayesian MCMC framework the latter often
proves straightforward; see Section 17.3.5.
In many situations high values of Yi and Yj exhibit different levels (or even directions) of depen-
dence than low values of Yi and Yj; something that is called ‘asymmetric (pairwise) dependence’. As
noted by [47; Chap. 4], when Yi and Yj are continuous-valued, then the dependence properties of
the bivariate margin in these two variables is characterized by the dependence properties between
Ui and Uj. In this case, measures of asymmetric dependence are often based on the conditional
probabilities
λup
i,j (α) = pr(Ui > α|Uj > α)
λlow
i,j (α) = pr(Ui < α|Uj < α),
where 0 < α < 1. The limits of these are called the upper and lower tail dependencies [35, p. 33],
and denoted as
λup
i,j = lim
α↑1 λup
i,j (α) , and λlow
i,j
= lim
α↓0 λlow
i,j (α) .
For bivariate copula models there is only a single pairwise combination, Y1 and Y2, and for many
bivariatecopulafunctionsdependencemeasuresareavailableinclosedform.Forexample,Table17.1
gives expressions for measures of dependence for the Frank, Gumbel and Clayton copulas; see [35],
[47] and [33] for others. Pairwise dependence measures in multivariate m-dimensional elliptical
copulas can also have closed form expressions. In particular, the Gaussian copula has zero tail
dependence, with λup
i,j = λlow
i,j
= 0; whereas, the t copula has tail dependence that is non-zero, but
is symmetric with λup
i,j = λlow
i,j . When employing a copula model it is important to ensure that the
copula has dependence properties that are consistent with those exhibited by the data.
17.3 Bayesian inference for continuous margins
Whenthedataarecontinuous,thelikelihoodof nindependentobservationsy = {y1, . . . , yn},each
distributed as equation (17.1), is f(y|, φ) = 	n
i=1 f(yi|, φ), where yi = (yi1, . . . , yim)′ and
f(yi|, φ) = c(ui; φ)
m

j=1
fj(yij; θj) .
(17.9)
Here, ui = (ui1, . . . , uim)′, uij = Fj(yij; θj),  = {θ1, . . . , θm} are any parameters of the marginal
models,andfj(yij; θj) =
∂
∂yij Fj(yij; θj)isthemarginaldensityofyij.Initially,equation(17.9)appears

Bayesian approaches to copula modelling
345
separable in θ1, . . . , θm and φ, but this is not the case because ui depends on . Most parametric
copula functions have analytical expressions for the densities c(u; φ), so that maximum likelihood
estimationisoftenstraightforward.However,thereareanumberofcircumstanceswhereaBayesian
analysis can be preferable:
(i) For more complex marginal models Fj(yij; θj) and/or copula functions C(u; φ), the likeli-
hood can be hard to maximize directly. One solution is to use a two-stage estimator, where
the marginal model parameters θj are estimated first, and then φ estimated conditional on
these. In the copula literature, this is called ‘inference for margins’; see [36] and references
therein for a discussion. Another solution is to use to an iterative scoring algorithm to
maximize the likelihood, as suggested by [69]. However, an attractive Bayesian alternative
in this circumstance is to construct inference from the joint posterior f(, φ|y) evaluated
in a Monte Carlo manner, with  and φ generated separately in a Gibbs style sampling
scheme; see [54], [59] and [4] for discussions.
(ii) Bayesian hierarchical modelling has proven very successful for the modelling of multivari-
ate data. This includes parsimonious modelling of covariance structures using Bayesian
selection and model averaging; see [29], [65], [72] and [25] for examples. Bayesian selec-
tion can be extended to nonlinear dependence by considering priors with point mass
components for φ. For example, [54] use a ‘spike and slab’ prior similar to [72] for the
off-diagonal elements of the concentration matrix −1 of a Gaussian copula. Similarly,
[67] use Bayesian selection ideas to mix over independent and dependent pair-copulas in
a vine copula. Hierarchical models can also be employed for the margins Fj(yj; θj), and
estimated jointly with the dependence structure captured by the copula function.
(iii) When estimating a copula model, the objective is often to construct inference on mea-
sures of dependence, quantiles and/or functionals of the random variable vector Y or
parameters (, φ). Evaluation of the posterior distribution of these quantities is often
straightforward using MCMC methods.
17.3.1 The Gaussian copula model
To illustrate, Bayesian estimation of a Gaussian copula model for continuous margins is outlined as
suggested by [54]. Following [68] and others, derivation of the copula density is straightforward by
differentiation of equation (17.3), so that
c(u; φ) = ∂
∂uC(u; φ) = ||−1/2 exp

−1
2x′(−1 −I)x

(17.10)
where x = (−1
1 (u1; 1), . . . , −1
1 (um; 1))′. Thus, the likelihood at equation (17.9) is a function
of  and , and can be written as
f(y|, ) = ||−n/2
⎛
⎝
n

i=1
exp

−1
2x′
i(−1 −I)xi
 m

j=1
fj(yij; θj)
⎞
⎠,
(17.11)
where xi = (xi1, . . . , xim)′, xij = −1
1 (uij; 1) and uij = Fj(yij; θj). Bayesian estimation can be
undertaken using the following MCMC sampling scheme:

346
M. S. Smith
Sampling scheme. Estimation of a Gaussian copula
Step 1: Generate from f(θj|{\θj}, , y) for j = 1, . . . , m.
Step 2: Generate from f(|, y).
Here, {A\B} is notation for A with component B omitted. Steps 1 and 2 are repeated (in sequence)
a large number of times, with each repeat usually called a ‘sweep’ in the Bayesian literature. The
scheme requires an initial (feasible) state for the parameter values, which is denoted here as
([0], φ[0]).TheiteratesfromtheschemeformaMarkovchain,whichcanbeshowntoconvergeto
draws from the joint posterior distribution f(, φ|y), which is the (unique) invariant distribution
of the chain. After an initial number of sweeps, the chain is assumed to have converged and sub-
sequent iterates form a Monte Carlo sample from which the parameters are estimated, and other
Bayesian inference obtained as outlined in Section 17.3.5. For introductions to MCMC methods for
computing Bayesian posterior inference see [70] and [55].
The posterior in Step 1 is given by
f(θj|{\θj}, , y) ∝f(y|, )π(θj)
∝||−n/2
 n

i=1
exp

−1
2x′
i(−1 −I)xi

fj(yij; θj)

π(θj) ,
(17.12)
where π(θj) is the marginal prior for θj. In general, the density is unrecognizable because xij is
a function of θj, so [54] suggest using a Metropolis–Hastings (MH) step with a multivariate t
distribution as a proposal to generate θj in Step 1. The mean of the t distribution, ˆθj, is the mode of
equation (17.12), which is obtained via quasi-Newton–Raphson methods applied to the logarithm
of the posterior density. The Hessian
H = ∂2 log(f(θj|{\θj}, , y))
∂θj∂θ′
j
&&&&&θj= ˆθj
is calculated numerically using finite difference methods. The scale matrix of the MH proposal is
−H−1, and a low degrees of freedom, such as ν = 5 or ν = 7, is employed so that the proposal
dominates the target density in the tails. If θj has too many elements for H to be evaluated in
a numerically stable and computationally feasible fashion, θj can be partitioned and generated
separately. Alternative MH steps are also possible, including those based on the widely employed
random walk proposals.
The approach used to generate  in Step 2 varies depending on the prior and matrix parameter-
ization adopted, of which there are several alternatives. For example, [54] consider a prior on the
off-diagonal elements of −1, which is equivalent to assuming a prior for the partial correlations
Corr(Xt, Xs|Xj/∈{s,t}) for t = 2, . . . , m; s < t. Alternatively, [32] suggests using a prior for  in
a Gaussian copula that results from an inverse Wishart prior for a covariance matrix. However,
because  is just a correlation matrix (for X), any prior for a correlation matrix can also be used; for
example, see those suggested by [5], [43], [3], [19] and references therein.
17.3.1.1 Prior based on a Choelsky factor
One such prior for a correlation matrix is based on a Cholesky factorization, which is particularly
suited to longitudinal data. This prior uses the decomposition
 = diag()−1/2 diag()−1/2
(17.13)

Bayesian approaches to copula modelling
347
where  is a positive definite matrix, and diag() is a diagonal matrix comprised of the leading
diagonal of . The matrix −1 = R′R, with R = {rk,j} being an upper triangular Cholesky factor,
and to ensure that the parameterization is unique, rk,k = 1, for k = 1, . . . , m. Generation of  in
Step 2 is undertaken by generating the elements {rk,j; j = 2, . . . , m, k < j} one at a time from the
conditional posterior
f(rk,j|{R\rk,j}, , y) ∝||−n/2
 n

i=1
exp

−1
2x′
i(−1 −I)xi

π(rk,j)
using random walk MH; see [70; p.177] for a discussion of this simulation tool. Once an iter-
ate of R is obtained, the iterate of  can be computed using the relationship at equation (17.13).
Using a different prior, [32] uses a similar approach to generate a correlation matrix for a Gaussian
copula.
17.3.1.2 Prior based on partial correlations
It is suggested in [19] to parameterize a correlation matrix using the partial correlations
λt,s = Corr(Xt, Xs|Xt−1, . . . , Xs+1) , for s < t.
(17.14)
This prior is based on the work of [37], who notes that these are unconstrained on (−1, 1),
and that # = {λt,s; t = 2, . . . , m, s < t} provides a unique parameterization of . Note that λt,s
is sometimes called a ‘semi-partial’ correlation because it is not the correlation conditional on
all other variables Corr(Xt, Xs|Xj/∈{t,s}), which is the ‘full’ partial correlation considered by [54].
One advantage is that the conditional distribution of λt,s|{#\λt,s} is only bounded to (−1, 1),
whereas the conditional distribution of the full partial correlations have more complex bounds.
Beta or uniform priors for λt,s are suggested by [19], which can be employed and Step 2 under-
taken by generating the elements of # one at a time, again using MH with a random walk pro-
posal. Once an iterate of # is obtained,  can be computed using the identity at equation (2)
of [19].
There is an interesting link between the Gaussian copula parameterized by the partial correla-
tions#,andtheD-vinecopulainequation(17.7).Whenthepair-copulasintheD-vinearebivariate
Gaussian copulas, with densities
ct,s(u1, u2; φt,s) =
1
;
1 −φ2t,s
exp

−
φ2t,s(x2
1 + x2
2) −2φt,s x1 x2
2(1 −φ2t,s)

(17.15)
where x1 = −1
1 (u1; 1) and x2 = −1
1 (u2; 1), then the D-vine copula can be shown to be a
Gaussiancopulawithcopuladensityatequation(17.10);see[1]and[30].Inthiscase,theindividual
pair-copula parameters φt,s above are the partial correlations λt,s.
17.3.2 Bayesian selection in a Gaussian copula
Bayesian selection approaches can be employed to allow for parsimonious modelling of  in a
Gaussian copula. It is well known that Bayesian selection can significantly improve estimates of
a covariance matrix compared to maximum likelihood; see [73], [29], [65], [72], [25] and oth-
ers for extensive evidence to this effect. As shown by [54], this is also the case when estimating
the dependence structure of Y using a Gaussian copula model. They consider a selection prior
with point mass probabilities on the off-diagonal elements of −1. In the Gaussian copula this is

348
M. S. Smith
equivalent to identifying for which pairs (t, s) the full partial correlation Corr(Xt, Xs|Xj/∈{s,t}) = 0.
ThisalsocorrespondstoconditionalindependencebetweenYt andYs,withtheconditionaldensity
f(yt, ys|yj/∈{s,t}) = f(yt|yj/∈{s,t})f(ys|yj/∈{s,t}).
17.3.2.1 Priors for selection
Bayesian selection can also be undertaken for the semi-partial correlations # defined in equa-
tion (17.14). In the Gaussian copula this is equivalent to determining for which pairs (t, s) there
is conditional independence between elements of Y, with conditional density
f(yt, ys|yt−1, . . . , ys+1) = f(yt|yt−1, . . . , ys+1)f(ys|yt−1, . . . , ys+1)
when λt,s = 0. To introduce a point mass probability for this value, binary indicator variables γ =
{γt,s; t = 2, . . . , m, s < t} are introduced, such that
λt,s = 0 iff γt,s = 0.
The non-zero partial correlations λt,s|γt,s = 1 are independently distributed with proper prior
densities π(λt,s). It is noted by [37] that λt,s|{#\λt,s} are unconstrained on [−1, 1], so that
either independent uniform or Beta priors are simple choices for π(λt,s); see [19]. In compar-
ison, each full partial correlation has bounds that are complex functions of the other full par-
tial correlations and computationally demanding to evaluate. For this reason, Bayesian selection
using the partial correlations # is computationally less burdensome than using the full partial
correlations.
The prior on the indicators γ can be highly informative when the number of indicators N =
m(m −1)/2 is large. For example, if wγ = 
t,s γt,s is the number of non-zero elements in #,
then assuming flat marginal priors π(γt,s) = 1/2 puts high prior weight on values for wγ ≈N/2.
This problem has been noted widely in the variable selection literature; see [38], [75] and [8]. One
solution is to employ the conditional prior
π(γt,s = 1|{γ \γt,s}) ∝B(N −wγ + 1, wγ + 1) ,
(17.16)
where B(·, ·) is the beta function. This prior has been used effectively in the Bayesian selec-
tion literature, with early uses in [62] and [65]. It corresponds to assuming the joint mass
function
π(γ ) =
1
N + 1

N
wγ
−1
.
The implied prior for the total number of non-zero elements of # is uniform, with π(wγ ) =
1/(1 + N), while the marginal priors π(γt,s) are all equal; see [57] for a discussion. This prior is
also equivalent to the uniform volume-based prior suggested by [72] and [16] on the model space.
17.3.2.2 MCMC sampling scheme
To evaluate the joint posterior distribution of the indicator variables and the partial correlations
#, latent variables ˜λt,s, for t = 2, . . . , m, s < t, are introduced such that λt,s = ˜λt,s if γt,s = 1.
Notice that λt,s is known exactly given the pair (˜λt,s, γt,s), so it is sufficient to implement a sampling
scheme to evaluate the joint posterior f( ˜#, γ , |y), where ˜# = {˜λt,s; t = 2, . . . , m, s < t}, as
below.

Bayesian approaches to copula modelling
349
Sampling scheme. Bayesian selection for a Gaussian copula
Step 1: Generate from f(θj|{\θj}, , y) for j = 1, . . . , m.
Step 2: Generate from f(˜λt,s, γt,s|, { ˜#\˜λt,s}, {γ \γt,s}, y) for t = 2, . . . , m, s < t.
Step 3: Compute # from ( ˜#, γ ), and then  from #.
Step 1 is unchanged from that in Section 17.3.1, while Step 2 consists of MH steps to generate each
pair (˜λt,s, γt,s), conditional on the others. The MH proposal density is
q(˜λt,s, γt,s) = q1(γt,s)q2(˜λt,s) .
To generate from the proposal q above, an indicator is generated from q1(γt,s = 0) =
q1(γt,s = 1) = 1/2, and ˜λt,s from a symmetric random walk proposal q2 constrained to (−1, 1).
For example, one such symmetric proposal for q2 is to generate a new value of ˜λt,s from a
normal distribution with mean equal to the old value, standard deviation 0.01, and constrained
to (−1, 1).
Temporarily dropping the subscripts (t, s) for convenience, a new iterate (˜λnew, γ new) generated
from the proposal q is accepted over the old value (˜λold, γ old) with probability
min

1, α π(˜λnew)
π(˜λold)
κ

,
(17.17)
where κ is an adjustment due to the bounds (−1, 1) on λ. If the symmetric density q2(·) has
distribution function Q2(·), then this adjustment is
κ = Q2(1 −˜λold) −Q2(−1 −˜λold)
Q2(1 −˜λnew) −Q2(−1 −˜λnew)
.
If a uniform prior is adopted for ˜λt,s, as suggested in [19], then the ratio π(˜λnew)/π(˜λold) = 1 in
equation (17.17). At each generation in Step 2, the likelihood in equation (17.11) is a function of
(˜λ, γ ), so it can be written here as L(˜λ, γ ). Using this notation, the value α in equation (17.17) can
be expressed separately for the four possible configurations of (γ old, γ new) as:
α

(˜λold, γ old = 0) →(˜λnew, γ new = 0)

= 1
α

(˜λold, γ old = 0) →(˜λnew, γ new = 1)

= L(˜λnew, γ new = 1)δ1
L(0, γ old = 0)δ0
α

(˜λold, γ old = 1) →(˜λnew, γ new = 0)

=
L(0, γ new = 0)δ0
L(˜λold, γ old = 1)δ1
α

(˜λold, γ old = 1) →(˜λnew, γ new = 1)

= L(˜λnew, γ new = 1)
L(˜λold, γ old = 1)
where δ0 and δ1 are the conditional probabilities from equation (17.16) that γt,s = 0 and 1, respec-
tively. Notice that when (γ old = 0) →(γ new = 0) the likelihood does not need computing to
evaluate the acceptance ratio at Equation (17.17). This case will occur frequently whenever there is
a high degree of sparsity in the dependence structure, so that each sweep of Step 2 will be much
faster than if no selection were considered.

350
M. S. Smith
Reintroducing subscripts, Step 3 of the sampling scheme is straightforward, with each partial
correlation
λt,s =

0 if γt,s = 0
˜λt,s if γt,s = 1
and the correlation matrix  can be obtained directly from # using the relationship in [37]
and [19].
17.3.3 Bayesian estimation and selection for a D-vine
Bayesian estimation for vine copulas is discussed in [45, 46] and [67]. The latter authors consider
Bayesian selection and model averaging via the introduction of indicator variables in the tradition
of Bayesian variable selection. It is this approach that is outlined here, although readers are referred
to [67] for a full exposition.
The objective of Bayesian selection for a vine copula is to identify component pair-copu-
las that are equal to the bivariate independence copula. Recall that the bivariate independence
copula has copula function C(u1, u2) = u1u2, and corresponding copula density c(u1, u2) =
∂C(u1, u2)/∂u1∂u2 = 1. This leads to a parsimonious representation because the independence
copula is not a function of any parameters.
For the D-vine with copula density at equation (17.7), Bayesian selection introduces indicator
variables γ = {γt,s; t = 2, . . . , m, s < t}, where
ct,s(u1, u2) =

1
if γt,s = 0
c⋆t,s(u1, u2; φt,s) if γt,s = 1.
(17.18)
In the above, c⋆t,s is a pre-specified bivariate copula density with parameter φt,s.14 The
copula type can vary with (t, s), but for simplicity only the case where c⋆t,s(u1, u2; φt,s) =
c⋆(u1, u2; φt,s) is considered here. That is, each pair-copula ct,s is either an independence cop-
ula, or a bivariate copula of the same form for all pair-copulas, but with differing parameter
values. From equation (17.6) it follows that when ct,s(u1, u2) = 1, f(ut, us|ut−1, . . . , us+1) =
f(ut|ut−1, . . . , us+1)× f(us|ut−1, . . . , us+1), so that there is conditional independence between
Ut and Us.
The pre-specified bivariate copula can nest the independence copula, so that there exists a value
φ+, such that c⋆(u1, u2; φ+) = 1. In this case, the condition at equation (17.18) can be rewritten
as ct,s(u1, u2) = c⋆(u1, u2; φt,s), with φt,s = φ+ iff γt,s = 0. One example of such a copula is the
Gumbel when φ+ = 1, which is easily seen by substituting the value into the copula density, as
given in Table 17.1.
To estimate the joint posterior f(φ, |y), latent variables ˜φt,s, for t = 2, . . . , m, s < t, are intro-
duced such that φt,s = ˜φt,s if γt,s = 1. As with the partial correlations in the previous section,
φt,s is known exactly given the pair ( ˜φt,s, γt,s). Therefore, it is sufficient to implement a sam-
plingschemetoevaluatethejointposterior f( ˜φ, γ , |y),where ˜φ = { ˜φt,s; t = 2, . . . , m, s < t},as
below.
14 Note that this parameter is often a scalar, such as for an Archimedean or bivariate Gaussian copula.
However, it can also be a vector, as in the case of a bivariate t copula, where both the degrees of freedom and
correlation are parameters.

Bayesian approaches to copula modelling
351
Sampling scheme. Bayesian selection for a D-vine copula
Step 1: Generate from f(θj|{\θj}, φ, y) for j = 1, . . . , m.
Step 2: Generate from f( ˜φt,s, γt,s|, { ˜φ\ ˜φt,s}, {γ \γt,s}, y) for t = 2, . . . , m, s < t.
Step 3: Compute φ from ( ˜φ, γ ).
Generating the marginal parameters θj in Step 1 is undertaken using the same MH step outlined in
Section 17.3.1, but where the conditional posterior is now
f(θj|{\θj}, φ, y) ∝
 n

i=1
f(yi|, φ)

π(θj)
∝
 n

i=1
c(ui; φ)fj(yij; θj)

π(θj).
In the above, c(ui; φ) is the D-vine copula density at equation (17.7), evaluated at observation
ui = (F1(yi1; θ1), . . . , Fm(yim; θm)).15 The algorithm in Section 17.2.6 is run separately for each
observation ui to evaluate the arguments of the component pair-copulas of c(ui; φ). Interestingly,
selection can speed up this algorithm substantially because ht,s(u1|u2; φt,s) = u1 if γt,s = 0.
Generating the pair ( ˜φt,s, γt,s) follows the same MH step outlined in Section 17.3.2 for the partial
correlations. The main difference is that whenever ˜φt,s is vector-valued, each element is generated
separately in the same manner. Also, for many bivariate copulas (particularly the Archimedean
ones) proper non-uniform priors for ˜φt,s are often preferred.
17.3.4 Equivalence of selection for Gaussian and D-vine copulas
It is worth highlighting here that the Bayesian selection approach for the D-vine nests that for the
Gaussian copula, when the correlation matrix is parameterized by the semi-partial correlations #.
If the pair-copula c⋆is the bivariate Gaussian copula with density at equation (17.15), then φt,s =
λt,s and φ = #. In this case, the sampling schemes for Bayesian selection for D-vine and Gaussian
copulas are identical.
17.3.5 Posterior inference
Estimation is based on the Monte Carlo iterates

(φ[1], [1]), . . . , (φ[J], [J])

,
obtained from the sampling schemes after convergence to the joint posterior distribution, so that
(φ[j], [j]) ∼f(φ, |y).WhenBayesianselectionisundertaken,asinSections17.3.2and17.3.3,iter-
ates {γ [1], . . . , γ [J]} are also obtained, with γ [j] ∼f(γ |y). Monte Carlo estimates of the posterior
means can be used as point estimates. For example, the posterior means
E(θk|y) ≈1
J
J

j=1
θ[j]
k , and E(φ|y) ≈1
J
J

j=1
φ[j] ,
15 In the copula literature the n observations {u1, . . . , un} are often called the ‘copula data’.

352
M. S. Smith
are used as point estimates of the marginal model and copula parameters, respectively. Marginal
100(1 −α)% posterior probability intervals can be constructed for any scalar parameter by simply
ranking the iterates, and then counting off the αJ/2 lowest values, and the same number of the
highest values.
When undertaking Bayesian selection for a Gaussian copula, the estimates
pr(γt,s = 1|y) ≈1
J
J

j=1
γ [j]
t,s , and E(λt,s|y) ≈1
J
J

j=1
λ[j]
t,s ,
can be computed. The former gives the posterior probability that the pair Yt, Ys are dependent,
conditional on (Ys+1, . . . , Yt−1), for s < t. The latter is the posterior mean of the semi-partial
correlation. At each sweep of the sampling scheme, some elements of #[j] will be exactly equal
to zero, as determined by γ [j]. The estimate E(|y) ≈1
J
J
j=1 [j] is therefore often called a
‘model average’ because it is computed by averaging over these configurations of zero and non-zero
semi-partial correlations in #[j].
Similar estimates can be computed when undertaking Bayesian selection for D-vine copulas.
When the form of the component pair-copulas nests the independence copula, so that copula
density c⋆(u1, u2; φ+) = 1, then it is possible to compute the posterior mean of the pair-copula
parameters as E(φt,s|y) ≈1
J
J
j=1 φ[j]
t,s , because φ[j]
t,s = φ+ when γ [j]
t,s = 0. However, when the
pair-copulas do not nest the independence copula, φt,s is undefined when γt,s = 0.
If the measures of pairwise dependence discussed in Section 17.2.7 have a closed form expres-
sion (or an accurate numerical approximation), then Monte Carlo estimates are straightforward to
compute. For example, the estimate of Kendall’s tau for continuous valued data is
E(τi,k|y) =

τi,k(φ)f(φ|y)dφ ≈1
J
J

j=1
τi,k(φ[j]).
Posterior probability intervals are constructed using the iterates {τi,k(φ[1]), . . . , τi,k(φ[J])} in the
same manner as for the model parameters. If the pairwise dependence measures are difficult to
compute, then Kendall’s tau and Spearman’s rho can be obtained by evaluating the expectations at
equation (17.8) via simulation as follows. At the end of each sweep of a sampling scheme, generate
an iterate from the copula distribution U[j] ∼C(u; φ[j]), and then compute
E(CB
i,k(Ui, Uk)) ≈1
J
J

j=1
CB
i,k(U[j]
i , U[j]
k ) , and E(UiUk) ≈1
J
J

j=1
U[j]
i U[j]
k .
Simulating from most copula distributions is straightforward and fast; see [12; Chap. 6].
17.4 Bayesian inference for discrete margins
Estimation of copula models with one or more discrete marginal distributions differs substantially
from those with continuous margins; see [27] for an extensive discussion on the differences. In this

Bayesian approaches to copula modelling
353
section, the case where all margins are discrete is considered, although extension to the case where
some margins are discrete and others continuous is discussed in [64].
The likelihood of n independent observations y = {y1, . . . , yn}, each distributed as equa-
tion (17.1) and with probability mass function at equation (17.5), is
L(, φ) =
n

i=1
bim
aimbim−1
aim−1 · · · bi1
ai1C(v; φ).
(17.19)
Here, v = (v1, . . . , vm) are indices of differencing, each observation yi = (yi1, . . . , yim), the upper
bound bij = Fj(yij; θj), and the lower bound aij = Fj(y−
ij ; θj) is the left-hand limit of Fj at yij. In
general, computing the likelihood involves O(n2m) evaluations of C, which is prohibitive for high
m. Moreover, even for low values of m, it can be difficult to maximize the likelihood for some copula
and/or marginal model choices.
An alternative is to augment the likelihood with latent variables, and integrate them out in a
MonteCarlofashion.FromaBayesianperspectivethisinvolvesevaluatingtheaugmentedposterior
distribution by MCMC methods; an approach that is called Bayesian data augmentation [71]. It is
shownin[64]howthiscanbeundertakenbyaugmentingtheposteriordistributionwithlatentvari-
ables distributed as U = (U1, . . . , Um) ∼C(u; φ). While their approach applies to all parametric
copula functions, in the specific case of a copula constructed by inversion as at equation (17.2),
latent variables distributed as X ∼G(x; φ), can also be used. This is proposed in [54] to estimate
Gaussian copula models, and in [66] when G is the distribution function of the skew t of [56].
17.4.1 The Gaussian copula model
For the Gaussian copula, latent variables x = {x1, . . . , xn} are introduced, where xi = (xi1, . . . ,
xim) ∼N(0, ). The augmented likelihood is L(, , x) = 	n
i=1 f(yi, xi|, ), with mixed joint
density
f(yi, xi|, ) = pr(Y = yi|xi, )fN(xi; 0, )
∝
⎛
⎝
m

j=1
I(Aij ≤xij < Bij)
⎞
⎠fN(xi; 0, ).
Here, fN(x; μ, V) is the density of a N(μ, V) distribution evaluated at x, I(Z) is an indicator func-
tion equal to one if Z is true, and zero otherwise. The mass function
pr(Yj = yij|xij, θj) =

1 if Aij ≤xij < Bij
0
otherwise
,
where Aij = −1
1 (aij; 1) and Bij = −1
1 (bij; 1) as noted in Section 17.2.5, and 1(·; 1) is the dis-
tribution function of a standard normal.
The likelihood of the copula model in equation (17.19) is obtained by integrating over the latent
variables, with L(, ) =

L(, , x)dx. Let x(j) = {x1j, . . . , xnj} be the latent variables cor-
responding to the jth margin, then the following sampling scheme can be used to evaluate the
augmented posterior.

354
M. S. Smith
Sampling scheme. Data augmentation for a Gaussian copula
Step 1: For j = 1, . . . , m:
1(a) Generate from f(θj|{\θj}, {x\x(j)}, , y)
1(b) Generate from f(x(j)|, {x\x(j)}, , y)
Step 2: Generate from f(|, x).
Steps 1(a) and 1(b) together produce an iterate from the density f(θj, x(j)|{\θj}, {x\x(j)}, , y).
The conditional posterior at Step 1(b) can be derived as
f(x(j)|, {x\x(j)}, , y) ∝L(, , x)
∝
 n

i=1
I(Aij ≤xij < Bij)fN(xij; μij, σ2
ij )

where μij and σ 2
ij are the mean and variance of the conditional distribution of xij|{xi\xij} obtained
from the joint distribution xi ∼N(0, ). Thus, x(j) can be generated element-by-element from
independent constrained normal densities. In Step 1(a), θj is generated using the same MH
approach as in the continuous case, but where the conditional density is now
f(θj|{\θj}, {x\x(j)}, , y) ∝
 n

i=1
1
Bij −μij
σij
; 1

−1
Aij −μij
σij
; 1

π(θj)
In Step 2 any of the existing methods for generating a correlation matrix  from its posterior distri-
bution for Gaussian distributed data x can be used, as outlined in Section 17.3.1. Bayesian selection
ideas can also be used as discussed in Section 17.3.2.
The efficiency of this sampling scheme is demonstrated empirically in [54], and [18] show it
can be applied effectively to a problem with m = 45 dimensions. Alternative sampling schemes are
proposed in [64] that can be used with the Gaussian copula, or with other copula models.
17.4.2 Measuring dependence
Forcontinuousmultivariatedata,dependencebetweenelementsofY iscapturedfullybythecopula
function C. In this case, the measures of dependence based on C discussed in Section 17.2.7 are
adequate summaries. But when one or more margins are discrete-valued, in general, measures of
concordance involve the marginal distributions; see [21], and [48]. Nevertheless, the dependence
structure of the latent vector U (or the latent vector X for copulas constructed by inversion) is still
informative concerning the level and type of dependence in the data. Moreover, estimation using
nonparametricrank-basedestimatorsbecomesinaccurate[27]andlikelihood-basedinference,such
as that outlined here, preferable.
17.4.3 Link with multivariate probit and latent variable models
Last, it is not widely appreciated that the multivariate probit model is a special case of the Gaussian
copula model with univariate probit margins [68]. Data augmentation for a Gaussian copula there-
fore extends the approaches of [13], [22] and others for data augmentation for a multivariate probit
model, to other Gaussian copula models. Similarly, the approach generalizes a number of Gaussian
latent variable models for ordinal data, such as that of [14] and [39].

Bayesian approaches to copula modelling
355
17.5 Discussion
The impact of copula modelling in multivariate analysis has been substantial in many fields. Yet,
Bayesian inferential methods have been employed by only a few empirical analysts to date. Never-
theless, they show great potential for computing efficient likelihood-based inference in a number
of contexts. One of these is in the modelling of multivariate discrete data, or data with a combi-
nation of discrete and continuous margins. Here, method of moments style estimators cannot be
used effectively, and there can be computational difficulties in maximizing the likelihood, so that
Bayesian data augmentation becomes attractive; see [64] for a full discussion. Another is in the use
of hierarchical models, including varying parameter models [4] or hierarchical models for Bayesian
selectionandmodelaveraging,asdiscussedhere.Last,whilethisarticlehasfocusedontheGaussian
and D-vine copulas, the Bayesian methods and ideas discussed here are applicable to a wide range
of other copula models, and it seems likely that their usage will increase in the near future.
Acknowledgements
I would like to thank Robert Kohn, Claudia Czado, Anastasios Panagiotelis and particularly
Mohamad Khaled, for their insightful comments on copula models and associated methods of
inference. This research was funded by the Australian Research Council grants FT110100729 and
DP1094289.
References
[1] Aas, K., Czado, C., Frigessi, A. and Bakken, H. (2009). Pair-copula constructions of multiple
dependence. Insurance: Mathematics and Economics, 44, 182–198.
[2] Abramowitz, M. and Stegun, I. A. (Eds.) (1965). Handbook of Mathematical Functions, New
York: Dover Publications.
[3] Armstrong,H.,Carter,C.K.,Wong,K.F.K.andKohn,R.(2009).Bayesiancovariancematrix
estimation using a mixture of decomposable graphical models. Statistics and Computing, 19,
303–316.
[4] Ausin, M. C. and Lopes, H. F. (2010). Time-varying joint distribution through copulas. Com-
putational Statistics and Data Analysis, 54, 2383–2399.
[5] Barnard, J., McCulloch, R. and Meng, X. (2000). Modeling covariance matrices in terms
of standard deviations and correlations, with application to shrinkage. Statistica Sinica, 10,
1281–1311.
[6] Bedford, T. and Cooke, R. (2002). Vines–a new graphical model for dependent random
variables. Annals of Statistics, 30, 1031–1068.
[7] Bhat, C. R. and Eluru, N. (2009). A Copula-Based Approach to Accomodation Residen-
tial Self-Selection Effects in Travel Behavior Modeling. Transportation Research Part B, 43,
749–765.
[8] Bottolo, L. and Richardson, S. (2010). Evolutionary Stochastic Search for Bayesian model
exploration. Bayesian Analysis, 5, 583–618.
[9] Cameron, A., Tong, L., Trivedi, P. and Zimmer, D. (2004). Modelling the differences in
counted outcomes using bivariate copula models with application to mismeasured counts.
Econometrics Journal, 7, 566–584.
[10] Chen,X.andFan,Y.(2006).Estimationandmodelselectionofsemiparametriccopula-based
multivariate dynamic models under copula misspecification. Journal of Econometrics, 135,
125–154.

356
M. S. Smith
[11] Chen, X., Fan, Y. and Tsyrennikov, V. (2006). Efficient Estimation of Semiparametric Multi-
variate Copula Models. Journal of the American Statistical Association, 101, 1228–1240.
[12] Cherubini, U., Luciano, E. and Vecchiato, W. (2004). Copula Methods in Finance, Wiley.
[13] Chib, S. and Greenberg, E. (1998). Analysis of multivariate probit models. Biometrika, 85,
347–361.
[14] Chib, S. and Winkelmann, R. (2001). Markov chain Monte Carlo Analysis of Correlated
Count Data. Journal of Business and Economic Statistics, 19, 428–435.
[15] Clayton, D. (1978). A model for association in bivariate life tables and its application to
epidemiological studies of family tendency in chronic disease incidence. Biometrika, 65,
141–151.
[16] Cripps, E., Carter, C. and Kohn, R. (2005). Variable selection and covariance selection in
multivariate regression models, in Handbook of Statistics 25: Bayesian Thinking: Modeling and
Computation, D. Dey and C. Rao, (Eds.), Amsterdam: North-Holland, pp. 519–552.
[17] Czado, C. (2010). Pair-copula constructions of multivariate copulas. In Workshop on Copula
Theory and Its Applications. Eds. F. Durante, W. Härdle, P. Jaworki and T. Rychlik, Dordrecht:
Springer.
[18] Danaher, P. and Smith, M. (2011). Modeling multivariate distributions using copulas: appli-
cations in marketing, (with discussion). Marketing Science, 30, 4–21.
[19] Daniels, M. and Pourahmadi, M. (2009). Modeling covariance matrices via partial autocorre-
lations. Journal of Multivariate Analysis, 100, 2352–2363.
[20] Demarta,S.andMcNeil,A.J.(2005).Thet-copulaandrelatedcopulas.InternationalStatistical
Review, 73, 111–129.
[21] Denuit, M. and Lambert, P. (2005). Constraints on concordance measures in bivariate dis-
crete data. Journal of Multivariate Analysis, 93, 40–57.
[22] Edwards, Y. D. and Allenby, G. M. (2003). Multivariate analysis of multiple response data.
Journal of Marketing Research, 40, 321–334.
[23] Fang, H. B., Fang, K. T. and Kotz, S. (2002). The meta-elliptical distributions with given
marginals. Journal of Multivariate Analysis, 82, 1–16.
[24] Frees,E.W.andValdez,E.A.(1998).Understandingrelationships usingcopulas. North Amer-
ican Actuarial Journal, 2, 1–25.
[25] Frühwirth-Schnatter,S.andTüchler,R.(2008).Bayesianparsimonouscovarianceestimation
for hierarchical linear mixed models. Statistics and Computing, 18, 1–13.
[26] Genest, C., Ghoudi, K. and Rivest, L.-P. (1995). A semiparametric estimation procedure of
dependence parameters in multivariate families of distributions. Biometrika, 82, 543–552.
[27] Genest, C. and Nešlehová, J. (2007). A primer on copulas for count data. The Astin Bulletin,
37, 475–515.
[28] Genest,C.andRivest,L.-P.(1993).StatisticalinferenceproceduresforbivariateArchimedean
copulas. Journal of the American Statistical Association, 88, 1034–1043.
[29] Giudici, P. and Green, P. (1999). Decomposable graphical Gaussian model determination.
Biometrika, 86, 785–801.
[30] Haff, I., Aas, K. and Frigessi, A. (2010). On the simplified pair-copula construction- Simply
useful or too simplistic? Journal of Multivariate Analysis, 101, 1296–1310.
[31] Hjort, N. L., Holmes, C., Müller, P. and Walker, S. (2010). Bayesian Nonparametrics, CUP.
[32] Hoff, P. (2007). Extending the rank likelihood for semiparametric copula estimation. The
Annals of Applied Statistics, 1, 265–283.
[33] Huard, D., Évin, G. and Favre, A.-C. (2006). Bayesian copula selection. Computational Statis-
tics and Data Analysis, 51, 809–822.
[34] Joe, H. (1996). Families of m-variate distributions with given margins and m(m-1)/2 bivariate
dependence parameters. In Rüschendorf, L., Schweizer, B., Taylor, M.D. (Eds.) Distributions
with Fixed Marginals and Related Topics.
[35] Joe, H. (1997). Multivariate Models and Dependence Concepts, Chapman and Hall.

Bayesian approaches to copula modelling
357
[36] Joe, H. (2005). Asymptotic efficiency of the two-stage estimation method for copula-based
models. Journal of Multivariate Analysis, 94, 401–419.
[37] Joe, H. (2006). Generating random correlation matrices based on partial correlations. Journal
of Multivariate Analysis, 97, 2177–2189.
[38] Kohn, R., Smith, M. and Chan, D. (2001). Nonparametric regression using linear combina-
tions of basis functions. Statistics and Computing, 11, 313–322.
[39] Kottas, A., Müller, P. and Quintana, F. (2005). Nonparametric Bayesian modeling for multi-
variate ordinal data. Journal of Computational and Graphical Statistics, 14, 610–625.
[40] Lambert, P. and Vandenhende, F. (2002). A copula-based model for multivariate non-normal
longitudinal data: analysis of a dose titration safety study on a new antidepressant. Statistics
in Medicine, 21, 3197–3217.
[41] Lee, A. (1999). Modelling rugby league data via bivariate negative binomial regression. Aus-
tralian and New Zealand Journal of Statistics, 41, 141–152.
[42] Li, D. X. (2000). On default correlation: a copula function approach. The Journal of Fixed
Income, 9, 43–54.
[43] Liechty, J. C., Liechty, M. W. and Müller, P. (2004). Bayesian correlation estimation.
Biometrika, 91, 1–14.
[44] McNeil, A. J., Frey, R. and Embrechts, R. (2005). Quantitative Risk Management: Concepts,
Techniques and Tools, Princeton University Press, Princton: NJ.
[45] Min, A. and Czado, C. (2010). Bayesian inference for multivariate copulas using pair-copula
constructions. Journal of Financial Econometrics, 8, 511–546.
[46] Min, A. and Czado, C. (2011). Bayesian model selection for D-vine pair-copula constructions.
Canadian Journal of Statistics, 39, 239–258.
[47] Nelsen, R. B. (2006). An Introduction to Copulas, (2nd Ed.), New York: Springer.
[48] Nešlehová, J. (2007). On rank correlation measures for non-continuous random variables.
Journal of Multivariate Analysis, 98, 544–567.
[49] Nikoloulopoulos, A. and Karlis, D. (2008). Multivariate logit copula model with an applica-
tion to dental data. Statistics in Medicine, 27, 6393–6406.
[50] Nikoloulopoulos, A. and Karlis, D. (2010). Modeling multivariate count data using copulas.
Communications in Statistics- Simulation and Computation, 39, 172–187.
[51] Oakes, D. (1989). Bivariate survival models induced by frailties. Journal of the American Statis-
tical Association, 84, 487–493.
[52] Oakes, D. and Ritz, J. (2000). Regression in bivariate copula model. Biometrika, 87, 345–352.
[53] Patton, A. (2006). Modelling asymmetric exchange rate dependence. International Economic
Review, 47, 527–556.
[54] Pitt, M., Chan, D. and Kohn, R. (2006). Efficient Bayesian inference for Gaussian copula
regression models. Biometrika, 93, 537–554.
[55] Robert, C. P. and Casella, G. (2004). Monte Carlo Statistical Methods, (2nd Ed.), New York:
Springer
[56] Sahu,S.K.,Dey,D.K.andBranco,M.D.(2003).Anewclassofmultivariateskewdistributions
withapplicationstoBayesianregressionmodels.TheCanadianJournalofStatistics,31,129–150.
[57] Scott, J. G. and Berger, J. O. (2010). Bayes and empirical-Bayes multiplicity adjustment in the
variable-selection problem. The Annals of Statistics, 38, 2587–2619.
[58] Shih, J. H. and Louis, T. A. (1995). Inferences on the association parameter in copula models
for bivariate survival data. Biometrics, 51, 1384–1399.
[59] Silva, R. and Lopes, H. (2008). Copula, marginal distributions and model selection: a
Bayesian note. Statistics and Computing, 18, 313–320.
[60] Sklar, A. (1959). Fonctions de répartition à n dimensions et leurs marges. Publications de
l’Institut de Statistique de L’Université de Paris, 8, 229–231.

358
M. S. Smith
[61] Smith, M. D. (2003). Modelling sample selection using Archimedean copulas. Econometrics
Journal, 6, 99–123.
[62] Smith, M. (2000). Modeling and short-term forecasting of New South Wales electricity sys-
tem load. Journal of Business and Economic Statistics, 18, 465–478.
[63] Smith, M. S. and Kauermann, G. (2011). Bicycle commuting in Melbourne during the 2000s
energy crisis: A semiparametric analysis of intraday volumes. Transportation Research Part B,
45, 1846–1862.
[64] Smith, M. S. and Khaled, M. A. (2012). Estimation of copula models with discrete margins
via Bayesian data augmentation. Journal of the American Statistical Association, 107, 290–303.
[65] Smith, M. and Kohn, R. (2002). Parsimonious covariance matrix estimation for longitudinal
data, Journal of the American Statistical Association, 97, 1141–1153.
[66] Smith, M. S., Gan, Q. and Kohn, R. J. (2012). Modelling dependence using skew t copulas:
Bayesian inference and applications. Journal of Applied Econometrics, 27, 500–522.
[67] Smith, M., Min, A., Almeida, C. and Czado, C. (2010). Modeling longitudinal data using a
pair-copuladecompositionofserialdependence.JournaloftheAmericanStatisticalAssociation,
105, 1467–1479.
[68] Song, P. (2000). Multivariate dispersion models generated from Gaussian copula. Scandina-
vian Journal of Statistics, 27, 305–320.
[69] Song, P., Fan, Y. and Kalbfleisch, J. D. (2005). Maximization by Parts in Likelihood Inference.
Journal of the American Statistical Association, 100, 1145–1158.
[70] Tanner, M. A. (1996). Tools for Statistical Inference: Methods for the Exploration of Posterior
Distributions and Likelihood Functions, 3rd Ed., New York: Springer.
[71] Tanner, M. A. and Wong, W. H. (1987). The calculation of posterior distributions by data
augmentation. Journal of the American Statistical Association, 82, 528–540.
[72] Wong, F., Carter, C. K. and Kohn, R. (2003). Efficient estimation of covariance selection
models. Biometrika, 90, 809–830.
[73] Yang, R. and Berger, J. O. (1994). Estimation of a covariance matrix using the reference prior.
Annals of Statistics, 22, 1195–1211.
[74] Zellner,A.(1962).Anefficientmethodofestimatingseeminglyunrelatedregressionsandtests
for aggregation bias. Journal of the American Statistical Association, 57, 348–368.
[75] Zhang, Z., Dai, G. and Jordan, M. (2011). Bayesian generalized kernel mixed models. Journal
of Machine Learning Research, 12, 111–139.

Part VIII
Model Elaboration and Prior Distributions

This page intentionally left blank 

18
Hypothesis testing and
model uncertainty
m. j. bayarri and j. o. berger
18.1 Introduction
T
his chapter gives a brief and mostly elementary review of Bayesian hypothesis testing and
model uncertainty. In Section 18.2, the key concepts of Bayesian hypothesis testing are intro-
duced. The Bayesian approach is compared with classical methods, such as use of p-values, in
Section 18.3.
Section 18.4 introduces the basics of dealing with model uncertainty. The key difficulty is that of
choosing prior distributions, especially when there are many models involved. General approaches
to the development of suitable prior distributions for model uncertainty are discussed in Sec-
tion 18.5. Other issues arising in model uncertainty are considered in Section 18.6, in particular,
computation and search, approximation and asymptotics, multiplicity, and model criticism.
MuchofthedevelopmentinthisareabeganwiththeworkofAdrianSmith,especiallytheseminal
papers (discussed later)[125],[126],and [57].Overall,this is ahugemethodological area,and many
important techniques and approaches will be mentioned herein only briefly, if at all. Other useful
reviews, with many more references, include [74], [14], [35], [90], [54], and [7].
18.2 Basics of Bayesian hypothesis testing
We introduce the basic elements of Bayesian hypothesis testing through a pedagogical example.
18.2.1 A pedagogical illustration
In hypothesis testing, one has to select among two possible models or explanations of data X; these
are usually denoted by H0 (the null hypothesis) and H1 (the alternative hypothesis). We defer
discussion of the important issue of correct formulation of hypotheses until Section 18.2.3, first
presenting the key methodological ingredients of hypothesis testing.
One of the major scientific goals of the Large Hadron Collider (LHC) at CERN is to determine
if the Higgs boson particle actually exists. A simplified version of the problem, that nevertheless
containsmanyofitskeyfeatures,presumesthatthedataX consistsofthenumberofeventsobserved
intimeT thatarecharacteristicofHiggsbosonproductioninLHCparticlecollisions.Thestatistical
model assumes that the density of X is the Poisson density

362
M. J. Bayarri and J. O. Berger
Poisson(x | θ + b) = (θ + b)xe−(θ+b)
x!
where θ is the mean rate of production of Higgs events in time T, and b is the (known) mean rate of
production of events with the same characteristics from background sources in time T. One then
wishes to test
H0 : θ = 0
versus
H1 : θ > 0.
(H0 corresponds to ‘no Higgs.’)
As we present the Bayesian approach, it will be useful to simultaneously present the classical
approach of using p-values for testing. For observed x, the p-value is given by
p = Pr(X ≥x | b, θ = 0) =
∞

m=x
Poisson(m | 0 + b) .
We will use two cases for illustration:
Case 1: x = 7, b = 1.2, which results in p = 0.00025;
Case 2: x = 6, b = 2.2, which results in p = 0.025.
18.2.2 Priors, Bayes factors and posteriors
18.2.2.1 Prior distribution
For Bayesian hypothesis testing, one needs to assess the prior probability of each hypothesis and,
conditional on the truth of each of the hypotheses, the prior distribution of the unknown parame-
ters in the statistical model corresponding to that hypothesis. In the pedagogical example, Pr(Hi)
will denote the prior probability that Hi is true, i = 0, 1; also, on H1 : θ > 0, π(θ) will denote the
prior density for θ. (Note that H0 does not involve any unknown parameters.) The choice of the
prior distribution can be either subjective or objective:
Subjective Bayesian analysis chooses the Pr(Hi) and π(θ) based on personal beliefs and/or
previous information about the problem (e.g. π(θ) could result from using the standard physics
model predictions of the mass of the Higgs).
Objective Bayesian analysis does not introduce any external or additional information into the
problem(otherthanthedataandthemodel).Forinstance,anaturalobjectivechoiceoftheprior
probabilities of the hypotheses is Pr(H0) = Pr(H1) = 1/2. Making an objective choice for
π(θ) is considerably more problematical, as will be discussed later. For illustration here we uti-
lizethe‘expectedposteriorprior’(discussedinSection18.5.4.3),givenbyπE(θ) = b(θ + b)−2.
Note that this prior is proper—essential as will be seen in Section 18.2.4—and has median b.
18.2.2.2 Bayes factors
An ‘objective’ alternative to choosing Pr(H0) = Pr(H1) = 1/2 is to report the Bayes factor. Infor-
mally, the Bayes factor of H0 to H1 is the ratio of the average likelihood under H0 to the average
likelihood under H1, where the averages are with respect to the prior distributions of the parameters.
(A more formal definition is deferred until Section 18.4.1.) In the pedagogical example,

Hypothesis testing and model uncertainty
363
B01 =
Poisson(x | 0 + b)

 ∞
0
Poisson(x | θ + b)π(θ) dθ =
bx e−b

 ∞
0 (θ + b)x e−(θ+b)π(θ) dθ
For the prior πE(θ) = b(θ + b)−2, the Bayes factor is given by
B01 =
bx e−b

 ∞
0 (θ + b)x e−(θ+b)b(θ + b)−2 dθ = b(x−1) e−b
(x −1, b)
where  is the incomplete gamma function. In particular, in Case 1, B01 = 0.0075 (recall
p = 0.00025), and, in Case 2, B01 = 0.26 (recall p = 0.025).
The common intuitive interpretation of the Bayes factor is simply as ‘odds of H0 to H1’. Thus,
in Case 2 above, B01 = 0.26 would be interpreted as saying that the data provide 1 to 4 odds in
favour of the alternative hypothesis. It is interesting that the p-value here was p = 0.025, which
many view as strong evidence against H0, while 1 to 4 odds would hardly be viewed as strong
evidence.
18.2.2.3 Posterior distribution and Bayesian reporting
The posterior probability of H0, given the data, is given by
Pr(H0 | x) =
Pr(H0)B01
Pr(H1) + Pr(H0)B01
.
(Ofcourse,Pr(H1 | x) = 1 −Pr(H0 | x).)FortheobjectivechoicePr(H0) = Pr(H1) = 0.5,this
becomes
Pr(H0 | x) =
B01
1 + B01
For the pedagogical example, in Case 1, Pr(H0 | x) = 0.0075 (recall p = 0.00025), and, in Case 2,
Pr(H0 | x) = 0.21 (recall p = 0.025).
The complete posterior distribution in this example can be summarized by
1. Pr(H0 | x), the posterior probability of the null hypothesis, and
2. π(θ | x, H1), the posterior distribution of θ under H1.
Both of these components are displayed in Figure 18.1 for the situation of Case 1; this type of figure
is a very useful graphical presentation of the posterior. A useful numerical summary of the complete
posterioris Pr(H0 | x)andC,a(say)95%posteriorcrediblesetfor θ underH1.Forthepedagogical
example, these summaries are
Case 1: Pr(H0 | x) = 0.0075; C = (1.0, 10.5),
Case 2: Pr(H0 | x) = 0.21; C = (0.2, 8.2).
It is important to note that, for testing hypotheses as here, confidence intervals alone are not a
satisfactory inferential summary. Thus, in Case 2 above, if one ignored the testing aspect of the
problem and simply found a 95% credible set for θ, the result would be C = (0.2, 8.2), which does
not contain 0. In classical statistics, it is viewed as correct to say that, if a confidence interval does
not contain the null parameter value, then one has ‘significant’ evidence against the null hypothesis.
In Bayesian testing this is not so; here the credible interval if we had ignored the testing aspect

364
M. J. Bayarri and J. O. Berger
0.0075
0
2
4
6
8
10
12
0.00
0.05
0.10
0.15
Figure 18.1 Pr(H0 | x) (the vertical bar) and the posterior density for θ given x and H1 for Case 1 of
the pedagogical example.
of the problem does not contain zero, yet the null hypothesis still has a reasonable probability of
being true.
Finally, note that we can write
Pr(H0|x)
Pr(H1|x)
=
Pr(H0)
Pr(H1)
×
B01
(posterior odds)
(prior odds)
(Bayes factor)
Because prior probabilities of hypotheses often differ amongst individuals, it is common to primar-
ily report Bayes factors, allowing any individual to convert to his/her own posterior probabilities.
Note that we are not saying that Bayes factors are the correct final answer, but that they are an
important component of the final answer and are very useful quantities for communication.
18.2.3 Formulating hypotheses when using Bayesian testing
18.2.3.1 Precise versus non-precise hypotheses
An important issue to consider is that of proper formulation of a hypothesis testing problem. The
scientificliteratureisfullofproblemsformulatedashypothesistestingproblemswhichwouldbetter
be addressed as estimation problems, and vice versa (although the latter is less frequent). A crucial
issue is that the hypotheses must all be ‘plausible,’ i.e. they must have reasonable prior probability
of being true. For instance, in our pedagogical illustration, the hypothesis H0 : there is no Higgs
boson particle, is a plausible hypothesis, as is the alternative hypothesis.
To better understand this crucial issue, consider the example of comparing the effects of two
treatments A and B. Letting θ denote the difference between the mean treatment effects, one often
sees tests of H0 : θ = 0 versus H1 : θ ̸= 0. The key question is then whether H0 is a plausible
hypothesis. Consider, for instance, the following two possible scenarios involving treatment for
cancer:

Hypothesis testing and model uncertainty
365
Scenario 1:
Treatment A = standard chemotherapy
Treatment B = standard chemotherapy + steroids
Scenario 2:
Treatment A = standard chemotherapy
Treatment B = a new radiation therapy
In Scenario 1, H0 : θ = 0 is plausible, in that the effect of steroids could well be essentially negligi-
ble. In Scenario 2, however, H0 : θ = 0 is not plausible; there is no plausible reason why the new
radiation therapy would have essentially the same effect as the standard chemotherapy (assuming
we can rule out both being completely ineffective or completely effective) and it would thus be
much more appropriate to test H0 : θ < 0 versus H1 : θ > 0.
A final observation on this issue is that this is not an issue of one-sided versus
two-sided testing. Indeed, in Scenario 1, it is quite possible to test H0 : θ = 0 versus
H1 : θ < 0 versus
H2 : θ > 0, which involves one-sided testing. The important point is
rather whether θ = 0 is a point that has non-negligible probability of being true; if so, H0 : θ = 0
must enter the formulation of the problem to properly capture the scientific situation; we call such
hypotheses ‘precise’ hypotheses. Note that, if the scientific situation calls for a precise hypothesis
having prior mass, it is an egregious mistake not to include such; it is not simply a modelling
‘choice.’
18.2.3.2 Approximating a believable null hypothesis by a precise null
A precise null hypothesis, such as H0 : θ = θ0, is typically never true exactly; rather, it is used as a
surrogate for an approximate precise hypothesis
Hϵ
0 : |θ −θ0| < ϵ, ϵ small
For instance, in the pedagogical example, while the Higgs boson may well not exist, the LHC
experiment almost certainly has some very small bias ϵ, so that the real hypothesis being tested
is Hϵ
0 : θ < ϵ.
Luckily, it is typically the case that one obtains essentially the same answer whether using H0 or
Hϵ
0. Indeed, in [10], it was shown that Pr(Hϵ
0|x) ≈Pr(H0|x) if
ϵ < 1
4 σ ˆθ
(18.1)
where σ ˆθ is the standard error of the estimate of θ. Thus one simply needs to assess that ϵ satisfies
this inequality to utilize the precise null. Note that, typically, σ ˆθ ≈c/√n, where n is the sample
size so, for very large n, the above condition can be violated and using a precise null may not be
appropriate, even if the real null (e.g. ‘no Higgs’) is believable.
18.2.4 Priors and paradoxes
Whenprecisehypothesesareinvolvedinthetest,oneneedstobequitecarefulinthechoiceofprior
distributions. For instance, one cannot generally employ usual objective Bayes estimation priors.
To see this, suppose X ∼N(x | θ, 1), with density written f(x | θ). In estimation of the mean θ,
it is perfectly reasonable to use the improper objective estimation prior π(θ) = c, where c is any
constant,inthattheposteriordensityofθ isπ(θ | x) = f(x | θ)c/

f(x | θ)cdθ = f(x | θ)(since

f(x | θ)dθ = 1), which does not depend on the choice of the constant c.

366
M. J. Bayarri and J. O. Berger
ConsidernowtestingofH0 : θ = 0versusH1 : θ ̸= 0.TheBayesfactor,ifπ(θ) = cwereused,
would be
B01(c) =
f(x | 0)

 ∞
−∞f(x | θ)(c)dθ = f(x | 0)
c
and, hence, depends on the arbitrary choice of c. For this reason, one often hears it stated that
improper priors cannot be used for hypothesis testing when there are precise hypotheses.
Even worse than use of improper priors here is use of vague proper priors, such as a
Uniform(−K, K) prior for θ, with K chosen very large; many Bayesians erroneously view the use
of such vague proper priors to be better than the use of improper priors. But, for this prior in the
normal example, the Bayes factor becomes
B01(K) =
f(x | 0)

 K
−K f(x | θ)(2K)−1dθ
≈
2K f(x | 0)

 ∞
−∞f(x | θ)dθ = 2K f(x | 0)
which depends dramatically and inappropriately on the arbitrary choice of K. Indeed, the situ-
ation in practice is typically much worse with vague proper priors than with improper priors;
the usual choice of c would be 1, which causes no dramatic problems, while K is usually chosen
huge—e.g. K = 1000—leading to a nonsensical answer. This problem with vague proper priors is
often referred to as Bartlett’s Paradox (from [3]).
A closely related paradox is the Jeffreys–Lindley Paradox, from [79] and [91]. This is not really
a paradox in the usual sense of the word, but simply describes a stark example of the contrasting
behaviour of, say, Bayes factors and p-values. For instance, consider the normal example above
but now with an i.i.d. sample of data X1, . . . , Xn. Reducing first to the sufficient statistic ¯X =
n
i=1 Xi/n ∼N(¯x | θ, n−1), and considering a fixed proper prior for θ, such as the N(θ | 0, 1)
prior, one obtains the Bayes factor
B01(n) =
N(¯x | 0, n−1)

N(¯x | θ, n−1)N(θ | 0, 1)dθ =
N(¯x | 0, n−1)
N(¯x | 0, n−1 + 1) =
√
n + 1 e−
n
2(n+1) z2
wherez = √n¯xisthestandardizedteststatistic.The‘paradox’isthat zcanbemadearbitrarilylarge
which makes the p-value arbitrarily small yet, for fixed z and large enough n, B01 will be very large.
Then classical testing would state that there is very significant evidence against H0, while Bayesian
testing would state that H0 has very strong odds of being true.
Again,thisisnotaparadox;iftheBayesianinputsarecorrect,theBayesiananswerisindisputably
correct—it is just probability theory. Note, however, that the Bayesian formulation of an exact
precise hypothesis test might well be wrong in practical contexts. If n is very large, (18.1) might well
be violated, so that testing H0 : θ = 0 would be inappropriate and a Bayesian would need to do the
more difficult analysis with Hϵ
0.
We delay discussion of actual choice of priors until the model uncertainty sections, given that
the same issues arise there. Note, however, that there is one completely general objective Bayesian
procedure for testing two hypotheses with i.i.d. data; see Section 18.5.4.1.
18.2.5 Other testing scenarios
We have focused primarily on precise hypothesis testing in this section, although there are many
other kinds of testing. For instance, in normal testing of H0 : θ < 0 versus H1 : θ > 0, with no
precise hypothesis, one can legitimately use the ordinary estimation improper prior π(θ) = 1 and,

Hypothesis testing and model uncertainty
367
indeed, will find that the posterior probability of H0 equals the p-value (see, e.g. [28]). There are
many interesting generalizations of this idea (see [75]).
We do not focus on such problems, partly because of space constraints and partly because they
can often just be approached as estimation problems, using standard objective estimation priors,
obtaining the posterior distribution of the parameters, and computing the posterior probability of
the regions corresponding to the non-precise hypotheses.
18.3 Understanding differences with classical testing
18.3.1 Discrepancy between p-values and Bayesian answers
In the pedagogical example for Case 1, the p-value was 0.00025 but the Bayes factor for the null
was 0.0075, a quantity 30 times larger. Still, both would imply strong evidence against the null
hypothesis while, in Case 2, the p-value was 0.025 and the Bayes factor was 0.26, a dramatic practical
conflict; common understanding is that a p-value of 0.025 indicates strong evidence against the null
hypothesis, but the Bayes factor suggests it is less than 1 to 4 odds against the null.
The discrepancy arises from two sources: the ‘Ockham’s razor’ effect of the prior (see Sec-
tion 18.4.6) and the fact that the p-value is a tail area of the sampling distribution, and not the
likelihood of the data. As an aid to understanding this latter point, it is useful to first compute the
lower bound on the Bayes factor over all possible prior distributions. Indeed,
B01 =
Poisson(x | 0 + b)

 ∞
0
Poisson(x | θ + b)π(θ) dθ ≥Poisson(x | 0 + b)
Poisson(x | ˆθ + b)
= min{1,
b
x
x
ex−b}
the lower bound arising by choosing π(θ) to be a point mass at ˆθ, an egregious favouring of the
alternative hypothesis. In Case 1, this gives B01 ≥0.0014 (recall p = 0.00025) and, in Case 2,
B01 ≥0.11 (recall p = 0.025). That the discrepancy holds for every prior, even that which is most
favourable to the alternative hypothesis, highlights the serious error of replacing the likelihood of
the actual data with the tail area of the data distribution.
The Ockham’s razor effect of the prior is basically that the prior mass is spread over the a
priori specified values of θ for the alternative, and many values of θ for the alternative are no
more supportive of the data than the null value of θ. This is also the reason that Bayesian anal-
ysis seeks parsimony—a simpler model that explains the data is preferred to a complex one that
does so.
Thus, in Case 1 of the pedagogical example, the difference, by a factor of 30, between the Bayes
factor of 0.0075 and the p-value of 0.00025 arose as follows:
• A factor of 0.0014/0.00025 ≈5.6 is due to the difference between the tail area {X ≥7} and
the actual observation x = 7.
• The remaining factor of roughly 5.4 in favour of the null results from the Ockham’s razor
penalty that Bayesian analysis automatically gives to a more complex model.
One way to help teach students that p-values are very different from error probabilities (both
Bayesian and frequentist) is to utilize the applet (of German Molina) available at www.stat.duke.
edu/∼berger.

368
M. J. Bayarri and J. O. Berger
18.3.2 Conditional frequentist testing
To a strict frequentist, p-values are not relevant, since they cannot be given an interpretation as
real error rates in repeated experimentation. Indeed, the difference between p-values and actual
frequentist error probabilities can be seen from the conditional frequentist viewpoint ([88], [24]).
This approach proceeds by
1. finding a statistic S that reflects the ‘strength of evidence’ in the data;
2. computing the frequentist measure of error conditional on the observed S.
Example 18.1 Observe X1 and X2 where
Xi =

θ + 1
with probability 1/2
θ −1
with probability 1/2
It is easy to see that
C(X1, X2) =
(X1 + X2)/2
if X1 ̸= X2
X1 −1
if X1 = X2
is a confidence set for θ, with coverage Pr{C(X1, X2) contains θ | θ} = 0.75. This is a silly state-
ment, however, since, when x1 ̸= x2 it is a logical certainty that C(X1, X2) is θ while, if x1 = x2, it
is intuitively clear that C(X1, X2) has only a 50% chance of being θ.
Here, the strength of evidence in the data is appropriately measured by S = |X1 −X2| (which is
either 0 or 2), so conditional frequentists compute instead the conditional coverage
Pr{C(X1, X2) contains θ | θ, S} =
 0.5
if S = 0
1.0
if S = 2 ,
which appropriately agrees with intuition.
For the testing problem, [16] (continuous case) and [42] (discrete case) proposed the following
conditional frequentist test:
1. Develop the ‘strength of evidence’ statistic S as follows:
• let pi(x) be the p-value from testing Hi against the other hypothesis, recognizing that
p-values are monotonically related to the strength of evidence against hypotheses (and
any monotonic function of a conditioning statistic yields the same result);
• define S(x) = max{p0(x), p1(x)}; its use is based on deciding that data (in either the
rejection or acceptance regions) with the same p-value has the same ‘strength of evi-
dence.’
2. Accept H0 when p0(x) > p1(x) and reject otherwise.
3. Compute Type I and Type II conditional error probabilities as
α(s) = Pr(rejecting H0 | S = s, H0) ≡Pr(p0(X) ≤p1(X) | S = s, H0)
β(s) = Pr(accepting H0 | S = s, H1) ≡Pr(p0(X) > p1(X) | S = s, H1) .

Hypothesis testing and model uncertainty
369
The major surprise that results from this test is that the conditional frequentist Type I error prob-
ability exactly equals the Bayesian posterior probability of the null hypothesis when Pr(H0) =
Pr(H1) = 0.5. Thus, in the pedagogical example, the conditional frequentist Type I error is α(s) =
Pr(H0 | x) = B01/(1 + B01) (= 0.0075 in Case 1; = 0.21 in Case 2). So the discrepancy with the
p-value is not a Bayesian versus frequentist issue, but rather an issue of conditioning on the actual
data versus using a tail area.
18.3.3 When there is no alternative hypothesis
One commonly heard defence of p-values is that they can be used when there is only the null
hypothesis, whereas Bayesian and frequentist testing requires an alternative hypothesis. Robust
Bayesian theory suggests a way to proceed, however, even in the absence of an alternative
hypothesis.
A proper p-value satisfies H0 : p(X) ∼Uniform(0, 1). [120] consider testing this versus H1 :
p ∼f(p), where Y = −log(p) has a decreasing failure rate (a natural nonparametric alternative).
Then,
Theorem 18.2 If p < e−1, B01(p) ≥−e p log(p). An analogous lower bound on the conditional
Type I frequentist error is
α(p) ≥(1 + [−e p log(p)]−1)−1
(18.2)
In the pedagogical example, p = 0.00025 results in −ep log p = 0.0057 ≈α.
Here are some common p-values and their associated ‘calibrated conditional Type I frequentist
error rates’.
p
0.2
0.1
0.05
0.01
0.005
0.001
α(p)
0.465
0.385
0.289
0.111
0.067
0.0184
18.4 Basics of Bayesian model uncertainty
The Bayesian way of dealing with model uncertainty is not fundamentally different from the way
of dealing with hypothesis testing. However, there can be so many models (if one is doing variable
selection with p possible variables, there are 2p models) that the nature of the problem changes,
both in the methodology and the interpretation. In this section we highlight the basic issues.
18.4.1 Notation for model uncertainty
We assume that data, X, can arise from one of q possible models Mi, i = 1, . . . , q. Each model
specifies a different density for X so that, under model Mi,
Mi: X has density fi(x | θi).
The prior distribution now consists of the model probabilities, Pr(Mi), and the prior densities of
each of the model parameters θi, to be denoted πi(θi). Because of the potentially large number of
models involved, the specification of these quantities is difficult and will be the focus of much of
the development.

370
M. J. Bayarri and J. O. Berger
Once the prior distributions have been assessed, the analysis proceeds by computing the
marginal density of X under each model Mi, i = 1, . . . , q, that is
mi(x) =

fi(x | θi)πi(θi) dθi
intuitively, this is the model likelihood, indicating how likely is x under Mi. The posterior density
of θi under model Mi is
πi(θi | x) = fi(x|θi)πi(θi)
mi(x)
and the posterior probability of each of the models is
Pr(Mi | x) =
Pr(Mi) mi(x)
q
j=1 Pr(Mj) mj(x)
It is often more convenient to work with Bayes factors: the Bayes factor of model Mj to model Mi is
Bji = mj(x)
mi(x)
since this is the ratio of the (integrated) likelihoods of model Mj to model Mi, it is typically inter-
preted as the odds of model Mj to model Mi provided by the data. It is often convenient to choose
a base model M1 (usually the null model if defined), and then report all the Bayes factors Bj1. From
these, it is possible to reconstruct all the posterior model probabilities as
Pr(Mi | x) =
Pr(Mi)Bi1
q
j=1 Pr(Mj)Bj1
.
18.4.2 Assigning model prior probabilities
One must choose prior probabilities, Pr(Mi), for each model. A common choice is equal probabil-
ities, Pr(Mi) = 1/q, but this is often inappropriate, from several perspectives.
Consider the problem of variable selection, for instance. In this problem, there are variables
(e.g. regression coefficients) θ1, . . . , θm that could be included in the model, or could be excluded.
Giving equal probability to all models is equivalent to saying that each variable is in or out of the
modelwithprobability1/2,whichhastheproblemthatthereisnopenaltyforinclusionofvariables.
For instance, if one is testing 100 000 genes for gene expression related to some condition, allowing
each gene to have probability 1/2 of being effective is typically ridiculous.
Forthisproblem,thecommonsolutionistoalloweachvariabletobeindependentlyinthemodel
with unknown probability p (called the prior inclusion probability), and then assign p a distribution.
For instance, if p is given the uniform distribution, the prior probability of a model Mi that has ki
variables is
Pr(Mi) =
 1
0
pki(1 −p)m−kidp = Beta(1 + ki, 1 + m −ki) = ki!(m −ki)!
(m + 1)! .

Hypothesis testing and model uncertainty
371
Curiously, this is the same probability assignment recommended by [79] from a different perspec-
tive.Hesuggestedgivingeachpotentialmodelsizeanequalprobabilityof1/(m + 1)(assumingthe
null model of no variables is also allowed). He then divided this probability up amongst all models
of a given size, the result equalling the expression above.
Forotherdiscussionsofthechoiceofpriorprobabilitiesofmodels,see[60,61],[37],[124],[108],
[118, 119], and [89].
18.4.3 Issues in assigning priors to model parameters
In hypothesis testing, the need for proper priors (as opposed to improper or vague proper pri-
ors) was discussed and applies equally well to choice of priors for model parameters in model
uncertainty. Other complications can also arise; three of the most important are introduced in
this section, namely, the meaning of parameters, predictive matching and information consistency.
Section18.5considersparticularstrategiesthathavebeenproposedforselectionofmodelparameter
priors, especially those oriented to addressing the above issues.
18.4.3.1 Meaning of parameters
Parameters in different models typically have different meanings, even though they might be repre-
sented with the same symbol.
Example 18.3 Consider the variable selection in regression scenario with models
M1 : Y = θ0 + θ1X1 + σ ϵ
M2 : Y = θ0 + θ1X1 + θ2X2 + σ ϵ
ϵ ∼N(0, 1)
It is all too common to see assignment of the same prior, π(θi), to θi regardless of the model in
which it occurs (implicitly also assuming independence of the parameters within a model). This is
usually wrong, since the parameters can have radically different meanings in the two models. For
instance, suppose the problem is predicting fuel consumption, Y, of a car from weight, X1, and
engine size, X2. Clearly θ1 has a very different meaning under M1 than under M2. (Regressing Y
on X1 alone produces larger θ1 than regressing on both, due to the high correlation between X1
and X2.)
The right way to proceed is to formulate the model selection problem as:
M1 : Y = θ(1)
0
+ θ(1)
1 X1 + σ(1) ϵ
M2 : Y = θ(2)
0
+ θ(2)
1 X1 + θ(2)
2 X2 + σ (2) ϵ
and then assess distinct priors π1(θ(1)
0 , θ(1)
1 , σ (1)) and π2(θ(2)
0 , θ(2)
1 , θ(2)
2 , σ (2)) under each of the
models.
Of course, this only makes the problem more complicated, with the need for 2p different priors
in variable selection.
18.4.3.2 Predictive matching
Predictive matching is a major tool for deriving priors for model uncertainty, and is also very
valuable as a method of evaluating prior choices. The idea is based on the observation that, if one
makes a mistake of 2 in the prior scale for a one-parameter model compared to a null model, the
Bayes factor is only wrong by a factor of 2. But, if one makes a mistake of a factor of 2 in the scale of

372
M. J. Bayarri and J. O. Berger
a 50-dimensional model, the Bayes factor is off by a factor of 250. Hence it is imperative that priors
across models be appropriately ‘matched’ to avoid major biases.
The most common type of matching is predictive matching, the idea being as follows. Suppose
X∗are observables of interest, usually taken as some small set of possible observations. The pair
{Mi, πi} would yield the marginal density
mi(x∗) =

fi(x∗| θi)πi(θi)dθi .
We then say that {Mi, πi} is ‘predictively matched’ to {Mj, πj} if mi(x∗) ≈mj(x∗). Numerous
examples of this idea will be seen later.
18.4.3.3 Information consistency
Computational considerations often suggest use of conjugate prior distributions, but they can be
problematical in situations of model uncertainty.
Example 18.4 We observe i.i.d. data, X1, . . . , Xn, from the N(xi | θ, σ 2) distribution, with both
parameters unknown. The two models under consideration are M1 : θ = 0 and M2 : θ ̸= 0. The
‘natural’ conjugate priors are
π1(σ 2) = 1/σ 2
π2(θ | σ2) = N(θ | 0, σ 2), π2(σ 2) = 1/σ 2
Note that the improper πi(σ 2) = 1/σ 2 can be used because they are both invariant scale parame-
ters (see Section 18.5.1.1).
The Bayes factor can be computed to be
B21 =
√
n + 1
1 + t2/(n + 1)
1 + t2
n/2
where t = √n¯x/s is the usual t-statistic. Notice that B21 has the following strange behaviour: as
|t| →∞, B21 →(n + 1)−(n−1)/2 > 0. For instance,
if n = 3,
B21 →1/4 ;
if n = 5,
B21 →1/36.
While not conclusively damning, this behaviour is of enough concern that we recommend it be
avoided for default procedures.
18.4.4 Model averaging
18.4.4.1 Basics of model averaging
Selecting a single model and using it for inference ignores model uncertainty, which can result in
biased inferences and considerable overstatements of accuracy. The Bayesian approach to model
uncertainty is model averaging, which simply views the uncertain model as another unknown, and
treats uncertainties regarding the model probabilistically. Thus if, say, inference concerning ξ, a
quantity which is common to all models (such as a future observation or the response mean) is
desired, it would be based on

Hypothesis testing and model uncertainty
373
π(ξ | x) =
q

i=1
Pr(Mi | x) π(ξ | x , Mi),
where π(ξ | x , Mi) is the posterior distribution of ξ under model Mi alone. The reason for the
name ‘model averaging’ is apparent.
Example 18.5 In [96], the problem of determining whether a vehicle type meets regulatory
emission standards was considered. The emissions data X = (X1, . . . , Xn) was assumed to be i.i.d.
from either the Weibull or lognormal distributions given, respectively, by
M1 : fW(x | β, γ ) = γ
β
 x
β
γ −1
exp
1
−
 x
β
γ 2
M2 : fL(x | μ, σ2) =
1
x
7
2πσ 2 exp
1−(log x −μ)2
2σ 2
2
The analysis from [43] proceeds by assigning each model prior probability 1/2. In Section 18.5.1.1,
it will be shown that it is appropriate to use the model parameter priors πW(β, γ ) = 1/(βγ ) and
πL(μ, σ) = 1/σ, respectively. (This is a case where improper priors can be utilized.) Then, the
posterior probabilities (also equal to the conditional frequentist error probabilities) of the two
models are
Pr(M1 | x) = 1 −Pr(M2 | x) =
B(x)
1 + B(x)
where zi = log xi, ¯z = 1
n
n
i=1 zi, s2z = 1
n
n
i=1(zi −¯z)2, and
B(x) =

 
 	n
i=1 fW(xi | β, γ ) (βγ )−1dβdγ

 
 	n
i=1 fL(xi | μ, σ) (σ)−1dμdσ
= (n)nnπ(n−1)/2
(n −1/2)
 ∞
0

y
n
n

i=1
e
 zi−¯z
szy
−n
dy
For the data from [96], computation yields Pr(M1 | x) = 0.712. It thus follows that
Pr(meeting regulatory standard | x) = 0.712 Pr(meeting standard | x, M1)
+ 0.288 Pr(meeting standard | x, M2)
This is superior to selecting one of the models and then computing the probability of meeting the
standard under that model, as it accounts for the model uncertainty.
18.4.4.2 Learning model structure
One of the difficulties with model averaging is that one cannot easily understand model structure,
since one cannot look at a single model to gain insight. One can, however, still look at model-
averaged quantities that reflect model structure, although this is typically very context dependent.
An important example is when the parameters, θi, can be in or out of the model, reflecting the
presence in the model of certain structure. In regression, for example, θi would be the coefficient
of a covariate, and its presence or absence from the model reflects whether or not that covariate
affects the response variable. In graphical models, θi could be associated with a link in the graph, its

374
M. J. Bayarri and J. O. Berger
presence or absence determining whether that link is present in the graph. In all such situations key
model-averaged structural quantities are the posterior inclusion probabilities
qi = Pr(θi ∈model | x) =

j:θi∈Mj
Pr(Mj | x),
(18.3)
i.e. the posterior probability that the ith feature of interest is in the model.
Example 18.6 This is a classical dataset that has been used by several authors (see [26] for
references). The sample size of the data Y is n = 13 and there are four possible regressors: X1, X2,
X3, X4. The full model for an observation is
Y = θ0 + θ1X1 + θ2X2 + θ3X3 + θ4X4 + ϵ, ϵ ∼N(0, σ 2)
with σ2 unknown. The models under consideration are all of the models that can be defined with
subsets of regressors, with the intercept being present in all models. We use the following notation:
Model {1, 3, 4}
denotes the model
Y = θ0 + θ1X1 + θ3X3 + θ4X4 + ϵ.
Table18.1reportstheresultsofamodeluncertaintyanalysisusingtheencompassingAIBFapproach
of [? ]. The posterior probability of each model is reported, along with ‘excess predictive risks’,
R(Mi), that will be discussed in the next section.
The posterior inclusion probabilities here are
q1 = 
j:θ1∈Mj Pr(Mj | Y) = 0.95, q2 = 
j:θ2∈Mj Pr(Mj | Y) = 0.73 ,
q3 = 
j:θ3∈Mj Pr(Mj | Y) = 0.43, q4 = 
j:θ4∈Mj Pr(Mj | Y) = 0.55.
(18.4)
Thus there is a strong indication that X1 is an important regressor, with lesser evidence for the
importance of the other Xi as regressors.
Table 18.1 Posterior model probabilities and corresponding excess predictive risks for the Hald
regression example.
Model
Pr(Mi | Y)
R(Mi)
null
0.000003
2652.44
{1}
0.000012
1207.04
{2}
0.000026
854.85
{3}
0.000002
1864.41
{4}
0.000058
838.20
{1,2}
0.275484
8.19
{1,3}
0.000006
1174.14
{1,4}
0.107798
29.73
Model
Pr(Mi | Y)
R(Mi)
{2,3}
0.000229
353.72
{2,4}
0.000018
821.15
{3,4}
0.003785
118.59
{1,2,3}
0.170990
1.21
{1,2,4}
0.190720
0.18
{1,3,4}
0.159959
1.71
{2,3,4}
0.041323
20.42
{1,2,3,4}
0.049587
0.47

Hypothesis testing and model uncertainty
375
Among the many references to model averaging are [62], [51], [108], and [33]. See also the
Bayesian Model Averaging webpage http://www.research.att.com/volinsky/bma.html.
18.4.4.3 Prediction
When the goal is to predict a future Y, given x, the optimal prediction is based on model averaging.
If one of the Mi is indeed the true model (but unknown), the posterior predictive distribution of Y
(its posterior distribution given x) is
m(y | x) =
q

i=1
Pr(Mi | x) mi(y | x, Mi),
where
mi(y | x, Mi) =

fi(y | θi) πi(θi | x)dθi
is the posterior predictive distribution when Mi is true. For instance, the usual predictor of Y
would be the posterior predictive mean, which would be ˆY = q
i=1 Pr(Mi | x) ˆYi, where ˆYi is the
posterior predictive mean arising from model Mi. This is, indeed, the optimal predictor of Y under
squared error loss. For illustration of the excellent performance of model averaged prediction, see
http://www.research.att.com/volinsky/bma.html.
It should be noted that the optimality of model averaged prediction implicitly assumes that
the true model is among those being considered, which is often referred to as the closed model
perspective. (See, e.g. [21].) Under the open model perspective, in which the true model is not
assumedtobeamongthoseunderconsideration,itisnotclearwhatisoptimal.Nevertheless,model
averagingwouldstillseemintuitivelytobevaluable,atleasttotheextentofprovidingmoreaccurate
assessments of uncertainty in prediction. (See also [87].)
18.4.4.4 Optimal single model prediction
Computational or other considerations often require choice of a single model, which will then
be used for prediction. Standard practice is to choose the maximum posterior probability model
(leading, e.g. to the ubiquitous ‘MAP’ estimates). This practice is fine if only two models are being
entertained (see [9]) and in problems such as variable selection in linear models with orthogonal
design matrices (cf. [34, 35]), but is not generally optimal.
For instance, consider the scenario where models are defined by parameters θi that are in or out
of the model, reflecting model features such as covariates. The optimal single predictive model is
then often the median probability model, defined as the model consisting of those parameters whose
posterior inclusion probability (18.3) is at least 1/2.
Consider Example 18.6 for instance. From (18.4), it is clear that the median probability model
is {1, 2, 4}, since the corresponding parameters have probability greater than 1/2 of being in the
model. Note from Table 18.1 that this is not the maximum posterior probability model, which is
instead {1, 2}.
Conditions under which the median probability model is guaranteed to yield better predictive
performance are given in [2]. Even when these conditions are not satisfied, however, the median
probability model will often be optimal in practice. For instance, Example 18.6 is not a situation
which satisfies the conditions in [2], yet the predictive risk of {1, 2, 4} is seen in Table 18.1 to be
smaller than the predictive risk of any other model. More precisely, the table reports R(Mi) =
E[(Y −ˆYi)2] −E[(Y −ˆY)2], the difference between the expected squared error loss of the single
model (best) predictor, ˆYi, and the expected squared error loss of the optimal overall predictor,
which is the model averaged predictor; expectation here is over the model averaged posterior

376
M. J. Bayarri and J. O. Berger
predictive distribution of Y. Not only is {1, 2, 4} clearly superior to {1, 2} (or any other model),
but it does almost as well in this example as the optimal model-averaged predictor.
18.4.5 Consistency
A key feature of proper Bayesian model uncertainty analysis is that it is asymptotically consistent,
which means that, if one of the entertained models is true, then the posterior probability of that
model will go to one as the sample size grows to ∞(assuming the model began with prior proba-
bilitygreaterthanzero,andthesupportoftheparameterpriorforthatmodelistheentireparameter
space). Even more remarkably, if the true model, M∗, is not among the models being considered,
then the posterior probability will go to one for that model, among those being considered, that
is closest to M∗in terms of Kullback–Leibler divergence. (See [19] and [50]; related references on
consistency of Bayesian methods are [44], [17], [136] and [99].)
The paragraph above began with the phrase ‘proper Bayesian model uncertainty analysis’,
because these consistency results are only guaranteed to hold when the analysis is fully Bayesian,
with proper and non-zero priors. We will see that practical considerations often lead to a host
of modifications or approximations to Bayesian model uncertainty analysis, and it is important
to recognize that consistency is no longer guaranteed for these modifications. Indeed, verifying
consistency then becomes one of the basic checks to see if the modification is satisfactory.
18.4.6 Ockham’s razor
Ockham’srazoristhelong-believedscientificprinciplethat,iftwomodelsarebothcompatiblewith
the data, then the simplest one should be preferred. Simplest here does not refer to difficulty in
understanding the model, but in the ‘degrees of freedom’ in the model.
For instance, [80] considered a historical problem in which two theories were advanced to
explain an anomaly in the orbit of Mercury. One theory (model) was Einstein’s general relativity,
which was essentially a fully specified theory with no free parameters (and hence a ‘simple’ theory);
the other theory (model) supposed the existence of a planet Vulcan circling too close to the sun to
be seen, and this theory had free parameters (e.g. the mass of the planet). Both did a reasonable job
of explaining the anomaly in Mercury’s orbit, but Ockham’s razor would say to favour the theory
with fewer degrees of freedom, here general relativity.
One of the attractive features of Bayesian analysis is that it automatically follows Ockham’s razor,
because of the prior distributions placed on the parameters (the degrees of freedom) of models.
Space precludes a demonstration here; see [80] for application of the Bayesian Ockham’s razor to
the historical problem.
18.5 Choosing priors for model uncertainty
In this section we review some frequently used methods for choosing priors for analysis of model
uncertainty.Moreelaboratereviewsofvariousofthesemethodscanbefoundin[14],[64,65],[90],
and [7].
18.5.1 Choosing priors for ‘common parameters’
It was seen, in Section 18.2.4, that, if a parameter occurs in one model but not another, then it must
be assigned a proper (and non-vague) prior for the Bayes factor between the models to make sense.
Iftheparameteroccursinbothmodels,however,thisisnotnecessarilythecase;improperobjective
priors can then often be used. Here we discuss two situations in which this is reasonable.

Hypothesis testing and model uncertainty
377
18.5.1.1 Invariance
If there are parameters in each hypothesis that have what is called the same ‘group invariance
structure’, then one can use the ‘right-Haar priors’ for those parameters, even when improper.
Development of this is beyond the scope of the chapter, but the following illustration conveys the
basic idea.
Example
18.7
Suppose i.i.d. data X1, . . . , Xn
arises from a density of the form
σ −1g ((x −μ)/σ); such densities are called location-scale densities, with μ being the
location parameter and σ the scale parameter. (This is an important class including, for instance,
the normal distribution.) This class has a group invariance structure for which the right-Haar prior
is πH(μ, σ) = 1/σ, which is clearly improper.
Suppose now that one has two different location scale models, determined by g1 and g2. The
invariance theory then says that one can use the same right-Haar prior for both in computing the
Bayes factor, leading to
B12 =

 
 	n
i=1 σ −1g1 ((xi −μ)/σ)

πH(μ, σ)dμdσ

 
 	n
i=1 σ −1g2 ((xi −μ)/σ)

πH(μ, σ)dμdσ
This was the result used in Example 18.5 for the choices of priors there. (πL(μ, σ) = 1/σ was
clearly the right-Haar prior; πW(θ, γ ) = 1/(θγ ) can be seen to be the right-Haar prior after
transforming to y = log x, μ = log β, and σ = 1/γ .)
Onemotivationforusingtheright-Haarpriorherearisesfromthenotionofpredictivematching,as
introduced in Section 18.4.3.2. The intuition, following similar arguments in [79], is that, if one only
had two observations, X1 and X2, there should be no way to differentiate between g1 and g2, since
the two observations can only learn about μ and σ; there are no ‘degrees of freedom’ left to learn
about g. The argument proceeds that one should choose model parameter priors so that B12 = 1
if there are only two observations.
It is, indeed, shown in [18] that, for the right-Haar prior and any g,
m(x1, x2) =
  1 1
σ2 g
x1 −μ
σ

g
x2 −μ
σ
2 1
σ dμdσ =
1
2|x1 −x2|
from which it is immediate that B12 = 1 for any two observations. [18] also generalize this to
essentially any model with a group invariance structure, thus providing a wide class of problems
for which we know that use of objective improper priors is fine.
18.5.1.2 Parameters with the same scientific meaning
If there are parameters in each model that have the same scientific meaning, reasonable default
priors(e.g.theconstantprior1)canbeused.Forinstance,inthepedagogicalexampleofSection18.2,
if b were unknown it would have the same scientific meaning in both hypotheses, and could hence
be assigned the same improper objective prior, e.g. a constant prior, or the Jeffreys prior 1/
√
b
for a Poisson mean. Note that the difficulties with normalizing constants that were discussed in
Section 18.2.4 do not apply when there is a common prior in both the numerator and denominator
of a Bayes factor.
Often, similar parameters are present in various models, but they do not have the same meaning;
see Section 18.4.3.1. A common strategy to obtain parameters with the same meaning—initiated by
[79]—istoorthogonalizetheparameters,i.e.toreparameterizesothattheexpectedFisherinforma-
tion matrix is diagonal. The idea is that the parameters are then ‘independent in the likelihood’ (at
least asymptotically) so that a parameter then more plausibly has the same meaning across models.

378
M. J. Bayarri and J. O. Berger
There is still the issue of what objective prior to choose for the ‘orthogonalized parameter,’ but the
notion is that usually one can then employ standard estimation objective priors. Discussions of this
can be found in [85], [36], [41], [74] and [25].
18.5.2 Inducing model priors from a single prior
The number of models under consideration is often vast (e.g. 2p in variable selection), so that
separate determination of parameter priors for each model is typically not feasible. In this section
we discuss the powerful idea of selecting only one prior, and inducing all others from this single
prior.
18.5.2.1 Basic idea
Specify a prior πL(θL) for the ‘largest’ model, and use this prior to induce priors on the other
models. Possibilities for inducing priors on other models include
1. In variable selection, remove variables by conditioning them to be zero.
2. In variable selection, marginalize out the variables to be removed.
3. Projecting πL(θL) onto the parameter space of other models through a minimization of
Kullback–Leibler divergence. While this last is a potentially powerful tool (see [68] and [20]
for illustration), it is often difficult to implement and will not be considered here.
Example 18.8 SupposethelargestmodelhaspriorπL(p1, . . . , pm) ∼Dirichlet(1, . . . , 1)(i.e.the
uniform distribution on the simplex). If other models have parameters (pi1, . . . , pil),
1. conditioning yields π(pi1, . . . , pil, p∗| other pj = 0) = Dirichlet(1, . . . , 1), where p∗=
1 −l
j=1 pij;
2. marginalizing yields π(pi1, . . . , pil, p∗) = Dirichlet(1, . . . , 1, m −l).
This example clearly indicates that the conditional approach is the correct approach; the marginal
approach would result in priors for (pi1, . . . , pil) that are much too concentrated near zero if m −l
is large.
18.5.2.2 Application to the linear model
Analysesofmodeluncertaintyforthelinearmodelusuallyutilizeso-calledg-priorsorZellner–Siow
priors ([135]). These and more modern alternatives can all be derived through the above condi-
tional inducement from a full prior, as will be illustrated here.
The full linear model for data Y = (Y1, . . . , Yn)′ is given by
Y = 1 θ0 + Xθ + ε
(18.5)
where X (p × n) is the matrix of covariates (full rank), θ = (θ1, . . . , θp) is an unknown vector of
regression coefficients; 1 is a vector of ones; θ0 is the unknown mean level (intercept); and ε is
N(0, σ2I). For notational simplicity we assume that 1tX = 0, which results from ‘centring’ the
columns of X by their means.
The models under consideration are all the submodels from (18.5) resulting from deleting com-
ponents of θ and corresponding columns in X; we assume, however, that all models have the
intercept. A convenient notation for such submodels is to let γ = (γ1, . . . , γp), where γi = 1 if

Hypothesis testing and model uncertainty
379
variable Xi enters the model (that is, θi ̸= 0), and γi = 0 otherwise (θi = 0). Then, the 2p values
for γ index the model space with elements Mγ , with corresponding θγ and Xγ .
Note first that the parameters θ0 and σ are common to all models. Furthermore, it can be shown
that they are location-scale parameters and, hence, an adaptation of the argument in Section 18.5.1.1
justifies use of the common right-Haar prior πγ (θ0, σ) ∝1/σ for these parameters in all models.
See [104] and [7] for further discussion.
The priors for θγ must be proper, since they are not common to all models. Considering first
the full model in (18.5), an interesting class of priors is
π(θ | σ) =
 ∞
0
N(θ | 0, g σ 2 (XtX)−1)π(g)dg
(18.6)
where π(g) is a density on g > 0. Centring the prior at 0 is a natural choice from an objective
perspective.Choosingthecovariancematrixtobeproportionalto σ 2(XtX)−1,whichisthecovari-
ance matrix of the least squares estimate of θ, has three purposes. The first is to ensure that the
prior is invariant to change in the units of measurement of both Y and the covariates X. The
second is to satisfy a predictive matching criterion that is given in [7]; space limitations preclude
discussion here. Finally, we will see that this choice of covariance matrix greatly simplifies the
computation.
With a prior for the full model, we can now induce a prior on each submodel by conditioning.
In particular, from multivariate normal theory it is immediate that, given g and σ 2, the distribution
of θγ given that the other coordinates are set to zero is N(θγ | 0, g σ 2 (Xtγ Xγ )−1), from which it
follows that the induced priors on the submodels are
πγ (θγ | σ) =
 ∞
0
N(θγ | 0, g σ 2 (Xt
γ Xγ )−1)π(g)dg
(18.7)
Priors such as this are called mixtures of g-priors, and are extensively studied in [90] and [7]. The
two most common choices of π(g) are as follows.
g-priors (from [134]) use just a fixed g, typically g = n, the reason being that n(Xtγ Xγ )−1
typically stabilizes as n grows. This choice allows closed form computation of Bayes factors but
can be shown to violate information consistency (see Section 18.4.3.3).
Zellner–Siow priors (from [135]) utilize an inverse gamma density for g with scale parameter
n/2 and shape parameter 1/2; for this choice, (18.7) is actually the multivariate Cauchy density.
The disadvantage of this prior is that it does not lead to closed form Bayes factors.
Recently, a g-mixture prior has been proposed that yields closed form answers and satisfies all the
desiderata that have been suggested for priors for model uncertainty in the linear model. Indeed,
[7] propose use of
πγ (g) = (0.5)

(1 + n)/(1 + kγ )
1/2 (g + 1)−3/21{g>(1+n)/(1+kγ )−1}
where kγ is the dimension of θγ . This results in the following closed form expression for the Bayes
factor of model Mγ to the intercept only model M0:
Bγ 0 =
1 n + 1
kγ + 1
2−
kγ
2
Q−n−1
2
γ 0
kγ + 1 2F1
8kγ + 1
2
; n −1
2
; kγ + 3
2
;
(1 −Q−1
γ 0 )(kγ + 1)
(1 + n)
9

380
M. J. Bayarri and J. O. Berger
where 2F1 is the standard hypergeometric function (see [1]) and Qγ 0 = SSEγ /SSE0 is the ratio
of the sum of squared errors of Mγ and M0.
There is a huge literature on priors for linear and generalized linear models, with many other
ideas and suggestions. A few of the references are [34], [59], [31], [81, 82], [39], [131], [93], [40],
[70], [94], [95] and [114].
18.5.3 Predictive matching approaches
We have already seen an example of predictive matching in invariant situations utilizing the
right-Haar prior. This section mentions three other examples of application of the idea. Other
examples will be seen in Section 18.5.4.
18.5.3.1 Subjective matching
It is often asserted that, in subjective Bayesian statistics, one should elicit distributions of observ-
ables, not distributions of parameters (cf. [45], [83]). Thus suppose one begins the model uncer-
tainty analysis by eliciting a distribution m(x∗) of observables x∗; we will assume here that x∗is a
potential sample of observations, and will usually be chosen to be a small sample size (so that the
elicitation is easier).
If we now consider a model Mi, it is natural to choose a prior πi(θi) so that this prior reflects
the beliefs that have been encoded in m(x∗). In particular, if we were to interpret m(x∗) as
the marginal density arising from our true model and prior, then m(x∗) should be close to
mT(x∗) =

fT(x∗| θT) πT(θT)dθT. It follows that, for any model Mi being considered, one
should choose the prior πi(θi) so that mi(x∗) =

fi(x∗| θi) πi(θi)dθi is as close as possible
to m(x∗).
[121] established the following interesting result. Start with any prior π(0)
i
(θi) with full support
(e.g. a constant prior), and iteratively define
π(l)
i (θi) =

π(l−1)
i
(θi | x∗) m(x∗)d(x∗)
(18.8)
where π(l−1)
i
(θi | x∗) is the posterior under model Mi if π(l−1)
i
(θi) were the prior. Then π(l)
i
converges to that prior such that the resulting mi(x∗) is closest to the elicited m∗(x∗) in
Kullback–Leibler divergence. Furthermore, the convergence is extremely fast, so that often only
two or three iterations are needed.
18.5.3.2 Predictive moment matching
This approach seeks to choose the πi(θi) so that the mi(x∗) are similar in terms of moments or
other features for the various models. (See [76], [77].)
18.5.3.3 ‘Calibrated’ noninformative priors
This approach utilizes standard improper objective estimation priors, but chooses specific multi-
plicative constants for the priors so as to obtain matching of the mi(x∗0) at some specified point (or
points) x∗0. See [126] and [65] for examples and discussion.
18.5.4 Training sample methods of model selection
Efforts to utilize the data itself or imaginary data to help determine the prior have a long history,
starting with [67], [79], and [125]. There have been very bad versions of this idea, such as repeated

Hypothesis testing and model uncertainty
381
efforts to utilize the likelihood itself as the prior. The successful versions of this idea utilize only
a small fraction of the data—or a small amount of imaginary data—to help determine the prior.
Three variants of the idea are discussed in this section.
18.5.4.1 Median intrinsic posterior probabilities
ThismethodutilizessubsetsofthedatatodirectlyconstructBayesfactorsorposteriorprobabilities
from objective improper priors. We only illustrate the idea here in the simplest setting, that of
choosing between two models. Also, we discuss only one of a class of related methods, the median
intrinsic method of [13].
Suppose that data X = {X1, X2, . . . , Xn} are i.i.d. from either M1 : f1(x | θ1) or M2 :
f2(x | θ2). The standard objective prior probabilities are Pr(M1) = Pr(M2) = 1/2, and we
assume that objective estimation priors πo
j (θj) are available, leading to marginal likelihoods
mo
j (x) =

fj(x | θj)πo
j (θj)dθj. We know, of course, that we cannot use these marginal likeli-
hoods directly for model comparison (unless the two models have the same group invariance
structure).
A key notion is that of minimal training sample size, which is defined to be the smallest sample size
for which mo
1(x) and mo
2(x) are finite. Let x(l) denote any subset of the data of minimal training
sample size; such subsets are called minimal training samples. It is immediate that πo
j (θ | x(l)) =
fj(x(l) | θ) πo
j (θj)/mo(x(l)) are proper posterior distributions.
Wecannowutilizetheseposteriorsaspriors,togetherwiththeremainingdatax(−l),tocompute
the posterior probabilities of M1 and M2; the result is
Pr(M1| x(−l)) = 1 −Pr(M2| x(−l)) =

1 +

f2(x(−l) | θ2)πo
2 (θ2|x(l))dθ2

f1(x(−l) | θ1)πo
1 (θ1|x(l))dθ1
−1
=

1 + mo
2(x)
mo
1(x) · mo
1(x(l))
mo
2(x(l))
−1
Finally,thesuggestionisto‘average’overthechoiceofthetrainingsamplesx(l)bytakingthemedian
of the above values, leading to the median intrinsic posterior probabilities
Prmed(M1 | x) = 1 −Prmed(M2 | x) =

1 + mo
2(x)
mo
1(x) · Median
mo
1(x(l))
mo
2(x(l))
−1
Note that this is a completely general prescription (assuming there are only two models under
consideration), and requires only standard objective estimation priors (even a constant prior could
be used). Furthermore, and most importantly, the procedure can be shown to correspond (at least
forlargen)toanactualBayesprocedurewithsensibleobjectivepriors;thecorrespondingpriorsare
called intrinsic priors and this property that the training sample methods correspond to actual priors
motivates the name for the methodology. Among the many references related to this approach are
[49], [55], [129], [50], [115], [12, 14, 15], [47], [78], [56], [97, 98] [87] [92], [116], [8], [110], [109],
and [52].
18.5.4.2 Fractional Bayes factors
This idea was introduced in [101, 102]; instead of using a fraction of the data as a training sample,
the notion is to use a fraction of the likelihood. The algorithm is as follows:

382
M. J. Bayarri and J. O. Berger
Algorithm
Step 1. Choose some ‘fraction’ 0 < b < 1.
Step 2. For model Mj, use the prior π∗
j (θj) ∝

fj(x|θj)
b · πo
j (θj), where πo
j (θj) is an objective
estimation prior (which could just be the constant prior).
Step 3. Compute Bayes factors using these priors and the ‘remaining likelihoods’ [fj(x|θj)](1−b),
resulting in
Bji =

 
fj(x|θj)
(1−b) π∗
j (θj)dθj

 
fi(x|θi)
(1−b) π∗
i (θi)dθi
=

fj(x|θj)πo
j (θj)dθj

fi(x|θi)πo
i (θi)dθi
·

 
fi(x|θi)
b πo
i (θi)dθi

 
fj(x|θj)
b πo
j (θj)dθj
.
The posterior probabilities are then computed from these Bayes factors.
This approach is particularly attractive when the Bayes factors for objective estimation priors are
available in closed form. It is also broadly applicable (except for serious concerns in irregular prob-
lems, as observed in [13, 14]). The key issue is choosing the fraction b, and the typically recom-
mended choice is b = ki/n, where n is the sample size and ki is the dimension of the parameter in
model Mi; it has been noted, however, that specification of different fractions for different parts of
the likelihood may be necessary ([48]).
18.5.4.3 Expected posterior priors
Thenamereflectsthefactthattheprioriscomputedasanappropriateexpectationofposteriors(see
[105, 106], [100]). The method proposes to train the initial objective estimation priors, πo
i (θi), as
follows:
1. Compute the ‘initial marginals’ mo
i (x) =

fi(x | θi)πo
i (θi)dθi; note that these will be
improper if the initial priors are improper.
2. Next, consider a (random) training sample, x∗, such that the posterior distributions
πo
i (θi | x∗) = fi(x∗| θi)πo
i (θi)/mo
i (x∗) exist, for i = 1, . . . , q.
3. Specify a density m∗(x∗). The prior densities
π∗
i (θi) =

πo
i (θi | x∗) m∗(x∗)dx∗
are the expected posterior priors for the θi, with respect to m∗(·).
Note that the expected posterior priors, π∗
i (θi), will not be proper unless m∗itself is proper, but
are always properly ‘calibrated’ across models, which make them appropriate for objective Bayesian
model selection.
An interesting choice for the mixing measure m∗is the empirical distribution. Specifically, given
observations x1, . . . , xn, let
m∗(x∗) = 1
L

l
I{x(l)}(x∗),

Hypothesis testing and model uncertainty
383
where x(l) = (xl1, . . . , xlm) is a subsample of size 0 < m < n such that πo
i (θi | x(l)) exists for all
models Mi, and L is the number of such subsamples of size m. For other reasonable choices of m∗,
and discussion of computation with expected posterior priors, see [105, 106].
Example 18.9
For the pedagogical example in Section 18.2, suppose we choose the initial
πo(θ) = 1/(θ + b). (Jeffreys prior, the square root of πo, would probably be better, but
leads to a much more difficult computation.) Following the ideas in [15], we represent the
Poisson observation, X, over the time period T from the distribution in the example as
a sum of i.i.d. observations from an exponential inter-arrival time process. Indeed, for i =
1, . . ., if we consider Yi ∼f(yi | (θ + b)/T) = (θ + b)T−1 exp{−(θ + b) yi/T}, then X ≡
{first j such that Sj = j
i=1 Yi > T} −1. The minimal sample size for this exponential distribu-
tion can easily be seen to be 1. Computation then yields
πE(θ) =
 ∞
0
πo(θ | y1)f(y1 | b/T) dy1 =
b
(θ + b)2
which was the conventional proper prior used for Bayesian testing in the example.
18.5.5 Evaluating choices of priors for model uncertainty
In objective Bayesian estimation, there are a variety of criteria that objective priors should satisfy
which often yield a unique (or at least, robust) objective prior. This is not the case with objec-
tive priors for model uncertainty. There are certainly important criteria; consistency, information
consistency, and invariance have been discussed herein, and others can be found in the literature
(see, e.g. [7]). But these criteria rarely yield a unique or robust answer, and even application of
these criteria is far from universal (e.g. there are many proposed Bayesian model uncertainty proce-
dures—such as DIC [127]—that are not even consistent).
Oneseemlyobviouscriterionisthatobjectivemodelselectionproceduresshouldcorrespond,in
some way, to actual Bayesian procedures arising from reasonable priors. Calling a procedure which
fails to satisfy this criterion ‘Bayesian’ is not reasonable. Yet many so-called Bayesian procedures
(DIC again is an example) fail this simple test. This basic point was first highlighted in [125], which
showed how various model selection criteria were formal Bayesian procedures, but some corre-
sponded to bizarre priors (e.g. prior variances →0 as n →∞). See [14] for additional discussion
and examples.
Note, finally, that, if one is comparing real Bayesian model selection procedures, use of simu-
lations for comparison is typically useless. By definition, a Bayes procedure will perform best for
models and model parameters chosen from its prior distribution so, when one real Bayes procedure
outperforms another, it means nothing more than that the priors used to construct the simulation
were closer to the priors defining that Bayes procedure.
18.6 Other issues with Bayesian model uncertainty
18.6.1 Computation and search
There are two main computational difficulties encountered in dealing with Bayesian model uncer-
tainty. The first is that computation of the marginal likelihoods mi(x) =

fi(x | θi)πi(θi) dθi can
be difficult, as they potentially involve high-dimensional numerical integration. There is a huge
literature addressing such computations. One of the early key references was [57]. Others include
[27], [69], [84], [130], [108], [33], [30], [46], [66], [72], [11], [29], [123], [122], [109], [113], [32].

384
M. J. Bayarri and J. O. Berger
The second computational difficulty is the potential size of the model space. If one has, say, 60
variables in a variable selection problem, the number of possible models is 260, which is far too
large for enumeration; indeed, only a very small fraction of these models could ever be visited in
any computational scheme. This is not an issue if the variables are orthogonal (see e.g. [36]), but
otherwise can be highly problematic. For approaches to dealing with this problem, see [11], [73],
[22], [132], and [38].
18.6.2 Approximations and asymptotics
An important approximation to a Bayes factor is the Laplace approximation, given by
BL
21 =

f2(x | θ2)π2(θ2)dθ2

f1(x | θ1)π1(θ1)dθ1
≈f2(x | 'θ2) |'I2|−1/2
f1(x | 'θ1) |'I1|−1/2 · (2π)q2/2π2('θ2)
(2π)q1/2π1('θ1)
(18.9)
where'θ1 and'θ2 are the m.l.e.s for θ1 and θ2 (which have dimensions q1 and q2) and'I1 and'I2 are
observed information matrices (slightly more accurate would be to base'θi and'Ii on the full inte-
grands in (18.9) rather than only the likelihoods). This is an asymptotically correct approximation
as the sample size grows and, often, is surprisingly accurate for even small sample sizes. Indeed, this
approximation has become the computational basis of a popular Bayesian analysis package INLA
(see www.r-inla.org/ where software, references and useful material is provided).
Furthermore, this approximation is used to develop simple model selection tools such as BIC
(the Bayes Information Criterion from [117]). Following [107], one route to BIC from (18.9) is to
choose the πj(θj) to be N(θj | 'θj, n'I−1
j
), where n is the sample size, in which case (18.9) becomes
B21 ≈f2(x | 'θ2)
f1(x | 'θ1)
· n
1
2 (q2−q1)
which is the Bayes factor form of BIC and is very convenient to use. Unfortunately, this choice of
prior is problematical (the prior being centred on the mle), and BIC can behave quite poorly when
the sample size is not large relative to the dimensions of the model parameters. Further discussion
of these issues, and generalizations, can be found in [86], [53], [85], [103], [14], [64], [17], [63], and
[133].
18.6.3 Multiplicity
Inclassicalstatistics,dealingwithmultiplehypothesesrequiresamultiplicitycorrectiontotheerror
probabilities. In contrast, Bayesian analysis deals with multiplicity adjustment solely through the
assignment of prior probabilities to models or hypotheses.
Example 18.10 Suppose one is testing mutually exclusive hypotheses Hi, i = 1, . . . , q, so each
hypothesis is a separate model. If the hypotheses are viewed as exchangeable, it is natural to choose
Pr(Hi) = 1/q. For instance, suppose 1000 energy channels are searched for presence of a signal
indicating the Higgs boson;
• if the signal is known to exist and occupy only one channel, but no channel is theoretically
preferred, assign each channel prior probability 0.001;
• if the signal is not known to exist, prior probability 1/2 should be given to ‘no signal,’ and
probability 0.0005 to each channel.
The key fact is that this is the Bayesian solution regardless of the structure of the data.

Hypothesis testing and model uncertainty
385
In contrast, frequentist control for multiplicity depends strongly on the structure of the data. To
see this, further specialize the example so that, for each channel, one is testing H0i : μi = 0 versus
H1i : μi > 0, i = 1, . . . , 1000, based on data Xi, i = 1, . . . , 1000, that are normally distributed
with mean μi, variance 1, and correlation ρ.
If ρ = 0 and it is desired to obtain an overall error probability of α = 0.05, one can just do
the individual tests at level 0.05/1000 = 0.00005; this ‘Bonferonni correction’ guarantees that the
overall error probability of the multiple testing procedure is 0.05. If ρ > 0, however, the situation is
more difficult. One natural way to proceed would be to choose the overall decision rule “declare μi
to be a signal if Xi is the largest value and Xi > K,” and then compute the corresponding frequentist
type I error probability
α = Pr(max
i
Xi > K | μ1 = . . . = μm = 0) = EZ
1
1 −
K −√ρZ
√1 −ρ
m2
where  is the standard normal cdf and Z is a standard normal random variable.
This gives (essentially) the Bonferroni correction when ρ = 0, but can be shown to converge
to 1 −[K] as ρ →1, which is the type I error that would result from a single test. Thus the
needed frequentist control for multiple testing ranges from the drastic Bonferroni correction to
none, depending on the correlations among the data.
This highlights one of the ways in which dealing with model uncertainty or multiple testing from
aBayesianperspectiveintroducesamajorsimplification;Bayesianaccommodationofmultiplicities
does not depend on the error structure of the data, and the Bayesian adjustment is not highly
conservative in the presence of dependent data.
At the same time, there is a common misconception among many Bayesians that Bayesian anal-
ysis need not concern itself with multiplicity adjustments; it is supposedly handled automatically
by the Bayesian paradigm. This is indeed true if a thorough subjective Bayesian analysis is done,
in the sense that choice of the subjective prior will spread the total prior probability of 1 among
the possible models or hypotheses being considered. We have repeatedly argued, however, that a
full subjective Bayes analysis is rarely possible in situations of model uncertainty (also, in multiple
hypothesis testing), because of the large number of unknowns being considered. Furthermore, as
mentioned in Section 18.4.2, naive and all-too-common choices, such as equal prior probabilities of
models, will not typically control for multiplicity, so the issue is of major importance to Bayesians.
Further general discussion of these issues can be found in [118, 119], which also refer to the previous
Bayesian literature on multiplicity adjustment.
18.6.4 Model criticism
18.6.4.1 Introduction
Bayesianmodeluncertaintyanalysisisbasedoncomparisonofpossiblemodels.Ofteninthemodel
development process, however, one is in the situation of entertaining a single specific model, and
seeking to determine if the model is adequate or needs elaboration—i.e. should one even begin to
develop and consider alternative models.
For the purpose of criticizing a postulated model, classical statisticians use p-values and a variety
of diagnostic tools. Bayesians also use p-values and a variety of diagnostic tools. Because of space
limitations, we limit discussion here to the use of p-values. (For review and references on alternative
non-parametric tests see [128].)
Before beginning, an obvious question is why p-values are even being considered, given all the
problems with p-values that were raised in Section 18.3.1. The answer is that we are not formally

386
M. J. Bayarri and J. O. Berger
rejecting a model based on the p-value but, rather, deciding whether there is an indication that we
shouldexplorefurther.Indeed,asmall p-valueisanindicationthatsomethingunusualhasoccurred
(more precisely, a small value of (18.2) is such an indication), and when something unusual has
occurred it is natural to look further.
Suppose that a statistical model H0 : X ∼f(x | θ) is being entertained, data xobs is observed,
and it is desired to check the adequacy of the model. This is commonly done by choosing a statistic
T = t(X), where large values of T indicate incompatibility with the model. The classical p-value is
then defined as
p = Pr (t(X) ≥t(xobs) | θ).
(18.10)
If θ is known, this probability computation is with respect to f(x | θ); the question of interest
here is what to do when θ is unknown, since computation of the p-value requires some way of
‘eliminating’ θ.
18.6.4.2 Plug-in p-value
There are many non-Bayesian approaches to this problem, some of which are reviewed in [5] and
[111]. The most common method is to replace θ in (18.10) by its m.l.e., ˆθ. The resulting p-value is
called the plug-in p-value (pplug), and is defined as
pplug = Prf(·| ˆθ)(t(X) ≥t(xobs))
(18.11)
Although simple to use, there is a worrisome ‘double use’ of the data in pplug—first to estimate θ and
then to compute the tail area corresponding to t(xobs) in that distribution. Indeed, this difficulty
was one of the motivations for creation of more sophisticated frequentist procedures such as the
bootstrap.
18.6.4.3 Three Bayesian p-values
The principled Bayesian approach is to construct p-values, not from (18.10), but from the marginal
(or predictive) density m(x) =

f(x | θ)π(θ)dθ, where π(θ) is a subjective proper prior. The
resulting p-value was called the predictive p-value by [23].
Much of model checking, however, takes place in scenarios in which the model is quite tentative
and, hence, for which serious subjective prior elicitation is not feasible. And, unfortunately, use of
improper objective prior distributions is not directly possible with the predictive p-value, since the
marginal distribution is itself then improper. (But see [4] for suggestions concerning the use of
conditional marginal distributions based on improper priors.)
The ‘Bayesian solution’ that has become quite popular is to utilize objective initial priors, but
then use the posterior distribution π(θ | xobs), instead of the prior, to define the distribution used
to compute the p-value. This leads to the posterior predictive p-value, originating with [71] and
popularized in [112] and [58], given by
ppost = Prm(· | xobs)(T ≥tobs) ,
m(t | xobs) =

f(t | θ)π(θ | xobs) dθ
(18.12)
Note that, as with the plug-in p-value, there is a ‘double use’ of the data in ppost, first to convert the
objective improper prior into a proper distribution for determining the predictive distribution, and
then for computing the tail area corresponding to t(xobs) in that distribution.
To avoid a double use of the data, [5] proposed the following alternative way of eliminating θ,
basedonBayesianmethodology.Beginwithanobjectivepriordensityπ(θ).Next,definethepartial
posterior density

Hypothesis testing and model uncertainty
387
π(θ | xobs\tobs) ∝f(xobs | tobs, θ)π(θ) ∝f(xobs | θ)π(θ)
f(tobs | θ)
(18.13)
resulting in the partial posterior predictive density of T
m(t | xobs\tobs) =

f(t | θ)π(θ | xobs\tobs) dθ
(18.14)
Since this density is free of θ, it can be used in (18.10) to compute the partial posterior predictive
p-value
pppp = Prm(· | xobs\tobs)(T ≥tobs).
(18.15)
Note that pppp uses only the information in xobs that is not in tobs = t(xobs) to ‘train’ the prior and
eliminate θ. This avoids double use of the data because the contribution of tobs to the posterior is
removed before θ is eliminated by integration.
18.6.4.4 A hierarchical example
An interesting example comparing the above p-values follows, the example taken from [6].
Consider the hierarchical (or random effects) model
Xij | μi ∼N(Xij | μi, σ 2
i ) for i = 1, . . . , I,
j = 1, . . . , ni
μi | ν, τ ∼N(μi | ν, τ2)
for i = 1, . . . , I,
(18.16)
where all variables are independent and the variances, σ 2
i , at the first level are known. Of primary
interestiswhetherthenormalityassumptionforthemeansμi iscompatiblewiththedata.Consider
the test statistic T = max{ ¯X1, . . . , ¯XI}, where ¯Xi denotes the group sample means. Since the μi are
random effects, tests should be based on the marginal densities of the sufficient statistics ¯Xi, with
the μi integrated out. The resulting null distribution is
¯Xi | ν, τ ∼N( ¯Xi | ν, σ 2
i + τ 2)
for i = 1, . . . , I
(18.17)
Thus pplug is computed with respect to this distribution, with the m.l.e.s, ˆν, ˆτ 2 (numerically com-
puted from (18.17)), inserted back into (18.17) and (18.16).
Tocomputetheposteriorpredictivep-valueandthepartialposteriorpredictivep-value,webegin
with a common objective prior for (ν, τ2), namely π(ν, τ2) = 1/τ (not 1/τ2 as is sometimes
done, which would result in an improper posterior). The computation of ppost and pppp require
MCMC methods discussed in [6], though it should be noted that computation of ppost is much
easier.
All three p-values were computed from a realization from the following simulated dataset, in
which one of the groups comes from a distribution with a much larger mean than the other groups:
Xij | μi ∼N(Xij | μi, 4) for i = 1, . . . , 5
j = 1, . . . , 8 ,
μi
∼N(μi | 1, 1)
for i = 1, . . . , 4 ,
μ5
∼N(μ5 | 5, 1).
(18.18)
The resulting sample means were 1.560, 0.641, 1.982, 0.014, 6.964. Crucial is that the sample mean of
the 5th group is 6.65 standard deviations away from the mean of the other four groups. The results:

388
M. J. Bayarri and J. O. Berger
• pplug = 0.130, failing to strongly indicate that the assumption of i.i.d. normality of the μi is
wrong;
• ppost = 0.409, giving absolutely no indication that there is any problem with the assumption
of i.i.d. normality of the μi;
• pppp = 0.010, properly indicating that more investigation of the model is in order.
There is much more that can be said here, and the articles referenced above contain many more
details and arguments. But the take-home message is that double use of the data is harmful when
donebyfrequentists,andseemstobeevenworsewhendonebyBayesians.Moregenerally,thereisa
message that the extra power obtained from Bayesian analysis seems to accentuate logical errors, so
that Bayesians must treat their methodology with care and respect, not giving in to ‘intuitive flights
of fancy.’
References
[1] Abramowitz, M. and Stegun, I. A. (1964). Handbook of Mathematical Functions with Formulas,
Graphs, and Mathematical Tables. New York: Dover.
[2] Barbieri, M. M. and Berger, J. O. (2004). Optimal predictive model selection.Annals of Statis-
tics, 32, pp. 870–897.
[3] Bartlett, M. (1957). A Comment on D. V. Lindley’s Statistical Paradox. Biometrika 44,
533–534.
[4] Bayarri, M. J. and Berger, J. (1998). Quantifying surprise in the data and model verification
[with discussion]. In Bayesian Statistics 6 (Bernardo, J. M., Berger, J. O., Dawid , A. P. and
Smith, A. F. M., eds.), 53–82, Oxford University Press, Oxford.
[5] Bayarri, M. J. and Berger, J. (2000). P-values for composite null models [with discussion].
J. American Statist. Assoc, 95, 1127–1142.
[6] Bayarri, M. J. and Castellanos, M. E. (2007). Bayesian checking of the second level of hierar-
chical models (discussion paper). Statistical Science 22, 3, pp. 322–342; Rejoinder pp. 363–367.
[7] Bayarri, M. J., Berger, J. O., Forte, A. and García-Donato, G. (2012). Criteria for Bayesian
Model Choice with Application to Variable Selection. Annals of Statistics, 40, 1550–1570.
[8] Beattie, S. D., Fong, D. K. H. and Lin, D. K. J. (2002). A two-stage Bayesian model selection
strategy for supersaturated designs. Technometrics, 44, 55–63.
[9] Berger, J. O. (1997). Bayes factors. In Encyclopedia of Statistical Sciences, Update (S. Kotz,
C. B. Read and D. L. Banks, eds.) 3 20–29. New York: Wiley.
[10] Berger,J.andDelampady,M.(1987).TestingPreciseHypotheses(withdiscussion).Statistical
Science, 3, 317–352.
[11] Berger, J. O. and Molina, G. (2003). Discussion of “Recognition of Faces versus Greebles:
A Case Study in Model Selection” by Viele, K., Kass, R. E., Tarr, M. J., Behrmann, M., and
Gauthier, I. In Case Studies in Bayesian Statistics, Vol. VI (Gatsonis, C., Carriquiry, A., Higdon,
D., Kass, R.E., Pauler, D., and Verdinelli, I., eds.), 111–124. New-York: Springer-Verlag.
[12] Berger, J. and Pericchi, L. (1996). The intrinsic Bayes factor for model selection and predic-
tion. Journal of the American Statistical Association, 91, 109–122.
[13] Berger, J. O. and Pericchi, L. R. (1998). Accurate and stable Bayesian model selection: the
median intrinsic Bayes factor. Sankhya: The Indian Journal of Statistics. Series B, 60, 1–18.
[14] Berger, J. O. and Pericchi, R. L. (2001). Objective Bayesian Methods for Model Selection:
Introduction and Comparison (with discussion). Model Selection, ed. P. Lahiri, Institute of
Mathematical Statistics Lecture Notes – Monograph Series, volume 38, pp. 135–207.

Hypothesis testing and model uncertainty
389
[15] Berger, J. O. and Pericchi, L. R. (2004). Training samples in objective Bayesian model selec-
tion. Annals of Statistics, 32, 841–869.
[16] Berger, J. O., Brown, L. D. and Wolpert, R. L. (1994). A unified conditional frequentist and
Bayesian test for fixed and sequential simple hypothesis testing. Annals of Statistics, 22 (4),
1787–1807.
[17] Berger, J. O., Ghosh, J. K. and Mukhopadhyay, N. (2003). Approximations and consistency
of Bayes factors as model dimension grows. Journal of Statistical Planning and Inference, 112,
pp. 241–258.
[18] Berger, J. O., Pericchi, L. R. and Varshavsky, J. A. (1998). Bayes factors and marginal distribu-
tions in invariant situations. Sankhya: The Indian Journal of Statistics. Series A, 60, 307–321.
[19] Berk, R. (1966). Limiting Behavior of posterior distributions when the model is incorrect.
Annals of Mathematical Statistics, 37, 51–58.
[20] Bernardo, J. M. (1999). Nested hypothesis testing: the Bayesian reference criterion. In
Bayesian Statistics 6 (J. M. Bernardo, J. O. Berger, A. P. Dawid and A. F. M. Smith, eds.),
pp. 101–130. London: Oxford University Press.
[21] Bernardo, J. M. and Smith, Adrian F. M. (1994). Bayesian Theory. John Wiley & Sons.
[22] Bottolo, L. and Richardson, S. (2010). Evolutionary stochastic search for Bayesian model
exploration. Bayesian Analysis, 5, 583–618.
[23] Box, G. E. P. (1980). Sampling and Bayes inference in scientific modelling and robustness.
Journal of the Royal Statistical Society, Series A, 143, 383–430.
[24] Brown, L. D. (1978). A contribution to Kiefer’s theory of conditional confidence procedures.
Annals of Statistics, 6, 59–71.
[25] Buck, C. E. and Sahu, S. K. (2000). Bayesian models for relative archaeological chronology
building. Journal of the Royal Statistical Society: Series C (Applied Statistics), 49, 423–440.
[26] Burnham, K. P. and Anderson, D. R. (1998). Model Selection and Inference – A Practical Infor-
mation-Theoretic Approach. New York: Springer-Verlag.
[27] Carlin, B. P. and Chib, S. (1995). Bayesian model choice via Markov chain Monte Carlo.
Journal of Royal Statistical Society – Series B, 57, 473–484.
[28] Casella, G. and Berger, R. L. (1987). Reconciling Bayesian and frequentist evidence in the
one-sided testing problem. Journal of the American Statistical Association, 82, 106–111.
[29] Chen, M. H. (2005). Bayesian computations, from posterior densities to Bayes factors,
marginal likelihoods and posterior model probabilities. In Handbook of Statistics, Volume 25:
Bayesian Thinking, Modeling and Computation (Dipak K. Dey, C. R. Rao, eds.), 437–458.
North Holland.
[30] Chib, S. and Jeliazkov, I. (2001). Marginal likelihood from the Metropolis–Hastings output.
Journal of the American Statistical Association, 96, 270–281.
[31] Chipman, H., George, E. I. and McCulloch, R. (2001). The practical implementation of
Bayesian Model Selection. In Model Selection (P. Lahiri, ed.), 67–116. IMS Lecture Notes
Volume 38.
[32] Chopin, N. and Robert, C. P. (2010). Properties of nested sampling. Biometrika, 97, 741–755.
[33] Clyde, M. (1999). Bayesian Model Averaging and Model Search Strategies (with discussion).
In Bayesian Statistics 6. (J. M. Bernardo, J. O. Berger, A. P. Dawid and A. F. M. Smith, eds.),
pp. 157–185. Oxford University Press.
[34] Clyde, M. and George, E. I. (1999). Empirical Bayes Estimation in Wavelet Nonparametric
Regression. In Bayesian Inference in Wavelet-Based Models (P. Muller and B. Vidakovic, eds.),
309–322. Springer-Verlag.
[35] Clyde, M. A. and George, E. (2004). Model uncertainty. Stastical Science, 19, pp. 81–94.
[36] Clyde,M.andParmigiani,G.(1996).OrthogonalizationsandPriorDistributionsforOrthog-
onalized Model Mixing. In Modelling and Prediction: Honoring Seymour Geisser (J. C. Lee,
W. O. Johnson, and A. Zellner, eds.), 206–227, Springer-Verlag, New York.

390
M. J. Bayarri and J. O. Berger
[37] Clyde, M., DeSimone, H. and Parmigiani, G. (1996). Prediction via orthogonalized model
mixing. Journal of the American Statistical Association, 91, 1197–1208.
[38] Clyde,M.,Ghosh,J.andLittman,M.(2011).Bayesianadaptivesamplingforvariableselection
and model averaging. Journal of Computational and Graphical Statistics, 20, 80–101.
[39] Cripps,E.,Carter,C.andKohn,R.(2005).Variableselectionandcovarianceselectioninmul-
tivariate regression models. In Handbook of Statistics, Volume 25: Bayesian Thinking, Modeling
and Computation (Dipak K. Dey, C. R. Rao, eds.), 519–552. Elsevier.
[40] Cui, W. and George, E. I. (2008). Empirical Bayes vs. fully Bayes variable selection. Journal of
Statistical Planning and Inference, 138, 888–900.
[41] Czado, C. (1997). On selecting parametric link transformation families in generalized linear
models. Journal of Statistical Planning and Inference, 61, 125–139.
[42] Dass, S. C. (2001). Unified Bayesian and Conditional Frequentist Testing Procedures for
Discrete Distributions, Sankhya Ser. B, 63, 251–269.
[43] Dass, S. and Berger, J. (2003). Unified Bayesian and conditional frequentist testing of com-
posite hypotheses. Scandinavian Journal of Statistics, 30, 193–210.
[44] Dass, S. C. and Lee, J. (2004). A note on the consistency of Bayes factors for testing point null
versus non-parametric alternatives. Journal of Statistical Planning and Inference, 119, 143–152.
[45] de Finetti, B. (1975). Theory of Probability (English edition). New York: Wiley.
[46] Dellaportas, P., Forster, J. J. and Ntzoufras, I. (2002). On Bayesian Model and Variable Selec-
tion Using MCMC. Statistics and Computing, 12, 27–36.
[47] De Santis, F. and Spezzaferri, F. (1997). Alternative Bayes factors for model selection. Cana-
dian Journal of Statistics 25, 503–515.
[48] De Santis, F. and Spezzaferri, F. (2001). Consistent fractional Bayes factor for linear models.
Journal of Statistical Planning and Inference, 97, 305–321.
[49] de Vos, A. F. (1993). A fair comparison between regression models of different dimension.
Technical Report, The Free University, Amsterdam.
[50] Dmochowski,J.(1996).IntrinsicpriorsviaKullback–Lieblergeometry.InBayesianStatistics5
(J. M. Bernardo, J. O. Berger, A. P. Dawid and A. F. M. Smith, eds.), 543–550. London: Oxford
University Press.
[51] Draper, D. (1995). Assessment and Propagation of Model Uncertainty. Journal of the Royal
Statistical Society, Ser. B, 57, 45–98.
[52] Draper, D. and Krnjajic, M. (2010). Calibration results for Bayesian model specification.
Bayesian Analysis, 1, 1–43.
[53] Dudley, R. M. and Haughton, D. (1997). Information criteria for multiple data sets and
restricted parameters. Statistica Sinica, 7, 265–284.
[54] Dutta, R., Bogdan, M. and Ghosh, J. K. (2012). Model Selection and Multiple Testing –
A Bayesian and Empirical Bayes Overview and some New Results. Journal of Indian Statistical
Association, Golden Jubilee Year (Volume 50).
[55] Gelfand, A. E. and Dey, D. (1994). Bayesian model choice: asymptotic and exact calculations.
Journal Royal Statistical Society B, 56, 501–514.
[56] Gelfand,A.E.andGhosh,S.K.(1998).ModelChoice:AMinimumPosteriorPredictiveLoss
Approach. Biometrika, 85, 1–11.
[57] Gelfand, Alan E. and Smith, Adrian F. M. (1990). Sampling-based approaches to calculating
marginal densities. Journal of the American Statistical Association, 85, 398–409.
[58] Gelman, A., Carlin, J. B., Stern, H. and Rubin, D. B. (1995). Bayesian Data Analysis. London:
Chapman and Hall.
[59] George, E. I. and Foster, D. P. (2000). Calibration and Empirical Bayes Selection. Biometrika,
87, 731–748.
[60] George, E. I. and McCulloch, R. E. (1993). Variable selection via Gibbs sampling. Journal of
the American Statistical Society, 88, 881–889.

Hypothesis testing and model uncertainty
391
[61] George,E.I.andMcCulloch,R.(1997).ApproachesforBayesianVariableSelection.Statistica
Sinica, 7, 339–374.
[62] Geisser, S. (1993). Predictive Inference: An Introduction. New York: Chapman & Hall.
[63] Ghosh, J. K. and Ramamoorthi, R. V. (2003). Bayesian Nonparametrics. New York:
Springer.
[64] Ghosh, J. K. and Samanta, T. (2001). Model selection – an overview. Current Science, 80,
1135–1144.
[65] Ghosh, J. K. and Samanta, T. (2002). Nonsubjective Bayes testing – an overview. Journal of
Statistical Planning and Inference, 103, 205–223.
[66] Godsill, S. J. (2001). On the relationship between Markov chain Monte Carlo methods for
model uncertainty. Journal of Computational Graphics and Statistics, 10, 230–248.
[67] Good, I. J. (1950). Probability and the Weighing of Evidence. London: Charles Griffin.
[68] Goutis, C. and Robert, C. P. (1998). Model choice in generalized linear models: a Bayesian
approach via Kullback–Leibler projections. Biometrika, 85, 29–37.
[69] Green, P. (1995). Reversible jump Markov chain Monte Carlo computation and Bayesian
model determination. Biometrika, 82, 711–732.
[70] Gupta, M. and Ibrahim, J. (2009). An information matrix prior for Bayesian analysis in gen-
eralized linear models with high dimensional data. Statistica Sinica, 19, 1641–1663.
[71] Guttman, I. (1967). The use of the concept of a future observation in goodness-of-fit prob-
lems. Journal of the Royal Statistical Society Ser. B Stat. Methodol, 29, 83–100.
[72] Han, C. and Carlin, B. P. (2001). Markov Chain Monte Carlo Methods for Computing
Bayes Factors: A Comparative Review. Journal of the American Statistical Association, 96(455),
1122–1132.
[73] Hans, C., Dobra, A. and West, M. (2007). Shotgun stochastic search for “large p” regression.
Journal of the American Statistical Association, 102, 507–516.
[74] Hoeting, J. A., Madigan, D., Raftery, A. E. and Volinsky, C. T. (1999). Bayesian model averag-
ing: a tutorial. Statistical Science, 14(4), 382–417.
[75] Hoijtink, H., Klugkist, I. and Bollen, P. A. (2008). Bayesian Evaluation of Informative Hypothe-
ses. New York: Springer.
[76] Ibrahim,J.andLaud,P.(1994).Apredictiveapproachtotheanalysisofdesignedexperiments.
Journal of the American Statistical Association, 89, 309–319.
[77] Ibrahim, J. G., Chen, M. H. and MacEachern, S. N. (1999). Bayesian variable selection for
proportional hazards models. Canadian Journal of Statistics, 27, 701–717.
[78] Iwaki, K. (1997). Posterior Expected Marginal Likelihood for Testing Hypotheses. Journal of
Economics, Asia University, 21, 105–134.
[79] Jeffreys, H. (1961). Theory of Probability. London: Oxford University Press.
[80] Jefferys, W. H. and Berger, J. O. (1992). Ockham’s razor and Bayesian analysis. American
Scientist, 80, 64–72.
[81] Johnstone, I. M. and Silverman, B. W. (2004). Needles and hay in haystacks: empirical Bayes
estimates of possibly sparse sequences. Annals of Statistics, 32, 1594–1649.
[82] Johnstone,I.M.andSilverman,B.W.(2005).EmpiricalBayesselectionofwaveletthresholds.
Annals of Statistics, 33, 1700–1752.
[83] Kadane, J. B. (1980). Predictive and Structural Methods for Eliciting Prior Distributions. In
Studies in Bayesian Econometrics and Statistics in Honor of Harold Jeffreys (A. Zellner, Eds.),
89–93. North Holland Publishing Company.
[84] Kass, R. E. and Raftery, A. (1995). Bayes factors. Journal of the American Statistical Association,
90, 773–795.
[85] Kass, R. E. and Vaidyanathan, S. K. (1992). Approximate Bayes Factors and Orthogonal
Parameters, with Application to Testing Equality of Two Binomial Proportions. Journal of
the Royal Statistical Society, 54, 129–144.

392
M. J. Bayarri and J. O. Berger
[86] Kass, R. E. and Wasserman, L. (1995). A Reference Bayesian Test for Nested Hypotheses
and Its Relationship to the Schwarz Criterion. Journal of the American Statistical Association,
90, 928–934.
[87] Key, J. T., Pericchi, L. R. and Smith, A. F. M. (1999). Bayesian Model Choice: What and
Why? Bayesian Statistics 6 (J. M. Bernardo, J. O. Berger, A. P. Dawid, and A. F. M. Smith,
eds.), pp. 343–370. Oxford University Press.
[88] Kiefer, J. (1977). Conditional confidence statements and confidence estimators (with dis-
cussion). Journal of the American Statistical Association, 72, 789–827.
[89] Ley, E. and Steel, M. F. J. (2009). On the effect of prior assumptions in Bayesian model aver-
aging with applications to growth regression. Journal of Applied Econometrics, 24, 651–674.
Wiley Online InterScience. DOI: 10.1002/jae.1057.
[90] Liang, F., Paulo, R., Molina, G., Clyde, M. A. and Berger, J. O. (2008). Mixtures of g Priors
for Bayesian Variable Selection. Journal of the American Statistical Association, 103, 410–423.
[91] Lindley, D. V. (1957). A statistical paradox. Biometrika, 44, 187–192.
[92] Lingham, R. and Sivaganesan, S. (1999). Intrinsic Bayes factor approach to a test for the
power law process. Journal of Statistical Planning and Inference, 77, 195–220.
[93] Marin, J. M. and Robert, C. P. (2007). Bayesian Core: A Practical Approach to Computational
Bayesian Statistics. New York: Springer.
[94] Maruyama, Y. and George, E. I. (2011). A fully Bayes factor with a generalized g-prior. Annals
of Statistics, 5, 2740–2765.
[95] Maruyama, Y. and Strawderman, W. E. (2011). Robust Bayesian variable selection with
sub-harmonic priors. Technical report, Center for Spatial Information Science, University
of Tokyo. arXiv:1009.1926v2 [stat.ME].
[96] McDonald, G. C., Vance, L. C. and Gibbons, D. I. (1995). Some tests for discriminating
between lognormal and Weibull distributions – an application to emission data. In Recent
Advances in Life Testing and Reliability (N. Balakrishnan, ed.), pp. 475–490 (Chapter 25),
CRC Press. Inc. (Boca Raton).
[97] Moreno, E., Bertolino, F. and Racugno, W. (1998). An intrinsic limiting procedure for model
selectionandhypothesistesting.JournaloftheAmericanStatisticalAssociation,93,1451–1460.
[98] Moreno, E., Bertolino, F. and Racugno, W. (1999). Default Bayesian analysis of the
Behrens–Fisher problem. Journal of Statistical Planning and Inference, 81, 323–333.
[99] Moreno, E., Giron, F. J. and Casella, G. (2010). Consistency of objective Bayes factors as the
model dimension grows. Annals of Statistics, 38, 1937–1952.
[100] Neal,R.(2001).Transferringpriorinformationbetweenmodelsusingimaginarydata.Tech-
nical Report 0108, Dept. Statistics, University of Toronto.
[101] O’Hagan, A. (1995). Fractional Bayes factors for model comparisons. Journal of the Royal
Statistical Society, Ser. B, 57, 99–138.
[102] O’Hagan, A. (1997). Properties of intrinsic and fractional Bayes factors. Test, 6, 101–118.
[103] Pauler, D. (1998). The Schwarz Criterion and Related Methods for Normal Linear Models.
Biometrika, 85, 13–27.
[104] Paulo, R. et al. (2002). Notes on model selection for the normal multiple regression model.
Model selection group of the 2002 stochastic computation SAMSI Program. SAMSI.
[105] Pérez,J.M.andBerger,J.(2001).Analysisofmixturemodelsusingexpectedposteriorpriors,
with application to classification of gamma ray bursts. In Bayesian Methods, with applications
to science, policy and official statistics (E. George and P. Nanopoulos, eds.), 401–410. Official
Publications of the European Communities, Luxembourg.
[106] Pérez,J.M.andBerger,J.(2002).Expectedposteriorpriordistributionsformodelselection.
Biometrika, 89, 491–512.
[107] Raftery, A. E. (1999). Bayes factors and BIC–Comment on “A critique of the Bayesian
information criterion for model selection”. Sociological Methods and Research, 27, 411–427.

Hypothesis testing and model uncertainty
393
[108] Raftery, A. E., Madigan, D. and Hoeting, J. A. (1997). Bayesian model averaging for regres-
sion models. Journal of the American Statistical Association, 92, 179–191.
[109] Raftery, A. E., Newton, M. A., Satagopan, J. and Krivitsky, P. (2007). Estimating the
integrated likelihood via posterior simulation using the harmonic mean identity (with dis-
cussion), Bayesian Statistics 8 (J. M. Bernardo, M. J. Bayarri, J. O. Berger, A. P. Dawid,
D. Heckerman, A. F. M. Smith, and M. West, eds.), pp. 1–45. Oxford University Press.
[110] Robert, C. P. (2007). The Bayesian Choice: From Decision-Theoretic Foundations to Computa-
tional Implementation. Springer Texts in Statistics.
[111] Robins, J. M., van der Vaart, A. W. and Ventura, V. (2000). The asymptotic distribution
of p-values in composite null models [with discussion]. Journal of the American Statistical
Association, 95, 1143–1172.
[112] Rubin, D. B. (1984). Bayesianly Justifiable and Relevant Frequency Calculations for the
Applied Statistician. The Annals of Statistics, 12, 1151–1172.
[113] Rue, H., Martino, S. and Chopin, N. (2009). Approximate Bayesian inference for latent
Gaussian models by using integrated nested Laplace approximations. Journal of the Royal
Statistical Society B, 71, 319–392.
[114] Sabanés Bové, D. and Held, L. (2011). Hyper-g priors for generalized linear models. Bayesian
Analysis, 6, 1–24.
[115] Sansó, B., Pericchi, L. R. and Moreno, E. (1996). On the Robustness of the Intrinsic Bayes
Factor for Nested Models. In Bayesian Robustness Volume 29 (J. Berger, F. Ruggeri, and
L. Wasserman, eds.), pp. 157–176. Hayward: IMS Lecture Notes – Monograph series.
[116] Schluter, P. J., Deely, J. J. and Nicholson, A. J. (1999). The averaged Bayes factor: a
new method for selecting between competing models. Technical Report, University of
Canterbury.
[117] Schwarz, G. (1978). Estimating the dimension of a model. Annals of Statistics, 6, 461–464.
[118] Scott, J. and Berger, J. (2005). An exploration of aspects of Bayesian multiple testing. Journal
of Statistical Planning and Inference, 136, 2144–2162.
[119] Scott, J. and Berger, J. (2010). Bayes and Empirical-Bayes multiplicity adjustment in the
variable-selection problem. Annals of Statistics, 38, 2587–2619.
[120] Sellke, T., Bayarri, M. J. and Berger, J. (2001). Calibration of p-values for testing precise null
hypotheses. The American Statistician, 55, 62–71.
[121] Shyamalkumar,D.N.(1996).CyclicI0 projectionsanditsapplicationsinStatistics.Technical
Report 96-24, Purdue University, Department of Statistics.
[122] Sivia,D.S.andSkilling,J.(2006).DataAnalysis:ABayesianTutorial,SecondEdition.Oxford
University Press.
[123] Skilling, J. (2006). Nested Sampling for General Bayesian Computation. Bayesian Analysis
1, pp. 833–860.
[124] Smith,M.and Kohn,R.(1996).Nonparametricregression usingBayesian variableselection.
Journal of Econometrics, 75, 317–344.
[125] Smith, A. F. M. and Spiegelhalter, D. J. (1980). Bayes Factors and Choice Criteria for Linear
Models. Journal of the Royal Statistical Society Ser. B, 42, 213–220.
[126] Spiegelhalter, D. J. and Smith, A. F. M. (1982). Bayes Factors for Linear and Log-Linear
Models with Vague Prior Information. Journal of the Royal Statistical Society, Ser. B, 44,
377–387.
[127] Spiegelhalter, D. J., Best, N. J., Carlin, B. P. and van der Linde, A. (2002). Bayesian measures
of model complexity and fit (with discussion). Journal of the Royal Statistical Society B, 64,
583–639.
[128] Tokdar, S. T., Chakrabarti, A. and Ghosh, J. K. (2010). Bayesian nonparametric goodness of
fit. In Frontier of Statistical Decision Making and Bayesian Analysis (M. H. Chen, D. K. Dey,
P. Muller, D. Sun and K. Ye, eds.), 185–193.

394
M. J. Bayarri and J. O. Berger
[129] Varshavsky, J. A. (1996). Intrinsic Bayes factors for model selection with autoregressive data.
In Bayesian Statistics 5 (J. M. Bernardo, J. O. Berger, A. P. Dawid, and A. F. M. Smith, eds.),
pp. 757–763. London: Oxford University Press.
[130] Verdinelli, I. and Wasserman, L. (1996). Bayes Factors, Nuisance Parameters, and Imprecise
Tests. In Bayesian Statistics 5 (J. M. Bernardo, J. O. Berger, A. P. Dawid, and A. F. M. Smith,
eds.), pp. 765–771. London: Oxford University Press.
[131] Wang, X. and George, E. I. (2007). Adaptive Bayesian criteria in variable selection for gen-
eralized linear models. Statistica Sinica, 17, 667–690.
[132] Wilson, M. A., Iversen, E. S., Clyde, M. A., Schmidler, S. C. and Schildkraut, J. M. (2010).
Bayesian model search and multilevel inference for SNP association studies. Annals of
Applied Statistics, 4, 1342–1364.
[133] Zak-Szatkowska, M. and Bogdan, M. (2011). Modified versions of Bayesian Information
Criterion for sparse Generalized Linear Models. Computational Statistics and Data Analysis,
55, 2908–2924.
[134] Zellner, A. (1986). On Assessing Prior Distributions and Bayesian Regression Analysis with
g-prior Distributions. In A. Zellner, ed., Bayesian Inference and Decision Techniques: Essays in
Honor of Bruno de Finetti, pp. 389–399. Edward Elgar Publishing Limited.
[135] Zellner, A. and Siow, A. (1980). Posterior odds for selected regression hypotheses. In
Bayesian Statistics (J. M. Bernardo, M. H. DeGroot, D. V. Lindley and A. F. M. Smith, eds.),
pp. 585–603. Valencia Univ. Press.
[136] Zhang, Z., Jordan, M. I. and Yeung, D. Y. (2009). Posterior consistency of the Silverman
g-prior in Bayesian model choice. In Proceedings of Advances in Neural Information Processing
Systems (NIPS) (Koller, D., Bengio, Y., Schuurmans, D., and Bottou, L., eds.), Volume 21,
1969–1976.

19
Proper and
non-informative
conjugate priors for
exponential family
models
e. gutiérrez-peña and m. mendoza
19.1 Introduction
E
xponential families constitute an important class of probability models that occur, in one form
oranother,aspartofmorecomplexmodelswidelyusedinappliedstatisticssuchasgeneralized
linear models, hierarchical models and dynamic models. Therefore, it is of some importance to
understand their properties. These families are related to the notion of sufficiency and can also
be motivated as a set of solutions to certain maximum entropy problems ([1],[20],[17]). On the
other hand, conjugate distributions play an important role in the Bayesian approach to parametric
inference. One of the main features of such families is that they are closed under sampling, but a
conjugate family often provides prior distributions which are tractable in various other respects.
Indeed, conjugate families for exponential family models are themselves exponential families so, in
particular, they can also be regarded as solutions to maximum entropy problems.
Maximum entropy (or, more generally, minimum relative entropy) is known to be closely related
to the decision theoretical problem of minimizing a worst-case expected loss (see [17] and the
references therein). Incidentally, Jeffreys’ prior can be shown to be asymptotically least favourable
under entropy risk [3]. In the context of exponential families, it is also noteworthy that, under
certain conditions, Jeffreys’ and other non-informative priors—including some forms of ‘unbi-
ased’ priors—can be obtained as suitable limits of conjugate distributions. Moreover, there exists
an interesting duality between unbiased estimators and optimal Bayes estimators that minimize
expected risk ([27]). The aim of this paper is to discuss these various concepts and to highlight
the relationship between them.
In the next section we briefly review some basic concepts concerning exponential families and
information theory. Section 19.3 discusses Bayesian inference for exponential families based both
on proper and certain non-informative, improper conjugate priors. In Section 19.4, we take a look
at more general versions of these latter priors and discuss an interesting unbiasedness property of

396
E. Gutiérrez-Peña and M. Mendoza
maximum likelihood estimators. Possible extensions of these and related results are also pointed
out. Finally, Section 19.5 contains some concluding remarks.
19.2 Preliminaries
19.2.1 Exponential families
We first review some basic results concerning natural exponential families. See [1] for a comprehen-
sive account of the properties of these models. Let η be a σ-finite positive measure on the Borel sets
of IRd, and consider the family F of probability measures whose density with respect to η is of the
form
p(x|θ) = b(x) exp{xtθ −M(θ)}
θ ∈%
for some function b(·), where M(θ) = log

b(x) exp{xtθ} η(dx) and % = int , with  = {θ ∈
IRd : M(θ) < +∞}. We assume that b(x) η(dx) is not concentrated on an affine subspace of IRd,
and that % is not empty. The family F is called a natural exponential family (with canonical
parameter θ) and is said to be regular if  is an open subset of IRd. In this paper we shall only
be concerned with regular natural exponential families. The function M(θ), called the cumulant
transform of F, is convex and infinitely differentiable.
Themappingμ = μ(θ) = ∂M(θ)/∂θ isone-to-oneanddifferentiable,withinverseθ = θ(μ),
and provides an alternative parameterization of F, called the mean parameterization since
μ = E(X|θ). The set  = μ(%) is termed the mean parameter space. The function
V(μ) = ∂2M{θ(μ)}
∂θ 2
μ ∈
is called the variance function of F. An important property of the variance function is that the pair
(V(·), ) characterizes F (see, for example, [26]).
The standard conjugate family for the natural exponential family F has densities (with respect
to the Lebesgue measure on the Borel sets of IRd) of the form
p(θ|x0, n0) = H(x0, n0) exp{n0xt
0 θ −n0M(θ)}
Some fundamental properties of this conjugate family are described by Diaconis and Ylvisaker
([5]). We shall refer to it as the DY-conjugate family.
19.2.2 Information theory and the minimum relative entropy
principle
We now discuss some fundamental concepts of information theory (for details, see [4]). The
entropyofarandomvariableX isdefinedbyH(X) = −

X p(x) log p(x)η(dx) = −Ep[log p(X)].
Intuitively, the entropy describes the uncertainty inherent in the distribution p(x). Thus, for
example, the entropy of a discrete distribution with finite support p(x) = px (px > 0, x =
1, 2, . . . , k; 
x px = 1) is maximized when p(x) is the uniform distribution, i.e. px = 1/k for all
x = 1, 2, . . . , k.Unfortunately,inthecontinuouscasetheentropy(knownasdifferentialentropyin
that case) does not share all the properties of the discrete version. The relative entropy (also known
as Kullback–Leibler divergence [22]) addresses this issue by introducing an invariant measure
q(x)η(dx) with respect to which the entropy is computed:

Proper and non-informative conjugate priors
397
DKL(p(·) || q(·)) =

p(x) log
p(x)
q(x)

η(dx)
The maximum entropy principle ([20]) states that, subject to precisely stated prior information
(usually in the form of moment constraints), the probability distribution that best represents the
currentstateofknowledgeaboutX istheonewiththelargestentropy.Forcontinuousdistributions,
the relative entropy is minimized instead, leading to the minimum relative entropy principle16 (also
known as the Principle of Minimum Discrimination Information, [22]).
Another important quantity in information theory is the mutual information between the ran-
dom variables X and Y:
I(X, Y) =
 
p(x, y) log
 p(x, y)
p(x)p(y)

η(dx)η(dy)
=

p(x)

p(y|x) log
p(y|x)
p(y)

η(dy)

η(dx)
=

p(x)

DKL(p(y|x) || p(y))

η(dx)
I(X, Y) describes the amount of information that the random variable Y carries about the random
variable X (and vice versa). It is a measure of the dependence between the two random variables X
and Y. From its definition, it is easy to see that I(X, Y) = I(Y, X) and that I(X, Y) = 0 if and only
if X and Y are independent. Another important property of I(X, Y) is that it is a concave functional
of p(x) for fixed p(y|x), and a convex functional of p(y|x) for fixed p(x) ([4]).
19.3 Bayesian parametric inference
From a Bayesian perspective, a problem of parametric inference is one where a phenomenon is
to be described through the observation of a random variable X whose distribution function is
completely specified up to the unknown value of a finite-dimensional parameter θ. Under such
circumstances, the initial state of knowledge is described through a joint probability model p(x, θ),
thus recognizing that uncertainty arises from two different sources: variability of X and lack of
information regarding θ. This joint probability may be represented either as
p(x, θ) = p(x|θ) p(θ)
or as
p(x, θ) = p(x) p(θ|x)
(19.1)
The first representation is the most common since then p(x|θ), the sampling model, describes the
uncertainty about the observable X for a fixed value of θ, whereas the prior, p(θ), describes the state
ofknowledgeregardingthevalueoftheparameter.Thus,asafirststeptowardssolvingtheinference
problem, an appropriate model p(x, θ) must be chosen. This selection is usually accomplished
sequentially: first the sampling model and then the prior distribution.
16 We note that [17] define the relative entropy as −DKL(p(·) || q(·)), so minimization of DKL can be stated
as the ‘maximum relative entropy principle’ in that case.

398
E. Gutiérrez-Peña and M. Mendoza
19.3.1 Sampling model
Following [2] (Section 4.5.4), let us assume that there exists a known measure b(x) which might be
regardedasafirstroughapproximationtothetruesamplingmodel,q(x).Assumealsothatthereare
some conditions which are not satisfied by b(x) but are useful to describe q(x). If these conditions
can be stated as moment constraints of the form

hi(x)q(x)dx = μi;
i = 1, . . . , k
where the hi(·) are known functions and the μi are given constants (i = 1, . . . , k), then the prob-
lem of selecting an appropriate sampling model (i.e. an approximation to the true model q(x))
may be posed as that of looking for a distribution, as close as possible to b(x), but satisfying the
above constraints. If, as a measure of closeness, we use the Kullback–Leibler divergence discussed
in Section 19.2, then the optimal model belongs to the exponential family
p(x|θ) = b(x) exp{h(x)tθ −M(θ)}
where θ is the k-dimensional canonical parameter and h(x) is the corresponding vector of sufficient
statistics. For the sake of simplicity, and without loss of generality, we can assume that the observa-
tion is the sufficient statistic so that the exponential family can be written in its natural form
p(x|θ) = b(x) exp{xtθ −M(θ)}
(19.2)
Thus, we may conclude that under a variety of conditions an exponential family may be used as an
optimal approximation to the sampling model.
Example. Suppose that a phenomenon will be observed, leading to a discrete random variable
taking values in X = {0, 1, 2, . . .}. If, as a first rough approximation, we take the counting measure
b(x) = 1/x! and use the first moment to describe the true sampling model, then the appropriate
constraint would be

x q(x) dx = μ
Minimization of the relative entropy then leads to the solution
p(x|θ) = 1
x! exp{xθ −exp(θ)}
(19.3)
which corresponds to a Poisson distribution. This is usually parameterized in terms of the mean
parameter μ = exp(θ).
19.3.2 Prior
19.3.2.1 Conjugate priors
Concerning the uncertainty about the parameter θ, it can be argued that, since θ can be thought of
as the limit of a sequence of observable quantities, some information about the observables may
be used to elicit a prior on θ. As before, we assume that this prior information can be roughly
approximated by means of a base measure B(θ). If additional prior information can be expressed in
terms of constraints regarding the expected value of the functions g1(θ) = θ and g2(θ) = −M(θ),

Proper and non-informative conjugate priors
399
then the optimal approximation to B(θ) satisfying the constraints is given by a member of the
exponential family
p(θ) ∝B(θ) exp{n0xt
0θ −n0M(θ)}
(19.4)
where ψ = (x0, n0)t is the canonical hyperparameter. This family is conjugate for the sampling
model (19.2). Conjugate families of priors have received a great deal of attention in the statistical
literature since their introduction by [28]. One of the main features of such a family is that it is
closed under sampling, in the sense that formal updating of a prior in the conjugate family via Bayes
theorem yields a posterior distribution which also belongs to that family. In fact, given a sample
x(n) = (x1, . . . , xn) from p(x|θ), the posterior distribution is given by
p(θ|x(n)) ∝B(θ) exp{(n¯x + n0x0)tθ −(n + n0)M(θ)}
Besides this property, conjugate families often provide prior distributions which are tractable in
at least two other respects: (i) for many exponential family likelihoods the normalizing constant
of the conjugate density is readily found; (ii) it is often possible to express in convenient form
the expectations (and, in some cases, higher-order moments) of some important functions of the
parameters ([12]).
It is worth noting that [5] discuss conditions that ensure that the conjugate density (19.4) defines
a proper distribution for θ (when the base measure B(θ) is taken as uniform). In Section 19.3.2.2 we
shall return to the choice of B(θ), specifically in the context of non-informative priors.
Example. (continued). In the case of the Poisson model (19.3), we have θ = log μ. Thus, the
corresponding constraints for the prior are

θp(θ)dθ = m1,

exp(θ)p(θ)dθ = m2
Equivalently, in terms of μ,

log μp(μ)dμ = m1,

μp(μ)dμ = m2
In this case (19.4) becomes
p(θ) ∝B(θ) exp{n0x0θ −n0 exp(θ)}
which, under the corresponding transformation, leads to
p(μ) ∝Bμ(μ)μs0 exp{−n0μ}
with s0 = n0x0.
It is clear that if we use, as a first approximation, the improper base measure Bμ(μ) = μ−1, then
we get the usual Gamma conjugate prior on μ. We note that, written in terms of θ, this measure is
B(θ) ∝1.
19.3.2.2 Some non-informative conjugate priors
In the context of Bayesian inference, the need often arises to specify a prior distribution such that,
even for moderate sample sizes, the information provided by the data dominates the prior because
of the ‘vague’ nature of the prior knowledge about the parameter. Here we explore the case where
the base measure B(θ) is chosen to be non-informative in some sense.

400
E. Gutiérrez-Peña and M. Mendoza
Uniformprior A(naive)prioroftenusedasnon-informativeistheuniformprior πL(θ) ∝1,also
known as the Laplace prior. If we use B(θ) = πL(θ) as the base measure we get
p(θ) ∝exp{n0xt
0 θ −n0M(θ)}
the DY-conjugate family. This family has a number of important properties. In particular, if we
reparameterize in terms of the mean parameter μ, it can be shown that
E(μ|x(n)) = n¯x + n0x0
n + n0
so the Bayes estimator under squared error loss is a linear function of the sample mean. Moreover,
ˆμ = E(μ|x(n)) is also the Bayes estimator under the Kullback–Leibler loss ([11]). This result is
particularly interesting since
E(μ|x(n)) = ¯x
when x0 = 0 and n0 = 0. The coincidence of the Bayes estimate with the usual frequentist unbi-
ased estimator for the mean in this limiting case, shows that the idea of choosing the equivalent
sample size (in the terminology of [28]) n0 = 0 to define a non-informative conjugate prior, is most
natural when the base measure is πL(θ).
Jeffreys’prior A widely used non-informative prior is that obtained through the so-called Jeffreys’
rule:πJ(θ) ∝iθ(θ)1/2,whereiθ(θ)denotestheFisherinformationforθ.IfwetakeB(θ) = πJ(θ)
we get
p(θ) ∝iθ(θ)1/2 exp{n0xt
0 θ −n0M(θ)}
(19.5)
which may be regarded as a restricted reference prior in the sense of [2]. There is an interesting
relationship between Jeffreys’ prior and the DY-conjugate family. A parametrization λ = λ(θ) is
said to be conjugate for θ (denoted λ ⌣θ), if the Jacobian Jλ(θ) = |∂λ(θ)/∂θ| is such that
Jλ(θ) ∝exp{kt
1 θ −k2M(θ)}
for some constants k1, k2 ([15]). In the case of the mean parameterization μ, we have Jμ(θ) =
iθ(θ). Provided that μ ⌣θ (a sufficient condition for this to hold is that the sampling distribution
be a natural exponential family having a quadratic variance function), it can be shown that (19.5)
becomes
p(θ) ∝exp

n0x0 + k1
2
t
θ −

n0 + k2
2

M(θ)

= exp

˜s t
0 θ −˜n0M(θ)

This is again a DY-conjugate prior. Thus, in this case Jeffreys’ prior can be seen as a limiting case
of the DY-conjugate prior as ˜s0 →k1/2 and ˜n0 →k2/2. Moreover, n0 retains its interpretation
as an equivalent sample size, only relative to the Jeffreys prior, so n0 = 0 can still be regarded as
non-informative in this sense ([16]).

Proper and non-informative conjugate priors
401
Unbiased priors The idea of looking for a prior leading to a posterior mean for μ which equals
the corresponding sufficient unbiased estimator, can be explored in more general settings. To
start with, μ is just one possible transformation of θ. Suppose that we are interested in another
parameterization, say λ, and that we want to use a non-informative prior for it. Specifically, if
there exists a sufficient unbiased estimator ˆλ(x(n)), we would like to choose a base measure B(θ)
such that the prior is non-informative for λ in the sense that the corresponding posterior satisfies
E(λ|x(n)) = ˆλ(x(n)).
The problem of finding these unbiased priors has been addressed by [18], [13], and [25]. For an
ample class of transformations λ = λ(θ) such that λ ⌣θ, if the sampling distribution belongs to
a natural exponential family with quadratic variance function then the required base measure B(θ)
exists and is given by
B(θ) = iθ(θ)|Jλ(θ)|−1
(19.6)
In this case,
p(θ) ∝exp

[n0x0 + (k1/2) −r1]t θ −[n0 + (k2/2) −r2] M(θ)

= exp

˘st
0 θ −˘n0M(θ)

where r1 and r2 are constants that depend on the specific choice of λ(·). It is interesting to note that
the base measure B(θ) in (19.6) can also be seen as a limiting case of the DY-conjugate family as
˘s0 →[(k1/2) −r1] and ˘n0 →[(k2/2) −r2]. Written in terms of λ, the prior induced by (19.6)
then takes the form πλ(λ) ∝iλ(λ).
This prior was originally proposed by Hartigan ([18]). Thus, we shall denote the unbiased priors
on θ and λ by
πH(θ) ∝iθ(θ)|Jλ(θ)|−1
and
πH(λ) ∝iλ(λ)
respectively.
This latter representation is particularly evocative since, when we express Jeffreys’ and Laplace
priors in terms of λ, we get
πJ(λ) ∝iλ(λ)1/2
and
πL(λ) ∝1
thus suggesting that different powers (between 0 and 1) of the Fisher information may be regarded
as non-informative in some sense.
As in the previous case, n0 retains its interpretation as an equivalent sample size, this time
relative to the unbiased prior πH(θ), so n0 = 0 can still be regarded as non-informative in the
sense that it yields an unbiased prior for λ. Unbiasedness of priors will be further discussed in
Section 19.4.

402
E. Gutiérrez-Peña and M. Mendoza
19.3.3 Hierarchical models
The sequential approach described at the beginning of this section to motivate the use of conjugate
priors for exponential families, can be carried on in order to specify models with more than two
levels. A structure of this kind is called a hierarchical model. A large amount of literature has
been devoted to the analysis of hierarchical models since their introduction by [10] and further
development by [24].
Inthisnewsettingwehavekconditionallyindependentrandomsamplessuchthat X(ni) isdrawn
from
p(x|θi) = b(x) exp{xtθi −M(θi)}
for i = 1, . . . , k. Thus, all sampling models have the same form but differ in the value of the corre-
sponding parameter θi. If each sample is processed separately, then we have k instances of the same
exponential conjugate structure discussed before. Alternatively, if a hierarchical model is adopted
then θ1, θ2, . . . , θk are assumed to be exchangeable (thus allowing for possible dependence among
the parameters) and a conditional parametric model p(θ|ψ) can be used to describe the variability
among these second level parameters. Following the ideas of the previous section, p(θ|ψ) can
be approximated by a member of an exponential conjugate family. Thus, θ1, θ2, . . . , θk may be
assumed to be i.i.d. according to the model
p(θ|ψ) ∝B(θ) exp{st
0θ −n0M(θ)}
In the hierarchical setting, a third level is defined by treating the canonical hyperparameter ψ =
(s0, n0)t as unknown and eliciting a prior distribution for it. This structure allows the computation
of a posterior for ψ which incorporates the information from all k samples. More importantly,
the corresponding posterior for θi also involves the information from X(nj) (j ̸= i) due to the
dependence among the second level parameters. This mechanism is known as borrowing strength.
Here, the relevant issue is that one more probability model p(ψ|ν) must be elicited. We can
recognize k
i=1 θi and k
i=1 M(θi) as the sufficient statistics for ψ, so the corresponding moment
constraintsmaybedefinedintermsofs0 andn0.Inthisway,theminimumrelativeentropyprinciple
leads to a conjugate exponential family
p(ψ|ν) ∝G(ψ) exp{ψtν}
with respect to a given approximating measure G(ψ).
In a hierarchical model such as this there are three sources of uncertainty: variability within each
sample X(ni), variability among the second level parameters θ1, . . . , θk, and lack of information
regarding the hyperparameter ψ. The joint model is then p(x(n1), . . . , x(nk), θ1, . . . , θk, ψ), which
is represented as
p(x(n1), . . . , x(nk)|θ1, . . . , θk) p(θ1, . . . , θk|ψ) p(ψ)
using
the
fact
that
{x(n1), . . . , x(nk)}
and
ψ
are
conditionally
independent
given
{θ1, . . . , θk}. Once the data become available, interest focuses on the posterior distribution
p(θ1, . . . , θk, ψ|x(n1), . . . , x(nk)) given by
p(θ1, . . . , θk|ψ, x(n1), . . . , x(nk)) p(ψ|x(n1), . . . , x(nk))

Proper and non-informative conjugate priors
403
or, alternatively
p(ψ|θ1, . . . , θk) p(θ1, . . . , θk|x(n1), . . . , x(nk))
From these expressions it is clear that, in both cases, the first factor is a conjugate posterior but the
second is a mixture of conditional conjugate posteriors which will not be conjugate in general. This
suggests that an alternative approach to conjugacy in hierarchical models might be to: first elicit
the second level distribution p(θ|ψ) as an exponential conjugate prior for the sampling model as
above; then, with this prior, calculate the predictive distribution p(x(n1), . . . , x(nk)|ψ) as

p(x(n1), . . . , x(nk)|θ1, . . . , θk) p(θ1, . . . , θk|ψ) dθ1 · · · dθk;
finally, choose p(ψ) to be conjugate for this predictive distribution. In the context discussed here,
however, this approach is not useful since the predictive will not generally result in an exponential
family.
Note that, even for those components of the posterior distribution which are conjugate (and
hence closed under sampling), simplification of the calculations involved in the prior–posterior
analysis is not guaranteed. This will be illustrated in the following example. In practice, most calcu-
lations for hierarchical models involve analytical and numerical approximations. For example, [21]
are concerned with Laplace approximations to posterior moments, whereas [7] and [8] discuss the
application of MCMC methods in this context. It is worth noting that the Gibbs sampler is partic-
ularly suitable in this case. Another potentially relevant contribution is [6], where it is shown that,
for certain classes of exponential families, Laplace approximations to marginal posterior densities
are exact up to a proportional constant. Moreover, in practice it is often the case that, even when the
Laplace approximation to a marginal density cannot be shown analytically to be exact, it provides a
remarkably accurate approximation. Hence, Laplace approximations to marginal densities may still
prove useful in the analysis of some hierarchical models.
Example. (continued).Wenowassumethatwehaveasetofk(conditionallyindependent)random
samples such that X(ni) is drawn from a Poisson sampling model
p(x|μi) = 1
x!μx
i exp{−μi}
For the second level, let θ1, θ2, . . . , θk be i.i.d. according to the Gamma distribution
p(μ|ψ) =
βα
(α)μα−1 exp{−βμ}
where ψ = (α, β)t. If, for the third level, we approximate the corresponding prior starting from
an initial base measure G(ψ) with constraints on the expected values of α and β, we get the
exponential conjugate family
p(ψ|μ0) ∝G(ψ)
 βα
(α)
k0
μα−1
0
exp{−βμ0}
(19.7)
Analytic calculations with the posterior corresponding to (19.7) are no longer possible in this case.
Even for the conjugate likelihood prior discussed by [7], we can proceed with the conditional
distribution for β (given α), which turns out to be Gamma, but the marginal distribution for α

404
E. Gutiérrez-Peña and M. Mendoza
is analytically intractable. Thus, we still have a family of distributions for ψ which is closed under
sampling (of the θs) but we do not obtain any advantage for analytic calculations.
We close this section by recalling that hierarchical models provide a simple way of describing the
relationship among the parameters of the second level. It must be pointed out, however, that since
we specify the prior through the components p(θ1, . . . , θk|ψ) and p(ψ), this dependence is only
implicitly defined and described by
p(θ1, . . . , θk) =

p(θ1, . . . , θk|ψ)p(ψ)dψ
where the conditional density p(θ1, . . . , θk|ψ) is given by 	k
i=1 p(θi|ψ). Thus, dependence
among θ1, . . . , θk is generated by a mixture of these ‘independent’ priors using p(ψ) as the weight
function. Moreover, the posterior
p(θ1, . . . , θk|x(n1), . . . , x(nk)) ∝p(x(n1), . . . , x(nk)|θ1, . . . , θk)p(θ1, . . . , θk)
will
always
keep
the
same
(prior)
source
for
its
dependence
structure
since
p(x(n1), . . . , x(nk)|θ1, . . . , θk) is given by the product 	k
i=1 p(x(ni)|θi) which implies
independence among the second level parameters.
19.4 Unbiasedness
19.4.1 A general definition of unbiasedness
In Section 19.3.2.2 we discussed the case where some Bayes estimators ˆλ = ˆλ(x(n)) turned out to be
unbiased for certain functions λ = λ(θ) of the canonical parameter, in the sense that E(ˆλ|λ) = λ.
This definition of unbiasedness is related to the squared error loss L2
λ(ˆλ, λ) ≡(ˆλ −λ)2, as is the
Bayes estimator ˆλ = E(λ|x(n)), i.e. the posterior expectation of λ.
[23] proposed a generalization of this notion of unbiasedness which takes into account the loss
function being used. For a general loss functionL(ˆλ, λ), we shall say that the estimator ˆλ = ˆλ(x(n))
is L-unbiased for the parameter λ if
E(L(ˆλ(X(n)), λ)|λ) ≤E(L(ˆλ(X(n)), λ′)|λ)
for all λ, λ′ ∈#. Similarly, we shall say that the estimator ˆλ is (L, p)-Bayes (for a loss function L and
a prior p) if it minimizes the corresponding posterior expected loss

L(ˆλ, λ) p(λ|x(n)) dλ
Using this general definition of unbiasedness, [18] showed that the prior which minimizes the
asymptotic bias of the Bayes estimator relative to the loss function L(ˆλ, λ) is given by
πH(λ) ∝E
∂log p(X(n)|λ)
∂λ
2&&&&& λ
 1∂2L(λ, ω)
∂ω2
2−1/2
ω=λ
= iλ(λ)
1∂2L(λ, ω)
∂ω2
2−1/2
ω=λ

Proper and non-informative conjugate priors
405
For the squared error loss, L2
λ(ˆλ, λ), this becomes
πH(λ) ∝iλ(λ)
(19.8)
[18]alsoshowedthat,forexponentialfamilymodelsandsquarederrorlosswithrespecttothemean
parameter (i.e. L2μ( ˆμ, μ) = ( ˆμ −μ)2), the unbiasedness of πμ(μ) ∝iμ(μ) is exact. This prior
can be written as
πμ(μ) ∝
1
V(μ)
while in terms of the canonical parameter it becomes
πθ(θ) ∝1
Hence, the (L2μ, πμ)-Bayes estimator ˆμ = E(μ|x(n)) is L2μ-unbiased and the corresponding unbi-
ased prior is πμ. As noted in Section 19.3.2.2, (19.8) also attains exact posterior unbiasedness (in the
usual L2
λ-sense) for certain other parameterizations λ = λ(θ).
19.4.2 Relative entropy loss
For an arbitrary parameterization λ, let
LK(ˆλ, λ) = DKL(p(x|λ) || p(x|ˆλ))
denote the relative entropy (Kullback–Leibler) loss, and let
LK∗(ˆλ, λ) = DKL(p(x|ˆλ) || p(x|λ))
denote the corresponding dual loss. Note that, unlike the squared error loss L2
λ, both of these loss
functions are invariant under reparameterizations of the model and so we may drop the subscript λ
from their notation.
With this notation, and as pointed out in Section 19.3.2.2, ˆμ = E(μ|x(n)) is not only
(L2μ, πμ)-Bayes but also (LK, πμ)-Bayes. Therefore, for the mean parameter of an exponential family,
the (LK, πμ)-Bayes estimator is L2μ-unbiased.
A partial dual result holds for the canonical parameter θ. In this case, the (LK∗, πθ)-Bayes esti-
mator is ˆθ = E(θ|x(n)), which is also the (L2
θ, πθ)-Bayes estimator of θ. Thus, if ˆθ happens to be
unbiased in the usual sense,17 then we have that, for the canonical parameter of an exponential family,
the (LK∗, πθ)-Bayes estimator is L2
θ-unbiased.
On the other hand, it is interesting that the (LK, πθ)-Bayes estimator of θ is its posterior mode
which, since πθ(θ) ∝1, coincides with the maximum likelihood estimator (see [11]). In other
words, πθ(θ) ∝1 is a ‘maximum likelihood prior’ as defined by [19].
Unlike (L2, p)-Bayes estimators, both (LK, p)- and (LK∗, p)-Bayes estimators are invariant
under reparameterizations of the model. In a recent paper, [29] discuss a decomposition of the
Kullback–Leibler risk which is analogous to the decomposition of the mean squared error into vari-
ance and (squared) bias.18 More specifically, they introduce a general framework under which the
17 Note that, under regularity conditions, ˆμ is always unbiased in the usual sense. See [5] and Section 19.3.2.2.
18 Unlike us, [29] refer to LK∗as the Kullback–Leibler divergence and to LK as the dual Kullback–Leibler
divergence.

406
E. Gutiérrez-Peña and M. Mendoza
distribution that generates the data (and not just the mean or some other parameter) is estimated.
Therefore, they define estimates to be probability distributions so that the analogues of bias and
variance are parameter-free. Such estimates are compared using the Kullback–Leibler divergence
as the loss function. They point out that the maximum likelihood estimator is parameter invariant
and so is naturally described by a distribution.
In the case of exponential families, they show that the maximum likelihood estimator is
LK∗-unbiased (regardless of the parameterization). We can rephrase this result to say that, for expo-
nential families, the (LK, π)-Bayes estimator is LK∗-unbiased, so it is unbiased in a dual sense. Here π
is the prior induced by the uniform prior on the canonical parameter θ. It follows from the results
mentioned at the begining of this subsection that, under regularity conditions, the LK∗-unbiased
estimator for an arbitrary (one-to-one, continuous) transformation λ = λ(μ) of the mean param-
eter always exists and can be obtained by correspondingly transforming the usual L2μ-unbiased
estimator ˆμ = E(μ|x(n)),i.e. ˆλ = λ( ˆμ),whichinthiscasecoincideswiththemaximumlikelihood
estimator. However, such ˆλ is not necessarily unbiased in the usual L2
λ-sense.
A partial dual result can be obtained for the canonical parameter. Using results from [29], it can
be shown that an estimator is LK-unbiased for θ if it is L2
θ-unbiased. Recall that the (LK∗, π)-Bayes
estimator is ˆθ = E(θ|x(n)). Thus, if ˆθ happens to be unbiased in the usual sense, then we have that the
(LK∗, π)-BayesestimatorisLK-unbiased.Underthesecircumstances,theLK-unbiasedestimatorfor
an arbitrary (one-to-one, continuous) transformation λ = λ(θ) of the canonical parameter can be
obtained by correspondingly transforming the usual L2
θ-unbiased estimator ˆθ, i.e. ˆλ = λ( ˆθ). As
before, such ˆλ is not necessarily unbiased in the usual L2
λ-sense.
19.4.3 Extensions
[27] further extend Lehmann’s definition of unbiasedness to take into account, besides a general
lossfunction,thepriordistributionoftheparameter.Theynoteaninterestingdualitybetweentheir
definition of unbiased estimator and the usual definition of Bayes estimator given the same loss and
prior. It would be interesting to explore this duality in the context of exponential families, both with
respect to relative entropy loss and with respect to more general loss functions.
On the other hand, [17] found a close relationship between maximizing entropy and minimiz-
ing worst-case expected loss. They generalized this result to arbitrary decision problems and loss
functions. This, in turn, allowed them to define generalized versions of entropy, divergence and
exponential families. As an interesting particular case, mutual information I(X, ) can be regarded
as a generalized entropy based on the loss function
LK∗( ˆθ, θ) = DKL(p(x| ˆθ) || p(x|θ))
Recall the representation (19.1) and consider the distribution p(x). It is shown in [14] that, for a
certain class of distributions p(x), minimization of I(X, ) with respect to p(θ|x), subject to the
constraint
 
p(x)p(θ|x)L( ˆθ(x), θ)η(dx)dθ ≤l
leads to the conjugate posterior
p(θ|x) ∝exp{(n¯x + n0x0)tθ −(n + n0)M(θ)}
From this, we can derive the corresponding sampling model p(x|θ) and prior density p(θ).

Proper and non-informative conjugate priors
407
Conversely, [3] have shown that fixing p(x|θ) and (asymptotically) maximizing I(X, ) with
respect to p(θ), yields a Jeffreys prior.
19.5 Concluding remarks
Exponential families and maximization of entropy, subject to certain moment constraints, are
closely related. Choosing appropriately such constraints on the canonical parameter leads to conju-
gacy. On the other hand, there exists a duality between maximization of entropy and minimization
ofworst-caseexpectedloss.Thisrelationshipallowsexponentialfamiliestobeinterpretedasrobust
Bayes acts against a class of distributions defined by mean-value constraints ([17]).
We have shown how several non-informative priors can be obtained as limiting cases of the
DY-conjugate prior. A particular case is that where the posterior expected value of a parameter λ
coincides with the corresponding unbiased estimator ˆλ. Another interesting duality holds between
the classical notion of unbiasedness and minimization of expected squared error loss. We have seen
that this result can be extended to account for more general loss functions. Further generalizations,
usingthetheorydevelopedbyGrünwaldandDawid[17],mayalsobepossible.Specifically,itwould
be interesting to explore the existence or conjugate priors for generalized exponential families
derived from general discrepancies, as well as the corresponding definition of unbiasedness and
its relationship to the resulting Bayes estimators. Finally, the existence of unbiased conjugate priors
may also be of interest.
Acknowledgements
I would like to express my most sincere gratitude to Adrian, not only for his guidance, constructive
criticismandopennessduringthecourseofmyPhDstudies,butalsobecausehehasbeenaconstant
source of inspiration throughout my career. (EGP)
This work was supported by Sistema Nacional de Investigadores, Mexico. The second author
also wishes to acknowledge support from Asociación Mexicana de Cultura, A.C.
References
[1] Barndorff-Nielsen, O. (1978). Information and Exponential Families in Statistical Theory.
Chichester: Wiley.
[2] Bernardo, J. M. and Smith, A. F. M. (2000). Bayesian Theory. Chichester: Wiley.
[3] Clarke, B. S. and Barron, A. R. (1994). Jeffreys’ prior is asymptotically least favorable under
entropy risk. Jounal of Statistical Planning and Inference, 41, 37–60.
[4] Cover, T. M. and Thomas, J. A. (1991). Elements of Information Theory. New York: Wiley.
[5] Diaconis, P. and Ylvisaker, D. (1979). Conjugate priors for exponential exponential families.
Annals of Statistics, 7, 269–281.
[6] Efstathiou, M., Gutiérrez-Peña, E. and Smith, A. F. M. (1998). Laplace Approximations for
natural exponential families with cuts. Scandinavian Journal of Statistics, 25, 77–92.
[7] George, E., Makov, U. and Smith, A. F. M. (1993). Conjugate likelihood distributions. Scandi-
navian Journal of Statistics, 26, 509–517.
[8] George,E.,Makov,U.andSmith,A.F.M.(1994).BayesianHierarchicalAnalysisforexponen-
tialfamiliesviaMarkovChainMonteCarlo.InAspectsofUncertainty:aTributetoD. V. Lindley
(P. R. Freeman and A. F. M. Smith, eds.). Chichester: Wiley.

408
E. Gutiérrez-Peña and M. Mendoza
[9] Goel, P. K. and DeGroot, M. H. (1981). Information about hyperparameters in hierarchical
models. Journal of the American Statistical Association, 76, 140–147.
[10] Good, I. J. (1965). The Estimation of Probabilities. An Essay on Modern Bayesian Methods.
Cambridge: MIT Press.
[11] Gutiérrez-Peña,E.(1992).Expectedlogarithmicdivergenceforexponentialfamilies.Bayesian
Statistics 4 (J. M. Bernardo, J. O. Berger, A. P. Dawid, A. F. M. Smith, eds.). Oxford: Oxford
University Press, pp. 669–674.
[12] Gutiérrez-Peña, E. (1997). Moments for the canonical parameter of an exponential family
under a conjugate distribution. Biometrika, 84, 727–732.
[13] Gutiérrez-Peña, E. and Mendoza, M. (1999). A note on Bayes estimates for exponential fam-
ilies. Revista de la Real Academia de Ciencias Exactas, Físicas y Naturales (España), 93, 351–356.
[14] Gutiérrez-Peña, E. and Muliere, P. (2004). Conjugate priors represent strong pre-experimen-
tal assumptions. Scandinavian Journal of Statistics, 31, 235–246.
[15] Gutiérrez-Peña, E. and Smith, A. F. M. (1995). Conjugate parameterizations for natural expo-
nential families. Journal of the American Statistical Association, 90, 1347–1356.
[16] Gutiérrez-Peña, E. and Smith, A. F. M. (1997). Exponential and Bayesian conjugate families:
Review and extensions. Test, 6, 1–90 (with discussion).
[17] Grünwald, P. D. and Dawid, A. P. (2004). Game theory, maximum entropy, minimum dis-
crepancy and robust Bayesian decision theory. Annals of Statistics, 32, 1367–1433.
[18] Hartigan, J. (1965). The asymptotically unbiased prior distribution. Annals of Mathematical
Statistics, 36, 1137–1152.
[19] Hartigan, J. (1998). The maximum likelihood prior. Annals of Statistics, 26, 2083–2103.
[20] Jaynes,E.T.(1989).PapersonProbability,StatisticsandStatisticalPhysics(2nded.).Dordrecht:
Kluwer Academic.
[21] Kass, R. E. and Steffey, D. (1989). Approximate Bayesian inference in conditionally inde-
pendent hierarchical models. (parametric empirical Bayes models). Journal of the American
Statistical Association, 84, 717–726.
[22] Kullback, S. (1959). Information Theory and Statistics. New York: Wiley.
[23] Lehmann, E. L. (1951). A general concept of unbiasedness. The Annals of Mathematical Statis-
tics, 22, 587–592.
[24] Lindley, D. V. and Smith, A. F. M. (1972). Bayesian estimates for the linear model. Journal of
the Royal Statistical Society B, 34, 1–41 (with discussion).
[25] Meng,X.-L.andZaslavsky,A.M.(2002).Observationunbiasedpriors. Annals of Statistics,30,
1345–1375.
[26] Morris, C. N. (1982). Natural exponential families with quadratic variance functions. Annals
of Statistics, 10, 65–80.
[27] Noorbaloochi, S. and Meeden, G. (1983). Unbiasedness as the dual of being Bayes. Journal of
the American Statistical Association, 78, 619–623.
[28] Raiffa, H. and Schlaifer, R. (1961). Applied Statistical Decision Theory. Boston: Harvard
University.
[29] Wu, Q. and Vos, P. (2012). Decomposition of Kullback–Leibler risk and unbiasedness for
parameter free estimators. Journal of Statistical Planning and Inference, 142, 1525–1536.

20
Bayesian model
specification: heuristics
and examples
david draper
20.1 Introduction
Y
ou(apersonwishingtoreasonsensiblyinthefaceofuncertainty:[12])areabouttobeginwork
onanewscientificproblemP.Youbeginbyidentifyingθ,theunknownaspectofPofprincipal
interest; in the story I wish to tell here, θ could be just about anything (e.g., a map precisely locating
thehighestandlowestpointsonthesurfaceofanewly-discoveredEarth-likeextra-solarplanet),but
(forconcreteness)thinkofθ = (θ1, . . . , θk)asavectorinℜk (allfinite-dimensionalunknownscan
be expressed in this way). You take stock of Your resources and realize that it’s possible to obtain a
new dataset D to decrease Your uncertainty about θ; again, D could be just about anything (e.g., a
surveillance-camera video record of a crime, offering a partial identification of the perpetrator), but
(again, for concreteness) think of D = (y1, . . . , yn) as a vector in ℜn (all datasets can be expressed
in this way). Your other source of information relevant to solving P is a set B of (true/false)
propositions, all regarded by You as true, describing the scientific context of P and the nature of
the data-gathering process. (An example of a proposition in B from (e.g.) the field of history is as
follows: {(y1, . . . , yn) is a random sample of size n from the population P of all words in essay 19 of
the Federalist Papers} [20], with θ as the unknown author of the essay (among Alexander Hamilton,
James Madison, and John Jay).) At design time (i.e., when You’re still contemplating how to obtain
D), You notice that the existence of D at analysis time (i.e., after D has arrived) partitions the
overall information about θ into {information internal to D} and {information external to D}, and
this means that (at analysis time) You’ll face a fundamental question: how should the information
about θ both internal and external to D be combined, to create an optimal summary of Your total
information (and therefore an accurate audit of Your uncertainty) about θ?
Here’s a simple but real example, to fix ideas. In 1962 and 1963 [11], two employees of the
US National Bureau of Standards (now called the National Institute of Standards and Technology)
maden = 100weighingsofablockofmetalcalledNB10—giventhisnamebecauseitwassupposed
to weigh 10 grams—under conditions that were as close as humanly possible to the statistical ideal
of independent, identically distributed (IID) sampling from the population PNB10 = {all possible
weighings of NB10 with the given apparatus}. Calling this problem PNB10, here θ is evidently the
‘true’ weight of NB10, by which I mean the average of all the potential data values in PNB10; D con-
sistsofthe100weighingsy = (y1, . . . , yn);andB containstheproposition{yisanIIDsamplefrom

410
D. Draper
PNB10} (along with background propositions known to be true from the context of PNB10, such as
{θ > 0} and {θ is close to 10 grams}). In this problem the same fundamental question looms: how
can an optimal summary of the total information about the weight of NB10 be constructed?
The Bayesian approach to answering this inferential question, and to making predictions of future
data D∗and decisions in the face of uncertainty, has been settled from a foundational perspective
by de Finetti [2] and RT Cox [1]. Each of them proved a theorem, from different points of view
aboutthemeaningofprobability:fordeFinetti,probabilitiesarisefrombetting,andforCoxthey’re
numerical expressions of information, in both cases about the truth status of propositions whose
truth is unknown to You. The theorem says that if You specify two ingredients for inference and
prediction—a probability distribution p(D|θ B) (usually referred to as Your sampling distribution)
quantifying Your information about θ internal to D, and a probability distribution p(θ|B) (usually
referred to as Your prior distribution) quantifying Your information about θ external to D—and two
additional ingredients for decision-making—a set A of possible actions (usually referred to as Your
action space) and a real-valued utility function U(a, θ∗) trading off the costs and benefits that will
ariseif Youchooseactionaandθ takesthevalueθ∗—then(toobtainlogically-internally-consistent
inferences, predictions and decisions) You must combine the four ingredients according to the
following three equations:
p(θ|D B) ∝p(θ|B) p(D|θ B),
(20.1)
p(D∗|D B) =


p(D∗|θ D B) p(θ|D B) dθ,
(20.2)
a∗= argmax
a∈A
E(θ|D B) U(a, θ) = argmax
a∈A


U(a, θ) p(θ|D B) dθ.
(20.3)
Here  is the set of possible values of θ; p(θ|D B) (usually referred to as Your posterior distribution)
summarizes Your total information about θ and solves the inference problem; p(D∗|D B), Your
(posterior) predictive distribution for future data D∗, solves the prediction problem; and a∗solves
the decision problem by maximizing expected utility (where the expectation is over Your posterior
distribution p(θ|D B)).
Thisisexcellent,asfarasitgoes,buttheoriginalfundamentalquestionhasnowbeenreplacedby
a new task that’s almost as fundamental: how do You optimally specify the four ingredients {prior
distribution, sampling distribution, action space, utility function} to be used in the three equations
(20.1–20.3)? This task is Bayesian model specification, construed broadly. Sometimes this phrase
is used more narrowly, to apply just to the sampling distribution, or just to {prior distribution,
sampling distribution} if inference and/or prediction are the only goals. In the NB10 problem, for
instance, although there may be a subsequent decision with action space {replace NB10 (because it
doesn’t actually weigh 10 grams), keep it}, I’ll focus here on the inferential issue of the ‘true’ weight
θ of NB10; in this problem let’s call M = {p(θ|B), p(D|θ B)} Your model for (Your uncertainty
about) θ.
To make the last paragraph meaningful I need to say what I mean by optimal Bayesian model
specification, and this in turn depends on the following two-step argument:
• All Bayesian reasoning under uncertainty is based on P(A|B) = P(A B)
P(B) for propositions A
and B, and this is undefined if B is false; therefore
• Rule 1: You should try hard not to condition on propositions (a) that You know to be false
and (b) that may be false.
This motivates the following terminology: in model specification, optimal = {to come as close as
possible to the goal of [conditioning only on propositions rendered true by the context of the

Bayesian model specification
411
problem and the design of the data-gathering process, while at the same time ensuring that the set
of conditioning propositions includes all relevant problem context]}.
Achieving this goal seems hard; for example, a popular method of Bayesian model specification
involves looking at the data to specify p(D|θ B)—for example, with the NB10 data You could make
a normal quantile plot of the 100 observations and assume {(yi|θ σ 2 B) IID
∼N(θ, σ 2)} for Your
sampling distribution if the plot indicated approximate normality—but if You do this You’ll be
conditioning on a proposition that seems true on the basis of Your data analysis (see Rule 1(b)) but
wasnotcompelledbytheproblemcontextordata-collectingdesign.Thisapproachcanberegarded
as a kind of ‘cheating’ in the model-specification process: You peek at the data to help guide this
process away from conditioning on obviously false propositions, but the something-for-nothing
bell in Your head is probably ringing—the very fact that You peeked may be an action that should
come with a price-tag.
In this chapter I examine three methods that may be helpful in moving toward the
optimal-model-specification goal described above: an approach called Calibration Cross-Validation
(CCV) that helps You to pay the right price for the data-peeking mentioned in the previous para-
graph (Section 20.2), and Bayesian non-parametric methods for specifying sampling distributions
(Section 20.3) and prior distributions (Section 20.4).
20.2 Calibration cross-validation
Two paragraphs ago I mentioned that a common method for specifying the model M =
{p(θ|B), p(D|θ B)} involves (a) looking at the data to identify an apparently reasonable choice
for the sampling distribution p(D|θ B)—call this particular choice S∗—and then (b) acting as
if S∗is something that can safely be conditioned on in drawing inferences about θ. This clearly
doesn’t satisfy the definition of optimal model specification introduced in Section 20.1, because S∗
didn’t arise from the problem context or data-gathering design, and it’s also likely to be deficient
from a calibration point of view (in this chapter, a well-calibrated inferential process is one that,
informally, gets the right answer about as often as it claims to do so): the S∗approach uses the
full dataset twice (once to find S∗, and again to draw inferential conclusions about θ based on
S∗). The mis-calibration consequences of the S∗approach will generally be that Your nominal
100(1 −γ )% inferential intervals for (univariate components of) θ and predictive intervals for
(univariatecomponentsof)futuredatasetsD∗willincludetheactualvalueslessthan100(1 −γ )%
of the time.
A natural approach to improving on the calibration performance of the S∗method for sam-
pling-distribution specification is two-component cross-validation (CV), undertaken in three steps:
first (1) You partition D exchangeably (see Section 20.3) into (mutually exclusive and exhaustive)
modelling and validation subsets—call them M and V, respectively; then (2) You explore a variety
of models with the data in M, eventually settling on one or more that appear to fit the data well; and
then finally (3) You see how well the model(s) from (2) validate on the data in V, for example by
constructing 100(1 −γ )% predictive intervals (based on the data in M) for all of the data values in
V and seeing what percentage of these intervals contain the actual observations. (The S∗approach
could be considered a kind of one-component CV, in which modelling and validation take place on
the same data.)
Two-component CV (2CV) is clearly a big improvement on the S∗method, but what happens if
the model(s) in step (2) don’t validate well in step (3)? This occurs more often than You would like
itto,andisanembarrassmentfor2CV.Thenaturalthingtodoistogobacktostep(2),re-modelling
and re-validating in step (3), iterating (2) and (3) until You finally do have one or more models that
validate well in V, but You now notice that You’ve painted Yourself into a corner: You don’t have

412
D. Draper
any pristine data values left to see how well the iterative modelling process calibrates on data not
used in that process. This motivates calibration cross-validation (CCV; [4]): going out one more
term in the Taylor series, so to speak, the idea is to
(a) partition the data into modelling (M), validation (V) and calibration (C) subsets;
(b) use M to explore a variety of models until You’ve found one or more plausible candidates,
which You can collect in an ensemble M = {M1, . . . , Mm};
(c) see how well the models in M predictively validate in V;
(d) if none of them do, iterate (b) and (c) until You do get good validation, and
(e) fitthebestmodelinM(or,better,useBayesianmodelaveraging (see,e.g.,[19]and[3])with
theentireensembleM)onthedatain(M ∪V),andreportboth(i)inferentialconclusions
based on this fit and (ii) the quality of predictive calibration of Your model/ensemble on
the data in C.
The goal with this method is both
(1) a good answer, to the main scientific question, that has paid a reasonable price for model
uncertainty (the inferential answer is based only on (M ∪V), not the entire dataset, making
Your uncertainty bands wider than those from an S∗analysis), and
(2) an indication of how well calibrated {the iterative fitting process yielding the answer in (1)}
is in the calibration subset C, which is a good proxy for future data.
You can use Bayesian decision theory [4] to decide how much data to put in each of M, V and C:
the more important calibration is to You, the more data You want to put in C, but only up to a
point, because getting a good answer to the scientific question is also important. I’ve found that
(0.5, 0.25, 0.25) is often a reasonable allocation of data fractions into (M, V, C), and that’s what I’ll
use here. In the rest of this subsection I illustrate the use of CCV on the NB10 dataset, which is
summarized in the top part of Table 20.1 (values are expressed in micrograms below the nominal
weight of 10 g).
I randomly partitioned the 100 NB10 data values into the (M, V, C) subsets of sizes (50, 25, 25)
given in the bottom part of Table 20.1 (for greatest stability of conclusions, this random partitioning
should be repeated a number of times, with CCV performed in parallel on the repetitions and the
results combined appropriately (see [4] for details); in the interests of brevity, here I only show
results with the partition in Table 20.1). Step (b) of CCV now involves exploratory modelling with
the data in M.
Given the NB10 problem context, it’s natural to begin by fitting the parametric Gaussian model
M1:

(θ σ 2|B)
∼p(θ σ 2|B)
(yi|θ σ 2 B) IID
∼
N(θ, σ 2)

(20.4)
for i = 1, . . . , n. At the point at which these 100 weighings of NB10 were performed in 1962–63,
it’s likely that workers at the National Bureau of Standards (NBS) already knew quite a bit about
the weight of this block of metal, but here I’m going to illustrate the analysis from the view-
point of someone (like me, and probably You) who has little information external to the present
dataset D about the actual weight of NB10 or the accuracy of the NBS weighing process. To make
this state of information operational, I used the diffuse prior p(θ σ 2|B) = p(θ|B) p(σ 2|B), with
(θ|B) ∼N(0, 106) and (σ 2|B) ∼−1(0.001, 0.001) (other diffuse prior specifications yielded
nearly identical conclusions). With this prior, under the Gaussian model (20.4), (i) the marginal

Bayesian model specification
413
Table 20.1 Top: A raw frequency distribution of n = 100 weighings of NB10; bottom: the random
CCV partition illustrated here (with the data values in each component sorted).
Value
375
392
393
397
398
399
400
401
Frequency
1
1
1
1
2
7
4
12
Value
402
403
404
405
406
407
408
409
Frequency
8
6
9
5
12
8
5
5
Value
410
411
412
413
415
418
423
437
Frequency
4
1
3
1
1
1
1
1
M:
375
399
399
399
399
400
400
400
401
401
401
401
401
401
402
402
402
402
402
402
403
403
403
403
403
404
404
404
404
404
404
404
405
405
405
406
406
406
406
406
407
407
407
408
408
408
409
410
411
437
V:
393
397
398
399
400
401
401
402
403
404
405
406
406
406
407
407
407
408
408
409
409
412
412
418
423
C:
392
398
399
399
401
401
401
401
402
404
405
406
406
406
406
407
407
409
409
410
410
410
412
413
415
posterior for θ is approximately Gaussian with mean 403.8 and standard deviation (SD) 1.00, (ii) a
95% central posterior interval for θ runs from 401.8 to 405.8, (iii) the marginal posterior for σ has a
moderately long right-hand tail (as You would expect for a scale parameter) with mean 7.06 and SD
0.730, (iv) the posterior predictive distribution for a future observation is approximately Gaussian
with mean 403.8 and SD 7.17, and (v) the 95% central posterior predictive interval for the next data
point runs from 389.7 to 417.9.
It’s now interesting to see how well calibrated the Gaussian model is on the data set used to fit it.
The left panel of Figure 20.1 presents a calibration plot based on the data in M, comparing nominal
and actual coverage of 100(1 −γ )% predictive intervals for γ = (0.01, 0.02, . . . , 0.99). You can
seethattheGaussianmodelproducespredictiveintervalsthataresharplyconservative;forexample,
at all nominal levels from 70%to 95%, theactual coverageis 96%. Theright panel of Figure20.1 gives
a normal quantile plot of the data in M, which identifies the reason for the poor validation of the
Gaussian model: the distribution is unimodal and close to symmetric but has substantially heavier
tails than the Gaussian, and this has led in the Gaussian framework to a large estimate of σ. By way
of a second, improved model this suggests a t sampling distribution, as in
M2:

(θ σ2 ν|B)
∼p(θ σ 2 ν|B)
(yi|θ σ2 ν B) IID
∼
tν(θ, σ 2)

.
(20.5)
This model is easy to fit via MCMC with slice sampling; 100 000 monitoring iterations took 15 sec-
ondsat3.3GHz(thismonitoringsamplesizeproducedMonteCarlostandarderrorsforallposterior
summaries less than 0.01). Here I used the diffuse prior p(θ σ 2 ν|B) = p(θ|B) p(σ2|B) p(ν|B),
with the same marginal priors as in the Gaussian model for θ and σ 2 and with (ν|B) ∼
Uniform(1.0, 10.0) (the right endpoint was chosen to be large enough to avoid truncation of the
likelihood; other values that avoid truncation give similar results).

414
D. Draper
0
20
40
60
80
100
0
20
40
60
80
100
Nominal Level (%)
Actual Level (%)
−2
−1
0
1
2
380
390
400
410
420
430
Theoretical Quantiles
Sample Quantiles
Figure 20.1 Left panel: calibration curve (dotted line) for the Gaussian model (20.4) fit to the NB10
data in M and validated in M (the solid line represents the target behaviour under good calibration);
right panel: normal quantile plot of the data in M.
The results from fitting the t model (20.5) to M are as follows: (i) the marginal posterior for
θ is again approximately Gaussian, but this time with mean 403.4 and SD 0.50; (ii) a 95% cen-
tral posterior interval for θ runs from 402.5 to 404.4; (iii) the marginal posterior for σ again has
moderate positive skew, this time with mean 2.73 and SD 0.46; (iv) the marginal posterior for ν
has a substantial right-hand tail, with (mode, median, mean) = (2.31, 2.44, 2.60) and SD 0.91; (v)
the posterior predictive distribution for a future observation is approximately Gaussian with mean
403.4 and SD 2.80; and (v) the 95% central posterior predictive interval for the next data point
runs from 397.9 to 409.0. Note how much smaller both the inferential uncertainty about θ and
the predictive uncertainty about future observations are with the t model than with the Gaussian
sampling distribution; this is a consequence of the Gaussian having minimal Fisher information for
location among all symmetric unimodal sampling distributions on ℜ. The much smaller values for
σ are because observations from a tν(θ, σ2) sampling distribution have variance
ν
ν−2σ2 (i.e., scale
and shape are confounded in this model).
Is the t model better than the Gaussian for the data in M? There are a number of ways to answer
thisquestion;theoneIlikebest[5]involvesfull-sample log scores.Theidea,withaunivariatedataset
D = y = (y1, . . . , yn)(suchastheNB10weighings)andmodelsMj (herej = 1, 2)tobecompared,
involves computing

Bayesian model specification
415
380
390
400
410
420
430
−12
−10
−8
−6
−4
−2
y
Log Score Contributions
t
Gaussian
Figure 20.2 Contributions to the overall LSFS values for each model from each observation; triangles
(solid curve) and circles (dotted curve) track the Gaussian and t models, respectively.
LSFS(Mj|D B) = 1
n
n

i=1
log p(yi|D Mj B)
(20.6)
and favouring the model with the bigger log score LSFS. Computation of LSFS is straightforward;
when parametric model Mj with parameter vector ηj is fit via MCMC, the predictive ordinate
p(y∗|D Mj B) in LSFS can be approximated as follows. With m identically distributed (not nec-
essarily independent) MCMC monitoring draws (ηj)∗
k from p(ηj|D Mj B),
p(y∗|D Mj B) =

p(y∗|ηj Mj B) p(ηj|D Mj B) dηj
= E(ηj|D Mj B) p(y∗|ηj MjB)
(20.7)
.= 1
m
m

k=1
p[y∗|(ηj)∗
k Mj B].
Applying this method to models M1 ((20.4), Gaussian) and M2 ((20.5), t) with the data in M yields
LSFS values of −3.30 and −2.86, respectively; this represents a (sharp) preference for the t model.
Figure 20.2 shows the individual contributions, from each data value in M, to the overall LSFS values
from the Gaussian and t models. It’s evident that the t model fits better both in the tails (where the
most influential observations are from the Gaussian point of view) and in the centre (where most
of the data values are); in fact, 80% of the data values in M are predicted better by the t model than
by the Gaussian.
Next question: is the t model good enough to stop looking for a better model? The answer is
complicatedherebythesmallsamplesizesineachofthe MandVpartitioncomponents.Figure20.3

416
D. Draper
0
20
40
60
80
100
100
80
60
40
20
0
Nominal Level (%)
Actual Level (%)
100
80
60
40
20
0
Actual Level (%)
100
80
60
40
20
0
Actual Level (%)
0
20
40
60
80
100
Nominal Level (%)
0
20
40
60
80
100
Nominal Level (%)
Figure 20.3 Calibration plots for the t model (20.5), fit to the data in M and validated in M (left panel);
fit to M and validated in V (centre); and fit to V and validated in V (right).
gives calibration plots for the t model with three different data configurations: fit to the data in M
and validated in M (left panel); fit to M and validated in V (centre; this corresponds to step (c) in the
CCV algorithm); and fit to V and validated in V (right). Internal validation (evaluating the fit on the
samedatasetusedtocreatethefit,asin{fittoM,validateinM},whichcouldbeabbreviatedM →M,
and similarly V →V) ranges from barely adequate (the left panel) to excellent (the right display),
butexternalvalidation(evaluatingthefitonnewdatanotusedinthefittingprocess,asinM →V,in
the centre) is abysmal, with the opposite calibration problem (predictive intervals that are not wide
enough) from that exhibited by the Gaussian M →M model in the left panel of Figure 20.1. With
only 50 observations in M and 25 in V, the parameter estimates from the t model are quite different
when it’s applied separately to M and V (see the first two rows in Table 20.2 below). Another way to
put the difficulty, looking at the full NB10 dataset in Table 20.1, is that there are ‘only’ 3 outliers in
the entire dataset (namely, the observations 375, 423 and 437), and the presence or absence of any
oneoftheseoutliersinM or Vis,byitsverynature,highlyinfluentialfortheparameterestimates.As
mentionedpreviously,[4]performstheobviousanalysistoremedythisproblem—repeattheCCV
algorithm across many random (M, V, C) partitions and average the results—which, in the interests
of brevity, I do not reproduce here; the conclusion from this broader analysis is that the t model is
a good basis for stopping the iterative step (d) in CCV and proceeding to the final step (e).
The third row in Table 20.2 gives posterior summaries from fitting the t model to the 75 obser-
vations in (M ∪V), and the left panel in Figure 20.4 gives the calibration plot for this fit when
applied to C. You can see that the model’s validation is not perfect, again in part because of the
small sample sizes: for instance, the nominal 95% predictive interval runs from 397.1 to 410.9 and
includes only 88% of the data values in C. Although it’s not part of the CCV algorithm to do so,
for comparison purposes the final row of Table 20.2 summarizes the fit of the t model to the entire

Bayesian model specification
417
Table 20.2 Parameter and predictive summaries from fitting the t model separately to the M and V
partition components, to the merged dataset (M ∪V), and to the entire dataset D; y∗is a future
data value.
Data
Sample
Posterior mean (SD)
partition
size
θ
σ
ν
y∗
M
50
403.4 (0.50)
2.73 (0.46)
2.60 (0.91)
403.4 (2.80)
V
25
405.3 (1.23)
5.31 (1.12)
5.73 (2.39)
405.3 (5.54)
(M ∪V)
75
404.0 (0.50)
3.42 (0.47)
2.88 (0.95)
404.0 (3.48)
D
100
404.3 (0.47)
3.85 (0.45)
3.56 (1.18)
404.3 (3.91)
dataset D, and the right panel in Figure 20.4 displays the calibration plot that results when the t
model is fit to, and validated in, all of D; this shows what someone using the S∗approach would
conclude,bothabouttheparametersandaboutthequalityofthemodelfit.TherightpanelofFigure
20.4providesasomewhatrosierviewofthequalityofthet modelthantheleftpanel,andistherefore
somewhat misleading about the calibration performance of the iterative modelling process leading
to the results of the S∗method.
On the basis of the CCV approach to dealing with specification uncertainty about the sampling
distribution in the NB10 problem, I would draw the following conclusions:
(A) The block of metal called NB10 weighed (in 1963) about 404.0 micrograms below the
nominal weight of 10 grams, give or take about 0.50 micrograms, and a 95% interval for
its weight runs from 403.0 to 404.9; and
(B) the iterative modelling process leading to the inferential conclusion in (A) is somewhat
over-confident in its ability to predict future data values not used in the model-fitting, with
nominal 95% predictive intervals for future observations including the actual data values
about 88% of the time, give or take about 100
;
(0.88)(0.12)
25
% .= 6.5%.
20.3 Bayesian nonparametric sampling-distribution
specification
In the NB10 problem, at design time (before any data have been collected), and with no covariate
information that would serve to distinguish one observation from another, upon reflection (fol-
lowing de Finetti [2]) You would notice that Your uncertainty about the NB10 weighings D =
(y1, . . . , yn) is exchangeable, in the usual sense that Your predictive distribution p(y1 . . . yn|B) is
invariant under permutation of the order in which the data values are observed. Moreover, if the
weighing process were to be continued indefinitely (still with no covariate information), yielding
the entire population PNB10 = (y1, y2, . . . ), Your predictive distribution p(y1 y2 . . . |B) would
still be exchangeable (in the sense that exchangeability would hold for any finite subset of PNB10).
In settings such as this, de Finetti [2] proved a celebrated theorem that says (slightly informally)

418
D. Draper
0
20
40
60
80
100
Nominal Level (%)
Actual Level (%)
0
20
40
60
80
100
0
20
40
60
80
100
0
20
40
60
80
100
Nominal Level (%)
Actual Level (%)
Figure 20.4 Calibration plots for the t model (20.5), fit to the data in (M ∪V) and validated in C (left
panel); and fit to, and validated in, the entire data set (right panel).
that all logically-internally-consistent predictive distributions p(y1 . . . yn|B) are expressible hierar-
chically as

(G|B) ∼p(G|B)
(yi|G B) IID
∼G

,
(20.8)
where G is the empirical CDF of (y1, y2, . . . ); here p(G|B) is a prior distribution on the set G of all
CDFsonℜ.Thistheoremfoundedthesub-fieldofBayesiannon-parametric(BNP)modelling,which
concerns inference on functions such as G (and also—not addressed in this chapter—functions
such as regression surfaces). At the time he proved the theorem, de Finetti didn’t know how to put
a scientifically meaningful prior on G, but progress toward this goal—started 40–50 years ago by
Freedman [10] and Ferguson [9]—culminated, in the work of people such as Escobar and West
[7] and Lavine [18], with MCMC-based approaches to extracting information from the posterior
distribution p(G|D B), and BNP modelling has become increasingly routine in the past 15 years.
This approach offers the possibility of optimal model specification (in the definitional sense in
Section 20.1) in the NB10 problem, because the judgement of exchangeability leading to model
(20.8) arises directly from problem context; the only remaining issue with this approach is how
to specify p(G|B) in a manner that is both (a) accurately driven by the nature of the data-gathering
process and (b) well-calibrated.
Two approaches to specifying p(G|B) have by now been developed to the point that they’re
both scientifically useful and computationally tractable: Dirichlet-process (DP) mixture modelling
[7, 9] and Pólya-tree (PT) mixture modelling (e.g., [13]). I’ll concentrate here on Pólya trees;
see, e.g., [17] for practical examples of DP modelling with count data. For a univariate sample
D = y = (y1, . . . , yn) such as the NB10 dataset, a natural PT mixture model would take the
following form:

Bayesian model specification
419
⎧
⎪⎪⎨
⎪⎪⎩
(yi|GB) IID
∼G
(i = 1, . . . , n)
(G|αθσ 2B) ∼PT
8
	N(θ,σ 2), Aα
9
(αθσ2|B) ∼p(αθσ 2|B)
⎫
⎪⎪⎬
⎪⎪⎭
,
(20.9)
for an appropriately chosen prior distribution p(α θ σ 2|B) on (α, θ, σ2).
The meaning of the expression PT

	G0(η), Aα

is as follows. Rather generally in Bayesian
work, prior distributions are specified through two main ingredients: a prior estimate of the thing
receiving the prior distribution, and a prior sample size indicating how tightly concentrated the
prior should be around the prior estimate. PT priors for a CDF G follow this pattern: G0(η) is
the prior estimate or centring distribution, which will typically be a parametric family indexed (in
this case) by the parameter vector η, and α acts like a prior sample size, in the sense that bigger
(smaller) values of α lead to posterior distributions on G that are closer to (farther away from)
the centring distribution. In model (20.9), G0(η) is the N(θ, σ2) distribution; this is natural in the
NB10problemforthesamereasonthattheGaussiansamplingdistributionappearedinmodelM1 in
Section 20.2.
This approach is referred to as PT mixture modelling because a point-mass prior on(α, θ, σ 2) of
the form (α = α0, θ = θ0, σ 2 = σ 2
0 ) would correspond to fitting a single Pólya-tree prior for G,
whereasamorerealistictreatmentofprioruncertaintyabout(α, θ, σ 2)—inwhichnon-point-mass
distributions are given to one or more elements of the (α, θ, σ 2) vector—amounts to mixing over
individual Pólya trees. For univariate outcomes, PT priors are based on binary partitions of ℜwith
2m partition sets at level m of the tree, and act like random histograms; to get PT priors to directly
model continuous data, strictly speaking the number of histogram bars has to become countably
infinite, but in practice finite Pólya trees (with 2M bars, for finite M, at the bottom level) are all that’s
needed, because the real-world process of measuring conceptually continuous outcomes always
discretizes them anyway.
These days it’s relatively straightforward to fit model (20.9) via MCMC with a Metropolis-with-
in-Gibbsapproach:thefull-conditionaldistributionp(G|D α θ σ2 B)turnsouttobeanotherPólya
tree, and then You can Metropolis-sample the other full-conditionals (such as p(θ|D G α σ 2 B)).
The ensemble of R functions called DPpackage [14], available from CRAN, contains several func-
tions that can fit model (20.9), including PTlm and PTdensity, and WinBUGS code for this model
is available from Tim Hanson; this permits attention to shift away from the MCMC details and
toward the modelling, where several surprises await (in relation to Your experience with parametric
modelling).
It’s possible to put a prior distribution on α, but—with an eye on calibration, as in Sec-
tion 20.2—You can instead regard α as a kind of tuning constant that You can vary across a range of
fixed values to achieve good out-of-sample calibration. In the NB10 problem, I again use a diffuse
prior on (θ, σ 2)—Gaussian with huge variance for θ, −1(ϵ, ϵ) for σ 2 with small positive ϵ—to
quantify the information base of someone who knows little, external to the NB10 dataset, about the
weight of NB10 or the accuracy of the weighing process.
As a first example of the results from the BNP approach to dealing with specification uncertainty
about sampling distributions, I used PTlm on the entire NB10 dataset with α = 1 and M = 6,
employing a burn-in of 5000 iterations (from starting values for μ and σ that were not far from their
likely posterior means) and a monitoring run of 10 000 saved values after thinning by a factor of 20.
(In PTlm, by default θ is identified as the median of the population empirical CDF.) The resulting
205 000 iterations took 4.5 minutes at 3.3 GHz, and initially yielded poor acceptance rates for the
Metropolis steps for θ and σ2. Iterative tuning of the proposal distribution SDs eventually yielded
near-optimal univariate acceptance rates of 44–49%, at which point I examined the Monte-Carlo
accuracy achieved by this MCMC sampling strategy. The saved iterations for θ behaved like draws

420
D. Draper
from an AR1(ρ1) time series with a first-order autocorrelation ˆρ1 of +0.75, even after 20-fold thin-
ning. From the usual expression

MCSE
 ¯θ∗
=
ˆσθ
√
n∗
<
1 + ˆρ1
1 −ˆρ1
(20.10)
for the Monte Carlo standard error (MCSE) of the MCMC estimate ¯θ∗= 1
n∗
n∗
j=1 θ∗
j of the
posterior mean of θ, where ˆσθ is the estimated posterior SD of θ and n∗is the number of saved
monitoringiterations,it becameclearthat—withonly200 000iterationsgoingintothemonitoring
process—the MCSEs of the posterior mean and SD estimates were on the order of 0.08, which was
too big for getting a good idea of the posterior SD of θ. To drive the MCSEs down to about 0.01, a
monitoring run of 12 000 000 iterations (thinning by a factor of 200) was needed; this took about
3.9 hours at 3.3 GHz. The first surprise with BNP modelling is how much longer in clock time it
can take to get results with decent Monte-Carlo accuracy, in relation to Your parametric-modelling
experience; on reflection, this is perhaps not actually so surprising, for two reasons: (i) You’re
treating G as a nuisance parameter that has to be learned along with the main parameter(s) of
interest (with M = 6 in Pólya trees, this is like learning an additional 26 = 64 parameters (albeit
ratherhighlycorrelated,sothattheeffectivedimensionalityofthelearningprocessforGisprobably
on the order of a few dozen additional parameters)), and (ii) uncertainty about G is bound to create
poorer mixing for θ and the other parameters You care about.
Figure 20.5 displays the marginal posterior distributions for θ (left panel) and σ (right panel)
from this fitting of model (20.9), using default window-widths for the kernel density estimation.
The second surprise with BNP modelling, when compared with parametric-modelling intuition,
is how rough these posterior distributions are; on reflection this is once again perhaps not so
0.0
0.2
0.4
0.6
0.8
1.0
1.2
theta
Density
402
403
404
405
406
6
8
10
12
14
0.0
0.2
0.4
0.6
0.8
1.0
sigma
Density
Figure 20.5 Marginal posterior distributions for θ (left panel) and σ (right panel), from fitting the Pólya-
tree model (20.9).

Bayesian model specification
421
startling (with the NB10 data, the empirical CDF is itself quite rough, from the granularity of the
observations). The marginal posterior for θ has a mean of 404.2 and an SD of 0.58, and the 95%
central posterior interval runs from 403.1 to 405.4; these results are in reasonable agreement with
those from the CCV approach in Section 20.2, with perhaps a bit more uncertainty about θ arising
from what may be a better attempt to fully quantify uncertainty about G.
As a second example of the fitting of BNP models, to get a closer look at their calibration
properties, I created an artificial dataset that had the same mean ¯y and SD s as the NB10 data but
was (in a certain sense) as close to Gaussian as possible: observation i in this artificial dataset
had the value y′
i = ¯y + s −1

i−1
2
n

, where  is the standard normal CDF. I then fit model
(20.9) to this artificial dataset, with 12 different priors on (α, θ, σ2); all these priors were of the
form p(α, θ, σ 2|B) = p(α|B) p(θ|B) p(σ2|B), with (θ|B) ∼N(0, 106) and (σ|B) ∼U(0, 20)
in each case (the upper limit on the uniform prior on σ was again chosen to avoid likelihood
truncation). My goal in this work was (a) to represent (as in all of the results in this section) the
information base, external to the NB10 data, of someone who knows little about the weight of NB10
ortheaccuracyoftheNBSmeasuringprocess,and(b)toexaminetheresultingposteriorinferences
about (θ, σ) as a function of various priors on α, which is also (to put it mildly) not a quantity
strongly pinned down by information external to the NB10 dataset. I used Tim Hanson’s WinBUGS
code for these runs; in this code θ is identified as the mean of the population empirical CDF.
Consider a point-mass prior on α that sets α = α∗(say). At each iteration of the
Metropolis-within-Gibbs sampling used to fit model (20.9), at the point at which θ∗and σ ∗
values have been drawn from p(θ σ|G D B), imagine standardizing the artificial data values y′
i to
create y′′
i = y′
i−θ∗
σ ∗, and let G′′ be the empirical CDF of the resulting y′′
i values. To complete the
current scan of the sampler, the final step is to draw a CDF G∗from the Pólya-tree distribution
PT

	G†, Aα∗
, where G† is a weighted average of the standard normal CDF  and G′′ with
weights given by α∗and n (respectively). Thus as α∗grows (with n fixed at 100), with the artificial
dataset examined here (in which the empirical CDF is as close to Gaussian as possible), You would
expect the Pólya-tree results to more and more closely resemble those from fitting the parametric
Gaussian model (20.4), with the same diffuse prior on (θ, σ) as above; the question is how quickly
(as α∗increases) this convergence will occur.
Table 20.3 presents the results of these calculations. By way of priors on α I used a popular
choice in BNP modelling—a variety of (a, b) priors on α (almost all of which had b = 1)—and I
compared these with point-mass priors having the same prior means as the Gamma distributions;
thebottomrowofthetablegivestheparametricGaussianresultsforfurthercomparison.(Allofthe
Monte Carlo standard errors for the values in this table were 0.01 or smaller.) You can see that the
expected convergence has indeed occurred, but the interesting thing (and this is a third surprise
fromBNPmodelling)ishowlargeα needstobetoget(calibrationallycorrect)resultsthatareclose
to those from the parametric model. With small α, even with n = 100 observations, with diffuse
priors on θ and σ, the uncertainty about those two parameters imposed upon the BNP modelling,
above and beyond the uncertainty about G, makes the BNP inferences extremely conservative. (Of
course, to really pin this down You would have to create a simulation environment in which many
Gaussian datasets were generated at random, rather than simply using the one “super-Gaussian”
artificial dataset I used here; I intend to report on results from this broader simulation experiment
elsewhere.)
The reason for the inferential conservatism in Table 20.3 with small α is that, in the BNP formu-
lation, (θ, σ) and G are correlated in the posterior (especially when α is small), and uncertainty
about G is therefore propagated into uncertainty about the parameters. As an example of these
correlations, I monitored the posterior for G on an equally spaced grid of 200 points in the range
(¯y ± 3.5s), obtaining a vector (G∗
1, . . . , G∗
200) on each MCMC scan; with α = 1, correlations

422
D. Draper
Table 20.3 Posterior summaries from fitting the Pólya-tree model (20.9) with an artificial Gaus-
sian dataset having the same mean and SD as the NB10 data, using a variety of prior distribu-
tions on α. In the first column, an integer k signifies α = k, and a,b is the (a, b) distribution.
The last row gives results from fitting the parametric Gaussian model (20.4) to the same dataset,
for comparison.
Posterior summaries for
θ
σ
α
α
Mean
SD
Mean
SD
Mean
SD
1,1
404.6
1.69
6.75
0.72
3.26
1.53
1
404.5
3.13
7.11
1.11
—
—
5,1
404.6
1.32
6.66
0.59
6.37
2.54
10,2
404.6
1.63
6.66
0.60
5.74
1.63
10,1
404.6
1.09
6.61
0.55
10.9
3.21
10
404.6
1.11
6.62
0.55
—
—
20,1
404.6
0.96
6.59
0.51
20.6
4.53
50,1
404.6
0.82
6.56
0.49
50.2
7.08
100,1
404.6
0.75
6.55
0.48
100.1
9.97
100
404.6
0.74
6.55
0.48
—
—
200,1
404.6
0.71
6.54
0.47
200.1
14.2
500,1
404.6
0.68
6.54
0.48
499.8
22.3
Parametric
Gaussian
404.6
0.65
6.53
0.47
—
—
between θ and elements of this G∗vector ranged from −0.33 for G∗
1 to 0 for G∗
100 to +0.34 for
G∗
200, and correlations between σ and elements of the G∗vector ranged from +0.67 for G∗
1 to
−0.06 for G∗
100 to +0.65 for G∗
200.
The upshot of this inquiry is that if You know little, external to Your present dataset D,
about the population empirical CDF G that gave rise to Your data (in a one-sample problem
like that posed by the NB10 dataset), and You express this uncertainty—in the Pólya-tree ver-
sion of BNP modelling—with a prior on α that concentrates on small values (thereby ensuring
that most of the information about G in the posterior comes from the empirical CDF based
on Your sample), the resulting inferential answers for the parameters in Your model may not be
well-calibrated, even if the centring distribution G0 in Your Pólya-tree prior closely matches the
actual data-generating mechanism. (Note that the conservatism in Table 20.3 is not present in
the results summarized in Figure 20.5. I conjecture that this is because (a) θ was identified, in
the modelling leading to Figure 20.5, as the median of G, whereas it was identified as the mean
of G in the modelling that produced Table 20.3, and (b) the correlations noted in the previ-
ous paragraph are substantially smaller in the median modelling; this is a subject of continuing
investigation.)

Bayesian model specification
423
20.4 Bayesian nonparametric prior-distribution
specification
Changing the focus now to specification of the prior distribution, it’s common in Bayesian work to
solvethisspecificationproblemwithonememberoranotherofastandardparametricfamily,some-
times chosen (e.g., for reasons of computational convenience) to be conjugate to Your sampling
distribution. But this almost always goes beyond the optimal model-specification goal identified
in Section 20.1; typically the sorts of propositions (relevant to Your prior distribution) that are
rendered true by the context of the problem are (a) qualitative shape criteria such as monotonicity,
convexity,orunimodality,andpossiblyalso(b)oneormorequantitativeboundsonpriormoments
or percentiles. In such situations it would seem more satisfying to work with an infinite-dimen-
sional non-parametric class C of prior densities satisfying the qualitative and quantitative criteria,
for instance either (i) by sampling random members of this class and averaging over the implied
uncertainty or (ii) by calculating upper and lower bounds over C for the posterior summaries of
greatest interest (this is a form of sensitivity analysis).
Here’s a case study in which to explore this idea. Suppose You’re observing an IID Bernoulli(θ)
process that has so far yielded n consecutive zeros, and the goal is to use the data to discriminate
between two competing explanations for this outcome: θ = 0 or θ > 0. (In the real-world appli-
cation on which this model is based, I once had occasion to buy n cups of tea over a several-week
period from a machine that featured on its front a stick-on label announcing to customers that they
might be lucky and get a free beverage, implying the existence of a device inside the machine that
dispensed free drinks at random. After n = 78 consecutive fee-paying cups of tea, it was natural to
speculate whether the makers of the machine had found it cheaper to attach the stick-on label, with
no intent to offer free drinks at all, than to supply the machine with a randomization mechanism.
Other applications of this problem arise, e.g., in medicine, when the first n patients screened in a
particularsub-populationallfailtohaveadiseasethat’srareintheoverallpopulation,andinprocess
control, when the first n items manufactured have all been free of defects.)
Although most inferential settings involving observation of a Bernoulli process are more satisfy-
inglyapproachedthroughintervalestimationbasedonamodelthattreats0 ≤θ ≤1continuously,
with no individual value singled out for special treatment, this situation is a genuine sharp-null
hypothesis-testing problem, and may be approached from the Bayesian point of view through the
model

(θ|B)
∼
p(θ|B)
(yi|θ B) IID
∼Bernoulli(θ)

(20.11)
(i = 1, . . . , n), with a prior of the form
p(θ|B) =

0
with probability
λ
π(θ|B)
(1 −λ)

(20.12)
forsome0 ≤λ ≤1.Intheinitialchoiceofπ(θ|B)inthetea-machinecasestudy,itseemednatural
to quantify the following set of prior information about θ, conditional on θ being positive: (a)
smaller values are more likely than bigger values, and (b) on substantive (economic) grounds, prior
uncertainty about θ should be centred between two values (α1, β1), for instance

1
75, 1
25

. (The
upper bound in (b) arises because the makers of the tea machine would not wish to give away more

424
D. Draper
free drinks than necessary, and the lower bound corresponds to the view that, if θ were too small,
customers would not perceive a large enough reward from the possibility of a free cup of tea for
the randomization strategy to be worthwhile. Unimodal priors with a positive mode are also worth
considering in this problem; this possibility will be examined elsewhere.)
20.4.1 A conjugate parametric solution
The off-the-shelf choice for π(θ|B) is of course a member of the Beta (η1, η0) family chosen, in
view of (a) and (b), to be monotonically decreasing (and possibly also convex) and to have a mean
between α1 and β1. Examination of the qualitative behaviour of the Beta family reveals that the
desired monotonicity and convexity correspond to the region within which 0 < η1 ≤1 and η0 ≥
2. The mean constraint (b) in the Beta family,
α1 ≤
η1
η1 + η0
≤β1,
(20.13)
further restricts the appropriate subclass of parametric priors to those with
η1
 1
β1
−1

≤η0 ≤η1
 1
α1
−1

,
(20.14)
giving rise with α1 = 1
75 and β1 = 1
25 to the roughly triangular admissible region in Figure 20.6
(the contours in this plot will be explained below).
alpha
beta
0.0
0.2
0.4
0.6
0.8
1.0
0
5
10
15
20
25
0.2
0.4
0.6
0.8
1
Figure 20.6 Admissible parametric priors given the substantive constraints (inside the dotted region),
together with contours of p (y|θ > 0, B) with n = 78; see equation (20.16).

Bayesian model specification
425
With data y = (y1, . . . , yn) = (0, . . . , 0),
1 posterior
odds
2
=
1 prior
odds
2
·
1 Bayes
factor
2
1p(θ = 0|y B)
p(θ > 0|y B)
2
=
1p(θ = 0|B)
p(θ > 0|B)
2
·
1p(y|θ = 0, B)
p(y|θ > 0, B)
2
(20.15)
=

λ
1 −λ

·
1
1
p(y|θ > 0, B)
2
where
p(y|θ > 0, B) =
 1
0
p(y|θ, θ > 0, B) p(θ|θ > 0, B) dθ
=
 1
0
(1 −θ)n π(θ|B) dθ ≡B−1.
(20.16)
With the parametric choice π(θ|B) = Beta(η1, η0), the Bayes factor in favour of θ = 0 takes
the form
B(η1, η0) = (η0) (η1 + η0 + n)
(η1 + η0) (η0 + n).
(20.17)
0 < B−1(η1, η0) < 1 is a probability and is easier to contour-plot than the Bayes factor; the con-
tours in Figure 20.6 are values of B−1(η1, η0) with n = 78. From this it may be seen that in the
admissible region B−1 takes its minimum value 0.235 at (η1, η0) = (1, 24) and its maximum value
of 0.899 at (η1, η0) = (0.027, 2). Thus in the parametric Beta(η1, η0) class with the given prior
specifications of monotonicity, convexity and bounds on the mean,
1
0.899 = 1.11 ≤
⎛
⎜⎝
Bayes factor
in favor of
θ = 0
⎞
⎟⎠≤4.25 =
1
0.235,
(20.18)
i.e., even with 78 consecutive zeros the strength of data evidence that θ = 0 is surprisingly small.
Using the informal guidelines of Jeffreys [15], as modified by Kass and Raftery [16], further calcu-
lation reveals that one would need more than 450 consecutive zeros for the evidence that θ = 0
(as summarized by the upper bound on the Bayes factor) to pass from ‘positive’ to ‘strong’ with the
prior specification examined here.
However, this conclusion is conditional on the Beta form of π(θ|B), which is not specified
by the scientific context; how much bigger are the bounds when the calculation is made more
appropriately over the nonparametric class C mentioned earlier? Answering this question involves
finding the extreme values (here I mean supremum/infimum, which need not be attained) of the
integral
I = I(π) =
 1
0
(1 −θ)n π(θ|B) dθ
(20.19)

426
D. Draper
when π ranges over C∗, the set of functions π(θ|B): [0, 1] →ℜin the constraint set
⎧
⎪⎨
⎪⎩
π(θ|B) ≥0,

 1
0 π(θ|B) dθ = 1,
(∗) π is monotone nonincreasing
0 < α1 ≤

 1
0 θ π(θ|B) dθ ≤β1 ≤1
2
⎫
⎪⎬
⎪⎭
,
(20.20)
or the set C∗∗of π(θ|B) in the same constraint set but with (∗) replaced by
(∗∗) π is monotone nonincreasing and convex.
(20.21)
20.4.2 A nonparametric solution
Draper and Toland [6] give solutions to the nonparametric specification problems detailed
in the previous paragraph, using a method based on functional analysis that appears to be
new to the literature; space constraints here permit only a sketch of these results, itemized as
follows.
• LetC∗andC∗∗beasin(20.20)and(20.21)forn > 1.Implementationofthemethoddetailed
in [6] leads to the conclusion that
sup
π∈C∗
 1
0
(1 −θ)n π(θ|B) dθ = 1 −2 α1 n
n + 1 .
(20.22)
• It turns out that this supremum is not attained by any π ∈C∗, but instead occurs at the
generalized function
π∗
sup(θ|B) = (1 −2 α1) δ0 + 2 α1,
(20.23)
where δ0 is the Dirac delta measure at 0, i.e., the maximizing distribution has a point mass at
0 of size (1 −2 α1) and is otherwise constant at height 2 α1 on [0, 1].
• One of the main ideas in [6] is to (a) identify a relaxed version of the optimization problem
and then (b) relate the solutions of the relaxed problem to those of the original problem. To
this end, Toland rewrites the primary problem (20.19) and (20.20) as follows:
sup / inf

1 +
 1
0

(1 −θ)n −1

π(θ|B) dθ

(20.24)
over all functions π: [0, 1] →ℜsatisfying (20.20). This ensures that hypothesis (H1) in Sec-
tion 2.1 of [6] holds, and the relaxed problem is then (20.24) over all functions π: [0, 1] →ℜ
in the relaxed constraint set
⎧
⎨
⎩
π(θ|B) ≥0,

 1
0 π(θ|B) dθ ≤1,
π is monotone nonincreasing
0 < α1 ≤

 1
0 θ π(θ|B) dθ ≤β1 ≤1
2
⎫
⎬
⎭.
(20.25)

Bayesian model specification
427
Table 20.4 Bayes factor bounds as a function of how the prior is specified, with n = 78, α1 = 1
75,
and β1 = 1
25.
Bayes factor
Specification
Low
High
Parametric
1.11
4.25
Nonparametric C∗
1.03
6.33
Nonparametric C∗∗
1.03
5.29
The main point of the discussion in this case study is the observation that the supremum and
infimum of the relaxed problem are attained at the constant function π ≡2α1, and coincide
withthesupremumandinfimumoftheprimaryproblem(20.19,20.20)(eventhoughthelatter
supremum is not attained).
• The infimum of I over π ∈C∗turns out to be
inf
π∈C∗
 1
0
(1 −θ)n π(θ|B) dθ = 1 −(1 −2 β1)n+1
2 β1 (n + 1)
;
(20.26)
the infimum is attained in C∗by
π∗
inf(θ|B) =

1
2 β1 for 0 ≤θ ≤2 β1
0
2 β1 < θ ≤1

,
(20.27)
i.e., a piecewise constant density (histogram).
• When convexity is added the supremum is unchanged, but the infimum of I over C∗∗is
2
1
1
3 β1 (n + 1) −
1 −(1 −3 β1)n+2
(3β1)2 (n + 1)(n + 2)
2
(20.28)
and occurs at the function
π∗∗
inf (θ|B) =

2
(3 β1)2 (3 β1 −θ) for 0 ≤θ ≤3 β1
0
3 β1 < θ ≤1

,
(20.29)
i.e., a piecewise linear density (a frequency polygon).
Withn = 78, α1 = 1
75,andβ1 = 1
25,theminimumandmaximumvaluesofI overC∗are0.158and
0.974, respectively, and over C∗∗the minimum rises to 0.189. Table 20.4 summarizes the numerical
findings,andFigure20.7plotstheoptimizingdensities.Withoutconvexitythenonparametriclimits
are 8% lower and 49% higher than the parametric values, and even with convexity the correspond-
ing figures are 8% and 24%; the casual adoption of a convenient parametric family satisfying the
scientifically motivated monotonicity and convexity constraints has led to noticeably narrower
sensitivity bounds than those that more appropriately arise from assuming only monotonicity and
convexity.

428
D. Draper
theta
Density
0.0
0.02
0.04
0.06
0.08
0.10
0.12
0.14
0
20
40
60
80
100
Figure 20.7 Optimal densities π∗
inf (long dotted line), π∗∗
inf (short dotted line), and approximation to
π∗sup in which the point mass at 0 is replaced by a histogram bar of width ϵ = 0.01 (solid line).
20.4.3 A heuristic sketch of the method of proof
The goal is to optimize the integral I = I(π) in (20.19) over functions π subject to monotonicity
and/or convexity constraints, (20.20) and (20.21), respectively. The basic idea is to think of π as
though it were a point in a convex subset of ℜk and to use intuitions from the geometry of such sets
in ℜk to inform the proof.
(1) The set C∗of admissible functions π may be thought of as like a convex polygon in ℜk,
but with infinitely many vertices and edges. In this heuristic proof sketch, consider the
situation with k = 2 and visualize a polygon with a finite number of vertices and edges.
The boundary points are of two kinds: extreme points and all the other boundary points.
An extreme point is not an interior point of any line segment in the set. (For example, the
corners of a square are its only extreme points.)
(2) The function I in (20.19) is linear on π, analogous to a linear function in the plane. But
it’s important to realize that, because the set of functions satisfying (20.19) and (20.20) is
infinite-dimensional, the extreme values may not be attained at points of the constraint
set; and in fact the supremum is not attained but the infimum is. Because of this difficulty,
Toland replaced the primary problem with a relaxed problem over a larger convex set and
showed that in the relaxed problem the extreme values are attained and that they coincide
with the extreme values of the original problem. Moreover he showed that the solution of
the relaxed problem is finite-dimensional, although the original problem was not.
(3) Thelevelsetsofalinearfunctiononℜ2 areparallelstraightlines.Whentherelaxedpolygon
liesononesideofalevellineandtouchesit,thepolygonandthelineintersectinoneoftwo
ways: at single vertices (one for each of the minimizer and maximizer), or along an edge.
In the latter case, even though the intersection set includes points that are not vertices, the
set always includes vertices. Thus it suffices in optimizing a linear function to evaluate it at

Bayesian model specification
429
the vertices of the polygon (this is the basic intuition behind linear programming). This is
where the Krein–Milman theorem (e.g., [21]) comes into the infinite-dimensional argument
(see Theorem 2 in Section 2 of [6]).
(4) Because of geometric constraints of monotonicity on π in the relaxed problem, the ana-
logue of vertices in C∗turns out to be the class of step functions with at most three distinct
values; thus the infinite set of extrema can be indexed with at most five parameters.
(5) A vertex π of the relaxed polygon has the property that no linear perturbation (π ± φ π)
away from it for small non-zero φ lies completely inside the admissible set. Toland was able
to conjecture a particular form of φ, namely
φ(θ) =
 θ
0
h(t) π′(t) dt
(20.30)
and show that if π is more complicated than a step function with two distinct values, a
non-trivial (φ π ̸= 0) h can always be found such that all of the constraints in C∗are
satisfied. Therefore the vertices are histograms with two or three bars.
(6) Thinking of a two-bar histogram, in the limit as the left-hand bar becomes infinitely tall the
maximizer π∗sup over C∗results: a point mass at 0 plus a constant over the rest of [0, 1]. In
the limit as the right-hand bar goes to 0 the minimizer over C∗is obtained.
(7) When convexity is added, the relaxed polygon vertices become the class of convex piecewise
linear functions with exactly three distinct segments; here only six parameters are needed.
The maximizer over C∗∗remains the same as in C∗because π∗sup is already convex. The
minimizer of the relaxed problem turns out to be a two–part piecewise linear function
(frequency polygon) with the second segment 0.
(8) When unimodality is assumed instead of the other qualitative constraints examined, a
modification of the method Toland employs for dealing with monotonicity is available,
because unimodal densities on [0, 1] are non-decreasing on [0, d) and non-increasing on
(d, 1] for some d ∈[0, 1].
Results similar to the findings here under monotonicity have been obtained elsewhere in the
Bayesian robustness literature by quite different means, through the use of Khintchine’s Theorem
(e.g., [8]) on generating unimodal densities as mixtures of uniform distributions. The approach
sketched here, via functional analysis, both subsumes the condition of unimodality and yields new
results under the alternative qualitative specifications of monotonicity and convexity.
20.4.4 Conclusions
As more moment constraints are added to the quantitative mean constraint examined here to
increase realism, e.g.,
σ 2
low ≤
 1
0
[θ −E(θ|B)]2 π(θ|B) dθ ≤σ 2
high,
(20.31)
the optimal nonparametric solutions become k–part piecewise linear functions (frequency poly-
gons) with increasing k, approaching the smoothness built into parametric families like Beta (α, β).
Thus continuous parametric assumptions are equivalent to infinite sets of moment constraints, i.e.,
when You choose continuous parametric priors You’re probably assuming more than You think
You are.

430
D. Draper
The set of practical problems in which
(a) the prior really matters and
(b) off-the-shelf parametric specifications are often used instead of qualitative descriptions
involving shape (e.g., number of modes, monotonicity, convexity, smoothness) and sub-
stantive bounds on quantitative descriptions (e.g., moments or quantiles)
is larger than is generally acknowledged. The method of proof offered here shows promise to
inform Bayesian sensitivity analysis in a wide variety of such problems, because all of the above
characteristics may be enforced with linear constraints through derivatives and integrals of π.
Postscript On the 79th visit to the machine it yielded a free cup of tea.
Acknowledgements
I’m grateful to Tim Hanson and Alejandro Jara (a) for help with the programming that led to the
results presented in Section 20.3 and (b) for comments that aided interpretation of the Bayesian
nonparametric findings; to Milovan Krnjajić for helpful discussions about calibration cross-valida-
tion; to John Toland for doing all of the heavy lifting in the proofs underlying Section 20.4; and to
Jim Berger, Brad Efron, Richard Olshen, Luc Tartar, and Stephen Walker for helpful comments and
references. Membership on this list does not imply agreement with the conclusions drawn here, nor
are any of these people responsible for any errors that may be present.
References
[1] Cox, R. T. (1946). Probability, frequency, and reasonable expectation. American Journal of
Physics, 14, 1–13.
[2] deFinetti,B.(1937).Laprévision:sesloislogiques,sessourcessubjectives.Annalesdel’Institut
Henri Poincaré, 7, 1–68.
[3] Draper, D. (1995). Assessment and propagation of model uncertainty (with discussion). Jour-
nal of the Royal Statistical Society (Series B), 57, 45–97.
[4] Draper, D. (2012). Bayesian model specification: towards a theory of applied statistics.
Submitted.
[5] Draper, D. and Krnjajić, M. (2012). Calibration results for Bayesian model specification.
Submitted.
[6] Draper, D. and Toland, J. (2012). Bayesian non-parametric prior specification. Technical
Report, Department of Applied Mathematics and Statistics, University of California, Santa
Cruz.
[7] Escobar, M. and West, M. (1995). Bayesian density estimation and inference using mixtures.
Journal of the American Statistical Association, 90, 577–588.
[8] Feller, W. (1971). An Introduction to Probability Theory and its Applications (2nd edn), Vol-
ume 2. Wiley, New York.
[9] Ferguson, T. S. (1974). Prior distributions on spaces of probability measures. Annals of Statis-
tics, 2, 209–230.
[10] Freedman, D. (1963). On the asymptotic behavior of Bayes’ estimates in the discrete case.
Annals of Mathematical Statistics, 34, 1194–1216.
[11] Freedman, D., Pisani, R. and Purves, R. (2007). Statistics (4th edn). Norton, New York.

Bayesian model specification
431
[12] Good, I. J. (1950). Probability and the Weighing of Evidence. Charles Griffin, London.
[13] Hanson, T. (2006). Inference for mixtures of finite Pólya tree models. Journal of the American
Statistical Association, 101, 1548–1565.
[14] Jara,A.,Hanson,T.,Quintana,F.,Müller,P.andRosner,G.(2011).DPpackage:Bayesiansemi-
and nonparametric modeling in R. Journal of Statistical Software, 40, 1–30.
[15] Jeffreys, H. (1967). Theory of Probability (3rd edn). Oxford University Press, Oxford.
[16] Kass, R. E. and Raftery, A. E. (1995). Bayes factors. Journal of the American Statistical Associa-
tion, 90, 773–795.
[17] Krnjajić, M., Kottas, A. and Draper, D. (2008). Parametric and non-parametric Bayesian
model specification: a case study involving models for count data. Computational Statistics
and Data Analysis, 52, 2110–2128.
[18] Lavine, M. (1992). Some aspects of Pólya tree distributions for statistical modeling. Annals of
Statistics, 20, 1222–1235.
[19] Leamer, E. E. (1978). Specification Searches: Ad Hoc Inference with Nonexperimental Data.
Wiley, New York.
[20] Mosteller, F. and Wallace, D. L. (1984). Applied Bayesian and Classical Inference: The Case of
The Federalist Papers. Springer-Verlag, New York.
[21] Rudin, W. (1991). Functional Analysis (2nd edn). McGraw-Hill, New York.

21
Case studies in Bayesian
screening for
time-varying model
structure: the partition
problem
zesong liu, jesse windle and
james g. scott
21.1 Introduction
P
roblems of model selection are often thought to be among the most intractable in modern
Bayesian inference. They may involve difficult high-dimensional integrals, nonconcave solu-
tion surfaces or large discrete spaces that cannot be enumerated. All of these traits pose notorious
computational and conceptual hurdles.
Yet model-choice problems—particularly those related to feature selection, large-scale simulta-
neous testing and inference of topological network structure—are also some of the most impor-
tant. As modern datasets have become larger, they have also become denser—that is, richer with
covariates, more deeply layered with underlying patterns, and indexed in ever more baroque ways
(e.g. xijkt, rather than just xij). It is this complex structure, more than the mere tallying of terabytes,
that defines the new normal in twenty-first-century statistical science. There is thus a critical need
for Bayesian methodology that addresses the challenges posed by such datasets, which come with
an especially compelling built-in case for sparsity.
The difficulties of model selection are further exacerbated when the structure of the model is not
‘merely’ unknown, but also changes as a function of auxiliary information. We call this the partition
problem: the auxiliary information defines an unknown partition over sample space, with different
unknown models obtaining within different elements of the partition. Here are three examples
where model structure plausibly covaries with external predictors.
Subgroup analysis Howcancliniciansconfrontthemultiplicityprobleminherentindeciding
whether a new cancer drug is effective for a specific subgroup of patients, even if it fails for the
larger population? Here the model is simply a binary indicator for treatment effectiveness, while
the partitions are defined by diagnostically relevant covariates—for example, age, sex or smok-

Case studies in Bayesian screening
433
ing status. No good approaches exist, Bayesian or otherwise, that are capable of systematically
addressing this problem. The difficulty is that examining all possible partitions wastes power:
manysubstantivelymeaninglessornonsensicalpartitionsareconsidered,andmustreceiveprior
probability at the expense of the partitions we care about.
Partitioned variable selection A patient comes to hospital complaining of a migraine. The
hospital wishes to use the patient’s clinical history to diagnose whether the migraine may por-
tend a subarchnoid haemorrhage, a catastrophic form of brain bleed. Such haemorrhages are
thought to be etiologically distinct for children and adults. Thus the age of the patient influ-
ences which aspects of her clinical history (i.e. variables) should be included in the predictive
model.
Network drift A delay-tolerant network (DTN) for communication devices has few instanta-
neous origin-to-destination paths. Instead, most messages are passed to their destination via a
series of local steps (at close range) from device to device. In such a setting, it helps to know the
underlying social network of users in the model—that is, who interacts with whom, and how
often—in order to predict the likelihood of success for specific directed transmissions. Thus
the time-varying topological structure of the social network has important implications for the
efficient routing of traffic within the device network.
All three of these problems recall the literature on tree modelling, including [4], [6], [7] and
[11]. Yet to our knowledge no one has studied tree models wherein one large discrete space (for
example, predictors in or out of a linear model) is wrapped inside another large discrete space
(trees).
This poses all the usual computational and modelling difficulties associated with tree structures,
and large discrete spaces more generally. But it also poses a major, unique challenge. In all exist-
ing applications of Bayesian tree models we have encountered, the collapsed sampler (whereby
node-levelparametersaremarginalizedawayandMCMCmovesaremadeexclusivelyintreespace)
is the computational tool of choice. But in the partition problem, the bottom level parameter in
the terminal nodes of the tree is itself a model indicator, denoting an element of some potentially
large discrete space. This makes it difficult to compute the marginal likelihood of a particular tree
in closed form, since doing so would involve a sum with too many terms. The collapsed sampler
therefore cannot always be used.
Trees are, of course, just one possible generative model for partitions of a sample space based
on such auxiliary information. Others include species-sampling models, coalescent models or urn
models (such as those that lie at the heart of Bayesian nonparametrics). But no matter what par-
titioning model is entertained, new models and algorithms are necessary to make inferences and
quantify uncertainty for this very general class of problems.
Thischapterpresentstwocasestudiesofdatasetswithinthisclass.Forbothdatasetstheauxiliary
information is time. In the first case study, we identify time-varying graphical structure in the
covariance of asset returns from major European equity indices from 2006–2010. This structure has
important implications for quantifying the notion of financial contagion, a term often mentioned
in the context of the European sovereign debt crisis of this period. In the second case study, we
screen a large database of historical corporate performance in order to identify specific firms with
impressively good (or bad) streaks of performance.
Our goal in these analyses is not to address all the substantive issues raised by each dataset.
Rather, we intend: (1) to present our argument for the existence of non-trivial dynamic structure in
each dataset, an argument that can be made using simple models; (2) to draw parallels between the
case studies, both of which exemplify the partition problem quite well; and (3) to identify certain
aspects of each model that must be generalized in future work if these case studies are to provide a
useful template for other datasets.

434
Z. Liu, J. Windle and J. G. Scott
21.2 Case study I: financial contagion and dynamic
graphical structure
21.2.1 Overview
During times of financial crisis, such as the bursting of the US housing bubble in 2008 and the Euro-
pean sovereign-debt crisis in 2010, the co-movement of asset prices across global markets is hypoth-
esized to diverge from its usual pattern. Many financial theorists predict, and many empiricists have
documented, changes in market relationships after these large market shocks. It is important to
track these large shocks and measure their impacts on the global economy so that we can better
understand future market behaviours during times of crisis.
In general, the idea that market relationships change after large shocks is called contagion [9]. In
the literature, there has been a lengthy debate over precise definition of this term. As a practical
matter, we define contagion as significant change in the pattern of correlation in the residuals
from an asset-pricing model during times of crisis, following in the tradition of previous authors
[e.g. 1, 2, 10]. Focusing primarily on how the relationships between markets change, we want to
determine whether large shocks have significant impact on the subsequent interactions between
markets.
The standard way to study the co-movements and interdependent behaviour of markets is by
lookingatthecovariancematricesofreturnsacrossdifferentcountries.Inthiscasestudy,weexplore
ways of estimating this covariance structure to study the change of the market dynamic over time.
Normally,whenconstructingcovariancematrices,thealgorithmsappliedarecomputationallyiden-
tical to repeated applications of least squares regressions. Instead, we apply the ideas of Bayesian
modelselection,usingtheBayesianinformationcriterion,orBIC[16],toapproximatethemarginal
likelihoods of different hypotheses, and a flat prior over model space.
Inapplyingthismethod,weuncovermanysignsofcontagion,whichmanifestsitselfastime-vary-
inggraphicalstructureinthecovariancematrixofreturns.Forexample,ifwelookattherelationship
between Italy and Germany, the traditionally positive correlation between the countries changes
sign during the sovereign debt crisis. This provides just one example of the evidence for contagion
discovered in these investigations.
21.2.2 Contagion in factor asset-pricing models
The sovereign debt crisis started when Greece became in danger of defaulting on its debt. For years,
Greece had been a rapidly growing economy with many foreign investors. This strong economy
was able to withstand large government deficits that Greece had during that time. But after the
worldwide 2008 financial crisis hit, two of the country’s largest industries, tourism and shopping,
were badly affected. This downturn caused panic in the Greek economy. Although Greece was
not the only country that confronted debt problems, its debt-to-GDP ratio was judged excessively
high by markets and ratings agencies, reaching 120% in 2010. Moreover, one of the major fears that
arose during this period was that investors would lose faith in other similarly situated Euro-zone
economies, which could cause something similar to a run on a bank.
One of the major events in this episode occurred on May 9, 2010. On that day the 27 member
states of the EU agreed to create the European Financial Stability Facility, a legal instrument aimed
at preserving financial stability in Europe by providing financial assistance to states in need. This
legislation was upsetting to countries with large healthy economies such as Germany, whose elec-
torate focused on the negative effects of the bailout. In light of these developments, not only do we
want to show that the pattern of asset-price correlation changed, but we also want to make sense of
these changes by linking them to the news headlines about bailouts.

Case studies in Bayesian screening
435
Our raw data are daily market returns from equity indices corresponding to nine large European
economies—Germany,theUK,Italy,Spain,France,Switzerland,Sweden,BelgiumandtheNether-
lands—from December 2005 to October 2010. We do not include Greece because of its small size
relative to the other economies of Europe, but we do include the Euro–Dollar exchange rate as a
tenth column in the dataset.
Byourdefinitionofcontagion,weneedtoexaminetheresidualsofthereturnswithinthecontext
of an asset-pricing model. Specifically, we use a four-factor model where
E(yit | EU, US) = βUS
i
xUS
t
+ βEU
i
xEU
t
+ γ US
i
δUS
t
+ γ EU
i
δEU
t
where yit is the daily excess return on index i; xUS
t
is the daily excess return on a value-weighted
portfolio of all US equities; xEU
t
is the daily excess return on the EU-wide index of Morgan Stanley
Capital International; δUS
t
is the volatility shock to the US market; and δEU
t
is the excess volatility
shock to the European market. The excess shock is defined as the residual after regressing the
EU volatility shock upon the US volatility shock. This is necessary to avoid marked collinearity,
since the US volatility shock strongly predicts the EU volatility shock. These volatility factors are
calculated using the particle-learning method from [14], not described here.
In this model, the loadings βUS
i
and βEU
i
measure the usual betas relative to the US and
Europe-wide equity markets. Thus we have controlled for regional and global market integration
via an international CAPM-style model [2]. The loadings γ US
i
and γ EU
i
, meanwhile, measure
country-level dependence upon global and regional volatility risk factors. As shown in [14], these
loadings can be interpreted in the context of a joint model that postulates correlation between
shocks to aggregate market volatility and shocks to contemporaneous country-level returns.
21.2.3 A graphical model for the residuals
The above model can be fitted using ordinary least squares, leading to an estimate of all model
parameters along with a set of residuals ϵit for all indices. We now turn to the problem of imposing
graphical restrictions on the covariance matrix of these residuals.
A Gaussian graphical model defines a set of pairwise conditional-independence relationships on
a p-dimensional zero-mean, normally distributed random vector (here denoted x). The unknown
covariance matrix  is restricted by its Markov properties; given  = −1, elements xi and xj of
the vector x are conditionally independent, given their neighbours, if and only if ij = 0. If G =
(V, E) is an undirected graph whose nodes represent the individual components of the vector x,
then ij = 0 for all pairs (i, j) /∈E. The covariance matrix  is in M+(G), the set of all symmetric
positive-definite matrices having elements in −1 set to zero for all (i, j) /∈E.
We construct a graph by selecting a sparse regression model for each country’s residuals in terms
ofalltheothercountries,asin[8]and[20].Wethencobbletogethertheresultingsetofconditional
relationships into a graph to yield a valid joint distribution. Each sparse regression model is selected
by enumerating all 29 possible models, and choosing the one that minimizes the BIC. This leads to
a potentially sparse model for E(ϵit | ϵj,t, j ̸= i).
In this manner, an adjacency matrix can be constructed for the residuals from the four-factor
model. The (i, j) element of the adjacency matrix is equal to 1 if the residuals for countries i and j
both appear in each other’s conditional regression models, and is equal to 0 otherwise. One may
also assemble the pattern of coefficients from these sparse regressions to reconstruct the covariance
matrix for all the residuals, denoted .
Weactuallylookatadjacencymatricesandcovariancematricesonarollingbasis,sincewebelieve
thattherearechangesin overtime.Eachwindowinvolvesaseparatesetofregressionsforaperiod
of 150 trading days, which is thirty weeks of trading, or about seven months. We shift the window

436
Z. Liu, J. Windle and J. G. Scott
in five-day increments, thereby spanning the whole five-year time period in our study. For each
150-day window, we refit the estimate for t using the entire graphical-model selection procedure.
For the sake of comparison, we also include the estimates of t using OLS, ridge regression, and
lasso regression.
21.2.4 Results
From Figure 21.1, which depicts the rolling estimates of the Italy–Germany and Spain–Germany
regression coefficients, it is clear that there are nonrandom patterns that remain in the residuals.
If the factor model fully explained the co-movements in the European market, we would expect
the residuals to have no covariance and look like noise. We would also expect that the Bayesian
variable-selection procedure would give regression coefficients of 0. To be sure, the data support
the hypothesis that specific elements of the precision matrix t = −1
t
are zero over certain time
periods. An example of this is the ITA-DEU coefficient during much of 2008. Yet it is patently not
the case that all such elements are zero for all time periods: the standard significance test of an
empty graph is summarily rejected (p < 10−6) at all time points. For details of this test, see [13]
and Proposition 1 of [5].
There are several explanations for the observed correlation between the residuals. Firstly, it is
highly probable that the factor models are imperfect. Regressing only on the market returns and
market volatility, the four-factor model involves a substantial simplification of reality. For example,
during the sovereign debt crisis, we could reasonably add an explanatory variable that takes into
account the change in likelihood of a bailout. Secondly, even if we imagine that the four-factor
model is the true model for this system of markets, we only have proxies for both the global and
local returns and volatility. Specifically, using the US market return as a proxy for the world mar-
ket return is a reasonable estimate, but it is far from perfect. Moreover, the factors that measure
market volatility are at best a measure of the average market volatility over a short time span.
This could potentially distort the residuals, since we cannot observe volatility spikes on a more
granular scale. Most likely, the correlations in the residuals stems from some mixture of these two
effects.
The same conclusion about significant residual correlation is also borne out by examining the
time-varying topology of the graph itself. While it is difficult to visualize the time-varying nature
of the network’s structure in its entirety, we can look at quantities such as how the adjacency of a
specific node in the graph—that is, how many neighbours it has—changes over time. Figure 21.2
shows the estimated adjaceny degrees for Sweden and the UK, two non-Euro countries. Again we
see that the factor model is not perfect, as the residuals still exhibit correlation. On the other hand,
we see that the degree of each vertex is not 9 at every time point. This means that shrinkage is often
useful: it is clear that estimating p(p −1)/2 separate correlation parameters is a poor use of the
data, and will lead to estimators with unnecessarily high variance. We can almost certainly reduce
the required number of parameters while still obtaining a good estimate. This illustrates the utility
of the graphical modelling approach.
Finally, the relationship between the Spain and Germany residuals is easily interpretable in terms
oftheunderlyingeconomicpicture.Inthesummerof2010,thereisanapparentdivergencefromthe
historical norm, precisely coinciding with the Greek sovereign-debt crisis and associated bailout.
The historically aberrant negative correlations between the residuals from Germany and the south-
ern countries suggests that markets reacted very differently in these two countries to news of the
period. A useful comparison is with the period of September and October 2008, when the global
financial crisis associated with the bursting of the housing bubble was at its peak. These were global
rather than EU-centric events, and no such divergence was observed involving the German-market
residuals.

Case studies in Bayesian screening
437
Coefficient for Spain on Germany
Coefficient
–0.4
–0.2
0.0
0.2
0.4
20060620
20061109
20070409
20070829
20080123
20080616
20081105
20090401
20090824
20100115
20100610
OLS
Lasso
BIC
Coefficient for Italy on Germany
Coefficient
–0.4
–0.2
0.0
0.2
0.4
20060620
20061109
20070409
20070829
20080123
20080616
20081105
20090401
20090824
20100115
20100610
OLS
Lasso
BIC
Figure 21.1 Estimated regression coefficients for Italy (top) and Spain (bottom) on Germany, where
the coefficients are calculated on a rolling basis using Bayesian model selection via BIC.

438
Z. Liu, J. Windle and J. G. Scott
Degree of Sweden in Graph
Coefficient
0
2
4
6
8
10
20060620
20061109
20070409
20070829
20080123
20080616
20081105
20090401
20090824
20100115
20100610
Lasso
BIC
Degree of UK in Graph
Coefficient
0
2
4
6
8
10
20060620
20061109
20070409
20070829
20080123
20080616
20081105
20090401
20090824
20100115
20100610
Lasso
BIC
Figure 21.2 Estimated adjacency degree in the time-varying graph of residuals for the UK (top) and
Sweden (bottom). There seems to be clear evidence of time-varying topological structure in the
graph.

Case studies in Bayesian screening
439
Ourapproachprovidesinitialevidenceforcontagioneffects,buthassomeimportantlimitations.
In particular, we have estimated time-varying graphical structure using a moving-window variable
selection approach, which does not explicitly involve a dynamic model over graph space. Some
authors have made initial efforts in studying dynamic graphs [e.g. 21, 22], but much further work
remains to be done to operationalize the notion of contagion within this framework. The issue is
that we expect contagion to be associated with a sharp change in the underlying graphical structure
of the residual covariance matrix, as opposed to the locally drifting models considered by these
other authors. Such sharp changes are likely obscured by our rolling-regression approach, in that
only about 3% of the data changes in each new window.
21.3 Case study II: simultaneous change-point screening
and corporate out-performance
21.3.1 Overview
In this case study, we compare publicly traded firms against their peer groups using a standard
accountingmetricknownasROA,orreturnonassets.Thedatasetcomprises645 456company-year
records from 53 038 companies in 93 different countries, spanning the years 1966–2008.
Justasinthepreviousexample,wewillattempttouncoversubstantivelymeaningfulchangesover
timeintheunderlyingmodelforeachtimeseries.Letyit denotethebenchmarkedROAobservation
for company i at time t; let yi denote the whole vector of observations for company i observed at
times ti = (t1, . . . , tni); and let Y denote the set of yi for all i. We say that the observations have
been ‘benchmarked’ to indicate that they have undergone a pre-processing step that removes the
effects of a firm’s size, industry and capital structure. For details, see [18].
The goal is to categorize each time series i as either signal or non-signal, both to be defined
shortly. The model we consider takes the general form
yi = fi + ϵi, ϵi ∼Noise
(21.1)
fi ∼ω · Signal + (1 −ω) · Null
(21.2)
where Signal is the distribution describing the signal and Null is the distribution describing the
non-signal. In this case, ‘noise’ should not be conflated with actual measurement error. Instead, it
represents short-term fluctuations in performance that are not indicative of any longer-term trends,
and are thus not of particular relevance for understanding systematic out-performance.
We can rephrase this model as
yi = fi + ϵi, ϵi ∼Noise
fi ∼Fγi, F1 = Signal, F0 = Null
(21.3)
γi ∼Bernoulli(ω)
which provides us with the auxiliary variable γi that determines whether a time series i is either
signal or noise. Thus the posterior distribution p(γi = 1|Y) is a measure of how likely time series i
is signal. One can sort the data points from most probable to least probable signal by simply ranking
p(γi = 1|Y). Importantly, these posterior probabilities will contain an automatic penalty for data
dredging: as more unimpressive firms are thrown into the cohort, the posterior distribution for
ω will favour increasingly smaller values, meaning that all observations have to work harder to
overcome the prior bias in favour of the null [see, e.g. 3, 19].

440
Z. Liu, J. Windle and J. G. Scott
Suppose, for example, that fi = 0 corresponds to the average performance of a company’s peer
group, and that we want deviations from zero to capture long-range fluctuations in yi from this
peer-group average—that is, changes in a company’s fortunes or long-run trends that unfold over
many years. Several previous authors have proposed methodology for the multiple-testing problem
that arises in deciding whether fi = 0 for all firms simultaneously [12, 15, 17]. The origin of such a
testing problem lies in the so-called ‘corporate success study’, very popular in the business world:
begin with a population of firms, identify the successful ones, and then look for reproducible
behaviours or business practices that explain their success.
The hypothesis that fi = 0, then, implies that a firm is no better, or worse, than its peer group
over time. One way to test this hypothesis is by placing a Gaussian-process prior on those fis that
differ from zero. Suppose, for example, we have an i.i.d. error structure and some common prior
inclusion probability:
yi = fi + ϵi, ϵi ∼N(0, σ 2I)
fi ∼Fγi, F1 = N(0, σ 2K(ti)), F0 = δ0
γi ∼Bernoulli(ω)
where K(t) is the matrix produced by a covariance kernel k(·, ·), evaluated at the observed times
t = (t1, . . . , tM)′. The (i, j) entry of K is:
Ki,j = k(ti, tj).
Typically the covariance function will itself have hyperparameters that must be either fixed or
estimated. A natural choice here is the squared-exponential kernel:
k(ti, tj) = κ1 exp

−(ti −tj)2
2κ

+ κ3δti,tj
where δti,tj is the Kronecker delta function. If the three κ hyperparameters are fixed, then this is just
a special case of a conjugate multivariate Gaussian model, and the computation of the posterior
model probabilities p(γi = 1|Y) may proceed by Gibbs sampling. As shown in [17], this basic
idea may be generalized to more complicated models involving autoregressive error structure and
Dirichlet-process priors on non-zero trajectories.
21.3.2 Detecting regime changes
One shortcoming of this strategy is that fi is assumed to be either globally zero or globally non-zero.
Thepartitionproblemis different,andcaptures animportant aspect ofrealityignoredbythemodel
above: the signal of interest may not involve consistent performance, but rather a precipitous rise
or fall in the fortunes of a company.
We therefore consider the possibility that each firm’s history may, though not necessarily, be
divided into two epochs. The separation of these epochs corresponds to some sort of significant
schism in performance between time periods. For instance, a positive jump might arise by virtue of
a drug patent or the tenure of an especially effective leader—someone like Steve Jobs of Apple, or
Jack Welch of General Electric. There may also be periods of inferior performance when the jump
is negative.

Case studies in Bayesian screening
441
We therefore adapt model (21.3) in the following way. With each firm, we associate not a binary
indicator of ‘signal’ or ‘noise’, but rather a multinomial indicator for the location in time of a
major shift in performance. We then index all further parameters in the model by this multinomial
indicator:
yi = fi + ϵi, ϵi ∼Noise
fi ∼Fγi
(21.4)
γi ∼Multinomial(ω)
with the convention that γi = 0 denotes the no-split case where fi is globally zero, and γi = n the
no-split case where fi is globally non-zero.
This differs from the traditional changepoint-detection problem in two respects: we are
data-poor in the time direction, but data-rich in the cross-section. Indeed, this case study is the
mirror image of the previous one, where the number of time series was moderate the number of
observations per times series was large. This fact requires us to consider models that are simpler
in the time domain, but also allows us to borrow cross-sectional information across firms for the
purpose of estimating shared model parameters. This is particularly important for the multinomial
parameter ω, which lives on the (n + 1)-dimensional simplex, and descibes the population-level
distribution of changepoints.
There are many potential choices for Fk and Noise. For instance, we could choose
Fk = N(0, Ck) and Noise = N(0, )
where  describes the covariance structure of the noise and Ck describes a split in epochs at time
k (again recalling the convention that C0 is degenerate at zero and that Cn corresponds to no
split at all). Of course, we need not limit ourselves to this interpretation, and may intead choose a
collection of {Ck} that embodies some other substantive meaning. For instance, we could consider
the collection Ci,k where C1,k corresponds to a small jump at time k and C2,k corresponds to a large
jump at time k. We could also generalize to multiple regime changes per firm. For now, however, we
considerthesimplercasewheretherecanbeatmostoneshift,andwhereallshiftsareexchangeable.
Recall that we intend such an intentionally oversimplified model to be useful for high-dimensional
screening, not nuanced modelling of an individual firm’s history.
As before, both {Ck} and  will include some sort of hyperparameters, which we will denote as
θ for now. Conditional on the hyperparameters, we may write the distribution of the data as
yi|γi ∼N(0, Cγi + )
which are conditionally independent across i. Thus when calculating the posterior distribution
using a Gibbs sampler, the conditional distribution p(γ |Y, θ, ω) will conveniently decompose into
a product over p(γi|yi, θ, ω). Moreover, when each time series has its own hyperparameter θi and
theonlysharedinformationacrosstimeseriesisthemultinomialprobabilityvector ω,theposterior
calculation simplifies further. In particular, after marginalizing out each θi, the only quantities that
must be sampled are {p(γi|yi, ω)} and p(ω|Y, γ ).
Many of the details of such a model are encoded in particular choices for the covariance matrices
describing signals and noise. As an illustration of this general approach, consider a simple model
in which fi is piecewise constant. This assumption is reasonable given the relatively short length
of each time series; in any case, one may think of it as a locally constant approximation to the true
model. Suppressing the index i for the moment, we write the model as

442
Z. Liu, J. Windle and J. G. Scott
ys = fs + ϵs, ϵs ∼N(0, σ 2
s I),
fs ≡θ,
θ ∼N(0, σ 2
s τ2),
σ 2
s ∼IG(a/2, b/2)
where s is some subsequence of the times {1, . . . , n}. Marginalizing over θ and σ 2s yields a multi-
variate-T marginal:
ys ∼Ta+|s|(0, Rs)
Rs = a
b(Is + τ2Ss).
If we know θ = 0, or in other words that θ ∼δ0, then Rs = (a/b)Is. Notice that this formulation
automatically handles missing data, since one can simply exclude those times from s.
This can be phrased in terms of model (21.4) by letting Sk = 1k1′
k be the k × k matrix of ones,
and defining
Fk = N(0, τCk)
where
Ck|σ 2
ij =

σ 2
i1Sk
0
0
σ 2
i2Sn−k

for k = 1, · · · , n −1
Fn = N(0, σ 2
i τSn), and F0 = δ0 (that is Cn = σ 2
i Sn and C0 = 0). Furthermore, we define the
prior over the residuals so that it, too, depends on the index γi:
Noise = Eγi = N(0, γi)
where k|σ 2
ij = σ 2
1iI for k = 0 and n, and where
k|σ 2
ij =

σ 2
i1I
0
0
σ 2
i2I

for k = 1, . . . , n −1
Finally, for p(ω) we assume a conjugate Dirichlet prior (details below).
This simple model has many advantages: it is analytically tractable; it handles missing data
easily; it allows for the possibility of a sharp break between epochs; and it allows for preprocessing
of all marginal likelihoods, which saves time in the Gibbs sampler. To see this, observe that the
conditional posterior distribution for γ is
p(γ |Y, ω) ∝

i
p(yi|γi, ω)p(γi|ω)
so we can sample each p(γi|yi, ω) independently. In particular,
p(γi = k|Y, ω) ∝p(yi|γi = k)p(γi = k|ω)

Case studies in Bayesian screening
443
Let ℓk be the observation times which are less than or equal to k and rk be the observation times
which are greater than k, both of which depend upon i. When k > 0,
p(γi = k|Y, ω) ∝Ta+|ℓk|(yi(ℓk); 0, Rℓk) · Ta+|rk|(yi(rk); 0, Rrk) · p(γi = k|ω)
with the convention that rk = ∅if k = n. When k = 0,
p(γi = k|Y, ω) ∝Ta+|ℓk|(yi(ti); 0, a
bIti)p(γi = k|ω)
All of the T densities can be computed beforehand for each i and k, and the conditional posterior
distribution of γi may be calculated directly over the simplex {0, . . . , n}.
When implementing this model, we restrict our dataset to those firms which have at least 20
observations, leaving us with 6067 data points. Including firms with fewer data points would
eliminate the possibility of survivorship bias, but would likely result in a significant decrease
in power for the firms with longer histories, because of shared dependence of all firms on
p(ω | Y).
Following the discussion above, the posterior distribution was simulated using a Gibbs sampler
with 3000 steps. We set τ2 = 10.0 and chose the prior distributions as follows: IG(2.0/2, 2.0/2)
for all noise variance parameters; and ω ∼Dirichlet(α) with α0 = 0.8, αn = 0.1, and αi =
0.1/(n −1)fori = 1, . . . , n −1.Thisreflectsthebelief,borneoutbypriorstudies,thatmostfirms
do not systematically over- or under-perform their peer groups over time. The choice of τ2 = 10
will result in increased power for detecting major shifts in performance, but also a significant
Occam’s-razor penalty against small shifts.
Onemustbecarefulininterpretingtheposteriordistributionp(γ |Y)thatarisesfromthismodel.
For instance, it may not be meaningful to categorize time series i in terms of the single time point j
thatmaximizesp(γi = j|Y),sinceitisentirelypossiblethatp(γi = j|Y)isofcomparablemagnitude
for a range of different values of j. This would suggest either no split, or a split that cannot be
localized very precisely. In such cases, it may be more appropriate to look at firms where the largest
entry p(γi | Y) is sufficiently large. This would be strong evidence that there is a split at time j for
time series i.
Figure 21.3 provides intuition for the various scenarios we might encounter: the posterior of γi
may strongly favour γi = 0 or γi = n, in which case no split occurs; it may show evidence of a split,
but at an ambiguous time; it may show strong, but not decisive evidence of a split; or it may be flat,
which does not tell us anything. The ideal case for interpretation, of course, would involve strong
evidence of a split at a particular time, as seen in the last pane of Figure 21.3.
In examining these plots, it appears that the posterior mode
PM(γi) = max
0<j<n p(γi = j|Y)
providesagoodmeasureofachangeinepochsaslongaswechooseasufficientlyhighcutoff,suchas
requiring that the maximum satisfy max0<j<n{γi = j|Y} > 0.95. To check that this is reasonable,
we plot the histogram of PM(γi) in Figure 21.4. Of the 3033 firms, only 58 have a value greater
than or equal to 0.95. The largest twenty posterior modes were used to select the time series in
Figure 21.5.

444
Z. Liu, J. Windle and J. G. Scott
3
Key 1004
Key 1013
p(gamma_i | y), i = 1004
p(gamma_i | y), i = 1013
Key 1019
Key 1038
p(gamma_i | y), i = 1019
p(gamma_i | y), i = 1038
1
–1
–3
1970
1990
Time
3
1
–1
–3
1970
1990
Time
0.8
0.4
0.0
0
10
20
30
40
Index
0.8
0.4
0.0
0
10
20
30
40
Index
3
1
–1
–3
1970
1990
Time
3
1
–1
–3
1970
1990
Time
0.8
0.4
0.0
0
10
20
30
40
Index
0.8
0.4
0.0
0
10
20
30
40
Index
Key 10225
p(gamma_i | y), i = 10225
3
1
–1
–3
1970
1990
Time
0.8
0.4
0.0
0
10
20
30
40
Index
Figure 21.3 Five examples of a firm-level posterior distribution over possible changepoints, labelled
by Compustat keys. The five panes embody a wide range of possible conclusions, with the
data on the left and p(γi | Y ) on the right. From top to bottom, we see: strong evidence of a
null case (γ = 0); evidence of a hard-to-localize changepoint; moderate evidence of a specific
changepoint; near-total uncertainty over changepoints; and very strong evidence of a specific
changepoint.
21.4 Discussion
In each of these two case studies, we have confronted a similar problem: time-varying model uncer-
tainty for each of many different time series observed in parallel. In the first case, the model was a
graph,encodingconditionalindependencerelationshipsaboutresidualsfromcountry-levelreturns
duringtheEuropeansovereigndebtcrisis.Inthesecondcase,themodelwasanindicatorofwhether
afirm’shistoricalROAtrajectorywassignificantlydifferentfromitspeer-groupaverage.Thesewere
seen to be examples of a general class of problems wherein the model changes as a function of
auxiliary information.
The models we have entertained are based upon fairly standard tools, and were chosen specifi-
cally to avoid the difficulties associated with the most general form of partitioning that were men-
tioned in the introduction. They are thus more appropriate for first-pass screening than for detailed
analysis. Nonetheless, even these simple models were sufficient to support the general thrust of our
argument: that each dataset exhibited non-trivial dynamic model structure. In each case, further
work is clearly needed to build upon the limited, broad-brush conclusions that can be reached
within the context of these simple models.

Case studies in Bayesian screening
445
6
5
4
3
2
1
0
0.2
0.4
max p(gamma_i = j | y, 1 <=j < n)
P(w | Y)
Histogram of max p(gamma_i = | j Y, 1 <= j < n)
0.6
0.8
1.0
0
10
20
30
Index
40
0.30
0.25
0.20
0.15
0.10
0.05
0.00
Prob
Figure 21.4 Top: the histogram of the largest entry in the posterior mode PM(γi) across all firms.
Bottom: the posterior mean of the multinomial probability vector ω. Notice that null cases (γi = 0)
dominate the sample, but that some years clearly have more changepoints than others.

3
1
–1
–3
1970
1990
Key 1990
3
1
–1
–3
1970
1990
Key 9761
3
1
–1
–3
1970
1990
Key 10225
3
1
–1
–3
1970
1990
Key 8304
3
1
–1
–3
1970
1990
Key 1203
3
1
–1
–3
1970
1990
Key 6807
3
1
–1
–3
1970
1990
Key 5667
3
1
–1
–3
1970
1990
Key 13733
3
1
–1
–3
1970
1990
Key 5574
3
1
–1
–3
1970
1990
Key 8151
3
1
–1
–3
1970
1990
Key 9882
3
1
–1
–3
1970
1990
Key 3413
3
1
–1
–3
1970
1990
Key 208980
3
1
–1
–3
1970
1990
Key 14894
3
1
–1
–3
1970
1990
Key 4087
3
1
–1
–3
1970
1990
Key 9504
3
1
–1
–3
1970
1990
Key 7065
3
1
–1
–3
1970
1990
Key 7974
3
1
–1
–3
1970
1990
Key 9005
3
1
–1
–3
1970
1990
Key 7402
Figure 21.5 The firms with the 20 largest values for PM(γi | Y ). These are the 20 firms in the cohort where the evidence for a specific changepoint is the strongest.

Case studies in Bayesian screening
447
References
[1] K. Bae, G. Karolyi and R. Stulz. (2003). A new approach to measuring financial contagion.
Review of Financial Studies, 16(3): 717–763.
[2] G. Bekaert, C. Harvey, and A. Ng. (2005). Market integration and contagion. Journal of Busi-
ness, 78(1): 39–69.
[3] M. Bogdan, A. Chakrabarti, F. Frommlet and J. K. Ghosh. (2011). Asymptotic Bayes-opti-
mality under sparsity of some multiple testing procedures. The Annals of Statistics, 39(3):
1551–1579.
[4] L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone. (1984). Classification and Regression
Trees. Chapman and Hall/CRC.
[5] C. M. Carvalho and J. G. Scott. (2009). Objective Bayesian model selection in Gaussian
graphical models. Biometrika, 96(3): 497–512.
[6] H. A. Chipman, E. I. George, and R. E. McCulloch. (1998). Bayesian CART model search.
Journal of the American Statistical Association, 93 (443): 935–948.
[7] D. G. Denison, B. K. Mallick, and A. F. Smith. (1998). A Bayesian CART algorithm.
Biometrika, 85(2): 363–377.
[8] A. Dobra, B. Jones, C. Hans, J. Nevins, and M. West. (2004). Sparse graphical models for
exploring gene expression data. Journal of Multivariate Analysis, 90: 196–212.
[9] R. Dornbusch, Y. C. Park, and S. Claessens. (2000). Contagion: Understanding how it
spreads. The World Bank Research Observer, 15(2): 177–197.
[10] K. J. Forbes and R. Rigobon. (2002). No contagion, only interdependence: Measuring stock
market comovements. The Journal of Finance, 57: 2223–2261.
[11] R. Gramacy and H. K. Lee. (2008). Bayesian treed Gaussian process models with an applica-
tion to computer modeling. Journal of the American Statistical Association, 103 (483): 1119–1130.
[12] A. D. Henderson, M. E. Raynor, and M. Ahmed. (2009). How long must a firm be great
to rule out luck? benchmarking sustained superior performance without being fooled by
randomness. In The Academy of Management Proceedings.
[13] S. L. Lauritzen. (1996). Graphical Models. Clarendon Press, Oxford.
[14] N. G. Polson and J. G. Scott. (2011). An empirical test for eurozone contagion using an
asset-pricing model with heavy-tailed stochastic volatility. Technical report, University of
Texas at Austin, arXiv:1110.5789v2.
[15] N. G. Polson and J. G. Scott. (2012). Good, great, or lucky? Screening for firms with sustained
superior performance using heavy-tailed priors. The Annals of Applied Statistics. (to appear).
[16] G. Schwarz. (1978). Estimating the dimension of a model. Annals of Statistics, 6(2): 461–464.
[17] J. G. Scott. (2009). Nonparametric Bayesian multiple testing for longitudinal performance
stratification. The Annals of Applied Statistics, 3(4): 1655–1674.
[18] J. G. Scott. (2010). Benchmarking historical corporate performance. Technical report, Uni-
versity of Texas at Austin, http://arxiv.org/abs/0911.1768.
[19] J. G. Scott and J. O. Berger. (2006). An exploration of aspects of Bayesian multiple testing.
Journal of Statistical Planning and Inference, 136(7): 2144–2162.
[20] J. G. Scott and C. M. Carvalho. (2008). Feature-inclusion stochastic search for Gaussian
graphical models. Journal of Computational and Graphical Statistics, 17 (790–808).
[21] M. Taddy, R. B. Gramacy, and N. G. Polson. (2011). Dynamic trees for learning and design.
Journal of the American Statistical Association, 106 (493): 109–123.
[22] H. Wang, C. Reeson, and C. M. Carvalho. (2011). Dynamic financial index models: Modeling
conditional dependencies via graphs. Bayesian Analysis.

This page intentionally left blank 

Part IX
Regressions and Model Averaging

This page intentionally left blank 

22
Bayesian regression
structure discovery
hugh a. chipman,
edward i. george and
robert e. mcculloch
22.1 Introduction
T
he general problem of statistical regression is concerned with the discovery of a relationship
between a variable of interest y and a set of potential predictors x1, . . . , xp. It is usually real-
istic, especially when p is large, to consider that y may be related only to an unknown subset of
the potential predictors, thus making variable selection an inherent part of the problem. In this
paper, we describe two very different Bayesian approaches to this general problem. The feasible
implementation of both of these approaches has been made possible by Markov chain Monte
Carlo (MCMC) Bayesian posterior simulation, [7] and [14]. In particular, variations of the Gibbs
sampler and the Metropolis–Hastings algorithms have allowed for the exploration of the otherwise
intractable posteriors via simulation.
One approach, which dovetails with classical parametric approaches to variable selection, begins
with an assumption that the relationship between y and x1, . . . , xp can be described by a full
parametric model within which the actual subset model is nested. The most popular form used
here is the normal linear model, in large part because of its appealing analytical tractability and
becauseofitsusefulnessasanapproximationtootherforms,possiblyaftersuitabletransformations.
A structured hierarchical mixture prior that captures all sources of remaining uncertainty is then
used to obtain a posterior distribution which allocates more probability to the more promising
subset models.
In contrast to the parametric approach, our second approach does not require an initial assump-
tionaboutthenatureofalltherelationshipsbetweenyandthesubsetsofx1, . . . , xp.Nonparametric
in nature, it begins with a very rich over parameterized functional form, a sum-of-trees model, that
approximates a wide class of functions from Rp to R. However, with this more complex model it
becomesmorechallengingtoformulateusefulpriorsandextractinformationabouttherelationship
between y and x. A strong regularization prior over the multitude of parameters of the sum-of-trees
model is used to obtain a posterior distribution over the possible relationships between y and
x1, . . . , xp. A variety of useful inferential summaries can be obtained by MCMC sampling from
this posterior. In particular, by keeping track of how often each predictor is used in the sum-of-trees
model,thisapproachallowsformodel-freevariableselection,andfurtherformodel-freeinteraction
detection, the discovery of when variables work together to influence the response.

452
H. A. Chipman, E. I. George and R. E. McCulloch
22.2 Parametric Bayesian structure discovery
To illustrate the parametric Bayesian approach to structure discovery, we focus on the classical
version of the problem which begins with the assumption of a normal linear model for every subset
model, namely
Y = Xγ βγ + ϵ,
ϵ ∼Nn(0, σ 2I)
(22.1)
where Y is the n × 1 vector of y observations, Xγ is the n × qγ matrix whose columns correspond
to the γ th subset of x1, . . . , xp, and βγ is the qγ × 1 vector of unknown regression coefficients.
For convenience, we have indexed each of the 2p possible subset choices by
γ = (γ1, . . . , γp)′
(22.2)
where γi = 1 or 0 according to whether predictor xi is included or excluded, respectively. The
size (number of covariates) of the γ th subset is thus qγ ≡γ ′1. The variable selection problem
may then be regarded as how to use the data to choose γ . Particular Bayesian treatments of this
formulation yield analytical reductions that allow for faster calculations as well as clearer insights
into how the machinery works. Such Bayesian treatments also extend naturally to likelihoods that
are a function of Xγ only through Xγ βγ . There is by now a vast literature on Bayesian analyses for
this formulation. See, for example, [9], [2] [4], and the references therein.
It should be noted that assumption (22.1) for every possible submodel γ is a strong assumption.
Its strength is that it effectively turns the variable selection problem into a model selection problem
which can be treated using variations of standard Bayesian parametric formulations. Its weakness is
that a subset of predictors may be rejected because a normal linear submodel is inadequate rather
than because Y is unrelated to the subset.
22.2.1 Prior formulations
The parametric problem formulation in (22.1), provides a likelihood L(βγ , σ, γ |Y). Thus, a
Bayesian analysis proceeds with the choice of prior forms for
p(βγ , σ, γ ) = p(βγ , σ |γ )p(γ )
(22.3)
For the specification of the model space prior p(γ ), many Bayesian variable selection implementa-
tions have used simple independence priors of the form
p(γ ) = wqγ (1 −w)p−qγ
(22.4)
with a prespecified value for w, the expected proportion of x′
is in the submodel. Under this prior,
each xi enters the submodel independently with probability p(γi = 1) = 1 −p(γi = 0) = w. To
avoid the fact that any such prior will be informative about the size of the model, a reasonable
alternative is to margin out w in (22.4) with respect to a Beta prior to obtain
p(γ ) = B(α + qγ , β + p −qγ )
B(α, β)
(22.5)

Bayesian regression structure discovery
453
a special case of the more general form
p(γ ) =
 p
qγ
−1
h(qγ )
(22.6)
which is uniform over the set of submodels of a given size qγ . See [8], [5] and [13].
Forthespecificationoftheparameterpriorp(βγ , σ |γ ) = p(βγ |σ 2, γ ) p(σ 2 |γ ),anespecially
convenient choice is the conjugate normal-inverse-gamma prior
p(βγ |σ 2, γ ) = Nqγ (0, σ 2γ )
(22.7)
p(σ 2 |γ ) = p(σ 2) = IG(ν/2, νλ/2)
(22.8)
(p(σ 2) hereis equivalent to νλ/σ 2 ∼χ2ν ). A valuable feature of this prior is its analytical tractabil-
ity; βγ and σ 2 can be eliminated by routine integration to yield
p(Y |γ ) ∝|X′
γ Xγ + −1
γ |−1/2|γ |−1/2(νλ + S2
γ )−(n+ν)/2
(22.9)
where
S2
γ = Y′Y −Y′Xγ (X′
γ Xγ + −1
γ )−1X′
γ Y
(22.10)
The use of these closed form expressions can substantially speed up posterior evaluation and
MCMC exploration, as we will see.
For choosing the prior covariance matrix γ that controls p(βγ |σ 2, γ ), specification is sub-
stantially simplified by setting γ = c Vγ , where c is a scalar and Vγ is a preset form such as
Vγ = (X′γ Xγ )−1 (as in the [16] g-prior) or Vγ = Iqγ , the qγ × qγ identity matrix. Having
fixed Vγ , the goal is then to choose c large enough so that p(βγ |σ 2, γ ) is relatively flat over the
region of plausible values of βγ , thereby reducing prior influence. At the same time it is impor-
tant to avoid excessively large values of c because the Bayes factors will eventually put increas-
ing weight on the null model as c →∞, the Bartlett–Lindley paradox. For practical purposes,
a rough guide is to choose c so that p(βγ |σ 2, γ ) assigns substantial probability to the range of
all plausible values for βγ . A recent alternative of interest, are the hyper-g priors for βγ which
effectively integrate out c with respect to Beta prime distributions, Cui and George (2008) [5], [10]
and [11].
In choosing values for the hyperparameters that control p(σ 2), λ may be thought of as a prior
estimate of σ 2, and ν may be thought of as the prior sample size associated with this estimate.
Alternatively, one might use the data informally to choose λ and ν as follows. Let σ 2
FULL and
σ 2
Y denote the traditional estimates of σ 2 based on the saturated and null models respectively.
Treating σ 2
FULL and σ 2
Y as rough under- and over-estimates of σ 2, one might choose λ and ν so
that p(σ 2) assigns substantial probability to the interval (σ 2
FULL, σ 2
Y). This should at least avoid
gross misspecification. As a third option, the explicit choice of λ and ν can be avoided by using
p(σ 2) ∝1/σ 2, the limit of the inverse-gamma prior as ν →0.
22.2.2 Posterior exploration and information extraction
The previous conjugate prior formulations allow for analytical margining out of β and σ 2 from
p(Y, β, σ 2 |γ ) to yield a computable, closed form expression

454
H. A. Chipman, E. I. George and R. E. McCulloch
g(γ ) ∝p(Y |γ )p(γ ) ∝p(γ |Y)
(22.11)
that can greatly facilitate posterior calculation and exploration. For example, when γ =
c (X′γ Xγ )−1, we can obtain
g(γ ) = (1 + c)−qγ /2(νλ + Y′Y −(1 + 1/c)−1W′W)−(n+ν)/2p(γ )
(22.12)
where W = T′−1X′γ Y for upper triangular T such that T′T = X′γ Xγ (obtainable by the Cholesky
decomposition). This representation allows for fast updating of T, and hence W and g(γ ), when γ
ischangedonecomponentatatime,requiringO(q2γ )operationsperupdate,whereγ isthechanged
value.
The availability of g(γ ) ∝p(γ |Y) allows for the flexible construction of MCMC algorithms
that simulate a Markov chain
γ (1), γ (2), γ (3), . . .
(22.13)
converging (in distribution) to p(γ |Y). A variety of such MCMC algorithms can be conveniently
obtained by applying the Gibbs sampler with g(γ ). For example, by generating each γ component
from the full conditionals
p(γi |γ(i), Y)
(22.14)
(γ(i) = {γj : j ̸= i}) where the γi may be drawn in any fixed or random order. The generation of
such components can be obtained rapidly as a sequence of Bernoulli draws using simple functions
of the ratio
p(γi = 1, γ(i) |Y)
p(γi = 0, γ(i) |Y) = g(γi = 1, γ(i))
g(γi = 0, γ(i))
(22.15)
The availability of such closed form g(γ ) also facilitates the use of MH algorithms. Because
g(γ )/g(γ ′) = p(γ |Y)/p(γ ′ |Y), these are of the form:
1. Simulate a candidate γ ∗from a transition kernel q(γ ∗|γ (j)).
2. Set γ (j+1) = γ ∗with probability
α(γ ∗|γ (j)) = min

q(γ (j) |γ ∗)
q(γ ∗|γ (j))
g(γ ∗)
g(γ (j))
, 1

(22.16)
3. Otherwise, set γ (j+1) = γ (j).
When available, fast updating schemes for g(γ ) can be exploited in all of these MCMC algorithms.
The simulated Markov chain sample γ (1), . . . , γ (K) contains valuable information about the
posteriorp(γ |Y).Empiricalfrequenciesprovideconsistentestimatesofindividualmodelprobabil-
ities or characteristics such as p(βi ̸= 0 |Y). When closed form g(γ ) are available, we can do better.
For example, the exact relative probability of any two values γ 0 and γ 1 is obtained as g(γ 0)/g(γ 1)
in the sequence of simulated values. Such g(γ ) also facilitates estimation of the normalizing con-
stant p(γ |Y) = Cg(γ ). Let A be a preselected subset of γ values and let g(A) = 
γ ∈A g(γ ) so
that p(A |Y) = Cg(A). Then, a consistent estimate of C is

Bayesian regression structure discovery
455
ˆC =
1
g(A)K
K

k=1
IA(γ (k))
(22.17)
where IA( ) is the indicator of the set A. This yields alternative estimates of the probability of indi-
vidual γ values ˆp(γ |Y) = ˆCg(γ ), as well as an estimate of the total visited probability ˆp(B |Y) =
ˆCg(B), where B is the set of visited γ values.
22.3 Nonparametric Bayesian structure discovery
To illustrate the nonparametric Bayesian approach to structure discovery, we focus on an approach
we call BART (Bayesian Additive Regression Trees), ([3]) which assumes only that y is related to
x = (x1, . . . , xp) via a flexible sum-of-trees model of the form19
Y =
m

j=1
g(x; Tj, Mj) + ϵ,
ϵ ∼N(0, σ 2)
(22.18)
whereeachTj isabinaryregressiontreewithasetMj ofassociatedterminalnodeconstantsμij,and
g(x; Tj, Mj) is the function which assigns μij ∈Mj to x according to the sequence of decision rules
in Tj. These decision rules are binary splits of the predictor space of the form {x ∈A} vs {x /∈A}
where A is a subset of the range of x. When m = 1, (22.18) reduces to the single tree model used by
[1] for Bayesian CART.
Under (22.18), E(Y |x) equals the sum of all the terminal node μijs assigned to x by the
g(x; Tj, Mj)’s. As these can be any values, it is easy to see that the sum-of-trees model (22.18) is a
veryflexiblerepresentationcapableofrepresentingawideclassoffunctionsfromRn toR,especially
when the number of trees m is large. Note also that the sum-of-trees representation is composed of
many simple functions from Rp to R, namely the g(x; Tj, Mj), rendering it much more manageable
than a representation with more complicated basis elements such as multidimensional wavelets or
multidimensional splines.
22.3.1 A regularization prior
We complete the BART model specification by imposing a prior over all the parameters of the
sum-of-trees model, namely (T1, M1), . . . , (Tm, Mm) and σ. Note that these parameters entail all
the bottom node parameters as well as the tree structures and decision rules, a very large number
of parameters, especially when m is large. We do this using a prior that effectively regularizes the
fit by keeping the individual tree effects from being unduly influential. Without such a regularizing
influence, large tree components would overwhelm the rich structure of (22.18), thereby limiting its
scope of approximation.
To begin with we simplify our prior specification task by restricting attention to prior formula-
tions of the form
p((T1, M1), . . . , (Tm, Mm), σ) =
⎡
⎣
j

i
p(μij |Tj)

p(Tj)
⎤
⎦p(σ)
(22.19)
19 Note that here we use Y as a random scalar rather than an n × 1 random vector as in Section 22.2.

456
H. A. Chipman, E. I. George and R. E. McCulloch
where μij ∈Mj. These independence restrictions simplify prior specification to the choice of prior
forms for p(Tj), p(μij |Tj) and p(σ), and to simplify matters further we consider for all of these, the
same prior forms as those proposed by [1] for Bayesian CART. These forms are controlled by just a
few interpretable hyperparameters which can be calibrated using the data to yield effective default
specifications for regularization of the sum-of-trees model.
For p(Tj), we use the [1] tree-generating process which is specified by three aspects: (i) the
probability that a node at depth d (= 0, 1, 2, . . .) is nonterminal, given by
α(1 + d)−β,
α ∈(0, 1), β ∈[0, ∞),
(22.20)
(ii) the distribution on the splitting variable assignments at each interior node, and (iii) the distri-
bution on the splitting rule assignment in each interior node, conditional on the selected splitting
variable. For (ii) and (iii) we use the simple defaults in [1] , namely a uniform prior on each set of
possibilities
For p(μij |Tj), we use the conjugate normal distribution N(μμ, σ 2μ) which allows μij to be
margined out, greatly simplifying MCMC posterior calculations. Note that under this choice the
prior distribution of E(Y |x) is N(m μμ, m σ2μ), (because E(Y |x) is the sum of m independent μijs
under the sum-of-trees model). Thus, it is highly probable that E(Y |x) is between ymin and ymax,
the observed minimum and maximum of y in the data, a fact which we can use to guide the specifi-
cation of the hyperparameters μμ and σμ. The essence of our informal strategy is then to choose
μμ and σμ so that N(m μμ, m σ 2μ) assigns substantial probability to the interval (ymin, ymax).
This can be conveniently done by choosing μμ and σμ so that m μμ −k √m σμ = ymin and
m μμ + k √m σμ = ymax for some preselected value of k such 1,2 or 3. For example, k = 2 would
yielda95%priorprobabilitythatE(Y |x)isintheinterval(ymin, ymax).Thegoalofthisspecification
strategy for μμ and σμ is to ensure that the implicit prior for E(Y |x) is in the right ‘ballpark’ in the
sense of assigning substantial probability to the entire region of plausible values of E(Y |x) while
avoiding overconcentration and overdispersion. As long as this goal is met, BART seems to be very
robust to the variations of these specifications.
For p(σ), we also use a conjugate prior, here the inverse chi-square distribution σ 2 ∼ν λ/χ2ν ,
the same form we used for p(σ) for the parametric variable selection problem previously. Here
again, we use a data-informed prior approach, to guide the specification of the hyperparameters ν
and λ, in this case to assign substantial probability to the entire region of plausible values of σ while
avoiding overconcentration and overdispersion. Essentially, we calibrate the prior df ν and scale λ
using a ‘rough data-based overestimate’ ˆσ of σ. Two natural choices of where ˆσ are (1) a ‘naive’
specification, the sample standard deviation of Y, or (2) a ‘linear model’ specification, the residual
standard deviation from a least squares linear regression of Y on all the predictors. We then pick a
value of ν between 3 and 10 to get an appropriate shape, and a value of λ so that the qth quantile of
the prior on σ is located at ˆσ, that is P(σ < ˆσ) = q. We consider values of q such as 0.75, 0.90 or
0.99 to centre the distribution below ˆσ.
22.3.2 Posterior calculation and information extraction
Combining the regulation prior with the likelihood, L((T1, M1), . . . , (Tm, Mm), σ |y) induces a
posterior distribution
p((T1, M1), . . . , (Tm, Mm), σ| y)
(22.21)
over the full sum-of-trees model parameter space. Fortunately, the following backfitting MCMC
algorithm can be used to simulate samples from this posterior.

Bayesian regression structure discovery
457
We begin with a Gibbs sampler at the outer level. Let T(j) be the set of all trees in the sum except
Tj,andsimilarlydefineM(j),sothatT(j) willbeasetofm −1trees,andM(j) theassociatedterminal
node parameters. A Gibbs sampling strategy for sampling from (22.21) is obtained by m successive
draws of (Tj, Mj) conditionally on (T(j), M(j), σ):
(Tj, Mj)|T(j), M(j), σ, y
(22.22)
j = 1, . . . , m, followed by a draw of σ from the full conditional:
σ|T1, . . . Tm, M1, . . . , Mm, y
(22.23)
The draw of σ in (22.23) is simply a draw from an inverse gamma distribution and so can be easily
obtained by routine methods. More subtle is the implementation of the m draws of (Tj, Mj) in
(22.22). This can be done by taking advantage of the following reductions. First, observe that the
conditional distribution p(Tj, Mj| T(j), M(j), σ, y) depends on (T(j), M(j), y) only through
Rj ≡y −

k̸=j
g(x; Tk, Mk),
(22.24)
the n−vector of partial residuals based on a fit that excludes the jth tree. Thus, the m draws of
(Tj, Mj) given (T(j), M(j), σ, y) in (22.22) are equivalent to m draws from
(Tj, Mj)|Rj, σ
(22.25)
j = 1, . . . , m. Because we have used a conjugate prior for Mj, p(Tj|Rj, σ) can be obtained in closed
form up to a norming constant. This allows us to carry out each draw from (22.25) in two successive
steps as
Tj|Rj, σ
(22.26)
Mj|Tj, Rj, σ.
(22.27)
The draw of Tj in (22.26), although somewhat elaborate, can be obtained using the
Metropolis–Hastings (MH) algorithm of [1]. The draw of Mj in (22.27) is simply a set of
independent draws of the terminal node μijs from a normal distribution. The draw of Mj
enables the calculation of the subsequent residual Rj+1 which is critical for the next draw
of Tj.
We initialize the chain with m simple single node trees, and then iterations are repeated until
satisfactory convergence is obtained. Fortunately, this backfitting MCMC algorithm appears to mix
very well as we have found that different restarts give remarkably similar results even in difficult
problems.Ateachiteration,eachtreemayincreaseordecreasethenumberofterminalnodesbyone,
or change one or two decision rules. The sum-of-trees model, with its abundance of unidentified
parameters, allows for ‘fit’ to be freely reallocated from one tree to another. Because each move
makes only small incremental changes to the fit, we can imagine the algorithm as analogous to
sculpting a complex figure by adding and subtracting small dabs of clay.
For inference based on our MCMC sample, we rely on the fact that our backfitting algorithm is
ergodic. Thus, the induced sequence of sum-of-trees functions

458
H. A. Chipman, E. I. George and R. E. McCulloch
f ∗(·) =
m

j=1
g(·; T∗
j , M∗
j )
(22.28)
for the sequence of draws (T∗
1, M∗
1), . . . , (T∗m, M∗m), is converging to p(f | y), theposterior distribu-
tion on the ‘true’ f(·). Thus, by running the algorithm long enough after a suitable burn-in period,
the sequence of f ∗draws, say f ∗
1 , . . . , f ∗
K, may be regarded as an approximate, dependent sample of
size K from p(f | y). Bayesian inferential quantities of interest can then be approximated with this
sample as indicated below.
To estimate f(x) or predict Y at a particular x, in-sample or out-of-sample, a natural choice is the
average of the after burn-in sample f ∗
1 , . . . , f ∗
K,
1
K
K

k=1
f ∗
k (x)
(22.29)
whichapproximatestheposteriormeanE(f(x) | y).Posterioruncertaintyaboutf(x)maybegauged
by the variation of f ∗
1 (x), . . . , f ∗
K(x). For example, a natural and convenient (1 −α)% poste-
rior interval for f(x) is obtained as the interval between the upper and lower α/2 quantiles of
f ∗
1 (x), . . . , f ∗
K(x).
Finally, BART provides a new approach to variable selection and interaction detection by iden-
tifying those variables or combination of variables that appear most often in the fitted sum-of-trees
models. Interestingly, the variable selection strategy does not seem to work well when m is large
because the redundancy offered by so many trees allows many irrelevant predictors to be mixed in
with the relevant ones. However, as m is decreased and that redundancy is diminished, BART tends
to heavily favour relevant predictors for its fit. In a sense, when m is small the predictors compete
witheachothertoimprovethefit.Incontrast,interactiondetectionseemstoworkwellwithlargem.
This model-free approach to variable selection is accomplished by observing what happens to
the x component usage frequencies in a sequence of MCMC samples f ∗
1 , . . . , f ∗
K as the number of
trees m is set smaller and smaller. More precisely, for each simulated sum-of-trees model f ∗
k , let zik
be the proportion of all splitting rules that use the ith component of x. Then
vi ≡1
K
K

k=1
zik
(22.30)
is the average use per splitting rule for the ith component of x. As m is set smaller and smaller, the
sum-of-trees models tend to more strongly favour inclusion of those x components which improve
prediction of y and exclusion of those x components that are unrelated to y. In effect, smaller m
seemstocreateabottleneckthatforcesthexcomponentstocompeteforentryintothesum-of-trees
model. As we shall see in Section 22.4.2, the x components with the larger vis will then be those
that provide the most information for predicting y. A BART approach to model-free interaction
detection proceeds in analogous fashion, for example, let zijk be the proportion of all trees in which
both the ith and jth components of x appear.
22.4 Information extraction: details and examples
In Section (22.3) we outlined the BART model and discussed, in general terms, how it can be
used to extract information about the relationship between y and x. In Section (22.4.1) we provide

Bayesian regression structure discovery
459
additional detail on the CART MCMC, highlighting the crucial aspects of our prior and algorithm
that enable us to find structure. In Section (22.4.2) we give examples of information extraction. We
show how we can extract information about what variables are important (using equation (22.30))
and which pairs of variables work together generating an ‘interaction’ effect.
22.4.1 Stochastic search in CART models
Perhaps the crucial model search step in Section (22.3) is the draw given in (22.26): Tj|Rj, σ. Our
Gibbs sampler MCMC structure allows us to focus on one tree so that we are back to a CART
problem. It is in this step, that we actually modify the structure of a tree. It is in this step, that a new
variable may be introduced to our model.
This draw is done using a Metropolis-within-Gibbs proposal. The CART algorithm given in [1]
uses several types of proposals (see also [15] for additional MCMC strategies).
The essential proposals20 are a complementary BIRTH/DEATH pair of moves. In a BIRTH
proposal, a bottom node of the current tree is chosen and we propose to give it a pair of children.
A nog node of a tree is a tree which has children, but no grandchildren. Thus, both children of a nog
node are bottom nodes. In a DEATH proposal, we choose a nog node from the current tree and we
propose ‘killing its children’. In order to make our general discussion more concrete and document
some of the details, we give the acceptance probability for a BIRTH proposal.
The CART algorithm assumes a discrete set of possible split values for each component of x and
integrates out the bottom node μij so that our Metropolis search in tree space is over a large but
discrete set of possible models. Let T0 denote the current tree and T∗denote the proposed tree.
Thus, T∗differs from T0 only in that one of the bottom nodes of T0 has given birth to a pair of
children in T∗.
Since we are traversing a discrete space, we accept the proposal with Metropolis–Hastings
probability
α = min{1, P(T∗) P(T∗→T0)
P(T0) P(T0 →T∗) }
(22.31)
where P(T0) and P(T∗) are the posterior probabilities of trees T0 and T∗respectively, P(P →T0)
is the probability of proposing T0 while at T∗(a DEATH), and P(T0 →T∗) (a BIRTH) is the
probability of proposing T∗while at T0. P(T0) and P(T∗) will depend on both the likelihood and
our prior, while the transition probabilities depend on the mechanics of our proposal.
First we discuss the likelihood contribution. Let yi denote the observed y in the ith bottom node
given a tree T. Because the μij are iid in our prior we have:
p(y | T) = 	p(yi |Ţ)
(22.32)
Thus the contribution of the likelihood to the ratio P(P)/P(T0) is just
p(yl, yr | T∗)
p(ylr | T0)
= p(yl | T∗) p(yr | T∗)
p(ylr | T0)
(22.33)
where yl denotes the observations in the new left child in T∗, yr denotes the observation in the
new right child in T∗, and ylr denotes {yl, yr}. All other contributions to the likelihoods cancel out
because of the product form of (22.32). Note that all three terms in the right-hand side of (22.33) are
20 The other two proposals in CMG98 are CHANGE and SWAP.

460
H. A. Chipman, E. I. George and R. E. McCulloch
just the predictive densities for a normal mean problem with known variance and normal prior on
the mean.
As with the likelihood, much of the prior contributions to the posterior ratio cancel out since
there is only one place where the trees differ and our stochastic tree growing prior draws tree
components independently at different ‘places’ of the tree. Hence the prior contribution to the
P(T∗)/P(T0) ratio is
(PG) (1 −PGl) (1 −PGr) P(rule)
(1 −PG)
(22.34)
where
• PG: prior probability of growing at chosen bottom node of T0.
• PGl: prior probability of growing at new left child in T∗.
• PGr: prior probability of growing at new right child in T∗.
• P(rule): prior probability of choosing the rule defining the new children in T∗.
Each of the PG quantities is obtained from (22.20). The prior P(rule) places a uniform distribution
on variables and then a uniform distribution on the discrete set of split values associated with the
drawn variable.
Finally, the ratio P(T∗→T0)/P(T0 →T∗), is given by
(PD) (Pnog)
(PB) (Pbot) P(rule)
(22.35)
where
• PD: probability of choosing the death proposal at tree T∗.
• Pnog: probability of choosing the nog node that gets you back T0.
• PB: probability of choosing a birth proposal at T0.
• Pbot: probability of choosing the T0 bottom node such that a birth gets you to T∗.
• P(rule): probability of drawing the new splitting rule to generate T∗’s children.
Our proposal draw of the new rule generating the two new bottom nodes is a draw from the prior.
It is in this draw that variable selection (or, perhaps, variable proposal) occurs! Note that since our
proposal for the rule is a draw from the prior, it cancels out in the ratio (22.31).
The formulas given above correspond very closely to the source code in the BayesTree pack-
age in R. However, there are still many details omitted. For example, a quantity PGl might be
zero if we keep track of which variables in x have been ‘used up’ in that no further splits are
possible.
22.4.2 Variable selection and interaction detection using BART
In this section we illustrate two forms of information extraction. The first is the variable selection
approach given in (22.30). The second, interaction detection, uncovers which pairs of variables
interact in analogous fashion by keeping track of the percentage of trees in the sum in which both
variables occur. This exploits the fact that a sum-of-trees model captures an interaction between xi
and xj by using them both for splitting rules in the same tree.

Bayesian regression structure discovery
461
We illustrate the use of these methods in a simulated example and a real data example. Both
examples are ‘old chestnuts’. Since our goal is interpretation, rather than prediction, we hope the
use of familiar examples eases the path of the reader.
22.4.2.1 The Friedman simulation setup
We simulate n = 500 observations from our basic model
y = f(x) + σ Z, Z ∼N(0, 1)
with x ten-dimensional and
f(x1, x2, . . . , x10) = 10 sin(π x1 x2) + 20 (x3 −0.5)2 + x4 + x5
The xi are iid uniform on (0, 1) and σ = 1.
[6] originally suggested this simulation setup to study the efficacy of nonlinear regression tech-
niques. However, the setup is perfect for illustrating variable selection and the discovery of interac-
tion. Only the first five of the ten x components matter. With ten xs there are 45 possible interaction
pairs. Our simulated data has just one of these possibilities present: only x1 and x2 interact. In a real
application it would be of tremendous interest to know that only these two variables interact, even
without having further knowledge of the functional form.
Results for one simulated dataset are displayed in Figure (22.1). In panel (a) we have variable
selection results. This panel corresponds closely to Figure (5) of [3]. For each variable, we plot the
posterior mean of the percentage of rules (across all m tree) which use that variable. With m = 20,
we very clearly identify the first five variables as being important.
Panel (b) gives the interaction detection results. With ten variables, there are
10
2

= 45 possible
variable pairs. For each pair, we plot the posterior mean of the percentage of trees (out of m)
which use both of the variables in splitting rules. We normalize the m = 20 and m = 200 results
by dividing by each set of 45 posterior means by the maximum. Thus, the largest value displayed
in each case is one. With both m = 20 and m = 200 we clearly identify the first pair (x1 and x2)
as being of interest. With two variables involved, a pair is less likely to come in inconsequentially,
so that the identification of interesting pairs is less sensitive to the choice of m than in the case of
variable selection.
2
4
6
8
10
0.00
0.05
0.10
0.15
0.20
0.25
variable
percent of rules
(a) variable selection
0
10
20
30
40
0.0
0.2
0.4
0.6
0.8
1.0
variable pair
percent of trees (normalized)
(b) interaction detection
m=20
m=200
Figure 22.1 In panel (a) we correctly identify the first five variables as being important. In panel(b) we
correctly identify the first interaction, which corresponds to variables x1 and x2.

462
H. A. Chipman, E. I. George and R. E. McCulloch
22.4.2.2 The Boston housing data
Foranexamplewithrealdataweturntooursecond‘oldchestnut’,theBostonhousingdata.Thedata
were obtained from the R-package mlbench ([12]). There are 506 observations. Each observation
corresponds to neighbourhood. The response is the median house price in the neighbourhood.
There are 13 explanatory variables measuring characteristics of the neighbourhoods. We did a pre-
liminary variable selection (using the approach illustrated in the previous section) and tossed out
three of the xs. Fitted values (from BART) with and without the three xs are very similar.
Figure (22.2) displays the results of the interaction detection. The format is the same as in panel
(b) of Figure (22.1). Several pairs of interest are identified. Our real data has more interesting
structurethanoursimulateddata!Wewillinvestigatethepairdisandlstatsimplybecausethese
variables are more easily understood. dis is the ‘weighted distances to five Boston employment
centres’. lstat is the “percentage of lower status of the population”.
In Figure (22.3) we attempt to see graphically the interaction between dis and lstat suggested
byFigure(22.2).Inpanel(a)weplotdisvs.lstat.Foursubsetsofpointsareidentifieddepending
on whether dis and lstat are ‘low’ or ‘high’. The points in the four subsets are plotted with a,b,c,
or d while the rest of the points are plotted with a small circle. In the (b) panel we plot the fitted
values from the BART run with m = 200. Before fitting we subtracted off the average response so
the vertical axis is actually the amount the median value for a neighbourhood is above the average.
The four boxplots correspond to the four data subsets indicated in panel (a).
So, for example, the first boxplot displays the fitted prices when both ds and lstat are low. The
observations included here correspond to those highlighted in the bottom left corner of panel (a).
The label ‘dL_lL_a’ indicates that ds is Low and lstat is Low and the observations correspond
to those plotted with a in panel (a). Similarly, the third boxplot is labelled ‘dH_lL_c’, indicating
that ds is High and lstat is Low and the points are plotted with the symbol c in panel (a).
The first pair of boxplots indicate the effect of increasing lstat when ds is low. The second pair
of boxplots indicate the effect of increasing lstat when ds is high. Clearly, the boxplots indicate a
strong interaction. For low dl, the effect of the change in lstat is much more pronounced. A nice
neighbourhood close to the city centre is highly desirable whereas a bad neighbourhood close to
the city centre may be very bad.
0
10
20
30
40
0.0
0.2
0.4
0.6
0.8
1.0
variable pair
percent of trees (normalized)
interaction detection
m=20
m=200
(rad,rm)
(lstat,nox)
(lstat,dis)
Figure 22.2 Interaction detection for the Boston housing data with ten explanatory variables.

Bayesian regression structure discovery
463
2
4
6
8
10
12
10
20
30
 dis
 lstat
(a) ds vs. lstat
yhat_dL_lL_a
yhat_dL_lH_b
yhat_dH_lL_c
yhat_dH_lH_d
−10
0
10
20
(b) fitted values of median house prices
Figure 22.3 In panel (a) we identify four subsets of our data by whether each of ds and lstat are low
or high. In panel (b) the boxplots display the fitted values (median house values) for the observations
in the four subsets. The average of the dependent variable was subtracted off so that the vertical axis
is the amount the median value of a neighbourhood is above average. The first pair of boxplots both
have low values of dis. The first box has low values of lstat and the second box has high values
of lstat. The second pair of boxplots again compare low and high lstat but now ds is high.
22.5 Discussion and beyond
Thediscoveryofregressionstructureisanimportantanddifficultproblemforallapproachestodata
analysis. With our modern computational tools it has become even more important. However, in a
sense, it has also become more difficult, as we struggle to grapple with complex, high-dimensional
models.
In this article, we describe and contrast two different Bayesian approaches that illustrate the vast
potential of Bayesian methods to extract information hidden in high-dimensional data. The first is

464
H. A. Chipman, E. I. George and R. E. McCulloch
based on the classical parametric form of the normal linear model, while the second is based on a
rich overparameterized sum-of-trees model, nonparametric in nature. In our examples, we show
that even though the overall BART sum-of-trees model is complex, the simple structure of the
individual tree components enables us to uncover structure with inferential posterior summaries.
Inparticular,wehaveshownhowBARTprovidesanovelapproachtomodel-freevariableselection,
the search for interesting variables, and model-free interaction detection and the search for interest-
ing pairs of variables. Going beyond what we have presented here, the companion pieces by Clyde
and Iversen (Chapter 24 in this volume) and Gramacy (Chapter 23 in this volume) in this volume,
shed new light on directions for the development of Bayesian methods for grappling with model
uncertainty.
As laid out by Clyde and Iversen (see Chapter 24), the general Bayesian formulations for dealing
withmodeluncertainlyincludesourparametricBayesianformulationforvariableselectionasaspe-
cial case. An important issue there is whether the class of models under consideration includes the
actual data generating model. When it does, the so-called M-closed setting, the implicit posterior
model probabilities make sense. This will be the case in our parametric Bayesian variable selection
framework when it is valid to assume that the complete data was generated by normal linear model
(with possibly some zero coefficients). However, it may often be more realistic to allow that the
unknown actual model is outside the class under consideration, the so-called M-open setting.
This is precisely the linear model assumption limitation which we alluded to earlier, that a subset of
actuallyrelatedpredictorsmaybeignoredsimplybecausetherelationshipisnotlinear.Recognizing
that the general limitation of using conventional Bayesian machinery for the M-open setting,
Clyde and Iversen consider alternatives to obtaining the weights corresponding to the conventional
setting’s posterior model probabilities. For this purpose they propose principled decision theoretic
cross-validation approaches for selection of weights that optimize model averaged predictions.
A key message in Gramacy (see Chapter 23) is the central role played by the prior formulation
in Bayesian variable selection. Indeed, the structured hierarchical mixture prior of Section 22.2.1 for
the normal linear model, and the regularization prior of Section 22.3.1 for BART are essential for
the effectiveness of these approaches. In both cases, it is necessary to use sensible hyperparameter
values that balance ‘null-versus-alternative’ possibilities in a way that allows the variable selection
information in the data to emerge. Gramacy speaks of this in discussing the prior allocations that
must be balanced in a variety of structured hierarchical mixture priors for the linear model, priors
with coefficient marginals that are both concentrated near 0 and heavy-tailed, similar in spirit to the
lasso. By concentrating prior probability near zero, strong input from the data is needed to escape a
neighbourhood about zero. However, once the estimate has escaped from zero, the heavy tails allow
it to wander far. Going further, Gramacy shows how latent variable formulations allow extension of
theapproachestonon-normalerrorsandbinaryobservations.ConvenientandefficientGibbssam-
plingalgorithmsforposteriorcomputationaredetailedthroughoutallowingGramacytoargueper-
suasively that these Bayesian approaches are powerful tools in our modern data rich environment.
Acknowledgement
The authors are grateful to Adam Kapelner for valuable suggestions.
References
[1] Chipman, H. A., George, E. I. & McCulloch, R. E. (1998), Bayesian CART model search,
Journal of the American Statistical Association 93, 935–948.
[2] Chipman, H. A., George, E. I. & McCulloch, R. E. (2001), The practical implementation of
Bayesian model selection, in P. Lahiri, ed., Model Selection, Vol. 38 of IMS Lecture Notes –
Monograph Series, Institute of Mathematical Statistics, Beachwood, OH, pp. 65–116.

Bayesian regression structure discovery
465
[3] Chipman,H.A.,George,E.I.&McCulloch,R.E.(2010),BART:Bayesianadditiveregression
trees, Annals of Applied Statistics 4(1), 266–298.
[4] Clyde, M. & George, E. I. (2004), Model uncertainty, Statistical Science 19, 81–94.
[5] Cui,W.&George,E.I.(2008),EmpiricalBayesvs.fullyBayesvariableselection,Statist.Plann.
Inference 138, 888–900.
[6] Friedman, J. H. (1991), Multivariate adaptive regression splines (Disc: P67-141), The Annals
of Statistics 19, 1–67.
[7] Gelfand, A. E. & Smith, A. (1990), Sampling-based approaches to calculating marginal densi-
ties, Journal of the American Statistical Association 85, 398–409.
[8] George, E. I. & McCulloch, R. E. (1993), Variable selection via Gibbs sampling, Journal of the
American Statistical Association 88, 881–889.
[9] George,E.I.&McCulloch,R.E.(1997),ApproachesforBayesianvariableselection, Statistica
Sinica 7, 339–374.
[10] Liang, F., Paulo, R., Molina, G., Clyde, M. A. & Berger, J. O. (2008), Mixtures of g-priors for
Bayesian variable selection, Journal of the American Statistical Association 103, 410–423.
[11] Maruyama, Y. & George, E. I. (2011), Fully Bayes factors with a generalized g-prior, Annals of
Statistics 39(5), 2740–2765.
[12] R Development Core Team (2011), R: A Language and Environment for Statistical Computing,
R Foundation for Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0.
[13] Scott, J. G. & Berger, J. O. (2010), Bayes and empirical Bayes multiplicity adjustment in the
variable selection problem, Ann. Statist 38, 2587–2619.
[14] Tierney, L. (1994), Markov chains for exploring posterior distributions, Ann. Statist
22, 1701–1762.
[15] Wu, Y., Tjelmeland, H. & West, M. (2007), Bayesian CART: Prior specification and posterior
simulation, Journal of Computational and Graphical Statistics 16, 44–66.
[16] Zellner, A. (1986), On assessing prior distributions and Bayesian regression analysis with
g-priordistributions,inBayesianInferenceandDecisionTechniques,Stud.BayesianEconometrics
Statist, Vol. 6, North-Holland, Amsterdam, pp. 233–243.

23
Gibbs sampling for
ordinary, robust and
logistic regression with
Laplace priors
robert b. gramacy
23.1 Introduction
W
hereas the advent of fast and cheap computation signalled a turning point in Bayesian
statistical inference at the end of the last century, today a further technological advance
is defining a new era. Data is now gathered on a massive scale. Examples include stock prices for
thousands of assets at almost any resolution, text or images from web pages added to the internet
in nearly continuous time, or genetics studies involving DNA sequencing and the like. Regression
and classification, as ever the work horse of statistical inference, still play a major role. However,
modern applications usually involve regressions or classifications where the number of predictors,
p, in xi = (xi1, . . . , xip)⊤, is large. To help select relevant predictors, and also to obtain stable
predictions, it is widely accepted that restrictions need to be placed on the parameters, e.g. the
regression coefficients, in the model. In classical statistics this is what is meant by regularization.
In Bayesian statistics it simply means deploying informative priors.
As one example, consider estimating the covariance of asset returns for balancing portfolios.
Varying lengths of historical price information are available because some companies/indices have
been publicly traded for longer than others. It has been illustrated that the appropriate estimators
for this problem involve OLS regression as a subroutine [30]. However, scaling up to thousands
of assets requires that the regressions be regularized [17]. Better still, a fully Bayesian approach
with Laplace priors, discussed below, has been shown to produce superior regression estimators
and more profitable portfolios [15]. These fully Bayesian estimators heavily leverage the technique
of data augmentation and, thereby, Gibbs sampling [9]—historically, the first MCMC technique
deployed for Bayesian inference.
Although such problems/applications are modern, the methods used to solve them were in fact
so well established they had been forgotten (at least by some). They leveraged techniques from the
80s and 90s, making heavy use of Gibbs sampling algorithms that were abandoned when the sledge
hammer of the Metropolis–Hastings (MH) sampler and other more generic algorithms came
along. Logistic regression is another example. Many texts [e.g. 10] taught early twenty-first-century

Gibbs sampling for regression with Laplace priors
467
graduate students that MH and approximate methods were best suited to GLMs, implying that
Gibbs sampling was not an option. But then [22] showed that a data augmentation/Gibbs sampling
scheme, similar to the one for the Laplace and in the style popularized in the 90s, gave better
MCMCperformancethanMH.Therehavesincebeenmanyadvancesonthesefronts.Forexample,
a natural extension pairing the Gibbs samplers for logistic regression with those of Laplace priors
for regularization [16] enables fully Bayesian inference for large classification problems like those
needed for text classification [31].
This paper reviews the ideas behind the Gibbs samplers for both OLS and logistic regression
underregularization,focusingontheLaplaceprior.Section23.2considersOLSwithextensionsthat
allowformodelselectionandaveraging,andheavy-tailederrorsforrobustestimation.Examplesare
provided using the implementation in the R package called monomvn, available on CRAN. Section
23.3 covers similar routines for logistic regression, with examples illustrated via the reglogit
package. Finally, the paper concludes in Section 23.4 with references to further extensions to these
methods.
23.2 Bayesian shrinkage regression
Consider the typical linear regression model:
y = β01n + Xβ + ϵ,
where
ϵ ∼Nn(0, σ 2In)
(23.1)
To keep the discussion simple, assume a standardized n × p design matrix X where the columns are
individuallyadjustedtohavezero-meanandunitL2-norm.Thiscausesβ0 andβ tobeindependent
a posteriori and recognizes that regularized posterior summaries for β are not equivariant under a
re-scaling of X.
The lasso estimator [e.g. 21, Section 3.4.3] is the solution to an ordinary least squares criteria
subject to an L2 penalty on the regression coefficients:
ˆβ = argminβ
⎧
⎨
⎩(˜y −Xβ)⊤(˜y −Xβ) + λ
p

j=1
|βj|
⎫
⎬
⎭
(23.2)
for some λ ≥0. The intercept is excluded from penalization via ˜y = y −¯y1n. There is no closed
formsolutionfor ˆβ,buttheentirepathofsolutionsforallλcanbeobtainediterativelyviatheLARS
algorithm [6]. The estimator may be interpreted as the posterior mode under and i.i.d. Laplace
(i.e. double-exponential) prior for each βi: π(β(1)|σ 2) = 	p
j=1
λ
2
√
σ 2 e−λ|β(1)
j
|/
√
σ 2. Estimators
so obtained, either via the MAP or otherwise, are shrunk towards zero compared to their OLS
alternativesbyanamountthatdependsonthevalueofthepenaltyparameter, λ.Aparticularfeature
ofthelasso,i.e.theMAPsolution(23.2),isthat ˆβ mayhavemanycoefficientsshrunktoexactlyzero,
which is convenient for variable selection. Often,λ is chosen via cross-validation (CV). Calculating
the posterior mean estimator, or using the posterior distribution to choose the penalty parameter,
λ, requires more work.
23.2.1 Hierarchical models for Bayesian shrinkage regression
For a fully Bayesian lasso, there is a latent variable formulation [3, 29] that represents the Laplace as
a scale mixture of normals:

468
R. B. Gramacy
y|β0, X, β, σ 2 ∼Nn(β01n + Xβ, σ 2In)
Dτ = diag(τ2
1 , . . . , τ2
p )
(23.3)
β|σ 2, τ2
1 , . . . , τ2
p ∼Np(0, σ 2Dτ ), β0 ∝1
σ 2 ∼IG(aσ /2, bσ /2)
τ2
j |λ2 iid
∼Exp(λ2/2)
λ2 ∼G(aλ, bλ)
IG and G are the rate- and scale-parameterized inverse-gamma and gamma distributions, respec-
tively. The default prior π(σ2) ∝σ −2 is obtained with aσ = bσ = 0.
Since the full conditionals for all of the parameters are of a standard form, Gibbs sampling (GS)
is an obvious choice for MCMC.
β0|σ 2, y ∼N(¯y, σ 2/n)
β|σ 2, {τ 2
j }p
j=1, y ∼Np( ˜β, σ 2A−1),
A = X⊤X + D−1
τ , ˜β = A−1X⊤˜y
σ 2|β, {τ 2
j }p
j=1, y ∼IG((aσ + n −1 + p)/2, (bσ + ψβ)/2),
ψβ = ||˜y −Xβ||2 + β⊤D−1
τ β
τ −2
j
|βj, σ 2, λ
iid∼Inv-Gauss(
;
λ2σ 2/β2
j , λ2)
(23.4)
λ2|τ 2
1 , . . . , τ 2
p ∼G(aλ + pγ , bλ/γ + p
j=1 τ 2
j /2)
Usingamarginalposteriorconditionalforσ 2 insteadcanhelpreduceautocorrelationintheMarkov
chain. Integrating over the posterior conditional for β gives
σ2|τ2
1 , . . . , τ2
p , y ∼IG((aσ + n −1)/2, (bσ + ψ ˜β)/2),
where ψ ˜β = ||˜y −X ˜β||2 + ˜β⊤D−1
τ
˜β = ˜y⊤˜y −˜β⊤A ˜β
An alternative hierarchical modelling framework for the Bayesian lasso is provided by [20]. While
it does not require p latent τ2
j variables, the resulting GS procedure is not fully blocked, and rejec-
tion sampling is required for σ 2. ‘Orthogonalizing’ the sampler helps mitigate slow mixing of the
un-blocked conditionals, and the resulting sampler is believed to be superior in such contexts. The
current discussion focuses on the approach of [29] as it is more readily adaptable to some of the
extensions, like heavy-tailed errors and model selection, described below.
Whereas the classical lasso has the property that the estimate ˆβ may have components which are
zero—in fact, it would never have more than min{p, n −1} non-zero components—samples of β
from the posterior would never have zeros. So the Bayesian lasso is less useful for variable selection.
We also note that when p ≥n—and without the ability to explicitly restrict β to having at most
min{p, n −1} non-zero components—a proper prior must be used for σ2 or the posterior will be
improper.AnempiricalBayesremedythatworkswellinthiscaseistotakeasmallaσ ,sayaσ = 3/2,
and then set bσ so that the (1 −α) part of the IG(aσ , bσ ) distribution lies at the point ˜y⊤˜y (i.e.
the MLE under the intercept model) via the incomplete gamma inverse function. Another remedy
is Bayesian model averaging.
23.2.2 Bayesian model selection and averaging
Although the MAP lasso fit may indeed set some of the coordinates of ˆβ(1) to zero, this is more
of a side effect of the solution space of the quadratic program (23.2) than the result of a deliberate
prior modelling choice [20]. Bayesians rarely base inference on the MAP; it is more natural to select
variables by inspecting the posterior model probabilities.

Gibbs sampling for regression with Laplace priors
469
There are several standard ways of performing Bayesian variable selection in regression models
that are amenable to GS. They essentially fall into two camps. Loosely, the first camp [e.g. 12, 14]
employs a product-space wherein the prior for each βj is augmented to include a point-mass at
zero. Inference proceeds by GS on each of the conditionals βj|β−j, y, . . . , j = 1, . . . , p, which may
flop between zero and non-zero values. [20] augmented this product space approach to variable
selection under the Laplace prior by further conditioning on λ.
The second camp [e.g. 32] is transdimensional in that the β-vector may vary in length while
model space is traversed via Reversible Jump (RJ) MCMC [18]. An advantage of this approach
is that, when p ≫n, it is implementationally more compact, only requiring memory for the
(non-zero) β-components. This can represent a huge saving in some contexts like large-scale port-
folio balancing [15]. Another advantage is that it emits fully blocked sampling for the non-zero
components of β for within-model moves.
Suppose that the transdimensional Markov chain is currently visiting a model with k non-zero
regressioncoefficientsβk = (β1, . . . , βk)usingdesignmatrixXk.ThecolumnsofXk shouldcome
from a two-way partition (of k and p −k elements) of the p columns of X, but they need not
coincide with the first k of the p columns. Now consider proposing to add a column to Xk. Choose
one of the p −k columns of X not present in Xk for addition, thus creating Xk+1. By considering
the ratio of the marginal posterior distributions (integrating out βk and βk+1) conditional on
σ2, τ2
1 , . . . , τ2
k and a new proposed τ2
k+1 (which can be taken from the prior), the move may be
accepted with probability min{1, Ak→k+1}, where
Ak→k+1 =
(τ−2
k+1|A−1
k+1|)
1
2 exp

1
2σ 2 ˜β⊤
k+1Ak+1 ˜βk+1

|A−1
k |
1
2 exp

1
2σ 2 ˜β⊤
k Ak ˜βk

q(τ2
k+1)
× π(k + 1)q(k + 1 →k)
π(k)q(k →k + 1)
(23.5)
and Ak = X⊤
k Xk + D−1
τk , ˜βk = A−1
k X⊤
k ˜y, with Dτk = diag(τ2
1 , . . . , τ2
k ). The reverse, of propos-
ing to remove one of the columns of Xk, may be accepted with probability min{1, A−1
k−1→k}.
A uniform prior over all models with k non-zero components is typical, but there are other
options [see, e.g. 12, 15, 20]. Movement throughout the 2p-sized space is slow for large p, so a
certain amount of thinning of the RJ-MCMC chain is appropriate. Collecting a sample from the
posterior after p transdimensional moves approximates the model-level mixing (and computation
burden) of the product-space approach. Throughout the RJ-MCMC the length of β varies, and
the components shift to represent the partition of X stored in the columns of Xk. The posterior
probability that variable j, j = 1, . . . , p, is relevant for predicting y can be approximated by the
proportion of time that Xk contains variable j.
23.2.3 Student-t errors via scale-mixtures
The MVN assumption is not always appropriate. Instead, one may wish to consider the possibility
that errors in y have a Student-t distribution with an unknown degrees of freedom ν: y = β01n +
Xβ + ϵ, {ϵi}n
i=1
iid
∼St(0, σ 2; ν). Following [4] and [13], it is convenient to represent the Student-t
distribution as a scale mixture of normals with an IG(ν/2, ν/2) mixing density.
We must redefine X = (1n, X) as a n × (p + 1) matrix, β = (β0, β⊤)⊤= {βj}p
j=0 so that the
model becomes y = Xβ + ϵ since the posterior intercept β0 is no longer independent of the other
components of β in the presence of heavy-tailed errors. The setup is otherwise unchanged from
Section 23.2.1. Upon assuming an exponential prior for the degrees of freedom parameter, ν, the
modifications to the hierarchical model in Eq. (23.3) are:

470
R. B. Gramacy
y|X, β, σ 2, {ω2
i }n
i=1 ∼Nn(Xβ, σ 2Dω)
Dω = diag(ω2
1, . . . , ω2
n)
(23.6)
β|σ 2, {τ2
j }p
j=1 ∼Np+1(0, σ 2Dτ )
Dτ = diag(∞, τ2
1 , . . . , τ2
p )
ω2
i |ν iid
∼IG(ν/2, ν/2)
ν|θ ∼Exp(θ)
Note that Dτ is a p + 1 diagonal matrix, and that the first component insures that β0 is given a
flat prior as before. After redefining A = X⊤D−1
ω X + D−1
τ , ˜β = A−1X⊤D−1
ω y and ψβ = (y −
Xβ)⊤D−1
ω (y −Xβ) + β⊤D−1
τ β, the modified full posterior conditionals follow:
β|σ 2, {τ2
j }p
j=1, {ω2
i }n
i=1, y ∼Np+1( ˜β, σ2A−1)
(23.7)
σ 2|β, {τ2
j }p
j=1, {ω2
i }n
i=1, y ∼IG
aσ + n + p
2
, bσ + ψβ
2

ω2
i |β, σ 2, ν, y iid
∼IG
ν + 1
2
, ν + σ −2((y −Xβ)i)2
2

p(ν|{ω2
i }n
i=1, θ) ∝
ν
2
 nν
2 

ν
2
−n
exp(−ην)
where η = 1
2
n
i=1(log(ω2
i ) + ω−2
i
) + θ
The conditional posterior of ν does not have a standard form, but there is an efficient rejec-
tion sampler [13]. A draw from ν ∼Exp(ν∗), where ν∗is chosen optimally as the root of
(n/2)[log(ν/2) + 1 −(ν/2)] + ν−1 −η, may be retained with probability
min

1,
1(ν∗/2)
(ν/2)
2n 1 (ν/2)ν
(ν∗/2)ν∗
2n/2
exp[(ν −ν∗)((ν∗)−1 −η)]

As before, integrating out β gives σ 2|{τ2
j }p
j=1, {ω2
i }n
i=1, y ∼IG((aσ + n −1)/2, (bσ + ψ ˜β)/2)
by redefining ψ ˜β = (y −X ˜β)⊤D−1
ω (y −X ˜β) + ˜β⊤D−1
τ
˜β = y⊤D−1
ω y −˜β⊤A ˜β, leading to a
moreefficientsampler.Finally,theBayesianmodelselectionandaveragingmethodofSection23.2.2,
via equation (23.5), may be used with Xk = (1n, Xk), βk = (β0, β⊤
k )⊤, ˜βk = A−1
k X⊤
k D−1
ω y and
Ak = X⊤
k D−1
ω Xk + D−1
τk and Dτk = diag(∞, τ 2
1 , . . . , τ2
k ). The number of latent variables now
grows with the sample size, so automatic O(n) thinning from the Markov chain is sensible.
23.2.4 Empirical results on detecting fat tails
[20] offers a plethora of insights about the Bayesian lasso with comparison to the classical lasso.
There is no need to re-produce these results here. Instead we offer a demonstration focusing on
Student-t extensions. One can follow along with this example, on the diabetes data [6], via the help
file for blasso in the monomvn package.
Considertestingthenullhypothesis(modelMN)ofnormalerrorsversusthealternative(model
MSt) that they follow a Student-t with ν ∼Exp(θ = 0.1) a priori. Jacquier et al. [23, Section 2.5.1]
show how to exploit that the Student-t and normal models differ by just one parameter in the
likelihood, ν, to calculate a Bayes factor (BF) for MN over MSt as the expectation of the ratio
of un-normalized posteriors using samples from the Student-t model. That is,

Gibbs sampling for regression with Laplace priors
471
nu histogram
nu samples
Frequency
0
20
40
60
80
100
120
0
200
400
600
800
1000
0
50
150
250
350
20
60
100
nu trace
t
nu
Figure 23.1 Histogram (top) and trace plot (bottom) for samples from marginal posterior for ν, the
degrees of freedom parameter in the Student-t model for the diabetes data.
E
 p(y|ψ, MN)
p(y|ψ, ν, MSt)

≈1
T
T

t=1
p(y|ψ(t), MN)
p(y|ψ(t), ν(t), MSt)
,
where
(ψ(t), ν(t)) ∼p(ψ, ν|y, MSt)
and where ψ collects the parameters shared by both models.
Doing this calculation on the diabetes data leads to a BF of essentially zero, showing ‘decisive’
evidence in favour of MN under reasonable priors [see 15]. Figure 23.1 shows that, after burn-in,
the mixing was very good for ν (marginally) under MSt, starting at ν(0) = 1/θ. It is easy to see
now MN is favoured, since most of the posterior density is allocated to ν > 10. Figure 23.2 shows
thatthemixinginmodelspace(underMSt),throughthemodelorderkstartingat k(0) = 0,isalso
very good.
Figure 23.3 summarizes the posterior distribution of the coefficients of β and μ ≡β0, offering a
comparison to point estimates obtained under OLS and classical MLE/CV lasso, and the Bayesian
MAP. Observe that for β1, β2, β6, β8, and β10 the classical lasso solution and MAP agree that the
regression coefficient in question is zero. They disagree on β5 and β7 where one regards it as zero
and the other does not. Finally, they agree that the rest (β3, β4, and β9) are non-zero. Also observe
that posterior distribution(s) are not symmetric, as expected under a Laplace prior and that, in the
case of β7, the sign of the OLS estimate is at odds with the posterior density. The probabilities that
β|y are non-zero are shown below the plot in Figure 23.3, demonstrating how the fully Bayesian
approach, in contrast to the lasso–CV approach, offers full accounting in uncertainty in variable
selection.

472
R. B. Gramacy
k histogram
k samples
Frequency
0
2
4
6
8
10
0
100
200
300
0
200
400
600
800
1000
0
4
8
k trace
t
k
Figure 23.2 Histogram (top) and trace plot (bottom) for samples from the marginal posterior for the
model order parameter k ∈{0, 10} for the diabetes data.
mu
b.1
b.2
b.3
b.4
b.5
b.6
b.7
b.8
b.9
b.10
–1000
–500
0
500
1000
Boxplots of regression coefficients
coef
blasso map
lasso
lsr
Figure 23.3 Summarizing samples from the posterior distribution of β under the Bayesian lasso
model averaging prior on the diabetes data. The top plot summarizes the marginal posterior of
the components βj, j = 1, . . . , 10 and intercept μ ≡β0 via boxplots; the bottom table shows the
posterior probability that the components βj are, marginally, non-zero.

Gibbs sampling for regression with Laplace priors
473
0
200
400
600
800
1000
0
20
40
60
80
100
n
frequency of correct model selection
normal
=3
=5
=7
=10
Figure 23.4 Frequency of correct model determinations as a function of the sample size, n, and the
degrees of freedom parameter, ν, where ‘normal’ is interpreted as ν = ∞.
To shed light on the ‘selectability’ of the Student-t model, consider synthetic data where β =
(2, −3, 0, 0.75, 0, 0, −0.9)⊤, μ ≡β0 = 1, the rows of the n × 7 design matrix X are uniformly
distributed in [0, 1]7, and ϵi ∼St(0, σ 2 = 1; ν), for i = 1, . . . , n. Consider a Monte Carlo exper-
iment where n and ν vary, with n ∈{30, 75, 100, 200, 500, 1000} and ν ∈{3, 5, 7, 10, ∞}, and the
frequency of times that the BF indicated ‘strong’ preference for the correct model in repeated trials.
In each trial, GS (23.7) was used to obtain 1200 samples from the posterior by thinning every 7n
rounds, with the first 200 discarded as burn-in. For n ≤200 we repeated the experiment with
random data 300 times; when n = 500 we used 50 replications; and when n = 1000 we used 20.
Figure23.4showstherelationshipsbetweenn,ν andthefrequencyofcorrectmodeldeterminations
(higher frequencies are better). In the case of normal errors, and Student-t errors with ν = 3, the
correct model can be determined with high accuracy when n ≥200. When ν = 5, a sample size of
n = 1000 is needed; when ν = 7, 10 we need n ≫1000. Clearly for 10 ≤ν < ∞the situation is
hopeless unless n is very large. The conclusion is that the dataset must be huge, and simultaneously
the degrees of freedom small, in order for the returns on investment in the extra latent variables in
the Student-t model to be realized.
23.3 Logistic regression
Now consider a set of binary responses, yi, encoded as ±1, regressed on p-dimensional predictors
xi via the model P(yi = ±1|xi, β) = (1 + exp{−yix⊤
i β})−1, for i = 1, . . . , n. For a review of
Bayesianapproachestologisticregressionsee,e.g.[22][HHhereafter]and[8].AsintheOLSsetup,
when p is large it is paramount to infer β under regularization or penalization. Mirroring (23.2), a
common formulation [e.g., 11, 26, 28] in this context is
ˆβ = argminβ
⎧
⎨
⎩
n

i=1
ln

1 + exp{−yix⊤
i β}

+ ν−1
p

j=1
&&βj
&&
⎫
⎬
⎭
(23.8)

474
R. B. Gramacy
Theparameterν dictatestheamountofregularization,ortherelativepull(ν−1)orshrinkageofthe
βjs towards zero.21 Borrowing from the OLS literature, [27] discuss how the LARS algorithm can
beusefulasasubroutineforthepopularcaseofα = 1.Again,itistypicaltoworkwithxi pre-scaled,
and not penalize the intercept.
We consider the following power-posterior distribution inspired by equation (23.8):
πκ(β|y, ν, ) = Cκ,(ν) exp
⎧
⎨
⎩−κ
⎛
⎝
n

i=1
ln

1 + exp{−yix⊤
i β}

+ ν−1
p

j=1
&&βj
&&
⎞
⎠
⎫
⎬
⎭
(23.9)
The placement of κ in the subscript in πκ and Cκ(ν), a normalization factor, signals that it is user
specified, not a parameter to be estimated. We call κ the multiplicity parameter,but it is known as the
thermodynamic parameter the simulated annealing literature [see, e.g. 25]. It is a tool that facilitates
several types of simulation based inference, as we shall describe. The discussion centres around the
following likelihood–prior combination which, together with Bayes’ rule, yields the expression in
equation (23.9).
Lκ(y|β) = exp

−κ
n

i=1
ln

1 + exp{−yix⊤
i β}

=
n

i=1

1 + exp{−yix⊤
i β}
−κ
(23.10)
pκ(β|ν) ∝exp
⎛
⎝−κν−1
p

j=1
|βj|
⎞
⎠=
p

j=1
exp

−κ
&&&&
βj
ν
&&&&

.
Power-posterior analysis can be helpful for calculating modes and posterior means from complex
optimization criteria, and marginal likelihoods for Bayesian estimators. See [16] for more details
on these procedures. The focus here is on how κ can be used to obtain an efficient computational
frameworkforbinomialregression,wheremultiplebinaryresponsesarerecordedforeachpredictor
which is what motivates calling κ the multiplicity parameter. For the immediate discussion, how-
ever, let κ be fixed.
23.3.1 Representing the likelihood and prior
Extending a well-known result by [22], [16] recognized the likelihood (23.10) for β as a marginal
quantity obtained after integrating over latent variables (z, λ), where z = (z1, . . . , zn) and λ =
(λ1, . . . , λn). Briefly, one recognizes that each component (1 + exp{−yix⊤
i β})−κ of the like-
lihood can be written as the cumulative distribution function (cdf) evaluation (at zero) of a
particular z-distribution [2]. For details see [16]. This implies a hierarchical model obtained by
mixing
zi|β, λi, yi, κ ∼N +

yix⊤
i β + 1
2(1 −κ)λi, λi

,
over a particular λi ∼q1,κ
(23.11)
where N + indicates the normal distribution truncated to the positive real line. The mixing density
qa,b has a messy expression, but simple generative form:
21 Note that ν = λ−1 from Section 23.2.1. We have chosen to stay closer to the notation in [16], who use λ
for a different quantity.

Gibbs sampling for regression with Laplace priors
475
λ D=
∞

k=0
2ψ−1
k
ϵk,
where
ϵk ∼Exp(1),
and
ψk = (a + k)(b + k)
(23.12)
In
more
compact
notation:
z|β, λ, y, κ ∼N +
n ((y.X)β + 1
2(1 −κ)λ, ),
where
y =
(y1, . . . , yn)⊤, y.X = diag(y)X, # = diag(λ1, . . . , λn), and truncation is to the all-positive
orthant. The κ = 1 the case is identical to the generative model described by HH, where
yi = sign(zi),
where
zi ∼N(x⊤
i β, λi)
and
λi =
∞

k=1
2
(1 + k)2 ϵk,
ϵk
iid
∼Exp(1).
(23.13)
When κ > 1, the asymmetry of the z-distribution makes it harder to extract yi from yix⊤
i β +
1
2(1 −κ)λi,themeanofthetruncatednormalinequation(23.11).However,resultsinSection23.3.3
indirectly suggest that one can interpret κyi as a binomial response for integer κ.
The data augmentation scheme for the (power-) prior is very similar to the OLS setup. The
essence is to consider βj = ν
κ σj√τjϵj, where τj ∼p(τ) and ϵj
iid
∼N(0, 1). Observe that small ν
(i.e. heavy regularization) and large κ (i.e. heavy concentration of power-posterior density around
the mode at the origin) both shrink βj towards zero. Adapting a result from [33] to account for κ, we
have that if τj
iid
∼Exp(2) then pκ(β|ν) is Laplace with a mean of zero and a scale of ν2/κ2. There
are two reasonable choices for ν ∼pκ(ν) which lead to efficient inference by Gibbs sampling if we
wishtofullyaccountforitsuncertainty,ratherthanfixittoaparticularvalue,sayviaCV.Oneoption
is an inverse gamma (IG) prior for ν2 with shape rκ = κ(r + 1) −1 and scale dκ = κd, where
κ = 1 yields a base IG(ν2; r, d) prior. The second option is IG for ν, with identical powering-up
identities. It has lighter tails in ν−1, thus providing more aggressive shrinkage.
23.3.2 Simulation-based inference
We develop the posterior conditionals for sampling from power-posterior pκ(β, z, τ, λ, ν|y), for
any κ, thereby describing a Gibbs sampling algorithm. When κ = 1 the marginal samples of β
summarize the posterior distribution of the main parameters of interest. To obtain the MAP esti-
mator or MLE requires establishing an inhomogeneous Markov chain, which is left to our refer-
ences. Section 23.3.3 describes how a vectorized κ can be used for efficient inference with binomial
responses.
By construction (23.11), the posterior full conditional for the latent zi|λi, . . . is a truncated
(non-negative) normal distribution. HH derive an expression for λi|zi, . . . when κ = 1 and pro-
vide a rejection sampling algorithm by squeezing. Although this works for general κ, there is a sim-
pler, yet radically different, Rao–Blackwellized approach which involves an alternate z-distribution
result [see 16]. A proposal λ′
i ∼q1,κ(λ) from the mixing density with probability may be accepted
with probability min{1, Ai} where
Ai =
{(−yix⊤
i β −1
2(1 −κ)λ′
i)/
;
λ′
i}
{(−yix⊤
i β −1
2(1 −κ)λi)/√λi}
(23.14)
The easiest way to simulate from q1,κ is approximately, by truncating the sum in equation (23.12)
at K = 100 or so. There are many reasons to prefer a MH-within-Gibbs approach to the rejec-
tion/squeezing method of HH. But the most important reason, beyond implementational and

476
R. B. Gramacy
computational simplicity, is that drawing λi unconditional on zi yields lower autocorrelation in the
overall joint MCMC sampling scheme.
The MVN mixing for z and priors for β combine to give that β|z, τ, λ, ν, κ ∼Np( ˜β, V) where
˜β = V(y.X)⊤−1 (z −(1 −κ)λ/2), and V−1 = (ν/κ1/α)−2−1D−1
τ
+ (y.X)⊤−1(y.X).
The full conditional distribution of τj is given by
pκ(τj|βj, ν) ∝
1
72πτj
exp

−1
2
 κ2β2
j
ν2σ 2
j τj
+ τi

≡GIG

τj; 1
2, 1,
κ2β2
j
ν2σ 2
j

which implies that τ−1
j
∼Inv-Gauss

ν
κ
&&& βj
σj
&&& , 1

. Finally, the IG priors for ν are both condition-
ally conjugate. We have,
ν2|β, τ, κ ∼IG
⎛
⎝rκ + κp
2 , dκ + κ2
2
p

j=1
β2
j
σ 2
j τj
⎞
⎠
or
ν|β, κ ∼IG
⎛
⎝rκ + κp, dκ + κ
p

j=1
&&&&
βj
σj
&&&&
⎞
⎠
depending on whether the prior for ν2 or ν is chosen, respectively. Observe that the latter leads to
efficiency gains (in addition to better tail properties) since we do not need to condition on τ, and
therefore this extends the analysis of [29].
23.3.3 Efficient handling of binomial data
Often, binary response data are collected repeatedly and independently for identical subjects, i.e.
with the same covariates x. For example, consider having observed yi|xi ∼Bin(ni, μi), where
μi = eηi/(1 + eηi) and ηi is linear in xi. One way to work with this data is to flatten it, so that
ni components appear in the likelihood for each subject i: 	ni
j=1(1 + exp{−yijx⊤
i β})κ, where
yij ∈{−1, 1} giving | ni
j yij| = ni. This allows inference to proceed as described in Section 23.3.2,
but requires a lot of latents (ni) for each individual (i).
A more efficient multiplicity representation is obtained by recognizing that the compo-
nent of the likelihood for each observation, i, may be written instead with two terms as
(1 + exp{−x⊤
i β})κyi(1 + exp{x⊤
i β})κ(ni−yi). This suggests that the full likelihood, with m
unique subjects, can be written by defining κi−= κ(ni −yi) and κi+ = κyi as 	m
i=1(1 +
exp{−x⊤
i β})κi+(1 + exp{x⊤
i β})κi−.Inotherwords,thisisapowered-uplogisticlikelihoodwhere
the first m terms use response ‘data’ y′
i = +1 with multiplicity parameter κi+, and the second m
terms use y′
i = −1 with κi−. Forming vectors y′ and κ′, each of length n = 2m in this way, allows
the likelihood to be written as 	n
i=1(1 + exp{−y′
ix⊤
i β})κ′
i . Usually 2m ≪m
i=1 ni yielding a
much more efficient MCMC scheme, which is similar to that described in Section 23.3.2 with some
vectorizing modifications. For example, the conditionals for zi and λi would use κ′
i instead of κ. For
β, replace κ1n with κ′ in the expression for ˜β. The original, scalar, κ is used for the conditionals
corresponding to the parameters of the prior. For example, the posterior conditional covariance V
of β is unchanged.
23.3.4 Illustrations
Pima Indian data
The Pima Indian diabetes data is available from the UCI Machine Learning Repository [1]. It
includes test outcomes for diabetes performed on n = 768 women of Pima heritage with eight

Gibbs sampling for regression with Laplace priors
477
real-valued predictors. Some of the predictors have many zeros, which may reasonably be inter-
preted as ‘missing’ values. However, to remain consistent with the treatment of this data by H&H,
and other authors, we do not treat these values in any special way. In what follows we describe
the estimators of β = (β0 ≡μ, β1, . . . , β8) obtained from our regularized logistic regression
framework. Throughout, T = 1000 samples are taken from the posterior, discarding the first 100
as burn-in. This example is contained in the documentation for reglogit in the R package by the
same name.
Figure 23.5 summarizes the marginal posterior for β with boxplots. Two settings of κ ∈{1, 20}
(each panel) were used, and heavy regularization (fixing ν = 6) was applied. The MLE, obtained
fromtheglmcommandinR,andtheMAPasestimatedfromthesample(s),arealsoshown.Shrink-
age is apparent in the divergence between the MAP and MLE values in all panels. Observe how the
quartiles and outliers converge on the MAP as κ is increased. The convergence is particularly rapid
for the intercept term, and the two coefficients with considerable mass near zero (β4 and β5). In
fact, the corresponding columns of X have the highest concentration of ‘missing’ values (30% and
49% respectively), so it is not surprising that the MAP estimator excludes them.
Synthetic binomial data
To illustrate the efficient handling of binomial data, consider the following simple binomial logis-
tic regression problem. This example is also contained in the documentation for reglogit.
The true linear predictor is ηi = 1 + x⊤
i β where β = (2, −3, 2, −4, 0, 0, 0, 0, 0)⊤, and the p =
9-dimensional xi are uniform in [0, 1]p. The responses, yi ∈{0, . . . , ni}, are sampled with yi ∼
Bin(μi, ni) where ni = 20 and μi = eηi/(1 + eηi).
Two different implementations of regularized binomial logistic regression are compared based
on the output of 100 repeated experiments with  ni = 2000 (i.e. m = 100 distinct xi predictors).
The metrics for comparison are root mean squared error (RMSE) between the true and posterior
mean βs, and overall computing time of the respective MCMC samplers. In all cases we used T =
1000 MCMC rounds with MH sampling of λi at thinning level(s) set by the effective κ′ (i.e. via
κi for each λi). The first 100 rounds were discarded as burn-in. The flattened version had a mean
RMSEof0.2117(sd0.0602),whereasthemultiplicityversionhad0.2120(0.0606).Sogiventhesame
number of MCMC iterations, there is apparently no benefit to one representation over the other,
and moreover the extra/fewer latent variables do not seem to affect the MC error of the resulting
estimators. But there is a big difference in CPU times. The flattened version took 570.4 s (37.8 s)
whereas the multiplicity version was much (9x) faster at 64.6 s (0.82 s). Since this comes with no
cost in accuracy (via RMSE), this implementation is much preferred over the flattened version.
A simulated p ≫n experiment
Now consider a predictive comparison, including both fully Bayesian and full/joint MAP (includ-
ing ν), benchmarked against other modern approaches to regularized logistic regression. Consider
the following synthetic data experiment that uses the identical setup as above with the following
exceptions. Here, ni = 5 with 20 total samples giving  ni = 100 total instances, and we consider
three variations on the β describing the slope part of the linear predictor. In the first case let p = 9
and β = (2, −3, 0.74, −0.9, 0, 0, 0, 0)⊤; in the second case p = 100 augmenting β from the first
case with 91 more zeros; and in the third p = 1000 with 900 more zeros still. Random design
matrices in the unit p-cube were used, yielding random training sets of (x, y) values, which was
repeated 100 times for each of the three cases in a Monte Carlo fashion. Similarly created random
test sets of size 1000, with n′
i = 100 so that  n′
i = 10 000, were used to compare the methods by
misclassification rate.
The fully Bayesian estimator (i.e. κ = 1) used priors/MCMC exactly as described in the pre-
ceding sections. MCMC rounds included (100, 1000), (500, 1500), (1000, 2000) burn-in and
total samples in each of the cases p = 9, 100, 1000, respectively. The actual predictor used in the

478
R. B. Gramacy
mu
b1
b2
b3
b4
b5
b6
b7
b8
−20
0
20
40
60
80
100
120
nu=6, kappa=1
coefficients
posterior
MLE
MAP
mu
b1
b2
b3
b4
b5
b6
b7
b8
−20
0
20
40
60
80
100
120
nu=6, kappa=20
coefficients
posterior
Figure 23.5 Illustrating shrinkage ν = 6 in the power-posterior on the Pima Indian data for κ ∈
{1, 20}.

Gibbs sampling for regression with Laplace priors
479
b
map
glmn
mle
krish
b
map
glmn
krish
b
map
glmn
krish
0.05
0.15
0.25
miss rate
miss
5%
avg
95%
b
0.065
0.152
0.201
map
0.189
0.199
0.212
glmn
0.092
0.159
0.217
mle
0.074
0.136
0.213
krish
0.061
0.113
0.184
b
0.172
0.191
0.210
map
0.188
0.199
0.212
glmn
0.133
0.189
0.212
krish
0.129
0.189
0.244
b
0.187
0.198
0.215
map
0.188
0.198
0.215
glmn
0.142
0.193
0.214
krish
0.151
0.211
0.252
Figure 23.6 Misclassification rates in boxplot (top) and tabular (bottom) form. There are three sec-
tions, depending on the number of irrelevant predictors in the design matrix, wherein the same
estimators are applied. The vertical dashed lines in the boxplots indicate the same demarkation as
the horizontal lines in the tables.
comparisons was the mean of the posterior predictive after burn-in. The comparators include the
standard MLE obtained via the glm command in R, a binomial fit from the glmnet package [7]
for R, and the estimator of [26] [‘krish’ for short]. The MLE is unstable in all but the p = 9 case,
so it is not considered for the p = 100, 1000 cases. CV was used to choose the penalty parameter
in the p = 9, 100 cases for glmnet, via cv.glmnet. The same procedure gave fatal errors in the
p = 1000 case so we plugged in the estimate obtained from the corresponding p = 100 run in
for this final case. Reliably setting the penalty parameter for ‘krish’, via CV or otherwise, was too
computationally intensive for the p = 100, 1000 cases so a setting was chosen by hand using the
best out-of-sample simulations from the p = 9 case.
The results of the Monte Carlo experiment are summarized in Figure 23.6 by boxplots, and
numerically.Thebestestimatorshavelowmissrateswithlowervariabilityacrossthe100repetitions.
Lets consider the first, ‘original’, p = 9 part of the experiment, summarized in the left-hand region
of the boxplots and the top region of the tables. The fully Bayesian and ‘krish’ methods come out on
top. It is a close call, but ‘krish’ edges out the fully Bayesian estimation. This may not be surprising
considering that its penalty parameter was, for all intents and purposes, set by oracle for this case
in advance. The MLE is good on average, but has some extreme ELL and miss rate values. The

480
R. B. Gramacy
glmnet and MAP estimators are in between, the former having better values of both metrics but
with higher variability.
The distinctions in performance between the methods increases with p. See the right-hand
regions of the boxplots and the bottom regions of the tables. The ‘krish’ method suffers from high
variability due to the fixed choice of the penalty parameter. The glmnet variability is much lower,
but there are many extreme outliers. The behaviour in both p = 100 and 1000 cases is qualitatively
similarforthisestimatoreventhoughtheformerusedCVtosetthepenaltyparameterandthelatter
used the same fixed value. The MAP and fully Bayesian estimators have similar average behaviour
to other estimators, but with lower variability. Apparently, choosing the penalty parameter via
the posterior is most reliable in high-dimensional settings. The fully Bayesian approach appears
preferable to the MAP in all cases, but this distinction is harder to make out as p increases.
23.4 Discussion
The methods discussed here have many special cases, and extensions, that are outlined in our
references. For example, Bayesian ridge regression, which involves an L2-norm rather than L1, is
facilitated by straightforward simplifications. One extension would involve expanding the hierar-
chical model using a so-called normal-gamma (NG) prior for β [e.g. 19], a particular setting of
which encodes the specific Laplace prior case that we handed in this paper. [15] give the details
in the OLS framework, requiring an extra conditional in the Gibbs sampling. This is easily ported
to logistic regression. Providing the option case = "ng" to blasso in the monomvn package
invokes inference under the NG prior. A further extension which has been shown to improve on
the Laplace and NG priors is the horseshoe prior [5]. Although we are unaware of any particular
reference which outlines the Gibbs sampler for OLS (or logistic regression), the monomvn pack-
age provides an implementation through the (as yet undocumented) function bhs, which works
similarly to blasso.
Handling polychotomous data, i.e. logistic classification with >2 classes, is straightforward.
Following the setup in HH, one may introduce C collections of coefficients β(1), . . . , β(C) for C
classes with the convention that β(C) = 0 so that logistic regression is recovered in the C = 2 case.
Then, the conditional likelihoods L(β(j)|y, β(−j)) turn out to have exactly the form of a logistic
regression likelihood for the class indicator for each yi = j, independently for i = 1, . . . , n. If there
are ni > 1 trials for predictors xi, then a vectorized multiplicity parameter can be used to get a
fast implementation, as described in Section 23.3.3. Extending the methods to ordinal responses
is even easier. Johnson and Albert [24, Chapter 4] describe a Bayesian probit model which is easily
adapted for the logit case described here. Finally, adding variable selection via reversible jump into
the regularized logistic regression arsenal would proceed similarly to the OLS setup described in
Section 23.2.2.
References
[1] Asuncion, A. and Newman, D. (2007). UCI Machine Learning Repository.
[2] Barndorff-Nielsen, O., Kent, J. and Sorensen, M. (1982). Normal variance-mean mixtures and
z-distributions. International Statistical Review, 50, 145–159.
[3] Carlin, B. P. and Polson, N. G. (1991). inference for nonconjugate Bayesian models using the
Gibbs sampler. The Canadian Journal of Statistics, 19, 4, 399–405.
[4] Carlin, B. P., Polson, N. G. and Stoffer, D. S. (1992). A Monte Carlo approach to nonnormal
and nonlinear state–space modeling. Journal of the American Statistical Association, 87, 418,
493–500.

Gibbs sampling for regression with Laplace priors
481
[5] Carvalho, C., Polson, N. and Scott, J. (2010). The horseshoe estimator for sparse signals.
Biometrika, 97, 2, 465–480.
[6] Efron, B., Hastie, T., Johnstone, I. and Tibshirani, R. (2004). Least angle regression (with
discussion). Annals of Statistics, 32, 2.
[7] Friedman, J. H., Hastie, T. and Tibshirani, R. (2010). Regularization paths for generalized
linear models via coordinate descent. Journal of Statistical Software, 33, 1, 1–22.
[8] Frühwirth-Schnatter, S. and Frühwirth, R. (2010). Data augmentation and MCMC for binary
and multinomial logit models. In Statistical Modelling and Regression Structures: Festschrift in
Honour of Ludwig Fahrmeir, eds. T. Kneib and G. Tutz, 111–132. Physica-Verlag.
[9] Gelfand, A. and Smith, A. (1990). Sampling-based approaches to calculating marginal densi-
ties. Journal of the American Statistical Association, 85, 398–409.
[10] Gelman, A., Carlin, J., Stern, H. and Rubin, D. (2003). Bayesian Data Analysis. Chapman &
Hall/CRC.
[11] Genkin, A., Lewis, D. and Madigan, D. (2007). Large-scale Bayesian logistic regression for
text categorization. Technometrics, 49, 3, 291–304.
[12] George, E. and McCulloch, R. (1993). Variable selection via Gibbs sampling. Journal of the
American Statistical Association, 88, 881–889.
[13] Geweke,J.(1993).BayesianTreatmentoftheIndependentStudent–t LinearModel.Journalof
Applied Econometrics,Vol.8,Supplement:SpecialIssueonEconometricInferenceUsingSim-
ulation Techniques, S19–S40.
[14]
(1996). Variable selection and model comparison in regression. In Bayesian Statistics 5,
eds. J. Bernardo, J. Berger, A. Dawid, and A. Smith, 609–620. Oxford University Press.
[15] Gramacy, R. and Pantaleo, E. (2010). Shrinkage regression for multivariate inference with
missing data, and an application to portfolio balancing. Bayesian Analysis, 5, 2, 237–262.
[16] Gramacy, R. and Polson, N. (2010). Simulation-based regularized logisitic regression. Tech.
Rep. arXiv:1005.3430, The University of Chicago, Booth School of Business.
[17] Gramacy, R. B., Lee, J. H. and Silva, R. (2008). On estimating covariances between
many assets with histories of highly variable length. Tech. Rep. 0710.5837, arXiv. Url:
http://arxiv.org/abs/0710.5837.
[18] Green, P. (1995). Reversible jump Markov chain Monte Carlo computation and Bayesian
model determination. Biometrika, 82, 711–732.
[19] Griffin, J. E. and Brown, P. J. (2010). Inference with Normal–Gamma prior distributions in
regression problems. Bayesian Analysis, 5, 1, 171–188.
[20] Hans,C.(2008).Bayesianlassoregression.Tech.Rep.810,DepartmentofStatistics,TheOhio
State University, Columbus, OH 43210.
[21] Hastie, T., Tibshirani, R. and Friedman, J. (2001). The Elements of Statistical Learning: Data
Mining, Inference, and Prediction. Springer-Verlag.
[22] Holmes, C. and Held, K. (2006). Bayesian auxilliary variable models for binary and multino-
mial regression. Bayesian Analysis, 1, 1, 145–168.
[23] Jacquier, E., Polson, N. and Rossi, P. E. (2004). Bayesian analysis of stochastic volatility mod-
els with fat-tails and correlated errors. J. of Econometrics, 122, 185–212.
[24] Johnson, V. and Albert, J. (1999). Ordinal Data Modeling. Springer.
[25] Kirkpatrick, S., Gelatt, C. and Vecci, M. (1983). Optimization by simulated annealing. Science,
220, 671–680.
[26] Krishnapuram, B., Carin, L., Figueiredo, M. and Hartemink, A. (2005). Sparse multinomial
logistic regression: fast algorithms and generalization bounds. IEEE Pattern Analysis and
Machine Intellegence, 27, 6, 957–969.
[27] Madigan, D. and Ridgeway, G. (2004). Discussion of ‘least angle regression’ by B. Efron,
T. Hastie, I. Johnstone, and R. Tibshiran. Annals of Statistics, 32, 2, 465–469.

482
R. B. Gramacy
[28] Park, M. and Hastie, T. (2008). Penalized logistic regression for detecting gene interactions.
Biostatistics, 9, 1, 30–50.
[29] Park, T. and Casella, G. (2008). The Bayesian Lasso. Journal of the American Statistical Associ-
ation, 103, 482, 681–686.
[30] Stambaugh, R. F. (1997). Analyzing investments whose histories differ in length. Journal of
Financial Economics, 45, 285–331.
[31] Taddy, M. A. (2011). Inverse regression for analysis of sentiment in text. Tech. Rep.
arXiv:1012.2098, The University of Chicago, Booth School of Business.
[32] Troughton, P. T. and Godsill, S. J. (1997). A reversible jump sampler for autoregressive
time series, employing full conditionals to achieve efficient model space moves. Tech. Rep.
CUED/F-INFENG/TR.304, Cambridge University Engineering Department.
[33] West, M. (1987). On scale mixtures of normal distributions. Biometrika, 74, 3, 646–648.

24
Bayesian model
averaging in the M-open
framework
merlise clyde
and edwin s. iversen
24.1 Introduction
C
onsideration of multiple models is ubiquitous in statistical practice. In Chapter 6, Bernardo
& Smith [9] describe three distinct settings for the model comparison problem, denoted
as M–closed , M–complete and M–open which have far reaching consequences for how models
should be compared, selected or combined.
The predominant perspective is the M–closed view, where one entertains a collection of models
M = {Mj, j = 1, . . . J}, with the belief that one of the models in {Mj} is the ‘true’ generating
model for the data, but that the true generating model is unknown. In this framework, a Bayesian
would use probabilities p(Mj) to represent one’s subjective (or objective) prior beliefs about the
‘truth’ofmodelMj.Thesebeliefscombinedwithanypriorbeliefsaboutparameterswithinmodels
areupdatedviaBayestheoremtoobtainajointposteriordistributionformodelsandmodelspecific
parameters. The Bayesian paradigm provides a comprehensive framework for accounting for both
parameter and model uncertainty, leading to the well-known Bayesian Model Averaging solution.
For additional references, history, and examples we refer the reader to review articles by [24]. In
conjunction with a decision theoretic approach, this joint posterior distribution can be used to
construct optimal decision rules for selecting the ‘best’ model, make inferences about parameters
or predicting future observations under selected utility functions. For additional references for the
Bayesianapproachtomodelchoicewereferthereadertoreviewarticlesby[12,16,17,24]forhistory
and examples.
In reality, the true process generating the data may be too complex to be used in practice or even
to articulate as a probabilistic model, which leads to the M–complete and M–open perspectives
discussed in [9]. In both of these formulations, the true generating model MT is not included
in the collection of models M, rather the models in M are viewed as potential proxies available
for comparison or model selection. With the belief that the true model is MT, assigning prior
probabilities to models in M no longer makes sense, as the model is no longer part of the unknown
specification of the data generating process. In theM–complete specification, while one can specify
p(Y|θ, MT), one may still wish to select a proxy model in M because of its attractive simplicity
or ease of communication of results with others or computational tractability. In the more realistic

484
M. Clyde and E. S. Iversen
M–open alternative, the list of models in M are also to be used in place of MT, however, there is
no explicit specification of a belief model p(Y|MT).
UndertheM–openperspective,[9,26]motivatetheroleofcross-validationtoevaluateexpected
utility,leadingtointrinsicBayesfactorsforthemodelchoiceproblem.Ratherthanmodelselection,
our goal in this paper is optimal combination of multiple proxy models in the M–open framework.
Inthenextsection,wereviewthestandardM–closedBayesianModelAveragingapproachanddeci-
sion-theoretic methods for producing inferences and decisions. We then review model selection
from the M–complete and M–open perspectives, before formulating a Bayesian solution to model
averaging in the M–open perspective. We construct optimal weights for MOMA: M–open Model
Averaging using a decision-theoretic framework, where models are treated as part of the ‘action
space’ rather than unknown states of nature. We illustrate MOMA using ‘incompatible’ retrospec-
tive and prospective models for data from a case-control study and demonstrate that MOMA gives
better predictive accuracy than using any of the proxy models. We conclude with open questions
and future directions.
24.2 M−closed model averaging
In the standard setup the joint distribution of the data and all unknowns may be described hierar-
chically, with p(Y|θj, Mj) specifying the distribution of the data Y = (Y1, . . . Yn)T given model
specific parameters θj in model Mj, p(θj|Mj) reflecting prior uncertainty in the model specific
parameters. A Bayesian would assign a prior probability, p(Mj), representing their belief (subjec-
tive or objective) that each model Mj is the true model.
In turn, posterior model uncertainty is represented by the posterior probabilities of models
obtained via Bayes theorem
p(Mj|Y) =
p(Y|Mj)p(Mj)
J
j=1 p(Y|Mj)p(Mj)
(24.1)
where
p(Y|Mj) =

p(Y|θj, Mj)p(θj|Mj)dθj
(24.2)
is the marginal likelihood of Mj. Given observed data Y, the posterior probability of each model
p(Mj|Y) represents a posterior measure that model Mj generated the data. The joint posterior
distribution of θj, Mj, p(θj|Y, Mj)p(Mj|Y), provides a complete post-data representation of
parameter and model uncertainty that can be used for a variety of inferences and decisions. For
example, the distribution of a future observation Y∗. Under the hierarchical model for the data, the
Bayesian predictive distribution of Y∗is a mixture model
p(Y∗|Y) =

j
p(Y∗|Mj, Y)p(Mj|Y)
(24.3)
with components in the mixture the conditional predictive distributions
p(Y∗|Mj, Y) =

p(Y∗|θj, Mj)p(θj|Mj, Y)dθj
(24.4)
and mixing weights given by the posterior probabilities of models from equation (24.1).

Bayesian model averaging
485
24.2.1 Optimal decisions
The joint posterior distribution of Mj and θj provides a complete summary of one’s beliefs after
seeing the data. Combined with a decision-theoretic framework, this posterior permits making
inferences or decisions that optimize one’s utility. More formally, let u(ω, a) be a mapping from
A ×  to R that reflects the utility of taking action a when the unknown state of nature is ω.
Commonly used utility functions are negative quadratic loss for estimation or prediction or proper
scoring rules if ω is a distribution. For a Bayesian, the optional action to take is the one that
maximizes the posterior expected utility
a∗= arg sup
a∈A


u(ω, a)p(ω | Y)dω
(24.5)
where p(ω | Y) is the posterior (predictive) distribution of ω given the data Y.
Consider the decision problem of prediction under quadratic loss
u(Y∗, a) = −(Y∗−a)2
where Y∗is the unknown ‘state of nature’, a is a possible action in action space A = R and u is
the utility of taking action a when the future value is Y∗. Under quadratic loss for prediction, the
optimal action for the point prediction of Y∗is a∗= E(Y∗|Y), the (posterior predictive) mean of
Y∗given Y, which under the M-closed perspective, can be expressed as
E(Y∗|Y) =
J

j=1
E(Y∗|Mj, Y)p(Mj|Y) =
J

j=1
p(Mj|Y)ˆY∗
Mj
(24.6)
where ˆY∗
Mj is the posterior mean under model Mj. This is the well-known Bayesian Model Aver-
aging solution, where the prediction is a weighted average of the model specific predictions ˆY∗
Mj
with weights that are given by the posterior model probabilities. Such model averaging or mixing
procedures have been developed and advocated for by [27], [20], [17], [32] and [15], and are now
widespread.
If the goal is to find the single model that leads to the best prediction under quadratic loss,
then the set of actions consist of selecting a model and reporting the prediction under that model.
The solution given by [9, Section 6.1] is the model that minimizes (ˆY∗
Mj −EY∗(Y∗| Y))2; the
single model whose predictions are closest to the BMA solution. For the case of two models, this
is the highest probability model, but in general the model closest to the BMA solution may not
correspond to the highest probability model nor the median probability model of [1] except in
special circumstances. While closed form expressions are generally unavailable, one can determine
the best model by evaluating the distances between the models under consideration. When there
is high correlation among the predictors this is preferable to the median probability model. [33]
use a log scoring rule for selecting the model that is closest to model averaging solution in terms of
predictive densities.
24.2.2 BMA is not a panacea
In problems where there are a large number of predictors (p), such as genome wide association
studies, one might consider model averaging where the candidate models are each based on a single

486
M. Clyde and E. S. Iversen
predictor, rather than approximating model averaging by stochastic search over the 2p potential
models. To illustrate that model averaging in such a setting may fail, consider the simplified setting
with just two models in M
M1 : Y = X1β1 + e
(24.7)
M2 : Y = X2β2 + e
(24.8)
leading to ˆY∗= p(M1 | Y)X1 ˆβ1 + p(M2 | Y)X2 ˆβ2. This seems appealing as the model averag-
ing solution does contain all potential predictors, even though the full model was not included in
the list of candidate models. If the ‘true’ model does in fact contain both predictors Y = X1β1T +
X2β2T + e then, under standard regularity conditions, the BMA model weights converge to 1 for
the model that is ‘closest’ to the true model (in terms of Kullback–Leibler divergence); BMA only
usespredictionsfromthatmodel;andinthelimitBMAisnotconsistentifMT /∈M.Theobvious
solution is to add the full model to the list of models under consideration for this toy example.
However, if the true model is some complex nonlinear function, one may need to use a richer set
of basis vectors, such as in over-complete representations, for model averaging to lead to consistent
results [38]. For ease of exposition, one may still wish to use simple proxy models when the true
model is not included in M, which leads to the M–closed and M–open perspectives.
24.3 Model comparison without the true model
When the true model is not in M, we consider two cases
M–complete : we know the true model, MT, and p(Y∗|Y) = pC(Y∗|MT, Y) is available.
We may, however, wish to use the models in M because of ease in communication of results,
tractability of computations, reasonable proxies, etc.
M–open : we know that the true model is NOT in M, but we cannot specify p(Y∗|Y) =
po(Y∗|MT, Y) because it is too difficult, we lack time to do so, or do not have the expertise,
computational intractability, etc.
For the model comparison problem in the M–complete setting, one simply finds the model in M
which maximizes the expected utility, where now the expectation is with respect to the predictive
distribution pc(Y∗| MT, Y). For the M–open case, one again finds the optimal model and action
a∗(Y, Mj) under model Mj that maximizes expected utility,

u(y∗, a∗(Y, Mj))po(y∗|MT, Y) dy.
(24.9)
AsthepredictivedistributionisnotavailableintheM–opensetting[9,26]arguethatforexchange-
able data and large n the expected utility can be approximated by
1
n
n

i=1
u(yi, a∗(Y(i), Mj))
(24.10)
based on partitioning YT = (yi, YT
(i)) into n partitions of the data where Y(i) denotes the data
without the ith observation and serves as a proxy for the observed data and yi as a proxy for the
future value Y∗. Randomly selecting from K of these partitions, they suggest a law of large numbers
argument to justify that as n, K →∞

Bayesian model averaging
487
&&&&&&

u(Y∗, a(Y, Mj))po(Y∗|Y, MT) dY∗−1
K
K

k=1
u(yk, a(Y(−k), Mj))
&&&&&&
→0,
thereby justifying the use of cross-validation to approximate expected utility.
Walker & Gutiérrez-Peña [34] in the discussion of [26] provide an alternative justification for
the above as an approximation based in a Bayesian nonparametric model. If we assume the data are
exchangeable, coming from an unknown distribution F, then one may place a nonparametric prior
on F, such as a Dirichlet process,
F ∼DP(α0, Fo)
with α0 a scale or prior weight parameter and F0 a parametric distribution that is the location
parameter such that E(F) = F0 [18]. Given a sample of size n, the posterior of F is again DP(αn, Fn)
where αn = n + α0, Fn = (nˆFn + α0F0)/(n + α0) and ˆFn is the empirical distribution of the
data. Using the nonparametric prior, the posterior predictive distribution for a new observation
Y∗is Fn and the expected utility is expressed as

u(y∗, a∗(Y, Mj))dFn(y∗) =
n
n + α0

u(y∗, a∗(Y, Mj))dˆFn(y∗)+
(24.11)
α0
n + α0
u(y∗, a∗(Y, Mj))dFo(y∗)
(24.12)
[23]takeF0 tobecentredattheM–closedpredictivedistribution,sothatasα0 →∞onerecovers
the M–closed solution, while as α0 →0

u(y∗, a∗(Y, Mj))dFn(y∗) →1
n
n

i=1
u(yi, a∗(Y, Mj))
(24.13)
leads to their M–open solution. The main difference between (24.13) and (24.10) is that the
optional action under model Mj uses all data in constructing the distributions that go into
a∗(Y, Mj) in (24.13), while [26] use a∗(Y(i), Mj) based on the training data in (24.10). Equation
(24.13) provides internal rather than external validation as in (24.10).
In the case of prediction under quadratic loss under the limiting DP model, we would minimize
over M
1
n
n

i=1
(yi −E(Yi | Mj, Y))2
(24.14)
In the case of linear models E[Y] = XMβM with non-informative priors p(βM) ∝1 assigned
to parameters in Mj, E(Yi | Mj, Y) = xT
i ˆβM where ˆβM is the ordinary least squares estimate.
The criterion would lead to picking the model with the smallest residual sum of squares regardless
of model dimension (or highest R2), which leads to poor predictive performance. In contrast, the
CV-approach of Bernardo & Smith [9] chooses the model that minimizes
1
n
n

i=1
(yi −E(Yi | Mj, Y(i)))2
(24.15)

488
M. Clyde and E. S. Iversen
over M. This captures how well model Mj predicts, on average, a left-out observation given
the remaining cases [21]. While we do not advocate non-informative priors in this setting, this
highlights a potential problem of using the (limiting) DP prior.
Under the log scoring rule

log(p(y | Mj, Y))p(y | Y)dy
(24.16)
[9, 26] propose the following approximation to the expected utility
1
K
k

k=1
log(p(yk | Y(k), Mj))
(24.17)
which may be rearranged to form a criterion that implies that one would prefer model Mi to model
M0 if
K

k=1
1 p(yk | Y(k), Mj)
p(yk | Y(k), M0)
21/K
> 1
(24.18)
This corresponds to the Geometric Intrinsic Bayes factor criterion of [4–6] where Y(k) represents
a minimal training sample. This is related to the expression in [36] where Y replaces Y(k).
Winkler [35] in the discussion of [26] raises the question of ‘Why there is so much focus on
model choice. If there is no ‘true’ model, why do we have to choose a single model?’. As George
Box is often quoted ‘Essentially all models are wrong, but some are useful.’ Why should we restrict
attention to just one of the proxy models if all are potentially useful? Rather selecting a model, we
examine optimal weighted averages.
24.4 Combining models in the M−open setting
In the M–closed setting models are essentially an expansion of the ‘parameter’ space so that the
unknown state of nature  is comprised of models and model specific parameters. The optimal
weights for prediction  wjE(Y∗| Y, Mj) are the posterior probabilities of models, which are
proportional to the prior model probabilities times the marginal distributions of the data p(Y |
|Mj). In both the M–complete and M–open viewpoints, the assignment of prior probabilities
{p(Mi), i ∈M} no longer makes sense as a measure of our degree of belief in model Mj if we
reallybelievethatMT /∈M.ThusthestandardBMAsolutiontocombiningmodelsusingweights
that are posterior model probabilities is not applicable.
In the decision theoretic framework for the M–closed or M–open perspectives, models are not
part of the state of unknowns , but may be part of the decision or action space. Under this alter-
native viewpoint model weights wj are solely part of the action space A, so that optimal weights to
combinepredictionsorpredictivedistributionsfromthecollectionofproxymodelsinMbecomes
a decision problem.
24.4.1 Combining models as a decision problem
Let {wj, j ∈J wj ∈} denote the weights w and consider decision rules of the form a(Y, w) =

j wjE(y∗| Y, Mj) in the case of prediction or a(Y, w) = 
j wjp(y∗| Y, Mj) for predictive
densities. For quadratic loss, the expected utility is

Bayesian model averaging
489
EY∗[u(y∗, a(Y, w))|Y] = −

∥y∗−

j
wjˆy∗
Mj ∥2 p(y∗|Y, Mt) dy∗
while for the log scoring rule,
EY∗[u(y∗, a(Y, w))|Y] =

log(

j
wjp(y∗| Mj, Y))p(y∗| Y, Mt) dy∗
In the M–complete perspective, since we have MT, we can in principle solve the optimization
problem.
In the M–open formulation, as before, partition YT = (yT
k , YT
(k)) into future and training data
vectors of size n −m and m respectively. Randomly select K from these n choose m partitions to
construct the approximate criterion
ˆw = arg max
w
1
K
K

k=1
u(yk, a(Y(−k), w))
(24.19)
For the problem of prediction the problem may be stated as,
Solve
ˆw = arg max
w
−1
K
K

k=1
∥yk −

Mj∈M
wj ˆY(k),Mj ∥2
(24.20)
subject to
(24.21)
J

j=1
wj = 1
(24.22)
wj ≥0
∀j ∈{1, . . . , J}
(24.23)
where the optimal solution may be found using a quadratic programming algorithm. This has an
equivalent representation using Lagrangians:
−1
K
K

k=1
∥yk −
J

j=1
wj ˆY(k),Mj ∥2 −λ0(
J

j=1
wj −1) +
J

j=1
λjwj.
The two constraint functions ensure that the weights have the same support as posterior model
probabilities in BMA (sum to one and non-negativity), however, the weights do not have an inter-
pretation as posterior probabilities. While the expression above looks like a log likelihood from a
Gaussian distribution, it is not the predictive log likelihood.
Similarly, under the log scoring rule,
1
K
K

k=1
log
⎛
⎝
J

j=1
wjp(yk | Y(k),Mj, Mj)
⎞
⎠−λ0(
J

j=1
wj −1) +
J

j=1
λjwj
the expected utility takes a form similar to a likelihood from a mixture model. This relationship
permits an iterative solution for the weights as in estimation of mixture models, where starting with
initial weights ˆw(0)
j
, we update the weights

490
M. Clyde and E. S. Iversen
ˆw(t)
j
≡1
K

k
ˆw(t−1)
j
p(yk | Y(k), Mj)

j ˆw(t−1)
j
p(yk | Y(k), Mj)
(24.24)
until convergence.
Remark on solution In the M–closed setting the model weights may be obtained from Bayes fac-
tors for comparing any model to a base model, P(Mj | Y) = wjB(Mj : M0)/ 
j wjB(Mj :
M0) where wj is the prior probability of Mj. In the M–open framework, the geometric
intrinsic Bayes factor (GIBF) leads to a model selection criterion under the log scoring rule[5],
however,theoptimalmodelweightsin(24.24)forcombiningmodelsunderthelogscoringrule
are not equivalent to the renormalized GIBF nor the closely related arithmetic intrinsic Bayes
Factors.
24.4.2 Restrictions on weights
As predictions may have support on RK, we may impose a range of restrictions on the weights
by choice of λj. With λ0 = λ1 = . . . = λJ = 0 we obtain arbitrary weights (wj ∈R). Setting
λ1 = . . . = λJ = 0 enforces the weights to sum to one, but allows positive and negative weights,
while with all λj >> 0 the weights are constrained to be non-negative and sum to one. Because the
weights are non-negative, the last penalty resembles a ‘lasso’ or L1 penalty, which permits weights
to be zero. For the log-scoring rule we must have both sets of constraints for the MOMA density
estimate to be a valid density.
To illustrate the behaviour of the solutions under quadratic loss, we focus on the case where
m = n −1 and let ˆe = [ˆϵkj] = [yk −ˆy(−k)Mj] denote the n × J matrix of predicted residuals for
predicting yk under model Mj using data Y(k).
Remark 1 With the sum to one constraint alone, ˆw ∝(ˆeTˆe)−11. If residuals from models
are uncorrelated, then weights are proportional to the inverse of the Predicted REsidual Sum
of Squares for model Mj, PRESSj = 
k ˆϵ2
kj. With non-informative priors in linear models,
PRESSj =  e2
kj/(1 −hkk) where ejk is the ordinary residual for case k under model j and
hkk is the leverage of case k, putting a premium on models that are able to fit points with high
leverage. In the more general case of correlated predicted residuals across models, the weights
are adjusted for the other models.
Remark 2 With highly correlated residuals under similar proxies, weights with just the sum to
one constraint may be negative and highly unstable. The non-negativity constraint induces a
lasso-like L1 penalty, which stabilizes weights and may drive the optimal weights to zero for
redundant components.
Remark 3 The solution to (24.20) is in fact equivalent to the frequentist method of stacking
[10, 11], although the Bayesian may prefer to include predictions under more robust prior dis-
tributions than using the non-informative prior distribution which leads to the least squares
predictions.
24.5 Aeroplane failures examples
WecomparetheDirichlet Process M–open model averaging procedureof [37] and MOMA, which
uses the predictive reuse approximation to the predictive distribution of future observations. The
dataarebasedonn = 30intervalsbetweenairconditioningfailuretimesforplane7912[30].Walker
et al. [37] consider two models: an exponential

Bayesian model averaging
491
pE(y) = θ exp(θy)
(24.25)
θ ∼G(a, b)
(24.26)
and a log-normal model
pL(y) = (2πσ 2)−1/2 1
y exp

−1
2
log(y) −μ
σ
2
(24.27)
μ | σ 2 ∼N(μ0, n0σ 2)
(24.28)
(σ 2)−1 ∼G(η0/2, σ 2
0 η0/2).
(24.29)
Using non-informative improper prior distributions, traditional model averaging leads to indeter-
minate Bayes factors due to potentially arbitrary constants in the improper priors. That is not a
problem with the M–open approach. Using non-informative priors a = b = 0 and μ0 = n0 =
σ0 = 0, η0 = −1/2, to obtain the predictive densities for a future observation under each model,
the MOMA weight for the exponential model is 0.435 using equation (24.24). In contrast the
optimal weight from [37] is 0.315 for the exponential model. The predictive distributions for both
approaches are illustrated in Figure 24.1. While the distributions are very similar in the tails, the
main difference is near the mode.
To compare the two methods, we generated 30 observations from a G(2, 1) distribution and
used Monte Carlo integration to evaluate the utility

log ˆp(y | Y)pG(y)dy under the true Gamma
model. Figure 24.2 illustrates one realization, where the utility under the MOMA estimate is −1.65
compared to −1.68 for the DP method. The estimate of the mixing weight for the exponential
predictive distribution is 0.22 under MOMA, while it is 2.2 × 10−13, virtually zero, under the DP
0.025
0.020
0.015
0.010
Predicted Density
0.005
0.000
0
50
100
150
y
200
250
Figure 24.1 Predicted distributions under MOMA (solid line) and the DP process estimate of [37]
(dashed line).

492
M. Clyde and E. S. Iversen
0.4
0.3
0.2
Predicted Density
0.1
0.0
0
1
2
3
y
4
5
Figure 24.2 Predicted distributions under MOMA (long dash) and the DP process estimate of [37]
(short dashed line), with the true Gamma(2,1) distribution (solid line).
mixture. The differences between the two approaches is most pronounced in small samples, while
the methods yield very similar results for larger sample sizes.
24.6 Ovarian cancer example
Berchuck et al. [3] develop a model to predict binary survival status (short-term: < 3 years ver-
sus long-term: > 7 year) among patients diagnosed with advanced stage serous ovarian cancer
using gene expression data from the primary tumor. The data consist of a retrospective sample
with n = 30 short-term survivors, n = 24 long-term survivors and eleven early stage (I/II) cases.
Expression was measured for 22, 283 targets using the Affymetrix U133a microarray. In addition to
thetumorphenotype,sixvariablesofclinicalrelevance(age,post-treatmentCA125levels,etc.)were
also collected for each women.
Based on the retrospective sampling design, the likelihood would be proportional to the joint
distribution of the 22, 283 expression and six clinical variables given survival status. The sample size
and the dimensionality of the problem preclude undertaking serious joint modelling, and instead
several proxy models are used to develop predictive models. We consider three classes of models:
Clinical trees (Five variants) Prospective Bayesian classification and regression tree models
using only the six clinical variables;
Expression trees (Four variants)ProspectiveBayesian classification and regression treemod-
els using only expression data;
Expression LDA (Four variants) Retrospective discriminant models built using expression
data given survival status.

Bayesian model averaging
493
Bayesian CART models using both clinical variables and expression variables lead to models that
included only clinical variables, so this combination is excluded from the analysis as it would be
redundant.
The clinical and expression tree models use a prospective likelihood and are based on Bayesian
model averaged predictions from the Bayesian CART method of [29] with the different variants
corresponding to different choices of the hyper-parameter settings. The LDA discriminant model
isbasedonclassificationwitharetrospectivemodeldescribedin[25];predictionsunderthismodel
are also model averaged. Because the data are retrospectively sampled, the prospective tree mod-
els provide simple proxies for prediction. The LDA method is a simple classification model that
attempts to construct predictions assuming either conditional independence (labelled ‘P1’) or a
sparse dependence structure (labelled ‘P2’) among the genes included in the analysis (either 100
or 200), and cannot reasonably be viewed as the true model. Traditional model averaging is not
suitable for combining these predictions as there is no probability model that encompasses the
two approaches employed in this example. Instead, we consider constructing optimal weights for
MOMAestimatesoftheprobabilityofbeingalong-termsurvivorunderthequadraticlosscriterion.
This treats the 54 vectors of survival status, clinical data and expression data as being exchangeable
inapproximatingtheexpectedutility.Amorerealisticassumptionwouldbethatofpartialexchange-
ability; given disease status the vectors of clinical and expression data are exchangeable. Population
proportionsofdiseasestatuscouldthenbeusedforoverorundersamplingacrossthediseasegroups
to construct the predictive distribution.
Non–Neg, Sum=1
(expanded)
Non–Neg, Sum=1
Sum=1
–40
–20
0
0
1/4
1/2
3/4
1
20
MOMA Weights
Clinical Trees
Expression Trees
LDA (both)
40
Figure 24.3 MOMA weights under the (top) sum to one constraint and (middle and bottom) the
sum to one and non-negativity constraint. Solid with circles denotes the clinical trees, dotted line
with triangles the expression trees and dashes with squares the LDA models.

494
M. Clyde and E. S. Iversen
Ida200.P2
Ida200.P1
Ida100.P2
Ida100.P1
tree4
tree3
tree2
tree1
clin5
clin4
clin3
clin2
clin1
Ida200.P2
Ida200.P1
Ida100.P2
Ida100.P1
tree4
tree3
tree2
tree1
clin5
clin4
clin3
clin2
clin1
Figure 24.4 Correlation of predicted residuals between the clinical trees (bottom 5), expression trees
(middle 4) and LDA models (top 4); the range is 0.9327–0.9999 for clinical trees, 0.9257–0.9999
for expression trees, and 0.7257–0.8424 for LDA models.
Figure 24.3 illustrates the effects of the constraints on the weights. Predictions from the expres-
siontreesarequitesimilartoeachotherleadingtohighcorrelationinthepredictedresiduals(Figure
24.4, middle block). This is also true in the case of the clinical trees and the LDA models, although
less so, while correlations between residuals from models in different classes are weakly correlated.
High positive correlations lead to large positive and negative weights within a class of models which
in effect cancels the contribution from these models to the overall prediction. Under the additional
non-negativity constraint, all of the weights of the expression trees are 0, with the resulting MOMA
predictions based predominantly on a subset of one clinical tree and two LDA models.
24.6.1 Validation experiment
Weevaluatedthesensitivityofpredictionstotheformofconstraint(sum-to-zeroversussum-to-zero
and non-negativity) applied to the weight vector using five-fold cross-validation. We randomly
split the data into a training set Y and a validation set YV. Using the training data we obtained
model weights ˆw, using the Monte Carlo approximation to the expected utility in (24.20). We then

Bayesian model averaging
495
Table 24.1 MOMA weights and prediction accuracy for the ovarian cancer data for five randomly
selected training and validation sets using the sum to one constraint.
set1
set2
set3
set4
set5
clin1
53.08
−4.43
−0.01
−24.41
15.94
clin2
−79.92
−5.16
0.90
0.80
−4.63
clin3
−1.25
−0.24
−0.90
−0.01
5.35
clin4
27.36
10.14
−0.33
23.73
−17.24
clin5
1.13
0.27
0.27
0.36
0.55
tree1
−0.05
−0.55
−2.92
0.03
27.93
tree2
−0.12
−0.07
−3.21
−0.62
0.63
tree3
0.51
0.53
0.15
0.48
−3.35
tree4
−0.28
0.22
6.26
−0.04
−24.10
lda100.P1
−0.40
0.04
−0.01
0.02
−0.11
lda100.P2
0.44
−0.02
0.53
−0.06
−0.07
lda200.P1
0.30
0.17
−0.32
0.09
−0.03
lda200.P2
0.21
0.08
0.60
0.63
0.12
Accuracy
0.64
0.64
0.46
0.73
0.60
constructed the MOMA estimates of the probability of long-term survival ˆpj = 
i ˆwi ˆY∗
Mi(Y)
for the left-out validation samples and classified an individual as a long-term survivor if ˆpj ≥1/2.
Finally, we computed the classification accuracy for the validation set, then repeated the procedure
for the remaining partitions of the data. Tables 24.1 and 24.2 illustrate the variability of the weights
across different training sets.
Overall the accuracy of the MOMA with non-negative weights and the sum to zero constraint is
better than any of the individual models. The expression data, through the LDA models, appear to
improve the predictions over the clinical trees alone. A followup study by [2] confirmed association
of the top genes from the LDA models with long-term survival status.
24.7 Discussion
Expanding on the original work of [9, 26] we have presented a method for model averaging in the
M–open setting using sample re-use methods to approximate the predictive distribution of future
observations [19, 20]. The solution of the mixing weights depends on the choice of utility functions
aswellasanyconstraintsthatareincorporatedintheproblem.Thenon-negativityconstraint,which
isnatural,behaveslikealassopenaltyandforcesweightstobezerosothatredundantpredictionsare
not added. This is a striking difference to the traditional BMA solution where models with similar
predictions often have similar marginal likelihoods, with the result that posterior mass is ‘diluted’

496
M. Clyde and E. S. Iversen
Table 24.2 MOMA weights and prediction accuracy for the ovarian cancer data for five randomly
selected training and validation sets using the non-negativity and sum to one constraints.
set1
set2
set3
set4
set5
clin1
0.00
0.07
0.00
0.00
0.00
clin2
0.00
0.00
0.00
0.00
0.00
clin3
0.00
0.00
0.00
0.00
0.00
clin4
0.00
0.11
0.00
0.00
0.00
clin5
0.30
0.17
0.07
0.41
0.00
tree1
0.00
0.00
0.00
0.00
0.77
tree2
0.00
0.00
0.00
0.00
0.21
tree3
0.23
0.44
0.21
0.00
0.01
tree4
0.00
0.00
0.00
0.00
0.01
lda100.P1
0.00
0.00
0.00
0.00
0.00
lda100.P2
0.22
0.00
0.30
0.00
0.00
lda200.P1
0.00
0.00
0.00
0.00
0.00
lda200.P2
0.26
0.21
0.41
0.58
0.00
Accuracy
0.82
0.73
0.55
0.73
0.60
over similar models [14, 22]. MOMA using the log scoring rule is closely related to Ensemble BMA
[31],whichusesmaximumlikelihoodtoestimatetheweightsofaweightedaverageofbiascorrected
forecasts. The method of [37] uses a Dirichlet Process prior on the unknown distribution of the
data to obtain the predictive distribution and leads to similar solutions to MOMA, although their
method in the Gaussian case utilizes ordinary residuals, which may favour more complex models.
The solutions in MOMA do not take into account the complexity of the models, however, the
use of predicted residuals provides some penalization for poor out-of-sample prediction. If model
complexity is an important criterion this can be incorporated as an additional constraint in the
procedure.
AnopenquestionregardstheselectionofpartitionsofthedataforMOMA.Ratherthanpartition
Y into {yk, Y(k)} where yk is a single observation, [28] considered partitions {Y−S, YS} where YS
is now a vector. In a simple but illustrative example, [28] showed that using the maximal training
sample YS of dimension n −1 could lead to inconsistent selection of the true model, while use
of the minimal training sample (dimension one) had more desirable asymptotic properties. As
MOMAandtheDPmethodmaybeviewedasusingtrainingsamplesofsizen −1andn,asymptotic
properties of model averaging in this framework is an area that needs additional research.
Unlike traditional BMA, MOMA provides a formal mechanism for combining predictions from
models where the likelihoods are not commensurate. We have focused on linear combinations
of the predictions and predictive distributions as motivated by traditional BMA. However, there
is a rich literature on the related problem of combining expert opinions in risk analysis (with

Bayesian model averaging
497
beliefs represented as distributions) [13]. Rather than using the linear opinion pool (dating back
to Laplace), alternative methods such as logarithmic pooling or Bayesian approaches may be useful
in this context.
24.8 Acknowledgement
ThisworkwassupportedbyNationalInstituteofHealthgrant1-R01-HL-090559andgrantNational
Science Foundation DMS-1106891.
References
[1] Barbieri, Maria Maddalena and Berger, James O. (2004). Optimal predictive model selection.
Annals of Statistics, 32(3), 870–897.
[2] Berchuck, A., Iversen, E. S, Luo, J., Clarke, J. P., Levine, H. Horne D. A., Boyd, J., Alonso,
M. A., Secord, A. A., Bernardini, M. Q., Barnett, J. C., Boren, T., Murphy, S. K., Dressman,
H. K., Marks, J. R. and Lancaster, J. M. (2009). Microarray analysis of early stage serous
ovarian cancers shows profiles predictive of favorable outcome. Clinical Cancer Research, 15,
2448–2455.
[3] Berchuck, A., Jr., Iversen, E. S., Lancaster, J. M., Pittman, J., Luo, J., Lee, P., Murphy, S.,
Dressman, H. K., Febbo, P. G., West, M., Nevins, J. R. and Marks, J. R. (2005). Patterns of
geneexpressionthatcharacterizelong-termsurvivalinadvancedstageserousovariancancers.
Clinical Cancer Research, 11(10), 3686–3696.
[4] Berger, James O. and Pericchi, Luis R. (1996). The intrinsic Bayes factor for linear models.
See [7], pp. 25–44.
[5] Berger, James O. and Pericchi, Luis R. (1996). The intrinsic Bayes factor for model selection
and prediction. Journal of the American Statistical Association, 91, 109–122.
[6] Berger, James O. and Pericchi, Luis R. (2001). Objective Bayesian methods for model selec-
tion: Introduction and comparison. In Model Selection (ed. P. Lahiri), Volume 38 of Lecture
Notes in Statistics, pp. 135–193. Institute of Mathematical Statistics, Hayward, CA.
[7] Bernardo, José Miguel, Berger, James O., Dawid, A. Phillip, and Smith, Adrian F. M. (ed.)
(1996). Bayesian Statistics 5, Oxford, UK. Oxford Univ. Press.
[8] Bernardo, José Miguel, Berger, James O., Dawid, A. Phillip, and Smith, Adrian F. M. (ed.)
(1999). Bayesian Statistics 6, Oxford, UK. Oxford Univ. Press.
[9] Bernardo, José M. and Smith, Adrian F. M. (1994). Bayesian Theory. Wiley, New York, NY.
[10] Breiman, Leo (1996). Heuristics of instability and stabilization in model selection. Annals of
Statistics, 24, 2350–2383.
[11] Breiman, Leo (1996). Stacked regressions. Machine Learning, 24, 49–64.
[12] Chipman, Hugh A., George, Edward I., and McCulloch, Robert E. (2001). The practical
implementation of Bayesian model selection. In Model Selection (ed. P. Lahiri), Volume 38
of Lecture Notes in Statistics, pp. 65–134. Institute of Mathematical Statistics, Hayward, CA.
[13] Clemen, Robert T. and Winkler, Robert L. (1999). Combining probability distributions from
experts in risk analysis. Risk Analysis, 19(2), 187–203.
[14] Clyde, Merlise (1999). Bayesian model averaging and model search strategies (with discus-
sion). See [8], pp. 157–185.
[15] Clyde, Merlise, DeSimone, Heather and Parmigiani, Giovanni (1996). Prediction via orthog-
onalized model mixing. Journal of the American Statistical Association, 91, 1197–1208.
[16] Clyde, Merlise and George, Edward I. (2004). Model uncertainty. Statistical Science, 19(1),
81–94.

498
M. Clyde and E. S. Iversen
[17] Draper, David (1995). Assessment and propagation of model uncertainty (with discussion).
Journal of the Royal Statistical Society, Series B, 57, 45–70.
[18] Ferguson, Thomas S. (1974). Prior distributions on spaces of probability measures. The
Annals of Statistics, 2(4), 615–629.
[19] Geisser, Seymour (1975). A predictive sample reuse method with application. jasa, 70,
320–328.
[20] Geisser, Seymour (1993). Predictive Inference: An Introduction. Chapman & Hall, New York,
NY.
[21] Geisser, Seymour and Eddy, William F. (1979). A predictive approach to model selection
(Corr: V75 p. 765). Journal of the American Statistical Association, 74, 153–160.
[22] George, Edward I. (1999). Discussion of “Model averaging and model search strategies” by
M. Clyde. See [8].
[23] Gutiérrez-Peña, E. and Walker, S.G. (2001). A Bayesian predictive approach to model selec-
tion. Journal of Statistical Planning and Inference, 93(1–2), 259–276.
[24] Hoeting, Jennifer A., Madigan, David, Raftery, Adrian E., and Volinsky, Chris T. (1999).
Bayesianmodelaveraging:atutorial(withdiscussion).StatisticalScience,14(4),382–401.Cor-
rected version at http://www.stat.washington.edu/www/research/online/hoeting1999.pdf.
[25] Iversen, Edwin S. and Luo, Rosy J. (2003). Molecular and genetic modeling of disease risk.
In Proceedings of the American Statistical Association, Risk Section, Alexandria, VA: American
Statistical Association, pp. CD–ROM.
[26] Key, Jane T., Pericchi, Luis R. and Smith, Adrian F. M. (1999). Bayesian model choice: What
and why? See [8], pp. 343–370.
[27] Leamer, Edward E. (1978). Specification searches: Ad hoc Inference with Nonexperimental Data.
Wiley, New York, NY.
[28] Mukhopadhyay, Nitai, Ghosh, Jayanta K. and Berger, James O. (2005). Some bayesian predic-
tive approaches to model selection. Statistics & Probability Letters, 73, 369–379.
[29] Pittman, Jennifer, Huang, Erich, Nevins, Joseph, Wang, Quanli and West, Mike (2004).
Bayesian analysis of binary prediction tree models for retrospectively sampled outcomes.
Biostatistics, 5(4), 587–601.
[30] Proschan, F. (1963). Theoretical explanation of observed decreasing failure rate. Technomet-
rics, 5, 375–383.
[31] Raftery, Adrian E., Gneiting, Tilmann, Balabdaoui, Fadoua and Polakowski, Michael (2005).
Using Bayesian model averaging to calibrate forecast ensembles. Monthly Weather Review, 133,
1155–1174.
[32] Raftery, Adrian E., Madigan, David and Volinsky, Chris T. (1996). Accounting for model
uncertainty in survival analysis improves predictive performance. See [7], pp. 323–349.
[33] San Martini, A. and Spezzaferri, Fulvio (1984). A predictive model selection criterion. Journal
of the Royal Statistical Society, Series B, 46, 296–303.
[34] Winkler, R. L. (1999). “Bayesian Model Choice. What and Why?: Comment,” in J. M.
Bernardo, J. O. Berger, A. P. Dawid, and A. F. M. Smith, eds., Bayesian Statistics 6. Oxford:
Oxford University Press, 367–368.
[35] Walker, Stephen G. and Gutiérrez-Pena, Eduardo (1999). Discussion of Bayesian model
choice: What and why? See [8], pp. 367.
[36] Walker, Stephen G. and Gutiérrez-Pena, Eduardo (1999). Robustifying Bayesian procedures.
See [8], pp. 685–710.
[37] Walker,StephenG.,Gutiérrez-Pena,EduardoandMuliere,Pietro(2001).Adecisiontheoretic
approach to model averaging. The Statistician, 50, 31–39.
[38] Wolpert, Robert L., Clyde, Merlise A. and Tu, Chong (2011). Stochastic expansions using
continuous dictionaries: Lévy adaptive regression kernels. Annals of Statistics, 39, 1916–1962.

Part X
Finance and Actuarial Science

This page intentionally left blank 

25
Asset allocation in
finance: a Bayesian
perspective
eric jacquier
and nicholas g. polson
25.1 Introduction
B
ayesian methods have long played a role in finance and asset allocation since the seminal work
of de Finetti [12] and Markowitz (see [32]). In this paper, we show how the principle of maxi-
mum expected utility (MEU) [44], [45], [5] together with Stein’s lemma for stochastic volatility
distributions [19] solves for the optimal asset allocation. Stein’s lemma provides the solution to
the first-order condition that accompanies MEU. The optimal asset allocation problem couched
in equilibrium then leads to models such as the Capital Asset Pricing Model (CAPM) or Merton’s
inter-temporal asset pricing model (ICAPM).
We consider an investor who wishes to invest in the risky asset in order to maximize the expected
utility of their resulting wealth. Under logarithmic utility, this leads to the famous Kelly criterion
which maximizes the expected long-run growth rate of the risky asset. We review the link between
theKellyrule[37]andtheMertonoptimalassetallocation[40].Weillustratetheirimplementation
for a discrete binary setting and for the standard historical returns on the S&P500. Under a constant
relative risk aversion utility (CRRA) we use Stein’s lemma to derive fractional versions of the Kelly
rules where the amount allocated is normalized by the investor’s relative risk aversion.
The rest of the paper is as follows. Section 25.2 reviews the impact of Bayesian thinking in models
of finance: asset pricing equilibrium models; how agents learn from prices; properties of returns
data including predictability and stochastic volatility. Section 25.3 views asset allocation from a
Bayesian decision theoretic perspective (see, for example, [5]). Section 25.3 studies maximization
of the expected long-run growth rate and derives the classic Kelly and Merton allocation rules.
Section 25.4 describes methods for estimating this long-run growth rate. Section 25.5 describes
estimation methods for long-run asset allocation. Section 25.6 considers extensions to Bayesian
dynamic learning [3] and time-varying investment opportunity sets [15]. When investors are faced
with a return distribution that is an exchangeable Beta-Binomial process, the effect of dynamic
learning makes investors willing to invest a small amount of capital to current returns that have a
negative expectation, even though they are averse to risk. This is due to the fact that they might
learn that the investment opportunity set improves in the future and this is taken account of in the
Bayesian MEU solution. Finally, Section 25.7 concludes.

502
E. Jacquier and N. G. Polson
25.2 Bayesian methods in finance
Bayesian thinking underpins financial modelling in a number of empirical and theoretical ways.
Bayesian MCMC and particle methods are prevalent in empirical finance, see [33], [34]. [35] dis-
cuss MCMC methods in financial econometrics, [9] describes portfolio choice problems and [43]
provide an empirical analysis of the S&P500 stock index. [32] provide a recent survey of Bayesian
methods in finance. For example, many of the theoretical developments in finance rely on Bayesian
learning by agents. Here we discuss applications to learning from prices and the implications of
return predictability and stochastic volatility of asset returns [50].
25.2.1 Learning from prices
Bayesian methods are designed for learning, and market equilibrium occurs after individuals with
differences of opinion have an incentive to trade and finally agree on a price. The differences of
opinion literature has a long history dating to [13], [17], [18], [25], [28] and [49, 50]. [42] and [2]
discuss investor behaviour in financial markets.
A basic argument is as follows. Let y denote an observed signal. The insight is that observing
prices P(y) will change a trader’s beliefs. The trader needs to be able to coherently update their
probabilities via the Bayes theorem. [20, 21] summarizes the logic clearly as follows:
A smart trader t might even tell herself: let all the other traders naively use their own
information. I will wait until the market clears, and after observing the current realization
of P(y), make my purchases of commodities to maximize E [U(W)|yt, P(y)]. Since I am
a price taker, I will expect to do better than by trading now and maximizing E [U(W)|yt]
Market efficiency arguments follow a similar route, see [22]. Let π(y) be the vector of probabilities
that the trader holds for the states. If the observed prices P(π(y)) are invertible in π, the trader can
back out everybody else’s beliefs. Then implementing the principle of maximum expected utility
E

Ut(Wt)|yt, P(π(y))

≡E

Ut(Wt)|y

The trader who only has information yt can still act as if he had the full information set of all
investors’ signals y. Hence, in an efficient market prices are fully revealing of trader’s beliefs.
25.2.2 Return predictability and stochastic volatility
Time varying stochastic volatility is a widely documented feature of financial series, Typically,
volatility is time-varying, persistent, mean-reverting and in some instances has jumps [33, 34], [14].
[23, 24] shows that the eighteenth and twentieth century time series distributions of stock returns
are statistically very similar, and both exhibit stochastic volatility. In particular, he analyses biweekly
prices and returns for shares of the London stock market index and the Dutch East India company
from 1723–1794 and shows empirical evidence of stochastic volatility.
Another, more controversial, feature of financial returns is predictability, typically modelled as a
projection on a set of predetermined information variables. For example, the dividend yield, or net
payoutratio,variableplaysacentralrole,see[1]and[36].[36]combinepredictabilityandstochastic
volatility.Ratherthanaconstantoptimalallocationasisthecasewithi.i.d.returns,thetime-varying
opportunity set arising from predictability induces a hedging-demand into the investor allocation.
[1]showshowhorizoneffectscanbedramaticwhentheinvestorengagesinBayesianlearningabout
the mean return. In a continuous-time setting, [11] quantify the hedging demands from stochastic

Asset allocation in finance
503
volatility. [38] provide a theoretical analysis of dynamic portfolio strategies when there is jump risk,
an effect that is also present in a discrete time setting. Clearly, economically significant hedging
demand can exist and sensitivity analysis to models and priors is an important issue. Finally, as the
optimalallocationrulecanleadtoleverage,issuesofshort-salesandmargin-basedtradingarise.[16]
provide a framework for generalizing the CAPM when investors face margin-based constraints.
We now turn to the central problem of asset allocation.
25.3 Asset allocation
The asset allocation problem can be described as a Bayesian decision-theoretic problem [5] as
follows. An investor has initial wealth W0 that can be invested in a risk-free bond or a risky asset.
The end of period wealth is W = W0

(1 −ω)rf + ωR

where rf is the return on the risk-free
rate and R is the return on the risky asset. The Bayesian investor maximizes expected utility, namely
maxω E [U (W(ω))]. This leads to a first-order condition of the form:
E
8
U′(W)(R −rf )
9
= 0
Applying the definition of covariance yields
Cov
8
U′(W), R −rf
9
+ E

U′(W)

E
8
R −rf
9
= 0
ωE

U′′(W)

var(R) + E

U′(W)

E
8
R −rf
9
= 0
where we have used Stein’s lemma for a differentiable function g(X) where E|g′(X)| < ∞then
cov(g(X), X) = E

g′(X)

var(X). This has a solution for the optimal weight
ω⋆= 1
γ
E [R] −rf
Var [R]

(25.1)
where γ = −WE

U′′(W)

/E

U′(W)

is the agent’s relative risk aversion. This is a form of the
famous Merton optimal asset allocation result.
Thisresultcanbeextendedtoallowforstochasticvolatilityintheriskyassetreturn.Let(X|V) ∼
N (0, V) where V ∼p(V). The equivalent Stein result is
Cov

g (X) , Y

= EQ 8
g
′ (X)
9
Cov [X, Y]
Here EQ is taken with respect to the distribution q(V) = Vp(V)/E [V]. This is referred to as
the size-biasing of the original volatility distribution p(V). If Y = X, we have Cov

g (X) , X

=
EQ 8
g
′ (X)
9
var [X].The optimal allocation rule is then
ω⋆
SV =
1
Q
E [R] −rf
Var [R]

(25.2)
where Q = −EQ 
U′′
/E

U′
is the volatility adjusted risk aversion. See [19] for an analysis of
comparative statics.

504
E. Jacquier and N. G. Polson
In this one period setting, given that agents adopt the optimal allocation rule, one can then
showthatanequilibriumCapitalAssetPricingModel(CAPM)holds.Specifically,understochastic
volatility (SV), the expected return E(Rj) on the jth security is given by
E(Rj) −rf = βj

E(Rm) −rf

where rf is the risk-free rate and βj = cov(Rj, Rm)/var(Rm) is the risk premium.
A commonly used utility function is constant relative risk aversion (CRRA). It has the advantage
that the optimal rule is unaffected by wealth effects. The CRRA utility of wealth takes the form
Uγ (W) = W1−γ −1
1 −γ
The special case U(W) = log(W) for γ = 1 plays a central role in growth rate analysis. It leads to
maximizing the expected long-run rate of growth, namely
max
ω E

log WT|W0 = x

We now solve for this rule and derive the Kelly criterion and Merton’s rule.
25.4 Maximizing expected long-run growth
25.4.1 Kelly rule and Merton’s optimal allocation
The Kelly criterion corresponds to the following Bayesian decision problem under binary uncer-
tainty. Consider a sequence of i.i.d. bets where
p(Xt = 1) = p and p(Xt = −1) = q = 1 −p
The investor who maximises E

log WT|W0 = x

uses a myopic-rule with weight
ω⋆= p −q = 2p −1
Indeed, we can see that maximizing the expected long-run growth rate leads to the solution
max
ω E (ln(1 + ωWT)) = p ln(1 + ω) + (1 −p) ln(1 −ω)
≤p ln p + q ln q + ln 2 and ω⋆= p −q
If one believes the event is certain i.e. p = 1, then one bets all wealth and, a priori one is certain to
double invested wealth. On the other hand, if one thinks the bet is fair, i.e. p = 1
2, one bets nothing,
ω⋆= 0, due to risk-aversion.
We will use the following notation. Let p denote the probability of a gain and O = (1 −p)/p the
odds. We can generalize the rule to the case of asymmetric payouts (a, b) where
p(Xt = 1) = p and p(Xt = −1) = q = 1 −p

Asset allocation in finance
505
Table 25.1 Kelly rule
Market
You
p
ω⋆
4/1
3/1
1/4
1/16
12/1
9/1
1/10
1/40
Then the objective expected utility function is
p ln(1 + bω) + (1 −p) ln(1 −aω)
with optimal solution
ω⋆= bp −aq
ab
= p −q
σ
If a = b = 1 this reduces to the pure Kelly criterion.
A common case occurs when a = 1. We can now interpret b as the odds O that the market is
willing to offer the invest if the event occurs and so we write b = O. The rule becomes
ω⋆= p · O −q
O
We now provide a counter-intuitive example.
Example. Betting Consider the following two betting situations described in Table 1. Assume
two possible market opportunities: one where it offers you 4/1 when you have personal odds of
3/1 and a second one when it offers you 12/1 while you think the odds are 9/1. In expected return
these two scenarios are identical both offering a 33% gain. In terms of maximizing long-run growth,
however, they are not identical. From Table 25.1, the Kelly criteria advises an allocation that is twice
as much capital to the lower odds proposition: 1/16 weight versus 1/40.
Specifically, we have the following optimal weight calculation ω⋆= (pO −q)/O with
allocations
(1/4) × 4 −(3/4)
4
= 1
16 and (1/10) × 12 −(9/10)
12
= 1
40
respectively.
We now turn to the continuous-time setting and find Merton’s rule.
Continuously compounded returns: In a continuous-time setting, let μ denote the expected
return, σ the volatility and γ the risk aversion. Suppose that the risky asset follows a Black–Scholes
geometric Brownian motion model
dSt = St (μdt + σdBt)
for a constant volatility σ. Then the value of the asset at time T is
ST = S0 exp

μ −1
2σ 2

T + σ
√
tZ

where Z ∼N(0, 1). This model implies that returns are log-normally distributed.

506
E. Jacquier and N. G. Polson
Now consider the evolution of wealth for an investor who keep a constantly rebalanced weight
ω allocated to the risky asset and (1 −ω) to the risk-free rate rf . Their wealth Wωt now evolves
according to dWωt /Wωt =

(1 −ω)rf + ωμ

dt + ωσdBt. Let α = μ + 0.5σ 2 be the expected
arithmetic return on the market. Then, using Itˆo’s lemma, we can solve for wealth at time t with
Z ∼N(0, 1) as
Wt = W0 exp

(rf + ω(μ −rf ) −1
2ω2σ 2)t + ωσ
√
tZ

Similarly, the expected utility of wealth is
1
1 −γ exp

(1 −γ )

rf + ω(α −rf ) −1
2ω2σ2 + 1
2(1 −γ )ω2σ 2

Long-run growth rate: This leads to a natural definition of the growth rate as
G(ω) ≜ω(α −rf ) −γ
2 ω2σ 2
Maximizing the growth rate with respect to ω leads to the optimal allocation
ω⋆= 1
γ
α −rf
σ2
If γ = 1, this is known as the pure Kelly rule. Fractional Kelly rules are, as their name indicates,
rules that allocate a fraction of the Kelly rule to the risky asset via the agents risk aversion γ .
ThisanalysiscanbeseenasautilityinterpretationoffractionalKellyrulesandagreeswithStein’s
lemma approach in the previous section.
We can analytically compute the growth rate of wealth at the optimal allocation as:
G(ω⋆) = 1
γ

1 −1
2γ
 α −rf
σ
2
and if γ < 1
2, a case of an agent with extremely low risk aversion, then G(ω⋆) < 0.
Estimation risk also affects the growth rate: if estimation error mistakenly leads to using twice
the optimal rule, then we have lost all of the growth of our portfolio as G(2ω⋆) = 0.
We now provide an equivalence with the Kelly criterion by scaling wealth in terms of volatility
units. In the continuous case, let the investor be faced with a sequence of returns where the payout
has expectation E(RT) = μ
p(RT = σ) = p = 1
2 + 1
2
α −rf
σ
and p(RT = −σ) = q = 1
2 −1
2
α −rf
σ
Given (μ, σ), the optimal Kelly rule is
ω⋆= p −q
σ
=
α −rf
σ
· 1
σ = μ
σ 2
This provides our equivalence with Merton’s rule.

Asset allocation in finance
507
Example. S&P500: Consider a simple example of logarithmic utility (CRRA with γ = 1). This
is a pure Kelly rule. We assume iid log-normal stock returns with an annualized expected excess
return of 5.7% and a volatility of 16% which is consistent with long-run equity returns. In our
continuous time formulation ω⋆= 0.057/0.162 = 2.22 and the Kelly criterion which imply that
the investor borrows 122% of wealth to invest a total of 220% in stocks. This is a the risk-profile of
the Kelly criterion. One also sees that the allocation is highly sensitive to estimation error in ˆμ. We
consider dynamic learning in a later section and show how the long horizon and learning affect the
allocation today.
The fractional Kelly rule leads to a more realistic allocation. Suppose that γ = 3. Then the
Sharpe ratio is
μ
σ = 0.057
0.16 = 0.357 and ω⋆= 1
3
0.057
0.162 = 74.2%
An investor with such a level of risk aversion then has a more reasonable 74.2% allocation.
This analysis ignores the equilibrium implications. If every investor acted this way, then this
would drive up prices and drive down the equity premium of 5.7%.
25.5 Long run asset allocation
Discussions of long-term investment policy revolve around measures of the expected long-term
return on a risky portfolio such as the global market index. In this section we review how optimal
Bayesian asset allocation leads to an estimate of long run expected returns with very attractive
properties. We first give a background on the estimates resulting from the classical literature, and
their potential shortcoming.
25.5.1 Background on classical estimation
To concentrate on the main issue, that of the uncertainty in the mean, we assume that variance is
known and that returns are not auto-correlated, see [31] and [29] for a robustness analysis. Recall
that, as financial returns exhibit very little auto-correlation, there is no gain in observing the data
morefrequently.Inthiscontext,wethereforeconsiderasampleofT annuali.i.d.log-normalreturns
log(1 + R) ∼N(μ, σ 2). The reader will quickly see that they can adapt the discussion to any
estimator of the mean return given its associated variance. The long-term, H-period return, or
wealth return per dollar invested is log-normal. Long-term investors and policy-makers seek an
estimate of its expected compound return
E(VH) = eH(μ + 0.5σ 2)
(25.3)
The Maximum Likelihood estimate (MLE) of μ is the sample mean, it corresponds to the Bayesian
posterior mean with no prior information. For long-term forecasts, practitioners used to choose
a point estimate by compounding the sample geometric return G = 1
T log PT
P1 . This amounts to
estimating E(VH) by e ˆμH. Academics, however, tended to substitute ˆμ in the theoretical expecta-
tion (25.3), often invoking a maximum likelihood justification, where the estimator of a function
is approximated by the function of the estimator. This second suggestion is equivalent to the com-
pounding H times of the arithmetic sample mean. The difference in these two estimates becomes
very large in the long run. Using [47]’s geometric and arithmetic averages of 7% and 8.5%, the two
approaches grow $1 to $160 versus $454 over 75 years. [30] show that the ML approach makes little

508
E. Jacquier and N. G. Polson
sense; as H is often of a magnitude comparable to T, the ML estimator suffers from an enormous
upward bias due to the Jensen effect. An unbiased estimator is U = exp{H( ˆμ + 0.5σ 2(1 −H
T ))},
a simple log-linear combination of the geometric and arithmetic estimators. Observe how the
compounding factor is linearly decreasing in H. [31] argue that there is little justification for mere
unbiasedness, and derive a minimum mean squared error classical estimator of E(VH):
M = eH('μ + 0.5σ 2(1 −3 H
T ))
(25.4)
These estimators nest the ML (also known as arithmetic) estimator, only justified with extremely
small H
T , and the geometric estimator, itself only justified when H happens to be equal to T
3 . For
both U and M, the compounding factor decreases linearly with the horizon H, with a downward
penalty increasing with H
T . This is desirable because, (1) H affects the amount of compounding that
magnifies (by the Jensen effect) the upward bias due to the estimation error in μ, and (2) T reduces
the uncertainty in μ. For realistic values of μ, σ, T, H, the penalty is quite severe; longer-term
investors must be far more modest in their predictions than shorter-term investors, given the same
base estimator of μ.
However, since the compounding factor decreases linearly, it can lead to expected returns lower
than the risk-free rate, even negative, for long enough horizons. This feature of the estimator makes
noeconomicsense;anydiscountfactorshouldtendtonolowerthantherisk-freerateasthehorizon
increases. We now turn to a simple Bayesian estimator based on optimal asset allocation, which
naturally incorporates this desired feature.
25.5.2 Bayesian estimation of the long run expected return
Parameteruncertaintyhasanimportantimpactontheoptimalallocation.Thishasbeenrecognized
since [10]. Intuitively, the proper distribution for the investor to consider is the predictive density,
which gets inflated by the uncertainty in the mean. Relative to the case with known parameters, the
optimal allocation is then lower in the risky asset.
Consider first the classic [40] asset allocation, it is a framework with one risky asset with a i.i.d.
normallydistributedlog-returnN(μ, σ 2),arisk-freereturnrf ,andapowerutilitywithriskaversion
γ . If all parameters are known, [40] shows that, with continuous re-balancing, the horizon H is
irrelevant and drops out of the computation. He derives the now well-known optimal allocation,
w∗=
α −rf
γ σ 2
(25.5)
whereα = μ + 0.5σ 2 istheexpectedarithmeticone-periodreturn.Toobtainthisresult,assuming
constant rebalancing to an allocation w, it is easy to show first that the random H period return is
log normally distributed as
log(VH|α, σ) ∼N

(r0(1 −w) + wα −0.5w2σ2)H, w2σ 2H

(25.6)
The expected utility of this random wealth is then:
E[U(VH)] =
1
1 −γ exp

(1 −γ )H(r0 + w(α −r0) −0.5w2σ 2 + 0.5(1 −γ )w2σ 2)

.
(25.7)
The maximum likelihood estimator of μ is the standard average of past log-returns ˆμ ∼
N(μ, σ 2/T). With diffuse priors, the Bayesian posterior of μ is numerically equivalent, albeit with

Asset allocation in finance
509
the well-known difference in interpretation. It is clear that simply substituting'α in equation (25.7)
or (25.5) is not the optimal solution. [29] derives the Bayesian optimal allocation with uncertainty
in μ. The investor must consider the predictive utility, i.e. the utility of the predictive density of the
H period return. Because the integrations over the parameter and over the distribution of returns
can be exchanged, one can also view this as integrating μ out of the conditional expected utility in
(25.7), using its posterior distribution. The expected (predictive) utility becomes:
E[U(VH)] =
1
1−γ exp
1
(1−γ )H[r0 + w(ˆα −r0) −0.5w2σ 2 + 0.5(1 −γ )w2σ2(1 + H
T )]
2
(25.8)
We observe that α has been replaced by its posterior mean ˆα, and there is a new term in H/T at
the end. Maximizing the expected utility in (25.8), [29] finds the optimal asset allocation under
uncertainty:
w∗=
'α −r0
σ2 
γ (1 + H
T ) −H
T

(25.9)
Figure25.1plotstheoptimalallocationversusthehorizonforaninvestorwitharelativeriskaversion
of 4 and standard values of the mean and variance of the market return. It shows that the effect of
uncertainty on the optimal allocation is important for realistic values of μ, rf , σ, γ .
This optimal allocation in (25.9) implies an estimate of the expected long-term return under
uncertainty. For this investor with risk aversion γ , denote α∗this risk-adjusted future expected
return, where the risk is estimation risk. For this risk-adjusted return, the optimal allocation would
be the Merton allocation in (25.5). Equating the two allocations, we find that this risk-adjusted
estimate is
α⋆−rf =
'α −rf
1 + H
T (1 −1
γ )
(25.10)
It can be rewritten in terms of μ if desired. Figure 25.2 shows this estimate versus the horizon. Even
with a moderate risk aversion of 4, it reinforces the stark (low expected return) prediction of the
minimum mean squared error estimate in (25.4).
0
10
20
30
40
0.30
0.35
0.40
0.45
0.50
0.55
0.60
0.65
Horizon in Years
Optimal weight in equity
0.30
0.35
0.40
0.45
0.50
0.55
0.60
0.65
γ = 4, μ = 0.1, σ = 0.16, Rf = 0.05
μ known
Bayes, T=75
Bayes, T=40
Figure 25.1 Bayesian long-term asset allocation under uncertainty.

510
E. Jacquier and N. G. Polson
0
10
20
30
40
0.02
0.03
0.04
0.05
0.06
0.07
0.08
Horizon in years
Annualized estimate
Bayes, T=40
Bayes, T=75
MMSE, T=75
MMSE, T=40
γ = 4, μ = 0.06, σ = 0.16, Rf = 0.03
μ + 0.5σ2
Figure 25.2 Diffuse prior on μ. Bayesian and classical minimum mean-squared estimates of annual
compound factor.
This estimate is optimal for a given investor with risk aversion γ . Now, not only investors with
different horizons but also investors with different risk aversion, formulate different optimal point
forecasts. Note that the estimate in (25.10) can never be below the risk-free rate. This is to be
expected since it is consistent with the Bayesian optimal allocation which has a lower bound of
zero for the very long run.
Another related approach is the classic Black and Litterman [6, 7] framework for combining
investor views with market equilibrium. In a multivariate returns setting the optimal allocation
rule is ω⋆= 1
γ −1μ. The question is how to specify (μ, ) pairs? For example, given ˆ, BL
derive Bayesian inference for μ given market equilibrium model and a priori views on the returns
of pre-specified portfolios which take the form
( ˆμ|μ) ∼N

μ, τ ˆ

and (Q|μ) ∼N

Pμ, ˆ

Combining views, the implied posterior is (μ| ˆμ, Q) ∼N (Bb, B) with mean and variance spec-
ified by B = (τ ˆ)−1 + P′ ˆ−1P and b = (τ ˆ)−1 ˆμ + P′−1Q. These posterior moments are
then used in the optimal allocation rule.
25.6 Dynamic Bayes learning
When the opportunity set varies in time, the agent who maximizes long run growth will take
this into account in her decision rule today. The Bayesian dynamic portfolio problem dates to
[3, 4]. Here we will follow the analysis of [15] and consider the extensions to CRRA utility and
to exchangeable return distributions where the agent will engage in dynamic learning.

Asset allocation in finance
511
Remember that in an i.i.d. discrete setting, the classic Kelly rule is for p > 1
2,
ω⋆= p −q = 2p −1
and zero otherwise. The investor never bets on outcomes which have unfavourable (given their
views) odds, or even fair odds due to risk aversion.
Now if returns are still independent but have time-varying known probabilities pt we can still
solve for the optimal allocation: for pt > 1
2 invest
ω⋆
t =
pγ −1
t−1 −qγ −1
t−1
pγ −1
t−1 + qγ −1
t−1
If pt is unknown, a myopic Bayes rule is to track the sufficient statistics under a Beta prior Be(α, β)
distribution with T observations y = (y1, . . . , yT) as
E(p|y) = α T
t=1 yt
T + α + β
and uses a myopic plug-in rule by replacing p with E(p|yT).
To be fully Bayesian, we consider the exchangeable case where the investor can learn from expe-
rience. The solution of maximizing discounted expected utility has a very different solution. We
need to solve for the value function using Bellman’s equation and take account of the fact that in the
future they will be using Bayes rule and learning from prices.
Bayes learning
ConsideraconjugateBernoulli-Betamodelwhere (y|p) ∼Ber(p)andpriordistribution(p|a, b) ∼
Be(a, b) for given hyperparameters.
Value function
If we consider the case of power utility, the agent solves
max
ω E [U(WT)|W0 = x] = x1−γ VT(a, b)
where VT is the value function at period n.
Let fT(x|α, β) denote the optimal value of E

W1−γ
T
|W0 = x

when the prior distribution is
p ∼Be(α, β). The posterior is then Be (α + 1, β) given a success and Be (α, β + 1) given a failure.
At the initial condition, we have f0(x|α, β) = x1−γ . We can then solve for the value function
recursively using the identity
f1(x|α, β) = max
0≤b≤x

α
α + β (x + b)1−γ +
β
α + β (x −b)1−γ

= max
0≤c≤1

α
α + β (1 + c)1−γ +
β
α + β (1 −c)1−γ

= x1−γ V1(α, β)

512
E. Jacquier and N. G. Polson
Following recursively, we find
Vk(a, b) = max
0≤c≤1

a
a + bVk−1(a + 1, b)(1 + c)1−γ +
b
a + bVk−1(a, b + 1)(1 −c)1−γ

The optimal allocation is then
ωk(a, b) =
1 −w
1 + w
+
where w =
bVk−1(a, b + 1)
aVk−1(a + 1, b)
γ −1
, γ > 1
In the myopic Kelly case where γ = 1, we have the rule ωk(α, β) = 0 for α < β as one might
expect. You will not invest if your prior mean says the bet is unfair.
This is not true in general though due to the learning effect. For example, with a uniform prior
w10(1, 1) = 0.875
and
w9(1, 2) = 0
w10(1, 1) = 0.973
and
w9(1, 2) = 0.117
and the investors allocate a large portion to the risky asset. Even in the case where they see a failure
and they think that the odds are two to one against them, they are still willing to invest w9(1, 2) =
0.117 that is 11.7% of their wealth.
We therefore have the important effect of Bayesian learning on asset allocation, that the agent
will invest in the first period even though the expected return is negative and they are risk
averse!
25.7 Discussion
Bayesian thinking is central to finance and asset allocation. Stein’s lemma provides a useful tool for
analysingfirst-order maximumexpectedutilityconditions.TheclassicKellyandMertonallocation
rules correspond to Bayes rules where the investor maximizes the expected long-run growth rate of
accumulation.TheserulesaresensitivetoestimationriskandBayesianestimationmethodsprovide
the necessary inputs for expected returns and volatility.
Under the maximum growth condition when returns are independent these rules are myopic.
Investors will not be willing to allocate any capital to unfavourable bets. However, when the invest
opportunity set is extended to allow for Bayesian learning with exchangeable return distributions,
we see that risk-averse investors are willing to hold a small amount of the risky asset in the hope that
they will learn in the future that conditions are improved.
There are many avenues for future research. One currently active area is to use learning methods
to explain bubbles and speculative behaviour (see [26], [46] and [48]). Early models in this lit-
erature ‘explained’ bubbles by incorporating agents who are persistently ‘naive’ and do not update
beliefs coherently. The recent literature has focused more on the dynamics of Bayesian learning and
beliefstructures.Forexample,[41]allowsagentstodosomebeta-binomialupdatingoftheirbeliefs,
and [27] use prices to learn whether one is smart or dumb money in a market.
An interesting vignette comes from the South Sea bubble of 1720. The English parliament
passed the Bubble Act in the following year 1721 trying to ban future bubbles. At the height of
the bubble, the price-earnings multiple of the stock was between 150 and 190 based on current
earnings. In the first six month of 1720 the South sea stock rose 500 per cent. The major ‘news’
being only the large demand for their shares. A number of investors lost large sums of money. Sir
Isaac Newton (1642–1729) who was Master of the Mint from 1699 to 1729 and who put England on

Asset allocation in finance
513
the Gold standard in 1717, reportedly lost the equivalent of $20,000 in the Bubble. He was quoted
as saying I can predict the motion of Heavenly bodies but not the behaviour of the stock-market.
25.8 Acknowledgement
Polson is Professor of Econometrics and Statistics at the Chicago Booth School of Business. email:
ngp@chicagobooth.edu. Jacquier is visiting professor of finance at MIT Sloan School of Manage-
ment,onleavefromHECMontreal,email:jacquier@mit.edu.Jacquieracknowledgessupportfrom
the HEC Montreal professorship in derivative securities and Sloan research fund.
References
[1] Barberis, N. (2000). Investing in the long run when returns are predictable. Journal of Finance,
55, 225–264.
[2] Barberis, N. and R. Thaler (2003). A Survey of behavioral finance. Handbook of the Economics
of Finance (eds Constantinides et al.), 1053–1128.
[3] Bellman, R. and R. Kalaba (1956). On the role of dynamic programming in statistical com-
munication theory. IRE Transactions on Information Theory, IT-3, 197–203.
[4] Bellman, R. and R. Kalaba (1958). On communication processes involving learning and ran-
dom duration. IRE National Convention Record, 4, 16–20.
[5] Bernardo, J. and A. F. M. Smith (2000). Bayesian Theory. Wiley.
[6] Black,F.(1976).StudiesofStockMarketVolatilityChanges.ProceedingsofJournalofAmerican
Statistical Association, 177–181.
[7] Black, F. and R. Litterman (1991). Asset allocation: combining investor views with market
equilibrium. Journal of Fixed Income, 1, 7–18.
[8] Black, F. and R. Litterman (1992). Global portfolio optimization. Financial Analysts Journal,
48(5), 28–43.
[9] Borel,E.(1924).Aproposofatreatiseonprobability.RevuePhilosophique.ReprintedinStudies
in Subjective Probability, Kyburg and Smokler (1980) (eds).
[10] Brandt, M. (2009). Portfolio choice problems. Handbook of Financial Econometrics (eds
Ait-Sahalia and L. P. Hansen), 269–336.
[11] Brown, S. (1976). Optimal Portfolio Choice Under Uncertainty: A Bayesian Approach. Ph.D,
University of Chicago.
[12] Campbell, J. Y. and L. M. Viceira (2002). Strategic Asset Allocation. Oxford University Press.
[13] deFinetti,B.(1941).IlproblemadeiPieni.Reprinted:JournalofInvestmentManagement,4(3),
19–43.
[14] DeGroot, M. H. (1973). Reaching a consensus. Journal of the American Statistical Association,
69, 118–121.
[15] Eraker,B.,M.JohannesandN.G.Polson(2003).Theimpactofjumpsinvolatilityandreturns.
Journal of Finance, 58(3), 1269–1300.
[16] Ferguson, T. S. and C. Z. Gilstein (1985). A General Investment Model. Technical Report,
UCLA.
[17] Garleanu, N. and L. H. Pedersen (2011). Margin-based asset pricing and deviations from the
law of one price. Review of Financial Studies, 24(6), 1980–2022.
[18] Geanakopolos, J. and H. Polemarchakis (1982). We can’t disagree forever. Journal of Economic
Theory, 192–200.

514
E. Jacquier and N. G. Polson
[19] Geanakopolos, J. and J. Sebenius (1983). Don’t bet on it: a note on contingent agreements
with asymmetric information. Journal of the American Statistical Association, 78, 224–226.
[20] Gron, A., B. Jorgensen and N. G. Polson (2011). Optimal portfolio choice and stochastic
volatility. Applied Stochastic Models.
[21] Grossman, S. (1976). On the efficiency of competitive stock markets where traders have
diverse information. Journal of Finance, 31, 573–585.
[22] Grossman, S. (1978). Further results on the informational efficiency of competitive stock
markets. Journal of Economic Theory, 18, 81–101.
[23] Grossman, S. J. and J. E. Stiglitz (1980). On the impossibility of informationally efficient
markets. American Economic Review, 70, 393–408.
[24] Harrison, P. (1998). Similarities in the distribution of stock market price changes between the
eighteenth and twentieth centuries. Journal of Business, 71(1), 55–79.
[25] Harrison, P. (2001). Rational equity valuation at the time of the South Sea Bubble. History of
Political Economy, 33(2), 269–281.
[26] Harris, M. and A. Raviv (1993). Differences of opinion make a horse race. Review of Financial
Studies, 6(3), 473–506.
[27] Harrison, J. M. and D. Kreps (1978). Speculative behavior in a stock market with heteroge-
neous expectations. Quarterly Journal of Economics, 92(2), 323–336.
[28] Heaton, J. B. and N. G. Polson (2011). Smart Money, Dumb Money and Learning from Prices.
Working Paper, University of Chicago.
[29] Hong, H. and J. C. Stein (2003). Differences of opinion, short-sales constraints, and market
crashes. Review of Financial Studies, 16, 487–525.
[30] Jacquier, E. (2008). Long-term forecasts of mean returns: Statistical versus economic ratio-
nales. Working paper, HEC Montreal.
[31] Jacquier, E., Kane, A. and A. Marcus (2003). Geometric or arithmetic mean: a reconsidera-
tion. Financial Analysts Journal, 59(6), 46–53.
[32] Jacquier, E., Kane, A. and A. Marcus (2005). Optimal estimation of the risk premium for the
long-term and asset allocation. Journal of Financial Econometrics, 3, 37–56.
[33] Jacquier, E. and N. G. Polson (2011). Bayesian Methods in Finance. Handbook of Bayesian
Econometrics, H. van Dyk et al. (eds).
[34] Jacquier,E.,N.G.PolsonandP.Rossi(1994).Bayesiananalysisofstochasticvolatilitymodels.
Journal of Business and Economic Statistics, 12(4), 371–89.
[35] Jacquier, E., N. G. Polson and P. Rossi (2005). Bayesian analysis of stochastic volatility models
with fat-tails and correlated errors. Journal of Econometrics, 122(1), 185–212.
[36] Johannes, M. and N. G. Polson (2009). MCMC Methods for continuous-time financial
econometrics. Handbook of Financial Econometrics (eds Ait-Sahalia and L. P. Hansen), 1–72.
[37] Johannes, M., A. Korteweg and N. G. Polson (2011). Sequential Learning, Predictive Regres-
sions and Optimal Portfolio Allocation. Working paper.
[38] Kelly, J. R. (1956). A new interpretation of the information rate. Bell System Technical Journal,
35, 917–926.
[39] Liu, J. and J. Pan (2003). Dynamic derivatives strategies. Journal of Financial Economics, 69,
401–430.
[40] Markowitz, H. (2006). de Finetti scoops Markowitz. Journal of Investment Management, 4(3),
5–18.
[41] Merton, R. C. (1969). Lifetime portfolio selection under uncertainty: the continuous time
case. Review of Economics and Statistics, 50, 247–257.
[42] Morris,S.(1996).Speculativeinvestorbehaviourandlearning.Quarterly Journal of Economics,
111(4), 1111–1133.
[43] Odean, T. (1998). Volume, volatility, price, and profit when all traders are above average.
Journal of Finance, 53, 1887–1934.

Asset allocation in finance
515
[44] Polson, N. G. and B. V. Tew (2000). Bayesian portfolio selection: an empirical analysis of the
S&P500 indices 1970–1996. Journal of Business and Economic Statistics, 164–173.
[45] Ramsey, F. P. (1926). Truth and Probability. Reprinted in Studies in Subjective Probability,
Kyburg and Smokler (1980) (eds).
[46] Savage, L. J. (1954). Foundations of Statistics. John Wiley and Sons.
[47] Scheinkman, J. A. and W. Xiong (2003). Overconfidence and speculative bubbles. Journal of
Political Economy, 111(6), 1183–1220.
[48] Siegel, J. J. (1994). Stocks for the Long Run. McGraw-Hill.
[49] Stein, J. C. (2009). Sophisticated investors and market efficiency. Journal of Finance, 64(4),
1517–1548.
[50] Varian, H. R. (1985). Divergence of opinion in complete markets: A Note. Journal of Finance,
40(1), 309–317.
[51] Varian, H. R. (1989). Differences of Opinion in Financial Markets. In Financial Risk: Theory,
Evidence and Implications. Courtnet C. Stone (ed).

26
Markov chain Monte
Carlo methods in
corporate finance
arthur korteweg
T
hischapterintroducesMarkovchainMonteCarlo(MCMC)methodsforempiricalcorporate
finance. These methods are very useful for researchers interested in capital structure, invest-
mentpolicy,financialintermediation,corporategovernance,structuralmodelsofthefirmandother
areas of corporate finance. In particular, MCMC can be used to estimate models that are difficult
to tackle with standard tools such as OLS, Instrumental Variables regressions and Maximum Like-
lihood. Starting from simple examples, this chapter exploits the modularity of MCMC to build
sophisticated discrete choice, self-selection, panel data and structural models that can be applied to
avarietyoftopics.EmphasisisplacedoncasesforwhichestimationbyMCMChasdistinctbenefits
compared to the standard methods in the field. I conclude with a list of suggested applications.
Matlab code for the examples in this chapter is available on the author’s personal homepage.
26.1 Introduction
In the last two decades the field of empirical corporate finance has made great strides in employing
sophisticated statistical tools to achieve identification, such as instrumental variables, propensity
scoring and regression discontinuity methods. The application of Bayesian econometrics and in
particular Markov chain Monte Carlo (MCMC) methods, however, has been lagging other fields
of finance such as fixed income and asset pricing, as well as other areas of scientific inquiry such as
marketing, biology, and statistics. This chapter explores some of the many potential applications of
this powerful methodology to important research questions in corporate finance.
With the current trend in the corporate finance literature towards more complex empirical mod-
els, MCMC methods provide a viable and attractive means of estimating and evaluating models for
which classical methods such as least squares regressions, GMM, Maximum Likelihood and their
simulated counterparts are too cumbersome or computationally demanding to apply. In particu-
lar, MCMC is very useful for estimating nonlinear models with high-dimensional integrals in the
likelihood (such as models with many latent variables), or a hierarchical structure. This includes,
but is not limited to, discrete-choice, matching and other self-selection models, duration, panel
data and structural models, encompassing a large collection of topics in corporate finance such as
capitalstructureandsecurityissuance,financialintermediation,corporategovernance,bankruptcy,

Markov chain Monte Carlo methods in finance
517
and structural models of the firm. The MCMC approach thus opens the door to estimating more
realistic and insightful models to address questions that have thus far been out of reach of empirical
corporate finance.
To illustrate the method, I consider the effect of firm attrition on the coefficient estimates in
typical capital structure panel data regressions. Firms disappear from the sample for non-random
reasons such as through bankruptcy, mergers or acquisitions, and controlling for this non-random
selection problem alters the estimated coefficients dramatically. For example, the coefficient on
profitability changes by about 25%, and the coefficient on asset tangibility drops roughly in half.
Whereas estimating this selection correction model is difficult with classical methods, the MCMC
estimation is not particularly complex, requiring no more than standard probability distributions
and standard regressions. I provide the Matlab code for this model on my personal website.22
The goals of this chapter are two-fold. First, I want to introduce MCMC methods and provide a
hands-onguidetowritingalgorithms.Thesecondgoalistoillustratesomeofthemanyapplications
of MCMC in corporate finance. However, these goals come with a good deal of tension. Most
sections in this chapter start with developing MCMC estimators for simple problems that have
standard frequentist solutions that come pre-packaged in most popular software packages. The
reason I discuss these examples is not because I think that researchers should spend their time
coding up and running their own MCMC versions of these standard estimators, but rather to
illustrate certain core principles and ideas. These simple examples then function as a stepping stone
tomorecomplexproblemsforwhichMCMChasadistinctadvantageoverthestandardapproaches
such as least squares regressions, GMM, and Maximum Likelihood (or where such approaches are
simply not feasible). For example, Section 26.4 starts with a standard probit model, focusing on the
core concept of data augmentation. The modularity of MCMC allows us to extend this model to
buildadynamicselectionmodelinSection26.4.3thatisnearlyimpossibletoestimatebyMaximum
Likelihood or other classical methods.
To aid readers interested in applying MCMC methods, I have provided Matlab code for all the
numbered algorithms in this chapter on my personal webpage.23 Apart from educational purposes,
these examples can also be used as building blocks to estimate more complex models, thanks to
the inherent modularity of MCMC. It is, for example, quite straightforward to add a missing data
feature to a model by adding one or two steps to the algorithm, without the need to rewrite the
entire estimation code.
At the core of MCMC lies the Hammersley–Clifford theorem, by which one can break up
a complex estimation problem into bite-size pieces that usually require no more than standard
regressiontoolsandsamplingfromsimpledistributions.Moreover,MCMCmethodsdonotrelyon
asymptotic results but instead provide exact small-sample inference of parameters (and nonlinear
functions of parameters), and do not require optimization algorithms that often make Maximum
Likelihood and GMM cumbersome to use.
This chapter is organized by modelling approach. Section 26.2 introduces MCMC estimation
through a simple regression example. Section 26.3 introduces the concept of data augmentation
through a missing data problem. Section 26.4 discusses limited dependent variable and sample
selection models, currently the most widely used application of MCMC in corporate finance. Sec-
tion 26.5 addresses panel data models, introduces the powerful tool of hierarchical modelling, and
presents the application to capital structure regressions with attrition. Section 26.6 describes the
estimation of structural models by MCMC, and in particular the concepts of Metropolis–Hastings
sampling and Forward Filtering and Backward Sampling. Section 26.7 suggests a number of further
22 https://faculty-gsb.stanford.edu/korteweg/pages/DataCode.html.
23 Other popular packages for running MCMC estimations are R, WinBugs and Octave (all can be down-
loaded free of charge). Many code examples for these packages can be found online.

518
A. Korteweg
applications in corporate finance for which MCMC is preferable to classical methods. Section 26.8
concludes.
26.2 Regression by Markov chain Monte Carlo
A simple introduction to MCMC is found by considering the standard linear model
y = Xβ + ε,
where y is an N × 1 vector of dependent variables, X is an N × k matrix of predictor variables,
and the error term is distributed iid Normal, ε ∼N

0, σ2IN

. With conjugate Normal-Inverse
Gamma priors, σ 2 ∼IG(a, b) and β|σ2 ∼N

μ, σ 2 · A−1
, this problem has well-known ana-
lytical expressions for the posterior distribution of the parameters of interest, β and σ2. Alterna-
tively, one can learn about the joint posterior of β and σ 2, by drawing a sample from it through
MonteCarlosimulation.Algorithm1explainsthesimulationstepsindetail(foreaseofnotationIdo
not write the conditioning on the observed data, X and y, in the algorithm). First, draw a realization
of σ 2 from its posterior Inverse Gamma distribution. Next, draw a realization of β from its posterior
distribution, using the draw of σ 2 from the first step. Together, these two draws form one draw of
the joint posterior distribution p(β, σ 2|X, y). Repeating these two steps many times then results
in a sequence of draws from the joint posterior distribution. This sequence forms a Markov chain
(in fact the chain is independent here), hence the name Markov chain Monte Carlo [31, 33]. This
particular MCMC algorithm, in which we can draw from exact distributions, is also known as Gibbs
sampling.
Algorithm 1 Regression
1. Draw σ 2 ∼IG(a + N, b + S),
whereS =

y −Xm
′ 
y −Xm

+ (m −μ)′A(m −μ),andm = (X′X + A)−1(X′y+Aμ)
2. Draw β|σ 2 ∼N

m, σ 2 · (X′X + A)−1
3. Go back to step 1, repeat.
To illustrate the algorithm, I simulate a simple linear model with N = 100 observations and one
independent variable, X, drawn from a standard Normal distribution, and no intercept. I set the
true β = 1 and σ = 0.25. For the priors I set a = 2.1 and b = 1, corresponding to a prior mean
of σ2 of 0.91 and a variance of 8.26, and I set μ = 0 and A = IK · 1/10 000, such that the prior
standard deviation on β is one hundred times σ2. Unless otherwise noted, I use the same priors
throughout this chapter. Using Matlab it takes about 3.5 seconds on a standard desktop PC to run
25 000 iterations of Algorithm 1. Figure 26.1 shows the histogram of the draws of β and σ. These
histograms are the marginal posterior distributions of each parameter, numerically integrating out
the other. In other words, the histogram of the 25 000 draws of β on the left-hand plot represents
p

β|X, y

, and with enough draws converges to the analytical t-distribution. In the right-hand plot,
the draws of σ2 are first transformed to draws of σ by taking square roots before plotting the
histogram. This highlights the ease of computing the posterior distribution of nonlinear functions
of parameters. This example may appear trivial here, but this transformation principle will prove
very useful later.
The vertical lines in Figure 26.1 indicate the true parameter values. Note that the point estimates
areclosetothetrueparameters,despitethesmallsampleandtheprior meansbeingcentredfarfrom
the true parameter values. Moreover, the simulated posterior means coincide with the analytical

Markov chain Monte Carlo methods in finance
519
0.85
0.9
0.95
1
1.05
1.1
0
500
1000
1500
2000
2500
3000
3500
Posterior distribution of β
0.2
0.22
0.24
0.26
0.28
0.3
0.32
0.34
0
500
1000
1500
2000
2500
3000
3500
4000
Posterior distribution of σ
True β = 1.000
Posterior
mean = 0.972
OLS = 0.972
True σ = 0.250
Posterior mean = 0.258
OLS = 0.241
Figure 26.1 Posterior distribution of regression parameters. Histograms of 25 000 parameter draws
of the standard regression model estimated by MCMC on a simulated dataset of 100 observations.
The vertical lines indicate the true parameter values that were used to generate the data.
Bayesian solutions. The (1, 99%) credible intervals are [0.910, 1.034] for β, and [0.231, 0.290] for
σ. The posterior standard deviation of β is 0.026, compared to a standard error of 0.025 from OLS
regression. The difference is due to the MCMC estimates being small-sample estimates that do
not rely on asymptotic approximations, unlike standard errors. After all, the very definition of the
posterior distribution implies that the estimates are conditioned on the observed data only, not an
imaginary infinitely large dataset. This allows for exact inference, which may be quite different from
the asymptotic inference of classical methods, especially in smaller datasets.
26.3 Missing data
To make the inference problem more interesting, suppose that some of the observations in y are
missing at random (I postpone the problem of non-randomly missing data until the next section).
The problem of missing data is widespread in corporate finance, even for key variables such as
investmentandleverage.Forexample,forthe392,469firm-yearobservationsinCompustatbetween
1950 and 2010, capital expenditure is missing for 13.9% of the observations. Debt issuance has been
collected since 1971 but 14.1% of the 348,228 firm-year observations are missing, whereas market
leverage (book debt divided by book debt plus market value of equity) is missing 22.4% of the time.
For R&D expenditures the missing rate is over 50%. Even a canonical scaling variable such as total
assets is missing around 5% of the time. As I will illustrate below, MCMC provides a convenient
way of dealing with the missing data problem.
With missing data one loses the Bayesian analytical solution to the posterior distribution. How-
ever, the sampling algorithm from the previous section needs only one, relatively minor, modifica-
tion, based on the important concept of data augmentation [94], in order to deal with this issue.
Think of the missing observations, denoted by y∗, as parameters to be estimated along with the
regression parameters. In other words, we augment the parameter vector with the latent y∗, and
sample from the joint posterior distribution p

β, σ 2, y∗|X, y

.
The key to sampling from this augmented posterior distribution is the Hammersley–Clifford
theorem. For our purposes, this theorem implies that the complete set of conditional distributions
p

β, σ 2|y∗, X, y

and p

y∗|β, σ 2, X, y

completely characterizes the joint distribution. Algorithm
2 shows that, unlike the joint distribution, the complete conditionals are very straightforward to
sample from: p

y∗|β, σ 2, X, y

is a Normal distribution (and each missing observation can be

520
A. Korteweg
sampled independently since the error terms are iid), and p

β, σ 2|y∗, X, y

is simply Algorithm 1, a
Bayesianregressiontreatingthemissingy∗asobserveddata.Thisgivesafirsttasteofthemodularity
of the MCMC approach: we go from a standard regression model to a regression with missing data
byaddinganextrasteptothealgorithm.NoteagainthatIsuppresstheconditioningontheobserved
data in the algorithm.
Algorithm 2 Missing data
1. Draw the missing y∗
i for all i with missing yi, treating β and σ 2 as known:
y∗
i |β, σ 2 ∼N

X′β, σ 2
2. Draw β, σ 2 from a Bayesian regression with Normal-IG priors, treating the y∗as observed
data. The posterior distributions are:
σ 2|y∗∼IG(a + N, b + S)
β|σ2, y∗∼N

m, σ 2 · (X′X + A)−1
3. Go back to step 1, repeat.
Denoting by

σ 2(g) the draw of σ 2 in cycle g of the MCMC algorithm, the MCMC algorithm
thus starts from initial values {β}(0) and

σ 2(0), and cycles between drawing y∗, σ 2 and β,
conditioning on the latest draw of the other parameters:
{β}(0) ,

σ 2(0) →

y∗(1) →

σ 2(1) →{β}(1) →

y∗(2) →. . .
The resulting sequence of draws is a Markov chain with the attractive property that, under mild
conditions, it converges to a stationary distribution that is exactly the augmented joint posterior
distribution. This is the essence of MCMC. Figure 26.2 shows the first 50 draws of Algorithm 2,
using the same regression model as the previous section (with true β = 1 and σ 2 = 0.25), but
randomly dropping half of the observations of y. The convergence to the stationary distribution
is most noticeable for σ 2, and quite rapid for this particular model. The period of convergence is
called the ‘burn-in’ period and should be dropped before calculating parameter estimates and other
properties of the posterior distribution.
For many problems the likelihood function is not globally concave and has multiple local max-
ima. For such problems the chain needs to run for a larger number of cycles in order to fully
explore the posterior distribution. As a general rule, the MCMC algorithm is more hands-off than
Maximum Likelihood, which requires a great deal of manual work by the researcher to make sure
that a global optimum is reached, for example through the use of different starting values, applying
a variety of maximization algorithms, or simulated annealing routines. On rare occasions, it is
possibleevenfortheMCMCchaintoget‘stuck’inalocalmaximum,soitisstillgoodpracticetotry
different starting values. This is also helpful in determining when the chain has converged (Gelman
and Rubin [32] develop a convergence test based on the within and between variance of multiple
MCMC chains), and does not waste much computing time because the post-convergence draws
of the different chains can be combined in order to obtain a better approximation to the posterior
distribution.

Markov chain Monte Carlo methods in finance
521
10
20
30
40
50
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1.1
1.2
1.3
Iteration
β
10
20
30
40
50
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Iteration
σ
Simulation
True
Figure 26.2 Convergence of the MCMC chain. Plot of the first 50 iterations of the Markov chain from
the estimation of the missing data regression model in Algorithm 2, estimated on a simulated dataset
of 100 observations, of which 50 are dropped at random. The dashed horizontal lines indicate the
true parameter values that were used to generate the data.
Table 26.1 shows parameter estimates from two OLS regression approaches to the missing data
problem, as well as MCMC estimates. The first OLS results drop the observations for which y is
unobserved altogether. The second set of OLS estimates fill in the unobserved y∗using the point
estimates of β from the dropped observations. In other words, y∗
i = x′
i ˆβ. Unlike other common
fill-in schemes such as using the sample average, this results in unbiased estimates of β.
The key issue here is one of statistical efficiency: dropping the unobserved data altogether
ignores the information in X that is contained in the dropped observations, while filling in the
missing data with point estimates understates standard errors by ignoring the prediction variance
in the filled-in data. The latter problem is evident from the fact that the standard errors, as well
as the estimates of the residual standard deviations of the filled-in OLS regressions, are consider-
ably lower compared to the OLS regressions that drop the data with missing observations. The
MCMC algorithm solves both these problems by using all observations on X while accounting for
prediction variance by filling in different values for y∗every time we take a draw of β and σ 2. For
comparison, the first MCMC column shows the MCMC version of the regression dropping the
observations with missing ys. The posterior standard deviations are larger than the OLS standard
errors because they are small-sample rather than asymptotic estimates. The last column shows the
results from Algorithm 2, accounting for the information in the dropped X while also accounting
for the uncertainty of the missing y∗.
It is evident from Table 26.1 that integrating out the missing y∗is not particularly helpful in
this example. However, Table 26.2 shows that the benefits are more substantial when allowing for
missing observations on the explanatory variables in a multiple regression. Simulating and inte-
grating out the missing variables leads to parameter estimates that are generally closer to the true
parameters than the other methods, even for a relatively low correlation between the explana-
tory variables of 0.15. Moreover, since the full information about the dependent and non-missing
explanatory variables is exploited, the estimates have lower posterior standard deviations, i.e. they
are more precise, compared to the MCMC estimates that drop the observations with some missing
data altogether. The algorithm for tackling this problem is very similar to Algorithm 2, essen-
tially simulating the missing explanatory variables from a regression of the variable with missing
data on the other variables. An example of a corporate finance application of such a problem is

522
A. Korteweg
Table 26.1 Missing dependent variable regressions. Estimates of a missing data regression model
based on a simulated dataset of 100 observations, randomly dropping 50% of the dependent vari-
able data (but not the regressor). The true coefficients are shown in the first column (there is no
intercept). The OLS columns estimate the model by dropping the missing observations altogether
(the column labelled ‘Drop’), and filling in the missing data using fitted values from the ‘Drop’
regression (the column labelled ‘Filled’). The MCMC estimates in the ‘Drop’ column uses the stan-
dard Bayesian regression of Algorithm 1, dropping the missing observations. The final column uses
Algorithm 2, which simulates and integrates out the missing observations. The MCMC estimates
use 1 000 burn-in cycles followed by 25 000 cycles to sample the posterior distribution. Standard
errors for the OLS estimates and posterior standard deviations for the MCMC estimates are in
brackets.
True
OLS
MCMC
Drop
Filled
Drop
Alg 2
β
1
1.012
1.012
1.013
1.011
(0.047)
(0.025)
(0.058)
(0.057)
σ
0.25
0.239
0.171
0.298
0.297
–
–
(0.029)
(0.032)
in Frank and Goyal [29], who impute missing factors in leverage regressions using an MCMC
algorithm.
Other, more complex, cases also promise better results, for example if y follows a time-series
processbuthasmissingdatagapsintheseries.AnillustrationofthiskindisfoundinKorteweg[56],
who uses panel data for corporate bond and equity values to estimate the net benefits to leverage,
where a non-trivial fraction of the corporate bond values are unobserved. Another avenue for
improving performance is to sample the empirical distribution of the residuals, instead of imposing
the Normal distribution, to obtain results that are more robust to distributional assumptions. For
further information on using Bayesian methods for missing data, see Rubin [88] and Graham and
Hirano [36].
26.4 Limited dependent variable and selection models
In the previous section I assumed that data is missing at random. If data is instead missing for a rea-
son,itbecomesnecessarytospecifythemodelbywhichobservationsareselectedinordertoobtain
estimates of the parameters of interest. More generally, selection models are useful for addressing
many questions in corporate finance such as the effect of underwriter choice on bond issue yields,
thediversificationdiscountduetoconglomerationchoice,andtheimpactofbankversuspubicdebt
financingoncostofcapital(seeLiandPrabhala[68]foracomprehensiveoverviewandreferences).
I start this section with a simple probit example. The probit model serves as a basis to devel-
oping an estimation algorithm for the Heckman selection model. Since both probit and Heckman
have canned Maximum Likelihood-based modules in popular statistics packages such as Stata, this
may not sound very exciting. However, in Section 26.4.3 and beyond, I introduce extensions to

Markov chain Monte Carlo methods in finance
523
Table 26.2 Missing explanatory variable regressions. Estimates of a missing data regression model
based on a simulated dataset of 100 observations with two explanatory variables, y = x1β1 +
x2β2 + ε, and randomly dropping 50% of the observations on x2. The true coefficients are shown
in the first column. The explanatory variables have a correlation coefficient of 0.15. The first column
estimates the model by dropping the missing observations altogether, and the second column uses
the Griliches [37] GLS method to fill in the missing data, using a regression of the variable with
missing data on the other explanatory variable. The MCMC estimates in the ‘Drop’ column use the
standard Bayesian regression of Algorithm 1, dropping the missing observations, whereas the final
column uses a version of Algorithm 2 to simulate and integrate out the missing observations. The
MCMC estimates use 1 000 burn-in cycles followed by 25 000 cycles to sample the posterior dis-
tribution. Standard errors for the OLS estimates and posterior standard deviations for the MCMC
estimates are in brackets.
True
OLS
GLS
MCMC
Drop
Filled
Drop
Alg 2
β1
0.5
0.493
0.416
0.493
0.476
(0.038)
(0.002)
(0.042)
(0.039)
β2
–0.5
–0.425
–0.426
–0.424
–0.474
(0.044)
(0.003)
(0.049)
(0.039)
σ
0.25
0.251
0.262
0.280
0.282
–
–
(0.020)
(0.025)
dynamic selection, matching models and switching regressions, that are very difficult to estimate
with Maximum Likelihood, but are quite feasible with MCMC, both from an ease of implementa-
tion as well as from a computational perspective.
26.4.1 Probit model
In the standard probit model, yi has two possible outcomes, zero and one. The probability of
observing yi = 1 is:
pr( yi = 1) =  (xiβ)
where  (·) is the standard Normal cdf. Observations are assumed to be iid. Probit models
have been used in corporate finance to estimate, for example, the probability of issuing debt or
equity [49], takeovers [4], bankruptcy [84] and the firing of CEOs [53].
The estimation goal is to find the posterior distribution of β given y and X. It will prove conve-
nient to rewrite the model in the following way:
yi = I{wi≥0}
wi = xiβ + ηi

524
A. Korteweg
with ηi ∼N(0, 1), iid. The auxiliary selection variable, w, is unobserved. If w ≥0 then y equals
one, otherwise y equals zero. Augmenting the posterior distribution with w, MCMC Algorithm 3
(from Albert and Chib [3]) shows how to sample from the joint posterior distribution of β and
w, conditional on the observed data. The algorithm cycles between drawing from the complete
conditionals w|β and β|w, which by the Hammersley–Clifford theorem fully characterize the joint
posterior distribution.
Algorithm 3 Probit model
1. Draw wi|β for all i:
(a) for yi = 1:
wi|β ∼LT N (xiβ, 1)
(b) for yi = 0:
wi|β ∼UT N (xiβ, 1)
2. Draw β|w from a Bayesian regression of w on X, with Normal priors on β and known
variance equal to one:
β|w ∼N

(X′X + A)−1(X′w + Aμ), (X′X + A)−1
3. Go back to step 1, repeat.
In step 1, when y equals one, w must be greater than zero, and the distribution of w is therefore
truncated from below at zero. I denote this lower-truncated Normal distribution by LT N. Simi-
larly, UT N is the upper truncated Normal distribution, again truncated at zero. Step 2 draws from
the posterior distribution of coefficients in a Bayesian regression, as in Algorithm 1 but fixing the
variance of the error term to unity.
An advantage of MCMC for the probit model is in the calculation of nonlinear functions of
parameters. Researchers are often interested in the partial effects, ∂pr(y = 1|x)/∂x = φ(x′β)β,
which are highly nonlinear functions of β. With the standard Maximum Likelihood approach the
asymptotic distribution of the partial effects has to be approximated using the Delta method. With
MCMC we obtain a sample from the exact posterior distribution without relying on asymptotics
or approximations by simply calculating the partial effect for each draw of β (discarding the burn-in
draws). We can then compute means, variances, intervals etc.
Many extensions of Algorithm 3 have been developed, for example to the multivariate probit
model with several outcome variables [14], the multinomial probit that allows more than two dis-
crete outcomes [73], and the multinomial-t and multinomial logit models [15]. In the next section
I discuss another extension of the probit model, the classic Heckman selection model.
26.4.2 Heckman selection model
In the Heckman (also known as Tobit type 2) selection model, yi is no longer a binary variable but
can take on continuous outcomes:
yi = xiβ + εi
wi = ziγ + ηi

Markov chain Monte Carlo methods in finance
525
The outcome variable yi is observed only when wi ≥0. The error terms are distributed iid jointly
Normal with zero means, var(εi) = σ2, var(ηi) = 1, and correlation ρ. The top equation is
referred to as the outcome equation, and the bottom equation is the selection equation.
The Heckman selection model can be used to control for endogenously missing data and self-
selection by firms. For example, the choice to issue equity may depend on the type of firm. If there
is an unobserved component to firm type, then selection cannot be controlled for by covariates in
the outcome equation alone. In panel data applications it is common practice to use fixed effects
to control for selection, but these do not control for the fact that the reasons for selection can (and
often do) change over time. Selection models do allow for that possibility.
To estimate the Heckman model by MCMC, we decompose εi into a component that loads on
ηi and an orthogonal component ξi:
yi = xiβ + δ · ηi + σξ · ξi
wi = ziγ + ηi
whereδ = σ · ρ isthecovariancebetweenε andη,andσξ = σ ·
7
1 −ρ2 istheconditionalstan-
dard deviation of ε|η. From this representation it follows immediately that the selection equation
cannot be ignored if ρ (and hence δ) is not equal to zero. Consider the expected value of yi if it is
observed:
E

yi|wi ≥0, data

= xiβ + δE [ηi|ηi ≥−ziγ ]
Ignoring the selection equation (dropping δ · η in the observation equation) thus intro-
duces an omitted variables bias if ρ ̸= 0 [43]. The omitted variable, E [ηi|ηi ≥−ziγ ] =
φ(−ziγ )/(−ziγ ), is called the inverse Mills ratio.
MCMC Algorithm 4 (based on Li [65]) shows how to draw from the posterior distribution of
the parameters augmented with the latent selection variable, w, and the missing observations, y∗.
The algorithm essentially combines the randomly missing data routine with the probit estimation.
From the sampled parameters it is straightforward to use nonlinear transformations to recover
the posterior distribution of ρ and σ, as well as treatment effects, analogous to the calculation of
partial effects in the probit model.
The typical approach to estimating Heckman models is the two-step estimator [43]: In the
first stage we estimate the selection equation using a probit model, and in the second stage we
plug the fitted inverse Mills ratio from the first stage into the outcome equation to correct for the
omitted variable bias. This estimator generates inconsistent estimates for the covariance matrix in
the second stage, and correct standard errors have to be computed from an asymptotic approxima-
tion or through a bootstrap. Full information estimators (MCMC and the Maximum Likelihood
estimator) exhibit better statistical properties but are often criticized for their sensitivity to the
Normality assumption. Robust and nonparametric estimators have been proposed to deal with this
issue (e.g. [45, 71, 72]), but tend to be limited in the types of models they can estimate. For example,
Manski’s [72] model is limited to two regressors. In contrast, the MCMC algorithm is more flexible.
Van Hasselt [97] extends the algorithm to accomodate a mixture of Normals in the error terms
without losing the generality of the model. Mixtures of Normals are able to generate many shapes
of distributions such as skewness, kurtosis and multimodality, and the algorithm lets the data tell
you what the shape of the error distribution is. Van Hasselt also shows how to estimate the number
of mixture components, something that is very difficult to do with frequentist methods.24
24 A common concern with the standard selection model is that it is identified from distributional assump-
tions only, unless one employs an instrument that exogenously changes the probability of being selected but is

526
A. Korteweg
Algorithm 4 Heckman selection model
1. Draw wi, y∗
i |β, γ , δ, σ 2
ξ
(a) for yi observed:
wi|β, γ , δ, σ 2
ξ ∼LT N
⎛
⎝ziγ + ρ ·
⎡
⎣yi −xiβ
;
δ2 + σ2
ξ
⎤
⎦, 1 −ρ2
⎞
⎠
whereρ = δ/
;
δ2 + σ 2
ξ
(b) for yi not observed:
wi|β, γ , δ, σ 2
ξ ∼UT N (ziγ , 1)
y∗
i |wi, β, γ , δ, σ2
ξ ∼N

xiβ + δ [wi −ziγ ] , σ2
ξ

2. Draw β, γ |w, y∗, δ, σ 2
ξ from a Bayesian Seemingly Unrelated Regression ([99]) of [y; w] on
[X; Z], with Normal priors on β and γ and known covariance matrix :
β, γ |w ∼N

C′−1C + A
−1 
C′−1 
y; w

+ Aμ

,

C′−1C + A
−1
where
 =

σ2
ξ + δ2 δ
δ
1

⊗IN
and
C =

X 0
0 Z

3. Draw δ, σ 2
ξ |β, γ , w, y∗from a Bayesian regression of y −Xβ on w −Zγ , with Normal-IG
priors (see Algorithm 1).
4. Go back to step 1, repeat.
The Heckman selection algorithm outlined above can be adapted to estimate many related
models. For example, Chib [13] develops an MCMC algorithm to estimate the Tobit censoring
model where y takes on only non-negative values. Tobit censoring is relevant in corporate finance
applications because many variables are naturally non-negative, such as gross equity issuance, cash
balances and investment, and ignoring any censoring (for example from irreversible investment
bounding capital expenditures at zero) may mask certain causal relationships of interest. Double--
censoring can also be accommodated, to account for the fact that leverage (measured gross of cash)
is bounded between zero and one, which is important for estimating speed-of-adjustment models
[10, 51]. Similarly, the outcome variable may be qualitative (exactly zero or one) to model binary
outcomes such as default versus no default, or merger versus no merger.
orthogonal to ε, the shock in the observation equation [45]. Relaxing the Normality assumption may loosen
the distributional assumptions somewhat, but should not be seen as a substitute for an instrument.

Markov chain Monte Carlo methods in finance
527
The standard selection model has only two possible outcomes from selection: a data point is
either observed or not observed. In many corporate finance applications there are multiple possible
outcomes. For example, a company can choose not to raise debt financing, choose to issue public
bonds or to obtain a bank loan. Obrizan [81] shows how to estimate the selection model with
a multinomial probit in the selection equation by MCMC. Classical estimation of this model is
possibleaswell,butrequiresnumericalintegrationofthelikelihoodusingquadratureorsimulation.
Iwillreturntothisissuebelow.Intheremainderofthissection,Iintroducethreeotherextensionsto
theHeckmanmodelthathavemanypotentialapplicationsincorporatefinancebutareverydifficult
to estimate with traditional methods.
26.4.3 Dynamic selection
The standard Heckman model assumes that the error terms in the selection equation are inde-
pendent across units of observation. Under this assumption the unobserved data points are only
informative about γ , the parameters of the selection equation. They carry no further information
about the parameters of the outcome equation, β. In many corporate finance applications this is
not the case. For example, a firm may be more inclined to issue equity because a peer firm is doing
the same, or because some common unobserved factor induces both firms to issue. For the purpose
of illustration, consider the case of two firms. The outcome of the first company is unobserved and
the outcome of the second is observed. The expected value of the outcome of the second firm is
E

y2|w2 ≥0, w1 < 0, data

= x2β + δE [η2|η2 ≥−z2γ , η1 < −z1γ ]
Unlike the standard Heckman model, if the ηs are correlated then firm 1 carries information about
the conditional mean of y2 despite firm 1’s outcome being unobserved. In other words, the fact that
firm 1 is unobserved matters for the conditional mean of firm 2. With two firms the expectation is
a two-dimensional integral. With thousands of firms the integral becomes very high-dimensional,
and with the current state of computing power it is too time-consuming to evaluate in a Maximum
Likelihood estimation, or even to compute the inverse Mills ratio in the two-step procedure.25
Asimilarestimationissueariseswhentheoutcomevariablefollowsanautoregressivedistributed
lag (ADL) model. For example, consider the following ADL process for an individual firm:
yt = λyt−1 + xtβ + εt
Assume that the error terms are temporally independent (but ε and η are still contemporanesouly
correlated so that δ ̸= 0). In a two-period setting, if the outcome at time 1 is unobserved but
observed at time 2, the conditional mean of the outcome at time 2 is
E

y2|w2 ≥0, w1 < 0, data

= x2β + λE

y1|w2 ≥0, w1 < 0, data

+ δE [η2|η2 ≥−z2γ ]
With λ = 0 this works out to the standard Heckman correction. With non-zero λ we get a similar
integration issue as in the cross-sectional case, because the value of y1 depends on the realized
value of y2, due to the ADL process. The resulting model is thus a dynamic generalization of the
25 The usual way to numerically integrate out the latent variables in Maximum Likelihood is through quadra-
ture methods, which are effective only when the dimension of the integral is small, preferably less than five [96].
The alternative, Simulated Maximum Likelihood (SML), is less computationally efficient than MCMC. I will
discuss this in more detail in Section 26.5.

528
A. Korteweg
standard selection model. Autocorrelation in the error term results in similar estimation problems,
even without the lagged dependent variable.
Korteweg and Sørensen [59] tackle the estimation problem of the dynamic selection model
using an MCMC algorithm, and apply it to estimate the risk and return to venture capital funded
entrepreneural firms. The outcome variable is the natural logarithm of a start-up’s market value,
which follows a random walk (the ADL process above with λ = 1). However, the valuation is only
observed when the company obtains a new round of funding. The probability of funding depends
strongly on the firm’s valuation, and this gives rise to the selection problem. Korteweg and Sørensen
develop an MCMC algorithm to estimate the model in a computationally efficient way.26 In a
follow-up paper, Korteweg and Sørensen [60] apply the model to estimating loan-to-value ratios
for single-family homes, as well as sales and foreclosure behaviour and home price indices. They
extend the model to include multiple selection equations, in order to capture the probability of a
regular sale versus a foreclosure sale.
The dynamic selection model is very versatile, and can be applied to virtually any linear asset
pricing model with endogenous trading. The model is also applicable to a variety of corporate
finance problems, since many of the standard variables follow ADL processes, and, in addition,
autocorrelation in the error term is a common occurrence. Moreover, the estimation problem is not
unique to the selection model, but generalizes to the Tobit model and other censoring problems.
For example, investment follows an ADL but is censored at zero (if irreversible), leading to similar
integration issues as the dynamic selection model. Other examples include cash balances, default
or M&A intensity, and leverage, where the latter is subject to double censoring as mentioned above.
26.4.4 Switching regressions
In a switching regression, y is always observed, but the parameters of the outcome equation depend
on whether w is above or below zero:
yi =

yi0 = xi0β0 + εi0
if
wi > 0
yi1 = xi1β1 + εi1
if
wi ≤0
For example, Scruggs [89] considers the market reaction to calls of convertible bonds, which can
be ‘naked’ (without protection) or with the assistance of an underwriter that guarantees conver-
sion at the end of the call period. We observe the announcement reaction, y, under either call
method but the choice of method is endogenous through the correlations between η, ε0 and ε1.
Unlike standard average announcement effect studies, the β0 and β1 parameters in the switching
regressions reflect announcement effects conditional on the endogenously chosen call method, as
advocatedbyAcharya[1],Eckbo,Maksimovic,andWilliams[25],Maddala[70],andPrabhala[83].
Inotherwords,theparameterscapturethecounterfactualofwhatwouldhavehappenedifafirmhad
chosentheunobservedalternative.Assuch,wecanusethemodeltoanalysetreatmenteffects.Asin
the Heckman model, without an instrument the model is identified from parametric assumptions
alone, and imposing an exclusion restriction is helpful to achieve nonparametric identification.
Scruggs assumes that the error terms have a fat-tailed multivariate t-distribution and estimates the
model using an MCMC algorithm.
Switching models have many potential applications in corporate finance. For example firm’s cash
and investment policies may be different in growth versus recession regimes, or hiring and firing
intensities of CEOs may vary depending on the state of the firm.
26 A detailed description of the algorithm as well as Matlab and C++ code to implement it can be found on
my personal webpage.

Markov chain Monte Carlo methods in finance
529
It is possible to estimate a switching regression using classical methods [43, 61], but this is
cumbersome at best. The MCMC approach is flexible and easy to extend to more complex models.
For example, Li and McNally [67] use MCMC to estimate a switching regression with multiple
outcome equations within each regime. They apply their model to the choice of share repurchase
method, modelling the percentage of shares bought, the announcement effects and the tender
premium(iftherepurchaseisbytenderoffer).Thismodelcaninturnbeextendedtooutcomeequa-
tions that are not all continuous, but instead may be composed of a mix of continuous, truncated
and discrete outcomes. Another logical extension is to have more than two regimes since in many
cases corporate managers face a decision between multiple options (similarly to the multinomial
selection model). Such models become increasingly intractable with classical methods, but are
quite manageable using MCMC.
26.4.5 Matching models
A prevalent form of matching in corporate finance is the endogenous two-sided matching between
two entities. For example, firms match with banks for their financing needs, and CEOs match with
the firms they run. Sørensen [91] develops a model in which venture capitalists (VCs) match with
entrepreneurs. He asks whether the better performance of experienced VCs is driven by sorting
(more experienced VCs pick better firms) or influence (more experienced VCs add more value).
Sincesomeofthedimensionsalongwhichsortingoccursareunobserved,theresultingendogeneity
problem makes identification more tricky. The economics of the problem makes finding an instru-
ment very difficult, so Sørensen develops a structural model that exploits the fact that investors’
decisiontoinvestdependsontheotheragentsinthemarket,whereastheoutcomeoftheinvestment
does not. This provides the exogenous variation needed for identification.
The resulting model is prohibitively time-consuming to estimate by Maximum Likelihood
because investment decisions interact. If one investor invests in a start-up, then other investors
cannot.Thisimpliesthattheerrortermsinthemodelarenotindependentandhavetobeintegrated
jointly in order to compute the likelihood function. Given that there are thousands of investments,
such an extremely high-dimensional integral is computationally infeasible at present. Sørensen
develops a feasible MCMC procedure to estimate the model, which is computationally much
quicker than Maximum Likelihood.
Later studies [9, 82] use a similar MCMC methodology to study the matching of targets and
acquirers in M&A, and the matching between banks and firms.
ThenextsectiononpaneldatadivesdeeperintothebenefitsofMCMCmethodsforformulating
feasible estimators that perform high-dimensional integration in a computationally efficient way.
26.5 Panel data
In corporate finance one often observes the actions of a set of agents (companies, CEOs etc.) over
time. Such panel datasets are a rich source of identification, but also come with certain empirical
challenges. The standard issues in classical estimation of panel data models are the assumptions
regardingasymptotics(whetherweassumethatNorTapproachesinfinity)andtherelatedinciden-
talparameters problem[78],27 theinitialvaluesproblem[44],andtheHurwiczasymptoticbiasfor
27 The incidental parameters problem in the panel data context states that individual fixed effects are not
estimated consistently for fixed T, which results in inconsistent estimates of the parameters of interest. In some
cases a transformation (such as first-differencing to cancel out the fixed effects) can resolve the problem, but
these are rarely found outside of the linear and logit models.

530
A. Korteweg
ADLtypemodels(alsoknownasNickellbiasor,whenappliedtopredictiveregressions,Stambaugh
bias). The Bayesian approach avoids many of these pitfalls. For example, asymptotic assumptions
are unnecessary in the Bayesian paradigm since one conditions on the observed data only, and the
initial values problem is easier to handle since we can treat it like a missing data problem. Moreover,
MCMC methods allow for the estimation of a wider variety of panel data models, as I will discuss
below.
26.5.1 Random effects probit
Consider the panel data extension of the probit model with random effects (RE):
yit = I{wit≥0}
wit = xitβ + αi + ηit
For example, pr(yit = 1) could represent the probability that firm i goes bankrupt at time t. The
unit-specific intercept, αi, is assumed to be randomly generated from a Normal distribution with
mean zero and variance τ2, and is uncorrelated with ηit ∼N

0, 1 −τ 2
. This ‘random effect’
controls for time-invariant, unobserved heterogeneity across units.28 The parameters, β, are there-
fore identified from the time-series variation within firms.29
It is useful to think of the structure of the panel probit model as a hierarchy, where each level
builds upon the previous levels:
τ2 ∼IG (a, b)
αi|τ2 ∼N

0, IN ·

1 −τ2
/τ2
wit|αi, τ2 ∼N

xitβ + αi, 1 −τ2
This hierarchy can be extended to as many levels as desired (e.g. industry-company-executive-year
data).Hierarchicalmodels[69]areusefulinmanycorporatefinancesettings,andMCMCmethods
are very well suited for estimating these models, due to the complete conditional structure of
the algorithm. By breaking up the problem into simple regression steps based on its hierarchical
structure, one can estimate models for which even the act of writing down the likelihood function
becomes an arduous task. This allows one to compute correct standard errors and perform hypoth-
esis testing without resorting to standard shortcuts such as two-stage estimators.
Algorithm 5 shows how to extend the probit Algorithm 3 to estimate the panel probit model.
Steps 1 and 2 follow straight from Algorithm 3. Step 3 jointly draws a set of αs by regressing wit −
xitβ on a set of dummies, one for each firm (note that the prior means are zero). Step 4 estimates
the variance of the αs, again in regression form. Note that the Algorithm follows the hierarchy of
the model.
28 Alternatively, one can think of the random effects as a form of error clustering. Note that in Stata the
‘cluster’ command gives larger standard errors than the RE estimates, because Stata only considers the residual
idiosyncratic error after removing the group error component.
29 Therandomeffectsestimatorisdifferentfromthefixedeffectsestimator,whichistypicallyestimatedusing
dummy variables. The random effects estimator dominates the fixed effects estimator in mean-squared error
[26,92],whereasthebenefitofthefixedeffectsestimatoristhatitallowstheunit-specificmeanstobecorrelated
with the other explanatory variables. Mundlak [76] develops a correlated random effects model by specifying
αi = ¯xiγ + ui, where ¯xi is the time-series average of xit, and ui is an othogonal error term. Chamberlain [8]
extends the approach to a more flexible specification of α as a function of x.

Markov chain Monte Carlo methods in finance
531
Algorithm 5 Panel random effects probit
1. Draw wit|β, α, τ2 for all i and t:
(a) for yit = 1:
wit|β, α ∼LT N (xitβ + αi, 1)
(b) for yit = 0:
wit|β, α ∼UT N (xitβ + αi, 1)
2. Draw β|w, α, τ2 from a Bayesian regression of w −α on xit, with Normal priors on β and
known variance 1 −τ2:
β|w ∼N

(X′X + A)−1(X′(w −α) + Aμ),

1 −τ2
· (X′X + A)−1
where w −αis the stacked vector {wit −αi} across i and t, corresponding to the matrix X.
3. Draw α|β, w, τ2 from a Bayesian regression of w −Xβ on a NTxN matrix of firm dummies
D, using a N

0, IN ·

1 −τ2
/τ2
prior:
α|β, w, τ2 ∼N

D′D + IN ·

1 −τ2
/τ2−1 · D′(w −Xβ),

1 −τ2
·

D′D + IN ·

1 −τ2
/τ2−1
4. Draw τ2|α, β, w, using an IG (a, b) prior:
τ2|α, β, w ∼IG

a + N, b +
N

i=1
α2
i

5. Go back to step 1, repeat.
Besides the relative ease of programming,30 there is also a computational advantage to MCMC
in models with high-dimensional integrals over many latent variables. To appreciate why nonlinear
panel data models such as the panel RE probit are difficult to estimate by Maximum Likelihood,
consider the likelihood function:
L =
N

i=1
∞

−∞
 T

t=1


(2yit −1) · xitβ + αi
√
1 −τ2

φ
αi
τ

dαi
where, as before, φ(·) is the pdf of the standard Normal distribution, and (·) is the cdf. The term
in square brackets is the standard probit likelihood, conditional on αi. Because of the nonlinearity
of (·), the expectation over α cannot be solved analytically, so numerical methods are required to
evaluate the integral. In order to calculate the likelihood for one set of parameters, we need to eval-
30 The core (steps 1 through 5) of the panel probit routine of Algorithm 5 requires only about 20 lines of code
in Matlab.

532
A. Korteweg
uate N unidimensional integrals (in addition to the integrals required to evaluate the standard Nor-
mal cdf in the inner term of the likelihood). This can be done quite efficiently by Gauss–Hermite
quadrature (this is how Stata estimates this model). However, even with small changes to the model
the integral becomes of high dimension, at which point quadrature quickly loses its effectiveness
(even for as few as five dimensions [96]). For example, allowing for auto-correlation in the ηits, the
inner term, 	T
t=1 

(2yit −1) · xitβ+αi
√
1−τ 2

, becomes a T-dimensional integral with no analytical
expression.31 Allowing instead for cross-correlation (but no auto-correlation) in the error terms,
rewrite the likelihood as
T

t=1

f

y1t . . . yNt

g (α1 . . . αN) d(α1 . . . αN)
wheref(·)isthejointlikelihoodofy1t . . . yNt conditionalontheαs,andg(·)isthejointprobability
density of the REs. Even conditional on the αs, the N-dimensional joint likelihood f(·) has no
analytical solution, and on top of that one needs to integrate over the distribution of the REs. The
classicalalternativetoquadrature,SimulatedMaximumLikelihood,thusrequiresalargesimulation
exercise to evaluate the likelihood, covering the entire joint distribution of all latent variables. This
simulation has to be repeated for every guess of the parameters vector. MCMC on the other hand
switches between drawing new parameters and drawing the latent states. The integration over the
distribution of the latent states only needs to be done once, after the simulation is finished. This
speeds up estimation considerably. For example, Jeliazkov and Lee [53] extend MCMC Algorithm
5 and estimate a random effects panel probit model in which the ηit are serially correlated, and
apply it to women’s labour force participation. The estimation problem extends to many related
models for which the likelihood is non-linear in the parameters, and Algorithm 5 can be adapted to
estimate these models as well. For example, Bruno [6] develops an algorithm for a panel RE Tobit
model.Suchmodelshavewideapplicabilityincorporatefinanceforthesamereasonsasmentioned
above: many standard variables, such as leverage, investment or the decision to fire a CEO, are of a
binary or truncated nature, and fixed or random effects help control for time-invariant unobserved
heterogeneityinapaneldatasetting.Anotherusefulextensionistodealwithunbalancedpaneldata
by combining Algorithm 5 with the randomly missing data Algorithm 2.
26.5.2 Panel data with selection/attrition
In this section I combine the Heckman model from Section 26.4.2 with the panel RE model from
the previous section. In other words, I allow for non-random missing data in a random effects panel
model. This model is useful for controlling for non-random attrition, for example firms disappear-
ing through bankruptcy or merger/acquistion. In spite of the wide range of potential applications,
no canned estimators are currently available in popular software packages.32
The model is
yit = αi + xitβ + δ · ηit + σξ · ξit
wit = θi + zitγ + ηit
31 Note that the problem of integration with auto-correlated errors is closely related to the estimation of the
dynamic selection model of Section 26.4.3.
32 Running a panel Heckman in Stata and using the ‘cluster’ option to allow for random effects does not lead
to the same result, as the error clustering is not true Maximum Likelihood and does not allow for random effects
in the selection equation.

Markov chain Monte Carlo methods in finance
533
where δ and σξ are as defined in Section 26.4.2. The random effects are iid, αi ∼N

μ, τ2
,
and θi ∼N

κ, ω2
. The error terms are iid, ηit ∼N

0, 1 −ω2
, and ξit ∼N

0, σ 2
ξ

, and are
uncorrelated with each other and with the random effects. As in the standard Heckman model in
Section 26.4.2, selection enters through δ ̸= 0. Hausman and Wise [41] were the first to consider
this model. Other Maximum Likelihood approaches have been developed by Ridder [85], Nijman
and Verbeek [79] and Vella and Verbeek [98]. These models impose strong assumptions and are
computationally burdensome as they require the evaluation of multiple integrals. To circumvent
the computational burden, two-step estimators are typically employed, but these understate the
standard errors of the parameters in the observation equation by not accounting for the estimation
error in the inverse Mills ratios. MCMC is useful in these models because it is a computationally
more efficient estimation method, and it leads to correct inference, taking into account all sources
of estimation error.
Algorithm 6 shows the MCMC procedure, which is essentially the standard Heckman model of
Algorithm 4, augmented with the RE components as in Algorithm 5. Dropping Steps 3 through 6
and setting μ, κ, τ and ω to zero collapses the algorithm back to the standard Heckman model.
Similarly, forcing ρ = 0 collapses the algorithm down to a standard RE panel regression without
selection. Although Algorithm 6 is slightly longer than the algorithms shown thus far, it is not much
more complicated as it is still essentially a sequence of regressions.
To illustrate the importance of selection effects in corporate finance, I run a RE panel regression
of quasi-market leverage (defined as the book value of debt divided by the book value of debt plus
the market value of equity) on lagged profitability (operating income divided by the book value
of assets), tangibility (net property plant and equipment divided by book assets), market-to-book
ratio (market value divided by book value of equity) and the natural logarithm of book assets.
Regressions of this nature are quite common in the literature (e.g. [64]), although researchers
typically use fixed effects rather than random effects. I use data for a random sample of 1 000 firms
from Compustat between 1950 and 2010, for a total of 11 431 firm-years. The first column in Table
26.3 shows the standard GLS estimates of the regression coefficients. To gauge the effect of the
priors and the additional distributional assumptions of the MCMC algorithm in this example, the
second column of the table reports the MCMC estimates of the same regression model, ignoring
the selection issue (i.e. forcing ρ = 0). The coefficient estimates are very close, suggesting that
MCMCindeedreplicatesthestandardGLSregressionwhenignoringselection.Therandomeffects
are important as they account for 57% of the variance (result not reported in the table).
Animportantconcernisthatleverageismissingfor1 572,or14%,offirm-years.Ifobservationsare
not missing at random, for example if firms drop out of the sample due to a merger or a bankruptcy,
this can result in misleading estimates. Unreported results reveal that the missing firm-years are
characterized by higher profitability, higher tangibility and lower market-to-book ratios, suggesting
that they are indeed different in observable respects. This is in principle not a problem, unless there
is also selection on unobservable variables, which would manifest itself as a non-zero correlation
betweentheerrortermsintheselectionandobservationequations,ρ.ThelastcolumnofTable26.3
showstheestimatesfromMCMCAlgorithm6.Theposteriormeanofthecorrelation ρ is0.367,the
first percentile of the posterior distribution is 0.237 and the 1/10th percentile is 0.070. This finding
indicates that ρ is not zero and there is indeed non-random selectivity on unobserved variables.
Moreover, the selection correction has a large impact on parameter estimates. The coefficient on
profitability drops from –0.186 in the GLS to –0.237 after correcting for selection, a change of
about 25%. Moreover, the coefficient on tangibility roughly drops in half, from 0.207 to 0.101. The
estimates of market-to-book and firm size are only marginally affected by the selection issue. Note
also the well-known result that the estimate of residual variance (and hence standard errors) is
biased downwards when ignoring selection [42], hence the larger posterior standard deviations
of the coefficients in the selection correction model. For brevity I do not report the coefficients

534
A. Korteweg
Algorithm 6 Panel random effects with selection
1. Draw wit, y∗
it|α, θ, β, γ , δ, σξ , μ, τ2, κ, ω2
(a) for yit observed:
wit ∼LT N
⎛
⎝θi + zitγ + ρ
7
1 −ω2 ·
⎡
⎣yit −αi −xitβ
;
δ2 + σ 2
ξ
⎤
⎦,

1−ρ2
·

1−ω2
⎞
⎠
where ρ = δ/
;
δ2 + σ2
ξ .
(b) for yit not observed:
wit ∼UT N

θi + zitγ , 1 −ω2
y∗
it|wit ∼N

αi + xitβ + δ [wit −θi −zitγ ] , σ2
ξ

2. Draw β, γ |w, y∗, α, θ, δ, σξ, μ, τ2, κ, ω2 from a Bayesian Seemingly Unrelated Regression of
[y −α; w −θ] on [X; Z], with Normal priors on β and γ and known covariance matrix 
as in Algorithm 4 Step 2, where
 =

σ 2
ξ + δ2
δ
√
1 −ω2
δ
√
1 −ω2
1 −ω2

⊗IN
3. Draw α|w, y∗, θ, β, γ , δ, σξ, μ, τ2, κ, ω2 from a Bayesian regression of y −Xβ on a NTxN
matrix of firm dummies D , using a N

μ, IN ·

δ2 + σ2
ξ

/τ2
prior.
4. Draw θ|w, y∗, α, β, γ , δ, σξ , μ, τ2, κ, ω2 from a Bayesian regression of w −Zγ on a NTxN
matrix of firm dummies D , using a N

κ, IN ·

1 −ω2
/ω2
prior.
5. Draw μ, τ2|w, y∗, α, θ, β, γ , δ, σξ, κ, ω2 from a Bayesian regression.
6. Draw κ, ω2|w, y∗, α, θ, β, γ , δ, σξ , μ, τ2 from a Bayesian regression.
7. Draw δ, σ 2
ξ |w, y∗, α, θ, β, γ , μ, τ2, κ, ω2 from a Bayesian regression of y −α −Xβ on
w −θ −Zγ , with Normal-IG priors (see Algorithm 1).
8. Go back to step 1, repeat.
of the selection equation, although these could be interesting in their own right as they convey
information about the reasons for selection.
It is important to note that the results in Table 26.3 should be taken as suggestive only. There
are other observable variables that can be included in the observation and selection equations that
may alleviate the omitted variable problem. Moreover, I include the same variables in the selection
equation as in the observation equation, so the model is identified from distributional assumptions
only. A more thorough analysis requires an instrument that changes the probability of observing
leverage but does not drive leverage itself. In other words, one needs a variable in the selection
equation that does not appear in the observation equation. This requires delving deeper into the
economic reasons for selection. For example, the fact that more profitable firms are more likely to
disappear from the data suggests that the main source of attrition is mergers and acquisitions rather
than bankruptcy. One would then look for an instrument that drives M&A but not leverage. Other

Markov chain Monte Carlo methods in finance
535
Table 26.3 Random effects panel regressions. Random effects panel regression estimates of quasi--
marketleverage(definedasthebookvalueofdebtdividedbythebookvalueofdebtplusthemarket
value of equity) on profitability (operating income divided by the book value of assets), tangibility
(net property plant and equipment divided by book assets), market-to-book ratio (market value
dividedbybookvalueofequity)andthenaturallogarithmofbookassets,basedonarandomsample
of 1 000 firms spanning 11 431 firm-years from Compustat between 1950 and 2010. All explanatory
variables are lagged by one period. The first column uses the standard GLS method to estimating a
random effects panel model. The ‘No Selection’ column estimates the same random effects model,
butusingMCMC(Algorithm6withρ forcedtozero).Thecolumnlabelled‘Selection’usesMCMC
Algorithm6tocorrectforsampleselection.TheMCMCestimatesuse1000burn-incyclesfollowed
by 10 000 cycles to sample the posterior distribution. Standard errors for the GLS estimates and
posterior standard deviations for the MCMC estimates are in brackets.
Dependent variable: Quasi-market leverage
GLS
MCMC
No selection
Selection
correction
correction
Operating income / assets
–0.183
–0.186
–0.237
(0.015)
(0.015)
(0.017)
Tangibility
0.209
0.207
0.101
(0.016)
(0.016)
(0.021)
Market-to-book
–0.029
–0.029
–0.028
(0.002)
(0.002)
(0.002)
Log(assets)
0.020
0.020
0.019
(0.002)
(0.002)
(0.002)
ρ
–
–
0.367
–
–
(0.049)
possible extensions are to use two selection equations to separately model bankruptcy and M&A
as different reasons for attrition, essentially producing a joint model of capital structure, M&A and
bankruptcy, or to use the Korteweg and Sørensen [59] approach and model leverage as an AR(1)
process. Note also that the above example, given the use of random effects, only considers selection
in the time series. There could be important cross-sectional sample selection issues over and above
the time-series selection problem.
It is fairly straightforward to generalize Algorithm 6 to make the dependent variable a binary
(probit)or truncated (Tobit)variable. For example, Hamilton [38] specifies aRE panel Tobit selec-
tion model with t-distributed error terms and uses MCMC to estimate the effect of HMO choice
on healthcare costs. A different extension to the model is in Cowles, Carlin, and Connett [19] who
estimate a panel selection model allowing for two observation equations. Selection is multinomial
and the observation equations are observed at different cutoffs of the selection variable. They apply
their model to a longitudinal clinical trial measuring the effect of smoking cessation paired with an
inhaler treatment on lung function. The selection problem is that patients endogenously do not
show up for follow-up visits, or show up but fail to return canisters with the inhaler.

536
A. Korteweg
26.6 Structural models
Structural models have many potential applications in empirical corporate finance, and have been
used in areas such as capital structure (e.g. [46, 47, 93]) and corporate governance (e.g. [95]).
These models are typically estimated by simulated method of moments (SMM) or, in some cases,
Simulated Maximum Likelihood (SML, see e.g. [5, 80]). In this section I will illustrate the benefits
of estimating these models by MCMC, especially models with latent state variables.
Consider Merton’s [75] model of the firm in state-space representation:
vt = vt−1 + μ + σεt
Et = P (vt, σ; θ) + ηt
The state variable of the model is the natural logarithm of the market value of the firm’s assets, vt,
which follows a random walk with drift μ. The shocks to firm value, εt, have a standard Normal
distribution. The observed market value of equity, Et, is a function of vt, volatility, σ, and other
parameters, θ. In Merton’s model the pricing function, P(·), is the Black–Scholes European call
option function, and the parameters vector θ consists of the maturity of debt (time-to-expiration),
the face value of debt (strike price), and the risk-free interest rate, all of which I will assume are
observed.Thepricingerror,ηt,allowsforunmodelledfeaturessuchasmarketmicrostructurenoise
[50, 58] that may force observed prices away from the model.33
I assume for now that, in addition to θ, the time series of firm value, vT = {v1 . . . vT} as well as
the equity values are all observed. The inference problem is then to obtain the posterior distribu-
tion p

σ 2, μ|ET, vT
. As usual, an MCMC algorithm cycles between drawing from the complete
conditionals, p

μ|σ 2, ET, vT
and p

σ 2|μ, ET, vT
. The first distribution is a simple Bayesian
regression and poses no problems. The second distribution is more tricky because σ is present in
both equations of the state-space, and although the conditional posterior can be evaluated without
much trouble, it is not a known distribution that is easily sampled. The solution to this problem is
an accept–reject type algorithm known as Metropolis–Hastings.34 Denote by ς the current draw
of

σ 2(g) in cycle g of the MCMC algorithm. To sample the next draw,

σ2(g+1), one proceeds
as follows:
1. Draw s from a proposal density f (s; ς).
2. Compute α = min

1, p

s|μ,ET,vT
·f(ς;s)
p(ς|μ,ET,vT)·f(s;ς)

.
3. Set

σ 2(g+1) =
 s w/ probability α
ς w/ probability 1 −α
.
Notethatweusethelatestdrawforμwhencomputingα.Theproposaldensityiskeyfortheperfor-
manceofthealgorithm.Ideally,itisadensitythatisclosetothetargetdensity,p

σ2|μ, ET, vT
,yet
easy to sample from. The proposals can be iid (commonly known as ‘independence Metropolis’) or
proposalsmaydependonthecurrentdrawofσ 2.Apopularexampleofthelattertypeisthe‘random
33 An alternative motivation for the pricing errors is simply to avoid a stochastic singularity problem in the
sense that the model makes predictions about more observable variables than there are structural shocks and
hence could be rejected with the observation of as few as two time periods.
34 The Metropolis–Hastings algorithm is derived from the detailed balance condition of the stationary dis-
tribution of the Markov chain, which ensures that the chain will be reversible. I will not go into the theoretical
detailshere,butinsteadreferthereadertoJohannesandPolson[54],RobertandCasella[86],orRossietal.[87]
for a comprehensive treatment.

Markov chain Monte Carlo methods in finance
537
walk Metropolis’ in which s equals the current draw, ς, plus a random increment. Note that if we
are able to sample from the target density, i.e. f(·) = p(·), then we are back to a Gibbs sampler step:
α = 1 and we always accept the proposal. In this sense we can think of the Metropolis–Hastings
algorithm as a generalization of the Gibbs sampler. As in the Merton model example, an MCMC
algorithm can be a mixture of Gibbs steps and Metropolis–Hastings steps.
It is important to ‘tune’ the proposal density to get reasonable performance from the sampler.
Clearly an acceptance rate near zero is bad because the sampler will be slow to converge to, and
explore,theposteriordistributionduetothemanyrejectedproposals.Anacceptanceratenear100%
may seem great at first sight, but one may worry that the chain is moving very slowly because the
incremental steps in a random walk Metropolis are too small, or because the tails of the proposal are
too thin relative to the target distribution in an independence Metropolis sampler. Either way, we
may be undersampling an important part of the posterior distribution, leading to poor inference.
Thereisnogenerictheoreticaladvicethatcanbegivenastohowbesttopickaproposaldistribution.
Typical advice in practice is to aim for a 50–80% acceptance rate, but it should be noted that the
acceptance rate alone does not determine whether the sampler does a good job. For more details
on the Metropolis–Hastings algorithm and tuning, see Johannes and Polson [54], Robert and
Casella [86], or Rossi et al. [87].
In many structural models inference is complicated further by the fact that the underlying state
variable is not observed (e.g. [46, 47, 63]). MCMC deals with this by augmenting the posterior
distribution with the state variable, p

σ, μ, vT|ET
, which can subsequently be integrated out to
obtain the marginal distribution of the model parameters. Conveniently, the complete conditionals
for μ and σ do not need any modification (they are already conditioned on a draw of vT), so the
only extra step that is required is to sample from the conditional distribution of the state variable
p

vT|μ, σ, ET
. In the Merton model a linear Kalman filter provides us with the distribution of
v1|E1 through vT|ET, dropping the conditioning on the parameters for ease of exposition. Since
we need to draw from v1|ET through vT|ET, one more step is required: smoothing. This essentially
involves running the Kalman filter again, but going backwards starting at time T, and sampling the
vtsaswegoalong.Thisprocedureiscalled‘ForwardFiltering,BackwardsSampling’(FFBS)[7,30].
Korteweg and Polson [58] describe the MCMC algorithm for a structural model of the firm in
detail,withFFBSandMetropolis–Hastingssamplingforσ 2.TheyestimateLeland’s[62]modelfor
apaneloffirmsandcomputecorporatebondcreditspreads,takingintoaccounttheeffectofparam-
eter and latent state uncertainty. Using the robust pricing framework of Hansen and Sargent [40],
the bond price under uncertainty, Pt, is the expectation of the model price over the distribution of
latent state and parameters given the data up to time t:
Pt = Eσ,vt|Et (B(vt, σ; θ))
≈1
G
G

i=1
B

v(i)
t , σ(i); θ

whereB(·)isthemodel’sbondpricingfunction.Bayesianmethodsareverywellsuitedforproblems
of learning and uncertainty, since the posterior distribution captures the degree of parameter and
state uncertainty based on the observed data. The second line shows the approximation to the
bond price based on G cycles of the MCMC algorithm (after dropping the initial burn-in cycles).
The expectation in the top line becomes a simple average over the draws of the algorithm. The
concavity of the bond pricing formula inv and σ results in larger credit spreads for bonds compared
to estimates from standard methods (e.g. [27]).
Apart from the usefulness for learning and uncertainty problems, MCMC methods have the
same advantage over SMM and SML in speed of computation as described in Section 26.5.1: instead
of simulating the latent state variables for each set of parameters as is required in SMM/SML, the
MCMCalgorithmbouncesbetweenparameterdrawsanddrawsofthestatevector,leadingtofaster

538
A. Korteweg
convergence. Moreover, the MCMC and other likelihood-based estimates incorporate all available
information, unlike SMM which only considers a set of moments chosen by the researcher and
therefore results in less powerful tests. However, this efficiency gain does come at the expense of
making stronger distributional assumptions on the observation error, η (see Korteweg and Lem-
mon [57] for a detailed discussion of structural model testing). Finally, as shown earlier, MCMC
gives correct small-sample inference and is amenable to computing nonlinear functions of param-
eters and states. This is a particularly useful feature for structural models where the observables are
often nonlinear in both the parameters and states.
The MCMC algorithm for structural models can be extended in various important directions,
includingbutnotlimitedtopaneldata,autocorrelationintheerrorstructure,handlingmissingdata,
and adding stochastic volatility and jumps to the state process, as well as more flexible observation
error distributions, for example through mixtures of Normals. The inherent modularity of MCMC
makes this task more convenient to handle than with classical methods.
There are other applications of state space models outside of strict structural modelling. One
example is Korteweg [56], who uses MCMC to estimate the net benefits to leverage from a state
space model in which the state vector is composed of individual firms’ unlevered asset values and
industry asset betas. The observations are the market values of firms’ debt and equity and their
riskiness (i.e. betas) with respect to the market portfolio. Under the identifying assumption that
all firms within the industry share the same (unlevered) asset beta, Korteweg identifies the present
value of the net benefits to leverage as a function of leverage and other firm characteristics such as
profitability, market-to-book ratio, and asset tangibility. The MCMC algorithm for this model is
similar to the algorithms described above, employing the Kalman filter and FFBS to integrate out
the latent states.
26.7 Extensions and other applications
In this section I will highlight some further potential applications of MCMC methods in corporate
finance, focusing on cases which are difficult to estimate using classical methods.
Hierarchical models are a particularly useful type of model that has to date seen little application
incorporatefinance.HierarchicalmodelswereintroducedinSection26.5.1inthecontextofestimat-
ingrandomeffectsinapanelprobitmodel,butthebasicconceptofthehierarchicalmodelhasmuch
broader applicability. For example, consider a model of the decision to issue equity. The typical
approach would be to run a probit or hazard model that specifies the probability of issuing equity as
a function of a number of covariates, most importantly the financing deficit, one of the key variables
in the pecking order theory of capital structure. However, a common concern is that the financing
deficit and the decision to issue equity are jointly determined in the sense that they are both driven
by (unobserved) investment opportunities. Lacking a good instrument or natural experiment, one
example of a hierarchical modelling solution to this problem is to model the deficit conditional on
an underlying (latent) investment opportunity variable, and to specify the probability of issuing
equity conditional on both the deficit and the latent variable, potentially allowing for correlation
between the error terms.35
It is also useful to add hierarchical model features to structural models. For example, it would be
interesting to analyse the cross-sectional distribution of firms’ bankruptcy costs, or the distribution
of CEO talent in structural models of the firm. However, there is usually not enough data to reliably
pindowntheestimateonafirmbyfirmbasis.Onewaytoovercomethisissueistouseahierarchical
35 Of course an instrument that shocks the deficit (but not the equity issuance probability) will help the
identification of the model. The intuition is similar to the argument for having an instrument in the Heckman
selection model.

Markov chain Monte Carlo methods in finance
539
setup and specify a firm’s bankruptcy cost or a CEO’s talent as being generated from a particular
distribution, using the observed data to estimate the mean and variance of this distribution, as was
done in the random effects model.
Bayesian methods are also very useful for duration (hazard) models. For example, one could
model the probability of attrition in Section 26.5.2 through a hazard rate instead of a probit model.
This would do a better job of capturing the essence of liquidation or an acquisition in the sense that,
unlike in the probit model, a firm could not come back to life the next period. Li [66] estimates the
duration of Chapter 11 bankruptcy spells from a Bayesian perspective, using an approximation to
the posterior density, accounting for parameter and model uncertainty as well as providing correct
sample properties based on the small dataset. Horny, Mendes and Van den Berg [48] estimate
a hazard model of job duration with worker and firm-specific random effects. They use random
effects because fixed effects are not feasible due to right-censoring of the unemployment spells,
and because the random effects allow them to decompose the variation of job durations into the
relative contributions of workers’ and firms’ characteristics. In addition, they allow for multiple job
spells per worker and for correlation between the worker and firm random effects. They estimate
the model by MCMC because the joint dependence of the random effects makes classical likeli-
hood-based estimation very difficult for both computational speed and the difficulty of finding the
appropriate asymptotic distribution in order to calculate standard errors. Chen, Guo and Lin [11]
develop a model of switching hazards which they use to estimate the probability of IPO withdrawal
in relation to its subsequent survival hazard, which in turn depends on the IPO decision. They
use MCMC because of the computational advantage in both estimation and performing model
selectionandcross-validation,aswellasthesmall-sampleinferenceproperties.FahrmeirandKnorr
Held [28] develop a nonparametric MCMC method for a duration model with multiple outcomes,
suchasunemploymentendinginafull-timeversusapart-timejob.Suchamodelcould,forexample,
be applied to firms’ survival spells ending in either bankruptcy or an acquisition, or CEO’s tenure
spells ending in forced or voluntary retirement.
Another area where MCMC can be applied is count data. These models are related to duration
models, but instead of a time spell the dependent variable is a non-negative integer that counts the
number of events that have occurred within a given time period. Examples include the number
of takeover bids received by a target firm [52], the number of failed banks [22] or the number of
defaults in a portfolio of assets [55]. Chib, Greenberg and Winkelmann [16] develop an MCMC
algorithm for panel count data models with random effects. They argue that Maximum Likelihood
is not a viable estimator for this model due to the presence of random effects paired with the
nonlinearity of count data. Chib and Winkelmann [17] generalize this model to allow for multivari-
atecorrelatedcountdata,representedbycorrelatedlatenteffects.MunkinandTrivedi[77]embeda
count model within a self-selection model with two correlated outcome equations, one of which is
a count and the other a continuous variable. The authors strongly motivate their MCMC approach
bythecomputationaldifficultiesencounteredwhenattemptingtoestimatethemodelbySML.Deb,
Munkin and Trivedi [23] extend this selection model by allowing the entire outcome function to
be different among the treated and untreated groups, essentially turning the model into a switching
regression with count outcomes. They apply their MCMC estimation to separate the incentive and
selection effects in private insurance on the number of doctor visits, using a multiyear sample of
the US adult non-Medicare population. This could be applied in corporate finance, for example, to
identify the incentive and selection effects in public versus private firms undertaking acquisitions,
using the count of M&A as the dependent variable.
A class of models that is very closely related to the switching regressions of Section 26.4.4, and
which is also related to the state space models of Section 26.6 is the set of hidden Markov models
(HMM). Unlike switching regressions, there are typically no covariates that drive the selection into
a specific state, but they generally allow for multiple states (in some cases a continuum of states) of
the system that switch according to a Markov process. In economics, HMM are usually applied

540
A. Korteweg
to regime switching settings, where the economy may switch between expansion and recession.
Albert and Chib [2] argue that the two-step Maximum Likelihood approach to estimating HMM
of Hamilton [39] does not give correct standard errors as the uncertainty about the parameters
in the first step is not incorporated in the second step. In addition, the ML approach does not
provideacompletedescriptionofthelikelihood,suchasbimodalityorasymmetry.AlbertandChib
develop an MCMC algorithm that deals with both issues. McCullogh and Tsay [74] use MCMC
to estimate an HMM that is very close to the switching regressions of Section 26.4.4 and apply
it to GNP data. Ghysels, McCullogh and Tsay [35] estimate a nonlinear regime switching model
and apply their MCMC estimator to two examples, one using housing starts data while the other
employsindustrialproductiondata.TheyarguethattheMCMCapproachisparticularlysuitableto
theirmodelbecauseclassicalestimationofperiodicMarkovchainmodelsoftenresultsinparameter
estimates at the boundary.
Recent work has started exploring the uses of MCMC for Instrumental Variables, with some
success (see Sims [90] for a discussion and further references). In particular, when the error dis-
tributions are non-Normal, the Bayesian estimates may be more efficient than classical methods
[18]. On a different note, two recent papers by Davies and Taillard [20, 21] propose an MCMC
approach to dealing with omitted variables that does not use an instrument at all, but instead
achieves identification by assuming that any common variation in the residuals is due solely to the
omitted variables.
Finally, thanks to the modularity of MCMC, models can be mixed and extended in various
ways that are quite straightforward. For example, one can deal with missing data by adding the
Algorithm 2 steps to any of the other algorithms. Error clustering can be handled by adding random
effects to the models. Last but not least, one can deal with heteroskedasticity and non-Normal error
terms by using mixtures of Normals (see Diebolt and Robert [24] and Geweke [34] for MCMC
mixture models, Chen and Liu [12] for Kalman filters with mixtures of Normals, and Korteweg and
Sørensen [59] for an application). These mixture models can be added to MCMC algorithms with
relative ease, are very flexible in generating both skewness and kurtosis in the error distributions,
and make the MCMC estimates more robust to outliers.
26.8 Conclusion
With the current trend towards more complex empirical models in the corporate finance literature,
Markov chain Monte Carlo methods provide a viable and attractive means of estimating and evalu-
ating models where classical methods such as least squares regression, GMM and Maximum Like-
lihood and their simulated counterparts are difficult or too computationally demanding to apply. In
particular, this includes nonlinear models with many latent variables that require high-dimensional
integration to evaluate the likelihood, or models that have a hierarchical structure. Examples of
such models include panel limited dependent variable models, matching and other self-selection
models, and structural models of the firm. The potential application of these types of models in
corporate finance is vast, including such diverse areas as capital structure, financial intermediation,
bankruptcy, and corporate governance.
The core feature of the method is the Hammersley–Clifford theorem, which breaks up the prob-
lem into its complete conditional distributions. These are usually relatively easy to sample from,
requiring no more than standard regression tools. Another benefit of the MCMC approach is that
it is modular, so that, for example, one can add a missing data module to a panel probit algorithm
with relative ease. Moreover, the method allows for exact small-sample inference of parameters and
nonlinear functions of parameters (the latter being helpful, for example, when calculating marginal
effects in a probit or logit model), and does not require optimization algorithms, simulated anneal-
ing or other methods that can make Maximum Likelihood and GMM cumbersome to use.

Markov chain Monte Carlo methods in finance
541
Every introductory text necessarily has to focus on certain ideas at the expense of others, and I
have chosen to focus on applications rather than to discuss some of the more technical details of
the MCMC method, the role of priors, and convergence diagnostics. Most introductory textbooks
thoroughly discuss these and other topics, and I refer the interested reader to Rossi et al. [87] and
Johannes and Polson [54] for a particularly lucid treatise and further reading.
This chapter has only touched the tip of the iceberg of possibilities that MCMC has to offer for
empirical corporate finance research, and I hope to have convinced the reader that the potential
benefits of the method are plentiful. Given that learning MCMC does come with some fixed cost,
I hope that this chapter and the accompanying code samples help to lower the cost of adoption,
and inspire and motivate corporate finance researchers to dive deeper into MCMC methods. With
time, hopefully this methodology will become part of the standard toolkit in finance, as it already
is in many other areas of scientific inquiry.
Acknowledgements
I thank the editors, and Dirk Jenter, Kai Li, Michael Roberts, Morten Sørensen and Toni Whited
for helpful comments and suggestions. All errors are my own.
References
[1] Acharya, S. (1988). A generalized econometric model and tests of a signalling hypothesis with
two discrete signals. Journal of Finance, 43, 412–429.
[2] Albert, J. and Chib, S. (1993). Bayes inference via Gibbs sampling of autoregressive time series
subjecttoMarkovmeanandvarianceshifts.Journal of Business and Economic Statistics,11,1–15.
[3] Albert, J. and Chib, S. (1993). Bayesian analysis of binary and polychotomous response data.
Journal of the American Statistical Association, 88, 669–679.
[4] Billet, M. T. and Xue, H. (2007). The takeover deterrent effect of open market share repur-
chases. Journal of Finance, 62, 1827–1850.
[5] Bruche, M. (2007). Estimating structural models of corporate bond prices. Working paper,
CEMFI Madrid.
[6] Bruno, G. (2004). Limited dependent panel data models: A comparative analysis of classical
and Bayesian inference among econometric packages. Working paper, Bank of Italy.
[7] Carter,C.K.andKohn,R.J.(1994).OnGibbssamplingforstatespacemodels.Biometrika,81,
541–553.
[8] Chamberlain, G. (1984). Panel data. In Handbook of Econometrics (ed. Z. Griliches and
M. Intriligator). Elsevier, Amsterdam: North Holland.
[9] Chen, J. (2010). Two-sided matching and spread determinants in the loan market. Working
paper, UC Irvine.
[10] Chen, L. and Zhao, X. (2007). Mechanical mean reversion of leverage ratios. Economics Let-
ters, 95, 223–229.
[11] Chen, R., Guo, R.-J. and Lin, M. (2010). Self-selectivity in firm’s decision to withdraw IPO:
Bayesian inference for hazard models of bankruptcy with feedback. Working paper, Rutgers
University.
[12] Chen, R. and Liu, J. S. (2000). Mixture Kalman filters. Journal of the Royal Statistical Society
Series B, 62, 493–508.
[13] Chib, S. (1992). Bayes inference in the Tobit censored regression model. Journal of Economet-
rics, 51, 79–99.
[14] Chib, S. and Greenberg, E. (1998). Analysis of multivariate probit models. Biometrika, 85,
347–361.

542
A. Korteweg
[15] Chib, S., Greenberg, E. and Chen, Y. (1998). MCMC methods for fitting and comparing
multinomial response models. Working paper, Washington University in St. Louis.
[16] Chib, S., Greenberg, E. and Winkelmann, R. (1998). Posterior simulation and Bayes factors
in panel count data models. Journal of Econometrics, 86, 33–54.
[17] Chib, S. and Winkelmann, R. (2001). Markov chain Monte Carlo analysis of correlated count
data. Journal of Business and Economic Statistics, 19, 428–435.
[18] Conley, T. G., Hansen, C. B., McCulloch, R. E. and Rossi, P. E. (2008). A semi-paramet-
ric Bayesian approach to the instrumental variable problem. Journal of Econometrics, 144,
276–305.
[19] Cowles, M. K., Carlin, B. P. and Connett, J. E. (1996). Bayesian Tobit modelling of longi-
tudinal ordinal clinical trial compliance data with nonignorable missingness. Journal of the
American Statistical Association, 91, 86–98.
[20] Davies, P. and Taillard, J. (2010). Omitted variables, endogeneity, and the link between man-
agerial ownership and firm performance. Working paper, University of Iowa and Boston
College.
[21] Davies, P. and Taillard, J. (2011). Estimating the return to education: An instrument-free
approach. Working paper, University of Iowa and Boston College.
[22] Davutyan, N. (1989). Bank failures as Poisson variates. Economics Letters, 29, 333–338.
[23] Deb, P., Munkin, M. K. and Trivedi, P. K. (2006). Private insurance, selection, and health care
use: A Bayesian analysis of a Roy-type model. Journal of Business and Economic Statistics, 24,
403–415.
[24] Diebolt, J. and Robert, C. P. (1994). Estimation of finite mixture distributions through
Bayesian sampling. Journal of the Royal Statistical Society Series B, 56, 363–375.
[25] Eckbo, B. E., Maksimovic, V. and Williams, J. (1990). Consistent estimation of cross-sectional
models in event studies. Review of Financial Studies, 3, 343–365.
[26] Efron, B. and Morris, C. (1975). Data analysis using Stein’s estimator and its generalizations.
Journal of the American Statistical Association, 70, 311–319.
[27] Eom, Y. H., Helwege, J. and Huang, J. (2004). Structural models of corporate bond pricing:
An empirical analysis. Review of Financial Studies, 17, 499–544.
[28] Fahrmeir, L. and Knorr Held, L. (1997). Dynamic discrete-time duration models. Working
paper, University of Munich.
[29] Frank, M. Z. and Goyal, V. K. (2009). Capital structure decisions: Which factors are reliably
important? Financial Management, 38, 1–37.
[30] Fruhwirth-Schnatter, S. (1994). Data augmentation and dynamic linear models. Journal of
Time Series Analysis, 15, 183–202.
[31] Gelfand, A. and Smith, A. F. M. (1990). Sampling based approaches to calculating marginal
densities. Journal of the American Statistical Association, 85, 398–409.
[32] Gelman, A. and Rubin, D. B. (1992). Inference from iterative simulation using multiple
sequences. Statistical Science, 7, 457–511.
[33] Geman,S.andGeman,D.(1984).Stochasticrelaxation,Gibbsdistributions,andtheBayesian
restoration of images. IEEE Transactions on Pattern Analysis and Machine Intelligence, 6,
721–741.
[34] Geweke, J. (2006). Interpretation and inference in mixture models: Simple MCMC works.
Working paper, University of Iowa.
[35] Ghysels, E., McCulloch, R. E. and Tsay, R. S. (1998). Bayesian inference for periodic
regime-switching models. Journal of Applied Econometrics, 13, 129–143.
[36] Graham, B. S. and Hirano, K. (2011). Robustness to parametric assumptions in missing data
models. American Economic Review Papers & Proceedings, 101, 538–543.
[37] Griliches, Z. (1986). Economic data issues. In Handbook of Econometrics, Volume 3 (ed.
Z. Griliches and M. Intriligator), pp. 1466–1514. Elsevier, Amsterdam: North Holland.

Markov chain Monte Carlo methods in finance
543
[38] Hamilton, B. (1999). HMO selection and medicare costs: Bayesian MCMC estimation of a
robust panel data Tobit model with survival. Health Economics, 8, 403–414.
[39] Hamilton, J. D. (1989). A new approach to the economic analysis of nonstationary time series
and the business cycle. Econometrica, 57, 357–384.
[40] Hansen, L. and Sargent, T. (2010). Fragile beliefs and the price of uncertainty. Quantitative
Economics, 1, 129–162.
[41] Hausman, J. A. and Wise, D. A. (1979). Attrition bias in experimental and panel data: The
Gary income maintenance experiment. Econometrica, 47, 455–473.
[42] Heckman, J. J. (1976). The common structure of statistical models of truncation, sample
selection and limited dependent variables and a simple estimator for such models. Annals of
Economic and Social Measurement, 5, 475–492.
[43] Heckman, J. J. (1979). Sample selection bias as a specification error. Econometrica, 47, 153–161.
[44] Heckman, J. J. (1981). The incidental parameters problem and the problem of initial condi-
tions in estimating a discrete time–discrete data stochastic process. In Structural Analysis of
Discrete Data with Econometric Applications (ed. C. Manski and D. McFadden). MIT Press,
Cambridge.
[45] Heckman, J. J. (1990). Varieties of selection bias. American Economic Review, 80, 313–318.
[46] Hennessy, C. A. and Whited, T. M. (2005). Debt dynamics. Journal of Finance, 60, 1129–1165.
[47] Hennessy, C. A. and Whited, T. M. (2007). How costly is external financing? Evidence from
a structural estimation. Journal of Finance, 62, 1705–1745.
[48] Horny,G.,Mendes,R.andVandenBerg,G.J.(2009).Jobdurationswithworkerandfirmspe-
cific effects: MCMC estimation with longitudinal employer–employee data. Working paper,
IZA Institute for the Study of Labor, Bonn.
[49] Hovakimian, A., Hovakimian, G. and Tehranian, H. (2004). Determinants of target capital
structure: The case of dual debt and equity issues. Journal of Financial Economics, 71, 517–540.
[50] Huang, S. and Yu, J. (2010). Bayesian analysis of structural credit risk models with microstruc-
ture noises. Journal of Economic Dynamics and Control, 34, 2259–2272.
[51] Iliev, P. and Welch, I. (2010). Reconciling estimates of the speed of adjustment of leverage
ratios. Working paper, UCLA.
[52] Jaggia, S. and Thosar, S. (1995). Contested tender offers: An estimate of the hazard function.
Journal of Business and Economic Statistics, 13, 113–119.
[53] Jeliazkov, I. and Lee, E. H. (2010). MCMC perspectives on simulated likelihood estimation.
In Advances in Econometrics (ed. W. Green and R. Hill), Volume 26, pp. 3–39. Emerald Group
Publishing Limited.
[54] Johannes, M. and Polson, N. (2012). Computational Methods for Bayesian Inference: MCMC
methods and Particle Filtering. Unpublished manuscript.
[55] Koopman,S.J.,Lucas,A.andSchwab,B.(2010).Macro,industryandfrailtyeffectsindefaults:
The 2008 credit crisis in perspective. Working paper, Tinbergen Institute.
[56] Korteweg, A. (2010). The net benefits to leverage. Journal of Finance, 65, 2137–2170.
[57] Korteweg, A. and Lemmon, M. (2012). Structural models of capital structure: A framework
for model evaluation and testing. Working paper, Stanford University.
[58] Korteweg, A. and Polson, N. G. (2010). Corporate credit spreads under uncertainty. Working
paper, University of Chicago.
[59] Korteweg, A. and Sørensen, M. (2010). Risk and return characteristics of venture capi-
tal-backed entrepreneurial companies. Review of Financial Studies, 23, 3738–3772.
[60] Korteweg, A. and Sørensen, M. (2012). Estimating loan-to-value and foreclosure behavior.
Working paper, Stanford University.
[61] Lee, L.-F. (1979). Identification and estimation in binary choice models with limited (cen-
sored) dependent variables. Econometrica, 47, 977–996.
[62] Leland, H. (1994). Bond prices, yield spreads, and optimal capital structure with default risk.
Working paper, UC Berkeley.

544
A. Korteweg
[63] Leland, H. (1994). Risky debt, bond covenants and optimal capital structure. Journal of
Finance, 49, 1213–1252.
[64] Lemmon, M. L., Roberts, M. R. and Zender, J. F. (2008). Back to the beginning: Persistence
and the cross-section of corporate capital structure. Journal of Finance, 63, 1575–1608.
[65] Li, K. (1998). Bayesian inference in a simultaneous equation model with limited dependent
variables. Journal of Econometrics, 85, 387–400.
[66] Li, K. (1999). Bayesian analysis of duration models: An application to Chapter 11 bankruptcy.
Economics Letters, 63, 305–312.
[67] Li, K. and McNally, W. (2004). Open market versus tender offer share repurchases: A condi-
tional event study. Working paper, University of British Columbia.
[68] Li, K. and Prabhala, N. R. (2007). Self-selection models in corporate finance. In Handbook of
CorporateFinance:EmpiricalCorporateFinance(ed.B.Eckbo),VolumeI,Chapter2,pp.37–86.
Elsevier, Amsterdam: North Holland.
[69] Lindley, D. V. and Smith, A. F. M. (1972). Bayes estimates for the linear model. Journal of the
Royal Statistical Society Series B, 34, 1–41.
[70] Maddala,G.S.(1996).Applicationsoflimiteddependentvariablemodelsinfinance.InHand-
book of Statistics (ed. G. Maddala and G. Rao), Volume 14, pp. 553–566. Elsevier, Amsterdam:
North Holland.
[71] Manski, C. (1989). Anatomy of the selection problem. Journal of Human Resources, 24,
343–360.
[72] Manski, C. (1990). Nonparametric bounds on treatment effects. American Economic
Review, 80, 319–323.
[73] McCulloch, R. E., Polson, N. G. and Rossi, P. E. (2000). A Bayesian analysis of the multino-
mial probit model with fully identified parameters. Journal of Econometrics, 99, 173–193.
[74] McCulloch, R. E. and Tsay, R. S. (1994). Statistical analysis of economic time series via
Markov switching models. Journal of Time Series Analysis, 15, 523–539.
[75] Merton, R. C. (1974). On the pricing of corporate debt: The risk structure of interest rates.
Journal of Finance, 29, 449–470.
[76] Mundlak, Y. (1978). On the pooling of time series and cross section data. Econometrica, 46,
69–85.
[77] Munkin, M. K. and Trivedi, P. K. (2003). Bayesian analysis of a self-selection model with
multiple outcomes using simulation-based estimation: An application to the demand for
healthcare. Journal of Econometrics, 114, 197–220.
[78] Neyman, J. and Scott, E. L. (1948). Consistent estimates based on partially consistent obser-
vations. Econometrica, 16, 1–32.
[79] Nijman, T. and Verbeek, M. (1992). Nonresponse in panel data: The impact on estimates of
the life cycle consumption function. Journal of Applied Econometrics, 7, 243–257.
[80] Nikolov, B., Morellec, E. and Schuerhoff, N. (2012). Corporate governance and capital struc-
ture dynamics. Journal of Finance, 67, 803–848.
[81] Obrizan, M. (2011). A Bayesian model of sample selection with a discrete outcome variable:
Detecting depression in older adults. Working paper, Kyiv School of Economics.
[82] Park, M. (2008). An empirical two-sided matching model of acquisitions: Understanding
merger incentives and outcomes in the mutual fund industry. Working paper, UC Berkeley.
[83] Prabhala, N. R. (1997). Conditional methods in event studies and an equilibrium justification
for standard event-study procedures. Review of Financial Studies, 10, 1–38.
[84] Pulvino, T. (1999). Effects of bankruptcy court protection on asset sales. Journal of Financial
Economics, 52, 151–186.
[85] Ridder, G. (1990). Attrition in multi-wave panel data. In Panel Data and Labor Market Studies
(ed. G. R. J. Hartog and J. Theeuwes). Elsevier, Amsterdam: North Holland.

Markov chain Monte Carlo methods in finance
545
[86] Robert, C. P. and Casella, G. (2004). Monte Carlo Statistical Methods (2nd edn). Springer,
New York.
[87] Rossi, P. E., Allenby, G. M. and McCulloch, R. (2005). Bayesian Statistics and Marketing
(1st edn). John Wiley and Sons, Hoboken, NJ.
[88] Rubin, D. (1983). Some applications of Bayesian statistics to educational data. The Statisti-
cian, 32, 55–68.
[89] Scruggs,J.T.(2007).Estimatingthecross-sectionalmarketresponsetoanendogenousevent:
Naked vs. underwritten calls of convertible bonds. Journal of Empirical Finance, 14, 220–247.
[90] Sims, C. A. (2007). Thinking about instrumental variables. Working paper, Princeton
University.
[91] Sørensen, M. (2007). How smart is smart money? A two-sided matching model of venture
capital. Journal of Finance, 62, 2725–2762.
[92] Stein, C. (1955). Inadmissibility of the usual estimator for the mean of a multivariate normal
distribution. In Proceedings of the third Berkeley symposium.
[93] Strebulaev, I. A. (2007). Do tests of capital structure theory mean what they say? Journal of
Finance, 62, 1747–1787.
[94] Tanner, M. A. and Wong, W. H. (1987). The calculation of posterior distributions by data
augmentation. Journal of the American Statistical Association, 82, 528–549.
[95] Taylor, L. A. (2010). Why are CEOs rarely fired? Evidence from structural estimation. Journal
of Finance, 65, 2051–2087.
[96] Train, K. (2003). Discrete Choice Methods with Simulation (1st edn). Cambridge University
Press, New York.
[97] van Hasselt, M. (2009). Bayesian inference in a sample selection model. Working paper,
University of Western Ontario.
[98] Vella, F. and Verbeek, M. (1994). Two-step estimation of simultaneous equation panel data
models with censored endogenous variables. Working paper, Tilburg University.
[99] Zellner, A. (1971). An introduction to Bayesian inference in econometrics. Wiley, New York.

27
Actuarial credibility
theory and Bayesian
statistics—the story
of a special evolution
udi makov
27.1 Introduction
A
ctuarial practitioners and researchers have clearly been more open to Bayesian thinking than
their counterparts in the statistical world. This is much in evidence in the context of credibility
theorywhichhasadoptedBayesianinfluencesalmostfromthestartandistodatesolidlyfoundedon
empirical Bayes philosophy. The paper is not devoted to the Bayesian impact on actuarial science,
but rather to the evolution of credibility theory, the early Bayesian impact and the current divergence
between credibility theory and Bayesian statistics.
According to [38] “The word credibility was originally introduced into actuarial science as a
measure of the credence that the actuary believes should be attached to a particular body of expe-
rience for ratemaking purposes”. Since 1918 to this very day, credibility is used to assess premi-
ums by considering the way to merge two sources of information: the individual experience of
the insured (the data) and the existing information on the entire portfolio or class the individ-
ual belongs to (prior information). While the problem is clearly tailored for a Bayesian frame-
work, solutions are shown to be constrained by limiting practices deeply rooted in the actuarial
profession.
Section 27.2 traces the early days of credibility theory and the influence of Bayesian thoughts.
Section 27.3 describes the empirical Bayes solution to the problem, a solution which has dominated
the actuarial profession until today. Section 27.4 is devoted to approximate Bayesian credibility
solutions for special loss distributions. These approximations are inspired by the motivation to
enrich credibility theory with Bayesian inputs while maintaining the constraints imposed by the
profession.
For surveys of credibility theory see [22], [54], [18] and [43]. For surveys of Bayesian statistics in
actuarial science, with some emphasis on credibility models, see [49], [40] and [39].

Actuarial credibility theory and Bayesian statistics
547
27.2 Credibility theory—early Bayesian thoughts
Bayesian thoughts first entered into actuarial science (life insurance in particular) with Richard
Price (1723–1791), who was influenced by the writing of Thomas Bayes (1702–1761) and who pub-
lished Bayes’ essay (‘An essay towards solving a problem in the doctrine of chances’) posthumously
in the Philosophical Transactions of the Royal Society of London (1763). Incidentally, the first life
insurance policy in North America was issued in 1761, the year Bayes died. Credibility theory was
conceived by American actuaries before World War I as the body of knowledge aimed at gener-
ating practical solutions to insurance ratemaking problems. [41] was concerned with the amount
of individual risk exposure needed for the estimated mean claim to be regarded as reliable. In
particular,ifgivenθ,theriskparameter,annualclaimsamountsX1, . . . , Xn arei.i.dwithmeanμ(θ)
(otherwise known as risk or fair premium) and variance σ 2(θ), how large should n be for −x to
be a fully credible estimator of μ(θ)? Mowbray relied on p[| −x −μ(θ) |≤kμ(θ)] ≥1 −ε (k is
somewhat arbitrary) and suggested that n ≥z2
1−εs2
k2−x
, where −x, and s2 are, respectively, the sample
mean and variance of the n claims. The philosophy at the time, termed limited fluctuation credibility,
was that if n is sufficiently large, −x is a fully credible estimator of μ(θ).
[52] suggested to replace full credibility with partial credibility. In particular, he proposed that
the risk premium be estimated by credibility premium ∧μ via a credibility formula, a weighted average
of the individual experience −x and m = E[μ(θ)], the industry-wide premium rate charged for a
particular class, or the overall mean in the insurance portfolio:
∧μ(θ) = z−x + (1 −z)m
(27.1)
where the weight z is the credibility factor, a factor which was regarded as equal to one in limited
fluctuation credibility. This was the first step in what was called the greatest accuracy credibility theory.
[52] justified (27.1) by assuming a binomial distribution for the number of claims with a normal
prior distribution for the parameter p, the probability of making a claim. Although his derivation
was erroneous, it was a pioneering attempt to adopt Bayesian thinking for the solution of a practical
actuarial problem. This has to be taken in historical perspective: At a time when Bayesian statistics
was under the adverse dominance of Fisherian and frequentist approaches, actuaries suggested
Bayesian-driven credibility models. [27] suggested a Poisson distribution with Gamma prior, and
[3] investigated the Beta-Binomial and the Normal-Normal models. For Bailey, a Bayesian at heart
and, unfortunately, unknown in Bayesian statistics circles, it was almost inconceivable to calculate
premiums without the use of priors [4]:
The statistical methods, developed by the mathematicians and available in the standard
textbooks on statistical procedures, deal with the evaluation of the indications of a group
of observations, but under the tacit or implicit assumption that no knowledge existed
prior to the making of those particular observations. The credibility procedures, used
in the revisions of casualty rates, have been developed by casualty actuaries to give
consistent weightings to additional knowledge in its combination with already existing
knowledge.
Similarly, [19] reflected:
What was amazing was that, at the same time, several philosophers of science and
statisticians were saying almost exactly the same thing. This group included Jeffreys,
Barnard, Ramsey, de Finetti (also a contributor to actuarial science), Savage, and

548
U. Makov
Lindley. What made Bailey remarkable was that he came to his criticism of sampling
theory and support of the Bayesian approach because of intensive study of a very
practical business problem.
In an earlier paper, [2] introduced a generalized theory of credibility which contained the seeds of
empirical Bayes thinking to be developed a decade later by [46].
27.3 The empirical Bayes phase
The early empirical Bayes ideas of Bailey were finally sprouting in the late 1960s against the back-
ground of dramatic advancement in Bayesian statistics, empirical Bayes and decision theory. In his
classical model [7, 8] aimed at minimizing the mean square error
E[μ(θ) −∧μ(θ)]2
(27.2)
within the linear form
∧μ(θ) = a + b−x.
(27.3)
He derived the credibility formula (27.1) by using
z =
λn
λn + η ,
(27.4)
where
λ = V[m(θ)]
(27.5)
and
η = E[σ2(θ],
(27.6)
with the unknown parameters λ and η estimated using the data.
In what has become a seminal paper, [9] modify the risk variance to take the form
V[Xj | θ] = σ 2(θ)
pj
,
(27.7)
to allow for different amounts of risk exposure (or volume) pj. This led to a modified credibility
formula with
z =
 pjλ
 pjλ + η
(27.8)
and
−x =
 pjxj
 pj
.
(27.9)

Actuarial credibility theory and Bayesian statistics
549
Here, too, in the spirit of empirical Bayes, the unknown parameters, akin to Bayesian hyperparam-
eters, were estimated using the data, taking into account the exposures pj. A decade later, [42]
summarized this state of affairs as follows:
A credibility estimator is Bayes in the restricted class of linear estimators and may be
viewed as a linear approximation to the unrestricted Bayes estimator. When the struc-
tural parameters occurring in a credibility formula are replaced by consistent estimators
based on data from the collective of similar risks, we obtain an empirical estimator, which
is a credibility counterpart of empirical Bayes estimators.
[9]’s results swept the actuarial world and were universally adopted as the ultimate methodology
for premium calculations. Since it was first published, practising actuaries are using these results
unquestionably, although new research inroads into credibility theory have demonstrated that there
is life beyond empirical Bayes techniques. This conservatism is, in part, the responsibility of profes-
sional bodies, like the Institute of Actuaries in the UK and the Society of Actuaries & the Casualty
Actuarial Society in the USA, whose syllabuses have failed to bridge the gap between credibility
theory and Bayesian statistics. This is in spite of the fact that the link between the two has long been
established.[3]wasthefirsttoidentifyexactcredibility,thecredibilityformulawhichcoincideswith
a Bayesian solution. This was further investigated by [20, 21], [17], [28], [48], [10] in the case of the
exponential family, [53] in a nonparametric setup and [30, 31] for the exponential dispersion family.
In these contexts, the credibility formula is equivalent to E[Xn+1 | x1, . . . xn], i.e. setting the pre-
mium at a value equal to the mean predicted risk, which has such an intuitive appeal. Unfortunately,
most actuaries are unable to calculate this mean when the conditional expectation does not have a
linear form.
27.4 Constrained Bayesian solutions
Over the years credibility theory has attracted a lot of attention in various directions, Bayesian and
otherwise. Since it is not the aim of this paper to provide an extensive review of the topic, only
a sample of recent contributions are now mentioned: [12], [47], [11], [16], [37], [1], [51], [14, 15],
[44], [50] and [45].
The main aim of this section is to provide a brief description of the published approxi-
mate-Bayesian papers attempting to adapt the credibility formula (27.1) to other families of distri-
butions, for which the predictive mean of the risk is no longer linear. The intention of these papers
was to equip practising actuaries with useful approximate Bayes estimators which could only be
accepted if they agreed with the structure of the classical credibility formula. Two approaches were
introduced: the derivation of approximate credibility formula using second-order Bayes estimators
[29] and the use of stochastic approximation techniques, which is briefly outlined.
We first make the observation [30, 31] that for the exponential dispersion family (EDF)
dPθ,λ = f (x|θ, λ) dx = eλ(xθ−k(θ))qλ(x)dx, θ ∈ ⊂R1, λ ∈# ∈R+,
(27.10)
with a conjugate prior for θ
	(θ) ∝en0(x0θ−k(θ)),
(27.11)
the following credibility formula exists:
E[Xn+1 | x1, . . . , xn, λ] = E[μ(θ) | x1, . . . , xn, λ] =
nλ
nλ + n0
−x +
n0
nλ + n0
m.
(27.12)

550
U. Makov
(27.12) can be written as a stochastic approximation recursion,
['μn = 'μn−1 −an ('μn−1 −xn) ,
(27.13)
where an =
λ
n0+nλ is the gain function fully defined by the prior distribution’s hyperparameters.
Usingstochasticapproximationtheory,(27.13)canbeshowntoconvergetothetruemeanriskw.p.1.
(For additional Bayesian analysis of credibility models for the EDF, see [34, 35].)
[32] exploited this observation to generate credibility formulas for other families of loss distri-
bution. The first family is the location dispersion family (LDF) (see [23, 24, 25]),
dPμ,λ = f (x|θ, λ) dx = a (λ) exp (λu (x −θ)))dx, x ∈R,
(27.14)
θ ∈R, λ ∈R+,
(27.15)
which includes, amongst other distributions, the log-gamma distribution, the Brandorff–Nielsen
hyperbolic distribution and the log generalized inverse Gaussian distribution. For this family the
stochastic approximation takes the sequential credibility form
'μn = 'μn−1 −anλu′(xn −'μn−1 + μ0 (λ)),
(27.16)
where μ0 (λ) is the expectation of (27.14) when θ = 0. Regularity conditions are provided for the
convergence with probability one of (27.16).
The gain function in (27.16) cannot automatically rely on the hyperparameters since the Bayes
estimator isnonlinear.Instead,againfunction,the first-order optimal gain function,whichminimizes
the Bayes risk, Eλ['μn −μ]2, is used
a∗
n =
Ro
nκR0 + 1
(27.17)
where R0 = Eλ (μ −m)2 is the variance of μ with respect to π (μ) dμ and where k = Bλ/Iλ.
Here Iλ = λ2a (λ)

 ∞
−∞u′(x)2 exp (λu(x)) dx = −λa (λ)

 ∞
−∞u′′(x) exp (λu(x)) dx, is Fisher
Information about parameter μ, and Bλ = λ2a (λ)

 ∞
−∞u′′(x)2 exp (λu(x)) dx. The resulting
credibility formula is called the generalized sequential credibility formula. For example, for losses
following the log-gamma distribution, κ = Iλ/Bλ = λ + 1 and a∗n =
Ro
n(λ+1)R0+1.
Special attention is given in [33] to the symmetric location dispersion family which includes two
important members: the exponential power family f (x|θ, λ) =
δλ1/δ
2(1/δ) exp(−λ|x −θ|δ), which
attracted considerable attention in the context of robust Bayesian statistics [6], and the generalized
student-t family, discussed in [5], f

x|θ, p, σ

= cp
8
1 + (x−θ)2
kσ 2
9−p
,
−∞< x < ∞, where
cp =
1
σ
√
kβ(0.5,λ−0.5)and for p ≥2, k = 2p −3, and for 1 ≤p < 2, k = 1. β (., .) is the beta
function.
[36] extended the sequential approach to a problem of credibility evaluation of a scale-dispersion
family (SDF) ([26], Section 1.4.2),
dPθ,λ = a (λ) x−1 exp (λu (θx)))dx, x ∈R+.
(27.18)
Here
θ ∈R+
is the risk parameter of Pθ,λ, the distribution of the claim size X, and
λ ∈R+ is a dispersion parameter. SDF contains important distributions. For example, the
lognormal family, for which u(x) = −1
2 ln2 x, frequently used successfully to represent loss

Actuarial credibility theory and Bayesian statistics
551
data.
A considerably rich three-parameter class of SDF was introduced by [13], dPθ,λ,γ =
|γ |λλ
(λ)
1
x exp(λ

γ ln(xθ) −(xθ)γ 
)dx.
[36]modified,respectively,theBayesianrisksequencesandthefirst-orderstepwiseoptimalgain:
R∗
n =
Ro
nkR0/(cλVλ(X)) + 1
(27.19)
a∗
n =
μ0 (λ)
nk + cλVλ(X)/R0
,
(27.20)
n = 1, 2, . . .
(27.21)
where
cλ =
μ0 (λ)2
Vμ0(λ),λ(X),
(27.22)
and provided regularity conditions for the convergence w.p.1 of the sequential credibility formula
'μn = 'μn−1 −a∗
nλxnu′

xn
μ0 (λ)
'μn−1

.
(27.23)
27.5 Epilogue
The actuarial profession is disadvantaged by its failure to adopt modern Bayesian methodologies.
This unfortunately affects us all as risk management tools do not exploit the rich Bayesian advance-
ments continuously reported in the statistical literature. MCMC for example, while reported in
actuarial journals to a limited extent, has failed to enter the professional guidelines provided to
practicing actuaries. Given the conservatism of this profession, changes should be introduced at
a slow pace, centred on gradual modifications of exiting actuarial techniques with an increasing
Bayesian content. In this way, as demonstrated above, the common linear empirical Bayes can be
modified to cater for a wide range of loss distributions within the constraint of linearity. While the
focus of this paper was on credibility theory, the observations made here would apply to other major
problems in actuarial science.
References
[1] Atanasiu, V. (2007). Theoretical aspects of credibility theory. Romai J., 3, 1–14.
[2] Bailey, A. (1945). A generalized theory of credibility. Proc. of the Casualty Act. Soc., 32, 13–20.
[3] Bailey, A. (1950). Credibility procedures: LaPlace’s generalization of Bayes’ rule and the
combination of collateral knowledge with observed data. Proc. of the Casualty Act. Soc.,
37, 7–23.
[4] Bailey, A. (1950). Discussion of a paper of Carson. Journal of American Teachers of Insurance
(now The Journal of Risk and Insurance), 17, 17–24.
[5] Bian, G. & Tiku, M. (1997). Bayesian inference based on robust priors and MML estimators:
Part 1, symmetric location-scale distributions. Statistics, 29, 317–345.
[6] Box, G. & Tiao, G. (1973). Bayesian Inference in Statistical Analysis. Addison-Wesley, Reading,
MA.
[7] Bühlmann, H. (1967). Experience and credibility. Astin bulletin, 4, 199–207.

552
U. Makov
[8] Bühlmann, H. (1969). Experience rating and credibility. Astin bulletin, 5, 157–165.
[9] Bühlmann, H. & Straub, E. (1970). Glaubwürdigkeit für Schadensätze. Mitt. SVVM, 70,
111–133.
[10] Diaconis, P. & Ylvisaker, D. (1979). Conjugate priors for exponential families. Annals of Statis-
tics, 7, 269–281.
[11] Ebegil, M. (2006). A study to examine Bühlmann–Straub credibility model in generalized
linear models. Commun. Fac. Sci. Univ. Ank. Series A1, 55, 9–16.
[12] Frees, E. (2003). Multivariate credibility for aggregate loss models. North American Actuarial
Journal, 7, 13–37.
[13] Fergusson, T. (1962). Location and scale parameters in exponential families of distributions.
Ann. Math. Stat., 33, 986–1001.
[14] Gomez-Deniz, E. (2008). A Generalization of the credibility theory obtained by using the
weighted balanced loss function. Insurance: Mathematics & Economics, 42, 850–854.
[15] Gomez-Deniz, E. (2008). Deriving credibility premiums under different Bayesian methodol-
ogy. Advances in Mathematical and Statistical Modelling. Statistics for Industry and Technology,
6, 219–229.
[16] Goulet, V., Forgues, A. & Lu, J. (2006). Credibility for severity revisited. North American
Actuarial Journal, 10, 49–62.
[17] Herzog, T. (1989). Credibility: the Bayesian model versus Bühlmann’s model. Transactions of
Society of Actuaries, 41, 43–88.
[18] Herzog, T. (1994). Introduction to Credibility Theory. ACTEX Publications, Winsted.
[19] Hickman, J. & Heacox, L. (1999). Credibility theory: The cornerstone of actuarial science.
North American Actuarial Journal, 3, 1–8.
[20] Jewell, W. (1974). Credible means are exact Bayesian for exponential families. Astin bulletin,
8, 77–90.
[21] Jewell,W.(1975).Theuseofcollateraldataincredibilitytheory:ahierarchicalmodel.Giornale
dell’ Istituto Italianio degh Attuari, 38, 1–16.
[22] Jewell, W. (1976). A survey of credibility theory. Operation Research Center, University of
California, Berkeley.
[23] Jorgensen, B. (1983). Maximal likelihood estimation and large-sample inference for general-
ized linear and nonlinear regression models. Biometrika, 70, 19–28.
[24] Jorgensen, B. (1987). Exponential dispersion models (with discussion). J. Roy. Statist. Soc.
Ser.B, 49, 127–162.
[25] Jorgensen, B. (1992). Exponential dispersion models and extensions: A review. Internat.
Statist. Rev., 60, 5–20.
[26] Jorgensen, B. (1997). The Theory of Dispersion Models. Chapman and Hall, London.
[27] Keffer,R.(1929).Anexperienceratingformula.TransactionsoftheActuarialSocietyofAmerica,
30, 130–139.
[28] Klugman,S.(1992).BayesianStatisticsinActuarialSciencewithEmphasisonCredibility.Kluwer
Academic Publishers.
[29] Landsman,Z.(2002).Credibilitytheory:anewviewfromthetheoryofsecondorderoptimal
statistics. Insurance: Mathematics & Economics, 30, 351–362.
[30] Landsman, Z. & Makov, U. (1998). Exponential dispersion models and credibility. Scandina-
vian Actuarial Journal, 1, 89–96.
[31] Landsman,Z.&Makov,U.(1999).Credibilityevaluationsforexponentialdispersionfamilies.
Insurance: Mathematics & Economics, 24, 33–39.
[32] Landsman,Z.&Makov,U.(1999).Onstochasticapproximationandcredibility.Scandinavian
Actuarial Journal, 1, 15–31.
[33] Landsman, Z. & Makov, U. (1999). Sequential credibility evaluation for symmetric location
claim distributions. Insurance: Mathematics & Economics, 24, 291–300.

Actuarial credibility theory and Bayesian statistics
553
[34] Landsman, Z. & Makov, U. (2001). Bayesian prediction in the exponential dispersion family
with an application to actuarial credibility. Monographs of Official Statistics, Eurostat, 283–289.
[35] Landsman, Z. & Makov, U. (2001). On credibility evaluation and the tail area of exponential
dispersion family. Insurance: Mathematics & Economics, 27, 277–283.
[36] Landsman, Z. & Makov, U. (2003). Sequential quasi credibility for scale dispersion models.
Scandinavian Actuarial Journal, 2, 119–135.
[37] Lau, J., Siu, T. K. & Yang, H. (2006). On Bayesian mixture credibility. Astin bulletin, 36,
573–588.
[38] Longley-Cook, L. (1962). An introduction to credibility theory. Proc. of the Casualty Act. Soc.,
49, 194–226.
[39] Makov, U. (2001). Principal applications of Bayesian methods in actuarial science: A perspec-
tive. (with discussion). North American Actuarial Journal, 5, 53–73.
[40] Makov, U., Smith, A. & Liu, Y. (1996). Bayesian methods in insurance: a review. The Statisti-
cian, 45, 503–515.
[41] Mowbray, A. (1914). How extensive a payroll exposure is necessary to give a dependable pure
premium. Proc. of the Casualty Act. Soc., 1, 24–30.
[42] Norberg, R. (1980). Empirical Bayes credibility. Scandinavian Actuarial Journal, 4, 177–194.
[43] Norberg, R. (2006). Credibility theory. Encyclopedia of Actuarial Science, John Wiley & Sons.
[44] Ohlsson, E. (2008). Combining generalized linear models and credibility models in practice.
Scandinavian Actuarial Journal, 4, 301–314.
[45] Payandeh Najafabadi, Amir T. (2010). A new approach to the credibility formula. Insurance:
Mathematics & Economics, 46, 334–338.
[46] Robbins, H. (1955). An empirical Bayes approach to statistics. Proceeding of the Third Berkeley
Symposium on Mathematical Statistics and Probability, 1, University of California Press, Berke-
ley, 157–163.
[47] Ronka-Chmielowiec, W. & Poprawska, E. (2005). Selected methods of credibility theory and
its application to calculating insurance premium in heterogeneous insurance portfolios. in
Innovations in Classification, Data Science, and Information Systems, VI, 490–497.
[48] Schmidt, K. (1990). Convergence of Bayes and credibility premiums. Astin bulletin, 20,
167–172.
[49] Schmidt, K. (1998). Bayesian models in actuarial mathematics. Math. Meth. Oper. Res., 48,
117–146.
[50] Siu,T.K.&Yang,H.(2009).NonparametricBayesiancredibility.AustralianActuarialJournal,
15, 209–230.
[51] Van Der Merwe, A. & Bekker, K. (2007). A computational Bayesian approach to the balanced
Bühlmann credibility model. South African Statistical Journal, 41, 65–103.
[52] Whitney, A. (1918). The theory of experience rating. Proc. of the Casualty Act. Soc., 4, 274–292.
[53] Zehnwirth, B. (1977). The mean credibility formula is a Bayes rule. Scandinavian Actuarial
Journal, 4, 212–216.
[54] Zehnwirth, B. (1983). Credibility theory: a concise partial survey. Austral. J. Statist., 25,
402–411.

This page intentionally left blank 

Part XI
Medicine and Biostatistics

This page intentionally left blank 

28
Bayesian models
in biostatistics
and medicine
peter müller
28.1 Introduction
B
iomedical studies provide many outstanding opportunities for Bayesian thinking. The prin-
cipled and coherent nature of Bayesian approaches often leads to more efficient, more ethical
andmoreintuitivesolutions.Inmanyproblemstheincreasinglycomplexnatureofexperimentsand
theeverincreasingdemandsforhigherefficiencyandethicalstandardsleadstochallengingresearch
questions.
In this chapter we introduce some typical examples. Perhaps the biggest Bayesian success stories
in biostatistics are hierarchical models. We will start the review with a dicussion of hierarchical
models. Arguably the most tightly regulated and well controlled applications of statistical inference
in biomedical research are the design and analysis of clinical trials, that is, experiments with human
subjects. While far from being an accepted standard, Bayesian methods can contribute significantly
to improving trial designs and to constructing designs for complex experimental layouts. We will
discuss some areas of related current developments. Another good example of how the Bayesian
paradigmcanprovidecoherentandprincipledanswerstocomplexinferenceproblemsareproblems
related to the control of multiplicities and massive multiple comparisons. We will conclude this
overview with a brief review of related research.
28.2 Hierarchical models
28.2.1 Borrowing strength in hierarchical models
A recurring theme in biomedical inference is the need to borrow strength across related subpopu-
lations. Typical examples are inference in related clinical trials, data from high throughput genomic
experiments using multiple platforms to measure the same underlying biologic signal, inference
on dose–concentration curves for multiple patients etc. The generic hierarchical model includes
multiple levels of experimental units. Say

558
P. Müller
yki | θk, φ ∼p(yki | wki, θk, φ)
θk | φ ∼p(θk | xk, φ),
φ ∼p(φ)
(28.1)
Without loss of generality we will refer to experimental units k as ‘studies’ and to experimental units
i as ‘patients’, keeping in mind an application where yk = (yki, i = 1, . . . , nk) are the responses
recorded on nk patients in the k-th study of a set of related biomedical studies. In that case wk =
(wki, i = 1, . . . , nk) could be patient-specific covariates, θk are study specific parameters, typically
including a study-specific treatment effect, and xk might be study-specific covariates. We will use
these terms to refer to elements of the hierarchical model, simply for the sake of easier presentation,
but keeping in mind that the model structure is perfectly general.
In a pharmacokinetic (PK) study k could index patients and yk = (yki, i = 1, . . . , nk) could be
drug concentrations for patient k observed at nk time points, wki, i = 1, . . . , nk. In that case θk are
the PK parameters that characterize how patientk metabolizes thedrug.In apharacodynamic(PD)
study yki could be repeat measurements on blood pressure, blood counts, etc.
In another example, k could index different platforms for high throughput genomic experiments,
for example k = 1 for RPPA data that records protein activation and k = 2 for microarray data that
measures gene expression. In that case i, i = 1, . . . , n, could index different genes and proteins and
θk = (θki, i = 1, . . . , n) could code differential gene expression and protein activation.
In[40] weuseahierarchicalmodelfor smallareaestimation.Weborrow strengthacross states to
estimate the rate of mammography usage θk in each state in the USA, k = 1, . . . , K. The data were
collected at a national level, leaving very small or zero sample sizes in some states. By borrowing
strengthacrossstateswecanstillreportinferenceforallstates.Figure28.1showstheposteriormeans
E(θk | data).
In [54] a hierarchical model is used to define a clinical trial design for sarcoma patients. Sarcoma
is a very heterogeneous disease. The subpopulations k = 1, . . . , K index K = 12 different sarcoma
types, and i = 1, . . . , nk indexes enrolled patients who are diagnosed with sarcoma subtype k. The
hierarchical model borrows strength across sarcoma types. Some sarcoma types are very rare. Even
in a large cancer hospital it would be difficult to accrue sufficiently many patients for a trial for one
subtype alone. Only by borrowing strength across subtypes does it become feasible to investigate
such rare subtypes. The other extreme of pooling all patients would be equally inappropriate, as it
would ignore the heterogeneity and varying prognosis across different subtypes. The hierarchical
model allows for a compromise of borrowing strength at a level between pooling the data and
runningseparateanalyses.Onelimitation,however,remains.Thehierarchicalmodel(28.1)assumes
that all subtypes are a priori exchangeable. That is not quite appropriate for the sarcoma subtypes.
There are likely to be some known differences. [38] develop a variation of hierarchical models that
allows for exchangeability of patients across subsets of subpopulations. In the case of the sarcoma
study this implies that patients within some sarcoma subtypes are pooled. The selection of these
subsets itself is random, with an appropriate prior.
In all five examples the second level of the hierarchical model formalizes the borrowing of
strength across the submodels. Most applications include conditional independence at all levels,
with θk independent across k conditional on φ and yki independent across i conditional on θk, φ.
All five examples happen to use hierarchical models with two levels. Extensions to more than two
levels are conceptually straightforward.
The power of the Bayesian approach to inference in hierarchical models is the propagation of
uncertainties and information across submodels. For example, when k = 1, . . . , K indexes related
clinical trials then inference for the k-th trial borrows strength from patients enrolled in the other
K −1 trials. Let y−k = (yℓ, ℓ̸= k) denote all data excluding the k-th study. We can rewrite the
implied model for the k-th study as

Bayesian models in biostatistics and medicine
559
0.0
0.2
0.4
0.6
0.8
E(P)
S.D.(P)
MDP (BARPLOT)
PHAT (w. error bars)
SYNTH
DC
MA
DE
MD
NV
NY
CT
RI
CO
OR
AK
MI
CA
FL
MT
WA
PA
SC
OH
TN
MO
KS
WI
VA
ID
NM
AZ
GA
MN
OK
AL
IN
IA
LA
ME
WV
WY
NE
IL
MS
NC
VT
SD
TX
KY
NJ
AR
ND
UT
NH
HI
Figure 28.1 Posterior estimates E(θk | data) for each US state in a hierarchical model for mam-
mography usage. The barplot shows the posterior means. The barplot below the x-axis shows the
posterior standard deviations SD(θk | data). The solid line shows the data (empirical frequency of
mammography usage). The dotted line shows the estimate 'θk in a regression on state-specific
demographic summaries.
p(yk | θk, φ) and p(θk, φ | y−k)
This highlights the nature of borrowing information across studies. The original prior is replaced
by the posterior conditional on data from the other studies. We could describe this aspect of
hierarchical models as a principled construction of informative priors based on related studies.
The important feature in the process is that this borrowing of strength is carried out in a coherent
fashion as dictated by probability calculus, rather than ad-hoc plug-in approaches. The implication
is a coherent propagation of uncertainties and information.
Besides the pragmatic aspect of borrowing strength, hierarchical models can also be introduced
from first principles. Essentially, if observations within each subpopulation are judged as arising
from an infinitely exchangeable sequence of random quantities, and the subpopulations themselves
are judged to be exchangeable a priori, then model (28.1) is implied [5, Chapter 4].
28.2.2 Posterior computation
OneoftheearlypathbreakingdiscussionsthatintroducedBayesianthinkingforhierarchicalmodels
appears in [39]. The paper appeared long before the routine use of posterior Markov chain Monte
Carlo simulation, when computational implementation of Bayesian inference in complex models
was still a formidable challenge. One of the important contributions of Lindley and Smith’s paper
was to highlight the simple analytic nature of posterior inference when all levels of the hierarchical
model are normal linear models.
The restriction to models that allow analytic results severely limited the practical use of Bayesian
inference in biomedical applications. This radically changed with the introduction of Markov chain
Monte Carlo posterior simulation in [21]. In fact, hierarchical models were one of the illustrative
examples in [21] and the companion paper [19] with more illustrative applications.

560
P. Müller
28.2.3 Related studies and multiple platforms
One of the strengths of the Bayesian approach is the coherent and principled combination of
evidence from various sources. A critical need for this feature arises in the combination of evidence
acrossrelatedstudies.Whilemanystudiesarestillplannedandpublishedasiftheywerestand-alone
experiments, as if they were carried out in total isolation from other related research, this is an
incresingly unreasonable simplification of reality.
One simple approach to borrow information across related studies that investigate the same con-
ditionispost-processingofresultsfromthesestudies.Thisisknownasmeta-analysis[11,Chapter3].
A typical example appears in [24], who analyse evidence from eight different trials that all inves-
tigated the use of intravenous magnesium sulphate for acute myocardial infarction patients. The
discussion in [24] shows how a Bayesian hierarchical model with a suitably sceptic prior could have
anticipated the results of a later large-scale study that failed to show any benefit of the magnesium
treatment.
Multiple related studies need not always refer to clinical trials carried out by different investiga-
tors. An increasingly important case is the use of multiple experimental platforms to measure the
same underlying biologic signal. This occurs frequently in high throughput genomic studies. In a
recent review paper [29] argue for the need of hierarchical modelling to obtain improved inference
by pooling different data sources.
28.2.4 Population models
In [63] the authors discuss population models as an important special case of hierarchical models
and Bayesian inference in biostatistics. Typically each submodel corresponds to one patient, with
repeated measurements yki, and a sampling model that is indexed by patient-specific parameters θk
and perhaps additional fixed effects φ. The first-level prior in the general hierarchial model (28.1)
now takes the interpretation of the distribution of patient-specific parameters θk across the entire
patient population.
In population PK/PD models the hierarchical prior p(θk | xk, φ) represents the distribution
of PK (or PD) parameters across the population. One of the typical characteristics of patient
populations is heterogeneity. There is usually no good reason beyond technical convenience to
justifystandardpriorslikeamultivariatenormal.Whilethepopulationdistribution p(θk | xk, φ)is
usually not of interest in itself, good modelling is important, mainly for prediction and inference for
future patients. Let i = n + 1 index a future patient and let Y = (y1, . . . , yn) denote the observed
data. Inference for a future patient is driven by
p(θn+1 | xn+1, Y) =

p(θn+1 | xn+1, φ) dp(φ | Y)
assuming that the patient-specific PK parameters θk are conditionally independent given φ. The
expression for the posterior for θn+1 highlights the critical dependence of prediction on the para-
metric form of p(θk | xk, φ). For example, assuming a normal distribution might severely under-
estimate the probability of patients with unusual PK parameters. Several authors have investigated
the use of more general population models in Bayesian population PK/PD models. Let N(x; m, S)
denote a multivariate normal distribution for the random variable x with moments m and S. For
example, a mixture of normals

Bayesian models in biostatistics and medicine
561
p(θk | φ) =
L

ℓ=1
wℓN(θk; μℓ, ℓ)
(28.2)
could be used to generalize a normal population model without substantially complicating poste-
rior simulation. Here φ = (L, wℓ, μℓ, ℓ, ℓ= 1, . . . , L) indexes the population model. This and
related models have been used, for example, in [31, 43] and others. The mixture model needs to
be completed with a prior for the parameters φ. This is easiest done by writing the mixture as

N(θk; μ, )dG(μ, ) for a discrete probability measure G = 
ℓwℓδ(μℓ,ℓ). Here δx indi-
cates a point mass at x. The prior specification then becomes the problem of constructing a prob-
ability model for the random probability measure G. We will discuss such models in more detail
below, in Section 28.7.
28.3 Bayes in clinical trials: phase I studies
Few other scientific studies are as tightly regulated and controlled as clinical trials. However, most
regulatoryconstraintsapplyforphaseIIIstudiesthatcomparethenewexperimentaltherapyagainst
standard of care and clinically relevant standards. For early phase studies the only constraint is that
they be carried out in scientifically and ethically responsible ways. This is usually controlled by
internal review boards (IRB) that have to approve the study.
Phase I studies aim to establish safety. In oncology a typical problem is to find the maximum
tolerable dose (MTD) of a new chemotherapy agent (or combination of agents). Let z = (zj, j =
1, . . . , J) denoteagridofavailabledoses.Manydesignsassumethattheformalaimofthestudyisto
find a dose with toxicity closest to a pre-determined maximum tolerable target level π⋆. Typically
the outcome is a binary indicator, y ∈{0, 1} for a dose-limiting toxicity. Let πj = p(y = 1 | zj)
denote the probability of toxicity at dose level j. One of the still most widely used designs is the
so called 3+3 design. It is simply a rule for escalating the dose in subsequent patient cohorts until
we observe a certain maximum number of toxicities in a cohort. The design is an example of a
rule-based design. In contrast to model-based designs that are based on inference with respect to
underlying statistical models, rule-based designs simply follow a reasonable but otherwise ad hoc
algorithm. There is no probabilistic guarantee that the reported MTD is in fact a good approxima-
tion of the unknown truth. Rule-based designs are popular due to the ease of implementation, but
theyarealsoknowntobeinefficient[36].Here,efficiencyisjudgedbyfrequentistsummariesunder
repeateduseofadesign.Summariesincludetheaveragesamplesizeandtheaveragetrueprobability
of toxicity at the reported MTD.
[47] proposed one of the first model-based Bayesian designs to address some of the limitia-
tions of traditionally used rule-based designs. The method is known as continual reassessment
method (CRM). The underlying model is quite straightforward. Let dj, j = 1, . . . , J denote a
grid of available dose levels and recall that πj is the probability of toxicity at dose j. For a given
skeleton d = (d1, . . . , dJ) of doses the model is indexed with only one more parameter as πj = da
j .
Several variations with alternative one-parameter models are in use. The algorithm uses a target
dose, say π⋆= 0.30 and proceeds by sequentially updating posterior inference on a and assigning
the respective next patient cohort to the dose with 'πj = d'a
j closest to the target toxicity π⋆. Here
'a = E(a | data) is the posterior mean conditional on all currently available data and 'πj is a plug
in estimate of πj. In a minor variation one could imagine to replace 'πj by the posterior mean
'πj = E(da | data). The coding of the doses dj is part of the model, but is fixed up-front. The
values dj are not raw dose values, but chosen to achieve desired prior means πj = E(da
j ). Here the

562
P. Müller
expectation is with respect to the prior on a. The initially proposed CRM gave rise to serious safety
concerns. The main issue is that the algorithm could jump to inappropriately high doses, skipping
intermediate and yet untried doses.
Several later modifications have improved the original CRM, including the modified CRM of
[22] to address the safety concerns, and the TITE-CRM of [9] for time to event outcomes and
many more. The TITE-CRM still uses essentially binary outcomes, but allows for weighting to
accomodate early responses and enter patients in a staggered fashion. Let Ui denote the event time
for patient i, for example, time to toxicity. Let yi denote a binary outcome for patient i, defined as Ui
beyond a certain horizon T, i.e, yi = I(Ui > T). Let yin denote the toxicity status of patient i just
before the n-th patient enters the trial. When Ui is already observed then yin = yi. Also when Ui is
censored beyond T, i.e. Ui is known to be beyond the horizon T, then yin = yi = 0. Only when Ui
is censored before T, then yin = 0, while yi would still be considered censored. The TITE-CRM
replacesthebinaryresponseyi byyin andusesanadditionalweightwi = min(Ui/T, 1)toreplaceπj
in the likelihood by gj = πjwi. This allows use to be made of early responses implied by censored
Ui < T and can significantly reduce the trial duration. The approach of [55] goes a step further
using a parametric model for the time to event endpoint. [3] generalize the TITE-CRM with a
probit model for discretized event times to allow for lack of monotonicity. Some authors have
suggested alternative model-based approaches. The EWOC (escalation with overdose control)
method of [1] uses a cleverly parameterized logistic regression of outcome on dose. A common
theme of these model-based methods is the use of very parsimonious models. This is important in
the context of the small sample sizes in phase I trials.
Another common feature is the use of a target toxicity level π⋆. Several recent authors argue that
the assumption of a single value π⋆is unrealistic, and replace the notion of a target dose by target
toxicity intervals. This view is taken, for example, in [30]. Keeping the model ultimately simple
they use independent Beta/Binomial models for each dose. Only post-processing with isotonic
regression ensures monotonicity. A related approach is proposed in [45] who go a step further and
introduce ordinal toxicity intervals, including intervals for underdosing, target toxicity, excessive
toxicity,andunacceptabletoxicity.Theunderlyingprobabilitymodelisalogisticregressioncentred
at a reference dose. Sequential posterior updating after every patient-cohort includes updated pos-
terior probabilities for the target toxicity intervals at each dose. The respective next dose is assigned
by trading off the posterior probabilities of these intervals.
The designs and models mentioned so far are all exclusively phase I designs. Inference is only
concerned with toxicity outcomes, entirely ignoring possible efficacy outcomes. The EffTox model
introduced in [56] explicitly considers both, toxicity and efficacy. Thall and Cook develop a design
that trades off target levels in both endpoints. The probability model is based on two marginal
logisticregressionsforabinarytoxicityandabinaryefficacyoutcome,andoneadditionalparameter
that induces dependence of the two outcomes. The design includes sequential posterior updating
andadesirabilityfunctionthatisusedlikeautilityfunctiontoselectacceptabledosesandeventually
an optimal dose.
28.4 Phase II studies
Phase II studies aim to establish some evidence for a treatment effect, still short of a formal com-
parison with a control or standard of care in the following final phase III study. Larger sample sizes
and more structure, compared with phase I, allow for more impact of model-based Bayesian design.
Opportunities for innovative Bayesian designs arise in sequential stopping, adaptive design and the
use of problem-specific utility functions.

Bayesian models in biostatistics and medicine
563
28.4.1 Sequential stopping
Some sequential stopping designs use posterior predictive probabilities to decide upon continua-
tion versus termination of a trial. Let PP denote the posterior predictive probability of a positive
result at the end of the trial. For example, assume that the efficacy outcome is a binary indicator
for tumour response, and that a probability of tumour response π > π0 is considered a clinically
meaningful response. Let y denote the currently available data, i.e. outcomes for already enrolled
patients, and let yo denote the still unobserved responses for future patients if the trial were to run
until some maximum sample size. Also assume that evidence for efficacy is formalized as the event
{p(π > π0 | data) > 1 −ϵ}. The posterior predictive probability PP = p{p(π > π0 | y, yo) >
1 −ϵ | y} is the probability of a successful trial if the study continues until the end. Continuous
monitoring of such predictive probabilities facilitates the implementation of flexible stopping rules
basedonthechanceoffuturesuccess.Thisisimplementedin[28]whodefineasequentialstopping
rulebasedontheposteriorpredictiveprobabilityof(future)conclusiveevidenceinfavourofoneof
two competing treatments. Similarly, also [37] argue for the use of posterior predictive probabilties
to implement sequential stopping in phase II trials. See also the discussion in [7].
Similarinspirit,manyrecentlyproposedclinicaltrialdesignsusecontinuouslyupdatedposterior
probabilitiesofclinicallymeaningfuleventstodefinestoppingrules.Theuseofposteriorpredictive
probabilities can be seen as a special case of this general principle, using a particular type of poste-
rior inference related to future posterior probabilities. In general, one could consider any event of
interest, usually related to some comparison of success probabilities or other parameters under one
versus the other therapy. [11, Chapter 6] refers to such approaches as ‘proper Bayes’ design. A class
of such designs that use continuously updated posterior probabilities for sequential stopping for
futility and efficacy was introduced in [58] and [57]. For example, Let pn = p(θE > θS + δ | data)
denote the posterior probability that the response rate θE under the experimental therapy is larger
than the response rate θS under standard of care by more than δ. A design could stop for futility
whenpn < L andstopforefficacywhenpn > U,whereU andL arefixedthresholds.[58]includea
modelformultipleoutcomes,includingindicatorsfortoxicityandtumourresponse.Inthatcasethe
posterior probabilities of appropriate combinations of outcomes under competing treatments can
be used to define stopping. Figure 28.2 summarizes a possible history of a trial using such stopping
rules. The two curves pn(EFF) and pn(TOX) plot the continuously updated posterior probabilities
pn(·) = p(· | data)ofatoxicityevent(TOX)andanefficacyevent(EFF).Thetwohorizontallines
are thresholds. When pn(TOX) > U the trial stops for toxicity. When pn(EFF) < L the trial stops
forfutility,i.e.lackofefficacy.Thisparticulartrialhadnosequentialstoppingforefficacy.Thefigure
shows a simulated trial history under a very favourable assumed truth. Neither curve crosses the
corresponding stopping boundary.
28.4.2 Adaptive allocation
Sequential stopping is one (important) example of outcome adaptive designs. Those are clinical
trial designs that use interim analysis during the course of the trial to change some design element
as a function of already observed outcomes. The implementation and careful planning of such
experiments is far more natural and straightforward under a Bayesian approach than under the
classical paradigm [6].
Besides sequential stopping another commonly used type of adaptive design is adaptive treat-
ment allocation for multi-arm trials, i.e. trials that recruit patients for more than one therapy. The
intent of most adaptive allocation designs is to favour allocation to the better therapy, but to keep
some minimum level of randomization. Adaptive allocation is thus different from deterministic
rules like play-the-winner. The designs are usually rule-based, i.e. there is no notion of optimality.

564
P. Müller
5
10
15
20
0.0
0.2
0.4
0.6
0.8
MONTH
Pr(eta[S]+delta < eta[E] | Y)
EFF
TOX
Figure 28.2 Sequentially updated posterior estimates for toxicity and efficacy and stopping by
decision boundaries.
The adaptive allocation is carried out following some reasonable, but ad-hoc rule. The idea goes
back to at least [59]. A recent review appears in [53]. Consider a study that allocates patients to
two treatments, say T1 and T2, and let θ1 and θ2 denote treatment-specific parameters that can be
interpretedasefficacyoftreatmentT1 andT2,respectively.Forexample,θj mightbetheprobability
of tumour response under treatment Tj. Let rj(y) denote the probability of allocating the next
patient (or patient cohort) to treatment Tj. Importantly, rj(·) is allowed to depend on the observed
outcomes y. A popular rule is
rj(y) ∝

p(θj = max
i
θi | y)
c
Thetwoprobabilities,therandomizationprobabilityrj andtheposteriorprobabilityofTj beingthe
best treatment, are defined on entirely different spaces, and are entirely unrelated in the probability
model. Only the adaptive allocation rule links them, following the vague notion that it is preferable
to assign more patients to the better treatment. The power c is a tuning parameter. It is usually
chosen as c = 1 or c = 1/2, [53] recommend c = n/2N for current sample size n and maximum
sample size N. The recommendation is based on empirical evidence only.
Finally,forafairdiscussionofadaptivetrialdesignweshouldnotethatBayesianadaptivedesigns
are far from routine. In fact, in a recent guidance document the US Food and Drug Administration
(FDA) does not encourage the use of Bayesian methods for adaptive designs.
28.4.3 Delayed response
OneofthebigwhiteelephantsindrugdevelopmentisthehighfailurerateofphaseIIIconfirmatory
studies, even after successful phase II trials. In cancer more than 50% of phase III studies fail [32].

Bayesian models in biostatistics and medicine
565
One of the possible causes for this is that phase II studies typically use a binary indicator for tumour
response, for example an indicator for tumour shrinkage, as a proxy for survival, which is a typical
phase III endpoint. Ideally one would want to see the same endpoint being used in phase II and III.
But thedelayed natureof asurvival responsewould makephaseII trials unacceptablyslow. See[26]
for a discussion. They use model-based Bayesian inference to develop a phase II design that miti-
gates the problem. The solution is simple and principled. Let Si ∈{1, 2, 3, 4} denote an indicator
for tumour response for the i-th patient. They code tumour response as a categorical outcome with
four levels. Let Ti denote survival time. They use a joint sampling model p(Si, Ti | λ, p), where
p are the probabilities of Si under different treatments and λ indexes an exponential regression
of Ti on Si and treatment assignment. Under this model it now becomes meaningful to report
posterior probabilities for events related to survival. As a welcome side effect, inference about
tumour response is improved by borrowing strength from the survival outcome.
28.5 Two Bayesian success stories
One of the big opportunities and challenges for Bayesian approaches in clinical trial design is the
possibility to match treatments with patients in a coherent fashion. Two recent successful studies
illustrate these features.
28.5.1 ISPY-2
ISPY-2 [2] uses a Bayesian adaptive phase II clinical trial design. The trial considers neoadjuvant
treatments for women with locally advanced breast cancer. The study simultaneously considers
five different experimental therapies. All five treatments are given in combination with standard
chemotherapy, before surgery (neoadjuvant). ISPY-2 defines an adaptive trial design, i.e. design
elements are changed in response to the observed data. Adaptation in ISPY-2 includes changing
probabilities of assigning patients to the treatment arms and the possibility of dropping arms early
for futility or efficacy. In the latter case the protocol recommends a following small phase III study.
The treatment is ‘graduated.’
In addition to these more standard adaptive design elements, the most innovative and important
feature of the trial is explicit consideration of population heterogeneity by defining subpopulations
based on biomarkers and a process that allows different treatments to be recommended for each
subpopulation.Theimportantdetailisthatboth,theidentificationofsubpopulationsandthetreat-
ment recommendation happen in the same study. With this feature ISPY-2 might be able to break
the so-called biomarker barrier. Many previous studies have attempted to identify subpopulations,
butonlyveryfewstoodthetestoftimeandprovedusefulinlaterclinicaltrials.InISPY-2,theprocess
ofbiomarkerdiscoverystartswithalistofbiomarkersthatdefineupto256differentsubpopulations,
although only about 14 remain as practically interesting, due to prevelance and biologic constraints.
Foreachpatientwerecordpresenceorabsenceofthesebiomarkers,includingpresenceofhormone
receptors (estrogen and progesterone), human epidermal growth factor receptor 2 (HER2) and
MammaPrint risk score. The recorded biomarkers determine the relevant subgroup, which in turn
determines the allocation probabilities.
The trial is a collaboration of the US National Cancer Institute, the US Food and Drug Admin-
istration, pharmaceutical companies and academic investibators. Please see http://www.ispy2.org
for more details.

566
P. Müller
28.5.2 BATTLE
The BATTLE (Biomarker-integrated approaches of targeted therapy of lung cancer elimination)
trial is in many ways similar to ISPY-2. The study is described in [66]. BATTLE is a phase II
trial for patients with advanced non-small cell lung cancer (NSCLC). The design considers five
subpopulations defined by biomarker profiles, including EGFR mutation/amplification, K-ras and
B-raf mutation, VEGF and VEGFR expression and more. The primary outcome is progression free
survival beyond eight weeks, reported as a binary response. We refer to the binary outcome as
disease control. Similarly to ISPY-2, the design allows allocation of treatments with different prob-
abilities in each subpopulation, and to report subpopulation-specific treatment recommendations
uponconclusionofthetrial.Treatmentallocationisadaptive,withprobabilitiesproportionaltothe
probabilities of disease control. Let γjk denote the current posterior probability of disease control
for a patient in biomarker group k under treatment j. The next patient in biomarker group k is
assigned to treatment j with probability proportional to γjk. Posterior probabilities are with respect
to a hierarchical probit model. The probit model is written in terms of latent probit scores zjki for
patient i under treatment j in biomarker group k. The model assumes a hierarchical normal/normal
model for zjki. The model includes mean effects μjk of treatment j in biomarker group k, and mean
effects φj for treatment j.
The model is also used to define early stopping of a treatment arm j for the k-th disease group.
An arm is dropped for futility when the posterior predictive probability of the posterior probability
for disease control being beyond θ1 is less than δL. Here the latter posterior probability refers to
inference conditional on future data that could be observed if the treatment were not dropped.
And θ1 would naturally be chosen to be the probability of disease control under standard of care.
Similarly, treatment j is recommended for biomarker group k if the posterior predictive probability
of (future) posterior probability of disease control being greater than θ0 is greater than δU. Here
θ0 > θ1 would be some clinically meaningful improvement over θ1.
28.6 Decision problems
Some biomedical inference problems are best characterized as decision problems. A Bayesian deci-
sion problem is described by a probability model p(θ, y) on parameters θ and data y, a set of
possible actions d ∈A, and a utility function u(d, θ, y). The probability model is usually factored
as a prior p(θ) and a sampling model p(y | θ). It is helpful to further partition the data into (yo, y)
for data yo that is already observed at the time of decision making, and future data y. The utility
function describes the decision maker’s relative preferences for actions d under assumed values of
the parameters θ and hypothetical data y. In this framework the optimal decision is described as
d⋆= arg max
d∈A U(d, yo) with U(d, yo) =

u(d, θ, y) dp(θ, y | yo)
(28.3)
In words, the optimal decision maximizes the utility, in expectation over all random quantities that
are unknown at the time of decision making, and conditional on all known data. The expectation
U(d, ·) is the expected utility.
In [48] we find an optimal schedule for stem cell collection (apheresis) for high-dose chemo-ra-
diotherapy patients under two alternative treatments, x ∈{1, 2}. We develop a hierarchical model
to represent stem cell counts for each patient over time. Stem cell counts are measured by CD34
antigen levels per unit volume. We do not need details of the model for the upcoming discussion.
The model includes a sampling model p(yij | tij, θi) for the CD34 counts yij that is recorded for

Bayesian models in biostatistics and medicine
567
Table 28.1 Optimal (and 2nd and 3rd best) design for two future patients. The first column reports
the estimated value 'U(d⋆x, x).
U
d1
d2
d3
d4
d5
d6
treatment x = 1
2.03
1
0
0
0
0
0
3.00
1
1
0
0
0
0
4.00
1
1
1
0
0
0
treatment x = 2
5.14
0
1
1
0
0
0
5.18
0
1
1
1
0
0
5.47
1
0
1
1
0
0
patient i at (known) time tij, a random effects distribution p(θi | xi, φ) for patient-specific param-
eters of a patient under treatment xi ∈{1, 2}, and a hyperprior p(φ). The decision is a vector of
indicatorsd = (d1, . . . , dN),withdj = 1whenanapheresisforafuturepatientisscheduledonday
j of an N day period. The action space A is the set of all binary N-tuples. The utility function u(·) is
a combination of sampling cost for nd = 
j dj stem cell collections and a reward for collecting
a target volume y⋆of stem cells. Let L denote the volume collected at each collection and let
y = (y1, . . . , yn, yn+1)denotetheobservedCD34counts,includingthefuturepatientn + 1.Then
u(d, θ, y, x) = nd + λI(

j
yn+1,jL < y⋆),
for a future patient i = n + 1 assigned to treatment xi = x. The optimal design d⋆x is found by
maximizing
U(d, x) =

u(d, θ, y) dp(θ, yn+1 | xn+1 = x, y1, . . . , yn)
Table 28.1 summarizes the optimal design for treatments x = 1 and x = 2.
Another interesting example of the benefit of decision theoretic thinking occurs in phase II
clinical trials with sequential stopping decisions. After each cohort of patients we make a decision
d ∈{0, 1, 2}, where d = 0 indicates stopping enrolment and recommending against further devel-
opment (failure), d = 2indicates stoppingenrolment recommendingfor afollowingphaseIII con-
firmatory trial (victory), and d = 1 indicates continued enrolment. A useful utility function in this
contextformalizestheconsiderationsthatfeatureinthisdecision.Enrolingpatientsisexpensive,say
c units per patient. If the following confirmatory trial shows a statistically (frequentist) significant
effect then the drug can be marketed and the developer collects a substantial reward C. A significant
effect in a follow-up trial is usually easy to consider. The beauty of frequentist tests is that they are
usually quite simple. Let z denote the (future) responses in the follow-up trial. All that is needed
for the utility function is the posterior predictive probability of the (future) test statistic S(z) falling
in the rejection region R, using a sample size n3 based on the usual desiderata of type-I error and
power under a current estimate of the treatment effect.
Forthestatementoftheutilityfunctionwedonotneedanydetailsoftheprobabilitymodel,short
of an assurance that there is a joint probability model for data and parameters. Let y = (y1, . . . , yn)
denote the currently observed data. Let n3(y) denote the sample size for a future phase III trial.

568
P. Müller
Thesamplesizecandependoncurrentestimatesofthetreatmenteffectandotherparameters.Let z
denote the (future) data in the phase III study, letS(z) denote the test statistic that will be evaluated
upon conclusion of the phase III study, and let R denote the rejection region for that test. Also,
without loss of generality we assume that patients are recruited in cohorts of size 1, i.e. we consider
stopping after each new patient. Formally, the utility function becomes
u(d, θ, y) =
⎧
⎪⎪⎨
⎪⎪⎩
c + E{U(d⋆, y, yn+1) | y}
if d = 1
0
if d = 0
cn3(y) + C p{S(z) ∈R | y}
if d = 2
Here U(d⋆, . . .) is the expected utility under the optimal action in the next period. This appears in
the utility function because of the sequential nature of the decision problem. Discussing strategies
for the solution of sequential decision problems is beyond the scope of this discussion. Here we
only want to highlight how relatively straightforward it is to incorporate a stylized description of
the following phase III study in the utility function. Variations of this utility function are used in
[41, 49, 62].
There is a caveat about the use of decision theoretic arguments in biomedical research problems.
Many investigators are reluctant to use formal decision theoretic approaches in biomedical prob-
lems. The main reason is perhaps the nature of the optimal decision d⋆as an implicitly defined
solution. There is no guarantee that the solution d⋆looks intuitively sensible. Technical details
of the probability model and the typically stylized utility function determine the solution in a
very implicit way, as the solution to the optimization problem (28.3). However, many details are
usually chosen for technical convenience rather than based on substantive prior information. Of
course, when counter-intuitive solutions are found, one could always go back and include addi-
tional constraints in A. But this is a post-hoc fix, and not all counter-intuitive features are readily
spotted.
28.7 Nonparametric Bayes
28.7.1 BNP priors
Nonparametric Bayesian (BNP) models are priors for random probability models or functions. A
commontechnicaldefinitionofBNPmodelsisprobabilitymodelsforinfinite-dimensionalrandom
quantities. However, traditionally most applications of BNP involve random distributions only. So
for this discussion we will restrict attention to BNP priors for random probability measures. Let
G denote an (unknown) probability model of interest. For example, G could be the distribution of
event times in a survival analysis, or the random effects distribution in a mixed effects model, or
the probability model for residuals in a regression problem. Generically, let p(y | G, η) denote the
sampling model for the observable data given G and possibly other parameters η. To be specific we
assume a density estimation problem for a random sample y = (y1, . . . , yn) with
p(y | G) =
n

i=1
G(yi)
(28.4)
Bayesian inference requires that the model be completed with a prior for the unknown quantities
G and η. When the prior p(G) restricts G to a family of probability models {Gθ, θ ∈Rp} that

Bayesian models in biostatistics and medicine
569
Density of y
values
density
1
2
3
4
5
0.0
0.2
0.4
0.6
0.8
1.0
1.2
Figure 28.3 Inference on the unknown distribution G under a BNP model (solid line) and a parametric
model (dashed line).
is indexed by a finite-dimensional parameter vector θ, then we are back to standard parametric
inference.Forexample,assuminganormalsamplingmodelG(·) = N(·; μ, σ)reducestheproblem
to inference for the unknown normal moments θ = (μ, σ). If, however, the investigator is not
willing or not able to restrict attention to a parametric family then we require a prior for the infinite
dimensional quantity G,
G ∼p(G)
Good recent reviews of BNP appear in [65] and [25]. Figure 28.3 illustrates the flexibility of BNP
in a simple density estimation problem. For a good recent discussion of nonparametric Bayes in
biostatistics and bioinformatics we refer to [13].
28.7.2 Survival analysis
One of the most common applications of BNP in biostatistics is to survival analysis, i.e. den-
sity estimation (28.4) when the data are event times, and typically include extensive censoring.
[52] and [18] developed BNP estimates of survival functions in the presence of censoring, still
relying on analytic results. They used the Dirichlet process (DP) prior [16, 17]. The DP prior
and variations is to date by far the most commonly used BNP model. With the introduction of

570
P. Müller
Gibbs sampling the modelling options greatly improved. [34] discuss Gibbs sampling for right,
left and interval censored data. They assume that data is observed at discrete times only, reducing
the DP prior to a Dirichlet distribution of the quantiles over finitely many time intervals. The
mentioned approaches all use variations of the basic model
Ti ∼F and F ∼DP(F⋆, α),
i.e. a DP prior on the unknown event time distribution. The DP requires two parameters. The base
measure F⋆and the total mass parmaeter α. The base measure F⋆fixes the prior mean, E(F) = F⋆,
Among other implications, α determines the variation, F(A) ∼Be[αF⋆(A), α{1 −F⋆(A)}]. An
important property of the DP prior is that it generates a.s. discrete random probability measures.
This is awkward and often avoided by using an additional convolution with a continuous kernel
k(x; θ), for example, a normal kernel N(x; θ, σ) with known scale.
F(Ti) =

k(Ti; θ) dG(θ) and G ∼DP(G⋆, α).
(28.5)
[10] propose an accelerated failure time model using a Dirichlet process prior. Similarly, [33] and
[20] develop accelerated failure time models based on DP mixtures. These models are semipara-
metric. The model component that implements the regression on baseline covariates remains
parametric. A fully nonparametric survival regression based on DP priors is proposed in [12]. In
principle any nonparametric density regression model, i.e. a nonparametric prior for families of
random distributions {Gx} indexed by covariates x, could be used. Many such models have been
proposed in the recent literature, including, for example, [14] and [15].
Besides the DP model and variations, many other BNP models have been proposed for survival
data. Many approaches are based on the Polya tree (PT) prior. See [35] for a discussion of these
priors and references. A fully Bayesian semiparametric survival model using the PT was proposed
by [64]. More recently, [23, 60] proposed mixtures of Polya Tree priors for use in semiparametric
proportional hazards, accelerated failure time and proportional odds models. They assume a mix-
ture of PT priors for a baseline survival distribution. A fully nonparametric extension of the PT
model for survival data to include a nonparametric regression on covariates, is proposed in [61].
We refer to [27] and the following chapter in this volume for a thorough review of nonparametric
Bayesian methods in survival analysis.
28.8 Multiplicities and error control
28.8.1 Posterior inference accounts for multiplicities
Many important scientific problems naturally lead to massive multiple comparisons. Typical exam-
ples are experiments that record gene expression under different biologic conditions, simultane-
ously for massively many genes. The problem is to compare for each gene relative gene expression
across biologic conditions and report those genes that show significant differences across condi-
tions. The number of comparisons can be thousands or tens of thousands.
Formally, let δi ∈{0, 1}, i = 1, . . . , n denote the unknown truth for n comparisons. A stylized
example of differential gene expression experiments could involve a sampling model p(yi | θi) =
N(θi, σ), i = 1, . . . , n, for a gene-specific difference score yi. The sampling model is indexed with a
gene-specificparameterθi thatcanbeinterpretedasthelevelofdifferentialexpression.Thevariance
σ is assumed to be common across all genes. The i-th comparison is θi = 0 versus θi ̸= 0, i.e.

Bayesian models in biostatistics and medicine
571
no differential expression versus non-zero differential expression. In this context δi = I(θi ̸= 0)
is an indicator of (true) differential expression. The model is completed with a hierarchical prior
on θi. For the moment, we need not worry about the details of this prior model. For a meaningful
discussionweonlyneedtoassumethatthepriorincludesapositivepriorprobabilityp(δi = 0) > 0
of non-differential expression. We focus on inference of δi. Under a Bayesian approach one might
report, for example, pi = p(δi = 1 | y), the posterior probability of differential expression for the
i-th gene.
A popular folk theorem asserts that Bayesians need not worry about multiplicities. Posterior
probabilities are already (automatically) adjusted for multiplicities. This is illustrated, for example
in [50]. Under some assumptions on the hierarchical prior for δi, the statement is correct. The
posterior probabilities pi adjust for multiplicities, in the following sense. Focus on one particular
comparison,saythei-thcomparisonwithaparticulardifferencescoreyi andconsidertwoscenarios
with the same value yi, but different values for other yj, j ̸= i. When all other observed difference
scores yj, j ̸= i, are closer to zero, then pi will be shrunken more towards zero than what would be
the case for larger yj. In other words, posterior probabilities adjust for multiplicities by increased
shrinkage in pi when the data suggest a high level of noise in the data. Of course, this statement
depends on the details of the model, but it holds for any reasonable hierarchical model. See [50] for
details.
However, reporting posterior probabilities pi ‘is only half the solution’ [8]. The remaining part
of the solution is the decision to select which genes should be reported as differentially expressed.
The magic automatic adjustment for multiplicities only happens for the probabilities, not for the
decision. Let di(y) ∈{0, 1}, i = 1, . . . , n, denote this inference summary. In a classical framework,
this could simply be a test of H0i : θi = 0. Under a Bayesian perspective one could consider, for
example, di = I(pi > c). This seems an innocent and reasonable decision rule. It will turn out to
actually be the Bayes rule under certain assumptions. In any case, it is a plausible rule to consider.
In both cases, fequentist and Bayesian, we are left with the decision of where to draw the line,
i.e. how to choose the threshold c? Clearly, traditional type I error control for each comparison is
meaningless. In most applications one would end up reporting way too many false positives. The
otherextremeofcontrollingexperiment-wideerrorrates,ontheotherhand,iswaytooconservative
in most applications.
28.8.2 False discovery rate (FDR)
A commonly used compromise between the two extremes of comparison-wise and experiment-
wideerrorcontrolisthecontroloffalsediscoveryrate,therelativefractionoffalsepositives,relative
tothenumberofpositives.LetD =  di denotethenumberofreportedgenes.Thefalsediscovery
rate is defined as
FDR = 1
D
n

i=1
(1 −δi)di.
Often the denominator is replaced by (D + ϵ) to avoid zero division. At this moment the FDR is
neither frequentist nor Bayesian. It is a function of both, the data, indirectly through di(y), and the
parameters δi. Marginalizing with respect to the data leads to a frequentist expectation of the FDR.
Most references to FDR in the literature refer to this frequentist expectation. We refer to it as =
FDR,
to distinguish it from the posterior expected FDR = E(FDR | y), conditional on the data.
A clever procedure proposed and popularized by [4] allows straightforward control of =
FDR. In
contrast,theevaluationofFDRrequiresnoclevertricks.Conditionalonthedatatheonlyunknown
remainsδi andwefindFDR = 1/D n
i=1(1 −pi)di.OnecoulduseadesiredboundonFDRtofix

572
P. Müller
the threshold c in the decision rule di = I(pi > c). This is proposed, for example, in [46]. Under
the Bayesian paradigm, FDR control turns out not only to be easy, it is even the correct thing to
do. The decision rule di = I(pi > c) can be justified as a Bayes rule under several loss functions
combining false discovery counts (or proportions) and false negative counts (or proportions). See
[42] for a discussion.
An important special case of multiplicity adjustments arises in subgroup analysis. Many clinical
studies fail to show the hoped for effect for the target patient population. It is then tempting to
consider subgroups of patients. Often it is possible to make clinically or biologically reasonable
argumentsofwhythetreatmentshouldbemorespecificallysuitableforcertainsubgroups.Withthe
increased use of biomarkers it is becoming more common to consider interesting subpopulations
defined by various relevant biomarkers. For example, a targeted therapy that aims to address a
pathological disruption of some molecular network can only be effective when the disease is in
fact caused by a disruption of this network. Naturally, the investigation of possible subgroup effects
needs to proceed in a controlled fashion to avoid concerns related to multiplicities. The problem is
naturally approached as a decision problem, with a probability model for all unknowns, including
the unknown subgroup effects, and a utility function that spells out the decision criterion. Recent
discussions of a Bayesian decision theoretic approach appear in [51] and [44].
28.9 Conclusion
We have discussed some prominent applications of Bayesian theory in biostatistics. The judgement
ofwhatisprominent,ofcourse,remainssubjective.SurelymanyimportantapplicationsofBayesian
methods have been missed. A good recent discussion of some applications of more sophisticated
Bayesian models in biostatistics appears in [13]. An extensive review of Bayesian methods specifi-
cally in clinical trials and healthcare evaluations appears in [11].
References
[1] Babb, James, Rogatko, André and Zacks, Shelemyahu (1998). Cancer phase 1 clinical trials:
efficient dose escalation with overdose control. Statistics in Medicine, 17(10), 1103–1120.
[2] Barker, A. D., Sigman, C. C., Kelloff, G. J., Hylton, N. M., Berry, D. A., and Esserman, L. J.
(2009).I-spy2:Anadaptivebreastcancertrialdesigninthesettingofneoadjuvantchemother-
apy. Clinical Pharmacology, 86, 97–100.
[3] Bekele, B. N., Ji, Y., Shen, Y. and Thall, P. F. (2008). Monitoring late-onset toxicities in phase I
trials using predicted risks. Biostatistics, 9, 442–47.
[4] Benjamini, Yoav and Hochberg, Yosef (1995). Controlling the false discovery rate: A practical
and powerful approach to multiple testing. Journal of the Royal Statistical Society, Series B:
Methodological, 57, 289–300.
[5] Bernardo, J. M. and Smith, Adrian F. M. (1994). Bayesian Theory. John Wiley & Sons.
[6] Berry, Donald A. (1987). Statistical inference, designing clinical trials, and pharmaceutical
company decisions. The Statistician: Journal of the Institute of Statisticians, 36, 181–189.
[7] Berry, Donald A. (2004). Bayesian statistics and the efficiency and ethics of clinical trials.
Statistical Science, 19(1), 175–187.
[8] Berry, Scott M. and Berry, Donald A. (2004). Accounting for multiplicities in assessing drug
safety: A three-level hierarchical mixture model. Biometrics, 60(2), 418–426.
[9] Cheung, Ying Kuen and Chappell, Rick (2000). Sequential designs for phase I clinical trials
with late-onset toxicities. Biometrics, 56(4), 1177–1182.

Bayesian models in biostatistics and medicine
573
[10] Christensen, Ronald and Johnson, Wesley (1988). Modelling accelerated failure time with a
Dirichlet process. Biometrika, 75, 693–704.
[11] Spiegelhalter, D. J., Abrams, Keith R. and Myles, Jonathan P. (2003). Bayesian Approaches to
Clinical Trials and Health-care Evaluation. Wiley.
[12] DeIorio,M.,Johnson,W.,Müller,P.,Rosner,G.Trippa,L.,Müller,P.andJohnson,W.(2009).
A ddp model for survival regression. Biometrics, 65, 762–771.
[13] Dunson, David (2010). Nonparametric Bayes applications to biostatistics. In Bayesian Non-
parametrics (ed. N. L. Hjort, C. Holmes, P. Müller, and S. G. Walker), pp. 235–291. Cambridge
University Press.
[14] Dunson, D. B. and Park, J. H. (2008). Kernel stick-breaking processes. Biometrika, 95(2),
307–323.
[15] Dunson, David B., Pillai, Natesh and Park, Ju-Hyun (2007). Bayesian density regression.
Journal of the Royal Statistical Society: Series B (Statistical Methodology), 69(2), 163–183.
[16] Ferguson, Thomas S. (1973, April). A Bayesian analysis of some nonparametric problems.
Annals of Statistics, 1(2), 209–230.
[17] Ferguson, Thomas S. (1974, August). Prior distributions on spaces of probability measures.
Annals of Statistics, 2(4), 615–629.
[18] Ferguson, Thomas S. and Phadia, Eswar G. (1979, January). Bayesian nonparametric estima-
tion based on censored data. Annals of Statistics, 7(1), 163–186.
[19] Gelfand, Alan E., Hills, Susan E., Racine-Poon, Amy and Smith, Adrian F. M. (1990). Illus-
tration of Bayesian inference in normal data models using Gibbs sampling. Journal of the
American Statistical Association, 85, 972–985.
[20] Gelfand, Alan E. and Kottas, Athanasios (2003). Bayesian Semiparametric Regression for
Median Residual Life. Scandinavian Journal of Statistics, 30(4), 651–665.
[21] Gelfand, Alan E. and Smith, Adrian F. M. (1990). Sampling-based approaches to calculating
marginal densities. Journal of the American Statistical Association, 85, 398–409.
[22] Goodman, S., Zahurak, M. and Piantadosi, S. (1995). Some practical improvements in the
continual reassessment method for phase I studies. Statistics in Medicine, 14, 1149–1161.
[23] Hanson, Timothy and Johnson, Wesley O. (2002). Modelling regression error with a mixture
of polya trees. Journal of the American Statistical Association, 97, 1020–1033.
[24] Higgins, Julian P. T. and Spiegelhalter, David J. (2002). Being sceptical about meta-analyses:
a Bayesian perspective on magnesium trials in myocardial infarction. International Journal of
Epidemiology, 31(1), 96–104.
[25] Hjort, Nils Lid (ed.), Holmes, Chris (ed.) Müller, Peter (ed.), and Walker, Stephen G. (ed.)
(2010). Bayesian Nonparametrics. Cambridge University Press.
[26] Huang, X., Ning, J., Li, Y., Estey, E., Issa, J. P. and Berry, D. A. (2009). Using short-term
response information to facilitate adaptive randomization for survival clinical trials. Statistics
in Medicine, 28(12), 1680–1689.
[27] Ibrahim, Joseph G., Chen, Ming-Hui and Sinha, Debajyoti (2001). Bayesian Survival Analysis.
Springer-Verlag, New York, NY, USA.
[28] Inoue, Lurdes Y. T., Thall, Peter F. and Berry, Donald A. (2002). Seamlessly expanding a
randomized phase II trial to phase III. Biometrics, 58(4), 823–831.
[29] Ji, H. and Liu, X. S. (2010). Analyzing ’omics data using hierarchical models. Nature Biotech-
nology, 28(4), 337–340.
[30] Ji, Y., Li, Y., and Bekele, N. (2007). Dose-finding in oncology clinical trials based on toxicity
probability intervals. Clinical Trials, 4, 235–244.
[31] Kleinman, K. P. and Ibrahim, J. G. (1998). A semi-parametric Bayesian approach to the ran-
dom effects model. Biometrics, 54, 921–938.
[32] Kola,IsmailandLandis,John(2004).Canthepharmaceuticalindustryreduceattritionrates?
Nat Rev Drug Discov, 3(8), 711–716.

574
P. Müller
[33] Kuo, L. and Mallick, B. (1997). Bayesian semiparametricinferencefor theaccelerated failure--
time model. Canadian Journal of Statistics, 25, 457–472.
[34] Kuo, L. and Smith, A. F. M. (1992). Bayesian computations in survival models via the Gibbs
sampler. In Survival Analysis: State of the Art (ed. J. P. Klein and P. K. Goel), pp. 11–24. Boston:
Kluwer Academic.
[35] Lavine, Michael (1992). Some aspects of Polya tree distributions for statistical modelling.
Annals of Statistics, 20, 1222–1235.
[36] Le Tourneau, Christophe, Lee, J. Jack and Siu, Lillian L. (2009). Dose escalation methods in
phase I cancer clinical trials. Journal of the National Cancer Institute, 101(10), 708–720.
[37] Lee, J. J. and Liu, D. D. (2008). A predictive probability design for phase II cancer clinical
trials. Clinical Trials, 5(2), 93–106.
[38] Leon-Novelo, L., Bekele, B. N., Müller, P., Quintana, F. and Wathen, K. (2011). Borrowing
strength with non-exchangeable priors over subpopulations. Biometrics, to appear.
[39] Lindley, D. V. and Smith, A. F. M. (1972). Bayes estimates for the linear model. Journal of the
Royal Statistical Society. Series B (Methodological), 34(1), pp. 1–41.
[40] Malec, D. and Müller, P. (2008). A Bayesian semi-parametric model for small area estimation.
In Festschrift in Honor of J.K. Ghosh (ed. S. Ghoshal and B. Clarke), pp. 223–236. IMS.
[41] Müller, Peter, Berry, Don A., Grieve, Andy P., Smith, Michael, and Krams, Michael
(2007). Simulation-based sequential Bayesian design. Journal of Statistical Planning and Infer-
ence, 137(10), 3140–3150.
[42] Müller, P., Parmigiani, G., Robert, C. and Rousseau, J. (2004). Optimal sample size for
multiple testing: the case of gene expression microarrays. Journal of the American Statistical
Association, 99(468), 990–1001.
[43] Müller, P. and Rosner, G. (1997). A Bayesian population model with hierarchical mixture
priorsappliedtobloodcountdata.JournaloftheAmericanStatisticalAssociation,92,1279–1292.
[44] Müller, P., Sivaganesan, S. and Laud, P. W. (2010). A Bayes rule for subgroup reporting.
In Frontiers of Statistical Decision Making and Bayesian Analysis (ed. M.-H. Chen, D. Dey,
P. Mueller, D. Sun, and K. Ye), pp. 277– 284. Springer-Verlag.
[45] Neuenschwander, B., Branson, M. and Gsponer, T. (2008). Critical aspects of the Bayesian
approach to phase I cancer trials. Statistics in Medicine, 27, 2420–2439.
[46] Newton, Michael A. (2004). Detecting differential gene expression with a semiparametric
hierarchical mixture method. Biostatistics (Oxford), 5(2), 155–176.
[47] O’Quigley, John, Pepe, Margaret and Fisher, Lloyd (1990). Continual reassessment method:
A practical design for Phase 1 clinical trials in cancer. Biometrics, 46, 33–48.
[48] Palmer,J.andMüller,P.(1998).Bayesianoptimaldesigninpopulationmodelsofhematologic
data. statmed, 17, 1613–1622.
[49] Rossell, D., Müller, P. and Rosner, G. (2007). Screening designs for drug development. Bio-
statistics, 8, 595–608.
[50] Scott, James G. and Berger, James O. (2006). An exploration of aspects of Bayesian multiple
testing. Journal of Statistical Planning and Inference, 136(7), 2144–2162.
[51] Sivaganesan, S., Laud, P. and Müller, P. (2011). A Bayesian subgroup analysis with a zero-
enriched polya urn scheme. Statistics in Medicine, to appear.
[52] Susarla, V. and Ryzin, J. Van (1976). Nonparametric Bayesian estimation of survival curves
from incomplete observations. Journal of the American Statistical Association, 71, 897–902.
[53] Thall, P. F. and Wathen, J. K. (2007). Practical Bayesian adaptive randomisation in clinical
trials. European Journal of Cancer, 43(5), 859–866.
[54] Thall, P. F., Wathen, J. K., Bekele, B. N., Champlin, R. E., Baker, L. H. and Benjamin, R. S.
(2003).HierarchicalBayesianapproachestophaseIItrialsindiseaseswithmultiplesubtypes.
Statistics in Medicine, 22, 763–780.

Bayesian models in biostatistics and medicine
575
[55] Thall, P. F., Wooten, L. H. and Tannir, N. M. (2005). Monitoring event times in early phase
clinical trials: some practical issues. Clinical Trials, 2, 467–478.
[56] Thall, Peter F. and Cook, John D. (2004). Dose-finding based on efficacy-toxicity trade-offs.
Biometrics, 60(3), 684–693.
[57] Thall, P. F. and Simon, R. (1994). Practical Bayesian guidelines for phase IIB clinical trials.
Biometrics, 50, 337–349.
[58] Thall,PeterF.,Simon,RichardM.andEstey,ElihuH.(1995).Bayesiansequentialmonitoring
designsforsingle-armclinicaltrialswithmultipleoutcomes.StatisticsinMedicine,14,357–379.
[59] Thompson, William R. (1933). On the likelihood that one unknown probability exceeds
another in view of the evidence of two samples. Biometrika, 25(3/4), pp. 285–294.
[60] Hanson, Timothy, Johnson Wesley O. and Laud, Purashotam (2009). Semiparametric infer-
ence for survival models with step process covariates. Canadian Journal of Statistics, 37, 60–79.
[61] Trippa, L., Müller, P. and Johnson, W. (2011). The multivariate beta process and an extension
of the polya tree model. Biometrika, 98(1), 17–34.
[62] Trippa, Lorenzo, Rosner, Gary L. and Müller, Peter (2012). Bayesian enrichment strategies
for randomized discontinuation trials. Biometrics, 68(1), 203–11.
[63] Wakefield, J. C., Smith, A. F. M., Racine-Poon, A. and Gelfand, A. E. (1994). Bayesian analysis
of linear and non-linear population models by using the Gibbs sampler. Applied Statistics, 43,
201–221.
[64] Walker, Stephen and Mallick, Bani K. (1999). A Bayesian semiparametric accelerated failure
time model. Biometrics, 55, 477–483.
[65] Walker, Stephen G., Damien, Paul, Laud, Purushottam W. and Smith, Adrian F. M. (1999).
Bayesian nonparametric inference for random distributions and related functions (Disc:
P510–527). Journal of the Royal Statistical Society, Series B: Statistical Methodology, 61, 485–509.
[66] Zhou, Xian, Liu, Suyu, Kim, Edward S., Herbst, Roy S. and Lee, J. Jack (2008). Bayesian
adaptive design for targeted therapy development in lung cancer–a step toward personalized
medicine. Clinical Trials, 5, 181–193.

29
Subgroup analysis
purushottam w. laud, siva
sivaganesan and peter müller
29.1 Introduction
S
ubgroup analysis is the comparison of treatment efficacies in a clinical trial among subgroups
defined by baseline patient characteristics such as gender and age. Such analyses are com-
monplace and often not carried out with statistically sound techniques. Lagakos [15], in an article
addressing medical researchers in the New England Journal of Medicine, discusses in a clear and
direct manner the challenges of reporting subgroup analyses. He also suggests some simple and
minimalremediestoavoiddistortedreporting.InaSpecialReportinthesamejournal,Lagakosand
coauthors [31] present empirical evidence of then-current reporting practices. Subgroup analyses
were reported in 59 of the 97 primary reports of clinical trials in the same prestigious journal in the
year July 2005–June 2006. The vast majority of these subgroup analysis reports were substandard.
The Special Report then provides guidelines for good reporting practice. Other authors have also
addressed such issues; see, for example, [3, 4, 33].
Subgroupanalysisiscarriedoutfordifferentpurposes.Oneoftheseistheidentificationofpartic-
ular subgroups where the treatment is highly efficacious (or is ineffective or even harmful). Another
is to look for consistency of effect across various subgroups [12], and it is also recommended for
risk-stratified subgroups [24]. All of these are important considerations leading to direct clinical
implications. Improvement in subgroup analysis techniques can, therefore, have a substantial effect
on better extraction of information from clinical trials and lead to improved clinical trial designs.
29.1.1 A dementia trial
We introduce an example of a clinical trial to focus attention on subgroup analysis. Kovach et al.
[14] reported on a double-blinded randomized experiment to study the effectiveness of a new
treatment called Serial Trial Intervention (STI) compared to standard treatment (control). The
treatments are intended to affect positively the comfort and behaviour of patients with late-stage
dementia and are initiated after certain behavioural symptoms are observed. The study was con-
ducted in 14 nursing homes on 112 subjects with late-stage dementia. STI is an innovative clini-
cal protocol for assessment and management of unmet needs in people with late-stage dementia.
The outcome variable of interest was the difference, pre and post treatment, in Discomfort-DAT
(Discomfort-Dementia of the Alzheimer’s Type scale), a measure of discomfort felt by the sub-
jects. The treatment group contained 55 subjects and the control group 57. The investigators were
interested in the subgroups defined by two covariates, Functional Assessment Staging of Dementia
(FAST) score (covariate X1) and presence/absence of vocalization (MVOCAL, covariate X2) in

Subgroup analysis
577
Table 29.1 Dementia trial sample sizes
X1 = 0
X1 = 1
Total
X2 = 0
X2 = 1
Control
31
26
57
19
38
Treated
35
20
55
19
36
Total
66
46
112
38
74
thebehaviouralsymptomsthatinitiatedtreatment,standardorSTI.Twosubgroupswereofinterest
based on X1, defined by X1 = 1 when FAST Score ≥7, and, = 0 if FAST score < 7. The presence
(X2 = 1) and absence (X2 = 0) of vocalization in behavioural symptoms initiating treatment also
define two additional subgroups of interest. Subgroup sample sizes are shown in Table 29.1.
29.1.2 Different approaches to subgroup analysis
The main concern in conducting tests of hypotheses for subgroup effects is that such multiple
testing has a detrimental effect on Type I error rate. Most clinical trials are designed to address
the overall effect in the entire population with careful attention to this error rate and to the power
to detect a prespecified effect size of the treatment over control. Thus all recommended methods
require an a priori specification of subgroups to be tested. Pocock et al. (2002) [23] and Wang
et al. (2007) [31], among others, argue for the use of interaction tests rather than the reporting of
treatment effects separately for each level of the subgroup. A test of interaction between treatment
groups (STI versus Control) and subgroups (presence or absence of vocalizaton) examines the
evidenceforinconsistencyoftreatmenteffectsacrosssubgroups.Standardmultiplicityadjustments
such as the Bonferroni method are then used with these interaction tests to account for testing of
multiplepre-specifiedsubgroups.IntheDementiaTrialexample,therearetwointeractiontestsand
the overall effect test. Thus the adjustment would require conducting each test at a level obtained
by dividing the originally intended Type I error rate by 3. Without multiplicity control, subgroup
analyses—even when identified using an interaction test—are considered exploratory rather than
confirmatory. Proschan and Waclawiw (2000) [25] advocate testing for a subgroup effect only if the
overall treatment effect has been established. This controls the Type I error based on the principle
of fixed sequence testing. Alternatively, the overall Type I error can simply be split across the overall
and subgroup comparisons in a possibly unequal allocation. Other authors have advocated fallback
type procedures, in which the subgroup can still be tested even if the overall treatment effect is
not significant ([2, 30, 32]). These utilize the correlation between the overall and the subgroup
specific test statistics as well as the anticipated directional consistency of the treatment effect across
subgroups to improve efficiency. Alpha-splitting and fallback type procedures require a smaller
significance level for the test of an overall effect in order to allocate some Type I error to the
subgroup test and still maintain the overall Type I error rate at the prespecified level α.
There are also some recommendations from the Bayesian viewpoint in the literature. These
fall mainly into two categories. The first approach is estimation based. It assumes that the
treatment–subgroup interactions are exchangeable [9, 11, 13, 17, 28], and has essentially focused on
post hoc analysis. This approach reports shrinkage estimates of the treatment–subgroup interac-
tions, and estimates of the variance components representing the inter–subgroup variability. This
inference is the basis for making judgements about the existence and the extent of subgroup effects.
Various forms of exchangeability for treatment-subgroup interactions have been studied.
The second approach is the one we take here and in [20, 29]. It focuses on evaluating sub-
group effects, i.e. treatment–subgroup interactions, only for pre-specified subgroups. Subgroups
are defined by the different values of pre-specified categorical covariates. The main goal is to deter-

578
P. W. Laud, S. Sivaganesan and P. Müller
mine whether there is a subgroup effect, and if so, which of the subgroups have different effect
sizes. Various configurations of subgroup effects are represented by different models, and Bayesian
model selection is used to choose among models using predetermined threshold values for poste-
rior probabilities. Multiplicity adjustment is incorporated with both the Bayesian and frequentist
approaches, by a suitable choice of priors and by controlling Type I and other error rates of interest
via a suitable choice of threshold values in the model selection procedure.
This Bayesian model selection approach that we take here has several advantages. Firstly, with
appropriate choice of priors, an automatic multiple comparison adjustment of the reported proba-
bilities is possible [26, 27]. Secondly, coherence and decision theoretic justification [20] makes the
approachattractivefromtheviewpointofoptimality.Thirdly,itis possibleanddesirabletoevaluate
the operating characteristics of the procedure over repeated experiments. Indeed results of such
evaluations can be used in the design phase to quantify the price of including subgroup analysis in
the protocol of the clinical trial.
In Section 29.2 we describe the models under consideration, followed by definitions of various
error types of interest in Section 29.3. Section 29.4 details the priors to be used, on the model space
as well as on the parameters of each model. Posterior computation and a model selection procedure
are described in Section 29.5. We revisit the Dementia Trial in Section 29.6, outline a decision
theoretic approach in Section 29.7 and conclude with a discussion of possible further developments
in Section 29.8.
29.2 Models for subgroup analysis
To set the stage, consider a two-arm clinical trial, where a treatment is compared with a control. To
be specific, suppose that a continuous response variable is observed on independent random sam-
ples of subjects under treatment and control. Let Y0j, j = 1, . . . , J0 and Y1j, j = 1, . . . , J1 denote
the responses under control and treatment, respectively, and take Ytj, t = 0, 1 to be N(μt, σ 2)
where μt may depend on some covariates. To begin, suppose that the values of a covariate X are
available on each subject, and that the values are classified into S categories. The main question
of interest is whether the treatment is effective overall, i.e. μ1 = μ0 or not. In subgroup analysis,
interest lies in the effectiveness of the treatment among the subgroups of patients as defined by each
covariate. In particular, we want to determine whether the treatment is effective within any of the S
subgroups and, if it is found effective in two or more subgroups, whether the sizes of effects differ
between these subgroups.
To cast this problem as a model selection problem, first consider two competing models
M00 : δ = μ1 −μ0 = 0 M01 : δ = μ1 −μ0 ̸= 0
and define the model space at this stage as M0 = {M00, M01}. Now let μ0s, μ1s denote the
mean outcome under control and treatment, respectively, in subgroup s, s = 1, . . . , S so that
δs = μ1s −μ0s represents treatment efficacy in subgroup s. The goal is to identify subgroups
which have no treatment effect and, among those having treatment effects, to characterize how the
treatmenteffectsdifferacrossthecorrespondinglevelsofthecovariate.Tothisend,wewillconsider
several models representing all such configurations of subgroup effects, and use MX to represent
the set of all such models.
29.2.1 Indexing and counting models
We index the models in MX using a vector, γ = (γ1, . . . ., γS), of length S, where γi is a non-
negative integer assigned to the i-th subgroup. A zero in any position indicates no treatment effect

Subgroup analysis
579
in that subgroup. The non-zero elements are integers ranging from 1 to K, where K is the number
of distinct non-zero treatment effects among all subgroups. The integers are assigned by order of
appearance, such that subgroups with common values of treatment effect receive the same integer.
For example, taking S = 3, the model with non-zero and distinct treatment effects in the three
subgroups is denoted by γ = (1, 2, 3); the model with equal but non-zero effect in the first and
thirdsubgroupsandadistinctnon-zeroeffectinsubgroup2isdenotedasγ = (1, 2, 1).TakingS =
5 subgroups, γ = (1, 0, 2, 1, 3) represents the case δ2 = 0, δ1 = δ4 ̸= 0, δ3 ̸= 0, δ5 ̸= 0, δ1 ̸=
δ3, δ1 ̸= δ5, δ3 ̸= δ5. Thus γs, s = 1, .., S, can be regarded as the cluster membership indicator for
the S subgroup effects corresponding to the covariate X. We also note that γ with all elements
equalling zero represents the overall null, and with all elements equalling 1 corresponds to the
hypothesis of overall effect in the population.
With S = 2 subgroups, there are five models in MX enumerated as:
(0, 0), (0, 1), (1, 0), (1, 2), (1, 1)
and S = 3 yields the 15 models:
(0, 0, 0), (0, 0, 1), (0, 1, 0), (1, 0, 0), (0, 1, 1), (1, 0, 1), (1, 1, 0), (0, 1, 2), (1, 0, 2), (1, 2, 0),
(1, 2, 2), (1, 2, 1), (1, 1, 2), (1, 2, 3), (1, 1, 1).
The number of models grows rapidly with S. To count all possible models, note that a model
puts the S subgroups into clusters and assigns each cluster a distinct treatment effect δk including,
possibly, zero. The number of distinct ways S distinguishable objects can be put in R clusters (or
indistinguishable cells) equals St(S, R), the Stirling number of the second kind, as in Chapter 24.1.4
of [1]. In each case, all of the R clusters may correspond to R distinct non-zero treatment effects;
or one of the R clusters to a zero treatment effect, and all others to R −1 distinct non-zero effects;
leadingtoR + 1possibilities.Inotherwords,eachoftheSt(S, R)partitionscorrespondsto(R + 1)
models obtained by labelling one of the R clusters with δ = 0, plus the model that does not label
any of the R clusters with δ = 0. Thus, the number of models, H, is given by
H =
S

R=1
(R + 1)St(S, R) =
S

R=1
(R + 1)
R!
R

i=0
(−1)i
R
i

(R −i)S
Actual counting can be accomplished more readily by the recursion
St(1, 1) = 1, St(S, R) = 0 if R < 1, and St(S, R) = R St(S −1, R) + St(S −1, R −1)
yielding:
S
2
3
4
5
6
H
5
15
52
203
877 .
When subgroups are made with multiple covariates X1, . . . , XI, we denote models in MX⟩by
Mih, h = 0, . . . , Hi reserving h = 0 for the null model γ = (0, . . . , 0) and h = Hi for the overall
effect model γ = (1, . . . , 1). More details are given in a later subsection as needed.

580
P. W. Laud, S. Sivaganesan and P. Müller
29.3 Error rates of interest
As theproceduretobedescribedbelow selects amodelfrommanycompetingmodels,severalerror
ratesofinterestcanbedefined.OfprimeimportanceamongtheseistheTypeIError(TIE)defined
astheprobability,inrepeatedexperiments,ofrejectingtheoverallnull(M00)byselectinganyother
modelwhenthetruemodelisM00.Othererrorratespertaintoprobabilitiesundertheoveralleffect
model and each subgroup model. While there are many possibilities, we focus on the following
definitions, where Pf represents probability under repeated experiments.
TIE
: Type I Error
Pf(M00 not selected|M00)
FNR : False Negative Rate
Pf(M00 selected|M01)
TPR : True Positive Rate
Pf(M01 selected|M01)
FSR : False Subgroup Rate
Pf(some Mih, i ̸= 0, h ̸= 0, h ̸= Hi selected|M01)
TSR : True Subgroup Rate
Pf(Mih selected|Mih, i ̸= 0, h ̸= 0, h ̸= Hi)
FPR : False (overall) Positive Rate
Pf(M01 selected|Mih, i ̸= 0, h ̸= 0, h ̸= Hi)
It is important to note that all but the TIE require additional specifications for proper definitions.
An effect size is required for FNR, TPR and FSR. Moreover, TSR and FPR further depend on i, h.
These definitions lead to Table 29.2, summarizing the various possibilities.
These error rates and the operating characteristics of the procedure can be evaluated via simula-
tionoverrepeateddatasets.FortheDementiaTrialexampleweshowtheresultsofsuchsimulations
in Section 29.6.
29.4 Priors
To carry out Bayesian inference we need a prior on the model space MX and priors on the
parameters in each model in MX . We specify the latter first, considering and restating the simple
model for observables mentioned at the beginning of Section 29.2. With independent normally dis-
tributed samples of J0 subjects under control and J1 under treatment, with measurements denoted
by Y0j, j = 1, . . . , J0 and Y1j, j = 1, . . . ., J1, respectively. More precisely,
Y0j ∼N(μ0s, σ 2), s = x0j;
Y1j ∼N(μ1s, σ2), s = x1j
where x0j = s, if the covariate X equals s for the j-th subject in the control group and similarly
for x1j.
Table 29.2 Error rates
Rates
Overall null
model M00
Truth
subgroup effect
model Mih
Overall alternative
model M01
M00
1-TIE
FNR
Decision
Mih
TSRih
FSR
M01
FPRih
TPR

Subgroup analysis
581
29.4.1 Priors for model parameters
The unknown parameters under a model M are the vector of S control means, μ0 =
(μ01, . . . , μ0S), the K non-zero distinct treatment effects vector δ⋆= (δ⋆
1, . . . , δ⋆
K), and σ 2. We
assign mixture g-priors for the δ⋆’s, and noninformative priors for the other parameters which are
common to all models. Mixture g-priors have been found to be reasonable non-informative priors
in linear model settings, and also computationally easy to work with [16]. The choice of prior is
critical for a fair model comparison and selection. For a good discussion of these issues, see [5, 10]
and the references cited there. The priors we use here are commonly used as good non-informative
priors.
Using generic notation P(·) to denote a probability distribution, conditionally on g, μ0 and σ2,
we take
δ⋆∼NK(0, gσ2IK)
and
P(g, μ0, σ 2) = P(g) · P(μ0, σ2),
where
P(g) =
1
(1 + g)2 and P(μ0, σ 2) = 1
σ2 ; g > 0, μ0 ∈RS, σ 2 > 0.
29.4.2 Prior on the model space
The prior distribution on the space MX can be specified by what we call a zero-enriched Polya
urn. Before spelling out the details below, we first give an outline emphasizing construction of the
prior. Consider the following useful version of the Polya urn noted by Blackwell & MacQueen (see
[6, 22]) in the context of a Dirichlet process. The urn consists of balls of various colours. At each
step, a ball is added to the urn with the following scheme. At the beginning of step n + 1, the urn
contains n balls of k ≤n colours. With probability n/(α + n) a ball is randomly drawn from this
urn,andreturnedtoitalongwithanotherballofthesamecolour.Withprobabilityα/(α + n)aball
of a new colour is added, the colour determined by a random draw from a bagful of colours. A prior
on MX is specified by the following procedure for generating the model index γ = (γ1, . . . , γS).
Given γ1, . . . , γs, the next element γs+1 equals 0 with probability p. Then, given γ1, . . . , γs and
γs+1 ̸= 0, γs+1 is generated from the above described Polya urn where the non-zero γ s serve as
colours. As an example, the probability that γ equals (1, 2, 1) is given by
{(1 −p)} × {(1 −p) ×
α
α + 1} × {(1 −p) ×
2
α + 2 × 1
2}.
We reparameterize α to q = 1/(α + 1) and take p, q to be independent beta random variables with
parameters (α1, β1) and (α2, β2), respectively.
For a complete specification, let Ks = max{γs′ ̸= 0; s′ ≤s} denote the number of distinct
non-zerotreatmenteffectsamongthefirst scovariatelevels,withKS = K forthefullsetofγss.Also,
when Ks ≥1 and 1 ≤k ≤Ks, let Nsk = #{s′ : γs′ = k, s′ ≤s} and Ls = #{s′ : γs′ ̸= 0, s′ ≤s}
denote, respectively, the number of treatment effects that match the k-th distinct non-zero effect
and the total number of non-zero treatment effects, among the first s levels of the covariate. Note

582
P. W. Laud, S. Sivaganesan and P. Müller
that s
k=1 Nsk = Ls. We use two parameters (p, q) to define the probabilities:
P(γs+1 = 0 | γ1, . . . , γs) = p
P(γs+1 = k | γ1, . . . , γs) = (1 −p)
Nskq
1−q+Lsq for k = 1, . . . , Ks ≥1
P(γs+1 = Ks + 1 | γ1, . . . , γs) = (1 −p)
1−q
1−q+Lsq for Ks ≥0
(29.1)
Conditional on non-zero treatment effects, the last two lines define a Polya urn with total mass
parameter α = (1 −q)/q. With probability proportional to q · Ls the treatment effect for the
(s + 1)-st level of the covariate is tied with an earlier level. With probability proportional to 1 −q
the treatment effect is distinct.
We assign independent Beta priors for the parameters (p, q),
P(p, q) = Beta(p; α1, δ1)Beta(q; α2, δ2)
(29.2)
whereBeta(x; a, b) indicatestheprobabilitydensityfunctionofaBetadistributionwithparameters
a and b.
The equation (29.1) implies the prior probability of a model M ∈MX, given p and q. To give a
closed form expression to this probability, let, for 0 ≤k ≤K ≤S
Nk = #{s : γs = k, 1 ≤s ≤S}
(29.3)
so that K
k=0 Nk = S and Nk = NSk. For example, N0 is the number of subgroups with zero
treatment effect, and N1 is the number of subgroups with treatment effects that are equal to the
first non-zero subgroup effect, and so on. The process of specifying the probability of a model M
indexed by γ can be thought of as filling in each of the S positions in γ by 0 with probability p, or
by a positive integer with probability 1 −p. The positive integers, which identify the configuration
of the non-zero subgroup effects, are chosen successively according to the probability specification
in (29.1).
Then, the prior probability of a model M, given p and q is
P(M | p, q) = c(p, q) P(N0, . . . , NK | p, q)
(29.4)
where
P(N0, . . . , NK | p, q) = pN0(1 −p)S−N0 αK 	K
k=1[Nk −1]!
	S−N0
s=1 {α + (s −1)}
(29.5)
[x] = max{x, 0}, Nks are as in (29.3), c(p, q) is the normalizing constant, and a product over an
empty set is equal to 1.
The probability model 29.1 is a zero-enriched Polya urn scheme. Each integer in the index vector
γ of a model M is allowed to be zero with probability p; and each non-zero integer is either equal
to a previously selected value or to the subsequent (hitherto unselected) value.
The normalizing constant c(p, q) is determined by counting the number of different models
corresponding to a given K and (N0, . . . , NK),
c(p, q)−1 =
S

K=0
  S
N0

P(N0, . . . , NK | p, q)

Subgroup analysis
583
Table 29.3 Conditional prior on model space, S = 3.
Model(s)
P(M|p, q)
P(M), α1 = β1 = α2 = β2 = 1/2
(0, 0, 0)
p3
10/32
(0, 0, 1), (0, 1, 0), (1, 0, 0)
p2(1 −p)
6/32
(0, 1, 1), (1, 0, 1), (1, 1, 0)
p(1 −p)2q
3/32
(0, 1, 2), (1, 0, 2), (1, 2, 0)
p(1 −p)2(1 −q)
3/32
(1, 2, 2), (1, 1, 2), (1, 2, 1)
(1 −p)3q(1 −q)/(1 + q)
0.255(10/32)
(1, 2, 3)
(1 −p)3(1 −q)2/(1 + q)
0.320(10/32)
(1, 1, 1)
2(1 −p)3q2/(1 + q)
0.425(10/32)
where the inside summation spans over all integers N0 ≥0, N1 > 0, . . . , NK > 0 satisfying the
condition N0 + N1 + . . . + NK = S and P(N0, . . . , NK | p, q) is as in 29.5.
As an example, for S = 3, the assigned probabilities for the 15 models are displayed in Table 29.3
conditioned on p and q as well as marginally for one choice of parameters for the two beta
distributions. These unconditional probabilities can be controlled by modifying the choice of
α1, β1, α2, β2.
29.5 Posterior probabilities and a subgroup reporting
procedure
Calculation of posterior model probabilities is straightforward. With ⃗y denoting all observed data,
wehaveP(⃗y|M, p, q) = P(⃗y|M)asaconsequenceofconditionalindependence.Theposteriorprob-
ability of a model M, therefore, is
P(M | ⃗y) =
P(⃗y|M)P(M)

M′∈M P(⃗y|M′)P(M′)
where
P(M) =

P(M|p, q)P(p, q)dpdq
(29.6)
Further,
P(⃗y|M) =

P(⃗y|M, g)P(g)dg
where
P(⃗y|M, g) =

P(⃗y | μ0, δ∗, σ 2)P(δ∗|g, μ0, σ 2)P(μ0, σ 2)dμ0dδ∗dσ 2,

584
P. W. Laud, S. Sivaganesan and P. Müller
where δ∗is the vector of (S −N0) non-zero treatment effects. For the normal models and priors
specified in Section 29.4, P(⃗y|M, g) has a closed form expression, which allows the calculation of
P(⃗y|M) using a one-dimensional integral over g.
29.5.1 Multiple covariates
Suppose there are I covariates of interest X1,...,XI, with Xi classified into Si categories. Now define
a model space MXi = Mi for each covariate Xi, leading to I distinct probability models. The
primary hypotheses of interest are the overall null and alternative models M00 and M01, which
constitute the space M0 in subsection 4.2.1. This overall-effect model space M0, along with
Mi, i = 1, . . . , I define the collection of models that are of interest in the subgroup analysis. List
the models in Mi in sequence, labelling the hth model by Mih, 0 ≤h ≤Hi. Often, the index i
is understood from the context in which case we omit it and write simply H. The labelling of the
modelsinMi isdonesothatthefirstmodel(h = 0)correspondstotheabsenceofsubgroupeffects
in all si subgroups and is represented by γ = (0, . . . , 0). The last model (h = H) corresponds to
thepresenceofsubgroupeffectsofequalsizeinallsubgroupsandisrepresentedby γ = (1, . . . , 1).
These two models correspond to the overall null and alternative models M00 and M01, respec-
tively. Thus, each of the remaining models in Mi represents the presence of a ‘bona-fide’
subgroup effect.
29.5.2 Procedure for reporting subgroup effects
For each model space Mi, first calculate posterior model probabilities denoted ¯Pi(Mih), i =
1, . . . , Hi. The reporting procedure is described in full step-wise detail in [29]. Here we describe
the essence of it. In each model space, the first and last models correspond to M00 and M01. Using
thresholds c0 and c1 to compare with these respectively, we proceed as follows.
Start: Choose M01 and stop if M01 is better than M00, i.e., ¯P(M01)
¯P(M00) > c0, and in each model
space, no subgroup model is better than the last model MiHi, i.e. ¯P(Mih)
¯P(MiHi) ≤c1 for all h.
Continue: In each model space, choose the highest probability model if it is better than both
end-models with the respective thresholds.
Finish: Choose M00 if no subgroup effect model is picked in any model space.
The overall effect model is chosen, only if there is strong evidence in its favour in comparison to the
overall null model, and if thereis no strong evidenceagainst it in comparison to any singlesubgroup
effect model. This serves to control two types of errors. When a model representing a subgroup
effect (in Mi, i > 0 ) is true, simply comparing M00 and M01 alone could result in a very high
posterior probability for M01 (if this is the one ‘closer’ to the true model) and lead to choosing
the wrong model M01. Comparing the overall effect model with the subgroup effect models (in
addition to the null model) protects against this error. On the other hand, it is also important to
control the error of choosing a subgroup effect model when in fact the overall effect model is true;
this can be achieved by requiring sufficiently large evidence against the overall effect model, i.e. by
choosing a large value for c1.
Thevaluesof c0 andc1 canbechosensothattheoverallType-Ierrorisequaltoapre-determined
value, and the probability of choosing a subgroup effect model when the overall effect model (with
a specified effect size) is true is also small. This can be done using simulation. The value of c0 relates
to the amount of evidence required for rejecting the null model in favour of either the overall or a
subgroupeffectmodel.Thevalueofc1 representsthethresholdforprotectingtheoverallalternative
against wrongly deciding in favour of a subgroup effect model. Adjusting for multiple testing, and

Subgroup analysis
585
controlling the error of choosing a subgroup effect when there is an overall effect are important
goals; the framework here is specifically geared to achieving these goals.
29.6 Error rate evaluation by simulation
Let us return to the Dementia Trial. We used the sample sizes in Table 29.1 and independent
Beta(0.5, 0.5) priors for p and q. For each of the many settings needed to construct Figures 29.1
and 29.2, one thousand datasets were generated.
The two lower curves in Figure 29.1(a) show the estimated True Positive Rate (TPR) and the
False Subgroup Rate (FSR), both calculated by simulating data from a specific overall effect (true)
model. The standardized effect size for this model was set at 0.8. The uppermost curve marked
TPR0 results from a simple procedure without subgroup analysis, i.e. this shows the traditional
power at various levels of significance. The Type I Error (TIE) was varied by setting c1 = c0, and
varying the common value from 19 down to 1, resulting in increasing values of TIE shown in the
figure. At TIE of 0.05, TPR is 0.85, FSR is 0.10 and TPR0 is 0.98. These quantify the tradeoffs
involved in planning a subgroup analysis as opposed to a simple overall effect analysis without
considering subgroups.
The curves in Figure 29.1(b) were obtained with data from a particular subgroup model, namely,
M11 = (1, 0) representing an effect in the subgroup with FAST score less than 7. The standardized
effect size was set to 0.8 again, i.e. this was the effect size in the subgroup with a non-zero treatment
effect while the other subgroup had effect size zero. The TSR curve represents the rate of correctly
choosingthesubgroupeffectmodelwhiletheFPRcurverepresentstherateofincorrectlychoosing
the overall effect model M01. Note that 1 −(TSR + FPR) is the rate of incorrectly choosing the
overall null or choosing a different subgroup model.
Figure 29.2 addresses issues similar to those in traditional power curves, plotting rates against
various standardized effect sizes. We calculated TIE for a range of common threshold values for
c0 = c1.Forc0 = c1 = 1.9wefoundTIE = 0.05.WethusfixedTIEat0.05bychoosingc0 = c1 =
1.9. In Figure 29.2(a) the true model is the overall effect model M01. As in Figure 29.1(a), TPR and
FSR are plotted along with the traditional power curve TPR0 for comparison. The curves in Figure
29.2(b) are computed under the same true subgroup model as in Figure 29.1(b), i.e. M11 = (1, 0).
0.00
0.02
0.04
0.06
0.08
0.10
0.0
0.2
0.4
0.6
0.8
1.0
Type−I Error Rate
Rates
TPR
FSR
TPR0
0.02
0.04
0.06
0.08
0.10
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Type−I Error Rate
Rates
TSR
FPR
Figure 29.1 Panel (a) on left, panel (b) on right.

586
P. W. Laud, S. Sivaganesan and P. Müller
0.0
0.5
1.0
1.5
0.0
0.2
0.4
0.6
0.8
1.0
Standardized effect size
Rate
TPR
FSR
TPR0
0.0
0.5
1.0
1.5
0.0
0.2
0.4
0.6
0.8
1.0
Standardized effect size
Rate
TSR
FPR
Figure 29.2 Panel (a) on left, panel (b) on right.
With these operating characteristics of the procedure, we used the experimental data to calculate
posterior model probabilities. As noted above, the choice c1 = c2 = 1.9 can achieve a Type I error
rate of 0.05.
To address the FSR, one would need to study it as a function of the overall effect size under
the assumption of no subgroup effects. However, it is possible to define and control the value of
averageFSR,averagedoverareasonableeffectsizedistribution.Weusedthenormaldistributionfor
the overall effect size with mean 0 and standard deviation equal to that of the data with simulation
carried out under zero subgroup-effects. By choosing a range of values of c0 and c1, a range of values
for TIE and average FSR can be obtained and suitably small values for these rates may then be
chosen.
Setting both c0 and c1 at 1.9, the average FSR was also found to be 0.05. we also calculated the
values of TIE on a rectangular grid of values for (c0, c1) and found that the choice (c0, c1) =
(1.9, 5.7) also corresponds to a TIE of 0.05. The average FSR for this choice was 0.01. Thus the
tuning parameters in the procedure were chosen to control the probability of incorrectly rejecting
the overall null and the probability of incorrectly picking a subgroup model when the overall effect
model is true.
Implementation of the stepwise procedure resulted in the posterior probabilities as given in
Table 29.4, and selection of the models, as given in Table 29.5. The result shows that, when TIE is
0.05andaverageFSRis0.05,theprocedureselectsthesubgroupeffectforMVOCAL;thetreatment
effect is absent when MVOCAL=0 and present when MVOCAL=1. When TIE is 0.05 and average
FSR is 0.01, the procedure selects the overall effect.
29.7 Subgroup reporting as a decision problem
It is natural to cast subgroup reporting as a Bayesian decision problem. To describe how, let
i denote all models except Mi0 and MiHi (corresponding to the overall null and alternative
hypotheses) in the model space MX⟩for subgroups made by the covariate Xi. Then take M =
M0 ∪1 ∪· · · ∪I. Let δ denote the desired decision. Possible decisions are to report an overall
treatment effect, δ = M01; to report no evidence for any treatment effects, δ = M00; or to report
subgroup effects. When reporting subgroup effects we allow reporting of multiple subgroups, one
for each covariate i. Thus reporting subgroups involves the identification of a set of covariates,

Subgroup analysis
587
Table 29.4 Posterior probabilities of overall and subgroup effects models for Dementia Trial data.
Model spaces M1 and M2 correspond to the covariates FAST and MVOCAL, respectively.
Model Space
M0
Models
M00
M01
Posterior Probability
0.011
0.989
Model Space (FAST)
M1
Models
M10
M11
M12
M13
M14
Posterior Probability
0.0105
0.0032
0.2089
0.3235
0.4539
Model Space (MVOCAL)
M2
Models
M20
M21
M22
M23
M24
Posterior Probability
0.0023
0.0003
0.5714
0.2843
0.1417
Table 29.5 Overall or Subgroup effect model as selected Dementia Trial data.
c0
c1
TIE
Model(s) Selected
Average FSR
1.9
1.9
0.05
M22
No effect if MVOCAL = 0,
non-zero effect if MVOCAL = 1
0.05
1.9
5.7
0.05
M01
Overall Alternative
0.01
AI ≡{i1, . . . , im} ⊂{1, . . . , I} together with a subgroup model index γi ∈ for each covariate.
LetI = {γi, i ∈AI}andletA = (AI, I)denotethepairofcovariateindicesandlistofsubgroups
for each chosen covariate. Reporting subgroups is thus characterized as δ = A. In summary
δ ∈{M0, M1, A} ≡D with A = (AI, I)
Note that the action space D differs from the model space M because we allow reporting of mul-
tiple subgroups simultaneously, but the probability model p(M) allows only for one true subgroup
model at a time.
A utility function u(δ, M, y) represents the investigator’s relative preferences for the alternative
actions under an assumed true model M and data y. Let nA = |AI| denote the number of reported
subgroups when δ = A. We assume a natural generalization of a traditional 0/c utility function for
testing problems:
u(δ, M, y) =
⎧
⎪⎪⎨
⎪⎪⎩
u0 I(M = M0)
if δ = M0
u1 I(M = M1)
if δ = M1
u2 I(M ∈AI) −(nA −1)
if δ = A
(29.7)

588
P. W. Laud, S. Sivaganesan and P. Müller
In short, we realize a reward when the correct model is reported, and we pay a price for reporting
more than one subgroup. As in many decision problems, the specific choice of u includes some
arbitrary and simplifying choices. In particular, we assume that the data enters the utility function
only indirectly through the decision rule δ = δ(y). This is typical for inference problems.
Let p(M) denote a probability model over the model space and let
U(δ, y) ∝

u(δ, M, y) p(M | y)
denotetheposteriorexpectedutility.Theoptimaldecisionδ∗istheactionwithmaximumexpected
utility.Itiseasytoshowthattheoptimaldecisionunder29.7canbecharacterizedasfollows.Assume
δ∗(y) = A. If i ∈AI, i.e. we report subgroups for covariate i, then the reported subgroups for i are
the subgroups with highest posterior probability,
γ ∗
i = arg max
γ ∈{p(Miγ | y)}
And
A∗
I = {i : p(Miγ ∗
i | y) ≥1/u2}
i.e. we report subgroups for all covariates that include a model Miγ ∗
i with posterior probability
greater than 1/u2. Let ∗
I = {γ ∗
i , i ∈A∗
I }. In summary, if δ∗= A, then it must be A∗= (A∗
I , ∗
I ).
Thus, to determine the Bayes rule δ∗we only need to compare expected utilities for δ = M0, M1
and A∗:
U(δ, y) =
⎧
⎪⎨
⎪⎩
u0 p(M0 | y)
if δ = M0
u1 p(M1 | y)
if δ = M1
u2

i∈A∗
I p(Miγ ∗i | y) −(nA∗−1)
if δ = A∗
We can now see the Bayes rule. Write p(M) as short for p(M | y), let M∗
i = Miγ ∗
i denote the
maximum posterior subgroup model with covariate xi, let M∗= arg max{p(M∗
i )} denotethehigh-
est posterior probability subgroup model and let i∗= arg maxi p(M∗
i ) denote the index of the
covariate that defines M∗. Then
δ∗=
⎧
⎪⎪⎪⎨
⎪⎪⎪⎩
M1
if p(M1)
p(M0) > u0
u1 and p(M1)
p(M∗) > u2
u1 + 
A∗
I \i∗u2p(M∗
i )−1
u1 p(M∗)
A∗
if p(M1)
p(M∗) < u2
u1 + 
A∗
I \i∗u2p(M∗
i )−1
u1p(M∗)
and p(M0)
p(M∗) < u2
u0 + 
A∗
I \i∗u2p(M∗
i )−1
u0p(M∗)
M0
otherwise
Note that u2 p(M∗
i ) > 1 for all i ∈A∗
I , i.e. the terms in the sums are all strictly positive (although
some can be very small).
It is possible to relate this Bayes rule to the procedure described in Section 29.5. To do this, we
depart from a strictly decision theoretic implementation, and take the form of the Bayes rule δ∗
as a motivation for a slightly simplified rule. We drop the sum over A∗\ i∗in the conditions for
reporting A∗, i.e. we are slightly more conservative in reporting subgroups. Then
δ∗=
⎧
⎪⎪⎨
⎪⎪⎩
M1
if p(M1)
p(M0) > u0
u1 and p(M1)
p(M∗) > u2
u1
A∗
if p(M1)
p(M∗) < u2
u1 and p(M0)
p(M∗) < u2
u0
M0
otherwise

Subgroup analysis
589
and finally, we replace A∗by {Miγ ∗
i : p(Miγ ∗
i ) > 1
u2 max{p(M1)u1, p(M0)u0}}. This enables us
to describe the final rule in terms of thresholds on odds p(M1)/p(M0), p(M∗
i )/p(M0) and
p(M∗
i )/p(M1) only. Noting that p(M∗) < x ⇔p(M∗
i ) < x∀i we get
δ∗=
⎧
⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎩
M1
if p(M1)
p(M0) > t0 and p(M∗
i )
p(M1) < t1 for all i
A∗
if for some i: p(M∗
i )
p(M0) > t0t1 and p(M∗
i )
p(M1) > t1
and A∗= {i : above holds}
M0
otherwise
(29.8)
This is very nearly the procedure described in Section 29.5. The main difference is that t0t1 is
replaced by t0.
For an implementation of the proposed rule we need to specify a probability model p(M)
over the space of all models M. Let Mi = {Miγi, γi ∈} ∪{M00, M01} denote the subspace
defined by groupings based on covariate xi, including the overall null and alternative. We define
probability models pi(M) for M ∈Mi, i = 1, . . . , I. We construct pi such that π0 ≡pi(M00) and
π1 ≡pi(M01) are common across i. The we piece the sub-models together by
p(M) =
⎧
⎪⎨
⎪⎩
π0
for M = M00
π1
for M = M01
pi(M) 1
I
for M = Miγ , γ ∈
We simplify the construction by using the same zero-enriched Polya urn model with common
parameter values (p, q). If Si = 2 for all covariates, the above definition works as stated. Otherwise
we need to rescale pi(M) in the last line of the above display as
pi(M) 1 −π0 −π1
1 −πi0 −πiHi
where πi0 is the probability assigned by the zero-enriched Polya urn to model Mi0 and similarly
πiHi to the last model (equal and non-zero effect in all subgroups) MiHI.
More details and results for the Dementia Trial are reported in [20].
29.8 Discussion
The methods presented here cast subgroup analysis as a model selection procedure that can also
be seen as a decision problem. Bayesian thinking allows one readily to formulate the probability
model and to implement inference and decision making. We have used a simple model here for the
observables(namely,conditionallyindependentnormals)inordertofocusmoreonvariousaspects
of model selection. These aspects include a careful specification of the model space, priors on this
space and on the parameters in each model, and repeated-data frequency evaluation or operating
characteristics. Beyond these aspects, the Bayesian formulation makes it fairly straightforward to
proceed to post-data calculations and inference for other models for the observables such as binary,
countortime-to-eventoutcomes.Thematerialpresentedherecanthereforebeseenasaframework
in which to carry out subgroup analysis rather than a specific instance of it.
We have used low-information priors for illustration. We have not addressed how to incorporate
substantive contextual information that might be available, external to the data from the clinical

590
P. W. Laud, S. Sivaganesan and P. Müller
trial. One example is post-approval studies of a drug’s safety and effectiveness. Typically, informa-
tiongatheredduringtheclinicaltrialsthatledtotheapprovalofthedrugisavailablewhendesigning
such studies. The framework presented here should allow the use of this information. However,
methods need to be developed for this purpose. Also, investigation is needed into the flexibility of
the priors to represent the available external information.
In this article, we have limited our goals to determining the presence or absence of a subgroup
effect (as well as overall effect) and which subgroups show equal or differing effects. It is also of
interest to estimate the effect sizes with interval estimates for making clinical judgements. It would
be desirable to extend the method presented here to provide estimate(s) based on the selected
model(s), or to provide smoothed estimates in the spirit of [28] and [8].
The framework presented here treats each subgroup-making covariate separately, not accomo-
dating any possible interactions such as due to age–gender combinations. It is possible to form a
single covariate using these combinations and proceed as before. However, a better approach could
be formulated to include and estimate interactions and to find optimal combinations. The work in
[21] and [7] is relevant in this context.
The current implementation of the calculations employs a full enumeration of models. Sampling
based evaluation of the posterior probabilities of models using reversible jump MCMC would be
much more efficient. Such methods have been typically implemented in the variable selection con-
text. The model space here is somewhat distinct and some features of it could offer opportunities
for added efficiencies by minimizing transdimensional MCMC. A sparse prior and the expectation
of an effect for only a few subgroups could be exploited for efficiency as well. It is also possible to
adapttheposteriorMCMCsimulationtodiscovertheoptimaldecisiontheoreticsolutionasin[18]
and [19].
Finally, it would be interesting to explore the possibility of employing Bayesian nonparametric
models that allow flexible clustering, for post-hoc subgroup analysis. Carrying out the clustering
without covariate information and then aligning any discovered clusters with the available covari-
ates may mitigate concerns related to multiplicities. It would be important to evaluate repeated-data
operating characteristics of such methods.
Acknowledgements
We thank Christine Kovach, PhD, RN of the University of Wisconsin-Milwaukee and Brent Logan,
PhD of the Medical College of Wisconsin for providing advice and the data from their study.
This research was initiated during a research program on multiplicities and repeatability at SAMSI
(Statistical and Mathematical Sciences Institute, NC).
References
[1] Abramowitz, M. and Stegun, I. A. (1972). Stirling Numbers of the Second Kind (9th printing
edn)., Chapter 24.1.4, pp. 824–825. Handbook of Mathematical Functions with Formulas,
Graphs and Mathematical Tables. Dover, New York.
[2] Alosh, M. and Huque, M. F. (2009). A flexible strategy for testing subgroups and overall pop-
ulation. Statistics in Medicine, 28(1), 3–23.
[3] Assmann, S. F., Pocock, S. J., Enos, L. E. and Kasten, L. E. (2000). Subgroup analysis and other
(mis)uses of baseline data in clinical trials. Lancet, 355(9209), 1064–1069.
[4] Bailar,J.C.andMosteller,F.(1992).MedicalUsesofStatistics(2ndedn).NEJMBooks,Waltham,
MA.
[5] Berger, J. O. (2006). The case for objective Bayesian analysis. Bayesian Analysis, 1(3), 385–402.

Subgroup analysis
591
[6] Blackwell, D. and MacQueen, J. B. (1973). Ferguson distributions via polya urn schemes.
Annals of Statistics, 1, 353–355.
[7] Brinkley, J., Tsiatis, A. and Anstrom, K. J. (2010, Jun). A generalized estimator of the
attributable benefit of an optimal treatment regime. Biometrics, 66(2), 512–522.
[8] Chipman, Hugh A., George, Edward I. and McCulloch, Robert E. (2010). Bart: Bayesian
additive regression trees. The Annals of Applied Statistics, 4(1), 266–298.
[9] Dixon, D. O. and Simon, R. (1991, Sep). Bayesian subset analysis. Biometrics, 47(3), 871–881.
[10] Goldstein, M. (2006). Subjective Bayesian analysis: principles and practice. Bayesian Analy-
sis, 1(3), 403.
[11] Hodges, J. S., Cui, Y., Sargent, D. J. and Carlin, B. P. (2007). Smoothing balanced
single-error-term analysis of variance. Technometrics, 49(1), 1225.
[12] Jackson, R. D., LaCroix, A. Z., Gass, M., Wallace, R. B., Robbins, J., Lewis, C. E., Bassford,
T., Beresford, S. A., Black, H. R., Blanchette, P., Bonds, D. E., Brunner, R. L., Brzyski, R. G.,
Caan, B., Cauley, J. A., Chlebowski, R. T., Cummings, S. R., Granek, I., Hays, J., Heiss, G.,
Hendrix, S. L., Howard, B. V., Hsia, J., Hubbell, F. A., Johnson, K. C., Judd, H., Kotchen,
J. M., Kuller, L. H., Langer, R. D., Lasser, N. L., Limacher, M. C., Ludlam, S., Manson, J. E.,
Margolis, K. L., McGowan, J., Ockene, J. K., O’Sullivan, M. J., Phillips, L., Prentice, R. L.,
Sarto, G. E., Stefanick, M. L., Horn, L. Van, Wactawski-Wende, J., Whitlock, E., Anderson,
G. L., Assaf, A. R., Barad, D., and Investigators, Women’s Health Initiative (2006, Feb 16).
Calcium plus vitamin d supplementation and the risk of fractures. The New England Journal of
Medicine, 354(7), 669–683.
[13] Jones, H. E., Ohlssen, D. I., Neuenschwander, B., Racine, A. and Branson, M. (2011). Bayesian
models for subgroup analysis in clinical trials. Clinical Trials, 8, 129–143.
[14] Kovach, C. R., Logan, B. R., Noonan, P. E., Schlidt, A. M., Smerz, J., Simpson, M. and Wells,
T. (2006, Jun–Jul). Effects of the serial trial intervention on discomfort and behaviour of
nursing home residents with dementia. American Journal of Alzheimer’s Disease and Other
Dementias, 21(3), 147–155.
[15] Lagakos, S. W. (2006). The challenge of subgroup analyses–reporting without distorting. The
New England Journal of Medicine, 354(16), 1667–1669.
[16] Liang, F., Paulo, R., Moina, G., Clyde, M. A. and Berger, J. O. (2008). Mixtures of g-priors for
Bayesian variable selection. Journal of the American Statistical Association, 103(481), 410–423.
[17] Louis, T. A. (1984). Estimating a population of parameter values using Bayes and empirical
Bayes methods. Journal of the American Statistical Association, 79, 393–398.
[18] Müller, P. (1999). Simulation based optimal design, pp. 459–474. Bayesian Statistics 6. Oxford
University Press.
[19] Müller, P., Sansó, B. and DeIorio, M. (2004). Optimal Bayesian design by inhomogeneous
Markov Chain Monte Carlo. Journal of the American Statistical Association, 99(467), 788–798.
[20] Müller, Peter, Sivaganesan, Siva, and Laud, Purushottam W. (2010). A Bayes rule for subgroup
reporting. In Frontiers of Statistical Decision Making and Bayesian Analysis: In Honor of James O.
Berger (ed. M.-H. Chen, D. K. Dey, P. Müller, D. Sun, and K. Ye), pp. 277–284. Springer-Verlag
Inc.
[21] Nobile, A. and Green, P. J. (2000). Bayesian analysis of factorial experiments by mixture
modeling. Biometrika, 66(2), 512–522.
[22] Pitman, J. (2006). Some developments of the Blackwell-MacQueen urn scheme, Volume 30 of
Statistics, Probability and Game Theory, pp. 245–267. IMS Lecture Notes.
[23] Pocock,S.J.,Assmann,S.E.,Enos,L.E.andKasten,L.E.(2002).Subgroupanalysis,covariate
adjustment and baseline comparisons in clinical trial reporting: current practice and prob-
lems. Statistics in Medicine, 21(19), 2917–2930.
[24] Pocock, S. J. and Lubsen, J. (2008). More on subgroup analyses in clinical trials. The New
England Journal of Medicine, 358(19), 2076; author reply 2076–7.

592
P. W. Laud, S. Sivaganesan and P. Müller
[25] Proschan, M. A. and Waclawiw, M. A. (2000). Practical guidelines for multiplicity adjustment
in Clinical Trials. Controlled Clinical Trials, 21(6), 527–539.
[26] Scott, J. G. and Berger, J. O. (2006). An exploration of aspects of Bayesian multiple testing.
Journal of Statistical Planning and Inference, 136, 2144–2162.
[27] Scott, J. G. and Berger, J. O. (2010). Bayes and empirical Bayes multiplicity adjustment in the
variable selection problem. The Annals of Statistics, 38(5), 2587–2619.
[28] Simon, R. (2002). Bayesian subset analysis: application to studying treatment-by-
gender interactions. Statistics in Medicine, 21(19), 2909–2916.
[29] Sivaganesan,S.,Laud,P.W.andMüller,P.(2011).ABayesiansubgroupanalysiswithazero-en-
riched polya urn scheme. Statistics in Medicine, 30(4), 312–323.
[30] Song, Y. and Chi, G. Y. (2007). A method for testing a prespecified subgroup in clinical trials.
Statistics in Medicine, 26(19), 3535–3549.
[31] Wang, R., Lagakos, S. W., Ware, J. H., Hunter, D. J. and Drazen, J. M. (2007). Statistics
in medicine – reporting of subgroup analyses in clinical trials. The New England Journal of
Medicine, 357(21), 2189–2194.
[32] Wiens, B. L. and Dmitrienko, A. (2005). The fallback procedure for evaluating a single family
of hypotheses. Journal of Biopharmaceutical Statistics, 15(6), 929–942.
[33] Yusuf, S., Wittes, J., Probstfield, J. and Tyroler, H. A. (1991). Analysis and interpretation of
treatment effects in subgroups of patients in randomized clinical trials. JAMA : The Journal of
the American Medical Association, 266(1), 93–98.

30
Surviving fully Bayesian
nonparametric
regression models
timothy e. hanson and
alejandro jara
30.1 Introduction
S
emiparametric survival models split the model, and hence inference, into two parts: parametric
andnonparametric.Theparametricportionofthemodelprovidesasuccinctsummaryrelating
patient survival to a relatively small number of regression coefficients: risk factors, acceleration fac-
tors, odds ratios, etcetera. The nonparametric part of the model—the baseline hazard, cumulative
hazard, or survival function—is modelled as flexibly as possible, so inference does not depend on
a particular parametric form such as log-normal or Weibull.
This chapter compares two Bayesian nonparametric models that generalize the accelerated fail-
ure time model, based on recent work concerning probability models for predictor-dependent
probability distributions. Both models allow for crossing hazards for different covariates x1 and
x2, as well as crossing cumulative hazards, and hence crossing survival curves, and thus convey
substantial flexibility over standard accelerated failure time models. Furthermore, the entire den-
sity is modelled at every covariate level x ∈X, so full density and hazard estimates are available,
accompanied by reliable interval estimates, unlike many median (and other quantile) regression
models. Perhaps most importantly, both models are implemented as user-friendly functions calling
compiled FORTRAN in DPpackage for R [45].
The chapter is organized as follows. Commonly used semiparametric survival models are
reviewed in Section 30.2. A discussion about the Bayesian nonparametric priors used in the gen-
eralizations of the accelerated failure time model is given in Section 30.3. The two generalizations
of the accelerated failure time model are introduced in Section 30.4. The two models are compared
by means of real-life data analyses in Section 30.5. The chapter concludes with a short discussion in
Section 30.6.
30.2 Semiparametric survival models
A common starting point in the specification of a regression model for time-to-event data is the
definition of a baseline survival function, S0, that is modified (either directly or indirectly) by

594
T. E. Hanson and A. Jara
subject-specific covariates x. Let T0 be a random survival time from the baseline group (with all
covariates equal to zero). The baseline survival function is defined by S0(t) = P(T0 > t). Contin-
uous survival is assumed throughout. Thus, the baseline density and hazard functions are defined
by f0(t) = −d
dt S0(t) and h0(t) = f0(t)/S0(t), respectively. The survival, density and hazard func-
tions for a member of the population with covariates x will be denoted by Sx(t), fx(t), and hx(t),
respectively.
30.2.1 Proportional hazards
A proportional hazards (PH) model [20], for continuous data, is obtained by expressing the covari-
ate-dependent survival function Sx(t) as
Sx(t) = S0(t)exp(x′β)
(30.1)
In terms of hazards, this model reduces to
hx(t) = exp(x′β)h0(t)
Note then that for two individuals with covariates x1 and x2, the ratio of hazard curves is constant
andproportionalto hx1(t)
hx2(t) = exp{(x1 −x2)′β},hencethename‘proportionalhazards.’Cox[20]is
the second most cited statistical paper of all time [74], and the proportional hazards model is easily
themostpopularsemiparametricsurvivalmodelinstatistics,tothepointwheremedicalresearchers
tend to compare different populations’ survival in terms of instantaneous risk (hazard) rather than
mean or median survival as in common regression models. Part of the populariy of the model has to
dowiththeincrediblemomentumthemodelhasgainedfromhoweasyitistofitthemodelthrough
partial likelihood [21] and its implementation in SAS in the procedure proc phreg. The use of
partial likelihood and subsequent counting process formulation [4] of the model has allowed ready
extension to stratified analysis, proportional intensity models, frailty models, and so on [81].
The first Bayesian semiparametric approach to PH models posits a gamma process as a prior on
the baseline cumulative hazard H0(t) =

 t
0 h0(s)ds [48]; partial likelihood emerges as a limiting
case (of the marginal likelihood as the precision approaches zero). The use of the gamma process
prior in PH models, as well as the beta process prior [41], piecewise exponential priors, and corre-
lated increments priors are covered in [43] (pp. 47–94) and [78]. Other approaches include what
are essentially Bernstein polynomials [11, 29] and penalized B-splines [40, 51]. The last two models
are available in a free program called BayesX [7].
30.2.2 Accelerated failure time
An accelerated failure time (AFT) model is obtained by expressing the covariate-dependent sur-
vival function Sx(t) as
Sx(t) = S0{exp(−x′β)t}
(30.2)
This is equivalent to a linear model for the log transformation of the corresponding time-to-event
response variable, T,
log T = x′β + ϵ
(30.3)
where exp(ϵ) ∼S0. The mean, median, and any quantile of survival for an individual with covari-
ates x1 is changed by a factor of exp{(x1 −x2)′β} relative to those with covariates x2.

Surviving Bayesian nonparametric regression models
595
An early frequentist least squares teatment of the AFT model with right-censored data is
due to Buckley and James [10]; the Buckley–James estimator is implemented in Frank Harrell’s
Design library for R [3]. More refined estimators followed in the 1990s [86, 89] focusing on
median-regression.
From a Bayesian nonparametric perspective, the first approach, based on a Dirichlet process
prior, obtained approximate marginal inferences to the AFT model [18]; a full Bayesian treatment
using the Dirichlet process is not practically possible [47]. Approaches based on Dirichlet process
mixture models have been considered by Kuo and Mallick [56], Kottas and Gelfand [55] and
Hanson[34].Dirichletprocessmixtures‘fix’thediscretenatureoftheDirichletprocess,asdoother
discrete mixtures of continuous kernels. We refer the reader to Komarek and Lesaffre [54], for an
alternativeapproachbasedonmixturesofnormaldistributions.Tailfreepriorsthathavecontinuous
densities can directly model the distribution of ϵ in expression (30.3) [33, 37, 83, 93].
Although PH is by far the most commonly-used semiparametric survival model, several stud-
ies have shown vastly superior fit and interpretation from AFT models [33, 38, 42, 49, 67, 71].
Many further argue for alternatives to hazard ratios in reporting the results of survival analyses
[9, 39, 49, 50, 67, 68, 75, 80, 85, 94]. Cox pointed out himself [72] “. . . the physical or substantive
basis for . . . proportional hazards models . . . is one of its weaknesses . . . accelerated failure time models
are in many ways more appealing because of their quite direct physical interpretation . . . ”. Additionally,
Keene [50] points out difficulties with PH analysis for use in meta-analytic analysis designed to
combine information across several studies and further comments “Accelerated failure time models
are a valuable and are often a more realistic alternative to proportional hazards models."
Since the AFT model is a log-linear model, one can obtain a point estimate of survival for
covariates x as simply exp(x′ ˆβ), where ˆβ is an estimate of β. Prediction is impossible within
the PH model framework without an estimate of the baseline hazard function, so reporting only
coefficients—which is common—disallows others to predict survival.
30.2.3 Proportional odds
The proportional odds (PO) model has recently gained attention as an alternative to the PH and
AFT models. PO defines the survival function Sx(t) for an individual with covariate vector x
through the relation
Sx(t)
1 −Sx(t) = exp{−x′β}

S0(t)
1 −S0(t)

(30.4)
The odds of dying before any time t are exp{(x1 −x2)′β} times greater for those with covariates
x1 versus x2.
The first semiparametric approaches to proportional odds models involving covariates are due
to Cheng et al. [17], Murphy et al. [65], and Yang and Prentice [87]. A semiparametric frequentist
implementationoftheproportionaloddsmodelisavailableinMartinussenandScheike’stimereg
package [62] for R. Bayesian nonparametric approaches for the PO model have been based on
Bernstein polynomials [5], B-splines [84], and Polya trees [33, 36, 38, 93].
The PH, AFT, and PO models all make overarching assumptions about the data generating
mechanism for the sake of obtaining succinct data summaries. An important aspect associated with
the Bayesian nonparametric formulation of these models is that, by assuming the same, flexible
model for the baseline survival function, they are placed on a common ground [33, 36, 38, 92, 93].
Furthermore, parametric models are special cases of the nonparametric models. Differences in fit
and/or predictive performance can therefore be attributed to the survival models only, rather than
to additional possible differences in quite different nonparametric models or estimation methods.

596
T. E. Hanson and A. Jara
Of the Bayesian approaches based on Polya trees considered by Hanson [33], Hanson and Yang
[38], Zhao et al. [93] and Hanson et al. [36], the PO model was chosen over PH and AFT according
to the log-pseudo marginal likelihood (LPML) criterion [28]. In three of these works, the paramet-
ric log-logistic model, a special case of PO that also has the AFT property, was chosen. This may
be due to the fact that the PO assumption implies that hazard ratios limt→∞
hx1(t)
hx2(t) = 1, that is,
eventuallyeveryonehasthesameriskofdyingtomorrow.Theseauthorsalsofoundthat,everything
else being equal, the actual semiparametric model chosen (PO, PH or AFT) affects prediction far
morethanwhetherthebaselineismodellednonparametrically.Itisworthnotingthatnoneofthese
papers favoured the semiparametric PH model in actual applications.
30.2.4 Other models
PH, AFT and PO are only three of many semiparametric survival models used in practice. There
are a few more hazard-based models including the additive hazards (AH) model [1, 2], given by
hx(t) = h0(t) + x′β
which is implemented in Martinussen and Scheike’s timereg package for R. An empirical Bayes
approach to this model based on the gamma process was implemented by [79]. Fully Bayesian
approaches require elaborate model specification to incorporate the rather awkward constraint
h0(t) + x′β ≥0 for t > 0 [23, 88].
Recently, there has been some interest in the accelerated hazards model [16, 91], given by
hx(t) = h0{exp(−x′β)t}
This model allows hazard and survival curves to cross. A highly interpretable model that relates
covariates to the residual life function, m0, which is defined by m0(t) = E(T0 −t|T0 > t), is the
proportional mean residual life model [15]. Under this model, the residual life function for a subject
with covariates x is given by
mx(t) = exp(x′β)m0(t).
It is important to stress that there have been no Bayesian approaches to these two models to date.
Certainly there are other semiparametric models we are omitting here, but these round out several
available methods.
Finally, several interesting ‘super models’ have been proposed in the literature, including trans-
formation models that include PH and PO as special cases [61, 76], transformation and extended
regression models that include PH and AH as special cases [62, 88] and hazard regression models
that include both PH and AFT as special cases [14]. While highly flexible, all these models suffer in
that, once fit, the resulting regression parameters lose any simple interpretability.
30.2.5 Extensions
Thereareseveralgeneralizationsthathavebeenmadetothesemiparametricmodelspresentedhere.
A standard approach for dealing with correlated data has been the introduction of frailty terms to
the linear predictor (e.g., x′
ijβ + γi for the jth subject in cluster i). Frailty models have been widely
discussed in the literature and correspond to particular cases of hierarchical models.
Hazard-based models (proportional, additive and accelerated) naturally accommodate time-de-
pendent covariates; the linear predictor is simply augmented to be x(t)′β. Similarly, hazard-based

Surviving Bayesian nonparametric regression models
597
models can also include time-dependent regression effects via x′β(t) or even x(t)′β(t). A tradi-
tional ‘quick fix’ for nonproportional hazards is to introduce an interaction between a covariate
x and time, e.g. hx(t) = exp(xβ1 + xtβ2)h0(t), yielding a particular focused deviation from PH.
After implementing time-dependent regression effects, model inference is essentially reduced to
examining plots, much like additive models.
These extensions allow one to continue using the familiar proportional hazards model is situa-
tions where proportional hazards does not hold. Such is the mindset of many people involved in
analysing survival data that other, potentially more parsimonious models, are never even consid-
ered. Therneau and Grambsch [81] discuss the Cox model including many generalizations. When
proportional hazards fails they recommend, (a) stratification within the Cox model, (b) partitioning
the time axis so that proportional hazards may hold over shorter time periods within the Cox model,
(c) time-varying effects β(t) within the Cox model, and (d) as a last resort the consideration other
models, e.g. AFT or AH.
Other model modifications include cure rate models, joint longitudinal/survival models, recur-
renteventsmodels,multistatemodels,competingrisksmodels,andmultivariatemodelsthatincor-
porate dependence more flexibly than frailty models.
30.3 Two Bayesian nonparametric priors used
in survival analysis
Ultimately, we generalize AFT models based on extension of Dirichlet process mixture models and
Polya tree models. Therefore, we briefly review both of these priors in this section. Many other
priorsforbaselinehazard,cumulativehazard,orsurvivalfunctionshavebeensuccessfullyemployed
over the last 20 years. These include the gamma process [48], the beta process [41], Bernstein
polynomials [12, 29, 69, 70], piecewise exponential models [43], penalized B-splines [40, 51, 84]
and extensions of these approaches. The literature is too vast to attempt even a moderate review,
and we instead refer the interested reader to Sinha and Dey [78], Ibrahim et al. [43], Müller and
Quintana [64], and Hanson et al. [35] for general overviews.
30.3.1 The Dirichlet process mixture model
Convolving a Dirichlet process (DP) [26] with a parametric kernel, such as the normal, gives a DP
mixture(DPM)model[25,59].AsimpleDPMofGaussiandensitiesforcontinuousdataϵ1, . . . , ϵn
is given by
ϵi|G iid∼

N(μ, σ 2)dG(μ, σ2),
(30.5)
where the mixing distribution, G, is a random probability measure defined on R × R+, following
a DP. A random probability measure G follows a DP with parameters (α, G0), where α ∈R+ and
G0 is an appropriate probability measure defined on R × R+, written as
G | α, G0 ∼DP(αG0)
(30.6)
if for any measurable non-trivial partition {Bl : 1≤l≤k} of R × R+ the vector {G(Bl) : 1 ≤l ≤k}
has a Dirichlet distribution with parameters (αG0(B1), . . . , αG0(Bk)). It follows that
G(Bl) | α, G0 ∼Beta(αG0(Bl), αG0(Bc
l )),

598
T. E. Hanson and A. Jara
and therefore, E[G(Bl) | α, G0] = G0(Bl) and
Var[G(Bl) | α, G0] = G0(Bl)G0(Bc
l)/(α + 1).
TheseresultsshowtheroleofG0 andα,namely,thatGiscentredaroundG0 andthatα isaprecision
parameter. If G | α, G0 ∼DP(αG0), then the trajectories of the process can be represented by the
following stickbreaking representation, due to Sethuraman [77]:
G(·) =
∞

i=1
wiδ
μi,σ 2
i
(·)
where δθ(·) is the Dirac measure at θ, wi = Vi
	
j<i(1 −Vj), with Vi | α iid∼Beta(1, α), and
(μi, σ 2
i ) | G0
iid∼G0.
The stickbreaking representation of the DP allows formulating (30.5) as a countably infinite
mixture of normals given by
ϵi|G iid∼
∞

j=1
⎡
⎣Vj
j−1

k=1
(1 −Vk)
⎤
⎦N(μj, σ2
j )
(30.7)
NotethatE(wj) > E(wj+1)forallj,sotheweightsarestochasticallyordered.Thepriordistribution
on ϵi is centred at the normal distribution; Griffin [30] discusses prior specifications that control
the ‘non-normalness’ of this distribution.
30.3.2 The Polya tree
A Polya tree (PT) successively partitions the reals into finer and finer partitions; each refinement
of a partition doubles the number of partition sets by cutting each of the previous level’s sets into
two pieces; there are two sets at level 1, four sets at level 2, eight sets at 3, and so on. We focus on
a PT centred at the standard normal density, that is, where N(0, 1) is the centring distribution for
the Polya tree. At level j, the Polya tree partitions the real line into 2j intervals Bj,k = (−1((k −
1)2−j), −1(k2−j)) of probability 2−j under , k = 1, . . . , 2j. Note that Bj,k = Bj+1,2k−1 ∩
Bj+1,2k. Given an observation ϵ is in set k at level j, i.e. Bj,k, it could then be in either of the two off-
spring sets Bj+1,2k−1 or Bj+1,2k at level j + 1. The conditional probabilities associated with these
sets will be denoted by Yj+1,2k−1 and Yj+1,2k. Clearly they must sum to one, and so a common
prior for either of these probabilities is a beta distribution [27, 33, 37, 57, 58, 82, 83, 93], given by
Yj,2k−1|c ind.
∼beta(cj2, cj2), j = 1, . . . , J; k = 1, . . . , 2j−1
where c ∈R+, which ensures that every realization of the process has a density, allowing the mod-
elling of continuous data without the need of convolutions with continuous kernels. The resulting
model for data ϵ1, . . . , ϵn is given by
ϵi|G iid∼G
(30.8)
where
G ∼PTJ(c, N(0, 1))
(30.9)

Surviving Bayesian nonparametric regression models
599
The user-specified weight c controls how closely the posterior follows N(0, 1) in terms of L1 dis-
tance[32],withlargervaluesforcingGclosertoN(0, 1);oftenapriorisplacedonc,e.g.c ∼(a, b).
The PT is stopped at level J (typically J = 5, 6, 7); within the sets {BJ,k : k = 1, . . . , 2J} at the level
J G follows N(0, 1) [33]. The resulting density is given by
p(ϵ|{Yj,k}) = φ(ϵ)
J
j=1
2Yj,⌈2jφ(ϵ)⌉
(30.10)
where ⌈·⌉is the ceiling function, and so a likelihood can be formed. For the simple model, the PT
is conjugate. Let ϵ = (ϵ1, . . . , ϵn). Then
Yj,2k−1|ϵ ind.
∼beta

cj2 +
n

i=1
I{⌈2jφ(ϵ)⌉= 2k −1}, cj2 +
n

i=1
I{⌈2jφ(ϵ)⌉= 2k}

and Yj,2k = 1 −Yj,2k−1.
Location μ and spread σ parameters are melded with expression (30.8) and the PT prior (30.9)
to make a median-μ location-scale family for data y1, . . . , yn, given by
yi = μ + σϵi,
where the ϵi | G iid∼G and G follows a PT prior as in expression (30.9), with the restriction Y1,1 =
Y1,2 = 0.5. Allowing μ and σ to be random induces a mixture of PT (MPT) model for y1, . . . , yn,
smoothing out predictive inference [37, 57]. Note that Jeffreys’ prior under the normal model is a
reasonable choice here [8], and leads to a proper posterior [33].
30.3.3 Which approach is better?
In recent years, there has been a dramatic increase in research and applications of Bayesian non-
parametric models, such as DPM and MPT, motivated largely by the availability of simple and
efficient methods for posterior computation. However, much of the published research has been
concentrated on the proposal of new models with insufficient emphasis given to the real practical
advantage of the new proposals. The overriding problem is the choice of what method to use in a
givenpracticalcontext.Ingeneral,thefullsupportofthemodelsandtheextremelyweakconditions
underwhichthedifferentmodelshavebeenshowntohaveconsistentposteriorsmightwelltrapthe
unwaryintoafalsesenseofsecurity,bysuggestingthatgoodestimatesoftheprobabilitymodelscan
be obtained in a wide range of settings. More research seems to be needed in that direction.
Early papers on PTs [57, 82, 83] show ‘spiky’ and ‘irregular’ density estimates. However, these
papers picked a very small precision c and used a fixed centring distribution (without a random
scale σ) that was often much more spread out than what the data warranted. The MPT prior
automatically centres the prior at a reasonable centring distribution and smooths over partition
boundaries. We argue that both MPT and DPM are competitor models, with appealing properties
regarding support and posterior consistency, and that performance of each should be evaluated in
real-life applications with finite sample sizes. We will illustrate this point by means of the analyses
of simulated data.
We compared MPT and DPM estimates using ‘perfect samples’ (data are percentiles of equal
probability from the distribution, approximating expected order statistics) from four densities,
motivated by Figures 2.1 and 2.3 in [24]. Both models were fitted under more or less standard prior
specifications for samples of size n = 500. Specifically, the MPT model was fitted in DPpackage

600
T. E. Hanson and A. Jara
[45] using the PTdensity function with an N(μ, σ 2) baseline measure, and the following prior
settings: J = 6, c ∼(10, 1), and p(μ, σ) ∝σ −1 (Jeffreys’ prior under the normal model). The
DPM model was fit using the DPdensity function included in DPpackage [45]. This function
fits the DPM model considered by Escobar and West [25], which is given by
yi|μi, τi ∼N(μi, τ−1
i
), (μi, τi)|G ∼G, G|α, G0 ∼DP(αG0),
wherethecentringdistribution,G0,correspondstotheconjugatenormal/gammadistribution,i.e.
G0 ≡N(μ|m, (kτ)−1) × (τ1, τ2). The model was fitted by assuming τ1 = 2 and τ2 = 1 and,
m ∼N(0, 105), k ∼(0.5, 50) and α ∼(1, 1).
Figure 30.1 shows the true models and the density estimates under the DPM and MPT models,
along with the histogram of the data. Although it is difficult to see differences between the estimates
under the DPM and MPT models across true models, the density estimates under the MPT are a
y
density
0
1
2
3
4
5
6
7
0.0
0.2
0.4
0.6
0.8
(a) Mixture of normals and uniform.
y
density
−4
−2
0
2
4
0.0
0.1
0.2
0.3
0.4
0.5
(b) Double exponential.
y
density
−0.5
0.5 1.0 1.5 2.0 2.5
0.0
0.2
0.4
0.6
0.8
1.0
(c) Triangle.
y
density
−3 −2 −1
0
1
2
3
0.0
0.1
0.2
0.3
0.4
(d) Standard normal.
Figure 30.1 Simulated data. The estimated density functions under the MPT and DPM models are
displayed as solid and dashed lines, respectively. The data generating model is represented as
dotted lines. Panels (a), (b), (c) and (d) display the density estimates, true model and the histogram
of the simulated data under a mixture of normals and uniform, double exponential, triangle and
standard normal distribution, respectively.

Surviving Bayesian nonparametric regression models
601
bit rougher than under DPM, but there are no obvious partitioning effects or unruly spikes where
there should not be. More importantly, either method can perform better than the other depending
on the data generating mechanism; they both can do a good job.
When the true model is a mixture of two normals and a uniform distribution, the L1 distance
between the MPT estimates and the true model was 0.056, while for the DPM L1 = 0.034. When
the true model was a double exponential distribution, the MPT model outperformed the DPM.
In this case L1 = 0.025 and L1 = 0.060 for the MPT and DPM model, respectively. A similar
behaviour was observed when the model under consideration had a triangular shape. In this case,
L1 = 0.051 and L1 = 0.096 for the MPT and DPM model, respectively. Finally, when the data
generating mechanism was a standard normal distribution, both models performed equally well;
L1 = 0.009 for both MPT and DPM. From the plots in Figure 30.1 and the L1 distances, the MPT
appears to be a serious competitor to the DPM model, doing (two times) better or as well in three
out of four cases.
30.4 Two generalizations of the AFT model
Section 30.2 overviewed several useful semiparametric models for analysing survival data. We
mentioned that the PH model can be augmented with time-varying effects, stratification, etc., to
handle non-proportional hazards, but that these fixes destroy any easy interpretability from the
model. In this section we discuss two generalizations of the AFT model to handle data that do
not follow AFT assumptions. Similarly to augmenting hazard models with time-varying effects,
the AFT generalizations allow for crossing survival and hazard curves, but still allow straightfor-
ward interpretability. Furthermore, both models boil down to simple DPM and PT models for
baseline x = 0 groups, thus enabling the placement of all competing models on common ground,
and facilitating comparisons among quite different assumptions on how covariates affect survival.
Both augmentations are examples of ‘density regression’, allowing the entire density fx(·) to change
smoothly with predictors.
Thetwoapproachesarethe‘lineardependentDirichletprocessmixture’(LDDP)andthe‘linear
dependent tailfree process’ (LDTFP). The former can be interpreted as a mixture of parametric
AFT models, and the latter is an AFT model with very general heteroscedastic error terms. In this
section we introduce the models and their properties, in the next we compare them using datasets
that have been examined in the literature.
Note that unlike traditional linear models that focus on the trend (mean or median), we are
interested in modelling the entire density as well; otherwise we could directly use quantile regres-
sion models, such as the ones implemented in Koenker’s quantreg package in R [52]. In what
follows, consider standard interval-censored failure time data {(li, ui, ˜xi)}n
i=1, where the responses
are known up to an interval, Ti ∈(li, ui], and ˜xi are covariates for subject i, without the intercept
term. The AFT model for the failure time response is given by the log-linear model
yi = log(Ti) = ˜x′
iβ + ϵi
(30.11)
30.4.1 Linear dependent Dirichlet process mixture
A natural semiparametric specification of the AFT model would consider a nonparametric model
for the error distribution of the errors in (30.11). By considering a DPM of normal distributions for
the errors, the distribution for the log failure time is the distribution of ϵi, given by (30.7), shifted
by the covariates ˜x′
iβ. Specifically,

602
T. E. Hanson and A. Jara
yi|β, G ind.
∼
∞

j=1
wjN(μj + ˜x′
iβ, σ 2
j )
The interpretation of the components of β are as usual and the model can be fitted using standard
algorithms for Dirichlet process mixture models [66].
The LDDP [22, 45, 46] can be interpreted as a generalization of the previous model, which
arises by additionally mixing over the regression coefficients, yielding a mixture of log-normal AFT
models. Set xi = (1, ˜x′
i)′. The LDDP model is given by
yi|G ind.
∼
∞

j=1
wjN(x′
iβj, σ2
j )
(30.12)
where, as before, wi = Vi
	
j<i(1 −Vj), with Vi | α iid∼Beta(1, α), and βj
iid∼N(m0, V0) and
σ 2
j
iid∼−1(a, b).
The model trades easy interpretability offered by a single β for greatly increased flexibility. In
particular, the LDDP model does not stochastically order survival curves from different predictors
xi1 and xi2, and both the survival and hazard curves can cross. However, if the data warrant only a
few weights from {w1, w2, . . . } with non-negligible mass, the model can be re-fitted using a simple,
finite mixture of log-normal distributions. The number of components J in the finite mixture can
be estimated from the posterior number of components from a fit of (30.12) yielding
yi|w, β, τ ind.
∼
J

j=1
wjN(x′
iβj, σ 2
j )
(30.13)
where w = (w1, . . . , wJ), β = (β1, . . . , βJ) and τ = (σ2
1 , . . . , σ 2
J ). This model defines J homo-
geneous subpopulations with simple unimodal survival densities LN(βj1, τj) and accompanying
acceleration factors given through (βj2, . . . , βj,p). These can be viewed as homogeneous subpop-
ulations corresponding to an omitted variable with J levels. The model is also a mixture of experts
model with a gating mechanism that is independent of the covariates. Generalization of this model,
where weights also depend on covariates can be found in, for instance, Müller et al. [63] and Chung
and Dunson [19].
30.4.2 Mixture of linear dependent tailfree processes
A PT defines the conditional probabilities Yj+1,2k−1 and Yj+1,2k as beta. However, we can instead
define a logistic regression for each of these probabilities, allowing the entire shape of the density
to change with predictors; this is the approach considered by Jara and Hanson [44]. Given covari-
ates x,
(Yj+1,2k−1, Yj+1,2k)
are modelled through logistic regressions
log{Yj+1,2k−1(x)/Yj+1,2k(x)} = x′τj,k

Surviving Bayesian nonparametric regression models
603
There are 2J −1 covariate vectors τ = {τj,k}. For instance, for J = 3, {τ0,1, τ1,1, τ1,2, τ2,1, τ2,2,
τ2,3, τ2,4}. Let X = [x1 · · · xn]′ be the n × p design matrix. Following Jara and Hanson [44],
each is assigned an independent normal prior, τj,k ∼Np

0,
2
c(j+1)2 

. Several options could
be considered for . Jara and Hanson [44] discussed in detail the case where  = n(X′X)−1,
generating a g-prior [90] for the tailfree regression coefficients.
Augmenting (30.10), the random density is given by
gx(ϵ) = φ(ϵ)2J
J
i=1
Yj,⌈2j(ϵ)⌉(x)
The parameter c ∈R+ controls how non-normal gx(e) is, and can be interpreted as a measure of
the random L1 distance ||gx −φ|| [32]. Since the {Yj,k} are modelled as logistic-normal instead
of beta, the resulting random density is called a tailfree process. The final linear dependent tailfree
process AFT model is given by
yi = x′
iβ + σϵi, ϵi|τ ind.
∼gxi.
Unlike the LDDP, the LDTFP separates survival into one distinct trend x′β and an evolving
log-baseline survival density gx. By setting gx to have median-zero, eβj gives a factor by how median
survival changes when xj is increased just as in standard AFT models. This heightened interpretabil-
ity in terms of median-regression in the presence of heteroscedastic error allows a fit of the LDTFP
model to easily relate covariates x to median survival.
The LDTFP models the probability of falling above or below quantiles of the N(x′β, σ 2) dis-
tribution, but in terms of conditional probabilities. This model can be viewed as a particular kind
of quantile regression model. Koenker and Hallock [53] suggest that ‘. . . instead of estimating linear
conditional quantile models, we could instead estimate a family of binary response models for the
probability that the response variable exceeded some prespecified cutoff values.’ However, Koenker
and Hallock [53] prefer the linear (in covariates) quantile specification because ‘. . . it nests within
it the independent and identically distributed error location shift model of classical linear regres-
sion.’ By augmenting a median-zero tailfree process with a general trend x′β we accomplish the
same objective, nesting the ubiquitous normal-errors linear model within a highly flexible median
regression model, but with heteroscedastic error that changes shape with covariate levels x ∈X.
30.5 Illustrations
The two generalizations of the AFT model are illustrated using real-life datasets. The general-
ized AFT models were fitted using the LDDPsurvival and LDTFPsurvival functions, which
are available in version 1.1–4 of DPpackage [45]. The models were compared in terms of the
LPML [28].
30.5.1 Breast cancer data
We consider a dataset involving time to cosmetic deterioration of the breast for women with stage
1 breast cancer who have undergone a lumpectomy [6]. The data come from a retrospective study
designed to compare the cosmetic effects of radiotherapy versus radiotherapy plus chemotherapy
on women with early breast cancer. Both treatments are alternatives to a mastectomy that preserve

604
T. E. Hanson and A. Jara
(and thus enhance the appearance of) the breast. It is postulated that chemotherapy in addition
to radiotherapy (treatment A) reduces the cosmetic effect of the procedure by inducing breast
retraction more quickly than radiotherapy alone (treatment B).
There are 46 radiation only and 48 radiation plus chemotherapy patients. Patients were typically
observedevery4to6months,atwhichpointacliniciangradedthelevelofbreastretractionasnone,
moderate, or severe. The event is moderate or severe breast retraction, and thus the event times are
interval censored, with interval endpoints occurring at clinic visits. These data were analysed using
atraditional(homoscedastic)AFTmodelconsideringbaselinedistributionsmodelledasamixture
of DP by Hanson and Johnson [31].
The LDDP and LDTFP models were fitted, including as predictor the treatment indicator. For
the LDTFP model we set J = 4 and  = n(X′X)−1, where n is the sample size. The median
function parametersβ0 and β1 were given a Zellner’s g-prior [90], g(X′X)−1, with g = 2n, σ −2 ∼
(5.01, 2.01), and c ∼(10, 1). For the LDDP model, we assume m0 ∼N2(02, 100 × I2),
V−1
0
∼Wishart(4, I2), a = 3.01, b ∼(3.01, 1.01) and α ∼(10, 1). For all models, a burn-in
of 20 000 iterates was followed by a run of 100 000 thinned down to 10 000 iterates.
The two models based on dependent process priors outperformed a classical semiparametric
analysisbasedintheAFTassumption.Roundedtothenearestinteger,theLPMLfortheLDDPand
LDTFP model was −147 and −149, respectively, better than −159 obtained using the mixture of
DP model [31], fixing the total mass parameter α = 5 and using a N(γ , θ2) centring distribution.
Figure 30.2 shows the estimated survival curves for the two treatment groups under the different
models, evaluated in a grid of 200 equally-spaced points. The survival curves are similar to the ones
reported by Hanson and Johnson [31], with the exception that the estimated survival curves are
initially indistinguishable before 15 months under the LDDP and LDTFP model; the AFT model
forces a more pronounced stochastic ordering of the survival curves. Although the LDDP model
shows marginally better predictive performance than the LDTFP model for these data, the survival
point estimates obtained under the two models are qualitatively similar. The better predictive
performance of the LDDP models is explained by its lower posterior variability.
Under the LDTFP model, the estimated treatment effect was ˆβ1 = 0.30 and nonsignificant with
a 95% highest posterior density (HPD) interval of (−0.07, 0.68). The median time to retraction
from treatment B is estimated to be e0.30 ≈1.38 times longer than treatment A with 95% HPD
interval (0.90, 1.91). Priors favouring smaller values of c yielded qualitatively similar inferences,
although estimated point estimates of the survival curves cross at about 15 months.
The results of the AFT analyses with homoscedastic error show a significant regression effect,
indicating lower times to retraction under treatment A as expected, somewhat contradicting the
LDTFP analysis where no significant difference in median survival was found. However, a glance at
Figure 30.2 shows marginal evidence of different median lifetimes given the large variability of the
survival curves across the groups. Under the homoscedastic AFT model the regression parameter
affects all quantiles simultaneously and indicates a net scale shift in probability; under the LDTFP
model the conditional probabilities change beyond the median function. The significant effect
under the homoscedastic model can be viewed as an averaging of the overall warping of the density
across treatment levels, embodied in the parameters {τj,k}.
30.5.2 Cancer clinical trial data
We consider data arising from a cancer clinical trial, described in Rosner [73], and analyzed by De
Iorio et al. [22] using a LDDP mixture of normals model. The data records the event-free survival
time in months for 761 women, i.e. the response of interest corresponds to the time until death,
relapse or treatment-related cancer. Researchers are interested in determining whether high doses
of the treatment are more effective for treating the cancer compared to lower doses. High doses
of the treatment are known to be associated with a high risk of treatment-related mortality. The

Surviving Bayesian nonparametric regression models
605
0
10
20
30
40
50
60
70
0.0
0.2
0.4
0.6
0.8
1.0
months
survival
(a)
0
10
20
30
40
50
60
70
0.0
0.2
0.4
0.6
0.8
1.0
months
survival
(b)
0
10
20
30
40
50
60
70
0.0
0.2
0.4
0.6
0.8
1.0
months
survival
(c)
0
10
20
30
40
50
60
70
0.0
0.2
0.4
0.6
0.8
1.0
months
survival
(d)
0
10
20
30
40
50
60
70
0.0
0.2
0.4
0.6
0.8
1.0
months
survival
(e)
0
10
20
30
40
50
60
70
0.0
0.2
0.4
0.6
0.8
1.0
months
survival
(f)
Figure 30.2 Breast retraction data. Panels (a) and (b) show estimated survival curves for treatments A
and B, respectively, under the LDTFP model. Panels (c) and (d) display survival curves for treatments
A and B, respectively, under the LDDP model. Panels (e) and (f) display survival curves for treatments
A and B, respectively, under the mixture of Dirichlet process model for comparison purposes. In all
cases, the pointwise 95% credible bands are also displayed as a grey area.

606
T. E. Hanson and A. Jara
clinicians hope that this initial risk is offset by a substantial reduction in mortality and disease
recurrence or relapse, consequently justifying more aggressive therapy. Thus the primary reason
for carrying out the clinical trial was to compare low versus high dose. Following [22], we consider
twocategoricalcovariates,onecontinuouscovariate,andoneinteractionterm:treatmentdose(low
or high), estrogen receptor (ER) status (negative or positive), the size of the tumour (standardized
to zero mean and unit variance), and the treatment dose and ER status interaction.
The LDDP and LDTFP models were fitted to the data. For the LDTFP, we set J = 5
and  = 103I5, and the median function parameters were assigned independent normal pri-
ors β ∼N5(05, 103I5), σ −2 ∼(1.5, 6.0), and c ∼(7.0, 0.1). For the LDDP model, we
assume m0 ∼N5(05, 100 × I5), V−1
0
∼Wishart(7, I5), a = 1.01, b ∼(1.51, 3.01) and α ∼
(5, 1). For both models, a burn-in of 20 000 iterates was followed by a run of 100 000 thinned
down to 10 000 iterates. Qualitatively similar inferences were obtained under the two models.
0
20
40
60
80
120
0.3
0.5
0.7
0.9
months
survival
0
20
40
60
80
120
0.3
0.5
0.7
0.9
months
survival
0
20
40
60
80
120
0.3
0.5
0.7
0.9
months
survival
0
20
40
60
80
100
0.3
0.5
0.7
0.9
months
survival
(a)
(b)
(c)
(d)
Figure 30.3 Cancer clinical trial data. In all panels the results are displayed for tumour size equal
to 2.0 cm (first quartile) under the LDTFP model. Panels (a), (b) and (c) show the posterior mean
(and pointwise 95% HPD band in grey) for the survival curves for low treatment dose—negative
ER status, high treatment dose—negative ER status and low treatment dose—positive ER status,
respectively. Panel (d) shows the posterior mean for the four combinations of treatment dose and
ER status. The low treatment dose—negative ER status, high treatment dose—negative ER status,
low treatment dose—positive ER status and high treatment dose—positive ER status is represented
as a continuous, dashed, dotted and dotdash lines, respectively.

Surviving Bayesian nonparametric regression models
607
0
20
40
60
80
120
0.3
0.5
0.7
0.9
months
survival
0.3
0.5
0.7
0.9
survival
0
20
40
60
80
120
months
0
20
40
60
80
120
0.3
0.5
0.7
0.9
months
survival
0.3
0.5
0.7
0.9
survival
0
20
40
60
80
100
months
(a)
(b)
(c)
(d)
Figure 30.4 Cancer clinical trial data. In all panels the results are displayed for tumour size equal
to 2.0 cm (first quartile) under the LDDP model. Panels (a), (b) and (c) show the posterior mean
(and pointwise 95% HPD band in grey) for the survival curves for low treatment dose—negative
ER status, high treatment dose—negative ER status and low treatment dose—positive ER status,
respectively. Panel (d) shows the posterior mean for the four combinations of treatment dose and
ER status. The low treatment dose—negative ER status, high treatment dose—negative ER status,
low treatment dose—positive ER status and high treatment dose—positive ER status is represented
as a continuous, dashed, dotted and dotdash lines, respectively.
Figures 30.3 and 30.4 show the estimated survival curves, and corresponding posterior uncertainty,
for ER positive patients with tumour size 2.0 cm (the first quartile) under the LDTFP and LDDP
model, respectively. The two models based on dependent process priors outperformed a classical
semiparametric analysis based in the AFT assumption. Rounded to the nearest integer, the LPML
fortheLDDPandLDTFPmodelwas−2048and−2052,respectively,betterthan−2063obtained
using a parametric AFT lognormal regression model.
An advantage of the LDTFP model over the LDDP model is that direct inferences can be made
on the median survival time. In order to evaluate the posterior evidence against the hypothesis
of null effect of the covariates on the median survival function, the pseudo contour probability
(PsCP) was evaluated for each hypothesis. The PsCP was computed based on the highest posterior
density (HPD) intervals, which were estimated using the method proposed by Chen and Shao
[13]. The PsCP is defined as one minus the smallest credible level for which the null hypothesis is

608
T. E. Hanson and A. Jara
contained in the corresponding HDP. The results suggest a non-important effect of the treatment
dose (PsCP = 0.55) and its interaction with ER status (PsCP = 0.5), and an important effect of
the ER status (PsCP< 0.01) and a negative effect of the tumour size (PsCP < 0.01)onthemedian
survival time.
30.5.3 Lung cancer data
We consider data presented in Maksymiuk et al. [60] on the treatment of limited-stage small-cell
lung cancer in n = 121 patients. The data have been analysed in the literature by using median-
regression models [33, 55, 83, 86, 89]. In the study, it was of interest to determine which sequencing
of the drugs cisplaten and etoposide increased the lifetime from time of diagnosis, measured in
days, of those with limited-stage small-cell lung cancer. Treatment A applied cisplaten followed by
etoposide, whereas treatment B applied etoposide followed by cisplaten. The patients’ ages in years
at entry into the study were also included as a concomitant variable. The LDTFP model was fitted
to the data assuming J = 5 and  = 103I2. The median function parameters were assigned inde-
pendent normal priors β ∼N2(02, 103I2), σ −2 ∼(3, 1.5), and c ∼(1.0, 1.0). For the LDDP
model, we assume m0 ∼N2(02, 100I2), V−1
0
∼Wishart(5, I2), a = 3.01, b ∼(3.01, 3.01) and
α ∼(5, 1).Forbothmodels,aburn-inof20 000iterateswasfollowedbyarunof100 000thinned
down to 10 000 samples.
The LPML measures for the LDDP and LDTFP models were −732 and −733, respectively.
These results suggest that both dependent models slightly outperform from a predictive point
of view alternative parametric and semiparametric survival models. In fact, the LPML for the
Weibull, log-logistic, and PO, PH, and AFT models, using a MPT prior for the baseline survival
function, were −747, −735, −734, −737, and −734, respectively [33]. The LDDP and LDTFP
models in some sense predict the data ‘best’, but there is little real predictive difference among
the LDDP, LDTFP, PO and AFT models. The Weibull model is clearly inferior, whereas the
LDDP and LDTFP models have a pseudo Bayes factor of about 50 relative to the PH model.
The similar predictive behaviour of the dependent model is confirmed by the density plots in
Figures 30.5 and 30.6.
Table 30.1 presents posterior regression parameter inferences for the MPT AFT, PO and PH
models and for the LDTFP model. Holding age fixed, patients typically survive e0.345 ≈1.4 times
longer under treatment A versus treatment B under the AFT assumption. The PO model indicates
that the odds of surviving past any time t is e0.93 ≈2.5 greater for treatment A versus treatment B.
Similarly to observations under the MPT AFT model, the results of the LDTFP suggest that the
median survival time for patients under treatment A is e0.407 ≈1.5 times the median survival time
for patients under treatment B.
30.6 Concluding remarks
We have discussed, compared and illustrated flexible nonparametric models that can be used to
introduce categorical and continuous covariates in the context of time-to-event data. The models
correspond to generalizations of AFT models based on dependent extensions of the DP and PT
priors. Advantages of the induced survival regression models include ease of interpretability and
computational tractability. An important property of the proposed models is that the complete dis-
tribution of survival times is allowed to change with values of the predictors (including properties
suchasskewness,multimodality,quantiles,etc.)insteadofjustoneortwocharacteristics,asimplied
for many commonly used survival models.

Surviving Bayesian nonparametric regression models
609
500
1000
2000
0.0000
0.0010
0.0020
days
density
500
1000
2000
0.0000
0.0010
0.0020
days
density
500
1000
2000
0.0000
0.0010
0.0020
days
density
500
1000
2000
0.0000
0.0010
0.0020
days
density
500
1000
2000
0.0000
0.0010
0.0020
days
density
500
1000
2000
0.0000
0.0010
0.0020
days
density
(a)
(b)
(c)
(d)
(e)
(f)
Figure 30.5 Lung cancer data. Panels (a), (c) and (e) show the posterior mean (and pointwise 95%
HPD band in grey) for the densities at age 56, 61.1 and 68 for treatment A under the LDDP model.
Panels (b), (d) and (f) show the posterior mean (and pointwise 95% HPD band in grey) for the densities
at age 56, 61.1 and 68 for treatment B under the LDDP model.

610
T. E. Hanson and A. Jara
500
1000
2000
0.0000
0.0010
0.0020
days
density
500
1000
2000
0.0000
0.0010
0.0020
days
density
500
1000
2000
0.0000
0.0010
0.0020
days
density
500
1000
2000
0.0000
0.0010
0.0020
days
density
500
1000
2000
0.0000
0.0010
0.0020
days
density
500
1000
2000
0.0000
0.0010
0.0020
days
density
(a)
(b)
(c)
(d)
(e)
(f)
Figure 30.6 Lung cancer data. Panels (a), (c) and (e) show the posterior mean (and pointwise 95%
HPD band in grey) for the densities at age 56, 61.1 and 68 for treatment A under the LDTFP model.
Panels (b), (d) and (f) show the posterior mean (and pointwise 95% HPD band in grey) for the densities
at age 56, 61.1 and 68 for treatment B under the LDTFP model.

Surviving Bayesian nonparametric regression models
611
Table 30.1 Lung cancer data Posterior mean (95% credible interval) for the regression coefficients.
Coefficient
MPT AFT
MPT PO
MPT PH
LDTFP
β1 (Age)
0.007
0.034
0.028
–0.019
(–0.004, 0.036)
(–0.001, 0.071)
(0.003, 0.054)
(–0.037, –0.001)
β2 (Treatment)
0.345
0.930
0.533
0.407
(0.157, 0.533)
(0.292, 1.568)
(0.130, 0.926)
(0.130, 0.691)
Acknowledgements
TheworkofthefirstauthorwassupportedinpartbyNSFgrantCMMI-0855329.Thesecondauthor
was supported by Fondecyt 11100144 grant.
References
[1] Aalen, O O (1980). A model for nonparametric regression analysis of counting processes. In
Lecture Notes in Statistics, Vol. 2, pp. 1–25. Springer-Verlag.
[2] Aalen, O O (1989). A linear regression model for the analysis of life times. Statistics in
Medicine, 8, 907–925.
[3] Alzola, C and Harrell, F (2006). An introduction to S and the Hmisc and Design libraries. Online
manuscript available at http://biostat.mc.vanderbilt.edu/wiki/pub/Main/RS/sintro.pdf.
[4] Andersen, P K and Gill, R D (1982). Cox’s regression model for counting processes: A large
sample study. The Annals of Statistics, 10, 1100–1120.
[5] Banerjee, S and Dey, D K (2005). Semi-parametric proportional odds models for spatially
correlated survival data. Lifetime Data Analysis, 11, 175–191.
[6] Beadle, G, Harris, J, Silver, B, Botnick, L, and Hellman, S (1984). Cosmetic results following
primary radiation therapy for early breast cancer. Cancer, 54, 2911–2918.
[7] Belitz, C, Brezger, A, Kneib, T, and Lang, S (2009). BayesX – Software for Bayesian infer-
ence in structured additive regression models. Version 2.00. Available from http://www.stat.
uni-muenchen.de/∼bayesx.
[8] Berger, J O and Guglielmi, A (2001). Bayesian testing of a parametric model versus nonpara-
metric alternatives. Journal of the American Statistical Association, 96, 174–184.
[9] Bradburn,MJ,Clark,TG,Love,SB,andAltman,DG(2003).SurvivalanalysispartII:Multi-
variate data analysis – an introduction to concepts and methods. British Journal of Cancer, 89,
431–436.
[10] Buckley, J and James, I (1979). Linear regression with censored data. Biometrics, 8, 907–925.
[11] Carlin, B P and Hodges, J S (1999). Hierarchical proportional hazards regression models for
highly stratified data. Biometrics, 55, 1162–1170.
[12] Chang, I S, Hsiung, C A, Wu, Y J, and Yang, C C (2005). Bayesian survival analysis using
Bernstein polynomials. Scandinavian Journal of Statistics, 32, 447–466.
[13] Chen, M H and Shao, Q M (1999). Monte Carlo estimation of Bayesian credible and HPD
intervals. Journal of Computational Graphical Statistics, 8, 69–92.
[14] Chen, Y Q and Jewell, N P (2001). On a general class of semiparametric hazards regression
models. Biometrika, 88, 687–702.

612
T. E. Hanson and A. Jara
[15] Chen, Y Q, Jewell, N P, Lei, X, and Cheng, S C (2005). Semiparametric estimation of propor-
tional mean residual life model in presence of censoring. Biometrics, 61, 170–178.
[16] Chen, Y Q and Wang, M C (2000). Analysis of accelerated hazards models. Journal of the
American Statistical Association, 95, 608–618.
[17] Cheng, S C, Wei, L J, and Ying, Z (1995). Analysis of transformation models with censored
data. Biometrika, 82, 835–845.
[18] Christensen, R and Johnson, W O (1988). Modeling accelerated failure time with a Dirichlet
process. Biometrika, 75, 693–704.
[19] Chung, Y and Dunson, D B (2009). Nonparametric Bayes conditional distribution modeling
with variable selection. Journal of the American Statistical Association, 104, 1646–1660.
[20] Cox, D R (1972). Regression models and life-tables (with discussion). Journal of the Royal
Statistical Society, Series B: Methodological, 34, 187–220.
[21] Cox, D R (1975). Partial likelihood. Biometrika, 62, 269–276.
[22] De Iorio, M, Johnson, W O, Müller, P, and Rosner, G L (2009). Bayesian nonparametric
nonproportional hazards survival modeling. Biometrics, 65, 762–771.
[23] Dunson, D B and Herring, A H (2005). Bayesian model selection and averaging in additive
and proportional hazards. Lifetime Data Analysis, 11, 213–232.
[24] Efromovich, S (1999). Nonparametric Curve Estimation: Methods, Theory and Applications.
Springer-Verlag.
[25] Escobar, M D and West, M (1995). Bayesian density estimation and inference using mixtures.
Journal of the American Statistical Association, 90, 577–588.
[26] Ferguson, T S (1973). A Bayesian analysis of some nonparametric problems. The Annals of
Statistics, 1, 209–230.
[27] Ferguson, T S (1974). Prior distributions on spaces of probability measures. The Annals of
Statistics, 2, 615–629.
[28] Geisser, S and Eddy, W F (1979). A predictive approach to model selection. Journal of the
American Statistical Association, 74, 153–160.
[29] Gelfand, A E and Mallick, B K (1995). Bayesian analysis of proportional hazards models built
from monotone functions. Biometrics, 51, 843–852.
[30] Griffin, J (2010). Default priors for density estimation with mixture models. Bayesian Analy-
sis, 5, 45–64.
[31] Hanson, T and Johnson, W O (2004). A Bayesian semiparametric AFT model for interval-
censored data. Journal of Computational and Graphical Statistics, 13, 341–361.
[32] Hanson, T, Kottas, A, and Branscum, A (2008). Modelling stochastic order in the analysis
of receiver operating characteristic data: Bayesian nonparametric approaches. Journal of the
Royal Statistical Society, Series C, 57, 207–225.
[33] Hanson,TE(2006).InferenceformixturesoffinitePolyatreemodels.JournaloftheAmerican
Statistical Association, 101, 1548–1565.
[34] Hanson, T E (2006). Modeling censored lifetime data using a mixture of gammas baseline.
Bayesian Analysis, 1, 575–594.
[35] Hanson,TE,Branscum,A,andJohnson,WO(2005).Bayesiannonparametricmodelingand
data analysis: An introduction. In Bayesian Thinking: Modeling and Computation (Handbook
of Statistics, volume 25) (ed. D. Dey and C. Rao), pp. 245–278. Elsevier: Amsterdam.
[36] Hanson, T E, Branscum, A, and Johnson, W O (2011). Predictive comparison of joint lon-
gitudinal–survival modeling: a case study illustrating competing approaches. Lifetime Data
Analysis, 17, 3–28.
[37] Hanson, T E and Johnson, W O (2002). Modeling regression error with a mixture of Polya
trees. Journal of the American Statistical Association, 97, 1020–1033.
[38] Hanson, T E and Yang, M (2007). Bayesian semiparametric proportional odds models. Bio-
metrics, 63, 88–95.

Surviving Bayesian nonparametric regression models
613
[39] Heller, G and Simonoff, J S (1992). Prediction in censored survival data: A comparison of the
proportional hazards and linear regression models. Biometrics, 48, 101–115.
[40] Hennerfeind, A, Brezger, A, and Fahrmeir, L (2006). Geoadditive survival models. Journal of
the American Statistical Association, 101, 1065–1075.
[41] Hjort, N L (1990). Nonparametric Bayes estimators based on beta processes in models for
life history data. The Annals of Statistics, 18, 1259–1294.
[42] Hutton,JLandMonaghan,PF(2002).Choiceofparametricacceleratedlifeandproportional
hazards models for survival data: Asymptotic results. Lifetime Data Analysis, 8, 375–393.
[43] Ibrahim, J G, Chen, M H, and Sinha, D (2001). Bayesian Survival Analysis. Springer-Verlag.
[44] Jara, A and Hanson, T E (2011). A class of mixtures of dependent tailfree processes.
Biometrika, 98, 553–566.
[45] Jara, A, Hanson, T E, Quintana, F A, Müller, P, and Rosner, G L (2011). DPpackage: Bayesian
semi- and nonparametric modeling in R. Journal of Statistical Software, 40, 1–30.
[46] Jara, A, Lesaffre, E, De Iorio, M, and Quitana, F (2010). Bayesian semiparametric inference
for multivariate doubly-interval-censored data. The Annals of Applied Statistics, 4, 2126–2149.
[47] Johnson, W O and Christensen, R (1989). Nonparametric Bayesian analysis of the accelerated
failure time model. Statistics and Probability Letters, 8, 179–184.
[48] Kalbfleisch, J D (1978). Nonparametric Bayesian analysis of survival time data. Journal of the
Royal Statistical Society, Series B: Methodological, 40, 214–221.
[49] Kay, R and Kinnersley, N (2002). On the use of the accelerated failure time model as an
alternative to the proportional hazards model in the treatment of time to event data: A case
study in influenza. Drug Information Journal, 36, 571–579.
[50] Keene, O N (2002). Alternatives to the hazard ratio in summarizing efficacy in time-to-event
studies: an example from influenza trials. Statistics in Medicine, 21, 3687–3700.
[51] Kneib, T and Fahrmeir, L (2007). A mixed model approach for geoadditive hazard regression.
Scandinavian Journal of Statistics, 34, 207–228.
[52] Koenker, R (2008). Censored quantile regression redux. Journal of Statistical Software, 27(6),
1–25.
[53] Koenker, R and Hallock, K F (2001). Quantile regression. Journal of Economic Perspectives, 15,
143–156.
[54] Komárek, A and Lesaffre, E (2008). Bayesian accelerated failure time model with multivariate
doubly-interval-censoreddataandflexibledistributionalassumptions.JournaloftheAmerican
Statistical Association, 103, 523–533.
[55] Kottas, A and Gelfand, A E (2001). Bayesian semiparametric median regression modeling.
Journal of the American Statistical Association, 95, 1458–1468.
[56] Kuo, L and Mallick, B (1997). Bayesian semiparametric inference for the accelerated
failure-time model. Canadian Journal of Statistics, 25, 457–472.
[57] Lavine, M (1992). Some aspects of Polya tree distributions for statistical modelling. The
Annals of Statistics, 20, 1222–1235.
[58] Lavine, M (1994). More aspects of Polya tree distributions for statistical modelling. The
Annals of Statistics, 22, 1161–1176.
[59] Lo, A Y (1984). On a class of Bayesian nonparametric estimates: I. Density estimates. Annals
of Statistics, 12, 351–357.
[60] Maksymiuk, A W, Jett, J R, Earle, J D, Su, J Q, Diegert, F A, Mailliard, J A, Kardinal, C G,
Krook,JE,Veeder,MH,Wiesenfeld,M,Tschetter,LK,andLevitt,R(1994).Sequencingand
schedule effects of cisplatin plus etoposide in small cell lung cancer results of a north central
cancer treatment group randomized clinical trial. Journal of Clinical Oncology, 12, 70–76.
[61] Mallick,BKandWalker,SG(2003).ABayesiansemiparametrictransformationmodelincor-
porating frailties. Journal of Statistical Planning and Inference, 112, 159–174.

614
T. E. Hanson and A. Jara
[62] Martinussen, T and Scheike, T H (2006). Dynamic Regression Models for Survival Data.
Springer-Verlag.
[63] Müller, P, Erkanli, A, and West, M (1996). Bayesian curve fitting using multivariate normal
mixtures. Biometrika, 83, 67–79.
[64] Müller, P and Quintana, F A (2004). Nonparametric Bayesian data analysis. Statistical Sci-
ence, 19, 95–110.
[65] Murphy, S A, Rossini, A J, and van der Vaart, A W (1997). Maximum likelihood estimation in
the proportional odds model. Journal of the American Statistical Association, 92, 968–976.
[66] Neal, R M (2000). Markov chain sampling methods for Dirichlet process mixture models.
Journal of Computational and Graphical Statistics, 9, 249–265.
[67] Orbe, J, Ferreira, E, and Núñez Antón, V (2002). Comparing proportional hazards and accel-
erated failure time models for survival analysis. Statistics in Medicine, 21, 3493–3510.
[68] Orbe, J and Núñez Antón, V (2006). Alternative approaches to study lifetime data under
different scenarios: from the PH to the modified semiparametric AFT model. Computational
Statistics and Data Analysis, 50, 1565–1582.
[69] Petrone, S (1999). Bayesian density estimation using Bernstein polynomials. The Canadian
Journal of Statistics, 27, 105–126.
[70] Petrone, S (1999). Random Bernstein polynomials. Scandinavian Journal of Statistics, 26,
373–393.
[71] Portnoy, S (2003). Censored regression quantiles. Journal of the American Statistical Associa-
tion, 98, 1001–1012.
[72] Reid, N (1994). A conversation with Sir David Cox. Statistical Science, 9, 439–455.
[73] Rosner, G L (2005). Bayesian monitoring of clinical trials with failure–time endpoints. Bio-
metrics, 61, 239–245.
[74] Ryan, T and Woodall, W (2005). The most-cited statistical papers. Journal of Applied Statis-
tics, 32, 461–474.
[75] Sayehmiri, K, Eshraghian, M R, Mohammad, K, Alimoghaddam, K, Foroushani, A R, Zer-
aati, H, Golestan, B, and Ghavamzadeh, A (2008). Prognostic factors of survival time after
heatopoietic stem cell transplant in acute lymphoblastic leukemia patients: Cox proportional
hazard versus accelerated failure time models. Journal of Experimental & Clinical Cancer
Research, 27, 74.
[76] Scharfstein, D O, Tsiatis, A A, and Gilbert, P B (1998). Efficient estimation in the general-
ized odds-rate class of regression models for right-censored time-to-event data. Lifetime Data
Analysis, 4, 355–391.
[77] Sethuraman, J (1994). A constructive definition of Dirichlet priors. Statistica Sinica, 4,
639–650.
[78] Sinha, D and Dey, D K (1997). Semiparametric Bayesian analysis of survival data. Journal of
the American Statistical Association, 92, 1195–1212.
[79] Sinha, D, McHenry, M B, Lipsitz, S R, and Ghosh, M (2009). Empirical Bayes estimation for
additive hazards regression models. Biometrika, 96, 545–558.
[80] Swindell, W R (2009). Accelerated failure time models provide a useful statistical framework
for aging research. Experimental Gerontology, 44, 190–200.
[81] Therneau,TMandGrambsch,PM(2000).ModelingSurvivalData:ExtendingtheCoxModel.
Springer-Verlag Inc.
[82] Walker,SGandMallick,BK(1997).Hierarchicalgeneralizedlinearmodelsandfrailtymodels
with Bayesian nonparametric mixing. Journal of the Royal Statistical Society, Series B: Method-
ological, 59, 845–860.
[83] Walker, S G and Mallick, B K (1999). A Bayesian semiparametric accelerated failure time
model. Biometrics, 55, 477–483.

Surviving Bayesian nonparametric regression models
615
[84] Wang, L and Dunson, D B (2011). Semiparametric Bayes’ proportional odds models for cur-
rent status data with underreporting. Biometrics, 67, 1111–1118.
[85] Wei, L J (1992). The accelerated failure time model: a useful alternative to the Cox regression
model in survival analysis. Statistics in Medicine, 11, 1871–1879.
[86] Yang, S (1999). Censored median regression using weighted empirical survival and hazard
functions. Journal of the American Statistical Association, 94, 137–145.
[87] Yang, S and Prentice, R L (1999). Semiparametric inference in the proportional odds regres-
sion model. Journal of the American Statistical Association, 94, 125–136.
[88] Yin, G and Ibrahim, J G (2005). A class of Bayesian shared gamma frailty models with multi-
variate failure time data. Biometrics, 61, 208–216.
[89] Ying, Z, Jung, S H, and Wei, L J (1995). Survival analysis with median regression models.
Journal of the American Statistical Association, 90, 178–184.
[90] Zellner, A (1983). Applications of Bayesian analysis in econometrics. The Statistician, 32,
23–34.
[91] Zhang, J, Peng, Y, and Zhao, O (2011). A new semiparametric estimation method for acceler-
ated hazard model. Biometrics, 67, 1352–1360.
[92] Zhang, M and Davidian, M (2008). “Smooth” semiparametric regression analysis for arbitrar-
ily censored time-to-event data. Biometrics, 64, 567–576.
[93] Zhao,L,Hanson,TE,andCarlin,BP(2009).MixturesofPolyatreesforflexiblespatialfrailty
survival modelling. Biometrika, 96, 263–276.
[94] Zhou, M and Li, G (2008). Empirical likelihood analysis of the Buckley-James estimator.
Journal of Multivariate Analysis, 99, 649–664.

This page intentionally left blank 

Part XII
Inverse Problems and Applications

This page intentionally left blank 

31
Inverse problems
colin fox, heikki haario
and j. andrés christen
31.1 Introduction
T
he aim of collecting data from a physical system is to gain meaningful information about the
system or phenomenon of interest. However, in many situations the quantities that we wish
to determine are different from the ones which we are able to measure, or have measured. Starting
with the data that we have measured, the problem of trying to reconstruct the quantities that we
really want is called an inverse problem. Loosely speaking, we say an inverse problem is where we
measure an effect and want to determine the cause.
Most science and statistics is data-driven in this way, though not always called an ‘inverse prob-
lem’. Here we want to discuss the features that are characteristic for the problems most typically
treated under the umbrella of inverse problems. The quintessential setting is where the measure-
ment process is a complex physical relationship, and inversion presents analytic difficulties.
In a mathematical setting, we represent the measurement process by a family of models parame-
terized by x, where all necessary physical parameters are contained inx, including nuisance parame-
ters.Inthelanguageofinverseproblems,simulationofthemodelforgivenxdefinestheforwardmap
A : x →d giving data d in the absence of errors. Determining and simulating the map A : x →d
is the forward problem, whereas inferring x from d is the inverse problem.
A mathematical model of the forward map A is usually based on some physical theory. For many
physical models the mathematical analysis of the forward map is well developed; indeed, many
areas of mathematics have been developed precisely to understand the structure of these mappings.
Computer evaluation of A(x) is typically the subject of computational science, and again, much
of numerical computation has been developed to simulate these problems. For example, solving
large-scale partial differential equations arising as models of physical systems drives a great deal of
computational science and engineering. Thus, distinctive features of inverse problems are that the
forward map is based on physics, mathematical analysis of the forward map is well developed, and
evaluation of the forward map uses advanced numerical computation.
Bayesian methods are well suited to incorporating these mathematical and computational mod-
els, and for accounting for errors or uncertainties in each of these steps. In this chapter we present
methodology and algorithms that are currently used for the Bayesian analysis of inverse problems.
A diverse range of researchers and practitioners work on inverse problems. There are probably
as many notions of what it means to solve an inverse problem as there are communities of people
working on inverse problems. Our notion of an inverse problem and the methods we use to solve
them has been influenced by the problems in front of us, and the shared experience of trying
to achieve solutions with quantified accuracy in industrial and scientific contexts. That has led

620
C. Fox, H. Haario and J. A. Christen
us to reformulate the inverse problem in the Bayesian (probabilistic) framework, and to employ
sample-based inference to evaluate summary posterior statistics. In doing so we are outliers in
the wider inverse-problems community in which deterministic ‘regularization’ methods (discussed
in Section 31.2) are overwhelmingly the most popular. Bayesian methods have the reputation of
providing the ‘gold standard’ amongst solutions, but also of being computationally impractical.
Perhaps for those reasons, and also because regularization has a Bayesian interpretation, it is com-
mon to see analyses of inverse problems under the title of ‘Bayesian’ that amount to nothing more
than regularization. While regularized solutions can be very useful, actually regularization is not a
Bayesianmethodandourviewisthatscientificaccuracyisservedbymakingalinguisticdistinction.
Arecentdevelopmentisthefocusonuncertaintyquantification(UQ)withincomputationalmod-
els,particularlyinthecomputationalscienceandengineeringcommunity.Weseethisdevelopment
as very heartening, as we are already seeing a renewed vigour in research into methods for tackling
the sizable computational tasks involved in Bayesian analysis of inverse problems.
Inverse problems are often high dimensional in the sense of many unknowns and many data.
When using low-level representations it is common to work with 103 or 104 unknown parameters,
which we call high dimensional. For example, in impedance tomography about 103 elements are
neededinanunstructuredfiniteelementmeshtoensurethatthecomputedforwardmapaccurately
simulates the physics. A global climate model contains upwards of 107 unknowns, which we call
veryhighdimensional.Mid-levelrepresentations,suchasrepresentationsofsurfaces,caneffectively
reduce the number of unknowns. In inverse problems, this reduction often leads to a more difficult
sampling problem, that we attribute to the geometry of state space becoming more complex. Of
order 10 unknowns is low dimensional for inverse problems, and usually arises when using para-
metric representations. Such problems can be very difficult when the system response is chaotic, as
occurs in weather and chemical systems.
The remainder of this chapter is organized as follows. This introductory section continues with
a list of representative examples of inverse problems followed by a discussion of the the key math-
ematical property of ill-posedness. We further discuss deterministic and regularization methods in
Section 31.2. Some history of Bayesian analysis, as viewed from physics, is presented in Section 31.3.
We present the framework for current methodology in Section 31.4, in the context of case studies.
We also present some of the recent advances in MCMC algorithms in Section 31.4. We conclude
with a glimpse of future directions in Section 31.5.
31.1.1 Examples of inverse problems
• Compton scattering The inelastic scattering of photons in matter can be used to probe the
wave function of electrons in matter. The forward problem is to predict the angle and energy
ofscatteredphotonsgiventheelectronstructure;theinverseproblemistodetermineelectron
structure from measurements of the scattering.
• Computeraxialtomography X-rays are partially transmitted through the body, with various
internal structures having different opacity to X-rays. CAT scans display a picture of that
variation in vivo. Non-invasive measurements are made of the total absorption along lines
through the body. Given measurement of such line integrals, how do we reconstruct the
absorption as a function of position in the body?
• Model fitting A common task in science and engineering is to ‘fit’ parameters θ of a model
d = f(x, θ) + ϵ
foragivensetofmeasuredpoints{xi, di}n
i=1.Theunknownvectorθ maybelowdimensional,
and the fit routinely done by suitable optimization routines. But even here, with a nonlinear

Inverse problems
621
model and possibly non-ideal data, only the rather recent advent of efficient Bayesian sam-
pling algorithms has enabled us to properly analyse the reliability of parameter values and
model predictions.
• Radio-astronomical imaging When using a multi-element interferometer as a radio tele-
scope, the measured data is not the distribution of radio sources in the sky (called the ‘sky
brightness’ function) but is approximately the Fourier transform of the sky brightness. It is
not possible to measure the entire Fourier transform, but only to sample this transform on a
collectionofirregularcurvesinFourierspace.Fromsuchdata,howisitpossibletoreconstruct
the desired distribution of sky brightness?
• Measuringbulkflow Many industrial processes transport mixed phase fluids in closed pipes.
Control of the process is often improved by real-time measurement of total flow of one or
more of the phases. Soft-field imaging, that uses diffusive or highly scattering fields, provides
a suitable non-invasive measurement that is sensitive to bulk properties. The image recovery
problem is ill-posed, while the determination of bulk flow corresponds to image analysis or
segmentation.
• Geophysics Inverse problems have always played an important role in geophysics as the
interior of the Earth is not directly observable yet the surface manifestation of waves that
propagate through its interior is measurable. Like many classes of inverse problems, ‘inverse
eigenvalue problems’ were first investigated in geophysics when, in 1959, the normal modes of
vibration of the Earth were first recorded and the modal frequencies and shapes were used to
learn about the structure of the Earth in the large.
From this short and incomplete list, it is apparent that inverse problems occur in a myriad of
settings.
31.1.2 Ill-posed and ill-conditioned
The problem of solving
A (x) = d
(31.1)
for x given d is called well-posed (in the sense of Hadamard) [42] if:
1. a solution exists for any data d,
2. the solution is unique, and
3. the inverse mapping d →x is continuous.
Conditions 1 and 2 are equivalent to saying that the operator A is onto and one-to-one. Condition
3 is a necessary but not sufficient condition for stability of the solution.
A problem that is not well-posed is said to be ill-posed. So an ill-posed problem is one where an
inverse does not exist because the data is outside the range of A, or the inverse is not unique because
more than one value of x is mapped to the same data d, or because an arbitrarily small change in the
data can cause an arbitrarily large change in the solution. Most correctly stated inverse problems
turn out to be ill-posed, including all of the examples listed above.
For a well-posed problem, relative error propagation from the data to the solution is controlled
by the condition number of A, denoted cond (A). If d is a variation of d and x the corresponding
variation of x, then

622
C. Fox, H. Haario and J. A. Christen
||x||
||x||
≤cond (A) ||d||
||d||
(31.2)
where (for linear forward problems) cond (A) = ||A||
&&&&A−1&&&& . When the 2-norm is used,
cond (A) is just the ratio of largest to smallest singular values of A. It is possible to find a variation
in data d for which eqn (31.2) is arbitrarily close to equality, so we usually think of eqn (31.2) with
equality since the worst case behaviour will dominate the inverse.
Smaller values of cond(A) give more stable problems. If cond(A) is not too large, the problem
in eqn (31.1) is said to be well-conditioned, otherwise the problem is said to be ill-conditioned. The
separation between well-conditioned and ill-conditioned problems is not very sharp and depends
on the computational environment. Strictly speaking, a problem that is ill-posed because it fails
condition3mustbeinfinitedimensional—otherwisetheratio||x||/||d||isbounded.However,
for ill-conditioned problems the ratio can become very large and we refer to such problems as
(discrete) ill-posed problems [22].
The classical example of an ill-posed problem is a Fredholm integral equation of the first kind
 b
a
k (t, s) x (s) ds = d (t) ,
a ≤t ≤b
(31.3)
with a square integrable, or Hilbert–Schmidt, kernel k. If the solution x is perturbed by x (s) =
ϵ sin(2πps), ϵ a constant, and d (t) is the corresponding perturbation of d (t), it follows from
the Riemann–Lebesgue lemma that d →0 as p →∞. Hence, the ratio ||x||/||d|| can
become arbitrarily large by choosing the frequency p large enough, showing that eqn (31.3) is an
ill-posed problem because it fails condition 3. In particular, this calculation shows that inverses of
Hilbert–Schmidt integral equations are extremely sensitive to high-frequency perturbations.
Hilbert–Schmidt operators are examples of compact operators [45] that commonly arise in
inverse problems. Since the inverse of a compact operator cannot be continuous (in standard
topologies), all such inverse problems are ill-posed. Many forward problems, especially those that
probe an object by the propagation of energy, are also smoothing operators. That is, the energy
fields throughout the domain have a higher order of differentiability than the imposed excitation.
It follows that the singular values of the forward map are summable to some power [3], again
ensuring that the inverse is unbounded and the inverse problem is ill-posed. These considerations
also explain why best-fit and maximum likelihood estimates are unreliable.
The properties of compact and smoothing both imply that the forward map is arbitrarily well
approximated by a finite-dimensional operator, even though the spaces for parameters and data
could be arbitrarily high dimensional. This means that, in the presence of uncertainty, the physical
measurement process conveys only a finite amount of information about the unknowns, even when
many more data are measured. Commonly the effective (local) rank can be of the order of 10 to 100.
Then the physically possible data lies on a manifold of much lower dimension than data space. This
explains the extreme sensitivity that inverse problems display to measurement error or model error,
since measurement error will easily put data out of the range of the forward map, while modelling
error will mean that the range of the model does not coincide with the physical process.
31.2 Deterministic approaches
The deterministic inverse problem is to invert the function A to obtain unknowns x as a function of
data d. Mathematical studies in inverse problems typically focus on the idealized inverse problem
in which all data is measured, and are concerned with invertability of the forward map and to what
degree the inverse problem is ill-posed.

Inverse problems
623
In the absence of an inverse, a solution that achieves a best fit to data can be computed as
ˆx0 = arg min
x C(x),
where
C (x) = ||d −Ax||2
is the data misfit functional, in this case the square of the norm of the residual. When A is invertible
the minimum misfit is C

ˆx0

= 0 for ˆx0 = A−1d.
However,choosing ˆx thatminimizesC (x)almostalwaysgivesapoorsolution.Inthepresenceof
noise, finding the (possibly non-unique) minimum of C leads to amplification of the noise because
of the ill-posedness. Instead, deterministic studies often regard the data as defining a feasible set of
solutions for which C (x) ≤Cm where Cm depends on the ‘level’ of the noise.
The primary difficulty in deterministic solutions to ill-posed inverse problems is due to small
singular values of the linearized forward map. Actually, the situation is a little worse in practice since
the forward map A never models the measurement process precisely. If we consider measurement
error e and model error A and the simple observation model d = (A + A)x + e then direct
inversion may be written symbolically as
ˆx = d
A = x + Ax + e
A
Using the bases of singular vectors makes this formula precise, and shows that the direct inverse
will be dominated by model error and measurement noise in the directions of singular vectors of A
corresponding to small singular values.
31.2.1 Regularization methods
The most common resolution in the deterministic setting is to formulate and apply a regular opera-
tor that approximates the singular inverse operator A−1. That is most commonly performed using
the method of regularization introduced by Tikhonov [42], via the variational statement
ˆxλ = arg min
x

C(x) + λ2R(x)

(31.4)
Here R(·) is a regularizing functional that represents our aversion to a particular solution, with larger
values being larger aversion, and λ is the regularizing parameter.
There are many ways of arriving at this variational form. One way is to think of minimizing
the regularizing functional R(x) over the set of solutions satisfying C(x) = Cm, for some Cm.
Introducing the Lagrange multiplier 1/λ2 gives the form in eqn (31.4).
The most common regularizing functional is Tikhonov regularization
R(x) = ||x||2
2
Sometimes, there is a preference for solutions which are close to some default solution x∞which
can be accommodated by choosing
R (x) = ||x −x∞||2
(31.5)
Moregenerally,itmaynotbethenormofx −x∞whichneedstobesmall,butsomelinearoperator
acting on this difference. Introducing the operator L for this purpose, we can set
R (x) = ||L (x −x∞)||2 = (x −x∞)T LTL (x −x∞)
(31.6)

624
C. Fox, H. Haario and J. A. Christen
In discrete problems the matrix L is of size p × n where p ≤n. Typically, L is a banded
matrix approximation to the

n −p

th derivative. For example, when data and unknowns are
one-dimensional functions discretized with interval h, approximations to the first and second
derivatives are given by the matrices
L1 = 1
h
⎛
⎜⎜⎜⎜⎝
−1 1
−1 1
... ...
−1 1
⎞
⎟⎟⎟⎟⎠
and
L2 = 1
h2
⎛
⎜⎜⎜⎜⎝
1 −2 1
1
−2 1
... ... ...
1
−2 1
⎞
⎟⎟⎟⎟⎠
Useofthesecondderivative,alsocalled Laplacian regularization,penalizescurvatureinthesolution
and is commonly used when making contour maps.
In other cases, it may be appropriate to minimize some combination of the derivatives such as
R (x) = α0 ||x −x∞||2 +
q

k=1
αk
&&&&Lk (x −x∞)
&&&&2
whereLk isamatrixwhichapproximatesthekthderivative,andαk arenon-negativeconstants.Such
a quantity is the square of a Sobolev norm that may also be written in the form of eqn (31.6).
Equation (31.4) provides a family of solutions parameterized by the regularization parameter λ.
Ifλisverylarge,thedatamisfittermC (x)isnegligiblecomparedto R (x)withlimλ→∞ˆxλ = x∞.
We effectively ignore the data (and any noise on the data) and minimize the solution seminorm by
choosing the default solution. On the other hand, if λ is small, the weighting placed on the solution
seminorm is small and the data misfit at the solution becomes more important. If λ is reduced to
zero, the solution reduces to the least squares case.
When A is linear and the regularizing functional has the quadratic form in eqn (31.6), a solution
to eqn (31.4) may readily be found by solving

ATA + λ2LTL

ˆxλ = λ2LTLx∞+ ATd
(31.7)
Computing the regularized solution is thus reduced to solving a (large) system of simultaneous
equations with a symmetric positive definite coefficient matrix, for which there are many effi-
cient algorithms. In stationary time-series problems sequential solutions may sometimes be imple-
mented by repeated action of a linear operator, or filter. Examples are the Wiener filter and the
Kalman filter.
The regularization functionals we have discussed are norms or seminorms on the space of solu-
tions, as is typically the data misfit functional. There are many other regularizing functionals in
common use, many designed to overcome the observation that regularization can over smooth
solutions, especially at transitions in images. For example,total variation regularization is often used
to encourage ‘blocky’ images [22]. Other norms are also used such as the 0-norm that penalizes the
number of non-zero components and hence prefers sparse solutions.
31.2.1.1 Truncated singular value decomposition
A linear operator A with rank r has the singular value decomposition (SVD)
A =
r

l=1
σlut
lvl
(31.8)

Inverse problems
625
forsomebasesofleftandrightsingularvectors{ul}and{vl},respectively,andsingularvaluesσl.The
truncatedSVDmethodisbasedontheobservationthatthecomponentsofthesolutionforsingular
vectors associated with the larger singular values of A are well determined by the data, whereas the
componentscorrespondingtosmallersingularvaluesarenot.Whenthesingularvaluesupto k ≤n
are deemed to be significant the truncated SVD solution is
x′
k =
k

l=1

uT
l d
σl

vl
(31.9)
The integer k takes the role of regularizing parameter.
31.2.1.2 Filter factors
For the case of linear forward maps, the filter factor representation displays the solutions to the
regularization problem for all values of λ in a convenient form. Here we analyse Tikhonov regular-
ization since the SVD in eqn (31.8) suffices. Equivalent results for more general L are available using
the generalized SVD.
Writing dl = uT
l d, ˆxl = vT
l ˆx, and x∞l = vT
l x∞, i.e. resolving each vector into the bases of sin-
gular vectors, the regularized solution can be written
ˆxl =
⎧
⎪⎨
⎪⎩
σ 2
l
λ2 + σ 2
l
 dl
σl

+
λ2
λ2 + σ 2
l
x∞l
for l = 1, 2, . . . , r,
x∞l
for l = r + 1, . . . , n.
(31.10)
The terms dl/σl and x∞l give the solution coefficient in the extreme cases of no regularization
(λ = 0) and no data (λ = ∞), respectively. The coefficients of these terms are the filter factors.
Notice how the filter factors sum to one, and the first filter factor smoothly decreases to zero as
the singular values gets smaller, or as λ increases. The value of λ sets the boundary between ‘small’
and ‘large’ singular values. In contrast, the filter factors for the truncated SVD method are equal
to unity for those singular values which are deemed to be non-negligible (l ≤k) and to zero for
those singular values which are negligible (l > k). That sharp cutoff typically leads to ringing36 in
solutions. Thus, Tikhonov regularization may be viewed as a type of windowing as employed in
signal processing.
31.2.1.3 Choosing the regularization parameter
We have seen that λ sets the balance between minimizing the residual norm ||d −Ax|| and mini-
mizingthesolutionseminorm||L(x −x∞)||.Thereisnosingleruleforselectingλthatworksinall
cases. Perhaps the most convenient graphical tool is the L-curve [22], that is a parametric plot of log
of the solution seminorm versus log of the data misfit. One of the simplest methods is the Morozov
discrepancy principle that sets λ so that the data misfit equals the measurement error ‘level’. Another
method is generalized cross validation (GCV) for selecting the parameter in ridge regression [15],
which is equivalent to regularized inversion.
36 More formally known as Gibbs’ phenomenon.

626
C. Fox, H. Haario and J. A. Christen
31.3 A subjective history of subjective probability
For the many physicists and astronomers who were applying Bayesian analysis to inverse problems
in the 1980s, the history of Bayesian methods is synonymous with the development of probabilistic
methodsinthephysicalsciences.ThisviewpointissupportedbymanykeycomponentsinBayesian
methodology being developed in response to problems arising in physics, including the Metropolis
algorithm. This section presents a history of Bayesian methods as imbibed by one of us (CF) while
studying inverse problems amongst Bayesian physicists.37,38
The name of Bayes was attached to Bayes’ theorem by Poincaré around 1886, in his own work on
probability. Bayes never wrote Bayes’ theorem in the modern form. He did, however, give a method
forfindinginverse probabilitywhilesolvinganunfinishedproblemstatedbyBernoulli.Thatmethod
was reasoned by lengthy arguments and appeared in a paper published in 1763, after Bayes’ death in
1760.
The first clear statement and use of Bayes’ theorem was given by Laplace in almost his first
published work in 1774. Laplace rediscovered Bayes’ principle in greater clarity and generality, and
then for the next 40 years applied it to scientific and civic problems. Laplace published in 1812
his two-volume treatise Théorie Analytique des Probabilités in which the analytical techniques for
Bayesian calculations were developed. The second volume contains Laplace’s definition of proba-
bility, Bayes’ theorem, remarks on moral and mathematical hope (or expectation), a discussion of
the method of least squares, Buffon’s needle problem, and inverse probability. Later editions also
contain supplements which consider applications in physics and astronomy. Laplace was mainly
concerned with overdetermined problems (many observations and few unknowns) and solely used
the principle of insufficient reason39 to determine prior probabilities.
Laplace’s calculus of probability was soon applied to explaining physical phenomena. The physi-
cist James Clerk Maxwell said in 1850 [32],
the true logic for this world is the calculus of Probabilities, which takes account of the
magnitude of the probability which is, or ought to be, in a reasonable man’s mind.
Even though Maxwell was only 19 years old at the time, he was already a formidable scientist and
theseprinciplesremainedinMaxwell’slaterwork.InhiskinetictheoryofgasesMaxwelldetermined
the distribution over molecular velocities, effectively determining a prior probability distribution
by ‘pure thought’ [27]. Experimental verification promoted the Maxwell distribution to the status
of physical law, founding the subject of statistical physics.
However,amongthoselookingtodevelopatheoryofuncertaineventstheconceptofprobability
as representing a state of knowledge was rejected, from about 1850, and replaced by the notion that
probability must refer to frequency in a random experiment. Largely that rejection took place when
it was realized that the notion of equiprobable, encapsulated in Laplace’s principle of insufficient
reason, gave results that depended on the parameterization chosen, and since Laplace had based
his notion of probable on the more fundamental notion of equiprobable the whole theory was
rejected. Bertrand constructed his paradox in 1889, as a transformation of Buffon’s needle problem,
to demonstrate the difficulties.
By the beginning of the twentieth century, application of Bayes’ theorem was severely criticized
with a growing tendency to avoid its application [9]. The new statistics40 was connected with
37 This term was apparently coined by Brian Ripley as a pejorative.
38 A more extensive early history can be found in the first section of [28].
39 Renamed the principle of indifference by Keynes [32].
40 Interestingly, Cramér referred to Bayesian methods as ‘classical’ in 1945.

Inverse problems
627
the theory of fiducial probabilities due to R. A. Fisher and the theory of confidence intervals due
to J. Neyman. These methods became so dominant that for half a century from 1930 a student of
statistics could easily not know that any other conception had existed. In that period, von Mises
said that Bertrand’s paradox did not even belong to the field of probability, apparently unaware of
theBoltzmann(includingMaxwell)distributionsinphysicsthatresolveproblemsofthesametype.
In the 1930s, Harold Jeffreys found himself unconvinced by Fisher’s arguments and rediscovered
Laplace’s rationale while working on ‘extracting signals from noise’ in geophysics. In 1939 he pub-
lishedhisTheoryofProbabilityinwhichheextendedBayesianinference,explainingthetheorymuch
more clearly than did Laplace. In the 1948 edition Jeffreys gave a much more general invariance
theory for determining ignorance priors, which remains of importance today in the form of reference
priors.
For many physicists the question of whether one can or cannot use Bayes’ theorem to quantify
uncertainty was answered by the physicist Richard T. Cox in 1946 and 1961 [7]. Instead of asking
whether or not Laplace gave us the right ‘calculus of inductive reasoning’, he raised the question
of what such a calculus must look like. Supposing that degrees of plausibility are to be represented
by real numbers, he found the functional conditions that such a calculus be consistent and showed
that the general solution uniquely determines the product and sum rules for probability to within
a change of variables. An immediate consequence is Bayes’ theorem. This does not answer the
question of how to assign probabilities, but it does determine how they must be manipulated once
assigned.
The reappearance of Bayesian methods in the physical sciences from about 1970 can in many
cases be traced to the physicist Edwin T. Jaynes who, from the 1960s to 1980s, championed Bayesian
methods as an inductive extension of deductive logic. While looking to unify statistical physics
and Shannon’s new theory of communication, he observed that methods that were experimen-
tally verified in statistical physics appeared to be derided in statistics, and set about formalizing
the basis of those methods. This led Jaynes to formulate the maximum entropy principle for prior
distributions [28], as an extension of Jeffreys’ uninformative prior. Jaynes also adapted the group
invariancemethods,thatarestandardinphysicsforderivingthemathematicalformofphysicallaws,
to the method of transformation groups for determining prior probabilities. Notably, this resolved
Bertrand’s ‘paradox’, showing that it is actually well posed [27]. Jaynes had rephrased Laplace’s
indifference between events to an indifference between problems. An anonymous poet celebrated this
contribution in the lines:
So, are you faced with problems you can barely understand?
Do you have to make decisions, though the facts are not in hand?
Perhaps you’d like to win a game you don’t know how to play.
Just apply your lack of knowledge in a systematic way.
Bythe1980s,anumberofgroupsinphysicsandastronomysawBayesiananalysisasthecorrectroute
to resolving inverse problems in the presence of ‘incomplete and noisy data’ [18]. The advanced
state of computational optimization allowed Bayesian MAP estimates to be calculated in large-s-
cale problems, with some notoriety being achieved by the maximum entropy method (MEM). The
practical properties and limitations of MEM were pointed out by a number of statisticians, most
influentially in [12]. In the same period, inverse problems became a ‘topic’ in statistics, though
analysis was limited to regularization estimators [38], or Bayesian analyses that used an artificial
likelihood conditioned on a regularized solution.
The renewed appreciation of MCMC following the publication of Gelfand and Smith in 1990
influenced those applying Bayesian methods to inverseproblems, with the first substantive analyses
of inverse problems using MCMC appearing in 1997 [14, 37]. The analysis in [34] of a realistic
problem in geophysics also appeared in that year using a Metropolis algorithm, apparently (though

628
C. Fox, H. Haario and J. A. Christen
somewhat implausibly) unaware of Gelfand and Smith, or Hastings’ improvement. That work fol-
lowed the direction set by Albert Tarantola in formulating inverse problems in a Bayesian frame-
work [41]. The title Inverse Problems = Quest for Information, alone, of the 1982 paper by Tarantola
and Valette had motivated many in the inverse problems community to explore Bayesian methods.
For Bayesian statisticians the early impact of MCMC was summed up by Peter Clifford when he
wrote in 1993,
from now on we can compare our data with the model we actually want to use rather
than with a model which has some mathematical convenient form.
The situation for Bayesian physicists was somewhat different since they were already using phys-
ically realistic models (at least for the forward map) but lacked the computational tools for
unhindered exploration of the posterior distribution. MCMC provided that tool, though the com-
putational challenges were formidable. Exposure to spatial statistics brought the mid-level and
high-level representations [26], that don’t fit into a regularization framework, with a clear route
for inference having been charted by Grenander and Miller [17].
31.4 Current Bayesian methodology
The methods of regularization and truncation in Section 31.2 provide valid algorithms to tame
ill-posed computational problems. They also come close to the Bayesian approach in the sense
that a regularization can be interpreted as equivalent to setting prior knowledge—or guess—to
some characteristics of the solution. The estimate then will be a compromise produced by the
regularization and the measurement data. But a crucial component of the Bayesian approach is still
missing: how to produce a proper analysis of the certainty, or rather uncertainty, of the estimates?
How much, indeed, can we trust the predictions given by our models, often simulating complex
physical systems? Here, we believe, is the main contribution that present day Bayesian Monte Carlo
algorithms are able to provide.
In this section we discuss our computational approaches to the statistical aspects of inverse
problems, as well as the spirit in which we see ourselves as ‘Bayesians’. The discussion is largely
influenced by the applied projects from our own experience, and so inevitably is subjective again.
All available data contains measurement errors, so the estimated unknowns are more or less
uncertain. A natural question then arises: if measurement noise corrupting the data follows some
statistics, what is the distribution of the possible solutions after the estimation procedure? Bayesian
thinking explicitly allows for the unknown vector x to be interpreted as a random variable with a
distribution of its own. In addition, the approach typically emphasizes the use of prior knowledge
in the estimation process, even subjective. As we all know, and we alluded to in our ‘history’, these
questions have been the focus of a longstanding dispute between the two opposing views:
• Frequentists argue that analysis should be driven by the data as much as possible, and that
attaching a distribution to a parameter based on one’s subjective belief should not be a part of
valid statistical analysis. Moreover, parameters indeed are constants without distributions of
their own.
• Bayesians argue that treating solutions as random variables is actually more realistic and, by
considering different choices for distributions, Bayesian analysis is perfectly valid. Moreover,
scientific research most often contains strong hidden prior information, such as the choice of
model used to explain the phenomena under study.

Inverse problems
629
A practically oriented researcher might find the dispute somewhat academic. In a real modelling
project, are we really so concerned about the ‘true’ interpretation of parameters? In any case we
all certainly should be interested in the reliability of model predictions. Naturally, the estimates for
unknowns should be physically plausible. We have experience in geophysics applications where it
is necessary that estimates show a sub-surface structure that is believable to a geologist, before the
predictions will be trusted.
But as the solution is estimated from noisy data, some uncertainty always remains, whether we
interpret the ‘truth’ as fixed or random. So, it is essential, in any case, to realize that estimation
problems do not have a unique solution. A numerical optimizer may find a true global minimum for
agivenleastsquaresfunctionwithfixeddatavalues.However,amultitudeofdifferentsolutionsmay
fit the data ‘equally well’, when we take into account the noise in the measurements. The practical
essence of the Bayesian approach, in our experience, is to to find all those possible solutions, as
well as the respective model predictions, as probability distributions. An added value is also the
interpretation of those probabilities in a clear formal perspective (see e.g. [25]), that permit not
only useful engineering solutions but valid ‘scientific’ answers as well.
For many of us, the Bayesian approach is almost synonymous with the use of MCMC methods.
The advantages of using MCMC for solving inverse problems are various: full characterization of
(non-Gaussian) posterior distributions is possible. We have full freedom in implementing prior
information.Evenmodellingerrorscanbetakenintoaccountinaflexibleway.Moreover,weareless
likely to get trapped in local minimums than when employing optimization methods to get MAP
estimates.
31.4.1 Mathematical formulation
The framework for Bayesian analysis of inverse problems is straightforward in concept; one formu-
lates the likelihood function by modelling the measurement process and errors, specifies a prior
distribution over unknowns, and then performs posterior inference (commonly by MCMC).
A general stochastic model for the measurement process is
d = G (x, v)
(31.11)
wherexrepresentsthedeterministicunknowns,typicallyphysicalconstants,andvisarandomvari-
able accounting for variability between ‘identical’ experiments. In practice the separation between
‘deterministic’ and ‘random’ is a modelling choice, since all effects may be modelled as random. We
findthatbetterresultsaregivenbymodellingasmanydeterministicprocessesaspossible.However,
modelling practicalities often demand that some residual deterministic processes are treated as
random.
In the state space approach, eqn (31.11) is the observation equation in a problem that does not vary
withtime.Thetime-varyingproblem[29,44]iscommonlytreatedasinferenceforahiddenMarkov
model [5], for which sequential Monte Carlo methods are applicable.
In the simplest formulation the stochastic part is attributed to measurement error that is additive
and independent of x so that
G (x, v) = A(x) + v
where v ∼πn (·) comes from the noise distribution. Then, when the forward map is treated as
certain, the distribution over data conditioned on x is is given by
π(d|x) = πn (d −A(x))
(31.12)

630
C. Fox, H. Haario and J. A. Christen
The likelihood function for given data d is the same function considered as a function of the
unknown variables x. Hence, formulating the likelihood function requires modelling the forward
map as well as the distribution over measurement errors. Evaluation of the likelihood function
requires simulation of the forward map, and hence is typically computationally expensive.
Given measurements d, the focus for inference, at least in parameter estimation, is the posterior
distribution given by Bayes’ theorem
π(x|d) = π(d|x)π(x)
π(d)
∝π(d|x)π(x)
(31.13)
where π(x) is the prior distribution and π(d) is often called the evidence. Note that we take the
usual (and sometimes dangerous) liberty with notation where each density function is implicitly
distinguished by the type of argument it takes.
31.4.2 Models for model error
All models are wrong, and particularly so in inverse problems. We are not aware of any inverse
problemwherethemeasurementerrorisgreaterthanthemodeluncertainty.Perhapsthisisbecause
measurements may be made more accurately whereas more accurate physical modelling requires
conceptual advances.
It is useful to distinguish between the physical process, the mathematical model and the compu-
tational model, that we denote Ap, Am and Ac, respectively. Kennedy and O’Hagan [31] introduced
a model for inadequacy in computer models, writing
Ap (x) = Ac (x) + D (x)
where the model inadequacy D(x) was modelled nonparametrically as a Gaussian process (GP), as
was Ac.41 This approach would be familiar in machine learning. While a nonparametric model for
model inadequacy seems very sensible, the use of Gaussian process models is somewhat unsatisfac-
toryforinverseproblems.Forexample,formulatingaGPisprohibitiveinhighdimensions.Instead,
modelling D by a Gaussian distribution is feasible, as we will see. Also, building a GP surrogate to
the forward map is problematic since the complex input/output structure is effectively only cap-
tured in the mean process, but that amounts to tabulating input/output pairs, which is prohibitive.
More successful is using a reduced order (computational) model (ROM) A∗c of the computational
forward map Ac that approximately captures that structure with a cheap computation.
The use of ROMs is almost mandatory in large-scale inverse problems, to reduce computa-
tional cost of the forward map. There are many schemes for building ROMs, such as local lin-
earization, coarse numerical discretization, or low-order expansions. A systematic approach can be
found in [1].
A ROM necessarily introduces a model error that we can analyse as
Ac (x) = A∗
c (x) + B(x)
(31.14)
We call B(x) = Ac(x) −A∗c(x) the model reduction error.
The approximation error model (AEM) of Kaipio and Somersalo [30] has proved effective in
mitigating the effects of model reduction error. They modelled the model reduction error as being
41 A taxonomy for the arguments of these functions, that fits well in the inverse problem context, was given
by Campbell and McKay in the discussion of [31].

Inverse problems
631
independent of the model parameters and normally distributed. Then the observation process is
reduced to
d = A∗
c(x) + B + v
(31.15)
where B ∼N(μB, B), when we assume that the accurate computational model is correct, i.e.
Ap = Ac, as in [30]. However, it is interesting to note that if the model inadequacy D is also taken
to be Gaussian, then eqn (31.15) still holds without the assumption Ap = Ac, with the distribution
over B also accounting for bias and uncertainty in the mathematical model.
31.4.3 Prior information
Mostoften,wedonot reallywanttospecifyanon-trivialpriordistributionforthesolution.Wemay
just know that the solution components must have some bounded and positive values, leading to
uninformative or flat priors. Naturally, one must remember that ‘flatness’ depends on the parame-
terization of the model. For instance, a flat prior for the conductivity σ is non-flat for the resistivity
1/σ, while a model could be equally written in terms of either parameterization.42
A practical guide for parameterization is simply to try to write a model that is easily identified by
available data. For a given parameterization then, we may just set a box of ‘simple bounds’, just lower
and upper bounds, to constrain the solutions. The analysis is now fully driven by data, supposing
that the posterior distribution of the parameters is well inside the given bounds.
If, on the other hand, the posterior does not stay inside any reasonable bounds, we must observe
that the available data is not sufficient to identify the parameters. This is an important conclusion, and
not too unusual! We can then consider a few options:
• Design of Experiments. If non-identifiability of parameters is due to lack of data, an obvi-
ous remedy is to design new experiments to gain more informative measurements. Several
classical linearization-based methods exist. Bayesian analysis and MCMC sampling provide
a comprehensive way to design simulation based experiments for, e.g. situations where the
classical criteria can not be implemented due to a singular information matrix [35].
• Model reductions. Often, however, the non-identifiability is an inherent feature of the forward
map and no practically measurable data (or just reparameterization) is able to correct the
situation. This occurs when parts of a physics-based model are unobservable due to, e.g.
different scales in time or space: fast equilibria of certain parts of chemical kinetics, or negli-
gible diffusion due to small catalyst particles are typical examples. An alternative option for
fixing priors for unidentified parameters is then to simplify the model, and thus reduce the
list of parameters to be identified. Again, MCMC sampling gives an algorithmic tool here.
Insteadof‘politicaldecisions’onhowtoreducethemodel,wemaycreateparameterposterior
distributions by MCMC to see which model parameters remain unidentified, and reduce the
model accordingly. The reduction process itself may require special tools, such as the singular
perturbation methods (see [19] for an example).
Typically, Bayes’ theorem is seen as the way of putting together a fixed prior, data, and model. We
may observe that the approaches suggested above rather employ Bayesian sampling techniques as
flexible, algorithmic tools for model development, that may guide all the relevant steps of modelling:
not only the analysis of model parameter identifiability, but also the design of measurements as well
as testing different versions of the model for the phenomenon under study. Only if such measures
42 The Jeffreys’ prior for a scale parameter works here, that is uniform in log(σ).

632
C. Fox, H. Haario and J. A. Christen
are not available, one should carefully seek true prior information to be included as the prior
distribution in the estimation process.
Unfortunately, sometimes one is forced to consider prior information in detail. In problems
with more than a few unknowns, such as inverse problems, simply setting ‘flat’ priors over each
coordinate direction can result in the prior being highly ‘informative’ for posterior statistics of
interest. We first saw this effect pointed out in the context of estimating occupancy time, or span, of
archaeological sites from radiocarbon dating of artifacts [36], where a uniform prior over the date
of each artifact leads to a strong bias towards larger estimates of span, to the point where a short
span is effectively ruled out. We have had to correct for this effect when using electrical capacitance
tomography (ECT) to make quantitatively accurate measures of the cross-sectional area of water
inclusions in oil pipe lines [44]. Interestingly, in the presence of uncertainties, correcting the prior
to give quantitatively accurate estimates of area produces bias in estimates of the boundary length,
and reminds us that information is a relative concept; uninformative with respect to one question is
typically informative with respect to another.
31.4.4 Exploration by sampling
The Metropolis–Hastings (MH) algorithm is the basis of nearly all sampling algorithms that we
currently use. This algorithm was originally developed for applications in statistical physics, and
was later generalized to allow general proposal distributions [23], and then allowing transitions in
state space with differing dimension [16]. Even though we do not always use variable-dimension
models, we prefer this Metropolis–Hastings–Green (MHG) ‘reversible jump’ formulation of MH
as it greatly simplifies calculation of acceptance probabilities for the subspace moves that are fre-
quently employed in inverse problems. One step of MHG dynamics can be written as:
Algorithm 1 (MHG)
Let the chain be in state xn = x, then xn+1 is determined in the following way:
1. Proposeanewcandidatestatex′ fromxdependingonrandomnumbersγ withdensityq(γ ).
2. With probability
α(x, x′) = min

1, π(x′|d)q(γ ′)
π(x|d)q(γ )
&&&&
∂(x′, γ ′)
∂(x, γ )
&&&&

(31.16)
accept the proposed state by setting xn+1 = x′. Otherwise reject by setting xn+1 = x.
The last factor in eqn (31.16) denotes the magnitude of the Jacobian determinant of the trans-
formation from (x, γ ) to (x′, γ ′), as implemented in computer code for the proposal. A few
details remain to be specified such as the choice of starting state, and the details of the proposal
step.
TheonlychoiceonehaswithintheMHGalgorithm,ishowtoproposeanewstatex′ whenatstate
x. The popular choice of Gibbs sampling is the special case where x′ is drawn from a (block) condi-
tional distribution, giving α(x, x′) = 1. The choice of the proposal density is largely arbitrary, with
convergence guaranteed when the resulting chain is irreducible and aperiodic. However, the choice
ofproposaldistributioncriticallyaffectsefficiencyoftheresultingsampler.ThemostcommonMH
variants employ random walk proposals that set x′ = x + γ where γ is a random variable with den-
sity q(·), usually centred about zero. In high-dimensional problems, global proposals that attempt
to change all components of the state usually have vanishingly small acceptance probability, so are

Inverse problems
633
not used. Since ill-posedness results in extremely high correlations, single-component proposals
result in slow mixing. Hence, a multi-component update is usually required, that is problem
specific.
In problems where the posterior distribution is essentially unimodal, computational cost can be
minimized by starting at the MAP estimate computed by computational optimization. Indeed, the
optimization step can provide useful input to the MCMC, such as a low rank approximation to
the Hessian of the log of the target density when using BFGS optimization. This has been used to
seed the proposal covariance in the adaptive Metropolis (AM) algorithm. For multi-modal target
distributions,orwhendebuggingcode,itisoftennecessarytostartfromarandomizedstartingstate
drawn from an ‘over-dispersed’ distribution, though this can be very computationally expensive as
the MCMC may require many iterations to find the support of the posterior distribution.
31.4.4.1 Algorithm performance
Since many steps of the MHG algorithm are typically required for convergence, and each step
requires a computationally expensive evaluation of the forward map, it is important to evaluate and
tune on the computational efficiency of a sampling algorithm.
A common measure of statistical efficiency is the integrated auto-correlation time (IACT) that
measures the number of samples from the chain that have the same variance reducing power as
one independent sample. It is desirable to have a small number of steps per IACT, so that estimates
evaluated over the chain converge more quickly for a given number of steps.
However, statistical efficiency is not a sufficient measure of algorithmic performance in inverse
problems where the CPU time taken per step can vary, such as when using a ROM. For example,
in the delayed acceptance algorithms we consider later, the computational cost of a rejection step is
much smaller than the computational cost of an acceptance. Hence, it is also necessary to measure
the average CPU time per step.
We measure computational efficiency as the product of these two terms, to give the CPU time per
IACT. This then measures the CPU time (sometimes called the wall-clock time) required to reduce
the variance in estimates by the same amount that one independent sample would achieve. Clearly,
small CPU time per IACT is desirable.
Unfortunately some papers showing new sampling algorithms only report statistical efficiency.
We know of several such papers where an ‘improved’ algorithm is correctly reported as increasing
statistical efficiency, but actually decreases computational efficiency, and hence would take longer
to produce estimates with a given accuracy compared with the unimproved algorithm.
31.4.5 Atmospheric remote sensing and adaptive Metropolis
As an example of an ill-posed inverse problem, we discuss in some detail the recovery of ozone
profiles by satellite measurements. This case study also provides an example on how practical
challenges from real-life projects may give us impetus to develop new computational methods.
Remote sensing techniques are today routinely used for atmospheric research. The data process-
ing of these instruments typically involve solving nonlinear inverse problems. GOMOS (Global
Ozone Monitoring by Occultation on Stars) is one of the 10 instruments on board the European
Space Agency’s Envisat satellite which is targeted on studying the Earth’s environment. The Envisat
satellite was launched on the 1st of March in 2002 to a polar, sun-synchronous orbit at about 800
km above the Earth. It is still fully operational now in 2012. The main objective of GOMOS is to
measure the atmospheric composition and especially the ozone concentration in the stratosphere
and mesosphere with high vertical resolution. The GOMOS instrument was the first operational
instrument that uses the stellar occultation technique to study the Earth’s atmosphere. The mea-
surement principle, demonstrated in Figure 31.1, is elegant: the stellar spectrum seen through the
atmosphere is compared with the reference spectrum measured above the atmosphere. Due to

634
C. Fox, H. Haario and J. A. Christen
z
z
z
Earth radius
300
400
500
600
0
1
2
3
4
x 10
4
300
400
500
600
0
1
2
3
4
x 10
4
=>
   Transmission:
300
400
500
600
0 
 1 
   Signals:
satellite orbit
Figure 31.1 GOMOS measurement principle. The horizontal transmission of the atmosphere at
tangent altitude z is obtained by dividing the attenuated stellar spectrum with the reference spectrum
measured above the atmosphere.
the absorption and scattering in the atmosphere the light measured through the atmosphere is
attenuated and the attenuation is proportional to the amount of constituents in the atmosphere.
The measurements are repeated at different tangential altitudes to obtain vertical profiles of the
concentrations of different atmospheric constituents. The advantages of the GOMOS instrument
compared to other instruments measuring ozone are the fairly good global coverage, with 300–400
occultations daily around the Earth combined with the excellent vertical resolution (sampling
resolution0.3–1.7km).ThealtituderangewhichcanbecoveredbyGOMOSislarge:15–100kmand
the brightest stars can be followed even down to 5 km. Each occultation consists of about 70–100
spectra measured at different tangential altitudes and each UV-vis spectra includes measurements
at 1416 different wavelengths. Because of the multitude of stars it is important that the optimal set
of stars is selected for each orbit. This optimization was included in the GOMOS mission planning.
IntheGOMOSdataprocessingconstituentdensitiesareretrievedfromstellarspectraattenuated
in the atmosphere. The GOMOS inverse problem can be considered as an exterior problem in
tomography, but in practice it is solved locally considering only data collected from one occultation
at a time. This inverse problem is as follows. By dividing the stellar spectrum measured through
the atmosphere with the reference spectrum measured above the atmosphere we obtain a so-called
transmission spectrum. The transmission at wavelength λ, measured along the ray path ℓ, includes
a term Tabs
λ,ℓdue to absorption and scattering by atmospheric constituents and a term Tref
λ,ℓdue to
refractive attenuation and scintillations, that is, Tλ,ℓ= Tabs
λ,ℓTref
λ,ℓ. The dependence of the transmis-
sion on the constituent densities along the line of sight ℓis given by Beer’s law:
Tabs
λ,ℓ= e
8
−

ℓ

gas αgas
λ (z(s))ρgas(z(s))ds
9
where ρgas(z) gives the constituent density at altitude z and α denotes the cross-sections. Each
atmospheric constituent has typical wavelength ranges where the constituent is active either by
absorbing, scattering or emitting light. The cross-sections reflect this behaviour and their values
are considered to be known from laboratory measurements. In the equation above the sum is over

Inverse problems
635
different gases and the integral is taken over the ray path. The problem is ill-posed in the sense
that continuous profile is retrieved from a discrete set of measurements. Therefore some additional
regularization or prior information is required to make the problem well-posed and solvable. In
practice this is done by discretizing the atmosphere into layers and assuming some smoothness
prior, or even just constant or linearly varying density inside layers.
The measurements are modelled by
yλ,ℓ= Tabs
λ,ℓTref
λ,ℓ+ ϵλ,ℓ,
ϵλ,ℓ, ∼N(0, σ 2
λ,ℓ), λ = λ1, . . . , λ#, ℓ= ℓ1, . . . , ℓM. The likelihood function for the constituent
profiles then reads as
P(y|ρ(z)) ∝e−1
2 (T−y)C−1(T−y)
with C = diag(σ 2
λ,ℓ) and y = (yλ,ℓ), T = (Tλ,ℓ). The true statistics is Poisson, but can be
safely treated as Gaussian. The inverse problem is to estimate the constituent profiles ρ(z) =
(ρgas(z)), gas = 1, . . . , ngas.
In the operational data processing of GOMOS the problem is divided into two parts. The sep-
aration is possible if the measurement noise is independent between successive altitudes and the
temperature-dependent cross-sections can be sufficiently well approximated with ’representative’
cross-sections (e.g. cross-sections at the temperature of the tangent point of the ray path). In the
operational algorithm these simplifications are assumed and the problem is solved in two steps.
The spectral inversion is given by
Tabs
λ,ℓ= exp
⎡
⎣−

gas
αgas
λ,ℓNgas
ℓ
⎤
⎦, λ = λ1, . . . , λ#,
which is solved for the horizontally integrated line-of-sight densities Ngas
ℓ. The vertical inversion
Ngas
ℓ
=

ℓ
ρgas(z(s))ds, ℓ= ℓ1, . . . , ℓM
is solved for local constituent densities ρgas using the line-of-sight densities from the previous
step as the data. Naturally, it is also possible to solve the problem directly in one step by inverting
the local densities from the transmission data. This approach is here referred to as the one-step
inversion.
The first step of the operational GOMOS data processing, the spectral inversion problem, is
nonlinear, with all the usual advantages available if solved using the MCMC technique. At each
line-of-sight, the dimension of the problem is small, only some five parameters (horizontally inte-
grated line-of-sight densities of different constituents) to be retrieved. However, the estimation
is done repeatedly at each altitude, about 70–100 times for each occultation. The natural way of
implementing the MCMC technique is to use random walk MH algorithm. But here we meet
the difficulty of tuning the proposal distribution to obtain efficient sampling. The special feature
in the GOMOS data processing is that the posterior distributions of the spectral inversion vary
strongly. They depend on the tangential altitude and also on the star used for the occultation.
The line-of-sight densities vary typically several decades between 15 to 100 km for ozone vertical
profile measured by GOMOS. When the star is dim (and hence the signal-to-noise ratio is low) the

636
C. Fox, H. Haario and J. A. Christen
posteriordistributionsbecomemanytimeswidercomparedwiththeonesobtainedforabrightstar.
Insuchasetupitisimpossibletofindanyfixedproposaldistributionthatwouldworkatallaltitudes
and for all stars. Therefore, the proposal distributions need to be optimized for each altitude and
for each occultation separately. However, any offline manual tuning of the proposal distributions is
also impossible to realize because of the huge number of datasets. Automatic algorithms for tuning
the proposal distribution were therefore needed.
To overcome these problems of GOMOS spectral inversion problems the adaptive MCMC
algorithms were originally developed, AM for the two-step algorithm and adaptive MwG (SCAM)
for the one-step inversion. The advantage of these algorithms is that they make the implementation
of the MCMC easy; the adaptation can be used in a fully automatic way without increasing the
computational time dramatically.
TheadaptationonlyrequiresasmallchangeintheMHGalgorithm.ThebasicadaptiveMetropo-
lis(AM)[21]versionusesaGaussian(andthussymmetric)proposalq,whosecovarianceisupdated
by the empirical covariance of the chain:
Algorithm 2 (AM)
At step n, with state xn = x and covariance Cn, determine xn+1 and Cn+1 in the following way:
1. Generate a proposal x′ ∼N(x, Cn).
2. Accept with probability
α(x, x′) = min
1
1, π(x′|d)
π(x|d)
2
setting xn+1 = x′. Otherwise reject by setting xn+1 = x.
3. Update the proposal covariance by Cn+1 = sd Cov(x1, x2, ..., xn+1).
The covariance here is scaled down with the parameter sd with 1/d dependence on the dimension
d. The adaptation naturally can be started only when there are enough different accepted samples
in the chain to compute the covariance. This may be a drawback if the initial proposal is too large;
see below the discussion on the DRAM version for a remedy. Also, it may be better, especially in
higher-dimensional problems, to keep adapting at some fixed intervals rather than at every step.
Note also that the ergodicity does not require of use the whole chain but an increasing part of it, e.g.
the last half.
31.4.6 Cheap MCMC tricks
We now present several other advances to the MHG algorithm that we have developed in
response to particular inverse problems. These represent the state-of-the-art for sampling in inverse
problems.
31.4.6.1 Delayed rejection AM
The delayed rejection (DR) method [16] uses several proposals: when a proposed candidate point
in a Metropolis–Hastings chain is rejected, a second stage move is proposed from another proposal
distribution. For example, one can use downscaled versions of a ‘basic’ proposal, with the motive to
get acceptance after rejection. Delayed rejection can be combined with AM, as done in [20]. This
method (DRAM) has been shown to be efficient in many applications, see e.g. [43]. It is helpful
to get the sampler moving, especially in the beginning of the MCMC run, since AM can easily

Inverse problems
637
correct a proposal that is too small, but needs accepted points for the adaptation to take place. The
DR step can provide such points. In a computationally demanding situation, such as the parameter
tuning of a climate model, no standard ways (i.e. preliminary parameter fitting together with the
Jacobian-based approximation for the covariance) of getting an initial proposal may be available. In
addition, only short chains may be simulated. In such a case, DRAM typically turned out to be a
reliable approach to get a reasonably well mixed chain created.
The adaptation in DRAM could be performed in various ways. We have found it enough to keep
it simple: only have two proposals, compute the empirical covariance from the chains just as in AM,
and keep an identical but down-scaled version of it for the second stage proposal.
31.4.6.2 Parallel adaptive chains
Parallelizing the adaptive MCMC algorithms has been studied relatively little. In [4] a parallel
MCMCimplementationinthecontextofregenerationwasstudied.Combiningparallelcomputing
and MCMC is inherently difficult, since MCMC is serial by nature. Running many parallel chains
independent of each other may not be satisfactory, since it takes time for each single chain to
find the mode(s) of the target and for the proposal to adapt. The question whether it is better
to run multiple (non-adaptive) short chains or a single long chain has been considered in many
studies. In the present case with extremely time-consuming calculations, this question is not rele-
vant, since running a single long chain is simply not possible. Instead, several short chains can be
run, and parallel communicating adaptive chains can speed up the mixing of the MCMC chains
considerably. For this purpose, we employ a parallel chain version of the AM algorithm. To par-
allelize AM, we use a simple mechanism called inter-chain adaptation, recently introduced in [8].
In inter-chain adaptation one uses the samples generated by all parallel chains to perform proposal
adaptation and the resulting proposal is used for all the chains. This naturally means that one has
more points for adaptation and the convergence of every individual MCMC chain is expected to
speed up.
The parallel chain approach is rather straightforward to implement. The only difference to run-
ning independent parallel AM samplers is that each sampler uses and updates the same joint pro-
posal covariance. Covariance updating can be performed at any given update interval, for instance
using the rank-1 covariance update formulas, see [21]. Note that also more advanced adaptation
schemes, such as the DRAM and SCAM methods discussed above, can easily be combined with
the inter-chain adaptation.
31.4.6.3 Early rejection
CPU can also be saved at no cost just by looking closer at the steps of calculations. Suppose the
current state in the MH algorithm is xi. Recall that MH proceeds by proposing a candidate value
x′ and accepting the proposed value with probability α = min(1, π(x′|d)/π(x)|d). In practice,
one first evaluates π(x′|d), then simulates a uniform random number u ∼U(0, 1) and accepts x′ if
u < α. Thus, a point will be rejected if u > π(x′|d)/π(x|d).
In numerous applications the likelihood can be divided into n independent parts π(di|x), i =
1, 2, . . . , n. Moreover, the partial unnormalized posterior densities ˜πk(x|d) = π(x) 	k
i=1 π(di|x)
may be monotonically decreasing with respect to the index k, k = 1, 2, . . . , n. This is the situation,
for example, if the likelihood has an exponential form π(d|x) ∝exp(−l(d|x)), with l(di|x) ≥0,
as in the Gaussian case. In these situations, we can reject as soon as ˜πk(x′|d)/π(x|d) < u for
some value of k. Thus, we can speed up the sampling simply by switching the order of the cal-
culations: generate the random number u first, evaluate the likelihood part by part, and check
after each evaluation, if the proposed value will end up being rejected. Naturally, before evaluat-
ing any likelihood terms, we can check if the proposed point will be rejected based on the prior
only.

638
C. Fox, H. Haario and J. A. Christen
The amount of calculation saved by ER depends on the problem (amount of data, properties of
themodel,shapeoftheposteriordistribution)andonthetuningoftheproposal.Incaseswherethe
topology of the posterior distribution is complicated (strongly nonlinear, thin ‘bananas’, or multi-
modal),theMHsampler,evenifproperlytuned,resultsinlowacceptanceratesandpotentiallylarge
performancegainscanbeachievedthroughER.Thesameistrueiftheinitialproposalcovarianceis
too large: many points are rejected and ER is beneficial again. We have found that this ‘cheap trick’
maysavecomputationaltimebetweenaround10%and80%.Incaseswithwell-posedGaussian-type
posteriors the benefit is lowest. However, these are the situations for which MCMC is not even
needed in the first place, as the classical linearization-based Fisher information matrix approach
already works quite well.
31.4.6.4 Delayed acceptance
The delayed acceptance Metropolis–Hastings [6] (DAMH) algorithm improves computational
efficiency of MCMC sampling by taking advantage of approximations to the forward map that are
available in many inverse problems. The approximation to the forward map is used to evaluate a
computationallyfastapproximationπ∗x (·)tothedesiredtargetdistributionπ(·|d),thatcandepend
on the current state x.
Given a proposal drawn from the distribution q(x, y), DAMH first ‘tests’ the proposal with the
approximation π∗x (y) to create a modified proposal distribution q∗(x, y) that is used in a standard
MH. DAMH gains computational efficiency by avoiding calculation of π(y|d) for poor proposals
that are rejected by π∗x (y). One iteration of DAMH is given by:
Algorithm 3 (DAMH)
At step n, with state xn = x, determine xn+1 in the following way:
1. Generate a proposal y from q(x, ·).
2. When x ̸= y, with probability
α(x, y) = min
1
1, π∗x (y)q(y, x)
π∗x (x)q(x, y)
2
continue to step 3. Otherwise reject by setting xn+1 = x and exit.
3. With probability
β(x, y) = min
1
1, π(y|d)q∗(y, x)
π(x|d)q∗(x, y)
2
accept y setting xn+1 = y, where q∗(x, y) = α(x, y)q(x, y). Otherwise reject y setting
xn+1 = x.
For a state-dependent approximation we can assume that the approximation is exact when eval-
uated at the current state, i.e., π∗x (x) = π(x|d). Then the second acceptance probability can be
simplified to
β(x, y) = min
⎡
⎣1,
min

π(y|d)q(y, x), π∗y (x)q(x, y)

min

π(x|d)q(x, y), π∗x (y)q(y, x)

⎤
⎦
(31.17)

Inverse problems
639
If the approximation does not depend on the current state, we write π∗(·) in place of π∗x (·) and the
second acceptance probability simplifies to
β(x, y) = min
1
1, π(y|d)π∗(x)
π(x|d)π∗(y)
2
(31.18)
which is exactly the surrogate transition method introduced by Liu [33].
DAMH necessarily reduces statistical efficiency, but a good approximation will produce
β(x, y) ≈1 ([6] Theorem 2) and can increase computational efficiency by up to the inverse of
the acceptance ratio. Christen and Fox gave an example in electrical impedance tomography (EIT)
using the local linear approximation
A∗
x(x + x) = A(x) + Jx,
where J is the Jacobian of A evaluated at state x, that improved computational efficiency by a factor
of 25.
31.4.6.5 Adaptive approximation error
One way to construct an approximation is to directly replace the forward model A by a
reduced-order model (ROM) A∗in evaluating the likelihood function in eqn (31.12). With for-
ward problems that are induced by PDEs, the most obvious approach is to use coarse meshes.
These induce a global, or state-independent, approximation. However, as we will see, a substantial
improvement in efficiency is achieved by using a local correction that leads to a state-dependent
approximation.
Not accounting for model reduction error in eqn (31.15) can give poor results. For example, in an
inverse problem in geothermal reservoir modelling [10], we found that simply using a coarse model
for A∗in place of A achieved only 17% acceptance in step 3 of DAMH. The reduction in statistical
efficiency, by about a factor of 5, nullified any potential gain in computational efficiency.
Kaipio and Somersalo [30] estimated the mean μB and covariance B of the AEM off-line by
drawing M samples from the prior distribution over x and used the sample mean and covariance
of

A(xi) −A∗(xi)
M
i=1. This AEM will be accurate over the support of the prior distribution, but
willnotnecessarilybeaccurateovertheposteriordistribution.Instead,Cuietal.[10,11]constructed
the AEM over the posterior distribution adaptively, within the DAMH algorithm. Using this adap-
tive AEM, and a local correction explained next, resulted in an increase of the second acceptance
ratio from 17%, quoted above, to 95%; so the stochastically corrected approximation is effectively
perfect.
Whenimplementingastate-independentROMwithinDAMH,wehavefounditisalwaysadvan-
tageous to make the zeroth-order local correction
A∗
x(y) = A∗(y) +

A(x) −A∗(x)

which has virtually no computational cost since both A(x) and A∗(x) have been computed when
at state x. The resulting approximation A∗x(·) now depends on the state x, so DAMH is required
in eqn (31.17), rather than surrogate transition eqn (31.18). This corrected approximation has the
property that AEM has mean of zero [11] and hence the adaptive AEM converges to a zero mean
Gaussian. We find in practice that simply setting the mean to zero in the adaptive algorithm gives
best results.
One step of the resulting adaptive delayed acceptance Metropolis–Hastings (ADAMH) algo-
rithm is:

640
C. Fox, H. Haario and J. A. Christen
Algorithm 4 (ADAMH)
At step n, with state xn = x, approximate target distribution π∗x,n(·), and proposal distribution
qn(x, ·), determine xn+1 and updated distributions in the following way:
1. Generate a proposal y from qn(x, ·).
2. When x ̸= y, with probability
α(x, y) = min

1,
π∗x,n(y)qn(y, x)
π∗x,n(x)qn(x, y)

continue to step 3. Otherwise reject by setting xn+1 = x and goto step 4.
3. With probability
β(x, y) = min
1
1, π(y|d)q∗n(y, x)
π(x|d)q∗n(x, y)
2
accept y setting xn+1 = y, where q∗n(x, y) = α(x, y)qn(x, y). Otherwise reject y setting
xn+1 = x.
4. Update the AEM covariance by
B,n+1 = 1
n
8
(n −1) B,n +

A(xn+1) −A∗
x(xn+1)
 
A(xn+1) −A∗
x(xn+1)
T9
.
5. Update the proposal to qn+1(xn+1, ·).
Usingthisalgorithm,Cuietal.[11]increasedcomputationalefficiencybyafactorof8inalarge-scale
nonlinear inverse problem in geothermal modelling with 104 continuous unknowns. This reduced
computing time from 8 months to 1 month, which is significant. Actually, the performance of
ADAMH in that example was remarkable, drawing each independent sample from the correct pos-
terior distribution at a cost of only 25 evaluations of the accurate model.
We have not yet given the form of the proposal, yet the choice of proposal distribution is critical
in achieving computational feasibility, as with any MH MCMC. While adaptation can remove the
needfortuningofproposals,choosingthestructureoftheproposaltoadapttoremainssomethingof
anart.Inhighdimensionalinverseproblemsneitheroftheextremesofsingle-componentproposals
(e.g. SCAM) or global proposals (e.g. AM) is optimal; see e.g. [11] for a discussion on this point,
and [24] for a demonstration of the failure of AM. Instead, proposing block updates over highly
correlated sets of variables, as in [11], can be very effective, although requires some exploration to
find a suitable blocking scheme.
31.5 Future directions
Alan Sokal introduced his lecture notes on Monte Carlo methods [40] with the warning,
Monte Carlo is an extremely bad method; it should be used only when all alternative
methods are worse.
We wholeheartedly agree, and add that in practice the situation can be desperate, when we have no
decent proposal distribution. Adaptive MCMC methods are useful here by automatically tuning

Inverse problems
641
proposals, but even they can never exceed the performance with an optimal proposal. However,
sometimes one must sin43 when there is no alternative route to solving a problem, and we do so
nowadays routinely for large classes of models. This leaves a pressing need to improve MCMC
sampling.
There are now many options for performing MCMC sampling such as the random-walk MH,
hybridMonteCarlo,proposalsbasedonLangevindiffusions,andmanyothers.Asignificantissuein
inverse problems is not just to rely on algorithms that are provably convergent, but to make sensible
algorithmic choices in terms of computational efficiency, and particularly how the algorithm cost
scales with problem size.
We expect that lessons learned in computational optimization will be valuable for future
improvements in MCMC. In that field many sophisticated algorithms have been developed such
as the Krylov space methods that go by the acronyms PCG, Bi-CGSTAB, and GMRES, and the
quasi-NewtonmethodsincludingBFGS.Theseoptimizersnavigatehigh-dimensionalsurfaceswith
minimal need to evaluate a complex function, which is a requirement shared by efficient MCMC
for inverse problems. There are already sampling algorithms that use these ideas. In [2] LBFGS
optimization is used to construct approximate filtering in state spaces that are too high dimensional
for the usual extended Kalman filtering. The same approach has been tested for ensemble filter-
ing, and provides a way to high-dimensional MC sampling, without MCMC. The CG sampling
algorithm for Gaussian distributions presented in 2001 by Schneider and Willsky, was improved
in [39] and characterized for finite precision calculations. The observation that Gibbs samplers are
essentially identical to stationary iterative linear solvers that are now considered very slow (see [39]
for references) provides a perspective on MCMC in relation to linear solvers, and points towards
fundamental improvements.
These algorithms hold the promise of drawing independent samples with the same computa-
tional cost as the optimization required for regularized solution. While that would be a dramatic
improvement over the current situation, even then the reality is that sample-based inference will
only become routine in engineering if the entire cost is no more than a few times the cost of
optimization. That means, even with such improvements, that for the foreseeable future ‘solutions’
will need to be based on at most a handful of samples drawn from the posterior distribution.
If we set aside the goal of accurate estimates of errors on estimates, and set the more modest
goal of improving on current practice in inverse problems, we have a chance. As argued in [13], a
single sample drawn from the posterior distribution can be better than the regularized solution,
in the sense of being more representative. One could then improve substantially by drawing a few
samples, since that would at least give some indication of variability in solutions, while a few dozen
samples would often be good enough to show the extent of posterior variability (although which
few dozen might be difficult to determine). This is, especially, true if those few samples already are
enough to verify the negative conclusion: that our unknown is far from being identified. We should
keep in mind that in truly high-dimensional inverse problems the number of samples most likely
remains far fewer than the dimension of the unknown, so any discussion on assured convergence of
posterior estimates, in the usual sense, remains academic too.
References
[1] Antoulas, A. C. (2005). Approximation of Large-Scale Dynamical Systems. SIAM.
[2] Auvinen, H., Bardsley, J., Haario, H. and Kauranne, T. (2010). Variational Kalman filter and
an efficient implementation using limited memory BFGS. International Journal for Numerical
Methods in Fluids, 64(3), 314–335.
43 John von Neumann is quoted as saying: ‘anyone using Monte Carlo is in a state of sin’.

642
C. Fox, H. Haario and J. A. Christen
[3] Birman, M. S. and Solomyak, M. Z. (1977). Estimates of singular numbers of integral opera-
tors. Uspekhi Mat. Nauk, 32(1), 17–84. Engl. transl. in: Russian Math. Surveys 32(1977), no. 1,
15–89.
[4] Brockwell, A. (2006). Parallel Markov chain Monte Carlo simulation by pre-fetching. Journal
of Computational and Graphical Statistics, 15(1), 246–260.
[5] Cappé, O., Moulines, E. and Rydén, T. (2005). Inference in Hidden Markov Models. Springer
Series in Statistics. Springer.
[6] Christen, J. A. and Fox, C. (2005). Markov chain Monte Carlo using an approximation.
Journal of Computational and Graphical Statistics, 14(4), 795–810.
[7] Cox, R. T. (1961). The Algebra of Probable Inference. Johns Hopkins.
[8] Craiu, R. V., Rosenthal, J. and Yang, C. (2009). Learn from thy neighbor: Parallel-chain
and regional adaptive MCMC. Journal of the American Statistical Association, 104(488),
1454–1460.
[9] Cramér, H. (1946). Mathematical Methods of Statistics (First US edn). Princeton University
Press.
[10] Cui, T., Fox, C. and O’Sullivan, M. J. (2011). Adaptive error modelling in MCMC sampling
for large scale inverse problems. Technical Report no. 687, University of Auckland, Faculty of
Engineering.
[11] Cui, T., Fox, C. and O’Sullivan, M. J. (2011). Bayesian calibration of a large scale geothermal
reservoirmodelbyanewadaptivedelayedacceptanceMetropolis-Hastingsalgorithm. Water
Resources Research, 47. 26 pp.
[12] Donoho, D. L., Johnstone, I. M., Hoch, J. C. and Stern, A. S. (1992). Maximum entropy and
the nearly black object. Journal of the Royal Statistical Society. Series B, 54, 41–81.
[13] Fox, C. (2008). Recent advances in inferential solutions to inverse problems. Inverse Problems
Sci. Eng., 16(6), 797–810.
[14] Fox, C. and Nicholls, G. K. (1997). Sampling conductivity images via MCMC. In The Art and
Science of Bayesian Image Analysis (ed. K. Mardia, R. Ackroyd, and C. Gills), pp. 91–100. Leeds
Annual Statistics Research Workshop: University of Leeds.
[15] Golub, G. H., Heath, M. and Wahba, G. (1979). Generalized cross-validation as a method for
choosing a good ridge parameter. Technometrics, 21(2), 215–223.
[16] Green, P. J. and Mira, A. (2001). Delayed rejection in reversible jump Metropolis-Hastings.
Biometrika, 88, 1035–1053.
[17] Grenander, U. and Miller, M. (1994). Representations of knowledge in complex systems.
Journal of the Royal Statistical Society. Series B, 56(4), 549–603.
[18] Gull, S. F. and Daniell, G. J. (1978). Image reconstruction from incomplete and noisy data.
Nature, 272(5655), 686–690.
[19] Haario, H., Kalachev, L. and Laine, M. (2009). Reduced models for algae growth. Bulletin of
Math. Biology, 71(7), 1626–1648.
[20] Haario, H., Laine, M., Mira, A. and Saksman, E. (2006). DRAM: Efficient adaptive MCMC.
Statistics and Computing, 16(3), 339–354.
[21] Haario, H., Saksman, E. and Tamminen, J. (2001). An adaptive Metropolis algorithm.
Bernoulli, 7(2), 223–242.
[22] Hansen, P. C. (1998). Rank-Deficient and Discrete Ill-Posed Problems. Numerical Aspects of
Linear Inversion. SIAM.
[23] Hastings, W. K. (1970). Monte Carlo sampling methods using Markov chains and their appli-
cations. Biometrika, 57(1), 97–109.
[24] Higdon, D., Reese, C. S., Moulton, J. D., Vrugt, J. A. and Fox, C. (2011). Posterior exploration
for computationally intensive forward models. In Handbook of Markov Chain Monte Carlo
(ed. S. Brooks, A. Gelman, G. Jones, and X.-L. Meng), pp. 401–418. Chapman & Hall/CRC.

Inverse problems
643
[25] Howson,C.andUrbach,P.(2005).ScientificReasoning:TheBayesianApproach(3edn).Open
Court.
[26] Hurn, M. A., Husby, O. and Rue, H. (2003). Advances in Bayesian image analysis. In Highly
Structured Stochastic Systems (ed. P. J. Green, N. Hjort and S. Richardson), pp. 302–322.
Oxford: Oxford University Press.
[27] Jaynes, E. T. (1973). The well-posed problem. Foundations of Physics, 3(4), 477–492.
[28] Jaynes, E. T. (1978). Where do we stand on maximun entropy? In Maximum Entropy Formal-
ism (ed. R. D. Levine and M. Tribus), p. 16. MIT Press.
[29] Kaipio, J. and Fox, C. (2011). The Bayesian framework for inverse problems in heat transfer.
Heat Transfer Engineering, 32(9), 718–753.
[30] Kaipio,J.andSomersalo,E.(2007).Statisticalinverseproblems:discretization,modelreduc-
tion and inverse crimes. J Comput Appl Math, 198, 493–504.
[31] Kennedy, M. C. and O’Hagan, A. (2001). Bayesian calibration of computer models (with
discussion). Journal of the Royal Statistical Society: Series B, 63, 425–464.
[32] Keynes, J. M. (1921). A Treatise on Probability. Macmillan and Co.
[33] Liu, J. S. (2005). Monte Carlo Strategies in Scientific Computing. Springer.
[34] Mosegaard, K., Singh, S. C., Snyder, D. and Wagner, H. (1997). Monte Carlo analysis of
seismic reflections from Moho and the W-reflector. Journal of Geophysical Research B, 102,
2969–2981.
[35] Müller,P.(1999).Simulation-basedoptimaldesign.InBayesianStatistics6(ed.J.M.Bernardo,
J. O. Berger, A. P. Dawid, and A. F. M. Smith), pp. 459–474. Oxford University Press. 6,
459–474.
[36] Nicholls, G. and Jones, M. (2001). Radiocarbon dating with temporal order constraints.
Journal of the Royal Statistical Society. Series C (Applied Statistics), 50, 503–521.
[37] Oliver, D. S., Cunha, L. B. and Reynolds, A. C. (1997). Markov chain Monte Carlo methods
for conditioning a permeability field to pressure data. Mathematical Geology, 29(1), 61–91.
[38] O’Sullivan, F. (1986). A statistical perspective on ill-posed inverse problems. Statistical Sci-
ence, 1(4), 502–527.
[39] Parker, A. and Fox, C. (2011). Sampling Gaussian distributions in Krylov spaces with conju-
gate gradients. SIAM Journal on Scientific Computing. In the press.
[40] Sokal, A. D. (1996). Monte Carlo methods in statistical mechanics: Foundations and new
algorithms. In Lectures at the Cargése summer school on ‘Functional Integration: Basics and
Applications’.
[41] Tarantola, A. (1987). Inverse Problem Theory: Methods for Data Fitting and Model Parameter
Estimation. Elsevier.
[42] Tikhonov, A. N. and Arsenin, V. Y. (1977). Solutions of Ill-posed Problems. Scripta series in
mathematics. Winston.
[43] Villagran, A., Huerta, G., Jackson, C. S. and Sen, M. K. (2008). Computational methods for
parameter estimation in climate models. Bayesian Analysis, 3(3), 1–27.
[44] Watzenig, D. and Fox, C. (2009). A review of statistical modelling and inference for electrical
capacitance tomography. Measurement Science and Technology, 20(5), 22 pp.
[45] Young, N. (1998). An Introduction to Hilbert Space. Cambridge University Press.

32
Approximate
marginalization over
modelling errors and
uncertainties in inverse
problems
jari kaipio and ville kolehmainen
I
n this chapter, we discuss Bayesian modelling of errors that are induced by model uncertainties
and practical implementational constraints. Our focus is on problems that are severely resource
limited with respect to computational power, memory and time. This is the common case in
industrial and biomedical problems in general, and often also in other problems, in which a con-
tinuous stream of data is to be processed. Such problems suggest employing highly approximative
reducedordermodels,andoftenonlysomeoftheactualunknownsareofinterest.Furthermore,the
uncertainties may also be related to such information which traditionally has been considered to be
mandatory, for example, the boundary data in problems governed by partial differential equations
(PDE).
To put the computational problem in scale, consider the following. In industrial imaging of
flows using electromagnetic fields such as electrical impedance tomography, the domain and the
unknown(s) are usually modelled as (low level) three-dimensional random fields [23, 49, 60].
Traditional accuracy requirements for the forward model suggest using discretized approxima-
tions for the associated PDEs typically with ∼1 000–100 000 unknowns. The time frame for the
computation of the state, on the other hand, may be of the order of a millisecond. Since the esti-
mates are eventually to be used in (optimal stochastic) control, feasible error estimates (posterior
covariance) are also needed [10]. Furthermore, the computations are usually to be computed using
standard industrial computers, with processing power comparable to somewhat outdated personal
computers.
Suchconstraintsexcludethepossibilityof(andusuallytheneedfor)accurateBayesianinference.
Furthermore, the problems are typically nonlinear, and even the computation of the MAP estimate
and highly approximate posterior covariance as spread estimate can be a formidable task. What
needs to be done, is to use approximative (simplified) physical models and crude computational
approximations, and to neglect many of the actual unknowns. With inverse problems, which can
loosely be defined as problems that tolerate measurement and modelling errors poorly, straightfor-

Approximate marginalization over modelling errors
645
ward adherence to such constraints heralds a disaster [6, 24]. Nevertheless, something has to be
done to provide feasible estimates.
The approach we take here, is to construct (prior) models for all unknowns and compute a
crude likelihood model over the modelling errors that are induced by numerical model reduction
and uncertainty in the ‘uninteresting’ unknowns. The modelling errors are modelled as additive
errors in the likelihood model, and thus they can be formally marginalized before the inference.
In the sequel, numerical approximation and all modelling errors are referred to as approximation
errors.
The rest of the chapter is organized as follows. In Section 32.1, we discuss the characteristics of
inverse problems in the Bayesian framework and give a brief review of earlier application of the
approximation error approach. In Section 32.2, we give the basic formulation of the approximation
error approach, and in Sections 32.3 and 32.4, we discuss general implementational aspects and the
high-dimensional observation cases, respectively. In Section 32.5, we discuss the local X-ray tomog-
raphyproblem,inwhichonlya(small)partofthespatialmassattenuationdistributionisestimated,
and relatively few measurements are acquired. This leads to an unidentifiable problem, with respect
to the traditional deterministic framework for inverse problems. This can be modelled as a linear
problemwithnormalposteriormodel.InSection32.6,weconsidertheelectricalimpedancetomog-
raphy problem with unknown boundary geometry. We show that the Bayesian approximation error
approach facilitates the computation of feasible estimates despite the inaccurately known geometry
and, furthermore, also yields feasible approximations for the low-level uncertainties.
32.1 Inverse problems as Bayesian inference problems
In addition to Chapter 31 in this volume, we refer the reader to [6, 24, 55] for treatises of inverse
problems in the Bayesian context. Inverse problems are a particular class of Bayesian inference
problems due to the following considerations. Firstly, the representations for the unknowns are
typicallyrelativelyhighdimensional.Infact,itiscommonthatthenumberofunknownsexceedsthe
numberofmeasurements,sometimesbyafactoroftenormore.Secondly,inverseproblemstolerate
poorly (measurement and modelling) errors, and thus only such problems are usually considered
in which the measurements (given an accurate model) are relatively accurate. This means that the
likelihoods are typically nonlinear manifolds with very small variances, that is, std⟨b, d⟩are small
compared to E⟨b, d⟩, where d ∈Rm is the measurement, b ∈Rm is any vector with ∥b∥= 1.
Distributed parameter estimation problems induced by partial differential equations and the
related initial-boundary value problems constitute perhaps the largest class of inverse problems.
Such models always provide a more or less simplified approximation for the physical reality. In
particular, the following modelling problems are common:
• Geometry is unknown (biomedical imaging) [16, 17, 33, 45, 46]
• Measurement sensor locations are only approximately known (geophysics, some biomedical
imaging modalities) [43]
• Measurement noise statistics are poorly known (most applications) [39, 55]
• Approximate physical measurement models are used (biomedical, geophysical and industrial
applications) [34, 56]
• Significant uncertainty in models for the unknown variables (geophysics, industrial flows)
[29, 34, 38]
• Boundary conditions are partially unknown (biomedical, geophysics and industrial applica-
tions) [33, 36, 49, 59]

646
J. Kaipio and V. Kolehmainen
As a result, it is almost inevitable that the modelling errors dominate the (effects of the) measure-
ment error. We will be more precise regarding this claim in Section 32.2.
With a fixed parameterization x = P¯x for an unknown physical variable ¯x, where P is typically
a projection operator, the best we can hope for a particular point estimate is ˆx = P¯x. In terms of
probability mass, we can loosely say that unaccounted-for modelling errors move the likelihood
and thus posterior probability mass away from the projection P¯x. In this chapter, we refer to having
π(P¯x|d) ≈0 as an infeasible posterior model. In Figure 32.1, we show an example of a posterior
marginal density and the actual variable in the case of local X-ray tomography, which is considered
in Section 32.5. This is typical behaviour for inverse problems, and gives a probabilistic interpre-
tation for the notion of poor tolerance to modelling errors. In the local tomography problem, the
likelihood is normal and the infeasibility of the posterior model is entirely due to the modelling
errors in the likelihood. In the case of inverse problems, carrying out proper inference with MCMC
methods makes no sense without highly accurate likelihood models.
The Bayesian framework for inverse problems is a natural one when modelling and other uncer-
tainties are to be considered. Sometimes these uncertainties can be parameterized by a small num-
ber of unknowns, which suggests using hyperprior models. In the majority of cases, however, the
model errors and uncertainties do not allow for a feasible small-dimensional hyperprior model.
One example of such cases is that of unknown boundary geometry, which is a common problem in
biomedical diffuse tomography. Here, if the geometry were known, the straightforward approach
wouldbetoconstructthe(say,finiteelement)meshesofthePDEsolvertomatchthegeometry.But
if the geometry is changing between the measurements (due to breathing, for example), the finite
element matrices would have to be recomputed. We are saved from this typically infeasible com-
putational problem by the fact that there is no clinically available measurement method to obtain
0.09
0.095
0.1
0.105
0.11
0.115
0.12
0.125
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Figure 32.1 A posterior marginal density when the approximation and modelling errors have been
modelled (solid line), have not been modelled (dash-dot line); and the actual value of a pixel in a local
tomography problem. This infeasibility of the posterior estimates is typical for inverse problems if the
approximation and modelling errors are ignored.

Approximate marginalization over modelling errors
647
the geometry of the body. Thus, we are left with the uncertainty of the boundary geometry. The
bad news is that even a relatively small error in boundary geometry usually renders the estimates
completely meaningless. We address this problem in Section 32.6.
As explained above, the practical constraints will typically allow a few evaluations of the like-
lihood and prior only, and the associated models have to be such that even these computations
cannot be based on accurate physical models. A further complication is provided by the fact that
many inverse problems are time-varying, and the proper formalism is that of sequential Bayesian
inference [9]. But again, particle filters are typically out of question, and the best one can do, is to
constructafeasiblemodelforobservationandstatenoiseprocesses,andusesomeformofextended
Kalman filters [18–21].
All the above suggests that the actual estimation stage has to be more or less ‘quick and dirty’.
But this does not usually exclude the possibility of carrying out extensive offline precomputations,
possibly with very accurate models. In this chapter, we describe the Bayesian approximation error
approach [24, 25] which was originally introduced to cope with numerical model reduction in
PDE induced distributed parameter estimation problems. The approach is based on constructing
a (prior) model for all low-level uncertainties, carrying out simulations with the most accurate
available model, and the model that is to be used in the estimation stage. The difference of the
prediction of these two models is called the approximation error and is then treated as a (further)
additive error term, usually in addition to the measurement errors. A normal approximation to the
joint distribution for the primary unknown and the approximation error is constructed and the
additive random variables are marginalized before the actual inference. Again, the best that can
usually be done within the time and resource constraints in practical applications, is to compute
the MAP estimate and an approximate posterior covariance.
As noted above, the approximation error approach was introduced in [24, 25] originally to han-
dle pure model reduction errors. For example, in electrical impedance (resistance) tomography
(EIT, ERT) and deconvolution problems, it was shown that significant model reduction is possible
without essentially sacrificing the feasibility of estimates. With EIT, for example, this means that
very low-dimensional finite element approximations can be used. Later, the approach has also been
applied to handle other kinds of approximation and modelling errors as well as other inverse prob-
lems: model reduction, domain truncation and unknown anisotropy structures in diffuse optical
tomography were treated in [2, 16, 17, 27]. Missing boundary data in the case of image processing
and geophysical ERT/EIT were considered in [5] and [33], respectively. Furthermore, in [42, 44]
the problem of recovery from simultaneous domain truncation and model reduction was found to
be possible, and in [45, 46] recovery from the errors related to inaccurately known body shape was
shown feasible.
The approximation error approach was extended to non-stationary inverse problems in [19]
in which linear non-stationary (heat transfer) problems were considered, and in [18] and [20] in
which nonlinear problems and state space identification problems were considered, respectively.
The earliest similar but partial treatment in the framework on non-stationary inverse problems was
considered in [50] in which the boundary data that is related to stochastic convection diffusion
models was partially unknown. A modification in which the approximation error statistics can be
updated with accumulating information was proposed in [21] and an application to hydrogeophys-
ical monitoring in [35].
From pure model reduction and unknown parameters or boundary data, a step forwards was
recently considered in [56] in which the physical forward model itself was replaced with a (compu-
tationally)muchsimplermodel.In[56],theradiativetransfermodel(Boltzmanntransferequation)
which is considered to be the most accurate PDE model for light transfer in (turbid) media, was
replaced with the diffusion approximation. It was found that in this kind of case, the statistical
structure of the approximation errors enabled the use of a significantly less complex model, again
simultaneously with significant model reduction for the diffusion approximation. But here also,

648
J. Kaipio and V. Kolehmainen
both the absorption and scattering coefficients were estimated simultaneously, while in [30], the
scattering coefficient was modelled as a normal Markov random field and was not estimated.
The approximation error approach relies on the Bayesian framework of inverse problems, in
which all unknowns are explicitly modelled as random variables [6, 24, 55]. The uncertainty in the
unknowns given the models and measurements is reflected in the posterior (probability) distribu-
tion. In the Bayesian framework, all unknowns are subject to inference simultaneously, which often
results in excessively heavy computational loads. Generally, Markov chain Monte Carlo algorithms
have to be used to obtain a representative set of samples from the posterior distribution. Then, after
a set of samples has been computed, marginalization over the uninteresting unknowns is trivial.
Only in few special but important cases, such as the additive error model, some of the uninteresting
unknowns can be eliminated before inference. We refer to such elimination as pre-marginalization.
For Markov chain Monte Carlo inference of inverse problems, see Chapter 31 and the references
therein in this volume.
32.2 Approximate marginalization over modelling errors
32.2.1 Marginalization over additive errors
In the approximation error approach, the modelling and other errors as well as uncertainties are
propagated to additive errors. With uncertainties, we refer to the random variables (fields etc) that
are not estimated, that is, written as variables in the posterior model.
Therefore, we review briefly how the additive errors are formally pre-marginalized [24, 30] and
introduce the basic notation. Let the observation model be
d = ¯A(x) + e
(32.1)
where e are additive errors and x →¯A(x) is a deterministic forward model. With deterministic
we mean that the model ¯A does not contain any uncertainties or other model errors. Let the joint
prior model of the unknowns x and e be π(x, e). Using the Bayes’ theorem repeatedly, the joint
distribution of all associated random variables can be decomposed as
π(d, x, e) = π(d | x, e)π(e | x)π(x)
(32.2)
= π(d, e | x)π(x)
(32.3)
Inthecasethatbothxandearefixed,themeasurementdinthemodel(32.1)iscompletelyspecified,
so the conditional distribution π(d | x, e) is formally given by
π(d | x, e) = δ(d −¯A(x) −e)
(32.4)
where δ is the Dirac delta distribution. Using (32.2)–(32.4), we get the likelihood model
π(d | x) =

π(d, e | x) de =
(32.5)
=

δ(d −¯A(x) −e)π(e | x) de
(32.6)
= πe | x(d −¯A(x) | x)
(32.7)

Approximate marginalization over modelling errors
649
and further, noting that once the measurements have been obtained, π(d) > 0 is a fixed normal-
ization constant, we have the posterior model
π(x | d) ∝π(d | x)π(x)
(32.8)
= πe | x(d −¯A(x) | x)π(x)
(32.9)
In the quite common case of mutually independent x and e, we have πe | x(e | x) = πe(e). Further-
more, if e and x are normal, we can write π(e) = N(e∗, e) and π(x) = N(x∗, x) and we have
the form
π(x | d) ∝exp

−1
2

∥Le(d −¯A(x) −e∗)∥2 + ∥Lx(x −x∗)∥2
,
(32.10)
where LTe Le = −1
e
and LTx Lx = −1
x , for the posterior model. The MAP estimate for the model
(32.10) is obtained by
ˆx = arg min
x

∥Le(d −¯A(x) −e∗)∥2 + ∥Lx(x −x∗)∥2
(32.11)
An approximate covariance estimate is obtained as
ˆx|d =

JT−1
e
J + −1
x
−1
(32.12)
where the Jacobian matrix J of the mapping A is computed at the MAP estimate.
Intheabove,theunknown(uninteresting)additiveerrorewaspre-marginalized,thatis,marginal-
ized before the inference procedure, and e is not present in (32.9) or (32.10).
32.2.2 Approximate pre-marginalization over model reduction
related errors and other uncertainties
The problem that is generally related to uninteresting auxiliary unknowns ξ is that we usually
cannot perform pre-marginalization such as in (32.6–32.7). In most cases, we have to estimate
both x and ξ which may be a considerably more demanding undertaking than estimating just x
if ξ was known. For example, if a Markov chain Monte Carlo (MCMC) approach were used, the
marginalization over ξ can only be done after running the chain for both x and ξ. Once this is
carried out, however, the marginalization over ξ is trivial. For MCMC and inverse problems, see
for example [12, 26, 54] for inference in the EIT problem.
In this section, we discuss the computational procedure in more detail in the case in which there
are two distributed parameters of which pre-marginalization over the other parameter, together
with the additive measurement errors and other uncertainties is to be carried out.
Let now the unknowns be (x, z, ξ, e) where again e represents additive errors while ξ represents
auxiliary uncertainties such as unknown boundary data, and (x, z) are two distributed parameters
of which only x is of interest. The accurate forward model
(x, z, ξ) →¯A(x, z, ξ)
(32.13)
isusuallyanonlinearone.Theuncertainties ξ mustsometimesbemodelledasmutuallydependent
with (x, z), especially when ξ represents boundary data on the computational domain boundary
and (x, z) are modelled as random fields. On the other hand, if ξ represents unknown boundary

650
J. Kaipio and V. Kolehmainen
shape, ξ might be modelled as mutually independent with (x, z). In the following, we consider
the case in which the noise e is additive and the unknowns (x, z, ξ) are not necessarily mutually
independent.
Let
d = ¯A(¯x, z, ξ) + e ∈Rm
denote an accurate model for the relation between the measurements and the unknowns44 and let
e be mutually independent with (x, z, ξ).
Below, we approximate the accurate representation of the primary unknown ¯x by x = P¯x where
P is typically a projection operator. Let π(x, z, ξ, e) be a feasible model for the joint distribution of
the unknowns. We identify x = P¯x with its coordinates in the associated basis.
Intheapproximationerrorapproach,weproceedasfollows.Insteadofusingtheaccurateforward
model (¯x, z, ξ) →¯A(¯x, z, ξ) with (¯x, z, ξ) as the unknowns, we fix the random variables (z, ξ) ←
(z0, ξ0) and use a computationally (possibly drastically reduced) approximative model
x →A(x, z0, ξ0)
Here, the predictions of the two models ¯A(¯x, z, ξ) and A(x, z0, ξ0) may be drastically different.
Thus, we write the measurement model in the form
d = ¯A(¯x, z, ξ) + e
(32.14)
= A(x, z0, ξ0) +
¯A(¯x, z, ξ) −A(x, z0, ξ0)

+ e
(32.15)
= A(x, z0, ξ0) + ε + e
(32.16)
where we define the approximation error ε = ϕ(¯x, z, ξ) = ¯A(¯x, z, ξ) −A(x, z0, ξ0). Thus, the
approximation error is the discrepancy of predictions of the measurements (given the unknowns)
when using the accurate model ¯A(¯x, z, ξ) and the approximate modelA(x, z0, ξ0). Note that (32.16)
is exact.
Earlier, we referred to the problem of approximation error dominating the measurements errors.
In the case of additive measurement errors, we can make this notion quantitative by considering
∥e∗∥2 + trace e < ∥ε∗∥2 + trace ε
(32.17)
and
e∗(k)2 + e(k, k) < ε∗(k)2 + ε(k, k) ,
k = 1, . . . , m
(32.18)
If (32.17) holds, we say that the approximation errors dominate the measurement errors. Neglecting
the approximation errors from the likelihood model will usually result in completely meaningless
posterior estimates. But if (32.18) holds for any k, this may also be the case. In Section 32.4, we
decompose the approximation errors into two components, and (32.18) is used as the decompo-
sition criterion.
Formally, after the models ¯A and A are fixed, we have π(ε | ¯x, z, ξ) = δ(ε −ϕ(¯x, z, ξ)). We
will later, however, employ approximative joint distributions and therefore consider π(ε, ¯x, z, ξ)
without any special structure. As the first approximation, we approximate ϕ(¯x, z, ξ) ≈ϕ(Px, z, ξ)
44 If there are no additive errors, we write e = 0 and consider the other types of errors to be included in ξ.

Approximate marginalization over modelling errors
651
and thus π(ε | ¯x, z, ξ) ≈π(ε | Px, z, ξ). This means that we assume that the model predictions and
thus the approximation error is essentially the same for ¯x as x = P¯x. This assumption holds for
inverse problems in most cases. In very severe model reduction for the unknown, such as in the
coloured polygon models [41], this may not be the case, and the projection approximation might
be needed to be taken into account.
Proceeding as in Section 32.2.1, we use the Bayes’ formula repeatedly
π(d, x, z, ξ, e, ε) = π(d | x, z, ξ, e, ε)π(x, z, ξ, e, ε)
= δ(d −A(x, z0, ξ0) −e −ε)
π(e, ε | x, z, ξ)π(z, ξ | x)π(x)
= π(d, z, ξ, e, ε | x)π(x)
Hence
π(d | x) =

π(d, z, ξ, e, ε | x)de dε dz dξ
=

δ(d −A(x, z0, ξ0) −e −ε)
·
1
π(e, ε | x, z, ξ)π(z, ξ | x)dz dξ
2
de dε
=

δ(d −A(x, z0, ξ0) −e −ε)π(e, ε|x)de dε
=

πe(d −A(x, z0, ξ0) −ε)πε|x(ε | x) dε
(32.19)
since e and x are mutually independent, and (32.19) is a convolution integral with respect to ε. In
particular, since e is mutually independent with (x, z, ξ), e and ε are also mutually independent.
At this stage, in the approximation error approach, both πe and πε|x are approximated with
normal distributions. Let the normal approximation for the joint density π(ε, x) be
π(ε, x) ∝exp
⎧
⎨
⎩−1
2

ε −ε∗
x −x∗
T 
ε εx
xε x
−1 
ε −ε∗
x −x∗
⎫
⎬
⎭
(32.20)
Thus we write
e ∼N(e∗, e),
ε | x ∼N(ε∗,x, ε|x)
where
ε∗,x = ε∗+ εx−1
x (x −x∗)
(32.21)
ε|x = ε −εx−1
x xε
(32.22)
Define the normal random variable ν so that ν | x = e + ε | x
ν | x ∼N(ν∗|x, ν|x)

652
J. Kaipio and V. Kolehmainen
where
ν∗|x = e∗+ ε∗+ εx−1
x (x −x∗)
(32.23)
ν|x = e + ε −εx−1
x xε
(32.24)
Thus, we obtain the approximate likelihood model
d | x ∼N(d −A(x, z0, ξ0) −ν∗|x, ν|x)
Since we are after computational efficiency, a normal approximation for the prior model would also
typically be employed in the construction of the posterior model
x ∼N(x∗, x)
Thus, we obtain the approximation for the posterior distribution
π(x | d) ∝π(d | x)π(x) ∝exp

−1
2V(x)

where V(x) is the posterior potential
V(x) = (d −A(x, z0, ξ0) −ν∗|x)T−1
ν|x(d −A(x, z0, ξ0) −ν∗|x)
(32.25)
+ (x −x∗)T−1
x (x −x∗)
= ∥Lν|x(d −A(x, z0, ξ0) −ν∗|x)∥2 + ∥Lx(x −x∗)∥2
(32.26)
and where −1
ν | x = LT
ν|xLν|x, −1
x
= LTx Lx and ν∗|x = ν∗|x(x).
The MAP estimate of x with the approximation error model is obtained by
ˆx = arg min
x

∥Lν|x(d −A(x, z0, ξ0) −ν∗|x)∥2 + ∥Lx(x −x∗)∥2
(32.27)
Then,theapproximateposteriorcovariancewouldbecomputedbylinearizingA(x, z0, ξ0)atx = ˆx
ˆx|d ≈

JT−1
ν|xJ + −1
x
−1
(32.28)
where ˜J = J + εx−1
x
and J is the Jacobian of A(x, z0, ξ0) evaluated at x = ˆx .
32.3 Computational considerations
32.3.1 Physical versus relatively accurate reference models
Above, we have referred to the model ¯A(¯x, z, ξ) as the accurate (physical) model. Of course, we
do not have access to such model prediction, but it has turned out that it is adequate to have a
‘sufficiently accurate’ model as the reference model ¯A. In practice, one may have to construct a
sequence of approximations Ak to determine the ‘sufficiently accurate’ computational reference
model [2, 24, 25].

Approximate marginalization over modelling errors
653
With respect to uncertainties in general, the key is definitely not to underestimate the uncert-
ainties.
32.3.2 Precomputations versus online computations
The actual computational complexity of the approach can be considerable, since in most cases, a
largish number (typically from a few hundred to tens of thousands in the problems studied this far)
of accurate predictions ¯A(¯x, z, ξ) have to be computed. But the key is that no accurate predictions
need to be computed in the inference stage; these predictions are only needed for the computation
of the approximate second-order statistics of (x, ε). We also remark that with the typical dimension
of the unknowns, the computational complexity is small or comparable to a single MCMC run
which usually requires several hundred thousands or millions of evaluations of ¯A(¯x, z, ξ).
32.3.3 Sample sizes and the second-order sample statistics
In the case of linear normal cases, the approximation error statistics can be computed analytically.
In most cases, however, one needs to compute a number of samples from the joint prior model
π(x, z, ξ), and then the approximate second-order joint statistics of (x, ε).
Roughly, the required number of samples depends on the mappings ¯A and A, as well as the
variances of π(x, z, ξ) relative to the mean. If the variances are very small in this sense, one needs
only a small sample, or could even set ε = 0 and ε∗= ¯A(¯x∗, z∗, ξ∗) −A(P¯x∗, z∗, ξ∗), see for
example [33].
32.3.4 Sampling, prior models and atlases
In Section 32.2.2, we wrote the normal approximation (32.20) for the joint distribution of (x, ε).
Generally, this approximation is done to make efficient computation of the MAP estimates feasible.
If the actual prior model is normal, the marginal distribution of x induced by the (32.20) coincides
withtheactualpriormodel.Thepriormodelπ(¯x, z, ξ)doesnot,however,havetobejointlynormal
andneither,inparticular,doesthemarginalpriormodelπ(¯x).Inpractice,whateverthepriormodel
π(¯x, z, ξ) is, a set of samples (¯x(ℓ), z(ℓ), ξ(ℓ)) is usually to be drawn and the approximation errors
ε(ℓ) = ϕ(¯x(ℓ), z(ℓ), ξ(ℓ)) = ¯A(¯x(ℓ), z(ℓ), ξ(ℓ)) −A(Px(ℓ), z0, ξ0) ,
ℓ= 1, . . . , q
are then to be computed, where q is the number of draws. The normal approximation for π(ε, x)
is then formed by setting x(ℓ) = P¯x(ℓ) and computing the mean and joint covariance as sample
averages over the ensemble.
In Section 32.6, we employ an (anatomical) atlas in the construction of the model for the uncer-
tain boundary geometry. If such information is available, a ‘closed form’ model for π(ξ) is not
usually needed.
32.3.5 Neglecting the crosscovariances, approximating x⊥ε
Although we have ε = ε(x), and thus clearly x and ε could in most cases not be taken as mutually
orthogonal, the use of the further (computational) approximation xε = 0 has been shown to lead
to very similar estimates with ‘full error model’ in several problems. With this further approxima-
tion, the mean (32.23) and covariance (32.24) become
ν∗= e∗+ ε∗
ν = e + ε
(32.29)

654
J. Kaipio and V. Kolehmainen
In most problems studied thus far, the practical advantage of the further approximation (32.29)
has been that it gives feasible estimates with significantly smaller amounts of samples than the full
approximation error model. The approximation (32.29) was originally referred to as the enhanced
error model in [24, 25].
32.4 Dealing with high-dimensional data
If dimension m of the data is very large, such as in 3D X-ray tomography, magnetic resonance
imaging, and (inverse) transient wave propagation problems, the computation (and storage) of ε
and especially Le+ε can be prohibitive tasks. Why these problems don’t usually seem to pose a
problem without approximation errors, is that the iid assumption or approximation for e is usu-
ally adopted e = diag (σ 2
e,1, . . . , σ 2e,m) so that Le = diag (σ −1
e,1 , . . . , σ −1
e,m ). In addition, when the
sample covariance ε is computed, only a smallish number q ≪m of samples may be available.
32.4.1 Eigensystem of the approximation errors
Withqsamplesε(ℓ) oftheapproximationerrorarrangedincolumnsofmatrixW,wecouldcompute
ε∗= 1
q
q

ℓ=1
ε(ℓ)
ε =
1
q −1WWT −
q
q −1ε∗εT
∗= ¯V ¯VT
(32.30)
where ¯vℓ= (q −1)−1/2(ε(ℓ) −ε∗) are the columns of ¯V. As noted above, we may not be able
to either compute or store ε ∈Rm×m explicitly. Instead, we often need only a small rank approx-
imate covariance ε,p (a small-dimensional principal subspace of the eigensystem), and want to
compute it without explicit formation of matrix ε. In such a case, the simultaneous or orthogonal
iterations can be employed, see Section 32.4.3.45 Note that ¯V ∈Rm×q and q < m or even q ≪m.
Thus, ε is heavily rank-deficient, and assumes the eigenvalue decomposition
ε =
m

k=1
λkvkvT
k =
q

k=1
λkvkvT
k = V#VT
since λℓ= 0 at least for ℓ> q.
Since ε is positive semidefinite, the eigenvectors {vk, k = 1, . . . , q} are (algebraically)
orthonormal and
span{ε(ℓ) −ε∗, ℓ= 1, . . . , q} = span{¯vk, k = 1, . . . , q}
= span{vk, k = 1, . . . , q}
Thus, we can write46
ε(ℓ) −ε∗=
q

k=1
βkvk =
q

k=1
⟨ε(ℓ) −ε∗, vk⟩vk
45 The idea is not to compute ε, but to retain it (until further operations) in the form ¯V ¯VT.
46 This decomposition is exact for the samples ε(ℓ), but we can also interpret it as a low-dimensional model
for the approximation errors in general, as is implicitly done in Section 32.6.

Approximate marginalization over modelling errors
655
and further
Eβk = 0 ,
var βk = λk ,
Eβkβj = 0, k ̸= j
We shift from the linear algebraic interpretation to the statistical interpretation in the following. Of
all p-dimensional approximations εp for the random vectors ε that are of the form
εp = ε∗+
p

k=1
⟨ε −ε∗, wk⟩wk
the choice for {wk} that minimizes
E∥ε −εp∥2
is obtained by setting wk = vk, where vk are the eigenvectors of the covariance of ε. We denote
the associated subspace by Vp = span{v1, . . . , vp}. This applies both when we consider the actual
distributions and covariances, or the sample sets and sample covariances.
This theory is variably known as principal component analysis, proper orthogonal decomposi-
tion, Hotelling transform and Karhunen–Loeve decomposition (transform), see for example, [22].
In these theories, the main difference is how the decompositions are used and interpreted.
32.4.2 Augmenting the unknowns, approximating x⊥ε
For simplicity, assume that var ek = δ2 for all k so that trace e = E∥e −e∗∥2 = mδ2. We write
e+ε = e + ε,p + ε,−p
where
ε,p =
p

k=1
λkvkvT
k ,
ε,−p =
q

k=p+1
λkvkvT
k
and we can also write ε = ε∗+ εp + ε−p. As a rough starting point, choose p so that
q

k=p+1
λk ⪅0.2mδ2
With such a choice, we have e + ε,−p ≈e, and ε,p is the sought low rank approximation
for ε.
Now, write εp = ε∗+ p
k=1 βp,kvk, βp ∈Rp, Vp = (v1, . . . , vp) ∈Rm×p which leads to the
computational problem
min
x,βp
∥Le+ε−p(y −A(x) −Vpβp −e∗−ε∗)∥2 + ∥Lx(x −x∗)∥2 + ∥Lpβp∥2
(32.31)
where the last term is brought by the technical approximation of mutual uncorrelatedness of (x, εp)
and thus (x, βp), and where we have made the normal approximation for βp with

656
J. Kaipio and V. Kolehmainen
Lp = diag (λ−1/2
1
, . . . , λ−1/2
p
).
(32.32)
Furthermore, we can approximate Le+ε−p ≈Le = δ−1I
32.4.3 Orthogonal iterations for computation of low rank
approximation for the eigensystem
The orthogonal iteration is a Krylov subspace method, and yields p eigenvectors (corresponding
to the largest eigenvalues) of a m × m symmetric positive semidefinite matrix D = ε, see for
example [15]. In our case (low rank representation for the covariance), the orthogonal iteration
algorithm works as follows.
Define the sequence of matrices V(k) with V(0) = Im×p or other matrix with linearly indepen-
dent columns (or, better still, a good guess for the eigenvectors).
for k = 1...d
(Q,R) = qr(V(k-1));
V(k) = DQ;
end
(V,R) = qr(V(d))
Of course, if D were obscenely large and we don’t have this, there would be a problem. But in
our case, we can again use parentheses (and abuse notations): V = DQ = ¯V( ¯VTQ) which is fine,
since ¯VTQ is (q × m) × (m × p) = q × p. Here, ¯V is the centred and normalized sample matrix
as in (32.30). The limit V(k) →Vp has the p eigenvectors. The eigenvalues are obtained from the
diagonal of VTp εVp = VTp ¯V ¯VTVp = (VTp ¯V) · ( ¯VTVp).
32.5 Case study 1. Application to local tomography
32.5.1 Local X-ray tomography
The problem of local tomography is to reconstruct a region of interest (ROI) inside a target body
based on a set of truncated X-ray projection images [40, 52]. In medical imaging, the truncation
of the projection images is typically enforced by intentional minimization of the ionizing radiation
dose to the patient. The principle of local tomography is illustrated in Figure 32.2. In the conven-
tional (global) computerized tomography (CT) problem, the whole target body is fully visible in
all of the X-ray projection images. In the local tomography problem, only part of the target (ROI) is
visible in all projections, which is shown as a dark grey patch in Fig. 32.2. For the X-ray tomography
problem and the local tomography problem, see [11, 37, 40, 52].
For the construction of the measurement model, we consider the global tomography problem
as the starting point. We follow the direct discretization formulation that enables also the further
limited-angle limitation of X-ray tomography, see for example [28]. The domain of the unknown
attenuation density function is modelled by a bounded subset  ⊂R2 together with a non-
negative attenuation coefficient x(r) :  →[0, ∞). The domain  is chosen large enough so that
thebodyunderinvestigationiscompletelyinsidethedomain,thatis,supp(x(r)) ⊂.TheX-ray
attenuation measurement is commonly modelled by the line integral

γ
x(r) dr = log I0 −log I1
(32.33)

Approximate marginalization over modelling errors
657
X−ray source
X−ray detector plane
roi
X−ray source
X−ray detector plane
Figure 32.2 Global (left) and local (right) tomography. The source and detector panel rotate around
the object along the dotted circle. In the right-hand image, the dark grey patch represents the ROI
subdomain that is present in all of the projection images in the local tomography case. In local
tomography, only the ROI is to be reconstructed, with a minimal number of projection data.
where γ is the line between the source and detector points, I0 is the source intensity and I1 is
the attenuated intensity at the detector. In the discretization of the problem, the domain  is
divided into n disjoint pixels Di so that  = >n
i=1 Di and the function x(r) is approximated with
a piecewise constant function with x|Di ≡xi, leading to the approximation

γ
x(r) dr ≈
n

i=1
xi |Di ∩ξ|
(32.34)
for the line integral in (32.33). Arranging the pixels into a column vector x = (x1, x2, . . . , xn)T ∈
Rn and all the measured line integrals in the X-ray tomography experiment into ˜d = (d1, d2, . . . ,
dmg)T ∈Rmg, we get the model
˜d = ˜Ax + ˜e
(32.35)
fortheglobaltomographyproblem.Here,nischosenlargeenoughsothat(32.35)canbeconsidered
an accurate model for the global tomography experiment. The measurement noise e can be taken
to be normal mutually independent random variables but with different variances [3, 51].
Consider now the local tomography problem. Decompose the domain into two disjoint subdo-
mains as  = 0 + 1, where 1 is the region of interest (ROI) and 0 consists of the rest of the
image domain, that is, the uninteresting part. Given the global tomography data and model (32.35),
a textbook description of local tomography can be stated such that the objective is to estimate
x ∈Rn in  using a subset d = ˜d(I1) ∈Rm of the complete (global) data, where the index set
I1 ⊂{1, 2, . . . , m} indicates the subset of line integrals that intercept the ROI, that is, j ∈I1 if
|γj
? 1| > 0. Thus, we have projection model
d = ¯Ax + e
(32.36)
where ¯A is m × n block of ˜A such that ¯A := ˜A(I1, :). Note that model (32.36) is an accurate projec-
tion model for local tomography in the sense that the unknown attenuation coefficient is modelled

658
J. Kaipio and V. Kolehmainen
in the whole domain . We note that the reconstruction of the entire x from this partial data d is
inherently a non-unique problem.
32.5.2 Approximation error model for local tomography
A complication with the model (32.36) is the high computational cost induced by the large dimen-
sion of x. Obviously, since in local tomography one is interested in the ROI only, it would be
computationally appealing to reduce the model (32.36) by decomposing x into interesting and
uninteresting parts as
x = x|0 + x|1 := x0 + x1,
x0 ∈Rn0, x1 ∈Rn1,
n0 + n1 = n
and write the accurate measurement model as
d = ¯Ax + e = A0x0 + A1x1 + e
and then estimate the interesting part x1 ∈Rn1 from the truncated model
d ≈A1x1 + e.
(32.37)
Here, the matrices A0 and A1 are blocks of ¯A such that A0 := ¯A(:, J0) and A1 := ¯A(:, J1) where
the index sets J0 and J1 correspond to the subsets of pixels inside the domains 0 and 1,
respectively. However, the model (32.37) employing equality in place of ‘≈’ is severely erroneous,
since the attenuation of the rays in 0 is not modelled. Effectively, we would be writing A0x0 ≈0,
andastheresult,thelikelihoodandtheposteriormodelswouldbegrosslyinfeasible,seeanexample
of a marginal posterior of a single pixel in Figure 32.1.
In the following, we marginalize the local tomography problem with respect to the uninteresting
variable x0 using the approximation error approach. For this, we write the accurate model as
d = A1x1 +
¯Ax −A1x1

+ e = A1x1 + ε + e
(32.38)
where the discrepancy ε between the accurate model ¯Ax and truncated model A1x1 is the approx-
imation error. Obviously, we have in this case ε = A0x0.
32.5.3 The employed MRF prior model
WeuseaproperGaussiansmoothnesspriorfortheunknownimagex,constructedasin[24,27,30].
In this construction, x is considered in the form
x = xin + xbg
where xin is a spatially inhomogeneous coefficient47 with zero mean, and xbg is a spatially homoge-
neous (background) coefficient. For the latter, we can write xbg(r) = sI, where I is a vector of ones
and s is a scalar random variable with distribution s ∼N(x∗, ζ2
bg). With respect to the basis for
x, we have the coordinates xin ∈Rn and set xin ∼N(0, in). We model the spatial distributions
xin and sI as mutually independent, that is, the background is mutually independent with the
inhomogeneities.
47 In the sequel, ‘in’ refers to inhomogeneous, ‘bg’ to background.

Approximate marginalization over modelling errors
659
Figure 32.3 Two samples x(ℓ) from the prior model π(x).
Thus, we have x = in + ζ 2
bgIIT, and
π(x) = N(x∗I, x)
(32.39)
In the construction of in, the approximate correlation length can be adjusted to match the size
of the expected inhomogeneities. See [24, 27, 30] for details of the construction and [48] for
construction of Markov random fields in general.
In the construction of the model for the data considered in this chapter, the prior parameters
were set as follows. For the background attenuation, the mean was set as x∗= 0 and the stan-
dard deviation as ζbg = 0.005. For the inhomogeneity part, the target correlation length was set
to 7 mm and the standard deviation ζin = 0.05. Figure 32.3 shows two random draws from the
prior (32.39).
Note that the interesting and uninteresting parts x1 and x0 can be modelled as projections x1 =
P1x and x0 = P0x, and the corresponding marginal priors can be obtained respectively as
π(xℓ) = N(xℓ,∗, xℓ),
xℓ,∗= Pℓx∗,
xℓ= PℓxPT
ℓ, ℓ= 0, 1.
32.5.4 Experimental setup and projection models
ArealizationofglobaltomographyX-rayprojectiondatawasmeasuredfromatoothspecimenusing
a commercial dental X-ray source, dental CCD X-ray detector and a rotating platform. The mea-
surement equipment was arranged such that the experiment corresponds to the global tomography
illustrated in the left image in Figure 32.2. For more details on the experimental setup, see [28].
We took 23 equi-angularly spaced projection images of the tooth specimen from a total view-angle
of 187 degrees and extracted one slice of this data to form a 2D tomography problem, resulting in
global tomography data ˜d with mg = 15 272. For the distribution of the measurement noise, we
use approximation
π(e) = N(0, e),
e = δ2I
where the standard deviation δ of the noise was estimated using empty (i.e. air) regions around the
tooth specimen in the projection images.
For the discretization of the global projection model ˜A in equation (32.35), the domain  was
chosen as 12 × 12mm2 square and this domain was divided into n = 96 × 96 = 9216 regular
pixels. Thus, the size of ˜A is 15 272 × 9216.

660
J. Kaipio and V. Kolehmainen
In the construction of the accurate local tomography model ¯A, we chose the region of interest
1 as a square domain that encloses one of the two roots of the tooth specimen, and formed the
local tomography data by determining the subset d = ˜d(I) of measured X-rays that intercept the
chosen ROI. This resulted in the data d ∈R3964 and projection matrix ¯A := ˜A(I1, :) with size
3964 × 9216.
For the construction of the truncated model (32.37), we determined the index set J1 of the
pixels that belong to 1, and formed the truncated projection matrix A1 := ¯A(:, J1) with size of
3964 × 1681 (i.e. the number of unknowns is n1 = 1681 in the truncated projection model).
32.5.5 Results
Figure 32.4 shows the MAP estimates with different measurement models for the global and local
X-ray tomography example. Top row displays the estimates in the whole image domain . For the
estimates (columns 3–5) that are based on the truncated projection model A1, the (uninteresting)
outside of the ROI domain 0 which is not included in the projection model is displayed with
constant grey value. The bottom row shows the ROI details 1 from the estimates.
The columns from the left to right show the following MAP estimates:
1. Global tomography MAP estimate using all the available data, i.e. measurement model
(32.35):
ˆx = arg min
x

∥L˜e(˜d −˜Ax)∥2 + ∥Lx(x −x∗)∥2
(32.40)
where LT
˜e L˜e = −1
˜e
,
LTx Lx = −1
x . This estimate serves for the local tomography esti-
mates as the ‘ground truth’ reference.
1
2
3
4
5
Figure 32.4 Estimates from X-ray projection data from a tooth specimen (23 projections from a
view angle of 187 degrees). Columns from left to right: Global tomography, local tomography with
accurate model ¯Ax, local tomography with (truncated) model A1x1 and conventional measurement
error model, local tomography with model A1x1 and the approximation error model, local tomography
with model A1x1 and the high-dimensional modification of the approximation error model. Top row:
estimate in whole domain  (for the cases with the truncated model A1x1, the uninteresting subdo-
main 0 that is not estimated is displayed with constant value). Bottom row: ROI detail 1 from the
estimates.

Approximate marginalization over modelling errors
661
2. Local tomography with accurate measurement model (32.36):
ˆx = arg min
x

∥Le(d −¯Ax)∥2 + ∥Lx(x −x∗)∥2
(32.41)
whereLTe Le = −1
e
,
LTx Lx = −1
x .Thisestimateservesasreferenceoflocaltomography
usingaccurateprojectionmodel.Notethattherestriction ˆx|1 fromthisestimateistheexact
marginal MAP for x1.
3. Local tomography with truncated projection model and conventional measurement error
model (32.37):
ˆx1 = arg min
x1

∥Le(d −A1x1)∥2 + ∥Lx1(x1 −x1,∗)∥2
(32.42)
where LTx1Lx1 = −1
x1 . This is the straightforward trivial approach corresponding to setting
x0 = 0.
4. Local tomography with truncated projection model and approximation error model (32.37):
ˆx1 = arg min
x1

∥Lν|x(d −A1x1 −ν∗|x)∥2 + ∥Lx1(x1 −x1,∗)∥2
(32.43)
where ν∗|x is given by equation (32.21) and Lν|x by equation (32.22). Notice that since the
problemislinearandGaussian,allthetermsinequations(32.21)and(32.22)haveclosed-form
solutions.
5. Local tomography with (augmented) high-dimensional modification of the approximation
error model (32.31):
( ˆx1, ˆβp) = arg min
x1,βp

∥Le(y −A1x1 −Vpβp −ε∗)∥2
+ ∥Lx1(x1 −x1,∗)∥2 + ∥Lpβp∥2
(32.44)
where Lp is defined by equation (32.32). To demonstrate the performance of the high-dimen-
sional modification, sample based approximations are used for ε∗and ε, computed based
on 500 samples ε(ℓ) = ¯Ax(ℓ) −A1P1x(ℓ). The dimension p is selected by q
k=p+1 λk ⪅
0.2mδ2 and the approximation e + ε,−p ≈e is used.
When the estimate is computed using the truncated projection model A1 and conventional mea-
surement error model, the estimate (third column) shows stripe-like artefacts in the whole ROI
and spiky high amplitude errors near the boundary of the ROI. These errors are due to neglecting
the contribution of the tissues outside the ROI to the measured projections. Loosely speaking,
discrepancybetweentheprojectionmodelandmeasurementsiscompensatedintheMAPestimate
with spurious details in the ROI domain 1. The estimate (32.43) with the approximation error
model(fourthcolumn),ontheotherhand,isclearoftheseartefactsandtheestimateoftheROIcor-
respondtotheglobaltomographyreference(first column)andis equal(withinnumericalroundoff
errors, relative error ∼10−10) to the MAP of exact marginal posterior (i.e. the ROI part ˆx|1 from
the estimate (32.41)). Comparing the estimate (32.44) (fifth column) with the high-dimensional
(augmented) modification of the approximation error model to the ‘conventional’ approximation
error estimate (fourth column), one can see that the estimates are very similar despite the fact that
the augmented form uses the approximation xε = 0 and is based on using a sample based, low-
dimensional approximation for the covariance ε. This suggests that the augmented formulation

662
J. Kaipio and V. Kolehmainen
in Section 32.4 could be applied also in the very high-dimensional 3D local tomography case in
which the explicit construction of the approximation error covariance matrix is computationally
not feasible.
32.6 Case study 2. Inaccurately known body shape
in electrical impedance tomography
32.6.1 Electrical impedance tomography (EIT)
In EIT, the objective is to estimate the unknown conductivity function inside a body based on
electric current and voltage measurements at the exterior boundary of the body. The medical
applications of EIT include, for example, the detection of tumours from breast tissue and bedside
monitoring of pulmonary function of intensive care patients [4, 13, 58, 61]. For reviews on the EIT
problem, see [7, 26].
One of the practical challenges in medical EIT is that the boundary of the body is usually not
known. As an example, consider EIT measurements of monitoring pulmonary function from the
surface of the thorax. In principle, the shape of the patient’s thorax could be obtained from other
imaging modalities such as computerized tomography (CT) but such measurement is usually not
available(e.g.thepatientcannotbetransferredawayfromtheintensivecare).Inaddition,theshape
of the thorax varies in time due to breathing and also depends on the orientation (posture) of the
patient. Therefore, the body shape would be inaccurately known even at best and the estimation
of the conductivity has to be carried out using an approximate model domain. On the other hand,
it is well known that the use of an incorrect model for the body shape leads to serious artefacts
in the conductivity images, see for example [14, 31]. In practical biomedical EIT, only so-called
difference imaging is usually attempted. In this modality, only a very rough qualitative image can
be constructed, but, on the other hand, the unknown boundary shape has less drastic effect, see for
example [1].
Inthefollowing,weconsidertheapproximatepre-marginalizationovertheunknownbodyshape
by the approximation error approach. Furthermore, we describe how the high-dimensional mod-
ification (augmented form) of the approximation error approach in Section 32.4 can be used to
recover an approximation for the unknown body shape based on the low rank estimate εp of the
approximation error.
32.6.2 Forward model of EIT
Let  ⊂R3 denote the measurement domain and let γ denote a parameterization of the domain
boundary∂.InEIT,anarrayofNel contactelectrodesareattachedontheboundary∂.Usingthe
electrodes,electriccurrents(calledcurrentpatterns)areinjectedintothebody(volumeconductor)
andtheresultingvoltagesaremeasuredusingthesameelectrodes.Wemodelthesemeasurements
with the complete electrode model [8, 53]:
∇· σ(x)∇u(x) = 0,
x ∈
(32.45)
u(x) + zℓσ(x)∂u(x)
∂n
= Uℓ,
x ∈eℓ⊂∂,
(32.46)

eℓ
σ(x)∂u(x)
∂n dS = Iℓ,
x ∈eℓ⊂∂,
(32.47)

Approximate marginalization over modelling errors
663
σ(x)∂u(x)
∂n
= 0,
x ∈∂ \
Nel
@
l=1
eℓ.
(32.48)
where u(x) is the potential distribution in , n is the outward unit normal vector at ∂, σ(x)
is the conductivity, and zℓis the contact impedance between the object and the electrode eℓ.
The existence and uniqueness of the solution of the boundary value problem (32.45–32.48) are
quaranteed by
Nel

ℓ=1
Iℓ= 0,
Nel

ℓ=1
Uℓ= 0
(32.49)
where the former constraint is the conservation of charge and latter fixes ground level for the
voltages.
In the following, the numerical approximation of the boundary value problem (32.45–32.49) is
based on the finite element (FEM) approximation, for details of the implementation used in this
chapter, see [26, 57]. In the following, we use notation
U(σ, γ ) ∈Rm
(32.50)
for the FEM based forward solution corresponding to single EIT experiment, that is, the vector
U(σ, γ ) contains computed voltages for all thecurrent patterns in themeasurement paradigm. The
dependence of the forward model on the domain  is expressed by the parameterization γ of the
boundary ∂.
32.6.3 Approximation error model
Let
V = U(¯σ, γ ) + e,
(32.51)
denote a (sufficiently) accurate model between the unknowns and measurements. Here the param-
eters γ of the boundary ∂ are such that the error in the FEM approximation is smaller than the
measurement error (in the sense defined in Section 32.4). The conductivity ¯σ is a parameterization
in the actual  and is dense enough in the above sense.
As explained above, in practical clinical measurements one usually lacks accurate knowledge of
theshapeof thebody  andthereforetheestimation ofσ is carried out usingan approximatemodel
domain ˜. In such a case, the accurate model (32.51) is traditionally replaced by the approximate
measurement model:
V ≈U(σ, ˜γ ) + e
(32.52)
where ˜γ are the parameters of the boundary ∂˜ of the model domain, and one hopes that the
approximation in (32.52) is a feasible one.
The relation of the representation of the conductivities in (32.51) and (32.52) is of the form
¯σ(x) = σ(T(x)), where
T :  →˜
(32.53)

664
J. Kaipio and V. Kolehmainen
is a mapping that models the deformation of domain  to ˜. Obviously, the true deformation T
between the measurement domain and model domain is not known and not unique, and one has
to choose a model for the deformation. In the numerical examples considered in this chapter, T is
chosen such that the angle and relative distance (between the center of the domain and the bound-
ary) of a coordinate point is preserved. The deformation of the conductivity can be numerically
implemented by a linear interpolation
P¯σ = σ,
(32.54)
where P is a matrix that interpolates the conductivity from  into ˜ according to the deforma-
tion T.
We write the accurate measurement model (32.51) in the form
V = U(σ, ˜γ ) + (U(¯σ, γ ) −U(σ, ˜γ )) + e = U(σ, ˜γ ) + ε(¯σ, γ ) + e,
(32.55)
where ε(¯σ, γ ) represents the modelling error due to the incorrect boundary, and we denote
ν = ε + e.
32.6.4 The EIT experiment
The EIT data was measured from a vertically symmetric measurement tank , see Fig. 32.7. Sixteen
equally spaced stainless steel electrodes were attached on the boundary ∂ of the tank. The (incor-
rect) model domain ˜ was a cylinder with diameter equivalent to the diameter of the measurement
domain, see Fig. 32.5. The heart and lung shaped inclusions in the target were made of agar and
placed in the chest-shaped tank filled with saline of conductivity 3.0 mS cm−1. The conductivity of
the lung and heart targets were 0.73 mS cm−1 and 5.8 mS cm−1, respectively.
The measurements were carried out with the KIT 4 EIT device using adjacent electrode current
patterns measurement paradigm, leading to m = 256 voltage measurements, see [32] for details of
the measurement system. For the estimation of measurement error statistics, 40 000 realizations
were measured and a sample based Gaussian approximation π(e) = N(e∗, e) was constructed,
for details see [45].
Figure 32.5 Left: The cross-section of the actual domain  is shown as a grey patch. The shape
of the domain was extracted from a segmented CT image of the thorax. The cross-section of the
cylindrical model domain ˜ is shown as a solid line. Right: Arrangement of lung and heart phantoms
in the measurement tank.

Approximate marginalization over modelling errors
665
32.6.5 Prior models and construction of approximation error
statistics
As the prior model π(σ), we use a proper Gaussian smoothness prior π(σ) = N(σ∗I, σ ). with
σ = in + ζ 2
bgIIT constructed similarly to Section 32.5.3. The correlation length in the prior
model was set to 7 cm. The other prior parameters were set as follows. The prior mean was set
to the conductivity of the saline background, that is, σ∗= 3.0 mS cm−1, ζin = 0.6 mS cm−1, and
ζbg = 0.15 mS cm−1.
As the prior model π(γ ) we use a sample based Gaussian approximation that is constructed
based on an atlas of chest CT images of npr = 150 different individuals in the population. Since the
measurement tank in this example is translationally symmetric, we simplified the implementation
procedure by treating the translationally symmetric boundary shape by a 2D parameterization.
For this, the CT images were segmented to interior and exterior of the body domain, leading
to ensemble of chest domains {(ℓ), ℓ= 1, 2, . . . , npr}. To obtain the corresponding parametric
representations for the chest boundaries {∂(ℓ)}, we extracted the boundaries {∂(ℓ)} from the
segmented CT images and then computed a Fourier series representation with nf = 20 terms for
the boundaries. Thus, we obtained an ensemble {γ (ℓ), ℓ= 1, . . . , npr} of parametric representa-
tions of chest shapes. Using the ensemble, we approximate the prior model π(γ ) by a sample based
normal distribution π(γ ) ≈N(γ∗, γ ).
32.6.5.1 Estimation of the approximation error statistics
Fortheestimationofapproximationerrorstatistics,wegeneratedasetofnsamp = 1000drawsfrom
the prior models π(γ ) and π(¯σ) similarly as explained in Section 32.3.4. Figure 32.6 shows a central
cross-section from four samples {¯σ (ℓ)} on the sample domains {γ (ℓ)}. The samples were used for
the computation of the samples ε(ℓ) of the approximation error as
ε(ℓ) = U(¯σ(ℓ), γ (ℓ)) −U(σ (ℓ), ˜γ )
Figure 32.6 Cross-sections from four samples {¯σ (ℓ), (ℓ)} for the construction of the approximation
error model. The sample domains {(ℓ)} are from an ensemble of chest CT images of different
individuals and the conductivities are drawn from the prior model π(¯σ).

666
J. Kaipio and V. Kolehmainen
where σ (ℓ) = P(ℓ) ¯σ (ℓ) The second-order statistics of the modelling errors were then estimated as
sample based averages to obtain the normal approximation π(ε) ≈N(ε∗, ε).
32.6.6 Results
The MAP estimates with different measurement error models are shown in Fig. 32.7. The images
that are shown, are the central horizontal cross-sections of the estimated 3D conductivity. The
images are arranged as follows:
• (top left) Photograph of the target conductivity σtrue.
• (top right) MAP estimate with conventional measurement error model
ˆσ = arg min
¯σ≥0

∥Le(V −U(¯σ, γ ) −e∗)∥2 + ∥L¯σ (¯σ −¯σ∗)∥2
(32.56)
in the correct domain  (forward model U(¯σ, γ )). This estimate serves as reference when
domain boundary is modelled with sufficient accuracy so that the modeling errors are negli-
gible.
• (bottom left) MAP estimate with the conventional measurement error model
ˆσ = arg min
σ≥0

∥Le(V −U(σ, ˜γ ) −e∗)∥2 + ∥Lσ (σ −σ∗)∥2
(32.57)
in the model domain ˜ (forward model U(σ, ˜γ )), representing conventional estimate in
presence of domain modelling errors.
Figure 32.7 Top left: The measurement tank. Top right: MAP estimate using conventional measure-
ment error model and the correct domain . Bottom left: MAP using the conventional measurement
error model and incorrect model domain ˜. Bottom middle: MAP using the approximation error
model and domain ˜. Bottom right: MAP with the augmented approximation error approach using
domain ˜. The images show the central horizontal cross-sections from the 3D reconstructions.

Approximate marginalization over modelling errors
667
• (bottom middle) MAP with the approximation error model
ˆσ = arg min
σ≥0

∥Le+ε(V −U(σ, ˜γ ) −e∗−ε∗)∥2 + ∥Lσ (σ −σ∗)∥2
(32.58)
in the model domain ˜ (forward model U(σ, ˜γ )). Here we use the approximation (32.29)
and set LT
e+εLe+ε = −1
ε+e.
• (bottom right) MAP with the high-dimensional (augmented) modification of the approxi-
mation error model using the model domain ˜. Here the use of the augmented form is not
motivatedbythedimensionofthedata,butweinsteadseektoobtainanapproximaterecovery
of the domain shape from the (low rank) estimate ˆεp of the approximation error. For this, we
estimate (ˆσ, ˆβp) from
(ˆσ, ˆβp) = arg min
σ≥0,βp

|| Le+ε,−p(V −U(σ, ˜γ ) −Vpβp −ε∗−e∗) ||2
+ || Lσ (σ −σ∗) ||2 + || Lpβ ||2
,
(32.59)
Given ˆβp, the estimate for γ is computed by forming a normal approximation for the joint
density of εp = Vpβp and γ and finding the MAP estimate ˆγ = arg max ˜π(γ |ˆεp), given by
ˆγ = γ εp−1
ε,p ˆεp + γ∗,
(32.60)
where ˆεp = Vp ˆβp. Approximate spread estimates for the boundary shape are obtained from
the covariance of ˜π(γ |ˆεp), given by
 ˆγ |ˆεp = γ −γ ε,p−1
ε,p T
γ ε,p.
(32.61)
Notethattheestimate(32.59)oftheconductivityσ andtheprojectioncoefficientsβ iscarried
out in the (incorrect) model domain ˜.
Once the estimates of σ, β and ˆγ have been computed, the estimated conductivity σ
is mapped from the model domain ˜ into the reconstructed domain ˆ (that corresponds
to estimated ˆγ ) by a linear interpolation ¯σ = ˜Pˆσ, where ˜P implements interpolation from
domain to another according to the inverse T−1 of the domain deformation model.
The nonlinear minimization problems for the computation of the different MAP estimates were
solved with the Gauss–Newton algorithm using a line search algorithm [47].
Figure 32.8 shows the estimated boundary (32.60) and two standard deviation limits for the
posterior ˜π(γ |ˆεp) with dashed line and the true measurement domain  with grey patch.
The MAP estimate in which the incorrect model domain is used but the approximation error is
not accounted for (bottom left), shows infeasible estimation errors. In contrast, the MAP estimate
in which the approximation errors are accounted for (bottom middle), is mostly free of these arte-
facts and gives a deformed image of the conductivity in the model domain ˜. The MAP estimate
with the augmented form of the approximation error model (bottom right), on the other hand, is
almost as good as the reference estimate in the correct domain (top right). The shape of the domain
also has been found quite well, and moreover, the approximate posterior spread estimates for the
boundary shape are feasible. In addition to the reconstruction of the shapes of the organs, the actual
conductivity values also match the reality quite well.

668
J. Kaipio and V. Kolehmainen
Figure 32.8 The cross-section of the actual domain  is shown as a grey patch. The estimated
boundary with the augmented approximation error model is shown with a solid line and two posterior
(approximate) standard deviation limits for the approximate posterior ˜π(γ |ˆεp) with dashed lines.
32.7 Discussion
Inverseproblemsareknowntotoleratemeasurementandmodellingerrorspoorly.Intermsofstatis-
tics,thismeansthat(unaccounted-for)errorsanduncertaintiesshifttheentireposteriorprobability
mass away from the actual values, possibly drastically. While the uncertainties can be handled in
several ways, most of the approaches require such computational complexity that renders these
as academic exercises. In particular, modelling all uncertainties as unknowns and carrying out
inference for all these using MCMC, is completely out of the question in most practical inverse
problems with continuous data streams.
In this chapter, we have discussed the so-called approximation error approach, which was orig-
inally meant to model numerical model reduction only. The approach is based on a number of
consecutive approximations for the associated models and densities, based on Bayesian modelling
of all uncertainties, approximations and unknowns. The aim is to end up with highly approximative
‘dirty but fast’ computational models, which are, however, feasible in the sense that the actual
unknowns should lie within a couple of approximate credibility intervals.
The approach has been shown to be feasible for a number of modelling errors and uncertain-
ties, including drastic model reduction, unknown geometry and boundary conditions and highly
approximate physical models. The approach has also been shown to provide feasible spread esti-
mates, and thus enable, for example, optimal stochastic (feedback) control.
The approach calls for sometimes extensive simulations using relatively accurate computational
models and is computationally heavy in this sense. All of these computations are, however, precom-
putations, and the online real-time calculations are fast and efficient. With a particular application,
it is difficult to predict how well the approach will work. The linear normal case is an exception.
Thus, it currently seems that the only way to find this out, is to construct all the required models
and carry out simulations and then tests with real data.
Acknowledgements
The authors would like to thank Antti Nissinen (PhD) for the figures of the EIT example. The work
wassupportedbytheAcademyofFinlandprojects119270,140731,218183andprojects213476,250215,
Finnish Centre of Excellence in Inverse Problems Research for 2006–2011 and 2012–2017.

Approximate marginalization over modelling errors
669
References
[1] Adler, A., Guardo, R. and Berthiaume, Y. (1996). Impedance imaging of lung ventilation: Do
we need to account for chest expansion? IEEE Trans. Biomed. Eng., 43, 414–420.
[2] Arridge, S. R., Kaipio, J. P., Kolehmainen, V., Schweiger, M., Somersalo, E., Tarvainen, T. and
Vauhkonen, M. (2006). Approximation errors and model reduction with an application in
optical diffusion tomography. Inverse Probl, 22, 175–195.
[3] Bouman, C. and Sauer, K. (1993). A generalized Gaussian image model for edge-preserving
map estimation. IEEE Trans. Image Process, 2, 296–310.
[4] Boverman, G., Kao, T.-K., Kulkarni, R., Kim, B. S., Isaacson, D., Saulnier, G. J. and Newell,
J.C.(2008).Robustlinearizedimagereconstructionformultifrequenceeitofthebreast.IEEE
Trans. Med. Im., 27, 1439–1448.
[5] Calvetti, D., Kaipio, J. P. and Somersalo, E. (2006). Aristotelian prior boundary conditions.
International Journal of Mathematics, 1, 63–81.
[6] Calvetti, D. and Somersalo, E. (2007). An Introduction to Bayesian Scientific Computing Ten
Lectures on Subjective Computing. Springer. ISBN 978-0-387-73393-7.
[7] Cheney, M., Isaacson, D. and Newell, J. C. (1999). Electrical impedance tomography. SIAM
Rev, 41, 85–101.
[8] Cheng,K.-S.,Isaacson,D.,Newell,J.C.andGisser,D.G.(1989).Electrodemodelsforelectric
current computed tomography. IEEE Trans. Biomed. Eng., 36, 918–924.
[9] Doucet, A., de Freitas, N. and Gordon, N. (2001). Sequential Monte Carlo Methods in Practice.
Springer.
[10] Duncan, S., Ruuskanen, J. P., Kaipio, A., Malinen, M. and Seppanen, A. (2005). Control
systems. In Handbook of Process Imaging for Automatic Control (ed. D. Scott and H. McCann),
pp. 237–262. CRC Press.
[11] Faridani, A., Finch, D. V., Ritman, E. L. and Smith, K. T. (1997). Local tomography II. SIAM
J. Appl. Math., 57, 1095–1127.
[12] Fox, C. and Nicholls, G. (1997, 1-4 July). Sampling conductivity images via MCMC. In “The
art and science of Bayesian image analysis”. Proceedings of the Leeds annual statistics research
workshop (ed. K. V. Mardia, C. A. Gill, and R. G. Aykroyd), Leeds, UK, pp. 91–100. Leeds
university press.
[13] Frerichs, I. (2000). Electrical impedance tomography (eit) in applications related to lung and
ventilation: a review of experimental and clinical activities. Physiol. Meas., 21, R1–R21.
[14] Gersing, E., Hoffmann, B. and Osypka, M. (1996). Influence of changing peripheral geom-
etry on electrical impedance tomography measurements. Med. Biol. Eng. Comput., 34,
359–361.
[15] Golub, G. H. and van Loan, C. F. (1996). Matrix Computations, Volume 3rd. The Johns Hop-
kins University Press, Baltimore, MD.
[16] Heino, J. and Somersalo, E. (2004). A modelling error approach for the estimation of optical
absorption in the presence of anisotropies. Phys Med Biol, 49, 4785–4798.
[17] Heino, J., Somersalo, E. and Kaipio, J. P. (2005). Compensation for geometric mismodelling
by anisotropies in optical tomography. Optics Express, 13(1), 296–308.
[18] Huttunen, J. M. J. and Kaipio, J. P. (2007). Approximation error analysis in nonlinear state
estimation with an application to state-space identification. Inverse Problems, 23, 2141–2157.
[19] Huttunen, J. M. J. and Kaipio, J. P. (2007). Approximation errors in nostationary inverse
problems. Inverse Problem and Imaging, 1(1), 77–93.
[20] Huttunen, J. M. J. and Kaipio, J. P. (2009). Model reduction in state identification problems
with an application to determination of thermal parameters. Applied Numerical Mathemat-
ics, 59, 877–890.

670
J. Kaipio and V. Kolehmainen
[21] Huttunen, J. M. J., Lehikoinen, A., Hämäläinen, J. and Kaipio, J. P. (2009). Importance filter-
ing approach for the nonstationary approximation error method. Inverse Problems. in review.
[22] Jolliffe, I. T. (1986). Principal Component Analysis. Springer-Verlag.
[23] Kaipio, J. P., Duncan, S., Seppanen, A., Somersalo, E. and Voutilainen, A. (2005). State esti-
mation. In Handbook of Process Imaging for Automatic Control (ed. D. Scott and H. McCann),
pp. 207–235. CRC Press.
[24] Kaipio, Jari and Somersalo, Erkki (2005). Statistical and Computational Inverse Problems.
Springer-Verlag.
[25] Kaipio, J. and Somersalo, E. (2007). Statistical inverse problems: discretization, model reduc-
tion and inverse crimes. J Comput Appl Math, 198.
[26] Kaipio, J. P., Kolehmainen, V., Somersalo, E. and Vauhkonen, M. (2000). Statistical inversion
and Monte Carlo sampling methods in electrical impedance tomography. Inverse Probl, 16,
1487–1522.
[27] Kolehmainen, V., Schweiger, M., Nissilä, I., Tarvainen, T., Arridge, S. R. and Kaipio, J. P.
(2009). Approximation errors and model reduction in three-dimensional diffuse optical
tomography. J. Opt. Soc. Am., 26(10), 2257–2268.
[28] Kolehmainen, V., Siltanen, S., Järvenpää, S., Kaipio, J. P., Koistinen, P., Lassas, M., Pirttilä, J.
and Somersalo, E. (2003). Statistical inversion for medical x-ray tomography with few radio-
graphs ii: Application to dental radiology. Phys. Med. Biol., 48, 1465–1490.
[29] Kolehmainen, V., Tarvainen, T., Arridge, S. R. and Kaipio, J. P. (2010). Marginalization of
uninterestingdistributedparametersininverseproblems–applicationtoopticaltomography.
Int J Uncertainty Quantification. In review.
[30] Kolehmainen, V., Tarvainen, T., Arridge, S. R. and Kaipio, J. P. (2011). Marginalization of
uninterestingdistributedparametersininverseproblems–applicationtoopticaltomography.
Int. J. Uncertainty Quantification, 1(1), 1–17.
[31] Kolehmainen, V., Vauhkonen, M., Karjalainen, P. A. and Kaipio, J. P. (1997). Assessment of
errors in static electrical impedance tomography with adjacent and trigonometric current
patterns. Physiol. Meas., 18, 289–303.
[32] Kourunen, J., Savolainen, T., Lehikoinen, A., Vauhkonen, M. and Heikkinen, L. M. (2009).
Suitability of a pxi platform for an electrical impedance tomography system. Meas. Sci. Tech-
nol., 20, 015503.
[33] Lehikoinen, A., Finsterle, S., Voutilainen, A., Heikkinen, L. M., Vauhkonen, M. and Kaipio,
J.P.(2007).Approximationerrorsandtruncationofcomputationaldomainswithapplication
to geophysical tomography. Inverse Probl Imaging, 1, 371–389.
[34] Lehikoinen, A., Huttunen, J. M. J., Finsterle, S., Voutilainen, A., Kowalsky, M. B. and Kaipio,
J. P. (2010). Dynamic inversion for hydrological process monitoring with electrical resistance
tomography under model uncertainties. Water Resources Res, 46, W04513. In press.
[35] Lehikoinen, A., Huttunen, J. M. J., Voutilainen, A., Finsterle, S., Kowalsky, M. B. and Kaipio,
J. P. (2009). Dynamic inversion for hydrological process monitoring with electrical resistance
tomography under model uncertainties. Water Resources Res. In press.
[36] Lipponen,A.,Seppänen,A.andKaipio,J.P.(2009).Nonstationaryinversionofconvection-d-
iffusion problems – recovery from unknown nonstationary velocity fields. Inverse Probl. In
review.
[37] Maass, P. (1992). The interior radon transform. SIAM J. Appl. Math., 52, 710–724.
[38] Mannington, W. O’Sullivan, M. J. and Bullivant, D. P. (2004). Computer modelling of the
wairakei-tauhara geothermal system. Geothermics, 33, 401–419.
[39] Mota, C. A. A., Orlande, H. R. B., Carvalho, M. O. M., Kolehmainen, V. and Kaipio,
J. P. (2010). Bayesian estimation of temperature-dependent thermophysical properties and
boundary heat flux. Heat Transfer Eng, 31, 570–580.
[40] Natterer, F. (1986). The Mathematics of Computerized Tomography. Wiley, Philadelphia.

Approximate marginalization over modelling errors
671
[41] Nicholls,G.K.(1998).BayesianimageanalysiswithMarkovchainMonteCarloandcoloured
continuum triangulation models. J Royal Statistical Society B, 60, 643–659.
[42] Nissinen, A., Heikkinen, L. M. and Kaipio, J. P. (2008). The Bayesian approximation error
approach for electrical impedance tomography—experimental results. Meas. Sci. Technol., 19,
015501.
[43] Nissinen, A., Heikkinen, L. M., Kolehmainen, V. and Kaipio, J. P. (2009). Compensation of
errors due to discretization, domain truncation and unknown contact impedances in electri-
cal impedance tomography. Meas Sci Technol, 20, doi:10.1088/0957–0233/20/10/105504.
[44] Nissinen, A., Heikkinen, L. M., Kolehmainen, V. and Kaipio, J. P. (2009). Compensation of
errors due to discretization, domain truncation and unknown contact impedances in electri-
cal impedance tomography. Meas. Sci. Technol., 20, 105504.
[45] Nissinen, A., Kolehmainen, V., and Kaipio, J. P. (2011). Compensation of modelling errors
due to unknown domain boundary in electrical impedance tomography. IEEE Trans. Med.
Im., 30(2), 231–242.
[46] Nissinen, A., Kolehmainen, V. and Kaipio, J. P. (2011). Reconstruction of domain bound-
ary and conductivity in electrical impedance tomography using the approximation error
approach. Int. J. Uncertainty Quantification., 1(3), 203–222.
[47] Nocedal, J. and Wright, S. J. (2006). Numerical Optimization (second edition). Springer,
New York.
[48] Rue, H. and Held, L. (2005).Gaussian Markov Random Fields: Theory and Applications. Chap-
man and Hall.
[49] Seppänen, A., Vauhkonen, M., Vauhkonen, P. J., Somersalo, E. and Kaipio, J. P. (2001). State
estimation with fluid dynamical evolution models in process tomography – an application to
impedance tomography. Inverse Probl, 17, 467–484.
[50] Seppänen, A., Vauhkonen, M., Vauhkonen, P. J., Somersalo, E. and Kaipio, J. P. (2001). State
estimation with fluid dynamical evolution models in process tomography – an application to
impedance tomography. Inverse Probl, 17, 467–484.
[51] Siltanen, S., Kolehmainen, V., Järvenpää, S., Kaipio, J. P., Koistinen, P., Lassas, M., Pirttilä, J.
and Somersalo, E. (2003). Statistical inversion for medical x-ray tomography with few radio-
graphs i: General theory. Phys. Med. Biol., 48, 1437–1463.
[52] Smith, K. T. and Keinert, F. (1985). Mathematical foundations of computed tomography.
Appl. Optics, 24, 3950–3957.
[53] Somersalo, E., Cheney, M. and Isaacson, D. (1992). Existence and uniqueness for electrode
models for electric current computed tomography. SIAM J. Appl. Math., 52, 1023–1040.
[54] Somersalo, E., Kaipio, J. P., Vauhkonen, M., Baroudi, D. and Järvenpää, S. (1997). Impedance
imaging and Markov chain Monte Carlo methods. In Proc SPIE’s 42nd Annual Meeting, Com-
putational, experimental and numerical methods for solving ill-posed inverse imaging problems:
medical and nonmedical applications (ed. R. Barbour, M. Carvlin, and M. Fiddy), San Diego,
USA, June 27–August 1, pp. 175–185.
[55] Tarantola, A. (2004). Inverse Problem Theory and Methods for Model Parameter Estimation.
SIAM, Philadelphia.
[56] Tarvainen, T., Kolehmainen, V., Pulkkinen, A., Vauhkonen, M., Schweiger, M., Arridge, S. R.
and Kaipio, J. P. (2010). Approximation error approach for compensating modelling errors
between the radiative transfer equation and the diffusion approximation in diffuse optical
tomography. Inv. Probl., 26, 015005 (18pp).
[57] Vauhkonen, P. J., Vauhkonen, M., Savolainen, T. and Kaipio, J. P. (1999). Three-dimen-
sional electrical impedance tomography based on the complete electrode model. IEEE Trans.
Biomed. Eng., 46, 1150–1160.
[58] Victorino, J., Borges, J. B., Okamoto, V. N., Matos, G. F. J., Tucci, M. R., Caramez, M. P. R.,
Tanaka, H., Sipmann, F. S., Santos, D. C. B., Barbas, C. S. V., Carvalho, C. R. R. and Amato,

672
J. Kaipio and V. Kolehmainen
M. B. P. (2004). Imbalances in regional lung ventilation. Am. J. Respir. Crit. Care. Med., 169,
791–800.
[59] Voutilainen, A., Lehikoinen, A., Lipponen, A. and Vauhkonen, M. (2011). A reduced-order
filtering approach for 3d dynamical electrical impedance tomography. Meas Sci Technol, 22,
025504.
[60] Williams, R. A. and Beck, M. S. (1995). Process Tomography: Principles, Techniques and Appli-
cations. Butterworth-Heinemann, Oxford.
[61] Zou, Y. and Guo, Z. (2003). A review of electrical impedance techniques for breast cancer
detection. Med. Eng. Phys., 25, 79–90.

33
Bayesian reconstruction
of particle beam phase
space
c. nakhleh, d. higdon, c. k. allen
and r. ryne
33.1 Introduction
Understanding the physics of charged particle beams (e.g. proton beams) is essential to designing
and controlling efficient particle accelerators. The dynamics of a beam are naturally formulated
in a six-dimensional phase space (three position and three momentum or velocity dimensions).
However, experimental beam profile data taken from accelerators are typically one-dimensional
(coordinate) projections of the phase space distribution or image. The objective of this study is to
apply Bayesian inversion methodology to reconstruct the initial phase space configuration of the
beam using a series of one-dimensional projection datasets (wirescans). Given this initial phase
space configuration, the evolution of the phase space down the beam-line can be inferred, provid-
ing a key beam diagnostic that is of great interest to accelerator designers. Because of the limited
information provided by the wirescan projection data, encoding prior information regarding the
high-dimensional initial phase-space configuration of the beam is crucial.
The outline of this chapter is as follows. Firstly, we give a brief description of the proton beam
produced by the Low Energy Demonstration Accelerator (LEDA) at the Los Alamos National
Laboratory [1]. The proton beam’s phase space evolution is affected by various magnets along the
beamline, as well as interactions between the charged particles themselves. Two basic strategies
exist for modeling the beam’s evolution. The first propagation approach uses a computationally
demanding forward model [13], using a high-fidelity particle-in-cell approach; the second uses
linear transfer matrices to propagateprotons along thebeamline, sacrificing accuracy for substantial
gains in speed. This faster modelling approach proves to be sufficiently accurate, making Markov
chainMonteCarlo(MCMC)afeasibleapproachforposteriorexploration,evenforahighlyparam-
eterized representation of the initial phase space.
Next,wedescribeourmodellingapproach,usingprocessconvolutions[7]torepresenttheinitial
phase space configurations. This process convolution representation gives a parsimonious repre-
sentation of the particle density as a function of spatial position and momentum, while ensuring
positivity.WedescribetheMCMCschemetoproduceposteriordraws,producingareconstruction
for the initial phase space. We also outline additional sensitivity studies to assess the impact of the
prior smoothness on the resulting initial phase space reconstruction.

674
C. Nakhleh, D. Higdon, C. K. Allen and R. Ryne
33.2 The Low Energy Demonstration Accelerator
LEDA, now decomissioned, was an 11 m-long, 6.7 MeV proton accelerator designed specifically
to study continuous, high-current proton beams. The LEDA beamline consisted of 52 focus-
ing/defocusing (FODO) quadrupole magnets; a number of steering magnets; and nine wire scan-
ners. A picture of the actual machine is given in Figure 33.1; the wire scanners are visible in the
picture, pointing out of the beamline at a 45 degree angle from straight up.
The data utilized in this chapter come from two separate beamline segments, each containing
four pairs of x and y wirescanners—both of these segments are visible in Figure 33.1. At each wire
scan station, the proton beam distribution was projected onto orthogonal directions (x and y) at
±45 degrees from vertical. The wirescanner (Figure 33.2) used a 33 μm carbon wire to measure the
beam profile via secondary electron emission (because the wire itself was not thick enough to stop
the protons themselves).
33.2.1 The experimental setup
For the purposes of this chapter, we focus on a 1.25 m segment of the LEDA beamline, as shown in
Figure 33.3. The figure shows a simulated beam with the associated x- and y-direction phase space
configurations as the beam passes through six quadrupole magnets and four pairs of wirescanners.
The proton beam generally moves along a linear path, influenced by three pairs of quadrupole mag-
nets. Each quadrupole magnet takes up about 7 cm of length along the beamline and is separated by
about 14 cm of drift space. A quadrupole magnet acts on the particle beam as a lens acts on a beam
of light. A focusing quadrupole causes the beam to converge in the x dimension and to diverge in
the y dimension; a defocusing quadrupole causes the beam to diverge in the x dimension and to
Figure 33.1 The Low Energy Demonstration Accelerator at Los Alamos National Laboratory.

Bayesian reconstruction of particle beam phase space
675
Figure 33.2 A wirescanner used in the LEDA experiments. Groups of four wirescanners are visible
in Figure 33.1.
converge in the y dimension. The first of each magnet pair is a defocusing quadrupole, represented
by the dark shaded region in the beamline plots of Figure 33.3; the second is a focusing quadrupole,
represented by the light shaded region in the beamline plots of Figure 33.3.
As the beam passes the wirescanners, a histogram of the particle density is produced in both the
x and y directions, shown by the light dots at the bottom of the phase space diagrams in Figure 33.3.
The wirescanners measure a current intensity that is proportional to the beam density projected
onto its component axis (either x or y) at four equally spaced positions along the 1.25 m beamline.
Hence the experiment produces eight 1-d intensity profiles representing the beam density as a
function of distance along the two transverse spatial coordinates.
33.3 The forward model
For the experiments we consider, the beam is in steady state, so its x- and y-phase space configura-
tion is only a function of its initial configuration, and its distance along the beamline. Furthermore,
we can expect that correlations between the x and y phase space do not affect how the beam
propagates. Hence the x and y phase spaces can be characterized separately, without having to
specify additional dependencies between the x and y phase spaces. Note that we use the standard
font (e.g. u, θ) to denote statistical parameters, differentiating them from phase space coordinates
(e.g. x, px).
The initial phase space configuration θ is described by two 2-d point clouds—one over (x, px),
and one over (y, py). Alternatively, the initial phase space could be described by two 2-d density
images, giving the density of protons over a dense grid of (x, px) or (y, py) points. In Figure 33.3,
θ is described by the two leftmost phase space point clouds.
Given the initial phase space configuration θ, the forward model propagates the beam along the
1.25 m beamline, accounting for the effects of the quadrupole magnets on the moving protons, and
accounting for charge interactions between the protons themselves. At various positions along the
beamline, the proton density can be projected along the x and y coordinates, producing predicted
values for the wirescanners. We take'd(θ) to denote the modelled wirescanner output using the
initial phase space configuration θ
'd(θ) = ('d1x,'d1y,'d2x,'d2y,'d3x,'d3y,'d4x,'d4y)
The dots in Figure 33.3 show the predicted wirescanner values for that particular simulation.
We considered two candidate forward models for this particular inverse problem. The first is a
computationalmodelcalledMaryLie/IMPACT(ML/I)[13].Thiscodeevolvesindividualprotons
according to the electromagnetic forces acting on them. In particular, this code implements a parti-

676
C. Nakhleh, D. Higdon, C. K. Allen and R. Ryne
–4
–2
0
2
4
–15
–5
0
5
10
15
px
(miliradians)
–4
–2
0
2
4
–4
–2
0
2
4
–4
–2
0
2
4
x displacement (mm)
0.0
0.2
0.4
0.6
0.8
1.0
1.2
x displacement (mm)
beamline (m)
–2
0
2
–2
0
2
0.0
0.2
0.4
0.6
0.8
1.0
1.2
y displacement (mm)
beamline (m)
–4
–2
0
2
4
–15
–5
0
5
10
15
py
(miliradians)
–4
–2
0
2
4
–4
–4
–2
0
2
4
–2
0
2
4
y displacement (mm)
Figure 33.3 Proton beam simulation of a 1.25 m segment of the LEDA beamline. The central
diagrams show part of the LEDA beamline consisting of three pairs of focusing and defocusing
quadrupole magnets denoted by the dark and light shaded regions respectively. Wirescan locations
are given by the four dashed vertical lines. At these four beamline locations, the resulting x and y
phase space is shown for this particular simulation. The wirescanners produce a ‘histogram’ of the
phase space projected onto the x- and y-axes (shaded dots at the bottom of the phase space
clouds).

Bayesian reconstruction of particle beam phase space
677
–15
–10
–5
0
5
1
15
MLI
px
(miliradians)
–4
–2
0
2
4
–15
–10
–5
0
5
10
15
–4
–2
0
2
4
–4
2
0
2
4
–4
–2
0
2
4
transfer matrix
px
(miliradians)
x position (mm)
projection 1
projection 2
projection 3
projection 4
Figure 33.4 A comparison of phase space configurations produced by the computational model
ML/I (top) and the transfer matrix approach (bottom). The simulations correspond to the experimental
configuration shown in Figure 33.3, using the same initial phase space (leftmost frames labelled
projection 1). While the two modelling approaches give nearly identical results for this example, the
transfer matrix approach is orders of magnitude faster.
cle in cell algorithm to capture the repulsive effects of the charged particles on one another. While
the effect of the quadrupole magnets on the beam is nearly linear, the charge interaction can be
highly nonlinear in some cases, making it necessary to use such a high-fidelity code to accurately
model the beam dynamics.
An alternative modelling strategy, motivated in part by these LEDA experiments, uses linear
transfer matricies to evolve the phase space as the beam propagates down the beamline [2]. This
approach accounts for the linear effects of the quadrupole magnets, and uses an approximation to
account for the effects of the charge interactions. This approximation has proven to be quite accu-
rate in the conditions produced at the LEDA facility. Figure 33.4 gives a comparison of phase spaces
produced by the two forward modelling approaches—the results are nearly identical. Moreover, it
can evolve the initial beam θ over the beamline, producing modelled wirescanner output'd(θ) very
quickly. This drastic reduction in computing time allows us to consider more highly parameterized
process convolution representations [7, 9] of the initial phase space θ—see Section 33.4.2 below.
This is a distinct advantage over approaches that use the slower ML/I code [12].
33.4 Statistical formulation
As stated in the introductory chapter on inverse problems, we need to define the sampling model
for the data d, a prior for the unknown field to be estimated θ, and possibly additional statistical
parameters in the formulations. Each of these terms will be described below, producing a posterior
distribution which will be sampled using standard MCMC techniques [4, 14].

678
C. Nakhleh, D. Higdon, C. K. Allen and R. Ryne
33.4.1 Sampling model for the wirescanner data
As mentioned earlier, the wirescanners produce a current that is proportional to the density of the
proton beam projected down to the x or y axes, as shown by the light dots in Figure 33.3. Hence the
data are eight vectors, each giving an intensity as a function of spatial displacement from the centre
of the beam along the x and y axes
d = (d1x, d1y, d2x, d2y, d3x, d3y, d4x, d4y)
Giventhefittedwirescannersignalfromtheforwardmodel'd(θ),eachofthesecomponentsismod-
elled independently, as multivariate normal draws, after taking a square root transformation. We
use the square root transformation to stabilize the variance, improving the normality and making
it easier to account for dependence within a single wirescan. So now when we write d or'd(θ), we
assume the square root transformation has been carried out.
So, for d1x, using n1x to denote the number of points produced by this particular wirescan, the
sampling density can be written
L(d1x|θ, λd) ∝λ
n1x
2
d
exp

−1
2λd(d1x −'d1x(θ))′R−1
d1x(d1x −'d1x(θ))

.
Theparameterλd isanunknownprecisionparametertobeestimatedinthisanalysis.Heretheerror
covariance λ−1
d Rd1x accounts for scatter in the measurements, dependencies induced by the pro-
cess of producing the wirescanner signal, and by the discrepancy between the model and the actual
physical system. More systematic attempts to estimate the appropriate form of R can be found
in [8, 11]. Here we use expert judgement and past experience to specify R as a mixture of iid and
correlated errors. We use the same R for each of the wirescans.
The same sampling model is used for each of the remaining seven wirescans, using the appropri-
ate forward model prediction'd(θ). This produces a larger normal sampling model for the data
L(d|θ, λd) ∝λ
n
2
d exp

−1
2λd(d −'d(θ))′R−1
d (d −'d(θ))

(33.1)
where n is the total number of measurements produced by all eight wirescans and Rd =
diag(Rd1x, . . . , Rd4y). To complete this specification, we assign a (ad, bd) prior for the precision
parameter
π(λd) ∝λad−1
d
exp{−bdλd}
We take ad = 1 and bd = 0.001, giving a rather uninformative prior, allowing the substantial
amount of wirescanner data to inform about λd.
33.4.2 Process convolution prior for the phase space
We elect to characterize the unknown initial phase space configuration θ using a pair of two-dimen-
sional images θx and θy, describing the particle density in phase space. Each image is a 200 × 160,
but represented with a lower-dimensional process convolution. Before getting into the specifics of
the representation, we first describe the basic approach of using process convolutions on a simple,
one-dimensional example that contains some of the features of this accelerator application.

Bayesian reconstruction of particle beam phase space
679
33.4.2.1 A simple example
Consideraone-dimensionalemissionsourceshowninFigure33.5.Thisobject,100unitslong,emits
objects according to an inhomogeneous Poisson process, whose emission rate is given by the black
line. Over a fixed time interval, 382 emissions occur at the locations marked by the dashes at the
bottom of Figure 33.5.
The data collected here are the total number of counts occurring in the five intervals I1 =
[0, 20), . . . , I5 = [80, 100). These counts, divided by the interval length of 20, are given by the
horizontal lines over each of the five segments in Figure 33.5.
The process convolution model represents the intensity function θ(s), s ∈[0, 100] as a simple
process u(s) convolved with a smoothing kernel k(·). We take u(s) to be a discrete process, with
independent normal values at m = 7 fixed knot locations s∗
1, . . . , s∗m as shown in the left frame
of Figure 33.6. When u(s) is convolved with a normal kernel (a normal density with a standard
deviation of 25), the grey line in the right frame of Figure 33.6 is produced. We take θ+(s) to be the
non-negative part of this smooth process, given by the black line in the right frame of Figure 33.6.
To be more concrete, we specify a normal prior for u = (u1, . . . , um)′, and associate locations
{s∗
1, . . . , s∗m} to each component of u. Thus the model specification becomes
θ(s) =
m

j=1
k(s −s∗
j )uj
π(u) ∝λ
m
2u exp{−1
2λuu′u}
π(λu) ∝λau−1
u
exp{−buλu}
0
20
40
60
80
100
0
5
10
15
s
emission intensity
|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
|| |||||||||||||||||||||||||||||||||| ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Figure 33.5 A simple example of using process convolutions to estimate the underlying image
intensity. A linear region [0,100] is emitting particles at a rate given by the black line. Over a fixed time
382 emissions occur at locations shown by the dark shaded marks at the bottom of the figure. The
data are total counts recorded over each of five consecutive intervals of length 20—the dark shaded
lines show the total number of counts divided by the interval length (20) for the five aggregated
counts. Realizations from the resulting posterior distribution for the image intensity are given by the
light shaded lines.

680
C. Nakhleh, D. Higdon, C. K. Allen and R. Ryne
s
emission intensity
0
50
100
–10
0
5
10
s
s
0
50
100
s∗1, . . . , s∗7
θ+(s)
Figure 33.6 Representing a non-negative image with process convolutions.
Note that λu, the precision for u, is also treated as a parameter to be estimated; we use the rather
uninformative settings au = 1 and bu = 0.001. Because θ(s) can go negative, we define the mod-
elled image intensity to be the non-negative part of θ(s)
θ+(s) =

θ(s) if θ(s) ≥0
0
if θ(s) < 0.
Each of the n = 5 counts d = (d1, . . . , dn)′ follow independent Poisson distributions with rate
μi(θ) given by
μi(θ) =

Ii
θ+(s)ds
so that
L(d|θ) ∝
n

i=1
eμi(θ)μi(θ)di
di!
.
The resulting posterior density for this simple image reconstruction problem has the form
π(u, λu|d) ∝
n

i=1
eμi(θ)μi(θ)di × λ
m
2u exp{−1
2λuu′u} × λau−1
u
exp{−buλu}
which can be explored using standard single-site MCMC methods. Metropolis updates can be used
for the uis, and a Gibbs step can be used for the precision parameter λu. A number of posterior real-
izationsofθ+(s)aregivenbythegreylinesinFigure33.5.Notethattheimageintensityθ+(s)canbe
evaluated for any s since this function is determined by the knot values u. Also posterior realizations
of the model can easily reproduce a 0 emission rate. This will be important for modelling the phase
spaceimageswheremuchoftheimagehas0particledensity.Notealsothatthisprocessconvolution
approachshowsdifferentbehaviourascomparedtolog-Gaussianfieldsthatareoftenusedtomodel
spatially distributed emissions from a Poisson process [5].
33.4.2.2 Representing the x and y phase space images
Recall the unknown initial phase space configuration θ is described using a pair of 200 × 160
imagesθx andθy.Aswiththeprevioussimpleexample,werepresenteachimagewithaprocesscon-
volution,but now s = (x, px) indexes a two-dimensional phase space. We define the m = 29 × 21

Bayesian reconstruction of particle beam phase space
681
knot locations shown in Figure 33.7. We take the smoothing kernel k(·) to have the tricube [6] form
k(s) ∝(1 −|s|3/r3)3I[|s| ≤r]
(33.2)
where r is the range of the kernel, and I[·] is the indicator function. This representation also allows
for computational savings since it localizes the influence of a particular knot.
Focusing on the x phase space image we have
θx(s) =
m

j=1
k(∥s −s∗
j ∥)uj
where ∥· ∥denotes Euclidean distance, the grid points s∗
j = (x∗
j , px∗
j ) are marked in Figure 33.7,
as is the smoothing kernel. The value of r which scales the tricube kernel is chosen to give particle
density variation expected by accelerator scientists. Subsequent sensitivity studies have shown this
value of r to be good—not oversmoothing, and not producing wildly irregular phase space recon-
structions. At the end of Section 33.5, an analysis with r taken to be half its selected value produces
overly irregular reconstructions.
The positive part of the phase space images θ+
x (s) and θ+
y (s) are then taken as inputs to the
forward model, producing fitted wirescans 'd(θ) as well as phase space configurations along the
beamline. Of particular interest for us are the phase space images at the three locations correspond-
ing to the remaining wirescanners.
33.4.3 Posterior distribution
Puttingthisalltogetherproducesaposteriordistributionthatdependsonthedataprecisionparam-
eter λd, the latent knot values u, and the regularizing precision for the knot values λu
π(λd, u, λu|d) ∝L(d|u, λd) × π(λd) × π(u|λu) × π(λu).
–6
momentum (miliradians)
–4
–2
0
displacement (mm)
2
4
6
–20
–15
–10
–5
0
5
10
15
20
Figure 33.7 Knot locations and kernel used for the process convolution representation of the x and
y phase space.

682
C. Nakhleh, D. Higdon, C. K. Allen and R. Ryne
Note that given the values for u, the initial phase space image is completely determined. Mathemat-
ically, the posterior can be written
π(λd, u, λu|d) ∝λ
n
2
d exp

−1
2λd(d −'d(θ))′R−1
d (d −'d(θ))

×
(33.3)
λad−1
d
exp{−bdλd} ×
λ
m
2u exp{−1
2λuu′u} × λau−1
u
exp{−buλu}.
The two precision parameters can be updated with Gibbs steps, sampling directly from their
Gamma full conditional distributions.
λd| · · · ∼

ad + n/2, bd + 1
2(d −'d(θ))′R−1
d (d −'d(θ))

λu| · · · ∼

au + m/2, bu + 1
2u′u

We update the components of u with standard random walk Metropolis updates. Note that when
updating a single ui, its effect on'd(θ) can be computed very efficiently since its impact on θ(s) is
linear. The final step of computing the impact of changes to θ+(s) is also fast, allowing an efficient
means for computing changes to the likelihood term (33.1).
33.5 Results
We consider data taken from a single experiment, considering two separate 1.25 m segments of the
beamline which conform to Figure 33.3. Results using data from this first segment are shown in
Figure 33.8; results from the second segment, about 4 m further down the beamline, are shown in
Figure 33.9.
For the x and y phase space, Figure 33.8 shows two rows of four plots. The bottom four plots
showthewirescannerdata,givenbythedots.Thetopfourplotsgivetheposteriormeanofthephase
spaceimageinitially,coincidentwiththefirstwirescannerlocation,andatlocationscoincidentwith
the remaining three wirescanners. These last three images are produced by propagating the initial
phase space estimate through the forward model.
The dark, interior lines in the wirescanner plots show pointwise 90% credible intervals for the
beam density projected down to the x or y axes. The width of these intervals is due to uncertainty
in the initial phase space images θ. The light, outer lines show pointwise 90% bounds for the
wirescanner data, which include additional uncertainty due to the observation process, controlled
by λd and R.
To assess the impact of our choice of kernel width—controlled by r in equation (33.2)—we
first tried altering the prior specification for the process u, replacing the i.i.d. normal prior with a
two-dimensional intrinsic Markov random field (MRF) [3, 15]. Such spatial dependence between
thecomponentsofucanmodifythesmoothnessintheresultingposteriorrealizationsfortheimage
θ [10]. This implementation is simple since it only slightly modifies the posterior distribution, and
adds little additional computational complexity. The resulting posterior mean and uncertainty for
θ under this alternative formulation is very similar, suggesting the data do not support smoother
realizations for θ, and that the choice of kernel width is compatible with the data.
As a final check, we carried out the analysis with our original formulation, but substituting the
value of r with one that was half its original value, leading to a much narrorwer kernel k(·) in the
process convolution specification. The results are shown in Figure 33.10, using data from the first

Bayesian reconstruction of particle beam phase space
683
 px (mrad)
proj 1
10
0
–10
proj 2
proj 3
proj 4
 py (mrad)
10
0
–10
0
0.2
0.4
intensity
–5
0
0
0.2
0.4
0.6
intensity
–5
0
–5
0
–5
0
5
y–coordinate s
x–coordinates
Wirescan data
phase space
Wirescan data
phase space
position (mm)
Figure 33.8 Posterior summary of the analysis of wirescanner data from the first LEDA beam
segment.
 px (mrad)
proj 1
10
0
–10
proj 2
proj 3
proj 4
 py (mrad)
10
0
–10
0
0.2
0.4
intensity
–5
0
0
0.2
0.4
0.6
intensity
–5
0
–5
0
–5
0
5
y–coordinates
x–coordinates
Wirescan data
phase space
Wirescan data
phase space
position (mm)
Figure 33.9 Posterior summary of the analysis of wirescanner data from the second LEDA beam
segment.

684
C. Nakhleh, D. Higdon, C. K. Allen and R. Ryne
 px (mrad)
proj 1
10
0
–10
proj 2
proj 3
proj 4
 py (mrad)
10
0
–10
0
0.2
0.4
intensity
–5
0
0
0.2
0.4
0.6
intensity
–5
0
–5
0
–5
0
5
y–coordinates
x–coordinates
phase space
phase space
position (mm)
Figure 33.10 Posterior summary of the analysis of wirescanner data from the first LEDA beam
segment using a convolution kernel with half the width of the original specification. The resulting
phase space reconstructions are unrealistically patchy.
beam segment. Hence this figure corresponds to Figure 33.8 which shows the original results. While
this reconstruction produces a posterior mean that gives a slightly better match to the wirescanner
data, the phase space reconstruction θ is now unrealistically composed of many small bunches of
particles. Again, this sensitivity study argues for our original kernel width choice.
33.6 Discussion
Reconstruction of particle beam phase space images from projection data provides an excellent
application of modern computational Bayesian inference. The quality of the reconstructions is
quitegood,andconvincinglydemonstratestheabilityofthisapproachtoextractphysicallysensible
phase space information from the projection data. The ability to capture complex phase space
information outside the image cores is particularly noteworthy. This type of phase space image
detail has been previously unavailable to accelerator physicists, and should enhance their ability
to predict accelerator performance when changing beamline parameters and to design accelerator
upgrades. This type of analysis will furthermore allow accelerator physicists to gain insight into the
properties of intense charged particle beams at locations where it might be too expensive or too
difficult to make direct measurements.
On the statistical side, the use of the process convolution model for the phase space images θ
leads to a number of benefits—easy to control regularization of the image, parameter reduction,
ensuring positivity, allowing 0s in the posterior realizations, and leading to a posterior that can
be easily explored using standard algorithms. This application might also be adapted to make use
of alternative spatial representations such as the integrated nested Laplace approximation [16],
alleviating the need for posterior sampling.

Bayesian reconstruction of particle beam phase space
685
The major limiting approximation made in this paper is the use of the transfer matrix method
to model the beam dynamics. As we have shown, this approximation is satisfactory for the
LEDA accelerator. However, in other applications this approximation is not adequate, so that full
particle-in-cell simulations are necessary, making computational expense an important factor.
MCMC(orothercomputationallyintensive)techniquesplaceahighpremiumonfindingmethods
for rapidly obtaining simulator output. This challenge is likely to be met through a combination of
advanced algorithms combined with large-scale parallel simulation.
Acknowledgements
This work was supported in part by the US Department of Energy Office of Science, Office of
Advanced Scientific Computing Research, Scientific Discovery through Advanced Computing
(SciDAC) program. This research also used resources of the National Energy Research Scientific
Computing Center, which is supported by the Office of Science of the US Department of Energy
under Contract No. DE-AC02-05CH11231.
Sandia National Laboratories is a multi-program laboratory managed and operated by Sandia
Corporation, a wholly owned subsidiary of Lockheed Martin Corporation, for the US Department
of Energy’s National Nuclear Security Administration under contract DE-AC04-94AL85000.
References
[1] Allen, C. K., Chan, K. C. D., Colestock, P. L., Crandall, K. R., Garnett, R. W., Gilpatrick, J. D.,
Lysenko, W., Qiang, J., Schneider, J. D., Schulze, M. E., Scheffield, R. L., Smith, H. V. and
Wangler,T.P.(2002).Beam-halomeasurementsinhigh-currentprotonbeams.PhysicalReview
Letters, 89(21), 214802.
[2] Allen, C. K. and Pattengale, N. D. (2002). Theory and technique of beam envelope simula-
tion: Simulation of bunched particle beams with ellipsoidal symmetry and linear space charge
forces. Technical Report LA-UR-02-4979, Los Alamos National Laboratory.
[3] Besag,J.(1993).TowardsBayesianimageanalysis.JournalofAppliedStatistics,20(5–6),107–119.
[4] Besag, J., Green, P. J., Higdon, D. M. and Mengersen, K. (1995). Bayesian computation and
stochastic systems (with discussion). Statistical Science, 10, 3–66.
[5] Brix, A. and Moller, J. (2001). Space-time multi type log Gaussian Cox processes with a view
to modelling weeds. Scandinavian Journal of Statistics, 28(3), 471–488.
[6] Cleveland, William S. (1979). Robust locally weighted regression and smoothing scatterplots.
Journal of the American Statistical Association, 74, 829–836.
[7] Higdon, Dave (2002). Space and space-time modeling using process convolutions. In Quan-
titative Methods for Current Environmental Issues (ed. C. Anderson, V. Barnett, P. C. Chatwin,
and A. H. El-Shaarawi), London, pp. 37–56. Springer Verlag.
[8] Higdon, D., Kennedy, M., Cavendish, J. C., Cafeo, J. A. and Ryne, R. D. (2005). Combining
field data and computer simulations for calibration and prediction. SIAM Journal on Scientific
Computing, 26(2), 448–466.
[9] Higdon, D. M., Lee, H. and Holloman, C. (2003). Markov chain Monte Carlo-based
approachesforinferenceincomputationallyintensiveinverseproblems.InBayesianStatistics7.
Proceedings of the Seventh Valencia International Meeting (ed. J. M. Bernardo, M. J. Bayarri,
J. O. Berger, A. P. Dawid, D. Heckerman, A. F. M. Smith and M. West), pp. 181–197. Oxford
University Press.

686
C. Nakhleh, D. Higdon, C. K. Allen and R. Ryne
[10] Lee, H. K. H., Higdon, D. M., Calder, C. A. and Holloman, C. H. (2005). Efficient models for
correlated data via convolutions of intrinsic processes. Statistical Modelling, 5(1), 53.
[11] Lee,H.,Sansó,B.,Zhou,W.andHigdon,D.(2006).Inferringparticledistributioninaproton
accelerator experiment. Bayesian Analysis, 1(2), 249–264.
[12] Lee, H. K. H., Sanso, B., Zhou, W. and Higdon, D. M. (2008). Inference for a proton accel-
erator using convolution models. Journal of the American Statistical Association, 103(482),
604–613.
[13] Qiang,J.,Ryne,R.D.andHabib,S.(2000).Fortranimplementationofobject-orienteddesign
in parallel beam dynamics simulations. Computer Physics Communications, 133(1), 18–33.
[14] Robert, Christian P. and Casella, George (1999). Monte Carlo Statistical Methods. Springer-
Verlag Inc.
[15] Rue, H. and Held, L. (2005). Gaussian Markov Random Fields: Theory and Applications, Vol-
ume 104. Chapman & Hall.
[16] Rue, H., Martino, S. and Chopin, N. (2009). Approximate Bayesian inference for latent Gaus-
sian models by using integrated nested Laplace approximations. Journal of the Royal Statistical
Society: Series B (Statistical Methodology), 71(2), 319–392.

Adrian Smith’s research supervision
(PhD)
1972–1974
M. Goldstein: Aspects of linear statistical inference, University of Oxford.
1975–1977
D. J. Spiegelhalter: Bayesian inference using finite mixture models, University
College London.
1974–1980
B. Booth: Identification of change-points in time series models, University College
London.
1975–1983
U. E. Makov: Bayesian approximations to unsupervised learning procedures,
University College London.
1977–1983
J. C. Naylor: Some numerical aspects of Bayesian inference, University of
Nottingham.
1978–1982
M. West: Aspects of recursive Bayesian estimation, University of Nottingham.
1979–1983
L. I. Pettit: Bayesian approaches to outliers, University of Nottingham.
1980–1985
F. L. Ezzet: Applied sequential procedures: robustness and change-point problems,
University of Nottingham.
1982–1985
A. N. Pole: Inference for threshold models, University of Nottingham.
1982–1985
M. Upsdell: Bayesian inference for functions, University of Nottingham.
1981–1986
K. Gordon: Modelling and monitoring of medical time series, University of
Nottingham.
1981–1988
J. Marriott: Aspects of Bayesian methodology for ARMA time series, University of
Nottingham.
1983–1988
J. E. H. Shaw: Numerical and graphical methods for Bayesian inference, University
of Nottingham.
1983–1988
L. D. Sharples: Combining related information, University of Nottingham.
1984–1988
N. G. Polson: Bayesian perspectives on statistical modelling, University of
Nottingham.
1984–1992
A. P. Grieve: Applications of Bayesian methods to pharmaceutical problems,
University of Nottingham.
1985–1989
S. Hills: Aspects of parameterization in statistical inference, University of
Nottingham.
1986–1989
D. Stephens: Applications of change-point methods to image restoration, University
of Nottingham.
1986–1992
J. Wakefield: Bayesian analysis of pharamacokinetic models, University of
Nottingham.
1989–1994
P. Damien: Some Contributions to Bayesian Nonparametric Inference, Imperial
College, London.
1990–1994
N. Gordon: Bayesian methods for tracking, Imperial College, London.
1990–1994
D. Buckle: Bayesian portfolio analysis, Imperial College, London.
1990–1994
L. Foreman: Bayesian analysis of hidden Markov models, Imperial College, London.

688
Adrian Smith’s research supervision (PhD)
1990–1994
D. Phillips: Bayesian analysis of images via templating, Imperial College, London.
1990–1994
P. Vounatsou: Computer graphic techniques and Bayesian inference summaries,
Imperial College, London.
1991–1995
E. Gutierrez-Pena: Topics in Bayesian Statistics relating to the exponential family,
Imperial College, London.
1991–1995
K. F. Lam: Statistical studies of optimal lending, Imperial College, London.
1992–1996
S. T. B. Choy: Bayesian robustness studies, Imperial College, London.
1992–1996
M-Y. E. Yen: Bayesian classification from images, Imperial College, London.
1992–1996
M. Efstathiou: Laplace approximations and Markov chain Monte Carlo, Imperial
College, London.
1992–1997
M. Curtis: Statistical studies of hedging, Imperial College, London.
1993–1996
J. T. Key: Bayesian model choice. Imperial College, London.
1993–1997
A. M. Brink: Bayesian analysis of contingency tables, Imperial College, London.
1994–1998
R. A. Haro-Lopez: Bayesian robustness, Imperial College, London.
1994–1997
D. G. T. Denison: Bayesian curves, CART and MARS, Imperial College, London.
1995–2000
C. J. Hoggart: Bayesian methods in Forensic Science, Imperial College, London.
1995–2000
J. E. Griffin: Bayesian nonlinear design, Imperial College, London.
1995–1999
S. B. Tan: Bayesian clinical trials, Imperial College, London.
1996–2001
N. A. Heard: Bayesian sequential design, Imperial College, London.
1996–2000
J.W.Sandy:DevelopmentandvalidationofanIBSsymptomindex,ImperialCollege,
London.
1997–2001
R. A. H. J. Al-Jaralla: Bayesian analysis of models where variances depend on
covariates, Imperial College, London.

Adrian Smith’s publications
Books
1985
(with U. E. Makov and D. M. Titterington) The Statistical Analysis of Finite Mixture Models.
Wiley.
1994
(with J. M. Bernardo) Bayesian Theory. Wiley.
2002
(with D. G. T. Denison, C. C. Holmes and B. K. Mallick) Bayesian Methods for Nonlinear
Classification and Regression. Wiley
Editing and translation
1974
(co-translator with A. Machi) Theory of Probability; a critical introductory treatment. Vol. I,
by Bruno de Finetti. Wiley.
1975
(co-translator with A. Machi) Theory of Probability; a critical introductory treatment. Vol. II,
by Bruno de Finetti. Wiley.
1981
(joint editor with J. M. Bernardo, M. H. DeGroot and D. V. Lindley) Bayesian Statistics:
Proceedings of the International Meeting on Bayesian Statistics. University of Valencia
Press.
1983
(joint editor with J. P. Florens, M. Mouchart, J. P. Raoult and L. Simar) Specifying Statistical
Models. Springer-Verlag, New York.
1983
(joint editor with A. P. Dawid) Practical Bayesian Statistics. Longman.
1985
(joint editor with J. M. Bernardo, M. H. DeGroot and D. V. Lindley) Bayesian Statistics 2.
Amsterdam. North-Holland.
1987
(joint editor with A. P. Dawid) Practical Bayesian Statistics. Carfax.
1988
(joint editor with J. M. Bernardo, M. H. DeGroot and D. V. Lindley) Bayesian Statistics 3.
Oxford University Press.
1992
(joint editor with J. Berger, J. M. Bernardo and A. P. Dawid) Bayesian Statistics 4. Oxford
University Press.
1994
(joint editor with P. R. Freeman) Aspects of Uncertainty: A Tribute to DV Lindley. Wiley.
1996
(joint editor with J. Berger, J. M. Bernardo and A. P. Dawid) Bayesian Statistics 5. Oxford
University Press.
1999
(joint editor with J. Berger, J. M. Bernardo and A. P. Dawid) Bayesian Statistics 6. Oxford
University Press.
2003
(joint editor with J. M. Bernardo, M. J. Bayarri, J. O. Berger, A. P. Dawid, D. Heckerman and
M. West) Bayesian Statistics 7. Oxford University Press.
2007
(joint editor with J. M. Bernardo, M. J. Bayarri, J. O. Berger, A. P. Dawid, D. Heckerman and
M. West) Bayesian Statistics 8. Oxford University Press.
2011
(joint editor with J. M. Bernardo, M. J. Bayarri, J. O. Berger, A. P. Dawid, D. Heckerman and
M. West) Bayesian Statistics 9. Oxford University Press.

690
Adrian Smith’s publications
Articles
1972
(with D. V. Lindley) Bayes estimates for the linear model (with discussion). J R Statist Soc,
B, 34, 1–41.
1973
Bayes estimates in one-way and two-way models. Biometrika, 60, 319–329.
1973
A general Bayesian linear model. J R Statist Soc, B, 35, 67–75.
1974
(with C. D. Payne) An algorithm for determining Slater’s i and all nearest adjoining orders.
Br J Math Statist Psychol, 27, 49–52.
1975
(with M. Goldstein) Ridge regression: some comments on a paper of Conniffe and Stone.
Statistician, 24, 61–66.
1975
A Bayesian approach to inference about a change-point in a sequence of random variables.
Biometrika, 62, 407–416.
1976
(withN.B.Booth)Batchacceptanceschemesbasedonanauto-regressiveprior.Biometrika,
63, 133–136.
1977
Bayesian statistics and efficient information processing constrained by probability mod-
els. In Decision Making and Change in Human Affairs (H. Jungermann and G. de Zeeuw:
Editors). Reidel, pp. 479–490.
1977
A Bayesian approach to some time-varying models. Proceedings of the European
Congress of Statisticians (J. R. Barra: Editor). North-Holland Publishing Company,
pp. 257–267.
1977
(with U. E. Makov) Quasi-Bayes procedures for unsupervised learning. Proceedings of the
1976 IEEE Conference on Decision and Control.
1977
(with U. E. Makov) A quasi-Bayes unsupervised learning procedure for priors. IEEE Trans-
actions on Information Theory, IT-23, 761–764.
1977
A Bayesian note on reliability growth during a development testing program. IEEE Trans-
actions on Reliability, R-26, 346–364.
1977
(Invited Discussant) Comments on “A simulation study of alternatives to ordinary least
squares” (Dempster, Schatzoff and Wermuth). J Amer Statist Ass, 71, March.
1978
(with A. P. Dawid, J. I. Galbraith, R. F. Galbraith and M. Stone) A note on forecasting car
ownership. J R Statist Soc, A, 141, 64–68.
1978
(with U. E. Makov) A quasi-Bayes sequential procedure for mixtures. J R Statist Soc, B, 40,
106–112.
1980
(with U. E. Makov) Bayesian Detection and Estimation of Jumps in Linear Systems. In The
AnalysisandOptimizationofStochasticSystems(C.HarrisandO.Jacobs:Editors).Academic
Press, pp. 333–345.
1980
(with D. G. Cook) Switching straight-lines: an analysis of some renal transplant data.
Applied Statistics, 29, 180–189.
1980
(withD.J.Spiegelhalter)Bayes factors andchoicecriteriafor linear models. J R Statistic Soc,
B, 42, 213–220.
1980
(with I. Verdinelli) A note on Bayesian designs for inference using a hierarchical linear
model. Biometrika, 67, 613–619.
1980
Some comments on a paper of D. E. H. Llewelyn, Clinical Science, 58.
1981
Change-point problems: approaches and applications. Proceedings of the International
Meeting on Bayesian Statistics (J. M. Bernardo et al.: Editors). University of Valencia Press.
1981
(with D. J. Spiegelhalter) Bayes factors in multivariate analysis. Chapter 17 of Looking at
Multivariate Data (V. Barnett: Editor). Wiley.
1981
On random sequences with centered spherical symmetry. J R Statist Soc, B, 208–209.
1981
(with U. E. Makov) Unsupervised learning for signal versus noise. IEEE Trans on Inf Th,
498–500.

Adrian Smith’s publications
691
1981
(with D. J. Spiegelhalter) Decision analysis and clinical decisions. In Perspectives in Medical
Statistics. Academic Press, pp. 103–131.
1981
La teoria Bayesiana delle decisioni in medicina. In Teoria delle decisioni in medicina (Girelli
Bruni: Editor), Bertoni, Verona.
1981
(with R. Dabir, S. J. Ellis, A. Hollingsworth and W. A. Wallace) Comparison of bupivocaine
and prilocaine used in Bier block – a double blind trial. Injury, 331–336.
1982
(with J. C. Naylor) Applications of a method for the efficient computation of posterior
distributions. Applied Statistics, 31, 214–225.
1982
(with D. J. Spiegelhalter) Bayes factors for linear and log-linear models with vague prior
information. J R Statist Soc, B, 44, 377–387.
1982
(with N. B. Booth) A Bayesian approach to the retrospective identification of
change-points. J of Econometrics, 19, 7–22.
1982
(with M. S. Knapp, I. Trimble, R. Pownall and M. West) The detection of sudden change in
renal function by time-series analysis. In Towards Chronopharmacology (R. Takalashi et al.:
Editors). Pergamon Press, Oxford.
1983
(with I. Trimble, M. West, M. S. Knapp and R. Pownall) Detection of renal allograft rejec-
tion by computer. British Medical Journal, 1695–1699.
1983
Bayesianapproachestooutliersandrobustness.InSpecifyingStatisticalModels(J.P.Florens
et al.: Editors). Springer-Verlag, New York.
1983
(with M. Knapp, I. Trimble, R. Pownall and K. Gordon) Mathematical and statistical aids
to evaluate data from renal patients. Kidney International, 24, 474–486.
1983
(with J. C. Naylor) A contamination model in clinical chemistry. Statistician, 32, 82–87.
1983
(with M. West, K. Gordon, M. S. Knapp and I. Trimble) Monitoring kidney transplant
patients. Statistician, 34, 46–54.
1983
(with M. West) Monitoring Renal Transplants: an application of the multi-process Kalman
filter. Biometrics, 39, 867–878.
1984
Bayesian Statistics: Chapter 15 of Handbook of Applicable Mathematics: Vol. 6; Wiley.
1984
Decision Theory: Chapter 19 of Handbook of Applicable Mathematics: Vol. 6; Wiley.
1984
(with L. I. Pettit) Bayesian model comparisons in the presence of outliers. Proceedings of
the 44th ISI Meeting, Madrid.
1984
Present position and potential developments – some personal views; Bayesian Statistics.
J R Statist Soc, A, 147, 245–259.
1985
(with L. I. Pettit) Outliers and influential observations in linear models. In Bayesian Statis-
tics 2 (Proceedings of the 2nd Valencia International meeting on Bayesian Statistics).
North-Holland.
1985
(with K. Gordon, R. Pownall and M. S. Knapp) The development of new statistical meth-
ods for event detection in time series. The Annual Review of Chronopharmacology, Vol. I,
161–164.
1985
(with A. M. Skene, J. E. H. Shaw, J. C. Naylor and M. Dransfield) The implementation of
the Bayesian paradigm. Commun Statist A5, 1079–1102.
1985
(with J. M. Bernardo and J. R. Ferrandiz) The foundations of decision theory; an intuitive,
operational approach with mathematical extensions. Theory and Decision, 19, 127–150.
1985
(with A. N. Pole) A Bayesian approach to some threshold switching models. J of Economet-
rics, 29, 97–119.
1986
Discussion of Efron’s ‘Why isn’t everyone a Bayesian?’ In American Statistician, 40.
1986
Some Bayesian thoughts on modelling and model choice. Statistician, 35, 97–102.
1986
(with A. Racine-Poon, A. P. Grieve and H. Flühler) Bayesian statistics in practice: experi-
ences in the pharmaceutical industry (with discussion). Appl Statist, 35, 93–150.
1986
Observations, Imaginary. In Encyclopaedia of Statistical Science, Vol. 7 (S. Kotz and
N. L. Johnson: Editors). Wiley.

692
Adrian Smith’s publications
1987
(with A. M. Skene, J. E. H. Shaw and J. C. Naylor) Progress with numerical and graphical
methods for practical Bayesian statistics. Statistician, 36, 75–82.
1987
An overview of some problems relating to finite mixture distributions. Rassegna di Metodi
Statistici, 5, 137–150.
1987
Discussion of Hodges’ ‘Uncertainty, Policy Analysis and Statistics’. In Statistical Science, 3.
1987
(with A. Racine-Poon, A. P. Grieve and H. Flühler) A two-stage procedure for bioequiva-
lence studies. Biometrics, 43, 847–856.
1988
(with J. C. Naylor) Econometric illustrations of novel numerical integration methodology
for Bayesian inference. J of Econometrics, 38, 103–125.
1988
(with K. Gordon) Modelling and monitoring discontinuous changes in time series. Chap-
ter 17 of Bayesian Analysis of Time Series and Dynamic Models (J. C. Spall: Editor). Marcel
Dekker.
1988
(with J. C. Naylor) An archaeological inference problem. J Amer Statist Ass, 83, 588–595.
1988
What should be Bayesian about Bayesian software? In Bayesian Statistics 3 (J. M. Bernardo
et al.: Editors). Oxford University Press.
1988
(with K. Gordon, B. A. Bradley and S. M. Gore) Kalman Filter Monitoring. Chapter 8
of Renal Transplantation: Sense and Sensitization (S. M. Gore and B. A. Bradley: Editors).
Council of Europe. Kluwer Academic Publishers.
1989
(withA.Racine-Poon)PopulationModels.Chapter4ofStatisticalMethodologyinthePhar-
maceutical Sciences (D. A. Berry: Editor). Marcel Dekker.
1989
Discussion of Trumbo’s ‘How to get your first research grant’. Statistical Science, 4, 134–136.
1990
(with J. A. Achcar) Aspects of Reparametrization in Approximate Bayesian Inference. In
Essays in Honour of GA Barnard (J. Hodges: Editor). North-Holland, pp. 439–452.
1990
(with K. Gordon) Modelling and monitoring biomedical time series. J Amer Statist Ass, 85,
328–337.
1990
(with A. Gelfand) Sampling-based approaches to calculating marginal densities. J Amer
Statist Ass, 85, 398–409.
1990
(with A. Gelfand, A. Racine-Poon and S. Hills) Illustration of Bayesian inference in normal
data models using Gibbs sampling. In J Amer Statist Ass, 85, 972–985.
1991
(with J. Wakefield and A. Gelfand) Efficient generation of random variates via the
ratio-or-uniforms method. Statistics and Computing, 1, 129–133.
1991
(with J. Wakefield, A. Skene and I. Evett) The evaluation of fibre transfer evidence in
forensic science: a case study in statistical modelling. Appl Statist, 40, 461–476.
1991
An overview of the Bayesian approach. Chapter 2 of Bayesian Methods in Reliability
(P. Sander and R. Badoux: Editors). Kluwer Academic Publishers, pp. 15–80.
1991
(with A. Gelfand) Gibbs sampling for posterior expectations. Commun Statist: Th and
Methods, 20, 1747–1766.
1991
Bayesian computational methods. Phil Trans R Soc Lond, A, 337, 369–386.
1991
(with C. Buck, J. Kenworthy and C. Litton) Combining archaeological and radiocarbon
information: a Bayesian approach to calibration. Antiquity, 65, 808–821.
1991
(with C. Buck and C. Litton) Calibration of radiocarbon results pertaining to related
archaeological events. J Arch Sci, 19, 497–512.
1992
(with A. Racine-Poon and C. Weihs) Estimation of relative potency with sequential dilu-
tion errors in radioimmunoassay. Biometrics, 47, 1235–1246.
1992
(withJ.M.Marriott)ReparametrizationaspectsofnumericalBayesianmethodsforARMA
models. J Time Series Anal, 13, 327–343.
1992
(with B. Carlin and A. Gelfand) Hierarchical Bayesian analysis of change point problems.
Appl Statist, 41, 389–405.
1992
(with A. Gelfand and T. M. Lee) Bayesian analysis of constrained parameter and truncated
data problems via Gibbs sampling. J Amer Statist Ass, 87, 523–532.

Adrian Smith’s publications
693
1992
(with S. E. Hills) Parameterization issues in Bayesian inference. In Bayesian Statistics 4
(J. Berger et al.: Editors). Oxford University Press, pp. 227–246.
1992
(with L. Kuo) Bayesian computation for survival models via the Gibbs sampler. In Survival
Analysis and Related Topics (J. P. Klein and P. K. Goel: Editors). Marcel Dekker, pp. 11–24.
1992
(with A. Gelfand) Bayesian statistics without tears: a sampling–resampling perspective.
American Statistician, 46, 84–88.
1992
(with L. Pericchi) Exact and approximate posterior moments for a normal location param-
eter. J R Statist Soc, B, 54, 793–804.
1993
(with I. Verdinelli and F. Ball) Biased coin designs with a Bayesian bias. J Stat Inf and Plan,
34, 403–421.
1993
(with G. O. Roberts) Bayesian computation via the Gibbs sampler and related Markov
chain Monte Carlo methods. J R Statist Soc, B, 55, 3–23.
1993
(with D. Stephens) Sampling–resampling techniques for the computation of posterior
densities in normal means problems. Test, 1, 1–18.
1993
(with P. Dellaportas) Bayesian inference for generalized linear and proportional hazards
models via Gibbs sampling. Appl Statist, 42, 443–459.
1993
(with D. Stephens) Bayesian edge-detection in images via change-point methods. In Com-
puting Intensive Methods in Statistics (W. Hardle and L. Simar: Editors). Physica-Verlag,
pp. 1–29.
1993
(withN.GordonandD.J.Salmond)Novelapproachtonon-linear/non-GaussianBayesian
state estimation. IEEE Proceedings - F, 140, 107–113.
1993
(with S. E. Hills) Diagnostic plots for improved parameterization in Bayesian inference.
Biometrika, 80, 61–74.
1993
(with E. I. George and U. E. Makov) Conjugate likelihood distributions. Scand J Statist, 20,
147–156.
1993
(with N. Gordon) Approximate non-Gaussian Bayesian estimation and modal consistency.
J R Statist Soc, B, 55, 913–918.
1993
(with J. C. Wakefield, A. Racine-Poon and A. E. Gelfand) Bayesian analysis of linear and
nonlinear population models using the Gibbs sampler. Appl Statist, 43, 201–222.
1993
(with P. Damien and P. W. Laud) Nonparametric Bayesian bioassay with prior constraints
on the shape of the potency curve. Biometrika, 80, 489–498.
1993
(with L. Pericchi and B. Sanso) Posterior cumulant relationships in Bayesian inference
involving the exponential family. J Amer Statist Soc, 88, 1419–1426.
1993
(with S. K. Upadhyay) Simulation based Bayesian approaches to the analysis of a lognor-
mal regression model. In Reliability: A Cutting Edge (P. J. Van Gestel and W. Roseboom:
Editors). Kema, pp. 196–207.
1993
(with P. Damien and P. W. Laud) Random variate generation for D-distributions. Statist
and Comp, 3, 109–112.
1993
(with D. Stephens) Bayesian inference in multipoint gene mapping. Ann Hum Genetics,
57, 65–82.
1993
(withS.K.Upadhyay)SimulationbasedBayesianapproachestotheanalysisofalognormal
regression model. Proc. SRE Symp. “Reliability of a Competitive Edge”, The Netherlands,
Vol. 1, 196–207.
1994
(with S. K. Upadhyay) Modelling complexities in reliability, and roles of Bayes simu-
lation. International Jr Cont Eng Educ: Sp. Issue on Applied Probability Mod., Vol. 4,
93–104.
1994
(with G. O. Roberts) Simple conditions for the convergence of the Gibbs sampler and
Metropolis–Hastings algorithms. Stoch Proc and Their Applic, 49, 207–216.
1994
(with J. C. Wakefield) The hierarchical Bayesian approach to population pharmacokinetic
modelling. Int J Bio-Med Comp, 36, 35–52.

694
Adrian Smith’s publications
1994
(with E. I. George and U. E. Makov) Fully Bayesian hierarchical analysis for exponential
families via Monte Carlo approximation. In Aspects of Uncertainty (P. R. Freeman and
A. F. M. Smith: Editors). Wiley, pp. 181–199.
1994
(with S. K. Upadhyay) Modelling complexities in reliability, and the role of simulation in
Bayesian computation. Int J Cont Eng Ed, 4, 93–104.
1994
(with E. J. Green, F. A. Roesch and W. E. Strawderman) Bayesian estimation for the
three-parameter Weibull distribution with tree diameter data. Biometrics, 50, 254–269.
1994
(withD.B.Phillips)Bayesianfacesviahierarchicaltemplatemodelling.JAmerStatistAssoc,
89, 1151–1163.
1994
(with P. Vounatsou) Bayesian analysis of ring-recovery data via Markov chain Monte Carlo
simulation. Biometrics, 51, 687–708.
1994
(with J. C. Wakefield, A. Racine-Poon and A. E. Gelfand) Bayesian analysis of linear and
non-linear population models by using the Gibbs sampler. Appl Statist, 43, 201–221.
1995
(with E. Gutierrez-Pena) Conjugate parameterizations for natural exponential families.
J Amer Statist Assoc, 90.
1995
(with P. Damien and P. W. Laud) Approximate random variate generation from infinitely
divisibledistributionswithapplicationstoBayesianinference.JRStatistSoc,B,57,547–564.
1996
(with S. K. Upadhyay and R. Agrawal) Bayesian analysis of inverse Gaussian non-linear
regression by simulation. Sankhya Ser. B, 58, part 3, 363–378.
1996
(with D. Gamerman) Bayesian analysis of longitudinal data studies. In Bayesian Statistics 5
(J. M. Bernardo et al.: Editors). Oxford University Press, 587–598.
1996
(with E. J. Green and W. E. Strawderman) Construction of thematic maps from satellite
imagery. In Bayesian Statistics 5 (J. M. Bernardo et al.: Editors). Oxford University Press,
181–196.
1996
(with P. Vounatsou) Graphical methods for simulation-based Bayesian inference. In
Bayesian Statistics 5 (J. M. Bernardo et al.: Editors). Oxford University Press, 773–782.
1996
(with P. Damien and P. W. Laud) Implementation of Bayesian non-parametric inference
based on beta processes. Scand J Statist, 23, (1), 27–37.
1996
Mad cows and ecstasy: chance and choice in an evidence-based society. J R Statist Soc, A,
159, 367–383.
1996
(with P. Vounatsou) Bayesian analysis of contingency tables: a simulation and graphic-
s-based approach. Statist Comput, 6, 277–287.
1996
(with U. E. Makov and Y-H. Liu) Bayesian methods in actuarial science. The Statistician, 45,
503–515.
1996
(with D. A. Stephens, P. Dellaportas and I. Guttman) A comparative study in perinatal
mortality using a two component mixture model. In Bayesian Biostatistics (D. A. Berry and
D. K. Stangl: Editors). Marcel Dekker, New York.
1996
(with P. Damien and P. W. Laud) A Monte Carlo method approximating a posterior hazard
rate process. Statistics and Computing, 6, 77–84.
1997
(with S. T. B. Choy) On robust analysis of a normal location parameter. J R Statist Soc, B,
59, 463–474.
1997
(with R. Moskovic and P. L. Windle) Modeling Charpy impact energy property changes
using a Bayesian method. Metallurgical and Materials Transactions, A, 28, 1181–1193.
1997
(with L. A. Foreman and I. W. Evett) A Bayesian approach to validating STR multiplex
databases for use in forensic casework. Int. J Legal Med. 110, 244–250.
1997
(with P. Damien and P. W. Laud) Bayesian estimation of unimodal distributions. Comm in
Stat, 26, 429–440.
1997
(with P. Damien and P. W. Laud) Bayesian nonparametric and covariate analysis of failure
time data. In Practical Nonparametric Bayes (D. Dey, D. Sinha and P. Mueller: Editors).
Springer-Verlag, New York.

Adrian Smith’s publications
695
1997
(withD.A.StephensandR.Moskovic)Charpyimpactenergydata:AMarkovchainMonte
Carlo analysis. Appl Statist, 46, (4), 477–492.
1997
(with L. A. Foreman and I. W. Evett) Bayesian analysis of DNA profiling data in forensic
identification applications. J R Statist Soc, A, 160, (3), 429–469.
1997
(with E. Gutierrez-Pena) Exponential and Bayesian conjugate families: review and exten-
sions. Test, 6, (1), 1–90.
1998
(with J. J. Deely) Quantitative refinements for comparisons of institutional performance.
J R Statist Soc, A, 161, (1), 5–12.
1998
(with N. Lynn and N. Singpurwalla) Bayesian assessment of network reliability. SIAM Rev,
40, (2), 202–227.
1998
(with P. Laud and P. Damien) Bayesian nonparametric and covariate analysis of failure
time data. In Practical Nonparametric Bayes; D. Dey, D. Sinha and P. Mueller: Editors),
Springer-Verlag, New York, 213–225.
1998
(with D. G. T. Denison and B. K. Mallick) Bayesian MARS. Statistical Comp., 8, 337–346.
1998
(with D. G. T. Denison and B. K. Mallick) A Bayesian CART algorithm. Biometrika, 85,
363–377.
1998
(with D. G. T. Denison and B. K. Mallick) Automatic Bayesian curve fitting. J R Statist Soc,
B, 60, 333–350.
1999
(with R. A. Haro-Lopez) On robust Bayesian analysis for location and scale parameters.
Journal of Multivariate Analysis, 70, 30–56.
1999
(with S. G. Walker, P. Damien and P. W. Laud) Bayesian nonparametric inference for ran-
dom distributions and related functions (with discussion). J R Statist Soc, B, 61, 485–516.
1999
(with B. K. Mallick and D. G. T. Denison) Bayesian survival analysis using a MARS model.
Biometrics, 55, 1071–1077.
2000
(with S. K. Upadhyay and N. Vasisha) Bayes inference in life testing and reliability via
Markov chain Monte Carlo simulation. Sanhkya, Series A, 62, 203–222.
2000
(with D. Ashby) Evidence-based medicine as Bayesian decision-making. Statistics in
Medicine, 19, 3291–3305.
2000
(with P. Dellaportas and P. Stavropoulos)Bayesian analysis of mortalitydata. J R Statist Soc,
A, 275–292.
2001
(with S. K. Upadhyay and N. Vasisha) Bayes inference in life testing and reliability via
Markov chain Monte Carlo simulation. Sanhkya, Series A, part I, 63, 15–40.
2003
(with C. J. Hoggart and S. G. Walker) Bivariate kurtotic distributions of garment fibre data.
Applied Statistics, 52, Part 3, 323–335.

This page intentionally left blank 

Index
ABC, 154, see also approximate
Bayesian computation
accelerated failure time (AFT),
594–595, 601–608
action space, 484
adaptive importance sampling,
154
adaptive MCMC, 100, 125
adaptive Metropolis–Hastings
(AM) algorithm, 128–129
adaptive scale
Metropolis–Hastings
(AMS) algorithm, 129–130
adaptive scaling within the
adaptive
Metropolis–Hastings
(ASWAM) algorithm,
130–131
convergence of adaptive
MCMC algorithms, 135–137
robust adaptive
Metropolis–Hastings
(RAM) algorithm, 131–133
single component adaptive
Metropolis (SCAM)
algorithm, 137–138
Akaike information criterion
(AIC), 327
allocation, adaptive, 563
alpha-splitting, 577
annealed importance sampling,
123–124
approximate Bayesian
computation (ABC), 154
approximation error, 648
approximation error model,
630, 648
asset allocation, 503
optimal allocation, 504
asset pricing, 434
attrition, 532, 534
autocorrelation, 468, 476, 532
autoregressive (AR) model, 146
average squared jumped distance,
126–127
Barlett’s paradox, 366, see also
Jeffreys–Lindley paradox
base measure, 398
basis functions
Demmler Reinsch basis
functions, 311
radial basis functions, 323
batch-means, 91
BATTLE, 565
Bayes factor, 362, 364, 367, 370,
384, 425, 470
fractional Bayes methods, 381
intrinsic Bayes factor, 488
lower bounds on Bayes factor,
367, 369
Bayes rule, 566, 572, 588
Bayes theorem, 648
Bayesian additive regression trees,
455
Bayesian asymptotics, 256
Bayesian inference in particle
physics, 673
Bayesian information criterion
(BIC), 327, 384
Bayesian machine learning, 50
Bayesian melding, 45
Bayesian methods in finance,
501
dynamic learning, 510
Bayesian model averaging
(BMA), 483
ensemble BMA, 496
Bayesian model selection,
347–352
Bayesian model specification,
410
Bayesian nonparametric mixture
model, 71
Bayesian nonparametric
prior-distribution
specification, 423
Bayesian nonparametric
regression, 297
Bayesian nonparametric
sampling-distribution
specification, 417
Bayesian nonparametrics, 249
Bayesian p-value
partial posterior predictive
p-value, 387
plug-in p-value, 386
posterior predictive p-value,
386
predictive p-value, 386
biomarker barrier, 564
block maxima, 183
blocked Gibbs sampling, 469
Barndorff–Nielsen hyperbolic
distribution, 550
calibration cross-validation, 411
categorical outcomes, 98, 99
censoring, see Tobit model
classification, 466
classification and regression trees
(CART), 492
clinical trial design, 576
complexity in Bayesian
modelling, information
extraction, 453
composition sampling, 42
computer model emulation,
155
conditional frequentist, 368
conditionally independent, 192
conditionally independent
hierarchical models
(CIHM), 35, 40
conditioning by Kriging, 194
confidence intervals, 363, 368

698
Index
conjugate
density, 399
distribution, 395
posterior, 403, 406
prior, 398, 399
consistency, 265, 376
continual reassessment method
(CRM), 561
copula
Archimedean, 340
discrete, 342, 352–355
Gaussian, 345, 353
inversion, 341
vine, 342–343
copula function, 339
correlation length, 659
counterfactual, 528
covariance estimation, 435
covariance function; correlation
function, 40, 41
credibility
credibility factor, 547
credibility formula, 547
credibility theory, 546, 547
exact credibility, 549
cross-validation, 471, 475, 479,
480, 487
curve-fitting, 114–116
Dahlhaus-locally stationary
process, 328
data augmentation, 309, 314–318
data augmentation, latent
variable, 466, 470, 475
data fusion; data assimilation, 45
de Finetti’s theorem, 19
de Finetti, Bruno, 19
decision problem, 566
sequential, 568
decision space, 488
decision, optimal, 566, see Bayes
rule
density estimation, 568
density ordinate, 99, 100
density regression, 570
dependence, measures of,
343–344
design, proper Bayes, 563
developmental toxicity studies,
70
deviance information criterion
(DIC), 383
diagonally dominant, 41
diffusion process, 285
Dirichlet process (DP), 39, 73,
271, 297–299, 487, 569, 581,
597–603
dependent, 71
Dirichlet process mixture, 297
stickbreaking construction, 272
total mass parameter, 273
discount factor, 148, 155
discriminant models, 492
distributed parameter estimation,
647
divergence, 406
Kullback–Liebler, 396, 398, 406
DLM see dynamic linear model
dose-response relationship, 71
dynamic factor model, 169–71,
177
dynamic graphical model, 158
dynamic latent factors, 156
dynamic linear model (DLM),
145, 171, 186, 187
DLM discount factor, 188
DLM-GEV distribution, 188
first-order polynomial DLM,
187
dynamic model, 42, 203, 204, 395
dynamic principal components,
156
dynamic regression, 146
dynamic selection, 527, 528
dynamic sparsity, 159
dynamic systems biology models,
154
E-insensitive loss, 53, 55, 57, 58
E-M algorithm, 35
EEG, 159
EEG time series, 155
EffTox, 561
eigensystem, 654
electrical impedance tomography,
652
endogenous, 525, 528, 529
enhanced error model, 654
entropy, 396
differential, 396
generalized, 406
maximum, 395
minimum relative, 395, 397
relative, 396
equi-energy sampler, 122–123
equivalent sample size, 400
ergodicity
ergodic limit theorem, 91
sample path average, 91
uniformly ergodic, 91, 93
error rates
evaluation, 585
false negative rate, 580
false subgroup rate, 580
true positive rate, 580
true subgroup rate, 580
type I error, 580
errors-in-variables, 37
evolutionary Monte Carlo,
121–122
EWOC, 561
exchangeability, 19, 271
definition, 6
partial, 22
representation theorem, 9
row-column, 23
second order, 12, 24
second order representation
theorem, 12
exchangeable, 402
exchangeable models, Prior
inference theorem for, 17
exchangeable partition, 273
exchangeable time series models,
155
exclusion condition, 528
expectation
adjusted, 13
as a primitive, 10
expected utility, 486
experimental layout, 25
expert opinion, 496
exponential dispersion family, 549
exponential family, 395, 396, 398,
399, 402, 549
generalized, 407
exponential power family, 550
extreme point model, 21
factor analysis, 168, 172
factor model, 435–439
fair premium, 547
fallback procedures, 577
false discovery rate, 571
filtering, 147
financial contagion, 434–439
finite automata, 230
finite mixture models, 113–114,
126, 133
finite population sampling, 4
Fisher information, 400, 401
flexible Bayesian modelling, 455

Index
699
flexible regression modelling,
116–117
forecasting, 147
forward filtering and backward
simulation (FFBS), 43, 150,
188, 537, 538
Fourier frequencies, 319
full conditional densities, 94
full credibility, 547
full-sample log scores (for model
comparison), 414
Gaussian graphical model, 158
Gaussian kernel, 54, 66
Gaussian Markov random fields
(GMRF), 190, 192–194
canonical parameterization
GMRF, 194
GMRF prior, 193
second-order intrinsic GMRF,
192
Gaussian process, 40, 45, 73, 172,
175, 177, 440
Gaussian smoothness prior, 658
generalized extreme value (GEV)
distribution
GEV likelihood function, 187
GEV log-likelihood, 184
time-varying GEV, 187
generalized linear model (GLM),
42, 395, 467, 477, 479
binomial regression, 474, 476
logistic regression, 466, 473
generalized student-t family,
550
Gibbs sampling, 34, 96, 97, 403,
466, 468, 518, 537, see also
Markov chain Monte Carlo
(MCMC)
global air temperature anomalies,
324, 326–327
graphical models, 435
greatest accuracy credibility
theory, 547
Hammersley–Clifford theorem,
519, 524
Harris recurrent, 91
heavy tails/robust inference, 467,
469
hidden Markov model, 42
hierarchical model, 22, 23, 27, 171,
177, 395, 402–404, 530, 538,
557
highest probability model,
485
hinge loss, 33
multicategory, 53
hyper-inverse Wishart
distribution, 158
hyperparameters, 549
canonical, 399, 402
hypothesis testing, 361, 470
ill-posed problem, 621
imputation, 36
inclusion probabilities, 370, 374
information consistency, 372
information theory, 396
initial boundary value problem,
645
instrumental variable, 540
integrated nested Laplace
approximation (INLA), 35
integro-difference equation,
43, 44
interaction tests, 577
intersubjective model, 20
intervention, 148
invariance, 20, 88, 372, 377
invariant distribution, 90, 91
inverse problem, 619, 645
inverse Wishart autoregression,
159
inverse Wishart processes, 158, 159
inverse-Wishart autoregressive
model (IW-AR(1)), 159
ISPY-2, 564
Jeffreys–Lindley paradox, 366, see
also Bartlett’s paradox
Kalman filter, 42, 43, 147, 207, 537,
538
Kelly rule, 504
kernel machine, 50, 51, 53, 68
Krein–Milman theorem, 429
L-unbiased, 404
Laplace approximation, 35, 384,
403
LARS algorithm, 474
lasso, 436
latent factor model, 156
latent threshold model (LTM),
159
latent variables, 34, 36, 37, 98, 99,
278, 532, 536
modelling, 278
learning model, 251
learning, dynamic learning, 510
likelihood model, 648
limited fluctuation credibility,
547
linear dependent Dirichlet
process, 601–602
linear dependent tailfree process,
602–603
linear regression, 452, 466, 518
local tomography, 656, 658
location dispersion family, 550
log generalized inverse Gaussian
distribution, 550
log scoring rule, 488
log-gamma distribution, 550
logistic regression, 133
lognormal, 550
long run asset allocate, 507
loss
function, 404, 406
Kullback–Liebler, 400, 405
squared error, 400, 404, 405
marginal likelihood, 88, 100, 474
computation, 383
marginal prior model, 653
marginalization, 648
Markov chain Monte Carlo
(MCMC), 35, 38, 72, 87, 168,
170, 403, see also Gibbs
sampling
convergence, 90, 135–137
convergence of adaptive
MCMC algorithms, 135–137
Gibbs sampling, 518, 537
Multiple block MCMC, 94, 96
population MCMC, 117–121
reversible jump, 168, 105–109,
171, 301–302, 327, 328, 469
sampling, 301–302
Markov chain, inhomogeneous,
475
Markov process, 287
Markov properties, 285, 287
Markov random field, 682
Markov random field prior,
Gaussian smoothness prior,
658
Markov transition kernel, 88
massive data, 466
matrix normal distribution, 155
matrix normal DLM, 158

700
Index
matrix time series, 158
maximum a posteriori (MAP)
estimate, 649
maximum entropy
method, 627
principle, 397, 627
maximum likelihood estimator,
396, 405, 406
maximum tolerable dose, 561
mean square error (MSE), 548
median intrinsic methods, 381
median probability model, 375,
485
meta analysis, 560
Metropolis–Hastings (MH)
algorithm, 34, 88, 89, 466,
536, 537
Adaptive DAMH (ADAMH),
639
adaptive Metropolis (AM), 636
delayed acceptance MH
(DAMH), 638
delayed rejection AM
(DRAM), 636
independence M-H, 93
Langevin M-H, 92
Metropolis–Hastings–Green
(MHG), 632
Metropolis-within-Gibbs, 97,
475
Metropolis-within-Gibbs
sampling, 137–138
parallel adaptive chains, 637
proposal density, 88, 92, 94
minimal training sample, 381
minimum discrimination
information, 397
minimum relative entropy
principle, 397
missing data, 147, 519–522, 525,
532, 533
misspecified model, 257
mixed model, 26
mixing (of probability
distributions), 525, 540
mixture, 560
mixture models, 38, 39, 152, 273
composite mixtures, 234
mixture of Dirichlet process, 253
mixtures-of-experts, 327, 328
model
autoregressive distributed lag,
527
duration (see hazard model)
dynamic selection (see
dynamic selection)
hazard, 539
Heckman (see selection)
hidden Markov model, 539
hierarchical, 557
matching, 529
nonparametic, 283
probit, 523, 524, 530–535
state-space, 536
switching regression, 528, 539
Tobit, 526, 528, 532, 535, 539
model averaging, 153, 372, 375,
467
model choice, 483
model criticism, 385
model monitoring, 149
model reduction, 649
model selection, 434, 467, 483,
578
M-closed, 484
M-complete, 483
M-open, 483
model space, 578
model structure, 373
model uncertainty, 369, 483
modelling errors, 645
modified predictive process,
175
multi-level stochastic model, 33
multi-process models, 153
multimodal targets, 134–135
multiple testing, 440, 577
multiplicities, 570
comparison, multiple, 570
multiplicity, 384, 385
adjustment, 578
control, 577
multivariate stochastic volatility
model, 155, 157, 158
mutual information, 397, 406
national security, 229
newgroup classification, 242
non-linear dynamic model, 162
non-linear interaction, 460
non-stationary trend, 150
nonlinear regression models,
110–113
nonparametric, 549
nonparametric Bayes, 568
nonparametric priors
construction via
augmentation, 278
dependent, 283
geometric weights, 272, 277
Poisson–Dirichlet, 272
posterior inference for, 280
nonparametric regression, binary,
314–316
numerical standard error, 91
objective Bayesian, 362
Ockham’s razor, 367, 376
odds, 363, 364
operating characteristics, 578
optimal decisions rules, 483
ordinal categorical data, 36
ordinal regression, 480
orthogonal iterations, 654
orthogonalized parameters, 377,
378
outliers, 149, 317, 318
output analysis, 100
p-values, 367, 369
panel data, 529–535
parameter
canonical, 396, 398, 405
mean, 396, 400, 405
parametric inference, 395
partial correlation, 347
partial credibility, 547
partial differential equation, 645
particle filtering, 100, 154, 203
particle learning, 214, 230
partition model, 276
penalization priors
horseshoe prior, 480
normal-gamma (NG) prior,
480
penalized regression
Laplace/double
exponential/L1/lasso, 466,
467, 475, 480
lasso penalty, 490
periodogram, 319, 320
phase I, 561
phase II studies, 561
phase space, 675
plausible hypothesis, 364, 365
Poisson–Dirichlet (Pitman–Yor)
process, 303
Polya tree (PT), 570, 598–603
Polya urn representation, 272
Polya urn, zero enriched, 582
polychotomous regression, 480
polynomial kernel, 54, 59, 66

Index
701
polynomial trend DLM, 146
population genetics, 26
population models, 560
population pharmacokinetics/
dynamics (PK/PD), 560
portfolio balancing, 466
posterior distribution, 652
posterior model, 649, 652, see also
posterior distribution
power-posterior, 474
pre-marginalization, 648
precise hypothesis, 365, 366
prediction, 487
predictive matching, 371, 377, 379,
380
predictive probability, posterior,
563
PRESS criterion, 490
principal component analysis,
655
principle of indifference, 626
prior
correlation matrix, 346
Jeffreys’, 305, 400, 407
Laplace, 400
maximum likelihood, 405
non-informative, 395, 399–401,
407
unbiased, 395, 401
uniform, 400
prior distribution
evaluating priors, 383
expected posterior priors,
382
g-priors, 378, 379
intrinsic priors, 381
mixture of g-priors, 379
prior for models, 370, 371
priors for model parameters,
371, 378
right-Haar priors, 377, 379
vague proper priors, 366
Zellner–Siow priors, 378, 379
prior inference, 16
prior model, 648
process convolution, 678
product space, 469
quadratic loss, 485
quadrupole, 674
quasi-cyclic time series, 150
R
glmnet package, 479, 480
monomvn R package, 467, 470,
480
reglogit R package, 467, 477
random effects, 530–535
random model, 25
random partition, 273
posterior for, 274
prior for, 273
Rao–Blackwellization, 100, 475
regime changes, 528, 540
regional climate model (RCM),
190, 191, 194
regression, 175, 177–8
regression model, 264
regularization, 466
method of 623
rejection sampling, 475
relevance vector machine
(RVM), 51, 53, 55, 57, 58, 60,
66, 67
representation theorem, 256
reproducing kernel Hilbert space
(RKHS), 51, 52, 55, 56, 60, 63,
67, 68
response, delayed, 564
retrospective analysis, 148
reversibility, 88
ridge regression/L2, 480
risk
entropy, 395
Kullback–Liebler, 405
risk assessment, 70
risk aversion, 504
risk exposure, 548
robust regression, 317
robustness, 540
sampling, 653
sampling model, 397, 398
scale mixture of normals, 469
scale-dispersion family, 550
search on model space, 384
seasonal model, 146
second-order Bayes estimators,
549
seismic data, 330–332
selection, 522, 524–527, 532–535
dynamic, 527, 528
self-selection, 525
semisupervised learning, 229
sequential Monte Carlo (SMC),
154, 203, 208
sequential updating, 147
simulated annealing, 474
simulation-consistent, 90
Sklar’s theorem, 337–338
small area estimation, 558
SMC, see Sequential Monte Carlo
(SMC)
smoothing, 148
smoothing parameter, 310
Southern Oscillation Index, 329,
330
spam detection, 236
sparse regression, 435
spatial process, 172
spatio-temporal, 172
spatial statistics, 172, 178
spectral density, 318–320, 328,
329
splines
locally adaptive smoothing
splines, 326
multi dimensional smoothing
splines, 323
penalized splines, 326
polynomial splines, 309, 310
regression splines, 313, 326
smoothing splines, 309–332
thinplate splines, 323
stacking, 490
state space model, 42, 145
stationary distribution, 88
stochastic approximation, 549,
550
stochastic process, 271, 283
stochastic search, 459
stochastic volatility models, 154,
502
stopping, sequential, 563
structural equation model, 178,
536–538
subgroup analysis, 572, 576
subgroup reporting
as a decision problem, 586
procedure, 584
treatment-subgroup
interactions, 577
subjective Bayesian, 362
sufficiency, 397
sufficient statistics, 21, 398, 402
sunspots data, 313–316
superposition, 146
support vector machine (SVM),
51, 53, 55, 59–62, 66–68
survival analysis, 569
symmetric location dispersion
family, 550

702
Index
symmetry
permutational, 19
rotational, 22
spherical, 23
synthetic reality, 148, 155
system biology, 162
temporal rationality, 14
temporal sure preference
principle, 14
time series, 145
components, 149
financial time series,
155
model, 258
multivariate, 169
nonstationary, 169
stationary, 169
time-varying autoregressive
model (TVAR), 146
time-varying location parameter,
186, 187
time-varying parameters, 145
time-varying periodicities, 149
time-varying spectral density,
330
time-varying variance matrix, 155
TITE-CRM, 561
traffic flow forecasting, 155
training sample, 380
transdimensional Markov chain,
469
TVAR(p) model, 149
unbiased estimator, 395, 400, 401,
406, 407
unbiasedness, 395, 401, 404, 406,
407
uncertainty, 33
union membership, 324
utility
expected utility, 502, 508
predictive utility, 509
utility function, 566
validation, 37
variable selection, 139
variable star data, 321
variance function, 396
quadratic, 400
variance, adjusted, 14
Wiener process, 310
Whittle approximation, 329
wirescanner, 675
Wishart processes, 158
worst-case expected loss, 395,
406, 407
Z-distribution, 474

