Dirk Draheim
Semantics of the
Probabilistic
Typed Lambda Calculus
Markov Chain Semantics, Termination 
Behavior, and Denotational Semantics

Semantics of the Probabilistic
Typed Lambda Calculus 

Dirk Draheim 
Markov Chain Semantics, Termination 
Behavior, and Denotational Semantics 
Semantics of the 
Probabilistic
Typed Lambda Calculus 

 
 
 
Dirk Draheim 
Large-Scale Systems Group 
Tallinn University of Technology 
Tallinn, Estonia 
ISBN 978-3-642-55197-0 
ISBN
 
978-3-642-55198-7
 
(eBook)
 
DOI 10.1007/978-3-642-55198-7 
 
Library of Congress Control Number: 2017932370
 
© Springer-Verlag Berlin Heidelberg 2017 
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of 
the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation, 
broadcasting, reproduction on microfilms or in any other physical way, and transmission or information 
storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology 
now known or hereafter developed.  
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication 
does not imply, even in the absence of a specific statement, that such names are exempt from the relevant 
protective laws and regulations and therefore free for general use.  
The publisher, the authors and the editors are safe to assume that the advice and information in this 
book are believed to be true and accurate at the date of publication. Neither the publisher nor the authors 
or the editors give a warranty, express or implied, with respect to the material contained herein or  
for any errors or omissions that may have been made. The publisher remains neutral with regard to 
jurisdictional claims in published maps and institutional affiliations.  
 
Printed on acid-free paper 
 
This Springer imprint is published by Springer Nature 
The registered company is Springer-Verlag GmbH Germany 
The registered company address is: Heidelberger Platz 3, 14197 Berlin, Germany 

Preface
Today’s information systems operate in probabilistic environments. Programs
need to react to probabilistic events. Therefore, a rigorous understanding of
probabilistic program behavior becomes ever more important. Probabilistic
programming is relevant in its own right, as a means to implement random-
ized algorithms. This book takes a foundational approach to the semantics
of probabilistic programming. It deals with the probabilistic typed lambda
calculus, which is the typed lambda calculus with recursion plus probabilistic
choice.
We elaborate a Markov chain semantics for the probabilistic lambda cal-
culus. As part of this operational semantics, we deﬁne a reduction semantics
and an evaluation semantics in terms of Markov chain hitting probabilities.
The Markov chain semantics unlocks probability theory and Markov chain
theory to be used in reasoning about probabilistic programs. Also, we intro-
duce the notions of reduction graphs and reduction trees. Reduction graphs
and reduction trees are not part of but rather accompany the Markov chain
semantics. They unlock results from graph theory. These prove useful, e.g., in
reasoning about termination behavior. On the basis of this, we investigate the
termination behavior of probabilistic programs. We introduce the notions of
termination degree, bounded termination and path stoppability and investi-
gate their mutual relationships. Path stoppability characterizes a broadened
class of termination and allows for the computation of program runs that are
otherwise considered as non-terminating.
Furthermore, we elaborate a denotational semantics for the probabilistic
lambda calculus. The domains of this denotational semantics are probabilistic
pre-distributions as base domains and ω-continuous function spaces as higher-
type domains. We show the basic correspondence between the denotational
semantics and the established Markov chain semantics.
Tallinn, November 2016
Dirk Draheim
V

Contents
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.2
The Probabilistic Lambda Calculus . . . . . . . . . . . . . . . . . . . . . . . .
5
1.3
Termination Behavior of Probabilistic Programs . . . . . . . . . . . . .
9
1.4
Denotational Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
1.5
Chapter Outline and Further Remarks . . . . . . . . . . . . . . . . . . . . . 14
2
Preliminary Mathematics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
2.1
Probability Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
2.2
Markov Chains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
2.3
Graph Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
2.4
Inductive Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
2.5
Miscellaneous . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
3
Syntax and Operational Semantics . . . . . . . . . . . . . . . . . . . . . . . . . 65
3.1
Syntax of the Probabilistic Lambda Calculus . . . . . . . . . . . . . . . . 66
3.2
Operational Semantics of the Typed λ-Calculus . . . . . . . . . . . . . 73
3.3
The Probabilistic Operational Semantics . . . . . . . . . . . . . . . . . . . 76
3.4
Important Readings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
4
Termination Behavior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
4.1
Introductory Examples of Termination Behavior . . . . . . . . . . . . . 96
4.2
Bounded and Unbounded Termination . . . . . . . . . . . . . . . . . . . . . 101
4.3
Program Executions and Program Runs . . . . . . . . . . . . . . . . . . . . 103
4.4
The Reduction Graph . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
4.5
Central Graph Cover Lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
4.6
Path Stoppability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
4.7
Program Reduction Trees. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127
4.8
Characteristics of Bounded Termination . . . . . . . . . . . . . . . . . . . . 131
VII

VIII
Contents
5
Denotational Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
5.1
Domains and Denotations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
5.2
Well-Deﬁnedness of the Denotational Semantics . . . . . . . . . . . . . 145
5.3
Semantic Correspondence. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157
5.4
Important Readings on Domains and Probabilism . . . . . . . . . . . 189
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211

1
Introduction
In this book, we are interested in systems that consist of programmable com-
ponents and encounter probabilistic impact. We ﬁnd such systems in many
application areas, i.e., whenever a software-intensive system operates in a
dynamic, vague environment: control systems, production systems, logistics
systems, socio-technical systems of any kind. Also, the components of these
systems themselves may show probabilistic behavior. However, probabilistic
programs are interesting also in their own right, i.e., even if the probabilism is
not a circumstance that we need to deal with, but is generated for the sake of
probabilistic programming itself. This is the ﬁeld of randomized algorithms.
Randomized algorithms become ever more important in practice, in particu-
lar, in the ﬁeld of cryptographic systems. In this book, we are interested in
the semantics of probabilistic programs. And we are interested in systematic
reasoning about probabilistic programs.
We take a foundational, completely reductionist approach. We narrow our
investigation to a maximally reductionist programming language, the typed
lambda calculus with recursion. We enrich this lambda calculus by a single
programming construct for probabilistic choice, which yields the probabilistic
typed lambda calculus, which we also often call just the probabilistic lambda
calculus for short. We investigate both the operational semantics and the de-
notational semantics of the resulting calculus. First, we will delve into the
operational semantics. On top of its basic operational semantics, we system-
atically give a Markov chain semantics to the probabilistic lambda calculus.
This way we unlock the whole machinery of probability theory, in general, and
Markov chains, in particular, for reasoning about probabilistic program sys-
tems. We use this mathematical machinery to systematically investigate the
termination behavior of probabilistic programming systems. We will come
up with a broadened notion of termination, so-called path stoppability. Path
stoppable programs have a ﬁnite term cover, therefore, linear algebra can
be exploited to determine the probability with which program outcomes are
reached. Our investigation yields a precise inﬁnitesimal understanding of the
termination degree of a program.
© Springer-Verlag Berlin Heidelberg 2017
D. Draheim, Semantics of the Probabilistic Typed Lambda Calculus,  
DOI 10.1007/978-3-642-55198-7_1 
1

2
1 Introduction
Next, we will deﬁne a denotational semantics of the probabilistic lambda
calculus. Denotational semantics is the Scott-Strachey approach to the se-
mantics of programming languages [243]. The mathematical beauty of deno-
tational semantics stems from its compositionality resp. de-compositionality.
A denotational semantics is given inductively along the abstract syntax of
a programming language. It establishes a correspondence of syntactical and
semantical constructors. This way, a denotational semantics achieves imple-
mentation independency [238], i.e., it can be considered the speciﬁcation
of a programming language. Denotational semantics has developed into the
de facto standard for the investigation of programming language semantics,
see [192, 253, 224, 117, 103, 118]. Moreover, denotational semantics gave rise
to domain theory, see [239, 240, 105, 116, 106] and also [224, 117, 3]. Domain
theory provides and investigates appropriate mathematical structures for pro-
gramming language semantics. However, domain theory is not only important
when teamed together with denotational semantics, rather, it yielded impor-
tant results in its own right. Most importantly, in [240] Dana Scott found
a model for the untyped lambda calculus. In [242], Dana Scott incorporates
probabilism into such a model. This way, the semantics for untyped prob-
abilistic lambda calculi, called stochastic lambda calculi in [242], has been
achieved.
In this book we deal with the typed probabilistic lambda calculus. And also
with respect to denotational semantics we only deal with the typed version
of the probabilistic lambda calculus. We will deﬁne a denotational seman-
tics for the probabilistic lambda calculus based on ω-cpos (ω-complete partial
orders). We use pure probability pre-distributions as ω-cpos. In the case of
call-by-name semantics the probabilistic choices at higher types can be ﬂat-
tened denotationally to probabilistic choices of ground type. This way, in case
of call-by-name we need distributions only in the construction of the base do-
mains but no nested constructions as higher types. Also, we prove the basic
corresponce between the denotational semantics and our operational Markov
chain semantics.
In the upcoming sections we will give a more detailed overview of the
motivation and the contributions as well as pointers to important literature. In
Sect. 1.1 we motivate the book’s investigations from the perspective of system
simulation and system analytics as well as from the perspective of randomized
algorithms. In Sect. 1.2 we outline the probabilistic lambda calculus and its
Markov chain semantics. In Sect. 1.3 we explain what will be achieved with
respect to the analysis of termination behavior of probabilistic programs. In
Sect. 1.4 we give an outline of our denotational semantics. In Sect. 1.5 we give
further remarks on the book’s content and provide a chapter outline of the
book.

1.1 Motivation
3
1.1 Motivation
In the IT sector, we have many systems that are mere data-processing sys-
tems. Their task is to capture some data, maybe transactional, and to process
and keep them for us [83, 82, 34, 89, 86, 79, 78]. We may ﬁnd such systems
in enterprise computing [85, 84, 75, 10], e.g., enterprise resource-planning sys-
tems, customer relationships management systems, any kind of master data
management systems, e.g., identity management systems, any kind of data
repositories, optical archives, information bases and so forth. Of course, all of
these systems are no silos and oﬀer interfaces to their environments. They are
used by humans and also other information systems. However, the interaction
with such systems is usually conﬁned to data access.
On the other hand, we see many software-intensive systems that are highly
engaged, i.e., actively engaged, with their environment. They react to external
triggers. They adapt to the changing state of their environment. This is, in
a sense, the realm of agent-oriented systems [261, 132, 133]. Examples stem
from the ﬁeld of control systems, robotics, manufacturing execution systems,
production planning systems or logistics systems. The degree of interaction,
e.g., in terms of frequency, reaction time or criticality may greatly vary. Also,
the frontiers to the data-processing systems mentioned above vanish more and
more in today’s system landscapes: business process management systems [74,
7, 10, 73] become adaptive [167, 229, 260, 76, 135, 88, 8, 80], decision support
systems become reactive [120, 256], etc. In general, IT systems become ever
more adaptive. With cloud computing [100, 77], elasticity of IT infrastructure
has become mainstream [188].
Also, we might want to deal with internal components of the system that
show probabilistic behavior, i.e., we need to deal not only with external but
also internal probabilistic events.
The described systems are all highly relevant and there are two very impor-
tant and huge communities that deal with them, i.e., the community of model
checking and the community of model-based design. We will give some further
remarks on model checking and model-based design together with hints to
the respective literature in due course in Sect. 1.5. On the programming side,
reaction to probabilistic events always gives rise to non-determinism. If we
know the statistical distribution of the relevant external events this opens the
opportunity of probabilistic reasoning about the overall system. If we have
a rigorous model of how probabilities propagate through the programmed
systems, we can make assumptions on program outcomes and overall sys-
tem behavior. Given the Six Sigma approach [125, 126] the potential of such
statistically founded reasoning should be immediately clear for the ﬁeld of
numerical control and manufacturing execution systems. Consider an exam-
ple from a higher-level use case, i.e., from the domain of logistics. Consider a
stock management system. A stock management system would react to events
concerning the amount of incoming goods, overrunning or too scarce stock-
piles and maybe other variable resources such as availability of employees and

4
1 Introduction
so forth. Based on that it would automatically order goods or re-distribute
goods. Now, as a mature option, the dataﬂow through a single storage could
be modeled with queueing theory [101, 115, 268, 31], also, the supply chain
consisting of a network of several storages could be modeled as a net of queues.
Other options to model the storages and their network exist. For example, we
could try to exploit stochastic extensions of Petri nets [119, 64, 13] or stochas-
tic extensions of process algebra [107, 134, 50] for this endeavor. Anyhow, our
reasoning about the programmed system in the single stores should ﬁt into
the overall probabilistic model to enable seamless reasoning. Therefore, we
need a rigorous semantics of the programmed system involving probabilities.
Our approach is reductionist. We will choose the lambda calculus as a can-
didate for our investigations. We will extend it by a probabilistic choice and
give a Markov chain semantics to it. A probabilistic choice can be thought
of as an input channel, yielding a reductionist, binary external information
“left” or “right”, i.e., the decision where to move next. This approach can be
considered a ﬁrst, fundamental step in the direction of an overall target – the
switch from simulation of systems to a systematic analytical approach.
By the way, against the background of the above storage example, it is
worth noting that there exist several business-process-modeling tools that
oﬀer features for process simulation. Simulation is exactly about forecasting
the behavior of the modeled system like the ﬂow of goods through a net
of storages as described above. However, to our best knowledge, we do not
know of a single business-process-modeling tool that incorporates queueing
theory to support an analytical approach. This means, although with queueing
theory we have a powerful tool to analyze systems, queueing theory is not yet
consumable, i.e., it is not yet brought to the end-user, not yet brought to the
average domain expert working in the ﬁeld. Now, in computer science, or, to
be more precise, in the ﬁeld of software engineering, we actually have a long
tradition in approaching simulation systematically. The original motivation of
the ﬁrst object-oriented programming language SIMULA [212] was to create
a framework and language for system simulation. So, approaching simulation
systematically was at the root of the early object-oriented paradigm. Only
later, object-oriented programming turned into a paradigm of reusable [104],
self-responsible software components that was particularly well-suited to serve
the needs of upcoming object-oriented user interfaces. The original motivation
towards system simulation has been a little bit forgotten in the object-oriented
programming languages and design community. Instead, we can recognize the
simulation approach as a basis of the agent-oriented system and modeling
paradigm [261]. Nevertheless, in a sense, the original vision of SIMULA simply
has been turned into reality. Today’s object-oriented programming languages
are mature candidates to specify executable system models – it’s just about
programming. What we need is to raise the level to system analytics. And
there is a need to do this systematically, by building analytical features into
existing programming and modeling environments. Even better, we should

1.2 The Probabilistic Lambda Calculus
5
think about systematically applying automatic or semi-automatic reasoning
platforms [40, 39, 209] in the ﬁeld of software-intensive systems.
So far, we have considered probabilistic programming languages as em-
bedded into probabilistic environments. Here, the probabilistic programming
language is used to program components that have to react to probabilistic
events. In this perspective, our reductionist probabilistic choice models an in-
put channel that delivers information about events from the environment to
the programmed component. However, probabilistic programming is impor-
tant in its own right, in order to program algorithms stand-alone, without
relationship to an environment. Here, the probabilistic choice is fed by a ran-
dom generator, i.e., it is a programming element instead of representing an
information channel to an outside system. This is the ﬁeld of randomized
algorithms. Randomized algorithms can speed up the solution of problems
dramatically, at the price of yielding an erroneous result occasionally. For
a seminal work on randomized algorithms see [226] by Michael O. Rabin,
see also the work of Andrew C. Yao in [264] as well as Andrew C. Yao and
F. Frances Yao in [265, 266]. The classical example of randomized algorithms
is about primality testing, approached by Solovay and Strassen in [248] and
Michael O. Rabin in [227]. For an overview on the topic of randomized al-
gorithms see [205] and also [148]. For a thorough treatment of randomized
algorithms including many use cases, see [204]. An introduction to the com-
plexity theory of randomized algorithms can be found in the standard text
book on automata theory [137].
Now, a formal semantics of probabilistic programming languages also
allows for reasoning about randomized algorithms. Reductionist models of
randomized algorithms have been given as probabilistic automata in [68]
and [225]. For a formal treatment of complexity of randomized algorithms
see the seminal text book on automata and language theory by Hopcroft,
Motwani and Ullman [137], which encompasses the deﬁnition of complexity
classes on the basis of the probabilistic Turing machine. An important source
concerning the complexity theory of randomized algorithms can be found in
the quantum computing literature. See [208] for a comprehensive text book
on quantum computing and [25] for a survey of quantum computing com-
plexity theory that also clariﬁes the relationship between the complexity of
randomized algorithms and the complexity of quantum computing algorithms.
1.2 The Probabilistic Lambda Calculus
The typed lambda calculus with recursion can be considered a most reduc-
tionist functional programming language. It can be considered the essence of
functional programming languages like ML [190, 111, 193] and Haskell [138],
compare also with [24, 23, 102]. Furthermore, the typed lambda calculus with
recursion has been subject to intensive investigation in the semantics of pro-
gramming language community, where it is also called PCF (Programming

6
1 Introduction
Language for Computable Functions) [223] on many occasions. Therefore, we
have chosen it as our candidate for investigating the semantics of probabilis-
tic computation. It is the task of this section to explain how the probabilistic
lambda calculus emerges as an extension of the typed lambda calculus with
recursion, see Figs. 1.1 and 1.2. We have preferred the probabilistic lambda
calculus over other options such as the probabilistic Turing machine [68, 225].
As opposed to the Turing machine, the lambda calculus comes with a particu-
lar 3GL (third generation language) or even 4GL (fourth-generation language)
look and feel, albeit in a most reductionist form. Programs of the probabilistic
lambda calculus are particularly intuitive and easy to read, because of their
high similarity to the mathematical notation of recursive functions. Similarly,
the probabilistic lambda calculus is particularly amenable to a denotational
treatment that we will also provide in this book.
1.2.1 The Typed Lambda Calculus with Recursion
The lambda calculus in its original form, as introduced by Alonzo Church [47,
48], is an untyped language. If the lambda calculus is enriched by a type
system, it is also called the simply typed lambda calculus [19]. In order to
gain a Turing-complete typed calculus, an explicit recursion construct μ is
added to the simply typed lambda calculus. Then, the resulting calculus is
usually called the typed lambda calculus with recursion. Henceforth, we will
also refer to this calculus simply as the lambda calculus or λ-calculus if it is
clear from the context which calculus we mean.
Basically, the lambda calculus is introduced as a syntax and its operational
semantics – see Fig. 1.1. The syntax is deﬁned as context-free syntax plus a
type system which speciﬁes the notion of well-typed term. The operational
semantics is introduced in two stages. First, the so-called immediate reduction
relation is deﬁned. This speciﬁes which single steps are possible between terms.
Actually, the immediate reduction relation is a partial function from terms
to terms. The constants are considered the result values of programs. The
constants and all of those terms that are outermost abstractions are the so-
called values of the lambda calculus. It is not possible to do a further step from
a value. Values stop computations. For each other term M there exists exactly
one successor term N to which a next step is possible, which is denoted by
M −→N. This right-uniqueness of the immediate reduction relation makes the
considered lambda calculus a deterministic calculus. The considered lambda
calculus is deterministic, because a concrete reduction strategy, in our case
call-by-name, is ﬁxed for it.
The immediate reduction relation forms the ﬁrst stage of the lambda cal-
culus’ operational semantics. As the second stage the reduction relation is
deﬁned as the transitive, reﬂexive closure of the immediate reduction rela-
tion. We say that a term M reduces to another term N if it is connected to
it – in the correct direction – via the reduction relation, which is denoted by

1.2 The Probabilistic Lambda Calculus
7
type system 
 O-calculus 
context-free syntax 
M     N 
immediate reduction relation 
M     N 
reduction relation 
 
Fig. 1.1. Syntax and semantics of the λ-calculus
M
⋆−→N. We then also say that N is reachable from M. It is very interest-
ing to recognize that the speciﬁcation of the immediate reduction relation is
already suﬃcient for an implementation of the lambda calculus as a program-
ming language. It might be a bit unfair, but we could say that the reduction
relation does not add anything else but some terminology, i.e., the notion of
reachability of terms. It is actually unfair, because semantics is, ﬁrst, about
the agreement of what we actually intend with a formal language and, sec-
ond, a means to get access to further semantical tools that can be used in
reasoning about the program. Obviously, we need to agree upon the notion of
program results and, furthermore, an understanding of the reduction relation
as a transitive closure will be needed in formal argumentations on program
behavior. Nevertheless, the deﬁnition of the immediate reduction relation is
not suﬃcient for all investigations of program behavior that we might want to
conduct. Further notions, such as program reduction trees, are usually deﬁned
on top of it to gain appropriate mathematical tools for program reasoning.
Anyhow, it is worth noting that with respect to the behavior of programs,
the immediate reduction relation is already a complete speciﬁcation. This
viewpoint will also be useful in the comparison with the probabilistic lambda
calculus in due course.
In general, it is not necessary to ﬁx a reduction strategy for a lambda calcu-
lus, so that a lambda calculus may encounter some level of non-determinism.
However, such non-determinism does no harm, or, to say it better, makes no
diﬀerence with respect to the program outcomes. This is so due to the Church-
Rosser property [49]. If a program is able to reduce to a constant, i.e., if it
is a terminating program, then this constant is uniquely given. Furthermore,
we can reduce to it from any reachable intermediate term. However, the lat-
ter is not so important for us here. What interests us here is the uniqueness
of terminating program outcomes. This actually guarantees a certain level of
determinism. With respect to terminating program results, each lambda cal-
culus is deterministic, independent of the chosen reduction strategy. And here
also lies the diﬀerence between the non-determinism encountered in lambda

8
1 Introduction
calculi in general as opposed to the probabilistic lambda calculus in this book.
In the probabilistic lambda calculus, a program may terminate with diﬀerent
constants.
1.2.2 The Probabilistic Lambda Calculus Compared
Now, let us turn to the probabilistic lambda calculus, see Fig. 1.2. Syntacti-
cally, the probabilistic lambda calculus is just the typed lambda calculus with
recursion plus a program construct for probabilistic choice. Of course also the
type system is adjusted to the new terms. Now, for any two terms M and N,
the term M|N denotes the probabilistic choice of M and N. Given a program
M|N, this program executes with ﬁfty per cent probability as M and, equally,
with ﬁfty per cent as N. Again, we give the semantics in two stages. First we
deﬁne a one-step semantics. However, this time the one-step semantics is a
total function that assigns to each pair of terms M and N the probability i
with which the program may move from M to N, which is then denoted by
M
i−→N.
Of course, all terms of the plain lambda calculus are also terms of the
probabilistic lambda calculus. Each immediate reduction M −→N can be
found in the probabilistic lambda calculus as step M
1−→N. Of course, the
crucial diﬀerence lies in terms of the form M|N. In case that M ̸= N we
specify two possible reductions, i.e., a reduction M|N
0.5
−−→M and a reduction
M|N
0.5
−−→N. For each term P that is diﬀerent from both M and N, we deﬁne
an immediate one step reduction M|N
0−→P to ensure that the one-step
reduction becomes a total function. In case of terms M|M we will introduce
a possible reduction M|M
1−→M. Again, for each term P diﬀerent from M we
deﬁne a one-step reduction M|M
0−→P.
On top of the one-step semantics we then deﬁne the Markov chain seman-
tics of the probabilistic lambda calculus, see Fig. 1.2. We take closed terms
of the probabilistic lambda calculus as the states of a Markov chain S. We
take the one-step semantics as the transition matrix of this Markov chain.
Now, we deﬁne the reduction semantics of the probabilistic lambda calculus
via hitting probabilities of the Markov chain. The probability to reduce from
a term M to a term N, denoted by M ⇒N, is deﬁned as the Markov chain’s
probability of starting in M and ever hitting N. With the Markov chain se-
mantics we inherit all results from probability theory and Markov chains for
reasoning about program behavior of probabilistic programs. For example,
we can determine reduction probabilities as least solutions of linear equation
systems.
In this book we consider the lambda calculus under the call-by-name strat-
egy. This is a very common choice: note that also PCF [223] is considered with
the call-by-name strategy. The choice of call-by-name is convenient. Actually,
the results on termination behavior in Chap. 4 are independent of the call-
by-name strategy, i.e., they would also hold under a concrete call-by-value

1.3 Termination Behavior of Probabilistic Programs
9
type system 
probabilistic lambda calculus 
context-free syntax 
M     N 
one-step semantics 
S 
Markov 
chain 
i 
M  N 
reduction semantics 
Fig. 1.2. Syntax and semantics of the probabilistic lambda calculus
strategy. However, the choice of call-by-name is crucial for the denotational
semantics in Chap. 5. Here, the choice of call-by-value would result in diﬀerent
domains than the chosen ones.
1.3 Termination Behavior of Probabilistic Programs
In the deterministic lambda calculus a program either terminates or does
not. Each program corresponds to exactly one program run. This is not so
any more with the probabilistic lambda calculus. Here, a program results, in
general, in one out of many possible program runs. It is the single program run
that may terminate or not. Now, a non-deterministic program may have some
terminating program runs plus some non-terminating program runs. However,
we will deﬁne the notion of termination degree for probabilistic programs. The
termination degree of a program is the probability that it will ever reach one
of the constant values. Or, to say it diﬀerently, the termination degree of a
program is the accumulated probability of all of its terminating program runs.
Let us coin the somehow artiﬁcial term of strictly terminating program.
We say that a program strictly terminates if all of its program runs termi-
nate. Actually, with respect to terminology we are in a bit of a dilemma. We
would like to avoid calling a non-deterministic program a terminating pro-
gram. The problem is that we have the interesting class of programs with
termination degree one. In this class, there are also programs that may have
a non-terminating program run. For example, the program M = μλx.(x|0)
has a termination degree of one, however, it also has a non-terminating pro-
gram run. The program M will reach the constant 0 with a hundred per

10
1 Introduction
cent probability. On the other hand M has a non-terminating program run
M
1−→λx.(x|0)μλx.(x|0)
1−→(M|x)
0.5
−−→M
1−→· · · which is kept in an end-
less loop back to the starting term M. However, this terminating program
run has a probability of zero. Now, it would be fair to say that M is always
terminating, or just terminating for short. We prefer to say that M has a
termination degree of one and that a program that has no non-terminating
program runs is strictly terminating. All this has to do with the original ex-
plicatio of probability theory given by Kolmogorov in [163] as a model of
experimental data, and with how we usually speak about events that have
zero per cent probabilities as impossible events. The termination degree of M
equals the termination degrees of the programs μλx.0 and 0 in our semantics,
i.e., they are inﬁnitesimally “equal”.
Based on the Markov chain semantics we will be able to identify a broad-
ened notion of termination, so-called path stoppability, see Fig. 1.3. Path
stoppability is a notion of program analysis. It allows us to stop some non-
terminating programs and to determine their termination degree. Let us walk
through the example programs given in Fig. 1.3. The program (λx.x)(0|1)
is a strictly terminating program. All of its program runs terminate. This is
not so for the program M = μλx.(x|0). We have just discussed that this pro-
gram has a non-terminating program run. We will design an algorithm, let us
call it the path-stopping algorithm, that dovetails a given non-deterministic
program and detects and stops all of its endlessly looping program runs. We
will show that this algorithm terminates for all of those programs that have
a ﬁnite cover. The path-stopping algorithm implements a program analysis.
Now, program M has a ﬁnite cover, and therefore it is stoppable by the path-
stopping algorithm. It falls into the class of path stoppable programs. This is
not so for the program (μλx.(+1(x) | 0)). The cover of this program contains
inﬁnitely many terms, e.g., all terms of the form +1n(0) for each number n.
The notion of path stoppability also applies to deterministic lambda pro-
grams. We have given the corresponding examples in Fig. 1.3. The program
(λx.x)0 serves as an example for strictly terminating programs, the most
simple non-terminating program μλx.x as an example for path stoppable pro-
grams and the program μλx. + 1(x) as an example for programs that are not
path stoppable.
For path stoppable programs, it is possible to compute their termination
degrees. As a consequence, it is possible to compute all reduction probabili-
ties for path stoppable programs. We will also speak of path computability or
p-computability of reduction probabilities. In order to investigate the termi-
nation behavior of probabilistic programs as just outlined, we will need results
from graph theory. Therefore, the Markov chain semantics is teamed together
with the notion of reduction graph and the notion of reduction tree – see
Fig. 1.4. We will interpret the one-step semantics as a graph, the so-called re-
duction graph R. Based on that we will precisely deﬁne program executions,
program runs and term covers. We will tightly integrate the graph seman-

1.4 Denotational Semantics
11
probabilistic lambda calculus 
O-calculus 
strictly 
terminating 
programs 
path stoppable 
programs 
Ox.x)0
Ox.x)(0|1)
POx.x
POx.(x|0)
POx.+1(x)
POx.(+1(x) | 0))
Fig. 1.3. The λ-calculus and the probabilistic lambda calculus compared
tics with the Markov chain semantics. This way we unlock graph theoretical
results for reasoning about programs and their behavior. For example, we
will exploit König’s lemma in the investigation of termination behavior of
programs. Similarly, we deﬁne a tree semantics on top of the one-step seman-
tics. For each program M we deﬁne the tree τ[M] of program runs starting
in M. Reduction trees are deﬁned on the basis of the reduction graph R.
They provide a tree-speciﬁc viewpoint on the reduction graph and unlock
tree-speciﬁc graph theoretical results for program reasoning. For example we
will use Beth’s Tree Theorem, which is an instance of König’s Lemma, in the
investigation of bounded program termination.
1.4 Denotational Semantics
Denotational semantics is the Scott-Strachey approach to the semantics of
programming languages [243]. The denotational semantics of a programming
language is given directly in terms of the mathematical objects that are com-
puted by the programs of a programming language. A denotational semantics
targets implementation independency [238], i.e., it can be considered the spec-
iﬁcation of a programming language as opposed to the several possible imple-
mentations of this programming language. A major characteristic of denota-
tional semantics is compositionality. This means that a denotational semantics

12
1 Introduction
type system 
probabilistic lambda calculus 
context-free syntax 
M     N 
one-step semantics 
R 
reduction 
graph 
W[M] 
reduction 
trees 
S 
Markov 
chain 
term 
walks 
i 
M p N 
 
p-computation semantics 
M  N 
reduction semantics 
term 
covers 
   
hitting 
probabilities 
Fig. 1.4. Auxiliary operational concepts for the probabilistic lambda calculus
introduces an appropriate semantic constructor for each of the syntactic con-
structors of the programming language. Then, the denotational semantics is
given inductively along the abstract syntax of the programming language and
the correspondence of syntactical and semantical constructors. Given this in-
ductiveness, a denotational semantics also reveals operational semantics, i.e.,
it can be considered a program of a recursive “meta” programming language.
The point is that it does not have to rely on an operational semantics of this
pre-assumed meta programming language, it itself receives its semantics from
ﬁrst principles, i.e., the notion of inductive deﬁnitions. For more on inductive
deﬁnitions see also our primer on this topic in this book in Sect. 2.4.
Against the background of implementation independence, a denotational
semantics can be considered as coming ﬁrst. Then, it can be considered a
speciﬁcation in a programming language engineering process. However, also
the opposite perspective is admissible. Here, the denotational semantics is de-
ﬁned for an existing programming language for the purpose of clarifying its
semantics and, even more important, for unlocking the mathematical toolkit
for reasoning about program behavior. At least when we treat reduction-
ist programming languages like the lambda calculus, denotational semantics
sometimes rather has this ﬂavor of coming second, after the operational se-
mantics.

1.4 Denotational Semantics
13
The reductionist programming language and reasoning system Edinburgh
LCF (Logics for Computable Functions) [237, 190, 191, 111], also just LCF
for short, has been given a denotational semantics in [192]. The reductionist
programming language PCF, which is also based on LCF, has been given a
denotational semantics in [223]. A major task in denotational semantics is
to establish the appropriate domains from which the semantical objects are
drawn. A major challenge is to provide domains for recursively deﬁned data
types which naturally arise in programming languages. Dana Scott showed
how to solve this problem of ﬁnding solutions of recursive domain equations
even if function spaces are involved. In [240] he was able to construct a model
of the untyped lambda calculus. A model of the untyped lambda calculus
amounts to a function space that is isomorphic to itself, i.e., is a solution to
the domain equation D ∼= D →D. In general, i.e., in the case of sets, it is
impossible to ﬁnd a solution to the domain equation D ∼= D →D, because
the cardinality of D →D is larger than the cardinality of D for any set D.
In [240] such a function space has been established on the basis of complete
lattices.
The construction of domains for denotational semantics evolved into a
discipline in its own right, i.e., domain theory. The foundational challenge
addressed by domain theory is to tighten the correspondence between the
denotational semantics and the operational semantics of programming lan-
guages and to provide optimized domains for this purpose. Orthogonal to
this challenge, domain theory provides specialized domains to address various
programming language phenomena such as non-determinism or parallelism.
For texts on domain theory, see [116, 224, 3]. For comprehensive texts on
denotational semantics in general, see, e.g., [253, 235, 117, 203, 118, 263].
We will elaborate a denotational semantics for the probabilistic lambda
calculus. The chosen approach is straightforward and standard from the lit-
erature; compare with the work of Saheb-Djaromi in [232, 233]. Our deno-
tational semantics is based on ω-complete partial orders, i.e., ω-cpos. We
have that ω-cpos are, among other domains such as, e.g., complete lattices,
directed complete partial orders, a well-known choice for denotational seman-
tics. They have been used very early for this purpose, i.e., in the deﬁnition of
a denotational semantics of Edinburgh LCF, see [192]. As basic mathematical
objects of our denotational semantics, we will use vectors of real numbers in
[0, 1]. These vectors assign probability values to data points. We call these
vector probability pre-distributions, because they play the same role as dis-
tributions. There is a crucial diﬀerence to distributions. Their total mass,
i.e., the sum of all the values of all possible data points, does not necessarily
have to be a hundred per cent in case of pre-distributions. And this makes
sense. A total mass of less than a hundred per cent stands for the existence of
some non-terminating program runs. Actually, we will call the total mass of
a pre-distribution the degree of termination later. As a result, we work with-
out explicit bottom elements representing non-termination. Bottom elements
arise implicitly as distributions that assign a zero per cent probability to each

14
1 Introduction
data point. Furthermore, we will see that probabilistic choices at higher types
can be ﬂattened completely to probabilistic choices of ground type. This way,
we need distributions only in the construction of the base domains. All the
domains of higher type that we introduce in our semantics turn out to be
vector spaces, which greatly eases our argumentations and formal proofs.
Given a program M of the probabilistic lambda calculus, we will denote, as
usual, the semantical object assigned to it as [[M]]. Given a number constant
ni, its semantics is given as the (pre-)distribution that assigns a hundred per
cent probability to the so-called data point i, i.e., [[ni]](i) = 1 and [[ni]](j) = 0
for all j ̸= i. Next, we also say that ni represents the data point i and use
[ni] to denote it, i.e., [ni] = i . Similar deﬁnitions can be given for the other
ground type of the probabilistic lambda calculus, i.e., Boolean. Once we have
introduced the denotational semantics for the probabilistic lambda calculus,
we will investigate its relationship to the operational semantics. We will prove
the one-to-one correspondence at the base element level. More concretely, this
correspondence means that the semantics of a program M, applied to a data
point [c], equals the probability with which M reduces to that constant c that
represents [c], which can expressed in the notation that we have introduced
so far as follows: ([[M]][c]) = (M ⇒c).
1.5 Chapter Outline and Further Remarks
Chapter 2 is a preparatory chapter. It recaps and comments on basic math-
ematical tools needed throughout the book, in particular, from the ﬁelds of
probability theory, Markov chains, graph theory and domain theory. Also, it
delves into the topic of inductive deﬁnitions, because they form the founda-
tion of rigorous speciﬁcation of semantics. In Chap. 3 we deﬁne the syntax
and establish the Markov chain semantics of the probabilistic lambda calcu-
lus. To improve comparability we also introduce the operational semantics
of the plain, deterministic lambda calculus. In Chap. 4 we investigate the
termination behavior of the probabilistic lambda calculus. We deﬁne the no-
tion of termination degree. Furthermore, we deﬁne the notion of bounded
termination, which is about programs that do not exceed an upper bound
of steps whenever they terminate. We deﬁne the notion of path stoppability
that we have described above as a broadened notion of termination. Then,
we systematically investigate the mutual dependencies between path stoppa-
bility, bounded termination and termination degrees of a hundred per cent.
To achieve all this, the chapter establishes the graph semantics as well as
the tree semantics of the probabilistic lambda calculus. Also, it shows some
needed graph cover lemmas, i.e., the fact that the cover of a graph is al-
ready completely determined by the cover of its paths and, second, that the
ﬁnite cover of a graph is computable for all k-ary graphs that have a ﬁnite
cover and a computable edge relation. Finally, in Chap. 5 we deﬁne a deno-
tational semantics of the probabilistic lambda calculus, based on functionals

1.5 Chapter Outline and Further Remarks
15
over probability distributions as domains. As the basic semantic correspon-
dence, we show the correspondence of the denotational semantics with respect
to the Markov chain semantics.
The main focus of this book is the Markov chain semantics for the proba-
bilistic higher-order typed lambda calculus. It is a natural idea to treat proba-
bilistic computation with Markov chains, compare, e.g., to the textbook [204]
of Motwani and Raghavan on randomized algorithms and, again, to the work
on the probabilistic lambda calculus by Saheb-Djahromi in [232, 233]. Com-
pare also with, e.g., [128, 174, 38, 94, 110, 175, 72] to name a few. The book’s
aim is to fully elaborate the Markov chain semantics, i.e., to elaborate it to a
level that systematically unlocks results from Markov chain theory to be used
in reasoning about program semantics and, in particular, establishing further
formal results. This can be understood best by looking at how we exploit the
established semantics to investigate termination behavior of probabilistic pro-
grams and come up with and further investigate notions like path stoppability,
path computability and bounded termination.
The focus of the book is narrow in several ways, i.e., with respect to the
probabilistic programming phenomena it delves into, the chosen program-
ming language paradigm, the programming language semantic approaches it
exploits, the level of investigation and the motivation it stresses for its inves-
tigations. All of these aspects are mutually dependent. First, we deal with the
functional programming language paradigm and here we have chosen the most
reductionist language, i.e., the typed lambda calculus also known as Plotkin’s
PCF [223]. A thorough treatment of probabilistic imperative programming is
provided by the book [185] by McIver and Morgan.
We delve into operational semantics. Also, we work with denotational se-
mantics. We treat denotational semantics only as far as we feel is needed
to bridge our treatment into the extremely mature body of knowledge that
is established by denotational semantics and domain theory for probabilistic
computation, see Sect. 5.4 on selected important readings in the ﬁeld. We
do not look into axiomatic semantics [136] of probabilistic computing. Once
more, we want to recommend the book [185] by McIver and Morgan as an
authoritative reference. The important ﬁeld of axiomatic semantics is so rich
with respect to probabilistic computation, we do not even attempt to give
a literature overview, again, the reader might want to use [185] as a good
starting point.
The ﬁeld of model checking is extremely mature with respect to proba-
bilistic systems. The overview article [175] of Legay, Delahaye and Bensalem
provides a good entry point into the subject matter. The reason why the ﬁeld
of model checking is particularly important is because it does not stop at deﬁn-
ing and investigating formal logics and reasoning systems, but actually pro-
vides concrete implementations of model-checking platforms or model check-
ers. Important probabilistic model checkers are ETMCC [131], Prism [172],
Ymer [267], Vesta [244], and MRMC [149]. The list does not aim to be com-
plete, nor does it express preference or priority. A rigorous comparison of these

16
1 Introduction
model checkers is provided in [140] by Jansen et al. A typical model checker for
probabilistic systems allows us to model systems as discrete- and continuous
Markov chains. Based on these models, it allows for system simulation and
automated or semi-automated veriﬁcation of system properties. Probabilistic
versions of the temporal logics CTL and CTL*, i.e., pCTL and pCTL*, have
been introduced by Hansson and Jonsson in [121]. In [11, 12], Aziz et al. intro-
duce the logic CSL (Continuous Stochastic Logic), which allows for reasoning
about continuous-time Markov chains, compare also with [14], which treats,
in more depth, model checking aspects of CSL. As we said, we consider model
checking based on Markov chain models as typical, albeit other important
approaches exist such as, e.g., the application [30] of uniform continuous-
time Markov decision processes [15] to statecharts [122, 123], the GreatSPN
tool [64, 13] with respect to Petri nets, or the PEPA workbench [107, 134]
with respect to stochastic process algebras.
It is also important to mention the industrial-strength modeling environ-
ment Simulink [257] and, in particular, also its module SimEvents [114, 44].
Simulink is based on Matlab. It supports model-based design, a combination
of modeling, simulation, code generation for and veriﬁcation of dynamic sys-
tems consisting of both discrete and continuous switching blocks. Its original
domain is the domain of control systems and it is applied at several levels and
instances thereof ranging from manufacturing execution systems over embed-
ded systems to circuit design. The module SimEvents extends Simulink by
queueing-system building blocks.
Programming languages such as IBAL [218], Church [110] and Ven-
ture [180] are programming languages that contain a probabilistic program-
ming primitive. The purpose of these languages is to express stochastic models,
i.e., to generate stochastic models. They allow for querying distribution out-
comes against the traces of a probabilistic program. This way, these program-
ming languages become decision support tools. They are called probabilistic
programming languages by Stuart Russell in [231] or stochastic programming
languages in [110], however, the language IBAL is called a rational program-
ming language by Pfeﬀer in [218], because the purpose of such languages is
to support reasoning about rational agents. A precursor of IBAL was already
developed by Pfeﬀer et al. in [161].

2
Preliminary Mathematics
This chapter provides basic mathematical deﬁnitions and propositions needed
in this book. The chapter is a preparatory chapter that can be skipped on ﬁrst
reading without major loss. Nevertheless, the chapter sets the stage for the
upcoming material and it might be a good means to tune in, so I recommend
at least glancing at the material before turning to the real content of the book.
Note that I have tried to motivate each piece of mathematics in this chapter,
i.e., I would like to make clear why it is important and where it is used in
the book. I tried to create a living repository rather than a dead list of deﬁ-
nitions and theorems. Of course, a sweet spot had to be maintained between
readability and conciseness. The purpose of this chapter is many-fold. In the
ﬁrst place, it should serve as a quick and easy reference for the study of the
upcoming material. In doing so, the chapter also aims at streamlining the no-
tation used in the book. Last, but not least, we give pointers to the literature,
both to foundational texts as well as to further readings. However, the major
objective of the resulting book organization was to extract necessary standard
material from the content chapters into its own, dedicated chapter in order to
create lean and better readable content chapters. We only provide proofs in
this chapter whenever we think that the proof adds to the understanding of
other parts of the book.
We start with basic material from probability theory in Sect. 2.1, which
is at the core of the book’s topic. Then, we present basic material in Markov
chains in Sect. 2.2. In the book we will exploit Markov chains to give system-
atic operational semantics to probabilistic computations. Next, in Sect. 2.3
we turn to graph theory which will be needed as a tool to study and analyze
the operational semantics of the probabilistic lambda calculus, in particular,
to establish results about termination behavior. Then in Sect. 2.4 we discuss
various means and approaches of inductive deﬁnitions. Inductive deﬁnitions
provide the foundations of denotational semantics. Actually, at an appropriate
conceptual level, the discipline of denotational semantics can be identiﬁed with
the ﬁeld of inductive deﬁnitions. Further mathematical material and tools are
compiled in Sect. 2.5.
© Springer-Verlag Berlin Heidelberg 2017
D. Draheim, Semantics of the Probabilistic Typed Lambda Calculus,  
DOI 10.1007/978-3-642-55198-7_2 
17

18
2 Preliminary Mathematics
2.1 Probability Theory
Probability theory is the fundament of the book’s material. The original work
of Andrey Kolmogorov [162, 163, 164] is a very important source. See [37, 46,
251] for classic textbooks on the material and furthermore, e.g., [45, 17, 93, 22,
28, 95, 230]. See [163] on how probability spaces model experimental scenarios.
For a rather Bayesian interpretation of probability theory, we recommend [141]
as a mature discussion. The wide spread and classic frequentist interpretation
of probability theory is completely suﬃcient for this book.
2.1.1 Probability Spaces
A probability space consists of a set of outcomes, a set of events and a prob-
ability function. Events are modeled as sets of outcomes. The set of events
forms a sigma algebra over the set of outcomes, which means that it contains
the whole set of outcomes, the empty set and is closed under complement and
union of countable subsets. The probability function assigns real values as
probability values to the events and fulﬁlls the three axioms of Kolmogorov,
i.e., the probability values are in the range from zero to one, the probability
value of the whole set of outcomes equals one, and the probability of a count-
able set of pairwise disjoint events equals the sum of all of the individual
events.
Deﬁnition 2.1 (σ-Algebra) Given a set Ω, a σ-Algebra Σ over Ω is a set
of subsets of Ω, i.e., Σ ⊆P(Ω), so that the following conditions hold true:
1) Ω ∈Σ
2) If α ∈Σ then Ω\α ∈Σ
3) For all countable subsets of Σ, i.e., for all sequences α0 ∈Σ, α1 ∈Σ, α2 ∈
Σ, . . . it holds true that
∞

i=0
αi ∈Σ
Deﬁnition 2.2 (Probability Space) A probability space (Ω, Σ, P) consists
of a set of outcomes Ω, a σ-algebra of (random) events Σ over the set of
outcomes Ω and a probability function P : Σ →R, also called a probability
measure, so that the following axioms hold true:
1) ∀α ∈Σ . 0 ⩽P(α) ⩽1 (i.e., P : Σ →[0, 1])
2) P(Ω) = 1
3) (Countable Additivity): For all countable sets of pairwise disjoint events,
i.e., for all sequences A0 ∈Σ, A1 ∈Σ, A2 ∈Σ, . . . with Ai∩Aj =∅for all
i ̸= j, it holds true that
P
 ∞

i=0
Ai

=
∞

i=0
P(Ai)

2.1 Probability Theory
19
Note that it is a common to call the axioms (1) through (3) in Def. 2.2 the
three axioms of Kolmogorov. The original formulation in [162, 163] consists of
six axioms, i.e., (i) Σ is a ﬁeld [129], (ii) Σ contains Ω, (iii) ∀A ⊆Ω.P(A) ⩾0,
(iv) P(Ω) = 1, (v) A ∩B = ∅=⇒P(A + B) = P(A) + P(B) and (vi) the
axiom of continuity, which requires
A0 ⊃A1 ⊃A2 ⊃. . . and
∩
i⩾0 Ai =∅implies lim
n→∞P(An) = 0
(2.1)
Then, in [162, 163], countable additivity, i.e., axiom (3) in 2.2 is proven
equivalent to Eqn. (2.1) by the generalized addition theorem.
Often, we use A ∧B as well as A, B to denote the intersection A ∩B
of events A and B. Such notation is very common, in particular to denote
probabilities of events, e.g., as in P(A ∧B) or P(A1, . . . , An). We always use
the notation that seems most convenient to us in the respective context. With
respect to conditional probabilities, we equally use the notation P(A | B) as
well as the notation PB(A), depending on what is more telling or more concise
in a given situation. Usually, we use the ﬁrst form if the description of the
event B is rather too complex to be used as an index, e.g., in the case of the
Markov property in Eqn. (2.13).
Deﬁnition 2.3 (Conditional Probability) Given events A and B, the
probability P(A | B) of A conditional on B, also denoted by PB(A), is de-
ﬁned as
P(A | B) = P(A ∧B)
P(B)
(2.2)
Given a probability space (Ω, Σ, P) we call a countable collection of pair-
wise disjoint events E ⊆Σ a discrete probability distribution if the individual
probabilities of the events in E sum up to one. Basically, in this book we are in-
terested in discrete probability distributions and not in continuous probability
distributions. Therefore we also talk about discrete probability distributions
simply as probability distributions for short, or, even shorter, as distributions.
Usually, a random variable, see Sect. 2.1.3, is used to characterize a distribu-
tion as the collection of inverse images under the random variable. Note that
the collection of inverse images under a random variable is necessarily a col-
lection of disjoint events, which is due to the right-uniqueness of each random
variable. Now, it is common to call each function from an arbitrary countable
index set I into the range of probability values [0, 1] a probability function, as
long as all values of the function sum up to one. We adopt this terminology in
this book. In particular, we also need a notion of pre-distribution later, which
is an approximation to a distribution. A probabilistic pre-distribution is then
a function from a countable index set into the range [0, 1], which sums up to
a value less than or equal to one; compare with Def. 5.1. Furthermore, we call
the sum of all values of a real-valued function the total mass of this function.

20
2 Preliminary Mathematics
Deﬁnition 2.4 (Probability Distribution) A function I : S −→[0, 1] is
called a discrete probability distribution, or distribution for short,
iﬀits
domain I is at most countably inﬁnite and its total mass sums up to 1, i.e.,

s∈S
P(s) = 1
(2.3)
For us, the original explicatio of probability by Kolmogorow, i.e., the de-
duction of probability theory from its primary application ﬁeld, which is the
observation of experimental data, is very important. Here [163], it is explicitly
stated that an event that has probability zero is not impossible. Rather, it
is said that an event with probability zero is practically impossible, however,
the notion of practical impossibility has been created to have a concept that
is diﬀerent from impossibility. Furthermore, it is said that all the events of a
probability space are considered a priori as possible. This means if we want
to model a certain outcome as impossible, we should, from the outset, not
include it in the set Ω of outcomes of the probability space. In particular,
with our Markov chain semantics for the probabilistic lambda calculus we
leave open the question whether a probability of zero in our transition matrix
stands for an impossible or a practically impossible move. All of this should
not bother us, it is not too important for the development of the subsequent
theory, but should be kept in mind for further, advanced discussions. Either
way, in this book we prefer to talk about events with a 100% probability or
events with a zero percent probability instead of sure and impossible events.
2.1.2 Properties of Probability Spaces
In this section we list some basic properties of each probability space (Ω, Σ, P).
The facts are an application of measure theory, i.e., the properties follow from
the fact that (Ω, Σ) is a measurable space and (Ω, Σ, P) is a measure space
with measure P, see, e.g., [17, 28, 22, 230], compare also with Def. 2.9.
Lemma 2.5 (Monotonicity) If A ⊂B for A, B ∈Σ then P(A) ⩽P(B).
Lemma 2.6 (Sub-Additivity)
Given a countable set A0, A1, A2, . . . of
events Ai ∈Σ we have that
P
 ∞

i=0
Ai

⩽
∞

i=1
P(Ai)
(2.4)
Lemma 2.7 (Continuity from Below) Given a (strictly) ascending chain
of events, i.e., a countable set A0 ⊂A1 ⊂· · · of events Ai ∈Σ we have that
P(
∞

n=0
An) = lim
n→∞P(An)
(2.5)

2.1 Probability Theory
21
Lemma 2.8 (Continuity from Above) Given a (strictly) descending chain
of events, i.e., a countable set A0 ⊃A1 ⊃· · · of events Ai ∈Σ we have that
P(
∞

n=0
An) = lim
n→∞P(An)
(2.6)
In case the intersection of all An is empty in Eqn. (2.6) , we have that
lim
n→∞P(An) equals zero due to P(∅) = 0. Therefore, Lemma 2.8 is a gener-
alization of the original sixth axiom of Kolmogorov [163], i.e., the axiom of
continuity, see also the remarks on Eqn. (2.1) above.
2.1.3 Random Variables
Given a probability space, a random variable is a means to specify events and
probability distributions. A random variable is a measurable function from
the outcome space to an indicator set. The chosen indicator set and the spec-
iﬁcation of the function are used to model concrete probability distributions.
Random variables form the basis of Markov chains, see Sect. 2.2. We will use
random variables in the operational semantics of the probabilistic lambda cal-
culus to model the fact that one term reduces to another term in n steps with
a certain probability.
Deﬁnition 2.9 (Measurable Space, Measurable Function) Given two
measurable spaces (X, Σ) and (Y, Σ′), i.e., sets X and Y equipped with a
σ-algebra Σ over X and a σ-algebra Σ′ over Y . A function f : X →Y is
called a measurable function, also written as f : (X, Σ) →(Y, Σ′), if for all
sets U ∈Σ′ we have that the inverse image f −1(U) is an element of Σ.
Deﬁnition 2.10 (Random Variable) A random variable X based on a
probability space (Ω, Σ, P) is a measurable function X : (Ω, Σ) →(I, Σ′)
for a measurable space (I, Σ′) with indicator set I. The notation (X = i) is
used to denote the inverse image X−1(i) of an element i ∈I under f, i.e.,
(X = i) =DEF X−1(i) = {ω ∈Ω | X(ω) = i}
(2.7)
P(X = i) =DEF P(X−1(i)) = P({ω ∈Ω | X(ω) = i})
(2.8)
Henceforth, we usually omit the σ-algebras in the deﬁnition of concrete
random variables X : (Ω, Σ) →(I, Σ′) and specify them in terms of functions
X : Ω →I only. The notation (X = i) is a typical notation used in the context
of random variables. Given a random variable X, the expression (X = i) is
just an alternative means to denote the inverse image X−1(i) of i under the
function X. The set (X = i) is a subset of Ω and therefore denotes an event.
The random variable notation for events can be extended in a natural, obvious
way. For example, given a random variable X : Ω −→N0 with the set of
natural numbers as indicator set, we can denote the following event:

22
2 Preliminary Mathematics
(X ⩾0) = {ω ∈Ω | X(ω) ⩾0} =

n⩾0
(X = n)
(2.9)
The reason for using notation like that in Eqn. (2.9) is merely for pre-
sentation purposes. It is used to avoid bloated set notation in formulas. For
the same reason, it is also usual to use predicate logic expressions, also over
families of random variables. The target is always to achieve formulas that
are easier to read. It is common not to introduce such notation formally.
Such notation is rather introduced on the ﬂy and should be self-explanatory.
For example, given a countable set of random variables (Xn)n⩾0 we can use
(∃n ⩾0.Xn = i) to denote the following event:
(∃n ⩾0.Xn = i) =

n⩾0
(Xn = i)
(2.10)
Once more see that (∃n ⩾0.Xn = i) in Eqn. (2.10) actually stands for
{ω ∈Ω | ∃n ⩾0 . Xn(ω) = i }. The notations shown in Eqns. (2.9) and (2.10)
are concrete examples of notations used in this book, e.g., in the deﬁnition of
hitting times η in Sect. 2.2.
The indicator set I can be ﬁnite, countable or non-denumerable. This is
worth mentioning, because the case that the indicator set is R is so impor-
tant and convenient that in many textbooks the notion of random variable
is introduced immediately and only with R as the indicator set. In this text
we will be interested mostly in the case of a countably inﬁnite indicator set,
because we are interested in the terms of a language as an indicator set. In
case the indicator set is countable, the random variable is called a discrete
random variable.
Next, we recap the notion of expected value of a discrete random variable.
Furthermore, we will also need to deﬁne the notion of conditional expected
value. We need these concepts for the deﬁnition of mean reduction lengths of
a program; compare with Def. 3.7. For our purposes, it is suﬃcient to assume
that the indicator set of the random variable is the set N0 ∪{∞} of natural
numbers plus inﬁnity, reﬂecting the possible reduction lengths before hitting a
term. Remember that a random variable is used to assign values to outcomes:
in particular, we can use them to weight outcomes of a probability experiment
and it therefore makes sense to speak of the values assigned to outcomes as
outcome values. Now, informally, the expected value of a random variable is
the mean of outcome values of a probability experiment after conducting the
experiment a large number of times or, let’s say it better, a suﬃciently large
number of times. In Def. 2.11 we assume, as usual, that ∞· 0 = 0, ∞· n = ∞
and n + ∞= ∞to write the deﬁnitions as sums, instead of writing them as
explicit case distinctions.
Deﬁnition 2.11 (Expectation, Conditional Expected Value)
Given
a random variable X : Ω →N0 ∪{∞} based on a probability space (Ω, Σ, P)

2.2 Markov Chains
23
and an event A ⊆Ω, we deﬁne the expected value E(X) of X, or expectation
of X for short, as well as the expected value EA(X) of X conditional on A as
follows:
E(X) =
∞

i=0
i · P(X = i) + ∞· P(X = ∞)
(2.11)
EA(X) =
∞

i=0
i · PA(X = i) + ∞· PA(X = ∞)
(2.12)
As usual, we also use E(X|A) to denote EA(X). Note that it is very com-
mon to use the symbol μ to denote the expected value E(X). In this book, we
use the symbol μ to denote the recursion operators of typed lambda calculi.
Therefore, we will avoid using μ to denote expected values in this text.
2.2 Markov Chains
Markov chains are used to model probabilistic, state-changing systems for
which the probability of each move only depends on the state of a ﬁnitely and
absolutely bounded number of prior states. A widespread special case is given
by those Markov chains for which the probability of each next move depends
solely on the current state. This case is so common that Markov chains are
often introduced in the form of this special case. Markov chains in which, fur-
thermore, the next move is independent of the number of steps already taken
are called time-homogenous Markov chains. Markov chains that model time
as discrete are called discrete-time Markov chains (DTMC). The case that
time is modeled as discrete is very common. Therefore, discrete-time Markov
chains (DTMC) are usually called Markov chains for short. And, similarly, it
is also usual to call time-homogenous Markov chains just Markov chains for
short. Also, in this book, we will only deal with time-homogenous, discrete-
time Markov chains. Therefore, we feel free to call them Markov chains for
short, unless we feel it is important, e.g., in deﬁnitions or proofs, to stress the
fact that we deal with a time-homogenous, discrete-time Markov chain.
A Markov chain models a state-changing system as a countable inﬁnite
family of random variables. The indicator sets of all of these random variables
are equal and consist of the states of the system model. Now, the n-th random
variable models the probabilities that the system is in each of its states after
n steps. Each outcome of the underlying probability space models a state-
changing process instance. We are tempted to talk about the outcomes as the
processes of the state-changing system. However, it is usual to call the whole
system a process, so that it is more accurate to talk about the outcomes as
process instances. Similarly, we are tempted to talk about the outcomes as
random walks. Again, it is usual to call a whole system a random walk, which
is moreover reserved for Markov chains that obey further special conditions.
Furthermore, the Markov chain and the system it models are conceptually so

24
2 Preliminary Mathematics
close that it is often usual to talk about the modeled system as the Markov
chain by which it is modeled. For texts on Markov chains, see, e.g., [211, 181,
177, 179].
In this book we will exploit Markov chains to systematically give an opera-
tional semantics to the probabilistic lambda calculus. We do so by identifying
the term reduction system of the probabilistic lambda calculus with a con-
crete Markov chain, in which the terms form the Markov chain states, Markov
chain moves correspond to reduction steps and the outcomes of the underlying
probability space correspond to concrete program runs.
Deﬁnition 2.12 (Time-Homogenous Discrete-Time Markov Chain)
An inﬁnite series, i.e., N0-indexed family of random variables (Xn)n⩾0 with
Xn : Ω →S, is called a time-homogenous discrete-time Markov chain with
state space S, or Markov chain for short,
iﬀthe followoing two conditions
hold:
1. (Markov Property) For all n ⩾0 and states s0, . . . , sn+1 it holds that
P(Xn+1 = sn+1 | X0 = s0, . . . , Xn = sn) = P(Xn+1 = sn+1 | Xn = sn)
(2.13)
2. (Time Homogenity) For all n, m ⩾0 and states s, s′ ∈S it holds that
P(Xn+1 = s′ | Xn = s) = P(Xm+1 = s′ | Xm = s)
(2.14)
The property that the probability of a Markov chain move only depends on
a maximum number of prior states is often called the Markov property. Due
to the Markov property, a time-homogenous Markov chain can be uniquely
characterized by its so-called transition matrix, which contains the probability
of a possible move for any two states. Assume that the source states are
organized in the rows of the two-dimensional transition matrix, whereas the
target states are organized in the columns of the matrix. Now, the transition
matrix of a Markov chain is a probability matrix, which means that each row
of the transition matrix is a probability distribution; compare with Def. 2.4.
Deﬁnition 2.13 (Probability Matrix) A matrix m : I×I →[0, 1] is called
a probability matrix
iﬀeach row of the matrix is a probability distribution,
i.e., for all i ∈I it holds that

j∈I
mij = 1
(2.15)
Deﬁnition 2.14 (Transition Matrix of a Markov Chain) Given a time-
homogenous Markov chain X = (Xn : Ω →S)n⩾0. The probability matrix of
the Markov chain X, also called the transition matrix of the Markov chain X,
is a probability matrix p : S × S →[0, 1] on the state set S which is deﬁned
for all i, j ∈S as follows:
pij ≡DEF P(X1 = j | X0 = i)
(2.16)

2.2 Markov Chains
25
With X0 = i we have chosen the start time n = 0 as exit time in Def. 2.14,
however, this is an arbitrary choice. For a time-homogenous Markov chain,
the probability of evolving from a given state i into another given state j is
the same independent of the number of steps that have already been taken.
This is exactly because of time-homogeneity as expressed by property (2) of
Def. 2.12. Therefore, the exit time n in the deﬁnition of the transition matrix
could be arbitrarily chosen. Time homogeneity can be restated in terms of the
transition matrix by the following Corollary 2.15.
Corollary 2.15 (Transition Matrix of a Markov Chain) Given a time-
homogenous Markov chain X = (Xn : Ω →S)n⩾0 and its transition matrix
p : S × S →[0, 1]. Then for all n ⩾0 and all i, j ∈S it holds that
P(Xn+1 = j | Xn = i) = pij
(2.17)
Proof. This follows immediately from the time-homogenity of the Markov
chain X, i.e., property (2) of Def. 2.12.

Next, we introduce the notation Ps(A) for the probability of an event con-
ditional on the fact that the Markov chain starts in state s. The introduction
of this notation is really only a notational issue. It is nothing but a short-cut
notation for the notation PX0=s(A). The notation Ps(A) is introduced because
it is a very usual case to consider a probability conditional on a given start
state.
Deﬁnition 2.16 (Probability Conditional on Start State)
Given a
time-homogenous Markov chain X = (Xn : Ω →S)n⩾0, an event A ⊆Ω
and a state s ∈S, we deﬁne the probability Ps(A) of event A conditional on
the event that process instances start in s, or conditional on s for short, as
follows:
Ps(A) = P(A | X0 = s)
(2.18)
The initial distribution ι is a function that assign the probability P(X0 = i)
to each state i. We denote the value of ι for state i as ιi and call it the initial
probability of i. Note that ιi is the probability that a Markov chain is in state
i before it undertakes its ﬁrst step. We can also say that ιi is the probability
that the Markov chain starts in i or, equally well, the probability that i is
the start state of the Markov chain. The initial distribution ι actually forms
a probability distribution; see Def. 2.4.
Deﬁnition 2.17 (Initial Distribution of a Markov chain)
Given a
time-homogenous Markov chain X = (Xn : Ω →S)n⩾0. The initial distribu-
tion of the Markov chain X is a probability distribution ι : S →[0, 1] on the
state set S which is deﬁned for all i ∈S as follows:
ιi ≡DEF P(X0 = i)
(2.19)

26
2 Preliminary Mathematics
Sometimes, we denote an initial distribution of a Markov chain ι also
as
ι, in particular, if the initial distibution is used as a row vector in matrix
operations. Next, Theorem 2.18 summarizes some crucial properties of Markov
chains that all follow from the deﬁnition of Markov chains in Def. 2.12. The
properties tell us how to compute concrete probabilities on the basis of a
probability matrix.
Theorem 2.18 (Properties of Markov Chains)
Given a
time-homogenous Markov chain X = (Xn : Ω →S)n⩾0 with state space S
and transition matrix P = p : S × S →[0, 1], then for all n, m ⩾0 and
i, j, i0, . . . , in ∈S it holds that
1. P(X0 = i0 ∧. . . ∧Xn = in) = ιi0 · pi0i1 · pi1i2 · · · · · pin−1in
2. P(Xn = j) = (
ιP n)j
3. P(Xn = j | X0 = i) = P(Xm+n = j | Xm = i) = (P n)ij
2.2.1 Existence of Markov Chains
In Def. 2.14 we have deﬁned the transition matrix for a given Markov chain.
Now, we take the opposite direction. Given a probability matrix m, we can be
sure that there exists a Markov chain that has m as transition matrix. This
greatly eases things in modeling a probabilistic system. It means that there is
no need to explicitly construct the outcome space of the underlying probability
space, as long as we know the transition probabilities that characterize the
probabilistic system under consideration. We make use of this when we deﬁne
the operational semantics of the probabilistic lambda calculus in Sect. 3.3. We
will not ﬁx a concrete set of outcomes, i.e., there is no need to syntactically
construct a set of program runs. In a sense, we stay axiomatic. Later, in
Chap. 4 we will construct reduction graphs and reduction trees syntactically,
because we need a means to exploit graph theory, see Sect. 2.3, to analyze
the termination behavior of the probabilistic lambda calculus and to develop
crucial propositions with respect to this. Still, reduction graphs and reduction
trees are not outcomes themselves but viewports onto the outcomes of the
Markov chain semantics.
Theorem 2.19 (Existence of Markov Chains) Given a probability ma-
trix m : S × S −→[0, 1] for an at most countable state set S and a
probability distribution d : S −→[0, 1]. Then, there exists a Markov chain
X = (Xn : ΩS →S)n⩾0 based on a probability space (ΩS, ΣS, P) with transi-
tion matrix m and initial distribution d, i.e., for all n ∈N0 and i, j ∈S we
have that
1. P(Xn+1 = j | Xn = i) = mij
2. P(X0 = i) = di
Proof. No proof provided. See, e.g., §1.3, Theorem 13 and Corollary 14 in [245]
or §2.1.1.and Theorem 6.3.2 in [254].


2.2 Markov Chains
27
It is the theorem of Ionescu-Tulcea that proves the existence of Markov
chains even for state spaces that are non-denumerable, i.e., in case S = Rn.
We work with countable state sets only in the sequel, so that Theorem 2.19
is suﬃcient for our purposes.
Corollary 2.20 (Existence of Markov Chains (ii)) Given a probability
matrix m : S × S −→[0, 1] for an at most countable state set S. Then,
there exists a Markov chain (Xn)n⩾0 with transition matrix m and initial
distribution ι so that ιs > 0 for all s ∈S.
Proof: We can choose an arbitrary probability distribution d : S −→[0, 1]
with ds > 0 for all s ∈S for the given S and apply Theorem 2.19. Corol-
lary 2.20 follows immediately with ι = d. Due to the fact that S is countable,
we can assume that S = {s0, s1, s2, . . .}. We can, for example, construct the
needed probability measure as si →(0.5)i.

The choice of initial distribution d in Corollary 2.20 is not relevant for
the development of the subsequent theory. Ultimately we are not interested
in the absolute probabilities of the states of the developed term reduction
system, but in the probabilities of states relatively to given start states, which
amounts to probabilities dependent on given start states. Therefore the initial
distribution always eventually factorizes out. It is only important that the
initial distribution is non-zero for all states that we are interested in as start
states, so that the probability conditional on these states as start states is
well deﬁned. Therefore, we have introduced the side condition ιs > 0 for all
states s in Corollary 2.20.
Deﬁnition 2.21 (Markov Chain for Probability Matrix)
Given a
probability matrix m and an arbitrary but ﬁxed Markov chain (Xn)n⩾0 that
has been constructed according to Theorem 2.19 and Corollary 2.20, we use
the following notation for the constructed Markov Chain:
M(m) =DEF (Xn)n⩾0
(2.20)
We need M(m) as introduced by Def. 2.21 as a succinct notation to deﬁne
the operational semantics of the probabilistic lambda calculus later.
2.2.2 Hitting Probabilities
Often, we are particularly interested in the so-called hitting probability, which
is the probability that a certain state is eventually reached by the process
instances of a Markov chain. In our semantics of the probabilistic lambda
calculus, we are interested in the probability that a given term ever reduces
to another given term, which forms the notion of reduction probability, which
is the central notion of our Markov chain semantics. It is a usual option to
deﬁne the hitting probability via the notion of ﬁrst hitting time. It is also
possible to deﬁne this so-called hitting probability directly, without detour,

28
2 Preliminary Mathematics
and we will see how in due course in Corollary 2.25. Given a Markov chain
X and a set of target states T , the ﬁrst hitting time is deﬁned as a random
variable HX(T ) that assigns, to each process instance ω, the number of steps
after which ω hits a state from T for the ﬁrst time.
Deﬁnition 2.22 (First Hitting Time)
Given a Markov chain
X = (Xn : Ω −→S)n⩾0 and a subset of target states T ⊆S, we deﬁne the
random variable HX(T ) of ﬁrst hitting times by
HX(T ) : Ω −→N0 ∪{∞}
(2.21)
HX(T )(ω) =DEF

⊓{i ∈N0 | Xi(ω) ∈T }
, ∃i ∈N0.Xi(ω) ∈T
∞
, else
(2.22)
The greatest lower bound notation ⊓is used here to select the minimum,
i.e., smallest number of {i ∈N0 |Xi(ω) ∈T }. First hitting times are also often
called ﬁrst passage times. Next, based on the notion of ﬁrst hitting times
HX(T ) we deﬁne the notion of hitting probabilities.
Deﬁnition 2.23 (Hitting Probability)
Given a Markov chain
X = (Xn : Ω −→S)n⩾0, a subset of target states T ⊆S and a start state s,
we deﬁne the probability ηX⟨s, T ⟩of ever hitting one of the target states from
start state s as follows:
ηX⟨s, T ⟩=DEF Ps(HX(T ) < ∞)
(2.23)
Note that a probability ηX⟨s, T ⟩is a conditional probability; see Defs. 2.16
and 2.3. It is the probability of ever hitting one of the target states conditional
on the event that the Markov chain starts in state s initially. For instructive
purposes, we also give the verbose deﬁnition of the hitting probability:
ηX⟨s, T ⟩= P(HX(T ) < ∞∧X0 = s)
P(X0 = s)
(2.24)
Given a single target state t, we also write ηX⟨s, t⟩to denote ηX⟨s, {t}⟩.
In proofs we are often interested in a hitting probability up to a given max-
imum number of steps. We call such a kind of probability a bounded hitting
probability.
Deﬁnition 2.24 (Bounded Hitting Probability) Given a Markov chain
X = (Xn : Ω −→S)n⩾0, a subset of target states T ⊆S, a start state s and
an upper bound n ⩾0, we deﬁne the probability ηn
X⟨s, T ⟩of hitting one of the
target states from start state s in at most n steps as follows:
ηn
X⟨s, T ⟩=DEF Ps(HX(T ) ⩽n)
(2.25)

2.2 Markov Chains
29
Again, given a single target state t, we also write ηn
X⟨s, t⟩to denote
ηn
X⟨s, {t}⟩. Now, we introduce alternative, more direct, deﬁnitions of hitting
probabilities and bounded hitting probabilities without the detour via ﬁrst
hitting times, in Corollary 2.25. The notation used in the Corollary to specify
the respective events in Eqns. (2.26) and (2.27) has already been discussed in
Sect. 2.1.3; see Eqn. (2.10) and the surrounding discussion.
Corollary 2.25 (Alternative Hitting Probability Deﬁnitions)
Given
a Markov chain X = (Xn : Ω −→S)n⩾0, a subset of target states T ⊆S and
a start state s the following characterizations hold true:
ηX⟨s, T ⟩= Ps(∃i<∞. Xi ∈T )
(2.26)
ηn
X⟨s, T ⟩= Ps(∃i⩽n . Xi ∈T )
(2.27)
Proof. The corollary follows from the deﬁnition of ﬁrst hitting times in
Def. 2.22, hitting probabilities in Def. 2.23 and bounded hitting probabili-
ties in Def. 2.24.

The alternative deﬁnitions of hitting probabilities in Corollary 2.25 are
more straightforward than the ones via hitting probabilities given in Defs. 2.23
and 2.24 and, actually, they are even more intuitive. Nevertheless, the deﬁni-
tion of hitting probabilities via hitting times can often be found in textbooks
and turns out to be useful in inductive proofs, because ﬁrst hitting times enjoy
the property that they are disjoint for diﬀerent numbers of steps, i.e.,
i ̸= j =⇒(HX(T ) = i) ∩(HX(T ) = j) = ∅
(2.28)
Furthermore, the random variable HX(T ) is crucial for the deﬁnition of
mean hitting times in Def. 2.32. So, we gain a certain correspondence in the
deﬁnition of hitting probabilities and mean hitting times when the deﬁnition
of hitting probabilities is based on the random variable of ﬁrst hitting times.
Several further characterizations of hitting probabilities and bounded hitting
probabilities exist that can also be very useful in proofs; see Corollaries 2.26
and 2.27.
Corollary 2.26 (Characterizations of Hitting Probabilities)
Given
a Markov chain X = (Xn : Ω −→S)n⩾0, a subset of target states T ⊆S, a
start state s and a number n ∈N0 the following characterizations hold true:
ηX⟨s, T ⟩=
∞

n=0
Ps(HX(T ) = n)
(2.29)
ηn
X⟨s, T ⟩=
n

i=0
Ps(HX(T ) = n)
(2.30)

30
2 Preliminary Mathematics
Proof. This follows from the additivity of the probability function and the fact
that HX(T )=n and HX(T )=m are disjoint for all m ̸= n.

Corollary 2.27 (Limit of Bounded Hitting Probabilities)
Given a
Markov chain X = (Xn : Ω −→S)n⩾0, a subset of target states T ⊆S, a
start state s and numbers m, n ∈N0 the following holds true:
ηX⟨s, T ⟩= lim
n→∞ηn
X⟨s, T ⟩
(2.31)
Proof. Immediate from Corollary 2.26.

Bounded hitting probabilities increase monotonically with the bound of
steps as expressed by the following Corollary 2.28.
Corollary 2.28 (Monotonicity of Bounded Hitting Probabilities)
Given a chain Markov X = (Xn : Ω −→S)n⩾0, a subset of target states
T ⊆S, a start state s and numbers m, n ∈N0 the following holds true:
m ⩾n =⇒ηm
X ⟨s, T ⟩⩾ηn
X⟨s, T ⟩
(2.32)
Proof. Immediate from Corollary 2.26.

The vector of hitting probabilities of a Markov chain can be characterized
as the least solution of a linear equation system – see Theorem 2.29. The
characterization as a linear equation system is important for us, because, based
on it, we can exploit the results and algorithms of linear algebra to determine
and argue about reduction probabilities of the probabilistic lambda calculus.
Theorem 2.29 (Linear Equation System of Hitting Probabilities)
Given a Markov chain X = (Xn : Ω −→S)n⩾0 with transition matrix
p : S × S →[0, 1], a start state s and a set of target states T ⊆S. The vec-
tor of hitting probabilities (ηX⟨i, T ⟩)i∈S is the least solution of the following
equation system:
∀s ∈T .
ηX⟨s, T ⟩= 1
∀s ̸∈T .
 
t∈S
pst · ηX⟨t, T ⟩

−ηX⟨s, T ⟩= 0
(2.33)
Proof. See, e.g., Theorem 1.3.2 in [211], or Theorem 1.24 in [177].

All the terms of the form ηX⟨s, T ⟩as well as all terms of the form ηX⟨t, T ⟩
for each state s ∈S resp. t ∈S stand for individual variables in the equation
system of Theorem 2.29. The equation system consists of an equation for each
of the states in S. Therefore, in general, the equation system is inﬁnite. Later,
it will be a crucial step to reduce the state set of the considered Markov chain
to a ﬁnite subset, so that linear algebra algorithms become applicable. The
linear equation system in Eqn. (2.33) is in matrix form M × x = r with a

2.2 Markov Chains
31
column vector r of scalar values. However, the correctness of Theorem 2.29 is
easier to see if the equation system is rewritten in a slightly diﬀerent form:
∀s ∈T.ηX⟨s, T ⟩= 1
(2.34)
∀s ̸∈T.ηX⟨s, T ⟩=

t∈S
pst · ηX⟨t, T ⟩
(2.35)
A set of Markov chain states is called a closed class if it is not possible
to escape from it, once a state of the set has been reached. A hitting proba-
bility ηX⟨s, T ⟩is called an absorption probability if the set T is closed. The
states of a closed class are also called absorbing states. Given an absorbing
state s and a process instance ω we say that ω is absorbed behind s. In our
lambda calculus semantics we deal primarily with hitting probabilities that
are absorption probabilities. We usually consider cases in which the set of tar-
get states consists of a single state and the Markov chain henceforth remains
cycling in this state.
Deﬁnition 2.30 (Closed Class)
Given a Markov chain
X = (Xn : Ω −→S)n⩾0 and a subset of target states T ⊆S, the set T is
called a closed class of states, or closed for short,
iﬀall states s′ ∈S that
are reachable from a source state s ∈T also belong to T , i.e.,
∀s ∈T . ∀s′ ∈S . ( ηX⟨s, s′⟩> 0 =⇒s′ ∈T )
(2.36)
The fact that hitting probabilities are characterized by the equations in
Eqns. (2.34) and (2.35) is important because it allows us to determine con-
crete hitting probability values. It is also important because the equations
are needed to prove propositions about Markov chains and the system they
model. For us, a similar result about bounded hitting probabilities is impor-
tant, which is expressed in the decomposition Lemma 2.31. Lemma 2.31 ex-
plains how a bounded hitting probability can be calculated from the bounded
hitting probabilities of a fewer number of steps.
Lemma 2.31 (Decomposition of Bounded Hitting Probabilities)
Given a Markov chain X = (Xn : Ω −→S)n⩾0 with transition matrix
p : S × S →[0, 1] and a bound n ∈N0 the following characterizations of
bounded hitting probabilities hold true:
∀s ∈T.ηn
X⟨s, T ⟩= 1
(2.37)
∀s ̸∈T.η0
X⟨s, T ⟩= 0
(2.38)
∀s ̸∈T.ηn+1
X
⟨s, T ⟩=

t∈S
pst · ηn
X⟨t, T ⟩
(2.39)
Proof. Let us start with Eqn. (2.37), which follows from the deﬁnition of
bounded hitting probabilities in Def. 2.24. Due to Eqn. (2.27) we have that
ηn
X⟨s, T ⟩equals

32
2 Preliminary Mathematics
P(∃i ⩽n.Xi ∈T ∧X0 = s) / P(X0 = s)
(2.40)
Due to the premise of Eqn. (2.37), i.e., s ∈T , we have that (X0 = s) is
a subset of (∃i ⩽n.Xi ∈T ). Therefore, we know that Eqn. (2.40) equals
P(X0 = s)/P(X0 = s) which equals 1.
Let us turn to Eqn. (2.38). Again, due to Eqn. (2.27) we have that η0
X⟨s, T ⟩
equals
P(∃i ⩽0.Xi ∈T ∧X0 = s) / P(X0 = s)
(2.41)
We know that (∃i ⩽0.Xi ∈T ) equals (X0 ∈T ). Now, given that s ̸∈T we
know that (X0 ∈T )∩(X0 = s) = ∅. Due to P(∅) = 0 we have that Eqn. (2.41)
equals 0.
Now, let us show Eqn. (2.39). Due to Eqn. (2.27) we have that ηn+1
X
⟨s, T ⟩
equals
P(∃i ⩽n+1 . Xi ∈T ∧X0 = s) / P(X0 = s)
(2.42)
Due to the premise that s ̸∈T and similar arguments as in case of Eqn. (2.38)
we have that Eqn. (2.42) equals
P(∃1 ⩽i ⩽n+1 . Xi ∈T ∧X0 = s) / P(X0 = s)
(2.43)
Now, due to the countable additivity of the probability function, see Def. 2.2,
and the fact that (X1 =t) is disjoint from (X1 =t′) for all t̸= t′ we have that
Eqn. (2.43) equals

t∈S
P(∃1 ⩽i ⩽n+1 . Xi ∈T ∧X0 = s ∧X1 = t) / P(X0 = s)
(2.44)
Now, Eqn. (2.44) can always be transformed into the following:

t∈S
P(X0 = s ∧X1 = t)
P(X0 = s)
· P(∃1 ⩽i ⩽n+1 . Xi ∈T ∧X0 = s ∧X1 = t)
P(X0 = s ∧X1 = t)
(2.45)
Just for convenience, let us rewrite Eqn. (2.45) as follows:

t∈S
P(X1 = t | X0 = s) · P(∃1 ⩽i ⩽n+1 . Xi ∈T | X0 = s, X1 = t)
(2.46)
Now, due the deﬁnition of transition matrices of Markov chains in Def. 2.14,
we have that Eqn. (2.46) equals the following:

t∈S
pst · P(∃1 ⩽i ⩽n+1 . Xi ∈T | X0 = s, X1 = t)
(2.47)
Next, due to the Markov property, i.e., Eqn. (2.13), it can be shown that
Eqn. (2.47) equals the following:

t∈S
pst · P(∃1 ⩽i ⩽n+1 . Xi ∈T | X1 = t)
(2.48)

2.3 Graph Theory
33
Due to the time homogeneity of the involved Markov chain, i.e., Eqn. (2.14),
it can be shown that Eqn. (2.48) equals the following:

t∈S
pst · P(∃0 ⩽i ⩽n . Xi ∈T | X0 = t)
(2.49)
Finally, due to the deﬁnition of bounded hitting probabilities in Def. 2.24 we
have that Eqn. (2.49) equals:

t∈S
pst · ηn
X⟨t, T ⟩
(2.50)

Next, we deﬁne the mean hitting time |ηX⟨s, T ⟩| of reaching one of the
target states in T from a start state s. It is deﬁned as the expected average
number of steps needed to reach one of the target states from the start state.
Deﬁnition 2.32 (Mean Hitting Time)
Given a Markov chain
X = (Xn : Ω −→S)n⩾0, a subset of target states T ⊆S and a start state
s ∈S, we deﬁne the mean hitting time |ηX⟨s, T ⟩| needed to reach a state in T
starting from s as follows:
|ηX⟨s, T ⟩| =DEF Es(HX(T ))
(2.51)
Given a single target state t, we also write |ηX⟨s, t⟩| to denote |ηX⟨s, {t}⟩|.
The notion of mean hitting time is based on the random variable of ﬁrst
hitting times deﬁned in Def. 2.22 and the notion of conditional expectation
in Def. 2.11. Again, mean hitting times can be determined as a solution of
a linear equation system; see Theorem 2.33. Again, each term of the form
|ηX⟨s, T ⟩| in Eqn. (2.52) stands for an individual variable.
Theorem 2.33 (Linear Equation System of Mean Hitting Times)
Given a Markov chain X = (Xn : Ω −→S)n⩾0 with transition matrix
p : S × S →[0, 1], a start state s and a set of target states T ⊆S. The vec-
tor of mean hitting times (|ηX⟨i, T ⟩|)i∈S is the least solution of the following
equation system:
∀i ∈T .
|ηX⟨i, T ⟩| = 0
∀i ̸∈T .
 
j̸∈T
pij · |ηX⟨j, T ⟩|

−|ηX⟨i, T ⟩| = −1
(2.52)
Proof. See, e.g., Theorem 1.3.5 in [211].

2.3 Graph Theory
We need graph theory for the analysis of the operational semantics of the
probabilistic lambda calculus in Sect. 4. We are particularly interested in the

34
2 Preliminary Mathematics
termination behavior of probabilistic programs. We will establish the notion
of unbounded termination. We say that a program terminates unbounded
if it has terminating program runs of arbitrary length. We will see that an
unbounded program necessarily also has a non-terminating program run. We
will identify a class of probabilistic programs for which the termination degree
is computable, the so-called path stoppable programs. All of these results rely
on a graph-theoretic treatment of the reduction system of the probabilistic
lambda calculus. Basically, we will view the transition matrix of our Markov
chain semantics as a graph, the so-called reduction graph, in order to achieve
the notion of path stoppability. Only after the establishment of reduction
graphs we step further to deﬁne reduction trees, which become necessary in
the analysis of bounded vs. unbounded terminating programs. In order to
prove the desired properties of program behavior we exploit graph-theoretic
results, i.e., König’s Lemma and Beth’s Theorem.
In order to establish the notion of path stoppability and to prove the
main result for it, i.e., the computability of termination behavior for a certain
class of programs, we need to prove further lemmas for graphs. We need the
result that the nodes that are covered by the walks of a graph are already
completely covered by the paths of the graph. Furthermore, we need to state
under what circumstances the cover of a graph is computable. These two
important lemmas are not proven here in this chapter but are deferred until
Chap. 4 where they occur as Lemma 4.25 and Theorem 4.26 in the context
where they naturally emerge. This shows, once more, the appropriateness of
a graph-theoretic viewpoint of the operational semantics.
2.3.1 Digraphs
In this book we work with digraphs, i.e., directed graphs. Often, we call di-
graphs also graphs for short, in particular if there is no risk of confusion or we
do not want to stress explicitly that we deal with directed graphs. Our notion
of digraph is straightforward. There is at most one edge between two vertices,
i.e., our digraphs are not multigraphs. This notion of graph is particularly
appropriate for our purpose of modeling the reduction graph and, with its
edges being modeled as a relation, particularly easy to handle in proofs. From
time to time it is instructive to consider digraphs as graphs in general; this is
why we also introduce the deﬁnitions of graphs in general later in this section.
See [16] for a thorough treatment of digraphs.
Deﬁnition 2.34 (Digraph) A digraph (directed graph) G is a tuple ⟨V, E⟩
consisting of vertices V , also called nodes, and edges E ⊆V × V .
A digraph G = ⟨VG, EG⟩is considered to be directed, because its edges
are ordered pairs. The direction is somehow considered from left to right as
shown in the deﬁnition of walks and paths later. Furthermore, given an edge
e = ⟨v, v′⟩between nodes v and v′, the edge e is said to be an outgoing edge

2.3 Graph Theory
35
of v and, at the same time, it is said to be an ingoing edge of v′. The number
of outgoing edges of a node is called the degree of that node. If the number
of outgoing edges of a digraph is limited by a number k for all nodes of a
digraph G, the digraph G is said to be k-ary. The degree of a node can be
either ﬁnite or inﬁnite; we then also say that the node is of ﬁnite degree resp.
inﬁnite degree. Next, we introduce the notion of walks in a digraph. A walk
in a digraph is a sequence of nodes that are, sequentially, connected by edges
as deﬁned in Def. 2.35.
Deﬁnition 2.35 (Walks of a Digraph) Given a digraph G = ⟨VG, EG⟩,
the set nWG of its walks of length n ∈N0, the set ⋆WG of its walks of ﬁnite
length, the set ωWG of its inﬁnite walks and the set ⊕WG of its walks, are
deﬁned as sets as follows:
nWG = {w | w ∈V n+1
G
, ∀i<n.⟨wi, wi+1⟩∈EG}
(2.53)
⋆WG = {w | w ∈V ⋆
G, ∀i< #(w)−1.⟨wi, wi+1⟩∈EG}
(2.54)
ωWG = {(wi)i∈ω | wi ∈VG, ∀i∈N0.⟨wi, wi+1⟩∈EG}
(2.55)
⊕WG = ⋆WG ∪ωWG
(2.56)
If w is a walk of a graph G, we also say that w is a walk in the graph
G and we also say G has the walk w. For the deﬁnition of V n
G and V ⋆
G
see the deﬁnition of sequences of length n as well as sequences of arbitrary
length in Sect. 2.5.2. As usual, we also use w0w1w2 · · · wn to denote a walk
(wi)i∈{0,...,n}. Textbooks [16, 32, 33] on graphs usually introduce walks as se-
quences v0e0v1e1v2e2 · · · en−1vn of interchanging vertices vi and edges ei, and
so we will do in case of graphs later in Def. 2.40. In case of digraphs, how-
ever, we can forget about the edges in the walks. This is possible, because a
digraph is not a multigraph, and the edges of its walks are therefore uniquely
determined by the vertices of its walks. Note that also textbooks on digraphs
such as [16] might use a deﬁnition based on sequences involving edges. We
prefer a deﬁnition based on sequences of vertices only. Then, as opposed to
many textbooks, we make explicit the technical details of the sequences in
our deﬁnition. Last but not least, as an important technical diﬀerence, we
also deal explicitly with the possibility of inﬁnite walks. All of this is extra
accurate but pays back later in proofs, where it shortens notation and eases
argumentation. Next, we introduce resp. recap some useful notation for the
nodes and sizes of graphs, walks as well as sets of walks.
Deﬁnition 2.36 (Nodes and Sizes in Digraphs)
Given a digraph
G = ⟨VG, EG⟩. We denote the set of its nodes also by κ(G), i.e., κ(G) = VG.
We denote its size by |G|, i.e., |G| = |VG|. Given a walk w ∈⊕WG, we denote
the set of its nodes by κ((wi)i∈I) = {wi | i ∈I}, its size by |w| = |κ(w)| and
its length by l(w) = #(w) −1. Given a set of walks U ⊆⊕WG, we denote the
set of its nodes by κ(U) = ∪{κ(u)| u ∈U} and its size by |U| = |κ(U)|.
A walk consists of at least one node; compare with Eqn. (2.53). Therefore,
walks of length zero also consist of one node. We distinguish between the

36
2 Preliminary Mathematics
length l(w) of a walk w and its sequence length #(w). The length of a walk
equals its sequence length minus one, which is in accordance with the deﬁnition
of walks in graphs in Def. 2.40, where the length of a walk is deﬁned as the
number of its edges. Note that the size of a walk w ∈⊕WG is less than or
equal to its sequence length, i.e., |w| ⩽#(w) = l(w) + 1.
Often, we are interested in walks that start with a given node. We introduce
some convenient notation for sets of walks that all start with the same node in
Def. 2.37. The notation always relies on a given set of walks W. Then we use
W(v) to denote the subset of all walks of W that start with v. For example,
given a digraph G and a node v ∈κ(G) the set of all of its walks starting in
v is denoted by ⊕WG(v).
Deﬁnition 2.37 (Walks with a Start Node) Given a digraph G, a set of
walks W ⊆⊕WG, and a node v ∈κ(G), we deﬁne the set W(v) of walks from
W starting in v as follows:
W(v) = {w ∈W | w0 = v}
(2.57)
Next, we deﬁne the important notion of paths. Informally, a path is a walk
that has no cycles, i.e., a walk along which it is not possible to visit a node
twice.
Deﬁnition 2.38 (Paths) Given a digraph, a walk is called a path if all of its
nodes are pairwise disjoint. Given a digraph G and a set of walks W ⊆⊕WG,
we deﬁne the set π(W) of paths of W as follows:
π(W) = {(wi)i∈I ∈W | ∀i, j ∈I, i ̸= j . wi ̸= wj}
(2.58)
For example, given a digraph G, the set of all of its paths is π(⊕WG) and
the set of all of its paths of length n is π(nWG). Note that the size of a path
p ∈π(nWG) equals its sequence length, i.e., |p| = #(p) = l(p) + 1.
In acyclic graphs, and in particular in trees, all the walks are paths.
Now, let us turn to König’s Lemma. Informally, it states that an inﬁnite
graph necessarily has an inﬁnite path, as long as all of its nodes only have
ﬁnitely many outgoing edges.
Lemma 2.39 (König’s Lemma for Digraphs and Start Nodes) Given
a digraph G = ⟨VG, EG⟩so that all of its nodes have a ﬁnite degree. Given
a node v ∈VG. If the set of nodes covered by walks from G starting in v is
inﬁnite, then there exists an inﬁnite path starting from v, i.e.,
|κ(⋆WG(v))| = ∞=⇒∃ω . ω ∈π(ωWG(v))
(2.59)
Proof. This Lemma can be proven as a corollary of König’s Lemma for graphs,
i.e., Theorem 2.42, based on the fact that the sub-digraph consisting of nodes
reachable from v, interpreted as a graph, is a connected graph.

2.3 Graph Theory
37
2.3.2 Graphs
Like digraphs, graphs consist of nodes that are connected by edges. Unlike
digraphs, the edges in a graph are not directed. We recap the deﬁnition of
ordinary graphs and their walks, trails and paths in Def. 2.40; compare with
[32, 70, 33].
Deﬁnition 2.40 (Graphs, Walks, Trails, Paths, Degrees) A graph G
is a triple ⟨V, E, φ⟩consisting of a set of vertices V , a set of edges E and a
so-called incident function φ : E →{{v1, v2} | v1 ∈V, v2 ∈V } that assigns an
unordered pair of vertices to each edge. A walk (inﬁnite walk) of a graph G is
a sequence v0e0v1e1 · · · en−1vn of arbitrary length n resp. an inﬁnite sequence
v0e0v1e1 · · · of interchanging nodes vi and edges ei so that for all i ⩾0 we
have that φ(ei) = {vi, vi+1}. A trail is walk in which no edge occurs more
than once. A path is a walk in which no node occurs more than once. The
degree of a node v ∈V is deﬁned as the number of its connected edges, i.e., as
|{e | v ∈φ(e)}| in case there are ﬁnitely many connected edges, and otherwise,
as inﬁnite (∞) in case there are inﬁnitely many connected edges.
Note that according to Def. 2.40 the length of a path equals the length of
its edges. Note that each path of a graph is a trail, but not vice versa. The
deﬁnition of graphs based on an incident function as deﬁned in Def. 2.40 is
standard in the literature, although many other equivalent deﬁnitions of course
exist. For a detailed treatment of graphs, see [33]. The graphs as deﬁned in
Def. 2.40 are undirected multigraphs, i.e., the edges do not have a designated
source or target, and there may exist more than one edge between two given
vertices.
Given a digraph D = ⟨V, E⟩, the digraph can be immediately considered
as a graph ⟨V, E, φ⟩with φ(⟨vi, vj⟩) = {vi, vj} for each ⟨vi, vj⟩∈E. Note that
this transformation of a digraph D into a graph loses information, i.e., the
information about the direction of edges. Furthermore, the transformation
may result in a multigraph. Nevertheless, this re-interpretation of digraphs
allows for the exploitation of some results that are available for graphs in
general, e.g., König’s Lemma in Theorem 2.42.
Deﬁnition 2.41 (Connected Graph) A graph G = ⟨V, E, φ⟩is connected
if each pair v ̸= v′ ∈V of its nodes is connected by a path, i.e., for all pairs
v ̸= v′ ∈V there exists some path p0e0p1e1 · · · en−1pn for some n ∈N0 so
that p0 = v and pn = v′.
Theorem 2.42 (König’s Lemma) Given a connected graph G so that all
vertices of G have ﬁnite degree. If G is inﬁnite then there exists an inﬁnite
path in G.
Proof. See [165, 166]. The proof can be conducted by structural induction on
the length of walks, by proving the possibility of a next admissible move by
an indirect argument as induction step – see also [171].


38
2 Preliminary Mathematics
The converse of König’s Lemma trivially holds. Each graph that has an
inﬁnite path necessarily has inﬁnitely many nodes. This is so, because the
nodes in a path are all pairwise disjoint.
2.3.3 Trees
Trees are special graphs. A tree is an acyclic graph in which there exists a
unique path between any two of its nodes. In this book we work with directed
trees, i.e., trees that are deﬁned on the basis of directed graphs. More con-
cretely, we work with rooted directed trees, which have a designated node
as so-called root. Again, we often simply talk about trees instead of rooted
directed trees in the sequel, as long as everything is clear from the context
and an explicit distinction is not required. First, we introduce the notion of
directed acyclic graphs (DAG) in Def, 2.43, then we deﬁne rooted directed
trees as special DAGs. The deﬁnition of leaves and inner nodes of a rooted
directed tree in Def. 2.44 is straightforward.
Deﬁnition 2.43 (DAGs) A digraph G is a DAG (directed acyclic graph)
iﬀall of its walks are paths, i.e., ⋆WG = π(⋆WG).
Obviously, a cycle is a walk that eventually returns to its start node. See
Def. 2.46 for a deﬁnition of cycles in graphs. A similar deﬁnition can be given
for cycles in digraphs. Therefore, according to Def. 2.43, a DAG contains no
cycles; in particular, a DAG also does not contain any self-cycles, i.e., cycles
of length one. Note that walks of length zero are considered not to be cycles.
Furthermore, walks of length zero are considered to be paths; compare with
Def. 2.38. Therefore, walks of length zero do not pose a problem with respect
to Def. 2.43 and the notion of DAG.
Deﬁnition 2.44 (Rooted Directed Tree)
A rooted directed tree
T = ⟨V, E, r⟩, rooted tree or tree for short, is a triple that is established by
a digraph ⟨V, E⟩and a root node r ∈V , called its root for short,
iﬀT
is a DAG (directed acyclic graph), and each node diﬀerent from the root is
(end-to-end) connected to the root by exactly one path.
Deﬁnition 2.45 (Leaves and Inner Nodes of a Tree)
Given a
rooted tree T = ⟨V, E, r⟩a node v ∈V is a leaf
iﬀit has no outgoing edges,
i.e., { v′ | ⟨v, v′⟩∈E} = ∅. A node v ∈V ′ is an inner node
iﬀv is not a
leaf.
Again, for the sake of completeness, we also include here deﬁnitions for
ordinary trees, i.e., trees that are based on ordinary graphs; again, compare
with [32, 33]. We do so because in the sequel we want to exploit results that
are available for ordinary trees and immediately transport them to directed
trees. We proceed, as usual, by the deﬁnition of cycles via the deﬁnition of
acyclic graphs to the deﬁnition of trees and close with the observation that
paths between any two nodes of a tree are unique.

2.4 Inductive Deﬁnitions
39
Deﬁnition 2.46 (Cycle) Given a graph G, a walk v0e0v1e1 . . . vn−1en−1vn
of G is a cycle
iﬀit is not empty, its ﬁrst node is equal to its last node
and the walk up to the last node is a path, i.e., n ⩾1, v0 = vn and
v0e0v1e1 . . . en−1vn−1 is a path.
Deﬁnition 2.47 (Acyclic Graph) A graph G = ⟨V, E, φ⟩is acyclic
iﬀit
contains no cylces.
Deﬁnition 2.48 (Trees) A tree T is a graph T = ⟨V, E, φ⟩that is acyclic
and connected.
Lemma 2.49 (Uniqueness of Paths in Tree) If a graph T = ⟨V, E, φ⟩is
a tree then any two of its nodes u, w ∈V are (end-to-end) connected by exactly
one path, i.e., there exists exactly one path v0e0v1e1 · · · en−1vn with v0 = u
and vn = w.
Proof. See Theorem 2.1 in [32].

Any rooted directed tree can be re-interpreted as a tree. This is so, because
any rooted directed tree is a digraph and therefore can be transformed into
a graph as described in Sect. 2.3.2, where it can be shown that the rooted-
tree property is preserved by the transformation, i.e., implies the general tree
property. This allows for the application of results that are available for trees
in general, e.g., Beth’s Tree Theorem 2.50, to rooted directed trees. Beth’s
Theorem can be considered to be an instance of Königs Lemma for the case
of trees.
Theorem 2.50 (Beth’s Tree Theorem) Given a tree T . If G is inﬁnite,
there exists an inﬁnite path in T .
Proof. This Theorem is a corollary of König’s Lemma, i.e., Theorem 2.42.
Apart from that, Beth’s Tree Theorem has been found and proven indepen-
dently of König’s Lemma [26, 27].

2.4 Inductive Deﬁnitions
Inductive deﬁnitions are one of the most basic tools in building arbitrary
kinds of mathematical structures and arguing about them. In computer sci-
ence, we come across inductive deﬁnitions everywhere, implicitly or explicitly,
e.g., always in the deﬁnition of programming languages, deﬁnition of type
systems [42] as well as the investigation of algorithms [52] and formal lan-
guages [137]. Usually, the mechanism of inductive deﬁnition is just taken for
granted. Usually, it is not explained and often it is even not explicitly men-
tioned. This is so, because the focus regularly needs to be solely on the genuine
mathematical or otherwise-structured object of interest. It is diﬀerent in this

40
2 Preliminary Mathematics
book. We make a concrete language of randomized algorithms, i.e., the prob-
abilistic lambda calculus, the subject of our investigation and formal treatise.
Therefore, we need to make the theory of inductive deﬁnitions explicit, because
we need its propositions in conclusions, argumentations and proofs. This is so
later when we come up with the denotational semantics for our language. But
also earlier, when we treat the operational semantics, it makes sense to make
explicit and reﬂect upon the inductive deﬁnitions of the established language.
Not everywhere, but in large parts of the book, we have chosen ω-complete
partial orders as domains for our inductive deﬁnitions. The concrete choice of
underlying mathematical structures may always, at least to a certain extent,
appear to be arbitrary or a matter of taste. Actually, the choice depends on the
needs of the targeted analysis and the requirements of the object of investiga-
tions. We aim at motivating our concrete choices of mathematical structures
in place here in this chapter but also in the upcoming Chap. 5 where we deal
with the denotational semantics. In this chapter we furthermore present the
basic motivations of inductive deﬁnitions and also delve into technical issues,
in particular, concerning ω-cpos and ω-continuous functions.
So what is an inductive deﬁnition? Whenever you have deﬁned a set of ob-
jects as the least set that fulﬁlls a collection of conditions, you have provided
an inductive deﬁnition. Actually, the concrete speciﬁcation of the involved
collection of conditions is exactly what inductive deﬁnition is about. As a
standard example, a formal language can be considered the least set of words
that is closed under the production rules of the corresponding grammar. The
notion of inductive deﬁnition can be brought into shape with the Knaster-
Tarski ﬁxed-point theorem. In its earliest version [160] the Knaster-Tarski
ﬁxed point theorem is formulated for each power set over a set, ordered by
subset inclusion. It is proven that each monotone function over a power set
has a least ﬁxed point. Now, the least ﬁxed point of such a monotone func-
tion provides an inductive deﬁnition. Later [255], the Knaster-Tarski ﬁxed
point theorem was formulated more abstractly, in terms of arbitrary complete
lattices.
We proceed as follows. We give the necessary deﬁnitions for partial orders
and lattices needed for the Knaster-Tarski theorem in its generalized form
and state this theorem in Sect. 2.4.1. Then, we turn to rule-based inductive
deﬁnitions in Sect. 2.4.2. Rule-based inductive deﬁnitions provide a concrete
form, i.e., a concrete notation, to present inductive deﬁnitions. Rule-based
inductive deﬁnitions, or rule-based deﬁnitions for short, are particularly intu-
itive and in widespread use, in particular, in the computer science literature.
Nonetheless, it is important to carve out their formal meaning, in order to
achieve rigor in the material in which we use them. We will use rule-based
inductive deﬁnitions in many places, e.g., in the deﬁnition of the one-step se-
mantics as well as in the deﬁnition of syntactical approximation for lambda
terms. Next, we turn to cpos and ω-cpos in Sects. 2.4.3 through 2.4.8. We
need to treat ω-cpos in detail, because they are the domains of choice for our
denotational semantics. We also review cpos in this book for the sake of com-

2.4 Inductive Deﬁnitions
41
pleteness and for better comparability with the literature. With this direction
and these techniques we have chosen a concrete viewpoint on the ﬁeld of in-
ductive deﬁnitions. For a comprehensive treatment of inductive deﬁnitions we
also recommend [201, 202].
2.4.1 The Knaster-Tarski Fixed-Point Theorem
A partially ordered set, or partial order, is a set together with a reﬂexive,
anti-symmetric and transitive binary relation. Partial orders are the basis
for all further structures that we need in inductive deﬁnitions and later in
denotational semantics, i.e., lattices, complete lattices, cpos and ω-cpos.
Deﬁnition 2.51 (Partial Order) A partially ordered set (S, ⊑), also partial
order for short, consists of a set S and binary relation ⊑: S × S, which is
reﬂexive, anti-symmetric and transitive, i.e., for all s, s1, s2, s3 ∈S it holds
that
1. s ⊑s (reﬂexivity)
2. s1 ̸= s2 =⇒¬(s1 ⊑s2 ∧s2 ⊑s1) (anti-symmetry)
3. s1 ⊑s2 ∧s2 ⊑s3 =⇒s1 ⊑s3 (transitivity)
Given a partial order D = (D′, ⊑D′) as deﬁned by Def. 2.51. Then, the
set D′ is also called the carrier or base set of D. We also say d is an element
of D if d is an element of the carrier D′, and also write d ∈D for d ∈D′.
Often, in terms of used symbols, we want to neglect the distinction between
a partial order and its carrier completely, i.e., use the same symbol for them:
D = (D, ⊑D) in our example.
In the context of denotational semantics the binary relation ⊑D is often
considered to be an information approximation, and the binary relation ⊑D is
called an approximation relation. Similarly, we often say that s1 approximates
s2 if s1 ⊑s2. Next, let us deﬁne the notions of monotone functions, upper
bounds, least upper bounds, lower bounds and greatest lower bounds.
Deﬁnition 2.52 (Monotone Function) Given two partially ordered sets
(D, ⊑D) and (E, ⊑E). A function f : D −→E is monotone if it preserves the
partial order, i.e., for all d1, d2 ∈D:
d1 ⊑D d2 =⇒f(d1) ⊑E f(d2)
(2.60)
Deﬁnition 2.53 (Upper Bound and Least Upper Bound) Given a par-
tial order S = (S, ⊑) and a subset U ⊆S. An element e ∈S is called an upper
bound of U
iﬀu ⊑e for all u ∈U. An element e ∈S is called the least
upper bound (l.u.b.) of U
iﬀe is an upper bound of U and for any e′ that
is an upper bound of U it holds that e ⊑e′. The least upper bound of a set
U, which is also called the supremum of U, is unique and is also denoted by
⊔S U.

42
2 Preliminary Mathematics
Deﬁnition 2.54 (Lower Bound and Greatest Lower Bound) Given a
partial order S = (S, ⊑) and a subset U ⊆S. An element e ∈S is called
a lower bound of U
iﬀe ⊑u for all u ∈U. An element e ∈S is called
the greatest lower bound of U
iﬀis e is a lower bound of U and for any e′
that is a lower bound of U it holds that e′ ⊑e. The greatest lower bound of a
set U, which is also called the inﬁmum of U, is unique and is also denoted by
⊓S U.
Given a partial order S = (S, ⊑S) and a subset U ⊆S, we also write ⊔U
and ⊓U for the least upper bound ⊔SU resp. greatest lower bound ⊓SU if S is
clear from the context. Furthermore, it is usual to talk about ⊔U as the join
of the elements of U and to speak about ⊓U as the meet of the elements of U.
Furthermore, given two elements s and t, it is usual to use the inﬁx notations
s⊔t and s⊓t to denote the least upper bound ⊔{s, t} resp. the greatest lower
bound ⊓{s, t} of s and t. Now, a lattice is deﬁned as a partial order in which
both the meet and the join exist for all pairs of elements, whereas a complete
lattice is a partial order that contains least upper bounds and greatest lower
bounds for all of its subsets.
Deﬁnition 2.55 (Lattice) A partial order (S, ⊑S) is a lattice
iﬀthere
exist the meet s ⊓s′ and the join s ⊔s′ for all elements s ∈S and s′ ∈S.
Deﬁnition 2.56 (Complete Lattice) A partial order (S, ⊑S) is a complete
lattice
iﬀthere exist the least upper bound ⊔U and the greatest lower bound
⊓U for all subsets U ⊆S.
In particular, given a complete lattice S, we have that both the least upper
bound ⊔S and the greatest lower bound ⊓S exist and both belong to S. It
is usual to call ⊓S the bottom element of S and to denote it as ⊥S ∈S or
⊥∈S if S is clear from the context. Similarly, it is usual to call ⊔S the top
element of S and to denote it as ⊤S ∈S resp. ⊤∈S.
Deﬁnition 2.57 (Top and Bottom Elements of Complete Lattices)
Given a complete lattice (S, ⊑S) we deﬁne
⊥S = ⊓S
(bottom element)
(2.61)
⊤S = ⊔S
(top element)
(2.62)
An important example of complete lattices is the power set (P(S), ⊆) of
subsets of a given set S ordered by subset inclusion. Another important ex-
ample is arbitrary closed intervals of real numbers ([r1, r2], ⩽) with the usual
ordering. With respect to (P(S), ⊆) we have that each subset A ⊆P(S) has
∪A and ∩A as least upper bound resp. greatest lower bound with respect to
subset inclusion. Therefore, P(S) forms a complete lattice with ⊥= ∅and
⊤= S. With respect to ([r1, r2], ⩽) we have that each u ⊆[r1, r2] has r1 as
lower bound and r2 as upper bound. Therefore, due to the least-upper-bound
property of the real numbers, compare with Axiom 2.88, we have that u also

2.4 Inductive Deﬁnitions
43
has a supremum ⊔u. The least-upper-bound property is a completeness ax-
iom that ensures that a subset a ⊆R has a least upper bound ⊔a whenever
it has an upper bound. Analogously, the greatest-lower-bound property, see
Axiom 2.89, ensures the existence of the inﬁmum of u. Therefore, u ⊆[r1, r2]
forms a complete lattice with ⊥= r1 and ⊤= r2. However, as a counterex-
ample, the lattice (R, ⩽) does not form a complete lattice, but only a so-called
condititonal complete lattice, in which the existence of an inﬁmum is only en-
sured for those subsets that have a lower bound and, analogously, the existence
of a supremum is only ensured for subsets that have a upper bound
Now, let us turn to the crucial result of lattice theory, i.e., the Knaster-
Tarski theorem, which ensures, among other things, the existence of a least
upper bound for every monotone function from a given complete lattice to
itself. In [255] the Knaster-Tarski ﬁxed-point theorem is called the lattice-
theoretical ﬁxed-point theorem. In an earlier work [160] the Knaster-Tarski
theorem was ﬁrst proven for the special case of the complete lattice (P(S), ⊆).
Then, in [255] it was generalized to complete lattices.
Theorem 2.58 (Knaster-Tarski Fixed Point Theorem) Given a com-
plete lattice A = (A, ⊑A), and a monotone function f : A →A, we have
that the set P = {a | f(a) = a} of ﬁxed points of f is not empty and the
partial order (P, ⊑A) is a complete lattice so that the following holds:
⊓{a | f(a) = a} = ⊓{a | f(a) ⊑A a}
(⊥P )
(2.63)
⊔{a | f(a) = a} = ⊔{a | a ⊑A f(a)}
(⊤P )
(2.64)
Proof. See Theorem 1 and its proof in [255].

With respect to inductive deﬁnitions we are essentially interested in the
least ﬁxed point ⊓{a|f(a) = a} of a given monotone function. Whenever an
inductive deﬁnition of a set is given it can be made precise by carving out
the encompassing domain from which its elements are drawn and deﬁning the
monotone function of which it is the least ﬁxed point. Implicitly, we will make
use of this several times in this book when we give rule-based deﬁnitions, but
also explicitly in the deﬁnition of the semantic equations that make up the
denotational semantics in Chap. 5. Let us have a look at a simple example
on how inductive deﬁnitions work formally. Let us take the speciﬁcation of a
function as an example. Let us take the familiar factorial function, which is
informally deﬁned as follows:
f!(n) = 1 · 2 · 3 · · · · · (n −1) · n
(2.65)
Now, we deﬁne the factorial function as a relation fac ⊆N0 ×N0. We do so
by deﬁning a transformation function t as an endofunction on sets of binary
relations over N0, i.e., a function t : P(N0 × N0) −→P(N0 × N0) as follows:
t = f →{⟨0, 1⟩} ∪{⟨n + 1, (n + 1) · i⟩| ⟨n, i⟩∈f}
(2.66)

44
2 Preliminary Mathematics
Now, it can be shown that f! in Eqn. (2.65) equals the least ﬁxed point
of the transformation function t, i.e., we have that f! = ⊓{f | t(f) = f}.
Therefore, it is correct to deﬁne fac as the least ﬁxed point of t, i.e.,
fac = ⊓{f | t(f) = f}
(2.67)
Actually, it can be seen that t is a monotone function with respect to the
complete lattice (P(N0 ×N0), ⊆) which guarantees, due to Theorem 2.58, that
the least ﬁxed point of t exists. Let us compare the deﬁnition of fac based
on t with the recursive deﬁnition of the factorial function in some convenient,
usual notation as found in the theory of recursive functions or, up to concrete
syntax, found in each high-level programming language:
f ′(n) =

n · f ′(n −1)
, n ⩾1
1
, n = 0
(2.68)
To get the point, ﬁrst note that the deﬁnition of t in Eqn. (2.66) is itself
non-recursive. The deﬁnition of fac becomes inductive only later through its
deﬁnition as the least ﬁxed point of t in Eqn. (2.67). In particular, although the
function variable f in Eqn. (2.66) occurs to the left and to the right of the tuple
constructor →, this expresses no recursion in itself, but just the construction
of tuples in the space P(N0 × N0) × P(N0 × N0) that then together form the
function t. This is diﬀerent for the variable f ′ in Eqn. (2.68). Its occurrence
on the left-hand side and right-hand side of the equation directly expresses
an inductive resp. recursive deﬁnition. However, as a consequence of this, we
must pre-assume an appropriate semantics of the notation used in Eqn. (2.68)
or must otherwise give an appropriate semantics to it. Now, eventually such
a semantics has to be based on some notion of least ﬁxed point. We can
give such a semantics directly or we can establish an operational semantics
based on some notion of recursive call. However, eventually also an operational
semantics has to be based on some inductive deﬁnition, e.g., in the deﬁnition
of an underlying reduction system.
At this point, it is also very important to refer to the theory of recursive
functions as established by Kleene [151, 152, 153, 154, 155, 156, 157, 158, 159].
The theory of recursive functions provides a or the classical means to give
semantics to the notation used in Eqn. (2.68). It does so by reducing it to the
well-foundedness of natural numbers. Again, this semantics eventually relies
on an inductive deﬁnition, i.e., the deﬁnition of natural numbers in this case.
Now, if you still ﬁnd it hard to see the correspondence between the deﬁnition
in Eqn. (2.68) and the deﬁnition based on Eqn. (2.66) you might want to
rewrite Eqn. (2.66) into the following, completely equivalent form:
t = f →
{⟨n, n · i⟩| n ⩾1, ⟨n−1, i⟩∈f }
∪{⟨0, 1⟩}
(2.69)
Next, let us give a further deﬁnition of the factorial function that is closer
to the convenient notation in Eqn. (2.68) but still completely equivalent to the

2.4 Inductive Deﬁnitions
45
deﬁnitions provided on the basis of t in Eqn. (2.66) or Eqn. (2.69). For this
purpose we establish a transformation t′ as an endofunction on the partial
endofunctions on N0, i.e., as a function t′ : (N0 ↛N0) −→(N0 ↛N0) as
follows:
t′ = f ′′ →n →

n · f ′′(n −1)
, n ⩾1
1
, n = 0
(2.70)
See, how close Eqn. (2.70) is to the notation in Eqn. (2.68). Now, again
it can be shown that f! in Eqn. (2.65) equals and therefore can be deﬁned as
the least ﬁxed point of the transformation t′. Actually, given an arbitrary set
A we have that the set of partial functions from A to A ordered by subset
inclusion, i.e., (A ↛A, ⊆), forms what is called a meet-complete semilattice.
As in the case of P(S) for a set S, we have that the greatest lower bound
exists for all sets of partial functions F ⊆(A ↛A), i.e., ⊓F = ∩F. Therefore,
(A ↛A, ⊆) forms a meet-complete semi-lattice with the completely undeﬁned
function as bottom element, i.e., ⊥= ∅. This already suﬃces to guarantee the
existence of least ﬁxed points of monotone functions and therefore provides
a convenient framework to give inductive deﬁnitions of sets that draw their
elements from A, and all of this in a neat notation as in Eqn. (2.70). Actually,
given sets A and B, the set of partial functions A ↛B can also be naturally
embedded into a complete lattice by introducing a top element ⊤B to B and
deﬁning f ⊔f ′ as (f ⊔f ′)(x) = ⊤B for those x for which both f(x) and f ′(x)
are deﬁned but f(x) ̸= f ′(x).
2.4.2 Rule-Based Inductive Deﬁnitions
Rule-based deﬁnitions provide additional concrete terminology and notation
to give inductive deﬁnitions. Rule-based deﬁnitions can be considered particu-
larly intuitive; in any case, they are extensively used, in particular in computer
science, take Martin-Löf type theory [182, 183, 51] as an important example.
See also [4] for a standard work on inductive deﬁnitions based on rule-based
notation. In this book, we will use rule-based notation, e.g., in the deﬁnition of
type systems of lambda calculi as well as for the one-step semantics of lambda
calculi.
Let us give an example ﬁrst. In rule-based notation, the deﬁnition of the
factorial function as provided by Eqn. (2.66) can be rewritten as Eqn. (2.71),
i.e., the factorial function is deﬁned as the least relation f ⊆N0 × N0 that is
closed under the following rules:
(i)⟨0, 1⟩∈f
(ii)
⟨n, i⟩∈f
⟨n + 1, (n + 1) · i⟩∈f
(2.71)
Although the deﬁnition of the factorial function in Eqn. (2.71) as a least set
that is closed under a collection of rules is clear and intuitive, it deserves a little
formalization to make it a more rigorous statement. As a ﬁrst observation,

46
2 Preliminary Mathematics
note that Eqn. (2.71) already establishes some convenient notation, e.g., (ii)
is actually not a single rule but a rule schema that speciﬁes a set of inﬁnitely
many rules, one for each n ∈N0.
Let us start from scratch. We follow [4] to explain rule-based deﬁnitions.
Basically, a rule is a pair (X, x) of premises X ⊆B and a conclusion x ∈B
that draw from the same base set B. Now, a set A ⊆B is said to be closed
under a rule (X, x) if X ⊆A implies x ∈A. Furthermore, given a set of rules
  we say that a set A ⊆B is closed under
  if it is closed under all r ∈
 .
Next, the set inductively deﬁned by
  is deﬁned as the intersection of all sets
A that are closed under
 .
Deﬁnition 2.59 (Rule-Based Inductive Deﬁnitions)
Given a set of
rules
  we deﬁne the set inductively deﬁned by
 , denoted by I( ), as follows:
I( ) = ∩{A | ∀(X, x) ∈
  . X ⊆A ⇒x ∈A}
(2.72)
Now, the deﬁnition of rule-based induction in Def. 2.59 is obviously well-
deﬁned. In Eqn. (2.72), the intersection of all the sets that are closed under
  always exists. However, how do we know that the deﬁnition is good? How
do we know that it achieves what we wanted, i.e., to yield the least set that
is closed under
 ? Fortunately, to see this, we have the Knaster-Tarski ﬁxed-
point theorem 2.58 to hand as well as the discussion in Sect. 2.4.1 on how to
base inductive deﬁnitions on complete lattices. First, given a set of rules
 
so that X ⊆B and x ∈B for all rules (X, x) ∈
 , let us deﬁne the follow-
ing transformation t as an endofunction on the complete lattice (P(B), ⊆) as
follows:
t = A →{x | (X, x) ∈
 , X ⊆A}
(2.73)
Now, it can be seen that t is monotone. Therefore, due to the Knaster-
Tarski ﬁxed-point theorem 2.58 its least ﬁxed point exists and furthermore
equals ∩{A | t(A) ⊆A}. Now, it can be checked that ∩{A | t(A) ⊆A} equals
I( ) as deﬁned in Def. 2.59. Therefore, we have that ⊓t equals I( ). Further-
more, it can be seen in this way that I( ) is the least set that is closed under
 . We see that a rule-based deﬁnition is just a means to implicitly specify an
appropriate monotone function for which a least ﬁxed point exists.
The usual way to deﬁne a rule set is by a set of rule schemes. Conceptually,
a single rule scheme somehow has the following form:
P1 · · · Pn
M
C1 · · · Cm
(2.74)
A rule scheme lists some assertions P1 to Pn on set membership to gen-
erate the premises of the rules and gives an expression on set membership
for generating the conclusion, possibly along with some side conditions C1 to
Cm to narrow the premises. Please have a look at the example in Eqn. (2.71)

2.4 Inductive Deﬁnitions
47
and how it relates to Eqn. (2.66). Then, several rule schemes are used to fur-
ther introduce case distinctions. The rules of all rules schemes of a rule-based
deﬁnition are simply joined.
We deliberately make no attempt here to establish a language of rule
schemes and to explain how they exactly specify resp. generate sets of rules.
Rather, we give an explicit explanation, which rule sets are meant to be gen-
erated or which mathematical objects are involved, whenever we give a rule-
based inductive deﬁnition and whenever we feel it is needed in the sequel. The
point is the following. Rule-based inductive deﬁnitions are in wide spread use,
in particular in the literature on reduction calculi and the semantics of pro-
gramming languages. Their meaning is usually obvious as the typical reader
can be expected to have enough practice in reading these inductive deﬁnitions.
Even in theoretical treatments this usually does not pose a problem, because
the used mechanism of rule-based deﬁnition is considered part of the back-
ground mathematics like all the rest of the respective prerequisite mathemat-
ical tool kit. In our case, however, it is not satisfying to fully accept inductive
deﬁnitions as given or granted, because to a large extent inductive deﬁnitions
are, in their special shape of higher-type computable functions, themselves
objects of investigation and clariﬁcation. We do not want and in this case
actually do not have to rely on the same phenomena of inductive deﬁnition in
the exploited background mathematics as in the area that we actually want
to investigate. Therefore, we will make the background mechanisms at work
explicit in the sequel. We use usual rule-based notation in our deﬁnitions at
several places. However, formalizing the concrete language of these rule-based
deﬁnitions would be too much overhead. If the reader is nevertheless inter-
ested in how a language for rule-based deﬁnitions can be fully elaborated we
recommend the work [187, 41, 124] on inductive relation deﬁnitions with the
theorem prover Isabelle/HOL (Higher-Order Logic) [209]. With [187, 41, 124]
a concrete package is provided for writing rule-based deﬁnitions.
As a minor notational detail, we will also use, e.g., the following usual
variants of notation in our rule-based deﬁnitions that are meant to denote the
same rule set as Eqn. (2.74):
P1 . . . Pn
C1 . . . Cm
M
∀C1 . . . Cm . P1 . . . Pn ⊢M
(2.75)
Let us give some further remarks on the notation for rule-based deﬁnitions.
Most commonly, the set R that is speciﬁed is a relation drawn from some
space S1 × · · · × Sk. Then, the assertions in rule schemes like Eqn. (2.74) and
the conclusion expression are often given in the form Pi = (P ′
i ∈R) and
M = (M ′ ∈R), i.e.,
P ′
1 ∈R
· · ·
P ′
n ∈R
M ′ ∈R
C1 · · · Cm
(2.76)
Having a notational form as in Eqn. (2.76), it is then said that the rules
deﬁne R as the least relation satisfying these rules. This means that R is used

48
2 Preliminary Mathematics
as the name of the target object, as well as the name of a relation variable
which is bound in the rules. This is similar to inductively deﬁning a set A as
the least upper bound of a monotone transformation function A →F(A), i.e.,
A = ⊓{A | F(A) = A}. This style of re-using the name of the target object in
the rules is usually also adopted for special relation notation, i.e., it is usual
that the notation of the target relation is used in the speciﬁcation of the rules.
As an example, have a look at the speciﬁcation of the one-step semantics in
(3.54) through (3.64). Here, the notation M
i−→N of the target relation is also
used in the rules. All of this makes sense and leads to particularly intuitive
deﬁnitions.
An important use case of rule-based inductive deﬁnition, which concerns
us in this book, is the speciﬁcation of term rewriting systems. Given a set of
terms
 , a term rewriting system establishes a reduction relation ⊆
  ×
 between terms. Therefore if a rule-based induction is used to specify such a
reduction relation ρ, both the premises and the conclusions take the form
M  N for some terms M and N. Now, some extra terminology exists for
such term tuples M  N. All of these term tuples might be called reductions
or also reduction steps. If M  N is a conclusion, the term M is called a
redex, whereas N might itself also be called a reduction, or the reduction of
M  N.
2.4.3 Complete Partial Orders and Continuous Functions
Complete partial orders are partially ordered sets in which there exist least
upper bounds for all subsets of a certain kind. For example, we have the notion
of directed complete partial order, usually abbreviated as dcpo, the notion of
chain-complete partial order and the notion of ω-complete partial order.
In a dcpo there exist least upper bounds for all directed subsets. A set is
called a directed set it if contains a shared upper bound for all of its pairs
of elements. Now, continuous functions for dcpos are functions that preserve
least upper bounds of directed subsets. Directed complete partial orders are in
widespread use in denotational semantics. Sometimes, they are also called in-
ductive complete partial orders, then abbreviated as ipos. Often, they are just
called complete partial orders for short and then abbreviated as cpos instead
of dcpos. But note that such cpos, in general, do not enjoy full completeness
properties like, e.g., complete lattices. On the contrary, we usually do not use
cpo to indicate that a partial order contains least upper bounds for all of its
subsets. Rather, a partial order that is sure to contain least upper bounds for
all of its subsets is called a join-complete semi-lattice.
A chain-complete cpo contains least upper bounds for all of its chains. A set
is called a chain if all pairs of its elements are actually related by the respective
approximation. An ω-chain is, moreover, a possibly inﬁnite, countable chain.
We will base our denotational semantics in Sect. 5 on the notion of ω-cpos.
Therefore, we have devoted several sections, i.e., Sects. 2.4.4 through 2.4.8, to

2.4 Inductive Deﬁnitions
49
the introduction of ω-cpos and the discussion of concepts that are related to
them.
2.4.4 ω-Complete Partial Orders
The choice of domains for a concrete denotational semantics depends on the
needs of the respective investigation. The choice of ω-chains is one possible,
usual choice; see, e.g., [192] and [224].
Deﬁnition 2.60 (ω-Chain) Given a partially ordered set (S, ⊑), a countable
subset of elements (si ∈S)i∈ω of S is called an ω-chain in S, or ω-chain for
short,
iﬀsi ⊑si+1 for all i ∈ω, i.e., s0 ⊑s1 ⊑s2 ⊑. . ..
Deﬁnition 2.61 (Bounds of ω-Chains)
Given a partially ordered set
S = (S, ⊑) and an ω-chain U = (ui ∈S)i∈ω. An element e ∈S is called the
upper bound of U
iﬀui ⊑e for all i ∈ω. An element e ∈S is called the
least upper bound of U
iﬀfor any e′ that is an upper bound of U it holds
that e ⊑e′. The least upper bound of an ω-chain U, which is also called the
supremum of U, is unique and is also denoted by ⊔S U.
Obviously, an element e ∈S is the upper bound of an ω-chain U : ω →S
if e is an upper bound of the range of U in S, i.e., if e is an upper bound of
U †(ω). Similarly, the least upper bound of U equals the least upper bound
of the range of U, i.e., ⊔SU = ⊔S(U †(ω)). Given an ω-chain (ui ∈S)i∈ω we
also use an alternative notation for the least upper bound of such a chain,
which gives the ranging index i ∈ω as a subscript to the least upper bound
symbol rather than to the chain, i.e., we use all of the following notations
equivalently:
⊔S(ui)i∈ω = ⊔(ui)i∈ω = ⊔
i∈ωui = ⊔S
i∈ωui
(2.77)
The auxiliary notation can be particularly intuitive when we deal with
nested least upper bound structures; see also Lemma 2.75, for example:
⊔
i∈ω ⊔
j∈ω ⟨ai, bj⟩= ⊔(⊔(⟨ai, bj⟩)j∈ω)i∈ω
(2.78)
Now, let us turn to ω-cpos in Def. 2.62, which play a central role in our
denotational semantics of the probabilistic lambda calculus.
Deﬁnition 2.62 (ω-Complete Partial Order) A structure (S, ⊑, ⊥) that
consists of a partially ordered set (S, ⊑) and an element ⊥∈S is called an
ω-complete partial order, or ω-cpo for short, if every ω-chain U = (ui ∈S)i∈ω
has a least upper bound ⊔U ∈S and ⊥is the least element of S with respect
to ⊑, i.e., for all s ∈S we have that ⊥⊑s.

50
2 Preliminary Mathematics
2.4.5 ω-CPO Targeting Function Spaces
Next, we are interested in sets of functions that have an ω-cpo as target
domain. We will equip these function spaces with a partial ordering and a
bottom element and they will turn out to be cpos. Then, we will call them
ω-cpo targeting function spaces. In semantics of programming languages we
are usually interested in function spaces of ω-continuous functions only; com-
pare with Sect. 2.4.7. An ω-continuous function is a function for which both
the source and the target domain are ω-cpos, whereas in case of an ω-cpo
targeting function space only the target space is required to be an ω-cpo.
We will use ω-cpo targeting function spaces as base domains in our denota-
tional semantics. For standard, non-probabilistic calculi, you will usually ﬁnd
ﬂat domains as base domains in the denotational semantics. In our semantics,
base elements must be functions, because they assign probabilities to even
more basic objects, which we will call data points later. However, it will turn
out that it is not important that these functions are ω-continuous. It will only
be important that these functions form an ω-cpo. We will see that ω-cpos are
not needed as source domains to ensure the existence of least upper bounds
in function spaces. It suﬃces that the target domain is an ω-cpo to ensure the
general existence of such least upper bounds.
Deﬁnition 2.63 (ω-CPO Targeting Function Space) Given a set S and
an ω-cpo E = (E, ⊑E, ⊥E) we deﬁne the ω-cpo targeting function space
⌊S −→E⌋as a structure (S −→E, ⊑, ⊥) with ⊑∈P((S −→E) × (S −→E))
and ⊥∈S −→E so that for all f1, f2 ∈S −→E we have that
f1 ⊑f2 ⇔∀s ∈S . f1(s) ⊑E f2(s)
(2.79)
⊥= s ∈S →⊥E
(2.80)
We immediately have that (S −→E, ⊑) in Def. 2.63 is a partial order.
We proceed with proving that the whole structure ⌊S −→E⌋forms an ω-cpo.
First, as the crucial step, we prove that each ω-chain in ⌊S −→E⌋has a
least upper bound in Lemma 2.64. Next, the fact that ⌊S −→E⌋is an ω-cpo
follows immediately from Lemma 2.64 as Corollary 2.65.
Lemma 2.64 (L.U.B.s in ω-CPO Targeting Function Spaces)
Given
an ω-cpo targeting function space ⌊S −→E⌋and an ω-chain (ci : S −→E)i∈ω
the least upper bound ⊔S→EC exists and is given pointwise as follows:
⊔C = s ∈S →⊔E (ci(s))i∈ω
(2.81)
Proof. As a premise we know that the sequence (ci)i∈ω is an ω-chain. Therefore
we know that ci ⊑ci+1 for all i ∈ω. This implies, due to the pointwise
deﬁnition of ⊑in Eqn. (2.79) that also ci(s) ⊑E ci+1(s) for all i ∈ω and s ∈S.
Therefore, we know that (ci(s))i∈ω is an ω-chain for all s ∈S. Therefore, due
to the premise that E is an ω-cpo, we know that the least upper bound

2.4 Inductive Deﬁnitions
51
⊔E(ci(s))i∈ω exists. Based on that we can deﬁne a function l ∈⌊S −→E⌋as
follows:
l = s ∈S →⊔E (ci(s))i∈ω
(2.82)
Next, we prove that l is the least upper bound of C, i.e., l = ⊔S→EC.
This again follows pointwise from the deﬁnition of ⊑in Eqn. (2.79). We know
that ci(s) ⊑E l(s) for all i ∈ω and s ∈S and therefore ci ⊑l for all i ∈ω.
Furthermore, given a function l′ ∈⌊S −→E⌋with ci ⊑l′ for all i ∈ω.
Then, we know that ci(s) ⊑E l′(s) for all s ∈S. Therefore, we know that
l(s) ⊑E l′(s) for all s ∈S. Therefore we know that l ⊑l′.

Corollary 2.65 (ω-CPO Targeting Function Spaces are ω-CPOs)
Each ω-cpo targeting function space ⌊S −→E⌋is an ω-cpo.
Proof. With ⊥S→E there exists a least element in S →E. The fact that ⊥S→E
is the least element of S →E follows pointwise from the deﬁnition of ⊥S→E
in Eqn. (2.80). Then, Lemma 2.64 ensures the existence of a least upper bound
for each ω-chain in S →E.

2.4.6 Product Spaces of ω-CPOs
Before we turn to ω-continuous function spaces in Sect. 2.4.7 we will show
how to construct a product space out of two given ω-cpos so that the result-
ing space is itself an ω-cpo. Consequently, we will call the result of such a
construction a product space of ω-cpos. Actually, the construction is straight-
forward, pointwise, as in the case of the ω-cpo targeting function space seen
in Sect. 2.4.5.
Deﬁnition 2.66 (Product Space of ω-CPOs)
Given two ω-cpos
D = (D, ⊑D, ⊥D) and E = (E, ⊑E, ⊥E) we deﬁne their product space [D×E]
as a structure (D × E, ⊑, ⊥) with ⊑∈P((D × E) × (D × E)) and ⊥∈D × E
so that for all d, d′ ∈D and e, e′ ∈E we have that
⟨d, e⟩⊑⟨d′, e′⟩⇐⇒(d ⊑D d′ ∧e ⊑E e′)
(2.83)
⊥= ⟨⊥d, ⊥e⟩
(2.84)
Lemma 2.67 (Product Spaces of ω-CPOs are ω-CPOs) Each product
space of ω-cpos [D × E] is an ω-cpo.
Proof. From the deﬁnition of ω-continuous product spaces in Def. 2.66 it
follows component-wise that ⟨⊥d, ⊥e⟩is the least element of [D × E] and,
furthermore, that for each chain (⟨di, ei⟩)i∈ω there exists a least upper bound
in [D × E].


52
2 Preliminary Mathematics
Product spaces of ω-cpos are not needed directly in the deﬁnition of our de-
notational semantics; nevertheless, they are important to consider. The prob-
abilistic lambda calculus that we will consider is reductionist with respect to
its types. It knows only ground types and functional types. As usual, due to
currying [236], product types do not add a conceptual value to the investiga-
tion. This means that we have no product types in our calculus and therefore
we also do not need product spaces of ω-cpos as domains in the deﬁnition
of our denotational semantics. However, we technically need them, because
they emerge implicitly, on the ﬂy, in some crucial proofs in the book. For
example, we need them in proving that the semantic ﬁxed-point operator Φ
is ω-continuous; see Lemma 2.82. Also, we need them to prove that seman-
tic update preserves ω-continuity; see Lemma 5.21. In both cases we turn a
function application into an explicit apply operator; compare with Def. 2.73,
which causes product domains to appear.
2.4.7 ω-Continuous Function Spaces
The notion of ω-continuous function plays a central role. An ω-continuous
function is a function between two ω-cpos that is monotone and, moreover,
preserves least upper bounds of ω-chains. These properties will be exploited
later, to prove the existence of ﬁxed points; compare with Theorem 2.79. First,
we introduce images of ω-cpos. Then we deﬁne ω-continuous functions and, in
particular, ω-continuous function spaces. After a series of important technical
lemmas we will prove that ω-continuous function spaces are themselves cpos.
Deﬁnition 2.68 (Images of ω-Chains)
Given two sets A and B,
a function f : A →B and an ω-chain a = (ai ∈A)i∈I. We deﬁne the image
of a under f, also denoted by f †(a), as an indexed family as follows:
f †(a) = (f(ai))i∈I
(2.85)
Note that we overload the notation f †((ai ∈A)i∈I) for the image of an
ω-chain with the notation for the image f †(A) of some set A under the function
f. Technically, we often need the fact that the image of an ω-chain is again
an ω-chain, as expressed by Lemma 2.69.
Lemma 2.69 (Images of ω-Chains)
Given two ω-cpos (A, ⊑, ⊥) and
(B, ⊑, ⊥) and a monotone function f : A →B. The image of an ω-chain
(ai ∈A)i∈ω under f, i.e., (f(ai) ∈B)i∈ω, is again an ω-chain.
Proof. This follows immediately by the fact that f is a monotone function.
We have that ai ⊑ai+1 for all i ∈ω, because (ai ∈A)i∈ω is an ω-chain.
Therefore, and due to the monotonicity of f, we have that f(ai) ⊑f(ai+1)
for all i ∈ω.

Next, an ω-continuous function is a monotone function between ω-cpos that,
moreover, preserves least upper bounds. We will take the set of ω-continuous

2.4 Inductive Deﬁnitions
53
functions between two ω-cpos and turn it into a structure which is called an
ω-continuous function space. Then, we will be able to show that ω-continuous
function spaces are ω-cpos. Given two ω-cpos E and D, we use [E −→D] to
denote both the set of ω-continuous functions between E and D as well as the
ω-continuous function space constructed for E and D.
Deﬁnition 2.70 (ω-Continuous Function)
Given two ω-cpos
D = (D, ⊑D, ⊥D) and E = (E, ⊑E, ⊥E). A function f : D −→E is
ω-continuous iﬀit is monotone and preserves least upper bounds of ω-chains,
i.e., for all ω-chains U = (ui ∈D)i∈ω it holds that
f(⊔DU) = ⊔E (f(ui))i∈ω
(2.86)
Deﬁnition 2.71 (Set of ω-Continuous Functions)
Given two ω-cpos
D = (D, ⊑D, ⊥D) and E = (E, ⊑E, ⊥E), we deﬁne the set of ω-continuous
functions between E and D, denoted by [D −→E], as follows:
[D −→E] = {f : D −→E | f is ω −continuous}
(2.87)
Deﬁnition 2.72 (ω-Continuous Function Space)
Given two ω-cpos
D = (D, ⊑D, ⊥D) and E = (E, ⊑E, ⊥E), we deﬁne the ω-continuous function
space [D−→E] as the structure ([D−→E], ⊑, ⊥) with approximation relation
⊑∈P([D−→E] × [D−→E]) and bottom element ⊥∈[D −→E] so that for
all f1, f2 ∈[D−→E] we have that
f1 ⊑f2 ⇔∀d ∈D . f1(d) ⊑E f2(d)
(2.88)
⊥= d ∈D →⊥E
(2.89)
Note that the deﬁnition of ω-continuous function in Def. 2.70 is well de-
ﬁned, i.e., the sequence (f(ui))i∈ω needed to deﬁne ω-continuity is actually an
ω-chain, because the function f is required to be monotone by Def. 2.70; com-
pare with Lemma 2.69. Therefore, we know that also the least upper bound
of (f(ui))i∈ω actually exists.
Next, we make explicit function application as a family of apply operators
to ease argumentation in the sequel. We can perceive a function application
f(d) also as the result of applying a semantic application operator at one
level higher in the functional hierarchy. The operator, which we call apply,
is a function apply : (((A →B) × A) →B) for all sets A and B, i.e., it
takes a function f : A →B and data d : A as its arguments and yields the
value of applying f to d as its result. This viewpoint is exactly the viewpoint
established by c.c.c. models (Cartesian closed category) [173, 144] of typed
lambda calculi. As an important technical lemma, we will prove that each
apply operator is monotone in both of its arguments, if these arguments are
ω-cpos; see Lemma 2.74.
Deﬁnition 2.73 (The Apply Operator) For each pair of sets A and B
the apply operator is deﬁned for all f : A →B and d : A as the following
function:

54
2 Preliminary Mathematics
apply : ((A −→B) × A) −→B
(2.90)
apply(f, d) = f(d)
(2.91)
Lemma 2.74 (Monotonicity of Function Application)
Given ω-cpos
A = (A, ⊑, ⊥) and B = (B, ⊑, ⊥), the apply operator for the ω-continuous
function space [[[A →B] × A] →B] is monotone in both of its arguments,
i.e., for all f, f ′ : [A →B] and d, d′ ∈A we have that
f ⊑f ′ =⇒apply(f, d) ⊑apply(f ′, d)
(2.92)
d ⊑d′ =⇒apply(f, d) ⊑apply(f, d′)
(2.93)
Proof. First, with respect to Eqn. (2.92) we have that f ⊑f ′ implies
f(d) ⊑f ′(d), which follows pointwise. Next, with respect to Eqn. (2.93) we
have that d ⊑d′ implies f(d) ⊑f(d′), which follows by the fact that
f ∈[A →B] is ω-continuous and therefore monotone. Now, the Lemma
follows immediately by the deﬁnition of the apply operator in Def. 2.73.

Next, we will show that each ω-continuous function space is an ω-cpo. The
proof of this proposition, see Corollary 2.78, is a reﬁnement of the proof of
Corollary 2.65 in which we have shown that each ω-cpo targeting function
space is an ω-cpo. The basic steps concerning the existence of a bottom ele-
ment and the existence of a least upper bound for each chain in the function
space remain exactly the same. The diﬀerence is that we cannot be sure any
more that the least upper bound that we construct for a chain of functions
is itself an ω-continuous function. However, we want it to be an ω-continuous
function, otherwise it would lay outside the deﬁned ω-continuous function
space.
You can ﬁnd a proof that ω-continuous function spaces are ω-cpos also
as Proposition 2.1 in [192]. In typical proofs in textbooks or, e.g., the proof
in [192], the proofs of a l.u.b. exchange lemma and a proof about least upper
bounds of ω-continuous function chains are typically merged together into one
proof about ω-continuous function spaces. We have turned them into a series
of explicit lemmas, because we will need them later in proofs, e.g., in the proof
that our denotational semantics is well deﬁned.
Lemma 2.75 (L.U.B. Elimination Lemma) Given two ω-cpos A and B
and a function f : A × B →D that is monotone in both of its arguments.
Then, for all chains a = (ai ∈A)i∈ω and b = (bi ∈A)i∈ω we have that
⊔
m∈ω( ⊔
n∈ωf(am, bn) ) = ⊔
i∈ωf(ai, bi)
(2.94)
⊔
n∈ω( ⊔
m∈ωf(am, bn) ) = ⊔
i∈ωf(ai, bi)
(2.95)
Proof. We show Eqn. (2.94) only. First it is necessary to see that all involved
least upper bounds actually exist. The fact that A and B are cpos, the fact

2.4 Inductive Deﬁnitions
55
that f is monotone and Lemma 2.69 ensure the existence of all of the follow-
ing sequences together with the respective least upper bounds: the sequence
f(ai, bi)i∈ω, all sequences of the form f(am, bn)n∈ω for arbitrary but ﬁxed am
as well as the sequence (⊔f(am, bn)n∈ω)m∈ω.
We start with proving that ⊔(⊔f(am, bn)n∈ω)m∈ω ⊑⊔f(ai, bi)i∈ω. Con-
sider an arbitrary element f(am, bn) ∈D for some m, n ∈ω. Without loss of
generality, we can assume that m ⩽n. Now, we know that am ⊑an, because
a is an ω-chain. Therefore, we know due to the monotonicity of f in both
of its arguments that f(am, bn) ⊑f(an, bn). Now, we know that f(an, bn) is
smaller than the least upper bound of f(ai, bi)i∈ω. Altogether we have that
∀m ∈ω.∀n ∈ω.f(am, bn) ⊑⊔f(ai, bi)i∈ω
(2.96)
Let us take am as arbitrary but ﬁxed. Due to Eqn. (2.96) we know
that ⊔f(ai, bi)i∈ω is an upper bound of the ω-chain f(am, bn)n∈ω and there-
fore also ⊔f(am, bn)n∈ω ⊑⊔f(ai, bi)i∈ω. But from the latter it follows that
⊔f(ai, bi)i∈ω is also an upper bound of the ω-chain (⊔f(am, bn)n∈ω)m∈ω which
amounts to ⊔(⊔f(am, bn)n∈ω)m∈ω ⊑⊔f(ai, bi)i∈ω.
Next, we show that ⊔f(ai, bi)i∈ω ⊑⊔(⊔f(am, bn)n∈ω)m∈ω. For each ar-
bitrary but ﬁxed j ∈ω, we know that f(aj, bj) must be smaller than the
least upper bound of f(ai, bi)i∈ω, i.e., f(aj, bj) ⊑⊔f(ai, bi)i∈ω. Furthermore,
we can see that f(aj, bj) ⊑⊔(⊔f(am, bn)n⩾j)m⩾j. Therefore we also know
that f(aj, bj) ⊑⊔(⊔f(am, bn)n∈ω)m∈ω, i.e., ⊔(⊔f(am, bn)n∈ω)m∈ω is an up-
per bound of f(aj, bj) and therefore ⊔f(ai, bi)i∈ω ⊑⊔(⊔f(am, bn)n∈ω)m∈ω. 
Corollary 2.76 (L.U.B. Exchange Lemma) Given two ω-cpos A and B
and a function f : A × B →D that is monotone in both of its arguments.
Then, for all chains (ai ∈A)i∈ω and (bi ∈A)i∈ω we have that
⊔
m∈ω( ⊔
n∈ωf(am, bn) ) =
⊔
n∈ω( ⊔
m∈ωf(am, bn) )
(2.97)
Proof. Immediate corollary from the two parts of the l.u.b. elimination Lemma,
i.e., Lemma 2.75, as follows:
⊔
m∈ω( ⊔
n∈ωf(am, bn) ) =
⊔
i∈ωf(ai, bi) =
⊔
n∈ω( ⊔
m∈ωf(am, bn) )

Lemma 2.77 (ω-Continuity of Least Upper Bounds)
Given an
ω-continuous function space [D →E] and an ω-chain F of functions in
[D →E], then the least upper bound ⊔F is an ω-continuous function.
Proof. We assume that F is given as F = (fi ∈[D →E])i∈ω. According to
Def. 2.70, we need to show for all chains D′ = (di ∈D)i∈ω we have that

56
2 Preliminary Mathematics
(⊔F)(⊔D′) = ⊔( (⊔F)(di) )i∈ω
(2.98)
Due to Lemma 2.64 we know that the least upper bound of F is given
pointwise so that the left-hand side of Eqn. (2.98) equals the following:
⊔
i∈ω( fi(⊔D′) )
(2.99)
Next, we can exploit that all fi in the ω-chain F are ω-continuous func-
tions, so that Eqn. (2.99) equals
⊔
i∈ω( ⊔
j∈ωfi(dj) )
(2.100)
Next, the application function in Eqn. (2.100) can be made explicit yielding
the following formula:
⊔
i∈ω( ⊔
j∈ωapply(fi, dj) )
(2.101)
Now, we know due to Lemma 2.74 that apply is monotone in both of its
arguments and therefore it is possible to apply the l.u.b. exchange Lemma 2.76
to Eqn. (2.101) so that Eqn. (2.101) equals
⊔
j∈ω( ⊔
i∈ωapply(fi, dj) ) = ⊔
j∈ω( ⊔
i∈ωfi(dj) )
(2.102)
Now, again by the pointwise deﬁnition of ⊔F, i.e., due to Lemma 2.64, we
know that Eqn. (2.102) equals
⊔( (⊔F)(dj) )j∈ω
(2.103)

Corollary 2.78 (ω-Continuous Function Spaces are ω-CPOs)
Each ω-continuous function space [D −→E] is an ω-cpo.
Proof. The pointwise deﬁnition of ⊥S→E in Eqn. (2.89) ensures that ⊥S→E
is the least element of [D −→E]. Next, due to Lemma 2.64, we know that
for each ω-chain F in [D −→E] there exists a least upper bound ⊔S→EF
in S →E. It remains to show that ⊔S→EF also is an element of [D −→E],
i.e., that ⊔S→EF is ω-continuous. But this is exactly what has been proven
as Lemma 2.77.

2.4.8 Fixed Points in ω-CPOs
In this section we prove the ﬁxed-point theorem for ω-cpos, which ensures
the existence of a least ﬁxed point for ω-continuous functions of the form
f ∈[D −→D]. The ﬁxed-point theorem is crucial for the development of the
denotational semantics. We will turn the uniquely existing ﬁxed point into an

2.4 Inductive Deﬁnitions
57
operator, i.e., we deﬁne a family of operators Φ : (D →D) →D for each ω-cpo
D that yields the ﬁxed point for each argument function. Then, the ﬁxed-point
operator Φ will be exploited in the denotational semantics of Chap. 5 to deﬁne
the semantics of recursion in our probabilistic lambda calculus. Furthermore,
we need to prove monotonicity and ω-continuity of the ﬁxed-point operator, in
order to prove the l.u.b. substitution Lemma 5.21 later, which is the basis for
proving the denotational semantics of lambda abstractions to be well deﬁned.
Theorem 2.79 (Fixed-Point Theorem for ω-CPOs ) Given an ω-cpo D
and an ω-continuous function f ∈[D −→D]. Then, there exists a least ﬁxed
point d ∈D of f and, moreover, d can be constructed as the least upper bound
of an ω-chain in D, i.e.,
1. f(d) = d
2. for all d′ with f(d′) = d′ it holds that d ⊑D d′
3. d = 	
n⩾0
f n(⊥D)
Proof. See, e.g., Proposition 2.2 in [192] or Theorem 4.12 in [118]. First, we
need to show that (f n(⊥D))n∈ω is actually an ω-chain. But the ω-chain prop-
erty f n(⊥D) ⊑D f n+1(⊥D) for all n ∈N0 can immediately be seen by a
natural induction on n. First, due to the minimality of ⊥D and f 0(⊥D) = ⊥D
we have that f 0(⊥D) ⊑f 1(⊥D) as induction anchor. Next, we know that f is
monotone, because f is ω-continuous. Therefore, as induction step for n ⩾1,
we know that f n−1(⊥D) ⊑f n(⊥D) implies f(f n−1(⊥D)) ⊑f(f n(⊥D)), i.e.,
f n(⊥D) ⊑f n+1(⊥D). Next, we show that ⊔
n⩾0f n(⊥D) is a ﬁxed point of f. Due
to the ω-continuity of f we know that f( ⊔
n⩾0f n(⊥D)) equals ⊔
n⩾0(f(f n(⊥D)))
which can be written as ⊔
n⩾0f n+1(⊥D) and equally well as ⊔
n⩾1f n(⊥D). Now,
again due to f 0(⊥D) ⊑f 1(⊥D) we have that ⊔
n⩾1f n(⊥D) equals ⊔
n⩾0f n(⊥D).
Next, we show the minimality of
⊔
n⩾0f n(⊥D). Assume that we have an ele-
ment d′ ∈D so that f(d′) = d′. Now, due to the minimality of ⊥D we know
that ⊥D ⊑d′. Now, due to the monotonicity of f it can be shown by natural
induction that f n(⊥) ⊑f n(d′) = d′ for all n. This means that d′ is an upper
bound of (f n(⊥))n⩾0 and therefore we also know that ⊔
n⩾0f n(⊥D) ⊑d′.

Deﬁnition 2.80 (Fixed-Point Operator) Given an ω-cpo D, the ﬁxed-
point operator Φ : [[D −→D] −→D], which yields, according to Theo-
rem 2.79, for every function f : [D −→D] the least ﬁxed point of f, is
deﬁned as follows:
Φ(f) =

n⩾0
f n(⊥D)
(2.104)
Corollary 2.81 (Monotonicity of the Fixed-Point Operator) Given an
ω-cpo D, the ﬁxed-point operator Φ is monotone.

58
2 Preliminary Mathematics
Proof. Direct Corollary from the deﬁnition of the ﬁxed-point operator and the
ﬁxed-point Theorem 2.79. Given functions f1 ⊑f2 we have that Φf1 = f1 and
Φf2 = f2 and therefore Φf1 ⊑Φf2.
Lemma 2.82 (ω-Continuity of the Fixed-Point Operator)
Given an
ω-cpo D, the ﬁxed-point operator Φ is ω-continuous.
Proof. See, e.g., Proposition 3 in [192]. Due to Corollary 2.81 we already know
that the ﬁxed-point operator Φ is monotone. Therefore it remains to show
that for all ω-chains F = (fi ∈[D →D])i∈ω we have that
Φ(⊔F) = ⊔(Φ†F)
(2.105)
Let us write Eqn. (2.105) more explicitly in terms of the constituting chain
elements, i.e.,
Φ( ⊔
i∈ω(fi)) = ⊔
i∈ω(Φfi)
(2.106)
We show that both Φ( ⊔
i∈ω(fi)) ⊑⊔
i∈ω(Φfi) and ⊔
i∈ω(Φfi) ⊑Φ( ⊔
i∈ω(fi)) and start
with the latter. We know that fi ⊑
⊔
i∈ω(fi) for all i ∈ω. Then, we know
due to the monotonicity of the ﬁxed-point operator, i.e., Corollary 2.81, that
Φfi ⊑Φ( ⊔
i∈ω(fi)) for all i ∈ω, which means nothing else but Φ( ⊔
i∈ω(fi)) is an
upper bound for all Φfi and therefore ⊔
i∈ω(Φfi) ⊑Φ( ⊔
i∈ω(fi)).
We proceed to show that Φ( ⊔
i∈ω(fi)) ⊑
⊔
i∈ω(Φfi). Since we know that
Φ( ⊔
i∈ω(fi)) is the least ﬁxed point of ⊔F it suﬃces to show that
⊔
i∈ω(Φfi)
is also a ﬁxed point of ⊔F in order to prove this. Now, the target is to prove
that (⊔F)( ⊔
i∈ω(Φfi)) = ⊔
i∈ω(Φfi). Now, due to the deﬁnition of the least upper
bound in Lemma 2.64 we have that (⊔F)( ⊔
i∈ω(Φfi)) equals
⊔
j∈ω( fj ( ⊔
i∈ω(Φfi)) )
(2.107)
Now we know that each fj ∈[D →D], i.e., that each fj is ω-continuous.
Therefore, we have that Eqn. (2.107) equals
⊔
j∈ω( ⊔
i∈ω(fj(Φfi)) )
(2.108)
Now we can introduce the explicit apply operator from Def. 2.73 to Eqn. (2.108)
so that it is turned into the following formula:
⊔
j∈ω( ⊔
i∈ωapply(fj, Φfi) )
(2.109)
Given the monotonicity of the apply operator as stated in Lemma 2.74, it
is possible to apply the l.u.b. elimination Lemma 2.75 to Eqn. (2.109) so
that Eqn. (2.109) is shown to equal

2.5 Miscellaneous
59
⊔
i∈ωapply(fi, Φfi) = ⊔
i∈ω(fi(Φfi))
(2.110)
Finally, due to the fact that Φfi is a ﬁxed point for all of the fi we have
that Eqn. (2.110) equals
⊔
i∈ω(Φfi)
(2.111)

2.5 Miscellaneous
The purpose of this section is to compile further, rather basic mathematical
concepts and notation that are used in the book. We have selected just a few
concepts, for which we felt that it is convenient to present them at a single
spot. We do not discuss concepts from automata theory here, albeit these con-
cepts are very important for this book, i.e., in the treatment of termination
behavior in Chap. 4. We take all the important notions, such as recursive lan-
guages, recursive functions, total recursive functions etc. for granted. As usual,
it is necessary to mention [137] as an authoritative standard textbook with
respect to automata theory and formal languages. In particular, the funda-
mental notions of formal languages are important for us and, also, knowledge
about how they are practically exploited in the speciﬁcation of languages and
calculi. For example, a robust understanding of abstract syntax versus con-
crete syntax as found in the ﬁeld of compiler construction is important. As
usual we refer to the well-known “dragon book” [5] as reference for compiler
construction material.
2.5.1 Set and Function Notation
In this section we compile and ﬁx some important terminology and notation
for sets and functions that is used throughout the book.
Given sets S and T , we denote the complement of T in S, which is deﬁned
as {s ∈S | s ̸∈T }, by S\T or S−T. If we can assume S is known from the
context and T ⊆S we denote S\T also by T, which is then just called the
complement of T for short. Given sets A, B and U such that A ⊆U and
B ⊆U, we have that A\B equals A ∩B, where B is assumed to denote the
complement of B in U. Given sets A, B and C we have that A\(B ∩C) equals
A\B ∪A\C. We denote the one-element set by 1 and its element by 1, i.e.,
1 = {1}.
Given a function f : S −→T . We use f −1 : T −→P(S) to denote the
inverse function of f which is deﬁned by f −1(t) =DEF {s ∈S | f(s) = t}.
We call f −1(t) the inverse image of t under f. We use f † : P(S) −→P(T ) to
denote the lifting of f to sets of source and target elements which is deﬁned
for all subsets U ⊆S as f †(U) =DEF {f(u) | u ∈U}. We say that f †(U)

60
2 Preliminary Mathematics
is the image of U under f, or simply f’s image of U. We call f †(S) ⊆T
the range of the function f. The set S is usually called the domain of the
function, whereas T is called the codomain or also the range of the function.
This means that the use of range of a function is ambiguous. Furthermore,
with domain we usually refer to more complex structures or spaces than sets,
i.e., the structures that denotational semantics is based on. All of these issues
are mere presentational issues, because it should always be clear from the
context which kind of concrete mathematical structure is meant in each case.
Given a function f : S →T with f(d) = F(d) for each d ∈S for some
expression F(d), we use the notation d →F(d) to denote the function f,
i.e., f = d →F(d). An expression of the form d →F(d) is called a seman-
tic abstraction. The semantic abstraction notation can be used to avoid the
introduction of additional, intermediate function symbols. For example, we
can write ((d →+1(d))x) instead of writing f(x), where f(d) = +(1(d)). In
semantic equations it is used to make the deﬁnition of functions more explicit,
i.e., we often write f =DEF d →F(d) instead of writing f(d) =DEF F(d).
We denote the partial function space between sets A and B by A ↛B.
We denote the set of injective functions, also called embeddings, between sets
A and B by A →B. A function f : S −→S′ is called an endofunction if
and only if S = S′. Given a set S, the identity function on S is denoted by
idS : S →S and is deﬁned as x ∈S →x. If S is clear from the context, idS
is also written id for short.
Deﬁnition 2.83 (n-fold Function Application)
Given an endofunction
f : S −→S and an object d ∈S, we deﬁne f n(d), i.e., the n-fold application
of f to d, for each n ⩾0 as follows:
f n(d) =

d
, n = 0
f(f n−1(d))
, else
(2.112)
Deﬁnition 2.84 (Function Update) Given a function φ : S −→T , an
element x ∈S and an element d ∈T , we deﬁne the update of the function φ
with respect to the argument x (at the point x) by data d, denoted by φ[x := d],
for each s ∈S as follows:
φ[x := d](s) =

d
, s = x
φ(s)
, else
(2.113)
2.5.2 Indexed Families and Sequences
Indexed families are a basic mathematical notation. Given a set S, an indexed
family e = (ei)i∈I of elements of S indexed by I is a function e : I −→S so
that ei = e(i) for all i ∈I. Then, the set I is called the index set and S is
said to be indexed by I. The function e : I −→S is just a means to list and
access objects in S via I. Sequences are sets indexed by the natural numbers

2.5 Miscellaneous
61
or starting fragments of the natural numbers. Often, counting of sequence
elements may start with zero, as is usual for walks and paths in graphs;
compare with Defs. 2.35 and 2.40. Also often, counting of sequence elements
may start with one, as is usual for n-vectors; see Sect. 2.5.5. A ﬁnite sequence
e = (ei)i∈{0,...,n} is also written e0e1e2 · · · en. We denote its last element en
by [e]▶, i.e., [e0e1e2 · · · en]▶= en. Given a sequence e we denote its length by
#(e). Similarly, given a set of sequences E we denote the maximum length
of sequences in E as #(E). Given a ﬁnite sequence s and a ﬁnite or inﬁnite
sequence t we denote the concatenation of s and t by s • t.
Next, we recap the usual Kleene closure notation that provides neat nota-
tion for certain sets of sequences. Given a set S, its empty sequence ϵ, the set
Sn of its element sequences of length n, the set S⋆of its element sequences
of ﬁnite length, and the set S+ of its non-empty element sequences of ﬁnite
length are deﬁned as follows:
S0 = {ϵ} , with arbitrary but ﬁxed ϵ ̸∈S
(2.114)
Sn = {(si)i∈{0,..,n−1} | si ∈S } , n ⩾1
(2.115)
S⋆= {s | n ⩾0, s ∈Sn }
(2.116)
S+ = {s | n ⩾1, s ∈Sn }
(2.117)
Note that the set {ϵ} is a one-element set for an arbitrarily chosen but ﬁxed
object ϵ ̸∈S not yet contained in S, which represents the empty sequence of
elements of S. The set S⋆in Eqn. (2.116) is called the Kleene closure of S, or
also the Kleene hull of S.
2.5.3 Equivalence Relations
In this section we recap the notions of equivalence relation, equivalence class
and quotient set. We need these concepts in Sect. 4.3.2 in order to explain
the notion of program run event, which is an equivalence class of program
executions that cannot be distinguished further by the underlying Markov
chain semantics; compare with Def. 4.12.
Deﬁnition 2.85 (Equivalence Relation) A binary relation ≈: S ×S on S
is an equivalence realation if it is reﬂexive, symmetric and transitive, i.e., for
all s, s1, s2, s3 ∈S it holds that
1. s ≈s (reﬂexivity)
2. s1 ≈s2 =⇒s2 ≈s1 (symmetry)
3. s1 ≈s2 ∧s2 ≈s3 =⇒s1 ≈s3 (transitivity)
Deﬁnition 2.86 (Equivalence Class of an Equivalence Relation)
Given an equivalence relation ≈: S × S and an element e ∈S we deﬁne the
equivalence class of e with respect to ≈, which is denoted by [e]/≈, as follows:
[e]/≈= {e′ | e′ ≈e}
(2.118)

62
2 Preliminary Mathematics
Deﬁnition 2.87 (Quotient Set) Given an equivalence relation ≈: S×S we
deﬁne the quotient set S/≈of S under ≈as follows:
S/≈= {[s]/≈| s ∈S}
(2.119)
2.5.4 Real Analysis
Real analysis is important for us, because the domains of our semantics are
based on real numbers. The foundational axioms of real analysis, which will
be exploited in semantic argumentations, are equally important for us as basic
terminology and notation from real analysis. For thorough treatments of real
analysis, please have a look, e.g., at [6, 234].
Axiom 2.88 (Least-Upper-Bound Property) If a set of real numbers
has an upper bound then it has a least upper bound.
Axiom 2.89 (Greatest-Lower-Bound Property) If a set of real numbers
has a lower bound then it has a greatest lower bound.
Deﬁnition 2.90 (Convergent Sequences and Limits)
A sequence of
real numbers (ai)i∈ω is called convergent
iﬀthere exists an a ∈R such that
for all ϵ ∈R there exists an n ∈N0 such that for all n′ > n we have that
|a −an′| < ϵ. Then, the number a is called the limit of (ai)i∈ω and is denoted
by lim
n→∞an. In case a sequence is not convergent, it is called divergent.
Lemma 2.91 (Limits of Convergent Sequences) Given sequences of real
numbers (ai)i∈ω and (bi)i∈ω, as well as a real number k ∈R we have that
k + lim
n→∞an = lim
n→∞(k + an)
(2.120)
k · lim
n→∞an = lim
n→∞(k · an)
(2.121)
lim
n→∞an + lim
n→∞bn = lim
n→∞(an + bn)
(2.122)
lim
n→∞an · lim
n→∞bn = lim
n→∞(an · bn)
(2.123)
Deﬁnition 2.92 (Monotonically Increasing Sequence)
A sequence of
real numbers (an ∈R)n∈ω is monotonically increasing
iﬀai ⩽ai+1 for all
i ∈N0.
The real numbers (R, ⩽) form a partial order; compare with Def 2.51. Ob-
viously, a monotonically increasing sequence is an ω-chain in (R, ⩽); compare
with Def. 2.60. If a sequence of real numbers (an ∈R)n∈ω has an upper bound
it is also said that it is bounded above. In real analysis, the least upper bound
of a sequence of real numbers is usually called the supremum of the sequence;
compare with Def. 2.53.

2.5 Miscellaneous
63
Theorem 2.93 (Monotone Convergence Theorem) If a monotonically
increasing sequence of real numbers (an ∈R)n∈ω is bounded above then its
supremum exists and equals its limit, i.e.,
lim
n→∞(an) = ⊔{an | n ∈N0}
(2.124)
2.5.5 Algebraic Structures
In Sect. 5.1.4 we will deﬁne operations ⊕and ⊗for functionals f of the form
f : Sn →. . . S1 →S0 →R that mirror the arithmetic operations + and ×
of the base domain R on the functional domain S = Sn →. . . S1 →S0 →R.
Then, it turns out that the algebraic structure (S, ⊕, ⊗, 0S) forms a vector
space. This is important, because we need the entire set of vector space laws
in proofs of properties of our denotational semantics. In this section we recap
the vector space laws. As usual, we have organized the deﬁnition of vector
spaces as a sequence of reﬁnements, evolving from groups, over abelian groups
and ﬁelds to vector spaces.
Deﬁnition 2.94 (Group) An algebraic structure (G, +, 0G) with set G, op-
eration + : G × G →G and element 0G, called the neutral element, is called
a group
iﬀthe following axioms hold true for all e, e′, e′′ ∈G:
(e + e′) + e′′ = e + (e′ + e′′)
(2.125)
e + 0G = 0G + e = e
(2.126)
∃e−1 ∈G . e + e−1 = e−1 + e = 0G
(2.127)
The axiom in Eqn. (2.125) expresses the associativity of +. The axiom
in Eqn. (2.126) expresses the neutrality of 0G with respect to + and axiom
Eqn. (2.127) requires the existence of an inverse element e−1 for each element
e in G.
Deﬁnition 2.95 (Abelian Group) A group (G, +, 0G) is called an abelian
group
iﬀthe following axiom of commutativity holds true for all e, e′ ∈G:
e + e′ = e′ + e
(2.128)
Deﬁnition 2.96 (Field) An algebraic structure (F, +, ·, 0F , 1F ) with set F,
operations + : F × F →F and · : F × F →F, and elements 0F ∈F and
1F ∈F is called a ﬁeld
iﬀboth (F, +, 0F ) and (F\{0F}, ·, 1F) are abelian
groups plus the following axioms of distributivity hold true for all e, e′, e′′ ∈F:
e · (e′ + e′′) = (e · e′) + (e · e′′)
(2.129)
(e + e′) · e′′ = (e · e′′) + (e′ · e′′)
(2.130)
Axioms Eqn. (2.129) and Eqn. (2.130) together express the distributiveness
of + over ·, where Eqn. (2.129) expresses left-distributiveness and Eqn. (2.130)
expresses right-distributiveness. For us, the important example of a ﬁeld is the
ﬁeld of real numbers (R, +, ·, 0, 1).

64
2 Preliminary Mathematics
Deﬁnition 2.97 (Vector Space) Given a ﬁeld (F, +, ·, 0F , 1F ) based on a
set F, called scalars. An algebraic structure (V, ⊕, ⊗, 0V ) based on a set V
of elements, called vectors, with operations ⊕: V × V →V , called vector
addition, and ⊗: F × V →V , called scalar multiplication, as well as a
neutral element 0V ∈V , called the null vector, is called a vector space over
F or F-vector space for short
iﬀ(V, ⊕, 0V ) forms an abelian group plus the
following axioms hold true for all scalars i, i′ ∈F and all vectors v, v′ ∈V :
i ⊗(v ⊕v′) = (i ⊗v) ⊕(i ⊗v′)
(2.131)
(i + i′) ⊗v = (i ⊗v) ⊕(i′ ⊗v)
(2.132)
(i · i′) ⊗v = (i ⊗(i′ ⊗v))
(2.133)
1F ⊗v = v
(2.134)
The laws expressed by Eqn. (2.131) and Eqn. (2.132) in Def. 2.97 are
distributivity laws, i.e., Eqn. (2.131) explains how scalar multiplication dis-
tributes over vector addition, whereas Eqn. (2.132) explains how scalar ad-
dition distributes over vector multiplication. The axiom in Eqn. (2.133) ex-
presses the compatibility of scalar multiplication with vector multiplication.
Axiom Eqn. (2.134) expresses neutrality of the scalar one element 1F with
respect to scalar multiplication. Some further properties of vector spaces are
given in the following Corollary 2.98.
Corollary 2.98 (Derived Vector Space Laws)
Given a vector space
(V, ⊕, ⊗, 0V) over a ﬁeld (F, +, ·, 0F , 1F ) the following holds for all scalars
i ∈F and vectors v ∈V :
0F ⊗v = 0V
(2.135)
i ⊗0V = 0V
(2.136)
The property expressed in Eqn. (2.135) explains the interplay of the scalar
neutral element with vectors, whereas the property expressed in Eqn. (2.136)
explains the interplay of the null vector with scalar values.
Often, we consider vector spaces (V, ⊕, ⊗, 0V ) over a ﬁeld (F, +, ·, 0F , 1F)
in which V is deﬁned as a set of sequences I →F for some I = {1, . . ., n}
or I = N. These are the vectors in the narrow sense. Vectors of the form
(vi)i∈{1,...,n} are called n-dimensional vectors, or just n-vectors for short. In
case V : {1, . . ., n} →F it is usual to consider V also as the n-times Cartesian
product F × . . . × F and to denote it F n as usual. We call n-vectors the ﬁnite
vectors to distinguish them from the inﬁnite vectors of the form (vi)i∈N. In
case of inﬁnite vectors V : N →F we denote V also as F ∞. We might also
start counting n-vectors with zero, also less usual, so that an n-vector has
the form (vi)i∈{0,...,n−1}. Similarly, we also call sequences of the form (vi)i∈ω
inﬁnite vectors.

3
Syntax and Operational Semantics
In this chapter we introduce the probabilistic lambda calculus, which is a
typed, probabilistic lambda calculus with recursion plus an extra construct
for probabilistic choice. In this book we refer to this calculus simply as the
probabilistic lambda calculus, i.e., the fact that the probabilistic lambda cal-
culus is typed and has a recursion operator is taken for granted in this book.
The probabilistic lambda calculus can be considered a minimalistic functional
programming language. We completely specify the calculus, so that it could be
immediately implemented as a working programming language. This means
that we deﬁne both the syntax and the operational semantics of the calculus.
The operational semantics is given in two stages. In the ﬁrst stage, we give a
labeled transition system between terms of the language. On the basis of this
we elaborate a Markov chain semantics of the calculus. For this purpose, we
will use the labeled transition system as a probabilistic matrix and will then
explain reduction probabilities as hitting probabilities in the Markov chain
that exists for this probabilistic matrix. Note that already the ﬁrst stage of
this semantics, i.e., the labeled transition system, is suﬃcient as a complete
speciﬁcation for the implementation of a programming language. However, we
are interested in properties of programs. The purpose of introducing a formal
language is to enable formal reasoning about program properties. Now, it is
the second stage that makes the diﬀerence between simulation and analytical
treatment of program properties. Only with the full Markov chain semantics
we gain access to the important mathematical toolkit that we desire for seman-
tic analysis. We will encounter this, e.g., when we investigate the termination
behavior of the probabilistic lambda calculus in Chap. 4.
We introduce the probabilistic lambda calculus as an extension of the
standard typed lambda calculus. The standard operational semantics of the
typed lambda calculus is given by a transition system. This transition system
is then extended to a labeled transition system. Here the labels carry the
probabilities of probabilistic choices.
© Springer-Verlag Berlin Heidelberg 2017
D. Draheim, Semantics of the Probabilistic Typed Lambda Calculus,  
DOI 10.1007/978-3-642-55198-7_3 
65

66
3 Syntax and Operational Semantics
3.1 Syntax of the Probabilistic Lambda Calculus
3.1.1 Context-Free Syntax
We deﬁne the set of types T by the following grammar:
t = num
|
bool
|
t →t
We use Tg to denote the set of ground types num and bool. Types of the form
t1 →t2 are called higher types.
We assume a countable set Var containing arbitrarily many typed vari-
able symbols for each type t ∈T . As usual, we do not ﬁx a concrete syntax
for variable symbols but simply assume that we have enough of them, e.g.,
xt, yt, zt or vt, v′′
t , v′′′
t , . . . for each type t ∈T . Furthermore, as usual, we feel
free to omit the type subscript of variable symbols wherever the type can be
implicitly derived from the typing rules in Sect. 3.1.2. We deﬁne a set Cnum
of constant symbols ni for each natural number i ∈N0. In example terms,
we feel free to use the usual number symbols as these constants. We deﬁne
a set Cbool of constant symbols ˙t and ˙f to denote the corresponding truth
constants. We deﬁne the set of constants C as the union of Cnum and Cbool.
We deﬁne the set of lambda terms Λ according to the following grammar:
M = xt ∈Var |
(3.1)
ni ∈Cnum | + 1(M) | −1(M) |
(3.2)
˙t | ˙f | 0?(M) |
(3.3)
if M then M else M |
(3.4)
λxt.M | MM | μM
(3.5)
M = M|M
(3.6)
Terms of the form +1(M) and −1(M) stand for the addition resp. substraction
of one, whereas 0?(M) is a test for zero. Terms of the form if M thenN1elseN2
are called conditional expressions or conditionals for short. Throughout the
book we also use if (M, N1, N2) as an alternative concrete syntax for condi-
tionals. The term M in a conditional expression is called its condition, and the
terms N1 and N2 are called its clauses, i.e., its left resp. right clause. Terms of
the form MN are called applications. The term M in an application is called
the function and the term N is called the parameter of the application. Terms
of the form λv.M are called lambda abstractions or abstractions for short.
An abstraction always has a higher type, i.e., it always deﬁnes a function.
Whenever we refer to an abstraction λv.M as a function, it is usual to call
the term M its function body or body for short. Terms of the form μM are
called μ-recursions or recursions, where each μ is called the recursion opera-
tor, or μ-operator. Furthermore, the μ-operator is sometimes also called the
ﬁxed-point operator. However, we prefer to use the term ﬁxed-point operator
rather for the denotational counter part Φ of the μ-operator; see Def. 2.80.

3.1 Syntax of the Probabilistic Lambda Calculus
67
Last but not least, terms of the form M|N are called probabilistic choices
and the corresponding operator | is called the choice operator. Please, just as
a caution, note that we use the vertical bar | in Eqns. (3.1) through (3.5) as
the usual separator for the several grammatical rules. However, in Eqn. (3.6)
the vertical bar in M|M is our syntax for the choice operator and not a rule
separator. The choice to use M|N to denote probabilistic choice is an arbitrary
choice. Other options that might be be found in the literature are, e.g., M ⊕N
or the fat bar notation M[]N.
The probabilistic lambda calculus Λ is the language speciﬁed by the whole
set of rules in Eqns. (3.1) through (3.6). The standard typed lambda calculus,
let us denote it by Λ′, is the subset of Λ which is speciﬁed by the Eqns. (3.1)
through (3.5), i.e., the probabilistic lambda calculus is distinguished from the
standard calculus by exactly one extra language construct, the probabilistic
choice, introduced by the rule in Eqn. (3.6). In the sequel, we assume that all
syntactical deﬁnitions that we will give as well as all the syntactical properties
that we discuss for the probabilistic lambda calculus Λ such as free and bound
variables, open and closed terms, ground terms etc. immediately transport to
the standard typed lambda calculus Λ′.
As usual, the grammar given by Eqn. (3.1) ﬀ. is considered an abstract
syntax speciﬁcation. This means that the objects in Λ are actually abstract
syntax trees. As usual, we do not stress that fact any more in the sequel and
simply call the objects in Λ terms. Nevertheless, implicitly we exploit the fact
that our terms are abstract syntax trees heavily in structural inductive proofs
throughout the book. As usual, we use parentheses in concrete term syntax
to indicate the term tree syntax of the abstract syntax. Also, we are allowed
to omit parentheses and can then assume the usual constructor precedences
and ﬁxities. Application binds tighter then λ- and μ-abstraction. Application
also binds tighter then the case construct in its third argument, i.e., we have
if T then N1 else MN equals if T then N1 else (MN). Application associates
to the left, i.e., M0M1M2 should be parsed as (M0M1)M2. Consequently, the
type constructor associates to the right, i.e., t1 →t2 →t3 should be parsed
as t1 →(t2 →t3).
Next, we need to deﬁne precedence and associativity for the choice opera-
tor. The choice constructor binds even tighter than application, and therefore
also binds tighter than λ- and μ-abstraction as well as conditional expressions.
For example, λxs.M1M2|M3 should be parsed as λxs.(M1(M2|M3)). We de-
ﬁne, as an arbitrary choice, that the choice constructor associates to the left,
i.e., L|M|N should be parsed as (L|M)|N. In Corollary 3.8 we will see that
the semantics of the choice constructor is non-associative, and therefore ﬁxing
a precedence rule for the choice constructor matters.
3.1.2 Typing Rules
A lambda term M is well typed and then has type t, denoted by M : t,
according to the following deﬁnition of type derivation:

68
3 Syntax and Operational Semantics
xt ∈Var
xt : t
(3.7)
ni ∈Cnum
ni : num
M : num
+1(M) : num
M : num
−1(M) : num
(3.8)
˙t : bool
˙f : bool
M : num
0?(M) : bool
(3.9)
M : bool
N1 : t
N2 : t
if M then N1 else N2 : t
(3.10)
xt1 ∈Var
M : t2
λxt1.M : t1 →t2
M : t1 →t2
N : t1
MN : t2
(3.11)
M : t →t
μM : t
(3.12)
M : t
N : t
M|N : t
(3.13)
It is usual to deﬁne typing of terms as a type derivation system as given by
Eqn. (3.7) ﬀ; compare, e.g., with [223, 19, 118, 42]. Formally, the so-called
typing rules in Eqn. (3.7) ﬀ. are rule sets that inductively deﬁne the type
relation : ⊆Λ × T ; compare with our discussion of inductive deﬁnitions in
Sect. 2.4 and, in particular, to the discussion of rule-based inductive deﬁnitions
in Sect. 2.4.2. Now, a term M is considered well typed if there exists a type
t ∈T such that M : t. Then, M is said to have type t. Actually, it can be
shown that the type of a term, if it exists, is unique, i.e., that the type relation
is a partial function.
As expressed by the next lemma, each type has a right-associate top-level
structure in terms of a sequence of other types, ﬁnally targeting a basic type.
This canonical structure of types can be exploited in proofs of properties
of terms or types. Here, it allows for a natural induction over the length of
this canonical type structure, which is an alternative to the usual structural
induction over the construction of terms.
Lemma 3.1 (Top-Level Functional Structure of Types)
Each type
t ∈T has the form (tn →(. . . (t2 →(t1 →g))...)) for an n ⩾0, a type ti ∈T
for each 1 ⩽i ⩽n and a ground type g ∈Tg.
Proof. By structural induction over the set of terms T .

In case n = 0 in Lemma 3.1 the type t takes the form g ∈Tg. For n = 1 it
takes the form t →g with t ∈T and g ∈Tg.

3.1 Syntax of the Probabilistic Lambda Calculus
69
Typing Rules and Type Environments
Our typing rules are straightforward; for example, they directly correspond
to the typing rules given in [223]. We just use some other notation than [223]
to denote the rules, which arranges the premise and the conclusion vertically,
separated by a horizontal line. Such notation is common for rule-based induc-
tive deﬁnitions, compare with Sect. 2.4.2, and, actually, it also very common
in the type systems community; compare with [210, 42, 219]. In particular,
we work without so-called type environments. In many texts [118, 42] type
environments are used to give types to variables. In such formalizations, a
type statement has the form Γ ⊢M : t for some type environment Γ, some
term M and some type t, whereas our type statements simply have the form
M : t. In formalizations without type environments we work with a set of
typed variables, which shows in the type subscript notation xt in our calcu-
lus. In a formalization with type environments, we start with a single set of
untyped variables that receive their types from the type environment. There-
fore, a type environment Γ is a set of basic typing tuples of the form x : t.
For example, compare the very basic variable-typing rule Eqn. (3.7) with its
counterpart version based on a type environment, which would look like this:
{x : t} ⊢x : t
(3.14)
Type environments are particularly useful for formalizing more advanced
type system concepts [42, 219] such as polymorphism, type genericity or ex-
istentially quantiﬁed types. Also we use type environment notation on other
occasions, e.g., when we specify type safety for the generative programming
language GENOUPE [178, 90, 91, 92] or when we specify the strongly typed
web service programming language NSP [81, 83]. On other occasions we also
deal without type environments, e.g., in case of the type systems for the web
service type recovery tool JSPICK [87] or the reﬂective constraint language
OCLR [79]. In the current book type environments oﬀer no advantage and
therefore we stay with a formalization that works without type environments.
3.1.3 Closed Terms, Open Terms, Programs and Values
The notions of variables of a term, free and bound variables, closed and open
terms as well as programs are all standard and deﬁned as usual. Given a term
M, we denote the set of its variables by Var(M), the set of its free variables
by Vfree(M) and the set of its bound variables as Vbound(M). We denote the
set of all closed terms by Λ∅and the set of all programs by ΛP . It is the task
of this section to give deﬁnitions of all of these concepts, plus some further
important syntactical concepts such as variable substitution, α-equivalence
and values.
First, in order to ease the deﬁnition of the several syntactical constructs we
introduce a set Ψ of functions on Λ of diﬀerent arity that we call syntactical
constructors or also just constructors for short.

70
3 Syntax and Operational Semantics
Deﬁnition 3.2 (Syntactical Constructors) The set Ψ of syntactical con-
structors consists of the following functions:
ψ+ : Λ →Λ =DEF M →+1(M)
ψ−: Λ →Λ =DEF M →−1(M)
ψ? : Λ →Λ =DEF M →0?(M)
ψif : Λ×Λ×Λ →Λ =DEF ⟨L, M, N⟩→if L then M else N
ψapp : Λ×Λ →Λ =DEF ⟨M, N⟩→MN
ψλ : Λ×Λ →Λ =DEF ⟨v, M⟩→λv.M
ψμ : Λ →Λ =DEF M →μM
ψγ : Λ×Λ →Λ =DEF ⟨M, N⟩→M|N
(3.15)
The constructors Ψ can be exploited to avoid redundancies in the deﬁni-
tion of syntactical properties. Furthermore, we can use constructor notation
also to shorten proofs, because they allow us to apply the same argument
simultaneously to diﬀerent kinds of terms at once; see, e.g., the proof of the
environments-shortening Lemma, i.e., Lemma 5.23. The constructors decom-
pose the set of lambda terms Λ, to be more precise, the set Λ excluding
variables and constants. This means that the images of the constructors are
pairwise disjoint and, furthermore, the union of the images of all construc-
tors includes all terms except variables and constants. This follows from the
grammar of Λ as given by the rules in Eqn. (3.1) ﬀ. and the deﬁnition of Ψ in
Def. 3.2. Each rule in the grammar except those for variables and constants
is uniquely represented by one syntactical constructor in Ψ.
Let us proceed with the deﬁnition of the needed syntactical concepts. We
start with the concept of variables Var(M) of a term M. In case of variables
v ∈Var and constants c ∈C the set of variables of a term is deﬁned as follows:
Var(v) =DEF {v}
(3.16)
Var(c) =DEF ∅
(3.17)
For all other terms, i.e., terms M such that M = ψ(M1, . . . , Mnψ) for some
constructor ψ ∈Ψ and appropriately many terms M1, . . . Mnψ the set of
variables is deﬁned as follows:
Var

ψ(M1, . . . , Mnψ)

=DEF Var(M1) ∪. . . ∪Var(Mnψ)
(3.18)
Let us turn to the concepts of free variables and bound variables of a given
term. In case of variables v ∈Var and constants c ∈C the set of free variables
and the set of bound variables of a term are deﬁned as follows:
Vfree(v) =DEF {v}
(3.19)
Vbound(v) =DEF ∅
(3.20)
Vfree(c) =DEF ∅
(3.21)
Vbound(c) =DEF ∅
(3.22)

3.1 Syntax of the Probabilistic Lambda Calculus
71
For lambda abstractions λv.M the sets of its free variables and its bound
variables are deﬁned as follows:
Vfree(λv.M) ≡DEF Vfree(M)\{v}
(3.23)
Vbound(λv.M) ≡DEF Vbound(M) ∪{v}
(3.24)
For all terms other than variables, constants or lambda abstractions, i.e.,
terms M such that M equals ψ(M1, . . . , Mnψ) for some constructor ψ ̸= ψλ
and appropriately many terms M1, . . . Mnψ the sets of their free variables and
their bound variables are deﬁned as follows:
Vfree

ψ(M1, . . . , Mnψ)

=DEF Vfree(M1) ∪. . . ∪Vfree(Mnψ)
(3.25)
Vbound

ψ(M1, . . . , Mnψ)

=DEF Vbound(M1) ∪. . . ∪Vbound(Mnψ) (3.26)
Now, we are able to deﬁne the notions of closed and open terms. A term M ∈Λ
is a closed term if and only if it contains no free variables, i.e., Vfree(M)= ∅.
Otherwise, it is called an open term. Similarly, the set of closed terms Λ∅and
the set of open terms Λopen are deﬁned as follows:
Λ∅=DEF {M ∈Λ | Vfree(M) = ∅}
(3.27)
Λopen =DEF {M ∈Λ | Vfree(M) ̸= ∅}
(3.28)
Next, we deﬁne the set of ground terms, denoted by Λg, and the set of higher-
typed terms, denoted by Λ→, as follows:
Λg =DEF {M ∈Λ | ∃t ∈Tg . M : t}
(3.29)
Λ→=DEF {M ∈Λ | ∃t, t′ ∈T . M : t →t′}
(3.30)
Next, a program is a closed term of ground type. We denote the set of programs
by ΛP , i.e.,
ΛP =DEF Λ∅∩Λg
(3.31)
Variable Substitution
Next, we turn to the important notion of variable substitution. Substitution
is the essential notion of term rewriting, term rewriting systems and symbolic
computation. Given terms M and N, substitution is about replacing all oc-
currences of a free variable v in term M by the new expression N. We denote
such substitution by the common notation M[v := N]. Given M[v := N] we
also say that v is substituted by N. Diﬀerent forms of variable substitution
exist. What we actually introduce here is a so-called context substitution,
which means that free variables in N might be captured by λ-bindings and

72
3 Syntax and Operational Semantics
this way be turned into bound variables after substitution. Context substi-
tution is a straightforward notion of substitution. Several reﬁned notions of
variable substitution exist that circumvent the variable capture problem. In
this book, we will always only substitute variables with closed terms, so that
we do not run the risk that free variables become captured by substitution;
see also Sect. 3.2.1, where we explain this in more depth. For this reason, we
just stay with context substitution. Also, we just use context substitution,
variable substitution and substitution as synonyms in this book.
For variables v, v′ ∈Var, constants c ∈C and closed terms N ∈Λ∅
substitution is deﬁned as follows:
v[v:=N] ≡DEF N
(3.32)
v[v′ :=N] ≡DEF v
, v ̸= v′
(3.33)
c[v:=N] ≡DEF c
(3.34)
For lambda abstractions of the form λv.M ∈Λ, variables v, v′ ∈Var and
terms N ∈Λ substitution is deﬁned as follows:
λv.M[v:=N] ≡DEF λv.M
(3.35)
λv.M[v′ :=N] ≡DEF λv.

M[v′ :=N]

, v ̸= v′
(3.36)
For all other terms, i.e., terms M such that M = ψ(M1, . . . , Mnψ) for some
constructor ψ ̸= ψλ and appropriately many terms M1, . . . Mnψ substitution
is deﬁned as follows:
ψ(M1, . . . , Mnψ)[v:=N] =DEF ψ(M1[v:=N], . . . , Mnψ[v:=N])
(3.37)
α-Equivalence
For the sake of completeness, we also introduce the notion of α-equivalence.
An understanding of this notion is necessary to follow the discussion on sub-
stitution and the capturing of free variables that we conduct in Sect. 3.2.1.
The α-equivalence relation is intended to compare lambda terms that are
syntactically equal up to renaming of bound variables. It is deﬁned as the
least relation ≡α for which the following holds true for all variables v ∈Var,
constants c ∈C, lambda abstractions λx.M, λy.N, and terms of the form
ψ(M1, . . . , Mnψ), ψ(N1, . . . , Nnψ) for some ψ ̸= ψλ and appropriately many
terms M1, . . . , Mnψ and N1, . . . , Nnψ:
v ≡α v
c ≡α c
(3.38)
λx.M ≡α λy.N iﬀ∃z ̸∈Var(M ∪N) . M[x := z] ≡α N[y := z]
(3.39)
ψ(M1, . . . , Mnψ) ≡α ψ(N1, . . . , Nnψ) iﬀ∀1 ⩽i ⩽nψ . Mi ≡α Ni
(3.40)

3.2 Operational Semantics of the Typed λ-Calculus
73
Values of the Probabilistic Lambda Calculus
Next, we turn to the concept of values. The values of the probabilistic lambda
calculus, denoted by ΛV , are deﬁned as the set consisting of constants and
closed lambda abstractions, i.e.,
ΛV = C ∪{ λv.B | B ∈Λ, Vfree(B) = {v} }
(3.41)
It is immediately clear to name the constants of a programming calculus
as values, because we consider the constants as the result of reductions. A
program run is considered to terminate if it eventually reaches a constant.
However, a broadened notion of values is often needed in the deﬁnition of
concrete evaluation strategies for a programming calculus or programming
language. For example, in a call-by-value operational semantics, we will de-
fer a function application until the argument is reduced to a given notion
of value. Requiring that these values are constants could then exclude some
meaningful programs from terminating. The values of the call-by-value evalu-
ation strategy for the standard typed lambda calculus are exactly as deﬁned
here, i.e., constants plus lambda abstractions. In this book we deal with call-
by-name operational semantics only; please also compare with the discussion
on that in Sect. 3.2. Therefore, we do not need a notion of values in the deﬁni-
tion of the operational semantics. Nevertheless, the notion of values as given
in Eqn. (3.41) is crucial for us. We need it in the analysis of denotational
semantics and its correspondence to operational semantics in Sect. 5.3. More
concretely, we need values to deﬁne a big-step evaluation semantics for our
calculus; compare with Lemma 5.30.
3.2 Operational Semantics of the Typed λ-Calculus
Before we turn to the operational semantics of the probabilistic lambda calcu-
lus Λ in Sect. 3.3 we ﬁrst digress with an investigation of the standard typed
lambda calculus Λ′. We give an operational semantics in the standard way;
see, e.g., [223], as a so-called reduction relation between the closed terms of
Λ′. We do so, as usual, by specifying an immediate reduction relation that
is then turned into the desired reduction relation. For the proceedings of the
book it is helpful to have the operational semantics of the standard typed
lambda calculus to hand, for instructive purposes and, even more important,
for better comparability. The section can be skipped on ﬁrst reading without
loss, if the reader is already familiar with the typed lambda calculus and its
operational semantics.
The so-called immediate reduction relation is introduced as a relation be-
tween the closed lambda terms, i.e.,
→⊆Λ′
∅× Λ′
∅
(3.42)

74
3 Syntax and Operational Semantics
The immediate reduction relation is deﬁned inductively by the following
sets of rules:
i)
M →M ′
+1(M) →+1(M ′)
ii)
i ⩾0
+1(ni) →n(i+1)
(3.43)
i)
M →M ′
−1(M) →−1(M ′)
ii)
i ⩾1
−1(ni) →n(i−1)
iii)−1(n0) →n0
(3.44)
i)
M →M ′
0?(M) →0?(M ′)
ii)0?(n0) →˙t
iii)
i ⩾1
0?(ni) →˙f
(3.45)
M →M ′
if (M, N ′, N ′′) →if (M ′, N ′, N ′′)
(3.46)
i)if (˙t, N ′, N ′′) →N ′
ii)
if ( ˙f, N ′, N ′′) →N ′′
(3.47)
i)
M →M ′
MN →M ′N
ii)(λv.B)N →B[v := N]
(3.48)
μM →M(μM)
(3.49)
Now, the reduction relation
⋆→is deﬁned as the reﬂexive and transitive
closure of the immediate reduction relation →. It turns out that reduction to
constants is uniquely given. This means that given a program M ∈Λ′ and a
constant c ∈C such that M
⋆→c we have that c is uniquely determined, i.e.,
there is no other constant c′ ∈C with c′ ̸= c and M
⋆→c′. Based on that, the
evaluation semantics of the standard typed lambda calculus can be deﬁned as
a partial function that assigns to each program M ∈Λ′
P the uniquely given
constant c to which it can be reduced via M
⋆→c, given that this c exists at
all. The evaluation semantics necessarily is a partial function, because we also
have non-terminating programs in Λ′
P . A non-terminating program in Λ′
P is
a program that never reaches a constant.
Call-by-Name Operational Semantics
The operational semantics as speciﬁed by the rules (3.43) ﬀ. is a call-by-name
semantics. This shows in the reduction rule Eqn. (3.48-ii). If a reduction has
reached an intermediate term (λv.B)N the term N is immediately, without
further reduction, substituted as an actual parameter into the function body
B. This is exactly what call-by-name is about. Other evaluation strategies are
possible [220, 69]. With call-by-value semantics substitution (λv.B)N of the
argument is deferred until the argument has been reduced further to some
value, i.e., (λv.B)N
⋆→(λv.B)N ′ →B[v := N ′] for some value N ′ ∈Λ′
V ,
where Λ′
V stands, as usual, for the set consisting of all constants C plus all
lambda abstractions.

3.2 Operational Semantics of the Typed λ-Calculus
75
3.2.1 The Variable Capture Problem
The deﬁnition of the operational semantics by the rules (3.43) ﬀ. is based on
a concept of variable substitution M[v := N]; see the rule set (3.48-ii). See
how we have deﬁned this syntactical concept in Eqn. (3.32) ﬀ. The substi-
tution we use is a very general form of substitution, i.e., a so-called context
substitution. This means that free variables of an argument term may become
captured underneath a lambda binding after substitution, which would change
the intended semantics of the term. The point is that this fact will never pose
a problem in our operational semantics. In the operational semantics of the
typed lambda calculus, the only potentially problematic rule set is the rule
set (3.48-ii) which reveals a redex of the form (λv.B)N. However, the argu-
ment N cannot have a free variable, because the reduction relation is deﬁned
for closed terms only. Now, given that the whole application term (λv.B)N is
closed, we also know that the argument term N is closed; compare with the
deﬁnition of free variables in Eqn. (3.20) ﬀ.
In general, reductions for λ-calculi are deﬁned for all terms, not only for
closed terms. Furthermore, it is usual to consider transition relations that
are compatible closures. A motivation for using a transition relation that is a
compatible closure is to avoid prescribing reduction strategies from the outset
and therefore enable the study of diﬀerent reduction strategies. For an expla-
nation of compatible closure, see also [18], §3.1.1. Compatible closure means
that a notion of reduction such as the β-reduction (λv.M) →M[x := N] is
transferred to arbitrary sub-terms of any other term, i.e., that given terms M
and N we have that M →N implies C[M] →C[N]. Here, C[M] is a usual
notation that stands for a context substitution without explicitly mentioning
a variable as in the notation C[v := M]. Rather, the term C[_] is called a
context with a so-called hole [_]. Let us have a look at an example in which
a variable capture problem might occur if a plain context substitution is used
without further arrangements. Let us consider the term (λx.(λy.λx.y)x) 0 1
Now, with the reduction system as established with call-by-name operational
semantics, it is possible to reduce this term as follows:
(λx.(λy.λx.y)x) 0 1
→(λy.λx.y) 0 1
→(λx.0)1
→0
(3.50)
Now, if we allow arbitrary β-reduction on arbitrary sub-terms including open
terms based on context substitution, the following other reduction also be-
comes possible:
(λx.(λy.λx.y)x) 0 1
→(λx.λx.x) 0 1
→(λx.x)1
→1
(3.51)

76
3 Syntax and Operational Semantics
The problem shows in the fact that the two computations in Eqns. (3.50)
and (3.51) yield diﬀerent outcomes, i.e., 0 and 1. Here, the outcome 1 must
be considered spurious, which shows in the unintended reduction of the sub-
term (λy.λx.y)x to the term λx.x. There exist diﬀerent approaches to deal
with the variable capture problem. A typical approach is to introduce an im-
proved concept of variable substitution that avoids the capture of variables
from the outset. This can be achieved by adding an appropriate side condition
Vfree(N) ∩Vbound(M) = ∅to the relevant clause in the deﬁnition of substi-
tution, compare with Eqn. (3.36), and then allow for renaming of variables,
i.e., the introduction of fresh variables during substitution. Technically, this
can be accompanied by a factorization of the set of terms along α-equivalence
as, e.g., in [118]. Another technical option is to establish a variable-name-free
apparatus like the de Bruijn notation [65].
In this book we are not concerned with the variable capture problem and
therefore stay with context substitution. This eases argumentations and for-
mal proofs, in which we do not have to care about extra syntactical properties
and technical machinery for variable substitution.
3.3 The Probabilistic Operational Semantics
3.3.1 The One-Step Semantics
We introduce the call-by-name one-step semantics to deﬁne the probabilities
with which immediate transitions between closed terms are possible. We use
M
i−→N to denote that a transition from M to N is possible with probability i.
In that sense, the one-step semantics can be considered as a labeled transition
system. The call-by-name one-step semantics is introduced as a relation:
→⊆Λ∅× Λ∅× {0, 0.5, 1}
(3.52)
Then, we introduce M
i−→N as a notation for a predicate on triples of the
one-step semantics in the following way:
M
i−→N ≡DEF

⟨M, N, i⟩∈→

(3.53)
In due course, with Lemma 3.3, it will turn out that the one-step se-
mantics is a total function, i.e., →:

Λ∅× Λ∅−→{0, 0.5, 1}

. For the time
being, we treat the one-step semantics as a relation as deﬁned in Eqn. (3.52).
Now, we deﬁne the one-step semantics inductively by the rule sets given in
Eqns. (3.54) through (3.64) for all closed lambda terms M, M ′, N1, N2, N ′.
We have grouped the rule sets into several blocks. The ﬁrst two blocks deal
with term constructs that make up usual typed lambda calculi with recursion.
We start with a block of rule sets needed for basic operators and conditional
expressions:

3.3 The Probabilistic Operational Semantics
77
i)M ̸∈C
M
i→M ′
+1(M)
i→+1(M ′)
ii)
i ⩾0
+1(ni)
1→n(i+1)
(3.54)
i)M ̸∈C
M
i→M ′
−1(M)
i→−1(M ′)
ii)
i ⩾1
−1(ni)
1→n(i−1)
iii)
−1(n0)
1→n0
(3.55)
i)M ̸∈C
M
i→M ′
0?(M)
i→0?(M ′)
ii)
0?(n0)
1→˙t
iii)
i ⩾1
0?(ni)
1→˙f
(3.56)
M ̸∈C
M
i→M ′
if (M, N ′, N ′′)
i−→if (M ′, N ′, N ′′)
(3.57)
i)
if (˙t, N ′, N ′′)
1−→N ′
ii)
if ( ˙f, N ′, N ′′)
1−→N ′′
(3.58)
The next three rules deal with the semantics of function application and re-
cursion:
i)M ̸= (λv.B)
M
i→M ′
MN
i→M ′N
ii)
(λv.B)N
1→B[v := N]
(3.59)
μM
1→M(μM)
(3.60)
The third block of derivation rules deals with the semantics of the choice
operator that is the key ingredient of the probabilistic lambda calculus:
i)
M ̸= N
M|N
0.5
−−→M
ii)
M ̸= N
M|N
0.5
−−→N
iii)
M|M
1−→M
(3.61)
The next two blocks of derivation rules are needed to make the one-step
semantics a total function. Actually, the derivation rules ensure that the one-
step semantics forms a probabilistic matrix. This way, the one-step semantics
can serve as the basis of a Markov chain semantics. The following two rules
deal with transition probabilities for the values:
i) M ∈C
M
1→M
ii)
λv.B
1→λv.B
(3.62)
The next two rules introduce the necessary null transition probabilities for all
relevant terms:
M
1→N
N ′ ̸= N
M
0→N ′
(3.63)
M
0.5
−−→N1
M
0.5
−−→N2
N ′ ̸= N1
N ′ ̸= N2
M
0→N ′
(3.64)

78
3 Syntax and Operational Semantics
With rule (3.62-i) we ensure a direct transition M
1−→M between each
constant M and itself. This makes sense. It means that we will model a ter-
minating computation run as an inﬁnite process instance that is absorbed
behind the hit of a constant. This is a perfectly adequate model of the sce-
nario, because from an observer’s viewpoint inﬁnite process instances that are
absorbed behind constants can be considered conceptually or abstractly ﬁnite,
in particular, because the hit of a constant can be run-time decided by each
computational engine that is used to run our programs.
For any two terms M and N there exists exactly one number i such that
M
i−→N belongs to the one-step semantics. In the standard typed lambda
calculus, impossibility of a reduction between two terms M and N simply
shows in the fact, that there is no tuple M −→N in the immediate reduction
relation; compare with Sect. 3.2. In the probabilistic lambda calculus, the
impossibility of a reduction is turned into a zero percent probability.
Now, the extra one-step reductions introduced by (3.62) through (3.64)
come at a price, i.e., that we need to introduce further side conditions into
the premises of rule sets as compared to the standard typed lambda calculus.
Compare, as an example, rule (3.54-i) and its corresponding rule (3.43-i). In
rule (3.54-i) we must add the extra side condition M ̸∈C. Without this extra
side condition we would be able to derive +1(n0)
1−→+1(n0) via rules (3.62-i)
and (3.54-i), which is unwanted as an immediate reduction. Also note that we
already have +1(n0)
1−→n1 via rule (3.54-ii) and therefore +1(n0)
0−→+1(n0)
via (3.63), which is completely adequate. To see this, you might also want to
have a look at Lemma 5.48, which is a reﬁnement of Lemma 3.3 and which,
amongst other things, characterizes the one step-semantics as follows: for each
closed term P there either exists a closed term P ′ so that P
1−→P ′ and P
0−→P ′′
for all P ′′ ̸= P ′ or otherwise there exist closed terms P ′ and P ′′ so that
P ′ ̸= P ′′, P
0.5
−−→P ′ and P
0.5
−−→P ′′ and P
0−→P ′′′ for all P ′′′ with P ′′′ ̸= P ′
and P ′′′ ̸= P ′′.
Lemma 3.3 (The One-Step Semantics is a Function) The one-step se-
mantics is a total function on pairs of closed terms →:(Λ∅× Λ∅−→{0, 0.5, 1})
that fulﬁlls the equation Eqn. (3.65) for all X, X′ ∈Λ∅, where X →X′ is used
to denote →(X, X′).
Proof. We need to show that the relation →: Λ∅×Λ∅×{0, 0.5, 1} is right-unique
and left-total in Λ∅× Λ∅. This can be shown by a complete case distinction
for all pairs of closed terms ⟨X, X′⟩in Λ∅× Λ∅. It is possible to structure the
complete case distinction along the possible cases of syntax construction of
the ﬁrst function argument X of ⟨X, X′⟩. We only show one case that already
suﬃces to demonstrate how this works, i.e., the case of constants. All the
other cases of syntactical construction can be proven following the same proof
pattern.

3.3 The Probabilistic Operational Semantics
79
X →X′ =
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
M →M ′ , M ̸∈C, X =+1(M), X′ =+1(M ′)
(i)
1
, X =+1(ni), X′ =n(i+1)
(ii)
M →M ′ , M ̸∈C, X =−1(M), X′ =−1(M ′)
(iii)
1
, X =−1(ni), X′ =n(i−1), i⩾1
(iv)
1
, X =−1(n0), X′ =n0
M →M ′ , M ̸∈C, X =0?(M), X′ =0?(M ′)
(vi)
1
, X =0?(n0), X′ = ˙t
(vii)
1
, X =0?(ni), X′ = ˙f, i⩾1
(viii)
M →M ′ , M ̸∈C, X=if (M, N ′, N ′′), X′=if (M ′, N ′, N ′′)
(ix)
1
, X = if (˙t, N ′, N ′′), X′ =N ′
(x)
1
, X = if ( ˙f, N ′, N ′′), X′ =N ′′
(xi)
M →M ′ , M ̸=(λv.B), X =MN, X =M ′N
(xii)
1
, X =(λv.B)N, X′ =B[v := N]
(xiii)
1
, X =μM, X′ =M(μM)
(xiv)
0.5
, M ̸=N, X =M|N, X′ =M
(xv)
0.5
, M ̸=N, X =M|N, X′ =N
(xvi)
1
, X = M|M, X′ = M
(xvii)
1
, X ∈C, X =X′
(xviii)
1
, X =λv.B, X =X′
(xix)
0
, else
(xx)
(3.65)
In Case of X ∈C: In case X is a constant we can distinguish two cases,
i.e., the case that X = X′ and the case that X ̸= X′. Let us consider the case
that X = X′. We start with the observation that the rule set Eqn. (3.62-i)
contains the rule ∅⊢⟨X, X, 1⟩. Now, due to the deﬁnition of →we know
that →is closed under the rule ∅⊢⟨X, X, 1⟩and therefore ⟨X, X, 1⟩∈→.
Now, we need to prove that ⟨X, X, 0⟩̸∈→and ⟨X, X, 0.5⟩̸∈→. We prove
that ⟨X, X, 0⟩̸∈→only. Let us consider the set →\⟨X, X, 0⟩. We observe that
→\⟨X, X, 0⟩is closed under the complete collection of rule sets Eqns. (3.54)
through (3.64). This can be understood by walking through all of these rule
sets and checking that none of the contained rules requires ⟨X, X, 0⟩∈→.
Therefore, actually we know that ⟨X, X, 0⟩̸∈→, because ⟨X, X, 0⟩∈→would

80
3 Syntax and Operational Semantics
contradict that fact that →is the least relation that is closed under these rule
sets.

Note that in Lemma 3.3 we have used and, henceforth, we will use M →N
to denote the result of applying the one-step semantics as a function to a pair
of given closed terms M and N, i.e., we deﬁne
(M →N) =DEF →(M, N)
(3.66)
This means that we use M →N to denote the uniquely given probability
of the immediate transition from M to N, i.e., we have that
(M →N) = i
iﬀ
M
i−→N
(3.67)
Similarly, we use M →N to denote the matrix element in the M-th
row and N-th column instead of the usual notation →MN. As expressed by
Corollary 3.4 it turns out that the one-step semantics forms a probabilistic
matrix.
Corollary 3.4 (Probabilistic Matrix) The one-step semantics forms a
probabilistic matrix, i.e., for each closed lambda term M we have
 
N∈Λ∅
M →N

= 1
(3.68)
Proof. The Lemma follows immediately from Lemma 3.3 by a structural in-
duction over term tuples M and N. In particular, each row contains either
exactly one element having value 1 or two elements with both having value
0.5, whereas all other elements are zero.

3.3.2 Markov Chain Semantics
Now, based on Corollary 2.20 and Corollary 3.4 we can assume the existence of
a Markov chain S = (Sn)n⩾0 with the deﬁned one-step semantics as transition
matrix, i.e.,
S = M(→)
(3.69)
Each random variable Sn models the probabilities that a reduction reaches
given terms after n steps based on the initial distribution ι. Note that the
concrete initial distribution ι is not relevant for our semantics. It is determined
by the arbitrarily choosen, but ﬁxed Markov chain M(→) and will factor out
in the deﬁnition of reduction probabilities based on hitting probabilities.
Henceforth, we use S to denote the Markov chain M(→). Nevertheless, we
feel free to switch between the usage of S and M(→) in the sequel. Typically,
will use M(→) whenever we want to bring to mind the construction aspect of
the Markov chain semantics. We say that S = M(→) is the reduction chain of

3.3 The Probabilistic Operational Semantics
81
the probabilistic lambda calculus. We also say that S = M(→) is the Markov
chain, or even that it is the Markov chain semantics of the probabilistic lambda
calculus.
Now, we will exploit the notion of hitting probability given in Def. 2.23
to deﬁne the reduction probability M ⇒N. The reduction probability is the
central notion of the operational semantics. The reduction probability M ⇒N
is the probability that the reduction of a term M ever hits the term N, i.e.,
that the Markov chain S ever hits N conditional on S0 = M.
Deﬁnition 3.5 (Reduction Probability) Given closed terms M and N we
deﬁne the reduction probability M ⇒N as follows:
M ⇒N
=DEF
η M(→)⟨M, N⟩
(3.70)
Given terms M and N, we also say that M reduces to N with probability
M ⇒N. As usual, we are particularly interested in programs, i.e., closed
ground terms. Consequently, we are particularly interested in reduction prob-
abilities M ⇒c from programs M to constants c ∈C. We say M evaluates to
c with probability M ⇒c in these cases. Also, we call the reduction proba-
bility M ⇒c an evaluation probability in such a case. Furthermore, we speak
of the evaluation semantics of a program. Given a program M, its evaluation
semantics is the function that assigns the respective evaluation probability to
each constant.
Deﬁnition 3.6 (Evaluation Semantics) Given a program M, its evalua-
tion semantics M ⇒_ : C →[0, 1] is naturally given by c ∈C →(M ⇒c).
There might be several diﬀerent possibilities to construct an operational se-
mantics for the probabilistic lambda calculus and the Markov chain semantics
is one possibility, however, in this book we prefer to use operational semantics
and Markov chain semantics as synonyms. The transition matrix M
i−→N,
the Markov chain S = M(→) and the reduction probability M ⇒N are the
essential ingredients of the Markov chain semantics.
Although it is fair to say that the Markov chain semantics is a typical op-
erational semantics, operational semantics is a more general notion. It stands
for a certain style of semantics that is distinguished from other styles of se-
mantics such as axiomatic semantics or denotational semantics. It is typical
that an operational semantics is close to operational concepts such as pro-
gram execution, program reduction or program transformation. However, we
are not restricted in the range of operational phenomena that we want to
study. Particularly interesting operational aspects are found in the ﬁelds of
algorithmic complexity and termination behavior. For example, based on the
Markov chain semantics, it is possible to deﬁne the operational concept of
mean reduction length. The mean reduction length yields the average number
of steps ∅(M ⇒N) needed to reduce a program M to another program N.

82
3 Syntax and Operational Semantics
Deﬁnition 3.7 (Mean Reduction Length) Given closed terms M and N
we deﬁne the mean reduction length ∅(M ⇒N) of the reduction from M to
N as follows:
∅(M ⇒N) = |η M(→)⟨M, N⟩|
(3.71)
See how ∅(M ⇒N) is deﬁned as the expected value of steps needed to
reach N from M by Eqn. (3.71); see also the deﬁnition of mean hitting time in
Def. 2.32. Programs that are equal with respect to their evaluation semantics
might nevertheless be diﬀerent with respect to other operational aspects. We
will discuss this further in the next chapter on termination behavior.
Given the Markov chain semantics, we see that the choice operator is non-
associative, i.e., in general we have that (L|M)|N ⇒c ̸= L|(M|N)⇒c.
Corollary 3.8 (Non-Associativity of the Choice Operator) The eval-
uation semantics of the choice operator is non-associative.
Proof. Take the programs Ml = (1|2)|3 and Mr = 1|(2|3) as a counter-
example. On the one hand we have that (Ml ⇒1) = 0.25, (Ml ⇒2) = 0.25
and (Ml ⇒3) = 0.5. On the other hand we have that (Mr ⇒1)=0.5,
(Mr ⇒2)=0.25 and (Mr ⇒3)=0.25.

3.3.3 An Example Probabilistic Program
Let us see how the operational semantics works for an example term. Let us
consider the following term m:
m =DEF μλf.λx.( x | f(+1(x)) )
(3.72)
The term m has the functional type num →num. Let us see what happens
it m is applied to one of the number constants ni. You can easily check the
following. For each j ⩾i, the term m ni evaluates to the constant nj with
probability 0.51+j−i, whereas for each j < i, it evaluates to the constant nj
with probability zero, i.e.,
m ni ⇒nj =

0
, j < i
0.51+j−i
, j ⩾i
(3.73)
For example, consider the application of m to the ﬁrst three numbers n0,
n1 and n2, which we denote by their usual number symbols in the example:
(m 0 ⇒0) = 0.5
(m 1 ⇒0) = 0
(m 2 ⇒0) = 0
(m 0 ⇒1) = 0.25
(m 1 ⇒1) = 0.5
(m 2 ⇒1) = 0
(m 0 ⇒2) = 0.125
(m 1 ⇒2) = 0.25
(m 2 ⇒2) = 0.5
(m 0 ⇒3) = 0.0625
(m 1 ⇒3) = 0.125
(m 2 ⇒3) = 0.25
(m 0 ⇒4) = 0.03125
(m 1 ⇒4) = 0.0625
(m 2 ⇒4) = 0.125
· · ·
· · ·
· · ·

3.3 The Probabilistic Operational Semantics
83
It is interesting to have a look at the termination behavior of programs of
the form m ni. The probability that a program m ni hits any of the number
constants sums up to one as you can see in the following equation for any
arbitrary but ﬁxed ni:
ηS⟨m ni, C⟩=
∞

j=i
m ni ⇒nj =
∞

j=i
0.51+j−i =
∞

j=1
0.5j = 1
(3.74)
Later, in Chap. 4, we will call the probability that a program ever reaches
a constant the termination degree of the program; compare with Def. 4.1. We
will see how to exploit linear algebra to argue about the termination degree
of programs.
Of course, we can apply m not only to constants but to arbitrary terms.
Let us consider what happens if we apply it to the term n0|n1. Here, the
probability that m(n0|n1) reduces to any of the number constants nj equals
the sum of 0.5 · (m n0 ⇒nj) and 0.5 · (m n1 ⇒nj), i.e., we have:
(m (0|1) ⇒0) = 0.25
(m (0|1) ⇒1) = 0.375
(m (0|1) ⇒2) = 0.1875
(m (0|1) ⇒3) = 0.09375
· · ·
Now, let us analyze the probability m M ⇒nj in its most general form,
i.e., for arbitrary terms M and number constants nj. In general, we have the
following:
(m M ⇒nj) =
j

i=0
0.51+i · (M ⇒nj−i)
(3.75)
Actually, via a couple of steps, it can be seen that the probabilities for
the special case n0|n1 above can be derived as instances of Eqn. (3.75). Now,
let us explain how to come up with such a result as Eqn. (3.75). Note that
the following is an informal argumentation, i.e., not a proof. Argumentations
like the one conducted here can be turned into formal proofs by establishing
structural inductions or exploiting linear algebra. First, we can conduct a one-
step decomposition of hitting probabilities as described by Eqn. (2.35). Now,
due to the deﬁnition of m in Eqn. (3.72) we can see that (m M ⇒nj) equals
the following:
0.5 · (M ⇒nj) + 0.5 · (m(+1(M)) ⇒nj)
(3.76)
Now, we can unfold Eqn. (3.76) further, ad inﬁnitum, so that we can see that
(m M ⇒nj) equals the following for each arbitrary number k:

84
3 Syntax and Operational Semantics

k

i=0
0.51+i · +1i(M) ⇒nj

+

0.5k+1 · m(+1k+1(M)) ⇒nj

(3.77)
Note, that terms of the form +1i(M) in Eqn. (3.77) are an ad hoc, informal
notation. We use it to denote the i-times syntactical application of +1 to the
term (m M), i.e., +1(+1(+1(...mM))) i times. Next, we can exploit the rule
sets of (3.54) for addition terms +1(N) in our argumentation. First, it can be
understood by (3.54-ii), i times, that a term of the form +1i(nj−i) leads to
the following one-step transitions:
+1i(nj−i)
1−→+1i−1(nj−i+1)
1−→+1i−2(nj−i+2)
1−→· · ·
1−→+1(nj−1)
1−→nj
(3.78)
Note that the probability of each of the transitions in Eqn. (3.78) is 100 per
cent. Similarly, it can be understood that for all other nk ̸= nj−i the term
+1i(nk) must lead to transitions of the following form:
+1i(nk)
1−→+1i−1(nk+1)
1−→· · ·
1−→nk′
0−→nj
(3.79)
Have a look at the last step in Eqn. (3.79). Due to k ̸= j −i we know that
k′ ̸= j −1. Therefore, due to the rule scheme (3.63) we know that nk′
0−→nj,
i.e., there is a zero per cent probability to step from nk′ to nj. Altogether,
based on Eqns. (3.78) and (3.79) we know that (+1i(nj−i) ⇒nj) = 1 and
(+1i(nk) ⇒nj) = 0 for all nk ̸= nj−i. Based on that and the rule set (3.54-i) it
can be understood that for all terms N ∈ΛP we have the following evaluation
semantics of the n-fold addition operator:
+1i(N) ⇒nj =

N ⇒nj−i
, i ⩽j
0
, else
(3.80)
Once more note that all of the argumentation given here is informal. We do
not use formal inductions. Also we do not aim to make explicit the complete
case distinctions. This will change in formal proofs, e.g., when we investigate
the semantic correspondence between operational semantics and denotational
semantics in Sect. 5.3. Now, given Eqn. (3.80) we have that Eqn. (3.77) equals

k

i=0
0.51+i · M ⇒nj−i

+

0.5k+1 · +1k+1(m M) ⇒nj

(3.81)
Now, given the case distinction in Eqn. (3.80), we can further narrow the range
of the stepping index i in Eqn. (3.81) to 0 ⩽i ⩽j, which yields Eqn. (3.75).
3.3.4 Remarks On Multiset Semantics
In the deﬁnition of the one-step pre-semantics for the nondeterministic choice,
i.e., for terms of the form M|N, we have explicitly distinguished between the

3.3 The Probabilistic Operational Semantics
85
case M ̸= N in rules (3.61-i) and (3.61-ii) and the case M = N in rule
(3.61-iii). Intuitively, it is an option not to distinguish between these two
cases in the deﬁnition of the one-step pre-semantics and to replace all of the
rules in Eqn. (3.61) simply by
(i)
M|N
0.5
−−→M
(ii)
M|N
0.5
−−→N
(3.82)
However, the formalization given with Eqn. (3.82) would only work with
a non-standard understanding of inference rules because in case M = N not
one but two labeled transitions of the form
0.5
−−→would be introduced between
M|M and M. For this purpose we would have to use a non-standard deﬁni-
tion of labeled transition systems that allows for multiple transitions between
nodes, e.g., by exploiting the notion of multisets [29]. However, ultimately we
are interested in exploiting the one-step semantics as a probability matrix.
Therefore, we would have to ﬂatten multiple transitions of the form
0.5
−−→to
a single matix entry of value 1 between terms of the form M|M and M. For
these reasons, we have chosen the formalization given by Eqn. (3.61). The
given formalization is a completely adequate description of the intended oper-
ational semantics, because if a reduction has reached a term of the form M|M
there is one possible and at the same time necessary next reduction to M.
3.3.5 Remarks On Choices with Arbitrary Probabilities
Note that the probabilistic choice M|N as deﬁned by Eqn. (3.61) has a ﬁxed,
somehow arbitrary probability of 0.5 for each possible choice. It would be
an alternative to introduce a general choice construct of the form Mi|N for
0 ⩽i ⩽1 that allows for the speciﬁcation of an arbitrary probability for
concrete choices by the modeler with appropriate rules such as
(i)
M ̸= N
Mi|N
i→M
(ii)
M ̸= N
Mi|N
1−i
−→N
(iii)
Mi|M
1→M
(3.83)
Yet another possibility would be to work with an even more general choice
construct Mi|jN with 0 ⩽i + j ⩽1 that allows for the speciﬁcation of a
probability for each direction of the choice with appropriate rules such as
(i)
M ̸= N
Mi|jN
i→M
(ii)
M ̸= N
Mi|jN
j→N
(iii)
Mi|jM
i+j
−→M
(3.84)
The point is that more general choice constructs such as Eqns. (3.83) and
(3.84) do not add much to the expressive power. This means that the choice
construct M|N with ﬁxed probability is able to simulate such more general
choice constructs. In [139] it has been shown that a probabilistic choice with
ﬁxed probability is suﬃcient to implement a generalized probabilistic choice.

86
3 Syntax and Operational Semantics
The algorithm in [139] is also used in [185] where it is turned into an imperative
version and proven correct with the axiomatic reasoning framework of [185].
Let us sketch a program M i|Λ N that is intended to simulate the program
Mi|N from Eqn. (3.83) as follows:
M i|Λ N ≡( μλC.λp.λd.
if (p = i) then N else
if (p + 0.5d ⩽i) then
M | (C (p + 0.5d) (d + 1))
else
N | (C p (d + 1))
) 0 1
(3.85)
First, it has to be noted that M i|Λ N is not yet a term of Λ, it is rather
a sketch. This is so, because we make use of rational number arithmetic in
M i|Λ N as if it were built into Λ. For example, we have a constant 0.5 and the
operation 0.5d, i.e., a power function. But this should not concern us too much
here. Obviously, it would be possible to extend the probabilistic lambda cal-
culus with appropriate types, variables, constants and operators. However, it
is also possible to represent rational arithmetic by appropriate terms without
extending Λ. For example, we can represent each rational number q = n/d
as a term q =DEF λs.if (s, n, d). See how q packs the numerator n and the
denominator d together and allows access to them via the selector s. Now,
appropriate operations can be programmed. For example, addition of rational
numbers can be programmed as follows:
plusQ ≡λx.λy.λs.if (s,
(plusN(multN (x ˙t)(y ˙f))(multN (x ˙f)(y ˙t))),
(multN (x ˙f)(y ˙f))
)
(3.86)
The operation plusQ in Eqn. (3.86) is again only a sketch, because it relies
on the existence of properly programmed operators for multiplication and
addition of natural numbers. Fortunately, natural numbers are already repre-
sented in Λ by the type Cnum. We do not want to delve into this further here,
we just wanted to show that it is, in principle, possible to represent rational
number arithmetic in Λ as is. Therefore, we can proceed with our discussion
of M i|Λ N in Eqn. (3.85).
See, how M i|Λ N works. It realizes an interval nesting around the targeted
probability i. The program M i|Λ N recursively calls itself and upon each
recursive call it might give M or N the chance to execute. In d the program
keeps track of the number of recursive calls already executed, i.e., the recursion
depth. In p the program keeps track of the chance already granted to term M
during the course of the execution. Think of p as an accumulated probability.
Now, it is p that steers which term, i.e., either M or N, gains the chance to
execute. It can be shown that the probability of M i|Λ N ending up in M is

3.3 The Probabilistic Operational Semantics
87
i, whereas the probability of M i|Λ N ending up in N is 1 −i. This is exactly
what we wanted to achieve with M i|Λ N. In order to prove a program like
M i|Λ N correct, the apparatus of the developed Markov chain semantics can
be exploited.
Albeit it is possible to simulate Mi|N by M i|Λ N, the two programs are
still diﬀerent with respect to other operational aspects such as run-time be-
havior and termination behavior. We have not yet developed the appropriate
terminology and apparatus for the systematic investigation of such aspects
and refer to Chap. 4 for this purpose.
In Eqn. (3.83) we have assumed that the probability speciﬁcation is an
arbitrary but ﬁxed number 0 ⩽i ⩽1. A further interesting idea would be to
allow terms as probability speciﬁcations i. This way, it would be possible to
let probabilities of choice evolve dynamically. Again the operational semantics
for such a programming language construct can be given in a straightforward
manner. We just need some further reduction rules like these:
(i)ci ∈C
M ̸= N
Mci|N
i→M
(ii)ci ∈C
M ̸= N
Mci|N
1−i
−→N
(iii)
MQ|M
1→M
(3.87)
(iv)P ̸∈C
P
j→Q
M ̸= N
MP |N
j→MQ|N
(3.88)
If the probabilistic choice allows us to use real numbers from [0, 1] in
the speciﬁcation of arbitrary probabilities, the whole programming language
consists of an uncountable number of terms. Actually, this is a minor issue,
because the set of terms reachable from a given starting program is, of course,
always countable and for the purpose of semantics it is therefore always pos-
sible to consider a countable subset of the whole language.
3.3.6 Remarks On Probabilistic Choice at Higher Types
We introduced probabilistic choice at higher types; compare with rule (3.13).
For example, we allow for a term such as (λxnum.x)|(λynum.+1(y)). Actually,
we allow for all terms M|N of some higher type t. We could do this diﬀerently
and introduce probabilistic choice at the ground type only. Actually, in a sense
this would not change the expressive power of our language.
First, we still have the conditional construct if-then-else that allows for
branching to terms of arbitrary type, i.e., also of some higher type. Given two
terms M and N of some higher type t, let us assume that we are not allowed
to express the probabilistic choice directly as T ≡M|N. Still, we can realize
the probabilistic choice with the term T ′ ≡if(0|1)thenM elseN in which the
term (0|1) plays the role of a coin ﬂip. Actually, the terms T and T ′ behave
the same, i.e., they are operationally equivalent. Two terms M and N are said
to be operationally equivalent if substituting them into an arbitrary context

88
3 Syntax and Operational Semantics
K[_] of appropriate type always leads to terms K[M] and K[N] that have
the same evaluation semantics, i.e., (K[M] ⇒C) = (K[N] ⇒C); compare
with Def. 3.6. We do not provide a proof for this here.
Second, probabilistic choice for higher-typed terms M and N can be simu-
lated anyway, i.e., without the need to exploit the conditional construct. Given
again that the terms M and N have type t, we know by Lemma 3.1 that t
has a top-level functional structure t = (tn →(. . . (t2 →(t1 →g))...)) for n
types ti ∈T and a ground type g ∈Tg. Now, we can write the following term
for n fresh variables xti, i.e., variables that are not free in either M or N:
T ′′ ≡λxt1.λxt2. . . . λxtn.((Mxt1 · · · xtn) | (Nxt1 · · · xtn))
(3.89)
Now, we have again that T ′′ from Eqn. (3.89) is operationally equivalent
to T = (M|N). Again, we do not provide a proof for this, but it should be
easy to see that it is the case, because T = T ′′ is a kind of η-equivalence.
Remember that η-equivalence [18] expresses extensionality, i.e., the fact that
each term M converts to λx.(Mx) as long as x is not free in M. Therefore,
we can see that T and the term T ′′′ ≡λxt1.λxt2. . . . λxtn((M|N)xt1 · · · xtn)
are actually operationally equivalent. Now, it should be easy to see that also
T ′′ and T are operationally equivalent.
This means we could restrict the probabilistic choice to ground types with-
out loss of operational expressiveness, in any case, i.e., even if our conditional
construct did not allow for higher-typed branches. However, having the prob-
abilistic choice at higher type ﬁts together with the crucial notion of func-
tional programming languages, i.e., that functions are ﬁrst-class citizens. In
functional programming languages functions are fundamental building blocks
that can be passed around as parameters and used as data in data struc-
tures. The design of functional algorithms, functional data structures [213],
programs and programming systems heavily relies on that notion of functions
as ﬁrst-class citizens. For example, the widely known functional map-reduce
programming pattern gathers functions as objects in a data structure.
The typed lambda calculus is a maximally reductionist functional pro-
gramming language. As such, it is interesting to investigate the semantics of
the typed lambda calculus. The typed lambda calculus is, of course, also a
model of computation. As such it is only one option among others for studying
probabilistic computation. For example, Dana Scott investigates probabilistic
choice for the untyped lambda calculus in [242] and Dal Lago and Zuppiroli
characterize probabilistic computation in the style of Kleene’s partial recur-
sive functions in [59, 60]. A similar question is whether treating probabilistic
choice at higher types or restricting it to ground types can be asked with
respect to any programming primitive or building block, e.g., for the condi-
tional if-then-else. In Plotkin’s original version of PCF [223], the if-then-else
construct is restricted to ground types, i.e., terms if (C, M, N) can only be
formed for terms M and N of ground type. In the book by Gunther [118], a
standard textbook on semantics of programming languages, PCF comes in a

3.3 The Probabilistic Operational Semantics
89
version that allows for higher-typed conditionals, i.e., so that the branches M
and N might have higher type. Now, the same discussion as conducted for the
probabilistic choice applies. Again, we can rewrite a higher-typed conditional
term R ≡if (C, M, N) by an operationally equivalent term
R′ ≡λxt1. . . . λxtn.if (C, (Mxt1 · · · xtn), (Nxt1 · · · xtn))
for an approriate vector of variables such that Mxt1 · · · xtn and Nxt1 · · · xtn
have ground type. We can even go further. Yet, the conditional construct is
not in its most reductionist form. We can further restrict the branches of the
conditional construct from arbitrarily terms of ground type to variables of
ground type. Still, we can write a term
R′′ ≡λxt1. . . . λxtn.(λ l. λ r.if (C, l, r))(Mxt1 · · · xtn)(Nxt1 · · · xtn)
for ground-type variables l, r and further variables xt1 · · · xtn that are all not
free in M and N so that R′′ is operationally equivalent to R. Now, with
λ l. λ r.if (C, l, r) in R′′ we have arrived at conditional terms that are purely
combinatorical, i.e., just select between the arguments that they are given.
With respect to the elaboration of the operational semantics, the intro-
duction of the probabilistic choice at higher types comes at no price. It is
not relevant for the structures and techniques that we establish in the op-
erational semantics, whether we introduce the probabilistic choice generally
for all types or restrict it to ground types. At the same time the general in-
troduction for all types is more straightforward and somehow more natural,
i.e., in better accordance with the notion of functions as ﬁrst-class citizens.
Actually, with respect to the elaboration of the denotational semantics the
generally typed probabilistic choice comes at a price, albeit not a very high
price. We need to deﬁne functional versions of the vector space operations,
see Sect. 5.1.4, to be used in the semantic equations. On the other hand, for-
tunately, that is all. Even with a generally typed probabilistic choice we need
to introduce distributions only at the level of ﬂat domains in our semantics.
With the functional vector space operations from Sect. 5.1.4 we can consume
or ﬂatten probabilistic choice at higher types immediately whenever it occurs
in semantic equations. The functional vector space operations semantically
replay the pattern that is shown in Eqn. (3.89).
3.3.7 Remarks On Call-by-Value
Reduction strategies constitute a wide ﬁeld. Not only do they aﬀect the se-
mantics of a programming language and, therefore, program and program sys-
tem design, but they are crucial in programming language implementation,
i.e., when it comes to non-functional aspects such as performance; see, e.g.,
the book of Simon Peyton Jones [217]. We cannot delve into these issues here
and only glance at the diﬀerence between call-by-value and call-by-name [220]
where we are interested only in direct semantical diﬀerences. The operational

90
3 Syntax and Operational Semantics
semantics that we have introduced is a call-by-name semantics. In determin-
istic lambda calculi call-by-value and call-by-name diﬀer only with respect to
termination behavior. Programs that terminate under both of the reduction
strategies evaluate to the same value. Some programs that terminate under
call-by-name might not terminate under call-by-value. In a probabilistic cal-
culus, the diﬀerence between the two reduction strategies is more ﬁne grained.
Let us have a look at the following program:
T ≡(λf.f(f(0)))



M
( (λx. + 1(x))



N1
| (λx. + 1(+1(x)))



N2
)



N
(3.90)
Under the call-by-name semantics that we have introduced, the program
T reduces to value 2 with a 25% probability, to value 3 with a 50% probability
and to value 4 again with a 25% probability. Under call-by-name the argument
term N is substituted into the program body of M as a whole. Under call-
by-value it is decided earlier, before function application, whether N1 or N2
eventually can aﬀect the reduction and the occurence of the term +(+(+(0)))
is pre-empted. Therefore under call-by-value the program T reduces to value
2 with a 50% probability and to value 4 also with a 50% probability.
With respect to the elaboration of the denotational semantics the dif-
ference between call-by-name and call-by-value matters. As we have already
described in Sect. 3.3.6, in the case of call-by-name it suﬃces to introduce
probabilistic distributions over ﬂat domains. The semantics of the term N1
is just a function that takes a natural number and yields a distribution over
the natural numbers. It is not a distribution over this or any other kind of
functions. The same goes for the term N2. Then, the semantic version of the
probabilistic choice merges the semantics of N1 and N2 with appropriate func-
tional vector space operations. In such merging the information from where
single probabilities stem vanishes, which does no harm. In the case with call-
by-value this cannot work. In a denotational semantics with call-by-value, we
must keep track of such information, so that it can be exploited in function
application.
With respect to the elaboration of the operational semantics there is no es-
sential diﬀerence between call-by-name and call-by-value. Actually, the inves-
tigation of termination behavior and its results in Chap. 4 hold independently
of the chosen reduction strategy.
We complete these remarks by giving the one-step-semantics rules for the
case of call-by-value. All that is needed is to replace (3.59-ii) by the following
two rules:
i)
N ∈ΛV
(λv.B)N
1→B[v := N]
ii)
N ̸∈ΛV
N
i→N ′
(λv.B)N
i→(λv.B)N ′
(3.91)
The set ΛV in Eqn. (3.91) is the set of values that consists, as usual, of
constants and lambda abstractions; compare with Def. 3.41.

3.4 Important Readings
91
3.4 Important Readings
The work [232] of Saheb-Djahromi gives an operational and a denotational se-
mantics to a version of the probabilistic lambda calculus. The host language
is the higher-typed lambda calculus. Probabilistic choice is introduced at the
level of ground types. The language allows for arbitrary real number prob-
abilities as annotations to the probabilistic choice. The language allows for
both call-by-name and a limited form of call-by-value. Two diﬀerent kinds of
lambda abstractions are introduced for the purpose of steering the evaluation.
Call-by-value lambda abstractions are limited to variables of ground types.
The operational semantics starts with a one-step semantics, which forms a
probabilistic matrix. Reduction is not explained as the hitting probability of
a Markov chain. Instead, on the basis of the probabilistic matrix, all ﬁnite
evaluation sequences are deﬁned inductively. Then, an evaluation semantics
is deﬁned as the limit of ﬁnite evaluation sequences. In this approach to op-
erational probabilistic semantics the decomposition of reduction probabilities
is the deﬁning concept, i.e., it becomes part of an explicit construction and
does not follow as a property of a Markov chain semantics; compare with
Lemma 2.31 and Eqn. (2.35).
For predicate transformer semantics of probabilistic programming lan-
guages, see the work of Keimel et al. in [150]. The work describes predicate
transformers for partial correctness semantics for a reductionist imperative
programming language that contains primitives for both probabilistic and
nondeterministic choice. Compare also the work of Tix, Keimel and Plotkin
in [258]; see Sect. 5.4.
In [58] Dal Lago and Zorzi deﬁne operational semantics for probabilistic
versions of the untyped lambda calculus, i.e., for both the call-by-name and
the call-by-value case. For both cases, small-step and big-step evaluation se-
mantics are provided. Here, both inductive and co-inductive [170] deﬁnitions
are provided. The mutual relationships between the several operational seman-
tics are investigated. The small-step semantics are shown to be equivalent to
the respective big-step semantics. Also, standard continuation-passing-style
transformations [220] between call-by-value and call-by-name semantics are
generalized to the probabilistic case.
The seminal work on probabilistic bisimulation is the paper [174] by Larsen
and Skou. In [62, 61] Dal Lago, Sangiorgi and Alberti deﬁne a notion of ap-
plicative bisimulation [2] for the probabilistic untyped lambda calculus. They
investigate congruence and completeness of the resulting probabilistic applica-
tive bisimulation. Congruence is shown and a counterexample to completeness
is provided for the deterministic fragment as well as a further speciﬁcally re-
ﬁned notion of bisimulation. In [54, 55] Crubillé and Dal Lago proceed with
the study of probabilistic applicative bisimulation for the probabilistic typed,
call-by-value lambda calculus. It turns out that in this case, probabilistic ap-
plicative bisimulation exactly meets context equivalence.

92
3 Syntax and Operational Semantics
In [59, 60] Dal Lago and Zuppiroli take a genuinely diﬀerent approach to
probabilistic computation. They characterize it from scratch in the style of
Kleene recursive function deﬁnitions [151], without detour via deterministic
computation. This way they can bridge more directly to recursion-theoretical
and complexity-theoretical considerations; compare also with Dal Lago and
Toldin [56] for an early reference and again later to [57].
Languages such as IBAL [218], Church [110] and Venture [180] are proba-
bilistic programming languages, called rational programming languages in the
case of IBAL [218]. Their genuine purpose is not to implement randomized
algorithms but to model and generate stochastic distributions; compare also
with Sect. 1.5. Appropriate formal semantics of such languages must model
the evolution of stochastic distributions along the traces of probabilistic pro-
gram executions. In [228], Ramsey and Pfeﬀer deﬁne a version of the untyped
probabilistic lambda calculus that incorporates continuous distributions as
computational atoms as well as a primitive to query these distributions. They
give a monadic semantics to the resulting stochastic lambda calculus and
provide a Haskell implementation for it. Compare also the work of Park in
[214, 215]. In [35, 36] Borgström et al. give a big-step, trace-oriented semantics
for a stochastic untyped lambda calculus, which serves as a reductionist model
of rational programming languages. Similarly, in [250] Staton et al. provide
both an operational and a monad-based denotational semantics for a simply
typed probabilistic lambda calculus; compare also with [249].

4
Termination Behavior
In this chapter we study the termination behavior of the probabilistic lambda
calculus. The degree of termination is the central concept in these investiga-
tions. Given a program M, its degree of termination is the probability that
it ever hits a constant value. We also simply say termination degree for the
degree of termination of a program. We also say that the termination degree
of a program is its probability to terminate.
Deﬁnition 4.1 (Degree of Termination) Given a program M, its degree
of termination (termination degree) equals ηS⟨M, C⟩, i.e., the probability that
it ever hits a constant value.
In the probabilistic lambda calculus, it is not suﬃcient any more to talk
about the termination and non-termination of a program as exclusive oppo-
sites. Rather, we need to distinguish between a program and its program runs.
A single program run either terminates or does not, whereas a program has
a termination degree, which is the probability that the program executes a
terminating program run. Furthermore, we might have programs with some
non-terminating program runs that, however, terminate with a hundred per-
cent probability. As with standard, non-probabilistic programs, termination is
about the reachability of constants. A program run that eventually reaches a
constant value is said to terminate, whereas a program run that never reaches
a constant is said to be non-terminating. In the standard, non-probabilistic
case there is a one-to-one correspondence between programs and program
runs. Each program speciﬁes exactly one program run. In the probabilistic
case, there is a one-to-many correspondence between a program and its pro-
gram runs. The standard execution of a probabilistic program results in one
of its program runs.
In the next sections we will make precise notions such as program runs,
terminating program runs, non-terminating program runs and further related
notions. Based on that, we will investigate termination behavior. We will intro-
duce the notions of bounded and unbounded termination and show how these
are related to the existence of non-terminating program runs. We will identify
© Springer-Verlag Berlin Heidelberg 2017
D. Draheim, Semantics of the Probabilistic Typed Lambda Calculus,  
DOI 10.1007/978-3-642-55198-7_4 
93

94
4 Termination Behavior
a widened notion of termination, so-called path stoppability or p-stoppability,
which allows us to determine the degree of termination of certain programs
albeit they might have non-terminating program runs.
Please have a quick look at Tables 4.1 and 4.2. These tables give an
overview of the most important terminology and results of the next sections.
You might want to have a glance at the tables to gain a ﬁrst impression
about the upcoming material. In any case, please use Tables 4.1 and 4.2 as a
reference for the following discussion and observations.
ηS⟨M, C⟩= 1
ηS⟨M, C⟩< 1
T (M) = P(M)
All program runs terminate.
The program terminates with
degree one. The program
terminates bounded.
–
T (M) ⊂P(M)
Not all of the program runs
terminate. The program
terminates with degree one. The
program terminates unbounded.
Not all of the program runs
terminate. The program
terminates with degree less than
one. It is not determined
whether the program terminates
bounded or unbounded.
Table 4.1. Bounded and unbounded termination
ηS⟨M, C⟩= 1
ηS⟨M, C⟩< 1
T (M) = P(M)
All program runs
terminate. The
program terminates
with degree one.
–
ﬁnite
Cover(M)
T (M) ⊂P(M)
Not all of the program runs terminate. However,
all program runs are p-stoppable, because the term
cover of the program is ﬁnite. Program dovetailing is
p-stoppable. The termination degree is computable,
e.g., based on applications of Gauss-Jordan elimina-
tion.
Not all of the program runs terminate. Not all of the
program runs are p-stoppable. Program dovetailing is
not p-stoppable. The termination degree is not com-
putable.
inﬁnite
Cover(M)
Table 4.2. p-Stoppability and term covers

4 Termination Behavior
95
In Table 4.1 and Table 4.2 we use P(M) to denote the set of program
runs of M, whereas T (M) stands for the set of terminating program runs of
M. In principle, you can think of program runs and program executions as
synonymous. It is only later, in Sect. 4.3, when we will distinguish between
program runs and program execution for technical reasons. Obviously, with
T (M) = P(M) we indicate that all of the program runs of M terminate,
whereas T (M) ⊂P(M) indicates that there exists a non-terminating program
run. Table 4.1 summarizes how boundedness of program termination is related
to the termination degree of a program. A program is said to be bounded
if the execution lengths of all of its terminating program runs are capped
by an upper bound. Otherwise, the program is said to be unbounded. We
will deﬁne the notion of bounded and unbounded termination in Sect. 4.2.
Next, Table 4.2 summarizes how ﬁniteness of a term cover relates to the path
stoppability of programs. With the term cover of a program M, or just cover
of the program, we name the set of all terms that can be reached by any
potential program execution starting from M. We also denote the cover of
a program by Cover(M). We investigate term covers and path stoppability
Sect. 4.6.
In accordance with the degree of termination we say that ηS⟨M, C⟩is the
degree of non-termination of a program M, i.e., the probability that program
M fails to terminate. Obviously, the degree of termination and the degree of
non-termination of a program sum up to one, as expressed by Lemma 4.2.
Lemma 4.2 (Degrees of Termination and Non-Termination)
Given a program M we have that
ηS⟨M, C⟩= 1 −ηS⟨M, C⟩
(4.1)
Proof. This follows from the fact that C and C are complements and the
deﬁnitions of ﬁrst hitting times and hitting probabilities in Defs. 2.22 and 2.23.
First, we know that the sets HS(C) < ∞∧S0 = M and HS(C) < ∞∧S0 =
M are disjoint and sum up to S0 = M. Next, we know that ηS⟨M, C⟩and
ηS⟨M, C⟩sum up to 1; also compare with Eqn. (2.24).

The subject of investigation of this chapter is the termination behavior
of the probabilistic typed lambda calculus. Here, we are not only interested
in almost sure termination, i.e., termination degrees of one, but in the con-
cepts of path stoppability and bounded termination, which are available for
all termination degrees. For an investigation of termination behavior of im-
perative programming systems, see the work of Lehmann, Pnueli and Stavi in
[176] and Hart, Sharir and Pnueli in [127, 128]. The subject of investigation
in [176, 127, 128] is systems that consist of a ﬁnite number of concurrent pro-
cesses, where each of the processes is a state-changing machine manipulating
private and shared variables.

96
4 Termination Behavior
4.1 Introductory Examples of Termination Behavior
Before we start a rigorous investigation of termination behavior, we walk
through a series of examples, and, for the time being, we use the concepts
of program runs, terminating program runs, non-terminating program runs,
termination, and degree of termination as informal, intuitive notions. It is
the task of upcoming sections to make all of these notions precise and give
a formal semantics to them. We begin with a very simple example, i.e., a
program with termination degree 0.5. Given an arbitrary constant ni ∈Cnum
we deﬁne the following program:
M0 = ni | μλx.x
(4.2)
The program M0 in Eqn. (4.2) allows for exactly two program runs, i.e., the
one that terminates with ni after one step and a second non-terminating
program run:
ni | μλx.x
0.5
−−→ni
ni | μλx.x
0.5
−−→μλx.x
1−→(λx.x)(μλx.x)
1−→μλx.x
1−→· · ·
Each of the program runs has probability 0.5 and therefore the program ter-
minates with probability 0.5 and also diverges with probability 0.5. Note that
the program runs that reaches the constant ni does not stop after reaching
ni, i.e., it is an inﬁnite program run that actually looks like this:
ni | μλx.x
0.5
−−→ni
1−→ni
1−→· · ·
When we say that a program reaches a constant, it reaches that constant
necessarily after a ﬁnite number of steps. After it has reached the constant, it
stabilizes. Therefore with respect to termination behavior, it makes sense to
think of terminating program runs as ﬁnite executions, whereas it makes sense
to think of non-terminating program runs as inﬁnite executions. Henceforth,
we will write down the inﬁnite program runs that terminate, i.e., that reach
a constant, as ﬁnite sequences of term reductions as we did in the above
example. Either way, such notation in examples is merely informal notation.
However, later, in Sect. 4.7 on program reduction trees we will turn the notion
of ﬁniteness vs. inﬁniteness of program runs into a concrete tree paths model.
Given an arbitrary but ﬁxed constant ni ∈Cnum, all of the following
programs have the same evaluation semantics:
M1 = −1(+1(ni)) | ni
(4.3)
M2 = μλx.(x | ni)
(4.4)
M3 = μλx.(−1(+1(x)) | ni)
(4.5)
The evaluation semantics of all the programs Mi in Eqns. (4.3) through (4.5)
is the following:

4.1 Introductory Examples of Termination Behavior
97
Mi ⇒c =

1
, c = ni
0
, else
(4.6)
Consequently, the termination degree of all of the programs in Eqns. (4.3)
through (4.5) is the same. Their termination degree equals one, i.e., there
is a hundred percent probability that the program terminates. Although the
evaluation semantics of all the programs is equal, they diﬀer crucially in their
operational behavior with respect to several aspects. These aspects are, ba-
sically, the average execution time, the question whether there exists a non-
terminating program run or does not, the question whether the set of their
reachable terms is ﬁnite and so forth. The ﬁrst program M1 reaches the result
ni always in a ﬁnite number of steps, i.e., either immediately after one step
or otherwise after three steps:
−1(+1(ni)) | ni
0.5
−−→ni
−1(+1(ni)) | ni
0.5
−−→−1(+1(ni))
1−→−1(ni+1)
1−→ni
Program M2 is diﬀerent. It has a non-terminating program run ωM2, i.e., a
program run that never reaches a constant value:
ωM2 = μλx.(x|ni)
1−→· · ·
0.5
−−→μλx.(x|ni)
1−→· · ·
0.5
−−→μλx.(x|ni)
1−→· · ·
The program run ωM2, taken as an event {ωM2}, has a zero percent proba-
bility, i.e., PM2({ωM2}) = 0. However, it is the only non-terminating program
run of M2 so we know that the termination degree of M2 remains one. There
is exactly one value, i.e., ni, that can be reached by M2. However, there are
inﬁnitely many program runs τi to reach the result that take the following
form for each number i:
τi = μλx.(x|ni)
1−→· · ·
0.5
−−→μλx.(x|ni)



i times
1−→· · ·
0.5
−−→ni
1−→ni · · ·
Informally, a program run τi is a program run that loops i times before it takes
its execution branch to the ﬁnal result ni. Altogether the program runs τi have
a probability of one, because the probabilities of the individual program runs τi
sum up to 0.5+0.25+0.125+· · · which equals one, i.e., PM2({τi | i ∈N0}) = 1.
Fortunately, we do not have to rely on such informal argumentation, because
we have the Markov chain semantics to hand. Note that PM2({τi | i ∈N0})
is exactly the reduction probability M2 ⇒ni. Now, we know that a ﬁnite
number of terms are reachable by program executions of M2, i.e., the term
M2 itself, (λx.(x|ni))M2, ni|M2, and ni. Therefore, and because of the Markov
chain semantics and Theorem 2.29, we have that the corresponding vector of
reduction probabilities is the solution of the following equation system:
[M2 ⇒ni] = [(λx.(x|ni))M2 ⇒ni]
[(λx.(x|ni))M2 ⇒ni] = [ni|M2 ⇒ni]
[ni|M2 ⇒ni] = 0.5 · [ni ⇒ni] + 0.5 · [M2 ⇒ni]
[ni ⇒ni] = 1
(4.7)

98
4 Termination Behavior
Note that each term of the form M ⇒N in the above equation sys-
tem Eqn. (4.7) stands for a single variable. We use brackets to denote these
variables by [M ⇒N] in the equation system, however, we do this only in
order to improve readability. Solving the equation system yields, among other
things, that M2 ⇒ni equals one. To see this, just substitute variables from
bottom to top in the equation system Eqn. (4.7); which simply yields
[M2 ⇒ni] = 0.5 + 0.5 · [M2 ⇒ni]
(4.8)
[(λx.ni|x)M2 ⇒ni] = 0.5 + 0.5 · [M2 ⇒ni]
(4.9)
[ni|M2 ⇒ni] = 0.5 + 0.5 · [M2 ⇒ni]
(4.10)
[ni ⇒ni] = 1
(4.11)
Now, solving Eqn. (4.8) yields a probability of one for M2 ⇒ni.
Now, the diﬀerence between M1 and M2 is neither in the probability of
reducing the program to the result, nor in the termination degree. The diﬀer-
ence lies in the fact that M2 has a non-terminating program run. Therefore,
any number of steps may be needed to eventually arrive at the ﬁnal result
when M2 is executed. This is diﬀerent from the case of M1. There, there
exists a maximum number of steps needed to yield the result. Now, we can
say that the termination of M1 is bounded, whereas the termination of M2 is
unbounded.
We have said that program M2 is unbounded, i.e., we cannot give a bound-
ary for the number of steps it executes before it terminates. However, at least
it is possible to determine the expected average number of steps needed by
M2 to yield the result value ni. Again based on the Markov chain semantics,
we know that the vector of average reduction lengths is the least solution to
an equation system, which in case of M2 yields the following:
∅(M2 ⇒ni) = 1 + ∅((λx.(x|ni))M2 ⇒ni)
∅((λx.(x|ni))M2 ⇒ni) = 1 + ∅(ni|M2 ⇒ni)
∅(ni|M2 ⇒ni) = 1 + 0.5 · ∅(ni ⇒ni) + 0.5 · ∅(M2⇒ni)
∅(ni ⇒ni) = 0
(4.12)
Now, in the above equation system, each term of the form ∅(M ⇒N) stands
for a single variable. Solving the equation system Eqn. (4.12) yields, among
other things, that the average reduction length of M2 ⇒ni equals six. To see
this, again transform the above equation system by upwards variable substi-
tution into the following set of equations:
∅(M2 ⇒ni) = 1 + 1 + 1 + 0.5 · ∅(M2⇒ni)
(4.13)
∅((λx.(x|ni))M2 ⇒ni) = 1 + 1 + 0.5 · ∅(M2⇒ni)
(4.14)
∅(ni|M2 ⇒ni) = 1 + 0.5 · ∅(M2 ⇒ni)
(4.15)
∅(ni ⇒ni) = 0
(4.16)
Now, solving Eqn. (4.13) yields six for ∅(M2 ⇒ni), i.e., for the average
number of steps of M2 ⇒ni.

4.1 Introductory Examples of Termination Behavior
99
All that has been said for the program M2 is also valid for the program
M3 with the uniquely existing non-terminating program run ω3, which can
be illustrated as follows:
ωM3 = μλx.(−1(+1(x)) | ni)
1−→· · ·
0.5
−−→
−1(+1(M3))
1−→· · ·
0.5
−−→
−1(+1(−1(+1(M3))))
1−→· · ·
All the arguments that we have used with respect to M2 immediately apply to
the program M3. Nevertheless, there is a very important diﬀerence between
the programs M2 and M3. The execution of M2 yields at most a ﬁnite number
of terms, even in case of the non-terminating program run ω2. This is diﬀerent
in the case of M3. Here, the number of terms reachable by program execution
is uncapped, i.e., an inﬁnite number of terms can be reached, which encompass
all terms of the following forms for all numbers n:
(−1(+1(



n times
. . . (ni) . . .)))
(−1(+1(



n times
. . . M3 . . .)))
This is an important observation. Let us call the set of terms reachable by
execution of a program the term cover of this program, or cover of the pro-
gram for short. We can exploit the fact that the cover of M2 is ﬁnite to de-
termine its vectors of reduction probabilities and average execution lengths,
algorithmically, via solution of a ﬁnite equation system. This is not the case
for M3, because the cover of M3 is inﬁnite. Fortunately, ﬁnite term covers are
computable. This means that there exists an algorithm that terminates and
correctly computes the term cover for a program, whenever this term cover is
ﬁnite. This will be the topic of the upcoming sections. Actually, the ﬁniteness
of term covers characterizes a widened class of termination behavior that we
will call path stoppability, or p-stoppability, later.
4.1.1 The Complete Picture of Termination Behavior
Let us complete the big picture of termination behavior with all of its aspects
that are discussed in this chapter. As shown in Table. 4.3 we deal with four
diﬀerent aspects. These aspects are the termination degree, the existence of a
non-terminating program run, the boundedness of a program and the ﬁnite-
ness of the cover of a program. We consider the case that the termination
degree equals one and the case that the termination degree is less than one.
As in Table 4.1, the existence of a non-terminating program run is indicated
by T (M) ⊂P(M). Next, β(M) indicates that a program is bounded, whereas
β(M) indicates that a program M is unbounded; compare with Defs. 4.3
and 4.4. The inﬁnity sign ∞in Table. 4.3 indicates that the cover of a pro-
gram Cover(M) is inﬁnite, whereas ∞indicates that the cover is ﬁnite.

100
4 Termination Behavior
ηS⟨M, C⟩= 1 ηS⟨M, C⟩< 1
T (M)
=
P(M)
M1
×(i)
×(ii)
×(iii)
∞
×(iv)
×(v)
×(vi)
×(vii)
∞
T (M)
⊂
P(M)
×(viii)
M2
M0
M5
∞
×(ix)
M3
M6
M7
∞
β(M) β(M) β(M) β(M)
Table 4.3. Diﬀerent aspects of termination behavior
In principle, given the four dimension with two possible instances each,
we have sixteen possible combinations in Table 4.3. Only some part of these
combinations are possible. The impossible combinations are indicated by a
cross in Table 4.3. It is the task of this chapter to prove these combinations to
be impossible. Now, for each possible combination we have given an example
in Table 4.3. All the example programs that have been discussed earlier in
this section occur in Table 4.3. The discussed programs M1, M2 and M3
can all be found in the column of termination degree one.
Actually, with
respect to a termination degree of one these three examples are exhaustive.
All other combinations of termination degree one are impossible. First, in case
of termination degree one, the boundedness of a program is determined by the
existence of a non-terminating program run. A program is unbounded if and
only if it has a non-terminating program run. Then, a program that has an
inﬁnite cover necessarily has a non-terminating program run.
A program run that has a termination degree less than one must have a
non-terminating program run. Therefore, there remain four combinations for
which we have not yet discussed existing examples. These programs can be
given, e.g., by M0 = (ni | μλx.x), M5 = (M2 | μλx.x), M6 = (ni | μλx.+1(x)),
and M7 = (M3 | μλx.x).
4.1.2 Outline of the Propositions on Termination Behavior
Let us give an overview of the propositions proved in this chapter and see how
they relate to the overall picture provided by Table 4.3.
•
Eqn. (4.40) The termination degree of a program equals the probability
of its terminating program runs.
•
Lemma 4.32 If a program has an inﬁnite cover then it has a non-
terminating program run.
•
Lemma 4.39 If a program terminates unbounded then it has a non-
terminating program run.

4.2 Bounded and Unbounded Termination
101
•
Lemma 4.40 If a program has termination degree of one and has a non-
terminating program run then it terminates unbounded.
Together, Eqn. (4.40) and Lemmas 4.32, 4.39 and 4.40 prove all the ﬁelds in
(i) through (ix) in Table 4.3 impossible. Based on the deﬁnitions of termination
degree in Def. 4.1 and terminating program runs in Def 4.18, Eqn. (4.40)
proves ﬁelds (ii), (iii), (vi) and (vii) impossible. Lemma 4.32 proves ﬁelds (iv),
(v), (vi) and (vii) impossible. Lemma 4.39 proves ﬁelds (i), (v), (iii) and (vii)
impossible. Lemma 4.40 proves ﬁelds (i), (v), (viii) and (ix) impossible.
Although there is some redundancy between the above propositions, i.e.,
overlap in proving ﬁelds in Table 4.3 impossible, all of the propositions are
necessary. Eqn. (4.40) is essential to prove ﬁeld (ii) impossible, Lemma 4.32
is essential to prove ﬁeld (iv) impossible, Lemma 4.39 is essential to prove
ﬁeld (i) impossible, and Lemma 4.40 is essential to prove ﬁelds (viii) and (ix)
impossible.
4.2 Bounded and Unbounded Termination
With the notion of bounded termination we model that the termination of
a program never exceeds a known maximum number of steps. A program
terminates bounded if all of its terminating program runs terminate in at
most a known maximum number of steps. Otherwise, we say that the program
terminates unbounded.
We now deﬁne bounded and unbounded termination in terms of probabil-
ities, or, to be precise, in terms of hitting probabilities and bounded hitting
probabilities. Given a program M, we say that it terminates bounded if its de-
gree of termination is already determined after a maximum number of ﬁnitely
many steps. This means that its bounded hitting probability to reach a con-
stant does not increase any more after a certain maximum number of steps.
Deﬁnition 4.3 (Bounded Termination) Given a program M we say that
it terminates bounded, denoted by β(M),
iﬀ
there exists a bound n ∈N0
such that the program’s probability to reach a constant after at most n steps
equals its termination degree, i.e.,
ηn
S⟨M, C⟩= ηS⟨M, C⟩
(4.17)
Now, unbounded termination is deﬁned as the dual notion of bounded ter-
mination, i.e., a program is considered to be terminating unbounded whenever
it does not terminate bounded.
Deﬁnition 4.4 (Unbounded Termination) Given a program M we say
that it terminates unbounded, denoted by β(M),
iﬀ
the program does not
terminate bounded, i.e., ¬β(M), i.e.,
∀n ∈N0 . ηn
S⟨M, C⟩̸= ηS⟨M, C⟩
(4.18)

102
4 Termination Behavior
Next, Lemma 4.5 once more illustrates why we are speaking about bounded
resp. unbounded termination. Of course, for all programs the degree of ter-
mination is limited, absolutely, because no program can have a termination
degree greater than one. However, in case of unbounded termination, the de-
gree of termination never stops increasing as expressed by Lemma 4.5.
Lemma 4.5 (Monotonicity of Bounded Termination Degrees)
Given a program M that terminates unbounded, i.e., β(M), we have that:
∀n . ∃i>n . ηi
S⟨M, C⟩> ηn
S⟨M, C⟩
(4.19)
Proof. The Lemma is proven by contraposition. Assume a program M such
that there exists an n such that for all i>n we have that ηi
S⟨M, C⟩⩽ηn
S⟨M, C⟩.
Actually, we know that ηi
S⟨M, C⟩= ηn
S⟨M, C⟩for all i > n, because by
Lemma 2.28 we know that ηi
S⟨M, C⟩in monotonically increasing and there-
fore it is impossible that ηi
S⟨M, C⟩< ηn
S⟨M, C⟩. Furthermore, due to Corol-
lary 2.27 we know that lim
i→∞ηi
S⟨M, C⟩= ηX⟨M, C⟩and therefore also
ηn
S⟨M, C⟩= ηX⟨M, C⟩, which means that M is bounded.

Let us call the probability that a program reaches a constant after at most
n steps its bounded termination degree after n steps, or termination degree
after n steps for short. Lemma 4.5 expresses that the bounded termination
degree is more than only monotonically increasing. It is not strictly increasing,
yet it is more than only monotonically increasing. Independent of the num-
ber of steps already taken, we can be sure that the termination degree will
eventually increase further. The fact that the bounded termination degree is
monotonically increasing is not the point. This already follows immediately
from the fact that each bounded hitting probability is monotonically increas-
ing, see Lemma 2.28, and is, moreover, independent of the question whether
a program is bounded or not.
The question whether a program terminates bounded or unbounded is
independent of its termination degree. In particular, we also speak about
bounded and unbounded program termination in case of programs with ter-
mination degree less than one, as indicated by Table 4.1. For, example, the
program 0|μλx.x, which has a termination degree of 0.5, terminates bounded,
because it has only one terminating program run. Actually, even in case of
the program μλx.x, which has no terminating program runs at all, we say
that the program terminates bounded. Bounded termination means only that
all the terminating program runs of a program have a maximum execution
length, it does not say anything about the termination degree.
Irrespective of all this, we are particularly interested in discussing the
boundedness of program termination in case of programs that have a termi-
nation degree of one. Again, as indicated by Table 4.1, in case of a termination
degree of one, the question whether a termination is bounded or unbounded
is determined by whether all program runs of a program terminate or there
exists a non-terminating program run. We have observed this already in our

4.3 Program Executions and Program Runs
103
examples, however, we have not yet proven this. Although this might be intu-
itively clear, we have not yet developed the appropriate technical apparatus
to precisely prove this fact. We need to defer the proof of this fact to Sect. 4.8
after we have deﬁned reduction graphs in Sect. 4.4 and reduction trees in
Sect. 4.7.
4.3 Program Executions and Program Runs
4.3.1 Program Executions
Basically, program executions are outcomes of the Markov chains semantics.
However, we do not want to consider those outcomes as program executions
that contain a step or steps with a zero percent probability. In general, in-
ﬁnitely many such outcomes exist for each program, however, they are not
intended as program executions, i.e., they are unwanted as program execu-
tions. In the sequel we will refer to such outcomes as spurious outcomes. This
choice of terminology is an arbitrary choice and maybe not even the best one.
Other options would be unwanted, undeﬁned or false outcomes.
A program execution of a program M is a process instance starting from
M in which all steps have a non-zero percent probability. We denote the set
of program executions of a given program M by Pε(M).
Deﬁnition 4.6 (Program Executions)
Given a program M, the set
Pε(M) ⊆ΩS of its program executions is deﬁned as follows:
Pε(M) = { ω ∈(S0 = M) | ∀i ∈N0 . Si(ω)→Si+1(ω) > 0 }
With respect to the above deﬁnition, it might be helpful to recall some of
the Markov chain syntax. Given a program M, the set of process instances
starting from M is given by the set S0 = M. Remember, that (S0 = M) ⊆ΩS
is the Markov chain notation to denote S−1
0 (M), i.e., the inverse image of M
under S0 – see Def. 2.10. It is also instructive to make explicit the single
process instances in the set S0 = M as in { ω ∈ΩS | S0(ω) = M }.
The intention of Def. 4.6 is to restrict the set of program executions to
those process instances that have no steps with a zero percent probability.
The required probability is expressed in Def. 4.6 in terms of the probability
matrix. Recall, that this is entirely adequate, because due to Corollary 2.15
we know that for all i ∈N0 we have that
P(Si+1 =Si+1(ω) | Si =Si(ω)) = Si(ω)→Si+1(ω)
Next, we deﬁne the set of spurious outcomes of a program M, which we denote
by P ε(M). Remember that a spurious outcome is an outcome that is not a
program execution. Consequently, given a program M, its spurious outcomes
are deﬁned as the complement of Pε(M) in S0 = M.

104
4 Termination Behavior
Deﬁnition 4.7 (Spurious Outcomes) Given a program M, the set P ε(M)
of its spurious outcomes is deﬁned as follows:
P ε(M) = (S0 = M)\Pε(M)
(4.20)
A spurious outcome has a zero percent probability, because it contains at
least one transition with a zero percent probability. This is intuitively clear
and can be proven easily by natural induction. Sets of spurious outcomes
all have a zero percent probability. Similarly, the probability that a program
is executed as one of its program executions is a hundred percent. Although
these facts are intuitively clear, they are non-trivial. Lemma 4.8, Corollary 4.9
and Lemma 4.10 show such and similar facts in the sequel.
Lemma 4.8 (Probability of Program Executions) Given a program M,
the probability of its set of program executions equals its initial probability, i.e.,
we have that
P(Pε(M)) = ιM
(4.21)
Proof. We deﬁne the n-approximating set to Pε(M), denoted by P<n(M), as
follows:
P<n(M) = { ω ∈(S0 =M) | ∀i < n . Si(ω)→Si+1(ω) > 0 }
(4.22)
It can be shown by natural induction that the set S†
n(P<n(M)) is ﬁnite for
all n. Similarly, it can be shown by natural induction that P(P<n(M)) equals
ιM for all n. Now we know that P<n(M) ⊇P<n+1(M) for all n and there-
fore that P<0(M) ⊇P<1(M) ⊇· · · forms a decreasing chain. Therefore, by
continuity from above, i.e., Lemma 2.8, we know that
P( ∩
n∈N0P<n(M)) = lim
n→∞P(P<n(M)) = lim
n→∞ιM = ιM
(4.23)
Furthermore, by appropriate set transformations and application of De Mor-
gan transformations it can be shown that
Pε(M) =
∩
n∈N0P<n(M)
(4.24)
Now, Eqn. (4.21) follows immediately from Eqns. (4.23) and (4.24).

Given a program, the event that one of its program executions is executed
upon program start has a hundred percent probability, whereas the event that
one of its spurious outcomes is executed has a zero percent probability. These
facts are expressed by Corollary 4.9.
Corollary 4.9 (Probability of Program Executions) Given a program
M we have that
PM(Pε(M)) = 1
(4.25)
PM(P ε(M)) = 0
(4.26)

4.3 Program Executions and Program Runs
105
Proof. Corollary from Lemma 4.8.

Spurious outcomes do not add to probabilities at all. They can be erased
from any event without an eﬀect on its probability. This is expressed by the
next Lemma 4.10.
Lemma 4.10 (Restriction to Program Executions) Given a program M
and an event A ⊆ΩS we can restrict A to its subset of program executions
without changing its probability conditional on M, i.e.,
PM(A) = PM(A ∩Pε(M))
(4.27)
Proof. First, we show the following:
P(A ∩S0 =M) = P(A ∩Pε(M))
(4.28)
By the deﬁnition of spurious outcomes in Def. 4.7 we know that S0 = M
equals Pε(M) ∪P ε(M). Furthermore, we know that Pε(M) and P ε(M) are
disjoint. Therefore we know that
P(A ∩S0 =M) = P(A ∩Pε(M)) + P(A ∩P ε(M))
(4.29)
By Corollary 4.9 we know that PM(P ε(M)) = 0. Therefore, we also know that
P(P ε(M)) = 0 and also know that P(A ∩P ε(M) = 0. Taking this together
with Eqn. (4.29), we now know that P(A ∩S0 = M) equals P(A ∩Pε(M)),
i.e., we know that Eqn. (4.28) holds. Now, Eqn. (4.27) immediately follows as
a corollary. We know that PM(A) equals P(A ∩S0 = M)/P(S0 = M) which,
according to Eqn. (4.28), equals P(A ∩Pε(M) ∩S0 = M)/P(S0 = M), which
equals PM(A ∩Pε(M)).

Next, we deﬁne the set of terminating program executions starting from
a program M, which we denote by Tε(M). A terminating program run is
a program run that eventually hits a constant. Dually, a non-terminating
program run is a program run that never hits a constant and we denote the
set of non-terminating programs by T ε(M).
Deﬁnition 4.11 (Terminating Program Executions) Given a program
M, the set of its terminating program executions, denoted by Tε(M) ⊂ΩS,
and the set of its non-terminating program executions, denoted by T ε(M), are
deﬁned as follows:
Tε(M) = (∃i<∞. Si ∈C) ∩Pε(M)
T ε(M) = Pε(M)\Tε(M)
According to Corollary 2.25, Tε(M) can also be characterized diﬀerently
as (HX(T ) ⩽n ∩Pε(M)). Now, due to Lemma 4.10 we have that each
event can be restricted to its program executions without changing its prob-
abilities. Therefore, and due to the deﬁnitions of degrees of termination and

106
4 Termination Behavior
hitting probabilities, see Defs. 4.6 and 2.23, we have that a program’s degree of
termination equals the probability of this program’s terminating executions,
which is again intuitively immediately clear:
ηS⟨M, C⟩= PM(Tε(M))
(4.30)
Similarly, we have that a program’s degree of non-termination equals the
probability of this program’s non-terminating executions:
ηS⟨M, C⟩= PM(T ε(M))
(4.31)
For technical reasons of Markov chains we need to distinguish between pro-
gram executions and program runs. A program execution is an outcome of
the Markov chain semantics. A program run is a class of program executions
that cannot be distinguished any further by the Markov chain semantics. This
distinction should not be overstressed in argumentations, as least not at the
informal or conceptual level. Nevertheless, it is an important distinction that
must be maintained throughout the development of the subsequent theory.
In particular, we will need to face this distinction in proofs. Let us stop and
delve into this topic for a while in Sect. 4.3.2.
4.3.2 Program Runs in the Sigma Algebra
A program run is a speciﬁcation that ﬁxes a program for each stage of
our Markov chain semantics, i.e., it is an inﬁnite sequence (si ∈ΛP )i∈N0.
In due course, in Sect. 4.4, we will deﬁne a concrete concept of program
runs as inﬁnite walks in a reduction graph. Now, given such a program run
s = (si ∈ΛP )i∈N0, in general, we cannot assume that the program execution
that adheres to s is uniquely deﬁned. This means that it is not guaranteed,
that the set {ω | ∀i.Si(ω) = si} consists of exactly one element. Note that
a single program execution ω has – technically – no probability, i.e., only
taken as an event {ω} it receives a probability P({ω}). Now, let us say that
two program executions ω1 and ω2 are equal, denoted by ω1 ≡S ω2, if they
cannot be distinguished by S, i.e., Si(ω1) = Si(ω2) for all i ∈N0.
Now, we say that a program run is an equivalence class of program ex-
ecutions under ≡S. Note that in Def. 4.12 we use quotient set notation as
introduced in Def. 2.87 in order to denote the set ΩS/≡S of all relevant equiv-
alence classes of program executions.
Deﬁnition 4.12 (Program Run Events in the Sigma Algebra)
An
event p ∈ΣS is called a program run event, or just program run for short, if
p ∈ΩS/≡S, where ≡S: ΩS × ΩS is deﬁned as image equality under S, i.e.,
given ω1 and ω2, we have that ω1 ≡S ω2
iﬀSi(ω1) = Si(ω2) for all
i ∈N0.
Things would change and all of the discussed technical issues would per-
haps become easier, if we required the random variables in S to be injective,

4.4 The Reduction Graph
107
however, we prefer to stay with the general case. Conceptually, we can for-
get about the distinction between program executions and program runs in
upcoming argumentations. This is so, because in the sequel we are never in-
terested in the probabilities of distinct, equivalent program executions ω1 and
ω2 but always only in the probability of their joint equivalence class. However,
the situation would change, if we introduced, besides the random variables in
S, further auxiliary random variables of the form X : ΩS →S′ that model
diﬀerent aspects of resp. more ﬁne-grained perspectives on the program exe-
cutions. However, we are only interested in S in the sequel, with which, by its
deﬁnition, ω1 and ω2 cannot be distinguished.
In the sequel we freely use the term program run for equivalence classes of
program executions, unique speciﬁcations of inﬁnite program sequences, and
concrete concepts for speciﬁcations of program sequences such as the reduction
walks in our reduction path. In informal descriptions we often neglect the
diﬀerence between a program run and its single executions. Then, we state a
property about the program run which is actually an all-quantiﬁed property
about its program executions. For example, we might say that a program
run is terminating, which actually means that all of its program executions
terminate. Or we say that a program run eventually reaches a certain state.
Again we mean that all of its program executions reach that state. All of this
is acceptable, at least in informal descriptions, given that the single program
executions of a program run cannot be distinguished merely by the Markov
chain semantics itself.
4.4 The Reduction Graph
The one-step semantics M
i−→N expresses the possibility of an immediate
reduction from closed term M to closed term N with probability i. For the
analysis of termination behavior we need to investigate the ﬁnite reachabil-
ity of terms, to which we can abstract from the probabilities of the choices
during program executions. We are interested in diﬀerent kinds of reducibility
relations, reduction paths and reducibility predicates that equip us with the
necessary properties of term reductions. All of these notions can be deﬁned
on the basis of graphs and walks in graphs.
As a ﬁrst step we deﬁne the one-step reduction relation, also called the
immediate reduction relation, on the basis of the one-step semantics. The
immediate reduction relation forgets about probabilities in the one-step se-
mantics and, hand-in-hand with this, erases steps that have a zero probability.
The intention behind this is clear. We want to single out spurious program
executions. The immediate reduction relation is denoted by ρ. It is therefore
deﬁned as a binary relation over the set of programs ΛP .
Deﬁnition 4.13 (The Immediate Reduction Relation) The immediate
reduction relation of the probabilistic lambda calculus, denoted by ρ, is deﬁned

108
4 Termination Behavior
as follows:
ρ ⊆ΛP × ΛP
(4.32)
ρ = {⟨M, N⟩| M →N > 0}
(4.33)
Next, we deﬁne the reduction graph R of the lambda calculus as the graph
consisting of the set of programs ΛP as nodes and the reduction relationships
deﬁned by ρ as edges.
Deﬁnition 4.14 (The Reduction Graph) The reduction graph of the prob-
abilistic lambda calculus, denoted by R, is deﬁned as a digraph ⟨VR, ER⟩with
nodes VR and edges ER as follows:
R = ⟨VR, ER⟩
(4.34)
VR = ΛP
(4.35)
ER = ρ
(4.36)
Now, reduction walks are walks in the reduction graph. We call reduction
walks also multi-step reductions or simply reductions for short. Similarly, we
call the paths in the reduction graph reduction paths. We inherit all deﬁnitions
for walks and paths in graphs. This way we have the set nWR of ﬁnite reduc-
tions of length n, compare with Eqn. (2.53), the set ⋆WR of ﬁnite reductions
of arbitrary length, compare with Eqn. (2.54), the set ωWR of inﬁnite reduc-
tions, compare with Eqn. (2.55), and the set ⊕WR of all reductions, compare
with Eqn. (2.56). Given a set of walks W ⊆⊕WR we denote the subset of its
reductions starting with a term M by W(M), compare with Def. 2.37. Reduc-
tion paths are those reductions in which no term occurs more than once and,
given a set of reduction walks W ⊆⊕WR, we denote its subset of reduction
paths by π(W); compare with Def. 2.38. Equally, all other notation available
for graphs applies immediately to the reduction graph and its parts; see, e.g.,
Def. 2.36. Recall that, given a graph G and a walk w, we use |G| and |w| to
denote their sizes, κ(G) and κ(w) to denote the sets of their nodes, and #(w)
to denote the length of a walk.
4.4.1 Program Runs in the Reduction Graph
Now, the inﬁnite walks of the program reduction graph R will serve as a model
for program runs. An inﬁnite walk in the reduction graph ﬁxes a state for
each stage of the program execution. An inﬁnite walk in the reduction graph
uniquely identiﬁes a set of program executions that cannot be distinguished
further by the Markov chain S, i.e., a program run of our Markov chain
semantics; see Def. 4.12. Henceforth, we will naturally identify inﬁnite graph
walks with events of our Markov chain semantics. Henceforth, we will also
talk about inﬁnite graph walks simply as program runs.

4.4 The Reduction Graph
109
Deﬁnition 4.15 (Program Runs in the Reduction Graph) A program
run p is an inﬁnite walk of the reduction graph R, i.e., p ∈ωWR. Given
a program M, the set P(M) of its program runs is deﬁned as the set of its
inﬁnite walks starting from M, i.e.,
P(M) = ωWR(M)
We use only the inﬁnite walks of the reduction graph as models of the
process instances of our Markov chain semantics. Nonetheless, the whole set
⊕WS of all walks in the reduction graph is important for us. We need ﬁnite
walks as approximations to program runs in informal arguments as well as
in formal proofs of program properties. We might call the ﬁnite walks in
the reduction graph ⋆WS(M) the approximating program runs of program
M. Things will be diﬀerent later in Sect. 4.7 when we introduce the notion of
reduction tree. We will use the inﬁnite paths of the reduction tree to model the
non-terminating program runs and nothing but the non-terminating program
runs. In the reduction tree, also some of the ﬁnite paths are considered as
program runs, i.e., they are used to model the terminating program runs.
The reduction graph and the reduction tree serve diﬀerent purposes. We use
the reduction graph to analyze a widened class of termination, the so-called
path stoppability. We use the notion of reduction tree to analyze boundedness
of program termination. The reduction graph comes ﬁrst. This means that
reduction trees are deﬁned on the basis of the reduction graph; actually, each
reduction tree is deﬁned in terms of the walks in the reduction graph.
Program runs are formalized as sequences of terms and not as sequences of
alternating terms and probabilities. The reduction graph is a digraph, not a
multigraph, and all digraph walks are already completely determined by their
nodes – see also the remarks on walks in digraphs that follow Def. 2.35. This
is appropriate, because, as we know from Lemma 3.3, the one-step semantics
is a function with respect to pairs of terms. Given a program run r0r1r2 . . .
we immediately know its form as r0
i0
−→r1
i1
−→r2
i2
−→. . .. Although the ﬁrst
form is the form that will be with us in proofs, the second one is the one that
we usually prefer in informal discussions, i.e., in examples we will depict a
program run also in that second form.
A program run stands for a set of program executions. A program run
ﬁxes a state for each stage of a program execution. A program execution ω
adheres to a program run r if it is in state ri for all stages i ∈N0, i.e., whenever
Si(ω) = ri. Then, we say that the program execution ω is a program execution
of the program run r and, vice versa, that r is the program run of program
execution ω. We denote the program run of a program execution ω by ϱ(ω)
and the set of program executions of a program run r by ε(r). Obviously, all
program executions of a program run are equal with respect to S, i.e., they
cannot be distinguished only in terms of S. Actually, a set ε(r) is a program
run event in the sense of Def. 4.12, i.e., ε(r) ∈ΩS/≡S .

110
4 Termination Behavior
Deﬁnition 4.16 (Program Run of a Program Execution) Given a pro-
gram execution ω ∈Pε(M) we deﬁne its program run, denoted by ϱ(ω), as
follows:
ϱ(ω) = (Si(ω))i∈N0
Deﬁnition 4.17 (Executions of a Program Run) Given a program run
r ∈P(M) and a set of program runs R ⊆P(M) we deﬁne the set of program
executions of r, denoted by ε(r), and the set of program executions of R,
denoted by ε(R), as follows:
ε(r) = ϱ−1(r)
ε(R) = ∪ε†(R)
Obviously, given a program M, we have that the set of its program execu-
tions as deﬁned by Def. 4.6 equals the set of program executions of all of its
program runs, i.e.,
Pε(M) = ε(P(M))
(4.37)
At least in informal descriptions and argumentations, we can speak of a pro-
gram run as if it were an event. In particular, we can say that a program
run has a probability. We can do so, exactly because of the one-to-one cor-
respondence between the program run events and graph walks as described
above. Formally, the probability of a program run r = w0w1w2 · · · can be
immediately deﬁned as the probability Pw0(ε(r)). These extra technical and
terminological eﬀorts are complicated only at a ﬁrst sight. In concrete argu-
mentations the distinctions between the two kinds of program runs do not
play a major role. On the other hand, the eﬀorts pay back a lot. We have set
the stage for graph theory to argue about program runs and program execu-
tions. Despite the fact that the clear distinction between the event facet and
the graph facet of a program run can be neglected in informal discussions, we
stay with the dualism when we give further deﬁnitions.
4.4.2 Terminating and Non-Terminating Program Runs
Next, we turn to the notions of terminating and non-terminating program
runs. A terminating program run is a program run that eventually reaches a
constant. Dually, a non-terminating program run is a program run that never
reaches a constant. Given a program M, we denote its terminating program
runs by T (M), whereas we denote its non-terminating program runs as T(M).
Deﬁnition 4.18 (Terminating Program Runs) Given a program M, the
set T (M) ⊆ωWS of its terminating program runs and the set T(M) ⊆ωWS
of its non-terminating program runs are deﬁned as follows:
T (M) = {w ∈P(M) | ∃i <∞. wi ∈C }
(4.38)
T(M) = P(M)\T (M)
(4.39)

4.4 The Reduction Graph
111
In Eqn. (4.37) we have seen how ε : P(ωWS) →P(ΩS) equates pro-
gram runs to program executions, i.e., Pε(M) = ε(P(M)). Similar corre-
spondences exist for terminating program runs and non-terminating program
runs, i.e., we have that Tε(M) = ε(T (M)) and T ε(M) = ε(T(M)). In par-
ticular, with respect to degrees of termination and non-termination we can
broaden Eqns. (4.30) and (4.31) to program runs and summarize them as
follows:
ηS⟨M, C⟩= PM(Tε(M)) = PM(ε(T (M)))
ηS⟨M, C⟩= PM(T ε(M)) = PM(ε(T(M)))
(4.40)
In the sequel, we will use any of the characterizations shown in Eqn. (4.40) in-
terchangeably to denote degrees of termination resp. degrees of non-termination
without further comment.
An important observation is that a terminating program run cannot be a
path in R. This is so, because a terminating program run contains at least
the circle . . . c
1−→c . . . for the constant c that it eventually reaches. To say it
diﬀerently, as the contrapositive, each program run that is a path is automat-
ically non-terminating. The converse is not true. There exist many program
runs that are non-terminating but are not automatically paths. Take, as an
example, the most simple non-terminating program μλx.x. This program ex-
ecutes as the program run μλx.x
1−→(λx.x)μλx.x
1−→μλx.x
1−→. . . , which is
obviously not a path.
The fact that a terminating program run cannot be a path is suﬃcient
to prove that programs that have an inﬁnite cover necessarily have a non-
terminating program run; see Lemma 4.32. Actually, Lemma 4.32 follows
more or less immediately from this fact against the background of König’s
Lemma; see Lemma 2.39. However, the fact is not suﬃcient to prove that ev-
ery unbounded program necessarily has a non-terminating program run; see
Lemma 4.39. In order to prove Lemma 4.39 we need some stronger model of
non-terminating program run later. With the reduction tree in Sect. 4.7 we
turn each non-terminating program run into an inﬁnite tree path, whereas
terminating program runs become ﬁnite tree paths. With this correspondence
it will be then be possible to prove Lemma 4.39.
The fact that a terminating program run cannot be a path follows from
the fact that terminating programs stabilize behind the constant they reach.
A further property that we need in proofs later is the fact that the constant
that is reached by a terminating program run is uniquely determined. We
summarize these facts in the following in Lemmas 4.19 and 4.20 and Corol-
lary 4.21.
Lemma 4.19 (Terminating Program Runs Stabilize) Given a program
M, each of its terminating program runs p ∈T (M) stabilizes behind the con-
stant it reaches, i.e., for all p ∈T (M), i ∈N0 and j > i such that pi ∈C we
have that pj = pi.

112
4 Termination Behavior
Proof. Let us assume that pi = c for some constant c ∈C and i ∈N0. We
proceed by natural induction over the sequence index j ⩾i. The case j = i
is trivial with pi = c. In case j ⩾0 we can assume that pj = c. Due to the
deﬁnition of the one-step semantics, rules (3.62) and (3.63), we know that
c
1−→c is the only transition with c
1−→N > 0. Therefore we know due to the
deﬁnition of P(M) in Def. 4.15 that pj+1 must equal c = pj.

Lemma 4.20 (Program Runs Terminate Uniquely)
Given a
program M, the constant that is reached by one of its terminating program
runs p ∈T (M) is uniquely given, i.e., for all p ∈T (M) there exists a c ∈C
such that for all i ∈N0 we have that pi ∈C implies pi = c.
Proof. Due to Def. 4.18 we know that there exists a c ∈C such that pk = c
for some k ∈N0. Now assume that pl ∈C for some l ∈N0. Now for all l ∈N0
either l = k, k > l or l > k. The case i = k is trivial. In case k > l we know due
to Lemma 4.19 that c = pk = pl. In case l > k we know due to Lemma 4.19
that pl = pk = c.

Corollary 4.21 (Terminating Program Runs are not Paths) If a pro-
gram run p ∈P(M) is terminating, then p is not a path, i.e., we have that
p ∈T (M) implies p ̸∈π(P(M)).
Proof. Corollary to Lemma 4.19.

Corollary 4.21 amounts to saying that the set of terminating program runs
and the set of paths are disjoint, i.e., T (M) ∩π(P(M)) = ∅.
Now, we turn to the central concepts of termination behavior that we have
introduced in Defs. 4.1 and 4.3, i.e., termination degree and boundedness of
termination. We want to see how these notions meet the intuition behind
the program runs that we have just introduced. We turn to the notion of
termination degree ﬁrst. The termination degree of a program M has been
deﬁned as the hitting probability that our Markov chain reaches a constant by
starting from M, i.e., informally, the probability that M reaches a constant.
In terms of program runs, the termination degree will turn out to be the
joint probability of all terminating program runs of M, i.e., the probability
that M executes as one of its terminating program runs. The latter is again,
informally, the probability that M reaches a constant.
Next, let us turn to the notion of bounded termination and its relationship
to the notion of program runs as deﬁned for the reduction graph. We have
deﬁned bounded termination as the property that the termination degree of a
program is already known after a ﬁxed number of steps. In terms of program
runs a program is bounded whenever the number of steps needed to reach a
constant is capped. This is expressed by Lemma 4.22.
Lemma 4.22 (Bounded Termination)
A program M terminates
bounded iﬀthere exists a bound n < ∞so that for all terminating program
runs t ∈T (M) there exists an i ⩽n such that ti ∈C, i.e.,

4.4 The Reduction Graph
113
β(M) ⇔∃n<∞. ∀t ∈T (M) . ∃i ⩽n . ti ∈C
(4.41)
Proof. We start with the characterization of bounded termination in terms of
program runs, i.e., the right-hand side of the equivalence in Eqn. (4.41). Given
that T (M) equals {t | ∃i<∞.ti ∈C, t ∈P(M)} we can write the right-hand
side of Eqn. (4.41) diﬀerently in the following form:
∃n<∞. {t | ∃i<n.ti ∈C, t ∈P(M)} ⊇{t | ∃i<∞.ti ∈C, t ∈P(M)}
(4.42)
In the course of the proof, we will henceforth use T [n] to denote the set
{t | ∃i < n.ti ∈C, t ∈P(M)} from Eqn. (4.42) and T ′ to denote the set
{t | ∃i < ∞.ti ∈C, t ∈P(M)}. Now, the subset relationship T [n] ⊇T ′ in
proposition Eqn. (4.42) can be turned into an equality yielding the equivalent
proposition in Eqn. (4.43). The backward direction (4.42)⇐(4.43) is trivial.
To prove the forward direction (4.42)⇒(4.43) it suﬃces to see that T [n] ⊆T ′,
which is obviously the case. Altogether it follows that Eqn. (4.42) is equivalent
to
∃n<∞. T [n] = T ′
(4.43)
Now, Eqn. (4.43) implies
∃n<∞. ε(T [n]) = ε(T ′)
(4.44)
By the deﬁnition of ε in Def. 4.17 we can rewrite Eqn. (4.44) as follows:
∃n<∞. (∃i<n.Si ∈C ∩Pε(M)) = (∃i<∞.Si ∈C ∩Pε(M))
(4.45)
It is trivial that two equal events have the same probability. Therefore, it is
obvious that Eqn. (4.45) implies
∃n<∞. PM(∃i<n.Si ∈C ∩Pε(M)) = PM(∃i<∞.Si ∈C ∩Pε(M))
(4.46)
Up to now, we have proven (4.41)⇔(4.42)⇔(4.43)⇒(4.44)⇔(4.45)⇒(4.46).
We proceed with proving all equivalences of the above chain by completing
the ring proof (4.43)⇒(4.44)⇒(4.45)⇒(4.46)⇒(4.43). We show (4.46)⇒(4.43)
by contraposition, i.e., we prove ¬(4.43)⇒¬(4.46). We show this by contra-
diction, i.e., we assume ¬(4.43)∧(4.46) and show that this leads to a contra-
diction. We start with assuming that (4.46) holds. This means that we can
assume an n that makes proposition (4.46) true.
We take this n as arbitrary but ﬁxed in the sequel.
Now, we assume that (4.43) does not hold. Therefore, we can assume that
the set T [n] ̸= T ′. We know that in any case T [n] ⊆T ′ so that we have
T [n] ⊂T ′ now. We know that the diﬀerence set of T ′ and T [n] has the
following form:
T ′\T [n] = {t | ∃n<i<∞. ti ∈C, ∀i⩽n.ti ̸∈C, t ∈P(M)}
(4.47)

114
4 Termination Behavior
Now, we can assume that there exists a program run t′ ∈T ′\T [n]. Due to
basic Markov chain properties, i.e., Theorem 2.18, and due to t′
0 = M we
know
PM(S0 =t′
0 ∩. . . ∩Sn =t′
n) =
n−1

i=1
(t′
i →t′
i+1)
(4.48)
Now, we know that t′
i →t′
i+1 > 0 for all i ∈N0, because t is a program run,
i.e., t ∈P(M). Therefore we know
PM(S0 =t0 ∩. . . ∩Sn =tn) > 0
(4.49)
Now, due to t ∈T ′\T [n] and Eqn. (4.47) we can see that
(S0 =t′
0 ∩. . . ∩Sn =t′
n) ⊆(∃n<i<∞. Si ∈C, ∀i⩽n.Si ̸∈C)
(4.50)
Due to Eqns. (4.50) and (4.49) we know by the monotonicity of the probability
function, compare with Lemma 2.5, that the following holds:
PM(∃n<i<∞. Si ∈C ∩∀i⩽n.Si ̸∈C) > 0
(4.51)
Due to Lemma 4.10 we can restrict any event to its program executions.
Therefore, Eqn. (4.51) is equivalent to
PM(∃n<i<∞. Si ∈C ∩∀i⩽n.Si ̸∈C ∩Pε(M)) > 0
(4.52)
Next we can see that
PM(∃i<∞.Si ∈C ∩Pε(M))
= PM(∃i<n.Si ∈C ∩Pε(M))
+ PM(∃n<i<∞. Si ∈C ∩∀i⩽n.Si ̸∈C ∩Pε(M))
(4.53)
However, we have assumed Eqn. (4.46). Therefore, and due to Eqn. (4.53), we
have that
PM(∃n<i<∞. Si ∈C ∩∀i⩽n.Si ̸∈C ∩Pε(M)) = 0
(4.54)
Now, Eqn. (4.54) contradicts Eqn. (4.52). Overall, this proves (4.46)⇒(4.43)
correct and therefore (4.43)⇔(4.44)⇔(4.45)⇔(4.46).
Now, let us proceed with Eqn. (4.46). Due to Lemma 4.10 we can en-
rich any event with spurious outcomes without changing its probability so
that Eqn. (4.46) can be turned into the following equivalent proposition:
∃n < ∞. PM(∃i < n . Sn ∈C) = PM(∃i < ∞. Si ∈C)
(4.55)
By the deﬁnition of hitting probabilities and bounded hitting probabilities in
Def. 2.23 and Def. 2.24 we know that Eqn. (4.55) is equivalent to
∃n<∞. ηn
S⟨M, C⟩= ηS⟨M, C⟩
(4.56)

4.5 Central Graph Cover Lemmas
115
Now, we have completed the proof as Eqn. (4.56) adheres to the deﬁnition of
β(M), i.e., the deﬁnition of bounded termination according to Def. 4.3.

We say that a program run p vanishes if taken as an event ε(p), it has a
zero percent probability Pp0(ε(p)) = 0. From the terminology that we have
introduced, the fact that T (M) = P(M) describes the fact that all program
runs of a program M terminate – see Table 4.1. If all program runs of a
program M terminate we know, by deﬁnition, that the degree of termination
of M equals one, i.e., PM(Tε(M))=PM(Pε(M))=1. This explains the empty
ﬁeld in Table 4.1.
4.5 Central Graph Cover Lemmas
Given a digraph G and one of its nodes v, the node cover of v in G, or just
cover of v, denoted by CoverG(v) is the set of nodes that we can reach by a
walk starting in v. Equally, the path cover of v, denoted by π-CoverG(v) is
the set of nodes that we can reach via a path starting in v.
Deﬁnition 4.23 (Graph Covers) Given a digraph G = ⟨VG, EG⟩and a
node v ∈VG, we deﬁne the node cover CoverG(v) and the path cover
π-CoverG(v) as follows:
CoverG(v) =DEF κ(⋆WG(v))
(4.57)
π-CoverG(v) =DEF κ(π(⋆WG(v)))
(4.58)
With respect to the reachability of nodes, inﬁnite walks make no diﬀerence.
When a node is on an inﬁnite walk, it is also on a ﬁnite walk. Therefore, the
nodes of inﬁnite walks of a node v are already included in the nodes that we
can reach by ﬁnite walks starting in v. The same is true for paths.
Lemma 4.24 (Covers of Finite Walks and Paths)
Given a digraph
G = ⟨VG, EG⟩and a node v ∈VG, we have that:
κ(ωWG(v)) ⊆CoverG(v)
(4.59)
κ(π(ωWG(v))) ⊆π-CoverG(v)
(4.60)
Proof. We show Eqn. (4.59) only. Due to Def. 4.23 we need to show that
κ(ωWG(v)) ⊆κ(⋆WG(v))
(4.61)
For each (wi)i∈ω ∈ωWG(v) and n ∈N0 we have that (wi)i∈{0,...,n} ∈nWG(v).
Now, Eqn. (4.61) follows from the deﬁnitions of nodes in a graph; compare
with Def 2.36.

In a digraph the set of nodes that are reachable from a start node by some
arbitrary walk equals the set of nodes that are reachable by some arbitrary

116
4 Termination Behavior
path from that node. In order to see this, it suﬃces to show that two nodes
that are connected by a walk are also connected by a path. Informally, this is
rather easy to see. We just need to erase all cycles from a walk in order to get
the desired connecting path. In order to prove it formally, we can sharpen the
proposition slightly so that we can prove it by natural induction over lengths
of walks. We can show that two nodes connected by a walk are also connected
by a path that is at most as long as that walk. Now in the induction step we
consider a walk w0w1 . . . wn. If the walk is already a path we are done. If it
is not a path it must be possible to identify a cycle wi . . . wj with i, j ⩽n in
it. We can erase the tail wi+1 . . . wj of that circle from w0w1 . . . wn yielding
a shorter walk w0w1 . . . wiwj+1 . . . wn. By the induction hypothesis we then
know that there must exist a path that connects w0 and wn. We conduct the
proof more accurately in Lemma 4.25 in terms of whole covers reachable from
a start node.
Lemma 4.25 (Central Cover Lemma) Given a digraph G = ⟨VG, EG⟩
and a node v ∈VG we have that
CoverG(v) = π-CoverG(v)
(4.62)
Proof. Each path p ∈π(⊕WG(v)) is a walk, i.e., p ∈⊕WG(v). Therefore,
CoverG(v) ⊇π-CoverG(v) follows immediately. It remains to be shown that
also CoverG(v) ⊆π-CoverG(v). We do so by showing that all ﬁnite slices of
the cover are subsets of the path cover. A ﬁnite slice of a cover is simply a
subset of the cover resulting from all reduction walks of a given ﬁnite length.
For a node v and a number n we denote the cover slice by CoverG,n(v) as
follows:
CoverG,n(v) = κ(nWG(v))
Given a cover slice Covern(v) we say that n is the reduction length of the
cover slice. Now, we have that
CoverG(v) =

n∈N0
CoverG,n(v)
Therefore, it suﬃces to show that CoverG,n(v) ⊆π-CoverG(v) for all n. We
do so by natural induction on the reduction length of cover slices.
In Case of n=0: We know that CoverG,0(v) consists of the single node v.
We know that the walk (vi)i∈{0} is a path and therefore also v ∈π-CoverG(v).
From this CoverG,0(v) ⊆π-CoverG(v) follows immediately.
In Case of n ⩾1:
We can assume that CoverG,n(v) ⊆π-CoverG(v). In
order to prove that CoverG,n+1(v) ⊆π-CoverG(v) we need to show that
for all w and w′ with w ∈CoverG,n(v) and ⟨w, w′⟩∈EG we have that
w′ ∈π-CoverG(v). For this, it suﬃces to show that there exists a path p′
from v to w′, i.e.,

4.5 Central Graph Cover Lemmas
117
∃n′ ∈N0 . ∃p′ ∈π(n′WG(v)) . p′
n′ = w′
(4.63)
First, because of CoverG,n(v) ⊆π-CoverG(v) we know that there exists a
path p from v to w, i.e.,
∃n′′ ∈N0 . ∃p ∈π(n′′WG(v)) . pn′′ = w
(4.64)
We can distinguish exactly two cases now, i.e., the case that w′ is diﬀerent
from all nodes that have appeared in the path p so far and the case that
w′ already appeared in p. Let’s turn to the ﬁrst case. From the fact that
⟨w, w′⟩∈EG and w′ is diﬀerent from all other nodes in p we know that the
walk p′ = (p′
i)i∈{0,..,n′′+1} with p′
i = pi for all i ⩽n′′ and p′
n′′+1 = w′ is a
path with reduction length n′′ +1 and therefore Eqn. (4.63) is satisﬁable with
n′ = n′′ +1 in this case. Next, let us turn to the case that w′ already appeared
in the path p. We can assume that it appeared at reduction length n′′′ ⩽n′′.
Now, we know that p′ = (p′
i)i∈{0,..,n′′′} with p′
i = pi for all i ⩽n′′′ is a path
with pn′′′ = w′ and reduction length n′′′. Again, Eqn. (4.63) is satisﬁable with
n′ = n′′′.

Theorem 4.26 (Computability of the Finite Cover) Given a k-ary di-
graph G = ⟨VG, EG⟩, such that the function v∈VG →{⟨v, v′⟩∈E} is total com-
putable. Then, CoverG(v) is computable for all v ∈V for which CoverG(v)
is ﬁnite, i.e., the following partial function is computable:
v ∈V →

CoverG(v)
, CoverG(v) is finite
⊥
, else
(4.65)
Proof. First, we deﬁne a recursive algorithm cover that is intended to compute
existing ﬁnite covers of nodes as follows:
cover : VG ↛F(VG)
(4.66)
cover′ : F(VG) × VG ↛F(VG)
(4.67)
cover(v) = cover′(∅, v)
(4.68)
cover′(M, v) =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
M
, v ∈M
M ∪{v}
, {⟨v,v′⟩∈EG}=∅

⟨v,v′⟩∈E
cover′(M ∪{v}, v′) , else
(4.69)
Note, that, given a set S, the set F(S) ⊆P(S) denotes the set of ﬁnite subsets
of S. We will show that cover(v) terminates and correctly computes the cover
of a given node v if the cover of v is ﬁnite and fails to terminate if the cover
of v is inﬁnite.
Intuitively, the intention of the algorithm is clear. The algorithm dovetails,
via the helper function cover′, all possible walks starting from a given node

118
4 Termination Behavior
n and stops each walk whenever it encounters a node that has already been
visited by this walk. This way, the algorithm steps through all possible paths
starting from a node and collects all the nodes to be yielded as the ﬁnal result
– it is the ﬁrst parameter of cover′ that serves as an accumulator for the
ﬁnal result. Furthermore, if there is an inﬁnite path, which is true in case the
cover is inﬁnite, the algorithm fails to terminate. Up to now we have described
that the algorithm correctly computes ﬁnite path covers. Now, Lemma 4.25
applies. Lemma 4.25 states that the cover of a node equals its path cover.
Therefore, the algorithm correctly computes ﬁnite covers.
We proceed showing both parts of the claim, i.e., ﬁrst termination and
correctness in case of ﬁnite covers and then, second, non-termination in case
of inﬁnite covers.
(Termination and Correctness) First, we deﬁne the following function:
c′(M, v) = M ∪κ({ p | p ∈π(⋆WG(v)), κ(p) ∩M = ∅})
(4.70)
Now, as a ﬁrst step, we show that cover′(M, v) terminates in case CoverG(v)
is ﬁnite and then computes c′(M, v) for all M ⊆VG and nodes v ∈VG. Let us
assume that the size of the cover, |CoverG(v)|, equals n. We know that the
sequence length of a path p equals its size, i.e., #(p) = |p|. Therefore we know
that the sequence length of each path in π(⊕WG(v)) must be smaller than
or at most equal to n. We can exploit this to prove the supposed property
of cover′. We conduct the proof for all nodes v that have a ﬁnite cover, by
natural induction on the size n of such v.
In Case of n=1:
We need to consider three cases corresponding to the
three clauses in the deﬁnition of cover′ in (4.69). In case v ∈M we know that
cover′(M, v) terminates with cover′(M, v) = M = M ∪{v}. Furthermore, we
then know that κ(p) ∩M ̸= ∅for all p ∈π(⋆WG(v)) and therefore we also
know that κ({ p | p ∈π(⋆WG(v)), κ(p) ∩M = ∅}) is empty. From this follows
that c′(M, v) = M = M ∪{v} and therefore cover′(M, v) = c′(M, v).
In the next case we have v ̸∈M and {⟨v, v′⟩∈E}=∅. In that case we know
that cover′(M, v) terminates with cover′ = M ∪{v}. Furthermore, we know
that in this case (vi)i∈{0} is the only path in ⋆WG(v). Therefore we know that
κ({p|p ∈π(⋆WG(v)), κ(p) ∩M = ∅}) equals {v} and therefore c′(M, v) equals
M ∪{v} so that again cover′(M, v) = c′(M, v).
Now, let us assume that the third case applies, i.e., v ̸∈M but there
exists ⟨v, v′⟩∈EG. Now, due to the current induction case we know that
|CoverG(v)| = n = 1. Therefore, we know that the only edge ⟨v, v′⟩∈EG is
the edge ⟨v, v⟩. Therefore, we know that cover′(M, v) = cover′(M ∪{v}, v).
Now the ﬁrst clause of Eqn. (4.69) applies to cover′(M ∪{v}, v), so that
cover′(M ∪{v}, v) = M ∪{v} and therefore also cover′(M, v) = M ∪{v}. Fur-
thermore, we know that (vi)i∈{0,1} = vv is the only path in ⋆WG(v) in this
case. Therefore we know that κ({p|p ∈π(⋆WG(v)), κ(p) ∩M = ∅}) equals {v}
and therefore c′(M, v) = M ∪{v} so that again cover′(M, v) = c′(M, v).

4.5 Central Graph Cover Lemmas
119
In Case of n⩾2: Again, we need to consider three cases. However, the proof
for the ﬁrst case is completely equal to the induction case of n = 1 above.
The second case can actually not appear in case |CoverG(v)| = n ⩾2, because
there must exist a node v′ ̸= v that is reachable from v via an edge. Let us
turn to the third case, in which we have that v ̸∈M but {⟨v, v′⟩∈E}̸=∅. By
the premises of the lemma we know that ⟨v, v′⟩∈E is computable for each v′.
Therefore, cover′(M, v) can be computed and equals:

⟨v,v′⟩∈E
cover′(M ∪{v}, v′)
(4.71)
Now, we know for all v′ with ⟨v, v′⟩∈E that the maximum length of its paths
is reduced by one, i.e., #(π(⋆WG(v′))) < #(π(⋆WG(v))). Therefore, by the
induction hypothesis we know for each v′ that cover′(M ∪{v}, v′) terminates
with the value of c′(M ∪{v}, v′) so that Eqn. (4.71) equals

⟨v,v′⟩∈E
c′(M ∪{v}, v′)
(4.72)
Now, due to Eqn. (4.70) we have that Eqn. (4.72) equals

⟨v,v′⟩∈E
M ∪{v} ∪κ({ p | p ∈π(⋆WG(v′)), κ(p) ∩(M ∪{v}) = ∅})
(4.73)
Now, Eqn. (4.73) can be rewritten immediately as follows:
M ∪

⟨v,v′⟩∈E
κ({ v • p | p ∈π(⋆WG(v′)), κ(p) ∩(M ∪{v}) = ∅})
(4.74)
Now, we know that v • p is a path if and only if p is a path and v does not
occur in p, i.e., v ̸∈κ(p). Therefore, we can rewrite Eqn. (4.74) as follows:
M ∪κ({ v • p | v • p ∈π(⋆WG(v)), κ(p) ∩M = ∅})
(4.75)
Now, we can again exploit the fact that v ̸∈M, which holds in the currently
considered case. Therefore, we have that Eqn. (4.75) equals
M ∪κ({ q | q ∈π(⋆WG(v)), κ(q) ∩M = ∅})
(4.76)
Finally, due to the deﬁnition of c′, see Eqn. (4.70), we know that Eqn. (4.76)
equals c′(M, v).
Now, we have ﬁnished the induction proof and know that cover′(M, v)
terminates and equals c′(M, v) for all v that have a ﬁnite cover. Next, by the
deﬁnition of c′, we know that the following holds for all nodes:
c′(∅, v) = ∅∪κ({ p | p ∈π(⋆WG(v)), κ(p) ∩∅= ∅}) = π(⋆WG(v))
(4.77)

120
4 Termination Behavior
Given Eqn. (4.77) we have already shown that cover correctly computes the
path cover π(⋆WG(v)) for v that have a ﬁnite cover. Now, by the central cover
Lemma 4.25 we know that the cover of a node equals its path cover. Therefore
we also know that cover correctly computes the cover ⋆WG(v) for all v that
have a ﬁnite cover.
(Non-Termination) To complete the proof, we need to show that the algo-
rithm cover fails to terminate in case of inﬁnite covers. Given a node v so that
CoverG(v) is inﬁnite. Then, due to the fact that G is k-ary, by König’s Lemma,
see Lemma 2.39, we know that there exists an inﬁnite path ω ∈π(ωWG(v))
starting from v = ω0. For ω we know that ωi+1 is not an element of the set
{ω0, . . . , ωi} for all i, because ω is a path. Therefore, there exists the follow-
ing inﬁnite series of recursive calls, which amounts to the non-termination of
cover(v):
cover′(∅, ω0)  cover′({ω0}, ω1)  . . .  cover′({ω0, . . . , ωi−1}, ωi)  . . .
(4.78)

Let us proceed with some remarks on the proof conducted for Theorem 4.26
and the deﬁnitions it establishes. First, the notation f  f ′ in Eqn. (4.78) is an
ad hoc pseudo-notation that indicates that a function call f leads to a further
function call f ′. Then, the condition {⟨v, v′⟩∈E} = ∅in the second clause
of Eqn. (4.69) can be rewritten in more convenient form as ∄v′.⟨v, v′⟩∈E. It
has got the chosen form just because it equals the big union comprehension
in the third clause of the deﬁnition this way. For the application of our lemma
to the reduction graph later, the second clause is even non-relevant, because
in our reduction graph, each node has at least one outgoing node. For the
general case of arbitrary digraphs, the second clause is indispensable. The
function c′ yields the nodes of all paths that do not contain a node from M.
Note that the deﬁnition of cover′ does not exclude nodes from a path just
because it extends to a longer path that eventually contains some nodes from
M. This means that if we have a path a1 · · · aiamai+2 · · · with am ∈M but
a1, . . . , ai ̸∈M we still have that a1, . . . , ai belong to c′(a1, v) just because
a1 · · · ai is also a path in ⋆WG(v).
4.6 Path Stoppability
In this section we introduce a broadened notion of termination for programs
of the probabilistic lambda calculus, which we call path stoppability. It relies
on the notion of term covers and characterizes a class of programs for which
we can determine the degree of termination, albeit they might possess some
non-terminating program runs. A term cover of a program is simply the set
of terms that can be reached by any of its program runs. We use the concepts
introduced in the preceding sections to formally deﬁne the concept of term

4.6 Path Stoppability
121
covers. Term covers are just graph covers of the reduction graph R. Given a
program M, we deﬁne its term cover as its graph cover CoverR(M) with M
taken as start node. Often, we talk of the term cover of a program simply
as its cover. Occasionally, we also drop the name of the reduction relation
and denote a term cover CoverR(M) simply as Cover(M). We do so, e.g., in
Table 4.2.
Let us turn to the central result. The degree of termination is computable
for programs with ﬁnite term covers. The algorithm consists of three steps:
•
Compute the ﬁnite term cover, if it exists.
•
Generate a linear equation system that describes the hitting probabilities
of ever hitting a constant for all involved terms from the ﬁnite cover. A
ﬁnite linear equation system can always be found in case of ﬁnite covers.
•
Solve the linear equation system to ﬁnd its least solution. In case of a ﬁnite
equation system, its least solution can always be determined algorithmi-
cally by Gauss-Jordan elimination.
The computation of ﬁnite covers in the above result is just an application
of the computability of graph covers, see Theorem 4.26, to the case of the
reduction graph. Then, the computability of termination degrees is just a
consequence of Gauss-Jordan elimination. Next, it is the task of Theorem 4.27
to give a formal account of the computability of termination degrees.
Theorem 4.27 (Computability of Termination Degrees) The degree of
termination is computable for all programs that have a ﬁnite term cover, i.e.,
the following partial function is computable:
δ = M ∈ΛP →

ηS⟨M, C⟩
, CoverR(M) is ﬁnite
⊥
, else
(4.79)
Proof. Once more, note that ηS⟨M, C⟩equals PM(ε(T (M))). By Theorem 4.26
we know that CoverR(M) is computable in case it is ﬁnite. Therefore, as the
ﬁrst step we compute CoverR(M). Next, by Def. 4.1 and Theorem 2.29 we
know that the vector of termination degrees (ηS⟨M, C⟩)M∈ΛP is the least
solution of the following inﬁnite equation system:
∀c ∈C . ηS⟨c, C⟩= 1
∀N ̸∈C . ηS⟨N, C⟩=

N ′∈ΛP
(N →N ′) · ηS⟨N ′, C⟩
(4.80)
Due to the fact that CoverR(M) is ﬁnite we can reduce the equation
system (4.80) to an equivalent ﬁnite version. To see this, we bring the equation
system (4.80) into a diﬀerent form, now consisting of four subsystems:
∀c∈C\CoverR(M).ηS⟨c, C⟩= 1
(4.81)

122
4 Termination Behavior
∀N ′ ∈ΛP \C\CoverR(M).ηS⟨N ′, C⟩=

N ′′∈ΛP
(N ′ →N ′′) · ηS⟨N ′, C⟩(4.82)
∀c∈CoverR(M)∩C.ηS⟨c, C⟩= 1
(4.83)
∀N ∈CoverR(M)\C.ηS⟨N, C⟩=

N′∈
CoverR(M)
(N →N ′) · ηS⟨N ′, C⟩+

N′̸∈
CoverR(M)
(N →N ′) · ηS⟨N ′, C⟩
(4.84)
The subsystems (4.81) and (4.82) single out equations that give hitting
probabilities for programs that are not in the cover. Subsystems (4.83) and
(4.84) contain the remaining equations. Now, consider subsystem (4.84). Here
the second sum, which iterates over programs that are not in the cover, sums
up to zero, because each single summand is zero. To see this, consider the
probability N →N ′ in the sum. We know that for each of the summands, N
is in the cover, whereas N ′ is not. Now, the fact that N is in the cover implies
that there is a path Mt1t2 · · · tn−1N from M to N. Now, if N →N ′ were
diﬀerent from zero there would exist a path Mt1t2 · · · tn−1NN ′ from M to
N ′, which we know is not true due to the iterator condition N ′ ̸∈CoverR(M)
of the sum. Therefore, N →N ′ must be zero. Therefore, we can drop the
second sum from all equations in subsystem (4.84). Furthermore, we see that
all left hand side variables of subsystems (4.81) and (4.82) are neither directly
relevant to the eventual object of interest, which actually consists only of
a single variable, i.e., ηS⟨M, C⟩, nor do they occur in any of the equations
of the subsystems (4.83) and (4.84). Therefore, also subsystems (4.81) and
(4.82) can be dropped without loss for the determination of the ﬁnal solution.
Therefore, eventually we can transform the equation system (4.80) into the
following equivalent equation system:
∀c∈CoverR(M)∩C.ηS⟨c, C⟩= 1
∀N ∈CoverR(M)\C.ηS⟨N, C⟩=

N′∈
CoverR(M)
(N →N ′) · ηS⟨N ′, C⟩
(4.85)
Now, due to the fact that CoverR(M) is ﬁnite we also know that the
equation system (4.85) is ﬁnite. Now, for each ﬁnite linear equation system, it
is possible to compute the least solution vector, e.g., by transformation to row
echelon form by application of the Gauss-Jordan algorithm; see, e.g., [43, 189].

The class of programs that have a ﬁnite cover deﬁnes a widened notion
of termination that can also be characterized in terms of the core algorithm
used to determine the cover of programs; see Def. 4.28. We coin the term path

4.6 Path Stoppability
123
stoppability, also called p-stoppability, for this concept. Where the existence
of a ﬁnite cover is a rather declarative notion, the notion of p-stoppability
is a rather operational notion. Obviously, the notion of p-stoppability and
the existence of a ﬁnite cover are equivalent, as expressed by Lemma 4.29. A
program is path stoppable, or p-stoppable, in case it has a ﬁnite cover.
Deﬁnition 4.28 (Path Stoppability) A program M is p-stoppable
iﬀ
applying the path-stopping algorithm π to M terminates, i.e., if π(M) termi-
nates, where π is deﬁned as follows:
π : ΛP ↛1
(4.86)
π′ : F(ΛP ) × VG ↛1
(4.87)
π(A) = π′(∅, A)
(4.88)
π′(A, v) =
⎧
⎨
⎩
1
, M ∈A

⟨M,M′⟩∈E
π′(A ∪{M}, M ′)
, v ̸∈A
(4.89)
Corollary 4.29 (Path Stoppability and Finite Covers) A program M
is path stoppable, i.e., π(M) terminates, iﬀits cover CoverR(M) is ﬁnite.
Proof. Corollary from Def. 4.28 and Theorem 4.26. Basically, the algorithm
π : ΛP ↛1 in Def. 4.28 mimics the algorithm cover : VG ↛F(VG) in
Theorem 4.26.

Now that we have coined the term path stoppability for programs, we also
use it for single program runs. We call those program runs path stoppable that
are not paths, i.e., that contain a cycle; see Def. 4.30. The intuition behind
this should be clear. Each walk that is not a path is eventually stopped by the
algorithm cover in Theorem 4.26. It is executed by cover as long as it is a path,
i.e., its longest path preﬁx is executed. As soon as cover discovers that one
of the program executions that it maintains is a cycle, it stops this program
execution. This also explains why we have chosen to name the established
notion of stoppability as path stoppability. If all program runs eventually run
into cycles during simultaneous execution by cover, the whole program is
stoppable. This is also expressed by the following easy Lemma 4.31.
Deﬁnition 4.30 (Path Stoppability of Program Runs) A program run
p ∈P(M) is path stoppable, also called p-stoppable, iﬀp is not a path in the
reduction graph, i.e., p ̸∈π(P(M)).
Corollary 4.31 (Path Stoppability of Programs) A program M is path
stoppable
iﬀall of its program runs are path stoppable.
Proof. Corollary from Defs. 4.28 and 4.30 and Theorem 4.26.

We proceed with the fact that a program with an inﬁnite cover necessarily
possesses a non-terminating program run, as expressed in Lemma 4.32. Re-
member that Lemma 4.32 is needed as one of the essential Lemmas in our
analysis of termination behavior; compare with Table 4.3 and Sect. 4.1.2.

124
4 Termination Behavior
Lemma 4.32 (Inﬁniteness of Covers and Non-Termination) If a pro-
gram M has an inﬁnite cover then it has a non-terminating program run.
Proof. If a program M has an inﬁnite cover we know by König’s Lemma, i.e.,
Lemma 2.39, that M has an inﬁnite path, i.e., there exists q ∈π(P(M)). Due
to Corollary 4.21 we know that all p ∈π(P(M)) are non-terminating and
therefore also p is non-terminating, i.e., p ̸∈T (M).

Path Computability
We can adapt the result from Theorem 4.27 to the computation of reduction
probabilities M ⇒N. For this purpose, we deﬁne the partial function ⇒p
for arbitrary programs M and N, called path computation of M ⇒N or
p-computation for short, as follows in Def. 4.33.
Deﬁnition 4.33 (Path Computation)
We deﬁne the partial function
_ ⇒p _ : ΛP × ΛP →[0, 1], called path computation or p-computation, for all
program M and N as follows:
M ⇒p N →

M ⇒N
, CoverR(M) is ﬁnite
⊥
, else
(4.90)
Along the lines of Theorem 4.27 we have that also path computation is
a computable function, which justiﬁes its name. As in the argumentation
preceding Theorem 4.27 the computation is about determining the ﬁnite term
cover of M, if it exists, and then generating and solving an appropriate linear
equation system.
Path Stoppability and Program Analysis
Path stoppability is a form a program analysis. It can also be, somehow,
related to the ﬁeld of static program analysis [262]; compare also with [71,
198, 199, 53] for some important examples from the ﬁeld of probabilistic com-
putation. In the ﬁeld of static program analysis we try to ﬁgure out useful
properties of a program before, or let’s say independent of, run-time. Prop-
erties might be measures from the ﬁeld of software quality, i.e., code quality.
In principle, all kinds of non-functional requirements, i.e., concerning perfor-
mance, interoperability, maintainability or, in particular, IT security, might be
subject to static program analysis. However, also functional requirements, i.e.,
correctness criteria, might be checked with static program analysis. Usually,
we would rather expect that the properties investigated by static program
analysis are decidable properties. Then, a good approach is to characterize
the ﬁeld of static program analysis in terms of compiler construction [5, 216]
terminology. Then, static program analysis might be deﬁned as the ﬁeld of
context-sensitive as opposed to context-free program properties. Then, the

4.6 Path Stoppability
125
type system of a language would be an important, albeit reductionist exam-
ple of static program analysis. However, all that said, we are not sure whether
decidability should be considered a necessary ingredient of static program
analysis at all. In any case, note that path stoppability is a semi-decidable
notion. In that sense, we would not say that path stoppability is an instance
of static program analysis. Nevertheless, it is a form of program analysis, and
as such, it is a very important one, both theoretically and practically.
Path stoppability is a severe notion of program analysis. It takes termina-
tion behavior as its subject of investigation. It deﬁnes a class of probabilistic
programs that might be trapped in a non-terminating program run and pro-
vides an algorithm for their identiﬁcation and for the calculation of their ter-
mination degrees. The fact that path stoppability is semi-decidable does not
hurt too much, just because the subject of investigation is termination, or to
say it even better, non-termination. This can be seen best in the special case
of deterministic programs. Of course, path stoppability can also be applied
to deterministic programs. Let us assume that you apply the cover algorithm
to a non-terminating program, let us call it the object program, before you
actually run the program. If the object program run has a ﬁnite cover, then
the cover algorithm will stop and you have won something, because you will
not try to execute the object program with its original operational semantics
any more. If the object program has an inﬁnite cover, of course, the cover
algorithm will not terminate any more due to its semi-decidability. But this
does not hurt, because you have not lost anything: the object program with
its original operational semantics would also not terminate.
Now, a similar argument as in the special case of deterministic programs
can be constructed for the general case of probabilistic programs. Here, con-
ducting the test for path stoppability in advance, before we actually execute
the object program, can have the eﬀect that we lose some outcomes in case of
a program with inﬁnite cover. We will wait for the termination of the cover
algorithm forever; however, if we had executed the object program we might
have observed a positive outcome. Actually, maybe the object program even
has a termination degree of one. Remember that we have seen an example of
a program with termination degree one that has a non-terminating program
run. In such a case the chance that we miss an outcome is a 100 per cent.
However, executing the program analysis in advance is just a wrong, or
let’s say misleading, thought experiment. We have been guided by our pre-
occupation with static program analysis. Still, it makes sense to conduct the
path stoppability analysis independent of the actual program execution. Let’s
just assume that we conduct the program analysis in parallel with the actual
program analysis. Let’s neglect the extra computing resources for doing so.
In practice, of course, we cannot neglect them, in particular, because the
path stoppability analysis actually requires signiﬁcant resources. However, if
we neglect the necessary extra resources, the semi-decidability of our program
analysis again does not hurt, as in the case of deterministic programs described

126
4 Termination Behavior
above. If the analysis terminates, we can stop the whole execution. If the
analysis does not stop, it does not hurt.
Now, if the task is to investigate the degree of termination of a given pro-
gram, executing the program analysis does not hurt at all, even if we also take
into account the needed computing resources. In any case, we need to simulate
on the basis of the given program, i.e., we have to dovetail its program runs.
So, in that scenario the parallel execution of the path stoppability analysis
comes at no price, it can be masked into the running simulation in that case.
All of the above discussion is, of course, quite narrative. But we hope
that it already shows the practical relevance of path stoppability and gives an
impression of its use cases.
Strength of Path Stoppability
The class of programs characterized by path stoppability is quite large. And it
can be considered as strong, because not only does it yield information about
the termination behavior of a program, but its result can also be exploited
to determine the degree of termination of the program, of course, only in
case that the program analysis terminates. In a sense, it can be considered as
strong, because the cover algorithm works for the largest class of programs
for which Gauss-Jordan elimination can be exploited, i.e., the class of all pro-
grams that have ﬁnite term cover. Of course, the notion of termination can
be further broadened, arbitrary kinds and arbitrarily many possible exten-
sions are imaginable, and among those, there are surely many very practical
notions. Here, we enter the ﬁeld of abstract interpretation and related dis-
ciplines. However, the class of program characterized by path stoppability is
particularly natural.
It is always the same with program analysis. To get the point take the
brutal case of total termination as a program analysis property. This means
we are interested in analyzing whether a program terminates. Here, it is a
minor point whether we are interested in the question for all of its possible
input data or some, or even a single input datum. Now, as we all know, total
termination is not decidable, i.e., there is no algorithm that always terminates
and correctly analyses whether the given object always terminates. However,
this should not demotivate us to ﬁnd better and better analyses for program
termination. This means that if we cannot ﬁnd the absolute algorithm it
nevertheless makes sense to implement approximations to it. For example, in
case of termination analysis, it adds value to parse a program for obvious
endless loops. By data ﬂow analysis we can ﬁnd better and better means to
detect endlessly looping call structures.
The discussion that we just conducted is an informal discussion. All of
the crucial categories that we have used in the above discussion to describe
program analysis such as size, strength, optimality etc. are necessarily vague.

4.7 Program Reduction Trees
127
4.7 Program Reduction Trees
The reduction trees introduced in this section are a natural notion. Reduction
trees are a common device in the analysis of reduction systems. They are so
common that they are often introduced directly, without mention of the notion
of reduction graph. However, for us, the distinction of reduction graphs and
reduction trees is important, because the two structures are used for diﬀerent
purposes of program analysis.
4.7.1 Intuition Behind the Reduction Tree Construction
We will deﬁne a redution tree, denoted by τ[M], for each program M. A
reduction tree τ[M] turns reduction walks in R into reduction paths. If a
reduction walk contains a cycle from a term N back to N, a new node is
generated for each repeated occurrence of N in this walk. To see how this works
have a look at Fig. 4.1. The left-hand side of the ﬁgure shows the reduction
graph of μλx.x|0, or, to be more precise, the part of the reduction graph
R that contains all walks starting from μλx.x|0. The right-hand side shows
the corresponding reduction tree τ[M]. In the reduction graph each term M
uniquely identiﬁes a node of the graph. This is not so in the reduction tree.
Here, the terms are rather the label or let us say the content of a node. The
term μλx.x|0, the term (λx.x|0)|μλx.x|0 and the term 0 all appear inﬁnitely
many times in the tree, however, each appearance of one of these terms stands
for a distinct node. It would be possible to distinguish the nodes explicitly in
the tree, e.g., by using indices like [μλx.x|0]′, [μλx.x|0]′′, [μλx.x|0]′′′ and so
forth for the single occurrences of [μλx.x|0]. However, it is usual to save such
extra eﬀorts when a path is shown. Nevertheless, when we step from graph to
walks it is our task to equip the terms with the necessary extra identities.
As we have said, reduction trees are a usual means to visualize or analyze
the reductions of a reduction system. If a deterministic notion of reduction is
ﬁxed for a reduction system, its reduction trees are single paths. This is so
whenever we ﬁx a concrete evaluation strategy for the lambda calculus or a
functional programming language and this is also so for PCF [223]. However,
in general, the reduction to a term is not unique in a reduction system. Then
it makes sense to consider the set of possible reductions as a tree. Usually,
the reduction tree is introduced directly, without the need to introduce or
even to mention a notion of reduction graph. Then, it is taken as implicit
that occurrences of terms in example paths stand for diﬀerent nodes. It might
not even be worth mentioning, because this somehow follows from the fact
that the considered objects are paths, and not arbitrary walks. However, for
us, the distinction is important. The notion of reduction tree would not have
been appropriate for us to prove the propositions of Sect. 4.6 on path stop-
pability of programs. The notion of path stoppability relies on the distinction
between reduction walks, which may have cycles, and reduction paths, which
do not have cycles. However, in a reduction tree, all walks are paths. On the

128
4 Termination Behavior
POx.x|0 
(Ox.x|0)(POx.x|0) 
(POx.x|0)|0
0
POx.x|0 
(Ox.x|0)(POx.x|0)
(POx.x|0)|0 
POx.x|0 
(Ox.x|0)(POx.x|0) 
(POx.x|0)|0 
POx.x|0 
(Ox.x|0)(POx.x|0) 
(POx.x|0)|0 
0
0
0
Fig. 4.1. Reduction graph and reduction tree compared
other hand, we need the notion of reduction trees to prove other properties
of program behavior for which the reduction graph is not the optimal tool.
For example, we will exploit the notion of reduction tree to prove that ev-
ery unbounded program necessarily has a non-terminating program run in
Lemma 4.39.
4.7.2 Program Runs in Reduction Graphs and Trees
The most basic diﬀerence between reduction graphs and reduction trees is
that all walks in the reduction tree are paths. Of course, cycles in reduction
walks can be maintained in the reduction tree, because they can be retrieved
from the terms contained in nodes, however, in the reduction graph, walks
that are not paths are immediately distinguished from paths. Now, there is
another crucial diﬀerence between reduction graphs and reduction trees. It
is about how program runs are represented in a reduction graph and how
they are represented in a reduction tree. In a reduction graph, all program
runs are represented by the inﬁnite walks in the graph. Terminating program
runs are those that eventually reach a constant and non-terminating program
runs are those that never reach a constant. Nevertheless, both the terminat-
ing and the non-terminating program runs are modeled as inﬁnite walks. The
ﬁnite walks in the graph are never considered as program runs themselves,
they always only serve as approximations to program runs. This is diﬀerent

4.7 Program Reduction Trees
129
in program trees. Here, all walks are paths. The inﬁnite paths in a reduction
tree are exclusively used to represent non-terminating program runs. Conse-
quently, a terminating program run always corresponds to a ﬁnite path in the
reduction tree. This one-to-one identiﬁcation of termination with ﬁniteness
strongly meets our intuition of program behavior and makes the strength of
reduction trees in proofs. To see this correspondence, once more have a look
at the program example in Fig. 4.1. The program μλx.x|0 has two kinds of
program runs, one non-termination program run that is kept in a cycle always
returning to μλx.x|0, and inﬁnitely many program runs that terminate with
zero. The non-terminating program run is turned into the unique inﬁnite path
in τ[M] seen as the spine of the tree in Fig. 4.1. The inﬁnitely many termi-
nating program runs are turned into inﬁnitely many ﬁnite paths in τ[M] each
ending with a node that contains 0 as term.
We have seen earlier that the notion of program run has diﬀerent repre-
sentations. We have deﬁned program runs in the σ-algebra, which is an event.
A program run in the σ-algebra is a largest set of program executions that
cannot be distinguished further only by means of the Markov chain semantics.
Then, a program run in a graph is an inﬁnite sequence of terms and is therefore
an inﬁnite walk in the reduction graph. Now we have a third representation
of program run, i.e., a certain kind of path in the program reduction tree.
To avoid confusion we usually talk about a tree program run if we mean the
presentation of a program run in a tree, whereas we rather often talk about a
program run in a graph simply as a program run.
4.7.3 Construction of the Reduction Tree
In order to equip terms with the necessary extra identities to become tree
nodes, we simply take the ﬁnite walks of the reduction graph R as nodes
in reduction trees. However, not all of the walks of the reduction walk are
included in the set of nodes of the reduction tree. This is so, because we
want to anticipate the strict match between terminating program runs and
ﬁniteness of corresponding paths in the tree. Therefore, only those ﬁnite walks
in which a constant appears at most once are taken as nodes of a reduction
tree.
Given a program M the nodes of the reduction tree τ[M] are the walks
in R starting with M and containing a constant at most once. Two kinds of
walks are taken as nodes. The ﬁrst kind of walk does not contain a constant.
The second kind of walk does contain a constant, but at most once. If a ﬁnite
walk contains a constant at most once, this constant must necessarily be the
last term of the walk. The walks that contain a constant at most once will
serve as leaves in reduction trees, as can be seen in Fig. 4.1. The walks that
contain no constant will always be inner nodes of a reduction tree.
Each node in the reduction tree is a walk in the reduction graph. Given a
node v in the reduction tree, we call its least element M, i.e., the least element
of the tree node taken as a graph walk, the term contained in v or the term

130
4 Termination Behavior
represented by v. We then also simply say that M is the term of v. Now, we
deﬁne that an edge between two tree nodes v and v′ exists if and only if there
exists an edge between the two terms contained in v and v′ in the graph R or,
equally, if and only if there exists a transition between the terms contained in
v and v′ in the one-step semantics.
Now, given a path in a reduction tree, we say that the path contains a
term M if the term M is contained by one of its nodes. Furthermore, we call
the term contained in the last node of a path the term reached by this path.
Of course, the terms reached by paths are the leaves of the tree.
Deﬁnition 4.34 (Program Reduction Tree) Given a program M we de-
ﬁne its program reduction tree, denoted by τ[M], as the rooted directed tree
τ[M] = ⟨V, E, r⟩as follows:
V ⊆⋆WR(M)
(4.91)
V = {m0 · · · mn ∈⋆WR(M) | ∀i < n . mn ̸∈C}
(4.92)
E = {⟨m0 · · · mn , m0 · · · mnmn+1⟩| ⟨mn, mn+1⟩∈ER}
(4.93)
r = (M)i∈{0}
(4.94)
Actually, the deﬁnition of reduction trees in Def. 4.34 must be shown to be
well deﬁned. The deﬁnition contains the implicit proposition that the structure
⟨V, E, r⟩it deﬁnes is actually a rooted tree. Obviously, the structure ⟨V, E⟩
is a digraph and r is a designated element in this digraph. Now, in order to
show that τ[M] is a rooted tree with r as root, it remains to show that τ[M]
is acyclic and each node v ∈V which is diﬀerent from the root is connected to
the root by a unique path. This can be seen by the deﬁnition of the edges E
and can be proven, formally, by induction on the length of walks underlying
the nodes in V .
As we have described in Sect. 4.7.2 we now deﬁne tree program runs,
terminating program runs and non-terminating tree program runs. Given a
program M its non-terminating tree program runs are the inﬁnite paths in
its reduction tree starting from M, whereas its terminating program runs are
the ﬁnite paths in the reduction tree starting from M that contain a constant.
Now, the program runs of M consist of its terminating plus its non-terminating
program runs.
First, note that it suﬃces to describe the terminating program runs as
paths that contain a constant, i.e., it is not necessary to say that they contain
a constant at most once. By the deﬁnition of nodes and edges of reductions
it is already guaranteed that a path that contains a constant does not con-
tain that constant more than once. Furthermore, note that it is necessary
to deﬁne the set of program runs explicitly as the union of terminating and
non-terminating program runs. All of the inﬁnite paths in the tree represent
a program run, whereas ﬁnite tree paths that contain no constant can be
considered as approximations to program runs.
Let us turn to the deﬁnition of the several kinds of tree program runs in
Def. 4.35. Recall that we use [s]▶to denote the last element of a sequence s.

4.8 Characteristics of Bounded Termination
131
Deﬁnition 4.35 (Tree Program Runs) Given a program reduction tree
τ[M] = ⟨V, E, r⟩we deﬁne its tree program runs, denoted by Pτ(M), its ter-
minating tree program runs, denoted by Tτ(M) and its non-terminating tree
program runs, denoted by T τ(M) as follows:
Tτ(M) = {v0 · · · vn ∈⋆Wτ[M](M) | [vn]▶∈C}
(4.95)
T τ(M) = ωWτ[M](M)
(4.96)
Pτ(M) = Tτ(M) ∪T τ(M)
(4.97)
Deﬁnition 4.36 (Terms of a Reduction Tree) Given a program reduc-
tion tree τ[M] = ⟨V, E, r⟩, one of its nodes v ∈V and one of its terminating
program runs t ∈Tτ(M). The term of the node v is deﬁned as its last element
[v]▶. The term reached by t is deﬁned as the term of its last node [[t]▶]▶.
By their design, the tree program runs Tτ(M), T τ(M) and Pτ(M) stand in
a one-to-one correspondence to their program run counterparts T (M), T(M)
and P(M). Next, we make this correspondence explicit in two mutually inverse
functions ς : P(M) →Pτ(M) and ς−1 : Pτ(M) →P(M) in the following
deﬁnition Def. 4.37 and Corollary 4.38. Note that in Def. 4.37 we use s • t to
denote the concatenation of sequences s and t.
Deﬁnition 4.37 (Correspondence of Reduction Graphs and Trees)
Given a program M, we deﬁne ς : P(M)→Pτ(M), the interpretation of pro-
gram runs as tree program runs, and ς−1 : Pτ(M)→P(M), the interpretation
of tree program runs as program runs as follows:
ς(w) =

(w0 · · · wi)i∈{ 0 , ... , ∞}
, w ∈T(M)
(w0 · · · wi)i∈{ 0 , ... , ⊓{i | wi∈C} }
, w ∈T (M)
(4.98)
ς−1(w) =

([wi]▶)i∈N0
, w ∈T τ(M)
([wi]▶)i∈{ 0 , ... , #(w)−1 } • ([[w]▶]▶)i∈N0
, w ∈Tτ(M)
(4.99)
Corollary 4.38 (Correspondence of Reduction Graphs and Trees)
Given a program M, the program run interpretation ς : P(M) →Pτ(M) and
tree program run interpretation ς−1 : Pτ(M) →P(M) are inverse functions,
i.e.,
ς ◦ς−1 = idP (M)
ς−1 ◦ς = idPτ (M)
Proof. Omitted.
4.8 Characteristics of Bounded Termination
In this section we ﬁnish our analysis of termination behavior. We investigate
how bounded termination relates to the existence of terminating program

132
4 Termination Behavior
runs. We provide the missing propositions to complete the whole picture of
program analysis outlined in Sect. 4.1.1; see Table 4.3. We beneﬁt from all
the technical apparatus that we have introduced in the previous sections such
as bounded termination, program runs in the reduction graph, program runs
in the reduction tree, and the several mutual correspondences.
A program terminates bounded if the length of its terminating program
runs is capped by a maximum length and unbounded otherwise. Now, we
have the following. A program that terminates unbounded necessarily has a
non-terminating program run. Or, to state the contraposition, we have the
following. A program that has only terminating program runs necessarily ter-
minates bounded. The opposite of that fact does not hold in general. However,
for the special case of a termination degree of one, we actually have that the
opposite holds. Therefore, in case a program has a termination degree of one
the above implications turn into equivalences. Then, the program has a non-
terminating program run if and only if it terminates unbounded. Or, to say
it diﬀerently, the program only has terminating program runs if and only if it
terminates bounded. This section is exactly about these two facts, treated in
Lemma 4.39 and Lemma 4.40.
Lemma 4.39 (Unbounded Termination and Non-Termination)
If a
program M terminates unbounded then M has a non-terminating program
run.
Proof. We assume that the reduction tree of M is given as τ[M] = ⟨V, E⟩.
We assume that the program terminates unbounded. We deﬁne an embed-
ding v : N0 →V which proves V to be inﬁnite. Due to the fact that M
terminates unbounded, we know that for all i ∈N0 there exists a termi-
nating program run ti = m0m1 · · · mi−1mi · · · c c c · · · with mj ̸∈C for all
j < i in the reduction graph. For the reduction graph, this fact alone does
not imply the inﬁniteness of the reduction graph, because it is not ensured
that enough of the mjs are distinct. However, in the reduction tree τ[M], the
existence of the program run ti = m0m1 · · · mi−1mi · · · c c c · · · amounts to
a new, distinct node v(i) = m0m1 · · · mi−1mi for each i ∈N0. To see this,
note that the existence of the program run m0m1 · · · mi−1mi · · · c c c · · · im-
plies that m0m1 · · · mi−1mi is a walk in the reduction graph. Therefore, due
to Def. 4.34 the graph walk m0m1 · · · mi−1mi is a node in the reduction tree.
Furthermore, m0m1 · · · mi−1mi must be diﬀerent from all v(j) for all j < i,
simply because it is longer than all of these nodes taken as sequences. There-
fore, it follows that v is injective so that the reduction tree τ[M] is shown to
be inﬁnite. Now, it follows by Beth’s Tree Theorem 2.50 that there exists an
inﬁnite path ω in τ[M]. Due to the existence of the inﬁnite path ω we know
that there exists a non-terminating program run ς−1(ω).

Of course, Lemma 4.39 can also be proven by contraposition. We give an
outline. If a program M has no non-terminating program run, the reduction
tree τ[M] has no non-terminating tree program run due to Corollary 4.38,

4.8 Characteristics of Bounded Termination
133
which means that it has no inﬁnite path. Therefore, due to Beth’s Tree Theo-
rem, see Theorem 2.50, τ[M] has only ﬁnitely many nodes. The ﬁnite number
of nodes of τ[M], let us say n, is also an upper bound of the length of paths of
τ[M], because a path can contain each node at most once. All walks in a tree
are paths and so are the tree program runs. This means that n is also an up-
per bound for the tree program runs of τ[M]. Each terminating program run
t ∈T (M) is mapped to a tree terminating program ς(t). Due to Def. 4.37 we
know that t ∈T (M) is as most as long as ς(t). Therefore, the number of tree
nodes n is also an upper bound for the length of terminating program runs,
which means that program M terminates bounded; compare with Def. 4.3.
Lemma 4.40 (Degree-One and Unbounded Termination)
Given a
program M. If M has termination degree of one and M has a non-terminating
program run then M terminates unbounded.
Proof. We provide a proof sketch ﬁrst. By currying we can rewrite the propo-
sition also as
ηS⟨M, C⟩=1 =⇒(∃t ∈T(M) ⇒¬β(M))
(4.100)
Overall, we assume ηS⟨M, C⟩= 1. Then, we will prove ∃t∈T(M) ⇒¬β(M)
by contradiction, i.e., we will prove ∃t∈T (M) ∧β(M) to be impossible.
We assume that the program has a termination degree of one. Furthermore,
we assume that the program terminates bounded. Therefore, we know that
there exists a bound n ∈N0 such that ηn
S⟨M, C⟩= ηS⟨M, C⟩and therefore
ηn
S⟨M, C⟩= 1. Be Def. 2.23 we have that ηn
S⟨M, C⟩= PM(∃i ⩽n.Si ∈C). We
can see that the set (∀i ⩽n.Si ̸∈C) is the complement set of (∃i ⩽n.Si ∈C).
Therefore we also know the following:
PM(∀i ⩽n.Si ̸∈C) = 0
(4.101)
Now, let us assume that there exists a non-terminating program run t ∈T(M).
Due to the basic Markov chain properties, i.e., Theorem 2.18, due to Def. 2.16
and due to t0 = M we know
PM(S0 =t0 ∩. . . ∩Sn =tn) =
n−1

i=0
(ti →ti+1)
(4.102)
Now, we know that ti →ti+1 > 0 for all i ∈N0, because t is a program run.
Therefore we know
PM(S0 =t0 ∩. . . ∩Sn =tn) > 0
(4.103)
We know that ti ̸∈C for all i ∈N0, because t is a non-terminating program
run. Therefore we know that (S0 = t0 ∩. . . ∩Sn = tn) ⊆(∀i ⩽n.Si ̸∈C).
Therefore we know that PM(∀i ⩽n.Si ̸∈C) ⩾PM(S0 = t0 ∩. . . ∩Sn = tn).
Therefore, and due to Eqn. (4.103), we know that PM(∀i ⩽n.Si ̸∈C) > 0
which contradicts Eqn. (4.101) and therefore completes the proof.


5
Denotational Semantics
In this chapter we deﬁne a denotational semantics for the probabilistic lambda
calculus. We will investigate the correspondence between this denotational
semantics and the Markov chain semantics.
Distinct denotational semantics diﬀer from each other in the domains they
choose as their basis. The choice of mathematical structures depends on the
concrete phenomena that the denotational semantics is intended to exam-
ine and model. Also, the targeted level of abstraction inﬂuences the choice
of domains. The original Scott-Strachey approach was based on complete lat-
tices [243, 253]. A common choice for the domain is a directed complete partial
order [117, 118]. In particular, also the denotational semantics given for PCF
in [223] is based on directed complete partial orders. Another choice often
found is an ω-cpo. They are used as domains, e.g., by [192, 224, 117]. In par-
ticular, if computability is the subject of interest, i.e., if modeling of general-
ized notions of computability is the target, ω-cpos enter the stage. Then, they
come as ω-algebraic cpos, see [224]. Also, our denotational semantics is based
on ω-cpos. For our purposes, they are the ideal basis for denotational seman-
tics. This is so, because our base domains are probability (pre-)distributions,
see Def 5.1, which, of course, have the real numbers as their target domain.
Now, ω-chains of real numbers are, by deﬁnition, monotonically increasing
sequences of real numbers. As such, they are subject to the monotone conver-
gence Theorem of real numbers, which therefore bridges between denotational
semantics and the theory of real numbers.
In Sect. 5.1 we deﬁne the denotational semantics of the probabilistic
lambda calculus, by specifying its domains and giving its semantic equations.
Sect. 5.2 is a technical section that establishes the well-deﬁnedness of the deno-
tational semantics, and provides further semantical tools needed for the anal-
ysis of the denotational semantics. Then, Sect. 5.3 proves the basic correspon-
dence between the denotational and the operational semantics. In Sect. 5.4
we compile a list of important work in the ﬁeld of denotational semantics of
probabilistic programming languages. It is rather an individual snapshot of
the ﬁeld. The purpose of Sect. 5.4 is to give the reader an impression of what
© Springer-Verlag Berlin Heidelberg 2017
D. Draheim, Semantics of the Probabilistic Typed Lambda Calculus,  
DOI 10.1007/978-3-642-55198-7_5 
135

136
5 Denotational Semantics
has been achieved in the ﬁeld. The section overviews groundbreaking work
in the ﬁeld, work that is important due to its theoretical insight, technical
maturity, recentness of results etc. As such, the section cannot be complete.
The purpose is to provide the reader entry points into the impressive body of
knowledge concerning domains for higher-type probabilistic computing. Prob-
abilistic powerdomains will be a dominating topic in this section.
5.1 Domains and Denotations
5.1.1 Semantics of Types
Given a program, the evaluation semantics assigns a probability to each con-
stant, i.e., the probability with which the program reduces to that constant
– see Def 3.6. The constants are considered the result values of the program.
However, in general, the evaluation semantic function does not form a prob-
ability distribution, i.e., the reachability probabilities of all constants do not
sum up to one in general. This is exactly what the termination degree was
about. In case the termination degree is one, all constant probabilities sum up
to one and the evaluation semantics is a probability distribution. Obviously,
we know that the termination degree can never exceed a value of one. In gen-
eral the sum of probabilities of terms reachable by a program can, of course,
exceed the value of one. For example the program M = μλx. + 1(x) reaches
all terms of the form +1n(M) with probability one, for all numbers n ⩾1.
With our denotational semantics we want to give a semantics that mimics
the evaluation semantics as yielded by our operational semantics. Therefore,
the semantics of a program turns out to be what we call a pre-distribution,
which is a function with values in the interval [0, 1] that sum up to less than
or equal to one.
Deﬁnition 5.1 (Pre-Distribution) A function d : S −→[0, 1] is called
a discrete probability pre-distribution, or pre-distribution for short
iﬀits
domain S is countably inﬁnite and its total mass is less than or equal to one,
i.e.,

s∈S
d(s) ⩽1
(5.1)
Pre-distributions are used as semantics for programs that have a termina-
tion degree less than one. Besides that they are also needed in case of programs
with termination degree one. Here, in cases where the program contains a μ-
recursion, they are needed as semantics of the ﬁnite approximation of the
program semantics. Once we have understood that the semantics of programs
are, in general, pre-distributions, we can call them also just distributions on
some informal occasions.
We denote the set of truth values, as usual, by B. We use
  and
  to denote
the respective semantic truth values. We do so, in order to distinguish them

5.1 Domains and Denotations
137
from the lambda constants ˙t and ˙f in semantic equations. We use the usual
number ﬁgures 0, 1, . . . to denote the elements of the set of natural numbers
N0. There is no risk of confusing them with the constant symbols ni for natural
numbers, because we use the usual number ﬁgures only in informal examples,
but not in semantic equations.
Next, we need to see that the interval [0, 1] with its natural ordering and
zero as bottom element forms an ω-cpo. We will use [0, 1]ω to denote [0, 1] in
its role as an ω-cpo. We say that [0, 1]ω is our domain of probability values.
Deﬁnition 5.2 (Domain of Probability Values) We deﬁne the domain
of probability values, denoted by [0, 1]ω, as the ω-cpo ([0, 1], ⊑, ⊥) for all
i, j ∈[0, 1] as follows:
i ⊑j ⇔i ⩽j
⊥= 0
The deﬁnition of the domain of probability values contains an implicit
proposition, i.e., the fact that [0, 1]ω actually forms an ω-cpo as deﬁned in
Def. 2.62. First, as a matter of course, zero is the least element in [0, 1]ω.
Therefore, to show that Def. 5.2 is well deﬁned it remains to show that each
ω-chain in [0, 1]ω has a least upper bound in [0, 1]ω. But this is easy. It im-
mediately follows from the least-upper-bound property of real numbers; see
Axiom 2.88. The least-upper-bound property is a fundamental property of the
real numbers which states that every non-empty set of real numbers that has
an upper bound also has a least upper bound. Therefore, with 1 as the bound
for all numbers of the interval [0, 1]ω we have that each ω-chain i0 ⊑i1 ⊑i2 · · ·
in [0, 1]ω has a least upper bound. Note that we even do not need the fact
that the set {i0, i1, i2 . . .} forms a chain. It suﬃces that the set has 1 as an
upper bound.
Now, the semantics of types is given recursively for all types t1, t2 ∈T by
the following ω-cpos:
[[num]] = ⌊N0 −→[0, 1]ω ⌋
(5.2)
[[bool]] = ⌊B −→[0, 1]ω ⌋
(5.3)
[[t1 →t2]] =

[[t1]] −→[[t2]]

(5.4)
Eqns. (5.2) and (5.3) rely on the deﬁnition of function spaces that have
an ω-cpo as a target domain; compare with Def. 2.63. Next, Eqn. (5.4) relies
on the deﬁnition of ω-continuous function spaces in Def. 2.72. The following
equations do not provide diﬀerent information, but show the semantic domains
more explicitly for more easy reference later:
[[num]] =

N0 →[0, 1]ω, ⊑num, ⊥num

(5.5)

138
5 Denotational Semantics
d1 ⊑num d2 ⇔∀n ∈N0 . d1(n) ⩽d2(n)
(5.6)
⊥num = n ∈N0 →0
(5.7)
[[bool]] =

B →[0, 1]ω, ⊑bool, ⊥bool

(5.8)
d1 ⊑bool d2 ⇔∀b ∈B . d1(b) ⩽d2(b)
(5.9)
⊥bool = b ∈B0 →0
(5.10)
[[t1 →t2]] =

{f : [[t1]]→[[t2]] | f is ω-continuous}, ⊑t1→t2, ⊥t1→t2

(5.11)
f1 ⊑t1→t2 f2 ⇔∀x ∈[[t1]] . f1(x) ⊑t2 f2(x)
(5.12)
⊥t1→t2 = x ∈[[t1]] →⊥t2
(5.13)
We deﬁne the set [[T ]] of all domains and the set (|T |) of all domain objects
as follows:
[[T ]] = {[[t]] | t ∈T }
(5.14)
(|T |) = ∪[[T ]]
(5.15)
Furthermore, we deﬁne the set of base domains [[Tg]], i.e., domains for the
ground types, and the set of functional domains [[T →T ]], which is the set of
non-base domains. Similarly, we also deﬁne the set (|Tg|) of all base objects
and the set of all functionals (|T→T |) as follows:
[[Tg]] = {[[num]], [[bool]]}
(5.16)
[[T→T ]] = [[T ]]\[[Tg]]
(5.17)
(|Tg|) = [[num]] ∪[[bool]]
(5.18)
(|T→T |) = (|T |)\(|Tg|)
(5.19)
In Lemma 3.1 we have expressed that each type has a right-associate
top-level structure. Of course, a respective form also exists for domains, as
expressed by Lemma 5.3. Again this top-level functional structure of domains
can be useful as a basis for natural induction proofs.
Lemma 5.3 (Top-Level Functional Structure of Domains)
Each
domain D ∈(|T |) has the form [Dn →[. . . [D2 →[D1 →B]]...]] for some
n ⩾0 with Di ∈(|T →T |) and a base domain B ∈[[Tg]].
Proof. Corollary from Lemma 3.1


5.1 Domains and Denotations
139
5.1.2 Semantics of Lambda Terms
The crucial aspect of denotational semantics is that it strictly follows the
principle of decomposition. A denotational semantics assigns the same kind of
mathematical object to each term of a language, a domain object from (|T |)
in our case. It does so along the abstract syntax of the respective language.
Each term of a language is composed from sub-terms by the application of a
syntactical constructor; compare also with Def. 3.2. A denotational semantics
follows this composition of terms. It assigns a semantics to a term by recur-
sively applying a semantic function to its sub-terms. In the case of lambda
calculi the decomposition principle of denotational semantics implies that we
also need to specify mathematical objects for free variables and open terms.
Therefore, we need a concept of variable environment which ﬁxes a mathe-
matical object for each free variable. Closed terms are independent of variable
environments, however open terms receive a unique semantics only via a given
variable environment.
Variable Environments
The set of variable environments
 , also environments for short, is deﬁned as
the set of type-respecting functions from variables to domains. The undeﬁned
environment ∅:
 , also called the empty environment, is deﬁned as the envi-
ronment that assigns to each variable the bottom element of the corresponding
domain.
Deﬁnition 5.4 (Variable Enviroments)
The set
  of variable
environments, also environments for short, is deﬁned as follows:
  = { ρ : Var →(|T |) | ∀xt ∈Var . ρ(xt)∈[[t]] }
(5.20)
Deﬁnition 5.5 (Empty Environment) The empty environment ∅:
  is de-
ﬁned as follows:
∅= xt ∈Var →⊥t
(5.21)
We have not deﬁned environments as families of functions indexed by
types, but as type-respecting functions from the set of all variables into the set
of all domain objects. This way, we save eﬀort in maintaining type information.
Given an environment ρ :
  we can simple write ρ(xt) and do not have to care
about the type t of the variable xt.
Semantic Equations
The denotational semantics assigns a domain object to each lambda term, with
respect to a given variable environment. As usual, we use semantic bracketing
as notation for the denotational semantics, i.e., we denote the semantics of a

140
5 Denotational Semantics
term M with respect to an environment ρ by [[M]]ρ. We can make the semantic
function more explicit as follows:
[[ 2_]] 1_ :
  −→(Λ −→(|T |))
(5.22)
Note that the semantic function as speciﬁed in Eqn. (5.22) will be again a
type-respecting function for each environment ρ, i.e., if a lambda term M : t
has type t then its semantics [[M]]ρ is a domain object in [[t]]. However, this
property of type preservation is not immediately given. Rather we must show
that it holds. Actually, this property is exactly what the well-deﬁnedness in
Sect. 5.2 is about. Basically, the well-deﬁnedness of the semantic speciﬁcation
function is about the question whether all of the deﬁned semantic objects
actually exist. Here, it is crucial that all of the semantic objects have cer-
tain properties, in particular, it is necessary that all of the involved functions
at higher types must be ω-continuous. This is necessary because the deﬁni-
tion of recursion relies on the semantic ﬁxed-point operator, which relies on
ω-continuous functions. Now, we have deﬁned our domains as structures of
objects that show this important property. Therefore, the question of well-
deﬁnedness can be grasped as the question of semantic type preservation, as
we will see in Sect. 5.2. For each given environment ρ :
 , we deﬁne the deno-
tational semantics for all terms M, N, N1, N2 ∈Λ by a series of the following
equations, Eqns. (5.23) through (5.34).
Some of the semantic equations rely on the existence of basic semantic
operations [[+1]], [[−1]] and [[0?]], which are deﬁned in due course in Sect. 5.1.3.
Furthermore, the semantic equations rely on a functional addition operator
M ⊕N and a scalar multiplication operator i ⊗M for terms M and probabil-
ities i that are deﬁned in Sect. 5.1.4. The operators are needed to deﬁne the
semantics of the choice operation M|N as (0.5⊗[[N1]]ρ)⊕(0.5⊗[[N2]]ρ). In case
the terms M and N are programs, the eﬀect of this should be intuitively clear.
It yields a pointwise weighted average of the two pre-distributions that the
terms M and N stand for. In this case the weights are both 0.5 and therefore
it actually delivers the plain average of the two respective pre-distributions.
With respect to the syntactical choice operator, we are currently only inter-
ested in that special case. Nevertheless, the general case is also needed in our
semantic equations, i.e., in the speciﬁcation of the conditional expressions.
Here the weights stem from the probabilities that the condition is ˙t or ˙f and
can have any value. For terms of higher type, the deﬁnition of the semantic
choice propagates the probability weights down to the involved ﬂat domains
and this way appropriately merges the semantic objects. We will see how this
works in due course in Sect. 5.2.1, where we provide the deﬁnitions of the
semantic operators ⊕and ⊗and investigate them further. Furthermore, the
equations exploit the notation for function update, see Def. 2.84, which is used
to denote the update of the variable environment ρ. Furthermore, we need the
ﬁxed-point operator Φ as deﬁned in Def. 2.80 to give semantics to recursion,
i.e., the μ-operator.

5.1 Domains and Denotations
141
∀v ∈Var : [[v]]ρ = ρ(v)
(5.23)
∀ni ∈Cnum : [[ni]]ρ = n ∈N0 →

1
, n = i
0
, else
(5.24)
[[˙t]]ρ = b ∈B →

1
, b =
 0
, b =
 (5.25)
[[ ˙f]]ρ = b ∈B →

0
, b =

1
, b =
 (5.26)
[[+1(M)]]ρ = [[+1]] [[M]]ρ
(5.27)
[[−1(M)]]ρ = [[−1]] [[M]]ρ
(5.28)
[[0?(M)]]ρ = [[0?]] [[M]]ρ
(5.29)
[[if M then N1 else N2]]ρ = [[M]]ρ() ⊗[[N1]]ρ ⊕[[M]]ρ( ) ⊗[[N2]]ρ
(5.30)
[[λxt.M]]ρ = d ∈[[t]] →

[[M]]ρ[xt:=d]

(5.31)
[[MN]]ρ = [[M]]ρ [[N]]ρ
(5.32)
[[μM]]ρ = Φ( [[M]]ρ )
(5.33)
[[M|N]]ρ = 0.5⊗[[M]]ρ ⊕0.5⊗[[N]]ρ
(5.34)
5.1.3 Basic Semantic Operators
In this section we deﬁne the basic semantic operators of addition, subtraction
and test for zero.
Deﬁnition 5.6 (Basic Semantic Operators)
We deﬁne the functions
[[+1]] : [[num]]→[[num]], [[−1]] : [[num]]→[[num]] and [[0?]] : [[num]]→[[bool]] as
follows:
[[+1]] = d ∈[[num]] →

n ∈N0 →

d(n −1)
, n > 0
0
, else

(5.35)

142
5 Denotational Semantics
[[−1]] = d ∈[[num]] →

n ∈N0 →

d(n + 1)
, n > 0
d(0) + d(1)
, else

(5.36)
[[0?]] = d ∈[[num]] →

b ∈B →
⎧
⎨
⎩
d(0)
, b =
 
n⩾1

d(n)

, b =
 
(5.37)
Let us have a look at how the semantics of the test for zero [[0?]]d is deﬁned
for a datum d ∈[[num]], in particular, at how ([[0?]] d)( ) is deﬁned as a sum.
First, the semantics of ([[0?]] d)() is deﬁned as d(0). However, the semantics
of ([[0?]] d)( ) cannot be deﬁned simply as 1 −([[0?]] d)(). Instead, we must
sum up the d(n) of all n ⩾1 diﬀerent from zero to receive ([[0?]] d)( ). This
is so, because d is not a distribution but only a pre-distribution, i.e., its total
mass may be less than one leaving open room to represent non-termination
of a program. The denotational semantics is designed to correspond to the
operational semantics. Therefore, given a program M, we have that
(M ⇒˙t) + (M ⇒˙f) ⩽1
(5.38)
([[0?]] [[M]])() + ([[0?]] [[M]])( ) ⩽1
(5.39)
The sums in Eqns. (5.38) and (5.39) are less than one exactly if the degree
of non-termination ηM⟨S, C⟩of M is diﬀerent from zero.
Based on Def. 5.6 the semantic equations in Eqns. (5.27), (5.28) and (5.29)
can be rewritten into a more direct form. For all terms M ∈Λ we have that
[[+1(M)]]ρ = n ∈N0 →

[[M]]ρ(n −1)
, n > 0
0
, else
(5.40)
[[−1(M)]]ρ = n ∈N0 →

[[M]]ρ(n + 1)
, n > 0
[[M]]ρ(0) + [[M]]ρ(1)
, else
(5.41)
[[0?(M)]]ρ = b ∈B →
⎧
⎨
⎩
[[M]]ρ(0)
, b =


n⩾1

[[M]]ρ(n)

, b =
 (5.42)
It would also be usual to give the semantic equations for [[+1(M)]],
[[−1(M)]] and [[0?(M)]] immediately in their direct forms of Eqns. (5.40), (5.41)
and (5.42) and, actually, the direct equations are more easy to read, because
they work with one abstraction fewer. However, we need to make the basic
operators explicit as semantic operators, because we need to investigate them
in their own right. In particular, we need to prove that they are ω-continuous;
compare with Lemma 5.20.

5.1 Domains and Denotations
143
5.1.4 Higher-Type Arithmetics
The semantics of probabilistic choices M|N and conditional expressions
if M then N1 else N2 in Eqns. (5.34) and (5.30) rely on the existence of
higher-type operators for addition of functionals and scalar multiplication of
a number with a functional, which we denote ⊕and ⊗respectively. We will
call these operators also functional addition and functional scalar multipli-
cation in the sequel. The operators work for arbitrarily nested functionals as
long as the right-most or inner-most target type equals the set of real numbers
R, i.e., the operators work for objects that have a type of the following form:
(Sn →(. . . (S2 →(S1 →(S0 →R)))...))
(5.43)
In accordance with our semantic domains we call the elements of S0 in
Eqn. (5.43) data points. Eventually, the operators are deﬁned in terms of ﬂat
operations on real numbers and this way the usual arithmetical laws propa-
gate to the higher-type operators. All the higher-type operators are deﬁned
for arbitrary sets as arguments and the full set of real numbers R. In due
course, in Sect. 5.2, it will be our task to show that the usage of the higher-
type operators in our semantic equations does not lead us out of the allowed
domains of ω-continuous functions.
Deﬁnition 5.7 (Functional Addition) Functional addition is deﬁned as a
family of operators ⊕: S × S →S for all sets of functionals S of the form
Sn →. . . S1 →S0 →R, objects f, f ′ ∈S and objects ei ∈Si for all i ⩽n as
follows:
(f ⊕f ′) en . . . e0 = (f en . . . e0) + (f ′ en . . . e0)
(5.44)
Deﬁnition 5.8 (Functional Scalar Multiplication)
Functional scalar
multiplication is deﬁned as a family of operators ⊗: R × S →S for all sets of
functionals S of the form Sn →. . . S1 →S0 →R, real numbers k ∈R, objects
f ∈S and objects ei ∈Si for all i ⩽n as follows:
(k ⊗f) en . . . e0 = k · (f en . . . e0)
(5.45)
Deﬁnition 5.9 (Functional Null Element) For each set of functionals S
of the form Sn →. . . S1 →S0 →R we deﬁne the functional null element 0S
such that for all objects ei ∈Si for all i ⩽n the following holds:
0S en . . . e0 = 0
(5.46)
Lemma 5.10 (Functional Operator Vector Space)
For each set of
functionals S of the form Sn →. . . S1 →S0 →R the algebraic structure
(S, ⊕, ⊗, 0S) forms a vector space.
Corollary 5.11 (Functional Null Elements of Domains) Given a domain
(D, ⊑D, ⊥D) in [[T ]], we have that ⊥D = 0D.

144
5 Denotational Semantics
Deﬁnition 5.12 (Functional Summation) Functional summation is de-
ﬁned as a family of operators 







 : (ω →S) →S for all sets of functionals S
of the form Sn →. . . S1 →S0 →R, countable sets of objects (fi ∈S)i∈ω and
objects ej ∈Sj for all j ⩽n as follows:
 ∞









i=0
fi

en . . . e0 =
∞

i=0
(fi en . . . e0)
(5.47)
Lemma 5.13 (Applications Distribute over Functional Operators)
Given objects of some higher type f, f ′ ∈S →S′, a real number i ∈R and an
object e ∈S we have that
(f ⊕f ′) e = (fe) ⊕(f ′e)
(5.48)
i ⊗(fe) = (i ⊗f)e
(5.49)









f∈F
f

e =









f∈F
(f(e))
(5.50)
Lemma 5.14 (ω-Continuity of Functional Operators) Given an ω-cpo
D = [Dn →[. . . [D2 →[D1 →R]]...]], ω-chains (fi ∈D)i∈ω and (f ′
i ∈D)i∈ω,
a sequence of real numbers (in)n∈ω and a set of ω-chains F ⊆ω →D we have
that
⊔
n∈ωfn ⊕⊔
n∈ωf ′
n = ⊔
n∈ω(fn ⊕f ′
n)
(5.51)
lim
n→∞in ⊗⊔
m∈ωfm = ⊔
k∈ω(ik ⊗fk)
(5.52)









f∈F
( ⊔
n∈ωfn) = ⊔
n∈ω









f∈F
fn

(5.53)
5.1.5 Further Remarks on Domains and Denotations
A natural way to deal with non-determinism in programming languages is to
introduce sets of objects as denotations for programs. This gives rise to power-
domain structures in the literature. Several kinds of powerdomains have been
studied [221, 222, 246, 247]. Essentially, the several options diﬀer in the way
they treat and represent non-terminating program runs. Our base objects are
always single pre-distributions. Whenever several pre-distributions arise non-
deterministically, i.e., on occasion of the probabilistic choice construct, they
are immediately eliminated and ﬂattened into a single new pre-distribution.
This procedure is populated from base elements through to the objects of
all higher types. The least-upper-bound elimination Lemma, which we have
available for ω-cpos in Lemma 2.75, takes part in this technique. The ques-
tion of how best to represent non-termination by explicit bottom elements is
not an issue in our approach. In our approach, non-termination is implicitly

5.2 Well-Deﬁnedness of the Denotational Semantics
145
represented by the degree of non-termination. Bottom elements emerge auto-
matically in our base domains, as pre-distributions that assign a zero percent
probability to all data points. For the same reason, we also do not need to
use generalized notions of real number sequences, such as topological general-
izations as Moore-Smith Sequences [200, 186]. We are just ﬁne with ordinary
convergent sequences of real numbers.
5.2 Well-Deﬁnedness of the Denotational Semantics
In this section we prove that the semantic function provided in Sect. 5.1 is
actually well deﬁned. Given a term M and an environment ρ the semantic
function deﬁnes a semantic object by the semantic equations Eqns. (5.23)
through (5.34). It remains to show that the deﬁned objects actually exist and
actually exist in the correct domains, which is mutually dependent. First,
we need to show that all terms of ground type have a pre-distribution as
semantics. Furthermore, we need to show, inductively, that the semantic ob-
jects belong to the appropriate domains for all terms. This is exactly what
Lemma 5.22 is about. This type preservation is quite easy to see for con-
stants and the corresponding basic semantic objects in the domains [[num]]
and [[bool]]. However, it is not so immediately given for the other, complex
constructs of our calculus. For example, we need to argue that the ﬁxed point
used to deﬁne the recursion actually exists. In order to have that, we need to
show that all involved functions are ω-continuous.
Actually, we need to show for all higher-type constructs that the corre-
sponding semantic objects are ω-continuous functions. This necessity is im-
mediately clear for terms of lambda abstractions λv.M. Here, given v : t and
M : t′ the corresponding semantic equation Eqn. (5.31) deﬁnes a function in
[[t]] →[[t′]] as the corresponding semantic object. However, the semantic equa-
tion itself does not ensure that this function belongs to the required domain
[[[t]] →[[t′]]] of ω-continuous functions, which remains to be proven. Actu-
ally, the case of lambda abstraction can be considered as particularly tricky,
because it entails a further structural induction on terms of the bodies M of
lambda abstractions λ.M, which shows explicitly in the need for the l.u.b. sub-
stitution Lemma 5.21. However, conceptually the case of lambda abstraction
is not special. The ω-continuity of corresponding functions has to be proven
for all terms of higher type. The proof of this property always follows a similar
pattern. In each case, it relies, in one way or the other, on respective prop-
erties of corresponding semantic operators. For example, in case of recursion,
this is the ﬁxed-point operator Φ that we have investigated in Sect. 2.4.8.
In case of the probabilistic choice it is the so-called semantic choice operator
that we will elaborate together with the necessary lemmas in the upcoming
Sect. 5.2.1.

146
5 Denotational Semantics
5.2.1 The Semantic Choice Operator
The semantics of probabilistic choice M|N in Eqn. (5.34) and conditional
expressions if M then N1 else N2 in Eqn. (5.30) can be expressed succinctly
in terms of a semantic choice operator d ||i
j d′ for each domain D ∈[[T ]]; see
Def. 5.15. Here, i and j are probabilities and the task of the semantic choice
operator is to merge together data points d and d′ according to their respective
probability, and weighted according to the probabilities speciﬁed by i and j.
Deﬁnition 5.15 (Semantic Choice Operator) The semantic choice op-
erator is a family of functions ||i
j : D × D →D′ that is deﬁned for each
domain D ∈[[T ]], semantic objects f, g ∈D and indices i, j ∈[0, 1] as follows:

f ||i
j g

= (i⊗f) ⊕(j⊗g)
(5.54)
The semantic choice operator works for all kinds of domains. If it is applied
to data from the base domain, its arguments f and g are pre-distributions. In
this case, it takes each data point d and yields the weighted average probabil-
ity it has under the pre-distributions f and g weighted by i and j. This is an
arithmetic function. Otherwise, if the arguments of the semantic choice op-
erator are functionals, the choice operator recursively propagates the weights
down to data objects of basic domains, as expressed by Corollary 5.16.
Corollary 5.16 (Recursivity of the Semantic Choice Operator)
For
all domains D ∈[[T ]], semantic objects f, g ∈D and indices i, j ∈[0, 1] we
have the following:

f ||i
j g

=

d ∈S →( i·f(d) + j·g(d) ) ∈[0, 1] , f, g ∈⌊S →[0, 1]ω⌋
d ∈D1 →( f(d) ||i
j g(d) ) ∈D2
, f, g ∈[D1 →D2]
(5.55)
The set S in Eqn. (5.55) can be either N0 or B. In the case of base domains,
the semantic choice operator gets some base objects and also yields a base
object, i.e., in this case we know that the semantic choice operator is a function
D × D →D, where D can be either ⌊N0 →[0, 1]ω⌋or ⌊B →[0, 1]ω⌋. This
means that in the case of base domains we know that D′ = D already by
Corollary 5.16. This is diﬀerent in case of functional domains. Here we know
that the arguments f and g are elements of a domain [D1 →D2]. However,
all we know about the result f(d) ||i
j g(d) is that it is an element of D1 →D2.
It remains to show that D′ = D also in this case. As a consequence, we
need to show that f(d) ||i
j g(d) preserves ω-continuity. We will do this in
Lemma 5.18 and summarize the result that ||i
j : D × D →D for all domains
D in Corollary 5.19. Even more, we will have that ||i
j : [[D × D] →D] in
Corollary 5.19.
It is important to have this result as a tool to prove the well-deﬁnedness
of the denotational semantics. As a ﬁrst step, we will show that the semantic

5.2 Well-Deﬁnedness of the Denotational Semantics
147
choice operator is itself continuous. For each domain D, we have deﬁned the
semantic choice operator as a function in D × D →D′. The target is to show
that the semantic choice operator belongs to [[D × D] →D].
Lemma 5.17 (ω-Continuity of the Semantic Choice)
The semantic
choice operator is ω-continuous in both of its arguments.
Proof. We need to show that for all ω-chains C = (ci)i∈ω and C′ = (c′
i)i∈ω we
have that
⊔C ||i
j ⊔C′ =
⊔
n∈ω(cn ||i
j c′
n)
(5.56)
Due to Lemma 5.3 we can assume that the domains of C and C′ have the
following form for some n ⩾0, some possibly empty sequence of domains Di
for all 1 ⩽i ⩽n and some base domain B ∈[[Tg]] of the form ⌊S →[0, 1]ω⌋:
[Dn →[. . . [D2 →[D1 →B]]...]]
(5.57)
We show Eqn. (5.56) for all domains by natural induction over the length n
of the domain in Eqn. (5.57).
In Case of n=0: In case n = 0 we know that the domains of C and C′
have the form ⌊S →[0, 1]ω⌋for some S. We show Eqn. (5.56) by proving that
⊔C ||i
j ⊔C′ equals ⊔
n∈ω(cn ||i
j c′
n) for all data points p ∈S. Given an arbitrary
data point p we start with the following:
(⊔C ||i
j ⊔C′) p
(5.58)
Now, Corollary 5.16 applies. We are concerned with the ﬁrst clause of
Eqn. (5.55), which deals with the case of data points. Due to Corollary 5.16
we know that Eqn. (5.58) equals
(i · ((⊔C)p) + (j · (⊔C′)p))
(5.59)
Due to the pointwise construction of least upper bounds of ω-cpo targeting
functions, i.e., Lemma 2.64, we know that Eqn. (5.59) equals
(i · ⊔
n∈ωcn(p)) + (j · ⊔
n∈ωc′
n(p))
(5.60)
We know that the ω-chains (cn(p)) and (c′
n(p)) in Eqn. (5.60) are monotoni-
cally increasing sequences of real numbers; compare with Def. 2.92. Further-
more, we have that all sequences in [0, 1] are necessarily bounded from above,
with 1 as absolute bound. Therefore the monotone convergence Theorem 2.93
applies, which ensures that the least upper bounds of these sequences equal
the limits of these sequences in the sense of convergence in real analysis.
Therefore, altogether we have that Eqn. (5.60) is equivalent to the following
formula:
(i · lim
n→∞cn(p)) + (j · lim
i→∞c′
n(p))
(5.61)

148
5 Denotational Semantics
Due to the limit properties of sequences of real numbers, see Lemma 2.91, we
know that Eqn. (5.61) equals
lim
n→∞(i · cn(p) + j · c′
n(p)) = ⊔
n∈ω(i · cn(p) + j · c′
n(p))
(5.62)
Again, due to Corollary 5.16 we know that Eqn. (5.62) equals
⊔
n∈ω( (cn ||i
jc′
n) p)
(5.63)
Finally, again due to the pointwise construction of least upper bounds of
functions in Lemma 2.64 we know that Eqn. (5.63) equals
( ⊔
n∈ω(cn ||i
jc′
n) ) p
(5.64)
In Case of n > 0:
In case n > 0 we have that C and C′ have the form
[Dn+1 →[Dn →[. . . [D2 →[D1 →B]]...]]]. We show Eqn. (5.56) by proving
that ⊔C ||i
j ⊔C′ equals
⊔
n∈ω(cn ||i
j c′
n) for all objects d ∈Dn+1. Given an
arbitrary object d ∈Dn+1 we start with the following:
(⊔C ||i
j ⊔C′) d
(5.65)
Due to Eqn. (5.55), second clause, we know that Eqn. (5.65) equals
(⊔C)d ||i
j (⊔C′) d
(5.66)
Due to the construction of least upper bounds of functions in Lemma 2.64 we
know that Eqn. (5.66) equals
⊔
n∈ω(cn(d)) ||i
j
⊔
n∈ω (c′
n(d))
(5.67)
Let us consider the ω-chains (cn(d))n∈ω and (c′
n(d))n∈ω. In these, the functions
cn(d) and c′
n(d) are elements of the domain [Dn →[. . . [D2 →[D1 →B]]...]].
Therefore, the induction hypothesis applies and we have that Eqn. (5.67)
equals
⊔
n∈ω( (cn ||i
j c′
n) d )
(5.68)
Now, according to the construction of least upper bounds of functions in
Lemma 2.64 we know that Eqn. (5.68) equals
( ⊔
n∈ω(cn ||i
j c′
n) ) d
(5.69)

Now, given that the semantic choice operator is ω-continuous we have, as
a corollary, that it preserves ω-continuity.

5.2 Well-Deﬁnedness of the Denotational Semantics
149
Lemma 5.18 (The Semantic Choice Preserves ω-Continuity)
The
semantic choice operator preserves ω-continuity, i.e., for all functional do-
mains [D →E], functions f, f ′ ∈[D →E] and indices i, j it holds that
(f ||i
j f ′) is an ω-continuous function, i.e., (f ||i
j f ′) ∈[D →E] .
Proof. This Lemma follows as a corollary from Lemma 5.17. We need to show
that for all ω-chains D′ = (dn)n∈ω we have that
(f ||i
j f ′)(⊔D′) =
⊔
n∈ω( (f ||i
j f ′) dn )
(5.70)
By Corollary 5.16 we know that (f ||i
j f ′)(⊔D′) equals
f(⊔D′) ||i
j f ′(⊔D′)
(5.71)
Now, we know that both f and f ′ are ω-continuous. Therefore, Eqn. (5.71)
equals
⊔(f(dn))i∈ω
||i
j
⊔(f ′(dn))i∈ω
(5.72)
Now, we have that Lemma 5.17 applies, i.e., we know that the semantic choice
operator itself is ω-continuous in both of its arguments. Therefore, we know
that Eqn. (5.72) equals
⊔
n∈ω( f(dn) ||i
j f ′(dn) )
(5.73)
Again, by Corollary 5.16 we have that Eqn. (5.73) equals
⊔
n∈ω( (f ||i
j f ′) dn )
(5.74)

Next, we will summarize the results of Lemma 5.17 and Lemma 5.18 into
a single corollary. Both aspects of the corollary, i.e., ω-continuity as well as
the preservation of ω-continuity, are important for the well-deﬁnedness of the
denotational semantics.
Corollary 5.19 (Retraction of the Semantic Choice Operator)
The
semantic choice operator ||i
j is an element of [[D×D] →D] for all domains D.
Proof. Corollary from Lemma 5.17 and Lemma 5.18

5.2.2 Well-Deﬁnedness of the Basic Semantic Operators
Each term consists of a constructor and component terms; see also Def. 3.2.
Now, it is a general pattern that the semantics of a term is given as the
application of a constructor-speciﬁc semantic operator to the semantics of
the component terms. This is so in case of the probabilistic choice and the
conditional expressions that both exploit the choice operator ||i
j as semantic
operator. In case of recursion the ﬁxed point Φ serves as semantics operator.

150
5 Denotational Semantics
In case of application the operator apply introduced in Def. 2.73 can be con-
sidered as the corresponding semantic operator. The only case that slightly
deviates from this pattern is the case of lambda-abstracting terms. With the
basic semantic functions from Def. 5.6 also the semantic deﬁnitions of +1(M),
−1(M) and 0?(M) follow the described pattern of semantic description.
Lemma 5.20 (ω-Continuity of Basic Semantic Functions)
The
semantic functions [[+1]], [[−1]] and [[0?]] are ω-continuous functions, i.e., for
C : ω →[[num]] we have that
[[+1]](⊔numC) = ⊔num([[+1]]†C)
(5.75)
[[−1]](⊔numC) = ⊔num([[−1]]†C)
(5.76)
[[0?]](⊔numC) = ⊔bool([[zero]]†C)
(5.77)
Proof. We only show that [[+1]] is ω-continuous. The proofs that [[−1]] and [[0?]]
are ω-continuous are similar. With C = (ci)i∈ω we need to show the following:
[[+1]](⊔(ci)i∈ω) = ⊔(([[+1]]ci)i∈ω)
(5.78)
We start with the right-hand side of Eqn. (5.78). Due to the deﬁnition of [[+1]]
in Def. 5.6 we know that the following holds:
⊔(([[+1]]ci)i∈ω) =


n ∈N0 →

ci(n −1)
, n > 0
0
, else



fi

i∈ω
(5.79)
Now that (fi)i∈ω in Eqn. (5.79) is an ω-chain in [[num]] →[[num]] we can
apply Lemma 2.64 so that Eqn. (5.79) equals
n ∈N0 →


n ∈N0 →

ci(n −1)
, n > 0
0
, else

n

i∈ω
(5.80)
After semantic function application we have that Eqn. (5.80) equals
n ∈N0 →


ci(n −1)
, n > 0
0
, else

i∈ω
(5.81)
The conditions in the function deﬁnition of Eqn. (5.81), i.e., n > 0 or otherwise
n = 0, are independent of the index i ∈ω of the ω-chain. Therefore we deal
with two completely separate cases of ω-chains, i.e., the chain (ci(n −1))i∈ω
in case n > 0 and the chain (0)i∈ω in case n = 0. Therefore, Eqn. (5.81) can
be rewritten as follows:
n ∈N0 →

⊔(ci(n −1))i∈ω
, n > 0
⊔(0)i∈ω
, else
(5.82)

5.2 Well-Deﬁnedness of the Denotational Semantics
151
With 	(0)i∈ω = 0 and the introduction of a further semantic abstraction we
can turn Eqn. (5.82) into the following equivalent formula:
n ∈N0 →

(n →(⊔(ci(n)))i∈ω)(n −1)
, n > 0
0
, else
(5.83)
Now we have that (ci)i∈ω is an ω-chain in [[num]]. We know that [[num]] equals
⌊N0 →[0, 1]ω⌋; see Eqn. (5.2). Therefore, we can apply Lemma 2.64 so that
we have that Eqn. (5.83) equals
n ∈N0 →

(⊔(ci)i∈ω)(n −1)
, n > 0
0
, else
(5.84)
Finally, with Def. 5.6 we have that Eqn. (5.84) equals
[[+1]](⊔(ci)i∈ω)
(5.85)

5.2.3 Well-Deﬁnedness of Semantic Objects
As a ﬁrst step, we prove the so-called l.u.b. substitution Lemma 5.21. The
l.u.b. substitution Lemma is a kind of ω-continuity result for all terms. It is
a quite technical lemma, which becomes necessary to prove that lambda ab-
straction terms λv.M have a well-deﬁned semantics as part of Lemma 5.22.
Albeit the lemma is quite technical it is a central lemma, because it accu-
mulates and concentrates all the necessary results on the involved semantical
operators.
Open terms can receive a semantics only in the context of a variable envi-
ronment. Now, Lemma 5.21 considers two semantic objects. The ﬁrst is gained
as semantics of a term M after updating its environment at one point by the
l.u.b. of a given ω-chain C. The second is gained by updating the environment
several times with all elements of the chain C and taking the l.u.b. of the ω-
chain of the several resulting semantics of M. The Lemma states that both
of these semantic objects are equal. You can consider the lemma also as a
statement about the ω-continuity of the semantic function itself. The seman-
tic function has the form Λ ×
  →(|t|). Now, the lemma is a statement about
the continuity of the semantic function in its second argument, albeit a spe-
cialized one, because we consider only chains of environments whose elements
grow at exactly one point. For the purpose of proving the well-deﬁnedness of
the semantic function it is suﬃcient in its given form.
Lemma 5.21 (An L.U.B. Substitution Lemma) For all terms M : t,
environments ρ :
 , types t′, ω-chains c = (ci)i∈ω in [[t′]] and variables v : t′
we have that
[[M]]ρ[v:=⊔[[t′]]c] = ⊔[[t]]([[M]]ρ[v:=ci])i∈ω
(5.86)

152
5 Denotational Semantics
Proof. We proceed by structural induction over the construction of terms.
Variables and constants form the base cases of the induction, whereas the
other cases all exploit the induction hypothesis.
In Case of Variables: In case of a variable x we need to consider two cases
for [[x]]ρ[v:=⊔t′ c], i.e., the case v = x and the case v ̸= x. In case v = x we know
due to the deﬁnition of the semantic function in Eqn. (5.23), applied twice,
that
[[x]]ρ[x:=⊔[[t′]]c] = ⊔[[t]]((ci)i∈ω) = ⊔[[t]](([[x]]ρ[x:=ci])i∈ω)
(5.87)
In case v ̸= x the update of v in the environment is not relevant for the
semantics of x. Now, given an ω-chain that consists of a single data value for
all of its elements, we know that the l.u.b. of this ω-chain also equals all of its
members. Therefore, and again due to Eqn. (5.23); we know that
[[x]]ρ[v:=⊔[[t′]]c] = [[x]]ρ = ⊔[[t]](([[x]]ρ)i∈ω) = ⊔[[t]](([[x]]ρ[x:=ci])i∈ω)
(5.88)
In Case of Constants:
In case of constants k ∈C the environment is
not relevant at all for the semantics. The argumentation in this case therefore
equals the case of variables with v ̸= x, compare with Eqn. (5.88), with the
respective semantic equations Eqns. (5.24), (5.25) and (5.26):
[[k]]ρ[v:=⊔[[t′]]c] = [[k]]ρ = ⊔[[t]](([[k]]ρ)i∈ω) = ⊔[[t]](([[k]]ρ[x:=ci])i∈ω)
(5.89)
In Case of +1, -1 and 0?:
We show the result for terms of the form
+1(M). The cases −1(M) and 0?(M) both follow exactly the same pattern.
We start with the following term:
[[+1(M)]]ρ[v:=⊔c]
(5.90)
Due to the semantic equation Eqn. (5.27) we have that Eqn. (5.90) equals
[[+1]][[(M)]]ρ[v:=⊔c]
(5.91)
Now, due to the induction hypothesis we know that Eqn. (5.91) equals
[[+1]] (⊔(([[M]]ρ[v:=ci])i∈ω))
(5.92)
Due to Lemma 5.20 we know that [[+1]] is an ω-continuous function. Therefore
we know that Eqn. (5.92) equals
⊔(([[+1]] [[M]]ρ[v:=ci])i∈ω)
(5.93)
Finally, due to the semantic equation Eqn. (5.27) we have that Eqn. (5.93)
equals
⊔(([[+1(M)]]ρ[v:=ci])i∈ω)
(5.94)

5.2 Well-Deﬁnedness of the Denotational Semantics
153
In Case of Probabilistic Choice:
In a sense, the case of probabilistic
choice is the most interesting case. The probabilistic choice is the construct
that makes the diﬀerence with standard non-probabilistic calculi. Fortunately,
with the propositions of Sect. 5.2.1 we are well prepared to prove this case.
Due to the deﬁnition of the semantic function in Eqn. (5.34) we know that
the following equation holds:
[[M|N]]ρ[v:=⊔[[t′]]c] = [[M]]ρ[v:=⊔[[t′]]c] ||0.5
0.5 [[N]]ρ[v:=⊔[[t′]]c]
(5.95)
Due to the induction hypothesis we know that Eqn. (5.95) equals
⊔[[t]](([[M]]ρ[v:=ci])i∈ω) ||0.5
0.5 ⊔[[t]] (([[N]]ρ[v:=ci])i∈ω)
(5.96)
Now, due to Lemma 5.17 we know that the semantic probabilistic choice
operator is itself ω-continuous. Therefore, we know that Eqn. (5.96) equals
⊔[[t]](([[M]]ρ[v:=ci] ||0.5
0.5 [[N]]ρ[v:=ci])i∈ω)
(5.97)
Finally, again due to the deﬁnition of the semantic function in Eqn. (5.34),
we know that Eqn. (5.97) equals
⊔[[t]](([[M|N]]ρ[v:=ci])i∈ω)
(5.98)
In Case of Conditional Expressions: The semantics of conditional ex-
pressions is deﬁned completely in terms of the semantic choice operator so
that the proof in this case exactly follows the pattern demonstrated in case
of the probabilistic choice.
In Case of Applications: In case of applications (MN) : t we have that
M : s →t and N : s for some type s : T . Now we know, due to the deﬁnition
of the semantic function in Eqn. (5.32), that the following equation holds:
[[MN]]ρ[v:=⊔[[t′]]c] = [[M]]ρ[v:=⊔[[t′]]c] [[N]]ρ[v:=⊔[[t′]]c]
(5.99)
Due to the induction hypothesis we know that Eqn. (5.99) equals
⊔[[s→t]]([[M]]ρ[v:=ci])i∈ω (⊔[[s]]([[N]]ρ[v:=cj])j∈ω)
(5.100)
Now, due to the pointwise deﬁnition of the least upper bound in Lemma 2.64
we know that Eqn. (5.100) equals
⊔[[t]]( [[M]]ρ[v:=ci] (⊔[[s]]([[N]]ρ[v:=cj])j∈ω) )i∈ω
(5.101)
Now, we know that [[s →t]] equals [[[s]] →[[t]]] and therefore all functions in
[[s →t]] are ω-continuous. Therefore, also all of the functions [[M]]ρ[v:=ci] for
all i ∈ω are ω-continuous. Therefore we know that Eqn. (5.101) equals
⊔[[t]]( ⊔[[t]]( [[M]]ρ[v:=ci] [[N]]ρ[v:=cj] )j∈ω )i∈ω
(5.102)

154
5 Denotational Semantics
Next, we can make the function application in Eqn. (5.102) explicit by intro-
ducing the apply operator, which we have deﬁned in Def. 2.73, to Eqn. (5.102),
which yields
⊔[[t]]( ⊔[[t]]( apply([[M]]ρ[v:=ci], [[N]]ρ[v:=cj]) )j∈ω )i∈ω
(5.103)
Furthermore, we know due to Lemma 2.74 that the apply operator is monotone
in both of its arguments. Therefore, it possible to apply the l.u.b. elimination
Lemma 2.75 to Eqn. (5.103). Therefore we know that Eqn. (5.103) equals
⊔[[t]]( apply([[M]]ρ[v:=ci], [[N]]ρ[v:=ci]) )i∈ω
(5.104)
Now, by eliminating the explicit representation of function application, we
can turn Eqn. (5.104) again into
⊔[[t]]( [[M]]ρ[v:=ci] [[N]]ρ[v:=ci] )i∈ω
(5.105)
Now, due to the deﬁnition of the semantic function in Eqn. (5.32) we know
that Eqn. (5.105) equals
⊔[[t]](([[MN]]ρ[v:=ci])i∈ω)
(5.106)
In Case of Abstractions:
In case of abstractions λx.M we have that
t = s →s′ such that x : s and M : s′. We know, due to Eqn. (5.31), that the
following equation holds:
[[λx.M]]ρ[v:=⊔[[t′]]c] = d ∈[[s]] →([[M]]ρ[v:=⊔[[t′]]c, x:=d])
(5.107)
Due to the induction hypothesis we know that Eqn. (5.107) equals
d ∈[[s]] →⊔[[s′]] ([[M]]ρ[v:=ci, x:=d])i∈ω
(5.108)
Now, we can introduce a further semantic abstraction to Eqn. (5.108) yielding
the following equivalent formula:
d ∈[[s]] →⊔[[s′]] ( (e ∈[[s]] →[[M]]ρ[v:=ci, x:=e]) d )i∈ω
(5.109)
Now, having the function in the form of Eqn. (5.109) we see that the sequence
of functions (e ∈[[s]] →[[M]]ρ[v:=ci, x:=e])i∈ω forms an ω-chain in [[s →s′]].
Now, due to the result for least upper bounds of functions in Lemma 2.64 we
know that Eqn. (5.109) equals
⊔[[s→s′]](e ∈[[s]] →[[M]]ρ[v:=ci, x:=e] )i∈ω
(5.110)
As the ﬁnal step, we know due to the deﬁnition of the semantic function in
Eqn. (5.31) and the fact that t = s →s′ that Eqn. (5.110) equals
⊔[[t]]([[λx.M]]ρ[v:=ci])i∈ω
(5.111)

5.2 Well-Deﬁnedness of the Denotational Semantics
155
In Case of Recursion: In case of recursion we consider terms of the form
μM : t with M : t →t. We know that due to Eqn. (5.33) the following
equation holds:
[[μM]]ρ[v:=⊔[[t′]]c] = Φ[[M]]ρ[v:=⊔[[t′]]c]
(5.112)
Due to the induction hypothesis we know that Eqn. (5.112) equals
Φ(⊔[[t→t]]([[M]]ρ[v:=ci])i∈ω)
(5.113)
Now, due to Lemma 2.82 we know that the ﬁxed-point operator is itself ω-
continuous. Therefore we know that Eqn. (5.113) equals
⊔[[t]](Φ[[M]]ρ[v:=ci])i∈ω
(5.114)
Now, again due to Eqn. (5.33) we know that Eqn. (5.114) equals
⊔[[t]]([[μM]]ρ[v:=ci])i∈ω
(5.115)

Now, we turn to the well-deﬁnedness of the denotational semantics. As
we have already explained, the proposition is about the type preservation
of the semantic function. In proving the type preservation of the semantic
function we prove the existence of the semantic objects for all terms on the
ﬂy. The proof needs to be conducted for all terms by structural induction over
the construction of terms. The deﬁnition of the type system of the calculus
in Sect. 3.1.2 with its typing rules forms the background against which the
proposition has to be understood and its proof has to be conducted.
Lemma 5.22 (Well-Deﬁnedness of Denotations) For each term M of
type t, and environment ρ ∈
  we have that its semantics [[M]]ρ is an object in
the semantics of its corresponding domain [[t]], i.e.,
M : t =⇒[[M]]ρ ∈[[t]]
(5.116)
Proof. The proof is conducted by structural induction over all terms; compare
with Eqn. (3.1) ﬀ. In the proof, all statements on known typings are justiﬁed
by one of the typing rules (3.7) through (3.13) in Sect. 3.1.2 . For the sake of
better readability, we do not want to explicitly name the respective typing rule
in each case. Please use Sect. 3.1.2 as a permanent reference throughout the
proof. Similarly, all statements on semantical equality of terms refer to and are
justiﬁed by one of the semantic equations Eqns. (5.23) through (5.34). Again,
we do not want to explicitly state which of the concrete semantic equations
actually applies in each case.
For variables and constants, the proposition trivially holds. Given a vari-
able x : t we have that ρ(x) ∈[[t]], because the environment ρ is, due to the
deﬁnition of environments
  in Def. 5.4, a type-respecting function. Similarly,
for all constants ni : num we have that [[ni]]ρ is a function in N0 →[0, 1]

156
5 Denotational Semantics
and therefore also [[ni]]ρ ∈⌊N0 →[0, 1]ω⌋so that [[ni]]ρ ∈[[num]]. A similar
argument holds for the constants ˙t : bool and ˙f : bool so that [[˙t]]ρ ∈[[bool]] and
[[ ˙f]]ρ ∈[[bool]].
Let us turn to the case of applications (MN) : t2 with M : t1 →t2 and
N : t1. The case is rather trivial. We can assume, as induction hypothesis,
that [[M]]ρ ∈[[[t1]] →[[t2]]] and [[N]]ρ ∈[[t1]]. Now we know that that [[MN]]ρ
equals [[M]]ρ [[N]]ρ and therefore [[MN]]ρ ∈[[t2]].
In case of recursions we deal with terms of the form (μM) : t for some
term M : t →t. We know that [[μM]]ρ equals Φ[[M]]ρ. Due to the induction
hypothesis we know that [[M]]ρ ∈[t →t]. Therefore, we know that [[M]]ρ is an
ω-continuous function in [[[t]] →[[t]]]. Therefore, we can apply the ﬁxed-point
Theorem 2.79, which ensures that the ﬁxed point of [[M]]ρ, i.e., Φ[[M]]ρ, exists
and furthermore Φ[[M]]ρ ∈[[t]].
Now, let us turn to probabilistic choices. Given a term M|N with M : t
and N : t for some higher type t. We know that [[M|N]]ρ equals [[M]]ρ ||0.5
0.5[[N]]ρ.
Now, as induction hypothesis, we can assume that [[M]]ρ ∈[[t]] and [[N]]ρ ∈
[[t]]. Fortunately, we now have Corollary 5.19 to hand which ensures that
[[M]]ρ ||0.5
0.5 [[N]]ρ is an element of [[t]]. A similar argumentation immediately
applies to conditional expressions of the form if M then N1 else N2, because
the semantics of conditional expressions is given completely in terms of the
semantic probabilistic choice operator, compare with Eqn. (5.30).
Last but not least, let us turn to abstractions of the form λv.M. We know
that (λv.M) : (t1 →t2) for a variable v : t1 and a term M : t2. Furthermore
we know that [[λv.M]]ρ equals the function d ∈[[t1]] →[[M]]ρ[v:=d]. Therefore,
we know that [[λv.M]]ρ is an element of [[t1]] →[[t2]]. However, we have not
yet shown that [[λv.M]]ρ is also an element of [[[t1]] →[[t2]]], i.e., we do not yet
know that [[λv.M]] ∈[[t1 →t2]]. In order to have that, it remains to show that
[[λv.M]]ρ is an ω-continuous function. This means that we need to show that
for all ω-chains c = ( ci ∈[[t1]] )i∈ω we have that
[[λv.M]]ρ(⊔[[t1]]c) = ⊔[[t2]]([[λv.M]]†
ρ(c))
(5.117)
Due to Eqn. (5.31) we know that [[λv.M]]ρ(⊔[[t1]]c) equals
[[M]]ρ[v:=⊔[[t1]]c ]
(5.118)
Now, the l.u.b. substitution Lemma 5.21 applies and we know that Eqn. (5.118)
equals
⊔[[t2]](([[M]]ρ[v:=ci])i∈ω)
(5.119)
Now, again due to the deﬁnition of the semantic function in Eqn. (5.31) we
know that Eqn. (5.119) equals
⊔[[t2]](([[λv.M]]ρ(ci))i∈ω)
(5.120)
Actually, we are already done now. Due to Def. 2.68 we know that Eqn. (5.120)
equals

5.3 Semantic Correspondence
157
⊔[[t2]]([[λv.M]]†
ρ(c))
(5.121)

5.2.4 Futher Denotational Tools
In this section we provide two further, short technical lemmas that are needed
later to prove the semantic correspondence for the probabilistic lambda calcu-
lus. The ﬁrst, Lemma 5.23, allows, informally, for shortening environments. It
states that the update to a variable enviroment does not aﬀect the semantics
of a term, as long as the updated variable is not free in the considered term.
The second, Lemma 5.24, is a variable substitution lemma that is about the
interplay of syntax, semantics and variable environments. If we are interested
in the semantics of a term that results from a syntactical variable substitution
in a core term, we can consider the semantics of only the core term instead,
as long as we semantically update the variable environment appropriately.
Given a term M[v := N], where N is a program, its semantics with respect
to an environment ρ equals the semantics of M with respect to the new en-
vironment ρ[v := [[N]]∅]. Both lemmas are rather trivial and their proofs are
straightforward by structural induction.
Lemma 5.23 (Shortening Environments)
For all terms M : t,
environments ρ ∈
 , data d : [[t]] and variables x that are not free in M, i.e.,
x ̸∈Vfree(M), we have that [[M]]ρ[x:=d] = [[M]]ρ
Lemma 5.24 (Substitution Lemma) For all terms M, environments ρ :
 ,
variables v and programs N we have that [[M[v := N]]]ρ = [[M]]ρ[v:=[[N]]∅]
5.3 Semantic Correspondence
In Theorem 5.55 we will prove the semantic correspondence between the de-
notational and the Markov chain semantics for ground types. Before we start,
we introduce a useful notation [c] for the retrieval of data points from the
semantics of constants c that we also call data point semantics in the sequel.
Deﬁnition 5.25 (Data Point Semantics) We deﬁne the data point se-
mantics for all constants ni ∈Cnum and constants ˙t, ˙f ∈Cbool, denoted by
[ni], [˙t] and [ ˙f], as follows:
[ni] = i
(5.122)
[˙t] =

(5.123)
[ ˙f] =

(5.124)

158
5 Denotational Semantics
Actually, given a constant c, we have that [c] is just a shorthand notation
for [[c]]−1
∅(1). Now, the semantic correspondence means that the probability of
reducing a program M to a constant c is correctly yielded by applying the
program denotation [[M]]∅to the data point [c], i.e., the denotational semantics
exactly mirrors the operational semantics for ground terms:
[[M]]∅[c] =

M ⇒c

(5.125)
We investigate the semantic correspondence for ground types only, there-
fore we also speak about it as a basic correspondence. We will prove the
semantic correspondence as a corollary of two restricted forms of correspon-
dence, i.e., an upper bound correspondence (M ⇒c) ⩽[[M]]∅[c] which ap-
proximates the exact denotational semantics from above, and a lower bound
correspondence (M ⇒c) ⩾[[M]]∅[c] which approximates the exact denota-
tional semantics from below.
For deterministic calculi it is also usual to distinguish two kinds of rela-
tionships between operational and denotational semantics. For example, the
text in [118] distinguishes between soundness and so-called computational
adequacy. The soundness of the operational semantics with respect to the
denotational semantics shows in the fact that M
⋆−→c implies [[M]]∅= [[c]] for
all programs M and constants c. Similarly, computational adequacy shows in
the fact that [[M]]∅= [[c]] implies M
⋆−→c. In this terminology, the semantic
correspondence is considered from the perspective of the denotational seman-
tics, i.e., the denotational semantics is considered as given and soundness is a
property of the operational semantics. This adheres to a viewpoint in which
the denotational semantics comes ﬁrst, i.e., as the speciﬁcation of the pro-
gramming language, and the operational semantics is considered as part of
the implementation. In our terminology of upper and lower bound correspon-
dence, the operational semantics is considered as given and it is the denota-
tional semantics that provides a further characterization of the programming
language semantics.
It is fair to say that upper bound correspondence is the probabilistic ana-
logue of soundness, whereas lower-bound correspondence is the probabilistic
analogue of computational adequacy. And, actually, for the deterministic frag-
ment of the probabilistic lambda calculus the respective notions meet exactly.
In the deterministic case, soundness is the easier to show, whereas compu-
tationally adequacy is the more sophisticated case. Similarly, upper bound
correspondence is more straightforward to prove than lower bound correspon-
dence.
Throughout the section we make use of the vector space laws available for
the higher-type operators ⊕and ⊗as established by Lemma 5.10, however,
without further mentioning them explicitly, because we are so familiar with
them from the R-vector space; compare with Sect. 2.5.5.

5.3 Semantic Correspondence
159
5.3.1 Upper Bound Correspondence
In order to prove upper bound correspondence, we ﬁrst need a technical
Lemma 5.26 that relates the one-step decomposition of the operational se-
mantics as expressed by Eqn. (2.35) to the denotational semantics. In a sense,
Lemma 5.26 expresses that the denotational semantics is preserved by the
one-step semantics.
Lemma 5.26 (One-Step Semantic Correspondence)
For all closed
lambda terms P ∈Λ∅we have that
[[P]]∅=









Q∈Λ∅
(P −→Q ⊗[[Q]]∅)
(5.126)
Proof. The proof can be conducted by structural induction over terms M. We
show the cases of constants, basic operators, conditional expressions, applica-
tions and deterministic choices only.
In Case of Constants: As a ﬁrst step, we can always transform the right-
hand side of Eqn. (5.126) into the following equivalent formula:
(P −→P ⊗[[P]]∅) ⊕









Q̸=P
(P −→Q ⊗[[Q]]∅)
(5.127)
Now, Lemma 3.3 applies – see Eqn. (3.65). In case of constants P ∈C we know
that P −→P = 1. It is clause (xviii), which applies due to its selector condition
here, that allows us to conclude this. Furthermore, we know P −→Q = 0 for all
P ̸= Q. This time, it is clause (xx), i.e., the else-clause in Eqn. (3.65), that
applies. Altogether, we therefore know that Eqn. (5.127) equals
(1 ⊗[[P]]∅) ⊕









P ̸=Q
(0 ⊗[[Q]]∅)
(5.128)
And ﬁnally we know, due to Lemma 5.10, that Eqn. (5.128) equals [[P]]∅.
Henceforth, in this proof, we will often conduct equivalent transforma-
tions of formulae that are valid due to the equalities that hold for the one-
step semantics as expressed by Lemma 3.3 and Eqn. (3.65) without further
mentioning this Lemma and; similarly, we often use the laws that hold for
higher-type arithmetic as expressed by Lemma 5.10 without further men-
tioning Lemma 5.10. Lemma 5.10 establishes the vector space laws for the
higher-type operators. Therefore, you might want to have Sect. 2.5.5 to hand
as a reference in the sequel, which lists all the genuine and inherited vector
space laws needed in this proof.
In Case of Basic Operators: We prove Eqn. (5.126) for addition operator
terms P = +1(M) only. We need to distinguish two cases, i.e., the case that

160
5 Denotational Semantics
M in +1(M) is not a constant and the case that M is one of the constants
ni. We start with the case that M is not a constant. We need to prove the
following corresponding instance of Eqn. (5.126):
[[+1(M)]]∅=









Q∈Λ∅
(+1(M)−→Q ⊗[[Q]]∅)
(5.129)
The right-hand side of Eqn. (5.129) equals the following:









M′∈Λ∅
(+1(M)−→+1(M ′)⊗[[+1(M ′)]]∅) ⊕









Q̸∈{+1(M′) | M′∈Λ∅}
(+1(M)−→Q⊗[[Q]]∅) (5.130)
With a similar argument as in the case of constants we can see that the second
summand in Eqn. (5.130) vanishes. Again, Eqn. (3.65) applies, where the side
conditions M ̸∈C are crucial to uniquely identify the correct clause (xx).
Similarly, due to clause (i) we know that +1(M) −→+1(M ′) equals M −→M ′.
Altogether this means that Eqn. (5.130) equals









M′∈Λ∅
(M −→M ′ ⊗[[+1(M ′)]]∅)
(5.131)
Now, due to the deﬁnition of the basic operator [[+1]] in Def. 5.6 plus the
distributivity of function application over the higher-type arithmetic operators
as expressed in Lemma 5.13, we have, after a series of transformations, that
5.131 equals
n ∈N0 →









M′∈Λ∅(M −→M ′ ⊗[[M ′]]∅)

(n −1)
, n > 0
0
, else
(5.132)
Now, the induction hypothesis applies so that Eqn. (5.132) equals
n ∈N0 →

[[M]](n −1)
, n > 0
0
, else
(5.133)
Finally, we know that Eqn. (5.133) equals [[+1(M)]].
Next, we turn to the case that M in +1(M) is a constant ni for some
i ∈N0. In such a case, we need to prove the following:
[[+1(ni)]]∅=









Q∈Λ∅
(+1(ni)−→Q ⊗[[Q]]∅)
(5.134)
The right-hand side of Eqn. (5.134) equals the following:
(+1(ni)−→ni+1 ⊗[[ni+1]]∅) ⊕









Q∈Λ∅\{ni+1}
(+1(ni)−→Q ⊗[[Q]]∅)
(5.135)

5.3 Semantic Correspondence
161
Again, we can exploit Eqn. (3.65), clauses (ii) and (xx) this time, and we
see that Eqn. (5.135) equals [[ni+1]]. Therefore, it suﬃces to show that [[ni+1]]
equals [[+1(ni)]] in order to complete the proof. Now, by Def. 5.6 we have that
[[+1(ni)]]ρ = n ∈N0 →

[[ni]]ρ(n −1)
, n > 0
0
, else
(5.136)
Now, by the deﬁnition of the semantics for number constants [[ni]] in Eqn. (5.24)
we know that Eqn. (5.136) equals
n ∈N0 →
⎧
⎪
⎨
⎪
⎩
k ∈N0 →

1
, k = i
0
, else

(n −1)
, n > 0
0
, else
(5.137)
Now, by function application and a further simple transformation of n−1 = i
into n = i + 1 we have that Eqn. (5.137) equals
n ∈N0 →
⎧
⎪
⎨
⎪
⎩

1
, n = i + 1
0
, else

, n > 0
0
, else
(5.138)
Because we have that i+1 > 0 for all i we can rewrite Eqn. (5.138) as follows:
n ∈N0 →

1
, n = i + 1
0
, else
(5.139)
Finally, again due to Eqn. (5.24) we have that Eqn. (5.139) equals [[n(i+1)]].
In Case of Conditional Expressions: In case of conditional expressions
of the form P = if M then N ′ else N ′′ we again distinguish two cases, i.e.,
the case that the condition M is one of the constants ˙t or ˙f or otherwise
that M is not a constant. We show only the case that M is not a constant.
After exploiting Eqn. (3.65), clause (ix), we know that it suﬃces to show the
following:
[[if M then N ′ else N ′′]]∅=









M′∈Λ∅
(M −→M ′ ⊗[[if M ′ then N ′ else N ′′]]∅) (5.140)
Now, due to the semantic equation Eqn. (5.30) we know that the right-hand
side of Eqn. (5.140) equals









M′∈Λ∅
(M −→M ′ ⊗([[M ′]]ρ( ) ⊗[[N ′]]ρ ⊕[[M ′]]ρ( ) ⊗[[N ′′]]ρ) )
(5.141)
After several transformations we have that Eqn. (5.141) equals

162
5 Denotational Semantics









M′∈Λ∅
(M−→M ′ ⊗[[M ′]]ρ)

( ) ⊗[[N ′]]ρ ⊕









M′∈Λ∅
(M−→M ′ ⊗[[M ′]]ρ)

( ) ⊗[[N ′′]]ρ
(5.142)
Now, the induction hypothesis applies so that Eqn. (5.142) equals
[[M]]ρ() ⊗[[N ′]]ρ ⊕[[M]]ρ( ) ⊗[[N ′′]]ρ
(5.143)
Finally, we know that Eqn. (5.143) equals [[if M then N ′ else N ′′]].
In Case of Applications:
In case of applications P = MN we need to
distinguish two cases, i.e., the case in which M equals an abstraction λv.B and
the case in which M does not equal an abstraction. We show only the case that
M does not equal an abstraction. After exploiting Eqn. (3.65), clause (xii),
we know that it suﬃces to show the following:
[[MN]]∅=









M′∈Λ∅
(M −→M ′ ⊗[[M ′N]]∅)
(5.144)
Now, due to the semantic equation Eqn. (5.32) we know that the right-hand
side of Eqn. (5.144) equals









M′∈Λ∅
(M −→M ′ ⊗([[M ′]]∅[[N]]∅))
(5.145)
Next, we can exploit the distributiveness of higher-type arithmetic opera-
tors over and function application in Lemma 5.13. Therefore, ﬁrst due to
Eqn. (5.49) and second due to Eqn. (5.50), we have that Eqn. (5.145) equals
 








M′∈Λ∅
(M −→M ′ ⊗[[M ′]]∅)

[[N]]∅
(5.146)
Now, the induction hypothesis applies so that Eqn. (5.146) equals [[M]]∅[[N]]∅
which in turn equals [[MN]]∅, again due to Eqn. (5.32).
In Case of Deterministic Choice: In case of deterministic choices of the
form P = M|N we need to distinguish the cases in which M is diﬀerent from
N from the cases in which M equals N. We show only the case that M ̸= N.
We need to show the following:
[[M|N]]∅=









Q∈Λ∅
(M|N −→Q ⊗[[Q]]∅)
(5.147)
Now, in any case the right-hand side of Eqn. (5.147) can be transformed into
the following equivalent formula:

5.3 Semantic Correspondence
163
(M|N −→M ⊗[[M]]∅) ⊕(M|N −→N ⊗[[N]]∅) ⊕









Q∈Λ∅\{M,N}
(M|N −→Q⊗[[Q]]∅) (5.148)
Due to Eqn. (3.65) we know that Eqn. (5.148) equals
(0.5 ⊗[[M]]∅) ⊕(0.5 ⊗[[N]]∅)
(5.149)
Finally, due to the semantic equation Eqn. (5.34) we have that Eqn. (5.149)
equals [[M|N]]∅.

Next, we prove the upper bound correspondence in Lemma 5.27. Upper
bound correspondence means that the denotational semantics approximates
the Markov chain semantics from above, i.e., (M ⇒c

⩽[[M]]∅[c]. Upper
bound correspondence means that the investigated denotational semantics
yields an upper bound for the intended, exact denotational semantics, which
we expect, pointwise, to equal the evaluation semantics, i.e., (M ⇒c

=
[[M]]∅[c].
Lemma 5.27 (Upper Bound Correspondence) The denotational seman-
tics approximates the evaluation semantics from above. For each program M
and constant c we have that

M ⇒c

⩽[[M]]∅[c]
(5.150)
Proof. We will show Eqn. (5.150) as a corollary of a more general result which
shows that the denotational semantics is preserved by the reduction semantics
for all closed terms, i.e., not only for programs; see Eqn. (5.153). As a ﬁrst
step, we can see that (i⊗[[c]]∅)[c] equals i for each i ∈R; compare with Def. 5.8
and the semantic equations Eqns. (5.24), (5.25) and (5.26). Therefore, we have
that Eqn. (5.150) is equivalent to
((M ⇒c) ⊗[[c]]∅)[c]
⩽[[M]]∅[c]
(5.151)
Now, due to the pointwise deﬁnition of basic semantic objects we also have
that Eqn. (5.151) equals
(M ⇒c) ⊗[[c]]∅
⊑[[M]]∅
(5.152)
Now, we have that Eqn. (5.152) is a special case of the following, more general
proposition for all closed terms N:
(M ⇒N

⊗[[N]]∅
⊑[[M]]∅
(5.153)
We proceed by proving that the more general proposition Eqn. (5.153) holds
true for all closed terms M and N. We start with proving that all ﬁnite
approximations to Eqn. (5.153) hold true, i.e., that for all n ∈N0 we have the
following:
ηn
S⟨M, N⟩⊗[[N]]∅
⊑[[M]]∅
(5.154)

164
5 Denotational Semantics
We prove Eqn. (5.154) by natural induction over n.
In Case of n = 0:
We need to the distinguish the cases that M = N
and M ̸= N. In case M = N we know by the decomposition of bounded
hitting probabilities, i.e., Lemma 2.31, Eqn. (2.37), that η0
S⟨M, N⟩= 1 so
that we have that 1 ⊗[[N]]∅equals [[M]]∅
and therefore also approximates
[[M]]∅. Similarly, in case M ̸= N we know by Lemma 2.31, Eqn. (2.38), that
η0
S⟨M, N⟩= 0. Therefore, given that the type of M and N is T , we know that
0 ⊗[[N]]∅equals ⊥T and therefore approximates [[M]]∅.
In Case of n ⩾1: We start with the left-hand side of Eqn. (5.154), i.e.,
ηn
S⟨M, N⟩⊗[[N]]∅
(5.155)
Due to Lemma 2.31, Eqn. (2.39), we know that Eqn. (5.155) equals
 
M′∈Λ∅
M −→M ′ · ηn−1
S
⟨M ′, N⟩

⊗[[N]]∅
(5.156)
Furthermore, we know that Eqn. (5.156) equals









M′∈Λ∅
(M −→M ′ ⊗(ηn−1
S
⟨M ′, N⟩⊗[[N]]∅))
(5.157)
Now, we know that ηn−1
S
⟨M ′, N⟩⊗[[N]]∅⊑[[M ′]]∅, because the induction
hypothesis applies. Due to the ω-continuity of functional scalar multiplication,
Lemma 5.14, we know that ⊗is monotone in its second argument, compare
with Def. 2.70, and therefore we have that Eqn. (5.157) is less than or equal
to









M′∈Λ∅
M −→M ′ ⊗[[M ′]]∅
(5.158)
Finally, due to Lemma 5.26 we know that Eqn. (5.158) equals [[M]]∅, which
proves Eqn. (5.154).
Now, due to Eqn. (5.154) we know that [[M]]∅is an upper bound of
the chain (ηn
S⟨M, N⟩⊗[[N]]∅)n∈ω. Furthermore, by the deﬁnition of reduc-
tion probabilities in Def. 3.5, the limit of bounded hitting probabilities
as characterized in Corollary 2.27 and the ω-continuity of ⊗as stated by
Lemma 5.14 we know that (M ⇒N

⊗[[N]]∅is the least upper bound of the
chain (ηn
S⟨M, N⟩⊗[[N]]∅)n∈ω. Therefore, we know that Eqn. (5.153) holds true.

5.3.2 Lower Bound Correspondence
In order to prove lower bound correspondence we ﬁrst need to introduce a
stronger property for lambda terms that faithfully generalizes lower bound

5.3 Semantic Correspondence
165
correspondence from programs to open terms as well as terms of higher type.
We will then proceed to prove this stronger property for all lambda terms
by structural induction. With this proof idea we follow the original approach
of proving the denotational semantics of PCF (programming language for
computable functions) in [223] complete for programs. We call the property
α that we need to establish over-performance or performance for short.
Deﬁnition 5.28 (Performing Term) We deﬁne the property α(M) for all
terms M ∈Λ by the following comprehensive cases:
(a) If M is a program then α(M)
iﬀ(M ⇒c

⩾[[M]]∅([c]) for all c ∈C.
(b) If M is a closed lambda term of higher type t1 →t2 then α(M)
iﬀ
α(MN) for each closed lambda term N of type t1 for which α(N) holds.
(c) If M is an open term with FV (M) = {x1, . . . , xn} then α(M)
iﬀ
α(M[x1 := N1] . . . [xn := Nn]) for each collection of closed lambda terms
N1, . . . , Nn for which α(N1) through α(Nn) hold.
In the sequel, we will prove that all terms M are performing, i.e., α(M),
by a structural induction. Due to its length we split this proof into a sequence
of technical lemmas in the sequel. There will be one lemma for each case of
term construction, proving the performance of a closed term based on the
assumption that its component terms, i.e., the terms that it is constructed
from are already performing. Then, the collection of these lemmas can be used
to constitute a correct structural inductive proof of the desired property. These
lemmas are accompanied by further technical lemmas dealing with big-step
semantics or big-step semantical approximations concerning the respective
case. The case of recursion is particularly work-intensive to prove. Here, we
need the further notions of syntactical approximation and respective lemmas.
We start with the case of values, which encompass constants and lambda
abstractions.
Lemma 5.29 (Bounded Big-Step Semantics of Value Expressions)
Given values V ∈ΛV , V ′ ∈ΛV and a number n ∈N0 we have that
ηn
S⟨V, V ′⟩=

1
, V = V ′
0
, else
(5.159)
Proof. We distinguish the cases in which V = V ′ from cases in which V ̸= V ′.
Case V = V ′ immediately holds, see Lemma 2.31, Eqn. (2.37). Case V ̸= V ′
is shown by natural induction over the bound n.
In Case of n=0: In case n = 0 we know that η0
S⟨V, V ′⟩= 0 by the deﬁnition
of bounded hitting probabilities Def. 2.24; see also the deﬁnition of ﬁrst hitting
times in Def. 2.22.
In Case of n ⩾1:
In case n ⩾1 we have, due to the one-step decom-
position of bounded hitting probabilities, i.e., Lemma 2.31, Eqn. (2.39), that

166
5 Denotational Semantics
ηn+1
S
⟨V, V ′⟩equals

M∈Λ
V −→M · ηn+1
S
⟨M, V ′⟩
(5.160)
Now, Eqn. (5.160) can always be transformed into
V −→V · ηn
S⟨V, V ′⟩+

M∈Λ\{V }
V −→M · ηn+1
S
⟨M, V ′⟩
(5.161)
Due to the induction hypothesis we know that the ﬁrst summand in Eqn. (5.161)
equals zero. Due to Lemma 3.3, Eqn. (3.65), clause (xx), we know that V →M
equals zero for all values V ∈ΛV and terms M ̸∈Λ\{V } so that the second
summand in Eqn. (5.161) also equals zero, which completes the proof.

Lemma 5.30 (Big-Step Semantics of Value Expressions) Given values
V ∈ΛV and V ′ ∈ΛV we have that
V ⇒V ′ =

1
, V = V ′
0
, else
(5.162)
Proof. This Lemma follows as an immediate corollary from Lemma 5.29. Due
to the deﬁnition of reduction probabilities in Def. 3.5 we have that V ⇒V ′
equals lim
n→∞ηn
S⟨V, V ′⟩. Now, by Lemma 5.29 we have that ηn
S⟨V, V ′⟩yields the
correct right-hand side value of Eqn. (5.162) as a constant value, which proves
Eqn. (5.162).

Lemmas 5.29 and
5.30 hold, because a reduction stabilizes after it has
reached a value. In the sequel, as a helper Lemma, we also need to character-
ize how performance transports to expressions of higher type in general, as
expressed by Lemma 5.31.
Lemma 5.31 (Performance of Higher-Type Expressions)
Given a
closed term of higher type M : t1 →t2, closed terms 
N = N0, . . . , Nn such
that α(Ni) for all 0 ⩽i ⩽n and a program M 
N. Then, we have that α(M 
N)
implies α(M).
Proof. This Lemma immediately follows by the deﬁnition of performing terms
Def. 5.28, by applying clause (b) of Def. 5.28 n times plus once to MN0 . . . Nn,
i.e., for each 1 ⩽i ⩽n we can conclude by clause (b) that α(MN0 . . . Ni)
implies α(MN0 . . . Ni−1) and, ﬁnally, that α(MN0) implies α(M).

Performance of Basic Operators
Next, we turn to the case of basic operators. Here we ﬁrst introduce a big-step
semantics in Lemma 5.32. Then, on the basis of this big-step semantics, we
establish the performance of basic operators in Lemma 5.33.

5.3 Semantic Correspondence
167
Lemma 5.32 (Big-Step Semantics of Basic Operators) Given a closed
term M :num of the ground type of numbers we have that
+1(M) ⇒ni =

M ⇒ni−1
, i > 0
0
, else
(5.163)
−1(M) ⇒ni =

M ⇒ni+1
, i > 0
(M ⇒n0) + (M ⇒n1)
, else
(5.164)
0?(M) ⇒b =

M ⇒n0
, b = ˙t
ηS⟨M, C\{n0}⟩
, b = ˙f
(5.165)
Proof. We show this only for lambda terms +1(M). The other cases can be
proven analogously. First, due to the deﬁnition of reduction probabilities in
Def. 3.5 and Corollary 2.27 we have that Eqn. (5.163) is equivalent to
lim
n→∞ηn
S⟨+1(M), ni⟩=

lim
n→∞ηn
S⟨M, ni−1⟩
, i > 0
0
, else
(5.166)
Due to the monotonicity of bounded hitting probabilities, i.e., Lemma 2.28;
and the monotone convergence Theorem 2.93 we have that lim
n→∞ηn
S⟨M, ni−1⟩,
i.e., the right hand side of Eqn. (5.166), is also the least upper bound of
its sequence (ηn
S⟨M, ni−1⟩)n∈ω. Similarly we know that the left-hand side
of Eqn. (5.166), i.e., lim
n→∞ηn
S⟨+1(M), ni⟩, equals the least upper bound of
(ηn
S⟨+1(M), ni⟩)n∈ω. For the same reasons, we know that lim
n→∞ηn
S⟨+1(M), ni⟩
equals lim
n→∞ηn+m
S
⟨+1(M), ni⟩for an arbitrary but ﬁxed m ∈N0. In particular,
we know that lim
n→∞ηn
S⟨+1(M), ni⟩equals lim
n→∞ηn+1
S
⟨+1(M), ni⟩. Altogether,
we therefore have that, in order to prove Eqn. (5.166) it suﬃces to prove that
the following holds for all n ∈N0:
ηn+1
S
⟨+1(M), ni⟩=

ηn
S⟨M, ni−1⟩
, i > 0
0
, else
(5.167)
We will prove Eqn. (5.167) by natural induction over the bound n ∈N0. In
the proof we will maintain the distinction of the case that M equals a number
constant nj ∈C from the case that M is not a constant, i.e., M ̸∈C. Actually,
in case of constants, Eqn. (5.167) can be proven immediately, without natural
induction, and we will do so as preparatory work now. First, due to the one-
step decomposition of bounded hitting probabilities, i.e., Lemma 2.31, we have
for all constants nj ∈Cnum and bounds n ∈N0 that ηn+1
S
⟨+1(nj), ni⟩equals
the following:

Q∈Λ∅
+1(nj) →Q · ηn
S⟨Q, ni⟩
(5.168)

168
5 Denotational Semantics
We can transform Eqn. (5.168) into the following:
+1(nj) →nj+1 · ηn
S⟨ni, ni⟩+

Q∈Λ∅\{ni}
+1(nj) →Q · ηn
S⟨Q, ni⟩
(5.169)
Due to Lemma 3.3, Eqn. (3.65), clause (xx), we know that +1(nj) →Q
in the second summand of Eqn. (5.169) equals zero for all Q ̸= nj+1. Due
to the deﬁnition of bounded hitting probabilities in Def. 2.24 we know that
ηn
S⟨M, M⟩equals one for all terms M ∈Λ∅and therefore also ηn
S⟨ni, ni⟩in
the ﬁrst summand of Eqn. (5.169) equals one. Altogether we therefore have
that
ηn+1
S
⟨+1(nj), ni⟩=

1
, nj+1 = ni
0
, nj+1 ̸= ni
(5.170)
Due to the deﬁnition of number constants in Sect. 3.1.1 and a further case
distinction, it is possible to rewrite Eqn. (5.170) into the following form:
ηn+1
S
⟨+1(nj), ni⟩=
⎧
⎪
⎨
⎪
⎩

1
, nj = ni−1
0
, nj ̸= ni−1
, i > 0
0
, else
(5.171)
Remember that constants are values in the sense of Def. 3.1.3. Therefore
Lemma 5.29 applies and we have that Eqn. (5.171) equals
ηn+1
S
⟨+1(nj), ni⟩=

ηn
S⟨nj, ni−1⟩
, i > 0
0
, else
(5.172)
Note that Eqn. (5.172) just proves Eqn. (5.167) for the case of constants. Let
us do some further preparatory work and turn our focus onto ηn+1
S
⟨+1(M), ni⟩
for terms M ̸∈Cnum. For all terms M ̸∈Cnum and bounds n ∈N0 we have
that ηn+1
S
⟨+1(M), ni⟩equals

Q∈Λ∅
+1(M) →Q · ηn
S⟨Q, ni⟩
(5.173)
We can transform Eqn. (5.173) into the following:

M′∈Λ∅
+1(M)→+1(M ′) · ηn
S⟨+1(M ′), ni⟩+

Q̸∈{+1(M′) | M′∈Λ∅}
+1(M)→Q · ηn
S⟨Q, ni⟩
(5.174)
In case M is not a constant we know, due to Lemma 3.3, Eqn. (3.65), clause (i),
that +1(M) →+1(M ′) equals M →M ′. Furthermore, due to Lemma 3.3,
Eqn. (3.65), clause (xx), we know that +1(M) →Q equals zero for all terms
Q ∈Λ∅that are diﬀerent from +1(M ′) for all terms M ′ ∈Λ∅. Therefore,
we have that Eqn. (5.174) implies the following for all terms M ̸∈Cnum and
bounds n ∈N0:

5.3 Semantic Correspondence
169
ηn+1
S
⟨+1(M), ni⟩=

M′∈Λ∅
M →M ′ · ηn
S⟨+1(M ′), ni⟩
(5.175)
We proceed with the natural induction for Eqn. (5.167) over bound n ∈N0.
In Case of n=0:
The case that M is a constant is already proven by
Eqn. (5.172). Let us turn to the case of terms M ̸∈Cnum that are not number
constants. This case is also almost trivial. Informally it is not possible to
reach a constant in just one step in this case. Informally we have, due to
Eqn. (5.175), that
η1
S⟨+1(M), ni⟩=

M′∈Λ∅
M →M ′ · η0
S⟨+1(M ′), ni⟩
(5.176)
Now, +1(M ′) is not a constant and therefore, due to the deﬁnition of bounded
hitting probabilities, Def. 2.24, we know that η0
S⟨+1(M ′), ni⟩equals zero.
Therefore, Eqn. (5.176) implies that η1
S⟨+1(M), ni⟩equals zero. On the other
hand, we have that η0
S⟨M, ni⟩also equals zero, because M is not a constant
and therefore Lemma 3.3, Eqn. (3.65), clause (xx) applies, which completes
the proof of Eqn. (5.167) in this case.
In Case of n ⩾1: Again, the case that M is a constant is already proven
by Eqn. (5.172). In case M ∈Cnum is not a constant, we have, due to
Eqn. (5.175), that
ηn+2
S
⟨+1(M), ni⟩=

M′∈Λ∅
M →M ′ · ηn+1
S
⟨+1(M ′), ni⟩
(5.177)
Now, the induction hypothesis applies to ηn+1
S
⟨+1(M ′), ni⟩so that Eqn. (5.177)
is equivalent to
ηn+2
S
⟨+1(M), ni⟩=

M′∈Λ∅
M →M ′ ·

ηn
S⟨M ′, ni⟩
, i > 0
0
, else
(5.178)
Now, we have that ni is arbitrary but ﬁxed in Eqn. (5.178) so that Eqn. (5.178)
can be rewritten as follows:
ηn+2
S
⟨+1(M), ni⟩=

M′∈Λ∅M →M ′ · ηn
S⟨M ′, ni⟩
, i > 0
0
, else
(5.179)
As the ﬁnal step, the one-step decomposition of bounded hitting probabilities,
Lemma 2.31, can be applied backwards to the branch i > 0 in Eqn. (5.179)
so that Eqn. (5.179) is equivalent to
ηn+2
S
⟨+1(M), ni⟩=

ηn+1
S
⟨M, ni⟩
, i > 0
0
, else
(5.180)


170
5 Denotational Semantics
Lemma 5.33 (Performance of Basic Operators)
Given a performing,
closed term of the ground type of numbers, i.e., M :num such that α(M), we
have that α(+1(M)), α(−1(M)) and α(0?(M)).
Proof. We show this only for lambda terms +1(M). The other cases are analo-
gous. We start with the right-hand side of Def. 5.28, clause (a), for an arbitrary
constant c ∈Cnum as follows:
[[+1(M)]]∅([ni]) =

[[M]]([ni] −1)
, [ni] > 0
0
, else
(5.181)
Due to the deﬁnition of data points we have that [ni] = i and, again due to the
deﬁnition of data points, twice, we have that [ni] −1 equals [ni−1]. Therefore,
and due to the premise α(M), we know that Eqn. (5.181) implies
[[+1(M)]]∅([ni]) ⩽

M ⇒ni−1
, i > 0
0
, else
(5.182)
Now, due to Lemma 5.32 we have that Eqn. (5.182) implies
[[+1(M)]]∅([ni]) ⩽M ⇒ni
(5.183)
Eqn. (5.183) completes the proof, because it fulﬁlls the deﬁnition of performing
terms Def. 5.28, clause (a).

Performance of Conditional Expressions
We proceed with closed conditional expressions. We introduce a big-step se-
mantics for conditional expressions in Lemma 5.34 and use it to prove the
performance of conditional expressions in Lemma 5.35.
Lemma 5.34 (Big-Step Approximation of Conditional Expressions)
Given a closed term if (B, N ′, N ′′), closed terms 
N = N0, . . . , Nn such that
if (B, N ′, N ′′) 
N is a program and a constant c ∈C we have that
if (B, N ′, N ′′) 
N ⇒c ⩾B ⇒˙t · N ′ 
N ⇒c + B ⇒˙f · N ′′ 
N ⇒c
(5.184)
Proof. By the deﬁnition of reduction probabilities in Def. 3.5 we have that the
right-hand side of Eqn. (5.184) is equivalent to
ηS⟨B, ˙t⟩· ηS⟨N ′ 
N, c⟩+ ηS⟨B, ˙f⟩· ηS⟨N ′′ 
N, c⟩
(5.185)
Due to Corollary 2.27 and the properties of limits of sequences in Lemma 2.91
we have that Eqn. (5.185) is equivalent to
lim
n→∞( ηn
S⟨B, ˙t⟩· ηS⟨N ′ 
N, c⟩+ ηn
S⟨B, ˙f⟩· ηS⟨N ′′ 
N, c⟩)
(5.186)

5.3 Semantic Correspondence
171
Due to the monotonicity of bounded hitting probabilities, i.e., Lemma 2.28,
the monotonicity of real number multiplication and addition, and the mono-
tone convergence Theorem 2.93 we have that the limit Eqn. (5.186) is also the
least upper bound of its sequence. Therefore, in order to prove Eqn. (5.184)
it suﬃces to prove that the following holds for all n ∈N0:
if (B, N ′, N ′′) 
N ⇒c ⩾ηn
S⟨B, ˙t⟩· ηS⟨N ′ 
N, c⟩+ ηn
S⟨B, ˙f⟩· ηS⟨N ′′ 
N, c⟩(5.187)
We prove Eqn. (5.187) by natural induction over n, i.e., the bound common
to all bounded hitting probabilities in Eqn. (5.187).
In Case of n=0: We can distinguish the three cases that the condition B
is one of the truth constants ˙t or ˙f or otherwise neither of the truth constants.
The proofs for the cases B = ˙t and B = ˙f are almost the same and we show
the case B = ˙t only. In case B = ˙t the left-hand side of Eqn. (5.187) takes the
following form:
if (˙t, N ′, N ′′) 
N ⇒c
(5.188)
Due to Eqn. (2.35) we know that Eqn. (5.188) equals the following:

M′∈ΛP
(if (˙t, N ′, N ′′) 
N −→M ′) · ηS⟨M ′, c⟩
(5.189)
Selecting one particular summand of Eqn. (5.189) we have that Eqn. (5.189)
is greater than or equal (⩾) to
(if (˙t, N ′, N ′′) 
N −→N ′ 
N) · ηS⟨N ′ 
N, c⟩
(5.190)
Due to
Eqn. (3.65), clause (x), we know that (if (˙t, N ′, N ′′) −→N ′) equals
one. Therefore, due to Eqn. (3.65), clause (xii), n times, we know that also
(if (˙t, N ′, N ′′) 
N −→N ′ 
N) equals one. Therefore, we know that Eqn. (5.190)
equals
ηS⟨N ′ 
N, c⟩
(5.191)
Now, we have that η0
S⟨˙t, ˙t⟩= 1 and η0
S⟨˙t, ˙f⟩= 0 due to Lemma 3.3, Eqn. (3.65),
clause (xviii) resp. clause (xx). Therefore, we ﬁnally know that Eqn. (5.191)
equals the right-hand side of Eqn. (5.187), i.e., we have that Eqn. (5.191)
equals the following:
η0
S⟨˙t, ˙t⟩· ηS⟨N ′ 
N, c⟩+ η0
S⟨˙t, ˙f⟩· ηS⟨N ′′ 
N, c⟩
(5.192)
Next we turn to the case in which B is neither of the truth constants ˙t or ˙f. In
this case we know that both η0
S⟨B, ˙t⟩= 0 and η0
S⟨B, ˙f⟩= 0 due to Lemma 3.3,
Eqn. (3.65), clause (xx), so that the right-hand side of Eqn. (5.187) equals zero
in this case, so that Eqn. (5.187) trivially holds.
In Case of n ⩾1: In case n ⩾1 we start with the right-hand side instance
of Eqn. (5.187) as follows:

172
5 Denotational Semantics
ηn+1
S
⟨B, ˙t⟩· ηS⟨N ′ 
N, c⟩+ ηn+1
S
⟨B, ˙f⟩· ηS⟨N ′′ 
N, c⟩
(5.193)
Due to Lemma 2.31 on the decomposition of bounded hitting probabilities,
Eqn. (2.39), we know that Eqn. (5.193) equals the following:

B′∈Λ
B −→B′ · ηn
S⟨B′, ˙t⟩· ηS⟨N ′ 
N, c⟩+

B′∈Λ
B −→B′ · ηn
S⟨B′, ˙f⟩· ηS⟨N ′′ 
N, c⟩
(5.194)
Eqn. (5.194) can be transformed into

B′∈Λ
B −→B′ · (ηn
S⟨B′, ˙t⟩· ηS⟨N ′ 
N, c⟩+ ηn
S⟨B′, ˙f⟩· ηS⟨N ′′ 
N, c⟩)
(5.195)
Now, the induction hypothesis applies and we have that Eqn. (5.195) is less
than or equal (⩽) to

B′∈Λ
B −→B′ · (if (B′, N ′, N ′′) 
N ⇒c)
(5.196)
Now due to Lemma 3.3, Eqn. (3.65), clause(ix), we have that B −→B′ equals
if (B, N ′, N ′′) −→if (B′, N ′, N ′′) and therefore, due to Eqn. (3.65), clause(xii),
n times, we know that B −→B′ equals if (B, N ′, N ′′) 
N −→if (B′, N ′, N ′′) 
N.
Therefore, we know that Eqn. (5.196) equals

B′∈Λ
if (B, N ′, N ′′) 
N −→if (B′, N ′, N ′′) 
N · (if (B′, N ′, N ′′) 
N ⇒c)
(5.197)
Now, it is possible to rewrite Eqn. (5.197) as follows:

M∈{if (B′,N ′,N ′′) 
N | B′∈Λ}
if (B, N ′, N ′′) 
N −→M · (M ⇒c)
(5.198)
Now, as it has fewer summands, we see that Eqn. (5.197) is less than or equal
(⩽) to

M∈Λ
if (B, N ′, N ′′) 
N −→M · (M ⇒c)
(5.199)
Due to Eqn. (2.35) we know that Eqn. (5.199) equals
if (B, N ′, N ′′) 
N ⇒c
(5.200)
Actually, Eqn. (5.200) completes the proof because it equals the left-hand side
of Eqn. (5.187).

Lemma 5.35 (Performance of Conditional Expressions)
Given a
performing, Boolean program B and performing, closed terms N ′ and N ′′,
i.e., B :bool, N ′ : t and N ′′ : t for some type t ∈T such that α(B), α(N ′) and
α(N ′′) we have that α(if (B, N ′, N ′′)).

5.3 Semantic Correspondence
173
Proof. Given a constant c : t′ and closed terms 
N = N0, . . . , Nn such that
α(Ni) for all 0 ⩽i ⩽n and if (B, N ′, N ′′) 
N is a program of type t′. We start
as follows:
[[if (B, N ′, N ′′) 
N]]∅[c]
(5.201)
Due to semantic equation Eqn. (5.32), n times, we have that Eqn. (5.201)
equals
[[if (B, N ′, N ′′)]]∅
[[N]]∅[c]
(5.202)
Due to semantic equation Eqn. (5.30) and the deﬁnition of semantic data
points in Def. 5.25, i.e., [true] =
  and [ ˙f] =
 , we have that Eqn. (5.202)
equals
([[ B ]]∅[˙t] ⊗[[ N ′ ]]∅⊕[[ B ]]∅[ ˙f] ⊗[[ N ′′ ]]∅) 
[[N]]∅[c]
(5.203)
Due to the properties of the scalar operations as well as semantic equation
Eqn. (5.32), n times, we have that Eqn. (5.203) equals
([[B ]]∅[˙t] · [[ N ′ 
N ]]∅[c] + [[B ]]∅[ ˙f] · [[ N ′′ 
N ]]∅[c]
(5.204)
Now, the premises α(B), α(N ′) and α(N ′′) apply. Due to α(B) we have that
[[B]]∅[˙t] ⩽B ⇒˙t and [[B]]∅[ ˙f] ⩽B ⇒˙f, because of Def. 5.28, clause (a). Next,
due to Def. 5.28, clause (a), n times, the premises α(N ′) and α(N ′′), and the
fact that α(Ni) for all Ni of 
N we have that also α(N ′ 
N) and α(N ′′ 
N). Now,
due to α(N ′ 
N) we have that [[N ′ 
N]]∅[c] ⩽N ′ 
N ⇒c. Similarly, we have that
[[N ′′ 
N]]∅[c] ⩽N ′′ 
N ⇒c. Altogether, we have that Eqn. (5.204) is less than or
equal (⩽) to
B ⇒˙t · N ′ 
N ⇒c + B ⇒˙f · N ′′ 
N ⇒c
(5.205)
Next, due to the big-step approximation Lemma for conditional expressions,
i.e., Lemma 5.34, we have that Eqn. (5.205) is less than or equal (⩽) to
if (B, N ′, N ′′) 
N ⇒c
(5.206)
Due to the fact that Eqn. (5.201) is less than or equal (⩽) to Eqn. (5.206) for
all constants c : t′ and the deﬁnition of performing terms Def. 5.28, clause (a),
we have that α(if (B, N ′, N ′′) 
N). Therefore, and due to Lemma 5.31, we ﬁnally
have that α(if (B, N ′, N ′′)).

Performance of Applications
We proceed with closed application expressions. This is a particularly easy
case in which we do not need a notion of big-step semantics, i.e., this case is
an immediate Corollary of Def. 5.28; see Lemma 5.36.
Lemma 5.36 (Performance of Applications)
Given closed performing
terms M : t1 →t2 and N : t1, i.e., α(M) and α(N), we have that α(MN).

174
5 Denotational Semantics
Proof. The Lemma immediately follows from the deﬁnition of performing
terms, Def. 5.28. Due to Def. 5.28, clause (b), we have that α(M) and α(N)
implies α(MN).

Performance of Abstractions
We proceed with closed abstraction expressions. Here, we again follow the
pattern of establishing a big-step semantics ﬁrst and the respective perfor-
mance on the basis of this. We introduce a big-step semantics for abstrac-
tions in Lemma 5.37 and use it to prove the performance of abstractions in
Lemma 5.38.
Lemma 5.37 (Big-Step Approximation of Abstractions)
Given a
closed term λx.M, closed terms N0, . . . , Nn such that (λx.M) 
N is a program
and a constant c ∈C we have that
((λx.M)N0N1 . . . Nn ⇒c) ⩾(M[x:=N0] N1 . . . Nn ⇒c)
(5.207)
Proof. Henceforth, let us use 
N to denote N0, N1, . . . , Nn and 
N ′ to denote
N1, . . . , Nn. We start with the left-hand side of Eqn. (5.207) as follows:
(λx.M) 
N ⇒c
(5.208)
Due to the one-step decomposition of hitting probabilities, Eqn. (2.35), we
have that Eqn. (5.208) equals

Q∈Λ∅
(λx.M) 
N →Q · Q ⇒c
(5.209)
Selecting one particular summand of Eqn. (5.209) we have that Eqn. (5.209)
is greater than or equal (⩾) to
(λx.M) 
N →M[x:=N0] 
N ′ · M[x:=N0] 
N ′ ⇒c
(5.210)
Let us analyze Eqn. (5.210) further and have a look at its sub term (λx.M) 
N,
which actually is (λx.M)N0N1 . . . Nn. Due to Lemma 3.3, Eqn. (3.65), (xiii)
we have that (λx.M)N0 →M[x := N0] equals one. Now, Lemma 3.3,
Eqn. (3.65) (xii), applies n times so that (λx.M) 
N →M[x:=N0] 
N ′ equals
one, so that Eqn. (5.210) equals
M[x:=N0] 
N ′ ⇒c
(5.211)
But Eqn. (5.211) is just the right-hand side of Eqn. (5.207) so that it completes
the proof.


5.3 Semantic Correspondence
175
Lemma 5.38 (Performance of Abstractions)
Given a performing
term M, i.e., α(M), such that Vfree(M) = {x} and x : t, we have that
α(λx.M).
Proof. Given a constant c : t′ and closed terms 
N = N0, . . . , Nn such that
α(Ni) for all 0 ⩽i ⩽n and λx.M 
N is a program of type t′. We start as
follows:
[[λx.M 
N]]∅[c]
(5.212)
Due to semantic equation Eqn. (5.32), n times plus once, we have that
Eqn. (5.212) equals
[[λx.M]]∅[[N0]]∅[[N1]]∅. . . [[Nn]]∅[c]
(5.213)
Due to the semantic equation Eqn. (5.31) we have that Eqn. (5.213) equals
(λd ∈t →[[M]]∅[x:=d]) [[N0]]∅[[N1]]∅. . . [[Nn]]∅[c]
(5.214)
Function application of (λd ∈t →[[M]]∅[x:=d]) to [[N0]]∅in Eqn. (5.214) yields
the following:
[[M]]∅[x:=[[N0]]∅] [[N1]]∅. . . [[Nn]]∅[c]
(5.215)
Due to the substitution Lemma 5.24 we have that Eqn. (5.215) equals
[[M[x := N0]]]∅[[N1]]∅. . . [[Nn]]∅[c]
(5.216)
Again due to the semantic equation Eqn. (5.32), n times in this case, we have
that Eqn. (5.216) equals
[[M[x := N0] N1 . . . Nn]]∅[c]
(5.217)
Due to the premise α(M) of the Lemma, and the fact that α(M[x := N0]),
we have due to Def. 5.28, clause (c) that α(M[x := N0] N1 . . . Nn). Therefore,
due to Def. 5.28, clause (a) we have that Eqn. (5.217) is less than or equal
(⩽) to the following:
M[x := N0] N1 . . . Nn ⇒c
(5.218)
Now, due to the big-step approximation of abstractions, see Lemma 5.37, we
have that Eqn. (5.218) is less than or equal (⩽) to the following:
λx.M N0 N1 . . . Nn ⇒c
(5.219)
Due to the that fact Eqn. (5.212) is less than or equal (⩽) to Eqn. (5.219) for
all constants c : t′ and the deﬁnition of performing terms Def. 5.28, clause (a),
we have that α((λx.M) 
N). Therefore, and due to Lemma 5.31, we ﬁnally have
that α(λx.M).


176
5 Denotational Semantics
Performance of Recursions
We proceed with closed recursion expressions. This is the most elaborate case.
We need to introduce a family of standard non-terminating terms. Next, we
give some little helper lemmas on the denotational semantics and operational
semantics of these non-terminating terms. Next, we need to introduce the
syntactical notion of n-fold term application and the syntactical notion of
term unwinding. We will establish a big-step semantics for term unwindings
and, on the basis of this, will prove the performance of term unwindings.
In order to prove the performance of term unwindings we also need a little
helper lemma on the semantics of bottom elements in base contexts. Next, we
will establish a syntactical notion of approximation, called syntactic recursion
approximations. We will investigate how syntactic recursion approximation
is preserved under the decomposition of terms. Next, we will introduce a
notion of syntactic simulation. All this is needed to understand the semantic
correspondence of term unwinding and recursions. Based on that, we will be
able to prove the performance of recursions.
Deﬁnition 5.39 (Non-Terminating Term)
We deﬁne non-terminating
terms Ωt : t for all types t ∈T inductively as follows:
Ωnum = μλxnum . x
(5.220)
Ωbool = μλxbool . x
(5.221)
Ωt1→t2 = λxt1 . Ωt2
(5.222)
Lemma 5.40 (Denotational Semantics of Non-Terminating Terms)
For all types t ∈T we have
[[Ωt]]∅= ⊥t
(5.223)
Proof. The proof is straightforward by structural induction over the construc-
tion of types t ∈T .
In Case of t ∈Tg:
In case of ground types t ∈Tg we have that [[Ωt]]∅
equals [[μλxt . x]]∅due to Def. 5.39, Eqn. (5.220). Due to the semantic equation
Eqn. (5.33) and the ﬁxed-point Theorem 2.79 we have that [[μλxt . x]]∅equals
⊔
n∈ω[[λxt . x]]n
∅(⊥t). Now, due to the semantic equation Eqn. (5.32) we know
that [[λxt . x]]∅equals d ∈[[t]] →[[x]]∅[x:=d], which equals, due to the semantic
equation Eqn. (5.23), the function d ∈[[t]] →d, i.e., the identity function
id[[t]] on base domain [[t]]. Therefore, we know that also n-fold application
[[λxt . x]]n
∅(⊥t) of [[λxt . x]]∅to (⊥t) yields (⊥t) for all n ∈N0. Therefore, we
also know that ⊔
n∈ω[[λxt . x]]n
∅(⊥t) equals (⊥t).
In Case of t = t1 →t2:
In case of higher types t1 →t2 we have that
[[Ωt1→t2]]∅equals d ∈t1 →[[Ωt2]]∅[x:=d] which equals d ∈t1 →[[Ωt2]]∅, because
we have that Ωt2 is a closed term and therefore Lemma 5.23 applies. Now,

5.3 Semantic Correspondence
177
the induction hypothesis applies and we therefore know that d ∈t1 →[[Ωt2]]∅
equals d ∈t1 →⊥t2. However, ﬁnally we know that by deﬁnition of domain
bottom elements d ∈t1 →⊥t2 equals ⊥t1→t2; compare, e.g., with Eqn. (5.13).

Lemma 5.41 (Operational Semantics of Non-Terminating Terms)
For all types t ∈T and terms 
N = N0 . . . Nn such that Ωt 
N has ground type,
i.e., there exist t′ ∈Tg so that Ωt 
N : t′, we have, for all c ∈Ct′ that the
following holds:
(Ωt 
N ⇒c) = 0
(5.224)
Proof. The proof is conducted by structural induction over the construction
of types t ∈T .
In Case of t ∈Tg:
In case of ground types we know that 
N has length
n = 0, so that prooving (Ωt 
N ⇒c) = 0 amounts to proving (Ωt ⇒c) = 0.
Now, in case of ground types t ∈Tg the non-terminating term Ωt is deﬁned
as μλxt . x; see Def. 5.39, Eqn. (5.220) – let’s drop t from xt in the sequel for
better readability. Due to the deﬁnition of termination degree in Def. 4.1 we
know that a program M that has a termination degree of zero, i.e., a program
M with ηS⟨M, C⟩= 0, never hits a constant, which means that (M ⇒c) = 0
for all c ∈C. Therefore, let us prove (μλx.x ⇒c) = 0 for all c ∈Ct by
proving that the termination degree ηS⟨μλx.x, C⟩equals zero. We follow the
algorithm described in Theorem 4.27 to determine the termination degree of
μλx.x. As the ﬁrst step we use the cover algorithm from Theorem 4.26 to
determine the ﬁnite cover CoverS(μλx.x) of μλx.x. Actually, we can immedi-
ately see that CoverS(μλx.x) consists of the terms μλx.x and λx.x(μλx.x).
Nevertheless, we prove it rigorously on the basis of Theorem 4.26 as an exer-
cise. First, by Eqn. (4.68) we know that cover(μλx.x) equals cover′(∅, μλx.x).
Now, due to Lemma 3.3, Eqn. (3.65), clause (xiv) and clause (xx) we know that
λx.x(μλx.x) is the one and only term M ∈ΛP such that μλx.x −→M > 0.
Therefore, due to the deﬁnition of the reduction graph R in Def. 4.14 and its
underlying reduction relation ρ as deﬁned in Def. 4.13 we know that the set of
outgoing edges of μλx.x in ER consists of μλx.x −→M > 0 as single element.
Therefore, by Eqn. (4.69), third clause, we know that cover′(∅, μλx.x) equals
cover′({μλx.x}, λx.x(μλx.x))
(5.225)
For a similar line of argumentation, this time based on clause (xiii) and again
clause (xx) in Lemma 3.3, Eqn. (3.65), we can see that Eqn. (5.225) equals
cover′({μλx.x, λx.x(μλx.x)}, μλx.x)
(5.226)
However, we have that μλx.x belongs to the ﬁrst argument set of cover′ in
Eqn. (5.226). Therefore, due to Eqn. (4.69), ﬁrst clause, we know that cover′
terminates as the next step, which ﬁnally yields

178
5 Denotational Semantics
CoverS(μλx.x) = {μλx.x, λx.x(μλx.x)}
(5.227)
Now, due to Theorem 4.27, Eqn. (4.85), and again Lemma 3.3, Eqn. (3.65),
clauses (xiv), (xiii) and (xx), we have that the vector of hitting probabilities
consisting of ηS⟨μλx.x, C⟩and ηS⟨λx.x(μλx.x), C⟩is determined as the least
solution of the following ﬁnite linear equation system:
ηS⟨μλx.x, C⟩= ηS⟨λx.x(μλx.x), C⟩
ηS⟨λx.x(μλx.x), C⟩= ηS⟨μλx.x, C⟩
(5.228)
Finally, the least solution Eqn. (5.228) yields that μλx.x equals zero.
In Case of t = t1 →t2: In case of higher types we know due to Def. 5.39,
Eqn. (5.222) that Ωt1→t2 equals λxt1.Ωt2. Due to Eqn. (2.35) we have that
Ωt1→t2 
N ⇒c equals

M∈Λ∅
((λxt1.Ωt2) 
N −→M) · (M ⇒c)
(5.229)
Remember that 
N = N0N1 . . . Nn. In the next few equations, let 
N ′ denote
the tail of 
N after dropping N0, i.e., let 
N ′ = N1 . . . Nn. Now, we can always
transform Eqn. (5.229) into the following:
((λxt1.Ωt2) 
N −→Ωt2 
N ′) · (Ωt2 
N ′ ⇒c) +

M∈Λ∅\{Ωt2 
N ′}
((λxt1.Ωt2) 
N −→M) · (M ⇒c)
(5.230)
With respect to the second summand in Eqn. (5.230), we know, due to
Lemma 3.3, Eqn. (3.65), clause (xx) that (λxt1.Ωt2) 
N −→M equals zero for all
M ̸= Ωt2 
N ′. With respect to the ﬁrst summand in Eqn. (5.230) we can apply
the induction hypothesis and know that Ωt2 
N ′ ⇒c equals zero. Therefore,
overall we have that Eqn. (5.230) equals zero, which completes the proof. 
Deﬁnition 5.42 (n-fold Term Application) For each term of some higher
type M : t →t we deﬁne a term M n : t →t, called the n-fold application
of term M, for all n ∈N0 and arbitrary terms N : t of appropriate type t
inductively as follows:
M 0N = N
(5.231)
M n+1N = M(M nN)
(5.232)
Deﬁnition 5.43 (Unwinding Term) For each term of some higher type
M : t →t we deﬁne a term ⟨MnΩ⟩: t →t, called the n-times unwinding of
term M, or unwinding term for short, for all n ∈N0 inductively as follows:
⟨M0Ω⟩= Ωt→t
(5.233)
⟨Mn+1Ω⟩= (λft→t . (f ⟨MnΩ⟩)) M
(5.234)

5.3 Semantic Correspondence
179
Lemma 5.44 (Semantics of Bottom Elements in Base Contexts)
For all types t ∈T and data d = d0 . . . dn such that ⊥t d is a base element,
i.e., there exists t′ ∈Tg so that ⊥t d ∈[[t′]] with [[t′]] = ⌊S −→[0, 1]ω⌋for some
set S, we have, for all data points p ∈S that the following holds:
⊥t d p = 0
(5.235)
Proof. This lemma follows as an immediate corollary from the deﬁnitions of
the established domains in Sect. 5.1.1. We have that ⊥t d equals ⊥t′ due
to Eqn. (5.13), n times, and therefore ⊥t dp = 0 due to Eqn. (5.7) resp.
Eqn. (5.10) one time.

Lemma 5.45 (Big-Step Approximation of Term Unwindings) Given
a closed term M : t →t, closed terms 
N = N1, . . . , Nn such that ⟨Mn+1Ω⟩
N
is a program and a constant c ∈C we have that
⟨Mn+1Ω⟩
N ⇒c ⩾(M(⟨MnΩ⟩
N)⇒c)
(5.236)
Proof. Due to the one-step decomposition of hitting probabilities, Eqn. (2.35),
we have that the left-hand side of Eqn. (5.236) equals the following:

Q∈Λ∅
⟨Mn+1Ω⟩
N →Q · Q ⇒c
(5.237)
Now, we can select one particular summand of Eqn. (5.237) and have that
Eqn. (5.237) is greater than or equal (⩾) to the following:
⟨Mn+1Ω⟩
N →M(⟨MnΩ⟩
N) · M(⟨MnΩ⟩
N) ⇒c
(5.238)
Let us consider the following sub-term of Eqn. (5.238), i.e.,
⟨Mn+1Ω⟩
(5.239)
Now, due to the deﬁnition of unwinding terms, Def. 5.43, Eqn. (5.234), we
have that Eqn. (5.239) is identical to the following:
(λft→t . (f ⟨MnΩ⟩))M
(5.240)
Due to Lemma 3.3, Eqn. (3.65), clause (xiii), we know the following:
((λft→t . (f ⟨MnΩ⟩))M →((f ⟨MnΩ⟩)[f := M])) = 1
(5.241)
Now, due to the deﬁnition of substitution, the fact that M is a closed term,
and again Def. 5.43, Eqn. (5.234), we know that Eqn. (5.241) is equivalent to
the following:
(⟨Mn+1Ω⟩→(M ⟨MnΩ⟩)) = 1
(5.242)
Then, due to Lemma 3.3, Eqn. (3.65), clause (xii), applied n times, we have
that Eqn. (5.242) implies

180
5 Denotational Semantics
(⟨Mn+1Ω⟩
N →(M ⟨MnΩ⟩) 
N) = 1
(5.243)
Now, Eqn. (5.243) just states that the left factor of Eqn. (5.238) equals one.
Therefore, we have that Eqn. (5.238) equals
M(⟨MnΩ⟩
N) ⇒c
(5.244)
Now, with Eqn. (5.244) we are ﬁnished, because it is the right-hand side of
Eqn. (5.236).

Lemma 5.46 (Performance of Unwinding Terms) Given a performing,
closed term M : t →t we have that α(⟨MnΩ⟩) for all n ∈N0.
Proof. Given a constant c : t′ and closed terms 
N = N0, . . . , Nn such that
α(Ni) for all 0 ⩽i ⩽n and ⟨MnΩ⟩
N. We proceed with showing that
α(⟨MnΩ⟩
N) by a natural induction over the number of unwindings n. From
this we will then conclude that α(⟨MnΩ⟩).
In Case of n=0: In the base case, we start as follows:
[[⟨M0Ω⟩
N]]∅[c]
(5.245)
Due to the semantic equation Eqn. (5.32), n times, we have that Eqn. (5.245)
equals
[[⟨M0Ω⟩]]∅
[[N]]∅[c]
(5.246)
Due to the deﬁnition of unwinding terms, compare with Eqn. (5.233), we have
that Eqn. (5.246) equals
[[Ωt→t]]∅
[[N]]∅[c]
(5.247)
Due to the denotational semantics of non-terminating terms, i.e., Lemma 5.40,
we have that Eqn. (5.247) equals
[[⊥t→t]]∅
[[N]]∅[c]
(5.248)
Due to the denotational semantics of bottom elements in base contexts, i.e.,
Lemma 5.44, we have that Eqn. (5.248) equals zero for all constants and
therefore we have that α(⟨M0Ω⟩
N).
In Case of n ⩾1: In case the number of unwindings is n ⩾1, we start as
follows:
[[⟨Mn+1Ω⟩
N]]∅[c]
(5.249)
Again, due to the semantic equation Eqn. (5.32), n times, we have that
Eqn. (5.249) equals
[[⟨Mn+1Ω⟩]]∅
[[N]]∅[c]
(5.250)

5.3 Semantic Correspondence
181
Due to the deﬁnition of unwinding terms, compare with Eqn. (5.234), we have
that Eqn. (5.250) equals
[[(λft→t . (f ⟨MnΩ⟩)) M]]∅
[[N]]∅[c]
(5.251)
Due to semantic equation Eqn. (5.32) we have that Eqn. (5.251) equals
[[(λft→t . (f ⟨MnΩ⟩))]]∅[[M]]∅
[[N]]∅[c]
(5.252)
Due to semantic equation Eqn. (5.31) we have that Eqn. (5.252) equals
d ∈[[t →t]] →[[f ⟨MnΩ⟩]]∅[x:=d] [[M]]∅
[[N]]∅[c]
(5.253)
After function application we have that Eqn. (5.253) yields
[[f ⟨MnΩ⟩]]∅[f:=[[M]]∅] 
[[N]]∅[c]
(5.254)
Due to the substitution Lemma 5.24 we have that Eqn. (5.254) equals
[[(f ⟨MnΩ⟩)[x := M]]]∅
[[N]]∅[c]
(5.255)
Due to the deﬁnition of substitution plus the fact that M is a closed term we
have that Eqn. (5.255) equals
[[M(⟨MnΩ⟩)]]∅
[[N]]∅[c]
(5.256)
Due to semantic equation Eqn. (5.32) we have that Eqn. (5.256) equals
[[(M(⟨MnΩ⟩)) 
N]]∅[c]
(5.257)
Now, we can apply the induction hypothesis α(⟨MnΩ⟩
N). Due to α(⟨MnΩ⟩
N)
and Lemma 5.31 we also have that α(⟨MnΩ⟩). Furthermore, we can ex-
ploit α(M), which is a premise of the lemma. Due to α(M), α(⟨MnΩ⟩), and
Def. 5.28, clause (b), we have that α(M(⟨MnΩ⟩)). Now, due to α(M(⟨MnΩ⟩))
and again Def. 5.28, clause (b), n times, we have that α((M(⟨MnΩ⟩)) 
N).
Based on α((M(⟨MnΩ⟩)) 
N) and Def. 5.28, clause (a) we are able to see that
Eqn. (5.257) is less than or equal (⩽) to the following:
(M(⟨MnΩ⟩)) 
N ⇒c
(5.258)
Next, we can apply the big-step approximation of term unwindings, i.e.,
Lemma 5.45, to Eqn. (5.258), so that we know that Eqn. (5.258) is less than
or equal (⩽) to the following:
(⟨Mn+1Ω⟩) 
N ⇒c
(5.259)
Together with Def. 5.28, clause (a), we have that Eqn. (5.259) amounts to
α(⟨Mn+1Ω⟩
N) which completes our natural induction proof of α(⟨MnΩ⟩
N)
for all n ∈N0. Now, as the ﬁnal step we have, due to α(⟨MnΩ⟩
N) and
Lemma 5.31, that α(⟨MnΩ⟩).


182
5 Denotational Semantics
Deﬁnition 5.47 (Syntactic Recursion Approximation) We deﬁne the
syntactic approximation relation ≼: Λ × Λ inductively by the following set
of rules:
(i)
M : t
Ωt ≼M
(ii)M : t →t
n ∈N0
⟨MnΩ⟩≼μM
(iii)M ≼M
(iv)
M ≼M ′
λx.M ≼λx.M ′
(v)M ≼M ′
N ≼N ′
MN ≼M ′N ′
(vi)M ≼M ′
N ≼N ′
M|N ≼M ′|N ′
Lemma 5.48 proves that the syntactic approximation is preserved under
the one-step semantics. First, Lemma 5.48 reﬁnes Lemma 3.3. Lemma 3.3
states that the one-step transition is a total function; now, Lemma 5.48 makes
explicit why in terms of the concrete possible next reduction steps that can
be made for a term. On the basis of this, Lemma 5.48 states the preservation
property that is also illustrated in Fig. 5.1.
Lemma 5.48 (Preservation of Syntactic Approximation)
Given a
closed term P. Then (i) either there exists a closed term P ′ such that P
1−→P ′
and P
0−→P ′′ for all P ′′ ̸= P ′ or there exist closed terms P ′ and P ′′ such
that P ′ ̸= P ′′, P
0.5
−−→P ′, P
0.5
−−→P ′′ and P
0−→P ′′′ for all P ′′′ ̸= P ′ and
P ′′′ ̸= P ′′. Furthermore, (ii) given a closed term Q such that P ≼Q. Then,
in case there exists a P ′ with P
1−→P ′ there exists a Q′ with Q
1−→Q′ such
that P ′ ≼Q′. Furthermore, in case there exist closed terms P ′ and P ′′ with
P ′ ̸= P ′′, P
0.5
−−→P ′ and P
0.5
−−→P ′′ there exist closed terms Q′ and Q′′ with
Q′ ̸= Q′′, P
0.5
−−→Q′ and Q
0.5
−−→Q′′ such that P ′ ≼Q′ and P ′′ ≼Q′′.
Proof. The Lemma can be proven by structural induction over the construction
of term P on the basis of Lemma 3.3.

(i)
Q
1
−→Q′
≼
≼
P
1
−→P ′
(ii)
Q′
0.5
←−Q
0.5
−→Q′′
≼
≼
≼
P ′
0.5
←−P
0.5
−→P ′′
Fig. 5.1. Preservation of syntactic approximation under reduction
Lemma 5.49 (Syntactic Simulation) Given closed terms A and B such
that A ≼B and closed terms 
N = N0, . . . , Nn such that A 
N and B 
N are
programs we have that
A 
N ⇒c ⩽B 
N ⇒c
(5.260)

5.3 Semantic Correspondence
183
Proof. Due to the deﬁnition of reduction probabilites in Def. 3.5 and Corol-
lary 2.27 we have that Eqn. (5.260) is equivalent to
lim
n→∞ηn
S⟨A 
N, c⟩⩽lim
n→∞ηn
S⟨B 
N, c⟩
(5.261)
Due to the monotonicity of bounded hitting probabilities, i.e., Lemma 2.28
and the monotone convergence Theorem 2.93, we have that both of the limits
in Eqn. (5.166) are also the least upper bound of their respective chains.
Therefore, in order to prove Eqn. (5.261) it suﬃces to prove that the following
holds for all n ∈N0:
ηn
S⟨A 
N, c⟩⩽ηn
S⟨B 
N, c⟩
(5.262)
We can prove Eqn. (5.262) by a natural induction over the bound n ∈N0. We
show the base case n = 0 only. In case of η0
S⟨A 
N, c⟩it suﬃces to consider two
general cases, i.e., the case that A 
N ̸= c and the case that A 
N = c. In the case
that A 
N ̸= c we have, due to the deﬁnition of bounded hitting probabilities,
Def. 2.24, that η0
S⟨A 
N, c⟩equals zero, and therefore η0
S⟨A 
N, c⟩is less than or
equal to P ⇒c for all programs P and, as a special case, also for all programs
B with A ≼B. In the case that A 
N = c we have that A 
N is a constant, just
because c ∈C. As a matter of detail, we know that 
N is empty in this case
with n = 0 and A ∈C. Now, in case A is a constant we know, due to the
deﬁnition of syntactic approximation in Def. 5.47, that A is the only term
that is syntactically approximated by A, and we have that there is no B with
A ̸= B and A ≼B. This is so, because syntactic approximation is inductively
deﬁned by Def. 5.47 and is therefore the least relation closed under the rules
in Def. 5.47. Now, rule (iii) in Def. 5.47, which is the rule of reﬂexivity, is the
only one that is applicable to deduce a term B such that A ≼B in case that
A is a constant.

Lemma 5.50 (Semantic Equality of Unwindings and Recursions)
Given a closed term M and an arbitrary number n ∈N0 we have that
[[μM]]∅= ⊔
n∈ω[[⟨MnΩ⟩]]∅
(5.263)
Proof. Due to semantic equation Eqn. (5.31) and the ﬁxed-point Theorem 2.79
we know that [[μM]]∅equals
⊔
n∈ω[[M]]n
∅(⊥t→t)
(5.264)
Therefore, in order to prove Eqn. (5.263) it suﬃces to show that the following
holds for all numbers n ∈N0 of unwindings:
[[⟨MnΩ⟩]]∅= [[M]]n
∅(⊥t→t)
(5.265)
We prove Eqn. (5.265) by natural induction over n.

184
5 Denotational Semantics
In Case of n = 0: Due to Def. 5.43 we have that [[⟨M0Ω⟩]]∅equals [[Ωt→t]]∅.
Due to Lemma 5.40 we have that [[Ωt→t]]∅equals ⊥t→t. Finally, we immedi-
ately know that ⊥t→t equals [[M]]0
∅(⊥t→t).
In Case of n > 0: Due to the deﬁnition of unwinding terms in Def. 5.43
we have that [[⟨Mn+1Ω⟩]]∅equals
[[(λft→t . (f ⟨MnΩ⟩)) M]]∅
(5.266)
Due to the semantic equation Eqn. (5.32) we have that Eqn. (5.266) equals
[[λft→t . (f ⟨MnΩ⟩)]]∅[[M]]∅
(5.267)
Due to the semantic equation Eqn. (5.31) we have that Eqn. (5.267) equals
(d∈[[t →t]] →[[f ⟨MnΩ⟩]]∅[f:=d]) [[M]]∅
(5.268)
Due to ordinary function application we have that Eqn. (5.268) equals
[[f ⟨MnΩ⟩]]∅[f:=[[M]]∅]
(5.269)
Again, due to the semantic equation Eqn. (5.32) we have that Eqn. (5.269)
equals
[[f]]∅[f:=[[M]]∅] [[⟨MnΩ⟩]]∅[f:=[[M]]∅]
(5.270)
Due to the semantic equation Eqn. (5.23) applied to the function Eqn. (5.270)
plus the fact that the ⟨MnΩ⟩in Eqn. (5.270) is a closed term and again
semantic equation Eqn. (5.23), we have that Eqn. (5.270) equals
[[M]]∅[[⟨MnΩ⟩]]∅
(5.271)
Now, it is possible to apply the induction hypothesis to ⟨MnΩ⟩. Therefore we
know that Eqn. (5.271) equals
[[M]]∅([[M]]n
∅(⊥t→t))
(5.272)
Actually, with Eqn. (5.272) the proof is completed, because Eqn. (5.272) sim-
ply equals [[M]]n+1
∅
(⊥t→t); see Def. 2.83 for n-fold function application.

Lemma 5.51 (Performance of Recursions) Given a performing, closed
term M, i.e., α(M), we have that α(μM).
Proof. Given a constant c : t′ and closed terms 
N = N1, . . . , Nn such that
α(Ni) for all 0 ⩽i ⩽n and μM 
N is a program of type t′. We start as follows:
[[(μM) 
N]]∅[c]
(5.273)

5.3 Semantic Correspondence
185
Due to semantic equation Eqn. (5.32), n times, we have that Eqn. (5.273)
equals
[[μM]]∅
[[N]]∅[c]
(5.274)
Due to Lemma 5.50 we have that Eqn. (5.274) equals

⊔
n∈ω[[⟨MnΩ⟩]]∅
 
[[N]]∅[c]
(5.275)
Due to the deﬁnition of least upper bounds of chains of functions that have an
ω-cpo as range, i.e., Lemma 2.64, n times, we have that Eqn. (5.275) equals
the following:

⊔
n∈ω([[⟨MnΩ⟩]]∅
[[N]]∅)

[c]
(5.276)
Due to semantic equation Eqn. (5.32), n times, we have that Eqn. (5.276)
equals

⊔
n∈ω[[⟨MnΩ⟩
N]]∅

[c]
(5.277)
Again due to Def. 2.64 we know that Eqn. (5.277) equals
⊔
n∈ω

[[⟨MnΩ⟩
N]]∅[c]

(5.278)
Next, we turn our attention to the single elements of the chain in Eqn. (5.278),
i.e., [[⟨MnΩ⟩
N]]∅for all numbers n ∈N0. The idea is to show that μM 
N ⇒c is
an upper bound of all [[⟨MnΩ⟩
N[c]]]∅and therefore also greater than or equal
to the least upper bound in Eqn. (5.278). Now, we have α(M) as a premise
of this lemma. With α(M) we can apply Lemma 5.46, which ensures the
performance of unwinding terms, so that we have α(⟨MnΩ⟩) for all n ∈N0.
Now that we have α(⟨MnΩ⟩) and due to the fact that α(Ni) for all Ni of

N we also have that α(⟨MnΩ⟩
N) due to the deﬁnition of performing terms
Def. 5.28, clause (b), n times. Based on α(⟨MnΩ⟩
N) and Def. 5.28, clause (a),
we can conclude that the following holds:
[[⟨MnΩ⟩
N]]∅[c] ⩽⟨MnΩ⟩
N ⇒c
(5.279)
Next, by the deﬁnition of unwinding term approximation in Def. 5.47, rule
(ii) once and rule (v) n times, we know the following:
⟨MnΩ⟩
N ≼μM 
N
(5.280)
Now, due to the fact that ⟨MnΩ⟩syntactically approximates μM 
N, i.e.,
Eqn. (5.280), we can apply the syntactic simulation Lemma 5.49 so that we
have the following:
⟨MnΩ⟩
N ⇒c ⩽μM 
N ⇒c
(5.281)
From Eqn. (5.279) and Eqn. (5.281) we can conclude that for all n ∈N0 we
have that

186
5 Denotational Semantics
[[⟨MnΩ⟩
N]]∅[c] ⩽μM 
N ⇒c
(5.282)
With Eqn. (5.282) we know that (μM) 
N ⇒c is an upper bound for all chain
elements in Eqn. (5.278) and therefore is also greater than their least upper
bound Eqn. (5.278). Remember that we have already shown that Eqn. (5.273)
equals Eqn. (5.278), which almost ﬁnishes the proof, i.e., we have that
[[(μM) 
N]]∅[c] ⩽μM 
N ⇒c
(5.283)
By Def. 5.28, clause (a), we have that Eqn. (5.283) means α(μM 
N). Finally,
with α(μM 
N) and Def. 5.28, clause (b), n times, we have that α(μM).

Performance of Choice Expressions
The case of choice expressions is again straightforward. First, we introduce a
big-step semantics for choices in Lemma 5.52, then we prove the performance
of choices in Lemma 5.53.
Lemma 5.52 (Big-Step Approximation of Choices) Given closed terms
M1 and M2, closed terms N1, . . . , Nn such that (M1|M2) 
N is a program and
a constant c ∈C we have that
((M1|M2) 
N ⇒c) ⩾(0.5 · M1 
N ⇒c + 0.5 · M2 
N ⇒c)
(5.284)
Proof. Due to the one-step decomposition of hitting probabilities, Eqn. (2.35),
we have that the left-hand side of Eqn. (5.284), i.e., (M1|M2) 
N equals

Q∈Λ∅
(M1|M2) 
N →Q · Q ⇒c
(5.285)
Let us assume M1 ̸= M2. Now, we can select two particular summands of
Eqn. (5.285) and have that Eqn. (5.285) is greater than or equal (⩾) to the
following:
((M1|M2) 
N →M1 
N ·M1 
N ⇒c)+((M1|M2) 
N →M2 
N ·M2 
N ⇒c) (5.286)
Due to Lemma 3.3, Eqn. (3.65), clause (xv), we know that (M1|M2) →M1
equals 0.5. Then, due to Lemma 3.3, Eqn. (3.65), clause (xii), applied n times,
we have that (M1|M2) 
N →M1 
N equals 0.5. Analogously, due to Lemma 3.3,
Eqn. (3.65), clause (xvi) we have that (M1|M2) →M2 equals 0.5 and again,
due to Lemma 3.3, Eqn. (3.65), (xii), n times, that also (M1|M2) 
N →M2 
N
equals 0.5. Altogether, we therefore have that Eqn. (5.286) equals
0.5 · M1 
N ⇒c + 0.5 · M2 
N ⇒c
(5.287)
Eqn. (5.287) is the right-hand side of Eqn. (5.284) and therefore completes
the proof for the case M1 ̸= M2. In case M1 = M2 the proof is similar by
exploiting Eqn. (3.65), clause (xvii).


5.3 Semantic Correspondence
187
Lemma 5.53 (Performance of Choices) Given performing, closed terms
M1 and M2, i.e., α(M1) and α(M2), we have that α(M1|M2).
Proof. Given a constant c : t′ and closed terms 
N = N0, . . . , Nn such that
α(Ni) for all 0 ⩽i ⩽n and (M1|M2) 
N is a program of type t′. We start as
follows:
[[(M1|M2) 
N]]∅[c]
(5.288)
Due to semantic equation Eqn. (5.32), n times plus once, we have that
Eqn. (5.288) equals
[[M1|M2]]∅
[[N]]∅[c]
(5.289)
Due to semantic equation Eqn. (5.34) we have that Eqn. (5.289) equals
(0.5 ⊗[[M1]]∅⊕0.5 ⊗[[M2]]∅) 
[[N]]∅[c]
(5.290)
Due to the properties of the scalar operations as well as semantic equation
Eqn. (5.32), n times, we have that Eqn. (5.290) equals
0.5 · [[M1 
N]]∅[c] + 0.5 · [[M2 
N]]∅[c]
(5.291)
Now, due to Def. 5.28, clause (a), n times, the premises α(M1) and α(M2) and
the fact that α(Ni) for all Ni of 
N we have that also α(M1 
N) and α(M2 
N).
Due to α(M1 
N), we have that [[M1 
N]]∅[c] ⩽M1 
N ⇒c. Due to α(M2 
N), we
have that [[M2 
N]]∅[c] ⩽M2 
N ⇒c. Altogether, we have that Eqn. (5.291) is
less than or equal (⩽) to
0.5 · M1 
N ⇒c + 0.5 · M2 
N ⇒c
(5.292)
Next, due to the big-step approximation lemma for choices, i.e., Lemma 5.52,
we have that Eqn. (5.292) is less than or equal (⩽) to
(M1|M2) 
N ⇒c
(5.293)
Due to the fact that Eqn. (5.288) is less than or equal (⩽) to Eqn. (5.293) for
all constants c : t′ and the deﬁnition of performing terms Def. 5.28, clause (a),
we have that α((M1|M2) 
N). Therefore, and due to Lemma 5.31, we ﬁnally
have that α(M1|M2).

Complete Semantic Correspondence
Lower bound correspondence means that the denotational semantics approx-
imates the Markov chain semantics from below. It means that the given de-
notational semantics yields a lower bound for the intended denotational se-
mantics that we expect to equal the evaluation semantics. On the basis of the
results achieved so far, we now prove the lower bound correspondence and,
ﬁnally, the complete semantic correspondence between the denotational and
the operational semantics.

188
5 Denotational Semantics
Lemma 5.54 (Lower Bound Correspondence) The denotational seman-
tics approximates the evaluation semantics from below. For each program M
and constant c we have that

M ⇒c

⩾[[M]]∅

[c]

(5.294)
Proof: Now, we prove by structural induction that all terms are performing,
i.e., α(M) for all M ∈Λ. Proving that all terms are performing implies the
desired Lemma 5.54, because Lemma 5.54 is included as a special case in the
deﬁnition of performing terms Def. 5.28, i.e., as clause (a). We show the cases
of variables, constants and basic operators.
In Case of Variables:
Given a variable x. According to clause (c) of
Def. 5.28 we need to show that α(M) implies α(x[x := M]) for each closed
lambda term M of appropriate type. This follows immediately, because x[x :=
M] = M.
In Case of Constants: Constants are programs and therefore clause (a)
of Def. 5.28 applies. According to clause (a) we need to show for all c ∈C
and c′ ∈C that (c ⇒c′
⩽[[c]]∅

[c′]

. Actually, we can show immediately the
stricter property that (c ⇒c′
= [[c]]∅

[c′]

in case of constants. We show this
for number constants ni ∈Cnum and nj ∈Cnum only. We have
ni ⇒nj
(i)
=

1 , nj =ni
0 , else
(ii)
=

1 , j =i
0 , else
(iii)
=
[[ni]]ρ(j)
(iv)
= [[ni]]ρ[nj]
(5.295)
In Eqn. (5.295), (i) holds due to Lemma 5.30, (ii) holds due to the deﬁni-
tion of number constants Cnum in Sect. 3.1.1, (iii) holds due to the semantic
equation Eqn. (5.24) and (iv) holds due to the deﬁnition of data points in
Def. 5.25.
In Case of +1(M), −1(M) and 0?(M):
We show this for terms of
the form +1(M) only. The two other cases −1(M) and 0?(M) can be proven
analogously. Given a term +1(M), we can distinguish two cases, i.e., the case
in which M is closed and the case in which M is an open term with some
free variabIes x1, . . . , xn. If the term +1(M) is closed, we know that also
M is closed and we can immediately exploit the induction hypothesis α(M).
Due to α(M) and the fact that M is closed we can apply the performance
lemma for basic operators, i.e., Lemma 5.33, so that we have that α(+1(M)).
In case the term is open we need to consider all lists of closed, perform-
ing terms N1, . . . , Nn such that +1(M)[x1 := N1] . . . [xn := Nn] is a closed
term. However, in such a case, we know that also M[x1 := N1] . . . [xn := Nn]
is a closed term. Furthermore, due to α(N1), . . . , α(Nn) we also know that
α(M[x1 := N1] . . . [xn := Nn]). Altogether, we can again apply Lemma 5.33,
so that we have α(+1(M)) also in this case.
The other cases follow analogously. We always follow the pattern that we
have seen in the case of basic operators. We distinguish two cases, i.e., the case

5.4 Important Readings on Domains and Probabilism
189
in which the constituting terms are already closed and the case in which the
constituting terms are open. Actually, the case of closed constituting terms
can also be treated as a special case of the case of open constituting terms
with an empty list of free variables, so that the explicit treatment of the two
cases can be considered a bit artiﬁcial. However, in both cases we eventually
apply the corresponding helper lemma elaborated in the preceding text. In
case of conditional expressions we apply Lemma 5.35, in case of applications
we apply Lemma 5.36, in case of abstraction we apply Lemma 5.38, in case of
recursion we apply Lemma 5.51 and, ﬁnally, in case of probabilistic choices,
we apply Lemma 5.53.

Theorem 5.55 (Semantic Correspondence) For each program M and
constant c we have the following:
[[M]]∅[c] =

M ⇒c

(5.296)
Proof. The theorem follows immediately as a corollary from Lemma 5.27 and
Lemma 5.54.

5.4 Important Readings on Domains and Probabilism
In [242] Dana Scott clariﬁes the semantics of the stochastic lambda calculus.
He achieves this by using random variables to model randomized oracles and
adding them to his graph model [240] of the lambda calculus.
In his seminal work [232], Saheb-Djahromi deﬁnes an operational seman-
tics and denotational semantics for the probabilistic lambda calculus; compare
also with Sect. 3.4. The denotational semantics is provided based on the no-
tion of probabilistic domains [233]. In [233], a probabilistic domain is deﬁned
by the probabilistic distributions over a domain. The probabilistic distribu-
tions are partially ordered with respect to the open sets of the underlying
domain, i.e., approximation between two distributions is deﬁned pointwise for
all open sets. In [233] two alternative options are proposed as base domains
for the number type of the probabilistic lambda calculus. One option is the
probabilistic domain over the natural numbers (N0, ⩽, 0) with their natural
ordering and 0 as bottom element as cpo. The other option is the ﬂat domain
(N0, ⊑, ⊥). This option is also used for the denotational semantics in [232]. The
probabilistic domains over ﬂat domains in [232] and the constructions based
on pre-distributions used in this book are isomorphic. Probabilistic distribu-
tions over ﬂat domains are suﬃcient for the denotational semantics in [232].
This is so, because probabilistic choice is introduced at the level of ground
types only and call-by-name does not require probabilistic distributions at
higher types. Also, for the concrete call-by-value abstraction construct of the
language in [232] the distributions over ﬂat domains are suﬃcient, because

190
5 Denotational Semantics
the chosen call-by-value abstraction is a limited form of abstraction that is
available for variables of ground type only.
In [66], de Frutos Escrig introduces and investigates three kind of prob-
abilistic powerdomains on the basis of the category SFP (Sequences Finite
Partial) [221], which is drawn from limits of inﬁnite sequences of ﬁnite dcpos.
One of the probabilistic powerdomains is constructed as a probability dis-
tribution over a domain. The other generalizes Smyth’s notion of generating
trees [246] to probabilistic generating trees. The third one achieves a proba-
bilistic version of Scott’s domain-theoretic notion of information system [241].
In [67], de Frutos Escrig provides a model based on a reductionist notion of
control systems.
For closure properties of the category of retracts from SFP, i.e., the cat-
egory of ﬁnitely continuous partially ordered sets, and its exploitation in the
semantics of probabilistic computations see Graham [113].
In [168, 169] Dexter Kozen introduces two interpretations for probabilis-
tic programming languages, i.e., based on partial measurable functions on a
measurable space on the one hand, and continuous linear operators on a par-
tially ordered Banach space on the other hand. Also, natural embeddings of
standard semantic domains into these structures are shown.
In [143, 142] Jones and Plotkin construct a probabilistic powerdomain on
the basis of directed complete partial orders. The powerdomain construction
forms a monadic functor on the category of the involved domains. On the
basis of this, the work gives an axiomatic semantics for a probabilistic imper-
ative programming language and a denotational semantics to a call-by-value
version [142] of the probabilistic lambda calculus that is based on the compu-
tational lambda calculus [197] of Eugenio Moggi.
In [130] Heckmann deﬁnes a powerdomain construction on the basis of
information systems as deﬁned by Vickers [259]. He shows that this powerdo-
main construction is equivalent to the powerdomain construction deﬁned by
Jones and Plotkin in [143, 142].
In [146] Jung and Tix deal with the problem that the category of contin-
uous domains, which is the host of the continuous powerdomain construction
from [143, 142], is not a Cartesian closed category [173, 144]. Against this
background, the paper provides a review of Graham’s approach [113] to re-
strict the powerdomain construction to the retracts of biﬁnite domains [221];
see also [1]. Next, two solutions are approached based on ﬁnite trees on one
hand, and ﬁnite reversed trees on the other hand. Also, a promising solution
based on Lawson-compact domains, see [144, 105], is investigated. In [145]
Jung investigates the relationship of stably compact spaces [106] and Nach-
bin’s compact ordered spaces [206, 207] and their relevance to the construction
of probabilistic powerdomains.
In [258], Tix, Keimel and Plotkin elaborate a denotational semantics for
programming languages that support both non-deterministic and probabilis-
tic choice. The probabilistic powerdomain of [143, 142] is taken as a starting
point and blended with each of the three standard powerdomains used for

5.4 Important Readings on Domains and Probabilism
191
the interpretation of non-determinism, i.e., upper, lower and convex powerdo-
mains; see [221, 222, 246, 247]. The resulting probabilistic powerdomains are
made the subject of investigation of Hahn-Banach-style theorems [147]. It is
demonstrated that they work for programming languages that combine both
non-deterministic and probabilistic choice, i.e., they are used for the denota-
tional semantics of the concrete imperative programming language introduced
by Morgan and McIver in [184].
In [63], Danos and Ehrhard establish a model of linear logic [108] based
on a notion of probabilistic coherent spaces PCSs; compare also with [109].
Then, they use PCSs to deﬁne a denotational semantics for the probabilistic
typed lambda calculus that they deﬁne by extending PCF [223] by a random
generator primitive. Furthermore, in [96] Ehrhard, Pagani and Tasson use
PCSs also to give an adequate model to a probabilistic version of the pure,
i.e., untyped, lambda calculus. Again, in [98], they investigate the PCS-based
denotational semantics of the probabilistic typed lambda calculus and show
that it is fully abstract; see also [97] for a detailed version of [98].
In [20, 21] Barker deﬁnes a probabilistic version of PCF by adding a pro-
gramming primitive for random choice. The random choice allows for arbitrary
measures organized on Cantor trees. A monadic small-step semantics as well as
a monadic big-step semantics against a driving input bit stream is provided.
A full Haskell implementation of the proposed PCF extension is provided;
see [269]. The random choice monad turns out to be an endofunctor on the
Cartesian closed category of bc-domains [240]; compare also with the work of
Goubault-Larrecq and Varacca in [112] as well as the analysis in [194, 195] by
Michael Mislove.
In [196] Michael Mislove achieves a domain-theoretic foundation of ran-
dom variables. The work complements and transcends the important strand
of research on random variables and domains embodied in [194, 195]. In par-
ticular, the work achieves an adjustment of Skorohod’s Theorem [252] to sub-
probabilities as the crucial domain-theoretic objects.

References
1. Samy Abbes and Klaus Keimel. Projective Topology on Biﬁnite Domains
and Applications. Theoretical Computer Science, vol. 365, no. 3, 2006,
pp. 171–183.
2. Samson Abramsky. The Lazy λ-Calculus. In D. Turner, ed.: Research Topics
in Functional Programming, Addison-Wesley, Boston, 1990, pp. 65–117.
3. Samson Abramsky and Achim Jung. Domain Theory. In D.M. Gabbay,
T.S.E. Maibaum, eds.: Handbook of Logic in Computer Science, vol. 3,
Clarendon Press, Oxford, 1996.
4. Peter Aczel. An Introduction to Inductive Deﬁnitions. In Jon Barwise, ed.:
Handbook of Mathematical Logic – Studies in Logic and the Foundations
of Mathematics, vol. 90, Elsevier, Amsterdam, 1977, pp. 739–782.
5. Alfred V. Aho, Monica S. Lam, Ravi Sethi, and Jeﬀrey D. Ullman. Com-
pilers – Principles, Techniques, and Tools, 2nd ed. Addison-Wesley, Boston,
2006.
6. Charalambos D. Aliprantis, and Owen Burkinshaw. Principles of Real Anal-
ysis, 3rd Edition, Academic Press, Cambridge, 1998.
7. Dagmar Auer, Dirk Draheim, and Verena Geist. Extending BPMN with
Submit/Response-Style User Interaction Modeling. In: Proceedings of
BPMN Workshop at CEC’09 – the 11th IEEE Conference on Commerce
and Enterprise Computing, 2009, pp. 368–374.
8. Colin Atkinson and Dirk Draheim. Cloud-Aided Software Engineering -
Evolving Viable Software Systems through a Web of Views. In Zaigham
Mahmood, Saqib Saeed, eds.: Software Engineering Frameworks for the
Cloud Computing Paradigm. Springer, 2013, pp. 255–281.
9. Colin Atkinson, Philipp Bostan, and Dirk Draheim. Foundational MDA
Patterns for Service-Oriented Computing. In: The Journal Of Object Tech-
nology, vol. 14, no. 1, 2015, pp. 1–30.
10. Colin Atkinson, Dirk Draheim, and Verena Geist. Typed Business Process
Speciﬁcation. In: Proceedings of EDOC’2010 – the 14th IEEE International
Enterprise Computing Conference, IEEE Computer Society, 2010, pp. 69–
78
11. Adnan Aziz, Kumud Sanwal, Vigyan Singhal, and Robert K. Brayton. Ver-
ifying Continuous Time Markov Chains. In Rajeev Alur, Thomas Hen-
zinger, eds.: Proceedings of CAV’96 – the 8th International Conference on
© Springer-Verlag Berlin Heidelberg 2017
D. Draheim, Semantics of the Probabilistic Typed Lambda Calculus,  
DOI 10.1007/978-3-642-55198-7 
193

194
References
Computer-Aided Veriﬁcation, LNCS 1102, Springer, Berlin, 1996, pp. 269–
276.
12. Adnan Aziz, Kumud Sanwal, Vigyan Singhal, and Robert K. Brayton.
Model Checking Continuous Time Markov Chains. ACM Transactions on
Computational Logic, vol. 1, no. 1, July 2000, pp. 162–170.
13. Soheib Baarir, Marco Beccuti, Davide Cerotti, Massimiliano De Pierro,
Susanna Donatelli, and Giuliana Franceschinis. The GreatSPN Tool –
Recent Enhancements. ACM SIGMETRICS Performance Evaluation Re-
view, vol. 36, no. 4, March 2009, pp. 4–9.
14. Christel Baier, Boudewijn Haverkort, Holger Hermanns, and Joost-Pieter
Katoen. Model Checking Continuous-Time Markov Chains by Transient
Analysis. In E. Allen Emerson, Aravinda Prasad Sistla, eds.: Proceedings of
CAV 2000 – the 12th Annual Symposium on Computer-Aided Veriﬁcation,
LNCS 1855, Springer, 2000, pp. 358–372.
15. Christel Baier, Holger Hermanns, Joost-Pieter Katoen, and Boudewijn R.
Haverkort. Eﬃcient Computation of Time-Bounded Reachability Probabil-
ities in Uniform Continuous-Time Markov Decision Processes. Theoretical
Computer Science, vol. 345, no. 1, pp. 2–26, 2005.
16. Jørgen Bang-Jensen and Gregory Gutin. Digraphs – Theory, Algorithms
and Applications, Springer, Berlin, 2009.
17. Rodrigo Bañuelos. Lecture Notes on Measury Theory and Probability. Pur-
due University, June 2003.
18. Henk P. Barendregt. The Lambda Calculus – Its Syntax and Semantics.
North Holland, Amsterdam, 1984.
19. Henk P. Barendregt. Lambda Calculi with Types. In S. Abramsky, D.M.
Gabbay, T.S.E. Maibaum, eds.: Handbook of Logic in Computer Science,
vol. 2. Oxford University Press, Oxford, 1992.
20. Tyler C. Barker. A Monad for Randomized Algorithms. Ph.D. Thesis, Tu-
lane University, April 2016.
21. Tyler C. Barker. A Monad for Randomized Algorithms. In: Proceedings
of MFPS’2016 – the 32nd Conference on the Mathematical Foundations
of Programming Semantics, Electronic Notes in Theoretical Computer Sci-
ence, vol. 325, October 2016, pp. 47–62.
22. A.K. Basu. Measure Theory and Probability. Prentice-Hall of India, 2004.
23. Klaus J. Berkling and Elfriede Fehr. A Consistent Extension of the Lambda-
Calculus as a Base for Functional Programming Languages. In: Information
and Control, vol. 55, no. 1–3, 1982, pp. 89–101.
24. Klaus J. Berkling and Elfriede Fehr. A Modiﬁcation of the Lambda-Calculus
as a Base for Functional Programming Languages. In M. Nielsen, E.M.
Schmidt, eds.: Proceedings of ICALP’82 – the 9th International Colloquium
on Automata, Languages and Programming, LNCS 140, Springer, Berlin,
1982, pp. 35–47.
25. Ethan Bernstein and Umesh Vazirani. Quantum Complexity Theory. Soci-
ety for Industrial and Applied Mathematics (SIAM) Journal on Computing,
vol. 26, no. 5, October 1997, pp. 1411–1473.
26. Evert Willem Beth. Semantic Entailment and Formal Derivability. Med-
edelingen van de Koninklijke Nederlandse Akademie van Wetenschappen
Afdeling Letterkunde, vol. 18, no. 3, 1955, pp.309–342.
27. Evert Willem Beth. The Foundations of Mathematics, North Holland Pub-
lishing, Amsterdam, 1959.

References
195
28. B.R. Bhat. Modern Probability Theory. New Age International Publishers,
New Delhi, 2009.
29. Wayne D. Blizard. Multiset Theory. Notre Dame Journal of Formal Logic,
vol. 30, no. 1, 1989, pp. 36–66.
30. Eckard Bode, Marc Herbstritt, Holger Hermanns, Sven Johr, Thomas
Peikenkamp, Reza Pulungan, Ralf Wimmer, and Bernd Becker. Compo-
sitional Performability Evaluation for STATEMATE. In: Proceedings of
QEST’06 – the 3rd International Conference on the Quantitative Evalua-
tion of Systems, IEEE Computer Society, 2006, pp. 167–178.
31. Gunter Bolch, Stefan Greiner, Hermann de Meer, and Kishor S. Trivedi.
Queueing Networks and Markov Chains – Modeling and Performance Eval-
uation with Computer Science Applications, 2nd edition. Wiley, Chichester,
May 2006.
32. John Alan Bondy and U.S.R. Murty. Graph Theory with Applications.
North Holland, Amsterdam, 1976.
33. John Alan Bondy and U.S.R. Murty. Graph Theory. Springer, Berlin, 2008.
34. Behzad Bordbar, Dirk Draheim, Matthias Horn, Ina Schulz, and Gerald
Weber. Integrated Model-Based Software Development, Data Access and
Data Migration. In Lionel Briand, Clay Williams, eds.: Model Driven En-
gineering Languages and Systems, LNCS 3713, Springer, Berlin, 2005, pp.
382–396.
35. Johannes Borgström, Ugo Dal Lago, Andrew D. Gordon, and Marcin Szym-
czak. A Lambda-Calculus Foundation for Universal Probabilistic Program-
ming. In: Proceedings of ICFP’2016 – the 21st ACM SIGPLAN Interna-
tional Conference on Functional Programming, 2016, pp. 33–46.
36. Johannes Borgström, Ugo Dal Lago, Andrew D. Gordon, and Marcin Szym-
czak. A Lambda-Calculus Foundation for Universal Probabilistic Program-
ming – v.4. In: The Computing Research Repository, arXiv:1512.08990,
Cornell University Library, May 2016, pp. 1–56.
37. Leo Breiman. Probability. Addison-Wesley, Boston, 1968, out of print, ap-
peared also as: Probability – Classics in Applied Mathematics, vol. 7, So-
ciety for Industrial and Applied Mathematics, Philadelphia, 1992.
38. Franck van Breugel, Michael Mislove, Joël Ouaknine, and James Worrell.
Domain Theory, Testing and Simulation for Labelled Markov Processes.
Theoretical Computer Science, vol. 333, no. 1–2, March 2005, pp. 171–197.
39. Bruno Buchberger. Mathematics of 21st Century – A Personal View. In
L. Kovacs, T. Kutsia, eds.: Proceedings of SCSS 2013 – the 4th Symposium
on Symbolic Computation in Software Science, EPiC Series, vol. 15, 2013,
pp. 1–1.
40. Bruno Buchberger et.al. Theorema – Towards Computer-Aided Mathemat-
ical Theory Exploration. In: Journal of Applied Logic, vol. 4, no. 14, 2005,
pp. 470-504.
41. Juanito Camilleri and Tom Melham. Reasoning with Inductively Deﬁned
Relations in the HOL Theorem Prover. Technical Report No. 265, Univer-
sity of Cambridge Computer Laboratory, August 1992.
42. Luca Cardelli. Type Systems. In Allan B. Tucker, ed.: The Computer Sci-
ence and Engineering Handbook. CRC Press, Boca Raton, 1997.
43. James
B.
Carrell.
Fundamentals
of
Linear
Algebra,
July
2005.
https://www.math.ubc.ca/~carrell/NB.pdf

196
References
44. Christos G. Cassandras, Michael I. Clune, and Pieter J. Mosterman. Hy-
brid System Simulation with SimEvents. In: Proceedings of the 2nd IFAC
Conference on Analysis and Design of Hybrid Systems, IFAC Proceedings
Volumes, vol. 39, no. 5, Elsevier, Amsterdam, 2006, pp. 267–269.
45. Kai Lai Chung. Elementary Probability Theory with Stochastic Processes.
Springer, Berlin, 1974.
46. Kai Lai Chung. A Course in Probability Theory, revised 2nd edition. Aca-
demic Press, Cambridge, 2001.
47. Alonzo Church. A Set of Postulates for the Foundation of Logic. Annals of
Mathematics, Series 2, no. 33, 1932, pp. 346–366.
48. Alonzo Church. An Unsolvable Problem of Elementary Number Theory.
American Journal of Mathematics, vol. 58, no. 2, April 1936, pp. 345–363.
49. Alonzo Church, John B. Rosser. Some Properties of Conversion. Transac-
tions of the American Mathematical Society, vol. 39, no. 3, 1936, pp. 472–
483.
50. Allan Clark, Stephen Gilmore, Jane Hillston, and Mirco Tribastone.
Stochastic Process Algebras. In Marco Bernardo, Jane Hillstone, eds.: For-
mal Methods for Performance Evaluation, LNCS 4486, Springer, 2007, pp.
132–179.
51. Thierry Coquand and Peter Dybjer. Inductive Deﬁnitions and Type The-
ory – an Introduction. In P.S. Thiagarajan, ed.: Foundation of Software
Technology and Theoretical Computer Science, Lecture Notes in Computer
Science 880, Springer, Berlin, 1994, pp. 60–76.
52. Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clif-
ford Stein. Introduction to Algorithms, 3rd edition. MIT Press, Cambridge,
2009.
53. Patrick Cousot and Michael Monerau. Probabilistic Abstract Interpreta-
tion. In Helmut Seidl, ed.: Proceedings of ESOP’12 – the 21st European
Symposium on Programming, LNCS 7211, Springer, 2012, pp. 169–193.
54. Raphaëlle Crubillé and Ugo Dal Lago. On Probabilistic Applicative Bisim-
ulation and Call-by-Value λ-Calculi. In Zhang Shao, ed.: Proceedings of
ESOP – The 23rd European Symposium on Programming, LNCS 8410,
Springer, Berlin, 2014, pp. 209–228.
55. Raphaëlle Crubillé and Ugo Dal Lago. On Probabilistic Applicative Bisim-
ulation and Call-by-Value λ-Calculi. In: The Computing Research Reposi-
tory, arXiv:1401.3766v2, Cornell University Library, January 2104, pp. 1–
30.
56. Ugo Dal Lago and Paolo Parisen Toldin. A Higher-Order Characterization
of Probabilistic Polynomial Time. In R. Peña, M. van Eekelen, O. Shkar-
avska, eds.: Proceedings of FOPARA 2011 – the 2nd International Workshop
on Foundational and Practical Aspects of Resource Analysis. LNCS 7177,
Springer, Berlin, 2012, pp. 1–18.
57. Ugo Dal Lago and Paolo Parisen Toldin. A Higher-Order Characterization
of Probabilistic Polynomial Time. Information and Computation, vol. 241,
April 2015, pp. 114–141.
58. Ugo Dal Lago and Margherita Zorzi. Probabilistic Operational Semantics
for the Lambda Calculus. RAIRO – Theoretical Informatics and Applica-
tions, vol. 46, no. 3, 2012, pp. 413–450.

References
197
59. Ugo Dal Lago and Sara Zuppiroli. Probabilistic Recursion Theory and Im-
plicit Computational Complexity. In G. Ciobanu, D. Méry, eds.: Proceed-
ings of ICTAC 2014 – 11th International Colloquium on Theoretical Aspects
of Computing, LNCS 8687, Springer, Berlin, September 2014, pp. 97–114
60. Ugo Dal Lago and Sara Zuppiroli. Probabilistic Recursion Theory and Im-
plicit Computational Complexity. In: The Computing Research Repository,
arXiv:1406.3378, Cornell University Library, June 2104, pp. 1–27.
61. Ugo Dal Lago, Davide Sangiorgi, and Michele Alberti. On Coinductive
Equivalences for Higher-Order Probabilistic Functional Programs. ACM
SIGPLAN Notices – Proceedings of POPL’14 – the 41st ACM SIGPLAN-
SIGACT Symposium on Principles of Programming Languages, vol. 49,
no. 1, January 2014, pp. 297–308.
62. Ugo Dal Lago, Davide Sangiorgi, and Michele Alberti. On Coinductive
Equivalences for Higher-Order Probabilistic Functional Programs. In: The
Computing Research Repository, arXiv:1311.1722, Cornell University Li-
brary, November 2013, pp. 1–47.
63. Vincent Danos and Thomas Ehrhard. Probabilistic Coherence Spaces as a
Model of Higher-Order Probabilistic Computation. Information and Com-
putation, vol. 209, no. 6, June 2011, pp. 966-991.
64. Davide D’Aprile, Susanna Donatelli, and Jeremy Sproston. CSL Model
Checking for the GreatSPN Tool. In C. Aykanat, T. Dayar, I. Korpeoglu,
eds.: Proceedings of ISCIS 2004 – the 19th International Symposium Com-
puter and Information Sciences, LNCS 3280, Springer, 2004, pp. 543–552.
65. Nicolaas G. de Bruijn. A Survey of the Automath Project. In J.R. Hindley,
J.P. Seldin, eds.: To H.B. Curry – Essays on Combinatory Logic, Lambda-
Calculus and Formalism. Academic Press, Cambridge, 1980, pp. 580–606.
66. David de Frutos Escrig. Some Probabilistic Powerdomains in the Cate-
gory SFP. In Burkhard Monien, Guy Vidal-Nagnet, eds.: Proceedings of
STACS’86 – the 3rd Annual Symposium on Theoretical Aspects of Com-
puter Science. LNCS 210, Springer, Berlin, 1986, pp. 49–59.
67. David de Frutos Escrig. Probabilistic Ianov’s Schemes. Theoretical Com-
puter Science, vol. 53, no. 1, 1987, pp. 67–97.
68. Karel De Leeuw, Edward F. Moore, Claude E. Shannon, and Norman
Shapiro. Computability by Probabilistic Machines. In: Automata Studies,
vol. 34, 1955, pp. 183–212.
69. W.P. DeRoever. Call-by-Value versus Call-by-Name – a Proof-Theoretic
Comparison. In A. Blikle, ed.: Mathematical Foundations of Computer
Science, Lecture Notes in Computer Science 28, Springer, Berlin, 1975,
pp. 451–463.
70. Reinhard Diestel. Graph Theory. Springer, Berlin, 2005.
71. Alessandra Di Pierro, Chris Hankin, and Herbert Wiklicky. Probabilistic
λ-Calculus and Quantitative Program Analysis. Journal of Logical Compu-
tation, vol. 15, no. 2, 2005, pp. 159–179.
72. Alessandra Di Pierro, Chris Hankin, and Herbert Wiklicky. Probabilistic
Semantics and Program Analysis. In A. Aldini, M. Bernardo, A. Di Pierro,
H. Wiklicky, eds.: Formal Methods for Quantitative Aspects of Program-
ming Languages, Lecture Notes in Computer Science 6154, Springer, Berlin,
2010, pp. 1–42.

198
References
73. Dirk Draheim. SEKE 2007 Invited Talk: Towards Seamless Workﬂow and
Dialogue Speciﬁcation. In: Proceedings of SEKE 2007 – The 19th Inter-
national Conference on Software Engineering and Knowledge Engineering,
2007, pp. 402–403.
74. Dirk Draheim. Business Process Technology - A Uniﬁed View on Busi-
ness Processes, Workﬂows and Enterprise Applications. Springer, Berlin,
September 2010.
75. Dirk Draheim. The Service-Oriented Metaphor Deciphered. Journal of
Computing Science and Engineering, vol. 4, no. 4, 2010, pp. 253–275
76. Dirk Draheim. Smart Business Process Management. In: 2011 BPM and
Workﬂow Handbook, Digital Edition. Future Strategies, Workﬂow Man-
agement Coalition, 2012, pp. 207–223.
77. Dirk Draheim. MDHPCL 2012 Invited Talk. CASE 2.0 - On Key Success
Factors for Cloud-Aided Software Engineering. In: Proceedings of MDH-
PCL – the 1st International Workshop on Model-Driven Engineering for
High Performance and Cloud Computing, ACM Press, New York, 2012,
pp. 1–6.
78. Dirk Draheim. Sustainable Constraint Writing and Symbolic Viewpoints of
Modeling Languages. Invited Talk. In H. Decker et al., eds.: Proceedings
of DEXA’14 – the 25th International Conference on Database and Expert
Systems Applications, LNCS 8644, Springer, Berlin, 2014, pp. 12-19.
79. Dirk Draheim. Reﬂective Constraint Writing. In A. Hameurlain et al., eds.:
Transactions on Large-Scale Data- and Knowledge-Centered Systems, vol.
24, LNCS 9510, Springer, Berlin, 2016, pp. 1–60.
80. Dirk Draheim. FDSE Invited Talk: The Present and Future of Large-Scale
Systems Modeling and Engineering. In: Proceedings of FDSE 2106 – the 3rd
International Conference on Future Data and Security Engineering. LNCS
10018, Springer, Berlin, 2016.
81. Dirk Draheim and Gerald Weber. Strongly Typed Server Pages. In Alon
Halevy, Avigdor Gal, eds.: Proceedings of NGITS 2002 – Next Generation
Information Technologies and Systems, LNCS 2382, Springer, Berlin, 2002,
pp. 29–44.
82. Dirk Draheim and Gerald Weber. Storyboarding Form-Based Interfaces.
In: Proceedings of INTERACT 2003 – the 9th IFIP TC13 International
Conference on Human-Computer Interaction. IOS Press, Amsterdam, 2003,
pp. 343–350.
83. Dirk Draheim and Gerald Weber. Form-Oriented Analysis – A New
Methodology to Model Form-Based Applications. Springer, Berlin, October
2004.
84. Dirk Draheim and Gerald Weber (Editors). Post-Proceedings of TEAA
2006 – the VLDB Workshop on Trends in Enterprise Application Architec-
ture, LNCS 3888, Springer, Berlin, March 2006.
85. Dirk Draheim and Gerald Weber (Editors). Post-Proceedings of TEAA
2007 – the 2nd International Conference on Trends in Enterprise Application
Architecture, LNCS 4473, Springer, Berlin, June 2007.
86. Dirk Draheim and Christine Nathschläger. A Context-Oriented Synchro-
nization Approach. In: Electronic Proceedings of PersDB 2008 – the 2nd
International Workshop in Personalized Access, Proﬁle Management, and
Context Awareness: Databases (in Conjunction with the 34th VLDB Con-
ference), 2008, pp. 20–27.

References
199
87. Dirk Draheim, Elfriede Fehr, and Gerald Weber. JSPick – a Server Pages
Design Recovery Tool. In: Proceedings of CSMR 2003 – the 7th European
Conference on Software Maintenance and Reengineering. IEEE Press, Los
Alamitos, 2003.
88. Dirk Draheim, Melanie Himsl, Daniel Jabornig, Josef Küng, Werner Lei-
thner, Peter Regner, and Thomas Wiesinger. Concept and Pragmatics of
an Intuitive Visualization-Oriented Metamodeling Tool. Journal of Visual
Languages and Computing, vol. 21, no. 4, 2010, pp. 157–170.
89. Dirk Draheim, Matthias Horn, and Ina Schulz. The Schema Evolution and
Data Migration Framework of the Environmental Mass Database IMIS.
In: Proceedings of SSDBM 2004 – the 16th International Conference on
Scientiﬁc and Statistical Database Management. IEEE Computer Society,
Los Alamitos, 2004, pp. 341–344
90. Dirk Draheim, Christof Lutteroth, and Gerald Weber. A Type System for
Reﬂective Program Generators. In Robert Glück, Michael Lawry, eds.: Pro-
ceedings of GPCE 2005 – Generative Programming and Component Engi-
neering, LNCS 3676, Springer, 2005.
91. Dirk Draheim, Christof Lutteroth, and Gerald Weber. Generative Program-
ming for C#. ACM SIGPLAN Notices, vol. 40, no. 8., August 2005, pp. 29–
33.
92. Dirk Draheim, Christof Lutteroth, and Gerald Weber. Integrating Code
Generators into the C# Language. In: Proceedings of ICITA 2005 – the
3rd International Conference on Information Technology and Applications.
IEEE Computer Society, Los Alamitos, 2005, pp. 107–110.
93. R.M. Dudley. Real Analysis and Probability. Cambridge University Press,
Cambridge, 2004.
94. Marie Duﬂot, Laurent Fribourg, and Claudine Picaronny. Randomized
Finite-State Distributed Algorithms as Markov Chains. In Jennifer Welch,
ed.: Proceedings of DISC’01– the 15th International Conference on Dis-
tributed Computing, LNCS 2180, Springer, Berlin, 2008, pp. 240–254.
95. Rick Durrett. Probability – Theory and Examples. Cambridge University
Press, Cambridge, 2010.
96. Thomas Ehrhard, Michele Pagani, and Christine Tasson. The Computa-
tional Meaning of Probabilistic Coherent Spaces. In: Proceedings of LICS
2011 – the 26th Annual IEEE Symposium on Logic in Computer Science,
IEEE Computer Society, Los Alamitos, 2011, pp. 87–96.
97. Thomas Ehrhard, Michele Pagani, and Christine Tasson. Full Abstrac-
tion for Probabilistic PCF. In: The Computing Research Repository,
arXiv:1511.01272, Cornell University Library, November 2015.
98. Thomas Ehrhard, Christine Tasson, and Michele Pagani. Probabilistic Co-
herence Spaces are Fully Abstract for Probabilistic PCF. In: Proceedings of
POPL’14 – the 41st Annual ACM SIGPLAN-SIGACT Symposium on Prin-
ciples of Programming Languages, ACM Press, New York, January 2014,
pp. 309–320.
99. Hartmut Ehrig and Bernd Mahr. Fundamentals of Algebraic Speciﬁcations
1 – Equations and Initial Semantics. Springer, Berlin, 1985.
100. European Commission. Unleashing the Potential of the Cloud in Europe.
Communication from the Commission to the European Parliament, the
Council, the European Economic and Social Committee and the Committee

200
References
of the Regions, Com(2012) 529 ﬁnal. European Commission, Brussels, 27
Sept 2012.
101. Agner K. Erlang. The Theory of Probabilities and Telephone Conversations.
Nyt Tidsskrift for Matematik B, vol 20, 1909.
102. Elfriede Fehr. Expressive Power of Typed and Type-Free Programming
Languages. In: Theoretical Computer Science, vol. 33, nos. 2–3, 1984,
pp. 195–238.
103. Elfriede Fehr. Semantik von Programmiersprachen. Springer, Berlin, 1989.
104. Erich Gamma et al. Design Patterns – Elements of Reusable Object-
Oriented Software. Addison-Wesley, Boston, 1995.
105. Gerhard Gierz, Karl Heinrich Hofmann, Klaus Keimel, Jimmie D. Law-
son, Michael Mislove, and Dana S. Scott. A Compendium of Continuous
Lattices. Springer, Berlin, 1980.
106. Gerhard Gierz, Karl Heinrich Hofmann, Klaus Keimel, Jimmie D. Lawson,
Michael Mislove, and Dana S. Scott. Continuous Lattices and Domains.
Encyclopedia of Mathematics and its Applications, vol.
93. Cambridge
University Press, Cambridge, 2003.
107. Stephen Gilmore and Jane Hillston. The PEPA Workbench – a Tool to
Support a Process Algebra-based Approach to Performance Modelling. In
Günther Haring, Gabriele Kotsis, eds.: In Proceedings of the 7th Interna-
tional Conference on Computer Performance Evaluation Modelling Tech-
niques and Tools, LNCS 794, Springer, Berlin, 1994, pp. 353–368.
108. Jean-Yves Girard. Linear Logic. Theoretical Computer Science, vol. 50,
no. 1, 1987 pp. 1–101.
109. Jean-Yves Girard. Between Logic and Quantic – a Tract. In T. Ehrhard,
J.-Y. Girard, P. Ruet, P. Scott, eds.: Linear Logic in Computer Science,
London Mathematical Society Lecture Note Series, vol. 316, Cambridge
University Press, Cambridge, 2004, pp. 346–381.
110. Noah Goodman, Vikash Mansinghka, Daniel M. Roy, Keith Bonawitz, and
Joshua B. Tenenbaum. Church – a Language for Generative Models. In
D.A. McAllester, P. Myllymäki, eds.: Proceedings of UAI 2008 – the 24th
Conference in Uncertainty in Artiﬁcial Intelligence, AUAI Press, 2008,
pp. 220–229.
111. Michael J. Gordon, Arthur J.R.G. Milner, and Christopher P. Wadsworth.
Edinburgh LCF – A Mechanized Logic of Computation. Lecture Notes in
Computer Science 78, Springer, Berlin, 1979.
112. Jean Goubault-Larrecq and Daniele Varacca. Continuous Random Vari-
ables. In: Proceedings of LICS’11 – the 26th Annual IEEE Symposium on
Logic in Computer Science, IEEE Computer Society Press, Los Alamitos,
June 2011, pp. 97–106.
113. Steven K. Graham. Closure Properties of a Probabilistic Domain Construc-
tion. In M. Main, A. Melton, M. Mislove, D. Schmidt, eds.: Proceedings of
MFPS’87 – the 3rd Workshop on Mathematical Foundations of Program-
ming Language Semantics, LNCS 298, Springer, Berlin, 1988, pp. 213–233
114. Michael A. Gray. Discrete Event Simulation – A Review of SimEvents.
Computing Science Engineering, vol. 9, no. 6, 2007, pp. 62–66.
115. Donald Gross, John F. Shortle, James M. Thompson, and Carl M. Harris.
Fundamentals of Queueing Theory. John Wiley & Sons, New York, 2008. s

References
201
116. Carl A. Gunter and Dana S. Scott. Semantic Domains. In Jan van Leeuwen,
ed.: Handbook of Theoretical Computer Science, vol. B – Formal Models
and Sematics. MIT Press, Cambridge, 1990, pp. 634–674.
117. Carl A. Gunter, Peter D. Mosses, and Dana S. Scott. Semantic Domains and
Denotational Semantics. Lecture Notes of the International Summer School
on Logic, Algebra and Computation. Marktoberdorf, June/August 1989.
Appeared also in Jan van Leeuwen, ed.: Handbook of Theoretical Computer
Science, vol. B – Formal Models and Sematics. MIT Press, Cambridge, 1990,
pp. 575–631, 634–674.
118. Carl A. Gunter. Semantics of Programming Languages – Structures and
Techniques. The MIT Press, Cambridge, 1992.
119. Peter J. Haas. Stochastic Petri Nets – Modelling, Stability, Simulation.
Springer, Berlin, 2002.
120. B. Hahn and C. Ballinger. Tpump in Continuous Environment – Assembling
the Teradata Active Data Warehouse Series. Active Data Warehouse Center
of Expertise, April 2001.
121. Hans Hansson and Bengt Jonsson. A Logic for Reasoning About Time and
Reliability. Formal Aspects of Computing, vol. 6, no. 5, September 1994,
pp. 512–535.
122. David Harel. Statecharts – a Visual Formalism for Complex Systems. Sci-
ence of Computer Programming, vol. 8, no. 3, 1987, pp.231–274.
123. David Harel and Amon Naamad. The Statemate Semantics of Statecharts.
ACM Transactions on Software Engineering and Methodology, vol. 5, no.
4, 1996, pp. 293–333.
124. John Harrison. Inductive Deﬁnitions – Automation and Application. In
Phillip J. Windley, Thomas Schubert and Jim Alves-Foss, eds.: Proceed-
ings of the 1995 International Workshop on Higher Order Logic Theorem
Proving and its Applications, LNCS 971, Springer, 1995, pp. 200–213.
125. M.J. Harry. The Vision of Six Sigma, 8 volumes. Tri Star Publishing, 1998.
126. M.J. Harry. Six Sigma: A Breakthrough Strategy for Proﬁtability. In: Qual-
ity Progress, vol. 31, no. 5, May 1998, pp. 60–64.
127. Sergiu Hart, Micha Sharir and Amir Pnueli. Termination of Probabilis-
tic Concurrent Programs. In: Proceedings of POPL’82 – the 9th ACM
SIGPLAN-SIGACT Symposium on Principles of Programming Languages,
ACM Press, New York, 1982, pp. 1–6.
128. Sergiu Hart, Micha Sharir and Amir Pnueli. Termination of Probabilistic
Concurrent Programs. ACM Transactions on Programming Languages and
Systems, vol. 5, no. 3, 1983, pp. 356–380.
129. Felix Hausdorﬀ. Grundzüge der Mengenlehre, Veit & Comp, Berlin, 1927.
130. Reinhold Heckmann. Probabilistic Power Domains, Information Systems,
and Locales. In S. Brookes, M. Main, A. Melton, M. Mislove, D. Schmidt,
eds.: Proceedings of MFPS’93 – the 9th International Conference on Math-
ematical Foundations of Programming Semantics, LNCS 802, Springer,
Berlin, 1994, pp. 410–437
131. Holger
Hermanns, Joost-Pieter
Katoen, Joachim
Meyer-Kayser, and
Markus Siegle. A Markov Chain Model Checker. In Susanne Graf, Michael
Schwartzbach, eds.: Proceedings of TACAS 2000 – the 6th International
Conference on Tools and Algorithms for the Construction and Analysis of
Systems, LNCS 1785, Springer, Berlin, 2000, pp. 347–362.

202
References
132. Carl Hewitt and Henry Baker. Actors and Continuous Functionals. Tech-
nical Report MIT/LCS/TR-194. Laboratory of Computer Science, Mas-
sachusetts Institute of Technology, 1977.
133. Carl Hewitt, Peter Bishop, and Richard Steiger. A Universal Modular AC-
TOR Formalism for Artiﬁcial Intelligence. In: Proceedings of IJCAI’73 –
the 3rd International Joint Conference on Artiﬁcial intelligence, Morgan
Kaufmann, San Francisco, 1973, pp. 235–245.
134. Jane Hillston. A Compositional Approach to Performance Modelling. Cam-
bridge University Press, Cambridge, 1996.
135. Melanie Himsl, Daniel Jabornig, Werner Leithner, Dirk Draheim, Peter
Regner, Thomas Wiesinger, and Josef Küng. An Iterative Process for Adap-
tive Meta- and Instance Modeling. In Roland Wagner, Norman Revell, Gün-
ter Pernul, eds.: Database and Expert Systems Applications. LNCS 4653,
Springer, Berlin, 2007, pp. 519–528.
136. C.A.R. Hoare. An Axiomatic Basis for Computer Programming. Commu-
nications of the ACM, vol. 12, no. 10, 1969, pp. 576–580.
137. J.E. Hopcroft, R. Motwani, and J.D. Ullman. Introduction to Automata
Theory, Languages, and Computation. Addison-Wesley, Boston, 2001.
138. P. Hudak and P. Wadler (Editors). Report on the Programming Language
Haskell Version 1.1. Computer Science Departments, Glasgow University
and Yale University, August 1991.
139. Joe Hurd. A Formal Approach to Probabilistic Termination. In: V.A. Car-
reño, C. Muñoz, S. Tahar, eds.: Proceedings of TPHOLs’2002 – the 15th In-
ternational Conference on Theorem Proving in Higher Order Logics, LNCS
2410, Springer, Berlin, 2002, pp. 230–245.
140. David N. Jansen, Joost-Pieter Katoen, Marcel Oldenkamp, Mariëlle
Stoelinga, and Ivan Zapreev. How Fast and Fat Is Your Probabilistic Model
Checker – an Experimental Performance Comparison. In Karin Yorav,
ed.: Proceedings of HVC’2007 – the 3rd International Haifa Veriﬁcation
Conference (Hardware and Software – Veriﬁcation and Testing Volume),
LNCS 4899, Springer, Berlin, 2008, pp. 69–85.
141. Edwin T. Jaynes. Probability Theory. Cambridge University Press, Cam-
bridge, 2003.
142. Claire Jones. Probabilistic Non-Determinism. Ph.D. Thesis, University of
Edinburgh, August 1989.
143. Claire Jones and Gordon D. Plotkin. A Probabilistic Powerdomain of Evalu-
ations. In: Proceedings of the 4th Annual Symposium on Logic in Computer
Science, IEEE Computer Society, Los Alamitos, 1989, pp. 186–195.
144. Achim Jung. Cartesian Closed Categories of Domains, CWI Tracts, vol. 66,
Centrum voor Wiskunde en Informatica, 1989.
145. Achim Jung. Stably Compact Spaces and the Probabilistic Powerspace Con-
struction. Electronic Notes in Theoretical Computer Science, vol. 73, 2004,
pp. 1–2.
146. Achim Jung and Regina Tix. The Troublesome Probabilistic Powerdomain.
Electronic Notes in Theoretical Computer Science, vol. 13, 1998, pp. 70–91.
147. Leonid V. Kantorovič, Gleb P. Akilov. Functional Analysis. Pergamon, Ox-
ford, 1982.
148. Richard M. Karp. An Introduction to Randomized Algorithms. Journal of
Discrete Applied Mathematics – Special Volume: Combinatorics and The-
oretical Computer Science, vol. 34, nos. 1–3, Nov. 1991, pp. 165–201.

References
203
149. Joost-Pieter Katoen, Maneesh Khattri, and Ivan S. Zapreev. A Markov
Reward Model Checker. In: Proceedings of QEST’05 – the 2nd International
Conference on the Quantitative Evaluation of Systems, IEEE Computer
Society, Los Alamitos, 2005, pp. 243–244.
150. Klaus Keimel, A. Rosenbusch, and Thomas Streicher. Relating Direct and
Predicate Transformer Partial Correctness Semantics for an Imperative
Probabilistic-Nondeterministic Language. Theoretical Computer Science,
vol. 412, no. 25, 2011, pp. 2701-2713.
151. Stephen Cole Kleene. General Recursive Functions of Natural Numbers.
Mathematische Annalen, vol. 112, no. 1, 1936, pp. 727–742.
152. Stephen Cole Kleene. On Notation for Ordinal Numbers. Journal of Sym-
bolic Logic, vol. 3, no. 4, 1938, pp. 150–155
153. Stephen Cole Kleene. Recursive Functionals and Quantiﬁers of Finite
Types (i). Transactions of the American Mathematical Society, vol. 91,
1959, pp. 1–52.
154. Stephen Cole Kleene. Recursive Functionals and Quantiﬁers of Finite
Types (ii). Transactions of the American Mathematical Society, vol. 108,
1959, pp. 106–142.
155. Stephen Cole Kleene. Recursive Functionals and Quantiﬁers of Finite Types
Revisited (i). In J.E. Fenstad, R.O. Gandy, E. Sacks, eds.: Generalized
Recursion Theory (ii). North Holland, Amsterdam, 1978, pp. 185–222.
156. Stephen Cole Kleene. Recursive Functionals and Quantiﬁers of Finite Types
Revisited (ii). In J. Barwise, H.J. Keisler, K. Kunen, eds.: The Kleene
Symposium. North Holland, Amsterdam, 1980, pp. 1–29.
157. Stephen Cole Kleene. Recursive Functionals and Quantiﬁers of Finite Types
Revisited (iii). In G. Metakides, ed.: The Patras Logic Symposium. North
Holland, Amsterdam, 1982, pp. 1–40.
158. Stephen Cole Kleene. Unimonotone Functions of Finite Types – Recursive
Functionals and Quantiﬁers of Finite Types Revisited (iv). In A. Nerode,
R.A. Shore, eds.: Recursion Theory, AMS Proceedings of Symposia in Pure
Mathematics, 1985, vol. 42, pp. 119–138.
159. Stephen Cole Kleene. Recursive Functionals and Quantiﬁers of Finite Types
Revisited (v). In G. Metakides, ed.: The Patras Logic Symposium. Transac-
tions of the American Mathematical Society, vol. 325, no. 2, 1991, pp. 593–
630.
160. Bronisław Knaster. Un théorème sur les fonctions d’ensembles. In: An-
nales de la Société Polonaise Mathématiques, tome (vi) – Comptes rendu
des séances de la Société Polonaise Mathématiques Section de Varsovie.
Roczniki Polskiego Towarzystwa Matematycznego, 1927, pp. 133–134.
161. Daphne Koller, David McAllester, and Avi Pfeﬀer. Eﬀective Bayesian In-
ference for Stochastic Programs. In: Proceedings of AAAI’97 – the 14th
National Conference on Artiﬁcial Intelligence, MIT Press, Cambridge, 1997.
162. Andrey
Kolmogorov.
Grundbegriﬀe
der
Wahrscheinlichkeitsrechnung.
Springer, Berlin, 1933.
163. Andrey Kolmogorov. Foundations of the Theory of Probability. Chelsea,
New York, 1956.
164. Andrey Kolmogorov. On Logical Foundations of Probability Theory. In
Kiyosi Itô and Jurii V. Prokhorov, eds.: Probability Theory and Math-
ematical Statistics. Lecture Notes in Mathematics 1021, Springer, 1982,
pp. 1–5.

204
References
165. Denes König. Sur les correspondances multivoques des ensembles. Funda-
menta Mathematicae, vol. 8, 1926, pp. 114–134.
166. Denes König. Über eine Schlussweise aus dem Endlichen ins Unendliche.
Acta Scientiarum Mathematicarum (Acta Szeged), vol. 3, nos. 2–3, 1927,
pp. 121–130.
167. Felix Kossak, Christa Illibauer, Verean Geist, Christine Natschläger,
Thomas
Ziebermayr,
Bernhard
Freudenthaler,
Theodorich
Kopetzky,
Klaus-Dieter Schewe. Hagenberg Business Process Modelling Method.
Springer, Berlin, 2016.
168. Dexter Kozen. Semantics of Probabilistic Programs. In: Proceedings of
FOCS’79 – the 20th Annual Symposium on Foundations of Computer Sci-
ence, IEEE Computer Society, Los Alamitos, 1979, pp. 101–114.
169. Dexter Kozen. Semantics of Probabilistic Programs. Journal of Computer
and System Sciences, vol. 22, no. 3, 1981, pp. 328–350.
170. Dexter Kozen and Alexandra Silver. Practical Coinduction. In: Mathemat-
ical Structures in Computer Science, vol. 1, Cambridge University Press,
February 2016.
171. Kenneth Kunen. Set Theory – An Introduction to Independence Proofs.
North Holland, Amsterdam, 1980.
172. Marta Z. Kwiatkowska, Gethin Norman and David Parker. Prism 2.0 – A
Tool for Probabilistic Model Checking. In QEST’2004 – Proceedings of the
1st International Conference on the Quantitative Evaluation of Systems,
IEEE Computer Society, Los Alamitos, 2004, pp. 322–323.
173. Joachim Lambek. From Lambda Calculus to Cartesian Closed Categories.
In J. P. Seldin and J. Hindley, eds.: To H.B. Curry – Essays on Combinatory
Logic, Lambda Calculus and Formalism, Academic Press, Cambridge, 1980,
pp. 376–402.
174. Kim G. Larsen and Arne Skou. Bisimulation through Probabilistic Testing.
Information and Computation, vol. 94, no. 1, September 1991.
175. Axel Legay, Benoît Delahaye, and Saddek Bensalem. Statistical Model
Checking – an Overview. In Howard Barringer et al., eds.: Proceedings
of RV 2010 – the 1st International Conference on Runtime Veriﬁcation,
LNCS 6418, Springer, Berlin, 2010, pp. 122–135.
176. Daniel J. Lehmann, Amir Pnueli, and Jonathan Stavi. Impartiality, Justice
and Fairness – the Ethics of Concurrent Termination. In S. Even, O. Kariv,
eds.: Proceedings of ICALP’81 – the 8th International Colloquium on Au-
tomata, Languages and Programming, LNCS 115, Springer, Berlin, 1981,
pp. 264–277.
177. Olivier Lévêque. Lecture Notes on Markov Chains. National University of
Ireland, 2011.
178. Christof Lutteroth, Dirk Draheim, and Gerald Weber. A Type System for
Reﬂective Program Generators. Science of Computer Programming, vol. 76,
no. 5, May 2011, pp. 392–422.
179. Christian Maes. An Introduction to the Theory of Markov Processes –
Mostly for Physics Students. Instituut voor Theoretische Fysica, K.U. Leu-
ven, 2012.
180. Vikash Mansinghka, Daniel Selsam, and Yura Perov. Venture – a Higher-
Order Probabilistic Programming Platform with Programmable Inference.
In: The Computing Research Repository, arXiv:1601.04943, Cornell Uni-
versity Library, April 2014, pp. 1–10.

References
205
181. Andrei Andrejewitsch Markov. Extension of the Law of Large Numbers
to Dependent Quantities (in Russian). Izvestiya Fiziko-Matematicheskikh
Obschestva Kazan University, vol. 15, 1906, pp. 135–156.
182. Per Martin-Löf. Constructive Mathematics and Computer Programming.
In L.J. Cohen et al., eds.: Logic, Methodology and Philosophy of Science,
VI, 1979, pp.153–175. North Holland, Amsterdam, 1982.
183. Per Martin-Löf. Intuitionistic Type-Theory. Bibliopolis, 1984.
184. Annabelle McIver and Carroll Morgan. Partial Correctness for Probabilistic
Demonic Programs. Theoretical Computer Science, vol. 266, nos. 1–2, 2001,
pp. 513–541, 2001.
185. Annabelle McIver and Carroll Morgan. Abstraction, Reﬁnement and Proof
for Probabilistic Systems. Springer, Berlin, 2005.
186. Edward J. McShane. Partial Orderings and Moore-Smith Limits. The
American Mathematical Monthly, vol. 59, 1952, pp. 1–11.
187. Tom Melham. A Package for Inductive Relation Deﬁnitions in HOL. In M.
Archer, J. J. Joyce, K. N. Levitt, and P. J. Windley, eds.: Proceedings of
the 1991 International Workshop on the HOL Theorem Proving System
and its Applications, IEEE Computer Society Press, Los Alamitos, 1992,
pp. 350–357.
188. P. Mell and T. Grance. The NIST Deﬁnition of Cloud Computing – version
15. National Institute of Standards and Technology, Information Technol-
ogy Laboratory, 2009.
189. Carl D. Meyer. Matrix Analysis and Applied Linear Algebra. Society for
Industrial and Applied Mathematics, Philadelphia, February 2001.
190. Robin Milner. Logic for Computable Functions – Description of a Ma-
chine Implementation. Technical Report AD-785 072, Advanced Research
Projects Agency National Aeronautics and Space Administration, May
1972.
191. Robin Milner. Implementation and Applications of Scott’s Logic for Com-
putable Functions. ACM SIGPLAN Notices – Proceedings of ACM Con-
ference on Proving Assertions about Programs, vol. 7, no 1, January 1972,
pp. 1–6.
192. Robin Milner. Models of LCF. Memo AIM-186, Stanford Artiﬁcial Intelli-
gence Laboratory, Stanford University, 1973.
193. Robin Milner, Mads Tofte, Robert Harper. The Deﬁnition of Standard ML.
MIT Press, Cambridge, 1990.
194. Michael Mislove. Anatomy of a Domain of Continuous Random Vari-
ables (i). In: Models of Interaction – Essays in Honour of Glynn Winskel.
Theoretical Computer Science, vol. 546, August 2014, pp. 176–187.
195. Michael Mislove. Anatomy of a Domain of Continuous Random Vari-
ables (ii). In Bob Coecke, Luke Ong, Prakesh Panangaden, eds.: Compu-
tation, Logic, Games, and Quantum Foundations – the Many Facets of
Samson Abramsky, LNCS 7860, Springer, Berlin, 2013, pp. 225–245.
196. Michael Mislove. Domain Theory and Random Variables. In: The Com-
puting Research Repository, arXiv:1607.07698, Cornell University Library,
August 2106, pp. 1–23.
197. Eugenio Moggi. Computational Lambda-Calculus and Monads. In: Pro-
ceedings of LICS’89 – the 4th Annual Symposium on Logic in Computer
Science, IEEE Computer Society, Los Alamitos, 1989, pp. 14–23.

206
References
198. David Monniaux. Abstract Interpretation of Probabilistic Semantics. In
Jens Palsberg et al., eds.: Proceedings of SAS’ 2000 – the 7th International
Symposium on Static Analysis, LNCS 1824, Springer, Berlin, 2000, pp. 322–
339.
199. David Monniaux. Abstract Interpretation of Programs as Markov Deci-
sion Processes. Science of Computer Programming, vol. 58, no. 1–2, 2005,
pp. 179–2052.
200. Eliakim H. Moore and H. L. Smith. A General Theory of Limits. American
Journal of Mathematics, vol. 44, no. 2, April 1922, pp. 102–121.
201. Yiannis N. Moschovakis. Elementary Induction on Abstract Structures.
Dover Publications, Mineola, 1974.
202. Yiannis N. Moschovakis. On the Basic Notions in the Theory of Induc-
tion. In Robert E. Butts and Jaako Hintikka, eds.: Logic, Foundations of
Mathematics, and Computability Theory, The University of Western On-
tario Series in Philosophy of Science Volume 9, D. Reidel, Dordrecht, 1977,
pp. 207–236.
203. Peter D. Mosses. Denotational Semantics. In Jan van Leeuwen, ed.: Hand-
book of Theoretical Computer Science, vol. B – Formal Models and Semat-
ics. MIT Press, Cambridge, 1990, pp. 575–631.
204. Rajeev Motwani and Prabhakar Raghavan. Randomized Algorithms. Cam-
bridge University Press, Cambridge, 1995.
205. Rajeev Motwani and Prabhakar Raghavan. Randomized Algorithms. ACM
Computing Surveys, vol. 28, no. 1, March 1996, pp. 33-37.
206. Leopoldo Nachbin. Topologia e Ordem. University of Chicago Press,
Chicago, 1950, pp. 1-114.
207. Leopoldo Nachbin. Topology and Order. Van Nostrand, Princeton, 1965.
208. Michael A. Nielsen and Isaac L. Chuang. Quantum Computation and Quan-
tum Information – the 10th Anniversary Edition. Cambridge University
Press, Cambridge, 2010.
209. Tobias Nipkow, Lawrence C. Paulson, and Markus Wenzel. Isabelle/HOL
– A Proof Assistant for Higher-Order Logic, Lecture Notes in Computer
Science 2283, Springer, Berlin, 2002.
210. B. Nordström, K. Peterson, and J.M. Smith. Programming in Martin-Löf’s
Type Theory. The International Series of Monographs on Computer Sci-
ence. Clarendon Press, Oxford, 1990.
211. James R. Norris. Markov Chains. Cambridge University Press, Cambridge,
1997.
212. Kristen Nygaard and Ole-Johan Dahl. The Development of the SIMULA
Languages. The 1st ACM SIGPLAN Conference on History of Program-
ming Languages, pp. 245–272. ACM Press, New York, 1978.
213. Chris Okasaki. Purely Functional Data Structures. Cambridge University
Press, Cambridge, 1999, pp. 1–223.
214. Sungwoo Park. A Calculus for Probabilistic Languages. In Z. Shao, P. Lee,
eds.: Proceedings of TLDI’03: The 1st ACM SIGPLAN International Work-
shop on Types in Languages Design and Implementation, ACM Press, New
York, 2004, pp. 38–49.
215. Sungwoo Park. A Programming Language for Probabilistic Computation.
Ph.D. Thesis, CMU-CS-05-137, Carnegie Mellon University, August 2005.

References
207
216. Terence Parr, Sam Harwell, and Kathleen Fisher. Adaptive LL(⋆) Parsing
– the Power of Dynamic Analysis. In: Proceedings of OOPSLA 2014 – 28th
ACM Conference on Object-Oriented Programming, Systems, Languages
& Applications, ACM Press, New York, 2014, pp. 579–598.
217. Simon L. Peyton Jones. The Implementation of Functional Programming
Languages, Prentice Hall, Upper Saddle River, May 1987, pp. 1–500.
218. Avi Pfeﬀer. IBAL – A Probabilistic Rational Programming Language. In:
Proceedings of IJCAI’01 – the 17th International Joint Conference on Arti-
ﬁcial Intelligence, vol. 1, Morgan Kaufmann, San Francisco, 2001, pp. 733–
740.
219. Benjamin C. Pierce. Types and Programming Languages. MIT Press, Cam-
bridge, 2002.
220. Gordon D. Plotkin. Call-by-Name, Call-by-Value and the λ-Calculus, The-
oretical Computer Science, vol. 1, no. 3, 1975, pp. 125–159.
221. Gordon D. Plotkin. A Powerdomain Construction. In: SIAM (Society for
Industrial and Applied Mathematics) Journal of Computing, vol. 5, no. 3,
1976, pp. 452–487.
222. Gordon D. Plotkin. A Powerdomain for Countable Non-Determinism. In
M. Nielsen, E.M. Schmidt, eds.: Proceedings of ICALP’82: the 9th Interna-
tional Colloquium on Automata, Languages and Programming, LNCS 140,
Springer, Berlin, 1982, pp. 412–428.
223. Gordon D. Plotkin. LCF Considered as a Programming Language. Theo-
retical Computer Science, vol. 5, no. 3, December 1977, pp. 223–255.
224. Gordon D. Plotkin. Domains – Pisa Notes on Domains. University of Ed-
inburgh, 1983.
225. Michael O. Rabin. Probabilistic Automata. Information and Control, vol. 6,
no. 3, 1963, pp. 230–245.
226. Michael O. Rabin. 1976. Probabilistic Algorithms. In J.F. Traub, ed.: Al-
gorithms and Complexity – Recent Results and New Directions, Academic
Press, Cambridge, 1976, pp. 21–39.
227. Michael O. Rabin. Probabilistic Algorithms for Testing Primality. Journal
of Number Theory, vol. 12, no. 1, 1980, pp. 128–138.
228. Norman Ramsey and Avi Pfeﬀer. Stochastic Lambda Calculus and Mon-
ads of Probability Distributions. In: J. Launchbury, J.C. Mitchell, eds.:
Proceeding of POPL 2002 – the 29th SIGPLAN-SIGACT Symposium on
Principles of Programming Languages, ACM SIGPLAN Notices, vol. 37,
no. 1, January 2002, pp. 154–165.
229. Manfred Reichert and Peter Dadam. ADEPTﬂex – Supporting Dynamic
Changes of Workﬂows Without Losing Control. Journal of Intelligent In-
formation Systems, vol. 10, no. 2, 1998, pp. 93–12.
230. Dan Romik. MATH/STAT 325a – Probability Theory Lecture Notes. Uni-
versity of California Davis, Fall 2011.
231. Stuart Russell. Unifying Logic and Probability. Communications of the
ACM, vol. 58, no. 7, July 2015, pp. 88–97.
232. Nasser Saheb-Djahromi: Probabilistic LCF. In J. Winkowski, ed.: Proceed-
ings of MFCS 1978 – the 7th Symposium on Mathematical Foundations of
Computer Science, Lecture Notes in Computer Science 64, Springer, Berlin,
1978, pp. 442–451.
233. Nasser Saheb-Djahromi. CPO’S of Measures for Nondeterminism. Theoret-
ical Computer Science, vol. 12, no. 1, 1980, pp. 19–37.

208
References
234. Eric Schechter. Handbook of Analysis and Its Foundations. Elsevier, Ams-
terdam, 2015.
235. David A. Schmidt. Denotational Semantics – A Methodology for Language
Development. Allyn & Bacon, Boston, August 1986.
236. Moses Schönﬁnkel. Über die Bausteine der mathematischen Logik. Mathe-
matische Annalen, no. 92, 1924, pp. 305–316.
237. Dana S. Scott. A Type-Theoretic Alternative to ISWIM, CUCH, OWHY.
Theoretical Computer Science, vol. 121, no. 1–2, 1993, pp. 411–440.
238. Dana S. Scott. Outline of a Mathematical Theory of Computation. Techni-
cal Monograph PRG-2, Oxford University Computing Laboratory, Oxford,
November 1970.
239. Dana S. Scott. Continuous Lattices. Technical Monograph PRG-7, Oxford
University Computing Laboratory, Programming Research Group, August
1971.
240. Dana S. Scott. Data Types as Lattices. Society for Industrial and Applied
Mathematics (SIAM) Journal on Computing, vol. 5, no. 3, pp. 522–587,
1976.
241. Dana S. Scott. Domains for Denotational Semantics. In M. Nielsen, E. M.
Schmidt, eds.: Proceedings of ICALP’82 – the 9th Colloquium on Automata,
Languages and Programming, LNCS 140, Springer, Berlin, pp. 577–613.
242. Dana S. Scott. Stochastic λ-Calculi – An Extended Abstract. Journal of
Applied Logic, vol. 12, no. 3, 2014, pp. 369–376.
243. Dana S. Scott and Cristopher Strachey. Toward a Mathematical Semantics
for Computer Languages. Technical Monograph PRG-6, Oxford University,
1971.
244. Koushik Se, Mahesh Viswanathan, and Gul Agha. Vesta: A Statistical
Model-Checker and Analyzer for Probabilistic Systems. In: QEST 2005 –
Proceedings of the 2nd International Conference on the Quantitative Evalu-
ation of Systems, IEEE Computer Society, Los Alamitos, 2005, pp. 251–252.
245. Richard Serfozo. Basics of Applied Stochastic Processes – Probability and
its Applications. Springer, Berlin, 2009.
246. Michael B. Smyth. Power Domains. Journal of Computer and System Sci-
ences, vol. 16, no. 1, 1978, pp. 23–36.
247. Michael B. Smyth. Power Domains and Predicate Transformers – A Topo-
logical View. In J. Diaz, ed.: Proceedings of ICALP ’83 – the 10th Interna-
tional Colloquium on Automata, Languages and Programming, LNCS 154,
Springer, Berlin, 1983, pp. 662–676.
248. Robert M. Solovay and Volker Strassen. A Fast Monte-Carlo Test for Pri-
mality. SIAM Journal on Computing, vol. 6, no. 1, 1977, pp. 84–85.
249. Sam Staton, Hongseok Yang, Chris Heunen, Ohad Kammar, and Frank
Wood. Semantics for Probabilistic Programming, Higher-Order Func-
tions, Continuous Distributions and Soft Constraints. In: Proceedings of
LICS 2016 – the 31st Annual ACM/IEEE Symposium on Logic in Com-
puter Science, ACM, New York, 2016.
250. Sam Staton, Hongseok Yang, Chris Heunen, Ohad Kammar, and Frank
Wood. Semantics for Probabilistic Programming, Higher-Order Functions,
Continuous Distributions and Soft Constraints, version 3. In: The Com-
puting Research Repository, arXiv:1601.04943, Cornell University Library,
May 2016, pp. 1–10.

References
209
251. David Stirzaker. Elementary Probability. Cambridge University Press,
Cambridge, 2010.
252. Anatoli V. Skorohod. Limit Theorems for Stochastic Processes. Theory of
Probability & Its Applications, vol. 1, no. 3, 1956, pp. 261–290.
253. Joseph E. Stoy. Denotational Semantics. The Scott-Strachey Approach to
Programming Language Theory. MIT Press, Cambridge, 1981.
254. Daniel W. Stroock. An Introduction to Markov Processes. Springer, Berlin,
2005.
255. Alfred Tarski. A Lattice-Theoretical Fixpoint Theorem and its Applica-
tions. Paciﬁc Journal of Mathematics, vol. 5, no. 2, 1955, pp. 285–309.
256. T. Thalhammer, M. Schreﬂ, and M. Mohania. Active Data Warehouses –
Complementing OLAP with Analysis Rules. Data & Knowledge Engineer-
ing 39, 2001, pp. 241–269.
257. The MathWorks Inc. Simulink Reference – Matlab & Simulink. The Math-
Works Inc., 2015.
258. Regina Tix, Klaus Keimel, and Gordon D. Plotkin. Semantic Domains for
Combining Probability and Non-Determinism. Electronic Notes in Theo-
retical Computer Science, vol. 222, Elsevier, 2009, pp. 3–99.
259. Steven Vickers. Information Systems for Continuous Posets. Theoretical
Computer Science, vol. 114, no. 2, June 1993, pp. 201–229.
260. Barbara Weber and Manfred Reichert. Enabling Flexibility in Process-
Aware Information Systems – Challenges, Methods, Technologies. Springer,
Berlin, 2012.
261. Gerhard Weiss (editor). Multiagent Systems, 2nd edn. MIT Press, Cam-
bridge, April 2013.
262. B.A Wichmann, A.A. Canning, D.L. Clutterbuck, L.A. Winsbarrow, N.J.
Ward, and D.W.R. Marsh. Industrial Perspective on Static Analysis. Soft-
ware Engineering Journal, Mar 1995, pp. 69–75.
263. Glynn Winskel. The Formal Semantics of Programming Languages – an
Introduction. MIT Press, Cambridge, February 1993.
264. Andrew Chi-Chin Yao. Probabilistic Computations – Toward a Uniﬁed
Measure of Complexity. In: Proceedings of SFCS’77 – the 18th Annual
Symposium on Foundations of Computer Science, IEEE Computer Society,
Los Alamitos, 1977, pp. 222–227.
265. Andrew Chi-Chin Yao and F. Frances Yao. On the Average-Case Com-
plexity of Selecting the kth Best. Proceedings of FOCS’78, 19th Annual
Symposium on Foundations of Computer Science, IEEE Computer Society
1978, Los Alamitos, pp. 280–289.
266. Andrew Chi-Chin Yao and F. Frances Yao. On the Average-Case Complex-
ity of Selecting the kth Best. Society for Industrial and Applied Mathemat-
ics (SIAM) Journal on Computing, 1982, vol. 11, no. 3, pp. 428–447.
267. Hakan L. S. Younes. Ymer: A Statistical Model Checker. In Kousha Etes-
sami, Sriram K. Rajamani, eds.: Proceedings of CAV’2005 – 17th Interna-
tional Conference on Computer Aided Veriﬁcation, LNCS 3576, Springer,
2005, pp. 429–433
268. Moshe
Zukermann.
Introduction
to
Queueing
Theory
and
Stochas-
tic
Teletraﬃc
Models.
In:
The
Mathematical
Research
Repository,
arXiv:1307.2968, Cornell University Library, January 2016.
269. https://github.com/tyler-barker/Randomized-PCF

Index
Symbols
∅
see empty environment
0S
see functional null element
0?
see test for zero
1
see one-element set
1
see one element
[0, 1]ω
see domain of probability
values
≡α
see alpha equivalence
≈
see equivalence relation
S/≈
see quotient set
[e]/≈
see equivalence class
|
see choice operator
|Λ
see choice simulation
⊕
see functional addition
⊗
see functional scalar multiplication
||i
j
see semantic choice operator
[[ ]]
see semantic function
(| |)
see domain object
[ ]
see data point semantics
⌊A →B⌋
see omega-cpo targeting
function space
[A →B]
see omega-continuous
function space
⊔
see least upper bound
[x := d]
see variable substitution
⊓
see greatest lower bound
⊑
see partial order
≼
see syntactic approximation
−1
see inverse function
†
see image of an omega-chain, see
lifted function
#
see sequence length
∅
see mean reduction length
▶
see least element of a sequence
•
see sequence concatenation
S
see complement set
→
see embedding
→
see semantic abstraction
i−→
see one-step semantics
⋆→
see reduction relation
⇒
see reduction probability
⇒p
see path computability
↛
see partial function
⊢
see rule-based derivation
⊥
see bottom element
⊤
see top element
α
see perfoming term
α-equivalence
see alpha-equivalence
β
see bounded termination
β
see unbounded termination
δ
see node degree
ηM⟨s, S⟩
see hitting probability
ηn
M⟨s, S⟩
see bounded hitting
probability
|ηM⟨s, S⟩|
see mean hitting time
ε
see program run execution
 
see environment
E
see expected value
Ei
see conditional expected value
˙f
see truth constant
HM(s)
see ﬁrst hitting time
ι
see initial distribution
ι
see initial distribution
id
see identity function
© Springer-Verlag Berlin Heidelberg 2017
D. Draheim, Semantics of the Probabilistic Typed Lambda Calculus,  
DOI 10.1007/978-3-642-55198-7 
211

212
Index
if (, , )
see conditional expression
κ
see graph nodes
l
see length of a walk
λ-calculus
see lamdba calculus
Λ
see lambda term
Λ∅
see closed lambda term
Λ→
see higher-typed term
Λg
see ground term
Λopen
see open lambda term
ΛP
see program
ΛV
see value
lim
n→∞
see limit
μ
see recursion operator
⟨MnΩ⟩
see unwinding term
M
see Markov chain existence
π
see path
Φ
see ﬁxed-point operator
ψ
see syntactical constructor
Ψ
see syntactical constructor
P
see probability measure
P(A|B)
see conditional probability
PB
see conditional probability
ρ
see immediate reduction relation
ϱ
see program execution run
R
see reduction graph
σ
see substitution
σ-algebra
see sigma algebra
ς
see reduction tree correspondence
ΣΣΣ
ΣΣΣ
ΣΣΣ
see functional sum
S
see reduction chain
τ[M]
see reduction tree
Tg
see ground type
˙t
see truth constant
⋆WG
see ﬁnite walk
ωWG
see inﬁnite walk
⊕WG
see walk
ω-chain
see omega chain
ω-complete partial order
see omega-
complete partial order
ω-continuous function
see omega-
continuous function
ω-cpo targeting function space
see
omega-cpo targeting function
space
Ωt
see non-terminating term
Var
see variable
A
abelian group
63
absorption
31, 78
acyclic graph
39
agent orientation
3, 4, 16
algebraic structure
63
Alonzo Church
6
alpha equivalence
72
Andrew C. Yao
5
Andrey Kolmogorov
18
anti-symmetry
41
applicative bisimulation
91
apply
53
associativity
63
average
hitting time
see mean hitting time
reduction length
see mean reduction
length
axiomatic semantics
81
axioms of Kolmogorov
19
B
basic semantic functions
141
Beth’s Tree Theorem
39
big-step semantics
73, 91, 165
bisimulation
91
bottom element
42
bound variable
70
bounded
above
62
hitting probability
28
termination
94, 99, 101, 112
business process management
3
C
c.c.c
see Cartesian closed category
call-by-name
76
Cartesian closed category
53, 190
central cover Lemma
116
choice
operator
67
simulation
85
Church
16, 92
circuit design
16
closed
class
31

Index
213
term
71
closed lambda term
71
codomain
60
coherent space
191
commutative group
see abelian group
compact ordered space
190
complement set
59
complete
lattice
42
partial order
48
computational
adequacy
158
lambda calculus
190
concatenation
of sequences
see sequence concate-
nation
conditional
complete lattice
43
expectation
see conditional
expected value
expected value
22
expression
66, 74, 77, 166, 170, 174,
179, 186
probability
19
connected graph
37
constructor
67
ﬁxity
67
precedence
67
context
substitution
72
continuation-passing style
91
continuous
-time Markov chain
16
stochastic logic
16
control system
16
convergence
62
convergent sequence
see convergence,
62
convex powerdomain
191
cpo
see complete partial order
cryptographic systems
1
CSL
see continuous stochastic logic
CTL
see temporal logic
cycle
39
D
DAG
see directed acyclic graph
Dana Scott
13
data
point
50, 143
semantics
157
decomposition
139
degree
of a node
see node degree
of termination
see termination
degree
derivation
see rule-based derivation
Dexter Kozen
190
digraph
34
directed
acyclic graph
38
graph
see digraph
pseudograph
see multigraph
subset
48
discrete
-time Markov chain
see Markov
chain
random variable
22
distribution
see probability distribu-
tion
distributivity
64
divergence
62
divergent sequence
see divergence
domain
138
object
138
of probability values
137
restricted function
see restricted
function
domain theory
13
DTMC
see Markov chain
E
edge
34
Edinburgh LCF
see LCF
embedded system
16
embedding
60, 132
empty environment
139
endofunction
60
environment
139, 151, 155
equivalence
class
61
relation
61
ETMCC
15
evaluation semantics
81, 136
event
18
expectation
see expected value

214
Index
expected value
22
F
factorial
43
ﬁeld
63
ﬁnite
subset
117
vector
64
walk
35
ﬁrst
hitting time
28
passage time
see ﬁrst hitting time
ﬁxed-point
operator
57, 66, 141, 155
theorem
57
formal language
see language
fourth-generation language
6
free variable
70
function update
60
functional
addition
143
null element
143
programming
5, 88
scalar multiplication
143
sum
144
G
Gauss-Jordan
algorithm
122
elimination
121, 122, 126
generative programming
69
Genoupe
69
grammar
40
graph
35, 37
cover
115
nodes
35
greatest lower bound
42, 49
of an ω-chain
49
GreatSPN
16
ground
term
71
type
66
group
63
associativity
63
inverse element
63
H
Haskell
5, 191
Higher-Order Logic
47
higher-typed terms
71
hitting probability
28
HOL
see Higher-Order Logic
I
IBAL
16, 92
identity
function
60
ih (i.h.)
see induction hypothesis
image of an ω-chain
52
immediate reduction relation
6, 73,
107
of the typed lambda calculus
74
imperative programming
15
indexed
family
60
induction hypothesis
119
inductive
complete partial order
see directed
complete partial order
deﬁnition
40
inﬁnite walk
35
information system
190
initial distribution
25
injective function
see embedding
inner node
38
inverse
function
59
image
59
inverse element
63
Isabelle
see Higher-Order Logic
J
JSpick
69
K
König’s Lemma
36, 37, 111, 124
Kleene
hull
see Kleene closure
operator
see Kleene closure
star
see Kleene closure
Knaster-Tarski ﬁxed-point theorem
43
L
lambda
calculus
66

Index
215
terms
66
language
39
lattice
42
LCF
13
leaf
38
least
upper bound
41, 49
elimination Lemma
54
exchange Lemma
55
of an ω-chain
49
property
62
substitution
151
length
of a sequence
see sequence length
of a walk
35
lifted function
59
limit
62
linear
algebra
30
equation system
30, 33, 97–99, 121
logic
191
space
see vector space
lower
bound
42, 49
of an ω-chain
49
powerdomain
191
lower bound
correspondence
158, 164, 188
lub (l.u.b.)
see least upper bound
elimination Lemma
see least upper
bound elimination Lemma
exchange Lemma
see least upper
bound exchange Lemma
M
manufacturing execution system
16
map-reduce
88
Markov
chain
24
existence
26
property
24
Matlab
16
mean
hitting time
33
reduction length
82
measurable
function
21
space
21
meet
42
-complete
45
Michael O. Rabin
5
ML
5
model
-based design
3, 16
checking
3, 15
monad
190
monotone
convergence theorem
63
function
41
monotonically increasing sequence
62
MRMC
15
multigraph
34
N
n-dimensional vector
see n-vector
n-fold application
60
n-vector
61, 64
Nachbin
190
natural induction
68, 138
node
34
non-terminating term
176
NSP
69
null vector
64
O
object orientation
4
OCL-R
69
omega
-complete partial order
49, 137
-continuous function
53
space
56
-cpo targeting function space
50
chain
49
one
-step semantics
76, 76–78, 78
element
59
set
59
open lambda term
71
open term
71, 151
operational
equivalence
87
semantics
81, 76–81
outcome
18
over-performance
see performing term

216
Index
P
p-computation
see path computation
p-stoppability
see path stoppability
partial
function
60, 117, 121
order
41
path
36
computation
124
stoppability
94, 99, 123, 123
PCF
5, 13, 127, 165, 191
PCS
see probabilistic coherent space
pCTL
see temporal logics
PEPA
16
performance
see performing term
performing term
165
Petri net
4
powerdomain
144
pre-distribution
see probability
pre-distribution
Prism
15
probabilistic
applicative bisimulation
91
coherent space
191
lambda calculus
66
matrix
80
powerdomain
136, 190
programming language
16
probability
distribution
19
function
18
matrix
24
measure
18
pre-distribution
136
space
18
value domain
see domain of
probability values
process
algebra
4, 16
instance
103
program
71
analysis
124
execution
103, 105
run
109
run
106, 109
execution
110
Q
quantum computing
5
queueing
system
16
theory
4
quotient set
62
R
R
see reduction graph
random
generator
191
variable
21
randomized algorithm
5
range
of a function
60
rational
programming language
16
rational programming language
16
real number
62
recursion approximation
see syntactic
approximation
recursion operator
66
recursive
function
44
redex
48
reduction
chain
80
graph
108
probability
81, 81
relation
74
tree
130
correspondence
131
reﬂexivity
41, 61
rooted tree
38
row echelon form
122
rule
46
-based deﬁnition
45
-based derivation
47
S
S
see reduction chain
scalar
64
multiplication
64
Scott-Strachey approach
135
semantic
abstraction
60
choice operator
146
continuity
147, 149
correspondence
157

Index
217
data point
see data point
equation
139
function
140–141
well-deﬁnedness
145
semilattice
45
sequence
of real numbers
62
sequence concatenation
61
sigma algebra
18
SimEvents
16
simply typed lambda calculus
6
Simula
4
Simulink
16
Six Sigma
3
small-step semantics
91
soundness
158
spurious outcome
103, 104
statechart
16
static program analysis
124
stochastic
lambda calculus
2
process algebra
see process algebra
programming language
16
strict termination
9
structural induction
68
sub-term
139
substitution
72
Lemma
157
supremum
41, 62
symmetry
61
syntactic approximation
182
syntactical constructor
70
T
temporal logics
16
term
cover
94
rewriting system
48
term cover
99
terminating program runs
110
termination degree
93
test for zero
66
third generation language
6
time homogenity
24
top element
42
total mass
19, 136
transition matrix
24, 24
transitivity
41, 61
tree
39
program run
131
truth constant
66
type
-respecting
139, 140
environment
69
preservation
140
typing rule
67
U
unbounded termination
94, 99, 101
undeﬁned environment
see empty
environment
undirected graph
see graph
unwinding term
178
upper
powerdomain
191
upper bound
41, 49
correspondence
158, 159
of an omega-chain
49
V
value
73
variable
environment
see environment
substitution
see substitution
vector
64
addition
64
compatibility
64
distributivity
64
in the narrow sense
64
space
64, 143, 158
law
64
Venture
16, 92
vertice
see node
Vesta
15
W
walk
35
well-deﬁnedness
of the reduction tree
see reduction
tree well-deﬁnedness
of the semantic function
see
semantic function well-deﬁnedness
well-typed
67
Y
Ymer
15

218
Index
Z
zero test
see test for zero

