471
ISSN 1064-2307, Journal of Computer and Systems Sciences International, 2018, Vol. 57, No. 3, pp. 471–481. © Pleiades Publishing, Ltd., 2018.
Original Russian Text © V.P. Kutepov, 2018, published in Izvestiya Akademii Nauk, Teoriya i Sistemy Upravleniya, 2018, No. 3, pp. 116–127.
Models and Languages for Description of Parallel Processes
V. P. Kutepov
National Research University Moscow Power Engineering Institute (MPEI), Moscow, 111250 Russia
e-mail: kutepov@appmat.ru
Received October 11, 2017; in final form, November 27, 2017
Abstract—This paper considers models and languages of parallel processes that make it possible to
adequately describe the properties and relationships among real processes both at the level of events
and in real time. The proposed models and languages are shown to provide more flexibility in the
description of parallelism compared to similar well-known models and languages. We also discuss the
practical application of models and languages for parallel processes to design high-level concurrent
programming languages, as well as distributed computing and control systems.
DOI: 10.1134/S1064230718020119
INTRODUCTION
The concept of a process is so universal that, without it, we would not be able to give an adequate defi-
nition of a system, algorithm, or any random or purposeful activity [1].
According to the manner in which the actions of a process are carried out in time, processes are divided
into continuous and discrete processes, while, based on the law that determines causal relationships
among these actions, processes are classified into deterministic and random.
When studying processes, we have to consider the following triad: a model or language of processes,
rules for their execution and a set of tracks or histories of process execution, which reflect a time sequence
of process actions. The set of tracks generally depends on the execution time of the actions of a process
and the conditions of their influence on other actions.
If a model or language of processes and rules of their execution are known, then a set of histories gen-
erated for a particular process is restored by observing its execution. An inverse problem of determining
the model based on observed execution histories, however, is generally unsolvable. In this case, the max-
imum yield is an approximate model reconstruction of an observable set of processes (physics is replete
with examples that confirm this assertion).
In this paper, we consider deterministic discrete processes whose execution is represented as a
sequence of atomic process actions (acts, observable events, and changes in states). We focus on the model
description of the following properties and relationships: asynchrony and synchrony of process acts, as
well as the time and event representation of their sequences, which depend on the causal relationships
among sets of process acts. These relationships determine the conditions for the initialization of acts
during the execution of a process and, in the general case, depend not only on the specific characteristics
of a particular process but also on the time relationships among other acts that affect the initialization of
a particular act.
Among various models of discrete processes, we should first point out switching logic circuits, finite
automata, and asynchronous circuits [2, 3]. The development of computer systems and concurrent pro-
gramming languages promoted research in the models and languages of parallel processes for which par-
allelism, synchronism and asynchronism are crucial to achieve the maximum acceleration of the corre-
sponding computing devices and parallel programs [4–9].
Presently, programmable logic integrated circuits (PLICs) represent a new technology for creating
complex special-purpose computing devices and systems that are designed by the method of direct anal-
ogy, i.e., by translating parallel algorithms into the corresponding architectures and circuit solutions.
Works [10–12] are, in a sense, classical; they introduce a general approach to creating generalized models
that describe interacting parallel processes. In these works, the event modes of processes are constructed
based on three binary operators of process composition—sequential composition, parallel composition,
ARTIFICIAL
INTELLIGENCE

472
JOURNAL OF COMPUTER AND SYSTEMS SCIENCES INTERNATIONAL 
 Vol. 57 
 No. 3 
 2018
KUTEPOV
and choice (alternative composition)—as well as on the operators of synchronous interprocess communi-
cation [13].
The Petri net language [14], which was created to describe the operation of multicomponent systems,
has become very popular due to its convenient graph representation of processes. The necessity for the
description of real processes gave rise to numerous extensions of the Petri net language, aiming at the ade-
quate representation of parallelism [15, 16], stream processing (which requires data tagging), etc.
According to [10–12], parallel processes can be translated into equivalent Petri nets while preserving
all their execution histories (tracks and protocols). The converse, however, seems to hold only for safe
Petri nets, where each place contains no more than one token. Moreover, parallel processes have a number
of features that cannot be described with Petri nets [17, 18].
Generally, the parallel composition of two processes P1 and P2 in (P1 || P2) ⋅ P3, where the dot operator
represents sequential composition, requires the successful termination of both processes P1 and P2 before
initiating process P3. In practice, particularly in parallel programs, there are other forms of parallelism
[17, 18] that require more complex conditions for the successful termination of parallel processes.
For example, the code line y1 = if p(x) then f1(x) else f2(x); y2 = f3(y1) concurrently evaluates the func-
tions f1(x), f2(x) and the predicate p(x); however, the condition for initializing the evaluation of f3(y) is
determined by the time of the earliest successful evaluation of p(x) and f1(x) for the truth value of p(x) or
(exclusive or) 
 and f2(x) for the false value of p(x). Here, the condition for initializing the evaluation
of f3(y) is more complex.
Another typical example of parallelism involves several programs that use different methods to evaluate
the same function at different times. When merging them as parallel processes to minimize the time
required to evaluate the function, the condition for the successful termination of these parallel processes
is the time of the earliest termination of one of them. There is a form of parallelism whereby only the
simultaneous termination of two parallel processes can affect the initialization of the next process. AND
gates offer an example of such parallel processes. Several independent processes can merge to fulfill the
same task and asynchronously send their results to the next processes; this is typical for parallel stream
processing.
The models and languages described in this paper were created to adequately describe the specific
characteristics of parallel processes, which is a necessary condition for the development (based on them)
of effective execution control tools for parallel programs in computer systems [8, 9]. It should be noted
that there are a number of delicate problems concerning time identification in systems whose components
have their own clocks and time measurement accuracies [19–21]. Another important problem is the ver-
ification of processes [22] and development of effective concurrency control methods [23, 24].
The paper is organized as follows. Section 1 introduces a general model of discrete processes that is
based on specifying causal relationships among the actions (acts) of a process. As process acts, this model
uses intelligent data converters with several inputs (to receive the initialization data) and several groups of
outputs. According to a certain rule, the converter selects a group of outputs and determines a subset of
other converters to send the resulting data to their inputs. In our opinion, this allows the model to more
adequately describe processes in a real multicomponent system and parallel programs [9].
Section 2 introduces an automaton model for the description of asynchronous concurrent execution;
this model allows all tracks of asynchronous concurrent execution to be determined taking into account a
real-time parameter that specifies the execution times of the acts of the process. Section 3 describes the
language of parallel processes that extends the capabilities of the models and languages used to represent
real processes in systems and parallel programs. In Section 4, the language is extended to explicitly reflect
the real time in the course of process execution. Section 5 introduces a system of axioms for the equivalent
transformation of parallel processes. In Conclusions, we discuss some problems concerning the develop-
ment of the proposed approach to describe and analyze parallel processes.
1. GENERAL MODEL OF PARALLEL PROCESSES
In the general case, the initialization of process acts depends not only on causal relationships among
acts and their termination condition but also on the time relationships among instants of their termina-
tion. That is why the condition for the initialization of an act is generally given by a predicate formula that
specifies the necessary time relationships among the termination instants of the process acts that affect
the initialization of this act. For this purpose, a simple logical model can be constructed by defining a con-
structive set of numbers, e.g., a finite subset of real numbers, functions that determine termination
instants of process acts, arithmetic operators on time variables, and traditional logical operators.
( )
p x

JOURNAL OF COMPUTER AND SYSTEMS SCIENCES INTERNATIONAL 
 Vol. 57 
 No. 3 
 2018
MODELS AND LANGUAGES FOR DESCRIPTION OF PARALLEL PROCESSES
473
Definition 1. Process act a is a direct cause of act b, or b directly depends on a, if a “signal” triggering
the initialization of act b is transferred by act a without any mediators (a → b). A transitive closure of this
direct relationship is written as a* → b.
Obviously, act a can be both a direct and indirect cause of the initialization of act b.
The set of acts of a process that are direct causes of act a and inevitably lead to its execution is denoted
by IN (а). An act of a process can have several sets that necessarily initiate its execution. These sets can be
determined in a number of ways, randomly or deterministically, when executing a process.
For example, given a process for the concurrent execution of a conditional operator if p1(x) then f1(x)
else if p2(f2(x)) then f3(x) else f1(x), the act of evaluating the function f1(x) has two mutually exclusive sets
of acts that initialize its execution—{p1(x)} and {
(x), 
(x)}—which, in turn, are defined by the truth val-
ues of their predicates.
This example also demonstrates that acts p1(x) and p2(x) can choose (in this case, deterministically) the
acts of a process they can directly initialize upon their own completion. A sequence order, or temporal
overlapping, of the acts of a process in the course of process execution is determined by the fulfillment or
nonfulfillment of the conditions that specify the dependence among these acts. The following statements
clarify this dependence.
Statement 1. If a *→ b, and b *→ a does not hold, then act b is always executed upon execution of act a.
Statement 2. If both relationships a *→ b and b *→ a do not hold, then the arbitrary interleaving and
temporal overlapping of acts a and b is possible.
Statement 3. If the relationships a *→ b and b *→ a hold, then acts a and b can be executed concur-
rently; however, the set of all possible process execution histories (see below) depends significantly on the
durations of acts a and b.
Suppose that 
 is an at most countable set of acts, where mi is the number of groups
of inputs for the act ei (to which other acts can send signals initializing ei) and ni is the number of groups
of outputs (by choosing one of which, an act can send initializing signals to the inputs of other acts).
In each group, order the inputs and outputs of the act ei and denote (ei, i1, i2) ∈ E × N × N, where the
i2th output of the i1th group of outputs, ei, (i2, i1, ei) ∈ N × N × E, where the i2th input of the i1th group of
inputs of the act ei, and N is a natural sequence.
Definition 2. A process PR on a set of acts E' is represented as an ensemble of components PR = 〈E',
R, INIT, T, EXEC〉, where E' ⊆ E is the set of acts involved in the execution of the process, R ⊆ (E' × N ×
N) × 2N × N × E' is a relationship that links the inputs and outputs of the acts of a process (these links are
interpreted as channels for transmitting the initialization data between the inputs and outputs of the acts
of a process), INIT ⊆ E' is the subset of acts with which execution of the process begins, T is the time scale
that determines the accuracy of controlling the instants of initialization and termination of the acts of a
process, and EXEC represents execution rules of a process that govern the selection of a group of acts and
are used to transmit the initialization data (once an act is complete) to the inputs of other acts which are
specified by the relationship R.
The execution of the process begins as soon as some group of inputs of each act ei ∈ INIT receives sig-
nals that initialize its execution. Other acts of the process also start executing as soon as some group of their
outputs receives the initializing signals sent by the completed acts.
The following program operator describes the initialization of the act ei upon receiving the correspond-
ing signal by a group of its inputs: L: if p(ei, t) then “initialize the execution of act” ei else go to L.
Here, the predicate p(ei, t) is true if the signals that initialize the execution of the act ei have been
received by all inputs of at least one group of inputs at the instant t ∈ T.
It should be noted that this process model was used as a basis for designing a high-level concurrent pro-
gramming language [9].
Definition 3. A process is called structurally correct if each input of all its acts is linked with at least one
output of its other act.
A process is said to be correct if its acts are triggered at least once.
2. AUTOMATON REPRESENTATION OF EXECUTION TRACKS
The model of the asynchronous automaton considered below uses the description of a process to
reconstruct all possible tracks of its execution. A particular track is generated depending on the execution
1p
2p
=
=
(
, )
{
|
1,2,...}
i
i
m n
i
E
e
i

474
JOURNAL OF COMPUTER AND SYSTEMS SCIENCES INTERNATIONAL 
 Vol. 57 
 No. 3 
 2018
KUTEPOV
time of the acts, which can be arbitrary (the requirement of asynchrony of the automaton), as well as on
the rules used by the automaton to select a group of outputs through which the data that initializes the exe-
cution of other acts are sent. As a track, we consider a sequence of changes in the automaton’s states (in
which the sets of concurrently executed acts are fixed) with transitions between the states occurring upon
completion of one or (simultaneously) several acts executed in a given state.
This model assumes that the observer can control, at any time, a set of concurrently executed acts and
their termination, including the simultaneous termination of several acts. On the other hand, this model
can serve as a preimage of a centralized execution control system. Obviously, the accuracy of measuring
the time required to control the events related to the execution of a process determines the capabilities of
analyzing and modeling real processes.
Now proceed to a formal description of the automaton used to reconstruct process execution tracks in
the model described in Section 1.
Definition 4. An automaton’s state at the instant t is a subset E'' ⊆ 2E' of concurrently executed acts with
the transition from state Si, i = 1, 2, …, to state Si + 1 being induced at the instant t ' ≥ t of termination of
one or (simultaneously) several acts in Si. In a new state Si + 1, the acts in the state Si that have not been
terminated at the instant t' continue to be executed as do the new acts that have been initialized by the acts
successfully terminated in Si. The relationship R determines the cause–effect links between the acts of a
process.
The execution of a process begins in the state S0 with the simultaneous initialization of all acts from the
set INIT in the description of the process.
Note that the asynchrony property of the automaton implies that it can successfully operate in the case
where the execution time of the acts of a process is not specified in advance.
Definition 5. A process execution track is any finite or unbounded sequence of changes in the states of
a process that begin in the initial state S0.
If the execution time of the acts of a process is specified, then the number of execution tracks is reduced
significantly.
Figure 1 shows a graph-scheme [9] of a fully concurrent execution of the conditional operator if p(x)
then f1(x) else f2(x). The predicate act p has two groups of outputs (one output per each) and one group of
inputs. The other function acts have one group of outputs each. Acts p, f1, and f2 are the initial ones. The
description of links among the acts (relationship R) can easily be restored using the graph-scheme.
Figure 2 shows the possible execution tracks of the conditional operator in the cases of the termination of
the predicate p(x) with true and false values.
Note one important point concerning the specifics of representing the tracks of a process. Semantically
equivalent acts can often recur during the execution of a process (loops and recursions are typical causes
of this phenomenon). However, from a process perspective, these acts are distinct as they may have dif-
ferent execution times and communications with other acts; this is due to the fact that the rule for choos-
ing a group of outputs to send the initialization data to other acts is not specified in advance. Thus, a prob-
lem arises of uniquely naming the acts of a process that are regarded as equivalent in the course of execut-
ing a process. For instance, in the well-known operating systems with concurrency control (e.g., in the
PVM and ERLANG computer systems), this problem is solved by assigning a unique number (ID) to each
process generated.
In the course of executing a process, it is possible that the acts that are currently being executed, at a
certain instant, can no longer affect the continuation of a process. This is due to the fact that a terminated
act can choose one group of its outputs to send signals that initialize other acts.
Fig. 1. Graph-scheme of concurrent execution of conditional operator.
−
Result 1
Result 2
f1
p
1 V 2
p
p
f2

JOURNAL OF COMPUTER AND SYSTEMS SCIENCES INTERNATIONAL 
 Vol. 57 
 No. 3 
 2018
MODELS AND LANGUAGES FOR DESCRIPTION OF PARALLEL PROCESSES
475
Thus, a problem arises to determine and interrupt the acts being currently executed that, starting from
a certain instant, do not affect the continuation of a process. For parallel programs, this means the possi-
bility of early resource deallocation, which can significantly affect the runtime and resource usage [9].
Below, we define the conditions underlying an algorithm for the interruption of acts that, starting from
a certain instant, do not affect the continuation of a process.
Definition 6. For each act ei ∈ E' of a process, we define a set of acts E '' that directly affect this act; i.e.,
at least one of their outputs is linked with one of the inputs of the act ei.
By W(ei), we denote the set of acts that belong to a transitive closure of this relationship of direct effect
on the act ei. From the set W(ei), select a subset of acts W '(ei) that affect only the act ei. Suppose that ei
terminates at a certain instant t and a group j of its outputs is chosen to continue the process.
By V(ei, j), we denote the set of all acts that can be directly affected by the act ei on the condition that,
upon its termination, another group of its outputs (not j) is selected to continue the process.
Statement 4. All currently executing acts of a process that belong to a set S(ei, j) = {W'(e) | e ∈ V(ei, j)}
can be interrupted at the instant of termination of the act ei without affecting the continuation of the pro-
cess if the jth group of their outputs has been chosen to send the initialization signals to the corresponding
inputs of the other acts.
Figure 3 shows some processes of the concurrent execution of a conditional operator with interrup-
tions.
3. LANGUAGE OF PARALLEL PROCESSES
The following conditions specify the process semantics of the language.
1. Each act is initialized without delay, once the necessary conditions are met, and has finite duration.
2. Certain acts of a process can terminate with a controlled deadlock, which means that the acts fol-
lowing the terminated one cannot be executed.
3. On a set of observable events of the initialization and termination of process acts, the binary relations
simultaneously (=) and before (<) are defined that have a unique representation on a constructive set of
numbers used as the time scale.
4. Certain acts of a process can initiate the execution of a set of processes, which is determined dynam-
ically when executing the act.
Suppose that E = {ei | i = 1, 2, …} ∪ {∅} ∪ {stop}, X = {Xi | i = 1, 2, …} are at most countable sets of
constant and variable acts, ∅ is a deadlock act, and stop is the final act. A set of processes in the language
Fig. 2. Tracks of concurrent execution of conditional operator.
p, f1, f2
p
p
f1, f2
f1, f2
f1, f2
f1
f1
f1
f1
f1
f1
f2
f2
f2
f2
f2
f2
f1
f2
Result 1
Result 1
Result 1
Stop
Result 2
Result 2
Result 2
f1, f2
Result 1, f2
Result 1, f2
Result 2, f1
Result 2, f1
1 V 2
−

476
JOURNAL OF COMPUTER AND SYSTEMS SCIENCES INTERNATIONAL 
 Vol. 57 
 No. 3 
 2018
KUTEPOV
is defined inductively by using binary operators of composition (
, ⋅, 〈 ||, 〈||〉) and, in the general case, sys-
tems of recursive equations:
(1) Each act a ∈ E is a process;
(2) If P1 and P2 are processes, then (P1ΔP2) are also processes, where Δ ∈ {⋅, 
, 〈 ||, 〈||〉};
(3) System of equations
(3.1)
where τi is an expression, constructed by applying the composition operator to the processes and variables xi,
that defines n processes of , where  is the minimum (in terms of the inclusion of sets of tracks) solution
to system (3.1).
Here, we do not cite the well-known theoretical grounds (which go back to D. Scott) for the existence
of the minimum solution to such systems of equations [10, 11]. Note only that it is possible to construct
minimum solutions to the system of equations (*) as the least upper bounds of an ordered sequence of
approximations:
where the expression in square brackets means the simultaneous substitution of 
, j = 
, for all inclu-
sions of the variable xj in τi.
Hereinafter, to drop some brackets in writing, the following order of precedence for composition oper-
ators is used: ⋅, 〈||, 〈||〉, 
.
3.1. Rules of Process Execution at the Level of Events
A process Xj given by the system of equations (3.1) is executed by parsing its terms in reverse order com-
pared to their inductive generation, process interpretation of composition operators, and substitution of
variable acts by their terms in the system of equations.
1. Expression ϕ(P1 ⋅ P2) means that execution of process P2 begins without delay upon the successful
termination of process P1. If process P1 terminates with a deadlock, then the execution of process P2 is
blocked.
2. Expression ϕ(P1 
 P2) means that the execution of processes P1 and P2 begins simultaneously, and
process P1 
 P2 terminates at the instant of the earliest successful termination of either P1 or P2, or at the
instant of their simultaneous termination. When one of the processes terminates with a deadlock, the
⊕
⊕
= τ
=
,
1, ,
i
i
x
i
n
ix
ix
=
(0)
,
ix
stop
+
=
=
τ
=
=
(
1)
( )
[
/
|
1, ] ,
1, ,
0,1,...,
k
k
i
j
j
i
x
x
x j
n
i
n
k
( )
k
jx
1,n
⊕
⊕
⊕
Fig. 3. Tracks of concurrent execution of conditional operator with interruptions.
1 V 2
p, f1, f2
p
p
f1, f2
f1, f2
f1, f2
f1
f1
f1
f1
f2
f2
f2
f2
Result 1
Result 1
Stop
Result 2
Result 2
f1, f2
−

JOURNAL OF COMPUTER AND SYSTEMS SCIENCES INTERNATIONAL 
 Vol. 57 
 No. 3 
 2018
MODELS AND LANGUAGES FOR DESCRIPTION OF PARALLEL PROCESSES
477
other process continues to be executed. When both the processes terminate with a deadlock, the deadlock
is returned as a result.
To implement an alternative a posteriori choice between two processes by using the operator 
 we
introduce the concept of orthogonal acts. Two acts ei and ej are called orthogonal if, in any execution of
these acts, only one of them can be terminated successfully. Orthogonal acts are denoted as follows: ei
and
. When executing a process (P1 ⋅ ei ⋅ P2 
 P3 ⋅  ⋅ P4), only one of the processes related by 
 can be
terminated successfully. In programs, the predicates p(x) and (x) can be interpreted as orthogonal acts,
assuming that the false value of either of these predicates is equivalent to a deadlock.
Note that, in [7, 8], a similar operator with the same designation was used for the composition of func-
tions, which stresses its universality.
3. Operators 〈|| and 〈||〉 have the following process interpretation: ϕ(P1 〈|| P2) means that execution of
processes P1 and P2 begins simultaneously and terminates successfully if both the processes terminate with
a success. The execution time of a process P1 〈|| P2 corresponds to the maximum completion time of either
P1 or P2. Interpretation of ϕ(P1 〈||〉 P2) differs from that of ϕ(P1 〈|| P2) in the following way: for a process
P1 〈||〉 P2 to terminate successfully, P1 and P2 should simultaneously terminate with a success. If the pro-
cesses do not terminate simultaneously, then the execution of P1 〈||〉 P2 results in a deadlock.
4. Whenever any variable act xi, i = 
 is ready for execution, it is substituted by its term, the right-hand
side of the xi’s definition in the system of equations (3.1); then, the execution of the process continues.
As an example, consider the description of a process that represents a fully concurrent evaluation of the
function
where p and  are orthogonal acts.
The process below describes the concurrent operation of a Petri net (see Fig. 4), which assumes that
all transitions in the net fire as soon as the corresponding conditions are met, i.e., the tokens appear in all
the input places of a transition:
.
Here, t5 and t6 are orthogonal acts.
3.2. Description of Interprocess Communication
There are two types of communication between two parallel processes: synchronous and asynchro-
nous. The former assumes that a process that initiates the communication interrupts its execution until the
⊕
je
⊕
ie
⊕
p
1,n
=
1
2
3
4
5
4
1
2
3
( )
( ( ),
( ))
( (
( ),
( )))
( ( ( )),
( (
( ))))
F x
if p f x
f x
then g f
f x
f x
else f F g x
g F g x
=
〈
⋅
〈
〈
⋅
⋅
⊕
〈
⋅
〈
⋅
〈
⋅
⋅
⋅
1
2
4
5
3
1
2
1
3
2
4
(((
||
)
) ||((
||
)
))
(((
||
)
) ||(((
) ||(
))
)),
F
f
f
p
f
f
f
g
f
f
p
g
F
g
F
g
f
p
=
⋅
〈
⋅
⋅
⋅
⊕
1
1
2
3
4
5
1
6
(
|| )
(
)
x
t
t
t
t
t
x
t
Fig. 4. Petri net.
t2
t3
t1
t4
t6
t5

478
JOURNAL OF COMPUTER AND SYSTEMS SCIENCES INTERNATIONAL 
 Vol. 57 
 No. 3 
 2018
KUTEPOV
other process is ready for interaction. Once communication (often implemented as a message exchange)
is complete, the processes continue their execution.
In [10–12], this communication between two processes is formally described by the special designation
of the acts of a process that are integrated as acts of pair communication. This description of interprocess
communication can be easily incorporated into the process language. Asynchronous communication is
generally implemented through a “mail box” that stores incoming messages, which can be read by a pro-
cess in due time. In this case, a problem arises of excluding access to the “mail box” when messages are
sent to and read from the box simultaneously by several processes.
The well-known semaphore technique solves the problem of mutual exclusion by introducing integer
semaphores (which take positive values) and two functions p(x) and (x).
The predicate function p(x) checks the condition x > 0 for the integer variable x; if this condition is met,
then x is decremented by one and a process is allowed to access the mail box. If x = 0, then execution of
the process is delayed until another process increments x by one using the function (x), thus conveying
that it has finished accessing the mail box.
It is assumed that only one function, p(x) or (x), can be executed over the semaphore at the same
time, and its initialization and execution should take finite time. The example below demonstrates the
description of communicating parallel processes that require mutual exclusion when accessing a shared
data buffer.
Suppose that each ith process (i = 
) successively generates a finite amount of data ni and writes them
into a buffer with a finite number of positions N, N > 0, n1 + n2 + … + nk = N, and there is a process (data
processor) that successively reads these data from the buffer for processing. Since all processes are exe-
cuted concurrently and have to work with the shared resource (data buffer), all buffer access operations
should be carried out mutually exclusively, for which purpose the semaphore technique is employed.
Introduce the following designations: buff is the data buffer of the size N (N > 0), S1 and S2 are sema-
phores whose integer values determine the number of free and occupied positions in the buffer, and S3 is a
semaphore that takes values 0 and 1 and serves for the mutual exclusion of processes that access the buffer.
The following system of equations describes an asynchronous process x1 of the concurrent data pro-
cessing that maintains the maximum parallelism of its actions:
Here, produce_data is a data preparation function, push(buff) and pull(buff) are write and read operations,
and data_operation is an operation over data. The predicate and its negation are interpreted as
orthogonal acts.
3.3. Network Representation of Processes
It should be noted that network (structural) representations of parallel programs are used both as an
effective means for designing complex objects and as a representation that significantly facilitates the
implementation of concurrent languages in computer systems [4–6].
Network representation of processes uses graphics not only to display their structure as a composite
organization but also to facilitate their execution.
Network representation is defined as follows.
1. Every act ei ∈ E has a network representation (see Fig. 5a).
v
v
v
1,k
=
〈
⋅
1
2
3
4
(
||
)
,
X
x
x
x
=
=
〈
=
〈
=
2
1
2
3
(
:
) ||(
:
0) ||(
: 1),
X
S
N
S
S
=
=
〈
=
〈
〈
=
3
1
2
(
:
0) ||(
:
0) || ... ||(
:
0),
k
X
x
x
x
=
〈
4
5
6
||
,
X
x
x
=
〈
〈
〈
(1)
(2)
( )
5
5
5
5
||
|| ... ||
,
k
X
x
x
x
=
≤
⋅
⋅
⋅
⋅
⋅
⋅
⋅
=
+
⋅
⊕
>
⋅
=
( )
5
1
3
3
2
( )
5
(
)
_
(
)
(
)
(
)
(
)
(
) (
:
1)
(
)
,
1, ,
i
i
i
i
i
i
i
i
X
x
n
produce data p S
p S
push buff
S
S
x
x
x
x
n
stop
i
k
v
v
=
⋅
⋅
⋅
⋅
⋅
⋅
6
2
3
3
1
6
(
)
(
)
(
)
_
(
)
(
)
.
X
p S
p S
pull buff
data operation
S
S
x
v
v

JOURNAL OF COMPUTER AND SYSTEMS SCIENCES INTERNATIONAL 
 Vol. 57 
 No. 3 
 2018
MODELS AND LANGUAGES FOR DESCRIPTION OF PARALLEL PROCESSES
479
2. The network of a process P1ΔP2, where Δ ∈ {
, 〈||, 〈||〉}, is represented as a composition of networks
S(P1) and S(P2) of processes P1 and P2 (see Fig. 5b). Note that, in practice, when describing interprocess
communication in a real system, it is important to have the means for the explicit specification of com-
munication channels. In [25], a language was proposed that enables this specification on a strictly formal
basis.
3. The network of a process P1 ⋅ P2 has the representation shown in Fig. 5c.
Figure 6 shows the network of the process that evaluates the function F(x) (see Subsection 3.1).
Execution of the process xi in its network representation for the system of equations xi = τi, i = 
begins with the network obtained for the term τi. In this case, for opening operators 〈||, 〈||〉, , acts on both
branches originating from them are initiated simultaneously. Once the corresponding closing operator of
either branch for 
 is reached, acts following this closing operator are initiated. For the closing operator 〈||, all
acts that belong to each branch connecting this operator with the corresponding opening operator 〈||
should terminate. Only after that, the acts following this operator are initiated. For the close operator 〈||〉,
in contrast to 〈||, all acts on all branches connecting this operator with the corresponding opening
operator 〈||〉 should terminate simultaneously. Otherwise, the closing operator 〈||〉 results in a deadlock;
i.e., actions following this operator in the network cannot be executed. Upon the initialization of the vari-
able act xi, a network is substituted for the term xi and the process represented by this network is executed.
Let us make some general notes concerning the expressive power of the graphic and text descriptions
of processes, as well as the interpretation of multiple occurrences of an act with the same name in the
description of a process. A process for the fully concurrent evaluation of a function f(x) = f5(f3(f1(x), f2(x)),
⊕
1,n
⊕
⊕
Fig. 6. Network representation of parallel process that evaluates function F(x).
f1
f2
f5
f3
g
p
f4
−
f1
f2
g3
f4
p
F
F = 
F
g2
g1
+
+
Fig. 5. Network representation of processes.
(a)
(b)
(c)
S(P1)
S(P2)
S(P2)
S(P1)
e

480
JOURNAL OF COMPUTER AND SYSTEMS SCIENCES INTERNATIONAL 
 Vol. 57 
 No. 3 
 2018
KUTEPOV
f4(f2(x))) has a text representation ((f1 〈|| f2) · f3 〈|| (f2 · f4)) · f5 in which f2 occurs twice. In its network repre-
sentation (see Fig. 7), the second occurrence of f2 can be dropped.
Thus, the execution histories of a process in these two representations are different. Moreover, if we
assume that different occurrences of an act with the same name in the description of a process can have
different execution times (which is typical for programs), then a problem arises for the unique interpreta-
tion of these different occurrences. From the perspective of a process, these occurrences should be gener-
ally regarded as different actions carried out during the execution of a process, although they are equiva-
lent in their interpretation. In addition, the same act of a process can recur due to the loops and recursions
in the description of a process, and its duration, in the general case, can depend on its next initialization.
4. PROCESS EXECUTION IN REAL TIME AND INTRODUCTION OF DELAYS OF ACTS
Suppose that a function ϕ1: E × T → T determines the duration of the acts of a process on a set of time
intervals T. Then, ϕ1(e, t) = t' determines the duration of the act e ∈ E initiated at the instant t ∈ T. Sup-
pose also that we have a function ϕ2: E × T → T, where t'' = ϕ2(e, t) determines the delay in execution of
the act e. The introduction of delays of acts extends the capabilities of the language for representing a wider
range of real discrete processes. Based on these data, using the automaton representation of process exe-
cution, we can exactly restore the tracks of a process.
In the general case, the initialization of the acts of a process depends not only on causal relationships
among the acts and their termination condition but also on the time relationships among the instants of
their termination. That is why the condition for the initialization of an act is generally given by a predicate
formula that specifies the necessary time relationships among the instants of the termination of the acts
of the process that affect the initialization of this act. For this purpose, a simple logical model can be con-
structed by defining a constructive set of numbers, e.g., a finite subset of real numbers, functions that
determine the termination instants of the acts of a process, the arithmetic operators on time variables, and
the traditional logical operators.
5. EQUIVALENCE OF PARALLEL PROCESSES
Definition 7. Two processes P1 and P2 are called equivalent if the sets of the histories of their automaton
execution coincide.
Below, we present the most important axioms of the equivalence of processes that allow us to reduce
processes to a more compact and efficient form of concurrent execution. In these axioms, A, B, and C are
arbitrary processes.
Axioms of process equivalence:
(1) (AΔB)ΔC = AΔ(BΔC) (associative property of composition operators: Δ ∈ {
, 〈||, 〈||〉});
(2) AΔB = BΔA (commutative property of composition operators Δ ∈ {
, 〈||, 〈||〉});
(3) 
;
(4) 
;
(5) 
(6) 
(7) 
(8) (A 
 B)
);
(9) (A 
 B
) the condition that, in 8 and 9, A and B are orthogonal processes.
CONCLUSIONS
As mentioned above, our approach to the model description of parallel processes is largely based on
our works on designing and implementing concurrent programming languages [7–9, 17, 18]. The graph-
⊕
⊕
∅⋅
= ∅
A
∅〈
= ∅
|| A
∅〈〉
= ∅
||
;
A
⋅
=
;
stop A
stop
〈
=
||
;
stop
A
A
⊕
⋅
=
⋅
⊕
⋅
C
A C
B C
⊕
〈
=
〈
⊕
〈
|| 
|| 
|| 
C
A C
B
C
Fig. 7. Network representation of process.
f1
f3
f2
f4
f5

JOURNAL OF COMPUTER AND SYSTEMS SCIENCES INTERNATIONAL 
 Vol. 57 
 No. 3 
 2018
MODELS AND LANGUAGES FOR DESCRIPTION OF PARALLEL PROCESSES
481
scheme and network description of the processes introduced in these works was used as an effective tool
for designing and implementing them in computer systems. Moreover, this description can be viewed as a
direct analogy between a process and a system implementing this process. Programmable logic integrated
circuits illustrate the practical application of this analogy.
Obviously, it will take time for the concurrent programming paradigm to become dominant, rather
than being regarded as a special extension of sequential programming languages. This will require devel-
oping new high-level languages and design tools for parallel programs, analyzing their complexity, and
reducing them to the optimal concurrent form [2, 5, 7, 17, 18]. Compared to the verification of sequential
programs, the problem of parallel program verification is much more complex and calls for the extension
of the classical logic, thus creating conditions for its solution [22].
The development of methods for the parallel solution of mathematical problems, the adequacy of their
description in concurrent programming languages, and their effective implementation on computer sys-
tems are equally important problems [26]. Finally, the practical implementation of parallelism is not pos-
sible without the effective means for scheduling parallel processes and allocating resources, as well as new
architectural solutions for computer systems [23, 24].
ACKNOWLEDGMENTS
This work was supported by the Russian Foundation for Basic Research, project no. 15-01-08230.
REFERENCES
1. General Theory of Systems, Collection of Articles (Mir, Moscow, 1966) [in Russian].
2. Automatic Control of Asynchronous Processes in Electronic Computing Machine and Discrete Systems, Ed. by
M. Varshavskii (Nauka, Moscow, 1986) [in Russian].
3. V. A. Gorbatov, A. V. Gorbatov, and M. V. Gorbatova, Discrete Mathematics (Astrel’, Moscow, 2003) [in Russian].
4. G. R. Andrews, Foundations of Multithreaded, Parallel, and Distributed Programming (Addison-Wesley, Reading,
MA, 2000).
5. Series of Articles on Parallel Programming, Zh. Razrab. MSDN, No. 1 (83) (2008).
6. C. Hughes and T. Hughes, Parallel and Distributed Programming Using C++ (Addison-Wesley, Reading, MA, 2003).
7. V. P. Kutepov and V. N. Fal’k, “Models of asynchronous computations of function values in a language of func-
tional schemes,” Programmirovanie, No. 3, 15–23 (1978).
8. B. P. Kutepov and P. N. Shamal’, “Implementation of functional parallel typified language (FPTL) on multi-
core computers,” J. Comput. Syst. Sci. Int. 53, 345 (2014).
9. V. P. Kutepov, V. N. Malanin, and N. A. Pankov, “Flowgraph stream parallel programming: language, process
model, and computer implementation,” J. Comput. Syst. Sci. Int. 51, 65 (2012).
10. R. A. Milner, A Calculus of Communicating Systems, Lect. Notes Comput. Sci. 92, 1 (1980).
11. C. Hoare, Communicating Sequential Processes (Prentice Hall, Englewood Cliffs, NJ, 1985).
12. J. A. Bergstra and J. W. Klop, “Process algebra for synchronous communication,” Inf. Control 60, 109–137
(1984).
13. A. M. Mironov, Theory of Proceses. http://intsys.msu.ru/staff/mironov/processes.pdf. Accessed Sept. 10, 2017.
14. J. L. Peterson, Petri Net Theory and the Modeling of Systems (Prentice Hall, Englewood Cliffs, NJ, 1981).
15. U. Goltz and W. Reisig, “The non-sequential behavior of Petri nets,” Inf. Control 57, 125–147 (1983).
16. N. Melsen and P. S. Thigarajan, “Degrees of non-determinism and concurrence: a Petri net view,” Lect. Notes
Comp. Sci. 181, 89–117 (1984).
17. B. P. Kutepov and V. N. Fal’k, “Forms, presentation languages, criteria and parameters of parallelism complex-
ity,” Program. Prod. Sist., No. 3, 16–25 (2010).
18. B. P. Kutepov, “Various sides of parallelism,” in Proceedings of the 5th International Conference on Parallel Com-
putations and Control Problems (Inst. Probl. Upr., Moscow, 2010), pp. 42–50 [in Russian].
19. J. Baeten and J. Bergstra, “Real time process algebra,” Formal Aspects Comput. 3, 142–188 (1991).
20. C. A. Middelburg, “Revisiting timing in process algebra,” J. Logic Algebraic Program. 54, 109–127 (2003).
21. I. A. Zhuklinets and D. A. Khotimskii, “Logic time in distributed program systems,” Programmirovanie, No. 6,
3–19 (2000).
22. L. Lamport, “The temporal logic of actions,” ACM Trans. Program. Lang Syst. 7 (7), 1–52 (1993).
23. V. P. Kutepov, “Intelligent scheduling processes and controlling workload in computing systems,” J. Comput.
Syst. Sci. Int. 46, 726 (2007).
24. Yu. N. Brazhnkikova, Yu. A. Goritskii, V. P. Kutepov, and N. A. Pankov, “Investigation of the load prediction
methods in computer and computer systems,” Program. Prod. Sist., No. 2, 135–136 (2015).
25. R. Milner, J. Parrow, and D. Walker, “A calculus of mobile processes. Pt. 1,” Inf. Control 100, 1–40 (1992).
26. V. V. Voevodin, World Scientific Series in Computer Science, Vol. 33: Mathematical Foundations of Parallel Com-
puting (BKhV-Peterburg, St. Petersburg, 2002; World Scientific, Singapore, 1992).
Translated by Yu. Kornienko

