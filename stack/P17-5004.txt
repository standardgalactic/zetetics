Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics-Tutorial Abstracts, pages 8–14
Vancouver, Canada, July 30 - August 4, 2017. c⃝2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-5004
Deep Learning for Dialogue Systems
Yun-Nung Chen
National Taiwan University
Taipei, Taiwan
yvchen@ieee.org
Asli Celikyilmaz
Microsoft Research
Redmond, WA
asli@ieee.org
Dilek Hakkani-T¨ur
Google Research
Mountain View, CA
dilek@ieee.org
Abstract
In the past decade, goal-oriented spo-
ken dialogue systems have been the most
prominent component in today’s virtual
personal assistants. The classic dialogue
systems have rather complex and/or mod-
ular pipelines. The advance of deep learn-
ing technologies has recently risen the ap-
plications of neural models to dialogue
modeling. However, how to successfully
apply deep learning based approaches to
a dialogue system is still challenging.
Hence, this tutorial is designed to focus on
an overview of the dialogue system devel-
opment while describing most recent re-
search for building dialogue systems and
summarizing the challenges, in order to
allow researchers to study the potential
improvements of the state-of-the-art dia-
logue systems.
The tutorial material is
available at http://deepdialogue.
miulab.tw.
1
Tutorial Overview
With the rising trend of artiﬁcial intelligence, more
and more devices have incorporated goal-oriented
spoken dialogue systems.
Among popular vir-
tual personal assistants, Microsoft’s Cortana, Ap-
ple’s Siri, Amazon Alexa, Google Assistant, and
Facebook’s M, have incorporated dialogue system
modules in various devices, which allow users to
speak naturally in order to ﬁnish tasks more efﬁ-
ciently.
The traditional conversational systems have
rather complex and/or modular pipelines. The ad-
vance of deep learning technologies has recently
risen the applications of neural models to dialogue
modeling. Nevertheless, applying deep learning
technologies for building robust and scalable di-
alogue systems is still a challenging task and an
open research area as it requires deeper under-
standing of the classic pipelines as well as detailed
knowledge on the benchmark of the models of the
prior work and the recent state-of-the-art work.
The goal of this tutorial is to provide the au-
dience with developing trend of the dialogue sys-
tems, and a roadmap to get them started with the
related work. In the ﬁrst section of the tutorial,
we motivate the work on conversation-based in-
telligent agents, in which the core underlying sys-
tem is task-oriented dialogue systems. The second
and third sections describe different approaches
using deep learning for each component in the di-
alogue system and how it is evaluated. The last
two sections focus on discussing the recent trends
and current challenges on dialogue system tech-
nology and summarize the challenges and conclu-
sions. Then the detailed content is described as
follows.
2
Outline
1. Introduction & Background [15 min.]
• Brief history of dialogue systems
• Summarized challenges of intelligent
assistants
• Task-oriented dialogue system frame-
work
• Neural network basics
• Reinforcement learning (RL) basics
2. Deep Learning Based Dialogue System [75
min.]
• Spoken/Natural language understanding
(SLU/NLU)
– Semantic frame representation
– Domain classiﬁcation
– Slot tagging
– Joint semantic frame parsing
– Contextual language understanding
8

– Structural language understanding
• Dialogue management (DM) – Dialogue
state tracking (DST)
– Neural belief tracker
– Multichannel tracker
• Dialogue management (DM) – Policy
optimization
– Dialogue RL signal
– Deep Q-network for learning policy
– Hierarchical RL for learning policy
• Natural language generation (NLG)
– Template-based NLG
– Plan-based NLG
– Class LM NLG
– Phrase-based NLG
– RNN-LM NLG
– Semantic Conditioned LSTM
– Structural NLG
– Contextual NLG
3. Evaluation [10 min.]
• Crowdsourcing
• User simulation
4. Recent Trends on Learning Dialogues [45
min.]
• End-to-end neural dialogue systems
– Chit-chat seq2seq model
– E2E joint NLU and DM
– E2E supervised dialogue system
– E2E memory network for dialogues
– E2E RL-based InfoBot
– E2E LSTM-based dialogue control
– E2E RL-based task-completion bot
• Dialogue breath
– Domain adaptation
– Intent expansion
– Policy for domain adaptation
• Dialogue depth
– High-level intent for dialogue plan-
ning
– Multimodality in dialogue systems
5. Challenges & Conclusions [5 mins]
3
Dialogue System Basics
This
section
will
motivate
the
work
on
conversation-based intelligent agents, in which
the core underlying system is task-oriented spoken
dialogue systems.
The section starts with an overview of the stan-
dard pipeline framework for dialogue system illus-
trated in Figure 1 (Tur and De Mori, 2011). Ba-
sic components of a dialog system are automatic
speech recognition (ASR), language understand-
ing (LU), dialogue management (DM), and natu-
ral language generation (NLG) (Rudnicky et al.,
1999; Zue et al., 2000; Zue and Glass, 2000).. This
tutorial will mainly focus on LU, DM, and NLG
parts.
Language Understanding
Traditionally,
do-
main identiﬁcation and intent prediction are
framed as utterance classiﬁcation problems, where
several classiﬁers such as support vector ma-
chines and maximum entropy have been em-
ployed (Haffner et al., 2003; Chelba et al., 2003;
Chen et al., 2014).
Then slot ﬁlling is framed
as a word sequence tagging task, where the IOB
(in-out-begin) format is applied for representing
slot tags, and hidden Markov models (HMM) or
conditional random ﬁelds (CRF) have been em-
ployed for slot tagging (Pieraccini et al., 1992;
Wang et al., 2005; Raymond and Riccardi, 2007).
Dialogue Management
A partially observable
Markov decision process (POMDP) has been
shown to be beneﬁcial by allowing the dialogue
manager to be optimized to plan and act under
the uncertainty created by noisy speech recogni-
tion and semantic decoding (Williams and Young,
2007; Young et al., 2013).
The POMDP pol-
icy controlling the actions taken by the system is
trained in an episodic reinforcement learning (RL)
framework whereby the agent receives a reinforce-
ment signal after each dialogue (episode) reﬂect-
ing how well it performed (Sutton and Barto,
1998). In addition, the dialogue states should be
tracked in order to measure the belief of the cur-
rent situation during the whole interaction (Young
et al., 2010; Sun et al., 2014).
Natural Language Generation
There are two
NLG approaches, one focuses on generating text
using templates or rules (linguistic) methods,
the another uses corpus-based statistical tech-
niques (Oh and Rudnicky, 2002). Oh and Rud-
nicky showed that stochastic generation beneﬁts
from two factors: 1) it takes advantage of the prac-
tical language of a domain expert instead of the
developer and 2) it restates the problem in terms
of classiﬁcation and labeling, where expertise is
not required for developing a rule-based genera-
tion system.
9

Speech 
Recognition
Language Understanding (LU)
• Domain Identification
• User Intent Detection
• Slot Filling
Dialogue Management (DM)
• Dialogue State Tracking (DST)
• Dialogue Policy Optimization
Natural Language 
Generation (NLG)
Hypothesis
are there any action 
movies to see this 
weekend
Semantic Frame
request_movie(genre=action, date=this weekend)
System Action / 
Policy
request_location
Text response
Where are you located?
Text Input
Are there any action movies to see this weekend?
Speech Signal
Backend 
Knowledge 
Providers
Figure 1: Pipeline framework of spoken dialog system.
W
ﬁnd
action
movies
this
weekend
↓
↓
↓
↓
↓
S
O
B-genre
O
B-date
I-date
I
ﬁnd movie
Figure 2: An example utterance with annotations
of semantic slots in IOB format (S) and intent (I),
B-date and I-date denote the date slot.
4
Deep Learning Based Dialogue System
With the power of deep learning, there is in-
creasing research work focusing on applying deep
learning for each component.
Language Understanding
With the advances
on deep learning, deep belief networks (DBNs)
with deep neural networks (DNNs) have been
applied
to
domain
and
intent
classiﬁcation
tasks (Sarikaya et al., 2011; Tur et al., 2012;
Sarikaya et al., 2014). Recently, Ravuri and Stol-
cke (2015) proposed an RNN architecture for in-
tent determination. For slot ﬁlling, deep learning
has been viewed as a feature generator and the
neural architecture can be merged with CRFs (Xu
and Sarikaya, 2013). Yao et al. (2013) and Mesnil
et al. (2015) later employed RNNs for sequence
labeling in order to perform slot ﬁlling.
Such
architectures have later been extended to jointly
model intent detection and slot ﬁlling in multiple
domains (Hakkani-T¨ur et al., 2016; Jaech et al.,
2016). End-to-end memory networks have been
shown to provide a good mechanism for integrat-
ing longer term knowledge context and shorter
term dialogue context into these models (Chen
et al., 2016b,c).
In addition, the importance of
the LU module is investigated in Li et al. (2017a),
where different types of errors from LU may de-
grade the whole system performance in an rein-
forcement learning setting.
Dialogue Management
The state-of-the-art di-
alog managers focus on monitoring the dialog
progress by neural dialog state tracking models.
Among the initial models are the RNN based di-
alog state tracking approaches (Henderson et al.,
2013) that has shown to outperform Bayesian net-
works (Thomson and Young, 2010).
More re-
cent work on Neural Dialog Managers that provide
conjoint representations between the utterances,
slot-value pairs as well as knowledge graph repre-
sentations (Wen et al., 2016; Mrkˇsi´c et al., 2016)
demonstrate that using neural dialog models can
overcome current obstacles of deploying dialogue
systems in larger dialog domains.
Natural
Language
Generation
The
RNN-
based models have been applied to language gen-
eration for both chit-chat and task-orientated dia-
logue systems (Vinyals and Le, 2015; Wen et al.,
2015b). The RNN-based NLG can learn from un-
aligned data by jointly optimizing sentence plan-
ning and surface realization, and language varia-
tion can be easily achieved by sampling from out-
put candidates (Wen et al., 2015a). Moreover, Wen
et al. (2015b) improved the prior work by adding
a gating mechanism for controlling the dialogue
act during generation in order to avoid semantics
repetition, showing promising results.
5
Recent Trends and Challenges on
Learning Dialogues
This part will focus on discussing the recent trends
and current challenges on dialogue system tech-
nology.
10

End-to-End Learning for Dialogue System
With the power of neural networks, there are
more and more attempts for learning dialogue sys-
tems in an end-to-end fashion.
Different learn-
ing frameworks are applied, including supervised
learning and reinforcement learning. This part will
discuss the work about end-to-end learning for di-
alogues (Dhingra et al., 2016; Wen et al., 2016;
Williams and Zweig, 2016; Zhao and Eskenazi,
2016; Li et al., 2017b).
Recent advance of deep learning has inspired
many applications of neural models to dialogue
systems. Wen et al. (2016) and Bordes and Weston
(2016) introduced a network-based end-to-end
trainable task-oriented dialogue system, which
treated dialogue system learning as the problem
of learning a mapping from dialogue histories to
system responses, and applied an encoder-decoder
model to train the whole system. However, the
system is trained in a supervised fashion, thus re-
quires a lot of training data, and may not be able
to explore the unknown space that does not exist in
the training data for an optimal and robust policy.
Zhao and Eskenazi (2016) ﬁrst presented an
end-to-end reinforcement learning (RL) approach
to dialogue state tracking and policy learning in
the DM. This approach is shown to be promis-
ing when applied to a task-oriented system, which
is to guess the famous person a user thinks of.
In the conversation, the agent asks the user a se-
ries of Yes/No questions to ﬁnd the correct an-
swer.
Dhingra et al. (2016) proposed an end-
to-end differentiable KB-Infobot to improve the
ﬂexibility of question types and robustness.
Li
et al. (2017b) further presented an end-to-end neu-
ral dialogue system for completing tasks, which
supported ﬂexible question types, allowed user-
initiated requests during conversation, and ﬁnally
achieved better robustness.
Dialogue Breath
In order to extend the cover-
age of the systems, transfer learning has been ap-
plied to different extended systems in order to
proceed to a multi-domain scenario. Chen et al.
(2016a) transfered the dialogue acts across differ-
ent domains so that the performance of the newly-
developed domain can be boosted.
Kim et al.
proposed to learn a domain-speciﬁc and domain-
independent information in order to transfer the
shared knowledge more efﬁciently and effectively.
In addition, Gaˇsi´c et al. (2015) presented the pol-
icy committee in order to boost the performance
for policy training in a new domain. All above
work extended the dialogue coverage using differ-
ent directions.
Dialogue Depth
Most current systems focus on
knowledge-based understanding, but there are hi-
erarchical understanding according to the dialogue
complexity. For example, an intent about party
scheduling may include restaurant reserving and
invitation sending. Sun et al. (2016) learned the
high-level intentions that span on multiple do-
mains in order to achieve common sense under-
standing.
Moreover, a more complex dialogue
such as “I feel sad...” requires empathy in order to
generate the suitable response. Fung et al. (2016)
ﬁrst attempted to leverage different modalities for
emotion detection and built an emotion-aware di-
alogue system.
Given two branches of development, the ulti-
mate goal is to build an open-domain dialogue
system (coverage) with all levels of understanding
(depth).
6
Instructors
Yun-Nung (Vivian) Chen
is currently an assis-
tant professor at the Department of Computer Sci-
ence, National Taiwan University.
She earned
her Ph.D. degree from Carnegie Mellon Univer-
sity, where her research interests focus on spo-
ken dialogue system, language understanding, nat-
ural language processing, and multi-modal speech
applications.
She received the Google Faculty
Research Awards 2016, two Student Best Paper
Awards from IEEE SLT 2010 and IEEE ASRU
2013, a Student Best Paper Nominee from Inter-
speech 2012, and the Distinguished Master The-
sis Award from ACLCLP. Before joining National
Taiwan University, she worked in the Deep Learn-
ing Technology Center at Microsoft Research
Redmond.
More information about her can be
found at http://vivianchen.idv.tw.
Asli Celikyilmaz
is currently a researcher at the
Deep Learning Technology Center at Microsfot
Research. Previously, she was a Research Scien-
tist at Microsoft Bing from 2010 until 2016 fo-
cusing on deep learning models for scaling nat-
ural user interfaces to multiple domains.
She
has worked as a Postdoc Researcher at the EECS
Department of the UC Berkeley from 2008 until
2010. She has worked with researchers at ICSI @
Berkeley during her postdoc research study. She
11

has earned her Ph.D. from University of Toronto,
Canada in 2008.
Asli’s research interests are
mainly machine learning and its applications to
conversational dialogue systems, mainly natural
language understanding and dialogue modeling.
In the past she has also focused on research ar-
eas including machine intelligence, semantic tag-
ging of natural user utterances of human to ma-
chine conversations, text analysis, document sum-
marization, question answering, co-reference res-
olution, to name a few. Currently she is focus-
ing on reasoning, attention, memory networks as
well as multi-task and transfer learning for conver-
sational dialogue systems. She has been serving
as area chair, co-organizer of numerous NLP and
speech conferences, such as ACL, NAACL, Inter-
speech, and IEEE Spoken Language Technologies
(SLT). She co-organized a NIPS workshop on Ma-
chine Learning for Spoken Language Understand-
ing and Interactions in 2015.
Dilek Hakkani-T¨ur
is a research scientist at
Google Research. Prior to joining Google, she was
a researcher at Microsoft Research (2010-2016),
International Computer Science Institute (ICSI,
2006-2010) and AT&T Labs-Research (2001-
2005). She received her BSc degree from Mid-
dle East Technical Univ, in 1994, and MSc and
PhD degrees from Bilkent Univ., Department of
Computer Engineering, in 1996 and 2000, respec-
tively. Her research interests include natural lan-
guage and speech processing, spoken dialogue
systems, and machine learning for language pro-
cessing. She has over 50 patents that were granted
and co-authored more than 200 papers in natural
language and speech processing. She is the recipi-
ent of three best paper awards for her work on ac-
tive learning for dialogue systems, from IEEE Sig-
nal Processing Society, ISCA and EURASIP. She
was an associate editor of IEEE Transactions on
Audio, Speech and Language Processing (2005-
2008), member of the IEEE Speech and Lan-
guage Technical Committee (2009-2014), area ed-
itor for speech and language processing for Else-
vier’s Digital Signal Processing Journal and IEEE
Signal Processing Letters (2011-2013), and cur-
rently serves on ISCA Advisory Council (2015-
2018). She is a fellow of IEEE and ISCA.
References
Antoine Bordes and Jason Weston. 2016.
Learn-
ing end-to-end goal-oriented dialog. arXiv preprint
arXiv:1605.07683 .
Ciprian Chelba, Monika Mahajan, and Alex Acero.
2003. Speech utterance classiﬁcation. In 2003 IEEE
International Conference on Acoustics, Speech, and
Signal Processing, 2003. Proceedings.(ICASSP).
IEEE, volume 1, pages I–280.
Yun-Nung Chen, Dilek Hakkani-T, Xiaodong He, et al.
2016a. Zero-shot learning of intent embeddings for
expansion by convolutional deep structured seman-
tic models.
In 2016 IEEE International Confer-
ence on Acoustics, Speech and Signal Processing
(ICASSP). IEEE, pages 6045–6049.
Yun-Nung Chen, Dilek Hakkani-Tur, and Gokan Tur.
2014.
Deriving local relational surface forms
from dependency-based entity embeddings for un-
supervised spoken language understanding.
In
2014 IEEE Spoken Language Technology Workshop
(SLT). IEEE, pages 242–247.
Yun-Nung Chen, Dilek Hakkani-Tur, Gokhan Tur,
Asli Celikyilmaz, Jianfeng Gao, and Li Deng.
2016b.
Knowledge as a teacher:
Knowledge-
guided structural attention networks. arXiv preprint
arXiv:1609.03286 .
Yun-Nung Chen, Dilek Hakkani-T¨ur, Gokhan Tur,
Jianfeng Gao, and Li Deng. 2016c.
End-to-end
memory networks with knowledge carryover for
multi-turn spoken language understanding. In Pro-
ceedings of the Interspeech.
Bhuwan Dhingra, Lihong Li, Xiujun Li, Jianfeng
Gao, Yun-Nung Chen, Faisal Ahmed, and Li Deng.
2016.
End-to-end reinforcement learning of dia-
logue agents for information access. arXiv preprint
arXiv:1609.00777 .
Pascale Fung, Dario Bertero, Yan Wan, Anik Dey,
Ricky Ho Yin Chan, Farhad Bin Siddique, Yang
Yang, Chien-Sheng Wu, and Ruixi Lin. 2016. To-
wards empathetic human-robot interactions. arXiv
preprint arXiv:1605.04072 .
M Gaˇsi´c, N Mrkˇsi´c, Pei-hao Su, David Vandyke,
Tsung-Hsien Wen, and Steve Young. 2015. Policy
committee for adaptation in multi-domain spoken
dialogue systems. In Automatic Speech Recognition
and Understanding (ASRU), 2015 IEEE Workshop
on. IEEE, pages 806–812.
Patrick Haffner, Gokhan Tur, and Jerry H Wright.
2003.
Optimizing svms for complex call classi-
ﬁcation.
In 2003 IEEE International Conference
on Acoustics, Speech, and Signal Processing, 2003.
Proceedings.(ICASSP). IEEE, volume 1, pages I–
632.
12

Dilek Hakkani-T¨ur, Gokhan Tur, Asli Celikyilmaz,
Yun-Nung Chen, Jianfeng Gao, Li Deng, and Ye-
Yi Wang. 2016. Multi-domain joint semantic frame
parsing using bi-directional RNN-LSTM. In Pro-
ceedings of the Interspeech. San Francisco, CA.
Matthew Henderson, Blaise Thomson, and Steve
Young. 2013. Deep neural network approach for the
dialog state tracking challenge. In Proceedings of
the SIGDIAL 2013 Conference. pages 467–471.
A. Jaech, L. Heck, and M. Ostendorf. 2016. Domain
adaptation of recurrent neural networks for natural
language understanding. In Proceedings of the In-
terspeech. San Francisco, CA.
Young-Bum Kim, WA Redmond, Karl Stratos, and
Ruhi Sarikaya. ????
Frustratingly easy neural do-
main adaptation.
Xiujun Li, Yun-Nung Chen, Lihong Li, Jianfeng Gao,
and Asli Celikyilmaz. 2017a.
Investigation of
language understanding impact for reinforcement
learning based dialogue systems.
arXiv preprint
arXiv:1703.07055 .
Xuijun Li, Yun-Nung Chen, Lihong Li, and Jianfeng
Gao. 2017b. End-to-end task-completion neural di-
alogue systems. arXiv preprint arXiv:1703.01008 .
Gr´egoire Mesnil,
Yann Dauphin,
Kaisheng Yao,
Yoshua Bengio, Li Deng, Dilek Hakkani-Tur, Xi-
aodong He, Larry Heck, Gokhan Tur, Dong Yu, et al.
2015. Using recurrent neural networks for slot ﬁll-
ing in spoken language understanding. IEEE/ACM
Transactions on Audio, Speech, and Language Pro-
cessing 23(3):530–539.
Nikola Mrkˇsi´c, Diarmuid ´O S´eaghdha, Tsung-Hsien
Wen, Blaise Thomson, and Steve Young. 2016.
Neural belief tracker: Data-driven dialogue state
tracking. arXiv preprint arXiv:1606.03777 .
Alice H Oh and Alexander I Rudnicky. 2002. Stochas-
tic natural language generation for spoken dialog
systems. Computer Speech & Language 16(3):387–
407.
Roberto Pieraccini, Evelyne Tzoukermann, Zakhar
Gorelov, Jean-Luc Gauvain, Esther Levin, Chin-Hui
Lee, and Jay G Wilpon. 1992. A speech understand-
ing system based on statistical representation of se-
mantics. In 1992 IEEE International Conference on
Acoustics, Speech, and Signal Processing (ICASSP).
IEEE, volume 1, pages 193–196.
Suman Ravuri and Andreas Stolcke. 2015. Recurrent
neural network and lstm models for lexical utterance
classiﬁcation. In Sixteenth Annual Conference of the
International Speech Communication Association.
Christian Raymond and Giuseppe Riccardi. 2007.
Generative and discriminative algorithms for spoken
language understanding. In INTERSPEECH. pages
1605–1608.
Alexander I Rudnicky, Eric H Thayer, Paul C Constan-
tinides, Chris Tchou, R Shern, Kevin A Lenzo, Wei
Xu, and Alice Oh. 1999. Creating natural dialogs in
the carnegie mellon communicator system. In Eu-
rospeech.
Ruhi Sarikaya, Geoffrey E Hinton, and Anoop Deo-
ras. 2014. Application of deep belief networks for
natural language understanding. IEEE/ACM Trans-
actions on Audio, Speech, and Language Processing
22(4):778–784.
Ruhi Sarikaya, Geoffrey E Hinton, and Bhuvana Ram-
abhadran. 2011.
Deep belief nets for natural lan-
guage call-routing.
In 2011 IEEE International
Conference on Acoustics, Speech and Signal Pro-
cessing (ICASSP). IEEE, pages 5680–5683.
Kai Sun, Lu Chen, Su Zhu, and Kai Yu. 2014. A gener-
alized rule based tracker for dialogue state tracking.
In Spoken Language Technology Workshop (SLT),
2014 IEEE. IEEE, pages 330–335.
Ming Sun, Yun-Nung Chen, and Alexander I Rudnicky.
2016.
An intelligent assistant for high-level task
understanding.
In Proceedings of the 21st Inter-
national Conference on Intelligent User Interfaces.
ACM, pages 169–174.
Richard S Sutton and Andrew G Barto. 1998.
Re-
inforcement learning: An introduction, volume 1.
MIT press Cambridge.
Blaise Thomson and Steve Young. 2010. Bayesian up-
date of dialogue state: A pomdp framework for spo-
ken dialogue systems. Computer Speech and Lan-
guage 24(4):562–588.
Gokhan Tur and Renato De Mori. 2011. Spoken lan-
guage understanding: Systems for extracting seman-
tic information from speech. John Wiley & Sons.
Gokhan Tur, Li Deng, Dilek Hakkani-T¨ur, and Xi-
aodong He. 2012. Towards deeper understanding:
Deep convex networks for semantic utterance classi-
ﬁcation. In 2012 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP).
IEEE, pages 5045–5048.
Oriol Vinyals and Quoc Le. 2015. A neural conversa-
tional model. arXiv preprint arXiv:1506.05869 .
Ye-Yi Wang, Li Deng, and Alex Acero. 2005. Spo-
ken language understanding. IEEE Signal Process-
ing Magazine 22(5):16–31.
Tsung-Hsien Wen, Milica Gaˇsic, Dongho Kim, Nikola
Mrkˇsic, Pei-Hao Su, David Vandyke, and Steve
Young. 2015a. Stochastic language generation in di-
alogue using recurrent neural networks with convo-
lutional sentence reranking. In 16th Annual Meeting
of the Special Interest Group on Discourse and Dia-
logue. page 275.
13

Tsung-Hsien Wen,
Milica Gasic,
Nikola Mrksic,
Lina M Rojas-Barahona, Pei-Hao Su, Stefan Ultes,
David Vandyke, and Steve Young. 2016. A network-
based end-to-end trainable task-oriented dialogue
system. arXiv preprint arXiv:1604.04562 .
Tsung-Hsien Wen, Milica Gasic, Nikola Mrksic, Pei-
Hao Su, David Vandyke, and Steve Young. 2015b.
Semantically conditioned lstm-based natural lan-
guage generation for spoken dialogue systems.
arXiv preprint arXiv:1508.01745 .
Jason D Williams and Steve Young. 2007.
Partially
observable markov decision processes for spoken
dialog systems.
Computer Speech & Language
21(2):393–422.
Jason D Williams and Geoffrey Zweig. 2016.
End-
to-end lstm-based dialog control optimized with su-
pervised and reinforcement learning. arXiv preprint
arXiv:1606.01269 .
Puyang Xu and Ruhi Sarikaya. 2013. Convolutional
neural network based triangular CRF for joint intent
detection and slot ﬁlling. In 2013 IEEE Workshop
on Automatic Speech Recognition and Understand-
ing (ASRU). IEEE, pages 78–83.
Kaisheng Yao, Geoffrey Zweig, Mei-Yuh Hwang,
Yangyang Shi, and Dong Yu. 2013. Recurrent neu-
ral networks for language understanding. In INTER-
SPEECH. pages 2524–2528.
Steve Young, Milica Gaˇsi´c, Simon Keizer, Franc¸ois
Mairesse, Jost Schatzmann, Blaise Thomson, and
Kai Yu. 2010. The hidden information state model:
A practical framework for pomdp-based spoken dia-
logue management. Computer Speech & Language
24(2):150–174.
Steve Young, Milica Gaˇsi´c, Blaise Thomson, and Ja-
son D Williams. 2013.
POMDP-based statistical
spoken dialog systems: A review. Proceedings of
the IEEE 101(5):1160–1179.
Tiancheng Zhao and Maxine Eskenazi. 2016.
To-
wards end-to-end learning for dialog state tracking
and management using deep reinforcement learning.
arXiv preprint arXiv:1606.02560 .
Victor Zue, Stephanie Seneff, James R Glass, Joseph
Polifroni, Christine Pao, Timothy J Hazen, and
Lee Hetherington. 2000.
JUPITER: a telephone-
based conversational interface for weather informa-
tion. IEEE Transactions on speech and audio pro-
cessing 8(1):85–96.
Victor W Zue and James R Glass. 2000.
Conversa-
tional interfaces: Advances and challenges.
Pro-
ceedings of the IEEE 88(8):1166–1180.
14

