Quantum Machine Learning
using the ZXW-Calculus
Mark Koch
Lady Margaret Hall
University of Oxford
A thesis submitted for the degree of
Master of Science in Advanced Computer Science
Trinity 2022

Word count:
15, 793
Diagram count:
806
The word count was calculated using texcount via perl texcount.pl
-1 thesis.tex. Note that in diagram equations, each step is counted
as a separate diagram.

Abstract
The field of quantum machine learning (QML) explores how quantum computers can
be used to more efficiently solve machine learning problems. As an application of
hybrid quantum-classical algorithms, it promises a potential quantum advantages in
the near term. In this thesis, we use the ZXW-calculus to diagrammatically analyse
two key problems that QML applications face.
First, we discuss algorithms to compute gradients on quantum hardware that are
needed to perform gradient-based optimisation for QML. Concretely, we give new
diagrammatic proofs of the common 2- and 4-term parameter shift rules used in the
literature. Additionally, we derive a novel, generalised parameter shift rule with 2n
terms that is applicable to gates that can be represented with n parametrised spiders
in the ZXW-calculus. Furthermore, to the best of our knowledge, we give the first
proof of a conjecture by Anselmetti et al. by proving a no-go theorem ruling out
more efficient alternatives to the 4-term shift rule.
Secondly, we analyse the gradient landscape of quantum ans¨atze for barren plateaus
using both empirical and analytical techniques. Concretely, we develop a tool that
automatically calculates the variance of gradients and use it to detect likely barren
plateaus in commonly used quantum ans¨atze. Furthermore, we formally prove the
existence or absence of barren plateaus for a selection of ans¨atze using diagrammatic
techniques from the ZXW-calculus.

Acknowledgements
First and foremost, I would like to thank my advisors Quanlong Wang and Richie
Yeung for their invaluable support and guidance throughout the writing of this
thesis. I am very grateful for their advice and many helpful discussions and ideas.
I would also like to thank Aleks Kissinger, as well as John van de Wetering and
Stephano Gogioso for sparking my interest in quantum computing and the ZX-
calculus through their lectures. In particular, I am thankful for the opportunity to
write this thesis under Aleks’ supervision.
Furthermore, I am very grateful to my family and friends both in Germany and
Oxford, who supported me throughout my studies.
Together with the academic
community at my wonderful college Lady Margaret Hall, they provided a great
intellectual atmosphere that made the past year a truly unique experience. In par-
ticular, I would like to thank Nikhil Khatri for many inspiring discussions and for
proofreading this thesis.
Finally, I would like to thank the German Academic Exchange Service (DAAD) for
financially supporting me during this year at Oxford.

Contents
Abstract
iii
Acknowledgements
iv
1
Introduction
1
1.1
Main Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.2
Structure of this Thesis
. . . . . . . . . . . . . . . . . . . . . . . . .
4
2
Background
5
2.1
An Introduction to Quantum Theory . . . . . . . . . . . . . . . . . .
5
2.1.1
States . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
2.1.2
Unitary Evolution
. . . . . . . . . . . . . . . . . . . . . . . .
7
2.1.3
Measurements
. . . . . . . . . . . . . . . . . . . . . . . . . .
8
2.1.4
The Quantum Circuit Model
. . . . . . . . . . . . . . . . . .
10
2.2
Quantum Machine Learning . . . . . . . . . . . . . . . . . . . . . . .
11
2.2.1
Types of Ans¨atze . . . . . . . . . . . . . . . . . . . . . . . . .
12
2.2.2
Gradient-Based Optimisation . . . . . . . . . . . . . . . . . .
13
2.3
The ZXW-Calculus . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14
2.3.1
Generators and String Diagrams . . . . . . . . . . . . . . . .
15
2.3.2
Additional Notation . . . . . . . . . . . . . . . . . . . . . . .
16
2.3.3
Rules
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17

vi
Contents
2.3.4
Quantum Gates and Computation in ZXW . . . . . . . . . .
18
2.3.5
Pauli Boxes . . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
2.3.6
Useful Lemmas . . . . . . . . . . . . . . . . . . . . . . . . . .
22
3
Diagrammatic Differentiation
28
3.1
Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28
3.2
Differentiating Quantum Circuits . . . . . . . . . . . . . . . . . . . .
32
3.3
Properties of the Differentiation Gadget . . . . . . . . . . . . . . . .
36
4
Gradient Recipes
43
4.1
Parametrised Unitaries as ZX Diagrams . . . . . . . . . . . . . . . .
44
4.1.1
Diagonalising Parametrised Unitaries . . . . . . . . . . . . . .
45
4.1.2
General Construction
. . . . . . . . . . . . . . . . . . . . . .
46
4.1.3
Special Case for Two Eigenvalues . . . . . . . . . . . . . . . .
49
4.2
Parameter-Shift Rules . . . . . . . . . . . . . . . . . . . . . . . . . .
51
4.2.1
Two-Term Shift Rule . . . . . . . . . . . . . . . . . . . . . . .
51
4.2.2
Shift Rules Beyond Two Terms . . . . . . . . . . . . . . . . .
53
4.2.3
Proof of Anselmetti’s No-Go Conjecture . . . . . . . . . . . .
59
4.3
Ancilla Recipes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
63
5
Barren Plateaus
66
5.1
Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
67
5.2
Studied Ans¨atze
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
70
5.3
Numerical Barren Plateau Detection . . . . . . . . . . . . . . . . . .
72
5.3.1
Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
72
5.3.2
Note on Zero Variance . . . . . . . . . . . . . . . . . . . . . .
73
5.3.3
Results
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
74
5.4
Analytical Barren Plateau Detection . . . . . . . . . . . . . . . . . .
79
5.4.1
Introductory Example . . . . . . . . . . . . . . . . . . . . . .
80
5.4.2
Sim 1
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
82

Contents
vii
5.4.3
Sim 2
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
86
5.4.4
Sim 9
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
87
5.4.5
Single-Layer IQP Ans¨atze . . . . . . . . . . . . . . . . . . . .
89
5.4.6
Dealing with multiple parameter occurrences
. . . . . . . . .
96
5.4.7
Commuting Multi-Layer IQP Ans¨atze . . . . . . . . . . . . .
98
5.4.8
Non-Commuting Multi-Layer IQP Ans¨atze
. . . . . . . . . .
100
5.5
Barren Plateau Mitigation Techniques . . . . . . . . . . . . . . . . .
107
6
Discussion
108
6.1
Summary of Results
. . . . . . . . . . . . . . . . . . . . . . . . . . .
108
6.2
Discussion and Future Work . . . . . . . . . . . . . . . . . . . . . . .
109
A Constructing the Ancilla State
113
B Details on Recursive Contraction
115
B.1
Deriving the Recurrence Relation . . . . . . . . . . . . . . . . . . . .
115
B.2
Solving the Recurrence Relation
. . . . . . . . . . . . . . . . . . . .
119
C Additional Lemmas and Proofs
122
Bibliography
134

Chapter 1
Introduction
It is widely believed that quantum computers are capable of solving certain compu-
tational problems that are intractable for classical computers. While this potential
quantum advantage was already recognised in the 1980s, the quantum devices avail-
able today still lack the scale and reliability to tackle many practical problems, with
anticipated algorithms like Grover’s search [1] or Shor’s factorisation algorithm [2]
remaining out of reach. Because of those limitations, there is increasing interest
in hybrid quantum-classical algorithms. The rationale behind hybrid approaches is
that the required quantum resources can be significantly reduced by implementing
some subroutines on classical hardware. As a result, those algorithms are runnable
on the noisy intermediate-scale quantum (NISQ) devices available today.
One area where hybrid algorithms promise a quantum advantage is the field of
machine learning (ML). Roughly, ML is concerned with recognising and generalising
patterns in statistical data. It has been shown that even relatively small quantum
circuits can represent functions that are highly complex and difficult to express
via classical means [3]. Hence, the hope is that quantum computers can capture
certain data patterns more efficiently than classical computers, yielding a quantum
advantage in ML. This field of study is commonly referred to as quantum machine
learning (QML) [4].

2
Introduction
Typically, hybrid QML algorithms rely on parametrised quantum circuits, i.e. cir-
cuits that depend on some tunable parameters. An optimisation algorithm running
on a classical computer is used to find a parameter assignment such that the out-
put of the quantum circuit minimises some cost function. For example, circuits can
be trained to solve ML tasks like classification, regression, or generative modelling.
There are many classical optimisation techniques that can be used to train quantum
circuits. In the field of QML, one commonly uses gradient-based techniques like
gradient descent, which have already been very successfully used in classical ML,
especially for the training of neural networks. Notably, gradient-based methods have
also been proven to improve convergence in the quantum domain [5]. However, com-
pared to classical neural networks, training quantum circuits using gradient descent
comes with a set of unique challenges.
First, one has to determine the gradient of parametrised circuits, i.e. compute how
the output of a circuit changes when the parameters are altered. As it turns out,
it is not feasible to perform this computation classically. Instead, gradients need
to be evaluated on the quantum device itself. The quantum algorithms used for
those gradient computations are called gradient recipes and are subject to a lot of
research interest [6, 7, 8, 9]. Secondly, it has been shown that the gradient landscape
of many quantum circuits is not amenable to learning. Concretely, the landscape
is often exponentially flat [10], making gradient descent difficult or even impossible.
Naturally, there is a lot of interest in determining which circuits exhibit those so-
called barren plateaus [11, 12, 13].
This thesis is concerned with analysing both of these problems using diagrammatic
means.
The ZX-calculus [14] is a graphical language for reasoning about quan-
tum computation that has been successfully applied to a wide range of tasks in the
quantum domain, including circuit optimisation [15], compilation [16], and simula-
tion [17]. The ZXW-calculus [18] is a variant of ZX that has recently been used
to diagrammatically represent gradients and integrals [19]. Thus, it is particularly
well-suited for our diagrammatic analysis of gradient based optimisation for QML.

1.1.
Main Contributions
3
1.1
Main Contributions
Below are the main contributions of this thesis with regard to gradient recipes:
• We derive a simplified version of Wang and Yeung’s diagrammatic differenti-
ation [19] for the special case of parametrised circuits (Theorem 3.6).
• We give a diagrammatic proof of the most general version of Schuld et al.’s [7]
two-term parameter shift rule (Theorem 4.8) and Anselmetti et al.’s [8] four-
term shift rule (Theorem 4.11).
• We derive a novel generalised 2n-term shift rule for gates that can be repre-
sented with n parametrised spiders (Theorem 4.13)
• To the best of our knowledge, we give the first proof of a conjecture by Ansel-
metti et al. [8] showing that their shift rule is optimal. Concretely, we prove
a no-go theorem ruling out shift rules with less than four terms for all gates
whose Hermitian generators have eigenvalues of shape −λ, 0, λ (Theorem 4.16).
On the topic of barren plateaus we make the following contributions:
• We develop a tool that automatically computes Var

∂⟨H⟩
∂θi

and use it to em-
pirically show that barren plateaus likely appear in 7 ans¨atze studied by Sim
et al. [20] when measuring in the computational basis (Figures 5.3 and 5.4).
• We formally prove the existence of barren plateaus in three of the Sim ans¨atze
and give necessary conditions on the measurement Hamiltonian for when they
occur (Theorems 5.11, 5.12, and 5.14).
• We give a general framework for the barren plateau analysis of IQP circuits
(Theorem 5.16) and use it to prove that the main circuit used by the quan-
tum natural language processing library lambeq [21] has barren plateaus when
measuring in the computational basis (Theorem 5.19).

4
Introduction
1.2
Structure of this Thesis
We begin by discussing some of the background necessary to follow this thesis in
Chapter 2 and introduce diagrammatic differentiation in Chapter 3. Chapter 4 is
concerned with deriving gradient recipes using this diagrammatic technique. Sub-
sequently, we study the gradient landscape of parametrised circuit with regard to
barren plateaus in Chapter 5. Finally, we discuss our results and comment on future
work in Chapter 6.
For presentation purposes, we move some of the proofs throughout the thesis to the
appendix. This is remarked on underneath each such lemma. In the PDF version of
this thesis one can easily jump to the corresponding proof by clicking on the arrow
symbol (↓) on the right-hand side of the page.
The code to reproduce all numerical results and graphs in this thesis is available at
https://github.com/mark-koch/msc-code

Chapter 2
Background
In this chapter we give the necessary background to follow the thesis. Concretely,
we give a brief introduction to quantum theory in Section 2.1 and discuss quan-
tum machine learning in Section 2.2. Finally, we introduce the ZXW-calculus in
Section 2.3.
2.1
An Introduction to Quantum Theory
2.1.1
States
The states of quantum systems are given by normalised vectors in a complex Hilbert
space H. We exclusively work within H = C2n for this thesis, where states are given
by column vectors of complex numbers. The adjoint ψ† of a state ψ in this case is
given by the conjugate-transpose of ψ. States and their adjoints are usually written
in the Dirac bra-ket notation:
ψ
⇝
|ψ⟩
ψ†
⇝
⟨ψ|
The symbol |ψ⟩is called ket and ⟨ψ| is called bra. Plugging a bra into a ket yields
the inner product of the two vectors which we denote by ⟨ψ|ϕ⟩:= ⟨ψ||ϕ⟩and call

6
Background
z
β
α
y
x
|0⟩
|1⟩
|+⟩
|ψ⟩
Figure 2.1: Visualisation of a qubit state |ψ⟩= x|0⟩+ y|1⟩as a point on the Bloch
sphere. We have x = cos( α
2 ) and y = eiβ sin(α
2 ).
bra-ket. The most elementary state is given by a single quantum bit, or qubit, which
belongs to the two-dimensional Hilbert space C2 spanned by the standard basis
|0⟩:=
1
0

|1⟩:=
0
1

.
The states |0⟩and |1⟩are the quantum analogues of classical bits. Therefore, the
basis {|0⟩, |1⟩} is usually called computational basis. However, unlike classical bits,
qubits can represent any linear combination of |0⟩and |1⟩:
|ψ⟩= x|0⟩+ y|1⟩
for some x, y ∈C with |x|2 + |y|2 = 1. We can picture the state |ψ⟩as a point
on the so-called Bloch sphere as illustrated in Figure 2.1. We refer to those states
“in-between” 0 and 1 as superpositions.
In order to unleash the full power of quantum computation, we describe interactions
between multiple systems using the tensor product operation ⊗corresponding to the
Kronecker product. For example, the two-qubit system C2 ⊗C2 = C4 is spanned by
the basis
|00⟩:= |0⟩⊗|0⟩= (1, 0, 0, 0)T
|10⟩:= |0⟩⊗|1⟩= (0, 1, 0, 0)T
|01⟩:= |1⟩⊗|0⟩= (0, 0, 1, 0)T
|11⟩:= |1⟩⊗|1⟩= (0, 0, 0, 1)T

2.1.
An Introduction to Quantum Theory
7
where |ψ⟩⊗|ϕ⟩is the product state of |ψ⟩and |ϕ⟩. We sometimes also write the
computational basis vectors for C2n as |j⟩for j = 0, 1, ..., 2n −1.
2.1.2
Unitary Evolution
Definition 2.1. A square matrix U is unitary if UU† = U†U = I.
Computation on a quantum state |ψ⟩∈C2n is done using unitary evolutions, i.e.
acting on |ψ⟩according to a unitary matrix U ∈C2n×2n. The resulting state is given
by |ψ′⟩= U|ψ⟩. An example of a single-qubit action is the Hadamard operation
H =
1
√
2
1
1
1
−1

(2.1)
that maps the computational basis to the so-called X-basis {|+⟩, |−⟩}:
H|0⟩= |+⟩:= |0⟩+ |1⟩
√
2
H|1⟩= |−⟩:= |0⟩−|1⟩
√
2
Another example is the single-qubit RZ(α) operation that corresponds to a Z-
rotation on the Bloch sphere by an angle of α:
RZ(α) :=
e−i α
2
0
0
ei α
2

(2.2)
RZ(α) is an example of a parametrised unitary:
Definition 2.2. A (strongly continuous) one-parameter unitary group is a fam-
ily {U(α)}α∈R of single-parameter unitary matrices that are strongly continuous
( lim
α→α0 U(α) = U(α0) for all α0 ∈R) and homomorphisms (U(α + β) = U(α) U(β)).
When speaking of (single-)parametrised unitaries, we generally refer to one-parameter
unitary groups.
Definition 2.3. A matrix H is self-adjoint, or Hermitian, if H† = H.
Remarkably, there is a one-to-one correspondence between single-parameter uni-
taries and Hermitian operators:

8
Background
Theorem 2.4 (Stone [22]). Every strongly continuous one-parameter unitary
group {U(α)}α∈R is generated by a Hermitian operator H via U(α) = eiαH.
The matrix exponentials eA for square matrices A used in this theorem are defined
by eiA := P∞
k=0
Ak
k! and satisfy
ediag(a1,...,an) = diag(ea1, ..., ean)
eU†AU = U†eAU†
(2.3)
for all unitaries U.
2.1.3
Measurements
In order to extract information from quantum systems, we need to perform mea-
surements. Importantly, measuring a system usually also alters its state, making
measurement a somewhat destructive process. Note that there are many different
kinds of measurements one can perform. Mathematically, a measurement is specified
by a set M = {P1, ..., Pk} of projectors that sum up to the identity P
i Pi = I.
Definition 2.5. A square matrix P is a projector if P = P † = P 2.
Each projector represents a measurement outcome. Since measurement is a non-
deterministic process, we get a probability distribution over the outcomes. When
measuring |ψ⟩, the probability of outcome Pi can be computed using the Born rule:
Prob(i|ψ) = ⟨ψ|Pi|ψ⟩
(2.4)
Example 2.6 (ONB Measurements). The orthonormal basis measurement cor-
responding to a basis B = {|ϕi⟩}i is given by MB = {|ϕi⟩⟨ϕi|}i. For example, the
two-dimensional computational basis yields M = {|0⟩⟨0|, |1⟩⟨1|}. In that case, we
have Prob(i|ψ) = ⟨ψ|i⟩⟨i|ψ⟩. We can think of this as a measure of how “close” |ψ⟩is
to |0⟩or |1⟩: If |ψ⟩= x|0⟩+y|1⟩then Prob(0|ψ) = (x⟨0|0⟩+y⟨1|0⟩)(x⟨0|0⟩+y⟨0|1⟩) =
xx = |x|2.

2.1.
An Introduction to Quantum Theory
9
An important observation is that states that are equal up to a global phase of eiα
behave exactly the same with regard to measurement: Let |ϕ⟩:= eiα|ψ⟩, then
Prob(j|ϕ) = ⟨eiαψ|Pj|eiαψ⟩= eiα⟨ψ|Pje−iα|ψ⟩= ⟨ψ|Pj|ψ⟩= Prob(j|ψ).
Thus, there is no measurable difference between |ϕ⟩and |ψ⟩. Hence, states are not
just vectors, but equivalence classes of vectors that are equal up to a global phase.
One way to remove this redundancy is the doubling construction where we represent
the states as |ϕ⟩⟨ϕ| and |ψ⟩⟨ψ| instead, which are actually equal. We will make
heavy use of this when describing gradients of parametrised quantum circuits later.
Performing a single measurement corresponds to sampling from the distribution
(2.4). However, often we are not necessarily interested in a single sample, but want
to understand the broader distribution of outcomes. A useful tool for this is the
expectation value. To motivate its definition, suppose we associate a real number xj
with each projector Pj. Then, we define random variable X that takes the value xj
whenever we get the measurement outcome j. The expectation value of our state
|ψ⟩w.r.t. this operator then corresponds to the mean value of X:
E(X) =
k
X
j=1
xj · Prob(j|ψ)
(2.4)
=
k
X
j=1
xj · ⟨ψ|Pj|ψ⟩= ⟨ψ|


k
X
j=1
xjPj

|ψ⟩
In order to estimate the expectation value on a quantum computer, one can compute
the statistical mean of X by preparing and measuring the state |ψ⟩for a large number
of executions. One commonly refers to the different executions as shots.
Interestingly, Pk
j=1 xjPj is self-adjoint. Conversely, every self-adjoint matrix H with
eigenvectors λ1, ..., λk gives rise to a unique set of projectors MH =
nP
ϕ∈Φi |ϕ⟩⟨ϕ|
ok
i=1
where Φi is the set of eigenvectors of H corresponding to the eigenvalue λi. Because
of this duality, it is often more convenient to describe measurements via Hermitian
operators instead of projectors. In this context, H is commonly referred to as an
observable, or Hamiltonian and the expectation value is denoted by

10
Background
⟨H⟩:= ⟨ψ|H|ψ⟩.
Interestingly, every Hermitian matrix H ∈C2n can be written as a real combination
of Pauli operators P ∈{X, Y, Z, I}⊗n. We will use this in Chapter 5 to simplify our
barren plateau analysis.
2.1.4
The Quantum Circuit Model
The quantum circuit model is a model to describe quantum computation that is
inspired by classical circuits.
After preparing n qubits in a fixed state (usually
|0⟩⊗n) we apply gates that correspond to unitary operations on the qubits. Finally,
we measure one or more qubits. Circuits are read from left to right and qubits are
drawn as wires with gates on them:
|0⟩
|0⟩
|0⟩
H
⊕
RZ(α)
Z
X
RX(β)
⊕
RY (γ)
Y
Figure 2.2: Example of a 3-qubit quantum circuit.
We have already seen the Hadamard gate H and the Z-rotation RZ in (2.1) and
(2.2), respectively. Similarly, the single-qubit gates RX and RY correspond to X-
and Y -rotations on the Bloch sphere:
RX(α) :=
 cos( α
2 )
−i sin(α
2 )
−i sin(α
2 )
cos( α
2 )

RY (α) :=
cos( α
2 )
−sin(α
2 )
sin(α
2 )
cos( α
2 )

The special cases for α = 180◦rotations around the Bloch sphere give rise to the
so-called Pauli matrices (up to a global phase):
X :=
0
1
1
0

Y :=
0
−i
i
0

Z :=
1
0
0
−1


2.2.
Quantum Machine Learning
11
Finally, controlled gates are gates where the first qubit controls whether a unitary
U is applied to the remaining gates. They can be constructed via
CU =
U
...
...
:= (|0⟩⟨0| ⊗I) + (|1⟩⟨1| ⊗U) =
I
0
0
U

.
In Figure 2.2, we have controlled X and Z gates that are usually called CNOT 1 and
CZ, respectively. They have a special notation:
CNOT =
⊕
=
X
:=




1
0
0
0
0
1
0
0
0
0
0
1
0
0
1
0




CZ =
=
Z
:=




1
0
0
0
0
1
0
0
0
0
1
0
0
0
0
−1




The CNOT gate is drawn with a ⊕symbol since it acts like |x, y⟩7→|x, x⊕y⟩on the
computational basis where ⊕denotes XOR. The CZ gate is drawn with two black
dots since it is symmetric in which qubit is the control. Both CNOT and CZ are
used to entangle the two qubits to which they are applied.
2.2
Quantum Machine Learning
The goal of quantum machine learning (QML) is to achieve a quantum advantage
using the current noisy intermediate-scale quantum (NISQ) hardware. Typically,
QML algorithms employ a hybrid approach where a quantum processor works in
tandem with a classical computer. In this thesis, we focus on variational algorithms
for QML. This approach relies on parametrised quantum circuits (PQCs), i.e. circuits
that depend on tunable parameters.
For example, the circuit in Figure 2.2 is a
PQC if the parameters α, β, γ are not fixed. Given a PQC that depends on some
parameters ⃗θ, machine learning techniques are used to find an optimal parameter
1This is because the Pauli X acts like negation on the computational basis.

12
Background
|0⟩
U(⃗θ)
measure H
postprocess
optimizer
Quantum device
Loss
Classical Device
Parameter update
⟨H⟩
N shots
Figure 2.3: Pipeline for variational algorithms (adapted from Figure 1 in [13]).
assignment ⃗θ⋆for which the circuit exhibits some desired behaviour. This could for
example be fitting a dataset in a supervised classification or regression task [23, 6],
or modelling a probability distribution for a generative task [24, 25, 26].
Other
applications of variational algorithms include simulating quantum chemistry [27, 28],
solving combinatorial optimisation problems [29], and performing natural language
processing tasks [30, 21].
Figure 2.3 shows the schematic pipeline used by variational algorithms. Essentially,
the PQC is trained using a classical optimiser in order to minimise some loss calcu-
lated based on the expectation value ⟨H⟩produced by the quantum device. Because
of the current NISQ hardware, this process is generally noisy. However, many op-
timisers developed for machine learning are resilient to a certain amount of noise
which makes variational algorithms applicable in the NISQ era.
2.2.1
Types of Ans¨atze
The PQCs used for variational algorithms are typically referred to as ans¨atze. The
term ansatz comes from mathematics and physics where it describes an initial strat-
egy or approach to express a solution. Broadly, one can distinguish two different
kinds of ansatz designs commonly used for QML which are depicted in Figure 2.4.
Tensor network ans¨atze arrange gates in a fixed layout inspired by tensor net-
works [31, 32].
For example, the blocks in Figure 2.4 are laid out in a tree ar-
chitecture. Layered ans¨atze on the other hand consist of layers that are repeated
one after the other for a fixed number of times. Commonly, each layer is made up of

2.2.
Quantum Machine Learning
13
Tensor Network Ansatz:
U(⃗θ1)
U(⃗θ2)
U(⃗θ4)
U(⃗θ3)
U(⃗θ5)
U(⃗θ6)
Layered Ansatz:
U(⃗θ1)
U(⃗θ2)
U(⃗θℓ)
...
Figure 2.4: Different ansatz layouts.
single qubit unitaries, preceded or followed by a block of entangling gates. Another
commonly used type of layered ansatz is the alternating operator ansatz used in
the quantum approximate optimization algorithm (QAOA) [29]. There, the layers
are defined in terms of two Hamiltonians that encode a combinatorial optimisation
problem which can be solved by training the circuit.
In this thesis, we focus on layered ansatz designs that have been shown to be more
expressive than tensor network ans¨atze [33]. In particular, see Figure 5.1 in Chap-
ter 5 for layered ans¨atze that are used in practice.
2.2.2
Gradient-Based Optimisation
There is a wide range of optimisation algorithms that can be used to train PQCs [34,
35, 36, 37, 38, 39]. In this thesis, we focus on gradient-based optimisation approaches
which are commonly used in QML and provably improve convergence in variational
algorithms [5].
Gradient-based optimisation techniques such as gradient descent have been proven to
be widely successful in the domain of classical machine learning, in particular neural
networks. Given the output ⃗y of a neural network, the gradient
∂L
∂wi (⃗y) of some loss
function L with respect to the weight wi is computed via backpropagation and the
weight is updated in the opposite direction of this gradient. We can transfer this
approach to the quantum realm: Instead of the weights of a neural network, we train
the parameters of an ansatz. The “output” of the quantum circuit is an expectation
value ⟨H⟩. Hence, we want to compute ∂L
∂θi (⟨H⟩) which by the chain rule depends on

14
Background
∂⟨H⟩
∂θi . Unlike individual measurements, expectation values are continuous variables
such that this gradient is well-defined. Finally, we update the circuit parameters
according to the loss gradient.
However, gradient descent on quantum computers comes with a set of unique chal-
lenges. First, it is not feasible to compute ∂⟨H⟩
∂θi
classically. In particular, the back-
propagation algorithm is not available since quantum circuits have a fundamentally
different structure than neural networks. Instead, the gradient must be computed
on the quantum device itself. Quantum algorithms that solve this task are com-
monly referred to as gradient recipes and are subject of a lot research interest at
the moment [6, 7, 8, 9]. We contribute to this in Chapter 5 by giving diagram-
matic interpretations and proofs of existing recipes, and by proving a conjecture by
Anselmetti et al. [8] establishing the optimality of a certain recipe.
The second issue lies with the geometry of the gradient landscape. It is hypothesised
that gradient descent performs well on classical neural networks because their loss
surface has few bad local minima [40]. The same can unfortunately not be said for
PQCs [41]. Even worse, it has been shown that the gradient landscape of many
ans¨atze is exponentially flat with respect to circuit size, making gradient descent
difficult or even impossible [10]. Thus, there is a lot of interest in analysing which
ans¨atze exhibit those barren plateaus. In Chapter 5 we apply a diagrammatic method
to analyse ans¨atze for this problem.
2.3
The ZXW-Calculus
The ZX-calculus is graphical language for reasoning about quantum computation
originally developed by Coecke and Duncan [14]. It is universal and complete [42]
meaning that all quantum reasoning can be carried out in the realm of ZX diagrams.
The ZX-calculus has been applied in a variety of areas, including circuit optimisa-
tion [15, 43], compilation [16, 44], simulation [17], measurement-based quantum
computing [45, 46] and surface codes [47].

2.3.
The ZXW-Calculus
15
The ZXW-calculus [18] is a variant of ZX that has its roots in the algebraic ZX-
calculus [48]. It has recently been used to express derivates and integrals [19] which
makes it well-suited for our diagrammatic treatment of gradient-based QML.
2.3.1
Generators and String Diagrams
ZXW diagrams consist of generators that are wired together and connected to inputs
and outputs. Following the circuit notation, we put the inputs on the left side and
the outputs on the right. While diagrams can be studied as mathematical objects
in their own right, for this thesis we are mainly interested in their interpretation
as linear maps. Concretely, a diagram with n inputs and m outputs represents a
2m × 2n complex matrix. There are also diagrams with zero inputs and outputs
which thus represent single complex numbers.
We now give the three main generators of the ZXW-calculus:
a
n
...
m
...
:= |0m⟩⟨0n|+a|1m⟩⟨1n|
:=
1
√
2
1
1
1
−1

:=




1
0
0
1
0
1
0
0




where a ∈C. We call the generators the green box, Hadamard, and black triangle,
respectively. ZXW diagrams are formed by wiring these generators together. For
this, we also introduce generators that allow us to bend and cross wires:
:=
1
0
0
1

:=




1
0
0
1




:=
 1
0
0
1

:=




1
0
0
0
0
0
1
0
0
1
0
0
0
0
0
1




We can wire the generators together using the sequential and parallel composition
operators ◦and ⊗, corresponding to matrix multiplication and tensor product on
the underlying matrices.
For example, we write
2
:=
◦(
2
⊗
).
Furthermore, the wires satisfy the yanking equations
=
=

16
Background
This means we can arbitrarily deform diagrams by moving the generators around
the plane, bending and unbending wires as we go, without changing the underlying
matrix. We only have to make sure that the inputs and outputs stay in the same
order. This principle is summarised in the slogan only connectivity matters.
2.3.2
Additional Notation
Based on the generators, we define some additional notation. For example, the green
spider from the original ZX-calculus can be defined via the green box:
α
...
...
:=
eiα
...
...
...
...
:=
0
...
...
(2.5)
The red spiders from the original ZX-calculus can be defined by Hadamard conju-
gation:
α
...
...
:=
α
...
...
...
...
:=
0
...
...
(2.6)
If a diagram only contains spiders and no boxes or black triangles, we sometimes
drop the “W” and speak of traditional ZX-diagrams. Often we only have spiders
with phase α = 0 or α = π. For those cases, we define a special pink spider as a
rescaled version of the red spider that only has integer components in its matrix:
π
n
...
m
...
:= 2
n+m−2
2
π
...
...
n
...
m
...
:= 2
n+m−2
2
...
...
(2.7)
We give the scalars that are represented by commonly occurring diagrams below:
= 2
= 1
π =
π = 0
α = 1
α
π
= eiα
Finally, we define the triangle and inverse triangle as well as their transposes:
:=
=
1
1
0
1

:=
=
1
0
1
1

−1
:=
π
=
1
−1
0
1

−1
:=
−1
=
 1
0
−1
1

(2.8)

2.3.
The ZXW-Calculus
17
a
...
...
b
...
...
...
=
ab
...
...
=
ab
...
...
(sf )
=
=
(id)
=
=
(id′)
=
(b1)
=
(b2)
π
=
π
π
(b3)
a
= 1
(ety)
=
−1
(brk)
a
=
a + 1
(suc)
0
=
(zero)
=
(tri1)
π
=
(tri2)
−1
=
−1
=
(inv)
√
2
=
−2
(eu)
=
(sym)
=
(aso)
a
=
a
a
(pcy)
=
(wdc)
Figure 2.5: Rules of the ZXW-calculus for a, b ∈C.
2.3.3
Rules
So far, we have only seen ZX(W) diagrams as graphical representations of matrices.
Their real power comes from the rewrite rules that allow us to do matrix calculations
diagrammatically. The rules of the ZXW-calculus are listed in Figure 2.5.
Note that the equality signs in the rules mean that both sides represent exactly the
same matrix. In the original ZX-calculus, many rules like (b1), (b2), or (b3) only
hold up to a (non-zero) scalar that is often ignored. However, for the purposes of
this thesis we need to be precise about scalars. The fact that we can give many rules
without them is thanks to the rescaled pink spider. As a trade-off, the colour-change
rule now introduces scalars for pink spiders2:
2We prove this rule as well as other rules of the original ZX-calculus in Section 2.3.6.

18
Background
τ
...
...
n
m
(cc)
=
2−n+m−2
2
τ
...
...
τ
...
...
n
m
(cc)
=
2
n+m−2
2
τ
...
...
Furthermore, fusing pink spiders that are connected by multiple wires also introduces
a scalar:
τ
...
...
σ
...
...
...
n
(Lem. 2.13)
=
2n−1
τ + σ
...
...
We define a multi-legged version of the black triangle, which we call W spider:
...
:=
...
...
:=
(2.9)
Because of the (aso) rule it actually does not matter in which order we plug the
triangles together and it is easy to see that W spiders satisfy the following fusion
rule:
...
...
...
=
...
...
...
(wf )
On top of this, as we will prove in Lemma 2.23, they interact with pink spiders in
the following way:
...
(w)
=
...
π
...
(w)
=
...
π
+
...
π
+ ... +
...
π
This property will prove to be crucial when discussing diagrammatic differentiation
in Chapter 3.
2.3.4
Quantum Gates and Computation in ZXW
Next, we explain how quantum computation is expressed in ZX(W). First, note that
pink and green spiders can describe the computational and the X-basis:

2.3.
The ZXW-Calculus
19
= |0⟩
π
= |1⟩
=
√
2 |+⟩
π
=
√
2 |−⟩
(2.10)
Many matrix operations commonly used in quantum computing have elegant rep-
resentations in ZXW. For example, transposing a matrix corresponds to mirroring
the diagram horizontally and the conjugate matrix is obtained by conjugating the
numbers in boxes and negating the phases in spiders. Thus the adjoint of a ZXW
diagram is constructed by combining those two operations.
The Hadamard gate is given as a generator. We introduce the following notation,
denoting edges with a Hadamard on them as dashed blue lines:
⇝
The Pauli matrices are represented by
X =
π
Y
= i
π
π
Z =
π
the rotation gates can be written as
RZ(α) = e−i α
2
α
RX(α) = e−i α
2
α
RY (α) = e−i α
2
α
−π
2
π
2
= e−i α
2
α
−π
2
π
2
and common two-qubit gates are given by
CNOT =
⊕
=
CZ =
=
√
2
CRZ(α) =
RZ(α)
=
α
2
−α
2
(2.11)
Using those building blocks, we can easily turn quantum circuits into ZXW diagrams.
However, recall from our discussion in Section 2.1.3 that the matrix representation of

20
Background
quantum states has a certain redundancy in that states that only differ by a global
phase behave exactly the same. To deal with this problem, we use the doubling
construction to represent quantum circuits in ZXW. Concretely, whenever we want
to express quantum circuits in ZXW, we first construct a diagram capturing the
circuit structure, and then we double it. Doubling means tensoring the diagram
with its complex conjugate, i.e.
doubled

D
...
...

:=
D
...
...
D
...
...
This way, all global phases cancel out. See [49] for a more detailed description of
doubling.
2.3.5
Pauli Boxes
A useful ZX construction related to Paulis are so-called Pauli boxes [50, 51]:
Definition 2.7.
[51] The Pauli boxes are defined as
I
:=
X
:=
Y
:=
- π
2
π
2
Z
:=
Note that we can treat the wire sticking out on top as either input or output.
Plugging in a green π yields the corresponding Pauli:
Lemma 2.8.
[51] For all P ∈{I, X, Y, Z} we have
P
π
=
P
Pauli boxes can be used to define a type of gate we have not mentioned so far.
Given a Pauli string ⃗P ∈{I, X, Y, Z}⊗n, i.e. a tensor product of Paulis, we define
the Pauli exponential gate ⃗P(α) by

2.3.
The ZXW-Calculus
21
⃗P(α) := e−i α
2 ⃗P =
P1
Pn
α
...
In the special case where ⃗P ∈{I, Z}⊗n, we call ⃗P(α) a phase gadget. Paul exponen-
tials based on the same Pauli string fuse together:
Lemma 2.9.
[50] For all Pauli strings ⃗P we have
P1
Pn
...
P1
Pn
...
=
P1
Pn
...
(2.12)
In particular, this implies ⃗P(α)⃗P(β) = ⃗P(α + β).
Pauli gadgets also have interesting commutation properties:
Lemma 2.10. [50] Let ⃗P, ⃗Q be n-qubit Pauli strings. If the number of positions i
for which Pi ̸= Qi and Pi, Qi ̸= I is even, then
P1
Pn
...
Q1
Qn
...
=
Q1
Qn
...
P1
Pn
...
Otherwise,
P1
Pn
...
Q1
Qn
...
=
1
√
2
Q1
Qn
...
P1
Pn
...

22
Background
2.3.6
Useful Lemmas
We close the chapter by stating and proving some basic results that we will use
throughout the thesis.
Lemma 2.11.
[48] Hadamard is involutive:
=
(hh)
Lemma 2.12. Hadamards switch colours up to a scalar. For τ ∈{0, π}:
τ
...
...
n
m = 2−n+m−2
2
τ
...
...
τ
...
...
n
m = 2
n+m−2
2
τ
...
...
(cc)
The only scalar-free colour change happens for two legs:
τ
=
τ
τ
=
τ
Proof.
τ
...
...
n
m
(2.6)
=
τ
...
...
(2.7)
=
2−n+m−2
2
τ
...
...
τ
...
...
n
m
(2.7)
=
2
n+m−2
2
τ
...
...
(2.6)
=
2
n+m−2
2
τ
...
...
(hh)
=
2
n+m−2
2
τ
...
...
Lemma 2.13. Pink spiders fuse together. We also call this rule (sf ).
τ
...
...
σ
...
...
...
n
= 2n−1
τ + σ
...
...
(sf )

2.3.
The ZXW-Calculus
23
Proof.
τ
...
...
σ
...
...
...
n
a
b
c
d
(2.7)
=
2
a+b+n−2
2
2
c+d+n−2
2
τ
...
...
σ
...
...
...
(2.6)
=
2
a+b+c+d+2n−4
2
τ
...
...
σ
...
...
...
(hh)
=
2
a+b+c+d+2n−4
2
τ
...
...
σ
...
...
...
(sf )
=
2
a+b+c+d+2n−4
2
τ + σ
...
...
(2.6)
=
2
a+b+c+d+2n−4
2
τ + σ
...
...
(2.7)
=
2n−1
τ + σ
...
...
Lemma 2.14. The zero box disconnects:
0
...
...
=
...
...
(2.13)
Proof.
0
...
...
(sf )
=
0
...
...
0
(zero)
=
0
...
...
(cp)
=
...
...
Lemma 2.15. Pink spiders can be decomposed as follows:
...
...
= 1
2

...
...
+
...
...
π
π
π
π

π
...
...
= 1
2

...
...
−
...
...
π
π
π
π

(2.14)
Proof.
kπ
n
...
m
...
(cc)
=
2
n+m−2
2
kπ
...
...
(2.5)
=
2
n+m−2
2

...
...
+ (−1)k
...
...
π
π
π
π

(cc)
=
2
n+m−2
2

2−n+m
2
...
...
+ 2−n+m
2 (−1)k
...
...
π
π
π
π

= 1
2

...
...
+ (−1)k
...
...
π
π
π
π


24
Background
Lemma 2.16.
[48] Hopf rule:
=
(ho)
Lemma 2.17.
[48] Strong complementarity:
...
...
=
...
...
(sc)
Lemma 2.18.
[48] Pink π copies through and negates phases:
α
π
...
= eiα
−α
π
...
π
(π)
Lemma 2.19.
[48] For x, y ∈{0, 1} we have
a
xπ
...
= ax
xπ
...
xπ
yπ
xπ
...
= (−1)xy
xπ
...
xπ
(cp)
Lemma 2.20.
[48] Pink π transposes the triangle:
π
=
π
(2.15)
Lemma 2.21. The triangle acts as a change of bases:
=
π
=
=
π
=
π
(tri)
Proof. The first two equations are just (tri1) and (tri2). The third equation has
been proven in [48]:
(zero)
=
0
(suc)
=
1
=

2.3.
The ZXW-Calculus
25
Then, the second equations follow from
π
(sf )
=
π
(2.15)
=
π
(tri1 )
=
π
Lemma 2.22. The two-legged W spider satisfies
=
π
=
π
(2.16)
Proof.
(wdc)
=
(cp,sf )
=
(tri)
=
(cp,sf )
=
π
(wdc)
=
π
(cp,sf )
=
π
π
(tri)
=
π
(id)
=
π
Lemma 2.23. In general, the W spider acts on the computational basis as follows:
...
=
...
π
...
=
...
π
+
...
π
+ ... +
...
π
(w)
Proof. We prove both equation simultaneously by induction on the number of out-
puts. If the W spider has a single output, the equations hold trivially:
(2.9)
=
π
(2.9)
=
π
For the inductive step, we have
...
(wf )
=
...
(2.16)
=
...
(IH)
=
...
π
...
(wf )
=
π
...
(2.16)
=
...
π
(∗)
=
...
π
+
...
π

26
Background
(IH)
=
...
π
+
...
π
+ ... +
...
π
where the step (∗) follows from
π
= |+⟩⟨+| −|−⟩⟨−|
= 1
2(|0⟩+ |1⟩)(⟨0| + ⟨1|) −1
2(|0⟩−|1⟩)(⟨0| −⟨1|)
= |0⟩⟨1| + |1⟩⟨0|
=
π
+
π
Lemma 2.24. Plugging a pink dot into a two-legged spider produces identity:
=
(2.17)
Proof.
(wdc)
=
(cp,sf )
=
(tri,sf )
=
(id)
=
Lemma 2.25. Plugging a pink dot into a W spider makes the leg disappear:
...
...
=
...
(2.18)
Proof. By induction on the number of outputs. The base case holds by (2.17). For
the inductive step we have
...
...
(wf )
=
...
...
(IH)
=
...
(wf )
=
...
Lemma 2.26. The two-legged W spider adds boxes:
a
b
=
a + b
(2.19)

2.3.
The ZXW-Calculus
27
Proof. If a = 0, we have
0
b
(zero)
=
b
(2.17)
=
b
If a ̸= 0, we have
a
b
(sf ,pcy)
=
b
a
a
(2.8)
=
b
a
a
(suc)
=
1 + b
a
a
(sf )
=
a + b
Corollary 2.27. The W spider adds boxes:
a1
an
...
=
P ai
(2.20)
Proof. Follows by induction on n using (2.19).

Chapter 3
Diagrammatic Differentiation
For our diagrammatic analysis of gradient-based QML, we crucially need a graphical
representation of derivatives. This so-called diagrammatic differentiation for ZX-
calculus was first discovered in [52] and [13] and subsequently generalised to tensor
calculi based on monoidal categories [53]. Recently, Wang and Yeung [19] developed
a more compact graphical representation of derivatives avoiding sums of diagrams
using the ZXW-calculus.
We give an overview on diagrammatic differentiation in Section 3.1, following the
treatment by Wang and Yeung [19]. In Section 3.2, we present a novel, simplified
gradient representation for the special case of parametrised quantum circuits (The-
orem 3.6) that we will use for the remainder of the thesis. Finally, we discuss some
properties of this representation in Section 3.3.
3.1
Background
Recall that we can interpret every ZX diagram D with n inputs and m outputs as
a matrix C2m×2n. The derivative of a parametrised diagram D(θ), written
∂
∂θD(θ),
is defined as the gradient of the matrix associated with D(θ). Consider for example
a single-legged green spider:

3.1.
Background
29
θ
=
 1
eiθ

⇒
∂
∂θ [ θ
] =
 0
ieiθ

The goal of diagrammatic differentiation is to represent those gradients as ZX(W)
diagrams. For example, by inspecting the gradient matrix of our single-legged spider,
we observe that
∂
∂θ [ θ
] = ieiθ
π
(cp)
=
i
θ
π
In fact, this is one of the key equations of diagrammatic differentiation. However,
to cover the most general case, we should also to consider the possibility that the
phase of the spider is a different function in θ. The resulting equation is very similar
to the rule above:
Lemma 3.1. Let f be a differentiable real function. Then
∂
∂θ [ f(θ)
] = if′(θ)
f(θ)
π
(3.1)
Proof. We have
∂
∂θ [ f(θ)
]
(2.5)
=
∂
∂θ

|0⟩+ eif(θ)|1⟩

= if′(θ) · eif(θ)|1⟩
(cp)
=
if′(θ)
f(θ)
π
Furthermore, we note that when differentiating a larger diagram, we can ignore the
parts that do not depend on θ. This property is called linearity [52]:
Lemma 3.2 (Linearity). Let D(θ) be a parametrised ZX diagram depending on θ
and let E be a ZX diagram in which θ does not occur. Then
∂
∂θ

D(θ)
E
...
...
...

= ∂
∂θ

D(θ)
...
...

◦
E
...
...

30
Diagrammatic Differentiation
∂
∂θ


D(θ)
...
...
E
...
...

=
∂
∂θ

D(θ)
...
...

E
...
...
The equations also hold when switching the order of D(θ) and E.
Proof. Directly follows from the linearity of matrix differentiation for multiplication
and tensor product, since for matrices D(θ), E we have
∂
∂θ [D(θ)E] =
  ∂
∂θ [D(θ)]

E
and
∂
∂θ [D(θ) ⊗E] =
  ∂
∂θ [D(θ)]

⊗E.
In the following, we will use brackets to denote the parts of the diagram we are
differentiating. Using the previous two lemmas, we can give the derivative of any
green and red spider:
∂
∂θ
h
f(θ)
...
...
i
(sf ,Lem 3.2)
=
∂
∂θ
...
...
f(θ)
(3.1)
=
if′(θ)
...
...
f(θ)
π
(sf )
=
if′(θ)
f(θ)
...
...
π
(3.2)
∂
∂θ
h
f(θ)
...
...
i
(sf ,cc,Lem 3.2)
=
∂
∂θ
...
...
f(θ)
(3.1,cc,sf )
=
if′(θ)
√
2
f(θ)
...
...
π
(3.3)
This allows us to differentiate all ZX diagrams with only a single parametrised spider.
In general, given some ZX diagram D(θ) in which n spiders depend on θ, we can
always fuse out the parametrised spiders similar to first step in equations (3.2) and
(3.3) and obtain a diagram of shape
D′
f1(θ)
fn(θ)
...
where θ does not occur in D′. However, if we want to differentiate such diagrams
using Lemma 3.1, we have to make use of the product rule:
Lemma 3.3 (Product Rule). Let D(θ) and E(θ) be parametrised ZX diagram
depending on θ. Then

3.1.
Background
31
∂
∂θ

D(θ)
E(θ)
...
...
...

=
E(θ)
...
...
◦∂
∂θ

D(θ)
...
...

+ ∂
∂θ

E(θ)
...
...

◦
D(θ)
...
...
∂
∂θ


D(θ)
...
...
E(θ)
...
...

=
∂
∂θ

D(θ)
...
...

E(θ)
...
...
+
D(θ)
...
...
∂
∂θ

E(θ)
...
...

Proof. Directly follows from the product rule for matrix differentiation.
This allows us to differentiate diagrams with multiple occurrences of θ, for example
∂
∂θ
"
D
f1(θ)
f3(θ)
f2(θ)
#
(Lem 3.3)
=
∂
∂θ
D
f1(θ)
f3(θ)
f2(θ)
+
∂
∂θ
D
f1(θ)
f3(θ)
f2(θ)
+
∂
∂θ
D
f1(θ)
f3(θ)
f2(θ)
(3.1)
=
if′
1(θ)
D
f1(θ)
f3(θ)
f2(θ)
π
+ if′
2(θ)
D
f1(θ)
f3(θ)
f2(θ)
π
+ if′
3(θ)
D
f1(θ)
f3(θ)
f2(θ)
π
Unfortunately, the ZX-calculus is not well-equipped to deal with such linear com-
binations of diagrams. In particular, there are no rewrite rules that involve sums,
which means that we would need to rewrite and simplify each term separately.
Clearly, it would be more convenient if we could express the derivative as a single
diagram. Luckily, Wang and Yeung [19] developed a technique to achieve this in
ZXW using the W spider:
Theorem 3.4 (Wang and Yeung [19]). Let f1, ..., fn be real differentiable func-
tions and D a ZX diagram. Then

32
Diagrammatic Differentiation
∂
∂θ
"
D
f1(θ)
fn(θ)
...
f2(θ)
#
= i
D
f1(θ)
fn(θ)
...
f ′
1(θ)
f ′
n(θ)
π
f2(θ)
f ′
2(θ) ...
Proof. Follows from (w) and Lemma 3.1.
The detailed proof can be found as
Theorem 15 in [19].
3.2
Differentiating Quantum Circuits
While Theorem 3.4 can be used to obtain the derivative of any ZX diagram, for the
purposes of this thesis, we are only interested in the special case of ZX diagrams
representing parametrised quantum circuits. We prove a novel, simplified version of
Theorem 3.4 for this special case that we will use for the remainder of this thesis.
To motivate the idea, recall that a two-legged green spider corresponds to the RZ
gate up to a global phase:
RZ(θ) =
 
e−i θ
2
0
0
ei θ
2
!
= e−i θ
2
θ
Using Stone’s theorem (see Theorem 2.4), we can see that the derivative of the RZ
gate is given by
∂
∂θRZ(θ) = ∂
∂θe−i θ
2 Z = −i
2Ze−i θ
2 Z = −i
2ZRZ(θ)
= −i
2e−i θ
2
θ
π
= −i
2e−i θ
2
θ + π
Compared to Lemma 3.1, we obtain the derivative by simply adding π to the phase.
Similarly, we obtain an alternative version of Lemma 3.1 by adding a global phase:

3.2.
Differentiating Quantum Circuits
33
Lemma 3.5. Let f be a differentiable real function. Then
∂
∂θ
h
e−i f(θ)
2
f(θ)
i
= −if′(θ)
2
e−i f(θ)
2
f(θ) + π
(3.4)
Proof. We have
∂
∂θ
h
e−i f(θ)
2
f(θ)
i
(2.5)
=
∂
∂θ

e−i f(θ)
2 |0⟩+ ei f(θ)
2 |1⟩

= −if′(θ)
2
e−i f(θ)
2 |0⟩+ if′(θ)
2
ei f(θ)
2 |1⟩
= −if′(θ)
2
e−i f(θ)
2 (|0⟩+ ei(f(θ)+π)|1⟩)
(2.5)
=
−if′(θ)
2
e−i f(θ)
2
f(θ) + π
Since we work with quantum circuits, we can ignore global phases as they cancel
out because of the doubling construction (see Section 2.3.4). Therefore, we can use
Lemma 3.5 instead of Lemma 3.1 to differentiate all spiders in a circuit, yielding a
simplified version of Theorem 3.4:
Theorem 3.6. The derivative of a parametrised quantum circuit can be expressed
as the following diagram:
∂
∂θ


C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...

= −2n−1i
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
π
−f ′
n(θ)
−f ′
1(θ)
...
f ′
n(θ)
f ′
1(θ)
...
In other words, we can replace the triangles in Theorem 3.4 with Hadamards.
Proof.
∂
∂θ


C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...

= ∂
∂θ


C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
e−i f1(θ)
2
e−i fn(θ)
2
ei f1(θ)
2
ei fn(θ)
2



34
Diagrammatic Differentiation
(Lem 3.3,3.4)
=
−if′
1(θ)
2
C
f1(θ) + π
fn(θ)
−f1(θ)
−fn(θ)
...
...
e−i f1(θ)
2
e−i fn(θ)
2
ei f1(θ)
2
ei fn(θ)
2
+ if′
1(θ)
2
C
f1(θ)
fn(θ)
−f1(θ) + π
−fn(θ)
...
...
e−i f1(θ)
2
e−i fn(θ)
2
ei f1(θ)
2
ei fn(θ)
2
−
...
+
...
−if′
n(θ)
2
C
f1(θ)
fn(θ) + π
−f1(θ)
−fn(θ)
...
...
e−i f1(θ)
2
e−i fn(θ)
2
ei f1(θ)
2
ei fn(θ)
2
+ if′
n(θ)
2
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ) + π
...
...
e−i f1(θ)
2
e−i fn(θ)
2
ei f1(θ)
2
ei fn(θ)
2
= −if′
1(θ)
2
C
f1(θ) + π
fn(θ)
−f1(θ)
−fn(θ)
...
...
+ if′
1(θ)
2
C
f1(θ)
fn(θ)
−f1(θ) + π
−fn(θ)
...
...
−
...
+
...
−if′
n(θ)
2
C
f1(θ)
fn(θ) + π
−f1(θ)
−fn(θ)
...
...
+ if′
n(θ)
2
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ) + π
...
...
= −if′
1(θ)
2


C
f1(θ) + π
fn(θ)
−f1(θ)
−fn(θ)
...
...
−
C
f1(θ)
fn(θ)
−f1(θ) + π
−fn(θ)
...
...


−
...
−if′
n(θ)
2


C
f1(θ)
fn(θ) + π
−f1(θ)
−fn(θ)
...
...
−
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ) + π
...
...


(sf ,hh)
=
−if′
1(θ)
2
2n


C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
π
...
...
−
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
π
...
...


−
...
−if′
n(θ)
2
2n


C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
π
...
...
−
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
π
...
...



3.2.
Differentiating Quantum Circuits
35
(cp)
=
−2n−1i ·


C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
π
f ′
1(θ)
f ′
n(θ)
−f ′
1(θ)
−f ′
n(θ)
...
...
+
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
f ′
1(θ)
f ′
n(θ)
π
−f ′
1(θ)
−f ′
n(θ)
...
...
+ ...
+
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
f ′
1(θ)
π
f ′
n(θ)
−f ′
1(θ)
−f ′
n(θ)
...
...
+
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
f ′
1(θ)
f ′
n(θ)
−f ′
1(θ)
π
−f ′
n(θ)
...
...


(w)
=
−2n−1i
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
π
−f ′
n(θ)
−f ′
1(θ)
...
f ′
n(θ)
f ′
1(θ)
...
Thus, in order to differentiate a circuit, we just have to connect the following dif-
ferentiation gadget to the parametrised spiders.
Definition 3.7. The differentiation gadget is given by the following diagram:
π
−f ′
n(θ)
−f ′
1(θ)
...
f ′
n(θ)
f ′
1(θ)
...

36
Diagrammatic Differentiation
3.3
Properties of the Differentiation Gadget
We close this chapter by deriving some interesting properties of our differentiation
gadget. First, we consider the case where all spider have the same phase f(θ):
Fact 3.8. Let f be a differentiable real function. Then
∂
∂θ


C
f(θ)
f(θ)
−f(θ)
−f(θ)
...
...



n

= −f′(θ) · 2n−1i
C
f(θ)
f(θ)
−f(θ)
−f(θ)
...
...
π
π
π
...
...
Proof. By Theorem 3.6, the derivative is given by
−2n−1i
C
f(θ)
f(θ)
−f(θ)
−f(θ)
...
...
π
−f ′(θ)
−f ′(θ)
...
f ′(θ)
f ′(θ)
...
(pcy,sf )
=
−2n−1i
C
f(θ)
f(θ)
−f(θ)
−f(θ)
...
...
π
−1
−1
...
f ′(θ)
...

3.3.
Properties of the Differentiation Gadget
37
(cp)
=
−f′(θ) · 2n−1i
C
f(θ)
f(θ)
−f(θ)
−f(θ)
...
...
π
π
π
...
...
In the last step we also used the fact that
−1
=
π
.
Note that this fact is essentially a version of the chain rule since we have shown
∂
∂θC(f(θ)) = f′(θ) · ∂C
∂θ (f(θ)).
Another interesting question is how the derivative in Theorem 3.6 behaves if one
function fi is constant, i.e. one of the differentiated spiders does not actually de-
pend on θ. We can graphically show that such a spider does not contribute to the
derivative:
Fact 3.9. Let f1, ..., fn be differentiable real functions where fi is a constant func-
tion. Then
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
π
−f ′
n(θ)
−f ′
1(θ)
...
f ′
n(θ)
f ′
1(θ)
...
fi(θ)
−fi(θ)
...
...
−f ′
i(θ)
f ′
i(θ)
...
...
= 1
2
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
π
−f ′
n(θ)
−f ′
1(θ)
...
f ′
n(θ)
f ′
1(θ)
...
fi(θ)
−fi(θ)
...
...
Proof. Note that f′
i(θ) = 0 since fi is constant. Thus

38
Diagrammatic Differentiation
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
π
−f ′
n(θ)
−f ′
1(θ)
...
f ′
n(θ)
f ′
1(θ)
...
fi(θ)
−fi(θ)
...
...
−f ′
i(θ)
f ′
i(θ)
...
...
(wf )
=
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
π
−f ′
n(θ)
−f ′
1(θ)
...
f ′
n(θ)
f ′
1(θ)
...
fi(θ)
−fi(θ)
...
...
0
0
(pcy)
=
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
π
−f ′
n(θ)
−f ′
1(θ)
...
f ′
n(θ)
f ′
1(θ)
...
fi(θ)
−fi(θ)
...
...
0

3.3.
Properties of the Differentiation Gadget
39
(2.13)
=
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
π
−f ′
n(θ)
−f ′
1(θ)
...
f ′
n(θ)
f ′
1(θ)
...
fi(θ)
−fi(θ)
...
...
(w,cc,sf )
=
1
2
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
π
−f ′
n(θ)
−f ′
1(θ)
...
f ′
n(θ)
f ′
1(θ)
...
fi(θ)
−fi(θ)
...
...
(2.18)
=
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
π
−f ′
n(θ)
−f ′
1(θ)
...
f ′
n(θ)
f ′
1(θ)
...
fi(θ)
−fi(θ)
...
...
Finally, we emphasize that the ZX diagram representing a given linear map is not
unique. In particular, diagrams representing the same parametrised circuit can differ
in the number of parametrised spiders. A trivial example of this is evidenced by the
spider fusion rule:
f(θ) + g(θ)
−f(θ) −g(θ)
(sf )
=
f(θ)
g(θ)
−f(θ)
−g(θ)

40
Diagrammatic Differentiation
On the left-hand side we have 2 parametrised spiders, whereas we have 4 on the
right-hand side. This also means that the differentiation gadgets that we plug into
either side need to have a different number of legs. Of course, both representations
still represent the same linear map. We can verify this graphically by showing that
the differentiation gadget respects spider fusion. This requires the following auxiliary
lemma:
Lemma 3.10. For all a, b ∈C we have
a
b
=
a + b
Proof. If a = 0, then
0
b
(2.13,sf )
=
b
(2.18,id)
=
b
If a ̸= 0, then
a
b
(pcy)
=
a
b
a
(wdc)
=
a
b
a
(sf )
=
a
b
a
(ho,id)
=
a
b
a
(suc,sf )
=
a
1 + b
a
(sf )
=
a + b
Now, it easily follows that the differentiation gadget respects spider fusion:
Fact 3.11. Let f1, ..., fn, g, h be differentiable real functions. Then
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
π
−f ′
n(θ)
−f ′
1(θ)
...
f ′
n(θ)
f ′
1(θ)
...
g(θ)
...
...
−g′(θ)
g′(θ)
...
...
h(θ)
−g(θ)
−h(θ)
−h′(θ)
h′(θ)
= 1
2
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
π
−f ′
n(θ)
−f ′
1(θ)
...
f ′
n(θ)
f ′
1(θ)
...
g(θ) + h(θ)
−g(θ) −h(θ)
...
...
−g′(θ) −h′(θ)
g′(θ) + h′(θ)
...
...

3.3.
Properties of the Differentiation Gadget
41
Proof.
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
π
−f ′
n(θ)
−f ′
1(θ)
...
f ′
n(θ)
f ′
1(θ)
...
g(θ)
...
...
−g′(θ)
g′(θ)
...
...
h(θ)
−g(θ)
−h(θ)
−h′(θ)
h′(θ)
(wf )
=
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
π
−f ′
n(θ)
−f ′
1(θ)
...
f ′
n(θ)
f ′
1(θ)
...
g(θ)
...
...
h′(θ)
...
...
h(θ)
−g(θ)
−h(θ)
g′(θ)
−h′(θ)
−g′(θ)
(sf ,cc)
=
1
2
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
π
−f ′
n(θ)
−f ′
1(θ)
...
f ′
n(θ)
f ′
1(θ)
...
...
...
h′(θ)
...
...
g(θ) + h(θ)
−g(θ) −h(θ)
g′(θ)
−h′(θ)
−g′(θ)

42
Diagrammatic Differentiation
(Lem. 3.10,wf )
=
1
2
C
f1(θ)
fn(θ)
−f1(θ)
−fn(θ)
...
...
π
−f ′
n(θ)
−f ′
1(θ)
...
f ′
n(θ)
f ′
1(θ)
...
g(θ) + h(θ)
−g(θ) −h(θ)
...
...
−g′(θ) −h′(θ)
g′(θ) + h′(θ)
...
...

Chapter 4
Gradient Recipes
This chapter deals with the problem of computing gradients of parametrised quan-
tum circuits. Given a PQC C(⃗θ), we are usually interested in the gradient of the
expectation value w.r.t. a parameter θi, i.e.
∂
∂θi ⟨H⟩for some Hamiltonian H. While
we can represent this gradient as a ZXW diagram (c.f. Theorem 3.6), computing it
classically is very hard, akin to simulating the quantum system. Therefore, the gra-
dient computation should be ideally performed on quantum hardware. We can use
linearity (and the product rule if multiple gates depend on θi) to break the gradient
of the expectation value down to gradients of a single gate U(θi) that depends on
θi: Suppose C(θi) = EU(θi)D, then
∂
∂θi
⟨H⟩= ∂
∂θi
⟨0|D†U(θi)†E†HEU(θi)D|0⟩
= ∂
∂θi

D
...
U(θi)
...
E
...
H
...
D†
...
U(θi)†
...
E†
...
...

(Lem. 3.2)
=
∂
∂θi
D
...
U(θi)
...
E
...
H
...
D
...
U(θi)
...
E
...
...
...
(4.1)
Ideally, we would like to replace this gate with a new sub-circuit that represents the
matrix
∂
∂θi U(θi). Running this modified circuit would then yield the desired gradient

44
Gradient Recipes
∂
∂θi ⟨H⟩. Unfortunately, the derivate of a parametrised unitary U(θ) is usually no
longer unitary. For a trivial example of this, consider the RZ(θ) gates whose derivate
∂
∂θRZ(θ) = ∂
∂θ
 
e−i θ
2
0
0
ei θ
2
!
=
 
−i θ
2e−i θ
2
0
0
i θ
2ei θ
2
!
is clearly not unitary. One common approach to deal with this issue involves decom-
posing the gate into a linear combination of k unitaries that can be run on quantum
hardware. Thus, computing the gradient in such a way involves k circuit executions.
Such decompositions are called gradient recipes.
An important detail to note here is that the gate U(θi) occurs doubled in (4.1),
matching our previous discussion of quantum circuits in ZX. Thus, we actually
have to study decompositions of doubled(U(θi)) into a linear combination Pk
i=1 xi ·
doubled(Vi) of doubled unitaries. Thus, we can use the circuit differentiation ma-
chinery from Section 3.2 to analyse this problem.
After discussing a custom ZX representation of parametrised unitaries in Section 4.1,
we focus on a popular class of gradient recipes in Section 4.2, the so-called parameter-
shift rules. We give new proofs of various shift rules based on our diagrammatic
gradient representation. Furthermore, we prove a conjecture by Anselmetti et al. [8]
establishing that their 4-term recipe is optimal. For this, we prove a no-go theorem
lower bounding the number of terms needed to compute gradients of a certain class
of circuits in Section 4.2.3. Finally, we remark on a gradient recipe using ancillae in
Section 4.3.
4.1
Parametrised Unitaries as ZX Diagrams
In the literature, gradient recipes are usually derived based on properties of the ma-
trices representing the gates. For example, the validity of different parameter-shift
rules for a unitary eiθH depends on the make-up of the eigenvalues of the Hermitian
generator H. The goal of this section is to bridge the gap between this eigenvalue-

4.1.
Parametrised Unitaries as ZX Diagrams
45
description and the higher-level ZX representation of parametrised unitaries. This
is necessary for our derived rules to be comparable with the results in the literature.
In order to do this, we have to determine the number of parametrised spiders needed
to implement a parametrised unitary U(θ). Parametrised spiders in this context
refer to spiders whose phase is a (non-constant) function in θ.
This number is
important, because the cost of our recipes will depend on the number of legs that
the differentiation gadget for the unitary has. We have already seen that this can
vary because of the spider-fusion rule (c.f. Fact 3.11). However, there are also less
trivial examples. For instance, consider the CU1 gate that has the following two
representations:
CU1(θ) =




1
0
0
0
0
1
0
0
0
0
1
0
0
0
0
eiθ



=
θ
2
θ
2
−θ
2
=
∧
θ
(4.2)
where
∧
is the and-gate acting like conjunction on the computational basis.
4.1.1
Diagonalising Parametrised Unitaries
First, we reduce the problem to constructing diagrams for diagonal matrices. For
this, let us consider an n-dimensional parametrised unitary U(θ). By Stone’s the-
orem (2.4), we know that U(θ) = eiθH for some self-adjoint n-dimensional matrix
H. By the spectral theorem for finite dimensional self-adjoint matrices, H is di-
agonalisable. This means, there is an orthonormal basis B = {|v1⟩, ..., |vn⟩} called
the eigenbasis, satisfying H|vj⟩= λj|vj⟩for all j. Here, λj are the eigenvalues of
H which must all be real since H is self-adjoint.
We can now define a unitary
V := Pn
j=1 |vj⟩⟨j| mapping each computational basis element |j⟩to the correspond-
ing eigenvector |vj⟩in the eigenbasis. Furthermore, we define D := diag(λ1, ..., λn)
as the diagonal matrix consisting of the eigenvalues of H. Noting that we can also
write D = Pn
j=1 λj|j⟩⟨j|, we have

46
Gradient Recipes
V DV † =
n
X
j1,j2,j3=1
λj2|vj1⟩⟨j1|j2⟩⟨j2|j3⟩⟨vj3| =
n
X
j=1
λj|vj⟩⟨vj| = H.
Therefore,
U(θ) = eiθV DV † = V eiθDV † = V diag(eiθλ1, ...,iθλn )V †.
Note that only the diagonal matrix in the middle depends on the parameter θ. Hence,
when trying to determine the number of parametrised spiders needed to implement
U(θ) in the ZX-calculus, it suffices to look at eiθD.
4.1.2
General Construction
Consider a 2n-dimensional parametrised unitary U(θ) = eiθH whose Hermitian gen-
erator H has m non-zero eigenvalues λ1, ..., λm ̸= 0 (it does not matter if H has 0 as
an additional eigenvalue). In this section, we describe a construction to realise U(θ)
in the ZX-calculus using m parametrised spiders. Following the previous section,
we perform a diagonalization U(θ) = V †eiθDV where D is a diagonal matrix with
non-zero entries λ1, ..., λm. We define Boolean functions fλ1, ..., fλm that match on
the eigenvectors corresponding to λ1, ...λm:
fλj(⃗x) =
(
1
if D|⃗x⟩= λj|⃗x⟩
0
otherwise.
This allows us to characterise the action of eiθD on computational basis states as
follows:
Lemma 4.1. For all x ∈{0, 1}n, we have
eiθD|⃗x⟩=


m
Y
j=1
eiθλj·fλj (⃗x)

|⃗x⟩.
(4.3)

4.1.
Parametrised Unitaries as ZX Diagrams
47
Proof. D is a diagonal matrix whose entries are either zero or one of the non-zero
eigenvalues λj. Thus, we either have D|⃗x⟩= ⃗0, or D|⃗x⟩= λj|⃗x⟩for some j.
• Suppose D|⃗x⟩= ⃗0, then eiθD|⃗x⟩= |⃗x⟩. Furthermore, by definition fλj(⃗x) = 0
for all j. Thus,
Qm
j=1 eiθλj·fλj (⃗x)
|⃗x⟩=
Qm
j=1 1

|⃗x⟩= |⃗x⟩= eiθD|⃗x⟩.
• Suppose D|⃗x⟩= λj|⃗x⟩for some j, then eiθD|⃗x⟩= eiλjθ|⃗x⟩.
Furthermore,
fλj(⃗x) = 1 and fλk(⃗x) = 0 for all k ̸= j. Therefore,
Qm
j=1 eiθλj·fλj (⃗x)
|⃗x⟩=
eiλjθ|⃗x⟩= eiθD|⃗x⟩.
In order to realise this construction diagrammatically, we first need a result regarding
the representably of our Boolean functions fλ1, ..., fλm in the ZX-calculus:
Lemma 4.2. For every Boolean function f : {0, 1}n →{0, 1} there is a ZX diagram
such that for all ⃗x ∈{0, 1}n we have
f
x1π
xnπ
...
=
f(⃗x)π
Proof. We can express f as a propositional formula in variables x1, ..., xn using only
conjunction (∧) and negation (¬) connectives.1
We can implement this formula
as a diagram using gates that act like conjunction, negation, and copying on the
computational basis.2 In ZX calculus, those are given by
∧
:=
−1
¬
:=
π
COPY
...
:=
...
By appropriately wiring those gate together, we get the desired ZX representation
of f.
This yields the following construction in the ZX-calculus:
1This follows from the fact that conjunction and negation form a functionally complete set and
can thus encode all possible truth tables [54].
2The copying is necessary since inputs might be used multiple times.

48
Gradient Recipes
Theorem 4.3. Let U(θ) = eiθH be a parametrised unitary whose Hermitian gener-
ator H has m non-zero eigenvalues λ1, ..., λm and admits the diagonalization H =
V †DV . Then
U(θ) =
fλ1
λ1θ
...
fλm
λmθ
...
...
V
V †
Proof. It suffices to show that the middle part is equal to eiθD. We verify this by
plugging in a computational basis state |⃗x⟩:
fλ1
λ1θ
...
x1π
xnπ
fλm
λmθ
...
...
(cp)
=
fλ1
λ1θ
x1π
xnπ
fλm
λmθ
...
x1π
xnπ
...
x1π
xnπ
...
...
=
fλ1(⃗x)π
λ1θ
x1π
xnπ
λmθ
...
fλm(⃗x)π
...
(cp)
=


m
Y
j=1
eiθλj·fλj (⃗x)


x1π
xnπ
...
=


m
Y
j=1
eiθλj·fλj (⃗x)

|⃗x⟩
(4.3)
=
eiθD|⃗x⟩.
As an example, consider the CRZ(θ) and CU1(θ) gate, whose Hermitian generators
HCRZ =




0
0
0
0
0
0
0
0
0
0
−1
2
0
0
0
0
1
2




HCU1 =




0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1




have non-zero eigenvalues −1
2, 1
2, and 1, respectively. The functions matching on the
eigenvectors are given by f−1/2(x1, x2) = x1 ∧¬x2 and f1/2(x1, x2) = f1(x1, x2) =
x1 ∧x2. Invoking Theorem 4.3, we get
CRZ(θ) =
f−1/2
−1
2θ
f1/2
1
2θ
=
−1
2θ
1
2θ
∧
π
∧
(cp)
=
∧
1
2θ
∧
−1
2θ
π
π

4.1.
Parametrised Unitaries as ZX Diagrams
49
CU1(θ) =
θ
f1
=
∧
θ
To summarise, we constructed an alternate two-spider representation for CRZ(θ)
different from (2.11) and recovered the one-spider representation of CU1(θ) from
(4.2).
Note that phase gadgets are a special case of Theorem 4.3 where the function com-
putes the XOR of its inputs.
Also note that in general, the construction from
Theorem 4.3 is not optimal, in the sense that there might be representations that
require less parametrised spiders. For example, consider the parametrised unitary
U(θ) =
2θ
θ
=




1
0
0
0
0
eiα
0
0
0
0
e2iα
0
0
0
0
e3iα




whose Hermitian generator has three non-zero eigenvalues. However, we can show
that the construction in Theorem 4.3 is in fact optimal if the eigenvectors are
−λ, 0, λ:
Proposition 4.4. It is not possible to represent a parametrised unitary eiθH whose
Hermitian generator has eigenvalue −λ, 0, λ with less than two parametrised spiders.
Proof. See Appendix C.
↓
Furthermore, we discuss an improved optimal construction for unitaries with only
two eigenvalues λ1, λ2 in the next section.
4.1.3
Special Case for Two Eigenvalues
In the special case where H has only two eigenvalues λ1, λ2, it is possible to imple-
ment eiθH using only a single parametrised spider. In particular, this is the case for
all single-qubit unitaries.

50
Gradient Recipes
Theorem 4.5. Let U(θ) = eiθH be a parametrised unitary whose Hermitian gen-
erator H has only eigenvalues λ1, λ2 and admits the diagonalization H = V †DV .
Then
U(θ) = eiλ2
fλ1
(λ1 −λ2)θ
...
V
V †
Proof. Follows from Theorem 4.3 and the observation that fλ2(⃗x) = ¬fλ1(⃗x) since
either D|⃗x⟩= λ1|⃗x⟩or D|⃗x⟩= λ2|⃗x⟩:
U(θ) =
fλ1
λ1θ
...
fλ2
λ2θ
...
V
V †
=
fλ1
λ1θ
...
fλ1
λ2θ
...
V
V †
π
= eiλ2
fλ1
λ1θ
...
fλ1
−λ2θ
...
V
V †
(∗)
= eiλ2
fλ1
(λ1 −λ2)θ
...
V
V †
The step (∗) holds since function boxes acting on the computational basis form a
bialgebra with the green spider and thus
f
f
=
f
This construction is optimal since it is clearly not possible to implement parametrised
unitaries using zero parametrised spiders.

4.2.
Parameter-Shift Rules
51
4.2
Parameter-Shift Rules
The first parameter-shift rule was discovered by Mitarai et al. [6] and extended by
Schuld et al. [7]. It says that the derivate of a gate U(θ) = eiθH whose Hermitian
generator H has only two eigenvalues λ1, λ2 satisfies
∂
∂θU(θ) =
λ1 −λ2
2 sin((λ1 −λ2)α)(U(θ + α) −U(θ −α))
(4.4)
for an arbitrary shift angle α with sin((λ1−λ2)α) ̸= 0. Thus, computing the gradient
requires two evaluations of the circuit on the quantum device with parameter values
shifted by ±α. Remarkably, equation (4.4) is an exact representation of the gradient
and should not be mistaken for a numerical gradient approximation, which might
look similar:
∂
∂θU(θ) ≈1
2h(U(θ + h) −U(θ −h))
Unlike this noisy approximation, parameter-shift rules provide an unbiased estimator
for the gradient of the expectation value. Hence, they are widely used in practice.3
There has also been a focus in recent years on finding shift rules for a wider class
of gates going beyond two eigenvalues. For example, there is the four-term rule by
Anselmetti et al. [8] for Hermitians with eigenvalues −λ, 0, λ in addition to further
generalisations depending on the differences between eigenvalues by Wierichs et
al. [9].
In this section, we graphically derive the original rule by Schuld et al. and then
move on to gates with more than two eigenvalues.
4.2.1
Two-Term Shift Rule
A diagrammatic proof for a simplified version of Schuld.
et al.’s [7] parameter
shift rule (4.4) has already been given in [53] and [19]. However, all previous ZX-
3For example by the QML library pennylane [55].

52
Gradient Recipes
based proofs only derived the special case α = π
2 . Furthermore, they only consider
simple rotation gates without generalising to arbitrary parametrised unitaries with
two eigenvalues. We extend the proof to derive the two-term shift rule in its most
general form:
Lemma 4.6. For all α ∈R with α ̸= πn for all n ∈Z, we have
π
π
=
1
2i sin(α) (
α
−α
−
−α
α
) .
(4.5)
Proof. See Appendix C.
↓
This allows us to decompose a version of the two-legged differentiation gadget:
Lemma 4.7. For all α ∈R with α ̸= πn for all n ∈Z, we have
−i
π
π
=
1
2 sin(α) (
α
−α
−
α
−α
) .
(4.6)
Proof. We have
−i
π
π
(2.16)
=
−i
π
π
(cc,hh)
=
−i
π
π
(π)
=
i
π
π
(4.5)
=
1
2 sin(α) (
α
−α
−
α
−α
)
Combining this with the results from Section 4.1, we obtain the two-term shift rule:
Theorem 4.8 (Schuld et al. [7]). Every parametrised circuit C(θ) described by the
unitary eiθH whose Hermitian generator H has only two eigenvalues λ1, λ2 satisfies
∂
∂θC(θ) =
λ1 −λ2
2 sin((λ1 −λ2)α) (C(θ + α) −C(θ −α))
for all α ∈R with (λ1 −λ2)α ̸= πn for all n ∈Z.

4.2.
Parameter-Shift Rules
53
Proof. Using the construction from Theorem 4.5, we can write C(θ) as
C
(λ1 −λ2)θ
−(λ1 −λ2)θ
Thus, we have
∂
∂θC(θ) =
∂
∂θ

C
(λ1 −λ2)θ
−(λ1 −λ2)θ

(Fact 3.8)
=
−i(λ1 −λ2)
C
(λ1 −λ2)θ
−(λ1 −λ2)θ
π
π
(4.6)
=
λ1 −λ2
2 sin((λ1 −λ2)α)
 
C
(λ1 −λ2)θ
−(λ1 −λ2)θ
−(λ1 −λ2)α
(λ1 −λ2)α
−
C
(λ1 −λ2)θ
−(λ1 −λ2)θ
(λ1 −λ2)α
−(λ1 −λ2)α
!
(sf )
=
λ1 −λ2
2 sin((λ1 −λ2)α) (C(θ + α) −C(θ −α))
4.2.2
Shift Rules Beyond Two Terms
One way to extend the result from Theorem 4.8 to a wider class of circuits is to
invoke the product rule. For example, this gives us
∂
∂θ
"
C
θ
−θ
θ
−θ
#
(Lem. 3.3)
=
∂
∂θ
C
θ
−θ
θ
−θ
+
∂
∂θ
C
θ
−θ
θ
−θ
(Thm. 3.6,4.6)
=
1
2 sin(α)
 
C
θ + α
−(θ + α)
θ
−θ
−
C
θ −α
−(θ −α)
θ
−θ
!
+
1
2 sin(β)
 
C
θ + β
−(θ + β)
θ
−θ
−
C
θ −β
−(θ −β)
θ
−θ
!
(4.7)

54
Gradient Recipes
The downside of this approach is that it requires the gate to be decomposed such that
individual rotation angles can be shifted [56]. This introduces additional overhead if
the considered gate is hardware-native. One example of this studied in the literature
is the fsim gate native to Google’s gmon architecture [57]. As argued in [58], it is more
efficient to use a rule that shifts all parameter occurrences simultaneously, avoiding
the depth increase invoked by decomposing fsim into elementary gates. Furthermore,
it was proven in [9] that rules shifting all gates simultaneously sometimes require
less shots to get accurate gradient estimates.
The natural way to extend our proof of Theorem 4.8 is to find decompositions of the
differentiation gadget for more than two legs. Unfortunately, the proof of Lemma 4.7
does not scale since the simple representation of the W-state as a red π-spider no
longer holds if we add more legs. Instead, we characterise the validity of all possible
m-term shift rules for n-legged differentiation gadgets via a system of (complex)
polynomial equations:
Lemma 4.9. For ⃗ξ, ⃗α ∈Rm, the diagram equation
−2n−1i
π
π
π
n
...
...
n
=
m
X
i=1
ξi
αi
−αi
αi
...
−αi
...
holds iff for all k ∈{0, 1, ..., n} we have
m
X
j=1
ξj · eikαj = ki.
Proof. The diagram equation holds iff both sides are equal when plugging in com-
putational basis states. First, consider the left-hand side:
−2n−1i
π
y1π
x1π
π
xnπ
ynπ
π
...
...
(cc,sf )
=
−1
2i
π
ynπ + π
x1π
xnπ
...
y1π + π ...

4.2.
Parameter-Shift Rules
55
(2.20)
=
−1
2i
π
Pn
j=1(−1)xj −(−1)yj
= −1
2i
n
X
j=1
(−1)xj −(−1)yj
For the right-hand side, we get
m
X
i=1
ξi
xnπ
αi
y1π
−αi
x1π
αi
...
ynπ
−αi
...
=
m
X
i=1
ξi · eiαi
Pn
j=1 xj−yj.
Equating both sides yields
−1
2i
n
X
j=1
(−1)xj −(−1)yj =
m
X
i=1
ξi · eiαi
Pn
j=1 xj−yj
⇔i
n
X
j=1
xj −yj =
m
X
i=1
ξi · eiαi
Pn
j=1 xj−yj
since (−1)xj −(−1)yj = −2(xj −yj) for all xj, yj ∈{0, 1}. The equation above must
hold for all choices of ⃗x, ⃗y ∈{0, 1}n. Noting that Pn
j=1 xj −yj ∈{−n, ..., n}, we can
represent this more compactly as
m
X
j=1
ξj · e±ikαj = ±ki
for k ∈{0, ..., n}. Finally, we can drop the ± sign since negating just corresponds
to taking the complex conjugate on both sides.
This general characterisation of shift rules will be useful for proving a no-go result
in Section 4.2.3. However, for the purposes of this section it suffices to look at the
special case of symmetric shifts as in Lemma 4.7.
This simplifies the system of
equations:
Corollary 4.10. For ⃗ξ, ⃗α ∈Rm, the diagram equation
−2n−1i
π
π
π
n
...
...
n
=
m
X
i=1
ξi

αi
−αi
αi
...
−αi
...
−
αi
−αi
αi
...
−αi
...


56
Gradient Recipes
holds iff for all k ∈{1, ..., n} we have
m
X
j=1
ξj · sin(kαj) = 1
2k.
Proof. Invoking Lemma 4.9, we get the system
m
X
j=1
ξj

eikαj −e∓ikαj

= ki
⇔
2i
m
X
j=1
ξj · sin(kαj) = ki
for k ∈{0, 1, ..., n}. Notice that the case k = 0 is now trivially satisfied.
To make the notation more concise, we will write this system of equations in matrix
form as
S⃗α · ⃗ξ = 1
2⃗τ
(4.8)
where
S⃗α =





sin(α1)
...
sin(αm)
sin(2α1)
...
sin(2αm)
...
...
sin(nα1)
...
sin(nαm)





⃗τ =





1
2
...
n





If m = n, the system is square and solvable under some mild conditions on the αi.
For example, in the case n = m = 1, we get the single equation ξ sin(α) = 1
2 whose
solution ξ =
1
2 sin(α) is exactly the shift rule from Lemma 4.7. In the case n = m = 2,
we get the system
ξ1 sin(α1) + ξ2 sin(α2) = 1
2
ξ1 sin(2α1) + ξ2 sin(2α2) = 1
which for α1 ̸= α2 and sin(2α1), sin(2α2) ̸= 0 is solved by
ξ1 =
2 sin(α2) −sin(2α2)
2(sin(2α1) sin(α2) −sin(α1) sin(2α2))

4.2.
Parameter-Shift Rules
57
ξ2 =
sin(2α1) −2 sin(α1)
2(sin(α1) sin(2α2) −sin(2α1) sin(α2)).
This allows us to immediately derive the four-term shift rule given by Anselmetti et
al. [8]:
Theorem 4.11 (Anselmetti et al. [8]). Every parametrised circuit C(θ) described
by the unitary eiθH whose Hermitian generator H has eigenvalues −λ, 0, λ satisfies
∂
∂θC(θ) = ξ1 (C(θ + α1) −C(θ −α1)) + ξ2 (C(θ + α2) −C(θ −α2))
for ξ1 =
2 sin(λα2)−sin(2λα2)
2(sin(2λα1) sin(λα2)−sin(λα1) sin(2λα2)) and ξ2 =
sin(2λα1)−2 sin(λα1)
2(sin(λα1) sin(2λα2)−sin(2λα1) sin(λα2)).
Proof. Using the construction from Theorem 4.3, we can write C(θ) as
C
λθ
−λθ
−λθ
λθ
Thus, we have
∂
∂θC(θ) = ∂
∂θ
"
C
λθ
−λθ
−λθ
λθ
#
(sym,Fact 3.8)
=
−2λi
C
λθ
−λθ
−λθ
λθ
π
π
π
(sym,Corr. 4.10)
=
λ
2
X
i=1
ξi





C
λθ
−λθ
−λθ
λθ
λαi
−λαi
λαi
−λαi
−
C
λθ
−λθ
−λθ
λθ
−λαi
λαi
−λαi
λαi





(sf )
=
λξ1 (C(θ + α1) −C(θ −α1)) + λξ2 (C(θ + α2) −C(θ −α2))

58
Gradient Recipes
Similarly, solving the system (4.8) for m = n = 3, 4, ... yields 2n-term shift rules for
circuits with more than 2 parametrised spiders. Unfortunately, we are not aware of
a closed-form solution for the coefficients ⃗ξ for arbitrary n and ⃗α. However, if we fix
equidistant shift angles αj =
jπ
n+1, we can in fact derive a closed-form solution for ⃗ξ:
Lemma 4.12. If αj =
jπ
n+1, then S⃗α · ⃗ξ = 1
2⃗τ has the solution ξj =
1
n+1
Pn
k=1 k ·
sin

kjπ
n+1

.
Proof. For equidistant angles, the equations correspond to a type-I discrete sine
transform (DST-I) [59, 60]
xk =
n
X
j=1
ξj · sin
 kjπ
n + 1

where xk = 1
2k. Since the inverse of the DST-I is again given by the DST-I scaled
by
2
n+1, we get
ξj =
2
n + 1
n
X
k=1
xk · sin
 kjπ
n + 1

=
1
n + 1
n
X
k=1
k · sin
 kjπ
n + 1

.
This corresponds to the following generalised parameter-shift rule:
Theorem 4.13. Let C(θ) be a parametrised circuit that is represented by
C
θ
−θ
θ
−θ
...
...
Then
∂
∂θC(θ) = λ
n
X
j=1
ξj (C(θ + αj) −C(θ −αj))
if ⃗α and ⃗ξ satisfy the equations S⃗α · ⃗ξ =
1
2⃗τ.
One possible solution is given by
αj =
jπ
n+1 and ξj =
1
n+1
Pn
k=1 k · sin

kjπ
n+1

.

4.2.
Parameter-Shift Rules
59
Proof. Similar to Theorem 4.11, this follows from Fact 3.8 and Corollary 4.10.
A similar generalised shift rule has been proven by Wierichs et al. [9]. Their rule re-
quires 2k terms where k is the number of unique eigenvalue differences of the Hermi-
tian generator, whereas the cost of our rule depends on the number of parametrised
spiders needed to implement the gate. We already established a connection between
eigenvalues and ZX diagrams by upper-bounding the number of parametrised spi-
ders by the number of non-zero eigenvalues (c.f. Theorem 4.3). Furthermore, we
lower-bounded the number of spiders for eigenvalues 0, ±λ (c.f. Proposition 4.4). An
interesting future research direction would be to explore whether there are tighter
bounds for more general cases and any deeper relationships between eigenvalues and
parametrised spiders in diagrams. This could possibly lead to a diagrammatic proof
of Wierichs et al.’s version of the generalised shift rule. Note that this might also
require decompositions of the differentiation gadget where the spider-phases do not
all have the same absolute value as assumed in Theorem 4.13.
4.2.3
Proof of Anselmetti’s No-Go Conjecture
A general pattern in parameter shift rules seems to be that the number of terms
required is the same as when using the naive approach of the product rule combined
with two-term shifts (see equation (4.7)). This holds true for our generalised rule
(Theorem 4.13), as well as for Wierichs et al.’s general rule [9] and Anselmetti et
al.’s four-term rule [8] (Theorem 4.11). An obvious question at this point is whether
we can do any better than that.
As far as we are aware, no results regarding the optimality of shift rules in this sense
have been proven in the literature. In particular, Anselmetti et al. [8] conjecture
that their four-term rule is optimal, but do not give a proof. In this section, we
give the first proof (to our knowledge) of this conjecture. We show that it is indeed
impossible to compute gradients for gates whose generators have eigenvalue −λ, 0, λ
using less than four shifts.

60
Gradient Recipes
For this, we first look at an example.
One common gate whose generator has
eigenvalues of this shape is CRZ(θ). Recall that when calculating derivatives, we
always have to work with the doubling construction.
Thus, we define U(θ) :=
doubled(CRZ(2θ)) = CRZ(2θ) ⊗CRZ(2θ). We multiply θ by 2 to avoid fractions
in the matrix:
U(θ) = diag(1, 1, eiθ, e−iθ, 1, 1, eiθ, e−iθ, e−iθ, e−iθ, 1, e−iθ, eiθ, eiθ, e2iθ, 1)
The corresponding derivative is thus given by
∂
∂θU(θ) = diag(0, 0, ieiθ, −ie−iθ, 0, 0, ieiθ, −ie−iθ, −ie−iθ, −ie−iθ, 0, −ie−iθ, ieiθ, ieiθ, 2ie2iθ, 0)
Suppose we had a three-term shift rule for U(θ), i.e. ξ1, ξ2, ξ3, α, β, γ ∈R such that
∂
∂θU(θ) = ξ1U(θ +α)+ξ2U(θ +β)+ξ3U(θ +γ). By comparing the matrix elements,
this rule would need to satisfy the following equations:
ξ1 + ξ2 + ξ3 = 0
(4.9)
ξ1ei(θ+α) + ξ2ei(θ+β) + ξ3ei(θ+γ) = ieiθ
(4.10)
ξ1e−i(θ+α) + ξ2e−i(θ+β) + ξ3e−i(θ+γ) = −ie−iθ
(4.11)
ξ1e2i(θ+α) + ξ2e2i(θ+β) + ξ3e2i(θ+γ) = 2ie2iθ
(4.12)
Note that equation (4.10) is redundant since it is the complex conjugate of equation
(4.11). Furthermore, multiplying (4.11) with e−iθ and (4.12) with e−2iθ yields the
following simplified system:
ξ1 + ξ2 + ξ3 = 0
ξ1eiα + ξ2eiβ + ξ3eiγ = i
ξ1e2iα + ξ2e2iβ + ξ3e2iγ = 2i
Surprisingly, this is the exact same system we get in Lemma 4.9 for decomposing
the differentiation gadget. We can show that this system is in fact not solvable:

4.2.
Parameter-Shift Rules
61
Lemma 4.14. This system of equations has no solution for ξ1, ξ2, ξ3, α, β, γ ∈R:


1
1
1
eiα
eiβ
eiγ
e2iα
e2iβ
e2iγ




ξ1
ξ2
ξ3

=


0
i
2i


Proof. First, note that the system is given by a Vandermonde matrix. Thus, it
has full rank if α, β, γ are pairwise distinct angles. In that case, the solution to the
system is unique. Using the shorthand a = eiα, b = eiβ, c = eiγ, Gaussian elimination
yields
ξ1 = −i
b + c −2
(a −b)(a −c)
ξ2 = −i
a + c −2
(b −a)(b −c)
ξ3 = −i
a + b −2
(c −a)(c −b).
Suppose that ξ1, ξ2, ξ3 are real. This means that
ξ1 · ξ1 = ξ2
1
⇔−
b−1 + c−1 −2
(a−1 −b−1)(a−1 −c−1) ·
b + c −2
(a −b)(a −c) =
(b + c −2)2
(a −b)2(a −c)2
⇔a2(b + c −2)(2bc −b −c)
(a −b)2(a −c)2
=
(b + c −2)2
(a −b)2(a −c)2
⇔a2 =
b + c −2
2bc −b −c
Note that we have 2bc −b −c ̸= 0 since the equation 2ei(β+γ) = eiβ + eiγ has the
only angle solution β = γ = 0 which is ruled out by the assumption that β and γ
are distinct angles.
Similarly, we get b2 =
a+c−2
2ac−a−c and c2 =
a+b−2
2ab−a−b.
Thus, we have a system of
quadratic equations which we can solve using a computer algebra system. Using a
Mathematica program, we find that a = b = c = −3√−1 and a = b = c = (−1)
2
3
are the only solutions. This violates the assumption that α, β, and γ are distinct
angles.
Next, we consider the case where the angles are not distinct. W.l.o.g. assume that
γ = α. This means that the last column of the matrix becomes redundant and we
can simplify the system to

62
Gradient Recipes
ξ1 + ξ2 = 0
ξ1eiα + ξ2eiβ = i
ξ1e2iα + ξ2e2iβ = 2i
Since ξ1 and ξ2 are real, we know that the conjugate equations ξ1e−iα +ξ2e−iβ = −i
and ξ1e−2iα + ξ2e−2iβ = −2i also hold. Adding those conjugate equations to the
original versions and using ξ2 = −ξ1 yields cos(α) −cos(β) = 0 and cos(2α) −
cos(2β) = 0. This is only satisfied for α = β = π. But then ξ1eiα + ξ2eiβ = 0 ̸= i,
which violates the second equation.
With this lemma we have shown two things at once: First, we cannot decompose
the four-legged differentiation gadget into less than four shifts. Secondly, CRZ(θ)
does not satisfy a shift rule with less than four terms.
Now the question is how to extend this result to arbitrary gates with generator
eigenvalues −λ, 0, λ? The answer is surprisingly simple: It relies on the fact that
each such gate can be used to “simulate” CRZ(θ):
Lemma 4.15. Let U(θ) = eiθH be an n-qubit unitary whose Hermitian generator H
has eigenvalue −λ, 0, λ with corresponding eigenvectors |⃗x−λ⟩, |⃗x0⟩, and |⃗xλ⟩. Define
a Boolean function f : {0, 1}2 →{0, 1}n by
f(0, 0) = ⃗x0
f(0, 1) = ⃗x0
f(1, 0) = ⃗x−λ
f(1, 1) = ⃗xλ.
Then, we have
CRZ(θ) =
f
...
U
  θ
2λ

...
...
Proof. We check how the diagram acts on computational basis states:
f
bπ
aπ
...
U
  θ
2λ

...
...
(cp)
=
f
bπ
aπ
...
U
  θ
2λ

...
...
bπ
aπ

4.3.
Ancilla Recipes
63
=
f1(a, b)π
...
U
  θ
2λ

...
...
bπ
aπ
fn(a.b)π
(cp)
=
f1(a, b)π
U
  θ
2λ

...
...
bπ
aπ
fn(a, b)π
f1(a, b)π
fn(a, b)π
• For |00⟩we get ⟨⃗x0|U(θ)|⃗x0⟩|00⟩= ei·0· θ
2λ |00⟩= |00⟩= CRZ(θ)|00⟩.
• For |01⟩we get ⟨⃗x0|U(θ)|⃗x0⟩|01⟩= ei·0· θ
2λ = |01⟩= CRZ(θ)|01⟩.
• For |10⟩we get ⟨⃗x−λ|U(θ)|⃗x−λ⟩|10⟩= e−iλ θ
2λ |10⟩= e−i θ
2 |10⟩= CRZ(θ)|10⟩.
• For |11⟩we get ⟨⃗xλ|U(θ)|⃗xλ⟩|11⟩= eiλ θ
2λ |11⟩= ei θ
2 |11⟩= CRZ(θ)|11⟩.
This allows us to immediately conclude Anselmetti et al.’s conjecture:
Theorem 4.16 (Anselmetti’s No-Go Conjecture). The shift rule in Theo-
rem 4.11 is optimal, i.e. it is not possible to compute the gradient of gates with
generator eigenvalues −λ, 0, λ using less than four shifts.
Proof. Suppose there is such a gate U(θ) that admits a 3-term shift rule. But by
Lemma 4.15 this would also yield a 3-term rule for CRZ(θ) which we have shown is
not possible (Lemma 4.14).
Remark 4.17. This “proof by example” technique also generalises to the optimality
of other shift rules. As soon as we can prove that a shift rule is optimal for an
example gate, this immediately implies that the rule is optimal for all gates with the
same eigenvalues. This could be used to generalise this no-go theorem to capture the
cost of shift rules for all gates. The main difficulty lies in characterising for which
combinations of n and m the system in Lemma 4.9 is solvable.
4.3
Ancilla Recipes
One of the initial motivations for using the ZX calculus to study gradient recipes
was the hope that the graphical representation of derivatives might make it easier to
discover new recipes that possibly go beyond parameter shift rules. Generally, this

64
Gradient Recipes
requires decomposing the differentiation gadget into doubled maps. We have found
the following promising decomposition:
π
−f ′
n(θ)
−f ′
1(θ)
...
f ′
n(θ)
f ′
1(θ)
...
(wf )
=
π
−f ′
n(θ)
−f ′
1(θ)
...
f ′
n(θ)
f ′
1(θ)
...
(2.16)
=
−f ′
n(θ)
−f ′
1(θ)
...
f ′
n(θ)
f ′
1(θ)
...
π
(sf ,pcy)
=
f ′
n(θ)
f ′
1(θ)
...
f ′
n(θ)
f ′
1(θ)
...
π
π
(4.5)
=
1
2 sin(α)

f ′
n(θ)
f ′
1(θ)
...
f ′
n(θ)
f ′
1(θ)
...
α
−α
−
f ′
n(θ)
f ′
1(θ)
...
f ′
n(θ)
f ′
1(θ)
...
α
−α

=
1
2 sin(α)

doubled

f ′
n(θ)
f ′
1(θ)
...
α

−doubled

f ′
n(θ)
f ′
1(θ)
...
−α

(4.13)
Unfortunately, applying this decomposition to gates yields non-unitary terms in
general. The same holds true for other compositions of the gadget we investigated.
However, (4.13) suggests a general algorithm to compute gradients using ancillae.
We illustrate this on the example of two RZ gates. Note that
θ
θ
±α
(id,sf )
=
θ
θ
±α
Thus, we can perform this computation on a quantum computer by preparing two
ancillae, i.e. extra qubits, in the state
±α
,4 connecting them to the original
qubits via CZs, and then performing post-selection. Post-selection means that we
measure and ignore all executions where the outcome is not the one specified in the
circuit. This allows us to perform non-unitary operations like the gradient above.
This yields a 2-term recipe for the gate above which would have required four terms
using the regular shit rules. Generally, any gate with n parametrised spider can be
4We discuss how to construct this state in Appendix A

4.3.
Ancilla Recipes
65
differentiated this way using 2 terms and n ancilla qubits. However, note that each
term is more expensive to execute, requiring more shots to get accurate estimates
of the expectation value because of the post-selection. Furthermore, the linear re-
quirement of ancillae is a significant limitation of this rule since qubits are a very
scarce recourse on current quantum devices. Thus, while theoretically interesting,
the practical applicability of this rule is limited and shift rules should probably be
preferred.

Chapter 5
Barren Plateaus
After studying how gradients can be computed, we now turn to the question of how
the gradient landscape of quantum circuits looks like. A common challenge when
training PQCs using gradient-based methods is the so-called barren plateau phe-
nomenon. Roughly, it describes the problem that the gradient landscape of many
quantum circuits, unlike classical neural networks [40], flattens exponentially with
increasing circuit sizes. In other words, the probability that the gradient ∂⟨H⟩
∂θi is non-
zero to some fixed precision is exponentially small with regards to the number of
qubits [10]. As a result of this, gradient-based optimisation becomes increasingly dif-
ficult or even numerically impossible. Thus, identifying and studying which circuits
exhibit this undesirable behaviour has been a major focus of QML research [10, 11].
Recently, Wang and Yeung proposed a new method to detect barren plateaus using
the ZXW-calculus [19]. However, they only demonstrate their method on a trivial
example circuit. In this chapter we apply their diagrammatic approach to ans¨atze
actually used in QML research (see Figure 5.1). After formally defining the barren
plateau phenomenon in Section 5.1 and the circuits we study in Section 5.2, we
introduce a technique to empirically detect barren plateaus in Section 5.3.
• We develop a tool using the QuiZX library [17] in Rust that automatically

5.1.
Background
67
computes the variance of the expectation value gradients.
• We use the tool to numerically analyse 7 circuits used by Sim et al. [20] and
conclude that they likely all already have barren plateaus for a single layer
(Figures 5.3 and 5.4).
• We also study 3 IQP circuits, concluding that two of them likely have barren
plateaus while one does not (Figures 5.5, 5.6, and 5.7).
We verify our empirical hypotheses in Section 5.4 by diagrammatically proving the
existence of barren plateaus:
• We prove that the first Sim ansatz has barren plateaus even when only using
a single layer if we measure on Θ(n) qubits (Theorem 5.11) and derive similar
conditions for the second Sim ansatz (Theorem 5.12).
• We derive a general result that can be used to analyse any single-layer IQP
circuit for barren plateaus (Theorem 5.16) and apply it to prove the existence
of barren plateaus for 3 single-layer IQP ans¨atze (Theorem 5.18), including
the main ansatz used by the quantum natural language processing library
lambeq [21] (Theorem 5.19).
• We also prove that one of the IQP ans¨atze does not have barren plateaus for
any number of layers, with the variance converging to a constant in the limit
(Corollary 5.25).
Finally, we give a brief overview of barren plateau mitigation techniques presented
in the literature in Section 5.5.
5.1
Background
Consider a parametrised quantum circuit U(⃗θ) on n qubits and a Hamiltonian H.
We assume that the parameters of U are independently and uniformly distributed
over the interval [−π, π] since this is a common initialisation strategy.
One can

68
Barren Plateaus
show that the mean gradient of U’s expectation value with regards to H is zero
in that case, i.e. E

∂⟨H⟩
∂θi

= 0 [13]. Now, if furthermore Var

∂⟨H⟩
∂θi

≈0 then it
is likely that the training starts in a barren plateau where the gradient ∂⟨H⟩
∂θi
≈0.
Formally, we say that barren plateaus are present if Var

∂⟨H⟩
∂θi

∈O

1
2poly(n)

, i.e.
the variance vanishes exponentially as a function of the number of qubits n. Then,
Chebyshev’s inequality implies that Pr
 ∂⟨H⟩
∂θi
 ≥ε

≤Var

∂⟨H⟩
∂θi

/ε2.
In other
words, the probability that the gradient ∂⟨H⟩
∂θi
is non-zero up to some precision ε is
exponentially small in n.
The barren plateau phenomenon was first studied by McLean et al. [10] who proved
that barren plateaus appear if an ansatz is sufficiently random such that its parametri-
sations match the uniform distribution of unitaries (the so-called Haar-measure) up
to the second moment, i.e. they form a unitary 2-design. The distance between the
distribution of unitaries generated by an ansatz and the Haar distribution can be
seen as a measure for ansatz expressivity since it captures how uniformly an ansatz
explores the unitary space [11, 20]. Sim et al. [20] studied the expressiveness of
several commonly used ans¨atze. We will analyse a selection of these in Section 5.3
and Section 5.4. Holmes et al. relate the existence of barren plateaus to the ex-
pressiveness of an ansatz [11], showing that more expressive ans¨atze have flatter
gradient landscapes. Concretely, they upper-bound the variance of the gradient in
terms of how far an ansatz is from a 2-design, implying a trade-off between ansatz
expressiveness and trainability. Interestingly, the existence of barren plateaus also
depends on the Hamiltonian H: If we only measure a subset of qubits (i.e. we use
a so-called local cost function), then some ans¨atze can avoid barren plateaus up to
logarithmic circuit depth in n [12].
Zhao and Gao [13] were the first to employ the ZX-calculus to analyse barren
plateaus. They express Var

∂⟨H⟩
∂θi

as a linear combination of diagrams with an
exponential number of terms, which they handle using tensor networks. Wang and
Yeung [19] improve on this by expressing the variance in a single diagram, allowing

5.1.
Background
69
the analysis of barren plateaus to be carried out entirely within the framework of
ZX. They consider ans¨atze U(⃗θ) where each parameter only occurs a single time and
introduce the following notation for the expectation value:
⟨H⟩= ⟨0|U†(⃗θ)HU(⃗θ)|0⟩=
U
θ1
θm
...
...
H
...
U †
−θ1
−θm ...
...
...
=:
θ1
θm
⟨H⟩
...
−θ1
−θm
...
Since E

∂⟨H⟩
∂θi

= 0 (a diagrammatic proof of this is given as Lemma 25 in [19]), we
have
Var
∂⟨H⟩
∂θi

= E
 ∂⟨H⟩
∂θi
2!
=
1
(2π)m
Z π
−π
...
Z π
−π
∂⟨H⟩
∂θi
2
dθ1...dθm.
Using their graphical integration approach, Wang and Yeung express those nested
integrals as the following diagram:
Theorem 5.1 (Wang and Yeung [19]).
Var
∂⟨H⟩
∂θi

=
⟨H⟩
...
...
...
...
⟨H⟩
...
...
...
...
π
π
π
...
...
...
...
Parameter θi
Parameter θi
Proof. See Theorem 28 in [19].
However, Wang and Yeung only apply Theorem 5.1 to a small toy circuit with two
qubits and four parameters. In particular, they perform no actual barren plateau
analysis which would require computing the variance for an arbitrary number of
qubits n. The goal of this chapter is to apply Theorem 5.1 to ans¨atze that are used
in practice and characterise when barren plateaus show up.

70
Barren Plateaus
RX
RY
RX
RY
RX
RY
RX
RY
RX
RY
RX
RY
RX
RY
RX
RY
⊕
⊕
⊕
H
RX
H
RX
H
RX
H
RX
Sim1
Sim2
Sim9
RY
RY
RY
RY
RY
RY
RY
RY
RZ
RZ
RZ
RZ
⊕
⊕
⊕
RY
RY
RY
RY
RZ
RZ
RY
RY
Sim10
Sim11
RZ
RZ
RZ
RZ
RY
RY
RY
RY
RZ
RZ
RY
RY
RY
RY
RY
RY
⊕
RY
RY
RY
RY
⊕
⊕
⊕
⊕
⊕
⊕
⊕
Sim12
Sim15
Figure 5.1: Circuits from Sim et al. [20] we study in this chapter. The numbering
follows Figure 2 in [20]. The dashed box indicates a single layer that can be repeated
multiple times where each layer has unique parameters. We omitted the parameters
in the RX, RY , and RZ gates for brevity.
5.2
Studied Ans¨atze
In this chapter, we perform barren plateau analyses for two different classes of
ans¨atze. First, we consider a selection of circuits studied by Sim et al. [20]. Con-
cretely, we analyse all ans¨atze for which Wang and Yeung’s [19] ZX-based variance
computation from Theorem 5.1 is applicable. They are depicted in Figure 5.1. The
remaining circuits in [20] use controlled rotation gates which (as we have proven in
Proposition 4.4) need at least two parametrised spiders to be implemented. Thus,
Theorem 5.1 does not apply there. Sim et al. [20] calculated the expressiveness of
their ans¨atze, which makes them interesting cases to study as they are good can-
didates to empirically test the expressiveness vs. trainability trade-off described by
Holmes et al [11].

5.2.
Studied Ans¨atze
71
θ
...
θ1
...
θ2
θn/2
θ1
θ2
...
θn−1
IQP1
IQP2
IQP3
−θ1
θ1
θ2
...
−θn−1
θn−1
−θ2
IQP4
Figure 5.2: Various n-qubit IQP ans¨atze we study in this chapter given in ZX
notation. Similar to Figure 5.1, the dashed boxes can be repeated multiple times,
where each layer has unique parameters. Note that IQP2 is only defined for even n.
Secondly, we study instantaneous quantum polynomial (IQP) circuits. First intro-
duced in [61], IQPs consist of layers made up of diagonal gates, separated by columns
of Hadamards, i.e.
U(⃗θ1, ..., ⃗θℓ) =
D(⃗θ1)
D(⃗θ2)
...
H
H
...
H
H
D(⃗θℓ)
...
H
H
...
...
H
H
where the blocks D(⃗θi) only contain gates with diagonal matrices. Thus, all gates
that make up D(⃗θi) commute with each other. Therefore, it does not matter in
which order they are executed which is the reason why this type of ansatz is called
instantaneous. Remarkably, classical weak simulation of IQP circuits has been shown
to be #P-hard [62, 63] and an efficient simulation algorithm would collapse the
polynomial hierarchy to the third level [64].
Thus, the simple structure of IQP
circuits already captures a quantum advantage, which makes them an interesting
class of circuits to study.

72
Barren Plateaus
For the purpose of this chapter, we use phase gadgets for the diagonal gates that
make up the blocks. This is motivated by the fact that they have an elegant rep-
resentation in ZX an can be nicely reasoned about. Concretely, Figure 5.2 shows
the IQP ans¨atze we study in this chapter. IQP1 and IQP2 are of more theoreti-
cal interest and will serve as demonstrations for our analytical techniques. On the
other hand, IQP3 has been suggested in [30] and IQP4 is the default ansatz for the
quantum natural language processing (QNLP) library lambeq [21]. Thus, the barren
plateau analysis for this ansatz is of great practical interest. Recalling (2.11), IQP4
can be seen as a ladder of CRZ gates. Also note that each parameter occurs twice
in IQP4 which means that Theorem 5.1 is not directly applicable. However, we can
still compute the variance in some special cases which we discuss in Section 5.4.6.
5.3
Numerical Barren Plateau Detection
In this section, we develop a method to empirically test ans¨atze for barren plateaus
by computing Var(∂⟨H⟩
∂θi ).
5.3.1
Method
Our numerical barren plateau detection method relies on the following representation
of the triangle in ZX calculus:
Lemma 5.2.
= 2
−π
4
−π
4
π
4
π
4
Proof. See Appendix C.
↓
This allows us to represent the variance from Theorem 5.1 as a Clifford+T diagram1
1A ZX diagram is Clifford+T if all spider phases are multiples of π
4 . The variance diagram is of
course only Clifford+T if the ansatz is (not considering parametrised spiders), but this is the case
for almost all ans¨atze used in practice.

5.3.
Numerical Barren Plateau Detection
73
which in turn allows us to use the ZX contraction techniques from Kissinger et al. [65]
to compute the scalar represented by the diagram. Originally developed for classical
simulation of quantum circuits, they employ decompositions of so-called magic states
and cat states to successively simplify ZX diagrams leading to a runtime of O(2αt)
where α ≈0.396 and t is the number spiders with phase ±π
4 or ±3π
4 .
Thus, contracting the variance diagram from Theorem 5.1 using this method has
complexity O(24α(p−1)) where p is the number of parameters in the ansatz. While the
runtime scales exponentially, in practice the method is fast enough to handle a wide
range of ans¨atze. Concretely, all experiments in this section combined take roughly
two hours to run using a single core on a standard desktop computer equipped with
an Intel Core i7-8700k and 16Gb of RAM. Furthermore, the execution speeds up
linearly by utilising multiple CPU cores.
We implement the ans¨atze from Figure 5.1 and 5.2, and the variance diagram from
Theorem 5.1 in the Rust programming language using the QuiZX library [17]. Note
that QuiZX uses cyclotomic rational numbers [66] and has a special treatment for
powers of
√
2. Therefore, all scalars that occur during the ZX contraction can be
represented exactly, thus avoiding the imprecisions of floating point arithmetic.
Finally, we want to point out that one could also compute Var

∂⟨H⟩
∂θi

by computing
the gradient ∂⟨H⟩
∂θi for many random parameter samples using the shift rules discussed
in Chapter 4 and then compute the numerical variance. However, this would require
actually running the circuit on a quantum device or simulator for a large number
of shots. Furthermore, this method only yields noisy estimates of the variance (in
particular when using a NISQ device) whereas our tool computes exact values for
Var

∂⟨H⟩
∂θi

.
5.3.2
Note on Zero Variance
Before discussing our numerical results, we remark that we sometimes observe
Var

∂⟨H⟩
∂θi

= 0, meaning that the gradient is constant. We show in Section 5.4.2

74
Barren Plateaus
2
4
6
8
10
12
14
16
18
20
22
24
Number of qubits n
2−23
2−19
2−15
2−11
2−7
2−3
Var

∂⟨H⟩
∂θ1

Sim1
Sim2
Sim9
Sim10
Sim11
Sim12
Sim15
Figure 5.3: Gradient variance as function of qubits for a single layer of the different
Sim ans¨atze for the Hamiltonian H = Z⊗n. Concretely, the variance Var(∂⟨H⟩
∂θ1 ) for
the first parameter θ1 (i.e. the top-left rotations in Figure 5.1) is plotted. Note that
the y-axis has a logarithmic scale.
that in those cases the gradient is actually zero, meaning that varying the parameter
θi does not change ⟨H⟩. A trivial example of this is using the Hamiltonian H = I⊗n,
i.e. performing no measurement. However, there are also non-trivial cases where
some parameters do not influence the expectation value. Training such parameters
is of course pointless.
Therefore, we can exclude them from the barren plateau
analysis. See Remark 5.10 for more details on this.
5.3.3
Results
Sim Ans¨atze
We begin by analysing the Sim ans¨atze from Figure 5.1. Figure 5.3 shows the gradi-
ent variance for a single layer of the circuits when measuring with the Hamiltonian
H = Z⊗n. As we can see, the gradient variance of all ans¨atze seems to vanish expo-
nentially with increasing n. This suggests that the Sim ans¨atze have barren plateaus
for H = Z⊗n, even when using only a single layer.
However, note that Figure 5.3 only plots the gradient variance w.r.t. the first pa-
rameter θ1. It might be the case that other parameters do not vanish exponentially

5.3.
Numerical Barren Plateau Detection
75
2
6
10
14
18
22
n
2−22
2−18
2−14
2−10
2−6
2−2
Variance for θ2
2
6
10
14
18
22
n
2−23
2−19
2−15
2−11
2−7
2−3
Variance for θ3
2
6
10
14
18
22
n
2−22
2−18
2−14
2−10
2−6
2−2
Variance for θ4
2
6
10
14
18
22
n
2−23
2−19
2−15
2−11
2−7
2−3
Variance for θ5
2
6
10
14
18
22
n
2−24
2−20
2−16
2−12
2−8
2−4
Variance for θ6
2
6
10
14
18
22
n
2−24
2−20
2−16
2−12
2−8
2−4
Variance for θ7
2
6
10
14
18
22
n
2−22
2−18
2−14
2−10
2−6
Variance for θ8
2
6
10
14
18
22
n
2−24
2−20
2−16
2−12
2−8
2−4
Variance for θ9
Sim1
Sim2
Sim9
Sim10
Sim11
Sim12
Sim15
Figure 5.4: Gradient variance for different parameters θi as a function of qubits for
a single layer of the different Sim ans¨atze for the Hamiltonian H = Z⊗n. We do not
plot points if the parameter does not exist or Var(∂⟨H⟩
∂θi ) = 0.

76
Barren Plateaus
which would make learning possible. To investigate this, we run the same experi-
ment for different parameters θi. The results are shown in Figure 5.4. As we can
see, as long as Var

∂⟨H⟩
∂θi

̸= 0 we get exponentially vanishing variances for all cases.
This leads us to stating the following hypothesis:
Hypothesis 5.3. For H = Z⊗n, all single-layer Sim ans¨atze from Figure 5.1 have
barren plateaus on all parameters.
This matches with the expressiveness results computed by Sim et al.
[20]: All
ans¨atze in Figure 5.1 have a similar expressiveness for a single layer. Differences in
expressiveness only show up when additional layers are added, with some circuits
gaining more expressiveness by this than others. However, our experiments suggest
that even a single layer already suffices to generate barren plateaus.
We want to stress that just looking at graphs is of course not a proof for the existence
of a barren plateau. It could for example be the case that the curve in Figure 5.3
starts to flatten after some point n0 outside of the range we investigated. However,
the number of qubits used in QML experiments today is limited. Thus, in practical
terms, the variance behaviour for small n is most relevant to make statements about
the trainability of ans¨atze.
Here, our experiments suggest that the Sim ans¨atze
scale badly and might benefit from using barren plateau mitigation techniques (see
Section 5.5).
While our empirical results are of practical use, there is also significant value in for-
mal statements regarding the existence of barren plateaus. We turn to this question
in Section 5.4 where we formally analyse Sim1, Sim2, and Sim9 and prove Hypothe-
sis 5.3 for those three ans¨atze. Furthermore, we generalise to arbitrary Hamiltonians,
moving beyond the case H = Z⊗n considered here.

5.3.
Numerical Barren Plateau Detection
77
2
4
6
8
10
12
14
16
18
20
22
24
Number of qubits n
2−20
2−15
2−10
2−5
20
Var

∂⟨H⟩
∂θ1

IQP1
IQP2
IQP3
Figure 5.5: Gradient variance as a function of qubits for a single layer of the different
IQP ans¨atze. We do not plot points if Var(∂⟨H⟩
∂θi ) = 0.
IQP Ans¨atze
We run similar experiments for a single layer of IQP1, IQP2, and IQP3.2
How-
ever, while we still use the Hamiltonian H = Z⊗n for IQP1, we use an alternating
Hamiltonian H = Y ⊗X ⊗Y ⊗X... for IQP2 and IQP3. This is because we get
Var(∂⟨H⟩
∂θi ) = 0 otherwise.3 The results are shown in Figure 5.5. Similar to the Sim
ans¨atze, IQP2 and IQP3 appear to have exponentially vanishing gradient variances.
Surprisingly, rerunning the experiment for different parameters θi yields the exact
same numerical variance values.4 Thus, we make the following hypothesis:
Hypothesis 5.4. A single layer of IQP2 and IQP3 has barren plateaus on all pa-
rameter for H = Y ⊗X ⊗Y ⊗X....
However, the more interesting observation from Figure 5.5 is that the gradient vari-
ance of IQP1 does not vanish. To investigate whether using more than one layer
makes a barren plateau appear, we rerun the IQP1 experiment for increasing num-
bers of layers. But the results in Figure 5.6 show that this is not the case. While
adding more layers changes the variance, it stays constant with increasing n. Fi-
nally, we plot the variance for n = 3 as a function of ℓin Figure 5.7. As we can see,
2We cannot apply our method to IQP4 since multiple spiders share the same parameter, however
we will derive some theoretical results in Section 5.4.6.
3For a theoretical explanation of this see the proof of Theorem 5.18.
4We will prove later that this is in fact true for all single layer IQP ans¨atze (see Theorem 5.16
and Remark 5.17).

78
Barren Plateaus
2
6
10 14 18 22
n
0.24
0.25
0.26
Var

∂⟨H⟩
∂θ1

ℓ= 2
IQP1
2
6
10
14
18
22
n
0.36
0.38
ℓ= 3
IQP1
2
6
10
14
18
22
n
0.30
0.32
ℓ= 4
IQP1
Figure 5.6: Gradient variance of IQP1 as a function of qubits for different number
of layers ℓ. We do not plot points if Var(∂⟨H⟩
∂θi ) = 0.
1
3
5
7
9
11
13
15
17
19
Number of layers ℓ
0.3
0.4
0.5
Var

∂⟨H⟩
∂θ1

n = 3
IQP1
Figure 5.7: Gradient variance of IQP1 as a function of layers for n = 3.
the variance seems to converge with increasing ℓ. To summarise, we can make the
following hypothesis:
Hypothesis 5.5. IQP1 does not have barren plateaus for H = Z⊗n. More specifi-
cally, the variance for θ1 is constant in n and converges for ℓ→∞.
Again following the trade-off described by Holmes et al. [11], this observation might
be explained by the fact that IQP1 is a very simple ansatz with limited expressive-
ness.
We will prove both Hypothesis 5.4 and Hypothesis 5.5 in in the next section (see
Theorem 5.18 and Corollary 5.25).

5.4.
Analytical Barren Plateau Detection
79
5.4
Analytical Barren Plateau Detection
After investigating the gradient landscape of ans¨atze numerically, we now turn to the
formal analysis of barren plateaus using Theorem 5.1. For this, we introduce a bit
of terminology to refer to the structure of the variance diagram from Theorem 5.1:
Note that it is made up of two main building blocks which we call cycles:
π
π
π
The left cycle is plugged into the positions corresponding to the variance parameter
θi. The right cycle with the triangle is plugged into every other position, corre-
sponding to parameters θj with j ̸= i. The remainder of this section will largely
be concerned with simplifying those kinds of cycles for different expectation value
diagrams plugged in the middle. This will allow us to contract the diagram and
obtain a numerical value for the variance as a function of n or ℓ.
We make use of the following two lemmas throughout this section:
Lemma 5.6. For all x, y ∈{0, 1} we have
xπ
yπ
π
α...
...
...
=
xπ
yπ
α + π
...
π
...
...
α
β
π
xπ
...
...
...
=
α
β
π
xπ + π
...
...
...
(5.1)
Proof. See Appendix C.
↓
Lemma 5.7.
α
β
π
π
...
...
...
= eiα
β −α
π
π
...
...
π
π
...
...
...
n
= 2n−1
π
π
...
...
(5.2)
Proof. See Appendix C.
↓

80
Barren Plateaus
5.4.1
Introductory Example
Before discussing the Sim and IQP ans¨atze, we first show how to diagrammatically
compute the variance of a smaller example ansatz:
U(θ1, θ2) =
...
n
θ1
θ2
For the Hamiltonian H = X⊗n, we get the following expectation value:
⟨H⟩=
...
π
π
π
...
θ1
θ2
−θ2
−θ1
=
...
π
π
π
θ1
θ2
...
−θ1
−θ2
(cc,sf ,id)
=
1
2n
...
π
π
π
θ2
−θ2
θ1
−θ1
(cc)
=
1
4n
...
π
π
π
θ2
−θ2
θ1
−θ1
(cc)
=
2n−1
4n
...
π
π
π
θ2
−θ2
θ1
−θ1
(sf )
=
1
2n+1
...
π
π
π
θ2
−θ2
θ1
−θ1
...
...
(5.1)
=
1
4
nπ
θ2
−θ2
θ1
−θ1
...
...
π
(ho)
=













1
4
θ2
−θ2
θ1
−θ1
π
if n is even
1
4
π
θ2
−θ2
θ1
−θ1
π
if n is odd

5.4.
Analytical Barren Plateau Detection
81
(sf )
=







0
if n is even
1
4
π
θ2
−θ2
θ1
−θ1
π
if n is odd
If n is even, we have ⟨H⟩= 0 and thus ∂⟨H⟩
∂θ1
= ∂⟨H⟩
∂θ2
= 0 such that Var

∂⟨H⟩
∂θ1

=
Var

∂⟨H⟩
∂θ2

= 0. If n is odd, we can calculate the variance of ∂⟨H⟩
∂θi diagrammatically
using Theorem 5.1:
Var
∂⟨H⟩
∂θ1

=
1
16
π
π
π
π
π
π
π
(sf ,5.1)
=
1
16
π
π
π
π
π
π
π
π
(id,π,sf )
=
−1
16
π
π
π
π
(sf ,id)
=
−1
8
π
π
π
π
(cc)
=
−1
8
π
π
π
π
(π,sf )
=
−1
8
π
π
(sf ,ho)
=
−1
8
π
π
(tri)
=
−1
8
π
π
= −1
8 · (−1) · 2 = 1
4
Similarly, for ∂⟨H⟩
∂θ2 we get
Var
∂⟨H⟩
∂θ2

=
1
16
π
π
π
π
π
π
π
(id,cc)
=
1
32
π
π
π
π
π
π
π

82
Barren Plateaus
(cc)
=
1
32
π
π
π
π
π
π
π
(sf )
=
1
32
π
π
π
π
π
(5.2)
=
1
16
π
π
π
π
(5.2)
=
1
8
π
π
(sf ,ho)
=
1
8
π
π
(5.1,cp,sf )
=
1
8
π
π
π
π
= 1
4
π
π
= 1
4 · 1 · 1 = 1
4
In both cases, the variance of the gradient does not vanishes exponentially. Thus,
we can conclude that the barren plateau phenomenon does not appear in this ansatz
when measuring using the Hamiltonian H = X⊗n. The diagrammatic calculation
in this example was relatively straightforward since the ansatz U(θ1, θ2) has a fixed
number of parameters, independent of the number of qubits n. Next, we will consider
ans¨atze where the number of parameters increases when increasing n.
5.4.2
Sim 1
A single layer of Sim1 can be represented in the ZX-calculus as
Sim1(⃗θ) =
θ1
1
θ2
1
θ1
n
θ2
n
...
Given some Hamiltonian H, the corresponding expectation value is given by
⟨H⟩=
θ1
1
θ2
1
θ1
n
θ2
n
...
H
−θ1
1
−θ2
1
−θ1
n
−θ2
n
...
(sf ,cc)
=
1
2n
θ1
1
θ2
1
θ1
n
θ2
n
...
θ1
1
θ2
1
θ1
n
θ2
n
...
H

5.4.
Analytical Barren Plateau Detection
83
(sf ,id)
=
1
2n
θ1
1
θ2
1
θ1
n
θ2
n
...
θ1
1
θ2
1
θ1
n
θ2
n
...
H
Recall that each Hamiltonian can be written as a sum of Pauli strings {X, Y, Z, I}⊗n.
Thus, it suffices to compute Var

∂⟨H⟩
∂θi

for H = P1⊗...⊗Pn where Pj ∈{X, Y, Z, I}.
To make the following derivations more concise, we represent all three cases in a
single diagram
Pj
= iajbj
ajπ
bjπ
where
aj =
(
1
if Hj = Y, Z
0
if Hj = X, I
bj =
(
1
if Hj = X, Y
0
if Hj = Z, I.
Thus, we can write the expectation value as
⟨H⟩= i
P ajbj
2n
θ1
1
θ2
1
θ1
n
θ2
n
...
θ1
1
θ2
1
θ1
n
θ2
n
a1π
b1π
anπ
bnπ
Next, we consider the different types of cycles that show up in the variance diagram:
Lemma 5.8. We have
(−1)aibi
aiπ
biπ
aiπ
biπ
π
π
π
=





0
if Hi = I
1
if Hi = Y, X
2
if Hi = Z
(−1)aibi
aiπ
biπ
aiπ
biπ
π
π
π
=
(
0
if Hi = Z, I
1
if Hi = X, Y

84
Barren Plateaus
(−1)aibi
aiπ
biπ
aiπ
biπ
=





1
if Hi = X
2
if Hi = Z, Y
4
if Hi = I
Proof. See Appendix C.
↓
This leads to the following result regarding the variance of the gradients:
Fact 5.9. Let hP = |{Hj | Hj = P, j ∈{1, ..., n} \ {i}}| be the number of times the
Pauli P ∈{X, Y, Z, I} occurs in H, excluding the position Hi. Then
Var
∂⟨H⟩
∂θ1
i

=





0
if Hi = I
1
4n · 2hZ+hY · 4hI
if Hi = X, Y
2
4n · 2hZ+hY · 4hI
if Hi = Z
Var
∂⟨H⟩
∂θ2
i

=
(
0
if Hi = Z, I
1
4n · 2hZ+hY · 4hI
if Hi = X, Y
Proof. We start with the first equation where the gradient is w.r.t. θ1
i . By Theo-
rem 5.1, Var

∂⟨H⟩
∂θ1
i

is given by
(−1)
P ajbj
aiπ
biπ
aiπ
biπ
π
π
π
a1π
b1π
a1π
b1π
...
...
anπ
bnπ
anπ
bnπ
...
...
...
...
...
...

5.4.
Analytical Barren Plateau Detection
85
Note that the different cycles are not connected with each other, which means we
can arrange them as follows:
(−1)
P ajbj
aiπ
biπ
aiπ
biπ
π
π
π
a1π
b1π
a1π
b1π
anπ
bnπ
anπ
bnπ
...
B
A
By Lemma 5.8, we have
A =





0
if Hi = I
1
if Hi = Y, X
2
if Hi = Z
B =
n
Y
j=1
j̸=i





1
if Hj = X
2
if Hj = Z, Y
4
if Hj = I
= 1hX · 2hZ+hX · 4hI
such that A · B corresponds to desired equation. The proof for Var

∂⟨H⟩
∂θ2
i

is anal-
ogous.
Remark 5.10. One might wonder why the variance is zero in some of the cases. If
Hi = I, this corresponds to performing no measurement on qubit i. In this case, the
value ⟨H⟩actually does not depend on θ1
i and θ2
i since
θ1
i
θ2
i
−θ1
i
−θ2
i
I
=
θ1
i
θ2
i
−θ1
i
−θ2
i
(sf )
=
.
Therefore, we have
∂⟨H⟩
∂θ1
i
=
∂⟨H⟩
∂θ2
i
= 0 and thus Var

∂⟨H⟩
∂θ1
i

= Var

∂⟨H⟩
∂θ2
i

= 0.
Similarly, if Hi = Z we have
θ1
i
θ2
i
−θ1
i
−θ2
i
Z
=
θ1
i
θ2
i
−θ1
i
−θ2
i
π
(sf )
=
θ1
i
−θ1
i
π
such that θ2
i does not contribute to the expectation value and thus Var

∂⟨H⟩
∂θ2
i

= 0.

86
Barren Plateaus
Finally, Fact 5.9 immediately yields the condition for Sim1 to have a barren plateau:
Theorem 5.11. The barren plateau phenomenon appears in Sim1 if we measure on
Θ(n) qubits. In particular, this implies Hypothesis 5.3 for Sim1.
Proof. By Fact 5.9, the variance for all parameters (ignoring the scalar 2 in the
case θ1
i ) is either 0 or
2hZ+hY · 4hI
4n
=
1
22n−hZ−hY −2hI =
1
22hX+hY +hZ
Since we measure on Θ(n) qubits, we must have 2hX + hY + hZ = Θ(n) such that
the variance vanishes exponentially.
5.4.3
Sim 2
A single layer of Sim2 can be represented in the ZX-calculus as
Sim2(⃗θ) =
θ1
1
θ2
1
θ1
3
θ2
3
...
θ1
n
θ2
n
...
θ1
1
θ2
1
Using the same representation for a Hamiltonian H as in Section 5.4.2, we can write
the expectation value as
⟨H⟩= i
P ajbj
b1π
a1π
b2π
a2π
bnπ
anπ
...
θ1
1
θ2
1
θ1
3
θ2
3
...
θ1
n
θ2
n
...
θ1
1
θ2
1
−θ1
1
−θ2
1
−θ1
3
−θ2
3
...
−θ1
n
−θ2
n
...
−θ1
1
−θ2
1
b3π
a3π
(π,sf )
=
i
P ajbj
(P1
j=1 aj)π
(P2
j=1 aj)π
(Pn
j=1 aj)π
...
θ1
1
θ2
1
θ1
3
θ2
3
...
θ1
n
θ2
n
...
θ1
1
θ2
1
−θ1
1
−θ2
1
−θ1
3
−θ2
3
...
−θ1
n
−θ2
n
...
−θ1
1
−θ2
1
(P3
j=1 aj)π
(Pn
j=1 bj)π
(Pn
j=2 bj)π
(Pn
j=n bj)π
(Pn−2
j=3 bj)π

5.4.
Analytical Barren Plateau Detection
87
(sf ,ho,id)
=
i
P ajbj
(Pn
j=1 bj)π
(P1
j=1 aj)π
(Pn
j=2 bj)π
(P2
j=1 aj)π
(Pn
j=n bj)π
(Pn
j=1 aj)π
...
θ1
1
θ2
1
θ1
3
θ2
3
...
θ1
n
θ2
n
θ1
1
θ2
1
−θ1
1
−θ2
1
−θ1
3
−θ2
3
...
−θ1
n
−θ2
n
−θ1
1
−θ2
1
(Pn−2
j=3 bj)π
(P3
j=1 aj)π
Notice that this diagram has the same shape as the expectation value for Sim1. In
fact, the only difference is the Hamiltonian in the middle, which in this case is given
by
H′
i =


n
X
j=i
bj

X ·


i
X
j=1
aj

Z.
In other words, ⟨H⟩Sim2 = ⟨H′⟩Sim1. Thus, we can use Theorem 5.11 to characterise
the barren plateaus in Sim2:
Theorem 5.12. The barren plateau phenomenon appears in Sim2 if H′
i ̸= I at Θ(n)
positions. In particular, this implies Hypothesis 5.3 for Sim2.
Proof. Follows from Theorem 5.11. Note that for H = Z⊗n we have H′ = Z ⊗I ⊗
Z ⊗I... such that the theorem applies and Hypothesis 5.3 is true.
5.4.4
Sim 9
Sim9 can be represented in the ZX-calculus as
Sim9(⃗θ) =
√
2
n−1
...
θ1
θ2
θ3
θn
...
yielding the expectation value
⟨H⟩= 2n−1i
P ajbj
...
θ1
θ2
θ3
θn
...
−θ1
−θ2
−θ3
−θn
b1π
a1π
b2π
a2π
bnπ
anπ
...
b3π
a3π

88
Barren Plateaus
(cc,sf )
=
i
P ajbj
2
θ1
θ2
θ3
θn
−θ1
−θ2
−θ3
−θn
b1π
a1π
b2π
a2π
bnπ
anπ
...
b3π
a3π
(sf ,cc)
=
i
P ajbj
2n+1
θ1
θ2
θ3
θn
−θ1
−θ2
−θ3
−θn
b1π
a1π
b2π
a2π
bnπ
anπ
...
b3π
a3π
...
...
As before, we consider how the cycles simplify:
Lemma 5.13. We have
(−1)aibi
biπ
aiπ
...
...
biπ
aiπ
...
...
π
π
π
=











0
if Hi = I, X
...
π
π
...
...
π
π
...
if Hi = Y, Z
(−1)aibi
biπ
aiπ
...
...
biπ
aiπ
...
...
=





















4
biπ
...
...
biπ
...
...
if Hi = I, X
2
π
π
...
π
π
...
...
...
if Hi = Y, Z
Proof. See Appendix C.
↓
Unfortunately, this makes it difficult to give a closed-form expression of the gradient
variance in terms of a general Hamiltonian H as we have done in Fact 5.9. However,
we can easily investigate concrete instances. For example we can verify Hypothesis
Hypothesis 5.4 for Sim9:
Theorem 5.14. Hypothesis 5.3 holds for Sim9, i.e. Sim9 has barren plateaus for
H = Z⊗n.
Proof. By Theorem 5.1, we have

5.4.
Analytical Barren Plateau Detection
89
Var
∂⟨H⟩
∂θi

=
1
22n+2
π
π
π
...
...
...
...
...
...
π
π
π
...
...
...
...
...
...
π
π
π
...
...
...
...
Using Lemma 5.13, we can simplify this to
2n−1
22n+2
π
π
π
π
...
...
...
...
π
π
...
...
...
...
π
π
π
π
Position i
(2.14)
=
2n−1
23n+2
X
⃗x∈{0,1}n
x1π
x1π
x1π + π
x1π + π
x2π
x2π
x2π + π
x2π + π
...
...
...
...
xiπ
xiπ + π
xiπ + π
xiπ
...
...
...
...
xnπ
xnπ
xnππ
xnπ + π
Each of those “lines” can only represent the scalars 0, ±1, and ±2. Thus
Var
∂⟨H⟩
∂θi

≤2n−1
23n+2
X
⃗x∈{0,1}n
16 = 2n−1
23n+2 · 2n · 16 =
1
2n−1
such that we have a barren plateau.
5.4.5
Single-Layer IQP Ans¨atze
After discussing some of the Sim ans¨atze, we now move to IQPs. In this section, we
prove a general result that allows us to compute the gradient variance of any single-

90
Barren Plateaus
layer IQP circuit with single parameter occurrences. To motivate our approach, we
first look at an example IQP circuit:
U(⃗θ) =
θ1
θ2
θ3
(5.3)
The corresponding diagram for the expectation value is given by
⟨H⟩= i
P ajbj
θ1
θ2
θ3
−θ1
−θ2
−θ3
b1π
a1π
b2π
a2π
b3π
a3π
b4π
a4π
(cc,hh)
=
i
P ajbj
24
θ1
θ2
θ3
−θ1
−θ2
−θ3
b1π
a1π
b2π
a2π
b3π
a3π
b4π
a4π
(π,sf )
=
i
P ajbj
24
θ1
θ2
θ3
(a2 + a3 + a4)π
(a1 + a3 + a4)π
(a2 + a3)π
−θ1
−θ2
−θ3
b1π
b2π
b3π
b4π
(sf )
=
i
P ajbj
24
θ1
θ2
θ3
(a2 + a3 + a4)π
(a1 + a3 + a4)π
(a2 + a3)π
−θ1
−θ2
−θ3
b1π
b2π
b3π
b4π
The main insight is that the cycles for diagrams of this shape simplify nicely:
Lemma 5.15. The cycles from single-layer IQP circuits simplify as follows:

5.4.
Analytical Barren Plateau Detection
91
bi1π
bimπ
...
...
bi1π
bim
...
...
π
π
π
...
...
= 0
bi1π
bimπ
...
...
π
bi1π
bim
...
...
π
π
π
π
...
...
=
bi1π
bimπ
...
...
bi1π
bimπ
...
...
π
...
...
bi1π
bimπ
...
...
bi1π
bim
...
...
...
...
=
bi1π
bimπ
...
...
...
bi1π
bimπ
...
...
...
bi1π
bimπ
...
...
π
bi1π
bim
...
...
π
...
...
=
bi1π
bimπ
...
...
bi1π
bimπ
...
...
π
...
...
Proof. See Appendix C.
↓
To illustrate the application of Lemma 5.15, we show how to compute Var

∂⟨H⟩
∂θ2

for
the example circuit (5.3) for the Hamiltonian H = X ⊗Z ⊗X ⊗Y which corresponds
to a1 = b2 = a3 = 0 and b1 = a2 = b3 = b4 = a4 = 1 yielding the expectation value
⟨H⟩=
i
24
θ1
θ2
θ3
π
π
−θ1
−θ2
−θ3
π
π
π
(5.4)
Invoking Theorem 5.1 we get the following diagram for Var

∂⟨H⟩
∂θ2

:

92
Barren Plateaus
−1
28
π
π
π
π
π
π
π
π
π
π
π
π
π
(Lem. 5.15)
=
−1
28
π
π
π
π
π
π
π
π
π
(Lem. 5.15)
=
−1
28
π
π
π
π
π
π
π
π
π
(Lem. 5.15)
=
−1
28
π
π
π
π
π
π
π
π
(cp,sf )
=
−1
28
π
π
π
π
π
π
π
(cp,sf )
=
1
28
= 1
4
Generalising to arbitrary IQPs
Following the technique from the example circuit, we can compute the variance for
arbitrary single-layer IQP circuits. In the general case, our ansatz U(⃗θ) consists of
m phase gadgets, given by exponentials of Pauli strings P1, ..., Pm ∈{I, Z}⊗n:
U(⃗θ) =
P 1
1
P n
1
...
P 1
m
P n
m
...
...
θ1
θm

5.4.
Analytical Barren Plateau Detection
93
Furthermore fix a Hamiltonian H and define
ki =
X
1≤j≤n
P j
i =Z
aj
such that
⟨H⟩= i
P ajbj
P 1
1
P n
1
...
P 1
m
P n
m
...
...
θ1
θm
P 1
1
P n
1
...
P 1
m
P n
m
...
...
−θ1
−θm
a1π
a1π
a1π
a1π
(cc,hh)
=
i
P ajbj
2n
P 1
1
P n
1
...
P 1
m
P n
m
...
...
θ1
θm
P 1
1
P n
1
...
P 1
m
P n
m
...
...
−θ1
−θm
a1π
b1π
a1π
b1π
(π,sf )
=
i
P ajbj
2n
P 1
1
P n
1
...
P 1
m
P n
m
...
...
θ1
θm
P 1
1
b1π
k1π
P n
1
bnπ
...
P 1
m
kmπ
P n
m
...
...
−θ1
−θm
(sf )
=
i
P ajbj
2n
b1π
...
biπ
...
kjπ
θj
−θj
Qubit where Pj has a leg
Connect all ±θj
spiders as follows:
...
...
b1π
...
...
Compare this with (5.4): The green spiders in the middle represent one qubit each.
Furthermore, we get pink spiders on the left and right side for each parameter θj.
Those pink spiders are connected to all the qubits where the gadget associated with
θj has legs.
This leads to the following characterisation of the variance:

94
Barren Plateaus
Theorem 5.16. If ki = 0, then Var

∂⟨H⟩
∂θi

= 0. If ki = 1, then
Var
∂⟨H⟩
∂θi

= (−1)
Pn
j=1 ajbj
4n
b1π
bnπ
...
...
Qubit where Pj has a leg
b1π
bnπ
...
blπ
blπ
...
π
For all j with kj = 1:
...
...
...
...
...
...
blπ
blπ
...
...
...
...
Proof. Follows by simplifying the cycles in the variance diagram according to
Lemma 5.15.
Remark 5.17. A remarkable consequence of Theorem 5.16 is that the variance for
every parameter is either zero, or the same as all other parameters with non-zero
variance. Thus, when determining whether an ansatz exhibits the barren plateau
phenomenon, it suffices to look at a single parameter whose gradient has non-zero
variance.
Using Theorem 5.16, we can analyse the IQP ans¨atze for barren plateaus:
Theorem 5.18. Hypothesis 5.4 is true, i.e. we get the following results for single-
layer IQPs:
• IQP1 does not have barren plateaus.
• IQP2 has barren plateaus for H = (Y ⊗X)⊗n/2.
• IQP3 has barren plateaus for H = (Y ⊗X)⊗n/2.
Proof.
• IQP1: If k = P aj = 0, we get Var

∂⟨H⟩
∂θ

= 0. If k = 1, Theorem 5.16 gives
us

5.4.
Analytical Barren Plateau Detection
95
Var
∂⟨H⟩
∂θ

= (−1)
P ajbj
4n
b1π
b2π
bnπ
...
π
b1π
b2π
bnπ
...
(cp,sf )
=
(−1)
P ajbj
4n
(−1)b1
(b1 + b2)π
(b1 + bn)π
...
(b1 + b2)π
(b1 + bn)π
...
This is either 0, or 1
2. Thus, the variance does not vanish exponentially.
• IQP2: For IQP2, we have k1 = a1 + a2, k2 = a3 + a4, ..., kn/2 = an−1 + an. By
Theorem 5.16 we get Var

∂⟨H⟩
∂θi

= 0 if ki is even. Otherwise
Var
∂⟨H⟩
∂θi

= (−1)
P ajbj
4n
...
b3π
b4π
...
b3π
b4π
π
bn−1π
bnπ
bn−1π
bnπ
π
b1π
b2π
b1π
b2π
π
exists if k1 is odd, i.e. a1 ̸= a2
exists if k2 is odd, i.e. a3 ̸= a4
exists if kn/2 is odd, i.e. an−1 ̸= an
where the pink spiders only exist if the annotated condition is met. Concretely,
for H = (Y ⊗X)⊗n/2 we have a1 = a3 = ... = an−1 = 1, a2 = a4 = ... = an = 0,
bj = 1 for all j and hence
Var
∂⟨H⟩
∂θi

= (−1)n/2
4n

π
π
π
π
π
n/2
(cp)
=
(−1)n/2
4n

−
n/2
= 8n/2
4n
=
1
2n/2 .
Note that this exactly matches with the numerical data from Figure 5.5. We
conclude that we have a barren plateau.
• IQP3: Again, Theorem 5.16 yields

96
Barren Plateaus
Var
∂⟨H⟩
∂θi

= (−1)⌊n/2⌋
4n
π
π
π
π
π
π
π
π
π
π
π
π
π
...
...
(cp,sf )
=
−(−1)⌊n/2⌋
4n
π
π
π
π
π
π
π
π
...
...
(cp,sf )
=
−(−1)⌊n/2⌋
4n
π
π
π
π
π
π
π
...
...
= ... =
1
4n
...
π
only if n is odd
Thus, if n is odd we get variance 0. If n is even we get variance 2n
4n =
1
2n . This
exactly matches with the numerical data from Figure 5.5. Thus, we have a
barren plateau.
5.4.6
Dealing with multiple parameter occurrences
The biggest limitation to the current ZX based analysis of barren plateaus is the
fact that Theorem 5.1 only applies if each parameter occurs once in the diagram.
However, many circuits of interest (for example IQP4) require multiple spiders with
the same parameter.
Ideally, one would want alternate versions of Theorem 5.1
that support all possible combinations of parameter occurences. This would require
extending and generalising the integration results by Wang an Yeung [19]. While this
is principally possible using the summing technique from [18], the main challenge is
finding a representation that is amenable to rewriting and offering a way to break
up cycles.
In this section, we describe a trick that can sometimes be used instead to compute
variances using Theorem 5.1, even if parameters occur multiple times. The idea
is that in some special cases, one can choose a Hamiltonian for which the extra
parameter occurrences cancel out. We demonstrate this using the IQP4 ansatz with
the Hamiltonian H = Z⊗n. In this case, we can rewrite the expectation value as
follows:

5.4.
Analytical Barren Plateau Detection
97
⟨H⟩=
θ1
θ2
...
−θn−1
θn−1
−θ1
−θ2
−θn−2
π
π
π
π
π
−θ1
−θ2
...
θn−1
−θn−1
θ1
θ2
θn−2
(cc)
=
θ1
θ2
...
−θn−1
θn−1
−θ1
−θ2
−θn−2
π
π
π
π
π
−θ1
−θ2
...
θn−1
−θn−1
θ1
θ2
θn−2
(sf ,π)
=
θ1
θ2
...
−θn−1
θn−1
−θ1
−θ2
−θn−2
π
π
π
π
π
−θ1
−θ2
...
−θn−1
...
θn−1
θ1
θ2
θn−2
(Lem. 2.12)
=
...
−θn−1
−θ1
−θ2
−θn−2
π
π
π
π
π
...
θn−1
θ1
θ2
θn−2
(cp,sf )
=
...
−θn−1
−θ1
−θ2
−θn−2
π
π
π
π
π
...
θn−1
θ1
θ2
θn−2
=
...
−θn−1
−θ1
−θ2
−θn−2
π
π
π
π
...
θn−1
θ1
θ2
θn−2
Thus, we got rid of all two-legged phase gadgets. This is now amenable for barren
plateau analysis using Theorem 5.1 and Lemma 5.15:
Theorem 5.19. The barren plateau phenomenon appears in IQP4 for H = Z⊗n.
Proof. By Theorem 5.1 and Lemma 5.15, we have
Var
∂⟨H⟩
∂θi

=
1
4n−1
...
...
π
π
n −1
(cp,sf )
=
1
4n−1
...
n −1 = 2n−1
4n−1 =
1
2n−1 .

98
Barren Plateaus
5.4.7
Commuting Multi-Layer IQP Ans¨atze
So far, we only studied single-layered circuits. In this section we analyse a special
case where the multi-layers analysis of IQPs is straightforward. Note that since the
layers are separated by Hadamards, we can view multi-layer IQPs as alternating
layers of Z- and X-Pauli exponentials.
For example, consider IQP2 for an even
number of layers:
IQP2(⃗θ) =
θ1
1
...
θ1
n/2
θ2
1
...
θ2
n/2
θℓ
1
...
θℓ
n/2
...
...
=
X
X
θ1
1
Z
Z
θ2
1
Z
Z
θℓ
1
...
X
X
θ1
n−1
Z
Z
θ2
n−1
Z
Z
θℓ
n−1
...
...
...
...
X
X
θ3
1
X
X
θ3
n−1
...
Recalling the commutation properties of Pauli boxes (see Lemma 2.10), we see that
X- and Z-layers commute with each other for this ansatz.
In this special case,
computing the variance is actually not difficult since we can fuse all odd and even
layers together via Lemma 2.9:
IQP2(⃗θ) =
X
X
θ1
1 + θ3
1 + ...
Z
Z
X
X
θ1
n−1 + θ3
n−1 + ...
Z
Z
...
...
θ2
1 + θ4
1 + ...
θ2
n−1 + θ4
n−1 + ...
As a result, an ℓ-layer IQP2 circuit with even ℓ5 is equivalent to a 2-layer IQP2
circuit. The barren plateau analysis in this case is straightforward:
5We focus on the case where ℓis even. For odd ℓ, the derivations are orthogonal, noting that
the fused second layer will not have Hadamards at the end.

5.4.
Analytical Barren Plateau Detection
99
Theorem 5.20. The barren plateau phenomenon appears in IQP2 for H = (Z ⊗
Y )⊗n/2 for any number of layers.
Proof. As discussed before, it suffices to consider the case ℓ= 2. The expectation
value is given by
⟨H⟩=
θ1
1
...
θ1
n/2
θ2
1
...
θ2
n/2
−θ1
1
...
−θ1
n/2
−θ2
1
...
−θ2
n/2
π
π
π
π
π
π
(cc,π,sf )
=
1
4n
θ1
1
...
θ1
n/2
θ2
1
...
θ2
n/2
π
π
π
−θ1
1
...
π
π
π
−θ1
n/2
−θ2
1
...
−θ2
n/2
(2.12)
=
1
4n
θ1
1
...
θ1
n/2
...
π
π
π
−θ1
1
...
π
π
π
−θ1
n/2
(cp,sf ,id,hh)
=
1
4n
θ1
1
...
θ1
n/2
π
π
π
−θ1
1
π
π
π
−θ1
n/2
This allows us to use Lemma 5.15 to remove the cycles showing up during the
variance calculation via Theorem 5.16. Concretely, we get
Var
∂⟨H⟩
∂θ1
i

= (−1)n/2
4n
...
π
π
...
π
π
π
π
π
π
π
π
n/2
(cp,sf )
=
1
4n
...
n/2 = 8n/2
4n
=
1
2n/2 .
Thus, we have a barren plateau.
This result is not surprising since we showed that the single-layer version of IQP3
already has barren plateaus (see Theorem 5.18). The more interesting question is
how IQP1 behaves for multiple layers since it does not have barren plateaus for a
single layer. Unfortunately, the layers of IQP1 only commute for an even number of
qubits. Hence, the technique discussed in this section is not applicable if n is odd.

100
Barren Plateaus
In that case, the necessary calculations become significantly more involved, which
we explore in the next section.
5.4.8
Non-Commuting Multi-Layer IQP Ans¨atze
Apart from specifically designed examples like IQP2, it is uncommon that IQP
layers fully commute.
For example, the QNLP ans¨atze IQP3 and IQP4 do not
form commuting layers in a multi-layer configuration. In that case, the variance
computation becomes significantly more difficult.
Since we have already shown
that the QNLP ans¨atze have barren plateaus even for a single layer, we will not
consider them in this section. Instead, we focus on IQP1 to demonstrate our variance
computation technique for non-commuting layers. IQP1’s layers do not commute for
odd n and its single-layer version does not have barren plateaus which makes it an
interesting case to study.
To make the diagrams more concise, we introduce the following notation to denote
layers of IQP1:
θi
Li
=
...
...
...
The diagram for the expectation value is then given by
⟨H⟩= i
P ajbj
b1π
a1π
bnπ
anπ
...
L1
Lℓ
...
L2 ...
L†
1
L†
ℓ
...
L†
2
...
Lℓ−1
L†
ℓ−1
(cp,sf ,cc)
=
i
P ajbj · (−1)d
L1
Lℓ
...
L2 ...
L′
1
L′
ℓ
c1π
cnπ
...
L′
2
...
Lℓ−1
L′
ℓ−1
where

5.4.
Analytical Barren Plateau Detection
101
kiπ
−θi
L′
i
=
...
...
...
ki =
(
a1 + ... + an
if i has same parity as ℓ
b1 + ... + bn
otherwise
ci =
(
ai
if ℓis even
bi
if ℓis odd
d =
(
0
if ℓis even
Pn
i=1 aibi
if ℓis odd
Similar to the calculations we did before, we have pushed the Hamiltonian through
the layers on the right-hand side, occasionally adding a phase of π to the phase
gadgets. The factor (−1)d is introduced because if ℓis odd, we get the following
situation after pushing the Hamiltonian through:
L′
1
b1π
bnπ
...
...
...
a1π
anπ
(cp)
=
(−1)
P ajbj
L′
1
a1π
anπ
...
...
...
= (−1)d
L′
1
c1π
cnπ
...
...
...
However, the factor (−1)d does not really matter since it cancels out when computing
the variance. In order to draw the variance diagram, we add a wire coming out of
each layer that replaces the parametrised spider:
Li
=
...
...
...
kiπ
L′
i
=
...
...
...
Note that in the following variance diagram, we only explicitly draw the cycle con-
necting Lℓand L′
ℓ. We only hint at remaining cycles using dots:
Var
∂⟨H⟩
∂θi

= (−1)
P ajbj
L1
...
L2 ...
L′
1
c1π
cnπ
...
L′
2
...
Lℓ−1
L′
ℓ−1
L1
...
L2 ...
L′
1
cnπ
c1π
...
L′
2
...
Lℓ−1
L′
ℓ−1
Lℓ
Lℓ
L′
ℓ
L′
ℓ
...
...
...
...
...
...
...
...
...
...
...
...

102
Barren Plateaus
(sf )
=
(−1)
P ajbj
L1
...
L2 ...
L′
1
c1π
cnπ
...
L′
2
...
Lℓ−1
L′
ℓ−1
L1
...
L2 ...
L′
1
cnπ
c1π
...
L′
2
...
Lℓ−1
L′
ℓ−1
...
...
...
...
...
...
...
...
...
...
...
...
kℓπ
...
...
kℓπ
We can cut this cycle using our existing simplification strategy from Lemma 5.15.
Concretely, if kℓ= 0, we get
(−1)
P ajbj
L1
...
L2 ...
L′
1
c1π
cnπ
...
L′
2
...
Lℓ−1
L′
ℓ−1
L1
...
L2 ...
L′
1
cnπ
c1π
...
L′
2
...
Lℓ−1
L′
ℓ−1
...
...
...
...
...
...
...
...
...
...
...
...
In this case, Lℓ−1 and L′
ℓ−1 are now directly next to each other and we can continue
the same argument recursively.
However, if kℓ= 1 is odd, we get a red π-spider:
(−1)
P ajbj
L1
...
L2 ...
L′
1
c1π
cnπ
...
L′
2
...
Lℓ−1
L′
ℓ−1
L1
...
L2 ...
L′
1
cnπ
c1π
...
L′
2
...
Lℓ−1
L′
ℓ−1
π
...
...
...
...
...
...
...
...
...
...
...
...
Assuming that n is odd, commuting Lℓ−1 past this will add some extra Hadamard
wires according to Lemma 2.10:

5.4.
Analytical Barren Plateau Detection
103
(−1)
P ajbj
2
L1
...
L2 ...
L′
1
c1π
cnπ
...
L′
2
...
Lℓ−1 L′
ℓ−1
L1
...
L2 ...
L′
1
cnπ
c1π
...
L′
2
...
Lℓ−1 L′
ℓ−1
π
...
...
...
...
...
...
...
...
...
...
...
...
(sf )
=
(−1)
P ajbj
2
L1
...
L2 ...
L′
1
c1π
cnπ
...
L′
2
...
L1
...
L2 ...
L′
1
cnπ
c1π
...
L′
2
...
π
kℓ−1π
...
...
kℓ−1π
...
...
...
...
...
...
...
...
Note that the two new Hadamard wires connected to the red spiders in L′
ℓ−1 come
with a scalar of
1
√
2 each. In order to proceed from here, we need a new cycle cutting
lemma that applies when the right side is connected to shared pink spider(s):
Lemma 5.21. We have
...
kiπ
...
kiπ
α1 ...
αm ...
...
=
√
2
m
...
α1 ...
αm ...
...
kiπ
...
...
kiπ
...
kiπ
π
α1 ...
αm ...
...
π
π
=
√
2
m
α1 ...
αm ...
...
kiπ + π
π
...
...
Proof. See Appendix C.
↓

104
Barren Plateaus
Note that in the special case m = 0, Lemma 5.21 exactly corresponds to Lemma 5.15.
We can now use Lemma 5.21 to simplify the cycle in the variance computation
above, also replacing the previous application of Lemma 5.15 with the more general
Lemma 5.21:
(−1)
P ajbj
√
2
L1
...
L2 ...
L′
1
c1π
cnπ
...
L′
2
...
Lℓ−2
L1
...
L2 ...
L′
1
cnπ
c1π
...
L′
2
...
Lℓ−2
Lℓ−2
Lℓ−2
kℓ−1π
kℓπ
...
...
...
...
...
...
...
...
...
...
...
...
= (−1)
P ajbj
√
2
2
L1
...
L2 ...
L′
1
c1π
cnπ
...
L′
2
...
Lℓ−3
L1
...
L2 ...
L′
1
cnπ
c1π
...
L′
2
...
Lℓ−3
Lℓ−3
Lℓ−3
kℓ−1π
kℓπ
kℓ−2π
...
...
...
...
...
...
...
...
...
...
...
...
= (−1)
P ajbj
√
2
4
L1
...
L2 ...
L′
1
c1π
cnπ
...
L′
2
...
Lℓ−4
L1
...
L2 ...
L′
1
cnπ
c1π
...
L′
2
...
Lℓ−4
Lℓ−4
Lℓ−4
kℓ−1π
kℓπ
kℓ−2π
kℓ−3π
...
...
...
...
...
...
...
...
...
...
...
...
Iterating this process for all layers yields the diagram shown in Figure 5.8 which we
evaluate using a recursive strategy. However, we only sketch the proof here, fixing
i = 1 and skipping over some details. We refer to Appendix B for the full derivation.
One can show that Var

∂⟨H⟩
∂θ1

is only non-zero if c1 = c2 = ... = cn. Furthermore,
it turns out that the value of the c’s only effects the sign of the scalar represented
by the diagram. Therefore we will ignore them here. Also note that by definition

5.4.
Analytical Barren Plateau Detection
105
(−1)
P ajbj
√
2
h
...
cnπ
c1π
k1π
...
Connected to
L2, L4, L6, ...
L1
...
kjπ
...
Connected to
Lj+1, Lj+3, ...
Lj
...
...
Lℓ
...
...
kℓπ
π
kiπ + π
...
Connected to
Li+1, Li+3, ...
Li
...
Arbitrary parameter
Variance parameter
...
...
cnπ
c1π
...
...
...
...
Hadamards only
if ℓis odd
Figure 5.8: Diagram for Var

∂⟨H⟩
∂θi

where h is the number of Hadamard wires
connecting the red spiders.
we have ki = kj if i and j have the same parity. Thus, we define the following
shorthands:
ko := k1 = k3 = k5 = ...
ke := k2 = k4 = k6 = ...
This means that the diagram in Figure 5.8 only depends on the numbers ke, ko, and
ℓ. We can show that it satisfies the following recurrence relation.
Lemma 5.22. Let Vℓ(ke, ko, c) denote the diagram in Figure 5.8 and let ℓ> 1 be
odd. Then
V1(ke, 0) = 0
V1(ke, 1) = 1
2
Vℓ(0, 0) = 0
Vℓ(0, 1) = 1
4(3Vℓ−2(0, 1) −Vℓ−2(1, 0))
Vℓ(1, 1) = Vℓ(0, 1)
Vℓ(1, 0) = 1
2(Vℓ−2(1, 0) −Vℓ−2(0, 1))
Proof. See equations (B.7), (B.14), (B.15), and (B.16) in Appendix B.
Similarly, we can obtain recursive equations for even ℓ.
This yields a recursive
algorithm for computing Var

∂⟨H⟩
∂θ1

. However, it is also possible to derive a closed-
form solution:

106
Barren Plateaus
Lemma 5.23. For odd ℓwe have
Vℓ(1, 1) = Vℓ(0, 1) = 2 · 4⌊ℓ/2⌋+ 1
6 · 4⌊ℓ/2⌋
Vℓ(1, 0) = 4⌊ℓ/2⌋−1
3 · 4⌊ℓ/2⌋.
For even ℓwe have
Vℓ(1, 1) = Vℓ(1, 0) = 2ℓ−1
3 · 2ℓ
Vℓ(0, 1) = 2 · 4ℓ/2−1 + 1
6 · 4ℓ/2−1
Proof. See Lemma B.1 and Corollary B.2 in Appendix B.
As a result, we get the following formula for the variance:
Theorem 5.24.
Var
∂⟨H⟩
∂θ1

=





Vℓ(P aj, P bj)
if ℓis even and a1 = ... = an
Vℓ(P bj, P aj)
if ℓis odd and b1 = ... = bn
0
otherwise.
Proof. See Theorem B.3 in Appendix B.
Corollary 5.25. Either Var

∂⟨H⟩
∂θ1

= 0 or Var

∂⟨H⟩
∂θ1

→1
3 for ℓ→∞. In partic-
ular, this proves Hypothesis 5.5.
Proof. This follows from the fact that all terms in Lemma 5.23 converge to 1
3 for
ℓ→∞. See Corollary B.4 in Appendix B for the full details.
Corollary 5.26. For example, in the case H = Z⊗n we have aj = 1 and bj = 0 for
all j such that
Var
∂⟨H⟩
∂θ1

=



2ℓ−1
3·2ℓ
if ℓis even.
2·4⌊ℓ/2⌋+1
6·4⌊ℓ/2⌋
if ℓis odd
Note that this exactly matches the numerical values from Figure 5.7.

5.5.
Barren Plateau Mitigation Techniques
107
5.5
Barren Plateau Mitigation Techniques
After identifying barren plateaus in a variety of ans¨atze, we want to close this chapter
with a brief discussion of how to avoid them. Crucially, the barren plateau analysis
in this chapter relied on the assumption made in Section 5.1 that the parameters
θi are uniformly and independently sampled from [−π, π].
This means that our
results, as well the ones in the literature like McLean et al. [10], no longer apply if
one chooses a different parameter initialisation.
To this end, different initialisation strategies have been proposed with the goal of
avoiding barren plateaus: For example, Grant et al. [67] choose parameters such that
the circuit turns into a sequence of shallow blocks that each evaluate to the identity,
thus reducing the effective circuit depth. Kulshrestha and Safro [68] experimentally
show that initialisation with the Beta distribution reduces the prevalence of barren
plateaus.
Apart from initialisation strategies, various other techniques have been proposed:
Rad et al. [69] use Bayesian learning to find a promising regions in the parameter
space which are then explored using local optimisers. Sack et al. [70] introduce a new
learning scheme that adapts the learning rate when a barren plateau is detected.
Liu et al. [71] propose a novel ansatz family where barren plateaus can be mitigated
and Skolik et al. [72] use quantum circuit learning to find ans¨atze that avoid barren
plateaus. Patti et al. [73] discuss a variety of techniques including the addition of
noise, reducing entanglement and partitioning the qubit registers depending on the
cost function.

Chapter 6
Discussion
6.1
Summary of Results
Gradient Recipes
We have refined the diagrammatic differentiation technique by Wang and Yeung [19]
for the special case of parametrised quantum circuits and used it to give diagram-
matic proofs of parameter shift rules given by Schuld et al. [7] and Anselmetti et
al. [8]. Furthermore, we derived a novel 2n-term shift rule for gates that can be
represented with n parametrised spiders. We also discussed the optimality of shift
rules, proving an open conjecture by Anselmetti et al. [8] by deriving a no-go the-
orem ruling out shift rules with less than four terms for all gates whose Hermitian
generators have eigenvalues of shape −λ, 0, λ.
Barren Plateaus
We investigated both empirical and formal methods to detect barren plateaus in
ans¨atze using the variance computation framework laid out by Wang and Yeung [19].
For the empirical analysis, we developed a tool that automatically computes Var

∂⟨H⟩
∂θi

which can be used to diagnose barren plateaus without the user having to perform
any calculations or mathematical reasoning. Using this tool, we investigate several

6.2.
Discussion and Future Work
109
ans¨atze studied by Sim et al. [20] and empirically concluded that even at a single
layer they likely all have barren plateaus.
To showcase the analytical barren plateau analysis powered by ZX, we formally
proved this claim for three of the Sim ans¨atze. Furthermore, we analysed a range
of IQP ans¨atze, in particular showing that a single layer of the ansatz used by the
quantum natural language processing library lambeq [21] has barren plateaus when
measuring in the computational basis. Additionally, we proved that one of the IQP
ans¨atze does not have barren plateaus, with Var

∂⟨H⟩
∂θi

converging to a constant
independent of the number of qubits n when the number of layers ℓgoes to infinity.
6.2
Discussion and Future Work
Gradient Recipes
One of the initial motivations for using the ZX calculus to study gradient recipes
was the hope that the graphical representation of derivatives might make it easier
to discover new recipes that go beyond parameter shift rules. However, as we have
mentioned in Section 4.3, it proved to be harder than expected to find decompositions
of the differentiation gadget that actually yield unitaries when applied to gates.
However, the diagrammatic approach proved to be very fruitful for the analysis of
parameter shift rules. Originally, Schuld et al. [7] and Anselmetti et al. [8] arrived
at their shift rules by observing that the Hermitian generators for the gates they
consider satisfy H2 = I and H3 = H, respectively. From this, they derived systems
of equations that yielded the shift rules. While our approach also involved systems of
equations, we arrived at and solved them in a completely different way. Concretely,
we used a diagrammatic approach to find systems of equations that characterise valid
shift rules which turned out to be easily solvable using a discrete sine transform. The
benefit of this hybrid approach involving both graphical and algebraic techniques is
that it applies to a wider range of gates. This allowed us to generalise to the 2n-term

110
Discussion
shift rule, whereas Schuld et al.’s and Anselmetti et al.’s approach only works for
gates that satisfy specific eigenvalue constraints. Wierichs et al. [9] obtained their
generalised shift rule by expressing the expectation value ⟨H⟩in terms of a discrete
Fourier transform (DFT) which is closely related to the discrete sine transform. This
might suggest a possible connection between our diagrammatically obtained system
of equations and Wierichs et al.’s DFT reconstruction of the expectation value which
would be interesting to investigate in the future.
Another interesting question that showed up at multiples points in our work is the
relationship between eigenvalues of a parametrised unitary and the minimum num-
ber of parametrised spiders required to implement the unitary in ZX. To the best
of our knowledge, this question has not been investigated before. We have given
a general upper bound, and a lower bound for the special case of eigenvalues −λ,
0, λ. Those bounds were close enough to derive existing parameter shift rules and
prove Anselmetti et al.’s conjecture [8]. However, it would be interesting to investi-
gate whether there are tighter bounds and if there is a deeper relationship between
parametrised spiders and eigenvalues. Besides being interesting in its own right,
this could potentially unify our generalised shift rule with the one given Wierichs et
al. [9]. Orthogonally, proving lower bounds could lead to general optimality results
for shift rules, generalising our no-go theorem to arbitrary parametrised unitaries.
Barren Plateaus
We have presented both empirical and analytical methods to detect barren plateaus
in ans¨atze. Our numerical tool can be used to quickly check a specific combination of
ansatz and Hamiltonian for barren plateaus. While the tool cannot formally prove or
disprove the existence of barren plateaus, it gives a good indication of the behaviour
of an ansatz for practically used circuit dimensions. The potential future use case
we envision for software like this is as a part of the QML practitioners’ toolbox
for evaluating the suitability of ans¨atze for QML tasks. For example, exponentially

6.2.
Discussion and Future Work
111
vanishing variance curves like in Figure 5.3 could indicate that experimentation with
different initialisation strategies might be warranted. Additionally, the numerical
data is very useful for gaining confidence in theoretical results. In particular, it gave
us confidence that the intricate formula we derived for the variance of the multi-layer
IQP1 ansatz is correct.
While all the experiments in this thesis run relatively quickly, we have some ideas how
to further improve the performance of our tool. For example, we could experiment
with decomposing the triangle directly instead of using the representation with four
π
4 spiders. In that case, we would no longer benefit from the efficient magic state
and cat decompositions used in [65].
However, we could search for alternative,
more efficient decompositions of groups of triangles. Here, it might also help that
the triangles in Theorem 5.1 are embedded in a regular, known structure that is
possibly easier to decompose.
Moving beyond the methods and looking at the concrete data we obtained, it is
surprising that all Sim ans¨atze we considered seem to already have barren plateaus
for a single layer. The results by McClean et al. [10] for example only apply if the
ansatz has enough layers to approximate a 2-design. Sim et al. showed that most
of their ans¨atze only gain their expressive power when adding more layers. But our
results indicate that the low expressivity of a single layer already suffices to produce
barren plateaus. The same seems to be true for the IQP circuit used in lambeq [21].
In fact, the only ansatz we considered that does not have barren plateaus is the very
simple IQP1. This might suggest that the expressiveness vs. trainability trade-off
described by Holmes et al. [11] is already significant at fairly low expressive powers
with mildly expressible circuits already having poor trainability. Analysing more
circuits in this way is needed to gain a better understanding of this relationship in
the future.
The fact that barren plateaus already appear in a single layer actually simplified
our analysis. First, running the numerical experiments for multi-layer circuits is

112
Discussion
more expensive.1 Secondly, we have already seen for the example of IQP1 that the
formal analysis of multi-layer ans¨atze requires significantly more work. Nonetheless,
it would be very interesting to expand on this work and analyse ans¨atze where the
barren plateau phenomenon only appears after adding enough layers. One example
of this would be non-local cost functions as discussed in [12].
Finally, the biggest limitation of the current ZXW-based barren plateau analysis
is the fact that Theorem 5.1 only applies if each parameter occurs exactly once in
the ZX representation of the ansatz. In particular, this excludes all an¨atze that
use controlled rotations. We have discussed a small caveat to this in Section 5.4.6
where the analysis is possible in certain special cases where the Hamiltonian cancels
out additional parameter occurrences. However, in the general case, such ans¨atze
cannot be handled by our method. The difficulty of adding support for this differs
between our numerical and our analytical approach. Both would require extending or
generalising the integration results by Wang and Yeung [19]. But while the numerical
tool could, in principle (barring performance concerns), work with any diagram that
represents the variance, in order to prove results by hand we need a diagram that is
amenable to manual rewriting and reasoning. Thus, finding such representations for
the gradient variance of circuits with multiple parameter occurrences would serve to
significantly generalise the results presented in this work.
1Note that for the ans¨atze we considered, adding a qubit adds O(1) parametrised spiders while
a new layers adds O(n) new parametrised spiders.

Appendix A
Constructing the Ancilla State
In Section 4.3, we discussed a gradient recipe that prepares ancillae in the state
±α
.
In this appendix, we explain how to prepare this state on a quantum
device. First, not that because of the (pcy) rule, it actually suffices to prepare the
state
. As it turns out, this state is an equal superposition of basis states:
(2.5)
=
+
π
(2.16)
=
+
π
+
π
To construct this, we define the following gate:
Definition A.1. Let D(p) := RY (2 arccos(√p)) for 0 ≤p ≤1.
Lemma A.2. This gate satisfies D(p)|0⟩= √p|0⟩+ √1 −p|1⟩.
Proof. In general, we have
RY (α)|0⟩=
cos( α
2 )
−sin(α
2 )
sin(α
2 )
cos( α
2 )
 1
0

=
cos( α
2 )
sin(α
2 )

Setting α = 2 arccos(√p), we get
D(p)|0⟩=

√p
√1 −p

= √p|0⟩+
p
1 −p|1⟩.

114
Constructing the Ancilla State
Using D(p), we can construct the state as follows:
D( 2
3)
D( 1
2)
X
X
(Lem. A.2)
=
r
2
3
D( 1
2)
X
X
+
r
1
3
π
D( 1
2)
X
X
=
r
2
3
D( 1
2)
+
r
1
3
π
(Lem. A.2)
=
r
2
3
r
1
2
+
r
2
3
r
1
2
π
+
r
1
3
π
=
r
1
3|00⟩+
r
1
3|01⟩+
r
1
3|10⟩=
r
1
3

Appendix B
Details on Recursive
Contraction
Here, we give the full details for the recursive contraction of Figure 5.8. For the
reader’s convenience, we restate the diagram:
(−1)
P ajbj
√
2
h
...
cnπ
c1π
k1π
...
Connected to
L2, L4, L6, ...
L1
...
kjπ
...
Connected to
Lj+1, Lj+3, ...
Lj
...
...
Lℓ
...
...
kℓπ
π
kiπ + π
...
Connected to
Li+1, Li+3, ...
Li
...
Arbitrary parameter
Variance parameter
...
...
cnπ
c1π
...
...
...
...
Hadamards only
if ℓis odd
B.1
Deriving the Recurrence Relation
To contract Figure 5.8, we introduce the notation
ke := k2 = k4 = ... = kℓ= b1 + ... + bn
ko := k1 = k3 = ... = kℓ−1 = a1 + ... + an

116
Details on Recursive Contraction
and write VE ℓ(ke, ko, c1, ..., cn) and VOℓ(ke, ko, c1, ..., cn) for the diagram for Var

∂⟨H⟩
∂θi

for even and odd ℓrespectively, excluding the factor (−1)
P ajbj. Furthermore, we
write x for the negation of a Boolean variable, i.e. 0 = 1 and 1 = 0.
Out goal is to find recursive formulas to compute VE ℓand VOℓ. For the base case,
consider VE 0:
VE 0(ke, ko, c1, ..., cn) =
cnπ
c1π
cnπ
c1π
...
...
=
(
1
if c1 = ... = cn = 0
0
otherwise.
(B.1)
Note that the term becomes zero if the cj are not all the same. Hence, from now
on we can ignore all terms where this is the case and simplify the notation to
VOℓ(ke, ko, c) and VE ℓ(ke, ko, c). Now, we proceed recursively:
• If i = ℓand ℓis odd then
VOℓ(ke, ko, c) =
1
√
2
h
|{z}
Scalar for
part up to ℓ
·
1
√
2
⌊ℓ/2⌋
| {z }
Scalar for Had.
wires to L2, L4, ...
cπ
cπ
π
koπ + π
...
...
Lℓ
...
Connected to
L2, L4, ...Lℓ−1
2n
...
(2.14)
=
X
x∈{0,1}
1
√
2
h ·
1
√
2
⌊ℓ/2⌋· 1
2 · (−1)x
cπ
cπ
xπ
xπ
koπ + π
...
...
...
xπ xπ
...
(cc)
=
X
x∈{0,1}
1
√
2
h · 1
2 · (−1)x
cπ
cπ
xπ
xπ
koπ + π
...
...
...
xπ xπ
...
(sf )
=
X
x∈{0,1}
1
√
2
h · 1
2 · (−1)x
(c + x)π
(c + x)π
koπ + π
...
...
...
xπ xπ
= VEℓ−1(ke + x, ko, c + x)
...
=
(
0
if ko = 0
1
2(VE ℓ−1(ke, 1, c) −VE ℓ−1(ke, 1, c))
if ko = 1
(B.2)

B.1.
Deriving the Recurrence Relation
117
• If i = ℓand ℓis even then
VE ℓ(ke, ko, c) =
1
√
2
h ·
1
√
2
ℓ/2
cπ
cπ
π
keπ + π
...
...
Lℓ
...
Connected to
L1, L3, ...Lℓ−1
2n
...
(2.14)
=
X
x∈{0,1}
1
√
2
h ·
1
√
2
ℓ/2 · 1
2 · (−1)x
cπ
cπ
xπ
xπ
keπ + π
...
...
...
xπ xπ
...
(cc,cp)
=
X
x∈{0,1}
1
√
2
h · 1
2 · (−1)x
cπ
cπ
keπ + π
...
...
...
xπ xπ
...
=
(
0
if ke = 0
1
2(VOℓ−1(1, ko, c) −VOℓ−1(1, ko, c))
if ke = 1
(B.3)
• If i ̸= ℓand ℓis odd then
VOℓ(ke, ko, c) =
1
√
2
h ·
1
√
2
⌊ℓ/2⌋
cπ
cπ
koπ
...
...
Lℓ
...
Connected to
L2, L4, ...Lℓ−1
2n
...
(2.14)
=
X
x∈{0,1}
1
√
2
h ·
1
√
2
⌊ℓ/2⌋· 1
2
cπ
cπ
xπ
xπ
...
...
...
xπ xπ
xπ
koπ
...
(cc,sf )
=
X
x∈{0,1}
1
√
2
h · 1
2
(c + x)π
(c + x)π
...
...
...
xπ xπ
xπ
koπ
...
=
(
VE ℓ−1(ke, 0, c)
if ko = 0
1
2(VE ℓ−1(ke, 1, c) −VE ℓ−1(ke, 1, c))
if ko = 1
(B.4)
• If i ̸= ℓand ℓis even then

118
Details on Recursive Contraction
VE ℓ(ke, ko, c) =
1
√
2
h ·
1
√
2
ℓ/2
cπ
cπ
keπ
...
...
Lℓ
...
Connected to
L1, L3, ...Lℓ−1
2n
...
(2.14)
=
X
x∈{0,1}
1
√
2
h ·
1
√
2
ℓ/2 · 1
2
cπ
cπ
xπ
xπ
...
...
...
xπ xπ
xπ
keπ
...
(cc,cp)
=
X
x∈{0,1}
1
√
2
h · 1
2
cπ
cπ
...
...
...
xπ xπ
xπ
keπ
...
=
(
VOℓ−1(0, ko, c)
if ke = 0
1
2(VOℓ−1(1, ko, c) −VOℓ−1(1, ko, c))
if ke = 1
(B.5)
This yields an recursive algorithm for computing Var

∂⟨H⟩
∂θi

. One interesting thing
to note is that
VOℓ(0, 0, c)
(B.4)
=
VE ℓ−1(0, 0, c)
(B.5)
=
VOℓ−2(0, 0, c) = ...
=
(
VOi(0, 0, c)
if i is odd
VE i(0, 0, c)
if i is even
(B.2,B.3)
=
0.
(B.6)
Furthermore, for i ̸= ℓ, ℓ−1 we can derive
VOℓ(0, 0, c)
(B.6)
=
VOℓ−2(0, 0, c)
(B.7)
VOℓ(0, 1, c)
(B.4,B.5)
=
1
4(2VOℓ−2(0, 1, c) + VOℓ−2(1, 0, c) −VOℓ−2(1, 1, c))
(B.8)
VOℓ(1, 0, c)
(B.4,B.5)
=
1
2(VOℓ−2(1, 0, c) −VOℓ−2(1, 1, c))
(B.9)
VOℓ(1, 1, c)
(B.4,B.5)
=
1
4(−2VOℓ−2(0, 1, c) −VOℓ−2(1, 0, c) + VOℓ−2(1, 1, c))
(B.10)

B.2.
Solving the Recurrence Relation
119
B.2
Solving the Recurrence Relation
When considering concrete values of i, we can derive closed-form solutions for
Var

∂⟨H⟩
∂θi

. We discuss the case i = 1. First, note that
VO1(ke, ko, c)
(B.3)
=
(
0
if ko = 0
1
2(VE 0(ke, 0, c) −VE 0(ke, 0, c))
if ko = 1
(B.1)
=
(
0
if ko = 0
1
2 · (−1)c
if ko = 1
(B.11)
As a consequence, we have
VE ℓ(ke, ko, c) = −VE ℓ(ke, ko, c)
(B.12)
VOℓ(ke, ko, c) = −VOℓ(ke, ko, c).
(B.13)
Therefore,
VOℓ(1, 1, c)
(B.10)
=
1
4(−2VOℓ−2(0, 1, c) −VOℓ−2(1, 0, c) + VOℓ−2(1, 1, c))
(B.13)
=
1
4(2VOℓ−2(0, 1, c) + VOℓ−2(1, 0, c) −VOℓ−2(1, 1, c))
(B.8)
=
VOℓ(0, 1)
(B.14)
VOℓ(0, 1, c)
(B.8,B.14)
=
1
4(3VOℓ−2(0, 1, c) −VOℓ−2(1, 0, c))
(B.15)
VOℓ(1, 0, c)
(B.8,B.14)
=
1
2(VOℓ−2(1, 0, c) −VOℓ−2(0, 1, c)).
(B.16)
Now, we just need to derive a closed form for this recurrence relation:
Lemma B.1. VO has the following closed-form representation:
VO2l+1(0, 1, c) = (−1)c · 2 · 4l + 1
6 · 4l
VO2l+1(1, 0, c) = (−1)1−c · 4l −1
3 · 4l
Proof. By induction on l:

120
Details on Recursive Contraction
• We have VO1(0, 1, c)
(B.11)
=
(−1)c·1
2 = (−1)c·2·40+1
6·40
and VO1(1, 0, c)
(B.11)
=
0 =
(−1)1−c · 40−1
3·40 .
• We have
VO2l+3(0, 1, c)
(B.15)
=
1
4 (3VO2l+1(0, 1, c) −VO2l+1(1, 0, c))
(IH)
=
1
4

3 · (−1)c · 2 · 4l + 1
6 · 4l
−(−1)1−c · 4l −1
3 · 4l

= (−1)c · 1
4
2 · 4l + 1
6 · 4l
+ 4l −1
3 · 4l

= (−1)c · 1
4 · 8 · 4l −1
6˙4l
= (−1)c · 2 · 4l+1 + 1
6 · 4l+1
VO2l+3(1, 0, c)
(B.9)
=
1
2(VO2l+1(1, 0, c) −VO2l+1(0, 1, c))
(IH)
=
1
2

(−1)1−c · 4l −1
3 · 4l −(−1)c · 2 · 4l + 1
6 · 4l

= (−1)1−c · 1
2
4l −1
3 · 4l + 2 · 4l + 1
6 · 4l

= (−1)1−c · 1
2 · 4 · 4l −1
6 · 4l
= (−1)1−c · 4l+1 −1
3 · 4l+1
Corollary B.2. VE has the following closed-form representation:
VE 2l(0, 1, c)
(B.5)
=
VO2l−1(0, 1, c)
(Lem. B.1)
=
(−1)c · 2 · 4l−1 + 1
6 · 4l−1
VE 2l(1, 0, c)
(B.4)
=
VO2l+1(1, 0, c)
(Lem. B.1)
=
(−1)1−c · 4l −1
3 · 4l
VE 2l(1, 1, c)
(B.5)
=
1
2(VO2l−1(0, 1, c) −VO2l−1(1, 0, c))
(Lem.B.1)
=
1
2(−1)c
2 · 4l−1 + 1
6 · 4l−1
+ 4l−1 −1
3 · 4l−1

= (−1)c 4l −1
3 · 4l

B.2.
Solving the Recurrence Relation
121
Now, recalling the definition of ke, ko, and c, we finally have
Theorem B.3. We have
Var
∂⟨H⟩
∂θ1

=





(−1)
P ajbj · VE ℓ(P aj, P bj, a1)
if ℓis even and a1 = ... = an
(−1)
P ajbj · VOℓ(P bj, P aj, b1)
if ℓis odd and b1 = ... = bn
0
otherwise.
Corollary B.4. Either Var

∂⟨H⟩
∂θ1

= 0 or Var

∂⟨H⟩
∂θ1

→1
3 for ℓ→∞.
Proof. This essentially follows from the fact that all terms in Lemma B.1 and
Corollary B.2 converge to ±1
3. To be precise, we can show that the negation always
cancels out by considering the different cases: Suppose ℓis odd and b1 = ... = bn = 0.
Then
Var
∂⟨H⟩
∂θ1

= VOℓ(0,
X
aj, 0)
(B.7,Lem. B.1)
=
(
0
if P aj = 0
2·4⌊ℓ/2⌋+1
6·4⌊ℓ/2⌋
→1
3
if P aj = 1
If b1 = ... = bn = 1, then we have P bj = 1 since we assume that n is odd. Thus,
Var
∂⟨H⟩
∂θ1

= VOℓ(1,
X
aj, 1)
(B.13,Lem. B.1)
=
(
4⌊ℓ/2⌋−1
3·4⌊ℓ/2⌋→1
3
if P aj = 0
2·4⌊ℓ/2⌋+1
6·4⌊ℓ/2⌋
→1
3
if P aj = 1
We do not get a negation in the second case since P aj = 1 implies that (−1)
P ajbj =
1. The case for even ℓand a1 = ... = an is symmetric. Otherwise, Var

∂⟨H⟩
∂θ1

=
0.

Appendix C
Additional Lemmas and Proofs
Lemma C.1. For all x ∈{0, 1}, we have
xπ
=
1
√
2
xπ
xπ
(C.1)
Proof.
xπ
(sf ,π)
=
xπ
xπ
(sc)
=
xπ
xπ
(cc)
=
1
√
2
xπ
xπ
Lemma C.2.
= 2
(C.2)
Proof.
(sf )
=
(cc)
=
√
2
(ho)
=
√
2
(cc,sf )
=
2

123
Proof of Proposition 4.4. We first prove than we cannot represent the CRZ(θ)
gate using less than two parametrised spiders. Suppose we had
CRZ(θ) = eig(θ)
D
f(θ)
But then
∂
∂θCRZ(θ)
(3.1)
=
ig′(θ)eig(θ)
D
f(θ)
+ eig(θ)if′(θ)
D
f(θ)
π
(cp)
=
ig′(θ)CRZ(θ) + eig(θ)if′(θ)eif(θ)
D
π
(C.3)
Note that the diagram on the right-hand side no longer depends on θ.
Since
∂
∂θCRZ(θ) = diag(0, 0, −iθ
2 e−i θ
2 , iθ
2 ei θ
2 ) is diagonal, we must also have
D
π
= diag(a, b, c, d)
for some constants a, b, c, d ∈C. By comparing the diagonal entries to (C.3), we get
the equations
g′(θ) + aei(f(θ)+g(θ))f′(θ) = 0
(C.4)
g′(θ) + bei(f(θ)+g(θ))f′(θ) = 0
(C.5)
g′(θ)e−i θ
2 + cei(f(θ)+g(θ))f′(θ) = −θ
2e−i θ
2
(C.6)
g′(θ)ei θ
2 + dei(f(θ)+g(θ))f′(θ) = θ
2ei θ
2
(C.7)
Since (C.4) implies g′(θ) = −aei(f(θ)+g(θ))f′(θ), we can rewrite (C.6) and (C.7) to
ei(f(θ)+g(θ))f′(θ) · (c −ae−i θ
2 ) = −θ
2e−i θ
2
ei(f(θ)+g(θ))f′(θ) · (d −aei θ
2 ) = θ
2ei θ
2

124
Additional Lemmas and Proofs
In particular, this implies that
c −ae−i θ
2 = −d + aei θ
2
for all θ, which is clearly not possible for constant a, b, c.
Thus, we can conclude that we cannot represent CRZ(θ) with less than two parametrised
spiders.
Now, suppose there were some other unitary U(θ) = eiθH whose Her-
mitian generator has eigenvalues −λ, 0, λ that can be implemented with a single
parametrised spider:
U(θ) =
U
f(θ)
...
...
However, by Lemma 4.15 this would immediately yield a one-spider representation
on CRZ(θ) via
CRZ(θ) =
f
...
U
f(θ)
2λ
...
...
which is not possible.
Proof of Lemma 4.6. First, note that
π
π
(2.5)
=
π
−
π
π
π
(sf )
=
π
−
π
(2.10)
=
|1⟩⟨0| −|0⟩⟨1|
(C.8)
On the other hand, we have
α
−α
(2.5)
=
(|0⟩+ e−iα|1⟩)(⟨0| + eiα⟨1|) = |0⟩⟨0| + eiα|0⟩⟨1| + e−iα|1⟩⟨0| + |1⟩⟨1|
−α
α
(2.5)
=
(|0⟩+ eiα|1⟩)(⟨0| + e−iα⟨1|) = |0⟩⟨0| + e−iα|0⟩⟨1| + eiα|1⟩⟨0| + |1⟩⟨1|

125
such that
α
−α
−
−α
α
= (eiα −e−iα)|0⟩⟨1| + (e−iα −eiα)|1⟩⟨0|
= (eiα −e−iα)(|0⟩⟨1| −|1⟩⟨0|)
(C.8)
=
2i sin(α)
π
π
.
Proof of Lemma 5.2. By comparing the action on the computational basis:
−π
4
−π
4
π
4
π
4
(cp)
=
−π
4
−π
4
π
4
π
4
(id,sf )
=
−π
2
π
2
(∗)
= 2
(tri)
=
2
π
−π
4
−π
4
π
4
π
4
(cp)
=
π
π
−π
4
−π
4
π
4
π
4
(π,sf )
=
(cp,sf )
=
(tri)
=
2
π
where the step (∗) follows again from plugging in the computational basis:
−π
2
π
2
(sf ,id)
=
(sf )
=
2
−π
2
π
2
π
(sf ,π)
=
π
= 0
(sf )
=
2
π
Proof of Lemma 5.6.
xπ
yπ
π
α...
...
...
(sf )
=
xπ
yπ
π
α...
...
...
(π,sf )
=
xπ
yπ
π
α + π
...
...
...
(sf )
=
xπ
yπ
π
α + π
...
...
...
(ho)
=
xπ
yπ
α + π
...
π
...
...
α
β
π
xπ
...
...
...
(sf )
=
α
β
π
xπ
...
...
...
(π,sf )
=
α
β
π
xπ + π
...
...
...

126
Additional Lemmas and Proofs
(sf )
=
α
β
π
xπ + π
...
...
...
(ho)
=
α
β
π
xπ + π
...
...
...
Proof of Lemma 5.7.
α
β
π
π
...
...
...
(π,sf ,id)
=
eiα
−α
π
π
...
β
...
...
(sf )
=
eiα
β −α
π
π
...
...
π
π
...
...
...
n
(π,sf ,id)
=
π
π
...
...
...
n
(sf )
=
2n−1
π
π
...
...
Note that the scalar 2n−1 appears in the last step according to Lemma 2.13.
Proof of Lemma 5.8. We prove the three equations separately:
• We have
(−1)aibi
aiπ
biπ
aiπ
biπ
π
π
π
(π,cc,sf )
=
(−1)aibi(−1)bi
aiπ
aiπ
π
π
π
biπ
(sf )
=
(−1)aibi+bi
aiπ
aiπ
π
π
π
biπ
(ho,cc)
=
1
2(−1)aibi+bi
aiπ
aiπ
π
π
π
biπ
(5.1)
=
1
2(−1)aibi+bi
aiπ + π
aiπ
π
π
π
biπ
(id,sf )
=
1
2(−1)aibi+bi
aiπ + π
aiπ
π
biπ
(cc,sf )
=
1
2(−1)aibi+bi
aiπ + π
aiπ + π
biπ
If bi = 0, we get

127
1
2
aiπ + π
aiπ + π
(tri,sf )
=
1
2
aiπ + π
aiπ + π
(id,sf ,ho)
=
1
2
aiπ + π
aiπ + π
= 2ai.
If bi = 1, we get
1
2(−1)ai+1
aiπ + π
aiπ + π
π
(tri,cp,sf )
=
1
2(−1)ai+1
aiπ + π
aiπ + π
π
π
(π,sf ,id)
=
1
2(−1)ai+1(−1)ai+1
= 1.
• We have
(−1)aibi
aiπ
biπ
aiπ
biπ
π
π
π
(π,cc,sf )
=
(−1)aibi
aiπ
aiπ
π
π
biπ + π
biπ
(sf )
=
(−1)aibi
aiπ
aiπ
π
π
biπ + π
biπ
(ho,cp,cc,sf )
=
(−1)aibi(−1)ai
π
biπ + π
π
biπ
(cc)
=
1
2(−1)aibi+ai
π
biπ + π
π
biπ
(sf ,ho)
=
1
2(−1)aibi+ai
π
biπ + π
π
biπ
(π,sf )
=
1
2(−1)aibi+ai
π
biπ + π
biπ
=
(
0
if bi = 0
1
if bi = 1

128
Additional Lemmas and Proofs
• We have
(−1)aibi
aiπ
biπ
aiπ
biπ
(π,cc,sf )
=
(−1)aibi
aiπ
aiπ
biπ
biπ
(sf ,ho)
=
(−1)aibi
aiπ
aiπ
biπ
biπ
If bi = 0, we get
aiπ
aiπ
(tri,sf )
=
aiπ
aiπ
(id,sf ,ho)
=
aiπ
aiπ
(cc)
=
aiπ
aiπ
(sf ,ho)
=
aiπ
aiπ
(cp,tri,sf )
=
aiπ
=
(
4
if ai = 0
2
if ai = 1
If bi = 1, we get
(−1)ai
aiπ
aiπ
π
π
(tri,cp,sf )
=
aiπ
aiπ
π
π
π
(cp,cc,sf )
=
(−1)ai(−1)ai
π
π
π
(cc)
=
1
2
π
π
π

129
(sf ,ho)
=
1
2
π
π
π
(cp,sf )
=
1
2
π
π
= 1.
Proof of Lemma 5.13. We prove both cases separately:
• We have
(−1)aibi
biπ
aiπ
...
...
biπ
aiπ
...
...
π
π
π
(cc)
=
1
2(−1)aibi
biπ
aiπ
...
...
biπ
aiπ
...
...
π
π
π
(cc)
=
1
2(−1)aibi
biπ
aiπ
...
...
biπ
aiπ
...
...
π
π
π
(sf ,cp)
=
1
2(−1)aibi(−1)bi
aiπ
...
...
aiπ ...
...
π
π
π
(5.1)
=
1
2(−1)aibi+bi
aiπ + π
...
...
aiπ ...
...
π
π
π
If ai = 0, the diagram becomes 0. If ai = 1, we get
...
...
π ...
...
π
π
π
(π,sf )
=
...
π
π
...
...
π
π
...
• We have
(−1)aibi
biπ
aiπ
...
...
biπ
aiπ
...
...
(cc,hh)
=
(−1)aibi
biπ
aiπ
...
...
biπ
aiπ
...
...
(sf ,cc,5.1)
=
√
2(−1)aibi
aiπ
biπ
...
...
aiπ
biπ
...
...
aiπ

130
Additional Lemmas and Proofs
(cp,cc,sf )
=
2(−1)aibi
aiπ
...
...
aiπ ...
...
aiπ
biπ
If ai = 0, we get
2
...
...
...
...
biπ
(tri,sf ,cc)
=
2
...
...
...
...
biπ
(cp,sf )
=
2
biπ
...
...
biπ
...
...
(sf ,ho)
=
4
biπ
...
...
biπ
...
...
If ai = 1, we get
2(−1)bi
...
...
...
...
π
biπ
(tri,cp)
=
2
...
...
...
...
π
π
(cc,sf )
=
...
...
...
...
π
π
(5.2)
=
2
π
π
...
π
π
...
...
...
Proof of Lemma 5.15.
bi1π
bimπ
...
...
kπ
bi1π
bim
...
...
kπ
π
π
π
...
...
(sf )
=
bi1π
bimπ
...
...
kπ
bi1π
bim
...
...
kπ
π
π
π
...
...
...
...
(sc)
=
bi1π
bimπ
...
...
kπ
bi1π
bim
...
...
kπ
π
π
π
...
...
(cp,sf )
=
bi1π
bimπ
...
...
bi1π
bim
...
...
π + kπ
π
π
...
...

131
(sf ,ho)
=
bi1π
bimπ
...
...
bi1π
bim
...
...
π + kπ
π
π
...
...
(cp,sf )
=
bi1π
bimπ
...
...
bi1π
bim
...
...
π + kπ
...
...
π
(sf ,id)
=
bi1π
bimπ
...
...
π + kπ
bi1π
bimπ
...
...
π
...
...
bi1π
bimπ
...
...
kπ
bi1π
bim
...
...
kπ
...
...
(sc)
=
kπ
kπ
bi1π
bimπ
...
...
...
bi2π
bi1π
...
...
...
(cp,sf )
=
kπ
bi1π
bimπ
...
...
...
bimπ
bi1π
...
...
...
(sf ho)
=
kπ
bi1π
bimπ
...
...
...
bimπ
bi1π
...
...
...
If k = 0, we get
bi1π
bimπ
...
...
...
bimπ
bi1π
...
...
...
(tri,sf )
=
bi1π
bimπ
...
...
...
bimπ
bi1π
...
...
...
(sf ,ho)
=
bi1π
bimπ
...
...
...
bimπ
bi1π
...
...
...
(cp,sf )
=
bi1π
bimπ
...
...
...
bi1π
bimπ
...
...
...
If k = 1, we get

132
Additional Lemmas and Proofs
π
bi1π
bimπ
...
...
...
bimπ
bi1π
...
...
...
(tri,cp,sf )
=
π
π
bi1π
bimπ
...
...
...
bimπ
bi1π
...
...
...
(cp,sf )
=
bi1π
bimπ
...
...
...
π
bimπ
bi1π
...
...
...
(sf ,id)
=
bi1π
bimπ
...
...
bi1π
bimπ
...
...
π
...
...
Proof of Lemma 5.21. We have
...
kiπ
...
kiπ
α1 ...
αm ...
...
(C.1)
=
1
√
2
m
...
...
α1 ...
αm ...
...
kiπ
(C.2)
=
√
2
m
...
...
α1 ...
αm ...
...
kiπ
(sc)
=
√
2
m
...
α1 ...
αm ...
...
kiπ
...

133
(sc)
=
√
2
m
...
α1 ...
αm ...
...
kiπ
...
(sf ,ho,id)
=
√
2
m
...
α1 ...
αm ...
...
kiπ
...
For the second cycle, we have
...
kiπ
...
kiπ
π
α1 ...
αm ...
...
π
π
(C.1)
=
1
√
2
m
...
...
π
α1 ...
αm ...
...
π
π
kiπ
(C.2)
=
√
2
m
...
...
π
α1 ...
αm ...
...
π
π
kiπ
(sc)
=
√
2
m
...
...
π
α1 ...
αm ...
...
π
π
kiπ
(sf ,ho)
=
√
2
m
...
...
α1 ...
αm ...
...
π
π
kiπ + π
(π,sf )
=
√
2
m
α1 ...
αm ...
...
kiπ + π
π
...
...

Bibliography
[1] Lov K Grover. A fast quantum mechanical algorithm for database search. In
Proceedings of the twenty-eighth annual ACM symposium on Theory of com-
puting, pages 212–219, 1996.
[2] Peter W Shor. Polynomial-time algorithms for prime factorization and discrete
logarithms on a quantum computer. SIAM review, 41(2):303–332, 1999.
[3] Michael J Bremner, Ashley Montanaro, and Dan J Shepherd. Achieving quan-
tum supremacy with sparse and noisy commuting quantum computations.
Quantum, 1:8, 2017.
[4] Jacob Biamonte, Peter Wittek, Nicola Pancotti, Patrick Rebentrost, Nathan
Wiebe, and Seth Lloyd. Quantum machine learning. Nature, 549(7671):195–
202, 2017.
[5] Aram W Harrow and John C Napp. Low-depth gradient measurements can im-
prove convergence in variational hybrid quantum-classical algorithms. Physical
Review Letters, 126(14):140502, 2021.
[6] Kosuke Mitarai, Makoto Negoro, Masahiro Kitagawa, and Keisuke Fujii. Quan-
tum circuit learning. Physical Review A, 98(3):032309, 2018.
[7] Maria Schuld, Ville Bergholm, Christian Gogolin, Josh Izaac, and Nathan Kil-
loran. Evaluating analytic gradients on quantum hardware. Physical Review A,
99(3):032331, 2019.

Bibliography
135
[8] Gian-Luca R Anselmetti, David Wierichs, Christian Gogolin, and Robert M
Parrish.
Local, expressive, quantum-number-preserving VQE ans¨atze for
fermionic systems. New Journal of Physics, 23(11):113010, 2021.
[9] David Wierichs, Josh Izaac, Cody Wang, and Cedric Yen-Yu Lin.
General
parameter-shift rules for quantum gradients. Quantum, 6:677, 2022.
[10] Jarrod R McClean, Sergio Boixo, Vadim N Smelyanskiy, Ryan Babbush, and
Hartmut Neven. Barren plateaus in quantum neural network training land-
scapes. Nature communications, 9(1):1–6, 2018.
[11] Zo¨e Holmes, Kunal Sharma, Marco Cerezo, and Patrick J Coles. Connecting
ansatz expressibility to gradient magnitudes and barren plateaus. PRX Quan-
tum, 3(1):010313, 2022.
[12] Marco Cerezo, Akira Sone, Tyler Volkoff, Lukasz Cincio, and Patrick J Coles.
Cost function dependent barren plateaus in shallow parametrized quantum cir-
cuits. Nature communications, 12(1):1–12, 2021.
[13] Chen Zhao and Xiao-Shan Gao. Analyzing the barren plateau phenomenon in
training quantum neural networks with the ZX-calculus. Quantum, 5:466, 2021.
[14] Bob Coecke and Ross Duncan. Interacting quantum observables. In Interna-
tional Colloquium on Automata, Languages, and Programming, pages 298–310.
Springer, 2008.
[15] Ross Duncan, Aleks Kissinger, Simon Perdrix, and John Van De Wetering.
Graph-theoretic simplification of quantum circuits with the ZX-calculus. Quan-
tum, 4:279, 2020.
[16] Arianne Meijer-van de Griend and Ross Duncan. Architecture-aware synthesis
of phase polynomials for NISQ devices. arXiv preprint arXiv:2004.06052, 2020.
[17] Aleks Kissinger and John van de Wetering. Simulating quantum circuits with

136
Bibliography
ZX-calculus reduced stabiliser decompositions. Quantum Science and Technol-
ogy, 2022.
[18] Razin Shaikh, Quanlong Wang, and Richie Yeung. How to sum and exponen-
tiate hamiltonians in ZXW calculus. Quantum Physics and Logic, 2022.
[19] Quanlong Wang and Richie Yeung.
Differentiating and integrating ZX dia-
grams. arXiv preprint arXiv:2201.13250, 2022.
[20] Sukin Sim, Peter D Johnson, and Al´an Aspuru-Guzik. Expressibility and entan-
gling capability of parameterized quantum circuits for hybrid quantum-classical
algorithms. Advanced Quantum Technologies, 2(12):1900070, 2019.
[21] Dimitri Kartsaklis, Ian Fan, Richie Yeung, Anna Pearson, Robin Lorenz, Alexis
Toumi, Giovanni de Felice, Konstantinos Meichanetzidis, Stephen Clark, and
Bob Coecke. lambeq: An efficient high-level python library for quantum NLP.
arXiv preprint arXiv:2110.04236, 2021.
[22] Marshall H Stone. On one-parameter unitary groups in Hilbert space. Annals
of Mathematics, pages 643–648, 1932.
[23] Maria Schuld and Nathan Killoran.
Quantum machine learning in feature
hilbert spaces. Physical review letters, 122(4):040504, 2019.
[24] Marcello Benedetti, Delfina Garcia-Pintos, Oscar Perdomo, Vicente Leyton-
Ortega, Yunseong Nam, and Alejandro Perdomo-Ortiz. A generative modeling
approach for benchmarking and training shallow quantum circuits. npj Quan-
tum Information, 5(1):1–9, 2019.
[25] Jin-Guo Liu and Lei Wang. Differentiable learning of quantum circuit born
machines. Physical Review A, 98(6):062324, 2018.
[26] Seth Lloyd and Christian Weedbrook. Quantum generative adversarial learning.
Physical review letters, 121(4):040502, 2018.
[27] Abhinav Kandala, Antonio Mezzacapo, Kristan Temme, Maika Takita, Markus

Bibliography
137
Brink, Jerry M Chow, and Jay M Gambetta. Hardware-efficient variational
quantum eigensolver for small molecules and quantum magnets.
Nature,
549(7671):242–246, 2017.
[28] Yudong Cao, Jonathan Romero, Jonathan P Olson, Matthias Degroote, Peter D
Johnson, M´aria Kieferov´a, Ian D Kivlichan, Tim Menke, Borja Peropadre, Nico-
las PD Sawaya, et al. Quantum chemistry in the age of quantum computing.
Chemical reviews, 119(19):10856–10915, 2019.
[29] Edward Farhi, Jeffrey Goldstone, and Sam Gutmann. A quantum approximate
optimization algorithm. arXiv preprint arXiv:1411.4028, 2014.
[30] Konstantinos Meichanetzidis, Stefano Gogioso, Giovanni De Felice, Nicol`o Chi-
appori, Alexis Toumi, and Bob Coecke. Quantum natural language processing
on near-term quantum computers. arXiv preprint arXiv:2005.04147, 2020.
[31] William Huggins, Piyush Patil, Bradley Mitchell, K Birgitta Whaley, and
E Miles Stoudenmire.
Towards quantum machine learning with tensor net-
works. Quantum Science and technology, 4(2):024001, 2019.
[32] Xiangjian Qian and Mingpu Qin. From tree tensor network to multiscale en-
tanglement renormalization ansatz. Physical Review B, 105(20):205102, 2022.
[33] Y Du, MH Hsieh, T Liu, and D Tao. The expressive power of parameterized
quantum circuits. arXiv preprint arXiv:1810.11922, 2018.
[34] Xavier Bonet-Monroig, Hao Wang, Diederick Vermetten, Bruno Senjean,
Charles Moussa, Thomas B¨ack, Vedran Dunjko, and Thomas E O’Brien. Perfor-
mance comparison of optimization methods on variational quantum algorithms.
arXiv preprint arXiv:2111.13454, 2021.
[35] James C Spall et al. Multivariate stochastic approximation using a simultaneous
perturbation gradient approximation. IEEE transactions on automatic control,
37(3):332–341, 1992.

138
Bibliography
[36] Michael JD Powell. A direct search optimization method that models the objec-
tive and constraint functions by linear interpolation. Advances in optimization
and numerical analysis, pages 51–67, 1994.
[37] Jonas M K¨ubler, Andrew Arrasmith, Lukasz Cincio, and Patrick J Coles. An
adaptive optimizer for measurement-frugal variational algorithms. Quantum,
4:263, 2020.
[38] Ken M Nakanishi, Keisuke Fujii, and Synge Todo. Sequential minimal opti-
mization for quantum-classical hybrid algorithms. Physical Review Research,
2(4):043158, 2020.
[39] Max Wilson, Rachel Stromswold, Filip Wudarski, Stuart Hadfield, Norm M
Tubman, and Eleanor G Rieffel. Optimizing quantum heuristics with meta-
learning. Quantum Machine Intelligence, 3(1):1–14, 2021.
[40] Anna Choromanska, Mikael Henaff, Michael Mathieu, G´erard Ben Arous, and
Yann LeCun. The loss surfaces of multilayer networks. In Artificial intelligence
and statistics, pages 192–204. PMLR, 2015.
[41] Xuchen You and Xiaodi Wu. Exponentially many local minima in quantum neu-
ral networks. In International Conference on Machine Learning, pages 12144–
12155. PMLR, 2021.
[42] Kang Feng Ng and Quanlong Wang. A universal completion of the ZX-calculus.
arXiv preprint arXiv:1706.09877, 2017.
[43] Aleks Kissinger and John van de Wetering. Reducing T-count with the ZX-
calculus. arXiv preprint arXiv:1903.10477, 2019.
[44] Alexander Cowtan, Will Simmons, and Ross Duncan.
A generic com-
pilation strategy for the unitary coupled cluster ansatz.
arXiv preprint
arXiv:2007.10515, 2020.

Bibliography
139
[45] Ross Duncan. A graphical approach to measurement-based quantum comput-
ing. arXiv preprint arXiv:1203.6242, 2012.
[46] Aleks Kissinger and John van de Wetering. Universal MBQC with generalised
parity-phase interactions and Pauli measurements. Quantum, 3:134, 2019.
[47] Niel de Beaudrap and Dominic Horsman. The ZX calculus is a language for
surface code lattice surgery. Quantum, 4:218, 2020.
[48] Quanlong Wang. Algebraic complete axiomatisation of ZX-calculus with a nor-
mal form via elementary matrix operations. arXiv preprint arXiv:2007.13739,
2020.
[49] Bob Coecke and Aleks Kissinger. Picturing Quantum Processes: A First Course
in Quantum Theory and Diagrammatic Reasoning. Cambridge University Press,
2017.
[50] Alexander Cowtan, Silas Dilkes, Ross Duncan, Will Simmons, and Seyon
Sivarajah.
Phase gadget synthesis for shallow circuits.
arXiv preprint
arXiv:1906.01734, 2019.
[51] Aleks Kissinger and John van de Wetering. Picturing Quantum Software. 2022.
[52] Richie Yeung. Diagrammatic design and study of ans¨atze for quantum machine
learning. arXiv preprint arXiv:2011.11073, 2020.
[53] Alexis Toumi, Richie Yeung, and Giovanni de Felice. Diagrammatic differenti-
ation for quantum machine learning. arXiv preprint arXiv:2103.07960, 2021.
[54] William Wernick. Complete sets of logical functions. Transactions of the Amer-
ican Mathematical Society, 51:117–132, 1942.
[55] Ville Bergholm, Josh Izaac, Maria Schuld, Christian Gogolin, M Sohaib Alam,
Shahnawaz Ahmed, Juan Miguel Arrazola, Carsten Blank, Alain Delgado, So-
ran Jahangiri, et al. Pennylane: Automatic differentiation of hybrid quantum-
classical computations. arXiv preprint arXiv:1811.04968, 2018.

140
Bibliography
[56] Gavin E Crooks.
Gradients of parameterized quantum gates using the
parameter-shift rule and gate decomposition. arXiv preprint arXiv:1905.13311,
2019.
[57] Brooks Foxen, Charles Neill, Andrew Dunsworth, Pedram Roushan, Ben
Chiaro, Anthony Megrant, Julian Kelly, Zijun Chen, Kevin Satzinger, Rami
Barends, et al. Demonstrating a continuous set of two-qubit gates for near-
term quantum algorithms. Physical Review Letters, 125(12):120504, 2020.
[58] Oleksandr Kyriienko and Vincent E Elfving. Generalized quantum circuit dif-
ferentiation rules. Physical Review A, 104(5):052417, 2021.
[59] Vladimir Britanak, Patrick C Yip, and Kamisetty Ramamohan Rao. Discrete
cosine and sine transforms: general properties, fast algorithms and integer ap-
proximations. Elsevier, 2010.
[60] Anil K Jain. A sinusoidal family of unitary transforms. IEEE Transactions on
Pattern Analysis and Machine Intelligence, (4):356–365, 1979.
[61] Dan Shepherd and Michael J Bremner.
Temporally unstructured quantum
computation. Proceedings of the Royal Society A: Mathematical, Physical and
Engineering Sciences, 465(2105):1413–1439, 2009.
[62] Michael J Bremner, Ashley Montanaro, and Dan J Shepherd. Average-case
complexity versus approximate simulation of commuting quantum computa-
tions. Physical review letters, 117(8):080501, 2016.
[63] Austin P Lund, Michael J Bremner, and Timothy C Ralph. Quantum sampling
problems, boson sampling and quantum supremacy. npj Quantum Information,
3(1):1–8, 2017.
[64] Michael J Bremner, Richard Jozsa, and Dan J Shepherd. Classical simulation of
commuting quantum computations implies collapse of the polynomial hierarchy.

Bibliography
141
Proceedings of the Royal Society A: Mathematical, Physical and Engineering
Sciences, 467(2126):459–472, 2011.
[65] Aleks Kissinger, John van de Wetering, and Renaud Vilmart. Classical simula-
tion of quantum circuits with partial and graphical stabiliser decompositions.
arXiv preprint arXiv:2202.09202, 2022.
[66] John Coates and Ramdorai Sujatha. Cyclotomic fields and zeta values. Springer
Science & Business Media, 2006.
[67] Edward
Grant,
Leonard
Wossnig,
Mateusz
Ostaszewski,
and
Marcello
Benedetti.
An initialization strategy for addressing barren plateaus in
parametrized quantum circuits. Quantum, 3:214, 2019.
[68] Ankit Kulshrestha and Ilya Safro. BEINIT: Avoiding barren plateaus in varia-
tional quantum algorithms. arXiv preprint arXiv:2204.13751, 2022.
[69] Ali Rad, Alireza Seif, and Norbert M Linke.
Surviving the barren plateau
in variational quantum circuits with bayesian learning initialization.
arXiv
preprint arXiv:2203.02464, 2022.
[70] Stefan H Sack, Raimel A Medina, Alexios A Michailidis, Richard Kueng, and
Maksym Serbyn. Avoiding barren plateaus using classical shadows. PRX Quan-
tum, 3(2):020365, 2022.
[71] Xia Liu, Geng Liu, Jiaxin Huang, and Xin Wang. Mitigating barren plateaus
of variational quantum eigensolvers. arXiv preprint arXiv:2205.13539, 2022.
[72] Andrea Skolik, Jarrod R McClean, Masoud Mohseni, Patrick van der Smagt,
and Martin Leib. Layerwise learning for quantum neural networks. Quantum
Machine Intelligence, 3(1):1–11, 2021.
[73] Taylor L Patti, Khadijeh Najafi, Xun Gao, and Susanne F Yelin. Entanglement
devised barren plateau mitigation. Physical Review Research, 3(3):033090, 2021.

