Kernel Methods for Nonparametric
Bayesian Inference of Probability
Densities and Point Processes
Ryan Prescott Adams
S.B., Massachusetts Institute of Technology (2004)
St. John’s College
University of Cambridge
This dissertation is submitted for the degree of
Doctor of Philosophy
Inference Group
Cavendish Laboratory
University of Cambridge
2009

ii
Declaration
I hereby declare that my dissertation entitled “Kernel Methods for Nonparametric
Bayesian Inference of Probability Densities and Point Processes” is not substantially
the same as any that I have submitted for a degree or diploma or other qualiﬁcation at
any other University.
I further state that no part of my dissertation has already been or is being concurrently
submitted for any such degree or diploma or other qualiﬁcation.
This dissertation is the result of my own work and includes nothing which is the out-
come of work done in collaboration, except where speciﬁcally indicated in the text.
This dissertation does not exceed sixty thousand words in length.

iii
Abstract
Nonparametric kernel methods for estimation of probability densities and point pro-
cess intensities have long been of interest to researchers in statistics and machine learn-
ing. Frequentist kernel methods are widely used, but provide only a point estimate
of the unknown density. Additionally, in frequentist kernel density methods, it can
be difﬁcult to select appropriate kernel parameters. The Bayesian approach to infer-
ence potentially resolves both of these deﬁciencies, by providing a distribution over
the unknowns and enabling a principled approach to kernel selection. Constructing
a Bayesian nonparametric kernel density method has proven to be difﬁcult, however,
due to the need to integrate over an inﬁnite-dimensional random function in order to
evaluate the likelihood. To avoid this intractability, all Bayesian kernel density meth-
ods to date have either used a crippled model or a ﬁnite-dimensional approximation.
Recent advances in Markov chain Monte Carlo methods have improved the situation
for these doubly-intractable posterior distributions, however. If data can be generated
exactly from the model, then it is possible to perform inference without computing the
intractable likelihood. I propose two new kernel-based models that enable an exact
generative procedure: the Gaussian process density sampler (GPDS) for probability
density functions, and the sigmoidal Gaussian Cox process (SGCP) for the Poisson
process. With generative priors, I show how it is now possible to construct two dif-
ferent kinds of Markov chains for inference in these models. These Markov chains
have the desired posterior distribution as their equilibrium distributions, and, despite
a parameter space with uncountably many dimensions, require only a ﬁnite amount
of computation to simulate. The GPDS and SGCP, and the associated inference proce-
dures, are the ﬁrst kernel-based nonparametric Bayesian methods that allow inference
without a ﬁnite-dimensional approximation.
I also present several additional kernel-based models for data that extend the Gaussian
process density sampler and sigmoidal Gaussian Cox process to other situations. The
Archipelago model extends the GPDS to address the task of semi-supervised learning,
where a ﬂexible density estimate can improve the performance of a classiﬁer when
unlabeled data are available. I also generalise the SGCP to enable a nonparametric
inhomogeneous Neyman–Scott process, and present a soft-core generalisation of the
Mat´ern repulsive process that similarly allows non-approximate inference via Markov
chain Monte Carlo.

iv
To my grandmothers, Lois and LaDel.

v
Acknowledgements
I am extremely fortunate to have David MacKay as my supervisor and friend. It would
be no understatement to say that he has taught me how to think. More than that,
though, he has taught me how to communicate ideas and reason clearly. There is
still a long way to go, however, and I struggle every day to live up to the intellectual
standard he sets.
Zoubin Ghahramani has always made time for me and has been an invaluable source
of ideas and advice on all aspects of research and academia. I enjoyed immensely my
visits with him at Carnegie Mellon when we were both in Pennsylvania.
I also wish to thank Steve Gull, Leslie Pack Kaelbling, and Christopher Sawyer-
Lauc¸anno, mentors who have given me their time and advice, without which I could
not have reached this point.
I am grateful to my contemporaries in the Inference Group — Chris Ball, Phil Cowans,
Oliver Stegle, David Stern, Philip Sterne, Keith Vertanen, Hanna Wallach, Seb Wills
— for all of their help over the years. I appreciate their patience as I bombarded
them with ridiculous ideas, and I beneﬁted from the ideas I got in return. Among this
group I would especially like to thank Iain Murray, whose keen insight provided the
foundation upon which much of this thesis was built.
I have beneﬁted greatly from the generosity of the Gates Cambridge Trust and St.
John’s College. I also wish to thank the Canadian Institute for Advanced Research,
who funded my travels to Toronto and made possible some of the work that led to
this thesis.
I wish to thank my wonderful friends in Cambridge who have given me fond memo-
ries for a lifetime.
My parents, John and Cathy, my brother Vincent and my sister Katherine have enthu-
siastically supported every one of my ambitions, and this PhD was no different. My
family has given me opportunities that few people ever have, and I will always be
grateful.
Finally, there is nothing I could do to sufﬁciently express my gratitude to Brenda. She
has been supportive at every turn of a very twisty road. She’s proofread my papers,
listened to my practice talks, and raided the library on my behalf. Not a single word
of this thesis would exist without her.

Contents
Abstract
iii
Acknowledgements
v
Contents
v
List of Figures
x
List of Tables
xii
List of Algorithms
xiii
Mathematical Conventions
xiv
1
Introduction
1
1.1
Bayesian Nonparametric Modeling . . . . . . . . . . . . . . . . . . . . . .
1
1.2
The Gaussian Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.2.1
Covariance Functions
. . . . . . . . . . . . . . . . . . . . . . . . .
4
1.2.2
Interpretations and Computation . . . . . . . . . . . . . . . . . . .
5
1.3
The Logistic Gaussian Process . . . . . . . . . . . . . . . . . . . . . . . . .
7
1.4
The Log Gaussian Cox Process
. . . . . . . . . . . . . . . . . . . . . . . .
9
1.5
Other Density-Related Gaussian Process Models . . . . . . . . . . . . . .
10
1.5.1
The Csat´o Density Model . . . . . . . . . . . . . . . . . . . . . . .
10
1.5.2
The Gaussian Process Latent Variable Model . . . . . . . . . . . .
10
1.5.3
The Cunningham Poisson Model . . . . . . . . . . . . . . . . . . .
11
1.6
Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12
2
The Gaussian Process Density Sampler
13
2.1
The Prior on Probability Density Functions . . . . . . . . . . . . . . . . .
13
2.1.1
The Response Function Φ(·) . . . . . . . . . . . . . . . . . . . . . .
14
2.1.2
The Base Density π(x) . . . . . . . . . . . . . . . . . . . . . . . . .
16
2.1.3
The Effect of Gaussian Process Hyperparameters
. . . . . . . . .
16
2.2
Generating Data from the Prior . . . . . . . . . . . . . . . . . . . . . . . .
16
2.2.1
Rejection Sampling . . . . . . . . . . . . . . . . . . . . . . . . . . .
17

CONTENTS
vii
2.2.2
Sampling from the GPDS
. . . . . . . . . . . . . . . . . . . . . . .
18
2.2.3
Inﬁnite Exchangeability . . . . . . . . . . . . . . . . . . . . . . . .
19
2.3
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
3
The Sigmoidal Gaussian Cox Process
23
3.1
The Poisson and Cox Processes . . . . . . . . . . . . . . . . . . . . . . . .
23
3.2
Generating Poisson Data . . . . . . . . . . . . . . . . . . . . . . . . . . . .
24
3.2.1
Direct Sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
3.2.2
Time Rescaling
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
3.2.3
Thinning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
26
3.3
The Prior on Poisson Intensity Functions
. . . . . . . . . . . . . . . . . .
27
3.4
Generating Data from the Prior . . . . . . . . . . . . . . . . . . . . . . . .
27
3.5
Point Process Extensions to the SGCP
. . . . . . . . . . . . . . . . . . . .
29
3.5.1
The Marked Poisson Process
. . . . . . . . . . . . . . . . . . . . .
29
3.5.2
Point Processes with Interaction
. . . . . . . . . . . . . . . . . . .
31
3.6
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
42
4
Inference Via Exchange Sampling
43
4.1
Markov Chain Monte Carlo . . . . . . . . . . . . . . . . . . . . . . . . . .
44
4.2
Doubly-Intractable Distributions and Exchange Sampling . . . . . . . . .
45
4.3
Exchange Sampling for GPDS Inference . . . . . . . . . . . . . . . . . . .
50
4.3.1
Independence-Chain Exchange Sampling . . . . . . . . . . . . . .
50
4.3.2
Improving the Acceptance Rate with Conservative Proposals
. .
52
4.3.3
Hyperparameter Inference
. . . . . . . . . . . . . . . . . . . . . .
57
4.4
Exchange Sampling for SGCP Inference . . . . . . . . . . . . . . . . . . .
60
4.4.1
Hyperparameter Inference
. . . . . . . . . . . . . . . . . . . . . .
61
4.5
Predictive Samples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
63
4.6
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
64
5
Inference Via Latent Histories
65
5.1
Modeling the Latent History of the Generative Procedure . . . . . . . . .
65
5.2
Latent History Inference in the GPDS
. . . . . . . . . . . . . . . . . . . .
66
5.2.1
Sampling the Number of Latent Rejections . . . . . . . . . . . . .
67
5.2.2
Sampling the Locations of Latent Rejections
. . . . . . . . . . . .
69
5.2.3
Sampling the Latent Function . . . . . . . . . . . . . . . . . . . . .
70
5.2.4
Sampling the Gaussian Process Hyperparameters . . . . . . . . .
71
5.2.5
Sampling the Base Density Hyperparameters . . . . . . . . . . . .
71
5.2.6
Generating Predictive Samples . . . . . . . . . . . . . . . . . . . .
71
5.3
Latent History Inference in the SGCP . . . . . . . . . . . . . . . . . . . . .
73
5.3.1
Sampling the Number of Thinned Events . . . . . . . . . . . . . .
73
5.3.2
Sampling the Locations of Thinned Events . . . . . . . . . . . . .
74
5.3.3
Sampling the Latent Function . . . . . . . . . . . . . . . . . . . . .
75

CONTENTS
viii
5.3.4
Sampling the Gaussian Process Hyperparameters . . . . . . . . .
75
5.3.5
Sampling the Dominating Intensity Hyperparameters . . . . . . .
75
5.4
Latent History Inference Versus Exchange Sampling . . . . . . . . . . . .
77
5.5
Inference in Poisson-Derived Interacting Point Processes . . . . . . . . .
78
5.5.1
Inference in the Neyman–Scott Process
. . . . . . . . . . . . . . .
78
5.5.2
Inference in the Generalised Mat´ern Type III Process
. . . . . . .
81
5.6
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
84
6
Application Examples
85
6.1
Density Modeling Examples . . . . . . . . . . . . . . . . . . . . . . . . . .
85
6.1.1
Bounded Univariate Density
. . . . . . . . . . . . . . . . . . . . .
85
6.1.2
Bivariate Ring Density . . . . . . . . . . . . . . . . . . . . . . . . .
88
6.1.3
Macaque Skull Data
. . . . . . . . . . . . . . . . . . . . . . . . . .
90
6.2
Poisson Process Examples . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
6.2.1
Univariate Synthetic Data . . . . . . . . . . . . . . . . . . . . . . .
91
6.2.2
Coal Mine Disaster Data . . . . . . . . . . . . . . . . . . . . . . . .
93
6.2.3
Redwoods Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
93
6.3
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
94
7
Model Extensions
95
7.1
Estimation of Normalised Predictive Probabilities . . . . . . . . . . . . .
95
7.2
Improving Performance of Inference in the GPDS
. . . . . . . . . . . . .
97
7.3
Improving Performance of Inference in the SGCP
. . . . . . . . . . . . .
98
7.4
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
99
8
Archipelago: Nonparametric Bayesian Semi-Supervised Learning
100
8.1
The Semi-Supervised Learning Problem . . . . . . . . . . . . . . . . . . . 100
8.2
The Archipelago Model
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
8.3
Generating Data from the Prior . . . . . . . . . . . . . . . . . . . . . . . . 102
8.4
Latent History Inference in Archipelago . . . . . . . . . . . . . . . . . . . 104
8.4.1
Sampling the Number of Latent Rejections . . . . . . . . . . . . . 106
8.4.2
Sampling the Locations of Latent Rejections
. . . . . . . . . . . . 107
8.4.3
Sampling the Latent Functions . . . . . . . . . . . . . . . . . . . . 107
8.4.4
Sampling the Hyperparameters . . . . . . . . . . . . . . . . . . . . 108
8.4.5
Making Predictions . . . . . . . . . . . . . . . . . . . . . . . . . . . 108
8.5
Empirical Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108
8.5.1
Toy Pinwheel Data . . . . . . . . . . . . . . . . . . . . . . . . . . . 108
8.5.2
Wine Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
8.5.3
Oil Pipe Data
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
8.6
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
8.7
Computational Considerations . . . . . . . . . . . . . . . . . . . . . . . . 112
8.8
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112

CONTENTS
ix
9
Conclusions and Future Work
113
9.1
Modeling Other Spaces with the GPDS and Archipelago
. . . . . . . . . 113
9.1.1
Permutation Kernels . . . . . . . . . . . . . . . . . . . . . . . . . . 113
9.1.2
String Kernels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
9.1.3
Set Kernels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
9.1.4
Graph Kernels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
9.2
Inclusion of Covariates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
9.3
Doubly-Nonparametric Density Modeling . . . . . . . . . . . . . . . . . . 115
9.4
Archipelago with Dependent Latent Functions . . . . . . . . . . . . . . . 115
9.5
Summary of Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
A Additional Algorithms
117
B
Additional Tables
125
Symbol Glossary
126
References
129

List of Figures
1.1
Typical samples from a Gaussian process
. . . . . . . . . . . . . . . . . .
5
1.2
Example of marginal Gaussian process predictive distributions
. . . . .
6
2.1
Typical samples from the Gaussian process density sampler
. . . . . . .
14
2.2
Hyperparameter effects on typical GPDS samples
. . . . . . . . . . . . .
15
2.3
Rejection sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17
2.4
Sampling from the Gaussian process density sampler prior . . . . . . . .
19
2.5
Data samples from the Gaussian process density sampler . . . . . . . . .
21
3.1
Examples of a Poisson process in one and two dimensions
. . . . . . . .
24
3.2
Thinning for Poisson simulation on an irregular domain
. . . . . . . . .
26
3.3
Sampling from the sigmoidal Gaussian Cox process prior . . . . . . . . .
28
3.4
Marked Poisson realisations from the sigmoidal Gaussian Cox process .
30
3.5
Boolean model realisations from the sigmoidal Gaussian Cox process . .
31
3.6
Mother and daughter cluster process illustration . . . . . . . . . . . . . .
32
3.7
Inhomogeneous Neyman–Scott realisations via the SGCP . . . . . . . . .
33
3.8
Illustration of Hawkes process realisation . . . . . . . . . . . . . . . . . .
35
3.9
Spatial Hawkes process realisations via the SGCP
. . . . . . . . . . . . .
36
3.10 Illustration of the thinning of Mat´ern repulsive processes . . . . . . . . .
38
3.11 Comparison of hard-core and soft-core Mat´ern intervals . . . . . . . . . .
40
3.12 Inhomogeneous Mat´ern Type III process realisation via the SGCP . . . .
41
3.13 Soft-core Mat´ern Type III process realisation via the SGCP
. . . . . . . .
42
4.1
Illustration of exchange sampling for the GPDS . . . . . . . . . . . . . . .
53
4.2
Illustration of underrelaxed proposals with Gaussian processes
. . . . .
56
5.1
Inserting new latent rejections into the GPDS history
. . . . . . . . . . .
67
6.1
Bounded univariate density example . . . . . . . . . . . . . . . . . . . . .
86
6.2
Comparison of Markov state for the ES and LH methods . . . . . . . . .
87
6.3
Ring data and predictive distributions . . . . . . . . . . . . . . . . . . . .
88
6.4
Linear distances superimposed on Macaca mulatta CT scan . . . . . . . .
89
6.5
Synthetic Poisson data and estimated intensities . . . . . . . . . . . . . .
92
6.6
Intensity estimate of coal mine disaster data . . . . . . . . . . . . . . . . .
93

LIST OF FIGURES
xi
6.7
Intensity estimate of redwood forest data . . . . . . . . . . . . . . . . . .
94
7.1
Multiple latent functions leading to the same PDF . . . . . . . . . . . . .
97
8.1
Sampling labeled data from the Archipelago prior . . . . . . . . . . . . . 103
8.2
Inserting new latent rejections into the Archipelago history . . . . . . . . 106
8.3
Applying Archipelago to two-dimensional “pinwheel” data . . . . . . . 111

List of Tables
6.1
Empirical comparison of GPDS on ring and Macaca mulatta data . . . . .
90
6.2
Empirical comparison of the SGCP on synthetic data
. . . . . . . . . . .
94
8.1
Empirical comparison of Archipelago
. . . . . . . . . . . . . . . . . . . . 110
B.1
Anatomical landmark pairs for linear distances from Macaca mulatta
. . 125

List of Algorithms
2.1
Rejection sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
18
2.2
Sampling from the Gaussian process density sampler prior . . . . . . . .
20
3.1
Sampling from the sigmoidal Gaussian Cox process prior . . . . . . . . .
29
4.1
Metropolis–Hastings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
46
4.2
Exchange sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
49
4.3
Independence chain exchange sampling with the GPDS . . . . . . . . . .
51
4.4
Underrelaxed control point exchange sampling with the GPDS . . . . . .
58
4.5
Underrelaxed control point exchange sampling with the SGCP . . . . . .
62
5.1
MCMC sampling from the GPDS latent history . . . . . . . . . . . . . . .
72
5.2
MCMC sampling from the SGCP latent history . . . . . . . . . . . . . . .
76
8.1
Sampling from the Archipelago prior . . . . . . . . . . . . . . . . . . . . . 104
A.1 Sampling from the SGCP prior on an irregular region . . . . . . . . . . . 117
A.2 Sampling from the SGCP prior with marking . . . . . . . . . . . . . . . . 118
A.3 Sampling from a Neyman–Scott process with the SGCP . . . . . . . . . . 118
A.4 Sampling from a Hawkes process with the SGCP . . . . . . . . . . . . . . 119
A.5 Sampling from a generalised Mat´ern Type II process with the SGCP . . . 119
A.6 Sampling from a generalised Mat´ern Type III process with the SGCP . . 120
A.7 Taking an exchange sampling step on GP hyperparameters in the GPDS 121
A.8 Taking an ES step on base density hyperparameters in the GPDS . . . . . 122
A.9 Taking an exchange sampling step on GP hyperparameters in the SGCP 123
A.10 Taking an ES step on bounding intensity hyperparameters in the SGCP . 124

Mathematical Conventions
Notation
In this thesis, I will generally use lowercase letters, such as x, to denote scalar values,
bold lowercase, such as x, to denote vectors, and uppercase bold, such as X, to denote
matrices. When referring to speciﬁc elements within vectors and matrices I will use
subscripts paired with unbolded notation, such as xj for the jth component of x or Xij
for the entry of X in row i and column j. When referring to a speciﬁc matrix or vector,
I will often use bold lettering with a subscript, for example KN or kM. I will denote
the transpose of X as XT. I will generally use uppercase calligraphic characters, such
as X to refer to spaces. When referring to functions in general, I will use the normal
notation f(·), however, much of this thesis is concerned with functions as inﬁnite-
dimensional vectors on which it is possible to construct distributions. In these cases, I
will use the vector notation, such as f.
In algorithms I will use the leftarrow ←to indicate assignment and the tilde ∼to in-
dicate that a quantity is drawn from a particular distribution. Within functions, I will
use f(a ; b) to indicate a function with input a parameterised by b. If I use the nota-
tion p(a | b), I am indicating a probability distribution on a conditioned on b. I will
denote a Markov chain Monte Carlo proposal to transition from a to ˆa with q(ˆa ←a).
In general, I will use “hatted” variables such as ˆa to indicate Markov chain Monte
Carlo proposals, and “tilded” variables such as ˜a to indicate rejection sampling pro-
posals.
The notation R refers to the extended real numbers; R+ denotes the nonnegative ex-
tended real numbers. The notation N refers to the natural numbers, including zero.
For a comprehensive list of symbols used in this thesis, see the Symbol Glossary on
page 126.
Common Distributions
There are several distributions to which I will frequently refer.

LIST OF ALGORITHMS
xv
Uniform:
U(x ∈R | a, b) =



1
b−a
if a < x < b
0
otherwise
U(x ∈RD | V) =



1
µ(V)
if x ∈V
0
otherwise
Gaussian (Normal):
N(x ∈RD | µ, Σ) = (2π)−d
2 |Σ|−1
2 exp

−1
2(x −µ)TΣ−1(x −µ)

Gamma:
GA(x ∈R+ | α, β) =
1
βα Γ(α)xα−1e−βx
Poisson:
PO(k ∈N | λ) = 1
k!e−λλk
Exponential:
EX(x ∈R+ | λ) = λ e−λx

Chapter 1
Introduction
Nonparametric kernel methods for estimation of probability densities and point pro-
cess intensities have long been of interest to researchers in statistics and machine
learning. Frequentist approaches to kernel estimation of probability densities were
introduced by Rosenblatt (1956) and Parzen (1962), and extended to point processes
by Diggle (1985). These methods are widely used, but provide only a point estimate
of the unknown density. Additionally, in frequentist kernel density methods, it can
be difﬁcult to select appropriate kernel parameters. The Bayesian approach to infer-
ence potentially resolves both of these deﬁciencies, by providing a distribution over
the unknowns and enabling a principled approach to kernel selection. Constructing
a Bayesian nonparametric kernel density method has proven to be difﬁcult, however,
due to the need to integrate over an inﬁnite-dimensional random function. To avoid
this intractability, all Bayesian kernel density methods to date have either used a crip-
pled model or a ﬁnite-dimensional approximation. In this thesis, I take advantage
of recent developments in Markov chain Monte Carlo methods to develop the ﬁrst
fully-nonparametric kernel-based Bayesian methods for inference of probability den-
sity functions and point process intensity functions.
1.1
Bayesian Nonparametric Modeling
The Bayesian philosophy of inference brings many advantages to data analysis. It
speciﬁes a way to incorporate new data consistently. It allows for the representa-
tion of the uncertainty of unobserved quantities. It enables nuisance parameters to
be marginalised out. Comparing models of different dimensionality, however, re-
quires computations that can be difﬁcult to perform. Various methods have been pro-
posed to ease the computational burden of model selection: reversible-jump Markov
chain Monte Carlo (RJMC) (Green, 1995), the Laplace approximation (Lindley, 1980;
MacKay, 1992b, 1998b), the Bayesian information criterion (BIC) (Schwarz, 1978), and
variational methods (e.g. Minka (2001)). In contrast to these methods, which infer di-

Bayesian Nonparametric Modeling
2
mensionality after seeing the data, the nonparametric Bayesian approach constructs
models that have an inﬁnite number of dimensions a priori. The word “nonparamet-
ric” is misleading: it is not that there are no parameters, it is that there are an inﬁnite
number of parameters.
The most popular tool for nonparametric Bayesian modeling of probability distribu-
tions is the Dirichlet process (DP) (Ferguson, 1973). Samples from the Dirichlet process
and its cousins, the Pitman–Yor process (Pitman and Yor, 1997; Ishwaran and James,
2001) and the Indian buffet process (Grifﬁths and Ghahramani, 2006), are discrete with
probability one, however. This makes the vanilla Dirichlet process unsuitable for mod-
eling continuous random variables that require probability density functions.
To ﬁll the gap between nonparametric priors on discrete distributions and nonpara-
metric priors on continuous densities, the Dirichlet process is frequently used to add a
countably-inﬁnite number of parameters into a continuous model. The most popular
example is the inﬁnite mixture of parametric distributions (Escobar and West, 1995;
Rasmussen, 2000). Dirichlet process mixture models (DPMMs) have also been used
for point processes in time and space (Kottas and Sans´o, 2007), using beta distribu-
tions for the components. Other methods for using a Dirichlet process to construct a
prior that assigns mass to continuous densities include kernel convolution (Lo, 1984)
and the Dirichlet diffusion tree (DFT) (Neal, 2001, 2003a). The Dirichlet process is also
closely related to the P´olya tree model (Ferguson, 1974; Mauldin et al., 1992; Lavine,
1992, 1994), which can be conﬁgured to produce densities. P´olya trees are not tractable
as fully-inﬁnite models, however, and require ﬁnite-depth approximations for practi-
cal computation (Walker et al., 1999). For extensive discussion of topics related to
nonparametric Bayesian models for random distributions, see Walker et al. (1999) or
Ghosh and Ramamoorthi (2003).
Prior beliefs about a distribution over data are often about the probability density
function — its continuity, support and smoothness properties, for example. Similarly,
when constructing point process models we would like to specify directly our beliefs
about the associated intensity function. There is a rich literature on incorporating prior
beliefs about functions into nonparametric Bayesian regression models, using splines,
neural networks and stochastic processes (e.g. DiMatteo et al. (2001), MacKay (1992a),
and O’Hagan (1978)). However, as will be discussed in Section 1.3 and Section 1.4,
priors on general functions have largely resisted application to modeling of densities
and point process intensities, as it is difﬁcult to construct a tractable transformation
such that realisations from the prior are nonnegative and integrate to a known value.
The rest of this chapter is organised as follows: Section 1.2 gives a brief review
of Gaussian processes, Section 1.3 discusses the standard approach to modeling
probability density functions with Gaussian processes, and Section 1.4 examines the
log Gaussian Cox process. In Section 1.5 I review a handful of other models that
use Gaussian processes for modeling data, and in Section 1.6 I give an outline of the

The Gaussian Process
3
overall thesis structure.
1.2
The Gaussian Process
The main tool I will use to specify prior beliefs about probability densities and point
process intensity functions is the Gaussian process (GP). The Gaussian process pro-
vides a nonparametric distribution over functions of the form g(·) : X →R. The do-
main X is chosen based on what sort of functions the Gaussian process should sup-
port, but the range is always the real line. In this thesis, it can be assumed that X is
the D-dimensional Euclidean space RD.
Use of the Gaussian process as a tool for smoothing and interpolation in the time
domain has a long history, going back at least to Wiener (1949). The modern and more
general approach to Gaussian processes for regression was introduced by O’Hagan
(1978). Gaussian processes have also been regularly applied to problems in spatial
statistics, under the name kriging (e.g. Cressie (1991)). The Gaussian process was
made popular in the machine learning community by Neal (1994) and Williams and
Rasmussen (1996). The approach of Rasmussen and Williams (2006) is the one I will
largely follow.
The Gaussian process is a distribution on functions. The central idea is that if one
conditions on a ﬁnite set of (input or covariate) values in the domain, one gets a joint
Gaussian distribution over the corresponding (output or response) values in the range.
More precisely, given an indexed subset of X with size N, denoted {xn ∈X}N
n=1,
there is an associated Gaussian distribution on RN. The dimensions of this Gaus-
sian are interpreted as corresponding to the outputs {yn = g(xn)}N
n=1 of a random
function g(x). The N-dimensional Gaussian distribution is parameterised by an N-
dimensional mean vector mN and an N × N covariance matrix CN.
For the Gaussian process to make sense as a distribution on functions, there must
be a consistent way to arrive at mN and CN for any ﬁnite N and any set {xn}N
n=1.
These parameters are generated via a mean function m(·) : X →R and a covariance func-
tion C(·, ·) : X × X →R as
[mN]n = m(xn)
[CN]n,n′ = C(xn, xn′).
(1.1)
In this thesis I will take the mean function to be zero, i.e. m(x) = 0, ∀x ∈X. I will
denote any parameters that control C(·, ·) as θ and refer to them as hyperparameters.

The Gaussian Process
4
1.2.1
Covariance Functions
The covariance function determines what functions are typical samples from the Gaus-
sian process. The choice of an appropriate C(·, ·) is central to specifying a prior that
reﬂects our beliefs. There are many valid covariance functions; for reviews see Abra-
hamsen (1997) or Rasmussen and Williams (2006, Chapter 4). The main requirement
for a covariance function is that it be a positive semideﬁnite kernel. Positive semideﬁ-
nite kernel functions are those for which the matrix CN, as constructed in Equation 1.1,
is positive semideﬁnite for any ﬁnite subset of X. An N × N matrix C is positive
semideﬁnite if the quadratic product zTCz ≥0 for all z ∈RN. Covariance matrices
for Gaussian distributions must be positive deﬁnite in order for the density function to
integrate to one. Positive semideﬁnite covariance functions, guarantee that the Gaus-
sian distribution on the output space of the GP is always valid, regardless of what
inputs are selected.
Frequently, prior beliefs about functions are very general. It might be desirable for typ-
ical functions to exhibit a particular amount of “bumpiness” and for this bumpiness
to be constant across the input space. In such cases, it may be appropriate to choose
a stationary covariance function, which depends on the input space only through a
distance between the two inputs. Not only are stationary covariance functions more
intuitive, but they can be constructed in Fourier space via Bochner’s theorem (Gibbs,
1997). In Fourier space, choice of covariance can be guided by spectral density, rather
than the interaction of distance and correlation.
Choosing an appropriate covariance function for a particular problem, whether sta-
tionary or nonstationary, can be a difﬁcult task. Although it is an important topic, I
will not address covariance function choice in this thesis. For a detailed treatment of
covariance function selection see, for example, Paciorek (2003). Unless stated other-
wise, I will assume the “squared exponential” covariance function (Rasmussen and
Williams, 2006):
C(x, x′) = ω2 exp
(
−1
2
D
X
d=1
(xd −x′
d)2
ℓ2
d
)
.
(1.2)
There are D + 1 hyperparameters comprising θ in this covariance function: ω is an
“amplitude” that speciﬁes how far from zero the function outputs are likely to extend,
and ℓspeciﬁes a length scale for each dimension. Figure 1.1 shows typical samples
from a Gaussian process with the squared exponential covariance function in one and
two dimensions.

The Gaussian Process
5
(a) ℓ= 1, ω = 1
(b) ℓ= 5, ω = 1
(c) ℓ= 1
2, ω = 1
(d) ℓ= 1, ω = 5
(e) ℓx = 1, ℓy = 2, ω = 1
Figure 1.1: Typical samples from a Gaussian process with the squared exponential co-
variance function of Equation 1.2. (a)–(d) Three typical functions for a particular setting
of the hyperparameters. (e) Two input dimensions with different length scales.
1.2.2
Interpretations and Computation
There are several different interpretations of the Gaussian process construction. One
useful interpretation is to consider the Gaussian process to be a multivariate Gaussian
distribution on a vector with index set X, which may be uncountably inﬁnite. Alter-
natively, one may interpret the Gaussian process as a Bayesian approach to learning
with the reproducing kernel Hilbert space (RKHS) construction of Aronszajn (1950).
A third interpretation of the Gaussian process is as a Bayesian regression model with
a possibly-inﬁnite number of basis functions. Similarly, Neal (1996) equates the Gaus-
sian process to a neural network in an inﬁnite limit. I recommend Rasmussen and
Williams (2006) or MacKay (1998a) for further detail on the relationship between the
Gaussian process framework and other models.
In this thesis I will generally take the view of the GP as an inﬁnite-dimensional Gaus-
sian distribution. This interpretation makes it easy to see how many of the compu-
tations performed with the Gaussian process can be done via simple linear algebra.
For example, given some data {xn, yn}N
n=1 that are to be modeled with a Gaussian
process, it may be desirable to know the marginal likelihood to guide the choice of co-
variance function and hyperparameters. The marginal likelihood is the probability
of the data, given the model, but integrating out the parameters. In this case the pa-
rameters are the functions, which are inﬁnite-dimensional objects. Remarkably, in the
Gaussian process it is possible to integrate over this inﬁnite-dimensional space by sim-
ply discarding the irrelevant entries of the mean vector and covariance matrix. The log

The Gaussian Process
6
Figure 1.2: An example of a “sausage-link plot” showing the marginal predictive dis-
tribution from a Gaussian process. There are ﬁve data shown with red circles. The
posterior mean function is shown in black, and the grey areas show two standard devi-
ations of the marginal predictive distributions. This plot was generated with a squared
exponential covariance function with ℓ= 1 and ω = 1.
marginal likelihood then has the simple form
ln p({yn}N
n=1 | {xn}N
n=1, θ) = −N
2 ln 2π −1
2 ln |CN| −1
2yTC−1
N y
(1.3)
where y = [y1, y2, . . . , yN]T.
Having seen N data {xn, yn}N
n=1, we might want to make predictions of the function
values at a new set of M input locations {xm}M
m=1. This M-dimensional conditional (or
predictive) distribution integrates out the value of the function at all unseen locations
and is Gaussian. I denote the cross-covariance matrix between the N data already seen
and the M data at which I make predictions, as CN,M. This matrix is computed by
applying the covariance function to the two sets via
[CN,M]n,m = C(xn, xm).
(1.4)
Having computed this matrix, it is now possible to ﬁnd the parameters of the Gaussian
predictive distribution for the function values at the {xm}M
m=1. I denote the predictive
mean and covariance as µ⋆and Σ⋆, respectively, and they are computed via
µ⋆= CT
N,M C−1
N y
(1.5)
Σ⋆= CM −CT
N,M C−1
N CN,M
(1.6)
where CM is calculated for the prediction locations as in Equation 1.1.
For one-
dimensional inputs, it is frequently useful to view the marginal conditional distri-
butions across an entire region via a “sausage-link plot” — Figure 1.2 provides an
example.

The Logistic Gaussian Process
7
1.3
The Logistic Gaussian Process
Having established that the Gaussian process is a useful nonparametric prior on func-
tions, I now examine how a GP could be used to build a distribution on probability
density functions. Such a construction would result in a nonparametric Bayesian ker-
nel density model.
If V is a bounded subset of X, and g(x) is a function drawn from a Gaussian pro-
cess, it is possible to arrive at a probability density function f(x) with support V by
transforming g(x):
f(x) =
1
Z[g] exp{g(x)}
(1.7)
Z[g] =
Z
V
dx′ exp{g(x′)}.
(1.8)
This transformation is called the logistic Gaussian process (LGP). It was introduced by
Leonard (1978) and further developed by Lenk (1988, 1991) and by Thorburn (1986).
If the mean function and covariance kernel of the Gaussian process are continuous
and bounded, then the integral in Equation 1.8 is well-deﬁned (Lenk, 1988; Tokdar,
2006). Under these constraints, the distribution on f(x) that the GP implies meets the
requirements for a prior on probability density functions: the exponential function
ensures that it is everywhere nonnegative and the normalisation constant Z[g] ensures
that it integrates to one. Tokdar and Ghosh (2007) showed that this prior is consistent.
Unfortunately, the logistic Gaussian process is not tractable for inference. First, g(x)
is an inﬁnite object which cannot be represented with a ﬁnite amount of memory.
Second, the normalisation constant Z[g] cannot be evaluated, as it requires integrating
over a random inﬁnite-dimensional function. To illustrate the difﬁculty, I will write g
to denote the function g(x) as an object on which it is possible to perform inference,
ignoring for now the fact that it is inﬁnite. Given N data {xn}N
n=1, Bayes’ theorem says
p(g | {xn}N
n=1) =
GP(g) Z[g]−N exp
nPN
n=1 g(xn)
o
R
dg′ GP(g′) Z[g′]−N exp
nPN
n=1 g′(xn)
o,
(1.9)
where I am using GP(g) to indicate a Gaussian process prior on g. It is common for
complex probabilistic models to have the intractable integral that appears in the de-
nominator of Equation 1.9. This quantity is the marginal likelihood, and it does not
depend on g. Bayesians have developed many ways to deal with posterior computa-
tion when the marginal likelihood is unknown. Markov chain Monte Carlo (MCMC),
for example, typically only requires that the posterior distribution on parameters be
known to within a constant.
The difﬁculty with the logistic Gaussian process is that Equation 1.9 is a doubly-

The Logistic Gaussian Process
8
intractable posterior distribution (Murray et al., 2006). Not only is there an intractable
quantity in the denominator, but even the likelihood function
p({xn}N
n=1 | g) = Z[g]−N exp
( N
X
n=1
g(xn)
)
(1.10)
requires knowledge of Z[g]. As Z[g] depends on g, it cannot be ignored, even when
using MCMC. This constant gets its symbol from the German Zustandssumme (“sum of
states”) and in statistical physics this quantity is commonly called the partition function.
Within machine learning, this quantity arises frequently in the distributions deﬁn-
ing undirected graphical models, such as Boltzmann machines (Ackley et al., 1985;
Smolensky, 1986). In these ﬁnite models, Z[g] involves a sum over a very large, but
ﬁnite, number of states. In the logistic Gaussian process, however, calculating Z[g]
requires an integral over an uncountably-inﬁnite number of states: the values of g(x)
for all x in V.
To make the logistic Gaussian process practical for inference, two ﬁnite-dimensional
surrogate models have been proposed. The literature does not provide examples of
these approximations being used to model data with more than two dimensions. Lenk
(1991, 2003) approximates the Gaussian process with a ﬁnite number of basis func-
tions, chosen via a truncated Karhunen–Lo`eve expansion. As realisations of g(x) are
now ﬁnite-dimensional, it is possible to determine the normalisation constant Z[g].
As noted by Lenk (2003), however, the required number of basis functions grows ex-
ponentially with dimension. It is unclear in this approximation how to choose multi-
dimensional basis functions that allow the logistic Gaussian process to be both ex-
pressive and efﬁcient. Tokdar (2007) proposes approximating the Gaussian process
with a ﬁnite-dimensional proxy distribution over a ﬁxed grid of “knots.” When it is
necessary to evaluate the function at a new location, the value is imputed from the
mean function of the Gaussian process, conditioned on the knots, as in Equation 1.5.
Tokdar (2007) suggests calculating the normalisation constant Z[g] numerically from
the knots using, for example, the trapezoidal rule or Simpson’s rule. It is suggested
that reversible-jump Monte Carlo be used to determine the number of knots in higher
dimensions, but it is unclear how the normalisation constant is to be estimated when
the knots are irregularly spaced. Additionally, when implementing this approxima-
tion for the logistic Gaussian process, I have found there to be pathological interaction
between the high-order interpolation done by the GP imputation and low-order nu-
merical estimates of the normalisation constant.
In Chapter 2, I present a model called the Gaussian process density sampler (GPDS). Like
the logistic Gaussian process, the GPDS is a prior on densities arising from a Gaussian
process. Unlike the logistic Gaussian process, however, it is possible to simulate data
exactly from a random density drawn from the GPDS prior. With a method available
for exact generation of data, it is possible to perform inference via Markov chain Monte

The Log Gaussian Cox Process
9
Carlo even though the likelihood is intractable.
1.4
The Log Gaussian Cox Process
The Poisson process is a widely-used model for point data in temporal and spatial
settings. It forms the foundation for several other types of point processes with more
sophisticated properties (e.g. Stoyan and Stoyan (1994) or Møller and Waagepetersen
(2004)). The inhomogeneous variant of the Poisson process allows the rate of arrivals
to vary in time (or space), but typically we do not have a preconceived idea of the ap-
propriate functional form for this variation. In this setting, it is often desirable to use
another stochastic process to describe nonparametrically the variation in the Poisson
intensity function. This construction is called a doubly-stochastic Poisson process, or a
Cox process (Cox, 1955), and it has been applied in a variety of settings, such as neu-
roscience (Brown, 2005; Cunningham et al., 2008b), astronomy (Gregory and Loredo,
1992), and forestry (Heikkinen and Arjas, 1999).
One variant of the Cox process is the Gaussian Cox process, where the intensity func-
tion is a transformation of a random realisation from a Gaussian process (GP). As in
the logistic Gaussian process of Section 1.3, this is a particularly convenient way to
nonparametrically specify beliefs about the intensity function via a kernel. We are
able to select a Gaussian process covariance function based on our prior conceptions
of the intensity function, without having to choose a particular parameterisation or a
ﬁnite set of basis functions.
The most straightforward way to build a Poisson process from a Gaussian process is
to use an exponentiated draw from the GP as the intensity function. That is, if the
intensity function is λ(x) on the domain X, then a random GP realisation is the log
of λ(x), i.e. g(x) = ln λ(x). This construction is called the log Gaussian Cox process
(LGCP) and it has been studied by Rathbun and Cressie (1994) and by Møller et al.
(1998).
Unfortunately, likelihood-based inference in the LGCP is intractable, for very simi-
lar reasons to those that render the logistic Gaussian process intractable. Not only is
there again an inﬁnite-dimensional function g(x) that must be represented in ﬁnite
memory, but there is also an intractable likelihood. If the data are a sequence of K
events {xk}K
k=1 on a ﬁnite region V in X, then the Poisson process likelihood of g is
p({xk}K
k=1 | g) = exp
(
−
Z
V
dx exp{g(x)}

+
K
X
k=1
g(xk)
)
.
(1.11)
As with Z[g] in Equation 1.8, the integral in Equation 1.11 involves an inﬁnite-
dimensional random function, and is unknowable for nontrivial Gaussian process
priors on g(x). When incorporated into Bayes’ Theorem, this likelihood results in

Other Density-Related Gaussian Process Models
10
another example of a doubly-intractable posterior distribution.
To address this intractability, Møller et al. (1998) propose discretising the region V.
In this ﬁnite-dimensional approximation, each cell in the grid is considered to have a
constant rate. The logs of these constant rates are then tied together via the Gaussian
process prior. Relative to the knot-based approximation of the logistic Gaussian pro-
cess, this approximation seems well-behaved in practice. Nevertheless, it requires the
practitioner to make an a priori choice of bin size.
Chapter 3 presents an alternative model to the log Gaussian Cox process, called the
sigmoidal Gaussian Cox process (SGCP). This model transforms draws from a Gaussian
process into random Poisson process intensity functions, but has the additional prop-
erty that it is fully generative. That is, it is possible to generate exact Poisson data from
a random intensity function drawn from the prior. As in the Gaussian process den-
sity sampler, this enables tractable fully-nonparametric Bayesian inference via Markov
chain Monte Carlo.
1.5
Other Density-Related Gaussian Process Models
The logistic Gaussian process and the log Gaussian Cox process are not the only mod-
els to incorporate Gaussian processes into Bayesian density models. Here I brieﬂy
review several related models.
1.5.1
The Csat´o Density Model
Exponentiating the draw from a Gaussian process as in Equation 1.7 is only one way
to arrive at a nonnegative random function. Csat´o (2002) proposes the transformation
f(x) =
g(x)2
R
V dx′ g(x′)2
(1.12)
as a way to construct a probability density f(x) from a random function g(x). Poste-
rior inference with this model is doubly-intractable, as in the logistic Gaussian process,
but it also has the problem of having many possible posterior modes. These modes
arise because various sign-changes of the latent function g(x) can result in identi-
cal f(x). While the LGP has redundancy — adding a constant function to g(x) results
in the same f(x) — it does not have this sign pathology.
1.5.2
The Gaussian Process Latent Variable Model
The Gaussian process latent variable model (GPLVM) of Lawrence (2005) is another way
to use a Gaussian process to model the distribution of complex data. In the GPLVM,

Other Density-Related Gaussian Process Models
11
the Gaussian process prior is not placed on the probability density function itself,
but the GP is used to provide a nonparametric distribution over maps from a low-
dimensional latent space into a high-dimensional observed space. The objective of
the GPLVM is to ﬁnd low-dimensional explanations of high-dimensional data, and
it can be viewed as a kernelised dual of probabilistic principal components analysis
(Tipping and Bishop, 1999), or as a nonparametric generalisation of the density net-
work (MacKay, 1995). If the observations are in a D-dimensional space, then the N
observed data Y = [y1, y2, . . . , yN] can be modeled by a linear transformation of N
data X = [x1, x2, . . . , xN] in a latent D′-dimensional space, plus zero-mean indepen-
dent Gaussian noise with variance σ2:
p(Y | A, X) =
N
Y
n=1
N(yn | Axn, σ2ID)
(1.13)
where A is a D × D′ transformation matrix. A zero-mean spherical Gaussian prior is
now placed on the components of A:
p(A) =
D′
Y
d=1
N(ad | 0D, ID)
(1.14)
and A is marginalised out, giving
p(Y | X) =
D
Y
d=1
N(y(d) | 0N, XXT + σ2IN),
(1.15)
where y(d) is the length-N vector of the observed values in the dth dimension.
Lawrence (2005) makes the observation that when A is marginalised out, Equa-
tion 1.15 gives the same probability distribution as would D independent Gaussian
processes with linear kernels and Gaussian observation noise σ2. This linear kernel
can be replaced with an inﬁnite-dimensional one, such as discussed in Section 1.2.1.
This is equivalent to applying the “kernel trick” (e.g. Vapnik (1995)) to the inner prod-
uct matrix XXT. The GPLVM then optimises the values in the latent space to ﬁnd
appropriate explanations for the observed data.
The GPLVM has a straightforward interpretation and has been successfully applied to
several difﬁcult real-world problems, but it is not tackling the problems addressed by
this thesis. It does not place a distribution on the latent variables and it optimises their
values. We cannot easily ﬁnd the value of the density for some new observed datum.
1.5.3
The Cunningham Poisson Model
Cunningham et al. (2008a) propose a Cox process model for temporal data that is sim-
ilar to the log Gaussian Cox process, but rather than transforming the random func-

Overview
12
tions into intensity functions, they use them directly, i.e. λ(x) = g(x). This approach
is used to avoid the nonlinear effects of the exponential transform, but the result is
an inconsistent model that assigns prior mass to negative intensities. The main fo-
cus of Cunningham et al. (2008a) is on ﬁnding an efﬁcient computational scheme for
maximum a posteriori (MAP) inference that is constrained to prevent the aforemen-
tioned negative intensities. Their approach is limited to the time domain, as they use
a renewal-process formalism. They use a discretisation for their ﬁnite-dimensional
approximation, in a fashion similar to Møller et al. (1998).
1.6
Overview
This rest of this thesis constructs new nonparametric probability density and point
process models based on Gaussian processes and explains how inference can be per-
formed in these models by extending recent developments in Markov chain Monte
Carlo methods. In Chapter 2, I present a method for constructing priors on probabil-
ity density functions that incorporates a Gaussian process. In Chapter 3, I develop a
similar prior for the intensity function of a Poisson process. Chapter 4 and Chapter 5
review two recently-developed Markov chain Monte Carlo methods and apply them
to the new priors on probability densities and point process intensity functions. In
Chapter 6, I apply these models and inference algorithms to a few example problems.
Chapter 7 presents some extensions to the models. In Chapter 8, I discuss the task of
semi-supervised learning and show how the density model of Chapter 2 can be ex-
panded to solve this problem in a nonparametric Bayesian manner. Chapter 9 reviews
the thesis and discusses some potential future directions of research.
Several papers have been or will be published whose content overlaps signiﬁcantly
with the work presented in this thesis. Adams et al. (2009a) presents the model in
Chapter 2 and some of the material in Chapter 5 and Chapter 6. Adams et al. (2009b)
(and also Adams et al. (2008)) overlaps with material in Chapter 2, Chapter 4, Chap-
ter 5, Chapter 6, and Chapter 7. Material from Chapter 3, Chapter 5 and Chapter 6
appear in Adams et al. (2009c). Adams and Ghahramani (2009) presents the model in
Chapter 8.

Chapter 2
The Gaussian Process Density
Sampler
This chapter constructs the Gaussian process density sampler (GPDS), which is a distribu-
tion on probability density functions, based on a Gaussian process. I discuss various
properties of this prior and develop a procedure for generating data that have been
drawn from a single density, where the density was drawn from this prior.
2.1
The Prior on Probability Density Functions
Recall from Section 1.2 that I am treating a Gaussian process as a prior on functions
that have X as their domain and the real line as their range. I now address the topic
of deﬁning a prior on probability density functions (PDFs) on X. As in Section 1.2
I continue to use RD as the example for X. Probability density functions have two
requirements: they must be everywhere nonnegative and they must integrate to one.
Sample realisations from a Gaussian process do not meet these constraints a priori,
so the realisations must be transformed into the space of PDFs. If g(x) is a sample
function from a Gaussian process, I transform it into a PDF f(x) via
f(x) =
1
Zπ[g] Φ(g(x)) π(x)
(2.1)
where π(x) is an arbitrary base density on X. The function Φ(·) : R →(0, 1) is a positive
function with upper bound 1. I use the bold notation g to refer to the function g(x)
compactly as a vector of (inﬁnite) length on which it is possible to perform inference.
The normalisation constant Zπ[g] is a functional of g(x):
Zπ[g] =
Z
X
dx′ Φ(g(x′)) π(x′).
(2.2)

The Prior on Probability Density Functions
14
(a) π(x) = U(−3, 3)
(b) π(x) = x
8 U(0, 4)
(c) π(x) = N(0, 1)
(d) π(x) = GA(3, 1)
(e) π(x) = N(0, I)
Figure 2.1: Unnormalised typical samples from the GPDS prior, i.e. samples from a
Gaussian process transformed by Equation 2.1.
In each case, the Gaussian process
uses a squared-exponential covariance function with ℓ= 1 and ω = 1. (a)–(d) are uni-
dimensional, using four different base densities π(x). Random unnormalised densi-
ties Φ(g(x)) π(x) are shown in colours, with with π(x) shown via a thicker black line.
(a) The base density is uniform on (−3, 3). (b) The base density is a “wedge” from 0 to 4.
(c) The base density is a standard normal distribution. (d) The base density is a gamma
distribution with shape α = 3 and inverse scale β = 1. (e) This is a two-dimensional
sample density where π(x) is the spherical Gaussian with zero mean and unit variance.
The length scales in both dimensions are 1
2.
I include a subscript π to indicate implicit dependence on the density π(x). As π(x) is
a normalised probability density function, the constant Zπ[g] is restricted to the inter-
val (0, 1) for any g(x). Through the map deﬁned by Equation 2.1, a Gaussian process
prior becomes a prior distribution over normalised probability density functions on X.
Figure 2.1 shows several samples from this prior.
2.1.1
The Response Function Φ(·)
The function Φ(·) may be interpreted as a response function (Rasmussen and Williams,
2006), or as a warping as in Snelson et al. (2004). Although Φ(·) is only required to be
positive and bounded, it is convenient for inference if it is a bijective map between R
and (0, 1). If Φ(·) is bijective then each realisation g(x) from the Gaussian process cor-
responds to a unique function that maps X to (0, 1). Sigmoids, such as the cumulative
normal distribution function and the logistic function, are bijective functions with this
domain and range. In this thesis, I take Φ(·) to be the logistic function
Φ(z) =
1
1 + e−z
(2.3)

The Prior on Probability Density Functions
15
(a) ℓx = 1, ℓy = 1, ω = 1
(b) ℓx = 1, ℓy = 1, ω = 5
(c) ℓx = 1
4, ℓy = 1
4, ω = 1
(d) ℓx = 1, ℓy = 1
4, ω = 3
Figure 2.2: Unnormalised samples from the GPDS prior for four different settings of the
squared exponential covariance function of Equation 1.2. In each case the base density
is a spherical Gaussian with zero mean and unit variance.
as it is inexpensive to calculate.
As a side note, if the Gaussian process has a mean of zero and unit variance every-
where, i.e. C(x, x) = 1, ∀x ∈X, and Φ(·) is the standard normal cumulative distribu-
tion function
Φnorm−cdf(z) =
1
√
2π
Z z′
−∞
dz′ e−1
2 (z′)2 = 1
2

1 + erf
 z
√
2

,
(2.4)
where erf(·) is the error function (Abramowitz and Stegun, 1964), then the realisa-
tions Φ(g(x)) are from an inﬁnite generalisation of a Gaussian copula (Nelsen, 2007).
The marginals of this “Gaussian copula process” are uniform on (0, 1).

Generating Data from the Prior
16
2.1.2
The Base Density π(x)
I use the term base density for π(x) in analogy to the Dirichlet process base measure
(Ferguson, 1973). The inclusion of the base density π(x) makes the model semipara-
metric by some deﬁnitions (Tokdar and Ghosh, 2007). As pointed out by M¨uller et al.
(2004), “nonparametric” Bayesian models would be better described as “massively
parametric.” Bayesian semiparametric models are also massively parametric, and so
I view nonparametric versus semiparametric, in the Bayesian context, to be a false
dichotomy.
I introduced hyperparameters θ for the Gaussian process covariance function in Sec-
tion 1.2, and here I introduce additional hyperparameters ψπ that control the base
density.
2.1.3
The Effect of Gaussian Process Hyperparameters
As in Gaussian process regression, the choice of covariance function determines the
properties of typical sample probability density functions drawn from the Gaussian
process density sampler prior. For a given covariance function, the hyperparameters
provide additional knobs to turn. In this case, I am assuming the squared-exponential
covariance function of Equation 1.2 and the hyperparameters available are the length
scales ℓ= {ℓd}D
d=1 and the amplitude ω. The length scales specify how close in value
the probabilities of two points in the data space should be, relative to how far apart the
points are. The ℓdetermines to what extent “similar data should have similar proba-
bilities,” where similarity is determined by an appropriately-deﬁned distance metric
on X. The amplitude parameter determines how much variation there is between
the areas that have the largest densities versus those that have the smallest densities.
Large values of ω cause typical samples of g(x) to be more likely to saturate the sig-
moid Φ(·), leading to cliffs in the density and plateaus where the shape of the density
is very close to zero or very close to π(x). Figure 2.2 shows the effects of varying these
hyperparameters in two dimensions.
2.2
Generating Data from the Prior
The reason for introducing the GPDS construction of Section 2.1 rather than using
the logistic Gaussian process discussed in Section 1.3 is that the transformation in
Equation 2.1 allows the simulation of samples on the data space X, drawn from a
random density f(x) that has been drawn from from the prior. It is possible, in effect,
to draw a random density f(x) from the prior and then draw exact data on X that are
i.i.d. from f(x). Of course, f(x) is unknown, but the data are still exact. I use a variant
of rejection sampling to draw these data.

Generating Data from the Prior
17
p′(x)
c · q(x) = N(0, 1)
Figure 2.3: Schematic representation of rejection sampling. The red area is the dominat-
ing density c · q(x) = N(x | 0, 1), a standard Gaussian distribution with zero mean and
unit variance. In this example, c = 1. The blue area shows a more complicated unnor-
malised density p′(x), from which samples are required. Both densities are truncated
to the interval [−3, 3]. There are 1000 points uniformly distributed in the combined red
and blue areas. Only points in the blue area are kept, and the histogram in the lower
plot shows the resulting empirical density.
2.2.1
Rejection Sampling
Rejection sampling (e.g. Devroye (1986, Chapter 2), Robert and Casella (2004, Chapter
2), or MacKay (2003, Chapter 29)) is an algorithm for generating exact samples from
a probability density function. By “exact” I mean that the samples are not biased,
for example, by the starting state of a ﬁnite Markov chain. Here, I will denote the
density from which I intend to draw samples as p(x), and the known function pro-
portional to p(x) as p′(x). Rejection sampling is applicable in situations where p(x)
is known within a constant factor but is too complicated for direct sampling. One
chooses a proposal density q(x) from which it is possible to generate exact samples,
and a constant c such that the function c · q(x) provides an upper bound for p′(x),
i.e. ∀x ∈X, c · q(x) ≥p′(x).
To perform rejection sampling, in the rth iteration generate a random variate ˜xr from
the proposal density q(x). A random variate ur is then drawn uniformly on the inter-
val between zero and the upper-bounding function at ˜xr, that is ur ∼U(0, c · q(˜xr)).
The proposal ˜xr is accepted if ur is less than p′(˜xr), and otherwise rejected. This
idea is shown graphically in Figure 2.3, highlighting why this algorithm works: if
the pairs (˜xr, ur) are drawn uniformly beneath p′(x), then the marginal distribution
of ˜xr is p(x) (Robert and Casella, 2004). To generate these uniform pairs (˜xr, ur), gen-
erate uniformly from a larger envelope provided by c · q(x) and discard those that fall
above p′(x). Algorithm 2.1 shows the procedure in pseudocode.

Generating Data from the Prior
18
Algorithm 2.1
Generate N exact samples from p(x) via rejection sampling.
Inputs:
• Number of samples to draw N
• Unnormalised density p′(x) ∝p(x)
• Proposal density q(x)
• Constant c such that c · q(x) ≥p′(x), ∀x
Outputs:
• N samples from p(x), D = {˜xn}N
n=1
1: r ←0
▷Count the number of proposals made.
2: repeat
3:
˜xr ∼q(x)
▷Draw a proposal.
4:
ur ∼U(0, c · q(˜xr))
▷Draw uniformly beneath the proposal distribution.
5:
if ur < p′(˜xr) then
▷Acceptance rule.
6:
D ←D ∪˜xr
▷Store the proposal, discard ur.
7:
end if
8:
r ←r + 1
9: until |D| = N
▷Loop until N samples are accepted.
10: return D
Rejection sampling for probability densities is generally credited to von Neumann
(1951), although the concept of the reject/accept procedure for calculation by Monte
Carlo simulation is at least as old as 1733 when Georges-Louis Leclerc, Comte de Buf-
fon, proposed repeated drops of a needle as a means of estimating the constant π. This
was published years later in Leclerc de Buffon (1777), and has come to be known as
“Buffon’s Needle” (see Holgate (1981) for further discussion).
As discussed in MacKay (2003, Chapter 29), rejection sampling tends to become expo-
nentially less efﬁcient with increasing dimensionality. The function c · q(x) generally
becomes a very loose bound on p′(x) as the dimensionality increases, and so most
proposals are rejected.
2.2.2
Sampling from the GPDS
Rejection sampling can be used to simulate a set of data from a common density drawn
from the the prior described in Section 2.1. The proposal density in this case is π(x)
with c = 1. As the function Φ(g(x)) is less than one for all g(x), π(x) is guaranteed
to be an upper bound for Φ(g(x)) π(x) regardless of the realisation from the Gaussian
process. I assume that it is possible to draw samples directly from π(x).
If g(x) were known, it would be possible to generate samples from the associated
density f(x) ∝Φ(g(x)) π(x) as in Section 2.2.1. However, in the GPDS, g(x) is not
known: it is a random function drawn from a Gaussian process prior. Nevertheless,
rejection sampling can be used by “discovering” g(x) during the procedure, sampling
the function from the GP only at the places where it is necessary. As it is required only
to know g(x) at the {˜xr} to accept or reject these proposals, the samples are still exact.
It is possible to generate the samples sequentially, as shown graphically in Figure 2.4
and via pseudocode in Algorithm 2.2. In each loop, a proposal is drawn from the base

Generating Data from the Prior
19
1
0
Φ(g(x)) samples
(a) Initial state
˜x1
(b) Draw ˜x1 ∼π(x)
Φ(g1)
(c) Sample g1 from GP
u1
(d) Draw u1 ∼U(0, 1)
0
1
˜x2
u2
Φ(g2)
(e) Iteration r = 2
˜x3
Φ(g3)
u3
(f) Iteration r = 3
˜x4
u4
Φ(g4)
(g) Iteration r = 4
(h) Iteration r = 100
Figure 2.4: Several iterations of the GPDS sampling procedure. In these ﬁgures, the
base density π(x) is uniform on the interval shown. In Figures (a)–(g), three posterior
function samples are shown. Figure (h) only shows one function sample from the GP
posterior. Figures (e)–(h) also show histograms of the accepted samples.
density π(x) and the function g(x) is sampled from the Gaussian process at this pro-
posed coordinate, conditioning on all the function values already sampled. I will call
these data the conditioning set for the function g(x), and will denote the conditioning
inputs as X and the conditioning function values as G. After the function is sampled,
a variate is drawn uniformly from (0, 1) and compared to the Φ-squashed function at
the proposal location. If the uniform variate falls below Φ(g(x)) then accept the pro-
posal, otherwise reject. The proposals and their function values are added into the
conditioning set regardless of whether that proposal was accepted or rejected. The
loop repeats until there have been as many acceptances as are required.
2.2.3
Inﬁnite Exchangeability
If x1, x2, . . . is a possibly-inﬁnite sequence of data from a random process, the proce-
dure to generate the data is said to be inﬁnitely exchangeable if the joint probability of
any ﬁnite-length subsequence is the same under reordering. In other words, the pro-
cedure is exchangeable if p(x1, x2, . . . , xR) = p(xΠ(1), xΠ(2), . . . , xΠ(R)) for any R and
all permutations Π (Bernardo, 1996).
Exchangeability is a desirable property for Bayesian analysis. By de Finetti’s theo-
rem (Hewitt and Savage, 1955), it implies that the data may be considered condition-
ally independent, given some possibly-inﬁnite set of parameters γ. Moreover, as dis-
cussed by Bernardo (1996), the exchangeability of a sequence {x1, x2, . . . xR} implies

Generating Data from the Prior
20
Algorithm 2.2
Generate N samples from a density drawn from the GPDS prior.
Inputs:
• Number of samples to draw N
• Gaussian process covariance function C(x, x′ ; θ)
• Base density π(x | ψπ)
Outputs:
• N samples D = {xn}N
n=1 from a density drawn from the prior.
1: X ←∅, G ←∅
▷Initially the conditioning sets are empty.
2: D ←∅
▷Initialise the set to be returned.
3: r ←0
▷Count the number of proposals.
4: repeat
5:
˜xr ∼π(x | ψπ)
▷Draw a proposal.
6:
g(˜xr) ∼GP(g | ˜xr, X, G, θ)
▷Sample from the GP at the proposal.
7:
ur ∼U(0, 1)
▷Draw uniformly on (0, 1).
8:
if ur < Φ(g(˜xr)) then
▷Acceptance rule.
9:
D ←D ∪˜xr
▷Store the proposal, discard ur.
10:
end if
11:
X ←X ∪˜xr
▷Update the conditioning sets, even on rejections.
12:
G ←G ∪g(˜xr)
13:
r ←r + 1
14: until |D| = N
▷Loop until N samples are accepted.
15: return D
that there exists a probability distribution p(γ) such that
p(x1, x2, . . . , xR) =
Z
Γ
dγ p(γ)
R
Y
r=1
p(xr | γ).
(2.5)
Additionally, exchangeability implies the existence of a predictive distribution on the
data space given by
p(x | x1, x2, . . . , xR) =
Z
Γ
dγ p(x | γ) p(γ | x1, x2, . . . , xR).
(2.6)
These properties are critical to the validity of the inference and prediction tasks that I
will examine in later chapters.
The data generation procedure of Section 2.2.2 and Algorithm 2.2 is inﬁnitely ex-
changeable; the joint probability of a set of accepted proposals is the same under
reordering. Informally, one can see that the procedure is exchangeable by consid-
ering a different way of generating the data. We could draw R independent vari-
ates {˜xr}R
r=1 from π(x). We could then sample the function values {g(˜xr)}R
r=1 from
the R-dimensional Gaussian distribution implied by the {˜xr}R
r=1. The multivariate
Gaussian is exchangeable in its components. Finally, each accept/reject decision is an
independent Bernoulli draw with probability of acceptance Φ(g(˜xr)). We could per-
form each step simultaneously and draw all R at once, without introducing a concept
of ordering. This procedure would work for any R.
More formally, I introduce br ∈{0, 1} to indicate whether the rth proposal ˜xr is ac-
cepted (1) or rejected (0). I use the shorthand τr to indicate the rth triplet (˜xr, g(˜xr), br).
Consider the joint probability of a length-R sequence of triplets from the generative

Generating Data from the Prior
21
(a) ℓx = 1, ℓy = 1, ω = 1
(b) ℓx = 1, ℓy = 1, ω = 5
(c) ℓx = 1
4, ℓy = 1
4, ω = 1
(d) ℓx = 1, ℓy = 1
4, ω = 3
Figure 2.5: Using the same densities drawn in Figure 2.2, 250 draws on data space using
the algorithm of Section 2.2.2.
algorithm:
p(τ1, . . . , τr, τr+1, . . . , τR) =
p(τ1) · · · p(τr | {τr′}r−1
r′=1) p(τr+1 | {τr′}r
r′=1) · · · p(τR | {τr′}R−1
r′=1).
(2.7)
To prove exchangeability, it sufﬁces to show that τr and τr+1 can be exchanged for
any r < R without changing the probability, as it is possible to arrive at any permu-
tation of {1, 2, . . . , R} by adjacent pairwise swaps (Cormen et al., 2001). By causal-
ity, the joint probability of exchanging τr and τr+1 does not affect the joint probabil-
ity p(τ1, . . . , τr−1), so it is only necessary to show that
p(τr, τr+1, . . . , τR | {τr′}r−1
r′=1) = p(τr+1, τr, . . . , τR | {τr′}r−1
r′=1).
(2.8)

Summary
22
I write the joint for the left side of Equation 2.8:
p(τr, τr+1, . . . , τR | {τr′}r−1
r′=1) =
R
Y
r′=r
π(˜xr′) GP(g(˜xr′) | {˜xr′′, g(˜xr′′)}r′−1
r′′=1, ˜xr′) Φ(g(˜xr′))br′ [1 −Φ(g(˜xr′))]1−br′.
The π(˜xr′), Φ(g(˜xr′))br′ and [1 −Φ(g(˜xr′))]1−br′ terms inside the product are not con-
ditioned on any previous parts of the sequence, so their probability does not change
under reordering. After removing these invariant factors Equation 2.8 has only Gaus-
sian process terms. I combine these to form the joint distribution
GP(g(˜xr), g(˜xr+1) | {˜xr′, g(˜xr′)}r−1
r′=1, ˜xr, ˜xr+1)
(2.9)
in which g(˜xr) and g(˜xr+1) can be exchanged as long as ˜xr and ˜xr+1 are also ex-
changed.
2.3
Summary
This chapter introduced a prior on probability density functions that is based on trans-
formation of a Gaussian process. This prior is unique in that one can draw data from a
single density drawn from the prior. I call the prior and the associated data generation
procedure the Gaussian process density sampler.
Later chapters will demonstrate two ways to perform inference using this prior. The
ability to generate exact data will be crucial to the inference method of Chapter 4. In
Chapter 5, I will actually model the GPDS rejection sampler itself to perform infer-
ence.

Chapter 3
The Sigmoidal Gaussian Cox
Process
This chapter reviews the Poisson process and constructs the sigmoidal Gaussian Cox
process (SGCP), which is a Gaussian Cox process from which it is possible to generate
exact data. I begin with a discussion of Poisson and Cox processes in Section 3.1. Sec-
tion 3.2 reviews methods for generating Poisson event data. I introduce the sigmoidal
Gaussian Cox process in Section 3.3 and present the associated generative procedure
in Section 3.4. Section 3.5 examines a variety of Poisson-derived point processes and
discusses how the SGCP can incorporate nonparametric inhomogeneity into them.
3.1
The Poisson and Cox Processes
As before, I consider the space X = RD, and V is a bounded subset of X. A point pro-
cess on V is a random process that generates ﬁnite subsets of V. I will denote one
of these ﬁnite subsets as S ⊂V and refer to members of S as “events.” A point
process can be thought of as a random measure that takes nonnegative integer val-
ues, or a locally-ﬁnite random counting measure. A measure on X that is locally-ﬁnite
has the property that the measure of any bounded subset of X is ﬁnite (Møller and
Waagepetersen, 2004). Intuitively, a point process being locally ﬁnite means that for
any bounded region of X, the process will always realise a ﬁnite number of points.
A Poisson process is a point process with a locally-integrable intensity function (or rate
function) λ(x) : V →R+, where R+ denotes the nonnegative real numbers. Local in-
tegrability is the property that
R
V dx λ(x) < ∞for any bounded subset V ⊂X (Møller
and Waagepetersen, 2004). The Poisson process is deﬁned by two properties. First, the
number of events in a subset T of V is Poisson-distributed with parameter
ΛT =
Z
T
dx λ(x).
(3.1)

Generating Poisson Data
24
(a) One-dimensional temporal Poisson process
(b) Two-dimensional Poisson process
Figure 3.1: Examples of Poisson process realisations. (a) A one-dimensional Poisson
process in time, along with three independent time series realisations. (b) A spatial
Poisson process in two dimensions. The intensity function is shown by the colours and
a realisation of points is overlaid.
As λ(x) is locally ﬁnite, ΛT is always ﬁnite. Second, the number of events in disjoint
subsets of V are independent. This second property is called independent scattering
(Møller and Waagepetersen, 2004).
Figure 3.1a shows an example of a one-dimensional Poisson process and three
independently-drawn sets of events.
Figure 3.1b shows an example of a two-
dimensional Poisson process and a set of spatial events. Generally, in this chapter
I will use λ(t) when discussing the intensity function of a one-dimensional Poisson
process, and use λ(x) to refer to the intensity functions of Poisson processes with an
arbitrary number of dimensions. I will use the notation PP(S | V, λ(x)) to refer to the
probability density associated with a particular set of Poisson events S on a domain V
with intensity function λ(x):
PP(S = {xk}K
k=1 | V, λ(x)) = exp

−
Z
V
dx λ(x)
 K
Y
k=1
λ(xk).
(3.2)
3.2
Generating Poisson Data
There are several available methods for simulating data from a Poisson process. Their
applicability depends on the speciﬁc form of λ(x) and the domain V.

Generating Poisson Data
25
3.2.1
Direct Sampling
The simplest case is when λ(x) is a positive constant, i.e. λ(x) = c, where c > 0. This
is called the homogeneous Poisson process. To generate data from a homogeneous Pois-
son process on V with intensity c, ﬁrst calculate the measure of the set V, which I de-
note µ(V). Next, draw the number of events K from a Poisson distribution with param-
eter c · µ(V), i.e. K ∼PO(c · µ(V)). Finally, draw the locations of the K events, {xk}K
k=1,
by distributing the points independently and uniformly within V, i.e. xk ∼U(V).
For the inhomogeneous Poisson process, where λ(x) varies over V, it is possible to use
a two-stage procedure to draw Poisson data on V. First, integrate over the intensity
function:
ΛV =
Z
V
dx λ(x).
(3.3)
Use ΛV as the Poisson distribution parameter to determine the number of events in V,
via K ∼PO(ΛV). Finally, distribute the events independently within V according to
the probability density
f(x) = 1
ΛV
λ(x) IV(x),
(3.4)
where IV(x) is a set-membership indicator function for V (Devroye, 1986, Theorem
VI.1.5):
IV(x) =



1
if x ∈V
0
otherwise
.
(3.5)
3.2.2
Time Rescaling
A useful property of the homogeneous Poisson process in one dimension is that the
inter-event arrival times are exponentially distributed. That is, if
0 < t1 < t2 < . . . < tj−1 < tj < . . .
are events from a Poisson process with constant rate c, then
tj −tj−1 ∼EX(c).
(3.6)
This renewal-process approach, also called the exponential spacings method (Devroye,
1986), provides an alternative way to generate data from a temporal homogeneous
Poisson process.
When a Poisson process has a time-varying intensity λ(t), the
renewal-process method can sometimes be used to generate inhomogeneous Poisson

Generating Poisson Data
26
(a) Poisson process on a bounding box.
(b) Poisson process on the irregular region.
Figure 3.2: Thinning allows simulation of Poisson processes on irregular shapes, such as
this Lambert equal-area azimuthal projection of the island of Great Britain. On the left
are points from a homogeneous Poisson process on a rectangle that bounds the shape.
On the right, only points within the coastline have been kept.
realisations via time rescaling (Meyer, 1971; Papangelou, 1972). Taking the domain to
be [0, ∞), the cumulative intensity function is
Λ(t) =
Z t
0
dt′ λ(t′).
(3.7)
If a sequence 0 < t1 < t2 < . . . is a realisation from a unit-intensity homogeneous Pois-
son process, then the sequence 0 < Λ−1(t1) < Λ−1(t2) < . . . is a realisation from an
inhomogeneous Poisson process with cumulative intensity function Λ(t) (Devroye,
1986, Theorem VI.1.4), where Λ−1(t) is the inverse of Λ(t).
3.2.3
Thinning
Consider a realisation S = {xk}K
k=1 from a Poisson process with intensity λ(x), and
a function φ(x) : V →[0, 1]. For each of the K events in S, make an independent
draw from a Bernoulli distribution and remove the kth event from S with probabil-
ity 1 −φ(xk). Based on these independent random removals, a new set S′ is formed.
This new set S′, composed of any remaining events, is a realisation from a Poisson
process with intensity function λ′(x) = φ(x) λ(x). This procedure is called indepen-
dent thinning (Lewis and Shedler, 1979).
Thinning bears a strong resemblance to rejection sampling, discussed in Section 2.2.1,
and thinning can be used to generate Poisson process data from a complex intensity
function λ(x). Thinning requires a dominating intensity function ¯λ(x) that provides an
upper bound for λ(x), i.e. ¯λ(x) ≥λ(x), ∀x ∈V. Typically, ¯λ(x) is selected so that it
is easy to generate a Poisson realisation ¯S ∼PP(V, ¯λ(x)). The set ¯S can be turned

The Prior on Poisson Intensity Functions
27
into a realisation S from λ(x) by keeping events with independent Bernoulli probabil-
ity φ(x) = λ(x)/¯λ(x).
In spatial problems, interesting domains are often irregularly-shaped. Thinning can
be used to arrive at Poisson data that are drawn inside a region from which it would
be difﬁcult to sample directly. If the region of interest is V, construct a bounding
shape V′ ⊃V on which it is easy to simulate Poisson data, e.g. a rectangle. Next
simulate a Poisson process on V′ and discard those events that did not fall within V by
using φ(x) = IV(x), where IV(x) is a set-membership indicator function. Figure 3.2
provides an example using the coastline of Great Britain.
3.3
The Prior on Poisson Intensity Functions
As in Section 2.1, I consider a function g(x) : X →R, which is a realisation from a
Gaussian process. I transform this function into a Poisson intensity function via
λ(x) = Φ(g(x)) ¯λ(x),
(3.8)
where Φ(·) is a sigmoid function as in Section 2.1.1. As in Chapter 2, I will assume
that Φ(·) is the logistic function. The function ¯λ(x) is a parametric intensity from which
it is easy to generate Poisson process realisations, using, for example, the methods
in Section 3.2.1. I call this prior the sigmoidal Gaussian Cox process (SGCP), as it is a
Cox process where the intensity function is a sigmoidally-transformed draw from a
Gaussian process.
Realisations from the prior implied by a Gaussian process prior on g(x) and the trans-
formation of Equation 3.8 are random positive functions bounded above by ¯λ(x). As
with the GPDS base density in Section 2.1.2, I allow for hyperparameters ψλ that de-
termine the behaviour of ¯λ(x). When ψλ is relevant, I will write ¯λ(x ; ψλ).
3.4
Generating Data from the Prior
I use the transformation of Equation 3.8 because it allows simulation of exact Poisson
data from a random intensity function drawn from the prior provided by the Gaussian
process. As in Chapter 2, by exact I mean that the data are not biased by an approxi-
mate sampling procedure. I use thinning, discussed in Section 3.2.3, to generate these
data and augment the procedure to simultaneously sample the function g(x) from the
Gaussian process.
The objective is to generate a set of events {xk}K
k=1 on V ⊂X, where K is itself ran-
dom, from a Poisson process with an intensity function λ(x) that is the result of ap-
plying Equation 3.8 to a random function g(x) drawn from the Gaussian process. This

Generating Data from the Prior
28
¯λ(x)
{˜xj}
(a) Dominating intensity and initial events.
{Φ(g(˜xj))¯λ(˜xj)}
(b) Sampling the Gaussian process at the events.
{¯λ(˜xj)uj}
(c) Sampling in the vertical coordinate for thinning.
{xk}
λ(x)
(d) The kept events and random intensity function.
Figure 3.3: The generative procedure for the SGCP. (a) The (constant) dominating inten-
sity ¯λ(x) = 4 is shown, along with a Poisson series, {˜xj}J
j=1, generated from it. (b) At
each event, a sample is drawn from the Gaussian process, to get the set {g(˜xj)}J
j=1.
This function is squashed through the sigmoid function so that it is everywhere posi-
tive and upper-bounded by ¯λ(x). (c) Variates {uj}J
j=1 are drawn uniformly on (0, 1) in
the vertical coordinate. d) If the jth uniform variate is greater than the random function
value Φ(g(˜xj)), then event ˜xj is discarded. The kept events are drawn from the inhomo-
geneous Poisson process corresponding to the random intensity λ(x) = Φ(g(x)) ¯λ(x).
is done by ﬁrst simulating a set of events {˜xj}J
j=1 from a Poisson process on V with
intensity ¯λ(x), using the procedure of Section 3.2.1. Next, treat these {˜xj}J
j=1 as input
points for a Gaussian process and sample the function g(x) at these locations to gener-
ate a corresponding set of function values, denoted {g(˜xj)}J
j=1. Now use the thinning
procedure to choose which K ≤J events of {˜xj}J
j=1 will be kept so that the remaining
events, {xk}K
k=1, are drawn from an inhomogeneous Poisson process with an intensity
function λ(x) consistent with the {g(˜xj)}J
j=1 drawn from the Gaussian process. This
is done by generating J uniform random variates on (0, 1), denoted {uj}J
j=1. Only
events for which uj < Φ(g(˜xj)) are kept. Any accepted events form the set {xk}K
k=1.
This procedure is shown in Algorithm 3.1 and graphically in Figure 3.3.

Point Process Extensions to the SGCP
29
Algorithm 3.1
Generate a set of Poisson events from the SGCP prior.
Inputs:
• Domain V
• Gaussian process covariance function C(x, x′ ; θ)
• Dominating intensity function ¯λ(x ; ψλ)
Outputs:
• Poisson events S = {xk}K
k=1 from an SGCP prior
1: {˜xj}J
j=1 ∼PP(V, ¯λ(x ; ψλ))
▷Draw Poisson events according to intensity ¯λ(x ; ψλ).
2: {g(˜xj)}J
j=1 ∼GP(g | {˜xj}J
j=1, θ)
▷Draw the function from the GP at the events.
3: S ←∅
▷Initialise the set of unthinned events.
4: for j ←1 . . . J do
▷Loop over the proposed events.
5:
uj ∼U(0, 1)
▷Draw a uniform random variate on the unit interval.
6:
if uj < Φ(g(˜xj)) then
▷Apply the thinning acceptance rule.
7:
S ←S ∪˜xj
▷Add to the accepted events.
8:
end if
9: end for
10: return S
To generate data from the SGCP prior on an irregular region, a two-stage thinning
procedure can be used. First, generate Poisson data for the bounding region as in
Section 3.2.3. Next, discard events outside of the region. Sample the Gaussian process
only at the remaining events and perform the accept/reject thinning as above. This
procedure is provided in pseudocode in Appendix A as Algorithm A.1 (page 117).
As in the Gaussian process density sampler, the generative procedure for the sig-
moidal Gaussian Cox process makes it possible to simulate exact data from an inﬁnite-
dimensional random function without knowledge of the function at more than a ﬁ-
nite number of locations and without integrating over the function. In Chapter 4 and
Chapter 5, I will show that being able to generate data from the prior means that in-
ference can be done tractably via Markov chain Monte Carlo.
3.5
Point Process Extensions to the SGCP
The Poisson process is a widely-used model for temporal and spatial data, but it is
also the foundation for other types of point process with different properties. In this
section I discuss how the sigmoidal Gaussian Cox process can be used to introduce
nonparametric inhomogeneity into such processes to achieve marking and interaction.
3.5.1
The Marked Poisson Process
Given a set of events S drawn from a Poisson process, we might also wish to model
characteristics of those events. For example, a Poisson process might be used to model
trees in a forest, and layered upon that might be a probabilistic model for determin-
ing the species of each tree. A marked Poisson process is a distribution on the product
space of ﬁnite subsets of the domain V (realisations from the Poisson process on V),

Point Process Extensions to the SGCP
30
(a) Spatial intensity function
(b) Categorical marks
(c) Real-valued marks
Figure 3.4: (a) A Poisson intensity function on the unit square. (b) A multitype Poisson
process with four classes, shown as different marker types. This was drawn using the
SGCP with the intensity function in (a). (c) A marked Poisson process with a random
real-valued “orientation” characteristic. This was also drawn from an SGCP with the
intensity function in (a).
and some additional space Y that is the mark space. The distribution on marks is condi-
tioned on the event locations and the marks are independent, given the Poisson reali-
sation. If Y is a ﬁnite set, then the construction is sometimes called a multitype Poisson
process (Møller and Waagepetersen, 2004). Marked point processes with real-valued
marks have been used, for example, to model the luminosity properties of galaxies
(Beisbart and Kerscher, 2000). If y is a point in the mark space, i.e. y ∈Y, then the
joint distribution of a marked Poisson process realisation can be written as
p({xk, yk}K
k=1) = PP({xk}K
k=1)
K
Y
k=1
p(yk | xk).
(3.9)
From a simulation point of view, it is simple to turn the generative process for the
SGCP into one that also has marks. After using Algorithm 3.1 to generate the events,
draw a mark for each one from its conditional distribution.
Figure 3.4b and Fig-
ure 3.4c show realisations from marked Poisson processes with categorical marks and
real-valued marks, respectively. The associated intensity function is shown in Fig-
ure 3.4a. Algorithm A.2 (page 118) in Appendix A provides pseudocode for simulat-
ing a marked sigmoidal Gaussian Cox process.
The Boolean, or germ-grain, model is a marked Poisson process variant for generating
random closed subsets of the domain V. Typically, the Poisson event locations (germs)
are the centres of random local compact subsets (grains), which are drawn from the
marking distribution. The resulting random object is the union of these subsets. In
two dimensions this can be viewed as a distribution on binary images, and in three
dimensions as a model of volume occupancy. To extend the sigmoidal Gaussian Cox
process to the Boolean model, generate Poisson events from a random intensity using
Algorithm 3.1, then draw the marks that specify the properties of the local compact
set associated with each event. Figure 3.5b shows an SGCP Boolean model with a

Point Process Extensions to the SGCP
31
(a) Spatial intensity function
(b) Union of random squares
(c) Density from random circles
Figure 3.5: (a) A Poisson intensity function on the unit square. (b) A Boolean model re-
alisation via the SGCP with squares of random size and orientation. The union of these
squares creates a random subset of the unit square. The underlying Poisson intensity
is as in (a). (c) A Boolean model realisation with overlapping circles of random radius.
The density that results from accumulated set membership is shown in the colours.
union of squares of random size and orientation. Similar models were introduced
simultaneously by Kolmogorov (1937)1, Johnson and Mehl (1939) and Avrami (1939,
1940, 1941) as descriptions of crystal growth. Figure 3.5c shows an alternative use
of the Boolean model, where each local subset (in this case, determined by a circle
of random size) contributes additively to a local density. The Poisson intensity that
generated these processes is shown in Figure 3.5a. For an extensive discussion of the
Boolean model, see Molchanov (1997).
3.5.2
Point Processes with Interaction
The deﬁning characteristic of the Poisson process is that it has no interaction between
the events — once the number of events has been determined, the locations are dis-
tributed independently. This independence is not always a realistic modeling assump-
tion. It may be desirable for events to cluster together (underdispersion) or repel each
other (overdispersion). In this section, I examine several models with interaction and
show how the generative procedure of the sigmoidal Gaussian Cox process can be
extended to sample from them.
The Neyman–Scott (Neyman and Scott, 1958), Hawkes (Hawkes, 1971a,b; Hawkes;
Hawkes and Oakes, 1974), and Mat´ern (Mat´ern, 1960)2 point process families are in-
teresting from the point of view of exact simulation, because they are deﬁned by their
Poisson-based generative procedures and not in terms of their probability densities
on data. This is in contrast to, for example, the Strauss process (Strauss, 1975; Kelly
and Ripley, 1976) and more general Gibbs/Markov processes (see, e.g. Møller and
Waagepetersen (2004), Ogato and Tanemura (1989), and Stoyan and Stoyan (1998)),
which describe interactions between points via a potential function on conﬁgurations.
1Kolmogorov (1937) was translated into English in Kolmogorov (1992).
2Mat´ern (1960) was translated into English in Mat´ern (1986)

Point Process Extensions to the SGCP
32
(a) Mother process realisation
(b) Daughter process realisations
(c) Final observed points
Figure 3.6: An example of how a mother-daughter clustering process works. (a) The
mother process realises a set of points on the domain. (b) Daughter processes local to
each mother point are used to generate daughter realisations. (c) Only the daughter
points are kept.
There has been signiﬁcant interest in perfect simulation via coupling from the past
(CFTP) (Propp and Wilson, 1996) of homogeneous variants of Gibbs/Markov pro-
cesses (Kendall, 1997; H¨aggstr¨om et al., 1999; Kendall and Møller, 2000; Wilson, 2000),
but this thesis does not explore these methods.
Clustering Point Processes
Clustering point processes are those in which points tend to be more grouped than
would be expected if they were from a Poisson process. A natural idea for a clustering
point process is to use two stages: a “mother” process and a random set of “daughter”
processes. The mother point process ﬁrst realises a set of locations in the space and
then the daughter processes are localised around those random locations. The realisa-
tions from the daughter processes are the observations. Figure 3.6 illustrates this idea
graphically. Plants provide a motivating example for this kind of distribution: seeds
tend to land and sprout near their parents. Brix and Chadœuf (2002) examine such
a model for the distribution of weeds. There is a large taxonomy for these types of
processes, depending on the exact nature of the mother and daughter processes, see
e.g. Lawson and Dension (2002, Chapter 4). For example, if the daughter processes
are Poisson, then the overall process falls into the broad class of generalised shot noise
Cox processes described by Møller and Torrisi (2005). Here I am concerned with vari-
ants that have Poisson mother processes, as the sigmoidal Gaussian Cox process pro-
vides a drop-in replacement for the mother process to make it inhomogeneous. If the
daughter processes are Poisson, then these extended models could be called “triply-
stochastic” Poisson processes as they use the events from a Cox process to realise an
additional random Poisson intensity.

Point Process Extensions to the SGCP
33
(a) Mother SGCP intensity
(b) Mat´ern cluster process
(c) Truncated Thomas process
Figure 3.7: Realisations of Neyman–Scott processes with inhomogeneity in the mother
Poisson process introduced via the SGCP.
(a) The mother process intensity.
(b) A
Mat´ern cluster process realisation with daughter homogeneous intensity 2000 on a disc
of radius 0.05. (c) A truncated Thomas process with isotropic Gaussians of σ = 0.03,
truncated to a disc with radius 4σ.
The Neyman–Scott Process
The Neyman–Scott process (Neyman and Scott, 1958) is
the simplest example of a mother-daughter process: both mother and daughter are
Poisson. Generally, the mother and daughter intensity functions are different. The
daughter processes all typically have the same intensity function, except that they are
centred on the mother points. As the Neyman–Scott process has Poisson daughter
realisations, it is a Cox process (Stoyan and Stoyan, 1994; Møller and Waagepetersen,
2004) and the resulting intensity function has the form
λΣ(x) =
J
X
j=1
λdtr(x ; xmtr
j
)
(3.10)
where the set {xmtr
j
}J
j=1 is drawn from the mother Poisson process.
Usu-
ally, λdtr(x ; xmtr) is a scaled unimodal probability density function (kernel) centred
on xmtr. For example, the Thomas process (Thomas, 1949) is a Neyman–Scott process
where the intensity function of each daughter is a scaled isotropic Gaussian distri-
bution centred at the mother point, i.e. λdtr(x ; xmtr) = ν · N(x; xmtr, σ2ID) for some
variance σ2 and total intensity ν > 0. The Mat´ern cluster process (Mat´ern, 1960) is a
Neyman–Scott process where each daughter intensity is uniform with intensity ν on
a disc of radius z around the mother point.
The generative procedure of the sigmoidal Gaussian Cox process can be used to gen-
erate inhomogeneous Neyman–Scott cluster locations: use Algorithm 3.1 to generate
the mother points, generate the daughter points as in the homogeneous case, and then
keep the daughter points as the observations. Edge effects do introduce some com-
plication, however, if mother points are allowed to be generated outside V. Daughter
points can appear inside V even if the mother point is outside the boundary, and so to
make the claim that the generative procedure is exact, this must be taken into account.
If the centred daughter kernel has compact support Q, then ﬁrst generate data on a

Point Process Extensions to the SGCP
34
larger domain V ⊕Q, where the binary operator ⊕indicates the Minkowski sum. It
is not obvious how to draw exact samples from a Neyman–Scott process where the
daughter kernel has unbounded support, as in the Thomas process: mother points
could be arbitrarily far away and still have a non-zero probability of placing a daugh-
ter point within V.
Algorithm A.3 (page 118) in Appendix A provides the inhomogeneous SGCP
Neyman–Scott generation algorithm in pseudocode. Figure 3.7b shows an inhomo-
geneous Mat´ern cluster process on the unit square using the sigmoidal Gaussian Cox
process with daughter intensity ν = 2000 and radius z = 0.05. Figure 3.7c shows
an SGCP-based Neyman–Scott process on the unit square where the daughters are
isotropic Gaussians with σ = 0.03, scaled by a factor of 20 and truncated to a disc of
radius z = 4σ. I refer to this tractable version of the Thomas process as the truncated
Thomas process. Both of these realisations use the intensity in Figure 3.7a as the mother
process.
These examples have used identical daughter processes, but this is not necessary. A
marking process, as in Section 3.5.1 could be used to generate random daughter pa-
rameters. The approach I have presented could also be turned on its head and the
sigmoidal Gaussian Cox process could be used to generate the daughter events rather
than the mother events. This is a similar idea to the Archipelago cluster model I
present in Chapter 8.
The Hawkes Process
In the Neyman–Scott process, the mother points locate daugh-
ter processes, the daughter processes generate observations, and the process halts.
The Hawkes process (Hawkes, 1971a,b; Hawkes; Hawkes and Oakes, 1974) extends
this so that every daughter point also recursively spawns its own daughter Poisson
process. Unlike the Neyman–Scott process, in which only the daughter points are ob-
served, all points in the Hawkes process are observed. As long as the intensity func-
tion of each daughter Poisson process meets the requirement that
R
X dx λdtr(x) < 1,
then on a ﬁnite domain the Hawkes process will generate a ﬁnite number of points
with probability one. The Hawkes process is referred to as a self-exciting or conta-
gious process, and it has been applied to situations in which the presence of an event
causes additional events to be more likely. Example application areas are seismol-
ogy (Hawkes and Adamopoulos, 1973), neural spiking (Johnson, 1996), and ﬁnancial
markets (Giesecke and Kim, 2007). Figure 3.8 provides a graphical illustration of the
procedure for generating data from a Hawkes process.
In the Neyman–Scott process, it is possible to avoid edge effects in simulation by us-
ing compact daughter kernels and augmenting the simulation domain for the mother
process. In the Hawkes process, edge effects cannot be avoided without additional
assumptions, as even compact kernels can lead to events arbitrarily far away from the
original mother points. In a temporal setting this can be avoided by declaring a pri-

Point Process Extensions to the SGCP
35
(a) Mother process realisation
(b) Level 1 daughters
(c) Level 2 daughters
(d) Level 3 daughters
(e) Level 4 daughters
(f) Level 5 daughters
(g) Final observations
Figure 3.8: Sampling from a Hawkes process on the unit interval. In each ﬁgure, the
new points are shown in red. (a) The root mother Poisson process is homogeneous with
intensity 5 and there are nine events. (b) At each of the events in each realisation, a
new Poisson process is instantiated, in this case with λ(t) = 18e−20t. New points are
drawn from these daughter processes. (c)-(f) Points and daughter processes are created
recursively. (g) The Hawkes process terminates and all observations are kept.
ori that no mother events occur before t = 0 and that excitation is always causal, i.e.
daughters can only assign nonzero intensity to times in the future. Exact simulation
of a spatial Hawkes process appears to require either periodic boundary conditions
or the model assumption that no mother points can occur outside V. With compact
kernels, daughters could also be limited to ﬁnite-depth recursion.
There are two places in the Hawkes process where the sigmoidal Gaussian Cox process
could be introduced. The ﬁrst is in the root mother process, where inhomogeneity
from the SGCP could make a cascade of events more likely in some areas than in
others. A realisation of this case is shown in Figure 3.9, and pseudocode is provided in
Algorithm A.4 (page 119) in Appendix A. Another way to use the sigmoidal Gaussian
Cox process in the Hawkes process is in the daughter processes. A single conditioning
set could be used for the Gaussian process in the SGCP, resulting in Hawkes data
with a single, shared random daughter intensity. If the dominating intensity ¯λ(x) was
chosen so that
R
X dx ¯λ(x) ≤1, then the cascade would terminate with probability one
for all intensities supported by the prior. Such a construction could be useful in a
temporal setting if the self-excitement had an unknown time constant. For example,
trades in a market might induce other trades, but there may be a propagation delay
between a trade being placed and it being observed by other market participants.

Point Process Extensions to the SGCP
36
(a) Mother SGCP intensity
(b) Root mother realisation
(c) Final Hawkes observations
Figure 3.9: A realisation from a Hawkes process on the unit square with an SGCP for the
mother process. (a) The SGCP intensity function realised for the mother process. (b) The
mother realisations, restricted only to the unit square. (c) All Hawkes observations.
The realisation had a depth of fourteen. The daughter processes were Mat´ern discs of
radius z = 0.05, each with an integrated intensity of 0.99.
Repulsive Point Processes
While clustering processes such as the Neyman–Scott and Hawkes address the no-
tion that points in some models should tend to be near each other, repulsive point
processes model the situation in which points should not congregate too closely. For
example, many biological phenomena compete for local resources and are spatially
overdispersed as a result. Glass and Tobler (1971) used a repulsive model to study the
distribution of cities in Spain. In a temporal setting, neural spikes tend to be overdis-
persed due to the presence of refractory periods. Note that point process data can be
both underdispersed and overdispersed: neural spikes might tend to come in clusters,
but the individual spikes within the clusters may repel each other.
Repulsive point processes are generally categorised into two major types: soft-core
models and hard-core models. In the hard-core case, there is a radius of interaction and
points cannot be closer to each other than their radii allow. This can be thought of
as a random placement of spheres, where the objects have an extent. In the soft-core
model, objects simply resist being placed close to one other.
Among hard-core point process models, the most common is the simple sequential inhi-
bition process (SSI) (Ripley, 1981; Stoyan and Stoyan, 1994; Venables and Ripley, 1998;
Diggle, 2003). In this process, a hard-core radius z is chosen and points are added
sequentially to the domain V. At each step, a proposal is made to add a point at
a random location uniformly within V. If the proposal is within a distance z of an
already-accepted point, then the new proposal is rejected. Otherwise, the point is ac-
cepted and a new proposal is made. This process continues until the desired number
of points have been accepted or until no further points can be added. Penttinen and
Stoyan (1989) extended the model to arbitrary overlapping sets. I will not address the
SSI model in this thesis, as it is not rooted in a Poisson process and is very inﬂexible in

Point Process Extensions to the SGCP
37
that it conditions a priori on the number of points in V.
More interesting are the Poisson-based hard-core repulsive models of Mat´ern (1960).
Mat´ern examined methods for two hard-core processes, now known as Mat´ern Type I
and Mat´ern Type II processes. He also brieﬂy described a third process, elaborated
upon by Huber and Wolpert (2009), and now referred to as the Mat´ern Type III process.
Each of these processes begins with a domain V and the generation of a set of Poisson
events ˜S = {˜xj}J
j=1. The events ˜S are referred to as the primary points, and these are
thinned to arrive at a set of secondary points, which are the observations S = {xk}K
k=1.
There are three different rules for the primary-to-secondary thinning.
The Mat´ern Type I Process
The Type I process is the simplest of the three and results
in the lowest density of points. Events are thinned according to the following rule: if
two points ˜xj and ˜xj′ are closer than z to each other, then they both are excluded from
the secondary set. This process has the pathological behaviour that only intermediate
primary intensities are likely to result in many secondary realisations. If the primary
intensity is low, then few primary events will occur, but if the intensity is high, then
events are likely to overlap with other events and be thinned.
The Mat´ern Type II Process
The Type II process is the most widely-used of the
Mat´ern repulsive processes, and it introduces auxiliary “timestamps” for each of the
primary points via marking. These timestamps are drawn uniformly and indepen-
dently from (0, 1), so that the process generates the set {˜xj, uj}J
j=1, where uj ∼U(0, 1).
The purpose of the timestamps is to induce an ordering on the primary points. The
thinning rule is now that for a point to be added to the secondary set, there must be no
earlier point which is closer than z. That is, ˜xj is thinned only if there exists a point ˜xj′
for which ||˜xj′ −˜xj|| < z and uj′ < uj. If the point is not thinned, then it is placed
in the secondary set. The Type II procedure yields a higher density than the Type I
process and does not share the aforementioned pathology.
The Type II process has been generalised in several ways. Penttinen and Stoyan (1989)
used the same timestamp-based thinning rule, but deﬁned interaction as intersection
of a random line segment from a marking process, rather than intersection of circles
with radius z/2. Stoyan and Stoyan (1985) added a marking procedure so that each
primary point also had a random radius zj, with the objective of a soft-core effect. The
random radii also generate the ordering of the points so that a point ˜xj is thinned only
if there exists another point ˜xj′ for which the random radius zj′ > zj and the points
are closer than the larger radius zj′.
The Mat´ern Type III Process
The Type III process is exactly like the Type II process,
except that a point is thinned only if it is close to an earlier point in the secondary set.

Point Process Extensions to the SGCP
38
(a) Primary Mat´ern points
(b) Mat´ern Type I secondary points
(c) Mat´ern Type II secondary points
(d) Mat´ern Type III secondary points
Figure 3.10: Thinning in each of the Mat´ern process types. (a) The primary points are
shown as black dots. The blue lines show the timestamps, in “clock-face ordering” so
that 12:00 is earliest and 11:59 is the latest. The circles are also numbered according
to the timestamps. The circles have radii of half the interaction distance. (b) Type I
thinning: all circles which overlap any other circle are removed. (c) Type II thinning:
when circles overlap, the later one is removed. (d) Type III thinning: a circle is removed
only if it overlaps with an earlier secondary point.
This results in higher densities than the Type I or Type II variants. Huber and Wolpert
(2009) develop a CFTP approach to this model, studying the Spanish towns data of
Glass and Tobler (1971) and the pine sapling data of Ripley (1981). Inspired by Huber
and Wolpert (2009, Figure 1), Figure 3.10 shows how a single set of points would be
thinned by each of the processes.
Generalised Mat´ern Processes
It is often desirable to have more ﬂexibility than the
hard-core process allows. For example, we might wish to have non-isotropic interac-
tions, or to have points only repel each other stochastically. A wide variety of such
soft-core models have been proposed via potential functions (Strauss, 1975; Kelly and

Point Process Extensions to the SGCP
39
Ripley, 1976; Ogato and Tanemura, 1989; Stoyan and Stoyan, 1998), but there are not
many that are deﬁned in terms of the generative process. To ﬁll this gap, I propose
a general framework for soft- and hard-core repulsive Mat´ern processes that I call
generalised Mat´ern processes. These processes are Mat´ern Type II or Type III processes,
but rather than deterministically removing points, I propose the use of a repulsion
kernel, ρ(x ↚x′) : X × X →[0, 1]. Whereas previously an event would be thinned if it
was within z of an earlier primary point (in the Type II process) or an earlier secondary
point (in the Type III process), I now remove it with probability
p(remove ˜xj) = 1 −
Y
j′ s.t. uj′<uj
(1 −ρ(˜xj ↚˜xj′)),
(3.11)
where the set of earlier points is chosen appropriately. This repulsion kernel gives ear-
lier points a probability of vetoing a later point, depending on their relative locations.
The original hard-core processes can be recovered via
ρhc(x ↚x′; z) =



1
if ||x −x′|| < z
0
otherwise
.
(3.12)
If the kernel ρ(x ↚x′) has unbounded support,
i.e. there exists no z for
which ρ(x ↚x′) = 0 when ||x −x′|| > z, then any point an arbitrary distance
away can potentially veto any later point. This long-distance interaction causes edge
effects that make perfect simulation from the prior more difﬁcult, as I described with
the Neyman–Scott and Hawkes processes. As such, I will only discuss kernels with
compact support on the z-ball, i.e. ρ(x ↚x′) = 0, ∀x, x′ such that ||x −x′|| > z. I will
use the notation Bz(x) to indicate the ball of radius z centred at x.
Two such kernels that are potentially useful are the compact squared-exponential ker-
nel:
ρse(x ↚x′; z, ℓ) = exp
(
−1
2
D
X
d=1
(xd −x′
d)2
ℓ2
d
)
IBz(x)(x′),
(3.13)
and the Laplacian kernel:
ρlap(x ↚x′; z, ℓ) = exp
(
−
D
X
d=1
||xd −x′
d||
ℓd
)
IBz(x)(x′).
(3.14)
It is useful to examine the effect of this soft-core behaviour under very simple circum-
stances. Figure 3.11 shows a Poisson time series that has been thinned via several
different Mat´ern-like methods, along with histograms of the inter-event intervals. The
timestamps used were the natural ones in the temporal setting, resulting in only causal
inhibition. The hard-core processes prevent any events within intervals smaller than
the hard-core radius. The soft-core processes thin out many of the smaller intervals,

Point Process Extensions to the SGCP
40
(a) Original Poisson events
(b) Original Poisson interval histogram
(c) Mat´ern Type II events
(d) Mat´ern Type II interval histogram
(e) Mat´ern Type III events
(f) Mat´ern Type III interval histogram
(g) SE kernel soft-core events
(h) SE kernel soft-core interval histogram
(i) Laplacian kernel soft-core events
(j) Laplacian kernel soft-core interval histogram
Figure 3.11: Differences in thinning for four Mat´ern variants. The data were gener-
ated from a Poisson process with a homogeneous rate of 50 on an interval [0, 200].
The left-hand ﬁgures show events from the subinterval [0, 5]. The right-hand ﬁgures
show histograms of the intervals between events. The timestamp ordering used was
the same as the arrival times. The red lines in each of the histograms shows the hard-
core radius or soft-core length scale. (a,b) The original Poisson distribution. It has
exponentially-distributed intervals. (c,d) The hard-core Mat´ern Type II process with ra-
dius z = 0.02. (e,f) The hard-core Mat´ern Type III process with radius z = 0.02. (g,h) A
soft-core Mat´ern Type III process with a squared-exponential repulsion kernel of length
scale ℓ= 0.02. (i,j) A soft-core Mat´ern Type III process with Laplacian kernel of length
scale ℓ= 0.02.
but not all. Figure 3.11h and Figure 3.11j hint that the soft-core model may be useful
for modeling the inter-spike intervals (ISI) of refractory neurons. The gamma renewal
process (Yannaros, 1988) is a popular model for neural spike interval processes (e.g.
Stein (1965); Teich et al. (1978); Leng et al. (2001)) and the soft-core repulsive Mat´ern
process has qualitatively similar properties.
Simulation of Mat´ern Repulsive Processes
The sigmoidal Gaussian Cox process
can be inserted into the Mat´ern repulsive processes in place of the homogeneous Pois-

Point Process Extensions to the SGCP
41
(a) Primary SGCP intensity
(b) Primary realisation
(c) Secondary realisation
Figure 3.12: A realisation from a Mat´ern Type III process on the unit square with an
SGCP for the primary process. (a) The SGCP intensity function realised for the primary
process. (b) The primary realisations shown as black dots, with red circles showing the
hard cores and the blue lines showing the ordering as clock faces. (c) The secondary
realisations after Type III thinning is performed.
son process that generates the primary points. This allows the generation of inho-
mogeneous realisations with a Gaussian process prior on the intensity.
As in the
Neyman–Scott and Hawkes processes, however, it is necessary to address edge ef-
fects. The Type I process simply requires expanding the simulation region with the
Minkowski sum, as in the Neyman–Scott process. The Type II and III processes (and
the soft-core variants I propose) have similar difﬁculties to the Hawkes process. Sim-
ply augmenting the simulation region is not sufﬁcient, as a sequence of overlapping
regions could go arbitrarily far before a decisive veto occurs. Huber and Wolpert
(2009) resolve this with periodic boundary conditions, but it could also be stated a
priori that the primary process has zero intensity outside the region of interest. Fig-
ure 3.12 shows the result of applying the SGCP to the hard-core Mat´ern Type III pro-
cess, using the zero-intensity boundary conditions. Pseudocode is provided for the
generalised Mat´ern Type II process in Algorithm A.5 (page 119) and for the Type III
variant in Algorithm A.6 (page 120), both in Appendix A. Figure 3.13 demonstrates
the sigmoidal Gaussian Cox process applied to the soft-core Type III variant with a
non-isotropic kernel
ρ(x ↚x′) = exp

−1
2(x −x′)TW (x −x′)

IBr(x)(x′),
(3.15)
parameterised by positive deﬁnite W , which I set to
W =
"
1000
−900
−900
1000
#
.
(3.16)
The matrix W places a Mahalanobis distance metric (Mahalanobis, 1936) on the space,
from which repulsion is determined. This kernel is inspired by Vivarelli and Williams
(1999), who used a similar construction for dimensionality reduction in Gaussian pro-
cess regression.

Summary
42
(a) Primary intensity function
(b) Repulsion kernel
(c) Secondary points
Figure 3.13: A realisation from the soft-core Mat´ern Type III process, using the kernel
of Equation 3.15 with W as in Equation 3.16. (a) The SGCP intensity function on the
unit square. (b) The non-isotropic repulsion kernel, centred on the unit square. (c) A
realisation from the process.
3.6
Summary
This chapter introduced a Cox process that arises from transforming a Gaussian pro-
cess into a distribution on Poisson intensity functions. I named this process the sig-
moidal Gaussian Cox process. The utility of the SGCP lies in the fact that it is possi-
ble to simulate data exactly from a Poisson process with a random intensity function
drawn from the Gaussian process. I also reviewed a variety of extensions to the Pois-
son process for incorporation of marking, clustering and repulsion, and showed how
the sigmoidal Gaussian Cox process can be extended to introduce inhomogeneity into
these processes.
In Chapter 4, I develop an inference method for the sigmoidal Gaussian Cox process
prior. Chapter 5 proposes an alternative, and superior, method for inference in the
SGCP. This inference method can also be applied to some of the extensions described
in Section 3.5. In Chapter 6, I will use these models to examine real-world point pro-
cess data.

Chapter 4
Inference Via Exchange Sampling
In this chapter, I give an overview of the problem of inference with doubly-intractable
posterior distributions. I present the method of exchange sampling (ES), which allows
sampling from doubly-intractable posteriors under certain circumstances.
I show
how the Gaussian process density sampler of Chapter 2 and the sigmoidal Gaussian
Cox process of Chapter 3 both meet exchange sampling’s requirements and enable
tractable inference via Markov chain Monte Carlo.
In Section 4.1, I review Markov chain Monte Carlo, before introducing the specialised
MCMC method of exchange sampling in Section 4.2. In Section 4.3, I apply exchange
sampling to inference in the Gaussian process density sampler, ﬁrst using a simple
construction for ease of understanding, and then with a more complex but efﬁcient
method. Following this, I apply exchange sampling to inference in the sigmoidal
Gaussian Cox process in Section 4.4. In Section 4.5, I describe how these Markov chain
Monte Carlo methods could be extended to sample from the predictive distributions.
Before discussing doubly-intractable inference, I will ﬁrst review Markov chain Monte
Carlo. In Section 2.2.1, I reviewed the rejection sampling method for generating data
from a density function p(x). This method is useful for implementing a generative
process associated with the prior on density functions, as samples generated via rejec-
tion sampling are exact and independent. Rejection sampling, however, has undesir-
able properties in complex problems: it does not typically scale well to high dimen-
sions and it requires speciﬁcation of an upper-bounding density function. Often in
Bayesian inference it is not critical that posterior samples be independent, however.
For example, if we are using the samples to estimate an expectation, then correlation
between the samples can be tolerated. In such cases, a broad class of efﬁcient sampling
algorithms are applicable, based on Markov chains.

Markov Chain Monte Carlo
44
4.1
Markov Chain Monte Carlo
In this section, I examine the problem of sampling efﬁciently from a distribution pγ(γ).
I intend for γ to be interpreted as the parameters of a hierarchical model, and pγ(γ) to
be treated as a posterior distribution. This is in contrast to the previous discussion of
rejection sampling with a density p(x). I make this change of notation to emphasise
that rejection sampling is something done on the data space, while I use Markov chain
Monte Carlo for inference in parameter space. Later in this thesis, this difference will
become important as I will treat rejection samplers as objects to be modeled.
In Markov chain Monte Carlo, rather than specifying a computational procedure
on the distribution directly, one deﬁnes a transition operator for exploring the state
space Γ by moving stochastically from one point to another in time. By carefully
choosing the transition operator T(γ(t+1) ←γ(t)) and ensuring that it meets certain
requirements, it is possible to construct a Markov chain that has pγ(γ) as its equilib-
rium (also called stationary or invariant) distribution. MCMC methods are used by
simulating a sequence of states from a Markov chain γ(0), γ(1), . . . , γ(T), and hoping
that, after running the chain long enough, the state has evolved to be very close to a
draw from the equilibrium distribution. That is, one hopes that the simulated Markov
chain has “forgotten” its starting state γ(0) and that the state γ(T) is representative of
the distribution pγ(γ). For more comprehensive introductions to Markov chain Monte
Carlo methods, see, e.g. Gelman et al. (2004, Chapter 11), MacKay (2003, Chapter 29),
or Andrieu et al. (2003).
The ﬁrst requirement of the transition operator is that it be Markovian: the distribution
over the next state must depend only on the current state. To emphasise this, I will
generally not denote the time indices explicitly and will denote the current state γ(t)
by γ and the state γ(t+1) as ˆγ. The transition operator is then written T(ˆγ ←γ).
Secondly, for Markov chain Monte Carlo to be useful, the transition operator must
have pγ(γ) as its equilibrium distribution. This is the requirement that
pγ(ˆγ) =
Z
Γ
dγ T(ˆγ ←γ) pγ(γ).
(4.1)
This equation can be interpreted as the requirement that when marginalising over the
“origin” of the operator, assuming the origin is from pγ(·), the resulting distribution
on “destinations” must be pγ(·). For simulation, it is useful to note that the generalised
Kullback–Leibler (KL) divergence between pγ(ˆγ) and pγ(γ) in Equation 4.1 cannot in-
crease as the result of such a Markov transition (Cover and Thomas, 2006, Section 2.9).
Therefore, regardless of the initial distribution of γ(0), the distribution over γ(t) for
t > 0 cannot move “farther away” from the equilibrium distribution.
One way of achieving the invariance property of Equation 4.1 is to satisfy the stronger

Doubly-Intractable Distributions and Exchange Sampling
45
condition of detailed balance:
T(γ ←ˆγ) pγ(ˆγ) = T(ˆγ ←γ) pγ(γ)
(4.2)
for all γ and ˆγ in Γ. The MCMC methods that I discuss will generally satisfy detailed
balance, as in later chapters it will be a convenient identity to exploit for some Monte
Carlo-based estimations. For a discussion of Markov chain Monte Carlo methods that
do not satisfy detailed balance, see Neal (2004).
Finally, the Markov chain resulting from T(ˆγ ←γ) must be ergodic. Ergodicity re-
quires that the chain be irreducible: it is possible to eventually transition to any state
where pγ(γ) is nonzero from any other supported state, given enough time. Ergodic
chains must also be aperiodic, which is the requirement that the visitation to a given
state is not limited to certain times.
Different transition operators result in different Markov chain Monte Carlo algo-
rithms. There are many variants: slice sampling (Neal, 2003b), Gibbs sampling (Ge-
man and Geman, 1984), and Hamiltonian Monte Carlo (Duane et al., 1987), to name
a few. I will focus on the Metropolis–Hastings (MH) method (Metropolis et al., 1953;
Hastings, 1970), which includes several other MCMC methods as special cases.
The Metropolis–Hastings algorithm has the transition operator
T(ˆγ ←γ) = min

1, q(γ ←ˆγ) pγ(ˆγ)
q(ˆγ ←γ) pγ(γ)

q(ˆγ ←γ),
(4.3)
where q(ˆγ ←γ) is a proposal distribution. Equation 4.3 corresponds to a transition
with two steps. First, propose new parameters ˆγ from q(ˆγ ←γ). Next, make ˆγ the
new state of the Markov chain using a Bernoulli draw with probability taken from
the min(·) term. Otherwise, keep the current state γ. This transition operator satisﬁes
detailed balance (Hastings, 1970). I will frequently refer to the second argument of
the min(·) in Equation 4.3 as the acceptance ratio. The Metropolis–Hastings transition
operator results in the algorithm listed in Algorithm 4.1.
4.2
Doubly-Intractable Distributions and Exchange Sampling
In Section 1.3, I introduced the concept of the doubly-intractable posterior distribution.
In these distributions, the likelihood function p(x | γ) (where x is an observed datum)
is only known to within a constant, i.e. p(x | γ) = Z−1h(γ ; x) for unknown Z. When
performing Bayesian inference, the posterior distribution has the form
p(γ | x) =
p0(γ) Z(γ)−1h(γ ; x)
R
Γ dγ′ p0(γ′) Z(γ′)−1h(γ′ ; x)
(4.4)

Doubly-Intractable Distributions and Exchange Sampling
46
Algorithm 4.1
Generate R samples from pγ(γ) via Metropolis–Hastings
Inputs:
• Number of samples to draw R
• Posterior distribution pγ(γ)
• Proposal distribution q(ˆγ ←γ)
• Initial state γ0
Outputs:
• R correlated samples from pγ(γ), {γ(r)}R
r=1
1: γ ←γ0
▷Initialise the Markov chain.
2: for r ←1 . . . R do
▷Simulate R Markov transitions.
3:
ˆγ ∼q(ˆγ ←γ)
▷Make a proposal.
4:
amh ←q(γ ←ˆγ) pγ(ˆγ)
q(ˆγ ←γ) pγ(γ)
▷Calculate acceptance ratio.
5:
u ∼U(0, 1)
▷Draw uniformly on (0, 1).
6:
if u < amh then
▷Acceptance rule.
7:
γ ←ˆγ
▷Make the proposal the current state.
8:
end if
9:
γ(r) ←γ
▷Store the current state.
10: end for
11: return {γ(r)}R
r=1
where I write Z(γ) to make it clear that the likelihood normalisation constant (parti-
tion function) depends on the parameters γ. I use p0(γ) to denote the prior distribution
on γ. If the parameters are actually a function, as is the case in most of the models I
discuss in this thesis, then I use Z[γ] to indicate that it is a “partition functional.” Some
examples of models with doubly-intractable posterior distributions follow.
The Potts model
The Potts model is one of the most common types of doubly-
intractable models, and it motivated some of the original work in doubly-intractable
inference. The Potts model is a pairwise interaction model (or spin glass) with S pos-
sible spin states. When neighbouring nodes have different spins, the energy increases
and the probability of the overall state decreases. When there are only two types of
spins, it is often called the Ising model (Ising, 1925)1, the Boltzmann machine (Hopﬁeld,
1982; Ackley et al., 1985; Smolensky, 1986), the autologistic model (Møller et al., 2004)
or the binary Markov random ﬁeld (see, e.g. Murray (2007, Chapter 1)). For D nodes, the
Potts model likelihood terms are
h(W ; x ∈{1, 2, . . . , S}D) = exp
(
−1
2
D
X
d=1
D
X
d′=1
Wd,d′(δ(xd, xd′) −1)
)
(4.5)
Z(W ) =
X
x′
exp
(
−1
2
D
X
d=1
D
X
d′=1
Wd,d′(δ(x′
d, x′
d′) −1)
)
.
(4.6)
The function δ(·, ·) is the Kronecker delta function, which is equal to one if its argu-
ments are equal, and zero otherwise. Computing the normalisation constant of this
model requires a sum over a state space that grows exponentially with the number of
nodes. Many more general Markov random ﬁelds also have doubly-intractable poste-
1See Niss (2005) for a discussion of the history of the Ising model.

Doubly-Intractable Distributions and Exchange Sampling
47
rior distributions.
The logistic Gaussian process
See Section 1.3.
h(g ; x) = exp{g(x)}
(4.7)
Z[g] =
Z
X
dx′ exp{g(x′)}
(4.8)
The Gaussian process density sampler
See Chapter 2.
h(g ; x) = Φ(g(x)) π(x)
(4.9)
Z[g] =
Z
X
dx′ Φ(g(x′)) π(x′)
(4.10)
The log Gaussian Cox process
See Section 1.4.
h(g ; x) = exp{g(x)}
(4.11)
Z[g] = exp
Z
V
dx′ exp{g(x′)}

(4.12)
The sigmoidal Gaussian Cox process
See Chapter 3.
h(g ; x) = Φ(g(x)) ¯λ(x)
(4.13)
Z[g] = exp
Z
V
dx′ Φ(g(x′)) ¯λ(x′)

(4.14)
While Metropolis–Hastings is often a workhorse for Bayesian inference with complex
posterior distributions, it cannot be used directly for models with doubly-intractable
posteriors. If Equation 4.4 is plugged into Equation 4.3 for pγ(γ), the acceptance ratio
is
amh = q(γ ←ˆγ) p0(ˆγ) h(ˆγ ; x)
q(ˆγ ←γ) p0(γ) h(γ ; x) × Z(γ)
Z(ˆγ).
(4.15)
This acceptance ratio cannot be calculated without knowing the ratio of intractable
constants that appears on the right. These constants do not cancel because they de-
pend on the parameters. Further, the ratio in Equation 4.15 cannot be approximated
in an arbitrary way (using, for example, numerical integration to estimate the con-
stants) and still yield a Markov chain whose equilibrium distribution is the posterior
of interest.
In 2004, however, Møller et al. (2004)2 made the landmark contribution of the ﬁrst
method for constructing a Metropolis–Hastings Markov chain in which it is not nec-
2A shorter journal article was formally published in Møller et al. (2006).

Doubly-Intractable Distributions and Exchange Sampling
48
essary to evaluate this intractable ratio. There is a large caveat, however: it must be
possible to simulate exact data from the model for a given setting of the parameters.
These data have typically been generated via coupling from the past (CFTP) (Propp
and Wilson, 1996). In Møller et al. (2004), CFTP is used on the Strauss process (Strauss,
1975; Kelly and Ripley, 1976) to generate exact samples, and in Møller et al. (2006),
coupling from the past is applied to the Ising model.
Following Murray (2007), I will refer to the method of Møller et al. (2004)
as
the
single
auxiliary
variable
method
(SAVM).
The
distribution
of
interest
is p(γ | x) ∝p(γ, x) = p0(γ) Z(γ)−1 h(γ ; x).
The SAVM augments the joint dis-
tribution p(γ, x) with an additional variable w that is on the same space as x.
I
will refer to this new variable w as fantasy data. This augmented joint arises from
multiplying p(γ, x) by an arbitrary conditional distribution f(w | γ, x), so that the
overall distribution is p(x, w, γ) = f(w | γ, x) p0(γ) Z(γ)−1 h(γ; x).
Marginalising
over w still gives the distribution p(γ, x), so it is possible to simulate both γ and w
and reserve the samples of γ for posterior estimation.
To sample a doubly-intractable posterior via the SAVM, one performs Metropolis–
Hastings on the joint distribution over γ and w, for ﬁxed x. Proposals are made in
two stages. First, a new proposal for γ is drawn from the distribution q(ˆγ ←γ).
Second, a new w is proposed from the same distribution as the likelihood model, but
using the newly-proposed parameter ˆγ, i.e. q( ˆ
w ←w) = p( ˆ
w | ˆγ) = Z(ˆγ)−1 h(ˆγ ; ˆ
w).
This proposal ˆ
w is generated as an exact sample from the model with parameter ˆγ.
The overall proposal distribution is
q(ˆγ, ˆ
w ←γ, w) = q(ˆγ ←γ) Z(ˆγ)−1 h(ˆγ ; ˆ
w).
(4.16)
The Metropolis–Hastings acceptance ratio of this proposal is
asavm = q(γ ←ˆγ) f( ˆ
w | ˆγ, x) p0(ˆγ) 
Z(ˆγ)−1 h(ˆγ ; x) 
Z(γ)−1 h(γ ; w)
q(ˆγ ←γ) f(w | γ, x) p0(γ) 
Z(γ)−1 h(γ ; x) 
Z(ˆγ)−1 h(ˆγ ; ˆ
w)
= q(γ ←ˆγ) f( ˆ
w | ˆγ, x) p0(ˆγ) h(ˆγ ; x) h(γ ; w)
q(ˆγ ←γ) f(w | γ, x) p0(γ) h(γ ; x) h(ˆγ ; ˆ
w),
(4.17)
in which the normalisation constants cancel out.
Inspired by the SAVM, Murray et al. (2006) developed a procedure called exchange
sampling (ES), that removes the need for the conditional distribution f(w | γ, x).
Again, the distribution of interest is p(γ | x) ∝p(γ, x) = p0(γ) Z(γ)−1 h(γ ; x).
To
make an exchange sampling move, ﬁrst propose new parameters ˆγ from a pro-
posal distribution q(ˆγ ←γ).
Next, draw new fantasy data from the likelihood
model using the new parameter ˆγ. These data must be exactly from the distribu-
tion p(w | ˆγ) = Z(ˆγ)−1 h(ˆγ ; w). Finally, propose the eponymous exchange of γ and ˆγ.

Doubly-Intractable Distributions and Exchange Sampling
49
Algorithm 4.2
Generate R samples from p(γ | {xn}N
n=1) via exchange sampling
Inputs:
• Number of samples to draw R
• Observed data {xn}N
n=1
• Likelihood model p(x | γ) = Z(γ)−1h(γ ; x)
• Prior p0(γ)
• Proposal distribution q(ˆγ ←γ)
• Initial state γ0
Outputs:
• R correlated samples from p(γ | {xn}N
n=1), {γ(r)}R
r=1
1: γ ←γ0
▷Initialise the Markov chain.
2: for r ←1 . . . R do
▷Simulate R exchange sampling steps.
3:
ˆγ ∼q(ˆγ ←γ)
▷Make a proposal.
4:
for n ←1 to N do
▷Generate N fantasies.
5:
wn ∼p(x | ˆγ)
▷Generate an exact fantasy from ˆγ.
6:
end for
7:
aes ←q(γ ←ˆγ) p0(ˆγ)
q(ˆγ ←γ) p0(γ)
N
Y
n=1
h(ˆγ ; xn) h(γ ; wn)
h(γ ; xn) h(ˆγ ; wn)
▷Calculate acceptance ratio.
8:
u ∼U(0, 1)
▷Draw a uniform random variable on (0, 1).
9:
if u < aes then
▷Acceptance rule.
10:
γ ←ˆγ
▷Make the proposal the current state.
11:
end if
12:
γ(r) ←γ
▷Store the current state.
13: end for
14: return {γ(r)}R
r=1
The joint distribution over the current state and ﬁrst two proposal steps is
p(γ, x, ˆγ, w) = p0(γ) p(x | γ) q(ˆγ ←γ) p(w | ˆγ).
(4.18)
The Metropolis–Hastings acceptance ratio of the exchange is the ratio of Equation 4.18
with γ and ˆγ swapped, to Equation 4.18 as written, yielding:
aes = p0(ˆγ) 
Z(ˆγ)−1 h(ˆγ ; x) q(γ ←ˆγ) 
Z(γ)−1 h(γ ; w)
p0(γ) 
Z(γ)−1 h(γ ; x) q(ˆγ ←γ) 
Z(ˆγ)−1 h(ˆγ ; w)
= p0(ˆγ) h(ˆγ ; x) q(γ ←ˆγ) h(γ ; w)
p0(γ) h(γ ; x) q(ˆγ ←γ) h(ˆγ ; w).
(4.19)
Even with this simpler construction, the normalisation constants have canceled out
of the acceptance ratio. To generalise this procedure to multiple i.i.d. data, generate
as many exact fantasy data as there are true data. The exchange sampling algorithm
for N independent data is provided in pseudocode in Algorithm 4.2.
Exchange sampling and the single auxiliary variable method are the motivation for
modeling with the Gaussian process density sampler and the sigmoidal Gaussian Cox
process, rather than the logistic Gaussian process and the log Gaussian Cox process.
While the models I have presented are slightly more complicated than the LGP and
LGCP, I have coupled my proposed priors with generative procedures that enable
tractable inference via the methods presented in this section.

Exchange Sampling for GPDS Inference
50
4.3
Exchange Sampling for GPDS Inference
Inference is the task of “inverting” a model to explain the observed data. The Gaussian
process density sampler is a model for probability density functions, parameterised by
a latent function g(x), which has a Gaussian process prior. Given N data D = {xn}N
n=1,
that are modeled as i.i.d. from an unknown probability density, the objective is to sam-
ple from the posterior distribution on g(x), which, as before, I will treat as a vector g.
As the GPDS enables generation of exact data, it is possible to simulate a Markov chain
on the posterior distribution p(g | D) using the exchange sampling method described
in Section 4.2.
4.3.1
Independence-Chain Exchange Sampling
For clarity,
I will begin by describing exchange sampling in the GPDS us-
ing the simplest possible proposals for g:
independent draws from the prior,
i.e. q(ˆg ←g) = p(ˆg | θ) = GP(ˆg | θ).
This corresponds to an independence chain
Metropolis–Hastings variant of exchange sampling.
This method is inefﬁcient, for
reasons that will be explained shortly, but it is a useful starting point to see how
exchange sampling can be applied to the Gaussian process density sampler. It is also
useful to think of g as something that can be stored wholly in memory, even though
it is an inﬁnite-dimensional object. From an initial state g, an exchange sampling
step would ﬁrst require drawing a new function ˆg from the proposal (the prior in
this case). Following this, it is necessary to generate N fantasy data W = {wn}N
n=1
from the density implied by ˆg. Section 2.2 provided a way to do both of these steps at
once — sampling a function from the prior while simultaneously drawing data from
the corresponding density. This is precisely running Algorithm 2.2 until exactly N
data are accepted.
After fantasisation, the joint distribution over g, {xn}N
n=1, ˆg,
and {wn}N
n=1, given the hyperparameters, is
p(g, D, ˆg, W | θ, ψπ) = GP(g | θ) Zπ[g]−N
" N
Y
n=1
Φ(g(xn)) π(xn | ψπ)
#
× GP(ˆg | θ) Zπ[ˆg]−N
N
Y
n=1
Φ(ˆg(wn)) π(wn | ψπ).
(4.20)

Exchange Sampling for GPDS Inference
51
Algorithm 4.3
Simulate R steps using independence chain ES on the GPDS.
Inputs:
• Number of MCMC iterations R
• Observed data D = {xn}N
n=1
• Gaussian process covariance function C(x, x′; θ)
• Base density π(x | ψπ)
Outputs:
• R conditioning sets of function inputs and outputs {X(r), G(r)}R
r=1
1: {g(xn)}N
n=1 ∼GP(g | D, θ)
▷Initialise the function at the data.
2: X(1) ←{xn}N
n=1, G(1) ←{g(xn)}N
n=1
▷Initialise conditioning sets.
3: for r ←1 . . . R do
▷Take R exchange sampling steps.
4:
{ˆg(xn)}N
n=1 ∼GP(g | D, θ)
▷Draw a new function at the data.
5:
ˆX ←{xn}N
n=1, ˆG ←{ˆg(xn)}N
n=1
▷Initialise proposal conditioning sets.
6:
W ←∅
▷Initialise empty fantasy data set.
7:
repeat
▷Run the rejection sampling loop.
8:
˜
w ∼π(x | ψπ)
▷Draw a proposal from the base density.
9:
ˆg( ˜
w) ∼GP(ˆg | ˜
w, ˆX, ˆG, θ)
▷Draw the function value at the proposal.
10:
ufant ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
11:
if ufant < Φ(ˆg( ˜
w)) then
▷Rejection sampling acceptance rule.
12:
W ←W ∪˜
w
▷Keep the fantasy.
13:
end if
14:
ˆX ←ˆX ∪˜
w, ˆG ←ˆG ∪ˆg( ˜
w)
▷Add proposals to the conditioning sets.
15:
until |W| = N
▷Loop until N fantasies are accepted.
16:
{g(wn)}N
n=1 ∼GP(g | W, X(r), G(r))
▷Sample the current function at the fantasies.
17:
agpds−ices ←
N
Y
n=1
Φ(ˆg(xn)) Φ(g(wn))
Φ(g(xn)) Φ(ˆg(wn))
▷Calculate the acceptance ratio.
18:
umh ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
19:
if umh < agpds−ices then
▷Apply the Metropolis–Hastings acceptance rule.
20:
X(r+1) ←ˆX, G(r+1) ←ˆG
▷Keep the new function data.
21:
else
22:
X(r+1) ←X(r) ∪{wn}N
n=1
▷Add the fantasy evaluations to the current state.
23:
G(r+1) ←G(r) ∪{g(wn)}N
n=1
24:
end if
25: end for
26: return {X(r), G(r)}R
r=1
Now the proposal is made to exchange g and ˆg, which has the acceptance ratio
agpds−ices = 
GP(ˆg | θ) 
Zπ[ˆg]−N 
GP(g | θ) 
Zπ[g]−N

GP(g | θ) 
Zπ[g]−N 
GP(ˆg | θ) 
Zπ[ˆg]−N
×
N
Y
n=1
Φ(ˆg(xn)) 

π(xn | ψπ) Φ(g(wn)) 
π(wn | ψπ)
Φ(g(xn)) 

π(xn | ψπ) Φ(ˆg(wn)) 
π(wn | ψπ)
=
N
Y
n=1
Φ(ˆg(xn)) Φ(g(wn))
Φ(g(xn)) Φ(ˆg(wn)).
(4.21)
Not only have the normalisation constants canceled out of this acceptance ratio, but
the remaining terms depend only on evaluating the function at a ﬁnite number of
locations.
Of course, the acceptance ratio of Equation 4.21 is not the entire story. To ensure that
the algorithm has the correct invariant distribution, it is also necessary to perform

Exchange Sampling for GPDS Inference
52
some bookkeeping. Speciﬁcally, it is necessary to keep consistent track of the current
and proposed functions, g and ˆg. It is not required to know them everywhere, but
anything discovered about them (i.e. sampled from the Gaussian process prior) must
be retained for as long as that function is relevant to the current Markov state. Such
information can accrue in two different ways. First, when fantasy data are drawn via
Algorithm 2.2, there may be rejections. When fantasy proposals are rejected, the func-
tion ˆg is still evaluated and the input and output values are added to the conditioning
set. All future evaluations of this function must be conditioned on these values. Sec-
ond, it is necessary to sample the function values {g(wn)}N
n=1, i.e. the current function
evaluated at the fantasy data, to calculate the acceptance ratio in Equation 4.21. If the
exchange sampling move is then rejected, these values must nevertheless be added to
the conditioning set of the function that is the current Markov state. The practical ef-
fect of this bookkeeping is that the actual stored state of the Markov chain — the condi-
tioning set of the current function — grows by N function evaluations when exchange
sampling moves are rejected. Fortunately, when an exchange sampling move is ac-
cepted, the conditioning set of the old function can be discarded, due to the Markov
property of the chain. The conditioning set after an acceptance possesses only 1) the
true data, 2) the fantasy data, and 3) the rejections made along the way to generating
fantasy data.
The key to the tractability and practicality of exchange sampling with the Gaussian
process density sampler is that information about any function g(x) in the Markov
state is queried only when necessary. This idea of Markov chain Monte Carlo infer-
ence via sampling ﬁnite parts of an inﬁnite-dimensional random object is known as
retrospective sampling (Papaspiliopoulos and Roberts, 2008). The concept is to sample
and store only information that is immediately relevant to the inference computation.
Some probabilistic models make it easy to ask new questions about a random object,
conditioning on what is already known. The Gaussian process allows this conditional
sampling for g via Equation 1.5 and Equation 1.6. The effect is that inference can be
performed in the Gaussian process density sampler using ﬁnite computation, even
though the latent function g(x) has an inﬁnite number of dimensions. Retrospective
sampling was introduced by Papaspiliopoulos and Roberts (2008), who examined the
Dirichlet process. Beskos et al. (2006b) and Beskos et al. (2006a) applied retrospective
sampling to inference in diffusion processes. Algorithm 4.3 shows the independence
chain exchange sampling algorithm as pseudocode and Figure 4.1 illustrates the idea
graphically.
4.3.2
Improving the Acceptance Rate with Conservative Proposals
In general, the independence chain exchange sampling algorithm is not expected to
have a good acceptance rate. If there have been many observed data, then typical
samples from the Gaussian process prior are unlikely to result in densities that ex-

Exchange Sampling for GPDS Inference
53
{xn}
(a) Data
g(x)
{g(xn)}
(b) Initial g(x)
ˆg(x)
{ˆg(xn)}
(c) Proposed ˆg(x)
{ˆg(wn)}
{wn}
(d) Fantasies from ˆg(x)
{g(wn)}
(e) Evaluate and compare
(f) Reject proposed ˆg(x)
ˆg(x)
{ˆg(xn)}
(g) New proposed ˆg(x)
{ˆg(wn)}
(h) Fantasies from ˆg(x)
{g(wn)}
(i) Evaluate and compare
(j) Reject proposed ˆg(x)
(k) Propose, fantasise
g(x)
(l) Accept proposed ˆg(x)
Figure 4.1: A cartoon of three exchange sampling transitions. In the ﬁrst two transitions,
the proposals are rejected to demonstrate the expanding Markov state due to retrospec-
tive sampling of g(x). The third proposal is accepted and the previously-accumulated
state is discarded. (a) The observed data, illustrated as
. (b) The initial g(x) evalu-
ated at the data, shown as
. (c) The proposed ˆg(x) evaluated at the data, shown as
. (d) Fantasies are drawn from ˆg(x), illustrated as
. There is one rejected proposal,
shown as
, with the corresponding function value illustrated as
. (e) g(x) is evalu-
ated at the fantasies and the two explanations are compared using Equation 4.21. (f) The
proposal ˆg(x) is rejected. The Markov state expands to include the fantasies. (g) A
new ˆg(x), shown in green, is evaluated at the data. (h) Fantasies are drawn from ˆg(x)
(two rejected fantasy proposals). (i) g(x) is evaluated at the fantasies and the explana-
tions are compared. (j) The proposal was rejected. The Markov state expands to twelve
function evaluations. (k) Skipping the intermediate steps, propose, fantasise, evaluate
and compare, using the function shown in cyan. (l) The proposal is accepted and made
the new g(x). All of the information about the old function is thrown away, but the
new g(x) must keep information in its conditioning set about the fantasies it generated.
plain the data well. Tuning to get efﬁcient mixing is important in most Markov chain
Monte Carlo algorithms, but in exchange sampling for the Gaussian process density
sampler it is even more important: each time there is a rejection, the Markov state ex-
pands. This expanding Markov state causes subsequent calculations to have quadratic
space complexity due to the need to calculate the covariance matrix, and cubic time
complexity, due to the need to decompose or invert the covariance matrix.
One way to increase the acceptance rate of a Metropolis–Hastings sampler is to make
more conservative proposals. If the proposals are only small perturbations of the cur-

Exchange Sampling for GPDS Inference
54
rent state, the posterior probability is unlikely to change dramatically, and many pro-
posals will be accepted. In the case of exchange sampling for the Gaussian process
density sampler, being more conservative means altering the proposal distribution
over functions to assign greater probability to functions that are “similar” to the cur-
rent function.
Introducing Control Points
To make conservative proposals, I narrow the distribution on functions by introducing
a set of B control points in X, denoted C = {xb}B
b=1, xb ∈X. These control points
have associated function values, which I denote G = {g(xb)}B
b=1. I will assume that C
is a superset of the observed data, i.e. D ⊆C. The function values at the control
points are explicitly included in the Markov state and all retrospective function draws
condition on these points. New discoveries about the function continue to accumulate
in the conditioning sets, as before. The difference now is that the conditioning sets are
initialised with the control points and small, perturbative proposals can be made on
the function values at those initial points.
To make this construction explicit, Equation 4.20 is extended to
p(G, g\C, D, ˆG, ˆg\C, W | C, θ, ψπ) =
GP(G | C, θ) GP(g\C | G, θ) Zπ[g]−N
" N
Y
n=1
Φ(g(xn)) π(xn | ψπ)
#
× q( ˆG ←G) GP(ˆg\C | ˆG, θ) Zπ[ˆg]−N
N
Y
n=1
Φ(ˆg(wn)) π(wn | ψπ),
(4.22)
where
ˆG indicates the proposal of the function values at the control points,
i.e. ˆG = {ˆg(xb)}B
b=1, and g\C denotes the function values, excluding those at C.
The proposal density q( ˆG ←G) can be chosen to take smaller steps than the prior
draws of the previous section. With the joint distribution in Equation 4.22, and using
the conditional retrospective exchange sampling as before, the acceptance ratio of
exchanging the pair (G, g\C) for ( ˆG, ˆg\C) is
agpds−cpes = q(G ←ˆG) GP( ˆG | C, θ)
q( ˆG ←G) GP(G | C, θ)
N
Y
n=1
Φ(ˆg(xn)) Φ(g(wn))
Φ(g(xn)) Φ(ˆg(wn)).
(4.23)
Superﬁcially, this might seem similar to the knot-based imputation method of Tokdar
(2007). However, whereas Tokdar (2007) uses knots as a ﬁnite-dimensional approx-
imation, I am using the control points simply to constrain the proposal distribution.
The control points only initialise the retrospective sampling procedure. As I enforce
a Gaussian process prior on the function values of the control points, the inference
procedure still yields the correct posterior distribution on the uncompromised fully-

Exchange Sampling for GPDS Inference
55
nonparametric Gaussian process density sampler model. The number and locations
of the control points are free parameters. I have not signiﬁcantly explored the topic of
optimal placement of control points. Intuitively, however, a set of locations with low
discrepancy under the base density seems appropriate.
Underrelaxed Proposals
Gaussian process priors typically create strong correlations between the function val-
ues, in this case restricting the probability mass of G to a relatively narrow region. A
na¨ıve perturbative proposal, such as independent Gaussian proposals on each com-
ponent, is likely to step out of the high-density region and be rejected. To combat this,
it is desirable to make proposals that are invariant under the prior distribution and so
cannot be vetoed by a highly-structured prior such as the Gaussian process. Invari-
ant proposals of this type were introduced by Adler (1981) under the name overrelax-
ation, for Gibbs sampling of densities with univariate Gaussian marginals. The goal
of Adler (1981) was to make the Gibbs draws more aggressive to enhance mixing and
reduce random walk behaviour. Neal (1998) generalised this idea and also discussed
the underrelaxed variant, which I describe in slightly broader terms here. Addition-
ally, Rasmussen (1996) used a very similar idea to implement persistent momenta in
Hamiltonian Monte Carlo simulations.3
I return to the abstract parameter space γ,
examining a posterior distribu-
tion p(γ | D) ∝p0(γ) p(D | γ), where p0(γ) is the prior and p(D | γ) is the likelihood
function. I deﬁne underrelaxed proposals to be direct transitions from γ to ˆγ that
satisfy detailed balance for the prior:
p0(γ) q(ˆγ ←γ) = p0(ˆγ) q(γ ←ˆγ).
(4.24)
Lemma 4.1. If the proposal q(ˆγ ←γ) is a transition operator that satisﬁes detailed bal-
ance for the prior distribution p0(γ), then using Metropolis–Hastings acceptance ratio
a = p(D | ˆγ)/p(D | γ) yields an operator that satisﬁes detailed balance for the distribu-
tion p0(γ) p(D | γ).
Proof.
T(ˆγ ←γ) p0(γ) p(D | γ) = p0(γ) p(D | γ) q(ˆγ ←γ) min

1, p(D | ˆγ)
p(D | γ)

= p0(γ) q(ˆγ ←γ) min (p(D | γ), p(D | ˆγ))
= p0(ˆγ) q(γ ←ˆγ) min (p(D | γ), p(D | ˆγ))
(Equation 4.24)
= p0(ˆγ) q(γ ←ˆγ) min (p(D | γ), p(D | ˆγ)) p(D | ˆγ)
p(D | ˆγ)
3Hamiltonian Monte Carlo will be discussed in more detail in Chapter 5.

Exchange Sampling for GPDS Inference
56
(a) κ = 0.6
(b) κ = 0.9
(c) κ = 0.99
Figure 4.2: Examples of underrelaxed proposals for Gaussian processes, using different
values of κ, as in Equation 4.27. The black line shows the initial state, G, and the ﬁve
coloured lines show different proposals, ˆG. The ﬁve underlying H are shared across the
ﬁgures.
= p0(ˆγ) p(D | ˆγ) q(γ ←ˆγ) min

1, p(D | γ)
p(D | ˆγ)

= T(γ ←ˆγ) p0(ˆγ) p(D | ˆγ)
Naturally, proposals via independent draws from the prior, as in Section 4.3.1, ﬁt the
detailed balance condition. Independence chain Metropolis–Hastings is not an inter-
esting case, however, for the reasons discussed previously. Similarly, generating the
proposal via Metropolis–Hastings on the prior also satisﬁes detailed balance. This
procedure would result in the well-known MH two-stage acceptance rule (e.g. Murray
(2007, Chapter 2)). I also consider this an uninteresting case for my purposes, as it
only provides a way of making early rejections and does not actually increase the ac-
ceptance rate. In fact, the two-stage acceptance rule would likely decrease the overall
acceptance rate as it would occasionally veto some proposals that would have been
accepted.
More useful for this thesis are underrelaxed proposals that are conservative but that
can be made directly and not as the result of an intermediate accept/reject step. Specif-
ically, I will discuss a transition operator that is invariant under a Gaussian prior, such
as that arising on the function values of the control points in the previous section.
Lemma 4.2. Consider a transition from z to ˆz, q(ˆz ←z), for z, ˆz ∈RD, such that
ˆz = κ(z −µ) +
p
1 −κ2 (η −µ) + µ,
(4.25)
for η ∼N(µ, Σ), and −1 < κ < 1. Then q(ˆz ←z) satisﬁes detailed balance for the
distribution p(z) = N(µ, Σ), i.e. q(ˆz ←z) meets the condition of Equation 4.24 where the
equilibrium distribution is a D-dimensional Gaussian with mean µ and covariance matrix Σ.

Exchange Sampling for GPDS Inference
57
Proof. Start with the joint distribution over z and ˆz:
N(z | µ, Σ) q(ˆz ←z) = N(z | µ, Σ) N(ˆz | µ + κ(z−µ), (1−κ2)Σ).
(4.26)
The log probability of this joint distribution is
−1
2
h
(z−µ)TΣ−1(z−µ)+(1−κ2)−1(ˆz−µ−κ(z−µ))TΣ−1(ˆz−µ−κ(z−µ))
i
+const,
which can be rewritten as
−
1
2(1−κ2)
h
(z−µ)TΣ−1(z−µ)−2κ(ˆz−µ)TΣ−1(z−µ) + (ˆz−µ)TΣ−1(ˆz−µ)
i
+const,
which is symmetric in z and ˆz. This means that in Equation 4.26, z and ˆz could be
exchanged without changing the value of the joint distribution. This is equivalent to
detailed balance.
To make conservative proposals, κ is chosen to be close to one. At each step, a new
proposal for control points is made by perturbing the current state with a new draw
from the Gaussian process, using Equation 4.25. In the notation of the previous sec-
tion, the proposal is made via
ˆG = κ G +
p
1 −κ2 H,
(4.27)
where H ∼GP(C, θ) is an independent draw from the Gaussian process prior at the
control points. Figure 4.2 shows the sorts of proposals that result from underrelaxation
on Gaussian processes. Additional retrospective function evaluations are drawn from
the Gaussian process prior conditioning on these control points and any other values
in the conditioning set. Ultimately, the exchange sampling acceptance ratio for the
underrelaxed control point method is Equation 4.21. The algorithm is provided in
pseudocode in Algorithm 4.4.
4.3.3
Hyperparameter Inference
One of the appealing aspects of Bayesian probabilistic modeling is the ability to con-
struct and perform inference in hierarchical models. In the case of the Gaussian pro-
cess density sampler, this corresponds to inference of the hyperparameters θ that gov-
ern the covariance function, and ψπ that control the behaviour of the base density.
Inferring Hyperparameters of the Covariance Function
It is possible to perform hyperparameter inference on θ by including it in the exchange
sampling Markov chain state. The transitions of Section 4.3.2 are augmented so that

Exchange Sampling for GPDS Inference
58
Algorithm 4.4
Simulate R steps using underrelaxed control point ES on the GPDS.
Inputs:
• Number of MCMC iterations R
• Observed data D = {xn}N
n=1
• Control points C = {xb}B
b=1
• Underrelaxation parameter κ
• Gaussian process covariance function C(x, x′ ; θ)
• Base density π(x | ψπ)
Outputs:
• R conditioning sets of function inputs and outputs {X(r), G(r)}R
r=1
1: G ∼GP(g | C, θ)
▷Initialise the function at the control points.
2: X(1) ←C, G(1) ←G
▷Initialise conditioning sets.
3: for r ←1 . . . R do
▷Take R exchange sampling steps.
4:
H ∼GP(g | C, θ)
▷Make the independent GP draw for the proposal.
5:
ˆG ←κ G +
√
1 −κ2 H
▷Construct the actual proposal.
6:
ˆX ←C, ˆG ←ˆG
▷Initialise proposal conditioning sets.
7:
W ←∅
▷Initialise empty fantasy data set.
8:
repeat
▷Loop to generate fantasy data.
9:
˜
w ∼π(x | ψπ)
▷Draw a proposal from the base density.
10:
ˆg( ˜
w) ∼GP(g | ˜
w, ˆX, ˆG, θ)
▷Draw the function value at the proposal.
11:
ufant ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
12:
if ufant < Φ(ˆg( ˜
w)) then
▷Rejection sampling acceptance rule.
13:
W ←W ∪˜
w
▷Keep the fantasy.
14:
end if
15:
ˆX ←ˆX ∪˜
w, ˆG ←ˆG ∪ˆg( ˜
w)
▷Add proposals to the conditioning sets.
16:
until |W| = N
▷Loop until N fantasies are accepted.
17:
{g(wn)}N
n=1 ∼GP(g | W, X(r), G(r))
▷Sample the current function at the fantasies.
18:
agpds−ures ←
N
Y
n=1
Φ(ˆg(xn)) Φ(g(wn))
Φ(g(xn)) Φ(ˆg(wn))
▷Calculate the acceptance ratio.
19:
umh ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
20:
if umh < agpds−ures then
▷Apply the Metropolis–Hastings acceptance rule.
21:
X(r+1) ←ˆX, G(r+1) ←ˆG
▷Keep the new function data.
22:
G ←ˆG
▷Keep the new control point function values.
23:
else
24:
X(p+1) ←X(r) ∪{wn}N
n=1
▷Add the fantasy evaluations to the current state.
25:
G(p+1) ←G(r) ∪{g(wn)}N
n=1
26:
end if
27: end for
28: return {X(r), G(r)}R
r=1
before proposing control point function updates, new hyperparameters are ﬁrst pro-
posed from a distribution q(ˆθ ←θ). The control point function value proposals ˆG
are made while conditioning upon the new hyperparameters. Additional retrospec-
tive function draws for ˆg(x), including those for fantasisation, are also made using the
newly proposed hyperparameters ˆθ. Retrospective draws of the current function g(x),
however, are made using the current hyperparameters θ. The exchange proposal now
includes both the new function and the new hyperparameters. The pre-exchange joint

Exchange Sampling for GPDS Inference
59
distribution, including the hyperprior on θ, is
p(θ, G, g\C, D, ˆθ, ˆG, ˆg\C, W | C, ψπ) =
p0(θ) GP(G | C, θ) GP(g\C | G, θ) Zπ[g]−N
" N
Y
n=1
Φ(g(xn)) π(xn | ψπ)
#
× q(ˆθ ←θ) q( ˆG ←G; ˆθ) GP(ˆg\C | ˆG, ˆθ) Zπ[ˆg]−N
N
Y
n=1
Φ(ˆg(wn)) π(wn | ψπ),
(4.28)
and the acceptance ratio of exchanging the triplet (θ, G, g\C) for (ˆθ, ˆG, ˆg\C) is
agpds−gphp = p0(ˆθ) GP( ˆG | C, ˆθ) q(θ ←ˆθ) q(G ←ˆG; θ)
p0(θ) GP(G | C, θ) q(ˆθ ←θ) q( ˆG ←G; ˆθ)
N
Y
n=1
Φ(ˆg(xn)) Φ(g(wn))
Φ(g(xn)) Φ(ˆg(wn)). (4.29)
The underrelaxation trick cannot be used for hyperparameter updates because the
joint proposal distribution for ˆg and ˆθ would not generally satisfy detailed balance
for the corresponding joint prior. Conservative proposals are still suggested, but the
prior and proposal densities must be explicitly included in the acceptance ratio. Pseu-
docode for taking an exchange sampling step on the hyperparameters is provided in
Appendix A in Algorithm A.7 (page 121).
Inferring Hyperparameters of the Base Density
Sampling from the hyperparameters ψπ of the base density can also be done by aug-
menting the exchange sampling Markov chain. In this case, however, it is possible
to assume a ﬁxed latent function g, by using a single conditioning set for all retro-
spective samples, including those for generating the fantasies W = {wn}N
n=1. As in
previous discussions of exchange sampling, a proposal is drawn from the distribu-
tion q( ˆ
ψπ ←ψπ), followed by fantasisation using these new hyperparameters. The
joint distribution over the current hyperparameters, the data, the new hyperparame-
ters, and the fantasies is
p(ψπ, D, ˆ
ψπ, W | g) = p0(ψπ) Zπ[g]−N
" N
Y
n=1
Φ(g(xn)) π(xn | ψπ)
#
× q( ˆ
ψπ ←ψπ) ˆZπ[g]−N
N
Y
n=1
Φ(g(wn)) π(wn | ˆ
ψπ),
(4.30)
where I use ˆZπ[g] to indicate the dependence of the normalisation constant on ˆ
ψπ. The
acceptance ratio of the exchange of ψπ for ˆ
ψπ is
agpds−bdhp = p0( ˆ
ψπ) q(ψπ ←ˆ
ψπ)
p0(ψπ) q( ˆ
ψπ ←ψπ)
N
Y
n=1
π(xn | ˆ
ψπ) π(wn | ψπ)
π(xn | ψπ) π(wn | ˆ
ψπ)
.
(4.31)

Exchange Sampling for SGCP Inference
60
Algorithm A.8 (page 122) in Appendix A provides pseudocode for taking an exchange
sampling step on the base density hyperparameters.
4.4
Exchange Sampling for SGCP Inference
Having explained exchange sampling in Section 4.2 and applied it to the Gaussian pro-
cess density sampler in Section 4.3, I now apply exchange sampling to the sigmoidal
Gaussian Cox process of Chapter 3. Inference in the SGCP is very similar to the GPDS,
so I will skip over the independence chain approach and will start directly from the
control point method.
In the domain V, there are K observed events, S = {xk}K
k=1. Choose a set of B ≥K
control points C = {xb}B
b=1 that includes the observed events as a subset, i.e. S ⊆C.
Draws from the Gaussian process prior will be conditioned on the function val-
ues G = {g(xb)}B
b=1 at these points. As in Section 4.3.2, the number B and location C
of these control points are free parameters, but they remain ﬁxed throughout the algo-
rithm. The ﬁrst step in an exchange sampling transition is to draw new control point
function values ˆG = {ˆg(xb)}B
b=1 from a proposal density q( ˆG ←G). Next, a fantasy
set of events is drawn from the sigmoidal Gaussian Cox process using Algorithm 3.1,
as described in Section 3.4, while conditioning on C and ˆG. Unlike the Gaussian pro-
cess density sampler, the actual number of fantasy events may not be the same as
in the original data. I will denote the number of fantasy events as ˆK. After the fan-
tasies are generated, the current function g(x) is retrospectively sampled at the fantasy
events. Finally, the proposal to exchange the pair (G, g\C) for ( ˆG, ˆg\C) is accepted or
rejected, where g\C denotes the values of the function g(x), excluding those at the
control points. As in Gaussian process density sampler inference, all retrospective
evaluations, such as from thinned events during generation of fantasies, must be kept
in the Markov state. The control points are simply a way to make more conservative
proposals. Also as in the GPDS case, rejecting the exchange causes expansion of the
Markov state, via retrospective sampling of the current function at the fantasy events.
The joint distribution over current and proposed functions, the K observed
events {xk}K
k=1, and the
ˆK fantasy events {wk} ˆ
K
k=1 — the SGCP equivalent of

Exchange Sampling for SGCP Inference
61
Equation 4.22 — is
p(G, g\C, K, {xk}K
k=1, ˆG, ˆg\C, ˆK, {wk}
ˆ
K
k=1 | θ, ψλ) = GP(G | C, θ) GP(g\C | G, θ)
× exp

−
Z
V
dx′ Φ(g(x′)) ¯λ(x′ ; ψλ)
" K
Y
k=1
Φ(g(xk)) ¯λ(xk ; ψλ)
#
× q( ˆG ←G) GP(ˆg\C | ˆG, θ)
× exp

−
Z
V
dx′ Φ(ˆg(x′)) ¯λ(x′ ; ψλ)
 ˆ
K
Y
k=1
Φ(ˆg(wk)) ¯λ(wk ; ψλ).
(4.32)
The proposal to exchange the pair (G, g\C) for the pair ( ˆG, ˆg\C) has acceptance ratio
asgcp−cpes = q(G ←ˆG) GP( ˆG | C, θ)
q( ˆG ←G) GP(G | C, θ)
" K
Y
k=1
Φ(ˆg(xk))
Φ(g(xk))
#
ˆ
K
Y
k=1
Φ(g(wk))
Φ(ˆg(wk)),
(4.33)
where the difﬁcult integrals have canceled out.
It is also possible in the sigmoidal Gaussian Cox process to apply the underrelaxed
proposal trick that I discussed in Section 4.3.2. If the proposals for new control point
function values are made using Equation 4.27, then after generating the fantasy events,
the acceptance ratio is
asgcp−ures =
" K
Y
k=1
Φ(ˆg(xk))
Φ(g(xk))
#
ˆ
K
Y
k=1
Φ(g(wk))
Φ(ˆg(wk)).
(4.34)
The underrelaxed control point exchange sampling algorithm for the sigmoidal Gaus-
sian Cox process is provided as pseudocode in Algorithm 4.5.
4.4.1
Hyperparameter Inference
As with the Gaussian process density sampler in Section 4.3.3, it is possible to aug-
ment the exchange sampling Markov chain to sample from the Gaussian process
hyperparameters θ and any hyperparameters ψλ governing the dominating inten-
sity ¯λ(x ; ψλ).
Inferring Hyperparameters of the Covariance Function
Sampling from Gaussian process hyperparameters in the sigmoidal Gaussian Cox pro-
cess is similar to the method described in Section 4.3.3. Propose new hyperparame-
ters ˆθ, draw new control point function values ˆG, then generate fantasy events condi-
tioned upon these two proposals. The exchange proposes to swap the triplet (θ, G, g\C)

Exchange Sampling for SGCP Inference
62
Algorithm 4.5
Simulate R steps using underrelaxed control point ES on the SGCP.
Inputs:
• Number of MCMC iterations R
• Domain V
• Observed data {xk}K
k=1
• Control points C = {xb}B
b=1
• Underrelaxation parameter κ
• Gaussian process covariance function C(x, x′ ; θ)
• Dominating intensity ¯λ(x ; ψλ)
Outputs:
• R conditioning sets of function inputs and outputs {X(r), G(r)}R
r=1
1: G ∼GP(g | C, θ)
▷Initialise the function at the control points.
2: X(1) ←C, G(1) ←G
▷Initialise conditioning sets.
3: for r ←1 . . . R do
▷Take R exchange sampling steps.
4:
H ∼GP(g | C, θ)
▷Make the independent GP draw for the proposal.
5:
ˆG ←κ G +
√
1 −κ2 H
▷Construct the actual proposal.
6:
ˆX ←C, ˆG ←ˆG
▷Initialise proposal conditioning sets.
7:
{ ˜
wj}J
j=1 ∼PP(¯λ(x ; ψλ), V)
▷Draw from the bounding intensity.
8:
{ˆg( ˜
wj)}J
j=1 ∼GP(g | { ˜
wj}J
j=1, ˆX, ˆG)
▷Sample the proposed function at the events.
9:
ˆX ←ˆX ∪{ ˜
wj}J
j=1, ˆG ←ˆG ∪{g( ˜
wj)}J
j=1
▷Update the proposed conditioning set.
10:
W ←∅
▷Initialise fantasy set.
11:
for j ←1 . . . J do
▷Loop over the events.
12:
ufant ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
13:
if ufant < Φ(ˆg( ˜
wj)) then
▷Apply the thinning rule.
14:
W ←W ∪˜
wj
▷Add the event to the fantasy set.
15:
end if
16:
end for
17:
{g(wk)} ˆ
K
k=1 ∼GP(g | W, X(r), G(r))
▷Sample the current function at the fantasies.
18:
asgcp−ures ←
" K
Y
k=1
Φ(ˆg(xk))
Φ(g(xk))
# 

ˆ
K
Y
k=1
Φ(g(wk))
Φ(ˆg(wk))


▷Calculate the acceptance ratio.
19:
umh ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
20:
if umh < asgcp−ures then
▷Apply the Metropolis–Hastings acceptance rule.
21:
X(r+1) ←ˆX, G(r+1) ←ˆG
▷Keep the new function data.
22:
G ←ˆG
▷Keep the new control points.
23:
else
24:
X(r+1) ←X(r) ∪{wk} ˆ
K
k=1
▷Add the fantasy evaluations to the current state.
25:
G(r+1) ←G(r) ∪{g(wk)} ˆ
K
k=1
26:
end if
27: end for
28: return {X(r), G(r)}R
r=1
for (ˆθ, ˆG, ˆg\C), with acceptance ratio
asgcp−gphp = p0(ˆθ) GP( ˆG | C, ˆθ) q(θ ←ˆθ) q(G ←ˆG; θ)
p0(θ) GP(G | C, θ) q(ˆθ ←θ) q( ˆG ←ˆG; ˆθ)
×
" K
Y
k=1
Φ(ˆg(xk))
Φ(g(xk))
#
ˆ
K
Y
k=1
Φ(g(wk))
Φ(ˆg(wk)).
(4.35)
This algorithm is provided as pseudocode in Appendix A as Algorithm A.9 (page 123).

Predictive Samples
63
Inferring Hyperparameters of the Dominating Intensity
It is also possible to sample from the hyperparameters ψλ that govern the dominating
intensity ¯λ(x ; ψλ). This is analogous to sampling from the base density hyperparam-
eters in Section 4.3.3. If the current hyperparameters are ψλ, then a new proposal ˆ
ψλ
is drawn from the distribution q( ˆ
ψλ ←ψλ). It is not necessary to propose a new func-
tion — the current conditioning set can be used to generate the fantasies. The joint
distribution over the current and proposed hyperparameters, and the observed and
fantasy data, is
p(ψλ, K, {xk}K
k=1, ˆ
ψλ, ˆK, {wk}
ˆ
K
k=1 | g) =
p0(ψλ) exp

−
Z
V
dx′ Φ(g(x′)) ¯λ(x′ ; ψλ)
" K
Y
k=1
Φ(g(xk)) ¯λ(xk ; ψλ)
#
× q( ˆ
ψλ ←ψλ) exp

−
Z
V
dx′ Φ(g(x′)) ¯λ(x′ ; ˆ
ψλ)
 ˆ
K
Y
k=1
Φ(g(wk)) ¯λ(wk ; ˆ
ψλ).
(4.36)
The acceptance ratio of exchanging ψλ for ˆ
ψλ is
asgcp−bihp = q(ψλ ←ˆ
ψλ) p0( ˆ
ψλ)
q( ˆ
ψλ ←ψλ) p0(ψλ)
" K
Y
k=1
¯λ(xk ; ˆ
ψλ)
¯λ(xk ; ψλ)
#
ˆ
K
Y
k=1
¯λ(wk ; ψλ)
¯λ(wk ; ˆ
ψλ)
.
(4.37)
This algorithm is provided as pseudocode in Appendix A as Algorithm A.10 (page
124).
4.5
Predictive Samples
Commonly when performing inference, we are interested in the predictive distribu-
tion. This is the distribution that arises on the data space after integrating out the
posterior distribution over parameters. It can be viewed as the distribution over the
next datum, having seen a set of data, and taking into account uncertainty. While this
distribution is not available in closed form for the Gaussian process density sampler
or the sigmoidal Gaussian Cox process, it is possible to generate samples from it. To
generate predictive samples, simulate the exchange sampling Markov chain algorithm
and after each update, run the generative procedure using the current state to initialise
the conditioning set. This is done exactly as it was when generating fantasy data us-
ing Algorithm 2.2 and Algorithm 3.1, but starting with the conditioning set that is the
current state of the Markov chain.

Summary
64
4.6
Summary
In this chapter I presented one method of inference for the Gaussian process den-
sity sampler model and the sigmoidal Gaussian Cox process model. This method,
exchange sampling, relied on the ability to generate exact data from the models for
a given setting of the parameters. The result was a Metropolis–Hastings sampler in
which acceptance ratios could be calculated without estimation of a ratio of intractable
normalisation constants. Remarkably, it is possible to construct a Markov chain with
the Bayesian posterior as its equilibrium distribution for both models, even though
the objects of inference have inﬁnite dimensions. I also showed that for both models
it is possible to perform hyperparameter inference and discussed how one can sample
from the predictive distribution.
In Chapter 5, I will present an alternate method for inference in these two models and
show how, for the Gaussian process density sampler and the sigmoidal Gaussian Cox
process, it is preferable to exchange sampling.

Chapter 5
Inference Via Latent Histories
In this chapter, I present a method for inference in the Gaussian process density sam-
pler and the sigmoidal Gaussian Cox process that is superior to the exchange sampling
approach of Chapter 4. This method takes advantage of the generative procedures of
the GPDS and the SGCP to construct latent variable models in which inference can
be performed via Markov chain Monte Carlo, without it being necessary to compute
ratios of intractable normalisation constants.
I begin with a discussion of latent history inference in Section 5.1. In Section 5.2, I show
how the latent history method can be applied to the Gaussian process density sampler.
I apply the method to the sigmoidal Gaussian Cox process in Section 5.3. In Section 5.4,
I discuss how the latent history approach differs from exchange sampling, and why it
is an improvement. I describe how the latent history method can be extended to allow
inference in SGCP-derived interacting point processes in Section 5.5.
5.1
Modeling the Latent History of the Generative Procedure
Modeling data with a generative prior is, in effect, asserting that the observed data are
the result of running the relevant generative procedure. Typically, nothing is known
about the various intermediate states that led to the ﬁnal observations, but it is nev-
ertheless possible to model these unknown states with latent variables. One can gen-
erate samples from the posterior distribution over this latent history of the generative
procedure, and then keep samples from the parameters of interest.
Generative models as a concept are as old as probabilistic modeling itself. The idea
captured by “inference via latent histories,” however, is to model some speciﬁc com-
putational procedure that is not necessarily motivated by a natural process. In Chap-
ter 2 and Chapter 3, I presented generative processes based on rejection sampling and
thinning, respectively. These are “artiﬁcial” in the sense that it is not realistic to think
that variation in bus arrival rates is the result of the independent removal of some

Latent History Inference in the GPDS
66
buses. Still, the Gaussian process density sampler and the sigmoidal Gaussian Cox
process allow the construction of models that are tractable, but that are no less reason-
able explanations for the data than their cousins the logistic Gaussian process and the
log Gaussian Cox process.
Inference by Markov chain Monte Carlo of the history of a probabilistic computational
procedure has been studied previously. Beskos et al. (2006b) sampled from the state
of a rejection sampler for diffusions. Murray (2007), who coined the phrase “latent
history,” modeled data as having been the result of a Markov chain which had prov-
ably mixed via coupling from the past (Propp and Wilson, 1996). Another example
is Huber and Wolpert (2009), who model the history of the Mat´ern Type III process
to perform tractable inference. The Church programming language (Goodman et al.,
2008) also exploits this idea, by treating probabilistic procedures as ﬁrst class objects
on which inference can be performed.
5.2
Latent History Inference in the GPDS
To perform inference in the Gaussian process density sampler via the latent history
method, I model the N data D = {xn}N
n=1 as having been generated exactly as in Al-
gorithm 2.2. The unknown quantities in this model are 1) the number of rejected pro-
posals, which I denote as M; 2) the locations of the rejected proposals, which I denote
as M = {xm}M
m=1; 3) the values of the function at the data, denoted GN = {g(xn)}N
n=1,
and at the rejections, denoted GM = {g(xm)}M
m=1. The joint distribution over the data
and the ordered history of the GPDS generative procedure, given the hyperparame-
ters, is
p(D, GN, M, GM | θ, ψπ) = GP(GN, GM | D, M, θ)
×
" N
Y
n=1
Φ(g(xn)) π(xn | ψπ)
# M
Y
n=1
(1 −Φ(g(xm))) π(xm | ψπ).
(5.1)
To sample from this joint distribution, I suggest a Gibbs-like alternation between
1) modiﬁcation of the number of rejections M; 2) updating the rejection locations M;
3) modiﬁcation of the latent function values GM and GN. When discussing the latent
history, I imply that an ordering is maintained over the sequence of acceptances and
rejections in D and M. Due to exchangeability, however, it is not necessary to actu-
ally maintain this ordering. At any time, a reshufﬂing of the latent history could be
proposed, subject to it ending in an acceptance, and this proposal would always be
accepted, as the two permutations have the same probability under the model. When
thinking about the computation, it is often still useful to imagine an actual ordering,
but it will turn out that no computations actually depend on the ordering.

Latent History Inference in the GPDS
67
1
2
3
5
6
7
4
M = {xm}M
m=1
D = {xn}N
n=1
(a) Initial state of the latent history
1
2
3
5
6
7
4
M+ = {xm} ˆ
M
m=M+1
(b) Propose additional rejections after last acceptance
1
2
3
5
6
7
4
(c) Propose moving the new rejections into the history
1
2
3
4
5
6
7
(d) New state of the latent history, if accepted
Figure 5.1: A cartoon of how new rejections are inserted into the latent history. There
are seven data. (a) There are six latent rejections in the initial state. (b) Four additional
rejections are proposed after the seventh accepted datum. Each of these has associated
with it a function value drawn from the Gaussian process. (c) Locations for the new
rejections in the latent history are proposed. (d) If accepted, there is a new history, now
with ten latent rejections.
5.2.1
Sampling the Number of Latent Rejections
Propose a new number of latent rejections ˆ
M by drawing it from a proposal den-
sity q( ˆ
M ←M). If ˆ
M is greater than M, it is also necessary to propose the new rejec-
tion locations and function values that will be added to the latent state. We can take
advantage of the exchangeability of the process to generate the new rejections: we
imagine these proposals were made after the last observed datum was accepted, and
the proposal is to label them rejections and move them before the last datum. This idea
is shown graphically in Figure 5.1. If ˆ
M is less than M, do the opposite by proposing
to move some rejections to after the last acceptance.
When proposing additional rejections, it is also necessary to propose times for them
among the current latent history. There are
  ˆ
M+N−1
ˆ
M−M

such ways to insert these addi-
tional rejections into the existing latent history, such that the sampler terminates after
the Nth acceptance. When removing rejections, there are
 M
M−ˆ
M

possible sets that
can be moved to after the last acceptance. As mentioned before, none of the com-
putation depends directly upon the ordering, due to exchangeability. It is, however,
still necessary to account for the implicit ordering when constructing the proposals.

Latent History Inference in the GPDS
68
Upon simpliﬁcation, the proposal ratios for both addition and removal of rejections
are identical:
ˆ
M>M
z
}|
{
q(M ←ˆ
M)
  ˆ
M+N−1
ˆ
M−M

q( ˆ
M ←M)
 ˆ
M
ˆ
M−M

=
ˆ
M<M
z
}|
{
q(M ←ˆ
M)
 M
M−ˆ
M

q( ˆ
M ←M)
 M+N−1
M−ˆ
M
 = q(M ←ˆ
M)M!( ˆ
M +N −1)!
q( ˆ
M ←M) ˆ
M!(M +N −1)!
.
(5.2)
When inserting rejections, propose the locations of the additional proposals, de-
noted M+, and the corresponding values of the latent function, denoted G+
M.
These M+ are generated by making
ˆ
M −M independent draws from the base
density. The G+
M are then drawn jointly from the Gaussian process prior, conditioned
on all of the current latent state, i.e. G+
M ∼GP(M+, M, GM, D, GN, θ). This is the inter-
mediate state shown in Figure 5.1b (although the function draws are not illustrated),
with joint probability
p(D, M, M+, GN, GM, G+
M | θ, ψπ) = GP(GM, GN, G+
M | D, M, M+, θ)
×
" N
Y
n=1
Φ(g(xn)) π(xn | ψπ)
# " M
Y
m=1
(1 −Φ(g(xm))) π(xm | ψπ)
#
ˆ
M
Y
m=M+1
π(xm | ψπ).
(5.3)
The joint distribution in Equation 5.3 expresses the probability of all the base density
draws, the values of the function draws from the Gaussian process, the acceptance
probabilities of the data, and the rejection probabilities of the latent rejections, before
labeling the new proposals M+ as rejections. When an insertion proposal is made,
exchangeability allows the ordering to be shufﬂed without changing the probability;
the only change is that it is necessary now to account for labeling the new points as
rejections. In the acceptance ratio, all terms except for this “labeling probability” can-
cel. The reverse proposal is similar, however, I denote the removed proposal locations
as M−and the corresponding function values as G−
M. The overall acceptance ratios
for insertions or removals are
agpds−num =

















q(M ←ˆ
M) M! ( ˆ
M + N −1)!
q( ˆ
M ←M) ˆ
M! (M + N −1)!
Y
x∈M+
(1 −Φ(g(x)))
if ˆ
M > M
q(M ←ˆ
M) M! ( ˆ
M + N −1)!
q( ˆ
M ←M) ˆ
M! (M + N −1)!
Y
x∈M−
(1 −Φ(g(x)))−1
if ˆ
M < M.
(5.4)
A simple and convenient way of implementing this procedure is to make limited pro-
posals that either insert or delete only one latent rejection at a time. In practice, I
have found this to work well. I deﬁne a function ζ(M, N) : N × N+ →(0, 1] that is the
Bernoulli probability of making a proposal to insert a new latent rejection. It is, of

Latent History Inference in the GPDS
69
course, necessary that ζ(0, N) = 1. With this limited proposal, the ﬁrst case of Equa-
tion 5.4 (proposing one new latent rejection, i.e. ˆ
M = M + 1) can be written as
agpds−ins = (1 −ζ(M + 1, N)) (M + N) (1 −Φ(g(x+)))
ζ(M, N) (M + 1)
,
(5.5)
where x+ is the proposed rejection location.
The location x+ is drawn from the
base density π(x | ψπ).
In the second case, if there is at least one latent rejection
in the current history (M > 0), then the deletion of a single rejection is proposed,
i.e. ˆ
M = M −1. This deletion proposal has Metropolis–Hastings acceptance ratio
agpds−del =
ζ(M −1, N) M
(1 −ζ(M, N)) (M + N −1) (1 −Φ(g(x−))),
(5.6)
where x−is the location of the proposed removal. The rejection to remove is chosen
uniformly from among the M currently in the history. In my experience applying
the latent history method to the examples in Chapter 6, it appears that the speciﬁc
form of ζ(M, N) does not signiﬁcantly impact performance and I have had success
with ζ(M, N) = 1
2. It has, however, often been beneﬁcial to make several (≈10) of
these proposals for each of the other proposals mentioned in this section.
5.2.2
Sampling the Locations of Latent Rejections
This section discusses Markov chain Monte Carlo transitions on the locations of the
latent rejections, denoted M = {xm}M
m=1.
When making these moves, we condi-
tion on the rest of the latent history: the number of rejections M and the latent
function g(x). Given the latent function, the locations of the rejections are indepen-
dent. Iterate over each of the M rejections and sample its location using Metropolis–
Hastings.
For the mth rejection xm, ﬁrst propose a new location ˆxm from a dis-
tribution q(ˆxm ←xm).
Then sample the function at this location to ﬁnd g(ˆxm).
Draw this value from the Gaussian process, conditioning on the rest of the state,
i.e. g(ˆxm) ∼GP(ˆxm, D, GN, M, GM, θ). Reject or accept this proposal according to MH
acceptance ratio
agpds−loc = q(xm ←ˆxm) (1 −Φ(g(ˆxm))) π(ˆxm | ψπ)
q(ˆxm ←xm) (1 −Φ(g(xm))) π(xm | ψπ).
(5.7)
These moves could also be done with an aggregate proposal for all of M latent re-
jection locations at once, via q( ˆ
M ←M), where
ˆ
M = {ˆxm}M
m=1. This Metropolis–
Hastings proposal has acceptance ratio
agpds−locs = q(M ←ˆ
M)
q( ˆ
M ←M)
M
Y
m=1
(1 −Φ(ˆg(xm))) π(ˆxm | ψπ)
(1 −Φ(g(xm))) π(xm | ψπ).
(5.8)

Latent History Inference in the GPDS
70
As in most implementations of Metropolis–Hastings, choosing an appropriate pro-
posal distribution q(ˆxm ←xm) is important to efﬁciency. For perturbative proposals,
this corresponds to choosing a reasonable “step size” for proposed moves, e.g. the σ
of a Gaussian proposal. In the Gaussian process density sampler, when using a co-
variance function such as the squared-exponential, it is possible to select this step size
somewhat automatically, based on the length scale ℓof the GP, e.g. σ = c · ℓ, for some
“hyper-step-size” c. In Section 5.2.4, I discuss sampling from the hyperparameters
of the Gaussian process. Adapting the length scale of a stationary covariance func-
tion is equivalent to inferring an appropriate distance metric for the data space. It is
useful to take advantage of this information to improve mixing of the rejection loca-
tions. Each time the length scale is updated, the step size of q(ˆxm ←xm) can also
be updated. This adaptation is Markovian, so it does not sacriﬁce the validity of the
Markov chain’s equilibrium distribution.
5.2.3
Sampling the Latent Function
Conditioned on the number M and locations M of the latent rejections, it is also nec-
essary to sample from the latent function at both the data and rejection locations, de-
noted GN and GM, respectively. The conditional joint posterior distribution is
p(GN, GM | M, D, θ) ∝GP(GN, GM | D, M, θ)
×
" N
Y
n=1
Φ(g(xn))
#
M
Y
m=1
(1 −Φ(g(xm))) .
(5.9)
In Section 4.3.2, I discussed a complex underrelaxation scheme, based on control
points, to make effective proposals for the function g(x) in the Gaussian process den-
sity sampler. In the latent history approach to inference, however, it is not necessary
to use control points and underrelaxation to achieve efﬁcient sampling. Instead, we
can sample from Equation 5.9 using Hamiltonian Monte Carlo (HMC).
Hamiltonian (or hybrid) Monte Carlo (Duane et al., 1987) is a Metropolis–Hastings
sampling method that takes advantage of gradient information to make efﬁcient pro-
posals and reduce random walk behaviour. The idea is to augment the state of the
Markov chain with random “momentum” variables and then simulate the result-
ing Hamiltonian system in ﬁctitious time using, for example, Euler integration. The
leapfrog method described in Neal (1996), Rasmussen (1996) and MacKay (2003, Chap-
ter 30) is easy to implement and is effective for simulating these dynamics.
For numerical reasons, when sampling from a function with a Gaussian process prior,
as in Equation 5.9, it is useful to perform gradient calculations in the “whitened”
space resulting from applying to the function values the inverse Cholesky decom-
position of the covariance matrix. That is, if C is the positive-deﬁnite matrix result-

Latent History Inference in the GPDS
71
ing from applying the covariance function to the union of data D = {xn}N
n=1 and la-
tent rejections M = {xm}M
m=1, and gN,M = vec(GN ∪GM) is the vector of function val-
ues at those locations, then ﬁrst transform gN,M with the matrix L−1, where L is the
Cholesky decomposition of C, i.e. C = LLT.
Algorithm 5.1 implements the latent history algorithm in pseudocode, using a sim-
ple q( ˆ
M ←M) that proposes increasing or decreasing the number of latent rejec-
tions M by one, with probabilities ζ(M, N) and 1 −ζ(M, N), respectively.
5.2.4
Sampling the Gaussian Process Hyperparameters
The joint distribution in Equation 5.1 depends only on the Gaussian process hyperpa-
rameters θ through the GP prior term. Conditioning on the latent rejections and the
data, as well as the current function values, it is possible to sample from the hyperpa-
rameters using the Gaussian process marginal likelihood, as in Equation 1.3. As sug-
gested by Williams and Rasmussen (1996) and Neal (1998), Hamiltonian Monte Carlo
is a useful method for efﬁcient sampling from Gaussian process hyperparameters due
to the frequent availability of analytic gradients. See Rasmussen (1996, Chapter 4) for
a more comprehensive discussion of this topic.
5.2.5
Sampling the Base Density Hyperparameters
As with exchange sampling in Section 4.3.3, it is appealing to sample from the hyper-
parameters ψπ governing the base density π(x | ψπ). Conditioned on the number of
rejections M, the rejection locations M, and the function values GN and GM, the joint
distribution in Equation 5.1 depends on ψπ only through the products of base densi-
ties. This makes intuitive sense, as the generative model is that the union of the data
and rejections are i.i.d. from the base density. Therefore, samples from the base den-
sity hyperparameters can be drawn using any convenient Markov chain Monte Carlo
method. Conditioned on all other aspects of the latent history, π(x | ψπ) can be treated
as its own model, with D ∪M being the observed data. For example, with a simple
exponential-family base density, it is convenient to select a conjugate hyperprior. The
hyperparameters ψπ can then be updated using Gibbs sampling, as in Gelman et al.
(2004), for example.
5.2.6
Generating Predictive Samples
As discussed in Section 4.5, the predictive distribution plays an important role in
Bayesian modeling. To generate a predictive sample from the Gaussian process den-
sity sampler under the latent history scheme, take the current latent history and run
Algorithm 2.2 further until another (the N +1th) datum has been accepted. If this is

Latent History Inference in the GPDS
72
Algorithm 5.1
Generate R samples from the latent history of the GPDS
Inputs:
• Number of MCMC iterations R
• Observed data D = {xn}N
n=1
• Gaussian process covariance function C(x, x′; θ)
• Base density π(x | ψπ)
• Location proposal density q(ˆxm ←xm)
• Insert proposal probability function ζ(M, N)
Outputs:
• R samples of the latent history {M(r), G(r)
N , G(r)
M }R
r=1
1: M ←∅, GM ←∅
▷Start out with no latent rejections.
2: GN ∼GP(g | D, θ)
▷Initialise the function at the data.
3: for r ←1 . . . R do
▷Take R MCMC steps on the latent history.
4:
uζ ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
5:
if uζ < ζ(|M|, N) then
▷Decide whether to insert or delete.
6:
x+ ∼π(x | ψπ)
▷Draw a proposed rejection location.
7:
g(x+) ∼GP(g | x+, D, M, GM, GN, θ)
▷Draw the proposed function value.
8:
agpds−ins ←(1 −ζ(|M| + 1, N)) (|M| + N) (1 −Φ(g(x+)))
ζ(|M|, N) (|M| + 1)
▷Acceptance ratio.
9:
uins ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
10:
if uins < agpds−ins then
▷Metropolis–Hastings acceptance rule.
11:
M ←M ∪x+, GM ←GM ∪g(x+)
▷Add this new rejection.
12:
end if
13:
else if |M| > 0 then
14:
m ∼⌈U(0, |M|)⌉
▷Select one of the M rejections at random.
15:
agpds−del =
ζ(|M| −1, N) |M|
(1 −ζ(|M|, N)) (|M| + N −1) (1 −Φ(g(xm)))
▷Acceptance ratio.
16:
udel ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
17:
if udel < agpds−del then
▷Metropolis–Hastings acceptance rule.
18:
M ←M\xm, GM ←GM\g(xm)
▷Remove the mth rejection.
19:
end if
20:
end if
21:
for m ←1 . . . M do
▷Loop over the latent rejections.
22:
ˆxm ∼q(ˆxm ←xm)
▷Propose a new location.
23:
g(ˆxm) ∼GP(g | ˆxm, D, M, GN, GM, θ)
▷Draw a function value from the GP.
24:
agpds−loc = q(xm ←ˆxm) π(ˆxm) (1 −Φ(g(ˆxm)))
q(ˆxm ←xm) π(xm) (1 −Φ(g(xm)))
▷Acceptance ratio.
25:
uloc ∼U(0, 1)
▷Draw a uniform random variate from (0, 1).
26:
if uloc < agpds−loc then
▷Metropolis–Hastings acceptance rule.
27:
xm ←ˆxm, g(xm) ←g(ˆxm)
▷Update the rejection.
28:
end if
29:
end for
30:
GN,GM ∼HMC(GN, GM | D, M, θ)
▷Update function via Hamiltonian Monte Carlo.
31:
M(r) ←M, G(r)
N ←GN, G(r)
M ←GM
▷Store the current estimate of the latent history.
32: end for
33: return {M(r), G(r)
N , G(r)
M }R
r=1

Latent History Inference in the SGCP
73
done for each Markov chain Monte Carlo step in the latent history inference, then the
samples kept will be from the predictive distribution. This, in effect, integrates over
the posterior distribution on the latent function, and any hyperparameters included
in the model.
5.3
Latent History Inference in the SGCP
Inference can be performed in the sigmoidal Gaussian Cox process using the latent
history method in a very similar way to the Gaussian process density sampler. Given
a set of K observed events S = {xk}K
k=1, the task is to sample from the posterior
distribution on latent functions g(x) that gave rise to the unknown intensity func-
tion λ(x). Using the SGCP to model the data is equivalent to asserting that Algo-
rithm 3.1 was used to generate the data. The unknowns in this case are 1) the number
of events that were thinned, denoted M; 2) the locations of the thinned events, de-
noted M = {xm}M
m=1; 3) the values of the latent function g(x) at the observed events,
denoted GK = {g(xk)}K
k=1, and at the thinned events, denoted GM = {g(xm)}M
m=1.
This set of latent variables is nearly identical to that used to model the latent his-
tory of the Gaussian process density sampler. The joint distribution on the history is
different, however:
p(S, GK, M, GM | V, θ, ψλ) = GP(GK, GM | S, M, θ) exp

−¯ΛV(ψλ)
	
×
" K
Y
k=1
¯λ(xk ; ψλ) Φ(g(xk))
#
M
Y
m=1
¯λ(xm ; ψλ) (1 −Φ(g(xm))),
(5.10)
where
¯ΛV(ψλ) =
Z
V
dx ¯λ(x ; ψλ).
(5.11)
I assume that ¯λ(x ; ψλ) has been chosen so that the integral in Equation 5.11 is easy to
compute. As in the previous section with the Gaussian process density sampler, this
latent history can be sampled using Markov chain Monte Carlo in several stages.
5.3.1
Sampling the Number of Thinned Events
Metropolis–Hastings can be used to sample from the number of thinned events M.
Use a function ζ(M, K), as introduced in Section 5.2.1, to provide a Bernoulli proba-
bility of making a proposal to insert a new thinned event into the latent history. An

Latent History Inference in the SGCP
74
insertion move consists of proposing a new x+ from the density
qx+(x) =
¯λ(x ; ψλ)
¯ΛV(ψλ)
IV(x),
(5.12)
followed by a draw from the Gaussian process to ﬁnd g(x+), conditioned on GK
and GK, i.e. g(x+) ∼GP(x+, S, M, GK, GM). The proposal distribution of this new
location x+ and associated function value g(x+), taken together, is
qins(M ∪x+ ←M) = ζ(M, K)
¯λ(x+ ; ψλ)
¯ΛV(ψλ)
IV(x+) GP(g(x+) | x+, S, M, GK, GM).
(5.13)
A deletion move is proposed when the Bernoulli coin ﬂip does not indicate an in-
sertion. To delete a latent thinned event that is already in the history, ﬁrst select the
event m uniformly from the M events currently in the state. This proposal distribution
is
qdel(M\xm ←M) = 1 −ζ(M, K)
M
.
(5.14)
Incorporating the joint distribution in Equation 5.10, the Metropolis–Hastings accep-
tance ratios of the two types of proposals are
asgcp−ins = (1 −ζ(M + 1, K)) ¯ΛV(ψλ) (1 −Φ(g(x+)))
ζ(M, K) (M + 1)
(5.15)
asgcp−del =
ζ(M −1, K) M
(1 −ζ(M, K)) ¯ΛV(ψλ) (1 −Φ(g(xm)))
.
(5.16)
5.3.2
Sampling the Locations of Thinned Events
Given the number of thinned events M, sample next from the posterior distribution
on the locations of the events, M = {xm}M
m=1. As when updating the rejection loca-
tions in the Gaussian process density sampler, Metropolis–Hastings can be used to
perform this sampling. Iterate over each of the M thinned events and propose a new
location ˆxm via the proposal density q(ˆxm ←xm). Then draw a function value g(ˆxm)
from the Gaussian process, conditioned on the current state GK and GM, including
the mth one. The Metropolis–Hastings acceptance ratio for this proposal is
asgcp−loc = q(xm ←ˆxm) ¯λ(ˆxm ; ψλ) (1 −Φ(g(ˆxm)))
q(ˆxm ←xm) ¯λ(xm ; ψλ) (1 −Φ(g(xm)))
.
(5.17)
Typically, perturbative proposals on the order of the Gaussian process length scale are
appropriate for these Metropolis–Hastings steps, as discussed in Section 5.2.2. If the

Latent History Inference in the SGCP
75
move is accepted, the old values xm and g(xm) can safely be discarded.
5.3.3
Sampling the Latent Function
As in the Gaussian process density sampler, Hamiltonian Monte Carlo (Duane et al.,
1987) is useful for inference of the values of the function at the observed events and at
the thinned events. HMC enables the use of gradient information to make improved
proposals. As discussed previously, it is beneﬁcial to whiten the space for improved
numerical conditioning. The conditional distribution on the function values is
p(GK, GM | V, S, M, θ) ∝GP(GK, GM | S, M, θ)
×
" K
Y
k=1
Φ(g(xk))
#
M
Y
m=1
(1 −Φ(g(xm))).
(5.18)
5.3.4
Sampling the Gaussian Process Hyperparameters
Inference of the Gaussian process hyperparameters can be done easily using the stan-
dard Hamiltonian Monte Carlo methods discussed in Section 5.2.4. As in the Gaus-
sian process density sampler, conditioned on the latent history, the Gaussian process
marginal likelihood allows convenient sampling from GP hyperparameters.
5.3.5
Sampling the Dominating Intensity Hyperparameters
Sampling
from
the
dominating
intensity
hyperparameters
ψλ
helps
ensure
that ¯λ(x ; ψλ) is not limiting the maximum intensity of the Poisson model artiﬁ-
cially.
Alternatively, adapting the dominating intensity can prevent an excessive
number of thinned events being required for the model, if ¯λ(x ; ψλ) is providing only
a loose bound on the true intensity λ(x). The conditional posterior distribution over
the dominating intensity hyperparameters, writing out the integral for ¯ΛV(ψλ), is
p(ψλ | V, S, M) ∝exp

−
Z
V
dx′ ¯λ(x′ ; ψλ)
 " K
Y
k=1
¯λ(xk ; ψλ)
#
M
Y
m=1
¯λ(xm ; ψλ). (5.19)
Sampling from this conditional posterior via Markov chain Monte Carlo is exactly
as it would be if this was a simple parametric Poisson model.
One convenient
form of the dominating intensity is to simply make it constant, i.e. ¯λ(x ; ψλ) = λ⋆,
so that ψλ = λ⋆and ¯ΛV(ψλ) = λ⋆µ(V).
In this case, the gamma distribution is a
conditionally-conjugate prior for λ⋆. If the gamma prior parameters are α0 and β0,

Latent History Inference in the SGCP
76
Algorithm 5.2
Generate R samples from the latent history of the SGCP
Inputs:
• Number of MCMC iterations R
• Observed events S = {xk}K
k=1
• Gaussian process covariance function C(x, x′; θ)
• Dominating intensity gamma prior parameters α0 and β0
• Location proposal density q(ˆxm ←xm)
• Insert proposal probability function ζ(M, K)
Outputs:
• R samples of the latent history {M(r), G(r)
K , G(r)
M }R
r=1
• R samples of the dominating intensity {λ(r)
⋆}R
r=1
1: M ←∅, GM ←∅
▷Start out with no thinned events.
2: GK ∼GP(g | S, θ)
▷Initialise the function at the data.
3: λ⋆∼GA(α0, β0)
▷Draw the initial dominating intensity.
4: for r ←1 . . . R do
▷Take R MCMC steps on the latent history.
5:
uζ ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
6:
if uζ < ζ(|M|, K) then
▷Decide whether to insert or delete.
7:
x+ ∼U(V)
▷Draw a new location uniformly in V.
8:
g(x+) ∼GP(g | x+, S, M, GM, GK, θ)
▷Draw the proposed function value.
9:
asgcp−ins ←(1 −ζ(|M| + 1, K)) λ⋆µ(V) (1 −Φ(g(x+)))
ζ(|M|, K) (|M| + 1)
▷Acceptance ratio.
10:
uins ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
11:
if uins < asgcp−ins then
▷Metropolis–Hastings acceptance rule.
12:
M ←M ∪x+, GM ←GM ∪g(x+)
▷Add this new rejection.
13:
end if
14:
else
15:
m ∼⌈U(0, |M|)⌉
▷Select one of the M thinned events at random.
16:
asgcp−del =
ζ(|M| −1, K) |M|
(1 −ζ(|M|, K)) λ⋆µ(V) (1 −Φ(g(xm)))
▷Acceptance ratio.
17:
udel ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
18:
if udel < asgcp−del then
▷Metropolis–Hastings acceptance rule.
19:
M ←M\xm, GM ←GM\g(xm)
▷Remove the mth thinned event.
20:
end if
21:
end if
22:
for m ←1 . . . M do
▷Loop over the thinned events.
23:
ˆxm ∼q(ˆxm ←xm)
▷Propose a new location.
24:
g(ˆxm) ∼GP(g | ˆxm, S, M, GK, GM, θ)
▷Draw a function value from the GP.
25:
asgcp−loc = q(xm ←ˆxm) (1 −Φ(g(ˆxm)))
q(ˆxm ←xm) (1 −Φ(g(xm)))
▷Acceptance ratio.
26:
uloc ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
27:
if uloc < asgcp−loc then
▷Metropolis–Hastings acceptance rule.
28:
xm ←ˆxm, g(xm) ←g(ˆxm)
▷Update the thinned event location.
29:
end if
30:
end for
31:
GK,GM ∼HMC(GK, GM | S, M, θ)
▷Update function via Hamiltonian Monte Carlo.
32:
α ←α0 + |M| + K, β ←β0 + µ(V) ▷Posterior parameters for the dominating intensity.
33:
λ⋆∼GA(α, β)
▷Resample the dominating intensity.
34:
M(r) ←M, G(r)
K ←GK, G(r)
M ←GM
▷Store the current estimate of the latent history.
35:
λ(r)
⋆
←λ⋆
▷Store the current estimate of the dominating intensity.
36: end for
37: return {M(r), G(r)
N , G(r)
M , λ(r)
⋆}R
r=1

Latent History Inference Versus Exchange Sampling
77
then λ⋆can be resampled from a gamma distribution with parameters
αpost = α0 + K + M
(5.20)
βpost = β0 + µ(V).
(5.21)
Algorithm 5.2 shows in pseudocode the algorithm for a constant-rate dominating in-
tensity function. It also includes inference of the bounding intensity with a gamma
prior, as above.
5.4
Latent History Inference Versus Exchange Sampling
Having now examined the latent history method, how does it compare with the ex-
change sampling method of Chapter 4? Modeling of densities, whether PDFs or Pois-
son intensities, is fundamentally different from regression. In regression and classiﬁ-
cation, one conditions on having seen data in the input space when performing infer-
ence and prediction. In these cases, it is necessary only to model the function at places
where data have been observed, or at predictive query locations. In density modeling,
however, the places with low density are just as important to the model as those with
high density. Unfortunately, it is unlikely to have observed data in regions with low
density, so a representation of the function only at locations where there are data is not
adequate for the inference we wish to perform. One might think of deﬁning a density
as analogous to putting up a tent: pinning the canvas down with pegs (or stakes) is
just as important as putting up poles. In exchange sampling, the “pegs” are inferred
implicitly as rejections along the way to generating fantasy data. At each exchange
sampling step, a new tent is constructed — complete with its own pegs — and asked
to explain the data. In the latent history model, however, the tent is modiﬁed one piece
at a time: pegs and poles are inserted, removed, and adjusted gradually to explain the
data.
It is possible also to see that the latent history model is likely to require fewer sam-
ples from the Gaussian process as it proceeds. Consider the Gaussian process density
sampler: when the latent history method is at equilibrium, its state will have some
typical number of latent rejections M. This is about the same number of rejections as
would be expected to occur during an exchange sampling fantasy. However, to ﬁnd
the acceptance ratio in exchange sampling it is also necessary to evaluate against the
observed data after fantasising. This means that the Gaussian process in exchange
sampling requires at least 2N + M evaluations to make a Metropolis–Hastings move,
while the latent history method requires only N + M. This does not even consider the
expansion of state that occurs when exchange sampling rejects a proposal, and addi-
tional fantasy data are incorporated into the Markov state. As the time complexity of
computation in the Gaussian process grows cubically in the number of data, exchange

Inference in Poisson-Derived Interacting Point Processes
78
sampling can become rapidly more expensive.
Another reason that the latent history method is preferable to exchange sampling
is that it requires less bookkeeping about the function g(x).
The state of the ex-
change sampling Markov chain is the uncountably-inﬁnite object g(x).
The inno-
vation of the method is that through retrospective sampling we are able to make
Metropolis–Hastings moves with only a ﬁnite number of computations.
This ret-
rospective sampling, however, means that information discovered about a particu-
lar g(x) must be retained for as long as that function is relevant to the current Markov
state. In contrast, the state of the Markov chain when performing latent history infer-
ence only includes g(x) at the latent rejections or thinned events. That is, rather than
an uncountably-inﬁnite object g(x), the Gaussian process in the latent history model
conditions on a ﬁnite set of points in the input space. This means that the values of the
function do not need to be kept in memory, except for at the data and at the locations
of the rejections or thinned events. This contrast can also be seen in the difference be-
tween the joint distributions that I use to describe the two inference methods for the
Gaussian process density sampler. In exchange sampling, when writing Equation 4.20,
I use g to denote g(x) as an inﬁnite vector. When writing the posterior distribution on
the latent history, however, I do not need to denote an inﬁnite function. Equation 5.1
only deﬁnes a distribution on the function values at the data and the latent rejections.
Finally, while the latent history method enables efﬁcient Hamiltonian Monte Carlo
sampling of the latent function values, it is not clear how to combine HMC with ex-
change sampling. The underrelaxed proposal methods can be interpreted as a one-
step Hamiltonian simulation on the Gaussian process prior, but this effectively re-
moves the likelihood term from the gradient calculation. If there are enough data for
the posterior to be signiﬁcantly more peaked than the prior, then only small proposal
steps have a good probability of being accepted.
5.5
Inference in Poisson-Derived Interacting Point Processes
In Section 3.5, I discussed several ways to extend the Poisson process to construct point
processes with interaction. I showed that when these clustering or repulsive processes
are generative, the sigmoidal Gaussian Cox process provides a means to introduce
nonparametric inhomogeneity. In this section I look at how the latent history inference
method can be extended to two of these cases.
5.5.1
Inference in the Neyman–Scott Process
The Neyman–Scott process, discussed in Section 3.5.2, is a way to generate events
that tend to be closer to each other than would be expected from a Poisson process.

Inference in Poisson-Derived Interacting Point Processes
79
It consists of a mother Poisson process, whose realisations are not observed, but are
used to place localised independent daughter Poisson processes. I used the sigmoidal
Gaussian Cox process in place of a homogeneous Poisson mother process, to allow
for variation in the placement of the clusters. The data, as before, are K events in V,
denoted S = {xk}K
k=1. I am considering the daughter processes to have local intensity
functions λdtr(x ; xmtr) with compact support Q. The objective is to infer the inten-
sity of the mother process λmtr(x), on which I have placed an SGCP prior. It is also
desirable to know the number of mother points, which I will denote as J, and their
locations, which I denote as Smtr = {xmtr
j
}J
j=1. Due to the superposition property of
Poisson processes, conditioned on the mother points, the daughter points are from a
Poisson process with intensity λΣ(x), given by
λΣ(x) =
J
X
j=1
λdtr(x ; xmtr
j
).
(5.22)
I use the notation SGCP(S | V, θ, ψλ) to indicate an SGCP prior on a set of events S,
and write the joint distribution over the mother and daughter points as
p(Smtr, S | V, ψλ, θ, λdtr(·)) = SGCP(Smtr | V ⊕Q, θ, ψλ) PP(S | V, λΣ(x)).
(5.23)
By using the aggregated intensity function λΣ(x) that results from superposition, it is
possible to marginalise over the assignments of daughters to mothers. Conditioned
on the mother points Smtr, inference of the latent mother intensity is exactly as in
Section 5.3. Additional work must be done, however, to sample from the number and
location of the mother points themselves.
Sampling the Number of Mother Points
To sample the number J of mother points in Smtr, I deﬁne birth and death proposals
for the mother points on V ⊕Q. In its simplest form, the choice between proposing
to insert or delete a mother could be done via a Bernoulli coin ﬂip with probabil-
ity 1
2. When introducing a new mother point, condition on the latent function g(x),
the current mother points, and the set of thinned events currently in the history of the
sigmoidal Gaussian Cox process. Draw the location of the new mother, ˆxmtr uniformly
on the domain V ⊕Q, and draw the associated function values g(ˆxmtr) from the Gaus-
sian process, conditioning on everything currently known about g(x) in the sigmoidal
Gaussian Cox process. This proposal is similar to proposing a thinned event in the
SGCP, except in this case it is an unthinned (but unobserved) event. The Metropolis–
Hastings acceptance ratio of the proposed birth is then
ans−ins = µ(V ⊕Q) ¯λ(ˆxmtr ; ψλ) Φ(g(ˆxmtr))
(J + 1) exp

Λdtr
V (ˆxmtr)
	
K
Y
k=1
 
1 +
λdtr(xk ; ˆxmtr)
PJ
j=1 λdtr(xk ; xmtr
j
)
!
,
(5.24)

Inference in Poisson-Derived Interacting Point Processes
80
where
Λdtr
V (ˆxmtr) =
Z
V
dx λdtr(x ; ˆxmtr).
(5.25)
When proposing to remove a mother, I select one uniformly from among the J in Smtr.
The acceptance ratio of a proposal to remove the jth mother point is
ans−del =
J exp
n
Λdtr
V (xmtr
j
)
o
µ(V ⊕Q) ¯λ(xmtr
j
; ψλ) Φ(g(xmtr
j
))
×
K
Y
k=1
 
1 −
λdtr(xk ; xmtr
j
)
PJ
j′=1 λdtr(xk ; xmtr
j′ )
!
.
(5.26)
Even though the daughter intensities are modeled as being identical, except for their
locations, the exp{Λdtr
V (·)} terms are still necessary in these acceptance ratios because
mother points are allowed to be in the larger domain V ⊕Q. This is done to account for
edge effects. The aggregate intensity function λΣ(x), however, only models daughter
realisations in V, as that is how the likelihood is deﬁned. The data say nothing about
potential daughters outside of V. As not all of the support of a given daughter process
may be within V, it is important to account for this when sampling the mother point
conﬁguration.
Sampling the Mother Locations
Conditioned on the number of mothers J, we can also sample from the mother loca-
tions Smtr, given the rest of the history of the sigmoidal Gaussian Cox process. Iter-
ate over each mother, and draw a proposal to move the jth mother point from loca-
tion xmtr
j
to ˆxmtr
j
from a density q(ˆxmtr
j
←xmtr
j
), sampling the function value g(ˆxmtr
j
)
from the Gaussian process. The acceptance ratio of this proposal is
ans−loc =
q(xmtr
j
←ˆxmtr
j
) ¯λ(ˆxmtr
j
; ψλ) Φ(g(ˆxmtr
j
)) exp
n
Λdtr
V (xmtr
j
)
o
q(ˆxmtr
j
←xmtr
j
) ¯λ(xmtr
j
; ψλ) Φ(g(xmtr
j
)) exp

Λdtr
V (ˆxmtr
j
)
	
×
K
Y
k=1
λdtr(xk ; ˆxmtr
j
) + PJ
j′̸=j λdtr(xk ; xmtr
j′ )
PJ
j′=1 λdtr(xk ; xmtr
j′ )
.
(5.27)
The posterior distribution the latent history of the SGCP-derived Neyman–Scott pro-
cess does not depend on g(x) at any locations other than the latent thinned events and
the latent mother points. Therefore, as discussed in Section 5.4 for the Gaussian pro-
cess density sampler, if mother moves are accepted, then the old function values can
be discarded. Similarly, if the mother move is rejected, the proposed function value
does not need to be retained.

Inference in Poisson-Derived Interacting Point Processes
81
5.5.2
Inference in the Generalised Mat´ern Type III Process
Among the Mat´ern repulsive processes described in Section 3.5.2, the one capable of
the highest densities is the Type III variant. In that section, I also presented a softened
generalisation, which contains the original Mat´ern hard-core process as a special case.
I showed how the sigmoidal Gaussian Cox process could be used to make this process
inhomogeneous. This section provides an overview of how to extend latent history
inference in the SGCP to the generalised inhomogeneous Mat´ern Type III process.
I will assume a priori that all primary and secondary points are limited to V, as by
periodic boundary conditions. I will denote the repulsion kernel as ρ(x ↚x′).
The observations are K secondary points, which I denote S = {xk}K
k=1. These points
were the ones left after a possibly-larger set of primary points were thinned. I model
these primary points as having been drawn from a sigmoidal Gaussian Cox process.
The objective is to infer the latent function g(x) that gave rise to the intensity function
of the primary process. I model an additional J events that were not thinned by the
SGCP (becoming primary points), but were thinned by the repulsion kernel (so they
were not observed). I denote these thinned primary points as Sp\s = {xp\s
j
}J
j=1. I use
“p\s” to mean “in the primary set, excluding those in the secondary set.” As discussed
in Section 3.5.2, the original Mat´ern model uses timestamps to induce an ordering on
the primary events. Since the timestamps in the generative process are i.i.d., this is
equivalent to a uniform prior distribution over permutations of the K + J primary
events. I will represent this permutation directly in the model and denote it by Π,
rather than model the timestamps as done by Huber and Wolpert (2009). I deﬁne the
set PΠ(k) to be the indices of the events in the secondary set that, according to Π,
appear “earlier” than the member with index k. The set Pp\s
Π (j) is deﬁned in the same
way, but j indexes the thinned secondary points in Sp\s. More formally, I write these
as set functions:
PΠ(k) = {k′ : Π(xk′) < Π(xk), xk′ ∈S, xk ∈S}
(5.28)
Pp\s
Π (j) = {k : Π(xk) < Π(xp\s
j
), xk ∈S, xp\s
j
∈Sp\s}.
(5.29)
I deﬁne these two set functions so that it is easy to denote the events in S that had the
power to veto another point in S or in Sp\s, given the permutation Π. Having deﬁned
this set of latent variables, the joint distribution over the latent history — the observed
secondary points, the thinned primary points, and the ordering — is
p(S, Sp\s, Π, J, K | V, θ, ψλ) = SGCP(S ∪Sp\s | V, θ, ψλ)
1
(K + J)!
×


K
Y
k=1
Y
k′∈PΠ(k)
(1 −ρ(xk ↚xk′))


J
Y
j=1


1 −
Y
k∈Pp\s
Π (j)
(1 −ρ(xp\s
j
↚xk))


.
(5.30)

Inference in Poisson-Derived Interacting Point Processes
82
Given the set Sp\s, inference of the latent function and events thinned in the ﬁrst
(SGCP) stage is exactly as in Section 5.3. It is also necessary, however, to sample from
the number and location of the thinned primary events Sp\s, and the permutation Π.
Sampling the Number of Thinned Primary Events
We can make insertion or deletion proposals based on the outcome of a Bernoulli coin
ﬂip with probability 1
2. When inserting a new event into the set Sp\s, also propose
its location ˆxp\s uniformly from V. Draw a function value g(ˆxp\s) from the Gaussian
process, conditioning upon the rest of g(x) currently stored in the sigmoidal Gaussian
Cox process state. Also propose a location of the event in the ordering Π, selecting
uniformly from among the K + J + 1 possibilities. I use Pp\s
Π (⋆) to denote the set of
secondary events that would appear before the new proposed event. The Metropolis–
Hastings acceptance ratio of this new conﬁguration with an additional member of Sp\s
is
amat−ins = µ(V) (J + K + 1)
J + 1
¯λ(ˆxp\s ; ψλ) Φ(g(ˆxp\s))
×

1 −
Y
k∈Pp\s
Π (⋆)
(1 −ρ(ˆxp\s ↚xk))

.
(5.31)
When proposing a removal, choose uniformly from among the J members of Sp\s.
When removing the jth event, leave the ordering of the remaining events unchanged.
The MH acceptance ratio of the proposal to remove the jth member of Sp\s is
amat−del =
J
µ(V) (J + K)
¯λ(xp\s
j
; ψλ)−1 Φ(g(xp\s
j
))−1
×

1 −
Y
k∈Pp\s
Π (j)
(1 −ρ(xp\s
j
↚xk))


−1
.
(5.32)
Sampling the Locations of the Thinned Primary Events
Conditioned on the number of members in Sp\s and the permutation Π, we can sam-
ple from the locations of the Sp\s by iterating over each one and making a Metropolis–
Hastings move. Draw a proposal for a new location for the jth event by drawing
it from a density q(ˆxp\s
j
←xp\s
j
). Then draw an associated value for the latent func-
tion g(ˆxp\s
j
) from the Gaussian process, conditioning on the rest of the history. The

Inference in Poisson-Derived Interacting Point Processes
83
MH acceptance ratio of this proposal is
amat−loc =


q(xp\s
j
←ˆxp\s
j
) ¯λ(ˆxp\s
j
; ψλ) Φ(g(ˆxp\s
j
))

1 −
Y
k∈Pp\s
Π (j)
(1 −ρ(ˆxp\s
j
↚xk))





,

q(ˆxp\s
j
←xp\s
j
) ¯λ(xp\s
j
; ψλ) Φ(g(xp\s
j
))

1 −
Y
k∈Pp\s
Π (j)
(1 −ρ(xp\s
j
↚xk))




.
(5.33)
Here again, the latent history method allows the old values of the function to be dis-
carded after an acceptance.
Sampling the Ordering of Primary Events
It is necessary to propose changing the ordering Π of the primary events, in order to
sample from the posterior distribution on the latent history of the generalised Mat´ern
process. This can be done while conditioning on all of the rest of the state: the number
and locations of the thinned primary events Sp\s, the number and locations of the
events thinned during the sigmoidal Gaussian Cox process generation, and the latent
function g(x). I suggest simple local proposals that only swap two adjacent members
of the primary set. Choose uniformly and randomly from among the J + K −1 such
proposals. These proposals allow ergodic Markov chains on permutations, as it is
possible to eventually transition between any two orderings (Cormen et al., 2001). For
this inference task, these local swaps are appealing because they do not change the
ordering relationship of the pair with all of the other primary events. I will use the
symbol ◀to refer to the index of the “early” event in the pair and the symbol ▶to
denote the index of the “late” event in the pair. So, in the sequence of primary events,
there is a subsequence of size two — a pair of adjacent events — x◀immediately
followed by an event x▶. There are four possible cases, depending on the sets to
which these events belong.
Case 1: Both are Secondary Events
If both the early and late events are observed
and in the secondary set, i.e. x◀∈S and x▶∈S, then the MH acceptance ratio of
swapping their ordering is a comparison of their respective vetoes:
a1 = 1 −ρ(x◀↚x▶)
1 −ρ(x▶↚x◀).
(5.34)
Case 2: Neither is a Secondary Event
If neither is a secondary event, i.e. x◀∈Sp\s
and x▶∈Sp\s, then the joint probability of the latent history does not change when
the two events are swapped and a2 = 1.

Summary
84
Case 3: The Early Event is Secondary, the Late Event is Not
If the early event
is in the secondary set and the late event is not in the secondary set, i.e. x◀∈S
and x▶∈Sp\s, then the Metropolis–Hastings acceptance ratio of the swap is
a3 =
1 −Q
k∈PΠ(◀)(1 −ρ(xp\s
▶
↚xk))
1 −Q
k∈Pp\s
Π (▶)(1 −ρ(xp\s
▶
↚xk))
.
(5.35)
Case 4: The Late Event is Secondary, the Early Event is Not
This is the opposite
of the third case. The early event is not in the secondary set, but the late event is,
i.e. x◀∈Sp\s and x▶∈S. The MH ratio of exchanging their order is the inverse of a3
in Equation 5.35:
a4 =
1 −(1 −ρ(xp\s
▶
↚x◀)) Q
k∈Pp\s
Π (▶)(1 −ρ(xp\s
▶
↚xk))
1 −Q
k∈Pp\s
Π (▶)(1 −ρ(xp\s
▶
↚xk))
.
(5.36)
5.6
Summary
This chapter proposed a method of inference in the Gaussian process density sam-
pler and the sigmoidal Gaussian Cox process that models the latent history of their
respective generative procedures. Despite having doubly-intractable posterior distri-
butions, the availability of an exact generative procedure for data enables a latent vari-
able model that is tractable via Markov chain Monte Carlo. I also showed that this la-
tent history method could be applied to inhomogeneous variants of the Neyman–Scott
and generalised Mat´ern processes, when they are based on sigmoidal Gaussian Cox
processes. I will apply the latent history approach to data in Chapter 6 and show em-
pirically that it has superior properties to the exchange sampling approach of Chap-
ter 4. In Chapter 7, I will discuss additional topics related to latent history inference,
and in Chapter 8 I will infer the latent history of the Archipelago generative model for
semi-supervised learning.

Chapter 6
Application Examples
In this chapter, I apply to data the computational methods that I have developed in
this thesis. I look at several synthetic and real-world data sets. In Section 6.1, I study a
set of density modeling problems and compare the Gaussian process density sampler
to related methods. In Section 6.2, I apply the sigmoidal Gaussian Cox process to
several data sets and compare it to other methods.
6.1
Density Modeling Examples
In Chapter 2, I presented the Gaussian process density sampler as an alternative to
the logistic Gaussian process for nonparametric modeling of probability density func-
tions. In Chapter 4 and Chapter 5, I discussed two methods for performing inference
in the GPDS. In this section, I apply these methods and compare them empirically.
6.1.1
Bounded Univariate Density
I ﬁrst look at a simple case: data from an unknown univariate density with known
ﬁnite support. I study the same density on [0, 1] which was examined by Lenk (1991)
and Tokdar (2007) for the logistic Gaussian process:
flenk(x) ∝3
4 · 3 exp{−3x} + 1
4 ·
 π
32
−1
2 exp{−32(x −3
4)2}.
(6.1)
This density is a mixture of an exponential and a Gaussian on [0, 1] and data from it
are considered to be difﬁcult to model due to the Gaussian bump. I generated a set
of 50 independent data from this density. The data, and a histogram, are shown in
Figure 6.1a. The true density is shown in blue in Figure 6.1b.
I performed inference in the Gaussian process density sampler using the latent history
method, with a squared-exponential covariance function and a beta distribution for

Density Modeling Examples
86
(a) Observed data and histogram
(b) Probability density functions
(c) Histogram of the locations of rejections
(d) Histogram of the number of rejections
(e) Histogram of base density hyperparameters
(f) Histogram of GP hyperparameters
Figure 6.1: (a) The 50 observed data, and histogram. (b) The true density in blue, with
the Gaussian process density sampler estimate in green, and the logistic Gaussian pro-
cess estimate (with 150 knots) in red. (c) A histogram of the locations of rejections during
the latent history inference. (d) A histogram of the number of rejections in the latent his-
tory. (e) A histogram of the α and β parameters for the beta base density. (f) A histogram
of the length scale ℓand amplitude ω hyperparameters for the squared-exponential co-
variance function.

Density Modeling Examples
87
(a) Trace of Markov state on MCMC run
(b) Histogram of Markov state on MCMC run
Figure 6.2:
These ﬁgures compare the number of data kept in the Gaussian process
over the course of 30K MCMC samples. Both the exchange sampling and latent history
methods used identical data and hyperparameters. (a) A trace of the number of data
in the Markov state. For the latent history method this is the number of data plus the
number of latent rejections. For the exchange sampling method, this is the size of the
current conditioning set. (b) A histogram of the values in the trace.
the base density. I performed hyperparameter inference for both the base density
and the Gaussian process. I also applied the logistic Gaussian process to the data,
using the method of Tokdar (2007) with 100 uniformly-spaced knots, plus the 50 data.
Figure 6.1b shows the predictive distribution from both the GPDS and the LGP. The
Gaussian process density sampler does a better job of capturing the bump, but creates
an unwanted spike near x = 0, due to the shape of the beta base density.
Figure 6.1c is a histogram of the locations of the latent rejections inferred during the
Markov chain Monte Carlo inference of the Gaussian process density sampler latent
history, and Figure 6.1d is a histogram of the number of rejections. Figure 6.1e and
Figure 6.1f are histograms of the parameters of the beta base density and the GP hy-
perparameters, respectively.
In Section 5.4, I discussed in theoretical terms how one might expect exchange sam-
pling to compare to the latent history method for inference in the Gaussian process
density sampler. I argued that the number of data stored in the Markov state would
tend to be greater with exchange sampling. Speciﬁcally, I am concerned with the
number of unique locations at which any particular function in the Markov state
has been evaluated (sampled from the Gaussian process). In the exchange sampling
method, this is the size of the conditioning set. For the latent history inference, this
number is the sum of the number of data and the number of rejections.
In Fig-
ure 6.2a, I plot a trace over 30K Markov chain Monte Carlo transitions of the size
of the Gaussian process state for each method. Figure 6.2b shows the histograms
for these data. The exchange sampling algorithm was run using the underrelaxed

Density Modeling Examples
88
(a) True ring PDF
(b) Ring training and test data
(c) Ring predictive distribution
(d) Conditional predictive samples at x1 = 0
(e) Conditional predictive samples at x1 = 1.5
Figure 6.3: (a) The probability density function of the ring data, as given in Equation 6.2.
(b) The 100 training data are shown in blue and the 50 test data are shown in red. (c) The
predictive density from latent history inference with the Gaussian process density sam-
pler. (d) Predictive samples from x2, conditioned on x1 = 0. (e) Predictive samples
from x2, conditioned on x1 = 1.5. These two ﬁgures are vertical “slices” through the
predictive distribution in the middle of the ring and at the edge of the ring.
method with κ = 0.9 and a uniformly-spaced grid of 25 control points, plus the
data.
The latent history algorithm was run with ζ(M, N) =
1
2 and one insert or
delete proposal per MCMC step. In both cases, the hyperparameters for the base den-
sity and Gaussian process were ﬁxed and identical. Note that the plots reﬂect the
fact that the minimum number of data the exchange sampling algorithm can have is
125 = 50 data + 50 fantasies + 25 control points. In this example, even the worst-case
state of the latent history method was smaller than the best-case state of the exchange
sampling algorithm.
6.1.2
Bivariate Ring Density
I applied the Gaussian process density sampler and the latent history inference
method to data from a density with the shape of a ring:
fring(x) = 1
2π
Z π
−π
dχ N
 
x ; µ = 3
2
"
cos χ
sin χ
#
, σI2
!
,
(6.2)
for σ = 0.2. This density is shown in Figure 6.3a, and the 100 independent training
data are shown in Figure 6.3b. I generated an additional 50 test data to evaluate the
predictive log probability, and compared the GPDS to 1) a Parzen window method

Density Modeling Examples
89
(a) Macaca mulatta superior view
(b) Macaca mulatta inferior view
Figure 6.4: Ten linear distances between anatomical landmarks, superimposed on su-
perior and inferior views of a rhesus macaque (Macaca mulatta). The landmark names
are listed in Appendix B in Table B.1 (page 125).
with Gaussian kernels and bandwidth set via ten fold cross-validation on the log
likelihood (Rosenblatt, 1956; Parzen, 1962); 2) a Dirichlet process mixture of Gaus-
sians (Rasmussen, 2000; Neal, 2000); and 3) the Dirichlet diffusion tree method (Neal,
2003a). Radford Neal’s software for ﬂexible Bayesian modeling (FBM)1 was used to
evaluate the two Dirichlet methods. The GPDS predictive density is shown in Fig-
ure 6.3c and the numerical results appear in Table 6.1. The Bayesian methods, includ-
ing the Gaussian process density sampler, make signiﬁcantly better predictions than
the frequentist Parzen window method.
These ring data highlight a useful aspect of the Gaussian process density sampler con-
struction: it is convenient to draw from the conditional predictive distribution. If the D
dimensions of X are divided into two sets, xA and xB, so that we have x = [xA xB],
then one might wish to ﬁnd
p(xA | D, xB) =
Z
dg p(xA | g, xB) p(g | D).
(6.3)
This can be motivated by the supervised learning problem where the model has been
trained on the joint distribution over features and labels, and one wishes to make
1http://www.cs.toronto.edu/˜radford/fbm.software.html

Density Modeling Examples
90
GPDS
Parzen
DPMM
DFT
Ring
0.439
-2.253
-0.236
0.730
Macaque Trial 1
-15.285
-15.443
-15.267
-15.259
Macaque Trial 2
-15.044
-15.742
-15.176
-15.136
Macaque Trial 3
-14.863
-15.254
-15.077
-14.775
Table 6.1: This table shows the mean log probability of held-out test data for
each of the data sets and compared models. The compared models are the Gaus-
sian process density sampler (GPDS), the Parzen window method (Parzen), the
Dirichlet process mixture of Gaussians (DPMM) and the Dirichlet diffusion tree
(DFT).
predictions of the label given a previously-unseen set of features. Generating samples
from this distribution is exactly as in Section 4.5 and Section 5.2.6 — draw new fantasy
data after each MCMC step — with the difference being that the fantasy proposals are
drawn from π(xA | xB, ψπ) rather than π(x | ψπ). The histograms in Figure 6.3d and
Figure 6.3e are examples of the conditional predictive distribution, where the predic-
tions are “sliced” by conditioning on one dimension of the data.
6.1.3
Macaque Skull Data
I also studied the Gaussian process density sampler on a real-world task of skull re-
construction. I modeled the joint distribution of ten measurements of linear distances
between anatomical landmarks on 228 rhesus macaque (Macaca mulatta) skulls. These
linear distances were generated from three-dimensional coordinate data taken by a
single observer from dried skulls using a digitiser (Willmore et al., 2005).2 Linear
distances are commonly used in morphological studies as they are invariant under ro-
tation and translation of the objects being compared (Lele and Richtsmeier, 2001). Fig-
ure 6.4 shows superior and inferior views of a computed tomography (CT) scan recon-
struction of a macaque skull, along with the ten linear distances used. The anatomical
landmarks associated with each distance are given in Appendix B in Table B.1 (page
125). Each skull was measured three times in different trials, and these were modeled
separately. 200 randomly-selected skulls were used as a training set and 28 were used
as a test set. To be as fair as possible, the data were logarithmically transformed and
whitened as a preprocessing step, to have zero sample mean and spherical sample
covariance. The results are shown in Table 6.1. The tests indicate that the Gaussian
process density sampler is competitive with the other Bayesian methods, all of which
outperform the frequentist estimator.
2I thank Katherine Willmore, the Caribbean Primate Research Center, the University of Puerto Rico,
Medical Sciences Campus, Laboratory of Primate Morphology and Genetics, and the National Institutes
of Health (Grant RR03640 to CPRC) for contributing these data.

Poisson Process Examples
91
6.2
Poisson Process Examples
I applied the sigmoidal Gaussian Cox process and latent history inference to two types
of problems. I compared the SGCP to other equivalent methods on synthetic data, and
I applied the SGCP to two real-world data sets: one temporal and one spatial.
6.2.1
Univariate Synthetic Data
The objective of using synthetic data was to compare to other methods of estimating
Poisson intensity function, where the ground truth was known. I created three one-
dimensional data sets using the following intensity functions:
1. A sum of an exponential and a Gaussian bump:
λ1(t) = 2 exp{−t/15} + exp{−((t −25)/10)2},
(6.4)
on the interval [0, 50]. There are 53 training events.
2. A sinusoid with increasing frequency:
λ2(t) = 5 sin(t2)+6,
(6.5)
on [0, 5]. There are 29 training events.
3. λ3(t) is the piecewise linear function shown in Figure 6.5c, on the interval [0, 100].
There are 235 training events.
I compared the sigmoidal Gaussian Cox process to the classical kernel smoothing (KS)
approach of Diggle (1985). I performed edge-corrected kernel smoothing using a quar-
tic kernel and the recommended mean-square minimisation technique for bandwidth
selection. I also compared to the most closely-related nonparametric Bayesian tech-
nique, the log Gaussian Cox process of Rathbun and Cressie (1994) and Møller et al.
(1998). To implement this method, I used discretisation to make a ﬁnite-dimensional
approximation and applied Markov chain Monte Carlo. I ran the log Gaussian Cox
process method with 10 bins (LGCP10), 25 bins (LGCP25) and 100 bins (LGCP100).
I used the squared-exponential kernel for both the SGCP and the LGCP, and sampled
from the hyperparameters for both models.
I report the numerically-estimated L2 distance between the mean λ(t) provided by
each method and the known true function. I also report the mean log predictive prob-
ability of ten additional held-out time series generated from the same (known) λ(t).
These predictive probabilities were calculated by numerical integrations of the func-
tions. These results are provided in Table 6.2, and the resulting estimates (excluding

Poisson Process Examples
92
(a) Synthetic data from λ1(t), with intensity estimates
(b) Synthetic data from λ2(t), with intensity estimates
(c) Synthetic data from λ3(t), with intensity estimates
Figure 6.5: These ﬁgures show the three sets of synthetic Poisson data from known in-
tensities, along with the predictive estimates for the sigmoidal Gaussian Cox process
(SGCP), the frequentist kernel smoothing method (KS), and the log Gaussian Cox pro-
cess with 100 bins (LGCP100).

Poisson Process Examples
93
(a) Coal mine disaster data and intensity estimate
(b) Histogram of dominating intensity λ⋆
(c) Histogram of number of thinned events
Figure 6.6: (a) The coal mine disaster data, estimated intensity and quartile error bars.
(b) A histogram of the values of the dominating intensity λ⋆throughout the MCMC run.
(c) A histogram of the number of thinned events modeled by the latent history.
LGCP10 and LGCP25) are shown in Figure 6.5. For these evaluations, the sigmoidal
Gaussian Cox process appears to outperform the competing methods.
6.2.2
Coal Mine Disaster Data
I ran the Markov chain Monte Carlo inference procedure on the classic coal mine dis-
aster data of Jarrett (1979). These data are the dates of 191 coal mine explosions that
killed ten or more men in Britain between 15 March 1851 and 22 March 1962. Fig-
ure 6.6a shows the events along the top, and the inferred mean intensity function.
Also shown are approximate quartile error bars. In Figure 6.6b is a histogram of the
inferred upper bounding intensity, λ⋆. Figure 6.6c is a histogram of the number of
latent thinned events, M.
6.2.3
Redwoods Data
I used a standard data set from spatial statistics to demonstrate the sigmoidal Gaussian
Cox process in two dimensions. These data are the locations of redwood trees studied
by Ripley (1977) and others. There are 195 points and, as in previous studies, they

Summary
94
SGCP
KS
LGCP10
LGCP25
LGCP100
λ1(s)
ℓ2
4.20
6.65
5.96
6.12
5.44
lp
-45.11
-46.41
-46.00
-46.80
-45.24
λ2(s)
ℓ2
38.38
73.71
70.34
53.27
43.51
lp
24.45
28.19
23.36
22.89
25.29
λ3(s)
ℓ2
11.41
30.56
90.76
22.14
10.79
lp
-43.39
-46.47
-53.67
-52.31
-47.16
Table 6.2: This table shows the results of empirical comparison of the sigmoidal
Gaussian Cox process (SGCP) versus the frequentist kernel smoothing method
(KS), the the log Gaussian Cox process with various levels of discretisation (10
bins: LGCP10, 25 bins: LGCP25, 100 bins: LGCP100).
(a) Redwood data and intensity estimate
(b) Histogram of locations of thinned events
Figure 6.7: (a) The redwood data, scaled to the unit square, and the estimated intensity.
(b) A histogram of the locations of thinned events inferred during the MCMC run.
have been scaled to the unit square. Figure 6.7a shows the data along with the inferred
mean intensity function. These data are useful for examining the placement of latent
thinned events. Figure 6.7b shows a histogram of where the these events tended to be
located during the MCMC run. As expected, it is approximately a “negative” of the
mean intensity; the thinned events are moving to places where it is necessary to “peg
down” the intensity function.
6.3
Summary
In this chapter, I applied the inference methods of Chapter 4 and Chapter 5 to the
Gaussian process density sampler and the sigmoidal Gaussian Cox process. For both
models, I performed inference on both synthetic and real-world data and found my
proposed approaches to be competitive with existing methods.

Chapter 7
Model Extensions
This chapter presents some extensions to the Gaussian process density sampler and
the sigmoidal Gaussian Cox process. Section 7.1 discusses how to make Monte Carlo
estimates of the normalised predictive density for the GPDS. Section 7.2 deals with
avoidance of computational bottlenecks when performing inference in the Gaussian
process density sampler. Finally, Section 7.3 considers how to improve the perfor-
mance of latent history inference in the sigmoidal Gaussian Cox process.
7.1
Estimation of Normalised Predictive Probabilities
As discussed in Section 4.5 and Section 5.2.6, both exchange sampling and the latent
history inference methods can yield predictive samples from the Gaussian process
density sampler. It is also natural, however, to require that a density model provide
an estimate of the value of the normalised predictive density. It is possible to use the
Rao-Blackwellisation method of Chib and Jeliazkov (2001) to perform this estimation.
The desired quantity in this case is
p(x | D) =
Z
dg
Z
dθ
Z
dψπ p(x | g, θ, ψπ) p(g, θ, ψπ | D),
(7.1)
which integrates out the posterior on parameters to ﬁnd the predictive distribution
at x after seeing data D. Consider making a Metropolis–Hastings transition from x
to x′ on the distribution p(x | g, θ, ψπ) p(g, θ, ψπ | D) that appears inside the integral.
Metropolis–Hastings satisﬁes detailed balance, giving the identity
p(x | g, θ, ψπ) p(g, θ, ψπ | D) T(x′ ←x) = p(x′ | g, θ, ψπ) p(g, θ, ψπ | D) T(x ←x′).
(7.2)

Estimation of Normalised Predictive Probabilities
96
Using π(x′ | ψπ) as the proposal distribution, the transition operator is
T(x′ ←x) = π(x′ | ψπ) min

1, p(x′ | g, θ, ψπ) p(g, θ, ψπ | D) π(x | ψπ)
p(x | g, θ, ψπ) p(g, θ, ψπ | D) π(x′ | ψπ)

.
(7.3)
Conditioned on the latent function and hyperparameters, the generative procedure of
Section 2.2 provides a distribution over data space:
p(x | g, θ, ψπ) = π(x | ψπ) Φ(g(x)).
(7.4)
Using Equation 7.3 and Equation 7.4, the identity of Equation 7.2 can now be rewritten
as
p(x, g, θ, ψπ | D) π(x′ | ψπ) min

1, Φ(g(x′))
Φ(g(x))

=
p(x′, g, θ, ψπ | D) π(x | ψπ) min

1, Φ(g(x))
Φ(g(x′))

.
(7.5)
Integrate both sides of this identity over x′, g, θ, and ψπ, giving
Z
dθ
Z
dψπ
Z
dg
Z
dx′ p(x, g, θ, ψπ | D) π(x′ | ψπ) min

1, Φ(g(x′))
Φ(g(x))

=
Z
dθ
Z
dψπ
Z
dg
Z
dx′ p(x′, g, θ, ψπ | D) π(x | ψπ) min

1, Φ(g(x))
Φ(g(x′))

.
(7.6)
Now observe that
p(x, g, θ, ψπ | D) = p(x | D) p(g, θ, ψπ | x, D),
(7.7)
and so the predictive density can be found via
p(x | D) =
Z
dθ
Z
dψπ
Z
dg
Z
dx′ p(θ, ψπ, g, x′ | D) π(x | ψπ) min

1, Φ(g(x))
Φ(g(x′))

Z
dθ
Z
dψπ
Z
dg p(θ, ψπ, g | x, D)
Z
dx′ π(x′ | ψπ) min

1, Φ(g(x′))
Φ(g(x))
.
(7.8)
Both the numerator and the denominator in Equation 7.8 are expectations. The top is
an expectation under the posterior and the bottom is an expectation under the poste-
rior where the data have been augmented with x:
p(x | D) =
Ep(g,θ,ψπ,x′|D)

π(x | ψπ) min

1, Φ(g(x))
Φ(g(x′))

Ep(g,θ,ψπ|D,x)

Eπ(x′ | ψπ)

min

1, Φ(g(x′))
Φ(g(x))
.
(7.9)
The numerator can be estimated directly as part of the Markov chain Monte Carlo
inference. After each Markov step, generate a predictive sample x′ and record the

Improving Performance of Inference in the GPDS
97
(a) Probability density function
(b) Latent functions that lead to the same PDF
Figure 7.1: A demonstration of redundancy in the map between realisations from the
Gaussian process prior and probability density functions. The base density is a standard
normal. (a) A probability density function. (b) Three Φ-squashed functions that all
result in the probability density function shown in (a).
transition probabilities. The denominator requires a Markov chain to be run with a
data set augmented by the predictive location x. At each step in the Markov chain,
a sample x′ is generated from the base density and the transition probabilities are
evaluated.
7.2
Improving Performance of Inference in the GPDS
The major bottleneck for inference in the Gaussian process density sampler is the cubic
time complexity of the linear algebraic computations necessary for the Gaussian pro-
cess. While the number of data are ﬁxed, the latent history algorithm samples from
the posterior distribution on the number of latent rejections. These latent rejections
contribute to the cubic scaling, and one way to improve performance of the inference
in the GPDS would be to limit the posterior probability assigned to latent histories
with many rejections. It would be preferable to do this without compromising the
correctness of the inference algorithm or requiring a ﬁnite-dimensional approxima-
tion. To this end, it is signiﬁcant to note that multiple latent functions g(x), when
pushed through the transformation of Equation 2.1, lead to the same density f(x).
Figure 7.1 provides an example of several latent functions yielding the same density.
Figure 7.1b shows three Φ-squashed functions, and Figure 7.1a shows the probability
density function to which they all lead.
Consider the result of applying Algorithm 2.2 to the red function in Figure 7.1b.

Improving Performance of Inference in the SGCP
98
Roughly, the red line hovers around 0.1, which means that nine out of ten proposals
will be rejected when generating data. If we had data from the density in Figure 7.1a,
then when performing latent history inference we would sometimes consider the hy-
pothesis of the red line, as its likelihood is the same as that of the blue and green lines.
However, latent history inference would require about nine times as many rejections
as data in order to explain the red line. This many rejections would combine with the
cubic computational complexity of the Gaussian process to make inference expensive.
We would prefer a stronger prior than the vanilla Gaussian process, in order to remove
this kind of redundancy and instead cause the model to choose functions like the blue
and green line over the red line.
One way to achieve this is to use a tied Gaussian process prior. In the tied GP, I add a
new “hyperparameter” to the Gaussian process that is the location of a point at which
the function g(x) is forced to be zero. That is, I introduce a hyperparameter xtied
and require that g(xtied) = 0. I use π(x) as the prior on xtied, and include it in the
Markov chain Monte Carlo inference. This additional constraint does not seriously
compromise the Gaussian process prior, but helps prevent functions such as the red
one in Figure 7.1b from appearing during inference. Note that in Figure 7.1b, with a
tied Gaussian process, both the blue and green lines are still good hypotheses, as their
latent functions both include an x where g(x) = 0, i.e. where Φ(g(x)) = 1
2.
7.3
Improving Performance of Inference in the SGCP
Modeling a large number of latent thinned events in the sigmoidal Gaussian Cox pro-
cess presents similar difﬁculties to the latent rejections in the Gaussian process density
sampler. However, latent thinned events in the SGCP are not due to redundancy in the
function mapping, but to the dominating intensity ¯λ(x). If ¯λ(x) is a very loose bound
on the true intensity λ(x), then the latent history method will require many thinned
events to explain the data. As with the latent rejections, cubic time complexity of
computations in the Gaussian process make undesirable the inclusion of superﬂuous
latent thinned events. Preventing very loose ¯λ(x) is a question of choice of hyperpa-
rameters ψλ. For the simple case of a constant dominating intensity λ⋆, a weak gamma
prior may not be enough to prevent the occasional departure into loose-bound terri-
tory. In such cases, it may be desirable to use a truncated gamma prior that only offers
support for λ⋆up to some limit. This has the practical effect of placing a soft upper-
bound on the number of latent thinned events that the latent history method could be
required to model.

Summary
99
7.4
Summary
This chapter examined a few peripheral topics related to inference in the Gaussian pro-
cess density sampler and the sigmoidal Gaussian Cox process. I presented a method
for estimating the value of the normalised density under the GPDS. I also discussed
ways to prevent the GPDS and SGCP models from incorporating large quantities of
latent data.

Chapter 8
Archipelago: Nonparametric
Bayesian Semi-Supervised Learning
This chapter presents a nonparametric Bayesian method for solving the problem of
semi-supervised learning. I extend the Gaussian process density sampler of Chapter 2 to
model multiple, coupled densities in a classiﬁer and call this new model Archipelago.
I extend the latent history inference method of Chapter 5 for this new approach and
apply it to both synthetic and real-world data.
8.1
The Semi-Supervised Learning Problem
Semi-supervised learning (SSL) algorithms solve the problem of classiﬁcation under
the circumstance that only a subset of the training data is labeled. In contrast to the
purely-supervised setting, semi-supervised learning assumes that the probability den-
sity of the data is important to discovering the decision boundary. Semi-supervised
learning is motivated by the situation where copious training data are available, but
hand-labeling the data is expensive.
From a Bayesian perspective, the natural way to perform semi-supervised learning
is with a generative model of the data. We explicitly model the densities that gave
rise to the observations, integrating over the class assignments for unlabeled data. We
can then integrate over any parameters of the density model and arrive at predictive
classiﬁcations of unseen data.
We would like to perform this kind of modeling while making the fewest possible
assumptions about the densities in question. Nonparametric Bayesian methods are
appealing in this regard, as they incorporate an inﬁnite number of parameters into the
model. This prevents us from having to make difﬁcult choices about dimensionality.
Unfortunately, the nature of many nonparametric Bayesian density models makes

The Archipelago Model
101
them ill-suited for the semi-supervised setting. Speciﬁcally, the main assumption in
SSL is that data of the same class will cluster together; the labeled data provide the
appropriate class and the unlabeled data determine the cluster boundary. The most
common nonparametric Bayesian density model, the Dirichlet process mixture model
(DPMM) (Escobar and West, 1995; Rasmussen, 2000), suffers from the problem that
the mixture components are located independently. There is no tendency for mix-
ture models to form contiguous densities. If we take the natural approach of using
a DPMM to ﬂexibly model each class density in a semi-supervised learning problem,
the mixtures will grab unlabeled data away from other classes.
Due to these difﬁculties with specifying a ﬂexible density model, discriminative meth-
ods are more common than generative models for semi-supervised learning.
The
Bayesian discriminative model of Lawrence and Jordan (2005) takes advantage of the
Gaussian process to construct a nonparametric model for binary SSL. Similarly, Chu
et al. (2007) and Sindhwani et al. (2007) also specify nonparametric Bayesian discrim-
inative models with Gaussian processes that exploit graph-based side information.
In this chapter, I extend the Gaussian process density sampler model of Chapter 2 to
address the semi-supervised learning problem. This results in a fully-Bayesian gen-
erative approach to semi-supervised learning that uses Gaussian processes to specify
the prior on class densities. I call the model Archipelago as it performs Bayesian clus-
tering with inﬁnite-dimensional density models, but it prefers contiguous densities.
These clusters can form irregular shapes, like islands in a chain.
8.2
The Archipelago Model
As in previous chapters, I consider a model for data that live in a space X. There
are K possible discrete labels for these data. I condition on K, under the assump-
tion that, when performing inference, at least one of each class has been observed.
Let x be a point in X. I deﬁne K scalar functions (one for each class) {gk(x)}K
k=1,
where gk(·) : X →R. Conditioned on a point x, these functions are used with a soft-
max function to construct a categorical distribution for c ∈1, 2, . . . , K, the class label
of x:
p(c | x, {gk(x)}K
k=1) = exp{gc(x)}
Ω(x)
,
(8.1)
where I use Ω(x) = PK
k=1 exp{gk(x)} for notational convenience. I combine this dis-
criminative classiﬁer with a density model for x that is also constructed from the gk(x):
p(x | {gk(x)}K
k=1) =
1
Zπ[Ω]
Ω(x) π(x)
1 + Ω(x)
(8.2)

Generating Data from the Prior
102
where π(x) is the base density as in the Gaussian process density sampler. The con-
stant Zπ[Ω] is the normalisation given by
Zπ[Ω] =
Z
X
dx Ω(x) π(x)
1 + Ω(x) .
(8.3)
Multiplying Equation 8.1 by Equation 8.2 constructs a joint distribution for the location
and label together, given the functions {gk(x)}K
k=1:
p(x, c | {gk(x)}K
k=1) =
1
Zπ[Ω]
exp{gc(x)} π(x)
1 + Ω(x)
.
(8.4)
From the point of view of the semi-supervised learning problem, this construction is
appealing because Equation 8.2 can be viewed as marginalising out the class label in
Equation 8.4. This formulation is in contrast to typical Bayesian generative methods
for SSL which would construct p(x, c) from p(x | c) p(c). While it is easy to marginalise
out the class label c in p(c | x) p(x), it is not necessarily so easy for p(x | c) p(c). The
result of the Archipelago construction is a set of K coupled densities which are each
intractable individually, but whose sum is tractable.
Introducing K independent Gaussian process priors on the functions {gk(x)}K
k=1
makes the model nonparametric. As in the Gaussian process density sampler, there
may also be Gaussian process hyperparameters θ governing the covariance function,
and base density hyperparameters ψπ.
8.3
Generating Data from the Prior
The signiﬁcance of coupling the likelihood of Equation 8.4 with Gaussian process pri-
ors on the {gk(x)}K
k=1 is that it is possible to deﬁne a fully-generative process for ar-
riving at labeled data from a set of K random coupled densities. In other words, it is
possible to deﬁne a process that is equivalent to drawing a set of data from the den-
sity in Equation 8.2 with a random Ω(x) arising from the Gaussian process priors on
the {gk(x)}K
k=1, and then labeling that data according to Equation 8.1.
To generate a labeled datum, ﬁrst draw a proposal ˜x from the base density π(x). Then
draw a function value from each of the Gaussian processes at at the point ˜x. I denote
these function draws as {gk(˜x)}K
k=1. Use the function values to partition the unit in-
terval [0, 1] into K +1 non-overlapping segments with boundaries 0, ξ1, ξ2, . . . , ξK, 1
where
ξk = ξk−1 + exp{gk(˜x)}
1 + Ω(˜x)
(8.5)
and ξ0 = 0. Draw a uniform random variate u on (0, 1) and either assign the datum the
label k if it falls into the kth partition, i.e. ξk−1 < u < ξk, or reject the proposal if it is in

Generating Data from the Prior
103
(a)
(b)
(c)
(d)
π(x)
{u}
{˜x}
g3(x)
g2(x)
g1(x)
Figure 8.1: The generative process for Archipelago in one dimension. (a) Proposals
are drawn from the base density π(x), which here is a Gaussian with zero mean and
unit variance. (b) Next, each of the K = 3 functions is sampled from the Gaussian
process at the proposal locations. (c) The functions are used to partition the unit interval
into K + 1 slices at each proposal location and uniform variates u are drawn in the
vertical coordinate. (d) If u falls into the topmost partition, the proposal is rejected.
Otherwise, it is accepted and assigned the class label based on the partition in to which u
falls.
the topmost partition, i.e. u ≥ξK. If the ˜x is rejected, make another proposal and con-
tinue until an acceptance. When making these new proposals, sample conditionally
from the Gaussian process, incorporating the function draws from previous proposals.
As in the Gaussian process density sampler, I refer to these as the K conditioning sets,
with inputs Xk and outputs Gk. Continue this rejection/acceptance process, generat-
ing as many data as necessary, “discovering” the set of functions {gk(x)}K
k=1 during
the iterations. This procedure is shown as pseudocode in Algorithm 8.1 and graphi-
cally in Figure 8.1.
This generative procedure is inﬁnitely exchangeable and the data are exact, just
as in the Gaussian process density sampler.
It is also not necessary to determine
the {gk(x)}K
k=1 over any more than a ﬁnite number of points in X, nor is it necessary
to determine the normalisation constant Zπ[Ω] in order to generate these data.

Latent History Inference in Archipelago
104
Algorithm 8.1
Generate N labeled data from the Archipelago model
Inputs:
• Number of samples to draw N
• Gaussian process covariance function C(x, x′ ; θ)
• Gaussian process hyperparameters {θk}K
k=1
• Base density π(x | ψπ)
Outputs:
• N labeled data D = {xn, cn}N
n=1 from a density drawn from the prior.
1: for k ←1 . . . K do
2:
Xk ←∅, Gk ←∅
▷Initialise K empty conditioning sets.
3: end for
4: D ←∅
▷Initialise the set to be returned.
5: repeat
▷Run the rejection sampler.
6:
˜x ∼π(x | ψπ)
▷Draw a proposal from the base density.
7:
Ω(˜x) ←0
▷Initialise the sum of functions.
8:
for k ←1 . . . K do
▷Loop over the K functions.
9:
gk(˜x) ∼GP(g | ˜x, Xk, Gk, θk)
▷Draw the function from the GP.
10:
Ω(˜x) ←Ω(˜x) + exp{gk(˜x)}
▷Update the total.
11:
Xk ←Xk ∪˜x, Gk ←Gk ∪gk(˜x)
▷Update the conditioning sets.
12:
end for
13:
u ∼U(0, 1)
▷Draw a uniform variate on (0, 1).
14:
ξ0 ←0
▷Initialise the partitions.
15:
for k ←1 . . . K do
▷Loop over the partitions.
16:
ξk ←ξk−1 + exp{gk(˜x)}
1 + Ω(˜x)
▷Calculate the next partition.
17:
if u < ξk then
▷Test if the variate falls into this partition.
18:
D ←D ∪{˜x, k}
▷Accept this proposal and store the label.
19:
break
▷Break out of the loop.
20:
end if
21:
end for
22: until |D| = N
▷Loop until N proposals are accepted.
23: return D
8.4
Latent History Inference in Archipelago
I have so far described a nonparametric generative model for labeled data. I now
show how this model can be used to perform semi-supervised learning. The semi-
supervised inference task in Archipelago is to ﬁnd the predictive distribution over the
class label of some unlabeled datum x⋆, given N labeled data {xn, cn}N
n=1 and J unla-
beled data {xj}J
j=1, marginalising out the unknown latent functions {gk(x)}K
k=1. This
is the inductive interpretation of semi-supervised learning: x⋆is not known in advance
and is not included in the unlabeled data for inference. I mention this to contrast
Archipelago with the more restricted class of transductive models, which attempt to
ﬁnd the correct class labels for the J unlabeled examples. If, as in previous chapters,
I treat the function gk(x) as an inﬁnite vector gk, then the objective is to integrate out
these K vectors:
p(c⋆| x⋆, {xn, cn}N
n=1, {xj}J
j=1, {θk}K
k=1) =
Z
dg1 · · ·
Z
dgK p(c⋆| x⋆, {gk}K
k=1) p({gk}K
k=1 | {xn, cn}N
n=1, {xj}J
j=1, {θk}K
k=1)
(8.6)

Latent History Inference in Archipelago
105
where the posterior distribution on {gk}K
k=1 arises from Equation 8.2 and Equation 8.4
along with the Gaussian process priors and is proportional to
p({gk}K
k=1, {xn, cn}N
n=1, {xj}J
j=1 | {θk}K
k=1) =
Zπ[Ω]−N−J
K
Y
k=1
GP(gk | {xn}N
n=1, {xj}J
j=1, θk)
×
N
Y
n=1
exp{gcn(xn)} π(xn)
1 + Ω(xn)
J
Y
j=1
Ω(xj) π(xj)
1 + Ω(xj) .
(8.7)
Given a set of samples of {gk(x⋆)}K
k=1, one can estimate the distribution in Equation 8.6
via a sum, but acquiring samples from the posterior on the gk is difﬁcult because
it is doubly-intractable. As in Chapter 5 for the Gaussian process density sampler
and the sigmoidal Gaussian Cox process, I construct a Markov chain Monte Carlo in-
ference algorithm on the latent history of the generative process. The unknowns in
this case are 1) the number of latent rejections M; 2) the locations of the latent rejec-
tions M = {xm}M
m=1; and 3) the values of the functions at the rejections, at the labeled
data and at the unlabeled data. The true labels of the unlabeled data are also unknown,
but these quantities are easily marginalised over. As it is possible to run the genera-
tive algorithm without calculating Zπ[Ω] and without knowing the functions gk(x)
everywhere, it will be possible to construct a latent history model that inherits these
properties for inference.
Integrating out the classes of the unlabeled data, as in Equation 8.2, the joint distribu-
tion over the function values, the number and location of the latent rejections, and the
ﬁxed data is
p({gk}K
k=1, {xm}M
m=1, {xj}J
j=1, {xn, cn}N
n=1 | {θk}K
k=1, ψπ) =
K
Y
k=1
GP({gk(xn)}N
n=1, {gk(xj)}J
j=1, {gk(xm)}M
m=1 | {xm}M
m=1, {xj}J
j=1, {xn}N
n=1, θk)
×
N
Y
n=1
exp{gcn(xn)} π(xn | ψπ)
1 + Ω(xn)
J
Y
j=1
Ω(xj) π(xj | ψπ)
1 + Ω(xj)
M
Y
m=1
π(xm | ψπ)
1 + Ω(xm) .
(8.8)
The joint distribution in Equation 8.8 is proportional to the posterior distribution over
the latent history, and I sample from it with three kinds of Markov transitions: updat-
ing the number of latent rejections, updating the rejection locations, and updating the
function values. This is very similar to the latent history Markov chain Monte Carlo
discussed in Chapter 5 for the GPDS and SGCP.

Latent History Inference in Archipelago
106
1
2
7
M = {xm}M
m=1
D = {xn, cn}N
n=1
4
6
8
3
5
9
10
(a) Initial state of the latent history
1
2
7
4
6
8
3
5
9
10
(b) Propose additional rejections after last acceptance
1
2
7
4
6
8
3
5
9
10
(c) Propose moving the new rejections into the history
1
7
6
8
5
9
10
4
3
2
(d) New state of the latent history, if accepted
Figure 8.2: Inserting new latent rejections into the Archipelago latent history. (a) There
are six latent rejections and ten labeled data, with K = 3, represented as blue circles,
magenta diamonds and green triangles. The rejections are in red. (b) Two new rejections
are proposed after the last labeled datum. (c) It is proposed to move the two rejections
into randomly-selected times in the history. (d) If accepted, there is a new history with
eight latent rejections.
8.4.1
Sampling the Number of Latent Rejections
I take advantage of the inﬁnite exchangeability of the generative process to construct
a Metropolis–Hastings move that can add or remove rejections from the latent history.
The model for inference is that the data came about as the result of Algorithm 8.1,
stopping when there were N + J data accepted. The unlabeled data were generated
by the J labels being discarded, and the joint distribution in Equation 8.8 integrates
out the unknown label. Due to inﬁnite exchangeability, a reordering of the latent his-
tory can be proposed at any time and this move will always be accepted. Thus to in-
sert a new latent rejection, propose moving a rejection that occurred after the N +Jth
acceptance to be moved to sometime before it. This idea is shown graphically in Fig-
ure 8.2. To delete a rejection, make the opposite type of transition: select one of the
current rejections at random and propose moving it to after the N +Jth acceptance.
As in the Gaussian process density sampler it is not necessary in practice to actually
maintain an ordering. Use the function ζ(M, N + J), introduced in Section 5.2.1, as
the Bernoulli probability of making an insertion proposal versus a deletion proposal.
When deciding to add an additional rejection, ﬁrst propose a new location for it in X,
denoted ˆx, by drawing it from π(x | ψπ). Then draw each of the K function values at
that location, {gk(ˆx)}K
k=1, conditioning on all of the current function values. Finally,

Latent History Inference in Archipelago
107
accept or reject with Metropolis–Hastings acceptance ratio
aarch−ins = (1 −ζ(M + 1, N + J)) (M + N + J)
ζ(M, N + J) (M + 1) (1 + Ω(ˆx))
.
(8.9)
If proposing a deletion, choose an index m uniformly from among the M rejections
and remove the mth rejection with Metropolis–Hastings acceptance ratio
aarch−del =
ζ(M −1, N + J) M (1 + Ω(xm))
(1 −ζ(M, N + J)) (M + N + J −1).
(8.10)
As in Chapter 5, in practice it is often reasonable to simply set ζ(M, N + J) = 1
2. More
sophisticated proposals may yield improvements in mixing, but this is a topic for fu-
ture study. Typically, I make several of these transitions (≈10) for each of the transi-
tions in Section 8.4.2 and Section 8.4.3.
8.4.2
Sampling the Locations of Latent Rejections
Conditioned on the current function values and the number of rejections M, it is also
necessary to update the locations of the rejections. Iterate over each of the M rejections
and make a Metropolis–Hastings proposal with two stages. For the mth rejection, ﬁrst
draw a new location ˆxm from a proposal density q(ˆxm ←xm). Second, draw a new set
of K function values from the Gaussian process at this location, conditioning on the
rest of the latent history, yielding {gk(ˆxm)}K
k=1. Accept or reject the proposal according
to the acceptance ratio
am = q(xm ←ˆxm) π(ˆxm | ψπ) (1 + Ω(xm))
q(ˆxm ←xm) π(xm | ψπ) (1 + Ω(ˆxm)).
(8.11)
8.4.3
Sampling the Latent Functions
To sample from the latent functions, iterate over each of the K functions and use
Hamiltonian Monte Carlo (Neal, 1997) for efﬁcient sampling, as in Section 5.2.3. For
the kth function, the log conditional posterior distribution is
ln p({gk(xn)}N
n=1, {gk(xj)}J
j=1, {gk(xm)}M
m=1 | {xm}M
m=1, {xn, cn}N
n=1, {xj}J
j=1, θk) =
ln GP({gk(xn)}N
n=1, {gk(xj)}J
j=1, {gk(xm)}M
m=1 | {xm}M
m=1, {xn}N
n=1, {xj}J
j=1, θk)
+
N
X
n=1
[δ(cn, k) gk(xn) −ln(1 + Ω(xn))]+
J
X
j=1
ln
Ω(xj)
1 + Ω(xj) −
M
X
m=1
ln(1+Ω(xm))+const,
(8.12)
where δ(·, ·) is the Kronecker delta function.

Empirical Results
108
8.4.4
Sampling the Hyperparameters
An appealing feature of Bayesian inference methods is the ability to perform hierarchi-
cal inference. In this case, it is desirable to sample from the hyperparameters, {θk}K
k=1,
governing the Gaussian process covariance functions. Conditioned on the number
and locations of the rejections, and on the function values, this is done as described
in Section 5.2.4. Sampling from the base density hyperparameters is performed as in
Section 5.2.5.
8.4.5
Making Predictions
With samples from the posterior distribution over the function values, the integral in
Equation 8.6 can now be approximated. At each Markov chain Monte Carlo transi-
tion after burn-in, sample the function values {gk(x⋆)}K
k=1 from the Gaussian process,
conditioned on the current state of the history. From these values, the predictive dis-
tribution can be approximated via a mixture of categorical distributions arising from
the softmax functions.
We might also be interested in the class-conditional predictive distributions. These K
distributions are the ones that arise on data space, conditioning on membership in
class k, but integrating out the latent function and hyperparameters. While not avail-
able in closed form, it is straightforward to generate predictive fantasies. At each
MCMC step after burn-in, run the generative process forward from the current state
until a datum is accepted that is a member of class k.
8.5
Empirical Results
I now compare the Archipelago model and inference method to three other multi-
class Gaussian process classiﬁcation approaches: the standard softmax GP classi-
ﬁer (Williams and Barber, 1998), the probit classiﬁer of Girolami and Rogers (2006),
and the multiclass extension (Rogers and Girolami, 2007) of the Null Category Noise
Model of Lawrence and Jordan (2005). I present comparisons of these models on three
two-dimensional toy problems and two real-world datasets. Note that unlabeled data
were ignored in the softmax and probit models.
8.5.1
Toy Pinwheel Data
The toy problems are noisy pinwheels with three, four and ﬁve classes, shown in
Figure 8.3a, Figure 8.3d, and Figure 8.3g, respectively. There are 50 data points in each
set and the algorithms were run with 1, 2, 4, and 8 labeled data in each class. 300 held-
out data for each class were used to evaluate the predictive distributions by error rate

Discussion
109
and perplexity. Inference for each method was performed using Markov chain Monte
Carlo, and each used an isotropic squared-exponential covariance function. For each
method I also sampled from the length-scale and amplitude hyperparameters using
Hamiltonian Monte Carlo. The Archipelago base density was a bivariate Gaussian.
Figure 8.3 shows the predictive modes for the Archipelago and softmax models, as
well as the entropy of the Archipelago marginal predictive distribution as a function
of space. Numerical results are in Table 8.1.
8.5.2
Wine Data
The wine data are thirteen-dimensional, with three classes from Aeberhard et al. (1992)
via Asuncion and Newman (2007). As in Rogers and Girolami (2007), I translated and
scaled the inputs to have zero mean and unit variance. I used an automatic relevance
determination (ARD) covariance function (Rasmussen and Williams, 2006) and HMC
for inference of length scales and amplitude. I divided the data into two sets of 89 for
training and testing, with the classes divided approximately evenly. I ran four sets of
experiments with each method, as with the toy data, with 1, 2, 4, and 8 labeled data
in each class. I used a multivariate Gaussian for the Archipelago base density. The
results are given in Table 8.1.
8.5.3
Oil Pipe Data
The oil pipe data are included with software for Williams and Barber (1998). The task
is to classify the type of ﬂow in a pipe (laminar, hydrogenous, or amorphous), using
a set of fourteen gamma ray readings. I split the 400 data into 134 training and 266
testing. I used an ARD covariance function and followed the same procedures as in
Section 8.5.2. The results are given in Table 8.1.
8.6
Discussion
Archipelago combines ideas both from Gaussian process density modeling and Gaus-
sian process classiﬁcation into a single model.
When using a kernel such as the
squared-exponential, it is expressing the idea that similar data should have similar
probabilities and have similar class assignments. In contrast, a semi-supervised learn-
ing approach with a mixture model for each class must maintain both a class assign-
ment and a mixture component assignment for each datum, and the notion of smooth-
ness does not extend beyond the simple parametric form of the components.
The most relevant Bayesian model to Archipelago is the discriminative Null Cate-
gory Noise Model (NCNM) (Lawrence and Jordan, 2005) and the multi-class exten-
sion of Rogers and Girolami (2007). The NCNM enforces the idea of “margin” in a

Discussion
110
Archipelago
Softmax GP
Probit GP
NCNM
Toy3
1
error
0.167
0.347
0.290
0.612
perplexity
1.461
2.588
1.631
14.120
2
error
0.111
0.312
0.279
0.462
perplexity
1.565
2.769
1.350
4.801
4
error
0.042
0.118
0.142
0.114
perplexity
1.092
1.310
1.041
1.002
8
error
0.037
0.056
0.137
0.070
perplexity
1.070
1.065
1.043
1.000
Toy4
1
error
0.120
0.305
0.416
0.554
perplexity
2.478
3.436
1.239
16.160
2
error
0.092
0.188
0.253
0.429
perplexity
2.471
2.861
7.896
8.257
4
error
0.032
0.119
0.077
0.056
perplexity
1.469
1.505
1.343
1.113
8
error
0.025
0.061
0.088
0.0533
perplexity
1.135
1.076
1.086
1.009
Toy5
1
error
0.183
0.192
0.515
0.482
perplexity
3.766
4.519
3.533
294.758
2
error
0.124
0.181
0.178
0.365
perplexity
2.811
2.008
1.476
11.669
4
error
0.081
0.159
0.113
0.093
perplexity
2.345
1.730
1.375
1.210
8
error
0.051
0.095
0.073
0.051
perplexity
2.105
1.290
1.201
1.093
Wine
1
error
0.141
0.260
0.303
0.393
perplexity
1.928
2.790
1.769
31.832
2
error
0.135
0.292
0.213
0.393
perplexity
2.654
2.760
2.851
2.799
4
error
0.090
0.146
0.101
0.101
perplexity
1.198
2.440
1.387
1.153
8
error
0.090
0.067
0.067
0.067
perplexity
1.084
1.250
1.224
1.045
Oil Pipe
1
error
0.538
0.568
0.432
0.650
perplexity
2.997
3.024
5.631
3.56K
2
error
0.297
0.331
0.308
0.365
perplexity
2.451
2.576
3.499
1.024
4
error
0.211
0.215
0.271
0.176
perplexity
1.658
1.864
2.558
1.301
8
error
0.068
0.053
0.068
0.038
perplexity
1.241
1.137
1.232
1.002
Table 8.1: Results from four methods applied to test data: Archipelago, the soft-
max GP, the probit GP and the Null Category Noise Model (NCNM). Six prob-
lems were evaluated, with 1, 2, 4, and 8 labeled data per class. Test-set error and
perplexity are shown.

Discussion
111
(a) Toy3 Archipelago
(b) Toy3 Softmax GP
(c) Toy3 Archipelago Entropy
(d) Toy4 Archipelago
(e) Toy4 Softmax GP
(f) Toy4 Archipelago Entropy
(g) Toy5 Archipelago
(h) Toy5 Softmax GP
(i) Toy5 Archipelago Entropy
Figure 8.3: These ﬁgures show results of applying Archipelago to “pinwheel” data with
only one labeled datum per class (highlighted). The top row has three classes, the mid-
dle row has four classes and the bottom has ﬁve. The ﬁgures on the left show the modes
of the class assignments from Archipelago. The middle column shows the class assign-
ment modes using a softmax Gaussian process. The right column shows the entropies
of the predictive distribution produced by Archipelago.
Gaussian process classiﬁer by requiring a null-class transition between any two “real”
classes. The latent rejections play a similar role in Archipelago by allowing regions
with mass under π(x | ψπ) to have no data. However, Archipelago models data in the
null class explicitly as part of inference, and the rejections give Archipelago its ability
to model arbitrarily complex densities. Also, in contrast to Archipelago, the Null Cat-
egory Noise Model requires setting the null-category width and a priori determination
of labeling probability. In almost all of the tests, Archipelago had lower test classiﬁ-
cation error than the NCNM. In the regime with few labels, Archipelago signiﬁcantly
outperformed the other methods on test error. As Archipelago is a generative model

Computational Considerations
112
and the others are discriminative, this difference is expected.
8.7
Computational Considerations
Gaussian processes have relatively high computational costs, and the Archipelago
model inherits them. With a na¨ıve implementation, the time complexity per MCMC
step is O(K(N + J + M)3) and the space complexity is O(K(N + J + M)2). There
is a large literature on sparse approximations to Gaussian processes, e.g. Qui˜nonero-
Candela and Rasmussen (2005), and this is an area for future research. Mixing of
Markov chains is an additional concern, but I have not found this to be a problem in
practice due to the use of Hamiltonian Monte Carlo.
As the computational complexity grows rapidly with the number of latent rejections,
minimising these rejections is paramount.
The number of latent rejections relates
directly to the mismatch between the base density π(x | ψπ) and the true data den-
sity. Base density hyperparameter inference can lower the computational burden by
adapting π(x | ψπ) to the data, but it is important to choose an appropriate paramet-
ric family. In high dimensions this choice is difﬁcult to make, and in the absence of
signiﬁcant domain knowledge I expect that Archipelago will not work well in high
dimensions. This problem in high-dimensions is common to generative approaches to
semi-supervised learning, and it is unclear how to avoid it.
8.8
Summary
I have presented a nonparametric Bayesian method for semi-supervised learning that
is an extension of the Gaussian process density sampler of Chapter 2. I used a latent
history method for inference, similar to that presented for the GPDS and sigmoidal
Gaussian Cox process in Chapter 5. Empirical analyses on synthetic and real-world
data indicate that the Archipelago model successfully incorporates information from
the unlabeled data. The approach is competitive with other Bayesian approaches to
semi-supervised learning.

Chapter 9
Conclusions and Future Work
This chapter discusses some possible future directions for work on the Gaussian pro-
cess density sampler, the sigmoidal Gaussian Cox process, and the Archipelago semi-
supervised learning model. I also brieﬂy review the contributions of the thesis.
9.1
Modeling Other Spaces with the GPDS and Archipelago
One of the interesting aspects of the Gaussian process density sampler and
Archipelago is that they can be used on any space on which it is possible to de-
ﬁne a positive deﬁnite kernel function.
I have presented these methods with X
as RD, but this is not necessary. There is a growing literature describing positive
deﬁnite kernels on many different types of data (e.g. Haussler (1999), Kondor and
Lafferty (2002) and Rasmussen and Williams (2006, Section 4.4)). Some of these spaces
are countable and in these cases the Gaussian process density sampler provides a
nonparametric prior on probability mass functions, rather than density functions.
9.1.1
Permutation Kernels
Modeling a distribution on the space of permutations has similar difﬁculties to the
Potts model discussed in Section 4.2. If there are K items in our set, then there are K!
possible permutations. The na¨ıve approach to representing a distribution on permu-
tations is to deﬁne a categorical distribution on all K! possible situations. For K larger
than about 14, however, it becomes impossible to hold this distribution in memory,
and normalising the distribution becomes an intractable problem.
Kondor (2008) proposes a class of positive deﬁnite kernels on permutation groups.
It may be possible to combine such kernels with the Gaussian process density sam-
pler to construct tractable Bayesian models on permutations with K > 14, without

Inclusion of Covariates
114
approximation. This would enable inferences of the form “given a set of observed
permutations, fantasise additional permutations from the same distribution.”
9.1.2
String Kernels
Given an alphabet, a string is a sequence of members from that alphabet, possibly
with repeats. Several different proposals have been made of positive deﬁnite kernels
on strings, e.g. Haussler (1999), Watkins (2000), and Lodhi et al. (2002). These strings
can represent a wide variety of data structures and have been used to model, for ex-
ample, text (Collins and Duffy, 2001) and protein structure (Leslie et al., 2004). It is
possible that the Gaussian process density sampler and Archipelago could be used as
a nonparametric Bayesian prior for mass functions on these domains.
9.1.3
Set Kernels
Closely related to string kernels are kernel functions on sets. The space of interest in
this case is the space of unordered subsets of some other space. Kondor and Jebara
(2003), for example, describe a positive deﬁnite kernel on ﬁnite subsets of RD. This
can be thought of as a kernel between “bags of data.” It is interesting to consider that
the Gaussian process density sampler, deﬁned on the space of ﬁnite subsets of RD, is a
point process as described in Section 3.1. The speciﬁc characteristics of this point pro-
cess depend heavily on the choice of base density and the set kernel, and identifying
the properties of this point process is a potential topic for further study.
9.1.4
Graph Kernels
Many data are best described by graphs, and several authors, e.g., Kondor and Laf-
ferty (2002), G¨artner et al. (2003), and Borgwardt (2007), have proposed positive def-
inite kernels on the space of graphs. Modeling of protein interactions has been of
particular interest in this domain (Borgwardt et al., 2005). A common task in mod-
eling proteins is to predict their function with a classiﬁer. The Archipelago model is
promising in this regard, as it could potentially allow proteins with unknown function
to help guide classiﬁcation.
9.2
Inclusion of Covariates
There has been signiﬁcant recent interest in methods for introducing dependency be-
tween nonparametric processes (MacEachern, 2000; M¨uller et al., 2004; Srebro and
Roweis, 2005; Dunson and Park, 2008; Grifﬁn and Steel, 2009). The motivation for

Doubly-Nonparametric Density Modeling
115
these models has been to ﬁnd a way to tie together multiple nonparametric distri-
butions. For example, the distribution over a set of economic indicators may vary
in time. However, we expect that this distribution will change very slowly, and we
would like to take advantage of this additional structure when performing inference.
The Gaussian process density sampler can potentially be extended to include covari-
ates by augmenting the input space for the GP prior. The speciﬁc details of this con-
struction would be a topic for future work, but it appears to be straightforward to tie
multiple Gaussian process density samplers together via shared inputs.
9.3
Doubly-Nonparametric Density Modeling
When presenting the Gaussian process density sampler and the Archipelago model, I
have made the assumption that π(x) is a model with a ﬁnite set of parameters. How-
ever, this is not strictly necessary. Rather, what is required is that it be possible to
generate exact data from π(x). Dirichlet process mixture models (Escobar and West,
1995; Rasmussen, 2000) are nonparametric models from which it is possible to gener-
ate exact data. Potentially, the Gaussian process density sampler and the DPMM could
be combined to create a model with two nonparametric aspects. It appears that infer-
ence via the latent history method would be a direct extension of the vanilla GPDS
case, as long as component membership labels are explicitly modeled. This would
enable π(x) to be very ﬂexible and provide a tighter bound on the true density.
9.4
Archipelago with Dependent Latent Functions
In the Archipelago model, I used K independent Gaussian processes as part of the
model. This independence is not required. We might, for example, believe that data
from some classes tend to co-occur with data from another class. Dependency between
the Gaussian processes could be introduced to capture this kind of prior information,
using, for example, the latent factor model of Teh et al. (2005) or the multi-task learning
approach of Bonilla et al. (2008).
9.5
Summary of Contributions
Kernel-based methods for nonparametric inference of densities and point processes
have been of signiﬁcant interest to statistical modelers for several decades. Bayesian
approaches to this problem, while desirable in the abstract, have been difﬁcult due
to the need to integrate over inﬁnite-dimensional random functions. A variety of ap-
proximations have been introduced in the literature over the years.

Summary of Contributions
116
This thesis contributes the ﬁrst fully-nonparametric and non-approximate Bayesian
models for kernel-based MCMC inference of densities and point process intensities.
The methods I have presented combine generative models with recent advances in
Markov chain Monte Carlo to achieve tractability. I also proposed a soft-core gener-
alisation of the Mat´ern Type III repulsive process and showed how inference could
be performed in that model with the sigmoidal Gaussian Cox process as the primary
process. In addition, I extended the latent history inference approach in the SGCP to
allow for an inhomogeneous Neyman–Scott process. Finally, I presented a nonpara-
metric Bayesian model for semi-supervised learning and showed that it is competitive
with other Bayesian approaches to this problem.

Appendix A
Additional Algorithms
Algorithm A.1
Generate Poisson events from the SGCP on an irregular region.
Inputs:
• Bounding domain V
• Region indicator function I(x)
• Dominating intensity function ¯λ(x ; ψλ)
• Gaussian process covariance function C(x, x′; θ)
Outputs:
• Poisson events S = {xk}K
k=1 from an SGCP prior
1: {˜xj}J
j=1 ∼PP(¯λ(x ; ψλ), V)
▷Draw Poisson events on V according to intensity ¯λ(x).
2: ˆV ←∅
▷Initialise the ﬁrst set of unthinned events.
3: for j ←1 . . . J do
▷Loop over the initial events.
4:
if I(˜xj) then
▷Test the region membership.
5:
ˆV ←ˆV ∪˜xj
▷Keep if inside the irregular region.
6:
end if
7: end for
8: ˆJ ←|ˆV|
▷Get the number of events left inside the region.
9: {g(˜xj)} ˆ
J
j=1 ∼GP(g | {˜xj} ˆ
J
j=1, θ)
▷Draw the function from the GP at the events.
10: S ←∅
▷Initialise the set of unthinned events.
11: for all ˜xj ∈ˆV do
▷Loop over the events in the region.
12:
u ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
13:
if u < Φ(g(˜xj)) then
▷Apply the thinning acceptance rule.
14:
S ←S ∪˜xj
▷Add to the accepted events.
15:
end if
16: end for
17: return S

118
Algorithm A.2
Generate marked Poisson events from the SGCP.
Inputs:
• Domain V
• Marking distribution p(y | x)
• Dominating intensity function ¯λ(x ; ψλ)
• Gaussian process covariance function C(x, x′; θ)
Outputs:
• Marked Poisson events S = {xk, yk}K
k=1 from an SGCP prior
1: {˜xj}J
j=1 ∼PP(¯λ(x ; ψλ), V)
▷Draw Poisson events according to intensity ¯λ(x).
2: {g(˜xj)}J
j=1 ∼GP(g | {˜xj}J
j=1, θ)
▷Draw the function from the GP at the events.
3: S ←∅
▷Initialise the set of unthinned events.
4: for j ←1 . . . J do
▷Loop over the proposed events.
5:
u ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
6:
if u < Φ(g(˜xj)) then
▷Apply the thinning acceptance rule.
7:
˜y ∼p(y | ˜xj)
▷Draw from the marking distribution.
8:
S ←S ∪(˜xj, ˜y)
▷Add the pair to the accepted events.
9:
end if
10: end for
11: return S
Algorithm A.3
Generate a Neyman–Scott realisation from the SGCP.
Inputs:
• Domain V
• Daugher intensity λdtr(x ; xmtr) with compact support Q
• Dominating mother intensity function ¯λ(x ; ψλ)
• Gaussian process covariance function C(x, x′; θ)
Outputs:
• Neyman–Scott events S = {xk}K
k=1 from an SGCP prior
1: {˜xj}J
j=1 ∼PP(¯λ(x ; ψλ), V ⊕Q)
▷Draw Poisson events according to intensity ¯λ(x).
2: {g(˜xj)}J
j=1 ∼GP(g | {˜xj}J
j=1, θ)
▷Draw the function from the GP at the events.
3: S ←∅
▷Initialise the set of unthinned events.
4: for j ←1 . . . J do
▷Loop over the proposed events.
5:
u ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
6:
if u < Φ(g(˜xj)) then
▷Thin to get mother point.
7:
{xm}M
m=1 ∼PP(λdtr(x ; ˜xj), ˜xj ⊕Q)
▷Draw daughter points centred at ˜xj.
8:
for m ←1 . . . M do
▷Loop over the daughter events.
9:
if IV(xn) then
▷Test if the daughter is inside V.
10:
S ←S ∪xm
▷Keep the daughter point.
11:
end if
12:
end for
13:
end if
14: end for
15: return S

119
Algorithm A.4
Generate a Hawkes realisation from the SGCP.
Inputs:
• Domain V with periodic boundaries
• Daugher intensity λdtr(x ; xmtr)
• Dominating mother intensity function ¯λ(x ; ψλ)
• Gaussian process covariance function C(x, x′; θ)
Outputs:
• Hawkes events S = {xk}K
k=1 from an SGCP prior
1: {˜xj}J
j=1 ∼PP(¯λ(x ; ψλ), V)
▷Draw Poisson events according to intensity ¯λ(x).
2: {g(˜xj)}J
j=1 ∼GP(g | {˜xj}J
j=1, θ)
▷Draw the function from the GP at the events.
3: S ←∅
▷Initialise the set of unthinned events.
4: for j ←1 . . . J do
▷Loop over mother proposals.
5:
u ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
6:
if u < Φ(g(˜xj)) then
▷Thin to get mother point.
7:
S ←S ∪˜xj
▷Add the mother point to the set.
8:
S′ ←DAUGHTER(˜xj)
▷Simulate the daughter cascade.
9:
S ←S ∪S′
▷Add the daughter points to the set.
10:
end if
11: end for
12: return S
13: procedure DAUGHTER(x′)
14:
{˜xm}M
m=1 ∼PP(λdtr(x ; x′), Q)
▷Draw daughters centred at x′.
15:
S′ ←{˜xm}M
m=1
▷Store the daughter points.
16:
for m ←1 . . . M do
▷Loop over the daughter points.
17:
S′′ ←DAUGHTER(˜xm)
▷Recurse on the daughters.
18:
S′ ←S′ ∪S′′
▷Collect cascaded daughter points.
19:
end for
20:
return S′
21: end procedure
Algorithm A.5
Generate a generalised Mat´ern Type II realisation from the SGCP.
Inputs:
• Domain V with periodic boundaries
• Repulsion kernel ρ(x ↚x′)
• Dominating primary intensity function ¯λ(x ; ψλ)
• Gaussian process covariance function C(x, x′; θ)
Outputs:
• Generalised Mat´ern Type II events S = {xk}K
k=1 from an SGCP prior
1: {˜xj}J
j=1 ∼PP(¯λ(x ; ψλ), V)
▷Draw Poisson events according to intensity ¯λ(x).
▷(I assume a random ordering of the events.)
2: {g(˜xj)}J
j=1 ∼GP(g | {˜xj}J
j=1, θ)
▷Draw the function from the GP at the events.
3: S′ ←∅
▷Initialise the set of primary events.
4: for j ←1 . . . J do
▷Loop over the proposed events.
5:
u1 ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
6:
if u1 < Φ(g(˜xj)) then
▷Thin to get primary point.
7:
pkeep ←1
▷Initialise the probability of keeping this point.
8:
for j′ ←1 . . . j −1 do
▷Loop over older primary points.
9:
pkeep ←pkeep × (1 −ρ(˜xj ↚˜xj′))
▷Accumulate repulsion probabilities.
10:
end for
11:
u2 ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
12:
if u2 < pkeep then
▷Apply Type II primary-to-secondary thinning rule.
13:
S ←S ∪˜xj
▷Store the secondary point.
14:
end if
15:
end if
16: end for
17: return S

120
Algorithm A.6
Generate a generalised Mat´ern Type III realisation from the SGCP.
Inputs:
• Domain V with periodic boundaries
• Repulsion kernel ρ(x ↚x′)
• Dominating primary intensity function ¯λ(x ; ψλ)
• Gaussian process covariance function C(x, x′ ; θ)
Outputs:
• Generalised Mat´ern Type III events S = {xk}K
k=1 from an SGCP prior
1: {˜xj}J
j=1 ∼PP(¯λ(x ; ψλ), V)
▷Draw Poisson events according to intensity ¯λ(x).
▷(I assume a random ordering of the events.)
2: {g(˜xj)}J
j=1 ∼GP(g | {˜xj}J
j=1, θ)
▷Draw the function from the GP at the events.
3: S′ ←∅
▷Initialise the set of primary events.
4: for j ←1 . . . J do
▷Loop over the proposed events.
5:
u1 ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
6:
if u1 < Φ(g(˜xj)) then
▷Thin to get primary point.
7:
pkeep ←1
▷Initialise the probability of keeping this point.
8:
for all x′ ∈S do
▷Loop over older secondary points.
9:
pkeep ←pkeep × (1 −ρ(˜xj ↚x′))
▷Accumulate repulsion probabilities.
10:
end for
11:
u2 ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
12:
if u2 < pkeep then
▷Apply primary-to-secondary thinning rule.
13:
S ←S ∪˜xj
▷Store the secondary point.
14:
end if
15:
end if
16: end for
17: return S

121
Algorithm A.7
Take an exchange sampling step on GP hyperparameters for the GPDS
Inputs:
• Observed data D = {xn}N
n=1
• Control points C = {xb}B
b=1
• Control point proposal distribution q( ˆG ←G ; θ)
• Hyperparameter proposal distribution q(ˆθ ←θ)
• Hyperparameter prior p0(θ)
• Current conditioning sets X and G
• Gaussian process covariance function C(x, x′; θ)
• Base density π(x | ψπ)
• Current Gaussian process hyperparameters θ
Outputs:
• New Gaussian process hyperparameters θ
• New conditioning sets X and G
1: ˆθ ∼q(ˆθ ←θ)
▷Draw the hyperparameter proposal.
2: ˆG ∼q( ˆG ←G; ˆθ)
▷Draw new control point values.
3: ˆX ←C, ˆG ←ˆG
▷Initialise conditioning sets.
4: repeat
5:
˜
w ∼π(x | ψπ)
▷Draw a proposal from the base density.
6:
ˆg( ˜
w) ∼GP(g | ˜
w, ˆX, ˆG, ˆθ)
▷Draw the function value at the proposal.
7:
ufant ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
8:
if ufant < Φ(ˆg( ˜
w)) then
▷Rejection sampling acceptance rule.
9:
W ←W ∪˜
w
▷Keep the fantasy.
10:
end if
11:
ˆX ←ˆX ∪˜
w, ˆG ←ˆG ∪ˆg( ˜
w)
▷Add proposals to the conditioning sets.
12: until |W| = N
▷Loop until N fantasies are accepted.
13: {g(wn)}N
n=1 ∼GP(g | W, X(p), G(p), θ)
▷Sample the current function at the fantasies.
14: agpds−gphp ←p0(ˆθ) GP( ˆG | C, ˆθ) q(θ ←ˆθ) q(G ←ˆG; θ)
p0(θ) GP(G | C, θ) q(ˆθ ←θ) q( ˆG ←G; ˆθ)
N
Y
n=1
Φ(ˆg(xn)) Φ(g(wn))
Φ(g(xn)) Φ(ˆg(wn))
15: umh ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
16: if umh < agpds−gphp then
▷Apply the Metropolis–Hastings acceptance rule.
17:
θ ←ˆθ
▷Keep the new hyperparameters.
18:
X ←ˆX, G ←ˆG
▷Keep the new conditioning sets.
19:
G ←ˆG
▷Keep the new control points.
20: else
21:
X ←X ∪{wn}N
n=1, G ←G ∪{g(wn)}N
n=1
▷Update the current conditioning set.
22: end if
23: return θ, X, G

122
Algorithm A.8
Take an ES step on base density hyperparameters for the GPDS
Inputs:
• Observed data {xn}N
n=1
• Hyperparameter proposal distribution q( ˆ
ψπ ←ψπ)
• Hyperparameter prior p0(ψπ)
• Current conditioning sets X and G
• Gaussian process covariance function C(x, x′; θ)
• Gaussian process hyperparameters θ
• Base density π(x | ψπ)
• Current base density hyperparameters ψπ
Outputs:
• New base density hyperparameters ψπ
• New conditioning sets X and G
1: ˆ
ψπ ∼q( ˆ
ψπ ←ψπ)
▷Draw the hyperparameter proposal.
2: repeat
3:
˜
w ∼π(x | ˆ
ψπ)
▷Draw a proposal from the base density.
4:
g( ˜
w) ∼GP(g | ˜
w, X, G, θ)
▷Draw the function value at the proposal.
5:
ufant ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
6:
if ufant < Φ(g( ˜
w)) then
▷Rejection sampling acceptance rule.
7:
W ←W ∪˜
w
▷Keep the fantasy.
8:
end if
9:
X ←X ∪˜
w, G ←G ∪g( ˜
w)
▷Add proposals to the conditioning sets.
10: until |W| = N
▷Loop until N fantasies are accepted.
11: agpds−bdhp ←p0( ˆ
ψπ) q(ψπ ←ˆ
ψπ)
p0(ψπ) q( ˆ
ψπ ←ψπ)
N
Y
n=1
π(xn | ˆ
ψπ) π(wn | ψπ)
π(xn | ψπ) π(wn | ˆ
ψπ)
12: umh ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
13: if umh < agpds−bdhp then
▷Apply the Metropolis–Hastings acceptance rule.
14:
ψπ ←ˆ
ψπ
▷Keep the new hyperparameters.
15: end if
16: return ψπ, X, G

123
Algorithm A.9
Take an exchange sampling step on GP hyperparameters for the SGCP
Inputs:
• Observed data S = {xk}K
k=1
• Control points C = {xb}B
b=1
• Control point proposal distribution q( ˆG ←G ; θ)
• Hyperparameter proposal distribution q(ˆθ ←θ)
• Hyperparameter prior p0(θ)
• Current conditioning sets X and G
• Gaussian process covariance function C(x, x′; θ)
• Dominating intensity ¯λ(x ; ψλ)
• Current Gaussian process hyperparameters θ
Outputs:
• New Gaussian process hyperparameters θ
• New conditioning sets X and G
1: ˆθ ∼q(ˆθ ←θ)
▷Draw the hyperparameter proposal.
2: ˆG ∼q( ˆG ←G; ˆθ)
▷Draw new control point values.
3: ˆX ←C, ˆG ←ˆG
▷Initialise conditioning sets.
4: { ˜
wj}J
j=1 ∼PP(¯λ(x ; ψλ), V)
▷Draw from the dominating intensity.
5: {ˆg( ˜
wj)}J
j=1 ∼GP(g | { ˜
wj}J
j=1, ˆX, ˆG, ˆθ)
▷Sample the proposed function at the events.
6: ˆX ←ˆX ∪{ ˜
wj}J
j=1, ˆG ←ˆG ∪{g( ˜
wj)}J
j=1
▷Update the proposed conditioning set.
7: W ←∅
▷Initialise fantasy set.
8: for j ←1 . . . J do
▷Loop over the events.
9:
ufant ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
10:
if ufant < Φ(ˆg( ˜
wj)) then
▷Apply the thinning rule.
11:
W ←W ∪˜
wj
▷Add the event to the fantasy set.
12:
end if
13: end for
14: {g(wk)} ˆ
K
k=1 ∼GP(g | W, X(r), G(r), θ)
▷Sample the current function at the fantasies.
15: asgcp−gphp ←p0(ˆθ) GP( ˆG | C, ˆθ) q(θ ←ˆθ) q(G ←ˆG; θ)
p0(θ) GP(G | C, θ) q(ˆθ ←θ) q( ˆG ←G; ˆθ)
N
Y
n=1
Φ(ˆg(xn)) Φ(g(wn))
Φ(g(xn)) Φ(ˆg(wn))
16: umh ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
17: if umh < asgcp−gphp then
▷Apply the Metropolis–Hastings acceptance rule.
18:
θ ←ˆθ
▷Keep the new hyperparameters.
19:
X ←ˆX, G ←ˆG
▷Keep the new conditioning sets.
20:
G ←ˆG
▷Keep the new control points.
21: else
22:
X ←X ∪{wn}N
n=1, G ←G ∪{g(wn)}N
n=1
▷Update the current conditioning set.
23: end if
24: return θ, X, G

124
Algorithm A.10
Take an ES step on bounding intensity hyperparameters for the SGCP
Inputs:
• Observed data {xk}K
k=1
• Hyperparameter proposal distribution q( ˆ
ψλ ←ψλ)
• Hyperparameter prior p0(ψλ)
• Current conditioning sets X and G
• Gaussian process covariance function C(x, x′; θ)
• Dominating intensity ¯λ(x ; ψλ)
• Current dominating intensity hyperparameters ψλ
Outputs:
• New base density hyperparameters ψλ
• New conditioning sets X and G
1: ˆ
ψλ ∼q( ˆ
ψλ ←ψλ)
▷Draw the hyperparameter proposal.
2: { ˜
wj}J
j=1 ∼PP(¯λ(x ; ˆ
ψλ), V)
▷Draw from the dominating intensity.
3: {ˆg( ˜
wj)}J
j=1 ∼GP(g | { ˜
wj}J
j=1, X, G, θ)
▷Sample the proposed function at the events.
4: X ←X ∪{ ˜
wj}J
j=1, G ←G ∪{g( ˜
wj)}J
j=1
▷Update the proposed conditioning set.
5: W ←∅
▷Initialise fantasy set.
6: for j ←1 . . . J do
▷Loop over the events.
7:
ufant ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
8:
if ufant < Φ(ˆg( ˜
wj)) then
▷Apply the thinning rule.
9:
W ←W ∪˜
wj
▷Add the event to the fantasy set.
10:
end if
11: end for
12: asgcp−bihp ←p0( ˆ
ψλ) q(ψλ ←ˆ
ψλ)
p0(ψλ) q( ˆ
ψλ ←ψλ)
" K
Y
k=1
¯λ(xn ; ˆ
ψλ)
¯λ(xn ; ψλ)
#
ˆ
K
Y
k=1
¯λ(wn ; ψλ)
¯λ(wn ; ˆ
ψλ)
13: umh ∼U(0, 1)
▷Draw a uniform random variate on (0, 1).
14: if umh < asgcp−bihp then
▷Apply the Metropolis–Hastings acceptance rule.
15:
ψλ ←ˆ
ψλ
▷Keep the new hyperparameters.
16: end if
17: return ψλ, X, G

Appendix B
Additional Tables
Distance
Landmark 1
Landmark 2
1
Bregma
Right superior incisor
2
Bregma
Left superior incisor
3
Right fronto-zygomatic junction
Left fronto-zygomatic junction
4
Right zygomaxillare superior
Left zygomaxillare superior
5
Right basi-occipital synchondrosis
Right superior incisor
6
Left basi-occipital synchrondrosis
Left superior incisor
7
Right zygomaxillare inferior
Left zygomaxillare inferior
8
Right posterior canine
Right maxillary tuberosity
9
Left posterior canine
Left maxillary tuberosity
10
Right pterion anterior
Left pterion anterior
Table B.1: This table identiﬁes the anatomical landmarks associated with the lin-
ear distances used for the modeling of Macaca mulatta skulls.

Symbol Glossary
α
The shape parameter for the gamma distribution.
β
The inverse scale parameter for the gamma distribution.
ℓ
The length scale parameter for covariance functions and repulsion
kernels. Has components ℓd. See Section 1.2.1.
Γ
An abstract parameter space. See Section 2.2.3 and Section 4.1.
Γ(z)
The gamma function.
γ
An abstract parameter in the space Γ. See Section 2.2.3 and Sec-
tion 4.1.
κ
Underrelaxation parameter. Restricted to (−1, 1), but typically close
to 1 for underrelaxed proposals. See Section 4.3.2.
Λ(t)
The cumulative intensity function. See Section 3.2.2.
Λ−1(t)
The inverse cumulative intensity function. See Section 3.2.2.
λ(x)
A Poisson intensity function.
µ(T )
The measure of the set T .
ν
Poisson rate of a Neyman–Scott daughter process. See Section 3.5.2.
Ω(x)
The sum of exponentiated latent functions in the Archipelago
model. See Section 8.2.
ω
The amplitude parameter for the squared exponential covariance
function. See Section 1.2.1.
⊕
The Minkowski sum, a binary operator.
Φ(z)
A function Φ(·) : X →(0, 1), typically a sigmoid. In this thesis, gen-
erally taken to be a logistic function. See Section 2.1.1.
φ(x)
A function used for independent thinning. See Section 3.2.3.
ψλ
Hyperparameters of the dominating intensity function ¯λ(x ; ψλ).
See Section 3.3.
ρ(x ↚x′)
A repulsion kernel. See Section 3.5.2.
σ
The standard deviation of a univariate Gaussian distribution.
θ
Hyperparameters of the Gaussian process covariance function. See
Section 1.2.
ξk
The partition edges in the Archipelago generative model. See Sec-
tion 8.3.

Symbol Glossary
127
ζ(·, ·)
The Bernoulli probability of proposing to insert a new rejection or
thinned event into the latent history model.
a
The Metropolis–Hastings acceptance ratio.
B
The number of control points when using exchange sampling, in-
dexed by b. See Section 4.3.2.
Bz(x)
The z-ball centred at x. See Section 3.5.2.
C(x, x ; θ)
The Gaussian process covariance function C : X × X →R. A posi-
tive semideﬁnite function parameterised by θ. See Section 1.2.
C
The set of control points input locations, i.e. C = {xb}B
b=1. See Sec-
tion 4.3.2.
D
Dimensionality of the space X, indexed by d.
D
The observed data when performing inference with the GPDS. Typ-
ically, considered to be N i.i.d. data, i.e. D = {xn}N
n=1.
EX(x | λ)
The exponential distribution with parameter λ.
f(x)
A probability density function, typically random with a logistic
Gaussian process or Gaussian process density sampler prior.
g
A vector of inﬁnite length used to denote g(x) when it is an object
of inference. See Section 1.3.
g\C
The vector g, excluding the values at the control points. See Sec-
tion 4.3.2.
G
The conditioning set of outputs for a Gaussian process. See Sec-
tion 2.2.2.
GP(g | θ)
A Gaussian process prior on the function g, with hyperparameter θ
GA(x | α, β)
The gamma distribution with shape parameter α and inverse scale
parameter β.
G
The control point function values, i.e. G = {g(xb) : xb ∈C}. See Sec-
tion 4.3.2.
GM
The values of g(x) at the rejections or thinned events, when per-
forming latent history inference.
GN
The values of g(x) at the observed data in the GPDS.
g(x)
A function g : X →R that has a Gaussian process prior. See Sec-
tion 1.2.
H
The independent draw from a Gaussian process that is used for an
underrelaxed proposal. See Section 4.3.2.
h(γ ; x)
The tractable portion of a doubly-intractable likelihood. See Sec-
tion 4.2.
ID
The D × D identity matrix.
IV(x)
The indicator function for set membership in V. It returns one if x ∈
V, or zero otherwise. See Section 3.2.1.
K
When discussing point process models, this a number of events. In
the Archipelago model, this is the number of classes. Indexed by k.

Symbol Glossary
128
M
The number of latent rejections, when performing GPDS latent his-
tory inference (See Section 5.2.).
The number of latent thinned
events when performing SGCP latent history inference (See Sec-
tion 5.3.).
M
The set of latent rejections, or latent thinned events.
N
The number of i.i.d. data generated or observed in the GPDS. The
number of distinct sets of events observed in the SGCP. Indexed
by n.
N(x | µ, Σ)
The Gaussian (Normal) distribution with mean µ and covariance Σ.
PP(S | V, λ(x))
A Poisson process on V with intensity λ(·).
PO(k | λ)
The Poisson distribution with parameter λ.
Q
The support of a daughter or repulsion kernel in an interacting
point process. See Section 3.5.2.
q(x)
A rejection sampling proposal density. See Section 2.2.1.
q(ˆγ ←γ)
A Metropolis–Hastings proposal density. See Section 4.1.
R
The number of iterations of a Monte Carlo procedure, indexed by r.
R
The real line.
S
A ﬁnite set of events, as from a point process. See Section 3.1.
T(ˆγ ←γ)
A Markov chain transition operator. See Section 4.1.
t
A temporal event.
U(V)
The uniform distribution on the set V.
U(a, b)
The uniform distribution on (a, b).
u
A uniform variate on a bounded interval, typically (0, 1).
V
The domain of interest for a point process. See Section 3.1.
W
The positive deﬁnite matrix determining the Mahalanobis distance
in a quadratic repulsion kernel. See Section 3.5.2.
wn
The nth fantasy datum when using exchange sampling for the
GPDS. See Section 4.3.1.
W
A set of fantasy data.
X
A conditioning set of inputs for a Gaussian process.
See Sec-
tion 2.2.2.
x
A member of X.
X
The data space for density models and the event space for point
process models. Typically this is RD.
Y
The mark space of a marked Poisson process. See Section 3.5.1.
Z[g]
The normalisation constant for a doubly-intractable model that de-
pends on a function g.
Zπ[g]
The normalisation constant for the GPDS likelihood model. See Sec-
tion 2.1.

Bibliography
Petter Abrahamsen. A review of Gaussian random ﬁelds and correlation functions.
Technical Report 917, Norwegian Computing Center, Oslo, Norway, April 1997.
(page 4)
Milton Abramowitz and Irene A. Stegun.
Handbook of Mathematical Functions with
Formulas, Graphs, and Mathematical Tables. Dover, New York, ninth edition, 1964.
(page 15)
David H. Ackley, Geoffrey E. Hinton, and Terrence J. Sejnowski. A learning algorithm
for Boltzmann machines. Cognitive Science, 9(1):147–169, 1985.
(pages 8 and 46)
Ryan Prescott Adams and Zoubin Ghahramani.
Archipelago:
Nonparametric
Bayesian semi-supervised learning. In Leon Bottou and Michael Littman, editors,
Proceedings of the 26th International Conference on Machine Learning, 2009. To Appear.
(page 12)
Ryan Prescott Adams and Oliver Stegle. Gaussian process product models for non-
parametric nonstationarity. In Andrew McCallum and Sam Roweis, editors, Pro-
ceedings of the 25th International Conference on Machine Learning, pages 1–8, 2008.
Ryan Prescott Adams, Iain Murray, and David J. C. MacKay. Nonparametric Bayesian
density modeling with Gaussian processes. In ICML/UAI/COLT Workshop on Non-
parametric Bayes, 2008.
(page 12)
Ryan Prescott Adams, Iain Murray, and David J. C. MacKay. The Gaussian process
density sampler. In Advances in Neural Information Processing Systems 21, Cambridge,
MA, 2009a. MIT Press.
(page 12)
Ryan Prescott Adams, Iain Murray, and David J. C. MacKay. Nonparametric Bayesian
density modeling with Gaussian processes. In Preparation, 2009b.
(page 12)
Ryan Prescott Adams, Iain Murray, and David J. C. MacKay. Tractable nonparametric
Bayesian inference in Poisson processes with Gaussian process intensities. In Leon
Bottou and Michael Littman, editors, Proceedings of the 26th International Conference
on Machine Learning, 2009c. To Appear.
(page 12)

BIBLIOGRAPHY
130
Stephen L. Adler. Over-relaxation method for the Monte Carlo evaluation of the par-
tition function for multiquadratic actions. Physics Review D, 23(12):2901–2904, 1981.
(page 55)
S. Aeberhard, D. Coomans, and O. de Vel. Comparison of classiﬁers in high dimen-
sional settings. Technical Report 92-02, Department of Computer Science, James
Cook University, North Queensland, 1992.
(page 109)
Christophe Andrieu, Nando de Freitas, Arnaud Doucet, and Michael I. Jordan. Intro-
duction to MCMC for machine learning. Machine Learning, 50(1):5–43, 2003. (page 44)
Nachman Aronszajn. Theory of reproducing kernels. Transactions of the American Math-
ematical Society, 68(3):337–404, 1950.
(page 5)
A. Asuncion and D.J. Newman. UCI machine learning repository, 2007.
(page 109)
Melvin Avrami. Kinetics of phase change I: General theory. Journal of Chemical Physics,
7(12):1103–1112, 1939.
(page 31)
Melvin Avrami. Kinetics of phase change II: Transformation-time relations for random
distribution of nuclei. Journal of Chemical Physics, 8(2):212–224, 1940.
(page 31)
Melvin Avrami. Kinetics of phase change III: Granulation, phase change, and mi-
crostructure. Journal of Chemical Physics, 9(2):177–184, 1941.
(page 31)
Claus Beisbart and Martin Kerscher. Luminosity- and morphology-dependent clus-
tering of galaxies. The Astrophysical Journal, 545(1):6–25, December 2000.
(page 30)
Jos´e M. Bernardo. The concept of exchangeability and its applications. Far East Journal
of Mathematical Sciences, 4:111–121, 1996.
(page 19)
Alexandros Beskos, Omiros Papaspiliopoulos, and Gareth O. Roberts. Retrospective
exact simulation of diffusion sample paths with applications. Bernoulli, 12(6):1077–
1098, 2006a.
(page 52)
Alexandros Beskos, Omiros Papaspiliopoulos, Gareth O. Roberts, and Paul Fearn-
head. Exact and computationally efﬁcient likelihood-based estimation for discretely
observed diffusion processes. Journal of the Royal Statistical Society, Series B, 68:333–
382, 2006b.
(pages 52 and 66)
Edwin V. Bonilla, Kian Ming A. Chai, and Christopher K. I. Williams. Multi-task Gaus-
sian process prediction. In J.C. Platt, D. Koller, Y. Singer, and S. Roweis, editors,
Advances in Neural Information Processing System 20, pages 153–160. MIT Press, Cam-
bridge, MA, 2008.
(page 115)
Karsten M. Borgwardt. Graph Kernels. PhD thesis, Ludwig-Maximilians University,
Munich, 2007.
(page 114)

BIBLIOGRAPHY
131
Karsten M. Borgwardt, Cheng Soon Ong, Stefan Sch¨onauer, S. V. N. Vishwanathan,
Alex J. Smola, and Hans-Peter Kriegel. Protein function prediction via graph ker-
nels. Bioinformatics, 21(1):47–56, 2005.
(page 114)
Anders Brix and Jo¨el Chadœuf. Spatio-temporal modelling of weeds by shot-noise G
Cox processes. Biometrical Journal, 44(1):83–99, 2002.
(page 32)
Emery N. Brown. Theory of Point Processes for Neural Systems, chapter 14, pages 691–
726. Elsevier, Paris, 2005.
(page 9)
Siddhartha Chib and Ivan Jeliazkov.
Marginal likelihood from the Metropolis–
Hastings output. Journal of the American Statistical Association, 96(453):270–281, 2001.
(page 95)
Wei Chu, Vikas Sindhwani, Zoubin Ghahramani, and S. Sathiya Keerthi. Relational
learning with Gaussian processes. In B. Sch¨olkopf, J. Platt, and T. Hoffman, editors,
Advances in Neural Information Processing Systems 19, pages 289–296, Cambridge,
MA, 2007. MIT Press.
(page 101)
Michael Collins and Nigel Duffy. Convolution kernels for natural language. In T. G.
Dietterich, S. Becker, and Z. Ghahramani, editors, Advances in Neural Information
Processing System 14, pages 625–632, Cambridge, MA, 2001. MIT Press.
(page 114)
Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein.
Introduction to Algorithms.
MIT Press, Cambridge, MA, second edition, 2001.
(pages 21 and 83)
Thomas M. Cover and Joy A. Thomas. Elements of Information Theory. John Wiley and
Sons, Inc., Hoboken, New Jersey, second edition, 2006.
(page 44)
David R. Cox. Some statistical methods connected with series of events. Journal of the
Royal Statistical Society, Series B, 17(2):129–164, 1955.
(page 9)
Noel A. C. Cressie. Statistics for Spatial Data. Wiley-Interscience, New York, 1991.
(page 3)
Lehel Csat´o. Gaussian Processes - Iterative Sparse Approximations. PhD thesis, Aston
University, Birmingham, UK, March 2002.
(page 10)
John P. Cunningham, Krishna V. Shenoy, and Maneesh Sahani. Fast Gaussian process
methods for point process intensity estimation.
In Andrew McCallum and Sam
Roweis, editors, Proceedings of the 25th International Conference on Machine Learning,
pages 192–199, 2008a.
(pages 11 and 12)
John P. Cunningham, Byron M. Yu, Krishna V. Shenoy, and Maneesh Sahani. Inferring
neural ﬁring rates from spike trains using Gaussian processes. In J. Platt, D. Koller,
Y. Singer, and S. Roweis, editors, Advances in Neural Information Processing Systems
20, Cambridge, MA, 2008b. MIT Press.
(page 9)

BIBLIOGRAPHY
132
Luc Devroye. Non-Uniform Random Variate Generation. Springer–Verlag, New York,
1986.
(pages 17, 25, and 26)
Peter Diggle. A kernel method for smoothing point process data. Applied Statistics, 34
(2):138–147, 1985.
(pages 1 and 91)
Peter Diggle. Statistical Analysis of Spatial Point Patterns. Oxford University Press,
Oxford, 2003.
(page 36)
Ilaria DiMatteo, Christopher R. Genovese, and Robert E. Kass. Bayesian curve-ﬁtting
with free-knot splines. Biometrika, 88(4):1055–1071, 2001.
(page 2)
Simon Duane, A. D. Kennedy, Brian J. Pendleton, and Duncan Roweth. Hybrid Monte
Carlo. Physics Letters B, 195(2):216–222, 1987.
(pages 45, 70, and 75)
David B. Dunson and Ju-Hyun Park. Kernel stick-breaking processes. Biometrika, 95
(2):307–323, 2008.
(page 114)
Michael D. Escobar and Mike West. Bayesian density estimation and inference using
mixtures. Journal of the American Statistical Association, 90(430):577–588, June 1995.
(pages 2, 101, and 115)
Thomas S. Ferguson. A Bayesian analysis of some nonparametric problems. The An-
nals of Statistics, 1(2):209–230, 1973.
(pages 2 and 16)
Thomas S. Ferguson. Prior distributions on spaces of probability measures. The Annals
of Statistics, 2(4):615–629, 1974.
(page 2)
Thomas G¨artner, Peter Flach, and Stefan Wrobel. On graph kernels: Hardness results
and efﬁcient alternatives.
In Proceedings of the 16th Annual Conference on Compu-
tational Learning Theory and 7th Kernel Workshop, pages 129–143. Springer–Verlag,
August 2003.
(page 114)
Andrew Gelman, John B. Carlin, Hal S. Stern, and Donald B. Rubin.
Bayesian
Data Analysis.
Chapman and Hall/CRC, New York, second edition, 2004.
(pages 44 and 71)
Stuart Geman and Donald Geman.
Stochastic relaxation, Gibbs distribution and
Bayesian restoration of images. IEEE Transactions on Pattern Analysis and Machine
Intelligence, 6:721–741, 1984.
(page 45)
Jayanta K. Ghosh and R. V. Ramamoorthi. Bayesian Nonparametrics. Springer-Verlag,
Berlin, 2003.
(page 2)
Mark N. Gibbs. Bayesian Gaussian Processes for Regression and Classiﬁcation. PhD thesis,
University of Cambridge, Cambridge, 1997.
(page 4)

BIBLIOGRAPHY
133
Kay Giesecke and Baeho Kim. Estimating tranche spreads by loss process simulation.
In S. G. Henderson, B. Biller, M. H. Hsieh, J. Shortle, J. D. Tew, and R. R. Barton,
editors, Proceedings of the 2007 Winter Simulation Conference, pages 967–975, 2007.
(page 34)
Mark Girolami and Simon Rogers. Variational Bayesian multinomial probit regression
with Gaussian process priors. Neural Computation, 18(8):1790–1817, 2006. (page 108)
Leon Glass and Waldo R. Tobler. Uniform distribution of objects in a homogeneous
ﬁeld: cities on a plain. Nature, 233(5314):67–68, September 1971.
(pages 36 and 38)
Noah D. Goodman, Vikash K. Mansinghka, Daniel M. Roy, Keith Bonawitz, and
Joshua B. Tenenbaum. Church: a language for generative models. In Proceedings
of the 24th Annual Conference on Uncertainty in Artiﬁcial Intelligence, 2008.
(page 66)
Peter J. Green. Reversible jump Markov chain Monte Carlo computation and Bayesian
model selection. Biometrika, 82:711–732, 1995.
(page 1)
Phil C. Gregory and Thomas J. Loredo. A new method for the detection of a periodic
signal of unknown shape and period. The Astrophysical Journal, 398:146–168, October
1992.
(page 9)
Jim E. Grifﬁn and Mark F. J. Steel. Time-depenent stick-breaking processes. Technical
report, Institute of Mathematics, Statistics and Actuarial Science, University of Kent,
2009.
(page 114)
Thomas L. Grifﬁths and Zoubin Ghahramani. Inﬁnite latent feature models and the
Indian buffet process. In Advances in Neural Information Processing Systems 18, pages
475–482, Cambridge, MA, 2006. MIT Press.
(page 2)
Olle H¨aggstr¨om, Marie-Colette N. M. van Lieshout, and Jesper Møller. Characteriza-
tion results and Markov chain Monte Carlo algorithms including exact simulation
for some spatial point processes. Bernoulli, 5(4):641–659, 1999.
(page 32)
W. Keith Hastings. Monte Carlo sampling methods using Markov chains and their
applications. Biometrika, 57(1):97–109, April 1970.
(page 45)
David Haussler. Convolution kernels on discrete structures. Technical Report UCSC-
CRL-99-10, University of California at Santa Cruz, 1999.
(pages 113 and 114)
Alan G. Hawkes. Point spectra of some mutually exciting point processes. Journal of
the Royal Statistical Society, Series B, 33(3):438–443, 1971a.
(pages 31 and 34)
Alan G. Hawkes. Spectra of some self-exciting and mutually exciting point processes.
Biometrika, 58(1):83–90, April 1971b.
(pages 31 and 34)
Alan G. Hawkes. Spectra of some mutually exciting point processes with associated
variables. In Peter A. W. Lewis, editor, Stochastic Point Processes, pages 261–271. John
Wiley and Sons, New York.
(pages 31 and 34)

BIBLIOGRAPHY
134
Alan G. Hawkes and Leonidas Adamopoulos. Cluster models for earthquakes – re-
gional comparisons. Bulletin of the International Statistical Institute, 45:454–461, 1973.
(page 34)
Alan G. Hawkes and David Oakes. A cluster representation of a self-exciting process.
Journal of Applied Probability, 11(3):493–503, September 1974.
(pages 31 and 34)
Juha Heikkinen and Elja Arjas. Modeling a Poisson forest in variable elevations: a
nonparametric Bayesian approach. Biometrics, 55:738–745, 1999.
(page 9)
Edwin Hewitt and Leonard Jimmie Savage. Symmetric measures on Cartesian prod-
ucts. Transactions of the American Mathematical Society, 80:470–501, 1955.
(page 19)
Philip Holgate. Studies in the history of probability and statistics XXXIX: Buffon’s
cycloid. Biometrika, 68(3):712–716, December 1981.
(page 18)
John J. Hopﬁeld.
Neural networks and physical systems with emergent collective
computational abilities. Proceedings of the National Academy of Sciences of the USA, 79
(8):2554–2558, April 1982.
(page 46)
Mark L. Huber and Robert L. Wolpert. Perfect simulation of Mat´ern type III repulsive
point processes. In Preparation, 2009.
(pages 37, 38, 41, 66, and 81)
Hemant Ishwaran and Lancelot F. James. Gibbs sampling methods for stick-breaking
priors. Journal of the American Statistical Association, 96(453):161–173, March 2001.
(page 2)
Ernst Ising. Beitrag zur theorie des ferromagnetismus. Zeitschrift f¨ur Physik, 31:253–
258, 1925.
(page 46)
R. G. Jarrett. A note on the intervals between coal-mining disasters. Biometrika, 66(1):
191–193, 1979.
(page 93)
Don H. Johnson. Point process models of single-neuron discharges. Journal of Compu-
tational Neuroscience, 3(4):275–299, December 1996.
(page 34)
William A. Johnson and Robert F. Mehl.
Reaction kinetics in processes of nucle-
ation and growth. Transactions of the American Institute of Mining, Metallurgical and
Petroleum Engineers, 135:410–458, 1939.
(page 31)
Francis P. Kelly and Brian D. Ripley.
A note on Strauss’s model for clustering.
Biometrika, 63(2):357–360, August 1976.
(pages 31, 38, and 48)
Wilfrid S. Kendall. Perfect simulation for spatial point processes. In Proceedings of the
51st Session of the International Statistical Institute: Simulation of Stochastic Processes in
Engineering, Istanbul, pages 163–166, 1997.
(page 32)

BIBLIOGRAPHY
135
Wilfrid S. Kendall and Jesper Møller. Perfect simulation using dominating processes
on ordered spaces, with application to locally stable point processes. Advances in
Applied Probability, 32(3):844–865, 2000.
(page 32)
Andrey N. Kolmogorov.
Zur statistik der kristallisationsvorg¨ange in metallen.
Izvestiya Rossiiskoi Akademii Nauk, Seriya Matematicheskaya, 1(3):355–359, 1937.
(page 31)
Andrey N. Kolmogorov. Selected Works of A. N. Kolmogorov, Volume II: Probability The-
ory and Mathematical Statistics. Mathematics and Its Applications. Springer-Verlag,
Berlin, 1992.
(page 31)
Risi I. Kondor. Group Theoretical Methods in Machine Learning. PhD thesis, Columbia
University, New York, NY, May 2008.
(page 113)
Risi I. Kondor and Tony Jebara. A kernel between sets of vectors. In T. Fawcett and
N. Mishra, editors, Proceedings of the 20th International Conference on Machine Learn-
ing, pages 361–368, 2003.
(page 114)
Risi I. Kondor and John D. Lafferty.
Diffusion kernels on graphs and other dis-
crete structures.
In Claude Sammut and Achim G. Hoffmann, editors, Proceed-
ings of the 19th International Conference on Machine Learning, pages 315–322, 2002.
(pages 113 and 114)
Athanasios Kottas and Bruno Sans´o. Bayesian mixture modeling for spatial Poisson
process intensities, with applications to extreme value analysis. Journal of Statistical
Planning and Inference, 137:3151–3163, 2007.
(page 2)
Michael Lavine. Some aspects of P´olya tree distributions for statistical modelling. The
Annals of Statistics, 20(3):1222–1235, 1992.
(page 2)
Michael Lavine. More aspects of P´olya tree distributions for statistical modelling. The
Annals of Statistics, 22(3):1161–1175, 1994.
(page 2)
Neil D. Lawrence. Probabilistic non-linear principal component analysis with Gaus-
sian process latent variable models. Journal of Machine Learning Research, 6:1783–
1816, 2005.
(pages 10 and 11)
Neil D. Lawrence and Michael I. Jordan. Semi-supervised learning via Gaussian pro-
cesses. In L. Saul, Y. Weiss, and L. Bouttou, editors, Advances in Neural Information
Processing Systems 17, Cambridge, MA, 2005. MIT Press.
(pages 101, 108, and 109)
Andrew B. Lawson and David G. T. Dension. Spatial Cluster Modelling. Monographs on
Statistics and Applied Probability. Chapman and Hall/CRC, Boca Raton, FL, 2002.
(page 32)
Georges-Louis Leclerc de Buffon.
Essai d’arithm´etique morale.
In Suppl´ement `a
l’Histoire Naturelle, volume 4. Imprimerie Royale, Paris, 1777.
(page 18)

BIBLIOGRAPHY
136
Subhash R. Lele and Joan T. Richtsmeier. An Invariant Approach to Statistical Analysis of
Shapes. Chapman and Hall/CRC Press, London, 2001.
(page 90)
Gareth Leng, Colin H. Brown, Philip M. Bull, David Brown, Sinead Scullion, James
Currie, Ruth E. Blackburn-Monroe, Jianfeng Feng, Tatsushi Onaka, Joseph G. Ver-
balis, John A. Russell, and Mike Ludwig. Responses of magnocellular neurons to
osmotic stimulation involves coactivation of excitatory and inhibitory input: an ex-
perimental and theoretical analysis. The Journal of Neuroscience, 21(17):6967–6977,
September 2001.
(page 40)
Peter J. Lenk. The logistic normal distribution for Bayesian, nonparametric, predictive
densities. Journal of the American Statistical Association, 83(402):509–516, 1988. (page 7)
Peter J. Lenk.
Towards a practicable Bayesian nonparametric density estimator.
Biometrika, 78(3):531–543, 1991.
(pages 7, 8, and 85)
Peter J. Lenk. Bayesian semiparametric density estimation and model veriﬁcation us-
ing a logistic-Gaussian process. Journal of Computational and Graphical Statistics, 12
(3):548–565, 2003.
(page 8)
Tom Leonard. Density estimation, stochastic processes and prior information. Journal
of the Royal Statistical Society, Series B, 40(2):113–146, 1978.
(page 7)
Christina S. Leslie, Eleazar Eskin, Adiel Cohen, Jason Weston, and William Stafford
Noble. Mismatch string kernels for discriminative protein classiﬁcation. Bioinfor-
matics, 20(4):467–476, 2004.
(page 114)
Peter A. W. Lewis and Gerald S. Shedler. Simulation of a nonhomogeneous Poisson
process by thinning. Naval Research Logistics Quarterly, 26:403–413, 1979.
(page 26)
D. V. Lindley. Approximate Bayesian methods. In J. M. Bernardo, M. H. DeGroot,
D. V. Lindley, and A. F. M. Smith, editors, Bayesian Statistics, pages 223–237. Valencia
University Press, Valencia, 1980.
(page 1)
Albert Y. Lo. On a class of Bayesian nonparametric estimates: I. density estimates. The
Annals of Statistics, 12(1):351–357, March 1984.
(page 2)
Huma Lodhi, Craig Saunders, John Shawe-Taylor, Nello Cristianini, and Chris
Watkins. Text classiﬁcation using string kernels. Journal of Machine Learning Re-
search, 2:419–444, February 2002.
(page 114)
Steven N. MacEachern. Dependent nonparametric processes. Technical report, De-
partment of Statistics, The Ohio State University, 2000.
(page 114)
David J. C. MacKay. Bayesian interpolation. Neural Computation, 4(3):415–447, 1992a.
(page 2)

BIBLIOGRAPHY
137
David J. C. MacKay. A practical Bayesian framework for backpropagation networks.
Neural Computation, 4(3):448–472, 1992b.
(page 1)
David J. C. MacKay. Bayesian neural networks and density networks. Nuclear Instru-
ments and Methods in Physics Research, Section A, 354(1):73–80, 1995.
(page 11)
David J. C. MacKay. Introduction to Gaussian processes. In C.M. Bishop, editor, Neural
Networks and Machine Learning, NATO ASI Series, pages 133–166. Kluwer, 1998a.
(page 5)
David J. C. MacKay. Choice of basis for Laplace approximation. Machine Learning, 33
(1):77–86, 1998b.
(page 1)
David J. C. MacKay. Information Theory, Inference, and Learning Algorithms. Cambridge
University Press, Cambridge, 2003.
(pages 17, 18, 44, and 70)
Prasanta C. Mahalanobis. On the generalised distance in statistics. Proceedings of the
National Institute of Sciences of India, 2(1):49–55, 1936.
(page 41)
Bertil Mat´ern. Spatial variation. Meddelanden fr˚an Statens Skogsforskningsinstitut (Re-
ports of the Forest Research Institute of Sweden), 49(5), 1960.
(pages 31, 33, and 37)
Bertil Mat´ern. Spatial Variation. Lecture Notes in Statistics. Springer-Verlag, Berlin,
second edition, 1986.
(page 31)
R. Daniel Mauldin, William D. Sudderth, and S. C. Williams. P´olya trees and random
distributions. The Annals of Statistics, 20(3):1203–1221, September 1992.
(page 2)
Nicholas Metropolis, Arianna W. Rosenbluth, Marshall N. Rosenbluth, Augusta H.
Teller, and Edward Teller. Equations of state calculations by fast computing ma-
chines. Journal of Chemical Physics, 21(6):1087–1092, 1953.
(page 45)
Paul-Andr´e Meyer. D´emonstration simpliﬁ´ee d’un th´eor`eme de Knight. S´eminaire des
Probabilit´es de Strasbourg V, 191:191–195, 1971.
(page 26)
Thomas P. Minka. A Family of Algorithms for Approximate Bayesian Inference. PhD thesis,
Massachusetts Institute of Technology, Cambridge, MA, January 2001.
(page 1)
Ilya Molchanov. Statistics of the Boolean Model for Practitioners and Mathematicians. Prob-
ability and Statistics. John Wiley and Sons, New York, 1997.
(page 31)
Jesper Møller and Giovanni Luca Torrisi. Generalised shot noise Cox processes. Ad-
vances in Applied Probability, 37(1):48–74, 2005.
(page 32)
Jesper Møller and Rasmus Plenge Waagepetersen. Statistical Inference and Simulation for
Spatial Point Processes. Monographs on Statistics and Applied Probability. Chapman
and Hall/CRC, Boca Raton, FL, 2004.
(pages 9, 23, 24, 30, 31, and 33)

BIBLIOGRAPHY
138
Jesper Møller, Anne Randi Syversveen, and Rasmus Plenge Waagepetersen.
Log
Gaussian Cox processes.
Scandinavian Journal of Statistics, 25:451–482, 1998.
(pages 9, 10, 12, and 91)
Jesper Møller, Anthony N. Pettitt, Robert Reeves, and Kasper K. Berthelsen. An efﬁ-
cient Markov chain Monte Carlo method for distributions with intractable normal-
ising constants. Technical Report R-2004-02, Department of Mathematical Sciences,
Aalborg University, 2004.
(pages 46, 47, and 48)
Jesper Møller, Anthony N. Pettitt, Robert Reeves, and Kasper K. Berthelsen. An efﬁ-
cient Markov chain Monte Carlo method for distributions with intractable normal-
ising constants. Biometrika, 93(2):451–458, 2006.
(pages 47 and 48)
Peter M¨uller, Fernando Quintana, and Gary Rosner. A method for combining infer-
ence across related nonparametric Bayesian models. Journal of the Royal Statistical
Society, Series B, 66(3):735–749, 2004.
(pages 16 and 114)
Iain Murray.
Advances in Markov Chain Monte Carlo Methods.
PhD thesis, Gatsby
Computational Neuroscience Unit, University College London, London, 2007.
(pages 46, 48, 56, and 66)
Iain Murray, Zoubin Ghahramani, and David J.C. MacKay.
MCMC for doubly-
intractable distributions. In Proceedings of the 22nd Annual Conference on Uncertainty
in Artiﬁcial Intelligence, pages 359–366, 2006.
(pages 8 and 48)
Radford M. Neal. Priors for inﬁnite networks. Technical Report CRG-TR-94-1, Depart-
ment of Computer Science, University of Toronto, 1994.
(page 3)
Radford M. Neal. Bayesian Learning for Neural Networks. Springer–Verlag, Berlin, 1996.
(pages 5 and 70)
Radford M. Neal.
Monte Carlo implementation of Gaussian process models for
Bayesian regression and classiﬁcation. Technical Report 9702, Department of Statis-
tics, University of Toronto, 1997.
(page 107)
Radford M. Neal. Supressing random walks in Markov chain Monte Carlo using or-
dered overrelaxation. In Learning in Graphical Models, pages 205–225. Kluwer Aca-
demic Publishers, Dordrecht, 1998.
(pages 55 and 71)
Radford M. Neal. Markov chain sampling methods for Dirichlet process mixture mod-
els. Journal of Computational and Graphical Statistics, 9(2):249–265, 2000.
(page 89)
Radford M. Neal.
Deﬁning priors for distributions using Dirichlet diffusion trees.
Technical Report 0104, Department of Statistics, University of Toronto, 2001. (page 2)
Radford M. Neal. Density modeling and clustering using Dirichlet diffusion trees. In
Bayesian Statistics 7, pages 619–629, 2003a.
(pages 2 and 89)

BIBLIOGRAPHY
139
Radford M. Neal. Slice sampling (with discussion). The Annals of Statistics, 31(3):705–
767, 2003b.
(page 45)
Radford M. Neal.
Improving asymptotic variance of MCMC estimators:
non-
reversible chains are better. Technical Report 0406, Department of Statistics, Uni-
versity of Toronto, 2004.
(page 45)
Roger B. Nelsen. An Introduction to Copulas. Springer–Verlag, Berlin, second edition,
2007.
(page 15)
Jerzy Neyman and Elizabeth L. Scott. Statistical approach to cosmology. Journal of the
Royal Statistical Society, Series B, 20(1):1–43, 1958.
(pages 31 and 33)
Martin Niss. History of the Lenz–Ising model 1920-1950: From ferromagnetic to coop-
erative phenomena. Archive for History of Exact Sciences, 59(3):267–318, March 2005.
(page 46)
Yosihiko Ogato and Masaharu Tanemura. Likelihood estimation of soft-core interac-
tion potentials for Gibbsian point patterns. Annals of the Institute of Statistical Mathe-
matics, 41(3):583–600, 1989.
(pages 31 and 39)
Anthony O’Hagan. Curve ﬁtting and optimal design for prediction. Journal of the Royal
Statistical Society, Series B, 40(1):1–42, 1978.
(pages 2 and 3)
Christopher J. Paciorek. Nonstationary Gaussian Processes for Regression and Spatial Mod-
elling. PhD thesis, Carnegie Mellon University, Pittsburgh, PA, 2003.
(page 4)
Fredos Papangelou.
Integrability of expected increments of point processes and a
related random change of scale. Transactions of the American Mathematical Society,
165:483–506, March 1972.
(page 26)
Omiros Papaspiliopoulos and Gareth O. Roberts. Retrospective Markov chain Monte
Carlo methods for Dirichlet process hierarchical models. Biometrika, 95(1):169–186,
2008.
(page 52)
Emanuel Parzen.
On estimation of a probability density function and mode.
The
Annals of Mathematical Statistics, 33(3):1065–1076, 1962.
(pages 1 and 89)
Antti Penttinen and Dietrich Stoyan. Statistical analysis for a class of line segment
processes. Scandinavian Journal of Statistics, 16(2):153–168, 1989.
(pages 36 and 37)
Jim Pitman and Marc Yor. The two-parameter Poisson-Dirichlet distribution derived
from a stable subordinator. The Annals of Probability, 25:855–900, 1997.
(page 2)
James G. Propp and David B. Wilson. Exact sampling with coupled Markov chains
and applications to statistical mechanics. Random Structures and Algorithms, 9(1&2):
223–252, 1996.
(pages 32, 48, and 66)

BIBLIOGRAPHY
140
Joaquin Qui˜nonero-Candela and Carl Edward Rasmussen. A unifying view of sparse
approximate Gaussian process regression. Journal of Machine Learning Research, 6:
1935–1959, December 2005.
(page 112)
Carl Edward Rasmussen. Evaluation of Gaussian Processes and Other Methods for Non-
Linear Regression. PhD thesis, University of Toronto, Toronto, Ontario, March 1996.
(pages 55, 70, and 71)
Carl Edward Rasmussen. The inﬁnite Gaussian mixture model. In S.A. Solla, T.K.
Leen, and K.-R. M¨uller, editors, Advances in Neural Information Processing Systems 12,
pages 554–560, Cambridge, MA, 2000. MIT Press.
(pages 2, 89, 101, and 115)
Carl Edward Rasmussen and Christopher K. I. Williams. Gaussian Processes for Machine
Learning. MIT Press, Cambridge, MA, 2006.
(pages 3, 4, 5, 14, 109, and 113)
Stephen L. Rathbun and Noel Cressie. Asymptotic properties of estimators for the
parameters of spatial inhomogeneous Poisson point processes. Advances in Applied
Probability, 26(1):122–154, March 1994.
(pages 9 and 91)
Brian D. Ripley.
Modelling spatial patterns (with discussion).
Journal of the Royal
Statistical Society, Series B, 39:172–212, 1977.
(page 93)
Brian D. Ripley. Spatial Statistics. Probability and Mathematical Statistics. John Wiley
and Sons, New York, 1981.
(pages 36 and 38)
Christian P. Robert and George Casella. Monte Carlo Statistical Methods. Springer–
Verlag, Berlin, second edition, 2004.
(page 17)
Simon Rogers and Mark Girolami.
Multi-class semi-supervised learning with the
ϵ-truncated multinomial probit Gaussian process.
In JMLR Workshop and Con-
ference Proceedings: Gaussian Processes in Practice, volume 1, pages 17–32, 2007.
(pages 108 and 109)
Murray Rosenblatt. Remarks on some nonparametric estimates of a density function.
The Annals of Mathematical Statistics, 27(3):832–837, September 1956. (pages 1 and 89)
Gideon Schwarz. Estimating the dimension of a model. Annals of Statistics, 6(2):461–
464, 1978.
(page 1)
Vikas Sindhwani, Wei Chu, and S. Sathiya Keerthi. Semi-supervised Gaussian process
classiﬁers. In International Joint Conference on Artiﬁcial Intelligence, pages 1059–1064,
2007.
(page 101)
Paul Smolensky.
Information processing in dynamical systems:
foundations of
harmony theory.
In Parallel Distributed Processing: Explorations in the Microstruc-
ture of Cognition:
Volume 1, pages 194–281. MIT Press, Cambridge, MA, 1986.
(pages 8 and 46)

BIBLIOGRAPHY
141
Edward Snelson, Carl Edward Rasmussen, and Zoubin Ghahramani. Warped Gaus-
sian processes. In S. Thrun, L. Saul, and B. Sch¨olkopf, editors, Advances in Neural
Information Processing Systems 16, Cambridge, MA, 2004. MIT Press.
(page 14)
Nathan Srebro and Sam Roweis. Time-varying topic models using dependent Dirich-
let processes. Technical Report UTML TR 2005-003, Department of Computer Sci-
ence, University of Toronto, Toronto, ON, 2005.
(page 114)
Richard B. Stein. A theoretical analysis of neuronal variability. Biophysical Journal, 5
(2):173–194, March 1965.
(page 40)
Dietrich Stoyan and Helga Stoyan. On one of Mat´ern’s hard-core point process mod-
els. Mathematische Nachrichten, 122(1):205–214, 1985.
(page 37)
Dietrich Stoyan and Helga Stoyan.
Fractals, Random Shapes and Point Fields.
Probability and Mathematical Statistics. John Wiley and Sons, New York, 1994.
(pages 9, 33, and 36)
Dietrich Stoyan and Helga Stoyan.
Non-homogeneous Gibbs process models for
forestry – a case study. Biometrical Journal, 40(5):521–531, 1998.
(pages 31 and 39)
David J. Strauss.
A model for clustering.
Biometrika, 62(2):467–475, August 1975.
(pages 31, 38, and 48)
Yee Whye Teh, Matthias Seeger, and Michael I. Jordan. Semiparametric latent factor
models. In R. G. Cowell and Z. Ghahramani, editors, Proceedings of the Tenth Interna-
tional Workshop on Artiﬁcial Intelligence and Statistics, pages 333–340, 2005. (page 115)
Malvin Carl Teich, Leonard Matin, and Barry I. Cantor. Refractoriness in the main-
tained discharge of the cat’s retinal ganglion cell. Journal of the Optical Society of
America, 68(3):386–402, 1978.
(page 40)
Marjorie Thomas.
A generalization of Poisson’s binomial limit for use in ecology.
Biometrika, 36(1):18–25, June 1949.
(page 33)
Daniel Thorburn. A Bayesian approach to density estimation. Biometrika, 73(1):65–75,
1986.
(page 7)
Michael E. Tipping and Christopher M. Bishop. Probabilistic principal components
analysis. Journal of the Royal Statistical Society, Series B, 61(3):611–622, 1999. (page 11)
Surya T. Tokdar. Exploring Dirichlet Mixture and Logistic Gaussian Process Priors in Den-
sity Estimation, Regression and Sufﬁcient Dimension Reduction. PhD thesis, Purdue
University, West Lafayette, Indiana, USA, August 2006.
(page 7)
Surya T. Tokdar. Towards a faster implementation of density estimation with logistic
Gaussian process priors. Journal of Computational and Graphical Statistics, 16(2):1–23,
2007.
(pages 8, 54, 85, and 87)

BIBLIOGRAPHY
142
Surya T. Tokdar and Jayanta K. Ghosh.
Posterior consistency of logistic Gaussian
process priors in density estimation. Journal of Statistical Planning and Inference, 137:
34–42, 2007.
(pages 7 and 16)
Vladmir N. Vapnik. The Nature of Statistical Learning Theory. Springer-Verlag, Berlin,
1995.
(page 11)
William N. Venables and Brian D. Ripley. Modern Applied Statistics with S-PLUS. Statis-
tics and Computing. Springer–Verlag, Berlin, 1998.
(page 36)
Francesco Vivarelli and Christopher K. I. Williams. Discovering hidden features with
Gaussian process regression. In M. J. Kearns, S. A. Solla, and D. A. Cohn, editors,
Advances in Neural Information Processing Systems 11, Cambridge, MA, 1999. MIT
Press.
(page 41)
John von Neumann. Various techniques used in connection with random digits. Na-
tional Bureau of Standards, Applied Mathematics Series, 12:36–38, 1951.
(page 18)
Stephen G. Walker, Paul Damien, Purushottam W. Laud, and Adrian F. M. Smith.
Bayesian nonparametric inference for random distributions and related functions.
Journal of the Royal Statistical Society, Series B, 61(3):485–527, 1999.
(page 2)
Christopher J. C. H. Watkins. Dynamic alignment kernels. In A. Smola and P. Bartlett,
editors, Advances in Large Margin Classiﬁers, chapter 3, pages 39–50. MIT Press, Cam-
bridge, MA, 2000.
(page 114)
Norbert Wiener. Extrapolation, Interpolation and Smoothing of Stationary Time Series. MIT
Press, Cambridge, MA, 1949.
(page 3)
Christopher K. I. Williams and David Barber. Bayesian classiﬁcation with Gaussian
processes. IEEE Transactions on Pattern Analysis and Machine Intelligence, 20(12):1342–
1351, 1998.
(pages 108 and 109)
Christopher K. I. Williams and Carl Edward Rasmussen. Gaussian processes for re-
gression. In D.S. Touretzky, M.C. Mozer, and M.E. Hasselmo, editors, Advances in
Neural Information Processing Systems 8, pages 514–520, Cambridge, MA, 1996. MIT
Press.
(pages 3 and 71)
Katherine E. Willmore, Christian P. Klingenberg, and Benedikt Hallgrimsson.
The
relationship between ﬂuctuating asymmetry and environmental variance in rhesus
macaque skulls. Evolution, 59(4):898–909, 2005.
(page 90)
David B. Wilson. How to couple from the past using a read-once source of random-
ness. Random Structures and Algorithms, 16(1):85–113, 2000.
(page 32)
Nikos Yannaros. On Cox processes and gamma renewal processes. Journal of Applied
Probability, 25(2):423–427, June 1988.
(page 40)

