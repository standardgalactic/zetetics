
A Guide to Morphosyntax-Phonology Interface Theories


A Guide
to Morphosyntax-Phonology
Interface Theories
How Extra-Phonological Information is Treated
in Phonology since Trubetzkoy’s Grenzsignale
by
Tobias Scheer
De Gruyter Mouton

ISBN 978-3-11-023862-4
e-ISBN 978-3-11-023863-1
Library of Congress Cataloging-in-Publication Data
Scheer, Tobias, 1968
A guide to morphosyntax-phonology interface theories : how
extra-phonological information is treated in phonology since Tru-
betzkoy’s Grenzsignale / by Tobias Scheer.
p. cm.
Includes bibliographical references and index.
ISBN 978-3-11-023862-4 (hardcover : alk. paper)
1.
Grammar,
Comparative
and
general

Morphosyntax.
2. Grammar, Comparative and general  Phonology.
3. Historical
linguistics.
I. Title.
P241.S416
2010
4151.9dc22
2010040348
Bibliographic information published by the Deutsche Nationalbibliothek
The Deutsche Nationalbibliothek lists this publication in the Deutsche Nationalbibliografie;
detailed bibliographic data are available in the Internet at http://dnb.d-nb.de.
 2011 Walter de Gruyter GmbH & Co. KG, Berlin/New York
Cover image: Creatas/Thinkstock
Ra´ko prˇilı´ta´ by Mogdolı´na
Printing: Hubert & Co. GmbH & Co. KG, Göttingen
 Printed on acid-free paper
Printed in Germany
www.degruyter.com

Table of contents ± overview 
 
§
page
Table of contents ± detail ................................................................... vii
Table of graphic illustrations............................................................. xlv
1 Editorial note ................................................................................... xlvii
2 Foreword 
 
The plot, and how to use the book........................................................ il
3
Introduction 
4
1. Procedural and representational communication with  
phonology........................................................................................1
7
2. Functional historiography................................................................3
11 
3. The syntactic frame: minimalist phase theory.................................7
24 
4. Definition of the object of the study..............................................16
34 
5. Trying to get an independent handle on the interface ...................22
42 
6. Deforestation.................................................................................27
47 
7. Structure of the book and of Vol.2................................................31
Part One 
 
Morpho-syntactic information in phonology: a survey  
 since Trubetzkoy's Grenzsignale 
50 
1. The spectrum: what morpho-syntactic information can do to 
phonology......................................................................................35
55 
2. Trubetzkoy's Grenzsignale ............................................................39
59 
3. American structuralism: juncture phonemes.................................43
73 
4. Chomsky, Halle & Lukoff (1956).................................................59
81 
5. SPE sets the standards for 40 years...............................................67
109 
6. The life of boundaries in post-SPE times......................................93
139  7. Lexical Phonology.......................................................................123
215  8. Halle & Vergnaud (1987a): selective spell-out and  
SPE-restoration............................................................................185
258  9. Kaye (1995): selective spell-out and modification-inhibiting  
no look-back................................................................................219
360 10. Prosodic Phonology: on the representational side.......................301
450 11. Optimality Theory.......................................................................385
531 12. Distributed Morphology..............................................................447

vi 
Table of contents ± overview 
§
page
Interlude 
 
Modularity 
587 1. Introduction: the relative absence of modularity in interface 
thinking........................................................................................497
588 2. Modularity and connectionism, mind and brain..........................499
600 3. The modular architecture of the mind: where it comes from ......515
604 4. The modular architecture of the mind: how it works ..................519
622 5. Modularity of and in language, related systems..........................535
649 6. How modules communicate........................................................557
Part Two 
 
Lessons from interface theories 
656  1. A guide to the interface jungle ....................................................563
657  2. Empirical generalisations ............................................................565
666  3. Issues that are settled...................................................................573
687  4. Modularity, translation, the diacritic issue and local vs.  
domain-based intervention: settled in verb, but not in fact .........589
719  5. Open questions (general).............................................................609
762  6. Open questions (procedural) .......................................................647
841 
Conclusion 
 
Intermodular argumentation 
842  1. Trying to get a handle on the interface........................................705
846  2. Intermodular argumentation........................................................707
863 
References ......................................................................................717
864 
Subject index..................................................................................785
865 
Language index..............................................................................838
866 
Index of phenomena ......................................................................843

Table of contents ± detail 
 
§
page
Table of graphic illustrations ............................................................ xlv
1 Editorial note................................................................................... xlvii
2 Foreword 
The plot, and how to use the book ....................................................... il
3 Introduction 
4 1. Procedural and representational communication with phonology... 1
5
1.1. Cyclic derivation and hashmarks.............................................. 1
6
1.2. Interface Dualism: both means of talking to the phonology  
are needed ................................................................................ 2
7 2. Functional historiography................................................................ 3
8
2.1. Anderson's dualistic legacy: structure and process................... 3
9
2.2. Historiographic cherry-picking................................................. 5
10
2.3. No "external" history: only scholarly work is used .................. 6
11 3. The syntactic frame: minimalist phase theory ................................. 7
12
3.1. The inverted T delineates the scope of the book and serves  
as a referee................................................................................ 7
13
3.2. Interactionism, selective spell-out and no look-back  
devices (PIC) ............................................................................ 8
14
3.2.1. When the generative mainstream became  
interactionist ................................................................... 8
15
3.2.2. Selective spell-out .......................................................... 9
16
3.2.3. No look-back devices (the PIC)...................................... 9
17
3.3. Intermodular argumentation ................................................... 10
18
3.3.1. The intermodular potential of interactionist phase  
theory............................................................................ 10
19
3.3.2. Phase theory is the bridge that forces syntax and 
phonology to converge ................................................. 11

viii 
Table of contents ± detail 
§
page
20
3.4. Focus on the spell-out mechanism(s?).................................... 12
21
3.4.1. Minimalist interface orientation: spell-out marshals  
both morpho-syntax and phonology............................. 12
22
3.4.2. The word-spell-out mystery.......................................... 13
23
3.4.3. We need to know more about the spell-out  
mechanism.................................................................... 14
24 4. Definition of the object of the study .............................................. 16
25
4.1. The book is only about interface theories that follow the 
inverted T................................................................................ 16
26
4.2. Interface theories that lie beyond the inverted T model ......... 17
27
4.2.1. Theories where everything is scrambled: HPSG.......... 17
28
4.2.2. OT and its connectionist endowment: a  
programmed trope for scrambling all into one ............. 17
29
4.2.3. Jackendoff's parallel model: all modules are  
structure-building ......................................................... 19
30
4.3. PF, an androgenic intermundia............................................... 19
31
4.3.1. The minimalist dustbin: clean syntax, dirty  
phonology..................................................................... 19
32
4.3.2. Syntax, morphology, PF............................................... 21
33
4.4. Modularity is the touchstone................................................... 21
34 5. Trying to get an independent handle on the interface.................... 22
35
5.1. Intermodular argumentation, history ...................................... 22
36
5.2. Modularity .............................................................................. 23
37
5.2.1. Generative grammar deeply roots in modularity,  
but is often offended..................................................... 23
38
5.2.2. Modularity in the history of generative grammar: the 
GB-interlude of syntax-internal (nested) modules ....... 24
39
5.2.3. The refereeing potential of modularity lies waste ........ 25
40
5.2.4. Introduction to (Fodorian) modularity.......................... 26
41
5.2.5. Structuralist and generative modularity........................ 27
42 6. Deforestation.................................................................................. 27
43
6.1. The core of Government Phonology: lateral, rather than 
arboreal syllable structure....................................................... 27
44
6.2. The lateral project leaves no place for arboreal prosodic 
constituency............................................................................ 28
45
6.3. Recursion and other expected consequences of trees are  
absent in phonology................................................................ 29
46
6.4. The lateral project predicts that phonology is non-recursive.. 30

Table of contents ± detail ix 
§
page
47 7. Structure of the book and of Vol.2................................................. 31
48
7.1. How to access the book: the story, its relation with current 
syntactic theory and its thematic guide................................... 31
49
7.2. Vol.2: Direct Interface, One-Channel Translation and their 
application to CVCV .............................................................. 32
Part One 
Morpho-syntactic information in phonology:  
a survey since Trubetzkoy's Grenzsignale 
50 Chapter 1 
The spectrum: what morpho-syntactic information can  
do to phonology 
51 1. Boundaries have a triggering, a blocking or no effect ................... 35
52 2. Blocking and triggering effects: illustration .................................. 36
53
2.1. Process-blocking boundaries: French gliding......................... 36
54
2.2. Process-triggering boundaries: obstruent voicing in Puyo 
Pongo...................................................................................... 37
55 Chapter 2 
Trubetzkoy's Grenzsignale 
 
56 1. The cradle of the functional perspective........................................ 39
57 2. Grenzsignale do not contribute anything to the mapping puzzle... 40
58 3. Grenzsignale are immaterial and under morpho-syntactic  
control............................................................................................ 40
59 Chapter 3 
American structuralism: juncture phonemes 
 
60 1. Introduction.................................................................................... 43
61 2. Level independence: no morphology in phonology....................... 44
62
2.1. The orthodox point of view .................................................... 44
63
2.2. Junctural minimal pairs: night rate vs. nitrate........................ 45
64 3. Morphology in a phonological guise: Moulton (1947) on  
German........................................................................................... 46

x
Table of contents ± detail 
§
page
65 4. "Accidental" coincidence of juncture and morpho-syntactic 
divisions......................................................................................... 49
66 5. Structuralist views on the coincidence of juncture and morpho-
syntactic divisions.......................................................................... 50
67
5.1. Defenders of orthodoxy (Hockett, Joos, Trager) and Harris' 
ambiguous position................................................................. 50
68
5.2. Opposite view: Pike's grammatical prerequisites ................... 52
69 6. Whatever suits the analyst: juncture in the middle of  
morphemes..................................................................................... 54
70 7. Is there a phonetic correlate of juncture?....................................... 55
71 8. Structuralist terminology ............................................................... 57
72 9. Conclusion: Level Independence seeds modularity and enforces 
translation....................................................................................... 57
73 Chapter 4 
Chomsky, Halle & Lukoff (1956) 
74 1. The structuralist cover: economy................................................... 59
75 2. Phonological domains built on juncture distinctions ..................... 60
76 3. Level Independence abolished: phonology does take morpho-
syntactic information into account................................................. 61
77 4. Two for the price of one: multifunctional juncture........................ 62
78 5. Morpho-syntactic control over juncture restored, and no  
phonetic correlate........................................................................... 62
79 6. Privativity, an accidental consequence of economy ...................... 64
80 7. Cyclic derivation (inside-out interpretation).................................. 64
81 Chapter 5 
SPE sets the standards for 40 years 
82 1. Introduction.................................................................................... 67
83
1.1. Interface Dualism.................................................................... 67
84
1.2. Modular seeds in SPE: the inverted T and translation............ 68
85 2. Translation in SPE (output: boundaries)........................................ 70
86
2.1. The inverted T model.............................................................. 70
87
2.2. Boundaries.............................................................................. 71
88
2.2.1. Boundaries are [-segment] segments without  
phonetic correlate ......................................................... 71
89
2.2.2. Different types of boundaries: +, =, #........................... 72

Table of contents ± detail xi 
§
page
90
2.3. The general mapping algorithm: boundaries restore  
 (almost) full morpho-syntactic information........................... 73
91
2.4. Readjustment .......................................................................... 75
92
2.5. Affix classes and their representational management............. 77
93
2.5.1. Rule-blocking boundaries (stress-shifting affixes)....... 77
94
2.5.2. Rule-triggering boundaries (stress-neutral affixes) ...... 78
95
2.6. Labelled brackets.................................................................... 79
96
2.6.1. How brackets and labels are used in the phonology: 
bláckboard vs. black bóard .......................................... 79
97
2.6.2. Brackets and boundaries are (not) redundant: 
compensation vs. condensation.................................... 80
98
2.6.3. Brackets and interactionism.......................................... 83
99
2.6.4. Modularity and modularity offenders in SPE............... 84
100 3. The phonological cycle and one single phonology........................ 85
101
3.1. The phonological cycle........................................................... 85
102
3.1.1. Cyclic derivation: how it is motivated and how it  
works ............................................................................ 85
103
3.1.2. Cycles are defined like boundaries: by major  
categories (N,V,A)........................................................ 86
104
3.2. Word-level rules and the unity of phonological  
computation ............................................................................ 87
105
3.2.1. Cyclic vs. word level rules ........................................... 87
106
3.2.2. SPE is representational: class 1 vs. class 2, cyclic  
vs. word-level rules ...................................................... 89
107
3.2.3. SPE's representationalism maintains the unity of  
one single computational system.................................. 90
108 4. Conclusion ..................................................................................... 90
109 Chapter 6 
The life of boundaries in post-SPE times 
110 1. Introduction: overview until the 80s.............................................. 93
111 2. The mapping puzzle: alas, there are no natural classes of  
boundaries...................................................................................... 94
112 3. Boundary mutation rules................................................................ 95

xii 
Table of contents ± detail 
§
page
113 4. McCawley (1968): boundaries define domains of rule  
application...................................................................................... 96
114
4.1. Cyclic derivation on the grounds of phonological domains ... 96
115
4.2. Local vs. domain-based intervention ± notational variants?... 97
116 5. Typology and strength of boundaries............................................. 98
117
5.1. Boundary zoo.......................................................................... 98
118
5.2. Boundary contrast: minimal pairs and phonological 
permeability............................................................................ 99
119 6. Attempts to restrict boundary abuse and the boundary zoo ......... 100
120
6.1. Boundaries in an arbitrary rewrite-machinery...................... 100
121
6.2. Boundary strength as a diagnostic for boundary abuse ........ 101
122
6.3. Boundary economy I: Basbøll's general and grounded  
advice.................................................................................... 102
123
6.4. Boundary economy II: the + boundary can be dispensed  
with ....................................................................................... 103
124 7. Internal and external SPE-revision: Kiparsky (1968-73) and  
Natural Generative Phonology..................................................... 104
125
7.1. Introduction........................................................................... 104
126
7.2. Morpho-phonology in SPE and the 70s................................ 104
127
7.3. Natural revival of structuralist juncture (abuse) ................... 106
128
7.4. The elimination of (word) boundaries from P-rules ±  
a case of wishful thinking..................................................... 108
129
7.5. The retrenchment of morpho-phonology mechanically  
reduces the number of boundaries ........................................ 109
130
7.6. Autosegmental structure: from representational to  
procedural management of the word boundary .................... 111
131 8. What exactly is the output of translation, if any?......................... 112
132
8.1. Growing uncertainty: what kind of intermundia animals  
are boundaries?..................................................................... 112
133
8.2. Boundaries cannot be segments............................................ 114
134
8.2.1. If not segments, what then?........................................ 114
135
8.2.2. Lass (1971): # is [-voice]............................................ 115
136
8.2.3. Bankruptcy of boundaries and abandon of  
translation: Pyle (1972) .............................................. 116
137
8.2.4. When boundaries are bankrupt, the alternative is  
direct syntax: Pyle, Rotenberg, Hyman,  
Kenstowicz & Kisseberth........................................... 118
138 9. Conclusion ................................................................................... 119

Table of contents ± detail xiii 
§
page
139 Chapter 7 
Lexical Phonology 
 
140 1. Introduction.................................................................................. 123
141 2. Empirical foundations.................................................................. 124
142
2.1. Affix classes and affix ordering............................................ 124
143
2.2. Cross-linguistic reality of affix classes................................. 125
144 3. Lexical Phonology and the abstractness debate........................... 126
145 4. The general architecture of Lexical Phonology ........................... 127
146
4.1. Interactionism ± a new idea in the interface landscape......... 127
147
4.2. Strata and their procedural order: how to kill two birds  
with one stone....................................................................... 128
148
4.3. Morpheme-specific mini-grammars ..................................... 129
149
4.3.1. The stratal perspective supposes selective rule 
application .................................................................. 129
150
4.3.2. Underapplication is achieved by distinct mini- 
grammars and level ordering...................................... 130
151
4.3.3. How to make mini-grammars different but not 
waterproof: domain assignment.................................. 131
152
4.4. The general picture: interactionist Lexicon →syntax  
→postlexical phonology...................................................... 132
153
4.5. Praguian segregation: lexical vs. postlexical phonology ...... 133
154
4.5.1. The birth of postlexical phonology: Rubach (1981)... 133
155
4.5.2. Praguian segregation: syntax and morphology are 
different ...................................................................... 135
156
4.5.3. Morphologically conditioned vs. exceptionless  
rules ............................................................................ 135
157
4.5.4. Lexical vs. postlexical phonology: respective 
conditioning factors.................................................... 136
158
4.5.5. Cyclic vs. postlexical phonology: no cyclic  
interpretation of words ............................................... 137
159
4.6. Definition of interpretational units ....................................... 138
160
4.6.1. From brackets to strata ............................................... 138
161
4.6.2. Interactionism reconciles cyclic derivation with 
modularity................................................................... 138
162 5. The analysis of affix classes and its proceduralisation ................ 140
163 6. Rule-blocking boundaries are eliminated altogether.................... 141
164
6.1. Rule-blocking boundaries translate as level 1 rules.............. 141
165
6.2. Complete and unintended elimination of boundaries ........... 143

xiv 
Table of contents ± detail 
§
page
166 7. Rule-triggering boundaries: brackets and bracket erasure........... 144
167
7.1. English nasal cluster simplification...................................... 144
168
7.2. Brackets and bracket erasure are needed for a stratal  
account.................................................................................. 147
169
7.3. A hybrid representational-procedural theory because of  
the rule-triggering pattern..................................................... 149
170
7.3.1. LP-style brackets undo what was gained by 
interactionism ............................................................. 149
171
7.3.2. LP-style brackets and brackets in SPE have got  
nothing in common..................................................... 150
172
7.3.3. Brackets are boundaries that are introduced  
through the back door................................................. 151
173
7.3.4. A hybrid representational-procedural theory.............. 151
174
7.4. Bracket erasure ..................................................................... 152
175
7.4.1. No look-back devices in Lexical Phonology and 
elsewhere.................................................................... 152
176
7.4.2. SPE has bracket erasure, but no no look-back  
effect........................................................................... 153
177 8. Derived environment effects........................................................ 154
178
8.1. Properties and illustration of the phenomenon ..................... 154
179
8.1.1. Phonologically and morphologically derived 
environments .............................................................. 154
180
8.1.2. The foundational Finnish case.................................... 154
181
8.1.3. Non-application of rules to mono-morphemic  
strings ......................................................................... 155
182
8.1.4. Sensitivity to derived environments and to affix  
classes is orthogonal................................................... 157
183
8.2. Derived environments are an offspring of the  
abstractness debate................................................................ 157
184
8.2.1. Absolute neutralisation and free rides ........................ 157
185
8.2.2. The Alternation Condition.......................................... 158
186
8.2.3. "Low-level", "automatic" or "phonetic" rules may  
apply morpheme-internally......................................... 159
187
8.2.4. The Revised Alternation Condition: derived 
environments enter the scene...................................... 160

Table of contents ± detail xv 
§
page
188
8.3. Solution 1: the Strict Cycle Condition (SCC)....................... 161
189
8.3.1. Mascaró's SCC has got nothing to do with derived 
environments .............................................................. 161
190
8.3.2. Kiparsky (in fact Halle) adds derived environments  
to Mascaró's SCC ....................................................... 162
191
8.3.3. Deriving the SCC from the Elsewhere Condition ...... 164
192
8.3.4. There are rules that apply in the Lexicon but affect 
underived items .......................................................... 165
193
8.3.5. Structure-building vs. structure-changing rules.......... 165
194
8.3.6. Cyclicity as a property of strata vs. post-cyclic  
lexical rules................................................................. 166
195
8.3.7. The SCC-K is void of empirical content .................... 168
196
8.4. Solution 2: derived environments are made a lexical  
contrast (Kiparsky 1993) ...................................................... 169
197
8.4.1. Back to where we started: Kiparsky declares the 
bankruptcy of SCC-K................................................. 169
198
8.4.2. Different lexical representations for the same  
segment....................................................................... 170
199
8.4.3. Why NDEB processes must be obligatory and 
neutralising ................................................................. 171
200
8.4.4. Posterity of Kiparsky's lexical solution ...................... 172
201
8.5. Solution 3: bracket-sensitive rules (Mohanan 1982) ............ 172
202
8.5.1. Bracket-sensitive rules can do all derived  
environment effects .................................................... 172
203
8.5.2. Brackets and SCC-K are direct competitors ± but  
not in the literature...................................................... 174
204
8.6. Solution 4: derived environment effects are non-linguistic  
in nature (Anderson 1981).................................................... 175
205
8.6.1. Fultonians: speakers use extra-linguistic evidence 
(spelling) in order to establish underlying forms........ 175
206
8.6.2. Explaining the genesis of derived environment  
effects does not exonerate from coming up with a 
synchronic scenario .................................................... 176
207
8.7. Conclusion............................................................................ 177
208
8.7.1. A new phenomenon that is poorly understood........... 177
209
8.7.2. Kiparsky's solutions miss the facts or the point.......... 178
210
8.7.3. Mohanan's bracket-sensitive rules ± a misjudged  
option.......................................................................... 179

xvi 
Table of contents ± detail 
§
page
211 9. Conclusion ................................................................................... 179
212
9.1. Interactionism and multiple mini-grammars......................... 179
213
9.2. Unprecedented proceduralisation of the interface ................ 181
214
9.3. Representational communication and the pernicious  
SCC-K................................................................................... 181
215 Chapter 8 
Halle & Vergnaud (1987a): selective spell-out and SPE-
restoration 
216 1. Introduction: a hermaphrodite theory with a new idea ................ 185
217
1.1. Unseating Lexical Phonology and restoring SPE................. 185
218
1.2. Relations with Lexical Phonology........................................ 185
219
1.3. Relations with SPE ............................................................... 187
220
1.4. New ideas in interface thinking: selective spell-out and 
interpretation-triggering affixes............................................ 187
221
1.5. Relevant literature and roadmap........................................... 188
222 2. Anti-interactionism ...................................................................... 189
223
2.1. Restoration of the inverted T: all concatenation before all 
interpretation......................................................................... 189
224
2.2. Interactionism does not imply the Lexicon and is not 
incompatible with the inverted T.......................................... 191
225 3. Selective spell-out........................................................................ 191
226
3.1. A new idea: affix-triggered interpretation ............................ 191
227
3.2. Interpretational relevance of affixes percolates to their  
node....................................................................................... 192
228
3.3. Underapplication is achieved by selective spell-out of  
nodes..................................................................................... 194
229
3.4. The management of English stress ....................................... 195
230
3.4.1. Selective spell-out analysis of the párent - paréntal 
contrast ....................................................................... 195
231
3.4.2. Stress copy: storing before erasing............................. 196
232 4. The non-interactionist architecture .............................................. 197
233
4.1. Cyclic vs. word-level (non-cyclic) rules............................... 197
234
4.2. Multiple mini-grammars: morpheme- and chunk-specific 
phonologies........................................................................... 198
235
4.3. The general architecture........................................................ 200
236
4.4. Terminological pitfalls.......................................................... 201
237
4.5. No look-back devices............................................................ 203

Table of contents ± detail xvii 
§
page
238
4.6. Distinct pre- vs. post-word phonology yes, Praguian 
segregation no....................................................................... 204
239
4.7. The word as an autonomous phonological unit .................... 206
240
4.7.1. The word is sealed ± an insuperable barrier for  
some processes ........................................................... 206
241
4.7.2. Selective impact of no look-back?.............................. 207
242
4.8. Interpretational units............................................................. 208
243 5. Anti-interactionist ammunition: bracketing paradoxes................ 209
244
5.1. Affix ordering turns out to be wrong: bracketing  
paradoxes.............................................................................. 209
245
5.2. Dual membership, optionality, overgeneration..................... 210
246
5.3. Halle & Vergnaud's analysis of bracketing paradoxes ......... 211
247
5.4. Affix stacking generalisations as selectional restrictions  
or parsing-based (Fabb 1988, Hay 2002).............................. 212
248 6. Empirical coverage of Halle & Vergnaud's selective spell-out ... 213
249
6.1. Analysis of the rule-blocking pattern (level 1 rules) ............ 213
250
6.2. No solution for the rule-triggering pattern (level 2 rules)..... 214
251 7. Stratal vs. non-interactionist architecture: two testing grounds... 215
252
7.1. Syntactic information is or is not available when words  
are build ................................................................................ 215
253
7.2. Phonology-free syntax: is morphological concatenation 
sensitive to derived phonological properties?....................... 216
254 8. Conclusion ................................................................................... 216
255
8.1. SPE with Lexical Phonology freckles .................................. 216
256
8.2. Selective spell-out is a groundbreaking idea ........................ 217
257
8.3. Distinct computational systems yes ± but which ones?........ 218
258 Chapter 9 
Kaye (1995): selective spell-out and modification-inhibiting 
no look-back 
259 1. Introduction.................................................................................. 219
260
1.1. Editorial note ........................................................................ 219
261
1.2. Roadmap............................................................................... 220
262 2. Setting the scene: Kaye (1989) .................................................... 220
263
2.1. Phonology exists because it enhances parsing...................... 220
264
2.2. Perception-oriented views of phonology and the interface... 222
265
2.3. Typical boundary detectors................................................... 222

xviii 
Table of contents ± detail 
§
page
266 3. Domain structure: how it is created, what it represents and  
how it works................................................................................. 223
267
3.1. The concat- and the φ-function............................................. 223
268
3.1.1. General properties ...................................................... 223
269
3.1.2. Computation in Government Phonology.................... 223
270
3.1.3. Important properties of the φ-function for Kaye's 
interface theory........................................................... 225
271
3.2. Domain structure is created by interleaved concat and φ ..... 225
272
3.3. Analytic vs. non-analytic...................................................... 227
273
3.4. Domain structure is the result of selective spell-out............. 227
274
3.5. Interpretation prior to concatenation: domain structure 
generates more than spell-out can create .............................. 228
275
3.6. Domain structure is interactionist, brackets are only  
shorthand............................................................................... 229
276
3.7. Kaye's procedural-only approach and morpho-phonology... 230
277 4. Selective spell-out: Kaye's vs. Halle & Vergnaud's  
implementation ............................................................................ 231
278
4.1. Introduction........................................................................... 231
279
4.2. Underapplication is achieved by no look-back..................... 231
280
4.3. No automatic spell-out of roots, but systematic spell-out  
at the word-level ................................................................... 233
281
4.4. Who is interpretation-triggering ± class 1 or class 2  
affixes?.................................................................................. 234
282
4.5. Interpretation-triggering affixes: spell-out of the sister  
vs. their own node................................................................. 235
283
4.6. Morpheme- and chunk-specific phonologies........................ 236
284
4.7. Derived environments are a separate issue........................... 237
285
4.8. Cyclic interpretation of words?............................................. 238
286
4.9. Summary: two ways of doing selective spell-out ................. 238
287 5. No look-back devices: implementations since 1973.................... 239
288
5.1. Like lexicalism, no look-back is born in the early 70s as  
an overgeneration-killer........................................................ 239
289
5.2. Chomsky's (1973) Strict Cycle Condition: you need to  
use new material ................................................................... 240
290
5.3. Application to phonology: Kean (1974) and  
Mascaró (1976)..................................................................... 241
291
5.4. Halle/Kiparsky's SCC-K: scrambling with derived 
environments......................................................................... 242
292
5.5. Mohanan's bracket erasure: indirect bearing on rules........... 243

Table of contents ± detail xix 
§
page
293
5.6. Modification-inhibiting no look-back: first timid steps  
in the 70s and 80s ................................................................. 244
294
5.6.1. Early formulations in phonology and syntax.............. 244
295
5.6.2. Phonology I: stress and the Free Element  
Condition.................................................................... 244
296
5.6.3. The FEC is weak: process-specificity,  
parameterisation and restriction to structure that  
is absent from the lexicon........................................... 246
297
5.6.4. Phonology II: structure preservation in  
syllabification ............................................................. 247
298
5.6.5. Syntax: Riemsdijk's (1978) Head Constraint.............. 247
299
5.7. Modification-inhibiting no look-back in Kaye's system....... 250
300
5.7.1. Kaye calls on SCC-M, but applies something else..... 250
301
5.7.2. Kaye's modification-inhibiting no look-back ............. 251
302
5.7.3. Chomsky's "spell-out and forget" is too strong for 
phonology: "don't undo" and process-specific no  
look-back.................................................................... 253
303
5.7.4. Morpheme-specific phonologies and selective  
spell-out do the same job and are therefore  
mutually exclusive...................................................... 255
304
5.8. On the (modern) syntactic side: derivation by phase and  
Phase Impenetrability ........................................................... 255
305
5.8.1. Interactionism is enforced by the minimalist  
concern for economy of cognitive resources  
 (active memory)......................................................... 255
306
5.8.2. Phase Impenetrability is the instrument of active 
memory economy ....................................................... 259
307
5.8.3. The old and the new: a memory keeper and/or  
diacritic marking needed?........................................... 260
308
5.8.4. Ancestors of multiple and selective spell-out:  
Bresnan (1971) ........................................................... 261
309
5.9. Conclusion............................................................................ 264
310 6. Empirical coverage: Kaye's system and affix class-based 
phenomena................................................................................... 264
311
6.1. The empirical testing ground: five English affix class- 
based phenomena.................................................................. 264

xx 
Table of contents ± detail 
§
page
312
6.2. The rule-blocking pattern (level 1 rules) .............................. 266
313
6.2.1. Modification-inhibiting no look-back achieves 
underapplication at the outer cycle............................. 266
314
6.2.2. Nasal assimilation requires independent spell-out  
of the affix .................................................................. 267
315
6.2.3. Anti-affix ordering items cannot be done: stress  
violates no look-back.................................................. 269
316
6.3. Spell-out of terminals: the problem and a possible  
solution ................................................................................. 270
317
6.3.1. The problem: independent spell-out of affixes prior  
to their being merged.................................................. 270
318
6.3.2. Morphological adjuncts, counter-cyclic merger and 
intermodular predictions............................................. 270
319
6.3.3. Benefits: bracketing paradoxes, category selection, 
double affixation......................................................... 271
320
6.3.4. Procedural first ........................................................... 273
321
6.4. The rule-triggering pattern (level 2 rules)............................. 274
322
6.4.1. Underapplication at the inner cycle............................ 274
323
6.4.2. Kaye's solution is like Mohanan's, but respects 
modularity................................................................... 275
324
6.4.3. Why string-final /gN/ and /mn/ do not survive 
computation................................................................ 276
325
6.4.4. Prediction: processes without additional condition 
cannot instantiate the rule-triggering pattern.............. 276
326
6.4.5. Kaye's analysis predicts the word-final/class 2 
disjunction .................................................................. 277
327
6.5. Conclusion............................................................................ 277
328 7. Phonological consequences of domains and their erosion........... 278
329
7.1. Empty nuclei that are string-final upon computation ........... 278
330
7.1.1. Final empty nuclei in Government Phonology........... 278
331
7.1.2. From word-final to domain-final empty nuclei .......... 279
332
7.1.3. The well-formedness of final empty nuclei is  
carried over to outer domains..................................... 280
333
7.1.4. Computation is right-to-left: string-final nuclei are 
phase-initial ................................................................ 280
334
7.2. Consequences of domain structure for stress and vowel 
reduction ............................................................................... 281
335
7.2.1. Dialectal and idiolectal variation due to variable  
domain structure......................................................... 281

Table of contents ± detail xxi 
§
page
336
7.2.2. Following SPE: "old" stress protects against  
vowel reduction .......................................................... 282
337
7.2.3. How to detect the difference between [[X] [Y]]  
and [[X] Y] ................................................................. 283
338
7.2.4. Chunk-specific phonologies: like SPE, Kaye  
provides for a specific word-level phonology ............ 283
339
7.3. Diachronic erosion of domain structure................................ 284
340 8. Parsing cues ................................................................................. 286
341
8.1. Theory-independent parsing cues: knowledge of  
morpheme structure .............................................................. 286
342
8.2. Theory-dependent parsing cues (in English) ........................ 287
343
8.2.1. Empty nuclei detected by phonology ......................... 287
344
8.2.2. Morphological interpretation of empty nuclei............ 289
345
8.3. When phonology is useless................................................... 290
346 9. Lexical access and the organisation of the lexicon...................... 291
347
9.1. Lexical entries are grouped according to phonological  
structure ................................................................................ 291
348
9.2. Possible lexical entries are defined by phonology................ 292
349
9.2.1. How speakers decide that blick, but not lbick, is a 
possible word.............................................................. 292
350
9.2.2. The full addressing space is created, including  
"empty" slots .............................................................. 292
351
9.3. Phonology defines lexical access: look-up vs. compute....... 293
352
9.3.1. Introduction ................................................................ 293
353
9.3.2. Look-up I: related keep - kept vs. unrelated  
table - house ............................................................... 294
354
9.3.3. Look-up II: phonologically similar keep - kept vs. 
regular suppletion go - went ....................................... 295
355
9.3.4. Computation: when parsing cues are available  
 (peeped)..................................................................... 296
356
9.3.5. How parsing is done with hidden morphology  
 (stepped) .................................................................... 297
357
9.3.6. The four identification patterns are more or less  
costly .......................................................................... 297
358
9.3.7. Why is direct look-up not generalised?...................... 297
359 10. Conclusion ................................................................................. 298

xxii 
Table of contents ± detail 
§
page
360 Chapter 10 
Prosodic Phonology: on the representational side 
 
361 1. Overview: autosegmentalised boundaries and fresh data ............ 301
362 2. The roots of Prosodic Phonology................................................. 303
363
2.1. Selkirk adapts Liberman & Prince's strong/weak arboreal 
structure ................................................................................ 303
364
2.2. A second strand that became mainstream:  
Nespor & Vogel.................................................................... 304
365 3. From boundaries to domains: a historical choice that has gone 
almost unnoticed.......................................................................... 305
366
3.1. Boundaries are diacritic and local......................................... 305
367
3.2. The elimination of boundaries in Lexical Phonology  
remained unreflected in Prosodic Phonology ....................... 306
368
3.3. Prosodic Phonology is a child of autosegmentalism............. 307
369
3.4. The (non-)discussion of boundaries in Prosodic  
Phonology............................................................................. 308
370
3.4.1. Boundaries were not an issue anymore for Nespor  
& Vogel (1986)........................................................... 308
371
3.4.2. Looking for anti-boundary arguments........................ 309
372
3.4.3. References that do not contain any argument  
against boundaries ...................................................... 310
373
3.4.4. The diacritic argument................................................ 312
374
3.4.5. Domains have an independent motivation: stress,  
rhythm and musical properties ................................... 315
375
3.4.6. The idea of unified representations was abandoned  
by Selkirk herself........................................................ 316
376
3.4.7. Summary..................................................................... 317
377 4. The heart of Prosodic Phonology: Indirect Reference and its 
consequences................................................................................ 318
378
4.1. Introduction........................................................................... 318
379
4.2. The buffer, its construction workers and how it unloads  
its goods................................................................................ 319
380
4.2.1. Mapping rules and the black box................................ 319
381
4.2.2. Mapping is done in modular no man's land................ 320
382
4.2.3. The layers of the Prosodic Hierarchy ......................... 321

Table of contents ± detail xxiii 
§
page
383
4.2.4. Geometric properties of the Prosodic Hierarchy:  
the Strict Layer Hypothesis ........................................ 322
384
4.2.5. Three ways of making reference to the Prosodic 
Hierarchy.................................................................... 324
385
4.3. The old and the new: mapping rules and Indirect  
Reference.............................................................................. 324
386 5. Mapping: its mechanics, its evolution and our understanding  
thereof.......................................................................................... 326
387
5.1. Introduction: the mapping puzzle (again)............................. 326
388
5.2. Mapping and its inflational evolution................................... 328
389
5.2.1. Early mapping in Selkirk's work until her 1984  
book............................................................................ 328
390
5.2.2. Parametric variation of ω and φ in Nespor &  
Vogel (1986)............................................................... 329
391
5.2.3. More variation for the phonological phrase................ 330
392
5.2.4. Cross-linguistic atomisation of mapping.................... 331
393
5.2.5. The mapping puzzle is sometimes hidden by the  
clean Prosodic Hierarchy............................................ 332
394
5.3. What is the morpho-syntactic rationale behind mapping?.... 334
395
5.3.1. Selkirk (1986) puts to use the technology of the  
80s: X-bar-based mapping.......................................... 334
396
5.3.2. End-based mapping does not solve the mapping  
puzzle either................................................................ 335
397
5.3.3. Boundaries are the relevant descriptive currency....... 337
398
5.4. Phonology can see morpho-syntactic structure, but not its 
labels..................................................................................... 337
399 6. Closer inspection of the buffer (Prosodic Hierarchy): what it  
is and what it is not ...................................................................... 338
400
6.1. The only purpose of the Prosodic Hierarchy is the storage  
of morpho-syntactic information .......................................... 338
401
6.2. The buffer does not include syllables and feet...................... 340
402
6.3. The buffer is a diacritic ± an autosegmental diacritic........... 342
403
6.3.1. Prosodic Phonology lays claim to boundaries: they  
are the old buffer, prosodic domains are the  
modern buffer............................................................. 342
404
6.3.2. The buffer and SPE-type boundaries share all  
properties.................................................................... 343
405
6.3.3. What counts as a diacritic?......................................... 344

xxiv 
Table of contents ± detail 
§
page
406 7. Good and bad reasons for Indirect Reference.............................. 345
407
7.1. Direct syntax vs. Prosodic Phonology .................................. 345
408
7.1.1. Two approaches, their competition and their  
evolution..................................................................... 345
409
7.1.2. Is the buffer useless and redundant? A real good 
motivation is needed................................................... 347
410
7.2. A good reason: modularity ................................................... 347
411
7.2.1. Introduction: different modules do not speak the  
same language ............................................................ 347
412
7.2.2. Phonology-free syntax................................................ 347
413
7.2.3. Phonology and morpho-syntax do not speak the  
same language ± hence communication requires 
translation ................................................................... 351
414
7.2.4. Nobody makes the modular argument in order to  
sustain Indirect Reference .......................................... 352
415
7.2.5. Modularity and Level Independence.......................... 353
416
7.3. A bad reason: non-isomorphism........................................... 354
417
7.3.1. Non-isomorphism in the Prosodic Phonology  
literature...................................................................... 354
418
7.3.2. The phenomenon: cat-rat-cheese, phonology over 
sentences..................................................................... 355
419
7.3.3. Domain abuse I: there is no argument when  
phonology refers to boundaries instead of domains ... 357
420
7.3.4. Domain Abuse II: theoretical units are confused  
with descriptive categories ......................................... 358
421
7.3.5. Is prosodic phrasing sensitive to the length of the  
string? ......................................................................... 359
422
7.4. Conclusion............................................................................ 361
423 8. Relations with Lexical Phonology and the metrical grid............. 361
424
8.1. Introduction........................................................................... 361
425
8.2. The metrical grid................................................................... 362
426
8.2.1. Selkirk (1984): mapping modifies the  
 (pre-existing) grid...................................................... 362
427
8.2.2. Selkirk (1986): the grid is born from mapping on  
the grounds of prosodic constituency......................... 364
428
8.2.3. Alignment on Nespor & Vogel's peaceful (and  
modular) coexistence.................................................. 364

Table of contents ± detail xxv 
§
page
429
8.3. Lexical Phonology I: conflict with Prosodic Phonology ...... 366
430
8.3.1. No concurrence above the word level ........................ 366
431
8.3.2. Hayes (1989 [1984]): Prosodic Phonology above, 
Lexical Phonology below the word level ................... 366
432
8.3.3. Selkirk (1984): Lexical Phonology is redundant  
and has to go............................................................... 367
433
8.3.4. Inkelas (1990): Prosodic Phonology with the  
empty shell of Lexical Phonology.............................. 368
434
8.3.5. Lexical Phonology does not violate Indirect  
Reference.................................................................... 370
435
8.4. Lexical Phonology II: peaceful coexistence (soft version)... 371
436
8.4.1. How labour is supposed to be divided: "direct  
reference to morphological structure" ........................ 371
437
8.4.2. There is no natural division of rules into "purely 
phonological" vs. "morpho-phonological" ................. 372
438
8.4.3. Two examples............................................................. 373
439
8.4.4. Peaceful coexistence supposes split mapping ............ 374
440
8.5. Lexical Phonology III: peaceful coexistence (radical  
version) ................................................................................. 374
441
8.6. Conclusion............................................................................ 377
442 9. Prosodic Morphology................................................................... 378
443
9.1. Representational and non-representational incarnations ...... 378
444
9.2. Representational period: prosodic morphemes are units  
of the Prosodic Hierarchy ..................................................... 378
445
9.2.1. A typical example: reduplication................................ 378
446
9.2.2. Another typical example: (Semitic) templatic 
morphology................................................................. 379
447
9.2.3. Moras, syllables and feet do not carry any morpho-
syntactic information.................................................. 380
448
9.3. Generalized Template Theory: morphology marshals 
phonology ............................................................................. 381
449 10. Conclusion: translation yes, buffer no ....................................... 382

xxvi 
Table of contents ± detail 
§
page
450 Chapter 11 
Optimality Theory 
 
451 1. Setting the scene .......................................................................... 385
452
1.1. OT makes no contribution on the representational side........ 385
453
1.2. Representations marshalled by constraints........................... 385
454
1.3. Anti-cyclicity and the serial offspring of Lexical  
Phonology............................................................................. 386
455 2. Adaptation of Prosodic Phonology to the constraint-based 
environment ................................................................................. 388
456
2.1. Introduction........................................................................... 388
457
2.2. Constraint-based instead of rule-based mapping.................. 388
458
2.2.1. Mapping understood as the coincidence of  
constituent edges: ALIGN............................................ 388
459
2.2.2. Parallel mapping: translation and reference to  
prosodic constituency are conflated ........................... 389
460
2.2.3. Parametric variation: interaction of ALIGN and  
WRAP.......................................................................... 390
461
2.3. The Strict Layer Hypothesis made less strict........................ 391
462
2.4. Phase-based mapping............................................................ 392
463
2.5. Mapping: focus on new factors, but the puzzle is the  
same as before....................................................................... 393
464 3. Cyclic derivation and its relation with phonology....................... 394
465
3.1. Anti-cyclicity in OT and elsewhere: cutting off deep  
generative roots..................................................................... 394
466
3.1.1. Cyclic spell-out is a bone of contention: OT vs. 
generative grammar.................................................... 394
467
3.1.2. Anti-cyclic voices from other quarters....................... 395
468
3.1.3. The stake is high: inside-out interpretation ................ 396
469
3.2. OT could respect modular contours ± but it does not........... 396
470
3.2.1. Cyclic derivation and phonological computation  
are entirely independent as long as phonology is 
phonology proper........................................................ 396
471
3.2.2. Modularity is not an issue for classical incarnations  
of OT .......................................................................... 398
472
3.2.3. Cyclic derivation, but morphology and phonology 
merged in the same constraint chamber  
(Wolf 2008) ................................................................ 399

Table of contents ± detail xxvii 
§
page
473 4. Morpheme-specific mini-grammars in OT .................................. 400
474
4.1. Introduction........................................................................... 400
475
4.2. Opacity killers, cyclicity killers and their relationship ......... 400
476
4.3. Morpheme-specific mini-phonologies: parallel vs.  
reranked incarnations............................................................ 401
477 5. Parallel mini-grammars................................................................ 403
478
5.1. Co-phonologies: two constraint rankings ............................. 403
479
5.1.1. Lexical material selects a specific computational  
system......................................................................... 403
480
5.1.2. How affix class-based phenomena could be  
analysed...................................................................... 403
481
5.1.3. Are co-phonologies a version of Halle &  
Vergnaud (1987a)?..................................................... 404
482
5.2. Indexed constraints: two grammars in the same  
constraint ranking ................................................................. 405
483 6. Reranked mini-grammars: Stratal OT, DOT................................ 407
484
6.1. Serial vs. parallel solutions................................................... 407
485
6.1.1. Parallel OT couched in the stratal architecture of  
Lexical Phonology...................................................... 407
486
6.1.2. The critical contrast with parallel implementations  
is not discussed........................................................... 407
487
6.1.3. Indexed constraints, but not co-phonologies, are 
perceived as a competitor ........................................... 408
488
6.2. Stratal OT is more than just an OTed version of Lexical 
Phonology............................................................................. 409
489
6.2.1. Lexical Phonology anew: unhorsing the SPE  
heritage ....................................................................... 409
490
6.2.2. Inflational access to morpho-syntactic information  
is a concern in Stratal OT ........................................... 410
491
6.2.3. The solution is the same as before: Indirect  
Reference and peaceful coexistence........................... 411
492
6.3. How different can mini-grammars be? ................................. 412
493 7. Other cyclicity killers................................................................... 413
494
7.1. Interface constraints.............................................................. 413
495
7.1.1. Back to direct syntax .................................................. 413
496
7.1.2. Back to SPE-type morphological diacritics................ 414

xxviii 
Table of contents ± detail 
§
page
497
7.2. Analogy (Output-Output correspondence) ........................... 415
498
7.2.1. OO correspondence was designed as a cyclicity  
killer............................................................................ 415
499
7.2.2. OO is not a cyclicity killer by itself............................ 416
500
7.3. Enriched representations (van Oostendorp).......................... 417
501 8. More direct syntax: representational continuity between 
morphology and phonology ......................................................... 418
502
8.1. Introduction........................................................................... 418
503
8.2. Coloured Containment (van Oostendorp 2006a).................. 418
504
8.2.1. Faithfulness between morphology and phonology..... 418
505
8.2.2. Representational identification of the old and the  
new ............................................................................. 419
506
8.2.3. Information transmission: representational vs.  
procedural................................................................... 420
507
8.2.4. Independent representations marshal GEN and  
afford to be coloured .................................................. 420
508
8.2.5. Faithfulness between morphological and  
phonological structure ................................................ 421
509
8.2.6. Coloured Containment applied to derived  
environment effects .................................................... 423
510
8.2.7. Anti-Lexical Phonology: the interface 
representationalised.................................................... 425
511
8.2.8. Mapping: a second means of talking to the  
phonology................................................................... 425
512
8.3. Sign-Based Morphology (Orgun 1996a) .............................. 426
513
8.3.1. Monostratal HPSG-style representations where  
syntactic, semantic and phonological information  
is scrambled................................................................ 426
514
8.3.2. Cyclic effects in SBM ................................................ 428
515
8.3.3. There is no interface if all is one and the same  
thing............................................................................ 429
516 9. Derived environment effects in OT ............................................. 430
517
9.1. Introduction........................................................................... 430
518
9.2. Coloured Containment and Constraint Conjunction  
 (Łubowicz)........................................................................... 431
519
9.3. Comparative Markedness (McCarthy) and analogy  
 (Burzio)................................................................................ 432
520
9.4. Direct syntax (interface constraints): Root Faithfulness 
(Anttila)................................................................................. 434

Table of contents ± detail xxix 
§
page
521
9.5. Revival of the Elsewhere Condition (Cho, Iverson)............. 434
522
9.6. Co-phonologies (Yu) ............................................................ 435
523 10. OT is a strong modularity-offender: violations are in-built....... 435
524
10.1. Modularity yes or no ± this is the question, however  
rarely addressed in the OT literature................................. 435
525
10.2. Direct Syntax in OT is regular and uncontradicted .......... 438
526
10.3. Parallel mapping puts the Translator's Office in the 
phonology ......................................................................... 439
527
10.4. Scrambling: morpho-phonological contours are blurred.. 439
528
10.5. Radical scrambling: one single constraint ranking for 
morpho-syntax, semantics and phonology........................ 441
529
10.6. Two souls are dwelling in OT: generative and  
connectionist..................................................................... 442
530 11. Conclusion ................................................................................. 444
531 Chapter 12 
Distributed Morphology 
532 1. Introduction.................................................................................. 447
533 2. Setting the scene: Distributed Morphology vs. Lexical  
Phonology .................................................................................... 448
534
2.1. From Halle & Vergnaud (1987a) to Distributed  
Morphology: against the two-place approach....................... 448
535
2.2. The single engine approach is agnostic with respect to  
the phonological interpretation of the string (morpheme-  
and chunk-specific parsing).................................................. 449
536
2.3. The general architecture of Distributed Morphology ........... 450
537
2.4. The unity of syntax and morphology under debate .............. 452
538
2.4.1. Specific morphological operations: does DM live  
up to its ambition? ...................................................... 452
539
2.4.2. Voices that argue for the traditional stance:  
syntax ≠morphology.................................................. 452
540
2.5. Earlier versions of "No escape from syntax": Selkirk  
 (1984) and Inkelas (1990).................................................... 453
541 3. Direct merge and opacity............................................................. 455
542
3.1. Introduction: DM also looks at interpretative effects at LF.. 455

xxx 
Table of contents ± detail 
§
page
543
3.2. In DM, opacity is due to direct merge .................................. 456
544
3.2.1. Direct merge to a root produces opacity, merge to  
an xP guarantees transparency.................................... 456
545
3.2.2. An example of direct-merge-created PF and LF  
opacity: cómparable vs. compárable.......................... 457
546
3.2.3. The origin of the idea that direct merge causes  
opacity: idiosyncrasy is a property of "lower"  
items in the tree .......................................................... 458
547
3.3. Marvin's (2002) DM-analysis of condensation vs. 
compensation........................................................................ 460
548
3.3.1. SPE's classical take: two different suffixes ................ 460
549
3.3.2. The SPE analysis is empirically flawed: Halle & 
Kenstowicz (1991) admit a lexical conditioning........ 461
550
3.3.3. *Transport-ate: intermediate derivational forms  
that happen not to exist as words................................ 462
551
3.3.4. Direct (transportation) vs. indirect (condensation)
merge of -ate............................................................... 462
552
3.3.5. All xPs are phase heads, direct merge is the anti-
lexicalist way of encoding lexicalist observations...... 464
553
3.3.6. Direct merge may, but does not need to produce  
opacity ........................................................................ 464
554
3.4. Phase Impenetrability à la carte? .......................................... 465
555
3.4.1. The strong DM claim that all xPs are spelled out  
imposes process-specific Phase Impenetrability ........ 465
556
3.4.2. We know that stress is a strange guy anyway............. 466
557
3.5. All xPs are spelled out vs. selective spell-out plus the PIC.. 467
558
3.5.1. Affix class-based phenomena in DM ......................... 467
559
3.5.2. Underapplication cannot be done when all xPs are 
spelled out................................................................... 468
560
3.5.3. Opposite ways to go: distinct representations (DM)  
vs. distinct computation (Kaye, Halle & Vergnaud) .. 469
561
3.5.4. A direct merge analysis for affix class-based  
phenomena is not viable............................................. 471
562
3.5.5. Analysing cómparable vs. compárable with  
selective spell-out....................................................... 472
563
3.5.6. Conclusion.................................................................. 473

Table of contents ± detail xxxi 
§
page
564
3.6. Articulation of semantic and phonological opacity .............. 473
565
3.6.1. All logical possibilities occur ..................................... 473
566
3.6.2. Neither the PIC nor direct merge can account for  
all patterns .................................................................. 475
567
3.6.3. Independent LF and PF phases?................................. 475
568
3.7. Conclusion: predictable vs. unpredictable opacity and 
associated analyses ............................................................... 476
569 4. Anti-lexicalism is an orientation that allows for lexicalist  
analyses........................................................................................ 477
570
4.1. The phonological side of the (anti-)lexicalist issue .............. 477
571
4.2. A third player: allomorphy, suppletion................................. 479
572
4.3. Distributed Morphology relies on the usual "phonological 
similarity" ............................................................................. 480
573
4.4. There is no semantic effect if cómparable and  
compárable are made of two independent Vocabulary  
Items ..................................................................................... 481
574 5. PF movement ............................................................................... 483
575
5.1. Syntactic motivation ............................................................. 483
576
5.2. Phonological motivation....................................................... 484
577
5.2.1. Cases where phonology impacts syntax..................... 484
578
5.2.2. Phonology-internal triggers: Piggott & Newell on 
Ojibwa ........................................................................ 485
579
5.2.3. Phonologically motivated allomorphy:  
Lowenstamm on French ............................................. 487
580
5.3. Overgeneration, direct syntax, modularity and the  
creation of two distinct computational systems.................... 491
581 6. Conclusion ................................................................................... 493
582
6.1. Direct merge vs. selective spell-out: a geometric, rather  
than a computational solution............................................... 493
583
6.2. Spell-out at every xP stands in the way................................ 494
584
6.3. Unifying ambitions and specific tools for morphology ........ 494
585
6.4. Two specificities: LF and no proposal regarding 
representational communication........................................... 495

xxxii 
Table of contents ± detail 
§
page
Interlude 
 
586 Modularity 
587 Chapter 1 
Introduction: the relative absence of modularity in  
interface thinking........................................................................... 497
588 Chapter 2 
Modularity and connectionism, mind and brain 
 
589 1. Monism vs. dualism, symbolic vs. non-symbolic  
representations ............................................................................. 499
590
1.1. Levels of representation in the standard cognitive model..... 499
591
1.2. A language of thought: symbolic vs. anti-symbolic views  
of cognition........................................................................... 500
592
1.3. What would adult science look like without symbols?......... 502
593 2. Connectionism and its representatives in linguistics ................... 505
594
2.1. The symbolic front line and its roots in Cognitive Science.. 505
595
2.2. How neural networks work................................................... 506
596
2.3. No distinction between storage and computation (the  
rule/list fallacy)..................................................................... 507
597
2.4. All-purpose parallel vs. specialised step-by-step  
computation .......................................................................... 508
598
2.5. What it all comes down to: connectionist computation is 
content-free........................................................................... 510
599 3. Conclusion: peaceful coexistence at first, but not for long.......... 510
600 Chapter 3 
The modular architecture of the mind: where it comes from
601 1. The brain as a set of functional units: F-J Gall's early 19th  
century phrenology ...................................................................... 515
602 2. Independent faculties, their correlation with size and the skull  
bone.............................................................................................. 516
603 3. Faculty psychology married with computation theory  
(von Neumann - Turing) .............................................................. 517

Table of contents ± detail xxxiii 
§
page
604 Chapter 4 
The modular architecture of the mind: how it works 
 
605 1. Higher and lower cognitive functions, modules and the  
central system............................................................................... 519
606 2. How much of the mind is modular?............................................. 520
607
2.1. Peripheral vs. massive modularity: is there a non- 
modular core? ....................................................................... 520
608
2.2. Is the central system impenetrable for human  
intelligence?.......................................................................... 521
609
2.3. Is the mind (are modules) the result of Darwinian  
adaptation?............................................................................ 522
610 3. Core modular properties .............................................................. 523
611
3.1. Domain specificity................................................................ 523
612
3.2. Informational encapsulation ................................................. 524
613
3.3. Summary: how to identify a module..................................... 526
614 4. Specialised neurons and neural localisation of cognitive  
functions....................................................................................... 527
615
4.1. Mind-brain relationship ........................................................ 527
616
4.2. Functional anatomy: the existence of specialised and 
localisable (suites of) neurons is undisputed ........................ 528
617
4.3. Some literature...................................................................... 530
618 5. Modules can be plugged out without affecting other faculties .... 531
619
5.1. Double dissociation .............................................................. 531
620
5.2. Documented cases: face recognition, number sense............. 531
621
5.3. Double dissociation of language........................................... 532
622 Chapter 5 
Modularity of and in language, related systems 
 
623 1. Modularity in the early days of generative grammar: 50s-60s .... 535
624
1.1. A spearhead of the cognitive revolution of the 50s in  
language................................................................................ 535
625
1.2. LSLT: language is made of modules (levels), a  
concatenation algebra and interfaces .................................... 536
626
1.3. Modularity on its way: from LSLT to Aspects and SPE ...... 538
627 2. Modularity implies biology and innateness: the language  
organ ............................................................................................ 539

xxxiv 
Table of contents ± detail 
§
page
628 3. Grammar itself is made of modules: GB-subtheories and  
their (questionable) status as cognitive modules.......................... 540
629
3.1. The inverted T is the baseline since the 60s ......................... 540
630
3.2. GB-subtheories are presented as modules, but insulated  
from the cognitive context.................................................... 541
631
3.3. Chomsky (1981): subcomponents (inverted T) vs.  
subsystems (theta theory etc.)............................................... 542
632
3.4. Are GB-subsystems cognitive modules? .............................. 543
633
3.5. Biolinguistics: an evolutionary argument against  
language-internal modularity (Hornstein 2009).................... 545
634 4. GB modules and their perception in non-linguistic quarters ....... 547
635
4.1. Chomsky (1981) calls GB-subtheories modules without 
comment ............................................................................... 547
636
4.2. Perception of GB-modules in non-linguistic quarters: 
puzzlement............................................................................ 548
637 5. Minimalism and biolinguistics do away with GB modules ......... 550
638
5.1. Minimalism: GB-subtheories have to go.............................. 550
639
5.2. Grammar reduces to morpho-syntax: PF and LF are  
neither language- nor species-specific.................................. 550
640 6. Identifying linguistic modules ..................................................... 551
641
6.1. How to identify grammar-internal modules.......................... 551
642
6.2. Dissociation: Pragmatics, Lexicon vs. morpho-syntax......... 552
643
6.3. Domain specificity (Starke): morpho-syntax-semantics  
vs. phonology........................................................................ 553
644
6.4. Domain specificity (Jackendoff, Chomsky): phonology  
is distinct............................................................................... 554
645
6.5. Phonology-free syntax.......................................................... 555
646
6.6. Late Insertion is the segregation of phonological and  
other vocabulary ................................................................... 555
647
6.7. Phonology vs. phonetics ....................................................... 556
648 7. Encapsulation is called inclusiveness in syntax........................... 556

Table of contents ± detail xxxv 
§
page
649 Chapter 6 
How modules communicate 
 
650 1. Intermodular communication requires translation ....................... 557
651 2. Translation of what? .................................................................... 558
652
2.1. Modular computation: vocabulary (input) vs. structure  
 (output) ................................................................................ 558
653
2.2. Is structure, but not vocabulary, translated? ......................... 558
654 3. Translation is selective, and the choice of translated pieces is 
arbitrary........................................................................................ 559
655 4. Outlook: intermodular translation is the focus of Vol.2 .............. 560
Part Two 
Lessons from interface theories 
656 Chapter 1 
A guide to the interface jungle...................................................... 563
657 Chapter 2 
Empirical generalisations 
658 1. Introduction.................................................................................. 565
659 2. Morpho-syntax has no bearing on the content of phonological 
computation.................................................................................. 566
660 3. Morpho-syntax and melody are incommunicado......................... 568
661
3.1. Morpho-syntax can neither read melody nor bear on it........ 568
662
3.1.1. Phonology-free syntax is in fact melody-free  
syntax.......................................................................... 568
663
3.1.2. Carriers of morpho-syntactic information do not  
include melody ........................................................... 568
664
3.2. (Floating) morphemes without linear realisation originate  
in the lexicon......................................................................... 569
665
3.3. Conclusion: vocabulary excluded from translation  
altogether?............................................................................. 570

xxxvi 
Table of contents ± detail 
§
page
666 Chapter 3 
Issues that are settled 
 
667 1. There are no boundaries inside morphemes................................. 573
668 2. There is no phonetic correlate of morpho-syntactic  
information................................................................................... 574
669
2.1. Phonetic correlate of morpho-syntactic breaks: definition ... 574
670
2.2. Generative diacritics make no noise, except in Natural 
Generative Phonology........................................................... 575
671 3. Affix ordering is wrong ............................................................... 576
672 4. Interpretation is inside-out, grammar is interactionist, brackets  
are unnecessary relics .................................................................. 577
673
4.1. Inside-out interpretation and cyclic derivation ..................... 577
674
4.1.1. Two ways of organising inside-out interpretation: 
brackets vs. interactionism ......................................... 577
675
4.1.2. Brackets require a PF parsing device and make a 
procedural insight representational (and diacritic) ..... 579
676
4.2. The line-up of interface theories in regard of  
interactionism ....................................................................... 580
677
4.2.1. Revolution (Lexical Phonology) and counter- 
revolution (Halle & Vergnaud)................................... 580
678
4.2.2. Phonology and the interface are not the same thing... 581
679
4.2.3. Derivation by phase: when generative grammar  
became interactionist.................................................. 582
680
4.3. Only interactionism makes inside-out interpretation  
compatible with modularity.................................................. 583
681
4.3.1. Modularity referees in favour of interactionism......... 583
682
4.3.2. Nobody used modularity in the 80s............................ 584
683 5. Interface Dualism......................................................................... 585
684
5.1. If tacitly, (almost) all theories implement Interface  
Dualism................................................................................. 585
685
5.2. Representational communication needed (contra Kaye  
1995)..................................................................................... 586
686
5.3. Procedural communication needed (contra orthodox OT).... 587

Table of contents ± detail xxxvii 
§
page
687 Chapter 4 
Modularity, translation, the diacritic issue and local vs. 
domain-based intervention: settled in verb, but not in fact 
 
688 1. Introduction.................................................................................. 589
689
1.1. Three questions: two are settled, one has never been  
discussed............................................................................... 589
690
1.2. Modularity and diacritics are only settled in verb ................ 589
691
1.3. The three questions are the backbone of the  
representational channel ....................................................... 590
692 2. Translation in structuralist and generative interface theory......... 590
693
2.1. Interface design was done in absence of a modular/ 
cognitive background ± but translation has always been 
practised................................................................................ 590
694
2.2. The birth and variable incarnation of diacritics.................... 591
695
2.2.1. Juncture phonemes and SPE-type boundaries:  
diacritic translation and various degrees of  
camouflage ................................................................. 591
696
2.2.2. The abandon of Level Independence makes  
boundaries diacritics................................................... 592
697
2.2.3. Since structuralism, the output of translation has  
always been a diacritic................................................ 593
698
2.2.4. No Diacritics ! ± no diacritics ?.................................. 593
699
2.3. Modularity and translation were invented by  
structuralism ......................................................................... 594
700
2.3.1. Non-cognitive modularity: Level Independence  
enforces translation..................................................... 594
701
2.3.2. Translation affords the assessment of phonological 
theories according to their behaviour at the  
interface...................................................................... 594
702
2.4. Generative modularity offenders: reference to  
untranslated morpho-syntactic information.......................... 595
703
2.4.1. Translation was not a standard in generative  
theory until the mid 80s.............................................. 595
704
2.4.2. Turning back the wheel: weak and strong  
modularity offenders in (more or less) recent 
development ............................................................... 596
705
2.4.3. A note on Structural Analogy..................................... 597

xxxviii 
Table of contents ± detail 
§
page
706 3. Local vs. non-local carriers of morpho-syntactic information..... 598
707
3.1. Local boundaries vs. non-local domain-based  
intervention........................................................................... 598
708
3.2. Notational variants and real differences ............................... 599
709
3.2.1. Domain-based can be translated into local  
reference and vice-versa............................................. 599
710
3.2.2. The difference is conceptual, not empirical................ 600
711
3.3. The local baby and the diacritic bathwater ........................... 601
712
3.4. There can be non-diacritic boundaries, but what would a  
non-diacritic domain look like?............................................ 602
713
3.4.1. Non-diacritic boundaries (can) exist........................... 602
714
3.4.2. Top-down constructions are diacritic by definition 
(prosodic word and higher)......................................... 603
715
3.4.3. Higher layers of the Prosodic Hierarchy are the 
projection of nothing .................................................. 604
716
3.4.4. Projections created by phonological computation  
cannot be the output of translation ............................. 605
717
3.5. Conclusion: possible carriers reduce to syllabic space......... 606
718 4. Conclusion ................................................................................... 606
719 Chapter 5 
Open questions (general) 
 
720 1. Grammatical architecture: alternatives to the inverted T............. 609
721
1.1. Generative semantics............................................................ 609
722
1.2. Parallel modules.................................................................... 610
723
1.2.1. Against syntactico-centrism (Jackendoff) .................. 610
724
1.2.2. Designated portions of the skeleton project morpho-
syntactic features (Bendjaballah & Haiden)............... 611
725
1.3. Conclusion: the baseline of the generative paradigm is 
modularity............................................................................. 612
726 2. PF ± a strange hermaphrodite animal........................................... 613
727
2.1. Clean syntax, dirty phonology/PF?....................................... 613
728
2.1.1. Minimalism shrinks syntax......................................... 613
729
2.1.2. Minimalism pumps up PF .......................................... 614
730
2.1.3. Dumping into the PF dustbin and hoping that it is  
big enough .................................................................. 614
731
2.1.4. The syntacticians' phonology is not what  
phonologists call phonology....................................... 615

Table of contents ± detail xxxix 
§
page
732
2.2. Confusion and mistiness: what does PF mean, what does  
it contain?.............................................................................. 616
733
2.3. Properties of PF: what kind of animals live in the  
intermundia? ......................................................................... 619
734
2.3.1. Internal structure of PF............................................... 619
735
2.3.2. What happens "at PF"................................................. 619
736
2.4. Trying to make sense of PF from the modular point of  
view....................................................................................... 621
737
2.4.1. PF is a cover term for a number of serially ordered 
computational systems................................................ 621
738
2.4.2. The minimalism-born intermundia violates domain 
specificity ................................................................... 622
739
2.4.3. Mixing phonology and the intermundia ..................... 623
740
2.4.4. The internal structure of the intermundia: two  
distinct derivational stages, morphosyntax and 
morphophonology (Idsardi & Raimy forth) ............... 624
741
2.5. Linearisation ......................................................................... 626
742
2.5.1. Introduction: no business of phonology ..................... 626
743
2.5.2. In minimalist times: no business of syntax either....... 626
744
2.5.3. Both syntax-internal and syntax-external  
linearisation is minimalism-compatible...................... 627
745
2.5.4. Everybody but Kayne does linearisation "at PF" ....... 629
746
2.5.5. Linearisation in phonology in order to derive  
phonetics (Raimy)?..................................................... 631
747
2.6. Conclusion: a minimalism-born monster.............................. 633
748 3. The balance of procedural and representational  
communication............................................................................. 635
749
3.1. Which channel for which phenomenon?............................... 635
750
3.2. Prosodic Phonology tries to get away with peaceful  
coexistence and/or random distribution................................ 636
751
3.3. Random use of both channels is typical (and tacit), but it  
may be doubted that this is the right way to go .................... 636
752 4. Morpho-syntactic structure may, but content (labels) may not  
bear on phonology........................................................................ 637
753 5. The mapping puzzle..................................................................... 639
754
5.1. The issue(s), looked at by more or less helpless linguists .... 639
755
5.2. The mapping puzzle since SPE............................................. 640

xl 
Table of contents ± detail 
§
page
756 6. Privativity..................................................................................... 641
757
6.1. On the representational side: complete or privative  
translation of morpho-syntactic divisions?........................... 641
758
6.1.1. All theories are non-privative since SPE.................... 641
759
6.1.2. Unanimous non-privativity in individual theories...... 641
760
6.2. On the procedural side: selective vs. non-selective spell- 
out ......................................................................................... 643
761
6.3. Five arguments in favour of privativity ................................ 643
762 Chapter 6 
Open questions (procedural) 
 
763 1. Selective spell-out and interpretation-triggering affixes.............. 647
764
1.1. Selective spell-out: what it is and how it works ................... 647
765
1.2. Phase edge and piece-driven phase....................................... 648
766
1.2.1. Spell out your sister: the phase edge in phonology .... 648
767
1.2.2. Piece-driven vs. node-driven phase............................ 650
768
1.3. Systems with non-selective spell-out: Lexical  
Phonology (DM)................................................................... 650
769
1.4. Spell-out is selective in syntax, but is this an argument? ..... 651
770
1.5. Conclusion: a unifying perspective....................................... 653
771 2. Phase theory................................................................................. 654
772
2.1. A rapidly growing field whose diversity can be confusing  
at times (not only for phonologists)...................................... 654
773
2.2. What counts as a phase? ....................................................... 655
774
2.2.1. Inner- and extra-syntactic criteria for distributing 
phasehood................................................................... 655
775
2.2.2. The trend is towards atomisation................................ 656
776
2.2.3. Is there a lower limit for phasehood? Is spell-out 
selective? .................................................................... 657
777
2.2.4. Anti-locality of movement marshals atomisation....... 658
778
2.3. Extensions of the basic model .............................................. 659
779
2.3.1. Asymmetric spell-out: independent access of LF  
and PF......................................................................... 659
780
2.3.2. PIC à la carte: process-sensitive no look-back ........... 659
781
2.3.3. Phase Extension: when phasehood depends on  
what the head is made of ............................................ 661
782
2.3.4. Unification of piece-driven and node-driven phase  
by a lexical phasehood feature.................................... 662

Table of contents ± detail xli 
§
page
783 3. No look-back (Phase Impenetrability)......................................... 663
784
3.1. Limited scope of this section ................................................ 663
785
3.2. No look-back devices since Chomsky (1973) and their  
non-conflatability with derived environment effects............ 664
786 4. Why are there no phonological effects of the cyclic spell-out  
of words?...................................................................................... 665
787
4.1. The absence of cyclicity-induced external sandhi:  
a consensual fact that theories build on, but do not talk  
about ..................................................................................... 665
788
4.2. How interface theories behave: claims for and against  
cyclic spell-out of words, for and against its cyclic 
interpretation......................................................................... 666
789
4.2.1. The baseline position of SPE: everything is cyclic .... 666
790
4.2.2. Lexical Phonology: the interpretation of word  
sequences is not cyclic................................................ 666
791
4.2.3. Lexical Phonology makes no claim about  
spell-out and installs non-cyclic interpretation  
of word sequences without argument ......................... 667
792
4.2.4. Halle & Vergnaud and Kaye: restoration of SPE  
± everything is cyclic.................................................. 668
793
4.2.5. Distributed Morphology is entirely agnostic in 
phonological matters .................................................. 668
794
4.3. The word-spell-out mystery.................................................. 669
795
4.3.1. Cyclic spell-out of words but no phonological  
traces?......................................................................... 669
796
4.3.2. Wrong data or an on/off switch for Phase  
Impenetrability ........................................................... 669
797
4.3.3. A solution: (chunk-specific) PIC à la carte ................ 670
798
4.3.4. PIC à la carte that does not want to be named  
 (Samuels 2009a)........................................................ 671
799
4.3.5. Phase Impenetrability is a property of the spell- 
out mechanism, not of concatenative or  
interpretational systems.............................................. 672
800 4.4. Intonation requires cyclic spell-out of words for sure ± but  
this does not appear to concern phonological computation ...... 674
801
4.4.1. Intonation is governed by syntactic structure............. 674
802
4.4.2. Prosodic structure may be recursive ± phonology  
is not ........................................................................... 675

xlii 
Table of contents ± detail 
§
page
803
4.4.3. Phonology is not recursive: confusion between  
non-recursive phenomena and their eventual  
analysis with recursive constructions ......................... 676
804
4.4.4. Prosodic structure is not created by phonological 
computation................................................................ 678
805
4.4.5. Phonology only interprets: Merge must be absent,  
hence the result of phonological computation is flat.. 679
806
4.4.6. Is intonation a phonological phenomenon at all? ....... 680
807
4.5. Conclusion............................................................................ 681
808
4.5.1. If the generalisation is correct, Praguian  
segregation alone will not do...................................... 681
809
4.5.2. Chunk-specific PIC à la carte..................................... 682
810
4.5.3. Outlook....................................................................... 683
811 5. Chunk-specific phonologies......................................................... 683
812
5.1. Specific world-level phonology............................................ 683
813
5.1.1. Everybody has a word-specific phonology ................ 683
814
5.1.2. Since SPE, word-specific phonologies are based  
on (English) stress ...................................................... 684
815
5.2. Specific sentence-level phonology: Praguian segregation.... 685
816
5.2.1. Cyclic phonology of morphemes vs. non-cyclic 
phonology of words.................................................... 685
817
5.2.2. Arguments for Praguian segregation.......................... 686
818
5.3. Praguian segregation and double dissociation...................... 686
819
5.3.1. Double dissociation applied to Praguian  
segregation.................................................................. 686
820
5.3.2. Processes that are restricted to morpheme  
sequences.................................................................... 687
821
5.3.3. Processes that apply across the board......................... 688
822
5.3.4. Processes that are restricted to word sequences ......... 689
823
5.4. PIC à la carte......................................................................... 691
824
5.4.1. Multiple mini-phonologies and chunk-specific 
phonologies................................................................. 691
825
5.4.2. Process-specific PIC, rather than "don't undo!" ......... 692
826
5.4.3. PIC à la carte: process- and chunk-specific................ 693
827
5.5. Conclusion............................................................................ 694

Table of contents ± detail xliii 
§
page
828 6. Morpheme-specific mini-phonologies (level 1 - level 2)............. 695
829
6.1. Cyclicity analysed by morpheme-specific mini- 
phonologies vs. by no look-back: a major front line in 
generative interface theory.................................................... 695
830
6.2. Intermodular argumentation: if the PIC exists in syntax,  
it must be active in phonology as well.................................. 696
831 7. Empirical coverage ...................................................................... 697
832
7.1. Introduction: three competitors and the empirical record  
 (affix class-based phenomena)............................................. 697
833
7.2. Affix class-based phenomena............................................... 698
834
7.2.1. The rule-blocking pattern ........................................... 698
835
7.2.2. The rule-triggering pattern.......................................... 699
836
7.2.3. Is the rule-triggering pattern less real? ....................... 701
837
7.3. Derived environment effects................................................. 701
838
7.3.1. A separate issue.......................................................... 701
839
7.3.2. A blooming landscape of analyses ............................. 702
840
7.3.3. Anti-cyclic phenomena: derived environment  
effects have a big brother ........................................... 703
841 Conclusion 
 
Intermodular argumentation 
 
842 1. Trying to get a handle on the interface ........................................ 705
843
1.1. Looking at the interface through the prism of its history...... 705
844
1.2. Two more prisms used: Interface Dualism and modularity.. 705
845
1.3. Three theory-external ways to get a handle on interface  
theory.................................................................................... 706
846 2. Intermodular argumentation......................................................... 707
847
2.1. Intermodular potential of interactionist derivation by  
phase ..................................................................................... 707
848
2.1.1. Each end of the interactionist pipe may impact the  
other............................................................................ 707
849
2.1.2. Morpho-syntax can referee competing phonological 
analyses and theories.................................................. 708
850
2.1.3. Intermodular arguments can only be made through  
the procedural channel: translation is arbitrary .......... 708
851
2.2. Conditions and limitations of intermodular argumentation.. 709

xliv 
Table of contents ± detail 
§
page
852
2.3. Six properties of spell-out that can be made intermodular 
arguments.............................................................................. 709
853
2.3.1. Convergence of syntactic and phonological tools ...... 709
854
2.3.2. Strong and weak version of the intermodular  
argument..................................................................... 710
855
2.3.3. Import of phonology-based mechanisms into  
syntax.......................................................................... 711
856
2.3.4. Four syntactic referees for phonological theories  
and the special status of interactionism...................... 711
857
2.3.5. Phonology must provide for a "freezing" PIC,  
selective spell-out and the phase edge........................ 712
858
2.4. How many spell-out mechanisms are there in grammar?..... 713
859
2.4.1. The parallel is always between the spell-out of 
morphemes and words................................................ 713
860
2.4.2. The weak version of the argument can be made,  
but the strong version hinges on the unity of  
morphology and syntax .............................................. 714
861
2.4.3. The word-spell-out-mystery strikes again.................. 714
862
2.5. Conclusion............................................................................ 715
863 References....................................................................................... 717
864 Subject index .................................................................................. 785
865 Language index .............................................................................. 838
866 Index of phenomena....................................................................... 843

Table of graphic illustrations 
 
§
description 
table 
number 
copyright 
page
592 an atom: scientific reality (243a) 
free .........................................503
592 a transistor: symbolic 
(243b) 
GNU Licence.........................503
592 a transistor: physical 
(243c) 
GNU Licence.........................503
601 Franz Joseph Gall 
(252) 
free .........................................515
601 
 
American Phrenological 
Journal, 1848 
(253) 
free .........................................516
601 
 
Webster's Academic 
dictionary, 1895 
(253) 
free .........................................516
612 optical illusion: Zöllner 
(255) 
GNU Licence.........................525
612 optical illusion: Müller-
Lyer 
(255) 
GNU Licence.........................525
612 optical illusion: 
Poggendorff 
(255) 
GNU Licence.........................525
612 optical illusion: Hering 
(255) 
GNU Licence.........................525
All graphic illustrations are taken from Wikipedia (August 2010).  
 


1
Editorial note 
 
This book is a piece of a manuscript that was circulated since October 
2008, but (unsurprisingly) turned out to be too long to fit into the covers of 
a single book. The manuscript ran under the same title as the present book 
and was designed as the second volume of Scheer (2004a). Back in 2001 
when I started working on Scheer (2004a), it was meant to be the third part 
of it, but in the end had to be outsourced because the project grew hope-
lessly out of size.  
The ancestor of the 2008 manuscript was thus ready in 2003, and it 
was intended to become Vol.2 of the book that was published in autumn 
2004. At the outset of Scheer (2004a), I was naïve enough to believe that 
"[w]hen this editorial note was written (August 2004), the second volume 
was almost completed in draft. The constant reference that is made to it 
here should therefore reflect its divisions quite closely." Little did I know 
about the fact that the work on the manuscript would take another six years. 
And that it would end up the same way as the manuscript of Scheer 
(2004a): too long in order to be published within the covers of a book. The 
outsourcing thus continued in the way described below, and I hope that the 
piece which did not make it into the book that the reader holds in hands 
will really be published as a whole without further subdivision in the future 
(and earlier than six years from now, i.e. October 2010). 
The manuscript dated October 2008 was made of three Parts: 
 
1. Morpho-syntactic information in phonology: a survey 
since Trubetzkoy's Grenzsignale 
 
2. Lessons from interface theories 
 
this book 
3. How translation works: Direct Interface and just one 
channel 
±
Vol.2 
 
The book that the reader holds in hands encompasses the first two 
Parts. It thus proposes a history of the morpho-syntax →phonology inter-
face (in this direction only, Parti I), an Interlude that presents modularity 
from a Cognitive Science perspective, and a catalogue of design properties 
that a sound theory of the interface should or must not be based on given 
the lessons from the historical survey, the Cognitive Science background 
and the current (minimalist) landscape of generative grammar (Part II). 
The original Part III exposes my own view of the interface and will 
(hopefully) make it into an independent book. For reasons explained in the 
foreword and in § 42 below, this further book may be legitimately called 

xlviii Editorial note 
volume 2 of Scheer (2004a), while the present book is a stand-alone piece 
of work that has only an implicit relationship with Scheer (2004a). There-
fore, the forthcoming volume that accommodates the original Part III of the 
manuscript is referred to as Vol.2 below, while Scheer (2004a) appears as 
Vol.1.  
Beyond the obvious issue regarding the size of the original manu-
script (871 pages), the decision to make Part I and Part II a stand-alone 
book is motivated by the fact that they are thematically independent and 
theory-unspecific. 
Finally, it is worth mentioning that if the present book is largely 
identical to the aforementioned 2008 manuscript, the feedback from various 
sides that I have received (see the end of the foreword) and the final revi-
sion process have reshaped a number of sections and chapters quite signifi-
cantly. For example, a piece that was completely rewritten is the history of 
modularity in GB (§ 622). Also, topics are now discussed that were absent 
from the draft, or underexposed: these include Prosodic Morphology 
(§ 442), the strange hermaphrodite animal PF (§ 726), linearisation (§ 741), 
the adaptation of Prosodic Phonology to the phase-based environment 
(§ 462) and the early history of modification-inhibiting no look-back in the 
80s (§ 293). Thus it may still be worthwhile opening the book for readers 
who have already struggled with the manuscript. 
 

2
Foreword 
 
The plot, and how to use the book 
 
The ambition of this book is twofold, corresponding to its two Parts: it first 
proposes a history of the interface between morpho-syntax and phonology 
roughly since World War II, and then tries to see where we stand today; the 
Interlude and its position in the book points to the central role that modular-
ity plays in the generative (and minimalist) architecture of grammar. The 
questions asked are: what can we learn from previous endeavour? Is the 
current state of (phonological) theories of the interface really informed of 
earlier results? Which questions are solved, which ones remain open? Is the 
current state of affairs compatible with current (morpho-)syntactic theory 
and especially with the recent phase-based, i.e. interface-based (or even: 
interface-motivated) environment of the minimalist programme? How 
could phonological and morpho-syntactic theories of the interface converge 
(there is no way not to: a consistent theory of grammar must have an inter-
face theory that is compatible with both its input and output)? How can we 
argue with properties of one for or against theories of the other (intermodu-
lar argumentation)? 
The book may thus be accessed in three different ways: through a 
specific theory, through the chronology of events, and thematically. That is, 
the reader may want to know what a specific theory has got to say regard-
ing the interface, he may follow (a particular period of) the development of 
the question since Trubetzkoy, or he may use the thematic summaries that 
structure Part II and the keyword-based access that is offered by the the-
matic index (both distribute into Part I). 
The book is thus devised for a general audience that wants to know 
about the interface and its history, as much as for more specialized interests 
that wrestle with intermodular communication both in syntactic and in pho-
nological quarters: one thing that became increasingly clear to me as the 
book was growing is the fact that syntacticians and phonologists are largely 
unaware of the interface theories that are developed on the other side, 
which however may directly impact their work. 
In this context, modularity will be a key concept that escorts the 
reader all through the book as a guiding light. On the one hand, it is the 
basic idea about the architecture of grammar that unites structuralist and 
generative thinking; on the other hand, it offers an extra-linguistic reference 
point which sets the cognitive frame of interface theories and is able to 

l
Foreword 
referee them. This contrasts with the (phonological) interface literature 
where modularity is more or less irrelevant in practice (see § 36).  
 
It was mentioned in the editorial note that the book is actually a piece (in 
fact the lion share) of a manuscript that was originally intended to be the 
second volume of Scheer (2004a). The two Parts (and the Interlude) that 
now appear as the present book are the result of the fact that at some point I 
wanted to make sure that my own view of the interface ± Direct Interface ± 
does not reinvent the wheel. Direct Interface (which is introduced in the 
original Part III, also Scheer 2008a, 2009a,c) is based on the idea that only 
truly phonological objects can be the output of translation, that is, be repre-
sentational carriers of morpho-syntactic information in phonology. Unfor-
tunately, this claim had been made in Prosodic Phonology before, where the 
Prosodic Hierarchy was taken to be "truly phonological" (as opposed to 
diacritic SPE-type boundaries) (see §§ 405, 690). 
In order to find out that the "truly phonological" objects of Prosodic 
Phonology, i.e. the constituents of the Prosodic Hierarchy, are in fact dia-
critics in an autosegmental guise, I had to read through the foundational 
literature of this theory, which dates back to the early 80s. This reading then 
expanded to other "old stuff", which was growing older and older as I was 
gaining ground. About five years later, the result is this book on the (history 
of the) interface. 
The Introduction below provides further detail regarding the prisms 
that are used in the book in order to look at the interface, its structure and 
the delineation of its object of study. It also explains the kind of historiog-
raphy that is practised. 
The book may thus be described as a kind of necessary prelude to 
Part III of the original manuscript. This Part III being absent, however, the 
book acquires a stand-alone virtue: it is thematically consistent, and there is 
no reference to Government Phonology in general (except of course in the 
chapter on this specific theory) or to CVCV (strict CV) in particular. The 
bonds with Vol.1 are thus delicate, if any. Hence the decision, counter to its 
genesis, to have the book run as an independent item: it is well suited to 
stand on its own feet, and calling it volume two of Scheer (2004a) would 
have been inconsistent since the reader would have found no continuation 
or development of CVCV. 
This being said, let me explain in which way the book prepares Part 
III, which will also stand alone, as the true Vol.2 of Scheer (2004a). Again, 
the bond is Prosodic Phonology and something that may be called defores-
tation (see § 42): following the lateral core of Government Phonology, Vol.1 

Foreword li 
has worked out a lateral analysis of syllable structure, which is traditionally 
represented by trees. That is, lateral relations among constituents (govern-
ment and licensing) take over the function of arboreal structure, which is 
thus eliminated at the syllabic level.  
The present book follows up on this by doing away with the arboreal 
representation of morpho-syntactic information (i.e. the Prosodic Hierar-
chy), which is shown to be diacritic and hence unwarranted. Phonology, 
then, is entirely flat: no concatenation of any pieces, no Merge (or other 
tree-building device), no projection, no trees (trees are also absent below 
the skeleton if melodic representation is a matter of monovalent primes).  
The rationale behind deforestation is twofold. For one thing, the lat-
eral and the tree-based approaches to syllabic structure do the same labour 
and are therefore mutually exclusive: (at least) one of them must be wrong 
(see Vol.1:§165). The other reason for deforestation is the fact that in the 
generative architecture of grammar PF and LF are "merely" interpretational 
devices: concatenation is the privilege of (morpho-)syntax. Hence PF and 
LF do not concatenate anything, and if Merge is the universal concatenative 
engine, it must be absent from phonology. This means that there is no tree-
building device, and hence that there are no trees in this module. The ab-
sence of trees, in turn, explains why there is no recursion in phonology (see 
§42).  
It was mentioned that Part III of the original manuscript exposes Di-
rect Interface, my own view of how morpho-syntax talks to phonology. 
Direct Interface draws the consequences from the lessons that are estab-
lished in Part II: it is introduced as an answer to deforestation, i.e. the need 
for non-diacritic carriers of morpho-syntactic information in phonology. 
This programme is supplemented with the discussion of consequences for 
interface theory (non-computational translation of morpho-syntactic infor-
mation into phonological objects through a lexical access) and CVCV, as 
well as with an application to the representation of the beginning of the 
word in phonology (the so-called initial CV). A brief description of Vol.2 is 
provided in § 49. 
While writing the book and preparing the manuscript for print, a 
number of pieces have been published in form of articles (or are underway). 
The reader may find it useful to rely on them in parallel since they con-
dense this or that aspect of the book in a reasonably sized stand-alone item. 
Three articles concern the procedural side of the interface (i.e. cyclic spell-
out and the PIC): Scheer (2008c) (on the parallel between the edge of the 
phase in current syntactic theory and interpretation-triggering affixes in the 
classical phonological literature: in both cases the sister of actual phase 

lii Foreword 
head is spelled out, see § 765), Scheer (2009b) (on the word-spell-out mys-
tery, see §§ 786, 851) and Scheer (2010b) (on the number of computational 
systems in phonology, see § 828). 
Another article, Scheer (2008a), is about the diacritic issue: the Pro-
sodic Hierarchy is as much a diacritic as the hashmark (if in an autoseg-
mental guise) and therefore has to go (see §§ 402, 692). Finally, two articles 
are outsourced from Vol.2 (Part III): Scheer (2009a) and Scheer (2009c) 
concern external sandhi, the phonological motivation of phases above the 
word level and the question of how the beginning of the word is repre-
sented (the initial CV is phase-initial, rather than word-initial). 
 
Finally, a few words are in order regarding ideas and people that were im-
portant while writing the book. The treatment of the central issue regarding 
modularity (actually more in the forthcoming Vol.2 than in the present 
book) owes to (unpublished work by) Michal Starke and his classes at vari-
ous EGG summer schools (Novi Sad 2002, Cluj 2004, Olomouc 2006). On 
another front, the book was written in parallel with Ricardo Bermúdez-
Otero's Stratal Optimality Theory (Bermúdez-Otero forth a), a sister project 
regarding the interface (that is still to appear). Ricardo's book has also a 
strong historical inclination. Over the years, we entertained a continuous, 
gentle and critical conversation about our shared interests, and occasionally 
our diverging views, which has had quite some effect, especially on my 
understanding of Lexical Phonology. It looks like in the end I will win the 
race for publication ± which means that Ricardo will not have to quote page 
and section numbers of forthcoming manuscripts. 
A number of people have helped improving the book a lot over the 
six years of work that it took to get to this foreword. Namely the feedback 
based on the 2008 manuscript was rich and invaluable. Asking people to 
read 871 pages is very impolite and unrealistic ± and it does not make 
friends. The natural reaction is to shy away when opening the parcel. Three 
readers were masochistic enough not only to really go through the manu-
script from cover to cover, but also to write up pages and pages of detailed 
comments: Marc van Oostendorp, Diana Passino and Gaston Kočkourek. 
They are to be thanked in the first place.  
Terje Lohndal took the trouble to comment on the pieces of the 
manuscript that directly deal with syntactic theory (and its history). Since 
of course I am as ignorant in syntactic matters as a phonologist can be and 
had to work hard in order to have a remote chance not to utter monkeyshine 
when it comes to syntax proper, Terje's look at the text through the syntac-

Foreword liii 
tic lens and the detailed correspondence with him have made the book 
much less unreadable for syntacticians. 
Finally I am also indebted to Grzegorz Michalski, Markéta Ziková, 
Artur Kijak, Katérina Jourdan and Victor Manfredi for valuable feedback. 
 
Châteauneuf de Grasse, October 2010 
 


3
Introduction 
 
4
1. Procedural and representational communication with phonology 
 
5
1.1. Cyclic derivation and hashmarks 
 
This book discusses how morpho-syntactic information is shipped to and 
processed by phonology. It has a number of characteristics, which are 
fleshed out in the introduction below. 
The most prominent characteristic of the book, regarding both its or-
ganisation and content, is certainly the procedural-representational prism 
that is used in order to look at the interface and at interface theories. There 
are two ways for morpho-syntax to bear on phonology: procedurally and 
representationally. The former is a genuinely generative invention that has 
come into being in Chomsky et al. (1956:75) and was successively known 
as the transformational cycle, the phonological cycle, cyclic derivation and 
finally today as derivation by phase (in syntactic quarters). It embodies the 
insight that (phonological and semantic) interpretation applies successively 
from the most to the least embedded piece. It will therefore be sometimes 
referred to as inside-out interpretation in the book. 
The other means by which morpho-syntax can influence phonology 
is through the insertion of a representational object into the linear string 
that is submitted to phonological computation: morpho-syntactic structure 
is translated into items which are processed by phonology. This is the tradi-
tional interface management which is practised (at least) since the 19th cen-
tury, and in any case is shared by structuralist and generative thinking: car-
riers of extra-phonological information in phonology have successively 
incarnated as juncture phonemes, SPE-type diacritics (# and the like) and 
the Prosodic Hierarchy, each being the representative of its time. That is, 
carriers of morpho-syntactic information were (juncture) phonemes when 
phonemes were the basic currency in phonological theory, they were made 
segments in SPE (# was supposed to be a [-segment] segment) where the 
basic phonological units were segments, and finally became autosegmental 
domains (prosodic constituency) in the early 80s when all areas of phonol-
ogy were autosegmentalised. 
One goal of the book is to show that all objects which were thought 
of as the output of translation thus far are diacritics and therefore do not 
qualify (including the Prosodic Hierarchy: recall from the foreword that 

2
Introduction 
this was my original motivation to dive into historiography). Direct Inter-
face, to be introduced in Vol.2 (also Scheer 2008a, 2009a,c), is about the 
elimination of all diacritics that mediate between morpho-syntax and pho-
nology. 
 
6
1.2. Interface Dualism: both means of talking to the phonology are needed 
 
Following this orientation, the book systematically distinguishes between 
procedural and representational aspects of the interface. It defends what I 
call Interface Dualism, i.e. the idea that natural language provides for and 
uses both channels: theories that try to reduce interface activity to either 
channel are on the wrong track. The interface landscape as it stands today is 
structured along this fraction line anyway: roughly speaking, Lexical Pho-
nology (and its modern offspring: DOT, Stratal OT) is the procedural the-
ory of the interface, while Prosodic Phonology (and its modern offspring) is 
the representational theory of the interface.  
The book shows that the two aspects are complementary, rather than 
in competition. As we will see as we go along (see the summary in § 748), 
the interplay of procedural and representational means of managing inter-
face phenomena has always been vague, to say the least: typically the ques-
tion is not even addressed, and phonologists have actually put much effort 
into not bringing it up. The result is an undetermined peaceful coexistence 
(don't look at me, so I won't look at you) that was installed in the 80s (see 
§423, save two punctual attempts at reducing the interface to the represen-
tational channel), and is still the diplomatic standard today. 
A discussion that defines the rule of the game in order to arrive at a 
proper division of labour that does away with overlap is certainly war-
ranted: "show me your interface phenomenon, and I tell you whether it is 
due to procedural or representational activity" would be the ideal situation. 
The book is not a good place to call for this debate, though, since it does 
not make any contribution. I have tried to classify interface phenomena (i.e. 
phonological processes that are influenced by morpho-syntactic informa-
tion) for several years, at least into three categories: "procedural only", 
"representational only" and a misty in-between that could be due to either. 
In the end I have given up on this because of the complexity of the task (see 
the summary of this issue in § 748). 
There is just a very broad indication left that is based on the opportu-
nity of intermodular argumentation (on which more in §§ 17ff): Procedural 
First. That is, when competing procedural and representational analyses are 

Functional historiography 
3
empirically equivalent, choose the former because it may make predictions 
in morpho-syntax that can be controlled independently of phonological 
evidence (see § 316). On the empirical side, the issue is discussed on the 
occasion of what I call the word-spell-out mystery (chunk-specific pho-
nologies § 786, see § 22 below), and also in Vol.2 where so-called connected 
speech (i.e. external sandhi, cases where phonology applies across word 
boundaries) is examined. 
In any event, one day the question will have to be seriously ad-
dressed: which interface phenomena are due to procedural activity, against 
which other phenomena that are the result of representational communica-
tion? In absence of a significant contribution, the book can at least call for 
upgrading the issue on the research agenda. 
 
7
2. Functional historiography 
 
8
2.1. Anderson's dualistic legacy: structure and process 
 
The reader will have noticed that the procedural-representational prism 
which the book uses in order to look at the interface is much like the struc-
ture-process opposition that makes the spine of Stephen Anderson's (1985) 
history of phonology in the 20th century.  
Using this prism produces results that strike close to the mark ± at 
least in Anderson's case. Writing at the peak of the representational (auto-
segmental) wave and having observed the see-saw movement of phonology 
between process- and representation-oriented extremes, Anderson just had 
to extrapolate what comes next: another round of the computational ex-
treme, in revenge to the representational excess. Phonology was thus pro-
grammed to produce OT, which entered the scene a couple of years later. 
Anderson predicted its arrival, but little did he know how extreme this 
round of "phonology is computational and nothing else" could get: SPE is 
by far outcompeted. This is certainly not unrelated to the connectionist 
roots of OT (§ 529): connectionism knows only computation, objects (sym-
bols) do not exist (§ 593).  
Today there is a strand in OT (still timid but sensible, e.g. Blaho et 
al. 2007) which tries to rebalance the system by making representations 
(which are not "emergent") independent of constraints, and by crediting 
them with a true arbitral award (also independent, i.e. which cannot be out-
ranked by constraints). 

4
Introduction 
Anderson's legacy is dualistic in nature: at the end of his book he 
warns phonologists to believe that representations alone provide access to 
felicity ± but also that the next round of "computation is king" will not be 
any more successful than preceding attempts to reduce phonology to com-
putation. His words were not marked, and we assisted a computational fes-
tival for about a decade. The peak of this cycle may now be behind us, and 
it seems that here and there representations begin to play a role again that is 
not controlled by computation. All this notwithstanding, it goes without 
saying that OT has made a valuable contribution to computational theory 
and the expression of parametric variation: the study of computation is not 
objectionable ± but the ambition to make it (or rather: the fact of making it) 
the only thing that determines grammaticality is (see Scheer 2010a). 
Rather than oscillating between the procedural and the representa-
tional end of the spectrum, one may incline to believe that phonology 
would be better advised to break out of this cyclic movement. Each genera-
tion is reinventing the wheel of the teachers of their teachers ± always in a 
new guise, with different vocabulary and promising that this time the pro-
gress will be unequalled. This vicious circle seems to be entirely unim-
pacted by the fact that Anderson has made the see-saw movement explicit, 
together with its prejudicial effects. 
The aforementioned Interface Dualism thus follows Anderson's foot-
steps: as much as in phonology proper, both procedural and representa-
tional activity is needed at the interface.  
Alongside with the request for a sound balance between structure and 
computation, another dualistic property of adult science is a related point of 
interest which, unfortunately, characterises phonology less and less in re-
cent years. Representatives of adult science know that the scientific truth is 
where theoretical prediction (top-down) and empirical data (bottom-up) 
meet, and that one cannot exist without the other. What we are living 
through today, however, is a period of empiricist conquest (Katz & Bever 
1974 describe the cyclic return of empiricism in linguistics), the present 
wave being usage-based or even "cognitive" (Bybee 2001, Langacker 1987 
et passim). Sciences are characterised by an infantile empiricist period 
upon inception: "the more primitive the status of a science is, the more 
readily can the scientist live under the illusion that he is a pure empiricist" 
(A. Einstein). The problem with linguistics, and specifically with phonol-
ogy, is that empiricist waves roll ashore every couple of decades. 
 

The syntactic frame: minimalist phase theory 
5
9
2.2. Historiographic cherry-picking 
 
It is obvious from the preceding that historiographic activity in this book is 
not an end in itself: it serves a purpose and has a function in a broader ar-
gumentation. In this sense, the (hi)story that is told in this book has the 
same ambition as what traditionally made the motivation of historians: to 
learn from the past in order to understand the present, and to shape the fu-
ture. Knowing about the past is a good vaccination against multiple rein-
ventions of the wheel. 
The book thus tries to get a handle on present-day interface theories 
by looking at the past: history is taken as a source of insight into those 
properties that a correct interface theory should have, and into those that it 
must not have. 
Given this premise, not just any way of telling about past theories of 
the interface will do. Everything that Part I and Part II (as well as the Inter-
lude) report on is weighed according to its contribution to the demonstra-
tion: something is to be shown, and things that are mentioned are somehow 
relevant in this context. Also, a decision is made how important a given 
fact, analysis, period, mechanism or theory is according to the goal of the 
demonstration. This means that something which is taken to be a major fact 
about the interface may be relegated to a few lines in a sub-section, while 
some other item may be discussed over a whole chapter even though it does 
not usually appear as a relevant property of the interface in the literature. 
This way of proceeding may be called historiographic cherry-
picking. In practice, though, the former situation where a notorious fact is 
hardly explored does not really occur (I hope): cherry-picking is only done 
in the frame of a certain ambition at exhaustivity. On the other hand, there 
are cases of "positive" cherry-picking, i.e. where issues that the interface 
literature does not (or hardly) talk about are put into the spotlight. Exam-
ples include the local (roughly, boundaries) vs. non-local (domain-based, 
roughly the Prosodic Hierarchy) insertion of representational objects into 
the phonological string (§ 706), modularity (§ 844), selective spell-out 
(§ 763) and privativity (§ 756). 
The kind of history that is told is thus not neutral or impartial: it is 
goal-oriented and functional. Admitting that one does not look at facts like 
a robot, that one does not try to marshal oneself down to strict neutrality, is 
but a description of reality: there is no such thing as unoriented and purely 
factual historiography; those who pretend that history can be told from a 
strictly neutral vantage point merely try to achieve a rhetorical advantage 

6
Introduction 
that knights their own partial view on the facts with the promise of objec-
tivity.1
The question is not whether history-telling is partial and oriented or 
not; the only thing that it is worth bothering is the degree of partiality and 
orientedness. Everybody has his own, and the kind of bias at work may be 
very different. Also, the best history is not necessarily the one that is writ-
ten with the least degree of partiality: Michelet's history of the French 
Revolution is anything but impartial, but still invaluable today. History is 
not a concentration of unrelated and uninterpreted facts; it is only history 
when it makes sense, and sense can only be made by the historian from 
hindsight. 
Science is after insight, rather than after methodological correctness, 
impartiality or other formal and secondary virtues: this point is constantly 
made by Noam Chomsky since the 60s (e.g. Chomsky 1965:20). What can 
be done in order to facilitate the task of the reader is to make biases ex-
plicit. This is what is done in this introduction (as much as possible), which 
identifies the prisms that are used in order to look at the interface. 
 
10  2.3. No "external" history: only scholarly work is used 
 
Finally, a word is in order regarding the fact that the history of interface 
theories which is presented in this book is only "internal", that is, based on 
published (or unpublished, but written) scholarly work. Only incidentally 
will oral information be a relevant source. As far as I can see, there is only 
one case in point: Kaye's work on parsing cues (§ 340) and lexical access 
(§ 346), which is not available in print (for almost twenty years now). 
 
1
Regarding the history of linguistics, see Koerner (2002a:154f) for a different 
position that promotes a kind of enlightened positivism ("broad positivism" in 
Koerner's words), which is close to pure historiography (i.e. tries to show "what 
really happened"), declines any ambition to explain the present and to act on 
the future, but admits that there is no absolute objectivity, and that somebody 
must make sense of the "facts". 
In no case is any "external" history solicited: who was friends with 
whom, who broke up with whom because of an unpleasant review, who 
was the teacher of whom and programmed his pupils to think this or that 
way, who was married with whom, who studied where, who has which 
character sketch in the opinion of whom, who wrote which letter or e-mail 
to whom and so on play no role in the book. 

The syntactic frame: minimalist phase theory 
7
Of course, this is not to deny the possibility to gain insight through 
the study of "external" or social factors, or to assert that they have no bear-
ing on how interface theory developed. They certainly did to some extent. 
But this is simply not the way I look at the interface in this book: coming to 
grips with the scholarly record is serious enough a challenge; digging out 
social factors from oral information would require entirely different tech-
niques of investigation. 
 
11  3. The syntactic frame: minimalist phase theory 
 
12  3.1. The inverted T delineates the scope of the book and serves as a referee 
 
An important backdrop of the book is the generative architecture of gram-
mar, the so-called inverted T, which was developed in the 60s (Chomsky 
1965:15ff, §§ 86, 623 discuss its genesis at greater length) and since then 
stands unchallenged in generative quarters (the generative semantics inter-
lude and Jackendoff's parallel alternative lain aside, see § 24): a concatena-
tive device (morpho-syntax) feeds two interpretative devices (PF and LF). 
We will follow the career of the inverted T and its impact on inter-
face theories in Part I, but the interest is not merely historiographic: the 
inverted T delineates the scope of the book. That is, theories which follow a 
different architectural setup are mentioned, but not evaluated (see §§ 24, 720 
below). Also, the inverted T in its modern guise, i.e. phase theory, is used in 
Part II as a measure for the evaluation of interface theories.  
Finally, the minimalism-induced biolinguistic programme (initiated 
by Hauser, Chomsky & Fitch 2002, opposed by Pinker & Jackendoff 
2005a,b) that is designed to downplay UG and properties of language that 
are specifically linguistic (see §§ 609, 633, 639) does not fundamentally 
modify the interface landscape. Even if it were true that the only specifi-
cally linguistic property of language is recursion and hence that specifically 
linguistic mechanisms reduce to Merge and Phase, morpho-syntax would 
still have to talk to phonology (and semantics), the only difference being 
that phonology (and semantics) are based on more general cognitive 
mechanisms that are not specifically linguistic (or even species-specific, 
see e.g. Samuels 2009a,b).  
If thus (what is specific to) language reduces to (certain aspects of) 
morpho-syntax, the question of language-internal modular structure is cer-
tainly obsolete (there is no such thing), but the relations of morpho-syntax 
with phonology and semantics need to be organised in the same modular 

8
Introduction 
environment as before. The only difference is that PF and LF are not con-
sidered linguistic anymore: morpho-syntax will talk to them like it talks to 
other cognitive modules such as audition and vision. 
The sections below discuss in which way the minimalist focus on the 
interface has turned the interface landscape upside down by making it in-
teractionist and therefore allowing for what I call intermodular argumenta-
tion. Also, in necessary anticipation of Part I and Part II, we will see that a 
number of central properties of current syntactic phase theory have actually 
been invented in phonology.  
Note that all this only concerns the procedural side of the interface: 
modern phase theory is transparent for representational communication 
with phonology. The inverted T as such, however, impacts both procedural 
and representational communication. 
 
13  3.2. Interactionism, selective spell-out and no look-back devices (PIC) 
 
14  3.2.1. When the generative mainstream became interactionist 
 
Since its inception and until 1998/99, the inverted T was supplemented with 
a proviso which requires that all concatenation be done before all interpre-
tation. That is, the morpho-syntactic derivation is first completed, and the 
result (S-structure) is then sent to PF and LF in one go (SPE).  
An alternative view of the communication between morpho-syntax 
and LF/PF was formulated in phonology in the early 80s: the backbone of 
Lexical Phonology, so-called interactionism, holds that concatenation and 
interpretation are intertwined. That is, first some pieces are merged, the 
result is interpreted, then some more pieces are concatenated, the result is 
again interpreted, and so on (§ 146).  
While GB-syntax of that time hardly produced any echo, generative 
orthodoxy in phonology reacted on this violation of "all concatenation be-
fore all interpretation": Halle & Vergnaud (1987a) propose a non-
interactionist version of Lexical Phonology that restores the interface land-
scape of SPE on this count as well as on a number of others (§ 222). 
 

The syntactic frame: minimalist phase theory 
9
15  3.2.2. Selective spell-out 
 
Halle & Vergnaud (1987a) also promote a new idea: selective spell-out. 
Since cyclic derivation was introduced by Chomsky et al. (1956:75) and 
formalized in Chomsky & Halle (1968:15ff), interpretation was held to run 
through the bracketed string (that is inherited from S-structure) from inside 
out. Roughly (see § 103) every morpheme break defined a cycle. Halle & 
Vergnaud (1987a) dispense with this definition of what an interpretational 
unit is: they propose to grant cyclic status only to a subset of morpho-
syntactic divisions. In other words, some nodes trigger interpretation, oth-
ers do not. 
This is what I call selective spell-out, which is exactly how modern 
syntactic phase theory works: in more familiar terminology, nodes may or 
may not be phase heads, hence their material may or may not be an inter-
pretational unit. As far as I can see, the phonological heritage is left 
unmentioned in the syntactic literature since derivation by phase was intro-
duced by Epstein et al. (1998:46ff), Uriagereka (1999) and Chomsky 
(2000a, 2001 et passim) (§ 304). 
This is also true for interactionism: Epstein et al.'s (1998:46ff) Spell-
out-as-you-Merge (see § 776), Uriagereka's (1999) multiple spell-out and 
Chomsky's derivation by phase make the generative interface architecture 
interactionist, exactly along the lines of Lexical Phonology: first you do 
some concatenation, then some interpretation, then some more concatena-
tion etc. For (extra-linguistic) reasons of computational economy regarding 
the limited availability of active memory, a costly cognitive resource (e.g. 
Chomsky 2000a:101, 2001:15, see § 305), modern phase theory applies the 
interactionist world view. Here again, thus, the phonological origin of the 
idea went unnoticed as far as I can see (let alone the anti-interactionist reac-
tion of generative orthodoxy that was mentioned above). 
 
16  3.2.3. No look-back devices (the PIC) 
 
The book also closely follows the footsteps of a question that is intimately 
related to selective spell-out and interactionism: critical for current syntac-
tic phase theory is a device which guarantees that previously interpreted 
strings do not burden further computation ± in Chomsky's terms, strings 
that are returned from interpretation are "frozen" and "forgotten" when 
concatenation resumes. It is only this kind of no look-back device that 
brings home Chomsky's promise of active memory economy. 

10 
Introduction 
No look-back devices are around in generative thinking since 
Chomsky's (1973) Conditions on Transformations. Their offspring ± until 
its recent revival in the guise of the Phase Impenetrability Condition (PIC) 
± was essentially phonological (e.g. Mascaró's 1976 and Kiparsky's 
1982a,b Strict Cycle Condition). No look-back devices are designed to 
prevent computation to consider "old" strings. Depending on their precise 
formulation, however, they may have very different effects, which corre-
spond to the thing that the analyst wants the computation to be unable to 
do. We will see that Chomsky's modern "freezing" no look-back, the PIC, is 
quite different from its 1973 version, and like interactionism and selective 
spell-out has a phonological precedent (§ 287). 
 
17  3.3. Intermodular argumentation 
 
18  3.3.1. The intermodular potential of interactionist phase theory 
 
The interactionist perspective paves the way for what I call intermodular 
argumentation. In contrast to GB, where the completed morpho-syntactic 
derivation was merely dumped into PF (and LF) with a "good bye and don't 
come back", phase theory establishes a two-way pipe between the morpho-
syntactic and the phonological (and semantic) modules. Actors on both 
ends are not free anymore to do what they want: their theories and analyses 
may make predictions on the other end. 
This is what Procedural First is based on (recall this notion from § 6): 
while a particular syntactic or phonological analysis makes predictions on 
the other end of the pipe when the communication is procedural, represen-
tational communication does not offer this opportunity. That is, the transla-
tion of morpho-syntactic into phonological vocabulary is necessarily arbi-
trary and therefore never makes predictions on the other end of the pipe 
(§ 850, also Vol.2). 
The intermodular potential of phase theory, however, has not re-
ceived much attention thus far. Syntacticians use Phase Impenetrability for 
syntax-internal purposes, and phase theory evolves at high speed without 
taking into account what happens when the parcel spends time on the pho-
nological side. On the other hand, phonologists have barely acknowledged 
the existence of phase theory, let alone taken into account the predictions 
that it makes on the phonological side. 
I argue that intermodular argumentation provides stronger evidence 
than what can be produced by modular-internal reasoning: it offers the 

The syntactic frame: minimalist phase theory 
11 
maximal degree of independent assessment that linguists can expect with-
out leaving their discipline. Be it only for that reason, the new interactionist 
architecture that the minimalist perspective brought about is a good thing to 
have: after a long period of more or less waterproof coexistence, syntacti-
cians and phonologists can talk again about things that do not concern the 
weather or job openings. 
Intermodular argumentation shines through on various occasions in 
the book; the different strands are then bundled in the conclusion of Part II 
(§ 841).2
19  3.3.2. Phase theory is the bridge that forces syntax and phonology to 
converge 
 
The existence of a single and interactionist spell-out mechanism that relates 
the morpho-syntactic and the phonological derivation puts pressure on both 
ends of the pipe that ships pieces back and forth: it is hard to see how the 
respective devices could not be identical.  
An obvious example is the fact that the pieces which are exchanged 
must be the same: ideally, thus, we will find phonological and syntactic 
evidence for the same phase boundary. This question is discussed in Vol.2: 
while evidence sometimes converges (e.g. for the CP), phonologically mo-
tivated chunk delineation typically remains unechoed on the other side (e.g. 
the word), and vice-versa (e.g. DP) (see Scheer 2009a,c).  
This of course does not mean that the general idea is wrong; it just 
points to the possibility that there are phases which do not leave traces on 
either side of the pipe. While this is certainly not what linguists want to 
hear (we expect phases to leave traces), it is an empirical question that 
needs to be sorted out, and the diagnostics that I am able to apply are of 
course hopelessly incomplete. That is, in the best case my conclusion will 
turn out to be wrong: every phase boundary that is based on either phono-
logical or morpho-syntactic evidence will be found to leave traces in both 
phonology and syntax at least in some language. 
But phase theory has still a long way to go before this kind of ques-
tion can be addressed, if only because it is far from being stabilised on the 
syntactic side. Phase theory, and especially the question how phasehood is 
defined, are high-ranking items on the research agenda of syntacticians, and 
 
2
Three pieces of the book that revolve around this idea are also published sepa-
rately: Scheer (2008c, 2009b, 2010b). 

12 
Introduction 
the literature therefore produces a blooming variety of options, alternatives, 
extensions and refinements of Chomsky's (2000a et passim) original take 
according to which only vP and CP are phases. It is not easy for a phonolo-
gist to keep track of this field which evolves at high speed (probably syn-
tacticians are puzzled as well), but I did my best to find out about the gen-
eral direction, which is clearly towards the atomisation of phasehood, i.e. 
the recognition of smaller and smaller chunks that are granted phase status 
(see § 771). 
Obviously, it is difficult to hunt down phonological evidence for syn-
tactic phases if the set of what counts as a syntactic phase is constantly 
moving. 
 
20  3.4. Focus on the spell-out mechanism(s?) 
 
21  3.4.1. Minimalist interface orientation: spell-out marshals both morpho-
syntax and phonology 
 
The study of the mutual intermodular conditioning of morpho-syntax and 
phonology slowly shifts interest away from actual morpho-syntactic and 
phonological computation. Instead, the spell-out mechanism comes to stand 
in the spotlight. This is but to be expected in a modular perspective where 
morpho-syntax, phonology and semantics are input-output systems that 
carry out computation, but are blind for what happens before or after their 
activity.  
In this context, the following questions arise: is Phase Impenetrabil-
ity a property of phonology? Or of morpho-syntax? Does phonological 
computation decide to ignore "old" strings? And if so, does morpho-syntax 
single out exactly the same "old" strings that are to be "forgotten"? This is 
not very likely a scenario. Rather, the central mechanism where interpreta-
tional units (i.e. phases) are defined, and where decisions about Phase Im-
penetrability are made, is the device that is responsible for shipping: the 
spell-out mechanism. 
This means that things which have been (or are) thought of as prop-
erties of morpho-syntax or phonology may turn out to be properties of the 
spell-out mechanism. Cases in point are interactionism, Phase Impenetra-
bility and the phase edge (spell out your sister!, see § 765, Scheer 2008c). 
Altogether six devices are discussed in § 851 that could be common to mor-
pho-syntax and phonology, or rather, which characterise the spell-out 
mechanism that itself is common to both modules. 

The syntactic frame: minimalist phase theory 
13 
During the discussion of what it takes for an intermodular argument 
to bite, an old question crops up that is not likely to be solved tomorrow: 
we would need to know whether morphology and syntax are the same or 
two distinct computational systems. On this depends the possibility of hav-
ing more than one spell-out mechanism: if morphology and syntax are in-
dependent, each could come with its own spell-out mechanism. In this case, 
there would be no guarantee that the properties of the spell-out of mor-
phemes (interactionism, Phase Impenetrability etc.) are the same as what is 
encountered for the spell-out of words. If on the other hand morphology is 
just the lower piece of syntax, there can be only one spell-out mechanism, 
which means that intermodular predictions are much more precise (see also 
the word-spell-out mystery discussed next and Scheer 2009b). 
 
22  3.4.2. The word-spell-out mystery 
 
Examples where the cyclic spell-out of morphemes leaves phonological 
traces are commonplace: stress placement in [[párent] hood] and [parént-al] 
for instance is a direct function of the fact that the root is a phonologically 
relevant domain in the first case, but not in the second. The same structure 
[[A] B], however, does not appear to have any impact on phonology if A 
and B are words, rather than morphemes. As a matter of fact, the literature 
(on external sandhi) does not document any cases where the contrast be-
tween [[A] B] and [A B] produces a phonological effect when A and B are 
word-sized or larger chunks. 
This appears to be truly mysterious: hierarchical structure is certainly 
not the privilege of pieces that are smaller than words. On current minimal-
ist assumptions (interactionism), morpho-syntactic structure is sent to pho-
nology piecemeal (derivation by phase). Could a situation then be imagined 
where phonology is sensitive to chunk size? That is, where it reacts under 
the piecemeal fire of morphemes, but simply ignores the fact that it is also 
hit by successive waves of words?  
The default assumption is certainly that an interpretational system is 
sensitive to its input conditions, and in any case there is no reason for one 
particular chunk size (morphemes) to provoke a phonological reaction, 
while another chunk size (words and larger items) leaves phonology unim-
pacted. This is what I call the word-spell-out mystery (see §§ 786, 851). 
The classical solution in phonology was developed by Lexical Pho-
nology, where an on/off switch for cyclicity is proposed for morphology 
and syntax (which are then of course independent computational systems): 

14 
Introduction 
cyclic interpretation (i.e. piecemeal fire) is turned on for the interpretation 
of morphemes (lexical phonology), but off when words are computed (pos-
tlexical phonology).  
Some doubt may be reasonably entertained whether the empirical 
situation is really what the literature describes (i.e. that there are no cases 
where the cyclic spell-out of words leaves phonological traces). In case it 
turns out to be true, though, that phonology is insensitive to the cyclic 
spell-out of words, it is hard to see how chunk-specific phonologies (i.e. 
distinct computational systems that process distinct pieces according to 
their size) could be escaped.  
§794 explores a solution that does not rely on two distinct computa-
tional systems where an on/off switch regulates phonological computation. 
Rather, the on/off switch is on Phase Impenetrability. That is, the spell-out 
mechanism decides whether old strings are or are not submitted to phono-
logical computation: if they are not, a PIC-effect is encountered (i.e., a 
phonological trace of cyclic spell-out is produced); in case they are, no 
PIC-effect is observed. This configuration derives what is called postlexical 
phonology in Lexical Phonology: word sequences get away without any 
phonological trace of cyclic derivation. 
 
23  3.4.3. We need to know more about the spell-out mechanism 
 
The bottom line of all this is that the book raises a number of questions, but 
hardly provides any answers. The questions, however, are valuable I think, 
because they confront syntacticians with phonological issues that all of a 
sudden may become vital for them. This is what intermodular argumenta-
tion is about. 
The same holds true for the status of spell-out, which is a question 
that emerges as this introduction is written: as far as I can see, the genera-
tive literature has not worked out very detailed accounts of how spell-out 
actually works, what it does, what it is unable to do etc. One result of the 
book is certainly that the spell-out mechanism is the central piece of inter-
face theory: much depends on its properties ± and on its status. It can 
hardly be just some appendix to the syntactic derivation, as it is sometimes 
thought of. Spell-out must be able to read morpho-syntactic vocabulary and 
structure, and ± on the assumption that interpretation is chunk-specific ± to 
operate a distinction between different chunk sizes.  
The question, then, is whether this "intelligent" behaviour requires 
the spell-out mechanism to be a computational system in its own right 

The syntactic frame: minimalist phase theory 
15 
which, in a modular perspective, amounts to saying that it is a module. This 
would come close to the architecture of Prosodic Phonology (§ 379) and the 
Jackendoffian picture (Jackendoff 1997, 2002) where an interface module 
mediates between the three modules of the inverted T (see Vol.2 for the 
latter). It may thus be the case that the procedural side of the interface coin 
provides evidence for an "intelligent" mediator à la Jackendoff. This is 
precisely what Michal Starke (and Vol.2) argue against based on the evi-
dence of the representational side of the coin: One-Channel Translation 
holds that the transformation of morpho-syntactic into phonological vo-
cabulary is done through a lexical access, rather than through computation 
(see § 49 below). 
A split into computational mediation on the procedural, but lexical 
transmission on the representational side does not look like a viable archi-
tectural option. The alternative is to conceive of a spell-out mechanism that 
is non-computational, but still able to distinguish different chunk sizes (if 
these are really empirically relevant, i.e. if the word-spell-out-mystery turns 
out to be empirically correct).  
At this point I give up speculating: this is as far as the venture of the 
book takes the reader. What is for sure, though, is that the spell-out mecha-
nism, its precise attributions and its eventually modular status deserves to 
be upgraded on the research agenda. Work in this area is done for example 
by Idsardi & Raimy (forth) and Samuels (forth), as well as in Tromsø by 
Michal Starke and colleagues.  
That the mechanism which is responsible for the shipping of pieces 
between morpho-syntax and phonology is understudied is also shown by 
the muddy waters that people (well« syntacticians) usually refrain from 
naming and describing when they talk about "PF": it is obvious that PF is 
distinct from phonology (a lot of things are supposed to happen "at PF" and 
to be "phonological" that are truly miraculous for poor phonologists); at the 
same time, the minimalist perspective on language issues a strong demand 
to outsource important labour into some ill-defined intermundia that is nei-
ther narrow (morpho-)syntax nor phonology (clean syntax, dirty 
PF/phonology, see §§ 30, 726). 
 

16 
Introduction 
24  4. Definition of the object of the study 
 
25  4.1. The book is only about interface theories that follow the inverted T 
 
The discussion of the inverted T model in § 12 has an appendix, which is 
what we turn to now. The book is about the interface of morpho-syntax and 
phonology. The title, "How morpho-syntax talks to phonology", however, is 
explicit on a restriction: communication is only considered in one direction. 
Eventual phonological influence on morpho-syntax lies beyond the scope 
of the study.  
This of course does not mean that it is not mentioned. Relevant dis-
cussion around the principle of phonology-free syntax is provided in § 412 
(also §§ 253, 645) and actually produces a robust empirical generalisation 
that is significant in a modular perspective: melody (i.e. phonological ob-
jects below the skeleton) and morpho-syntax are entirely incommunicado ± 
there is no conditioning in either direction (§ 660). Beyond that, the bearing 
of phonology on morpho-syntax is only relevant in this book for the sake of 
completeness, and insofar as it makes a contribution to the interface man-
agement in the other direction. 
The same is true for two other restrictions of the scope of the book: 
interface theories that do not follow the inverted T, and the kind of inter-
mundia where objects of wonder such as PF movement and deletion of 
entire sentences are supposed to occur. These cases are discussed in § 26 
and § 30, respectively. 
The core of the inverted T is syntactico-centrism: there is only one 
device where pieces are glued together (morpho-syntax or, if morphology is 
independent, morphology and syntax); this device exchanges pieces with 
two interpretational systems, where they are assigned a meaning (LF) and a 
pronunciation (PF). Morpho-syntax has the privilege of Merge and Phase, 
i.e. the ability to concatenate pieces and to talk to other modules (Hauser et 
al. 2002). Thus LF and PF do not concatenate anything: they only interpret 
what they receive. 
There are (at least) two currently entertained approaches to the inter-
face which propose a different scenario: theories of representational conti-
nuity between morpho-syntax and phonology (and semantics), and the par-
allel-construction model. The former is the strand of HPSG and related 
work (§ 513), the latter is developed by Ray Jackendoff (1997 et passim).  
 

Definition of the object of the study 
17 
26  4.2. Interface theories that lie beyond the inverted T model 
 
27  4.2.1. Theories where everything is scrambled: HPSG 
 
HPSG and Jackendoff's parallel model are not at the same distance of the 
Chomskian inverted T: HPSG was generative at some point, but today is 
quite distant from Chomskian linguistics and generative concerns. An im-
portant factor of division is the architecture of grammar and the interface of 
morpho-syntax with phonology: HPSG denies that there is any.  
In HPSG, representations are monostratal. This means that they are 
fully informed of morpho-syntactic, semantic and phonological informa-
tion, which is available at any point in the derivation (actually, talking 
about a derivation is improper because of monostratalism). In practice, 
thus, terminals and nodes of the "syntactic" tree carry phonological infor-
mation, to the effect that there is no need for lexical insertion or for any 
procedural or representational communication between morpho-syntax and 
PF/LF: everything is one big tree, and all information is continuously avail-
able. 
The issue (or rather: one issue) that HPSG has with the generative 
approach is thus about modularity: there are no modules in the HPSG land-
scape. This, in turn, means that there can be no interface: an interface re-
quires two distinct entities that communicate. In a fully scrambled every-
thing-is-one environment, though, no such entities can be identified. HPSG 
may thus talk about the relationship of morpho-syntax and phonology, but 
hardly about any interface. 
The phonological affiliate of HPSG is Declarative Phonology (Scob-
bie 1996, Coleman 2005). The book discusses the HPSG-based work of 
Orgun (1996a et passim) on one occasion (§ 512), but only for the reasons 
mentioned, i.e. in the interest of completeness and contrast with some other 
demonstration. 
 
28  4.2.2. OT and its connectionist endowment: a programmed trope for 
scrambling all into one 
 
In this context, OT needs to be mentioned as well. Like HPSG, OT has a 
natural tendency to scramble everything into one big constraint hierarchy 
(see § 523). Of course there are many different degrees of scrambling also 
among OT practitioners, but the tendency is towards a single grammatical 
space where anti-derivationalism is enforced globally (see Scheer 2010a). 

18 
Introduction 
The most visible result of this trope is anti-cyclicity, i.e. the denial of in-
side-out interpretation (see § 464). Other diagnostics for OT's misty (and 
largely unreflected) relationship with modularity are the customary and 
uncontradicted violations of Indirect Reference (i.e. the prohibition to make 
reference to untranslated morpho-syntactic categories, see § 377), the fact 
that mapping (of morpho-syntactic into phonological categories) is done in 
the phonological constraint hierarchy (ALIGN and WRAP are interspersed 
with purely phonological constraints) and the common occurrence of con-
straints whose formulation combines phonological and morphological in-
structions. 
It is suggested in § 529 that this scrambling trope is a consequence of 
the other half of OT's genetic code: it is certainly true the OT is a genera-
tive theory, but it is also true that its central tool, constraint interaction and 
parallel assessment of competitors, was conceived in direct reference to 
connectionism, the theory that competes with modularity for the description 
of the cognitive architecture (see §§ 36, 586 below). Paul Smolensky is one 
of the founders of OT and of connectionist theory (e.g. Smolensky 1987, 
1988a). Connectionism, however, is the polar opposite of generative and 
rational thinking: it is empiricist, anti-symbolic and anti-modular (see 
§§ 588, 598).  
Knowing about the connectionist roots of OT thus helps to under-
stand the extreme computational orientation of phonology in the past dec-
ade and a half that was discussed in § 7. It is sometimes rightly recalled that 
OT is a theory of constraint interaction, not of constraints. This means that 
OT does not supply any substance itself: there are genuine vocabulary 
items in structuralism (phonemes), SPE (segments) and autosegmental the-
ory (autosegmental structure), but there are no OT-specific representational 
items. OT uses whatever representational material comes the way, and may 
well produce the same result with entirely different (and mutually incom-
patible) vocabulary.3 It is difficult not to establish a direct relationship be-
tween the fact that OT is a purely computational theory where representa-
tions make no sovereign contribution to the definition of grammaticality 
(which is decided by constraint interaction alone, see Vol.1:§309) and its 
content-free connectionist prototype. 
 
3
For example, Lombardi (2001:3) writes with respect to melodic representation: 
"the tenets of OT, regarding constraint violability and ranking, make no particu-
lar claims about phonological representations. We could, for example, do OT 
with any kind of feature theory: SPE feature bundles or feature geometric rep-
resentations, privative or binary features, and so on." 

Definition of the object of the study 
19 
The trouble is that modularity is one of the deepest layers of genera-
tive thinking (see §§ 603, 623). Two souls alas! are thus dwelling in the 
breast of OT, and the sparks of their encounter may be observed at the in-
terface. 
 
29  4.2.3. Jackendoff's parallel model: all modules are structure-building 
 
Unlike HPSG, Jackendoff's parallel model (which is described at greater 
length in § 722) represents an alternative to the inverted T within the gen-
erative paradigm. Morpho-syntax, semantics and phonology are modules, 
which means that there is an interface just like among the modules of the 
inverted T: procedural and representational communication needs to be 
organised between entities that do not speak the same language (of the 
mind). 
At variance with the inverted T, however, all modules are granted the 
ability to build structure, i.e. to glue pieces together. Morpho-syntactic, 
semantic and phonological structure is built in parallel, and information is 
exchanged among modules at any time in the derivation when this is neces-
sary for the construction on any of the three sides. This architecture has 
consequences for the communication among modules: beyond procedural 
and representational communication, it allows for additional types of inter-
action. Bendjaballah & Haiden (e.g. 2003a,b, 2007) for example argue that 
the parallel construction in the three modules is homomorphous, i.e. 
equally advanced, and that this is controlled for by constant communication 
among them. 
 
30  4.3. PF, an androgenic intermundia 
 
31  4.3.1. The minimalist dustbin: clean syntax, dirty phonology 
 
The heart of the minimalist programme is the ambition to clean syntax from 
everything that is not "perfect" in the Chomskian sense, i.e. that is not mo-
tivated by interface requirements ("bare output conditions"), or by a general 
condition on computational efficiency. This direction is the source of the 
notorious interface-orientation of minimalist syntax, of which we have seen 
an effect in § 11: the interface has become interactionist, and phase theory 
paves the way for intermodular argumentation. This is certainly all to the 
good.  

20 
Introduction 
The other side of the coin, however, is the creation of a kind of in-
termundia where things are unloaded that syntacticians do not want to ac-
commodate in syntax, but which are not phonological either. In the current 
environment, one is well advised to add that "phonological" in this context 
refers to what phonologists call phonology: there is a fair amount of confu-
sion in PF-oriented syntactic quarters where PF and phonology are used as 
synonyms. Typically, what syntacticians call phonological when they talk 
about PF-outsourced syntactic operations has got nothing to do with phono-
logical computation (§ 731): there is an ill-defined, minimalism-born inter-
mundia between spell-out and vocabulary insertion on the upper and pho-
nological computation on the lower end.  
Until the mid-90s, the PF of the inverted T model was more or less 
coextensive with phonology; minimalism has shrunk syntax and pumped 
up PF, which is now made of phonology plus "something else". This murky 
additional workspace obeys rules that are quite different from what is 
known from anywhere else: locality conditions are different from syntax 
(§ 580), it violates modularity by simultaneously accessing morpho-
syntactic and phonological vocabulary (§ 738), and it operates with a 
strange notion of hierarchy where the nodes of the PF tree are the projec-
tions of nothing ± at least not of the terminals, which are phonological (see 
§747 for a summary). 
§726 inquires on the properties and the internal structure of PF, as 
well as on the phenomena that PF is supposed to handle. Things that syn-
tacticians want to make PF responsible for include head movement (Chom-
sky 1995a, chapter 4), various kinds of ellipsis (e.g. Merchant 2001) and 
clitic placement (e.g. Boãković 2001). Typically, what PF is expected to do 
is to make things disappear: "delete at PF" (see §§ 732f).  
Syntacticians seem to use "PF" as a magic word ± pronounce it and 
get rid of your trouble. It may be reasonably asked whether anything is 
gained when a clean syntax is bought at the expense of an ill-defined buffer 
that emerges out of the blue and where established principles of linguistic 
analysis do not hold. Dumping displeasing things into PF is not analysing 
or solving them, and being allowed to analyse them with all kinds of ad hoc 
mechanisms (fission, fusion etc., the most exotic animal of the PF zoo be-
ing PF movement, §§ 574, 738) that are unheard of elsewhere may turn out 
to be a remedy that is worse than the disease. 
 

Definition of the object of the study 
21 
32  4.3.2. Syntax, morphology, PF 
 
On this backdrop of a minimalism-born buffer between narrow syntax and 
phonology, the book is only about the interface of "narrow phonology" with 
morpho-syntax. The PF intermundia does not appear in interface theories 
because it is too recent. It is therefore absent from the discussion in Part I 
(except in the chapter on Distributed Morphology) and appears only in Part 
II (§ 726). Of course the book does not try to find out exactly which pieces 
of morpho-syntax are narrow syntax and which pieces belong to the PF 
intermundia: this issue is debated by a large body of syntactic literature.  
Interface theories are phonologically oriented (they describe the in-
fluence of morpho-syntax on phonology, not the reverse), and they are 
made by phonologists (with Distributed Morphology being half an excep-
tion); like these, the book thus trades with morpho-syntax as a whole with-
out participating in the debate about the division of labour between narrow 
syntax and PF.  
The situation is a little different for another question that is much de-
bated in the syntactic literature, i.e. whether syntax and morphology are a 
single computational system or two distinct modules. This issue escorts the 
reader through a good deal of the book: it was brought to the forefront of 
interface discussion by Lexical Phonology (lexical vs. postlexical phonol-
ogy, § 153) and is the bone of contention for Distributed Morphology 
(§ 533). It also plays a central role in the aforementioned word-spell-out-
mystery (§§ 786, 851). 
 
33  4.4. Modularity is the touchstone 
 
It is not the case that the preceding pages are devised to evaluate the theo-
ries and mechanisms mentioned. They just explain what the book is about, 
and what it does not consider. Those theories and devices that are not in its 
focus may or may not be interesting or correct: the book does not argue 
about that, even though my personal view may shine through on occasion. 
There is one criterion, though, that is applied to all theories and de-
vices discussed: following the generative tradition, the book is committed 
to the modular architecture of the mind, and hence of language (modularity 
as a principle of cognitive organisation is introduced at length in the Inter-
lude § 586, also § 36 below). We will see that various generative theories 
have been at odds with modularity in various ways over time (see § 702 for 
a summary). This notwithstanding, modularity is considered a necessary 

22 
Introduction 
property of a correct interface theory: a law is not invalidated because it is 
disobeyed here and there. 
Among the theories and devices quoted, HPSG and PF movement 
are definitely incompatible with modularity, but Jackendoff's parallel archi-
tecture or the outsourcing-created intermundia are not. That is, it could turn 
out that the modular architecture of language is not syntactico-centristic, 
i.e. that PF and LF also enjoy the privilege of concatenation.  
Finally, modularity also automatically draws a red line between the 
book and functional approaches to language. These may have rule systems 
much along the lines of modular computational systems,4 but will always 
allow for extra-grammatical forces such as ease of articulation and commu-
nicative success to bear on grammar. A module, however, knows only its 
own law and carries out computation in complete absence of any external 
influence. 
 
4
Cast in Natural Phonology, the Beats and Binding model of Dziubalska-
Kołaczyk (2001b, 2002) for example is a lateral approach to syllable structure: 
bindings are (bidirectional) relations among adjacent segments.. 
34  5. Trying to get an independent handle on the interface 
 
35  5.1. Intermodular argumentation, history 
 
Like other theories, interface theories are built on data and on a conceptual 
background. The book of course moves along these lines. In addition, how-
ever, the book tries to get a handle on interface theories by three independ-
ent referees: its historical approach, modularity and intermodular argumen-
tation.  
The historical work indeed affords a certain degree of independence 
from individual interface theories and fashions: it allows making generali-
sations and discovering patterns that are not usually mentioned in the litera-
ture (and it also affords not to go in circles or to reinvent the wheel). Some 
examples were already mentioned in § 9: local (roughly, boundaries) vs. 
non-local (domain-based, roughly the Prosodic Hierarchy) insertion of rep-
resentational objects into the phonological string (§ 706), selective spell-out 
(§ 763), no look-back devices (the Strict Cycle Condition in its various 
brands, today Phase Impenetrability) (§ 287), privativity (§ 756).  
The historical strategy is complemented by two other instruments: 
intermodular argumentation and modularity. The former was already men-

Trying to get an independent handle on the interface 
23 
tioned in §§ 17ff (see the summary in § 841): it correlates the behaviour of 
phonology-oriented interface theories with the requirements of current syn-
tactic phase theory and thereby achieves an independent judgement.  
For example, if minimalist interface orientation and the strive for 
computational economy is on the right track, it must apply to all compo-
nents of grammar. Active memory must thus be unburdened in phonology 
as much as in syntax: phonological computation must also be able to "for-
get" strings that have already been interpreted (Chomsky 2001:12f is ex-
plicit on this, see § 306). This means that Phase Impenetrability must be 
active in phonology, and that interface theories which do not use this device 
at all such as Lexical Phonology (for the management of affix class-based 
phenomena) are on the wrong track (see § 828). 
 
36  5.2. Modularity 
 
37  5.2.1. Generative grammar deeply roots in modularity, but is often offended 
 
The third independence-fostering instrument is modularity. It was already 
mentioned in § 33 that modularity is used as a referee for interface theories 
in the book: the cognitive system is modular in nature (and it does not mat-
ter for interface theory whether PF and LF are language-specific or lan-
guage-unspecific modules, the latter option being entertained by the biolin-
guistics programme, see §§ 12, 633, 639). Morpho-syntax and phonology are 
distinct modules that carry out computation on the basis of domain specific 
vocabulary. Since they are incommunicado by themselves, their communi-
cation needs to be organised: modularity requires interface activity (§ 650). 
Modularity is one of the deepest layers of generative thinking (see 
§623), and its presentation in the Interlude reflects its central status: in the 
50s, Noam Chomsky participated in the development of the general compu-
tational paradigm (Turing - von Neumann, see § 603) that underlies much 
modern science and grew into the standard paradigm of how the mind 
works (Cognitive Science). On the grounds of Artificial Intelligence and 
19th century faculty psychology (F-J Gall's phrenology, see §§ 601f), the 
modern formulation of modularity is due to Fodor (1983). Language takes a 
prominent place in Fodor's book, which has grown out of a class co-taught 
with Chomsky. 
Despite the fact that modularity is so deeply rooted in generative 
thinking, it is not a loss of time to recall all this ± and to apply the modular 
referee to phonological and interface theories. This is one thing that I had to 

24 
Introduction 
learn while reading through the literature: modularity usually appears in 
introductory classes to linguistics and in first chapters of linguistic or pho-
nological textbooks ± but then disappears from the radar. It is not uncom-
mon for theories to explicitly subscribe to the modular architecture of the 
mind in general and of language in particular, but then to live in overt vio-
lation of modularity. The list of modularity-violating generative interface 
theories (something that should be a contradiction in terms) is examined in 
§702: since SPE through so-called direct syntax approaches in the 80s up to 
OT, Distributed Morphology (PF movement), and the misty PF-
intermundia that results from the minimalism-driven outsourcing of phe-
nomena into PF (§ 726), different theories violate modularity in different 
ways and for various reasons. 
 
38  5.2.2. Modularity in the history of generative grammar: the GB-interlude of 
syntax-internal (nested) modules 
 
A related aspect of the problem is the narrowly linguistic horizon that gen-
erative linguists typically have when they talk about modularity. The bridge 
with Cognitive Science does not accommodate much traffic: linguists may 
not know what it takes to be a cognitive module, what its properties are, 
how it works, how it is defined, how it is detected and so forth.  
§622 traces back the history of modularity in generative grammar. 
Since his earliest writings (LSLT, Chomsky 1955-56), Chomsky has de-
scribed the functional units of grammar as computational input-output de-
vices that work on a proprietary vocabulary (even though he used the terms 
of the time, which may be unfamiliar today and blur identification) (§ 623). 
This was condensed into the inverted T model in Aspects (Chomsky 1965), 
and the inverted T where a central concatenative device (morpho-syntax) 
feeds two interpretative devices (PF and LF) is the baseline of generative 
thinking up to the present day (§ 629). 
Until GB, the generative architecture was thus made of three compu-
tational systems which had all modular characteristics and were described 
as such (see for example the quote from SPE in § 613), but were not called 
modules. This word became a standard in Cognitive Science only with 
Fodor's (1983) ground-laying book, which emerged from a class that Fodor 
and Chomsky co-taught in fall 1980.  
The major innovation of the new development in generative gram-
mar that Chomsky was about to introduce then (and which was launched in 
written form in Chomsky 1981, 1982) was entirely based on the modular 

Trying to get an independent handle on the interface 
25 
idea, and now used the word module: the central idea of Government and 
Binding is to cut syntax down into six sub-systems, or sub-theories (theta 
theory, government theory etc.). This move was supposed to provide a han-
dle on syntactic complexity, which was out of reach, Chomsky argued, if 
approached with a single system. In GB, syntax is thus viewed as the result 
of the interplay of a number of fairly simple basic systems whose workings 
the linguist can hope to understand (§ 628). 
This left the general architecture with a kind of nested structure, and 
quite tacitly so: the focus was on the GB-subtheories, or modules, and the 
macro-modules of the inverted T, as well as their relationship with the GB-
modules, were left without much discussion. A fair question is thus what 
kind of status a nested modular structure has, and indeed whether GB-
subtheories qualify as cognitive modules in the Fodorian sense in the first 
place (§ 632). Also, the existence of two types of quite different units that 
are called modules (the endpoints of the inverted T and GB-subtheories) 
was a source of confusion and puzzlement outside of generative quarters 
(§ 634). 
Finally, the minimalist (and biolinguistic) turn brought generative 
grammar right back to where it started in the 60s: GB-modules are done 
away with, and the inverted T is more important than before in an environ-
ment where syntax is shaped according to interface-induced pressure 
(§ 637). 
 
39  5.2.3. The refereeing potential of modularity lies waste 
 
It was mentioned that modularity in generative grammar was typically con-
sidered in a narrowly linguistic (or even syntactic for the GB period) per-
spective. I have come across two concrete cases that are directly related to 
this issue, i.e. where an obvious argument from the properties of cognitive 
modules was left unmobilised in debates where it would have made a deci-
sive contribution.  
One is the quarrel that opposed so-called direct syntax approaches to 
Prosodic Phonology in the 80s (see § 407). The founding statement of Pro-
sodic Phonology is the principle of Indirect Reference which says that pho-
nological rules cannot make direct reference to morpho-syntactic catego-
ries; rather, morpho-syntactic information needs to be translated into pho-
nological objects (the Prosodic Hierarchy) in order to be able to bear on 
phonological computation.  

26 
Introduction 
This is the exact description of a modular relationship: modules can-
not look into other modules because they would not understand their idiom. 
They can only communicate through translation (§ 650). As far as I can see, 
though, the modular argument is entirely absent from the debate: although 
Fodor (1983) was contemporary, it was not used by defenders of Indirect 
Reference (instead, the decisive argument was taken to be so-called non-
isomorphism, which turns out to be a non-argument, see § 416). 
The other case in point where the modular referee was not called 
upon is interactionism: Lexical Phonology introduced this way of piece-
meal communication in the 80s, but even under anti-interactionist fire (see 
§222) did not use the argument that the interactionist architecture is the 
only way to reconcile inside-out interpretation (i.e. cyclicity, to which eve-
rybody subscribes) with modular requirements (more on this in § 680). 
 
40  5.2.4. Introduction to (Fodorian) modularity 
 
The point that intermodular argumentation offers the maximal degree of 
independence from phonology within the realm of grammar was already 
made. Modularity takes this independence one step further: it is able to 
referee linguistic theories from outside of grammar. Language is modular, 
and the computational systems that contribute to it (whether specifically 
linguistic or not), as well as their communication, are subjected to the same 
requirements as modules that compute other cognitive functions. 
The modular referee is thus taken seriously in this book: modularity 
will contribute its arbitral award to every issue. This of course is mainly 
done in Part II where theories are evaluated. In order to prepare the discus-
sion, modularity is introduced from a Cognitive Science perspective in the 
Interlude (§ 586): where it comes from (phrenology, F-J Gall's faculty psy-
chology), where it stands in the philosophical landscape (it is ra-
tional/mentalist), which is its competitor (empiricist connectionism), which 
are the issues at stake (e.g. symbolic vs. content-free), how modules are 
identified (double dissociation, domain specificity), examples of modular 
analyses of other cognitive functions (e.g. the number faculty), its applica-
tion to language, the predictions it makes and the requirements it issues. 
 

Deforestation 
27 
41  5.2.5. Structuralist and generative modularity 
 
Finally, it is interesting to observe the convergence of structuralist and gen-
erative thinking in regard of modularity: § 692 shows that translation (of 
morpho-syntactic into phonological objects), an important consequence of 
modularity, was actually invented by structuralism, where it was enforced 
by Level Independence (see also § 72).  
Just like generative theory, but without any cognitive background, 
structuralist Level Independence considers morpho-syntax and phonology 
two distinct ontological entities that are incommunicado as such. The struc-
turalist-generative unity further adds to the weight of the modular argu-
ment. 
 
42  6. Deforestation 
 
43  6.1. The core of Government Phonology: lateral, rather than arboreal 
syllable structure 
 
It was mentioned in the foreword in which way the book is related to Vol.1. 
The project of Vol.1 is to build a lateral alternative to the traditional arbo-
real conception of syllable structure: Vol.1:§165 explains at length in which 
way replacing arboreal structure by lateral relations (government and li-
censing) is the core of the research programme of Government Phonology. 
In a nutshell, the idea is that the syllabic position of a segment is not de-
fined by a constituent to which it belongs (and whose status is itself defined 
by the arboreal relations that it entertains with other constituents), but by 
lateral relations that hold among constituents.  
For example, a consonant does not show characteristic coda behav-
iour because it belongs to a constituent "coda" whose mother is the rhyme; 
rather, coda behaviour is due to the fact that relevant consonants occur be-
fore a governed empty nucleus which is unable to provide support (licens-
ing). This explains why coda consonants are weak, rather than strong 
(while the weakness of the coda constituent does not follow from any-
thing). 
Standard Government Phonology (Kaye et al. 1990) introduced the 
lateral project, but ran out of breath half-way: the result is a hybrid model 
where lateral relations cohabitate with arboreal structure that is left over 
from the traditional tree-based approach. On many occasions, lateral and 
arboreal structure do the same labour, which is an intolerable situation for 

28 
Introduction 
sure (this was correctly observed by Takahashi 1993 early on, see 
Vol.1:§208): either syllable structure is lateral or it is arboreal ± it cannot be 
both. Hence if the lateral project is worth being explored at all, it must be 
applied all the way down. This is what Lowenstamm's (1996) idea is about: 
arboreal syllable structure is done away with altogether (constituents re-
duce to a strict sequence of non-branching onsets and non-branching nu-
clei), and lateral relations alone define syllabic positions. Vol.1 works out 
the conditions of these premises. 
 
44  6.2. The lateral project leaves no place for arboreal prosodic constituency 
 
The result at the end of Vol.1 is a (fully) lateral theory of phonology ± or 
rather, of syllable-related phonology. For there are other areas in phonology 
where arboreal structure is traditionally assumed: below the skeleton for the 
representation of melody (Feature Geometry), above the skeleton for the 
representation of morpho-syntactic information (the Prosodic Hierarchy). 
While privative melodic representations (Anderson & Jones 1974 and ensu-
ing applications in Dependency Phonology, Particle Phonology and Gov-
ernment Phonology) provide a non-arboreal alternative for the former, the 
Prosodic Hierarchy stands unchallenged in the latter area. 
The question is thus whether a scenario is viable where arboreal 
structure is absent from all areas of phonology except for the representation 
of morpho-syntactic information. This ties in with Lowenstamm's (1999) 
idea that morpho-syntactic information can be represented by an empty CV 
unit, i.e. a non-arboreal object that is inserted locally into the linear string. 
Also, the initial CV is part and parcel of the Coda Mirror (Ségéral & Scheer 
2001, 2005, 2007, 2008, Vol.1:§§83,110). 
There is thus reason to question the arboreal standard of representing 
morpho-syntactic information: if it is represented in terms of objects that 
are inserted into the linear string rather than by prosodic constituency, pho-
nology as a whole has a non-arboreal perspective. But there is also positive 
evidence that pleads against the Prosodic Hierarchy, which turns out to be a 
diacritic upon closer inspection (§ 402, Scheer 2008a). If diacritics do not 
qualify, this is reason enough for the Prosodic Hierarchy ± and hence for 
the arboreal representation of morpho-syntactic information ± to be counted 
out. 
On this backdrop, Direct Interface, which is introduced in Vol.2 (also 
Scheer 2008a, 2009a,c), is an attempt to make the representation of mor-
pho-syntactic information 1) non-arboreal, 2) local and 3) non-diacritic. It 

Deforestation 
29 
completes the deforestation of phonology by doing away with the last piece 
of traditional arboreal structure. The historical inquiry of this book is a 
consequence of Direct Interface: it was mentioned in the foreword that by 
looking at the history of interface theories I originally wanted to make sure 
that I am not reinventing the wheel. The causal chain of the book thus runs 
from the inception of the lateral project in the late 80s over Vol.1 to the 
deforestation of phonology, Direct Interface (Vol.2) and the history of inter-
face theories (this book).  
It is therefore useful to expose this link in the introduction of the 
book: even though Direct Interface is only introduced in Vol.2, and al-
though the discussion of Prosodic Phonology (§ 360) and the local (i.e. non-
arboreal) vs. non-local (i.e. arboreal) perspective on the insertion of repre-
sentational carriers of morpho-syntactic information (§ 687) can stand 
alone, the reader should be given the means to follow the global project and 
the role that is played by the chain link of this book. 
In this perspective, the following section shows that the deforestation 
of phonology is also independently motivated: the phenomena that are ex-
pected to result from arboreal structure (such as recursion) are absent from 
the record. 
 
45  6.3. Recursion and other expected consequences of trees are absent in 
phonology 
 
Part and parcel of the inverted T model is that only morpho-syntax has the 
privilege of concatenation: phonology and semantics merely interpret; they 
are not equipped for gluing pieces together. In the minimalist environment, 
concatenation is the result of Merge. This operation is thus available in 
morpho-syntax, but not in phonology and semantics. 
Phonological theories, however, have always relied on tree-building 
devices, at least since autosegmental structure is used. While feature geo-
metric trees are lexically specified, syllabic and prosodic arborescence is 
assumed to be the result of online tree-building activity, today as much as 
in the past. A classical example are syllabification algorithms, which build 
arboreal syllable structure on the basis of the segmental properties of the 
lexically unsyllabified linear string. 
It is true that phonological trees do not involve any concatenation of 
pieces (they are built on a pre-existing linear string): this is what makes 
them different from morpho-syntactic trees. As a consequence, though, 
phonological and morpho-syntactic trees are not the same thing. Hence if 

30 
Introduction 
any, the phonological tree-building device is different from morpho-
syntactic Merge. Accommodating distinct Mergem-synt and Mergephon in 
grammatical theory of course ruins the minimalist ambition, which counts 
on only one universal piece-gluing (and hence tree-building) device. 
But there is more reason to believe that a tree-building phonological 
Merge cannot be the correct scenario. Neeleman & van de Koot (2006) 
show that trees of whatever kind have certain formal properties that make 
predictions on the type of phenomenon that should be found in a tree-
bearing environment. These include projection, long-distance dependencies 
and recursion. Neeleman & van de Koot (2006) demonstrate that phono-
logical phenomena do not display any of these properties. They therefore 
conclude that the presence of trees in phonology overgenerates: arboreal 
structure predicts things that are absent from the record. 
 
46  6.4. The lateral project predicts that phonology is non-recursive 
 
The same point can also be made from the other end. There is no phono-
logical equivalent to multiple phrasal embedding, where the only limit on 
the number of recursions is set by performance restrictions (see § 803 for 
examples, also from morphology).  
The absence of recursion has long been recognised as a major differ-
ence that sets phonology apart from morpho-syntax. Everybody knows 
about the fact, which is undisputed,5 but still begs the question: there must 
be a reason why phonology is not recursive. Nespor & Vogel (1986) for 
example make the difference explicit, but leave it at that. 
 
5
The phonological part of the recent literature on recursion which was generated 
by Hauser et al.'s (2002) idea that recursion (and hence Merge) could be re-
stricted to narrow syntax often falls prey to the confusion between recursive 
phenomena and the analysis thereof: recursion is a phenomenon whose exis-
tence is established by pre-theoretical and pre-analytic properties, not by analy-
ses that happen to use recursive constructions. The existence of the latter does 
not document recursion in phonology, but merely the fact that some analysts 
use recursive constructions. In syntax and morphology, recursion is a phe-
nomenon whereby you can keep repeating the same type of item indefinitely 
until grammar-external limits regarding memory etc. are reached. Nothing of 
that kind has ever been reported from phonology. More on this confusion in 
§803. 

Structure of the book and of Vol.2 
31 
(1) 
"In relation to the difference between the morpho-syntactic and prosodic 
hierarchies, it should be noted, furthermore, that the two differ not only in 
the way they divide a given string into constituents. They also differ with 
respect to depth. That is, since the rules that construct the phonological 
hierarchy are not recursive in nature, while the rules that construct the syn-
tactic hierarchy are, the depth of phonological structure is finite, while the 
depth of syntactic structure is, in principle, not finite." Nespor & Vogel 
(1986:2) 
 
What Nespor & Vogel say is that there is no particular reason why 
syntactic rules are recursive, but phonological tree-building rules are not. In 
other words, the absence of recursion in phonology is accidental in their 
system: phonological rules happen not to be recursive, but could well be. 
By contrast in a phonology where trees are absent altogether because 
interpretational devices have no access to the tree-building device Merge, 
the absence of recursion is predicted. This is because recursion is formally 
defined as a node that is dominated by another node of the same kind: if a 
computational system is unable to build trees, there can be no domination 
at all, and hence no recursive phenomena (this was also pointed out in the 
foreword to Vol.1; further discussion is provided in §§ 802ff). 
The absence of recursion in phonology is thus predicted by the lat-
eral project and its concomitant elimination of trees. 
 
47  7. Structure of the book and of Vol.2 
 
48  7.1. How to access the book: the story, its relation with current syntactic 
theory and its thematic guide 
 
As was mentioned, the book falls into two parts and an Interlude. Part I is 
historiographic: it reviews structuralist and generative interface thinking 
chronologically, but also proceeds theory by theory. The Interlude (§ 586) 
introduces modularity, the rationalist theory of the (human) cognitive sys-
tem that underlies the generative approach to language (but is also incar-
nated by structuralism through Level Independence, see § 692). It was ex-
plained in § 36 in which way modularity is a key concept of the book. 
Part II serves two functions: it distils lessons from the review of in-
terface theories on the one hand (a how-to is provided at the outset in 
§656), and locates the interface debate in the landscape of current minimal-
ist syntax on the other hand. 

32 
Introduction 
Regarding the latter, Part II introduces to ongoing debate in syntax 
that is by and large absent from (traditional, but also more recent) interface 
theories: linearisation is discussed in § 741, the blown-up PF area into 
which minimalism outsources a whole lot of mechanisms that were previ-
ously syntactic and are still not phonological (despite the P of PF) is exam-
ined in § 726, and § 771 reports on phasehood in current syntactic thinking. 
Regarding the former, answers to the following questions are sought: 
which ideas are theory-resident? In which different guises does a given idea 
appear over time? Which are the mechanisms that have survived the verdict 
of time? Which empirical generalisations emerge? Which are the watershed 
lines that separate interface theories into different camps? Which are the 
questions that interface theories are constantly after? Which ones are 
solved, which ones remain pending? 
Part II is thus a thematic guide to Part I: instead of approaching the 
interface period by period and theory by theory, relevant topics are ad-
dressed across periods and theories, which are accessed by systematic 
cross-reference for each issue. Also, Part II to a certain extent abandons the 
journalistic style that is used as much as possible in Part I: the goal now is 
to evaluate, to assess and to tell good from bad, correct from incorrect, 
plausible from implausible, successful from unsuccessful, rather than to 
report. 
This setting inevitably introduces a certain amount of repetition: like 
Vol.1, the book is not expected to be read from cover to cover. The reader 
will rather enter the book by looking up what a specific theory proposes 
(access by theory), what was on the research agenda at a given point in time 
(chronological access), or how theories deal with a specific phenomenon or 
generalisation (thematic access). Repetition and cross reference are neces-
sary in order to keep the information level constant for all types (and 
points) of access, but it is true that for the cover-to-cover reader this pro-
duces an annoying amount of repetition. 
 
49  7.2. Vol.2: Direct Interface, One-Channel Translation and their application 
to CVCV 
 
At the end of this introduction, it may be useful for the reader to be able to 
get an idea of what Vol.2 looks like. Much more than this book, it is ana-
lytic in the sense that it draws conclusions from the historical survey on the 
representational side: how is translation (of morpho-syntactic information 
into phonological objects) organised, and what does its output look like? 

Structure of the book and of Vol.2 
33 
Vol.2 falls into two theory-unspecific and two theory-specific chap-
ters. Chapter one introduces Direct Interface, the idea that is at the origin of 
the overall project on the interface and defines what the output of transla-
tion looks like (it must be non-diacritic). Chapter two is about how this 
output comes into being, i.e. the translational process itself. Following (un-
published) work by Michal Starke, it is argued that there is only one source 
of phonological material that enters phonological computation, no matter 
whether it represents morpho-syntactic or lexical information: the lexicon.  
One-Channel Translation contrasts with all previous approaches to 
translation, which systematically distinguish between morphemic and non-
morphemic information: the former is what morphemes are made of, and 
everybody agrees that it comes into being through lexical (or vocabulary) 
insertion when morpho-syntactic structure is converted into a phonological 
string. The latter is what I call boundary information, i.e. morpho-syntactic 
properties that materialise in phonology in form of representational objects, 
but do not ride on morphemes: since SPE, hashmarks and more recently 
prosodic constituents are born through a specific mapping mechanism that 
is computational in kind. Starke's alternative does away with computational 
translation: it makes boundary information originate in the lexicon as much 
as morphemic information. The result is a uniform translation of morpho-
syntactic into phonological material through a lexical access. 
These two chapters are theory-unspecific in the sense that they define 
the design properties of a correct interface theory: they do not make any 
statement about specific phonological theories. What they do allow for, 
though, is the evaluation of competing phonological theories according to 
their behaviour at the interface. Traditionally, a uniform interface vocabu-
lary that is shared by all individual phonological theories mediates between 
these and morpho-syntax: juncture phonemes, hashmarks, the Prosodic 
Hierarchy. Hence whatever variation competing phonological theories pro-
duce will be neutralised and invisible at the interface.  
By contrast in the perspective of Direct Interface, different phono-
logical vocabulary that is proposed by different phonological theories 
makes contrasting predictions when it acts as the output of translation; also, 
anything cannot be the output of translation anymore since only objects 
qualify that make a good lexical entry (One-Channel Translation). 
Chapters three and four then apply Direct Interface and One-Channel 
Translation to the particular phonological theory that I am committed to, 
Government Phonology in general and CVCV in particular. It is only this 
last half of Vol.2 that bridges over to Vol.1. Chapter three modifies the lat-
eral theory of phonology as it stands at the end of Vol.1 according to the 

34 
Introduction 
requirements of the interface, i.e. Direct Interface and One-Channel Trans-
lation (see also Scheer & Ziková forth). Shaping linguistic theory according 
to interface requirements of course is a very minimalist thing to do ± unlike 
in syntax-centred minimalism, however, here it is phonology that is shaped 
by the interface.  
Finally, chapter four shows the interface-readjusted system at work: 
the initial CV has been around in Government Phonology and CVCV for 
quite some time now (Lowenstamm 1999), and it has produced a reason-
able amount of empirical work. It is shown that only syllabic space passes 
the filters that are defined by Direct Interface and One-Channel Translation: 
it is therefore the only possible output of translation. In CVCV, syllabic 
space reduces to CV units, which are thus the only possible carriers of 
morpho-syntactic information.  
On this backdrop, a case study is undertaken which reviews the em-
pirical evidence for the initial CV and inquires on the modalities of its 
management. The parameterisation of the initial CV is discussed namely in 
the light of its behaviour in connected speech, i.e. where phonology applies 
across word boundaries. This chapter is about the only place in Vol.2 that is 
data-oriented, i.e. where genuine empirical generalisations are made. 

Part I 
Morpho-syntactic information in phonology:  
a survey since Trubetzkoy's Grenzsignale 
Chapter 1 
50 
The spectrum: what morpho-syntactic information 
can do to phonology 
51  1. Boundaries have a triggering, a blocking or no effect 
 
We start the historical survey of interface theories with a non-historical 
chapter that introduces the classification of interface events which is pro-
posed by Kenstowicz & Kisseberth (1977:83ff, 1979:407ff). Their system 
is particularly useful because it is pre-theoretical and a priori covers all 
logically possible situations. It will be constantly referred to as we go 
along, and it offers a rationale that the reader may use when encountering 
particular analyses in a specific theoretical environment. 
According to Kenstowicz & Kisseberth, morpho-syntactic divisions 
may have three and only three phonological effects. These are shown under 
 (2) below. 
 
(2) 
possible effects of morpho-syntactic structure on phonology 
 
given two morphemes M1 and M2, their concatenation may 
 
a. 
have no effect at all: 
phonology works as if there were no morpho-syntactic division, i.e. 
as if the sequence of sounds were mono-morphemic. 
 
b. 
block 
a process that would apply if the morpho-syntactic division were not 
there. 
 
c. 
be a condition 
on the application of a process that would not go into effect if the 
morpho-syntactic division were not there. These cases are known as 
derived environment effects. 
 
Kenstowicz & Kisseberth provide rich material for the illustration of 
the three situations. Let us consider a prototypical representative for each of 
them. (2a) is trivial: it corresponds to what is sometimes referred to as a 

36 
Chap 1: what morpho-syntactic information can do to phonology 
"late rule", a "rule of phonetic implementation".6 At the word level, a typi-
cal example would be the aspiration of English voiceless stops that occurs 
word-initially (phólitics, where an acute accent indicates stress) and before 
stressed vowels (pholithícian), but is not sensitive to any eventual mor-
pheme boundaries inside the word: it applies across the board. 
But there are also less surface-oriented processes where morpheme 
boundaries may be ignored by the phonology. Namely, this is the case for 
affix class-based phenomena (§§ 163, 166) where a given class of mor-
phemes follows this pattern, while another class imposes a phonological 
trace of the concatenation. For example, the division in parént-al is pho-
nologically invisible (stress is as penultimate as in the mono-morphemic 
párent), while the boundary in párent-hood is phonologically relevant: the 
computation of stress only takes into account the first portion of the word. 
 
6
While implementing the same idea of the phonological inertness of morpho-
syntactic boundaries, the notion of postlexical rules known from Lexical Pho-
nology (see § 153) is different since it is bound to a particular chunk size: it ap-
plies only to strings that are larger than words. 
52  2. Blocking and triggering effects: illustration 
 
53  2.1. Process-blocking boundaries: French gliding 
 
In order to illustrate boundaries that block processes, let us look at a typical 
case of the suffix-prefix contrast where a process applies across the "weak" 
suffix boundary, while it is blocked by the "strong" prefix boundary.  
In French, the hiatus created by a vowel-final stem and a vowel-
initial suffix is resolved by the insertion of a glide in case the stem-vowel is 
high. The glide in question is a copy of the high vowel, thus producing the 
sequences [ij-V], [uw-V], [yÁ-V] (see Dell 1976:109, Selkirk 1972:385ff). 
Table  (3) below offers illustration. 
(3a) shows that the glide does not belong to the lexical information 
of the roots in question: they appear with their final vowel when suffixed 
by a zero personal ending. There is no glide in the lexical representation of 
the vowel-initial suffixes under (3b) either, as evidenced by their vowel-
initial appearance after consonant-final stems. Under (3c), however, a glide 
appears when a hiatus is produced by the concatenation of a vowel-final 
stem and a vowel-initial suffix. Note that the quality of the suffixal vowel, 
as well as the kind of suffix added, is irrelevant. This behaviour contrasts 

Blocking and triggering effects: illustration 
37 
with the situation encountered in identical phonological circumstances but 
where the hiatus is created through the assembly of a prefix and a stem, as 
under (3d). No glide may break up the hiatus here: *[bi-j-anyEl] "bi-
annual". 
 
(3) 
French gliding 
 
a. the stem does not contain any glide: inflected forms with zero endings 
 
je lie 
je loue 
je sue 
[li] 
[lu] 
[sy] 
I relate 
I rent 
I sweat 
 
b. vowel- initial suffixes do not contain any glide: C-final stems (chant- 
"to sing") 
 
chant-er 
[Sãt-e] -e infinitive 
 
chant-ez 
[Sãt-e] -e 2pl pres 
 
 
chant-ais 
[Sãt-E]
-E 1sg pret 
 
chant-a 
[Sãt-a] -a 3sg passé simple 
 
 
c. concatenation of a V-final stem and a V-initial suffix 
 
-er inf. 
-ez 2pl pres 
-ais 1sg 
pret 
-ons 1sg 
pres 
-a 3sg passé 
simple 
 
li-er 
[li-j-e] 
[li-j-E]
[li-j-ç)]
[li-j-a] 
 
lou-er 
[lu-w-e] 
[lu-w-E]
[lu-w-ç)]
[lu-w-a] 
 
 
su-er 
[sy-Á-e] 
[sy-Á-E]
[sy-Á-ç)]
[sy-Á-a] 
 
d. concatenation of a V-final prefix and a V-initial stem 
 
bi-annuel 
[bi-anyEl] 
bi-annuel 
 
 
anti-existentiel 
[ãti-EksistãsjEl] anti-existential 
 
 
anti-alcoolique 
[ãti-alkoolik] 
anti-alcoholic 
 
 
archi-ondulé 
[aXSi-ç)dyle] 
very undulated 
 
 
archi-ennuyeux 
[aXSi-ãnyÁijø] 
very boring 
 
 
Hence the prefix boundary blocks glide-insertion. Since all prefixes 
behave like that, and all suffixes allow gliding to go into effect, the conclu-
sion that is commonly drawn ranks the boundaries: suffixation creates a 
"weak" boundary that allows the vowels on both sides to see each other, 
while prefixation involves a "strong" boundary that blurs visibility. 
 
54  2.2. Process-triggering boundaries: obstruent voicing in Puyo Pongo 
 
Let us now look at a process that applies only if a (specific) morpho-
syntactic division separates the agent and the patient of the phonological 

38 
Chap 1: what morpho-syntactic information can do to phonology 
event. Kenstowicz & Kisseberth (1977:88f, 1979:407f) report the following 
data from Puyo Pongo (Quicha, Eastern Ecuador, cf. Orr 1962). 
 
(4) 
Puyo Pongo: obstruent voicing after heteromorphemic nasals 
 
a. within a morpheme, obstruents may be voiced or voiceless after nasals 
 
voiceless T in N__ voiced T in N__
p-b 
pampaljina 
hambi 
skirt, poison 
t-d 
tÉSuntina 
indi 
to stir the fire, sun 
 
tÉs-dÉZ ¯ukantÉSi
pundÉZa
we, day 
 
k-g 
SiNki 
tÉSuNga 
soot, ten 
 
b. following a nasal and a morpheme boundary, obstruents are only voiced
V-__ 
N-__ 
 
 
/-ta/ 
wasi-ta 
kan-da 
house, you 
ajtÉSa-ta 
atan-da 
meat, the frog 
 
puru-ta 
wakin-da 
gourd, others 
 
/-tÉSu/ ali-tÉSu
kan-dÉZu
is it good?, you? 
 
lumu-tÉSu
tijan-dÉZu
manioc?, is there? 
 
mana-tÉSu
tÉSarin-dÉZu
isn't it?, does he have? 
 
(4a) shows that nasals may be followed by both voiced and voiceless 
obstruents if the NC cluster is mono-morphemic. In a heteromorphemic 
situation as under (4b), however, only voiced obstruents are observed. Con-
catenation to a vowel-final stem shows that the initial dentals of the objec-
tive marker /-ta/ and the question marker /-tÉSu/ are underlying voiceless: 
they undergo voicing when attached to a nasal-final stem. 
In this case, thus, a morpho-syntactic division is the critical condition 
for the application of a process, obstruent voicing. Or, in static terms, the 
voice-voiceless contrast after nasals is neutralised after a boundary. 
 

Chapter 2 
55 
Trubetzkoy's Grenzsignale 
56  1. The cradle of the functional perspective 
 
The first structuralist approach to the phonological effect of morpho-
syntactic divisions is functional. Trubetzkoy (1939:241) (see also earlier 
sources: Trubetzkoy 1935:30ff, 1936) holds that Grenzsignale (demarcation 
signals) alert the listener in order to facilitate the parsing of the phonetic 
continuum that reaches his ears. Without being helped by the phonology, 
the task of identifying morphemes would be much more difficult and take 
much longer. Therefore some morpho-syntactic divisions leave a material 
trace in the signal so that they could not be overheard. 
Trubetzkoy (1939:242) contends that "all languages possess specific 
phonological means in order to signal the presence or the absence of sen-
tence-, word- or morpheme boundaries in a particular location in the con-
tinuous stream of speech." According to him, Grenzsignale "may well be 
compared to the traffic lights in the streets."7
Trubetzkoy will have many followers, structuralist and generative 
alike.8 A functional component does not appear to be incompatible with a 
formal approach to the interface. A zoom on a functional interpretation 
within an overall formal frame will be undertaken in §§ 264, 340: the classi-
cal interface theory of Government Phonology is based on so-called parsing 
cues (Kaye 1995). Other generative continuators of Trubetzkoy's Grenzsig-
nale will also be briefly reviewed on this occasion. 
 
7
Translations are mine. The original German text is as follows: "Jede Sprache 
[besitzt] spezielle phonologische Mittel, die das Vorhandensein oder das Nicht-
vorhandensein einer Satz-, Wort- oder Morphemgrenze an einem bestimmten 
Punkt des kontinuierlichen Schallstromes signalisiert" (Trubetzkoy 1939:242); 
"Sie dürfen wohl mit den Verkehrssignalen in den Straßen verglichen werden." 
(Trubetzkoy 1939:242). 
8
On the structuralist side, the idea of his Grenzsignale was applied to various 
languages for example by Trnka (1940), Anderson (1965), Bolinger & 
Gerstman (1957), Romportl (1984), and in the work on phonetic correlates of 
juncture (see § 70, which are sometimes called boundary signals, i.e. by Lehiste 
1962). 

40 
Chap 2: Trubetzkoy's Grenzsignale 
57  2. Grenzsignale do not contribute anything to the mapping puzzle 
 
The functional issue brings up issue of the mapping puzzle for the first 
time. The mapping puzzle is a pervasive mystery that runs through the en-
tire interface literature and is not any clearer today than it was twenty or 
thirty years ago. The question is exactly which morpho-syntactic construc-
tion can, must or must not be promoted to phonological visibility: what 
kind of cross-linguistic generalisations are found?9
One could expect a significant contribution from the functional per-
spective, which precisely defines the "need" for this or that morpho-
syntactic structure to leave a phonological trace. As far as I can see, how-
ever, this is not the case. There is a large amount of variation across lan-
guages, which linguists have not been able to reduce to any rationale or 
recurring patterns. That is, some languages seem to be eager to help the 
listener and hence offer a lot of (different) demarcation signals, while oth-
ers appear not to care: they make masochistically little use of Grenzsignale. 
Trubetzkoy (1939:255ff) distinguishes positive and negative signals. 
The former identify the presence of a morpho-syntactic division, while the 
latter guarantee its absence. For example, the spiritus asper in Classical 
Greek unmistakably identifies the beginning of a word; in English, the ve-
lar nasal signals the end of a morpheme, and the sequences [Ts], [Dz], [tÉʃt], 
[tÉʃs], [sʃ] necessarily enclose a morpho-syntactic division. On the other 
hand, [r] and [h] only occur morpheme-internally in Efik (a variety of 
Ibibio, Niger-Congo). 
 
9
The mapping puzzle will be discussed on various occasions in the book: § 111 
(post-SPE times), §§ 387, 392f, 396 (Prosodic Phonology), § 463 (OT), § 753 
(summary). 
58  3. Grenzsignale are immaterial and under morpho-syntactic control 
 
Another interesting property of Grenzsignale is that they do not appear to 
possess any material existence (except in the phonetic signal). Unlike in all 
later theories, Trubetzkoy does not note boundaries, or give them any other 
material or graphic existence. They appear to be just right or left margins of 
meaningful units. Hence Trubetzkoy does not appear to consider them lin-
guistic objects in their own right, i.e. objects that are endowed with intrin-
sic properties. 

Grenzsignale are immaterial and under morpho-syntactic control 
41 
As we shall see below, this contrasts with later structuralist and gen-
erative conceptions, which have sought to grant a material phonological 
identity to extra-phonological information. That is, American Structuralists 
insert juncture phonemes in the linear string of phonemes, while extra-
phonological information materialises in the generative paradigm as SPE-
type diacritics such as # first, later on in form of the Prosodic Hierarchy. As 
will be shown in Vol.2 (also Scheer 2008a, 2009a,c), the purpose of Direct 
Interface is to do away with this diacritic tradition: juncture phonemes, #s 
and the Prosodic Hierarchy are diacritics, i.e. objects which do not exist in 
phonology in absence of the appeal to extra-phonological information. 
Thus structuralist as much as generative carriers of boundary information 
so far have only stored alien information in the phonology. Its carriers 
therefore do not have any phonological properties and hence do not make 
predictions: a # or a prosodic word can cause any phonological event and 
its reverse to occur (see Vol.2). 
Interestingly, Trubetzkoy's Grenzsignale cannot produce this kind of 
ghost ships in phonology: they are immaterial. On the other hand, they are 
of course as unable to make predictions regarding their effect as the struc-
turalist and generative diacritics. Ségéral & Scheer (2008) (and Vol.2 at 
greater length) show that this is odd since the influence of morpho-
syntactic information on the phonology of natural language is not arbitrary; 
rather, it produces recurrent effects. 
Direct Interface thus represents a compromise between the Trubetz-
koyan and later approaches: in order to have a predictable effect, morpho-
syntactic information must certainly materialise in the phonology, but not 
as a diacritic. The only option, then, is to make it a truly phonological ob-
ject, i.e. one that exists in phonology in absence of extra-phonological con-
ditioning. 
Finally, the fact that positive Grenzsignale signal the existence of a 
morpho-syntactic division makes their occurrence in the middle of mor-
phemes impossible (see the quote of Vachek 1970 in § 66, who points this 
out). Negative Grenzsignale do occur in the middle of morphemes (see 
§57), but they signal the absence of a morpho-syntactic division. Hence 
Trubetzkoyan carriers of morpho-syntactic information always respect 
morpho-syntactic divisions: morpheme-internal Grenzsignale can only 
signal their absence, while Grenzsignale that occur at morpheme bounda-
ries can only signal their presence. That is, Grenzsignale are distributed 
according to morpho-syntactic divisions in all cases. 
As we will see below, this allies the Trubetzkoyan and the generative 
conceptions against structuralist juncture phonemes. The structuralist en-

42 
Chap 2: Trubetzkoy's Grenzsignale 
shrining of descriptive economy indeed led to juncture phonemes in the 
middle of morphemes ± a move with disastrous consequences (see § 69). It 
is only in the generative paradigm (§ 78) that the morpho-syntactic control 
over boundaries (or juncture) will be restored. 
 

Chapter 3 
59  American structuralism: juncture phonemes 
 
60  1. Introduction 
 
In American Structuralism, morpho-syntactic information in phonology 
was carried by juncture phonemes. These were part and parcel of structural-
ist theory: among others, Hockett (1955:167ff, 1958:54ff), Trager (1962), 
Devine & Stephens (1976:293ff) and Aronoff (1980) offer (historical) sur-
veys. 
Structuralist theory required that morpho-syntactic information be 
recorded as a phonological object (a phoneme), rather than as a diacritic. 
This is due to so-called Level Independence. Rooting in a bottom-up dis-
covery procedure of linguistic structure, this principle prohibits the use of 
higher level information at any given level of description. Hence phonol-
ogy being described before morphology and syntax, no look-ahead is al-
lowed: units of the latter two levels must not be present in the former.  
The base line of structuralist orthodoxy is well expressed by 
Hockett's (1942) apodictic formulation below. 
 
(5) 
"No grammatical fact of any kind is used in making phonological analysis."
Hockett (1942:20) 
 
"There must be no circularity; phonological analysis is assumed for gram-
matical analysis, and so must not assume any part of the latter. The line of 
demarcation between the two must be sharp." Hockett (1942:21) 
 
We will see below that there were also voices that pled for a less 
strict enforcement of Level Independence. But even in quarters where the 
principle was strictly obeyed, juncture phonemes were promoted for two 
reasons, neither of which has anything to do with the representation of 
morpho-syntactic information. First, they served as an environment for the 
prediction of allophones. Second, they enhanced economy: the inventory of 
phonemes could be reduced when reference to juncture phonemes demoted 
phonemic candidates to allophonic status. 
The questions that were discussed in this environment all have to do 
with the intuitively awkward prohibition to use morpho-syntactic informa-
tion in phonology. The following pages show how structuralists tried to sell 

44 
Chap 3: American structuralism: juncture phonemes 
morphology for phonology in order to circumvent the difficulty (Moulton's 
analysis of German in § 64); they show how Level Independence led to the 
abuse of boundaries, which were placed in the middle of morphemes; fi-
nally, they discuss the debated question whether juncture phonemes (ought 
to) have a phonetic correlate. 
 
61 
2. Level independence: no morphology in phonology 
 
62  2.1. The orthodox point of view 
 
The empirical basis of American structuralism was the description of native 
American languages. In relation with the practice of the descriptivist school 
of the 40s and 50s, the methodology used in fieldwork was an important 
factor in theory-building. That is, American structuralism ambitioned at 
constructing a fully fledged grammatical statement of a language from 
scratch, i.e. from the raw data that reach the ear of the fieldworker. In the 
introduction to his book, Harris (1951) is explicit on the fact that this is 
what his work is all about. 
 
(6) 
"The whole schedule of procedures outlined in the following chapters [«] is 
designed to begin with the raw data of speech and end with a statement of 
grammatical structure." Harris (1951:6) 
 
The discovery procedure of grammatical structure, then, is strictly 
positivist in the sense that only recorded or previously constructed informa-
tion can feed linguistic analysis. Observable data are made of sound and of 
nothing else; the corresponding units are called phones. The analysis of 
phones establishes a higher order phonemic level, whose basic units are 
phonemes. Phonemes cluster together as morpho-phonemes, which are the 
building blocks of the morpho-phonemic level of analysis. Finally, morpho-
phonemes build clauses at the clausal level. 
Therefore information from a higher level of description could not 
possibly be present at a lower level: it does not exist yet. Hence no piece of 
morphological or syntactic vocabulary, or any representative thereof, could 
be used in phonological analysis.10 
10 Lehiste (1960:47ff) is also explicit on this. 

Level independence: no morphology in phonology 
45 
Aronoff (1980), whose line of reasoning I follow in the present sec-
tion, traces back how American structuralism addressed morphological 
information.11
(7) 
"One of the essential characteristics of the American descriptivists' phone-
mic level, a consequence of their theory of discovery procedures, was its 
autonomy from syntax, semantics, and morphology. One was supposed to 
be able to do a phonemic transcription which did not refer to higher levels of 
analysis. Indeed, according to the theoreticians, one was supposed to be able 
to do a phonemic analysis without having a clue as to the higher structure of 
an utterance. In the case of juncture, the phonemic transcription could not 
refer to the fact that night rate is a compound consisting of two words, while 
nitrate is one single morphological unit. One could not account for phonetic 
distribution in terms of morphology and syntax." Aronoff (1980:30) 
 
Hence within the limits set by this approach, morphological informa-
tion could either not be referred to at all in phonology, or it had to be sold 
as phonological. "The American descriptivists believed that junctures were 
phonemes because they had to", as Aronoff (1980:30) puts it. This is how 
and why morpho-syntactic information could only incarnate as truly phono-
logical objects (rather than as diacritics): "to a Descriptivist, then, if a 
boundary has a phonemic effect, it must be represented as an element on 
the phonemic level: a juncture phoneme" (Aronoff 1980:30). 
While this position regarding the use of morpho-syntactic informa-
tion in phonology was widespread, it is not the only one that can be found 
in structuralist thinking. Goldsmith (2008:49ff) offers an informed histori-
cal discussion: the spectrum of opinions ranged from Hockett's (1942) and 
Joos' (1964) unbending orthodoxy over Harris' (1951) apparent (but self-
contradicted) tolerance of some look ahead to Pike (1947) who argued that 
no phonological analysis can be carried out in absence of minimal morpho-
syntactic information (grammatical prerequisites). We will come back to 
these voices at greater length as we go along (§ 66). 
 
63  2.2. Junctural minimal pairs: night rate vs. nitrate 
The following sections illustrate the kind of dilemma into which structural-
ists were driven by Level Independence. We set out with the most impor-
 
11 Lehiste (1960:5ff) offers a detailed survey of how juncture was treated in the 
structuralist period from the internal point of view. 

46 
Chap 3: American structuralism: juncture phonemes 
tant one, which is caused by so-called junctural minimal pairs. These occur 
when identical phonemic sequences with contrastive meaning are phoneti-
cally distinct because of an allophonic variation that is governed by a mor-
pho-syntactic division. 
The most famous example is certainly the pair night rate - nitrate.
Being word-final, the dental of the former is unreleased; by contrast, since 
the dental of the latter occurs word-internally and before a tonic vowel, it is 
aspirated. Speakers consistently identify both words on the grounds of this 
difference, which is controlled by the word boundary. Word boundaries, 
however, must not exist in phonology, which means that the analyst is 
forced into the recognition of two distinct /t/ phonemes. 
The following section shows how an identical situation in German is 
circumvented by the introduction of juncture phonemes, whose function is 
to dress up illegal morpho-syntactic information in a phonological disguise. 
Moulton (1947) is often quoted as a typical illustration for juncture pho-
nemes. 
 
64 
3. Morphology in a phonological guise: Moulton (1947) on German 
 
The first problem that Moulton (1947:220) comes across is aspiration. He 
discusses junctural minimal pairs in German. Two instances appear under 
 (8) below. 
 
(8) 
junctural minimal pairs in German: aspiration 
 
spelling 
surface 
gloss 
 
a. dieses Kabinett 
[ʙdiiz´skhabI'nEt] 
this cabinet 
diese Skandale 
[ʙdiiz´skan'daal´]
these scandals 
 
b. ich antworte: Terrasse [/Içʙ/antvoåt´thE'´as´]
I answer 'terrace' 
 
ich antwortete: Rasse 
[/Içʙ/antvoåt´tE'´as´]
I answered 'race' 
 
Under (8a), the portion [ʙdiiz´ska] is identical except for aspiration, 
which occurs in the first, but not in the second sequence quoted. Therefore, 
aspiration cannot be predicted from any environment and must be granted a 
phonemic status. Another case that appears to show the distinctiveness of 
aspiration is the true "minimal pair" under (8b) (note that the stress pattern 
is identical: main stress on the last, secondary stress on the first [a]).12 
12 Moulton transcribes the first "e" in Terrasse and the last "e" in antwortete alike, 
i.e. in his phonemic transcription /e/. The standard pronunciation, however, 

Morphology in a phonological guise: Moulton (1947) on German 
47 
Facing this evidence, the regular structuralist analysis would be to 
recognise a phoneme of aspiration in the phonemic inventory of German. 
However, Moulton suggests an alternative which is based on the following 
observation: aspiration is predictable everywhere but in a very reduced set 
of utterances, which are represented under  (8). The general rule seems to be 
"/p t k/ are aspirated after a pause, but unaspirated after any segmental pho-
neme". This analysis is then simply extended to the few contrastive cases: 
"there are places within an utterance where /p t k/ behave as if they were 
preceded by a pause" (Moulton 1947:220). 
In order to give a phonemic interpretation to this insight, Moulton 
chooses to represent the "pause" by a segmental phoneme which he calls 
"open juncture" and refers to as /+/. As many other segmental phonemes, 
/+/ produces allophonic variation: "at the beginning or end of an utterance 
it appears as a pause of brief duration or, in free variation with this, as zero" 
(page 220). Hence the pair under (8b) is phonemically distinct in the fol-
lowing way: /+/ixʙ/antvorte+te'rase+/ vs. /+/ixʙ/antvortete'rase+/. 
Moulton admits that the solution which resorts to juncture, as it 
stands, is not any more attractive than the orthodox way of addressing the 
evidence, and perhaps even worrisome because it introduces a new concept. 
But there are two other phenomena in German that could be accounted for 
with open juncture as well: the distribution of the glottal stop and the alter-
nation of [X] and [ç]. 
The reasoning is the same as before: the glottal stop must be granted 
distinctive status because there are minimal pairs such as those under  (9) 
below. 
Den Bau erkennen under (9a) may be pronounced without glottal 
stop [deen''bauåʙkEn´n], in which case it is homophone with den Bauer 
kennen. However, the ambiguity may also be done away with by producing 
a glottal stop in den Bau erkennen [deen''bau/åʙkEn´n] (while no glottal 
stop can appear in den Bauer kennen). Therefore, the glottal stop is mean-
ingful: it can be used in order to distinguish the two sequences. 
Under (9b), the two items may also be homophones in case Arbeit 
ersuchen is produced without a glottal stop. As before, however, the op-
 
does not produce the same sound ([E] in Terrasse, schwa in antwortete). Per-
haps are there dialects (Moulton uses a Northern variety) where both are either 
schwa or [E]. In any event, I have noted [E] in both instances for the sake of ar-
gument. Following Standard German, I also transcribe r-vocalisation in codas 
and its uvularised versions elsewhere (Moulton only notes [r] and /r/). 

48 
Chap 3: American structuralism: juncture phonemes 
tional presence of a glottal stop makes the two sequences distinct, both 
phonetically and semantically. 
 
(9) 
junctural minimal pairs in German: glottal stop 
 
spelling 
surface 
gloss 
 
a. den Bauer kennen 
[deen''bauåʙkEn´n] 
"to know the farmer"
den Bau erkennen 
[deen''bauåʙkEn´n] 
[deen''bau/åʙkEn´n] 
"to recognise the 
building" 
 
b. Arbeiter suchen 
[''/arbaitåʙzuuXen] 
"to look for workers"
Arbeit ersuchen 
[''/aabaitåʙzuuXen] 
[''/aabait/åʙzuuxen] 
"to request work" 
 
Here again, the recognition of a juncture phoneme would afford to 
avoid admitting the glottal stop in the phonemic inventory of German: den 
Bauer kennen would be /+deen''bauåʙkEn´n+/, while den Bau erkennen 
would identify as /+deen''bau+åʙkEn´n+/. On this analysis, the distribution 
of the glottal stop is allophonic: "vowels show an allophone with glottal 
stop after /+/, but without glottal stop after all other segmental phonemes" 
(Moulton 1947:223). 
Finally, the distribution of [X] and [ç] (which is notorious from lin-
guistic classrooms) is another illustration of the same pattern. [X] occurs 
after non-front vowels (including [a]), while [ç] is found after front vowels 
and consonants (that is, [l,r,n] as in Milch, durch, manch "milk, through, 
some"). However, a small residue of words resists this distribution, and 
these invariably involve the diminutive morpheme -chen [-ç´n]. This time, 
thus, there are real minimal pairs as under (10a,b), i.e. which do not involve 
word boundaries. In addition, though, Moulton (1947:223) also mentions 
utterances such as under (10c) where [ç] and a preceding back vowel are 
separated by a word boundary. 
 
(10) 
junctural minimal pairs in German: [ç] - [X]
spelling 
surface 
gloss 
 
a. Kuchen 
[kuuX´n] 
cake 
Kuhchen 
[kuuç´n] 
little cow 
 
b. tauchen 
[tawX´n] 
to dive 
 
Tauchen 
[tawç´n] 
little rope 
 
c. da China so groß ist [daaçiinasoog´oosIst] since China is so large 
 

"Accidental" coincidence of juncture and morpho-syntactic divisions 
49 
This situation normally requires the existence of two phonemes, /ç/ 
and /X/. But an analysis along the lines of Moulton's juncture phoneme can 
rescue the items which violate the distributional regularity: if the mor-
pheme boundary of the diminutive suffix incarnates as /+/, the cake will be 
/+kuuX´n+/, whereas the little cow becomes /+kuu+X´n+/. On this analy-
sis, then, /X/ is subject to allophonic variation whereby [X] appears after 
non-front vowels, while [ç] is found after all other segmental phonemes, 
including the juncture /+/. 
 
65 
4. "Accidental" coincidence of juncture and morpho-syntactic 
divisions 
 
Considering the evidence from a wholesale perspective, Moulton 
(1947:223f) favours an analysis that uses one single object, i.e. the open 
juncture /+/, over the regular account where three new phonemes must be 
recognised (i.e. /ç/, /// and /aspiration/). Economy is thus the critical argu-
ment. The juncture /+/ is multifunctional and does the job of three other-
wise unrelated phonemes. However, Moulton insists on the fact that the 
benefit is functional, rather than numeric: a generalisation would be missed 
if the evidence relating to morphological boundaries were expressed by 
three independent items. He thus explicitly recognises the impact of mor-
phology on phonology. 
In the same way, Moulton is explicit about the morpho-syntactic 
conditioning: all minimal pairs for aspiration and the glottal stop that one 
can come by are monsters, i.e. contain a word boundary that is critical for 
the opposition. In the case of the [X]-[ç] alternation, the same holds true for 
morphological boundaries. The corresponding putative phonemes would 
not exist if only items of word-size (of morpheme-size for [X]-[ç]) were 
considered. Also, Moulton makes a phonetic argument: in slow speech, /+/ 
may (but need not) coincide with a pause. 
Finally, Moulton comes to grips with the critical question: all that he 
has said and done so far is in overt conflict with the structuralist principle 
of Level Independence. That is, there must not be any coincidence of /+/ 
with morpho-syntactic divisions. Or if so, it can only be accidental. 
This is precisely the line of argumentation that Moulton adopts. For-
tunately enough for him, aspiration and the glottal stop also occur mor-
pheme-internally: the complete descriptive statements are "word-initially 
and before stressed vowels" for the former, "before word-initial vowels and 

50 
Chap 3: American structuralism: juncture phonemes 
in the middle of a hiatus in case its second element is stressed" for the lat-
ter. Hence in words such as Papier [pha'phiiå] or Laterne [la'thEån´], the 
presence of aspirated word-medial consonants enforces the structure 
/+pa+pir+/ and /+la+terne+/, respectively. In the same way, Theater 
[the'/aatå] and Ruine [´u'/iin´] call for word-internal /+/, i.e. /+te+ater+/, 
/+ru+iin´+/. 
In the end, thus, Moulton (1947) tries to deny the phonological rele-
vance of morpho-syntactic information for which he has provided evidence. 
He does so under the pressure of structuralist orthodoxy and, one may as-
sume, against better understanding (see note 14 on page 225 of his article). 
The take-home message of the previous pages is the causal relation 
that, starting with Level Independence and the prohibition of higher level 
information in phonology, inevitably leads to juncture phonemes and their 
presence in the middle of morphemes. Before the absurd consequences of 
the latter are discussed in § 69, the following section provides a broader 
overview of how morpho-syntactic divisions were treated in the structural-
ist literature. 
 
66  5. Structuralist views on the coincidence of juncture and morpho-
syntactic divisions 
 
67  5.1. Defenders of orthodoxy (Hockett, Joos, Trager) and Harris' ambiguous 
position 
 
It was mentioned in § 62 that even though Level Independence was the or-
thodox structuralist position defended by Hockett (1955) and Joos (1964), 
more tolerant views that allow for morpho-syntactic information to inform 
phonological analysis are also found in the literature (see the discussion in 
Aronoff 1980:31f and Goldsmith 2008). 
Let us begin with Zellig Harris' (1951) position, which is ambiguous. 
Given the quote below from the outset of his chapter on juncture, he ap-
pears to defend true orthodoxy: morpho-syntactic traces in phonology are 
strictly prohibited, and the only purpose of juncture is phoneme economy. 
 

Coincidence of juncture and morpho-syntactic divisions in structuralism 
51 
(11) 
"This procedure introduces junctures as a factor in phonemicization, but 
only, of course, to the extent that this is possible without knowledge of mor-
phemes. 
 
8.1. Purpose: Eliminating Restrictions on Sets of Phonemes 
 
We reduce the number of phonemes, and simplify the statement of restric-
tions upon the environments in which they occur, by considering those re-
strictions of environments which apply to large numbers of phonemes." 
Harris (1951:79) 
 
That is, juncture phonemes do not need to comply with any require-
ment other than acting as an environment for the prediction of allophones. 
Just like all other phonemes, they thus occur at arbitrary places in the 
string. Accordingly, Harris (1951:87f) allows for the German word Teil 
[thajl] "part" to identify as /d#ajl/ in order to be able to generalise the final 
devoicing pattern which is found in this language: word-final underlying 
/d#/ appears as [t]; hence /d/ can be eliminated from the phonemic inven-
tory if all [t]s, even in non-neutralising and morpheme-internal environ-
ments, are interpreted as the result of devoicing before "#". The treatment 
of German voiceless obstruents is thus an application of the economic am-
bition: a world with fewer phonemes is a better world.13 
However, elsewhere in the book Harris (1951) departs from the or-
thodox point of view by allowing not only "accidental" coincidence of 
juncture and morpho-syntactic divisions, but also their causal relationship. 
In a footnote, Harris (1951:241) writes "that phonemic junctures are used 
for segments which occur only at morpheme (or other) boundary." Also, he 
appears to enjoy a perspective where juncture can be made to carry mor-
pho-syntactic information: "[t]he great importance of junctures lies in the 
fact that they can be so placed as to indicate various morphological bounda-
ries." Harris (1951:87). 
This inconsistency is pointed out by Aronoff (1980:34f), while Gold-
smith (2008:51ff) goes at great length to show that Harris cannot be 
counted as a representative of orthodoxy: he provides the quotes of the 
 
13 Hockett (1942:9) provides a general formulation of economy in structuralist 
theory: "Economy: if several different analyses equally satisfy the other re-
quirements, that which establishes the smallest number of phonemes is the one 
to be preferred. This is a corollary of the general scientific principle that the 
simplest description which accounts adequately for all the facts is to be pre-
ferred." 

52 
Chap 3: American structuralism: juncture phonemes 
preceding paragraph and many others in support, but does not mention the 
conflicting statement under  (11). 
Hockett (1955) was already identified as a defender of the orthodox 
position: In his textbook, he is explicit about the fact that the coincidence of 
juncture with morpho-syntactic divisions can only be accidental. 
 
(12) 
"There is one potential source of error which ought to be avoided. Juncture 
phonemes are not recognized in order to show grammatic boundaries of one 
or another kind - say boundaries between words. It often happens that
grammatic boundaries fall at open junctures, particularly grammatic word 
boundaries." Hockett (1955:172) 
 
Unlike Harris (1951), however, he seems to refrain from explicitly 
admitting that juncture may also fall in morpheme-internal position. Lehiste 
(1960:47) shares this view. 
Finally, Trager (1962) is another representative of structuralist ortho-
doxy: juncture phonemes are estranged from any morpho-syntactic corre-
late, and hence do not imply any prediction. 
 
(13) 
"Most places where /+/ occurs also indicate the end of a word, but in some 
instances it is only the end of a morpheme that is present, as in shyness 
/ãáy+nØs/; while in still others there is not even a morpheme-end, as in the 
pronunciation of center as /sén+t´r/. Moreover, there are word sequences 
without /+/: postman may be /pówsm´n/ as well as /pówst+m´n/."14 Trager 
(1962:19f) 
 
68  5.2. Opposite view: Pike's grammatical prerequisites 
 
While the orthodox attitude was widespread and dominant, it also faced 
principled opposition. Pike (1947) leads this move. His article is entitled 
"Grammatical prerequisites to phonemic analysis", and he argues that pho-
nemic analysis cannot be done without morpho-syntactic information. In a 
follow-up article five years later (Pike 1952), he adduces further support for 
his position and discusses the literature on the topic that has appeared in the 
meantime. 
 
14 Trager does not indicate why this particular pronunciation requires juncture. 
The transcriptions in slashes are approximate: it is difficult to reproduce the 
multiple diacritics on all sides of the basic symbols that are carried by struc-
turalist phonetic records. 

Coincidence of juncture and morpho-syntactic divisions in structuralism 
53 
(14) 
"In recent years various phonemicists seem to have set as an ideal of phono-
logical description and analysis the elimination of all reference or reliance 
upon facts about the grammatical structure of the language being investi-
gated. [«] The present article holds that it is impossible for such claims to 
be realized completely, and that even were it possible it would at times 
prove undesirable." Pike (1947:155) 
 
Pike also challenges economy: in a perspective that airs a generative 
flavour, he favours insight over description. 
 
(15) 
"We are not after simplicity first, but rather a representation of the structure 
of the language as it functions, whether the result be simple or complex." 
Pike (1947:172) 
 
Vachek (1970) builds on Trubetzkoy's Grenzsignale in order to sup-
port Pike's grammatical prerequisites: if juncture has the Trubetzkoyan 
demarcative function, it cannot exist in the middle of morphemes; indeed, 
there is nothing to be marked morpheme-internally or, worse, the listener 
could be put on the wrong track. 
 
(16) 
"W. Haas arrived at a conclusion analogous to ours. In answering the ques-
tion of how much grammatical information is necessary for an adequate 
phonemic analysis he insists on the necessity of a certain minimum of 
grammatical prerequisites for this purpose, and as such minimum he speci-
fies precisely the knowledge of the placement of word and morphemic lim-
its." Vachek (1970:963) 
 
"This zero character of the supposed juncture phoneme is in full conformity 
with the classical Prague conception of Trubetzkoy's frontier signals. [«] 
Such a potential pause can never occur inside a morpheme but only between 
words (and, though less frequently, between morphemes constituting a 
word)." Vachek (1970:965) 
 
Wells (1947:107) is also a critical voice. He writes that "linguists 
find themselves tempted to institute 'junctures' simply as notational devices 
for reducing the number of phonemes." In his view, "juncture, whenever it 
occurs, is a morpheme - though often with no detectable meaning" (page 
108). This indeed rules out morpheme-internal juncture. 
Unlike in his later textbook that was quoted above, Hockett (1949) 
also appears to argue for syntactic control over juncture phonemes. 
 

54 
Chap 3: American structuralism: juncture phonemes 
(17) 
"If some peculiar phenomenon is predictable [«], and if its successive oc-
currences seem to mark fairly well the borders between phonological words, 
then that phenomenon is junctural. [«] A juncture phoneme is then a group-
ing of such phenomena which makes for unambiguous and simple linear 
transcription. If this last statement seems arbitrary, it is no more so than is, 
for me, the definition of any kind of phoneme." Hockett (1949:35f) 
 
In sum, it seems that Level Independence was challenged especially 
in older sources: the orthodox position became only dominant in the 50s. 
 
69 
6. Whatever suits the analyst: juncture in the middle of morphemes 
 
Let us now have a closer look at the disastrous consequences when juncture 
phonemes are estranged from morpho-syntactic control. The structuralist 
dilemma is embodied in the word "juncture" itself: if juncture phonemes 
may occur in the middle of morphemes, one wonders in which way they 
deserve their name. 
The case of Hill (1954) provides good illustration. Hill 
 
(18) 
"define[s] juncture [«] as a lengthening of the preceding phoneme by one 
half-unit, where a full unit is equal to the average length of a sound as mem-
ber of a phoneme." Hill (1954:440) 
 
This general equation of juncture with lengthening comes from the 
evolution of Latin where several modifications of length occurred. For ex-
ample, Hill ascribes the gemination of lat. labra in it. labbra to the exis-
tence of a juncture phoneme, because "no explanation [«] is as simple as 
postulating the sequence /-b + r-/ [«], where the juncture resulted in a 
lengthening of the preceding consonant." That is, it. labbra is derived from 
/lab+ra/. 
The juncture phoneme is thus exclusively defined by its effect, and 
its effect is attributed to its existence. The analysis is overtly circular. The 
only thing to which Hill seems to commit himself is a stable effect of junc-
ture, i.e. lengthening. One could therefore expect that juncture is present in 
all lengthening environments, but absent elsewhere. 
Alas, Hill (1954:441) overthrows this principle as well: one page 
later, the presence of juncture is responsible for the stability of a cluster, 
while its loss triggers assimilation. Latin ad ferō, *quid-pe were /ad+ferō,
quid+pe/, but become afferō, quippe in Vulgar Latin because the juncture 
was lost: /adferō, quidpe/ opens the way to assimilation. 

Is there a phonetic correlate of juncture? 
55 
While this could still be said to bear on the length of some segment, 
Hill (1954:444) completely gives up on that notion as he tries to make junc-
ture responsible for the difference between [i] and [j]. On his analysis, [j] is 
an allophone of /i/ when juncture was lost: lat. ais "thou sayest" is /a+is/ 
and therefore comes out as ['ais], while lat. aes "brass" is /ais/ and appears 
as ['ays]. 
It may certainly be argued that Hill (1954) is not representative of the 
structuralist literature: a framework is not responsible for bad analyses that 
are done in its name. The point, however, is that the theory does not object 
against this kind of absurd analysis. What is more, it actually pushes pho-
nologists to posit juncture phonemes in the middle of morphemes, as we 
have seen: under Level Independence, their coincidence with morpho-
syntactic divisions must be purely accidental. 
As a result, juncture phonemes are demoted to a meaningless dia-
critic that may be used whenever it suits the analyst, and without any cost. 
Since their phonetic realization is "zero" most of the time, having or not 
having a juncture in a phonemic transcription is for free. Why, then, should 
phonologists bother to look for explanations and causal relations? Whatever 
the problem, an invisible juncture phoneme is the solution: as a deus ex 
machina, it can be made responsible for any phenomenon and its reverse. 
In other words, being able to implement juncture phonemes in the 
middle of morphemes is a license for printing banknotes ± worthless bank-
notes that do not buy anything. 
 
70  7. Is there a phonetic correlate of juncture? 
 
The other major issue that is discussed in the structuralist literature con-
cerns an eventual phonetic manifestation of juncture. The regular position 
is that, just as for all other phonemes, a stable phonetic correlate is re-
quired. Recall that Moulton (1947) proposes allophonic variation between a 
"pause" and "zero". 
However, a fraction that one may call abstract does not care for any 
phonetic grounding. Hockett's early writings represent this position. 
 
(19) 
"So we see that the failure of all the allophones of some juncture phonemes 
to have some (articulatory or acoustic) property in common is no logical 
defect." Hockett (1949:38f) 
 
Harris (1951:79ff) also favours this position, and Wells (1947:108) 
sets out to make juncture a true morpheme: "juncture, whenever it occurs, 

56 
Chap 3: American structuralism: juncture phonemes 
is a morpheme ± though often with no detectable meaning." In this case 
indeed, there is no place for any phonetic correlate: "the validity of juncture 
phonemes is open to grave doubts on phonetic grounds" (page 107). 
Shocked by Harris' (1951) juncture abuse that was reported earlier 
(German Teil analysed as /d#ajl/, § 66), Hockett stands on the traditional 
concrete side by 1955. 
 
(20) 
"Juncture phonemes achieve their power precisely because of their phonetic 
heterogeneity. [«] There is one way of speaking of juncture which retains 
phonetic homogeneity of all its allophones. This is Harris's way. Harris sets 
up a juncture as a 'zero' phoneme ± a phoneme having no phonetic proper-
ties at all (and, because of this, having identical phonetic properties in all 
environments). The only function of the 'zero' phoneme, then, is to function 
as environment for ordinary phonemes: English /b/ is represented by differ-
ent allophones when flanked by this 'zero' phoneme and when not so 
flanked, and by different allophones depending on whether the 'zero' pho-
neme precedes or follows. This seems to the present writer a most unfortu-
nate and misleading kind of hocus-pocus; he feels that setting up junctures 
as always involving identifiable phonetic material, no matter how diverse, is 
much better." Hockett (1955:171f) 
 
The phonetic reality of juncture has also been studied instrumentally. 
Examples are Bolinger & Gerstman (1957), Lehiste (1960, 1962, 1965) and 
Hoard (1966). All work in this area indeed found "phonetic factors that 
indicate the presence of internal open juncture" (Lehiste 1960:39). 
Lehiste (1960:5ff), Devine & Stephens (1976:294ff) and Aronoff 
(1980:32ff) offer an informed survey of the question. Aronoff reports on 
attempts to make juncture a suprasegmental object: still a phoneme, but a 
suprasegmental, rather than a segmental one (Lehiste 1960:48 also argues 
along these lines). In a comment on Moulton (1947) and Leopold (1948), 
Martin Joos writes in his Readings in Linguistics that "finally one must 
assign juncture to a phonemic status: otherwise it is nothing. By hypothesis 
it can't be segmental: no room there. Hence we are forced to the Hockett 
solution [«]: it is suprasegmental" (Joos ed. 1957:216). 
This may look like an escape hatch into a mushy category, especially 
since the difference between segmental and suprasegmental phonemes, 
beyond intuition, is not very clear. Rather, what Joos means is that su-
prasegmentals do not need to have any specific phonetic existence; there-
fore we are fine: juncture is a phoneme, but nobody can hear it. The su-
prasegmental alternative thus simply appears to be a rhetorically enhanced 
way to have your cake and eat it too. 

Structuralist terminology 
57 
71  8. Structuralist terminology 
 
For the sake of completeness, the terminological jungle, which is typical 
for the structuralist literature, needs to be mentioned. There were end- and 
meaningless debates on the vocabulary that should be used in order to refer 
to juncture. Lengthy discussion of terms such as transition, disjuncture, 
schismeme or contiguity without much, if any, empirical or theoretical con-
tent were led for example in Welmers (1947), Hall (1948), Kepke (1948), 
Bolinger & Gerstman (1957), Trager (1962). 
Also, different juncture phonemes were recognised (see Harris 
1951:86f for a survey): internal vs. terminal juncture, internal vs. external 
juncture (Trager & Bloch 1941), close juncture vs. disjuncture (Hall 
1946:81), level terminal vs. upturn terminal vs. downturn terminal juncture 
(Potter 1962) or plus vs. internal open vs. terminal juncture (or even "semi-
juncture") (Stockwell et al.1956). Trager (1972:45) for example ends up 
with five different junctures. 
 
72  9. Conclusion: Level Independence seeds modularity and enforces 
translation 
 
The foregoing pages have discussed a number of issues that were debated 
in the structuralist literature. Important for the following steps of the survey 
below are Level Independence, the morpho-syntactic control over juncture 
and its phonetic correlate. 
One could be tempted to say that structuralism was wrong on all of 
these counts. That would be too rash a conclusion, though. It is true that 
nobody today believes anymore that morpho-syntactic divisions leave a 
phonetic trace. It is also true that admitting juncture in the middle of mor-
phemes is a disaster: there is no point in doing phonology anymore since all 
facts observed can be ascribed to arbitrarily placed and arbitrarily chosen 
ghosts. 
The frequent mocking of the structuralist approach in modern retro-
spection, however, is undue and misevaluates an important contribution 
that hides behind unfamiliar vocabulary. Level Independence expresses the 
idea of what will later be known as Fodorian modularity, at least partly: 
although miles away from a cognitive perspective and ambitioning to 
achieve descriptive accuracy rather than understanding, it embodies the 
insight that phonology and morpho-syntax (the structuralist literature com-
monly opposes phonology and grammar) are two ontologically distinct 

58 
Chap 3: American structuralism: juncture phonemes 
systems, and a priori incommunicado. Therefore morpho-syntactic informa-
tion can only play a role in phonology if prior to its action it is translated 
into truly phonological units (rather than into diacritics). 
The impossibility to use untranslated morpho-syntactic units in pho-
nology (and vice-versa) follows from what is known as domain specificity 
in the modern modular perspective (§§ 610, 640). True, structuralist phonol-
ogy and morpho-syntax are only waterproof in one direction: the bottom-up 
discovery procedure uses phonological units in order to build morpho-
syntactic structure. Also, the claim that no information transits in the oppo-
site direction is of course wrong (but even structuralists did not really be-
lieve in this dogma: this is what the camouflage of juncture in a phonemic 
guise is all about). 
Beyond these issues, however, the idea that we face two different 
levels of analysis which use two distinct sets of vocabulary and possess 
their own computation is a central insight expressed by Level Independ-
ence. It also lies at the heart of Fodorian modularity which is introduced at 
length in the Interlude (§ 586) and will become the cognitive reference for 
the generative architecture of grammar in the 80s (see § 415). In short, 
Level Independence enforces intermodular translation of morpho-syntactic 
into phonological vocabulary (see § 649 and the summary regarding transla-
tion in § 692). 
Finally, it is interesting to observe that all subsequent theories of the 
interface (with the exception of so-called direct syntax, §§ 137, 407) have 
followed the track that was opened by structuralist translation. Since the 
only phonological vocabulary that was available in structuralist theory were 
phonemes, morpho-syntactic information could only incarnate as juncture 
phonemes. The output of translation then changed as the vocabulary of 
phonological theories evolved: phonemes were followed by segments in 
early generative phonology (sic: # and + were supposed to be [-segment] 
segments, § 87) and autosegmental domains (the Prosodic Hierarchy) in the 
early 80s after the advent of autosegmental structure (§ 368).  
The interface invariant, then, is that the carriers of morpho-syntactic 
information in phonology always correspond to the basic representational 
units that current phonological theory manipulates.15 
15 OT is an exception: being a theory of computation (and of nothing else), it has 
no genuine representational vocabulary (§ 452). As in other areas (such as seg-
mental representation), the old furniture of the 80s, prosodic constituency, is 
therefore still the relevant interface currency in present-day constraint-based 
environments. 

Chapter 4 
73  Chomsky, Halle & Lukoff (1956) 
74 
1. The structuralist cover: economy 
 
In the 50s when generative analysis was exotic in structuralist-dominated 
phonology, Chomsky et al. (1956) tried to introduce what later will become 
orthodox ideas of SPE (significantly, in a Festschrift for Roman Jakobson). 
Since the environment was by and large hostile, they attempted to clothe 
their work on boundaries in the structuralist strive for economy.16 That is, 
any move that reduces the number of phonemic entities was welcome (see 
§§ 60,65). In this perspective, Chomsky et al. (1956) propose to replace the 
four different stress phonemes that were commonly recognized for English 
(and numbered 1 to 4) by one single opposition, "accented" vs. "unac-
cented". All the rest of the labour, they submit, can be done by juncture. 
The examples that commonly served for the establishment of four 
stress phonemes are junctural minimal pairs that had been largely discussed 
in the structuralist literature. A good example is the oft-quoted light house 
keeper (e.g. Bolinger & Gerstman 1957). This item possesses four stress-
able vowels, and according to the distribution of stress can mean different 
things ("for some speakers" according to Chomsky et al. 1956). Table  (21) 
below illustrates the contrasts reported. 
 
(21) 
light house keeper: contrastive readings according to stress 
 
a. [2134] 
a housekeeper who is light in weight 
 
b. [1324] 
a person who keeps a light house 
 
c. [3134] 
a person who does light housekeeping 
 
Chomsky et al. (1956) propose to achieve the contrast by juncture, 
rather than by stress phonemes. They use two different junctures, "internal" 
"±" and "external" "=". Phonemically speaking, the threefold "minimal 
pair" is thus structurally, rather than prosodically distinct in the way shown 
under  (22) below. 
 
16 St. Anderson (1985:313f) describes the socio-political background and impact 
of Chomsky et al. (1956). 

60 
Chap 4: Chomsky, Halle & Lukoff (1956) 
(22) 
light house keeper: identities according to Chomsky et al. (1956) 
 
a. [2134] /light = house ± keeper/ 
a housekeeper who is light in weight
b. [1324] /light ± house ± keeper/ 
a person who keeps a light house 
 
c. [3134] /light house keeper/ 
a person who does light housekeep-
ing 
 
The distribution of stress, then, is allophonic according to juncture. 
With reference to Hockett (1955:158, 168), Chomsky et al. (1956) explic-
itly advertise simplicity and economy as the trump of their analysis: junc-
tures "are introduced for the purpose of reducing the number of physical 
features that must be considered phonemic" (pages 66 and 68). 
 
75 
2. Phonological domains built on juncture distinctions 
 
Pretending to follow the track of economy allows Chomsky et al. (1956) to 
introduce genuinely generative ideas into the structuralist environment. 
Among these features most prominently the claim that not only syntax and 
semantics, but also phonology is hierarchically organised. 
 
(23) 
"Constituent structure has always been considered a characteristic feature of 
the higher levels of morphology and syntax. We are suggesting here that it 
exists on the phonological level as well. Every linguistic level, then, has the 
basic form of a linear system of symbols, organised into a hierarchical ar-
rangement." Chomsky et al. (1956:78f) 
 
The phonological constituent structure that Chomsky et al. (1956:70) 
appeal to is built on the juncture phonemes that were introduced in order to 
reduce the number of phonemes. That is, all junctures are ranked according 
to their relative prominence: some are stronger, others are weaker. This 
move foreshadows the classical generative treatment of boundaries where 
the morphological + is weak, against the stronger syntactic # (boundary 
strength, §§ 87, 116). 
On these grounds, Chomsky et al. (1956:70) construct a "phonemic 
clause" which "will be bounded [«] by zero-order junctures. Within this 
domain, the two junctures discussed above [i.e. internal and external] suf-
fice to determine stress in a simple and significant manner." As far as I can 
see, this is the first occurrence of the idea that junctures define phonologi-
cal domains. Credit for this conception is usually given to McCawley 
(1968:52ff) (see §§ 113, 373). 
 

Level Independence abolished: phonology with morpho-syntactic information 
61 
76  3. Level Independence abolished: phonology does take morpho-
syntactic information into account 
 
Another thing that Chomsky et al. (1956:67) do is to overthrow the struc-
turalist mantra of Level Independence (§ 61). They argue that there is no 
reason why morphological and syntactic considerations should not be 
brought to bear in order to establish a phonemic transcription. 
Halle (1959) secures this position with an argument that draws on the 
analogy with other sciences: theoretical constructs are independent of the 
procedure that leads to their postulation. Hence any evidence, including 
morpho-syntactic, is good evidence for the establishment of the phonemic 
string.17 
(24) 
"The theoretical constructs which make up the representations discovered by 
the different types of analysis are, however, postulated within the framework 
of the individual sciences without regard for the procedures whereby they 
can be discovered in the data. Theoretical constructs are never introduced 
because of considerations that have to do with analytic procedures. Thus, for 
instance, it is inconceivable that chemistry would establish substances that 
can be identified by visual inspection as a category distinct from substances 
that require more elaborate techniques for their identification. Yet this is 
precisely the import of Condition (3a), for it sets up a distinction be-
tween phonemes and morphophonemes for the sole reason that the for-
mer can be identified on the basis of acoustic information alone, whereas 
the latter require other information as well.[«] 
The abolition of Condition (3a) is not as much at variance with tradi-
tional practice as might at first appear. It is hardly an accident that in the 
phonological descriptions of E. Sapir, and to some extent also in those of 
L. Bloomfield, Condition (3a) played no role." Halle (1959:23f) 
 
Another question related to structuralism is whether the phonemic 
transcription allows, or should allow, to arrive at a unique representation for 
every utterance heard. Chomsky et al.'s (1956:67) answer is no. 
 
17 Condition (3a) that is mentioned in the quote below is Level Independence: 
"Condition (3a): A phonological description must include instructions for infer-
ring (deriving) the proper phonological representation of any speech event, 
without recourse to information not contained in the physical signal" Halle 
(1959:21). 

62 
Chap 4: Chomsky, Halle & Lukoff (1956) 
77  4. Two for the price of one: multifunctional juncture 
 
Liberated from the two structuralist straitjackets discussed in the previous 
section, Chomsky et al. (1956) can take full advantage of what Moulton 
(1947) only hinted at: it can hardly be accidental that the distribution of 
juncture phonemes, which are established on purely phonological grounds, 
by and large coincides with morpho-syntactic divisions. Chomsky et al. 
(1956) now are able to emphasize the multifunctional character of juncture. 
 
(25) 
"Foremost among these advantages is the fact already mentioned that the 
constituent organisation imposed from purely phonological considerations 
(i.e., from considering the simplest way to state stress) correlates quite 
closely with the constituent organisation that is required for the description 
of English on other levels. This correspondence leads to an overall simplifi-
cation of the grammar of the language, since the constituent structure once 
stated can be made to serve a variety of functions." Chomsky et al.
(1956:78) 
 
Multifunctional juncture also responds to an objection that could be 
levelled against Chomsky et al. (1956) on phonological grounds: what kind 
of economy do we achieve if four stress phonemes are traded against one 
accent phoneme and two junctures (internal and external)? If the junctures 
that do the job of stress distribution are needed at higher levels anyway, 
they are not introduced into the grammar for the mere purpose of stress. 
Rather, Chomsky et al. (1956) only fertilise for phonological analysis a 
structure that is needed anyway. 
 
78  5. Morpho-syntactic control over juncture restored, and no phonetic 
correlate 
 
A direct consequence of restoring morpho-syntactic control over the distri-
bution of juncture is that juncture abuse as described in § 69 is expunged. 
That is, phonologists are not free anymore to distribute juncture whenever 
it suits their analysis; especially, no juncture can ever occur in the middle of 
morphemes. 
 
(26) 
"Junctures should be distributed in a manner that is significant on higher 
levels. Specifically, junctures should appear only at morpheme boundaries, 
and different junctures should correspond, by and large, to different mor-
phological and syntactical [sic] processes." Chomsky et al. (1956:67) 

Morpho-syntactic control over juncture restored, and no phonetic correlate 
63 
This, in turn, leads to the purely diacritic definition of boundaries 
that is practised in SPE: the phonetic correlate that was called for because 
of the phonemic status of juncture (see the structuralist discussion in § 70) is 
now definitely done away with. Recall, for example, Trager's (1962:17) 
antipathy for utterance-initial juncture because "there is nothing, phonemi-
cally speaking, before the beginning". In contrast to this position, Chomsky 
et al. (1956) deny any phonetic status to boundaries. 
 
(27) 
"The segmental phonemes represent physical entities and, therefore, each 
manifestation of a phoneme must have certain stateable physical properties. 
[«] The junctures, on the other hand, do not represent physical entities, but 
are introduced for the purpose of reducing the number of physical features 
that must be considered phonemic." Chomsky et al. (1956:66) 
 
On the first page of his book and in a chapter entitled "Segments and 
Boundaries", Halle (1959) consolidates this view. 
 
(28) 
"In phonology, speech events are represented as sequences of entities of 
two kinds : segments, to which specific phonetic (articulatory as well as 
acoustical) properties are assigned, and boundaries, which are character-
ized solely by their effects on the former)." Halle (1959:19), emphasis in 
original 
 
This distinction will later appear as the SPE feature [±segmental] 
which opposes juncture (negative value) and phonetically expressed seg-
ments (positive value) (see § 87). 
In a footnote depending on the quote above, Halle (1959) also justi-
fies the introduction of the term boundary.
(29) 
"Boundaries are analogous to what some linguists have termed 'junctures'. Since 
the latter term has recently been used in a very special sense, the more neutral 
'boundary' has been adopted here." Halle (1959:19) 
 
Hence it seems that the non-phonetic conception of juncture was at 
the origin of the introduction of the word boundary into phonology: Halle 
wanted an alternative to the phoneme-bound juncture. 
 

64 
Chap 4: Chomsky, Halle & Lukoff (1956) 
79 
6. Privativity, an accidental consequence of economy 
 
Another aspect that is relevant for the discussion below is privativity. We 
have seen that Chomsky et al. (1956) require juncture to coincide with 
some morpho-syntactic division. But is it also true in turn that all morpho-
syntactic boundaries are projected onto phonology? The answer is no. 
 
(30) 
"Since junctures are introduced for the purpose of reducing the number of
physical features that must be recognized as phonemic, we do not require 
that every morpheme boundary be marked by a juncture. [«] Only those 
morpheme boundaries are marked by a juncture where actual simplifications 
in the transcription are achieved. In other words, junctures are postulated 
only where phonetic effects can be correlated with a morpheme boundary." 
Chomsky et al. (1956:68) 
 
Chomsky et al. (1956) thus argue for the privative representation of 
morpho-syntactic information in phonology: only those divisions which 
indeed produce a phonological effect are projected. 
SPE will revert back to a non-privative mapping (see § 90): all mor-
pho-syntactic divisions land in phonology no matter whether they are pho-
nologically relevant or not. Like most other architectural properties of SPE, 
this stance abides in more recent theories, among which namely Prosodic 
Phonology. In contrast to this unanimous generative tradition, it is argued 
below (§ 756, also in Vol.2) that translation of morpho-syntactic information 
into phonological objects must be privative. 
 
80  7. Cyclic derivation (inside-out interpretation) 
 
Finally, due mention needs to made of the fact that cyclic derivation, a 
landmark in interface theory, was born in Chomsky et al. (1956). Cyclic 
derivation is unprecedented in structuralist or neogrammarian thinking; it 
has known a number of different incarnations according to the environment 
of particular theories and their take on the architectural design of grammar. 
The principle itself, however, stands (almost) unchallenged today (see 
§672). 
The idea is that the linear string is not interpreted as a whole. Rather, 
phonological (and semantic) computation applies to successive, morpho-
syntactically defined chunks along the hierarchical morpho-syntactic struc-
ture. In other words, strings experience inside-out interpretation along the 
morpho-syntactic tree. For example, given an embedded structure such as 

Cyclic derivation (inside-out interpretation) 
65 
[[[A] B] C], phonology applies to all domains, starting with the most em-
bedded one and moving outwards: first phonology assesses [A], then [AB], 
and finally [ABC]. That is, embedded pieces experience the same computa-
tion several times: first alone, then in the company of other pieces (in our 
example A is computed three times). 
Cyclic derivation appears in Chomsky et al. (1956) as a local and an-
ecdotic algorithm that derives stress placement. Chomsky et al. do not pro-
vide any further discussion, and no more general ambition is declared. 
 
(31) 
"Rule 4: Given a phonemic clause, 
 
(i) 
assign the value 1 to all accented words; 
 
(ii) then apply each rule pertaining to accented vowels no more than once 
to each constituent, applying a rule to a constituent of order n only 
after having applied it to all constituents of order n+1; i.e. beginning 
with the smallest constituents and proceeding to larger and larger 
constituents; 
 
[«]" 
 
Chomsky et al. (1956:75) 
 
The anecdotal way in which cyclic derivation was introduced into 
linguistic thinking contrasts with the landmark qualities that it has acquired 
in further evolution. This treatment is characteristic for the pre-SPE period, 
though: discussion only concerned the representational side of the interface 
coin. Nobody had thought of the possibility that there may also be a proce-
dural way for morpho-syntax to talk to phonology.  
Starting with Bromberger & Halle (1989:65ff), the idea that phonol-
ogy is made of procedurally (and extrinsically) ordered instructions is often 
quoted when it comes to explain in which way structuralism and generativ-
ism are different. A whole body of literature has pointed out, however, that 
ordered rules are not a generative invention: they are also present in 
Bloomfield's (1939) Menomini Morphophonemics and Wells (1949) (e.g. 
Huddleston 1972, Encrevé 2000, Koerner 2004).  
Goldsmith (2008) has recently studied the question whether the tran-
sition from structuralist to generative phonology is to be seen as a rupture 
(as is constantly claimed by generativists) or a continuity. Regarding or-
dered rules and other candidate properties that may be claimed to set gen-
erative phonology apart from its predecessor, Goldsmith concludes that all 
major generative ideas were present in structuralist thinking (even though 
they may not have been in the focus of structuralist attention). 
On this backdrop, cyclic derivation may be a successful candidate for 
a property that was completely absent from linguistic thinking before the 

66 
Chap 4: Chomsky, Halle & Lukoff (1956) 
advent of generative grammar: inside-out parsing is a genuinely generative 
idea. 
In any event, in 1956 we are still miles away from the generative 
standard that I call Interface Dualism (§ 683), i.e. the idea that there are two 
means for morpho-syntax to bear on phonology, one procedural, the other 
representational. The rebalancing of the exclusively representational view 
on the interface will only be operated in SPE. 
 

Chapter 5 
81  SPE sets the standards for 40 years 
82  1. Introduction 
 
83  1.1. Interface Dualism 
 
SPE has set the standards for interface theory that are still valid today. This 
will be obvious as more recent theories are discussed below. Beyond labels 
and vocabulary, which have changed since the 60s, concepts have remained 
the same; they may have been worked out in greater detail, couched in 
various syntactic and phonological environments and cover a larger empiri-
cal record, but the overall architecture has remained unchanged. 
The headstone of the interface architecture of SPE is what I call In-
terface Dualism. That is, morpho-syntax talks to phonology through two 
channels, one procedural, the other representational. Cyclic spell-out is the 
procedural way of bearing on a phonological process. It was introduced in 
Chomsky et al. (1956:75) (see § 80) and is known as derivation by phase 
today (Chomsky 2000a et passim) (see §§ 304, 673, Bermúdez-Otero forth b 
provides an overview).  
Note that SPE did not provide for any no look-back device. The an-
cestor of today's Phase Impenetrability Condition (PIC) was only intro-
duced in Chomsky's (1973) Conditions on Transformations under the 
header of the Strict Cycle Condition. It was then applied to phonology by 
Kean (1974) and Mascaró (1976) in the 70s, before becoming an important 
tool of Lexical Phonology (see § 287 for a survey). 
The representational way of talking to phonology is through objects 
that carry morpho-syntactic information and are inserted into the phono-
logical module. These objects were juncture phonemes in structuralism 
(§ 72), they are boundaries in SPE, and the autosegmental equivalent of the 
80s will be the Prosodic Hierarchy (see § 360). 
I argue that the dual nature of communication is critical for a correct 
interface theory: the post-SPE development has produced models which 
have maximised either the procedural (Lexical Phonology, § 139, Kaye 
1995, § 258) or the representational channel (Prosodic Phonology, § 360). 
These monocultures cannot account for all patterns found. 
 

68 
Chap 5: SPE sets the standards for 40 years 
84  1.2. Modular seeds in SPE: the inverted T and translation 
 
The generative approach to language is modular at heart, both regarding the 
interaction of grammar with other cognitive systems (physiology, percep-
tual psychology, acoustics, vision etc.) and its internal organisation proper. 
Modularity is introduced at greater length in the Interlude (§ 586, also 
§410). The reason why it needs to be mentioned here is that the modular 
idea is part and parcel of the generative enterprise since the 60s, even 
though modularity as a general theory of the cognitive system (Fodor 1983) 
was still in an embryotic state in the 60s (see § 623). As we will see below, 
it clearly shines through in SPE (without the word modularity appearing, 
though), but is also happily violated when it comes to labelled brackets. 
Modularity holds that the human cognitive system in general, and 
language in particular, is made of several independent computational sys-
tems that are specialised for the execution of a particular task and autistic in 
the sense that they do not know, or care for, what is going on outside of 
their narrow limits. Also, modules are non-teleological, i.e. they pursue no 
other goal than successfully carrying out their computation. This idea may 
be traced back to Chomsky (1955-56) (see §§ 623, 628, where the develop-
ment of modularity in generative grammar is discussed at greater length).  
The following quote from SPE shows that modularity is really what 
Chomsky and Halle meant when they were talking about phonology, even 
though they were lacking the modern vocabulary. 
 
(32) 
"The rules of the grammar operate in a mechanical fashion; one may think 
of them as instructions that might be given to a mindless robot, incapable of 
exercising any judgment or imagination in their application. Any ambiguity 
or inexplicitness in the statement of rules must in principle be eliminated, 
since the receiver of the instructions is assumed to be incapable of using 
intelligence to fill in gaps or to correct errors." Chomsky & Halle (1968:60) 
 
Modularity has shaped the general architecture of generative gram-
mar, which at least since Aspects (Chomsky 1965:15ff) recognises three 
modules (syntax, phonology and semantics). The corresponding inverted T 
model is presented in § 86 below. This architecture is still in place today 
(e.g. Chomsky 2000a et passim, § 304), and the loops that it made in the 
development of interface theory will be a loyal companion through subse-
quent chapters. 
The second obvious impact of modularity on how SPE conceives the 
interface with morpho-syntax is the existence of translation: SPE bothers 
transforming morpho-syntactic structure into items that are part of the in-

Introduction 
69 
ventory of phonological objects, #s. In the view of SPE, indeed, hashmarks 
are regular segments ([-segment] segments, see § 87). Were morpho-syntax 
and phonology one, and could they understand the vocabulary that the other 
uses, no such translation would be needed in the first place. The existence 
of translation is thus a clear trace of modular thinking (§ 85 describes how it 
is organised in SPE). 
It was already argued in § 72 that the modular idea was seeded by the 
structuralist principle of Level Independence (notwithstanding the fact that 
it was born in absence of any reference to the cognitive system, see § 61). 
Early generative work was of course embossed by the overarching meth-
odological principle of Level Independence that guided structuralist work: 
this is what Chomsky et al. (1956) were wrestling with (§ 76). Also, there is 
a very clear continuance of translation since structuralist days: successive 
phonological theories translate morpho-syntactic information into their 
genuine phonological vocabulary: first into (juncture) phonemes, then into 
([-segment]) segments, finally into autosegmental structure (the Prosodic 
Hierarchy) (see §§ 379, 692). 
It is thus certainly true that the existence of translation witnesses 
modular thinking ± but this thinking is not a generative privilege. Genera-
tivists built the modular inverted T model, which requires translation, on 
the foundations of structuralist Level Independence. Hence generative 
grammar may not get credit for the idea that morpho-syntax and phonology 
are distinct waterproof worlds. What it does get credit for, however, is the 
institutionalisation of translation whose existence, recall, was denied by the 
official structuralist mantra, but circumvented in practice. 
This aspect of the continuity between structuralist and generative 
thinking is taken up at greater length in §§ 415, 693. The discussion also 
shows that it was only the implementation of a translational mechanism 
that raised the diacritic issue (§ 78), which will run all through the remain-
der of the book. 
Finally, it is worth mentioning that the headstone of Prosodic Pho-
nology, Indirect Reference, is also an offspring of modularity, even though 
for some reason this went unnoticed in the 80s (see § 414). We will see that 
Indirect Reference roots in SPE: its ancestor is the Readjustment Compo-
nent. To date the literature motivates Indirect Reference with the original 
SPE example (cat-rat-cheese, see § 91): the pattern is called non-
isomorphism (see § 416). 
 

70 
Chap 5: SPE sets the standards for 40 years 
85 
2. Translation in SPE (output: boundaries) 
 
86  2.1. The inverted T model 
 
Modularity conceives the internal organisation of grammar as a collabora-
tion between distinct and independent computational systems. This archi-
tecture was made explicit in Aspects (Chomsky 1965:15ff): (mor-
pho-)syntax is the central concatenative system, whose output is interpreted 
by phonology (PF) and semantics (LF); these produce form and meaning, 
respectively. The architecture is shown under  (33) below; it is known as the 
inverted T model (or the Y model). 
 
(33) 
the inverted T model: 
all concatenation before all interpretation 
 
morpho-syntax 
 
 
 
 
 
 
 
 
 
PF
LF
In SPE and further practice, morpho-syntax and the two interpreta-
tive modules are procedurally ordered so that words and sentences are 
pieced together before being shipped to interpretation at PF and LF. That is, 
all concatenation is done before all interpretation.18 
While the inverted T model stands unchallenged up to the present 
day as a whole, the full completion of concatenative activity before inter-
pretation can begin will be a bone of contention in further development. It 
is therefore important to realise that the requirement "all concatenation 
before all interpretation" does not follow from the inverted T: it is an addi-
tional plug-in that needs to be motivated independently. It is certainly true 
that no such motivation was provided in SPE and the post-SPE literature, 
where "all concatenation before all interpretation" was assumed without 
discussion. 
The competing view is so-called interactionism, according to which 
concatenation and interpretation are interspersed. Interactionism was intro-
duced by the stratal architecture of Lexical Phonology (§ 146); it then 
 
18 Bresnan (1971) is an early and isolated case where this principle is violated (by 
a syntactician). Bresnan's analysis of English intonation is discussed in § 308. 

Translation in SPE (output: boundaries) 
71 
prompted Halle & Vergnaud's (1987a) reaction, which attempts to restore 
"all concatenation before all interpretation" (§ 216). Modern phase theory, 
however, is interactionist at heart (§ 304), and so are Kaye (1995) (§ 275) 
and Distributed Morphology (of which Morris Halle is a founder, § 532). 
 
87  2.2. Boundaries 
 
88  2.2.1. Boundaries are [-segment] segments without phonetic correlate 
 
In order to see how translation works in SPE, let us begin by introducing its 
output: boundaries. 
The generative approach to language conceives grammar as a set of 
basic symbols, which are modified by a computational system. In SPE, 
binary distinctive features (which are constitutive of segments) are the ba-
sic symbols, which are manipulated by (ordered) rules. Whatever is found 
in natural language must be formalised as an interplay of structure (fea-
tures/segments) and processes (rules). 
Boundaries are no exception: SPE considers them to be ordinary 
segments. Their only peculiarity is the fact that unlike /p/, /e/ and the like, 
they do not have any phonetic manifestation. SPE thus continuates the non-
phonetic generative view on juncture that Chomsky et al. (1956) have ar-
gued for (see § 78). Boundaries now root in morpho-syntactic structure 
alone: their job is to carry its information into the phonology. Economy (of 
phonemes) is not an issue anymore (there are no phonemes), and there can-
not be any boundary in absence of a morpho-syntactic division (i.e. in the 
middle of morphemes, see § 78). 
This non-phonetic scenario for boundaries, however, faces the same 
conceptual trouble as its juncture-based equivalent: all segments are sup-
posed to have a phonetic correlate, and the properties of segments are de-
fined by their featural make-up. Since only features can make segments 
different, then, the peculiar non-phonetic status of boundary segments must 
be due to some feature. Therefore Chomsky & Halle (1968:66f) use the 
feature [±segment] in order to distinguish regular segments that have a 
phonetic realisation ([+segment]) from boundary segments that do not 
([-segment]). They are explicit on the absence of any stable phonetic corre-
late of [-segment] segments: "boundary features do not have universal pho-
netic correlates, except perhaps for the fact that word boundaries may op-
tionally be actualised as pauses" (Chomsky & Halle 1968:364).  

72 
Chap 5: SPE sets the standards for 40 years 
SPE thus practices exactly the same solution for the integration of 
diacritics into phonological vocabulary as structuralism (where, recall from 
§64, juncture phonemes were said to be realised as a "pause of brief dura-
tion or, in free variation with this, as zero"). 
 
89  2.2.2. Different types of boundaries: +, =, # 
 
SPE recognises three different boundaries: "#", "+" and "=". This contrast is 
motivated as before in structuralism: different boundaries are needed be-
cause they provoke different phonological effects. However, unlike Chom-
sky et al. (1956) and McCawley (1968), SPE does not establish any hierar-
chy among the three boundaries at hand; rather, they remain an amorphous 
set of unranked and unordered [-segment] segments (Chomsky & Halle 
1968:371). 
The three boundaries fall into two groups: + and = are "morphologi-
cal", while # is "syntactic". That is, the former are recorded in the lexicon 
together with morphemes (all and only those lexical entries that are mor-
phologically complex bear a = or a +), while # is absent from the lexicon: it 
represents information that was created online by morpho-syntactic compu-
tation. Hashmarks thus by and large reproduce the morpho-syntactic tree 
and are inserted into the phonological string by a general mapping algo-
rithm (on which more in the following section). 
The difference between + and = is one of learned (Latinate) vs. regu-
lar vocabulary: the latter only occurs with prefixes in words such as 
per=mit, de=signate, inter=dict, ad=voc+ate, con=de=scend and the like 
(Chomsky & Halle 1968:94f), while the former is the morphological de-
fault. It occurs at all morpheme boundaries within a lexical entry, as well as 
at edges, hence for example /+para+site+/. Clusters of # and + that arise 
after lexical insertion are reduced to one single # or + by convention 
(Chomsky & Halle 1968:12f, 364f). The = boundary was exotic since the 
heydays of SPE (it did not do much labour), and was rapidly abandoned 
(e.g. Siegel 1980). 
As for all other segments, the contrast among boundaries could only 
be achieved by features, and a three-way distinction requires two binary 
features. Therefore SPE introduced the distinctive features [±word bound-
ary (WB)] and [±formative boundary (FB)]. The segment #, then, is speci-
fied as [+WB, -FB], + is made of [-WB, +FB], while = identifies as 
[-WB, -FB] (Chomsky & Halle 1968:66f). Basbøll (1975:110) points out 

Translation in SPE (output: boundaries) 
73 
that the fourth logical possibility, [+WB, +FB], begs the question ± an issue 
which is not taken up by Chomsky & Halle (1968). 
 
90  2.3. The general mapping algorithm: boundaries restore (almost) full 
morpho-syntactic information 
 
In practice, then, SPE works down all the way from syntax and morphology 
to phonology. Deep syntactic structure is first converted into surface syn-
tactic structure, which serves as the input to phonology. Independently of 
lexical insertion that treats only morphemic information (through a lexical 
access), morpho-syntactic structure is converted into boundaries according 
to a fixed algorithm that works on the grounds of morpho-syntactic criteria 
alone: # is inserted into the linear string at the beginning and at the end of 
each major category (i.e. nouns, verbs and adjectives), and also on each 
side of higher constituents that dominate major categories, i.e. NPs, VPs 
and so forth (Chomsky & Halle 1968:12f, 366ff). 
The distribution of # boundaries over the linear string restores all 
morpho-syntactic information in phonology except for one particular situa-
tion: successive morphemes that belong to the same major category are not 
separated by a #. Their morpho-syntactic relationship thus remains unre-
flected in the phonology. A case in point is the root [tele+graph] under  (34) 
below: tele- and -graph being both nominal under (34b), they are left un-
separated by a # boundary in the phonological output under (34c). We will 
see in § 103 that the distribution of brackets, i.e. of cycles, is done by the 
same algorithm as the one that places # boundaries: brackets and #s are 
exactly isomorphic. 
The process of translating morpho-syntactic structure into represen-
tational objects that are then inserted into phonological representations will 
later be called mapping (§ 379). While the mapping algorithm is simple and 
identical for all languages in SPE, it will expand into a whole mapping 
component with a host of parameterised mapping rules in further develop-
ment (§ 386). 
Table  (34) below reproduces a simplified version of Chomsky & 
Halle's (1968:13) favourite telegraphic example that shows how morpho-
syntactic structure is converted into boundaries. 
 

74 
Chap 5: SPE sets the standards for 40 years 
(34) 
mapping in SPE: 
exhaustive translation of morpho-syntactic structure into linear boundaries 
 
a. morpho-syntactic and phonological representations of the sentence 
"we established telegraphic communication" 
 
b. morpho-syntactic structure and phonological terminals 
 
[S#
[NP#[N# we #]#] 
 
[VP#[V'#[V# establish #] past #] 
 
[NP#[A#[N# tele+graph #] ic#] [N#[V# communicate #] ion #]#] 
 
#] 
#] 
 
c. phonological result of the translation alone 
 
### we ##### establish # ed ## 
## telegraph # ic ### communicate # ion #### 
 
Of course, (34b) is not an actual state of the grammar; it just helps 
visualising (less well than the tree structure in Chomsky & Halle's original) 
where #s are placed in recognition of which morpho-syntactic node. This 
mechanism produces important clusters of #s, which are reduced to maxi-
mally two consecutive items by convention (see Selkirk 1972:12, 
1974:578).  
Translation in SPE thus produces a string of morphemes where the 
"syntactic distance" of two adjacent items may be read off by looking at 
hashmarks: the more of them separate two morphemes, the more distant 
they are. Finally, all boundaries that are left at the end of the phonological 
derivation are erased by convention before the output of phonology is 
shipped off to the phonetic component. 
Unlike Chomsky et al. (1956), SPE thus promotes a non-privative 
management of morpho-syntactic information. That is, all higher level divi-
sions are injected into the phonology, including those that are useless. 
These are then either erased by conventional #-cluster reduction, or transit 
phonology in order to be eliminated at the end of the derivation This raises 
the issue of economy: why should the computational system translate pho-
nologically irrelevant material into boundaries? Why should phonology 
store and carry useless objects on its back all through the phonological 
derivation? And why, finally, should additional computational effort be 
conceded in order to eliminate the irrelevant? 
Whether translation should be privative or not is a pervasive issue in 
interface theory; although not in a prominent position, it will escort the 
reader through the remainder of the historical survey. A summary is then 
provided in § 757. 

Translation in SPE (output: boundaries) 
75 
91  2.4. Readjustment 
 
We have seen that SPE translates morpho-syntactic structure into bounda-
ries, that is into vocabulary that can be parsed by the phonology. Most of 
the time, the equivalence is one-to-one, and an invariable mapping algo-
rithm carries out the translation; nothing more needs to be said in this case. 
Sometimes, however, (translated) syntactic surface structure does not 
qualify as the input for phonological interpretation: it needs to be modified 
(readjusted) before phonology can make use of it. 
 
(35) 
"We have two concepts of surface structure: input to the phonological com-
ponent and output of the syntactic component. It is an empirical question 
whether these two concepts coincide. In fact, they do coincide to a very 
significant degree, but there are also certain discrepancies. These discrepan-
cies [«] indicate that the grammar must contain certain rules converting the 
surface structures generated by the syntactic component into a form appro-
priate for use by the phonological component. In particular, if a linguistic 
expression reaches a certain level of complexity, it will be divided into suc-
cessive parts that we will call 'phonological phrases', each of which is a 
maximal domain for phonological processes. [«] 
It appears that the syntactic component of the grammar generates a surface 
structure Σ which is converted, by readjustment rules that mark phonologi-
cal phrases and delete structure, to a still more superficial structure Σ'. The 
latter then enters the phonological component of the grammar." Chomsky & 
Halle (1968:9f) 
 
This quotation contains a good deal of what will be at the forefront 
of interface discussion in the 80s when Prosodic Phonology (§ 360) is de-
veloped. In the environment of SPE, the proviso introduced is that transla-
tion always inserts boundaries into the phonological string, but that these 
boundaries may represent syntactic surface structure (in most cases), or a 
readjusted version thereof (exceptionally). 
The reason for readjustment is the same as for what will be called 
Indirect Reference in Prosodic Phonology later on (§§378,406): the exis-
tence of cases where phonology obviously relies on a constituent structure 
that is different from the morpho-syntactic output. This pattern is called 
non-isomorphism in Prosodic Phonology (see §§ 416ff). The quote below 
shows how it was introduced in SPE on the grounds of the cat-rat-cheese 
example. 
 

76 
Chap 5: SPE sets the standards for 40 years 
(36) 
"Consider, for example, sentences such as (124), where the three bracketed 
expressions are the three noun phrases in the predicate: 
 
(124) This is [the cat that caught [the rat that stole [the cheese]]] 
 
Clearly, the intonational structure of the utterance does not correspond to the 
surface structure in this case. Rather, the major breaks are after cat and rat ;
that is, the sentence is spoken as the three-part structure this is the cat ± that 
caught the rat ± that stole the cheese. This effect could be achieved by a 
readjustment rule which converts (124), with its multiply embedded sen-
tences, into a structure where each embedded sentence is sister-adjoined in 
turn to the sentence dominating it. The resulting structure appears then as a 
conjunction of elementary sentences (that is, sentences without embed-
dings). This allows us to say that intonation breaks precede every occur-
rence of the category S (sentence) in the surface structure and that otherwise 
the ordinary rules prevail." (emphasis in original) Chomsky & Halle 
(1968:371f) 
 
Chomsky & Halle thus suggest to dis-embed the cat-rat-cheese sen-
tence: the constituent structure that syntax has produced ([the cat that 
caught [the rat that stole [the cheese]]]) is readjusted so that three sister 
nodes are created: [[the cat] [that caught the rat] [that stole the cheese]]. 
Note that readjustment and mapping into boundary structure are two differ-
ent things: the former manipulates brackets, not boundaries, and takes place 
before mapping translates brackets into boundaries. Phonology then uses 
the readjusted and translated structure. 
Finally, due mention needs to be made of the fact that readjustment is 
an unpredictable distortion of the original morpho-syntactic structure. That 
is, the content and behaviour of the readjustment component is idiosyn-
cratic: it does not depend on either morpho-syntax or phonology. In the 80s, 
Prosodic Phonology will reproduce the SPE architecture one-to-one, in-
cluding the readjustment component and its unpredictable action (see 
§380). 
 

Translation in SPE (output: boundaries) 
77 
92  2.5. Affix classes and their representational management 
 
93  2.5.1. Rule-blocking boundaries (stress-shifting affixes) 
 
Chomsky & Halle (1968) were aware of the fact that English has two affix 
classes: SPE is the source of this empirical generalisation. Its most promi-
nent effect is the (non-)bearing of affixes on stress placement. This is iden-
tified as follows in SPE. 
 
(37) 
"Alongside of the affixes that affect stress placement [«], there are other 
'neutral affixes' which characteristically play no role in the placement of 
stress, for example, the adjective-forming affixes -y, -like, -able, -ish and 
affixes such as -ing, -past tense, -hood, -ness, -ly, -wise. We can indicate the 
fact that an affix is neutral by making use of the # boundary." Chomsky & 
Halle (1968:84) 
 
For Chomsky & Halle, the challenge raised by this situation is to 
make sure that the Main Stress Rule (which shifts stress one vowel right 
upon every concatenation of a suffix, i.e. on every cycle) does not apply to 
strings that contain stress-neutral affixes. Stress-shifting affixes, on the 
other hand, are regular in regard of the Main Stress Rule. 
As shown by the quote, the solution adopted is representational: 
stress-neutral affixes (also called class 2) come with a #, while stress-
shifting affixes (class 1) are only equipped with a + boundary. The Main 
Stress Rule, then, is supplied with a proviso in prose which says that the 
rule can apply only to strings where no # boundary is found (Chomsky & 
Halle 1968:85). This makes sure that the application of the Main Stress 
Rule is blocked when it applies to [root # affix] (class 2 strings). 
Hence in [[parent] #hood], the Main Stress Rule assigns stress to the 
first vowel on the initial cycle, i.e. [párent], but cannot shift stress any fur-
ther to the right on the second cycle although the structural description is 
met: -hood comes with a # boundary, which thus occurs in the middle of the 
second cycle [párent # hood]. Therefore the Main Stress Rule is blocked, 
and the output of the derivation is párent-hood. By contrast, the stress-
shifting suffix -al (class 1) comes with a + boundary. The Main Stress Rule 
being insensitive to +, it also applies on the second cycle of [[parent] +al] 
and hence shifts stress one vowel right, which produces parént-al.

78 
Chap 5: SPE sets the standards for 40 years 
94  2.5.2. Rule-triggering boundaries (stress-neutral affixes) 
 
The same lexically encoded contrast also accounts for all other affix class-
based phenomena. The strategy is always the same: phonological rules are 
made sensitive to #, which either blocks or triggers the process at hand. 
This distinction corresponds exactly to Kenstowicz & Kisseberth's (1977, 
1979) typology of morphological impact on phonological processes that 
was introduced in § 51: morpho-syntactic divisions may be rule-blocking or 
rule-triggering. We have seen how # blocks stress assignment in SPE; all 
other cases of rule-blocking boundaries (which will be encoded as level 1 
rules in Lexical Phonology) work along the same lines. 
Rule-triggering boundaries (level 2 rules in Lexical Phonology), on 
the other hand, appear in the structural description of rules: the processes at 
hand only go into effect if the string contains the boundary. English features 
three processes of this kind, all of which control the simplification of a 
stem-final cluster that contains a nasal: gn-n (sign, sign-ing2
vs. 
sign-ature1), mn-n (damn, damn-ing2 vs. damn-ation1), mb/ŋg-m/ŋ (sing,
sing-ing2 vs. long-er1, bomb, bomb-ing2 vs. bomb-ard1). 
Chomsky & Halle (1968:85) point out that "the inflectional affixes 
which are neutral with respect to stress also characteristically affect final 
clusters in the same way as word boundary does." That is, cluster simplifi-
cation occurs word-finally and before stress-neutral (i.e. class 2) affixes. 
This disjunction is good reason indeed to suppose that the identity of stress-
neutral (class 2) affixes is to bear a # boundary: whatever the identity of the 
right edge of the word, it must also characterise stress-neutral (class 2) af-
fixes. 
In practice, then, the rule that is responsible for the gn - n alternation 
for example will be as follows: g →ø / __n #. The velar in [sign#] and 
[sign#ing], but not in [sign+ature], is thus deleted. An additional benefit is 
that the rule blocks deletion morpheme-internally, where all of the clusters 
mentioned systematically survive: ignore, amnesia, finger.
The inventory of affix class-based phenomena that are found in Eng-
lish will be introduced with greater care in §§ 162f, 166: their analysis is 
foundational for Lexical Phonology. For the time being, it is enough to bear 
in mind that they enjoy an entirely representational analysis in SPE. 
 

Translation in SPE (output: boundaries) 
79 
95  2.6. Labelled brackets 
 
96  2.6.1. How brackets and labels are used in the phonology: bláckboard vs. 
black bóard 
SPE also makes constant and crucial use of brackets which indicate mor-
pho-syntactic constituent structure. Consider under  (38) below the contrast 
between the noun blackboard and the NP black board that Chomsky & 
Halle (1968:16) propose (the notation is theirs). 
 
(38) 
cohabitation of brackets and boundaries in SPE 
 
a. bláckboard 
 
[N# [A# black #]A [N# board #]N #]N
b. black bóard 
 
[NP# [A# black #]A [N# board #]N #]NP 
The only difference is the morpho-syntactic label of the outermost 
constituent, i.e. N for blackboard, NP for black board. This contrast is re-
flected in the phonology by different stress contours: the noun has initial 
stress (bláckboard), while the NP is stressed on the second element (black 
bóard). Based on  (38), which is the input to phonological computation, 
Chomsky & Halle (1968:16f) derive this contrast by the cyclic application 
of the following three rules.19 
(39) 
compound and nuclear stress rule 
 
a. stress assignment 
in monosyllables, the vowel receives primary stress. 
 
b. compound rule 
assign primary stress to a primary-stressed vowel in the context 
__...Vˊ «]N
c. nuclear stress rule 
assign primary stress to a primary-stressed vowel in the context 
Vˊ «__...]NP 
Based on  (38), the derivation now proceeds from inside out, i.e. by 
applying phonology to all domains that are identified by brackets, starting 
with the most embedded domain and moving outwards. When the deriva-
 
19 For the sake of exposition, Vˊ indicates primary stressed, Vˋ secondary stressed 
vowels (instead of the integer-superscripts of SPE). Further distinctions that are 
made in SPE (3-stress, 4-stress) are irrelevant for the discussion. 

80 
Chap 5: SPE sets the standards for 40 years 
tion moves on to larger domains, inner (old) brackets are erased. This pro-
cedure is called the transformational cycle in SPE and will later be known 
as the phonological cycle, or simply as cyclic spell-out (or cyclic deriva-
tion). This concept is introduced at greater length in § 100 below. 
In the respective inner domains, then, only (39a) is applicable. After 
the erasure of inner brackets, the result is as under  (40) below. 
 
(40) 
intermediate representations 
 
a. bláckboard 
 
[N# # bláck # # bóard # #]N
b. black bóard 
 
[NP# # bláck # # bóard # #]NP 
All vowels have thus been assigned primary stress. The rules under 
 (39) now reapply to the outer domain, and this time (39b) and (39c) are 
applicable: given the explicit mention of N and NP in their structural de-
scription, the former applies to the noun (but not to the NP), while the latter 
transforms the NP (but not the noun). Chomsky & Halle then recur to a 
stress demotion convention which avoids that a given domain contains 
more than one primary stress: "when primary stress is placed in a certain 
position, then all other stresses in the string under consideration at that 
point are automatically weakened by one" (Chomsky & Halle 1968:16f). 
The application of (39a,b) and this convention, then, produces the correct 
result: bláckboard and black bóard.
97  2.6.2. Brackets and boundaries are (not) redundant: compensation vs. 
condensation 
The derivation shown in the preceding section is but an example of how 
SPE works in general: phonological derivations have (almost) complete 
and constant access to both morpho-syntactic structure (brackets) and mor-
pho-syntactic labels (N, NP etc.). 
Brackets are needed in order to run cyclic derivation: in their ab-
sence, embedded domains could not be identified. At the same time, having 
phonological rules refer to morpho-syntactic labels is the easiest way of 
making phonology sensitive to the nature of morpho-syntactic nodes when 
these are phonologically relevant (as in the case of bláckboard vs. black 
bóard). 
Two questions arise when looking at this setup: why is morpho-
syntactic structure translated into boundaries with rules making reference to 

Translation in SPE (output: boundaries) 
81 
the output of the translation (rather than to the original structure)? This 
seems superfluous given that morpho-syntactic labels can be made direct 
reference to. Second, given that brackets and # boundaries are exactly iso-
morphic (see § 90), isn't the double translation of morpho-syntactic structure 
into both redundant? If phonology has (almost) full access to constituent 
structure via brackets, what are boundaries and their complicated transla-
tional mechanism good for? 
Chomsky & Halle (1968:370f) are explicit on the fact that brackets 
and boundaries are not the same thing. The difference boils down to the fact 
that the former are hard-wired, while the latter are ordinary ([-segment]) 
segments which for this reason can be freely manipulated by phonological 
rules: # can be erased or transformed into + by rule (see § 112). By contrast, 
brackets are invisible and untouchable for phonological computation: they 
may not appear in either the structural change or the structural description 
of rules. Also, they can only be modified by readjustment, which is done 
prior to phonological action. The only thing that brackets do is to guide the 
derivation along the embedded morpho-syntactic structure. Chomsky & 
Halle are explicit on this. 
 
(41) 
"In our treatment, boundaries are units in a string, on a par in this sense with 
segments. Like segments, each boundary is a complex of features. Bounda-
ries function rather differently from the various types of constituent markers 
(labelled brackets) that play a role in determining the application of the 
phonological rules of the transformational cycle." Chomsky & Halle 
(1968:371) 
 
Chomsky & Halle (1968:370) also call on an example in order to 
show that the distortion which is introduced by an eventual rule-triggered 
deletion of boundaries makes brackets the only visible trace of morpho-
syntactic structure ("there are instances where word boundaries must be 
deleted but constituent structure maintained", Chomsky & Halle 1968:370). 
The two words compensation and condensation (a pair which is often 
quoted up to the present day, and on which more in § 547) look much the 
same at first sight. However, the second vowel of the former, but not of the 
latter, may be reduced to schwa. Chomsky & Halle (1968:39, 370) point 
out that this correlates with a contrast in the derivational history of the two 
words: while condensation is derived from the verb to condénse, there no 
such thing as *to compénse. Rather, compensation is derived from to com-
pensáte, which means that the two nouns do not bear the same suffix: con-
dens-ation vs. compensat-ion. Their respective structure is thus as under 
 (42) below. 

82 
Chap 5: SPE sets the standards for 40 years 
(42) 
condensation vs. compensation 
 
a. condensation 
 
[N# [V# condens #]V at+ion #]N
b. compensation 
 
[N# [V# compensat #]V ion #]N
Therefore, on the inner cycle, [condéns] receives stress on the second 
vowel (counting from the left margin), while [compensát] is stressed on the 
third vowel. According to Chomsky & Halle, this is the reason why the 
reduction of the e is blocked in condensátion: the vowel was stressed on an 
earlier cycle and is therefore protected. This is not the case for compen-
sátion, whose second vowel has never been stressed. 
Crucial for this analysis is the independent interpretation of the inner 
cycle of [#[#condens#] at+ion#]. The relevant chunk is identified by brack-
ets, but also by boundaries. Chomsky & Halle (1968:370) point out that the 
latter, however, cannot do the job of delineating the inner cycle since the 
right boundary of [#condens#] must be erased. This is because of stress, 
which shifts to the right on the outer cycle: -ation is a stress-shifting (class 
1) suffix. In SPE, the difference between stress-shifting (class 1) and stress-
neutral (class 2) affixes is that the latter, but not the former, come with a # 
boundary (see § 92). This means that the # boundary, which was initially 
inserted between the root and -ation, must be deleted by rule: otherwise 
stress would not shift, and *condéns-ation would be derived. After the 
elimination of the boundary, however, boundary structure cannot identify 
the inner cycle anymore. Therefore, Chomsky & Halle (1968:370) argue, 
"there are instances where word boundaries must be deleted but constituent 
structure maintained."  
Now it could be argued that boundary erasure takes place only after 
the boundary has served for cycle identification, i.e. once the inner cycle 
has been processed. As far as I can see, this option is not considered by 
Chomsky & Halle (1968:370), who merely state that "the elimination of 
internal # [«] can be taken care of by a lexical rule which will be auto-
matic with these and various other affixes and which will affect the bound-
ary but not the constituent structure." 
Be that as it may, the fact is that SPE deliberately organises a twofold 
representation of morpho-syntactic structure in phonology: in terms of 
brackets and in terms of boundaries. 
 

Translation in SPE (output: boundaries) 
83 
98  2.6.3. Brackets and interactionism 
 
In sum, SPE provides for a hard-wired and a soft representation of morpho-
syntactic structure. Boundaries are a perfect incarnation of the modular 
idea: they represent morpho-syntactic information that was translated into 
regular phonological vocabulary by a mapping mechanism, and they do not 
carry any labels: the only thing that they inject is the geometric structure of 
the morpho-syntactic tree. 
Labelled brackets, on the other hand, are modularity offenders: they 
give full and permanent access to morpho-syntactic structure and labels, 
that is to objects that are non-phonological in kind and have not been trans-
lated. 
As was pointed out earlier (§ 97), however, phonological computation 
(rules) cannot make reference to brackets, whereas they are able to refer to 
their labels, and also to boundaries. Access to morpho-syntactic structure 
and labels is thus organised by two distinct objects of the linear string: 
boundaries provide the former, while brackets carry the latter information. 
We have seen that Chomsky & Halle are also explicit on the fact that 
the only labour which is done by brackets is to identify relevant chunks for 
cyclic derivation. In other words, brackets seem to be representational ob-
jects, but they serve the purpose of organising the procedural communica-
tion with phonology. Hence they somehow representationalise the proce-
dural channel. 
Given the modern vantage point, one may ask whether SPE really 
means that brackets are present in the phonological string when they 
graphically appear in the midst of segments. They could also be used in a 
metaphorical sense, i.e. as a shorthand notation for morpho-syntactic struc-
ture which is still accessible, and along which spell-out moves. 
What exactly, then, is the difference between modern derivation by 
phase (Chomsky 2000a et passim, § 304) and SPE-style cyclic spell-out? 
Could the SPE mechanism just be shorthand for the modern idea of multi-
ple spell-out where successive pieces of the morpho-syntactic tree are 
shipped off to interpretation? The answer, I think, is yes in principle: noth-
ing in the architectural setup needs to be changed in order to eliminate 
brackets from the linear SPE-string, interpreting them as successive phases. 
But this is true only in principle ± in practice, the plugin to the inverted T 
model according to which phonology applies only once the morpho-
syntactic derivation is complete (§ 86) stands in the way. 
In other words, interactionism is the bone of contention. We will see 
in § 146 that Lexical Phonology introduces the idea that morphology and 

84 
Chap 5: SPE sets the standards for 40 years 
phonology are interleaved: first you concatenate some pieces, then you 
interpret them, then you add some more pieces, then you interpret the new 
string and so on. The inverted T model as introduced in § 86 is incompatible 
with interactionism; we will see that this is the major argument that Halle & 
Vergnaud (1987a) use against Lexical Phonology in their attempt to restore 
SPE in the environment of the 80s (§ 222). 
Since Epstein et al. (1998:46ff), Uriagereka (1999) and Chomsky 
(2000a et passim), however, and for reasons that have got nothing to do 
with phonology, generative grammar has become interactionist: the in-
verted T model is still in place, but the additional proviso that the complete 
morpho-syntactic derivation must be achieved before phonology can run is 
abandoned (§ 304). A summary of the issue involving brackets and interac-
tionism is provided in § 672. 
 
99  2.6.4. Modularity and modularity offenders in SPE 
 
Let us now look at SPE's ambiguous relationship with modularity. On the 
one hand, the generative architecture of grammar (the inverted T, § 86) is an 
application of modularity to language. Also, Chomsky & Halle have a typi-
cally modular conception of phonological computation (see the quote in 
§84 and compare with the description of modular activity in the Interlude 
§586).Finally, like its structuralist predecessor, SPE provides for translation 
(of morpho-syntactic structure into phonological boundaries), and transla-
tion is a necessary consequence of modularity (domain specificity: modules 
do not speak the same language). 
Another fundamental property of SPE, however, is a strong modular-
ity offender: labelled brackets. Brackets are phonological aliens (unlike 
boundaries, they are invisible for rules because they are non-segments) and 
therefore should not be able to be parsed by the phonological component. 
However, phonology must somehow take brackets into account when proc-
essing the linear string: this is the only way to know how cycles are deline-
ated. It was mentioned in the previous section that SPE may probably re-
ceive an interactionist interpretation from hindsight, in which case brackets 
disappear and the inverted T is fully compatible with modularity (see 
§680). 
This does not do away with the even more offending property of 
brackets to be labelled, though: rules can make direct reference to untrans-
lated morpho-syntactic labels (N, V, NP etc.). This should be excluded in a 

The phonological cycle and one single phonology 
85 
modular environment since phonology cannot parse this kind of alien vo-
cabulary. 
In sum, SPE certainly sensed modularity and applied its major con-
sequence, translation, "intuitively". That is, there is no explicit discussion 
of the matter in SPE: modularity as such remains unnamed and undefined; 
and it is violated by a central device of the theory, labelled brackets. Only 
in the 80s will the reference to untranslated morpho-syntactic information 
and especially to morpho-syntactic labels be explicitly prohibited under the 
header of Indirect Reference (§§ 377, 406) ± but even then without explicit 
mention of modularity as such (§ 414). 
 
100  3. The phonological cycle and one single phonology 
 
101  3.1. The phonological cycle 
 
102  3.1.1. Cyclic derivation: how it is motivated and how it works 
 
The phonological cycle is a hallmark of generative phonology: it runs 
through the entire literature from the earliest contribution until the most 
recent versions of minimalism where it appears in the guise of phase theory. 
In actual fact, the idea that there is a procedural communication between 
morpho-syntax and phonology is only carried into linguistic thinking by the 
generative approach: since the 19th century, this option had never been con-
sidered. The introduction of cyclic derivation thus creates what I call Inter-
face Dualism (see § 683 for a summary): it adjoins a procedural channel to 
the traditional representational channel of communication. 
Cyclic derivation was introduced in Chomsky et al. (1956:75) as a 
local (and nameless) algorithm for the derivation of stress (see § 80). In the 
60s, the generative architecture of grammar in form of the inverted T model 
was developed (§ 86). In this environment, SPE makes cyclic derivation the 
general mechanism that controls the communication between morpho-
syntax and phonology/semantics. 
While cyclic derivation is referred to as the Transformational Cycle 
in SPE, it is better known as the phonological cycle in the 70s and the 80s 
(a label that is due to Mascaró 1976, see § 189). Today, the same principle 
has reincarnated as derivation by phase (Chomsky 2000a et passim), an 
important tool at the forefront of the minimalist programme (§ 549). 
The following quote illustrates the general value that Chomsky & 
Halle grant to cyclic derivation. 

86 
Chap 5: SPE sets the standards for 40 years 
(43) 
"Investigation of English and other languages confirms this expectation and 
permits us to formulate the principle of the transformational cycle in full 
generality, applying to all surface structure whether internal or external to 
the word." Chomsky & Halle (1968:27) 
 
The cyclic interpretation of the string that is submitted to the phonol-
ogy proceeds step by step from inner domains outwards. SPE offers the 
following description. 
 
(44) 
"Regarding a surface structure as a labeled bracketing [«], we assume as a 
general principle that the phonological rules first apply to the maximal 
strings that contain no brackets, and that after all relevant rules have applied, 
the innermost brackets are erased; the rules then reapply to maximal strings 
containing no brackets, and again innermost brackets are erased after this 
application; and so on, until the maximal domain of phonological processes 
is reached." Chomsky & Halle (1968:15) 
 
Chomsky & Halle (1968) insist on the fact that the phonological cy-
cle expresses a natural and intuitive generalisation. 
 
(45) 
"Notice, once again, that the principle of the transformational cycle is a very 
natural one. What it asserts, intuitively, is that the form of a complex ex-
pression is determined by a fixed set of processes that take account of the 
form of its parts." Chomsky & Halle (1968:20) 
 
Illustration of how cyclic derivation works was already provided in 
§§ 96f (bláckboard vs. black bóard, compensation vs. condensation). De-
spite its generalization to the entire grammar in further development, the 
intimate relationship that cyclic derivation entertains with stress should be 
borne in mind: the very idea was born in Chomsky et al. (1956:75) on the 
basis of English stress, and only rules related to stress placement are cyclic 
in SPE. 
 
103  3.1.2. Cycles are defined like boundaries: by major categories (N,V,A) 
 
It is important for SPE (but not for more recent models of cyclic derivation 
such as Distributed Morphology, see § 550) that the result of every cycle is 
an actual word which may be pronounced and has a meaning.  
Hence the word theatricality that Chomsky & Halle (1968:88f) dis-
cuss is made of five morphemes that are distributed over three cycles: 
[[[theatr]N ic + al]A i + ty]N. The delineation of cycles follows the distribu-

The phonological cycle and one single phonology 
87 
tion of # boundaries: it is determined by major categories. Recall from § 90 
that nouns, verbs and adjectives as well as projections thereof are flanked 
by # boundaries in phonology. The output of each cycle, then, is an actual 
word: théatre, theátr-ic-al, theatr-ic-al-i-ty.
As far as I can see, the fact that brackets (i.e. cycles) only delineate 
transitions between major categories is not made explicit in SPE. Examples 
like theatricality, however, show that successive morphemes that belong to 
the same major category are not separated by brackets. The # boundary and 
brackets are thus exactly isomorphic (at a certain point in the derivation: 
right after translation, i.e. before eventual rule-governed modifications of 
boundaries, see §§ 97, 112).  
As a consequence, the restoration of morpho-syntactic structure in 
phonology is only almost complete: transitions between morphemes that 
belong to the same major category remain invisible ± invisible in terms of 
#s and brackets; they are of course marked by the default boundary + that 
accompanies every morpheme. 
 
104  3.2. Word-level rules and the unity of phonological computation 
 
105  3.2.1. Cyclic vs. word level rules 
 
Cyclic derivation along the transformational cycle concerns all pieces of a 
linguistic derivation, from the most embedded morpheme up to the largest 
syntactic unit. SPE is explicit on the fact that there is no difference between 
morphemes and words: "the principle of the transformational cycle [«] 
appl[ies] to all surface structure whether internal or external to the word" 
(Chomsky & Halle 1968:27). 
This notwithstanding, SPE distinguishes between two kinds of rules: 
cyclic rules20 and rules of word-level phonology.21 Rather than an expres-
sion of a theoretical premise, this contrast is acknowledged because it is 
necessary for the analysis of English that SPE proposes. For example, un-
stressed vowels are reduced to schwa by a context-free rule ± rule (103) in 
the quotation below. Chomsky & Halle (1968) explain why the Vowel Re-
duction Rule cannot apply to individual morphemes or clusters thereof that 
 
20 Which at that time were called cyclical, just as syntactic was syntactical. 
21 This distinction actually shapes the architecture of SPE: chapter three is called 
"The transformational cycle in English phonology", while chapter four is enti-
tled "Word-level phonology". 

88 
Chap 5: SPE sets the standards for 40 years 
do not make a word: it must apply at the word level, i.e. after all mor-
phemes have been concatenated. 
 
(46) 
"We see at once, incidentally, that the Vowel Reduction Rule cannot itself 
be cyclical. Once a vowel has been subject to rule (103) [the Vowel Reduc-
tion Rule], its original underlying form is unrecoverable. Therefore, if this 
rule were to apply at any point in the first cycle, for example, certain vowels 
will be reduced to [ə] even though in some later cycle they may receive 
primary stress. Evidently, rule (103) must apply only after the process of 
stress assignment within the word is complete. Within our framework, this 
means that the rule of Vowel Reduction is restricted to the level of word 
boundaries." Chomsky & Halle (1968:113) 
 
Hence vowel reduction must not apply to the inner cycle of 
[[parent] al] since this would reduce the /e/ to schwa (main stress falls on 
the /a/). This /e/, however, will end up being stressed on the outer cycle 
(parént-al), and thus must not be reduced (stressed vowels are never 
reduced). The insight behind the prohibition of vowel reduction to apply to 
chunks that are smaller than the word is simply that vowel reduction is a 
function of word stress, and hence must "wait" until the last morpheme is 
considered for the assignment of word stress. 
Word level rules thus do not apply to chunks that are smaller than a 
word ± but they do not apply to chunks that are bigger than a word either. 
 
(47) 
"The Vowel Reduction Rule (103), cannot be permitted to apply cyclically 
beyond the level of word boundary. [« It] must apply only once in the 
course of a derivation; within our framework this means that [it] must be [a] 
noncyclical rule restricted to the level of word boundary." Chomsky & Halle
(1968:133f) 
 
This is because stress is further manipulated above the word level, 
i.e. in intonation (sentence/phrasal stress), but this never leads to vowel 
reduction. The decision which vowels are reduced is taken at the word 
level, no matter how much stressed vowels may be weakened by intonation 
later on. 
Word-level rules thus apply exactly once in a derivation ± when 
words are completed: they do not affect either smaller or bigger chunks. 
The definition of word-level rules is thus evidently procedural: they apply 
to a certain chunk in the course of cyclic derivation. Curiously enough, 
though, their implementation is representational in SPE: given the general 
mapping mechanism that translates syntactic surface structure into clusters 

The phonological cycle and one single phonology 
89 
of hashmarks (§ 90), the word is defined as a string that is preceded and 
followed by ##. 
 
(48) 
"The surface structure specifies that each word constitutes a stage of the 
transformational cycle. By a word, we mean an element of the form ##...##, 
where « contains no occurrence of ##. [«] A rule restricted in application 
to contexts meeting this condition is what we call a rule of word phonology. 
Evidently, such rules will not reapply at successive stages of the transforma-
tional cycle, even if interspersed freely among the cyclic transformational 
rules." Chomsky & Halle (1968:163) 
 
Chomsky & Halle are certainly right in pointing out that the restric-
tion of word level rules to this context produces the desired effect. The 
question, however, is whether a representational disguise of a procedural 
event is warranted. 
 
106  3.2.2. SPE is representational: class 1 vs. class 2, cyclic vs. word-level 
rules 
 
Just as for word-level rules, SPE proposes a representational identification 
of the contrast between class 1 and class 2 affixes. Recall from § 92 that the 
former come with a + boundary, while the latter are identified by a # 
boundary. The heart of Lexical Phonology will be to replace this represen-
tational management of affix classes by a procedural solution where class 1 
affixes are concatenated (and interpreted) before class 2 affixes. This sup-
poses the existence of distinct mini-phonologies (one set of rule for the 
assessment of class 1 strings, another set of rules for the interpretation of 
class 2 strings, see § 148). 
In the 80s when the scene will be dominated by Lexical Phonology, 
Halle & Vergnaud (1987a) undertake the restoration of the SPE-setup. 
However, they follow the procedural trend of the 80s: just like the distinc-
tion between affix classes, the implementation of word-level rules will be 
procedural (in terms of a distinct block of so-called non-cyclic rules, see 
§233). 
Finally, it should be borne in mind that SPE's word-level rules do not 
recover the same notion as what will be known as postlexical rules in Lexi-
cal Phonology; also, the SPE-supported contrast between cyclic and word-
level rules does not correspond to either the distinction between level 1 and 
level 2 rules, or to the opposition between lexical and postlexical rules. 
Rather, it reappears in the 80s under the label of post-cyclic lexical rules 

90 
Chap 5: SPE sets the standards for 40 years 
(Lexical Phonology, see § 194) or the aforementioned non-cyclic rules 
(Halle & Vergnaud, see §§ 233, 236). 
 
107  3.2.3. SPE's representationalism maintains the unity of one single 
computational system 
 
It is argued below that the major conceptual division among interface theo-
ries on the procedural side is between those that work with multiple mini-
phonologies and those where all strings are assessed by the same computa-
tional system (see § 828). A number of other properties (such as the exis-
tence of a no look-back device, today called Phase Impenetrability) depend 
on this initial choice. 
It is therefore important to be explicit on the situation in SPE: Chom-
sky & Halle use one single set of phonological rules that assesses all 
strings, no matter what their size. The last quote in § 105 shows that word 
level rules are not set apart from cyclic rules in either formulation or loca-
tion: both types of rules are interspersed in the unique sequence of ordered 
rules that is active in SPE. 
That is, the unity of the computational system is achieved by a repre-
sentational (rather than a procedural) identification of word-level rules (a 
string is a word iff it is enclosed in ##...##). This definition will be aban-
doned by Halle & Vergnaud's (1987a) incarnation of the architecture of 
SPE, where cyclic and word-level rules are separate computational systems 
(§ 233). 
 
108 
4. Conclusion 
 
About all major issues of interface theory are discussed in SPE: Chomsky 
& Halle define the benchmarks for further development which, as we will 
see, make the research agenda up to the present day. 
SPE installs representational and procedural communication with 
morpho-syntax, organises translation, raises the question of readjustment 
and direct reference to untranslated morpho-syntactic categories, introduces 
affix class-based phenomena and analyses them according to a strictly rep-
resentational line of attack, argues for a specific word-level phonology, but 
couches its existence in the unique computational system that the theory 
provides for. 

Conclusion 
91 
Finally, SPE also contains the seeds of modularity, which however 
remains unspoken and undefined as an architectural principle of grammar: 
the conception of the computational system as an ignorant and autistic ro-
bot, the inverted T model, readjustment and the organisation of translation 
are the fruit of modular thinking. However, modularity is also violated: 
brackets and the checkless reference to their labels are non-modular ele-
ments of the theory, which did not raise any objection. We will see how the 
modular idea wins more conscious recognition in generative theory in the 
80s as we go along (§ 406). 
 


Chapter 6 
109  The life of boundaries in post-SPE times 
110 
1. Introduction: overview until the 80s 
 
Let us now look at the use that was made of linear boundary symbols in 
SPE itself as well as in the subsequent development of generative phonol-
ogy. 
The leading idea of the following pages is to document the growing 
dissatisfaction and frustration as boundaries were put to use during the 70s, 
and to identify the reasons for this development. Foremost among these is 
the fact that, just like on the segmental side, SPE does not impose any re-
strictions on the occurrence of boundaries (except that they must coincide 
with a morpho-syntactic division). Parallel to the development on the seg-
mental side, this gave rise to boundary abuse and a whole boundary zoo 
(§ 116). 
Reactions on this situation were numerous, both from inside and out-
side the SPE paradigm; they were also embedded in the general critique of 
SPE that ran through the 70s under the header of the abstractness debate 
and gave rise namely to Natural Generative Phonology, the external chal-
lenger of SPE (§§ 119, 124). 
This movement culminates in an article by Pyle (1972), who prop-
erly demonstrates that boundaries are unsuited for carrying morpho-
syntactic information: they are supposed to be segments but do not behave 
as such. That is, their diacritic identity is merely hidden behind the 
[-segment] delusion. "Culminating" in this context of course means logi-
cally culminating, since Pyle's demonstration of the bankruptcy of bounda-
ries was available as early as 1972 ± but had no significant echo. 
Another function of this chapter is to provide an outlook on the lead-
ing issues of the 80s. In fact, the scene that will be the background of Lexi-
cal Phonology and Prosodic Phonology is set in the 70s: at least as far as 
the representational side of the interface is concerned, all relevant questions 
are already asked, and all possible answers given. The 80s, then, just select 
proposals according to new theoretical premises (GB, modularity), and 
work out what was seeded. 
One case in point is the question whether morpho-syntactic interven-
tion should be local (boundaries) or domain-based (the domains of the Pro-
sodic Hierarchy). This issue was introduced by McCawley (1968) (§ 113); it 

94 
Chap 6: The life of boundaries in post-SPE times 
will be critical when Elisabeth Selkirk sets up Prosodic Phonology (§ 373) 
in the early 80s (although very quickly nobody will remember this debate 
anymore). Local vs. non-local intervention will come back to the focus of 
interest in § 706 below. 
Another case is what will be known as direct syntax approaches in 
the 80s, i.e. the main competitor of Prosodic Phonology. This perspective 
dispenses with the translation of morpho-syntactic structure into phono-
logical objects altogether. Instead, phonological rules are favoured that 
make direct reference to morpho-syntactic material. Direct syntax ap-
proaches were erratically voiced on several occasions in the 70s without 
reference to each other (§§ 123, 132, 137); but in all cases that I have come 
across, they were the result of the frustration that boundaries generated: if 
boundaries cannot do the job, they have to go, and so has thus translation. 
Translation itself is poorly understood in the 70s, because it is poorly 
studied, both theoretically and empirically. Its place in the overall interface 
architecture is vague (§ 131), and we encounter first frustrated comments on 
the mapping puzzle (§ 111). These two issues will be central targets of Pro-
sodic Phonology, which affords substantial progress regarding the former 
(§ 377), and at least the most serious empirical effort to date regarding the 
latter (§§ 387, 392f, 396). Summaries concerning translation and the mapping 
puzzle are available in § 687 and § 753, respectively. 
 
111  2. The mapping puzzle: alas, there are no natural classes of boundaries 
 
Since boundaries root in morpho-syntactic divisions, linguists have tried to 
find out which particular morpho-syntactic (or semantic) configuration 
produces a phonological effect. And in turn, which phonological effects are 
induced by boundaries. 
That is, some pattern should emerge as empirical coverage and rele-
vant studies grow: either for a given language, but even more plausibly on a 
cross-linguistic count. It can hardly be imagined that the correlation be-
tween morpho-syntactic causes and phonological effects is arbitrary. 
This is what I call the mapping puzzle, following the terminology of 
Prosodic Phonology where the process of translation from morpho-syntax 
to phonology is called mapping (see § 380). In the post-SPE environment 
where boundaries are the interface currency, trying to come to grips with 
the mapping puzzle amounts to looking for natural classes of boundaries. 
That is, for a set of boundaries that share phonological behaviour cross-
linguistically and also have a stable morpho-syntactic identity. 

Boundary mutation rules 
95 
I have only come across relatively few instances in the literature of 
that period where this issue is discussed: Kenstowicz & Kisseberth 
(1977:103ff), Basbøll (1975:121ff, 1978a:165f) as well as Devine & 
Stephens (1976, 1980). True, the empirical basis was anecdotic and vanish-
ingly small at that time, but there is hardly any less frustration today after 
an important descriptive effort during the 80s and early 90s (due to Pro-
sodic Phonology, § 463) than there was in post-SPE times. 
This is to say that the mapping puzzle has timidly emerged when in-
terface was done with boundaries. It appeared for the first time in the dis-
cussion of Trubetzkoy's Grenzsignale (§ 57), and will run through the rest of 
the historical survey (§§ 387, 392f, 396, 463). Unfortunately, though, at the 
end of the book mapping will remain as mysterious as it was in the 70s (see 
the summary in § 753). 
 
112  3. Boundary mutation rules 
 
So-called boundary mutation rules (or readjustment rules), context-
sensitive or not, can modify the boundary structure inherited from higher 
levels. This possibility was initiated by Chomsky & Halle (1968:366ff), and 
further developed for example by Selkirk (1972, 1974) and Sag (1974). 
Boundary mutation rules can achieve transformations such as # →+
or ## →# and so forth (including + →#, cf. Sag 1974:603f). Selkirk 
(1972, 1974) makes extensive use of boundary mutation rules for the de-
scription of French liaison, which is largely sensitive to morphological and 
syntactic information (e.g. ils *([z]) ont "they have" where liaison is man-
datory, against ont-ils *[z] eu "have they had?" where liaison is impossi-
ble). That is, Selkirk first simplifies the maximum boundary cluster ## that 
can come down from syntax in liaison environments (## →#); then she 
applies a rule that triggers liaison with a single intervening #, but which is 
blocked by double ##. The effect is that the environment for liaison is de-
fined in the phonology on the grounds of the boundary strength that pho-
nology inherits from higher levels (Elordieta 2008:212ff provides a com-
prehensive overview of Selkirk's early work). 
Boundary mutation rules were also given a socio-linguistic role ac-
cording to the general observation that "the more casual or 'reduced' the 
style level becomes, the more grammatical boundaries lose their effect" 
(Basbøll 1975:114). This perspective tacitly assumes that the "regular" 
effect of boundaries, lost in low style, is rule-blocking, rather than the en-
hancement of rule application. Following this line, Selkirk (1972) depletes 

96 
Chap 6: The life of boundaries in post-SPE times 
the linear string of more and more boundaries, or transforms the stronger # 
into less harmful +, = as the style level decreases. 
 
113  4. McCawley (1968): boundaries define domains of rule application 
 
114  4.1. Cyclic derivation on the grounds of phonological domains 
 
Chomsky et al. (1956) have introduced the idea that boundaries define do-
mains which correspond to relevant morpho-syntactic chunks of the linear 
string (the "phonemic clause") and serve as a measure for the application of 
rules in cyclic derivation (see § 75). 
This concept was further developed by McCawley (1968:52ff) who 
proposes to order boundaries along a strength hierarchy, something that was 
also done by Chomsky et al. (1956), but is rejected in Chomsky & Halle 
(1968:371). In doing so, boundaries acquire a "ranking function": each 
division has a hierarchical status and thereby ranks the rules in whose struc-
tural description it occurs. 
Boundaries, then, define the domain of application of rules in that 
"the juncture gives the limits of the stretches of utterance to which certain 
rules apply" (McCawley 1968:55). Basbøll (1975:111, 1978b) and Selkirk 
(1980a) are along the same lines. 
Chomsky & Halle (1968:371) recognise the appeal of McCawley's 
idea, but argue against the exclusive delimiting function of boundaries. 
McCawley's mechanism indeed reminds of Trubetzkoyan Grenzsignale 
(§ 55), albeit in a non-functional perspective. Devine & Stephens 
(1976:292f) put it this way: "while some morphosyntactically conditioned 
phonological rules do signal beginnings and ends, others, just like mor-
phologised rules proper, evidently signal the morpho-syntactic category and 
not its delimitation." 
In the example provided by McCawley, a rule that voices intervo-
calic /t/ will not apply to the first /t/ of the sequence /#pat#atak#/, but does 
affect the second one. This is because the rule applies separately to the two 
chunks #pat# and #atak#. Since /t/ is intervocalic in the latter, but not in the 
former domain, it will be transformed only in #atak#, and the overall result 
is [patadak]. 
This is obviously an application of cyclic derivation (§ 80) where also 
some no look-back device (§ 287) is needed: if there is an outer cycle, i.e. 
[[pat][atak]], something must prevent the voicing rule from applying to the 
second /a/ of the overall string at the outer cycle. 

McCawley (1968): boundaries define domains of rule application 
97 
If there is cyclic derivation based on regular cyclic structure (i.e. 
brackets), the question arises whether McCawley's boundary-based chunks 
are any different from those that are delineated by cyclic structure. If they 
are not, boundary-defined domains of rule application appear to be redun-
dant. 
Another way of looking at this situation is to recognise that there is a 
competition between a representational (boundaries) and a procedural (cy-
clic derivation) solution. As far as I can see, this issue was not discussed in 
the contemporary literature that debates McCawley's proposal. 
 
115  4.2. Local vs. domain-based intervention ± notational variants? 
 
McCawley's (1968) idea remained anecdotic in the SPE-dominated scene 
by the time it was aired. However, the further development of interface 
theory shows that it has an important potential: it introduces the central 
question whether morpho-syntactic intervention in phonology is local or 
domain-based. In the former case, a punctual object (# in SPE) is inserted 
into the linear string at a specific point and hence can only bear on its im-
mediate environment. By contrast, in McCawley's domain-based perspec-
tive no effect is caused by the presence of one single object in the linear 
string. Rather, only the association of two identical items (the stretch de-
lineated by #...#) can bear on the phonology. And even then is the effect not 
due to the neighbourhood action of a boundary; rather, the domain as such 
impacts the phonology. 
McCawley's mechanism is thus a linear notation of what will later be 
known as the Prosodic Hierarchy: by the time it was put forth, the linear 
environment did not allow for a formulation in terms of autosegmental 
domains. The heart of the proposal, though, is precisely this: morpho-
syntax bears on phonology through the action of domains, rather than of 
singleton items that are locally inserted into the linear string. 
When Elisabeth Selkirk set up Prosodic Phonology in the early 80s, 
she was embarrassed by McCawley's domain-defining boundaries (Selkirk 
1980a): her purpose is to show that domains are a better vector of morpho-
syntactic information than boundaries. If both turn out to be notational 
variants, the major break in interface tradition that she advertises would 
look less fresh (see § 373). 
The real issue, though, which is truly critical and which we come 
across for the first time here, is the alternative between local and non-local 
intervention in phonology. The former is represented by Trubetzkoy's 

98 
Chap 6: The life of boundaries in post-SPE times 
Grenzsignale, structuralist juncture and SPE-type boundaries, while the 
latter is advocated by McCawley (1968) and Prosodic Phonology, the to 
date dominant interface theory. It is argued in § 706 that the influence of 
one module on another through the representational channel can only be 
local. 
 
116  5. Typology and strength of boundaries 
 
117  5.1. Boundary zoo 
 
Linguists have always recognised different types of juncture. Some aspects 
of the structuralist typology were reported in § 71. Chomsky et al. (1956) 
operate with "internal" and "external" juncture, while [±word boundary] 
and [±formative boundary] are the basic items in SPE (§ 87). 
In post-SPE times, this limited inventory becomes a true boundary 
zoo. It is not uncommon to find treatments where up to seven different 
boundaries are identified in the grammar of a given language. These are 
then usually ranked on a scale of boundary strength.22 
Thus Basbøll (1975) acknowledges five different boundaries: ###, 
##, #, + and $ (see also Basbøll 1981). For the description of Japanese, 
McCawley (1968:57ff) recognizes $, #, #i, :, & and *, which appear in or-
der of decreasing strength. Stanley (1969) identifies seven different 
boundaries in Navaho, #, =, *, !, ", + and - (also in decreasing strength). 
Kaisse (1985:109ff) presents data from Modern Greek that need more than 
three boundaries in order to be readily described.23 
22 More recent applications of the notion of boundary strength can be found in 
Loporcaro (1999) and Bertinetto (1999). These authors assign increasing nu-
merals to boundaries that represent increasing morpho-syntactic distance (on a 
scale from -6 to +6, hence yielding a zoo of 13 different diacritics). Rotenberg 
(1978:20f) also elaborates on boundary strength. 
23 But rather than adding new boundaries to the inventory of SPE, which would 
have been in line with the general movement, Kaisse concludes on the failure 
of boundary theory. Instead, she argues for direct reference to morpho-syntactic 
categories. This so-called direct syntax approach is further discussed in §407. 

Typology and strength of boundaries 
99 
118  5.2. Boundary contrast: minimal pairs and phonological permeability 
 
On which grounds, then, are different boundaries distinguished? The best 
evidence are "minimal pairs" that contrast two different boundaries in an 
otherwise identical segmental environment. For example, there are two 
homophone suffixes -er in English: the comparative -er (long - long-er,
quick - quick-er), and the agentive -er (sing - sing-er). The latter does, the 
former does not trigger a rule which is presented as /g/-deletion in Chom-
sky & Halle (1968:85f, 369f): /long-er/ →lo[Ng]er vs. /sing-er/ →si[N]er.
If the analyst is lucky enough, a given root supports both affixes, as 
is the case in English where (at least some) speakers can derive the agentive 
longer "a person who is longing" from the verb to long. Hence the minimal 
pair longer lo[Ng]er "comparative of long" vs. longer lo[N]er "a person who 
is longing". The contrast must thus be ascribed to the existence of two dif-
ferent boundaries, i.e. agentive /sing#er/, /long#er/ vs. comparative 
/long+er/. On the account of Chomsky & Halle (1968:369f), a boundary 
mutation rule has transformed the original comparative /long#er/ into 
/long+er/. The rule that deletes /g/, then, contains # in its structural descrip-
tion and is therefore inoffensive in regard of /long+er/. Of course, it also 
leaves morphologically simplex forms such as finger /finger/ untouched. 
Note that the /g/ of /sing##/, where ## represents the word boundary, will 
also be deleted.24 
Hence one may expect that seven different boundaries rely on a 
seven-way contrast. But of course this is not the case. Stanley (1973:192f) 
admits that "phonologically parallel contexts can seldom be found to dis-
tinguish more than two or three types", and further says "'minimal pairs' for 
boundary phenomena are difficult to find, in general, and less direct meth-
ods of justifying boundary types must be used." 
The less direct method in question is the various degree of phono-
logical permeability of morpho-syntactic divisions: Stanley (1973:193) 
explains that in practice "it will soon be found that some [boundaries] are 
actually weaker than others in the sense that certain phonological rules will 
apply across some and not others." The same method is applied by McCaw-
ley (1968:55), who assumes "the existence of distinct junctural elements /#/ 
and /:/, corresponding to the fact that such rules as the p →h rule and the h 
→/ rule apply to different-sized chunks of utterance." 
Establishing different boundaries on the grounds of their phonologi-
cal permeability is indeed the common method that allows for arriving at 
 
24 More on English agma when Lexical Phonology is presented in § 167. 

100 
Chap 6: The life of boundaries in post-SPE times 
the aforementioned boundary zoo. Examples are Chomsky & Halle 
(1968:84ff), Siegel (1974), Aronoff (1976), Kenstowicz & Kisseberth 
(1977:103ff), Booij (1977), Allen (1980). Devine & Stephens (1976:298f) 
offer a general overview. 
To the best of my knowledge, nobody has ever tried to establish a 
cross-linguistic inventory of boundaries that is based on their sensitivity to 
certain rule types or some other cross-linguistically resident property. What 
has been done, though, is to define families according to the formal proper-
ties of boundaries. Stanley (1973) for example distinguishes three classes of 
boundaries on the grounds of three different rule classes: 1) rules that are 
blocked by boundaries of strength x or stronger, 2) rules that apply only 
when a specific boundary is present, 3) rules that apply only when a bound-
ary of strength x or stronger is mentioned at the beginning or the end of its 
structural description. 
 
119  6. Attempts to restrict boundary abuse and the boundary zoo 
 
120  6.1. Boundaries in an arbitrary rewrite-machinery 
 
In the 70s, the major objection levelled against SPE was its unrestricted-
ness: SPE can describe those processes that occur in natural language as 
much as those that do not. Indeed, nothing in the rewrite-machinery or in 
other parts of the theory marshals overgeneration. 
In chapter nine of SPE, Chomsky & Halle (1968) identify this prob-
lem. In their view, markedness is a prime candidate for a solution. During 
the 70s, then, things did not quite go their way: two strands tried to derive 
the impossibility of outlandish processes. One from formal properties of the 
theory (the movement initiated by Kiparsky 1968-73 and which led to 
Lexical Phonology), the other by cutting down the formal machinery to a 
minimum, and by retrenching the scope of phonology (Natural Generative 
Phonology, see § 124 below). This evolution is known as the abstractness 
debate (e.g. Kenstowicz & Kisseberth 1977:1-62, 1979:204ff, also §§ 125f 
and Vol.1:§305). 
Part of the critique was also that SPE-technicians, not unlike their 
structuralist peers, were only after the "correct" surface forms and did not 
care much for the way they are produced. This challenge also extends to 
how boundaries were used: analysts would appeal to them if they helped 
achieving the correct result, and otherwise dismiss them. True, everybody 
was bound by the morpho-syntactic corset of boundaries, which was put 

Attempts to restrict boundary abuse and the boundary zoo 101 
into force by Chomsky et al. (1956) (i.e., no boundaries in the middle of 
morphemes, see § 78). But beyond that, no principle defined when the ana-
lyst could, should or must not call on a boundary. 
The ensuing practice is questioned by Devine & Stephens (1976). 
 
(49) 
Boundaries were "considered justified by their proponents merely because 
they produced the correct output and were more or less consistent with 
background assumptions; whereas in fact a hypothesis should have empiri-
cal consequences different or in addition to its explanandum." Devine & 
Stephens (1976:309f) 
 
For this reason and also because of the awkward boundary zoo 
(§ 117), some authors tried to define criteria which are able to restrict the 
distribution of boundaries, and to control their use. These efforts are re-
viewed below. 
 
121  6.2. Boundary strength as a diagnostic for boundary abuse 
 
Kenstowicz & Kisseberth (1977) focus on the relative strength of bounda-
ries, which is established according to their phonological permeability in 
regard of a given process. This ranking, then, must be consistent with re-
spect to all other rules: boundary X may not be weaker than boundary Y in 
the conditioning of a one process, but stronger in regard of some other. 
 
(50) 
"Boundaries must be [«] ordered from 'weakest' (i.e., expressing the closest 
bond between morphemes and thus having the least inhibiting effect on 
phonological rules) to 'strongest' (i.e., expressing the weakest bond between 
morphemes and thus having the greatest inhibiting effect on phonological 
rules)." Kenstowicz & Kisseberth (1977:105ff) 
 
Also, "the relative strength of boundaries must conform to gram-
matical facts" (page 105). That is, the boundary hierarchy established on 
phonological grounds should match, or at least not fall foul, of the more or 
less close relationship of the morphemes in question. 
Boundary strength can thus be used as a diagnostic for misplaced 
boundaries or boundary abuse. 
 

102 
Chap 6: The life of boundaries in post-SPE times 
122  6.3. Boundary economy I: Basbøll's general and grounded advice 
 
Basbøll (1975, 1978a,b, 1981) attempts to make boundaries a last resort 
strategy. He argues that boundaries should not be called on in presence of 
an alternative solution that does the same job without them. 
An example of this strategy is Basbøll's (1975:115, 1978a:154) cri-
tique of SPE and Selkirk (1972, 1974), who recur to the boundary = only in 
learned (i.e. Latinate) vocabulary (see § 89). That is, Selkirk for example 
justifies the existence of =, which must be different from +, by the fact that 
the former, but not the latter triggers the loss of the prefixal nasal consonant 
(and ensuing compensatory lengthening of the following liquid) in French: 
/in=légal/ and /con=mémoratif/ come out as illégal [ilegal] and commémo-
ratif [kçmemoratif] (where the gemination of the liquid is only possible in 
high style), respectively. Basbøll argues that the diacritic [+learned] could 
do the same job as =, and hence should be preferred. 
Basbøll also makes a number of general remarks that call on external 
evidence in order to identify boundaries in the linear string. That is, psy-
cho-linguistic experimentation (Basbøll 1975:122ff) and a putative pho-
netic identity (Basbøll 1975:123, see § 70 on the structuralist debate regard-
ing this issue) could betray the (non-)existence of boundaries. Finally, Bas-
bøll (1975:128) conditions the occurrence of boundaries to productivity: he 
claims that productive, but not unproductive affixes, come with a boundary 
(# in his system). 
On more phonological grounds, Basbøll (1978a:164f) also argues 
that boundaries should not be used if their presence leads to a more compli-
cated formulation of other rules. And he proposes to require multiple evi-
dence for boundaries, which should only be introduced if needed for at 
least two phonological processes (Basbøll 1975:121, 1978a:165). 
Finally, Basbøll (1975:122) and Devine & Stephens (1976:301) re-
call a property of boundaries that should be self-evident: # boundaries rep-
resent morpho-syntactic, not lexical information; hence they may not be 
stored in the lexical entry of roots. By contrast, they may come with affixes 
since these precisely carry morpho-syntactic information (regarding class 
membership for example). Basbøll's ban on boundaries in roots is a reaction 
on an article by Hoard (1973), who proposes lexical entries of roots such as 
/dhadh#/ for Sanskrit. 
 

Attempts to restrict boundary abuse and the boundary zoo 103 
123  6.4. Boundary economy II: the + boundary can be dispensed with 
 
Boundary economy is also the concern of Hyman & Kim (1973), Hyman 
(1975:197f, 1978:457ff) and Strauss (1979). These authors argue that the 
formative boundary + of SPE can and should be done away with. 
Hyman (1978:459) reacts on "the abuses seen in such works as 
Stanley (1973), where boundaries are unnecessarily proliferated" (also 
Hyman 1975:197f and Hyman & Kim 1973). He claims that whatever the 
morpho-syntactic reality of +, it can never have a phonological effect. This 
is because all cases where + is held to be phonologically active that "we 
have investigated have either used the + boundary when the # boundary 
would have done as well, or have used the + boundary diacritically, and 
could just as well have used ad hoc boundaries such as $, % or ¢ or referred 
directly to the morphemes involved" (Hyman 1978:459).25 
In replacement of +, Hyman (1978:459) proposes to write rules that 
make direct reference to the particular morphemes involved. This option 
did not arouse any contemporary echo; but together with Pyle (1972) and 
Rotenberg (1978:16f) (see § 136, which Hyman leaves unmentioned), it 
constitutes the body of early and erratic formulations of what will be 
known as direct syntax approaches in the 80s. § 407 below reports on the 
contention between this line of thought and Prosodic Phonology: the cor-
nerstone of the latter is Indirect Reference, that is the proscription of mak-
ing reference to morpho-syntactic categories in phonological rules. 
Strauss (1979) also argues that all English facts can be accounted for 
if the SPE-created # and + are merged into one single concatenation opera-
tor.26 On his analysis, the distinctive function of # and + is taken over by 
the computational component (precyclic vs. postcyclic affixes) and the 
lexicon. 
 
25 Stevens (1980) discusses this issue and presents eventual counter-evidence. 
26 Following Siegel (1974:25), Strauss (1979:387) holds that = has no independ-
ent existence anyway: SPE was misled not to merge it with + (see also Siegel 
1980). 

104 
Chap 6: The life of boundaries in post-SPE times 
124  7. Internal and external SPE-revision: Kiparsky (1968-73) and Natural 
Generative Phonology 
 
125  7.1. Introduction 
 
The previous pages have reviewed initiatives against uncontrolled prolif-
eration and use of boundaries: the relevant literature made a case for a self-
applied boundary hygiene. The proposals at hand, however, had little, if any 
impact on the field. 
Part of the reason for this is certainly the fact that people simply lost 
interest in manicuring boundaries within a system that everybody knew 
needed a profound revision in central areas: overgeneration, abstractness 
and morpho-phonology were generative teething troubles that Chomsky & 
Halle (1968) had already lucidly spotted in the ninth chapter of SPE. The 
research agenda of the 70s, then, was dominated by the competition of an 
internal and an external revision movement. The former (socialist) was led 
by Kiparsky (1968-73) and attempted to reform SPE from inside, while the 
latter (communist) was initiated by Stampe (1972) and argued that there is 
no possible cure without completely overthrowing the system (see Scheer 
forth). 
The purpose of the following pages is not to review the history of 
generative phonology in the 70. Rather, I aim to show what kind of conse-
quences the critique of SPE had on interface theory, i.e. on boundaries at 
that time. As we will see, the bearing is on the quantity, rather than on the 
quality of boundaries. 
 
126 
7.2. Morpho-phonology in SPE and the 70s 
 
Morpho-phonology is the idea, tacitly admitted in all quarters of early gen-
erative phonology, that etymologically, paradigmatically or semantically 
related items contract a synchronic derivational relationship (Jonathan 
Kaye calls this attitude the Central Dogma). Otherwise, it was argued, a 
generalisation would be missed. Therefore, any two such items had a com-
mon underlying form, and their surface appearance was derived by rule. 
For the sake of illustration, it is useful to look at the wildest case on 
record: the work by Theodore Lightner. Lightner is certainly not representa-
tive for the average post-SPE phonologist; but the fact that theory allowed 
him to do what he did without raising any objection is an unmistakable 
indication that something was wrong. 

Internal and external SPE-revision: Kiparsky (1968-73) and NGP 105 
Lightner (1978:18f, 1981, 1985) holds that each one of the following 
pairs are derived from a common underlying form: eye and ocular, thunder 
and detonation, dental and tooth, rebel and bellicose, cardiac and heart,
three and third, gynaecology and queen, sweet and hedonism and so on. 
Since the alternations h-k (heart - cardiac), d-T (third - fourth) and s-h 
(sweet - hedonism) suppose Grimm's Law, Verner's Law and the Ancient 
Greek s > h shift, Lightner concludes that all these processes are performed 
by the grammar of present-day English natives. 
The origin, development and (non-)justification of morpho-
phonology is discussed in a large body of literature (St. Anderson 
1985:331f provides an informed overview). As a piece of the discussion 
regarding overgeneration and abstractness (see § 144), it has played an im-
portant role in the evolution of generative phonology. Overgeneration is at 
the origin of the internal and external critique of early generative phonol-
ogy that has made the phonological agenda of the 70s. The internal (i.e. 
non-revolutionary) revision was led by Paul Kiparsky and the abstractness 
debate that he initiated in 1968 (Kiparsky 1968-73: how abstract is phonol-
ogy?). This strand will open out in Lexical Phonology in the 80s. The ex-
ternal (i.e. system-overthrowing) critique was initiated by David Stampe 
(1972) and Natural Phonology, on which more shortly.27
The broad result of this evolution was that all phonological theories 
that individuated in the early and mid 80s have to some extent learned the 
following lesson: many alternations that early generativists believed were 
produced by online computation do not represent any synchronically active 
process at all. Two etymologically, paradigmatically or semantically related 
forms do not necessarily stand in a derivational relationship: they may as 
well be recorded as two independent lexical items, or represent allomorphic 
activity. Hence sweet and hedonism, but also, perhaps, electric and electric-
ity or sane and sanity, may represent two distinct lexical entries that have 
not been modified by any rule before they reach the surface.28 
27 Vol.1:§305 offers a more detailed review of the development of the abstractness 
debate and overgeneration (also Scheer 2004b:8ff, forth). 
28 Velar softening (electric - electricity) and Trisyllabic Shortening (or Laxening) 
(sane - sanity, see § 164) are two debated cases which up to the present day 
produce both defenders and adversaries of the single-underlying-form analysis. 
Relevant literature includes Chomsky & Halle (1968:219ff, 426f), Hooper 
(1975:544f), Kiparsky (1982a:40f), Halle & Mohanan (1985), Harris 
(1994:21ff), Kaye (1995:312, 328), Coleman (1995:375ff), Halle (2005) and 
McMahon (2007). Hayes (1995a) and Green (2007:172ff) provide a docu-
mented overview of the question. 

106 
Chap 6: The life of boundaries in post-SPE times 
It goes without saying that the question where exactly the red line 
runs between the computational and the lexical option is open: some cases 
are lexical for sure, and the online computation of others is beyond doubt. 
But the swampy midfield is large enough for much debate: relevant discus-
sion today runs under the header of (anti-)lexicalism; after a decidedly lexi-
calist period in the 80s (both in syntax and phonology), anti-lexicalist 
analyses in the spirit of the 60s have gained ground again in certain mini-
malist quarters. This issue is further discussed in § 569. 
It may be doubted that a formal criterion will be able one day to de-
cide whether a given alternation represents a common underlying form or 
two separate lexical entries (at least in phonology). Carvalho (2002:134ff) 
provides extensive discussion of this question. 
 
127  7.3. Natural revival of structuralist juncture (abuse) 
 
Natural Generative Phonology (Vennemann 1974, Hooper 1976) is born 
from a reaction against overgeneration, abstractness and morpho-
phonology.29 The central tenets of this theory distil into the True Generali-
zation Condition and the No-Ordering Condition. According to the former, 
only phonetically accessible information can be used in the formulation of 
phonological rules, while the latter prohibits rule ordering. 
Alternations are divided into two types. Those that do not suffer any 
exception in the entire language and exclusively appeal to phonetically 
retrievable information are called natural and granted phonological status 
(P-rules). By contrast, the statement of morpho-phonemic rules (MP-rules) 
requires non-phonetic information such as reference to morpho-syntactic 
 
29 Laks (2006) provides a historical overview of Natural Generative Phonology; 
see also Scheer (2004b:12ff) for a critical review of its phonetically oriented 
evolution. 
 
Note that there are two brands of Natural Phonology, one generative, the other 
not. Natural Phonology grew out of David Stampe's (1972) dissertation and is 
non-generative: the major fraction line is between the formal and the functional 
approach to language (in the sense of Newmeyer 1998): Natural (non-
generative) Phonology is functionalist at heart. Natural Generative Phonology 
also calls on Stampe's dissertation, but follows the formal line of thought. Non-
generative Natural Phonology is represented by, among others, Donegan 
(1978), Donegan & Stampe (1978, 1979), Dressler (1974, 1984), Hurch & 
Rhodes (eds.) (1996) and Dziubalska-Kołaczyk (2001a, 2002). 

Internal and external SPE-revision: Kiparsky (1968-73) and NGP 107 
categories, and the alternations at hand are typically riddled with excep-
tions. 
This division enforces a corresponding split among boundaries: since 
#, + and the like can hardly be said to represent phonetic information (they 
do not have any phonetic correlate, see § 88), they are banned from P-rules 
(Vennemann 1974:360ff). However, even natural (i.e. completely regular) 
rules need to make reference to boundaries such as the beginning of the 
word. This is why Hooper (1975:545) introduces "phonetic boundaries": 
the "syllable boundary $" and the "pause boundary ║". Elsewhere, Hooper 
(1976:14) also calls them "phonological boundaries" or "grammatical 
boundaries". The following quote shows how Hooper tries to tell bounda-
ries that do from boundaries that do not have a phonetic manifestation. 
 
(51) 
"'Phonetic terms' refer to phonological features (that have intrinsic phonetic 
content) and phonological boundaries (that have a necessary and consistent 
phonetic manifestation). The phonological boundaries are the syllable 
boundary (S) and the pause boundary. Both of these boundaries are deter-
mined by phonetic means. On the other hand, the word boundary (## and #) 
and the morphemic boundary (+) are determined by syntactic and semantic 
means. These latter boundaries are counted as nonphonetic information." 
Hooper (1976:14) 
 
The same dilemma is referred to with different vocabulary by 
Anderson (1974:3), who talks about "boundary elements" in morphopho-
nemic rules, against "phonetically realizable (i.e., word or phrase) bounda-
ries" that may occur in natural rules.30 
No doubt this perspective is much more akin to the structuralist con-
ception of juncture than to generative boundaries. Anderson (1974) and 
Hooper (1975, 1976) are forced to grant a phonetic identity to their bounda-
ries because otherwise they would not be entitled to use them. Concomi-
tantly, their boundaries are explicitly denied any morpho-syntactic identity 
± precisely the property that paved the way for structuralist boundary abuse 
(§ 69): nothing prevents this kind of boundaries from occurring in the mid-
dle of morphemes. 
 
30 Rather than trying to make (some) boundaries phonetic objects in order to have 
the right to use them, Rhodes (1974) attempts at doing away with them alto-
gether (through global and transderivational reference: a process that does not 
actually apply in a derivation could be "felt" and hence cause an effect in that 
derivation because it is active in some other derivation where the same mor-
phemes are involved). 

108 
Chap 6: The life of boundaries in post-SPE times 
Another obvious point of contact with structuralism is Level Inde-
pendence (§ 61): In Natural Generative Phonology, just as two decades ago, 
an alternation that requires the appeal to morpho-syntactic information 
cannot be phonological; it is rejected into morphology (or morpho-
phonology, MP-rules). 
 
128  7.4. The elimination of (word) boundaries from P-rules ± a case of wishful 
thinking 
 
Devine & Stephens (1980:57ff) and Clayton (1981) point out that bounda-
ries are an excellent testing ground for the central claim of Natural Genera-
tive Phonology, i.e. that alternations fall into two (major) classes of proc-
esses, P-rules and MP-rules. The former are productive, phonetically trans-
parent and entirely regular, while the latter are typically non-productive, 
admit exceptions, may be non-transparent and governed by morpho-
syntactic conditions. The corresponding division of boundaries into those 
that are phonetically expressed ($, ║) and those that are not (#, ##) was 
described above. 
A prediction is thus made to the effect that non-phonetic boundaries 
such as the word boundary will never be necessary for the statement of P-
rules. Devine & Stephens (1980:71ff) and Clayton (1981:577ff) demon-
strate that this is not true: many alternations in natural language are entirely 
regular, productive and make exclusive reference to the phonetic signal 
except for the fact that they crucially appeal to the word boundary. 
Devine & Stephens (1980:59f) also show that the elimination of 
word boundaries from phonological rules is wishful thinking, if anything, 
in Natural Generative Phonology practice. A processes as ordinary and 
frequent as apocope cannot be phonological because it needs to make refer-
ence to the right edge of the word. 
In spite of this, Hooper (1976:106) desperately tries to describe a 
case of apocope in Spanish without mentioning the word-final location. She 
attempts at obviating this context by setting up a structural description that 
appeals only to the preceding environment. Hooper contends, then, that the 
vowel in question is not lost in word-internal position because it is never 
preceded by the relevant triggering environment. Devine & Stephens show 
that this analysis does not stand up to fact: an apocope is called an apocope 
because it concerns the last vowel of the word. 
This case is instructive because it shows that even Natural Genera-
tive Phonology practitioners refrained from eliminating entirely productive, 

Internal and external SPE-revision: Kiparsky (1968-73) and NGP 109 
regular and phonetically transparent processes from phonology on the sole 
grounds of their making reference to word boundaries. The result is a the-
ory that warrants the absence of # from phonology, but ends up reintroduc-
ing it through the back door (something that Devine & Stephens 1980:59f 
call covert boundaries). 
 
129  7.5. The retrenchment of morpho-phonology mechanically reduces the 
number of boundaries 
 
Rather than eliminating morphologically conditioned processes from pho-
nology altogether, the reformist strand, which is represented by Kiparsky's 
work, set out to simply retrench morpho-phonology. To which extent was a 
matter of debate. The general goal, i.e. the reduction of abstractness, could 
be achieved either by restricting the computational facilities, or by having a 
restrictive definition of the relationship between underlying and surface 
forms. 
The latter strategy is relevant for boundaries since it shifts burden 
from the computational part of grammar into the lexicon. Trivial examples 
were already mentioned in § 126 above: instead of deriving dental from 
tooth by a rule that also computes a boundary in dent-al, the two items are 
independent lexical entries, and no phonological computation is performed 
when they are used. 
Kiparsky has attempted to formalise this orientation. The Alternation 
Condition (Kiparsky 1968-73, 1973a) (see § 185) defines what a possible 
underlying representation is: in case a morpheme shows no alternation on 
the surface, it must not be any different in its underlying form. This results 
in a ban against absolute neutralisation. In a further step, Kiparsky (1973a) 
restricts the application of rules in such a way that a certain rule class may 
only target derived environments. This was called the Revised Alternation 
Condition: obligatory neutralization rules apply only in derived environ-
ments. An environment is derived iff it is produced either by the concatena-
tion of two morphemes or by the application of a phonological rule. 
This proviso rules out a number of abstract SPE analyses such as for 
instance the one regarding Trisyllabic Shortening (div[aj]ne - div[I]nity,
op[ej]que - op[æ]city etc., see § 164 and note 28 for further discussion and 
literature). In order to account for the fact that this process fails to apply to 
mono-morphemic items such as n[aj]ghtingale (nightingale), [aj]vory 
(ivory) and [ɔw]maha (Omaha), SPE recurs to abstract underlying struc-
tures such as /nixtVngael/ for nightingale: since there is no long vowel in 

110 
Chap 6: The life of boundaries in post-SPE times 
the underlying representation of this word, it cannot be subject to shorten-
ing (and is ultimately turned into [aj] by independent rules). When assum-
ing the Revised Alternation Condition, this kind of abstract underlying rep-
resentation can be dispensed with: nightingale and the like remain un-
touched by Trisyllabic Shortening because they are underived (Kiparsky 
1982a, Booij 1987:54ff). 
In the same way, the theory gives up on the ambition to rule over 
"exceptions" that fail to correspond to any morphological regularity. For 
example, vowel shortening applies to mean [miin] ± meant [mEnt] but not 
to paint [pejnt], pint [pajnt], mount [mawnt] because the latter are morpho-
logically simplex, and their long vowel is specified as such in the lexicon: 
/miin+t/ vs. /pejnt/. Shortening, then, applies only to derived environments 
(Kiparsky 1985a:87). 
On the other hand, Kiparsky's struggle for defining a reasonable line 
of division between computation and the lexicon also meant that certain 
parts of morpho-phonology need to be defended against concretist ambi-
tion. In § 144 below, it is argued that Lexical Phonology, i.e. the theory that 
grew out of Kiparsky's struggle with abstractness, may be viewed as an 
attempt to maintain as much morpho-phonology as possible in the compu-
tational device of phonology while cutting away the wildest outgrowths of 
unrestricted SPE. 
Whatever the balance between computation and the lexicon, it is for 
sure that boundaries are eliminated from analysis every time a phonologist 
decides to freeze an alternation by recording two distinct lexical entries, 
rather than deriving it by rule. The evolution in the 70s and early 80s 
clearly goes that way: some possibly significant variation notwithstanding, 
all phonological theories that individuated in the 80s gave up on some 
computation that was practised in SPE.31 The effect in the 80s thus was a 
phonological landscape where computation was not king anymore, and 
boundaries less important: a negotiated and more balanced relationship was 
established with both the lexicon and representations. The following sec-
tion looks at the effect of the latter on boundaries. 
 
31 This concerns theories as diverse as Lexical Phonology (§ 144), Feature Geome-
try, Government Phonology, Dependency Phonology and even Halle & Mo-
hanan (1985), the direct continuators of SPE in the new autosegmental envi-
ronment. 

Internal and external SPE-revision: Kiparsky (1968-73) and NGP 111 
130  7.6. Autosegmental structure: from representational to procedural 
management of the word boundary 
 
The advent of autosegmental structure in the late 70s had an important ef-
fect on the number of boundaries that are needed in order to state phono-
logical processes. While in the linear environment of SPE all phonologi-
cally relevant morpho-syntactic divisions were represented by a boundary 
in the structural description of rules, the (re)introduction of syllable struc-
ture in form of an autosegmental arborescence replaced much reference to 
boundaries by reference to syllabic constituents. 
The most vigorous effect is produced by the coda, which was intro-
duced in place of the disjunction __{#,C}. That is, rules now make refer-
ence to the coda, rather than to "#,C" when a coda phenomenon is de-
scribed. Since the coda context is very frequent in the statement of different 
rules and across a variety of languages, a great deal of #s disappeared from 
phonology. 
An interesting question is whether the coda is just a non-linear surro-
gate of the end of the word, which continues to require a positive (and dia-
critic) statement in the phonology. That is, syllable structure is established 
by a syllabification algorithm that parses the items of the linear string. 
However, no # is parsed since the coda status of a consonant follows from 
the fact that there is no vowel to its right (rather than from the presence of a 
#). This, in turn, supposes that the phonology "knows" that there is "nothing 
to its right", even though another word may follow. In other words, the 
syllabification algorithm needs to know the limits of the domain to which it 
applies. 
This information of course is morpho-syntactic in nature; but it does 
not appear in the phonology (i.e. in a structural description). Rather, it de-
fines the stretch of the linear string to which phonology applies ± an en-
tirely different perspective. Obviously, cyclic derivation, or the segmenta-
tion of the linear string into phases in more modern terms, shines through in 
this discussion. As a matter of fact, then, autosegmental structure shifted 
the grounds of the coda context __{#,C} from a representational boundary-
based to a procedural analysis that relies on the segmentation of the linear 
string into autonomous chunks. Therefore, it is correct to say that autoseg-
mental structure eliminated a good deal of boundaries ± or rather: replaced 
their function by a procedural device. In any event, the procedural solution 
is not diacritic in nature, a fact that may be viewed as an improvement over 
the diacritic boundary solution. This could well have been used as an argu-
ment for the introduction of autosegmentalism. 

112 
Chap 6: The life of boundaries in post-SPE times 
It appears, however, that the articulation of procedural and represen-
tational intervention was not a topic of great interest in the 70s. It is maybe 
for this reason that the representational-procedural trade-off and hence the 
boundary-eliminating side-effect of autosegmental structure went by and 
large unnoticed (this was also pointed out in Vol.1:§86). Another reason 
why nobody used the coda in order to argue against awkward diacritic 
boundaries is probably that there was no specific antipathy against bounda-
ries in the first place: they were not considered aliens, and their diacritic 
character was not judged unwarranted. 
We will see shortly (§§ 136f) that there were exceptions to this atti-
tude: namely Pyle (1972) and Rotenberg (1978) called the diacritic charac-
ter of boundaries into question, albeit against the mainstream and without 
much impact on contemporary practice. The diacritic character of bounda-
ries only became an issue when Elisabeth Selkirk set up Prosodic Phonol-
ogy against the boundary record (§ 373). 
 
131  8. What exactly is the output of translation, if any? 
 
132  8.1. Growing uncertainty: what kind of intermundia animals are 
boundaries? 
 
Devine & Stephens (1976) formulate the question that is at the heart of the 
debate on boundaries in the late 70s. 
 
(52) 
"What ARE phonological boundaries? [«] What are the relations and dis-
tinctions in function between phonological boundaries and morpho-syntactic 
rule environments?" Devine & Stephens (1976:285f), emphasis in original 
 
The question is about the diacritic character of boundaries: phonolo-
gists felt (and some even demonstrated, see § 136) that they are not properly 
phonological objects: neither phonemes nor segments nor anything else that 
would be known in phonological quarters. But obviously they are not mor-
pho-syntactic objects either, even if they carry higher level information. 
Hence "the question of whether the juncture is a phonological entity or 
merely a list of morpho-syntactic boundary sequences then presents itself 
as usual" (Devine & Stephens 1976:307). 
The mushy identity of boundaries, which seem to be a mysterious 
blend of morpho-syntactic and phonological properties, led Kenstowicz & 
Kisseberth (1977:103ff, 1979:401ff, 421) to introduce a question that will 
be known as the direct syntax approach in the 80s. 

What exactly is the output of translation, if any? 113 
(53) 
"Does the fact that a given rule applies only to structures containing a par-
ticular morpheme or morpheme class constitute evidence that a boundary 
different from the morpheme boundary is present? In other words, are ALL 
instances where the grammatical (particularly, morphological) identity of an 
element is relevant to a rule's application to be analysed in terms of bounda-
ries, or is there a distinction between phenomena properly described by 
making reference to boundaries and phenomena properly described by 
means of direct reference to morphological identity? And if there is a dis-
tinction, how do we know when we are dealing with boundaries and when 
we are not?" Kenstowicz & Kisseberth (1977:103f), emphasis in original 
 
Kenstowicz & Kisseberth's suggestion is one of the isolated and un-
systematic occurrences in the 70s of the direct syntax idea that will be the 
main competitor of Prosodic Phonology in the 80s (§ 407). Along the same 
lines, Larry Hyman's work was already quoted (§ 123), and we will see in 
§137 below that direct syntax is also the natural escape hatch for those who 
really want to eliminate boundaries from phonology because of their dia-
critic character. 
Finally, the non-privative stance of SPE (§ 90) also contributed to the 
confusion: it led the literature to distinguish between "phonological 
boundaries" and "morpho-syntactic boundaries" (e.g. Devine & Stephens 
1976:286f, 1980:75). The former are those that are phonologically relevant, 
while the latter represent the exhaustive morpho-syntactic structure. SPE 
supposes both to be shipped to phonology, which means that at some point 
the subset of morpho-syntactic boundaries that are phonologically relevant 
mutate into phonological boundaries: "syntactic boundary markers are re-
placed by phonological ones, when significant, or deleted" (Saltarelli 
1970:37). 
Symptomatic for the unease with boundaries, then, is Greenberg 
(1970:10), who talks about "such shadowy but indispensable concepts as 
phonological word boundaries". Devine & Stephens (1976) conclude by 
striking the same sour note. 
 
(54) 
"All of this [the treatment of boundaries in early generative times] took 
place within a theoretical framework which seemed content to relegate 
boundaries to a sort of ill-defined intermundia between the syntax and the 
phonology" Devine & Stephens (1976:298) 
 
The frustration that shines through the quotes of this literature is 
largely due to the feeling that unbeloved boundaries are without alternative. 

114 
Chap 6: The life of boundaries in post-SPE times 
The following sections discuss attempts at breaking free from the strait-
jacket imposed by boundaries. 
 
133  8.2. Boundaries cannot be segments 
 
134  8.2.1. If not segments, what then? 
 
McCawley (1968) initiated another line of attack against boundaries and 
their diacritic character: he doubts that boundaries are segments. Recall that 
SPE accommodates boundaries in a particular sub-species of segments that 
is invented just for their purpose, i.e. [-segment] segments (§ 87). 
 
(55) 
"There are two aspects of this viewpoint [the general use of juncture by 
1968] which could be contested: the notion of juncture as a phonetic/ pho-
nemic (rather than morpho-phonemic) entity and the segmentalness of junc-
ture." McCawley (1968:52f) 
 
In § 136 below, arguments are reviewed which give flesh to this cri-
tique: boundaries do not behave like /p/, /u/ or any other regular segment. 
If this is true, then there are only two possible consequences: either 
there is no translation at all, or its output must be truly phonological ob-
jects, that is objects which are known in the phonology in absence of any 
issue related to the interface. 
We have already seen two approaches that follow the former option: 
structuralist Level Independence and Natural Generative Phonology. These 
not only deny the existence of translation (top-down: from morpho-syntax 
to phonology): they exclude the presence of any kind of morpho-syntactic 
information in phonology altogether. 
However, it is also possible to refuse translation while still allowing 
for morpho-syntactic information to bear on phonology: this is the so-called 
direct syntax approach that we have come across in Hyman's work which 
was reported in § 123, and also in the previous section where Kenstowicz & 
Kisseberth's worry was discussed. On this count, the structural description 
of phonological rules directly refers to morpho-syntactic categories (struc-
ture as much as labels). As we will see below (§ 136), this is what Pyle 
(1972) goes for after having shown that boundaries are meaningless diacrit-
ics, in any event not any kind of segment. 
The other option is to maintain both the influence of morpho-syntax 
on phonology and translation: the output of translation, then, must not be 
diacritics or rhetorically wrapped versions thereof (such as juncture pho-

What exactly is the output of translation, if any? 115 
nemes or SPE-type boundaries); rather, morpho-syntactic information must 
incarnate into truly phonological objects which exist in the phonology for 
phonology-internal reasons anyway. In the environment of SPE, truly pho-
nological objects are (real) segments and their ingredients, distinctive fea-
tures. These are then the only possible output of translation if the output 
must be non-diacritic. 
It is argued in Vol.2 (see also Scheer 2008a, 2009a,c) that this solu-
tion is correct: it is the heart of Direct Interface. The headstone of this op-
tion is the definition of the term "truly phonological": those who invent 
diacritics always invent some phonological-looking disguise and haste to 
assure that their diacritics are no diacritics: this is true for juncture pho-
nemes, [-segment] segment boundaries and later in the 80s for prosodic 
words and the like. The aforementioned independent and pre-theoretical 
criterion for alienness in phonology is discussed at greater length in § 405: 
something is truly phonological iff it can be observed in the phonology in 
absence of any morpho-syntactic conditioning. 
Understandably enough, though, this logical option was not pursued 
in the 70s when people were fed up with boundaries and diacritics: rather 
than trying to amend the existing system by modifying the output of trans-
lation, translation as such was thrown over board. This, it is argued below, 
is throwing out the baby with the bathwater.  
When reading through the literature of the 70s, I have come across 
one single attempt to translate morpho-syntactic information into a truly 
phonological item: Lass (1971). The following section introduces his prob-
lem and reasoning. 
 
135  8.2.2. Lass (1971): # is [-voice] 
 
Lass (1971) tries to get a handle on Old English fricatives, whose voice 
value is entirely predictable from their environment: fricatives are voiced 
between vowels and sonorants, but voiceless if geminate, adjacent to a 
voiceless obstruent or to a word boundary. Lass interprets geminates as a 
particular instantiation of the context where a voiceless obstruent precedes 
or follows. 
Voiceless consonants and # thus form a single distributional class in 
Old English. The question is whether it is a natural class as well. Since its 
action is to make adjacent fricatives voiceless and half of its members pre-
cisely are defined by the feature [-voice], Lass (1971:16) concludes that the 

116 
Chap 6: The life of boundaries in post-SPE times 
boundary # must also bear this feature: "# is really a voiceless obstruent 
(albeit one with no articulatory features besides voicelessness)." 
This enables Lass (1971:17) to write the rule under  (56) below, 
which earns the merit of avoiding a disjunctive statement where causes are 
obviously uniform. 
 
(56) 
Fricative voicing assignment 
[+ continuant] →[α voice] / [α voice] 
 
Lass (1971) is perfectly aware of what he is doing: he knows that 
making a boundary incarnate into a real feature, [-voice], is outlandish and 
unwarranted in the environment of SPE. 
 
(57) 
"Is it justified to talk in these terms, and refer to boundaries as something 
that segments can assimilate to?" Lass (1971:16) 
 
His answer is positive: "if in fact we can say that # is marked for 
[-voice], then the voicelessness of fricatives can reasonably be considered 
an assimilation" (Lass 1971:17). 
Needless to say, Lass' (1971) contribution to the question what ex-
actly boundaries are and what precisely is the output of translation re-
mained without any echo.  
 
136  8.2.3. Bankruptcy of boundaries and abandon of translation: Pyle (1972) 
 
Rather than merely another voice airing the discomfort and frustration with 
boundaries, the article by Pyle (1972) properly demonstrates their definitive 
bankruptcy. Pyle shows that it is absurd to treat boundaries as regular seg-
ments by pointing out the unwarranted predictions of this perspective. Just 
like Lass' contribution, though, Pyle's article did not have any impact on the 
contemporary literature. 
Were boundaries ordinary segments like /p/, /i/ etc., they would have 
to be subject to ordinary SPE rewrite rules. That is, they should be able to 
occur as any of the variables in the universal rule format X →Y / A__B. 
One such participation of boundaries in the rule component was indeed 
proposed: boundary mutation rules (§ 112). These place boundaries in X 
and Y (e.g. # →+), including the possibility for them to be eliminated. But 
what about cases where boundaries would be inserted by some rule ø →+ /
A__B? 

What exactly is the output of translation, if any? 117 
One could argue that SPE distributes boundaries according to mor-
pho-syntactic divisions. Therefore, no boundary can be inserted by rule in 
the middle of morphemes. However, this would require a filter that is active 
after the application of rules. The same filter could be said to be responsible 
for the absence of rules that change the linear order of boundaries in the 
way known from segmental metathesis +C →C+ / A__B (Pyle 1972:520). 
That is, strings where boundaries have been moved inside morphemes 
would be ill-formed. 
An additional convention would be needed in case some rule elimi-
nates an entire morpheme, thereby creating a cluster of boundaries. Hence 
A+B+C becomes A++C by the application of B →ø / A__C. Obviously, ++ 
is not a relevant linguistic object, and no rule ever appeals to it. But again, 
it could be argued that boundary clusters are eliminated by the general SPE 
convention that reduces any cluster of #s to two (§ 90), and which is ex-
tended to clusters of +s (that are reduced to one). 
However, the need for special provisions that regulate the life of 
boundaries, but not of regular segments, is precisely the point that Pyle 
(1972) makes: pretending that boundaries are just a little peculiar kind of 
segments is a trick. They are fundamentally different from /p/, /u/ etc. 
Still more serious than the special status of boundaries are the two 
following things that grammar cannot do to boundaries, but should be able 
to. Since anything can be turned into anything in SPE, and since boundaries 
are ordinary segments, some process should be able to transform a bound-
ary into a regular segment: + →a / C__C. Hence, say, /dog+s/ would come 
out as /dogas/. This, of course, is unheard of in natural language. 
The other impossibility that Pyle (1972:524) points out is the pecu-
liar "invisible" status that Chomsky & Halle (1968:364ff) assign to bounda-
ries. That is, rules are supposed to apply irrespectively of boundaries unless 
a specific boundary condition is mentioned in their structural description. 
That is, any rule which applies to the string XYZ also applies to X+YZ, 
XY+Z and X+Y+Z. If boundaries are not any different from regular seg-
ments, the latter should also be able to be "invisible" at times. But of 
course, there is no rule in natural language that ignores, say, /p/s unless a /p/ 
is explicitly mentioned in its structural description. 
Pyle (1972) identifies the fundamental crux as follows. 
 
(58) 
"All of the rules in question here would have the effect of making the char-
acterisation of formatives [i.e. boundaries] partly phonological. In these 
terms, the weakness of BM theory [boundary marker theory] is that it would 
allow phonological rules to redefine formatives in phonological terms." Pyle 
(1972:521) 

118 
Chap 6: The life of boundaries in post-SPE times 
In other words, in SPE boundaries represent morpho-syntactic in-
formation, but beyond the phonological effect produced are also supposed 
to be phonological objects with phonological behaviour (i.e. segments). It 
is this autonomous phonological life that is incompatible with their actual 
behaviour, and also with the special status that they are assigned ex cathe-
dra in SPE. 
 
137  8.2.4. When boundaries are bankrupt, the alternative is direct syntax: Pyle, 
Rotenberg, Hyman, Kenstowicz & Kisseberth 
 
The conclusion that Pyle (1972) draws from the bankruptcy of SPE-style 
boundaries is their non-existence. Phonology does make reference to mor-
pho-syntactic information, but this information is not translated into items 
that are inserted into the phonological string. Instead, Pyle advocates a 
transderivational mechanism whereby phonological rules "can look back in 
the derivation" and thereby detect the phonologically relevant morpho-
syntactic structure even though it has already been erased at earlier deriva-
tional stages (i.e. upon lexical insertion). 
This of course is at the expense of violating the basic principle of or-
dered rule application whereby the input of rule n+1 must be the output of 
rule n. In any case, though, Pyle's reaction on the failure of boundaries is a 
version of the direct syntax approach that we have already come across: he 
looks back into the derivation until he leaves phonology and recovers mor-
pho-syntactic structure. 
That phonology ought to make direct reference to morpho-syntactic 
structure and labels is also the conclusion of Rotenberg (1978), albeit fol-
lowing a somewhat different motivation: in a chapter called Against 
Boundaries, Rotenberg (1978) raises principled objections against the pres-
ence of any kind of objects in phonology that carry morpho-syntactic in-
formation. Particularly the diacritic character of boundaries is at stake, and 
a finger is pointed at phonologists, who do not behave according to regular 
linguistic (and scientific) standards: it would not cross the mind of any 
syntactician to invent some deus ex machina just in order to be able to refer 
to it when he is unable to do his job on syntactic grounds. That is, why do 
phonologists tolerate apples and bananas, when the idea of having aliens in 
their theory is judged outlandish by all other linguists? 
 

Conclusion 119 
(59) 
"Before I say anything, I note the naked fact that phonological and morpho-
logical rules have idiosyncratic domains of application: The morpheme, the 
syllable, the word, possibly the phrase, and the sentence come to mind. 
Rules of phonology and morphology are not very different from other kinds 
in this respect; syntactic and semantic rules of course show analogous 
boundedness, proving themselves to be limited to certain phrasal categories, 
sentences, utterances, or discourses. In syntax and semantics, this unavoid-
able observation is perceived as an incitement to discover properties of the 
various rules, or, better, of the various components to which they belong, 
from which their limitations will follow. A fatalistic and slightly empty 
solution to the problem, which no one even thinks to propose, would be to 
set up ad hoc boundary symbols flanking each sort of domain, which our 
rules can now pay attention to as it appears necessary. By doing merely this 
we seem to be condemning ourselves to a lack of insight into the several 
systems of rules. 
This same solution, however, is precisely the one generally accepted among 
phonologists. In order to implement it [«], one quickly finds the need for a 
great deal of theoretical machinery to place boundaries, to delete most of 
them when they pile up, and to ignore the rest of them when they get in the 
way. All of this comes from assuming that boundaries exist as items of vo-
cabulary on a par with the others." Rotenberg (1978:16f) 
 
Pyle (1972) and Rotenberg (1978) are thus representatives of the di-
rect syntax alternative that is born from the obvious inadequacy of bounda-
ries (Elordieta 2008:217ff also describes this evolution). Recall the discus-
sion of other proposals along these lines in §§ 123, 132: Hyman (1978:459), 
Kenstowicz & Kisseberth (1977:103ff, 1979:401ff, 421) and also Szpyra 
(1989:11) call for the elimination of translation, and its replacement by 
direct reference to morpho-syntactic structure and labels. The condensation 
of these isolated voices into a major player of interface theory in the 80s is 
discussed in § 407. 
 
138  9. Conclusion 
 
The discussion in the post-SPE period was completely monopolised by the 
representational side of the interface coin. The procedural management of 
morpho-syntactic information had just been introduced in SPE (its original 
mention in Chomsky et al. 1956 had had no real impact), but cyclic deriva-
tion went by and large unnoticed in the 70s until Lexical Phonology was 
established in the early 80s. The following chapter zooms in to this theory 
and to the procedural means of impacting phonology. 

120 
Chap 6: The life of boundaries in post-SPE times 
On the dominant representational front, thus, the question of bounda-
ries was discussed from top to bottom. At the end of the decade, a general 
feeling of dissatisfaction was widespread, but viable alternatives were not 
really fleshed out. Except perhaps the idea to abandon representational 
intervention in phonology altogether: what will later be known as direct 
syntax approaches was present in the literature in an embryotic from 
through several isolated and uncoordinated voices. 
Interestingly, though, the overall plot was set by the end of the 70s: 
all problems that are prompted by the representational question, and all 
logically possible solutions, were laid out. Up to the present day, all that 
followed is just more of the same, if using different vocabulary and a dif-
ferent rhetorical packaging. Let us review the three critical questions in 
their logical order. 
The first issue is whether or not phonology makes reference to mor-
pho-syntactic information. There can be no reasonable doubt that this ques-
tion is settled: higher level information informs phonology all over the 
place and is necessary for phonological computation to be able to run. 
The second issue is whether this reference is direct or through the 
mediation of translation. While direct reference could be reasonably advo-
cated in the 70s where modularity was not an issue, it is ruled out if modu-
larity is taken seriously: different modules do not speak the same language. 
While generative theory is a broad application of modularity to language, 
its first incarnation as SPE violates modularity in central areas (see § 99). 
The contours of modern modular theory were only defined in the 80s (see 
the Interlude § 586, the modular argument is discussed in §§ 649, 692). This 
is when Indirect Reference, the founding statement of Prosodic Phonology, 
appeared. While it did not explicitly rely on modularity (§ 414), it grew on 
the quarrel with direct syntax approaches (§ 407). 
If thus reference to morpho-syntactic information is needed but must 
not be direct, the final question is what it is made to. That is, what exactly 
is the output of the translational process? Boundaries do not qualify for the 
reasons shown by Pyle (1972). Nor do any other diacritics, for the same 
reason. Morpho-syntactic information can only incarnate into objects that 
are truly phonological, i.e. which are used by the phonology in absence of 
any interface issue. 
In principle, features are good candidates (see Lass' 1971 proposal 
regarding [-voice]). However, we will see in §§ 653, 663 below that a perva-
sive empirical generalisation points to the fact that melodic primes (i.e. 
everything that is located below the skeleton) are never carriers of morpho-
syntactic information in phonology. 

Conclusion 121 
We have come across other attempts to make the output of translation 
a piece of the vocabulary that is offered by whatever the current phonologi-
cal theory. The incarnation into phonemes that structuralists promoted 
failed as much as the incarnation into segments, the regular phonological 
currency of SPE. In both cases, arbitrary diacritics were rhetorically 
wrapped into a phonemic or a segmental guise. True incarnation into a real 
phoneme or a real segment is by and large outlandish: except Lass' (1971) 
attempt, nobody has ever found a truly featural identity of #. 
Hence there are only two solutions: either the entire reasoning re-
garding Indirect Reference and translation is wrong, or the attempts to in-
carnate morpho-syntactic information into truly phonological vocabulary 
have failed because phonological theories have not provided the right vo-
cabulary thus far. It is argued in Vol.2 that the latter conclusion is correct: 
rather than phonemes or segments, syllabic space ± a CV unit ± is the pho-
nological carrier of morpho-syntactic information. 
 


Chapter 7 
139  Lexical Phonology 
140 
1. Introduction 
 
The following pages introduce the basic ideas of Lexical Phonology in its 
classical stratal skin. The ambition is not to cover all aspects of the theory 
(this would go way beyond the scope of the book); rather, the focus rests on 
the treatment of extra-phonological information in phonology. 
More detailed introductions from an informed look-back position are 
offered by Giegerich (1999:7ff), McMahon (2000:35), Rubach & Booij 
(2003) and Bermúdez-Otero (forth a). Primary texts that have made impor-
tant contributions to the theory include Aronoff (1976), Allen (1978), 
Pesetsky (1979), Kiparsky (1982a,b,c, 1985a) Mohanan (1982, 1986), 
Rubach & Booij (1984, 1987), Rubach (1985, 1986, 1993), and an early 
overview is provided by Kaisse & Shaw (1985). 
Echoing the previous chapter, the presentation looks at Lexical Pho-
nology through the prism of boundaries in order to see to which extent the 
rather frustrating result of the post-SPE period can be relieved. Lexical 
Phonology achieves a maximal turnout from the procedural management of 
morpho-syntactic information. This is the exact opposite take of previous 
endeavour in the interface since the 19th century: the idea of procedural 
interface management was only introduced by Chomsky et al. (1956) (see 
§80); prior to this article, morpho-syntactic information was only hooked 
on some representational object that appears in the phonology. The maxi-
misation of procedural labour is also the opposite take of SPE, which 
(unlike in the segmental area) was by and large representational at the inter-
face (§§ 92, 107). Cyclic derivation (of which Bermúdez-Otero forth b pro-
vides an overview) is thus a specifically prominent feature of Lexical Pho-
nology, a theory that has shaped its face under the stratal banner for genera-
tions of phonologists. 
The following pages also try to show the price that has to be paid 
when the trade-off between representational and procedural interface man-
agement is shifted to the latter extreme. 
 

124 
Chap 7: Lexical Phonology 
141  2. Empirical foundations 
 
142  2.1. Affix classes and affix ordering 
 
The critical discovery for the establishment of Lexical Phonology was the 
existence of two classes of affixes in English, and of their non-arbitrary 
ordering with respect to the stem. Relevant generalisations for the former 
insight were made by SPE (Chomsky & Halle 1968:84ff, see § 92), for the 
latter by Dorothy Siegel's (1974) MIT dissertation. 
English affixes appear to fall into two classes whose members share 
a number of morphological and phonological properties that are not ob-
served for items of the other class. Table  (60) below shows class member-
ship (according to Mohanan 1986:16; see § 245 for discussion).32
(60) 
class membership of English affixes 
 
class 1 
class 2 
 
 
in- 
-ity 
-ic 
-ian 
-ory 
-ary 
-ion 
-ate 
-al 
-y 
 
(adjective-forming) 
(noun-forming) 
un- 
-ness 
-less 
-hood 
-like 
-dom 
-ful 
-ship 
-ed 
-ing 
 
(adjectival) 
(noun-forming) 
 
There are several diagnostics for class membership. On the morpho-
logical side, distributional evidence is brought to bear: class 1 affixes occur 
closer to the stem than class 2 affixes (this is where their name comes 
from). That is, affixes of both classes can freely attach to stems that already 
contain an affix of the same class (class 1: atom-ic1-ity1, univers-al1-ity1,
class 2: atom-less2-ness2, beauty-ful2-ness2, guard-ed2-ness2). In addition, 
class 2 affixes can hook on a class 1 affix (univers-al1-ness2). However, 
sequences of class 2 - class 1 affixes do not occur (*atom-less2-ity1,
32 The two classes at hand appear under different headings in the literature: level 1 
vs. level 2, stress-shifting vs. stress-neutral, neutral vs. non-neutral, cohering 
vs. non-cohering, cyclic vs. non-cyclic. In the remainder of the book, they are 
consistently referred to as class 1 vs. class 2. 

Empirical foundations 125 
*piti-less2-ity1, *guard-ed2-ity1 etc.). This observation is known as the affix 
ordering generalisation (Siegel 1974).33 
Another morphological property that sets the two classes apart is the 
ability of their members to attach to bound stems. Class 1 affixes can be 
concatenated to stems that have no independent existence (in-ert, in-trepid)
as well as to independently existing words (in-tolerable), while class 2 
affixes can only attach to words (un-aware, against *un-ert, *un-trepid). 
This morphological categorisation is mirrored in the phonology. In 
SPE, affix class distinction is expressed representationally: class 1 affixes 
are introduced by the + boundary, while class 2 affixes come with the 
"stronger" # boundary (see § 92). 
The phonological effects encountered most prominently concern 
stress placement, and this criterion is commonly admitted as the basic diag-
nostic for class membership. Class 1 affixes are reputed to be stress-
shifting, while class 2 affixes are stress-neutral. Classical examples are 
words such as párent, válid and átom, which appear with right-shifted 
stress when occurring with a class 1 suffix (parént-al, valíd-ity, atóm-ic), 
but conserve their lexical pattern when followed by a class 2 suffix 
(párent-hood, válid-ness, átom-ise). Further phonological affix class-based 
effects are reviewed as we go along. 
 
143  2.2. Cross-linguistic reality of affix classes 
 
A question of course is whether affix classes are a general phenomenon or 
merely a specific property of English. Although the equivalence is not 
complete, it is obvious that in English the two classes in question reflect 
different lexical strata in the historical development of the language: class 1 
affixes are of Romance origin, while class 2 affixes represent the Germanic 
heritage. 
The question whether affix classes exist in other languages is thus 
legitimate. Over the years, studies of other Germanic languages such as 
Dutch and German, but also of unrelated languages such as Malayalam 
(Dravidian, Mohanan 1986), Basque or Dakota (native American) have 
been mobilised in order to show that affix classes have a cross-linguistic 
reality and are therefore relevant for linguistic theory as such. The situa-
 
33 See for example Mohanan (1986:15ff), Szpyra (1989:40ff, 178ff), Giegerich 
(1999:11ff) for more detailed evidence. The empirical validity of affix ordering 
is further discussed in § 243 below. 

126 
Chap 7: Lexical Phonology 
tions found confirm the English pattern: typically, affix classes correspond 
to the import of various strata of vocabulary in different historical periods 
of the language. Also, the number of lexical strata varies across languages, 
and in principle is unbounded. Booij (2000 [1996]:297) offers an overview 
of these questions. 
Before looking at how the concordant phonological and morphologi-
cal effects of affix classes were condensed into Lexical Phonology, the 
following section recalls that the theory is also a result of a conceptual is-
sue, the abstractness debate. 
 
144  3. Lexical Phonology and the abstractness debate 
 
Lexical Phonology also roots in the abstractness debate that was initiated 
by Kiparsky (1968-73) and dominated the 70s (§ 125f, also Vol.1§307). 
This origin is made explicit in Kiparsky (1982a:34ff). 
Given the utterly overgenerating SPE mechanics, it was clear that the 
expressive power of the grammar needed to be marshalled somehow. Re-
strictions on possible underlying representations ((Revised) Alternation 
Condition, Kiparsky 1973a, see §§ 185ff) and the computational component 
(Strict Cycle Condition, Chomsky 1973, Kean 1974, Mascaró 1976, see 
§188) flanked Chomsky's (1970) cut-down of transformational power in 
morphology: Remarks on Nominalization discharge derivational morphol-
ogy from words such as reduction, transmission and recital. Since their 
formation is unproductive and semantically opaque, Chomsky argues, they 
are stored in the lexicon as a whole.34 
34 This move heralds the era of lexicalism, which will dominate the 80s, but is 
called into question in certain versions of minimalism (and in Distributed Mor-
phology). The lexicalist issue is discussed at greater length in §§ 539, 569. 
On the phonological side of this movement towards a less permissive 
grammar, the critical question is the attitude towards alternations that are 
subject to more or less heavy morphological conditioning. In the name of 
phonological realism, Natural (Generative) Phonology bans a rule from 
phonology as soon as its formulation involves the slightest bit of a morpho-
logical condition (see § 127). Contrasting with this radical position, Kipar-
sky tried not to throw out the baby with the bath water: abstractness is not 
evil in itself; therefore only a certain kind of abstractness needs to be done 
away with (see § 129 for examples). 

The general architecture of Lexical Phonology 127 
In this sense, Lexical Phonology may be viewed as an attempt to 
maintain as much morpho-phonology as possible in the computational de-
vice of phonology while cutting away the wildest outgrowths of SPE-
induced overgeneration. 
The early concern for overgeneration and a restricted grammar (of 
which Szpyra 1989:15ff, Giegerich 1999:2f, 100ff and McMahon 2000:35f 
provide an informed overview) was revived in the late 80s when Halle & 
Mohanan (1985) proposed a version of Lexical Phonology which untied 
much of the restrictions that the Lexicon had established: there was an in-
flation of the number of English strata, and derivations could "loop" back 
into earlier levels. McMahon (2000:50ff) considers this a major setback for 
the theory. 
 
145  4. The general architecture of Lexical Phonology 
 
146  4.1. Interactionism ± a new idea in the interface landscape 
 
The empirical and conceptual challenges mentioned, i.e. affix classes and 
affix ordering on the one hand, abstractness on the other, were condensed 
into what may be called classical Lexical Phonology. This move is de-
scribed at the outset of Kiparsky (1982a,b). 
The critical innovation that afforded to kill two birds with one stone 
was the idea of interspersing word formation rules with phonological rules: 
first you apply phonology to a piece, then you concatenate an affix, then 
you do some more phonology on the new string created, then you concate-
nate another affix etc. This procedural scrambling of morphology and pho-
nology was called interactionism later on. It was first proposed by Pesetsky 
(1979), Booij (1981), Williams (1981) and Kiparsky (1982a,b).35 
Interactionism indeed allows capturing the phonological effect of af-
fix classes, which was known since SPE, and the fresh facts from morphol-
ogy regarding affix ordering (this is where Kiparsky's 1982b title "From 
Cyclic Phonology to Lexical Phonology" comes from). 
Interactionism therefore certainly deserves to be recognised as the 
founding statement of Lexical Phonology (also in its self-understanding, 
e.g. Rubach & Booij 1984:1). The basic stratal architecture of the theory is 
 
35 See § 308 for discussion of Bresnan (1971), an early analysis along the lines of 
interactionism. 

128 
Chap 7: Lexical Phonology 
a consequence, as much as the introduction of morpheme-specific mini-
grammars. 
Interactionism is a new idea in the interface landscape: it is the only 
major concept that was not heralded in SPE. As a genuine contribution of 
Lexical Phonology, it will be assaulted by the generative mainstream in the 
80s (Halle & Vergnaud 1987a, see § 215), before making a swift career in 
current minimalist theory, where it appears as derivation by phase (§ 304) 
(see the summary of this evolution in § 676). 
 
147  4.2. Strata and their procedural order: how to kill two birds with one stone 
 
Interactionism accounts for affix ordering by assuming the existence of 
several procedurally defined levels (or strata ± both terms are used syn-
onymously in this book) that the morpho-phonological derivation runs 
through without being able to loop back: class 1 affixation is done at level 
1, hence before class 2 affixes are concatenated at level 2 (see § 152 for a 
schematic overview). This guarantees that a stem may take on a (number 
of) class 1 affix(es) and then move on to level 2 where class 2 affix(es) may 
join. The result are sequences of class 1 - class 2 affixes. The reverse order, 
however, cannot be generated because this would imply a return to level 1 
once an affix was added at level 2. 
A critical ingredient of Lexical Phonology is thus the existence of 
procedurally ordered strata. The prohibition of returning to an earlier stra-
tum is called level ordering. Note that level ordering is logically independ-
ent from interactionism; it is only with this additional stipulation that affix 
ordering can be derived. 
On the phonological side, two-step affixation allows for a two-step 
interpretation, hence capturing the insight of the phonological cycle: start-
ing with the stem, phonological interpretation works its way outwards 
through the affixes (see § 100). The outward-bound movement is guaranteed 
by the fact that level 1 accommodates class 1 affixes, and level 2, class 2 
affixes. Recall from § 141 that the former occur closer to the stem than the 
latter. 
Table  (61) below illustrates how interactionist Lexical Phonology 
works on the grounds of the familiar contrast between paréntal and párent-
hood (see § 93). 
 

The general architecture of Lexical Phonology 129 
(61) 
párent - parént-al vs. párent-hood in Lexical Phonology 
 
parent 
parént-al 
párent-hood 
 
lexicon  
parent 
parent 
parent 
level 1 concatenation  
² 
parent-al 
² 
 
stress assignment 
párent 
parént-al 
párent 
 
level 2 concatenation 
² 
² 
párent-hood 
 
rule application 
² 
² 
² 
 
Since the derivation strictly follows the path lexicon →level 1 →
level 2 without possibility of looping back, class 2 affixes may not come to 
stand closer to the root than class 1 affixes. 
Table  (61) shows that level ordering is needed on the phonological 
side as well: the stress assignment rule is only active at level 1. 
Párent-hood retains stress on the root because the stress rule is absent from 
level 2. Were párent-hood able to go through level 1 after -hood is concate-
nated, *parént-hood would be produced by the reapplication of the stress 
rule.36 
148  4.3. Morpheme-specific mini-grammars 
 
149  4.3.1. The stratal perspective supposes selective rule application 
 
An important consequence of strata is the split of phonology into two dis-
tinct computational systems. That is, the stratal model only works if there 
are distinct phonological mini-grammars, one for each stratum: phonology 
1 assesses the string that was concatenated at stratum 1 (and thus contains 
the stem plus class 1 affixes), while phonology 2 interprets the result of the 
concatenation that was made at stratum 2 (see  (62) below). Phonology 1 
and phonology 2 are thus morpheme-specific: they are designed to apply to 
strings that are only made of a subset of morphemes. 
The example under  (61) shows why the stratal approach requires dis-
tinct morpheme-specific mini-phonologies. The class 1 affix -al is concate-
nated at level 1, while the class 2 affix -hood comes in at level 2. In order to 
 
36 The possibility of looping back to previous levels was actually proposed by 
Halle & Mohanan (1985), together with an inflation of strata for the analysis of 
English. This option unties the bonds that strata are supposed to introduce ± it is 
a kind of SPE system in an empty stratal shell that overgenerates as wildly as 
before (see § 144). For that reason, the model has not found many followers: 
McMahon (2000:50ff) provides an overview of the critique. 

130 
Chap 7: Lexical Phonology 
achieve the correct result, stress assignment needs to apply at level 1 ± but 
it must not apply at level 2. Were it also active after the concatenation 
of -hood, *parént-hood with regular penultimate stress would be produced. 
Therefore the phonological computation that assesses level 1 strings 
must be different from the one that interprets level 2 strings. In classical 
Lexical Phonology where computation is done in terms of rules, this con-
trast is expressed by the fact that some rules are present at level 1, but ab-
sent at level 2 (this is the case of stress assignment in our example), or vice-
versa.37 That is, the set of rules that applies to level 1 strings is distinct from 
the set of rules that interprets level 2 strings. 
Rules are therefore identified as level 1 or level 2 rules: they must 
"know" where they apply. This is done by some lexical specification (do-
main assignment, see § 151). 
 
150  4.3.2. Underapplication is achieved by distinct mini-grammars and level 
ordering 
 
Distinct morpheme-specific mini-grammars are needed because a subset of 
the phonological computation which is active in the language (stress as-
signment under  (61)) must not apply to strings that are created by the at-
tachment of a subset of affixes: class 2 in our example.38 
What affix class-based phenomena require, thus, is the underapplica-
tion of phonology: a subset of the active phonology of the language must 
be precluded from applying to strings that were created by the attachment 
of a certain affix class. 
In a stratal perspective, this effect is achieved conjointly by the split 
of phonology into distinct morpheme-specific mini grammars and level 
ordering. Both are indeed necessary: § 147 has shown that distinct mini-
grammars are toothless in absence of level ordering (hence if the derivation 
may loop back to previous levels). On the other hand, level ordering alone 
is unable to enforce underapplication: were the stress rule present at level 2, 
the incorrect *parént-hood would be derived. 
 
37 In more recent constraint-based environments, the contrast between two distinct 
mini-grammars is expressed in terms of different constraint rankings, which are 
typically achieved by "constraint reranking" between strata (see § 473). 
38 There are also phenomena that require the non-application of certain phono-
logical processes to strings that were created by the concatenation of class 1 af-
fixes (so-called level 2 rules). These are discussed in § 166. 

The general architecture of Lexical Phonology 131 
151  4.3.3. How to make mini-grammars different but not waterproof: domain 
assignment 
 
In addition to distinct computational systems on the phonological side and 
level ordering, classical Lexical Phonology features a third device that par-
ticipates in achieving underapplication: domain assignment (which Mo-
hanan 1986:21 calls the Stratum Domain Hypothesis). That is, rules are 
augmented with a diacritic that specifies their domain of application; they 
thus identify as level 1 or level 2 rules. 
Domain assignment is not something that the stratal environment re-
quires. Rather, it is a particular view on how mini-grammars should be 
organised. In order to be able to maintain a certain unity of grammar, clas-
sical Lexical Phonology holds up a single pool of rules. According to 
Mohanan & Mohanan (1984) and Mohanan (1986:13f), these then freely 
"intervene" at a particular stratum or postlexically: rules may apply in any 
location, and any location may host any rule. Also, a given rule may hap-
pily apply in several locations, for example at stratum 1 and postlexically, 
but not at stratum 2. 
In practice, the effective application of rules in different locations is 
an empirical question: rules apply where their contribution is needed. How-
ever, since they do not apply everywhere (this is the whole point of under-
application), they have to know where exactly they intervene. This infor-
mation is recorded by a diacritic, domain assignment. 
Were a single pool of rules not a virtue by itself, domain assignment 
could be dispensed with. The alternative, then, would be to accept that there 
are two distinct mini-grammars which do not "see" each other, and where 
the rules of one stratum do not entertain any relationship with the rules of 
another stratum, notwithstanding the presence of the same rule in different 
locations. This option makes the distinct computational systems water-
proof, as opposed to Mohanan's non-waterproof mini-grammars: in Mo-
hanan's system, the same rule-individual intervenes in distinct strata, while 
different clones of the same rule are active in different strata in the water-
proof option. In one case there is one single pool of rules, while in the other 
two distinct pools act without their members ever "seeing" each other.39 
39 Whether mini-grammars are waterproof or not is an issue in OT, where it is 
known as the "co-phonology proliferation problem" (Orgun 1996a:114, see 
§492). It was also discussed in the context of Kiparsky's (1982a,b) attempt to 
derive the Strict Cycle Condition (SCC) from the Elsewhere Condition (see 
§190). Mohanan & Mohanan (1984) argue against two independent set of rules 
on the grounds of rules that apply both in the Lexicon and postlexically. 

132 
Chap 7: Lexical Phonology 
152  4.4. The general picture: interactionist Lexicon →syntax →postlexical 
phonology 
 
Illustrating the above discussion, table  (62) below shows the general archi-
tecture of classical Lexical Phonology. 
 
(62) 
underlying representations: underived roots 
  
 
 
Lexicon 
stratum 1 
morphology 
 
stratum 1 
phonology 
 
1. morphological 
word-formation 
rules 
2.
stratum 2 
morphology 
 
stratum 2 
phonology 
 
phonological rules 
that are sensitive to 
morphological 
information 
stratum n 
morphology 
 
stratum n 
phonology 
 
Output: words 
(i.e. items that have a meaning and a pronunciation)
syntax 
 
postlexical module 
 
1. phonological rules that are sensitive to syntac-
tic information 
 
2. "automatic" phonological rules, i.e. which are 
sensitive to phonological information only 
 
Output: sentences 
(i.e. that have a meaning and a pronunciation) 
 
towards phonetic interpretation 
 
  
 
 
This overall architecture encompasses the labour that is classically 
attributed to phonology, morphology and syntax. For the time being, only 

The general architecture of Lexical Phonology 133 
the interaction between morphology and phonology (interactionist) was 
considered: the output of stem-affix concatenation and (phonological) in-
terpretation of the strings created are words. Words are stand-alone items 
that possess a pronunciation and a meaning. Therefore the word factory is 
called the Lexicon: it produces words. It is opposed to the postlexical area, 
which is discussed below. 
For the time being, it is important for the discussion below to make 
explicit what a (lexical) stratum (or level) is in Lexical Phonology. The 
Lexicon is made of strata, and a stratum is the association of a certain type 
of concatenative activity (the attachment of affixes that belong to a given 
affix class) with a certain type of phonological (and semantic) interpreta-
tion (the computation of exactly the string that was created by the concate-
native activity described). Within each stratum, concatenation necessarily 
precedes interpretation, and the phonological grammar that assesses the 
string is necessarily different from the phonology that interprets strings at 
other strata (multiple mini-grammars). 
In the remainder of this book, the word "stratum" (or "level") is used 
only in this sense, namely when the stratal perspective is opposed to the 
classical inverted T model where all concatenation precedes all interpreta-
tion (§ 86). Terminology is relevant here because over the years "strata" and 
"stratal" have become a kind of cover term which makes broad reference to 
Lexical Phonology as such or, as we shall see, simply to the existence of 
multiple mini-grammars.40 
Let us now look at the major division that appears under  (62), which 
was not discussed yet: the Lexicon is followed by a postlexical module. 
 
153  4.5. Praguian segregation: lexical vs. postlexical phonology 
 
154  4.5.1. The birth of postlexical phonology: Rubach (1981) 
 
It was mentioned in § 146 that Kiparsky (1982a,b) takes Lexical Phonology 
to be the synthesis of three strands: affix classes, affix ordering and the 
abstractness debate. In actual fact, he also quotes a fourth source: cyclic 
phonology. This is in reference to Mascaró (1976): Kiparsky will adapt his 
Strict Cycle Condition to the stratal environment (see § 188). 
 
40 Halle & Vergnaud (1987a) for example use the word "stratum" in the latter 
sense (see § 235): even though they are anti-interactionist and hence have done 
away with strata, they call their mini-grammars (cyclic and word-level) strata. 

134 
Chap 7: Lexical Phonology 
In this context, Kiparsky quotes Rubach (1981). As far as I can see, 
Rubach (1981) is to be credited for the formal introduction of Praguian 
segregation (more on this term in the following section) into generative 
theory. On the backdrop of the systematic difference between regular and 
surface palatalisation in Polish, Rubach (1981:18ff) concludes that phono-
logical rules should be split into two separate and derivationally ordered 
blocks: first all regular rules apply; the output of this computation is then 
further assessed by "automatic" or surface-oriented rules (such as the dis-
tribution of aspiration in English, or surface palatalisation in Polish). 
This is the birth of postlexical rules, which is how phonological rules 
that apply to chunks above the word level are called in Lexical Phonology 
and up to the present day. They are opposed to word-constructing lexical 
rules, which Lexical Phonology places in the Lexicon.  
Note that the distinction between lexical and postlexical rules is dif-
ferent from the contrast that opposes level 1 and level 2 rules. While 
Rubach (1981) only distinguished between the former, fully-fledged Lexi-
cal Phonology implements both oppositions (see § 152). 
Finally, it is useful for the discussion below to be explicit on the fact 
that SPE's word-level phonology (§ 104) has no equivalent in stratal Lexical 
Phonology. It is not the same thing as postlexical phonology at all since it 
concerns only the word-level: SPE explicitly excludes the application of 
word-level rules to chunks that are larger than the word (§ 105). A specific 
version of Lexical Phonology will reintroduce word-level rules later on (in 
the guise of post-cyclic lexical rules, see § 194). 
In sum, then, Lexical Phonology accommodates (at least) three dis-
tinct computational systems: (at least) two in the Lexicon (level 1 and level 
2), and one more after syntax has applied (postlexical phonology). There is 
an important difference in kind regarding the way in which the three com-
putational systems are opposed, though. Lexical strata (i.e. levels) are dif-
ferent because of their morpheme-specificity: we are facing morpheme-
specific mini-phonologies. By contrast, the opposition between the pos-
tlexical and the lexical system is entirely unrelated to the quality of the 
chunks considered: it is their size alone that matters. Computational sys-
tems are thus either morpheme-specific (class 1 vs. class 2) or chunk-
specific (smaller chunks, i.e. morphemes, vs. bigger chunks, i.e. words). 
It is argued below (§ 212) that the introduction of multiple mini-
grammars (together with interactionism) is the genuine footprint of Lexical 
Phonology that makes this theory different from all others. Historically, 
then, Rubach (1981) was the first to depart from the unitary block of rules 

The general architecture of Lexical Phonology 135 
that was inherited from SPE ± this is how the idea of multiple mini-
grammars entered the scene. 
 
155  4.5.2. Praguian segregation: syntax and morphology are different 
 
Regarding the relationship between syntax and morphology, Lexical Pho-
nology follows the traditional view whereby the two components are dis-
tinct computational systems with distinct grammars and possibly distinct 
vocabulary. Lexical Phonology grants a formal status to this perspective: it 
introduces an architectural distinction between the Lexicon (i.e. morphol-
ogy, where words are constructed) and syntax (where sentences are con-
structed). Only is the order reversed: on the traditional view, syntax is done 
first, and its output is the input to morphology.  
The roots of the architecture that Lexical Phonology promotes are ul-
timately phonological: Booij (1997:264, note 3) traces the distinction be-
tween lexical and postlexical phonology back to the Prague Linguistic Cir-
cle (Circle 1931) where an distinction is made between the phonology of 
words (phonologie du mot) and the phonology of sentences (phonologie de 
la phrase). Below I therefore use the term Praguian segregation in order to 
refer to this conception (rather than the theory-laden notion of postlexical 
phonology). 
Whether syntax and morphology are distinct computational systems 
or one is a resident issue in linguistics that has gained renewed interest in 
recent years (see § 537, also on (anti-)lexicalism). 
 
156  4.5.3. Morphologically conditioned vs. exceptionless rules 
 
The difference between word- and sentence phonology defines the position 
of Lexical Phonology in the debate regarding morpho-phonology (see 
§§ 126, 129): how much morphological information, if any, should be al-
lowed for in the statement of phonological rules? Following the take of 
Lexical Phonology, all that can be expressed by strata, but no more. 
The effect of morphological conditions on phonological rules is that 
the rules in question appear to have exceptions: the phonological conditions 
may be met, but the process may still not go into effect (underapplication: 
the stress pattern of párent-hood is non-penultimate and hence opaque). 
On the other hand, there are phonological processes that apply any 
time their phonological conditions are satisfied, i.e. irrespectively of mor-

136 
Chap 7: Lexical Phonology 
phological conditions. These are then exceptionless (or automatic, i.e. the 
equivalent of natural P-rules in Natural Generative Phonology, see § 127). 
Lexical Phonology expresses this opposition in terms of the Praguian 
distinction between word-level and sentence-level phonology: the former is 
subject to morphological conditions because it builds words and thus inter-
acts with morphology, while the latter describes the life of adult words, 
hence with no morphology intervening anymore. 
Finally, Lexical Phonology grants an architectural and procedural re-
ality to the Praguian observation: word- and sentence phonology are done 
at autonomous derivational levels where either morphemes or words are 
concatenated. The question, then, to be discussed in § 158 below, is why in 
the architecture of Lexical Phonology morphology bears on the phonology 
of words (via interactionism), while syntax does not influence the phonol-
ogy of sentences in the same way (postlexical phonology is non-
interactionist, i.e. non-cyclic). 
 
157  4.5.4. Lexical vs. postlexical phonology: respective conditioning factors 
 
Beyond the Lexicon, words serve as the input to syntax. On the account of 
Lexical Phonology, syntax concatenates words, not morphemes; therefore 
the internal structure of words is invisible to syntax (no look-back, see 
bracket erasure in § 174). 
Upon the availability of syntactic structure, i.e. after syntax has ap-
plied, the string is assessed by the postlexical block of (phonological and 
semantic) rules. This is Praguian sentence phonology, which concerns 
processes that are either insensitive to any kind of extra-phonological in-
formation (morphological and syntactic alike), or that are conditioned by 
syntactic structure alone (the rule makes reference to syntactic informa-
tion). In the latter case, they could not apply in the Lexicon because syntac-
tic information had not yet been constructed. Conversely, rules that are 
sensitive to morphological information cannot apply postlexically: morpho-
logical structure is erased at the end of each stratum (by the aforementioned 
bracket erasure, see § 174 below). 
According to this system, lexical phonological processes interpret 
morphological structure and allow for exceptions, i.e. may be opaque, 
while postlexical rules interpret syntactic structure and are exceptionless. 
In sum, thus, Lexical Phonology splits the grammatical architecture 
into two (almost) waterproof components: morphology (the Lexicon) and 
syntax; both concatenate pieces, and each has its own associated phonol-

The general architecture of Lexical Phonology 137 
ogy. Neither the two concatenative devices nor the two associated phonolo-
gies need to share the same computation (they could in principle, but in 
practice they never do). 
 
158  4.5.5. Cyclic vs. postlexical phonology: no cyclic interpretation of words 
 
In reference to SPE (§ 105), rules that apply in the Lexicon are called cyclic 
in Lexical Phonology because they are said to apply cyclically, i.e. along 
the lines of the transformational cycle (§ 100). At the same time, they apply 
according to the interactionist architecture of the Lexicon, that is in alterna-
tion with concatenative activity. Cyclic interpretation in Lexical Phonology 
thus takes on a meaning that it did not have in SPE: it is interactionist 
(more on this in § 188 below when Kiparsky's 1982a,b Strict Cycle Condi-
tion SCC is discussed). 
By contrast, rules that apply to the string that is returned by syntax 
are called postlexical and are non-interactionist: there is no interleaving 
with the concatenative activity of words. In the terminology of Lexical 
Phonology, postlexical rules are thus non-cyclic. 
The contrast between lexical phonology that is interactionist and pos-
tlexical phonology that is not departs from SPE's conception of cyclic deri-
vation, which concerns morphemes as much as words ("the principle of the 
transformational cycle [«] appl[ies] to all surface structure whether inter-
nal or external to the word", Chomsky & Halle 1968:27, see § 105). Inter-
estingly, Lexical Phonology imposes the non-cyclic interpretation of words 
without discussion. As may be seen in the following quote, Kiparsky 
(1982b) simply decrees that the concatenation of words is not cyclic. 
 
(63) 
"The former, the rules of lexical phonology, are intrinsically cyclic because 
they reapply after each step of word-formation at their morphological level. 
The latter, the rules of postlexical phonology, are intrinsically noncyclic." 
Kiparsky (1982b:131f, emphasis in original) 
 
The question why sequences of morphemes should, but sequences of 
words should not be derived cyclically is an important issue that has re-
ceived almost no attention as far as I can see. Further discussion is provided 
in §§432, 786 below in the light of modern phase theory (the word-spell-out 
mystery). 
 

138 
Chap 7: Lexical Phonology 
159  4.6. Definition of interpretational units 
 
160  4.6.1. From brackets to strata 
 
A question that comes with cyclic derivation is how cyclic boundaries are 
defined. Every cycle delineates a portion of the linear string that is inter-
preted by phonology (and semantics).  
In SPE, these interpretational units are delineated by brackets, which 
roughly coincide with morpheme boundaries but in fact are only inserted at 
every transition of major categories (noun, verb, adjective, § 103).41 Lexical 
Phonology has a different take on the definition of interpretational units: 
instead of a rigid calculus in terms of morpho-syntactic labels, affix classes 
define the chunks of the linear string to which phonological (and semantic) 
computation applies. That is, all affixes of the same affix class are concate-
nated at a given stratum, and the resulting string is then interpreted.  
In Lexical Phonology, strata are thus the relevant interpretational 
units. In order to illustrate the contrast with SPE, consider the word ori-
gin-al-ity, which identifies as a three-cycle item [[[origin]N al]A ity]N in 
SPE, while it represents only one single interpretational unit in Lexical 
Phonology (both -al and -ity are stress-shifting class 1 affixes): [ori-
gin-al-ity]. 
The question how cyclic boundaries are defined runs through the en-
tire literature: different theories provide (slightly) different answers. In 
modern times, the issue is called phasehood: the question how phase 
boundaries are defined is at the forefront of the research agenda (§ 773) 
since Chomsky's (2000a et passim) derivation by phase has admitted an 
interactionist architecture (see § 304). 
 
161  4.6.2. Interactionism reconciles cyclic derivation with modularity 
 
In SPE, cyclic (inside-out) interpretation is assured by brackets that are 
inserted into the linear string and guide the derivation as it proceeds (§ 95). 
Brackets are needed because all concatenation is completed before interpre-
tation begins (§ 86): like a sponge they store morpho-syntactic structure 
(and also the labels associated) in order to make it available in phonology. 
 
41 Hence the word theatr-ic-al-i-ty identifies as [[[theatr]N ic + al]A i + ty]N: five 
morphemes make three cycles. Cyclic structure is thus a proper subset of mor-
pho-syntactic structure in SPE, even though most of the time both coincide. 

The general architecture of Lexical Phonology 139 
This raises the issue of untranslated morpho-syntactic information in pho-
nology, which should be prohibited on modular grounds (see §§ 98f). 
In short, the prohibition of intertwining concatenative and interpreta-
tional activity that was in place in SPE enforces brackets, which are incom-
patible with modularity. Interactionism does away with this prohibition and 
therefore opens the way for an entirely different perspective: interpreta-
tional units (i.e. the chunks of the string to which phonological computation 
applies) are delineated by strata, rather than by brackets. Unlike brackets, 
strata are procedurally defined: at stratum 1, only the root and class 1 af-
fixes exist ± class 2 affixes have not yet been concatenated. Therefore, at 
any given point in the derivation, phonological computation simply applies 
to the maximal string that is currently available.  
Table  (64) below depicts the two ways of implementing inside-out 
interpretation. 
 
(64) 
organisation of inside-out interpretation 
 
a. brackets (SPE) 
interpretation along the fully constructed morpho-syntactic spine 
 
[[[root] class 1 affixes] class 2 affixes] 
 
PF, LF 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
PF, LF 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
PF, LF 
 
 
 
 
 
 
 
 
 
 
 
 
 
b. interactionist/stratal perspective (Lexical Phonology) 
interpretation upon concatenation 
 
1. [root] →PF, LF 
2. [root - class 1 affixes] →PF, LF 
3. [root - class 1 affixes - class 2 affixes] →PF, LF 
 
In modern phase theory (Chomsky 2000a et passim, see §§ 304, 771), 
one would say that spell-out occurs at every phase head: phases define in-
terpretational units. The interactionist perspective of Lexical Phonology 
(and later on of derivation by phase) thus makes SPE-type brackets super-
fluous: at no point in the derivation does phonological computation process 
phonological aliens such as brackets because interpretational units are de-
lineated procedurally, rather than representationally.  
In other words, interactionism reconciles inside-out interpretation 
with modularity: it dispenses with the presence of untranslated morpho-
syntactic information in phonology (more on this in §§ 170, 305, 680). This 
is an important consequence of interactionism. Rubach (1984:225) for ex-

140 
Chap 7: Lexical Phonology 
ample is explicit on the fact that interactionism replaces brackets, but as far 
as I can see the advance that this represents from the modular point of view 
is not a concern in the literature. 
 
162  5. The analysis of affix classes and its proceduralisation 
 
Affix class-based phenomena in general, and those that are found in Eng-
lish in particular, have already been used above in order to illustrate the 
behaviour of SPE and Lexical Phonology. They will escort the reader all 
through the book since they are a valid testing ground for interface theories: 
affix class-based phenomena are historically relevant, well known and ac-
cessible to all readers. The basic facts are introduced in § 163 and § 166 
below. 
It was already mentioned in § 140 that Lexical Phonology procedural-
ises the interface: morpho-syntactic information that was transmitted to the 
phonology by representational devices (boundaries and brackets in SPE, 
see §§ 92, 95, 107) is now encoded procedurally. Roughly speaking, bounda-
ries (like brackets) are replaced by lexical strata. 
We have seen in § 97 that boundaries and brackets are orthogonal in 
SPE: while the former may be modified during phonological computation, 
the latter are set in stone and will always guide the cyclic derivation 
through the string. In this environment, SPE proposes a representational 
management of affix classes: class 1 affixes come with a + boundary, while 
a # boundary accompanies class 2 affixes (§ 92); rules then make reference 
to #, which either blocks or triggers the process at hand. 
In Lexical Phonology by contrast, affix classes have a procedural 
management: they are different because they belong to different strata, 
which means that they are concatenated at different derivational stages. 
Obviously there is no point in encoding affix class identity twice, i.e. 
once representationally (by boundaries) and another time procedurally (by 
strata). Since the whole point of Lexical Phonology is to capture morpho-
logical (affix ordering) and phonological effects of affix classes by (proce-
dural) interactionism, the representational treatment of SPE had to go. 
Lexical Phonology is thus characterised by the proceduralisation of the 
analysis of affix classes.
The competition between procedurally ordered strata and boundaries 
is perfectly explicit in the earliest source of Lexical Phonology. 
 

Rule-blocking boundaries are eliminated altogether 141 
(65) 
"To intrinsically order the levels of the morphology as they apply and to 
identify them uniquely with boundaries at the same time, would be overkill, 
since the boundaries themselves can do the work of ordering affixation 
processes. [«] I will, therefore, take the perhaps uncautious step in this 
section of assuming that boundaries are not linguistic units, and will gener-
ally assume an ordering hypothesis." Pesetsky (1979:16f) 
 
The detail of this general evolution, however, needs to be sorted out. 
The following pages discuss the new procedural management of affix class-
based phenomena. 
 
163  6. Rule-blocking boundaries are eliminated altogether 
 
164  6.1. Rule-blocking boundaries translate as level 1 rules 
 
In order to see the cleaning-up effect that Lexical Phonology produces on 
the representational side, it is useful to follow the distinction between rule-
blocking and rule-triggering boundaries that was introduced in § 51. Let us 
first look the former. A rule-blocking boundary is a specific morpho-
syntactic division that prevents a phonological process from going into 
effect, while this process would have applied in its absence. 
In Lexical Phonology, rule-blocking boundaries are useless alto-
gether. This was already shown in § 147: on the SPE-analysis of the contrast 
between paréntal and párenthood, stress assignment is blocked by #, which 
characterises class 2 affixes. In a stratal environment, however, the deriva-
tion runs without contribution of any boundary. That is, underapplication to 
class 2 strings is assured by the conjoint action of distinct morpheme-
specific mini-grammars and level ordering (§ 150). Crucially, stress assign-
ment is a level 1 rule in this environment. 
English Trisyllabic Shortening (or Laxening) may provide further il-
lustration of the pattern. Notwithstanding the fact that there is good reason 
to doubt that this process is synchronically active (see note 42), it was a 
flagship of the Lexical Phonology literature (e.g. Kiparsky 1982a:35ff, 
Mohanan 1986:18ff, see also Myers 1987). 
Trisyllabic Shortening is a process whereby the long vowel or diph-
thong of bisyllabic words is shortened when a class 1 suffix is added as 

142 
Chap 7: Lexical Phonology 
under (66a). By contrast, class 2 suffixes as under (66b) do not provoke any 
reaction.42 
(66) 
Trisyllabic Shortening (or Laxening) 
 
non-trisyllabic item 
trisyllabic item 
 
a. class 1 suffix sane 
[sejn] 
san-ity 
[sQnɪtɪ]
Christ 
[krajst] 
Christ-ian 
[krIstÉS´n] 
 
b. class 2 suffix maiden 
[mejd´n] 
maiden-hood 
[mejd´nhəd] 
 
wild 
[wajld] 
wild-ness 
[wajldnEs] 
 
An informal description will thus state that class 2 suffixes prevent 
Trisyllabic Shortening from applying. In SPE, this blocking effect is attrib-
uted to the presence of a # boundary that comes with class 2 affixes: the 
context of the phonological rule which is responsible for Trisyllabic Short-
ening requires that the morpheme break be represented by a + boundary 
(Chomsky & Halle 1968:180). 
On the other hand, the procedural architecture of Lexical Phonology 
does not need to appeal to boundaries. Trisyllabic Shortening is a level 1 
rule. As is shown under  (67) below, san-ity1 is pieced together at level 1, 
hence shortening will apply. By contrast, level 2 -hood2 has not yet been 
attached to maiden when shortening applies; therefore maiden remains 
unmodified: the trisyllabic condition is not met. 
A third example, less controversial than Trisyllabic Shortening, is na-
sal assimilation in the two prefixes un- and in-: the nasal of the latter takes 
on the place of articulation of the following obstruent (im-possible,
i[ŋ]-credible), while the nasal of the former remains (or may remain for 
certain speakers) unaltered (u[n]-predictable, u[n]-comfortable). 
 
42 Trisyllabic Shortening encounters quite a number of counterexamples such as 
obese [çwbiis] - obese-ness [çwbiisnEs] (class 2), which should but does not re-
act when the class 1 suffix -ity is added: obes-ity [çwbiisitɪ]. A given root may 
even produce reacting items along with derivatives that remain unaffected: 
wild-ness [wajldnEs] and wilderness [wIldånɛs] bear the same class 2 suffix but 
show contrasting behaviour. 
 
Also, Trisyllabic Shortening does not appear to be productive, and additional 
doubt has been cast on its synchronic reality by psycho-linguistic evidence. 
Hayes (1995a) and Green (2007:172ff) provide an informed review of the 
status of Trisyllabic Shortening today. Relevant literature that is concerned with 
the phenomenon since the 70s is mentioned in note 28. 

Rule-blocking boundaries are eliminated altogether 143 
(67) Trisyllabic Shortening in Lexical Phonology 
 
san-ity 
maiden-hood 
 
 
lexicon  
sejn 
mejd´n
level 1 
concatenation  
sejn-ɪtɪ
²
Trisyll. Short. 
sQn-ɪtɪ
²
level 2 
concatenation 
² 
mejd´n-hʊd
rule application 
² 
² 
 
 
Independent diagnostics such as the ability to attach to bound stems 
identify in- as a class 1 affix, while un- is class 2 (in-ert, in-trepid, but
*un-ert, *un-trepid etc., see § 142). In terms of SPE, as before, the # bound-
ary that comes with class 2 un- blocks the application of the nasal assimila-
tion rule. In Lexical Phonology, on the other hand, nasal assimilation is a 
level 1 rule. The contrastive behaviour of the two prefixes follows, as is 
shown under  (68) below. 
 
(68) nasal assimilation in Lexical Phonology 
 
im-possible 
un-predictable  
 
lexicon 
 
possible 
predictable 
 
level 1 
concatenation  
in-possible 
² 
 
 
nasal assimilation 
im-possible 
² 
 
 
level 2 
concatenation 
² 
un-predictable  
 
rule application 
² 
² 
 
 
The logic is as before: level 2 affixes escape whatever the process at 
hand (which is thus "blocked") because this process is not active anymore 
by the time they are concatenated. Level 1 phonology underapplies to class 
2 strings. 
In sum, rule-blocking boundaries translate as level 1 rules in a stratal 
environment. 
 
165  6.2. Complete and unintended elimination of boundaries 
 
The previous section has shown that the stratal account of rule-blocking 
boundaries does not mention any boundary anymore. The boundary-
eliminating effect of the stratal architecture is clearly identified in the litera-
ture: Mohanan (1982:24f, 94), Kiparsky (1982a:11, 1982b:131), Halle & 
Mohanan (1985:64), Szpyra (1989:24, 27) and Mohanan (1986) are explicit 
on the fact that boundaries are completely banned from phonological rules 
in Lexical Phonology.. 

144 
Chap 7: Lexical Phonology 
(69) 
"In Lexical Phonology, boundary symbols are replaced by references to the 
beginning and end of forms, using morphological bracketing, and no special 
conventions are needed for blocking the application of rules." Mohanan 
(1986:20) 
 
"Boundary symbols such as + and # can be entirely eliminated from phono-
logical representations. The requisite information is carried by the appropri-
ate ordering of levels and the morphological bracketing of the string." Ki-
parsky (1982b:139) 
 
The quote below shows that the eradication of boundaries was indeed 
understood as an unintended side effect, rather than as a goal of the theory. 
 
(70) 
"Originally postulated in order to account for morphological distribution, the 
conception of lexical strata also yields a way of dealing with morphological 
information in phonology. SPE makes use of boundary symbols like +, # 
and ## to refer to morphological information. Instead of using such sym-
bols, the phonological rules in Lexical Phonology (a) refer to the beginning 
and the end of morphological forms, and (b) are specified for their domain 
of application in terms of lexical strata." Mohanan (1986:18) 
 
In the last part of the quote, Mohanan points out that the elimination 
of boundaries is achieved at the expense of two new devices: the diacritic 
specification of every rule for the level(s) at which it applies (domain as-
signment, § 151), and edge-indicating brackets (interestingly, no mention is 
made of the split of phonology into multiple mini-grammars § 148, and of 
level ordering § 147).  
Brackets as used in Lexical Phonology (and bracket erasure) are in-
troduced on the following pages on the occasion of the discussion of rule-
triggering boundaries. 
 
166  7. Rule-triggering boundaries: brackets and bracket erasure 
 
167  7.1. English nasal cluster simplification 
 
Let us now consider rule-triggering boundaries and their fate in Lexical 
Phonology. Recall from § 51 that a rule-triggering boundary represents a 
specific morpho-syntactic division which triggers the application of a pho-
nological process that would not have gone into effect in absence of this 
division. 

Rule-triggering boundaries: brackets and bracket erasure 145 
English features three processes of this kind, all of which control the 
simplification of a stem-final cluster that contains a nasal (see § 94). In all 
cases, the cluster is simplified word-finally and before class 2 suffixes, but 
survives before class 1 suffixes and in morpheme-internal position: gn-n 
(sign,
sign-ing2 vs. sing-ature1, ignore), mn-n (damn, damn-ing2 vs. 
damn-ation1, amnesia), mb/ŋg-m/ŋ (sing, sing-ing2 vs. long-er1, finger,
bomb, bomb-ing vs. bomb-ard, Hamburg). The latter alternation, postnasal 
plosive deletion, suffers from a number of exceptions.43 The following dis-
cussion therefore focuses on the former two cases. Data and analysis under 
 (71) below are taken from Mohanan (1986:21ff) (the facts are also dis-
cussed by, among many others, Halle & Mohanan 1985:95f, Borowsky 
1986:232ff). 
Mohanan (1986:21ff) points out that the absence of word-final [gn, 
gm, mn] is certainly not due to syllabic reasons since parallel word-final 
clusters such as [-zm ÿ], [-klÿ], [-sn̩] do occur with a syllabic sonorant in very 
common words such as prism, pickle, listen. There is no reason why col-
umn and sign could not be colu[mn̩] and si[gn̩], respectively. Mohanan also 
bolsters the synchronic reality of the alternations by showing that they are 
productive: when asked to produce the infinitive and the -ing form of nonce 
words like limnation [lImnejS´n], native speakers return [lIm], [lImIN], 
rather than [lImn], [lImnIN]. 
Nasal cluster simplification illustrates the pattern of rule-triggering 
boundaries since the underlying form must contain a cluster (/gn/, /gm/ and 
/mn/), which is simplified by a phonological process when class 2 suffixes 
are attached. That is, class 2 suffixes trigger cluster simplification where 
class 1 suffixes are inert. 
 
43 For one thing, some class 1 affixes such as -ology and -ese trigger deletion: 
bomb-ólogy, Peking-ése. Their class membership is evidenced by the fact that 
they shift stress (as shown by the examples) and are able to combine with 
bound stems as in phren-ology, Portugu-ese (see § 142 for the bound stem diag-
nostic). Also, a number of words bear [ŋ] in morpheme-internal position: din-
ghy, hangar, Birmingham. Bermúdez-Otero (2008, forth a) shows that the two 
aspects in which post-nasal plosive deletion misbehaves are related along the 
lines of a generalisation that was established by Chung (1983:63). Based on 
evidence from explicit statements by 18th century orthoepist James Elphinston, 
Bermúdez-Otero (forth b) reconstructs the evolution of /ng/ simplification, 
showing that it crept into the language "from outside-in", i.e. affecting first lar-
ger, then smaller chunks (phrase level, word level, stem level). 

146 
Chap 7: Lexical Phonology 
A further challenge for analyses is due to the fact that the word-final 
context systematically behaves like class 2 suffixes: it triggers simplifica-
tion. The relevant rule must thus somehow make reference to the string-
final location as a condition for the process to go into effect. This is con-
firmed by the fact that morpheme-internal /gn/ and /mn/ do not simplify: 
a[gn]ostic, a[mn]esia.
(71) English nasal cluster simplification 
 
a. gN - n 
 
 
 
__# 
__-V 
class 2 suffixes 
class 1 suffixes 
n/m 
n/m 
gn/gm 
sign 
sign-ing 
sign-ature, sign-al, sign-ify 
resign 
resign-ed 
resign-ation 
assign 
assign-ment 
assign-ation 
design 
design-ed, design-s 
design-ate 
malign 
malign-ing, malign-ed 
malign-ant, malign-ity 
benign 
± 
benign-ity, benign-ant 
paradigm 
± 
paradigm-atic 
b. mn - m 
 
 
 
__# 
__-V 
class 2 suffixes 
class 1 suffixes 
m
m
mn 
solemn 
± 
solemn-ity 
damn 
damn-ing 
damn-ation 
condemn 
condemn-ing 
condemn-ation 
hymn 
hymn-ing, hymn-ed 
hymn-al, hymn-ology, 
hymn-ary, hymn-ic 
column 
column-s, column-ed 
column-al 
autumn 
± 
autumn-al 
Recall from § 94 that the disjunction "word-finally and before class 2 
suffixes" is reduced to # in SPE, which is what the deletion rule simply 
makes reference to: g →ø / __N#. This rule will not apply to clusters be-
fore class 1 suffixes because these come with a +, rather than with a # 
boundary. 
 

Rule-triggering boundaries: brackets and bracket erasure 147 
168  7.2. Brackets and bracket erasure are needed for a stratal account 
 
The stratal architecture alone cannot account for the rule-triggering pattern: 
in our examples, the deletion rule must be present at level 2 in order to 
touch strings that bear class 2 suffixes (e.g. sign-ing). Since all strings that 
are present at a given stratum must run through all subsequent strata on 
their way to the surface, however, strings that bear class 1 affixes (e.g. 
sign-ature) would also have to undergo deletion at level 2, which is not 
what they do. 
Some additional device is thus needed in order for Lexical Phonol-
ogy to be able to account for the rule-triggering pattern. This is when the 
cycle-delineating brackets known from SPE (see § 95) enter the scene. As 
we will see, though, the use that Lexical Phonology makes of brackets and 
bracket erasure is only remotely akin with the devices of the same name 
that were introduced in SPE. 
The analysis of the rule-triggering pattern in terms of brackets and 
bracket erasure is due to Mohanan (1982:24f) (see also Mohanan & Mo-
hanan 1984, Halle & Mohanan 1985, Mohanan 1986). In Lexical Phonol-
ogy, it has become the consensual analysis of the phenomenon at hand. We 
will see in § 203 that Kiparsky's (1982a,b) Strict Cycle Condition (SCC) is a 
direct competitor that does the same job. For the time being, though, let us 
introduce Mohanan's mainstream analysis. 
Mohanan (1986) explains the distribution and function of brackets as 
follows. 
 
(72) "We use the the notation of brackets to refer to morphological concatena-
tion: [ __ refers to the beginning of a form, __ ] to the end, and ] [ __ or 
__ ] [ to the junction between two forms (the end of a form followed by the 
beginning of another)." Mohanan (1986:18) 
 
Brackets thus delineate morpheme boundaries, and the structural de-
scription of phonological rules makes direct reference to them. Nasal clus-
ter simplification occurs in word-final position (sign) and before class 2 
affixes (sign-ing). It was mentioned in § 167 that SPE captured this disjunc-
tion with the # boundary, which follows the cluster in both environments 
(§ 94). On Mohanan's analysis, the two cluster-reducing contexts share the 
property of being morpheme-final. Since morpheme-boundary information 
is represented by brackets, the relevant rules thus need to go into effect 
before a (closing) bracket. They appear under  (73) below (from Mohanan 
1986:22). 
 

148 
Chap 7: Lexical Phonology 
(73) a. g deletion, domain: level 2 
g →ø / __ [+nasal]  ] 
 
b. n deletion, domain: level 2 
n →ø / [+nasal] __ ] 
 
Deletion thus takes place in word-final /mn/ and /gn/, which are fol-
lowed by a bracket: /[damn], [sign]/ →damn, sign. However, brackets are 
unable to distinguish between class 1 and class 2 suffixes: [[sign] [ing]] and 
[[sign] [ature]] should both lose their /g/. The distinction between affix 
classes therefore needs to be assured by some other means. This job is done 
by bracket erasure, as described under  (74) below.44 
(74) Bracket Erasure 
Erase internal brackets at the end of each level. 
 
Table  (75) below shows how the derivation of nasal cluster simplifi-
cation works when brackets and bracket erasure are in place. Note that rule-
triggering boundaries translate as level 2 rules in the stratal environment. 
 
(75) nasal cluster simplification in Lexical Phonology 
 
underived 
damn 
class 2 
damn-ing 
class 1 
damn-ation 
 
lexicon 
 
[damn] 
[damn] 
[damn] 
level 1 
concatenation  
± 
± 
[[damn] [ation]]
bracket erasure 
± 
±
[damn ation] 
 
level 2 
concatenation 
± 
[[damn] [ing]] ±
cluster simplification [dam] 
[[dam] [ing]] ± 
bracket erasure 
± 
[dam ing] 
± 
44 The version of bracket erasure under  (74) is Mohanan's (1982) original take 
which he called the Opacity Principle, and which was taken over by Kiparsky 
(1982b:140). Mohanan's (1982:23) original formulation is as follows: "the in-
ternal structure at one stratum is invisible to the processes of another." In later 
work, Mohanan (1986:25) goes back to the stronger version of SPE where 
brackets are erased at the end of each cycle (instead of each stratum only, Mo-
hanan 1986:59f, note 7 explains why). This move is based on the option of dis-
tinguishing between cyclic and non-cyclic strata (Mohanan & Mohanan 1984, 
Halle & Mohanan 1985, see § 194) and relies on an idiosyncratic definition of 
what counts as a cycle (which is different from the definition that is in place in 
SPE). 

Rule-triggering boundaries: brackets and bracket erasure 149 
By way of bracket erasure, [[damn] [ation]] becomes [damn ation] at 
the end of level 1. It is handed down as such to level 2, where cluster sim-
plification is active. However, the elimination of the inner brackets bleeds 
the deletion rule, which applies only to clusters that are followed by a 
bracket. Hence [damn ation] is left undamaged, just like mono-morphemic 
items (amnesia). 
By contrast, /-mn/ before class 2 suffixes is always followed by a 
"fresh" bracket since class 2 suffixes only join in at level 2: [[damn] [ing]] 
still bears inner brackets when cluster simplification applies. In the same 
way, /-mn/ in underived stems is always followed by a bracket, which is 
peripheral and therefore never erased: [damn] arrives at level 2 with the 
critical bracket following the cluster, which is therefore simplified. 
As a result, [damn] and [[damn] [ing]] lose their nasal, but 
[damn ation] and [amnesia] do not. That is, nasal cluster simplification 
underapplies to class 1 strings. 
 
169  7.3. A hybrid representational-procedural theory because of the rule-
triggering pattern 
 
170  7.3.1. LP-style brackets undo what was gained by interactionism 
 
It was mentioned in § 161 that interactionism and the stratal architecture 
have the beneficial effect of doing away with the modularity-violating 
brackets of SPE (see also §§ 161, 305, 680). Rather than by brackets (which 
are untranslated morpho-syntactic information in phonology), interpreta-
tional units are now identified by strata.  
Against this backdrop, though, Mohanan's reintroduction of brackets 
into the stratal architecture destroys the gain that interactionism had 
achieved. Lexical Phonology with brackets accommodates the old awkward 
representational delineation of morpho-syntactic structure on top of the 
procedural (stratal) definition of interpretational units. 
Or, in other words, Lexical Phonology holds that phonologically 
relevant morpho-syntactic divisions do not coincide with interpretational 
units: the latter, strata, are subdivided into the former, morphemes. That is, 
origin-al-ity is only one interpretational unit (a root plus two class 1 affixes 
that are concatenated at the same stratum), but accommodates internal 
structure through brackets: [[origin] [al] [ity]]. 

150 
Chap 7: Lexical Phonology 
This is at variance with SPE, where brackets and interpretational 
units coincided: every chunk delineated by brackets ± a cycle ± was subject 
to independent interpretation, and vice-versa. 
 
171  7.3.2. LP-style brackets and brackets in SPE have got nothing in common 
 
Let us now look at how LP-style brackets relate to their ancestors in SPE. 
In fact, they have barely anything in common beyond the name. The more 
the original literature is removed from the observer's perspective, the easier 
they may therefore be confused. 
We have already seen that brackets in Lexical Phonology can be 
mentioned in phonological rules (this is actually the reason why they exist 
in the first place, see  (73)). In SPE they cannot: their exclusive purpose is 
to guide the cyclic derivation through the linear string (§ 98). 
We have also seen that precisely this function ± the definition of in-
terpretational units ± is not what brackets do in Lexical Phonology: inter-
pretational units are defined by procedurally ordered strata. Their labour is 
simply to indicate morphological divisions. 
This is, then, another difference with respect to SPE. Recall from 
§§ 103, 160 that it is not true that brackets delineate all morphological divi-
sions in SPE: only those morpheme boundaries are armed with brackets 
which represent a transition between major categories. Hence the structure 
of [[[theatr]N ic + al]A i + ty]N. Mohanan's brackets, however, mark each 
and every morpheme (see the quote in  (72)). Originality will thus be repre-
sented as [[origin] [al] [ity]] where two class 1 morphemes cohabitate with 
a root in the same interpretational unit (stratum 1). 
Finally, brackets in SPE make the hierarchical morpho-syntactic 
structure available in the phonology: brackets reproduce morpheme breaks 
and the embedded status of morphemes. By contrast, Lexical Phonology 
does not care for the hierarchical status of morphemes (because this infor-
mation is already procedurally encoded in strata): all that Mohanan's brack-
ets do is to indicate that there is a morpheme boundary. For example, Mo-
hanan's structure of theatricality (supposing the same morphological analy-
sis as in SPE) is flat: [[theatr] [ic] [al] [i] [ty]]. 
 

Rule-triggering boundaries: brackets and bracket erasure 151 
172  7.3.3. Brackets are boundaries that are introduced through the back door 
 
LP-style brackets appear to be an attempt to reintroduce boundaries through 
the back door. Recall from § 165 that the elimination of boundaries is adver-
tised as an achievement of Lexical Phonology: it would be difficult to con-
cede that they are still needed for the analysis of the rule-triggering pattern. 
A theory that combines procedural and representational elements for 
the management of affix class-based phenomena is not really what one may 
expect given the research programme of Lexical Phonology that has set out 
to replace representational by procedural solutions. If representational 
boundaries are needed anyway and can do all the job, what is the proce-
dural technology good for? 
Despite the attempts to camouflage the representational travesty, 
stratal Lexical Phonology is in fact a hybrid representational-procedural 
theory. Bermúdez-Otero (2008) calls the use of brackets a cheap trick. He 
points out that just like SPE, Lexical Phonology needs a trigger for the rule-
triggering pattern. The only difference with respect to the analysis in SPE, 
then, is the name of the trigger: a boundary here (g →ø / __N#), a bracket 
there (g →ø / __N]). Recall that the difference between boundaries and 
brackets in SPE was precisely the ability of rules to refer to the former, but 
not to the latter. The bracket in Mohanan's rule is thus no more than a 
boundary in rhetorical disguise.45 
173  7.3.4. A hybrid representational-procedural theory 
 
Mohanan's brackets, however, do their job less well than boundaries in 
SPE. Recall from §§ 94, 167 that the rule-triggering pattern in English raises 
the challenge of the disjunction "word-finally and before class 2 suffixes" ± 
this is where nasal clusters are simplified. The disjunction is reduced to # in 
SPE, which is what the deletion rule makes reference to. We have seen in 
§168 that hybrid Lexical Phonology cannot capture this disjunction even 
when equipped with Mohanan's brackets. This is because there is only one 
kind of bracket: unlike boundaries in SPE, which fall into + and #, brackets 
are unable to distinguish class 1 and class 2 suffixes ± both bear the same 
bracket. The rule g →ø / __N] will thus incorrectly delete the velar also in 
[[sign] [ature]]. This problem is solved by the procedural architecture (and 
 
45 Kaisse & Shaw (1985:10ff) and Halle & Mohanan (1985:59, 64f) provide more 
comparative discussion regarding boundaries and brackets. 

152 
Chap 7: Lexical Phonology 
bracket erasure, to be further discussed shortly), which is able to distin-
guish class 1 ("old") from class 2 ("fresh") brackets. 
In other words, Lexical Phonology has split the information which in 
SPE is supported by the # boundary alone into a representational and a 
procedural piece: the location of a morphological division is signalled by a 
bracket, but whether this particular division is phonologically relevant or 
not, and if so, whether it has a blocking or a triggering effect, is controlled 
procedurally by level ordering. This fact is frankly acknowledged by Mo-
hanan (1982). 
 
(76) 
"In SPE, the use of boundary symbols serves two functions: (i) If a rule 
contains a boundary symbol such as + or # in its structural description, it 
applies to a string only if the string contains the required boundary. (17) 
shows how this function of the boundary symbol is taken care of in Lexical 
Phonology by defining the domain of the rule as the stratum associated with 
the boundary, and replacing the boundary with brackets." Mohanan 
(1982:24) 
 
Finally, another aspect of brackets is that they make Lexical Phonol-
ogy a representative of the non-privative take of SPE (§ 90). Brackets are 
the representational means of Lexical Phonology to refer to morpho-
syntactic information in phonology. Since they do not reflect the hierarchi-
cal aspect of morpho-syntactic structure, one must assume that they are the 
output of translation (or at least of readjustment: this question is not ad-
dressed in the Lexical Phonology literature). In these non-hierarchical lim-
its, then, brackets transmit full morpho-syntactic information, rather than 
just the information that is phonologically relevant. 
 
174  7.4. Bracket erasure 
 
175  7.4.1. No look-back devices in Lexical Phonology and elsewhere 
 
Let us now have a look at bracket erasure and the labour that it does in the 
analysis of the rule-triggering pattern. Bracket erasure destroys the morpho-
logical structure of a string before handing it down to the next stratum 
where further morphemes are concatenated. When the phonological compu-
tation of a later stratum applies, then, the original morphological structure 
of the "old" string is invisible: a string made of several "old" morphemes is 
treated exactly like a morphologically non-complex item. 

Rule-triggering boundaries: brackets and bracket erasure 153 
This means that at any given point of morphological construction, 
phonological computation cannot "look back" into previous strata ± it sees 
only those morphological divisions that were created in its own stratum. 
This is the first time that we come across what I call a no look-back device 
in this book. We will see that no look-back devices are accommodated in 
various theories and occur in a number of flavours. 
The ancestor of no look-back devices is Chomsky's (1973) Strict Cy-
cle Condition. Various theories have implemented different brands of no 
look-back devices over the years, including namely Kiparsky's SCC-K, an 
important brick of Lexical Phonology (on which more in § 188). A survey 
of no look-back devices is provided in § 287. 
In Lexical Phonology, bracket erasure is often advertised as a major 
insight (e.g. Kaisse & Shaw 1985:4f, Mohanan 1986:23ff, Bermúdez-Otero 
forth a:45ff): it is held to be the root of Praguian segregation (§ 153). That 
is, word- and sentence phonology are different because phonological rules 
which apply across words have no access to word-internal structure, which 
has been erased. 
Finally, due mention needs to be made of the fact that bracket erasure 
has a competitor in Lexical Phonology which does the same no look-back 
job: Kiparsky's (1982a,b) adaptation of the Strict Cycle Condition. Com-
parative discussion is provided in § 203. 
 
176  7.4.2. SPE has bracket erasure, but no no look-back effect 
 
Note that just like Mohanan's brackets, bracket erasure in Lexical Phonol-
ogy shares nothing but the name with the device of the same name that is 
known from SPE. Unfortunately, the constant reference of the Lexical Pho-
nology literature to the SPE-ancestor in this context contributes a lot to 
terminological and general confusion. 
Chomsky & Halle (1968:15) have indeed coined the term bracket 
erasure, but this device does not produce any no look-back effect. In SPE, 
bracket erasure effects the deletion of the brackets that delineate a cycle 
(i.e. an interpretational unit) at the outset of the next cycle (see § 100). 
Hence the structure [[A] B] is processed in such a way that first phonology 
applies to [A]; then the next cycle, [[A] B], is considered, but before pho-
nological rules apply, inner brackets are erased: the input to the phonologi-
cal computation is [A B]. Bracket erasure itself is thus identical in SPE and 
Lexical Phonology (see  (74), with the proviso regarding the different distri-
bution of brackets, see § 171). 

154 
Chap 7: Lexical Phonology 
However, recall that brackets serve only one purpose in SPE, i.e. the 
delineation of cyclic domains and hence the application of cyclic deriva-
tion. Phonological rules can make reference to boundaries, but crucially not 
to brackets (§§ 98, 170f). This is why brackets and bracket erasure are un-
able to produce a no look-back effect in SPE: in order for phonological 
computation to be unable to look back to erased brackets, it would have to 
be able to see brackets in the first place. This, however, is impossible: 
brackets may not be mentioned in phonological rules.  
Hence it is only because Mohanan allows rules to make reference to 
brackets that a no look-back effect is produced in Lexical Phonology on the 
grounds of the same bracket erasure convention that was active in SPE. 
 
177  8. Derived environment effects 
 
178  8.1. Properties and illustration of the phenomenon 
 
179  8.1.1. Phonologically and morphologically derived environments 
 
Lexical Phonology has coined the notion of so-called derived environment 
effects (e.g. Kiparsky 1982b, Rubach 1985).46 Processes that fall into this 
category apply only to strings that have already undergone some phono-
logical or morphological operation; underived items on the other hand re-
main unaffected. 
On the classical definition (e.g. Kiparsky 1982b, Rubach 1985:157), 
an item counts as derived iff it is either morphologically complex (that is, if 
some concatenation has taken place) or the result of the application of a 
phonological rule. 
 
180  8.1.2. The foundational Finnish case 
 
The canonical example for a phonologically derived environment is 
Kiparsky's (1973a,b) analysis of Finnish where underlying /t/ surfaces as 
[s] if followed by a "derived" i. Table  (77) shows relevant data. 
 
46 Much like the pages below, Bermúdez-Otero (forth a:§1.2) traces back the 
history of derived environment effects, and of Kiparsky's Strict Cycle Condi-
tion. 

Derived environment effects 155 
(77a) shows that /t/ is affected by a following -i if both segments are 
separated by a morpheme boundary: this is a morphologically derived envi-
ronment. The -i in the examples shown is the past tense marker, and the 
underlying stem-final /t/ is witnessed by morphemes such as the 3rd person 
impers. marker -koon, which produces /halut-koon/ →halutkoon "to want 
3rd impers." (compare with /halut-i/ →halusi "wanted"). 
Underlying /t/ also undergoes the t →s rule under (77b), i.e. in case 
the following i is an underlying /e/ that was raised in word-final position by 
way of an independent rule (the /e/ is witnessed by the essive forms where 
it escapes raising because it is not word-final). 
 
(77) 
Finnish t →s / __i in derived environments 
 
a. morphologically derived: the -i belongs to a different morpheme 
 
/halut-i/ 
→halusi 
wanted 
 
 
/hakkat-i/ 
→hakkasi 
hewed 
 
 
/turpot-i/ 
→turposi 
swelled 
 
 
b. phonologically derived: the i is an underlying /-e/: e →i / __# 
 
essive 
nominative 
 
 
 
vete-nä 
vesi 
water 
 
käte-nä 
käsi 
hand 
 
 
mete-nä 
mesi 
honey 
 
 
c. underived environments: stem-internal /i/ 
 
essive 
nominative 
 
 
 
neiti-nä 
neiti 
young lady 
 
äiti-nä 
äiti 
mother 
 
 
koti-na 
koti 
home 
 
 
Finally, (77c) shows that /t/ remains unaffected by a following i if 
this i is really underlying (i.e. not the result of a phonological process) and 
does not belong to a different morpheme. 
 
181  8.1.3. Non-application of rules to mono-morphemic strings 
 
It appears that phonologically derived environments have received far less 
attention and empirical support than morphologically derived environ-
ments.47 One reason is certainly the fact that the application of a rule is 
much subject to analysis and hence to debate, while the existence of a mor-
phological boundary is a hard fact. In a constraint-based environment for 
 
47 Some more discussion of phonologically derived environment effects is pro-
vided in § 517. 

156 
Chap 7: Lexical Phonology 
example where computation is parallel and hence no ordered phonological 
events exist, the entire notion of phonologically derived environment is 
obsolete anyway, or at least unstateable. 
On the other hand, effects of morphologically derived environments 
have been reported regularly. To date the discovery of this phenomenon and 
its formalisation is taken to be a major, for some the major contribution of 
Lexical Phonology: "The lasting result of Lexical Phonology is that phono-
logical generalizations may be bound by derived environments" Rubach & 
Booij (2003:446), "One important aspect of the phonology-morphology 
interface which has been discovered in the second half of the twentieth 
century" van Oostendorp (2007:135). 
Typically, sensitivity to morphologically derived environments is 
displayed by segmental rules, i.e. where a trigger and a target are clearly 
identifiable in the linear string, and some melodic property transmitted 
(which is not the case for prosodic phenomena such as stress placement). 
An example is the palatalisation in Polish discussed by Rubach 
(1984:59ff) and Rubach & Booij (1984:3f). In Polish, a certain kind of 
palatalisation targets preceding dental consonants, but only if the palatal 
trigger and the dental patient belong to two different morphemes. This is 
shown under  (78) below.48 
(78) 
Polish palatalisation 
 
dental with no palatal agent
dental + palatal agent 
 
spelling 
[ ] 
 
spelling 
[ ] 
 
a. derived  
g»ód 
gwut 
 
głodz-ić
gwɔdÉ¸-itÉ˛
grymas 
grɨmas 
 
grymas-ić
grɨma˛-itÉ˛
b. underived 
dinosaur 
dinɔsawr 
 
protest 
prɔtEst 
 
desant 
dEsant 
 
c. both 
servis 
sɛrvis 
 
servis-ie 
sɛrvi˛-ɛ
48 Glosses (left-to-right, top-down): "hunger, to starve somebody, grimace, to 
grouch, dinosaur, protest, landing". All cases where palatalisation does not ap-
ply morpheme-internally are recent loans; concomitantly, there are no native 
words with morpheme-internal [di] or [si]. Hence one could be tempted to re-
gard the pattern as a mere problem of loanword adaptation: loans are borrowed 
without amendment. However, Rubach & Booij point out that loanwords regu-
larly inflect and palatalise in the relevant environment (e.g. protest - protesc-ie 
[prɔtɛstÉ˛-ɛ] "protest, id. LOCsg"), which is not an argument in favour of this 
perspective. 

Derived environment effects 157 
As may be seen under (78a), stem-final [s,d] turn into [˛,dÉ¸] before 
the infinitive morpheme [-itÉ˛]. By contrast, (78b) shows that no palatalisa-
tion occurs in the same phonological environment if the triggering vowel 
and the dental target belong to the same morpheme. The word under (78c) 
demonstrates both effects on the same lexical item: the underlying se-
quence /se/ shows no effect when it is mono-morphemic, but the fricative 
palatalises before the LOCsg marker -ie [-ɛ]. Different analyses of this pat-
tern are discussed in §§ 188ff below. 
 
182  8.1.4. Sensitivity to derived environments and to affix classes is orthogonal 
 
Another aspect of derived environment effects is that they are entirely or-
thogonal to affix class-sensitivity. 
Trisyllabic Shortening for example is a process which combines the 
derived environment restriction (it only applies to plurimorphemic strings: 
nightingale and ivory remain unaffected, more on this shortly) with a selec-
tive application to a particular affix class (class 1: s[aj]ne - s[æ]n-ity1 vs. 
m[aj]den-hood2, see § 164). 
This, however, is a mere coincidence. Other affix class-sensitive 
rules also apply to mono-morphemic strings. For example, just like Trisyl-
labic Shortening, nasal assimilation is a level 1 rule (see § 164): the class 1 
affix in- reacts (im-possible), while the class 2 affix un- does not 
(un-predictable). Unlike Trisyllabic Shortening, however, nasal assimila-
tion is active in mono-morphemic strings: all mono-morphemic nasal-
obstruent clusters are homorganic in English (climb, hint, finger, etc.). 
Trisyllabic Shortening and nasal assimilation thus share the selective 
application to strings that are created by class 1 affixation, but go separate 
ways regarding the derived environment parameter. 
 
183  8.2. Derived environments are an offspring of the abstractness debate 
 
184  8.2.1. Absolute neutralisation and free rides 
 
The idea that phonological processes do not apply within morphemes, i.e. 
when the trigger and the target belong to the same morpheme, has emerged 
from the abstractness debate of the 70s (§§ 125f) and Kiparsky's continuous 
attempts to restrict the variability of underlying forms (§ 129). Cole (1995) 
and Bermúdez-Otero (forth a:§1.2) provide a good overview of this move-

158 
Chap 7: Lexical Phonology 
ment, which is also explained by Kiparsky himself in Kiparsky (1982b, 
1993), and by Anderson (1981:530ff). 
In SPE, underlying forms could be at any distance of what they 
sound like on the surface; whatever suited the analyst in order to get things 
right was allowed. Namely, the underlying form of morphemes that do not 
alternate at all could be different from their surface form. For example, 
mono-morphemic items such as n[aj]ghtingale (nightingale) and [aj]vory 
(ivory) systematically resist Trisyllabic Shortening even though they satisfy 
its structural description (§ 164). 
SPE reacts in a non-systematic way that misses the obvious morpho-
logical generalisation. That is, the application of the rule is eluded simply 
by destroying either the target or the triggering context of each individual 
lexical item: instead of /aj/, nightingale was said to have an underlying /i/, 
i.e. /nixtVngael/ (Chomsky & Halle 1968:234); and instead of /i/, the last 
segment of ivory was made a glide, i.e. /ivorj/ (Chomsky & Halle 
1968:181, which makes ivory miss the trisyllabic condition). Independent 
rules that are ordered after Trisyllabic Shortening, then take /ix/ to [aj] (via 
/i/), and vocalise the final glide of ivory.
Another trouble when the underlying form of invariable morphemes 
may be distinct from their surface form are so-called free rides. In our ex-
ample, these concern the converse surface situation, i.e. cases where the 
third but last vowel of a mono-morphemic item is short. That is, Kiparsky 
(1982b:148) points out that on the SPE analysis, the underlying form of 
[æ]libi, c[æ]mera or P[æ]mela cannot be determined: the third but last 
vowel of these words could either be faithfully short and hence appear as 
such on the surface, or it could be underlyingly long, i.e. /aj/libi, /kaj/mera,
/paj/mela, in which case the /aj/ will be shortened into [æ] via Trisyllabic 
Shortening ± a free ride, i.e. one without consequences. 
In the same way, nasal assimilation (§ 164) can give rise to free rides. 
English has no non-homorganic [NC] clusters at all. The nasal assimilation 
that is observed in i[m]-possible, i[ŋ]-credible, then, can also be said to be 
responsible for mono-morphemic [NC] clusters: lamp and think may be 
construed as /lænp/ and /Tɪnk/, which then take a free ride on nasal assimi-
lation in order to surface with a homorganic cluster. 
 
185  8.2.2. The Alternation Condition 
 
Kiparsky (1968-73:14f) coins the term absolute neutralisation, which de-
scribes a situation where a morpheme has an underlying sequence that may 

Derived environment effects 159 
never be inspected on the surface because it is modified by a rule in all 
occurrences. That is, the situation of nightingale and ivory on the analysis 
of SPE. Opposed to absolute neutralisation are contextual neutralisations, 
which transform only a subset of the occurrences of a morpheme. For ex-
ample, /in-/ appears with a modified nasal in i[m]-possible and 
i[ŋ]-credible, but surfaces as such in i[n]-applicable where the quality of 
the nasal may not be said to be the result of assimilation since the conso-
nantal trigger is missing. 
On this backdrop, Kiparsky argues that absolute neutralisation and 
free rides must be disallowed on principled grounds: grammar cannot toler-
ate underlying forms of non-alternating morphemes which are different 
from their surface form. This is done at first by the Alternation Condition 
(Kiparsky 1968-73:14ff), which states that "obligatory neutralization rules 
cannot apply to all occurrences of a morpheme" in Kiparsky's 
(1982b:148) formulation. 
 
186  8.2.3. "Low-level", "automatic" or "phonetic" rules may apply morpheme-
internally 
 
What the Alternation Condition amounts to is the insight that phonological 
rules never apply inside morphemes or, conversely, that phonology only 
applies across morpheme boundaries. The question is whether this state-
ment is empirically true in its overarching and somewhat brutal generality. 
Quite unsurprisingly, the answer is no: there are many cases where an un-
derlying mono-morphemic string is transformed by phonological computa-
tion. 
This is recognised by Kiparsky (1968-73:18) and Kiparsky 
(1973a:64), who concedes that "if a form appears in a constant shape, its 
underlying form is that shape, except for what can be attributed to low-
level, automatic phonetic processes" (Kiparsky 1968-73:18). The trouble, 
then, is to tell "real" phonological rules from low-level, automatic and pho-
netic processes. Kiparsky (1968-73:18) writes that "these can be defined as 
processes which do not cause neutralization of distinct representations" and 
quotes the great vowel shift together with the loss of /g/ in sing [sɪŋ] as 
examples. In Kiparsky (1982b:154), he adds velar softening (electri[k] -
electri[s]-ity, see § 126, note 28). "Automatic" aspiration of English voice-
less plosives (roughly word-initially and before stressed vowels) would 
certainly be another candidate, as much as the distribution of suprasegmen-

160 
Chap 7: Lexical Phonology 
tal properties such as stress, which always concerns underived roots as 
much as plurimorphemic strings. 
The question whether it can be predicted which rules obey and which 
rules disregard the prohibition to apply to mono-morphemic strings will 
escort the reader on the pages below. Having run Kiparsky's (1968-73, 
1973a) proposal against a more substantial set of empirical evidence, 
Kenstowicz & Kisseberth (1977) conclude, pessimistically, that  
(79) 
"Kiparsky's principle may be too strong in that some rules of nonautomatic 
neutralization apply in nonderived contexts. If so, it is not immediately clear 
that there is a way to predict which rules will apply only in derived contexts 
and which will apply in nonderived contexts as well." Kenstowicz & Kisse-
berth (1977:214) 
 
Halle (1978) agrees. 
 
(80) 
"To conclude it would appear that the special conditions on rules discovered 
by Kiparsky are unconnected with the automatic or nonautomatic character 
of the rule." Halle (1978:132) 
 
We will see below that the same class of "low level", "automatic" or 
"phonetic" processes ± which may therefore be called the bad guys ± also 
violates some versions of no look-back devices that have got nothing to do 
with derived environments (§ 315). 
 
187  8.2.4. The Revised Alternation Condition: derived environments enter the 
scene 
 
The definition of what exactly is low-level, phonetic and automatic will 
haunt Lexical Phonology all through, as will be evident from the discussion 
below. For the time being, with this question blinded out, the derived envi-
ronment condition emerges. For a number of reasons that Kiparsky 
(1982b:148ff) explains at length, he upgrades the Alternation Condition by 
building on derived environments. The Revised Alternation Condition 
(RAC), then, is as under  (81) below. 
 
(81) 
Revised Alternation Condition (RAC) 
Obligatory neutralization rules apply only in derived environments. 
Kiparsky (1982b:152) 
 

Derived environment effects 161 
As before, mono-morphemic strings may thus not be affected by 
the kind of rules that are non low-level, non-automatic and non-
phonetic. Given the RAC, Trisyllabic Shortening for example cannot 
apply to nightingale and ivory because the strings at hand are underived. 
 
188  8.3. Solution 1: the Strict Cycle Condition (SCC) 
 
189  8.3.1. Mascaró's SCC has got nothing to do with derived environments 
 
After having introduced the Revised Alternation Condition, Kiparsky 
(1982b:153ff) goes on to advertise Mascaró's (1976) Strict Cycle Condition 
(SCC) ("a major step forward"). According to Kiparsky, the advance of-
fered by Mascaró is the identification of the location in the grammar where 
the two types of rules live, i.e. "real" rules that apply only in derived envi-
ronments and "low-level" rules that are automatic. Mascaró proposes that 
the former are cyclic (in the sense of SPE, see § 105), and Kiparsky con-
cludes that the latter must then be non-cyclic, which in terms of Lexical 
Phonology means postlexical. 
Mascaró's (1976) SCC, however, has got nothing to do with derived 
environments at all: like Kean (1974), Mascaró works at importing Chom-
sky's (1973) Strict Cycle Condition (see § 289) into phonology ± something 
that he calls the Phonological Cycle, and which is known as such since then 
(SPE only talked about the Transformational Cycle, see § 100). In adapta-
tion to syntactic strict cyclicity, then, Mascaró's Phonological Cycle is the 
introduction of a no look-back device into phonology. This notion was in-
troduced in § 174 and is further discussed in § 287. 
Mascaró's (1976) SCC appears under  (82) below. 
 
(82) 
"Strict Cycle Condition (SCC) 
Proper application of cyclic rules 
For a cyclic rule to apply properly in any given cycle j, it must make specific 
use of information proper to (i.e. introduced by virtue of) cycle j." 
Mascaró (1976:7) 
 

162 
Chap 7: Lexical Phonology 
Mascaró (1976) explains that  
 
(83) 
"this condition ensures that no 'improper' cyclic application, that is, multiple 
application of a rule, opposite rule ordering, etc. on the same cycle results. In 
other words, it makes it impossible for rules to 'return to earlier stages of the 
cycle after the derivation has moved to larger, more inclusive domains' 
(Chomsky, (1973), 243)." Mascaró (1976:7f) 
 
Multiple application of a rule to a given string in two different cycles 
is thus prohibited by the requirement for rules to use at least some material 
that was added on the outer cycle. Hence given [[X]i Y]j, a cyclic rule may 
apply first to X on the inner cycle i (it takes into account material that was 
introduced on this cycle); however, on the outer cycle it may apply to [XY] 
j again only if it takes into account some material of Y. 
Mascaró's SCC is thus perfectly unable to account for derived envi-
ronment effects: the only thing that it does is to introduce a no look-back 
device into phonology. For example, SCC does not prevent Trisyllabic 
Shortening from applying to mono-morphemic items such as nightingale 
and ivory at all: on the innermost cycle, i.e. [nightingale], the rule uses ma-
terial of this cycle and hence applies "properly". Just as much as in [[san] 
ity] where the material of the outer cycle is needed in order to satisfy the 
structural description. 
 
190  8.3.2. Kiparsky (in fact Halle) adds derived environments to Mascaró's 
SCC 
 
Let us now look at how Kiparsky (1982a,b) introduces Mascaró's SCC. He 
writes that 
 
(84) 
"with some simplification, his [Mascaró's] proposal was: 
 
(47) Strict Cycle Condition (SCC): 
 
a. 
Cyclic rules apply only to derived representations. 
 
b. 
Def.: A representation φ is derived w.r.t. rule R in cycle j iff φ
meets the structural analysis of R by virtue of a combination of 
morphemes introduced in cycle j or the application of a phono-
logical rule in cycle j." 
 
Kiparsky (1982b:153f) 
 
Derived environments have thus appeared overnight in what Kipar-
sky sells as Mascaró's slightly "simplified" Strict Cycle Condition. Also, 

Derived environment effects 163 
the notion of phonologically derived environment has joined in where Mas-
caró was only talking about morphological conditions. Mascaró faithfully 
applies Chomsky's (1973) idea that a rule can only apply if it uses material 
that was freshly introduced on the latest cycle. It was shown in the previous 
section that this has got nothing to do with derived environments. 
Cole (1995:72) correctly points out that Kiparsky's SCC does two 
things which are logically unrelated: it restricts the application of cyclic 
rules to derived environments under (84a) and encodes Chomsky's (1973) 
no look-back device under (84b). The former continuates Kiparsky's Re-
vised Alternation Condition, while the latter introduces the no look-back 
idea (see also Iverson & Wheeler 1988 on this distinction). 
In actual fact, however, the fusion of Kiparsky's concern for derived 
environment effects on the one hand, and of Chomsky's Strict Cycle Condi-
tion (in Kean's 1974 and Mascaró's 1976 guise) on the other, was operated 
by Morris Halle (1978:129ff). Halle writes:  
 
(85) 
"the version of the constraint on cyclic rule application that I propose below 
is a combination of certain suggestions made by Kiparsky (1973[a]:60), with 
others due to Mascaró (1976:9)." Halle (1978:131) 
 
As far as I can seen, Kiparsky's SCC is identical to Halle's version of 
the Strict Cycle Condition (which is discussed at greater length in § 291). 
The existence of Halle (1978), however, has hardly left any trace in the 
literature. 49 Kiparsky (1982a) and Kiparsky (1982b), where  (84) is intro-
duced, are almost identical texts (the latter is a subset of the former). Halle 
(1978) is absent altogether from Kiparsky (1982b); it is mentioned in the 
reference section of Kiparsky (1982a), but does not appear in the text (or 
the notes). Also, Lexical Phonology in general and Kiparsky in particular 
are always credited for the SCC in the subsequent (overview) literature 
(Cole 1995 for example does not mention Halle 1978). 
Beyond the issue regarding the absence of Halle (1978) from the lit-
erature and from common phonological belief, the fusion of the manage-
ment of derived environments with the no look-back device may or may 
 
49 I am aware of two exceptions: prior to Kiparsky's (1982a,b) articles that have 
shaped the field, Rubach (1981:18ff) reports on Halle (1978) and is explicit 
about the fact that Halle's version of no look-back introduces derived environ-
ment effects into Chomsky's Strict Cycle Condition, which was not concerned 
with this phenomenon. Szpyra (1989:17) also mentions Halle (1978) as a pre-
cursor of Kiparsky's derived environment-containing SCC, but mistakenly lines 
up Kean (1974) and Mascaró (1976) as well. 

164 
Chap 7: Lexical Phonology 
not be a good idea. This is a separate question, and from today's post-hoc 
perspective the answer appears to be a clear no (see §§ 197, 214). 
Finally, note that we have already come across another way of im-
plementing a prohibition on look-back: bracket erasure (§ 174); the compe-
tition between the SCC and this mechanism is discussed in § 203. The take-
home message of the present section is that Lexical Phonology (or actually 
Halle 1978) has integrated Chomsky's no look-back device in order to 
make it cover derived environment effects. Contrary to what Kiparsky sug-
gests, however, Mascaró's SCC does not afford any labour regarding de-
rived environments: this clause needs to be explicitly added in form of 
(84a), which amounts to restating the Revised Alternation Condition  (81). 
191  8.3.3. Deriving the SCC from the Elsewhere Condition 
 
Kiparsky's (1973a,c) Elsewhere Condition regulates the competition be-
tween different rules that are applicable to a given form and produce differ-
ent results. In such a situation, Kiparsky argues, only the more specific rule 
applies. 
Kiparsky (1982a:46ff, 1982b:159ff) proposes to derive the SCC from 
the Elsewehre Condition. In order for this to be done, so-called lexical 
identity rules need to be introduced: every lexical entry constitutes a pho-
nological rule by itself whose output is identical to the input. Thus 
/niitingale/ is "transformed" into /niitingale/, /dog/ becomes /dog/ and so 
forth. Identity rules then compete with regular phonological rules in the 
Lexicon. In case there is true competition, i.e. when a real rule tries to mod-
ify an underlying item which is also represented by its identity rule, the 
latter always wins because it is more specific. 
The effect is that mono-morphemic items cannot be modified at all 
since the modifying rule will always lose against the identity rule. In the 
case of /niitingale/ for example, Trisyllabic Shortening will try to transform 
the /ii/ into /i/, but is blocked by the identity rule. In plurimorphemic strings 
such as /sææn-ity/, however, Trisyllabic Shortening can go into effect be-
cause there is no lexical item sanity, hence no identity rule and no competi-
tion. 
Under the pressure of Mohanan & Mohanan (1984) (see also Iverson 
& Wheeler 1988) and others, however, Kiparsky (1985b) abandons this line 
of attack altogether in subsequent work (as much as the SCC, see § 197). 
The idea to analyse derived environment effects by enforcing lexical iden-
tity for isolated morphemes, however, will be revived in OT (see § 521). 

Derived environment effects 165 
192  8.3.4. There are rules that apply in the Lexicon but affect underived items 
 
Kiparsky (1982b:154) is seduced by the perspective that the SCC affords 
expressing a correlation between the way a rule is ordered and the way it 
applies: "early" rules that live in the Lexicon are cyclic and hence can only 
apply to derived environments, while "late" postlexical rules that apply 
after syntactic computation are those that were called low-level (or auto-
matic, or phonetic) above: they apply across the board without any condi-
tion on derived environments. 
The distribution in the architecture of Lexical Phonology is thus clear 
± but it remains to be seen whether it is really true that no postlexical rule 
respects the derived environment condition, and that no cyclic (lexical) rule 
violates it, i.e. applies even to mono-morphemic items. 
The former question has not received much attention in the literature. 
It amounts to asking whether cyclic derivation is needed for sequences of 
words as well (it is documented for morphemes). This is an important issue 
that impacts Praguian segregation and lexicalism; it was already mentioned 
in § 158 and is discussed at greater length in § 786 under the header of the 
word-spell-out mystery. 
The latter question is intimately related to the one that was discussed 
in § 186 regarding "low level" processes that apply to mono-morphemic 
strings. It has a clear answer: it is not true that all rules which apply in the 
Lexicon are unable to modify mono-morphemic items. An example is Eng-
lish stress assignment, which must take place in the Lexicon because it is 
sensitive to affix classes (párent, parént-al vs. párent-hood, §147), but at 
the same time applies to underived /parent/, which is lexically unstressed 
and surfaces as párent.
193  8.3.5. Structure-building vs. structure-changing rules 
 
In the face of this evidence, a consensual move was to weaken the SCC so 
that cyclic rules may also apply to underived environments, but only if they 
add information (as opposed to the elimination or modification of existing 
information). This split of cyclic rules into a group of SCC-obeying (struc-
ture-changing) and SCC-violating (structure-building) items is introduced 
by Kiparsky (1982a:46ff, 1982b:160ff).  
Hence stress may be assigned to non-derived items in the Lexicon 
because stress assignment only involves the supplementation of prosodic 
structure: nothing in the input representation is modified. The same is true 

166 
Chap 7: Lexical Phonology 
for rules that assign syllable structure to lexically unsyllabified items. By 
contrast, a rule such as the Polish palatalisation discussed in § 181 will be 
unable to apply to mono-morphemic strings since it involves the modifica-
tion of the featural makeup of the input. 
An associated debate that was triggered by Kiparsky's introduction of 
the class of structure-building rules concerned the question whether such 
rules can destroy structure that was built on previous cycles. As far as I can 
see, this discussion only concerned two typical phenomena where structure 
was held to be built from scratch on the basis of lexical items that lack con-
stituency: stress (McCarthy 1980, Steriade 1988, Halle 1990:158ff) and 
syllabification (Steriade 1982, 1984). We will see in § 293 below that this 
kind of structure preservation may be interpreted as a herald of modifica-
tion-inhibiting no look-back (today known as the Phase Impenetrability 
Condition, PIC). 
A further complication is the question whether structure-building ap-
plications of rules create (phonologically) derived environments. Origi-
nally, Kiparsky (1982a:47) said yes, but Kiparsky (1985a:91) argues for a 
negative answer: only structure-changing rules allow other structure-
changing rules to apply in mono-morphemic items. 
In this context, underspecification also plays a role: autosegmental 
representations that have expanded in the early 80s allow for segments that 
are not fully specified for all melodic properties at the underlying level (e.g. 
Steriade 1987, Archangeli 1988). The missing information is then filled in 
by some (default) rule during the derivation. Filling in an underspecified 
gap may be interpreted as a structure-building, rather than a structure-
changing operation. By contrast, modifying the melodic setup of a segment 
is always structure-changing when all segments are fully specified underly-
ingly. 
 
194  8.3.6. Cyclicity as a property of strata vs. post-cyclic lexical rules 
 
But the structure-building vs. structure-changing proviso was still not found 
to be able to cope with the empirical situation: Rubach (1984), Rubach & 
Booij (1984, 1987), Rubach (1990) and Halle & Mohanan (1985) present 
cases from English, Polish and French where structure-changing rules 
whose application in the Lexicon is beyond doubt do apply to underived 
items. These rules must then be lexical, but cannot be cyclic. 
This further soaks the SCC: recall that Kiparsky was seduced by the 
fact that it seemed to be possible to predict from the lexical character of a 

Derived environment effects 167 
rule that it can only apply to derived environments. This now turns out to 
be wrong.  
In the face of this evidence, the SCC is further weakened in order to 
be rescued. Two strategies are developed that appear to be distinct and 
competing at first sight (but see below). Both further restrict the application 
of the SCC, this time not to a certain type of rule, but to a sub-area of the 
Lexicon. 
Mohanan & Mohanan (1984) and Halle & Mohanan (1985) propose 
that cyclicity is a property of strata: each individual stratum may or may 
not be cyclic, that is, may or may not respect the SCC. Halle & Mohanan 
(1985:96f) for example argue that in English, stratum 1 (level 1) is cyclic ± 
that is, its rules are blocked in underived environments. By contrast, stra-
tum 2 (level 2) is non-cyclic, which means that its rules may freely trans-
form underived strings. 
Halle & Mohanan (1985:95ff) motivate this move with English nasal 
cluster simplification (§ 167): mono-morphemic /mn/ sequences are reduced 
to [m] when their morpheme occurs in isolation (damn) and before class 2 
suffixes (damn-ing), but remains unaffected before class 1 suffixes 
(dam[n]-ation). Underapplication must thus be organised so that the dele-
tion rule (that is, no doubt a structure-changing rule) applies to the two 
former, but not to the latter context. If of all lexical rules only those observe 
the SCC (i.e. are blocked in underived environments) that are active at stra-
tum 1, the cluster of [damn] and [[damn] [ing]] may happily be reduced by 
the stratum 2 rule n →ø / [+nasal]__ ]. 50 
The alternative strategy is represented by Rubach & Booij (1984, 
1987) and Rubach (1990): their scenario weakens the SCC even more than 
Halle & Mohanan's (1985). They present evidence to the end that cyclicity 
is not tied to strata at all. That is, Rubach & Booij (1987:4) give up on any 
kind of predictability: there is nothing that allows us to distinguish lexical 
rules that do from lexical rules that do not respect the SCC. Instead, they 
simply set up a new category of rules that applies in the Lexicon, but is 
ordered after cyclic rules: lexical postcyclic rules. On their count, then, 
cyclic lexical rules respect the SCC and apply only to derived environ-
ments, while post-cyclic lexical rules violate the SCC and apply across the 
board. Both types of rules are lexical and thus continue to be opposed to 
postlexical rules. 
 
50 Halle & Mohanan (1985) use Mohanan's (1982, 1986) brackets and also other-
wise follow Mohanan's (1986) analysis of nasal cluster simplification (see 
§168). 

168 
Chap 7: Lexical Phonology 
Rubach & Booij's lexical post-cyclic rules revive SPE's word-level 
rules: recall from § 105 that while SPE's cyclic rules iteratively apply to 
each cycle, word-level rules apply only once to word-sized strings. Also, 
just like Rubach & Booij's lexical post-cyclic rules, word-level rules in SPE 
do not apply to chunks that are bigger than the word. 
We will see in §§ 233f that ± quite logically ± Halle & Vergnaud's 
(1987a) attempt to restore SPE and to unseat interactionism implements the 
same idea. In this model, SPE's word-level rules are called non-cyclic (as 
opposed to cyclic rules, which continuate the cyclic rules of SPE). 
 
195  8.3.7. The SCC-K is void of empirical content 
 
Given this general landscape where the SCC is weakened every time it 
meets an obstacle, it is difficult to see what remains of its empirical content. 
Or rather, what remains of Kiparsky's SCC. For Mascaró's original version 
had got nothing to do with derived environments, and (contrary to what 
Kiparsky says) did not try to identify cyclic rules as applying only in the 
Lexicon: there was no Lexicon by the time Mascaró (1976) wrote, not any 
more than there were Lexical Phonology or strata. 
Therefore it is useful to disentangle the terminological confusion that 
Kiparsky's annexation of the SCC has produced: the Lexical Phonology 
literature typically refers to "SCC" as Kiparsky's device, but one may also 
find reference to the offspring of Chomsky's (1973) and Mascaró's (1976) 
Strict Cycle. Talking just about the "SCC" is thus abetting confusion: lexi-
cal phonologists will think of Kiparsky's version, i.e. the tool for derived 
environment effects, while people familiar with the other tradition will 
think of the no look-back device that is known as Phase Impenetrability 
today and has got nothing to do with derived environments.  
For this reason, the remainder of the book carefully distinguishes be-
tween Mascaró's (SCC-M) and Kiparsky's (SCC-K) version of the SCC. 
The latter does, the former does not make reference to derived environment 
effects. 
 

Derived environment effects 169 
196  8.4. Solution 2: derived environments are made a lexical contrast (Kiparsky 
1993) 
 
197  8.4.1. Back to where we started: Kiparsky declares the bankruptcy of 
SCC-K 
 
Under the pressure of the empirical and conceptual problems reviewed, 
Kiparsky (1993) ends up acknowledging the failure of all attempts to build 
derived environment effects (which he calls NDEB: nonderived environ-
ment blocking) into the theory, or to derive them from some more general 
principle. 
In particular, he declares the bankruptcy of SCC-K:51 it is simply not 
true that the behaviour of a rule with respect to derived environments can 
be predicted from its location in the grammatical architecture. Kiparsky 
(1993:280ff) reviews cases which show that NDEB is neither specific to 
cyclic nor to lexical rules: there are cyclic lexical rules with no NDEB, and 
also NDEB in word-level and postlexical rules. He therefore abandons the 
strategy to add patch after patch to a theory that is void of empirical con-
tent: the SCC-K is on the wrong track and discredits the overall architecture 
of the theory; it must therefore be thrown over board. 
We are thus back to where we started: derived environment effects 
exist, but they are mysterious and escape an implementation in formal 
terms. Kiparsky (1993) declares the failure of all attempts, past and future, 
at expressing NDEB by constraints on underlying forms (Alternation Con-
dition) or phonological computation (Revised Alternation Condition, 
SCC-K, Elsewhere Condition).  
What we are left with, then, are the questions that Kiparsky (1968-
73) already struggled with (§ 186): 1) what distinguishes ("real") rules that 
apply only to derived environments on the one hand from "low-level", 
"automatic" or "phonetic" rules that apply across the board on the other? 2) 
assuming that the answer is known, how do we implement it into a formal 
theory of phonology? 
Kiparsky argues that the empirical record, after 20 years of research 
on the matter, has produced a picture that allows for an accurate description 
of the derived environment animal: the class of obligatory neutralisation 
rules are NDEB. This is the original Revised Alternation Condition (§ 187), 
which "is really no more than a descriptive generalization dressed up as a 
 
51 This is also Cole's (1995:89f) conclusion, who visibly did not hold Kiparsky 
(1993) in hands by the time she wrote. 

170 
Chap 7: Lexical Phonology 
principle and is unstateable as a formal condition on phonological rules", 
but empirically "has struck much nearer the mark" (Kiparsky 1993:277f) 
than SCC-K. 
 
198  8.4.2. Different lexical representations for the same segment 
 
Kiparsky (1993:285ff) then goes on to propose a solution that is based on 
two assumptions: 1) learners construct the simplest grammar (what "sim-
ple" means is left undefined, though, just as in the literature on the evalua-
tion measure, e.g. Kiparsky 1974); 2) lexical entries are maximally under-
specified: a feature can have three values (positive, negative, unspecified). 
What his proposal really relies on, however, is the idea that since the 
encoding of NDEB as a constraint on underlying forms and on computation 
has failed, the derived vs. non-derived contrast must be achieved by differ-
ent lexical representations. That is, morpheme-internal occurrences of a 
segment will have a melodic (featural) setup that is distinct from the one of 
the same segment in morpheme-marginal position (actually, in morpheme-
final position). The tool that allows Kiparsky to express this lexical distinc-
tion is underspecification (e.g. Steriade 1987). 
In the Finnish case of NDEB that was discussed in § 180, the /t/ of 
the essive vete-nä "water" turns into [s] before the infinitival -i in the corre-
sponding nominative form ves-i. By contrast, mono-morphemic /ti/ se-
quences surface without modification, as for example in neiti-nä "young 
lady, essive". Kiparsky (1993:286) proposes that the relevant assibilation 
rule adds the specification [+continuant] to segments that are lexically un-
specified for this feature: [0cont] →[+cont] / __i (where [0α] means that 
the value of the feature is unspecified). /t/s that occur before /i/ in their 
lexical entry, then, are fully specified as [-cont], while /t/s that stand else-
where in the string are unspecified and hence bear [0cont]. A late default 
rule then fills in all unspecified instances of [cont] with a negative value 
(hence making /[0cont]-t/ a real [t]). 
This system blocks the application of the assibilation rule to mor-
pheme-internal /ti/ strings because the /t/, occurring before a tautomor-
phemic /i/, is in fact a /[-cont]-t/: assibilation only targets /[0cont]-t/. Hence 
/neiti-nä/ →[neiti-nä]. By contrast, the underspecified /t/ in /veT-i/ (upper 
case letters indicate underspecification) will be supplemented with the posi-

Derived environment effects 171 
tive value for its /[0cont]/ feature because the assibilation rule targets 
[0cont]; the result is an [s].52 
In support of his analysis, Kiparsky argues that maximally under-
specified lexical representations are the result of the acquisitional process 
because learners target the simplest grammar. 
 
199  8.4.3. Why NDEB processes must be obligatory and neutralising 
 
The question, then, is why only obligatory and neutralising rules may be 
sensitive to derived environments. Recall that Kiparsky believes that this is 
the correct empirical generalisation.53 
Regarding the former issue, Kiparsky (1993:287) argues for an ac-
quisition-based scenario: in order to learn a rule that is sensitive to derived 
environments and optional at the same time, negative evidence would be 
required. Such a rule would produce two possible results in derived envi-
ronments, but only one result in non-derived environments (where it cannot 
apply). Hence, Kiparsky argues, the absence of variability in the latter con-
text cannot be inferred from distributional evidence or the stimulus, which 
means that it could only be understood upon an explicit instruction not to 
apply the rule morpheme-internally ± a piece of negative evidence. Nega-
 
52 In Kiparsky's system, morpheme-internal instances of /t/ that do not occur be-
fore /i/ are also underspecified. Assibilation does not target them, but they are 
filled in with the negative value by the late default rule. Hence /«aTa«/ →
[«ata«]. 
53 Kiparsky (1993) also discusses another condition that involves the distinction 
between structure-building and structure-changing rules (see § 192). In an auto-
segmental environment, autosegmental representations (below and above the 
skeleton) are considered to be structure. In an underspecification perspective, 
then, filling in an underspecified segment is a structure-building process, just 
like the construction of syllable- or stress-relevant structure (Kiparsky assumes 
feet). By contrast, structure-changing processes are those that delete or delink 
autosegmental objects (Kiparsky 1993:288 is not really explicit on this point 
and offers no illustration of a structure-changing process that cannot be 
NDEB). On Kiparsky's analysis, the contrast at hand is relevant foremost for 
suprasegmental phenomena (syllable structure, stress). As far as I can see, how-
ever, he does not provide any explanation why structure-changing processes 
cannot be sensitive to derived environments, or why the distribution of NDEB 
is not the reverse among structure-building and structure-changing processes. 
This aspect of Kiparsky's theory is not really relevant for the discussion, 
though. 

172 
Chap 7: Lexical Phonology 
tive evidence, however, is excluded on general learnability-theoretic 
grounds (e.g. Marcus 1993). 
The fact that rules must be neutralising in order to experience the de-
rived environment restriction follows from the simplicity request. In order 
to show this, Kiparsky (1993:287) discusses English aspiration, which is 
absent from underlying representations and added by rule in entirely pre-
dictable and "automatic" fashion (aspiration is thus a prototypical case for a 
postlexical rule in terms of Lexical Phonology): voiceless stops are aspi-
rated word-initially and in onsets of stressed syllables (with of course a fair 
amount of dialectal variation). This rule is not neutralising since its output 
does not coincide with any segment of the underlying inventory. Kiparsky 
argues that distributional evidence allows learners to construct underlying 
forms without the added feature (here aspiration), and that they will end up 
with unaspirated underlying forms across the board because this is the sim-
plest grammar of English. It is not clear to me, however, why uniformly 
non-aspirated underlying forms should prevent the aspiration rule from 
applying only in derived environments. 
 
200  8.4.4. Posterity of Kiparsky's lexical solution 
 
Even though Kiparsky's (1993) idea to lexically prespecify the invariability 
of morpheme-internal material had an offspring (Inkelas & Cho 1993, Oh 
1995, Inkelas & Orgun 1995, Inkelas 2000), it was not followed by the 
mainstream of Lexical Phonology and follow-up theories. The "orthodox" 
strand (e.g. Rubach & Booij 2003:444) as much as the continuators of 
Halle & Vergnaud (1987a) (§ 237, e.g. Halle & Nevins 2009) to date main-
tain the SCC-K and all the patches mentioned that are necessary in order to 
make the empty shell float. The eventually pernicious character of the 
SCC-K is further discussed in § 214. 
 
201  8.5. Solution 3: bracket-sensitive rules (Mohanan 1982) 
 
202  8.5.1. Bracket-sensitive rules can do all derived environment effects 
 
Mohanan's (1982:24f) bracket-sensitive rules are certainly a much simpler 
way of building derived environment effects into a formal system than the 
SCC-K and Kiparsky's (1993) lexical solution. Mohanan-type brackets and 
their rule-triggering function were discussed and illustrated in § 166; they 

Derived environment effects 173 
are put to use in Mohanan & Mohanan (1984), Halle & Mohanan (1985) 
and Mohanan (1986:21ff). 
Mohanan-type brackets delineate each and every morpheme upon 
concatenation (see § 168) ± what they signal are thus simply (all and only) 
morpheme boundaries. Therefore, a rule whose application is conditioned 
by the presence of a bracket automatically distinguishes between mono- 
and plurimorphemic strings. In order to restrict the application of a rule to 
derived environments, then, the only thing that needs to be done is to make 
it sensitive to brackets. A rule with a bracket in its structural description 
will never apply to mono-morphemic items. 
In the Polish case discussed in § 181, /s/ palatalises before /e/, but 
only if the two segments are separated by a morpheme boundary: /servis-e/ 
"service LOCsg" bears two instances of /se/, one mono-morphemic, the 
other separated by a morpheme boundary. The result is [sɛrvi˛-ɛ]: the latter 
is, the former is not subjected to palatalisation. In order to block palatalisa-
tion within morphemes, it is thus enough to write a rule as under  (86). 
 
(86) 
s →˛ / __ ] [ e 
 
All cases of morphologically derived environment effects could be 
managed like this. Bracket-sensitive rules also have an important advantage 
in comparison with the SCC-K that relies on computation: while brackets 
can be built into rules à la carte, computational principles such as the 
SCC-K marshal all rules alike. What we observe, though, is precisely that 
some rules do obey the derived environment condition, while others do not. 
All attempts at understanding why rules behave in this or that way have 
been rather unsuccessful: the distinction between structure building and 
structure changing rules (see § 193) is not any more operative than the lexi-
cal vs. postlexical distinction (§ 193) or any other criterion that relies on the 
place in the architecture where rules apply (this is what Kiparsky 1993 
shows, see § 197). 
Bracket-sensitive rules thus offer a very simple solution for derived 
environment effects that allows for a process-specific distribution of de-
rived environment sensitivity. This seems to be exactly what the empirical 
record requires. The more surprising is the fact that this option seems to be 
absent from the literature. It appears that nobody has thought of applying 
the bracket-based technology to derived environment effects. Mohanan 
(1986) for example makes ample use of brackets and bracket erasure, but 
does not address the question of derived environments at all. 

174 
Chap 7: Lexical Phonology 
The following section tackles another point that seems to have gone 
unnoticed in the literature: the competition between the two no look-back 
devices that Lexical Phonology has produced, i.e. bracket erasure and the 
SCC-K. 
 
203  8.5.2. Brackets and SCC-K are direct competitors ± but not in the literature 
 
It was shown in § 190 that Kiparsky's version of the Strict Cycle Condition, 
SCC-K, is designed for covering both derived environment effects and no 
look-back effects. It is thus a direct concurrent of Mohanan's (1986) brack-
ets and bracket erasure (see § 168). The previous section has shown that 
bracket-sensitive rules are well suited to account for derived environment 
effects. Together with bracket erasure, they also constitute the no look-back 
device in Mohanan's system (see § 174). 
Curiously enough, though, it seems that the concurrence of Kipar-
sky's SCC-K and Mohanan's bracket-based mechanism has gone unnoticed 
in the literature: I have not come across any work where both ways of go-
ing about derived environment effects and no look-back are discussed. 
Although writing on the backdrop of the SCC-K tradition that Lexi-
cal Phonology lived with in the early 80s, Mohanan (1986) for example 
does not even mention derived environment effects and the Strict Cycle 
Condition. He diplomatically writes that "in the model of Lexical Phonol-
ogy presented in this book, [«] information about concatenation is repre-
sented in terms of brackets" (Mohanan 1986:127f, emphasis mine).  
Be that as it may, the fact that brackets and the SCC-K do the same 
job for derived environments was shown in the previous section. That 
bracket erasure and the other side of the SCC-K coin (strict cyclicity) are 
functionally equivalent is demonstrated below. Table  (87) reproduces the 
SCC-K for convenience. 
 
(87) 
Strict Cycle Condition (SCC-K) 
 
a. Cyclic rules apply only to derived representations. 
 
b. Def.: A representation φ is derived w.r.t. rule R in cycle j iff φ meets the 
structural analysis of R by virtue of a combination of morphemes intro-
duced in cycle j or the application of a phonological rule in cycle j. 
 
(87a) covers derived environment effects, while (87b) takes care of 
no look-back phenomena: a rule may apply to a string only if it uses mor-
phological material that is introduced at the latest cycle.  

Derived environment effects 175 
Comparatively, recall from § 168 that the bracket is the critical ingre-
dient in Mohanan's rule "g →ø / __ [+nasal] ]" that prevents the /gn/ se-
quence in sign-ature from being reduced: at level 2 where it applies, the 
inner brackets of the level 1 concatenation [[sign][ature]] have been erased 
by virture of bracket erasure. By contrast, the level 2 concatenation 
[[sign][ing]] (as well as the nonderived [sign]) still bears inner brackets 
upon the application of the rule, which may thus go into effect. 
On the count of the SCC-K, the stratal organisation is identical, but 
the reason for the non-application of g-deletion to sign-ature is not the 
same: -ature being concatenated at level 1, the level 2 rule g-deletion is 
blocked from applying to the level 1 string sign-ature because it does not 
use any material that was added at the level of its application. By contrast, 
the rule may apply to sign-ing because -ing is merged at level 2. 
The systematic non-reduction of morpheme-internal /gn/ (and /mn/) 
as in ignore (and amnesia) is also covered by the SCC-K, this time by the 
side of the coin that takes care of derived environment effects (87a). 
The combined no look-back and derived environment effect of the 
SCC-K thus covers the rule-triggering pattern for free. The more surprising 
is the fact that the literature does not seem to relate level 2 rules to the 
SCC-K ± or derived environment effects to bracket-sensitive rules. 
Of course, the functional equivalence and hence competition of Mo-
hanan's bracket-based system and Kiparsky's SCC-K does not make any 
statement about the intrinsic merits or problems of the devices at hand. If 
the SCC-K is to be abandoned because it is simply wrong empirically as 
Kiparsky (1993) suggests (§ 197), it is out of business for the analysis of the 
rule-triggering pattern as well. And the same goes if Mohanan's brackets 
are riddled by the concerns that are discussed in § 169. In this case, how-
ever, Lexical Phonology has lost all instruments for the analysis of the rule-
triggering pattern, which begs the question. 
204  8.6. Solution 4: derived environment effects are non-linguistic in nature 
(Anderson 1981) 
 
205  8.6.1. Fultonians: speakers use extra-linguistic evidence (spelling) in order 
to establish underlying forms 
 
Anderson (1981) inquires on the relationship between the linguistic system 
(grammar) and extra-linguistic factors such as acoustics, physiology, per-
ception, general cognitive constraints and so forth. In this resident discus-
sion since Saussure introduced the distinction between Langue and Parole, 

176 
Chap 7: Lexical Phonology 
Anderson defends the Saussurian/Chomskian autonomy perspective. He 
concludes that "an adequate account of the phonological systems of natural 
languages must accord a central role to a set of principles that have no di-
rect foundation in extralinguistic considerations" (Anderson 1981:535). 
Part of his argumentation is to establish criteria that are able to detect 
patterns which are due to extra-linguistic causalities. One of the examples 
discussed are derived environment effects. Anderson (1981:530ff) shows 
that the claim of the (Revised) Alternation Condition is counterfactual: 
English stress reduction provides unquestionable evidence to the end that 
speakers lexicalise forms which never appear on the surface. Anderson's 
example is the proper name Fúlton, whose second syllable is unstressed 
and hence reduced to schwa. There is no way to ever hear anything else 
than a schwa in this name. According to the (Revised) Alternation Condi-
tion, the underlying form should thus be established with a schwa in the 
second syllable. Contra to that prediction, speakers produce an [ow] as 
soon as they are asked to talk about followers of Mr Fulton on the hypothe-
sis of him entering politics and creating his party, the Fultónians. The [ow] 
of course is the regular result of a stressed /o/, which speakers thus had 
lexicalised without prior exposure to the word Fultonians.
Anderson concludes that there are sources of evidence other than the 
phonetic signal and alternations that speakers use in order to establish un-
derlying forms. In the case of Fulton, the relation with spelling is obvious: 
speakers who produce Fultonians with an [ow] have lexicalised an /o/ be-
cause they know how Fulton is spelt. 
 
206  8.6.2. Explaining the genesis of derived environment effects does not 
exonerate from coming up with a synchronic scenario 
 
On these grounds, Anderson argues that the restrictive application of a rule 
to derived environments does not need to be a property of the linguistic 
system: it could as well be an artefact of the learning situation, which pre-
vents speakers from coming across evidence for alternations. That is, alter-
nations are absent within stems, just like in Fulton, but unlike in this case, 
the ordinary situation is that speakers happen to have no access to extra-
linguistic evidence such as spelling or neighbouring dialects. Hence they 
will be left without evidence for an alternation, and therefore do not pro-
duce any. 
Kiparsky (1993:278) discusses Anderson's alternative. While he 
agrees with the acquisitional scenario as an explanation for the genesis of 

Derived environment effects 177 
derived environment effects, he maintains the need for a grammatical man-
agement of the result in adult grammar. It is indeed not obvious how 
Anderson's solution could be implemented into the synchronic functioning 
of a grammar. The non-alternating mono-morphemic items must be some-
how lexicalised, and will then have to undergo phonological rules. If there 
is a rule that concerns an underlying sequence /XY/, and /XY/ occurs 
within a stem, it will undergo this rule. If this rule is sensitive to derived 
environments, however, /XY/ will resist. 
Hence nothing has been gained: we are still looking for a means of 
preventing rules from applying to mono-morphemic /XY/. Anderson (1981) 
does not explain what the lexicalised form of segments of mono-
morphemic items looks like: if their underlying form is faithful to their 
invariable surface, there is no reason why they should not undergo relevant 
rules. If on the other hand invariable items (may) have an underlying form 
that is different from their surface form, they may escape relevant rules ± 
but then we are back exactly to what Kiparsky (1993) proposes. And, as 
will be discussed in § 209 below, essentially to the SPE solution of making 
nightingale /nixtVngael/. 
 
207  8.7. Conclusion 
 
208  8.7.1. A new phenomenon that is poorly understood 
 
No doubt Lexical Phonology in general and Paul Kiparsky in particular are 
to be credited with the discovery of the derived environment phenomenon, 
which is certainly an important property of natural language and was a 
major concern for phonological theory over the years. "I regard the discov-
ery of the existence of rules of this kind as one of the most significant em-
pirical finds in modern phonology", Halle (1978:128) says for example. 
One the one hand, the study of derived environment effects has pro-
duced a stable empirical record, and has helped characterising those proc-
esses that apply only in derived environments, as opposed to those that 
apply across the board. On the other hand, however, the phenomenon is not 
really understood: no operative criterion that allows for a waterproof split 
of processes into those that are and those that are not restricted to derived 
environments has emerged, and the various attempts to account for the 
phenomenon by grammatical tools have not yielded convincing results. 
Lexical Phonology has produced three strategies for the analysis of 
derived environment effects: 1) a constraint on rule application (SCC-K, 

178 
Chap 7: Lexical Phonology 
Kiparksy 1982a,b, Rubach & Booij 1984, 1987); 2) a lexical contrast be-
tween morpheme-internal and morpheme-peripheral variants of segments 
(Kiparsky 1993); 3) Mohanan-style brackets and bracket-sensitive rules 
(following Mohanan's 1982, 1986 system, but which for some reason was 
never applied to derived environment effects). All three solutions are unsat-
isfactory. 
 
209  8.7.2. Kiparsky's solutions miss the facts or the point 
 
The SCC-K is void of empirical content (§ 195): it is simply not true that 
the location of a rule (its application in the Lexicon) determines the way it 
applies (cyclically, i.e. only to derived environments). 
Building the sensitivity to derived environments into the lexicon 
(Kiparsky 1993) comes at the cost of doubling the segmental inventory: the 
same object, i.e. the same phoneme and the same segment, may now have 
two distinct lexical representations, one underspecified at morpheme edges, 
the other not (in morpheme-internal position). Technically, this may pro-
duce the correct result. However, it is hard to trust a solution where the 
same phoneme (or segment) has two distinct lexical representations on the 
grounds of a parameter that has got nothing to do with lexical contrast.  
Still more worrisome is that the lexical solution misses the morpho-
logical generalisation that is at the origin of derived environment effects. 
That is, the environment that blocks the application of a rule is not just any 
environment: only mono-morphemic items block derived environment 
rules. Since the distribution of items is free in the lexicon, this would be 
entirely accidental on Kiparsky's (1993) count: the underspecified and the 
fully specified versions of the same phoneme could as well have the oppo-
site distribution, which would produce underived environment effects ± a 
phonological monster. 
Finally, Kiparsky's (1993) lexical solution is strikingly similar to the 
strategy that was used in SPE, which also relies on a lexical contrast. Recall 
that in order to prevent Trisyllabic Shortening from applying to nightingale 
(and only in order to do so), the underlying form /nixtVngael/ is set up 
(§ 184). Independent rules then take /ix/, which does not satisfy the struc-
tural description of the rule, to [aj]. On Kiparsky's (1993) account, the un-
derlying representation /neiti/ with a morpheme-internal [-cont] /t/ is set up; 
this blocks the Finnish assibilation rule, which applies only to [0cont] /t/. 
By lexical specification (accident?), the [0cont] version of the dental is only 

Conclusion 179 
encountered morpheme-finally (as in /veT/, which is turned into [ves-i] by 
the rule in question). 
In SPE as much as on Kiparsky's (1993) analysis, an artificial lexical 
contrast is introduced that has no motivation other than producing the cor-
rect derived environment effect. In both cases, a late (and automatic) de-
fault rule turns the underlying item that was made artificially different from 
its surface form back to what it really sounds like. 
 
210  8.7.3. Mohanan's bracket-sensitive rules ± a misjudged option 
 
The simplest way of analysing derived environment effects are Mohanan's 
(1982, 1986) bracket-sensitive rules. On this count, rules are directly made 
sensitive to morphological divisions, which appear in structural descrip-
tions as such. The unwarranted burden that brackets represent from the 
modular and theory-internal point of view was discussed in § 169. 
An obvious advantage of this solution, however, is its flexibility: the 
presence of brackets in a rule is an idiosyncratic property of this rule. 
Hence rules may or may not be sensitive to derived environments ± this is 
exactly what we observe: some processes are restricted to derived environ-
ments, others are not. Unless this split may be predicted (all attempts have 
failed thus far), an idiosyncratic solution that allows for process-specific 
sensitivity to derived environments hits closest to the mark. 
The discussion of derived environment effects will be resumed as we 
go along: their status in Kaye's system is discussed in § 284, and solutions 
that are proposed in OT are reviewed in §§ 509, 516. 
 
211  9. Conclusion 
 
212  9.1. Interactionism and multiple mini-grammars 
 
Lexical Phonology is to be credited for two important contributions to 
grammatical thinking and linguistic theory: interactionism and multiple 
mini-grammars. 
Interactionism is the idea that concatenative and interpretational ac-
tivity is interspersed (§ 146). It affords an elegant reconciliation of cyclic 
derivation with the modular request of not representing untranslated mor-
pho-syntactic information in the phonology: this is how the awkward 
brackets of SPE can be done away with (see §§ 161, 170). 

180 
Chap 7: Lexical Phonology 
Traditional grammar and generative orthodoxy (SPE on the phono-
logical, Aspects up to GB on the syntactic side) have always thought of a 
strict ordering of morpho-syntax and phonology (semantics): morpho-
syntactic concatenation is entirely completed before phonological and se-
mantic interpretation begins. This view was long associated with (but in 
fact does not follow from) the inverted T model (§ 86). Interactionism is a 
revolution in this environment: it opens an entirely different view of how 
the three pieces of the inverted T interact. 
We will see in the following chapter that interactionism aroused a 
strong reaction on the side of generative orthodoxy (Halle & Vergnaud 
1987a). A more remote posterity is discussed in §§ 304, 676: since Chom-
sky's (2000a et passim) phase theory, interactionism has become the central 
architectural device of grammar. 
Multiple mini-grammars are the other outstanding contribution of 
Lexical Phonology to linguistic theory. As far as I can see, the idea that 
phonology is made of several distinct computational systems was never 
expressed before.54
Here as well, the innovation unseats classical (generative) thinking, 
at least partly: we will see in § 234 below that it is useful to distinguish be-
tween two types of multiple computational systems: morpheme-based mini-
phonologies (level 1 vs. level 2 rules in Lexical Phonology) and chunk 
size-based mini-phonologies (SPE's word-level phonology, Praguian segre-
gation). Today morpheme-specific mini-phonologies stand unchallenged in 
OT (see §§ 477, 483). In § 828, it is argued that current syntactic theory, 
where Phase Impenetrability is critical, cannot work with morpheme-
specific computational systems at the other end of the phasal pipe (see also 
Scheer 2010b). 
 
54 One could think of loanword phonology as a precedent: a traditional view is 
that loanwords, which in some languages do not obey the same phonological 
constraints as native words, are governed by a specific computational system. 
This is certainly true, but the parallel appears to be spurious: the application of 
regular or loanword phonology is determined idiosyncratically for each lexical 
item; by contrast, multiple mini-phonologies are fully grammatical: they con-
cern the same lexical items. Also, loanword phonology has got nothing to do 
with the interface. As far as I can see, the loanword parallel has played no role 
in the development of Lexical Phonology. By contrast, there is an obvious rela-
tionship between parallel incarnations of multiple mini-phonologies (co-
phonologies, indexed constraints, see § 478) and loanword phonology. 

Conclusion 181 
213  9.2. Unprecedented proceduralisation of the interface 
 
In this book, interface theories are considered in the light of the balance 
between procedural and representational means of talking to phonology. In 
this perspective, the fate of traditional SPE-style boundaries was examined. 
Kenstowicz & Kisseberth (1977:83ff, 1979:407ff) have established a pre-
theoretical classification of phonological patterns that are sensitive to extra-
phonological information (§ 51): morpho-syntactic divisions may either be 
rule-blocking or rule-triggering. This contrast is faithfully reproduced by 
the stratal architecture of Lexical Phonology: it translates as the action of 
two different morpheme-specific mini-grammars. The set of rules that is 
active at level 1 (level 1 phonology) is responsible for the rule-blocking 
pattern, whereas level 2 phonology produces the rule-triggering pattern.  
While Kenstowicz & Kisseberth talked about rule-blocking and rule-
triggering boundaries, the analysis that Lexical Phonology proposes en-
codes the same contrast in terms of procedurally ordered mini-grammars. 
This equivalence is a good witness of the proceduralisation of the interface 
that Lexical Phonology has undertaken. 
Since the 19th century, the only way for morpho-syntactic informa-
tion to reach phonology that linguists have thought of was representational. 
Chomsky et al. (1956) and SPE have introduced cyclic derivation, i.e. the 
idea that information may also be transmitted procedurally (§ 100). How-
ever, SPE remained by and large a representational theory (as far as the 
interface is concerned): affix classes have a representational management in 
terms of boundaries (§ 92), and the idea of a specific word-level phonology 
is also implemented representationally (despite its obviously procedural 
character, see § 105). 
Lexical Phonology is thus the first theory that really gives flesh to 
the procedural idea. It affords an unprecedented proceduralisation of the 
interface, which is an appreciable advance on the diacritic front: boundaries 
are phonological aliens.  
 
214  9.3. Representational communication and the pernicious SCC-K 
 
The central problem of Lexical Phonology, in my view, is that it cannot 
stand up to its non-representational ambition: Lexical Phonology has set 
out to maximise the turnout of procedural communication with morpho-
syntax. Accordingly, the representational component should have shrunk, 
which it did indeed ± without however disappearing completely. 

182 
Chap 7: Lexical Phonology 
The project to proceduralise the interface at the expense of represen-
tational devices was a side-effect of the stratal architecture, rather than a 
primary goal (see § 165). Once it was set in motion, however, boundaries 
were reputed to be out of business. It is true that the stratal system affords a 
drastic reduction of (diacritic) boundaries in interface management. This 
offers an entirely new perspective to the many who were frustrated by the 
oddities of boundaries in the late 70s (see § 131). 
Unfortunately, the procedural tools of the new theory cannot do eve-
rything: the naked stratal architecture cannot account for two core phenom-
ena: the rule-triggering pattern (§ 166) and derived environment effects 
(§ 177). The patches that were proposed in order to bring them home were 
discussed, namely Kiparsky's SCC-K (§ 188) and Mohanan's bracket-based 
system (§§ 168f).55 Curiously enough, the former was not applied to the 
rule-triggering pattern, while the virtues of the latter for derived environ-
ment effects were not explored (§ 201). 
Kiparsky (1993) himself has then declared the bankruptcy of the 
SCC-K, which is simply empirically wrong (§ 197, but Rubach & Booij 
2003:444 continue to advertise an SCC-K-based version of Lexical Pho-
nology). On the other hand, Mohanan's brackets reintroduce SPE-type 
boundaries through the back door. The bracket-based remedy, which is 
designed to cover the rule-triggering pattern, may however turn out to be 
worse than the original disease: § 169 draws the list oddities that one must 
be prepared to go along with when brackets and bracket erasure are taken 
seriously. The result is a hybrid theory where boundaries, which come in 
the rhetorical guise of brackets, are just as critical as they have always been 
in SPE, and also do the same labour (they trigger rules). 
Bermúdez-Otero (2008, forth a:§1.2, §2.6.3) offers a much more de-
tailed overview of stratal Lexical Phonology. He reaches a very similar 
conclusion, expressed with greater vigour, though: all the adornment that 
the practitioners of the 80s were inveigled to add to the basic stratal idea ± 
namely the SCC-K and brackets ± was the fall of man of Lexical Phonol-
ogy (§1.2.2 of his book manuscript is called "The deleterious effects of 
Strict Cyclicity"). In Bermúdez-Otero's view, this is what lured Lexical 
Phonology on to decline (§1.2 is called "Lexical Phonology crippled by the 
legacy of SPE"), and Stratal OT is about to reinitialise the motion on the 
grounds of the original setup. 
 
55 But also Rubach & Booij's (1984) lexical post-cyclic rules or the option of non-
cyclic strata that Halle & Mohanan (1985) provide for, see § 194. 

Conclusion 183 
In conclusion, Lexical Phonology (in its classical or OTed skin, see 
§§ 477, 483) either buys into additional machinery in order to be able to 
account for the rule-triggering pattern, or cannot cover this phenomenon. 
Also, the two disputed patterns ± derived environment effects and 
rule-triggering boundaries ± have in common that they call for a no look-
back device. Today the no look-back issue is at the forefront of the research 
agenda in minimalist syntax: the modern device is called Phase Impenetra-
bility. It is shown in § 828 below that morpheme-specific mini-phonologies 
are incompatible with no look-back since both devices do the same job. If 
Phase Impenetrability is necessary in syntax, then, morpheme-specific 
mini-grammars have to go. 
Finally, it should be borne in mind that if derived environment ef-
fects and the rule-triggering pattern are both about no look-back, they are 
distinct phenomena. Kiparsky's SCC-K is precisely an unsuccessful attempt 
at unifying them. The two patterns are logically independent (§ 182), and 
we will see that while the rule-triggering problem may have a solution in 
the the classical approach to computation which does not provide for mor-
pheme-specific mini-phonologies, derived environment effects beg the 
question as much today as they did when Kiparsky gave up on the SCC-K. 


Chapter 8 
215  Halle & Vergnaud (1987a): selective spell-out and 
SPE-restoration 
216  1. Introduction: a hermaphrodite theory with a new idea 
 
217  1.1. Unseating Lexical Phonology and restoring SPE 
 
Halle & Vergnaud (1987a) (or actually Halle 1986, see § 221) is the starting 
point of a new tradition in the procedural communication between morpho-
syntax and phonology. It combines the basic architecture and tools of SPE 
with an entirely new idea: spell-out of morpho-syntactic nodes is selective; 
whether a node is spelled out or not depends on a lexical specification of 
affixes. 
Morris Halle has always defended SPE: he admits some develop-
ments such as autosegmentalism, but considers the basic architecture cor-
rect. This is also true for the interface: Halle & Vergnaud (1987a) is the 
attempt to restore SPE in this area.  
We have seen in the preceding chapter how profoundly the advent of 
Lexical Phonology has overthrown the architecture (interactionsim) and 
functioning (strata) of the system that SPE had defined. Lexical Phonology 
completely dominated the field by the mid-80s, and Morris Halle at first 
adopted the general framework (Halle & Mohanan 1985), if with the 
amendment that strata may be non-cyclic ± a herald of selective spell-out as 
we will see. Halle & Vergnaud (1987a) then break with Lexical Phonology 
by attacking its foundations, i.e. interactionism and the stratal architecture.  
 
218  1.2. Relations with Lexical Phonology 
 
In the self-understanding of Halle & Vergnaud (1987a:77), the model that 
they propose was "much influenced by the ideas of [Lexical Phonology] 
[«], as well as by such critics of this approach as Aronoff & Sridhar (1983) 
and Sproat (1985)" (more on the latter in § 243). Ten years later, Halle 
(1997b:302) talks about "the Halle & Vergnaud 1987a version of lexical 
phonology". 

186 
Chap 8: Halle & Vergnaud (1987a): selective spell-out and SPE-restoration 
Halle & Vergnaud (1987a:77) list the features that their model takes 
over from Lexical Phonology: strata and the distinction between a lexical 
and a postlexical phonology. They then make the bone of contention ex-
plicit: interactionism. On the face of it, Halle & Vergnaud's theory may thus 
be thought of simply as a non-interactionist version of Lexical Phonology ± 
which is the wrong way to look at the picture: both aspects of continuity 
with Lexical Phonology turn out to be empty word shells. Halle & Verg-
naud in fact eliminate strata and the lexical - postlexical distinction. In 
Lexical Phonology, the latter covers two different things: the distinction 
between a pre-word and a post-word phonology and the idea that these 
represent different computational systems (i.e. are made of different sets of 
rules). We will see in § 238 that Halle & Vergnaud subscribe to the former, 
but reject the latter idea. 
Also, the mention of strata as a tool that was taken over from Lexical 
Phonology is misleading ± or rather, a terminological confusion. While a 
stratum in Lexical Phonology is the association of a certain type of mor-
phological concatenation (e.g. class 1 affixes at level 1) with the associated 
phonological computation (level 1 rules) (see § 152), strata in Halle & 
Vergnaud's terminology are simply serially ordered blocks of rules: "we 
adopt from Lexical Phonology the organization of phonological rules into a 
number of blocks called strata" (Halle & Vergnaud 1987a:77, emphasis in 
original). No morphological activity is implied: Halle & Vergnaud could 
not interleave the serial ordering of rule blocks with concatenation since 
they precisely reject interactionism. Hence the object that is called stratum 
in Lexical Phonology has got nothing to do with Halle & Vergnaud's 
"strata" ± a regrettable terminological confusion that does not help deter-
mining who is who. 
Another point is that two relevant aspects of the relationship with 
Lexical Phonology are not mentioned. Halle & Vergnaud (1987a) follow 
the proceduralising programme of Lexical Phonology (§ 213): the interface 
is only thought of in terms of procedural communication with morpho-
syntax, which means that there is no place for boundaries. Also, morpheme-
specific multiple mini-grammars ± a major innovation of Lexical Phonol-
ogy (see § 212) ± are not mentioned. On the face of it, Halle & Vergnaud 
(1987a) have also taken over this idea: they distinguish between a cyclic 
and a non-cyclic pool of rules. These, however, do not match the level 1 - 
level 2 distinction of Lexical Phonology; rather, they replicate the SPE-
distinction between cyclic and word-level rules (more on this in § 232 be-
low). 
 

Introduction: a hermaphrodite theory with a new idea 187 
219  1.3. Relations with SPE 
 
This much for the relationship of Halle & Vergnaud with Lexical Phonol-
ogy: proceduralisation, multiple mini-grammars, Praguian segregation yes, 
interactionism (and hence strata) no. Again, this may look like a mere non-
interactionist version of Lexical Phonology. That Halle & Vergnaud's model 
is more than that ± in actual fact a movement that is directed against Lexi-
cal Phonology ± appears when comparing it with SPE. 
Boundaries set aside, Halle & Vergnaud restore the complete tech-
nology of SPE. Recall from § 105 that SPE entertained a contrast between 
cyclic and word-level rules. This is exactly what is reproduced under 
slightly different labels: cyclic rules still run under the same name, but 
word-level rules are now called non-cyclic rules (more on the use of the 
word cyclic in § 233).  
Another important aspect of SPE-restoration are brackets, which are 
reintroduced into phonological representations, and which play exactly the 
same role as they did in SPE (the delineation of interpretational units, see 
§98). The revival of brackets is an automatic consequence when interac-
tionism is abandoned: recall from § 161 that interactionism is an advance 
from the modular point of view because it allows eliminating brackets, 
which are phonological aliens.  
A third aspect of SPE-restoration is the dismissal of Praguian segre-
gation ± a genuine finding of Lexical Phonology (see § 238): Halle & Verg-
naud (1987a) acknowledge distinct pre-and post-word interpretation, but 
like in SPE hold that these are carried out by the same computational sys-
tem. 
Finally, SPE is also restored when Halle & Vergnaud (1987a) grant 
cyclic interpretation to sequences of morphemes as much as to sequences 
of words (see § 238): recall from § 158 that the derivation of words is non-
cyclic in Lexical Phonology (postlexical phonology is non-interactionist). 
 
220  1.4. New ideas in interface thinking: selective spell-out and interpretation-
triggering affixes 
 
All this being said, Halle & Vergnaud's model is not just pieced together 
from the bricks that previous theories put on the market. It also makes a 
genuine contribution to interface theory: the idea that the concatenation of 
an affix may or may not trigger interpretation, and hence that morpho-

188 
Chap 8: Halle & Vergnaud (1987a): selective spell-out and SPE-restoration 
syntactic nodes are spelled out only selectively (see § 308 for discussion of 
Bresnan 1971, an early analysis along these lines).  
This mechanism, though in a different guise as we will see 
(§§ 277, 304, 763), is what is known today as derivation by phase: some 
nodes (phase heads) do, others (non-phase heads) do not trigger interpreta-
tion (although phasehood is not ± at least in current syntactic theory ± a 
lexical property of the piece that is merged, an issue that is discussed in 
§§ 767, 782). 
 
221  1.5. Relevant literature and roadmap 
 
The body of work that we are talking about in this chapter is relatively 
small. It was mentioned at the outset of the chapter that the idea of selective 
spell-out and affix-triggered interpretation originates in a 1986 manuscript 
by Morris Halle (Halle 1986), which has never been published, but is some-
times quoted in the literature (not by Halle & Vergnaud 1987a, though).56 In 
this book, the theory exposed in the present chapter is referred to in terms 
of its first manifestation in print, i.e. Halle & Vergnaud's (1987a). 
Halle & Vergnaud (1987a) is a book about stress, not about the inter-
face. The interface as such only plays a role in chapter three, which is 
called Stress and the Cycle. The related interface theory only really 
emerged in subsequent work which includes Halle & Vergnaud (1987b), 
Steriade (1988), Halle (1990), Halle et al. (1991), Halle & Kenstowicz 
(1991) and Odden (1993). It was applied to various areas, and has a modern 
offspring; relevant literature includes Halle (1997b), Halle & Matushansky 
(2006), Halle & Nevins (2009). 
The following pages discuss the anti-interactionist foundations of 
Halle & Vergnaud's theory (§ 222), introduce the new idea, selective spell-
out (§ 232), and describe the design properties of its general architecture 
(§ 232). In a second step, empirical issues are discussed: affix-ordering, 
which turns out to be wrong (a fact that offers ammunition for anti-
interactionism) (§ 243), the empirical coverage of Halle & Vergnaud's 
model in regard of affix class-based phenomena (§ 248), and conflicting 
predictions made by the stratal and the non-interactionist architecture 
(§ 251). 
 
56 Despite intensive research (that included asking phonologists who were active 
in the 80s, as well as a request on Linguist List in June 2008, #044441), I could 
not put my hands on a copy of the manuscript. Morris Halle himself said he 
cannot find any copy. 

Anti-interactionism 189 
222  2. Anti-interactionism  
 
223  2.1. Restoration of the inverted T: all concatenation before all interpretation 
 
In his Ph.D, Sproat (1985) argues in favour of the idea that morphology and 
syntax are expressions of the same computational system whose difference 
lies only the size of the pieces that are concatenated.57 On the other hand, 
he calls into question the difference between the properties of lexical and 
postlexical phonological rules. 
This perspective is incompatible with interactionism where word 
formation, but not syntactic construction, is interspersed with phonology: 
either all concatenative activity is interleaved with phonology, or none is. 
Also, if there is no significant difference between lexical and postlexical 
rules, there is no reason to provide for a split application of phonology be-
fore and after syntax. 
Sproat (1985) thus attacks the basic architecture of Lexical Phonol-
ogy from all sides: his target is the Lexicon ± the locus of interactionism ±, 
which he argues does not exist. This means that the unique concatenative 
device ± morpho-syntax ± must be wholly located before phonology ap-
plies. This view thus restores the original interpretation of the inverted T 
model where all concatenation precedes all interpretation (§ 86). Table  (88) 
below opposes this view and the macro-architecture of Lexical Phonology. 
 
(88) inverted T (SPE) vs. interactionist architecture (Lexical Phonology) 
 
a. inverted T model (§ 86) 
 
b. interactionist architecture (LP) (§ 146) 
 
lexical material 
 
 
 
lexical material 
 
 
 
 
syntax 
 
morphology: word for-
mation 
phonology: interpretation 
of roots and morphemes 
Lexicon 
morphology 
 
 
 
 
 
 
syntax 
 
 
 
 
 
 
 
phonology 
 
 
 
 
postlexical phonology 
 
 
 
 
 
57 This is also the central claim of Distributed Morphology, see § 533. 

190 
Chap 8: Halle & Vergnaud (1987a): selective spell-out and SPE-restoration 
Halle & Vergnaud (1987a:78) quote Sproat (1985) as their source for 
anti-interactionism (but keep morphology and syntax distinct, as under 
(88a)).  
 
(89) 
"We deviate from most proponents of Lexical Phonology in that, following 
Sproat (1985), we do not assign the rules of morphology-prefixation, suffixa-
tion, reduplication, compounding, and so on ± to particular phonological 
strata. Instead, we make the traditional assumption that these rules are the prov-
ince of a special module, the morphology. In our theory, then, as in SPE, mor-
phology is distinct and separate from phonology. Morphology interacts with 
phonology in that it creates the objects on which the rules of phonology operate."
Halle & Vergnaud (1987a:78, emphasis in original) 
 
While this only concerns "most proponents of Lexical Phonology", 
the anti-interactionist stance has a stronger expression in Halle et al. 
(1991).58 
(90) 
"A fundamental tenet of all versions of Lexical Phonology is that affixation 
processes and other rules of word formation, traditionally thought to make 
up a separate module of the grammar (namely, the morphology) are inter-
leaved among the rules of phonology. Counterexamples to this interleaving 
were noted already in Aronoff (1976) but have been widely disregarded. 
They are taken seriously, however, in EOS [An Essay on Stress, i.e. Halle &
Vergnaud 1987a], where morphology is reinstated as a separate component 
of the grammar, ordered before the phonological component." Halle et al.
(1991:142) 
 
Odden (1993:111ff) is another voice that calls for a non-interactionist 
architecture (non-interactive in his terms). He also provides an informed 
comparison with the stratal perspective: necessary and optional pieces of 
both approaches are distinguished. 
 
58 The counter-examples mentioned in the quote are bracketing paradoxes that 
invalidate affix ordering. This issue is discussed in § 243. 
In the 90s, Sproat's view according to which morphology and syntax 
are expressions of the same computational system will become the central 
claim of Distributed Morphology (Halle & Marantz 1993 et passim) (the 
single engine approach, see § 536). The issue that Morris Halle had with 
Lexical Phonology in the 80s, then, is the same as the one that Distributed 
Morphology has with this theory today: the Lexicon has to go (§ 533). 
 

Selective spell-out 191 
224  2.2. Interactionism does not imply the Lexicon and is not incompatible 
with the inverted T 
 
An important point for the discussion below (which was already made in 
§86) is the fact that the inverted T model itself is not incompatible with 
interactionism. It is only its classical interpretation that rules out interleav-
ing of concatenative and interpretative activity: since Aspects and until 
Epstein et al. (1998:46ff), Uriagereka (1999) and Chomsky (2000a et pas-
sim), it was thought that all concatenation is done before all interpretation. 
This assumption, however, is independent of the inverted T architecture. 
We will see in §§ 304, 771 that an architecture where the output of a 
central concatenative system (morpho-syntax) is interpreted by semantic 
and phonological computation may well derive a sentence by iteratively 
piecing chunks together and shipping them off to interpretation. This is the 
description of Chomsky's (2000a et passim) derivation by phase. 
Also, there is no necessary relationship between interactionism and 
the Lexicon: the latter supposes the former, but an interactionist architec-
ture can well live without the Lexicon. Again, derivation by phase instanti-
ates such a system: the derivation is interactionist, but there is no Lexicon 
in sight. 
 
225  3. Selective spell-out 
 
226  3.1. A new idea: affix-triggered interpretation 
 
The headstone of Halle & Vergnaud's (1987a) system is a new idea in inter-
face thinking: affix-triggered interpretation. Affixes are lexically specified 
for triggering interpretation: upon concatenation, they may or may not pro-
voke spell-out. That is, there are interpretation-triggering and interpreta-
tion-neutral affixes. Halle & Vergnaud call the former cyclic, the latter non-
cyclic.59 The following quote illustrates this point. 
 
(91) 
"I shall assume that whether or not an affix is cyclic is not a property of the 
morphological rule by which it is assigned, but is rather an idiosyncratic and 
variable property of the affix." Halle (1986:6), quoted after Kaye 
(1992a:142) 
 
59 There is a trap associated to this terminology: non-cyclic affixes do not trigger 
non-cyclic phonology, which only applies at the word-level when all word-
internal concatenation is completed. 

192 
Chap 8: Halle & Vergnaud (1987a): selective spell-out and SPE-restoration 
As a result, spell-out is selective: two pieces may ± [[X] Y] ± or may 
not ± [X Y] be separated by an interpretational division (which is exactly 
what today is called a phase boundary). That is, they may or may not con-
stitute an interpretational unit. 
Which string exactly cyclic affixes trigger the spell-out of is an im-
portant, but a secondary question that does not vitiate the basic idea of se-
lective spell-out. In Halle & Vergnaud's system, the string that is spelled out 
upon the concatenation of a cyclic affix is made of all the material that was 
previously present in the derivation, plus the material of the affix itself. We 
will see in § 277 below that Kaye (1995) proposes a different take: in his 
model, which follows the idea of selective spell-out, the concatenation of 
an interpretation-triggering affix provokes only the spell-out of its sister 
(i.e. excluding its own material). 
Applied to (English) affix classes, selective spell-out builds on the 
class membership of affixes, which is specified in their lexical entry. Class 
2 affixes, then, do not trigger spell-out (they are non-cyclic), while class 1 
affixes do (they are cyclic). We will see in the following section that this 
perspective prompts the need for considering morpho-syntactic structure as 
such, i.e. as a real structure in the morpho-syntactic sense of the word. Re-
call that Lexical Phonology works without any (or with hardly any) refer-
ence to the morpho-syntactic tree: class membership determines at which 
stratum the affix is merged, and this is all that needs to be understood in 
order to run the derivation. Otherwise hierarchical morpho-syntactic struc-
ture is irrelevant and typically left unmentioned. 
 
227  3.2. Interpretational relevance of affixes percolates to their node 
 
Considerations regarding morpho-syntactic structure are absent from Halle 
& Vergnaud (1987a). As far as I can see, Halle et al. (1991:142) are the first 
to introduce the idea that the lexically specified class membership of affixes 
is inherited by morphological constituent structure upon concatenation. 
While Halle & Vergnaud (1987a) are not really explicit on this issue, Od-
den (1993:114ff) is unmistakable regarding the role of morphological struc-
ture and spell-out: unlike Halle et al. (1991), he shows actual trees and 
supplements them with affix class information. 

Selective spell-out 193 
On Halle & Vergnaud's analysis, then, affixes divide into cyclic and 
non-cyclic items, and this specification percolates to the nodes that domi-
nate them. Table  (92) below depicts this organisation.60
(92) Halle & Vergnaud (1987a): analysis of affix classes 
 
a. univérs-al-ness 
b. govern-mént-al 
 
γ
γ
phon 
 
 
 
 
 
class 2 
β
phon 
 
class 1 
β
class 1 
α
class 2 
α
x
root 
 
 
 
 
x 
root 
 
 
spell-out 
 
spell-out 
 
[root - class 1] class 2 
 
 
 
[root - class 2 - class 1] 
 
 
[univers-al] ness 
 
 
 
[govern-ment-al] 
 
 
Under (92a), the word [[[univérs]al]1ness]2 illustrates the pattern 
where a class 1 (cyclic) suffix precedes a class 2 (non-cyclic) suffix, while 
(92b) shows the reverse order of affix classes, illustrated by the word 
[[[govern]ment]2al]1. Under (92a), β is thus a class 1 node (a cyclic con-
stituent in Halle & Vergnaud's terminology), whereas γ is a class 2 node (a 
non-cyclic constituent). Under (92b), the distribution is the reverse. 
Following Halle & Vergnaud's non-interactionist perspective, the 
derivation then moves on until the structure of the full sentence is built. 
Upon completion of the concatenation, spell-out then transforms the tree 
 
60 The representations show an "x" as the sister of roots. This follows the practice 
in Distributed Morphology (see § 543) where roots are lexically unspecified for 
category (noun, verb, adjective), which is supplied by their sisters. Category-
supplying x's are not conceptually necessary in the present environment and of 
course are absent in Halle & Vergnaud (1987a) and the related literature. They 
merely show that affixes are not sisters of roots. As will be seen shortly, this is 
an explicit requirement of Halle & Vergnaud, since roots must be spelled out in 
isolation. Also note that according to affix ordering (§ 142), the sequence class 2 
- class 1 affix as under (92b) should not exist. This issue is discussed in § 243 
below. 

194 
Chap 8: Halle & Vergnaud (1987a): selective spell-out and SPE-restoration 
into a bracketed linear string, which is the input to phonological computa-
tion.  
Like in SPE, brackets thus transport morpho-syntactic structure into 
the phonology. The genuine modification that Halle & Vergnaud (1987a) 
apply to this system, though, is that the spell-out mechanism ignores class 2 
(non-cyclic) nodes: brackets are only inserted at class 1 (cyclic) nodes. 
Translated into modern (interactionist) terminology, class 1 nodes are phase 
heads, but class 2 nodes are not. That is, a string that is dominated by a 
class 1 node will be subject to phonological (and semantic) interpretation, 
while a string that is dominated by a class 2 node remains uninterpreted. 
 
228  3.3. Underapplication is achieved by selective spell-out of nodes 
 
In Halle & Vergnaud's (1987a) system, the difference between phase heads 
and non-phase heads is converted into contrasting bracketing: univérsalness 
comes down to phonology as /[univers-al] ness/, while governméntal ap-
pears as /[govern-ment-al]/. Like in SPE, interpretational units are thus 
defined by brackets ± but these have been readjusted during spell-out ac-
cording to the contrast between class 1 and class 2 affixes: the latter is in-
visible for the spell-out mechanism and therefore leaves no trace in the 
phonology: a [root+affix 2] string is treated exactly like a mono-morphemic 
string. 
The bracketed string is then parsed by cyclic rules (i.e. at stratum 1 
in Halle & Vergnaud's terms). In our example, the rules in question assign 
penultimate stress to every bracket-enclosed interpretational unit. Hence 
/[univers-al] ness/ 
will 
come 
out 
as 
univérs-al-ness,
while 
/[govern-ment-al]/ is interpreted as govern-mént-al. Note that crucially, 
cyclic rules must not reapply to the entire word in the former case, other-
wise *univers-ál-ness would be produced. This is guaranteed by the fact 
that the entire word is not enclosed in brackets, hence escapes interpreta-
tion. This also supposes, however, that the stress rule is absent from word-
level rules (non-cyclic, stratum 2 in Halle & Vergnaud's terminology), 
which always apply to the result of morphological concatenation. 
Underapplication, then, is achieved by the node-sensitive spell-out 
mechanism: nodes that are skipped do not leave any trace in the phonology. 
This is the central idea of Halle & Vergnaud's work; it is unprecedented in 
linguistic thinking (including SPE and Lexical Phonology). I therefore refer 
to the model as the selective spell-out perspective. This also does justice to 
the fact that Halle & Vergnaud, like SPE but unlike Lexical Phonology, take 

Selective spell-out 195 
the morpho-syntactic tree seriously: their spell-out works exactly like mod-
ern multiple spell-out, which also skips non-phase heads ± the only differ-
ence is Halle & Vergnaud's anti-interactionism, which requires translation 
into brackets prior to interpretation. 
 
229  3.4. The management of English stress 
 
230  3.4.1. Selective spell-out analysis of the párent - paréntal contrast 
 
We have already seen an aspect of Halle & Vergnaud's analysis of English 
stress. Let us now look at the complete mechanism. The reference point is 
the contrast between párent and parént-al which bear transparent penulti-
mate stress on the one hand, and opaque párent-hood on the other (the 
Lexical Phonology analysis of this pattern was discussed in § 147). 
The first thing to be considered are roots: the discussion in § 226 has 
only indicated that affixes may or may not trigger spell-out ± roots were not 
mentioned. The fact that bare roots such as párent receive stress supposes 
that they experience the application of cyclic rules (we already know from 
the analysis in § 226 that stress assignment is a cyclic rule). That is, the 
structures shown under (92a,b) are incomplete: the root-node α also triggers 
interpretation, a fact that, after spell-out, leaves the root enclosed by brack-
ets: the root is an interpretational unit of its own. 
Calling on Halle & Mohanan (1985:66), Halle & Vergnaud (1987a) 
are explicit on the cyclic status of roots. 
 
(93) 
"As noted by Halle and Mohanan (1985), in a cyclic stratum 'the relevant 
phonological rules apply to every morphological constituent in the stratum ±
to the basic stem [«] as well as to every constituent created by morphologi-
cal processes.' " Halle & Vergnaud (1987a:78) 
 
Given that on Halle & Vergnaud's analysis class 1 affixes are cyclic, 
but class 2 affixes are not, table  (94) below shows the structure of parént-al 
and párent-hood.
Paréntal is thus produced by a two-step derivation: first stress is as-
signed to [parent], yielding [párent], then the cyclic stress rule reapplies to 
[párent al], which produces páréntal. In order not to derive a monster with 
two primary stresses, Halle & Vergnaud (1987a:83) introduce a Stress Era-
sure Convention (see also Halle & Kenstowicz 1991:460f) which adds a 
proviso to the stress rule: prior to its application, all previously assigned 
stresses are eliminated. Hence the application of the stress rule to the outer 

196 
Chap 8: Halle & Vergnaud (1987a): selective spell-out and SPE-restoration 
cycle [párent al] first produces [parent al] before the string receives penul-
timate stress. 
 
(94) Halle & Vergnaud (1987a): analysis of affix class-based stress 
 
a. parént-al 
b. párent-hood 
 
β
phon 
 
 
β
al1
α
phon 
 
hood2
α
phon 
 
n
parent 
 
 
 
 
n 
parent 
 
 
spell-out 
 
spell-out 
 
[[parent] al] 
 
 
 
[parent] hood 
 
 
On the other hand, párenthood identifies as /[parent] hood/ and thus 
involves only one pass of the cyclic stress rule, which applies to [parent]. 
This produces the correct result párent-hood.
231  3.4.2. Stress copy: storing before erasing 
 
Stress erasure prompts a concern regarding the contrast between condensa-
tion and compensation, which until today is an oft-quoted piece of the evi-
dence that SPE has accumulated in regard of English stress (see § 546). The 
classical SPE analysis (§ 97) crucially needs stress to be carried over from 
earlier to later cycles: the e of condensation does not reduce to schwa 
(while the e of compensation does) because it bore main stress on the ear-
lier cycle that produced the existing verb to condénse. By contrast, there is 
no verb *to compénse. That is, the e of the associated verb to cómpensate 
was never stressed in its derivational history; it therefore remains unpro-
tected and may reduce (Chomsky & Halle 1968:116). 
This analysis is incompatible with Stress Erasure. Halle & Vergnaud 
(1987a:104ff) react by introducing an additional device called Stress Copy, 
which stores stress information of previous cycles in a parallel structure 
(the metrical grid) before Stress Erasure takes place (see also Halle & 
Kenstowicz 1991:490f, who offer more discussion).  
A further complication is that English features items such as con-
servátion and consultátion (cf. to consérve, to consúlt) that have the same 

The non-interactionist architecture 197 
derivational history as condensátion (cf. to condénse), but do allow for the 
reduction of the pretonic vowel. This contrast (which was unrecorded in 
SPE) appears to be unpredictable and hence an idiosyncratic property of 
words. Since secondary stress is supposed to protect vowels against reduc-
tion, Halle & Kenstowicz (1991:460f, 490f) propose that Stress Copy, 
which conserves primary stresses of earlier cycles in the grid-storage, is 
lexically restricted: rather than being automatic, it applies only on the basis 
of a lexical diacritic that condensátion does, but conservátion does not pos-
sess. 
 
232  4. The non-interactionist architecture 
 
233  4.1. Cyclic vs. word-level (non-cyclic) rules 
 
SPE distinguishes cyclic and word-level rules. Recall from § 105 that the 
former iteratively assess every cycle (i.e. every chunk that is delineated by 
brackets), while the latter apply only once in a derivation, at the word level. 
Also recall that this distinction was implemented representationally, rather 
than procedurally (§ 107): the structural description of word-level rules was 
flanked by ##. This made sure that they could not apply to strings either 
below or above the word-level. It also allowed to maintain all phonological 
rules in one single computational system: there were no multiple mini-
grammars in SPE. 
Halle & Vergnaud (1987a) restore this distinction, but abandon the 
representational management. This option was developed in Halle & Mo-
hanan (1985:66ff), an article that was still couched in regular interactionist 
Lexical Phonology. The innovation that Halle & Mohanan proposed was a 
contribution to the debate which rules are cyclic ± and hence apply only to 
derived environments ±, and which rules are not restricted in this way. Re-
call from § 188 that Kiprasky's SCC-K held that all lexical rules (i.e. those 
that contribute to the construction of words) are cyclic, while postlexical 
rules are not. This generalisation was riddled with counter-examples and 
finally abandoned by Kiparsky (1993) himself (see § 197, more on the dif-
ferent meanings of cyclic in § 236 below). 
In this context, it was already reported in § 194 that Halle & Mo-
hanan (1985) introduced the idea that cyclicity is a property of individual 
strata, rather than of the Lexicon as such. On their analysis, level 1 in Eng-
lish (where class 1 affixes are concatenated) is cyclic, but level 2 (where 
class 2 affixes are merged) is not. This was the birth of the idea that the 

198 
Chap 8: Halle & Vergnaud (1987a): selective spell-out and SPE-restoration 
difference between cyclic and non-cyclic rules is one of serial ordering: the 
former simply apply before the latter. Non-cyclic rules (which apply at 
Halle & Mohanan's 1985 non-cyclic stratum) were thus mechanically re-
jected at the end of the derivation of the word ± and hence exactly recover 
the word-level rules of SPE. 
Word-level rules in Halle & Vergnaud's (1987a) architecture do the 
same labour as they did in SPE, and are motivated by the same phenomena. 
In English, word-level rules are typically related to stress: a number of 
processes make reference to the location of main stress in a word and thus 
can only apply once the locus of main stress is determined (see § 105). 
Processes that take the vowel that bears primary stress as a reference point 
include vowel reduction and stress clash (the Rhythm Rule, Liberman & 
Prince 1977:309ff). The former reduces certain unstressed vowels (Páris 
vs. P[ə]rísian), the latter retracts final main stress when the following word 
has initial stress (thirtéen vs. thírteen mén). 
Halle & Vergnaud (1987a) and the subsequent literature also discuss 
cases from other languages where word-level rules do critical labour (see 
Ziková 2008 for discussion of Halle & Vergnaud's 1987a:82f analysis of 
Russian yers). 
 
234  4.2. Multiple mini-grammars: morpheme- and chunk-specific phonologies 
 
An important question for further discussion is whether Halle & Vergnaud's 
theory implements multiple mini-grammars or not. Recall that multiple 
mini-grammars are a landmark property of Lexical Phonology (§§ 148, 212). 
No doubt the answer is yes since the block of cyclic rules and the 
block of non-cyclic (word-level) rules constitute two distinct computational 
systems that are made of different sets of rules. The fact that they do not 
correspond to any division of the classical stratal architecture is a different 
question. In other words, the contrast between Halle & Vergnaud's cyclic 
and non-cyclic rules has got nothing to do with either the pair level 1 vs. 
level 2 rules or the pair lexical vs. postlexical rules. Table  (95) below reca-
pitulates the three pairs of computational systems that we have come across 
thus far. 
 

The non-interactionist architecture 199 
(95) multiple mini-grammars: three different types 
 
type 
specific phonologies for 
 
a. morpheme-specific pho-
nologies 
affix classes 
b.
1. chunks below vs. at the word level 
 
chunk size-specific pho-
nologies 
2. chunks until the word level vs. beyond 
 
The major line of division that characterises the pairs of computa-
tional systems is the property to which they are sensitive: either to specific 
(classes of) morphemes, or to chunks of a specific size. The former is the 
basic idea of Lexical Phonology where different affix classes are assessed 
by different phonologies (level 1 vs. level 2). The latter falls into two cate-
gories according to the size of the chunks that are opposed: the most famil-
iar distinction is between word- and sentence phonology (i.e. Praguian seg-
regation); this is what is known as the opposition between lexical vs. pos-
tlexical phonology. The other opposes chunks below and at the word level. 
Both have been implemented in Lexical Phonology, the latter only in some 
varieties of the theory under the label of post-cyclic lexical rules (Rubach 
& Booij 1984, see § 194). Table  (96) below shows which theory implements 
which opposition. 
 
(96) multiple mini-grammars: three different types 
 
SPE 
Lexical Phonology 
Halle&Vergn.
a. morpheme-specific 
± 
level 1 vs. level 2 
± 
b. chunk size -specific A 
(below vs. at word level) 
±
lexical cyclic vs. lexi-
cal post-cyclic (§ 194) 
cyclic vs. 
non-cyclic 
 
c. chunk size -specific B 
(morpheme vs. word 
sequences) 
±
lexical vs. postlexical ± 
 
Recall from § 106 that the distinction between cyclic and word-level 
rules existed in SPE, but was managed representationally. As a conse-
quence, SPE formally accommodates only one computational system. Halle 
& Vergnaud (1987a) took the step of implementing this distinction serially 
in terms of different blocks of rules, hence admitting the existence of mul-
tiple computational systems. However, we will see below that this is the 
only type of multiple mini-grammars that Halle & Vergnaud (1987a) ac-
cept: morpheme-specific effects are handled by cyclic rules alone (§ 248), 
and the same computational system assesses sequences of morphemes and 
sequences of words (§ 238). 
 

200 
Chap 8: Halle & Vergnaud (1987a): selective spell-out and SPE-restoration 
235  4.3. The general architecture 
 
It was shown in § 233 that Halle & Vergnaud's (1987a) revival of SPE's 
word-level rules in the guise of non-cyclic rules is based on Halle & Mo-
hanan's (1985) non-cyclic strata which were developed in the environment 
of interactionist Lexical Phonology. It was also mentioned in the previous 
section that Rubach & Booij (1984) (also in further work: Rubach & Booij 
1987, Rubach 1990) had already proposed the existence of lexical, but 
post-cyclic rules (as opposed to lexical cyclic rules, see § 194).  
All these ± word-level rules (SPE), lexical post-cyclic rules (Rubach 
& Booij 1984) and non-cyclic rules (Halle & Vergnaud 1987a) ± are indeed 
the same thing. The only difference between the two former and the latter is 
that Rubach & Booij's version of word-level rules come in addition of the 
regular interactionist strata (level 1 and level 2), while on Halle & Verg-
naud's (1987a) count they replace stratum 2. This is shown under  (97) be-
low. 
As may be seen, Halle & Vergnaud (1987a:78) and Halle et al. 
(1991:142) call the locus where cyclic rules apply stratum 2, while non-
cyclic rules are active at stratum 3.61 Stratum 1 accommodates preword 
allomorphy: this is where allomorphy of the kind that is found in English 
irregular verbs is computed (e.g. sing - sang - sung). In Chomsky & Halle's 
(1968:238ff) summary of rules, preword allomorphy corresponds to read-
justment rules, which are ordered before cyclic rules (word-level rules are 
distinguished from cyclic rules by an asterisk in this summary). 
In sum, thus, Halle & Vergnaud (1987a) reproduce exactly the archi-
tecture of SPE. The only thing that is modified is the switch from SPE's 
representational perspective to the procedural perspective of Lexical Pho-
nology: rather than a representational, word-level rules now have a proce-
dural definition, and boundaries are done away with. 
 
61 But recall from § 218 that "stratum" here does not mean the same thing as in 
Lexical Phonology. 

The non-interactionist architecture 201 
(97) general architectures with a block of non-cyclic word-level rules (SPE) 
 
a. Halle & Vergnaud (1987a) 
(incomplete) 
 
b. Lexical Phonology 
(Rubach & Booij's 1984 version)
underived roots 
 
underived roots 
 
stratum 1 
(preword allomorphy) 
 
Lexicon
stratum 2 
cyclic rules 
interpretation of class 1 nodes 
(before: level 1) 
 
concatenation of 
class 1 affixes 
 
interpretation 
of the result-
ing string 
concatenation of 
class 2 affixes 
 
interpretation 
of the result-
ing string 
word-level rules 
(= lexical post-cyclic rules) 
 
stratum 3 
word-level rules 
(= non-cyclic rules) 
(before: level 2) 
 
words 
 
words 
 
236  4.4. Terminological pitfalls 
 
Given the great many labels, some of which refer to the same thing, it may 
be useful to follow up on  (96) in order to recapitulate the situation. Table 
 (98) below shows relevant equivalences, also anticipating on the discussion 
below where more vocabulary further muddies terminological waters. 
One more terminological pitfall is the word cyclic, which means 
various things in different theories. Originally, SPE opposed cyclic and 
word-level rules because only the former were working through the brack-
eted string: cyclic rules apply iteratively to all chunks of the string that are 
delineated by brackets ± three times for example when the string [[[A]B]C] 
is interpreted. On the other hand, word-level rules apply only once after the 
parsing of the last cycle. They are thus non-cyclic in the sense that cycles 

202 
Chap 8: Halle & Vergnaud (1987a): selective spell-out and SPE-restoration 
are irrelevant for their application, which is triggered by ## (see § 105). In 
SPE, being cyclic for a rule thus merely means to apply to cycles. 
 
(98) equivalences across theories 
 
class 1 
class 2 
word-level 
 
SPE 
readjustment 
rules 
+
#
word-level rules 
Lexical 
Phonology 
±
level 1 rules level 2 
rules 
lexial post-cyclic 
(Rubach & Booij 
1984) (§ 194) 
Halle & 
Vergnaud 
(1987a) 
preword 
allomorphy 
stratum 1 
cyclic rules 
 
stratum 2 
±
non-cyclic rules 
 
stratum 3 
Kaye (1995) ± 
non-analytic analytic 
± 
Stratal OT 
± 
stem-level 
word-level ± 
In (classical) Lexical Phonology, the word cyclic is used in a com-
pletely different way. It now is a synonym of lexical: all rules that apply in 
the Lexicon are cyclic, as opposed to postlexical rules, which apply in non-
cyclic fashion. In other words, cyclicity simply means that the rule in ques-
tion is interactionist: lexical rules are interspersed with concatenative activ-
ity, but postlexical rules are not. This sense was coupled with another 
meaning. In classical Lexical Phonology, all lexical/cyclic/interactionist 
rules obey Kiparsky's Strict Cycle Condition (SCC-K, see § 188), which 
means that they apply only to derived environments. By contrast, postlexi-
cal rules apply across the board. 
In Lexical Phonology, then, the original meaning that the word cyclic 
had in SPE is entirely inoperative: given interactionism, there are no brack-
ets (Mohanan's brackets are not the same thing, see § 171) that could de-
lineate cycles (§ 161). Instead, the relevant interpretational units are strata 
(§ 159). Since specific mini-grammars apply to the different strata, there is 
no type of rule that could iteratively apply to all interpretational units. In 
other words, the stratal architecture and multiple mini-grammars leave no 
place for the SPE-concept of cyclic rules. 
In (classical) Lexical Phonology, lexical, cyclic, interactionist and 
"applying only to derived environments" were thus synonymous at first ± 
until Rubach & Booij (1984) and Halle & Mohanan (1985) introduced rules 
that were lexical, but not cyclic. What both Rubach & Booij's lexical post-
cyclic rules and Halle & Mohanan's rules at the non-cyclic stratum have in 
common is that they do not obey strict cyclicity. In the two approaches at 
hand, then, cyclic rules are necessarily lexical, but all lexical rules are not 

The non-interactionist architecture 203 
cyclic. Being a cyclic rule, however, still means to be interactionist and to 
apply only to derived environments. 
Halle & Vergnaud (1987a) now restore the architecture and the tools 
of SPE, also regarding the word cyclic: just like in SPE, a cyclic rule in 
their model is simply a rule that applies to cycles. Given the non-
interactionist architecture, cycles are defined by brackets, exactly like in 
SPE.  
At this point it may only be hoped that the panorama provided helps 
to disentangle terminological pitfalls, and does not further confuse the 
reader. Bringing up terminology in this context is inescapable: anybody 
who reads through the relevant literature will sooner or later be confronted 
to this question. 
 
237  4.5. No look-back devices 
 
While the Lexicon and its stratal interactionist architecture is dismissed by 
Halle & Vergnaud altogether, Halle & Vergnaud (1987a) (see also Halle et 
al. 1991:141f) take over the Strict Cycle Condition from Lexical Phonol-
ogy: "Strict Cyclicity governs the application of rules in cyclic strata but not 
elsewhere" (Halle & Vergnaud 1987a:78, emphasis in original). The rules 
that do not obey strict cyclicity are thus the same as in Lexical Phonology: 
word-level rules (for those versions of Lexical Phonology that provide for 
them) and postlexical rules. 
In Halle & Vergnaud (1987a) and subsequent publications, the no 
look-back device is always referred to as strict cyclicity, rather than as Ki-
parsky's well-known Strict Cycle Condition. One might thus suspect that 
there is a difference, but this turns out not to be the case: what Halle & 
Vergnaud implement is the SCC-K (rather than the SCC-M or some other 
no look-back mechanism). For example, Halle & Vergnaud (1987a:80) 
follow the classical analysis according to which Trisyllabic Shortening 
(§ 164) does not apply to items such as ivory and nightingale because the 
alternation is managed by cyclic rules, which according to the SCC-K (but 
not according to the SCC-M62) cannot apply to mono-morphemic items 
(see § 189). 
 
62 Recall from §§ 189f that the difference between Mascaró's (1976) SCC-M and 
Kiparsky's SCC-K are derived environment effects: the SCC-K prevents proc-
esses from applying to mono-morphemic items (roots), while the SCC-M does 
not. 

204 
Chap 8: Halle & Vergnaud (1987a): selective spell-out and SPE-restoration 
Given the well-known counter-examples (§ 186), they also follow 
Kiparsky (1982b:160ff) in assuming that the SCC-K is only violated by 
structure-changing rules: if a rule merely adds items to an autosegmental 
representation, it is structure-building and does not conflict with strict 
cyclicity (see § 193).  
An example that demonstrates this contrast is stress assignment in 
English and Vedic. In the former language, stress is not distinctive,63 which 
means that it is absent from lexical representations. The stress-assigning 
rule then adds metrical grid marks: this is adding new structure, rather than 
modifying existing structure. Therefore the SCC-K does not prevent stress-
assignment from applying to underived roots such as párent. By contrast, 
stress is distinctive in Vedic, which means that it is encoded in lexical rep-
resentations. Stress rules that apply to underived roots thus meet existing 
grid structure, which would be modified by their application. Therefore, 
Halle & Vergnaud (1987a:86f) argue, the SCC-K blocks the application of 
stress rules to underived roots in Vedic. 
The question which phonological processes may and which may not 
look back into previous cycles is resident in the literature on no look-back 
devices. Whether the structure-building vs. structure-changing division is 
the correct generalisation is further discussed in §§ 554,780.
238  4.6. Distinct pre- vs. post-word phonology yes, Praguian segregation no 
 
It was mentioned in § 218 that Halle & Vergnaud (1987a) do not subscribe 
to Praguian segregation: the same interpretational device ± the cyclic and 
non-cyclic block of rules ± assesses both sequences of morphemes and 
sequences of words. Hence there is no such thing as a distinct word- and 
sentence phonology. 
This notwithstanding, Halle & Vergnaud (1987a) do acknowledge 
that the word is an autonomous unit which enjoys an independent pronun-
ciation and an independent meaning. Like Lexical Phonology, thus, Halle & 
Vergnaud consider that there are two interpretational stages: first mor-
phemes are interpreted; the computation is then interrupted when the word 
 
63 This is shorthand for a more complicated situation: récord (noun) and recórd 
(verb) is a stress-based minimal pair. However, Halle & Vergnaud (1987a:105) 
consider that "in languages such as English and Spanish, where stresses need to 
be indicated in lexical representations only exceptionally, not systematically as 
in Vedic or Lithuanian, stress is not distinctive and the cyclic stress rules of 
English therefore apply freely to underived stems." 

The non-interactionist architecture 205 
level is reached; the string at hand is assessed by a specific computation ± 
word-level rules (the non-cyclic block in Halle & Vergnaud's terminology) 
±, which "seals" the unit and makes it inaccessible for further modification 
(more on this in the following section). Interpretation then resumes in order 
to assess larger chunks, that is sequences of words. 
Interpretation thus proceeds in two steps like in Lexical Phonology 
where lexical and postlexical phonology is distinguished with the same 
delineation at the word level. But unlike in Lexical Phonology, the content 
of "lexical" and "postlexical" phonology is the same in Halle & Vergnaud's 
architecture. 
This system is implemented into the formal architecture by simply 
adding extra "strata" (in the sense of Halle & Vergnaud) to the general ar-
chitecture. The version under  (97) above is incomplete: it only shows the 
window up to the word level. Table  (99) below completes the picture (Halle 
& Vergnaud 1987a:78, Halle et al. 1991:141f). 
In this system, strata 2 and 3 on the one hand and strata 4 and 5 on 
the other have the same content: the rules that apply at strata 2 and 4 (cy-
clic), as well as at strata 3 and 5 (non-cyclic), respectively, are the same. 
The only difference between strata 2/3 and 4/5 is the fact that a chunk of a 
specific size ± the word ± has been selected at which the cyclic interpreta-
tion (of stratum 2) is interrupted.  
Halle & Vergnaud (1987a) thus restore the classical picture, once 
again: Praguian segregation was unknown in SPE. And they restore the 
SPE-setup yet in another respect: all chunks are subject to cyclic interpreta-
tion, no matter what their size. Recall from § 102 that Chomsky & Halle 
(1968:27) hold that "the transformational cycle [is formulated] in full gen-
erality, applying to all surface structure whether internal or external to the 
word." Contrary to this principle, Lexical Phonology had introduced selec-
tive cyclic interpretation, which applied to sequences of morphemes (lexi-
cal phonology), but not to sequences of words (postlexical phonology) (see 
§158). 
 

206 
Chap 8: Halle & Vergnaud (1987a): selective spell-out and SPE-restoration 
(99) Halle & Vergnaud (1987a): general architecture (complete) 
 
underived roots 
 
 
 
stratum 1 
preword allomorphy 
 
stratum 2 
cyclic rules 
(interpretation of class 1 nodes) 
 
word-internal strata 
 
 
stratum 3 
non-cyclic rules 
(= word-level rules) 
 
words 
 
 
 
stratum 4 
cyclic rules 
 
word-sequence strata 
 
stratum 5 
non-cyclic rules 
 
sentences 
 
 
 
239  4.7. The word as an autonomous phonological unit 
 
240  4.7.1. The word is sealed ± an insuperable barrier for some processes 
 
It was mentioned in the previous section that the word is "sealed": its pho-
nological properties are constructed during the interpretation of morpheme 
sequences, but cannot be further modified when word sequences are inter-
preted. This is a basic insight from SPE which was discussed in § 105: in 
English stress-assignment is cyclic and applies to all cycles until the word 
level. Once this chunk-size is reached, primary stress is identified, and sec-
ondary, ternary etc. stresses are distributed according to this anchor. Vowel 
reduction is also effected according to primary stress. All this is done by 
word-level (non-cyclic in Halle & Vergnaud's terminology) rules which do 
not apply until the word level is reached. 
Chomsky & Halle (1968:133f) insist that word-level rules do not ap-
ply to chunks that are bigger than a word: in the whole derivation of a sen-

The non-interactionist architecture 207 
tence, they are active exactly once ± at the word level. The basic observa-
tion that motivates this is the inactivity of the process that determines word 
stress at larger chunks: whatever happens when phonology is done on word 
sequences, stress placement does not reapply, and the same is true for the 
vowel reduction that depends on it. That is, a word will have the same 
stress pattern no matter whether it receives strong or weak intonation 
(phrasal stress): word stress and intonation are independent.64
Therefore phonological theory must somehow guarantee that at least 
some phonological properties of the body of words cannot be further modi-
fied when phonology is done on word sequences. This is a typical motiva-
tion for Praguian segregation: the rules that apply to sequences of mor-
phemes (word phonology) are not the same as the rules that apply to se-
quences of words (sentence phonology). In Lexical Phonology, thus, the 
solution is simple: the stress-assigning rule is present in the Lexicon, but 
absent from postlexical phonology. 
Systems that reject Praguian segregation are in trouble: on the as-
sumption that the same computational system interprets morpheme- and 
word sequences, the stress rule that applies to the former will also have to 
be active when the latter are assessed. As far as I can see, none of the theo-
ries that implement the continuity of phonological interpretation between 
morphemes and words addresses this issue, let alone offers a mechanism 
that "freezes" words. This is true for SPE, Halle & Vergnaud (1987a), Kaye 
(1995) (on which more in the following chapter) and Distributed Morphol-
ogy. 
 
241  4.7.2. Selective impact of no look-back? 
 
In practice, what needs to be eluded in the English example is the applica-
tion of the stress rule when the pieces [fóllows] and [Jóhn] of the sentence 
Peter follows John are interpreted. The rule that assigns word stress is blind 
for the status of the pieces that it considers. Hence [fóllow-Jóhn] should be 
treated exactly like [órigin-al]: main stress is calculated anew, and vowels 
that bore main stress on earlier cycles are destressed. That is, the first vowel 
of fóllow should lose its main stress and we should observe *follów John,
just like we observe oríginal.
64 Word stress itself may be modified upon the concatenation of another word 
(stress clash, thirtéen vs. thírteen men), but this is done by a different phono-
logical process: the point is that the process that places word stress does not re-
apply to larger chunks. 

208 
Chap 8: Halle & Vergnaud (1987a): selective spell-out and SPE-restoration 
In absence of Praguian segregation, what is thus needed is a way of 
making words immune against further modification ± a no look-back de-
vice. This device, however, must make a difference between the word-
internal and the word-external situation: stress notoriously violates no look-
back word-internally (the concatenation of another suffix erases previous 
stress), but strictly observes no look-back beyond the word level (no further 
concatenation can erase previous stress). 
For the sake of completeness, let us also mention that of course there 
are phonological processes which apply across word boundaries, i.e. where 
the patient belongs to one word, and the trigger to another. Flapping in 
American varieties of English is a well-known case in point (on which 
more in § 821): it concerns /t/ in city as much as in invite Olivia. If words 
trigger phases and are reputed to be "sealed", it must be concluded that the 
sealing-effect applies selectively to processes: while stress assignment is 
blocked, flapping freely applies to word-internal material (see Balogné-
Bérces 2004, 2005 on this issue). 
Again, Praguian segregation offers a simple solution: the stress rule 
will simply be absent from postlexical phonology, while flapping will be 
present both in lexical and postlexical phonology. 
The take-home message at this point is that the word appears to be a 
barrier for some processes, but not for others, and all theories need to be 
able to account for this process-specific sealing effect. Praguian segregation 
offers a straightforward solution, which is not available in systems that 
provide for the interpretation of sequences of morphemes and words by the 
same computational system. These approaches need a sophisticated no 
look-back device that applies selectively to different phonological proc-
esses. Poser (1986, also 1989:135ff) is the earliest source that I could iden-
tify where process-specific no look-back is proposed. The process-
specificity of no look-back is further discussed in §§ 296, 302, 823 (see also 
Scheer 2009a,b,c). 
 
242  4.8. Interpretational units 
 
Let us now have a brief look at how interpretational units are defined in 
Halle & Vergnaud's (1987a) theory. Interpretational units are the chunks of 
the linear string that are interpreted at the same time. Recall from § 103 that 
the interpretational units of SPE, bracket-delineated cycles, are identical to 
morphemes, except that two successive morphemes of the same major 

Anti-interactionist ammunition: bracketing paradoxes 209 
category (noun, verb, adjective) cohabitate in the same cycle. Hence theat-
ricality identifies as [[[theatr]N ic + al]A i + ty]N.
In Lexical Phonology, strata are interpretational units (§ 159). That is, 
all affixes of the same affix class are interpreted together. A root with two 
class 1 affixes such as origin-al1-ity1 for example represents just one inter-
pretational unit: [origin-al-ity] (while it identifies as three units in SPE: 
[[[origin]N al]A ity]N). 
Here as well, Halle & Vergnaud (1987a) restore the take of SPE ± but 
it is not clear to me whether they abandon the proviso regarding major 
categories. On the one hand, they are explicit about the fact that indeed 
they do: every morpheme is a new cycle. 
 
(100) "As noted by Halle and Mohanan (1985), in a cyclic stratum 'the relevant 
phonological rules apply to every morphological constituent in the stratum ±
to the basic stem [«] as well as to every constituent created by morphologi-
cal processes.' " Halle & Vergnaud (1987a:78) 
 
On the other hand, however, they work with representations that em-
body the state of affairs in SPE: for example, one may come across the 
word ungrammaticality, which on Halle & Vergnaud's (1987a:81) account 
identifies as [[un-[grammat + ic + al]A ]A ity]N.
243  5. Anti-interactionist ammunition: bracketing paradoxes 
 
244  5.1. Affix ordering turns out to be wrong: bracketing paradoxes 
 
Interactionism (supplemented with level ordering) enforces affix ordering 
(§ 147), Siegel's (1974) generalisation according to which class 1 affixes 
never occur outside of class 2 affixes. Recall from § 146 that Siegel's dis-
covery played a crucial role in the establishment of the stratal architecture. 
Affix ordering is therefore a prime target for anybody who wants to do 
away with interactionism: in its absence, there is no reason for affixes to 
observe a specific order. 
This is precisely Halle & Vergnaud's line of attack: they call on work 
by Aronoff (1976) and Aronoff & Sridhar (1983, 1987) who have collected 
empirical evidence against affix ordering since 1976 ± so-called bracketing 
paradoxes ±, but which for some reason did not have much impact. Kipar-
sky (1982a:28f) for example acknowledges their existence, but has got 
nothing much to say, except that they are lexically marked as exceptional. 
The empirical argument along the lines of the counter-examples that Mark 

210 
Chap 8: Halle & Vergnaud (1987a): selective spell-out and SPE-restoration 
Aronoff has accumulated since 1976 is made in Halle & Kenstowicz 
(1991:459) and Halle et al. (1991:142) (Halle & Vergnaud 1987a:77 con-
tains only a hint at Aronoff & Sridhar 1983). 
Today there can be no doubt that affix ordering is indeed empirically 
unsustainable: it is simply a wrong generalisation. Bermúdez-Otero (forth 
a:29f) provides a documented overview of the issue from a post-hoc per-
spective. 
Bracketing paradoxes are thus cases where a class 2 affix occurs 
closer to the root than a class 1 affix. Items of this kind are actually not 
infrequent; some examples appear under  (101) below. 
 
(101) affix ordering: counter-examples 
 
a. patent-abíl2-ity1
b. develop-mént2-al1
c. organ-iz2-at-ion1
d. un-2grammatic-al1-ity1
Under (101a-c), the class 2 suffixes -able, -ment and -ize occur be-
fore the class 1 suffixes -ity, -al and -ion. Class membership of affixes is 
identified by their behaviour in regard of stress (which is taken to be a con-
clusive diagnostic in the literature): the former are stress-neutral, while the 
latter are stress-shifting. 
The most famous bracketing paradox is certainly (101d) 
un-grammatic-al-ity: the class 1 affix -ity attaches to un-grammatical,
which already contains the class 2 affix un-. That un- is concatenated to 
grammatic-al, rather than to the fully suffixed grammatic-al-ity is war-
ranted by two observations: 1) we know independently that un- only at-
taches to adjectives, and 2) ungrammaticality means "the fact of being non-
grammatical", not "non-grammaticality" (hence un- has scope only over 
grammatical). 
 
245  5.2. Dual membership, optionality, overgeneration 
 
Another argument that may be brought to bear against affix ordering is so-
called dual membership, i.e. the fact that some affixes seem to belong to 
several affix classes. Affixes may indeed show class 1 behaviour in regard 
of some phenomenon, but come along as class 2 affixes on other occasions. 
Cases in point are -ment and -ation (see the detailed discussion in Giegerich 
1999:21ff and Szpyra 1989:40ff, 186ff). 

Anti-interactionist ammunition: bracketing paradoxes 211 
Minimal pairs such as cómparable "roughly the same" vs. com-
párable "able to be compared" also illustrate dual membership: stress shift 
is usually taken to be a conclusive diagnostic for class 1 membership (class 
2 affixes are stress-neutral). Accordingly, there should be two -able suf-
fixes, one in each class (more on this issue in § 545). Dual membership of 
course weakens the empirical content of affix ordering. 
Optionality is also an issue: Trevian (2007:435) points out that some 
reportedly stress-shifting affixes (púpil - pupíll-ary) may or may not behave 
along these lines (free variation) when combined to certain stems: frágment 
- frágment-ary or fragmént-ary; dísciplin - dísciplin-ary or discíplin-ary.
In addition to these questions, other empirical and conceptual objec-
tions have been raised against the interactionist architecture of Lexical 
Phonology, for which the analysis of English affix always played an impor-
tant role. Giegerich (1999:21ff), McMahon (2000:55ff), Marvin (2002:74ff) 
and Bermúdez-Otero (forth a:§2.5) provide more detailed material from a 
settled post-hoc perspective. 
 
246  5.3. Halle & Vergnaud's analysis of bracketing paradoxes 
 
Since there is no interactionism in Halle & Vergnaud's system, there is no 
reason why affixes of both classes should not freely combine in any order. 
We have already seen in § 226 how both class 1 - class 2 and class 2 - class 
1 sequences are analysed according to Halle & Vergnaud's selective spell-
out: univérs-al1-ness2 and govern-mént2-al1 identify as /[univers-al] ness/ 
and /[govern-ment-al]/, respectively. Stress is then simply penultimate 
within the domain that is delineated by brackets. 
Let us now see how the notorious un2-grammatic-ál1-ity1 is derived 
(Halle & Vergnaud 1987a:81). Recall from § 244 that for semantic (un- has 
only scope over grammatical) and selectional (un- attaches only to adjec-
tives) 
reasons 
the 
morpho-syntactic 
structure 
must 
be 
[[un2 [[grammatic] al1]A]A ity1]N, which according to class-sensitive selec-
tive spell-out of affix boundaries is handed down to phonology as 
/[un [grammatic-al] ity]/ (recall that each class 1 node produces an interpre-
tational unit). Antepenultimate stress then applies first to the inner domain 
(yielding grammátical), and on a second pass (after stress erasure) to the 
outer domain, which produces antepenultimate ungrammaticálity.
In interactionist Lexical Phonology, bracketing paradoxes have been 
treated by carrying a representational component into the analysis. § 440 
shows how Rubach & Booij (1984) make use of the Prosodic Hierarchy: 

212 
Chap 8: Halle & Vergnaud (1987a): selective spell-out and SPE-restoration 
the morpho-syntactic structure (where affix ordering is respected) is trans-
formed into prosodic constituency (where affix ordering is not respected); 
phonological rules then make reference to the latter, rather than to the for-
mer. 
 
247  5.4. Affix stacking generalisations as selectional restrictions or parsing-
based (Fabb 1988, Hay 2002) 
 
An entirely different outlook on affix class-based phenomena is profiled by 
Fabb (1988) and further developed by Hay (2002), Hay & Plag (2004) and 
Plag & Baayen (2009). The initial fact observed by Fabb (1988) is that affix 
ordering quite largely overgenerates: given the number of suffixes, their 
class membership and all other combinatorial restrictions, there should be 
459 possible suffix pairs. The number of attested pairs, however, only 
amounts to fifty. 
Based on this observation, Fabb (1988) argues that Siegel's (1974) 
affix ordering generalisation is certainly too strong and empirically wrong, 
but that this does not mean that there are no restrictions on affix combina-
tion (affix stacking) at all. There are robust generalisations, and grammar 
must somehow be at the origin of the restrictions observed. He suggests 
that the mechanism which decides whether an affix can attach to a string is 
based on the selectional properties of this affix: individual affixes may (or 
may not) be sensitive to the fact that a potential host is already affixed. That 
is, a large number of affixes do not attach to already affixed words.  
Hay (2002), Hay & Plag (2004) and Plag & Baayen (2009) have fur-
ther developed this idea, shifting it on extra-grammatical grounds: they 
argue that affix stacking is controlled by parsing and perception along a 
hierarchy of processing complexity, rather than by selectional properties. 
On their view, the degree of internal complexity of a host that an affix tol-
erates is determined "by how much structure that affix itself creates. 
Phrased in terms of processing, an affix that can be easily parsed out 
should not occur inside an affix that cannot" (Hay 2002:528, emphasis in 
original). Plag & Baayen (2009) complement this strand by psycho-
linguistic evidence (lexical decision, word naming) which they argue shows 
that productivity and memory are also relevant factors. 
This approach thus first insulates affix class-based phenomena from 
phonology (selectional properties do not explain why there is a class-
specific phonological effect), and then from grammar altogether (percep-
tion and parsing are the reasons why some combinations do, but others do 

Empirical coverage of Halle & Vergnaud's selective spell-out 213 
not occur). Whether this is the correct way to go about affix class-based 
phenomena is left an open question in the book. 
 
248  6. Empirical coverage of Halle & Vergnaud's selective spell-out 
 
249  6.1. Analysis of the rule-blocking pattern (level 1 rules) 
 
We have seen how Halle & Vergnaud's system covers English stress: the 
selective spell-out analysis is the same whatever the order of affixes. Also, 
the opacity of párent-hood is derived with the same mechanism (§ 230). 
Recall from § 164 that English stress assignment is a representative of 
the rule-blocking pattern, which in Lexical Phonology translates as level 1 
rules. In Halle & Vergnaud's system, all other rule-blocking phenomena are 
analysed along the same lines. That is, relevant rules are always cyclic, but 
absent from the non-cyclic (word-level) block. The structure that selective 
spell-out of morpho-syntactic structure produces, then, is always the same.  
Trisyllabic Shortening for example applies to san-ity1, but not to 
maiden-hood2: the former reaches phonology as /[[san] ity]/, while the lat-
ter comes down as /[maiden] hood/. The trisyllabic condition prevents the 
rule from applying to [san], the inner cycle of sanity (as much as to the bare 
root sane). Since the whole word is a cycle as well, though, Trisyllabic 
Shortening tries to reapply at the word level, and this time goes into effect 
because the trisyllabic condition is met. By contrast, the only cycle of 
maidenhood, [maiden], does not allow for the application of the rule, and 
the word as a whole is not a cycle, which prevents Trisyllabic Shortening 
from reapplying. 
The same mechanism correctly derives the nasal assimilation of in-,
against 
the 
non-assimilation 
of 
un-.
Im-1possible 
identifies 
as 
/[in [possible]]/, 
while 
un-2predictable 
enters 
phonology 
as 
/un [predictable]/. The cyclic rule of nasal assimilation then applies to the 
former because the prefix together with the root is a cycle and hence ex-
periences common interpretation; by contrast, there is no outer cycle in the 
latter, which means that the string which contains the /«np«/ sequence is 
never assessed by nasal assimilation. 
Note that it is crucial for this analysis of the rule-blocking pattern 
that the relevant rules are absent from the word-level (non-cyclic) block. 
 

214 
Chap 8: Halle & Vergnaud (1987a): selective spell-out and SPE-restoration 
250  6.2. No solution for the rule-triggering pattern (level 2 rules) 
 
Let us now look at rule-triggering boundaries (level 2 rules, see § 166). As a 
matter of fact, Halle & Vergnaud's system is as unsuited for the analysis of 
this pattern as the stratal architecture of Lexical Phonology where, recall, 
additional machinery is needed (Mohanan's brackets or the SCC-K, see 
§§ 168, 203). 
The cyclic structure that Halle & Vergnaud's affix class-sensitive se-
lective spell-out produces for the three relevant items sign, sign-ing2 and 
si[g]n-ature1 is /[sign]/, /[sign] ing/ and /[[sign] ature]/, respectively. 
The cluster-reducing rule must be absent from the word-level (non-
cyclic) block: otherwise sign-ing and sign-ature will experience the same 
treatment. That is, no inner brackets are left at the word-level (the non-
cyclic stratum); therefore bare unstructured strings are assessed. A rule such 
as g →ø / __n will thus reduce the cluster of sign-ature as much as of 
sign-ing (and sign).  
Making the rule cyclic does not help either. It will be blocked from 
applying to the root-cycle by the SCC-K to which Halle & Vergnaud sub-
scribe (§ 237). The blocking effect is real since the cluster reducing rule is 
structure changing (it deletes an entire segment), not structure building (see 
§237). 
This means that the bare root sign will remain unreduced (also at the 
word level from which the cluster reduction rule must be absent as we have 
seen) ± this is an incorrect result. Worse, Halle & Vergnaud's system distin-
guishes class 1 si[g]n-ature1 and class 2 sign-ing2 by contrasting cyclic 
structure, but the result after computation is exactly the reverse of what is 
attested: /[sign] ing/ has no outer cycle and will thus remain unreduced 
*si[g]n-ing, while the complete string of /[[sign] ature]/ undergoes cyclic 
computation at the outer cycle, where cluster reduction goes into effect and 
produces *sign-ature.
This "reverse result" is characteristic for Halle & Vergnaud's system: 
it indicates that in fact the method is correct ± selective spell-out ±, but that 
it may need to be applied in the opposite way: class 2 affixes do, class 1 
affixes do not insert brackets into the phonological string. Distribution of 
brackets along these lines would produce /[[sign] ing]/ and /[sign] ature/; 
after computation, the cluster would be reduced in the former case because 
there is an outer cycle, but would remain untouched in the latter since there 
is no computation of the complete string. 

Stratal vs. non-interactionist architecture: two testing grounds 215 
We will see in § 281 that this is exactly the direction option taken by 
Kaye (1995): selective spell-out yes, but reverse distribution of brackets 
(today one would say: of phase heads). 
In sum, then, Halle & Vergnaud's system seems to be structurally un-
able to come to grips with the rule-triggering pattern. The situation is thus 
parallel to one that prevails in Lexical Phonology: in both cases the basic 
mechanism (i.e. the stratal architecture there, selective spell-out here) can 
cover the rule-blocking pattern without problem, but fails when it is con-
fronted with the rule-triggering pattern.  
Unlike in the case of Lexical Phonology, however, the additional 
machinery that was proposed will not help out Halle & Vergnaud. The 
string cannot be enriched by Mohanan's brackets (§ 168) at every morpheme 
boundary since the principle of Halle & Vergnaud's system is precisely to 
spell-out morphological boundaries selectively. The other tool that can ac-
count for the rule-triggering pattern in Lexical Phonology, the SCC-K 
(§ 203), will not help either since it is already operative. 
As far as I can see, the rule-triggering pattern is not discussed in the 
literature that subscribes to Halle & Vergnaud's (1987a) selective spell-out 
model at all. In Halle & Mohanan (1985:62f), nasal cluster simplification is 
analysed along Mohanan's bracket-sensitive rules that are not an option 
anymore two years later in Halle & Vergnaud's anti-interactionist environ-
ment. The silence regarding the fact that a well-known pattern cannot be 
accounted for by Halle & Vergnaud's theory is strange and does not help 
finding out about the comparative merits of the theories of procedural inter-
face management. 
 
251  7. Stratal vs. non-interactionist architecture: two testing grounds 
 
252  7.1. Syntactic information is or is not available when words are build 
 
The stratal architecture and Halle & Vergnaud's non-interactionist model 
contrast in a number of properties that may give rise to different predic-
tions. Two such testing grounds are discussed in the literature in some de-
tail: the possibility for derived phonological properties to bear on the con-
catenation of morphemes, and the availability of syntactic information for 
the construction of words. 
Let us first consider the latter. Lexical Phonology makes the predic-
tion that syntactic information cannot be used for the construction of 
words: morphological activity takes place in the Lexicon, which is ordered 

216 
Chap 8: Halle & Vergnaud (1987a): selective spell-out and SPE-restoration 
before syntax (§ 152). By contrast, syntax precedes morphology in the tradi-
tional view that Halle & Vergnaud (1987a) subscribe to.  
The contrasting predictions are the central issue of Odden 
(1993:117ff), who presents a case from Kimatuumbi where certain rules 
that must be lexical are also informed by syntactic properties. As far as I 
can see, this strand of the discussion was not further developed in the litera-
ture. 
 
253  7.2. Phonology-free syntax: is morphological concatenation sensitive to 
derived phonological properties? 
 
On the backdrop of Zwicky & Pullum's (1986a,b) principle of Phonology-
free Syntax (which is discussed at greater length in § 412), Lexical Phonol-
ogy has identified another testing ground. On interactionist assumptions, 
morphological concatenation can be done after some phonological rules 
have applied (to earlier strata). Therefore, morphological activity may be 
sensitive to derived phonological properties, i.e. to properties that are cre-
ated by phonological computation (but are absent from the lexicon). By 
contrast, in the traditional non-interactionist perspective where all concate-
nation is completed before phonological interpretation begins, morpho-
syntax can never be influenced by derived phonological properties. 
These contrasting predictions are run against the empirical record in 
the state-of-the-art volume edited by Hargus & Kaisse (1993): Booij & 
Lieber (1993), Booij (1997:262f) and Inkelas (1993) argue in favour of 
interactionism (also Szpyra 1987). Especially Hargus (1993) collects rele-
vant cases where derived phonological properties appear to influence mor-
phology, but Odden (1993) proposes a reanalysis in a non-interactionist 
perspective. 
While the predictions on both sides are sufficiently distinct and ex-
plicit, their confrontation with the empirical record appears to be inconclu-
sive, at least on the basis of the literature mentioned. 
 
254  8. Conclusion 
 
255  8.1. SPE with Lexical Phonology freckles 
 
One result of the discussion above is that Halle & Vergnaud's (1987a) 
model is more akin with Lexical Phonology in the self-understanding of the 

Conclusion 217 
authors than in actual fact. That is, it is rather misleading to think of Halle 
& Vergnaud's theory as a non-interactionist version of Lexical Phonology: 
Halle & Vergnaud (1987a) dismiss all key properties of the dominant inter-
face framework of the 80s, i.e. of course interactionism (and hence strata, 
despite the fact that they also talk about "strata", see § 218), but also Pra-
guian segregation and the management of affix class-based phenomena by 
multiple mini-grammars.  
On the other hand, Halle & Vergnaud (1987a) adopt two ideas that 
were coined by Lexical Phonology: the proceduralisation of the interface 
and the SCC-K. That is, boundaries have as much disappeared from the 
analysis of interface phenomena in Halle & Vergnaud's perspective as they 
have in Lexical Phonology. This cut-down of representational communica-
tion is at variance with the situation that prevailed in SPE (see § 105).  
Halle & Vergnaud (1987a) also take over Kiparsky's (1982a,b) ver-
sion of the Strict Cycle Condition, which roots in Chomsky (1973) and 
Mascaró (1976), but adds the concern for derived environment effects 
(§§ 189f). 
A characterisation of Halle & Vergnaud's project that strikes closer to 
the mark is certainly one that mentions SPE: the basic goal is to restore the 
SPE-setup. Without really being explicit on that, Halle & Vergnaud put 
back to office a non-interactionist architecture ("all concatenation before all 
interpretation"), the distinction between cyclic and word-level rules, the 
cyclic interpretation of word sequences (which was abandoned by the non-
cyclic conception of postlexical phonology in Lexical Phonology), the use 
of brackets (i.e. untranslated morpho-syntactic information in phonology), 
preword allomorphy and the SPE-definition of what counts as an interpreta-
tional unit. 
 
256  8.2. Selective spell-out is a groundbreaking idea 
 
Beyond the question how much genetic material Halle & Vergnaud's model 
has inherited from SPE, and how much is due to Lexical Phonology, its 
genuine contribution to interface theory needs to be praised: selective spell-
out. We will see below that this idea has become part and parcel of the gen-
erative interface architecture today (§§ 304, 763): in modern terminology, 
not every node is a phase head, and only phase heads trigger interpretation. 
Interestingly, the idea itself says little about its implementation: once 
it is understood that not all nodes are spelled out, it needs to be decided 
which nodes exactly do, and which do not trigger interpretation. Under the 

218 
Chap 8: Halle & Vergnaud (1987a): selective spell-out and SPE-restoration 
label of phasehood, this is an important issue in current syntactic debate 
(see § 771).  
We have seen that Halle & Vergnaud's choice to make class 1 nodes 
cyclic (phase heads), while class 2 nodes are transparent for interpretation, 
produces correct results for the rule-blocking pattern, but fails when con-
fronted with the rule-triggering pattern (§ 250). The following chapter 
shows that completely different results are produced when 1) the root is not 
made a cycle per se, 2) the same (i.e. cyclic), rather than a different (non-
cyclic) phonology reapplies at the word level, 3) a no look-back device 
does actual labour in the derivation of affix class-based phenomena and 4) 
this device is reduced to its original expression, that is the SCC-M.  
The system described is Kaye's (1995): selective spell-out yes, dis-
tinct word-level phonology no, derived environment management by the no 
look-back device no. 
 
257  8.3. Distinct computational systems yes ± but which ones? 
 
Multiple mini-grammars will be a resident issue in the book. The question, 
however, is not only whether phonology should accommodate distinct 
computational systems ± it is also, and perhaps foremost, which type of 
multiple mini-grammars should be provided for. A distinction that will 
prove relevant was introduced in § 234: distinct computational systems may 
be specific to morphemes (or morpheme classes), or they may be sensitive 
to the size of the chunks that are assessed. 
This issue is related to the status of the word as a chunk size that re-
quires particular care. Halle & Vergnaud (1987a) admit the distinction be-
tween pre- and post-word phonology (in continuity of Lexical Phonology, 
§238), but reject Praguian segregation (in discontinuity of Lexical Phonol-
ogy). This prompts the issue of the word as "natural barrier" for phonologi-
cal processes (§ 239). 
It is a characteristic property of theories which reject Praguian segre-
gation ± hence where the same computational system assesses morpheme- 
and word sequences ± to be in trouble when the application of word-
internal processes is blocked across words (as is the case for English word 
stress). Halle & Vergnaud (1987a) do not explain how they handle this phe-
nomenon any more than more recent theories which provide for an interpre-
tational continuity of morphemes and words. Another case in point, Kaye 
(1995), is discussed in the following chapter. 
 

Chapter 9 
258  Kaye (1995): selective spell-out and modification-
inhibiting no look-back 
259  1. Introduction 
 
260  1.1. Editorial note 
 
The following pages attempt to provide a comprehensive overview of how 
the interface has been thought of in Government Phonology. Or rather, by 
Jonathan Kaye, who has initiated and worked out relevant ideas. According 
to him, a conference presentation together with Jean-Roger Vergnaud (Kaye 
& Vergnaud 1990) was the initial spark of the programme that was then 
developed throughout the 90s. 
A pervasive problem is that Kaye has only published one article on 
the subject, Kaye (1995), and that this article contains only a subset of the 
ideas and the empirical material that were developed over the years. True, 
his 1989 book (Kaye 1989) gives the direction of much of the enterprise 
(parsing cues, following Trubetzkoy's Grenzsignale), and Kaye (1992a) is 
also relevant (regarding affix-triggered interpretation and the φ-function). 
These sources, however, are either programmatic (the book) or marginal for 
the purpose (the 1992a article). One can then rely on secondary sources, 
that is work by SOAS students of the 90s who summarise Kaye's interface 
design on a few pages at the outset of their own articles and dissertations. 
The available material here, however, is also sparse (e.g. Ploch 1996:76f, 
Cobb 1996:30f, 1997). 
In short, anybody who tries to reconstruct the complete picture of 
Kaye's interface theory from sources that are available in print will be given 
a hard time. This is especially true for the sections on parsing cues and 
lexical access (§§ 340, 346). The presentation below therefore relies on un-
published sources as well: Kaye's teaching at the EGG Summer School 
(Niã 2001, Novi Sad 2002, Lublin 2003), and personal discussion with him. 
Finally, a it is probably useful to make explicit the fact that although 
I am personally committed to Government Phonology, Kaye's interface 
theory is treated like all others in the book: its properties are reported, and 
connections are made with other theories. It is not necessarily the theory 
that I am defending, and I may or may not personally agree with it. 

220 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
261  1.2. Roadmap 
 
The roadmap is as follows: § 262 introduces the foundations of Kaye's ap-
proach to the interface, which are functional and perception-oriented. The 
formal apparatus that he uses, domain structure, is then presented in § 266. 
The heart of the chapter are § 266 and § 277: it is shown that Kaye 
follows Halle & Vergnaud (1987a) in implementing selective spell-out ± 
but he adds a no look-back device that, unlike all others (Chomsky 1973, 
SCC-M, SCC-K, Mohanan-style Bracket Erasure), inhibits the modification 
of "old" strings. The contrast of this mechanism with previous no look-back 
devices is discussed in § 287. Kaye's instrument turns out to be the ancestor 
of Chomsky's Phase Impenetrability Condition (PIC).  
Its empirical coverage is interesting: unlike Halle & Vergnaud 
(1987a), the rule-triggering pattern is fully covered; the rule-blocking pat-
tern is also accounted for, however with an exception regarding cases 
where the affix, rather than the root is modified (§ 310). 
Also, Kaye's position in the debate regarding multiple mini-
grammars is discussed: his system makes the same choices as Halle & 
Vergnaud's (1987a) model, that is morpheme-specific phonology no, word-
level-specific phonology yes, word-sequence-specific phonology no. 
In a second step, the (diachronic) consequences of domain structure 
are discussed (§ 328), Kaye's conception of the organisation of the lexicon 
is introduced (§§347f), and his view on lexical access exposed (§ 351).
262 
2. Setting the scene: Kaye (1989) 
 
263  2.1. Phonology exists because it enhances parsing 
 
The driving force behind Kaye's approach to the interface is functional. In 
his view, the evolution of the species has produced phonology because it 
makes communication faster, more effective and more reliable. That is, it 
facilitates the parsing of the continuous and indistinct phonetic signal into 
morphemes.65 Morpheme recognition is the first thing that the linguistic 
system has to do when it is exposed to a signal ± a critical step in the access 
 
65 In his teaching, but not (yet) in print as far as I can see, Kaye also mentions a 
second raison d'être: phonological structure is the spine of the addressing sys-
tem in the lexicon. This issue is discussed in § 346 below. 

Setting the scene: Kaye (1989) 221 
to meaning. Kaye calls the indications that phonology provides for mor-
pheme delineation parsing cues.
Kaye (1989:11ff) compares natural and programming languages: the 
latter have a syntax, eventually a morphology and semantics, but no pho-
nology. Why is that? Of course, an obvious answer is that unlike program-
ming languages, natural language is actually pronounced, and the variation 
in the signal comes from the mechanic and phonetic processes (coarticula-
tion, aerodynamics and the like) that occur when people speak. 
Kaye (1989:42ff) rejects this phonetic hypothesis. 66 Instead, he 
adopts a perception-oriented position: the linguistic system supplies the 
signal with predictable variation on purpose in order to facilitate the mor-
pheme-recognition task. That is, it flies a flag in order to tell the listener 
where morphemes begin, and where they end. 
In order to show that the demarcative function of phonology is real, 
Kaye proposes two experiments. A thought experiment to begin with (Kaye 
1989:49f): imagine a stretch of speech from which all effects of phonologi-
cal processes, segmental (e.g. final devoicing) and suprasegmental (e.g. 
stress) alike, have been removed. Played back to a native, such a doctored 
signal would most probably be incomprehensible; or at least, could it be 
understood at all, it would drastically slow down the rate of transmission. 
Kaye (1989:50) therefore concludes that "human linguistic capacity 
is certainly an enormous advantage to our species, doubtless essential to 
our survival. Would a communicative system that functioned at, say, one-
fifth our speed offer the same adaptive qualities?" 
The second experiment (Kaye 1989:51f) is to show how important 
sandhi information is in perception: when used out of purpose, it can easily 
fool listeners and corrupt communication altogether. In English, the se-
quence /t-j/ may be pronounced [tÉʃ] provided its members straddle a word 
boundary, and the second item is a function word (e.g. pronoun, posses-
sive). Hence the process may go into effect in the sentence I know what [tÉS]
you want and I hit [tÉS] your brother, but not in I want *[tÉS] universal free-
dom, I hit *[tÉS] Yorick because here the [j-] does not belong to a function 
word. 
 
66 See Ploch (2003) on this notion and its (ir)relevance for phonological theory. 
The central methodological claim of Kaye's approach to phonology (which 
Kaye refers to as the phonological epistemological principle) is that "the only 
source of phonological knowledge is phonological behaviour: Thus, phonetics 
[«] plays no role in the postulation of phonological objects nor the interaction 
of such objects" (Kaye 2005:283). 

222 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
Given this process, it is understandable why speakers fail to come up 
with any interpretation at all when presented with the input 
[ajnçwwatÉSuajwant]. The intended sentence is I know what ewe I want,
only that the sandhi process is wrongly applied to the (rare) non-function 
word ewe [ju], which is a homophone of you. Parsing, then, is corrupted 
because the phonological system that is used for parsing visibly enforces a 
function-word interpretation of [ju], which can only be you. Even under 
strong external urge (the result of this parsing leads to the breakdown of 
communication), speakers are unable to consider the alternative parse that 
ewe would offer: they cannot "plug off" their phonological knowledge and 
allow for a non-functional interpretation. 
We will see below how this general line of reasoning shapes the in-
teraction with morphology, where boundaries precisely may or may not fly 
a flag in the signal. 
 
264  2.2. Perception-oriented views of phonology and the interface 
 
Kaye's approach falls into the large body of perception-oriented approaches 
and theories of the interface. These may be traced back at least to Trubetz-
koy's Grenzsignale (§ 55), which had a rich offspring across disciplines and 
theories. 
Cutler (1996) provides a review of how speech recognition is done in 
the psychological literature, as well as of the role that is played by signal-
based models of segmentation. 
In phonology, listener-oriented approaches are pursued more or less 
explicitly in the literature since Trubetzkoy. They are particularly promi-
nent in the branch of OT that favours grounded (i.e. functional) constraints. 
Relevant literature includes Napoli & Nespor (1979:839), Booij (1983), 
Basbøll (1986), Bertinetto (1999), Loporcaro (1999), Hume & Johnson 
(eds.) (2001) and Boersma (1998, 2005). 
 
265 
2.3. Typical boundary detectors 
 
Kaye (1989:50ff) reviews phonological processes that are well suited to 
serve as flags for morphological parsing, and which are widely used for 
that purpose across languages. 
Two families of phenomena seem to be well equipped: suprasegmen-
tal indicators and harmony processes. The demarcative function of stress 

Domain structure: how it is created, what it represents and how it works 223 
for example is identified in the classical structuralist literature (e.g. 
Junković 1980, 1990). Stress is an accurate boundary detector: it either 
directly falls on edges and thereby identifies word boundaries, or it is edge-
anchored. That is, its location is calculated with reference to the left or the 
right edge of words. Interestingly, languages do not appear to place stress 
with reference to the middle of the word, although this would be just as 
easily computable as edge-anchoring. 
Also, Kaye points out that harmony processes have a domain of ap-
plication and thereby naturally indicate edges. 
 
266 
3. Domain structure: how it is created, what it represents and how it 
works 
 
267  3.1. The concat- and the φ-function 
 
268  3.1.1. General properties 
 
In Kaye's (1995:302ff) system, the concat function concatenates two mor-
phemes and returns them as a linear sequence. Hence given morphemes A 
and B, the action of concat is to produce the output [AB]. This is quite 
comparable with what modern Merge does, only that no particular label is 
attached to the output (whose hierarchical status is indicated by brackets). 
The φ-function is the set of phonological processes that are syn-
chronically active in a given language and computed online whenever pho-
nology is done on some string. Kaye's (1995:302) shorthand for the φ-
function is the order "do phonology!".  
Thus far, talking about the φ-function is just using a specific vocabu-
lary in order to talk about the phonological grammar in general: there is no 
theory-specific aspect, and the φ-function could be whatever is the favour-
ite computation of phonologists: a set of ordered rules, a set or ranked con-
straints or any other set of instructions that modify a string etc. 
 
269  3.1.2. Computation in Government Phonology 
 
Government Phonology is often referred to as a representation-oriented 
theory of phonology, and there is certainly good reason for this characteri-
sation. A correlate of the representational focus is the fact that computation 
in Government Phonology was not explicitly regulated for quite some time: 

224 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
the only indication that could be found in print was Kaye's (1992a:141, 
1995:291) statement according to which processes "apply whenever the 
conditions that trigger them are satisfied." Kaye avoids talking about rules 
since he strongly opposes SPE-type derivationalism where rules are extrin-
sically ordered (Kaye 1990b, 2008). 
Alongside with Optimality Theory (Prince & Smolensky 1993) and 
Declarative Phonology (Scobbie 1991, Scobbie et al. 1996), Government 
Phonology (Kaye et al. 1990) is thus one of the three theories that emerged 
in the early 90s (or mid-late 80s) on the grounds of a strong anti-
derivational mantra. The computation in all three cases is based on con-
straints, which however do not have the same status: while they are ranked 
and violable in OT, they are absolute (i.e. non-violable) in Declarative Pho-
nology. 
While it was always clear that Government Phonology rejects deriva-
tionalism (i.e. extrinsically ordered instructions), how exactly computation 
works and what a computational instruction looks like was not made ex-
plicit until the mid-90s when the constraint-based character of computation 
in Government Phonology became obvious: computation is done by so-
called Licensing Constraints (Charette & Göksel 1994, 1996, Kaye 2001).67
Following Kaye's (1992a:141) general philosophy mentioned, con-
straints in Government Phonology apply whenever a form may be modified 
by them, but with no extrinsic ranking or ordering, and without being able 
to be violated: constraints are (simultaneously and) iteratively applied to 
the string that is submitted to interpretation, and computation ends when no 
further modification can be made.68 
Using serial vocabulary, this system is thus able to handle a feeding 
relationship (the input for the application of a constraint is created by the 
modification of the string by another constraint), but no other type of rule 
interaction (bleeding, counter-feeding, counter-bleeding). A difference must 
 
67 Scheer (2010a, forth) discusses the approaches to computation in phonological 
theory that are available on the market in general, and how computation works 
in Government Phonology in particular (Scheer 2010c). 
68 This is an obvious parallel with Harmonic Serialism, which was introduced by 
Prince & Smolensky (1993) as a serial alternative to strictly parallel assessment 
of candidates (the output of EVAL loops back into GEN until no harmonic im-
provement can be made anymore). John Goldsmith's Harmonic Phonology 
(Goldsmith 1992, 1993, Larson 1992) and Harmonic Grammar (Legendre et al. 
1990, Smolensky & Legendre 2006) are further implementations of Harmonic 
Serialism that are more closely inspired by connectionism. Finally, the most re-
cent version of Harmonic Serialism is McCarthy's (2007) OT-CC. 

Domain structure: how it is created, what it represents and how it works 225 
therefore be made between serial computation (GP computation is serial in 
the sense that constraints may apply to the same string several times) and 
serialism (there is no extrinsic or logical ordering of instructions, i.e. classi-
cal extrinsic rule ordering).  
Also, there is no ranking or prominence relationship among con-
straints: all instructions are equally important. I am not aware of discussion 
in the GP literature of what happens when different constraints conflict, or 
whether such a situation is provided for at all (see discussion of this issue in 
Scheer 2010c). 
 
270  3.1.3. Important properties of the φ-function for Kaye's interface theory 
 
While indications how computation really works in Government Phonology 
are still sparse in print (Gussmann 2007 is probably the most complete 
source), the two properties of the φ-function that are important for our pur-
pose are clear: all processes are equal-righted, and all of them apply when 
phonological interpretation is performed. 
Equal-rightedness means that there is no extrinsic ordering of in-
structions (no sequential/chronological application, no hierarchy/constraint 
ranking): all processes apply simultaneously. The fact that none of them 
can be left unapplied excludes selective rule application (see § 149): there is 
no way for just a subset of the phonological processes to apply at a given 
time and to a given string. Phonology is not divisible, and "do phonology!" 
means "do all the phonology!". Kaye thus restores the view of SPE on pho-
nological processing: there is only one computational system (§ 107), and 
multiple mini-grammars of whatever kind (§ 234) are ruled out. Whether 
Kaye's system really stands up to this strict commitment is discussed in 
§338 below. 
Technically speaking, the φ-function "has one argument, a phono-
logical string, and returns the application of the phonology to this argu-
ment, also a phonological string. The expression φ(X) means, 'apply pho-
nology to the string X'. φ(X) returns the phonological string which results 
from the application of phonology to its argument" (Kaye 1995:302). 
 
271  3.2. Domain structure is created by interleaved concat and φ
Interpretational units are called domains in Kaye's terminology. Domains 
are defined as those chunks of the linear string that are phonologically rele-

226 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
vant, i.e. to which phonology applies. They are created by the interaction of 
the concat- and the φ-function. These are not interleaved when phonology 
is done on a morphologically simplex input, φ(X), or when it applies to a 
morphologically complex object, φ(concat(X,Y)). 
However, concat and phonological interpretation may also be inter-
twined, a situation that creates more complex structures. Given two mor-
phemes X and Y, either may be subjected to φ before concatenation takes 
place. This situation corresponds to the expressions φ(concat(φ(X),Y)) and 
φ(concat(X,φ(Y))). In the former case, phonology operates over morpheme 
X, the result is concatenated with morpheme Y, and phonology again ap-
plies to the output. That latter configuration is the symmetric counterpart. 
Finally, the system affords a third interleaved configuration, i.e. 
when both X and Y are interpreted before concatenation; this creates the 
compound structure φ(concat(φ(X),φ(Y))). 
Table  (102) below recapitulates the four logically possible configura-
tions when two morphemes X and Y are interpreted in Kaye's system. 
 
(102) possible domain structure for two morphemes X and Y 
 
formal 
brackets number of domains 
name 
 
a. φ(concat(X,Y)) 
[X Y] 
one: [X Y] 
non-analytic
b. φ(concat(φ(X),Y)) 
[[X] Y] 
two: [X] and [X Y] 
analytic 
 
c. φ(concat(X,φ(Y))) 
[X [Y]] 
two: [Y] and [X Y] 
analytic 
 
d. φ(concat(φ(X),φ(Y))) [[X] [Y]] three: [X], [Y] and [X Y] analytic 
 
In the simplest configuration under (102a) phonology is done only 
once, i.e. it applies to the result of the concatenation of X and Y. Under 
(102b) and (102c), it applies twice: to one of the two morphemes in isola-
tion, and to the result of their concatenation. Finally, the compound struc-
ture under (102d) affords three passes of the φ-function, which applies to 
both of the morphemes in isolation, and to the result of their concatenation. 
In this system, the number of domains and the number of applications of 
the φ-function is thus always identical. 
Finally, it is to be noted that Kaye (1995:305f) is inclined to dismiss 
(102c): while [X [Y]] is a logically possible structure, it does not appear to 
be attested. 
Domain structure is further discussed by Gussmann & Kaye (1993), 
Cyran & Gussmann (1998, 1999) and Gussmann (1998, 2002:45ff). 

Domain structure: how it is created, what it represents and how it works 227 
272  3.3. Analytic vs. non-analytic 
 
Kaye talks about analytic and non-analytic domains (see the last column of 
table  (102)). The former (e.g. [[X] Y]) contain another domain and may 
therefore be further analysed, while the latter (e.g. [X Y]) have no internal 
structure.  
Following the same logic, Kaye refers to a string of morphemes that 
has no internal structure as non-analytic morphology, while strings that 
subdivide into further domains are called analytic morphology.  
Whether two morphemes end up as an analytic or a non-analytic 
structure depends on their lexical properties (this is how affix classes are 
distinguished, see § 310). That is, some affixes are specified for not creating 
a single domain of interpretation with their host, such as Y in [[X] Y]; they 
are called analytic (or interpretation-triggering in the terminology that was 
used in the previous chapter). On the other hand, non-analytic affixes are 
interpreted together with their host (Y in [X Y], they are (they are interpre-
tation-neutral).  
Looked at from the vantage point of spell-out, the concatenation of 
analytic affixes triggers the spell-out of their sister (rather than of their own 
node, more on this contrast in § 282 below), while non-analytic affixes have 
no influence on the interpretation of their sister. 
 
273  3.4. Domain structure is the result of selective spell-out 
 
Domain structure is the result of selective spell-out in the sense of Halle & 
Vergnaud (1987a) (§ 225): given the morpho-syntactic tree, affixes may or 
may not trigger spell-out. If they do as Y under (103a) their sister is spelled 
out (i.e. enclosed by brackets in the linear notation).69 In case they do not as 
Y under (103b), their sister is not subjected to interpretation (i.e. will not be 
a bracket-delineated domain in phonology).  
 
69 Halle & Vergnaud's (1987a) take is slightly different: instead of the sister, they 
spell out the material that is dominated by the projection of the interpretation-
triggering affix, i.e. β under (103a). This contrast is further discussed in § 282 
below. 

228 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
(103) domain structure is impoverished morpho-syntactic structure 
 
a. interpretation-triggering Y 
b. interpretation-neutral Y 
 
β
β
Y
α
phon 
 
Y 
α
x
X
x
X
spell-out 
 
spell-out 
 
[X] Y 
 
 
 
X Y 
 
 
Put differently, the morpho-syntactic division between X and Y is 
made visible to the phonology under (103a) but not under (103b): spell-out 
is selective.  
 
274  3.5. Interpretation prior to concatenation: domain structure generates more 
than spell-out can create 
 
An interesting formal property of Kaye's domain structure that will turn out 
to be empirically relevant in §§ 314f is the possibility for pieces to be inter-
preted before they are concatenated. Consider the compound structure such 
as [[X] [Y]] under  (104) where both X and Y are interpreted in isolation 
before any concatenation takes place.  
 
(104) domains that are not created by spell-out 
 
a. Y is interpreted in isolation 
b. Y is interpreted in isolation 
 
β
phon 
 
 
β
Y
α
phon 
 
Y 
α
x
X
x
X
spell-out
spell-out
[[X] [Y]] 
 
 
 
X [Y] 
 

Domain structure: how it is created, what it represents and how it works 229 
Recall from § 271 that [[X] [Y] and [X [Y]] (where X is a root and Y 
an affix) are possible domain structures when two morphemes are concate-
nated. Neither, however, can be created by the (affix-triggered) spell-out of 
nodes, as introduced in the previous section. Under (104a) the spell-out of α
makes X a domain, and the spell-out of β defines the entire string [XY] as 
an interpretational unit. There is no way, however, to achieve the isolated 
interpretation of Y by spell-out. Likewise, no node under (104b) can be 
spelled out so that Y becomes an interpretational unit by itself. 
This means that Kaye's system allows for the spell-out of nodes 
(α, β) as much as of terminal elements (Y). That is, domain structure is 
shaped by spell-out, but does not reduce to the action of this device: some 
domains are created by independent means. In absence of additional op-
tions for the origin of domain structure, these non-spell-out-created do-
mains must be a lexical property of the pieces at hand. This is consistent 
with affix-triggered interpretation: it is the lexical properties of affixes that 
define interpretational units (i.e. domain structure), either by projecting 
their spell-out properties into the tree, or directly by specifying their own 
body as a domain. 
This may be illustrated by an interpretational structure such as [[pre-
fix] [root]], which cannot be generated by spell-out, but which is needed (as 
we will see in § 314) in order to derive the contrast between im-possible 
(where the prefix-final nasal assimilates) and un-predictable (where it does 
not). 
The status of independently spelled-out terminals and the fact that 
this cannot be expressed by regular spell-out is not discussed by Kaye 
(1992a, 1995). Kaye only looks at domain structure from the phonological 
(linear) point of view: domain structure is whatever phonological phenom-
ena require it to be.  
In syntax, the interpretation of pieces prior to their being merged has 
been proposed as a consequence of counter-cyclic merger (late adjunction). 
This formal parallel and its consequences for phonologically motivated 
independent spell-out of terminals is discussed in § 316. 
 
275  3.6. Domain structure is interactionist, brackets are only shorthand 
 
Kaye always uses fully-fledged bracketed representations such as [[X] Y] ± 
exactly what is known from SPE and Halle & Vergnaud (1987a). Unlike in 
these approaches, however, Kaye's structure is explicitly interactionist 
(§ 271). 

230 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
Also, brackets do not exist: they are not parsed or referred to by any 
phonological mechanism. The bracketed notation merely indicates the deri-
vational history of the string at hand as it was created by successive waves 
of spell-out. It is the way phonologists look at morpho-syntactic structure: 
they see only phonologically relevant information, and they feel at home in 
a linear, rather than in an arboreal representation. Domain boundaries thus 
represent procedural, not representational information. 
Recall from §§ 161, 170 that brackets in non-interactionist systems 
such as SPE and Halle & Vergnaud represent untranslated morpho-syntactic 
information in phonology and are therefore unwarranted from the modular 
point of view. Interactionism is the only way to reconcile inside-out inter-
pretation with modularity. 
 
276  3.7. Kaye's procedural-only approach and morpho-phonology 
 
Kaye seems to reject any representational communication between morpho-
syntax and phonology. This may be concluded from the section "morpho-
logical effects in the phonology" in Kaye (1995:301f): the only means for 
morpho-syntax to talk to phonology that Kaye mentions is procedural. That 
is, he does not provide for boundaries, LP-style brackets (§§ 170f), prosodic 
constituency or any other kind of representational carriers of morpho-
syntactic information.  
Let us have a brief look at the consequences of this procedural-only 
approach for the question of morpho-phonology. Recall from § 126 that the 
following issue was debated in post-SPE times: to which extent are alterna-
tions that make reference to morpho-syntactic information the result of 
online computation and suppose a single underlying form? 
Theories of the 70s and 80s vary as to how much of these alterna-
tions are unloaded into the lexicon; all approaches, however, impoverish 
the rule component of SPE. Lexical Phonology operates only a moderate 
lexicalisation of alternating patterns (some illustration was provided in 
§129). The most radical response comes from Natural (Generative) Pho-
nology, which ± in vain ± attempts to eliminate morpho-syntactic informa-
tion from phonology altogether (§ 127f). Kaye's system is also located on 
the far end of the spectrum. Like Natural (Generative) Phonology, Kaye 
does not allow for boundaries or any other kind of representational means 
to introduce morpho-syntactic information. 
The only way to make phonology sensitive to extra-phonological in-
formation, then, is to encode this information into domain structure. Any 

Selective spell-out: Kaye's vs. Halle & Vergnaud's implementation 231 
alternation that refers to morphological information but cannot be framed in 
this way must be recorded in the lexicon.  
Typical SPE-style alternations such as Velar Softening (electri[k] - 
electri[s]-ity, relevant literature is mentioned in note 28) and Trisyllabic 
Shortening (§ 164) are also dismissed by Kaye's restrictive view of what 
phonology is able to do. The vocalic alternations involved in the latter pat-
tern, Kaye (1995:312f) argues, cannot be afforded by the φ-function, which 
otherwise would be able to compute all kinds of alternations that do not 
occur in natural language. Today indeed, most phonologists will probably 
not want to consider Trisyllabic Shortening a productive phonological 
process anymore (see Hayes 1995a and note 42). 
 
277  4. Selective spell-out: Kaye's vs. Halle & Vergnaud's implementation 
 
278  4.1. Introduction 
 
The following pages introduce Kaye's implementation of Halle & Verg-
naud's (1987a) selective spell-out. The central instrument that sets Kaye's 
approach apart from Halle & Vergnaud's is a no look-back device that disal-
lows the modification of phonological properties which were acquired on a 
previous cycle (domain). It is really the formulation of the no look-back 
device that matters: Kaye's is unlike all previous versions. The different 
brands of no look-back devices that have been proposed since Chomsky 
(1973) are discussed at length in § 287. 
For the time being, it is enough to recall that Halle & Vergnaud 
(1987a) did use a look-back device (§ 237), Kiparsky's SCC-K, but that this 
instrument is entirely irrelevant for their analysis of affix class-based phe-
nomena (§ 248). 
The pages below first show how Kaye's no look-back device organ-
ises underapplication in affix class-based phenomena, and then moves on to 
identify a number of other important differences with Halle & Vergnaud's 
system. 
 
279  4.2. Underapplication is achieved by no look-back 
 
The difference between class 1 and class 2 affixes was encoded by different 
boundaries in SPE (§§ 92, 106), by strata in Lexical Phonology (§ 147) and 
by selective spell-out in Halle & Vergnaud's (1987a) model (§ 228). 

232 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
Kaye (1995) follows the latter option. As was shown in § 273, he ex-
presses the contrast between class 1 and class 2 affixes by what he calls 
non-analytic vs. analytic domain structure. In English, then, class 1 affixes 
are non-analytic (i.e. do not provoke the spell-out of their sister), while 
class 2 affixes is analytic (i.e. triggers the spell-out of their sister). 
In this perspective, the relevant domain structure for the familiar ex-
ample from English stress (párent, paréntal vs. párenthood, see § 147) is 
[parent], [parent al1] and [[parent] hood2]. Penultimate stress is then as-
signed in each domain, from inside out. On the innermost pass, this pro-
duces [párent], [parént-al] and [[párent] hood].70 The derivation ends for the 
former two words, which do not accommodate any other domain. When 
phonology interprets the outer domain of [párent-hood], so-called robust-
ness (Kaye's term) blocks the reassessment of stress (to *parént-hood): 
strings that have already experienced interpretation cannot be further modi-
fied. The precise formulation of Kaye's no look-back device is discussed 
and compared to other options in § 287 below. 
The example at hand requires underapplication of the stress rule to 
the class 2 string [párent hood]: the stress rule must not reapply to the outer 
cycle. Unlike in all other approaches to affix class-based phenomena, un-
derapplication is thus afforded by a no look-back device in Kaye's analysis. 
 
70 In SPE, vowels escape reduction to schwa when they bore main stress on a 
previous cycle (see § 97). Kaye follows this line of attack (see § 334 below). 
Since -hood2 does not experience vowel reduction, he concludes that it must 
have been stressed, which in turn requires it to be a domain (only domains are 
stressed). Therefore the actual domain structure that Kaye (1995:308, 313) pro-
poses is [[parent][hood]], where the competition between the two inner do-
mains for main stress is decided in favour of the leftmost domain by virtue of 
the fact that English compounds are always stressed on the first element (bláck-
bòard, see § 334).  
 
In addition of triggering the spell-out of the root, -hood2 has thus the lexical 
property of requiring its own spell-out prior to being concatenated. That is, we 
are facing a case of the kind that was discussed in § 274: a terminal may be sub-
ject to independent spell-out. This additional complication does not interfere 
with the purpose of the demonstration, for which the simplified domain struc-
ture [[parent] hood] will do. 

Selective spell-out: Kaye's vs. Halle & Vergnaud's implementation 233 
280  4.3. No automatic spell-out of roots, but systematic spell-out at the word-
level 
 
It was already mentioned that Kaye (1995) follows Halle & Vergnaud's 
(1987a) idea of selective spell-out, but ends up with quite different results. 
Let us now look at the factors that produce the contrast when selective 
spell-out is implemented. Three properties are relevant: the automatic spell-
out of roots (Halle & Vergnaud: yes, Kaye: no), the systematic spell-out at 
the word level (Halle & Vergnaud: no, Kaye: yes) and the management of 
derived environment effects (Halle & Vergnaud: integrated into the man-
agement of affix class-based phenomena, Kaye: a separate issue). The latter 
is only discussed in § 284 below. 
Let us start by comparing the interpretational structure of the same 
itmes that is proposed by Halle & Vergnaud and Kaye. Note that for the 
sake of comparability, specific word-level phonologies that eventually ap-
ply to the result of the cyclic derivation (non-cyclic rules in Halle & Verg-
naud's system) are disregarded for the time being. That is, brackets under 
 (105) below define domains of application of cyclic rules on the one hand 
(Halle & Vergnaud), of the φ-function on the other (Kaye). 
 
(105) interpretational units: Halle & Vergnaud vs. Kaye 
 
Halle & Vergnaud 
Kaye 
 
a. párent 
[parent] 
[parent] 
b. parént-al 
[[parent] al] 
[parent al] 
 
c. párent-hood 
[parent] hood 
[[parent] hood] 
 
In Halle & Vergnaud's system, all roots are spelled out in isolation: 
they form a cycle of their own (see § 230). On Kaye's count, this is not the 
case: roots have no intrinsic virtue of being spelled out. The spell-out of all 
strings, roots included, is decided by the lexical properties of pieces that are 
concatenated: analytic affixes (cyclic in Halle & Vergnaud's terminology) 
provoke the spell-out of their sister, while non-analytic affixes (non-cyclic) 
do not. This is shown under  (106) below. 
 

234 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
(106) Kaye: analytic affixes provoke the spell-out of their sister 
 
a. Y is analytic: α is spelled out 
b. Y is non-analytic: α is not 
spelled out 
 
β
β
Yanalytic 
α
phon 
 
Ynon-analytic
α
x
X
x
X
spell-out 
 
spell-out 
 
[[X] Y] 
 
 
 
[X Y] 
 
 
This procedure produces /[X] Y/ for (106a) and /X Y/ for (106b). The 
fact that the entire word ends up being delineated by brackets (i.e. as an 
interpretational unit) is due to the aforementioned fact that the word as a 
whole is always spelled out no matter what. Hence [[X] Y] and [X Y] under 
 (106), respectively, and [[parent] hood] vs. [parent al] for the example men-
tioned. This also explains the fact that párent in isolation is an interpreta-
tional unit: it is a domain by virtue of being a word with Kaye, while its 
being a cycle with Halle & Vergnaud is due to the fact that it is a root. 
The treatment of the root and the word as interpretational units that 
automatically trigger spell-out is thus opposite: while Halle & Vergnaud 
grant this status to the former but not to the latter, Kaye implements the 
reverse choice. 
 
281  4.4. Who is interpretation-triggering ± class 1 or class 2 affixes? 
 
Table  (105) also shows that Kaye (1995) makes the opposite choice of 
Halle & Vergnaud (1987a) regarding the type of affix that triggers interpre-
tation (the following table only mentions brackets that are created by the 
concatenation of an affix). 
 

Selective spell-out: Kaye's vs. Halle & Vergnaud's implementation 235 
(107) interpretation-triggering affixes 
 
a. Halle & Vergnaud (1987a) 
/[parent al1]/ vs. /parent hood2/
class 1 affixes trigger interpretation ± they are cyclic 
class 2 affixes do not trigger interpretation ± they are non-cyclic 
 
b. Kaye (1992a, 1995) 
/parent al1/ vs. /[parent] hood2/
class 2 affixes trigger interpretation ± they are analytic (cyclic) 
class 1 affixes do not trigger interpretation ± they are non-analytic (non-
cyclic) 
 
As far as I can see, the fact that Kaye (1995) proposes the exact re-
verse of Halle & Vergnaud's implementation of English affix classes has 
left no traces in the literature. Kaye (1992a) mentions that there may be 
differences with respect to Halle (1986), but does not make them explicit. 
 
(108) "I accept the notion of the cycle along with the PSC [Principle of Strict 
Cyclicity, cf. below] as crucial parts of a theory of UG. The cyclic domains 
which I posit do not necessarily agree with earlier assumptions, however. I 
do agree with Halle (1986) regarding the cyclic or non-cyclic status of af-
fixes. 
I shall assume that whether or not an affix is cyclic is not a property 
of the morphological rule by which it is assigned, but is rather an 
idiosyncratic and variable property of the affix. 
Halle (1986:6)" 
Kaye (1992a:142) 
 
In 1992, Kaye thus still uses the SPE-terminology of Halle & Verg-
naud which refers to cycles and cyclic vs. non-cyclic affixes. It is only later 
that cycles will appear as domains, and cyclic/non-cyclic as analytic/non-
analytic. Maybe this move in terminology is a way to mark the different ± 
actually opposite ± use of selective spell-out. 
 
282  4.5. Interpretation-triggering affixes: spell-out of the sister vs. their own 
node 
 
The contrast between /[parent al1]/ vs. /parent hood2/ (Halle & Vergnaud) 
and /parent al1/ vs. /[parent] hood2/ (Kaye) that is evidenced under  (107) 
also shows another fundamental difference between the two competing 
implementations of selective spell-out (which was already mentioned in 
§226 and §§ 272f): the string that is spelled out when an interpretation-

236 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
triggering affix (cyclic/analytic) is added is not the same. This is shown 
under  (109) below. 
 
(109) interpretation-triggering affixes: what exactly is spelled out 
 
a. Halle & Vergnaud (1987a): 
cyclic affixes trigger the spell-
out of their own constituent β
b. Kaye (1995): 
analytic affixes trigger the spell-
out of their sister α
β
phon 
 
 
β
Ycyclic 
α
Yanalytic 
α
phon 
 
x
X
x
X
spell-out 
 
spell-out 
 
[X Y] 
 
 
 
[X] Y 
 
 
On the other hand, the concatenation of affixes that do not trigger 
spell-out has the same effect in both systems: no interpretational unit is 
created.  
 
283  4.6. Morpheme- and chunk-specific phonologies 
 
Let us now look at Kaye's position regarding the issue of multiple computa-
tional systems in phonology. Kaye (1995:302ff) is explicit on the fact that 
all instructions for phonological processing are grouped together in the φ-
function, and that all instructions of this function apply when the function 
applies (§ 267). Hence there is no selective rule application, and there is 
only one computational system that contains phonological instructions. 
This clearly rules out any version of multiple mini-grammars, be 
they morpheme- or chunk-specific. Recall from § 234 that Halle & Verg-
naud (1987a) reject morpheme-specific phonologies (level 1 vs. level 2 
rules in Lexical Phonology) and a chunk-specific phonology for the sen-
tence level (Praguian segregation, i.e. lexical vs. postlexical phonology in 
Lexical Phonology). Also recall from § 238 that this notwithstanding, Halle 
& Vergnaud (1987a) make a difference between pre-word and post-word 
phonology by interrupting the derivation at the word level, where a phonol-
ogy specific to that chunk size applies. 

Selective spell-out: Kaye's vs. Halle & Vergnaud's implementation 237 
Kaye's (1995) take is largely, maybe exactly along these lines. He re-
jects for sure any kind of morpheme-specific phonology, and also Praguian 
segregation, i.e. the application of a specific phonology to sequences of 
words (as opposed to sequences of morphemes). However, just like Halle & 
Vergnaud, Kaye does implement a formal break in the derivation at the 
word level: recall from § 280 that the word is always spelled out as such no 
matter what the affixal situation and the derivational history. That is, the 
word is granted the status of an interpretational unit by default. 
The question is whether the recognition of the word as a chunk that 
has a special phonological status is also accompanied by the application of 
a specific word-level phonology. We have seen that in theory the answer is 
no ± but in practice it may well turn out to be yes. This issue is discussed in 
§338 below. 
 
284  4.7. Derived environments are a separate issue 
 
Kiparsky (1982a,b) has introduced derived environment effects into Chom-
sky's (1973) no look-back device (§§ 189f), which until then was only de-
signed to prevent the application of rules to "old" material. It was shown in 
§182 that derived environment effects and no look-back effects in affix 
class-based phenomena are logically and empirically independent. Also, 
Kiparsky (1993) himself has declared the bankruptcy of his SCC-K (§ 197). 
The logical and empirical independence notwithstanding, Halle & Verg-
naud (1987a) maintain the incorporation of derived environment effects 
into the no look-back device: they implement the SCC-K (§ 237). Unlike in 
Kaye's (1995) system, though, nothing in Halle & Vergnaud's analysis of 
affix class-based phenomena is due to the SCC-K, which does not intervene 
in the organisation of underapplication (§ 228). 
We have seen in § 279 that the no look-back device is critical in 
Kaye's system: it is responsible for underapplication. It was also mentioned 
that Kaye uses a (modification-inhibiting) version of the no look-back de-
vice that is different from previous blends (but not unprecedented in the 
literature). Its precise nature is discussed in § 299 below. In any event, de-
rived environment effects have got nothing to do with it: Kaye (1995) con-
siders that they are a separate issue (but does not offer any specific analy-
sis). His no look-back device has no ambition to account for them. This is 
also obvious from the explicit reference that Kaye (1992a:142, 1995:307, 
330 note 23) makes to Chomsky (1973), Kean (1974) and Mascaró (1976) 
(but not to Kiparsky 1982a,b). 

238 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
285  4.8. Cyclic interpretation of words? 
 
Finally, let us consider the question whether only morphemes, or also 
words experience cyclic (inside-out) interpretation. While SPE was explicit 
on the fact that the Transformational cycle applies to morphemes and words 
alike ("the principle of the transformational cycle [«] appl[ies] to all sur-
face structure whether internal or external to the word", Chomsky & Halle 
1968:27, see § 105), a headstone of Lexical Phonology is the idea that only 
morphemes enjoy cyclic derivation: lexical rules are cyclic, but postlexical 
phonology is not (§ 158). 
Regarding this issue, Kaye (1995) restores SPE as much as Halle & 
Vergnaud (1987a) before him (§ 219). He quotes French nasalisation as a 
case where cyclic derivation of words is required (Kaye 1992a:142ff, 
1995:306ff, the evidence is discussed in § 301). This issue also has an im-
pact outside of phonology: it is relevant for the debate regarding lexicalism 
and raises what I call the word-spell-out-mystery in § 786 below. 
 
286  4.9. Summary: two ways of doing selective spell-out 
 
We have seen that Kaye's (1995) and Halle & Vergnaud's (1987a) ways of 
implementing selective spell-out are quite different. The number of factors 
that were compared makes it worthwhile to propose an overview. Table 
 (110) below first gathers the properties that both systems share. 
 
(110) properties shared by Halle & Vergnaud (1987a) and Kaye (1995) 
 
Halle & Vergnaud 
Kaye 
 
a. multiple computational systems 
 
 
1. morpheme-specific 
no 
no 
 
2. sentence-specific (Praguian segreg.) 
no 
no 
 
3. word-level-specific 
yes 
yes? 
 
b. cyclic (inside-out) interpretation of words 
yes 
yes 
 
c. selective spell-out 
yes 
yes 
 
d. interpretation triggered by a lexical prop-
erty of affixes upon concatenation 
yes 
yes 
 
Table  (111) below recalls the factors that make Kaye's and Halle & 
Vergnaud's system different. 
 

No look-back devices: implementations since 1973 239 
(111) differences between Halle & Vergnaud (1987a) and Kaye (1995) 
 
Halle & 
Vergnaud
Kaye 
 
a. the root is an interpretational unit 
yes 
no 
b. the word is an interpretational unit 
no 
yes 
 
c. morpho-syntactic terminals may be inter-
pretational units 
no 
yes 
 
d. interpretation-triggering affixes trigger 
the spell-out of 
their own 
node 
their sister 
 
e. English affix classes: type that triggers 
interpretation 
class 1 
class 2 
 
f. underapplication is achieved by 
cycles 
cycles and no 
look-back 
 
g. no look-back device 
 
 
 
1. type of device used 
SCC-K 
modification-
inhibiting 
 
2. derived environment effects built in 
yes 
no 
 
3. no look-back is relevant for underap-
plication 
no 
yes 
 
The following section shows in which way exactly modification-
inhibiting no look-back is different from other incarnations that have been 
entertained since no look-back devices were introduced by Chomsky 
(1973). 
 
287  5. No look-back devices: implementations since 1973 
 
288  5.1. Like lexicalism, no look-back is born in the early 70s as an 
overgeneration-killer 
 
Cyclic (inside-out) derivation was introduced by Chomsky et al. (1956:75) 
(§ 80) and became a central piece of the generative interface architecture in 
SPE (§ 100). However, SPE did not feature any no look-back device yet. 
The idea that linguistic computation cannot look back to previously inter-
preted strings was only introduced by Chomsky (1973) under the heading 
of the Strict Cycle Condition. In the context of the early 70s, this was a 
contribution to the attempt at marshalling the generative power of the unre-
stricted derivational (transformational) mechanism. Ordered transforma-
tions in syntax overgenerated as much as ordered rules in phonology (see 
§126). Overgeneration was a plague, and the antidote into which generative 
theory engaged was a restriction on both underlying forms (see § 124), i.e. 

240 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
lexicalism (on which more in §§ 537, 569) and computation, i.e. no look-
back. 
In Remarks on Nominalization, Chomsky (1970) had argued that 
words such as reduction, transmission and recital are not the result of on-
line computation because their derivation is unproductive and semantically 
opaque; rather, they are stored in the lexicon as a whole. Therefore their 
pronunciation does not require any concatenation. On the phonological 
side, the same point was made regarding for example Velar Softening: 
some considered electri[s]ity a single lexical entry because the alleged 
palatalisation of the /k/ in electri[k] into [s] before /-i/ is riddled with ex-
ceptions and not productive (see § 126). 
 
289  5.2. Chomsky's (1973) Strict Cycle Condition: you need to use new 
material 
 
Chomsky's (1973) Strict Cycle Condition is designed to prevent rules from 
applying if they do not use material that was introduced into the derivation 
on the current cycle. The original formulation appears under  (112) below. 
 
(112) Strict Cycle Condition 
 
"No rule can apply to a domain dominated by a cyclic node A in such a way 
as to affect solely a proper subdomain of A dominated by a node B which is 
also a cyclic node." Chomsky (1973:243) 
 
The effect is that rules are blocked whose structural description is 
met by a string that is made exclusively of material that belongs to a previ-
ous cycle. That is, given [[AB]i C]j, a rule that is triggered by AB can apply 
at cycle i, but not at cycle j. In other words, rules must use material that 
was introduced on the latest cycle. 
In Chomsky's (1973:243) terms, "rules cannot in effect return to ear-
lier stages of the cycle after the derivation has moved to larger, more inclu-
sive domains."71 
Kean (1974:179) also discusses a more complicated situation where 
the Strict Cycle Condition bites: a rule whose context is not satisfied in 
some cycle, but which is fed by the application of another rule that only 
 
71 Following or parallel to Chomsky (1973), a number of mechanisms that restrict 
computation have been proposed in syntax. These include the Freezing Princi-
ple (Culicover & Wexler 1973) and the Binary Principle (Hamburger & Wexler 
1975, Wexler & Culicover 1980:119ff). 

No look-back devices: implementations since 1973 241 
applies at a later cycle, cannot go into effect if its trigger belongs to the 
earlier cycle. Suppose a rule such as A →B / __Y, which cannot apply in 
the inner cycle of [[A X] Z]. Suppose another rule X →Y / __Z, which will 
go into effect once Z was added on the outer cycle. This feeds the former 
rule, which should be able to apply to [A Y Z], transforming A into B. The 
Strict Cycle Condition blocks its application, though, since none of its in-
gredients, A and Y, was introduced on the outer cycle. 
 
290  5.3. Application to phonology: Kean (1974) and Mascaró (1976) 
 
During the 70s, strict cyclicity was applied to phonology by Kean (1974) 
and Mascaró (1976).72 Mascaró is at the origin of the term phonological 
cycle, which replaces the SPE-based notion of the transformational cycle in 
phonological quarters. 
Mascaró's SCC-M is repeated below (from §161). 
 
(113) Strict Cycle Condition (SCC-M) 
"Proper application of cyclic rules 
For a cyclic rule to apply properly in any given cycle j, it must make specific 
use of information proper to (i.e. introduced by virtue of) cycle j." 
Mascaró (1976:7) 
 
Mascaró (1976:7f) explains that "this condition ensures that no 'im-
proper' cyclic application, that is, multiple application of a rule, opposite 
rule ordering, etc. on the same cycle results." He also calls his version "a 
more general formulation of the basic idea of the Strict Cycle Condition 
[, which] was proposed in Chomsky (1973) for syntax" (Mascaró 1976:8). 
 
72 The earliest (published) sources that I could identify are two articles by Morris 
Halle from 1973 and Wilkinson (1974) where the authors refer to an unpub-
lished manuscript by Mary-Louise Kean (dated 1971: Kean 1971, maybe the 
forerunner of Kean 1974). In the "addendum" at the end of Halle (1973a), Halle 
advertises the fact that the revisions of the stress system of SPE that he has un-
dertaken in this article also avoid violations of strict cyclicity that were incurred 
by the original SPE rules. Halle says that the unpublished manuscript by Mary-
Louise Kean dated 1971 drew his attention to this issue. In Halle (1973b:319), 
the author also refers to Kean's manuscript as the source of "a general principle 
of rule application which in recent discussions has been termed STRICT 
CYCLICITY" (emphasis in original). In order to block the application of a rule in 
Telugu, Wilkinson (1974:261f) uses Chomsky's strict cyclicity, quoting the 
manuscript of Chomsky (1973), which he dates 1971. 

242 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
In any case, it appears to be more precise: "make crucial use" of new mate-
rial is less clear than "make specific use" of new material. 
 
291  5.4. Halle/Kiparsky's SCC-K: scrambling with derived environments 
 
It was already mentioned in § 190 that the SCC-K, a headstone of Lexical 
Phonology, was in fact introduced by Morris Halle (1978), rather than by 
Paul Kiparsky (1982a,b) as is commonly believed. 
Unlike to Kiparsky (1982a,b) who talks about his SCC in terms of a 
"simplified" version of Mascaró's (1976) SCC-M ("with some simplifica-
tion, his [Mascaró's] proposal was", Kiparsky 1982b:153), Halle 
(1978:131) is explicit on the fact that "the version of the constraint on cy-
clic rule application that I propose below is a combination of certain sug-
gestions made by Kiparsky (1973[a]:60), with others due to Mascaró 
(1976:9)." 
Paul Kiparsky was concerned with the (restriction of) rules that ap-
pear to look back in a derivation since Kiparsky (1968-73) and Kiparsky 
(1973a). The development that led to his version of the Strict Cycle Condi-
tion was reported in §157. 
Halle now modifies the formulation of Chomsky's Strict Cycle Con-
dition in one crucial aspect in order for it to also cover derived environ-
ments: instead of imposing only new material to be used by a rule, he re-
quires that new and old material be accessed. 
 
(114) "A cyclic rule R applies properly on cycle j only if either a) or b) is satisfied:
a) R makes specific use of information, part of which is available on a prior 
pass through the cyclic rules, and part of which becomes first available 
on cycle j. [«] 
 
b) R makes specific use of information assigned on cycle j by a rule apply-
ing before R." 
Halle (1978:131) 
 
Recall from § 189 that the SCC-M has got nothing to do with derived 
environment effects: it is unable to prevent rules from applying to mono-
morphemic strings. For example, it does not prevent Trisyllabic Shortening 
from applying to underived items such as nightingale and ivory: on the 
innermost cycle, i.e. [nightingale], the rule would use material of this cycle 
and hence apply "properly". 
The move of (114a) now introduces the proviso that in addition of 
new material, "properly" applying rules must also make use of old material. 

No look-back devices: implementations since 1973 243 
This indeed blocks the application of any rule to the innermost cycle, which 
by definition cannot contain any old material.  
This is how Chomsky's Strict Cycle Condition is made to cover de-
rived environment effects. The subsequent literature, as well as common 
phonological belief of generations that have not lived through this period, 
constantly confuse Chomsky's original "use new material!" requirement 
with Kiparsky's concern for derived environments (but see note 49). It is 
therefore important to make their independence explicit. Also recall from 
§182 that derived environment effects and no look-back effects in affix 
class-based phenomena are logically and empirically independent. 
Kiparsky's (1982a,b) brand of the SCC does exactly the same labour 
as Halle's, but affords a formulation that is quite different: while the fact of 
preventing rules from applying to derived environments is a mere conse-
quence of Halle's version, derived environments now are explicitly men-
tioned as such. 
 
292  5.5. Mohanan's bracket erasure: indirect bearing on rules 
 
Mohanan's (1986) bracket erasure is an entirely different no look-back 
mechanism. Recall from § 168 that it was originally designed for the rule-
triggering pattern of affix class-based phenomena. The fact that it could 
also be ± but quite surprisingly does not appear to have been ± used for 
derived environment effects was discussed in § 201. 
In any event, it has nothing to do with Chomsky's original idea to re-
quire that material from the latest cycle must be used by rules. With Mo-
hanan's bracket erasure, rules may or may not use material from the latest 
cycle, and they may or may not use material from previous cycles. Bracket 
erasure does not impose any restriction on the kind of material used. Its 
effect is different, and bears only indirectly on the application of rules. 
Bracket erasure makes all morphological divisions that were not cre-
ated by concatenation at the latest stratum invisible for phonological rules. 
Hence a string like [[[A] B]1 C]2 where subscripts indicate strata, and 
brackets morphological divisions, will appear as [[AB] C] on stratum 2 
since the internal structure of [[A] B] was erased at the end of stratum 1. 
Whether a rule appeals to A, B, C or any combination thereof is entirely 
irrelevant: bracket erasure makes no statement at all. 
On the other hand, bracket erasure makes only sense when it works 
in tandem with bracket-sensitive rules ± otherwise it has no effect at all. 

244 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
That is, only rules that bear brackets in their structural description will be 
affected by the absence of "old" brackets that were erased.  
In sum, Mohanan's bracket erasure stands aside in the concert of no 
look-back devices. 
 
293  5.6. Modification-inhibiting no look-back: first timid steps in the 70s and 
80s 
 
294  5.6.1. Early formulations in phonology and syntax 
 
In § 279 we have come across a version of no look-back that is different 
from all others: Kaye (1995) achieves underapplication of stress assign-
ment at the outer domain of [[parent] hood] by virtue a mechanism that 
makes previously computed strings immune against further modification on 
later cycles. As we will see in § 304, this is precisely the description of the 
Phase Impenetrability Condition that is assumed in current minimalist syn-
tax. In this book, the idea that previously interpreted strings cannot be fur-
ther modified is referred to as modification-inhibiting no look-back. 
Before looking at Kaye's implementation, this section identifies ear-
lier incarnations of the idea that may be found in the literature under the 
headers of structure preservation and the Free Element Condition in pho-
nology, and as Riemsdijk's (1978) Head Constraint in syntax. 
 
295  5.6.2. Phonology I: stress and the Free Element Condition 
 
There is a body of literature in the early autosegmental period where auto-
segmental structure that encodes stress and syllabic generalisations, i.e. 
metrical and syllabic trees, are subject to structure preservation (at least in 
some languages, see Steriade 1988 for the parametric variation assumed). 
Rules that build metrical and syllabic trees are thus held to be unable to 
"destroy" structure that was already erected on previous cycles. Let us 
briefly review one analysis for each phenomenon, stress and syllable struc-
ture. 
McCarthy (1980) (which is about stress and syncope in Damascene 
Arabic) and Poser (1986, 1989) (on stress in Diyari, South Australian) set 
aside, all cases for structure preservation of foot structure that I have come 
across are about the same data that were introduced by Steriade (1988): 

No look-back devices: implementations since 1973 245 
stress in constructions with an enclitic element in Latin and Greek (also 
Halle 1990, Halle & Kenstowicz 1991).  
In Latin, word stress is antipenultimate in trisyllabic or longer words 
(penultimate in bisyllabic and ultimate in monosyllabic items) unless the 
penultimate syllable is heavy, i.e. contains a long vowel or a closed sylla-
ble, in which case stress falls on this penultimate syllable. Hence fá.ce.re 
"to make" and có.lu.bra "blindworm" (penultimate light) vs. ha.bée.re "to 
have" and a.rís.ta "ear (of corn)" (penultimate heavy). In case an enclitic 
joins, however, stress shifts and invariably falls on the last syllable of the 
word (i.e. the syllable immediately to the left of the enclitic). Hence límina 
"thresholds" and éa "this" end up as liminá-que "and the thresholds" and 
eá-propter "for this reason". That the overall string is not treated like a 
word is shown by the fact that the forms *limína-que (penultimate light) 
and *ea-própter (penultimate heavy), which are expected when the string is 
computed as a whole, are not produced. 
The standard analysis of the Latin pattern adopted by Steriade 
(1988:297) is that the last syllable is extrametrical; on the remaining string 
binary, left-dominant feet are erected from right to left. Stress then falls on 
the last foot: on its first syllable by default, on the second syllable in case it 
is heavy. Hence fá.ce.re and có.lu.bra identify as (fa.ce)re and (co.lu)bra,
respectively (with -re and -bra extrametrical); since the second syllable of 
the foot is not heavy, the first syllable receives stress. The footing of 
ha.bée.re and a.ris.ta is identical, i.e. (ha.bee)re and (a.ris)ta, but this time 
the second syllable of the foot is heavy and therefore attracts stress. 
The analysis of words that occur with an enclitic is then based on the 
idea that the foot which was acquired on the word-internal cycle cannot be 
erased when the word is computed together with the enclitic. Computa-
tional domains thus identify as [[word] enclitic]. In order to achieve this 
effect, Steriade (1988:286) calls on Prince's (1985) Free Element Condition 
(FEC). The FEC restricts rules that erect foot structure to strings that do not 
possess any such structure yet. 
In our Latin examples, the last syllable is systematically extrametri-
cal and therefore available for foot construction on the outer cycle when the 
enclitic is added. The rest of the word, however, is already footed and 
hence immune against an eventual reparse by rules that build foot structure. 
As a result, the string that is subject to footing on the outer cycle is made of 
the last syllable of the word and the body of the enclitic (which of course is 
also unfooted). The same stress rules then apply again to the input 
(li.mi)na-que and (e)a-propter: the last syllable is made extrametrical, and a 
foot is constructed on the remaining material; the result is (li.mi)(na)-que 

246 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
and (e)(a-prop)ter. Stress then falls on the rightmost foot (i.e. liminá-que), 
and in case this foot is branching, always on its first syllable. This latter 
aspect is at variance with respect to the stress assigning rule that applies 
word-internally: the eventual heaviness of the second syllable is disre-
garded. Therefore eaá-propter is produced. 
 
296  5.6.3. The FEC is weak: process-specificity, parameterisation and 
restriction to structure that is absent from the lexicon 
 
We are thus facing an analysis where previously assigned structure is im-
mune against further modification on later cycles. But this is only true for 
stress and hence metrical structure: stress is the only thing that the Free 
Element Condition is competent for (even if it was later applied to syllable 
structure as well, see the following section). There is no more general am-
bition regarding other phenomena or other types of structure. Also recall 
that the FEC only applies in certain languages: it is not a property of com-
putation as such. Finally, we are only talking about previously erected auto-
segmental structure (i.e. structure that is absent from the lexicon) ± not 
about previously computed strings. Already computed strings will be happy 
to receive metrical structure provided that they do not already possess such 
structure. 
The Free Element Condition is thus much weaker than the modern 
Phase Impenetrability Condition that is known from current minimalist 
syntax (and which is introduced at greater length in § 304). We have already 
come across a hint that process-specific no look-back may be required in 
phonology, and this was precisely on the occasion of the analysis of (Eng-
lish) stress (§ 241): while stress placement is strictly bound by the limits of 
the word, English shows external sandhi phenomena such as t-flapping. 
Therefore the word can be no general barrier for phonological processes: 
for some its boundaries are insuperable, while for others they are invisible.  
Hence the radical Chomskian "compute-and-forget" that is expressed 
by Phase Impenetrability is much too strong: it does not fit the situation 
that is encountered in phonology. More evidence to this end is adduced 
below (§§ 302, 823). For the time being, we have seen a modification-
inhibiting look-back mechanism that is specific to stress assignment, with-
out this process-specificity being intended, though: there is no comparison 
in the literature quoted with other processes. Modification inhibition is 
postulated because it can solve a particular problem set. 
 

No look-back devices: implementations since 1973 247 
297  5.6.4. Phonology II: structure preservation in syllabification 
 
The other process to which modification-inhibiting no look-back was ap-
plied in the 80s is syllabification, i.e. the erection of syllable structure over 
strings that are lexically unsyllabified. The idea is the same as before: "old" 
syllable structure that was built on a previous cycle cannot be erased or 
modified by computation on later cycles. 
Examples typically involve suffix-prefix asymmetries that are ex-
plained by a difference in domain structure: while suffixes share a domain 
with the root ([root - suffix]), the prefix is located outside of this domain 
([prefix [root - suffix]]). As a consequence, the syllabification of the root 
cannot be undone or modified on the outer cycle when the prefix is added. 
This produces the "unnatural" syllabic parse CVC.VC when the root is 
vowel-initial and the prefix consonant-initial: the FEC applied to syllable 
structure prohibits resyllabification across prefix boundaries. 
Data along these lines are analysed by Steriade (1982:84ff, 1984, 
1988:205, Greek and Latin), van Oostendorp (1994, Dutch) and J. Harris 
(1993, Spanish). In Spanish for example, the rule that takes s to h in coda 
position is a diagnostic for syllable structure. Hence the contrast between 
deseo [deseo] "desire" and des-echo [deheo] "waste" must be due to con-
trasting syllabification: the s is an onset in the former (de.se.o), but a coda 
(des.e.o) in the latter case. In other words, there is no syllabification across 
the prefix boundary of des-.
J. Harris (1993:182ff) explains this lack of optimising CV parses by 
the fact that the prefix-final consonant cannot be syllabified into the onset 
of the root since this would modify the syllable structure that was built on 
the root cycle. Steriade (1982:355) is explicit on this mechanism: "syllabi-
fication rules [«] do not change already assigned syllable structures." 
As for stress, modification-inhibiting no look-back in these analyses 
is taken to be specific to a particular process, syllabification, and only con-
cerns autosegmental structure that is absent from the lexicon. 
 
298  5.6.5. Syntax: Riemsdijk's (1978) Head Constraint 
 
Let us now look at a syntactic precursor of modification-inhibiting no look-
back. Chomsky's (1973) original formulation of the SCC was meant to cut 
down the generative power of syntactic computation. It initiated a theory of 
movement whereby long-distance displacement is cyclic, i.e. where items 
leapfrog through a number of intermediate landing sites before reaching 

248 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
their final location. Abels (2003:16ff) traces back the evolution of cyclic 
movement since 1973, distinguishing theories where intermediate jumps 
are uniformly defined (uniform path) from those where they follow a non-
uniform track (punctuated path). The latter have three main incarnations: 
the Extended Standard Theory (Chomsky 1973 and developments thereof) 
where movement was defined by bounding (or cyclic) nodes and went 
through designated escape hatches, Barriers in GB (Chomsky 1986) and 
today the Phase Impenetrability Condition (PIC, Chomsky 2000a et passim, 
see § 304 below). 
While Chomsky's (1973) initial formulation of the SCC does not in-
clude any modification-inhibiting no look-back, Riemsdijk's (1978:160) 
Head Constraint, also couched in the Extended Standard Theory, does ex-
actly the same labour as the modern Phase Impenetrability Condition. This 
is what Abels (2003:41) shows. Consider both conditions under  (115) be-
low. 
 
(115) comparison of the Head Constraint and the PIC 
 
a. "The Head Constraint 
No rule may involve Xi/Xj and Yi/Yj in the structure 
«Xi«[Hn«[H'«Yi«H«Yj«]H'«]Hn«Xj«
(where H is the phonologically specified (i.e. non-null) head and Hn is 
the maximal projection of H [«])." 
Riemsdijk (1978:160) 
 
b. "Phase Impenetrability Condition 
In phase α with head H, the domain of H is not accessible to operations 
outside α, only H and its edge are accessible to such operations." 
Chomsky (2000a:108) 
 
Abels (2003:41) concludes that both conditions are identical: "no re-
lation can be established between an element outside of (phase) XP and the 
complement of the phase head or anything properly contained in the com-
plement of the phase head." Additional information that is needed in order 
to make either constraint work is the kind of XP to which it applies. While 
Riemsdijk (1978) provides a list (VP, NP, AP, PP), the definition of phase 
heads in phase theory is subject to debate (see § 773). 
If the effect of the two conditions is identical, though, their motiva-
tion is not, and hence their applicability to phonological matters is not ei-
ther. The PIC roots in an interface-based reasoning whereby, following the 
minimalist perspective of third factor explanations (Chomsky 2005), an 
extra-linguistic property of the cognitive system marshals linguistic mecha-
nisms. That is, Chomsky hypothesises that active memory (work bench 

No look-back devices: implementations since 1973 249 
memory) is too small in order to compute an entire sentence in one go. The 
sentence thus needs to be cut into pieces (that is, phases) and is computed 
in several successive waves. At the end of the computation of each phase-
chunk, the output is sent to LF and PF for interpretation and then "forgot-
ten": it comes back "frozen" and may not be accessed anymore by further 
computation (phase theory is introduced at greater length in § 304). 
The PIC under (115b) then merely specifies which piece exactly is 
spelled out and "forgotten": the complement of the phase head XP (the edge 
of the phase, i.e. the head of the XP and the Specifier, are only spelled out 
at the next higher phase). 
In this scenario, it is the interactionist architecture of phase theory 
that makes PF (and LF) enter the scene: something can be "forgotten" only 
because it was spelled out. This interpretation-based definition of "old un-
modifiable" and "new modifiable" chunks is applicable to phonology: 
strings that have already been subject to interpretation are "frozen" and not 
further modifiable. We have seen that this is precisely what defines modifi-
cation-inhibiting no look-back: on Kaye's analysis (§ 279), the stress that is 
assigned to the inner cycle of [[parent] hood] cannot be further modified on 
the outer cycle. 
By contrast, phonology is not touched or concerned at any point in 
the reasoning of the 70s: the motivation and definition of the chunks that 
are not available for further computation is purely syntax-internal. It cannot 
be extended to phonology no matter how much good will is put into the 
venture since interpretation plays no role, and anyway phonology will be 
unable to interpret the arboreal configuration that defines the unmodifiable 
"old" chunk. Only an interpretation-based definition of unmodifiable 
chunks provides a common language for syntax and phonology. 
The reason why interpretation was out of business in the 70s is the 
strictly non-interactionist architecture that was inherited from SPE: all con-
catenation was done before all interpretation (§ 86). Hence there was no 
way to even formulate an interpretation-based definition of "old" and un-
modifiable chunks. 
 

250 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
299  5.7. Modification-inhibiting no look-back in Kaye's system 
 
300  5.7.1. Kaye calls on SCC-M, but applies something else 
 
Let us now look at how modification-inhibiting no look-back is imple-
mented in Kaye's system. It was shown in § 279 that modification-inhibiting 
no look-back is critical in Kaye's analysis of affix class-based phenomena: 
it achieves underapplication. This contrasts with all other analyses, where 
no look-back plays no role. Also recall that Kaye (1992a:142, 1995:307) 
makes explicit reference to Chomsky (1973), Kean (1974) and Mascaró 
(1976) when he introduces his no look-back mechanism, but leaves Kipar-
sky's (1982a,b) SCC-K unmentioned. This is because derived environment 
effects are nothing that Kaye ambitions to account for (§ 284): the scope of 
his theory are only affix class-based phenomena. In a note, he is explicit on 
the fact that Kiparsky's version of no look-back is an entirely different ob-
ject. 
 
(116) "I mean strict cyclicity in its original sense as proposed by Chomsky (1973) 
and applied to phonology by Kean (1974). It has subsequently been used in 
a very different sense, for example, in lexical phonology." Kaye (1995:330, 
note 23, emphasis in original) 
 
While the non-reference to Kiparsky's derived environments corre-
sponds to Kaye's practice, his claim to use Chomsky's original strict cyclic-
ity turns out to be unsubstantiated. What Kaye really applies is modifica-
tion-inhibiting no look-back: whatever comes back from interpretation is 
"frozen" (Chomsky's terminology, see § 306), which means that it is entirely 
invisible and may not be counted or accessed anymore by further computa-
tion.  
That Kaye does not apply Chomsky/Mascaró's SCC-M is obvious 
from the simple fact that the SCC-M is perfectly unable to do the labour 
required. Recall from § 279 how [[parent] hood] is derived: in the inner 
domain, regular penultimate stress assignment produces párent. The same 
stress rule also applies when the outer domain is assessed ± but is blocked 
since the result of its application, *parént-hood, would require to undo the 
stress-assignment that was achieved on the inner domain. The SCC-M, 
however, would not prevent stress from being reassigned at all: the re-
quirement that the rule must use material which is introduced on the latest 
cycle is met: -hood is part of the string that the rule uses in order to com-
pute stress assignment. It is only when no look-back prohibits the modifica-

No look-back devices: implementations since 1973 251 
tion of previously interpreted strings that underapplication of the stress rule 
in párent-hood is guaranteed. 
 
301  5.7.2. Kaye's modification-inhibiting no look-back 
 
Given that Kaye (1992a, 1995) explicitly calls on the SCC-M, it is not im-
mediately obvious to understand that what he really does is quite different. 
Let us therefore look at the example from French that he uses both in Kaye 
(1992a:142ff) and Kaye (1995:306ff). Data and analysis are originally due 
to Prunet (1986, 1987). French shows a contrast between mon ami [mç)n
ami] "my friend" and bon ami [bçn ami] "good friend": the vowel of the 
possessive (mon "my") is nasalized, while the vowel of the adjective (bon
"good") is not. 
Both determiners bear a liaison consonant at their right edge: the [n] 
is only present when the following noun begins with a vowel. It is absent 
before consonants (mon café [mç) kafe] "my coffee", bon café [bç) kafe] 
"good coffee") and in case the words are pronounced in isolation (mon [mç)]
"my", bon [bç)] "good"). Following standard autosegmental assumptions on 
French liaison (Encrevé 1988), liaison consonants are lexically floating. 
The critical contrast, Prunet and Kaye argue (on non-phonological 
grounds), is only in domain structure. While mon ami is the complex 
[[mon] ami], bon ami lacks internal structure: it identifies as [bon ami]. 
Domain structure and the lexical ingredients, then, produce the structures 
under  (117) below. 
 
(117) French mon ami vs. bon ami: input to the phonology 
 
a. mon ami 
 b. bon ami 
 
O
N
O
N
O
N
O
N
O
N
O
N
|
|
|
|
|
|
|
|
|
|
|
|
[[
x
x
]
x
x
x
x
]
[
x
x
x
x
x
x
]
|
|
|
|
|
|
|
|
|
|
m
o
n
a
m
i
b
o
n
a
m
i
Two processes now apply: floating consonants associate to available 
consonantal positions (the floating nasal here behaves like all other floating 
consonants), and nasalization of vowels is effected by nasals that occur 
domain-finally or before a consonant (this is a specific behaviour of nasals, 
but general in the language). 

252 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
The derivation then proceeds cyclically: phonology is first done on 
the inner domain of [[mon] ami]; the result is vowel nasalization, i.e. the 
association of the floating nasal to the preceding nucleus. On the outer cy-
cle, liaison also associates the nasal to the following onset, which is now 
available. In the end, the nasal consonant enjoys a double association: it 
contributes to the pronunciation of the preceding nucleus and the following 
onset; the result is [mç)n ami]. 
By contrast, the nasal in [bon ami] will undergo liaison, but fails to 
nasalize the preceding vowel because bon is not a domain by itself ± hence 
the nasal is never domain-final. Therefore the triggering environment for 
nasalization is never met, and the result is [bçn ami]. 
Table  (118) below shows the output of both derivations. 
 
(118) French mon ami vs. bon ami: output of the phonology 
 
a. mon ami [mç)n ami] 
 b. bon ami [bçn ami] 
 
O
N
O
N
O
N
O
N
O
N
O
N
|
|
|
|
|
|
|
|
|
|
|
|
x
x
x
x
x
x
x
x
x
x
x
x
|
|
|
|
|
|
|
|
|
|
m
o
n
a
m
i
b
o
n
a
m
i
Critical for this analysis is that the association of the nasal to the pre-
ceding nucleus that is achieved on the inner domain under (118a) is not 
undone when the outer domain is subjected to the φ-function. In his 1992a 
article, Kaye comments that  
 
(119) "the PSC [Principle of Strict Cyclicity] will prevent tampering with the 
internal structure of the previous cycle and so N will remain linked to the 
nucleus." Kaye (1992a:144) 
 
In his 1995 article, Kaye provides a more explicit formulation, which 
appears under  (120) below. 
 
(120) "When phonology is done on the external domain, an empty onset is avail-
able for the n. However, the principle of strict cyclicity states that the asso-
ciation created in the inner domain cannot be undone in an external domain. 
The association remains and the n also links to the available onset." Kaye 
(1995:307, emphasis in original) 
 

No look-back devices: implementations since 1973 253 
This is what Kaye's no look-back device really does. A formulation 
that is neutral with respect to particular phenomena appears under  (121) 
below. 
 
(121) Strict Cyclicity Kaye 
a string that has already been subject to interpretation (on a previous cycle) 
cannot be further modified on a later cycle. 
 
It may be objected for the specific analysis of French that no particu-
lar (no look-back) mechanism is needed in order to maintain the association 
line between the nasal and the preceding nucleus on the outer cycle of mon 
ami. Indeed, there is no phonological process in the language that destroys 
association lines: there is no reason why the nasal should be disassociated. 
Hence whatever association is achieved at some point in a derivation sim-
ply piles up with all other associations.  
While this objection may call into doubt the necessity for modifica-
tion-inhibiting no look-back in the particular French example, it does not 
discredit the idea itself: other cases such as stress assignment (§ 279) do 
require modification-inhibiting no look-back in Kaye's system. 
 
302  5.7.3. Chomsky's "spell-out and forget" is too strong for phonology: "don't 
undo" and process-specific no look-back 
 
The formulation under  (121) is obviously too strong in regard of external 
sandhi phenomena, i.e. phonological processes that apply across word 
boundaries, which violate modification-inhibiting no look-back by defini-
tion: words are always spelled out in Kaye's system. They should therefore 
be "frozen" no matter what, and hence any further phonology that applies 
across word boundaries should be prohibited. This is obviously not the 
case: external sandhi (postlexical phonology) exists. 
This problem raises the issue of the word-level hurdle that we have 
already come across in § 241: the word level seems to be an insuperable 
barrier for some processes, but not for others. Also recall that process-
specific no look-back is practised in the early literature that made modifica-
tion-inhibiting no look-back emerge (§ 296): structure preservation and the 
Free Element Condition concerned only stress and/or syllabification, and 
only structure was concerned that is absent from the lexicon (segmental 
structure for example is left unsubjected to no look-back). 
It therefore appears that phonological phenomena are unsuited for 
Chomsky's fully radical "spell-out and forget": a weaker version of modifi-

254 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
cation-inhibiting no look-back is needed (something that Chomsky actually 
senses: see § 306). One way to weaken the formulation is indicated by the 
quote under  (120): Kaye says that properties of the string that were 
achieved by phonological computation on previous cycles cannot be un-
done later on. This is also implied by structure preservation and the Free 
Element Condition: only those properties of the string that were achieved 
by previous computation (metrical and syllable structure) are immune. 
Other properties may happily be modified. 
We are thus in presence of the two candidates for weakening the ex-
cessive strength of Chomsky's "spell-out and forget" that appear under 
 (122) below. 
 
(122) adapting Chomsky's "spell-out and forget" to phonology 
 
a. process-specific no look-back 
the prohibition to modify a previously interpreted string applies selec-
tively to individual processes: every process is specified for being sub-
ject to the no look-back restriction or not. 
 
b. don't undo! 
modification-inhibiting no look-back only concerns properties of the 
string that were acquired by previous computation. Lexical properties 
may be modified at any time even if the string was already interpreted. 
 
Both candidates do the job for the pattern that was discussed in § 241: 
word stress is strictly bound by the limits of the word (it remains unmodi-
fied by stress assignment when strings grow larger than the word), but there 
is external sandhi such as t-flapping across word boundaries (hi(t)[ɾ] Ann). 
Process-specific no look-back (PIC à la carte) solves the problem by mak-
ing stress assignment, but not t-flapping, subject to the prohibition to con-
sider "old" strings. On the other hand, (122b) is also successful: word stress 
cannot be undone when chunks grow bigger than the word because it was 
achieved by phonological computation. External sandhi, however, may 
happily go into effect since the word-final dental of hi(t)[ɾ] Ann is lexical: 
none of its properties is the result of previous computation.  
The latter solution may run into trouble with stress clash (thirtéen vs. 
thírteen men) where word stress is modified (if by a different process, see 
§240, note 64). But let us leave it at that for the time being. The take-home 
message is that the minimalist PIC "spell-out and forget" is too strong for 
phonology, and that there are two candidates for a weaker, phonology-
friendly version of modification-inhibiting no look-back. The issue is fur-
ther discussed in § 825 below. 
 

No look-back devices: implementations since 1973 255 
303  5.7.4. Morpheme-specific phonologies and selective spell-out do the same 
job and are therefore mutually exclusive 
 
The challenge raised by affix class-based phenomena is the organisation of 
underapplication: a process that is active in the language must be prevented 
from applying to strings that are created by the attachment of a particular 
affix class: to class 2 strings in the rule-blocking, to class 1 strings in the 
rule-triggering pattern. Theories propose various means of organising un-
derapplication, and this is what makes them different. 
We have seen three ways of approaching the problem: the one of 
Lexical Phonology, of Halle & Vergnaud and of Kaye. The front line runs 
between the former and the two latter: Lexical Phonology achieves under-
application by distinct morpheme-specific phonologies (§§ 147, 150); on the 
other hand, multiple computational systems play no role in the account of 
Halle & Vergnaud (§ 228) and Kaye (§ 279), which is based on selective 
spell-out and supplemented with modification-inhibiting no look-back in 
the case of Kaye. 
There are thus two philosophies of how to approach affix class-based 
phenomena: multiple computational systems that are morpheme-specific do 
the same job as selective spell-out (eventually supplemented with modifica-
tion-inhibiting no look-back). The empirical coverage is not exactly the 
same, and the conceptual problems that are met by each system are also 
different (see § 310 below). But what is for sure ± the take-home message of 
this section ± is that no system can reasonably implement both tools. Either 
underapplication is organised by morpheme-specific mini-phonologies, or 
by selective spell-out: no theory can feature both, except if redundancy is 
not an issue. 
 
304  5.8. On the (modern) syntactic side: derivation by phase and Phase 
Impenetrability 
 
305  5.8.1. Interactionism is enforced by the minimalist concern for economy of 
cognitive resources (active memory) 
 
The minimalist concern for extra-linguistic factors and the economy of 
cognitive resources has significantly modified the perspective and practice 
of generative grammar: syntax proper (where explanations are now sought 
at the interface, rather than in syntax itself) and the interface with LF and 
PF (which has become interactionist) are directly impacted; also, a no look-

256 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
back device, the Phase Impenetrability Condition (PIC), has become a cen-
tral tool of the theory. This broad and far-reaching evolution was initiated 
by Chomsky's (2000a et passim) derivation by phase, all aspects of which 
of course cannot be covered here. Some more discussion is provided in 
§§ 672, 771 (overview literature includes Frascarelli 2006, Lasnik & 
Lohndal 2009 and Freidin & Lasnik forth). 
Let us first look at interactionism. The generative interface architec-
ture, which stands unchallenged to date, was designed in the 60s. The in-
verted T model (§ 86) divides grammar into three computational devices: 
one where concatenation is done (morpho-syntax), and two others that in-
terpret its result (LF and PF). Until Epstein et al. (1998:46ff), Epstein 
(1999), Uriagereka (1999) and Chomsky (2000a), it was taken for granted 
in all successive and competing blends of syntax that all concatenation is 
done before all interpretation (§ 86).73 That is, morpho-syntax first com-
pletes the entire derivation, and then ships off the result to PF and LF. 
Interactionism is a fundamentally different take on how morpho-
syntax and the interpretational modules communicate: it holds that con-
catenation and interpretation are interleaved. This idea was carried into 
linguistic thinking by Lexical Phonology, of which it is an inescapable 
headstone (see §§ 146, 212). Shortly after its introduction, interactionism 
provoked a strong reaction on the side of generative orthodoxy: Halle & 
Vergnaud (1987a) tried to restore the take of SPE by proposing an analysis 
of affix class-based phenomena under the anti-interactionist banner (§ 222). 
Until Epstein et al. (1998:46ff), Epstein (1999) and Uriagereka 
(1999), the debate on interactionism was confined to phonological quarters. 
All of a sudden, then, it enters the syntactic scene in the late 90s, with a 
different name, though (multiple spell-out, derivation by phase), and as far 
as I can see without any reference to the phonological precedent. 
Uriagereka's multiple spell-out motivates the come and go between 
syntax and interpretational devices on economy-driven minimalist grounds. 
Uriagereka explains how the (radically) derivational perspective of an in-
teractionist architecture is made possible by the minimalist abandon of the 
distinction between deep and surface structure: while there was no place for 
derivational mechanisms in the representational GB-times of the 80s, the 
new perspective actually relates back to the more derivational 70s. 
 
73 Except by Bresnan (1971), to be discussed in § 308 below, and in Jackendoff's 
(1997 et passim) parallel model (on which more in § 722) where the inverted T 
is rejected. 

No look-back devices: implementations since 1973 257 
(123) "An older model provides an intriguing way of going about the general 
deduction of the LCA [Linear Correspondence Axiom]. For reasons that 
become apparent shortly, I refer to it as a dynamically split model. The ori-
gins of this outlook are discussions about successive cyclicity and whether 
this condition affects interpretation: are the interpretive components ac-
cessed in successive derivational cascades? Much of the debate was aban-
doned the moment a single level, S-structure, was postulated as the interface 
to the interpretive components. Now that S-structure has itself been aban-
doned, the question is alive again: what would it mean for the system to 
access the interpretation split in a dynamic way?" Uriagereka (1999:255, 
emphasis in original) 
 
On the other hand, Samuel Esptein and colleagues arrive at the same 
result (actually in its most extreme incarnation, Spell-out-as-you-Merge, 
see § 776) on principled grounds: their derivational approach to syntax is 
incompatible with single LF and PF levels. 
 
(124) "[W]e depart from the minimalist conception of linguistic levels and de-
velop a form of the derivational model of syntax, in which the derivational 
process not only determines syntactic relations but also provides informa-
tion directly to the interface systems. Under this derivational model, the 
syntactic relations in question are deduced from the way these relations are 
created by CHL [Chomsky's computational system of human language, see 
§638]; furthermore, upon creation, these relations enter into the interpretive 
procedures without mediation of linguistic levels." Epstein et al. (1998:47) 
 
"[E]ach transformational rule application constitutes a 'phase', which we 
believe to be the null hypothesis. Like Epstein et al. (1998), [«] and 
Uriagereka (1999), Chomsky (2000[a] [«]) abandons the Y-model's single 
split to PF and LF in which interface interpretation applies only after all 
transformational rules have applied." Epstein & Seely (2002:77) 
 
Multiple spell-out was then worked out in Chomsky's (2000a, 2001 
et passim) derivation by phase, which today is the standard way of conceiv-
ing of the communication between morpho-syntax and PF/LF in generative 
quarters. After almost 50 years of existence, the generative mainstream has 
thus abandoned "all concatenation before all interpretation" and became 
interactionist. As was mentioned, it appears that this about-turn was made 
without reference to Lexical Phonology and the quarrel regarding interac-
tionism that took place in the 80s. 
If the result of the minimalist move is exactly what Lexical Phonol-
ogy proposed in the 80s, its motivation is very different: it was already 

258 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
mentioned that Uriagereka's multiple spell-out is motivated by the minimal-
ist concern for economy. Chomsky argues that linguists are invited to cut 
the derivation of a whole sentence into smaller chunks ± phases ± if extra-
linguistic properties of the cognitive system are taken seriously: morpho-
syntactic computation uses active memory ("work bench memory", "work-
space"), a very limited cognitive resource. Chomsky's (2000a:101) mini-
malist take is that the faculty of language has "optimal" design properties 
and operates with economy principles. This means, among other things, 
that computational complexity is unwarranted.  
 
(125) "There is mounting evidence that the design of FL [faculty of language] 
reduces computational complexity. That is no a priori requirement, but (if 
true) an empirical discovery, interesting and unexpected. One indication that 
it may be true is that principles that introduce computational complexity 
have repeatedly been shown to be empirically false." Chomsky (2001:15) 
 
The bias against computational complexity is thus assumed to have 
extra-linguistic causes, i.e. the restriction on the availability of active mem-
ory, an expensive cognitive resource. 
In a linguistic derivation, then, a whole sentence is too big and too 
demanding computationally speaking in order to be able to be processed in 
one go. If sentences are built step by step, the burden imposed on active 
memory by the computation of the successive pieces is reduced. The inter-
actionist come and go between syntax and LF/PF is a consequence of this 
implementation-based approach, which Chomsky first explicitly mentions 
in his Minimalist Inquiries (Chomsky 2000a:106). 
Chomsky advertises the result of the interactionist architecture as fol-
lows. 
 
(126) "If such ideas prove correct, we have a further sharpening of the choices 
made by FL [faculty of language] within the range of design optimization: 
the selected conditions reduce computational burden for narrow syntax and 
phonology." Chomsky (2001:15) 
 
Chomsky thus explicitly extends the invisibility of previously inter-
preted strings to phonological computation. This is also shown by the fol-
lowing quote. 
 
(127) "The computational burden is further reduced if the phonological component 
too can 'forget' earlier stages of derivation." Chomsky (2001:12f) 
 

No look-back devices: implementations since 1973 259 
In the recent development of generative theory, the global architec-
ture of grammar has thus become interactionist under the pressure of econ-
omy-orientated design and the concern for cognitive (extra-linguistic) plau-
sibility (third factor explanations, Chomsky 2005), which are the driving 
force of the minimalist programme. 
 
306  5.8.2. Phase Impenetrability is the instrument of active memory economy 
 
The economy of active memory supposes that morpho-syntactic computa-
tion is unburdened with the management of the structure of previous 
phases: on each pass, only the material of the current phase is subject to 
morpho-syntactic computation. Chomsky (2001) refers to the inertness of 
previous phases by saying that they are "frozen in place" (Chomsky 
2001:6) or "forgotten" (Chomsky 2001:12) by later computation.  
The formal expression of this inertness, then, is the Phase Impenetra-
bility Condition (PIC), which is thus understood as a protection against the 
overheat of active memory.74 
(128) "The whole phase is 'handed over' to the phonological component. The de-
leted features then disappear from the narrow syntax. [«Uninterpretable 
features] have been assigned values (checked); these are removed from the 
narrow syntax as the syntactic object is transferred to the phonology. The 
valued uninterpretable features can be detected with only limited inspection 
of the derivation if earlier stages of the cycle can be 'forgotten' ± in phase 
terms, if earlier phases need not be inspected. The computational burden is 
further reduced if the phonological component too can 'forget' earlier stages of 
derivation. These results follow from the Phase-Impenetrability Condition 
(PIC) (MI [Minimalist Inquiries, i.e. Chomsky 2000a], (21)), for strong 
phase HP with head H, 
 
(7) The domain of H is not accessible to operations outside HP; only H and 
its edge are accessible to such operations." 
 
Chomsky (2001:12f) 
 
Note that according to Chomsky phonology is concerned by compu-
tational economy just like syntax. Chomsky (2004) reiterates the need for 
the PIC to exist in phonology; interestingly, though, he senses that "spell-
 
74 The notion of phase edge that is mentioned in the quote below, as well as its 
eventual equivalent in phonology, is discussed in § 765. 

260 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
out and forget" may be too strong a condition on phonological computation. 
This is indeed what we have seen in § 302. 
 
(129) "Φ [the phonological component] is greatly simplified if it can 'forget about'
what has been transferred to it at earlier phases; otherwise, the advantages of 
cyclic computation are lost. Although the assumption may be somewhat too 
strong, let us assume it to be basically true " (Chomsky 2004:107f) 
 
Phase Impenetrability is thus a cognitive-economy-born no look-
back device. Curiously enough, the syntactic literature does not appear to 
make reference to the phonological no look-back devices that are an impor-
tant piece of phonological thinking. Also, the literature typically does not 
mention that Phase Impenetrability is a revival of Chomsky's (1973) Strict 
Cycle Condition (but see Müller 2004): the idea of no look-back was born 
in syntax. 
Just as on the phonological side some time ago, there is ongoing de-
bate in current syntax what exactly "frozen" means. While this question is 
beyond the scope of the book, it is touched on in § 778. 
Phase Impenetrability is thus an old acquaintance, but comes in a 
new guise: motivation from cognitive economy was completely absent in 
earlier incarnations of no look-back devices, which were exclusively based 
on grammar-internal considerations. 
 
307  5.8.3. The old and the new: a memory keeper and/or diacritic marking 
needed? 
 
An obvious consequence of Phase Impenetrability that I could not find any 
trace of in the literature is the need for a memory keeper and/or diacritic 
marking of "old" strings. The PIC requires that the computational system 
make a difference between "old" and "new" strings, i.e. between those that 
have already been interpreted (frozen, not a possible input to computation), 
and those which are still uninterpreted and therefore a good input to com-
putation. 
There are two ways of implementing this idea: either the "old" string 
is reintegrated into the workspace when it comes back from interpretation, 
and the computational system is able to distinguish it from freshly concate-
nated material; or it never comes back to the computational workbench and 
instead is stored in some intermediate memory. In this case, all stored 
pieces are concatenated (in the correct order), and the sentence is pro-
nounced, when the last piece of the highest CP is interpreted.  

No look-back devices: implementations since 1973 261 
The former solution requires some diacritic marking of "old" strings: 
otherwise the computational system could not know that a string is "fro-
zen". The latter solution does not, but instead needs a memory keeper and 
workbench-independent storage (more on this in §§ 797f). The memory 
keeper option appears to be in line with the philosophy of Phase Impene-
trability: the PIC is motivated by the discharge of active memory. 
The question is left open for the time being. We will return to it at 
greater length in § 794. We know already that the old-new distinction is also 
relevant in phonology: this is what modification-inhibiting no look-back is 
all about (§§ 293, 299). In the chapter on OT we will see that it is also rele-
vant in systems that do not directly relate to modification inhibition or the 
PIC (McCarthy's 2003a Comparative Markedness § 519, van Oostendorp's 
2006a colours § 505). 
What may be said already here is that the memory keeper option is 
not workable in phonology for the reasons discussed in § 302: processes 
whereby pieces of the "old" string are modified under the influence of a 
piece of a "new" string are trivial and commonplace: e.g. external sandhi, 
but also regular palatalisations where a suffix-initial front vowel alters a 
stem-final velar (provided that it can be independently shown that there is a 
phase boundary between the stem and the suffix). Therefore the "old" string 
must be somehow available for further computation, even if (parts of it) 
cannot be modified. 
This leaves us with the two options (and possibly still others) that are 
discussed in § 302: process-specific PIC and "don't undo!". On the latter 
count (but not on the former), computation needs to be able not to identify 
which part of the string that is submitted to computation is "old", but which 
properties are the result of previous computation. Or, in other words, "old" 
in this context does not mean "a previously uninterpreted morpheme", but 
"a property of the string that was not created by previous computation, i.e. 
which was present as such in the lexicon." Again, some diacritic marking 
seems to be necessary in order for the computational system to be able to 
identify non-lexical properties of the string. Implications of process-
specific PIC are further discussed in § 825. 
 
308  5.8.4. Ancestors of multiple and selective spell-out: Bresnan (1971) 
 
Uriagereka (1999:277), Chomsky (2000a:150) and historical overviews of 
generative grammar such as Lasnik & Lohndal (2009:48) and Freidin & 
Lasnik (forth) identify Bresnan (1971) as an early case of multiple and 

262 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
actually selective spell-out of PF properties. On the LF side, they mention 
the Ph.Ds of Ray Jackendoff (1969) and Howard Lasnik (1972) as early 
sources of interpretation that occurs in the midst of the syntactic derivation. 
Like (phonological) interactionism and its modern syntactic version 
derivation by phase (or multiple spell-out), these analyses thus dispense 
with the principle "all concatenation before all interpretation" that accom-
panied the inverted T since the 60s (see § 86).  
Halle & Vergnaud (1987a) are credited with the paternity of selective 
spell-out in §§ 220,225; let us therefore have a brief look at Bresnan's argu-
ment. Bresnan's article is well-known in syntactic quarters since Bresnan is 
a syntactician and writes about intonation (sentence stress), which is the 
phonological phenomenon that syntacticians are confronted with first if 
they meet any phonology at all. Bresnan's (1971:258) central example is 
reproduced under  (130) below (based on an observation by Newman 1946; 
underscored words are intonationally prominent). 
 
(130) a. Helen left directions for George to follow. 
 
b. Helen left directions for George to follow.
In these examples, sentence stress impacts meaning, and the impact 
is not optional: under (130a) directions is the object of the verb to follow,
while under (130b) directions has no argumental involvement with to fol-
low. That is, Helen has left directions which George is supposed to follow 
under (130a) while Helen has left directions to the effect that George 
should follow under (130b). 
SPE has defined a Nuclear Stress Rule (NSR) that distributes pri-
mary intonational prominence to the rightmost item that bears primary 
word stress in the current cycle (Chomsky & Halle 1968:17f). In case of 
successive applications in several cycles, the latest application of the NSR 
defines primary stress: all previously distributed intonations are demoted 
by one on a scale of prominence. 
Bresnan argues that the contrast under  (130) cannot be derived if the 
NSR is blindly applied to the overall output of the syntactic derivation: the 
two sentences under  (130) involving identical words and word order, the 
intonation should always be as under (130b), i.e. rightmost. If on the other 
hand the NSR applies every time an S is completed, the derivational history 
of embedded S's matters. Bresnan (1971:260) assumes the following struc-
tures. 
 

No look-back devices: implementations since 1973 263 
(131) a. [S Helen left [NP directions [S for George to follow directions S] NP] S]
b. [S Helen left [NP directions [S for George to follow S] NP] S]
She then derives the intonational difference from the fact that follow 
has a direct object under (131a) while it does not under (131b). Being the 
rightmost constituent throughout the entire derivation, follow receives 
stress under (131b). By contrast under (131a) the rightmost directions is 
deleted after the completion of the embedded S, and this is why it bears 
primary stress in its surface position. Or, in other words, the surface intona-
tion that we see on directions was crucially assigned before the word was 
moved. 
The detail of the derivation is more intricate (and not really made ex-
plicit by Bresnan): it appears that some PIC-like device is needed in order 
to make the material of the embedded S under (131a) invisible when the 
matrix S is computed ± otherwise the moved copy of directions would not 
be the rightmost item, and its primary stress would be overridden when the 
matrix S is computed. 
Be that as it may, the take-home message is that Bresnan (1971) in-
deed practised a form of interactionism since in her analysis a phonological 
rule, the NSR, crucially applies to a word in situ and before the syntactic 
derivation is completed. In modern vocabulary, one would say that S is a 
phase head. Note that Bresnan calls the NSR a cyclic rule, but what she 
calls a cycle has got nothing to do with the cycle as defined in SPE (where 
roughly every morpheme is a cycle § 101). Rather, she appeals to the trans-
formational cycle as defined by Chomsky (1970). This means that she also 
practised selective spell-out in the sense of Halle & Vergnaud (1987a) 
(§ 225): not only is concatenation interspersed with interpretation, but also 
only a subset of nodes (S in this case) is a spell-out point. 
In the end, though, Bresnan's analysis may turn out not to involve 
any interactionism, or selective spell-out for that matter. This is because 
intonation is maybe defined by a syntactic, rather than by a phonological 
operation. The surface marker of intonation is certainly a modulation of 
sound, but this effect may as well be achieved if PF interprets a string 
where intonational prominence is encoded due to syntactic marking. This 
issue is further discussed in § 800.

264 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
309  5.9. Conclusion 
 
In conclusion of this section, it is useful to point out how a number of con-
cepts relate historically: there appears to be quite some confusion about no 
look-back devices (and it is true that one can think of less intricate matters). 
On the one hand, different incarnations of no look-back may not be related 
to each other (for example, bracket erasure is not related to the SCC-K, see 
§201). On the other hand, when they are, they are often held to be some-
how equivalent. For example, Halle/Kiparsky's SCC-K is taken to be a 
development of Chomsky/Mascaró's SCC-M, even though the two mecha-
nisms are quite different in design, scope and effect.  
Modification-inhibiting no look-back is an entirely different way of 
doing no look-back that emerged in the 80s in phonology and has also a 
syntactic precursor (Riemsdijk 1978). While the general idea is that previ-
ously interpreted strings are immune against further modification on later 
cycles, what exactly they are immune against is subject to debate. Chom-
sky's modern "spell-out and forget" is too strong for phonological matters, 
and there are at least two ways of weakening the formulation (§ 302). In any 
event, Chomsky/Mascaró's strict cyclicity has got nothing to do with modi-
fication-inhibition. 
In minimalist syntax, modification-inhibiting no look-back surfaces 
when Chomsky (2000a, 2001) describes previously interpreted strings as 
"frozen": further computation may "forget" about them. Even if the motiva-
tion is entirely different (computational economy, cognitive resources), it is 
quite surprising that Chomsky does not make reference to his own 1973 
article, which introduced the idea of no look-back into linguistic thinking 
(Chomsky 1973 is absent from Chomsky 2000a, 2001), and also that the 
minimalist literature does not appear to mention the phonological precedent 
regarding modification-inhibition. 
 
310  6. Empirical coverage: Kaye's system and affix class-based phenomena 
 
311  6.1. The empirical testing ground: five English affix class-based 
phenomena 
 
Let us now run Kaye's version of selective spell-out against the record that 
was used in order to evaluate the empirical coverage of affix class-based 
phenomena that Lexical Phonology (§§ 163, 166) and Halle & Vergnaud's 
(1987a) system (§ 248) offer. Table  (132) below recalls the five relevant 

Empirical coverage: Kaye's system and affix class-based phenomena 265 
affix class-based phenomena that are found in English (the record was es-
tablished in §§ 163, 166) ("yes" means that the process goes into effect, "±" 
that it does not). 
 
(132) English affix class-based phenomena 
 
monomor-
phemic 
situation 
class 1 
affix 
class 2 
affix 
type 
 
a. Trisyllabic Shortening 
± 
yes 
± 
rule-blocking 
b. nasal assimilation: un-
/in- 
yes 
yes 
± 
rule-blocking 
 
c. stress placement 
transparent trans-
parent 
opaque rule-blocking 
 
d. nasal cluster simplifi-
cation 
 
1. /gn/ →n
yes 
± 
yes 
rule-triggering
2. /mn/ →m
yes 
± 
yes 
rule-triggering
The table indicates the situation with class 1 and class 2 affixes, as 
well as in mono-morphemic situations. The latter are understood as inclu-
sive of all triggering conditions that are unrelated to affix classes. That is, 
Trisyllabic Shortening goes into effect with class 1 affixes (s[æ]n-ity,
against class 2 m[ej]den-hood), but requires a string of three syllables; it 
fails to apply, however, to mono-morphemic three-syllable strings (nightin-
gale, ivory, cf. § 129). Nasal assimilation has no other condition than the 
adjacency of a nasal with an obstruent and the affix class contrast between 
un- and in-: it always goes into effect morpheme-internally (there are no 
non-homorganic NC clusters in English mono-morphemic items). 
The situation of nasal cluster simplification is a little more compli-
cated since it only goes into effect if an additional condition (other than 
affix class requirements) is met. That is, clusters are only simplified in 
morpheme-final position (§ 203): while /sign/ and /damn/ undergo the proc-
ess and appear as sign and damn, the cluster remains undamaged mor-
pheme-internally (i[gn]ore, a[mn]esia). Therefore the morpheme-final 
condition must be included in the statement of the process. The table indi-
cates that it goes into effect in mono-morphemic situations because this is 
what sign and damn are. It does not in i[gn]ore and a[mn]esia because the 
morpheme-final condition is not fulfilled ± not because of affix class re-
lated matters.  
This also shows that the resistance of morpheme-internal /gn/ and 
/mn/ against reduction has nothing to do with derived environments: sign

266 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
and damn are perfectly underived, but still undergo the process. The situa-
tion is thus quite different from the one where ivory and nightingale resist 
Trisyllabic Shortening, which is a real derived environment effect. 
The last column of table  (132) classifies the five processes according 
to Kenstowicz & Kisseberth's typology that was introduced in § 51: Trisyl-
labic Shortening, nasal assimilation and stress placement instantiate the 
rule-blocking pattern (level 1 rules in Lexical Phonology), while nasal clus-
ter simplification illustrates the rule-triggering pattern (level 2 rules). Fol-
lowing the same procedure as before when Lexical Phonology and Halle & 
Vergnaud's (1987a) system were examined, the discussion below proceeds 
in this order. 
Finally, the special status of stress placement needs to be mentioned. 
Strictly speaking, this process is a category of its own: whether it goes into 
effect or not is not a question since it always does (there are no unstressed 
words). Rather, what is at stake is the transparent vs. opaque application of 
stress placement: mono-morphemic items (párent) and class 1 strings 
(parént-al) are in the former case (penultimate stress), while class 2 strings 
(párent-hood) receive opaque stress (non-penultimate). Stress placement is 
mentioned as a rule-blocking process because it is prevented from reapply-
ing (rather than from applying) to class 2 strings. This is also the reason 
why it is treated as a level 1 rule in Lexical Phonology (§§ 147, 164). 
 
312  6.2. The rule-blocking pattern (level 1 rules) 
 
313  6.2.1. Modification-inhibiting no look-back achieves underapplication at 
the outer cycle 
 
It was shown in § 279 that in Kaye's system modification-inhibiting no 
look-back achieves underapplication for a phenomenon of the rule-blocking 
pattern, stress assignment. While the affixation of a class 1 affix is neutral 
with respect to spell-out, the concatenation of a class 2 affix triggers the 
interpretation of its sister, the root in [[parent] hood]. The stress that [par-
ent] acquires at PF is then unmodifiable when the word is spelled out as a 
whole. By contrast, the word-level spell-out of [parent-al] is not confronted 
to any previously assigned stress; this allows for regular (i.e. transparent) 
stress placement. 

Empirical coverage: Kaye's system and affix class-based phenomena 267 
Trisyllabic Shortening is analysed along the same lines:75 it applies to 
class 1 strings (s[Q]n-ity1), but not to class 2 strings (m[ej]den-hood2) or to 
mono-morphemic items (nightingale). Underapplication to class 2 strings is 
a consequence of modification-inhibiting no look-back at the word level. 
Trisyllabic Shortening did not go into effect on the inner cycle of 
[[maiden] hood] because the trisyllabic condition was not met. At the outer 
cycle, then, the previously interpreted [ej] cannot be further modified. By 
contrast, the root of [san ity] has not experienced previous spell-out and is 
therefore free to undergo Trisyllabic Shortening at the word level. 
On the other hand, underapplication to mono-morphemic items such 
as [aj]vory or n[aj]ghtingale is a derived environment effect that, recall 
(§ 284), lies beyond the scope of Kaye's analysis of affix class-based phe-
nomena. 
 
314  6.2.2. Nasal assimilation requires independent spell-out of the affix 
 
Nasal assimilation is a case where the affix needs to be spelled out inde-
pendently before it is merged. Recall from § 274 that this is a possibility 
that Kaye's system provides for, but which is not available in regular spell-
out where only nodes of the morpho-syntactic tree, not terminals, can be 
interpretational units. 
In order to see this, it is enough to consider the result that is pro-
duced on the basis of [in possible] and [un [predictable]]: the class 2 affix 
un-, but not the class 1 affix in-, triggers the spell-out of the root. Nasal 
assimilation makes /nC/ sequence homorganic: it applies to [in possible], 
and nothing more needs to be said. Upon the derivation of 
[un [predictable]], the inner domain [predictable] is interpreted first: since 
there is no /nC/ cluster, nothing happens. At the outer domain, then, the 
string [un predictable] is computed, and nasal assimilation goes into effect. 
No look-back is toothless: the root was spelled out before and hence is un-
touchable ± but the prefix was not. Its nasal thus happily undergoes assimi-
lation, and the unwarranted *um-predictable is produced. 
In order to get things right, the affix needs to be spelled out before 
being merged. At the word-level domain, modification-inhibiting no look-
back would then guarantee the non-assimilation of the nasal. 
 
75 Though not by Kaye, who considers the alternations at hand non-phonological 
(see § 276). The analysis below merely shows how Trisyllabic Shortening could 
be done in Kaye's system, were it declared phonological. 

268 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
This is precisely the analysis that Kaye (1995:305) proposes: he 
identifies un-predictable as the analytic [[un] [predictable]], while 
im-possible (and of course all morpheme-internal clusters) are non-analytic: 
[in-possible] (and [lanp] for lamp for those who go along with the abstract 
analysis of an underlying dental). The nasal, then, assimilates to the follow-
ing obstruent in [im-possible] and [lamp], while un- remains unaffected: it 
was already spelled out in its own domain and hence cannot be further 
modified when nasal assimilation applies to the outer domain 
[un predictable]. 
Kaye (1995:305) also discusses the candidate structure [un [predict-
able]] where un- does not sit in a domain of its own. He rejects this option 
on the grounds of a phonological argument that is specific to Standard 
Government Phonology ± and which does not go through. 
In Government Phonology, lexical items always end in a nucleus: in 
case they are consonant-final on the surface, the final syllabic constituent is 
an empty nucleus (Kaye 1990a). Since un- is an independent lexical item, it 
ends in an empty nucleus, whose Empty Category Principle (ECP) needs to 
be satisfied. In case [unø-] is a domain of its own, the final empty nucleus 
is licensed by virtue of being domain-final (see § 330). No look-back guar-
antees that this phonological property ± the well-formedness of the final 
empty nucleus ± remains unmodified on later cycles. 
If on the other hand un- does not constitute a domain, Kaye argues, 
[unø [predictable]] is phonologically ill-formed because the only way for 
empty nuclei that are not domain-final to be silenced is through Govern-
ment from the following contentful nucleus. The intervening branching 
onset [pr], however, blocks Government, to the effect that the overall struc-
ture is ungrammatical. 
This argument is not conclusive: along the same lines im-probable,
which identifies as [inø probable], would be ill-formed since the empty 
nucleus is unable to receive Government from the first root vowel over the 
[pr] cluster. 
Kaye (1995) thus chooses the correct compound structure 
[[un] [predictable]] for the wrong reason. Un- must indeed come with a 
domain of its own in order for nasal assimilation to be unable to target its 
nasal, which will be protected by no look-back. But there is no independent 
phonological reason. 
 

Empirical coverage: Kaye's system and affix class-based phenomena 269 
315  6.2.3. Anti-affix ordering items cannot be done: stress violates no look-
back 
 
Finally, it needs to be mentioned that there is one sub-pattern of stress-
placement (132c) that Kaye's system cannot account for. This is when a 
class 1 suffix is merged to a class 2 suffix: the result is regular stress shift 
as everywhere else when class 1 affixes are concatenated. Given that the 
class 2 affix, which is lower in the tree, has already triggered interpretation; 
however, what is expected is that stress does not move: it should be pre-
vented from doing so by modification-inhibiting no look-back. 
The cases in question are exactly the ones that invalidate Siegel's 
(1974) affix ordering generalisation, and which are also known as bracket-
ing paradoxes. The relevant pattern was introduced in § 243, and Halle & 
Vergnaud's analysis was discussed in § 246. An example is gov-
ern-mént2-al1: -ment identifies as a regular class 2 suffix by not triggering 
stress shift ± its concatenation produces góvern-ment2. According to Kaye's 
system, this is because the suffixation of class 2 affixes triggers the spell-
out of the root, which acquires a stress pattern that no look-back prevents 
from being modified on the outer cycle of the relevant structure [[gov-
ern] ment]. 
Up to this point, everything is fine, and the derivation is exactly as in 
§313. When -al1 is added, then, the relevant domain structure is [[gov-
ern] ment2 al1]. The root was already spelled out through the action 
of -ment2 and therefore bears stress in góvern-ment ± it should therefore be 
immune against the "wish" inherent to -al1 to shift stress. But in fact it is 
not: the merger of -al1 causes stress to move one vowel right in violation of 
no look-back. 
There is nothing more to be said, except perhaps that the process 
which produces the violation of no look-back is stress. Stress, however, is a 
well-known problem child, which appears to be particularly apt to violate 
no look-back devices. Recall from § 192 that it was already stress which 
violated the generalisation regarding derived environments, i.e. Kiparsky's 
SCC-K, another no look-back mechanism. We will see in § 554 that stress is 
also declared exceptional in regard of no look-back by Marvin (2002). 
Ultimately, what this is all about is to find a rationale for determining 
the class of processes that (may) violate no look-back. This was already 
attempted in the 80s when structure-building were opposed to structure 
changing processes: the former were supposed to be able to violate the 
SCC-K, while the latter were held to obey no look-back (§ 192). 

270 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
Without this being very original (see Rubach 1984:222), one ration-
ale that is suggested in § 554 below is that suprasegmental processes such as 
stress and tone (may) violate no look-back. A summary of the quirky prop-
erties of stress is provided in § 814. 
 
316  6.3. Spell-out of terminals: the problem and a possible solution 
 
317  6.3.1. The problem: independent spell-out of affixes prior to their being 
merged 
 
Underapplication of the rule-triggering pattern is no problem when the 
process modifies the root: given [[root] A] (or [A [root]] for that matter), 
the root is protected by modification-inhibiting no look-back on the outer 
cycle since it was already spelled out. In a compound structure [[A] [root]] 
(or [[root] [A]] for that matter), however, the fact that [A] is a domain of its 
own requires its independent spell-out, crucially without the root being 
spelled out at the same time (which is what happens on the outer cycle). A, 
though, is necessarily dominated by a node that also dominates the root, 
which means that what the spell-out mechanism must be able to do is to 
send A to interpretation before it is merged into the tree (§ 274). Otherwise 
there is no way for it to be spelled out in absence of the root: on regular 
assumptions only nodes can be phase heads. 
Kaye's system thus requires the independent spell-out of terminals if 
an affix, rather than a root, is concerned by a no look-back effect, that is, in 
case the underapplication of a process to an affix needs to be organised. 
This is precisely what must be done in nasal assimilation: the prefix-final 
nasal in un-predictable does not assimilate and hence must be protected 
from nasal assimilation by a domain of its own: [[un] [predictable]] (§ 314). 
 
318  6.3.2. Morphological adjuncts, counter-cyclic merger and intermodular 
predictions 
 
Clearly, a solution to this problem can only be syntactic ± phonology has 
nothing to say about spell-out. Taking a closer look at the syntactic litera-
ture shows that the independent spell-out of terminals has actually been 

Empirical coverage: Kaye's system and affix class-based phenomena 271 
proposed ± of course for purely syntactic reasons that have nothing to do 
with our phonological motivation.76 
The idea of counter-cyclic merger (or late adjunction) in syntax is 
that items may be merged into the syntactic structure without extending the 
root of the tree. A specific version of this approach holds that the status of a 
phrase as an adjunct (or subject) entails interpretation at PF prior to 
counter-cyclic merger into the core syntactic tree (e.g. Lebeaux 1988, 
Stepanov 2001). Adjuncts are therefore a separate phase in the terminology 
of modern phase theory. This indeed looks like a description of the behav-
iour of un-. Let us therefore explore the hypothesis that un- (but not in-) is a 
(morphological) adjunct. 
In the perspective of the literature mentioned, adjuncts enjoy a cer-
tain autonomy and may be merged into syntactic structure counter-
cyclically, that is to a non-root node. An adjunct may thus be absent from a 
syntactic structure at a level of construction that has already grown higher 
than its own location: it may join in later. 
If the analysis of un- as an adjunct turns out to be plausible, and if 
morphological adjuncts are really spelled out before they are merged into 
the tree, the problem that is raised by Kaye's requirement that terminals 
must be able to be spelled out independently disappears. Or rather, it turns 
into an interesting cross-modular prediction, which has all for being wrong, 
but turns out to be true. The overall prediction is that all affixes which are 
subject to a phonological no look-back effect are in fact (morphological) 
adjuncts ± this is something that may be controlled on the morpho-syntactic 
side. 
Newell & Scheer (2007) make an argument in favour of this perspec-
tive that builds on the benefits which are produced on the syntactic as much 
as on the phonological side. That is, the interpretation of un- as an adjunct 
explains so-called bracketing paradoxes where a mismatch between mor-
phological and phonological structure seems to be produced by un-, but not 
by in-. A digest of the argumentation is provided below. 
 
319  6.3.3. Benefits: bracketing paradoxes, category selection, double affixation 
 
The phonologically contrasting behaviour of un- and in- is paralleled on the 
morpho-syntactic side. Visible effects are so-called bracketing paradoxes, 
which were already discussed in §§ 243,440: the structure of un-happi-er 
76 The discussion below is a digest of Newell & Scheer (2007). 

272 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
should be [[un [happy]] er] since it means "more unhappy", rather than "not 
more happy". That is, un- has only scope over the root. Phonologically, 
however, the structure should be [un [[happy] er]] since the synthetic com-
parative -er selects maximally bisyllabic stems (big - bigger, happy - hap-
pier); adjectives with more syllables have an analytic comparative (beauti-
ful - *beautifuller, more beautiful). The synthetic un-happi-er, then, is only 
possible if -er is concatenated before un- is merged. 
The same invisibility of un- (but not of in-) for comparative allomor-
phy selection is responsible for the fact that un- allows for unlikelier (like-
lier), while in- cannot build *impoliter (politer, more impolite).
These phenomena fall out if un- is a counter-cyclically merged ad-
junct: it is absent when the comparative selects for maximally bisyllabic 
roots. By contrast, in- is present upon suffixation and thus blocks the deri-
vation. 
Another known property of adjuncts is that they do not project fea-
tures (e.g. Lebeaux 1988, Stepanov 2001). This is precisely the case of un-,
which adjoins to various syntactic categories: verbs (unlock vs. *inlock), 
nouns used as adjectives (unBritney: "she is the unBritney" vs. *inBritney) 
and adjectives (unhappy, intolerable). By contrast, in-, being a non-adjunct, 
projects adjectival features and thus only attaches to adjectives (intoler-
able). Un- being an adjunct, on the other hand, it extends the base to which 
it attaches.  
Other morphological adjunction phenomena such as double affixa-
tion in cases like eater upper (vs. *eater up, *eat upper) are covered by the 
same analysis. Here the particle is argued to adjoin counter-cyclically. The 
derivation therefore includes an interruption of the one-to-one mapping 
between linear proximity and hierarchical structure of affixes, inducing re-
spell-out of the agentive morpheme. 
Counter-cyclic merger in general and the analysis of un- in particular 
also raise a number of concerns. For one thing, counter-cyclic merger vio-
lates Chomsky's (1995a) Extension Condition. Also, it may be argued that 
in fact there are two distinct un-'s: un- appears to be negative when com-
bined with an adjective, but reversative when combined with a verb. In 
defence of the analysis proposed, it may also be argued, though, that the 
meaning of un- is reversative even in combination with an adjectival host 
(Kennedy 2001); therefore all instances of un- represent one and the same 
item. 
Newell (2005a,b, 2008) expands on the syntactic issues related to the 
analysis of un- as an adjunct. 
 

Empirical coverage: Kaye's system and affix class-based phenomena 273 
320  6.3.4. Procedural first 
 
The appendix to this discussion is about a topic that is eluded elsewhere in 
the book: the balance of procedural and representational solutions for inter-
face phenomena (see § 748). Suppose there are empirically equivalent pro-
cedural and representational solutions for a given interface phenomenon ± 
which one should be preferred? Newell & Scheer (2007) argue that a pro-
cedural analysis is always more interesting because it makes predictions on 
the morpho-syntactic side. By contrast, representational analyses cannot 
have any impact beyond phonology for principled reasons. 
In order to make the point, let us look at the purely representational 
analysis of the nasal assimilation facts that is proposed in Prosodic Phonol-
ogy. Rubach & Booij (1984:11f) and Vogel (1991) derive the contrasting 
behaviour of un- and in- from contrasting prosodic structure: un- is mapped 
into a prosodic word (PW) of its own ([un]pw[predictable]pw), while in- is 
merged with the PW of the stem ([in-possible]pw). The assimilation rule, 
then, is restricted to apply within prosodic words. 
Unlike the procedural alternative, this analysis makes no claim at all 
regarding the morpho-syntactic properties of the affixes involved: it can run 
with any (syntactic) derivational history of in- and un-. Eventual morpho-
syntactic differences between the two affixes are thus unexpected and un-
explained. It was shown earlier, however, that in- and un- also contrast on 
the morpho-syntactic side.  
It is quite obvious that the difference between the two prefixes is 
given lexically and then produces effects both on the morpho-syntactic and 
on the phonological side. A correct analysis must thus be able to do exactly 
that: derive all contrastive behaviour from a lexical property of the items at 
hand. Since phonology only interprets morpho-syntactic structure, this lexi-
cal property must produce a morpho-syntactic effect before the result can 
make a difference in phonological interpretation. That is, the key lies in 
morpho-syntax, not in phonology ± hence analyses such as the one that is 
based on contrastive translation into prosodic words do not qualify: they 
create the (PW-) contrast during the translation of morpho-syntactic struc-
ture into phonological objects, rather than simply handing down an existing 
morpho-syntactic contrast. 
The thing is that this example where a representational analysis is 
unable to do justice to morpho-syntactic facts is not just an example. It is 
indicative of the principled inability of representational solutions to say 
anything about morpho-syntax at all. That is, the translation of morpho-
syntactic structure into phonological objects is arbitrary: a basic property of 

274 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
translation is that anything can be translated into anything (more on this in 
Vol.2). By contrast, in a phase-based environment, analyses on one end of 
the pipe that relates morpho-syntax and LF/PF may also impact the other 
end. 
Therefore Newell & Scheer (2007) argue for procedural first: given a 
phonological effect that is impacted by morpho-syntactic information, and 
given competing procedural and representational solutions, always choose 
the former. The procedural analysis will make predictions on the morpho-
syntactic side and hence allow for an extra-phonological control of a pho-
nology-based analysis. There is certainly reason to believe that the strong-
est argument for analyses in a given module is the (correct) prediction that 
it makes in another module. Phonological phenomena that are not condi-
tioned by extra-phonological information cannot benefit from non-
phonological refereeing. Phonological analyses that are in a position to be 
refereed outside of phonology should try to go for this arbitral award. This 
pattern ± intermodular argumentation ± is further developed on various 
occasions in the book; a summary is provided in § 841.
321  6.4. The rule-triggering pattern (level 2 rules) 
 
322  6.4.1. Underapplication at the inner cycle 
 
The rule-triggering pattern requires underapplication to strings that are the 
result of the concatenation of a class 1 affix. In the English examples from 
nasal cluster simplification, this means that the root-final cluster must be 
reduced in [[root] class 2] (sign-ing) as well as in roots that occur in isola-
tion (i.e. [root], sign), but not in [root class 1] (si[g]nature). 
It is obvious that modification-inhibiting no look-back is perfectly 
unable to describe this kind of underapplication: inside-out interpretation 
requires that a process which affects more embedded domains (the root in 
sign-ing) also applies to higher interpretational units, i.e. the word-level in 
our case. Unless, of course, like in Halle & Vergnaud's system, the word-
level is not systematically subjected to the same (cyclic) rules as more em-
bedded interpretational units. We have seen in § 280, though, that Kaye 
rejects this option: the φ-function systematically applies to word-sized 
chunks. Hence there is no way to have the cluster simplification rule apply 
to the root of sign-ing, but not to the root of si[g]nature at the outer do-
main.  

Empirical coverage: Kaye's system and affix class-based phenomena 275 
Kaye's approach therefore seems to be structurally unable to account 
for the rule-triggering pattern. Unless, however, there is a phonology-
internal reason for the underapplication to class 1 strings. As a matter of 
fact, English nasal cluster simplification does feature such a reason: in or-
der for the clusters /mn/ and /gn/ to reduce to [m] and [n], respectively, they 
not only need to be followed by a class 2 affix ± they also need to be final. 
Indeed, morpheme-internal clusters such as in i[gn]ore and a[mn]esia re-
main unreduced (recall that this has nothing to do with derived environ-
ments since the cluster happily simplifies in non-derived environments as 
well: sign).  
Therefore the question is what the clusters need to be final of in or-
der to reduce. Morpheme-final is not a solution: the morpheme-final cluster 
of class 1 strings (si[gn]-ature) does not reduce. 
The only thing that "final" can mean is thus "string-final upon pho-
nological computation". That is, the cluster reduces iff it is the last item in 
the string that is submitted to PF. In other words, if it is domain-final (or 
phase-final, see §329). Applying this rule to Kaye's domain structure pro-
duces the correct result: [sign] and [[sign] ing2] reduce, but [sign ature1]
and [ignore] do not because their /gn/ is never string-final upon PF-
computation. 
 
323  6.4.2. Kaye's solution is like Mohanan's, but respects modularity 
 
Note that this solution follows the same spirit as Mohanan's (1986) bracket-
sensitive rules (§ 168): Mohanan's rule is sensitive to "]" where Kaye's 
process applies only to string-final elements. In both cases, the structure 
that is submitted to phonological computation contrasts in the same way: 
while sign-ature is one single domain, sign-ing has ("fresh" according to 
Mohanan) internal structure. The difference is twofold, though: 1) with 
Kaye, the contrasting domain structure is the result of a principled mecha-
nism, i.e. selective spell-out (while Mohanan has no equivalent); 2) Kaye 
does not use any untranslated morpho-syntactic objects (Mohanan's brack-
ets). 
Kaye's solution is thus unvitiated of the conceptual shortcoming that 
was pointed out in § 170: interactionism having successfully done away 
with SPE-style brackets that violate modularity, Mohanan reintroduces 
them through the back door. The information that the process really makes 
reference to is not morpheme-finality or any diacritic, but simply the fact of 
being string-final when phonological computation applies. 

276 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
The question why string-finality should cause the reduction of the 
clusters at hand is discussed in the following section. 
 
324  6.4.3. Why string-final /gN/ and /mn/ do not survive computation 
 
The question is thus why unlike other string-final clusters of the same so-
nority profile, /gN/ and /mn/ do not survive phonological computation. As 
Mohanan (1986:21ff) points out, the clusters if prism [-zm ÿ], pickle [-klÿ],
listen [-sn̩] do, with their sonorant becoming syllabic. 
All analyses must thus somehow grant a particular status to /gN/ and 
/mn/, which is also to be related to the "weak" behaviour of the voiced 
stops in /ng,mb/ (bomb-ing, see note 43). 
Whatever the reason for the weakness of the clusters that do not sur-
vive phonological computation in string-final position, it is an observa-
tional fact that they survive in presence of a vowel to their right (upon 
computation). It is thus reasonable to hold the absence of such a vowel 
responsible for their implosion. 
In Government Phonology, the relevant generalisation is expressed in 
terms of the empty nucleus that follows all consonant-final words: the do-
main-final empty nucleus in [signø] and [[signø]ing] is unable to licence 
the preceding cluster; this task requires a full nucleus. In [ignorance] and 
[sign ature], the nucleus following the cluster is contentful (to the extent 
that the -a of -ature is floating and lands in the final empty nucleus of the 
root) ± therefore the cluster survives.  
On this analysis, even the domain-final condition that Kaye (1995) 
systematically mentions is superfluous: clusters simply reduce iff followed 
by an empty nucleus upon computation. If the mention of the domain-final 
condition could be suspected to draw on a (Mohanan- or SPE-type) dia-
critic, reduction before empty nuclei is entirely unambiguous: the interac-
tionist architecture assures that the phonological process at hand makes 
only reference to truly phonological objects. 
 
325  6.4.4. Prediction: processes without additional condition cannot instantiate 
the rule-triggering pattern 
 
We have seen in § 322 that Kaye's system alone is unable to account for the 
rule-triggering pattern. It predicts that there will always be an additional 
phonological condition that has nothing to do with affix classes and re-

Empirical coverage: Kaye's system and affix class-based phenomena 277 
stricts the application of relevant processes (domain finality in the English 
case). 
This prediction is falsified by a process that follows the rule-
triggering pattern and whose phonological condition is the mere existence 
of an underlying sequence, without any additional proviso. For example, 
nasal assimilation (un-predictable vs. im-possible) could not follow the 
rule-triggering pattern since on the phonological side the bare existence of 
an /nC/ string is enough to trigger assimilation. 
 
326  6.4.5. Kaye's analysis predicts the word-final/class 2 disjunction 
 
Kaye's system makes yet a different prediction: if there is any natural kin-
ship between contexts that are defined by affix classes and the end of the 
word, only class 2 strings can line up with the word-final situation. This is 
because the root in [[root] class 2] shares with the simplex root [root] the 
fact of being domain-final (as opposed to [root class 1] where the root is 
not domain-final). 
This is the consequence of Kaye's take that class 2, rather than class 
1 affixes, trigger interpretation. Recall from § 281 that Halle & Vergnaud 
subscribe to the opposite distribution where class 1 affixes do, but class 2 
affixes do not trigger spell-out. Kaye's result also supposes that what is 
actually spelled out is not the node that dominates the affix, but the affix' 
sister (§ 282): otherwise the root would not be a domain in [[root] class 2]. 
SPE has observed that English roots in word-final position and be-
fore class 2 affixes systematically behave in the same way (see § 94): "the 
inflectional affixes which are neutral with respect to stress also characteris-
tically affect final clusters in the same way as word boundary does" 
(Chomsky & Halle 1968:85).  
What was an unexplained coincidence then now follows from selec-
tive spell-out and the two additional choices mentioned. Note that these 
were not made in order to get Chomsky & Halle's observation right: the 
English system as a whole is only consistent with this configuration. 
 
327  6.5. Conclusion 
 
In conclusion, Kaye's system affords a complete empirical coverage of affix 
class-based phenomena. A special provision, however, needs to be made 
regarding the possibility for morpho-syntactic terminals to be spelled out 

278 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
prior to being merged (§ 274). This is necessary in Kaye's system, but noth-
ing that regular spell-out provides for: only nodes can be phase heads on 
standard assumptions. It was shown in § 316, however, that the independent 
spell-out of terminals was proposed independently in syntactic analysis 
under the header of countercyclic merger (or late adjunction). 
Minimally, what Kaye's system allows, or rather: what it provokes, is 
a dialogue between phonologists and syntacticians: his system, which is 
exclusively based on phonological evidence, can only work if a specific 
operation exists in morpho-syntax. I take this kind of intermodular argu-
mentation to be a valuable touchstone for analysis on both ends of the pipe 
that was established by phase theory (more on this in § 841). 
 
328 
7. Phonological consequences of domains and their erosion 
 
329 
7.1. Empty nuclei that are string-final upon computation 
 
330  7.1.1. Final empty nuclei in Government Phonology 
 
The following pages discuss some consequences of Kaye's domain struc-
ture. One thing that domains afford is a more precise definition of the pecu-
liar status that finality confers: empty nuclei are allowed to remain empty 
when they occur in domain-, rather than in word-final position. In other 
words, the latter is a special case of the former. 
In Government Phonology, word-final consonants are onsets of 
empty nuclei in all languages (Kaye 1990a). The ban on final codas also 
extends to lexically stored items: consonant-final morphemes end in an 
empty nucleus as well.  
Empty nuclei, however, are not for free: they must have a reason to 
be empty; the conditions under which empty nuclei are tolerated are de-
fined by the Empty Category Principle (ECP, see Kaye et al. 1990:219ff, 
Vol.1:§60). Government from a following full nucleus is typically respon-
sible for the emptiness of nuclei. Word-final empty nuclei, however, cannot 
be governed since there is no governor available to their right. Rather, it is 
their final location that allows them to remain empty. This observational 
statement is the way in which Government Phonology encodes the notori-
ously deviant behaviour of the right edge of the word (e.g. Broselow 2003, 
see Vol.1:§§266, 524 for further discussion). Final empty nuclei, then, are 
governed by virtue of being final (more on this parameter in Vol.2, see also 
Scheer & Ziková forth). 

Phonological consequences of domains and their erosion 279 
Finally, note that final empty nuclei are not tolerated in all languages: 
there are languages where all words must end in a vowel. The tolerance of 
final empty nuclei is thus the matter of a parametric choice that determines 
whether or not languages can have consonant-final words (Kaye 1990a). 
 
331  7.1.2. From word-final to domain-final empty nuclei 
 
One feature that makes the right edge of the word peculiar is the occurrence 
of massive consonant clusters which are not found elsewhere, (i.e. word-
internally or word-initially). Germanic languages offer typical illustration. 
In English for example, the word sixths affords the monster cluster 
[-ksTs]#, and German is perfectly happy with [-ntkst]# in a word like 
röntgst "you do x-ray". What all final monster clusters have in common, 
however, is the fact of being heteromorphemic. Mono-morphemic word-
final sequences are severely restricted and observe ordinary sonority se-
quencing.77 
There is thus a direct relationship between morphological and phono-
logical complexity: monster clusters can exist only because they are het-
eromorphemic. It is therefore safe to conclude that the morphological divi-
sions in six-th-s are phonologically relevant. In Kaye's system, phonologi-
cal visibility of morphological information can only be due to analytic 
morphology, that is to domain structure. Six-th-s is therefore made of three 
domains: [[[six]th]s]. Since all consonant-final morphemes end in an empty 
nucleus, though, the complete structure at hand is [[[sixø]thø]sø] (Kaye 
1995:304). 
Three empty nuclei in a row would of course be ill-formed in regular 
circumstances: one is word-final and may remain empty for that reason. 
The other two, however, beg the question. On the other hand, all of them 
share the fact of being domain-final, and we know that this domain bound-
ary is responsible for the well-formedness of the cluster. The conclusion, 
then, is that being word-final is irrelevant: what really counts for empty 
nuclei is domain-finality. That is, domain-final empty nuclei may remain 
unpronounced. 
 
77 The typical Germanic licence for an extra dental set aside. Goldsmith 
(1990:140ff) and Harris (1994:66ff) provide detailed discussion of the English 
situation, Hall (1992:110) offers exhaustive facts for German (see also 
Vol.1:§350). 

280 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
332  7.1.3. The well-formedness of final empty nuclei is carried over to outer 
domains 
 
As a result, word-final monster clusters lose their exotic flavour: sixths 
[[[sixø]thø]sø] is not any more exceptional than, say, sit, which identifies as 
[sitø]. Both words possess domain-final empty nuclei whose phonetic ab-
sence is due to their domain finality. The only difference is their number: 
three in the former, one in the latter case. This, however, is irrelevant: a 
sequence of three, five, or sixteen empty nuclei in a row is well-formed as 
long as all of them are domain-final. 
This means that just like other phonological properties, the autonomy 
of domain-final empty nuclei is carried over to later cycles by virtue of 
modification-inhibiting no look-back. The final empty nucleus of the inner 
domain in [[[sixø]thø]sø] is sealed when it experiences interpretation and 
then "forgotten" in subsequent computation on outer domains: the string 
[sixøthøsø] contains three empty nuclei in a row, two of which are "invisi-
ble": they have received their phonological properties upon the interpreta-
tion that they were subject to at earlier cycles. 
In conclusion, then, there is no upper limit for the size of word-final 
clusters as far as phonology is concerned: any number of consonants in a 
row is grammatical and may happily be executed. Only morphology mar-
shals the size of clusters: it will not keep adding analytic suffixes indefi-
nitely. 
 
333  7.1.4. Computation is right-to-left: string-final nuclei are phase-initial 
 
Being domain-final means being the rightmost object of a cycle (or a phase 
in modern terms). That is, domain-final (empty) nuclei are the rightmost 
object of the string that is submitted to phonological computation. Its spe-
cial status is an observational fact, but of course we would like to know 
why the rightmost, rather than, say, the leftmost (empty) nucleus of an in-
terpretational unit is special. 
A relevant consideration here is certainly the fact that in CVCV pho-
nological computation is done from right to left: all lateral relations are 
head-final (see Vol.1:§218). For two items that are related by a lateral rela-
tion, this logically supposes to know the result of the computation of the 
head, i.e. .the rightmost item, before the target, further to the left, can be 
assessed: its value depends on the value of the head. The parsing of strings 
from right to left has also an obvious empirical basis: the overwhelming 

Phonological consequences of domains and their erosion 281 
majority of phonological processes is right-to-left, i.e. the patient is fol-
lowed by the trigger (e.g. palatalisation).  
In this perspective, the fact that the phonological value of the phase-
initial object (i.e. the first item to be computed) is determined by a paramet-
ric choice that decides whether or not it may be empty is not really surpris-
ing: in order to parse the string, phonology needs to know about the first 
item since all the rest depends on its status. This issue is further discussed 
in Vol.2 and Scheer & Ziková (forth). 
 
334 
7.2. Consequences of domain structure for stress and vowel reduction 
 
335  7.2.1. Dialectal and idiolectal variation due to variable domain structure 
 
Recall from § 271 that out of the three logically possible analytic structures, 
Kaye (1995:305f) believes that [X [Y]] does occur. The present section 
discusses two contrasts that involve the two remaining analytic configura-
tions: the compound structure [[X] [Y]] is compared to [[X] Y] on the one 
hand, and to the non-analytic configuration [X Y] on the other. 
Kaye (1995:313) considers English compounds whose second mem-
ber is -metre. Table  (133) below shows some cases in point. Primary stress 
is indicated by an acute, secondary stress by a grave accent. Vowel reduc-
tion, then, applies to vowels with no degree of stress. 
 
(133) English compounds in -metre 
[[X] [Y]] 
[X Y] 
 
 
a. no variation across British and  
American varieties 
míllimètre 
thermómetre  
b. variation between British and  
American varieties 
áltimètre 
(British) 
àltímetre 
(American) 
 
c. idiolectal variation 
kílomètre 
kilómetre 
 
Since vowel reduction (to either schwa or nothing) is entirely pre-
dictable from stress, it would certainly be ill-advised to ascribe the varia-
tion under (133b,c) to contrasting lexical recordings of the vowel quality. 
Rather, the morphological complexity that was a property of the words at 
some stage of their evolution may or may not have survived into the pre-
sent-day lexicon. The stress-assigning mechanism, then, was stable over 
time. 
In the lefthand column of  (133), the original compound structure is 
still in place, which ensures the typical compound stress pattern: primary 

282 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
stress falls on the first member, while secondary stress (and accordingly no 
vowel reduction) is observed on the second member. In the righthand col-
umn, however, primary stress is located further to the right, and there may 
or may not be a sizable secondary stress. 
The distribution of the contrast over grammatical, dialectal or idio-
lectal parameters appears to be random: sometimes it witnesses a real 
grammatical difference to which all English natives subscribe (or, at least, 
both British and American speakers): under (133a) míllimètre is necessarily 
stressed on the initial vowel, while thermómetre must not. On the other 
hand, áltimètre under (133b) identifies British pronunciation, whereas 
àltímetre is characteristic for Americans. Finally, whether an English 
speaker pronounces kílomètre or kilómetre as under (133c) is a matter of a 
personal choice, and a given speaker may probably produce variable results 
from utterance to utterance. 
 
336  7.2.2. Following SPE: "old" stress protects against vowel reduction 
 
That secondary stress protects against vowel reduction (even if only present 
on an earlier cycle, viz. the famous contrast between compensation and 
condensation) was proposed in SPE (see §§ 96f). Kaye's treatment of stress-
determined vowel reduction is a close match of the SPE analysis. 
Following SPE (see § 96), thus, Kaye (1995:313) holds that both 
parts of the word receive stress in the lefthand column of  (133) because 
they constitute a domain of their own. Therefore phonology applies to them 
in isolation, which, among other things, makes them receive stress. By con-
trast, the words in the righthand column of  (133) are parsed as one single 
chunk by the φ-function: main stress falls on the penultimate syllable. 
In all cases, unstressed vowels are reduced when the outer domain is 
computed, that is at the word level. The difference is that the original mor-
phological complexity of the items in the righthand column has become 
invisible to the phonology (the internal structure of the initial compound 
[[X] [Y]] was lost), while it is still alive in the lefthand column. Items of 
the former kind are thus recorded as one single lexical entry with the non-
analytic structure [X Y]. They are therefore not any different from mono-
morphemic objects. This kind of diachronic domain erosion is further dis-
cussed in § 339 below. 
 

Phonological consequences of domains and their erosion 283 
337  7.2.3. How to detect the difference between [[X] [Y]] and [[X] Y] 
 
Let us now turn to the contrast between the compound structure [[X] [Y]] 
and [[X] Y]. The words in the righthand column of table  (133) have been 
interpreted as non-analytic items, i.e. [X Y]. But is there any reason why 
they could not be instances of [[X] Y]? For the particular cases at hand, the 
answer is no as far as I can see: [[kilo]metre] would produce the same re-
sult kilómetre. This is because stress would be assigned to [kilo], but not to 
metre since the latter is not a domain of its own and therefore fails to be 
considered by the stress-distributing φ-function. Vowel reduction then fol-
lows as before. 
Other cases, however, allow for distinguishing [[X] [Y]] and [[X] Y]. 
A word like póstman [pɔ́wstm´n] conveys two critical pieces of informa-
tion that may be used in perception: -man is unstressed and must therefore 
have been subject to vowel reduction, and [stm] is not a possible mono-
morphemic sequence in English. The former property rules out a compound 
analysis: were -man a domain of its own, it would bear secondary stress (as 
is the case, at least in Southern British English, for súpermàn, i.e. [[su-
per] [man]]). On the other hand, the presence of [stm] disqualifies a solu-
tion with no internal structure at all: [stm] can only be [[«stø]m«]. 
In sum, then, phonological properties of the input (parsing cues, on 
which more shortly in § 340) necessarily identify póstman as [[post] man]. 
 
338  7.2.4. Chunk-specific phonologies: like SPE, Kaye provides for a specific 
word-level phonology 
 
Given his treatment of stress-defined vowel reduction that follows SPE's 
line of attack, Kaye also validates the existence of a specific word-level 
phonology. Recall from § 104 that SPE provides for a specific word-level 
phonology, i.e. a set of rules that applies only to word-sized chunks, not to 
smaller or bigger pieces.  
Word-level phonology appears as post-cyclic lexical rules in Lexical 
Phonology (or at least some versions thereof, see § 194), and as non-cyclic 
rules in Halle & Vergnaud (1987a) (see § 233). Kaye (1995) explicitly re-
jects any brand of multiple computational systems in phonology: he insists 
on the fact that the φ-function is one, i.e. accommodates all phonological 
instructions of a language without exception. It was mentioned in § 267 that 
his practice, though, seems to provide for a specific word-level phonology.  

284 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
What was meant is Kaye's treatment of stress-driven vowel reduction 
in English. The argument is exactly the same as in SPE (§ 105): vowel re-
duction cannot apply to smaller chunks because it is calculated with respect 
to the main stress of the whole word, and it cannot apply to larger pieces 
because word stress is entirely insensitive to whatever happens after the 
word level.78 
The fact that Kaye subscribes to a specific word-level phonology is 
an element in the discussion of multiple computational systems in phonol-
ogy in general, and of the contrast between morpheme-specific and chunk-
specific phonologies in particular (§§ 234, 283). While the former are spe-
cific only to Lexical Phonology (level 1 vs. level 2), the latter is practised 
by all interface theories: SPE, Lexical Phonology, Halle & Vergnaud and 
Kaye provide for a specific word-level phonology. On the other hand, Pra-
guian segregation, another chunk-specific phonology, is only practised by 
Lexical Phonology; it is rejected by all other theories. 
 
339 
7.3. Diachronic erosion of domain structure 
 
When looking at English words that represent the combination of two inde-
pendent words (nouns) which has taken place at some point in the history 
of the language, the following generalisation emerges: the older the com-
pound, the more internal structure is lost. That is, compounds start out their 
life as the compound structure [[X] [Y]]. This is when the compound is not 
yet a separate lexical entry: it is the result of online concatenation of X and 
Y, which have been extracted by two independent lexical accesses. Dia-
chronic erosion then eliminates either of the inner domains, or both. The 
regularity of this process actually affords to make predictions on the rela-
tive age of words just by looking at their phonological behaviour. 
Consider words such as blackboard, blueberry, postman, shepherd 
and cupboard. Two criteria identify bláckbòard [blǽkbç$çd] as a true com-
pound: both of its members are stressed, and the sequence [kb] is nothing 
that English allows for morpheme-internally (more on clusters that signal 
morpheme-boundaries in § 340). Hence the original domain structure 
[[black] [board]] is still alive today, and we can bet that this word is not 
very old. Its lexicalisation is witnessed, though, by the unpredictable mean-
ing: a blackboard is not just any board that is black (and this is also true for 
the other compounds discussed). 
 
78 Stress clash (thirtéen vs. thírteen men) is a different issue, see § 240, note 64. 

Phonological consequences of domains and their erosion 285 
Blueberry is pronounced [blúb´r´] in Southern British varieties, but 
comes out as [blúbE$ri] in American dialects. The latter pronunciation is the 
result of the original structure: Americans have maintained [[blue] [berry]], 
while all internal structure was erased in British English, where [blue berry] 
is executed. Or rather, we cannot be sure whether British speakers interpret 
[blue berry] or [[blue] berry] since no trans-morphemic cluster provides 
evidence. 
By contrast, we have already seen that a word like postman identifies 
as [[post] man] (rather than as [post man]) due to its medial cluster (§ 337). 
There was thus a diachronic change from [[post] [man]] to [[post] man]. 
Finally, words like shepherd [Sɛ́p´d] and cupboard [k√́b´d] (South-
ern British) signal a complete loss of internal structure: they do not bear 
any secondary stress and accordingly show vowel reduction. Crucially, 
though, they have eliminated the original trans-morphemic clusters [ph] 
and [pb], which could never be mono-morphemic in English. In other 
words, the erasure of the internal structure has provoked cluster simplifica-
tion. The words at hand have thus evolved from [[X] [Y]] to [X Y] (possi-
bly via [[X] Y], which corresponds to the pronunciations [shiiph´d] and 
[k√́pb´d], respectively). 
All words discussed share a semantic fact that is typical for com-
pounds: their meaning is non-compositional. Interestingly, the degree of 
estrangement from the original meaning may be more or less important. 
The sense of blackboard for example is fairly close to "a board that is 
black": the compound almost matches the meaning of the ingredients. The 
semantic drift is no doubt greater for blueberry and postman, since the for-
mer is not just any berry that is blue, and the latter is not just any man that 
has to do with the post. Finally, the sense of cupboard is fairly opaque if 
one were to reconstruct it from "a board that carries cups". The meaning of 
shepherd is not as opaque as the one of cupboard, but it is certainly true 
that a shepherd is not just a dog that herds sheep. 
What this means is that our phonological measure of the age of the 
words at hand could be worse: it is a fairly good match of their semantic 
distance. 
 

286 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
340 
8. Parsing cues 
 
341 
8.1. Theory-independent parsing cues: knowledge of morpheme structure 
 
We are now in a position to address parsing: how can phonology help iden-
tifying morphemes in the unstructured linear signal? Recall from § 263 that 
according to Kaye, the enhancement of parsing is one of the two reasons 
why phonology exists (the other being lexical access, to be discussed in 
§346 below). Parsing cues follow the perception-oriented logic of Trubetz-
koy's Grenzsignale (§ 55), which counts a number of modern incarnations 
(see § 264). 
When the phonological system of the perceiver runs over the linear 
string, it is able to tell whether or not a given sequence is well-formed ac-
cording to its standards. That is, a sequence is ill-formed if it does not con-
form to what the application of the φ-function would have produced. In 
other words, speakers know what a morpheme may look like, and what it 
cannot look like. Classically, this knowledge is covered by the notion of 
Morpheme Structure Rules. 
Anything that constitutes a phonological anomaly or is not compati-
ble with morpheme structure, then, alarms the parsing system: it signals the 
presence of a morpheme boundary. 
This of course supposes that a morpheme cannot accommodate just 
any sequence of sounds: in order for the system to have any turnout at all, 
some clusters that occur in the language must be absent from mono-
morphemic strings. English (and arguably all other languages) follow this 
pattern. Let us look at a few examples. 
The cluster [mz] is a possible sequence in English (it seem-s,
dream-s etc.), but does not occur within a morpheme. The same is true for 
the cluster [stm] that is found in postman (see § 334). In both cases, a mono-
morphemic parse of the string is not compatible with the phonological 
knowledge of the listener: there is no morpheme in the language that ac-
commodates the clusters at hand. Hence the parses [[seem] s] and 
[[post] man] are enforced. 
Another example is the sequence [ksTs] in the word sixths that was 
discussed in § 331. Since neither [ksT] nor [sTs] nor [sT] nor [Ts] can be 
tautomorphemic, the correct structure must be [[[ksø]Tø]sø]. Darkness and 
enlargement could not be the result of a computation over a single domain 
either since [rkn] and [rdÉZm] are not good tautomorphemic clusters. This is 

Parsing cues 287 
how the suffixes -ness and -ment are identified by pure phonology, i.e. 
without look-up in the lexicon or any morphology intervening. 
 
342 
8.2. Theory-dependent parsing cues (in English) 
 
343 
8.2.1. Empty nuclei detected by phonology 
 
What a listener interprets as an alarm signal thus depends on his phonologi-
cal knowledge: something that cannot be produced by the φ-function can-
not be mono-morphemic. Finding out about the precise properties of the φ-
function, however, is what all phonological theories attempt to do. Hence 
what counts as a parsing cue to a certain extent is theory-dependent. Below 
the theory-specific parsing flags that are flied by Standard Government 
Phonology are discussed. 
In Standard Government Phonology, a surface cluster [CC] may or 
may not be separated by an empty nucleus: it either represents a coda-onset 
sequence, a branching onset or two independent onsets, which are then 
separated by an empty nucleus. For example, [ŋk] in Czech may be a true 
or a spurious (Kaye's terminology) cluster, whose identity is only betrayed 
by its behaviour. The cluster appears unaltered when the word banka 
[baŋka] "bank NOMsg" appears in GENpl where the case marker is zero: 
bank [baŋk]. By contrast, the GENpl of linka [liŋka] "line" is linek [linɛk]: 
a vowel-zero alternation splits up the cluster, and the nasal ceases to be 
homorganic. Hence banka identifies as /baŋka/, while linka is /linøka/ un-
derlyingly. 
The detection of empty nuclei is part of the morpheme recognition 
task: in order to identify a morpheme, the listener must run it against the 
lexicon and therefore needs to correctly identify its phonological structure. 
Since part of this structure (such as certain empty nuclei) cannot be pre-
dicted from the surface, it needs to be identified by some other means. Be-
low three parsing cues are discussed that reveal the existence of empty 
nuclei in the linear string. The following section then shows how it is de-
cided whether or not these "hidden" empty nuclei are morphologically rele-
vant (i.e. whether they are domain-final or not). 
The first parsing cue is based on the take of Government Phonology 
on superheavy rhymes: they do not exist (in English or elsewhere). Kaye 
(1990a) shows that the consonant of VVC sequences is always an onset, 
even when it is word-final or followed by another consonant. Hence speak-
ers know that the only possible parse of VVCC# sequences contains two 

288 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
empty nuclei, /VVCøCø#/.79 While the word-final empty nucleus is en-
forced by Coda Licensing anyway (see § 330), its cluster-internal peer is the 
only possible parse given the ban on superheavy rhymes. 
This means, then, that a universal property of syllable structure be-
trays the existence of empty nuclei in words such as seem-ed [siimd], peep-
ed [piipt], seep-ed [siipt] and fak-ed [fejkt], whose only possible parse is 
/siimødø/, /piipøtø/, /siipøtø/ and /fejkøtø/, respectively. In each case, the 
long vowel allows only for an onset interpretation of the following conso-
nant, which in turn can only be followed by another onset consonant. 
Another claim of Standard Government Phonology is that NC clus-
ters which are adjacent at the skeletal level are homorganic. On this take, 
the homorganicity of the nasal is an automatic consequence of the Intercon-
stituent Government that it experiences as the patient of a coda-onset se-
quence. Since adjacency at the skeletal level automatically induces homor-
ganicity, non-hormorganic NC clusters cannot be coda-onset sequences.80
A listener who comes across words such as dream-s [driimz] (plural), 
seem-ed [siimd], wing-ed [wINd] ("she winged her way home"), un-clip 
[√nklIp] or un-pleasant [√nplEz´nt] thus knows that the NC cluster in-
volved is separated by an empty nucleus: /driimøzø/, /siimødø/, /wINødø/, 
/unøclip/, /unøpleasant/. 
The third phonological property that allows for the detection of 
empty nuclei concerns sonorant clusters. In English, groups where the first 
member is either r or l are fine (-rl- darling, -rn- earn, -rm- harm, -lm- 
calm, -ln- vulnerable, -lr- walrus81), while sonorant clusters beginning with 
n do not occur (*-nl-, *-nr-). According to Kaye et al. (1990:218), this re-
striction is due to the relative complexity of the segments involved: r is the 
least complex sonorant and thus a perfect governee, while n is the most 
complex object and hence the best governor. Since sequences of sonorants 
 
79 Only in case the final cluster does not qualify as a branching onset of course. 
Otherwise a /VV.TRø/ parse is possible (though not obligatory). 
80 While spurious NC clusters (/NøC/) may or may not be homorganic: in about 
the Northern half of Poland, Gienku "proper name, VOCsg" is pronounced 
[gjɛnku] (NOMsg Gienek [gjɛnɛk]), while Southern Polish speakers say 
[gjɛŋku]. The same goes for the contrast between Czech banka and linka which 
was discussed earlier in this section. In conclusion, then, non-homorganicity of-
fers a parsing cue, but homorganicity does not. 
81 The reality of -ln- and -lr- may be doubted on the basis of their rarity: only 
three instances of each cluster seem to exist (kiln, vulnerable, ulna, cavalry, 
chivalry, walrus).  

Parsing cues 289 
can only instantiate coda-onset clusters (where the onset governs the coda), 
the heavy n will never be able to be governed by the light l,r.
Knowing about this, phonology flies a flag when listeners come 
across words such as un-real or un-lawful. Since the sonorant clusters at 
hand do not qualify for either a branching onset or a coda-onset sequence, 
the only way to parse them is as independent onsets with an intervening 
empty nucleus: /unølawful/ and /unøreal/ are the output of the phonological 
filter. 
The three theory-dependent parsing cues discussed certainly do not 
exhaust the flags that Standard Government Phonology flies upon parsing. 
And of course, other theories predict other parsing cues in different situa-
tions. This is all to the good, for it makes sure that different theories make 
different predictions. And it is to be expected that all theories make predic-
tions regarding well- and ill-formed mono-morphemic clusters. 
 
344 
8.2.2. Morphological interpretation of empty nuclei 
 
Let us now turn to the morphological interpretation of the "hidden" empty 
nuclei that have been detected on phonological grounds. In Government 
Phonology (Kaye et al. 1990:219), the Empty Category Principle regulates 
the interpretation of empty nuclei. That is, nuclei may be empty iff they are 
either governed or domain-final.82 Speakers who are equipped with this 
knowledge know that items with two empty nuclei in a row are ill-formed. 
That is, [peepødø] and [dreamøzø] cannot be the correct structure for the 
input peep-ed and dream-s: the internal empty nucleus cannot be governed 
because the following nucleus is empty as well. 
Were the φ-function to interpret [peepødø], the first empty nucleus, 
escaping Government, would be vocalised. This is indeed what happens 
when wicked [wickødø] and naked [nakødø] are executed: they appear as 
[wIk´d] and [nejk´d], i.e. with a schwa (*[wIkt] and *[nEjkt] are not possi-
ble pronunciations). 
Since in peep-ed and dream-s, however, no schwa appears, the only 
way to make sense of the internal empty nucleus is to conclude that it is 
 
82 Other circumstances that allow for empty nuclei have also been proposed in 
Standard Government Phonology (Magic Licensing, Interonset Government). 
They are irrelevant here (see Vol.1:§§96,106 for discussion). 

290 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
domain-final. The only parse that is consistent with the φ-function and the 
ECP is thus [[peepø]dø] and [[dreamø]sø], respectively.83 
This, in turn, means that a morpheme boundary must separate the 
word-final cluster: domain boundaries always coincide with morpheme 
boundaries. In sum, then, a piece of morphological structure is detected on 
purely phonological grounds. 
 
345 
8.3. When phonology is useless 
 
While phonology may help unpacking the acoustic signal, it is not some-
thing that morpheme recognition can always rely on. Morphologically 
complex strings may as well pass the phonological filter without any alarm 
bell being rung. How many parsing cues are actually produced depends on 
a set of heterogeneous and language-specific factors such as the type of 
morphology, phonological inventories and morpheme structure (see 
Trubetzkoy's take on this in § 57). 
The English past tense morpheme -ed for example will produce three 
alarm signals in seem-d: the existence of a long vowel before a word-final 
cluster, the non-homorganicity of [md] and the fact that [md] is not a possi-
ble tautomorphemic sequence. Elsewhere, the cluster in seep-ed [siipt] gets 
away without arousing suspicion ([pt] is a possible tautomorphemic se-
quence: apt, adopt), but the morpheme boundary will still be detected due 
to the preceding long vowel. 
Still in other cases, however, -ed will remain undetected: since [kt] 
and [pt] are possible morpheme-internal clusters (act, adopt), lack-ed 
[lækt], pack-ed [pækt] and stepp-ed [stEpt] are undistinguishable from 
mono-morphemic items. This is also true for words such as back-s (either 
the plural of back or the third person singular of to back): [ks] is a good 
tautomorphemic sequence (wax, lax). Phonology is useless here, and mor-
pheme recognition must solely rely on regular non-phonological mecha-
nisms. 
 
83 Note that the presence of an empty nucleus in un-real [unøreal] and un-lawful 
[unølawful] (see §343 0) does not allow us to conclude that it is also domain-
final: its absence from the surface could also be due to its being governed since 
there is a valid governor to its right. Recall from § 314 that Kaye's (1995:305) 
argument in favour of the empty nucleus being also domain-final is flawed. The 
only parsing cue that is able to detect that un- is a domain of its own is the non-
assimilation of its nasal. 

Lexical access and the organisation of the lexicon 291 
346 
9. Lexical access and the organisation of the lexicon 
 
347 
9.1. Lexical entries are grouped according to phonological structure 
 
Let us now look at the second reason for the existence of phonology that 
Kaye has identified (in his teaching, but not yet in print as far as I can see): 
the fact that it provides an addressing system for the lexicon. What Kaye 
means is that phonology defines the structure of the lexicon and thereby 
organises lexical access. That is, phonology helps speakers finding lexical 
entries more efficiently and more rapidly. 
Let us first consider the former aspect. The organisation of and ac-
cess to ordinary (man-made) dictionaries depends on the spelling system 
used. A consequence of the Latin spelling for a dictionary of English for 
example is that the section "k" reduces to a small number of pages, while 
words beginning with "c" or "b" represent a substantially bigger chunk. 
Now suppose that the same dictionary is written in Arabic characters. 
While the section "b" will have the same size as before, it will be located 
elsewhere in the volume. The Latin sections "c" and "k", however, will be 
merged under one single heading (since there is only one letter for the 
sound [k]). 
Given that the spelling system matters, then, Kaye contends that 
natural language lexica use the phonological code for storing purposes. 
This means that phonologically similar words are stored next to each other: 
there will not be any difference between "k" and "c" as in English diction-
aries. Rather, everything that begins with a [k] will be stored under this 
heading, like in the Arabic version of the English dictionary. 
The rule that phonological similarity determines the organisation of 
the dictionary also extends to syllable structure: the internal structure of the 
heading [k] subdivides into different storage spaces according to whether 
[k] belongs to a simplex onset, to a branching onset or, in languages that 
allow for word-initial #kt, #pt (such as Classical Greek), to sequences of 
two independent onsets (which are separated by an empty nucleus). Finally, 
s+C clusters constitute a fourth batch of phonologically homogeneous 
words: according to Kaye (1992b), the s belongs to a coda and is preceded, 
word-initially, by an empty onset and an empty nucleus. 
 

292 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
348  9.2. Possible lexical entries are defined by phonology 
 
349 
9.2.1. How speakers decide that blick, but not lbick, is a possible word 
 
Speakers know what a possible word is in their language, and what is not. 
This knowledge is independent of any syntactic or semantic property since 
judgements may be produced upon simple exposition to nonce words. 
Therefore phonology alone must be the basis on which speakers decide 
whether something is a possible word or not. 
Since SPE, the pair blick - lbick is often quoted for the sake of illus-
tration. Both items are not actual English words. However, the former could 
be one because its initial cluster is well formed (sonority increases), while 
the latter could not: its initial cluster violates sonority sequencing. That 
sonority sequencing is a property of English grammar is shown by the dif-
ferent attitude that natives adopt in regard of the two candidate words: lbick 
is not a possible word for any speaker, while blick could enter the language 
at any time, did it acquire a meaning.84
According to Kaye, though, the speaker's decision regarding lbick is 
not achieved by performing a phonological assessment of the candidate. 
Rather, the speaker simply looks up lbick in the lexicon, and finds no 
match. By contrast, blick is an entry of the lexicon of every English native, 
if one that lacks non-phonological properties. 
 
350 
9.2.2. The full addressing space is created, including "empty" slots 
 
Kaye thus contends that the mental lexicon contains not only those items 
which are indeed used by the language (that is, which have syntactic and 
semantic properties associated to their phonological address). It also pro-
vides for "empty" entries which are only specified for their phonological 
properties. Empty entries may become real words at any time ± they just 
need to be filled in with syntactic and semantic features. 
On this view, then, universal principles and language-specific pa-
rameters allow for the precise calculation of the overall addressing space as 
soon as mature phonology is available. That is, every possible address is 
 
84 See Scheer (2007) and Vol.2 for illustration in the Slavic family where word-
initial sonorant-obstruent clusters exist, but are far from exhausting the logical 
possibilities in any individual Slavic language. The gaps are argued to be acci-
dental (hence that can be filled at any time), rather than systematic (i.e. gram-
mar-driven). 

Lexical access and the organisation of the lexicon 293 
not only imagined, it is actually created: all entries, filled and empty alike, 
are fully specified for non-predictable phonological properties.85 Empty 
addresses are ordered according to the same principle of phonological simi-
larity as their filled cousins, and may be retrieved by lexical access. 
This means that speakers are not actually "learning" new words. 
Rather, they associate syntactic and semantic properties to a lexical address 
that already exists. Also, the lexicon as such never increases: the number of 
entries is stable during the entire life of a speaker, and identical among all 
natives of the same language. 
In this perspective, the lexicon is thus a cognitive implementation of 
the notion "possible word (morpheme)", and phonology decides what a 
possible lexical address (hence a possible word/morpheme) is. 
 
351 
9.3. Phonology defines lexical access: look-up vs. compute 
 
352  9.3.1. Introduction 
 
Given that phonological information contributes to the identification of 
morpheme boundaries, how exactly are phonological parsing cues used 
when the segmented string is compared with the lexicon in order to retrieve 
the associated morpho-syntactic and semantic information? And how is 
lexical information accessed in case of inputs such as stepp-ed [stEpt] 
which do not fly any phonological flag that betrays their morphological 
complexity? 
These questions are closely related to the issue regarding the identifi-
cation of those alternations which represent actual synchronically active, 
online computed processes. Recall from § 126 that the crux of phonology 
(as opposed to syntax, see Scheer 2004b:23ff), is that all alternations ob-
served do not represent the result of a computation over a common underly-
ing form (Kaye 1995:313). 
Different theories have adopted different delineations of alternations 
that are due to online processing and alternations which are lexicalised (see 
§124). It was reported in § 276 that Government Phonology is located on 
 
85 Only infinite morpheme length would produce an infinite set of possible lexical 
entries. Many languages impose restrictions on the maximal length of mor-
phemes, and those that do not (English can accommodate verbs of virtually any 
size: to abracadabrate etc. is certainly workable) may be thought of as limiting 
the projection of the addressing space to a certain length (e.g. calculated in 
terms of the number of x-slots). Kaye does not discuss this issue. 

294 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
the far end of the spectrum where actual phonological online computation 
covers only a small subset the alternations observed. Namely, classical 
phenomena of English phonology such as irregular past tense formation 
(keep - kept), Velar Softening (electri[k] - electri[s]-ity) and Trisyllabic 
Shortening (div[aj]ne - div[I]nity) have nothing to do with phonology: they 
are not the result of any computation performed by the φ-function. Rather, 
they represent two independent lexical entries (more on this debate in 
§569). 
On this backdrop, the following pages provide a more fine-grained 
picture of what it means for two morphologically, paradigmatically or se-
mantically related items to be distinct lexical entries: if keep and kept are in 
this situation, do they have the same lexical structure as two entirely unre-
lated words such as, say, table and house? The answer is no. There is a 
sense in which keep and kept are related, but this relation is not a matter of 
computation. Rather, it involves a "lexical pointer", i.e. something that ran 
under the label of via-rules in Natural Generative Phonology. 
 
353 
9.3.2. Look-up I: related keep - kept vs. unrelated table - house 
Morphologically complex kept is indistinguishable from mono-morphemic 
items, as is evidenced by words such as adopt and apt. This is also the case 
for most irregular past tense forms: left is just like soft and rift, no phono-
logical property betrays wove (cf. clove, stove), and sang cannot be told 
from bang or fang.86 Since these items do not provide any parsing cue, the 
listener can only rely on a direct look-up in the lexicon in order to find out 
about the associated morpho-syntactic and semantic information. 
The difference between keep - kept and a pair such as table - house is 
the fact that the latter two items are not grammatically related. According to 
Kaye, this contrast is mirrored by the shape of the lexical entries at hand: 
table and house list the full set of morpho-syntactic and semantic proper-
ties, and so does the lexical entry keep. By contrast, the entry kept is empty, 
except for the information that it is the past tense form of keep. That is, the 
user who hits the entry kept remains uninformed of the morpho-syntactic 
 
86 When comparing the past tense of regular and irregular verbs, it appears that 
the former provide generous parsing cues, while the latter seem to put some ef-
fort into "hiding away": they (have) transform(ed) their body so as to be unde-
tectable by the phonological filter. Kaye (1995:310ff) further discusses this 
"conspiracy" strategy. 

Lexical access and the organisation of the lexicon 295 
and semantic features that are necessary in order to interpret this item. 
These are only listed in the entry keep, and a "pointer" in the entry kept 
indicates where they may be looked up. 
The pointer at hand does the same labour as so-called via-rules in 
Natural Generative Phonology (Hooper 1976:47f). This theory denies the 
existence of any kind of morpho-phonology (only phonetically expressed 
information may be used by phonological processes, see § 127) and hence 
considers keep and kept two separate lexical entries which, however, are 
related by a via-rule (while table and house are not). 
 
354 
9.3.3. Look-up II: phonologically similar keep - kept vs. regular suppletion 
go - went 
Let us now consider cases of regular suppletion such as go - went. Just like 
keep - kept, they entertain a grammatical relationship and hence are differ-
ent from table - house. Is keep - kept thus a case of suppletion that works in 
the same way as go - went? Kaye says no: the difference is that the mem-
bers of the former pair are phonologically related, while the members of the 
latter are not. That is, keep and kept begin with a [k] and possess a [p], 
whereas go and went do not share any phonological property. In diachronic 
terms, the former two items have contracted a derivational relationship at 
some point in the history of the language, while the latter two have never 
been derived from one another. 
Phonological relatedness, Kaye argues, plays a role when a lexical 
entry is looked up and accessed. During this process, it is loaded into short-
term (active) memory; its immediate neighbours, however, accompany this 
move. Kaye uses the metaphor of vinyl records on a shelf: when looking 
for a particular record in an unordered collection, rather than going item by 
item, one pulls out (or rather: pulled out) a batch of records that probably 
contains the target. This neighbourhood method, Kaye contends, is also 
practised in lexical access: the target entry is loaded into short-term mem-
ory together with some previous and some following items. 
Short-term memory is very efficient but costly: access to its content 
is immediate (as opposed to a lengthy look-up procedure in long-term stor-
age), but has only a small capacity. Hence keep will be in the batch that is 
loaded into short-term memory when kept is looked up: because of their 
phonological similarity and the fact that the lexical addressing system is 
based on phonological structure, keep and kept are fairly close neighbours. 
Activating the pointer in the entry of kept will lead to keep where the rele-

296 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
vant morpho-syntactic and semantic features may be retrieved. Since, how-
ever, keep is already present in the short-term memory, there is no need for 
a heavy look-up procedure: the access is immediate. 
By contrast, go will not end up in the short-term memory batch when 
went is looked up: the addresses of both items are too distant. How, then, 
are the relevant morpho-syntactic and semantic features retrieved? Kaye 
argues that in cases of true suppletion, there is no lexical pointer. Rather, 
morpho-syntactic and semantic features are repeated in both grammatically 
related entries, which also contain an explicit statement regarding their 
relationship: "past tense see the entry 'went'" for go, "present tense see the 
entry 'go'" for went.
355 
9.3.4. Computation: when parsing cues are available (peeped)
The three patterns that have been discussed thus far (table - house, keep -
kept, go - went) share the property of not offering any parsing cue. This 
complicates the retrieval of the associated morpho-syntactic and semantic 
features for keep - kept: kept is morphologically complex (other than the 
lexical meaning of keep, it possesses a past tense feature), but this complex-
ity cannot be detected by phonological means. In order to access the asso-
ciated morpho-syntactic and semantic information, a two-step procedure is 
thus necessary whereby the first lexical entry that is hit (kept) does not pro-
vide the relevant features. These are only available in the lexical entry 
(keep) that is identified by the pointer which is found in kept.
Compared to this two-step look-up procedure, things are less compli-
cated when parsing cues allow for the identification of morphemes: the 
associated morpho-syntactic and semantic information may be directly 
retrieved from the first lexical entry that is looked up. This is what Kaye 
calls identification by (phonological) computation. 
For example, the structure [[peepø]dø] is identified by phonological 
means when the input peep-ed [piipt] is submitted because there are no 
long vowels before [pt] in mono-morphemic items. Since domain bounda-
ries identify morpheme boundaries, the stem [peepø] is isolated and may be 
submitted to look-up. This leads to a match which grants direct access to 
the associated morpho-syntactic and semantic information. 
 

Lexical access and the organisation of the lexicon 297 
356 
9.3.5. How parsing is done with hidden morphology (stepped)
Finally, the fifth pattern to be considered is hidden morphology that enjoys 
a phonological exponent, e.g. stepp-ed [stɛpt]. Like for keep - kept, a stem 
and a past tense feature need to be identified; this time, however, the latter 
has an independent lexical representative (while there is no morpheme -ed 
ever identified when kept is parsed). 
Since [stɛpt] does not provide any phonological parsing cue, look-up 
of the entire item is performed, which however returns no match: there is 
no lexical entry stept. Therefore alternative parsing mechanisms need to be 
called on; these may rely on morpho-syntactic information that is available 
from other chunks of the signal, or on look-up of substrings of stept.
357  9.3.6. The four identification patterns are more or less costly 
 
The four patterns discussed correspond to four different ways of identifying 
the morpho-syntactic and semantic information that is associated to the 
morphemes in question. The pathways at hand are more or less complex, 
and hence should be more or less costly. 
The easiest way of accessing the relevant lexical information is when 
no phonological computation is performed on an item, whose look-up then 
produces immediate success: this is the case of unrelated words (table -
house) as well as of suppletive forms (go - went). In the case of kept, the 
first lexical access leads to an empty entry, which only provides a pointer. 
This pointer needs then to be followed in order for the relevant information 
to be retrieved. The parsing of peeped supposes additional phonological 
computation before look-up can be performed. Finally, the failure of pho-
nological identification of the morphologically complex stepped produces 
certainly the most complex procedure: non-phonological morpheme identi-
fication needs to be performed before look-up can be successful. 
 
358  9.3.7. Why is direct look-up not generalised? 
 
A question that is prompted by this situation is why the less costly proce-
dure, direct look-up, is not generalised. That is, why is the entire lexicon 
not organised along the lines of went?
A possible answer is the amount of storage space that would be 
needed: all grammatical forms of a root, including inflection, would have to 

298 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
be listed separately. Kaye rejects this perspective because storage capacity 
is not something that humans are short of: they can learn three, four or 
more foreign languages and accordingly mobilise three or four times more 
storage space than if they just spoke their mother tongue. As may be seen 
from result, the human brain is able to satisfy this significant demand of 
extra storage space: the learning of new words does not cause the loss of 
old recordings. 
Rather than calling on storage, Kaye hints at acquisition, which 
would be slowed down: were all grammatical forms of a word lexically 
recorded, no paradigms could be created on the grounds of a given form. 
That is, a child could not infer the third person of a verb in case the root is 
known. 
 
359 
10. Conclusion 
 
Kaye's approach to the interface combines a central contribution of Lexical 
Phonology (interactionism, § 275), Halle & Vergnaud's idea of selective 
spell-out (§ 277) and modification-inhibiting no look-back (§§ 293, 299). 
This makes his system utterly modern: today all three takes are standard in 
the interface-oriented minimalist architecture.  
Since the 60s indeed, generative theory (Generative Semantics and 
Lexical Phonology set aside) has always respected the principle "all con-
catenation before all interpretation" ± until Chomsky's derivation by phase 
has made it interactionist (§ 305). Since the 60s, either all nodes were 
spelled out (SPE), or spell-out was absent from the radar (Lexical Phonol-
ogy) ± today phase theory is based on Halle & Vergnaud's selective spell-
out (§§ 256, 763). Since Chomsky (1973), a number of no look-back devices 
have been proposed, but the modification-inhibiting no look-back that first 
appeared in the 80s (§ 293) and which is generalised by Kaye (§ 299) is en-
tirely different. Chomsky's Phase Impenetrability Condition today does the 
same thing: it "freezes" previously computed strings, which are then un-
available for further computation (§ 306). Even if the phonological ver-
sion(s) of modification-inhibiting no look-back need to be worked out (the 
phonological situation requires a weaker formulation, § 302), the general 
idea is the same. 
Of course, the fact that minimalist syntax has made the same choices 
about ten years later does not mean that they are correct. The coincidence, 
however, is quite striking, and the more so given that the modern syntactic 
literature makes no reference to phonological precedents at all (Chomsky 

Conclusion 299 
does not even quote his own 1973 article when he introduces his freezing 
no look-back). 
Kaye has not invented modification-inhibiting no look-back (§ 293), 
but he has generalised the idea, making it a property of computation as such 
(this is the case in current syntactic theory as well). Also, he introduced it 
into the analysis of affix class-based phenomena. Finally, he proposed that 
affixes do or do not trigger interpretation, but rather than the node that 
dominates the affix, the sister of the affix is spelled out (§ 282, see Scheer 
2008c). This gives Halle & Vergnaud's selective spell-out an entirely new 
face, one that coincides with modern phase theory (or rather, modern phase 
theory coincides with Kaye's system) where the edge of the phase also de-
fines the sister of the head X° (i.e. the complement) as the string that is sent 
to interpretation (more on this in § 765). 
Like Halle & Vergnaud, Kaye promotes the restoration of SPE. This 
is true for example regarding the resident issue of multiple computational 
systems. The take of SPE is that there is a specific word-level phonology, 
but no morpheme-specific or sentence-specific phonology (Praguian segre-
gation). Halle & Vergnaud and Kaye hold the same position.  
Regarding affix classes, Kaye's system is unlike others in two impor-
tant respects. For one thing, class 2 affixes (rather than class 1 affixes as 
with Halle & Vergnaud) trigger interpretation (§ 281). On the other hand, as 
was mentioned, the driving force of affix class-based phenomena is a no 
look-back device: no other approach achieves underapplication by this 
means (§ 279). 
On the empirical side, Kaye's system offers a fairly good coverage of 
English affix class-based phenomena. When compared to Lexical Phonol-
ogy and Halle & Vergnaud, it appears to be a step ahead. This is true con-
ceptually regarding the former, where the rule-triggering pattern is ac-
counted for at the expense of reintroducing untranslated morpho-syntactic 
objects (Mohanan's brackets) that were blessedly eliminated by interaction-
ism (§ 170). On the empirical side, Kaye's system fares better than Halle & 
Vergnaud's, who cannot account for the rule-triggering pattern at all (§ 250). 
A concern is the syntactic viability of Kaye's claim that terminals can 
be spelled out independently (§ 274). The syntactic echo of this prediction is 
discussed in § 316. 
Kaye's domain structure (phase structure in modern terms) follows 
the general idea that some morpho-syntactic boundaries are visible in pho-
nology, while others are not. The former are phase heads, the latter are not. 
Beyond the morpho-syntactic footprint that domain structure represents in 

300 
Chap 9: Kaye (1995), selective spell-out and freezing no look-back 
phonology, its role as a lexical element, and hence in diachronic evolution, 
was discussed (erosion of domain structure, § 328). 
Kaye's approach to the interface as a whole is perception-oriented 
and hence functionalist: according to him, domain structure (and phonology 
as such) exist in order to provide parsing cues that enhance morpheme 
identification (§ 340). Another function of phonology is to provide an ad-
dressing space in the lexicon, which organises lexical access (§ 346).  
 

Chapter 10 
360  Prosodic Phonology: on the representational side 
361  1. Overview: autosegmentalised boundaries and fresh data 
 
Prosodic Phonology has been developed some 30 years ago and today 
stands still unchallenged87 as the (representational) phonological interface 
theory. After the advent of Optimality Theory, Prosodic Phonology has 
been translated into the new constraint-based environment, but this move 
did not modify its basic tenets and mechanisms: in OT, the interface with 
morpho-syntax is as much managed through prosodic constituency as it 
was before (see § 455). 
As we will see below, Prosodic Phonology carries over the interface 
architecture of SPE into the autosegmental environment of the 80s. The 
only true evolution concerns the units that carry morpho-syntactic informa-
tion: local boundaries are replaced by autosegmental domains (the Prosodic 
Hierarchy). Also, SPE concepts are sometimes borrowed without reference. 
This view on the matter is not quite what the early Prosodic Phonol-
ogy literature offers:88 the new theory is advertised as an antithesis of SPE. 
In some cases, counterfactual statements are even made in order to show 
that the new theory is radically different. For instance, Nespor & Vogel 
(1986:37) write that "in traditional generative theory it was supposed that 
these [morpho-syntactic] domains directly correspond to syntactic constitu-
ents (see Chomsky & Halle, 1968)" (more on this in § 385). 
The pages below thus show that the genuine contribution to interface 
theory made by Prosodic Phonology is the autosegmentalisation of the car-
riers of morpho-syntactic information: instead of boundaries, prosodic do-
mains are inserted into phonological representations. I argue that this de-
velopment was a result of the general autosegmentalisation that has af-
fected all areas of phonology in the late 70s and early 80s: the Prosodic 
Hierarchy is the specific implementation of autosegmentalism in the realm 
 
87 Or almost: some voices in Distributed Morphology quarters revive the direct 
syntax approach and hence do away with the Prosodic Hierarchy: Pak (2008), 
Samuels (2009a:239ff), see § 580. 
88 In the later literature (since about 1986), SPE is not a reference anymore. Nes-
por & Vogel (1986) for example take prosodic constituency for granted without 
discussion of the transition with SPE. 

302 
Chap 10: Prosodic Phonology, on the representational side 
of the interface (see § 368). It represents a major historical break: bounda-
ries have always been the interface currency since the 19th century. 
The difference between boundaries and domains is their local vs. 
non-local character. That is, a morpheme cannot belong to a boundary (as it 
can belong to a prosodic constituent), and it does not make sense to talk 
about a prosodic constituent that intervenes between two morphemes 
(while a boundary always separates items in the linear string). As far as I 
can see, the relative merits of local and non-local intervention have never 
been discussed (§366). Rather, the few occasions in the early Prosodic 
Phonology literature on which the competition with boundaries is ad-
dressed dismiss them on the grounds of their diacritic character. It was 
taken for granted, then, that unlike boundaries, the Prosodic Hierarchy is 
not a diacritic. This tacit assumption, however, does not stand up to fact: 
the Prosodic Hierarchy is just as much a diacritic as SPE-type boundaries, 
if an autosegmental one (§ 402). 
Later in the book it is argued that representational communication 
with phonology must not be through diacritics (§ 692) ± but it needs to be 
local (§ 706). What is required, thus, is some kind of non-diacritic bounda-
ries. That this is not a contradiction in terms is shown in Vol.2 and Scheer 
(2008a, 2009a,c). 
 
On the credits side, Prosodic Phonology can certainly claim the fact 
that it has made translation systematic and consensual. Recall that the frus-
tration of the late 70s has prompted calls from different quarters in favour 
of direct reference to morpho-syntactic categories (§ 131). Prosodic Pho-
nology has fought out this issue in the mid 80s (see § 407 below). As a re-
sult, the need for a Translator's Office where morpho-syntactic information 
is transformed into the phonological idiom has become the backbone of 
representational interface theory (Indirect Reference). 
A curious aspect of this evolution is that it was made on the grounds 
of an argument that turns out to be vacuous upon inspection: non-
isomorphism supposes that domains are taken for granted ± if the same 
reality is looked at through the prism of boundaries, non-isomorphism 
evaporates (§ 416). On the other hand, Prosodic Phonology has never called 
on modularity, the reason that makes Indirect Reference really indispensa-
ble (§ 410). This is strange indeed since the development of Prosodic Pho-
nology and Fodorian modularity was contemporary in the 80s. 
On the empirical side, Prosodic Phonology has aroused an important 
activity, to which phonologists owe a great amount of fresh and detailed 
descriptions, namely regarding the interface with syntax. Like other theo-

The roots of Prosodic Phonology 303 
ries, however, Prosodic Phonology could not elucidate the mapping puzzle 
(see § 111). The new empirical wealth has rather added to the tessellate 
character of the picture (§§ 387, 392f, 396). 
 
Prosodic Phonology is certainly the most influential interface theory 
of the past 40 years. Its resounding success may be measured when realis-
ing that up to the present day there is hardly any phonological theory that 
does without the Prosodic Hierarchy. Also, prosodic categories have ceased 
to engage phonologists theoretically: the prosodic word and its peers have 
become descriptive categories, much in the way syllabic vocabulary such 
as onset and coda is used when informally talking about languages. 
As is obvious from this overview, Prosodic Phonology is entirely de-
voted to the representational side of the communication between morpho-
syntax and phonology. It does not make any claim as to whether there is a 
procedural management, or how it could work. In actual fact, the question 
is eluded. By default, a peaceful cohabitation with Lexical Phonology, the 
dominant contemporary procedural theory, was engaged. However, Selkirk 
(1984) and Inkelas (1990) have pointed out that both theories actually 
compete below the word level. The relationship between Prosodic Phonol-
ogy and Lexical Phonology (which continues to be an issue in OT, see 
§488) is discussed in § 423. 
The following pages thus address the issues mentioned and try not to 
lose track of the general picture. 
 
362 
2. The roots of Prosodic Phonology 
 
363 
2.1. Selkirk adapts Liberman & Prince's strong/weak arboreal structure 
 
The earliest ancestors of Prosodic Phonology are commonly taken to be 
Liberman (1975) and Liberman & Prince (1977). The central idea of these 
authors is that segments are dominated by a multi-layered arboreal structure 
(syllables, feet and words) which expresses rhythmic (linguistically "musi-
cal") properties of the linear string and assign relative prominence (strong 
vs. weak status) to individual chunks. 
Based on this line of thought, Elisabeth Selkirk developed the first 
model of Prosodic Phonology: she fertilised the autosegmental arboreal 
idea for the interface of phonology with other modules, something that was 
not originally intended by Liberman & Prince (1977). 

304 
Chap 10: Prosodic Phonology, on the representational side 
In Selkirk's early work (Selkirk 1978, 1980a,b, 1981 [1978], 1981) 
and especially in the ground-laying article Selkirk (1981 [1978]),89 the six-
layer Prosodic Hierarchy which is still in place today was introduced: the 
syllable, the foot, the phonological word, the phonological phrase, the into-
national phrase and the phonological utterance. 
Selkirk's proposals were influential, and mainstream phonology rap-
idly integrated them as a major contribution to the general expansion of the 
autosegmental idea. Her 1984 book (Selkirk 1984), though, which was 
advertised in all of her articles since 1978, finally took a different turn un-
der the influence of Prince's (1983) grid-only approach: autosegmental 
prosodic constituency was evacuated altogether in favour of the metrical 
grid (more on this in § 426). 
Nevertheless, Selkrik (1984) is a landmark of early Prosodic Phonol-
ogy, also because it assures a bridging function between the linear SPE 
environment and the new autosegmental interface ± an aspect that is dis-
cussed at length in § 369. Finally, two years later, Selkirk (1986) returns to 
prosodic constituency, now arguing for a "peaceful coexistence" of the 
original Prosodic Hierarchy and the metrical grid (thus following Liberman 
& Prince 1977 and Nespor & Vogel 1982:226, 1986, see § 427). 
 
364 
2.2. A second strand that became mainstream: Nespor & Vogel 
 
Building on Selkirk's work but mobilising fresh data from languages such 
as Italian and Greek, Marina Nespor and Irene Vogel have grounded a par-
allel stream of inquiry: after an exploratory period (Nespor & Vogel 1979, 
1982, 1983, Napoli & Nespor 1979, Nespor 1985, 1986, Vogel 1982, 1985, 
1986), their 1986 book (Nespor & Vogel 1986) concentrates the insights 
gained. It rapidly became the authoritative reference in Prosodic Phonol-
ogy, and indeed the standard theory of how morpho-syntax communicates 
with phonology. 
Other authors that have contributed to the early period which pre-
pared Selkirk (1984) and Nespor & Vogel (1986) include Hayes (1989 
 
89 This article is commonly quoted as Selkirk (1978), hence as the oldest ancestor 
of Prosodic Phonology. Since chronology sometimes matters below, I add this 
date in square brackets. The content of this article was first presented at an Am-
herst conference in 1978; a manuscript almost identical to the 1981 publication 
was then circulated at least since 1980. The first published version, however, is 
the text that appeared in the proceedings of the Nordic Prosody conference in 
1981. 

From boundaries to domains: a historical choice gone almost unnoticed 305 
[1984]), Booij (1983, 1985a,b, 1986), Neijt (1985), Dell (1986), Itô (1986), 
Gvozdanović (1986). Namely Hayes (1989 [1984]) was influential.90 
The framework that emerged in Hayes (1989 [1984]) and Nespor & 
Vogel (1986), as well as in the strand represented by Selkirk (1984), stands 
unchallenged today (but see note 87). Almost thirty years have gone by 
without any substantial modification of its basic tenets. A fair means to 
judge the impressive success of Prosodic Phonology is the fact that its 
genuine units ± the foot, the phonological word, the phonological phrase, 
the intonational phrase and the phonological utterance ± have started out as 
theoretical constructions but today are common descriptive categories. 
Thus just like for syllables, there may be different opinions on how exactly 
a phonological word is built and what it encompasses, but its existence is 
beyond doubt: there is an arboreal structure above the syllable that encodes 
morpho-syntactic information. 
 
90 This article was circulated as a manuscript since 1984, but only published in 
1989. For this reason, it does not mention Nespor & Vogel (1986), but is re-
ferred to for example in Selkirk (1986). 
365 
3. From boundaries to domains: a historical choice that has gone 
almost unnoticed 
 
366 
3.1. Boundaries are diacritic and local 
 
Since the 19th century, morpho-syntactic influence on phonological proc-
esses has always been conceived in terms of boundaries. Vocabulary may 
have varied according to the period and the theory, but the way information 
is transmitted through the representational channel remained stable over 
neogrammarian analysis, structuralism (Trubetzkoy's Grenzsignale, junc-
ture phonemes) and SPE (boundaries): the carrier is diacritic and local. 
Boundaries are local because they define the relationship between 
two adjacent morphemes or words. This is the fundamental property that 
makes them different from domains, which are non-local by definition: they 
span a number of elements of the linear string, thereby creating labelled 
clusters. That is, an individual element of the linear string belongs to a do-
main, but it cannot belong to a boundary. On the other hand, a boundary is 
precisely located in the linear string and can influence only adjacent ob-
jects: the one immediately preceding and the one immediately following. It 
does not make sense to talk about domains that intervene, or are located 

306 
Chap 10: Prosodic Phonology, on the representational side 
between two elements of the linear string. Domains, by definition, are non-
local, while the essence of boundaries is to be local. 
The locality of intervention is well incarnated by the traditional no-
tion of sandhi: sandhi phenomena occur at the break of two morphemes or 
words, and are triggered (or uninhibited) by this division. 
Boundaries are also diacritic: when it comes to give them a material 
identity, arbitrary symbols are chosen. The diacritic character of boundaries 
is recognised in the literature, and its undesirable consequences are pointed 
out: see §§ 69f (structuralists), §§ 119, 133 (generativists), also Scheer 
(2009a,c), Vol.1 §§84,87 (discussion of the phonological identity of the 
beginning of the word). 
It is argued below that the true difference between boundaries and 
prosodic domains is their local vs. non-local action, rather than their 
(non-)diacritic character. The scarce Prosodic Phonology literature that 
talks about the transition from boundaries to domains at all, however, has 
never disentangled the local and the diacritic issue: the latter was pin-
pointed, while the former went unnoticed. There can be no doubt that we 
need to do away with diacritics ± but this does not mean that locality has to 
go as well. This is the whole point of Direct Interface (see Vol.2, Scheer 
2008a, 2009a,c): to find a means of making representational intervention 
local and non-diacritic. 
 
367  3.2. The elimination of boundaries in Lexical Phonology remained 
unreflected in Prosodic Phonology 
 
Lexical Phonology is relevant for the debate regarding the competition 
between boundaries and domains insofar as it has its own ways of eliminat-
ing the former. Recall from § 162 that the existence of procedurally ordered 
lexical strata makes boundaries toothless. Lexical Phonology pinpoints the 
redundancy of boundaries given the stratal environment, but does not pro-
duce any positive argument against them. Boundaries are just useless be-
cause the procedural mechanism does the labour and, according to Lexical 
Phonology, does it better since it is independently motivated (e.g. Mohanan 
1982:94ff). 
As far as I can see, the fate of boundaries in Lexical Phonology ± and 
hence the argument with the procedural side of the interface ± is entirely 
absent from the Prosodic Phonology literature. This ties in with the tor-
mented (non-)relationship between Lexical Phonology and Prosodic Pho-

From boundaries to domains: a historical choice gone almost unnoticed 307 
nology: § 423 discusses the peaceful coexistence that was officially pro-
claimed, as well as the backstage conflict. 
In the small body of early works that is discussed below, Prosodic 
Phonology has thus started the discussion of boundaries anew. This time, 
boundaries are not a competitor of serially ordered lexical strata, but of 
autosegmental domains. Unlike in the Lexical Phonology literature, this 
debate produced some concern for boundaries as such and for their proper-
ties. 
 
368 
3.3. Prosodic Phonology is a child of autosegmentalism 
 
When reading through the Prosodic Phonology literature, the almost com-
plete absence of reference to work from before the 80s (structuralist and 
generative alike) is quite striking. 
The only exceptions are a few early articles by Elisabeth Selkirk, two 
articles by Geert Booij (1983, 1985a) (on which more shortly), and most 
notably Selkirk's 1984 book, which assumes a pivotal role between SPE 
and Prosodic Phonology. Let us start by having a closer look at how Selkirk 
(1984) explains the transition from boundaries to domains. 
Selkirk has worked on the interface since the early 70s, mainly on 
the grounds of French liaison (Selkirk 1972, 1974). During that period, her 
work was couched in the SPE framework, thus using boundaries. Living 
through the advent of autosegmentalism, it seemed clear to her that the 
interface with morpho-syntax needs to join the move: a situation where all 
areas of phonology (syllable structure, stress, internal structure of seg-
ments) except its upper interface are progressively autosegmentalised 
would have been strange. The quote below shows that Selkirk clearly iden-
tifies the elsewhere winning arboreal approach as the motor for the intro-
duction of domains. 
 

308 
Chap 10: Prosodic Phonology, on the representational side 
(134) "The syllables of phonological representation are arranged in some kind of 
hierarchical organization. [«] By 'hierarchical organization' we mean, very 
roughly speaking, the organization of the units of phonological analysis into 
layers, vertically arranged on the same plane. [«] This conception of pho-
nological representation as having its own hierarchical structure(s) demands 
a radical rethinking of the relation between syntax and phonology. [«] Thus 
the interpretation question ± the question of the mapping between phono-
logical representation and syntactic representation ± takes on a much greater 
importance than in the standard theory, and has an entirely different quality 
to it. It must be viewed as a characterization of the relation between the 
syntactic hierarchy, on the one hand, and the phonological hierarchy (or 
hierarchies), on the other." Selkirk (1984:7f) 
 
Therefore, 
 
(135) "the junctural properties of sentences should be somehow represented 'su-
prasegmentally' rather than as the segmental boundaries of the standard 
theory. [«] Thus the theory of phonological representation that we will 
advocate here eliminates segmental boundary elements altogether." Selkirk 
(1984:8) 
 
This is how the domain enters the scene: the idea that morpho-
syntactic structure defines the domain of application of phonological rules 
had already been voiced early on in the linear environment, namely by 
McCawley (1968) (see § 113). Selkirk now calls on this perspective: do-
mains are non-local by definition, and they have an obvious autosegmental 
identity in terms of arboreal structure. 
 
369  3.4. The (non-)discussion of boundaries in Prosodic Phonology 
 
370  3.4.1. Boundaries were not an issue anymore for Nespor & Vogel (1986) 
 
Selkirk's (1984:7f) description of the transition from boundaries to domains 
is precious since the historical break at hand has remained by and large 
unreflected in the Prosodic Phonology literature. This is witnessed, among 
other things, by the fact that prosodic domains were taken for granted with-
out discussion in Nespor & Vogel (1986), the book that is considered the 
central reference of Prosodic Phonology. In the very first sentence of their 
book indeed, Nespor & Vogel merely state their disagreement with the lin-
ear SPE system that uses boundaries. They then go on talking about domain 
theory without making any argument regarding the transition. 

From boundaries to domains: a historical choice gone almost unnoticed 309 
(136) "In early generative theory, phonology was characterized by a linear organi-
zation of segments and a set of phonological rules whose domains of appli-
cation were implicitly defined in terms of the boundaries of the surface 
morpho-syntactic constituent structure. [«] It is our contention that this 
view of phonology is fundamentally inadequate. [«] The subsystem [of 
phonology] we will be concerned with in the present study is the prosodic 
subsystem, and in particular, the theory of domains." Nespor & Vogel 
(1986:1) 
 
Hence in 1986 boundaries are not considered a serious competitor 
anymore: they are a mere vestige of an earlier theory which today is over-
come. In the remainder of the book, boundaries are only occasionally men-
tioned: once on page five where their inadequacy is said to follow from 
non-isomorphism, and another time on page 35s. 
 
371  3.4.2. Looking for anti-boundary arguments 
 
Since the transition from boundaries to domains is a fundamental break in 
phonological culture, I have read through the early Prosodic Phonology 
literature (that is, until 1986) in order to find out whether this critical issue 
was discussed at all. 
The relevant literature falls into three categories: most of the time the 
issue regarding boundaries is not mentioned at all; sometimes boundaries 
are declared inadequate without argument but referring to other articles; 
finally, arguments against boundaries are made in less than a handful of 
articles. 
Selkirk (1978), Nespor & Vogel (1979), Nespor (1985, 1986), Vogel 
(1985, 1986), Gvozdanović (1986), Neijt (1985), Booij (1985b, 1986), Dell 
(1986) and Itô (1986) fall into the first category. Reference to articles that 
are supposed to contain anti-boundary arguments is made in Nespor & Vo-
gel (1982:226) (to Napoli & Nespor 1979 and Clements 1978), Selkirk 
(1980b:580) (to Selkirk 1981 [1978], 1984), Hayes (1989 [1984]:203) (to 
Selkirk 1980a) and Selkirk (1986:376) (to Selkirk 1980a and Rotenberg 
1978). 
Most of the target articles, however, contain no argument against 
boundaries at all. This is the case of Napoli & Nespor (1979), Selkirk (1981 
[1978]) and Selkirk (1984) (see § 368). Among the references quoted, only 
Selkirk (1980a) and Rotenberg (1978) really argue against boundaries. This 
is also the case of some sources that are not mentioned: Hayes (1989 

310 
Chap 10: Prosodic Phonology, on the representational side 
[1984]), Booij (1985a) and the aforementioned occasion in Nespor & Vogel 
(1986:35f). 
Let us first look at those references which are supposed to offer ar-
guments against boundaries, but in fact do not. 
 
372 
3.4.3. References that do not contain any argument against boundaries 
 
Napoli & Nespor (1979:818ff) talk about boundaries only when they re-
view an argument made by Selkirk (1972). Their goal is to show that pho-
nological rules can only make reference to surface-, not to deep syntactic 
structure. Working on French liaison, Selkirk (1972) has collected evidence 
to the end that a possible liaison between two phonetically adjacent words 
is blocked if a trace intervenes. On her analysis, movement has taken away 
the lexical item, but left its boundaries in place. Liaison, then, is computed 
on the grounds of the total number of boundaries that occur between the 
two words, including those that originate in the trace. Napoli & Nespor 
(1979:818ff) show that in a parallel situation regarding Raddoppiamento 
Sintattico in Italian, traces are irrelevant. This discussion is also reflected at 
greater length in Nespor & Vogel (1986:48ff), where the authors defend the 
position that phonetically absent syntactic constituents can never influence 
phonological processes. 
The issue at hand is thus quite independent from boundaries as an in-
terface currency: an argument is made against the phonological incidence 
of phonetically absent objects, not against boundaries as such. Nothing is 
said about which type of carrier should be chosen in order to represent 
morpho-syntactic information in phonology. Referring to this article with 
the promise to find arguments against boundaries is misleading at best. 
The case of Clements (1978) is parallel. True, this author admits that 
his previous analysis of Ewe (Kwa, West Africa) which used "tone group 
boundaries" is unwarranted because "a set of boundary-insertion conven-
tions unmotivated in the phonology of other languages" is required in order 
to describe the tonal alternations in external sandhi situation (p.22). But 
Clements then develops an alternative analysis that does away with tone 
group boundaries in favour of phonological rules whose structural descrip-
tion makes direct reference to syntactic constituents. Again, there is no 
argument against boundaries as such in this article, nor is it in any way 
Clements' intent to eliminate boundaries from phonological theory. It is 
only suggested that for the particular data set at hand an analysis without 

From boundaries to domains: a historical choice gone almost unnoticed 311 
boundaries fares better. This analysis then follows the lines of direct syntax 
(§ 136), which is at odds with Prosodic Phonology (§ 407). 
Selkirk (1981 [1978]) does not contain any argument against 
boundaries either: after having introduced the six layers of the Prosodic 
Hierarchy, the author simply says in the conclusion that if prosodic con-
stituency is accepted, boundaries are superfluous. 
 
(137) "Once prosodic categories form part of the phonological representation, the 
motivation for boundaries (cf. SPE, Selkirk (1972)) as part of a phonologi-
cal representation disappears. Boundaries are none other than an encoding in 
the string of segments (the standard generative representation) of the higher 
order prosodic structure organizing that string. At one time thought of as the 
appropriate formal mechanism for delimiting domains of application of 
phonological rules, boundaries are rendered otiose by the introduction of 
prosodic structure into phonological representation and, in particular, the 
inclusion of prosodic categories which effectively designate those domains. 
Looking at it in a different light, we can think of the focus being taken away
from boundaries, which were originally viewed as markers of juncture be-
tween syllables and other prosodic units, and being put on the prosodic units 
themselves." Selkirk (1981 [1978]:136ff) 
 
Booij (1983) makes the same point. 
 
(138) "In the theory of prosodic phonology, grammatical boundaries can be dis-
pensed with in phonological representations." Booij (1983:268) 
 
No doubt Selkirk and Booij are right ± but this does not tell us why 
boundaries should be replaced by domains in the first place, or in which 
way domains are superior. Declaring the existence of domains ex cathedra 
is not making an argument. Rather, Selkirk (1981 [1978]) and Booij (1983) 
follow the line of reasoning that is adopted later on by Selkirk (1984) (see 
§368): the general trend towards autosegmentalism imposes autosegmental 
structure for the interface as well; since boundaries are not autosegmental 
but local, they do not qualify. 
Finally, Nespor & Vogel (1986:35f) try to make an argument against 
boundaries on the grounds of a rule in Modern Greek. They show that in 
certain circumstances, the nasal of a nasal-obstruent sequence assimilates to 
the obstruent in place, while the obstruent, if voiceless, becomes voiced. 
The process at hand applies across morpheme boundaries as well as be-
tween a negative element and a verb, and between an article and a noun. It 
is blocked, however, between an auxiliary and a verb. Nespor & Vogel say 
that a solution using boundaries would have to place a morpheme boundary 

312 
Chap 10: Prosodic Phonology, on the representational side 
between articles/negative elements and nouns/verbs. This, however, the 
argument goes, is syntactically unwarranted since the division between 
words cannot be a morpheme boundary. 
This argument is not conclusive: there are no morpheme boundaries 
between words indeed ± but a solution using boundaries does not need to 
assume that there are any. All theories need to somehow group morpho-
syntactic divisions into a triggering and a blocking family. It is perfectly 
regular to see that morphological and syntactic boundaries are distributed 
over both of these groups. Hence there is no point in talking about mor-
pheme boundaries between words; morpheme boundaries just happen to 
produce the same effect as some word-level boundaries.91
373 
3.4.4. The diacritic argument 
 
Unlike in the references mentioned in the previous section, boundaries are 
really under fire in Rotenberg (1978), Selkirk (1980a), Booij (1983, 1985a) 
and Szpyra (1989). The point made by these authors concerns the diacritic 
character of boundaries.92 
In a chapter called Against Boundaries (that was already quoted in 
§136), Rotenberg (1978:16ff) makes a convincing argument against 
boundaries: phonology interprets phonological objects (just like syntax 
syntactic objects), not bananas or pink panthers (see also Pyle 1972 on this 
issue, as reported in § 136). This is a surprisingly modern reasoning: it looks 
at the interface from the modular perspective, which was little developed 
by the time Rotenberg wrote. That is, a module can only parse and under-
stand vocabulary that belongs to its own idiom. This idea is called domain 
 
91 Kaisse (1985:109ff) also argues against boundaries. Instead of replacing them 
by prosodic domains, however, she proposes to have their labour done by direct 
reference to syntactic categories (see §407 0). Her argument relies on the maxi-
mal number of different boundaries that SPE and Selkirk (1972, 1974) allow 
for, i.e. three. She presents Greek evidence which, according to her analysis, 
requires four different boundaries. Hence the argument does not concern 
boundaries as such; rather, a particular implementation thereof is at issue. 
92 It is noteworthy that linear diacritics have also been proposed in Prosodic Pho-
nology: after having constructed the metrical grid through regular mapping 
rules, Selkirk (1984:314) argues for "Silent Demibeat Addition" at morpheme- 
and word-intersections. Phonological rules, then, make reference to the overall 
grid structure. Selkirk (1986:376) admits that these silent demibeats are dia-
critic boundaries in a different guise. 

From boundaries to domains: a historical choice gone almost unnoticed 313 
specificity (see § 610). Its application enforces translation from morpho-
syntactic into phonological categories (§ 649), an issue that lies at the heart 
of Prosodic Phonology (Indirect Reference, see §§ 377, 406). 
It is thus certainly correct to call on Rotenberg as a voice against 
boundaries ± but not in order to promote the domain-based alternative. 
Rotenberg tells us nothing at all about the comparative merits of boundaries 
and domains. 
The case of Selkirk (1980a:126ff) is similar: she reviews the argu-
ments made by Pyle (1972) regarding the overgeneration that boundaries 
introduce. Boundaries indeed allow for the formulation of outlandish rules 
that lie outside of what natural language can do for sure. The reason again 
is their diacritic character: unlike true linguistic objects, arbitrary symbols 
have arbitrary effects.93
Szpyra (1989:11, 182f) and Booij (1983:268f, 1985a) fall into the 
same category as Rotenberg (1978) and Selkirk (1980a). In his conclusion, 
Booij (1985a:34) writes that the theory of Prosodic Phonology "excludes 
the rather arbitrary use of boundaries made possible in the SPE-framework" 
(see § 393 for further discussion of Booij 1985a). 
 
Selkirk (1980a) also considers a competitor that is more serious than just 
simple boundaries: McCawley's (1968) idea that boundaries define the 
domain of rule application, and that different boundary strengths determine 
different domains (see § 113). Obviously, this is the direct translation of 
autosegmental domains into linear vocabulary ± or rather, the new auto-
segmental perspective is the translation of McCawley's (1968) proposal. If 
both are just notational variants, the new Prosodic Hierarchy is in trouble. 
At this point, Selkirk says that 
 
(139) "the relations among boundaries that are captured in the strength hierarchy 
must be stipulated in the theory. They do not follow from anything inherent 
to the notion of boundary in the theory." Selkirk (1980a:128) 
 
This is certainly true ± but does the layering of prosodic constituents 
follow from anything in the theory of domains? Prosodic constituents exist 
 
93 The diacritic-overgeneration issue is usually brought up when the historical 
evolution from boundaries to prosodic constituency is described in more recent 
(overview) literature, e.g. Inkelas & Zec (1995:537f). The question whether 
prosodic constituency also overgenerates, however, is not addressed on these 
occasions. It is shown in § 402 below that the Prosodic Hierarchy is as much a 
diacritic as SPE-type boundaries. 

314 
Chap 10: Prosodic Phonology, on the representational side 
because the related facts exist, and their size adapts to whatever is found 
out there. Hence just as much as boundary strength, domains merely record 
what happens. 
Finally, Hayes (1989 [1984]:203ff) makes a similar point. He argues 
that boundary-based theories need two independent stipulations in order to 
cover the facts: 1) if a phonological rule can apply across one kind of 
boundary, it can also apply across all "weaker" boundaries; 2) if a rule ap-
plies before or after one kind of boundary, then it also applies before or 
after all "stronger" boundaries. Domain-based theories, on the other hand, 
need only one stipulation for the same job, i.e. the Strict Layer Hypothesis 
(see § 383 below). 
This argument does not take account of the non-monolithic character 
of the Strict Layer Hypothesis, which is pointed out for example by Inkelas 
(1990), Itô & Mester (2003 [1992]) and Ladd (1986, 1996). Selkirk (1996) 
herself admits that the Strict Layer Hypothesis is but a cover term for a 
heterogeneous set of four primitive component constraints. Hence Hayes' 
argument may well turn out to be counter-productive if four constraints are 
needed in order to capture the generalisations that are handled by two prin-
ciples in boundary theory. 
 
In sum, the diacritic character of boundaries is certainly a serious argument 
against them: the fact that diacritics do not qualify is an important lesson of 
the historical survey that is provided in § 692. Everybody is certainly called 
to look for a way to encode extra-phonological information in a non-
diacritic fashion, and domains are the solution proposed in the early 80s. 
Strangely enough, though, at no point does the Prosodic Phonology 
literature consider the eventuality that prosodic constituents are also dia-
critic. It is shown in § 402 below that the Prosodic Hierarchy indeed is a 
diacritic, if an autosegmental one (also Scheer 2008a). 
If this is true, we have nothing gained in the transition from bounda-
ries to domains. And we are still left with the pending question of local vs. 
non-local intervention. Recall from §366 that this contrast is what I take to 
really distinguish boundaries and domains ± precisely because they may not 
be told apart on the grounds of the diacritic issue. Only is the local vs. non-
local aspect never discussed in the literature when it comes to compare the 
two competitors. 
Since the eventually diacritic character of the Prosodic Hierarchy is 
not discussed any more than the local vs. non-local perspective, boundaries 
could be disqualified by simply pointing out their diacritic character. This is 

From boundaries to domains: a historical choice gone almost unnoticed 315 
exactly what happened. Or, in other words, the local baby was thrown out 
with the diacritic bathwater (more on this in § 706). 
 
374 
3.4.5. Domains have an independent motivation: stress, rhythm and 
musical properties 
 
Selkirk (1980a:126ff, 1984:8ff) certainly levels the most serious argument 
against boundaries. She argues that since Liberman (1975) and Liberman & 
Prince (1977) domains are independently motivated by stress, rhythm and 
musical aspects of speech. Boundaries, on the other hand, are unable to 
encode these properties. The former thus allow for a unified coverage of 
both interface information and stress/rhythm/musical aspects, while the 
latter multiplies representational devices. 
Let us first address stress and its associated prosodic category. For 
one thing, it is not the case that Liberman & Prince (1977) (or any of their 
followers for that matter) offer a uniform representation of stress: they 
build a tree based on weak/strong oppositions, but then from this arboreal 
structure derive the metrical grid, which is responsible for stress clash 
(thirtéen vs. thírteen men). Also, the unifying perspective holds only if 
arboreal structure is indeed the correct way of representing stress. This, 
however, cannot be taken for granted: Prince's (1983) grid-only approach 
competes with feet for the representation of stress. Still another option is 
explored by Szigetvári & Scheer (2005) who develop unified representa-
tions for the syllable and stress which are lateral, rather than arboreal or 
grid-based. 
Finally, it may not be a correct move to grant identical representa-
tions to things that are different in kind. Stress is a domestic property of 
phonology that, unlike those phonological phenomena for which prosodic 
domains are needed, owes nothing to extra-phonological information. Were 
there no interface, feet would still exist, while the five higher levels of the 
Prosodic Hierarchy would not. Just like syllables, feet are a bottom-up con-
struction and not, like higher prosodic categories, objects that are created 
by top-down mapping. In other words, the Prosodic Hierarchy is a blend of 
heterogeneous phonological objects, rather than a homogeneous arboreal 
representation. This is pointed out by Rice (1990:292 note 3) and is actu-
ally admitted by Nespor & Vogel (1986:109) (see § 401). 
In this light, then, it is worth wondering whether ontologically dis-
tinct categories should be represented by identical devices. Inkelas (1990) 
for example says no: it is not right to have properly prosodic constituency 

316 
Chap 10: Prosodic Phonology, on the representational side 
only from the word level on ± the Prosodic Hierarchy ought to be extended 
to smaller units (hence the title of her dissertation "Prosodic Constituency 
in the Lexicon", see § 433). 
Let us now have a look at rhythm and musical properties of speech. 
Since Hayes (1984), rhythm is regarded as an emanation of metrical poetry 
and music, rather than of the linguistic system. Hayes (1984:65) writes that 
"grids are not strictly speaking a linguistic representation at all" and con-
cludes on page 69 that rhythm on the one hand and linguistic structure such 
as stress or the Prosodic Hierarchy on the other belong to separate cognitive 
domains. Nespor (1988:228) adds that rhythm "is, in fact, not properly a 
phenomenon of language, but rather of all temporally organized events." 
If rhythm is not a linguistic object, then, linguistic theory must not 
attempt at representing it. This view was followed by all subsequent work 
including Nespor & Vogel (1986, 1989:87f) and Selkirk (1986): rhythmic 
structure materialises as the metrical grid, which is produced by a secon-
dary mapping that takes the Prosodic Hierarchy as an input (more on this in 
§427). It thus appears that the unification argument involves properties 
which according to subsequent work must not be unified. 
 
375  3.4.6. The idea of unified representations was abandoned by Selkirk herself 
 
The unification argument was abandoned in later work by Selkirk, who 
reverted to distinct representations for stress and rhythm on the one hand, 
and morpho-syntactic information on the other. 
In her early work, Selkirk promoted two different means of melting 
domestic phonological properties and interface information. Before her 
1984 book, the allround representations were autosegmental and arboreal. 
Selkirk (1984), however, gives up prosodic constituency in favour of 
Prince's (1983) grid-only approach: among the prosodic constituents that 
were assumed before, only the intonational phrase survives.94 The function 
of all other layers is taken over by the metrical grid (Selkirk 1984:29ff). 
Two years later, Selkirk (1986:376) joins Nespor & Vogel's (1986) 
perspective according to which three types of representations and distinct 
computational mechanisms live in peaceful coexistence above the syllable: 
prosodic constituency, the metrical grid (which is responsible for stress and 
rhythm) and Lexical Phonology (see § 427). In such a landscape, the unifi-
 
94 Selkirk (1984:27f) holds that intonation is an emanation of semantics alone 
("sense unit") which lacks any syntactic conditioning (see also §425 0). 

From boundaries to domains: a historical choice gone almost unnoticed 317 
cational argument is lost: it is tacitly admitted that domestic (stress, 
rhythm) and non-domestic phonological information (morpho-syntactic 
conditions on phonological processes) is different in kind and should not be 
encoded in a single set of representations. 
 
376 
3.4.7. Summary 
 
The arguments that have been levelled against boundaries reduce to two 
items: their diacritic character and the absence of independent motivation. 
Discussion of the transition from boundaries to domains is scarce, and there 
has never been any pro-boundary party that would have responded to the 
critiques, or compared the putative gain when domains are used. 
The replacement of boundaries by domains is a major break in the 
history of interface theory. Rather than by the two arguments mentioned, it 
was motivated by the general trend towards autosegmental structure that 
was ambient in the late 70s and early 80s. In this context, the transmission 
of morpho-syntactic information could not stand back: "the junctural prop-
erties of sentences should be somehow represented 'suprasegmentally' 
rather than as the segmental boundaries of the standard theory", as Selkirk 
(1984:8) explains. 
The diacritic argument is certainly valid: diacritics do not qualify. 
However, it was taken for granted without discussion that the alternative, 
the Prosodic Hierarchy, is not a diacritic. § 402 shows that it is: diacritic 
boundaries were replaced by diacritic domains, and nothing was gained on 
this count. 
The other argument may have been an issue in the early days when 
prosodic constituency and the metrical grid were mutually exclusive (Sel-
kirk's work until 1984). It has disappeared when Prosodic Phonology ad-
mitted the peaceful coexistence of both types of representation (Selkirk 
1986, Nespor & Vogel 1986). 
Finally, an important property of boundaries has gone entirely unno-
ticed: unlike domains, boundaries have a local action. This issue is further 
discussed in § 706 below. 
 

318 
Chap 10: Prosodic Phonology, on the representational side 
377 
4. The heart of Prosodic Phonology: Indirect Reference and its 
consequences 
 
378 
4.1. Introduction 
 
The following pages introduce Prosodic Phonology from the inside: its 
founding statement (Indirect Reference), the consequences thereof (the 
Translator's Office, mapping rules, the Prosodic Hierarchy), and how the 
various devices interact technically. 
The principle of Indirect Reference holds that morpho-syntactic 
categories are invisible to the phonology: phonological processes cannot 
make direct reference to them. Rather, morpho-syntactic structure needs to 
be translated into phonological vocabulary, the Prosodic Hierarchy, to 
which phonological processes may then appeal. 
Indirect Reference is present since the earliest incarnations of Pro-
sodic Phonology, and germane to all of its versions. Theories that disagree 
with it are called direct syntax approaches (on which more in §407). 
If it is true that phonology has no direct access to morpho-syntactic 
structure, higher level information needs to be transformed into items that 
are part of the phonological world. This translation is done by so-called 
mapping rules, whose input is the morpho-syntactic structure (and also 
what I call the black box, on which more below). They return the Prosodic 
Hierarchy, which lies inside the phonological module. 
I call this output the buffer because its only purpose is to take stock 
of morpho-syntactic information, and to restore its load inside the phonol-
ogy. The buffer is therefore the instrument of Indirect Reference: phono-
logical rules that are sensitive to morpho-syntactic information make refer-
ence to the buffer, rather than to morpho-syntactic categories themselves. 
What the buffer is made of and how exactly translation works are 
secondary questions.95 What is important to understand for the time being 
 
95 The latter is discussed in the following section and in § 387. Regarding the 
former, the content of the buffer indeed is not pre-empted by the overall archi-
tecture of Prosodic Phonology. Even though arboreal structure in general and 
Selkirk's (1981 [1978]) prosodic categories in particular have rapidly become 
the only kind of buffer used, other implementations are possible. Selkirk (1984) 
for instance abandons all arboreal prosodic structure except the intonational 
phrase. Instead, following Prince's (1983) grid-only approach, she holds that 
the content of the buffer is the metrical grid. That is, mapping rules produce 
units of the grid or modify existing grid structure; phonological rules then make 
reference to the grid. 

The heart of Prosodic Phonology: Indirect Reference and its consequences 319 
is that the existence of the buffer is the heart of Prosodic Phonology ± and 
that the buffer is the consequence of Indirect Reference. 
 
379 
4.2. The buffer, its construction workers and how it unloads its goods 
 
380  4.2.1. Mapping rules and the black box 
 
Table  (140) below shows the place of the buffer in the overall architecture 
of Prosodic Phonology. 
 
(140) the general architecture of Prosodic Phonology 
 
Morpho-Syntax 
 
Interface 
 
mapping rules 
 
?
Black Box 
 
Phonology 
 
the buffer: 
prosodic constituency 
x x x x x x x x x x x x x x x
phonological rules that are 
sensitive to morpho-
syntactic information make 
reference to the buffer 

320 
Chap 10: Prosodic Phonology, on the representational side 
The buffer is created by mapping rules, which do their job on the 
grounds of two sets of information: the output of morpho-syntax and what I 
call the Black Box. The existence of the Black Box is critical for Prosodic 
Phonology: it is the consequence of so-called non-isomorphism, the (only) 
argument that grounds Indirect Reference (and hence the buffer). 
Non-isomorphism is discussed at length in §§ 416ff: following SPE, 
Prosodic Phonology holds that the domains to which phonological rules 
make reference sometimes do not match any morpho-syntactic division: 
phonologically relevant and morpho-syntactic domains may be non-
isomorphic. Thus the output of morpho-syntax sometimes is not ready for 
phonological use. It therefore needs to be modified according to phonologi-
cal demands (in SPE, this job was done by the so-called readjustment com-
ponent, see § 91). 
Mapping rules transform morpho-syntactic structure into prosodic 
constituency, which is legible by phonological rules. However, they do not 
simply replicate morpho-syntactic structure in a different (prosodic) vo-
cabulary. On the one hand, not all properties of morpho-syntactic structure 
are phonologically relevant. Mapping rules therefore impoverish the mor-
pho-syntactic output. On the other hand, non-isomorphism enforces the 
rearrangement, eventually the augmentation of morpho-syntactic structure. 
Mapping rules thus work on the output of morpho-syntax, but also 
make sovereign readjustment decisions ± it is the latter that I call the Black 
Box. This label expresses the mystery that continues to be associated with 
readjustment decisions up to the present day: linguists have a poor under-
standing of the particular groupings of morpho-syntactic units that is rele-
vant for the phonology. This issue was referred to as the mapping puzzle 
above (§ 111); it is further discussed in §§ 387, 392f, 396. 
 
381  4.2.2. Mapping is done in modular no man's land 
 
In a modular perspective, mapping and the Black Box cannot be located 
either in morpho-syntax or in phonology. Mapping rules have access to 
both morpho-syntactic and phonological structure: they can read the for-
mer, and create part of the latter (the Prosodic Hierarchy). Since modules 
do not understand the language of other modules, the interface is necessar-
ily located in modular no man's land, i.e. somewhere after morpho-syntax 
and before phonology. This is indicated under  (140), but deserves to be 
made explicit (see § 413). 

The heart of Prosodic Phonology: Indirect Reference and its consequences 321 
The development of modular theory in the early 80s (Fodor 1983) 
was contemporary to Prosodic Phonology. Quite surprisingly, then, the 
Prosodic Phonology literature does not mention the modular issue and the 
fact that the architecture of Prosodic Phonology is a faithful implementa-
tion of modular principles (see § 414). 
Although Nespor & Vogel (1986) are not explicit on the location of 
the mapping activity throughout their book, their final diagram on page 302 
places mapping rules both outside of morpho-syntax and outside of pho-
nology, thereby confirming their neutral status. 
382  4.2.3. The layers of the Prosodic Hierarchy 
 
Since Selkirk (1981 [1978]) and up to the present day, the units of the Pro-
sodic Hierarchy have been remarkably stable. Table  (141) below shows 
Selkirk's initial inventory. 
 
(141) the Prosodic Hierarchy according to Selkirk (1981 [1978]) 
 
phonological utterance (U) 
sentence 
 
| 
 
 
intonational phrase (IP) 
intonational chunk 
 
| 
 
 
phonological phrase (φ)
NP, VP, AP 
 
| 
 
 
phonological word (ω)
word 
 
| 
 
 
foot (Σ)
|
syllable (σ)
Variation concerns the number and label of prosodic constituents: the 
phonological word is sometimes called prosodic word, and additional lay-
ers that have been proposed are moras and the clitic group (intermediate 
between the prosodic word and the prosodic phrase). 96 
As may be seen, the Prosodic Hierarchy parallels the relevant mor-
pho-syntactically defined chunks of the linear string: the phonological ut-
 
96 The clitic group, proposed by Hayes (1989 [1984]) and Nespor & Vogel (1986), 
was challenged early on (e.g. Inkelas 1990, Zec 1993, Booij 1995, 1996, 
Monachesi 1996, Peperkamp 1996), and today has quite consistently disappea-
red from the inventory of prosodic constituents. 

322 
Chap 10: Prosodic Phonology, on the representational side 
terance roughly corresponds to one (or several) sentences, the phonological 
phrase is about of the size of an XP, and the prosodic word encompasses a 
regular word. No direct equivalents may be quoted for the intonational 
phrase, feet and syllables, but they are also inserted in the hierarchy accord-
ing to their size. 
What exactly belongs to a specific prosodic constituent is subject to 
language-specific variation: a prosodic word for example may or may not 
include prefixes, and compounds may or may not count as one prosodic 
word. These choices are managed by mapping rules, which convert mor-
pho-syntactic into prosodic structure. Their parameterisation is discussed at 
greater length in § 388 below. 
 
383  4.2.4. Geometric properties of the Prosodic Hierarchy: the Strict Layer 
Hypothesis 
 
The Prosodic Hierarchy is a fairly unconstrained arboreal structure, compa-
rable to feature geometric trees below the segmental level. That is, restric-
tions on branching of the X-bar kind do not apply. A prosodic tree may host 
nodes that do not branch or that branch two, three or more times. Under 
 (142) below appears an example of a fully prosodified English sentence 
taken from Hayes (1990:86).97 
(142) complete prosodification of an English sentence 
 
U 
 
IP 
IP 
 
| 
 
 
 
 
 
 
 
 
φ
φ
φ
|
|
C
C
C
C
ω
ω
ω
ω
ω
ω
ω
ω
ω
|
|
|
|
|
|
|
|
|
On 
Wednesday, he
told 
the 
stories
to 
the 
children 
 
97 Note that the prosodification does not include the two lowermost layers of the 
Prosodic Hierarchy, syllables and feet. This is because they are bottom-up con-
structions to which mapping rules do not contribute anything (see § 401). Ab-
breviations: U (phonological utterance), IP (intonational phrase), φ (phonologi-
cal phrase), C (clitic group, see note 96), ω (phonological word). 

The heart of Prosodic Phonology: Indirect Reference and its consequences 323 
The only well-formedness condition on prosodic constituency is laid 
down in the Strict Layer Hypothesis (SLH), which was originally formu-
lated by Selkirk (1981) (the label Strict Layer Hypothesis only appears in 
Selkirk 1984:26f).98 It expresses the idea that a prosodic constituent of a 
given layer only dominates constituents of the immediately lower level, and 
is exhaustively contained in a constituent of the immediately higher level. 
Hence an IP for example is always the daughter of an U, and only domi-
nates φs. 
In the environment of OT, Selkirk (1996:189ff) has factored out the 
SLH into four more primitive component constraints, which appear under 
 (143) below (more on this in § 461). 
 
(143) the Strict Layer Hypothesis cut into pieces 
 
a. Layeredness 
a node of layer n can only dominate a node of layer n+1, and can only 
be dominated by a node of layer n-1. 
 
b. Headedness 
each node of layer n must dominate at least one unit of layer n-1. 
 
c. Exhaustivity 
association lines may not bypass any layer: no association of two units 
that belong to non-adjacent layers is allowed. 
 
d. Nonrecursivity 
nested structures are prohibited: no node may dominate a node of the 
same label. 
 
Selkirk (1996) believes that (143a,b) are universal (undominated in 
terms of OT), while (143c,d) may or may not be observed by languages. 
Finally, it is noteworthy that a by-product of the SLH is non-
privativity in the sense of § 79 (see also §400 and the summary in § 756): all 
strings are exhaustively parsed at all prosodic levels independently of 
whether there is any associated phonological effect or not (Hayes 1989 
[1984]:220, 1990:86, Nespor & Vogel 1986:11). That is, the full prosodic 
arborescence is always constructed, and all expressions in all languages 
have the same number of levels of embedding. 
 
98 Literature on the SLH abounds; it includes Nespor & Vogel (1986:7ff), Itô & 
Mester (2003 [1992]) and Selkirk (1996). 

324 
Chap 10: Prosodic Phonology, on the representational side 
384  4.2.5. Three ways of making reference to the Prosodic Hierarchy 
 
Finally, let us look at how morpho-syntactic information is restored in the 
phonology. The structural description of phonological rules may make ref-
erence to the Prosodic Hierarchy in three different ways (Selkirk 
1980a:111f, Vogel 1985, Nespor & Vogel 1986:77). The three types of rules 
are identified under  (144) below. 
 
(144) rule types in Prosodic Phonology 
 
a. domain span rule 
 
 
b. domain juncture rule 
 
 
c. domain limit rule 
 
 
A domain span rule applies in a certain segmental environment iff 
this environment is contained within a given domain. Domain juncture 
rules apply when some part of the segmental string needs to be adjacent to 
a boundary that separates two items of the same prosodic unit. For exam-
ple, English aspiration has been said to occur "foot-initially" (e.g. Nespor & 
Vogel 1986:90ff). As indicated by their name, domain juncture rules en-
dorse the function of regular linear boundaries: a specific morpho-syntactic 
division is targeted. 
Finally, domain limit rules apply when certain segmental conditions 
are met, but only at the beginning and at the end of a given unit of the pro-
sodic constituency. 
 
385 
4.3. The old and the new: mapping rules and Indirect Reference 
 
When looking at the evolution of generative interface theory, it appears that 
all properties of the Prosodic Phonology architecture have been formulated 
by Chomsky & Halle (1968). In SPE, mapping is done by a fixed algorithm 
that transforms morpho-syntactic structure into clusters of boundaries (see 
§90). This job is done by mapping rules in Prosodic Phonology. The read-
justment rules of SPE (see also Langendoen 1975) appear as the Black Box 
under  (140). 
Also, the idea that phonology does not make direct reference to the 
output of the syntactic component originates in SPE. The following quota-
tion is repeated from § 82 for convenience (see also Dresher's 1996:41ff 
overview article on this heritage). 
 

The heart of Prosodic Phonology: Indirect Reference and its consequences 325 
(145) "We have two concepts of surface structure: input to the phonological com-
ponent and output of the syntactic component. It is an empirical question 
whether these two concepts coincide. In fact, they do coincide to a very 
significant degree, but there are also certain discrepancies. These discrepan-
cies [«] indicate that the grammar must contain certain rules converting the 
surface structures generated by the syntactic component into a form appro-
priate for use by the phonological component. In particular, if a linguistic 
expression reaches a certain level of complexity, it will be divided into suc-
cessive parts that we will call 'phonological phrases', each of which is a 
maximal domain for phonological processes. [«] 
It appears that the syntactic component of the grammar generates a surface 
structure Σ which is converted, by readjustment rules that mark phonologi-
cal phrases and delete structure, to a still more superficial structure Σ'. The 
latter then enters the phonological component of the grammar." Chomsky & 
Halle (1968:9f) 
 
Of course it is true that Indirect Reference is more than just SPE-
readjustment, which in the Prosodic Phonology architecture corresponds to 
the Black Box. Indirect Reference bans phonological rules that make direct 
reference to morpho-syntactic structure and labels ± this kind of rule was 
common practice in SPE (see § 95). As will be shown below (§ 410), Indi-
rect Reference is thus a real progress from the modular point of view. This 
being said, the Prosodic Phonology literature often tries to insulate the new 
perspective from SPE so radically that wrong or incomplete statements are 
made. For example, I was unable to find any reference in the Prosodic Pho-
nology literature that establishes the heritage relation between the read-
justment rules of SPE and Indirect Reference. Readjustment rules are 
sometimes mentioned (regularly in the work by Selkirk), but never as the 
ancestor of Indirect Reference.99 
Worse, SPE is sometimes presented as a system where only direct 
reference to morpho-syntactic structure is made. 
 
(146) "According to SPE, phonological rules apply to the linear surface structure 
of a sentence, that is, to the output of the syntactic rules." Nespor & Vogel 
(1982:225) 
 
99 Significantly, this connection is made explicit by an opponent of Prosodic Pho-
nology: arguing for the direct syntax approach (see §407 0), Kaisse (1985:110 
note 1) asks whether "the rules building up metrical structure are or are not sig-
nificantly different from readjustment rules." 

326 
Chap 10: Prosodic Phonology, on the representational side 
 
"In traditional generative theory it was supposed that these [morpho-
syntactic] domains directly correspond to syntactic constituents (see Chom-
sky & Halle, 1968)." Nespor & Vogel (1986:37) 
 
"In an SPE-type model of phonology, the only way of representing the do-
mains of a phonological rule is in terms of morphosyntactic constituents, the 
implicit claim being that such constituents are, in fact, the only domains in 
which phonological rules may apply." Vogel (1986:59) 
 
In the first two quotes, Nespor & Vogel forget to mention the fact 
that there was translation in SPE: morpho-syntactic surface structure was 
transformed into phonological boundaries (§ 90). This translational process 
is exactly equivalent to mapping, except that the output categories are dif-
ferent: boundaries in SPE, prosodic domains in Prosodic Phonology. Vo-
gel's (1986) statement is simply counterfactual: she seems to have over-
looked the existence of readjustment in SPE. 
 
386  5. Mapping: its mechanics, its evolution and our understanding thereof 
 
387  5.1. Introduction: the mapping puzzle (again) 
 
How exactly does the mapping mechanism work? Is it possible to establish 
cross-linguistic generalisations that tell us which portions of the morpho-
syntactic structure are phonologically relevant, and which ones are not? 
This aspect of the interface ± the mapping puzzle ± is certainly the 
most poorly understood of all. For one thing, as Kaisse & Zwicky (1987) 
put it, 
 
(147) "the study of postlexical rules sensitive to syntactic or prosodic structure is 
still in its infancy. Phonologists know comparatively little about the range of 
phenomena that can be encompassed by such rules, compared for instance 
with what is known about word-internal phonological processes or rules of 
syntax. At the moment theories must be advanced on the basis of data that 
are, from the language-internal point of view, rich and complex, but are 
also, from the cross-linguistic point of view, sparse and diverse." Kaisse & 
Zwicky (1987:4) 
 
Odden (1987) and Ladd (1986:311) make the same observation. But 
also, the data that linguists are aware of seem to project a picture of relative 
anarchy: it was noted in §§ 111f, 379, 388ff (see also the summary of the 
mapping puzzle in § 753) that the morpho-syntactic contexts which trigger 

Mapping: its mechanics, its evolution and our understanding thereof 327 
or block phonological processes on many occasions do not make sense 
(morpho-syntactically speaking). 
In many cases the only thing that linguists are able to do is to write 
down an amorphous list of triggering and blocking boundaries. The practice 
of Prosodic Phonology, then, is to equate the size of the chunks that are 
delineated by blocking boundaries to some level of the prosodic constitu-
ency. In the next step, a mapping rule is written that specifies which parts 
of the morpho-syntactic structure are grouped together in order to build the 
phonologically relevant chunk of the linear string. This chunk is then called 
a unit of the Prosodic Hierarchy (e.g. a phonological phrase). The mapping 
job, thus, amounts to boundary grouping. 
Why a mapping rule groups this or that chunk of the linear string 
rather than others remains unanswered in most cases. In actual fact, the 
literature hardly asks the question in the first place. Nobody knows whether 
the mapping mechanism is restricted in any principled way, or according to 
which rationale mapping decisions are made. 
Another aspect of the mapping puzzle is the fact that cross-linguistic 
generalisations do not appear to emerge. The evolution of mapping from 
the earliest sources of Prosodic Phonology up to the present day has pro-
gressively made allowance for a highly variable empirical picture. That is, 
the mapping literature went through an evolution from firm universal 
statements with little or no tolerance for parametric variation to the recog-
nition of a bewildering variety of language-specific situations. 
Quite frustratingly, the availability of more and more data seems to 
make the overall picture mistier and mistier, instead of clearing it up. The 
above quote from Kaisse & Zwicky (1987:4) provides good testimony of 
this situation. 
The following pages attempt to document this evolution, that is both 
aspects of the mapping puzzle that were mentioned: the growing parametric 
variation that goes hand in hand with the absence of cross-linguistic gener-
alisations, and (the absence of) a morpho-syntactic rationale that governs 
mapping decisions. 
The former issue is addressed in § 388, the latter is discussed in § 394. 
To round off the discussion of mapping, § 398 discusses the observation that 
phonology may react on geometric properties of morpho-syntactic struc-
ture, but not on its labels. 
 

328 
Chap 10: Prosodic Phonology, on the representational side 
388  5.2. Mapping and its inflational evolution 
 
389  5.2.1. Early mapping in Selkirk's work until her 1984 book 
 
Recall from § 90 that SPE did mapping on the grounds of a universal algo-
rithm that does not admit any parametric variation: #s are inserted at both 
edges of major categories as well as of XPs, before the entire string is 
shipped off to the phonology. By convention, clusters of hashmarks are 
then reduced to a maximum of two. 
In Selkirk's first article, the genesis of the phonological word is not 
addressed (Selkirk 1981 [1978]:124f). The phonological phrase is con-
structed according to the following instructions, which Selkirk believes to 
be the "major principles". 
 
(148) "The Phonological Phrase: Constituency 
 
(i) 
An item which is the specifier of a syntactic phrase joins with the 
head of the phrase. 
 
(ii) An item belonging to a "non-lexical" category (cf. Chomsky 1965), 
such as Det, Prep, Verbaux, Conjunction, joins with its sister constitu-
ent." 
 
Selkirk (1981 [1978]:126) 
 
Two years later, Selkirk (1980b:580) still writes that "the conception 
of mapping between syntax and phonology is an eminently simple one." 
Nespor & Vogel (1982) make the following statement. 
 
(149) "[W]e propose a series of mapping conventions for Italian which we will 
then argue are sufficiently general to be able to account for any X-bar type 
language once the values of certain syntactic parameters have been as-
signed." Nespor & Vogel (1982:227) 
 
In her 1984 book (where the buffer is made of metrical grids, rather 
than prosodic constituents, see § 426), Selkirk proposes that mapping boils 
down to four universal classes of rules: 
 
(150) "The theory of metrical grid construction has two major components. The 
first is a set of text-to-grid alignment (TGA) rules. Through these rules, the 
particular properties of the text may impose requirements on the rhythmic 
realization of the sentence. [«] Quite certainly, one of the major descriptive 
tasks for a metrical grid theory of stress is to characterize the TGA rules 
available to language. As we will show, it seems that these rules fall into 
just four classes." (Selkrik 1984:54) 

Mapping: its mechanics, its evolution and our understanding thereof 329 
Some of these four classes enclose further possible parameters (see 
note 92). Hence the realm of the mapping system has already expanded 
quite significantly when compared to Selkirk's first article. 
 
390  5.2.2. Parametric variation of ω and φ in Nespor & Vogel (1986) 
 
Let us now look at the variation regarding the construction of the phono-
logical word and the phonological phrase that Nespor & Vogel (1986) ini-
tially provide for (see also Nespor & Vogel 1983:124f, as well as the varia-
tion acknowledged by Hayes 1989 [1984]:206ff and Gvozdanović
1986:40ff). 
According to their typology (p.117ff), phonological words may be 
coextensive with the constituent dominated by the terminal node of the 
morpho-syntactic tree, i.e. encompass the stem and all affixes as well as all 
elements of compounds. According to Nespor & Vogel's analysis, this is the 
case in Latin and Modern Greek. 
Another option for the phonological word is to not exactly mirror 
morpho-syntactic structure. In this case, two groupings are observed: the 
phonological word may be formed by the stem and all affixes, while com-
pounds represent two separate units: stem one with all prefixes, and stem 
two with all suffixes (Sanskrit, Turkish). The alternative grouping is as 
before, except that in compounds the prefixes of stem one form a separate 
domain (Hungarian). 
The cross-linguistic variation that Nespor & Vogel provide for is thus 
threefold as far as the phonological word is concerned. It is expressed by 
language-specific mapping rules which decide, for each level of the Pro-
sodic Hierarchy, which units of the morpho-syntactic input are grouped 
together. 
As a general measure, Nespor & Vogel (1986:5) argue that the degree 
of universality is proportional to the rank in the Prosodic Hierarchy: cross-
linguistic variation is most important for the phonological word (mapping 
rules do not intervene in the definition of syllables and feet, which are bot-
tom-up constructions, see § 401) and decreases as we move up in the pro-
sodic tree: the phrasing of the phonological utterance, then, is almost uni-
versal. 

330 
Chap 10: Prosodic Phonology, on the representational side 
Accordingly, the variation that Nespor & Vogel (1986) have found 
for the phonological phrase is as follows.100 
(151) "Phonological Phrase Formation 
 
I. 
φ domain 
 
The domain of φ consists of a C which contains a lexical head (x) and 
all Cs on its nonrecursive side up to the C that contains another head of 
the maximal projection of X. 
 
II. φ construction 
Join into an n-ary branching φ all Cs included in a string delimited by 
the definition of the domain of φ." 
 
Nespor & Vogel (1986:168) 
 
391  5.2.3. More variation for the phonological phrase 
 
Subsequent studies have shown, however, that there is much more cross-
linguistic variation than that. Cho (1990) for example considers a phono-
logical process in Korean whereby obstruents voice in intervocalic position 
depending on the type of adjacent boundary.101 He has found the following 
triggering and blocking environments (Cho 1990:48ff). 
 
(152) in Korean, an underlying word-initial plain voiceless obstruent that occurs 
after a vowel-final word 
 
is voiced in the context 
remains voiceless in the context 
 
determiner - noun 
adjective - noun 
possessive noun - noun 
 
(John's book) 
verb of a relative clause - noun 
object - verb 
verb - verb 
subject - verb 
subject - object 
object - object 
conjunction - noun 
topic-NP - S' 
 
(apples, they throw away) 
subject - sentential adjective 
subject - sentential adverb 
On these grounds (and also considering additional data that do not 
need to be reproduced here), Cho concludes that the mapping rule under 
 
100 "C" refers to the clitic group, i.e. the prosodic layer immediately below the 
phonological phrase in Nespor & Vogel's system (see note 96). 
101 Korean has three contrastive sets of obstruents, so-called plain, aspirated and 
tense. Only the former undergoes the process at hand. 

Mapping: its mechanics, its evolution and our understanding thereof 331 
(153) below is needed in order to correctly phrase the morpho-syntactic 
output. 
 
(153) mapping rule for phonological phrases in Korean (Cho 1990:57) 
 
apply the following rules cyclically to all maximal projections, proceeding 
from the bottom up. At any given stage (a) applies before (b). Let the 
maximal projection under consideration on a given cycle be M. 
 
a. if M branches, combine the head of M into a phonological phrase with 
all adjacent unphrased material, up to and including the closest XP, or 
if no such phrase is present, the left edge of M. 
 
b. phrase any focused word with the next word, unless that word is al-
ready phrased. 
 
After (a) and (b) have applied in all possible environments, (c) applies. 
 
c. unphrased words form phonological phrases of their own. 
 
The mapping operation for phonological phrases in Korean is thus 
clearly more complicated than what was foreseen in the early days of Pro-
sodic Phonology. 
 
392  5.2.4. Cross-linguistic atomisation of mapping 
 
Detailed studies of the mapping mechanism in other languages have pro-
duced similar results: the variational space is atomised, and every language 
seems to have its own idiosyncratic way of grouping morpho-syntactic 
divisions into prosodic constituents. 
Examples are Neijt (1985, Dutch), Cowper & Rice (1987, Mende), 
Vogel (1988, Hungarian), Vogel (1990), Condoravdi (1990, Greek), Poser 
(1990, Japanese), Bickmore (1990, Kinyambo, Bantu), Kidima (1990, Ki-
yaka, Bantu), Peperkamp (1995, Italian), Selkirk (2000, English), Kanerva 
(1990, Chichewa, Bantu), the latter focusing specifically on the issue re-
garding the unpredictability of the mapping mechanism. 
The most ambitious attempt at boxing the mapping mechanism on 
universal grounds is certainly Selkirk's (1986) end-based (or edge-based) 
model, which is presented in §§ 395f. Unfortunately, it does not really stand 
up to the evidence that was produced in subsequent years. Bickmore (1990) 
for example, who adheres to Selkirk's end-based perspective, concludes 
that 
 
(154) "we are still in search of a parameterized cross-linguistic phonological 
phrase-construction rule with descriptive adequacy (let alone explanatory 
adequacy)." Bickmore (1990:17) 

332 
Chap 10: Prosodic Phonology, on the representational side 
Clearly, rigid and universal mapping rules that were proposed in the 
early days of Prosodic Phonology are unable to describe the highly variable 
cross-linguistic picture. The same holds true for the mapping mechanisms 
suggested by Nespor & Vogel (1986) where timid parametric elements ap-
pear. Finally, Selkirk's (1986) end-based model does not offer significant 
progress on this front either.102 
Building on Selkirk (1986), OT has later expressed mapping in terms 
of constraint interaction (ALIGN and WRAP, see § 457), which opens a larger 
parametric space: under the pressure of more and more empirical variation, 
Selkirk (1996) for example cuts down the Strict Layer Hypothesis (§ 383) 
into four independent constraints, two of which may be violated (see § 461). 
In sum, the claim that mapping rules define a reasonable amount of 
cross-linguistic variation which is marshalled by universal properties of 
prosodic constituency does not stand up to fact: it is fair to say that still 
today linguists simply do not understand how mapping works. All that they 
can do is record amorphous lists of blocking and non-blocking environ-
ments that are produced by empirical observation. 
Therefore, the frustration that is generated by the mapping puzzle has 
not calmed down since the late 70s, in spite ± or perhaps because ± of the 
fact that the Prosodic Phonology literature has produced an impressive 
amount of new empirical wealth. As a reaction, the literature has rather 
turned away from the study of cross-linguistic variation in morpho-
syntactically conditioned prosodic phrasing. Further discussion of this 
move is provided in § 463. 
 
393  5.2.5. The mapping puzzle is sometimes hidden by the clean Prosodic 
Hierarchy 
 
The highly variable and uncontrolled mapping mechanism contrasts with 
the uniform Prosodic Hierarchy: Prosodic Phonology indeed aims to en-
 
102 Kanerva (1990:150f) and Bickmore (1990:3ff) provide an interesting overview 
of the various attempts that have been made to define the phonological phrase. 
Quite surprisingly, Inkelas & Zec 1995:539) agree that the mapping mechanism 
is by and large mysterious for intonational phrases and phonological utterances, 
but claim that the two smaller units, the phonological word and the phonologi-
cal phrase, "exhibit impressive cross-linguistic similarities; [«] the attested 
range of variation appears sufficiently small to be viewed as parametric in na-
ture." This is not exactly what one would conclude from the inspection of the 
relevant literature. 

Mapping: its mechanics, its evolution and our understanding thereof 333 
code the non-phonological information that is used in phonology in terms 
of a universal arboreal structure: the buffer is the same in all languages 
(Nespor & Vogel 1986:11). 
That the clean and universal Prosodic Hierarchy is the result of 
mushy mapping activity, however, is sometimes left unmentioned in the 
Prosodic Phonology literature. This is when prosodic constituency is meant 
to appear as a maximally simple, constrained and unified theory which, 
unlike direct syntax approaches and SPE, does not need to recur to flourish-
ing devices that get out of hand. 
One example is Nespor & Vogel's (1986) presentation of intervocalic 
s-voicing in Italian (ISV). They write that 
 
(155) "we can formulate ISV as a ω span rule in a maximally simple way as seen 
in (64), whereas the expression of the domain of application of this rule in 
terms of morphological constituents would not amount to more than a list of 
disparate environments." Nespor & Vogel (1986:129) 
 
Nespor & Vogel forget to mention that in order to achieve the maxi-
mally simple structural description of the ω span rule, they first need to 
create the ω by a maximally complicated and unnatural mapping rule which 
transforms the list of disparate environments into an ω.
More of the same is found in Booij (1985a). 
 
(156) "This theory [Prosodic Phonology] is superior to both standard and natural 
generative phonology in its approach to the influence of morphological 
boundaries on phonological processes. [«] It excludes the rather arbitrary 
use of boundaries made possible in the SPE-framework." Booij (1985a:34) 
 
It is certainly true that SPE is much too powerful a system and wildly 
overgenerates ± this has been spotted in the post-SPE period and actually 
by Chomsky & Halle (1968) themselves in their ninth chapter. However, 
Booij does not mention that the clean prosodic guise was built by an en-
tirely unconstrained construction worker: mapping rules can do anything its 
reverse. They are able to group any two adjacent objects into a prosodic 
constituent and hence overgenerate just as much as the SPE formalism. 
The embarrassment regarding the mapping puzzle is thus as real in 
Prosodic Phonology as it has always been ± perhaps even more pressing 
since nothing was gained by the fresh data that came in. The only thing that 
has changed is the vocabulary that is used for the description of the embar-
rassment: mapping rules now, the absence of natural classes of boundaries 
then. 

334 
Chap 10: Prosodic Phonology, on the representational side 
394  5.3. What is the morpho-syntactic rationale behind mapping? 
 
395  5.3.1. Selkirk (1986) puts to use the technology of the 80s: X-bar-based 
mapping 
 
This situation is the starting point of Selkirk (1986:384): "up to now there 
has been no general theory of the mapping between syntactic structure and 
prosodic structure." 
On this backdrop, Selkirk develops a mapping mechanism that sig-
nificantly restricts the availability of morpho-syntactic structure. Her sys-
tem is called end-based mapping (later often called edge-based theory), and 
Selkirk (1986:388, 400) suggests that it is universal. That is, end-based 
mapping is supposed to account for all possible mappings between morpho-
syntactic and phonological structure. 
In subsequent work, Selkirk's mapping mechanism was applied to a 
number of languages: Hale & Selkirk (1987), Cowper & Rice (1987), 
Selkirk & Tateishi (1988), Selkirk & Shen (1990). Dresher (1994:16ff) and 
Elordieta (2007:137ff, 2008:245ff) provide an informed overview of this 
project. In more recent minimalist times Elordieta (1997, 2007:157ff, 
2008:255ff) entertaines an alternative that is based on the idea that feature 
checking expresses primitive grammatical relationships (morphosyntactic 
feature chains), which define mapping relations.  
Most notably, however, it is Selkirk's focus on edges that has given 
rise to the dominant mapping mechanism when Prosodic Phonology was 
transported into Optimality Theory: McCarthy & Prince (1993, 2001:vii) 
are explicit on the fact that alignment (on which more in § 455) is directly 
inspired by Selkirk (1986). 
Building on Chen (1985), Selkirk's end-based theory holds that "the 
syntax-phonology mapping can be defined simply by reference to the ends 
of syntactic constituents" (Selkirk 1986:386, emphasis in original). Assum-
ing X-bar theory and the irrelevance of morpho-syntactic labels (i.e. 
whether an X-bar structure is headed by a verb, a noun or some other lexi-
cal category, see § 398), only the segmentations under  (157) are allowed for. 
 
(157) possible phonologically relevant segmentations of the linear string accord-
ing to Selkirk's (1986) end-based theory 
 
left end 
right end 
result on the phonological side 
 
a. Word[
]Word 
phonological word 
b. Xhead[
]Xhead 
"small phonological phrase" 
 
c. Xmax[
]Xmax 
phonological phrase 
 

Mapping: its mechanics, its evolution and our understanding thereof 335 
That is, each node of the X-bar structure may represent a division 
that is phonologically relevant. Or, looked at from the phonological per-
spective, phonologically relevant divisions of the linear string necessarily 
correspond to and end of one of the three X-bar levels. Whether the left or 
the right end determines the segmentation depends on a parametric choice. 
According to Selkirk (1986), chunks between two ends of X0 items 
(what she calls the word level, i.e. (157a)) are prosodic units known as the 
phonological word. On the other end of the scale, the chunks located be-
tween the two ends of Xmax domains are phonological phrases. Given X-bar 
structure, Selkirk must also come up with a phonologically relevant inter-
mediate chunk that is determined by the ends of Xhead. This prosodic unit, 
Selkirk (1986:394) claims, "has been discerned in a variety of languages. It 
is one which includes the head of a phrase and preceding or following 
specifier material, but not any complements (arguments) to the head" (also, 
functional words do not count as words). She calls this unit the "small pho-
nological phrase", for which she provides evidence from French liaison. 
Selkirk's end-based theory thus only concerns the middle area of the 
Prosodic Hierarchy: the phonological utterance and the intonational phrase, 
as well as feet and syllables, are not considered. This is because Selkirk 
believes that intonational phrases are semantically defined (rather than 
morpho-syntactically): her position on this issue has not varied since Sel-
kirk (1984:27f). Syllables and feet, on the other hand, are not part of the 
Prosodic Hierarchy for the reasons exposed in § 401.103 
396  5.3.2. End-based mapping does not solve the mapping puzzle either 
 
Selkirk thus claims to have found the key to the mapping-puzzle: all amor-
phous lists of triggering or blocking boundaries fall into place when looked 
at through the prism of  (157). A reanalysis of vowel length in Chi Mwi:ni 
(Bantu, originally studied by Kisseberth & Abasheikh 1974) shows how her 
system works: compare Hayes' (1989 [1984]) formulation of the relevant 
mapping with Selkirk's (1986:397) under  (158) below. 
 
103 Against her earlier work, Selkirk (1984:29ff) held that mapping rules produce 
(or modify) the metrical grid, rather than prosodic constituency (see § 426). In 
Selkirk (1986), she reverts to the Prosodic Hierarchy in its middle area, but 
continues to believe that stress is encoded by the metrical grid (and hence that 
feet do not exist: Selkirk 1986:385). 

336 
Chap 10: Prosodic Phonology, on the representational side 
(158) mapping in Chi Mwi:ni 
 
a. relation-based (Hayes 1989 [1984]:211) 
 
1. in [X0Y''«]X'', where X0 is the head of X'' and Y'' is an adjacent 
complement, the sequence X0Y'' forms a P-phrase. 
 
2. all clitic groups unaffected by 1) form P-phrases. 
 
b. end-based (Selkirk (1986) 
 
]Xmax 
that is, a new phonological phrase begins after the last word of each 
maximal projection. 
 
The gain of simplicity is indeed obvious. Selkirk (1986) thus levels 
her end-based approach against the usual way of grouping morpho-
syntactic units into prosodic constituents. She calls the latter relation-based 
because it invokes the linear order of constituents, as opposed to her 
mechanism, which does not appeal to relations between successive con-
stituents in surface syntactic structure. 
Of course, the question is whether Selkirk's end-based mapping 
really stands up to its universal ambition ± an empirical question. Some 
successful reanalyses in the end-based perspective notwithstanding,104 the 
answer is clearly negative: Selkirk's X-bar-based mechanism cannot reduce 
the flourishing lists of amorphous triggering and blocking boundaries (this 
issue was already discussed in § 392). In most cases, mapping remains as 
obscure as before. Chen (1990) for example demonstrates this fact. He ends 
up arguing that phonology needs both end-based and relation-based map-
ping. 
In sum, then, Selkirk's (1986) ambitious programme may not have 
solved the mapping puzzle; its merit, however, is to have carried the map-
ping question to the forefront of the scene. Or, in other words, the new X-
bar technology of the 80s has not prompted a significant advance over the 
state in which the mapping puzzle was left in the post-SPE literature (see 
§111): natural classes of boundaries do not emerge. 
 
104 Thanks to the end-based mechanism, Cowper & Rice (1987) for example are 
able to reanalyse certain data from Kimatuumbi (Bantu) according to regular 
prosodic constituency. These data had been presented by Odden (1987) in sup-
port of the direct syntax approach. 

Mapping: its mechanics, its evolution and our understanding thereof 337 
397  5.3.3. Boundaries are the relevant descriptive currency 
 
Selkirk's (1986) article also shows that boundaries are the relevant units for 
the description of morpho-syntactic contexts that trigger or block a phono-
logical process. "End-based" indeed means "at a given boundary": phonol-
ogically relevant chunks of the linear string are defined by a local transition 
from some morpho-syntactic category to another. Kaisse & Zwicky (1987) 
put it as under  (159) below. 
 
(159) "Reference to constituent edges also plays a central role in end-based ap-
proaches to prosodic domain determination [«]. These approaches repre-
sent a return in spirit to the word-boundary theory of Chomsky & Halle 
(1968) and Selkirk (1972), which held that only an impoverished subset of 
the information provided by syntax is available to phonology." Kaisse & 
Zwicky (1987:10) 
 
That is, linguists do not know why boundaries are grouped in the 
way they are, but it is safe to say that boundary grouping is the heart of the 
mapping mechanism: relevant generalisations are expressed in terms of 
local transitions, rather than in reference to domains. 
 
398  5.4. Phonology can see morpho-syntactic structure, but not its labels 
 
Unlike the unedifying situation regarding the mapping puzzle, another 
property of the mapping process has appeared quite clearly in the Prosodic 
Phonology literature. It concerns the kind of morpho-syntactic information 
that phonology may use: the tree geometry (immediate constituent hierar-
chy) is often relevant for phonological processes, while the particular labels 
of the nodes do not appear to play any role. In other words, phonology sees 
morpho-syntactic structure, but not its content. 
The observation that category membership is irrelevant to the pho-
nology goes back to Selkirk (1974) and Rotenberg (1978:111ff). It is dis-
cussed by, among others, Kaisse & Zwicky (1987:7), Hayes (1989 
[1984]:205, 1990:87), Inkelas & Zec (1990a:xiii) and Chen (1990). 
Chen (1990) actually argues against this generalisation: he presents 
evidence from Chinese (Xiamen) tone sandhi to the end that whenever 
"tree-geometry and functional relations make different predictions about 
phonological phrasing, it is the latter that prevails" (Chen 1990:45). 
Namely, he identifies the contrast between arguments and adjuncts as a 
phonologically relevant distinction. Some years later, however, Bao (1996) 

338 
Chap 10: Prosodic Phonology, on the representational side 
proposes a reanalysis of the data whereby phonology does not need to look 
at the distinction between arguments and adjuncts. 
In sum, the selective visibility of morpho-syntactic information for 
phonology is an interesting generalisation. Prima facie counter-examples 
such as English stress assignment which depends on whether the item is a 
noun (récord) or a verb (recórd), however, need to be addressed. This issue 
is discussed at greater length in § 752. 
Also, we will see in § 653 that the generalisation becomes meaningful 
beyond the descriptive level in a modular environment: modules are do-
main specific, which means that they use different vocabulary ± they speak 
different languages (of the mind). Therefore the vocabulary of a given 
module (or projections thereof, i.e. node labels) cannot be read by other 
modules, while structure (the tree itself) is not handicapped for intermodu-
lar communication. 
Finally, we will see in § 660 that the generalisation at hand ties in 
with similar observations from other areas and may turn out to be a piece of 
a more general property of how morpho-syntax and phonology communi-
cate. 
 
399  6. Closer inspection of the buffer (Prosodic Hierarchy): what it is and 
what it is not 
 
400 
6.1. The only purpose of the Prosodic Hierarchy is the storage of morpho-
syntactic information 
 
The Prosodic Hierarchy is process-defined: prosodic domains exist only 
because there are phonological processes that make reference to them. Sel-
kirk (1986:385) is explicit on this fact: "constituents like prosodic words or 
higher seem to have no role in the phonology other than the providing of 
domains." A common formulation therefore is "prosodic constituents define 
the domains of application of phonological rules" (e.g. Hannahs 1996:52). 
In turn, this means that there is only one way to detect a domain: the units 
of the Prosodic Hierarchy are those, and only those, that constitute the do-
main of application of a phonological rule. Nespor & Vogel (1986) put it 
the following way.105 
105 Nespor & Vogel (1986:59) also mention two other ways of establishing a pho-
nological constituent: when a given string is the locus of phonotactic restric-
tions, and when it expresses relative prominence relations. These two criteria 
may be safely disregarded in the context of the interface since they concern the 

Inspection of the buffer (Prosodic Hierarchy): what it is and what it is not 339 
(160) "A string is considered a constituent in phonology, as in syntax, if a) there 
are rules of the grammar that need to refer to it in their formulation, or b) 
there are rules that have precisely that string as their domain of application." 
Nespor & Vogel (1986:59) 
 
Hence prosodic domains exist only because they carry extra-
phonological information that is phonologically relevant. 
It is true that the Prosodic Hierarchy has also been used for purposes 
of domestic phonology that have no relation with the interface.106 This is a 
different debate, though: once prosodic constituency is created, it may be 
used ± but its exclusive purpose is the storage of morpho-syntactic informa-
tion; also, no piece of phonological information ever contributes to its con-
struction (see §§ 405, 421). 
Finally, it is noteworthy that even though phonological processes are 
the only evidence for prosodic constituents, all levels of the Prosodic Hier-
archy are always constructed in all languages ± even in absence of any 
phonological consequence (e.g. Hayes 1989 [1984]:220, Nespor & Vogel 
1986:11, see also § 383). Like SPE and Lexical Phonology, Prosodic Pho-
nology is thus a non-privative interface theory (see §§ 79, 756). 
 
two layers of the prosodic hierarchy that do not carry any extra-phonological 
information: syllables (phonotactic restrictions) and feet (prominence rela-
tions). The heterogeneous character of the buffer is further discussed in the fol-
lowing section. 
106 One case in point is Rubach's (1997 et passim) account of so-called trapped 
consonants in Polish (see Vol.1:§240, Scheer 2008b, 2009d), which he argues 
are extrasyllabic (even in the middle of words). On Rubach's analysis, these 
consonants end up being directly attached to the prosodic word. One suspicious 
aspect of this scenario is the existence of extrasyllabic consonants in the middle 
of morphemes (in violation of the Peripherality Condition, e.g. Clements, 
1990:290, Hayes, 1995b:57f). Also, a wrong prediction is made to the effect 
that some natural language could allow for three, five or eleven extrasyllabic 
consonants in a row: since nobody has ever defined co-occurrence restrictions 
for segments that are directly attached to prosodic words (obviously because 
this is also in violation of the Strict Layer Hypothesis, see § 383), any number 
of consonants should be able to be accommodated. 
 
In sum, cases where the Prosodic Hierarchy is used in the analysis of domestic 
phonology, i.e. in absence of reference to morpho-syntactic information, are 
suspicious by themselves. If the Prosodic Hierarchy is a diacritic and has to go, 
they must be misanalysis anyway. 

340 
Chap 10: Prosodic Phonology, on the representational side 
401 
6.2. The buffer does not include syllables and feet 
 
The two lowermost layers of the prosodic constituency, syllables and feet, 
stand out among the six layers of the Prosodic Hierarchy. As was shown in 
the previous section, the only purpose of the four uppermost layers is to 
store morpho-syntactic information. Also, they are constructed by mapping 
rules on the grounds of morpho-syntactic structure and readjustment deci-
sions without any participation of phonological information. That is, the 
four uppermost layers are pure top-down constructions.107
On the other hand, syllables and feet have a motivation that is inde-
pendent from the interface: the former is a bottom-up construction based on 
the sonority of its terminal elements, the segments, while the latter is a 
function of stress. Neither the sonority of segments, which is recorded in 
the lexicon, nor the distribution of stress relies on any structural description 
of some phonological rule. Also, no mapping activity of any kind contrib-
utes to the creation of syllables and feet. 
In other words, were there no interface, syllables and feet would still 
exist, but the four higher layers of the buffer would not. 
Nespor & Vogel (1986) admit the ontological difference between the 
syllable and feet on the one hand and the four uppermost layers of the Pro-
sodic Hierarchy on the other. 
 
(161) "The phonological word is the lowest constituent of the prosodic hierarchy 
which is constructed on the basis of mapping rules that make substantial use 
of nonphonological notions." Nespor & Vogel (1986:109) 
 
The quote from Nespor (1999) below confirms this split into two 
types of prosodic constituents. 
 
(162) "The three lowest prosodic categories are the syllable (σ), the foot (Σ) and 
the phonological word (ω). [«] Of these categories, the first two are purely 
phonological in nature, while the third incorporates morphosyntactic infor-
mation." Nespor (1999:119) 
 
107 What I mean is that no phonological property encoded in the lexical makeup of 
morphemes participates. Information from phonological processes ± the struc-
tural description of rules ± of course defines the division of the linear string into 
prosodic constituents, at least when readjustment is needed. But this is not a 
bottom-up construction in the sense that syllables are a function of the lexical 
properties of segments. 

Inspection of the buffer (Prosodic Hierarchy): what it is and what it is not 341 
Inkelas (1990:37f) and Downing (2006:8f) also make this distinction: 
bottom-up constructed items (mora, syllable, foot) are evicted from the 
Prosodic Hierarchy altogether. Downing specifically argues from the per-
spective of Prosodic Morphology (more on this in § 447).  
The fact that syllables and feet owe nothing to mapping rules is also 
pointed out by Selkirk (1986:385) and Rice (1990:292 note 3) (see also 
Chen 1990:36 on this issue). What really is behind the division at hand, 
however, is the seam between morphology and syntax: the phonological 
word and higher layers manage the interaction of words, while the catego-
ries below the word level define the relationship between morphemes. 
Hayes (1989 [1984]) draws the following conclusion from this situa-
tion. 
 
(163) "The Prosodic Hierarchy should be construed solely as a theory of syntactic 
juncture, with word-internal juncture handled within the Theory of Lexical 
Phonology." Hayes (1989 [1984]:207) 
 
That is, Prosodic Phonology defines the phonological relationship of 
words, while Lexical Phonology is competent for morphemes. This division 
of labour thus reduces Hayes' (1989 [1984]) Prosodic Hierarchy to only 
four layers (instead of six). This perspective, however, has not enjoyed any 
echo, and the regular practice in Prosodic Phonology was to claim a peace-
ful coexistence between prosodic constituents and Lexical Phonology be-
low the word level. § 429 discusses the relationship between the two theo-
ries at greater length. 
In conclusion of this section, we can record that the Prosodic Hierar-
chy as commonly understood is a heterogeneous assembly of autosegmen-
tal constituents which may or may not carry morpho-syntactic information, 
and which may be top-down or bottom-up constructions. It is thus inappro-
priate to talk about the whole prosodic constituency in terms of a buffer: 
only the four uppermost layers store and restore morpho-syntactic informa-
tion. On the pages below, I make allowance for this fact: the buffer refers 
only to a subset of the Prosodic Hierarchy. 
 

342 
Chap 10: Prosodic Phonology, on the representational side 
402  6.3. The buffer is a diacritic ± an autosegmental diacritic 
 
403  6.3.1. Prosodic Phonology lays claim to boundaries: they are the old buffer, 
prosodic domains are the modern buffer 
 
Vogel & Kenesei (1990:344) review the arguments in favour of Indirect 
Reference. One point they make is historical: all interface theories have 
been indirect thus far, so there is probably something to this approach. They 
single out SPE as a forerunner of Indirect Reference. 
 
(164) "Working within the SPE framework, Selkirk [1972] modifies the original 
proposal by showing that at least in certain types of phonological phenom-
ena, interaction between the two components is only indirect. Word bounda-
ries (#'s) inserted into a string on the basis of syntactic structure determine 
where external sandhi rules apply. Phonological rules thus do not directly 
'see' syntactic structure, but rather access only strings of segments and 
boundaries." Vogel & Kenesei (1990:344) 
 
Hence representatives of Prosodic Phonology lay claim to the 
equivalence of #s and the modern prosodic constituency. 
The same line of reasoning is found in the overview article by Inke-
las & Zec (1995). The authors call p-structure the level of representation 
that mediates between morpho-syntax and phonology; they explicitly iden-
tify boundaries as the ancestor of this mediating structure, whose more 
recent incarnation is the Prosodic Hierarchy. 
 
(165) "An early version of p-structure was proposed in SPE and developed in 
subsequent work (Selkirk, 1972, 1974; Rotenberg, 1978). According to this 
view, domains of phonological rules are expressed in terms of phonological 
boundary symbols, generated by rules. [«] Far more constrained is the 
'prosodic' view of p-structure. Under this view, p-structure occupies a level 
with its own hierarchical organization and a high degree of autonomy." 
Inkelas & Zec (1995:537f) 
 
If, thus, prosodic constituency is but a more advanced version of 
boundaries that presents a number of advantages, it must have the same 
formal properties as its predecessor. The two quotes clearly show that pro-
sodic constituency, just as hashmarks, is a diacritic: it serves no other pur-
pose than replicating phonologically relevant morpho-syntactic information 
in phonology (see §400). Although proponents of Prosodic Phonology are 
prompt to point out that boundaries are odd because they are diacritic 

Inspection of the buffer (Prosodic Hierarchy): what it is and what it is not 343 
(§ 373), nobody wonders whether the Prosodic Hierarchy may be a diacritic 
as well, even when it is advertised as the direct surrogate of arbitrary and 
diacritic boundaries (Scheer 2008a). 
 
404  6.3.2. The buffer and SPE-type boundaries share all properties 
 
That the Prosodic Hierarchy is a diacritic may also be seen when compar-
ing its birth and life with boundaries. Just as these, it is the output of a 
translational process: the fixed mapping algorithm (plus eventually read-
justment) in SPE (§§ 90f), mapping rules (including the Black Box) in Pro-
sodic Phonology. 
Just like boundaries, the Prosodic Hierarchy is a UFO in the phono-
logical module: it is injected for the exclusive purpose of storing extra-
phonological information (§400). Domestic phonology, i.e. the one that 
runs without extra-phonological conditioning, does not need to refer to 
either boundaries or prosodic constituency. 
Finally, just like boundaries, the units of the Prosodic Hierarchy are 
arbitrarily chosen and named: "ω" (the phonological word), "φ" (the phono-
logical phrase) etc. are not any less arbitrary than "+" and "#". For some 
reason, however, phonologists always point out the arbitrariness of the 
typewriting symbol #, but do not mind talking about omegas and phis. 
Saying that an omega is only shorthand for a real linguistic object, 
the phonological word, does not help: the same may be said about + and # ± 
only that a regular scientific-sounding terminology has never been intro-
duced for these objects. 
Finally, pointing out that omegas and phis represent certain stretches 
of the linear string which coarsely correlate with morpho-syntactic divi-
sions does not make them less arbitrary. For one thing, this merely shows 
that their only purpose is to replicate morpho-syntactic structure in phonol-
ogy. But more importantly, the same may be said about boundaries ± and 
actually was said (by McCawley 1968, see § 113): + and # represent two 
different boundary strengths, the latter dividing larger chunks of the linear 
string. If more boundaries are added to the list, they may also be correlated 
with increasing chunks of the linear string that coarsely represent morpho-
syntactic divisions. 
 

344 
Chap 10: Prosodic Phonology, on the representational side 
405  6.3.3. What counts as a diacritic? 
 
In order to assess the diacritic status of the Prosodic Hierarchy, one can also 
try to define what a diacritic is. A formal definition must rely on the alien 
status of the object in question in the environment where it evolves. A 
workable definition appears under  (166) below. 
 
(166) definition of the term "diacritic" 
 
a diacritic is a non-native object in module X: it is only used when infor-
mation from outside of X is processed. It is absent from events that do not 
appeal to extra-Xal information. 
 
Hashmarks and omegas alike meet these conditions: they are non-
phonological intruders in the phonological world which exist only when 
phonology appeals to extra-phonological information, and are systemati-
cally absent from phonological processes that do not use extra-
phonological information (such as ordinary palatalisations).  
Hashmarks and prosodic constituents are two ways of fulfilling the 
promise of Indirect Reference. For some strange reason, though, the former 
are stigmatised as arbitrary diacritics, while the latter are advertised as 
"truly phonological objects" (e.g. Selkirk, 1984:32, 409f, Nespor & Vogel, 
1986:27ff, 110ff). Nespor & Vogel (1986:3) for example call boundaries 
"pseudo-phonological terms" and argue that phonology should only be able 
to refer to truly phonological objects (just as syntax can only make refer-
ence to truly syntactic objects). This is quite ironic since nobody has ever 
examined the question whether the Prosodic Hierarchy is a diacritic as well. 
Reading through the literature, I have only come across one voice 
that clearly identifies the buffer for what it is. Without surprise, this voice 
comes from direct syntax quarters (see § 407) where of course no buffer is 
needed: Kaisse (1990:128) calls attention to the redundant and diacritic 
character of prosodic constituency. She points out that the direct syntax 
option "does not require the postulation of constituents that are needed only 
to describe the sandhi phenomena in question." 
In sum, thus, it appears that there is just one difference between 
hashmarks and omegas: the former are linear and local, while the latter are 
autosegmental, hence non-local units. The progress since SPE, then, does 
not concern Indirect Reference or the diacritic notation of phonologically 
relevant morpho-syntactic units; rather, it comes down to a change from a 
linear to a non-linear encoding of higher level information. 
This takes us back to the genesis of Prosodic Phonology: I have ar-
gued in §§ 368f that Prosodic Phonology is a child of autosegmentalism; it 

Good and bad reasons for Indirect Reference 345 
is the application of the general autosegmental trend of the early 80s to the 
interface. 
 
406 
7. Good and bad reasons for Indirect Reference 
 
407  7.1. Direct syntax vs. Prosodic Phonology 
 
408  7.1.1. Two approaches, their competition and their evolution 
 
In the years following the introduction of Prosodic Phonology, the main 
debate in the realm of the interface was about the buffer as such: so-called 
direct syntax approaches held that the extra layer of mediating prosodic 
representations is 1) superfluous and 2) complicates the statement of pho-
nological rules. Instead, phonological rules should be allowed to make di-
rect reference to morpho-syntactic structure. 
Direct syntax was common in early generative work on the interface, 
namely as a response to the frustration that was generated by boundaries: 
Rotenberg (1978) (§ 137), Clements (1978), Pyle (1972) (§ 136), Hyman 
(1978:459) (§ 123) and Kenstowicz & Kisseberth (1977) (§ 132) are exam-
ples. Interestingly, an early representative of the Prosodic Phonology tradi-
tion (where Indirect Reference visibly was not an issue yet) also bought 
into the direct syntax idea: Napoli & Nespor (1979). In the 80s, the direct 
syntax approach was most prominently entertained by Kaisse (1983, 1985, 
1990), Lobeck & Kaisse (1984), Manzini (1983), Odden (1987, 1990), 
Rizzi & Savoia (1993) and Chen (1990) (Elordieta 2007:126ff, 2008:211ff 
provides an informed overview).  
A more recent representative of direct syntax is Seidl's (2001) at-
tempt to marry Indirect Reference with direct syntax: Seidl provides for 
direct reference to morpho-syntactic structure by "early" rules (at a level 
she calls morphosyntactic), but maintains indirect reference to prosodic 
constituency by "late" rules (at a level called Prosodic Representation). Her 
Minimal Indirect Reference model is thus a hybrid entity which allows for 
direct syntax under the pressure of certain phenomena. Since there is no 
conceptual difference between doing a little or a lot of direct interface, 
though, her system may be considered a mere variant of direct syntax. Be-
yond this fact, it is argued in § 409 below that mixing both direct and indi-
rect reference is actually the worst of all systems since the existence of the 
direct syntax option makes the Prosodic Hierarchy superfluous. 

346 
Chap 10: Prosodic Phonology, on the representational side 
The competition of direct syntax approaches and Prosodic Phonology 
was launched in a special issue of the Phonology Yearbook (edited by 
Kaisse & Zwicky 1987), where both options appear with their pros and 
cons. Three years later in the volume on the phonology-syntax interface 
edited by Inkelas & Zec (eds.) (1990c), the balance is clearly in favour of 
Prosodic Phonology: all contributions but those by Odden and Chen either 
argue that reference to syntax may only be indirect via the buffer, or take 
this position for granted.108 New data that the direct syntax approach is 
supposed to be unable to get a handle on are presented (e.g. Cho 1990, 
Poser 1990, Selkirk & Shen 1990, Condoravdi 1990). On the other hand, 
evidence which was brought forth in favour of direct syntax is reanalysed 
(see already Cowper & Rice 1987). Hayes (1990) for example admits that 
there is a "direct residue", but only in order to propose a "theory of the resi-
due" within the prosodic frame where the relevant alternations are dealt 
with in the lexicon by some kind of allomorphy (precompilation theory). 
This trend is confirmed in the volume edited by Kleinhenz (1996) 
(e.g. Hannahs 1996) and the special issue of The Linguistic Review on the 
"phonology between words and phrases" edited by Marina Nespor in 1996: 
the Prosodic Hierarchy is by and large accepted as the correct approach to 
the interface. Its success is based on one single argument that is rehearsed 
over and over again: the units that are relevant for the statement of phono-
logical rules are determined by, but not isomorphic with, morpho-syntactic 
structure. In other words, the need of readjustment (in terms of SPE, the 
Black Box under  (140)) was decisive. 
In the younger OT-based literature, however, Indirect Reference is 
systematically violated and on many occasions (quite tacitly) replaced by 
direct syntax (§§ 494, 501, 525). As a consequence, the existence of the Pro-
sodic Hierarchy as such is called into question, at least by those defenders 
of direct syntax who care for not having done the same labour several times 
(Pak 2008:60ff and Samuels 2009a:284ff offer relevant discussion regard-
ing the uselessness of the Prosodic Hierarchy in a direct syntax environ-
ment). 
 
108 The introduction to the volume by Inkelas & Zec (1990a) offers a well-
informed overview of the debate regarding direct syntax approaches, and of the 
arguments that have led to their discredit. 

Good and bad reasons for Indirect Reference 347 
409  7.1.2. Is the buffer useless and redundant? A real good motivation is needed 
 
Prosodic Phonology holds that phonology is burdened with extra arboreal 
structure plus extra computation, the mapping rules. These devices have no 
other purpose than making morpho-syntactic structure available inside the 
phonological module (see §400). By contrast, the alternative solution that 
makes direct reference to morpho-syntactic categories achieves the same 
result without any additional structure or computation. 
A bare assessment of both directions will thus disqualify Prosodic 
Phonology without any hesitation: why having a significant amount of ad-
ditional structure and extra computation without any need? It is thus vital 
for Prosodic Phonology to be able to dismiss this obvious objection, which 
is made for example by Kaisse (1985:156 note 1, 110 note 1, 1990:128f). 
That is, Prosodic Phonology needs to find a real good reason why phonol-
ogy should be unable to directly refer to morpho-syntactic structure. 
 
410 
7.2. A good reason: modularity 
 
411  7.2.1. Introduction: different modules do not speak the same language 
 
In order to make the modular argument, the following pages need to antici-
pate on the proper introduction of modularity that is provided in the Inter-
lude (§ 586). 
Modularity (Fodor 1983 et passim) is certainly a good reason for In-
direct Reference. The modular perspective holds that grammatical activity 
± as other cognitive faculties ± is organised in terms of a number of onto-
logically distinct, non-teleological and specialised computational systems: 
the modules.  
Modules are domain specific and encapsulated (§ 610). That is, they 
are devoted to a specific task, which they carry out using a specific vocabu-
lary. Since they are ontologically distinct and speak different languages (of 
the mind), they are unable not understand, or even parse, what is going on 
in other modules. 
 
412  7.2.2. Phonology-free syntax 
 
An illustration of the incommunication between different modules is the 
well-known notion of phonology-free syntax. There is no syntactic move-

348 
Chap 10: Prosodic Phonology, on the representational side 
ment on record that would be triggered only if, say, the candidate begins 
with a labial. The same holds true for other categories that are relevant in 
phonology such as palatality, occlusion etc. Building on this observation, 
Zwicky & Pullum (1986a,b) have introduced the principle of phonology-
free syntax, which holds that phonology is entirely invisible to syntax. That 
is, conditioning is only top-down: syntax bears on phonology, but there is 
no communication in the other direction. 
Zwicky & Pullum's principle originally concerned only syntax; how-
ever, it was rapidly extended to morphology: no concatenation of two mor-
phemes is supposed to be conditioned by the phonological properties of the 
items involved.109 Phonology-free syntax has rapidly become the standard 
view of the macro-landscape regarding modular identities, also in the Pro-
sodic Phonology literature. Relevant references in this context include 
Pullum & Zwicky (1988), Vogel & Kenesei (1990:346ff), Miller et al. 
(1997) and Guasti & Nespor (1999). 
There is evidence, though, that the generalisation is too strong as it 
stands. Its scope is probably restricted to a subset of phonological items, i.e. 
those that occur below the skeleton (melody). That is, only melody is un-
able to influence concatenation (while items above the skeleton may impact 
the workings of morpho-syntax). Another issue is a putative difference in 
behaviour between morphology and syntax: while nobody doubts that syn-
tax is be melody-free (Zwicky & Pullum's original observation), morpho-
logical concatenation is sometimes claimed to be conditioned by phono-
logical factors that include melody. 
Let us first look at the literature that challenges the invisibility of 
phonological properties for morpho-syntax as such. These include Inkelas 
(1990), Inkelas & Zec (1990b, 1995), Hargus (1993), Neeleman & Reinhart 
(1998), Szendrői (2001, 2003, 2004) regarding syntax, Szymanek (1980), 
Ackema & Neeleman (2004:2), Burzio (2007) regarding morphology. 
Szymanek (1980), Vogel & Kenesei (1990) and Inkelas & Zec (1995) pro-
vide surveys of phenomena that are frequently quoted in support of the fact 
that phonology may have bearing on morphology and syntax. 
When looking at the inventory of phenomena that are argued to in-
duce a bottom-up conditioning, a clear regularity appears, though. Every-
body indeed agrees with Zwicky & Pullum's (1986a,b) original observation 
that segmental properties of sound never affect a syntactic derivation; Vogel 
& Kenesei (1990:346) as well as Inkelas & Zec (1990b:366, 1995:547) for 
 
109 Recall from § 253 that phonology-free syntax played a role in the discussion of 
interactionism, a key notion of Lexical Phonology. 

Good and bad reasons for Indirect Reference 349 
example are explicit on this. That is, nobody has ever seen anything like 
"verbs that begin with a velar are raising verbs". 
On the other hand, recurring candidates for bottom-up conditioning 
are located above the skeleton. This observation is also made by Kaisse & 
Hargus (1993:4) in the debate on interactionism: "if an affix subcategorizes 
for a base with certain derived phonological properties, those properties are 
almost always supra-segmental (e.g. stress)." 
A more documented record of this intuition can be gained when pars-
ing the literature that argues against phonology-free syntax: the phenomena 
quoted are intonation and stress (Szendröi 2001, 2003, 2004, Hargus 1993), 
tree-geometric properties of the prosodic constituency (for example the 
existence or branchingness of constituents, Inkelas & Zec 1988, 
1990b:372ff), the size of lexical items (minimal word constraints: number 
of syllables or moras, e.g. Inkelas & Zec 1990b:372ff, Hargus 1993, 
Bendjaballah & Haiden 2005, forth) and rhythm (Guasti & Nespor 1999). 
In other words, the literature has identified a red line that cuts the 
phonological space into two areas, above and below the skeleton (see 
Vol.1:§216). While the latter is invisible for syntax for sure, there is reason 
to believe that the former may be a factor in syntactic computation. 
Let us now turn to the putative distinction between morphology and 
syntax. The literature discusses cases where melodic properties impact the 
concatenation of morphemes (e.g. the aforementioned Szymanek 1980 and 
Ackema & Neeleman 2004:2, Burzio 2007). Hargus (1993:54ff) presents 
evidence for phonology-sensitive morphology from segmental processes, 
but points out herself (p.69) that most of these unexpectedly share the fact 
of involving non-concatenative morphology (Semitic, reduplication, infixa-
tion).  
This is certainly a correct observation. Let us have a closer look at 
phonologically conditioned infixation, which appears to be a particularly 
harsh violation of phonology-free morphology and therefore is typically 
quoted in this context. Based on Moravcsik (2000), Samuels (2009a:147ff) 
provides an overview of phonological factors that are known to condition 
infixation cross-linguistically. The list of anchor points that infixes look at 
in order to determine their landing site falls into two categories: edge-
oriented and prominence-oriented. For the left edge for example, docu-
mented situations are "after the first consonant (or consonant cluster)", 
"after the first vowel", "after the first syllable" and "after the second conso-
nant". Prominence-based attractors are stressed vowels, stressed syllables 
or stressed feet. 

350 
Chap 10: Prosodic Phonology, on the representational side 
In no case, however, is melody reported to be relevant for the defini-
tion of the landing site. Hence cases where infixes are inserted after, say, 
the first labial consonant of the word (and in absence of labials are pre-
fixed) do not seem to be on record.  
Only Zuraw (2007) has found evidence for the influence of major 
categories, which however is based on loanword adaptation, and which is 
only gradual, rather than categorical. In her Tagalog data (Austronesian, 
Philippines), word-initial stop-glide clusters are significantly more often 
split than stop-liquid clusters. Tagalog does not have native word-initial CC 
clusters, and hence speakers must make a decision to insert relevant infixes 
(which normally land after the first consonant of the word) either after C1
or C2 (e.g. graduate can come out as g-um-raduate or gr-um-aduate). The 
statistically relevant impact of cluster types, however, does not need to 
harm the generalisation that infixation is blind to melody: the most obvious 
analysis is to interpret the difference between stop-liquid and stop-glide as 
a contrast in (syllable) structure, rather than in melody. 
It thus seems that Zwicky & Pullum's generalisation also holds for 
infixation if the melodic proviso is observed: infixation does not react on 
melodic properties of phonology. 
On a more general note, defenders of phonology-free syntax have 
proposed reanalyses of bottom-up conditioning, or place it outside of 
grammar (discourse-related): among others, Zwicky & Pullum (1986b), 
Vogel & Kenesei (1990), Odden (1993), Miller et al. (1997), Guasti & 
Nespor (1999), Boãković (2001, 2005a) and Revithiadou (2006) have 
worked in this direction.110 
In conclusion of this survey, there is reason to believe that phonol-
ogy-free syntax is still a valuable generalisation which however needs to be 
restricted to melody. Melody-free syntax then also seems to extend to mor-
phology. 
It will be shown in § 660 that the non-communication between the 
area below the skeleton and morpho-syntax also holds true for the reverse 
 
110 Bendjaballah & Haiden's (2005, forth) analysis of Kabyle Berber also falls into 
this category: it puts a phenomenon which looks like a phonological condition-
ing of preposition selection back under the roof of phonology-free syntax. That 
is, in the variety of Berber examined, "small" prepositions can only occur with 
the Construct State not because syntax looks at their size, but because they are 
small enough to be hosted by a CV unit that is provided only by the Construct 
State. On this analysis, thus, it is true that a phonological property of the prepo-
sitions at hand decides on whether a given item can occur in a specific syntactic 
context ± but at no point of the process does syntax "look into phonology". 

Good and bad reasons for Indirect Reference 351 
direction: when morpho-syntax ships off information to phonology, it never 
accesses the area below the skeleton. That is, melodic properties of sound 
are never targeted by any higher level intervention (of the kind "p becomes 
r before this or that morpho-syntactic division", or "raising verbs palatal-
ise"). Morpho-syntax can only bear on the phonological structure above the 
skeleton. 
 
413  7.2.3. Phonology and morpho-syntax do not speak the same language ± 
hence communication requires translation 
 
Given this situation, no doubt there is an ontological gap between (at least 
the melodic part of) phonology and morpho-syntax.  
This is confirmed when comparing the basic vocabulary that is used 
in phonology and other linguistic areas: number, person, animacy, quantifi-
cation, aspect and so forth are categories that are used, understood and 
processed by syntax as much as by morphology and semantics. In this 
sense, syntax, semantics and morphology speak the same language. Much 
unlike phonology, which does not know what number, person etc. is. The 
reverse is also true: labiality, occlusion and the like play no role in either 
syntax, morphology or semantics.111 
This privacy of vocabulary is called domain specificity in modular 
theory. It is the basic argument which allows us to decide that two compu-
tations are located in distinct modules. Jackendoff (1997) for example is 
explicit on the fact that a module can only understand its own language (of 
the mind), and that two different languages cannot coexist within the same 
module.112 
(167) "'Mixed' representation[s] should be impossible. Rather, phonological, syn-
tactic and conceptual representations should be strictly segregated, but coor-
dinated through correspondence rules that constitute the interfaces." 
Jackendoff (1997:87ff) 
 
In sum, there are two macro-modules, morpho-syntax and semantics 
on the one hand, phonology on the other, which manipulate mutually exclu-
 
111 This argument is developed by Michal Starke in unpublished work. Further 
discussion is provided in § 641. 
112 This issue is discussed at greater length in §§ 640, 650. 

352 
Chap 10: Prosodic Phonology, on the representational side 
sive categories.113 We know for sure, however, that they communicate, at 
least top-down: morpho-syntax bears on phonology. Modularity thus en-
forces translation: there must be a Translator's Office where the morpho-
syntactic language is translated into the phonological idiom (mapping rules 
and the black Box in Prosodic Phonology). Were there no translation, poor 
phonology could not react on orders that are issued in the morpho-syntactic 
language. 
This also implies that the translational process cannot take place in 
either morpho-syntax or phonology: the Translator's Office has access to 
the structure and the labels of both sides. It therefore must stand in modular 
no man's land (§ 381). 
 
414  7.2.4. Nobody makes the modular argument in order to sustain Indirect 
Reference 
 
If implicitly and timidly on most occasions, modularity and the fact that 
phonology does not speak the same language as other modules is invoked 
in the Prosodic Phonology literature (e.g. Nespor & Vogel 1986:27ff, 
110ff). Some relevant quotes from Selkirk (1984) appear below. 
 
(168) "The syntax and the phonology are entirely autonomous components, the 
rules of syntax making no appeal to phonology and vice versa. Mediating 
between these components, however, are two others that define the relation 
between the syntactic and phonological representations of a sentence. The 
principles of these components have a mixed vocabulary. They appeal to 
certain limited aspects of syntactic representation in constructing the hierar-
chies of phonological representation." (Selkirk 1984:410f) 
 
"Phonological rules are blind to syntactic structure. In the general case, then, 
phonological representation, richly structured itself, mediates between syn-
tactic structure and the phonological rules that ultimately specify the details 
of the phonetic realization of the sentence." (Selkirk 1984:32) 
 
113 Eventual internal modular structure within the former is a debated issue, on 
which more in § 533. 

Good and bad reasons for Indirect Reference 353 
"Our hypothesis is that phonological rules make no direct reference to syn-
tactic structure, their application being governed only by the phonological 
representation itself.[«] We are saying that the phonological component of 
the sentence is syntax-free, or that phonology, defined in this way, is 
'postcyclic'. [«] It is the rules of the syntax-phonology mapping [«] that 
are unalterably syntax-dependent. [«] The rules look at syntax and build 
phonology." (Selkirk 1984:409f) 
 
Typically, modularity is put to use when the Prosodic Hierarchy is 
compared with boundaries: Nespor & Vogel (1986:3) for example call 
boundaries "pseudo-phonological terms" and argue that phonology should 
only be able to refer to truly phonological objects (just as syntax can only 
make reference to truly syntactic objects). 
As far as I can see, however, on no occasion is modularity used in 
order to sustain Indirect Reference. In a modular environment where pho-
nology and morpho-syntax are two distinct modules, though, the direct 
syntax perspective is definitely ruled out. Morpho-syntactic information 
can only be parsed by phonology if it was translated into the phonological 
language ± exactly what is required by Indirect Reference. 
Hence the general interface architecture  (140) that Prosodic Phonol-
ogy has established is a modular architecture whose central element is the 
Translator's Office (mapping rules and the Black Box). Strangely enough, 
though, it seems that this was a coincidence with, rather than an application 
of, the contemporary modular idea: the modular argument in favour of Indi-
rect Reference is missing in the Prosodic Phonology literature. 
 
415  7.2.5. Modularity and Level Independence 
 
The modular idea of distinct ontological entities itself, as well as its con-
comitant need for intermodular translation, signs the return of Level Inde-
pendence.114 
Recall from §§ 60f that this was the major architectural principle in 
structuralist theory: the use of morpho-syntactic information in phonology 
was prohibited. Bypassing this proscription more or less deliberately and 
more or less consciously, the only way to have morpho-syntactic informa-
tion bear on phonology was to put it in a phonological guise (§§ 64ff). Since 
 
114 The relationship between Level Independence and modularity is also discussed 
in §§ 72, 699. 

354 
Chap 10: Prosodic Phonology, on the representational side 
phonemes were the relevant phonological currency, extra-phonological 
information was carried by juncture phonemes in structuralist times. 
Level Independence thus expresses the idea that phonology and mor-
phology are two distinct ontological entities which work on different vo-
cabulary ± this is called domain specificity in modular theory. Given this 
rigid frame, structuralists were forced into translational activity that trans-
forms morpho-syntactic information into phonemes. 
Of course, Level Independence has never been formulated this way. 
Of course, it had an unfortunate implementation namely because the pho-
nemic principle enforced a free distribution of juncture phonemes, includ-
ing in the middle of morphemes (§ 69). Of course, its motivation was not 
even remotely related to the cognitive ambition of modularity: Level Inde-
pendence roots in the descriptive tradition of American structuralism that 
seeks a discovery procedure. And of course, it is wrong in its literal mean-
ing ("there is no morpho-syntactic information in phonology"). 
But all this does not belittle the fact that the basic idea of modularity 
and its consequence, translation, was present in structuralist thinking: Level 
Independence does not reduce to the proscription of morpho-syntactic in-
formation in phonology. 
Looked at from this perspective, Level Independence (which was 
abandoned in generative times, see § 76) appears to be quite modern: after a 
period of twenty years (that was initiated by SPE) where direct reference to 
morpho-syntactic labels was common practice, generative theory applies 
Level Independence in the guise of modularity since the advent of Prosodic 
Phonology and Indirect Reference in the mid 80s. 
 
416 
7.3. A bad reason: non-isomorphism 
 
417  7.3.1. Non-isomorphism in the Prosodic Phonology literature 
 
The argument in favour of Indirect Reference that is made in the Prosodic 
Phonology literature ± the only argument that one comes across ± is non-
isomorphism. This notion embodies the observation that in some cases, the 
domain to which a phonological rule makes reference is not co-extensive 
with any morpho-syntactic domain. Or, in other words, some phonological 
rules make reference to information that is absent from the syntactic surface 
structure. 
Therefore, the argument goes, there need to be a readjusting mecha-
nism that further transforms the output of morpho-syntax so to create the 

Good and bad reasons for Indirect Reference 355 
divisions which are needed for phonology. This job is done by the mapping 
rules whose output, the buffer, provides the adequate target for the refer-
ence of all phonological rules that are sensitive to morpho-syntactic infor-
mation. That is, mapping rules preserve all morpho-syntactic divisions that 
are necessary for phonological rules to apply, and add new information of 
their own (this is the function of the Black Box under  (140)). 
The notion of non-isomorphism goes back to SPE (though it was not 
called like that then), where it motivated the readjustment component. The 
relevant quote from Chomsky & Halle (1968:371f) is discussed in § 91. 
Non-isomorphism has then served to motivate Indirect Reference 
since Selkirk's (1981 [1978]:138) first article and runs through the entire 
Prosodic Phonology literature.115 The following quote from Selkirk (1984) 
is an example. 
 
(169) "An intonational phrase typically contains material belonging to a sequence 
of words and/or phrases and it is not necessarily isomorphic to any constitu-
ent of syntactic structure. [«] The existence of the intonational phrase is 
motivated primarily by the necessity of defining intonational contours with 
respect to some unit of representation that is both larger than the word and 
variable in extent. That unit cannot be a syntactic one, because the syntactic 
sequence with which an intonational contour is associated may not be a 
constituent of syntactic structure. And the metrical grid alignment of the 
sentence defines no such unit in the representation." Selkirk (1984:27) 
 
418  7.3.2. The phenomenon: cat-rat-cheese, phonology over sentences 
 
Nespor & Vogel (1986, all through the book: 4f, 34ff, 124ff etc.) are very 
conscious that their theory stands and falls with non-isomorphism. They 
therefore spend a lot of ink on making the argument, which is illustrated by 
empirical evidence from various languages. 
Two cases are discussed below. They are chosen on account of their 
significance and notoriousness. The cat-rat-cheese example was used by 
Chomsky & Halle (1968:371f), and since Nespor & Vogel (1983:130ff, 
1986:57f) has become the standard data set which is always repeated when 
 
115 Other references of the early literature include Selkirk (1980a:110), Nespor & 
Vogel (1982:226), Nespor & Vogel (1986:37ff), Hayes (1989 [1984]:201), Nes-
por (1985), Neijt (1985:180), Booij (1985b:149). Vogel (1999:117ff) is an ex-
ample from the more recent overview literature. 

356 
Chap 10: Prosodic Phonology, on the representational side 
non-isomorphism is discussed (e.g. Vogel & Kenesei 1990, Nespor et al. 
1996, Dresher 1996:42). 
Compare the major syntactic divisions of the sentence under (170a) 
with its intonational structure under (170b). 
 
(170) a. This is [the cat that caught [the rat that stole [the cheese]]] 
 
b. [This is the cat] [that caught the rat] [that stole the cheese] 
 
The two lines of division do not coincide. Hence, goes the argument, 
whatever drives phonology to decide that the intonation is as under (170b), 
it is not the output of the syntactic module. There is no node in the syntactic 
tree that uniquely dominates every intonational span of the sentence. Also, 
syntactic theory could not evolve in a way so to achieve this goal since this 
would mean that syntactic structure gives up on the embedding of sen-
tences: the middle intonational chunk [that caught the rat] is not uniquely 
dominated by any syntactic node because its CP also dominates the embed-
ded third chunk [that stole the cheese]. Therefore the relevant intonational 
structure must be created outside of the syntax by some interface activity: 
mapping rules flatten their syntactic input under the influence of the Black 
Box (see  (140)). 
The second phenomenon targets another unmodifiable property of 
syntactic structure: the fact that two independent sentences are not domi-
nated by any node. It is therefore impossible to describe a phonological 
event at the break of two sentences in terms of domains that are isomorphic 
with syntactic structure: the relevant domain, that is the string encompass-
ing the two sentences, does not exist in the syntactic tree. 
The witness for the existence of cross-sentence phonology that Nes-
por & Vogel (1986:4f) present is linking r. In certain non-rhotic varieties of 
English such as Received Pronunciation, etymological r remains unpro-
nounced utterance-finally as well as before consonant-initial morphemes 
and words (mothe*[r], mothe*[r]ly, my mothe*[r] comes), but appears 
before vowel-initial morphemes and words if the intervening boundary 
allows for the linking effect (mothe[r]ish, my mothe[r] is coming). The 
critical fact for the demonstration at hand is that linking r may also appear 
at the break of two sentences, as shown under  (171) below.116 
116 Examples are from Nespor & Vogel (1986:4f, 46f), data and argument are de-
veloped at length in Vogel (1986). The same pattern is produced by t-flapping 
in certain American English varieties, cf. Nespor & Vogel (1986:46f, 223ff). 

Good and bad reasons for Indirect Reference 357 
(171) a. There's my mothe[r]. I've got to go. 
 
b. There's my mothe*[r]. I've got two cats. 
 
Nespor & Vogel contrast (171a) where the r may be linked with 
(171b) where according to them no r may be pronounced. The difference, 
they argue, is semantic: the relationship between the two sentences under 
(171b) is distant, while it is intimate under (171a). This is the critical factor 
for the appearance of the linking r in otherwise identical conditions. 
Nespor & Vogel (1986) conclude that phonology makes reference to 
a domain which does not exist in syntax. The relevant phonological do-
main, the phonological utterance, must therefore be constructed by the in-
terface mechanism, that is mapping rules. On this count, then, r is only 
linked within a phonological utterance, and too much semantic distance 
does not allow a single phonological utterance to span two sentences. 
 
419  7.3.3. Domain abuse I: there is no argument when phonology refers to 
boundaries instead of domains 
 
The point made on the grounds of non-isomorphism is certainly correct ± 
but only if it is taken for granted that phonological rules make reference to 
domains, rather than to (local) boundaries. That is, (non-)isomorphism in 
the Prosodic Phonology literature is always understood as a comparison 
between domains: morpho-syntactic and phonological. While it is certainly 
true that morpho-syntactic organisation is arboreal, nothing affords the a 
priori that the interface currency on the phonological side are non-local 
domains, rather than local boundaries. This puts us back to the issue of 
whether higher level intervention in phonology is local or non-local 
(§§366, 706). 
We are thus invited to look at the same facts also through the lens of 
local boundaries. The effect is quite striking: non-isomorphism evaporates. 
In the cat-rat-cheese example under  (170), intonational chunks simply be-
gin at every CP. Hence it is enough to say that the intonation-building 
mechanism starts a new unit every time it hits the phonological translation 
of the CP-boundary. Intonational and syntactic structure are thus perfectly 
isomorphic, and no extra constituency on the phonological side is needed. 
The same holds true for linking r under  (171): the point made by 
Nespor & Vogel relies on the absence of a domain that encompasses two 
sentences. If boundaries are the units to which phonological rules make 
reference, however, no sentence-spanning domain is needed: the contrast 

358 
Chap 10: Prosodic Phonology, on the representational side 
observed stems from the different boundaries that separate the two sen-
tences at hand and denote their variable semantic relationship. 
When going through the evidence that has been produced in order to 
support non-isomorphism (among many others, Selkirk 1981 [1978], 1981, 
1984:27f, 1986, Nespor & Vogel 1982, Nespor 1985, Hyman et al. 1987, 
Rice 1987, Vogel & Kenesei 1987, Nespor & Vogel 1986:36ff, Nespor et al. 
1996:7), it appears that the result is always the same: the regularity which is 
formulated in terms of domains can as well be described with boundaries 
and then turns out to be perfectly isomorphic. That is, boundaries necessar-
ily correspond to some morpho-syntactic division. Thus case after case, 
non-isomorphism turns out to be an artefact of the domain-preempted 
analysis, rather than a fact about the relation between phonology and mor-
pho-syntax. 
In sum, prosodic constituency and the claim that phonological rules 
make reference to domains is a self-fulfilling promise: once domains exist, 
the argument based on non-isomorphism can be made to the effect that we 
need the Prosodic Hierarchy. Non-isomorphism disappears, however, if 
higher level intervention in phonology is local. 
Since non-isomorphism is the only argument for the buffer, the entire 
parallel world of prosodic constituency turns out to be superfluous if local 
intervention turned out to be correct. 
 
420  7.3.4. Domain Abuse II: theoretical units are confused with descriptive 
categories 
 
It was already mentioned that the success of Prosodic Phonology may be 
measured by the fact that generalisations are commonly stated in terms of 
prosodic constituents, rather than in terms of morpho-syntactic categories 
or descriptions of the divisions at hand. 
The following quote is an example of this practice: for the authors, 
"applying across words" is synonymous with "applying within a domain". 
 
(172) "When a phonological rule applies across words, it is necessary to be able to 
specify across which types of words it may apply and across which it may 
not, or in other words, within which domain it applies." Vogel & Kenesei 
(1987:243) 
 

Good and bad reasons for Indirect Reference 359 
Using domains as a descriptive category without considering the lo-
cal alternative may introduce a fatal bias into the analysis.117 This may be 
illustrated by Nespor & Vogel's (1986:42ff) analysis of Spanish nasal as-
similation: the nasal of a nasal-obstruent cluster that straddles a word 
boundary may come to agree in place with the obstruent. Nespor & Vogel 
provide two examples where homorganisation goes into effect when the 
two words in question are a verb followed by an object NP, and a verb fol-
lowed by an adjective, respectively. From this, Nespor & Vogel conclude 
that the domain of application of the homorganisation rule is "within the 
VP". 
They then introduce additional evidence that appears to violate this 
generalisation: there is no homorganisation between an object NP and a 
following preposition. They conclude that Spanish provides evidence for 
the conditioning of phonological processes by constituent size: processes 
are more easily blocked when their domain of application, the VP in the 
Spanish case, is long (i.e. contains many words). 
This analysis is inconclusive: in order to tell whether it is correct we 
would need to examine the case of an object NP-Prep boundary that does 
not make the VP too long. If this is not possible, the matter may not be 
decided since the blocking effect may either be due to the length of the VP 
or to the object NP-Prep boundary. In any event, declaring that the domain 
of application of a rule is the VP without having tested all possible VP-
internal boundaries is confusing boundaries ± the only descriptive unit that 
is given to the analyst ± and domains, a derived category. 
 
421  7.3.5. Is prosodic phrasing sensitive to the length of the string? 
 
Since Nespor & Vogel (1986), length sensitivity of prosodic phrasing runs 
through the literature. Given its initial illustration, however, it may be 
worthwhile checking whether it is an artefact of domain-biased analysis, 
rather than a fact about the interface. 
Four points can be made. For one thing, it is never the case that the 
alleged "short" and the alleged "long" portions of the string are morpho-
 
117 It is true, however, that work in Prosodic Phonology usually avoids this kind of 
pitfall: the inventory of boundaries which have a (non-)blocking effect in re-
gard of some phonological process is established first. These lists are then con-
verted into prosodic categories. Work along these lines includes Selkirk & 
Tateishi (1988), Hayes (1989 [1984]), Selkrik & Shen (1990), Cho (1990), 
Condoravdi (1990), Bao (1996). 

360 
Chap 10: Prosodic Phonology, on the representational side 
syntactically identical. This is the flaw in Nespor & Vogel's (1986) analysis 
of Spanish: the "longer" string has also more internal morpho-syntactic 
structure; hence these additional boundaries, rather than length, could well 
be responsible for the effect observed.118 
This is precisely what Wagner (2005a,b) shows for intonational 
units: following the question "who was at the party?", the answer "[Morgan 
and Joey]" is just one intonational unit, while the answer "[Morgan] or 
[Joey and Ronny]" bears two intonational spans. Contra Watson & Gibson 
(2004, 2005) who hold that the probability of the existence of a boundary 
depends on the size of the constituents that are adjacent to it, Wagner shows 
that "length" is responsible for nothing at all ± its alleged effects are due to 
the (recursive) syntactic structure of the "long" items. 
Second, it is not clear in which way "size" is a phonological cate-
gory. Phonology has no means of knowing how long a word or a morpheme 
is. And "size" is nothing that is known in phonology proper either (i.e. 
when no extra-phonological information intervenes): there is no phonologi-
cal process, say palatalisation, vowel harmony or the like, that depends on 
the length of something. Hence to the extent that anybody decides what is 
long and what is short, this job is surely not done by the phonology. 
Third, alleged size restrictions always seem to concern either the 
phonological phrase or the intonational phrase. There is no good reason 
why this should be so: if mapping may be size-sensitive, this option should 
at some point be visible at all levels of the Prosodic Hierarchy. 
 
118 The same holds true at the morphological level. Ricardo Bermúdez-Otero (pc) 
has brought up the following contrast: in the frame "« requires us to think 
again about these issues", a phrase-initial NP subject such as "contemporary 
thought" is less likely to constitute a separate intonational unit than "contempo-
rary antidisestablishmentarianism". He concludes that size matters: larger items 
which are otherwise identical tend to be cut down into several prosodically 
relevant portions. However, antidisestablishmentarianism and thought may be 
identical on the syntactic side ± they are certainly not identical morphologically 
speaking. Hence nothing guarantees that it is size, rather than the additional in-
ternal structure, which produces the effect. A test case would be two mono-
morphemic items that display an important contrast in length. 
Finally, the original size-based generalisation has long been reana-
lysed in the literature either along the lines discussed, or according to eu-
rhythmic properties of speech. Ghini (1993) is at the origin of the latter line 
of thought, while Sandalo & Truckenbrodt (2002) for example argue for the 
former solution (the authors use a constraint WRAP-XP which requires that 

Relations with Lexical Phonology and the metrical grid 361 
each XP be contained in a phonological phrase, thereby exploiting the addi-
tional structure of "long" items). 
In sum, then, there seems to be little evidence for and yet less appeal 
to analyses where the size of a string contributes to the construction of pro-
sodic constituency. 
 
422  7.4. Conclusion 
 
In sum, Prosodic Phonology has done exactly the right thing ± introducing 
Indirect Reference as the major principle of interface architecture and in-
stalling a no-man's land-based Translator's Office and mapping rules ± but 
for the wrong reason. Non-isomorphism is a non-reason: it exists only if the 
unsupported a priori is assumed that non-local domains are the operative 
interface currency; it evaporates when higher level information is handed 
down through local intervention at the seam between morphemes and 
words. 
The reason that really enforces the existence of Indirect Reference, 
the Translator's Office and mapping is modularity and the concomitant fact 
that phonology does not speak the same language as morpho-syntax. That 
is, any direct transmission of morpho-syntactic information to phonology 
would simply remain without effect since it could not be interpreted. 
 
423 
8. Relations with Lexical Phonology and the metrical grid 
 
424  8.1. Introduction 
 
Let us now look at the relations that Prosodic Phonology entertains with 
other approaches to the representation of morpho-syntactic information in 
phonology. Two cases need to be examined: Lexical Phonology and metri-
cal grids. The question is whether the scope and instruments of Prosodic 
Phonology are in concurrence with these approaches, or whether they are 
complementary.119 
119 Beyond the issue of Prosodic Phonology and hence the interface with other 
modules, there has also been some debate on purely phonology-internal 
grounds regarding the competition between (s/w-labelled) metrical trees and the 
grid. Arguing that the coexistence of both devices is redundant, Kiparsky 
(1979) proposes a tree-only solution. By contrast, Prince (1983) and Selkirk 
(1984), for the sake of the same economy argument, favour a grid-only ap-

362 
Chap 10: Prosodic Phonology, on the representational side 
Roughly speaking, two positions have been taken, one proposing a 
peaceful coexistence, the other arguing for a clear division of labour (with 
metrical grids) and an overt conflict with Lexical Phonology ("either must 
go"). The former view is defended by Nespor & Vogel (1986) (see also 
Nespor 1988, 1990) and Rubach & Booij (1984), Booij (1988, 1992), while 
the latter appears in Selkirk (1984:412ff) and Inkelas (1990). Inkelas is less 
radical than Selkirk in that she empties Lexical Phonology of its content, 
but formally maintains the existence of the empty shell (while Selkirk holds 
that Lexical Phonology has to go). 
As in other areas related to Prosodic Phonology, it is Nespor & Vo-
gel's (1986) view that was widely adopted by phonologists. That is, the 
assumption of prosodic constituency, metrical grids and the architecture of 
Lexical Phonology are taken to be orthogonal issues: phonologists can de-
sign phonological theories that implement either to various degrees without 
this prompting a conflict with other items of the list. 
 
425 
8.2. The metrical grid 
 
426  8.2.1. Selkirk (1984): mapping modifies the (pre-existing) grid 
 
After having introduced the idea of arboreal prosodic structure into the 
field in earlier work (Selkirk 1981 [1978], 1980a,b), Selkirk (1984) aban-
dons prosodic constituency. Now adhering to Prince's (1983) grid-only 
approach, she believes that metrical grids, the new competitor of the Pro-
sodic Hierarchy, is superior and makes most of the prosodic categories 
obsolete (Selkirk 1984:9ff). 
Selkirk (1984:29ff) holds that the function of all prosodic categories 
except the intonational phrase is taken over by the metrical grid. She argues 
that the metrical grid is independently needed because of the parallel be-
tween linguistic and musical/rhythmic structure. Also, grids express promi-
nence relations (strong vs. weak) among elements of the linear string. 
These arguments have originally been made by Liberman (1975), Liberman 
& Prince (1977) and were developed by Prince (1983). They were also 
discussed in §§ 374f. 
 
proach. Liberman & Prince's (1977) original peaceful coexistence where grids 
are derived from metrical trees (later prosodic constituents) has finally become 
unchallenged mainstream under the influence of Hayes (1984), Selkirk (1986), 
Nespor & Vogel (1986) and others. 

Relations with Lexical Phonology and the metrical grid 363 
The only arboreal categories that Selkirk admits are therefore the syl-
lable (which mediates between segments and the grid) and the intonational 
phrase, which is understood as a "sense unit". That is, intonational phrases 
are "units of information structure" and hence have a purely semantic defi-
nition (Selkirk 1984:27f). Therefore, Selkirk concludes that "it is signifi-
cant that the syntax of a sentence in no way determines its intonational 
structure" (Selkirk 1984:408). 
In sum, Selkirk (1984) proposes a version of Prosodic Phonology 
without prosodic constituency. In her system, the idea of the buffer remains 
unmodified, only is the buffer now incarnated by the metrical grid. As in all 
other versions of Prosodic Phonology, the translation of morpho-syntactic 
into phonological structure is done by mapping rules, whose output now is 
the metrical grid. 
The version of the grid that (Selkirk 1984:31ff) adopts, though, is 
particular in that it exists anyway and in absence of any mapping activity 
(while the Prosodic Hierarchy is a creature of mapping rules). This is be-
cause the grid, recall, is motivated independently from any issue related to 
the interface (by musical and rhythmic properties of speech). 
In this environment, Selkirk's (1984) mapping rules basically do two 
things: they either align syllables and specific grid marks, an idea that will 
be central twenty years later in OT (see § 457), or they insert extra grid 
marks at some boundary.120 
An example of the former is the universal rule of "Demi-Beat 
Alignment DBA" which operates on the lowest grid level and says "align 
just one demibeat with every syllable". The two "Basic Beat Rules" also 
contribute to mapping: they align syllables with beats on the second grid 
level on the grounds of their internal structure and their position in regard 
of a particular syntactic domain. For example, "align a syllable of composi-
tional type x with a beat", or "align a syllable in position y with a beat" 
(Selkirk 1984:54ff). Still another activity of mapping is the insertion of new 
grid marks at level 0 ("syntactic silent grid positions"); this is called "Silent 
Demibeat Addition SDA" (Selkirk 1984:305ff) and actually expresses Sel-
kirk's (1972) old idea that sandhi phenomena are more likely to occur at 
high speech tempo. 
Once grid marks are aligned and inserted, proper phonological rules 
(those sensitive to syntax as well as those sensitive to morphology) make 
reference to grid structure, and to nothing else. 
 
120 Selkirk (1986:376) will admit that the latter mechanism tacitly reintroduces 
unbeloved SPE-type boundaries through the back door. 

364 
Chap 10: Prosodic Phonology, on the representational side 
427  8.2.2. Selkirk (1986): the grid is born from mapping on the grounds of 
prosodic constituency 
 
Two years later, Selkirk (1986) redefines the nature of the buffer. That is, 
she takes a more conciliated position that allows for a peaceful coexistence 
of prosodic constituency and the metrical grid. Selkirk admits the existence 
of three layers of prosodic constituency that correspond exactly to the three 
levels of syntactic X-bar structure: the phonological word (X0), the phono-
logical phrase (X'') and an intermediate layer that she terms the "small pho-
nological phrase" (X') (see §§ 395f). 
In this landscape, the metrical grid exists as a parallel phonological 
structure that is created by mapping on the basis of prosodic constituency 
(Selkirk 1986:376). The system thus acknowledges two distinct mapping 
mechanisms that are serially ordered: prosodic constituency is the output of 
regular mapping rules (whose input is morpho-syntactic structure); the grid 
is then created by a second set of mapping rules, whose input is the pro-
sodic constituency. 
The function of the grid, then, is threefold according to Selkirk 
(1986:375f): it represents prominence relations (strong vs. weak), rhythmic 
patterning and sandhi effects (Silent Demibeat Addition, see § 426). 
 
428  8.2.3. Alignment on Nespor & Vogel's peaceful (and modular) coexistence  
 
Selkirk's (1986) move in fact is an alignment on Nespor & Vogel's (1986) 
position, who write on the first page of their book that SPE was wrong be-
cause it did not recognise the fundamentally fragmented nature of phonol-
ogy. 
 
(173) "While such a model [SPE] is appealing for its simplicity and has, indeed, 
yielded many interesting results, it is our contention that this view of pho-
nology is fundamentally inadequate. That is, on the basis of developments in 
phonological theory over the past decade, it seems that the phonological 
component cannot be considered a homogeneous system, but rather must be 
seen as a set of interacting subsystems, each governed by its own principles, 
such as the theories of the metrical grid, lexical phonology, autosegmental 
phonology, and prosodic phonology." Nespor & Vogel (1986:1) 
 
It is to be noted that the argument, which relies on the idea that pho-
nology is manifold, quite obviously owes to the modular architecture of 
grammar that was promoted by contemporary syntactic theory. The idea in 

Relations with Lexical Phonology and the metrical grid 365 
Government and Binding (Chomsky 1981), was that not only linguistic 
disciplines such as syntax and phonology are modules: they also subdivide 
into autonomous sub-modules. Syntax thus accommodated X-bar theory, 
theta theory, barrier theory, government theory, case theory, binding theory 
and control theory (see § 628). 
In this spirit, Nespor & Vogel (1986) talk about sub-systems (the 
word modularity is not used, and no reference to Fodor 1983 is made). The 
implicit reference to modularity, however, is quite remote from the one that 
is discussed in §§ 413, 586: it seems to reduce to the recognition of several 
sub-components within a linguistic discipline. How separate modular enti-
ties are identified and how they communicate are questions that are not on 
Nespor & Vogel's agenda. 
 
In any event, the result of this phonological manifoldness is peaceful 
cohabitation of the Prosodic Hierarchy and the metrical grid. This perspec-
tive was already argued for by Hayes (1984); it is further supported by Sel-
kirk (1986), Nespor & Vogel (1989) and Nespor (1987, 1988, 1990). 
In this environment, the only interface with morpho-syntax is the 
Prosodic Hierarchy, which subsequently is the input for the construction of 
the grid. As for the first mapping from morpho-syntax, the second mapping 
from prosodic constituency to the grid may create non-isomorphic struc-
ture. This occurs for example in the case of so-called stress clash when 
some repair is needed (thirtéen vs. thírteen men). 
Nespor (1990) sums up the general picture as follows. 
 
(174) "Both prosodic structure and the metrical grid are significant levels of repre-
sentation: prosodic structure mediates between syntax and the prosodic 
component of postlexical phonology, and the grid mediates between pro-
sodic phonology and the phonology of rhythm. External sandhi rules (as 
well as internal ones, for that matter) apply on a hierarchy organized into 
constituents, while rhythmic rules apply on a hierarchy that contains only a 
sequence of more or less prominent periodicities. According to this view, 
the interface between syntax and phonology is limited to prosodic phonol-
ogy; in the case of rhythmic phonology one can hardly speak of reference to 
syntax at all." Nespor (1990:244) 
 
This peaceful coexistence appears to be consensual in phonology 
since the late 80s, and to the extent that the grid has survived into more 
recent constraint-based environments, is still practised. 
 

366 
Chap 10: Prosodic Phonology, on the representational side 
429 
8.3. Lexical Phonology I: conflict with Prosodic Phonology 
 
430  8.3.1. No concurrence above the word level 
 
The relation between Prosodic Phonology and Lexical Phonology is clear 
as far as the level above the word is concerned: only the former can de-
scribe the influence of syntax on phonology. Lexical Phonology is a possi-
ble player only below the word level where morphology interacts with 
phonology. 
This is because Lexical Phonology holds that syntactic activity is 
postlexical and phonological processes "automatic" at this level. The tools 
of the theory thus cannot differentiate between syntactic configurations that 
do vs. those that do not provoke some phonological effect. This line of 
division is consensual and clearly stated by Nespor & Vogel (1986:30) (see 
also Selkirk 1986:402 note 6). 
In other words, the scope of Lexical Phonology is a proper subset of 
the scope of Prosodic Phonology, which however nothing prevents from 
also being active below the word level. Therefore it remains to be seen 
what the division of labour below and at the word level looks like. 
 
431 
8.3.2. Hayes (1989 [1984]): Prosodic Phonology above, Lexical Phonology 
below the word level 
 
One option is to say that there is no division of labour at all. That is, Lexi-
cal Phonology and Prosodic Phonology have complementary scope: the 
former operates only below the word level (hence manages morphology), 
while the latter is only competent for conditioning factors at and above the 
word level (hence takes care of syntax). This is the position of Hayes (1989 
[1984]). 
 
(175) "The Prosodic Hierarchy should be construed solely as a theory of syntactic 
juncture, with word-internal juncture handled within the Theory of Lexical 
Phonology." Hayes (1989 [1984]:207) 
 
As a consequence, Hayes' (1989 [1984]) version of the Prosodic Hi-
erarchy excludes syllables and feet, the two layers below the word level: it 
consists only of the five uppermost layers (the phonological word, the clitic 
group, the phonological phrase, the intonational phrase and the phonologi-
cal utterance). Significantly, this division between morphology and syntax 
coincides with the red line that separates categories of the buffer (i.e. that 

Relations with Lexical Phonology and the metrical grid 367 
carry morpho-syntactic information and are top-down constructions) from 
phonological categories (the syllable and feet, i.e. which carry no morpho-
syntactic information and are bottom-up constructions) (see § 401). 
 
432 
8.3.3. Selkirk (1984): Lexical Phonology is redundant and has to go 
 
A question that Hayes does not address is why Lexical Phonology is needed 
in the first place when Prosodic Phonology can do its job. This issue, econ-
omy, is Selkirk's (1984:412ff) central argument: if the Prosodic Hierarchy 
is the only candidate for managing the syntactic influence on phonology, 
and if its scope can be extended to the level below the word, why should 
there be an extra theory that handles the bearing of morphology on phonol-
ogy?121 
The following quote is from the conclusion of Selkirk's 1984 book. 
 
(176) "We see no theoretical or empirical advantage to the Siegel-Allen-Kiparsky 
theory of word formation as a characterization of the syntax of words. We 
have argued instead for characterizing word structure exactly as sentence 
structure is characterized." Selkirk (1984:415) 
 
Selkirk (1984) thus holds that the instructions which generate words 
and sentences are the same (while they are potentially distinct on the stratal 
perspective). Also, in her view the morpho-syntactic tree matters below as 
much as at and above the word level (while it is entirely irrelevant on the 
stratal count). The concern for a "single engine" that builds morphological 
and syntactic structure alike heralds Distributed Morphology, whose central 
claim is that morphology is but lower syntax (see § 533, and specifically 
§540 on Selkirk's work). 
According to Selkirk (1984), Lexical Phonology has to go because it 
is redundant: regular representational devices ± the syntax of words ± can 
do the job. Interestingly, her argument has got nothing to do with Prosodic 
Phonology itself: nothing hinges on any property or on any tenet of this 
 
121 Interestingly, the reverse move is also possible: if there is competition below 
the word level and Lexical Phonology wins, economy calls for the elimination 
of Prosodic Phonology at and above the word level. Hence, as pointed out by 
Kleinhenz (1998:22), there is a natural alliance between Lexical Phonology and 
direct syntax approaches (see § 407): the latter denies the existence of prosodic 
constituency in the postlexical area by making phonology directly refer to syn-
tactic categories. 

368 
Chap 10: Prosodic Phonology, on the representational side 
theory. Selkirk could have made the same point in an environment where 
prosodic constituents ± or the grid for that matter ± are unheard of.122 
Therefore the difference between Selkirk (1984) and Nespor & Vo-
gel's (1986) mainstream position that promotes peaceful coexistence does 
not concern Prosodic Phonology. It is simply about a broader view on the 
interface, about a view beyond the purely representational transmission of 
information for which Prosodic Phonology was designed. While Nespor & 
Vogel do not have any opinion on how the procedural side of the interface 
should work (and hence can live with whatever comes the way), Selkirk 
defends a precise position. 
 
433  8.3.4. Inkelas (1990): Prosodic Phonology with the empty shell of Lexical 
Phonology 
 
Inkelas (1990) may also be counted as support for the position that Lexical 
Phonology has to go because it is superfluous. On her analysis, nothing is 
left of Lexical Phonology, even though she formally leaves the empty shell 
in place. 
Inkelas' (1990:37ff) leading idea is to eliminate syllables and feet 
from the Prosodic Hierarchy (see also Zec 1988, Fitzpatrick-Cole 
1996:306f).123 One good reason for this move was already discussed in 
§401: syllables and feet owe nothing to mapping rules; their existence and 
shape is exclusively motivated by domestic phonological phenomena (they 
are bottom-up constructions). Since the Prosodic Hierarchy is about trans-
mitting extra-phonological information to phonology, syllable and feet are 
not concerned. 
 
122 The only echo of Selkirk's raid on Lexical Phonology that I have come across is 
Mohanan (1982:97ff), who was working on a manuscript of Selkirk (1984). 
Selkirk (1984) and Inkelas (1990, on which more in the following section) set 
aside, Mohanan is also the only text that I am aware of where the conflict be-
tween Lexical Phonology and Prosodic Phonology is made explicit. Mohanan 
ends up proposing a modification of Selkirk's arboreal solution that allows for 
the incorporation of lexical strata. 
123 Hannahs (1995:61ff) argues along similar lines. According to him, the introduc-
tion of prosodic constituency into the lexicon allows us to do away with the 
Lexicon altogether. Unlike Inkelas, however, Hannahs (1995:66f) takes this re-
sult to be particular to French: it depends on the language-specific situation and 
may not be generalised. In Italian for example, he argues, the regular stratal 
analysis of Lexical Phonology is compelling. 

Relations with Lexical Phonology and the metrical grid 369 
Another argument developed by Inkelas (1990:40ff) builds on mis-
matches between syllable/foot structure and prosodic structure. Inkelas 
presents evidence to the end that feet may need to straddle the boundary of 
phonological words, thus violating the basic principle of prosodic architec-
ture, the Strict Layer Hypothesis (§ 383). That is in her example, feet are not 
exhaustively contained in words. 
Up to this point, nothing has been said regarding the relationship be-
tween Prosodic Phonology and Lexical Phonology. If it is true that syllables 
and feet are not prosodic constituents, a waterproof division of labour à la 
Hayes (1989 [1984]) seems to be possible: Prosodic Phonology manages 
the interface with syntax, while Lexical Phonology takes care of the inter-
action with morphology. 
Inkelas (1990:28ff) dismisses this perspective on the grounds of Indi-
rect Reference: according to her, Lexical Phonology makes direct reference 
to morphological categories and is therefore incompatible with Prosodic 
Phonology. 
 
(177) "In its standard formulations, the theory of Lexical Phonology [«] is in-
compatible with the prosodic hierarchy theory. As part of its crucial claim 
that phonological rules can apply at each step of word formation, Lexical 
Phonology has assumed that these rules look directly at morphological 
structure, applying within strings of morphemes supplied to them by the 
morphology. However, this latter assumption is clearly incompatible with 
the Indirect Reference Hypothesis." Inkelas (1990:29f) 
 
In order to put Lexical Phonology in conformity with Indirect Refer-
ence, Inkelas argues, prosodic constituency must extend to the area below 
the word. Like syntactic information at and above the word level, morpho-
logical information must be translated before Lexical Phonology can make 
use of it. The carriers of morphological information are part of the Prosodic 
Hierarchy, but syllables and feet are out of business. Inkelas (1990:33f) 
therefore introduces a new set of prosodic constituents which, just like their 
higher level peers, are created by mapping rules (two other mechanisms, 
irrelevant here, may also bear on their shape). She claims that there are as 
many layers below the word as there are lexical levels in Lexical Phonol-
ogy (but does not name them). 
In the end, Selkirk's (1984) and Inkelas' (1990) positions are quite 
superposable, even as far as representational detail is concerned (compare 
the trees in Selkirk 1984:77 and Inkelas 1990:34f, the former are further 
discussed in § 540). Inkelas' understanding, however, is that her conclusions 
do not harm Lexical Phonology (she calls her model Prosodic Lexical Pho-

370 
Chap 10: Prosodic Phonology, on the representational side 
nology) since her purpose precisely is to restore Lexical Phonology in the 
legal frame of Indirect Reference. 
The critical question, then, is whether Inkelas' model uses strata in 
order to do morpheme grouping, or whether the regular morpho-syntactic 
tree does this job. Her implementation clearly follows the latter option, 
which means that her system has nothing in common with Lexical Phonol-
ogy (whose heart are strata, see §432). 
 
434  8.3.5. Lexical Phonology does not violate Indirect Reference 
 
The purpose of the preceding section was to present a contribution to the 
debate regarding the relationship between Prosodic Phonology and Lexical 
Phonology. Whether Inkelas (1990) is right or not is a different issue. I 
believe she is not, for the premise of her reasoning is wrong: Lexical Pho-
nology does not violate Indirect Reference. Since this question is more 
generally relevant, some discussion is provided below. 
Inkelas (1990) believes that Lexical Phonology does not comply with 
Indirect Reference because of interactionism (§146): the interleaving of 
morphological rules and phonological activity prompts a situation where 
phonological rules apply only to a certain chunk of the word. According to 
Inkelas, this makes phonology sensitive to a given morphological piece, i.e. 
one that is identified on morphological, rather than on phonological 
grounds. 
This is all true, but Inkelas confuses "phonology applies to X" with 
"phonology has chosen X". Indirect Reference is only violated in the latter 
case, i.e. when the structural description of a phonological rule somehow 
mentions the morphological identity of the string to which it applies. This is 
never the case in Lexical Phonology, where the stratal architecture on the 
contrary has eliminated almost all reference to extra-phonological informa-
tion (see §§ 165f). To an extent unrivalled by other interface theories, Lexi-
cal Phonology thereby affords purely phonological rules in the sense that 
they do not mention any (translated or untranslated) morpho-syntactic in-
formation. 
Nothing is wrong with phonology interpreting only substrings of 
words: this is how cyclic derivation works. When a substring is computed, 
phonology does not know anything about its morphological status, not any 
more than when a whole word is interpreted. Phonology works on whatever 
is submitted for interpretation, and as long as it does not participate in the 
selection of the chunks at hand, there is no direct reference. All implemen-

Relations with Lexical Phonology and the metrical grid 371 
tations of cyclic derivation respect the purely computational role of pho-
nology: chunk-submission is decided elsewhere in SPE, Lexical Phonology, 
Selkirk (1984), Kaye (1995) or Distributed Morphology. 
 
435  8.4. Lexical Phonology II: peaceful coexistence (soft version) 
 
436 
8.4.1. How labour is supposed to be divided: "direct reference to 
morphological structure" 
 
Contrasting with Hayes' (1989 [1984]) division of labour and Selkirk's 
elimination of Lexical Phonology (or Inkelas' transformation of Lexical 
Phonology into prosodic constituency), a third option is peaceful coexis-
tence of Lexical Phonology and Prosodic Phonology. This is Nespor & 
Vogel's (1982:226, 1986:18f, 27ff) take which, like in other areas of Pro-
sodic Phonology, has become mainstream. 
Peaceful coexistence means that certain phonological processes 
which have a morphological conditioning are managed by the tools of 
Lexical Phonology, while others make reference to prosodic constituency. 
The rationale according to which the labour should be divided is explained 
by Nespor & Vogel (1986:18).124 
(178) "There are, of course, also phonological processes that must make direct 
reference to morphological structure and/or specific morphological elements 
in the formulation of their environments. Such rules must clearly be ordered 
before the rules that apply in a strictly phonological domain, since, as we 
have mentioned, at this point the morphological structure is no longer avail-
able. Since such morpho-phonological rules are different from purely pho-
nological rules that are the subject of the present work, we will not discuss 
further how this type of interaction between morphology and phonology 
must be handled. We will assume here that morpho-phonological processes 
are accounted for by a different type of mechanism, such as the one pro-
posed recently within the framework of lexical phonology." Nespor & Vo-
gel (1986:18) 
 
The critical contrast is thus between purely phonological rules and 
those that make "reference to morphological structure and/or specific mor-
 
124 This position is reiterated by Nespor & Ralli (1996:361f). Nespor & Vogel 
(1982) on the other hand do not address the issue. 

372 
Chap 10: Prosodic Phonology, on the representational side 
phological elements". The Prosodic Hierarchy, of course, counts as a purely 
phonological item. 
 
437  8.4.2. There is no natural division of rules into "purely phonological" vs. 
"morpho-phonological" 
 
There are two worries with this definition: for one thing, it is not true that 
rules in Lexical Phonology make direct reference to morphological struc-
ture and/or specific morphological elements. This seems to have been a 
common belief in the mid 80s: it also grounds Inkelas' (1990) idea that 
Lexical Phonology violates Indirect Reference (§ 433). It was shown in 
§434 that this is not the case. Rather the contrary is true: Lexical Phonology 
has eliminated (almost) all reference to morphological diacritics and 
boundaries (§§ 163, 213). 
The second worry is that there are no grounds for deciding whether 
or not a given rule makes "reference to morphological structure and/or spe-
cific morphological elements". There is no natural division of that kind 
among phonological rules. Nespor & Vogel (1986) do not mention that on 
the count of Prosodic Phonology, mapping rules decide whether or not (and 
how) morpho-syntactic structure is transformed into "purely phonological" 
prosodic structure. 
For any phonologically relevant morphological division, then, who 
decides whether there is a mapping rule that translates it into prosodic con-
stituency? The mapping mechanism is poorly understood (§ 386) and en-
tirely unconstrained (§ 393): anything and its reverse can be a mapping rule. 
Hence whether or not some morphological division is reincarnated in terms 
of prosodic constituency depends on the taste of the analyst ± there is cer-
tainly nothing in the phenomena themselves that predestines them for trans-
lation (or makes them recalcitrant). 
Another way to put things is to ask what would be a phonologically 
relevant morphological division that is not translated into prosodic con-
stituency. And why should there be a prohibition of translation in the first 
place? Nespor & Vogel (1986) seem to take a landscape for granted where 
these questions have been answered, hence where rules fall into two natural 
classes: one that makes reference to translated morphological properties 
(which are thus managed by Prosodic Phonology), another that makes ref-
erence to non-translated morphological properties (which are dealt with by 
Lexical Phonology). Such a division does not exist, and the only way to 
introduce it would be by an arbitrary decision of the analyst. 

Relations with Lexical Phonology and the metrical grid 373 
438  8.4.3. Two examples 
 
Let us consider two examples from Nespor & Vogel (1986:28f) for the sake 
of illustration. In English, the place of the prefix-final nasal assimilates to 
the following stop in i[m]-possible (compare with i[n]-audible), but not in 
u[n]-predicatable. Nespor & Vogel argue that 
 
(179) "the formulation of Nasal Assimilation must take into account information 
about the morphological structure of the words in question. This type of rule 
is, therefore, different in nature from the strictly phonological rules we will 
consider in subsequent chapters of this book." Nespor & Vogel (1986:28) 
 
They thus try to sell a decision that was made by the analyst for a 
natural property of the rule in question. That is, Nespor & Vogel do not 
mention the reason why the level 1 vs. level 2 distinction which is at stake 
(see §§ 94, 167 where nasal assimilation was discussed at greater length) is 
not represented in prosodic structure: because somebody has decided that 
mapping rules are unable to divide affixes into two classes, one sharing a 
prosodic constituent with the root, the other ending up in a constituent of its 
own. 
Nothing, however, withstands this to be done: mapping rules would 
just need to be tailored in that sense. In actual fact, this option is chosen by 
Rubach & Booij (1984:12ff) and Booij (1992:53): the prefix un-, is made a 
phonological word of its own. A purely phonological rule, then, can assimi-
late nasals to following obstruents within phonological words. The prefix 
in- will be affected since it is merged with the prosodic word of the root 
([in-possible]PW), while un-predictable offers no PW-internal nasal-
obstruent sequence and hence escapes assimilation ([un]PW[predictable]PW]. 
Nasal Assimilation is thus a good witness of the fact that the "purely 
phonological" treatment of an alternation is a matter of taste of the analyst, 
rather than a natural property of the phenomenon itself. 
Another example quoted by Nespor & Vogel (1986:29) is category-
sensitive stress placement in English: récord, pérvert, éxtract (nouns) vs. 
recórd, pervért, extráct (verbs) and the like. Nespor & Vogel declare this 
kind of phenomenon out of scope for Prosodic Phonology visibly because 
they cannot imagine that mapping rules may be sensitive to major catego-
ries. Nothing, however, prevents mapping rules from taking into account 
morpho-syntactic categories. If the analyst decided to write a category-

374 
Chap 10: Prosodic Phonology, on the representational side 
sensitive mapping rule, the alteration at hand would become "purely phono-
logical" and thus fall into the scope of Prosodic Phonology.125 
In sum, there does not appear to be any morphological division that 
mapping rules could not translate into prosodic constituency. Hence peace-
ful coexistence is built on sand: two mechanisms can hardly coexist if no-
body knows how the labour is divided. 
 
439  8.4.4. Peaceful coexistence supposes split mapping 
 
Peaceful coexistence also bears on the position of mapping in the overall 
derivational architecture. 
Nespor & Vogel (1986:18f) point out that mapping cannot simply 
apply after the Lexicon of Lexical Phonology since it relies on morphologi-
cal divisions which, according to Lexical Phonology, are erased at the end 
of each stratum (bracket erasure, see § 167). That is, morphological struc-
ture is no longer available postlexically ± the no look-back mechanism in 
Lexical Phonology that embodies the insight of Praguian segregation 
(§ 174). 
The solution that Nespor & Vogel (1986:19) favour divides mapping 
rules into two sets: those that work on morphological structure, and those 
whose input is syntactic structure. The former apply before Lexical Pho-
nology, while the latter intervene postlexically. Ten years later, Nespor & 
Ralli (1996:361f) confirm this split mapping mechanism. 
What this means is that Praguian segregation (§ 153) is catered into 
Prosodic Phonology, and that this separate treatment of morphology and 
syntax is a direct consequence of peaceful cohabitation. Certainly an un-
warranted consequence since one goal of Prosodic Phonology originally 
was to provide a uniform screen (the Prosodic Hierarchy) for the reference 
to all phonologically relevant morpho-syntactic information. 
 
440  8.5. Lexical Phonology III: peaceful coexistence (radical version) 
 
Finally, a fourth way of looking at the relationship between Lexical Pho-
nology and Prosodic Phonology is a radicalised version of Nespor & Vo-
 
125 Independently of the issue discussed here, category-sensitive stress is an obvi-
ous and well-known problem child for the generalisation discussed in § 398 ac-
cording to which phonology may react on morpho-syntactic structure, but not 
on labels. Further discussion is provided in § 752. 

Relations with Lexical Phonology and the metrical grid 375 
gel's (1986) peaceful cohabitation: below the word level, phonological rules 
make random reference to either morphological structure or prosodic con-
stituency, and there is no principle that defines which phenomena use one 
or the other strategy. Lexical Phonology and Prosodic Phonology are thus 
both candidates for managing everything that is going on below the word 
level; whether one or the other comes to bear is random and unimportant. 
This approach is argued for by Rubach & Booij (1984) as well as by 
Booij (1988, 1992), Booij & Lieber (1993), Szpyra (1989:183ff), Vogel 
(1991) and Hannahs (1995:2); its modern heirs are Stratal OT and DOT 
(see §§ 477, 483). 
These authors and Nespor & Vogel (1986) march in opposite direc-
tions in order to set up peaceful coexistence: while the latter come from 
Prosodic Phonology and try to integrate the mechanisms of Lexical Pho-
nology, the former root in Lexical Phonology and attempt to incorporate the 
Prosodic Hierarchy into their system. 
Following this track, the literature quoted always aims to show that 
prosodic constituency, including the phonological word, must be available 
in the Lexicon. Examples are Rubach & Booij (1984), Booij (1988, 1992), 
Inkelas (1990), Vogel (1991) and Hannahs (1995). At the same time, thus, 
these authors take Lexical Phonology for granted, to the effect that the 
question whether Prosodic Phonology could take over the functions of 
Lexical Phonology is not a subject of debate. 
In this approach, the difference between Lexical Phonology and Pro-
sodic Phonology becomes a question of perspective: both theories cover the 
same empirical field, but look at it from the representational or the proce-
dural point of view. 
 
(180) "Lexical Phonology concerns the derivational aspect of phonological theory, 
and Prosodic Phonology concerns the representational aspect of phonology."
(Booij 1988:63). 
 
Also, Rubach & Booij (1984) and Rubach (1984:221ff) use prosodic 
constituency in order to account for so-called bracketing paradoxes (see 
§243). The structure of un-happi-er should be [[un [happy]] er] since it 
means "more unhappy", rather than "not more happy": un- has scope over 
the rest of the word. Phonologically, however, the structure should be 
[un [[happi] er]] since the synthetic comparative -er attaches only to stems 
with maximally two syllables (big - bigger, happy - happier); adjectives 
with more syllables have an analytic comparative (beautiful -

376 
Chap 10: Prosodic Phonology, on the representational side 
*beautifuller/more beautiful). In order to get the synthetic un-happi-er,
thus, -er should be concatenated before un- is added. 
Rubach & Booij (1984) propose that in most cases phonological 
structure is a function of morphological structure, but sometimes both do 
not coincide. That is, the phonological constituent structure is the Prosodic 
Hierarchy, which according to non-isomorphism may not replicate morpho-
syntactic divisions. Unhappier, then, is a case of readjusted mapping: the 
structure that is used by morpho-syntax is the one required by the scope of 
un-, while prosodic structure is looked at by the phonological mechanism 
that counts syllables. That is, the prosodic phrasing of unhappier isolates 
the prefix: [un]m[happy]m is the output of mapping (subscript "m" is 
Rubach & Booij's prosodic constituent "mot", the classical prosodicw-
Word). The syllable-counting mechanism then applies to the mot, and 
hence allows for the attachment of the synthetic -er.
Without this solution, the paradox is a serious problem for Lexical 
Phonology that Rubach & Booij (1984) assume: lexical strata imply that 
phonology applies after every step in the word formation. Mismatches are 
thus predicted not to exist. On the analysis presented, however, the "out-
sourcing" of allomorph selection to the Prosodic Hierarchy saves Lexical 
Phonology. Therefore Rubach & Booij (1984:24) conclude their article by 
saying that "the theory of prosodic phonology also functions as a well-
motivated 'protective belt' for the theory of Lexical Phonology." 
Finally, Booij (1988, 1992) takes the fact that cyclic, hence lexical 
rules, refer to syllable- or foot structure as a proof that prosodic constitu-
ency, which includes these categories, is present in the lexicon. On the 
other hand, lexical rules make also reference to morphological structure. 
According to Booij (1988:72), this is witnessed by rules that refer directly 
to morpho-syntactic labels such as "the final syllable is extrametrical in 
adjectives" (a rule proposed by Hayes 1982). 
On this count, Indirect Reference is thus nothing that marshals inter-
face activity: direct syntax cohabitates peacefully with prosodic constitu-
ency and the derivational system of Lexical Phonology. In other words, 
everything that interface theory has produced since SPE is scrambled. The 
cocktail, then, may well be made of ingredients that are incompatible with 
one another or do the same job. Manifoldness allows for a larger empirical 
coverage and hence appears to be an advantage. 
 

Relations with Lexical Phonology and the metrical grid 377 
441  8.6. Conclusion 
 
At least two conclusions may be drawn from the foregoing pages. There is 
competition between Prosodic Phonology and Lexical Phonology at and 
below the word level, and peaceful coexistence does not work in the way 
imagined by Nespor & Vogel (1986). 
No property of morphologically conditioned phonological phenom-
ena allows for a classification into clients of Prosodic Phonology and cli-
ents of Lexical Phonology. No waterproof division of labour between the 
two theories may thus be elaborated, which means that Nespor & Vogel's 
(1986) perspective is not workable. 
For a given phenomenon, analyses using either the technology of 
Lexical Phonology or Prosodic Phonology are possible, and the analyst 
may well be unable to decide which one fares better or is more appropriate. 
We are thus left with the radical option proposed by the Lexical Pho-
nology quarters: anything goes. A given phenomenon may randomly have a 
stratal or a prosodic analysis. This is certainly not how one would expect a 
competition to be solved in science. It is common to say that in our current 
understanding we are unable to tell two competitors apart. But granting 
them equal rights without willingness to show that either (or both) need(s) 
to be abandoned is a questionable position. 
We will see in § 483 that the modern heirs of Lexical Phonology, 
Stratal OT and DOT, continue this strand: both stratal and prosodic tech-
nology is available, and there is no division of labour (even though Stratal 
OT attempts to restrict the morphological impact on phonology, see § 490). 
Selkirk's (1984) option (and, to a certain extent, Inkelas' 1990) ap-
pears to be more consistent: she acknowledges that two solutions compete 
for the same set of phenomena and draws the conclusion that one has to go. 
Calling on Occam's Razor, she argues that Lexical Phonology is redundant 
since it needs extra technology (strata) that come for free when cyclic deri-
vation is practised on the grounds of regular morpho-syntactic structure. 
She also makes the point that the empirical scope of Lexical Phonology 
(morphology) is a proper subset of the scope of Prosodic Phonology, which 
covers both the interaction with morphology and syntax. 
 

378 
Chap 10: Prosodic Phonology, on the representational side 
442 
9. Prosodic Morphology 
 
443  9.1. Representational and non-representational incarnations 
 
Before closing this chapter, due mention needs to be made of Prosodic 
Morphology. Not so much because this theory is concerned with the inter-
face (it is not), but because it was very influential and eventually opened 
out into Optimality Theory. Indeed, two central mechanisms of OT, corre-
spondence and alignment, originate in Prosodic Morphology, as McCarthy 
& Prince (2001:vii) explain in the introduction to the ROA version of the 
original 1986 manuscript (McCarthy & Prince 1986, of which there is also 
a 1996 version: McCarthy & Prince 1996 [1986]). 
Prosodic Morphology has known two periods, representational and 
anti-representational. We will only be concerned with the former in this 
section, which expressed relevant generalisations by means of the units of 
the Prosodic Hierarchy (up to the word level, i.e. moras, syllables, feet and 
eventually the prosodic word). After the advent of OT, here as elsewhere 
representational units could not be considered linguistic primes anymore 
for the only decision-making entity is the constraint chamber: generalisa-
tions must be expressed in terms of processes, not of objects (see Scheer 
2010a). The constraint-based version of Prosodic Morphology is called 
Generalized Template Theory. 
The rich body of literature of the representational period before tem-
plates per se were abandoned includes McCarthy & Prince (1988, 1990) 
and many others; the OT-inspired dissolution of templates into constraint 
interaction was engaged in McCarthy & Prince (1994, 1995a,b) and is cur-
rently developed in ongoing work. Downing (2006) provides a comprehen-
sive and informed overview of both periods and shows how they are inter-
connected. 
 
444  9.2. Representational period: prosodic morphemes are units of the Prosodic 
Hierarchy 
 
445  9.2.1. A typical example: reduplication 
 
In its representational incarnation, Prosodic Morphology uses the autoseg-
mental structure of the Prosodic Hierarchy in order to analyse purely pho-
nological patterns that are related to morphological activity and call for a 
phonological generalisation. A good example, typical and foundational for 

Prosodic Morphology 379 
Prosodic Morphology, is reduplication: the cross-linguistic record shows 
that reduplicated items are never arbitrary in number and sequence. That is, 
the reduplicative morpheme picks segments from the base according to a 
non-arbitrary mechanism where the size and the linear order of reduplicated 
items is predetermined. Descriptions of reduplication, then, necessarily 
mention the number and linear order of consonants and vowels: "take the 
first CV pair of the base and concatenate it to the left of the base" would be 
a typical instruction.  
The goal of Prosodic Morphology is to capture the fact that size (and 
linearity) restrictions on the output of morphological operations are not 
random: it is not the case that any arbitrary string of segments may be the 
required output shape of reduplication (or any other relevant process). 
Rather, the mechanics of constant morpheme shape conform to recurrent 
patterns, and these patterns, Prosodic Morphology contends, are surface 
manifestations of the lower units of the Prosodic Hierarchy (up to the pro-
sodic word). In other words, the real identity of reduplicative morphemes is 
not segmental (although some segmental properties may be pre-specified): 
their lexical identity is a syllable or a foot, which are then "filled" by seg-
mental material from the base and impose their inherent restrictions on size 
and linearity (no arbitrary strings). 
 
446  9.2.2. Another typical example: (Semitic) templatic morphology 
 
Another typical area of competence of Prosodic Morphology is Semitic 
templatic morphology. In Classical Arabic for example, so-called measure I 
forms of verbs conform to the template CVCVC- (e.g. katab- "to write"), 
while measure II forms follow CVCCVC- (kattab-, gemination of the me-
dial consonant). Since a specific meaning is associated to measures (I is 
unmarked, II is intensive/iterative, and there are a number of measures), 
they must be considered morphemes. Therefore the bare information re-
garding the sequences of Cs and Vs must be somehow stored in the lexicon 
independently of the segmental content, but together with their meaning, 
i.e. "unmarked", "intensive/iterative" etc.  
McCarthy (1979) transposes the traditional analysis of Arabic gram-
marians into the emerging autosegmental frame, but leaves it at an amor-
phous list of templates that are made of sequences of Cs and Vs (to which 
melody is attached). McCarthy & Prince (1996 [1986]:2ff) argue that this 
misses the generalisation that these CV-strings are not arbitrary. Rather, 
they conform to well-formedness conditions of units of the Prosodic Hier-

380 
Chap 10: Prosodic Phonology, on the representational side 
archy: Arabic for example does not have any template of the kind 
CVCCCVC-. This is, McCarthy & Prince argue, because templates imitate 
the prosodic structure of the language at hand: in our case, Arabic syllabifi-
cation disallows triconsonantal clusters. Therefore the constant shape of 
measure I, II etc. morphemes must be recorded in terms of prosodic units, 
syllables in our case, rather than segments or Cs and Vs. 
 
447  9.2.3. Moras, syllables and feet do not carry any morpho-syntactic 
information 
 
This line of reasoning was extended to all instances where languages show 
morphologically defined constructions whose output has a constant shape. 
So-called prosodic morphemes capture relevant generalisations: they are 
made of units of the Prosodic Hierarchy which impose size and shape re-
strictions, thereby producing the canonical forms observed. Aside of redu-
plication and templatic morphology, other phenomena that are typically 
treated in terms of prosodic morphemes are minimal word constraints, in-
fixation and fixed segmentism. 
In any event, we are only talking about phenomena and representa-
tional items that concern chunk sizes at and below the word level: Prosodic 
Morphology is about (prosodic) morphemes. Interestingly, the aforemen-
tioned (§ 401) front line between mapping-created, top-down constructed 
units (the prosodic word and above) and truly phonological units which are 
the result of a bottom-up construction and owe nothing to mapping also 
surfaces in the discussion of Prosodic Morphology: while the prosodic 
word was explicitly included into the list of prosodic items that can make 
prosodic morphemes by McCarthy & Prince (1996 [1986]:6), its presence 
was called into question later on (see the discussion in Downing 2006:8f). 
In its representational skin, Prosodic Morphology may be character-
ized as an application of the autosegmental idea (which was still fresh in 
the mid-80s) to the phenomenon of constant shape and canonical forms. 
The "prosodic" aspect is more a matter of the terminology chosen than a 
claim regarding the Prosodic Hierarchy: all autosegmental categories above 
the skeleton were organized in the Prosodic Hierarchy, hence anybody who 
uses units of this hierarchy will come across the word "prosodic".  
Prosodic Morphology as it stood then was thus unrelated to the sub-
ject matter of the present book, i.e. the transmission or encoding of mor-
pho-syntactic information to/in phonology: relevant units ± moras, sylla-
bles, feet ± do not carry any such information. 

Prosodic Morphology 381 
448  9.3. Generalized Template Theory: morphology marshals phonology 
 
The take of Generalized Template Theory is significantly different. Con-
stant shape is not interpreted anymore as a consequence of phonological 
units whose genesis owes nothing to morpho-syntactic information. The 
units in question ± moras, syllables, feet ± are still the same, but their gene-
sis is now impacted by morpho-syntax: they are correlated ± aligned is the 
technical term ± with three types of morphological units, the affix, the root 
and the stem. This means that the parsing of lower level units into higher 
level units ± for example the syllabification of segments ± obeys regular 
phonological rules, but also depends on instructions regarding the edges of 
affixes, stems and roots. In other words, the units of the Prosodic Hierarchy 
below the word level are now subjected to mapping as well: they cease to 
be purely bottom-up constructions. 
In order to see how alignment constraints transmit morpho-syntactic 
information to phonology, let us consider a simple example from German 
(Kleinhenz 1998:39f). The word auf-essen "to eat up" is made of a stem 
(essen) and a prefix (auf). It is realised with an epenthetic glottal stop 
auf-ʔessen. The glottal stop is non-contrastive: it is always filled in word-
initially in case the word begins with a vowel underlyingly. 
According to Kleinhenz' analysis, the pronunciation at hand is the re-
sult of the ranking ONSET >> ALIGN (Stem, L, PrWd, L) >> DEP. The 
alignment constraint demands that the beginning of the stem coincides with 
the beginning of a prosodic word. Regular mapping would express the 
same requirement by the fact of assigning two separate prosodic words to 
the prefix and to the stem. 
Now ONSET demands the presence of a consonant in the first syllable 
of essen ± hence the epenthetic glottal stop. The concurrent solution that 
syllabifies the prefix-final consonant into the onset of the stem fails be-
cause of ALIGN: in au.fessen the stem and the prosodic word would be mis-
aligned, and this is fatal since ALIGN outranks the epenthesis-hostile DEP.
In a language with the reverse ranking, au.fessen without glottal stop would 
be optimal. 
Alignment constraints thus inject morphological information into 
syllabification and footing, which in the earlier version of Prosodic Mor-
phology parsed the string on the basis of phonological information alone. 
Downing (2006) describes the old ambition (constant shape) and the new 
way to go about it in Generalized Template Theory as under  (181) below. 
 

382 
Chap 10: Prosodic Phonology, on the representational side 
(181) "The central proposal of the Generalized Template Theory (GTT) of prosodic mor-
pheme shapes is that prosodic morphemes have a restricted repertoire of pro-
sodic shapes because they draw on the canonical shapes of a restricted repertoire 
of morphological categories. These canonical shapes follow from general theo-
retical principles correlating particular morphological categories (Stem, Root, 
Affix) with particular prosodic constituents and from a constraint grammar defining 
the canonical shapes as unmarked." Downing (2006:35) 
 
The introduction of this system leads over to the chapter on Optimal-
ity Theory where constraint-based mapping is generalised: as there are no 
rules there can be no mapping rules either. But of course there is mapping, 
i.e. the transmission of morpho-syntactic information to phonology, and its 
encoding in from of the Prosodic Hierarchy. The ALIGN (and WRAP) con-
straint families are central to this way of creating the Prosodic Hierarchy. 
The take of OT regarding the interface in general and constraint-based 
mapping in particular is introduced in the following chapter. 
 
449 
10. Conclusion: translation yes, buffer no 
 
Looking back at what has been done on the representational side of the 
interface since SPE, it appears that Prosodic Phonology has inherited the 
central concepts of Chomsky & Halle, which occasionally may have been 
(re)named: Indirect Reference, the existence of a Translator's Office, non-
isomorphism, mapping, the Black Box (readjustment rules). Prosodic Pho-
nology is to be credited for weaving a consistent theory based on these 
ingredients. 
Namely the institutionalisation (and exceptionlessness) of Indirect 
Reference and a Translator's Office that is located in modular no man's land 
is a landmark in the evolution of interface architecture. Even though this 
was done for the wrong reason (non-isomorphism), it is the faithful em-
bodiment of intermodular communication in Fodorian modular architecture 
(on which more in the Interlude § 586). Strangely enough, though, the 
modular argument (which is much akin to structuralist Level Independence, 
see § 415) does not appear to be afforded in the Prosodic Phonology litera-
ture. 
Valuable progress has also been made on the empirical side: Prosodic 
Phonology has produced a large number of detailed studies regarding mor-
pho-syntactic influence on phonology. The intensive study of the mapping 
mechanism, although ultimately still inconclusive, has greatly broadened 
our knowledge of how morpho-syntactic information seeps into phonology. 

Conclusion: translation yes, buffer no 383 
Finally, an internal and a global concern need to be mentioned. The 
former is about the hybrid character of the Prosodic Hierarchy, which en-
compasses layers that store morpho-syntactic information (the buffer) as 
much as constituents which have got nothing to do with extra-phonological 
information. The former are (top-down) constructed by mapping rules, 
while the latter (syllable and feet) are bottom-up constructions and exist in 
domestic phonology in absence of any issue related to morpho-syntactic 
information (§ 401). 
This hybridity is certainly not recommendable. An interface theory 
ought to provide for a phonological representation of phonologically rele-
vant extra-phonological information, and for nothing else. Making the same 
formal device endorse domestic phonological structure as much as the out-
put of the Translator's Office is a misconception of the interface. This issue 
was pointed out most sharply by Inkelas (1990) (§ 433). 
The global concern is about the body of Prosodic Phonology itself: 
the Prosodic Hierarchy is made of domains, and it is a diacritic. The tradi-
tional interface currency, boundaries, was evacuated in favour of domains 
with no good reason and hardly any discussion, in any event in absence of 
contrastive argumentation. The diacritic argument levelled against bounda-
ries was made in the erroneous belief that the alternative, domains, is non-
diacritic. The discussion of Prosodic Phonology is consensual in at least 
one point: whatever the way of encoding interface information, diacritics 
do not qualify. If in an autosegmental guise, the Prosodic Hierarchy is a 
diacritic as much as SPE-type boundaries ± hence both have to go (Scheer 
2008a). 
The key to the problem, then, is the fact that the diacritic character of 
boundaries is but one aspect of their identity. It has constantly been con-
fused with the property that really sets boundaries apart from domains: 
local vs. non-local action. 
The real question which is still pending at the end of this discussion, 
thus, is whether higher-level intervention in phonology should be local or 
non-local (more on this issue in § 706). Whatever the answer, a non-diacritic 
implementation is mandatory. 
 


Chapter 11 
450  Optimality Theory 
451  1. Setting the scene 
 
452  1.1. OT makes no contribution on the representational side 
 
Optimality Theory is a theory of constraint interaction, hence of computa-
tion ± not of representation. There are no genuine OT representations: the 
theory makes no claim regarding objects; hence using this or that type of 
representation is the responsibility of the analyst and subject to debate. 
This state of affairs is remarkably different from the situation that 
prevails in all other frameworks which we have come across thus far: theo-
ries propose a particular representational vocabulary, and this vocabulary is 
part of their identity. Hence the basic phonological currency in structuralist 
times were phonemes; SPE then installed segments (or distinctive features), 
before autosegmental structure became the regular representational cur-
rency in the early 80s. It was pointed out in § 72 that each stage of the evo-
lution of phonological representations comes with its own interface theory 
± or rather, whatever the current representational currency is also the output 
of translation. Hence morpho-syntactic information was carried by (junc-
ture) phonemes in structuralist times, by [-segment] segments (boundaries) 
in SPE, and by autosegmental prosodic constituency since the 80s. 
Given that OT does not make any genuine contribution on the repre-
sentational side, there is no additional step to be expected on this path. OT 
uses the representational stock of the 80s, which in the realm of the inter-
face means that the Prosodic Hierarchy is taken over. It is simply adapted to 
the constraint-based environment. 
 
453  1.2. Representations marshalled by constraints 
 
Another aspect of OT is that representations are not granted any sovereign 
arbitral award. The only thing in OT that determines the (relative) gram-
maticality of an item is constraint interaction. That is, an eventual arbitral 
award issued by a representation (such as line crossing for example) may 
well be outranked by some other constraints. Therefore the rule of the game 
is quite different when compared to theories that are not constraint-based: 

386 
Chap 11: Optimality Theory 
when a representation is ill-formed, this may or may not mean that it is out 
± representations as such do not mean anything (Scheer 2010a). 
On the other hand, representations are also the result of constraint in-
teraction: the output orientation of OT, embodied for example in Richness 
of the Base, does not allow for specific structure in underlying forms. 
Hence structure must be emergent, rather than given. It is therefore a prod-
uct of constraint interaction, rather than primitive (e.g. Itô et al. 2004). 
In sum, the almightiness of constraints in OT also subordinates rep-
resentations, which originate in the constraint chamber and are marshalled 
by it.126 
Like other representational objects from the 80s, prosodic constitu-
ency is imported into the OT environment without modification: the famil-
iar categories such as the phonological word, the phonological phrase etc. 
are taken over. The way they stock and unload morpho-syntactic informa-
tion, though, has been adapted. That is, prosodic constituency is not created 
by mapping rules anymore, and phonological rules do not make reference 
to it. Instead of rules, both mapping and reference are assured by a set of 
specialised constraints (§ 457): the ALIGN and WRAP families express the 
"desire" of a certain matching between units of the Prosodic Hierarchy and 
morpho-syntactic structure. These constraints, as violable as all others, are 
in competition with purely phonological constraints in the same ranking. 
The result, then, determines the kind of morpho-syntactic influence that 
phonology experiences. 
 
454  1.3. Anti-cyclicity and the serial offspring of Lexical Phonology 
 
Strictly parallel computation is the heart of OT.127 In a parallel environ-
ment, derivational mechanisms are outlawed. This is why OT has produced 
 
126 The balance of structure (representations) and process (computation: con-
straints) is the prism that St. Anderson (1985) uses in order to look at the evolu-
tion of phonology. In Vol.1:§305 (also Scheer 2003b), this issue is discussed in 
the light of OT, where computation is king. The factual elimination of structure 
as a player in OT is fully assumed and actually welcomed by the mainstream 
literature. In the outlook of his textbook on OT, Kager (1999:420f) for example 
writes that "a second major development that is likely to continue is a reduction 
of the role of representations in favour of constraint interaction." 
127 Although there is also a version where computation is serial, albeit in a way 
that is different from extrinsic rule ordering (see Scheer forth): Prince & 
Smolensky's (1993) Harmonic Serialism and its revival by McCarthy (2007). 

Setting the scene 387 
a body of anti-cyclicity literature, i.e. where it is argued that OT is incom-
patible with cyclic spell-out. Non-serial alternatives are therefore devel-
oped: in the same way as for the closely related issue of opacity, several 
cyclicity killers have been proposed (which appear to be competing, § 464). 
This has also led to new ways of implementing morpheme-specific 
phonologies: unlike on the stratal count where strings necessarily run 
through later strata and experience the associated stratum-specific computa-
tion, a parallel alternative subjects strings only to the computational system 
that they are specified for. Co-phonologies and indexed constraints repre-
sent this architecture, where morpheme-specific mini-grammars act in par-
allel, rather than being serially ordered (§ 478). 
Since the stratal architecture is derivational (strata are serially or-
dered), Stratal OT and DOT, the modern continuators of Lexical Phonol-
ogy, were unwarranted in the original parallel environment of OT (§ 483). 
The question, though, is whether the parallel ambition of OT applies only 
to phonology proper or extends to interface operations (§ 464). While the 
answer is not obvious a priori, the practice of OT at least in the 90s clearly 
imposed parallel computation also at the interface.  
This ties in with another issue: current practice in OT is in overt con-
flict with basic generative principles, a fact that is hardly reflected in the 
literature. That is, modular contours are blurred if existent at all 
(§§ 469, 523), inside-out interpretation is abandoned together with cyclicity 
(§ 468), and the procedural aspect of the interface seems to be denied alto-
gether (thus dispensing with Interface Dualism).  
Relevant in this context is also an alternative to morpheme-specific 
phonologies that is entertained in OT: so-called interface constraints make 
direct reference to "designated" morpho-syntactic categories and therefore 
overtly violate the principle of Indirect Reference (§ 406); direct syntax 
approaches are also common practice elsewhere in OT (ALIGN and WRAP). 
The faulty position of OT in regard of modularity is discussed at greater 
length in § 523. We have seen in previous chapters, though, that OT is not 
the only modularity offender; a comparison with other theories is provided 
in § 702. 
Finally, van Oostendorp's Coloured Containment (§ 503) and Orgun's 
Sign-Based Morphology (§ 512, an application of HSPG to the interface) 
 
The book on the derivational residue in OT that Ben Hermans and Marc van 
Oostendorp have edited (Hermans & van Oostendorp (eds.) 1999) and espe-
cially their introduction to the volume provide an (early) overview of the rela-
tionship of OT with serialism. 

388 
Chap 11: Optimality Theory 
are presented. These approaches share a monostratal view on the interface 
where translation (mapping) does not exist and morpho-syntactic informa-
tion is constantly available during phonological computation (direct syntax 
again). 
 
455  2. Adaptation of Prosodic Phonology to the constraint-based 
environment 
 
456  2.1. Introduction 
 
The constraint-based environment either allows or requires adaptations of 
the familiar Prosodic Phonology model to the general OT architecture. The 
disentangling of Selkirk's Strict Layer Hypothesis (SLH, § 383), which was 
monolithic in the 80s, falls into the former category, while anti-cyclicity 
and rule-based mapping are instances of the latter. 
The following pages discuss the adaptation of rule-based mapping 
(§ 457) and the Strict Layer Hypothesis (§ 461) (anti-cyclicity is considered 
in § 464 below). Finally, we also look at how OT treats the mapping puzzle 
± a resident question in the study of the interface (§ 463).  
 
457  2.2. Constraint-based instead of rule-based mapping 
 
458  2.2.1. Mapping understood as the coincidence of constituent edges: ALIGN 
The Prosodic Hierarchy represents the (mis)match of morpho-syntactic 
constituency and phonologically relevant chunks of the linear string. The 
operation that relates both, mapping, may thus be described as the 
(mis)alignment of the edges of morpho-syntactic constituents with the 
edges of prosodic constituents. 
As far as I can see, this implementation of mapping has been intro-
duced by Selkirk (1984:52ff), who builds prosodic structure (the metrical 
grid in her case) by alignment rules (e.g. Basic Beat Rules, Demi-Beat 
Alignment DBA, see § 426). Constituent margins then become the centre of 
interest two years later in Selkirk's (1986) edge-based mapping (§386). 
Finally, McCarthy & Prince (1993) generalise alignment to more empirical 
situations and make it the central tool for the interface with morpho-syntax 
(see Itô & Mester 1999a, McCarthy & Prince 2001:vii, Peperkamp 
1995:227ff for a historical overview). 

Adaptation of Prosodic Phonology to the constraint-based environment 389 
Today ALIGN is a constraint family with a uniform template: the left 
or right edge of a given unit coincides with the left or right edge of another 
unit. The units in question may be phonological, morphological or syntac-
tic, and both units involved in an alignment constraint may belong to the 
same area (phonology, morphology, syntax, see for example Yip 1998). 
 
459  2.2.2. Parallel mapping: translation and reference to prosodic constituency 
are conflated 
 
The following example from German, repeated from § 448 for convenience, 
provides illustration of how alignment works (Kleinhenz 1998:39f). The 
word auf-essen "to eat up" is made of a stem (essen) and a prefix (auf). It is 
realised with an epenthetic glottal stop auf-ʔessen. The glottal stop is non-
contrastive: it is always filled in word-initially in case the word begins with 
a vowel underlyingly. 
According to Kleinhenz' analysis, the pronunciation at hand is the re-
sult of the ranking ONSET >> ALIGN (Stem, L, PrWd, L) >> DEP. The 
alignment constraint demands that the beginning of the stem coincides with 
a prosodic word; regular mapping would express the same requirement by 
the fact of assigning two separate prosodic words to the prefix and to the 
stem. 
Now ONSET demands the presence of a consonant in the first syllable 
of essen ± hence the epenthetic glottal stop. The concurrent solution that 
syllabifies the prefix-final consonant into the onset of the stem fails be-
cause of ALIGN: in au.fessen the stem and the prosodic word would be mis-
aligned, and this is fatal since ALIGN outranks the epenthesis-hostile DEP.
In a language with the reverse ranking, au.fessen without glottal stop would 
be optimal. 
Regular rule-based mapping would describe this variation by a pa-
rameter on the assignment of the prosodic word, which may or may not 
encompass prefixes. That is, the domain of glottal stop insertion is the pro-
sodic word: glottal stops are inserted at their left edge. In German, the pre-
fix makes a prosodic word of its own; the prefix-final consonant cannot 
join essen because there is no syllabification across prosodic word bounda-
ries (in German). Essen will therefore be subject to glottal stop insertion. In 
the hypothetical language where au.fessen is encountered, the prefix and 
the stem cohabitate within a single phonological word: this allows the pre-
fix-final consonant to join essen, and no glottal stop will be inserted. 

390 
Chap 11: Optimality Theory 
As may be seen, OT produces the winner without mentioning any 
particular process and thus without any process (or rule) making reference 
to the Prosodic Hierarchy. The effect is achieved by the interspersing of 
alignment with regular phonological constraints that are not involved in 
issues related to the interface (ONSET and DEP). 
This system significantly contrasts with rule-based mapping: it con-
flates a two-step procedure into one single constraint. On the regular ac-
count, prosodic constituency is first created by mapping; phonological rules 
then make reference to the prosodic structure. These steps are procedurally 
ordered, and domestic phonological rules refer to the carrier of morpho-
syntactic information in the description of their environment, as much as 
they may refer to truly phonological conditions. 
Neither of these mechanisms survives in constraint-based mapping: 
there is no procedural difference between the translation of morpho-
syntactic into prosodic constituency and the reference of phonology to this 
structure. Also, the carriers of phonological computation, constraints in-
stead of rules, do not mention prosodic constituency anymore: ONSET, DEP 
or other constraints do not make reference to the Prosodic Hierarchy. Pro-
sodic structure appears only in one constraint family, ALIGN (and WRAP,
see below), which is specialised into importing morpho-syntactic informa-
tion. 
This looks like a simplification of the mapping mechanism, which of 
course roots in the anti-derivational philosophy of OT: a two-step proce-
dure whereby mapping precedes reference to prosodic constituency is in-
compatible with parallel computation. We will see in § 526 below, though, 
that this evolution, which looks like an advance, creates serious trouble in a 
modular perspective: it gives up the idea that mapping is done in modular 
no-man's land (§ 381). 
 
460  2.2.3. Parametric variation: interaction of ALIGN and WRAP 
A second constraint family that is specialised in mapping has been intro-
duced by Truckenbrodt (1995, 1999): WRAP militates for having all items 
that are dominated by a morpho-syntactic constituent included in the same 
prosodic constituent. For example, WRAP (DP, Phon Phrase) is satisfied 
only if all material of a DP is mapped into one single phonological phrase.  
WRAP and ALIGN create tension: opposite demands are issued. While 
the former militates for the invisibility of morpho-syntactic divisions on the 
phonological side (phonology follows purely domestic rule within a given 

Adaptation of Prosodic Phonology to the constraint-based environment 391 
prosodic constituent), the latter makes morpho-syntactic divisions phonol-
ogically salient. WRAP is therefore said to be cohesional, whereas ALIGN 
has a demarcative function. 
Another aspect of the introduction of WRAP regards the mapping ty-
pology and the expressive power of constraint-based mapping. That is, the 
number of different prosodic phrasings that can be generated by the inter-
leaving of WRAP and ALIGN is much higher than what the simple ordering 
of ALIGN with non-interface constraints produces. 
On the backdrop of the inflational evolution of mapping rules 
(§§ 388f), Selkirk (2000:231f) argues that this is an advantage. She cele-
brates the new factorial possibilities offered by OT in general and the an-
tagonistic WRAP and ALIGN families in particular. As in all other areas of 
grammar, cross-linguistic variation is covered by the factorial typology of 
universal constraints, i.e. the various incarnations of ALIGN and WRAP in 
the case of mapping. And as elsewhere in OT, generative power is consid-
ered to be a good thing. Whether the grammar produces large-scale over-
generation is not a prime concern. In the particular case of mapping at least, 
it does not appear to arouse any debate in the literature. 
 
461  2.3. The Strict Layer Hypothesis made less strict 
 
The Strict Layer Hypothesis (SLH) imposes formal restrictions on prosodic 
arborescence (see § 383): a constituent of layer n must be exhaustively con-
tained within a constituent of the immediately higher layer n+1, and can 
only exhaustively contain constituents of the immediately lower layer n-1. 
Hence there can be no nested constituents, nor can any association line 
bypass a layer. 
Responding to evidence and criticisms that challenge the monolithic 
character of the SLH (e.g. Inkelas 1990, Itô & Mester 2003 [1992], Ladd 
1986, 1996), Selkirk (1996:189ff) recognises that it makes sense to factor 
out four more primitive component constraints which can be manipulated 
independently. Table  (182) below (repeated from § 383) shows the four 
pieces into which Selkirk proposes to cut the SLH. 
Selkirk still holds that (182a,b) are universal principles (hence un-
dominated constraints in OT), but admits that (182b,c) may be violated in 
some cases, which she stresses are limited and local. 
The demotion of the SLH to a partially violable set of heterogeneous 
constraints has been largely adopted in subsequent work (e.g. Vogel 1999, 
Mazzola 1999). 

392 
Chap 11: Optimality Theory 
(182) The Strict Layer Hypothesis cut into pieces 
 
a. Layeredness 
a node of given layer cannot dominate a node of any higher layer (i.e. a 
syllable cannot dominate a foot) 
 
b. Headedness 
each node of layer n must dominate at least one unit of layer n-1. 
 
c. Exhaustivity 
association lines may not bypass any layer: no association of two units 
that belong to non-adjacent layers is allowed. 
 
d. Nonrecursivity 
nested structures are prohibited: no node may dominate a node of the 
same label. 
 
462  2.4. Phase-based mapping 
 
More recently, constraint-based mapping in OT has been impacted by and 
adapted to syntatic Phase Theory (§ 304). Kratzer & Selkirk (2007) intro-
duce the idea that chunks which are defined by the syntax as phases also 
grossly correspond to constituents of the Prosodic Hierarchy. Specifically, 
they propose that "the highest phrase within the spellout domain is spelled 
out as a prosodic major phrase" (Kratzer & Selkirk 2007:106, emphasis in 
original). We are thus still in the environment that was defined by Selkirk 
(1986) where three prosodic constituents are recognised (§ 394): the major 
phrase (called prosodic phrase then, and corresponding to X'' in an X-bar 
structure), the prosodic word (corresponding to X°), and an intermediate 
item called minor phrase (small phonological phrase then, corresponding to 
X'). 
On Kratzer & Selkirk's (conservative: § 773) assumption that only CP 
and vP are phases, the idea is thus that spell-out domains, i.e. CPs and vPs, 
correspond to major phrases on the phonological side. This is supposed to 
be a universal equivalence and the result of mapping; language-specific 
variation in prosodic phrasing is then achieved not by the syntax-phonology 
mapping as before, but by purely phonological "prosodic markedness con-
straints, which operate to produce surface prosodic structures that are more 
nearly phonologically ideal" (Kratzer & Selkirk 2007:126). This is a sig-
nificant departure from a Prosodic Phonology essential: mapping becomes 
universal and phase-driven, and the great amount of language-specific 
variation in prosodic phrasing is achieved in the phonology by a purely 
phonological mechanism. 

Adaptation of Prosodic Phonology to the constraint-based environment 393 
Another issue is the fact that there are more layers of the Prosodic 
Hierarchy than just the major phrase: what happens with them if mapping 
reduces to the equivalence "phase = major phrase". In a note, Kratzer & 
Selkirk (2007:125) hint at the possibility that the "prosodic word could be 
understood as the spellout of lexical (not functional) heads, while intona-
tional phrase could be the spellout of 'comma phrase'." 
Other work along the idea that phases form prosodic islands includes 
Piggott & Newell (2006), Dobashi (2003), Ishihara (2007) and Kahnemuy-
ipour (2009) (Elordieta 2008:274ff provides a survey). Elsewhere, Phase 
Theory has impacted mapping in different ways. Cheng & Downing (2007) 
for example propose alignment constraints that take the phase as an argu-
ment: ALIGN-L(PHASE, INTP) "align the left edge of a phase with the left 
edge of an Intonational Phrase."  
 
463  2.5. Mapping: focus on new factors, but the puzzle is the same as before 
 
Recall from §§ 111, 386 that the mapping puzzle is resident in the study of 
the interface, and a long-standing source of frustration. OT has not contrib-
uted any more to a solution than previous theories. Rather, the OT literature 
moved away from the study of morpho-syntactic influence on phonological 
processes in order to concentrate on mapping-conditioning factors that had 
not been taken into account before, such as information structure and eu-
rhythmy (i.e. the strive towards prosodic constituents of comparable 
length). 
Selkirk (2000) opened this direction, which led to a renewed interest 
in mapping. Unlike in her direction-giving 1986 article (see § 394), the pur-
pose is not to find a means of channelling the inflational variation of pho-
nologically relevant morpho-syntactic configurations. Rather, focus is laid 
on the different factors that may condition the construction of the Prosodic 
Hierarchy. Each type of influence, then, is associated to a particular con-
straint family. 
Selkirk distinguishes five constraint types. 1) ALIGN and WRAP are 
the core of the mapping mechanism, a family that she calls interface con-
straints.128 2) Domination constraints determine the geometric properties of 
the output of mapping. While the arboreal configuration of prosodic struc-
ture was defined in terms of the Strict Layer Hypothesis in the 80s, it is 
 
128 Note that Selkirk's interface constraints have nothing in common with the con-
straints of the same name that are discussed in § 494. 

394 
Chap 11: Optimality Theory 
now described by four independent constraints (see § 460). 3) Purely pho-
nological constraints translate pressure concerning the size of prosodic 
constituents or their stress properties. 4) Another constraint family takes 
into account information structure, i.e. properties such as focus and topic 
that are relevant for intonation (Selkirk 2007, 2008). 5) Finally, a set of 
prosodic constraints regulates eurhythmy that was evidenced by Ghini 
(1993), Sandalo & Truckenbrodt (2002) and others (Truckenbrodt 
2007:451ff provides an overview): languages may prefer prosodic constitu-
ents of equal length. 
Selkirk (2000) argues that OT is well suited for expressing the vari-
able pressure that can impact the translational process: the action of differ-
ent forces can be implemented by scrambling the respective constraints in 
the same constraint hierarchy. Factorial typology, then, produces the sur-
face variation observed. As in other areas, factorial typology probably 
overgenerates quite a bit, an issue that does not appear to arouse discussion. 
In sum, thus, a shift of focus has occurred when comparing the OT 
literature on mapping with the situation in the 80s. The problem then was to 
make sense of the seemingly anarchic and inflational cross-linguistic pic-
ture: why is it that boundaries X and Y, but not Z produce the same phono-
logical effect? What do X and Y have in common that is not shared by Z? 
What does a general system look like that may describe all mapping situa-
tions with a few principles and a number of parameters? These questions 
are no longer discussed: given the wild and largely untamable variation, 
phonologists appear to have given up on this issue. Instead, the amorphous 
lists of variable phrasings are decomposed into different isolatable factors 
which may describe the result in terms of constraint interaction. 
 
464  3. Cyclic derivation and its relation with phonology 
 
465  3.1. Anti-cyclicity in OT and elsewhere: cutting off deep generative roots 
 
466  3.1.1. Cyclic spell-out is a bone of contention: OT vs. generative grammar 
 
Since Chomsky et al. (1956:75), cyclic derivation lies at the heart of gen-
erative interface theory (§§ 80, 100): it was implemented by all theories 
prior to OT. At least in its classical incarnation, however, OT must reject 
cyclic derivation because of its general anti-derivational orientation: com-
putation, of whatever nature, must be parallel. In other words, there is no 
place for Interface Dualism (§ 82) in OT (see also § 686). 

Cyclic derivation and its relation with phonology 395 
The intrinsically derivational character of cyclic derivation, and 
hence its absolute ban in OT, is made explicit for example by Kager (1999). 
 
(183) "Proponents of serial theory have argued for derivational levels which do 
not coincide with the input, nor with the output. An important argument for 
intermediate derivational levels was based on phonological properties car-
ried over from morphologically simplex forms to complex forms. Such 
transderivational transfer was modelled as the transformational cycle
(Chomsky and Halle 1968), a mode of rule application in morphologically 
complex words in which rules apply in an 'inside-out' fashion, from smaller 
to larger morphological domains. Cyclic rule application is intrinsically 
derivational, as it implies intermediate levels between the input and output 
at which phonological generalizations are captured." Kager (1999:277, em-
phasis in original) 
 
Kager's measure for attributing the label "derivational" is the exis-
tence of intermediate forms. This position reflects the holistic view that 
considers a linguistic derivation as a whole without differentiating between 
inner- and inter-modular computation: for Kager there is no difference be-
tween phonological computation and interface activity. 
 
467  3.1.2. Anti-cyclic voices from other quarters 
 
Orgun (1999:248ff) provides a well-documented survey of objections that 
have been raised against cyclicity. Beyond OT, cyclicity has been under fire 
from Declarative Phonology (Cole & Coleman 1992) because of its deriva-
tional character. Charges against interactionism have been led from the 
quarters of "Cognitive" Grammar129 and connectionism (Goldsmith 1993, 
Lakoff 1993, Karttunen 1993, all in the same book), as well as for reasons 
of cognitive and computational plausibility (Sproat 1992). 
Alternatives to unbeloved cyclicity that have been developed in OT 
are discussed below: parallel mini-grammars (co-phonologies, indexed 
constraints, § 478), interface constraints (§ 494), analogy (which is called 
Output-Output faithfulness in OT, § 497) and Orgun's HPSG-based perspec-
 
129 I use quotation marks in order to refer to the framework that was founded by 
Ronald Langacker (1987) because the label chosen suggests that this theory has 
a copyright on cognitive aspects of grammar, and that anything which is non-
Langackerian must be non-cognitive. What about calling a particular theory of, 
say, biology, "scientific biology"? More on "Cognitive" Grammar in §§ 591, 596. 

396 
Chap 11: Optimality Theory 
tive (§ 512). Also, § 475 discusses the (inclusive) relationship between opac-
ity killers and cyclicity killers. 
 
468  3.1.3. The stake is high: inside-out interpretation 
 
Rejecting cyclic derivation en bloc has far-reaching consequences since 
inside-out interpretation, a central insight of generative thinking, will have 
to go as well. 
Recall from § 161 that inside-out interpretation is shared by all ver-
sions of generative interface theory: it is implemented by interactionist as 
much as by non-interactionist architectures. Inside-out interpretation em-
bodies the empirical insight that phonological computation mirrors mor-
pho-syntactic structure (see § 672, Bermúdez-Otero forth b). It will be diffi-
cult to throw this generalisation over board. Van Oostendorp (2007:143) for 
example points out that allowing for more embedded structure to be inter-
preted after less embedded structure creates anti-cyclicity, a pattern that 
appears to be absent from the record of natural language. 
 
469  3.2. OT could respect modular contours ± but it does not 
 
470  3.2.1. Cyclic derivation and phonological computation are entirely 
independent as long as phonology is phonology proper 
 
What OT really (and tacitly) does when rejecting cyclic spell-out because 
of its derivational character is to subject the entire grammar together with 
its interfaces to the non-derivational ambition. The question is whether this 
ambition requires such a move. We will see that in fact it does not: the de-
liberate non-distinction between phonology and its interface with morpho-
syntax does not follow from any principle of OT; rather, it is a choice that 
was made by OT practitioners ± a choice that is not made explicit, and 
whose origins lie in the misty and largely unreflected relationship of OT 
with modularity. 
Orgun (1999) points out that phonology proper is not impacted at all 
by whatever spell-out procedure is in place. He writes that OT and other 
approaches which reject cyclicity 
 

Cyclic derivation and its relation with phonology 397 
(184) "have taken it for granted that cyclic phonology, like rule ordering, is deri-
vational and that this is sufficient reason to look for alternatives to cyclicity. 
[«] In this paper, I reject the presupposition underlying these approaches, 
contending that there is an important distinction between rule ordering and 
phonology-morphology interleaving." Orgun (1999:250) 
 
He then concludes that  
 
(185) "whether or not there is a derivational residue in phonology is entirely a 
question for phonological theory proper. Phonology-morphology interleav-
ing is not a source of derivationalism." Orgun (1999:251) 
 
The distinction between phonology and its interface with morpho-
syntax ought to be self-evident in the generative paradigm, whose back-
bone is a modular architecture. In the modular perspective of the inverted T 
(§ 86), phonology and the interface mechanism that transports pieces of the 
linear string into PF (and LF) are not the same thing. That is, phonological 
computation and the piece-transporting computation that is done upon 
spell-out are distinct. Cyclic spell-out is a particular take on how pieces of 
the morpho-syntactic structure are submitted to phonological computation: 
in small chunks and from inside out. It does not interfere with phonological 
computation at all.  
Looked at from the vantage point of OT, the anti-derivational ambi-
tion concerns only EVAL, i.e. the stage of the derivation where a piece of 
the linear string is singled out for phonological interpretation and trans-
ferred to PF. How this piece is selected, how big it is and what morpho-
syntactic status it has is entirely irrelevant for constraint interaction, and in 
fact invisible. 
Following the regular scenario, thus, cyclic spell-out identifies 
chunks and dips them into the phonological bath (where a chemical reac-
tion transforms the raw material). Therefore spell-out is entirely orthogonal 
to phonological computation itself ± unless modular contours are blurred. 
That is, chunk-submission and phonological computation may not be dis-
tinct if phonology as such is not properly delineated from other grammati-
cal activities ± or, in terms of OT, if CON contains a scrambled heterogene-
ous set of constraints that combine morphological (or even syntactic), pho-
nological and interface-related instructions (more on this in §§ 526f). 
 

398 
Chap 11: Optimality Theory 
471  3.2.2. Modularity is not an issue for classical incarnations of OT 
 
Classical incarnations of OT follow the all-in-one perspective (see § 523), 
even though as far as I can see there is no principled reason that roots in the 
foundations of the theory. All-in-one means that morphological and phono-
logical constraints may happily be interspersed, that the body of a given 
constraint may refer to both phonological and morphological information, 
that so-called interface constraints (§ 494) are allowed to revive the direct 
syntax approach in overt (and unreflected) violation of Indirect Reference 
(§ 406). 
Most importantly, though, we have seen in § 455 that constraint-
based mapping transports mapping, into the phonology: mapping (i.e. the 
translation of morpho-syntactic into prosodic structure) and reference to its 
result is done by the same constraint, ALIGN (and WRAP), which is located 
in EVAL and ranked among other, fully phonological constraints. Doing 
mapping in the phonology is incompatible with modularity (recall from 
§381 that mapping must be done in modular no-man's land), and so is the 
permanent reference of ALIGN (and WRAP) from inside of EVAL to morpho-
syntactic categories. 
The question is thus how far the parallel ambition of OT goes: is it 
confined to phonology, or does it encompass interface management, the 
transportation of chunks of the morpho-syntactic structure into phonology, 
or even morphology or syntax as a whole? In terms of OT, this question 
comes down to the issue of how many domain specific CONS there are: do 
we have a phonological CON that is distinct from a morphological CON and 
a CON that manages spell-out? And if so, how is the membership of indi-
vidual constraints in a specific CON (or in multiple CONS) decided? As far 
as I can see, this kind of question is not debated in the OT literature. Rather, 
in its current incarnations OT behaves as if modularity were not an issue.  
The rare reflections regarding this question that I have come across 
in the OT literature are discussed in §§ 527f below (e.g. Burzio's 2007 ex-
plicit dismissal of modularity and Russell's 1999 proposal to have one sin-
gle constraint ranking that encompasses scrambled phonological, morpho-
logical and syntactic constraints). At some point, OT will have to make up 
its mind regarding modularity, rather than leaving the issue in wafting mist: 
either modular contours are respected, in which case constraint-based map-
ping (i.e. ALIGN and WRAP), interface constraints and a number of other 
currently entertained tools have to go; or OT is declared non-modular, in 
which case its status as a generative theory is called into question. This is 

Cyclic derivation and its relation with phonology 399 
especially true in the current syntactic environment where the interface, that 
is sharp modular contours, play a central role (see § 304). 
Of course, OT is not a monolithic whole, and every analyst has to 
make up his or her mind regarding modularity and the exact span of the 
parallel ambition. However, constraints such as ALIGN are so deeply rooted 
in (all versions of) OT that it is hard to see how they could be simply 
plugged out without this producing serious shock waves over the entire 
theory. 
On the other hand, anti-cyclicity does not follow from any core prop-
erty of the theory as far as I can see: OT could as well respect a strictly 
modular environment where the parallel ambition only concerns phono-
logical computation ± hence where derivational interface management 
would be perfectly sound. 
In conclusion, the allergy that OT has developed against cyclicity has 
got nothing to do with OT itself ± it is a consequence of an independent 
choice which scrambles phonology and interface management (eventually 
even other grammatical components) into one single constraint ranking. 
This choice needs to be placed in the broader context of modularity, which 
is systematically violated by current incarnations of OT. 
 
472  3.2.3. Cyclic derivation, but morphology and phonology merged in the 
same constraint chamber (Wolf 2008) 
 
Finally, adhering to cyclic derivation does not mean that modularity is re-
spected. This is shown by an approach called Optimal Interleaving (OI) that 
is developed by Wolf (2008). Couched in McCarthy's (2007) OT-CC (Har-
monic Serialism), the goal of OI is to implement the insight of Lexical 
Phonology that phonology and morphology are interleaved. Therefore cy-
clic (inside-out) derivation is adopted, but the kind of interleaving familiar 
from interactionism where two computational systems ship pieces of grow-
ing size back and forth is made much more intimate: morphology and pho-
nology are computed in the same constraint hierarchy where phonological 
and morphological constraints are interspersed, and lexical insertion takes 
place in the phonology (or rather: in the computational system that encom-
passes phonology and morphology).  
As a result, a constraint hierarchy where phonological and morpho-
logical constraints cohabitate evaluates candidate chains such as under 
 (186) below where the cyclic derivation proceeds by progressively filling in 

400 
Chap 11: Optimality Theory 
morphological structure with phonological material (from the root out-
wards). 
 
(186) <[ROOT]-[FEM]-[PL], peto-[FEM]-[PL], peto-xof-[PL], peto-xof-u> 
Wolf (2008:166) 
 
The derivation is thus certainly cyclic, but the merger of morphology 
and phonology in the same computational system is a harsh violation of 
modularity (more on everything-is-one approaches and the scrambling 
trope of OT in §§ 528f). 
 
473  4. Morpheme-specific mini-grammars in OT 
 
474  4.1. Introduction 
 
The following pages review the lines of attack that OT has developed in 
order to replace cyclicity, whose derivational character is held to be dis-
qualifying. Some of the surrogate devices have explicitly been conceived as 
cyclicity killers, others have an independent existence. The presentation 
aims to cover all approaches to the question how extra-phonological infor-
mation is processed in phonology that OT has produced. It proceeds in two 
steps: first direct heirs of Lexical Phonology are examined, that is ap-
proaches which implement morpheme-specific mini-phonologies. Other 
views on the interface are then discussed in a second step (§ 493). 
 
475  4.2. Opacity killers, cyclicity killers and their relationship 
 
Over the past fifteen years or so, OT has been struggling with opacity, 
which is traditionally analysed in terms of extrinsically ordered rules.130 
Various parallel solutions have been proposed (opacity killers), but none 
has proven successful: Output-Output (OO) correspondence (e.g. Benua 
1995, 1997), sympathy (various versions, e.g. McCarthy 1999, 2003b), 
Comparative Markedness (McCarthy 2003a), targeted constraints (Wilson 
2000, 2001), enriched inputs (Sprouse 1997) and a couple of others. 
 
130 What follows is a mere description of how the OT scene dealt with opacity. It 
does not contribute anything to the debate regarding the typology of opacity, 
which is a generic term for a number of empirical situations that may be quite 
different. 

Morpheme-specific mini-grammars in OT 401 
On the other hand, the idea that holistic parallelism is wrong is gain-
ing ground. According to this view, phonology proper is strictly parallel, 
but its interface with morpho-syntax is derivational. This is the position of 
the direct heirs of Lexical Phonology, i.e. Stratal OT and DOT. More re-
cently, phonological computation itself has been declared derivational by 
McCarthy's (2007) revival of Harmonic Serialism (Prince & Smolensky 
1993); interestingly, it was McCarthy who had engaged OT into anti-
derivationalism in the first place.  
As a matter of fact, all versions of OT with derivational elements 
have been designed under the pressure of opacity ± and at the same time do 
the job of cyclicity killers. As we will see, however, the reverse is not true 
for cyclicity killers (or what is taken as such), which have got nothing to 
say about opacity. 
That a particular view on opacity impacts cyclic spell-out makes 
sense: opaque derivations always involve the concatenation of some mor-
pheme. This is what Green (2007:169) points out: purely phonological 
opacity does not exist. Opacity is thus necessarily related to the representa-
tion of morpho-syntactic information in phonology, which in turn transits 
through the phonological cycle. Therefore a way to go about opacity is to 
work on how morpho-syntactic information impacts phonology. 
 
476  4.3. Morpheme-specific mini-phonologies: parallel vs. reranked 
incarnations 
 
On the following pages, the four currently entertained approaches that im-
plement morpheme-specific mini-grammars are discussed: co-phonologies 
(§ 478), indexed constraints (§ 482), DOT and Stratal OT (§ 483) (relevant 
references are provided below). The two latter are considered to be direct 
continuators of Lexical Phonology both in spirit and regarding their deriva-
tional character, while the two former are not thought of in these terms. 
I argue that Stratal OT and DOT are derivational in their self-
understanding and in the perception of the field, but that this derivational 
aura owes more to the historical reference (Lexical Phonology) than to a 
real need that is imposed by data or theory, at least as far as affix class-
based phenomena are concerned. 
The critical property which opposes Stratal OT/DOT on the one hand 
and co-phonologies/indexed constraints on the other is reranking. On the 
analysis of the former, mini-grammars apply in serial order, just like strata 
in classical Lexical Phonology: first a string is interpreted at stratum 1/by 

402 
Chap 11: Optimality Theory 
mini-grammar 1, then it is assessed by stratum 2/mini-grammar 2. The two 
mini-grammars do not exist independently at any given point in time; 
rather, there is only one single constraint chamber whose content is rear-
ranged once stratum 1 computation is completed. This operation is called 
reranking (of constraints in EVAL); it is reranking, and nothing else, that 
makes DOT and Stratal OT derivational. 
On the other hand, co-phonologies and indexed constraints provide 
for permanently distinct mini-grammars that co-exist in parallel. 
Table  (187) below depicts the two options at hand. 
 
(187) parallel vs. serially ordered mini-grammars 
 
a. co-phonologies, indexed constraints 
b. Stratal OT, DOT 
 
string 1 
 
string 2 
 
 
 
 
all strings 
 
 
 
 
phono 1 
 
phono 2 
 
phono 1 
 
phonology
reranking 
 
phono 2 
 
phonology
The difference is thus chronological (or derivational). Several mini-
grammars coexist permanently under (187a): phonology is made of a set of 
distinct subregularities, each of which forms a natural and consistent sys-
tem. By contrast under (187b), there is only one constraint chamber at any 
given point in time: the contrast between distinct mini-grammars is 
achieved by the reranking of constraints, an operation that takes place in 
the midst of phonological activity. 
Another important difference is the fact that under (187b) strings 
must run through all successive mini-phonologies on their way to the sur-
face. That is, a string which is created at the first stratum will also experi-
ence the computation of the second stratum. By contrast under (187a), 

Parallel mini-grammars 403 
strings that are specified for computation by mini-phonology 1 will never 
meet mini-phonology 2 (and vice-versa). 
On the pages below, implementations of the two scenarios are dis-
cussed.  
 
477  5. Parallel mini-grammars 
 
478  5.1. Co-phonologies: two constraint rankings 
 
479  5.1.1. Lexical material selects a specific computational system 
 
Co-phonologies are the closest match of (187a): they really implement two 
parallel, permanent and waterproof mini-grammars. Affixes, but also entire 
words, may be lexically specified for selecting this or that co-phonology (of 
which of course there may be more than two).  
In the case of entire words, co-phonologies mimic the traditional 
view on loanword phonology: each word is lexically specified as a member 
of a certain class such as "native", "foreign", "latinate", "learned" and the 
like. A specific co-phonology with a particular constraint ranking is associ-
ated to each lexical class. Whenever a word is engaged in a derivation, 
then, its diacritic marking selects the corresponding co-phonology. This 
management of course is much akin of the diacritic marking of rules that 
was common practice in SPE: "rule X applies only to words that are 
marked as [+latinate]". 
Co-phonologies are used by, among others, Itô & Mester (1995), 
Orgun (1996a), Inkelas (1996, 1998, 1999), Orgun & Inkelas (2002), 
Anttila (2002). 
 
480  5.1.2. How affix class-based phenomena could be analysed 
 
In the case of affixes, the mini-grammar for which the affix is marked is 
"called" in order to assess the string that the affix heads. A string such as 
[root-affix 1] will thus be computed by mini-phonology 1, while mini-
phonology 2 will be called for the assessment of [root-affix 2]. 
Unfortunately, I was unable to find relevant literature that shows how 
(English) affix class-based phenomena are analysed with co-phonologies. 
The following is thus my personal extrapolation of how this could be done. 
The coverage is only partial: I will not push the speculation too far. It is 
also worth mentioning that the literature on co-phonologies that I am famil-

404 
Chap 11: Optimality Theory 
iar with does not mention morpho-syntactic structure. This bit of the dis-
cussion below is also mine, for the sake of comparison with previously 
reviewed theories. 
With these reservations borne in mind, table  (188) below shows how 
more complex strings could be handled by co-phonologies. Examples are 
taken from English affix class-based stress assignment. 
 
(188) parallel morpheme-specific mini-phonologies 
 
a. univérs-al-ness 
b. govern-mént-al 
 
γ
phon 2
γ
phon 1
class 2 
β
phon 1 
 
class 1 
β
phon 2 
 
 
class 1 
α
phon 1 
 
class 2 
α
phon 1 
 
x
root 
 
 
 
 
x 
root 
 
 
In each case, the material that is dominated by the node that the affix 
projects is computed by the mini-phonology that the affix selects for. In the 
English example, the rule that distributes penultimate stress is present in 
class 1 phonology, but absent from class 2 phonology. Hence [univers-al] 
and [govern-ment-al], the two strings that are headed by a class 1 affix, 
receive penultimate stress: univérs-al and govern-mént-al. Since the stress 
rule is absent from class 2 phonology, stress remains unshifted with respect 
to the next lower node when class 2 nodes are interpreted: the result is 
univérs-al-ness and góvern-ment, respectively. 
 
481  5.1.3. Are co-phonologies a version of Halle & Vergnaud (1987a)? 
 
In order for roots in isolation to receive stress, they also need to be some-
how spelled out. This can be done as under  (188) by hard-wiring a specifi-
cation for all roots to be assessed by class 1 phonology. This replicates the 
logic of Halle & Vergnaud's (1987a) system where, recall, roots are always 
interpretational units (§ 280). As for Halle & Vergnaud, Kaye's (1995) pro-
viso according to which the word is always an interpretational unit must be 

Parallel mini-grammars 405 
dismissed by co-phonologies: did class 1 phonology systematically apply at 
the word level, *univers-ál-ness would be produced. 
The analogy with Halle & Vergnaud is also confirmed by the selec-
tion of the affix class that triggers stress assignment: recall from § 281 that 
unlike in Kaye's (1995) system where class 2 affixes are interpretation-
triggering, class 1 affixes play this role with Halle & Vergnaud. This is also 
the case under  (188). 
These three choices (roots are interpretational units, words are not, 
class 1 affixes trigger spell-out) may thus suggest a convergence which, 
however, is only apparent. For co-phonologies also carry out interpreta-
tional activity at class 2 nodes: the stress rule just happens not to be part of 
the processes that belong to class 2 phonology. By contrast, Halle & Verg-
naud (1987a) oppose nodes that trigger interpretation (cyclic) to nodes that 
do not (non-cyclic). This is precisely where the fundamental front line runs 
between theories that implement morpheme-specific phonologies (such as 
co-phonologies) and theories that work with just one computational system 
(such as Halle & Vergnaud's). 
Continuing the speculation about how affix class-based phenomena 
could be analysed with co-phonologies is idle. The solution that was 
sketched could also be said to hit far from the mark since it obviously sup-
poses inside-out interpretation, i.e. cyclic spell-out: it must first be decided 
that stress does not shift in góvern-ment before it can be decided that it 
shifts one vowel right in govern-mént-al. Co-phonologies, however, are 
supposed to be a cyclicity-killer. 
 
482  5.2. Indexed constraints: two grammars in the same constraint ranking 
 
Another way of implementing (187a) is to make all string-specific con-
straints cohabitate in the same constraint ranking. In this perspective, lexi-
cal items are specified for computation by mini-grammar A or mini-
grammar B as before. However, constraints come in two versions, A and B 
(FAITH for example may divide into FAITHAand FAITHB). Hence a lexical 
item that is specified for computation by mini-grammar A will only be as-
sessed by the subset of A constraints. Another subset, B constraints, com-
putes only B items. 
Every string-specific constraint thus exists twice, in an A- and a B-
guise. Different versions of the same constraint, then, have different rank-
ings in the same constraint chamber, both with respect to each other and 
regarding string-unspecific constraints (which are not doubled). In Pater's 

406 
Chap 11: Optimality Theory 
(2009:125) description, "a single constraint can be multiply instantiated in a 
constraint hierarchy, and each instantiation may be indexed to apply to a 
particular set of lexical items. These indexed constraints are universal 
markedness and faithfulness constraints, whose application is relativized to 
a set of lexical items." 
Itô & Mester (1999b) for example use indexed constraints in order to 
describe Japanese loan words, which according to them fall into four lexi-
cal classes, depending on the degree of assimilation: native words, estab-
lished loans, assimilated foreign words and unassimilated foreign words. 
Their analysis then establishes FAITH1, FAITH2, FAITH3 and FAITH4 in the 
same constraint ranking, where each version of FAITH is responsible for one 
of the four classes. 
Indexed constraints may be viewed as a modern implementation of 
diacritics that SPE added to rules in order to restrict their application to a 
specific subset of morphemes. They have been introduced by Prince & 
Smolensky (1993) for alignment, and were later generalised to other con-
straints (both faithfulness and markedness) by, among others, Itô & Mester 
(1999b, 2001) and Pater (2000). 
There is ongoing debate between defenders of co-phonologies and 
supporters of indexed constraints (e.g. Pater 2009). The difference is not 
easy to transform into contrasting predictions: different phonological mini-
grammars are implemented as different rankings in one case, in one single 
ranking in the other. Or, from the morphological point of view, morphemes 
select either constraint rankings or the index of a constraint. Table  (189) 
below depicts this contrast. 
 
(189) morpheme-specific mini-phonologies: parallel implementations 
 
a. co-phonologies 
 
 
b. indexed constraints 
 
/«X1«X2«/ 
 
 
/«Xx«Xy«/ 
 
 
 
 
 
 
constraint 1x 
 
 
constraint 4y 
 
 
phono 1 
 
phono 2 
 
constraint 2 
 
 
phono 1 
constraint 3x 
 
 
 
 
 
constraint 1y 
 
 
constraint 4x 
 
 
constraint 3y 
 
 
phono 2 
The following section considers the serial competitor of parallel 
morpheme-specific mini-phonologies. 

Reranked mini-grammars: Stratal OT, DOT 407 
483  6. Reranked mini-grammars: Stratal OT, DOT 
 
484  6.1. Serial vs. parallel solutions 
 
485  6.1.1. Parallel OT couched in the stratal architecture of Lexical Phonology 
 
DOT (Derivational Optimality Theory, Rubach 1997, 2000b, 2003, Booij 
1997) and Stratal OT (Kiparsky 2000, Bermúdez-Otero forth a) are con-
straint-based versions of stratal Lexical Phonology (although their contrast 
with Lexical Phonology does not reduce to this difference). They replicate 
the stratal architecture according to (187b): a number of lexical strata (and 
a postlexical phonology) are serially ordered and afford distinct phonologi-
cal computations. At each level, candidates are assessed by a classical con-
straint ranking in entirely parallel fashion, but constraints may be reranked 
between levels. 
Kiparsky (2000) outlines the research programme of Stratal OT in 
the following terms. 
 
(190) "LPM-OT's goal [LPM stands for Lexical Phonology and Morphology] is to 
reduce cyclicity to I/O faithfulness, and opacity to interlevel constraint 
masking. Thus, if α is the constraint system of some domain (say, stems) 
and β the constraint system of a larger domain (word level or postlexical) 
the β's markedness constraints can render α opaque. These are the only 
sources of cyclic effects and opacity: there are no O/O constraints, no para-
digm uniformity constraints, and no sympathy constraints. The intrinsic 
seriality of LPM-OT provides a handle on opaque and cyclic constraint 
interactions without retreating to the unconstrained ordering theory of pre-
OT days." Kiparsky (2000:352, emphasis in original) 
 
Kiparsky's positioning is very clear: he proposes to do parallel OT, 
but within the original stratal architecture of Lexical Phonology. That is, the 
overall derivation is serial, but within each stratum interpretation is strictly 
parallel.  
 
486  6.1.2. The critical contrast with parallel implementations is not discussed 
 
Stratal OT is thus serial in its self-understanding as much as in the percep-
tion in the field. Given that anti-derivationalism is the headstone of classi-
cal OT, this is not a minor issue. The trouble is that, as far as I can see, the 
derivationalism of Stratal OT/DOT is taken for granted without demonstra-

408 
Chap 11: Optimality Theory 
tion of the fact that this solution is any different from the parallel imple-
mentation of morpheme-specific mini-grammars under (187a). 
The whole derivational issue hinges on reranking, and on nothing 
else. Given the anti-derivational bias of OT, the default assumption is that 
parallel solutions are correct. Therefore, what one expects defenders of 
Stratal OT and DOT to show is that reranking is crucial, i.e. that approaches 
which lack this operation are not viable. Comparative discussion of serial 
and parallel implementations of morpheme-specific phonologies, however, 
is not easy to come by (see the following section). 
One contrast between stratal and parallel implementations of mor-
pheme-specific phonologies has already been mentioned in § 476. On the 
stratal account, strings have to run through all successive strata on their 
way to the surface. That is, roots are computed by all mini-grammars in the 
course of a derivation, and strings that are affixed at stratum X also experi-
ence the stratum-specific computation at stratum X+1 (and at all subse-
quent strata). By contrast in a system with parallel mini-grammars which 
are not related by any derivational means, every string only experiences the 
specific computation that it selects for: strings that are made of a root and a 
class 1 affix are computed by class 1 phonology, but never meet class 2 
phonology, and vice-versa. 
I have not come across any argument in the literature that is based on 
this contrast in underapplication.  
 
487  6.1.3. Indexed constraints, but not co-phonologies, are perceived as a 
competitor 
 
Kiparsky (2000) and Bermúdez-Otero & McMahon (2006:402ff) offer 
comparative discussion with a non-derivational solution for cyclicity- and 
opacity effects (Output-Output constraints, see § 497), but do not address 
non-derivational instantiations of morpheme-specific mini-grammars. 
On the other hand, Bermúdez-Otero (forth a:§2.4.5.1) argues that 
since the tools of Stratal OT allow for the analysis of morpheme-specific 
phonology, constraints do not need to be indexed. 
 

Reranked mini-grammars: Stratal OT, DOT 409 
(191) "Classical LPM expresses domain limitations indirectly: the formulation of 
a phonological rule need not mention the grammatical categories within 
which the rule applies or does not apply; rather, rules are assigned to levels 
and apply whenever a construction triggers a cycle of the appropriate level. 
The same is true in Stratal OT: specific hierarchizations of CON are assigned 
to particular levels; the level-n hierarchy applies only in a level-n domain. 
[«] As a result, individual constraints need not be relativized to particular 
morphological or syntactic constructions: constraint indexing is prohibited." 
Bermúdez-Otero (forth a:§2.4.5.1) 
 
Once the stratal model is chosen, indexed constraints are thus super-
fluous. This is certainly correct, but Bermúdez-Otero does not explain why 
this choice should be made in the first place. 
Unlike indexed constraints, co-phonologies do not appear to be per-
ceived as a competitor by Stratal OT. Bermúdez-Otero (forth a:§4.6.1) in-
deed uses the term co-phonology as a synonym for domains (domains in 
the sense of Lexical Phonology, i.e. strata): "in Spanish, when a verb stem 
[«] constitutes a phonological domain, it selects a stem-level cophonology 
that constructs an ω without foot structure." Also, Bermúdez-Otero & 
McMahon (2006:404ff) accept Anttila's (2002) co-phonology-based ac-
count of particular stress-shifting suffixes in English. 
The critical contrast, then, reranking, does not seem to make much of 
a difference, and in any event remains unreflected. 
In the DOT literature, the situation is much the same: Rubach (1997, 
2000a,b, 2003) presents cases that call for a treatment by morpheme-
specific mini-phonologies, but as far as I can see takes for granted that 
these follow the two-step logic. Alternative accounts based on parallel 
mini-grammars are not considered.  
What we end up with, then, are well-documented arguments in fa-
vour of the existence of distinct mini-grammars; but demonstration is lack-
ing that these must entertain a serial relationship. 
 
488  6.2. Stratal OT is more than just an OTed version of Lexical Phonology 
 
489  6.2.1. Lexical Phonology anew: unhorsing the SPE heritage 
 
Its roots notwithstanding, Stratal OT is more than just an OTed version of 
classical stratal Lexical Phonology. For example, Bermúdez-Otero (forth 
a:§1.2.1) dismisses the SPE-legacy that (in his words) crippled Lexical 
Phonology: underspecification, Kiparsky's SCC-K and structure preserva-

410 
Chap 11: Optimality Theory 
tion (see § 214). Also, Bermúdez-Otero (forth a:58ff) remains agnostic re-
garding interactionism. 
By contrast, Stratal OT is firmly committed to Praguian segregation 
(Bermúdez-Otero forth a:66ff): together with the two morpheme-specific 
mini-phonologies, grammar then contains (at least) three distinct computa-
tional systems (i.e. rankings of CON): the stem-level ranking, the word-
level ranking and the phrase-level ranking. 
 
490  6.2.2. Inflational access to morpho-syntactic information is a concern in 
Stratal OT 
 
DOT and Stratal OT follow the general practice in OT that was described in 
§455: the Prosodic Hierarchy is taken over from the 80s, but translation is 
now done by constraint-based mapping. That is, reference to prosodic con-
stituents is made through the constraint families ALIGN and WRAP.
The relationship between the procedural tools inherited from Lexical 
Phonology and the representational devices coming from Prosodic Phonol-
ogy is as unclear in OT as it was between the original theories (see § 423). 
That is, functional overlap and hence competition (rather than the peaceful 
coexistence that was tacitly promoted in the 80s) between procedural and 
representational means of talking to phonology are an issue: OT has a gen-
eral trope for the proliferation of tools that do the same job (opacity killers, 
cyclicity killers etc.). 
Bermúdez-Otero (forth a) is among the few references that I have 
come across which explicitly identify the unrestricted access of phonology 
to morpho-syntactic information as a problem (Orgun & Inkelas 2002:116 
is another example). He describes the current situation in OT as follows. 
 
(192) "Restricting the phonology's access to morphological and syntactic structure 
is a long-standing goal of generative linguistics. In nonstratal OT, however, 
this project seems to have been more or less abandoned. [«]In the absence 
of cyclicity, all the grammatical structure of a linguistic expression must be 
simultaneously accessible to the phonology. In such circumstances, the task 
of limiting the uses to which the phonology can put this grammatical infor-
mation devolves upon the theory of CON. So far, however, there has been no 
concerted effort to define the set of constraints that refer to nonphonological 
information: the situation is, in effect, a near free-for-all. " Bermúdez-Otero 
(forth a:43) 
 

Reranked mini-grammars: Stratal OT, DOT 411 
491  6.2.3. The solution is the same as before: Indirect Reference and peaceful 
coexistence 
 
In reaction to this, Bermúdez-Otero (forth a:45) calls on the classical prin-
ciple of Indirect Reference (§§ 377, 406), which cuts down the blooming 
diversity (also including interface constraints, see § 494). 
 
(193) "Indirect Reference Hypothesis (strong version) 
Phonological constraints do not refer to morphological or syntactic informa-
tion, modulo constraints on the alignment of prosodic categories with 
grammatical constituents. 
This results in a massive simplification of CON with respect to nonstratal 
OT: we retain IO-faithfulness and hybrid alignment constraints, but dispense 
with OO-correspondence, indexed constraints, MORPH-REAL, and the like."
Bermúdez-Otero (forth a:45, emphasis in original) 
 
Representational communication with phonology is thus disallowed 
altogether, except through the ALIGN channel. But even here Bermúdez-
Otero attempts to marshal unrestricted constraint-based mapping (see 
§455): he assumes only a restricted set of alignment constraints which has 
"very limited access to non-phonological categories" (Bermúdez-Otero 
1999:112). What this means in practice, though, remains to be seen. 
Bermúdez-Otero's (forth a) conclusion on the representational issue, 
then, calls for a phonology that is freed from representational reference to 
morpho-syntactic information. 
 
(194) "(2,76) No Symbols of Grammatical Affiliation 
Phonological representations do not contain symbols that refer to morpho-
logical or syntactic structure. 
 
Under principle (2,76), a phonological representation p can be globally 
associated with a grammatical unit g; [«] The content of p, however, must 
be exclusively phonological: the primitives of phonological representation
do not include symbols of morphological or syntactic affiliation. Accord-
ingly, (2,76) banishes not only the juncture phonemes of the Structuralist 
tradition and the boundary symbols of SPE (+, =, #), but also the morpho-
logical brackets of LPM and any such conceivable device. Notably, (2,76) 
prohibits the morphological or syntactic indexation of features, segments, or 
any other internal constituent of phonological representations." Bermúdez-
Otero (forth a:45) 
 

412 
Chap 11: Optimality Theory 
His practice, however, does not stand up to this promise. Bermúdez-
Otero's principle (2,76) cuts away all kinds of diacritic rank growth, except 
the Prosodic Hierarchy and direct reference to morpho-syntactic categories 
in ALIGN constraints (as explicitly mentioned in  (193)). That is, constitu-
ents of the Prosodic Hierarchy are as much symbols of grammatical affilia-
tion as were juncture phonemes, hashmarks and brackets. All of these de-
vices comply with the principle of Indirect Reference, but all of them are 
diacritics whose only purpose is to store morpho-syntactic information 
(§ 402). 
In the end, Stratal OT thus appears to continuate the aforementioned 
peaceful coexistence of Lexical Phonology and Prosodic Phonology: there 
does not appear to be a principled way of deciding whether a given phono-
logical phenomenon that is sensitive to morpho-syntactic information is the 
result of stratal (i.e. derivational) or representational activity. 
 
492  6.3. How different can mini-grammars be? 
 
The interface literature in OT either continuates morpheme-specific pho-
nologies, the legacy of Lexical Phonology, or develops approaches that are 
incompatible with modularity. The former were reviewed above, the dis-
cussion of the latter is to come. Before pursuing, though, let us look at an 
argument that has been levelled against morpheme-specific mini-
phonologies, in fact against all types of distinct computational systems. 
Golston (1996) and Orgun (1996a) discuss the "cophonology prolif-
eration problem" (Orgun 1996a:114). In Golston's (1996) view, multiple 
mini-grammars do not qualify because in principle they allow for a lan-
guages to be co-defined by very distant and completely different computa-
tional systems: one mini-grammar could feature, say, a three-vowel system 
such as the one that is found in Arabic, while another could allow for a 
flourishing vowel system of the Swedish type. This, Golston argues, is not 
a situation that is ever found in natural language: the phonologies of differ-
ent strata of a given language are always intimately akin; the range of varia-
tion found is not remotely comparable to what the cross-linguistic picture 
offers. Golston (1996:192) therefore pleads "against analyses which treat 
multiple levels in terms of multiple grammars.[«] The phonology of a 
language is always uniform, stable as a single set of constraints." 
Orgun (1996a:114ff) points out the same problem, but unlike Golston 
tries to constrain the degree to which co-phonologies in the same language 
can differ from one another. Both Golston and Orgun only talk about co-

Other cyclicity killers 413 
phonologies, but the logic of their argument is against the existence of 
mini-grammars as such, whatever their implementation.  
Benua (1997:90ff) and McCarthy (1999, 2007:42ff) indeed extend 
the critique to the option under (187b), which is represented by Stratal 
OT/DOT. The perspective here is slightly different, though. While Stratal 
OT/DOT also implements morpheme-specific mini-grammars, these are not 
waterproof. That is, they entertain a derivational relationship through the 
reranking operation. The mini-grammars of (187a) on the other hand do not 
"see" each other at all.  
It can therefore be argued by defenders of serially ordered mini-
phonologies that their distance is a function of the reranking operation: the 
more distant the two mini-grammars, the more reranking has taken place, 
i.e. the more constraints have been "displaced". This is indeed the line of 
attack of Ricardo Bermúdez-Otero, who argues that the limits of interstratal 
reranking are dynamically imposed by acquisition (iterative stratum con-
struction, Bermúdez-Otero 2003) and the rules of diachronic evolution 
(Bermúdez-Otero 1999:98ff).131
Reranked mini-grammars and the constraints that apply among them 
via the reranking operation therefore appear to be the modern version of the 
classical concern for a certain unity of grammar: recall from § 151 that do-
main assignment in Lexical Phonology already embodied the idea that there 
is just one set of phonological rules, whose members are assigned to this or 
that stratum, or to postlexical phonology. That is, identical rules that occur 
in several locations of the grammar are manifestations of the same regular-
ity, rather than different rules that happen to have the same formulation. 
 
131 It was mentioned in § 487 that according to Bermúdez-Otero & McMahon 
(2006), co-phonologies are not incompatible with derivationally ordered multi-
ple mini-grammars: a given stratum in Stratal OT may use a number of co-
phonologies. 
493  7. Other cyclicity killers 
 
494  7.1. Interface constraints 
 
495  7.1.1. Back to direct syntax 
 
Another way of making the interface non-cyclic that is entertained in the 
OT literature is to simply abandon Indirect Reference. So-called interface 
constraints (Anttila 2002) and work such as Pak (2008) and Samuels 

414 
Chap 11: Optimality Theory 
(2009a:284ff) revive direct syntax approaches that were entertained in the 
70s and early 80s (see § 407). Recall that since the mid 80s, the need for 
translation has been recognised: Indirect Reference was the guiding light in 
generative interface theory. This has led to the architecture of Prosodic 
Phonology where a Translator's Office that stands in modular no-man's land 
converts morpho-syntactic into phonological structure (§§ 381, 406). 
All this is thrown over board by interface constraints and, as far as I 
can see, this is done without discussion. Also, nothing is said regarding the 
articulation of interface constraints with prosodic constituency and continu-
ators of Lexical Phonology: as in other areas, OT allows for a toolbox that 
contains a number of instruments which may do the same job, and which 
may be conflicting. 
 
496  7.1.2. Back to SPE-type morphological diacritics 
 
The formulation of interface constraints is purely phonological, but it is 
supplemented with a diacritic. Diacritics in co-phonologies and indexed 
constraints determine the mini-phonology to which the constraint belongs; 
with interface constraints they identify the particular morphological cate-
gory that the constraint applies to (and in absence of which it is ineffec-
tive). 
Interface constraints thus make reference to designated morpho-
syntactic categories. They may be illustrated by Kager's (2000:146f) treat-
ment of class 1 vs. class 2 affixes in Dutch. On his analysis, the contrast is 
ultimately encoded arboreally: following Selkirk (1984:77), class 1 affixes 
are attached lower in the tree than class 2 affixes. The exact position of 
affixes in the tree, however, is governed by constraints; one of them pre-
vents class 1 affixes (such as -eer, -iteit) from attaching to higher positions: 
"NONRECSTEM: No Stem (affixed by -eer, -iteit etc.) immediately dominates 
a Stem." 
This type of constraint thus needs to mention every affix (or affix 
class for that matter) in its body. In SPE, rules were commonly supple-
mented with a statement in prose or a diacritic in subscript that specifies to 
which morpho-syntactic category it applies (e.g. the compound rule or the 
nuclear stress rule, see § 95). Interface constraints are thus the faithful rein-
carnation of this practice in a constraint-based environment. 
Interface constraints such as FAITH-root and FAITH-affix have been 
introduced by McCarthy & Prince (1995a); further relevant literature in-
cludes Smith (1999), Borowsky (2000) and Alderete (2001). Van Oosten-

Other cyclicity killers 415 
dorp (2007:125ff) and Anttila (2002) discuss the spectrum of interface con-
straints. Anttila (2002:2) also provides an overview of the particular mor-
phological categories to which interface constraints have made reference in 
the literature. Typical are more general categories such as roots, affixes, 
nouns, verbs, lexical vs. functional morphemes and affix classes, but the 
possibility of reference to individual morphemes is also entertained (e.g. 
Raffelsiefen 1996:207f, Hammond 1995, Russell 1999). Finally, reference 
to designated morphological categories is an option that is open to all kinds 
of constraints: faithfulness, markedness and alignment. 
 
497  7.2. Analogy (Output-Output correspondence) 
 
498  7.2.1. OO correspondence was designed as a cyclicity killer 
 
OO correspondence expresses the traditional concept of analogy in a con-
straint-based environment. That is, instead of describing a faithfulness rela-
tion between an input and an output, OO constraints impose a faithfulness 
relation between two independent outputs: a word falls prey to the influ-
ence of another word. 
Output-Output (OO) correspondence has been introduced by Benua 
(1995, 1997) and further developed by, among others, Kenstowicz (1996), 
Burzio (2000a,b, 2001), McCarthy (2005). It has rapidly become a standard 
tool in OT. Interestingly, Benua's original goal was to do away with the 
phonological cycle and lexical strata ± because of their derivational flavour. 
 
(195) "This theory obviates the traditional analysis that deviant phonology in 
complex words is the product of cyclic derivation. Given transderivational 
relations, cyclic effects are produced by constraint interaction in nonproce-
dural Optimality Theory. [«] In this transderivational theory, phonology is 
sensitive to morphology because phonological faithfulness relations hold 
over paradigmatically-related words. There are no cycles or levels of deriva-
tion. Complex words, like simplex words, are derived in a parallel grammar, 
without any intermediate stages." Benua (1997:vi-vii) 
 
This still appears to be the basic motivation for and merit of OO cor-
respondence: in the editorial note that heads the reprint of parts of Benua 
(1997), John McCarthy stresses the historical dimension of the idea. 
 

416 
Chap 11: Optimality Theory 
(196) "The phonological cycle is one of the central insights of Chomsky and Halle 
(1968). This insight was developed further in the theory of Lexical Phonol-
ogy (Kiparsky 1982[a,b]; Mohanan 1986). The idea is that phonological 
rules first apply to simple words and then apply again to morphologically 
complex words derived from them. The cycle and like conditions were 
worked out within a rule-based framework, and so it is natural to re-examine 
these ideas within OT. The proposal in this chapter is that effects formerly 
attributed to the cycle or lexical strata should be analyzed in terms of faith-
fulness constraints ± not the familiar input-output faithfulness, but rather 
faithfulness between different output forms or related words." McCarthy
(ed.) (2004:419) 
 
Hence OO correspondence counts as a non-derivational means of 
eliminating cyclicity. 
 
499  7.2.2. OO is not a cyclicity killer by itself 
 
When it comes to the concrete implementation of OO correspondence, 
however, it appears that the mere ability of faithfulness constraints to make 
reference to words does not guarantee a cycle-free analysis. In the same 
way as waterproof mini-grammars and interface constraints, OO corre-
spondence must use diacritics in order handle cyclic effects. 
An example is Benua's (1997) treatment of the English stem-final 
[-m] - [-mn] alternation (da[mn]-ation class 1 vs. damn-ing [m] class 2, 
damn [m], see § 167). Benua splits OO constraints into two types, for which 
affixes are subcategorised. 
 
(197) "OO1-Identity constraints evaluate class 1 paradigms [«] and OO2-Identity 
constraints rule class 2 paradigms. Both sets of OO-Identity constraints are 
ranked in the English hierarchy of markedness and IO-Faith constraints. 
When analogous OO1-Identity and OO2-Identity constraints have different 
rank in the grammar, the two classes of affixed words pattern differently." 
Benua (1997:163ff) 
 
That is, Benua uses morpheme-specific mini-phonologies, indexed 
constraints on her take: her constraints are doubled and supplemented with 
an index, which decides to which affix class they apply. 
Therefore OO correspondence may not be said to be a cyclicity killer 
per se: it is not true that it does away with the unwarranted cycle. A cycle-
surrogate (indexed constraints in our example) is still needed on top of the 
OO mechanism. Only "regular" cyclicity killers such as co-phonologies or 

Other cyclicity killers 417 
indexed constraints are direct competitors of the cycle that can do all of its 
labour.  
Finally, Bermúdez-Otero (forth b) argues on the empirical side that 
OO correspondence cannot cover all patterns that are classically managed 
by cyclic derivation. He also shows that it overgenerates: OO correspon-
dence can describe patterns that are not granted for by what Bermúdez-
Otero calls the Russian Doll Theorem (interaction of opacity and cyclicity). 
 
500  7.3. Enriched representations (van Oostendorp) 
 
Finally, the OT literature offers another strategy for the treatment of cyclic 
phenomena: in a series of articles, van Oostendorp (1999, 2002, 2004) ar-
gues that at least some of the effects at hand, namely in Dutch, have a 
purely phonological solution.132 This perspective, however, supposes a suf-
ficiently rich system of phonological representations. 
Regarding what is traditionally assumed to be class 1 vs. class 2 suf-
fixes in Dutch (Booij 1977), van Oostendorp's basic observation is that the 
former are all vowel-initial and monosyllabic, while the latter are all con-
sonant-initial and plurisyllabic. Only one suffix, -achtig (class 2) disobeys 
this generalisation. Class membership can thus be predicted on purely pho-
nological grounds (-achtig in the end will be shown to be /-ʔachtig/, i.e. 
consonant-initial). 
On the other hand, van Oostendorp discusses the well-known asym-
metry between prefixes and suffixes: the latter are "dependent" (for exam-
ple, they regularly resyllabify across their boundary), while the former are 
"autonomous" (they are more reluctant to do that). Van Oostendorp pro-
poses to directly encode this observation in a constraint, which he calls 
Morphological Syllable Integrity. The motor of the various events that are 
observed at prefix boundaries, then, is the tension between a general ten-
dency to have morpheme boundaries coincide with boundaries of prosodic 
constituents (PR≈LEX) and the wish to have "good" syllables, i.e. which 
possess an onset. 
 
132 A condensed version of this body of work appears in van Oostendorp 
(2006a:47ff). 

418 
Chap 11: Optimality Theory 
501  8. More direct syntax: representational continuity between morphology 
and phonology 
 
502  8.1. Introduction 
 
Finally, it is worth presenting two sister approaches to the phonology-
morphology interface that practise direct syntax (§ 407) in a separate sec-
tion. Both share the idea that untranslated morpho-syntactic information 
(structure and labels) is completely and permanently availability during 
phonological computation, and both claim a strong representational, i.e. 
anti-derivational position. 
Van Oostendorp's Coloured Containment is prepared to let phono-
logical constraints make reference to the fact that phonological objects 
(such as segments and features) do or do not belong to the same morpheme, 
and that they were or were not present underlyingly.  
A more radical type of representational continuity is argued for by 
Orgun's (1996a) Sign-Based Morphology, which is an application of HPSG 
to phonology. On this count, there is no difference between morpho-syntax 
and phonology at all: everything is monostratal (a property also claimed by 
van Oostendorp 2006a:5, 2007:144f), which means that there is just one 
global representation that encompasses all relevant morpho-syntactic, se-
mantic and phonological information. 
Proposing a representational analysis for affix class-based and re-
lated phenomena is outstanding in itself: since SPE this has been the kernel 
competence of procedural tools. Another consequence of global representa-
tions of course is the abandon of modular divisions. These issues are dis-
cussed below. 
 
503  8.2. Coloured Containment (van Oostendorp 2006a) 
 
504  8.2.1. Faithfulness between morphology and phonology 
 
Van Oostendorp (2006a,b, 2007) introduces a perspective on the interface 
which, as far as I can see, is unprecedented in the study of the morphology-
phonology interface ± and which is only possible in OT. The idea is to use 
faithfulness for the comparison of morphological and phonological struc-
ture. Van Oostendorp thus takes advantage of a mechanism that lies at the 
heart of OT and which is used in various incarnations elsewhere: Input-
Output, Base-Reduplicant and Output-Output (although in van Oosten-

More direct syntax: continuity between morphology and phonology 419 
dorp's Containment-based environment the two latter are not expressible 
and hence done away with). 
Coloured Containment thus reverts to direct syntax: instead of repli-
cating the technology of the 80s (strata, prosodic constituency) in a con-
straint-based environment (which as we have seen is current practice in 
OT), van Oostendorp builds an interface theory on the grounds of a genuine 
OT concept. In this sense, Coloured Containment is certainly the most OT 
of all interface theories: faithfulness is tested at the interface. 
 
505  8.2.2. Representational identification of the old and the new 
 
Prince & Smolensky (1993) have introduced the idea of faithfulness and its 
first implementation, Containment. McCarthy & Prince (1995a) have aban-
doned this view on faithfulness to the benefit of Correspondence Theory. 
The driving force of van Oostendorp's work is the idea that Containment is 
the correct theory of faithfulness, despite the problems that it faces and the 
fact that Correspondence has become largely consensual in OT. 
Containment requires that every element of the phonological input 
representation be contained in the output. This immediately prompts the 
question how anything could be deleted at all. Van Oostendorp argues that 
autosegmental representations offer a natural solution: an item that is pre-
sent in the input may be delinked in the output, to the effect that it is still 
present (thus satisfying Containment) but phonologically inert and inaudi-
ble. Table  (198) below (from van Oostendorp 2007:124) shows a relevant 
situation where "deleted" material is floating. 
 
(198) /takp/ →[takpi] 
 
μ
t
a
k
p
i
φ
On the assumption of a process whereby the first member of the clus-
ter in the underlying /takp/ remains unpronounced,  (198) shows the output 
representation: the /k/ is still present (hence Containment is satisfied) ± it is 
just not parsed by phonology (which is represented by the φ structure). The 

420 
Chap 11: Optimality Theory 
consonant is thus floating, which according to regular autosegmental con-
ventions means that it does not make it to the surface. 
The reverse process, epenthesis, also seems to escape a description in 
terms of Containment: what is the input-output relation of an item that is 
absent from the input when the input must be contained in the output? Un-
der  (198), though, the epenthetic character of the last vowel may be identi-
fied by the fact that it is not affiliated to morphology (which is represented 
by the μ structure). This is because all phonological material that is present 
in the input necessarily comes from lexical insertion and therefore belongs 
to a morpheme. 
In sum, items that float in regard of morphological structure are ep-
enthetic, while those that float with respect to phonological structure are 
deleted. This is how van Oostendorp distinguishes the old and the new, a 
distinction that was already discussed in § 307. 
 
506  8.2.3. Information transmission: representational vs. procedural 
 
An interesting question to be asked is what exactly makes van Oostendorp's 
way to import morpho-syntactic information into phonology different from 
the regular mechanism, i.e. mapping as practised in Prosodic Phonology. 
The answer translation: both morpho-syntactic and phonological trees are 
static in van Oostendorp's system ± there is no computational action that 
transforms one into another. Van Oostendorp thus rightfully claims a repre-
sentational approach to the interface, i.e. one where (derivational) transla-
tion/mapping is not needed.  
This non-derivational mantra commits van Oostendorp to direct syn-
tax, and also to the absence of readjustment (§ 91, called non-isomorphism 
in Prosodic Phonology, § 416), which is only possible when a computational 
system carries out mapping. We will see in § 511 below, however, that van 
Oostendorp in fact grants for regular mapping-created prosodic constitu-
ency, thereby building a hybrid system where all channels are open (while 
direct syntax and prosodic constituency ought to be competitors (see § 416). 
 
507  8.2.4. Independent representations marshal GEN and afford to be coloured 
 
The critical instrument of van Oostendorp's analysis under  (198) are auto-
segmental representations: the old and the new are defined by the 
(non-)association to some (phonological or morphological) constituent. It is 

More direct syntax: continuity between morphology and phonology 421 
also clear that only sovereign representations in the sense of § 453 will do. 
That is, representations need to have absolute validity: they must not be 
under the spell of the constraint chamber. 
According to van Oostendorp, this is guaranteed by Consistency of 
Exponence. This notion has been introduced by McCarthy & Prince (1993, 
1994); it prohibits changes in the exponence of a phonologically specified 
morpheme. That is, the relationship between a morpheme and the phono-
logical material that represents this morpheme in its lexical specification 
are one-to-one. No material created by phonological processes can have a 
morphological affiliation, and no morpheme can acquire a phonological 
representative that was absent from the lexicon. 
Van Oostendorp represents the players of this rigid correspondence 
by colours: the material of a given morpheme (both its morphological and 
phonological representatives) has a uniform colour, which is distinct from 
the colour of other morphemes. New material, i.e. which results from pho-
nological processes, is colourless. An example of how a representation that 
distinguishes old (coloured) and new (colourless) material looks like ap-
pears under  (201) below. 
Consistency of Exponence effects an important restriction on GEN, 
which is not all-powerful anymore (McCarthy & Prince 1993, 1994 are 
explicit on this fact): the colour-based formulation of van Oostendorp 
(2006a:105) states that "Gen cannot change the morphological colour of 
any phonological element." 
 
508  8.2.5. Faithfulness between morphological and phonological structure 
 
This representational system allows van Oostendorp (2006a:106, 
2007:125f) to formulate constraints that all have one thing in common: they 
impose restrictions on phonological processing on the grounds of the mor-
phological identity of the items involved (see also van Oostendorp 2005). 
Table  (199) below mentions three examples. 
 
(199) Coloured Containment constraints 
use morphological structure in order to restrict phonological action 
 
a. PARSE-Φ(α)
[against deletion] 
the morphological element α must be incorporated into the phonologi-
cal structure. 

422 
Chap 11: Optimality Theory 
(199) Coloured Containment constraints 
use morphological structure in order to restrict phonological action 
 
b. PARSE-Μ(α)
the phonological element α must be incorporated into the morphologi-
cal structure. 
 
c. ALTERNATION 
if an association line links two elements of colour α, the line should 
also have colour α.
The availability of morphological information in phonology also al-
lows for the formulation of what van Oostendorp calls recoverability con-
straints. Recoverability, in both directions, has a general definition and may 
incarnate as individual constraints. Examples appear under  (200) below. 
 
(200) recoverability constraints 
 
a. Morphological recoverability (MR) 
[a constraint family] 
Phonological structure mirrors morphological structure as closely as 
possible. 
 
1. Integrity 
Old vowels may not contain new material. 
 
2. Morphological syllable integrity 
All segments in a syllable should be in the same morphological 
domain as that syllable. 
The morphological domain of a segment S is the smallest morpho-
logical word in which S occurs. 
 
b. Phonological recoverability 
Every morpheme in the input should be represented in the phonological 
output. 
 
An area where recoverability constraints are useful is opacity: quite 
plausibly, opacity disappears (though perhaps not in all cases) if surface 
representations offer permanent and unalterable access to the underlying 
form. This is the case for Coloured Containment representations (van Oos-
tendorp 2006a:44ff). Consider for example the process /takp/ →[tapi] and 
its surface representation under  (198). Assume that the epenthesis of the 
final vowel was caused by the presence of the /kp/ cluster: in the hypotheti-
cal language at hand, final clusters trigger the epenthesis of a vowel, and a 
subsequent process deletes obstruents in codas. Hence the existence of 
the -i is opaque in the phonetic form [tapi] ± but not when we have access 
to the full-blown representation under  (198) where the epenthesis-
triggering cluster is recoverable. 

More direct syntax: continuity between morphology and phonology 423 
509  8.2.6. Coloured Containment applied to derived environment effects 
 
Another area that suits the coloured distinction between old and new mate-
rial are derived environment effects. These describe a situation where a 
phonological process applies across morpheme boundaries, while strings 
without boundaries remain unmodified (see § 177). That is, the process is 
triggered in presence of new material: the phonological representatives of a 
foreign morpheme are new with respect to the old material of the original 
morpheme. By contrast, the same process does not apply if the agent and 
the patient belong to the same morpheme, i.e. when both are "old". Van 
Oostendorp argues that Coloured Containment is well suited for the analy-
sis of derived environment effects because colours show derived environ-
ments.133
Van Oostendorp (2006a:92ff, 2007:135ff) reviews a number of clas-
sical cases and concludes that derived environment effects always involve 
spreading of some melodic prime (2006a:94, 2007:137). The architecture of 
Coloured Containment allows for the formulation of the constraint (199c) 
ALTERNATION which bears on the colour of association lines: if an associa-
tion line links two elements of colour α, the line should also have colour α.
That is, original pieces of the same morpheme must be linked in the under-
lying form. All other combinations are licit: an association line that is cre-
ated by phonological processing (i.e. a line representing spreading) is ab-
sent underlyingly and therefore colourless. It may thus relate 1) material 
that belongs to different morphemes, 2) material that represents a mor-
pheme and new, i.e. colourless material. Colourless material may either be 
epenthetic or the result of a phonological process such as spreading. 
Consider the following prototypical example from Korean which is 
discussed by van Oostendorp. In this language, voiceless dental stops are 
affricated before -i, provided that both segments belong to different mor-
phemes. Hence /hæ tot-i/ "sunrise NOM" comes out as [hæ dodÉʒi], while 
the underived /mati/ "knot" remains [madi]. The Coloured Containment 
 
133 Derived environment effects traditionally encompass phonologically and mor-
phologically derived environments (§ 179). An environment counts as derived 
in the former sense iff at least one phonological process has contributed to its 
creation. Van Oostendorp (2006a:92ff, 2007:135ff) considers morphologically 
derived environments, which are of primary interest here. He discusses the case 
of phonologically derived environments in van Oostendorp (2006a:96f, 
2007:140f) (more on the Polish case that organises the debate in this area in 
§517). Note that van Oostendorp (2007) is a piece of van Oostendorp (2006a), 
with identical structure and often identical wording. 

424 
Chap 11: Optimality Theory 
representation under  (201) below shows why spreading cannot go into ef-
fect in the latter case (Greek letters in subscript indicate contrasting col-
ours, "c" is shorthand for colourless). 
 
(201) Korean affrication 
 
a. /hæ tot-i/ "sunrise NOM" 
 
b. /mati/ "knot" 
 
tα
oα
dÉʒα
-
iβ
*mα
aα
dÉʒα
iα
α
c
α
c
[high] β
[high] α
As may be seen, ALTERNATION prohibits the existence of the slanted 
line under (201b) (the colourless spreading line relates two items of the 
same colour), but not under (201a) where the colourless spreading line 
associates an α-colour element with a β-colour item. 
Van Oostendorp (2006a:94ff) also analyses Turkish disharmonic 
roots along these lines. In the Turkish root-controlled harmony system, the 
observation is that root vowels impose their backness and roundness to 
suffix vowels as well as to epenthetic vowels, while roots with disharmonic 
lexical material are not harmonised. This is shown under  (202) below. 
 
(202) Turkish disharmonic roots 
 
a. suffixes are harmonised 
 
NOMsg 
GENsg 
NOMpl 
 
 
ip 
ip-in 
ip-ler 
rope 
kɨz
kɨz-ɨn
kɨz-lar 
girl 
 
yüz 
yüz-ün 
yüz-ler 
face 
 
b. epenthetic vowels are harmonised 
 
careful form 
colloquial form  
 
 
pranga 
pɨranga 
fetters 
 
kruvazör 
kuruvazör 
cruiser 
 
 
c. roots may be disharmonic 
 
vali 
governor 
 
 
 
kitap 
book 
 
 
 
bobin 
spool 
 
 
Van Oostendorp argues that the process at hand is a derived envi-
ronment effect because both classes of "new" items ± suffixal vowels and 
vowels that break up an illicit cluster ± are subject to harmony, while "old" 
vowels, i.e. those that represent the same morpheme underlyingly, remain 
unaffected. This is precisely what is predicted by ALTERNATION: colourless 

More direct syntax: continuity between morphology and phonology 425 
lines may relate old root vowels and new epenthetic vowels or suffixal 
vowels that bear a different colour; they may not, however, associate old 
vowels of the same colour. 
510  8.2.7. Anti-Lexical Phonology: the interface representationalised 
 
Interestingly, thus, van Oostendorp's analysis of derived environment ef-
fects is entirely representational: at no point does any procedural element 
intervene. Once the morphologically informed Coloured Containment rep-
resentation is available, the computation is strictly parallel. Therefore, van 
Oostendorp (2006a:5, 2007:144f) insists on the monostratal character of his 
system: only the surface representation is relevant: input representations or 
eventual intermediate steps are not needed. This of course is an interesting 
result for a theory such as OT that has a strong anti-derivational ambition. 
Derived environment effects are typical cyclic effects. As far as I can 
see, they have never been analysed by purely representational means. Van 
Oostendorp's approach may thus be understood as the opposite of Lexical 
Phonology: instead of proceduralising typical representational phenomena 
(§ 213), it representationalises typical procedural phenomena. Whether this 
move can be extended to other cyclic phenomena remains to be seen. 
 
511  8.2.8. Mapping: a second means of talking to the phonology 
 
A number of questions are prompted by the architecture of Coloured Con-
tainment. One regards mapping: what exactly does phonological structure 
in a Coloured Containment representation (abbreviated as φ under  (198)) 
encompass? In case it accommodates prosodic constituency, how has this 
structure been created?  
Roughly speaking, the answer is that the classical Prosodic Hierarchy 
is in place as before, and that the mapping mechanism which is at its origin 
works in the same way as elsewhere in OT. That is, the extra technology of 
Coloured Containment comes in addition to the standard interface mecha-
nism. 
The detail is a little more complicated, though. Van Oostendorp de-
parts from directionality-based mapping, which was introduced by Selkirk 
(1986) and became consensual in OT in the guise of the ALIGN family (see 
§§ 394,457). Van Oostendorp (2006a:50) argues that "the notions 'left' and 
'right' are relevant only for phonology, not so much for morphology or syn-
tax, in which other notions, such as hierarchy and embedding, play a role." 

426 
Chap 11: Optimality Theory 
Instead, he reverts back to Prince & Smolensky's (1993) constraint PR≈LX,
which requires that morpheme boundaries coincide with the boundaries of 
prosodic constituents (but treats right and left boundaries on a par). 
Nevertheless, ALIGN is still present in the grammar: instead of trans-
lating morpho-syntactic into prosodic structure, though, it relates only pro-
sodic constituents among themselves (van Oostendorp 2006a:49). ALIGN 
thus performs a kind of secondary mapping: primary mapping is assured by 
PR≈LX and imports morpho-syntactic information into the phonology. Its 
output, prosodic constituency, is then further aligned. 
This twofold mapping activity somehow interacts with the genuine 
technology of van Oostendorp's system, i.e. Coloured Containment con-
straints  (199) and Recoverability constraints  (200). These compare morpho-
logical and phonological structure, but the latter already includes morpho-
syntactic information that was imported by PR≈LX into prosodic constitu-
ency. 
The existence of two parallel ways for morpho-syntax to bear on 
phonology by representational means needs some clarification, namely 
regarding the issue of an eventual competition (or division of labour). As 
far as I can see, Coloured Containment is the only interface theory that 
allows for two distinct representational means of talking to the phonology. 
 
512  8.3. Sign-Based Morphology (Orgun 1996a) 
 
513  8.3.1. Monostratal HPSG-style representations where syntactic, semantic 
and phonological information is scrambled 
 
Orgun (1996a, 1998, 1999) (also Orgun & Inkelas 2002) proposes a model 
called Sign-Based Morphology (SBM), which is an application of the de-
clarative monostratal approach to the interface. The declarative perspective 
is represented in phonology by Declarative Phonology (Scobbie et al. 1996, 
Coleman 2005), and in syntax by HPSG (Pollard & Sag 1994).134 
134 Monostratalism is a broad architectural issue; it divides approaches before 
decisions regarding particular phonological theories can be made. It is therefore 
not obvious to accommodate the discussion of SBM in the chapter on OT. 
Orgun (1999:252) for example argues that the cyclic issue concerns the organi-
sation of the interface alone and hence is independent of whatever phonological 
theory runs below that. Even though SBM is thus formally agnostic regarding 
the correct phonological theory, Orgun's work has been discussed on an OT 
backdrop, and Orgun couches his analyses in OT. 

More direct syntax: continuity between morphology and phonology 427 
Declarative models share the anti-derivational take with OT. Unlike 
OT, however, Orgun argues that no anti-derivational patches (cyclicity-
killers) are needed for cyclic phenomena in SBM since the general 
monostratal architecture does a non-derivational job at the interface for 
free. According to him, cyclic derivation is a source of serialism only on 
the unwarranted (but standard) assumption that 1) terminal nodes of the 
morpho-syntactic tree are the only information-bearing elements and 2) 
concatenation is different from interpretation.  
By contrast, Orgun holds that rather than just terminal nodes, every 
node of the morpho-syntactic tree is considered a linguistic sign and thus 
fully specified for sound, meaning and morpho-syntactic properties. In 
SBM, every node is thus subject to phonological constraints: its properties 
are the result of a computation over the specifications of its daughters. In 
this perspective, then, "cyclic phonological effects follow as an automatic 
consequence of local tree wellformedness" or, in other words, "in declara-
tive fashion from static constituent structure configurations" (both quotes 
Orgun 1996a:51). 
In order to see how SBM works, first consider under  (203) below the 
regular arboreal representation of the Latin word dix-erā-mus "say past-
perf-1pl", as opposed to its representation in SBM (example from Orgun 
1996b:12). 
 
(203) terminal-based vs. sign-based structure of Latin dix-erā-mus 
a. terminal-based 
b. SBM representation 
 
β
syn  ζ (#10,#7) = #13 
sem ξ (#11,#8) = #14 
phon φ (12,#9) = #15 /dixerāmus/ 
 
α
dix   erā mus
syn  ζ (#1,#4) = #10 
sem ξ (#2,#5) = #11 
phon φ (#3,#6) = #12 /dixerā/
syn  
#1 
sem 
#2 
phon #3 /dix/
syn  
#1 
sem 
#2 
phon #3 /dix/
syn  
#4 
sem 
#5 
phon #6 /erā/
syn  #7 
sem #8 
phon #9/mus/

428 
Chap 11: Optimality Theory 
In SBM, every node is fully specified for phonological, syntactic and 
semantic information. Terminal nodes inherit their material from the lexi-
con (#1 to #9), while the content of a non-terminal node is the result of a 
computation over the material of its daughters at the three levels mentioned 
(#10 to #15). For instance, ξ(#2,#5) applies semantic computation to the 
string that consists of concatenated #2 and #5; the result is the semantic 
value #11. 
The construction of the morpho-syntactic tree is thus concomitant 
with the computation of phonological and semantic properties of the string, 
which necessarily follows the constituent structure from the most embed-
ded to the topmost level. Each node, then, must be well-formed according 
to the constraints defined by each of the three components, i.e. syntax, se-
mantics and phonology. 
 
514  8.3.2. Cyclic effects in SBM 
 
Orgun (1996a:19ff, 1998, 1999:260ff) repeatedly uses the following exam-
ple from Turkish in order to show how SBM handles cyclic effects. He 
reports that Turkish imposes a minimal word constraint on affixed forms, 
which must be at least bisyllabic (while unaffixed items may be monosyl-
labic). This is shown by the word for the musical note "do", which is doo
and fine by itself. When the possessive marker -m is added, though, the 
result of simple concatenation is ungrammatical: *doo-m "my do". One 
could expect this to be solved by the suffixation of another item, which 
makes the overall construction bisyllabic: *doo-m-u "my do ACC". The 
presence of the accusative marker -u, however, does not produce a gram-
matical result either. 
According to Orgun, *doo-m-u, which satisfies the bisyllabic con-
straint on the surface, is ungrammatical because the constraint was violated 
at a previous derivational stage when the accusative marker was not present 
yet. Or rather, in the non-derivational perspective of SBM, the constituent 
dominating doo and -m in the overall structure [[[doo]m]u] is as much ex-
posed to the bisyllabic constraint as the word-level constituent that domi-
nates all three morphemes. That is, "every node in a given constituent struc-
ture is subject to phonological constraints" (Orgun 1996a:19), and the ill-
formedness of any node at any of the three levels (syntactic, semantic, pho-
nological) makes the entire construction ill-formed. 
The ground rule that all constituents must be well-formed regarding 
syntactic, semantic and phonological constraints imposes a ternary struc-

More direct syntax: continuity between morphology and phonology 429 
ture for cases of non-cyclic phonology, i.e. where generalisations are sur-
face-true. Orgun (1996a:23ff) reports that the root je "to eat" may stand 
alone, but as doo-m before is agrammatical when the passive suffix -n is 
added: *je-n. This time, however, the suffixation of another suffix is a valid 
repair: je-n-ir "to eat passive imperfective" is well-formed. This, Orgun 
argues, is due to constituent structure. The word at hand identifies as a flat 
ternary, rather than as a nested structure: the three morphemes are domi-
nated by the same word-level constituent ± hence there is no node that vio-
lates the bisyllabic restriction. 
 
515  8.3.3. There is no interface if all is one and the same thing 
 
The phenomena that Orgun discusses are not typically cyclic. It remains to 
be seen what an SBM analysis of the classical data sets (such as affix 
classes) looks like. But let us assume that all cyclic phenomena can be han-
dled in the way that was shown in the previous section. 
The questions, then, lie on the conceptual side: SBM is a representa-
tive of the monostratal perspective that is known from Declarative Phonol-
ogy and HPSG in syntax. On the count of this approach, all is one and the 
same thing: computation is done in the representation, concatenation and 
interpretation are the same thing, and no difference is made between syn-
tactic, semantic and phonological computation, which all apply at the same 
time to the same object. 
Hence SBM is an instantiation of the monostratal idea according to 
which representations should incorporate as much information as possible 
and thereby provide a correct post hoc picture of what has happened: the 
same representation contains lexical ingredients, computational mecha-
nisms, the full derivational history with all intermediate steps and the final 
result. In short, an accurate description of the overall situation. The ques-
tion is whether linguistics is about a post hoc description of the events, or 
about their explanation. Also, it may be asked whether the monostratal per-
spective is but a notational variant of the regular system that looks at things 
from the linguist's perspective once the battle is over. 
Evidence against the perspective of a notational variant is the ternary 
structure that Orgun is forced to propose in order to analyse non-cyclic 
morphology in Turkish (see the previous section). On the regular modular 
approach where concatenation and interpretation are distinct, no need for 
ternary morpho-syntactic structure arises. Orgun thus has to live with ter-
nary structure (actually with n-ary constituents: a non-cyclic item may be 

430 
Chap 11: Optimality Theory 
made of n morphemes, which will all have to be sisters). This is certainly 
not an easy programme to defend on the morpho-syntactic side. 
Orgun's Sign-Based Morphology is not just an alternative approach 
to the morphology-phonology interaction that may be plugged in in place 
of some other interface theory. It supposes a peculiar view on the architec-
ture of grammar that is at variance with the baseline of structuralist and 
generative thinking where morpho-syntax and phonology (as well as se-
mantics) are different entities (modules). By contrast on monostratal as-
sumptions, everything is one and the same thing. It therefore does not really 
make sense to talk about any interface at all. 
 
516  9. Derived environment effects in OT 
 
517  9.1. Introduction 
 
The OT literature has produced a few original proposals, i.e. which use 
genuine tools of OT, in order to come to grips with derived environment 
effects. Other approaches to the phenomenon that are entertained in OT are 
mere adaptations of previous analyses to the constraint-based vocabulary 
(adding to confusion, they may run under different labels, though). 
Van Oostendorp's (2006a, 2007) Coloured Containment and 
McCarthy's (2003a) Comparative Markedness fall into the former category: 
they attempt to achieve the relevant distinction between the root and affix-
bearing strings by contrasting "old" and "new" items: either by doubling 
each constraint (McCarthy), or by making constraints directly sensitive to 
morphological affiliation (van Oostendorp). Łubowicz (2002) also uses a 
genuine OT tool, Constraint Conjunction. 
Analogy (Burzio 2000a) has also been brought to bear, as much as 
interface constraints (Root Faithfulness, Anttila 2009) and a simple rephras-
ing of the observation that roots are immune in terms of a constraint (Cho's 
2009 FAITH-LEX). The latter is also a revival of Kiparsky's old attempt at 
deriving derived environment effects from the Elsewhere Condition. Fi-
nally, Yu (2000) implements a specific mini-phonology for roots (a root co-
phonology). 
 

Derived environment effects in OT 431 
518  9.2. Coloured Containment and Constraint Conjunction (Łubowicz) 
 
We have already seen one way to handle derived environment effects in 
OT: van Oostendorp's (2006a, 2007) Coloured Containment (§ 509). Van 
Oostendorp (2006a:98ff, 2007:141ff) also provides a review of three other 
OT-based approaches to derived environment effects, i.e. Constraint Con-
junction, Comparative Markedness and Root Faithfulness. 
Let us first look at the former. Discussion here entirely revolves 
around classical and oft-quoted data from Polish. These have originally 
been introduced by Rubach (1984:120f), whose analysis is adapted to OT 
by Łubowicz (2002, 2004, 2005). The case at hand is peculiar insofar as it 
concerns a phonologically derived environment (rather than a derived envi-
ronment that is created by morphological concatenation, see § 179). That is, 
a process goes into effect when it applies to an input that is itself the result 
of a phonological operation, but does not apply to items that were previ-
ously unaffected by phonological computation (i.e. to phonologically un-
derived items). 
In Polish, the palatalised version of /g/ is [ʒ]: róg [ruk] "horn" - 
roż-ek [rɔʒɛk] "id., diminutive", skrag-a [skarga] "complaint" - skarż-yć
[skarʒɨtÉɕ] "to complain". Critical for the argument is the following SPE-
style assumption that Rubach (1984:110ff) has anchored in the analysis of 
Polish: /g/ goes through /dÉʒ/ on its way to [ʒ], even though /dÉʒ/ never ap-
pears on the surface. That is, there are two independent rules, palatalisation 
and (context-free) deaffrication, which apply in this order: the former first 
turns /skarg-ɨtÉɕ/ into /skardÉʒ-ɨtÉɕ/, which then serves as the input into the 
latter; the result is [skarʒɨtÉɕ]. 
Unlike /dÉʒ/ that is the result of the application of palatalisation, un-
derlying /dÉʒ/ does not undergo deaffrication: it surfaces as such. This is 
shown by the word brydż [brɨdÉʒ] "bridge", whose diminutive form is 
brydż-ek [brɨdÉʒɛk] (rather than *[brɨʒɛk]).  
It needs to be stressed that the existence of any derived environment 
issue related to these data hinges on the assumption of the intermediate 
stage /dÉʒ/. On an analysis where /g/ directly palatalises to [ʒ], there is no 
deaffrication process and hence no derived environment effect at all. Recall 
that the intermediate item /dÉʒ/ never appears on the surface: there is no 
independent evidence for it, and deaffrication is context-free. 
In Rubach's orignal analysis, underlying /dÉʒ/ remains unaffected be-
cause the application of the deaffrication rule is restricted to derived envi-

432 
Chap 11: Optimality Theory 
ronments. Łubowicz' analysis relies on the conjunction of a markedness 
constraint which militates against voiceless dental affricates, *dÉʒ, and a 
faithfulness constraint which requires coronal segments to remain coronal, 
IDENT-[CORONAL]. The result of the conjunction, [*dÉʒ
&
IDENT-
[CORONAL]]segment, assigns a violation mark to candidate segments which 
are dÉʒ and unfaithful to their coronal origin at the same time. This is the 
case of intermediate /dÉʒ/ in /skardÉʒ-ɨtÉɕ/ (from /skarg-ɨtÉɕ/), but not of under-
lying /dÉʒ/ in [brɨdÉʒɛk] (from /brɨdÉʒɛk/). 
Van Oostendorp (2006a:98f, 2007:142f) raises two objections against 
this analysis. For one thing, the formal tool of Constraint Conjunction is 
unrestricted, which means that derived environment effects related to the 
conjunction of any two constraints should be observed. This is obviously 
not the case since there is a non-arbitrary relationship between dÉʒ and deaf-
frication (rather than, say, dÉʒ and ONSET). 
The second objection points out that Łubowicz' analysis is made for 
phonologically derived environments: it has got nothing to say about mor-
phological divisions. It is therefore difficult to see how it could be extended 
to regular morphologically derived environment effects. Van Oostendorp 
shows that the limitation to the "segment" as the domain of application of 
Łubowicz' conjunction [*dÉʒ & IDENT-[CORONAL]]segment is a stipulation that 
does not follow from anything; monster languages are described if the por-
tion of the linear string to which the conjunction applies is varied. 
Łubowicz' (2005) attempt to restrict the domain of application to the seg-
ment requires McCarthy's (2003a) Comparative Markedness, on which 
more below. 
Van Oostendorp argues that derived environment effects, whether 
concerning phonologically or morphologically derived environments, are a 
unitary phenomenon and hence call for a uniform analysis. What all de-
rived environment effects have in common is the fact of distinguishing old 
from new material: old either in terms of morphological concatenation or in 
terms of phonological derivation (epenthesis, palatalisation etc.). This dis-
tinction, van Oostendorp argues, is correctly expressed by his colours. 
 
519  9.3. Comparative Markedness (McCarthy) and analogy (Burzio) 
 
Like van Oostendorp's Coloured Containment, McCarthy's (2003a) Com-
parative Markedness distinguishes between old and new items ± not fea-
tures, segments or morphemes, though, but constraints. That is, every 

Derived environment effects in OT 433 
markedness constraint divides into a version that refers only to old viola-
tions, and another one that counts only new violations. For example, *dÉʒNew 
will apply only to "new" dÉʒ, that is to those that were not underlyingly pre-
sent. By contrast, *dÉʒOld will concern underlying items, but not those that 
are produced by GEN. High ranking *dÉʒNew therefore achieves the derived 
environment effect observed in Polish. 
An argument against using Comparative Markedness for derived en-
vironment effects is that the reverse situation, i.e. high ranking *dÉʒOld, pro-
duces "non-derived environment effects", that is in our case the deaffrica-
tion of underlying, but not of derived dÉʒ. This pattern, however, is absent 
from the record: only underived environments block the application of 
rules. 
Also, Comparative Markedness only distinguishes old and new con-
straints ± no statement is made regarding morphological divisions. It is 
therefore unable to distinguish between old and new morphemes; the exten-
sion of the analysis to morphologically derived environments is thus im-
possible without additional machinery. The extra machinery that Compara-
tive Markedness uses in order to get to grips with morphologically derived 
environments is analogy, i.e. Output-Output faithfulness in terms of OT. 
Recall from § 497 that OO-constraints have also been used as a cyclicity 
killer. Old and new morphemes are then distinguished by Output-OutputNew 
constraints, which are only satisfied if the violation was absent in the un-
derlying form. 
Van Oostendorp (2006a:99, 2007:143) points out that this mecha-
nism, just like for phonologically derived environments, predicts the exis-
tence of unattested monster languages. This is because Output-OutputNew 
implies the existence of Output-OutputOld, which counts violations only if 
there is an underlying form in which they are already present. This allows 
for constructing anticyclicity, i.e. a pattern where a process applies to 
mono-morphemic items, but is blocked when a morpheme boundary is 
present in the string. This would be an underived environment effect, some-
thing that is just as unattested as blocking in phonologically derived envi-
ronments. 
Finally, OO-constraints have also been used alone in order to account 
for derived environment effects: according to Burzio (2000a,b), their multi-
functionality also covers this phenomenon. 
 

434 
Chap 11: Optimality Theory 
520  9.4. Direct syntax (interface constraints): Root Faithfulness (Anttila) 
 
Of course, the easiest way of making a difference between underived roots 
and a morphologically complex string is to make direct reference to the 
root. We are thus back to a version of interface constraints, which ± in overt 
violation of Indirect Reference ± make direct reference to designated mor-
pho-syntactic categories (see § 494). 
This is what Anttila (2009) promotes: he makes faithfulness con-
straints selectively applicable to roots only, which of course produces the 
desired effect. If FAITH-ROOT outranks the constraint that is responsible for 
the process at hand, modified candidates will be optimal everywhere but in 
roots. In other words, Root Faithfulness simply translates the descriptive 
observation into a morphological diacritic which is placed on constraints 
and restricts their application to a subset of morpho-syntactic categories. 
 
521  9.5. Revival of the Elsewhere Condition (Cho, Iverson) 
 
Anttila's (2009) analysis of derived environment effects appeared in the 
same book as Cho's (2009), a Festschrift for Paul Kiparsky. Iverson (2004) 
is a development of Cho's contribution, which circulated as a manuscript 
(dated 2002 by Iverson).  
Cho (2009) argues for a revival of Kiparsky's (1982a,b) attempt to 
interpret derived environment effects in terms of the Elsewhere Condition. 
Recall from § 191 that this requires to make each lexical entry a rule whose 
output is identical to its input (lexical identity rules). Since no rule can be 
more specific than lexical identity rules which simply rewrite their input, 
all rules that try to modify lexical entries in isolation will be failed by the 
Elsewhere Condition which in case of competition gives precedence to the 
more specific rule. Rules that try to modify plurimorphemic strings, how-
ever, will not have to compete with lexical identity rules since there is no 
lexical entry corresponding to the morphologically complex item. 
In the OT adaptation of Cho (2009), the prohibition for isolated lexi-
cal items to be modified by phonological computation is called Lexical 
Faithfulness. It is encoded as such in a top-ranked constraint, FAITH-LEX:
"output candidates must not be distinct from corresponding lexical entries". 
GEN may thus produce all kinds of variation of a mono-morphemic item: 
all modified candidates will incur a fatal violation of FAITH-LEX, to the 
effect that the completely faithful candidate always wins. As in Kiparsky's 
original version, morphologically complex candidates whose underlying 

OT is a strong modularity-offender: violations are in-built 435 
form was modified will not be eliminated by FAITH-LEX since there is no 
corresponding lexical entry that they need to be faithful to. 
This analysis simply translates the observation that mono-morphemic 
items do not change into the prose of a constraint, which is made undomi-
nated. The same questions then arise as in the 80s: it is not true that mono-
morphemic items remain unaltered all through. They are affected by "low-
level", "phonetic" or "automatic" processes: the structure-building vs. struc-
ture-changing distinction may be relevant, which means that underspecifi-
cation becomes an issue as well. This has all been discussed in the 80s (see 
§§ 192ff), and Iverson (2004) tries to implement the insights gained together 
with his own in the FAITH-LEX frame defined by Cho (2009). 
 
522  9.6. Co-phonologies (Yu) 
 
Finally, Yu (2000) puts co-phonologies to use in order to account for de-
rived environment effects: a specific mini-grammar is devoted to roots. 
These therefore experience a phonological computation that is different 
from strings that contain affixes. In Yu's (2000:122) terms, a root-specific 
phonology φroot is thus opposed to an affix-specific phonology φaffix.
523  10. OT is a strong modularity-offender: violations are in-built 
 
524  10.1. Modularity yes or no ± this is the question, however rarely addressed 
in the OT literature 
 
The OT literature is not very wordy regarding architectural issues. Kager's 
(1999) overview of the theory for example offers a chapter on acquisition 
and OT syntax, but relations of phonology with morpho-syntax are only 
mentioned in a sub-chapter on alignment (and the modular issue is entirely 
absent as far as I can see). The existence of modules implies a derivational 
relationship between them, which in (Chomskian) linguistics comes down 
to the inverted T (§ 86): the input to phonology (and semantics) is somehow 
the output of syntax. At best, then, the modular architecture (on which more 
in the Interlude § 586) appears to be a background assumption in OT that 
most of the time remains implicit and does not really impact particular 
analyses. 

436 
Chap 11: Optimality Theory 
Russell (1997) describes the interface landscape in OT as follows. 
 
(204) "It is often tacitly assumed that there is a morphology-like component which 
chooses the right underlying representations and ships them off to GEN in 
the phonological component, complete with handy morphological annota-
tions like 'Prefix' or 'Stem', but little effort has been spent on figuring out 
what this component is or how it works. In fact, while there is a growing 
body of work in OT syntax and OT phonology, there are still few clear ideas 
about how they relate to each other. Is there a classical serial relationship 
between the two, with an OT syntax first calculating the optimal syntactic 
representation, which then serves as the input to an OT phonology (perhaps 
stopping off at an OT morphology component in the middle)? Or is there 
some larger, integrated grammar, where EVAL chooses all at once the best 
overall combination of a phonological, a syntactic and a semantic represen-
tation?" Russell (1997:129) 
 
Two years later, he confirms that the classical modular architecture 
with a serial order among modules is the regular backdrop of work in OT. 
 
(205) "Most work in OT seems to have implicitly adopted this assembly-line view 
of the overall architecture of language. While individual modules (specifi-
cally phonology and syntax) are argued to function non-derivationally, the 
relationship between modules is usually assumed to be linear and direc-
tional. Each module has an input and an optimal output ± the inputs come 
from somewhere, and the outputs go somewhere for further processing." 
Russell (1999:6) 
Burzio (2007), another item of the sparse body of literature that dis-
cusses the architecture of grammar in OT, does not merely mourn the deri-
vational legacy of generative thinking, or leave it at a timid suggestion for a 
fully scrambled constraint chamber that encompasses phonetics, phonology, 
morphology, syntax and semantics. Addressing modularity explicitly, 
Burzio declares that this view of the architecture is falsified and needs to be 
overcome. 
 

OT is a strong modularity-offender: violations are in-built 437 
(206) "The mainstream generative tradition had postulated discrete modules that 
feed one another in a cascading arrangement: Morphology would feed Pho-
nology which would then feed Phonetics. This hypothesis makes grossly 
incorrect predictions about the range of possible interactions. It predicts that 
Phonology could not be driven by Phonetics except perhaps indirectly via 
evolutionary effects that weed out phonetically ill-suited phonologies, and it 
predicts that Phonology may not have any effect on Morphology. The incor-
rectness of the first prediction has been forcefully underscored by a very 
productive line of work of recent years aimed to show how perceptual cues 
and perceptual distances are behind phenomena that have been the tradi-
tional bread and butter of phonological work. See, e.g. Hayes et al. (2004). 
The present article addresses the incorrectness of the second prediction, by 
considering syncretism ± an eminently morphological phenomenon, which 
is nonetheless controlled by phonological factors in certain cases." Burzio 
(2007:1) 
 
This statement is commendable since it clarifies the situation: in this 
perspective modularity-violating OT practice is no longer in contradiction 
with the architectural superstructure. On the other hand, though, it requires 
a revision of the general generative philosophy, which is deeply anchored 
in the modular approach. If Burzio is right, the generative approach to lan-
guage as we know it for some fifty years is fundamentally wrong, and so is 
current syntax where clear-cut modular contours are the heart of Phase 
Theory and indeed of the interface-driven minimalist programme. 
The issue of whether modularity is right or wrong is not addressed on 
the pages below. The Interlude § 586 is devoted to the presentation of 
modularity in Cognitive Science and the generative enterprise. The follow-
ing sections merely identify in which way exactly OT systematically or 
occasionally (i.e. depending on the tools chosen by the analyst) violates 
modularity. Also, the connectionist part of its genetic endowment that in-
veigles to modularity violation is discussed (§ 529). 
In sum, OT is a strong modularity offender, but we have seen in pre-
vious chapters that OT is not alone in this respect in generative quarters 
(SPE in § 99, direct syntax approaches in §§ 137, 407). A summary of gen-
erative modularity offenders is provided in § 702 below.  
In completion of the discussion in § 469, three critical issues regard-
ing the positioning of OT with respect to modularity are thus discussed 
below: ALIGN and WRAP make permanent reference to morpho-syntactic 
categories, the formulation of constraints often conflates phonological and 
morphological statements, and mapping is done in the phonology (i.e. 
ALIGN and WRAP are interspersed with regular phonological constraints), 
rather than in modular no man's land. 

438 
Chap 11: Optimality Theory 
525  10.2. Direct Syntax in OT is regular and uncontradicted 
 
The debate between direct syntax approaches and Indirect Reference that 
lied at the heart of the interface debate in the 80s has been reviewed in 
§406. The position that is consensual in generative thinking since then is 
that reference to morpho-syntactic information is necessarily indirect. Also, 
direct syntax and Indirect Reference are in competition: there is no way to 
make both perspectives coexist. If direct reference to morpho-syntactic 
information is permitted, Prosodic Phonology is superfluous and has to go. 
Against this backdrop, the observation is that the OT literature makes 
regular use of direct reference to morpho-syntactic categories, typically 
without addressing the issue raised by Indirect Reference. Also, direct syn-
tax elements and prosodic constituency appear to regularly coexist without 
this causing indisposition. Hence the Prosodic Hierarchy is inherited from 
the 80s, but made an empty shell. Pak (2008:60ff) and Samuels 
(2009a:284ff) are rare occasions where the existence of the Prosodic Hier-
archy in a direct syntax environment is (rightfully) called into question (see 
also § 580). 
Three instances of direct syntax in OT have been discussed: interface 
constraints (§ 494) are the most overt representatives, but van Oostendorp's 
Coloured Containment (§ 503) also falls into this category. The most fre-
quent use of direct reference to morpho-syntactic items, however, is made 
by ALIGN and WRAP. This instance of direct syntax is important since the 
constraints at hand are used by all versions of OT as far as I can see. 
Note that ALIGN and WRAP not only make reference to morpho-
syntactic (tree) structure: they also constantly refer to morpho-syntactic 
labels (the stem, the DP etc.). Kager (1999) for example summarises the 
activity of ALIGN as follows. 
 
(207) "The categories 'Cat1' and 'Cat2' range over the alphabets of grammatical and 
phonological categories, for example: 
(68) GrammCat:  {Word, Stem, Root, Affix, «} 
 
ProsCat:  {PrWd, Foot, Syllable, Mora, «} 
These categories can also be filled by specific morphemes in the grammars 
of individual languages." Kager (1999:118f, emphasis in original) 
 
This is also true for Stratal OT which, recall from § 488, fosters a par-
ticular interest in constraining the access of phonology to morpho-syntactic 
information. Bermúdez-Otero (1999:112) says that alignment constraints 
should have a "very limited access to non-phonological categories". The 
issue, however, is categorical, not gradient: either there is or there is no 

OT is a strong modularity-offender: violations are in-built 439 
direct reference to morpho-syntactic categories. Violating Indirect Refer-
ence just a little bit has exactly the same effect as violating it a whole lot: 
modularity and the Prosodic Hierarchy are thrown over board. 
 
526  10.3. Parallel mapping puts the Translator's Office in the phonology 
 
Another effect of constraint-based mapping has been discussed in § 458: 
translation and reference to the output of translation are conflated. In Pro-
sodic Phonology, translation is done by mapping rules; phonological proc-
esses then make reference to its output, the Prosodic Hierarchy. These ref-
erence-making processes are necessarily different from the mapping activ-
ity, which they must serially follow. 
This is also required by the modular architecture: mapping rules have 
access to both morpho-syntactic and phonological structure since they con-
vert one into the other. Modules are domain specific and hence cannot 
parse the categories of other modules (§ 611). Therefore, translation cannot 
be done in either morpho-syntax or phonology: the Translator's Office must 
stand in modular no man's land (see § 413). 
The effect of parallel mapping, however, is that translation is done in 
the phonology: ALIGN and WRAP are interspersed with regular phonological 
constraints in the same constraint ranking. This situation is incompatible 
with a modular architecture. 
 
527  10.4. Scrambling: morpho-phonological contours are blurred 
 
The parallel ambition of OT fosters a tendency to scramble the computation 
of information that belongs to different domains: morphological, phono-
logical, phonetic and perhaps even syntactic and semantic constraints co-
habitate in the same constraint chamber. 
It was shown in § 469 that this everything-is-one perspective appears 
to be the default assumption in classical OT. The undifferentiated applica-
tion of the anti-derivational philosophy has created this trope which the 
theory itself does not enforce: the piece-transporting mechanism (cyclic 
spell-out) could be perfectly derivational if the parallel ambition were re-
stricted to phonology proper (the phonological module). 
Kager (2000) promotes quite the opposite view: rather than consider-
ing the scrambling of phonological and morphological constraints a prob-

440 
Chap 11: Optimality Theory 
lem, he argues that this morpho-phonological intimacy is an advantage: the 
more modular contours are blurred, the better a theory fares. 
 
(208) "Phonological and morphological constraints are ranked together in a single 
hierarchy. One might argue that parallelism is the counterpart of the 'inter-
leaving' of morphological and phonological rules in the derivational model 
of Lexical Phonology. However, parallel Correspondence Theory predicts a 
broader kind of sensitivity of morphology to phonology than is possible 
under interleaving Lexical Phonology. While interleaving restricts phono-
logical sensitivity of affixation to properties that are present in the stem 
'before' the affixation, the parallel model allows for sensitivity to the full 
range of output properties of the base-plus-affix combination." Kager 
(2000:123) 
 
Here again, the total-scrambling view is exposed without discussion 
of the fact that it conflicts with the basic generative interface architecture 
and modularity. 
Another issue is the body of constraints itself: since formulations are 
in prose and entirely unrestricted, they may well, and actually do, contain 
both phonological and morphological instructions. Hence even if there 
were a ban on interspersing phonological and morphological constraints, 
modular contours would still be blurred since it is sometimes impossible to 
decide whether a constraint is morphological or phonological in kind. 
Yip (1998) is explicit on this indecision. 
 
(209) "These results make it hard to identify a clear dividing line between mor-
phology and phonology. What is more, they go much further to blur the 
distinction than does the interleaving of phonology and morphology found 
in lexical phonology. In lexical phonology, each component has its own 
character: the entities are different, and the rules are different. In Optimality 
Theory, this is not necessarily the case. Alignment is the most striking ex-
ample. Alignment appears to play a role in pure morphology, in pure pho-
nology, and at the interface." Yip (1998:219) 
 
But of course, even if phonological and morphological constraints 
could be properly distinguished, this would not guarantee a modular segre-
gation: with explicit reference to Natural Generative Phonology, Green 
(2007) does away with constraints whose body is ambiguous, but crucially 
maintains scrambling of the clean phonological and morphological result. 
 

OT is a strong modularity-offender: violations are in-built 441 
(210) "The role of phonology [reduces] to those processes that can be analyzed 
solely in terms of universal markedness constraints and their interaction 
with faithfulness constraints, while placing the responsibility for processes 
that make reference to language-specific properties in the domain of mor-
phology, by using language-specific morphological constraints that are 
ranked in the same hierarchy with faithfulness constraints und universal 
markedness constraints." Green (2007:171) 
 
The only voice that I have come across which pleads for a clear dis-
tinction between phonology and morphology as well as for a restricted 
(rather than an unlimited) access to morphological information is Ber-
múdez-Otero's (forth a) Stratal OT (§ 488). But even here, parallel mapping 
introduces massive direct reference to morpho-syntactic categories, in vio-
lation of modularity. 
 
528  10.5. Radical scrambling: one single constraint ranking for morpho-syntax, 
semantics and phonology 
 
Russell (1999) argues for a radical version of the scrambling perspective 
which, though more articulated, joins monostratal HPSG practice where all 
is one and the same thing anyway (see § 512): language is made of one sin-
gle constraint chamber where morpho-syntactic, semantic and phonological 
constraints are interleaved (a slightly less radical variant is Wolf's 2008 
system where phonology and morphology, but not syntax, are merged into 
the same constraint hierarchy, see § 472). Russell (1997:129) entertains this 
view as a mere option (see the quote in § 524), but adopts it two years later. 
(211) "An OT grammar evaluates all sub-representations (e.g., phonology, syntax, 
semantics) in parallel. There is no serial derivation between modules such 
that, for example, syntax is the 'input' to morphology or phonology. [«] 
MOT [Russell's model] rejects the assembly-line view of how sub-
representations are related to each other. It takes seriously the claim that the 
job of a grammar is not to construct a representation to order (or even to 
choose a representation based on some input), but simply to look at a com-
plete linguistic representation and judge whether it is a legal or illegal repre-
sentation of the language." Russell (1999:5f) 
 
The serial relationship between modules (the assembly-line view), 
Russell argues, is unwarranted in a parallel perspective. However, he does 
not argue against modularity as such: on his analysis modular status is 
granted to morpho-syntax, semantics and phonology because they "deal 

442 
Chap 11: Optimality Theory 
with qualitatively different kinds of formal stuff" (Russell 1999:15). As a 
consequence, they enjoy different representations. Rather than being sub-
ject to three distinct computations, however, these are then evaluated by 
grammatical activity in parallel and at the same time. That is, an "OT 
grammar can impose interface constraints [in the sense of § 494] on which 
phonological, syntactic, and semantic representations can co-occur with 
each other" (Russell 1999:5). 
This view is incompatible with Fodorian modularity for sure: mod-
ules are computational units. It does not make sense to dissociate represen-
tations, which contain the domain specific vocabulary that is computed, 
from the computation itself. There is no way for distinct representations to 
live in different modules while being subject to a uniform computation. 
 
529  10.6. Two souls are dwelling in OT: generative and connectionist 
 
Regular practice in OT has reached an unprecedented degree of scrambling 
between phonological and extra-phonological information. As it stands, the 
result is incompatible with a modular architecture. Modularity, however, is 
the spine of generative interface theory. This issue is largely unreflected in 
the OT literature. As far as I can see, no intrinsic property of OT requires to 
go down the non-modular road, even if the scrambling of information from 
all sides appears to be a typical trope in OT. On the other hand, it is also 
true that OT would have to undergo a thorough revision of deeply rooted 
elements such as ALIGN, should it be made compatible with modularity. 
The reason for the OT trope to blur contours of functional units may 
well be the orientation of the theory towards constraint-satisfaction. Before 
OT was born, constraint satisfaction and parallel (rather than serial) compu-
tation was identified as a core property of connectionism, the theory of the 
cognitive system that competes with modularity (see § 588). David Rumel-
hart, a major figure of the connectionist approach, provides the following 
explanation of how computation works in connectionism. 
 
(212) "In addition to the fact that connectionist systems are capable of exploiting 
parallelism in computation and mimicking brain-style computation, connec-
tionist systems are important because they provide good solutions to a num-
ber of very difficult computational problems that seem to arise often in 
models of cognition. In particular they are good at solving constraint-
satisfaction problems. [«] 

OT is a strong modularity-offender: violations are in-built 443 
Many cognitive-science problems are usefully conceptualized as constraint-
satisfaction problems in which a solution is given through the satisfaction of 
a very large number of mutually interacting constraints. The problem is to 
devise a computational algorithm that is capable of efficiently implementing 
such a system. Connectionist systems are ideal for implementing such a 
constraint-satisfaction system." Rumelhart (1989:142) 
Based on such a description, an independent observer may conclude 
that OT is a connectionist theory. This impression will be reinforced by 
another contrast between connectionism and modularity: the former pro-
motes an all-purpose computation where computational units can work 
with any input and are not specialised for any particular task, while the 
latter devises specific and unexchangeable computational units that only 
understand a particular vocabulary and are only able to carry out a particu-
lar task (§ 597). 
Connectionism is indeed a significant piece of OT's genetic endow-
ment: Paul Smolensky comes from Cognitive Science and was at the fore-
front of the connectionist scene when the theory individuated from Artifi-
cial Intelligence in the mid 80s (Smolensky 1987, 1988a,b). Smolensky 
(2003:385f) himself explains this development, and the connectionist foun-
dations of OT are laid out at length in Smolensky & Legendre (2006). Ob-
viously, however, OT is also a symbolic theory: connectionist parallel dis-
tributed computation works on symbolic units, typically segments. This is 
in contradiction with connectionism, which is content-free, i.e. rejects sym-
bolic representations (see § 593). Smolensky & Legendre (2006) precisely 
set out to bridge this gap. This line of attack is reminiscent of the early 
days, when connectionism and traditional symbolic theories were under-
stood as complementary, the former being an interesting way of implement-
ing the latter at a lower level that is closer to neurology (the sub-symbolic 
level). Connectionism only grew into an irreconcilable competitor of the 
standard symbolic approach as the theory unfolded (see § 599). 
Surely many OT practitioners live in the belief that OT is a straight 
generative theory ± which it is, but only on the one hand. On the other 
hand, connectionism was inserted into its genetic code before OT was born, 
and silently pushes the theory to conflict with modularity and generative 
essentials ever since. The pre-natal bridge to connectionism is not usually 
made explicit in the OT literature, and the same goes for its connectionist 
behaviour (see Scheer 2010a, forth).  
In a connectionist environment, the all-is-one trope of OT makes per-
fect sense and is actually welcomed. In a modular perspective, it is a con-
stant source of conflict. The conclusion, then, is as before: OT needs to 

444 
Chap 11: Optimality Theory 
make up its mind where it stands, and to face the consequences of this deci-
sion. 
 
530  11. Conclusion 
 
OT does not make any representational contribution to the question of how 
extra-phonological information is processed in phonology because it does 
not develop genuine phonological vocabulary. Rather, the Prosodic Hierar-
chy is adapted to the constraint-based environment in the same way as 
other representational tools of the 80s are. On the procedural side, the anti-
derivational stance of classical OT has prompted anti-cyclicity, an attitude 
that in fact rejects the existence of any procedural aspect in interface man-
agement.  
This means that Interface Dualism is abandoned together with cyclic 
derivation (inside-out interpretation), two hallmarks of generative thinking. 
The global application of the anti-derivational requirement to grammar 
without differentiating between phonology and the interface (or even mor-
phology and syntax) is another serious issue (§ 469). No property of OT 
forces it to go down this road (the anti-derivational ambition concerns pho-
nological computation, not the interface), and Stratal OT/DOT indeed pro-
mote an architecture where relations with morpho-syntax are serial, while 
phonological computation proper is strictly parallel. 
As elsewhere in OT, competing and incompatible solutions have 
been proposed for the same problem, cyclicity in our case. There are not as 
many cyclicity-killers as there are opacity-killers, but the phenomenon is 
the same: distinct and eventually incompatible proposals coexist without 
this arousing much comparative discussion (§ 484). This is true namely for 
modern heirs of Lexical Phonology, i.e. solutions that accommodate mor-
pheme-specific mini-grammars, which may be parallel (co-phonologies, 
indexed constraints) or serially ordered (Stratal OT, DOT).  
A genuine contribution to interface theory is the way in which OT 
implements mapping, i.e. the translation of morpho-syntactic structure into 
prosodic constituency. Constraint-based mapping follows from the unavail-
ability of ordered (mapping) rules. It introduces a new logic whereby the 
translational process and the phonological reference to its result are 
merged: ALIGN and WRAP do all the job at once (§ 457). While this may 
appear to be a technical advantage at first, it turns out to be part of the seri-
ous issue that OT has with modularity: mapping is done in the phonology 
(rather than in modular no-man's land). 

Conclusion 445 
A strength of OT is certainly the description of a large array of typo-
logical variation with a small set of interacting constraints. This aspect of 
the theory comes to bear in the area of mapping: the formerly monolithic 
Strict Layer Hypothesis has been split into various smaller and violable 
units. Also, the study of mapping-conditioning factors that were not in the 
focus of previous research has been promoted (eurhythmy, information 
structure) (§ 461). 
The mapping puzzle as such, however, remains untapped: as in pre-
vious theories, we still have no handle on why this or that group of mor-
pho-syntactic boundaries do or do not provoke a phonological effect. 
Finally, OT has a serious issue with the generative architecture of 
grammar because of its misty and largely unreflected relationship with 
modularity. OT appears to have a natural tendency to scramble conditioning 
factors of various ontological and linguistic origins in the same constraint 
chamber. It seems to me that this tendency is not just the result of a particu-
lar practice that could as well be different; rather, it is a trope that roots in 
output orientation, competition and parallelism, in short: in the connection-
ist endowment of OT. OT is by far not the only modularity offender in gen-
erative quarters (a summary is provided in § 702), but its offending charac-
ter is systematic and deeply rooted (Scheer 2010a, forth). 


Chapter 12 
531  Distributed Morphology 
532  1. Introduction 
 
The centre of gravity of Distributed Morphology revolves around anti-
lexicalism, late insertion, the non-difference of morphology and syntax and 
the distribution of list-type information over three distinct lexica. Relevant 
references include Halle & Marantz (1993), Halle (1997a), Marantz 
(1997a), Embick & Noyer (2007), Embick (forth); Harley & Noyer (1999) 
provide a well informed overview. 
The communication of morpho-syntax with phonology is not a pri-
mary concern of Distributed Morphology; therefore relatively little work 
has been done that is directly relevant for phonology. 
As we will see below, Distributed Morphology has an issue with 
Lexical Phonology, namely with the Lexicon. This is consistent with the 
fact that it rejects morpheme-specific mini-phonologies ± not explicitly, but 
constantly in practice. That is, Distributed Morphology follows the classical 
take of SPE whose modern incarnations are Halle & Vergnaud (1987a) and 
Kaye (1995): the same computational system assesses strings of whatever 
morphological composition.135 
On the other hand, Distributed Morphology subscribes to Chomsky's 
derivation by phase (§ 304), which means that it is interactionist ± like 
Lexical Phonology and Kaye (1995), but unlike SPE and Halle & Vergnaud 
(1987a). 
The roadmap is as follows. The issue that Distributed Morphology 
has with Lexical Phonology is introduced in § 533 together with the central 
tenets of the theory. The analysis of opacity in Distributed Morphology is 
then discussed in § 541: the classical view where it is the result of computa-
tion (selective spell-out and Phase Impenetrability) is opposed to the DM 
alternative that is based on a contrast in arboreal structure (direct merge of 
the root with a morpheme). Other relevant aspects are the free distribution 
of phonological and semantic opacity (§ 564), the eventual independence of 
PF and LF phases (asymmetric spell-out, § 567) and the difference between 
predictable (párenthood) and unpredictable (cómparable) PF opacity 
(§ 568). The possible existence of lexicalist analyses in the anti-lexicalist 
 
135 Recall from §§ 234, 283 that chunk-specific phonologies are a separate question. 

448 
Chap 12: Distributed Morphology 
environment of Distributed Morphology is discussed in § 569, and finally 
the modularity-offending device PF movement is considered (§ 574). 
 
533  2. Setting the scene: Distributed Morphology vs. Lexical Phonology 
 
534  2.1. From Halle & Vergnaud (1987a) to Distributed Morphology: against 
the two-place approach 
 
Halle & Vergnaud (1987a) may be interpreted as a first attempt to unhorse 
Lexical Phonology which, however, was too dominant in the 80s in order 
for a frontal attack to be successful. Halle & Vergnaud therefore chose a 
reformist, rather than a revolutionary strategy (Halle 1997b:302 talks about 
"the Halle & Vergnaud 1987a version of lexical phonology", see § 218). 
What they do, however, is to eliminate the two headstones of Lexical Pho-
nology, morpheme-specific mini-phonologies and interactionism (§ 212). 
While Distributed Morphology (and thus Morris Halle) subscribes to 
derivation by phase and hence to interactionism (§ 304), Halle & Vergnaud's 
rejection of morpheme-specific mini-phonologies is carried over. Recall 
from § 303 that this is consistent: derivation by phase is the modern incarna-
tion of Halle & Vergnaud's selective spell-out (§ 225), which does the same 
job as morpheme-specific mini-phonologies; having both devices in the 
same theory would be redundant (§ 303). 
The modern charge against Lexical Phonology that completes this 
programme is led by Marantz (1997a, 2001). The bone of contention is the 
Lexicon: Lexical Phonology concatenates items in two distinct and proce-
durally separated locations, and it computes the interpretation of sound and 
meaning twice: once in the Lexicon whose output are words, another time 
after syntax, which produces sentences. This is what Marantz (2000, 2001) 
calls the two-place approach, which is depicted under  (213) below. 
Contrasting with this scenario, Distributed Morphology allows for 
only one location where objects are glued together (morpho-syntax); also, 
concatenation is done by a single device, Merge, which operates over mor-
phemes and words alike. Marantz (2000, 2001) refers to this alternative as 
the single engine hypothesis. 
 

Setting the scene: Distributed Morphology vs. Lexical Phonology 449 
(213) architecture of grammar in Lexical Phonology 
 
basic Lexicon 
 
 
Lexicon 
content and output: 
underived roots and 
affixes 
 
concatenation of building 
blocks coming from the basic 
Lexicon. 
Output: words 
computation 
of sound 
computation of 
meaning 
syntax 
concatenation of building 
blocks coming from the 
Lexicon. 
Output: sentences 
 
computation 
of sound 
computation 
of meaning 
 
535  2.2. The single engine approach is agnostic with respect to the phonologi-
cal interpretation of the string (morpheme- and chunk-specific parsing) 
 
Marantz' slogans "No escape from syntax" and "Syntactic hierarchical 
structure all the way down" illustrate the claim that there is only one con-
catenative engine. 
It is important to sort out what exactly the single engine approach is 
incompatible with. As far as I can see, only the existence of two separate 
concatenative systems for the construction of words and sentences conflicts 
with the tenets of Distributed Morphology. Phonological interpretation is 
not concerned at all: Distributed Morphology rejects multiple computa-
tional systems in morpho-syntax, but has got nothing to say about multiple 
computational systems in phonology. That is, from the vantage point of 
DM, PF may or may not accommodate morpheme-specific and/or chunk-
specific mini-phonologies (§ 234). These may indeed be specified to apply 
to different morphemes (level 1 vs. level 2) or chunks (word-level, Pra-
guian segregation) independently of whether the string was pieced together 
by one or several engines. 

450 
Chap 12: Distributed Morphology 
It is only the independent commitment of Distributed Morphology to 
derivation by phase (and hence to Phase Impenetrability) that rules out the 
morpheme-specific perspective (§ 303). 
 
536  2.3. The general architecture of Distributed Morphology 
 
Let us now look at the general architecture of Distributed Morphology. The 
classical inverted T model that grounds generative thinking since the 60s is 
repeated below for convenience (from § 86). 
 
(214) the inverted T model 
 
lexicon 
 
 
morpho-syntax 
 
 
(concatenation of building blocks) 
 
 
PF
(computation of sound)
LF 
(computation of meaning) 
 
Distributed Morphology endorses this scenario but, as was reported, 
conflates syntax and morphology. The theory also elaborates on the status 
and function of the lower part of the syntactic tree: terminal features may 
be (re)arranged by specific (morphological?) processes such as fission, 
fusion and impoverishment. These take place between syntax and lexical 
insertion, i.e. before feature bundles that qualify for morphemic status are 
replaced by phonologically interpretable material. 
Late Insertion embodies the insight that syntax manipulates only ab-
stract morpho-syntactico-semantic features that are void of phonological 
content. This perspective departs from the earlier Government & Binding 
architecture where items with full phonological specification were manipu-
lated in syntax ("sealed suitcases"). 
This is where the name of the theory comes from: rather than having 
a unique lexicon where all information is grouped in the entries of one sin-
gle list, non-predictable properties are distributed over three distinct lists: 
1) the input to the syntax (morpho-syntactico-semantic features), 2) vo-
cabulary items (the input to phonology) which consist only of phonological 
material and replace morpho-syntactico-semantic features upon lexical 

Setting the scene: Distributed Morphology vs. Lexical Phonology 451 
insertion, and 3) the so-called encyclopaedia where vocabulary items are 
associated to meaning, and idioms and non-linguistic knowledge stored.136 
The implementation of Late Insertion supposes a phonological lexi-
con (the vocabulary, consisting of vocabulary items) that is underspecified 
in comparison to earlier practice: vocabulary items do not supply morpho-
syntactic features; they only provide phonological material as well as rele-
vant information regarding the context in which this material may be in-
serted. 
The general architecture of Distributed Morphology is thus like un-
der  (215) below (adapted from Marantz 1997a:204). 
 
(215) general architecture of Distributed Morphology 
 
List 1 
 
 
(morpho-syntactic 
and semantic 
features) 
 
Syntax 
(concatenation of building blocks: 
Merge and Move) 
 
Morphology
(fission, fusion, impoverishment)
Late Insertion 
 
 
List 2:  
vocabulary 
PF 
 
LF 
List 3: 
encyclo-
paedia 
This organisation is discussed in the following section. 
 
136 In Distributed Morphology, the word "idiom" does not just mean "an expres-
sion whose meaning cannot be deduced from the meaning of its components"; 
rather, it refers to any sound-meaning association. Hence "dog" (meaning "ani-
mal with four legs that barks etc.") is as much an idiom as "kick the bucket" 
(meaning "to die") (but grammatical morphemes are not if their meaning fol-
lows from morpho-syntactic features). 

452 
Chap 12: Distributed Morphology 
537  2.4. The unity of syntax and morphology under debate 
 
538  2.4.1. Specific morphological operations: does DM live up to its ambition? 
 
According to Distributed Morphology, there is only one location where 
items can be glued together, and one set of principles that controls the glu-
ing mechanism: "Merge and Move". 
Table  (215), though, depicts syntax and morphology in two distinct 
boxes. This expresses the doubt that Distributed Morphology as it stands 
lives up to its ambition: operations such as fission, fusion or impoverish-
ment have been introduced as a consequence of anti-lexicalism and Late 
Insertion, but are unknown in syntax. A related issue is post-syntactic 
movement (PF movement, Embick & Noyer 2001, Embick & Noyer 
2007:318ff), which also considerably weakens the theory: it splits Merge 
into a syntactic (before vocabulary insertion) and a morphological (after 
vocabulary insertion) version, which do not obey the same locality proper-
ties. This for sure is washing out the ambition of a unified concatenative 
device (more on PF movement in § 574 below). 
In sum, crediting Distributed Morphology with a unified computa-
tion for syntax and morphology is not an easy thing to do. Williams (2007) 
for example raises the question whether Distributed Morphology is really 
that much different from classical lexicalist frameworks. He concludes that 
the difference lies in word, rather than in fact. 
 
539  2.4.2. Voices that argue for the traditional stance: syntax ≠morphology 
 
Beyond the question whether Distributed Morphology stands up to its uni-
tary ambition, the claim that morphology is just the syntax of morphemes is 
rejected by a large body of literature, which grants some degree of auton-
omy to morphology.  
Among the approaches that defend an autonomous morphology are 
Aronoff (1976), Booij (1977 et passim), St. Anderson (1982, 1992), 
Ackema & Neeleman (2004, 2007) and the work around the Lexical Integ-
rity Hypothesis that roots in Lexical Phonology (Mediterranean Morphol-
ogy Meetings, e.g. Booij et al. 2007). Julien (2007) and Lieber & Scalise 
(2007) provide a survey of the debate regarding the relationship of mor-
phology and syntax. 
The more specific question of (anti-)lexicalism is discussed for ex-
ample in Roeper (2005), Newmeyer (2005) and Li (2005) (see also § 569). 

Setting the scene: Distributed Morphology vs. Lexical Phonology 453 
Distributed Morphology takes a decidedly anti-lexicalist position that re-
sembles a lot the "abstract" practice in the 60s, and opposes the lexicalist 
period of the 70s and 80s (which is namely endorsed by GB syntax, but 
also by Chomsky 1995a). 
These broad issues of course are not the primary focus of the book, 
and no genuine contribution in this area is to be expected. However, they 
directly impact the way in which morpho-syntax can bear on phonology ± 
namely PF movement is an issue in this context (see § 574). 
 
540  2.5. Earlier versions of "No escape from syntax": Selkirk (1984) and 
Inkelas (1990) 
 
A word about the history of the unity of syntax and morphology before 
moving on. (Rather) on the phonological side, the question whether syntac-
tic and morphological representations and/or computation are distinct or the 
same is (at least) as old as Lexical Phonology.  
When Lexical Phonology made its first steps in the early 80s, Selkirk 
(1984) levelled the unificational argument against this theory (§432 0). Just 
like Distributed Morphology ten years later, it is the number of locations 
where concatenation is done, as well as the number of means by which it is 
achieved that lie at the heart of her critique. 
Selkirk (1984) refuses the division of concatenative activity into a 
syntactic (postlexical in Lexical Phonology) and a morphological (lexical) 
sector: she argues that the same mechanism should control the spell-out of 
both morphological and syntactic structure, the former being only the lower 
area of the syntactic tree. Selkirk calls this the "syntax-first" model. 
 
(216) "The general model we propose, for both words and phrases, is that a fully 
elaborated syntactic constituent structure (of the word as of the phrase) is 
mapped, in cyclic fashion, into a complete phonological representation. [«] 
It is claimed that for words, as for phrases, a set of context-free rewriting 
rules provides the foundations of that description. This is a 'syntax-first' 
model, where the organization of the grammar into components imposes an 
ordering of constituent structure formation rules before rules constructing or 
modifying phonological representation." Selkirk (1984:82) 
 
"According to Kiparsky and his predecessors, sentence structure and word 
structure must be generated in radically different fashion. [«] We see no 
theoretical or empirical advantage to the Siegel-Allen-Kiparsky theory of 
word formation as a characterization of the syntax of words. We have ar-

454 
Chap 12: Distributed Morphology 
gued instead for characterizing word structure exactly as sentence structure 
is characterized ± by a set of context-free rewriting rules. This means of 
course that the cycle cannot be eliminated in principle in words, for rewrit-
ing rules cannot be ordered and thus cannot be interspread with rules of 
phonological interpretation. Rather, they generate full-fledged embedded 
structures, which are available for interpretation only once they have been 
generated. [«] [T]he desired unity in the theory of grammar can be re-
stored. Words and sentences can be generated by the same sorts of rules and 
can be phonologically interpreted by the same general principles of the syn-
tax-phonology mapping." Selkirk (1984:415, actually the very last sen-
tences of the book) 
Table  (217) below shows the representations that Selkirk (1984:77) 
proposes for affix class-based phenomena. The contrast between affix 
classes is encoded in terms of their respective height in the morpho-
syntactic tree (root-level affixes are class 1, word-level affixes class 2 
items). This is precisely the solution favoured by Distributed Morphology 
(see § 546). 
 
(217) Selkirk (1984:77): representation of class 1 vs. class 2 affixes 
 
a. bare root 
 
b. root + class 1 affix 
 
 
c. root + class 2 affix 
 
Word 
 
 
 
Word 
 
 
 
 
 
Word 
 
 
 
 
|
|
Root 
 
 
 
Root 
 
 
 
 
Word 
Af 
 
 
 
|
Root 
Af 
 
 
 
Root 
 
 
 
|
|
|
nation 
 
 
nation- 
al 
 
 
 
nation- 
hood 
 
 
 
At that time, the competing Lexical Phonology scenario was stratal: 
rather than by contrasting morpho-syntactic representations, affix class-
based effects were achieved by morpheme-specific mini-grammars which 
carry out computation at different strata (§ 150). 
Later on in the 80s when Prosodic Phonology entered the scene, the 
Praguian segregation of morphology and syntax that Lexical Phonology 
implements also became an issue (see § 429). Everybody agrees that the 
Prosodic Hierarchy is the only interface mechanism for units above the 
word level, that is where words are concatenated (see §§ 158, 787f). At and 
below the word level, however, there are two candidates for interface man-
agement: Lexical Phonology and the units of the Prosodic Hierarchy below 
the word level (the syllable and feet, eventually moras). 

Direct merge and opacity 455 
While mainstream Prosodic Phonology (starting with Nespor & Vo-
gel 1986) has tried to sweep the competition under the rug (§ 435), Inkelas 
(1990) has drawn attention to the issue. She suggests to extend prosodic 
constituency to the Lexicon, a move that makes Lexical Phonology an 
empty shell (§ 433). 
 
541  3. Direct merge and opacity 
 
542  3.1. Introduction: DM also looks at interpretative effects at LF 
 
Let us now look at more narrowly phonological issues and their manage-
ment in Distributed Morphology. Due to its primary focus on morpho-
syntax, the body of work regarding phonological phenomena is rather 
scarce. The discussion below is based mainly on Marvin (2002, 2008), 
Newell (2005a, 2008), Piggott & Newell (2006) and Lowenstamm (2008). 
What Distributed Morphology has on top of "phonological" theories 
of the interface is that it cares for semantic interpretation: while SPE, Lexi-
cal Phonology, Halle & Vergnaud (1987a), Kaye (1995) or Prosodic Pho-
nology only try to account for the phonological behaviour of morphologi-
cally complex items, Distributed Morphology also aims to cover their se-
mantic behaviour. This is relevant and cannot be circumvented since, as we 
will see, concomitant and non-arbitrary effects are sometimes encountered 
on both interpretative sides. 
An interesting property of Distributed Morphology is that it appears 
to provide for two distinct origins of phonological opacity: direct merge 
(i.e. to a root) and Phase Impenetrability. However, only the former is held 
to produce semantic opacity. As far as I can see, this puzzle is not made 
explicit in the DM literature. Below it is tackled first by exposing direct 
merge, the opaque virtue that Distributed Morphology attaches to it and 
phenomena that fall into this category (§ 543). In a second step, I examine 
how Distributed Morphology analyses classical affix class-based phenom-
ena (§ 557). Both approaches are then crossed: the goal is to gain a com-
plete picture of how opacity and affix class-based phenomena are (or could 
be) treated in Distributed Morphology in general, and in the frame set by 
Marantz (2001, 2007) in particular. The general guideline of Marantz' ap-
proach is that opacity is the result of structure, rather than of computation. 
 

456 
Chap 12: Distributed Morphology 
543  3.2. In DM, opacity is due to direct merge 
 
544  3.2.1. Direct merge to a root produces opacity, merge to an xP guarantees 
transparency 
 
Distributed Morphology follows the idea that roots do not possess category 
information per se. Rather, category membership is the result of the merger 
of a root with a category-forming affix. This affix may be phonologically 
void (Marantz 2001). 
Category-forming affixes come in three flavours: those that, merged 
with roots, produce verbs (i.e. a vP), those that produce nouns (i.e. an nP), 
and those that produce adjectives (i.e. an aP). On this analysis, a noun such 
as dog which lacks overt morphological structure is a root that has been 
merged with an empty nominalising affix. This is shown under (218a). 
 
(218) category-forming affixes, direct and indirect merge 
 
a. bare root 
 
b. direct merge 
 
 
c. indirect merge 
 
aP 
 
 
 
 
 
nP 
 
 
 
 
 
aP 
 
 
 
a 
 
 
vP 
 
 
 
|
affix 
 
 
 
 
 
 
n 
 
 
√
a
√
v
√
|
|
|
|
|
|
ø
dog 
 
affix 
root 
 
ø 
 
root 
 
In case a phonologically contentful affix is attached directly to the 
root as a sister as under (218b) (or rather, strictly speaking, below the first 
xP), the result may be opaque, i.e. idiosyncratic (idiomatic) and unpredict-
able (non-compositional). This is, as Marantz (2001:6f) explains, because 
lexical items have idiosyncratic and unpredictable properties which may be 
taken into account when they are merged with another piece: the head in 
question sees the root, which must satisfy its selectional requirements. 
Opacity, then, is a consequence of the idiosyncrasy of the root, which im-
pacts the negotiation of sound and meaning upon interpretation.  
In this perspective, the idiosyncrasy of morphologically simplex and 
morphologically complex items have the same source, i.e. the negotiation 
of the idiosyncrasy of a root. The only difference is that in the former case 
(e.g. dog) the root is merged with a functional head (which is phonologi-

Direct merge and opacity 457 
cally and semantically empty), while in the latter the head contributes pho-
nological and semantic information. As a result, dog and cat are as much 
idiomatic expressions as phrasal idioms (e.g. take a break) (Marantz 
1997a:206ff). 
By contrast,  
 
(219) "heads attaching outside a little x [like under (218c)] take as complements a 
structure in which the root meaning (and pronunciation) has already been 
negotiated. [«]Structurally, when a head attaches outside of little x, it sees 
the features of x locally, not the features, properties, or identity of the root 
merged with x. So its selectional properties are satisfied by the features of x, 
drawn from the universal syntactic feature set, not the properties of the root, 
which are idiosyncratic to the language and to the individual speaker." Ma-
rantz (2001:7) 
 
Opacity is thus a property of "lower" attachment to a root before the 
first negotiation of sound and meaning, i.e. below the first xP. by contrast, a 
structure where a head attaches "higher up", i.e. outside of an xP, is neces-
sarily transparent because it negotiates with its sister, which is itself an item 
that has already been spelled out: the idiosyncrasy of the root cannot bite.  
The reader will have noticed that this scenario supposes that every xP 
is independently spelled out. This is indeed a basic assumption that is made 
by Distributed Morphology ± an assumption that is far from being self-
evident (more on this shortly in §§ 552, 557). 
 
545  3.2.2. An example of direct-merge-created PF and LF opacity: cómparable 
vs. compárable 
What Distributed Morphology takes to be the effect of direct vs. indirect 
merge may be illustrated by the "minimal pair" cómparable vs. compárable 
(Marvin 2002:75). The former word is both phonologically and semanti-
cally opaque, while the latter is transparent on both sides: cómpar-able 
means "roughly the same" and is stressed on the initial vowel. Were its 
meaning compositional, it would come out as "X+able", i.e. "to be able to 
be compared". Also, it does not have regular penultimate stress. By con-
trast, compár-able really means "to be able to be compared", and has trans-
parent penultimate stress. 
If non-compositionality is the consequence of direct merge, the con-
trast at hand identifies as under  (220) below. 
 

458 
Chap 12: Distributed Morphology 
(220) representation of (semantic) opacity in DM 
 
a. cómparable: opaque 
 
b. compárable: transparent 
 
aP 
 
 
 
 
 
 
aP 
 
 
 
a 
 
 
vP 
 
 
 
 
|
-able 
 
 
 
 
 
 
 
a
√
v
√
|
|
|
|
-able 
compare 
 
ø 
 
compare 
 
 
The following section shows how the opaque effect of direct merge 
is motivated (beyond the root-visibility that was mentioned in § 544). 
 
546  3.2.3. The origin of the idea that direct merge causes opacity: idiosyncrasy 
is a property of "lower" items in the tree 
 
The idea that direct merge is a source of opacity on both interpretative sides 
is a ground rule in Distributed Morphology. As far as I can see, it is a spin-
off of the classical evidence showing that word formation based on roots 
has different properties when compared to word formation based on exist-
ing words.  
The existence of a linguistically significant and cross-linguistically 
resident contrast of this kind is undisputed. It is at the origin of all the tradi-
tional distinctions that Distributed Morphology rejects: concatenation of 
morphemes vs. concatenation of words, inflectional vs. derivational mor-
phology, morphology vs. syntax. 
Marantz (2000, 2001) therefore attempts to find a solution within the 
single-engine landscape of Distributed Morphology.137 One thing that di-
 
137 Marantz (2000, 2001) appear to be the origin of the idea that direct merge 
causes idiosyncrasy. Marantz (1997a) already promoted the idea that "lower" 
items produce idiosyncrasy, while "higher" merge is transparent, but had not 
yet identified the distinction "below vs. above the first xP": "I haven't yet fig-
ured out anything like the complete theory of locality for special meanings" 
(Marantz 1997a:208). 
 
The trouble with Marantz (2000, 2001) is that they are conference handouts. 
They have been the basis for subsequent (student) work in Distributed Mor-
phology and are constantly referred to in the literature, but they are difficult to 

Direct merge and opacity 459 
vides root-based and word-based complexes is that the former produce 
idiosyncrasies (both phonological and semantic, i.e. non-compositionality) 
and paradigmatic gaps, while the latter do not: they tend to be regular and 
productive. Common to all traditional two-place approaches is that idiosyn-
cratic root-based formations are somehow "lower" than regular word-based 
constructions: the root is a smaller, hence more embedded object in com-
parison to the word. 
Marantz (2000, 2001, 2007:199ff) endorses this insight, but attempts 
to provide an implementation in a single engine environment: rather than 
by the locus of the computation (i.e. the lexicon/morphology vs. syntax), he 
argues that the difference between the two categories is defined by the rela-
tive position of an affix with respect to category-distributing labels (i.e. 
xPs). Marantz (2007) therefore opposes inner and outer word formation, the 
former producing words from roots, the latter from existing words. Table 
 (221) below reproduces Marantz' (2007:201) illustration. 
 
(221) inner vs. outer morphology 
 
outer 
 
 
 
 
 
 
 
y
x
inner 
 
x
root 
 
 
Formally, then, Marantz (2007) defines inner morphology as every-
thing that occurs below the first xP, while everything above the first xP is 
outer morphology; it includes all category changing and derivational mor-
phology. The former (may) produce(s) opacity and paradigmatic gaps, 
while the latter is phonologically and semantically transparent. Thus the 
contrast between the opaque cómparable under (220a), as opposed to the 
transparent compárable under (220b). Marantz (2007) concludes that 
 
access. Whenever possible, the present discussion is therefore based on Arad 
(2003), Marvin (2008) and Marantz (2007). The latter appears to be the written 
version of Marantz (2001). 

460 
Chap 12: Distributed Morphology 
(222) "the first phase above the root within a word shows properties often associ-
ated with lexical word formation, while higher phases triggered, e.g., by 
category-changing little x heads, behave in accordance with generalizations 
about syntactic word formation." Marantz (2007:219) 
 
The take-home message, then, is not only the identification of opac-
ity as a phenomenon that is located in the area below the first xP. It is also 
this: while merge above the first xP guarantees transparency, merge below 
the first xP does not automatically imply opacity ± it only opens the possi-
bility for an opaque interpretation. In other words, an opaque item must 
have a structure where an affix was merged below the first xP, while a 
transparent item does not give any indication regarding its structure (it may 
be the result of direct as much as of indirect merge). 
The difference between affixes which are merged below vs. above 
the first xP has become the basis for further work in Distributed Morphol-
ogy: empirical contrasts of various kinds have been interpreted in these 
terms, regarding opaque effects at both LF and PF. Work on the LF side 
includes Arad (2003) and Embick & Marantz (2008), while Marvin (2002, 
2008) follows this track at PF. 
 
547  3.3. Marvin's (2002) DM-analysis of condensation vs. compensation 
548  3.3.1. SPE's classical take: two different suffixes 
 
Marvin (2002) applies Marantz' system to phonological consequences of 
morphological structure. Specifically, Marvin (2002:66ff) seeks an explana-
tion for words that appear to contradict the famous contrast between con-
densation and compensation which runs through the phonological literature 
since Chomsky & Halle (1968:39, 370) (see § 97). 
Let us start by recalling the facts and the original SPE analysis. The 
noteworthy thing about the pair of words at hand is that the antepenultimate 
vowel may be reduced to schwa in comp[ə]nsation,
but
not
in 
cond[ɛ]nsation, which seems to be identical at first sight. SPE relates this 
fact to contrasting morphological makeups: -ation is just one suffix in con-
dens-ation, but it divides into -ate and -ion in compens-at-ion. This is wit-
nessed by the fact that the verb to condense exists, while *to compense 
does not: the verb related to compensation is to compensate. Hence the 
derivations √condense →condens-ation, against √compens →compens-ate 
→compens-at-ion.

Direct merge and opacity 461 
The vowel reduction facts, then, follow from stress: the irreducible 
vowel in cond[ɛ]nsation was stressed at a previous derivational stage 
(condénse); its main stress is converted into secondary stress by the suffixa-
tion of -ation, but continues to protect its host from being reduced. By con-
trast, the second vowel in compensation has never borne primary stress at 
any derivational stage: this word starts out as to cómpens-ate, and the suf-
fix -ion produces compens-át-ion. Being unprotected by stress, the vowel 
may reduce, and comp[ə]nsátion is produced. 
 
549  3.3.2. The SPE analysis is empirically flawed: Halle & Kenstowicz (1991) 
admit a lexical conditioning 
 
The trouble is that there are words which do allow for vowel reduction 
despite the fact that the vowel in question bore stress on an earlier cycle. 
Examples are quite common: consúlt - cons[ə]ltation, consérve -
cons[ə]rvation, transpórt - transp[ə]rtation, transfórm - transf[ə]rmation,
confírm - conf[ə]rmation, infórm - inf[ə]rmation and so on. These thus 
have the same derivational history as condensátion (cf. condénse), but be-
have as if they belonged to the comp[ə]nsátion (cf. cómpensate) pattern. 
This messy situation was only touched on in SPE: Chomsky & Halle 
(1968:161) mention transfórm - transf[ə]rmation and presént - 
pres[ə]ntation as true exceptions, and leave it at that. 138  Halle & 
Kenstowicz (1991:460f, 490f) take a closer look at these exceptions; they 
conclude that the contrast at hand is unpredictable and hence an idiosyn-
cratic property of words. That is, whether a word whose pretonic vowel 
bore stress at an earlier derivational stage allows for the reduction of this 
vowel (transpórt - transp[ə]rtation) or not (condénse - cond[ɛ]nsation) is 
somehow recorded in lexicon. 
Halle & Kenstowicz' (1991) solution for this lexical recording relies 
on a device called Stress Copy, which has been introduced by Halle & 
Vergnaud (1987a:104ff) (see § 231). Stress Copy stores stress information 
of previous cycles in a parallel structure (the metrical grid) before Stress 
Erasure takes place (Halle & Kenstowicz 1991:490f offer further discus-
sion). On these grounds, Halle & Kenstowicz (1991:460f, 490f) hold up the 
 
138 Curiously enough, though, Chomsky & Halle (1968:116, 161) record informa-
tion (which admits vowel reduction) as an instantiation of the compensation 
pattern, i.e. where the second vowel has never received stress in the deriva-
tional history. This is obviously wrong: to infórm exists. 

462 
Chap 12: Distributed Morphology 
basic SPE analysis whereby the primary stress of a former cycle protects 
vowels against reduction. That is, Stress Copy stores primary stress of pre-
vious cycles, but applies only on the basis of a lexical diacritic that is pre-
sent in condensátion, but absent from transportátion.
550  3.3.3. *Transport-ate: intermediate derivational forms that happen not to 
exist as words 
 
Marvin (2002:66f) argues for a different scenario. She points out that the 
contrast between (the well-behaving) cond[ɛ]nsation and (the ill-behaving) 
transp[ə]rtation is one of opacity: the derivational history of the former 
may be reconstructed from the surface, while the fact that the reduced 
vowel of the latter bore stress on a former cycle is hidden away by the re-
duced transp[ə]rtation.
Holding up the exceptionlessness of the original stress-based analysis 
of SPE, Marvin argues that the reduced vowel in transp[ə]rtation has never 
been stressed. That is, transportation is not derived from the verb to tran-
spórt. What is it then derived from? The anti-lexicalist mantra of Distrib-
uted Morphology allows for an answer that further atomises -ation: trans-
portation is derived from *to tránsport-ate, a form that is not an actual 
English word. That is, -ation is always composed of -ate and -ion irrespec-
tively of whether the intermediate item [root+ate] happens to exist as an 
independent word or not (Marvin 2002:65f): √compense →cómpens-ate →
compens-át-ion as much as √condense, √transport →*cóndens-ate,
*tránsport-ate →condens-át-ion, transport-át-ion.
551  3.3.4. Direct (transportation) vs. indirect (condensation) merge of -ate  
On this morphological backdrop, the headstone of Marvin's analysis is that 
stress is only assigned upon phonological computation: roots as such 
(√condense, √transport) do not bear any stress at all. The corresponding 
verbs to condénse, to transpórt are derived by the affixation of a category-
forming little v, and stress assignment then concerns the entire vP. This is 
shown under (223a) below. 
Critically, then, the root √transport has not experienced stress as-
signment before affixation of -ate occurs that produces the intermediate 
form *tránsport-ate: stress assignment would have yielded transpórt,
which ± counter to fact ± would have protected the last vowel against later 

Direct merge and opacity 463 
reduction. The key question is thus when stress assignment occurs ± that is, 
when exactly the structure is spelled out. Following Marantz (2001), 
Marvin's (2002) take is that every xP is a phase head (see (223a)).139 The 
requirement for the intermediate *tránsport-ate not to have gone through 
transpórt thus comes down to the fact that transport has never been alone 
in an xP. This, in turn, can only mean that -ate is its sister in *tránsport-ate,
as under (223b). 
The contrast between cond[ɛ]ns-át-ion and transp[ə]rt-át-ion, then, 
is due to the position of -ate in the tree: in transparent cond[ɛ]ns-át-ion, it 
attaches outside of the root xP, while in the opaque transp[ə]rt-át-ion it is 
merged as the sister of the root. This is shown under (223b,c) below. 
 
(223) condensation vs. transportation: contrast based on direct vs. indirect merge 
of -ate 
a. to transpórt
b. transp[ə]rt-át-ion 
 
 
c. cond[ɛ]ns-át-ion 
 
nP 
 
PF 
 
 
nP 
PF 
 
n 
 
 
vP 
 
PF 
 
|
-ion 
 
 
 
 
 
 
 
vP 
 
PF 
n 
 
vP 
PF 
 
 
v 
 
vP 
PF
|
|
-ion 
-ate 
 
 
 
 
 
v 
 
 
√
v
√
v
√
|
|
|
|
|
|
ø
transport 
 
-ate 
transport 
 
 
 
ø 
condense
Marvin (2002) thus offers an analysis which acknowledges the lexi-
cally arbitrary character of the contrast between cond[ɛ]ns-át-ion and 
transp[ə]rt-át-ion, but offers an encoding thereof which is more elaborate 
than Halle & Kenstowicz' (1991) lexical diacritic. Such a diacritic must still 
somehow distinguish condensation and transportation, but its effect in 
grammar is now more precise: the latter root is specified for taking on -ate 
as a sister, while the former first receives its category from the merger with 
little v. 
 
139 Following Marvin (2002), this assumption is also endorsed in subsequent work 
by Barragan & Newell (2003), Newell (2005b), Piggott & Newell (2006) and 
Piggott (2007). 

464 
Chap 12: Distributed Morphology 
552  3.3.5. All xPs are phase heads, direct merge is the anti-lexicalist way of 
encoding lexicalist observations 
 
This analysis rests on two premises: the idea that all xPs trigger spell-out 
(on which more shortly), and "abstract" anti-lexicalism that tolerates inter-
mediate unattested forms. It was already mentioned in § 539 that unlike the 
lexicalist 70s and GB-syntax, Distributed Morphology subscribes to the 
(almost unbounded) anti-lexicalism of the 60s. 
This frame being set, it accounts for opaque forms by direct merge: 
directly merged affixes produce items that are one spell-out short as com-
pared to indirectly affixed roots. This lack of spell-out produces idiosyn-
crasy, i.e. properties of the whole that cannot be predicted from its pieces.  
It is quite obvious that direct merge is the equivalent of lexicalised 
forms in an anti-lexicalist environment: in a lexicalist perspective, opacity 
would be recorded in the lexicon as a property of the whole. 
 
553  3.3.6. Direct merge may, but does not need to produce opacity 
 
For the time being, only phonological opacity has been considered. Marvin 
(2002:68f) bolsters her analysis by the observation that some of the items 
which are phonologically opaque are also semantically non-compositional. 
For instance, this is the case of inf[ə]rmátion, which affords reduc-
tion and lacks the intermediate form *ínformate, hence falls into the cate-
gory of transp[ə]rtátion (*tránsportate). Information, however, is not just 
the nominalised form of the verb to inform: while his relaxation of the con-
ditions can be drawn from he relaxed the conditions, *his information of my 
friend about the lecture is not a good counterpart of he informed my friend 
about the lecture. Marvin thus argues that information is semantically and 
phonologically opaque for the same reason: the direct merge of -ate as un-
der (223b). 
Crucially, though, this is only a possibility: direct merge may, but 
does not need to produce opacity (see § 546). Alongside with semantically 
opaque items such as information, there are words like ad[ə]ration 
(*ádorate) which instantiate the same pattern but relate to the correspond-
ing verb (to adóre) in the same way as the transparent condensátion does to 
condénse (see (223c)). 
That direct merge not always produces opacity is also confirmed on 
the phonological side: comp[ə]nsátion, one half of the original "minimal 
pair" is derivationally transparent since unlike for transportátion and in-

Direct merge and opacity 465 
formátion, its intermediate form to cómpensate exists. Therefore, the possi-
ble reduction of the vowel, which has never received stress (there is no verb 
*to compénse), may be reconstructed from the derivational history. Yet like 
all other items with a reducible vowel, comp[ə]nsátion must instantiate the 
direct merge structure under (223b). 
 
554  3.4. Phase Impenetrability à la carte? 
 
555  3.4.1. The strong DM claim that all xPs are spelled out imposes process-
specific Phase Impenetrability 
 
Distributed Morphology in general and Marvin (2002) in particular sub-
scribe to derivation by phase, and to Phase Impenetrability. Marantz' radical 
take on spell-out according to which each and every xP (i.e. vP, nP, aP) is 
independently interpreted (Marantz 2007, Embick & Marantz 2008:6, Em-
bick forth) imposes a very strong freezing effect on strings, much stronger 
than what is encountered on regular assumptions regarding spell-out, both 
on the syntactic and on the phonological side. 
That is, in case only a subset of nodes is spelled out (this is the prac-
tice in current syntax), Phase Impenetrability effects are only expected at 
these particular points in the derivation (which in Chomsky's original take 
reduce to vP and CP, maybe DP; more on this in § 773). If below the word 
all xPs are spelled out, Phase Impenetrability imposes much stronger freez-
ing effects than what is known from above the word level. 
Note that the spell-out of all xPs is a strong claim, but not quite as 
radical as spell-out-as-you-merge that is entertained in syntax by Epstein et 
al. (1998:46ff) (see § 776). That is, there are nodes below the word level 
which are non-categorising and hence do not fall into the xP set: depending 
on the analysis, functional heads such as ASP, VoiceP, DegP or AspP appear 
in the literature (e.g. Embick 2003:148, Embick & Marantz 2008, 
Alexiadou et al. 2009, Alexiadou & Grimshaw forth). On Marantz' take, 
then, and more generally in Distributed Morphology, only categorisers (nP, 
vP, aP) are phase heads: functional heads are not spelled out. 
This being said, spelling out all xPs is strong enough a claim to drive 
Marvin (2002) into trouble, which arises on the occasion of English pri-
mary stress. That is, the most basic derivations involving stress-shifting 
class 1 suffixes are indeed supposed not to exist: stress shifts two times on 
the way from órigin over orígin-al1 to origin-ál1-ity1, but Phase Impenetra-
bility should freeze it on the root-initial vowel since class 1 affixes are 

466 
Chap 12: Distributed Morphology 
regular and thus attach to an xP of their own. The spell-out of the root node 
should thus prohibit any further manipulation of stress in later derivational 
steps. 
Marvin (2002:56ff) therefore concludes that primary (but not secon-
dary) stress is an exception to Phase Impenetrability, which does not apply 
to this particular phenomenon. What that means is that Phase Impenetrabil-
ity is demoted to an optional condition on spell-out: it applies à la carte to 
some processes, but not to others.  
Process-specificity considerably weakens Phase Impenetrability. Re-
call, however, that process-specific no look-back was already discussed in 
§§ 241, 302 in an entirely different context, but also based on evidence from 
English stress. It will also be on the agenda in §§ 780, 796, and a summary is 
provided in § 823.  
 
556  3.4.2. We know that stress is a strange guy anyway 
 
Given the eventual need to allow for a process-specific weakening of Phase 
Impenetrability, it would certainly be nice to find a rationale that divides 
processes in PIC-obeying and (at least potentially) PIC-violating phenom-
ena. Research along these lines has not really begun as far as I can see, but 
the track is worth pursuing. In our example, if it can be shown that stress 
has a certain property that predestines (or forces) it to violate Phase Im-
penetrability, the predictive character of the device is restored in an inter-
esting, process-specific way. 
This is what Marvin (2002:56ff) tries to do: she points out that pri-
mary stress also violates Phase Impenetrability at a much higher level, i.e. 
between words. So-called stress clash (also called the Rhythm Rule, 
Liberman & Prince 1977), describes how the concatenation of words that 
produces adjacent word-stresses provokes stress shift: the classical example 
is thirtéen vs. thírteen mén. Stress clash is provoked by a syntactic opera-
tion (the concatenation of two words). This operation must thus have access 
to word stress, which it is able to read and to modify in spite of the fact that 
the word has been spelled out long before, i.e. at least at the word level.  
Another thread that runs through Part I also hints at the fact that 
something is wrong with stress. Recall from § 192 that it was stress that 
violates the SCC-K (that is, the generalisation regarding derived environ-
ments). The exceptional character of stress is also noticed by Szpyra 
1987:171, note 3). 

Direct merge and opacity 467 
The violation of the SCC-K by stress (roots can be stressed although 
they are a underived) pushed phonologists into the distinction between 
structure-building and structure-changing processes (§§ 193f, also note 53). 
The SCC-K, a no look-back device just like Phase Impenetrability, was 
supposed to apply to the latter (say, a palatalisation), but not to the former. 
On regular assumptions, stress is absent from the lexicon in languages 
where words are not specified for stress (such as English). Foot structure, 
the incarnation of stress, is then built during the phonological derivation, 
which is the sense in which stress placement is a structure-building opera-
tion. It was also mentioned in § 237 that Halle & Vergnaud (1987a:86f) 
report that languages where stress is lexical (such as Vedic and Russian) ± 
and hence stress-shift structure-changing, rather than structure-building ± 
do observe Phase Impenetrability (the SCC-K). 
Finally, also recall from § 315 that in Kaye's system where Phase Im-
penetrability is responsible for the contrast between párent - parént-al1 vs. 
párent-hood2, stress violates Phase Impenetrability in just one sub-pattern, 
i.e. the one that also violates Siegel's (1974) affix ordering (gov-
ern-mént2-al1). 
Based on this record, Rubach (1984:222) ventures to make the gen-
eralisation that stress disregards Phase Impenetrability (or the SCC-K) be-
cause it is a prosodic (i.e. a suprasegmental) process. Support for this gen-
eralisation comes from Bantu, where processes involving tone are able to 
look back into previously spelled out units (Marlo 2008). More discussion 
is provided in Part II (§§ 780, 814). 
In any event, the behaviour of stress appears to be self-contradictory 
when looked at through the prism of no look-back devices: it does not care 
for Phase Impenetrability when class 1 affixes shift stress (origin-ál1-ity1,
govern-mént2-al1), i.e. whether preceded by a root, a class 1 or a class 2 
affix, see § 561), but does produce Phase Impenetrability effects upon the 
interpretation of class 2 affixes (párent-hood2). 
 
557  3.5. All xPs are spelled out vs. selective spell-out plus the PIC 
 
558  3.5.1. Affix class-based phenomena in DM 
 
Let us now see how Distributed Morphology goes about regular affix class-
based phenomena. The literature does not appear to offer any explicit 
analysis (which is quite strange). In its absence, the minimal frame is set by 

468 
Chap 12: Distributed Morphology 
the commitment of Distributed Morphology to Chomskian phase theory 
(§ 304). The consequences are listed under  (224) below. 
 
(224) Distributed Morphology subscribes to derivation by phase; this means that
a. morpheme-specific mini-phonologies must be dismissed 
 
b. selective spell-out is required 
 
c. Phase Impenetrability is required 
 
DM subscribes to Phase Impenetrability (see § 555), and it was al-
ready mentioned that following SPE, Halle & Vergnaud (1987a) and Kaye 
(1995), the theory uses only one computational system for strings of what-
ever morphological quality. 
Selective spell-out, however, is problematic: we have seen in § 547 
that the baseline of Marantz' system is to require spell-out at every xP. It 
was shown in § 555 that this does not amount to Epstein et al.'s (1998) 
spell-out-as-you-merge (§ 776) where literally every node is a phase head 
since functional heads (VoiceP etc.) are not spelled out. Distributed Mor-
phology can thus claim selective spell-out (not all nodes are interpreted), 
but the kind of selectiveness is quite different from what we know both 
from phonology (where phasehood is a lexical property of pieces: class 1 
vs. class 2) and syntax (where phasehood is independent from the distinc-
tion between functional vs. non-functional heads). 
Recall that in phonology, it is precisely the selectiveness of the inter-
pretation-triggering nodes (class 1 vs. class 2) that allow Halle & Vergnaud 
(1987a) to treat affix classes with only one computational system (§ 225). 
As will be shown below, it is the peculiar kind of selective spell-out that 
DM imposes which makes the analysis of affix class-based phenomena 
impossible in this theory. 
 
559  3.5.2. Underapplication cannot be done when all xPs are spelled out 
 
A mechanical consequence of Marantz' system that has only one computa-
tional system but spells out every xP is its inability to produce underappli-
cation. Recall that this is what affix class-based phenomena are about, and 
that underapplication can either be achieved by morpheme-specific mini-
phonologies (§ 150) or by selective spell-out (Halle & Vergnaud, see § 228), 
which in Kaye's system is supplemented with Phase Impenetrability (see 
§279). But even in Lexical Phonology and subsequent implementations of 
morpheme-specific mini-phonologies, interpretation does not occur at every 
morpheme boundary, which is about what "spell-out at every xP" amounts 

Direct merge and opacity 469 
to. The closest match of Marantz' system is SPE where all nodes are indeed 
cyclic boundaries, that is subject to interpretation (see § 103). 
Distributed Morphology is thus facing a serious problem: either Ma-
rantz' requirement that every xP is spelled out is wrong, or affix class-based 
phenomena cannot be done.  
Note that the spell-out of every xP is not only a bewildering claim 
when looking at phonological effects. It also departs from current syntactic 
phase theory. Chomsky's (2000a) original take is that there are only two 
points in the derivation of a sentence, vP and CP (maybe DP), where spell-
out occurs. Since then, the evolution is to grant phasehood to more and 
more nodes that dominate smaller and smaller chunks (§ 775 describes this 
atomisation). As far as I can see, though, there is no parallel in syntax to the 
rationale that is based on the distinction between functional heads (which 
do not provoke spell-out) and non-functional heads (xPs, which are inter-
pretation-triggering) that is practised in Distributed Morphology. 
We are thus left with another property of Distributed Morphology 
which adds to the doubts that the theory stands up to its ambition to unify 
morphology and syntax (§ 538): the distribution of phasehood below and 
above the word level is not the same. This looks much like two different 
worlds ± exactly what Distributed Morphology has set out to show to be 
wrong. 
In order to be able to do affix class-based opacity effects, and to be in 
harmony with phase theory (which requires selective spell-out and a critical 
role played by Phase Impenetrability), it is argued below that a correct the-
ory must implement selective spell-out also below the word level. That is, 
the idea that all xPs are phase heads is on the wrong track. But, as we will 
see, the direct merge analysis may do a good job in a specific sub-area of 
opacity effects, i.e. where the kind of opacity that is encountered is not 
predictable. 
 
560  3.5.3. Opposite ways to go: distinct representations (DM) vs. distinct 
computation (Kaye, Halle & Vergnaud) 
 
Distributed Morphology looks at LF and PF effects through the prism of 
opacity. In this perspective, párent-hood is opaque because its stress pattern 
cannot be reconstructed from the surface, while parént-al has surface-true, 
hence transparent penultimate stress. Recall from §§ 272f that this is also 
Kaye's way of approaching affix class-based phenomena. 

470 
Chap 12: Distributed Morphology 
As a matter of fact, the two systems produce very different and in-
compatible analyses: while according to DM the root and the affix of 
párent-hood must be sisters (because they produce opacity at PF), they 
must not be sisters on Kaye's analysis. This is shown under  (225) below. 
Note that in Halle & Vergnaud's (1987a) system, -hood cannot be the sister 
of parent either: the relevant structure is like Kaye's under (225b), except 
that the higher nP (i.e. the word level) is not spelled out. 
 
(225) opacity-based analyses of affix class-based phenomena 
 
opaque párent-hood 
c. 
 
a. DM 
 
b. Kaye (1995) 
 
 
transparent parént-al
(both DM and Kaye) 
 
nP 
 PF 
 
 
 
 
aP 
    PF 
 
nP 
 
PF 
n 
 
nP 
 PF 
 
 
n 
 
nP 
|
|
hood 
al 
 
 
 
 
 
n 
 
 
√
n
√
n
√
|
|
|
|
|
|
hood 
parent 
 
 
ø 
parent 
 
 
 
ø 
parent 
 
All three approaches agree on the structure of transparent parént-al,
which is as under (225c). Critical for Kaye and Halle & Vergnaud is that 
(225b) and (225c), whose arboreal structure is identical, are not spelled out 
in the same way: while on Kaye's account both nPs are spelled out in the 
former (on Halle & Vergnaud's: only the lower nP), the lower nP must not 
be an interpretational unit in the latter (Halle & Vergnaud: the higher nP 
must not be spelled out). This is what selective spell-out is about. 
In conclusion, then, it appears that the two analyses are opposed ac-
cording to the fundamental dichotomy along which this book is organised: 
representation vs. procedural computation. This is shown under  (226) be-
low. 
 
(226) DM (structure) vs. selective spell-out (computation) 
 
structure 
 
computation 
 
a. DM 
 variable: 
affixes are sisters of the 
root vs. sit in their own xP
constant: 
spell-out at every xP
b. Kaye, 
Halle & Ver-
ganud 
 constant: 
every affix sits in its own 
xP 
 
variable: 
only a subset of xPs 
is spelled out 
 

Direct merge and opacity 471 
One general argument in favour of (226b) has already been made: 
Distributed Morphology is committed to selective spell-out (and hence to 
Phase Impenetrability) via phase theory, to which it subscribes. Below I 
take advantage of the fact that the two competing solutions have not been 
developed on the grounds of the same set of data: the question is explored 
whether the respective phenomena can be analysed in terms of the other 
approach. That is, whether one theory can be reduced to the other. 
 
561  3.5.4. A direct merge analysis for affix class-based phenomena is not viable 
 
Let us first have a closer look at the consequences of analysing the parent -
parental pattern in terms of direct merge. There is good reason to believe 
that this perspective cannot be correct. 
For one thing, it can hardly be accidental that the opaque stress pat-
tern of párent-hood is the same as the one that is produced by regular stress 
assignment when párent is pronounced in isolation. Direct merge is only 
said to be a source of opacity ± what this opacity will look like remains 
unspecified. What we see, however, is not just any opaque pattern: pre-
cisely the one that is produced by a two-step spell-out appears.  
The difference between predictable (párent-hood) and unpredictable 
(cómpar-able) opacity is discussed in §§ 562, 568 below: while the direct 
merge analysis is not suited for the former, it may be a way to go about the 
latter. 
Another strong argument against the direct merge analysis comes 
from the fact that there are cases where other affixes may intervene be-
tween the root and opacity-producing class 2 affixes (such as -hood). In 
góvern-ment2-hood2, and univérs-al1-ness2, -hood and -ness behave as ex-
pected, i.e. they do not shift stress (*governmént-hood, *universál-ness)
and hence create an opaque non-penultimate pattern. However, due to the 
presence of the intervening -ment- and -al-, they cannot be the sister of the 
root. Therefore the opacity that they are responsible for cannot be due to 
direct merge. 
The conclusion, then, is as follows: if there is only one affix -hood,
and if the opaque effect has always the same cause, -hood is never the sister 
of the root, not any more in párent-hood than in góvern-ment-hood.

472 
Chap 12: Distributed Morphology 
562  3.5.5. Analysing cómparable vs. compárable with selective spell-out 
 
Let us now see whether, conversely, the contrast between compárable and 
cómparable may be analysed in terms of selective spell-out. Table  (227) 
below shows how opacity is produced procedurally on the backdrop of 
identical structure (and two distinct -able suffixes, one class 1, the other 
class 2).  
 
(227) analysis of cómparable vs. compárable with selective spell-out and Phase 
Impenetrability 
 
a. compár-able1
b. cómpar-able2
aP 
PF 
 
 
 
 
aP 
    PF 
 
n
vP 
 
 
 
n 
 
vP 
PF 
 
|
|
able1
able2
v
√
v
√
|
|
|
|
ø
compare 
 
 
 
ø 
compare 
 
Like all other class 2 affixes, -able2 triggers the spell-out of its sister 
under (227b) (in Kaye's system), but -able1 under (227a) does not (in addi-
tion, both words are spelled out at the word level). The pronunciation and 
meaning of the root is thus negotiated separately under (227b), but not un-
der (227a). Phase Impenetrability will then prevent both PF and LF proper-
ties to be reassessed when the word as a whole is interpreted. 
What this analysis does not tell us, however, is why the root under 
(227b) receives stress on the first vowel, i.e. cómpare: regular stress as-
signment would have produced compáre, as is witnessed by the verb to 
compáre. The same goes for the non-compositional meaning: nothing tells 
us why the spell-out in isolation of compare produces the meaning that is 
observed, rather than some other non-transparent meaning. 
The difference with respect to PF opacity, though is obvious: while 
LF opacity is due to some lexical property of the root, stress assignment 
should be the result of regular computation. The fact that it is not may point 
towards a lexical recording of stress for this kind of root ± an option that 
deserves serious consideration. 
 

Direct merge and opacity 473 
563  3.5.6. Conclusion 
 
In sum, Marantz' (2001, 2007) idea that opacity is due to a specific struc-
tural configuration (direct merge) faces serious trouble: it is unable to or-
ganise underapplication, i.e. to account for affix class-based phenomena. 
Marantz' (2001, 2007) system also makes a prediction to the end that 
no additional affix can be merged between the root of an opaque form and 
the affix that causes opacity. That is, items such as [root+A+B] where B 
induces opacity are not supposed to exist since opacity must stem from the 
fact that B is merged under the xP of the root. This prediction is counterfac-
tual at PF (in góvern-ment2-hood2, univérs-al1-ness2); whether it is also 
wrong for LF opacity remains to be seen. 
Beyond empirical issues, Marantz leaves traditional grounds where 
opacity is the result of a distinction in procedural activity (selective spell-
out of identical structure and Phase Impenetrability). On his analysis, opac-
ity roots in a structural distinction (direct vs. indirect merge) that uses a 
uniform computational mechanism (spell-out at every xP). This take in-
stalls a mechanism below the word level that is at variance with current 
syntactic phase theory where spell-out is selective (even among categoris-
ers), and where Phase Impenetrability accounts for opacity. 
On the other hand, the perspective that was developed in phonology 
(by Halle & Vergnaud 1987a and Kaye 1995) allows for a uniform analysis 
of phenomena below and above the word level, which are based on selec-
tive spell-out and Phase Impenetrability. 
What remains unexplained, however, is the irregular PF opacity of 
cómparable, which contrasts with the predictable opacity of párent-hood.
In order to approach this issue, the pages below examine in which way PF 
and LF opacity can be crossed. 
 
564  3.6. Articulation of semantic and phonological opacity 
 
565  3.6.1. All logical possibilities occur 
 
A question that has been addressed on various occasions on the foregoing 
pages is the concomitance of semantic and phonological opacity. We have 
seen that they may indeed go hand in hand (cómparable vs. compárable,
§544). There are also cases, however, where PF opacity is produced in ab-
sence of LF opacity: párenthood instantiates this pattern. And of course, 
transparency on both sides may also occur: this is the case of paréntal.

474 
Chap 12: Distributed Morphology 
Table  (228) below shows the four logically possible configurations. 
 
(228) possible distribution of phonological and semantic opacity 
 
phonological 
opacity 
semantic 
opacity 
example 
compare with 
 
a.
+
+
cómpar-able 
compár-able 
b.
+
±
párent-hood 
párent 
 
c.
±
+
twink-ling 
twinkel-ing 
 
d.
±
±
parént-al 
párent 
 
(228a,b,d) have been discussed. Let us thus look at the missing con-
figuration (228c). The example comes from SPE (Chomsky & Halle 
1968:86) and is discussed by Marvin (2002:36ff). Twinkeling [twɪŋkəlɪŋ]
(which may also be pronounced with a syllabic liquid, in which case there 
is no schwa: [twɪŋklÿɪŋ]) means "the act of twinkling" and is phonologically 
irregular since it bears a schwa in an open syllable (or, alternatively, be-
cause a syllabic liquid appears before a vowel). By contrast, twinkling 
[twɪŋklɪŋ] means "a short moment" and does not bear any schwa (or syl-
labic liquid). 
On the SPE analysis that Marvin (2002:34) adopts (see also Piggott 
& Newell 2006:8ff, Newell 2008:20f), the verb in isolation twinkle 
[twɪŋkəl] possesses a schwa as the result of regular schwa epenthesis into 
word-final obstruent-liquid clusters: the underlying form is /twɪŋkl/ (or, on 
the alternative pronunciation, has a syllabic liquid due to a rule that pro-
duces liquid syllabicity in the same context). Hence the presence of the 
schwa (or of a syllabic liquid) in twinkeling [twɪŋkəlɪŋ] "the act of twin-
kling" is explained if the phase structure [[twinkl] ing] is assumed: the root 
is spelled out in isolation before -ing is merged. Schwa is thus regularly 
inserted into the final obstruent-liquid cluster (or its liquid made syllabic) 
upon the interpretation of /twinkl/. On later passes through phonology, 
Phase Impenetrability prevents epenthesis (or liquid syllabicity) to be un-
done. Twinkeling [twɪŋkəlɪŋ] is thus in instance of (228b): like párenthood,
it shows PF, but no LF opacity. 
On the other hand, twinkling [twɪŋklɪŋ] has no schwa (or syllabic 
liquid) and means "a short moment". Having no schwa in an open syllable 
(or a non-syllabic liquid before a vowel) is a phonologically transparent 
behaviour, which however is accompanied by semantic opacity: "a short 
moment" is nothing that can be deduced compositionally from to twinkle 
and -ing. Twinkling thus illustrates the missing pattern (228c). 
 

Direct merge and opacity 475 
566  3.6.2. Neither the PIC nor direct merge can account for all patterns 
 
Given the selective spell-out perspective, phonological transparency en-
forces the structure [twinkl-ing] (one single phase): were the root spelled 
out by itself, schwa would be inserted (or the liquid would be syllabic). The 
question is thus what the origin of LF opacity could be in (228c) cases. 
Phase Impenetrability does not qualify because there is no inner phase to be 
preserved. 
Looking at Marantz' (2001, 2007) theory, another candidate is direct 
merge: LF opacity could be produced by the sisterhood of the root and the 
affix ± recall from § 553 that direct merge may, but does not need to pro-
duce opacity. Hence there is nothing wrong with the two pieces of the 
transparent twinkling [twɪŋklɪŋ] "a short moment" being sisters and produc-
ing LF, but no PF opacity. 
If LF and PF opacity as a result of root-affix sisterhood is freely dis-
tributed, the reverse situation, i.e. where direct merge produces phonologi-
cal, but no semantic opacity, is also expected to exist. The pattern at hand, 
(228b), however, is already covered by Phase Impenetrability, and an 
analysis of párenthood along direct merge appears to be impossible (see 
§561). What would be needed, then, is a (228b) case analogous to transpar-
ent twinkling "a short moment", i.e. where a Phase Impenetrability analysis 
is ruled out on independent grounds. 
It thus seems that neither selective spell-out nor direct merge is able 
to cover the four-way pattern under  (228) alone: Phase Impenetrability 
cannot explain the semantic opacity of (228c) twinkling [twɪŋklɪŋ] "a short 
moment", while direct merge is unable to account for (228b) párenthood 
(and more generally for regular affix class-based phenomena). 
 
567  3.6.3. Independent LF and PF phases? 
 
The conclusion of the previous section is only relevant on the tacit assump-
tion that LF and PF phases are always concomitant: when a given node is 
spelled out, its content is sent to and interpreted at both LF and PF. That is, 
"asymmetric" spell-out whereby the content of a node is sent to one inter-
pretative module, but not to the other, is not an option. 
It is obvious that phase theory would be significantly weakened if a 
given node could be independently spelled out at LF and PF. Chomsky 
(2004) is explicit on this. 
 

476 
Chap 12: Distributed Morphology 
(229) "Assume that all three components are cyclic. [«] In the worst case, the 
three cycles are independent; the best case is that there is a single cycle 
only. Assume that to be true. Then Φ [the phonological component] and Σ
[the semantic component] apply to units constructed by NS [narrow syntax], 
and the three components of the derivation of <PHON, SEM> proceed cy-
clically in parallel. L [language] contains operations that transfer each unit 
to Φ and Σ. In the best case, these apply at the same stage of the cycle. [«] 
In this conception there is no LF: rather, the computation maps LA [lexical 
array] to <PHON, SEM> piece-by-piece cyclically." Chomsky (2004:107) 
 
Responding to empirical pressure of various kinds, though, inde-
pendent LF and PF spell-out is proposed or considered by, among others, 
Maruãič (2005), Maruãič & äaucer (2006), Felser (2004), Matushansky 
(2005), den Dikken (2007), Megerdoomian (2003) and Caha & Scheer 
(2008). 
There is no doubt that simultaneous phases are to be preferred. The 
question is whether they resist empirical pressure. In case they do not, 
phase theory loses a good deal of its appeal and predictive power, but the 
challenge raised by the free distribution of LF and PF opacity under  (228) 
evaporates. Asymmetric spell-out would allow for [twinkl-ing]PF to be 
spelled out at PF with no semantic implications, while LF could be said to 
interpret the structure [[twinkl]LF ing]LF with no consequences at PF. The 
global spell-out would thus follow the structure [[twinkl]LF ing]LF,PF.
568  3.7. Conclusion: predictable vs. unpredictable opacity and associated 
analyses 
 
It was pointed out in § 562 that the predictability of the stress pattern of 
párent-hood is good reason not to believe in a direct merge scenario for this 
kind of construction. While direct merge merely says "the item is irregu-
lar/opaque" without giving any indication which way opacity goes, the 
cyclic analysis makes a prediction as to where exactly irregular stress falls 
(i.e., on the vowel that receives main stress on the inner cycle: 
[[párent] hood]). The selective spell-out analysis is therefore unable to ac-
count for the opacity of cómpar-able: [compare] alone would receive stress 
on the first vowel where it is interpreted in isolation, and hence come out as 
compár-able.
It thus seems that there are two ways of being irregular/opaque: one 
that is predicted by Phase Impenetrability on the grounds of regular phono-

Anti-lexicalism is an orientation that allows for lexicalist analyses 477 
logical computation that is done on an inner cycle, and another one where 
the pronunciation is entirely unpredictable.  
Interestingly, LF opacity does not appear to provide for the same dis-
tinction: LF opacity is always unpredictable and idiosyncratic since it fol-
lows from lexical properties of the root, rather than from computation. 
The two kinds of opacity are paralleled with two mutually exclusive 
analyses, none of which, however, can account for all patterns of freely 
distributed LF and PF opacity (§ 565). One possibility is thus that selective 
spell-out is the correct analysis for predictable opacity (párent-hood), while 
unpredictable opacity (cómpar-able) is due to direct merge. 
 
569  4. Anti-lexicalism is an orientation that allows for lexicalist analyses 
 
570  4.1. The phonological side of the (anti-)lexicalist issue 
 
The headstones of Distributed Morphology are the single engine approach, 
late insertion, the distribution of list-type information over three distinct 
lexica and anti-lexicalism. Ongoing debate regarding the latter issue from 
the morpho-syntactic point of view was already touched on in §§ 539, 552. 
While the 60s and SPE were anti-lexicalist, Chomsky (1970) engaged the 
field into the lexicalist alternative, which was dominant in the times of GB. 
In the 90s, work in minimalist syntax encompasses both lexicalist and 
strongly anti-lexicalist approaches; DM stands on the latter side. 
Anti-lexicalim is also a resident issue in phonology: in the 70s, it lied 
at the heart of the abstractness debate (see § 126, Vol.1:§305), which has 
remained inconclusive. The question is whether there is any phonological 
computation involved in certain morphologically complex words at all. Or 
rather, in what the linguist is able to identify as a morphologically complex 
item. The classical example is the pair electri[k] - electri[s]-ity (see § 126, 
note 28): the linguist identifies two morphemes ± but does grammar make 
the same analysis? Electricity as a whole could as well be a single lexical 
entry, just like dog and table. In this case, there is no phonological activity 
at all when electricity is uttered: no underlying /k/ is palatalised by the fol-
lowing front vowel; the [s] is already /s/ at the underlying level. There is no 
concatenative, i.e. morphological activity either: electricity is made of one 
single piece, rather than of two pieces. 
The question is thus whether the pieces that a linguist is able to iden-
tify are really the pieces that are used in grammatical computation. Another 
way to look at the same problem is along the trade-off between the size of 

478 
Chap 12: Distributed Morphology 
the lexicon and the amount of phonological (and morphological computa-
tion): the anti-lexicalist stance is that the smaller the lexicon, the better the 
theory. That is, the more words are cut into pieces, the smaller the number 
of lexical entries, and the bigger the number of phonological processes that 
are needed in order to derive the correct surface form. This is what Jona-
than Kaye calls the central dogma, which produces decidedly outlandish 
results when systematically applied: Lightner (1978:18f, 1981, 1985) de-
rives sweet and hedonistic, queen and gynaecology, thirst and torrid, eye 
and ocular and so forth from the same underlying form, which supposes 
modern English speakers who perform Grimm's Law, Verner's Law and the 
pre-Greek s > h shift (see § 126, Vol.1:§333). This is absurd, and nobody 
today will endorse such a scenario. 
Another argument against the everything-is-phonology attitude of 
SPE is the nature of phonological processes that the phonology needs to 
endorse in order to bring underlying forms to the surface: many are "un-
natural" (in a sense that is hard to define) and transform phonology into an 
unrestricted pool of operations where anything can be transformed into 
anything. Finally, the following critique has been raised at least since Ki-
parsky (1968-73): anti-lexicalist practice produces a blooming rule appara-
tus which they need to suppose in fact describes the events of diachronic 
evolution that have occurred hundreds or thousands of years ago. There is 
no good reason to assume that a present-day native applies rules that were 
active centuries ago, or that these rules remain unchanged over such a long 
period of time. 
On a diachronic backdrop (Vennemann's 1976 [1971] "in the name of 
phonological realism"), the most radical opposition against the everything-
is-phonology attitude of SPE has grown into Natural Generative Phonology 
(see §§ 127f). Government Phonology also ranges at the far end of the anti-
anti-lexicalist scale (see § 276). To date the debate is inconclusive in the 
sense that nobody is able to provide a set of formal criteria (what was 
called the evaluation measure or evaluation metrics in the 70s, e.g. 
Kiparsky 1974) that affords to decide, for a given case, whether an item 
that looks morphologically complex is really considered as such by the 
grammatical system. All modern theories have somehow swung into a mid-
field position between the radical anti-lexicalism of SPE and the extreme 
position of Natural Generative Phonology. One may conclude that it is not 
good or bad per se to have a big or a small lexicon, or to do little or a lot of 
computation. Arguments must be made on a case-by-case basis. 
The goal of the discussion below is to determine the position of Dis-
tributed Morphology in this spectrum. The anti-lexicalist a priori is obvi-

Anti-lexicalism is an orientation that allows for lexicalist analyses 479 
ous, but it remains to be seen how far DM is prepared to go, and which are 
the phonological consequences of this position. Recall that Kaye's (1995) 
take on the issue, i.e. lexical access, was discussed at length in § 351. 
 
571  4.2. A third player: allomorphy, suppletion 
 
Two words that are felt as being related (phonetically, semantically, dia-
chronically or paradigmatically) may thus represent one single or two inde-
pendent lexical entries (vocabulary items in the terminology of Distributed 
Morphology). In the latter case, items which the linguist identifies as mor-
phologically complex may also be just one single vocabulary item. This 
situation is depicted under  (230) below. 
 
(230) 
nP 
 
 
 
 
 
nP 
 
 
 
 
 
 
 
 
 
 
 
n
√
n
√
|
|
|
|
ø
dog 
 
ø 
electricity
Aside from these possibilities, there is a third option: allomorphy. On 
this count, electricity represents two pieces, which however are not con-
catenated by the regular syntactic gluing operation (Merge). Rather, the 
selection of the stem electri[k] or electri[s] is made according to the 
grammatical context, here "in presence of -ity, choose electri[s]". The same 
mechanism controls the distribution of other allomorphs such as go and 
went, good and better and so forth (suppletion).140 
In DM, allomorphy/suppletion is a case of Readjustment (see 
Embick forth, the term is directly borrowed from SPE). In the diagram 
under  (215) which shows the general architecture of Distributed Morphol-
ogy, Readjustment is done upon Late Insertion, i.e. when vocabulary items 
compete for replacing morpho-syntactic features of terminal nodes. 
The overall situation is thus as under  (231) below.141 
140 Lowenstamm (2008) argues that the number of true cases of allomorphy and 
suppletion can be cut down when a more fine-grained analysis is able to show 
that different exponents express different (rather than the same) terminals (mul-
tiple exponence). 
141 For the sake of completeness, analogy needs to be added to the list. This way of 
relating two words is irrelevant for the present purpose. 

480 
Chap 12: Distributed Morphology 
(231) possible treatments for words that are phonetically, semantically, dia-
chronically or paradigmatically related 
 
a. phonology 
one single lexical entry, the difference is the result of phonological 
computation 
 
b. allomorphy, suppletion 
one single lexical entry with several allomorphs. A specific suppletive 
mechanism (Readjustment) decides which allomorph is chosen in 
specific grammatical contexts. No phonological computation is in-
volved at all. 
 
c. two independent lexical entries 
one single lexical entry, no concatenative (morphological, suppletive) 
or phonological activity. 
 
Let us now see how these three options are considered by practitio-
ners of Distributed Morphology. 
 
572  4.3. Distributed Morphology relies on the usual "phonological similarity" 
 
While Distributed Morphology has a clear bias in favour of (231a), it al-
lows for the implementation of all options: as far as I can see, no claim is 
made as to what kind of phenomenon can, should or must instantiate which 
mechanism. 
If this is true, then Distributed Morphology behaves like all other 
theories since the 80s: decisions need to be made on a case-by-case basis, 
and they often enough follow the intuition of the analyst. That is, notions 
such as "plausible phonological relatedness" may be critical. Talking about 
two manifestations of the Dutch nominal plural, Harley & Noyer (1999) 
make the following statement. 
 
(232) "Since -en and -s are not plausibly related phonologically, they must consti-
tute two Vocabulary Items in competition. Morphophonological allomorphy 
occurs where a single Vocabulary Item has various phonologically similar 
underlying forms, but where the similarity is not such that phonology can be 
directly responsible for the variation. For example, destroy and destruct-
represent stem allomorphs of a single Vocabulary Item; the latter allomorph 
occurs in the nominalization context. DM hypothesizes that in such cases 
there is a single basic allomorph, and the others are derived from it by a rule 
of Readjustment. The Readjustment in this case replaces the rime of the 
final syllable of destroy with -uct. (Alternatively such allomorphs might 
both be listed in the Vocabulary and be related by 'morpholexical relations'
in the sense of Lieber 1981)." Harley & Noyer (1999:5, emph. in original) 

Anti-lexicalism is an orientation that allows for lexicalist analyses 481 
Needless to say, "phonological similarity" is nothing that may be 
quantified or evaluated by some formal criterion. It leaves us with just our 
intuitive judgement. In an ideal world, one might expect a theory of supple-
tion to be able to tell us what possible suppletive activity is, and what is 
not. Marantz (1997b) has tried to advance in this direction. But signifi-
cantly, Harley & Noyer, for the case of destroy - destruction, remain unde-
cided between the suppletive solution (which they first advertise) and one 
that relies on two independent lexical entries (which they put into brackets). 
 
573  4.4. There is no semantic effect if cómparable and compárable are made of 
two independent Vocabulary Items 
 
In which way is this debate relevant for the issues that have been discussed 
thus far? If a phonological or an allomorphic computation cannot be taken 
for granted, a pair such as cómparable - compárable could as well represent 
two separate lexical entries. In this case, there is no semantic effect due to 
computation or contrasting arboreal structure at all since there is no compu-
tation and no complex structure of any kind in the first place. On this take, 
the LF difference observed is not any different from the one that exists 
between dog and cat: LF opacity is always unpredictable (unlike PF opac-
ity, see § 568).  
In this lexicalist perspective, the opaque item, cómparable, was lexi-
calised at some point; its meaning and stress pattern have then started to 
drift away from the original regular and compositional interpretation. This 
option is depicted under  (233) below. 
 
(233) two independent Vocabulary Items 
 
a. cómpar-able  
"roughly the same" 
b. compár-able 
"to be able to be compared" 
 
aP 
     
 
 
 
aP 
 
 
 
n 
 
vP 
 
 
 
 
|
able 
 
 
 
 
 
 
a
√
v
√
|
|
|
|
ø
cómparable 
 
 
ø 
compare 
 
 

482 
Chap 12: Distributed Morphology 
Alternatively, the pair could also be the result of allomorphic activity, 
a scenario which supposes that stress is part of the lexical properties of the 
allomorphs: cómpare would be selected by class 2 -able, while compáre 
would be adjoined to class 1 -able. This is shown under (234a). Finally, the 
fully computational solution (along Marantz' direct merge analysis) is 
shown under (234b). 
 
(234) allomorphic and phonological scenarios for cómparable and compárable 
a. allomorphy
b. fully computational solution 
 
root + class 1 affix 
 
root + class 2 affix 
 
aP 
 
 
 
 
 
aP 
 
 
 
 
 
aP 
 
 
 
a 
 
 
vP 
 
 
 
|
able2
a
√
a
√
x
√
|
|
|
|
|
|
ø
X
able1
compare 
 
ø 
 
compare 
 
X = cómpare with 
class 1 -able, com-
páre with class 
2 -able.
"roughly the same" 
"to be able to be compared" 
 
In case there are two independent lexical entries, or if the allomor-
phic scenario is correct, the entire discussion regarding opacity and direct 
merge (§ 541) may turn out to be vain: it makes only sense if it is estab-
lished on independent grounds, and beforehand, that the opaque items in 
question are really the result of computation. 
It thus looks like we are not any more advanced regarding this issue 
than generative linguists were in the 70s: there is simply no way to measure 
whether a given word is fully lexicalised or not, whether it is the result of 
allomorphic or of regular morphological activity. The overt anti-lexicalist 
orientation that Distributed Morphology promotes offensively does not 
make the situation any different: anti-lexicalism airs a general sympathy for 
everything-is-computation; it is unable, however, to make principled deci-
sions: allomorphic/suppletive and lexicalist solutions are always possible. 
 

PF movement 483 
574  5. PF movement 
 
575  5.1. Syntactic motivation 
 
Distributed Morphology has also introduced PF movement into the inter-
face debate, a tool that has no precedent as far as I can see. The idea is that 
morpho-syntactically defined items can continue to move along morpho-
syntactic structure after vocabulary insertion. There is thus a point in the 
derivation where the morpho-syntactic tree is still available, but terminal 
elements are phonological, rather than syntactic. Movement, then, is as 
much feature-driven as in syntax ± only are the features phonological. That 
is, displacement of morpho-syntactically defined chunks can be triggered 
by their phonological properties. 
Motivation for PF movement comes from both syntactic and phono-
logical quarters. On the former side, a number of phenomena resist regular 
analysis: they do not appear to have any syntactic or semantic motivation, 
and they may violate otherwise well established generalisations. Typical 
cases in point are extrapositions, which Chomsky (2001, 2005) argues are 
not due to core syntactic movement operations; rather, they take place in 
the phonological component. Some examples appear under  (235) below 
(from Göbbel 2007). 
 
(235) extraposition 
 
a. [A new book __] appeared last year about Turner.
b. He sold [a painting __] at Sotheby's by Turner.
c. Okay, you saw a picture yesterday, but by just whom did you see a pic-
ture yesterday OF? 
 
Displaced constituents (e.g. by scrambling or topicalisation) are 
normally "frozen" for further extraction, but (235c) shows that extraposed 
constituents can be further extracted from. Göbbel (2007) argues that PF 
movement offers a solution: the preposition is dislocated after wh-
movement has applied. 
The two reasons mentioned (absence of syntactic motivation, viola-
tion of syntactic regularities) appear to be the basis of PF movement on the 
syntactic side. Relevant literature that follows this line of attack includes 
Chomsky (2001:21ff), Embick & Noyer (2001), Sauerland (1998) and 
Sauerland & Elbourne (2002). PF movement may thus be considered an 
instrument of the minimalist programme: classically syntactic labour is 
outsourced in order to be understood as an interface condition. (Narrow) 

484 
Chap 12: Distributed Morphology 
syntax is cleaned up at the expense of a big, manifold (and dirty) inter-
face/PF (see § 727). 
On the other hand, there are also voices that argue against a PF-
motivation (or PF-management) in the analysis of particular displacement 
phenomena that are PF-outsourced in the literature mentioned. Julien 
(2006) for example shows that the displacement operations that Chomsky 
(2001) takes to be phonological in nature may be treated in syntax proper. 
 
576  5.2. Phonological motivation  
 
577  5.2.1. Cases where phonology impacts syntax 
 
On the phonological side, PF movement builds on phenomena that chal-
lenge phonology-free syntax. Recall from § 412 that the principle which 
holds that phonology never influences morpho-syntactic operations 
(Zwicky & Pullum 1986a,b) probably needs to be restricted to melody, i.e. 
to phonological properties that occur below the skeleton. Properties above 
the skeleton such as intonation, focus, minimal word constraints and the 
like appear to be able to bear on the workings of morpho-syntax. For ex-
ample, on Truckenbrodt's (1995) analysis, extraposition of an intonational 
phrase is blocked by an intervening intonational phrase in cases such as 
under  (236) below. 
 
(236) extraposition blocked by an intervening intonational phrase 
 
*A book delighted Mary by Chomsky. 
 (A bóok __i)φ (delighted Máry)φ by Chomskyi.
Following Truckenbrodt, locality conditions similar to the ones 
known from syntax also hold on the phonological side, that is when con-
stituents are defined in terms of the Prosodic Hierarchy. 
This is the kind of evidence which suggests that syntactic movement 
may be sensitive to phonological constraints.142 Its treatment requires the 
 
142 Another typical representative of this category are displacement phenomena 
that appear to be sensitive to the "heaviness" of the displaced object, which is 
commonly calculated according to the amount of phonological material that it 
is made of (a long DP is heavier than a short DP). Heavy NP shift is the typical 
example. While the grammaticality of ?He sold at Sotheby's (a painting) is du-
bious, increasing the size of the right-displaced item significantly improves the 
result: He sold at Sotheby's (a painting by Turner). Selkirk (2001) proposes a 

PF movement 485 
simultaneous availability of morpho-syntactic structure and phonological 
content. There must thus be a derivational stage where spell-out has already 
taken place (i.e. with vocabulary items inserted), but where morpho-
syntactic structure is still available. 
This ties in with the syntactic motivation for PF movement that was 
discussed: displacement in the kind of intermundia described does not obey 
the same set of constraints as in a purely syntactic environment. This is 
killing two birds with one stone: displacements that are embarrassing for 
syntactic theory are expelled to PF, and this is also the derivational stage 
where phonologically sensitive movement operations take place. 
 
578  5.2.2. Phonology-internal triggers: Piggott & Newell on Ojibwa 
 
The cases discussed in the previous section represent classical instances of 
phonologically conditioned syntactic phenomena: the phonological condi-
tioning is located at or above the skeleton. 
In contrast to this pattern, Piggott & Newell (2006) and Newell 
(2008:108) propose a PF movement analysis in absence of any syntactic 
phenomenon: the trigger is phonological, and the responding PF movement 
is syntactically undetectable. Also, the phonological phenomenon at hand is 
of melodic nature: an anti-hiatus reaction. 
The PF movement proposed hinges on an independent piece of 
analysis regarding the interpretation of hiatus avoidance in Ojibwa (Eastern 
Algonquian). Table  (237) below shows that this language sometimes does, 
but at other times does not react when a hiatus comes up. 
 
phonological solution that is driven by the principle of Weight Increase: a se-
quence of prosodic constituents is ordered such that their weight (i.e. their 
length) progressively increases (i.e. from left to right). 
 
The "phonological heaviness" of morpho-syntactic constituents and their al-
leged impact on syntax was discussed in § 420. Being "heavy" is an observa-
tional category which, since Nespor & Vogel (1986), is too quickly and too eas-
ily taken as the critical property for the phenomenon observed: longer constitu-
ents are not only longer ("heavier") ± they also have more (morpho-syntactic) 
structure. The phenomena observed may thus as well be due to this greater 
complexity, i.e. something that has nothing to do with phonology. This issue is 
discussed at greater length in § 421. 

486 
Chap 12: Distributed Morphology 
(237) (non-)reaction of Ojibwa against hiatus 
 
a. /namee-    im/ →nameem 
sturgeon   poss 
"sturgeon (possessive)" 
 
b. /gii-  aagam-     osee/ →giiaagamosee 
past-snowshoe-walk 
"he walked in snowshoes" 
 
c. /ni-   aagam-osee/ →nidaagamosee 
1sg- snowshoe-walk 
"I walk in snowshoes" 
 
Under (237a), an anti-hiatus reaction causes the loss of a vowel; un-
der (237b), however, the hiatus survives. On the analysis of Piggott & 
Newell (2006), the difference lies in phase structure: in the former case the 
hiatus occurs within the same phase ([namee-im]nP), while in the latter it 
straddles a phase boundary ([gii [aagam-osee]vP]CP). No reaction is recorded 
in the latter case because the vP-initial vowel was already spelled out in the 
inner vP phase: Phase Impenetrability prevents its reassessment when the 
outer cycle is interpreted. 
Based on this analysis, the hiatus should also survive under (237c), 
which however it does not. Piggott & Newell show that there is syntactic 
evidence to the end that both personal and tense markers occur outside of 
the vP/nP: they are spelled out at the CP phase. Hence the hiatus should 
appear on the surface in [ni [aagam-osee]vP]CP as much as in 
[gii [aagam-osee]vP]CP. Another issue is the way in which the hiatus is re-
solved: while the regular means appears to be vowel deletion, an epenthetic 
consonant is inserted under (237c). 
In this situation, Piggott & Newell (2006:23) (also Newell 
2008:130f) observe that whether or not the hiatus survives in identical syn-
tactic configurations depends on a phonological property of the item in the 
outer phase: morphemes with a long vowel appear in hiatus, while elements 
with a short vowel provoke consonant epenthesis. That is, short ni- "1sg" 
and ga- "future indefinite" trigger epenthesis, while long gii- "past" and 
wii- "future non-indefinite" do not react on a following vowel. 
On Piggott & Newell's (2006:21) analysis, this is due to the fact that 
degenerate feet (i.e. which are made of only one syllable) are only allowed 
at the right edge of a phase. Everywhere else, the size of the phonological 
material that is computed at its insertion site must be big enough to form a 
regular bisyllabic foot. This is indeed the case for the bimoraic gii- in 
[gii [aagam-osee]vP]CP. 143 Monomoraic ni- in [ni [aagam-osee]vP]CP, how-
 
143 It is unclear to me on the occasion of which phonological computation the size 
of gii-/ni-, and hence their viability as a bimoraic foot, is evaluated: the vP 
phase of [ni [a-gam-osee]vP]CP is first spelled out, and at the CP phase the pho-

PF movement 487 
ever, can only build a degenerate mono-moraic foot, which is prohibited in 
non-phase-final position. This is the trigger for PF movement: in order to 
save the derivation, ni- moves down into the vP phase (Piggott & Newell 
call this movement cliticisation), where it can build on other phonological 
material in order to be correctly footed. The resulting structure, then, is 
[__i [(nii-a)-(gam-o)(see)]vP]CP, which hosts an illegal phase-internal hiatus. 
Regarding the two distinct hiatus-avoiding strategies, Piggott & 
Newell (2006:27ff) argue that they mirror the derivational contrast at hand. 
That is, derivations are constantly monitored for phonological well-
formedness: strings are checked for constraint violations upon domain spe-
cific, and also after PF movement has taken place. Ojibwa then uses differ-
ent hiatus-killers depending on whether the violation occurs upon lexical 
insertion (vowel deletion as under (237a)) or after PF movement 
(d-insertion as under (237c)). While this is certainly a correct description of 
the facts on the assumption of Piggott & Newell's analysis, it does not ex-
plain why there should be different hiatus-avoiding strategies, and why they 
are distributed in the way they are. 
Be that as it may, the goal of this presentation is not to evaluate 
whether a particular analysis fares well or not. What was to be illustrated is 
the fact that PF movement may also be used for purely phonology-internal 
purposes: the trigger is phonological, the effect observed is phonological, 
and the movement is undetectable by morpho-syntactic indicators.  
 
579  5.2.3. Phonologically motivated allomorphy: Lowenstamm on French 
 
PF movement is also a central tool of Jean Lowenstamm's recent work that 
combines phonological representations with the sub.word architecture of 
Distributed Morphology (Lowenstamm 2008, also Rucart 2006, Lampitelli 
forth a,b). 
One example is Lowenstamm's (2008:110ff) analysis of gender in 
French. French features a puzzling pattern that looks like a phonologically 
driven allomorphy at first sight: while possessive pronouns regularly agree 
in gender with following consonant-initial nouns (see (238a)), only the 
 
nological material of both cycles should be interpreted together (i.e. 
[ni a-gam-osee]CP). Ni- should therefore be able to rely on the material of the 
inner cycle for foot construction without any PF movement. The authors proba-
bly suppose that cross-phase foot construction is ruled out by Phase Impenetra-
bility (but they are not explicit on this). 

488 
Chap 12: Distributed Morphology 
masculine mon/ton/son (first, second, third person, respectively) appear 
before vowel-initial nouns, even if these are feminine (see (238b)). 
 
(238) agreement of possessive pronouns in French 
 
a. Je vois maF voitureF
I see my   car 
Je vois monM copainM
I see my      friend 
 
b. Je vois mon? armoireF
I see my      wardrobe 
Je vois monM aquariumM
I see my      aquarium 
 
The behaviour of the possessive is obviously related to the fact that 
French elides determiner-final vowels in hiatus position, i.e. when they 
occur before a vowel-initial word: the definite article is la (fem.) in la moto 
"the motorbike" and le (masc.) in le train "the train", but l' in l'armoire "the 
wardrobe" (fem.) and l'aquarium "the aquarium" (masc.). The question 
therefore is why /saF armoireF/ does not appear as s'armoire, just like 
/laF armoireF/ produces l'armoire.
Given this situation, the classical analysis of monM armoireF simply 
relies on suppletion: for some unknown reason, the masculine form is cho-
sen when the noun is feminine and vowel-initial. 
Lowenstamm (2008) proposes a different analysis. He first decom-
poses determiners: the lateral in la [la] (fem.) and le [lə] (masc.) is the ex-
ponent of definiteness, while the -a and zero represent feminine and mascu-
line gender, respectively.144 The same goes for the possessives ma/mon 
(first person), ta/ton (second person) and sa/son (third person): m-, t- and 
s- represent possessiveness, while -a and zero are the gender markers as 
before.145 
The contrast between l'armoire (from /laF
armoireF/) and 
son/*s'armoire (from /saF armoireF/), then, is the result of the different posi-
tion of definiteness and possessiveness in the morpho-syntactic tree. This is 
shown under  (239) below (from Lowenstamm 2008:113f). 
 
144 Lowenstamm assumes that the schwa which appears on the surface in the mas-
culine article is the result of default epenthesis (hence schwa is in fact a zero). 
145 Lowenstamm (2008) is not explicit on the status of masculine -on, which could 
also be the exponent of masculine gender for possessives. Since Lowenstamm 
promotes an analysis where masculine gender is uniformly zero in French, 
however, -on in m-on appears to be epenthetic, even when the following noun 
is masculine. Its epenthetic status with vowel-initial feminine nouns is the heart 
of his analysis, to be exposed below. 

PF movement 489 
(239) Lowenstamm (2008): l'armoire vs. *s'armoire 
a. /laF armoireF/ →l'armoire
b. /saF armoireF/ →*s'armoire, son 
[sɔ±n] armoire 
DP 
 
 
 
 
 
 
 
 
s
D'
ɔ±
FP
insertion of 
default ç̃
F'
DP 
 
 
 
 
 
 
 
 
 
 
 
 nP
D
nP
3
n'
n
√
n
√
|
|
|
|
l
a
armoire 
 
 
 
 
 
 
 
 
 
a 
armoire 
 
 
On Lowenstamm's analysis, the feminine gender -a is always gener-
ated in little n and falls prey to regular elision before armoire in both (239a) 
and (239b). This is all that happens to /laF armoireF/, and the result is l'ar-
moire. With the possessive comes more structure, though, namely a func-
tional projection FP that Lowenstamm does not elaborate on. He argues that 
the possessive, third person s- in our case, is generated in Spec,nP and 
raises to Spec,DP ("3" stands for third person). Crucially, then, "the person 
features of the possessive in Spec,DP cannot be licensed by an empty head" 
(Lowenstamm 2008:114). This is why some phonological material must be 
inserted into the head of DP. According to Lowenstamm, the default vowel 
for this job is [ɔ±] in French, a claim that he tries to substantiate independ-
ently.146 He does not explain, however, why an empty head is able to li-
cense the definiteness features under (239a), which also sit in Spec,DP (/laF
armoireF/ →l'armoire). One concludes that according to his analysis, 
 
146 Which is certainly not an easy thing to do. Lowenstamm mentions that [ɔ±] is 
the surface subject in impersonal constructions such as on [ɔ±] a soutenu que« 
"one has claimed that«". But he does not explain how the division of labour is 
organised between the epenthetic schwa that on his analysis fills in zero mascu-
line gender (/l-zero/ →[lə]), and the epenthetic [ç̃]. Schwa is the vowel that is 
traditionally assumed to be unmarked and eventually epenthetic in French. 

490 
Chap 12: Distributed Morphology 
Spec,DP can be licensed by a phonologically empty head in case it hosts 
definiteness, but not if it accommodates person features. 
Lowenstamm's analysis combines morpho-syntactic structure with 
phonological terminals, which move along the morpho-syntactic tree. This 
is exactly what PF movement is about: morpho-syntactic structure is still 
available, but domain specific has already taken place, to the effect that 
terminals are phonological in nature. We have seen in § 578 that these pho-
nological terminals can trigger movement along the tree (Piggott & New-
ell's hiatus-induced movement). In this context, Lowenstamm's analysis has 
two interesting properties: phonological objects move along the tree for 
morpho-syntactic reasons, and morpho-syntactic well-formedness is deter-
mined by phonological content. 
The former is illustrated for example by ma voiture "my car" where 
the exponent of feminine gender, -a, raises to Spec,DP in the equivalent 
structure of (239b) in order to join the exponent of person features. Cru-
cially, though, this only happens once the survival of the -a has been nego-
tiated with the following noun: -a only raises if it does not fall prey to eli-
sion. In case it does as under (239b), the epenthetic [ɔ±] is needed precisely 
in order to fill in the gap of the eliminated -a. We are therefore sure that the 
movement of consonants and vowels along the tree is not just metaphorical: 
phonological computation has already taken place when the gender expo-
nent -a starts to move. 
Conversely, morpho-syntactic well-formedness may be determined 
phonologically in Lowenstamm's analysis, whose critical distinction is 
between definiteness features that can, and person features that cannot be 
licensed by a phonologically empty head of DP. 
Lowenstamm's analysis shows how powerful PF movement is: mor-
pho-syntactic and phonological information are available simultaneously 
and without any specified point in the derivation where one is converted 
into the other (domain specific).147 
147 Lowenstamm (2008) does not mention the fact that his analysis is an instantia-
tion of PF movement: the presence of phonological terminals in a morpho-
syntactic tree goes without discussion. 

PF movement 491 
580  5.3. Overgeneration, direct syntax, modularity and the creation of two 
distinct computational systems 
 
Facing the merits that are pointed out in the literature quoted, PF movement 
is certainly exposed to a number of objections. For one thing, it dramati-
cally increases the generative power of the the theory. Syntax weaves a 
strict corset of well-formedness conditions; if now displacement is possible 
in complete absence of syntactic control, one might want to ask what the 
whole struggle against overgeneration was worth in the first place. Unload-
ing unwarranted phenomena into PF or an ill-defined intermundia makes 
syntax minimalistically clean, but leaves other members of the family dirty 
(see § 727). If displacement can be freely triggered by phonological proper-
ties, one would expect a large set of PF-movement phenomena, certainly 
larger a set than what may be ascribed to this mechanism. This includes a 
number of outlandish "sandhi" phenomena: hiatus avoidance at word 
breaks for example could be solved by moving one word away. This kind 
of behaviour, however, is nothing that can be found in natural language. 
Also, the construction of a post-syntactic space where a computation 
takes place that is different in kind from syntactic computation undermines 
the basic claim of Distributed Morphology according to which there is no 
difference between syntax and morphology. PF movement certainly feeds 
the doubts that were voiced in § 537 regarding the question whether DM 
lives up to its ambition. The following statement is very clear. 
 
(240) "We develop a theory of movement operations that occur after the syntactic 
derivation, in the PF component, within the framework of Distributed Mor-
phology. The theory is an extension of what was called Morphological 
Merger in Marantz 1984 and subsequent work. A primary result is that the 
locality properties of a Merger operation are determined by the stage in the
derivation at which the operation takes place: specifically, Merger that takes 
place before domain specific, on hierarchical structures, differs from Merger 
that takes place post-domain specific/linearization." Embick & Noyer 
(2001:555, emphasis in original) 
We are thus left with two sets of locality properties for Merge ac-
cording to whether the operation occurs in or after syntax. Also, Marantz' 
(1984) Morphological Merger is now called PF movement, which takes 
place after syntax. This is advertised as a major result by authors who pro-
mote the DM approach and hence "reject the view that morphology is insu-
lated from syntax" (Embick & Noyer 2001:592). 

492 
Chap 12: Distributed Morphology 
Finally, PF movement begs the question regarding modularity: what 
kind of module carries out computation that has access to both morpho-
syntactic structure and phonological material? A module that corresponds 
to this derivational intermundia cannot exist if domain specificity defines 
modular contours (see §§ 610, 640): syntactic features and phonological 
material are ontologically different and thus uninterpretable in the sister 
module.  
It cannot be argued that PF movement takes place in what phonolo-
gists call phonology, i.e. the phonological module (whose relationship with 
PF is in need of definition, see § 726): here only phonological vocabulary 
can be processed, but PF movement supposes the presence of the full mor-
pho-syntactic tree structure, including node labels. This again leads to a 
violation of domain specificity: the phonological computational system 
cannot parse or compute morpho-syntactic labels or trees. 
Since the terminals are made of phonological material when PF 
movement takes place, another bewildering fact about the trees at hand is 
that their nodes and labels are the projection of nothing (see § 715): how 
could the morpho-syntactic tree "survive" in absence of its terminal fea-
tures? On standard assumptions, a tree is nothing but a projection of prop-
erties of the terminal elements (see Chomsky's inclusiveness, § 648). PF 
movement is thus a strong modularity offender. The modularity-offending 
character of PF as such and its relationship with true phonology (i.e. the 
thing that phonologists call phonology) is further discussed in §§ 731, 738). 
The modularity-offending character of PF movement is also con-
firmed on another count: Distributed Morphology has a natural sympathy 
for direct syntax (§ 407), another modularity-violating device. PF move-
ment is a strong form of direct syntax since on top of untranslated structure 
and labels, it promotes phonology-triggered displacement. Interestingly, 
though, and unlike what is done in OT where direct syntax is also com-
monplace (§ 525) but happily cohabitates with prosodic constituency, Pak 
(2008:42ff, in a DM environment) and Samuels (2009a:284ff) rightfully 
argue that if direct syntax is correct, the Prosodic Hierarchy is redundant 
and needs to be done away with altogether. Recall from (§ 407) that this is 
indeed a compelling move: prosodic constituency is useless if direct refer-
ence to morpho-syntactic structure and labels can be made (and in absence 
of non-isomorphism, which was shown in § 416 to be an artefact of the 
domain-based perspective, rather than a fact about language). 
 

Conclusion 493 
581  6. Conclusion 
 
582  6.1. Direct merge vs. selective spell-out: a geometric, rather than a 
computational solution 
 
Distributed Morphology is neither a theory of phonology nor a theory of 
the interface. The matters that are of interest for the interface-inclined pho-
nologist are therefore only secondary in the DM literature, and the body of 
work at hand is fairly restricted. 
Distributed Morphology follows Chomsky's minimalist perspective 
where much labour is unloaded from syntax in direction of the interface(s). 
Phase theory, the central instrument of this approach, is largely debated in 
syntactic quarters, but discussion usually ends when it comes to its lower 
end: PF is a black box for syntacticians, who hardly go beyond "and then 
PF is in charge", or "this is solved at PF" (see § 727). 
The phonologically relevant work in Distributed Morphology goes 
into greater detail. The direction was given by Marantz (2001, 2007): in 
response to the robust observation that "lower" items produce irregularity 
(while "higher" pieces are regular), he introduces the idea that direct merge 
is responsible for opacity, both phonological and semantic. This allows him 
to maintain just one arboreal structure and one computational system (i.e. 
one engine), against the traditional split between a morphological and a 
syntactic hierarchy with associated distinct computational systems. 
As a result, non-transparency at PF and LF is a geometric property 
(being a sister of the root may create opacity), rather than a consequence of 
selective spell-out. As far as I can see, this is an entirely novel take: opacity 
in general and affix class-based phenomena in particular have always been 
ascribed to a procedural (computational) mechanism on the grounds of 
identical geometric structure. Distributed Morphology now does the re-
verse: opacity is due to a static geometric contrast (direct vs. indirect 
merge), which is accompanied by an invariable computation (spell-out at 
every xP) (§ 560). 
This analysis where spell-out and Phase Impenetrability play no role 
is applied in a small body of literature whose main representatives (regard-
ing phonology) are the Ph.D of Tatjana Marvin (2002) and the work by 
Glyne Piggott and Heather Newell at McGill (Barragan & Newell 2003, 
Newell 2005a,b, 2008, Piggott & Newell 2006, Piggott 2007). 
 

494 
Chap 12: Distributed Morphology 
583  6.2. Spell-out at every xP stands in the way 
 
A shared assumption of the work in DM is the idea that all categorising 
heads, i.e. nP, vP, aP, are phase heads. The definition of phasehood is a de-
bated issue and a field of rapid evolution in the syntactic literature (see 
§771). It is certainly true that there is a trend towards the atomisation of 
phasehood: interpretational units are smaller and smaller, i.e. more and 
more nodes acquire this status. Spelling out every categorising, i.e. non-
functional node, however, is way beyond the current syntactic horizon. 
It was shown in § 557 that spell-out at every xP disables Distributed 
Morphology to account for affix class-based phenomena: underapplication 
cannot be expressed. On the other hand, it was shown in § 566 that selective 
spell-out is unable to handle cases of the twinkling type where LF, but not 
PF interpretation is opaque. How PF and LF opacity can combine was stud-
ied in § 564: free distribution prevails. When all four cases are examined, it 
thus appears that both direct merge and selective spell-out are unable to 
account for one pattern. This opens the possibility for both solutions being 
complementary according to the phenomenon considered.  
What makes direct merge and selective spell-out incompatible is the 
additional claim that all xPs are phase heads. Nothing withstands the simul-
taneous existence of a kind of opacity that is due to direct merge with an-
other kind that originates in selective spell-out if spell-out at every xP is 
abandoned. 
Spell-out at every xP is also at variance with syntactic phase theory, 
to which Distributed Morphology is committed: derivation by phase sup-
poses selective spell-out, and phase heads are not defined according to 
whether or not a node is functional head. Phase theory also relies on Phase 
Impenetrability, a mechanism that plays no role in the direct merge analysis 
of opacity (but which is used in Kaye's 1995 version of selective spell-out). 
 
584  6.3. Unifying ambitions and specific tools for morphology 
 
It was mentioned on a number of occasions that Distributed Morphology 
hardly stands up to its ambition, i.e. the unification of morphology and 
syntax. Fission, Fusion and Impoverishment are specific morphological 
devices that are unknown in syntax, and spell-out at every xP is incompati-
ble with current syntactic practice.  
PF movement also lines up here: beyond the severe overgeneration 
that it allows for and the blurred modular contours which ensue, it intro-

Conclusion 495 
duces a specific computational system whose locality conditions are differ-
ent from the ones that are known from syntactic computation. PF move-
ment takes place in a misty intermundia, PF, which is neither syntax nor 
phonology, but a little bit of both (more on the modularity-offending her-
maphrodicity of PF in § 726). 
 
585  6.4. Two specificities: LF and no proposal regarding representational 
communication 
 
When compared to other theories of the interface, Distributed Morphology 
has two specific characteristics that stem from its morpho-syntactic orienta-
tion: attention is paid to LF phenomena, and no statement is made regard-
ing representational communication with phonology. 
We have seen that Distributed Morphology considers semantic as 
much as phonological effects of morpho-syntactic structure and spell-out. 
The former were discussed since the earliest generative literature on mor-
phology (Siegel 1974, Allen 1978, 1980, Aronoff 1976, Pesetsky 1979), but 
are by and large absent from SPE and further literature on the interface: 
neither Lexical Phonology nor Prosodic Phonology look much at LF prop-
erties in order to explain the behaviour of phonology at the interface.  
The fact that there is a non-arbitrary relationship between effects on 
both sides at least in some cases is beyond doubt. Interface theory is there-
fore called to be able to derive LF and PF effects from the same morpho-
syntactic structure. The existence of simultaneous LF and PF effects is also 
support for the classical (syntactico-centristic) perspective of the inverted T. 
Finally, it is to be noted that Distributed Morphology makes no con-
tribution to the representational communication with phonology: no general 
position is taken whether any objects that represent morpho-syntactic in-
formation are inserted into phonological representations, and if so, what 
they might look like (boundaries, prosodic constituents etc.). Only Pak 
(2008:42ff) and Samuels (2009a:284ff) call into question the very existence 
of prosodic constituency, which according to them should be done away 
with in favour of direct reference to morpho-syntactic structure and labels 
(§ 580). 


Interlude 
586  Modularity 
 
Chapter 1 
587  Introduction: the relative absence of modularity in 
interface thinking 
 
On various occasions of the historical survey in Part I, modularity was re-
ferred to, and a number of arguments were made in its name. A striking fact 
is that the interface literature itself does not seem to take modularity into 
account: it is hard to find any explicit reference, and even harder to find 
modularity-based reasonings.148 This is unexpected, to put it mildly, since 
modularity is part and parcel of the generative approach to language: it is 
never missing in introductory classes and introductions to the general archi-
tecture of grammar in textbooks. Quite opposite of its supposed overarch-
ing importance, however, is its influence on theory design. In comparison 
to straight theories of syntax, phonology and other subdisciplines, this of 
course is a much more pressing issue for interface theories. 
The absence of modularity from interface thinking and interface de-
sign is certainly one reason for the current situation in OT: modularity is 
supposed to be in place (OT is a generative theory), but it is systematically 
violated without this arousing much discussion (§§ 469, 523). We have seen 
that OT is not the only modularity offender (SPE and Distributed Morphol-
ogy are other cases in point), though. A summary as well as further discus-
sion and classification of generative modularity offenders is provided in 
§702 below. 
A telling example of the absence of modularity in interface thinking 
was reported in § 407: the head stone of Prosodic Phonology, the principle 
of Indirect Reference, is a direct expression of modularity ± but it was in-
troduced without any reference to this concept. Rather, non-isomorphism 
was invoked ± an empirical argument that turns out to be immaterial when 
 
148 There are number of noticeable (and rather recent) exceptions, including 
namely the work by Charles Reiss and Eric Raimy: Reiss (2000), Hale & Reiss 
(2008:105ff), Isac & Reiss (2008), Reiss (2008), Cairns & Reiss (2009), Reiss 
forth, Raimy (2003), Idsardi & Raimy (forth). Unfortunately this work has 
quite little visibility in current interface thinking of mainstream theories. 

498 
Modularity Chap 1: The relative absence of modularity in interface thinking 
carriers of morpho-syntactic information are local, rather than domain-
based (§ 416). In sum, what happened is that Prosodic Phonology did ex-
actly the right thing ± Indirect Reference ± for the wrong reason (non-
isomorphism). Although modularity was contemporary (Fodor's founda-
tional book appeared in 1983), the simple argument that direct reference to 
untranslated morpho-syntactic objects is ruled out by the modular architec-
ture was never made as far as I can see. 
An introduction to modularity as such that exposes the modular view 
of how the cognitive system works is therefore not superfluous. Linguists, 
especially phonologists, may or may not be familiar with the cognitive 
foundations of modularity, what it requires, and what it rules out. Also, 
modularity has already done critical labour, and will do still more in this 
book, where it is used as a referee (§ 36).  
It goes without saying that the pages below do not aim at a fully-
fledged introduction to modularity: the specialised Cognitive Science and 
psychological literature that is mentioned throughout does a much better 
job. The same goes for connectionism, the competing theory of cognitive 
organisation. This Interlude is only meant as a short armamentarium in 
modularity for phonologists (and more generally linguists). 
Isac & Reiss' (2008) and Boeckx's (2010) recent (text)books on lan-
guage and cognition cover a number of issues that are discussed below: 
they provide a broad introduction to language and linguistics from the 
Chomskian (and, in the case of the latter, specifically biolinguistic) point of 
view, and argue on the backdrop of Cognitive Science (without however 
engaging into discussion with connectionism: modularity is taken for 
granted). 

Chapter 2 
588  Modularity and connectionism, mind and brain 
 
589  1. Monism vs. dualism, symbolic vs. non-symbolic representations 
 
590  1.1. Levels of representation in the standard cognitive model 
 
Under the header of what today is called the cognitive revolution (e.g. 
Gardner 1985), the modular approach to cognition was put on the agenda in 
the 50s and 60s as an alternative to (psychological) behaviourism and parts 
of (linguistic) structuralism. Rather than describing the stimuli and the re-
sponses of an organism, focus was put on the actual cognitive processes 
that take place when speech is produced and processed (a black box in be-
haviourism). Rather than describing a linguistic system without location in 
space and time, the cognitive operations that it supposes became the centre 
of interest. This call for cognitive realism is essentially what Chomsky's 
(1959) critique of Skinner's book is about. Generative linguistics were lead-
ing in the introduction of the new cognitive conception then, and today 
language remains a central issue. 
Critical for modularity and generative linguistics is the difference be-
tween mind and brain, which is akin to the distinction between competence 
and performance. Although the mind of course has a neural implementa-
tion, it may be studied independently of the neuro-biological reality. In fact, 
trying to get hold of language by looking at its neuronal reality alone is 
quite unlikely to produce significant insight. On the other hand, models of 
the mind are constrained by the limitations of what is neurally possible and 
plausible. The best understanding of language may therefore be expected 
from a dialectic exchange between the study of mind and the study of brain, 
bottom-up as much as top-down.149 
The debate between the classical cognitive model on the one hand 
and connectionism on the other is about 25 years old; the following discus-
sion only ambitions to provide a brief summary of some basic aspects. 
More detail is available for example in Dinsmore (1992). Laks (1996) and 
Pylyshyn & Lepore (eds.) (1999) offer informed overviews; more special-
ised literature includes Newell (1980), Fodor & Pylyshyn (1988), 
 
149 Simon & Kaplan (1989:7f) and Pylyshyn (1989a:60ff) elaborate on the stan-
dard notion of levels of representation in Cognitive Science. 

500 
Modularity Chap 2: Modularity and connectionism, mind and brain 
Smolensky (1988a, 1991), Fodor & McLaughlin (1990), Harnad (1990), 
and other references that are mentioned as we go along. Finally, Fodor 
(1985) provides a helpful overview of the different schools of thought in 
Cognitive Science. 
 
591  1.2. A language of thought: symbolic vs. anti-symbolic views of cognition 
 
Theories of the mind necessarily use representations and symbols (such as 
trees, DPs, nuclei etc.), which are supposed to get as close as possible to the 
units that are manipulated by the mind. This is the "language of thought", a 
notion that was introduced by Fodor (1975) and has been debated since 
then. 
 
(241) "There has always been opposition to the view that we have symbol struc-
tures in our heads. The idea that the brain thinks by writing symbols and 
reading them sounds absurd to many. It suggests to some people that we 
have been influenced too much by the way current electronic computers 
work. The basic source of uneasiness seems to come from the fact that we 
do not have the subjective experience that we are manipulating symbols. But 
subjective experience has been a notoriously misleading source of evidence 
for what goes on in the mind. Research in human information processing 
reveals countless processes that clearly must be occurring (for example, 
parsing, inference) of which we have little or no subjective awareness." 
Pylyshyn (1989a:61) 
 
The rejection of symbolic representations has condensed into the 
theory of connectionism in the 80s (Rumelhart et al. 1986). Connectionism 
challenges the standard cognitive model on the grounds of the mind-brain 
distinction, which is denied (typically, though not by all representatives of 
connectionism, as we will see): only the brain is relevant since only the 
neural level is decision-making. Therefore anything that goes beyond the 
study of the brain and its modelling (in terms of artificial neural networks) 
is misleading and unhelpful. That is, computation should be brain-style 
(rather than a machine-style), as Rumelhart (1989:134f) puts it: the basic 
calculating units must be (eventually artificial) neurons, and the items 
processed are numbers, rather than symbolic representations. 
Connectionism (or at least some versions thereof) is thus reductionist 
in kind: it does not accept the mind-brain dichotomy. Symbolic and repre-
sentational systems describe things that have no neural basis and hence are 

Monism vs. dualism, symbolic vs. non-symbolic representations 501 
pure speculation (e.g. Churchland 1993, Chomsky 1995b exposes the ra-
tionalist refutation of reductionism). 
Philosophically speaking, connectionism is monistic (the cognitive 
system is made of the brain and of nothing else), while the classical cogni-
tive model is dualistic (the mind and the brain exist and are both relevant). 
Also, connectionism is a typical incarnation of empiricism which relegates 
any reasoning that is not data-based into the realm of unwarranted specula-
tion. By contrast, the dualistic mind-brain approach falls into the tradition 
of rationalism/mentalism. 
Interestingly, the charge against the classical cognitive model is thus 
led in the name of cognitive realism, just as was the introduction of the 
cognitive model in the 50s-60s: cognitive realism then, neural realism now. 
The linguistic implementation of the empiricist-connectionist approach is 
called "Cognitive" Grammar (see § 596 for references and further discus-
sion). The name of this framework is a good illustration of the issue at 
hand: it is deliberately chosen in order to warrant a copyright on the word 
"cognitive". Defenders of this model try to establish that their theory is the 
only cognitive theory about language ± pure propaganda.150 But they are 
deadly serious about stamping generative linguistics as non-cognitive. The 
following quote is form a textbook that introduces to "Cognitive" Grammar. 
 
(242) "While most linguists, nowadays, would no doubt agree that linguistics is a 
cognitive discipline [«], there have been important approaches within lin-
guistics which have denied, or simply ignored, the discipline's cognitive 
dimension. Among these we can identify the formalist and the behaviourist 
approaches. (A cynic might say that quite a lot of modern linguistics is actu-
ally to be located within the formalist approach, with appeals to cognitive 
aspects being little more than lip-service to a modern fashion.) [«] Work by 
Chomsky and his sympathizers, as well as various offshoots of Chomsky's 
theories, [«] are very much formalist in orientation." Taylor (2002:6f) 
 
In this vein, Taylor (2002:6) talks about Chomskian linguistics as 
"cognitive linguistics", i.e. in quotation marks. Saying that one of the foun-
ders of modern Cognitive Science denies or ignores cognitive issues in 
language is coming on a little strong. This kind of statement illustrates the 
empiricist-connectionist line of attack, though (which is sometimes ex-
pressed with more subtlety). 
 
150 Which is the reason why I refer to the framework as "Cognitive" Grammar in 
this book. 

502 
Modularity Chap 2: Modularity and connectionism, mind and brain 
592  1.3. What would adult science look like without symbols? 
 
Looking at what appears to be one of the central debates of Cognitive Sci-
ence from the outside, the question arises whether any other science, espe-
cially any adult science, could afford such a discussion. 
What is physics, what is chemistry, what is biology about? Under-
standing how things work, or trying to produce a photograph of the natural 
object under study? Scientific discoveries have always been made in sym-
bolic terms (I am not sure whether there is any exception at all): objects are 
thought, described and drawn before instruments provide evidence for their 
existence (think of molecules, atoms, the double helix, electrons, protons or 
whatever is your favourite). And scientists write down mathematical formu-
lae in order to describe processes. 
The point is that in all adult sciences, the only scientific reality is a 
representation of the real-world reality, in terms of a drawing and/or in 
terms of a formula. The relationship between both is often non-trivial, and 
it typically takes a lot of effort in order to be able to go from one to another: 
this is what engineering is about. Engineers construct machines on the 
grounds of a scientific insight. The engineering effort is typically under-
taken long after the death of the scientist on whose discovery it is based. 
Engineers are the negotiators between the scientific reality and the real-
world reality.  
Take the atom: the well-known representation under (243a) is the 
only scientific reality that counts. No doubt the picture under (243a) is ide-
alised and only remotely resembles a real atom that would be visualised by 
some image-giving system (microscopes today can see individual atoms, 
but they cannot yet look into them). Or consider what it takes to understand 
how a computer works, i.e. its basic building block, the transistor: do we 
need to know about (243b), or do we need to inspect the makeup of the 
kind of physical item under (243c)? 
Science is about gaining insight, not about engineering. No physicist 
would ever challenge the physical reality of (243a); optical confirmation or 
any other instrumental evidence is of course welcome ± but this is secon-
dary with respect to the reality of (243a) that owes its legitimacy to its ex-
planatory virtue. In particle physics, highly sophisticated machines, particle 
accelerators, are busy providing experimental evidence (though indirect: 
nobody has ever seen a quark on a photograph) for all the particles that are 
predicted by theoreticians whose only equipment is a sheet of paper and a 
pencil. And the particles predicted were found one by one. 
 

Monism vs. dualism, symbolic vs. non-symbolic representations 503 
(243) physical and scientific reality 
 
a. an atom: scientific reality 
 
b. a transistor: symbolic 
c. a transistor: physical 
 
Of course representations such as (243a) may turn out to be impre-
cise, incomplete or, according to the degree of incompleteness, simply 
wrong. But they have been established as the scientific reality, the only 
reality that counts in science, on grounds that have got nothing to do with 
any attempt to mimic its real-world properties: electrons turn around pro-
tons and neutrons because there is evidence to this end ± remote effects 
whose inspection has led to (243a) as the best hypothesis. And it was by the 
same mechanism ± observation of remote effects that make only sense if a 
certain structure is assumed ± that it was discovered that protons are made 
of still smaller units, quarks. Will anybody argue against thirteen-
dimensional string theory because strings are only a symbolic metaphor for 
some real "reality"? 
Another point of interest is that in the history of (adult) science, pro-
gress has always been made when something was understood ± not when it 
could be implemented. Einstein did not do any real-world experiment in 
order to build relativity theory ± it was enough for him to think. Like it is 
often the case in adult science, the core of his discovery is a symbolic 
mathematical formula, E = mc2. Long after Einstein died, relativity (among 

504 
Modularity Chap 2: Modularity and connectionism, mind and brain 
other things) eventually allowed humans to walk on the moon, and to engi-
neer machines that allow a precise location on the planet (GPS). It was 
mentioned earlier that perhaps with a few exceptions, objects of the real 
world have always been thought and drawn on a piece of paper before they 
were eventually visualised by advanced instrumentation: cells, molecules, 
the double helix, quarks, strings, H2O and so forth.151 
It is therefore difficult to understand why regular scientific standards 
seem to be questioned just when the object of study happens to be the 
mind/brain. Prohibiting to draw pictures and to talk about things in terms of 
symbols because the real world does not have any of those would not cross 
any physicist's mind. On the other hand, it is obvious and undisputed (in 
physics, chemistry and Cognitive Science) that whatever symbolic hy-
pothesis is made, it must be compatible with what we know about the real 
world. That is, a biological theory that dismisses the cell can be rejected out 
of hand as much as a cognitive theory that supposes infinite storage capac-
ity. 
 
151 In phonology, Morris Halle has used this line of argumentation a long time ago 
in order to justify the reality of the phoneme: "Helmholtz postulated that elec-
tric current is a flow of discrete particles without having isolated or even 
having much hope of isolating one of these particles. The status of the pho-
neme in linguistics is, therefore, analogous to that of electrons in physics, 
and since we do not regard the latter as fictional, there is little reason for 
applying this term to phonemes. They are every bit as real as any other 
theoretical entity in science" Halle (1964:325). 
The relationship between symbolic scientific reality and real-world 
objects ± their "implementation" ± is intricate and dialectic, but in any case 
non-arbitrary: hypotheses must be implementable, but it takes a lot in order 
to show that a symbolic system could not possibly be the correct represen-
tation of a natural object. The history of science offers countless examples 
where some hypothesis was judged outright impossible, sometimes for 
centuries, before being found to be real (think of the history of astronomy). 
Scientific hypotheses are abandoned because they are shown to be wrong, 
not because they are made of symbols or non-symbols. 
It is hard to see why symbolic representations in cognitive matters ± 
a syntactic tree for example ± should have any different heuristic, epistemo-
logical or scientific value than (243a). In both cases, the negotiation with 
the real world is dialectic and complicated, and the distance with the sym-
bolic representation may be more or less important. Since the relationship 
between representation and "reality" is dialectic, experimentation in both 
cases will provide valuable evidence for the eventual amendment of the 

Connectionism and its representatives in linguistics 505 
representation, just as much as the experiments are designed on the grounds 
of hypotheses whose basis is the representation.  
In particle physics, particle accelerators provide experimental evi-
dence, while in Cognitive Science neurobiology (image-giving systems) 
plays this role. In both cases, representational and experimental activity 
must of course work hand in hand. And again, there is no question about 
that in adult science: it would be utterly absurd to doubt that this collabora-
tion is necessary. Non-adult science is not only non-adult because it is 
younger and not (yet) confirmed by massive experimental evidence and 
engineering success ± it is also childish because it does not behave like 
adults: reducing activity to either representational or neurobiological en-
deavour seriously reduces the chances of a serious scientific prospect. 
The dialectic relationship between the functions of the mind and their 
(specialised and localisable) neural existence is further discussed in § 614. 
 
593  2. Connectionism and its representatives in linguistics 
 
594  2.1. The symbolic front line and its roots in Cognitive Science 
 
The symbolic front line introduced above is worked out in a special issue of 
Cognition on Connectionism and Symbol Systems in 1988 (number 28, 
edited by Steven Pinker and Jacques Mehler, also published as Pinker & 
Mehler (eds.) 1988). As the editors explain in the introduction, this issue is 
more or less the answer of standard Cognitive Science to the connectionist 
challenge was raised by Rumelhart et al. (1986). Especially the article by 
Fodor & Pylyshyn (1988) works out the symbolic vs. anti-symbolic line of 
division. While Dinsmore (1992) provides a book-length contrastive over-
view of the two approaches, Newell (1989) is a non-comparative introduc-
tion to symbolic models of cognition (and their parallels with computers). 
The issue is discussed from a wholesale perspective by Pylyshyn (1999). 
But of course connectionism does not reduce to the symbolic issue. 
The quote of Fodor & Pylyshyn below locates the connectionist research 
programme in the context of traditional Cognitive Science.  
 

506 
Modularity Chap 2: Modularity and connectionism, mind and brain 
(244) "Connectionism really does represent an approach that is quite different 
from that of the Classical cognitive science that it seeks to replace. Classical 
models of the mind were derived from the structure of Turing and Von 
Neumann machines. They are not, of course, committed to the details of 
these machines as exemplified in Turing's original formulation or in typical 
commercial computers; only to the basic idea that the kind of computing 
that is relevant to understanding cognition involves operations on symbols.
[«] In contrast, Connectionists propose to design systems that can exhibit 
intelligent behaviour without storing, retrieving, or otherwise operating on 
structured symbolic expressions." Fodor & Pylyshyn (1988:4f) 
 
Below some basic information on how the connectionist model 
works is provided. 
 
595  2.2. How neural networks work 
 
The connectionist approach to the cognitive system is based on the assump-
tion that there are only two significant items, neurons and synapses. The 
former are computational units, which are fed by the latter: synapses trans-
port information among neurons and decide how much of it gets through 
the pipe: this is the weight of a neuronal connection, which decides on the 
activation value of the target neuron. The quote below provides a summary 
of how a neural network works. 
 
(245) "Connectionist systems are networks consisting of very large numbers of 
simple but highly interconnected 'units'. Certain assumptions are generally 
made both about the units and the connections: Each unit is assumed to 
receive real-valued activity (either excitatory or inhibitory or both) along its 
input lines. Typically the units do little more than sum this activity and 
change their state as a function (usually a threshold function) of its sum. 
Each connection is allowed to modulate the activity it transmits as a func-
tion of an intrinsic (but modifiable) property called 'weight'. Hence the ac-
tivity on an input line is typically some non-linear function of the state of 
activity of its sources. The behavior of the network as a whole is a function 
of the initial state of activation of the units and of the weights on its connec-
tions, which serve as its only form of memory." Fodor & Pylyshyn (1988:5)
There are many surveys and introductions to how connectionist sys-
tems work, e.g. Rumelhart (1989), Stillings et al. (1995:63ff), Thagard 
(2005:111ff); Smolensky (2003) and Smolensky & Legendre (2006) pro-
vide a linguistically oriented overview. The following section takes a closer 

Connectionism and its representatives in linguistics 507 
look at one particular aspect of the connectionist approach, the non-status 
of stored information and the outgrowths of this idea in linguistics. 
 
596  2.3. No distinction between storage and computation (the rule/list fallacy) 
 
Beyond the symbolic issue, the references are clear from the quote under 
 (245): regular Cognitive Science follows the Turing/von Neumann idea that 
computation is done by short-term/working memory in a procedural way 
(step by step) on the grounds of a storage device ± long-term memory. The 
dissociation of actual action and independently stored instructions that gov-
ern this action is the essence of the Universal Turing Machine where a 
"head" performs action on the grounds of instructions that are found on a 
"tape".  
This simple architecture was improved by John von Neumann, who 
introduced a distinction between two kinds of storage systems: the one that 
contains the actual instructions for action (Relative Access Memory, which 
today would be called the programme/software), and another one that is 
just a data-storage device where things can be stored that are not needed for 
current action, and from which they can be retrieved when necessary. To 
date this is the basic architecture of computers, and also of Artificial Intel-
ligence (AI) (e.g. Haugeland 1989:133ff, see also § 603).  
On the cognitive side, the memory that stores instructions for action 
(the programme/software) is the essence of the relevant module, the data-
storing device is long-term memory and the computational space where 
actual action is performed is short-term memory. There is neuropsycholgi-
cal evidence that declarative (long-term memory) and procedural (instruc-
tions for action) knowledge are distinct: they can be dissociated by brain 
damage (Stillings et al. 1995:62, 312ff, Squire 1987). 
In sum, computation and storage are crucially independent: the for-
mer builds on the latter. That is, a process transforms a pre-existing object. 
Connectionism denies the distinction between computation and storage: the 
only "storage" that it provides for is the online value of activation levels. In 
practice, the "experience" of a neural network ± the equivalent notion of 
memory ± is acquired when the patterns of connectivity change: neurons 
may develop new connections (synapses), may lose old connections, or 
modify the strength (weight) of existing connections (the two former are 
often viewed as a special case of the latter). The computational units them-
selves have no variable behaviour that contributes to the properties of the 

508 
Modularity Chap 2: Modularity and connectionism, mind and brain 
whole, which are exclusively determined by the connective network (see 
Stillings et al. 1995:114ff on connectionist models of memory). 
All linguistic theories since Antiquity of course rely on the assump-
tion that there is a lexicon which exists independently of grammatical activ-
ity. Grammar transforms lexically stored objects into actual speech. The 
linguistic mirror of the connectionist non-separation of storage and compu-
tation is so-called "Cognitive" Grammar, which was founded by Ronald 
Langacker (1987) (see Taylor 2002). Langacker (1987 Vol.1:42) talks about 
the "rule/list fallacy". The phonological off-spring of this line of thought is 
represented by exemplar- and usage-based approaches in general, and by 
Joan Bybee in particular. The following quote is explicit on that. 
 
(246) "Perhaps the most fundamental difference between the model to be explored 
here and structuralist or generativist models is the rejection of the notion 
that material contained in rules does not also appear in the lexicon and vice 
versa. [«] Linguistic regularities are not expressed as cognitive entities or 
operations that are independent of the forms to which they apply, but rather 
as schemas or organisational patterns that emerge from the way that forms 
are associated with one another in a vast complex network of phonological, 
semantic, and sequential relations." Bybee (2001:20f). 
 
We are thus light-years away from anything that could be reconciled 
with generative thinking, actually with any linguistic thinking at all at least 
since the 19th century. 
 
597  2.4. All-purpose parallel vs. specialised step-by-step computation 
 
Another important connectionist headline is Parallel Distributed Process-
ing, which contrasts with the classical Turing/von Neumann assumption 
that computation is serial: the output of one computation is the input to 
another. On the connectionist count, several computations take place simul-
taneously, like in the brain. Rumelhart (1989) explains why computation 
cannot be step-by-step when it is carried out by real brains: this would re-
quire too much time. 
 

Connectionism and its representatives in linguistics 509 
(247) "The operations in our models then can best be characterized as 'neurally inspired.'
How does the replacement of the computer metaphor with the brain metaphor 
as model of mind affect our thinking? This change in orientation leads us to a number 
of considerations that further inform and constrain our model-building efforts. 
Perhaps the most crucial of these is time. Neurons are remarkably slow relative to 
components in modem computers. Neurons operate in the time scale of millisec-
onds, whereas computer components operate in the time scale of nanoseconds ± a
factor of 106 faster. This means that human processes that take on the order of a 
second or less can involve only a hundred or so time steps. Because most of 
the processes we have studied ± perception, memory retrieval, speech processing,
sentence comprehension, and the like ± take about a second or so, it makes sense to 
impose what Feldman (1985) calls the '100-step program' constraint. That is, we 
seek explanations for these mental phenomena that do not require more than about 
a hundred elementary sequential operations. Given that the processes we seek to 
characterize are often quite complex and may involve consideration of large 
numbers of simultaneous constraints, our algorithms must involve considerable 
parallelism. Thus although a serial computer could be created out of the kinds of 
components represented by our units, such an implementation would surely violate the 
100-step program constraint for any but the simplest processes." Rumelhart 
(1989:135, emphasis in original) 
 
Another aspect of connectionist computation is that the units which 
carry out computation ± neurons, or clusters thereof ± are not specialised 
for a particular computational task, or for a particular input material. 
Rather, neurons are an all-purpose computational unit that is able to per-
form any computation on the grounds of any type of information submitted. 
This is why connectionist computation is called distributed.  
A corollary of distributed computation is the claim that computation 
is opportunistic and does not need any specialisation of its support units, 
the neurons: computation is colourless. 
We will see below that the modular approach works with the exact 
reverse assumption: there are stable, genetically endowed, content-sensitive 
computational units that are devised for a very narrow and specific func-
tion, which can only work with a particular type of input vocabulary, and 
can do nothing else than what they are designed for. 
In a historical perspective, Marshall (2001:510) comes up with a 
quote by Charlton Bastian from the late 19th century that is surprisingly 
modern in anticipating the debate between modularity and connectionism. 
 

510 
Modularity Chap 2: Modularity and connectionism, mind and brain 
(248) "The fundamental question of the existence, or not, of real 'localizations' of 
function (after some fashion) in the brain must be kept altogether apart from 
another secondary question, which though usually not so much attended to, 
is no less real and worthy of our separate attention. It is this: Whether, in the 
event of 'localization' being a reality, the several mental operations or facul-
ties are dependent (a) upon separate areas of brain-substance, or (b) whether 
the 'localization' is one characterized by mere distinctness of cells and fibres 
which, however, so far as position is concerned, may be interblended with 
others having different functions. Have we, in fact, to do with topographi-
cally separate areas of brain-tissue or merely with distinct cell and fibre 
mechanisms existing in a more or less diffuse and mutually interblended 
manner?" Bastian (1880, emphasis in original) 
 
Significantly, Bastian's book is entitled "The brain as an organ of 
mind" (more on this relationship in § 627). 
 
598  2.5. What it all comes down to: connectionist computation is content-free 
 
The properties of the connectionist architecture mentioned conspire to the 
assertion that the mind does not know what it is doing when computation 
takes place: computation is only general-purpose, that is non-specialised for 
any task or function; it works without reference to any symbolic code, 
which would make the operations specific to a particular domain or content 
since symbols are symbols of something, and may be opposed to symbols 
of a different kind. General-purpose parallel computation cannot rely on 
memory either because memory, again, would be the memory of some-
thing, that is specific to a particular content. 
We will see below (§ 604) that modularity takes the opposite position 
on every issue mentioned, and that this follows from the conception that 
computation is computation of something: it is specific to a domain and to 
a function, that is content-sensitive and content-imparting (Cosmides & 
Tooby 1992a focus on these notions as a key difference between the modu-
lar and the connectionist approaches). 
 
599  3. Conclusion: peaceful coexistence at first, but not for long 
 
In sum, there are two competing conceptions of how the mind/brain works: 
the cognitive system is either made of interconnected all-purpose units 
(neurons), or a network of specialised and unexchangeable units (modules). 

Conclusion: peaceful coexistence at first, but not for long 511 
The connectionist line of attack is to challenge the standard cognitive 
model because of its unwarranted analogy with microelectronic computers 
(that carry out specialised and serial computation and work with short- and 
long-term memory): nothing entitles to conclude that the mind/brain should 
work like the most sophisticated man-created machine that is currently 
available. This is challenging the symbolic model on the very grounds on 
which it emerged during the cognitive revolution of the 50s-60s: psycho-
logical realism. Still more real than symbolic units are neurons, and in their 
self-understanding, connectionist models are neurally inspired and develop 
a brain-style (rather than a machine-style) computation (Rumelhart 
1989:134). 
Interestingly, the connectionist and the standard cognitive approaches 
were not understood as irreconcilable competitors at first: in the early lit-
erature when connectionism individuated from the symbolic cognitive 
mainstream, it was viewed as an interesting complement which offers a 
biologically and neurally grounded implementation of the higher level 
symbolic system. Smolensky (1987) for example is explicit on this. 
 
(249) "In this paper I present a view of the connectionist approach that implies 
that the level of analysis at which uniform formal principles of cognition can 
be found is the subsymbolic level, intermediate between the neural and 
symbolic levels. Notions such as logical inference, sequential firing of pro-
duction rules, spreading activation between conceptual units, mental catego-
ries, and frames or schemata turn out to provide approximate descriptions of 
the coarse-grained behaviour of connectionist systems. The implication is 
that symbol-level structures provide only approximate accounts of cogni-
tion, useful for description but not necessarily for constructing detailed 
formal models." Smolensky (1987:95) 
 
Connectionism was thus a question of levels: following the work by 
Marr (1982) on vision, the symbolic level could stand unchallenged as long 
as connectionist neural networks were understood as an intermediate level 
between the (neural) biology of the brain and the functional view of the 
symbolic level. Dinsmore (1992) and Macdonald & Macdonald (1995) 
have edited books that revolve entirely around the possibility of under-
standing the classical theory of the mind and connectionist mimicking of 
neurons and synapses as two ways of looking at the same object which are 
equally legitimate: rather than constructing competing views of the 
mind/brain, they are complementary and both necessary for the understand-
ing of the mind/brain, just as zoology and biology are for the understanding 

512 
Modularity Chap 2: Modularity and connectionism, mind and brain 
of living species.152 The book about modularity and language edited by 
Garfield (ed.) (1987) also falls in this early period where a synthesis was 
still an option. 
Fodor & Pylyshyn (1988), from the camp opposite to Smolensky's, 
also arrive at this conclusion. 
 
(250) "Treat Connectionism as an implementation theory. We have no principled 
objection to this view (though there are, as Connectionists are discovering, 
technical reasons why networks are often an awkward way to implement 
Classical machines). This option would entail rewriting quite a lot of the 
polemical material in the Connectionist literature, as well as redescribing 
what the networks are doing as operating on symbol structures, rather than
spreading activation among semantically interpreted nodes. 
Moreover, this revision of policy is sure to lose the movement a lot of fans. 
As we have pointed out, many people have been attracted to the Connec-
tionist approach cause of its promise to (a) do away with the symbol level of 
analysis, and (b) elevate neuroscience to the position of providing evidence 
that bears directly on issues of cognition. If Connectionism is considered 
simply as a theory of how cognition is neurally implemented, it may con-
strain cognitive models no more than theories in biophysics, biochemistry, 
or, for that matter, quantum mechanics do. Al1 of these theories are also 
concerned with processes that implement cognition, and all of them are 
likely to postulate structures that are quite different from cognitive architec-
ture. The point is that 'implements' is transitive, and it goes all the way 
down." Fodor & Pylyshyn (1988:67f, emphasis in original) 
One senses, though, that the peaceful coexistence will not last long 
on either side: the battle is engaged for pocketing the biggest possible piece 
 
152 One track followed in the "bridging" literature, i.e. which tries to make classical 
Cognitive Science and connectionism peacefully cohabitate, is to take artificial 
neural networks that are designed according to connectionist principles, and to 
add content-labels to the neurons, which are also arranged graphically in order 
to mimic the image provided by the classical theory. In linguistics, for example, 
Stevenson (1999) draws regular syntactic trees whose nodes are interpreted as 
neurons with the relevant linguistic labels, and whose branches are synapses. 
This of course is violating all principles on all sides: connectionist neural net-
works cannot have any content, and branches of syntactic trees represent domi-
nation relationships: they have got nothing to do with activation levels. In the 
same spirit, Plaut (2003) relates sub-components of grammar by a neural net-
work: phonology is characterised as a neural entity that entertains relationships 
(in terms of activation levels) with other neural entities representing semantics, 
acoustics and articulation.  

Conclusion: peaceful coexistence at first, but not for long 513 
of the cake: how much of cognitive activity is symbolic, and how much is 
connectionist? Where exactly are decisions made? Smolensky's (1987) 
conclusion also goes this way. 
 
(251) "The heterogeneous assortment of high-level mental structures that have been 
embraced in this paper suggests that the symbolic level lacks formal unity. 
This is just what one expects of approximate higher-level descriptions, which, 
capturing different aspects of global properties, can have quite different charac-
ters. The unity which underlies cognition is to be found not at the symbolic 
level, but rather at the subsymbolic level, where a few principles in a single 
formal framework lead to a rich variety of global behaviours." Smolensky 
(1987:108) 
 
The front lines have grown more rigid since the 80s, and as far as I 
can see there is not much left of a peaceful level-specific coexistence of 
symbolic and connectionist models. They are globally competing theories 
of cognitive activity, even if this or that connectionist model may not com-
pletely exclude the existence of a symbolic residue. It was already men-
tioned in § 529 that Smolensky & Legendre's (2006) version of OT, Har-
monic Grammar, pursues the peaceful coexistence programme in linguis-
tics: parallel distributed computation (constraint ranking) operates over 
traditional symbolic items (typically segments).  
The main connectionist import into linguistics is parallel computa-
tion, which is the headstone of (all versions of) OT. The question whether 
this import into a rationalist theory of language (generative grammar) can 
succeed without serving as a Trojan Horse for other empiricist properties of 
connectionist thinking is discussed in Scheer (2010a:205ff). Namely the D 
of PDP (Parallel Distributed Processing) is modularity-offending, or gears 
OT towards the dissolution of modular contours, since it promotes a scram-
bling trope where all types of computation (phonetic, phonological, mor-
phological and even syntactic for some) are carried out in one single con-
straint chamber (see § 529). 
On the other hand, the modern version of the classical symbolic 
model is Jerry Fodor's modularity, which is introduced on the following 
pages. 


Chapter 3 
600  The modular architecture of the mind: where it 
comes from 
 
601  1. The brain as a set of functional units: F-J Gall's early 19th century 
phrenology 
 
The idea that certain brain areas have localised and specific functions goes 
back to the inventor of phrenology, Austrian physician Franz-Joseph Gall 
(1758-1828), who also first proposed that the brain is the (only) organ of 
the mind (e.g. emotions are not located in the heart, but in the brain). 
 
(252) 
Franz-Joseph Gall (1758-1828) 
 
Phrenology holds that the mind decomposes into a number of indi-
vidual mental faculties which are localised in a specific area of the brain 
and correlate with precise areas of the overlying skull bone. Hence in the 
19th century when phrenology was popular especially in the Anglo-Saxon 
world, phrenologists divided the human skull into areas that represent fac-
ulties such as combativeness, wit, hope, willpower, cheerfulness or number 
(mathematics): maps were drawn which identified certain areas of the skull 
with specific faculties. Table  (253) below reproduces two relevant figures. 
 

516 
Modularity Chap 3: Origins of the modular architecture of the mind 
(253) 
American Phrenological Journal 
1848 
Webster's Academic dictionary 
1895 
 
Phrenology and its history are described in greater detail for example 
by Sabbatini (1997) and van Wyhe (2004). Marshall (2001) situates the 
idea that cognitive functions are independent (in mind and brain) in the 
history of philosophy, namely in Ancient Greek thinking. Boeckx 
(2010:154ff) and Nicolas (2007) discusses phrenology in the context of 
modern functional anatomy (the localisation and cartography of cognitive 
functions in the brain, see § 614). 
 
602  2. Independent faculties, their correlation with size and the skull bone 
 
The basic observation that led to the decomposition of the mind/brain into a 
set of basic faculties was that certain individuals are good at doing some 
mental activity (e.g. counting) but bad at some other (e.g. memorising), and 
that the distribution of acuity concerning various faculties over humans 
cannot be predicted. Given this inter-individual independence of faculties, 
then, the conclusion is that they must be independent units ± mentally and 
in the brain.  

Faculty psychology married with computation theory 517 
Based on this observation, Gall promoted the idea that there is a cor-
relation between the acuity of a given faculty and its physiological size ± 
and that in addition the latter corresponds to a predictable zone on the skull 
bone. That is, the greater the acuity for a given faculty, the bigger the corre-
sponding area of the brain, whose size is directly proportional to a corre-
sponding zone of the skull ("the skull fits the brain like a glove fits the 
hand"). Hence somebody with a large number area will be good at mathe-
matics, but somebody with a small moral area will be of little morality etc. 
Predictably enough, this alleged skull-to-mental-faculty relation was 
misused for racist purposes and the apology of this or that ideology or be-
lief. This kind of instrumentalisation included the superiority of the white 
race in colonial 19th century, but also "domestic" issues: on the grounds of 
phrenology, the Irish were argued to be close to the Cro-Magnon man and 
thus to have links with the "Africinoid" races (van Wyhe no year). This was 
the more tempting as the mental faculties that phrenologists focused on 
concerned higher cognitive functions such as personality and character, 
rather than lower functions such as perceptual systems etc.  
For these reasons, phrenology has been largely discredited in the 20th 
century. Gall and 19th century phrenologists of course were wrong in assert-
ing that the size of the area of the brain that accommodates a mental faculty 
correlates with the performance of this faculty in any way. And it is also not 
true, of course, that mental faculties correlate in any way with areas of the 
skull bone. 
Gall's central tenet, however, has received massive empirical support 
in modern times: today it is an established cognitive and neurobiological 
fact that all areas of the brain do not perform all tasks: some are specialised 
in doing this, others in doing that ± mental and neural structure has a func-
tional architecture. The modern incarnation of this idea was formulated in 
terms of faculty psychology by Jerry Fodor (1983 et passim) before neuro-
imaging systems that reveal gross functional areas in the brain were avail-
able. 
 
603  3. Faculty psychology married with computation theory  
(von Neumann - Turing) 
 
In Fodor's work, the idea that the human cognitive system is composed of 
several functionally and computationally autonomous sub-systems is mar-
ried with the model of computation that was developed in the 40s, and 
which is the basis of Artificial Intelligence, Chomskian linguistics, the 

518 
Modularity Chap 3: Origins of the modular architecture of the mind 
standard model of Cognitive Science and various strands of mathematics, 
logic and the Humanities (see Gardner 1985 for a overview). 
Also, the technology of modern micro-computers is based on this 
work (hardware and software alike: structured modular programming), 
whose most prominent figures are the British mathematician Alan Turing 
(1912-1954) and the Hungarian-American mathematician John von Neu-
mann (1903-1957). Overview literature of what is commonly called the von 
Neumann-Turing model and its application to Cognitive Science includes 
Herken (1995), Clapin (2002), Pylyshyn (1984, 1989a,b), Haugeland 
1989:133ff); an introduction from the linguistic perspective is provided by 
Boeckx (2010:33ff). An early argument in favour of a computationally 
based modular conception was made by the founder of Computational Neu-
roscience, David Marr, on the grounds of vision (Marr 1982). 
Central to this theory of computation are the following claims: com-
putation is based on distinct short-term (working) and long-term memory 
(this is the essence of the Universal Turing/von Neumann Machine, see 
§596), it is serial (i.e. step-by-step, rather than parallel), it is based on a 
symbolic, pre-determined and machine-specific language, and it is organ-
ised in functional units that are devised to solve a specific problem ± the 
modules. The symbolic issue was already discussed in § 589.  
Fodor's modular organisation of the mind/brain thus unites the two 
strands, computation theory and faculty psychology (which roots in phre-
nology and related traditions in psychology, see Posner 1981). 

Chapter 4 
604  The modular architecture of the mind: how it works 
 
605  1. Higher and lower cognitive functions, modules and the central 
system 
 
Given Gall's idea that the mind is a set of functional sub-systems, the ques-
tion arises what exactly counts as a module: how many different faculties 
are there, how coarse-grained and of what type are they, what kind of evi-
dence can be brought to bear in order to identify them and how can they be 
delineated? 
Regarding the problem of functional taxonomy, Gall himself already 
argued against very broad abilities (whose operations may apply to differ-
ent domains) such as intellect, acuity, volition, attention, judgement or 
memory (Fodor 1983 calls these horizontal faculties). Just like instinct (of 
birds to sing etc.), these abilities do not have a specific neurological local-
isation in Fodor's model. Rather, they emerge from the conjugation of more 
fine-grained abilities (which Fodor 1983 calls vertical faculties) such as 
vision, audition or number processing. A range of this kind of problem-
solving entities (which are known as lower cognitive functions in psychol-
ogy) are thus the construction workers of higher cognitive abilities such as 
moral and social judgement, which Fodor (1983) calls the central system. 
Table  (254) below depicts the relationship between Fodor's central 
system and modules (how modules communicate with other modules, and 
with the central system, is a central issue that is discussed in § 650 and also 
in Vol.2). 
 
(254) Fodor (1983): modules and the central system that they inform 
number sense 
 
module Y  
vision 
 
central system 
 
audition 
 
module X 
 
language 
 
 
 

520 
Modularity Chap 4: The modular architecture of the mind, how it works 
The central system is (or rather: the central systems are) informed by 
the work that is done by modules, but it is not a module itself. Namely, 
higher cognitive abilities that are the result of the central system lack the 
two main characteristics that define modules: they are not domain specific, 
and they are not (informationally) encapsulated (more on these notions 
shortly). Also, they try "to make sense" of the information that is submitted 
to them and hence may be goal oriented.  
Unlike central systems, modules are "dummy" and non-teleological: 
they have do decisional latitude, do not make or evaluate hypotheses and 
hence do not try to achieve any goal: they are simple computational sys-
tems which calculate a predictable output on the grounds of a given input 
("input systems" which are stimulus-driven). They provide evidence that 
the central system needs in order to manage hypotheses, but are entirely 
insensitive to whatever the central system may "ask" them to do. Modules 
do their job fast, well, they are very reliable, and they are mandatory: hu-
mans cannot decide to switch them off. For example, visual stimulus al-
ways ends up as a three dimensional picture, language is always processed 
as such and not as noise, and subjects cannot help identifying what kind of 
surface their fingers are running over. 
Prime examples of lower cognitive functions that qualify as modules 
have already been mentioned: audition, vision, number sense. At least the 
two former are no doubt genetically endowed. Being innate is thus another 
property of modules. Fodor (1983:44) grants modular status to "the percep-
tual faculties plus language" ± an interesting definition. 
Following the Fodorian track, general introductions of the modular 
approach to the mind include Stillings et al. (1995:16ff), Segal (1996), 
Cattell (2006) and Samuels et al.(1999:85ff). Following Marr (1982), vi-
sion is certainly the best studied cognitive faculty which indeed provides 
pervasive evidence for a modular architecture of the mind/brain (e.g. the 
papers on vision in Garfield (ed.) 1987:325ff, Stillings et al. 1995:461ff). 
 
606  2. How much of the mind is modular? 
 
607  2.1. Peripheral vs. massive modularity: is there a non-modular core? 
 
Fodor (1983) is pessimistic about our ability to understand how central 
systems work: he assumes that they are resistant to scientific theorising and 
ultimately to human understanding because they cannot be appraised 

How much of the mind is modular? 521 
through the modular prism: "the more global [«] a cognitive process is, the 
less anybody understands it" (Fodor 1983:107).  
A different line of thought expands the modular architecture to cen-
tral systems as well. Pinker (1997) and Plotkin (1998) are the most promi-
nent figures of this direction: according to them, all mental processes are 
computations. Smith (2002, 2003) also questions the strict separation be-
tween modules and non-modular central systems, and Smith & Tsimpli 
(1995:164ff, 1999) are optimistic regarding our chances to understand how 
central systems work: they craft the notion of quasi-modules, which they 
believe higher cognitive functions are produced by. The volume edited by 
Hirschfeld & Gelman (eds.) (1994) also contains a number of papers that 
argue for the domain specificity of higher cognitive functions such as social 
categories, cultural representations and emotions (domain specificity is a 
central property of modules, see § 611 below). 
Following the same track, Higginbotham (1987:129f) argues that 
language is a central system and modular. Sperber (1994, 2001) also pro-
motes the modular character of central systems: according to his massive 
modularity, the brain is modular through and through. 
Fodor (1987:27) calls this the "modularity thesis gone mad": he has 
always held the view that not all cognitive functions are modular in nature. 
Fodor (1987) for example is a defence of this position. The article opens 
like this: "There are, it seems to me, two interesting ideas about modularity. 
The first is the idea that some of our cognitive faculties are modular. The 
second is the idea that some of our cognitive faculties are not." 
More recently, Fodor (2000) is a book entirely devoted to the ques-
tion whether all or only part of the cognitive system is based on a modular 
architecture. The book is an exegesis and a refutation of Pinker's and Plot-
kin's "New Synthesis Psychology" (which Fodor calls rationalist psychol-
ogy, see also Fodor 1998). Gerrans (2002) provides an informed overview 
of the debate regarding the articulation of modules with central systems. 
 
608  2.2. Is the central system impenetrable for human intelligence? 
 
What really is behind this debate is (against a possible prima facie impres-
sion) a categorical, rather than a gradual distinction ± one that has deep 
philosophical roots and far-reaching consequences. That is, the modular 
paradigm falls into two opposing camps, one holding up Descartes' position 
that the mind, or at least some of it (the central system in Fodor's terms), is 
beyond what can be understood by human intelligence and will always 

522 
Modularity Chap 4: The modular architecture of the mind, how it works 
remain an impenetrable mystery (the soul is of course lurking behind the 
mind of Descarte's mind-body dichotomy); by contrast, the other camp 
makes no difference between lower and higher cognitive functions, which 
are both the result of modular activity.  
We have seen that the former view is defended by Fodor (1998, 
2000), but also by Chomsky in linguistics (e.g. Chomsky 1984:6f, 23f, 
Chomsky 1995b:2f, chapter 4 of Chomsky 1975 is called "Problems and 
mysteries in the study of human language"). Fodor's and Chomsky's posi-
tion blocks any inquiry into how the mind really works (all of the mind for 
Descartes, just a subset of it, the central system, for Fodor/Chomsky) be-
fore it has even started: don't try to find out how it works, you will fail 
anyway. This has direct consequences for the dialogue with the implemen-
tational level (see § 614): only a subset of the mind may be mapped onto 
neuro-biology ± the central system is not based on any neuro-biological 
activity, or at least will humans never be able to understand what the rela-
tionship is. 
 
609  2.3. Is the mind (are modules) the result of Darwinian adaptation? 
 
The latter position, i.e. where all cognitive functions are in principle acces-
sible to human intelligence and must ultimately be able to be mapped onto 
neurobiology, is what Fodor calls rationalist psychology. In other quarters, 
it is called evolutionary psychology in recognition of the fact that it is inti-
mately interwoven with the Darwinian perspective. Pinker (1997) and Plot-
kin (1998) hold that the mind, like the brain and all other properties of liv-
ing beings, is the result of an adaptive evolution which was marshalled by 
selectional pressure over millions of years.  
Obviously, if all is the result of environment-driven adaptation, no 
part of the mind can stand aside. Which means, viewed from the other 
camp, that Fodor and Chomsky must deny the idea that all of the mind is 
the result of Darwinian selection. This is precisely what they do in the bio-
linguistic programme: the controversy between Hauser et al. (2002) (also 
Fitch et al. 2005) and Pinker & Jackendoff (2005a,b) is about this issue.  
Hauser et al. (2002) argue that the FLN (Faculty of Language in the 
Narrow sense), i.e. what really makes language distinct and unique (with 
respect to other cognitive functions), boils down to recursion (of morpho-
syntax) and the ability to talk to interpretational systems (phonology and 
semantics), that is to Merge and Phase. They also hold that the FLN is the 
only property of language that could not possibly be the result of an (adap-

Core modular properties 523 
tive) evolution based on an animal ancestor: the FLN is given (more on this 
debate in § 633). This claim lies at the heart of the biolinguistic programme 
(where phonology and semantics for example are not specifically human, 
see § 639) and is further developed with specific attention for phonology by 
Samuels (2009a,b). 
On the other hand, the general viewpoint of evolutionary psychology 
on the mind is exposed by Cosmides & Tooby (1992a, 1994), Barkow et al. 
(1992). Samuels et al. (1999) offer a valuable digest of the debate between 
peripheral (Fodor/Chomsky) and massive (evolutionary psychology) modu-
larity on the backdrop of the opposition between what they call Chomskian 
and Darwinian modules. Even though based on a non-evolutionary perspec-
tive, Sperber (1994, 2001), Smith (2002, 2003) and Smith & Tsimpli 
(1995:164ff, 1999) go along with the Darwinian party. 
 
610  3. Core modular properties  
 
611  3.1. Domain specificity 
 
Modules are computational units that are devised for just one highly spe-
cific task. Therefore the symbolic vocabulary that they work with is as spe-
cific as their task: the input, its transformation by computation and the out-
put are written in a specific vocabulary.  
A module can only understand its own vocabulary: whatever infor-
mation is submitted that is not written in the specific symbol code of the 
module is uninterpretable: it is treated as noise and simply ignored. For 
example, the visual module can only take visual stimulus as an input. It will 
ignore any auditive or other alien information.  
Arguments for domain specificity come from various fields, includ-
ing neuropsychology, computational theory and cognitive evolution (Ger-
rans 2002:261 provides an overview, see in particular Cosmides & Tooby 
1992a). Hirschfeld & Gelman (eds.) (1994) provide an overview of domain 
specificity and the kind of domains that can be isolated (which include 
higher cognitive functions such as social categories, culture-specific repre-
sentations and emotions); Fodor (2000:58ff) discusses the various ways in 
which domain specificity has been used. 
Domain specificity will be put to use in § 640 in order to identify the 
grammar-internal modular architecture. 
 

524 
Modularity Chap 4: The modular architecture of the mind, how it works 
612  3.2. Informational encapsulation 
 
Modules are also (informationally) encapsulated, which means that during 
the computation performed, they do not need and cannot take into account 
anything that was not present in the input. That is, once the input is defined 
and computation has begun, nothing can alter the course of events, and the 
output is produced in complete disregard of any module-external informa-
tion such as high-level expectations, beliefs (coming from the central sys-
tem), memory, inference and attention or results of other modules.153 Con-
versely, modules are unable to communicate any intermediate result of their 
work: transmission to other modules or to the central system is only possi-
ble once the computation is completed. In sum, modules are autistic (Fodor 
2000:62ff, Gerrans 2002 and Smith & Tsimpli 1995:30f provide a concise 
introduction to encapsulation). 
The effect (and hence existence) of encapsulation is typically shown 
on the grounds of optical illusions. Under  (255) below appear a number of 
well-known cases, which all demonstrate that humans are "fooled" by their 
visual system even if they know beforehand that what they "see" is not true: 
there is no way to willingly marshal vision according to prior knowledge of 
the central system, to some desire or presupposition. Vision does whatever 
it does without asking any other cognitive system, and even against the will 
of the subject: no other cognitive system, modular or central, can "break 
into" vision in order to change its course once computation has begun.154 
153 This of course does not withstand the existence of networks of modules or of 
"loops" whereby the result achieved by a given module serves as the input of 
several other modules and eventually, enriched with additional information, is 
pulled several times through the same module. 
154 The reason and genesis of the illusions are secondary for the argument. Also 
note that the effect is the same for all humans (who are subject to the illusion: 
some are not), i.e. perfectly independent of culture, language, age, social pa-
rameters and so forth. 

Core modular properties 525 
(255) 
Zöllner: 
all long lines are parallel 
Müller-Lyer 
lines are equal in length 
Poggendorff 
the lower line on the righthand 
side of the rectangle is the same 
(straight) line as the one on the 
lefthand side 
Hering 
vertical lines are parallel 
 
Encapsulation has been challenged on the grounds of the possibly 
non-encapsulated communication between the central system and modules 
whereby the former affects ongoing modular computation. Arguments to 
this end have been made on the connectionist side (e.g. Elman 1994), but 

526 
Modularity Chap 4: The modular architecture of the mind, how it works 
also in the quarters of developmental psychology (Karmiloff-Smith 1998). 
Ongoing debate is reviewed by Gerrans (2002), who argues in favour of 
encapsulation. 
The syntactic application of encapsulation is Chomsky's (1995a:228) 
inclusiveness, on which more in § 648. Encapsulation will also play a role 
in § 621 when the modular status of grammar and its subsystems is dis-
cussed. 
 
613  3.3. Summary: how to identify a module 
 
A module is thus a hard-wired and genetically determined computational 
unit that builds on a fixed and localisable neural structure; it is domain spe-
cific (i.e. content-based), autonomous, automatic, mandatory, stimulus-
driven and insensitive to central cognitive goals. Segal (1996:145) provides 
an informed and concise overview of the modular idea in its various incar-
nations. His list of core properties contains nine items, which are shown 
under  (256) below. 
 
(256) core properties of cognitive (Fodorian) modules according to Segal 
(1996:145) 
 
a. domain specificity 
 
b. informational encapsulation 
 
c. obligatory filtering 
 
d. fast speed 
 
e. shallow outputs 
 
f. limited inaccessibility 
 
g. characteristic ontogeny 
 
h. dedicated neural architecture 
 
i. characteristic patterns of breakdown 
 
Crucially for linguistics (as we will see below), a module is designed 
for a special purpose and can only work with the specific vocabulary asso-
ciated ± all the rest is noise: modules "solve a very restricted class of prob-
lems, and the information it can use to solve them with is proprietary" 
(Fodor 1998). 
Now recall Chomsky & Halle's (1968) description of the phonologi-
cal rule system that was already quoted in § 84: it is quite surprising an an-
ticipation of what Fodorian modules will look like 15 years later. 
 

Specialised neurons and neural localisation of cognitive functions 527 
(257) "The rules of the grammar operate in a mechanical fashion; one may think 
of them as instructions that might be given to a mindless robot, incapable of 
exercising any judgment or imagination in their application. Any ambiguity 
or inexplicitness in the statement of rules must in principle be eliminated, 
since the receiver of the instructions is assumed to be incapable of using 
intelligence to fill in gaps or to correct errors." Chomsky & Halle (1968:60) 
 
Given these core modular properties, a question is how modules are 
practically delineated within the host of cognitive functions. The typical 
answer is domain specificity: a computation that builds on heterogeneous 
primitive units cannot be done in one and the same module. As we will see 
below (§ 622), there is serious debate in linguistics regarding which entities 
(sub-disciplines) exactly are identical or distinct computational systems 
(ongoing controversy namely concerns morphology and syntax, see § 537). 
In this situation, the guiding light will be to look at which kind of vocabu-
lary is processed on each side, and whether it is the same. In case it is not, 
the two entities cannot be incarnations of the same module. 
§618 introduces yet another way of detecting modules, (double) dis-
sociation, which may be called external in comparison to the internal han-
dle that is offered by domain specificity. While the latter requires only the 
inspection of linguistic properties (the vocabulary used), (double) dissocia-
tion requires the examination of speakers that experience significant cogni-
tive and/or brain damage. 
Overview literature regarding the general properties of modules in-
cludes Segal (1996), Pinker (1997), Plotkin (1998), Sperber (2001), Ger-
rans (2002), Jackendoff (2002:218ff), Smith (2002, 2003) and Fodor 
(2000). Cosmides & Tooby (1992b:93ff) provide a historical overview of 
the modular idea from the psychologist's perspective. 
 
614  4. Specialised neurons and neural localisation of cognitive functions 
 
615  4.1. Mind-brain relationship 
 
The modular approach to the mind/brain has a number of implications in 
philosophy, neurobiology, psychology, linguistics and other areas of knowl-
edge. Chomsky (2002:45ff) provides a historically oriented overview, argu-
ing that Cognitive Science, where the mind-brain dichotomy is still puz-
zling, may learn a lot from the history of adult sciences like physics and 
chemistry, which had to face similar problems a while ago. 

528 
Modularity Chap 4: The modular architecture of the mind, how it works 
Below two testing grounds that have been prominently explored in 
the literature are given closer attention: on the one hand, the prediction that 
functional specialisation of the mind implies the existence of specialised 
and localisable suites of neurons in the brain. On the other hand, the predic-
tion that if there are functionally specialised modules and neurons, cogni-
tive and/or brain damage must be able to "plug them out" without this af-
fecting other faculties (§ 618). 
Let us first take a closer look at the former. It was mentioned in § 592 
that the relationship between symbolic representations and real-world ob-
jects, in physics, chemistry and biology as much as in Cognitive Science, is 
intricate and dialectic, but in any case non-arbitrary. It is an established 
neurobiological fact that all neurons do not do everything: suites of neurons 
may be specialised (although not necessarily to do one single thing).  
For example, that the Broca and Wernicke areas of the brain are spe-
cifically related to the processing of language is known since the 19th cen-
tury (Broca 1861, see e.g. Loevenbruck et al. 2005 for a modern investiga-
tion) and has even found its way into popular science. Posner (2001) and 
Nicolas (2007) offer a historical survey of the efforts that are made in order 
to localise cognitive functions in the brain (see also Boeckx 2010:149ff 
regarding language). The quote from Bastian's (1880) book "The brain as 
an organ of mind" that is reported in § 597 is quite instructive in this re-
spect. 
 
616  4.2. Functional anatomy: the existence of specialised and localisable (suites 
of) neurons is undisputed 
 
Gerrans (2002:259) points out that the symbolic issue which was discussed 
in § 589 is entirely independent of the functional specialisation that is pre-
dicted by modularity: whether or not computation relies on symbols and 
hence is content-sensitive is orthogonal to the question whether the 
mind/brain is made of functional units. Neurobiologically speaking, the 
existence of functionally specialised suites of neurons provides evidence 
for modularity no matter what it actually is that the neurons in question 
process. 
The modern study of vision for example has produced undisputed 
evidence that specialised neurons exist and are localisable in the brain. 
 

Specialised neurons and neural localisation of cognitive functions 529 
(258) "Functional specialisation occurs within the neural systems on which vision 
depends. The visual cortex contains individual and suites of neurons special-
ised for detecting orientation, disparity, wavelength, velocity, direction and 
size. (Marr, 1982). This neuroanatomical organisation reflects the functional 
organisation of the visual module for good reason. Rather than involve the 
same region in more than one task, 'Regional specialisation, on the contrary 
means that columns of cells can he connected with neighbours that have 
related functions.' (Shallice, 1988, p. 19)." Gerrans (2002:263) 
 
Gerrans (2002:263) goes on to point out that "clearly however, there is 
no one-to-one mapping from cognitive function to unique neural location" ± 
it was mentioned earlier that a complicated and dialectic relationship is cer-
tainly what is expected.  
In our past and present understanding where symbolic representations 
and functional anatomy are still light-years away from being able to be 
matched, the classical strategy is to approach the problem by thinking of it in 
terms of levels. Since linguistic representations are much too coarse grained, 
and neuobiological functioning way too fine grained, intermediate levels may 
help to do justice to both and make our understanding of the overall situation 
progress.  
This is what connectionism set out to do in the late 80s when it was 
considered to be an implementational level of symbolic representations, but 
still ranging above neurobiology: recall from § 599 that this is Smolensky's 
(1987) position, which he carried over into his version of OT (Smolensky & 
Legendre 2006). The work by David Poeppel, often in collaboration with 
linguists, also follows this track: here the relevant level of abstraction is the 
circuit, a brain structure that computes simple operations. A circuit is sim-
ple enough not to exceed what can be measured neurobiologically, but at 
the same time complex enough to allow for the representation of a simple 
linguistic process. This research programme is laid out in Poeppel & 
Hickok (2004), Embick & Poeppel (2005) and Poeppel & Embick (2005); 
relevant work includes Hickok (2004, 2007), Poeppel (2008). Boeckx 
(2010:158ff) echoes this line of thought and inserts it into a broader (also 
historical) perspective. 
The plasticity of the brain is another factor: suites of neurons that sup-
port a given cognitive function may "migrate" within the brain due to dam-
age, hemispherectomy, growth of a tumour and the like. Locations of cogni-
tive functions in the brain are thus approximative anyway (no two brains are 
identical), and only valid for subjects with normal development. Finally, 
nothing requires a cognitive function to be supported by a suite of neurons 

530 
Modularity Chap 4: The modular architecture of the mind, how it works 
where all neurons involved are adjacent: a function may be spread over sev-
eral locations in the brain. 
 
617  4.3. Some literature 
 
The section of Brain and Biology of Dupoux (ed.) (2001) offers a number 
of overview articles that report on how functional brain-imaging techniques 
(PET, fMRI, ERPs) 155 interact with classical psychology and Cognitive 
Science, eventually achieving the localisation of a number of cognitive 
functions in the brain. Posner (2001) is about language and attention; 
Newport et al. (2001) show how neuroscience can enlighten questions of 
language acquisition and the notion of critical periods (and vice-versa); 
Peretz (2001) uses brain imaging in order to approach auditory and emo-
tional processing in relation with music. The section on the neurological 
basis of language in Banich & Mack (eds.) (2003) offers similar perspec-
tives. 
In the area of phonology, the book edited by Durand & Laks (2002) 
contains three articles that discuss the relationship between cognitive func-
tions and their neural implementation in the brain, namely from the modern 
neuro-imaging point of view. Démonet et al. (2002) hunt down anatomical 
and temporal indexes of the neural activities that underlie language percep-
tion (especially phonological and lexical-semantic processes); they also 
discuss the evolution from aphasia-based to neuro-imaging-based tech-
niques that are and were used in the study of the physiology of cognition.  
Schwartz et al. (2002) discuss the relationship of perception, action 
control and phonology. They argue that empiricist approaches based on 
self-organising statistical and exemplar-based models are unsuited since 
they lack constraints on regulation and control, which according to the au-
thors can only come from a perception-action link at the intersection of 
phonetics and phonology. 
Abry et al. (2002) draw arguments from aphasia, especially from a 
babbling-like type (which tan-tan [tãtã], the bequeathed production of 
Broca's patient, could illustrate), in order to localise the control of CV-
recurring utterances in the non-lateral left hemisphere. 
 
155 PET = Positron Emission Tomography, fMRI = functional Magnetic Resonance 
Imaging, ERPs = Event-Related Potentials. 
These bibliographical indications are not systematic: the literature on 
the topic is booming, and I am not a specialist of the field. The purpose is 

Modules can be plugged out without affecting other faculties 531 
just to show that there is something like Cognitive Neuroscience, a new 
discipline that has emerged in the recent past, which tries to achieve "the 
synthesis of mind and brain", as Posner (2001) puts it. 
 
618  5. Modules can be plugged out without affecting other faculties 
 
619  5.1. Double dissociation 
 
Let us now consider the other interesting prediction made by modular the-
ory: so-called double dissociation is based on the functional character of 
modules; it opens a fairly precise empirical testing ground on the basis of 
cognitive and/or brain damage. 
If different functions are managed by different modules with no 
overlap (i.e. a given function is computed by one and only one module), 
then any module should be able to be plugged out, causing the loss of the 
function that it is responsible for, but leaving the rest of the system without 
damage. If on the other hand there are no modules and all functions are 
intertwined (this is the connectionist take), the damage of a particular area 
should impact a variety of other areas and functions. 
Hence showing that two cognitive functions are entirely independent 
is providing support for the modular architecture. The demonstration of 
functional independence requires so-called double dissociation (e.g. Smith 
2003): given two abilities, different subjects may lose one while retaining 
the other and vice versa. A trivial case is blindness and deafness: some peo-
ple are blind but not deaf, others are deaf but not blind. Hence it is reason-
able to assume that vision and audition do neither use the same hardware 
(brain) nor the same software (mind).  
 
620  5.2. Documented cases: face recognition, number sense 
 
Examples of (double) dissociation are frequently reported in the pathologi-
cal literature (e.g. Karmiloff-Smith et al. 1995). One case in point is dis-
cussed by Smith (1998:9): "prosopagnosia is the sad condition which af-
flicted Oliver Sacks' eponymous subject. 'The man who mistook his wife 
for a hat'. As a result of a cerebral lesion involving the visual system he 
became unable to recognise faces, even though he could still identify peo-
ple from their voice or smell or touch, and his conceptual abilities were 
unaffected." This is evidence to the end that vision is not just one undiffer-

532 
Modularity Chap 4: The modular architecture of the mind, how it works 
entiated cognitive function. Rather, it falls into several computational sys-
tems, one of which is specialised in face recognition (also, shape and colour 
appear to be determined independently). On the other hand, Moscovitch et 
al. (1997) document the symmetric dissociation: they study a case where 
object vision is impaired, but face recognition is normal.  
Another case in point is the number sense, which appears to actually 
involve two separate modules: one that computes small numbers up to four 
or five with high precision and very rapidly (paucal); the same module also 
roughly guesses bigger numbers (8 items are less than 20, 20 items are 
about 20, not 60) (approximate). A different module manages so-called 
verbal counting: it operates over natural numbers and performs mathemati-
cal calculus (the four basic operations). Based on evidence from subjects 
with various cerebral lesions, Dehaene (1997) reports that the paucal and 
the approximative abilities are always associated: if a subject is impeded in 
one area, the other will also be affected. However, verbal counting and 
paucal/approximate counting are doubly dissociated: subjects who cannot 
cope with one may have undamaged abilities regarding the other. 
Dissociation is also documented for implicit and explicit knowledge 
by Reber & Squire (1998). 
Besides pathological evidence that relies on damage of the mind 
and/or brain, the (double) dissociation of cognitive functions may also be 
demonstrated on the grounds of data from development: Hermer & Spelke 
(1996) for example study spatial reorientation in this perspective. 
 
621  5.3. Double dissociation of language 
 
Regarding language, Neil Smith and Ianthi-Maria Tsimpli have docu-
mented the case of Christopher over a relatively long period (Smith & 
Tsimpli 1991, 1995, 1999, also Smith 1998, 2002, 2003). Christopher has 
severe cognitive deficits (he cannot look after himself, has trouble to find 
his way around, poor hand-to-eye coordination etc.), but an extraordinary 
talent for the acquisition and use of language. That is, Christopher is fluent 
in some 15 or 20 languages, in which he can construct morphologically and 
syntactically well-formed sentences after minimal exposure. His enhanced 
talent for language and languages falls into the same category as other 
cases of the so-called savant syndrome: brain-damaged savants that are 
otherwise mentally handicapped and typically autistic are documented with 
unbelievable skills for calendrical calculation (ability to tell instantly on 
which day of the week any date in past, present or future centuries falls) or 

Modules can be plugged out without affecting other faculties 533 
various artistic talents (e.g. musicians who can play complex passages after 
a single hearing). 
Smith & Tsimpli (1995) explain the relevance of Christopher's case 
(and other similar cases) for establishing language as a module. 
 
(259) "Although no one else has been reported as displaying the multi-lingual 
prowess that Christopher does, these cases illustrate the same dissociation 
between linguistic and general cognitive abilities as is exhibited by such 
individuals as Laura [«], by Williams Syndrome children [«], by 'chatter-
box' children [«], and by hyperlexics [«], all of whom have great linguis-
tic ability in the presence of severe cognitive deficits. Examples in the oppo-
site direction ± cases of people with impaired language in the presence of 
normal intellectual ability ± are provided by some deaf people, some apha-
sics, and by those suffering from SLI (Specific Language Impairment), 
where brain damage (in some cases genetically caused) occasions a lan-
guage deficit independently of the rest of the cognitive profile [«]. 
The existence of these varied conditions provides a classical example of 
double dissociation: language can be impaired in someone of otherwise 
normal intelligence, and ± more surprisingly ± someone with intelligence 
impaired by brain damage may none the less have normal, or even en-
hanced, linguistic ability." Smith & Tsimpli (1995:3, emphasis in original) 
 
The basic argument for the (double) dissociation of language is thus 
the fact that in the case of Christopher the language faculty may work well 
(actually better than normal) in absence of control by "general intelli-
gence": Smith & Tsimpli (1991:325) write that "it is clear that his talent 
exists in the absence of the normal 'general intelligence' one might expect 
to find associated with multi-lingualism." They also draw on encapsulation 
of Christopher's language performance, which ± as predicted by Fodorian 
modularity ± is independent from general purpose considerations or global 
goals: the general goal to produce non-nonsensical translations is not able 
to "break into" Christopher's language performance while translating. 
 

534 
Modularity Chap 4: The modular architecture of the mind, how it works 
(260) "In the present context informational encapsulation would mean that 
Christopher's linguistic ability was independent of his general cogni-
tion and could operate in the absence of 'central' control. His method 
of translating makes this extremely plausible. When asked to trans-
late, he starts instantly and proceeds word by word rather like an 
automaton. If he is asked to slow down and mull over the meaning of 
the whole passage in an attempt to improve his performance, he 
shows visible signs of distress and professes himself incapable of 
doing any such thing. Moreover his equanimity at producing nonsen-
sical translations indicates either that he is incapable of discerning 
such nonsense, or that his linguistic (morpho-syntactic) system oper-
ates in divorce from any semantic or pragmatic control." Smith & 
Tsimpli (1991:325) 
This is evidence to the end that language as such is a module: it ap-
pears to be doubly dissociated. That is, it may be "plugged in or out" with-
out affecting the (non-)deficient rest of cognitive abilities.  
Williams Syndrome also provides strong evidence to this end (see 
Tager-Flusberg & Sullivan 2000). Williams Syndrome "is a rare genetic 
disorder resulting in certain characteristic facial features and physical prob-
lems as well as a unique and particularly striking cognitive profile. Subjects 
are retarded, with an average IQ of around 50. They are also particularly 
impaired with respect to arithmetical and visual-spatial abilities. However 
they exhibit an unusually high level of linguistic ability, with a particular 
penchant for sophisticated and unusual vocabulary items" (Segal 1996:154, 
who offers a concise general introduction to Williams Syndrome). 
This kind of evidence that is typically used for the (double) dissocia-
tion of language form other cognitive functions has also been given other 
interpretations: Bates (1994) argues for the innateness and the localization 
of language in the brain, but against its domain specificity. The argument is 
based on the fact that the dissociations observed are never one hundred 
percent waterproof: linguistic deficits are accompanied by minor non-
linguistic impairment as well, and non-linguistic developmental disorders 
such as Williams Syndrome have also some impact on language. 
In any event, modularity and Chomsky's conception of a language 
organ (§ 627, e.g. Chomsky 1995b, Chomsky 2000b:106ff) predict that 
language as such is a plug-in unit in the concert of cognitive functions. The 
question, then, is whether it may be decomposed into yet smaller units. The 
modular structure of language itself is hinted at by the quote under  (260), 
where morpho-syntax appears to be estranged from semantic and pragmatic 
control. This is what the following pages are about. 

Chapter 5 
622  Modularity of and in language, related systems 
 
623  1. Modularity in the early days of generative grammar: 50s-60s 
 
624  1.1. A spearhead of the cognitive revolution of the 50s in language 
 
Language has always played a prominent role in the development of Cogni-
tive Science: it was a prime candidate for the implementation of the von 
Neumann-Turing programme (see § 603, Gardner 1985:182ff) that really 
started to penetrate modern science in the 50s (e.g. Gardner 1985:28ff). 
Noam Chomsky and generative linguistics were the spearhead of the 
computational conception in the realm of language (e.g. Cosmides & Tooby 
1992b:93ff, Chomsky 1993b). In 1972, computer scientists Allen Newell 
and Herbert Simon recall the 50s and the inception of Cognitive Science. 
 
(261) "Within the last dozen years a general change in scientific outlook has oc-
curred, consonant with the point of view represented here. One can date the 
change roughly from 1956: in psychology, by the appearance of Bruner, 
Goodnow, and Austin's Study of Thinking and George Miller's 'The magical 
number seven'; in linguistics, by Noam Chomsky's 'Three models of lan-
guage'; and in computer science, by our own paper on the Logic Theory 
Machine." (Newell & Simon 1972:4, emphasis in original) 
 
Also, Chomsky has always considered that the study of language is 
undissociable from the study of mind: cognitive realism is a founding 
statement of the generative enterprise ± since Chomsky (1959) it constitutes 
the fraction line with (certain types of) structuralism (in linguistics) and 
behaviourism (in psychology and learning theory). 
In this context, modularity is a necessary ingredient of the generative 
enterprise, both regarding language in the concert of other cognitive func-
tions and its internal organisation. The former area may be illustrated by the 
following quote from Chomsky (1975) (among a host of others, e.g. 
Chomsky 1972, 1980, 1984, 1988, 1993b etc., Higginbotham 1987 and 
Hirschfeld & Gelman 1994:5ff provide historical discussion). 
 

536 
Modularity Chap 5: Modularity of and in language, related systems 
(262) "[T]he position we are now considering postulates that this faculty [the 
language faculty] does exist, with a physical realization yet to be discov-
ered, and places it within the system of mental faculties in a fixed way. 
Some may regard this picture as overly complex, but the idea that the sys-
tem of cognitive structures must be far more simple than the little finger 
does not have very much to recommend it. 
The place of the language faculty within cognitive capacity is a matter for 
discovery, not stipulation. The same is true for the place of grammar within 
the system of acquired cognitive structures. My own, quite tentative, belief 
is that there is an autonomous system of formal grammar, determined in 
principle by the language faculty and its component UG. This formal gram-
mar generates abstract structures that are associated with "logical forms" (in 
a sense of this term to which I will return) by further principles of grammar. 
But beyond this, it may well be impossible to distinguish sharply between 
linguistic and nonlinguistic components of knowledge and belief. Thus an 
actual language may result only from the interaction of several mental facul-
ties, one being the faculty of language. There may be no concrete specimens 
of which we can say, these are solely the product of the language faculty; 
and no specific acts that result solely from the exercise of linguistic func-
tions." Chomsky (1975:43) 
 
Another point of interest is that language has always been considered 
a prime candidate for modularity ± more than other cognitive systems ± in 
the debate regarding which faculties exactly are modular, and which ones 
are not, i.e. result from the activity of Fodorian central systems (see the 
question "how much of the mind is modular?" in § 606). Smith & Tsimpli 
(1995:30) for example distinguish between perceptual and cognitive sys-
tems, where the former identify as "the sensorium plus language", while the 
latter are Fodor's central systems (fixation of belief, thought, storing 
knowledge). On this view, language is on a par with vision, audition, taste, 
smell and the sense of touch. 
The intimate relationship of language and modular theory is also re-
flected by the fact that Fodor's (1983) seminal book has emerged from a 
class on cognitive theory that Fodor co-taught with Chomsky in fall 1980.  
 
625  1.2. LSLT: language is made of modules (levels), a concatenation algebra 
and interfaces 
 
The internal organisation of language in terms of distinct computational 
and functional systems that are specialised in morpho-syntax, phonology 
and semantics is made explicit in one of the earliest generative documents: 

Modularity in the early days of generative grammar: 50s-60s 537 
Chomsky's Logical Structure of Linguistic Theory, published only in 1975, 
is based on a 1955-56 manuscript (one chapter of which was eventually 
outsourced to make Chomsky's Ph.D thesis). In the structuralist environ-
ment of the time, Chomsky holds that the basic units that language is made 
of are levels (see § 61 on structuralist Level Independence). 
 
(263) "[T]he theory of linguistic structure [is], essentially, the abstract study of 
'levels of representation'. 
[«] 
A linguistic level is a system L in which we construct unidimensional repre-
sentations of utterances. Thus a level has a certain fixed and finite 'alphabet'
of elements, which we will call its 'primes.' Given two primes of L we can 
form a new element of L by an operation called 'concatenation,' symbolized 
by the arch ^. Thus if a and b are (not necessarily distinct) primes of L, we 
can form a^b and b^a as new elements of L. Concatenation is essentially the 
process of spelling, where primes are taken as letters. Given the element a^b 
and the prime c, we can form a new element (a^b)^c." Chomsky (1955-
56:105) 
 
Levels are thus computational systems, which operate each on a spe-
cific vocabulary and produce suites of vocabulary items associated with a 
hierarchical structure that reflects their concatenative history. This is pre-
cisely the description of a Fodorian module: a domain specific computa-
tional unit that works only on its own proprietary vocabulary (§ 611). And 
the quote also describes what is known today as the basic minimalist en-
gine, Merge. Viewed from this perspective, phrase structure rules were an 
ephemeral interlude (see also Lasnik & Lohndal 2009:46 on the 50s-roots 
on Merge). 
LSLT is at variance in an interesting way with the inverted T model 
that emerges in the 60s and represents the generative architecture of gram-
mar up to the present day (§ 86). Indeed, LSLT does not make any differ-
ence between concatenative and interpretative systems: all levels carry out 
concatenation. In phonology, Chomsky holds that phonemes are concate-
nated. 
 
(264) "[T]he level of phonemes for English has among its primes the symbols p, i,
n, which can be concatenated to form the string p^i^n, which is the Pm-
marker of 'pin'." Chomsky (1955-56:66) 
 
The number and nature of the levels that Chomsky assumes also wit-
nesses the structuralist environment. 
 

538 
Modularity Chap 5: Modularity of and in language, related systems 
(265) "We will find it necessary to distinguish at least the following levels for 
linguistic description: phonemes (Pm), morphemes (M), words (W), syntac-
tic categories (C), phrase structure (P), and transformations (T). The gram-
mar must indicate the structure of each utterance on each of these levels."
Chomsky (1955-56:66) 
 
Finally, the existence of distinct computational systems that produce 
hierarchised suites of distinct vocabulary items requires interface mecha-
nisms for inter-level communication. This need for translation, also a per-
fectly modern and modular concern, is made explicit by Chomsky. 
 
(266) "A linguistic level is not determined completely by the statement that it is a 
concatenation algebra. We must also specify its relations to other levels (i.e., 
the conditions of compatibility between levels)." Chomsky (1955-56:106) 
 
In sum, all basic ingredients of Fodorian modularity are already pre-
sent in one of the earliest generative documents: LSLT defines a number of 
modules that language is made of (many more than what the inverted T will 
recognise, though); these modules are input-output systems and have a 
"concatenation algebra", which in modern terms means that they are do-
main specific and carry out Merge (all modules, not just morpho-syntax, 
though have the concatenative privilege); finally, LSLT modules have the 
ability to talk to other modules, Phase in modern vocabulary. 
 
626  1.3. Modularity on its way: from LSLT to Aspects and SPE 
 
Newmeyer (1986:172f, 198f) provides some elements of how the modular 
conception that was laid out in LSLT was progressively introduced and 
worked out in generative grammar. He mentions Chomsky & Miller (1963) 
as an early source for the explicit statement that syntax and phonology are 
distinct computational (input-output) systems. 
 
(267) "We regard grammar as having two fundamental components, a syntactic 
component of the kind we have already described and a phonological com-
ponent to which we now briefly turn our attention. [«] The phonological 
component embodies those processes that determine the phonetic shape of 
an utterance, given the morphemic content and general syntactic structure of 
this utterance. [«] As distinct from the syntactic component, it plays no part 
in the formulation of of new utterances but merely assigns to them a pho-
netic shape." Chomsky & Miller (1963:306f, emphasis in original) 
 

Modularity implies biology and innateness: the language organ 539 
"The phonological component can be thought of as an input-output device 
that accepts a terminal string with a labelled bracketing and codes it as a 
phonetic representation." Chomsky & Miller (1963:308) 
 
The inverted T model was formally introduced in Aspects (Chomsky 
1965:15ff) (see §§ 84, 86); it fixes the existence of (at least) three independ-
ent computational systems (morpho-syntax, phonology, semantics) and to 
date represents the bottom line of the generative architecture of grammar. 
The quote from SPE under  (257) (§ 613) also shows that the generative 
conception of the internal structure of grammar was already modular in the 
60s, even though of course this particular vocabulary item was not used. 
Since 1965, Chomsky has been constantly explicit on the modular character 
of language (e.g. Chomsky (1972, 1975, 1984).  
An early source is also Chomsky (1965 [2006]), a chapter included 
in later editions of Chomsky (1972), but which Chomsky explains in the 
preface to the second edition was actually written in 1965. In this text, the 
units of the inverted T model are referred to as components (syntactic, pho-
nological, semantic). 
The further development of modularity within the inverted T model 
in the 80s is discussed in § 628 below. 
 
627  2. Modularity implies biology and innateness: the language organ 
 
A consequence of the view that language is a module is its genetic determi-
nacy: recall that modules, among other things, have the property of being 
genetically endowed (§ 613). 
This is where Chomsky's biological conception of language ± known 
under the header of the language organ and more recently the biolinguistic 
programme (§§ 609, 639) ± comes from. On this view, the neural existence 
of the language module and the genetic endowment for its inception in the 
growth of young humans gives rise to an organ just like the liver, the heart 
or other parts of the human body that are specialised in some particular 
task: cleaning or pumping of blood etc. The only peculiarity of the lan-
guage organ, then, is to be localised in the brain, rather than elsewhere in 
the body.156 
156 In psycholinguistic quarters that were a priori Chomsky-friendly, the biological 
conception of language was anything but popular in the 80s: people refused 
even to think about an eventual neural correlate of cognitive functions. 
Dehaene et al. (2001) report on this pre-brain imaging period with the follow-

540 
Modularity Chap 5: Modularity of and in language, related systems 
In this perspective, linguistics is "that part of psychology that focuses 
its attention on one specific cognitive domain and one faculty of mind, the 
language faculty" (Chomsky 1980:4). Therefore, "we may regard the lan-
guage capacity virtually as we would a physical organ of the body and can 
investigate the principles of its organization, functioning, and development 
in the individual and in the species" (Chomsky 1980:185) (also e.g. Chom-
sky 1975:11: "the idea of regarding the growth of language as analogous to 
the development of a bodily organ is thus quite natural and plausible. It is 
fair to ask why the empiricist belief to the contrary has had such appeal to 
the modern temper"). The modern offspring of this genuinely generative 
tradition is Chomsky's biolinguistic program (e.g. Hauser et al. 2002, 
Chomsky 2005, on which more in § 639; see Jenkins 2000 for an overview). 
Together with UG, the language organ is probably the best-known 
property of generative grammar outside of its own quarters. It has become a 
buzz-word in popular scientific texts and neighbouring disciplines, fore-
most philosophy and psychology where its validity is challenged and pro-
vokes much discussion. This debate goes far beyond the scope of the pre-
sent book. Relevant literature from both sides includes Stich (1972), Katz 
(1984), Devitt & Sterelny (1989), Kasher (1991), Fodor (1981), Chomsky 
(2002); Wauquier (2005:175ff) provides an informed overview. 
 
ing quote from Jacques Mehler, which sums up Mehler et al. (1984): "For all I 
know, language perception might be going on in the brain. but my research 
would not be affected if it was found to be occurring in the left pinky." Dehaene 
et al. (2001) and the section on Brain and Biology of Dupoux (ed.) (2001) that 
they introduce then show how things have changed today. 
628  3. Grammar itself is made of modules: GB-subtheories and their 
(questionable) status as cognitive modules 
 
629  3.1. The inverted T is the baseline since the 60s 
 
If language is one piece of the modular architecture of mind, the question 
arises whether there is only one single computational unit that carries out 
all grammatical calculation, or whether there are several linguistic modules. 
In turn, if language is made of distinct computational systems, the question 
is how many linguistic modules there are, and how exactly they are deline-
ated. 
The early generative literature on language-internal modularity was 
already discussed in § 623: the bottom line that is condensed in Aspects 

Grammar itself is made of modules: are GB-subtheories cognitive modules? 541 
(Chomsky 1965:15ff) grants modular status in terms of a an independent 
and domain specific computational system to the three components of the 
inverted T model: morpho-syntax, phonology and semantics. These repre-
sent the core of "internal" linguistic activity and are related to non-
linguistic cognitive activity by at least a conceptual device (which matches 
real-world objects and concepts with linguistics items) and pragmatics. Or, 
in other words, the interplay of the three "internal" components is called 
grammar, while their exchange with grammar-external cognitive activity 
produces language (see Newmeyer 1986:172ff for a historical description 
and the state of the art in early GB). 
 
630  3.2. GB-subtheories are presented as modules, but insulated from the 
cognitive context 
 
Modularity was embodied in the inverted T, but as such not much of an 
issue until the 80s when the principles and parameters framework was in-
troduced. In his Pisa lectures, Chomsky (1981) divides syntax into six 
autonomous subsystems (bounding theory, government theory, theta theory, 
binding theory, case theory, control theory), which he refers to as modules. 
The modular structure of GB is the major innovation of the new theory. 
Surprisingly enough, though, Chomsky studies language-internal (or 
rather: syntax-internal) modularity in absence of any reference to the 
broader claim that the entire human cognitive system is modular in kind. 
This is to be appraised in the context of Fodor (1983), the major reference 
of the modular theory of mind that was in the making when Chomsky 
wrote, and also of the fact that Fodor's book grew out of lecture notes of a 
class on contemporary cognitive theory that Jerry Fodor co-taught with 
Noam Chomsky in fall 1980 (see the acknowledgements in Fodor 1983).  
While language plays an important role in Fodor (1983), the idea that 
the language faculty and/or its sub-components are just specific cases of 
cognitive modules that are embedded in a broader modular architecture is 
absent from Chomsky (1981). Chomsky does not mention the fact that 
modules, whether they compute grammatical or other functions, have a 
number of properties (domain specificity, encapsulation, dissociation) 
which allow us to delineate their contours. 
The result is not really in line with the history of generative grammar 
and Chomsky's personal contribution to Cognitive Science: when genera-
tive linguists think of grammar-internal modularity, what they typically 
have in mind is an exclusively linguistic horizon (more on that in § 636). 

542 
Modularity Chap 5: Modularity of and in language, related systems 
One may be inclined to believe that this is a good deal of the reason 
why (real cognitive) modularity has played virtually no role within genera-
tive grammar, even when it would have been decisive (while it has always 
been an argument for the definition of grammar as opposed to other cogni-
tive functions). I have come across two obvious cases where the absence of 
the modular argument is really surprising, looked at from the outside: inter-
actionism and direct syntax (see §§ 222,414 and the summary in § 36).  
 
631  3.3. Chomsky (1981): subcomponents (inverted T) vs. subsystems (theta 
theory etc.) 
 
In the first chapter of the Pisa lectures entitled "Outline of the theory of 
core grammar", Chomsky (1981) first exposes the classical position accord-
ing to which the three extremities of the inverted T are modules. 
 
(268) "The theory of UG must therefore specify the properties of (at least) three 
systems of representation - S-structure, PF, LF - and of three systems of 
rules: the rules of the syntactic component generating S-structures, the rules 
of the PF-component mapping S-structures to PF, and the rules of the LF-
component mapping S-structure to LF. Each expression of the language 
determined by the grammar is assigned representations at these three levels, 
among others." Chomsky (1981:4) 
 
He then introduces the distinction between subcomponents of the 
rule system of grammar, and subsystems of principles. The relevant quote is 
provided under  (269) below. Subcomponents are the members of the in-
verted T, i.e. the default candidates for modular status, while subsystems 
are the subtheories of GB, which the book sets out to present. Chomsky 
(1982:4ff) is analogous, the only noteworthy difference being the fact that 
X-bar theory is added to the six subsystems that are mentioned under  (269). 
The characterisation of morpho-syntax (and semantics) as a network 
of interacting sub-devices is the central innovation of GB, and this is why 
the focus of Chomsky (1981) of course is on these subsystems. They are 
the new perspective, and this is what the book is all about. Also, they exist 
within the old architecture of grammar, the inverted T, which remains un-
touched by the new perspective. 
 

Grammar itself is made of modules: are GB-subtheories cognitive modules? 543 
(269) "UG consists of interacting subsystems, which can be considered from 
various points of view. From one point of view, these are the various sub-
components of the rule system of grammar. From another point of view, 
which has become increasingly important in recent years, we can isolate 
subsystems of principles. I will assume that the subcomponents of the rule 
system are the following: 
 
(1) 
(i)  lexicon 
 
(ii)  syntax 
 
(a) categorial component 
 
(b) transformational component 
 
(iii) PF-component 
 
(iv) LF-component 
 
[«] 
The subsystems of principles include the following: 
 
(2) 
(i) bounding theory 
 
(ii) government theory 
 
(iii) T-theory 
 
(iv) binding theory 
 
(v) Case theory 
 
(vi) control theory" 
Chomsky (1981:5) 
632  3.4. Are GB-subsystems cognitive modules? 
 
In the quotes above, Chomsky does not use the word "module" in order to 
refer to GB-subtheories, which he calls subsystems. These are opposed to 
subcomponents, i.e. the three computational systems of the inverted T. The 
question is whether these GB-subtheories ought to be regarded as modules 
in the Fodorian cognitive sense. Implicit in the quote under  (269) is that 
they are not granted this status: subcomponents are distinct rule systems, 
while subsystems are only distinct sets of principles. A module, however, is 
defined as a computational system. Whether GB-subtheories are input-
output systems that carry out a computation is certainly debatable, but I 
was unable to find any relevant discussion in the literature, both contempo-
rary of the 80s and more recent overview-oriented (e.g. Lasnik & Lohndal 
2009, Freidin & Lasnik forth, Newmeyer 1986:198ff), precisely (one 
senses) because linguistics were (and still are to a certain extent) insulated 
from the cognitive macrostructure in linguistic quarters.  

544 
Modularity Chap 5: Modularity of and in language, related systems 
The question to be asked is thus whether GB-subtheories act as mere 
filters that define well-formedness, or whether they carry out actual compu-
tation, i.e. modify an input. It seems to me that well-formedness filters and 
computational systems are not the same thing, but the question certainly 
deserves to be debated.157 
Applying the other diagnostics for cognitive modules that are avail-
able appear to be inconclusive, at least from my point of view: GB-
subtheories could perhaps be argued to be informationally encapsulated, 
but again the fact that they referee well-formedness would seems to require 
that they intervene at different stages of the syntactic construction.  
Domain specificity is also debatable: at first sight it looks like syntax 
as a whole uses the same vocabulary: person, gender, number etc. But these 
are the lexical ingredients, i.e. the input to the syntactic module as defined 
by the inverted T. GB-subtheories apply during the syntactic derivation, and 
their input, if any, will not be made of lexical material. Hence it could be 
argued that the case theory module works only with a specific vocabulary 
that is dedicated to case, the government module only calculates locality 
and so forth. This view is taken by Hornstein (2009:7, note 13) and is also 
entertained by a modern heir of the GB architecture, Edwin Williams' 
(2003) Representation Theory. Williams explains that  
 
(270) "several different aspects of clausal structure are characterized as separate 
'sublanguages' (to anticipate: Theta Structure (TS), Case Structure (CS), 
Surface Structure (SS), Quantification Structure (QS), Focus Structure 
(FS). Then the syntax of a sentence will be a collection of structures, one 
[«] from each of these sub-languages and a set of shape-conserving map-
pings among them." Williams (2003:2) 
This perspective may be argued to face a problem because of its 
nested modular structure (see also the quote in § 636): it supposes that there 
is a "big" syntactic derivation (the syntactic module of the inverted T) 
which somehow accommodates "small" sub-modules (the GB-subtheories) 
that concur to the overall result. It appears that this can only work in viola-
tion of informational encapsulation of the "big" syntactic module: its com-
putation should be complete before any result can be sent to other 
(sub)modules. The same objection may be levelled against derivation by 
phase, though: morpho-syntactic computation sends partial results to PF 
and LF before it has reached its end, i.e. the matrix CP. This may be solved 
 
157 See Scheer (forth) on the computational question and how computation is con-
ceived of in phonology and syntax. 

Grammar itself is made of modules: are GB-subtheories cognitive modules? 545 
by considering that the "big" syntactic derivation is not performed by a 
module in one single go, but that the same module treats pieces of a sen-
tence in several computations. Again I am not aware of any discussion in 
the (linguistic) literature on the compatibility of multiple spell-out with 
encapsulation, but Williams will be able to hook on the argument that will 
be made by defenders of derivation by phase, whatever that will be: the 
situations are parallel. 
Finally, the diagnostic based on double dissociation is probably not 
workable for GB-subtheories since it will be difficult to come by relevant 
pathologies (the evidence available is discussed in § 642 below). 
 
633  3.5. Biolinguistics: an evolutionary argument against language-internal 
modularity (Hornstein 2009) 
 
Biolinguistics looks at language from the biological and evolutionary per-
spective and thereby continues the earlier strand of Chomsky's language 
organ (§§ 609, 627, 633). Based on Hauser, Chomsky & Fitch (2002), the 
idea is that the appearance of language in the evolution of the species sets a 
restrictive frame that imposes certain properties upon grammar. Contrary to 
earlier generative thinking where much of what was found to be universal 
was put into UG, i.e. held to be genetically endowed and specific to lan-
guage, UG is by and large emptied.  
Chomsky (2005) identifies three factors in language design: 1) UG 
(i.e. genetically endowed properties that are specific to language), 2) ex-
perience and 3) more general cognitive capacities that are not specific to 
language or even to the species. The shift, then, is from UG to the third 
factor: language relies on mechanisms that are much less specific to lan-
guage than what was believed in earlier generative theories. Hauser et al. 
(2002) suggest that UG could actually reduce to recursion (Merge) and the 
ability to communicate with the interfaces (Phase): this is the Faculty of 
Language in the Narrow sense (FLN) (Pinker & Jackendoff 2005a,b oppose 
this view, see § 609). 
On this backdrop, Hornstein (2009:4ff) levels an objection against 
language-internal modularity that is based on evolutionary timelines. As 
was mentioned, Hornstein (2009:7, note 13) believes that GB-subtheories 
do qualify for modular status. The Language Faculty as such, however, he 
argues, must not be cut into further subsystems because modular complex-
ity implies genetic endowment and a relatively slow adaptational evolution 
along the Darwinian lines of environment-driven selection. The appearance 

546 
Modularity Chap 5: Modularity of and in language, related systems 
of language, however, was much too rapid in order to fit into an adaptive 
scenario. 
 
(271) "A common assumption is that language arose in humans in roughly the last 
50,000 - 100,000 years. This is very rapid in evolutionary terms. It suggests 
the following picture: FL [Faculty of Language] is the product of (at most) 
one (or two) evolutionary innovations which, when combined with the cog-
nitive resources available before the changes that led to language, delivers 
FL. This picture, in turn, prompts the following research program: to de-
scribe the pre-linguistic cognitive structures that yield UG's distinctive 
properties when combined with the one (or two) specifically linguistic fea-
tures of FL. The next three chapters try to outline a version of this general 
conception. 
The approach, I believe, commits hostages to a specific conception of FL. It 
does not have a high degree of internal modularity. The reason for this is 
that modular theories of UG suppose that FL is intricately structured. It has 
many distinct components that interact in complex ways. On the assumption 
that complexity requires natural selection and that natural selection requires 
time to work its magic (and lots of it: say on the order of (at least) millions 
of years), the rapid rise of language in humans does not allow for this kind 
of complexity to develop. This suggests that the highly modular structure of 
GB style theories should be reconsidered." Hornstein (2009:4f, emphasis in 
original) 
 
Hence we are back to the debate exposed in § 606 between the two 
camps within the modular approach: following Descartes, Chomsky and 
Fodor hold that some properties of the cognitive system (Fodor's central 
systems) lie beyond what can be understood by human intelligence and will 
always remain an impenetrable mystery; by contrast, evolutionary psychol-
ogy (Pinker, Plotkin, also Sperber and Smith) believe that all of the mind is 
modular and accessible to human understanding. A correlate of these con-
trasting positions is the Darwinian issue: in Fodor's and Chomsky's per-
spective, central systems are not the result of adaptive evolution along the 
laws of natural selection, while Pinker & Co hold that all properties of the 
mind/brain are modular and hence the result of adaptive evolution.  
Hornstein's argument thus supports the Fodorian/Chomskian view, 
and it is interesting to observe that Hornstein (2009:5, note 9) calls on lit-
erature from evolutionary psychology (Pinker 1997, Cosmides & Tooby 
1992a) in order to back his critical assumption that complexity requires 
natural selection. His alternative, i.e. the emergence of the Language Fac-
ulty as a (by-)product of one or two evolutionary innovations based on pre-

GB modules and their perception in non-linguistic quarters 547 
human cognitive capacities, is the basic idea of Hauser et al. (2002) and the 
biolinguistic programme.  
In this view, the FLN is not a product of selective adaptation, while 
the FLB (the Faculty of Language in the Broad sense) is shared with ani-
mals and results from natural selection. 
Finally, it should be added that the entire discussion is only about 
(morpho-)syntax: in the biolinguistic perspective, phonology and semantics 
belong to the animal-based FLB and hence do not really belong to gram-
mar, i.e. to what is language-specific in the human cognitive system. PF 
and LF are thus supposed to have been present before the one or two inno-
vations that produced Merge and Phase, and therefore to be available to and 
mastered (or masterable) by (certain) present-day animals (more on this in 
§639). 
This also explains why Hornstein in his discussion of what exactly 
counts as a module does not even mention the classical inverted T: his bio-
linguistically shaped horizon ends before PF and LF are in sight. The con-
clusion that one draws is that the inverted T still exists and that the three 
endpoints are still Fodorian modules ± only are PF and LF not located in 
grammar anymore. 
 
634  4. GB modules and their perception in non-linguistic quarters 
 
635  4.1. Chomsky (1981) calls GB-subtheories modules without comment 
 
It was mentioned in § 631 that at the outset of the Pisa lectures Chomsky 
(1981) distinguishes between subcomponents (the endpoints of the inverted 
T) and subsystems (GB-subtheories). Later in the book, however, he gives 
up on this distinction and systematically talks about modules when refer-
ring to the six GB-subtheories (also Chomsky 1982:29). 
 
(272) "The full range of properties of some construction may often result from 
interaction of several components, its apparent complexity reducible to 
simple principles of separate subsystems. This modular character of gram-
mar will be repeatedly illustrated as we proceed." Chomsky (1981:7) 
 
"Note that the distribution of the empty categories, the differences among 
them and their similarities to and differences from overt elements are deter-
mined through the interaction of quite simple principles that belong to sev-
eral different subtheories, in accordance with the modular approach to 
grammar that we are pursuing throughout." Chomsky (1981:72) 

548 
Modularity Chap 5: Modularity of and in language, related systems 
 
"This dissociation of properties is what we would expect on our modular 
assumptions - that is, on the assumption that such processes as 'passive' are 
composed of more fundamental abstract features, such as the elements of 
Case theory, T-theory, etc." Chomsky (1981:126) 
 
"Note that the full range of properties of PRO and trace discussed in §2.4, as 
well as the partially similar properties of overt anaphors, are determined by 
the interaction of four theories: the theory of bounding (for trace), the theory 
of control (for PRO), the theory of Case (for elements with phonetic content, 
including overt anaphors), and the theory of binding (for all NPs). The latter 
two theories are developed within the theory of government. Again, we see 
the highly modular character of the theory of grammar, with the basic sub-
systems of principles discussed in chapter 1 serving as quite simple and 
fundamental abstract components that interact to yield a complex range of 
properties." Chomsky (1981:192) 
 
After having introduced each individual GB-subtheory in chapter 2 
(which is called "Subsystems of core grammar"), the conclusion of this 
chapter confirms the modular character of GB-subtheories. 
 
(273) "The system that is emerging is highly modular, in the sense that the full 
complexity of observed phenomena is traced to the interaction of partially 
independent subtheories" Chomsky (1981:135) 
 
Finally, the modular interpretation of GB-subtheories is also repeated 
on the last page of the book: "[t]he system that has been developed is 
highly modular" (Chomsky 1981:344). 
All this is done without mention or discussion of the Cognitive Sci-
ence background, and without indicating whether the GB modules are con-
sidered to be cognitive modules. As we will see below, the discussion of the 
previous section has never been led, and everybody ± in generative quarters 
and elsewhere ± takes for granted that GB modules are cognitive modules 
in the Fodorian sense because Chomsky has used this word. 
636  4.2. Perception of GB-modules in non-linguistic quarters: puzzlement 
 
While in generative quarters the word module was continued to be used 
without any particular reference to the broader organization of the cognitive 
system, observers from other fields, and especially from Cognitive Science 
of course, took for granted that the modules of the linguists are cognitive 
modules in the Fodorian sense. This led to some puzzlement and confusion. 

GB modules and their perception in non-linguistic quarters 549 
In the introduction to the volume on domain specificity of cognitive 
functions ("toward a topography of mind"), that they edit, Hirschfeld & 
Gelman (1994) talk about the situation in GB from the position of the ex-
ternal observer. 
 
(274) "Chomsky and other maintain that these findings provide compelling evi-
dence for the claim that the mind is modular, comprising a number of dis-
tinct (though interacting) systems (the language faculty, the visual system, a 
module for face recognition), each of which is characterized by its own 
structural principles. [«] 
Chomsky, however, has also suggested that the mind is modular in a some-
what different way. [«] This, in other more technical writings, Chomsky 
has described 'modules of grammar' (e.g., the lexicon, syntax, bounding 
theory, government theory, case theory, etc.) (1988:135). Here the notion of 
modularity appears to be tied to specific subcomponents or subsystems of 
the language faculty rather than to the modular uniqueness of the language 
faculty itself. The grammar, in the traditional sense, is located at the inter-
section of these distinct modules. 
It is not clear whether these two notions of modularity are to be distin-
guished, and if so how to interpret the relationship between them. One pos-
sibility is that modules are nested, that is, the language faculty is a separate 
module that in turn consists of distinct component operations or modules. 
Another interpretation ± supported indirectly by the fact that Chomsky 
speaks of the language faculty as a module to nonlinguists but speaks of the 
language faculty as consisting of modules to linguists ± is that the mind is, 
strictly speaking, modular with respect only to these second-level compo-
nent modules. The language faculty itself would accordingly be a more 
vaguely defined construct resulting from the operation of these modules, but 
one that in itself is not modular in the sense of being defined in terms of a 
distinct set of principles." Hirschfeld & Gelman (1994:8, emphasis iin origi-
nal) 
Looked at from the inside, Hermon (1985) is a typical representative 
of the approach to modularity that was (and is) widespread in generative 
quarters. Hermon's goal is to demonstrate that the interplay of the subtheo-
ries of the newly established GB theory are well suited to account for pa-
rametric variation, and this is the only reason why the book is called Syn-
tactic Modularity. There is no reference to any extra-linguistic work regard-
ing modularity (Fodor 1983 is absent from the reference section), and the 
reader does not learn anything about cognitive modules, how they work, 
how they are defined, detected etc. Similar cases are Farmer (1984) and 
Nespor & Vogel (1986) (see § 428). 
 

550 
Modularity Chap 5: Modularity of and in language, related systems 
637  5. Minimalism and biolinguistics do away with GB modules 
 
638  5.1. Minimalism: GB-subtheories have to go 
 
In their textbook on minimalism, Hornstein et al. (2005:11ff) evaluate the 
validity of GB-subtheories in the light of minimalist requirements and, 
following the GB-tradition, refer to them as modules. The items of the in-
verted T, i.e. morpho-syntax, phonology and semantics, are called levels 
(Hornstein et al. 2005:9 and elsewhere). The word "modularity", however, 
only appears when language as a whole is considered in the concert of other 
cognitive functions (Hornstein et al. 2005:3, note 2). 
A core goal of the minimalist programme is to reduce the GB-
subtheory zoo to what is strictly required for conceptual reasons and by 
interface conditions. Grammar is perfect unless deviated from perfection by 
interface requirements: minimalist design produces "a theory of language 
that takes a linguistic expression to be nothing other than a formal object 
that satisfies the interface conditions in the optimal way" (Chomsky 
1995a:171). In this minimalist frame, Hornstein's (2009) argument against 
GB-modules that is based on the third-factor perspective of biolinguistics 
was already discussed in § 633. 
This does not mean, however, that the insight of GB is wrong: Horn-
stein (2009:6) believes that the generalisations made by GB are "roughly 
empirically correct". However, they are in need of further interpretation: 
minimalist work in general and his book in particular is about how to have 
the labour of GB-subtheories done by different, non-modular means, and to 
derive the empirical generalisations of GB by more general principles; 
these are ideally of the third factor kind, i.e. unspecific to language.  
 
639  5.2. Grammar reduces to morpho-syntax: PF and LF are neither language- 
nor species-specific 
 
It was already mentioned in § 633 that interestingly enough, PF and LF are 
not even mentioned when Hornstein (2009) and others talk about the fac-
ulty of language in a biolinguistic perspective. This is because according to 
Hauser et al. (2002), PF and LF do not belong to the FLN (Faculty of Lan-
guage in the Narrow sense). Rather, they are a piece of the FLB (Faculty of 
Language in the Broad sense), which humans share with (certain) animals. 
Unlike the FLN which did not have enough time to emerge by Darwinian 
means, the FLB came into being through adaptive evolution that occurred 

Identifying linguistic modules 551 
under selective pressure during the common evolution of certain animals 
and the ancestors of homo sapiens long before the critical hardware-
modification occurred that made emerge FLN.  
Filling in this scenario on the phonological side, Samuels (2009a,b) 
tries to show that phonology is entirely a third factor mechanism, i.e. that 
there is nothing language- or species-specific to human phonology: (cer-
tain) animals are perfectly equipped to do human phonology. 
In sum, language reduces to morpho-syntax, which is made of one 
single Fodorian module, i.e. morpho-syntax. This perspective reassesses the 
delineation of grammar (phonology and semantics stand aside), and hence 
makes the inverted T appear in a different light. The new limits of gram-
mar, however, do not change anything in the relationship between the three 
actors of the inverted T: PF and LF may not be specifically linguistic mod-
ules anymore, but they are still modules. Therefore whatever the relation-
ship of morpho-syntax with them, it must follow the general rules of inter-
modular communication: the way morpho-syntax talks to PF and LF is not 
any different from the way it talks to other cognitive modules such as audi-
tion or vision. 
 
640  6. Identifying linguistic modules 
 
641  6.1. How to identify grammar-internal modules 
 
Given the GB-interlude and the minimalist and eventually biolinguistic 
perspective, one may say that generative grammar is back to where it 
started in the 60s: we are left with the inverted T. That is, there are three 
relevant modules, morpho-syntax, PF and LF, of which the latter two lie 
outside of grammar if one wants to follow biolinguistics. At least two more 
systems are relevant and interact with these: pragmatics and a conceptual 
device. 
Below evidence is gathered that allows us to evaluate this working 
hypothesis. Methods for identifying cognitive modules are as before, one 
internal (domain specificity, §§ 610f), the other external (double dissocia-
tion, § 618). As far as I can see, there is only little evidence available from 
the latter source, which will be reviewed in the following section. The lit-
erature that builds on domain specificity in order to tease apart the number 
and nature of language-relevant modules is not substantial either.  
 

552 
Modularity Chap 5: Modularity of and in language, related systems 
642  6.2. Dissociation: Pragmatics, Lexicon vs. morpho-syntax 
 
Dissociation arguments come either from stable synchronic states where 
cognitive functions are selectively impaired (i.e. from subjects with cogni-
tive and/or brain damage), or from acquisition, where different cognitive 
functions are dissociated in their development (see § 620). When zooming 
into grammar (understood as including phonology and semantics) from the 
larger perspective of cognitive functions, the most coarse-grained differen-
tiation is between the two standardly assumed peripheral systems that relate 
grammar to other functions, and grammar itself. The two systems in ques-
tion are pragmatics and a conceptual device.  
Evidence for the independence of the pragmatic and the grammatical 
systems was already discussed in § 621: Christopher, the savant studied by 
Smith & Tsimpli (1991 et passim), appears to be unable to make pragmatic 
pressure (to produce a sound translation) influence his linguistic perform-
ance. Also, Chien & Wexler (1990) provide evidence from acquisition for 
the dissociation of binding (a grammatical principle) and pragmatics. 
In an early study on the dissociation of language-related cognitive 
functions based on pathological data, Curtiss (1981) concludes that while 
morpho-syntax is insulated from other cognitive functions, the develop-
ment of lexical and relational semantic knowledge hinges on broader con-
ceptual abilities. 
 
(275) "[D]ata from case studies of children show [«] clear dissociations between 
language and nonlanguage cognitive abilities. The implications of such data 
are discussed. The major implications appear to be that lexical and relational 
semantic abilities are deeply linked to broader conceptual development but 
morphological and syntactic abilities are not. The development of a normal 
linguistic system, however, one in which grammar is systematically related 
to meaning, requires concurrent and concomitant linguistic and nonlinguis-
tic cognitive development." Curtiss (1981:15) 
 
Finally, Newmeyer (2006:241f) proposes a kind of double dissocia-
tion argument without recurring to cognitive and/or brain damage. In order 
to show that syntax and semantics are independent computational systems, 
he demonstrates that a particular syntactic structure does not select for se-
mantic values, and conversely that a particular semantic or discourse-based 
construct may map onto various syntactic structures. 
Newmeyer (2006) thus defends a strict modular segregation of syn-
tax and semantics. He shows that the seeds of blurred modular contours 
between these two items of the inverted T were sown by Chomsky (1981), 

Identifying linguistic modules 553 
who introduced the idea that thematic roles are directly relevant for the 
statement of syntactic generalisations. Since then and especially in the 
minimalist environment, the bonds between syntactic position and semantic 
interpretation have been strengthened. On this backdrop, Newmeyer (2006) 
proposes evidence from an analysis of English negation that militates 
against a conflation of syntactic and semantic features. 
Higginbotham (1987) also argues for the autonomy of syntax and 
semantics in a modular perspective, which is tightly correlated to the read-
ing of Fodor (1983). He reviews the classical linguistics-internal arguments 
that Chomsky has made since the 50s in order to establish the mutual inde-
pendence of syntax and semantics. 
The following section discusses the reverse attitude, i.e. which vali-
dates the convergence of syntax and semantics on the grounds of domain 
specificity. 
 
643  6.3. Domain specificity (Starke): morpho-syntax-semantics vs. phonology 
 
In unpublished work,158 Michal Starke argues that morphology, syntax and 
semantics are just one module because they use the same vocabulary: num-
ber, person, animacy, quantification, aspect and so forth are categories that 
are used, understood and processed by syntax as much as by morphology 
and semantics.159 Much unlike phonology, where number, person and the 
like are unknown: phonology does not use or process these categories. 
Conversely, morphology, syntax or semantics neither process or are sensi-
tive to genuinely phonological concepts such as labiality, stopness and the 
like. 
On Starke's count, then, phonology (as much as pragmatics and the 
conceptual device) works with specific vocabulary and is thus a module 
distinct from morpho-syntax-semantics. Discussing the detail of the evi-
dence that Starke relies on would lead too far afield here (a published ver-
sion will hopefully be available at some point). Let us merely note the 
structure of his argument, which is along the lines of domain specificity. 
 
158 Starke's work has been presented at various conferences and at the Central 
European Summer School in Generative Grammar (EGG) in 2002 (Novi Sad) 
and 2006 (Olomouc). 
159 Of course semantics is to be understood as "grammatical" semantics, i.e. the 
system that assigns an interpretation to morpho-syntactic structure. The mean-
ing of lexical items and the relation with the conceptual world are entirely dif-
ferent issues. 

554 
Modularity Chap 5: Modularity of and in language, related systems 
The result is a broad distinction of two macro-modules, phonology and 
morpho-syntax-semantics, which are supplemented by (at least) two mod-
ules that mediate between grammar and other cognitive functions (pragmat-
ics and the conceptual device). 
 
644  6.4. Domain specificity (Jackendoff, Chomsky): phonology is distinct 
 
Jackendoff's (1987, 1992, 1997) modular theory, Representational Modu-
larity (which Jakendoff 2002:218ff prefers to call Structure-Constrained 
Modularity today), also points out the obvious ontological gap between 
phonology and other linguistic devices, which is greater than the distance 
between any other two linguistic candidate disciplines. 
 
(276) "The overall idea is that the mind/brain encodes information in some finite 
number of distinct representational formats or 'languages of the mind.' Each 
of these 'languages' is a formal system with its own proprietary set of primi-
tives and principles of combination, so that it defines an infinite set of ex-
pressions along familiar generative lines. For each of these formats, there is 
a module of mind/brain responsible for it. For example, phonological struc-
ture and syntactic structure are distinct representational formats, with dis-
tinct and only partly commensurate primitives and principles of combina-
tion. Representational Modularity therefore posits that the architecture of the 
mind/brain devotes separate modules to these two encodings. Each of these 
modules is domain specific. 
[«] The generative grammar for each 'language of the mind,' then, is a 
formal description of the repertoire of structures available to the correspond-
ing representational module." Jackendoff (1997:41) 
 
Chomsky (2000a) makes the same point. 
 
(277) "The phonological component is generally assumed to be isolated in even 
stronger respects: there are true phonological features that are visible only to 
the phonological component and form a separate subsystem of FL [the Fac-
ulty of Language], with its own special properties." Chomsky (2000a:118,
emphasis in original) 
 
Domain specificity within grammar thus identifies what appears to 
be the deepest fraction line, which separates phonology on the one hand 
and all other classical disciplines (syntax, morphology and semantics) on 
the other. 

Identifying linguistic modules 555 
Jackendoff ends up with three modules that are involved in the man-
agement of grammar: phonology, syntax and the conceptual device. He 
calls modules processors and distinguishes between integrative and inter-
face processors (see Vol.2). The latter translate the output of the former into 
vocabulary items that can be understood by other "true" modules, i.e. pho-
nology, syntax and the conceptual device in our case. Intermodular com-
munication is discussed in § 649 below (and at greater length in Vol.2). 
 
645  6.5. Phonology-free syntax 
 
That phonology is ontologically distinct also shines through more familiar 
linguistic work that does not think in modular categories or look at domain 
specificity: the distinctness of phonology is the core message of phonology-
free syntax, which was discussed in § 412 (also § 253). 
In Zwicky & Pullum's (1986a,b) strong original version, phonology-
free syntax holds that syntax and morphology are deaf for any phonological 
information: there is no morpho-syntactic process that has a phonological 
conditioning. For example, there is no syntactic movement on record that is 
triggered only if, say, the candidate begins with a labial. 
A weaker version (see § 412) distinguishes between melody (i.e. pho-
nological objects located below the skeleton) on the one hand and syllabic 
as well as prosodic properties on the other (e.g. supra-skeletal structure). 
The inability of melody to bear on morpho-syntax appears to be a correct 
generalisation, while syllabic and prosodic properties such as intonation, 
minimal word constraints and other counting operations are found to condi-
tion morphological and syntactic processes. 
The fact that the weaker version is probably correct is actually more 
interesting from the modular perspective: it means that the basic phono-
logical vocabulary is unintelligible for morpho-syntax, but that projections 
thereof may be perceived. Which thus nicely confirms that domain specific-
ity is about vocabulary, rather than about the output of a computation that is 
based on this vocabulary (§ 651 elaborates on this). 
 
646  6.6. Late Insertion is the segregation of phonological and other vocabulary 
 
The ontological separation between phonology and morpho-syntax is also 
central in Distributed Morphology: while up to GB morpho-syntactic com-
putation was done on the basis of complete lexical information that in-

556 
Modularity Chap 5: Modularity of and in language, related systems 
cluded syntactic, morphological and semantic features as much as phono-
logical material (sealed suitcases), Late Insertion is the idea that phonologi-
cal material is absent from morpho-syntactic computation (see § 536). Only 
morpho-syntactic information is available at the beginning of a derivation; 
phonological material (vocabulary items) is only inserted after the comple-
tion of the morpho-syntactic derivation. 
 
647  6.7. Phonology vs. phonetics 
 
Although this book does not consider the relationship of phonology with 
phonetics, i.e. the (eventual) lower limit of phonology, it is worth pointing 
out that domain specificity is also used in the large body of literature that 
debates this issue in order to insulate both areas: this is what Hale & Reiss 
(2008:118) do. Kingston (2007) provides a good overview of the positions 
that are taken, and especially of the debate whether phonology and phonet-
ics are distinct modules or instances of the same computational system. 
 
648  7. Encapsulation is called inclusiveness in syntax 
 
Informational encapsulation is a core property of modules (§ 610): modules 
produce an output on the grounds of a domain specific input, and there can 
be no communication with anything beyond the module (i.e. possible 
sources of additional information) during the computation. 
It is worthwhile to be mention that Chomsky's (1995a:228) inclu-
siveness is the syntactic formulation of encapsulation: syntactic structure 
must be exclusively based on information that is present in the input; no 
element may be added in the course of a syntactic derivation. 

Chapter 6 
649  How modules communicate 
 
650  1. Intermodular communication requires translation 
 
Let us now turn to intermodular communication. A direct consequence of 
the fact that different modules speak different languages (of the mind) is 
their inability to understand each other. Modules can only parse objects that 
belong to their own language, i.e. which are part of the domain specific 
vocabulary that they are designed to process. This is what Jackendoff ex-
plains in the quote below. 
 
(278) "'Mixed' representation[s] should be impossible. Rather, phonological, syn-
tactic and conceptual representations should be strictly segregated, but coor-
dinated through correspondence rules that constitute the interfaces."
Jackendoff (1997:87ff) 
 
Applied to the phonological module, this means that phonology 
could not react on any untranslated input from the morpho-syntactic mod-
ule. This is precisely the principle of Indirect Reference that was introduced 
by Prosodic Phonology (see §§ 377, 406): phonology can only take into ac-
count morpho-syntactic information that was previously translated into 
phonological vocabulary. The whole architecture of Prosodic Phonology is 
shaped according to Indirect Reference: a Translator's Office mediates be-
tween morpho-syntax and phonology. That is, the morpho-syntactic output 
is mapped onto prosodic constituency, which is the input to phonology. 
The basic idea of intermodular communication that materialises in 
the architecture of Prosodic Phonology is thus the following: in order for 
two modules to talk to each other, there must be a mediating instance which 
understands the vocabulary of both the input and the output module and 
translates information from one into the other. Untranslated information is 
noise and will be ignored by the receiving module. 
The idea that morpho-syntactic information must be translated before 
phonology can use it has always been present in phonological theory since 
the 19th century. A summary of how translation was practised since struc-
turalist times is provided in § 692 below. 
 

558 
Modularity Chap 6: How modules communicate 
651  2. Translation of what? 
 
652  2.1. Modular computation: vocabulary (input) vs. structure (output) 
 
When talking about modules, an important distinction is between vocabu-
lary (content) and structure. The structure of a module is the result of its 
computation: based on an input that is made of domain specific vocabulary, 
computation builds structure. In syntax for instance, the morpho-syntactic 
tree is the projection of morpho-syntactic features; in phonology, syllable 
structure is the projection of segmental properties. 
While vocabulary is necessarily domain specific, structure does not 
have to be. That is, different modules may produce the same type of struc-
ture, i.e. which has identical properties (one important aspect of which is 
hierarchical organisation). This means that structure is predestined for be-
ing shipped to other modules at the end of a computation: in case both vo-
cabulary items (terminals) and structure are shipped off, the receiving mod-
ule will be unable to make sense of the former, but may be able to interpret 
the latter, which is domain-unspecific. 
This is a somewhat tentative hypothesis that depends a lot on how in-
termodular translation actually works. Closer inspection of this issue is 
only provided in Vol.2. In anticipation of the discussion, the regular view is 
that translation is done by a specialised translation module, i.e. by some 
computation (the Translator's Office in Prosodic Phonology, Jackendoff's 
interface processors). An alternative is translation through a lexical access: 
like in a dictionary, each item of the input vocabulary is matched with an 
item of the output vocabulary. That is, translation does not involve any 
computation (this is what Michal Starke argues for). 
 
653  2.2. Is structure, but not vocabulary, translated? 
 
In principle, translation could translate vocabulary items and structure 
alike. There is some indication, though, that modules may be sensitive to 
structure, but not to vocabulary. This empirical generalisation was already 
mentioned in § 398: there is at least a strong trend for phonology to be sen-
sitive to morpho-syntactic structure, i.e. geometric properties of the tree, 
while node labels are by and large ignored. 
The same is true in the opposite direction: phonology-free syntax 
(see § 645, originally discussed in § 412) is in fact melody-free syntax: the 
basic vocabulary items of phonology are the objects that occur below the 

Translation is selective, and the choice of translated pieces is arbitrary 559 
skeleton, i.e. melodic primes such as labiality, stopness and so on. On the 
other hand, syllable structure and other properties of supra-skeletal phono-
logical representations are the result of phonological computation that is 
based on this basic vocabulary. 
If it is true that structure may be translated, while vocabulary remains 
untranslated, melody is predicted to be unable to bear on morpho-syntax ±
and this is indeed what we observe. By contrast, supra-skeletal phonologi-
cal structure may be read by other modules. This is indeed the result pro-
duced by the literature that set out to challenge phonology-free syntax: all 
cases where phonology influences morpho-syntax appear to concern pho-
nological properties that are located above the skeleton (§ 412, see also 
§662). 
While the empirical situation is unambiguous in the direction from 
phonology to syntax (cases where morpho-syntax reacts on labiality or the 
like are not on record), it is not exactly clear-cut in the opposite direction: 
cases such as the well-known stress-determining difference between nouns 
and verbs in English (récord vs. recórd etc.) stand in the way. Category-
sensitive phonology is further discussed in § 752. 
Finally, vocabulary may not only be excluded as an input to transla-
tion ± maybe it does not qualify as its output either. This is suggested by the 
discussion in § 661 below: melody (i.e. phonological vocabulary) is not 
only invisible for morpho-syntax ± it is also unheard of as a carrier of mor-
pho-syntactic information in phonology. In sum, then, vocabulary would be 
excluded from translation altogether: only structure qualifies as its input 
and output. 
 
654  3. Translation is selective, and the choice of translated pieces is 
arbitrary 
 
Another pervasive property of intermodular communication appears to be 
the fact that translation is never complete. That is, only a subset of the 
structure of the sending module is made available to the receiving module 
through translation. Also, it appears that the pieces which are chosen for 
transmission cannot be predicted. 
Ray Jackendoff's work regularly draws attention to the underfeeding 
of the receiving module. 
 

560 
Modularity Chap 6: How modules communicate 
(279) "Correspondence rules perform complex negotiations between two partly 
incompatible spaces of distinctions, in which only certain parts of each are 
'visible' to the other." Jackendoff (1997:221) 
 
"The overall architecture of grammar consists of a collection of generative 
components G1, «, Gn that create/ license structures S1, «, Sn, plus a set of 
interfaces Ijk that constrain the relation between structures of type Sj and 
structures of type Sk. [«] Typically, an interface Ijk does not 'see' all of 
either Sj or Sk; it attends only to certain aspects of them." Jackendoff 
(2002:123) 
 
The fractional character of translation in intermodular communica-
tion is further discussed in Vol.2, where illustration from various cognitive 
functions is provided. 
 
655  4. Outlook: intermodular translation is the focus of Vol.2 
 
How exactly the respective translating mechanisms work has received little 
or no attention at first: the distribution of juncture phonemes was stated in 
prose (if anything), and SPE had a universal algorithm that distributed 
hashmarks according to hierarchical morpho-syntactic structure (§ 90). Pro-
sodic Phonology paid much more attention to the labour that translation 
requires, which was done by a special kind of rules, i.e. mapping rules 
(§ 388). In OT, mapping is constraint-based (instead of rule-based, § 457), 
and in Jackendoff's (1997 et passim) general landscape, modules communi-
cate by means of so-called correspondence rules, which in his more recent 
work appear as Interface Processors (see Vol.2). 
Of course, translation only concerns the representational aspect of 
the interface: cyclic chunk-submission runs independently. The genuine 
contribution of Vol.2 to the interface discussion lies on the representational 
side. Two issues are examined in detail. On the one hand, the question is 
asked whether it is reasonable (or even workable) to have two distinct 
means of piecing together phonological material (representational objects) 
that serves as the input to the phonological module: vocabulary (lexical) 
insertion on the one hand (which concerns morphemic information, origin: 
the lexicon), and "added" non-morphemic information that comes in 
through translation (juncture phonemes, boundaries, prosodic constituency, 
origin: output of the Translator's Office). It will be argued that the answer is 
no: this is not reasonable. All phonological material that phonological com-

Outlook: intermodular translation is the focus of Vol.2 561 
putation uses originates in the lexicon (One Channel Translation, an idea of 
Michal Starke). 
On the other hand, the diacritic issue is examined. In the history of 
post-war phonology, the output of translation have always been the units of 
the current theory: juncture phonemes in structuralist times, ([-segment]) 
segments in SPE, prosodic constituency in the autosegmental 80s. The 
trouble is that all of these are diacritics: a juncture phoneme is obviously 
not a phoneme, a boundary is evidently not a segment, and prosodic con-
stituency, unlike all other tree structure (in phonology as much as in mor-
pho-syntax) is a projection of nothing, i.e. not a bottom-up construction 
(more on this in § 715). Direct Interface (Scheer 2008a, 2009a,c, to be in-
troduced at greater length in Vol.2) holds that the output of translation must 
be genuinely phonological objects, that is items which belong to the vo-
cabulary that the phonological module works with, and which exists inde-
pendently of any interface issue (i.e. of extra-phonological factors). 
 


Part II 
Lessons from interface theories 
 
Chapter 1 
656  A guide to the interface jungle 
 
The following pages take stock of the historical survey of Part I, as well as 
of the Interlude. The goal is to filter out important issues and ideas that are 
relevant beyond the theoretical context in which they were produced, and 
whose impact is constant over time as theories come and go. The result 
ought to provide a thematic access to interface questions, something like a 
blown-up index: the reader can look up this or that issue, follow this or that 
idea, and will be directed to all relevant discussion that was provided in 
Part I (and in the Interlude) under the header of a particular theory and a 
specific period.  
Interestingly, it will turn out that the relevant headers of chapters and 
sections are typically not the ones that one comes across in the literature: 
the distilling process of the historical mill produces focal points of interest 
that are not usually used in order to talk about the interface. Examples are 
inside-out interpretation (i.e. cyclic derivation), selective spell-out, local vs. 
non-local representational intervention in phonology, privativity and the 
word-spell-out mystery, to mention just a few (see also § 843). 
Given this pool of issues, ideas and questions, our guide through the 
interface jungle is organised along the following coordinate system: the 
basic distinction between representational and procedural aspects of the 
interface that is constant in this book on the one hand, the classification of 
questions according to whether they are settled or open (that is, whether or 
not they still discriminate among present-day theories) on the other.  
Hence there is a chapter on issues that are settled (on both procedural 
and representational sides: chapter 3), a chapter on open questions regard-
ing procedural issues (chapter 6), a chapter on open questions that are not 
specifically related to either procedural or representational questions (chap-
ter 5), and finally a chapter on open questions on the representational side 
(chapter 4). This chapter has ended up not being called like that because the 
three issues that it is made of ± translation, the diacritic issue and the 
(non-)locality of intervention ± are settled in verb, but (unfortunately) not 

564 
Chap 1: A guide to the interface jungle 
in fact, let alone in current practice. This general structure is completed by 
a chapter on empirical (i.e. pre-theoretical) generalisations (chapter 2), 
which is what we start out with below. 
 
The purpose of Part II is certainly to provide a structured and the-
matic access to issues, ideas and solutions that roughly 70 years of interface 
thinking have produced. As was mentioned in the introduction to the book, 
however, this is but a means to an end: what Part II is really after is to allow 
the reader to learn from the history of the interface; in the best case, the 
synopsis will teach us how we may, should or must not go about the inter-
face in further theory design: the vanishing point is a correct interface the-
ory. 
Like the rest of the book, the following pages are thus written in the 
interest of the future, rather than as a guide through the past: which errors 
have been made that we may want to avoid? Which principles emerge that 
must not be played fast and loose with? Have theories really stood up to the 
standards that they were advertising? 
Finally, it is worth cautioning that the narrative attitude which has 
prevailed thus far will stand back behind a less neutral prose: rather than 
merely reporting on what this and that theory says, proposals, attitudes and 
mechanisms are evaluated. As we go along, two measures will be used that 
build on grounds which lie beyond classical phonology-based reasoning: 
modularity and what I call intermodular argumentation. Both referee com-
peting phonological theories on the grounds of extra-phonological systems: 
syntactic evidence is brought to bear in the latter, properties of cognitive 
computation and architecture in the former case. 
 

Chapter 2 
657  Empirical generalisations 
 
658  1. Introduction 
 
This chapter lists empirical generalisations regarding the interface of mor-
pho-syntax and phonology that appear to hold independently of particular 
theoretical orientations. They are thus different from issues that are consen-
sual today (but eventually were not in the past) and involve a specific view 
on how the interface works. Inside-out interpretation (§ 672) or the need for 
translation (§ 692) for example fall into this category. 
Relevant empirical generalisations may or may not be discussed in 
the literature (and hence in Part I), and they may or may not be identified as 
such. Those that the reader has already come across are treated in the fol-
lowing chapter on issues that are settled. The present chapter only discusses 
cases which for some reason are not debated in the literature as far as I can 
see. 
Under  (280) below appear the four relevant empirical generalisations 
that I can think of. 
 
(280) empirical generalisations regarding the interface 
 
a. morpho-syntax has no bearing on the content of phonological computa-
tion: the application of phonological computation can be altered under 
morpho-syntactic influence, but not its properties 
 
b. morpho-syntax and melody are incommunicado 
 
c. there are no boundaries inside morphemes, hence morpho-syntax has 
no bearing on morpheme-internal phonological objects 
 
d. there is no specific phonetic correlate of morpho-syntactic information 
 
(280c) and (280d) have already been discussed in Part I; the issues at 
hand are summed up in the following chapter (§ 667 and § 668, respec-
tively). (280b) has been touched on in § 412 (phonology-free syntax), but 
not as an independent issue. Together with (280a) (which was not covered 
in Part I at all), it is discussed below in the present chapter. 
 

566 
Chap 2: Empirical generalisations 
659  2. Morpho-syntax has no bearing on the content of phonological 
computation 
 
An important generalisation regarding the interface is that whatever mor-
pho-syntax does to phonology, it is unable to create, to suppress or to mod-
ify phonological processes. That is, phonological computation exists inde-
pendently of morpho-syntactic computation and of any procedural or repre-
sentational agent thereof. It is not phonological instructions themselves that 
are impacted by extra-phonological information: it is their application that 
may be altered by morpho-syntax. 
On the procedural side, of course, there is no influence on the content 
of phonological computation: procedural influence on phonology is 
achieved by the successive submission of growing chunks of the whole to 
an invariable phonological computation. This may produce opacity effects 
but leaves the phonological computation alone with the vocabulary items 
that are the result of the spell-out of morphemes.  
In the case of representational communication, some carriers of mor-
pho-syntactic information that are not part of the morphemic endowment 
(juncture phonemes, hashmarks, prosodic constituency) have been added to 
the input to phonological computation. These carriers may then modify the 
result of the phonological computation (as compared with a situation where 
they are absent). The computational system itself, however, i.e. the set of 
instructions (the rule inventory and ordering, the constraint inventory and 
ranking etc.), remains unaltered. 
Empirically speaking, the effect of this division of labour is that no-
body has ever seen a phonological process that is active in a certain mor-
pho-syntactic environment (or in mono-morphemic strings), but not in oth-
ers. It does happen frequently, of course, that processes are blocked (or 
triggered) in a specific morpho-syntactic environment, and this may have 
procedural as much as representational reasons (e.g. affix class-based phe-
nomena, see §§ 163, 166). This does not mean, however, that the content of 
the phonological computation was modified: its application has just been 
suspended. 
Of course, this does not withstand the existence of distinct computa-
tional systems, which may either be morpheme-specific (level 1 vs. level 2 
in Lexical Phonology, § 148) or chunk-specific (lexical vs. postlexical in 
Lexical Phonology, § 234). What was said in the previous paragraph is only 
true for phenomena that fall into the competence of a given computational 
system. Or, put differently, the properties of phonological computation 
themselves remain unmodified, whatever morpho-syntactic influence 

Morpho-syntax has no bearing on the content of phonological computation 567 
comes to bear, also in theories that accommodate several computational 
systems. 
As far as I can see, the inalterability of phonological computation in 
the face of morpho-syntactic information is entirely consensual across all 
theories and protagonists over the 70 years of interface literature that have 
been covered. That is, all theories have attempted to reduce morpho-
syntactic influence to procedural and/or representational influence along 
the lines described. Although it is a logical possibility, nobody has seriously 
thought of modifying the phonological computational system according to 
morpho-syntactic contexts. One could imagine for example a rule k →tÉʃ /
__i,e (or its equivalent constraint) that is changed into k →tÉs / __i,e at a 
certain suffix boundary. Another way to alter phonological computation 
would be to add a rule (or a constraint) when some morpho-syntactic divi-
sion is run through the phonology. Nobody has ever attempted to do that: 
morpho-syntax influences the application of pre-existing phonological 
computation (by blocking or triggering processes), but it does not create or 
modify it. 
The fact that the definition of the properties of phonological compu-
tation is an exclusively phonological matter on which morpho-syntax has 
no bearing follows from modularity (see § 622): morpho-syntax (or mor-
phology and syntax) and phonology are distinct computational systems that 
work on distinct vocabulary items (domain specificity). The only way for 
modules to talk to each other is through the exchange of their respective 
outputs. The output of modules, however, is structure, not computation. 
Therefore the respective computational systems that modules are made of 
live in complete autarky and could not possibly bear on one another. 
The generalisation at hand is probably is too obvious to arouse spe-
cific concern in the literature: I have not come across any text that makes it 
explicit. The fact that it follows from modularity is certainly a good point 
for this theory of cognitive organisation; in turn, it bolsters the idea that 
morpho-syntax and phonology are distinct computational systems (mod-
ules). 
 

568 
Chap 2: Empirical generalisations 
660  3. Morpho-syntax and melody are incommunicado 
 
661  3.1. Morpho-syntax can neither read melody nor bear on it 
 
662  3.1.1. Phonology-free syntax is in fact melody-free syntax 
 
Recall from the discussion of phonology-free syntax in § 412 (also 
§§ 653, 253) that phenomena where melodic properties (i.e. phonological 
specifications that are made below the skeleton) condition a morphological 
or a syntactic process appear to be absent from the record (this was actually 
Zwicky & Pullum's 1986a,b original observation). By contrast, it seems 
that phonological properties located above the skeleton can bear on mor-
pho-syntax. Hence something like "verbs that begin with a labial are raising 
verbs" is unheard of. 
 
663  3.1.2. Carriers of morpho-syntactic information do not include melody 
 
There is good reason to believe that communication in the opposite direc-
tion, i.e. from morpho-syntax to phonology, is restricted in the same way: 
carriers of morpho-syntactic information that are inserted into phonology 
through the representational channel always land at (juncture phonemes, 
SPE-type hashmarks) or above (prosodic constituency) the skeleton; they 
do not include melody.160 Hence processes whereby, say, raising verbs pala-
talise, but non-raising verbs do not, are unheard of. 
On the other hand, phonotactic and suprasegmental effects in pho-
nology typically depend on morpho-syntactic information. Extrasyllabicity, 
extraprosodicity, the restriction of word-initial clusters to obstruent-
sonorant sequences, the tolerance of heavy clusters at the right edge (e.g. 
English sixths [sɪksTs]) are all examples where a non-melodic effect de-
pends on a calculus regarding string edges, which is a morphological in-
formation. Analogous melodic effects such as, say, "all velars palatalise 
word-initially", are not on record. 
 
160 The only case that I am aware of where morpho-syntactic information was 
really proposed to have a melodic incarnation is Lass' (1971) analysis where the 
word boundary identifies as [-voice]. This early attempt at translating morpho-
syntactic information into something else than diacritic boundaries is discussed 
in § 135. 

Morpho-syntax and melody are incommunicado 569 
The (ontological) gap between items that occur below and above the 
skeleton should then allow for the latter to be the output of translation. Be-
yond structural units such as syllabic space and prosodic constituency, an 
interesting candidate is tone: traditionally represented above the skeleton 
and counted as suprasegmental because of its lateral mobility, tone seems to 
have a melodic identity (H, L). Whether tone is a melodic or a supraseg-
mental item (or both) is an old question. Interesting evidence comes from 
an analysis of Yoruba cyclic accentuation: Manfredi (forth, section 2.2) 
shows that an H is distributed by each phase. That is, an otherwise inexpli-
cable high tone with no lexical origin appears in every spell-out domain 
(CP, TP, DP on Manfredi's analysis): phases distribute an H. This points to 
the ability for tone to be the output of translation and places it in the su-
prasegmental category of items that do not live below the skeleton: tone is 
not melodic. 
Finally, the exclusion of melody from the interface also ties in with 
the argument that Pyle (1972) has raised against SPE-type boundaries. Re-
call from § 136 that he observed that selling # for a ([-segment]) segment 
must be wrong because rules may transform segments into other segments, 
but # never becomes [p] or [a] (or vice-versa): # →a / X__Y is unheard of. 
This is an expression of the generalisation at hand in the terminology of the 
70s: morpho-syntactic information (the #) can never be transformed into 
melody (segments such as [a]). 
 
664  3.2. (Floating) morphemes without linear realisation originate in the 
lexicon 
 
Of course the ultimate effect of morpho-syntactic bearing on phonology is 
always either phonotactic (e.g. the restriction of word-initial consonantal 
sequences to obstruent-sonorant clusters) or melodic. The question is 
whether there are cases where a melodic effect is direct, i.e. not mediated 
by some structure at or above the skeleton. 
Prima facie candidates for non-mediated influence are cases where a 
morpheme has no surface manifestation that could be identified in the lin-
ear string: it merely modifies material that belongs to other morphemes. 
Umlaut, or any floating morpheme in autosegmental terms for that matter, 
fall into this category. One may be tempted to conclude, then, that the 
boundary of the morpheme at hand materialises as the triggering melodic 
item in question. Such an analysis appears to be outlandish, though, and as 
far as I can see has never been proposed. 

570 
Chap 2: Empirical generalisations 
Let us take a closer look at umlaut. In German for example, umlaut 
may mark the plural of a noun. In some cases, it appears together with a 
suffix (Haus - Häus-er "house sg, pl"), but in others it is the only marker. 
The plural of Mutter [mʊtɐ] "mother" is Mütter [mʏtɐ] for example: it is 
only marked by the palatalising effect on the root vowel. 
In the massive body of literature regarding this phenomenon, as far 
as I can see nobody has argued for an analysis whereby the plural boundary 
incarnates as a palatal agent, which then causes fronting of the back root 
vowel. All phonological analyses (there are also analyses that rely on allo-
morphy or other non-phonological mechanisms) hold that the lexical iden-
tity of the plural morpheme is a palatal piece of melody that is regularly 
linearised after the root. In linear SPE-type analyses, the morpheme is an -i 
(its historical identity), which fronts the root vowel before being deleted by 
a subsequent rule. In autosegmental environments, the lexical identity of 
the plural morpheme is a floating palatal prime, which parachutes on the 
root vowel and is never seen as such because it has no syllabic constituent 
that it can associate to. 
In any event, the lexicon is found to be the origin of the palatal ele-
ment: no phonologist has thought of it in terms of the output of the transla-
tion of morpho-syntactic structure. 
 
665  3.3. Conclusion: vocabulary excluded from translation altogether? 
 
Given the lexical origin of the melody of floating morphemes, there is good 
reason to exclude the area below the skeleton from the possible target zone 
of representational communication: whatever objects are the output of 
translation, they can only land at or above the skeleton. 
As far as I can see, if tacitly, the non-role of melody at the interface 
is undisputed: all phonological carriers of morpho-syntactic information in 
phonology that interface theories have used over the past 70 years are non-
melodic (i.e. are inserted at or above the skeleton): juncture phonemes, 
SPE-type hashmarks and prosodic constituency. 
When conjoining melody-free syntax and the fact that the output of 
translation cannot be melodic items, the conclusion makes sense: melody 
and morpho-syntax are entirely incommunicado. This appears to be a ro-
bust generalisation. 
In modular terms, this ties in with the discussion in § 651 where the 
tentative generalisation was made that only structure, not vocabulary items, 
are subject to translation in intermodular communication (see § 752 on the 

Morpho-syntax and melody are incommunicado 571 
particular case of phonologically (ir)relevant morpho-syntactic vocabulary). 
In our case indeed, phonological vocabulary ± melody ± is excluded from 
translation into morpho-syntax. A new aspect of intermodular communica-
tion is added, though: the generalisation concerning the reverse direction 
suggests that vocabulary (melody) is also unable to be the output of transla-
tion.  
This would mean that vocabulary does not participate in intermodu-
lar communication at all: neither as input nor as output. Even though, recall 
from the discussion in § 653, nothing in principle withstands the translation 
of vocabulary (or its being the output of translation). Even if in a modular 
environment it makes sense to ignore those objects that the receiving mod-
ule will not be able to parse anyway if untranslated, the two-way incom-
municado between melody and morpho-syntax is in need of explanation. 
As far as I can see, no theory of either the cognitive or the linguistic system 
knows why, say, labiality is excluded from the translational process in di-
rection of morpho-syntax, and why morpho-syntactic information can be 
translated into phonological vocabulary, but not into melody. 


Chapter 3 
666  Issues that are settled 
 
667  1. There are no boundaries inside morphemes 
 
Two issues that were at the forefront of structuralist discussion appear to be 
settled: there are no boundaries inside morphemes, and there is no phonetic 
correlate of morpho-syntactic divisions. 
Level Independence (§ 61) is a headstone of structuralist theory; in 
the perspective of a discovery procedure where linguistic representations 
are constructed bottom-up from phonetics over phonemes and morphemes 
to sentences, look-ahead is prohibited. Therefore there can be no morpho-
logical information in phonology. Even though the principle was largely 
admitted, structuralist practice was manifold (§§ 64- 66), and morpho-
syntactic information was reintroduced through the back door in the phono-
logical guise of juncture phonemes. If Level Independence was to be held 
up, then, the coincidence of juncture phonemes and morpho-syntactic divi-
sions had to be accidental. This opened (or rather: pushed) the door for the 
disastrous practice of referring to ghost-junctures in the midst of mor-
phemes: anything and its reverse could be ascribed to them (§ 69). 
Chomsky et al. (1956) expunged this kind of juncture abuse. In order 
to do so, Level Independence first needed to be unhorsed: not only is there 
nothing wrong with the presence of morpho-syntactic information in pho-
nology, but this kind of information is actually necessary and regular (§ 76). 
Morpho-syntactic control over the distribution of juncture was then re-
stored: boundaries ± the name that was now given to juncture phonemes ± 
can only occur in place of a morpho-syntactic division (§ 78).  
This necessary egress from the denial of morpho-syntactic bearing 
on phonology, and from juncture abuse, was made at the expense of the 
introduction of diacritics (§ 696): the diacritic representation of morpho-
syntactic information (by # and the like at that time, later by the Prosodic 
Hierarchy) runs through the entire history of interface theory up to the pre-
sent day. I take it to be the major plague on the representational side of the 
interface ± the more so since at times it hides behind anti-diacritic lip ser-
vice (see § 698). 
In any event, the morpho-syntactic control over the distribution of 
boundaries (or any other phonological representative of morpho-syntactic 
information) is a headstone of generative identity in the realm of the inter-

574 
Chap 3: Issues that are settled 
face. It was taken over in SPE and since then was never called into ques-
tion: there are no boundaries in the middle of morphemes, and morpho-
syntax has no bearing on morpheme-internal phonology. 
There is massive empirical support to the end that morpho-syntax is 
toothless regarding morpheme-internal phonology: phonological effects of 
extra-phonological intervention are only encountered at morpho-syntactic 
breaks. Every phonologist has come across cases where the kind of phonol-
ogy which is observed at morpheme edges is different from the phonology 
that applies morpheme-internally. This appears to be a robust cross-
linguistic generalisation; it is observed by, among others, Rubach & Booij 
(1990), Piggott (1999) and Broselow (2003). 
Finally, it is important to note that the edge-interior asymmetry is not 
asymmetric in just any way: phonology is always regular, normal, un-
marked, clean, well-behaved and so forth in the middle of morphemes, 
while edges typically introduce irregularities and exceptional patterns that 
cause theories to devise edge-specific mechanisms such as extrasyllabicity 
(or extra-metricality, extra-prosodicity for that matter).161
161 Another generalisation, which does not directly bear on the present discussion, 
is the fact that both edges are deviant, but not in the same way: left-edge and 
right-edge specificities are not the same. For example, the former introduces the 
typical TR-only restriction on clusters that is known from Indo-European lan-
guages, while the latter often allows for heavy clusters that are unheard of mor-
pheme-internally (see Rubach & Booij 1990, Vol.1:§377). This issue is further 
discussed in Vol.2. 
668  2. There is no phonetic correlate of morpho-syntactic information 
 
669  2.1. Phonetic correlate of morpho-syntactic breaks: definition 
 
Another issue that roots in structuralist thinking but has a generative off-
spring in Natural Generative Phonology is the question whether morpho-
syntactic information, i.e. juncture or boundaries, have a direct phonetic 
expression. In the structuralist perspective, morpho-syntactic divisions are 
represented by juncture phonemes. Juncture phonemes are phonemes and 
therefore should have a phonetic correlate just like all other phonemes 
(§ 70). For his "open juncture" phoneme, Moulton (1947) for example pro-
poses allophonic variation between a "pause" and "zero". 
It should be clear that what this discussion is about is not the influ-
ence that juncture phonemes or morpho-syntactic divisions have on 

There is no phonetic correlate of morpho-syntactic information 575 
neighbouring segments or phonological processes. This influence of course 
exists ± it is the reason why the issue of morpho-syntactic bearing on pho-
nology arises in the first place. Rather, a putative phonetic correlate of junc-
ture is a surface manifestation of the object that conveys morpho-syntactic 
information itself. That is, we are talking about a phonetic exponent that is 
stable and occurs independently of whether and how juncture bears on 
phonological processes. 
Finally, it is to be noticed that talking about a phonetic exponent of a 
morpho-syntactic division makes only sense if morpho-syntactic interven-
tion in phonology is local, i.e. materialises as a representational object that 
is inserted into the linear string. Juncture phonemes and SPE-style bounda-
ries are local carriers of morpho-syntactic information, while domain-based 
prosodic constituency is not (the string is not enriched by any objects that 
can be identified in linear terms). The distinction between local and non-
local representational intervention is further discussed in § 706. 
 
670  2.2. Generative diacritics make no noise, except in Natural Generative 
Phonology 
 
The question of a phonetic correlate of morpho-syntactic divisions has been 
handed over to generative theory, where it appears in form of the featural 
content of boundaries. In SPE, boundaries are regular segments which, like 
all other segments, are defined by features, one of which specifies that they 
are [-segment] (while real segments such as /p/ and /a/ are [+segment]) 
(§ 87). This is the generative way to make sure that boundaries have no 
phonetic manifestation: implicit in the [-segment] specification is that 
[-segment] segments are not pronounced. Note that just like in structural-
ism, the representational objects that carry morpho-syntactic information 
into phonology are variants of the phonological vocabulary that is used by 
the theory: phonemes then, segments now (and autosegmental domains 
later on in the autosegmental 80s, see § 692). 
That morpho-syntactic information does not behave like phonemes 
or segments was shown early on (Pyle 1972, see § 131), but phonologists 
then put a lot of effort into ignoring this fact. Until the early 80s, where it 
was used in order to replace one diacritic (boundaries) by another (prosodic 
constituency), claiming that this move does away with unacceptable diacrit-
ics (§ 369). Since then and up to the present day, phonology lives in the 
belief that ugly SPE-diacritics have been successfully eliminated, and that 
modern autosegmental theory is clean: in rule-based as much as in con-

576 
Chap 3: Issues that are settled 
straint-based environments, the Prosodic Hierarchy stands unchallenged (or 
almost unchallenged: Pak 2008, Samuels 2009a, § 580). What has really 
happened is that the linear diacritic that bore morpho-syntactic information 
was replaced by an autosegmental diacritic. This issue is further discussed 
in § 694 ± it is closely related to the question whether carriers of morpho-
syntactic information should be local (linear) or not (non-linear) (see § 706). 
A generative revival of the idea that morpho-syntactic divisions have 
a phonetic correlate has occurred in the 70s in Natural Generative Phonol-
ogy, which not only on this occasion walks in the footprints of structural-
ism. The basic idea was that "true" phonology can only process phonetic 
information: any regularity that needs to make reference to morpho-
syntactic information is a morpho-phonological, not a phonological rule (P-
rules vs. MP-rules) (§§ 127f). Unfortunately, there are countless cases 
where rules qualify as true P-rules (they are completely automatic, excep-
tionless and use only phonetic information), except that they are sensitive 
to a boundary. If boundaries need to be taken into account (something that 
even natural phonologists did not deny), then, they had to have a phonetic 
existence. 
Just as in structuralist times, this road led nowhere. Since Natural 
Generative Phonology, the absence of phonetic correlates of morpho-
syntactic information is not called into question anymore. It is safe to con-
sider this issue settled. 
 
671  3. Affix ordering is wrong 
 
Dorothy Siegel's (1974) Ph.D has introduced the generalisation known as 
affix ordering: class 1 and class 2 affixes may combine in all possible ways, 
except for [class 2 - class 1] sequences, which do not occur. This finding 
had an important impact on the development of interface theory: it paved 
the way for Lexical Phonology. 
SPE was aware of the existence of English affix classes (see § 92), 
but ignored that they were also morphologically relevant. Siegel's affix 
ordering showed that the same empirical object ± affix classes ± has phono-
logical as well as morphological effects. What was needed, thus, was a 
theory that accounts for both types of effects with the same mechanism. 
This conspiracy (alongside with the abstractness debate and Praguian seg-
regation, see § 154) produced Lexical Phonology: the stratal architecture 
could kill two birds with one stone (see § 146). 

Interpretation is inside-out, grammar is interactionist, brackets are out 577 
Quite ironically, then, the initial spark of Lexical Phonology has 
turned out to be simply wrong. English features numerous words where a 
class 2 suffix occurs closer to the stem than a class 1 suffix (e.g. pat-
ent-abil2-ity1, organ-izat2-ion1, develop-ment2-al1, govern-ment2-al1); rele-
vant discussion was reported in § 243. Logically enough, the bankruptcy of 
affix ordering has then been used as an argument against Lexical Phonol-
ogy and its stratal architecture by Halle & Vergnaud (Halle & Kenstowicz 
1991:459, Halle et al. 1991:142). 
Finally, it may be worthwhile to have a second thought about the an-
glo-centristic character of affix classes and affix ordering: the literature 
(including this book) ruminates the same English examples for 30 years. 
Despite reasonable effort to evidence affix classes in other languages (see 
§143), though, they remain quite marginal a phenomenon cross-
linguistically speaking.162 The case of affix ordering is worse: as far as I 
can see, no equivalent has ever been found elsewhere. 
We are thus left with a historical situation where the major theory of 
procedural interface management has grown on what appears to be a highly 
isolated pattern ± in fact that unique a pattern that it does not exist at all: the 
empirical generalisation is wrong. This does not mean, of course, that Lexi-
cal Phonology is wrong as well: it is not infrequent in science that correct 
conclusions are drawn on wrong premises. The episode of affix ordering 
nonetheless leaves a displeasing aftertaste of anglo-centricity. 
 
672  4. Interpretation is inside-out, grammar is interactionist, brackets are 
unnecessary relics 
 
673  4.1. Inside-out interpretation and cyclic derivation 
 
674  4.1.1. Two ways of organising inside-out interpretation: brackets vs. 
interactionism 
 
One of the oldest insights of generative grammar is that morpho-
syntactically complex strings are parsed from the root outwards upon inter-
pretation, i.e. from the most to the least embedded chunk. Inside-out inter-
pretation has been introduced by Chomsky et al. (1956) (see § 80) and is 
 
162 The desire to find affix classes elsewhere may sometimes have prompted spuri-
ous results: Dutch was known as an affix class-language for many years, but 
this was probably an erroneous belief: van Oostendorp (2004) shows that the 
alleged suffix classes in fact have a phonological definition (see § 500). 

578 
Chap 3: Issues that are settled 
hard-wired in generative thinking at least since SPE, where it appears as the 
Transformational Cycle (later called the phonological cycle) (see § 101). As 
far as I can see, if often tacitly, inside-out interpretation is accepted and 
practised by all versions of generative grammar: in syntactic, semantic and 
phonological quarters alike.163 
There are two ways of organising inside-out interpretation: either 
brackets are inserted into the linear string that is then shipped to LF/PF and 
the two interpretational devices are able to "read" them in order to make 
their way through the pieces. Or grammar is interactionist, which means 
that chunks are spelled out one by one under morpho-syntactic control, i.e. 
moving up the tree, and come back from interpretation after having been 
assessed by LF and PF. On this count, concatenation and interpretation is 
interspersed (§ 146), and brackets are done away with. 
 
(281) two ways of organising inside-out interpretation 
 
a. inside-out interpretation assured 
by brackets 
b. inside-out interpretation assured 
by interactionism 
 
β
phon 
 
 
β
phon 
 
 
Y
α
phon 
 
Y 
α
phon 
 
x
X
x
X
SYNTAX 
 
 
 
spell-out 
 
spell-out 
 
PHONOLOGY 
 
 
 
 
phonology receives and 
computes: 
 
phonology receives and 
computes: 
 
[[X] Y] 
 
 
1. X
2. XY 
 
 
instruction: inside-out 
computation 
 
no particular instruction 
 
163 The only doubt that one could have is about parallel implementations of mor-
pheme-specific phonologies which are practised in OT (co-phonologies and in-
dexed constraints, see § 477): here interpretation of pieces is not necessarily 
bound to morpho-syntactic structure. The relevant literature is not explicit 
about the issue, but it may be conjectured that even here interpretation proceeds 
from the most embedded to the least embedded chunk (see § 481). 

Interpretation is inside-out, grammar is interactionist, brackets are out 579 
Before looking at which theory implements which solution, let us 
make the difference explicit. Table  (281) above contrasts the two options. 
In the example, every node is spelled out, which is the state of affairs in 
SPE (see § 103). How exactly the spell-out mechanism works is a separate 
issue that is discussed in the section on selective spell-out (§ 763). 
The following section fleshes out the last line of the table, i.e. the ad-
ditional instruction that PF needs under (281a). 
 
675  4.1.2. Brackets require a PF parsing device and make a procedural insight 
representational (and diacritic) 
 
A difference between (281a) and (281b) is that the former requires an addi-
tional instruction: it can only work if phonology is advised to find out 
which is the most embedded bracketed interpretational chunk of the string, 
and then to apply computation successively to less embedded bracketed 
chunks. This also means that phonology must be able to "read" brackets. 
That is, phonology must in fact be made of two separate devices, one iden-
tifying interpretational units in the bracketed string and keeping in mind 
which chunk is next, the other applying actual phonological computation to 
the sub-string that is currently delineated by the parsing device.  
As far as I can see, this consequence of (281a) is not made explicit in 
the literature. SPE takes brackets and their existence in phonology ±
augmented with morpho-syntactic labels such as NP etc. ± for granted 
without discussion (see § 95). It seems to be self-evident for Chomsky & 
Halle (1968) that phonology can read and interpret brackets. The only right 
that brackets are denied is to be referred to by phonological rules: these can 
make reference to translated (boundaries), but not to untranslated (brackets) 
morpho-syntactic structure (§ 98) (reference to morpho-syntactic content, 
i.e. the labels, is allowed all through). 
What this means is that PF is not exactly what it is meant to be in 
generative thinking, i.e. an interpretational device: it is more than that since 
it must also be able to carry out chunk-recognition, a job that is typically 
attributed to the spell-out mechanism which interprets morpho-syntactic 
structure, and which has certainly got nothing to do with the computa-
tion/interpretation of a string. In other words, (281a) forces phonology into 
replicating the labour of spell-out: chunk-recognition (i.e. the identification 
of interpretational units) is done twice, once in morpho-syntax, another 
time in phonology. This is certainly not something that (281a) can score 
with. 

580 
Chap 3: Issues that are settled 
On the other hand, no extra machinery or any specific instruction is 
needed under (281b): phonology applies phonological computa-
tion/interpretation to whatever string is submitted; there is no need for any 
chunk-recognition device in PF. Unlike (281a), (281b) is thus a good match 
of the regular generative description that makes PF a purely interpretational 
system. We will see in § 797, however, that the interactionist option (281b) 
also requires an additional device, i.e. a memory-keeper: chunks that are 
interpreted must somehow be stored and pieced together at the end of the 
derivation (i.e. when spell-out arrives at the matrix CP) before they are 
pronounced. 
The contrast between (281a) and (281b) also appears when looking 
at brackets themselves: brackets are diacritic objects that the linear string 
which phonology computes is enriched with. Under (281b), the string is 
"clean" in the sense that it does not contain any diacritics in addition to the 
items that are taken into account by the phonological computation. Today 
there is a broad agreement (to which practice, however, does not really live 
up) that diacritics in phonology is not a good thing to have. § 692 discusses 
this issue at length. 
Finally, it is to be noted that brackets transform a procedural insight 
into a representational issue. What inside-out interpretation expresses is the 
fact that first a chunk that has a given (embedded) morpho-syntactic status 
is interpreted, before another chunk (larger and less embedded) is proc-
essed. In the perspective of (281a), this parsing issue is "stored" in the rep-
resentations that are sent to phonology by the means of brackets, a repre-
sentational object; these are then converted back into procedural informa-
tion by the parsing device that PF must accommodate. One may doubt that 
this wrapping of procedural information into a representational guise for 
shipping purposes, which requires encoding and decoding on both sides of 
the pipe, is really helpful. Especially in presence of an alternative that takes 
inside-out interpretation for what it is, a procedural insight, and does not 
need any additional machinery (PF parsing device, brackets). 
 
676  4.2. The line-up of interface theories in regard of interactionism 
 
677  4.2.1. Revolution (Lexical Phonology) and counter-revolution (Halle & 
Vergnaud) 
 
Let us now look at how generative theories of the interface have positioned 
themselves in regard of the two options under  (281). 

Interpretation is inside-out, grammar is interactionist, brackets are out 581 
(281a) is the classical world-view that was consensual in traditional 
grammar and classical generative thinking (SPE on the phonological, As-
pects up to GB on the syntactic side): it was taken for granted that morpho-
syntax and phonology (semantics) are strictly ordered. That is, morpho-
syntactic concatenation is entirely completed before phonological and se-
mantic interpretation begins. "All concatenation before all interpretation" 
was long held to be part and parcel of the inverted T model. It was men-
tioned in § 86 that this statement is an additional and entirely independent 
plug-in: the organisation of the grammatical architecture in terms of one 
concatenative and two interpretational devices makes no statement about 
the question whether or not concatenation and interpretation are inter-
leaved. 
In the early 80s, interactionism as under (281b) barged into this set-
tled and undisputed landscape. Interestingly, it was introduced by Lexical 
Phonology for practical, rather than for principled reasons, and in complete 
absence of any architectural motivation: interactionism allowed to kill two 
birds with one stone (morphological and phonological effects of affix 
classes, see §§ 146, 671). 
From the orthodox generative vantage point, interactionism was a 
revolution ± a revolution in phonology, though, which remained confined in 
its original duchy: as far as I can see, interactionism did not irradiate into 
syntax or semantics at all in the 80s, where business continued as if pho-
nologists were not out of their mind. The response was therefore only pho-
nological: Halle & Vergnaud (1987a) led the counter-revolution under the 
explicit banner of anti-interactionism in order to restore the authority of the 
principle "all concatenation before all interpretation" (§ 222). 
 
678  4.2.2. Phonology and the interface are not the same thing 
 
Kaye (1995) takes an original position in this debate: he practices cherry-
picking. That is, while Lexical Phonology was declining in the early 90s 
and phonology had become harshly anti-derivational over night with all 
new theories hooking on this trend (OT, Declarative Phonology, Govern-
ment Phonology), he holds up interactionism (§ 275). On the other hand, 
Kaye (1995) implements selective spell-out and interpretation-triggering 
affixes, i.e. ideas that originate in Halle & Vergnaud's (1987a) anti-
interactionist work. 
Mentioning Government Phonology in the list of anti-derivational 
theories may appear as a contradiction with Kaye's interactionism ± but in 

582 
Chap 3: Issues that are settled 
fact it is not: Kaye was the first in the debate on derivationalism, I think, to 
carefully distinguish between phonological computation proper (his 
φ-function) and the mechanism that ships the result of the morpho-syntactic 
derivation to phonology (his concat-function) (§§ 267, 271). While the for-
mer is strictly non-derivational in Kaye's view (there are no ordered rules), 
the latter is perfectly derivational, and there is no contradiction: phonologi-
cal computation and the interface are two different things ± from a modular 
point of view (§§ 622, 649) there is no alternative anyway. 
This issue is also central for OT and the anti-cyclic attitude that is 
adopted by classical representatives of this theory. It was reported in § 464 
that the anti-cyclicity literature that dominates (or today perhaps: has domi-
nated) the interface discussion in OT does not distinguish phonological 
computation and chunk submission (§ 469). Without discussion, anti-
derivationalism is taken to be a property of grammar as a whole, including 
the interface, and not just of the computational systems (such as phonol-
ogy) that it is made of. This undifferentiated view of grammar certainly has 
a holding in the blurred modular contours, if any, that OT lives with. Or, in 
other words, the connectionist pieces that OT carries in its genetic endow-
ment (see § 529) contribute to this kind of globalising view on grammar that 
leads to the systematic violation of modularity (§ 523) and the non-
distinction between phonology and its interface. 
Finally, note that the anti-cyclic position of OT goes way beyond 
simple anti-interactionism: it rejects in fact all versions of cyclic derivation, 
that is of inside-out interpretation. It is the cyclic nature of the parsing that 
is at stake ± whether this is implemented by brackets or interactionism is 
irrelevant. Therefore OT has an issue with a very deep layer of generative 
thinking (see § 465). Or rather, those versions of OT that are anti-cyclic: 
recall that just like Kaye (1995), Stratal OT and DOT, the modern heirs of 
Lexical Phonology, implement an interactionist architecture where strata 
are serially ordered, but phonological computation itself is strictly parallel 
(§ 483). 
 
679  4.2.3. Derivation by phase: when generative grammar became interactionist 
 
By the end of the 90s, then, the generative mainstream ± i.e. syntax ± be-
comes interactionist as well: as a direct consequence of the minimalist pro-
gramme, Epstein et al. (1998:46ff), Uriagereka (1999) and Chomsky 
(2000a et passim) make interactionism ± which is known as derivation by 
phase in syntactic quarters ± an absolutely central concept of syntactic the-

Interpretation is inside-out, grammar is interactionist, brackets are out 583 
ory, and of the general architecture of grammar as a whole. This move is 
described in § 304. 
Like before, though, morpho-syntax and phonology appear to be per-
fectly waterproof: just like non-interactionist syntactic theory of the 80s 
took no notice of the contemporary interactionist debate in phonology, pre-
sent-day anti-interactionist (or even anti-cyclic) phonology, as far as I can 
see, shows no reaction to this major change in the interface landscape at all. 
Either anti-interactionism (or anti-cyclicity) continues to be promoted 
without mentioning that this overtly conflicts with current syntactic theory, 
or silent conversions take place: Morris Halle, the leader of the anti-
interactionist movement of the 80s, is a prominent figure of interactionist 
Distributed Morphology today. 
Regarding the issue of morpheme-specific mini-grammars, § 828 be-
low argues that modern phase theory has direct consequences for phono-
logical theory: intermodular argumentation is now possible, and this is all 
to the good (see § 841, also Scheer 2008c, 2009b, 2010b).  
Finally, it is useful to look at phase theory and interactionism in the 
light of the pendular movement between procedural and representational 
orientations of (generative) grammar. In minimalist times, major tenets of 
syntactic theory in the 80s such as lexicalism and representationalism are 
called into question and charged at least in some quarters. Concomitantly, 
much of the spirit of the 60s is restored (generative semantics § 721, anti-
lexicalism to a certain extent, see §§ 539, 569). Also, phase theory (including 
Phase Impenetrability) in some areas is a direct continuator (or rather: 
competitor) of representational tools of the 80. An obvious case in point is 
the formulation of Barriers (and bounding nodes) in terms of Phase Im-
penetrability (e.g. Rizzi 2005, Frascarelli 2006:2f, Boeckx & Grohmann 
2007). 
 
680  4.3. Only interactionism makes inside-out interpretation compatible with 
modularity 
 
681  4.3.1. Modularity referees in favour of interactionism 
 
Brackets as under (281a) store morpho-syntactic structure in the linear 
string that is the input to phonological (and semantic) computation. They 
are incompatible with modularity since they represent untranslated morpho-
syntactic information in phonology: recall from § 651 that intermodular 
(representational) communication requires translation. On top of that, they 

584 
Chap 3: Issues that are settled 
are diacritics in phonology, and diacritics are unwarranted anyway (more 
on that in § 692). 
Now interactionism does away with brackets: it is the alternative or-
ganisation of inside-out interpretation. From the point of view of modular-
ity and the diacritic issue, this is a highly beneficial effect. Or, in other 
words, the only way to make inside-out interpretation compatible with 
modularity is to have an interactionist architecture. This was pointed out on 
various occasions in the book (§§ 161, 170, 305). 
 
682  4.3.2. Nobody used modularity in the 80s 
 
Modularity was thus relevant for Lexical Phonology and during the 80s 
when the debate with Halle & Vergnaud (1987a) and the anti-interactionist 
counter-revolution was led: it could have refereed the quarrel (in favour of 
interactionism). Although the development of modularity was exactly con-
temporary with Lexical Phonology (Pesetsky 1979, Kiparsky 1982a,b on 
the one hand, Fodor 1983 on the other), the argument from modularity has 
never been made as far as I can see. 
This ties in with the observation that was made in § 414: on the repre-
sentational side, the major interface theory of the 80s was born from the 
dispute with direct syntax approaches that allow for free reference to mor-
pho-syntactic structure and content (labels). Against this practice, Prosodic 
Phonology has introduced the principle of Indirect Reference which re-
quires that phonology can only make reference to translated morpho-
syntactic information ± exactly what modularity imposes. But here again, 
although contemporary (Selkirk 1984, Nespor & Vogel 1986 on the one 
hand, Fodor 1983 on the other), modularity was never mentioned. Instead, 
the notion of non-isomorphism was invoked (which was held to be a fact 
about language, but which on closer inspection turns out to be a fact about 
the domain-based bias of Prosodic Phonology, see § 416). 
It is certainly true that modularity was always a core property of the 
generative architecture of grammar (see § 623) ± but it is also true that it 
remained an intro-class topic without much consequence on actual linguis-
tic analysis in the 80s (see § 630). In the discussion of Phase Theory since 
the late 90s, this has not changed substantially as far as I can see: modular-
ity as an operative and refereeing principle is more or less absent from the 
debate. 
In any event, it seems reasonable to conclude that the interpretation 
of morpho-syntactic structure is inside-out, and that grammar is interaction-

Interface Dualism 585 
ist. Brackets are an unwarranted relic of times when linguists had under-
stood that interpretation is from the root outwards, but had not considered 
the possibility that concatenation and interpretation are interleaved. 
 
683  5. Interface Dualism 
 
684  5.1. If tacitly, (almost) all theories implement Interface Dualism 
 
The prism that I use in this book in order to look at the interface is the dis-
tinction between a procedural and a representational channel of communi-
cation that morpho-syntax uses in order to talk to phonology. Interface Du-
alism is the claim that both channels are needed and real: an interface the-
ory that denies the existence of either one, or which does not use either, is 
on the wrong track. 
Interface Dualism may appear to be trivial: all theories of the inter-
face that we have come across in the historical survey in one way or an-
other implement both procedural and representational communication. 
Well, almost all (see the two following sections). Also, the two major inter-
face theories that still today dominate the landscape have been selectively 
focusing on either channel: Lexical Phonology has carried out an extreme 
proceduralisation of the interface (see § 213), while Prosodic Phonology is 
an exclusively representational theory. The two theories were contempo-
rary, but in spite of a significant and potentially conflictual intersection (see 
§429) there was no real dialogue. The official and diplomatic statement 
simply claimed peaceful coexistence (see § 423). 
Interface Dualism as understood in this book not only requires inter-
face theories to accept the existence of a procedural and a representational 
channel; it also means that a sound interface theory needs to think of how 
the two channels interact. That is, peaceful coexistence ("the others do 
whatever they want, this is none of our business") is simply a wrong state-
ment: there is competition between procedural and representational solu-
tions (see §§ 320, 429). 
The two issues at hand are discussed in two sections below, one re-
garding the division of labour between procedural and representational 
mechanisms (§ 748, a question that remains open in this book), the other 
inquiring on an important source of competition, i.e. the alleged absence of 
phonological effects of cyclic spell-out above the word level (§ 786). 
In any event, the claim of this book is that whatever its specific ori-
entations, a correct interface theory needs to provide for a procedural and a 

586 
Chap 3: Issues that are settled 
representational way of talking to phonology. I have taken the liberty to 
place Interface Dualism in the chapter regarding issues that are settled. It 
was mentioned that it is largely undisputed: if tacitly, (almost) all interface 
theories provide for representational and procedural communication. Ex-
cept two cases that were mentioned in Part I: Kaye (1995) and orthodox 
OT. These are examined below. 
 
685  5.2. Representational communication needed (contra Kaye 1995) 
 
Kaye (1995) explicitly refuses representational communication: he holds 
that the only way for morpho-syntax to bear on phonology is through cyclic 
spell-out (see § 276). 
Boundary information concerns edges of morphemes and words, 
which phonological processes make regular reference to. Procedural 
mechanisms are unable to take on this function by definition since they 
cannot refer to specific locations in a string. 
In fact Kaye's system does allow for reference to edges, but only to 
phase edges (or domain edges in his terminology). For example, /mn/ is 
reduced to [m] in domain-final position (damn, damn-ing vs. damn-ation,
see § 321). Kaye argues that this is different from regular representational 
communication since no specific representational object is inserted into the 
linear string. The edge of a domain is simply defined by the fact that noth-
ing precedes or nothing follows. 
However, there is evidence to the end that this is not good enough: 
edges produce stable phonological effects across languages (see Vol.1:§87, 
Ségéral & Scheer 2008, Scheer 2009a,c). For example, if the beginning of 
the word produces a particular effect in a given language, this effect will 
not be arbitrary: word-initial consonants are observed to be strong (rather 
than weak), word-initial consonant clusters are restricted to obstruent-
sonorant sequences (rather than to sonorant-obstruent etc.), and first vowels 
of words are prevented from alternating with zero. Hence there is a "con-
spiracy" of the beginning of the word, and the fact of being domain-initial 
does not produce any indication whether consonants should be strong or 
weak etc. Not any more by the way than diacritics such as # or PrW: any-
thing and its reverse can happen in the vicinity of domain edges, # and 
PrW.  
This pattern is called the Direct Effect in Vol.2 and Scheer 2009a,c 
because what is needed is a non-diacritic carrier of morpho-syntactic in-
formation: this is argued to be an empty CV unit which, unlike diacritic 

Interface Dualism 587 
sleepers (that only impact phonology when a rule or a constraint makes 
reference to them) will provoke a phonological effect no matter what. 
The two word edges and the way in which they bear on phonology 
are discussed at greater length in Vol.2. 
 
686  5.3. Procedural communication needed (contra orthodox OT) 
 
On the other end of the spectrum, the anti-derivational foundations of OT 
have produced the orthodox position of this theory where the cycle and any 
form of cyclic derivation is rejected out of hand (§§ 465, 475). 
This, however, is not a compelling position for OT: rather than fol-
lowing from OT's commitment to parallelism, it follows from the non-
perception of the internal structure of grammar. That is, OT applies the anti-
derivational request holistically to the grammar as such without even con-
sidering the possibility that it could apply to grammatical sub-systems such 
as phonology, but not to the system that relates these sub-systems, i.e. the 
interface (see § 469). Nothing withstands a version of OT where modular 
contours are sharp, i.e. where phonological computation is distinct from 
morpho-syntactic and semantic computation, and where intermodular 
communication is still an independent shipping-system. This view is indeed 
defended by Stratal OT and DOT (see § 483): phonological computation is 
perfectly parallel, but there are multiple constraint rankings that are cycli-
cally fed by an independent shipping mechanism.  
It was suggested in § 529 that OT's trope for scrambling everything is 
due to the connectionist half of its genetic endowment. Connectionism ma-
terialises namely as parallel computation, and works against the generative 
half of OT's genetic code, which favours modularity. 
The result is a situation where modularity is acknowledged, but con-
stantly violated (§ 523). Particularly heavy weighs the fact that the rejection 
of cyclicity also throws inside-out interpretation over board, one of the 
deepest generative insights (§§ 468, 672). The fact that morpho-syntactic 
structure is interpreted from inside out ± nobody seriously doubts that it is ± 
certainly constitutes a strong argument in favour of a cyclic shipping 
mechanism: intermodular communication is serial. In the same way, con-
comitant phonological and semantic effects of a given morpho-syntactic 
structure (cómparable vs. compárable, see §§ 545, 564) provide strong em-
pirical evidence for the existence of a cyclic spell-out mechanism. 
Finally, the fact that cyclic spell-out is a critical property of current 
syntactic theory since Chomsky's (2000a et passim) derivation by phase 

588 
Chap 3: Issues that are settled 
(§ 304) adds to the trouble that phonologists who reject procedural chunk-
submission are in: they will have to claim that modern syntax ± actually the 
entire generative architecture of grammar ± is flat out wrong. 
Against this backdrop, it needs to be noted that OT is much less anti-
derivational today than it was in the 90s, when orthodox anti-
derivationalism was coined. It was mentioned that Stratal OT and DOT 
carefully distinguish communication at the interface(s) from intra-modular, 
i.e. phonological computation: the latter is parallel, while the former is 
derivational. But more recently McCarthy (2007) has given up on parallel-
ism altogether, including within phonological computation itself: he revives 
Harmonic Serialism (under the label of OT-CC), a derivational option en-
tertained by Prince & Smolensky (1993) where the result of parallel con-
straint evaluation loops back into GEN until no harmonic improvement can 
be achieved anymore. 

Chapter 4 
687  Modularity, translation, the diacritic issue and local 
vs. domain-based intervention: settled in verb, but 
not in fact 
 
688  1. Introduction 
 
689  1.1. Three questions: two are settled, one has never been discussed 
 
This chapter is about two questions that have been discussed at some point 
in the history of interface theory, but today are taken to be solved. It is also 
about an issue which, although being critical for the way morpho-syntax 
talks to phonology through the representational channel, has never been 
debated as far as I can see. The two former questions are modularity (and 
its major consequence, translation) on the one hand, and the diacritic issue 
on the other hand.  
The latter is the question how exactly carriers of (non-morphemic) 
morpho-syntactic information intervene in phonology: locally (i.e. as a 
piece in the linear string that is located between two morphemes) or not 
(i.e. in form of autosegmental domains that cannot be localised in the linear 
string). The former follow the local philosophy of Trubetzkoy's Grenzsig-
nale, juncture phonemes and SPE-style boundaries, while the latter are 
represented by prosodic constituency.  
This contrast was identified in §366 0, where it was also pointed out 
that the transition from linear SPE-type boundaries to non-linear domain-
based carriers was not identified as such: as far as I can see, nobody has 
ever evaluated whether morpho-syntactic intervention in phonology should 
be local or non-local, what the consequences and the predictions are, what 
kind of evidence pleads in favour or disfavour of either view and so on (see 
§365 where the transition from boundaries to domains is described, and 
especially the summary in § 376). 
 
690  1.2. Modularity and diacritics are only settled in verb 
 
The two questions that have been discussed in the literature ± modular-
ity/translation and the diacritic issue ± could be accommodated in either the 

590 
Chap 4: Issues settled in verb, but not in fact 
chapter on settled or on open questions. They appear to be settled because 
everybody agrees that modularity is part and parcel of the generative archi-
tecture of grammar ± but then modularity is violated by a number of gen-
erative theories (and namely by OT, §§ 469, 523) in a number of different 
ways. Everybody also agrees that diacritics ought to be banned from pho-
nology ± but then phonology happily lives with autosegmental diacritics in 
lieu of linear SPE-type boundaries since the early 80s (§ 399). 
The two issues are thus settled in verb, but not in fact, and this may 
be the reason why nobody talks about them: OT hardly discusses architec-
tural properties (§ 524), and the diacritic character of the Prosodic Hierarchy 
is not even remotely hinted at. That is, he field lives in the belief that the 
diacritic issue was solved when ugly SPE-style boundaries were replaced 
by beautiful and "truly phonological" (sic, see § 405) prosodic constituency. 
 
691  1.3. The three questions are the backbone of the representational channel 
 
Together with the locality-of-intervention question that is in need of discus-
sion, modularity/translation and diacritics are the backbone of what repre-
sentational communication with phonology is about. One could actually say 
that the representational side of the interface reduces to these three ques-
tions. Vol.2 is about these issues, and they actually made me write the book 
in the first place: the theory I am working in, CVCV, has got something to 
say regarding 1) the non-diacritic output of translation (CV units), 2) the 
locality of morpho-syntactic intervention and, by way of consequence, 3) 
the existence and properties of the translational process.  
The historical survey in Part I may thus be viewed as a prelude to the 
contribution of Vol.2, and the present chapter is designed to explain that 
there is an issue at all: the (non-)respect of modularity, translation and the 
No Diacritics! requirement may appear to be an old hat. They are not.  
 
692  2. Translation in structuralist and generative interface theory 
 
693  2.1. Interface design was done in absence of a modular/cognitive 
background ± but translation has always been practised 
 
On modular assumptions, translation is obligatory: whatever information 
morpho-syntax wants to be carried by an item that phonology can make 
reference to, this item must be the output of a translational process (§ 650). 

Translation in structuralist and generative interface theory 591 
This cognitive foundation was entirely absent from interface theory 
until very recently, and today still is in some quarters. Structuralists for sure 
were not working with a cognitive background. Generative linguistics and 
its interface architecture surely implement cognitive/modular ideas: Noam 
Chomsky actively participated in the computational movement that, follow-
ing the Turing - von Neumann programme, founded Cognitive Science in 
the 50s (§§ 603, 623). This notwithstanding, as far as I can see there is no 
identifiable and explicit footprint of modular ideas when it comes to trans-
lation beyond a general sympathy for modularity. We have seen indeed that 
generative phonology has violated modularity/translation on a number of 
occasions (including SPE, see § 95, more on this in § 702 below), and with 
the exception of the work by Charles Reiss, Eric Raimy and colleagues (see 
§587, note 148), I am not aware of any explicit mention of modularity in 
the older (or even more recent) literature that would have been used in or-
der to impose translation. What is more, we have come across two cases 
where modularity would have been a decisive referee in ongoing debate, 
but was not used in the argumentation: Indirect Reference (§ 414) and inter-
actionism (§ 680). 
What I want to say is that in spite of what appears to be a complete 
absence of modular background in the operational design of interface theo-
ries, translation has always been present. Modularity, then, appears to be 
some kind of cognitive post-hoc confirmation of what linguists have always 
done anyway ± to which degree and with what kind of exceptions is dis-
cussed below. 
 
694  2.2. The birth and variable incarnation of diacritics 
 
695  2.2.1. Juncture phonemes and SPE-type boundaries: diacritic translation 
and various degrees of camouflage 
 
§61 (and more generally the chapter on structuralism, i.e. § 59) has de-
scribed how structuralism tried to make the carrier of morpho-syntactic 
information a truly phonological object that has got nothing to do with 
morphology. Juncture phonemes were the result of the descriptivism-rooted 
requirement of Level Independence: the bottom-up discovery procedure did 
not allow phonology to contain any morpho-syntactic information. 
Much effort was put into the camouflage of the extra-phonological 
identity of morpho-syntactic information, which is of course necessary for 

592 
Chap 4: Issues settled in verb, but not in fact 
phonological description: as indicated by their name, juncture phonemes 
were supposed to be phonemes, that is truly phonological objects. 
SPE basically does the same thing, only that the phonological cur-
rency has changed in the meantime: phonology is now made of segments 
(rather than of phonemes), which means that boundaries are [-segment] 
segments (§ 87). The generative camouflage is not really less outlandish 
than the one of its structuralist predecessor: # is not any more a segment 
than it is a phoneme. The unwarranted consequences of its alleged segmen-
tal status have been made explicit early on, namely by Pyle (1972) (see 
§136). 
The real difference with the structuralist strategy is the admitted hy-
bridity of the carrier of morpho-syntactic information. Instead of denying 
the morpho-syntactic origin of boundaries, the generative perspective or-
ganises its identity as a morpho-syntactic agent in phonology (see §§ 90f). 
Boundaries are thus supposed to be truly phonological units (i.e. segments) 
and carriers of morpho-syntactic information at the same time. 
This masquerade, however, was entirely transparent right from the 
start: unlike in structuralist theory where the phonemic status was given 
real credit (see § 701 below), hardly anybody took the [-segment] camou-
flage seriously. The naked # was taken for what it really is in all phonologi-
cal quarters: a unit whose only purpose is to store and to release morpho-
syntactic information. 
 
696  2.2.2. The abandon of Level Independence makes boundaries diacritics 
 
A direct consequence of this situation is the emergence of the diacritic is-
sue: if nobody believes that boundaries are segments, they must be non-
phonological objects ± diacritics (this notion was defined in § 405; it is fur-
ther discussed in Vol.2). 
The legalisation of morpho-syntactic information in phonology has 
thus prompted the diacritic issue ± which is here to stay. The question what 
arbitrarily chosen symbols have got to do with phonology, or why phonol-
ogy, but not other linguistic modules, should have them, is a major concern 
in interface theory since SPE and until the introduction of prosodic con-
stituency in the early 80s, which is (wrongly) believed to have solved the 
problem. 
 

Translation in structuralist and generative interface theory 593 
697  2.2.3. Since structuralism, the output of translation has always been a 
diacritic 
 
At least since the late 70s, enough discomfort with diacritic boundaries was 
accumulated (see § 131) to make the disqualification of diacritics broadly 
consensual. This, however, does not mean that a better solution was in 
sight. A radical alternative was to do away with boundaries and to replace 
them by nothing, i.e. to give up on translation altogether (direct syntax); 
§702 below discusses this option where phonological rules make direct 
reference to morpho-syntactic categories.  
The mainstream, though, replaced linear diacritics (boundaries) by 
autosegmental diacritics (the Prosodic Hierarchy). We have seen in 
§§ 373, 402 that, paradoxically enough, the argument which was used in 
order to promote this move was precisely the claim that diacritics do not 
qualify 
Since structuralist times and up to the present day, then, the output of 
translation has always been a diacritic, and the degree of awareness of this 
fact among the protagonists of the respective theories is variable: high for 
SPE-type boundaries, choked but sensible for juncture phonemes, com-
pletely absent for prosodic constituency. 
 
698  2.2.4. No Diacritics ! ± no diacritics ? 
 
Vol.2 takes up the diacritic issue: truly non-diacritic carriers of morpho-
syntactic information are argued for. These can only be recruited among the 
basic phonological vocabulary that exists anyway and in absence of any 
issue related to the interface. 
In the present context where the Prosodic Hierarchy stands (almost) 
unchallenged, this may appear to be preaching to the converted: the re-
ceived chronicle has booked diacritics as a solved problem since the early 
80s when ugly diacritic boundaries were replaced by "truly phonological" 
(sic, see § 405) prosodic constituents. This move was described in § 365 and 
is further discussed in § 711 below. The point is that the converted were 
converted because they had a strong desire to leave the old faith, rather than 
because the new religion was intrinsically appealing: it did not take a lot in 
the late 70s to convince boundary-frustrated phonologists (see § 131) that an 
alternative solution offers relief. 
 

594 
Chap 4: Issues settled in verb, but not in fact 
699  2.3. Modularity and translation were invented by structuralism 
 
700  2.3.1. Non-cognitive modularity: Level Independence enforces translation 
 
The dismissal of Level Independence and hence the recognition that mor-
pho-syntactic information plays a role in phonology is typically quoted 
when it comes to explain the difference between structuralist and genera-
tive theory (e.g. St. Anderson 1985:313ff, Durand 2006:2266, Aronoff 
2003). 
This is certainly correct ± but it spots light only on one side of the 
coin. Disqualifying Level Independence as a description-based relic of 
naive structuralist times is nearsighted. For Level Independence also ex-
presses the idea that morpho-syntax and phonology are incommunicado, 
that they are two distinct ontological entities ± exactly the insight of modu-
larity.  
Structuralist practice was then to circumvent the prohibition to use 
morphological information in phonology by its translation into a truly pho-
nological object ± a (juncture) phoneme. This gross camouflage may be 
sniggered at from hindsight. But, as was argued in §§ 72, 415, this would fall 
short of structuralist thinking. Willingly or unwillingly, consciously or not, 
structuralists were the first linguists to translate morpho-syntactic into pho-
nological vocabulary. And it was Level Independence that forced them to 
do so. 
Level Independence and ensuing translation may therefore be con-
sidered the birth of modular thinking in linguistics, albeit on grounds that 
have got nothing to do with any cognitive perspective. 
 
701  2.3.2. Translation affords the assessment of phonological theories 
according to their behaviour at the interface 
 
Interestingly enough, structuralist translation was far more serious than 
subsequent translational attempts. For the output identity ± a phoneme ± 
was taken seriously: as all other phonemes, juncture phonemes had to enjoy 
free distribution (and hence independence from morpho-syntactic divisions, 
see §§ 66f), and they had to have a phonetic correlate (§ 70). That this led to 
absurd results (juncture abuse, see § 69) is all to the good: it falsifies a pho-
nological theory that is based on this particular kind of translation.  
This opens the possibility for phonological theories to be assessed (or 
falsified) by their behaviour at the interface ± if only the arbitral award of 

Translation in structuralist and generative interface theory 595 
the interface is taken seriously. That is, when the specific vocabulary of a 
given phonological theory makes outlandish predictions, if translation is 
not given up on and if diacritics are not a possible output of translation, it 
may be concluded that the vocabulary (phonemes, segments, autosegmental 
trees) is not appropriate: the phonological theory needs to be modified (see 
§138).  
For example, had the absurd consequences of SPE-type boundaries 
that were pointed out by Pyle (1972) and Rotenberg (1978) (§ 131) been 
taken seriously, phonologists would have been forced to change the then 
current phonological theory. That is, the outlandish behaviour of # at the 
interface would have enforced the conclusion that segments, of which # 
was supposed to be a sub-species, are not the adequate interface currency. 
In other words: there must be something else than just segments in phonol-
ogy: autosegmental representations. 
 
702  2.4. Generative modularity offenders: reference to untranslated morpho-
syntactic information 
 
703  2.4.1. Translation was not a standard in generative theory until the mid 80s 
 
When talking about translation in SPE, the diacritic character of boundaries 
is only a minor problem when compared to the systematic offense that is 
made to modularity. It was shown in § 95 that SPE freely allows for the 
presence of untranslated morpho-syntactic information in phonology: both 
morpho-syntactic structure and its labels (NP, VP etc.) are constantly avail-
able in untranslated guise. The former, however, are only there to run in-
side-out interpretation: phonological rules cannot refer to brackets (§ 97) 
SPE thus provides for both translated (boundaries) and untranslated 
(morpho-syntactic labels) reference to morpho-syntactic information. This 
being said, there was no clear rationale for a division of labour: should a 
given phonological rule make reference to morpho-syntactic information 
rather in translated or in untranslated form?  
In the late 70s, the post-SPE practice led to a general frustration re-
garding the diacritic issue (§ 131). In recognition of the problems that piled 
up, some voices called for the complete elimination of translated informa-
tion (boundaries) in favour of direct reference to morpho-syntactic catego-
ries. This strand condensed in the 80s under the label of direct syntax ap-
proaches and became the major rival of Prosodic Phonology (§ 407), whose 
founding statement is Indirect Reference (§§378,406). This principle ± the 

596 
Chap 4: Issues settled in verb, but not in fact 
ban of any untranslated reference to morpho-syntactic information ± has 
become the baseline of generative interface theory on the representational 
side. 
 
704  2.4.2. Turning back the wheel: weak and strong modularity offenders in 
(more or less) recent development 
 
Hence it is only since the advent of Prosodic Phonology in the 80s that 
generative theory meets the standards that were set by structuralist Level 
Independence, and later on by modularity. In this sense, structuralism was 
far more generative than SPE, and it took generative phonology twenty 
years to catch up with the modernity of Level Independence. 
More recently, however, the clear modular waters of Indirect Refer-
ence are muddied again by a number of approaches that allow phonology to 
make reference to untranslated morpho-syntactic information. These fall 
into two kinds: those that work on a modular basis where morpho-syntax 
and phonology are clearly distinct ontological spaces and computational 
systems but allow for direct reference to morpho-syntactic information 
(weak offenders), and those where the existence of distinct computational 
systems is either unclear or overtly denied (strong offenders). 
Weak modularity offenders include SPE, the direct syntax ap-
proaches of the 70s and 80s and more recently van Oostendorp's Coloured 
Containment (§ 503). Strong modularity offenders are OT as a whole 
(§§ 469, 523) and Distributed Morphology. In DM, PF movement is incom-
patible with modularity because it supposes that a computation simultane-
ously accesses morpho-syntactic and phonological vocabulary (§§ 574, 580), 
and current analyses also interleave PF operations such as linearisation with 
phonological rules (§ 739). In OT and DM the existence and/or the contours 
of distinct modules is unclear. They are denied altogether in Sign-Based 
Morphology, an outgrowth of HPSG (§ 512). 
Recall that the OT-trope to scramble all linguistic facts into one sin-
gle constraint ranking is probably not unrelated to its connectionist roots 
(§ 529): connectionism is an all-purpose computational theory of everything 
that makes content-unspecificity a programmatic claim (see §§ 597f). 
Also, PF as conceived of in current minimalist syntax is a strong 
modularity offender: in PF syntactic-looking operations are carried out 
because they displease in narrow syntax (clean syntax, dirty PF). On the 
consensual assumption that vocabulary insertion occurs upon spell-out of 
narrow syntax, PF (or the subset of PF that excludes what phonologists call 

Translation in structuralist and generative interface theory 597 
phonology) is an ill-defined intermundia where computation needs to si-
multaneously access morpho-syntactic and phonological vocabulary ± a 
violation of domain specificity (§§ 738, 747). 
Finally, the diacritic issue also violates modularity, if in a much 
weaker sense: all generative (and non-generative) theories to date propose 
diacritics as an output of translation (juncture phonemes, SPE-type bounda-
ries, prosodic constituency). This is incompatible with domain specificity 
(§ 611): like all other modules, phonology can only parse and interpret its 
own, proprietary vocabulary. 
 
705  2.4.3. A note on Structural Analogy 
 
Dependency Phonology promotes the notion of Structural Analogy, e.g. J. 
Anderson (1985, 1986, 1987, 1992), Anderson & Ewen (1987:283ff), 
Durand (1995). In Hulst's (2000:209) words, "grammar recapitulates, rather 
than proliferates, structures and principles". Government Phonology, a sis-
ter theory, has adopted this idea: a number of devices that are (or were) 
developed by Government Phonology are directly motivated by syntactic 
theory and phenomena. Most prominent among those are government, li-
censing and the projection principle (Kaye et al. 1990).164 
The question is whether Structural Analogy violates modularity, or at 
least favours a bias towards modularity violation: it appears to make pho-
nology and morpho-syntax similar, rather than distinct. It seems to me that 
the issue cannot be decided ex cathedra: instruments that root in Structural 
Analogy do not violate modularity per se. Modularity violation is about 
denying the existence of distinct computational systems, or about blurring 
their contours. It is also about having vocabulary manipulated in a compu-
tational system that is not domain specific to this system. None of these is 
an automatic or necessary consequence of Structural Analogy.  
For example, Dependency Phonology and Government Phonology 
have never claimed that phonology and syntax share a common vocabulary 
over which computation is performed. Or government for instance (beyond 
the fact that today it is not the same device anymore in Government Pho-
nology, and has disappeared from current syntax) does not violate modular-
ity in any way that I can see. This also goes for a recent application of Rela-
 
164 Other instances are so-called prosodic government (which applies c-command 
to phonology, Lowenstamm & Kaye 1986:115, Lowenstamm 1989) and a pho-
nological version of the Minimality Condition (Charette 1989, Harris 
1994:169f, Kaye et al. 1990:224f). 
 

598 
Chap 4: Issues settled in verb, but not in fact 
tivized Minimality (Rizzi 1990) to phonology (Brun-Trigaud & Scheer 
2010): modularity is unaffected if locality conditions on syntactic and pho-
nological processes are similar or identical. 
 
706  3. Local vs. non-local carriers of morpho-syntactic information 
 
707  3.1. Local boundaries vs. non-local domain-based intervention 
 
It was pointed out in §366 0 that the major cultural break on the representa-
tional side of the interface since the 19th century has occurred when Pro-
sodic Phonology replaced local boundaries by non-local domains in the 
early 80s. That is, phonologists have always thought of carriers of morpho-
syntactic information in terms of items that are inserted into the linear 
string, i.e. which are immediately preceded and followed by some phono-
logical symbol (that represents morphemic information). This is true for 
neogrammarian, structuralist and generative thinking: Trubetzkoy's Gren-
zsignale, juncture phonemes and SPE-style boundaries represent this con-
ception. In the early 80s, however, a previously unconsidered non-local 
alternative, prosodic constituency, took over. Since then and up to the pre-
sent day, the domain-based nature of translated morpho-syntactic informa-
tion stands unchallenged (§ 365 traces back this evolution in greater detail). 
The locality of intervention is well incarnated by the traditional no-
tion of sandhi: sandhi phenomena occur at the break of two morphemes 
(internal) or words (external), and are triggered by this division. 
Following the SPE-prototype, let us call boundary any local carrier 
of morpho-syntactic information, as opposed to domain, which is a non-
local means of carrying morpho-syntactic information into phonology. Ta-
ble  (282) below contrasts the two options; in both cases, carriers of extra-
phonological information appear as ¥. Morpho-syntactic units (morphemes 
or words) appear as a linearised sequence of pieces. 
 
(282) local vs. non-local intervention in phonology 
 
a. local:  
¥ is inserted at morpho-syntactic 
divisions 
b. non-local: 
¥ dominates a number of pieces 
 
¥
[piece 1] ¥ [piece 2] ¥ [piece 3] 
[piece 1]   [piece 2]   [piece 3] 
 

Local vs. non-local carriers of morpho-syntactic information 599 
The domain-based option under (282b) is what has become broadly 
consensual in generative phonology since the introduction of the Prosodic 
Hierarchy in the early 80s. The difference with respect to the traditional 
local alternative under (282a) is that a number of pieces of the linear string 
are spanned by a domain. That is, labelled clusters are created: an individ-
ual piece belongs to a domain (a ¥). By contrast under (282a), a piece can-
not belong to a boundary (to a ¥). 
On the other hand, a boundary has a linear location: it follows some 
piece, and precedes some other piece. It does not make sense to talk about 
domains that intervene between two pieces: domains are made of pieces, 
but they are not defined by a linear precedence relation with the items that 
they dominate. 
 
708  3.2. Notational variants and real differences 
 
709  3.2.1. Domain-based can be translated into local reference and vice-versa 
 
In the original conception of Prosodic Phonology, there were three ways for 
a phonological rule to make reference to prosodic domains (Selkirk 
1980a:111f, Nespor & Vogel 1986:77). Table  (283) below repeats them 
from § 384 for convenience. 
 
(283) rule types in Prosodic Phonology 
 
a. domain span rule 
 
 
b. domain juncture rule 
 
 
c. domain limit rule 
 
 
Domain span rules apply in a certain segmental environment iff this 
environment is contained within a specific domain. Domain juncture rules 
apply when some part of the segmental string needs to be adjacent to a 
boundary that separates two items of the same prosodic unit. Finally, do-
main limit rules apply when certain segmental conditions are met, but only 
at the beginning or at the end of a given unit of the prosodic constituency. 
Leaving the latter aside (which has not experienced a substantial em-
pirical echo), it is clear that domain-based intervention is actually a super-
set of local intervention. That is, domain juncture rules can reproduce the 
local effect, but in addition domain span rules can make reference to some-
thing that local boundary-based intervention appears to be unable to ex-
press: a phonological effect that applies to several morpho-syntactic pieces 
in a row. 

600 
Chap 4: Issues settled in verb, but not in fact 
This impression is wrong: just as much as domains can express local 
reference, local boundaries can express generalisations that apply to a set of 
neighbouring pieces. We have actually come across an exemplary case in 
§419 where the domain-based bias of Prosodic Phonology led to a wrong 
conclusion: non-isomorphism is a fact about the prism that Prosodic Pho-
nology uses in order to look at the evidence, not about the linguistic fact 
itself. The example discussed since SPE is about a cat, a rat and cheese. It 
is repeated under  (284) below from § 418 for convenience. 
 
(284) a. This is [the cat that caught [the rat that stole [the cheese]]] 
 
b. [This is the cat] [that caught the rat] [that stole the cheese] 
 
The major syntactic divisions of the sentence under (284a) do not co-
incide with its intonational structure under (284b). Hence, goes the argu-
ment since SPE, whatever drives phonology to decide that intonation is as 
under (284b), it is not the output of the syntactic module: there is no node 
in the syntactic tree that uniquely dominates every intonational span of the 
sentence. This discrepancy between (284a) and (284b) is what Prosodic 
Phonology (and the generative mainstream since then) calls non-
isomorphism. 
When we look at the same facts through the glasses of local bounda-
ries (instead of through the domain-based prism), though, there is no non-
isomorphism at all: intonational chunks simply begin with every CP. Hence 
it is enough to say that the intonation-building mechanism starts a new unit 
every time it hits a CP-boundary. Intonational and syntactic structure are 
thus perfectly isomorphic, and no specific autosegmental constituency on 
the phonological side is needed in order to express the relevant generalisa-
tion. 
 
710  3.2.2. The difference is conceptual, not empirical 
 
Abstracting away from this specific example, the following is true: any 
generalisation that involves a uniform behaviour of several neighbouring 
pieces of the linear string, and which is intuitively formulated in terms of a 
domain, may be translated into local terms. What it takes to do that is to 
insert a particular boundary (a ¥ in the terms of  (282)) between those pieces 
that belong to the domain at hand (and eventually before the first and after 
the last piece), and nowhere else. A process that makes reference to ¥ will 

Local vs. non-local carriers of morpho-syntactic information 601 
then target exactly the those morpho-syntactic breaks that are described by 
the original domain.  
Note that it does not matter whether the piece-transitions that need to 
receive a boundary are a homogeneous (or natural) class on the morpho-
syntactic side. The question which class of morpho-syntactic divisions pro-
vokes a given phonological effect is what I call the mapping puzzle (§ 753). 
Whatever the output of translation, boundaries or domains, it needs to be 
created through some mapping process, and domains do not represent mor-
pho-syntactic structure any "more directly" than boundaries. 
It is thus hard to imagine an empirical situation that can be accounted 
for by local, but not by domain-based intervention, or vice-versa. The con-
clusion, then, is that the difference is conceptual, rather than empirical. 
 
711  3.3. The local baby and the diacritic bathwater 
 
Below the local and the non-local options are compared regarding their 
conceptual properties. Before this is done, however, it may be worthwhile 
to recall that the issue has never been discussed. What was discussed in-
stead is something else: boundaries were outlawed because they are diacrit-
ics (§ 373), against domains which were held to be "truly phonological" 
objects (see § 405). It did not occur to anybody to even ask the question 
whether domains are diacritics, or to prove that they are not. Prosodic con-
stituency was a non-diacritic self-runner. The fact is that by all standards 
they are as much a diacritic as SPE-type boundaries (see § 402). 
Beyond the diacritic argument that was made, it is hard to find any 
other anti-boundary argument in the Prosodic Phonology literature (see 
§369): boundaries were not really an issue. They were considered old-
fashioned, and they were discredited anyway by a decade of frustrating 
practice (§ 131). The real reasons for the fact that the entire field subscribed 
to the overnight take-over of prosodic constituency may thus well be a frus-
tration-born "anything but boundaries" on the one hand, and the simple 
application of the new autosegmental technology to the interface on the 
other hand. If segmental, syllabic and other structure is autosegmental, so 
must be the carrier of morpho-syntactic information. The fact that the Pro-
sodic Hierarchy is a child of autosegmentalism (rather than of an empirical 
or a conceptual issue with boundaries) was shown in § 368. 
In sum, then, what happened was a double fault: boundaries were 
dismissed because they were diacritics, but just in order to be replaced by 
another diacritic; and the local vs. non-local question was decided without 

602 
Chap 4: Issues settled in verb, but not in fact 
having been discussed: the local option was thrown over board together 
with (diacritic) boundaries. Or, in other words, the local baby was thrown 
out with the diacritic bathwater. Both properties, however, are logically 
independent: a local boundary may or may not be diacritic, and so may be a 
non-local domain (at least in principle, more on this shortly). 
This does not help us to decide whether morpho-syntactic interven-
tion in phonology should be local or not ± but at least locality may now be 
re-considered as a relevant question.  
 
712  3.4. There can be non-diacritic boundaries, but what would a non-diacritic 
domain look like? 
 
713  3.4.1. Non-diacritic boundaries (can) exist 
 
In order to decide whether local or non-local intervention is correct, let us 
thus ask the question what a non-diacritic boundary would look like, and 
what a non-diacritic domain could be. Table  (285) below repeats the defini-
tion of what counts as a diacritic that was used in § 405. 
 
(285) definition of the term "diacritic" 
 
a diacritic is a non-native object in module X: it is only used when infor-
mation from outside of X is processed. It is absent from events that do not 
appeal to extra-Xal information. 
 
Hashmarks and constituents of the Prosodic Hierarchy (i.e. omegas) 
meet the conditions: they are non-phonological intruders in the phonologi-
cal world which do labour only when phonology appeals to extra-
phonological information, and which are systematically absent from phono-
logical processes that do not use extra-phonological information (such as 
ordinary palatalisations for example). 
A non-diacritic is thus an object that exists in phonology anyway, 
even in absence of any appeal to extra-phonological information. Lass' 
(1971) proposal that a boundary materialises as the feature [-voice] in pho-
nology (see § 135) therefore satisfies the non-diacritic requirement: [-voice] 
exists in phonological processes that have got nothing to do with extra-
phonological information. We know that in fact melodic primes are not 
good candidates for the output of translation because melody and morpho-
syntax are incommunicado (see § 663).  
Lowenstamm (1999) has introduced another type of carrier of mor-
pho-syntactic information: syllabic space. In his theory (Government Pho-

Local vs. non-local carriers of morpho-syntactic information 603 
nology in general, CVCV in particular, see Lowenstamm 1996, Scheer 
2004a), the minimal syllabic item is an empty CV unit, and it is an empty 
CV that marks the beginning of the word. Three cross-linguistically stable 
effects of the initial CV have been identified: they are briefly described in 
§685 (and at greater length in Vol.1:§§87,402, Ségéral & Scheer 2008, 
Scheer 2009a,c).  
In subsequent literature, interface phenomena that are unrelated to 
the left edge of the word have also been analysed in terms of syllabic space: 
boundary information is found to be carried by CV units in the analysis of 
the negative in Kabyle Berber (Bendjaballah 2001), a verbal marker in 
Chleuh Berber (Lahrouchi 2001) or tense in German strong verbs 
(Bendjaballah & Haiden 2003a,b). An empty CV unit also carries morpho-
syntactic information in Guerssel & Lowenstamm's (1990) analysis of 
Classical Arabic (what they call the derivational syllable) and Pagliano's 
(2003) analysis of intrusive consonants in French. 
These cases are discussed at length in Vol.2. Their enumeration at 
this stage of the discussion is only meant to show that there is an alternative 
to diacritic boundaries: syllabic space is certainly not a diacritic since it is a 
necessary ingredient of phonology even in absence of extra-phonological 
factors. At the same time, it is local, rather than domain-based: just like 
SPE-type boundaries, syllabic space is necessarily inserted into the linear 
string at morpho-syntactic divisions. Note that the particular incarnation of 
syllabic space is irrelevant for the argument: as x-slots, regular syllabic 
constituents (onset etc.) or the CV units of Government Phonology and 
CVCV. 
If the question is thus whether local boundaries can be non-diacritic, 
the answer is yes: counter to what early Prosodic Phonology wanted to 
make phonologists believe, nothing withstands the existence of non-
diacritic boundaries. One solution is worked out in Government Phonol-
ogy, but there are certainly other possibilities in other theories. 
 
714  3.4.2. Top-down constructions are diacritic by definition (prosodic word 
and higher) 
 
Let us now try to conceive of non-diacritic domains. A non-diacritic do-
main would have to exist in phonology independently of any issue related 
to extra-phonological information. Clearly, this excludes all higher layers of 
the Prosodic Hierarchy. Recall from § 401 that it is a recognised and admit-
ted fact in Prosodic Phonology that prosodic constituents fall into two cate-

604 
Chap 4: Issues settled in verb, but not in fact 
gories: those that are top-down, and those that are bottom-up constructions. 
All higher constituents, i.e. from the prosodic word on, represent the former 
type, which has the additional characteristic that no phonological property 
contributes to its construction: prosodic words and the like come into being 
through translation, and through translation only (see § 421). They exist in 
order to transmit morpho-syntactic information, and for no other reason. 
On the other hand, prosodic constituents below the word level (i.e. 
feet, syllables and eventually moras) are bottom-up constructions: they are 
projections of genuinely phonological vocabulary (ultimately of melodic 
primes).165 Also, the computation that produces them is purely phonologi-
cal, i.e. in no way influenced by extra-phonological information. In short, 
the existence of syllables and feet (eventually of moras) is entirely inde-
pendent of any extra-phonological information: if there were no interface, 
syllables and feet would still exist, while prosodic words and higher con-
stituents would not. 
The lower bottom-up constructed layers of the Prosodic Hierarchy 
thus appear to be sound candidates for non-diacritic domains. Whether this 
is indeed the case is discussed in § 716. By contrast, the higher layers from 
the prosodic word on are diacritic by definition: they serve no other pur-
pose than storing extra-phonological information. 
 
715  3.4.3. Higher layers of the Prosodic Hierarchy are the projection of nothing 
 
Another remarkable property of the higher layers of the Prosodic Hierarchy 
is the fact that they are the projection of nothing. 
Linguistics is (perhaps not exclusively, but certainly a lot) about hi-
erarchical structure, which is most commonly represented in form of trees. 
As far as I can see, a property that is shared by all hierarchical structure in 
 
165 It may seem at first sight that this is not true for Government Phonology, where 
lexical entries are fully syllabified and hence no syllabification algorithm builds 
syllable structure during phonological computation. This impression is mis-
taken. The presence of syllable structure in the lexicon does not imply that syl-
lable structure is not a projection of melodic primes. For one thing, it must 
somehow get into the lexicon, and hence children must transform a linear pho-
netic signal into a syllabified lexical entry. The same is true for adults when 
they lexicalise new lexical material (loans, acronyms etc.). Hence just like in 
other theories there is a syllabification algorithm in Government Phonology ± 
which however is active upon lexicalisation, rather than during regular phono-
logical computation.  

Local vs. non-local carriers of morpho-syntactic information 605 
linguistics is that it is the hierarchical structure of something. That is, syn-
tactic trees and phonological structure such as syllables are the projection 
of terminal elements, which originate in the lexicon, i.e. syntactic features 
and segments (i.e. clusters of melodic primes), respectively. This is what 
modular computation is all about: on the basis of (domain specific) vocabu-
lary items, computation creates structure (see § 652). 
Remarkably enough, though, prosodic constituents above the word 
level are the projection of nothing. They dominate items, and ultimately 
terminals, but these have no bearing on the structure that dominates them at 
all. Quite the opposite is true: the properties of terminals are determined by 
the higher constituent structure, which is imposed from the outside, i.e. as 
the result of translation. 
As far as I can see, the exclusively top-down (or, in modular terms, 
outside-in) character of the higher part of the Prosodic Hierarchy is un-
precedented in linguistics. The question may therefore be asked whether it 
is appropriate to talk about domains at all; and whether this kind of fake 
domain has any conceptual status in linguistics. As far as I can see, the fact 
that prosodic domains do not fulfil the basic requirement for hierarchical 
structure, i.e. projection, is not discussed in the literature. 
 
716  3.4.4. Projections created by phonological computation cannot be the 
output of translation 
 
Let us now turn to bottom-up constructed domains such as syllables and 
feet, which are non-diacritic and hence seem to be legitimate carriers of 
morpho-syntactic information. They are faced with another problem, 
though: if they are exclusively phonological, i.e. if no extra-phonological 
property contributes to their construction, how could they ever carry mor-
pho-syntactic information? The property that makes them non-diacritic also 
disqualifies them from being the output of translation. 
This may also be looked at from a more formal perspective: syllables 
and feet (eventually moras) cannot be carriers of morpho-syntactic informa-
tion because they are the result of phonological computation. Like all other 
domains (except, precisely, the higher layers of prosodic constituency), 
syllables and feet (eventually moras) are projections of basic vocabulary: 
syllables (and moras) are a function of segments, while feet are built on 
syllables. In modular terminology, syllables and feet (moras) represent the 
structure of the phonological module, while segments are its vocabulary. 

606 
Chap 4: Issues settled in verb, but not in fact 
Both are related by phonological computation: the latter is its input, the 
former is (a piece of) its output. 
Carriers of morpho-syntactic information, however, are necessarily 
created outside of the phonology, and by a means that is independent of 
phonological computation. Syllables and feet (moras), however, are entirely 
determined by the properties of their terminals. Therefore they do not qual-
ify as the output of translation. 
 
717  3.5. Conclusion: possible carriers reduce to syllabic space 
 
Let us now recapitulate the constraints that lie on possible carriers of mor-
pho-syntactic information. Domains are out of business altogether: they are 
either diacritics (the prosodic word and higher layers of prosodic constitu-
ency), or the result of phonological computation. This leaves no room for 
any kind of domain: all domains fall into one or the other category. 
By contrast, boundaries are not in the same trouble: if chosen among 
the objects that are present in phonology anyway, i.e. in absence of issues 
related to extra-phonological information, they pass the diacritic filter. 
What they have to face, though, is the independent and robust generalisa-
tion according to which melody cannot be the output of translation (§ 663). 
That is, only objects at and above the skeleton can participate in translation. 
The window for possible carriers of morpho-syntactic information 
thus shrinks quite dramatically: we are looking for objects 1) that are not 
the result of any (phonological) computation and 2) which occur at or 
above the skeleton. I argue in Vol.2 that the broad direction that is defined 
by these constraints is correct: what is inserted into phonology as a carrier 
of morpho-syntactic information is syllabic space. Depending on the theory, 
this may be skeletal slots or syllabic constituents. We have briefly opened a 
window on an implementation that is based on empty CV units. This per-
spective is discussed at greater length in Vol.2 (see also Vol.1:§§87,402, 
Ségéral & Scheer 2008, Scheer 2009a,c). 
 
718  4. Conclusion 
 
This chapter was designed to gather those issues that are relevant for Direct 
Interface, and which therefore lead over to Vol.2 (see also Scheer 2008a, 
2009a,c). Essentially, the three questions that make the core of the repre-
sentational side of the interface have been discussed: 1) modularity and 

Conclusion 607 
translation, 2) the diacritic issue, 3) the (non-)locality of intervention. The 
former is about the existence of translation, the second about its output, 
while the latter determines how this output is integrated and processed by 
phonology. 
Results (and hence preparation of Direct Interface) are the following: 
1) there was and still today is a diacritic issue (§ 698); 2) domains do not 
qualify as carriers of morpho-syntactic information (neither prosodic nor 
any other constituency) (§ 712); 3) morpho-syntactic intervention must be 
local (because non-local intervention is domain-based and domains do not 
qualify) (§ 711); 4) the window for the nature and insertion of carriers of 
morpho-syntactic information is extremely shrunk: only items of the do-
main specific phonological vocabulary qualify, but melody is out of busi-
ness (§ 717). The robot portrait of non-diacritic boundaries thus points to 
skeletal or syllabic space: this is what morpho-syntactic intervention is 
made of, and this is where it lands. 
 


Chapter 5 
719  Open questions (general) 
 
720  1. Grammatical architecture: alternatives to the inverted T 
 
721  1.1. Generative semantics 
 
All through Part I, it was assumed, more or less tacitly, that the correct ar-
chitecture of grammar, at least concerning generative thinking, is the syn-
tactico-centristic inverted T (see § 86): one central device concatenates 
pieces, which are then sent to two interpretative devices that assure the 
interface with the extra-linguistic world: LF with meaning, PF with sound.  
This section is just to point out that within generative quarters the in-
verted T architecture has (had) at least two competitors: generative seman-
tics and parallel modules. For people who have not lived through the late 
60s and early 70s, the former appears to be some kind of mythical period of 
early generative times that one reads about in books on the history of (gen-
erative) linguistics (e.g. Newmeyer 1986:81ff, 1996:101ff, R. Harris 
1993:101ff): in the late 60s, a handful of hippies led by John Robert (Háj) 
Ross, George Lakoff, James McCawley and Paul Postal have taken syntax 
to feature traces of semantic planning and concluded that semantics feeds 
syntax, rather than the reverse.  
The story of revolutionary generative semantics usually ends with 
the victory of the counter-revolution, which was led by Chomsky with no 
mercy and succeeded to expunge the semantico-centristic alternative root 
and branch by the mid 70s (Katz & Bever 1974 elaborate on the revolu-
tionary - counter-revolutionary interpretation). It is often said today, how-
ever, that recent minimalist analyses take up a number of insights from 
generative semantics (such as the idea that to kill in fact decomposes into 
cause to die). 
Overview literature includes R. Harris (1993), which was already 
mentioned. Going into greater detail would lead too far afield in the frame 
of the present book, and I am not exactly competent in this area. The only 
thing that this section aims at is to mention that alternatives to the inverted 
T exist, that they exist within the generative paradigm, and that generative 
semantics is one of them. 
 

610 
Chap 5: Open questions (general) 
722  1.2. Parallel modules 
 
723  1.2.1. Against syntactico-centrism (Jackendoff) 
 
A more recent alternative to the inverted T is the idea that morpho-syntax, 
semantics and phonology work in parallel, rather than in a specific serial 
order. This approach has been introduced and is promoted by Ray Jackend-
off; it is known as Representational Modularity (Jackendoff 1987, 1994, 
1997), and more recently under the label of Structure-Constrained Modu-
larity (Jackendoff 2002) (see Vol.2 for further detail regarding the differ-
ence). Ackema & Neeleman's (2004, 2007) work for example follows this 
parallel line of attack. 
The idea is that each module ± minimally syntax-morphology, se-
mantics, phonology ± retrieves the information that is relevant for its task 
from the lexicon. On these grounds, morpho-syntactic, semantic and pho-
nological representations are constructed in parallel and independently 
from one another. So-called correspondence rules (or interface processors 
today), Jackendoff's way to do translation, assure the communication 
among modules: they are responsible for the exchange of information, 
which occurs upon need and may be operated at any constructional stage. 
Jackendoff's parallel alternative is motivated by the rejection of the 
typical generative syntactico-centristic conception of grammar (Jackendoff 
1997:15ff): syntax is not the central construction worker that reduces se-
mantics and phonology to interpretative devices. Rather, all modules are 
equal-righted: they enjoy generative abilities and build their own structure. 
Whether this involves the concatenation of pieces or not is a secondary 
question.166 
It is worthwhile going into a little more detail here for two reasons: 
for one thing, Jackendoff has done relevant work on intermodular commu-
nication, which means that we will meet him again in Vol.2, where his 
computational conception of translation is discussed at length. The other 
reason is that modular parallelism is entertained in the area of interest of 
the book, the interface of phonology and morpho-syntax, in work by Sa-
brina Bendjaballah and Martin Haiden. This is what we turn to in the fol-
lowing section. 
 
166 Carvalho (2006) also argues against the purely interpretative status of phonol-
ogy, albeit from the structuralist point of view. Based on productive verbal 
paradigms in Portuguese, he contends that "morphological markedness uses 
stress placement and phonological markedness in order to build a five-degree 
scale of the complexity of inflected forms" (Carvalho 2006:157). 

Grammatical architecture: alternatives to the inverted T 611 
724  1.2.2. Designated portions of the skeleton project morpho-syntactic 
features (Bendjaballah and Haiden) 
 
Central in Bendjaballah and Haiden's work is the template (e.g. 
Bendjaballah & Haiden (2002, 2003a,c, 2007). Their idea is to generalise 
an insight that Guerssel & Lowenstamm (1990) gained on the basis of Se-
mitic. That is, morphological operations do not take place just anywhere in 
templates; rather, they apply to designated pieces thereof. These specific 
portions of the template must somehow be specified and lexically recorded: 
they are stable in a given language. An open question is whether they are 
really part of the template, i.e. inert in regular circumstances and "acti-
vated" upon specific morphological action; or whether they are a regular 
morpheme that is absent from the lexical recording of the template and 
joins in when the morpheme(s) that they represent are actuated. In this case, 
the only peculiarity of the designated portions ± typically a CV unit ± is 
their status as an infix (rather than as a prefix/suffix). While Semitic-style 
non-concatenative systems provide for the possibility of infixation, break-
ing up a root is not a standard process in languages whose morphology is 
known to be purely affixal. 
Bendjaballah & Haiden thus make the hypothesis that all languages 
may accommodate skeletal portions that are designated for being the thea-
tre of specific morphological activity. Their analysis of German ablaut is a 
case in point (Bendjaballah & Haiden 2003b). In this perspective, the skele-
ton acquires the role of a central market place that mediates between pho-
nological melody and morphological activity: it filters the morphemic value 
of melodic items.  
A more specific assumption is that only melody which is associated 
to some skeletal position can have morphemic value (i.e., floating pieces of 
melody cannot). That is, melody acquires a morphemic status only when it 
is associated to designated pieces of the skeleton, which project morpho-
syntactic features. Phonological alternations are therefore morpho-
syntactically irrelevant unless they produce a modification of the interpreta-
tion of feature-projecting skeletal chunks. 
Bendjaballah and Haiden's approach is akin to the work that was 
mentioned in the section on LF movement (§ 579). Whether, like Lowen-
stamm's (2008), it requires simultaneous presence of phonological material 
and morpho-syntactic structure is a question that needs to be discussed in 
relation with the homomorphous character of parallel modules that Haiden 
and Bendjaballah assume (e.g. Haiden 2005:166ff).  

612 
Chap 5: Open questions (general) 
One aspect of the notion of modular homomorphematicity is the re-
jection of the morpho-syntactic privilege for concatenation that divides the 
inverted T into a concatenative and two interpretative devices. According to 
the parallel alternative, all modules have concatenative ability, which 
means that "phonology has independent access to the structure-building 
algorithm of the computational system" (Haiden 2005:166). Homomorph-
ous modules, then, need to coordinate their concatenative activity and ex-
change information in order to keep the parallel constructions in line with 
each other. 
 
725  1.3. Conclusion: the baseline of the generative paradigm is modularity 
 
Further discussion would lead too far afield in the frame of this book, 
which only reviews at any significant detail the subset of generative ap-
proaches that follow the inverted T. This restriction ± which however cov-
ers more than the lion share of the landscape ± was implicit during Part I 
and is now made explicit. If one cannot speak of any competition with gen-
erative semantics anymore, the question whether morpho-syntax is the cen-
tral piece of grammatical architecture or not remains pending. 
The take-home message that emerges from this brief excursion is a 
clearer definition of what it means to be generative. It does not necessarily 
mean that morpho-syntax precedes LF/PF: it does not (or rather: did not) in 
generative semantics. And it does not necessarily mean that only morpho-
syntax is able to operate concatenation (Merge): all modules concatenate in 
Jackendoff's parallel perspective. In sum, not all generative approaches to 
the architecture of grammar are syntactico-centristic.  
What being generative does mean, however, is that there are mod-
ules: all options discussed are based on distinct computational systems for 
morpho-syntax, phonology and semantics. This is but a confirmation of the 
deep modular roots that generative thinking has acquired since the 50s and 
Chomsky's participation in the computational movement that implemented 
the ideas of Turing and von Neumann (see § 603). The question of genera-
tive modularity offenders (of which the list was drawn in § 702), then, re-
mains pending. 
 

PF ± a strange hermaphrodite animal 613 
726  2. PF ± a strange hermaphrodite animal 
 
727  2.1. Clean syntax, dirty phonology/PF? 
 
728  2.1.1. Minimalism shrinks syntax 
 
A pervasive effect of the minimalist programme is that a whole lot of phe-
nomena and mechanisms that were held to be syntactic in earlier practice 
are unloaded from syntax. As indicated by its name, the minimalist logic is 
indeed 
 
(286) "to examine every device (principle, idea, etc.) that is employed in charac-
terizing languages to determine to what extent it can be eliminated in favor 
of a principled account in terms of general conditions of computational 
efficiency and the interface condition that the [language] organ has to satisfy 
for it to function at all." Chomsky (2004:106) 
 
This is to say that anything that syntax is supposed to do beyond the 
concatenation of pieces must have an extra-syntactic reason, and the two 
reasons that Chomsky acknowledges are interface conditions ("bare output 
conditions") and computational efficiency. We have come across the latter 
in § 306: derivation by phase is motivated by the suspicion that the compu-
tation of an entire sentence is too complex given the limitations of active 
memory. Sentences are thus computed in successive smaller pieces. 
In Chomsky's biolinguistic approach, language is "perfect" just like 
other natural systems are (in reference to Galileo's "nature is perfect", see 
Chomsky 2004:105, also Chomsky 1995a:221, Jackendoff 1997:19). Pursu-
ing the goal of a "perfect" FLN (faculty of language in the narrow sense, 
Hauser et al. 2002, see § 633), the minimalist programme therefore ambi-
tions to reduce the FLN to just those properties that cannot be derived from 
computational efficiency and constraints imposed by the two interfaces. 
This also implies that LF and PF do not count as really linguistic (§ 639): 
they are imperfect and lie outside of the FLN, which reduces to narrow 
syntax. 
The elimination of conceptually unnecessary devices from syntax 
does not mean that they are simply beamed out of sight into some extra-
grammatical space, though. It means that they are poured into the inter-
faces, i.e. into what is called LF and PF.  
 

614 
Chap 5: Open questions (general) 
729  2.1.2. Minimalism pumps up PF 
 
The minimalist transfer of activity from syntax to the interfaces loads PF 
much more than LF. Under this charge, the status of PF changes quite dra-
matically. While in the classical inverted T that generative grammar has 
lived with since the 60s (§ 86) PF was more or less coextensive with pho-
nology, i.e. the phonological computational system, it is now pumped up 
with a whole lot of operations and items that have got nothing to do with 
what phonologists call phonology. In the minimalist landscape, PF has be-
come "phonology plus something", and as we will see below nobody really 
knows what either the whole or the "something" is.  
Syntacticians are quick and happy to dump all kinds of things into 
the PF-dustbin, but do not care much whether the dustbin is suited to re-
ceive the parcel, or whether the parcel can be handled by those who know 
the dustbin from the inside. That is, PF is often treated as a black box: syn-
tacticians do not look into what actually happens to the parcel when it is 
treated "at PF". The only thing that matters is that "PF" somehow manages 
to do things that syntacticians do not want to do in clinically pure syntax. 
 
730  2.1.3. Dumping into the PF dustbin and hoping that it is big enough 
 
A typical case of syntax-to-PF outsourcing is clitic placement, which is 
traditionally managed in syntax. Boãković (2001) and Franks & Boãković
(2001) for example argue for a PF-based solution: clitics in Bulgarian, Ma-
cedonian and Serbo-Croatian are generated in several locations by the syn-
tax, and then PF "chooses" the copy that is actually pronounced.  
Elaborating on Chomsky's (1993a) copy and delete where only the 
highest copy is pronounced and all others are deleted "at PF", Franks & 
Boãković (2001) propose an analysis whereby  
 
(287) "a chain is pronounced in the head position, with lower copies deleted in PF, 
unless pronunciation in the head position would give rise to a PF violation. 
If the violation can be avoided by pronouncing a lower copy of the chain, 
then the lower copy is pronounced instead of the head of the chain." Franks 
& Boãković (2001:176) 
 
One wonders, then, what a relevant PF violation looks like, and 
whether it has anything to do with phonology. The authors explain the con-
ditioning factor as follows. 
 

PF ± a strange hermaphrodite animal 615 
(288) "This is the well-known Tobler-Mussafia (TM) effect. It results from a pho-
nological difference between the relevant Bg [Bulgarian] and Mac [Mace-
donian] clitics: in Bg these elements are strictly enclitic, whereas in Mac 
they are not. When no nonverbal lexical material that could support the 
clitics occurs in front of the clitics, the verb must precede the clitics in order 
to provide phonological support for them. This 'repair' strategy of pronounc-
ing the verb to the left of the clitics occurs in Bg, but not Mac." Franks & 
Boãković (2001:175) 
 
The PF violation that makes the pronunciation of the highest copy il-
legal thus falls into two components: 1) the fact that in the particular lan-
guage at hand an item is an enclitic, and 2) the fact that in this language 
there is no "repair" strategy which places a word before the enclitic. The 
result is an enclitic without host, which leads to ungrammaticality. 
Looking at this analysis, one wonders about the use of the word 
"phonological": Franks & Boãković say that the effect is based on a "pho-
nological difference", but there is nothing that a phonologist would call 
phonological, or that any phonological theory could manage. Clitichood is 
certainly not anything that is defined in phonology, or that is manipulable 
by phonological computation, and repairs that manipulate entire mor-
phemes are certainly not the result of phonological computation either. 
 
731  2.1.4. The syntacticians' phonology is not what phonologists call phonology 
 
The preceding section has shown that there is quite some confusion around 
the "phonological" causes of what happens "at PF", and the example quoted 
is not isolated. Boãković' (2001) book is called "On the nature of the syn-
tax-phonology interface. Cliticization and related phenomena", but the in-
terested phonologist will not find anything that he would call phonological 
or due to phonological computation in the phenomena or analyses pre-
sented. 
"Deletion at PF" is also popular with pieces that are not involved in a 
chain, and which may be much bigger than simple clitics: the analysis of 
ellipsis and one specific form of this phenomenon, sluicing, may delete 
words, phrases or sometimes entire CPs (e.g. Merchant 2001, Fox & Lasnik 
2003). The standard analysis today is that ellipsis reduces to non-
pronunciation at PF (Gengel 2009). 
It was mentioned that the triggering conditions of Franks & Boãk-
ović' (2001) analysis are called phonological but have got nothing to do 
with phonology. The same is true for the action that is taken at PF: pho-

616 
Chap 5: Open questions (general) 
nologists may perhaps delete features or segments, but certainly not words, 
VPs or CPs. No phonological theory is suited for the manipulation of this 
kind of object, which phonologists look at like an ant looks at a jumbo jet. 
Under the minimalist pressure, PF-sinking of syntactic problems has 
become a natural and unquestioned move over the past decade. Interest-
ingly, though, this trend is by and large confined in syntactic quarters: syn-
tacticians talk about syntactic phenomena and may use the word "phonol-
ogy" in relation with PF, but nothing that phonologists would call phonol-
ogy is involved. In other words, the PF world that takes on more and more 
importance among syntacticians is quite waterproof with respect to phonol-
ogy as conceived of by phonologists.167
The following section documents the ambient confusion around the 
new minimalism-born PF. 
 
732  2.2. Confusion and mistiness: what does PF mean, what does it contain? 
 
When I first heard of PF as a student, I thought that "Phonological Form" 
was meant, and was quite surprised when I learned later on that PF actually 
stands for "Phonetic Form". This is at least the way Chomsky (1995a:2) 
spells out PF. The confusion lingers on in my mind, and I still need to make 
sure I think of phonetics when hearing and talking about PF. Maybe I am 
not the only one who gets confused by the meaning of the P. Chomsky for 
example does not make much difference between phonology and phonetics. 
In the quote under  (289) for instance, phonology is missing, and phonetics 
appears instead. 
 
(289) "We may think of the language, then, as a finitely specified generative pro-
cedure (function) that enumerates an infinite set of SDs [structural descrip-
tions]. Each SD, in turn, specifies the full array of phonetic, semantic, and 
syntactic properties of a particular linguistic expression." Chomsky 
(1995a:14f) 
 
167 As far as I can see, the only phenomenon that sometimes comes up in PF-based 
analyses of syntacticians, and which could qualify for phonological status, is in-
tonation (sentence stress). This is not surprising since intonation is the single 
one phonological phenomenon that syntax is classically concerned with. It is 
not so sure, however, that intonation is the result of any phonological computa-
tion at all (more on this in § 806). 

PF ± a strange hermaphrodite animal 617 
In the quote below, one senses that Chomsky actually means the pa-
rametric variation of phonology, rather than of phonetics: parameter set-
tings are a typical property of the former, but not really of the latter area. 
 
(290) "At the PF level, properties of the language can be readily observed and 
variation is possible within the fixed repertoire of phonetic properties and the 
invariant principles of universal phonetics." Chomsky (1995a:27) 
 
Finally, the confusion is overt in the following quote: if there is any 
distinction between phonology and phonetics at all, syllable structure is a 
property of the former. 
 
(291) "The PF representation π is a string of phonetic primes with syllabic and intona-
tional structure indicated, derived by a computation from σ." Chomsky 
(1995a:35) 
 
The three quotes mentioned are all from the first chapter of The 
Minimalist Program, i.e. actually from a 1993 paper that Chomsky co-
authored with Howard Lasnik. In later chapters of the book, Chomsky does 
make a difference between phonology and phonetics, as shown by the 
quote below. 
 
(292) "Similarly, the phonological component contains no rules to express special 
cases of general properties of universal phonetics or of phonetic representa-
tions." Chomsky (1995a:152) 
 
He now talks about a phonological component, and this component 
seems to be different in kind from phonetics. One may thus incline to con-
clude that phonetics is not part of PF.  
At the outset of chapter four, one reads the following statement, 
which is puzzling in more than one respect. 
 
(293) "Notice that I am sweeping under the rug questions of considerable signifi-
cance, notably, questions about what in the earlier Extended Standard The-
ory (EST) framework were called 'surface effects' on interpretation. These are 
manifold, involving topic-focus and theme-rheme structures, figure-ground 
properties, effects of adjacency and linearity, and many others. Prima facie, 
they seem to involve some additional level or levels internal to the phonologi-
cal component, postmorphology but prephonetic, accessed at the interface along 
with PF (Phonetic Form) and LF (Logical Form)." Chomsky (1995a:220) 
 

618 
Chap 5: Open questions (general) 
It seems to be safe to consider that PF is what Chomsky calls a 
"level", and he again is explicit on the fact that the P means "phonetic". 
One also learns that there is a "phonological component" which is ordered 
after morphology but before phonetics. This component, then, appears to be 
a piece of PF. So far, so good ± but how could this sub-division of PF then 
itself host additional internal levels? In a note to the last sentence under 
 (293), Chomsky states that the phenomena at hand (which are supposed to 
be accommodated by the "additional level or levels internal to the phono-
logical component") cannot be directly done at PF, but could perhaps be 
handled by "elements formed in the course of the mapping of syntactic objects 
to a PF representation." 
 
(294) "The PF level itself is too primitive and unstructured to serve this purpose, but 
elements formed in the course of the mapping of syntactic objects to a PF repre-
sentation might qualify." Chomsky (1995a:379) 
 
It is hard to imagine what kind of item could be at the same time ex-
ternal to PF but internal to the "phonological component", which itself is a 
piece of PF. 
In other writings of Chomsky's, one senses that PF and the "phono-
logical component" are the same thing. 
 
(295) "There are some reasons to suspect that a substantial core of head raising 
processes [«] may fall within the phonological component." Chomsky 
(2001:37) 
 
"'Stylistic' operations might fall within the phonological component."
(Chomsky 2000a:144) 
 
This selection of self-contradictory, puzzling and sometimes cryptic 
statements about PF could probably be pursued and extended to other au-
thors. The purpose of their review is not to point out the inconsistency, but 
the fact that this inconsistency is not innocent: people talk about PF in these 
terms because PF is a misty and ill-defined intermundia. And people may 
get confused as I do about the P and the relationship of the strange PF-
animal with what phonologists call phonology (and what Chomsky proba-
bly refers to as the phonological component). 
 

PF ± a strange hermaphrodite animal 619 
733  2.3. Properties of PF: what kind of animals live in the intermundia? 
 
734  2.3.1. Internal structure of PF 
 
One conclusion of the preceding discussion is that if anything, PF is a het-
erogeneous space. This is what is meant when the literature (namely the 
one related to Distributed Morphology) talks about "the PF branch", rather 
than just about PF. This opens up an entire workspace, indicating that there 
are many things going on "at PF", not just (the phonologists') phonology, 
and not just phonetics. It was mentioned in § 538 that Distributed Morphol-
ogy locates operations such as fission, fusion and impoverishment (which 
are unknown in syntax) in PF, and that PF movement obeys locality condi-
tions that are distinct from the ones that control regular movement in (nar-
row) syntax (§ 580). 
Therefore Pak (2008:26) says that "[t]he PF branch [«] is thus 
viewed as a highly articulated derivational component, which yields a 
number of intermediate structural representations before the final surface 
form is reached." This points to the manifoldness of the PF landscape: a lot 
of things are done, and a lot of different things are done. Like Chomsky and 
much of the literature, Pak does not make explicit whether she means a 
computational system in the sense of a Fodorian module when she talks 
about a "derivational component". The fact that there is a long way to go 
from the upper limit of PF that intersects with (narrow) syntax and its out-
put is illustrated by the interesting term "surface PF" that Pak introduces in 
a footnote. 
 
(296) "The term PF is used to refer both to the derivation along the branch and to 
the surface form produced at the end of the branch; for clarity, I will use 
the term surface PF when this latter meaning is intended." Pak (2008:26, 
note 1, emphasis in original) 
 
735  2.3.2. What happens "at PF" 
 
Let us now look at the kind of operations that syntacticians suppose are 
managed "at PF", i.e. those that do not concern regular phonology and, if 
included in PF, regular phonetics. The survey below of course does not 
ambition to be exhaustive: new things are constantly added, and as a pho-
nologist my visibility is rather poor. This being said, the most typical thing 
that syntacticians want PF to do is certainly deletion (of copies, or involv-
ing ellipsis and sluicing). In the previous sections we have also come across 

620 
Chap 5: Open questions (general) 
other candidates for a management at PF: topic-focus, theme-rheme, figure-
ground, linearity, head movement and stylistic operations.  
Richards (2004) adds an interesting hypothesis regarding the limita-
tions of PF action. 
 
(297) "The assumption that PF cannot drive syntactic operations ties in with the 
more general thesis, presented in section 2.5.1.3, that PF can only operate 
with the structures that the syntax provides to it: in particular, PF cannot 
build extra structure, that is, create new positions not licensed during the 
syntactic part of the derivation." Richards (2004:12, note 2) 
 
Hence PF movement for example can move phonological terminals 
around, but only to positions that are inherited by syntax. 
As was mentioned, Distributed Morphology is also concerned with 
the PF branch: this is where morphology-specific operations such as allo-
morphy, fission, fusion and impoverishment take place. Summarising Em-
bick & Noyer (2001, 2007), Pak (2008) provides a list of operations that 
are assumed to take place at PF in order to derive "the surface form at the 
end of the branch [which] clearly has very different properties from the 
syntactic structure" (Pak 2008:26). 
 
(298) "PF operations (unordered list): 
 
a. Structural readjustments, a limited set of movement, rebracketing, and 
deletion/insertion operations whose surface effects are often recognized 
as 'syntax-morphology mismatches' 
 
b. Vocabulary insertion, which adds phonological content to function 
morphemes 
c. Linearization operations, which establish linear order between/across 
structures" 
Pak (2008:26, emphasis in original) 
 
Under (298a), one senses that DM is aware of the fact that additional 
movement, deletion, insertion etc. is a source of dramatic overgeneration 
(see § 580), and therefore prophylactically talks about "a limited set" of 
operations. As far as I can see, though, nobody knows in which way exactly 
the operations "at PF" are limited, let alone the reason for such limitations. 
Linearisation (and its interleaving with phonology) is further dis-
cussed in § 741 below. Its occurrence at (the beginning of) PF is largely 
consensual also outside of DM quarters (except in Kayne's 1994 system). 
 

PF ± a strange hermaphrodite animal 621 
736  2.4. Trying to make sense of PF from the modular point of view 
 
737  2.4.1. PF is a cover term for a number of serially ordered computational 
systems 
 
Let us now try to make sense of PF and its internal structure from the 
modular point of view. This amounts to identifying individual computa-
tional systems that qualify for modular status, i.e. are domain specific. We 
have seen that various designations are used in the literature in order to 
refer to PF as a whole, or to its sub-systems: level, (phonological) compo-
nent, module (Pak 2008:6, 29 calls the entire PF branch the "PF module"). 
Authors typically do not specify, though, whether they talk about computa-
tional systems, i.e. input-output systems, or just informally about a func-
tional entity. 
Let us start with two points that are undisputed: 1) (narrow) syntax is 
a computational system with modular status of its own, and 2) the input to 
PF is created by the spell-out of (narrow) syntactic structure. Another non-
negotiable item is a phonology, i.e. a computational system with modular 
status that computes what phonologists call phonology. This system is do-
main specific because it works with its own proprietary vocabulary (labial-
ity, occlusion etc.) which is distinct from other linguistic vocabulary. On 
traditional (generative) assumptions, this list is rounded off by a distinct 
computational system that is in charge of phonetics, and which is ordered 
after phonology. There is a fair amount of debate, especially in the OT lit-
erature, regarding the question whether phonetics and phonology are 
merged into one single computational system, i.e. one single constraint 
hierarchy (Kingston 2007 for example provides an informed overview). 
This is an expression of OT's scrambling trope (§§ 28, 528). For the sake of 
exposition, below a distinct computational system appears for phonetics, 
but nothing hinges on that. 
We are thus left with a derivational sequence as under  (299) below. 
 

622 
Chap 5: Open questions (general) 
(299) what PF is made of 
 
(narrow) syntax 
(computation A) 
 
spell-out 
vocabulary insertion, linearisation, PF movement, 
rebracketing, deletion, insertion, fission, fusion, 
impoverishment 
(computation B) 
 
phonology 
(computation C) 
 
PF 
phonetics 
(computation D) 
 
PF thus consists of three independent and serially ordered computa-
tional systems. So far this view would be consistent with modularity.  
 
738  2.4.2. The minimalism-born intermundia violates domain specificity 
 
It was already pointed out in § 580, however, that there is trouble with com-
putation B, i.e. the misty intermundia that was created by minimalism 
where all those syntactic-looking things are managed that are rejected from 
clean narrow syntax. Computation B is past vocabulary insertion; this 
means that phonological material is present and, according to PF move-
ment, forms the terminal elements of the morpho-syntactic tree, which is 
also still available.  
As was shown in § 580, however, this cannot be reconciled with do-
main specificity: computation B would have to access the morpho-syntactic 
labels of the tree, the tree geometrics and phonological vocabulary at the 
same time. Also, the tree labels would be the projection of nothing: on 
standard assumptions hierarchical structure is a projection of terminal ele-
ments. In a PF movement tree, however, phonological terminals would 
cohabitate with morpho-syntactic structure and labels: this does not make 
any sense. Computation B is thus a modular alien. 

PF ± a strange hermaphrodite animal 623 
Another issue is linearisation: one wonders what it means to linearise 
upon spell-out from (narrow) syntax, but to leave the tree in place, and to 
allow for (PF) movement along its structure. A linearised string does not 
look like a tree, does it? Or does linearisation in fact take place at the end 
of computation B when PF movement has applied and a linear input to 
computation C, the phonologists' phonology, needs to be created? Lineari-
sation is examined at greater length in § 741 below. One thing is for sure, 
though: what phonologists call phonology requires a linear string as an 
input. 
Finally, one could think of the whole of PF, i.e. computations B, C 
and D, as a single macro-module which accommodates a number of sub-
modules. This is visibly what Pak (2008:6, 29) means when she calls the 
entire PF branch a "PF module". Nested computation (or computational 
systems), however, should be excluded in a modular environment: it vio-
lates (informational) encapsulation (see § 610, also § 632). 
 
739  2.4.3. Mixing phonology and the intermundia 
 
Minimalism-created intermundia, i.e. computation B, is already violating 
domain specificity by itself. There are proposals that go even further by 
mixing computation B with computation C, the real phonology. It was al-
ready mentioned in § 580 that DM, through PF movement, promotes a radi-
cal form of direct syntax. It was also mentioned that Pak (2008:42ff, 60ff) 
sets out to do away with the Prosodic Hierarchy: she correctly argues that 
prosodic constituency is superfluous if phonology has direct access to mor-
pho-syntactic information. 
In fact the core of her proposal is a much stronger violation of modu-
larity: she argues that the action of computation C (phonology) is serially 
interleaved with computation B (the intermundia). 
 
(300) "I propose that phonological rules apply at various points in the PF deriva-
tion. Specifically, phonological rules are interleaved with different kinds of 
linearization procedures, which apply in PF in order to convert abstract 
hierarchical structures into fully linearized strings." Pak (2008:6, emphasis 
in original) 
 
"The hypothesis pursued in this dissertation is that phonological rules may 
also use Concatenation statements ± as well as other kinds of linearization 
statements ± as their domains. In other words, phonological rules are inter-
leaved with linearization operations." Pak (2008:28, emphasis in original) 

624 
Chap 5: Open questions (general) 
DM thus turns out to be a strong modularity offender (see § 704). 
Linearisation is further discussed in § 741 below. 
 
740  2.4.4. The internal structure of the intermundia: two distinct derivational 
stages, morphosyntax and morphophonology (Idsardi & Raimy forth) 
 
Idsardi & Raimy (forth) argue that what appears as the intermundia under 
 (299) (computation B) in fact falls into two distinct and serially ordered 
systems as under  (301). 
 
(301) internal structure of computation B according to Idsardi & Raimy (forth) 
 
properties 
 
computational 
system 
 
hier-
archy
adja-
cency
linear 
order
phon. 
content
directed 
graphs 
 
narrow syntax 
(computation A) 
 
+
±
±
±
±
linearisation 1 
immobilisation
morphosyntax 
(computation B1)
+
+
±
±
±
linearisation 2 
spell-out 
 
 
 
 
 
 
morphophonology
(computation B2)
±
+
±
+
+
linearisation 3 
serialisation 
 
phonology 
(computation C) 
 
±
+
+
+
±
phonetics 
(computation D) 
 
Their proposal is linearisation-driven: the two additional stages cor-
respond to the idea that linearisation is a three-step operation: it falls into 
what they call immobilisation, spell-out and serialisation. 
Idsardi & Raimy consistently use the word "module" in order to refer 
to their systems, but they do not address the question which kind of pro-
prietary vocabulary is used by each one of their computational systems. 
This is understandable since for them the need to further divide computa-

PF ± a strange hermaphrodite animal 625 
tion B stems from the idea that linearisation is progressive: each step in 
linearisation, then, must be a computational system by itself. 
It may be noted that the minimal merit of Idsardi & Raimy's system 
is that they individuate the "real" phonology ± i.e. what phonologists call 
phonology ± from the misty intermundia "PF": their phonology (computa-
tion C under  (301)) is distinct from computation B (or B1, B2), and they are 
explicit on the fact that we are facing distinct modules. This may not be 
unrelated to the fact that (unlike authors from syntactic or DM quarters) 
they are phonologists and look at the misty "PF branch" from the phonolo-
gist's perspective. 
At variance with earlier writings of Raimy on directed graphs 
(Raimy 2000a,b, 2003, to be discussed in § 746), Idsardi & Raimy (forth) 
call "phonology" (computation C under  (301)) what appeared as phonetics 
before, i.e. the stage where directed graphs with loops (non-asymmetric 
representations as Raimy calls them) have been linearised to a strictly lin-
ear order of items without loops. Hence what Raimy called phonology (rep-
resentations with loops) before now appears as morphophonology, and 
earlier phonetics (representations without loops) is now phonology. 
Finally, for some reason Idsardi & Raimy restrict the label "PF" to 
"narrow" phonology, i.e. computation C under  (301).  
 
(302) "For the purposes of this paper, we will equate the phonological represen-
tation with PF and assume that there are further complex transformations 
in the phonetic modules which result in a representation interpretable at the 
SM [sensory-motor] interface." Idsardi & Raimy (forth:2) 
 
This adds confusion to the overall landscape where PF is typically 
held to encompass everything after narrow syntax (the "PF branch"). 
Idsardi & Raimy's system is born from Raimy's (2000a,b) theory of 
(morpho-)phonology that is based on the analysis of reduplication (and 
infixation), and as was mentioned it is linearisation-driven. Their backdrop 
is thus significantly different from the one of Distributed Morphology, 
where the motivation for inquiring on the internal structure of the PF-
intermundia is the accommodation of operations such as allomorphy, fis-
sion, fusion and PF movement. It is therefore not really surprising that the 
results are quite different. For example, PF movement cannot be accommo-
dated by Idsardi & Raimy's system: there is no single computational system 
under  (301) that allows phonological content to cohabitate with hierarchical 
structure. The shift from computation B1 (morphosyntax) to computation B2
(morphophonology) eliminates hierarchical structure and introduces phono-

626 
Chap 5: Open questions (general) 
logical content. In DM terminology, this is where vocabulary insertion 
takes place. 
 
741  2.5. Linearisation 
 
742  2.5.1. Introduction: no business of phonology 
 
A question that was not addressed at all in Part I but which is constantly 
mentioned on the preceding pages is the linear order of the phonological 
string, as opposed to the non-linear character of syntax. The reason why 
linearisation was not discussed in Part I is simply that it is no business of 
phonologists ± but as was mentioned before, theories of the interface be-
tween morpho-syntax and phonology are made by phonologists (with the 
half-exception of Distributed Morphology). What everybody agrees upon is 
the fact that the input to phonological computation is a linear string.168 Or, 
in other words, phonological computation does not create linearity. This is 
why phonologists never talk about linearity and linearisation: they work on 
linear strings and thus take linearity for granted. 
Today everybody agrees that some mechanism is required which 
transforms the hierarchical morpho-syntactic structure (the tree) into a lin-
ear string. The question is where exactly this mechanism is accommodated, 
how it works and eventually into how many sub-components it falls. 
Roughly speaking, Kayne's (1994) LCA (Linear Correspondence Axiom) 
places linearisation in narrow syntax, while all other proposals (which typi-
cally build on the LCA) locate this operation in PF (where "in PF" opens a 
rather large array of possibilities, as we have seen in § 733). 
 
743  2.5.2. In minimalist times: no business of syntax either 
 
In syntax, linearity was long taken to follow from syntactic constituent 
structure: word order is a function of constituent order. This was the case 
until (and including) GB: phrase structure rules were parameterised and 
responsible for language-specific variation in word order. In a language 
where prepositions precede nouns, the rule was PP →P, NP, while in a 
 
168 But even this notion needs to be further defined: we will see below (and have 
already seen in § 740) that Raimy's (2003) and Idsardi & Raimy's (forth) system 
allows for different degrees of linearisation of the string. 

PF ± a strange hermaphrodite animal 627 
language where the opposite order is observed, the rule PP →NP, P was 
instrumental. Hence the difference between right-branching languages such 
as English where heads precede their complements and left-branching lan-
guages like Japanese where the reverse order is found is managed by a pa-
rameter setting, the head parameter.
In the minimalist perspective where trees are constructed by Merge 
and hence phrase structure rules are eliminated, a different means for deriv-
ing linear order needs to be found. Estranging syntax from linear order ties 
in with the observation that syntactic generalisations are about hierarchical 
organisation (command and dominance relations), not about linear order. 
Therefore Chomsky (1995a:334) concludes that syntax has got nothing to 
do with linearity, not any more than LF: linearity is only relevant for pho-
nology. That is, it is imposed upon the linguistic system by external condi-
tions of language use: linearity is the result of the constraints that follow 
from the transmission of human language whereby speech unfolds in a 
temporal sequence. 
 
744  2.5.3. Both syntax-internal and syntax-external linearisation is minimalism-
compatible 
 
Given that linear order is imposed upon language by a non-linguistic con-
straint, Chomsky (1995a:335) welcomes Kayne's (1994) antisymmetry in a 
minimalist perspective. Kayne's idea is to derive linear order in the syntax 
by leftward movement: at the end of all movement operations, the highest 
item is the leftmost in the linear order, and so on. On Kayne's take, this is 
true for all languages: SVO is the universal order underlyingly, and lan-
guages like Japanese with an overt SOV order are derived by leftward 
movement. 
Incorporating the mechanism that creates linear order into the syntax 
may at first appear contradictory with the minimalist insight that syntax and 
linear order are independent. Chomsky (1995a:335), however, argues that 
syntax-internal linearisation is a prototypical implementation of minimalist 
thinking whose headstone is to reduce syntactic representations and compu-
tation to "bare output conditions". Hence linearity, imposed from the out-
side by language use, marshals syntax: movement needs to be carried out in 
order to satisfy its requirements. 
Chomsky therefore writes that Kayne's perspective is "very much in 
the spirit of the Minimalist Program and consistent with the speculation 
that the essential character of CHL [the computational system of human 

628 
Chap 5: Open questions (general) 
language] is independent of the sensorimotor interface" (Chomsky 
1995a:335). A few pages later, however, he places the LCA outside of (nar-
row) syntax, in PF: "we take the LCA to be a principle of the phonological 
component that applies to the output of Morphology" (Chomsky 
1995a:340, note that Chomsky operates with the traditional split between 
(narrow) syntax and morphology). 
Another line of attack that follows Kayne's track is Fox & Pesetsky's 
(2004) analysis whereby successive cyclic movement (in narrow syntax) is 
derived from linearity requirements. That is, just like in Kayne's system and 
in line with the minimalist philosophy, syntax-internal movement is moti-
vated by a necessity of a syntax-external cognitive system. The key idea of 
Fox & Pesetsky is that there is a mechanism that controls the result of lin-
earisation at every phase and compares it with the linear order achieved at 
previous phases. In case there is a mismatch between former and current 
linear order, the derivation crashes. This is what Fox & Pesetsky call order 
preservation: linear order must be the same at every spell-out of every 
phase. For the sake of illustration, consider the example under  (303) below 
(from Fox & Pesetsky 2004:5). 
 
(303) [To whom will he [__say [CP __ that Mary [VP __ gave the book __]]]]? 
 
Did the movement skip Spec,VP and went directly to Spec,CP as in-
dicated, and if VP is a phase head, Fox & Pesetsky argue, the derivation 
will crash at PF since the result of linearisation in the VP phase (where the 
displaced item remains in situ) is different from the linearised string after 
the CP phase (where nothing will be left in situ). By contrast, if movement 
goes through Spec,VP, the VP will be linearised with the displaced item in 
Spec,VP at the lower phase as well as at all other phases: order preservation 
is satisfied. Therefore, Fox & Pesetsky (2004:8) argue, "[a]n architecture of 
this sort will in general force successive cyclicity when movement crosses a 
Spell-out domain boundary." 
In sum, then, minimalist principles seem to be able to be used in or-
der to locate linearisation in either (narrow) syntax or PF. Or rather, the 
competition between both options cannot be refereed on minimalist 
grounds. 
 

PF ± a strange hermaphrodite animal 629 
745  2.5.4. Everybody but Kayne does linearisation "at PF" 
 
Work in Kayne's original perspective set aside, it appears that the field has 
by and large followed Chomsky's indication that linearisation occurs "at 
PF".  
It seems to me, though, that the question is treated without much ar-
gument in the literature: people acknowledge the existence of Kayne's 
LCA, but then do linearisation "at PF" without saying why it should or 
could not be done by movement in (narrow) syntax.169 One argument is 
provided by Richards (2004): Kayne's LCA is based on c-command, i.e. on 
an asymmetric relationship between the items that are to be linearised.  
 
(304) "Linear Correspondence Axiom 
If α asymmetrically c-commands β then (the terminals dominated by) α
precede(s) (the terminals dominated by) β" version of the LCA given by 
Richards (2004:11) 
 
What about cases of mutual c-command, then? Richards argues that 
the minimalist Bare Phrase Structure, which eliminates trivial, i.e. vacuous 
or unary-branching projections, regularly produces this kind of structure, 
for example in [John [ate it]] where ate and it are sisters and c-command 
each other. Kayne's LCA fails when trying to linearise this kind of struc-
ture. Richards therefore concludes that  
 
(305) "the LCA cannot be a constraint on phrase-markers themselves, i.e. a prop-
erty of Narrow Syntax, but must be a linearization strategy operative only 
after Spell-Out in the mapping of syntactic hierarchy onto phonotemporal 
order (cf. MP [Chomsky 1995a]: 340: 'We take the LCA to be a principle 
of the phonological component that applies to the output of Morphology'). 
This recasting of the LCA as a PF-mapping strategy (cf. the operation 
Linearize of Nunes 1999) conforms to the general principle that the 'hori-
zontal' dimension of time and sequential ordering is relevant only in the 
phonological component, so that the syntactic component of CHL [the com-
 
169 E.g. Bobaljik (2002) and Embick & Noyer (2001, 2007), discussed below, who 
do linearisation at PF "by hypothesis" or "assume" that it occurs at PF: 
"[a]ssuming that linear order is not included in the syntactic representation, PF 
operations, because they are responsible for creating the interface level that 
mediates between syntax and the articulatory/perceptual systems, must at the 
very minimum be responsible for linearizing hierarchical structures" (Embick 
& Noyer 2007:293). Hence Kayne's syntax-internal option is dismissed without 
argument or discussion. 

630 
Chap 5: Open questions (general) 
putational system of human language] deals only in the 'vertical' dimension 
of hierarchical relations." Richards (2004:12, emphasis in original) 
 
Richards (2004:23) then goes on to rehabilitate the old head parame-
ter of GB in order to make it a parameter of the PF-located LCA. Based on 
Epstein et al.'s (1998:139ff) Precedence Resolution Principle, Richards 
(2004, chapters 2 and 4, 2007a) proposes a sisterhood-based linearisation 
strategy: if a c-command relation translates to precedence at PF, heads and 
complements provide contradictory instructions to PF since sisters 
c-command each other: the head must precede the complement, but the 
complement must also precede the head. Which precedence will be chosen, 
Epstein et al. and Richards argue, is a matter of which head-complement 
directionality is deleted. This is what Richards (2004, 2007a) calls desym-
metrisation. While Esptein et al. (1998) apply this mechanism only to ex-
ternal Merge, Richards extends it to internal Merge, thereby promoting it to 
a parameter that governs the entire language. Parameterised desymmetrisa-
tion is then the old head parameter based on the LCA, but located in PF. 
Other syntax-based linearisation strategies also typically implement 
the head parameter in one way or another. Bobaljik (2002:216) for example 
says that "it should be clear that I am espousing a more or less traditional 
view of headedness parameters, for instance, that the German V' is head-
final while the English V' is head-initial; this is the information encoded in 
the precedence rules."  
Bobaljik's precedence rules are "a procedure that maps each node to 
an ordered pair: [X →Y] or [Y →X] (where the arrow is to be read as 
'precedes')" (Bobaljik 2002:213). He then shows how a German SOV and 
an English SVO order can be derived from the same syntactic structure 
when reverse precedence rules are applied to certain nodes (the head pa-
rameter): German will have [I' VP →Infl] and [VP DP2 →V], while English 
accommodates [I' Infl →VP] and [VP V →DP2]. On Bobaljik's count, thus, 
each language possesses a language-specific set of precedence rules (that 
look much like good old phrase structure rules, except that there is only one 
item to the right of the arrow). 
In Bobaljik's system, this all happens upon spell-out from (narrow) 
syntax to PF, whereby the spell-out process falls into four distinct opera-
tions (which Bobaljik 2002:214, note 16 calls "components"): "a) assign-
ment of precedence conditions to syntactic nodes [the precedence rules 
mentioned], b) chain reduction (= trace or copy deletion), c) conversion to 
linear string of X°s, d) vocabulary insertion" (Bobaljik 2002:214). 

PF ± a strange hermaphrodite animal 631 
The same picture is found in DM quarters. Embick & Noyer (2001, 
2007) and Embick (2007) hold that linearisation is concomitant with vo-
cabulary insertion. 
 
(306) "By hypothesis, linear ordering is not a property of syntactic representa-
tions but is imposed at PF in virtue of the requirement that speech be in-
stantiated in time (see Sproat 1985). It is therefore natural to assume that 
linear ordering is imposed on a phrase marker at the point in the derivation 
when phonological information is inserted, that is, at Vocabulary Insertion.
(8) The Late Linearization Hypothesis 
The elements of a phrase marker are linearized at Vocabulary Insertion." 
Embick & Noyer (2001:562, emphasis in original) 
 
Embick & Noyer work with a notational variant of Bobaljik's prece-
dence rules which they call "Lin" (or the reverse: Bobaljik's precedence 
rules are a notational variant of Lin):  
 
(307) "linear order is a binary operator ± represented by '*' ± imposed by an op-
eration Lin:  
 
Lin [X Y] →(X*Y) or (Y*X) 
 
This relationship is one of immediate (left-)adjacency; subsequent steps 
concatenate terminal nodes. Other types of conditions might be imposed by 
distinct linearization operations." (Embick & Noyer 2007:294). 
 
Embick & Noyer thus cut linearisation into (at least) two distinct op-
erations, Lin and Concatenate (see Pak 2008:26ff for a summary). The lin-
earisation procedures reviewed share the idea that linearisation in fact falls 
into a number of different operations that are serially ordered: (at least) two 
with Embick & Noyer (2001, 2007), three with Idsardi & Raimy (forth) 
(immobilisation, spell-out and serialisation, § 740), four with Bobaljik 
(2002) (precedence conditions, chain reduction, linearisation of X°s, vo-
cabulary insertion). 
 
746  2.5.5. Linearisation in phonology in order to derive phonetics (Raimy)? 
 
Raimy (2000a,b, 2003) proposes a view on linearisation that is quite differ-
ent from what we have seen thus far: he looks at the issue through a phono-
logical, rather than through a syntactic lens. Raimy's basic idea is that 

632 
Chap 5: Open questions (general) 
precedence relationships must be explicitly noted in all phonological repre-
sentations. Linear order is implicit in the standard graphic notation: "kæt" 
(representing cat, the word used for the sake of illustration by Raimy) for 
example reads "k before æ before t", and the same is true for x-slots in an 
autosegmental representation. Raimy proposes to make this explicit and to 
note "# →k →æ →t →%" instead (where # indicates the beginning of 
the linear string, and % its end). He calls the result a directed graph.
What is this good for if the graphic material added can be deduced 
from "kæt" and is therefore fully redundant? Raimy argues that there are 
cases where arrows actually represent morphological information: morpho-
logical computation is one that adds precedence relationships, i.e. arrows, 
to lexical material. The operation is trivial when prefixes and suffixes are 
concatenated, but involves the addition of "loops" within a root in case of 
reduplication and infixation. A process whereby "kæt" is entirely redupli-
cated, producing "kætkæt", thus boils down to the addition of an arrow that 
originates in the t and points to the k, as shown under  (308) below. 
 
(308) linearisation of loop-including representations 
 
a.  
# →k →æ →t →%
b. # →k →æ →t →k →æ →t →%
The loop under (308a) thus represents the morphological operation 
of reduplication. The resulting structure (which Raimy calls non-
asymmetrical) is then spelled out into a strictly linear string (an asymmetri-
cal structure) as under (308b): "[l]inearization eliminates non-asymmetrical 
precedence structures through repetition of segments which preserves the 
overall organization of a precedence structure while not causing problems 
of interpretation for the phonetics module" (Raimy 2003:133). The "prob-
lems of interpretation" that Raimy talks about are the loops: he assumes 
that phonology can live with loop-containing representations, but phonetics 
cannot ± here a fully linearised string is needed. 
In sum, then, phonological representations are only partially linear 
(loops are non-linear elements); exactly analogous to the relationship be-
tween (narrow) syntax and PF, bare output conditions ± the requirement of 
fully linearised strings at the phonetic level ± provoke a spell-out. 
 
(309) "Analogous to the syntactic LCA (Kayne 1994), phonology contains a 
linearization process which ensures that representations have asymmetrical
precedence structures and are thus interpretable at the phonetics interface. 

PF ± a strange hermaphrodite animal 633 
Linearization in phonology repeats segments within a 'loop' in order to 
eliminate [non-]asymmetrical precedence relations." Raimy (2003:132, 
emphasis in original; obviously Raimy means to say non-asymmetrical in 
the last line, the absence of the non- is an error) 
 
The operation that adds arrows to strings needs to "know" where to 
place the origin and the endpoint (anchor points). Adopting Raimy's di-
rected graphs, Samuels (2009a:147ff) has studied the cross-linguistic varia-
tion of infixation in order to determine what kind of information the arrow-
placing algorithm needs to be able to interpret. The list of anchor points 
that infixes look at in order to determine their landing site falls into two 
categories: edge-oriented and prominence-oriented. For the left edge for 
example, documented situations are "after the first consonant (or consonant 
cluster)", "after the first vowel", "after the first syllable" and "after the sec-
ond consonant". Prominence-based attractors are stressed vowels, stressed 
syllables or stressed feet. 
An example discussed by Samuels (2009a:179ff) is Tzeltal (Maya) 
intransitivisation whereby a verb is made intransitive by infixing 
an -h- after the first vowel: compare puk "to divide among" with pu-h-k "to 
spread the word", and kuč "to carry" with ku-h-č "to endure". The represen-
tation of this operation with directed graphs is as under  (310) below. 
 
(310) 
h
# →p →u →k →%
As was mentioned in § 740, Raimy has changed the labels of his sys-
tem since 2003: in Idsardi & Raimy (forth), he calls loop-containing repre-
sentations morphophonology (instead of phonology), and representations 
from which loops have been eliminated phonology (instead of phonetics). 
This leaves the workings of his system unaffected, but does away with the 
idea that phonology can handle non-linear structure. That is, like all other 
approaches, the relabelled version of directed graphs holds that the input to 
"true" phonological computation, i.e. the one that phonologists call phonol-
ogy and from which concatenation is absent, is strictly linear. 
 
747  2.6. Conclusion: a minimalism-born monster 
 
PF is an ex nihilo creation of minimalism: until the mid-90s PF was coex-
tensive with phonology, but since then adds an ill-defined intermundia be-

634 
Chap 5: Open questions (general) 
tween (narrow) syntax and "true" phonology, i.e. what phonologists call 
phonology. Today one is forced to talk about "true" phonology or "what 
phonologists call phonology" because there is a great amount of confusion 
around the word phonology. Syntacticians want a whole lot of things to be 
"phonological" in order to get rid of them: clean syntax, dirty phonology. 
Most of the things that are called "phonological" in the syntactic literature 
where phenomena are dumped into the PF dustbin, though, are nothing that 
phonologists are familiar with or could handle. 
While the upper limit of PF is clearly defined (PF is created by spell-
out from (narrow) syntax), its lower limit and eventual internal structure are 
murky. It is consensual that phonological material is present as soon as PF 
structure is created: vocabulary insertion occurs at spell-out. What happens 
then, though, is left misty in the literature: a lot of operations that have got 
nothing to do with phonology, and then, at some point, "true" phonology. 
Idsardi & Raimy (forth) set aside (they are phonologists), I could not find a 
single explicit mention that what phonologists call phonology is a distinct 
computational system whose input must be a linear string that does not 
contain any morpho-syntactic arboreal structure anymore. When talking to 
syntacticians and asking the question where "true" phonology is in the 
wafting PF body, if any, one often hears that there must be a clearly distinct 
phonological system somewhere further down the road when all the 
pseudo-syntactic labour is done ± but syntacticians are then unable to name 
a written source where this is made explicit. 
When one tries to make sense of PF in terms of domain-specific 
computational systems, a separate (and "true") phonology (plus eventually 
a phonetic system) can be identified, but an alien intermundia is left be-
tween spell-out and phonology (computation B under  (299)). This inter-
mundia cannot be a module because it mixes morpho-syntactic and phono-
logical vocabulary. It also violates another fundamental principle of hierar-
chical structure: the nodes of the tree are projections of nothing, in any case 
not of the terminals, which are phonological.  
Finally, linearisation is also unclear: it seems to be consensual 
(Kayne 1994 set aside) that it occurs upon spell-out and vocabulary inser-
tion, but the mechanisms that are available on the market (Richards 2004, 
2007a set aside) are based on speculation, rather than on data and/or analy-
sis. Also, they reproduce the traditional head parameter in one way or an-
other: instead of being linearised by phrase structure rules like in the times 
of GB, sisters in the tree are now linearised by linearisation statements 
(called precedence rules etc.) in PF. 

The balance of procedural and representational communication 635 
The strangest animal in the PF zoo (which everybody seems to want 
to restrict, but nobody says what exactly may and what may not be done at 
PF) is certainly PF movement. One issue is linearisation, which is supposed 
to occur at spell-out, that is before PF movement. But what does it mean to 
"linearise" when the output of "linearisation" is a not a linear, but an arbo-
real structure along which items continue to be displaced? And how is a 
truly linear string created at the end of PF movement when "true" phonol-
ogy is fed? After spell-out from (narrow) syntax, is there a second spell-out 
mechanism? 
All these questions, and foremost the massive violation of modularity 
by the intermundia computation B, raise the question what the whole PF 
business really buys us: a clean syntax, but a lot of trouble "at PF". Is it 
really worthwhile to move undesirable phenomena out of sight of syntacti-
cians (and of phonologists) into an ill-defined buffer where established 
principles of linguistic analysis do not hold? Dumping them into PF is not 
analysing or solving them, and being allowed to analyse them with all 
kinds of ad hoc mechanisms that are unheard of elsewhere may turn out to 
be a Pyrrhic victory rather than anything else. 
 
748  3. The balance of procedural and representational communication 
 
749  3.1. Which channel for which phenomenon? 
 
Given an interface phenomenon, i.e. a phonological process that is condi-
tioned by extra-phonological information, is there a way to know whether 
the effect is due procedural or representational communication with mor-
pho-syntax? If so, what kind of diagnostics allows us to find out about the 
distribution of the two interface mechanisms? Is there a class of phenomena 
that can only be done procedurally, and another class which requires a rep-
resentational solution? And are there phenomena that can have both proce-
dural and representational analyses? 
These are questions that one is tempted to ask when Interface Dual-
ism is taken seriously. Even though all theories of the interface provide for 
a procedural and a representational way to talk to phonology (with two 
exceptions, see § 683), the question of the balance between procedural and 
representational communication has never really been debated as far as I 
can see, and workable answers have not been generated. One notable ex-
ception is on record, though: the discussion regarding the illegitimacy of 
Lexical Phonology in presence of representational solutions that build on 

636 
Chap 5: Open questions (general) 
prosodic constituency, which could be extended to the area below the word 
(see § 429, Inkelas' 1990 prosodic constituency in the lexicon). 
 
750  3.2. Prosodic Phonology tries to get away with peaceful coexistence and/or 
random distribution 
 
As was mentioned in § 441, peaceful coexistence, the "official" attitude of 
Prosodic Phonology, is a non-answer that tries to sweep the issue under the 
rug. This being said, Nespor & Vogel (1986) are to be credited for at least 
having tried to define a set of phenomena that is taken care of by the proce-
dural mechanism, as opposed to another type which is due to representa-
tional communication (see § 435). According to them, the critical contrast is 
between "purely phonological" rules and those that make "reference to 
morphological structure and/or specific morphological elements". It was 
shown in §§ 437ff that this distinction is not operative: it is unable to de-
lineate two distinct sets of interface phenomena. 
Another contemporary point of view is expressed by Rubach & Booij 
(1984 et passim), who simply give up on any attempt to answer the ques-
tion (see § 440): below the word level, interface phenomena are due to ei-
ther procedural or representational devices, and there is no principle that 
defines which phenomena use which strategy. That is, Lexical Phonology 
and Prosodic Phonology are both candidates for managing everything that 
is going on below the word level; whether one or the other comes to bear is 
random and unimportant. 
 
751  3.3. Random use of both channels is typical (and tacit), but it may be 
doubted that this is the right way to go 
 
In practice, random use of whatever channel suits the analysis is actually 
the way that basically all interface theories that we have come across be-
have; the only difference with respect to Rubach & Booij is that the random 
application of procedural and representational solutions remains unre-
flected (except in Stratal OT, see §§ 490f). This is true for the division of 
labour between the Transformational Cycle and boundaries in SPE as much 
as for the example that was mentioned in § 130: the move from a represen-
tational to a procedural management of word boundaries when autoseg-
mental syllable structure was introduced seems to have gone entirely unno-
ticed. 

Morpho-syntactic structure may, but labels may not bear on phonology 637 
A random division of labour between procedural and representational 
devices at the interface seems implausible, though. Over the past years 
while working on the book, I have tried to establish an inventory and a 
classification of interface phenomena in order to see whether generalisa-
tions emerge: is there a group that has only been analysed procedurally and 
that could not be done representationally? Is there a group with the opposite 
orientation? And perhaps one where procedural and representational analy-
ses compete? 
A number of conference presentations have treated this question 
(Scheer 2005, 2006a,b, Newell & Scheer 2007), and the result was origi-
nally meant to be included here. Facing the complexity of the task, though, 
I have given up on the project, at least in the frame of this book (except for 
a broad direction, procedural first, which is briefly discussed in § 320). I am 
convinced that there is a rationale according to which interface phenomena 
fall into a procedural and a representational group (and eventually one more 
where both mechanisms are applicable in principle). 
A clearly defined class of interface events that was discussed as such 
all through Part I are affix class-based phenomena. My best guess for these 
is that they are only procedural. That is, theories such as Lexical Phonology 
that recur to a representational crutch (brackets for level 2 rules, see § 166) 
are on the wrong track. 
The evaluation of this claim requires further study. And also, the 
awareness of interface theories that the balance of procedural and represen-
tational solutions for interface phenomena is a relevant issue at all certainly 
needs to be sharpened. 
 
752  4. Morpho-syntactic structure may, but content (labels) may not bear 
on phonology 
 
The idea that geometric properties of the morpho-syntactic tree may influ-
ence phonology, while morpho-syntactic features (the basic vocabulary of 
the module) and projections thereof (the node labels) may not, was first met 
in the discussion of Prosodic Phonology (§ 398). Observations that led to 
this hypothesis go back to Selkirk (1974) and Rotenberg (1978:111ff) and 
have been taken up in Prosodic Phonology (relevant literature is discussed 
in § 398). 
The generalisation makes sense from the modular perspective since 
(domain specific, see § 640) vocabulary of a given module cannot be parsed 
by other modules; on the other hand, structure is not handicapped in the 
same way (see § 652 for the difference between vocabulary and structure). 

638 
Chap 5: Open questions (general) 
This has been pointed out in § 653, where the hypothesis was considered 
that only structure, not vocabulary, can be translated in representational 
intermodular communication. Further evidence to this end (from the oppo-
site direction, i.e. phonology →morpho-syntax) is discussed in § 660: pho-
nological melody is unable to bear on morpho-syntax (while phonological 
structure at or above the skeleton is). Also, (representational) carriers of 
morpho-syntactic information in phonology appear not to include melody. 
This points to a complete exclusion of vocabulary from translation, both as 
input and as output. 
The facts that phonological melody is unable to bear on morpho-
syntax and that carriers of morpho-syntactic information cannot land below 
the skeleton are undisputed empirical generalisations (§ 660). The empirical 
situation of the generalisation discussed in the present section, however, is 
much less clear-cut; this is why it is presented in the chapter on open ques-
tions. 
An oft-quoted prima facie counter-example is category-driven stress 
placement in English: the same items bear penultimate stress in case they 
incarnate as nouns (récord, pérvert, éxtract, rébel), but show final stress 
when they appear as verbs (recórd, pervért, extráct, rebél). I have come 
across a similar case in Czech, where vowel-final prefixes are long in case 
they attach to a noun, but short when they occur with a verb (Scheer 2001, 
2003a:109ff, 2004c). 
Jennifer Smith has developed a specific interest in category-sensitive 
phonological phenomena: her work provides a collection of data sets that 
appear to stand against the generalisation at hand. Smith specifically fo-
cuses on what she calls noun faithfulness, i.e. her observation that nouns 
appear to show positional faithfulness effects, and to maintain phonological 
contrast that is not permitted in verbs. Relevant work includes Smith (1997, 
1999, 2001). Interestingly, stress is again prominent in the cases of noun-
faithfulness that Smith discusses. 
A possible way to get around this evidence is to think of the phonol-
ogically relevant lexical contrast as an effect of structure, rather than of 
vocabulary. That is, the contrast between nouns, verbs and adjectives may 
be encoded in terms of vocabulary at first, but is transformed into a struc-
tural difference by the morpho-syntactic derivation: nouns have got some-
thing more (or less) than verbs. What produces the phonological effect, 
then, is the contrasting structure, not the original vocabulary. This hypothe-
sis should be testable on morpho-syntactic grounds: the additional structure 
should leave traces on this side of the coin as well. 

The mapping puzzle 639 
The generalisation that phonology can read structure, but not vocabu-
lary, is thus certainly interesting and ties in with similar generalisations that 
all make sense from the modular point of view (the fact that melody and 
morpho-syntax are incommunicado). Unlike these, though, it faces a seri-
ous empirical challenge which requires further study. 
 
753  5. The mapping puzzle 
 
754  5.1. The issue(s), looked at by more or less helpless linguists 
 
The mapping puzzle has escorted the reader all through the book (the detail 
is recapitulated in § 755 below). Rather than a particular theoretical device 
or a specific view on the interface, it concerns an empirical generalisation ± 
or rather, the absence thereof. 
When looking at the inventory of morpho-syntactic configurations 
that do or do not produce a phonological effect across languages, one may 
expect some generalisations to emerge. After at least 25 years of serious 
research in the area that has produced a fair amount of cross-linguistic data 
and a reasonable number of case studies from genetically unrelated lan-
guages, the frustrating fact is that the harvest is very poor, in any case way 
below anything that is solid enough to ground a theory. 
This is one aspect of the mapping puzzle. Another, just as intriguing, 
concerns the properties of the conditioning patterns that are found. On 
many occasions, the set of morpho-syntactic divisions that trigger or inhibit 
a particular phonological effect do not appear to make sense: they are noth-
ing that a syntactician would call a natural class. Why is it that this bound-
ary produces the phonological effect at hand, but that boundary does not? 
Sometimes nothing really seems to unite the pool of triggering boundaries 
on the syntactic side. On the other hand, there may be non-triggering 
boundaries which from the syntactic point of view would be expected to 
line up with the triggering boundaries, but do not. 
Finally, it needs to be noted that the mapping puzzle concerns syntax, 
rather than morphology: the effects of specific sets of morphological 
boundaries (i.e. of boundaries below the word level) have been formalised 
in terms of affix classes. This is one of the basic insights of Lexical Pho-
nology that was carried over to all subsequent theories: affixes may behave 
like this or like that because they are lexically specified for class member-
ship. The trouble regarding boundary grouping at and above the word level 
is due to the fact that the analogue strategy, "word classes", is absurd: 

640 
Chap 5: Open questions (general) 
words are not recorded in the lexicon and hence cannot bear lexical specifi-
cations. 
All this being said, a scenario where natural language devises an ar-
bitrary set of syntactic configurations to leave a phonological trace is fairly 
unlikely. It is also self-evident that phonology has got nothing to say about 
the issue: progress can only come from a better understanding of how syn-
tax works. 
755  5.2. The mapping puzzle since SPE 
 
The mapping puzzle was first mentioned in the chapter on the post-SPE 
period (§ 111). Since then it runs through Part I and has reduced linguists of 
all periods and all theoretical obediences to despair. Elisabeth Selkrik is 
certainly the one who has worked most on the issue: in her early work on 
Prosodic Phonology (Selkirk 1984) and in her theory of end-based mapping 
(Selkirk 1986, see § 396) which evolved into alignment in OT (§ 458). 
Elisabeth Selkrik has also been the motor of the wave of empirical 
work on mapping that Prosodic Phonology has produced in the second half 
of the 80s and in the early 90s. More recently, she has participated in the 
adaptation of prosodic constituency to phase-based mapping (§ 462). Fi-
nally, she has inspired the shift of focus away from morpho-syntactic con-
ditions to other factors that play a role in mapping, such as information 
structure and eurhythmy (§ 463). 
The theory that made the strongest contribution to the study of the 
mapping puzzle is Prosodic Phonology (see §§ 387, 392f). When Prosodic 
Phonology was about to launch its empirical programme on mapping, 
Kaisse & Zwicky (1987) made the following statement in the introduction 
of a special issue of the journal Phonology. 
 
(311) "The study of postlexical rules sensitive to syntactic or prosodic structure is 
still in its infancy. Phonologists know comparatively little about the range of 
phenomena that can be encompassed by such rules, compared for instance 
with what is known about word-internal phonological processes or rules of 
syntax. At the moment theories must be advanced on the basis of data that 
are, from the language-internal point of view, rich and complex, but are 
also, from the cross-linguistic point of view, sparse and diverse." Kaisse & 
Zwicky (1987:4) 
 
In spite of the progress that was made on both theoretical and em-
pirical sides, Kaisse & Zwicky's description still makes a fairly good match 
of the situation today. 

Privativity 641 
756  6. Privativity 
 
757  6.1. On the representational side: complete or privative translation of 
morpho-syntactic divisions? 
 
758  6.1.1. All theories are non-privative since SPE 
 
Privativity is discussed on several occasions in Part I, where it is related to 
the representational channel, rather than to procedural communication with 
phonology. We will see, however, that it is a relevant concept also on the 
procedural side of the interface. But let us first look at privativity in the 
former area. 
It is an undisputed fact that only a small subset of the available mor-
pho-syntactic information is actually relevant for phonology: most of it has 
no phonological effect at all. As far as I can see, this basic observation was 
first formulated by Chomsky et al. (1956), who conclude that phonology is 
underfed by translational activity (see § 79): if only a small subset of mor-
pho-syntactic information is used, the translational device has fed phonol-
ogy only with this subset ± phonologically irrelevant information has never 
been translated and is thus absent from phonology. 
In spite of this basic observation, the alternative non-privative view 
on the matter is implemented by SPE and, as far as I can see, all subsequent 
interface theories. That is, full morpho-syntactic information is shipped off 
to phonology regardless of whether it will be used or not. Phonology then 
appeals to whatever is relevant for its computation; finally, irrelevant in-
formation, which is present in form of SPE-type boundaries or prosodic 
constituency, is either erased by phonological action (as in SPE), or just sits 
in phonology and remains inert (as in Prosodic Phonology). 
 
759  6.1.2. Unanimous non-privativity in individual theories 
 
The position of individual theories in regard of privativity is as follows. 
Structuralists such as Moulton (1947) use "+" in order to anchor the begin-
ning and the end of each word in the phonemic transcription, irrespectively 
of whether it will have an effect or not (§ 64). The rigid mapping mecha-
nism of SPE also sends all edges of major categories and higher projections 
thereof to the phonology without discriminating between those that will and 
those that will not be used (§ 90). That is, the "syntactic" # boundary re-
stores full morpho-syntactic information in phonology: the syntactic dis-

642 
Chap 5: Open questions (general) 
tance of two neighbours in the linear string is a direct function of the num-
ber of intervening #s. The input to phonological computation is thus a 
string made of lexical items and clusters of hashmarks. After the applica-
tion of phonology, remaining hashmarks are erased by rule at the end of the 
derivation. 
In the 70s, the non-privative heritage of SPE has prompted the need 
to distinguish between those boundaries that are phonologically relevant 
and those that have no phonological function. The former have been called 
"phonological", the latter "morpho-syntactic" (see § 132) ± a misleading 
distinction since a "phonological boundary" is a contradiction in terms. 
Lexical Phonology is also on the non-privative side, at least those 
versions that use Mohanan-type brackets, which mark the beginning and 
the end of every morpheme in phonology (§ 169). 
Prosodic Phonology promotes non-privative translation as well, even 
if it is true that not all morpho-syntactic information is projected onto pho-
nology (the Translator's Office makes readjustment decisions, see the dis-
cussion of non-isomorphism in §§ 380, 416). Non-privativity in fact is a by-
product of the Strict Layer Hypothesis: all strings are exhaustively parsed at 
all prosodic levels independently of whether or not there is an associated 
phonological effect. That is, the full six-layered prosodic constituency is 
always constructed no matter whether there is evidence for particular divi-
sions or not (see §§ 383,400 0). 
Finally, models that implement direct syntax also stand on the non-
privative side: van Oostendorp's (2006a) Coloured Containment and 
Orgun's (1996a et passim) declarative sign-based morphology allow pho-
nology to directly see and refer to all elements of morphological (and syn-
tactic) structure (see § 501). Bermúdez-Otero (forth a:21ff) discusses this 
approach in greater detail; he calls Orgun's view on the matter isomorphism 
(of morphological and phonological structure). 
The only representatives of privative translation that we have come 
across in Part I, then, are Chomsky et al. (1956) (§ 79). Noam Chomsky and 
Morris Halle reverted back to non-privativity twelve years later in SPE, a 
move that determined the attitude of the field up to the present day. It is 
therefore reasonable to think of their privative stance as a mere accident 
that was due to the rhetorical demand of the time: Chomsky et al.'s (1956) 
strategy was to introduce generative boundaries into the hostile structuralist 
environment by appealing to the well-reputed structuralist notion of econ-
omy: juncture exists in order to simplify phonemic transcription (§ 74). 
 

Privativity 643 
760  6.2. On the procedural side: selective vs. non-selective spell-out 
 
Privativity on the procedural side incarnates as selective spell-out, which is 
discussed at length in the chapter on open questions in the procedural area 
(§ 763). In short, the question is whether all nodes of the morpho-syntactic 
tree are spelled out, or only a subset thereof. The front line leaves Lexical 
Phonology (but not all brands thereof, see § 769) on the non-privative side, 
against Halle & Vergnaud (1987a) and Kaye (1995) who are privative. On 
the face of it, Distributed Morphology is privative, but the privativity at 
hand is rigidly defined according to the type of projection: all categorising 
affixes (i.e. xPs) project phase heads, while functional projections never 
trigger interpretation (§ 583).  
It is also shown below that selective spell-out, which was introduced 
by Halle & Vergnaud (1987a), is the ground rule of modern phase theory: 
only a subset of nodes are phase heads in current syntactic theory. Anybody 
who subscribes to derivation by phase, and who believes that morphology 
and syntax are the same computational system, should therefore be bound 
to selective spell-out.  
The case of Lexical Phonology is different since phase theory cannot 
be positioned as a referee: if morphology and syntax are two distinct com-
putational systems as is claimed by Lexical Phonology, there may be two 
distinct spell-out mechanisms. This means that the spell-out of morphemes 
could be non-selective even in presence of phase theory where the spell-out 
of words is selective (see § 769). 
761  6.3. Five arguments in favour of privativity 
 
Privativity is not a notion that ranks high among the issues that interface 
theories manipulate consciously. I have not come across any case in the 
literature where it is named and argued for or against. This is much unlike 
the situation in melodic representations where privativity is the major front-
line that divides theories which use binary primes and theories that rely on 
monovalent/unary primes.170 
The present section is devised to carry privativity into the spotlight 
of interface theory as a relevant design-property that contrasts competing 
approaches. Although the issue will not be settled, I believe that there is 
 
170 Binary approaches are standard since Jakobson and SPE; the privative alterna-
tive has been introduced by Anderson & Jones (1974) and was implemented in 
Dependency Phonology (Anderson & Ewen 1987), Government Phonology 
(Kaye et al. 1985) and Particle Phonology (Schane 1984).  

644 
Chap 5: Open questions (general) 
good reason for granting a serious advantage to privative theories. Five 
points can be made. 
If the output of translation is non-diacritic, translation must be priva-
tive. This point is made in Vol.2 on the grounds of the fact that diacritic 
morpho-syntactic information is always accessed by a specific proviso in 
the formulation of processes (constraints or rules) of the kind "only within 
the prosodic word", or "if a hashmark precedes". A hashmark or a prosodic 
word alone are thus perfectly inert: they are "sleepers" that have no effect 
unless they are called on by a specific mention in a computational state-
ment. By contrast, if non-diacritic, i.e. phonologically contentful objects are 
the output of translation, they have an immediate effect on phonological 
computation without needing to be referred to by computational statements. 
This is what I call the Direct Effect (see Vol.2, Scheer 2009a,c). In turn, this 
means that every single object that is inserted into phonological representa-
tions as the output of translation will have an effect: inserting a "sleeper" is 
impossible. Therefore, if carriers of morpho-syntactic information are to be 
non-diacritic, their distribution is necessarily privative. 
The second argument concerns the bare observation that only a small 
subset of morpho-syntactic information is phonologically relevant. This 
fact at least puts the burden of proof on those who wish to argue for non-
privative translation. Why should the grammatical system bother putting 
the translational mechanism to work in order to translate things that will 
never be used? And why should useless structure (boundaries, prosodic 
constituency) be built on the phonological side? The minimalist philosophy 
is certainly privative. That is, GB syntax in the 80s was full of useless 
structure: functional categories were built regardless of whether they would 
be relevant or not. The minimalist perspective is privative: phrase structure 
is only built when it serves a purpose in the derivation. Minimalist privativ-
ity is the result of a concern for extra-linguistic resources (§ 306) such as 
active memory, which non-privative structure wastes.  
Along the same lines but on the procedural side, Bermúdez-Otero 
(forth a:21ff) discusses the unwarranted empirical consequences of untem-
pered proliferation of cycles. He concludes that selective spell-out is re-
quired for that reason. 
Current syntactic phase theory is an argument that has already been 
made: if this perspective is on the right track, and if there is only one spell-
out mechanism (see § 763 on this question), the fact that derivation by 
phase relies on selective spell-out excludes systems where all nodes are 
interpreted. 

Privativity 645 
Finally, the general properties of intermodular communication that 
are discussed in § 654 provide good evidence for privativity: in language as 
much as in other cognitive functions, the information that is made available 
to the receiving module through translation is only a small (and arbitrarily 
chosen) subset of what the sending module offers. 
In Vol.2, an additional argument will be made: local intervention in 
phonology (see § 706) rules out non-privative translation of morpho-
syntactic information. 
 


Chapter 6 
762  Open questions (procedural) 
 
763  1. Selective spell-out and interpretation-triggering affixes 
 
764  1.1. Selective spell-out: what it is and how it works 
 
In SPE, interpretational units were defined by each morpheme (and of 
course word) boundary, except in case of successive affixes of the same 
major category, which belonged to the same cycle (see § 103). Hence a 
word like theatricality is made of five morphemes that are distributed over 
three cycles: [[[theatr]N ic + al]A i + ty]N, that is three interpretational units. 
The idea that only a subset of morpho-syntactic divisions delineate 
interpretational units, and that it is a lexical property of affixes which de-
cides whether or not such a unit is created, was introduced by Halle & 
Vergnaud (1987a) (see §§ 220f, 225). Translated into the perspective of the 
morpho-syntactic tree and a spell-out operation, we are talking about selec-
tive spell-out of nodes and interpretation-triggering affixes: affixes are lexi-
cally specified (by some feature) for triggering interpretation or not. Upon 
concatenation, this feature is projected and identifies the dominating node.  
When the spell-out mechanism works through the tree, nodes that 
bear the spell-out feature ± phase heads in modern syntactic terminology ± 
are sent off to PF/LF. Or rather, which portion of the tree exactly is inter-
preted when spell-out hits a phase head is subject to debate.  
 
(312) selective spell-out: two options 
 
a. the phase head itself is spelled 
out (Halle & Vergnaud 1987a) 
b. the sister of the interpretation-
triggering affix is spelled out 
(Kaye 1995) 
 
phase 
head 
 
phase 
head 
 
β
PF/LF 
 
 
β
tr. affix 
α
tr. affix 
α
PF/LF 
 
x
root 
 
 
 
 
x 
root 
 

648 
Chap 6: Open questions (procedural) 
Two options are explored in the literature: either the phase head itself 
(Halle & Vergnaud 1987a) or the sister of the interpretation-triggering affix 
(Kaye 1995) is interpreted. This contrast is depicted under  (312) above. 
In both cases, β is the projection of an affix that is lexically specified 
for triggering interpretation (a "triggering affix"). It is therefore a phase 
head. It is important to note that the rest of what happens, i.e. the interpreta-
tion of exactly which node is triggered, is a matter of the spell-out mecha-
nism, not of any lexical property of affixes (or of two distinct types of 
phase heads). This is made explicit under  (313) below. 
 
(313) how does the spell-out mechanism work? 
 
a. it sends the node that interpretation-triggering affixes project (i.e. the 
phase head) to PF/LF (Halle & Vergnaud 1987a) 
 
b. it sends the sister of interpretation-triggering affixes to PF/LF (Kaye 
1995) 
 
This means that the difference between Halle & Vergnaud (1987a) 
and Kaye (1995) has got nothing to do with selective spell-out itself:  (314) 
below makes explicit what this notion implies ± Halle & Vergnaud sub-
scribe to all points as much as Kaye does. 
 
(314) selective spell-out: definition 
 
spell-out is selective iff 
 
a. there are nodes that are not spelled out (but will be phonologically 
realised). 
 
b. lexical pieces are specified for triggering or not triggering interpreta-
tion. 
 
c. this lexical specification is inherited by the node that the pieces project: 
the nodes in question are phase heads. 
 
d. the spell-out mechanism is sensitive to phase heads: only these nodes 
trigger the shipping of material to PF/LF. 
The following section discusses the fact that Kaye's system appears 
to provide for what is known as the phase edge in current syntactic theory. 
 
765  1.2. Phase edge and piece-driven phase 
 
766  1.2.1. Spell out your sister: the phase edge in phonology 
 
Quite striking a parallel between Kaye's take on spell-out, (313b), and 
Chomsky's notion of phase edge is to be recorded (Scheer 2008c, 2009b). 

Selective spell-out and interpretation-triggering affixes 649 
Current phase theory holds that in case XP is a phase head, the spell-
out of XP only triggers the interpretation of the complement; the head and 
Spec,XP ± the edge of the phase ± are spelled out only at the next higher 
phase (Chomsky 2000a:108, see the quote from Chomsky 2001 under  (128) 
in § 306). Kaye's version of interpretation-triggering affixes and Chomsky's 
phase edge are contrasted under  (315) below. 
 
(315) the phase edge in syntax and phonology 
 
a. Chomsky (2000a, 2001) 
b. Kaye (1995) 
 
phase 
head 
 
phase 
head 
 
XP 
     
 
 
β
Spec 
X' 
 
 
tr. affix 
α
PF/LF 
 
X° 
comp 
 
PF/LF 
x 
root 
 
 
Saying that Kaye's spell-out is the phonological version of the phase 
edge is of course imprecise: it is the result of phonological evidence, but it 
concerns morphology. That is, where Chomsky's mechanism spells out 
words and larger chunks, Kaye's system is about the spell-out of mor-
phemes. What the parallel really is about, then, is syntax and morphology: 
chunks of whatever size seem to be spelled out by the same mechanism.  
That is, once it is determined that a given node is a phase head, the 
sister of its head is spelled out. In syntax, this is the complement (i.e. the 
sister of the head of the phase head-XP); in morphology, it is the sister of 
the interpretation-triggering affix, whose projection is the phase head. This 
is certainly a relevant contribution to the debate whether morphology and 
syntax are instances of the same computational system or not ± an issue 
that runs through the the entire book (e.g. § 533) and will crop up again 
shortly (§ 769). 
Also, the motivation for devising the spell-out mechanism to send 
the sister of the head of the phase head to PF/LF is the same with Chomsky 
and Kaye: modification-inhibiting no look-back (Phase Impenetrability). 
That is, only material in the complement of XP is frozen by Phase Impene-
trability upon spell-out of XP; the edge is still accessible for extraction 
even when XP has been interpreted. Since material that is dominated by a 
phase head may still be active in further derivation, the phase edge offers 

650 
Chap 6: Open questions (procedural) 
an escape hatch where things can move to in order to escape the petrifica-
tion of Phase Impenetrability. On the phonological side, the interpretation 
of the sister is necessary in order for it to be unable to be modified by later 
interpretation: the stress of [[párent] hood] cannot be modified on the outer 
cycle because [párent] was already interpreted independently. 
Related questions are the definition of phasehood and geometric 
properties of syntactic and morphological structure (the fact that (315b) 
does not appear to follow X-bar: there is no Spec). The latter debate would 
lead too far afield in this book: the status of X-bar structure and specifiers 
are subject to debate in current syntactic theory (e.g. Starke 2004). The 
former issue is discussed at greater length in § 771: phasehood is also a 
topic of current syntactic debate. 
 
767  1.2.2. Piece-driven vs. node-driven phase 
 
A last thing to be mentioned is a difference between syntactic and "phono-
logical" (i.e. morphological) spell-out: in current syntactic phase theory, the 
question which nodes exactly are phase heads is at the forefront of the re-
search agenda. What nobody doubts, however, is that phasehood is a prop-
erty of nodes ± this is what I call node-driven phase. That is, vP and CP are 
always phase heads (on Chomsky's 2000a count) independently of the lexi-
cal material that they contain. Of course they are also projections of termi-
nals, but these terminals are grammatical, not lexical items. 
By contrast on the "phonological" side, the label of nodes plays no 
role at all in the definition of phasehood: following the notion of interpreta-
tion-triggering affixes, a node inherits phasehood, i.e. becomes a phase 
head, because the affix that it is the projection of bears a lexical feature that 
specifies is interpretation-triggering property. This is what I call piece-
driven phase (Scheer 2008c). 
The opportunity for syntactic phase theory to consider piece-driven 
phase as a serious option is further discussed in §§ 781f (namely in the light 
of den Dikken's 2007 Phase Extension). 
 
768  1.3. Systems with non-selective spell-out: Lexical Phonology (DM) 
 
The Lexical Phonology tradition practises non-selective spell-out: it sub-
scribes to the idea that lexical pieces bear a specification that determines 
their spell-out; but unlike in selective spell-out, all affixes are armed with 

Selective spell-out and interpretation-triggering affixes 651 
this kind of feature. The spell-out mechanism is then sensitive to two (or 
several) specifications that a node may bear, and sends material to distinct 
computational systems at PF (the strata/levels). That is, there are not just 
phase heads, but there are several types of phase heads, level 1 and level 2. 
Or rather, it does not really make sense to talk about phase heads at all 
since there are no nodes that do not enjoy the interpretation-triggering 
status.  
In other words, what opposes selective and non-selective spell-out is 
privativity (§ 760): the former operates a yes-no distinction among nodes 
regarding their interpretation, while the latter implements a yes1-yes2 con-
trast: spell-out takes always place, but not in the same way.171 
Another candidate for non-selective spell-out is Distributed Mor-
phology, where all categorisers (nP, vP, aP) trigger interpretation, but func-
tional heads do not (§ 555). While it is true that on the face of it spell-out is 
thus selective in DM, the kind of selection that is operated is quite different 
from what we know from syntax: rather than depending on the node (node-
driven phase), it depends on a class of node labels. The trouble that this 
system runs into when facing affix class-based phenomena and when com-
pared to current syntactic phase theory was discussed in § 583. 
 
769  1.4. Spell-out is selective in syntax, but is this an argument? 
 
In order to assess the different competing options, let us first look at non-
selective spell-out. At first sight, a strong argument against this orientation 
is the fact that syntax does not seem to work this way (the same argument 
will be made in § 828 against morpheme-specific mini-phonologies): if 
current phase theory hits any close to the mark, spell-out is selective. That 
is, only a (small) subset of syntactic nodes are phase heads. It is true that 
the trend in syntax is towards smaller and smaller interpretational units, i.e. 
towards more and more phase heads that are lower and lower in the tree ± 
but whether the vanishing point of this evolution, Spell-Out-as-you-Merge 
 
171 The classical take of Lexical Phonology is to apply level-specific phonologies 
only at the end of strata, that is when two successive morphemes belong to dif-
ferent affix classes. This option is reminiscent of SPE (see § 103) and empiri-
cally indistinguishable from a situation where literally every boundary triggers 
interpretation (which is what some versions of Lexical Phonology actually 
practise). In any event, Lexical Phonology does not distinguish between inter-
pretation-triggering and interpretation-neutral affixes: all affixes trigger inter-
pretation. 

652 
Chap 6: Open questions (procedural) 
(Epstein et al. 1998:46ff), can or will be reached is a question open to dis-
cussion (see §§ 775ff). As of the current state of affairs, a perspective where 
all nodes trigger spell-out is largely unsupported in syntax. 
A premise of this argument, though, is that there is only one single 
spell-out mechanism. Defenders of Lexical Phonology can argue that this 
premise is wrong. If syntax and morphology are two independent computa-
tional systems, it is reasonable (though not necessary) to assume that they 
will also have distinct spell-out mechanisms. These may then not work in 
the same way: syntactic spell-out (i.e. of chunks at and above the word 
level) may be selective as Chomsky says, while morphological spell-out 
(i.e. of chunks below the word level) spells out all nodes. 
This is exactly the position of Lexical Phonology indeed: a funda-
mental architectural property of classical Lexical Phonology is precisely 
that morphology and syntax are two distinct computational systems (see 
§152). Many (but not all172) modern heirs of Lexical Phonology follow this 
conception (see § 539), which is precisely the reason why Distributed Mor-
phology has an issue with (classical and modern versions of) Lexical Pho-
nology (§ 533). 
We are thus back to the question whether morphology and syntax are 
distinct computational systems, or just one engine. It is only when this 
question is decided that the argument in favour of selective spell-out will 
turn out to bite or not (Scheer 2009b). 
In sum, it is hard to see how a decisive argument could be made in 
order to referee the competing perspectives of Lexical Phonology and se-
lective spell-out. The empirical coverage of both approaches that is exam-
ined in § 831, though, may indicate an advantage of the latter. 
 
172 Bermúdez-Otero (forth a) is a modern heir of Lexical Phonology, but who does 
not necessarily subscribe to all design properties of classical Lexical Phonology 
(see § 488). Bermúdez-Otero (forth a:21ff) compares Orgun's (1996a) non-
privative isomorphism (Orgun argues for direct syntax where phonology has 
full access to morpho-syntactic structure, see § 512) with what he calls impover-
ishment. Impoverishment is privativity: it holds that "every domain [i.e. phase] 
is coextensive with some grammatical unit [i.e. node in the morpho-syntactic 
tree], but not all grammatical units create domains" (Bermúdez-Otero 
forth a:26). This shows that there is no principled incompatibility of selective 
spell-out and Lexical Phonology. 

Selective spell-out and interpretation-triggering affixes 653 
770  1.5. Conclusion: a unifying perspective 
 
In absence of decisive evidence regarding the single engine question, the 
unifying perspective of selective spell-out is certainly appealing and consti-
tutes evidence in favour of selective spell-out in general, and in support of 
Kaye's version thereof in particular. 
On the empirical side, Kaye's system affords a coverage of the two 
fundamental patterns of affix class-based phenomena, the rule-blocking 
(level 1 rules) and the rule-triggering (level 2 rules) pattern (§ 310). Halle & 
Vergnaud on the other hand are unable to analyse the latter (see § 250 and 
the comparison of empirical coverage in § 831 below).173
Selective spell-out in general and Kaye's system in particular offer a 
converging perspective with syntax regarding three issues: selective spell-
out itself, the edge of the phase ("spell out your sister!") and modification-
inhibiting no look-back (i.e. Phase Impenetrability, see § 299). Recall from 
§279 that Kaye's system achieves underapplication by Phase Impenetrabil-
ity. The unifying perspective is further discussed in § 852 below. 
The latter parallel regarding Phase Impenetrability is a little different 
from the two former since it concerns an effect, rather than a property of 
the spell-out mechanism. Its independence from the single engine issue 
makes it a stronger argument: the presence of syntactic PIC effects is a 
good reason (a compelling reason for Chomsky, see the quote under  (126) 
in § 305) for predicting that phonological effects of the same kind will also 
be found. 
 
173 It is true that Halle & Vergnaud can do anti-affix ordering items (gov-
ern-mént2-al1, §246), which appear to violate Phase Impenetrability and are 
therefore troublesome in Kaye's system (see § 315). In fact, the same items are 
problematic for Halle & Vergnaud as well: they violate all no look-back de-
vices, including the SCC-K to which Halle & Vergnaud subscribe. The problem 
is probably more general and has to do with stress: suprasegmental processes 
have long been observed to violate no look-back generalisations. This issue is 
discussed at greater length in §§ 554, 780. 

654 
Chap 6: Open questions (procedural) 
771  2. Phase theory 
 
772  2.1. A rapidly growing field whose diversity can be confusing at times (not 
only for phonologists) 
 
Since Uriagereka (1999) and Chomsky (2000a, 2001), phase theory evolves 
at high speed, but today is still in an embryotic state and rather poorly un-
derstood (Boeckx & Grohmann 2007). Many different directions are ex-
plored, the relevant literature is growing rapidly, and the evolution is some-
times difficult to follow, especially for a phonologist. 
The overall picture may be quite confusing at times: everybody 
seems to have his/her private way of doing phases, many of which are in-
compatible. The common denominator reduces constantly, probably to not 
much these days, except that 1) things are sent off to LF/PF and 2) come 
back frozen (to various extents). 
Below I attempt to provide an overview of the directions that are 
taken, of their relation and (in)compatibility with Chomsky's original idea, 
and of their eventual meaning in or interpretation by phonological (phase) 
theory. Needless to say, all will be looked at through the prism of the pho-
nological point of view, which means that almost all technical detail will be 
left out, to the effect that things which are important for syntacticians may 
be left unmentioned; by contrast, properties of phase theory that are not 
usually on the syntactic radar may be highlighted because they are relevant 
for phonology. 
Overview literature includes Richards (2004:57ff), Frascarelli 
(2006), Boeckx & Grohmann (2007), den Dikken (2007) and Grohmann 
(2007a,b).174 
Finally, due mention needs to be made of the fact that there are also 
voices which believe that phase theory is not a good thing to have in lin-
guistic theory. Scepticism is fed by various objections: Boeckx & Groh-
mann (2007) (see also Matushansky 2005) invoke principled reasons, the 
fact that too many problems arise, that too much confusion is created by the 
blooming diversity of approaches that is reported below, that the theory is 
riddled with internal inconsistencies (especially Matushansky 2005), and 
that the conceptual motivation is too poor. 
 
174 The latter are the introductions to two successive special issues of Linguistic 
Analysis that Grohmann has edited. Under the general header of Dynamic In-
terfaces, these concentrate a number of relevant papers (one issue, 33.1-2, is 
about phases and derivations, the other, 33.3-4, inquires on spell-out and lin-
earisation). 

Phase theory 655 
773  2.2. What counts as a phase? 
 
774  2.2.1. Inner- and extra-syntactic criteria for distributing phasehood 
 
One question that anybody who accepts the frame of derivation by phase 
has to answer is what exactly counts as a phase. As far as I can see, com-
mon to all versions of phase theory is the fact that phasehood is a property 
of nodes. This is what I call node-driven phase, as opposed to piece-driven 
phase (see § 767). In this perspective, the initial question is thus about the 
properties that a node must possess in order to be granted the privilege of a 
phase head.  
Once the criteria for phase head-eligibility defined, a further question 
is which nodes exactly satisfy them. While the former question is covered 
in the present section, the latter issue is discussed in the following sections. 
We will see that the election of a node as a phase head does not always 
follow from the application of the criteria that ought to govern the distribu-
tion of phasehood: typically, a node is grated the phase head privilege for 
practical reasons, i.e. because some data are argued to require spell-out at 
some stage of the derivation. 
Based on Chomsky (2000a:106) and other practice, den Dikken 
(2007:27ff) offers a comprehensive discussion of the properties that qualify 
a portion of the tree for being a phase. Chomsky tries to derive phasehood 
from extra-syntactic properties, which is certainly the strongest way to go 
about the question: ideally, syntax-internal considerations such as "this data 
set requires spell-out at node X" will be toothless, or rather, will be able to 
be evaluated on extra-syntactic grounds. 
Chomsky (2000a:106) defines a phase as a "natural syntactic object 
SO", that has a certain degree of independence both phonologically and 
semantically. Being independent means being prosodically isolable and 
movable on the phonological side, and being propositional on the semantic 
side, which means for example that phases are expected to be T-complete. 
A syntax-internal ± thus weaker ± control over phasehood that 
Chomsky proposes is the idea that phases are probes (i.e. loci of uninter-
pretable formal features), and more recently, that they "have an EPP-
position as an escape hatch for movement and are, therefore, the smallest 
constructions that qualify for Spell-Out" (Chomsky 2004:124). 
As was mentioned earlier, the coronation of a node as a phase head 
does not always depend on these criteria in the actual practice that is found 
in the literature. The atomising evolution towards smaller and smaller 

656 
Chap 6: Open questions (procedural) 
phases that is described in the following section weakens (or rather, under-
mines) especially the extra-syntactic control over phasehood.  
Also, the literature has questioned Chomsky's criteria for phasehood, 
which are found to be non-operational (Legate 2003, Boeckx & Grohmann 
2007). One argument that attacks the heart of the escape-hatch mechanism 
is the following.175 According to Chomsky, the item that should enjoy ex-
tra-syntactic independence is whatever is actually spelled out. Since, how-
ever, only the complement of vP and CP, rather than vP and CP themselves, 
is sent to LF/PF upon the spell-out of vP/CP, it should be the complement 
that enjoys interface independence. That is, complements of phases, not 
phases themselves, should be isolable units regarding sound and meaning. 
This, however, is obviously not the case. 
 
775  2.2.2. The trend is towards atomisation 
 
Chomsky's original take on phasehood identifies CP and vP, maybe DP 
(Chomsky 2005:17f), as phase heads. The DP track has been followed, and 
also DP-internal phases are argued for (Svenonius 2004:265f, Matushansky 
2005, Boãković 2005b). Den Dikken (2007:33ff) provides an overview of 
the DP issue, arguing that "there is good reason to believe that DP and CP 
are each other's counterparts in their respective domains (the noun phrase 
and the clause)" (p.33). 
TP is also under debate: while Chomsky (e.g. 2000a:106, 2004:124, 
2008) is explicit on the fact that TP does not qualify as a phase head (be-
cause it is not propositional, see also Richards 2007b and the discussion in 
Abels 2003:62ff, 116ff), den Dikken (2007:29ff) points out that according 
to Chomsky's own criteria (see § 774), this conclusion is not really obvious. 
Indeed, TP is assumed to act as a phase head in the literature, and also 
nodes below TP such as Voice° (Baltin 2007, Aelbrecht 2008) and AspP 
(Hinterhölzl 2006) are sometimes granted phasehood. Finally, Abels 
(2003:227ff) argues that PP may also (parametrically) be a phase head.176 
A label-insensitive proposal that goes farther than the above quoted 
is Müller's (2004), who suggests that every maximal projection is a phase 
head. 
 
175 The argument is made by Boeckx & Grohmann (2007:215), who report that it 
has three independent origins, Abels (2003), Grohmann (2003) and Epstein 
(2006). 
176 Samuels (2009a:248) also provides an overview of the syntactic phasehood 
literature. 

Phase theory 657 
Finally, it needs to be mentioned for the sake of completeness that ± 
predictably enough ± phasehood has also been proposed to be subject to 
cross-linguistic parameterisation: Gallego (2007, 2010) entertains a per-
spective where different nodes enjoy the phase head privilege in different 
languages (also Abels 2003:227ff for PP). 
 
776  2.2.3. Is there a lower limit for phasehood? Is spell-out selective? 
 
Given the trend towards atomisation, the vanishing point of the evolution is 
that all nodes trigger interpretation or, in other words, that interpretation 
occurs upon every application of Merge. As a matter of fact, this view has 
actually been proposed in work by Samuel Epstein and others: Epstein et 
al. (1998:46ff), Epstein & Seely (2002:77ff, 2006:174ff) (see also § 305). 
 
(316) "LF and PF necessarily evaluate linguistic entities at every point in the 
derivation. Thus, if X and Y are merged creating C, then C is necessarily 
input to both LF and PF." Epstein & Seely (2006:174, emphasis in origi-
nal) 
 
The question that the atomisation movement raises from the phono-
logical perspective is not so much how many nodes are ennobled as phase 
heads, which nodes exactly are concerned and how high (or low) they are 
in the tree. Rather than about the granularity of phase heads, the question is 
whether there is a principled limit to atomisation. Or, in other words, 
whether there are any nodes left that must not trigger interpretation. If such 
nodes exist, spell-out is selective (in the sense of §§ 228, 763). If no princi-
pled reason prevents atomisation from hitting the programmed vanishing 
point where Samuel Epstein waits for the rest of syntax, spell-out may as 
well turn out to be non-selective. 
In this case, the intermodular argument that was made in § 769 is 
vacuous: if syntactic spell-out may or may not be selective, phonological 
spell-out may just as well be selective or not. It is only when syntax has a 
firm (selective) position that an argument in favour of selective spell-out 
can be made in phonology. 
What it takes for the intermodular argument to go through, then, is a 
clarification in syntax: can non-selective Spell-out-as-you-Merge be ex-
cluded or be reasonably disqualified? The following section discusses an 
argument to this end that is made in the syntactic literature. 
 

658 
Chap 6: Open questions (procedural) 
777  2.2.4. Anti-locality of movement marshals atomisation 
 
One effect of phase theory which is always put to its credit is the fact that it 
provides an elegant and more general way of deriving the cyclic character 
of long distance movement: the labour that was done by Barriers (and 
bounding nodes, relativized minimality) before is now afforded by Phase 
Impenetrability (see § 679, e.g. Rizzi 2005, Frascarelli 2006:2f).  
Counter this apparent convergence, Richards (2004:59f) argues on 
empirical grounds (defective intervention, i.e. cases where a single head 
can be valued by two distinct goal categories) that intervener-relativized 
locality is not reducible to a phase-based account. That is, the cycles of 
probes and goals do not necessarily coincide: while the former obey strict 
XP-by-XP cyclicity, the cycle of the latter must sometimes be larger. 
Boeckx & Grohmann (2007:211ff) also argue that the link between 
phase theory and successive-cyclic movement may actually turn out to 
challenge the former since a widely held view on the latter is that every 
maximal projection is a cycle (Boeckx & Grohmann mention a host of 
relevant literature). Under the PIC-analysis of successive-cyclic movement, 
this would mean that every maximal projection is also a phase (which is 
what Müller 2004 proposes) ± thus further atomising phasehood.  
Boeckx & Grohmann argue that this leads to a contradiction since on 
Chomsky's count every phase induces a Phase Impenetrability effect. If all 
XPs are subject to Phase Impenetrability, however, "no extraction would be 
possible, as the complement of any phase would have to move to the edge 
of that phrase/phase, a movement step that would count as too local under 
any version of 'anti-locality'" (Boeckx & Grohmann 2007:212). 
Beyond the intended goal (which is to show that phase theory as such 
is in trouble), the point that Boeckx & Grohmann (2007) make is that anti-
locality (Grohmann 2003, Abels 2003:91ff) marshals the atomisation of 
phasehood. In the evolution that makes smaller and smaller chunks of the 
tree phase heads, there is a level where the phase edge (see § 765 on this 
notion) will not be able to act as an escape hatch anymore for material that 
is trapped in the complement: anti-locality will prevent it from escaping. 
This purely syntactic argument ± if it goes through ± appears to be an 
important reference point in the ongoing discussion of phasehood: Chom-
sky's original distribution of phase heads was certainly too coarse, but the 
atomising evolution has also a lower limit, which is set by anti-locality 
constraints on movement. 
What anti-locality ultimately does, then, is to guarantee that spell-out 
will always be selective, no matter how fine- or coarse-grained phasehood 

Phase theory 659 
turns out to be. This result is relevant for phonology because it enables 
intermodular argumentation along the lines that were mentioned in the pre-
vious section: (non-)selective spell-out draws a red line between the two 
major conceptions of how procedural communication works that compete 
on the phonological side (see § 763). 
 
778  2.3. Extensions of the basic model 
 
779  2.3.1. Asymmetric spell-out: independent access of LF and PF 
 
Beyond the central issue of phasehood, a number of proposals have been 
made how phase theory works. Most of them are plug-ins in the sense that 
they may or may not be subscribed to independently of each other, and also 
independently of how phasehood is sorted out. 
One question that has already been addressed in § 567 is asymmetric 
spell-out, i.e. a scenario where LF and PF can be accessed independently. 
This perspective considerably weakens phase theory: "minimal pairs" such 
as cómparable vs. compárable where semantic and phonological opacity go 
hand in hand (the former is opaque on both sides, the latter on none, see 
§545) would be a mere accidental coincidence of LF and PF interpretation 
that occurs at the same node. § 567 reproduces a quote of Chomsky's 
(2004:107) in this direction, and provides relevant literature. 
Nonetheless, there are also arguments in favour of asymmetric spell-
out (§ 567), and the question is open for further debate. 
 
780  2.3.2. PIC à la carte: process-sensitive no look-back 
 
Another issue that we have come across, and which will be relevant below 
(§ 794), is what was called PIC à la carte in § 554. No look-back devices are 
riddled with specific counter-examples for a long time, and these appear to 
not just involve any process. § 556 has pointed out that stress is a notori-
ously bad guy who has violated the SCC-K (hence the derived environment 
generalisation) in the 80s (§ 192), and also does not care for Phase Impene-
trability in Marvin's (2002) analysis (§ 555). On these grounds, it was sug-
gested in § 241 that Phase Impenetrability could apply à la carte, i.e. for a 
given phase constrain the application of some processes, but not of others. 
Certainly a relevant research question today is whether it is possible 
to identify a specific class of processes that violate no look-back, as op-

660 
Chap 6: Open questions (procedural) 
posed to another class that produces no no-look back-effects. In the 80s, the 
candidate rationale was structure-building (able to violate no look-back) vs. 
structure-changing processes (unable to violate no look-back, see §§ 193f) 
whereby the prime candidates for the former were stress (construction of 
foot structure) and syllabification (construction of syllable structure) (see 
§293). Another track is the segmental vs. suprasegmental distinction (proc-
esses of the latter, but not of the former kind, are able to violate no look-
back). That is, tone is found to violate Phase Impenetrability as much as 
stress does (Marlo 2008). 
What that would come down to is process-sensitive Phase Impene-
trability. The reason why relevant phonological evidence is discussed here 
is that the same idea is also present in the syntactic literature: Bobaljik & 
Wurmbrand (2005:828f) and Boãković (2007) for example hold that Move, 
but not Agree, is subject to the PIC: agree relationships are notoriously 
long-distance and may reach into a lower frozen phase. 177  Grohmann 
(2007a:13) generalises the issue raised by Boãković's case study: does the 
PIC really apply to all narrow-syntax operations? 
Further study must show whether the line that separates the pool of 
phenomena that is and the pool of phenomena that is not impacted by Phase 
Impenetrability can be stated according to any rationale, i.e. whether the 
two sets can be described as "natural classes" of events, both syntactically 
and phonologically. Phonologists have certainly a serious advance in this 
field: even though the issue is not top ranked on the research agenda since 
the 80s (to say the least), they have thought about the question for a long 
time, and some cross-linguistic data are available. By contrast on the syn-
tactic side, the eventuality of process-sensitive Phase Impenetrability is an 
entirely new (and rather exotic) perspective; as far as I can see syntacticians 
have not begun to try to find a rationale for properly separating violating 
and non-violating processes.  
This is certainly not unrelated to the fact that PIC à la carte is quite 
unminimalistic an idea: the PIC is an instrument of computational econ-
omy, and according to Chomsky economy conditions are always obeyed. 
PIC à la carte, then, amounts to economy à la carte. Note, however, that 
Chomsky (2004:107f) senses that "spell-out and forget" may be too strong 
 
177 Another solution for the same pattern is also entertained in the literature: since 
in Romanian and Greek a long distance agree relationship (between a matrix 
verb and the embedded subject) reaches into a CP in violation of the PIC, 
Alexiadou (forth:15) hold that the CP layer (and hence the associated phase) 
does not exist in these languages. 

Phase theory 661 
a condition on phonological computation (see § 306, more on this in 
§§ 796f). 
 
781  2.3.3. Phase Extension: when phasehood depends on what the head is  
made of 
 
Since Chomsky's inception of derivation by phase, one of the few proper-
ties that appear to remain stable through the blooming evolution of the the-
ory is the fact that phasehood is a rigid property of nodes. As den Dikken 
(2007) puts it, "once a phase, always a phase", and "not a phase at the out-
set, then never a phase". That is, phasehood is not syntactically manipu-
lable: whatever happens in the course of a syntactic derivation has no influ-
ence on which node is a phase head, and which node is not. 
Den Dikken (2007) explores the opportunity of a more dynamic out-
look on phasehood: nodes continue to be defined as phase heads upon con-
struction, but this is only an option they take for being interpretation-
triggering in the end. Whether or not pre-specified candidates really are the 
point of PF/LF access at the end of the day is determined by what happens 
in the syntactic derivation.178 That is, den Dikken proposes that the phase-
hood of a node which was acquired through initial node-based distribution 
may move together with the material that it dominates. This privilege, how-
ever, is restricted to heads and head movement. 
In practice, this means that a node which was not a phase head qua 
"initial distribution" may inherit this property from material that it has 
come to dominate through movement if this material was a phase-head (qua 
"initial distribution") in its base position. Since movement is only upwards, 
den Dikken calls his theory Phase Extension: its effect is that a syntactic 
derivation may cause interpretational units (i.e. the material that is sent to 
the interfaces as a block) to enlarge, but not to shrink. 
What is called "initial distribution" above is a not an obvious notion 
in den Dikken's theory. For example, CPs are deprived of the phase head 
privileges that Chomsky's system grants them per se; this does not mean, 
however, that they cannot be phase heads at the end of the day: depending 
 
178 A related take where effective spell-out of a node depends on the properties of 
the syntactic derivation is convergence-based phasehood as proposed by 
Svenonius (2001) and Felser (2004). The idea is that phrases are sent to inter-
pretation as soon as they are ready, i.e. when all of their unvalued features have 
been checked. 

662 
Chap 6: Open questions (procedural) 
on the syntactic derivation, they may become an interpretation-triggering 
node if they receive material that was a phase head in its old position. 
It is not worthwhile going into greater detail here, den Dikken ex-
plains at length how phasehood is distributed outside of inheritance through 
movement. What is important for the comparison with what I call piece-
driven phase (which is practised in phonology) (see §§ 767, 782) is profiled 
under  (317) below. 
 
(317) Phase Extension ± relevant properties for the comparison with phonology 
 
a. phasehood is defined by syntactic computation, rather than given. 
 
b. the phasehood of heads moves together with the head: if a phase head 
moves, it will also be a phase head in its new position. 
 
c. nodes may inherit phasehood from the material that they dominate; that 
is, the phasehood of a node may be a projection of its head. 
 
Especially (317c) is useful for the comparison of how phasehood is 
defined in syntactic and phonological theory, as we will see in the follow-
ing section.  
 
782  2.3.4. Unification of piece-driven and node-driven phase by a lexical 
phasehood feature 
 
Den Dikken's (2007) Phase Extension may be interpreted as a first step 
towards a lexical definition of phasehood, i.e. where interpretation is trig-
gered by a lexical property of pieces, a "phasehood feature", that is pro-
jected into morpho-syntactic structure. Recall that this is how all phono-
logical effects of affix class-based phenomena work (piece-driven phase, 
see §§ 225, 767). 
While the lexical origin of phasehood is thus undisputed below the 
word level (piece-driven phase), phasehood is thought of as a property of 
node labels in syntax (node-driven phase, see §§ 767,781). The assumption 
in syntax is that phase heads as such do not share any property that could 
be predicted from the syntactic derivation. Rather, the spell-out mechanism 
executes a hard-wired programme where it is specified that this node does, 
but that node does not trigger interpretation. 
The idea of a phasehood feature allows us to extend the phonological 
piece-driven phase to syntax: phase heads bear a phasehood feature that is 
projected by their head. The spell-out mechanism, then, is blind to labels: it 
only looks at the phasehood feature, spelling out nodes iff they have it. 

No look-back (Phase Impenetrability) 663 
In this perspective, nodes such as vP and CP have inherited their 
phasehood by a projection from a lexical item: vP is the result of the merger 
of v and VP, which means that little v is the carrier of the phasehood fea-
ture. If, say, TP is not a phase head (either universally or parametrically), 
there is no equivalent lexical "little t" that carries the phasehood feature. 
The parallel between an interpretation-triggering morpheme and little 
v is shown under  (318) below. 
 
(318) piece- and node-driven phase unified: 
the head bears an interpretation-triggering (phasehood) feature 
 
a. "node-driven" phase 
b. "piece-driven" phase 
 
vP 
     
 
 
β
Spec 
v' 
 
 
class 2 
α
PF/LF 
 
v
VP 
 
PF/LF 
x 
root 
 
 
What is shared by all phase heads, then, is the fact that their head is a 
lexically recorded item that possesses a phasehood feature: little v under 
(318a), the class 2 affix under (318b). In both cases, the sister of the inter-
pretation-triggering item is spelled out (the phase edge, see § 766). 
In this perspective, the impression that phasehood is node-driven 
above, but piece-driven below the word level is a mirage that stems from 
the fact that affixes are "material" in the sense that they have a direct pho-
netic correlate, while items such as little v do not. 
 
783  3. No look-back (Phase Impenetrability) 
 
784  3.1. Limited scope of this section 
 
No look-back devices in general and Phase Impenetrability in particular 
have been discussed all through Part I, and they are also an important piece 
of the argumentation in Part II: they appear on various occasions in the 
section on selective spell-out (§ 763), in the general section on (syntactic) 
phase theory (§ 771) where Phase Impenetrability plays the role of a referee 
for the definition of phasehood, in the section on the word-spell-out-
mystery where the non-cyclicity of the interpretation of word sequences is 
ascribed to the absence of the PIC at this level (§ 794), in the section on 

664 
Chap 6: Open questions (procedural) 
chunk-specific interpretation where the PIC is made process-specific (§ 823, 
also § 780), in the section on morpheme-specific mini-phonologies where 
the PIC is used as an argument (§ 828) and also in the final synopsis of con-
vergent syntactic and phonological interface devices (§ 852). 
The present section therefore offers only a brief survey of the role 
that no look-back devices have played in previous (phonological) interface 
theories as discussed in Part I. 
 
785  3.2. No look-back devices since Chomsky (1973) and their non-
conflatability with derived environment effects 
 
Phase Impenetrability is the modern incarnation of the idea that computa-
tion has no or only limited access to "old" strings, i.e. to those that have 
already been subject to interpretation. No look-back devices have appeared 
in a number of guises since Chomsky (1973), who has first made cyclic 
derivation subject to a no look-back condition. The relevant history is de-
scribed in § 287 at some length, where it is shown that the exact wording of 
the no look-back condition matters: different formulations produce quite 
different empirical effects (§ 302).  
Noteworthy is the fact that the current version of no look-back, Phase 
Impenetrability, has emerged in phonology in the 80s (see also Riemsdijk's 
1978 Head Constraint in § 298) and was generalised by Kaye (1992, 1995) 
(§ 299). This is where the idea of modification-inhibiting no look-back en-
tered the scene: the modern Phase Impenetrability Condition is an imple-
mentation of this specific way to organise no look-back. The PIC "freezes" 
previously computed strings, which are then unavailable for further compu-
tation and are "forgotten" (§ 306). Even if the phonological version(s) of 
modification-inhibiting no look-back need to be worked out (the phono-
logical situation requires a weaker formulation, § 302), the general idea is 
the same. 
Finally, it is to be mentioned that the ambition to merge derived envi-
ronment effects and no look-back effects into one single device was enter-
tained for a long time in the 80s, where it actually shaped a good deal of the 
research agenda at the interface. The origins and evolution of this project, 
which revolved around Kiparsky's SCC-K, are described in § 177. Its failure 
is obvious at least since Kiparsky (1993) himself has declared the bank-
ruptcy of his SCC-K (see § 197, although a branch of Lexical Phonology, 
represented by Rubach & Booij 2003, continue on this track). Bermúdez-
Otero (2008, forth a:§2.6.3) even holds that the SCC-K was the major 

Why are there no phonological effects of the cyclic spell-out of words? 665 
brake that prevented Lexical Phonology from evolving and contributed a 
good deal to its temporal discredit during the 90s (§ 214). It is shown in 
§182 that sensitivity to affix classes and to derived environments is logi-
cally independent: either may occur without the other. 
 
786  4. Why are there no phonological effects of the cyclic spell-out of 
words? 
 
787  4.1. The absence of cyclicity-induced external sandhi: a consensual fact 
that theories build on, but do not talk about 
 
Traditional terminology distinguishes between internal and external sandhi. 
The former refers to phonological effects of morpheme boundaries, while 
the latter describes phonological effects of word boundaries. This distinc-
tion comes in handy for the purpose of this section, which is about an ab-
sence, i.e. something that the literature does not talk about: the cyclic spell-
out of words. While the procedural management of morphemes has spilled 
a lot of ink (this is essentially what Lexical Phonology is about), I have not 
come across either a phenomenon that requires, or an analysis that proposes 
a procedural treatment of words or bigger chunks ± save the notorious case 
of intonation, which is discussed at length in § 800. 
The absence of procedural activity above the word level ± or rather: 
of phonological traces thereof ± is admitted as the correct empirical record 
in the field. The literature therefore offers only representational treatments 
of syntactically conditioned phonological effects. In practice, this means 
that all external sandhi phenomena are ascribed to some variation in pro-
sodic constituency.  
The exclusive ambition of representational management at and above 
the word level is rarely made explicit, though. The only case that I am 
aware of was discussed in §§432 0f: Selkirk (1984) and Inkelas (1990) ob-
serve that while prosodic constituency can cover the full spectrum of units 
(morphemes and words alike), Lexical Phonology is confined to the Lexi-
con, i.e. to morphemes. Since there is no place for two devices (procedural 
and representational) that do the same job below the word level, Inkelas 
(1990) argues, prosodic constituency should be extended to the Lexicon. 
Lexical Phonology, then, is an empty shell at best. 
The pages below describe the attitude of different interface theories 
with respect to the absence of phonological traces of the cyclic spell-out of 
words (§ 788). This phenomenon, which I call the word-spell-out-mystery, 

666 
Chap 6: Open questions (procedural) 
is quite extraordinary if spell-out of words is indeed cyclic: why should 
phonology refuse to react on piecemeal fire at and above the word, but 
produce traces thereof below the word level? While no answer to this ques-
tion will be provided, § 794 evaluates what it takes to implement the word-
spell-out-mystery in a phase-based environment. 
 
788  4.2. How interface theories behave: claims for and against cyclic spell-out 
of words, for and against its cyclic interpretation 
 
789  4.2.1. The baseline position of SPE: everything is cyclic 
 
Given this empirical situation and its reception in the literature, let us 
briefly review the spectrum of positions that have been taken by phono-
logical interface theories. Two things need to be carefully distinguished: on 
the one hand the submission of pieces to interpretational modules, which 
may or may not be cyclic; on the other hand, the phonological (or semantic) 
interpretation thereof (i.e. of whatever is submitted), which may also be 
cyclic or not. The former is a matter of the spell-out mechanism, while the 
latter may appear to be a decision of the phonological computational sys-
tem: either I ignore that I receive a string in pieces and act only at the end 
when the last piece has come in, or I do my job any time a piece is submit-
ted.179 
The baseline position is represented by Chomsky et al. (1956) and 
SPE where cyclic derivation was introduced: both the spell-out and the 
phonological interpretation of word sequences is cyclic. The relevant quote 
from § 102 is reproduced below. 
 
(319) "The principle of the transformational cycle [«] appl[ies] to all surface
structure whether internal or external to the word" Chomsky & Halle 
(1968:27). 
 
790  4.2.2. Lexical Phonology: the interpretation of word sequences is not cyclic 
 
Lexical Phonology has a different take. It was mentioned in § 153 that all 
versions of this theory implement Praguian segregation, i.e. two distinct 
 
179 We will see in §§ 797f that it is reasonable to believe that whether interpretation 
is cyclic or not is as much a decision made by the spell-out mechanism as the 
decision whether the spell-out itself is cyclic. 

Why are there no phonological effects of the cyclic spell-out of words? 667 
chunk-specific phonologies that compute sequences of morphemes 
(word/lexical phonology) and sequences of words (sentence/postlexical 
phonology), respectively. The issue regarding chunk-specific phonologies 
is discussed in § 811 below ± it is entirely orthogonal to the cyclic question: 
both lexical and postlexical levels may or may not be declared cyclic. 
The term "cyclic rule" (which is still used today in a kind of lingua 
franca-understanding) is indicative of the front line that is set in Lexical 
Phonology: early versions of the theory assumed that all phonological rules 
which contribute to word-formation (i.e. which apply to sequences of mor-
phemes, that is in the Lexicon) are cyclic, while all postlexical rules (i.e. 
those that apply to sequences of words) are non-cyclic. The cyclic condi-
tion on lexical rules was called into question later on (Rubach & Booij 
1984 introduced lexical post-cyclic ± i.e. non-cyclic ± rules, see § 194), but 
the necessarily non-cyclic character of postlexical rules stands unchal-
lenged in all Lexical Phonology quarters up to the present day. 
 
791  4.2.3. Lexical Phonology makes no claim about spell-out and installs non-
cyclic interpretation of word sequences without argument 
 
On the other hand, as far as I can see, Lexical Phonology makes no claim 
regarding the cyclic character of spell-out. The only thing that is central for 
this theory is the contrast between the cyclic interpretation of morpheme 
sequences (lexical phonology), against the non-cyclic interpretation of 
word sequences (postlexical phonology). 
The reasons for this fundamental distinction, however, are not made 
explicit as far as I can see. One may suppose that postlexical phonology is 
declared non-cyclic on the grounds of the observation that cyclicity-
induced external sandhi is absent from the record. This, however, is no 
more than speculation since, as was reported in § 158, Kiparsky (1982b) 
simply decrees that there is no cyclic derivation of words without argument 
or discussion. 
 
(320) "The former, the rules of lexical phonology, are intrinsically cyclic because 
they reapply after each step of word-formation at their morphological level. 
The latter, the rules of postlexical phonology, are intrinsically noncyclic." 
Kiparsky (1982b:131f, emphasis in original) 
 

668 
Chap 6: Open questions (procedural) 
792  4.2.4. Halle & Vergnaud and Kaye: restoration of SPE ± everything is 
cyclic 
 
Let us now turn to Halle & Vergnaud (1987a), who are committed to the 
SPE heritage, but also to Lexical Phonology and the lexicalist environment 
of the 80s, of which Praguian segregation is an expression (§ 216). The re-
sult is a system where both morphemes and words are subject to cyclic 
spell-out; the concatenative process, however, takes place in two rounds, 
one where words are created, another where sentences are built (word-
internal vs. word-sequence strata in Halle et al. 1991). Word- and sentence-
construction is separated by a specific word-level phonology (see § 238). 
This much for spell-out. Within this architecture, then, all phonologi-
cal interpretation is cyclic, no matter whether the input are morphemes or 
words. That is, following their general orientation (§ 219), Halle & Verg-
naud restore SPE: 1) there are no morpheme-specific phonologies; 2) there 
is a chunk-specific phonology at the word level (SPE's word-level rules, see 
§104, which Halle & Vergnaud call non-cyclic rules), but not at the post-
word level (i.e. contra Lexical Phonology, there is no distinction between a 
lexical and a postlexical phonology: both chunk-sizes are interpreted by the 
same computational system); 3) all phonological interpretation that sees 
cycles is cyclic; that is, the unique computational system that assesses mor-
pheme- and word sequences is cyclic (§ 238), but word-level phonology is 
not because it cannot: it is punctual and hence does not see any cyclic 
boundaries. 
Kaye's (1995) position is the same as Halle & Vergnaud's as far as I 
can see: Kaye rejects morpheme-specific phonologies (§ 303), provides for 
a word-specific phonology (§ 283), but has morpheme- and word-sequences 
interpreted by the same computational system, which carries out cyclic 
interpretation.  
793  4.2.5. Distributed Morphology is entirely agnostic in phonological matters 
 
Finally, Distributed Morphology is entirely agnostic in regard of the issue 
at hand, simply because it is not concerned with, and does not make any 
claim about, phonological interpretation (see § 535). From the vantage point 
of DM, morpho-syntax cannot accommodate multiple computational sys-
tems, but PF may or may not accommodate morpheme-specific and/or 
chunk-specific mini-phonologies, whose interpretational action also may or 
may not be cyclic. 
 

Why are there no phonological effects of the cyclic spell-out of words? 669 
794  4.3. The word-spell-out mystery 
 
795  4.3.1. Cyclic spell-out of words but no phonological traces? 
 
From a global perspective, the situation thus seems paradoxical: cyclic 
spell-out of words and larger chunks ± derivation by phase in modern ter-
minology ± is a central piece of current syntactic thinking, but it looks like 
it has no phonological consequences. By contrast, the cyclic spell-out of 
morphemes is just as undisputed, but ± as expected ± leaves ample traces in 
the phonology. 
Having distinct chunk-specific phonologies that distinguish word- 
and sentence phonology as proposed by Lexical Phonology does not solve 
the problem: it merely records the contrast between the area that produces 
phonological effects (internal sandhi) and the one that does not (external 
sandhi). What it does not, however, is to correlate the phonological non-
effect for chunks at and above the word level with the other end of the in-
teractionist pipe: we want to know how it could be that the same input to 
(an) interpretational system(s) ± the piecemeal submission of a string 
hacked into pieces of growing size ± in one case produces (opacity) effects, 
but in another case leaves no trace at all. 
 
796  4.3.2. Wrong data or an on/off switch for Phase Impenetrability 
 
There are only two ways that I can think of how this mystery can make 
sense: either the empirical generalisation is wrong (phonologists have not 
worked hard enough, if they have a closer look, they will find cyclicity-
induced external sandhi), or interpretational systems are able to ignore their 
input conditions. The latter option means that a phonological system (or a 
semantic system for that matter) has a switch that decides whether "old" 
strings, i.e. those that have already undergone previous computation, are 
subject to a special treatment or not. Or rather, as we will see in § 799, the 
switch at hand is borne by the spell-out-mechanism, not by the phonologi-
cal computational system. 
In other words, word phonology would feature a no look-back de-
vice, while sentence phonology has no Phase Impenetrability Condition and 
hence treats all strings in the same way, old and new alike. 
A third option that is logically possible is certainly not a serious can-
didate and may be left unexplored: spell-out of words and larger chunks 
could be non-cyclic (while morphemes are submitted piecemeal to interpre-

670 
Chap 6: Open questions (procedural) 
tation). This would mean that cyclic derivation in general and interactionist 
derivation by phase in particular are flat out wrong. 
 
797  4.3.3. A solution: (chunk-specific) PIC à la carte 
 
Let us pursue the option according to which interpretational systems are 
parameterised for subjecting or not subjecting "old" strings to a special 
treatment. An interesting question is what "special treatment" actually 
means, and by whom it is organised. As far as I can see, the literature on no 
look-back devices in general, and on Phase Impenetrability in particular, 
does not really address this issue: no look-back is declared to be a property 
of the system, but what it actually takes for the system to implement the 
desired effect remains vague. 
It was mentioned in § 306 that the (Chomsky's) whole motivation for 
hacking sentences into pieces and sending them to PF/LF piecemeal is to be 
able to achieve computational economy regarding active memory by im-
posing the Phase Impenetrability Condition on "old" pieces. The economy 
effect is achieved by allowing further computation to "forget" these "old" 
pieces and their internal structure. 
Also recall from § 306 (see the quotes under  (128) and  (129)) that 
Chomsky (2001:12f, 2004:107f) is explicit on the fact that the economy of 
active memory concerns phonological as much as syntactic computation 
("the phonological component too can 'forget' earlier stages of deriva-
tion"). Which means that Chomsky takes Phase Impenetrability to be a 
general condition on computational systems (at least in grammar). This is 
in line with the general minimalist philosophy where conditions on compu-
tational economy are always obeyed.  
Note, however, that Chomsky (2004:107f) senses that "spell-out and 
forget" may be too strong a condition on phonological computation (§ 306, 
quote  (129)). This is what was observed in § 302 anyway, and the alterna-
tive that we are currently exploring, PIC à la carte (see also § 780), points in 
the same direction: a computational system may "choose" to benefit from 
computational economy or not. That is, a PIC condition lies on the phono-
logical interpretation of sequences of morphemes (computational economy 
realised), while sequences of words remain unmarshalled by the PIC (com-
putational economy waived). Note that this type of PIC à la carte is differ-
ent from the one that we have already come across: the PIC à la carte dis-
cussed in § 780 is process-specific, while the mechanism explored here is 
chunk-specific. In one case the type of process decides (for a given phase 

Why are there no phonological effects of the cyclic spell-out of words? 671 
boundary), while in the other the size of the chunk determines whether or 
not the PIC applies (chunks below the word yes, at and above the word no). 
 
798  4.3.4. PIC à la carte that does not want to be named (Samuels 2009a) 
 
Samuels (2009a) has comet to the same conclusion, (chunk-specific) PIC à 
la carte, but refrains from admitting that the PIC is stalled above the word 
level. Her formulation is that it applies in two different ways, whereby the 
way to apply above the word level is not to apply. 
Samuels (2009a:248f) follows the core properties of the DM archi-
tecture and the DM definition of phase heads below the word level (catego-
risers have this status: n,v,a, see § 555). From a minimalist and phase-based 
perspective, she holds that "spell-out domains are the only domains that 
phonology needs" (Samuels 2009a:249, emphasis in original), where spell-
out domains are phases (both below and above the word level). This leaves 
the question open what should be done with phases that phonology does not
need (i.e. which do not leave any phonological footprint): this is exactly the 
issue that is raised by the word-spell-out-mystery.  
Samuels adheres to the rigid syntactic take that each and every phase 
is marshalled by a PIC condition (PIC violations are only apparent: 
Samuels 2009a:265ff). On this backdrop, she converts the lexical vs. pos-
tlexical distinction into a phase-based formulation whereby the PIC of pos-
tlexical rules is only enforced above the word level (Samuels 
(2009a:260ff). 
 
(321) "I maintain the distinction between these two rule types by arguing that all 
phonological rules obey the Phase Impenetrability Condition, but in one of 
two different ways. Lexical rules must obey the Phase Impenetrability Con-
dition at both the morpheme level (phase heads n, a, etc.) and the clausal 
level (phase heads v, C, D, etc.); [«] Post-lexical rules apply once a se-
quence of morphemes has been turned into an atomic unit and obey the 
Phase Impenetrability Condition only at the clausal level." Samuels 
(2009a:262) 
 
Samuels thus follows Lexical Phonology in all points: 1) there are 
two distinct computational systems, lexical and postlexical, 2) processes 
(rules) are assigned to either (or to both), and 3) postlexical processes are 
blind to phase structure (i.e. above the word level) and ignore the PIC. 
Terminology and notational variation set aside, this is exactly the solution 
that is referred to as PIC à la carte in the previous section (and in § 780). 

672 
Chap 6: Open questions (procedural) 
The basic insight is that in a phase-based environment the non-cyclic char-
acter of postlexical computation (i.e. the fact that there are no phonological 
footprints of phases above the word level) needs to be expressed by a 
chunk-specific suspension of the PIC. 
 
799  4.3.5. Phase Impenetrability is a property of the spell-out mechanism, not 
of concatenative or interpretational systems 
 
Let us now consider the fact that computational economy needs to be 
somehow organised. Some kind of memory-keeper must keep track of 
which portion of the string was already subject to interpretation, and which 
portion is new (§ 307). Everything that we know about how modules work 
suggests that the modular computation itself is perfectly unable to do this 
job. All that modular computation does is performing a calculus on an in-
put, and returning an output (modules are input-output devices, their com-
putation is automatic, mandatory, "blind" and so on, see § 613). Given this 
description, modules are perfectly unable to distinguish between those por-
tions of the string submitted that are in need of computation, and those that 
are not: modules do not make decisions. 
This means that Phase Impenetrability is not a property of computa-
tional systems such as morpho-syntax, phonology (or semantics for that 
matter). What is it then a property of? The spell-out mechanism appears to 
be the only candidate. As a consequence, the system which is supposed by 
phase theory has three, rather than two individuatable units (as far as the 
derivation of sound is concerned): a concatenative system (morpho-syntax), 
a spell-out system and an interpretational system (phonology).  
While the former and the latter are modules, the status of the spell-
out mechanism is unclear: it reminds of the Translator's Office of Prosodic 
Phonology (see § 377) and Jackendoff's (1997 et passim) interface proces-
sors (§§ 23, 652), but does not share the basic property of these devices, i.e. 
the ability to understand the vocabulary and the structure of both the send-
ing and the receiving modules. Rather, the spell-out mechanism reads the 
result of morpho-syntax and manages chunk-submission to phonology, 
which includes the distinction of "old" and "new" portions of the string.180 
180 The status of the spell-out system in a modular architecture is a central and 
understudied question in interface theory. It is further discussed in Vol.2. Un-
published work by Michal Starke inquires on its properties (see also Caha 
2009). 

Why are there no phonological effects of the cyclic spell-out of words? 673 
Table  (322) below depicts what this system looks like based on an 
example where all nodes are phase heads, where (following regular as-
sumptions regarding the phase edge, see § 766) only the complement of the 
head of a phase head is actually sent to interpretation, and where the high-
est node is a CP, i.e. the end of the syntactic derivation. 
 
(322) no look-back managed by the spell-out mechanism 
 
morpho-syntax 
 
 
 
 
action of the spell-
out mechanism 
 
phonology 
end of the deriva-
tion 
 
restores the content 
of the memory: 
[Z Y X W] 
 
 
 
 
 
«
Y
γ
1. adds X to memory 
 
 
 
 
 
2. reads γ, sends Y 
 
 
X 
 
Z
β
1. stores [W] 
 
 
 
 
 
2. reads β, sends X 
 
 
 
 
 
W
Y
α
reads α, sends W 
 
 
 
 
 
X
W
When spell-out occurs at α, W is sent to phonology, where it is com-
puted and sent back to morpho-syntax. It is then excluded ("forgotten") 
from further morpho-syntactic computation, but needs to be stored in order 
to be restituted at the end of the derivation. When spell-out treats β, only X 
is sent to phonology since, just like for morpho-syntactic computation, 
previously interpreted strings are excluded from phonological computation. 
This procedure works through the string until the end of the derivation, 
where the memory-keeper, that is the spell-out mechanism, restores its 
memory, which is the linear sequence of all interpreted items. 
This of course is only a rough schematic picture that does not come 
any close to what is actually going on. For one thing, the labour that the 
spell-out mechanism is supposed to do under  (322) describes only a vanish-
ingly small portion of its real action. Unpublished work by Michal Starke 

674 
Chap 6: Open questions (procedural) 
(see also Caha 2009) studies the properties of the spell-out mechanism in 
greater detail. 
Also, it is probably obvious for every phonologist that phonological 
computation needs to be able to see previously interpreted strings, even if it 
cannot modify them. Many phonological processes take material from more 
embedded morphemes into account (§ 307). Finally, as was mentioned in 
§302, "old strings are frozen" is too strong a condition in regard of the exis-
tence of phonological processes that apply across word boundaries. There-
fore § 780 (also § 823 below) has concluded that the PIC applies to phono-
logical processes à la carte: it must be specified for each process whether its 
application is marshalled by the PIC or not. 
From the minimalist perspective, the obligation for the spell-out 
mechanism (or some other device which is not on my radar) to act as a 
memory-keeper raises the question whether the trade-off between this extra 
burden for active memory and the computational economy that is realised 
by morpho-syntax and LF/PF is all that positive. 
 
800  4.4. Intonation requires cyclic spell-out of words for sure ± but this does 
not appear to concern phonological computation 
 
801  4.4.1. Intonation is governed by syntactic structure 
 
Let us now examine intonation, the only case that I am aware of where the 
cyclic spell-out of words leaves phonological traces ± if intonation is any 
phonological at all. At least since Bresnan (1971), it is established that in-
tonation (also called sentence or phrasal stress) directly depends on syntac-
tic structure. The topic is covered by a rich syntactic literature, including 
Berman & Szamosi (1972), Cinque (1993), Kahnemuyipour (2009) and 
Adger (2007).  
Bresnan's (1971) original data and analysis have been presented in 
§308; a characteristic example is repeated under  (323) below for conven-
ience (underscored words are intonationally prominent). 
 
(323) syntax-sensitive intonation 
 
a. 
Helen left directions for George to follow. 
 
b. 
Helen left directions for George to follow.
(323a) means that Helen has left some directions that George should 
follow, while (323b) is an invitation for George to follow Helen. Since both 
sentences are phonologically identical but have contrasting syntactic struc-

Why are there no phonological effects of the cyclic spell-out of words? 675 
ture, the different intonation must be a consequence of the latter: under 
(323a) follow is transitive and belongs to a relative clause whose head is 
directions, while under (323b) it is intransitive and complements directions.
The causal relationship between syntax and phonology has also been 
thought of in the opposite direction: Szendrői (2001, 2003, 2004) argues 
that syntactic properties such as focus and climbing can be controlled by 
intonation. Intonation is thus a phenomenon that challenges Zwicky & Pul-
lum's (1986a,b) original (strong) version of phonology-free syntax (see 
§§ 412, 660 on this notion, which is probably more accurately referred to as 
melody-free syntax). 
In sum, there can be no doubt that cyclic spell-out of words and lar-
ger units impacts the calculus of intonation. In order for this fact to qualify 
as a prove that cyclic spell-out may also bear on phonology, however, it 
needs to be shown that the calculus of intonation is the result of phonologi-
cal computation. Against the intuition that intonation is a phonological 
phenomenon, there may be good reason to believe that this is not the case. 
Also relevant is the fact that intonation is the typical phonological 
phenomenon which is argued to be recursive (or rather: to require recursive 
structure, which as we will see is not quite the same thing). A pervasive and 
largely undisputed empirical generalisation, however, is that recursion is 
the privilege morpho-syntax, the only concatenative device(s) in grammar 
(Hauser et al. 2002, Neeleman & van de Koot 2006, §§ 45f). This is reason 
enough to doubt that intonation, should it require recursive structure, is any 
phonological at all: its putative recursive nature disqualifies intonation as a 
phonological phenomenon. 
Whether or not intonation requires recursive structure will not be de-
cided here. In case it does, however, it is shown that the bare existence of 
recursive structure in phonology does not mean that phonology itself is 
recursive as long as the structure in question is built by mechanisms that 
are foreign to phonological computation. We will see that this is indeed the 
case for all recursive prosodic structure that is argued for in the literature. 
We begin by considering this question. 
 
802  4.4.2. Prosodic structure may be recursive ± phonology is not 
 
Beyond the syntactic literature, intonation has been studied in the perspec-
tive of Janet Pierrehumbert where it is phonologically represented as tones 
(e.g. Pierrehumbert 1980, 2000, Beckman & Pierrehumbert 1986, 1988 and 
Ladd 2000 provide overviews). Also, this approach puts to use the tools of 

676 
Chap 6: Open questions (procedural) 
Prosodic Phonology (among many others, Liberman 1975, Ladd 1986, 
1996, Gussenhoven 1992, 2004, Kratzer & Selkirk 2007, the articles in van 
Oostendorp & Horne (eds.) 2005 are specifically about the role of bounda-
ries in intonation). 
As far as I can see, Ladd (1986) was the first voice to argue that in-
tonation is recursive, in the sense that it requires recursive prosodic struc-
ture. Formally speaking, recursion is defined as a structure where a node is 
dominated by another node of the same kind. Ladd (1986) works with two 
prosodic constituents, the Major Phrase (MP, cf. Selkirk 1986, § 394) and 
the Tone Group (TG). He aims at showing that intonation cannot be ade-
quately described unless an MP may dominate other MPs, and a TG other 
TGs. 
Nested prosodic structure was ruled out by the original version of 
Selkirk's Strict Layer Hypothesis, and this is what Ladd (1986) stands up 
against. Under this pressure (among others), Selkirk (1996) abandons the 
ban on recursive prosodic structure: in the new constraint-based formula-
tion, the non-recursion of prosodic structure is demoted to a violable con-
straint (§ 461). Languages and analysts are thus free to use nested prosodic 
structure. Since then, numerous analyses have taken advantage of this op-
tion (among many others, Booij 1996, Peperkamp 1997, Truckenbrodt 
1999). 
 
803  4.4.3. Phonology is not recursive: confusion between non-recursive 
phenomena and their eventual analysis with recursive constructions 
 
There are thus analyses that rely on recursive prosodic structure in order to 
account for intonation. They could be wrong, and the analytic tools that 
they use ± prosodic constituency ± could be unwarranted. It was argued in 
§§ 694, 706 that prosodic constituents are diacritics as much as juncture 
phonemes and hash marks are, and that diacritics do not qualify for the 
output of translation.  
The alternative are carriers of morpho-syntactic information that be-
long to the phonological vocabulary, i.e. exist in phonological processes 
that do not appeal to any extra-phonological information. It was argued in 
§717 that only syllabic space qualifies as an output of translation. If this is 
correct, of course an alternative means for the analysis of intonation needs 
to be found that does not rely on prosodic constituency. This track is ex-
plored in § 806: intonation may not be phonological in the first place, i.e. it 
may be entirely due to syntactic, rather than to phonological computation. 

Why are there no phonological effects of the cyclic spell-out of words? 677 
But beyond this debate where right and wrong is a matter of assess-
ment, the whole reasoning according to which a particular type of analysis 
that is based on recursive structure demonstrates the existence of recursion 
in phonology is flawed. For this is confusing the existence of a phenome-
non, and an analysis thereof. Recursion is a phenomenon of natural lan-
guage, and as such has a pre-theoretical definition: relevant diagnostics are 
known. In syntax and morphology, it is defined as follows: you can keep 
repeating the same type of item indefinitely until grammar-external limits 
regarding memory etc. are reached.  
Relevant examples from syntax and morphology are shown under 
 (324) below. 
 
(324) recursion in syntax and morphology 
 
a. 
Peter thinks [that John says [that Amy believes [that«]]] 
 
b. 
Czech iterative -áv 
dĕlat    
 
 
"to do" 
dĕl-áv-at  
 
 
"to do repeatedly/often" 
dĕl-áv-áv-at   
 
"to do even more often" 
dĕl-áv-áv-áv-«-at  "to do really really often" 
 
French re- prefixation (about the same in English) 
faire   
 
 
"to do" 
re-faire  
 
 
"to do again" 
re-re-faire  
 
"to do with two repetitions" 
re-re-re-faire 
 
"to do with three repetitions" 
re-re-re-re-«-faire "to do with n repetitions" 
 
Recursive structure in natural language has the property of producing 
grammatically unbounded embedding: grammar happily generates and 
tolerates an infinite number of embedded clauses (or phrases), and in the 
case of recursive morphology, an infinite number of embedded morphemes. 
The limits on recursive structure in actual production are imposed by per-
formance (factors such as memory), not by competence. That is, speakers 
will get confused upon the third of fourth level of embedding.  
Also, recursion is obviously a consequence of concatenation: there is 
no embedding without gluing pieces together. This is reflected in the opera-
tion Merge, which is the central (and only) recursion-creating device in 
current syntax. The simple fact that phonology does not concatenate any-
thing but merely interprets fully concatenated strings shows that there could 
not be any recursion in phonology, at least not anything that satisfies mor-
pho-syntactic standards. 

678 
Chap 6: Open questions (procedural) 
Empirically speaking, nothing that resembles the phenomena under 
 (324) and their pre-theoretical description has ever been reported in pho-
nology. This empirical situation is the reason why the absence of recursion 
is firmly established as a major property that sets phonology (and seman-
tics) apart from morpho-syntax (e.g. Pinker & Jackendoff 2005a,b). It is 
entirely independent of eventual analyses that use recursive constructions: 
having some prosodic constituent such as the Prosodic Word ω and the 
"Prosodic Word Prime" ω' where the latter dominates the former does not 
make the phenomenon at hand recursive.  
The same goes for analyses of other phonological phenomena that 
use recursive constructions. Hulst (2010) has gathered a number of this 
kind of analyses regarding for example the internal structure of segments 
(melodic organisation). He argues that they document the existence of re-
cursion in phonology. They do not: the only thing that they document is the 
existence of analyses that use recursive structure in order to account for 
non-recursive phenomena. The existence of recursion in phonology is es-
tablished by a pre-theoretical and pre-analytical checklist, and nobody has 
ever found a phonological phenomenon that qualifies. 
 
804  4.4.4. Prosodic structure is not created by phonological computation 
 
But let us return to intonation and consider an eventual situation where it 
turns out that the correct analysis of this phenomenon is based on recursive 
prosodic structure. Even in this case phonology would not be recursive. 
What it means for phonology to be recursive (if syntax and morphology 
define this notion) is to accommodate a recursive mechanism in phonologi-
cal computation. On standard assumptions, though, prosodic constituency 
is not created by phonological computation: it is the result of a mapping 
mechanism that is located in modular no man's land (the Translator's Of-
fice, see § 381).181 Mapping is an exclusively top-down operation that trans-
forms relevant morpho-syntactic structure into phonologically legible 
items,182 and eventually introduces distortions that are not motivated by the 
morpho-syntactic input (non-isomorphism, see § 380). 
 
181 But recall that in OT (constraint-based) mapping is done in the phonology, see 
§526. 
182 This was shown in §§ 420f and §§ 714ff: mapping is uninformed of any phono-
logical property, except of course for the syllable and the foot, which are bot-
tom-up constructions. Prosodic Phonology acknowledges this difference (see 
§401). 

Why are there no phonological effects of the cyclic spell-out of words? 679 
We are thus left with a situation where recursive structure may exist 
in phonology, but with phonological computation being perfectly non-
recursive.  
 
805  4.4.5. Phonology only interprets: Merge must be absent, hence the result of 
phonological computation is flat 
 
The absence of recursion in phonological (and semantic) computation is 
also central for the generative architecture of grammar. The inverted T 
model (§ 86) embodies the insight that there is only one concatenative sys-
tem in grammar, morpho-syntax.183 Phonology and semantics are interpre-
tational systems (modules) which do not glue any pieces together: they 
merely interpret a string whose size, composition and linearity is decided 
elsewhere. 
The fact that phonology and semantics do not concatenate anything 
is also a headstone of Hauser et al.'s (2002) argumentation, who hold that 
recursion (Merge) and the ability to talk to other modules in a specific way 
(phase) are the only properties of the human faculty of language that are 
specifically linguistic (§ 639). 
If phonology and semantics only interpret strings but are unable to 
build them, it follows that they must not have access to the building device, 
that is Merge in current syntactic theory. This is pointed out by Neeleman 
& van de Koot (2006), who provide detailed argumentation to the end that 
allowing for Merge (and hence for trees) in phonology and semantics 
wrongly predicts the existence of recursive structure, and hence of recur-
sive phenomena in these modules.184 
The (undisputed) empirical record (there are no recursive phenomena 
in phonology) as much as the headstone of the generative architecture of 
grammar (concatenation is the privilege of morpho-syntax) thus require the 
absence of Merge from phonological (and semantic) computation.  
Finally, it is worth pointing out that the research programme of Gov-
ernment Phonology in general, and of CVCV in particular, roots in the 
claim that syllable structure is better understood in terms of lateral relations 
among segments than by using traditional arboreal structure. This is where 
 
183 An eventual sub-division between morphology and syntax notwithstanding. 
The present discussion is unaffected by this debate (see § 537). 
184 Note that this is a strong argument against Jackendoff's (1997 et passim) paral-
lel approach to modular structure where all modules are granted access to con-
catenation (§ 722). 

680 
Chap 6: Open questions (procedural) 
the title of Vol.1 comes from: a lateral theory of phonology. The lateral 
perspective, whose motivation is purely phonology-internal, thus allows for 
a non-contradictory implementation of the architectural requirement that 
phonology has no access to Merge, and that trees must not be the output of 
phonological computation: phonology-created structure is flat, and the ab-
sence of recursion is predicted (this argument was already made in the 
foreword to Vol.1, see § 42). 
 
806  4.4.6. Is intonation a phonological phenomenon at all? 
 
Let us now return to the initial question which, recall, was about the ab-
sence of phonological effects of the cyclic spell-out of words. We have seen 
that cyclic spell-out is a factor that influences intonation for sure. Whether 
through the mediation of the Prosodic Hierarchy or otherwise, intonation 
seems to militate against the generalisation that cyclic spell-out of words 
leaves no phonological traces. This, however, is only true if intonation is a 
phonological phenomenon in the first place. That is, according to our defi-
nition of phonology, if intonational structure is created by phonological 
computation. 
Cinque's (1993) and Wagner's (2005a) work shows that intonation is 
much more syntactically bound than the phonological literature may sug-
gest. In actual fact, it raises the question whether intonation is any phono-
logical at all: it may as well be syntax and nothing else. This is the conclu-
sion of Cinque (1993), who derives the parameterisation of the the Nuclear 
Stress Rule (which is responsible for English intonation in SPE and much 
subsequent work, see § 308) from purely syntactic factors. As a conse-
quence, the Nuclear Stress Rule and phonological treatments thereof (such 
as Halle & Vergnaud's 1987a:263ff grid-based implementation that Cinque 
discusses specifically) are redundant and have to go: 
 
(325) "if the effects of the Nuclear Stress Rule [«] depend entirely n the direc-
tion in which depth of embedding develops, the the rules become redun-
dant. They merely recapitulate what follows from purely syntactic parame-
ters. Hence they should be eliminated." Cinque (1993:244) 
 
This direction may appear counter-intuitive because intonation is 
somehow "made of sound", and hence should be treated in the phonology. 
Maybe ± but we have seen that this does not mean that phonology builds 
the structure which ultimately gets to the surface in the guise of intonation. 
Phonology may well be responsible of nothing at all in the process that 

Why are there no phonological effects of the cyclic spell-out of words? 681 
decides where intonation falls: like elsewhere, its action is purely interpre-
tative; in the case of intonation, the action of phonology could well reduce 
to making a particular portion of the string phonologically prominent, 
whereby the portion itself was designated by extra-phonological devices. 
A strong argument in favour of this perspective is the following fact: 
it appears that intonation may be calculated in complete absence of phono-
logical material, that is before lexical (vocabulary) insertion and hence 
before phonological computation has a chance to do anything at all. Féry & 
Ishihara (2009) make this generalisation: knowing about the syntactic and 
the information structure of a sentence is enough in order to predict where 
intonation falls; the particular words and their phonological properties that 
will ultimately instantiate this structure are irrelevant.  
If it is true that intonation may be calculated in complete absence of 
phonological material, the logical conclusion is that phonological computa-
tion does not participate in the entire process: the prominence of this or that 
item is calculated in syntax alone; phonology (or phonetics) only provides a 
specific pronunciation for the portion that is made prominent. 
Finally, another argument for the independence of phonology and in-
tonation is the fact that both appear to live in waterproof worlds: there does 
not seem to be any conditioning in either way. That is, sentence stress is not 
influenced by word stress (or vice-versa), intonation does not bear on seg-
mental phenomena, nor is it impacted by labiality, occlusion etc., and so on. 
It may be concluded, then, that there is a purely syntactic alternative 
to the traditional phonological treatment of intonation. 
 
807  4.5. Conclusion 
 
808  4.5.1. If the generalisation is correct, Praguian segregation alone will  
not do 
 
At the end of this inquiry, we are left with a number of open questions, and 
some vague indications. The cyclic character of the spell-out of both mor-
phemes and words is undisputed; why is it, then, that the literature abounds 
in phonological effects of the former, but does not seem to have met any 
phonological trace of the latter?  
One solution is that phonological effects of the cyclic spell-out of 
words have simply been overlooked: the generalisation is just wrong. Into-
nation, however, which appears to be a massive counter-example at first 
sight, turns out not to harm the word-spell-out-mystery (§ 800). On the con-

682 
Chap 6: Open questions (procedural) 
trary, it rather adds grist to the mill of the mystery since it relies on recur-
sive structure that phonology has no handle on and to which phonological 
computation does not contribute anything. 
In case the generalisation turns out to be correct, just jumping into 
Praguian segregation will not do: the existence of distinct chunk-specific 
phonologies, one for morpheme-, another for word sequences, is necessary, 
but not sufficient to explain what is going on. What we need on top of that 
is a means to make postlexical phonology ignore cyclic structure. For the 
zero hypothesis is certainly that if an interpretational system is exposed to 
piecemeal chunk submission, traces thereof will appear in its output.  
It is therefore certainly empirically adequate to decree that lexical 
phonology is, but postlexical phonology is not cyclic ± this is the reaction 
of Lexical Phonology (§ 791). It does not tell us, however, how come and 
what it means that interpretational systems can "decide" to react on or to 
ignore piecemeal chunk submission.  
 
809  4.5.2. Chunk-specific PIC à la carte 
 
One way to go about this question was explored in § 794. "Reacting on cy-
clic structure" can mean two things for an interpretational system. One 
perspective is the solution of Lexical Phonology where the cyclic structure 
that (cyclic) lexical phonology encounters is interpreted by two distinct 
mini-phonologies according to the morpho-syntactic makeup of the string 
(level 1 vs. level 2, see § 150). By contrast, the cyclic structure that phonol-
ogy encounters at and above the word level is interpreted by only one com-
putational system (postlexical phonology). 
Another way of encoding the reaction on piecemeal chunk submis-
sion is through the parameterisation of no look-back (i.e. of Phase Impene-
trability). On the account of Kaye (1995), the phonological effect of the 
cyclic spell-out of morphemes is due to modification-inhibiting no look-
back: while underapplication is due to morpheme-specific mini-
phonologies in Lexical Phonology, it is a consequence of Phase Impenetra-
bility in Kaye's system (§ 279). 
In this perspective, if the phonological effect of the cyclic spell-out 
of morphemes is due to Phase Impenetrability, and if this effect is absent 
when it comes to the cyclic spell-out of words, the conclusion is that the 
PIC constrains the computation below, but not at and above the word level. 
This is what §§ 796f suggest: chunk-specific PIC à la carte. The next ques-
tion, then, is what Phase Impenetrability is a property of. It appears that the 

Chunk-specific phonologies 683 
PIC is unlikely to be managed by concatenative/interpretational systems; 
rather, it is a property of the spell-out mechanism, which in addition to 
organising chunk-submission also decides to make "old" strings subject to a 
specific treatment (§ 799). 
 
810  4.5.3. Outlook 
 
About all that was said on the pages above is more or less speculative. This 
is worth what it's worth, for the whole issue ± the word-spell-out-mystery ± 
appears to be unreflected in the literature. One reason is certainly the fact 
that the absence of cyclic impact on external sandhi is set in stone since 
Lexical Phonology and the correlated idea of a completely regular ("auto-
matic") postlexical phonology. 
The study of a larger body of empirical material will have to show 
whether the current state of affairs is due to this theoretical bias (which, 
recall, was installed without argument), or whether natural language has 
really different ways of treating morphemes and words in phonological 
computation. Which is but another occasion to be thrown back to the ques-
tion of the (non-)unity of morphology and syntax (§ 537). 
 
811  5. Chunk-specific phonologies 
 
812  5.1. Specific world-level phonology 
 
813  5.1.1. Everybody has a word-specific phonology 
 
This and the following thematic block (§ 828) work through the question of 
multiple computational systems in phonology: chunk-specific phonologies 
are examined first, followed by morpheme-specific phonologies.  
SPE "officially" held that phonology is one single computational sys-
tem, but in fact was already operating with a specific word-level phonology 
that was made distinct by representational means (thereby allowing to 
maintain the unity of a single set of ordered rules, see § 104). 
This may be considered the (unconceded) birth of chunk-specific 
phonologies. As far as I can see, all subsequent theories, their disagreement 
elsewhere notwithstanding, provide for a specific word-level phonology in 
one way or another. The notion of chunk-specific phonology was intro-
duced in § 234, and a comparative tableau in § 236 shows under which ban-

684 
Chap 6: Open questions (procedural) 
ner they run in different theories. Phonological interpretation of word-sized 
chunks by a specific computation is referred to as lexical post-cyclic rules 
in Lexical Phonology (Rubach & Booij 1984, § 194) and as non-cyclic rules 
in Halle & Vergnaud (1987a, § 233). Although Kaye (1995) firmly and ex-
plicitly rejects multiple computational systems (phonological computation 
reduces to the φ-function, which is one is indivisible, see § 267), he admits 
the existence of a specific word-level computation in practice (§§ 283,338). 
It is true, however, that I could not identify any formalised version of word-
level phonology in OT-based interface theories (which typically implement 
morpheme-specific phonologies, either serially, § 483, or in parallal fashion, 
§477). 
 
814  5.1.2. Since SPE, word-specific phonologies are based on (English) stress 
 
A remarkable property of the idea of a word-specific phonology is that it 
has always been motivated by English stress. The original reasoning of 
Chomsky & Halle (1968) is exposed in § 105 and has remained the typical 
motivation for word-specific phonologies up to the present day. Probably 
other phenomena from other languages have also been mobilised, but in 
any case the reader may be sure to meet English stress when it comes to 
explain word-specific phonologies, no matter what the theory. 
English stress requires that a specific computation applies exactly 
and exclusively to word-sized chunks: the rules in question must not apply 
to any chunk below the word level, nor to any piece that is bigger than a 
word. This is because other properties of the word are calculated according 
to where primary stress sits: vowel reduction (to schwa) applies to un-
stressed vowels (the detail is more complicated but irrelevant here, some 
illustration is provided in §§ 334, 339).  
Since primary stress may be modified by stress-shifting (class 1) 
morphemes until the last concatenation, vowel reduction cannot apply be-
fore the last morpheme has joined in. On the other hand, vowels that have 
once been reduced to schwa cannot be "unreduced" by later computation of 
larger units: their reduction is set in stone. Intonation (sentence stress) for 
example manipulates the relative prominence of words as such, but is per-
fectly unable to modify the relative prominence of vowels (stress or vowel 
reduction) inside words. 
Vowel reduction must therefore apply exactly once in the derivation: 
at the word level, i.e. after the last morpheme has been concatenated and 
computed, and before any further computation that involves larger units. 

Chunk-specific phonologies 685 
The fact that English (primary) stress is a problem child needs to be 
taken into account, though. Recall from § 780 that it has always messed up 
no look-back generalisations: it violated the SCC-K (i.e. could apply to 
non-derived environments, see § 192), does not observe Phase Impenetrabil-
ity in Marvin's (2002) analysis (§ 555) and also violates Kaye's modifica-
tion-inhibiting no look-back in anti-affix-ordering strings (e.g. gov-
ern-mént-al, see § 834). 
Given this criminal record of (English) stress, there may be reason to 
feel queasy about the fact that a prominent device of phonological interface 
theory, the existence of a specific computational system for word-sized 
pieces, historically roots in the analysis of English stress, and since SPE has 
been carried over to all major theories on the grounds of the same evidence. 
 
815  5.2. Specific sentence-level phonology: Praguian segregation 
 
816  5.2.1. Cyclic phonology of morphemes vs. non-cyclic phonology of words 
 
The other chunk-specific division of phonology into distinct computational 
systems that is argued for in the literature is called Praguian segregation in 
this book (see § 153). It distinguishes between the interpretation of mor-
pheme- and word sequences, which are held to be done by two distinct 
computational systems, lexical and postlexical phonology. 
Lexical Phonology has given an architectural status to this insight in 
placing word phonology (the Lexicon) before syntactic computation, while 
sentence phonology is only done when syntax has completed the concate-
nation of words (see §§ 152f). 
The idea of two distinct computational systems for the interpretation 
of morpheme- and word sequences was taken over by modern OT-based 
incarnations of Lexical Phonology (Stratal OT, DOT, see § 483). On the 
other hand, this division is denied by SPE (§ 102), Halle & Vergnaud 
(1987a) (§ 238) and Kaye (1995) (§§ 283, 301). 
Another effect of the Lexical Phonology tradition is the non-cyclic 
anchoring of sentence phonology (§ 158). While there is no a priori reason 
to believe that morpheme sequences are, but word sequences are not inter-
preted according to their cyclic structure, the non-cyclicity of postlexical 
phonology was set in stone by the idea that prevailed in early Lexical Pho-
nology according to which cyclicity is an exclusive property of the Lexi-
con. This is what Kiparsky's adaptation of the Strict Cycle Condition 
(SCC-K) expresses (see § 188).  

686 
Chap 6: Open questions (procedural) 
This question, together with more detail regarding the historical de-
velopment of Praguian segregation, was discussed in §§ 787f. The empirical 
situation that the literature offers, which is undisputed though unspoken, 
appears to support the conclusion of Lexical Phonology: there do not seem 
to be any phonological effects of the cyclic spell-out of words. This is 
strange in itself, and was called the word-spell-out-mystery in § 794. Its 
empirical validity, namely regarding intonation, was examined in § 800. 
Given the theoretical bias that was introduced by Lexical Phonology 
(postlexical phonology must be non-cyclic), it therefore remains to be seen 
whether the absence of phonological effects of cyclic spell-out of words is 
a fact about this bias or really a fact about language. 
 
817  5.2.2. Arguments for Praguian segregation 
 
Why should the computational system that interprets morpheme sequences 
be different from the computational system that assesses words? Because 
morpheme- and word-phonologies do not behave in the same way, is the 
answer of Lexical Phonology. Below this basic argument is examined along 
the lines of double dissociation, the diagnostic for the identification of dis-
tinct computational systems (distinct cognitive modules) that was discussed 
in § 618. 
Another obvious argument in favour of Praguian segregation is the 
word-spell-out-mystery: if the generalisation is empirically correct, it is 
hard to see how a distinction between the interpretation of morphemes and 
words could be avoided. 
 
818  5.3. Praguian segregation and double dissociation 
 
819  5.3.1. Double dissociation applied to Praguian segregation 
 
Double dissociation (§ 618) is a method that provides evidence for the inde-
pendence of two systems: if each can exist and work normally in absence 
of the other, there is reason to believe that they are distinct (rather than 
emanations of the same entity). 
Praguian segregation is the claim that the computational system 
which interprets morpheme sequences is different from the computational 
system that interprets word sequences. The opposite claim, i.e. that chunks 

Chunk-specific phonologies 687 
of all sizes are assessed by the same phonology, is made by SPE, Halle & 
Vergnaud (1987a) and Kaye (1995). 
Evidence in favour of the existence of two independent computa-
tional systems will thus be produced if it can be shown that phonological 
processes may be restricted to either morpheme- or word sequences, or 
apply across the board. Table  (326) below makes the conditions of double 
dissociation explicit. 
 
(326) there is reason to believe that the interpretation of morpheme- and word 
sequences is done by two independent systems if there are phonological 
processes that 
 
a. apply to morpheme-, but not to word sequences and 
 
b. apply to word-, but not to morpheme sequences and 
 
c. apply to both morpheme- and word sequences 
 
The three cases are examined one by one on the pages below. Rele-
vant discussion regarding a chunk-specific PIC à la carte was already done 
in § 241 and §§ 780, 796f, 809. 
 
820  5.3.2. Processes that are restricted to morpheme sequences 
 
We have already come across (326a): English primary stress placement 
applies only below the word level: stress may be shifted upon the concate-
nation of (class 1) morphemes, but once the word level is reached the word 
is sealed: no further concatenation of the word with other pieces can trigger 
the reapplication of the rule that is responsible for primary stress place-
ment.  
This is intuitively obvious: primary stress is also sometimes called 
word stress, and words have exactly one primary stress. Moving stress out 
of a word because of post-word concatenation would thus make a word 
stressless, which is impossible (for "real" words, but this distinction does 
not matter here). 
Also note that we are not talking about the question whether primary 
stress can be moved within the word upon post-word concatenation: it can 
if the process called stress clash (or the Rhythm rule) indeed moves the 
primary stress of a word that is too close to the primary stress of another 
word (thirtéen vs. thírteen mén, see § 556). One interpretation of this phe-
nomenon is that word stress is not completely sealed at the word level. Al-
ternatively, stress clash may be interpreted as a redistribution of promi-
nence among vowels that receive a certain degree of word stress (primary, 

688 
Chap 6: Open questions (procedural) 
secondary etc.), which however does not modify word stress itself. In any 
event, stress clash is not an instance of the stress placement rule that reap-
plies: this process is strictly bound by the limits of the word. Stress clash is 
a different phonological process that applies to word sequences. 
What would be awaited if the process of stress placement were active 
below and above the word level is a continuous move to the right as new 
words are concatenated, and a result where the string of words bears only 
one primary stress that appears close to the right margin of the sequence. 
This of course is not what we observe: the concatenation of fóllow and 
Jóhn is not treated like the merger of órigin and -al: main stress is not cal-
culated anew, that is vowels that bore stress on earlier cycles are not 
destressed, and formerly unstressed vowels do not acquire stress. 
The game is not the same, of course, because fóllow and Jóhn bear 
already primary stress when they are concatenated; by contrast, órigin is 
merged with a stressless affix. This is true, but in order to derive the em-
pirical contrast from that, a no look-back device is needed ± one that seals 
word stress at the word level and makes it immune for any further access of 
the word stress placement rule. 
The solution in Lexical Phonology where Praguian segregation is 
applied is to make the process at hand present in lexical, but absent from 
postlexical phonology. On the other hand, systems that provide for only one 
computational system for all chunk sizes need to make the word an insu-
perable barrier for all processes of the (326a) pattern. 
 
821  5.3.3. Processes that apply across the board 
 
Many phonological processes apply across word boundaries, i.e. instantiate 
(326c). Especially the Prosodic Phonology literature documents relevant 
patterns. English t-flapping is a classical case in point. The literature on 
t-flapping in General American, both descriptive and analytic, is abundant; 
it includes Kahn (1976), Kiparsky (1979), Mohanan (1982), Kaisse 
(1985:25ff) and Rubach (1996a). The data under  (327) below are taken 
from Nespor & Vogel (1986:46f, 224ff) and Balogné-Bérces (2005). 
 

Chunk-specific phonologies 689 
(327) t-flapping in General American185
a. word-internal /t/ 
 
[ɾ]
city, atom 
 
b. word-final /t/ across word boundaries 
 
[ɾ]
at issue 
a white owl 
invite Olivia 
at eleven 
just the other night a racoon was spotted in our neighbourhood 
 
According to Nespor & Vogel (1986), flapping is entirely unbounded 
within the highest constituent of the Prosodic Hierarchy, the phonological 
utterance. That is, flapping applies in all syntactic environments alike pro-
vided the /t/ is word-final and intervocalic. 
Praguian segregation accounts for across-the-board processes by 
making the relevant rule part of both the lexical and the postlexical phonol-
ogy of the language. Note that there is no way to predict whether a given 
rule will belong to either computational system, or to both. 
In the alternative perspective where only one computational system 
assesses chunks of whatever size, the across-the-board pattern is expected: 
"regular" phonological processes should be of this kind. All restrictions to a 
specific chunk size depart from the idea, inherent to this conception, that 
chunk size does not matter for the application of phonological rules (Scheer 
2009a,c). 
 
822  5.3.4. Processes that are restricted to word sequences 
 
Processes that follow pattern (326b), i.e. apply across word-, but not across 
morpheme boundaries, are the sentence-level version of derived environ-
ment effects (§ 177): like these, they apply only across a domain boundary, 
but are inert with the domain in question. And like derived environment 
effects, processes that follow this pattern are the nightmare case for systems 
that provide for only one interpretational system: instead of being inside-
 
185 Within words, flapping is inhibited if the following vowel bears stress: [ɾ] átom 
vs. *[ɾ] atómic. Also, only word-final /t/ is subject to flapping across word 
boundaries: word-initial /t/ does not react (*[ɾ] a tissue, which makes a minimal 
pair with [ɾ] at issue. These aspects of the phenomenon are irrelevant for the 
discussion. 

690 
Chap 6: Open questions (procedural) 
out, this pattern appears to parse the string from "outside in", i.e. in anti-
cyclic fashion. 
Several instances of the pattern (326b) are reported in the literature, 
the most prominent being so-called Cracow voicing (to be discussed be-
low). All cases that I could identify, though, concern voicing, and this is 
highly suspicious: the gordian knot is always a cross-word regressive influ-
ence of word-initial sonorants (and sometimes vowels) on preceding word-
final obstruents (sometimes only on frcatives as in Catalan) whereby under-
lyingly voiceless obstruents are voiced. The same process, however, is not 
observed within morphemes or across morpheme boundaries. Cracow 
(Poznań) voicing is discussed by, among others, Bethin (1984) and Rubach 
(1996b), Catalan facts are described by Wheeler (1986) and Bermúdez-
Otero (2006), and relevant data from West Flemish are documented by De 
Schutter & Taeldeman (1986). 
The fact that no phonological properties other than voicing seem to 
be involved casts doubt on the reality of the anti-cyclic pattern, and espe-
cially the transmission of voicing from sonorants and vowels to voiceless 
obstruents is suspicious (see e.g. Rice 1993 on active voicing of sonorants 
and vowels). Therefore the literature typically studies the question whether 
the effect is phonetic, rather than phonological (Michalski 2009:205ff, 
Strycharczuk 2010). 
Let us look at the best known case, Cracow voicing. The discussion 
below follows Rubach (1996b), who compares two varieties of Polish, 
Warsaw and Cracow. To a large extent, the two dialects show the same 
behaviour in regard of voice assimilation: both have final devoicing, and 
voice assimilation is consistent in obstruent clusters, across morpheme- as 
much as across word boundaries. What sets both dialects apart is their be-
haviour when an obstruent-final word is followed by a sonorant- or vowel-
initial word. As is shown under  (328) below, the Warsaw variety behaves as 
expected, i.e. devoices word-finally, without the word-final obstruent being 
subject to any influence from the following word. In Cracow, however, the 
word-final obstruent systematically voices when the following word begins 
with a sonorant or a vowel. 
 
(328) Cracow-Poznań voicing 
 
a. across word boundaries 
 
/d # V/son/ [d # l] 
samochód Leona 
Leon's car 
 
[d # o] 
samochód ojca 
father's car 
 
/t # V/son/ 
[d # l] 
brat Leona 
Leon's brother 
 
[d # o] 
brat ojca 
father's brother 

Chunk-specific phonologies 691 
(328) Cracow-Poznań voicing 
 
b. across morpheme boundaries 
 
[t - o] 
brat-owa 
brother's wife 
 
[t - a] 
brat-a 
brother GENsg 
 
[t - n] 
brat-ni 
brotherly 
 
c. morpheme-internally 
 
[ta] 
Katarzyna 
Cathrine 
 
[tr] 
wiatru 
wind GENsg 
 
(328b) shows that the regressive assimilation does not go into effect 
when a voiceless obstruent is followed by a sonorant or a vowel across a 
morpheme boundary, let alone morpheme-internally as under (328c). 
In a system that acknowledges Praguian segregation, this pattern is 
simply accounted for by inscribing the rule at hand in the pool of postlexi-
cal, but not in the pool of lexical phonology. On the other hand, there is no 
way I can see in which theories that provide for only one interpretational 
system for all chunk sizes could account for this pattern. A no look-back 
restriction of the PIC-kind will not do: given inside-out interpretation, the 
process must not apply in earlier computation, but needs to go into effect 
when larger strings are assessed. No look-back devices are thus out of busi-
ness, and one would need to introduce something like a "no look-ahead 
device", which is unheard of elsewhere. 
It was already mentioned that the problem looks strikingly similar to 
derived environment effects (for which nobody has a good solution, see 
§§ 207, 516, 837); this suggests that a the best solution, if any, will be one 
that is applicable to both phenomena, which differ only in the size of the 
chunks involved (morphemes in derived environment effects, words in 
 (328)). 
 
823  5.4. PIC à la carte 
 
824  5.4.1. Multiple mini-phonologies and chunk-specific phonologies 
 
Let us now sum up what we know about distinct computational systems in 
phonology in general, and chunk-specific mini-phonologies in particular. 
The fact that a specific computational system for the word level is largely 
consensual was documented in § 813. This means that there is no principled 
reason to reject the cohabitation of distinct computational systems in pho-
nology, not any more than there is reason to doubt the existence of chunk-
specific phonologies: if there is a particular interpretational system for the 

692 
Chap 6: Open questions (procedural) 
computation of the chunk size "word", there could also be one for other 
chunk sizes. 
The evidence for the computation of morpheme- and word sequences 
by distinct computational systems (Praguian segregation), however, is in-
conclusive: the empirical validity of the word-spell-out-mystery needs to be 
confirmed, and the evidence from double dissociation that was examined in 
§818 hinges on the interpretation of the Cracow voicing pattern as a real 
phonological (rather than phonetic) process. 
An entirely different question are distinct morpheme-specific compu-
tational systems, the basic tool of Lexical Phonology (level 1 vs. level 2 
phonology). There may be no reason to reject multiple interpretational sys-
tems in phonology as such, and chunk-specific mini-phonologies in particu-
lar, but this does not mean that any additional mini-phonology is welcome. 
Morpheme-specific phonologies are discussed in § 828 below. 
 
825  5.4.2. Process-specific PIC, rather than "don't undo!" 
 
In § 302, it was shown that for a variety of reasons Chomsky's "spell-out 
and forget" is too strong a condition in phonology. Two ways in which this 
rigid formulation of the PIC could be weakened were considered: process-
specific PIC or "don't undo!" where only those properties of a previously 
interpreted string may not be modified that were created by phonological 
computation. Under "don't undo!", English stress is not negotiable beyond 
the word level because it was acquired by previous computation, but noth-
ing prevents t-flapping from going into effect across word boundaries since 
word-final dentals were not subject to any previous processes. 
It was already pointed out in § 307 that the notion "old" and "new" is 
not quite the same with the two solutions: under "don't undo!", an new item 
that needs to be guaranteed against further modification is not just any 
string that has was previously interpreted: it is only those particular proper-
ties of a string that were created by previous computation, i.e. which are 
absent from the lexicon. This seems to require some diacritic marking on 
top of the memory-keeping mechanism that is needed anyway for all no 
look-back devices (§ 799).  
This may be reason to believe that process-specific PIC is a less in-
convenient way to distinguish the "old" and the "new". Finally, recall from 
§780 that process-sensitive PIC has also been proposed in syntax (Boãković
2007). 
 

Chunk-specific phonologies 693 
826  5.4.3. PIC à la carte: process- and chunk-specific 
 
The English facts discussed in §§ 820f show that in case a single computa-
tional system that applies to all chunk sizes is upheld (and hence Praguian 
segregation dismissed), the PIC must be process-specific: it marshals stress 
assignment, but not t-flapping. The process-specificity of (external) sandhi 
seems to be a hard empirical fact (that we have come across on a number of 
occasions in the book: §§ 193, 241, 302, 780, Balogné-Bérces 2004, 2005). 
Process-specific PIC is not enough, though, to account for the Eng-
lish data. In addition, it needs to be somehow specified at which chunk size 
exactly stress assignment is marshalled by the PIC: at the word level (rather 
than, say, at every application of Merge). Since the PIC is associated to 
phases, this just means that the word is a phase in English ± not quite spec-
tacular an insight.  
We have seen in § 809, however, that the word-spell-out-mystery, if 
real, requires that all syntactic phases, i.e. everything above the word level, 
be exempted from PIC-effects: the PIC is "switched off" for phonological 
computation beyond the word level (and no matter what process is in-
volved). But even if the word-spell-out-mystery turns out to be spurious, 
t-flapping must somehow be allowed to ignore the PIC condition that 
should be associated with syntactic phases: the fact that it goes into effect 
shows that the vP phase for example does no harm to the process.  
This means that it is certainly important and useful to know what the 
phase structure in a language looks like, but that this does not tell us any-
thing about its eventual phonological footprint: phases may or may not 
enforce Phase Impenetrability, i.e. every phase boundary may or may not 
be armed with a PIC. 
The PIC is thus both process- and chunk-specific: the system that en-
forces the PIC upon phonological computation looks at both parameters 
before making a decision. This is recapitulated under  (329) below. 
Note that in case a process is declared to be unsubjected to the PIC at 
a given phase, this does not mean that it actually goes into effect at this 
phase: recall that in the present chapter we are only talking about proce-
dural means to influence phonology. There are also representational ways 
of preventing a process from applying: classically, all external sandhi is 
managed by representational instruments (§ 787). Vol.2 discusses at length 
how non-diacritic carriers of morpho-syntactic information (CV units) can 
inhibit or trigger external sandhi. 
 

694 
Chap 6: Open questions (procedural) 
(329) process- and chunk-specificity of the PIC 
for each phase (chunk-specificity), it is specified which processes (proc-
ess-specificity) are subjected to a PIC condition. 
 
Examples 
 
word stress 
t-flapping 
 
 
 
CP 
yes 
no 
 
 
vP 
yes 
no 
DP 
yes 
no 
word 
yes 
no 
level 2 affixation 
yes 
no 
level 1 affixation 
no 
no 
Finally, recall that parameterising the PIC may not appear to be a 
very minimalist thing to do at first sight: the PIC is an instrument of com-
putational economy, and PIC à la carte amounts to economy à la carte. 
Computational economy conditions, however, are supposed to be always 
obeyed. This being said, Chomsky (2004:107f) senses that "spell-out and 
forget" may be too strong a condition on phonological computation (§ 306,
quote  (129)) ± something that was observed in § 302 anyway. Therefore PIC 
à la carte does not appear to be an outlandish mechanism in a minimalist 
environment (see §§ 780, 797). 
 
827  5.5. Conclusion 
 
Process-specificity and chunk-specificity seem to be undisputed facts of 
(external) sandhi phonology. Since the 80s, the standard way of managing 
both phenomena is Praguian segregation, a major insight of Lexical Pho-
nology (which is carried over into all modern versions thereof, see § 489). 
The preceding sections have evaluated the opportunity to replace the 
Praguian mechanism that is based on two distinct and chunk-specific com-
putational systems (lexical and postlexical phonology) by a perspective that 
builds on phase theory and the PIC, and where only one computational 
system assesses all strings. Following this track, the instrument that en-
codes process-specificity and chunk-specificity is the parameterisation of 
Phase Impenetrability. 
In the system that builds on PIC à la carte, phonological interpreta-
tion is completely regular and inhibition-driven: by default it applies across 
all boundaries of all kinds unless a no look-back condition stands in the 

Morpheme-specific mini-phonologies (level 1 - level 2) 695 
way. The normal situation is thus regularity, and it takes specific grammati-
cal action ± adding a PIC condition ± to produce irregularity. This is how 
regularly invisible structure is made visible to the phonology. 
Praguian segregation has certainly a number of things going for it: 
the fact that the word level is a recurrent barrier for phonological processes 
across languages, the word-spell-out-mystery and double dissociation. The 
two latter arguments, however, are inconclusive for the time being, and the 
question is left open in the end. 
 
828  6. Morpheme-specific mini-phonologies (level 1 - level 2) 
 
829  6.1. Cyclicity analysed by morpheme-specific mini-phonologies vs. by no 
look-back: a major front line in generative interface theory 
 
The idea that phonological interpretation could fall into two (or several) 
distinct computational systems according to the morphological properties 
of the string was introduced into interface thinking by Lexical Phonology, 
of which it is a (perhaps the) genetic footprint (see § 212). 
Theories line up for or against morpheme-specific mini-phonologies 
in the following way: while SPE, Halle & Vergnaud (1987a), Kaye (1995) 
and Distributed Morphology reject the idea, it stands unchallenged in pre-
sent-day OT-based phonology (in serial or parallel incarnations, see 
§§ 477, 483). 
The alternative is an architecture where strings of whatever morpho-
logical composition are interpreted by the same computational system. 
Morpheme-specific mini-phonologies exist in order to account for affix 
class-based phenomena, that is cyclicity effects: what they do is to organise 
underapplication (opacity) (see § 150). The alternative way to do the same 
labour is through selective spell-out (§ 228,, summary in § 763) and a no 
look-back device (§ 279). It was shown in § 303 that the two instruments ± 
morpheme-specific mini-phonologies and no look-back devices ± do the 
same job and are therefore competing devices: they are mutually exclusive. 
The line-up of theories and the use of no look-back cuts an aisle 
through the interface landscape, which it does not take long to interpret: a 
Chomskian strand that follows SPE and uses no look-back (which is a 
Chomskian idea, see § 287) is opposed to an approach that has left the 
Chomskian track in the early 80s. A good measure of this contrast is the 
charge of orthodox generative quarters against Lexical Phonology that was 
led by Morris Halle in the 80s (Halle & Vergnaud 1987a, see § 216). 

696 
Chap 6: Open questions (procedural) 
830  6.2. Intermodular argumentation: if the PIC exists in syntax, it must be 
active in phonology as well 
 
The opposition between the Chomskian and the Lexical Phonology track is 
not merely a phonology-internal matter: it has also a syntactic branch. That 
is, the spine of the current minimalist architecture, phase theory, reactivates 
no look-back, a Chomskian idea (Chomsky 1973, see § 287) that was un-
employed in the 80s, which has incarnated into Phase Impenetrability today 
(§ 304).  
In other words, Lexical Phonology's morpheme-specific mini-
phonologies are not only opposed to the PIC-based alternative in phonol-
ogy ± they also have to face the fact that the PIC is a critical ingredient of 
current syntactic theory: no look-back is the instrument of active memory 
economy, which is the (extra-linguistic) reason why derivation by phase 
exists in the first place (§ 306). 
The following is thus a relevant question: could a situation be imag-
ined where the PIC is a condition on morpho-syntactic, but not on phono-
logical computation? That is, would it be consistent with minimalist as-
sumptions that the economy of active memory forces syntax into a piece-
meal derivation, while phonology does not care for using active memory? 
There is certainly reason to believe that this is not a workable perspective: 
active memory is costly, no matter whether it stores syntactic or phonologi-
cal items; if the minimalist philosophy is on the right track, the phonologi-
cal system is constrained by active memory economy just as much as the 
syntactic system. An overall picture where the PIC is a central element of 
syntactic workings, but entirely absent from phonological mechanisms is 
not viable. 
Unsurprisingly enough, this is Chomsky's take: "the computational 
burden is further reduced if the phonological component too can 'forget' 
earlier stages of derivation" (Chomsky 2001:12f, see § 306 for a more com-
plete version of this quote). 
Given these premises, the phonology-internal competition for the 
analysis of cyclicity between morpheme-specific mini-phonologies and the 
PIC-based system may be refereed: the latter is selected. Which, of course, 
also rules out a scenario where both solutions co-exist in the same gram-
mar: no theory can afford accommodating two devices that do the same job 
(§ 303). 
The question just how much active memory economy is enforced, or 
should be enforced by the PIC, needs to be addressed, but is logically inde-
pendent. Recall from § 826 that PIC à la carte, i.e. the double parameterisa-

Empirical coverage 697 
tion of the device (process- and chunk-specificity), intermits active memory 
economy under certain conditions under the pressure of pervasive phono-
logical evidence: PIC à la carte is also computational economy à la carte. 
Following Structural Analogy (Dependency Phonology, see § 705), a 
weaker version of the same argument can be made in absence of any refer-
ence to active memory economy. That is, even in case phonological theory 
owes nothing to syntactic theory, the following situation is encountered: a 
tool, no look-back, is present in syntax, and is also one of two competitors 
for the analysis of cyclicity in phonology. A unifying perspective thus 
beckons: syntactic and phonological phenomena could be explained by the 
same tool. Or, in other words, why should a phonology-specific tool be 
used when its competitor is needed in syntax anyway? And when we know 
independently that both systems are related by a pipe through derivation by 
phase? 
 
831  7. Empirical coverage 
 
832  7.1. Introduction: three competitors and the empirical record (affix class-
based phenomena) 
 
What remains to be done is a comparison of the empirical coverage that the 
various theories reviewed can offer. In this book, affix class-based phenom-
ena in English are chosen as a uniform and well-studied testing ground in 
order to compare competing theories of the procedural management of the 
interface (see § 162). A by-product of this inquiry, as it were, is the discus-
sion of derived environment effects, which has actually taken on quite hon-
ourable dimensions (§§ 177, 516) and was a regular companion of the 
reader. Below derived environment effects are therefore included into the 
overview. 
The historical review of Part I has identified three relevant models: 
Lexical Phonology (past and present incarnations), Halle & Vergnaud 
(1987a) and Kaye (1995). The major front line runs between the former, 
where cyclic effects (underapplication) are accounted for by morpheme-
specific mini-phonologies, and the two latter, which do not provide for 
morpheme-specific computational systems in phonology (§ 828). Hand in 
hand with this choice (a necessary concomitance) goes the fact that Halle & 
Vergnaud's and Kaye's systems are based on selective spell-out, while 
Lexical Phonology spells out all nodes (§ 763). 

698 
Chap 6: Open questions (procedural) 
The difference between Halle & Vergnaud (1987a) and Kaye (1995), 
in turn, is that the latter uses a no look-back device (modification-inhibiting 
no look-back which is the ancestor of Chomsky's modern "freezing" PIC) 
in order to account for cyclic effects (underapplication), while the former 
do not. 
In § 833 below these three theories are run against the empirical re-
cord, which divides into two major classes. These enjoy a pre-theoretical 
definition and therefore appear to deserve credit. Recall from § 51 (and also 
§§ 163, 166) that a rule-blocking pattern (level 1 rules in Lexical Phonology) 
may be distinguished from a rule-triggering pattern (level 2 rules in Lexical 
Phonology). In the former case, a process that goes into effect in absence of 
a particular morpho-syntactic division is inhibited, while in the latter case a 
process which otherwise would not occur is triggered by a specific morpho-
syntactic environment. 
Finally, § 837 reviews the spectrum of analyses that have been pro-
posed for derived environment effects. 
 
833  7.2. Affix class-based phenomena 
 
834  7.2.1. The rule-blocking pattern 
 
The rule-blocking pattern is unproblematic for the three theories: underap-
plication (to class 2 strings) is achieved by morpheme-specific mini-
grammars (Lexical Phonology, § 150), selective spell-out alone (Halle & 
Vergnaud 1987a, § 228) or in association with the PIC (Kaye 1995, § 279). 
Two specific issues arise: strings that violate Siegel's (1974) affix or-
dering generalisation (i.e. where a class 2 affix occurs closer to the root 
than a class 1 affix, e.g. govern-ment2-al1, see §§ 142, 243), and the inde-
pendent spell-out of terminals (as opposed to nodes). The former cannot be 
covered by Lexical Phonology and by Kaye (1995), though not for the 
same reason: the stratal architecture is based on affix ordering and therefore 
structurally unable to do anti-affix-ordering strings;186 on the other hand, 
 
186 Hence only serial implementations of Lexical Phonology that maintain the 
original stratal architecture (level ordering § 150: first class 1 affixes are con-
catenated, then class 1 interpretation occurs, then class 2 affixes come in, then 
class 2 interpretation takes place, and no loop back is allowed) are concerned. 
OT-based parallel implementations of morpheme-specific mini-phonologies 
(see § 477) have no trouble with anti-affix-ordering strings: the relevant mini-
phonology is simply "called", whatever the linear (and hierarchical) order of af-

Empirical coverage 699 
Kaye's system cannot account for the items in question because they violate 
modification-inhibiting no look-back (§ 315). Significantly, though, this 
diagnostic is only based on one phenomenon, stress assignment, which is a 
notorious problem child (especially regarding the violation of no look-back 
devices, see §§ 556, 780, 814). Finally anti-affix-ordering strings are unprob-
lematic for Halle & Vergnaud (1987a) (§ 246). 
The issue regarding the spell-out of terminals prior to their being 
merged only concerns Kaye (1995), whose system predicts that this must 
be possible (§§ 274, 314). While spell-out only concerns nodes on standard 
assumptions, it was pointed out that the hypothesis of an independent inter-
pretation of terminals is also currently entertained in syntax (see § 316). 
 
835  7.2.2. The rule-triggering pattern 
 
Bare stratal architecture combined with morpheme-specific mini-
phonologies cannot cover this pattern. Lexical Phonology therefore needs 
some additional device. What exactly such a device should look like was 
much debated in the 80s, but what was proposed always looked like 
patches, rather than like solutions. Some modern heirs of Lexical Phonol-
ogy have simply given up: they outsource the pattern into suppletion (Ber-
múdez-Otero & McMahon 2006).  
The classical way to do the rule-triggering pattern in Lexical Phonol-
ogy is due to Mohanan (1982, 1986), who recurs to a representational de-
vice (brackets) and a no look-back mechanism, bracket erasure: rules are 
made sensitive to brackets, which are erased at the end of each stratum (see 
§166). Given the procedural ambition of Lexical Phonology (§ 213), the 
reintroduction of a representational device through the back door was not 
very popular. Also, it was pointed out that no look-back and morpheme-
specific mini-phonologies are direct competitors ± hence no theory can 
afford to accommodate both (see §§ 303, 830). 
As far as I can see, brackets and bracket-sensitive rules have never 
been eliminated from the analysis of the rule-triggering pattern in Lexical 
Phonology: this is also true for attempts to find alternative means of encod-
ing cyclicity when it became clear that Kiparsky's original take (according 
 
fixes. Bermúdez-Otero (forth a) follows this track. It was pointed out in § 484 
that the contrast between so-called stratal and parallel versions of morpheme-
specific mini-grammars is not as clear-cut as the literature may suggest: the 
former may well turn out to be a version of the latter, which means that the se-
rial issue evaporates. 

700 
Chap 6: Open questions (procedural) 
to which cyclicity is a property of the Lexicon as such, see § 188) was too 
strong. Non-cyclic islands in the Lexicon were proposed by Halle & Mo-
hanan (1985) who make cyclicity a property of strata (i.e. strata may or 
may not obey the SCC-K, see § 194) and by Rubach & Booij (1984 et pas-
sim) who maintain that all strata are cyclic, but introduce post-cyclic lexical 
rules, which apply after all strata, but still in the Lexicon (see also § 194).  
All that was done around the SCC-K and the various areas where 
cyclicity could be enforced has not produced a handle on the rule-triggering 
pattern, which continues to require reference to brackets and some no look-
back device. Which takes us back to the aforementioned incompatibility of 
the latter with morpheme-specific mini-phonologies. 
Finally, it was mentioned in § 203 that Kiparsky's SCC-K is able to 
cover the rule-triggering pattern, an option that for some reason does not 
seem to have been explored. But the abandon of the SCC-K (§ 197) clears 
that option anyway. 
Given this inveterate problem child, modern representatives of the 
stratal architecture have simply given up on the rule-triggering pattern: 
Bermúdez-Otero & McMahon (2006:398) argue that it is not the result of 
any synchronic phonological activity. Rather, damn - damn-ing and 
damn-ation for example represent three independent lexical entries: /dQm/, 
/dQmn/ and /dQmneiʃn/. The phenomenon as such is thus outsourced to 
suppletive management. 
Soon after having proposed strata-specific cyclicity in Halle & Mo-
hanan (1985), Morris Halle also gives up on the rule-triggering pattern: 
Halle & Vergnaud's (1987a) system is unable to account for the phenome-
non, but unlike Bermúdez-Otero & McMahon (2006), Halle & Vergnaud 
simply do not talk about the issue: I could not find any mention of the rule-
triggering pattern in the relevant literature (§ 250). 
Contrasting with the difficulty that Lexical Phonology and Halle & 
Vergnaud (1987a) experience, the rule-triggering pattern is unproblematic 
for Kaye's (1995) system (see § 321). Logically, the PIC must be held re-
sponsible since its action is what sets Kaye's approach apart from the oth-
ers. 
Finally, it is worth mentioning that Kaye's analysis of the rule-
triggering pattern makes a prediction to the end that all processes of this 
kind must be subjected to a phonological condition on top of being sensi-
tive to affix classes (see § 325). In the case of English nasal cluster simplifi-
cation, this is the fact of applying only in morpheme-final position 
(sign-ing vs. i[g]nore). 
 

Empirical coverage 701 
836  7.2.3. Is the rule-triggering pattern less real? 
 
It was already mentioned that the distinction between the rule-blocking and 
the rule-triggering pattern is pre-theoretical and exhausts the logical possi-
bilities of how morpho-syntactic divisions can bear on phonological proc-
esses (see § 51); it therefore deserves credit. The stratal architecture of clas-
sical Lexical Phonology echoes this division by making rule-blocking 
processes level 1 rules, against rule-triggering processes, which appear as 
level 2 rules. This is a remarkable result since the stratal makeup was not 
designed in order to reproduce the empirical contrast. There is thus reason 
to believe that it is empirically meaningful. 
Now the discussion has shown that theories are not well suited for 
the analysis of the rule-triggering pattern and therefore tend to make it less 
real, either relegating it to suppletion (Stratal OT), or sweeping it under the 
rug (Halle & Vergnaud 1987a). It was just pointed out, though, that there is 
little reason to believe that rule-triggering processes are less natural or less 
real than rule-blocking processes. Both represent logical possibilities of 
procedural intervention in phonology. 
It is therefore reasonable to acknowledge that Kaye's PIC-based sys-
tem fares better empirically speaking, at least as far as English affix class-
based phenomena are concerned. It uses the same technology for both rele-
vant patterns (modification-inhibiting no look-back) and makes a number 
of predictions that have an impact in and beyond phonology (§§ 316, 325). 
 
837  7.3. Derived environment effects 
 
838  7.3.1. A separate issue 
 
Let us now look at derived environment effects. Before examining specific 
analyses, it is important to recall that this phenomenon and affix class-
based phenomena are two separate issues. Lexical Phonology in general 
and Paul Kiparsky in particular have put a lot of effort into showing that 
both phenomena can be reduced to a single mechanism, the SCC-K. All 
attempts in this direction failed, and it took quite some time to understand 
that this unifying ambition is on the wrong track (see §§ 197,785). 
It was shown in § 182 that sensitivity to affix classes and derived en-
vironments is logically independent: one may occur without the other. This 
means that a theory may be successful in one area, but not in the other, 
without this having any significance beyond this very fact. 

702 
Chap 6: Open questions (procedural) 
839  7.3.2. A blooming landscape of analyses 
 
Let us now consider individual lines of attack, starting with voices that 
argue for placing derived environment effects outside of grammar alto-
gether. This idea originates in Anderson (1981) (§ 204); it is entertained in 
various brands by Kiparsky (1993), who tries to make the relevant distinc-
tion lexical (§ 196), and by Burzio (2000a,b), who attempts at making de-
rived environment effects a case of analogy (§ 519, as so many other 
things).187
Solutions that propose a grammar-internal mechanism were dis-
cussed in relation with Lexical Phonology (§ 177, with a summary in § 207), 
with Halle & Vergnaud's (1987a) (§ 237) and Kaye's (1995) system 
(§§ 284, 300), as well as with OT (§§ 509,516). 
One group may be identified by the strategy to differentiate between 
"old" and "new" morphemes and/or computation. In the 80s (and in Lexical 
Phonology), this is the case of Mohanan's brackets (§ 201) and Kiparsky's 
SCC-K (§ 188); in the OT environment, van Oostendorp's (2006a) Coloured 
Containment (§§ 509,518), McCarthy's (2003a) Comparative Markedness 
(§ 519), and Cho's (2009) revival of Kiparsky's Elsewhere Condition (§ 521)
hook up with this tradition. 
Another way to go about derived environment effects was opened by 
the idea of parallel (instead of serially ordered) morpheme-specific mini-
phonologies (see § 477). Where others have to make acrobatic moves and 
add extra machinery, the parallel system just needs to set up a specific pho-
nology for the root. This comes with no conceptual expense since it simply 
extends the use of the basic tool of the theory, morpheme-specific mini-
grammars. Yu (2000) has explored this track along the lines of co-
phonologies (§ 522). 
Finally, a third group of analyses may be criticized either for general 
reasons or from the vantage point of modularity. Łubowicz (2002) and Cho 
(2009) are hardly viable because of the general properties of their analyses. 
The former offers only a solution for phonologically derived environments 
that is not applicable to morphologically derived environments (the latter 
being of course the primary target in interface discussion). This was pointed 
out by van Oostendorp (2006a, 2007) (see § 518). On the other hand, Cho 
(2009) simply writes a constraint which restates the observation that roots 
are faithful to their lexical makeup (FAITH-LEX, see § 521). If we write a 
 
187 This supposes that analogy ± which is called Output-Output Faithfulness in OT 
± is considered a mechanism that lies beyond the limits of grammar proper. 

Empirical coverage 703 
specific constraint for every empirical phenomenon, we will no doubt suc-
cessfully derive all existing patterns (as well as many others) ± but the re-
sult will be closer to a sophisticated description in prose than to what a 
grammar looks like. 
Van Oostendorp's Coloured Containment (§§ 509,518) and Anttila's 
interface constraints (Root Faithfulness § 520) violate modularity by virtue 
of making direct reference to morphological categories (direct syntax). 
Finally, Kula (2008) offers a representational solution for a number 
of well-known cases: the idea is to derive the different behaviour of derived 
and underived items from distinct lexical representations. Whether this 
approach may be generalised to all derived environment effects remains to 
be seen. 
 
840  7.3.3. Anti-cyclic phenomena: derived environment effects have a big 
brother 
 
Derived environment effects describe a situation where computation ap-
plies to a morphologically complex chunk, but not to the pieces that it is 
made of. To the extent that these pieces are interpretational units (phase 
heads, which may or may not be the case), all theories that do not provide 
for morpheme-specific mini-phonologies are structurally unable to cover 
the pattern. This is because the smaller piece must be interpreted (because it 
is a phase head), but at the same time must not (because it is underived). 
These conflicting requests can only be satisfied by distinct interpretational 
systems. 
Now recall the interesting parallel at the word level that was de-
scribed in § 822: there are processes that apply across word boundaries, but 
do not go into effect across morpheme boundaries (or within morphemes). 
So-called Cracow voicing is the best-known representative of this class of 
processes (which all seem to be based on voicing). Their parallel with de-
rived environment effects is obvious: in a three-chunk hierarchy made of 
the context 1) "within morphemes", 2) "across morpheme boundaries" and 
3) "across word boundaries", Cracow voicing-type processes apply to 3), 
but not to 2) and 1), while derived environment effects apply to 2), but not 
to 1). 
As far as I can see, this parallel has gone unnoticed in the literature. 
One way to go about derived environment effects, then, would be to evalu-
ate analyses with respect to their ability to also cover the big brother, i.e. 
sentence-level "outside-in" (or anti-cyclic) phenomena. 


Conclusion 
841  Intermodular argumentation 
 
842  1. Trying to get a handle on the interface 
 
843  1.1. Looking at the interface through the prism of its history 
 
At the end of this survey, a summary is not really what is needed: the entire 
Part II is devised for this function, and the chapters and sections are meant 
to work out focal points of interest in interface design. It does not really 
make sense to go over them one by one, but it is certainly an interesting 
fact to be pointed out that the headlines of Part II are not exactly what a 
reader of the interface literature comes across: procedural vs. representa-
tional management of the interface, inside-out interpretation, selective 
spell-out, local vs. non-local representational intervention in phonology, 
privativity, the word-spell-out mystery, to mention just a few.  
There are two explanations for this discrepancy that I can think of. 
On the one hand, it is a result of the historical study: looking at an object 
over time does not produce the same image as a punctual examination. If 
this is the case, it was worth going through the pains of Part I and II (as 
well as through the Interlude). On the other hand, interface theories and 
phenomena have not been interpreted without direction: as was mentioned 
in the introduction, the book is conceived so as to look at the interface 
through two prisms, the difference between representational and procedural 
means of talking to phonology, and modularity. This may also make a dif-
ference. 
 
844  1.2. Two more prisms used: Interface Dualism and modularity 
 
The procedural-representational prism mimics the filter that Stephen 
Anderson has applied to the history of phonology in the 20th century (St. 
Anderson 1985). Modularity is an extra-linguistic referee: following one of 
the deepest layers of generative thinking, I take for granted that the mind is 
organised along a modular architecture; and that language is modular in this 
sense. Modularity imposes a number of restrictions on how modular com-
putation can look like, and on intermodular communication. Conclusions 

706 
Conclusion: Intermodular Argumentation 
have repeatedly been drawn on these grounds: interface theories have either 
proved compatible with modular requirements (e.g. Prosodic Phonology, 
see § 410), or were found to offend modularity in various ways and for a 
number of reasons (see the summary in § 702). 
Although modularity has grounded generative thinking since its ear-
liest incarnations (see §§ 603, 623 on Chomsky's participation in the compu-
tational perspective of post-war science), although a good deal of Fodor's 
(1983) formalisation of the modular idea was based on language and the 
book itself a result of a class co-taught with Chomsky, and even though 
modularity is part and parcel of every general introduction to generative 
linguistics, it is quite striking to see how small the footprint of modularity 
is in generative interface thinking. This is one thing that I have learned 
while working through the literature. 
There is reason to believe that modularity is a good compass for 
identifying the position of interface theories on the linguistic chess board. 
Those who do active interface design should be aware of what it takes to 
respect modular requirements, as well as of the consequences that that their 
violation has for the positioning of the theory in the landscape of cognitive 
science. 
 
845  1.3. Three theory-external ways to get a handle on interface theory 
 
One goal of the book is thus certainly to make a historiographic contribu-
tion to structuralist and generative interface theory; that is, to make histori-
cal generalisations, to identify traps that theories may want to avoid, and to 
work out the basic ideas that circulate, often enough in various disguises 
that are not understood as such, and on the backdrop of the parasitic noise 
that theories and data may generate.  
One of the strands that runs through all of structuralist and generative 
interface thinking is actually modularity itself. Relevant evidence is bun-
dled in § 692: structuralists practised Level Independence, which conceives 
of morphology and phonology as two ontologically distinct worlds and 
enforces translation; Prosodic Phonology set up Indirect Reference and a 
Translator's Office, but visibly ignored that this architecture materialises the 
modular idea (§ 414); finally, Lexical Phonology introduced interactionism, 
that is modern derivation by phase, obviously without being aware of the 
fact that this architectural design is the only way to reconcile inside-out 
interpretation with modular requirements (§ 680). 

Intermodular argumentation 707 
The book is thus designed to study the history of interface thinking 
not just for the historiographic sake, but also in order to get a handle on 
what is right and wrong, how we can avoid to reinvent the wheel with 
every new theory, which mistakes have already been made and do not need 
to be repeated, which ideas seep through when theories come and go, and 
how we can apply what history has taught us to the present-day landscape. 
Vol.2 ought to be a result of this track. 
Therefore the book tries to get a handle on present-day interface 
theories; it attempts to gain insight into the properties that a correct inter-
face theory must not have, and into those that it must have. One way is 
studying the history of the field. Another way is modularity, i.e. the recog-
nition that language and its interfaces are constrained by the general proper-
ties of the cognitive system. A third way, finally, is one that has shined 
through on various occasions of the book: a pattern that I call intermodular 
argumentation. Bundling the different intermodular arguments that have 
been made is, I think, a good conclusion of Part II. 
 
846  2. Intermodular argumentation 
 
847  2.1. Intermodular potential of interactionist derivation by phase 
 
848  2.1.1. Each end of the interactionist pipe may impact the other 
 
The idea of intermodular argumentation is to exploit the potential of 
the interactionist architecture that multiple spell-out and derivation by 
phase (Epstein et al. 1998:46ff, Uriagereka 1999, Chomsky 2000a et pas-
sim, see § 304) have introduced. The shipping back and forth of pieces be-
tween (morpho-)syntax and the PF/LF interfaces during the derivation of a 
sentence establishes a pipe between the concatenative and the interpreta-
tional devices that did not exist in GB or earlier versions of the inverted 
T-architecture. It creates a situation where syntactic theories and analyses 
may have direct consequences on the phonological side, and vice versa. 
Intermodular argumentation is interesting because it provides 
stronger evidence than what modular-internal reasoning can produce: it 
offers the maximal degree of independent assessment that linguists can 
expect without leaving their discipline (and arguments based on modularity 
go even beyond this limit). 
 

708 
Conclusion: Intermodular Argumentation 
849  2.1.2. Morpho-syntax can referee competing phonological analyses and 
theories 
 
The structure of intermodular arguments is always the same; it may concern 
a particular analysis of a specific data set as much as theoretical devices. 
Only the latter is further discussed below: given that the same shipping 
device (the spell-out mechanism) relates morpho-syntax and phonology (or 
PF, as well as LF), its properties must be the same on both sides. That is, a 
situation where some device is critical on one side, but unheard of on the 
other, cannot be a correct description of the interface. In practice, what will 
be done below is only argumentation in one direction: current syntactic 
theory is used as a referee for competing phonological theories. 
The application of intermodular argumentation to particular analyses 
was only briefly illustrated in § 320 on the occasion of the discussion of 
English nasal assimilation, to which the prefix-final nasal of un- is not sub-
jected (while in- does assimilate). The argument is that the phonological 
facts observed must be a consequence of the different derivational history 
of un- and in- if ± as is indeed the case ± these show distinct behaviour in 
morpho-syntax. That is, a phonology-internal solution that makes no pre-
diction as to what happened in the derivational history of morpho-syntax 
(as is proposed for example by Rubach & Booij 1984:11f and Vogel 1991), 
and which in fact can live with any morpho-syntactic analysis and its re-
verse, does not qualify. In this example, two competing phonological analy-
ses (one representational, the other procedural) are refereed by the exis-
tence of a morph-syntactic contrast between the pieces involved. 
 
850  2.1.3. Intermodular arguments can only be made through the procedural 
channel: translation is arbitrary 
 
It was also mentioned in § 320 that intermodular argumentation is a privi-
lege of the procedural channel: representational communication goes 
through translation, and the relation between the input and the output of 
translation is necessarily arbitrary (more on this in Vol.2). The conclusion 
that Newell & Scheer (2007) draw is that given competing and empirically 
equivalent representational and procedural analyses of the same phenome-
non, choose the latter since it may make falsifiable predictions on the other 
end of the interactionist pipe (procedural first). 
 

Intermodular argumentation 709 
851  2.2. Conditions and limitations of intermodular argumentation 
 
Another question that is addressed below (§ 858) are the conditions that 
must be met for intermodular argumentation to be conclusive. We will see 
that ± unfortunately ± much of the intermodular refereeing potential hinges 
on a question that is subject to ongoing debate: whether morphology is just 
the lower part of syntax, or whether it is a computational system in its own 
right (see § 539).  
Depending on this question is the number of spell-out mechanisms 
that exist in grammar which, as we will see, is critical for the comparison of 
phonological and syntactic effects of cyclic spell-out. If it turns out that 
morphology and syntax are two distinct computational systems, it could 
indeed be argued with some right that each system comes with its own 
spell-out mechanism. On the other hand, in case morphology and syntax 
are found to be emanations of one and the same computational system, 
there is of course no room for two distinct spell-out mechanisms. 
The reason why the number of spell-out mechanisms matters is the 
word-spell-out-mystery, which was discussed in § 786: what we actually do 
when we compare phonological and syntactic effects of cyclic spell-out is 
to compare the spell-out of morphemes with the spell-out of words. That is, 
a phonological footprint seems to be produced by the cyclic spell-out of 
morphemes, but never of words. In order to be able to draw conclusions 
from the comparison of phonological and syntactic effects of cyclic spell-
out, we must first make sure that it is the same spell-out that we are looking 
at. 
 
852  2.3. Six properties of spell-out that can be made intermodular arguments 
 
853  2.3.1. Convergence of syntactic and phonological tools 
 
On a number of occasions in Part I and Part II, we have come across pho-
nological devices that were found to be strikingly similar or identical to 
tools that are used in current syntactic theory. These parallels are significant 
because of their complete independence: they are made on entirely different 
sets of data, which have not even a remote resemblance in kind (phonology 
and syntax), and they are typically made by people who do not know that 
the same mechanism is used on the other side of the mirror. The devices at 
hand which converge, however, concern an object that is shared, in fact the 
pipe by which syntax and phonology are related: the spell-out mechanism. 

710 
Conclusion: Intermodular Argumentation 
This is too much convergence to suffer an interpretation where similarities 
are taken to be accidental. 
Table  (330) below lists relevant items and locates them in the previ-
ous discussion. 
 
(330) convergence between syntactic and phonological devices 
 
a. "freezing" no look-back: the PIC 
§§ 287, 783, 828 
 
b. selective spell-out 
§ 763 
 
c. the phase edge: spell out your sister! 
§ 766 
 
d. interactionism 
§ 672 
 
e. piece-driven phase (vs. node-driven phase) 
§§ 767, 781f 
 
f. spell-out of terminals (interpretation prior to merge) 
§ 316 
 
Interestingly, it seems that all devices mentioned have been invented 
in phonology. All of them (save piece-driven phase) are part and parcel of 
syntactic theory today, but the phonological legacy is hardly mentioned in 
the literature. 
 
854  2.3.2. Strong and weak version of the intermodular argument 
 
This convergence is remarkable as such and may certainly motivate at-
tempts to unify the devices at hand: why should phonology have its private 
mechanism if an alternative exists that uses the same technology as syntac-
tic theory? This reasoning follows Structural Analogy (Dependency Pho-
nology, see § 705), and it is the weak version of the intermodular argument 
that was made in § 830 where morpheme-specific mini-phonologies and the 
PIC were compared as competitors for the analysis of cyclic effects; the 
argument was in favour of the latter because the PIC is needed in syntax 
anyway.  
There is also a strong version of the intermodular argument (§ 830): 
the premises are the same, but this time it is considered that convergence is 
not just an enjoyable thing to have; rather, the interactionist interface archi-
tecture is inconsistent if the spell-out mechanism needs to have some prop-
erty on the syntactic side, which is either unheard of on the phonological 
side, or even incompatible with phonological theory (or the other way 
round). Therefore if we are sure that a spell-out-relevant device (such as the 
PIC) is critical and undisputed in syntax, it must also exist in phonology. 
 

Intermodular argumentation 711 
855  2.3.3. Import of phonology-based mechanisms into syntax 
 
In the opposite direction, there are two phonology-based mechanisms under 
 (330) that are candidates for introducing phonological evidence into the 
syntactic debate: piece-driven phase and the spell-out of terminals. Some 
voices in the syntactic literature follow similar ideas: Phase Extension 
(§ 781) and counter-cyclic merger (late adjunction, see § 316). These tracks, 
especially the possible interpretation of current syntactic node-driven phase 
in terms of phonological piece-driven phase (by means of a phasehood 
feature, § 782), seem to be worth exploring in further study. 
 
856  2.3.4. Four syntactic referees for phonological theories and the special 
status of interactionism 
 
Four out of the six convergent items under  (330) are prime candidates for 
intermodular argumentation where syntax referees competing phonological 
theories (the phonological origin of the devices notwithstanding). There is 
no doubt that the PIC, selective spell-out, the phase edge and interactionism 
are absolutely critical ingredients of current syntactic phase theory. Follow-
ing the strong version of the argument, they must therefore be active on the 
phonological side as well. 
The case of interactionism is peculiar insofar as being interactionist 
or not is not really discriminating phonological theories today (see § 676). 
The strong anti-interactionist reaction of Halle & Vergnaud (1987a) (§ 222)
against the introduction of the interactionist architecture by Lexical Pho-
nology was in defence of generative orthodoxy, which at the time was still 
based on the idea that all concatenation is done before all interpretation 
(§ 305).  
Today, however, generative orthodoxy has changed allegiance: cur-
rent syntactic theory is based on derivation by phase and hence has joined 
the interactionist party. Therefore, if interactionism was a strongly dis-
criminating front line in phonology in the 80s, it is not anymore today. Only 
orthodox versions of OT that extend the anti-derivationalist ambition to the 
entire grammatical architecture (instead of restricting it to phonological 
computation) will reject interactionism (§ 678). This resistance is intimately 
related to the misty relationship that OT has with modularity: interaction-
ism and the shipping of pieces can only exist when morpho-syntax and 
phonology are two distinct entities, something that OT is quite far from 
acknowledging or practising (see § 523). 

712 
Conclusion: Intermodular Argumentation 
Interactionism is thus ill-suited for discriminating competing phono-
logical theories, but certainly a knockdown argument that should make the 
anti-cyclicity fraction of OT reconsider their position, and OT as such its 
attitude regarding modularity. 
 
857  2.3.5. Phonology must provide for a "freezing" PIC, selective spell-out and 
the phase edge 
 
Let us now look at the three remaining syntactic referees for phonological 
theories. If selective spell-out, the PIC and the phase edge are necessary 
properties of phase theory, phonological theories of the effects of cyclic 
spell-out must also have them.188 
Recall from § 763 that selective spell-out divides phonological theo-
ries in two camps, one where all nodes are spelled out (Lexical Phonology), 
another where spell-out is selective (Halle & Vergnaud 1987a, Kaye 1995). 
The former can thus be dismissed on intermodular grounds, while the latter 
qualifies. The PIC further filters phonological theories: Lexical Phonology 
and Halle & Vergnaud (1987a) do not use any no look-back device (for the 
analysis of affix class-based phenomena189), while modification-inhibiting 
no look-back is the mechanism that accounts for cyclic effects in Kaye's 
system (see § 828). Syntactic theory thus selects Kaye (1995), which is the 
only theory to pass both filters. 
Finally, current phase theory requires that in case XP is a phase head, 
the spell-out of XP only triggers the interpretation of the complement; the 
head and its specifier ± the edge of the phase ± are spelled out only at the 
next higher phase (see § 766). This requirement may be run against the re-
cord from competing phonological theories of cyclicity-induced effects: 
Lexical Phonology spells out all nodes, Halle & Vergnaud (1987a) spell-
out only the node that dominates interpretation-triggering affixes, while 
Kaye (1995) sends only the sister of interpretation-triggering affixes to 
interpretation (see § 763). In an intermodular perspective, then, if the spell-
 
188 The intermodular argument regarding selective spell-out, the PIC and the phase 
edge are also made in three articles that are drawn from the book: Scheer 
(2008c, 2009b, 2010b). 
189 Of course, (classical versions of) Lexical Phonology feature(s) Kiparsky's 
(1982a,b) Strict Cycle Condition (SCC-K), which is a no look-back device. The 
SCC-K, however, is devised for derived environment effects ± it plays no role 
in affix class-based phenomena (§ 237).  

Intermodular argumentation 713 
out mechanism spells out the complement of phase heads ± their sister ±, 
the latter is selected, while the two former are dismissed. 
 
858  2.4. How many spell-out mechanisms are there in grammar? 
 
859  2.4.1. The parallel is always between the spell-out of morphemes and 
words 
 
The headstone of the argumentation made in the previous section ± which 
is tacitly assumed ± is that the syntactic and the phonological effects of 
cyclic spell-out that we are talking about are the two ends of the same pipe. 
That is, they are produced by the same spell-out mechanism. Were they 
not, there would be no reason for "phonological" spell-out to mimic the 
properties of "syntactic" spell-out: the latter could, say, spell out the sister 
of the phase head, while the former spells out something else; the latter 
could also be selective and implement the PIC, while the former could ig-
nore these devices. 
The existence of just one spell-out mechanism in the realm of the in-
verted T architecture is intuitive: a grammatical architecture that accom-
modates more than one parcel-shipping mechanism is not the first option 
that springs to one's mind. It is however an alternative that requires serious 
attention. 
Reconsider for example the phase edge in syntax. Saying that spell-
ing out the sister of interpretation-triggering affixes is the phonological 
version of the phase edge is imprecise: it is certainly the result of phono-
logical evidence, but it concerns morphology. That is, where Chomsky's 
mechanism spells out words and larger chunks, the phonological evidence 
is based on the spell-out of morphemes. And surprisingly enough (or not, 
depending on where one stands), this turns out to be the situation of all 
convergent devices: the phonological evidence for all items under  (330) is 
based on the spell-out of morphemes, never on the spell-out of words. 
What the parallel really is about, then, is syntax and morphology: 
relevant chunks in both areas, morphemes and words, seem to be spelled 
out by the same mechanism ± spell out your sister!  
 

714 
Conclusion: Intermodular Argumentation 
860  2.4.2. The weak version of the argument can be made, but the strong 
version hinges on the unity of morphology and syntax 
 
This result may be considered a contribution to the ongoing debate whether 
morphology and syntax are instances of the same computational system or 
not (see § 539). Leaving it at that is making the aforementioned weak ver-
sion of the intermodular argument: the convergence of syntactic and phono-
logical devices is probably not accidental and invites to think of a unified 
perspective. 
Whether or not the strong version of the intermodular argument can 
be made, however, hinges precisely on the debate whether morphology and 
syntax are one: if it turns out that morphology and syntax are two distinct 
computational systems, it could be argued with some reason that each sys-
tem comes with its own spell-out mechanism.190 
In this case, the strong intermodular argument cannot be made since 
the phonological evidence for, say, the phase edge concerns the spell-out of 
morphemes, whereas the syntactic evidence for the same device is based on 
the spell-out of words and larger pieces. If on the other hand it is found that 
morphology is just the lower part of syntactic structure, there can be only 
one spell-out mechanism, and the strong intermodular argument goes 
through. 
This objection to intermodular argumentation has already been made 
in § 769 regarding selective spell-out: from the perspective of Lexical Pho-
nology where morphology and syntax are two distinct computational sys-
tems, spell-out could well be selective in syntax, but not in morphology. 
 
861  2.4.3. The word-spell-out-mystery strikes again 
 
We have thus reached a point of indecision: the prima facie arguments only 
hold if we can be sure that there is only one single spell-out mechanism, 
and this depends on the debate whether morphology and syntax are one. 
In this situation, an obvious thing to do is to try to circumvent this 
"technical" difficulty by simply looking at phonological effects of the cy-
clic spell-out of words (rather than of morphemes). But alas, as we have 
seen there are none: this is what the word-spell-out mystery is about (see 
 
190 Note, however, that this is not a necessary conclusion: two distinct structures 
may as well be harvested by the same mechanism. 

Intermodular argumentation 715 
§786). All roads thus lead to the question whether morphology and syntax 
are one. 
 
862  2.5. Conclusion 
 
Intermodular argumentation comes in a strong and a weak version. The 
latter follows Structural Analogy (§ 705) and can always been made since it 
simply points out that there is no good reason to favour a mechanism when 
a competing solution is based on a device that is needed in syntax (or in 
phonology) anyway. 
The strong version of the argument is eliminative in the sense that it 
disqualifies theories on one end of the interactionist pipe in presence of an 
alternative that is compatible with (or selected by) a requirement that is 
established on the other end. 
In order for the strong version to go through, however, it needs to be 
made sure that the spell-out mechanism which sends word sequences to PF 
is really the same as the shipping mechanism which submits morpheme 
sequences to phonological computation. The null hypothesis is certainly 
that all shipping business in the inverted T architecture is done by the same 
mechanism. But if it turns out that morphological and syntactic structure 
are distinct computational systems, a scenario may (but does not have to) 
be construed where two different structures come each with its own spell-
out mechanism. This means in turn that there is no guarantee for the prop-
erties of these mechanisms to be the same, for example regarding the PIC 
(present/absent), selective spell-out (yes/no) and the spell-out of the head's 
sister (yes/spell out something else). 
Concluding on the question whether morphology and syntax are in-
stances of the same computational system is certainly appropriate for a 
book on the interface: it is one of the big questions in interface architecture; 
it will not be solved tomorrow, but it is a good thing to see that its prospect 
directly impacts another area, phonology. This intermodular conditioning is 
an effect of derivation by phase, which has opened new ways of evaluating 
interface theories as much as module-specific theories. 
 


863  References 
 
References followed by the mention WEB are available at 
www.unice.fr/dsl/tobias.htm. 
 
Abels, Klaus 
 
2003 
Successive cyclicity, anti-locality, and adposition stranding. Ph.D 
dissertation, University of Connecticut. 
Abry, Christian, Muriel Stefanuto, Anne Vilain, and Rafael Laboissière 
 
2002 
What Can the Utterance 'Tan, Tan' of Broca's Patient Leborgne 
Tell Us about the Hypothesis of an Emergent 'Babble-Syllable' 
Downloaded by SMA? In Phonetics, Phonology and Cognition,
Jacques Durand and Bernard Laks (eds.), 226-243. Oxford: Ox-
ford University Press. 
Ackema, Peter, and Ad Neeleman 
 
2004 
Beyond Morphology. Interface Conditions on Word Formation.
Oxford: Oxford University Press. 
Ackema, Peter, and Ad Neeleman 
 
2007 
Morphology ≠Syntax. In The Oxford Handbook of Linguistic 
Interfaces, Gillian Ramchand and Charles Reiss (eds.), 325-352. 
Oxford: OUP. 
Adger, David 
 
2007 
Stress and Phasal Syntax. Linguistic Analysis 33: 238-266. 
Aelbrecht, Lobke 
 
2008 
Licensing ellipsis as Agree. Paper presented at the 27th West 
Coast Conference on Formal Linguistics, UCLA 16-18 May. 
Alderete, John 
 
2001 
Root-controlled accent in Cupeño. Natural Language & Linguis-
tic Theory 19: 455-502. 
Alexiadou, Artemis, Elena Anagnostopoulou, Gianina Iordachioaia, and Mihaela 
Marchisi 
 
forth 
In support of Long Distance Agree. In Local modeling of non-
local dependencies, Artemis Alexiadou, Gereon Müller and T. 
Kiss (eds.). Tübingen: Niemeyer. 
Alexiadou, Artemis, Elena Anagnostopoulou, and Florian Schäfer 
 
2009 
PP licensing in nominalizations. Proceedings of NELS 38: 39-52. 
Alexiadou, Artemis, and Jane Grimshaw 
 
forth 
Verbs, nouns and affixation. 
Allen, Margaret 
 
1978 
Morphological Investigations. Ph.D dissertation, University of 
Connecticut. 

718 
References 
Allen, Margaret 
 
1980 
Semantic and Phonological Consequences of Boundaries: A Mor-
phological Analysis of Compounds. In Juncture, Mark Aronoff 
and Mary-Louise. Kean (eds.), 9-27. Saratoga: Anma Libri. 
Anderson, James 
 
1965 
The demarcative function. Lingua 13: 185-188. 
Anderson, John 
 
1985 
Structural analogy and Dependency Phonology. Acta Linguistica 
Hafniensia 19: 5-44. 
Anderson, John 
 
1986 
Structural analogy and case grammar. Lingua 70: 79-129. 
Anderson, John 
 
1987 
Structural Analogy and Dependency Phonology. In Explorations 
in Dependency Phonology, John Anderson and Jacques Durand 
(eds.), 15-48. Dordrecht: Foris. 
Anderson, John 
 
1992 
Linguistic representation. Structural analogy and stratification.
Berlin & New York: Mouton de Gruyter. 
Anderson, John, and Colin Ewen 
 
1987 
Principles of Dependency Phonology. Cambridge: Cambridge 
University Press. 
Anderson, John, and Charles Jones 
 
1974 
Three theses concerning phonological representations. Journal of 
Linguistics 10: 1-26. 
Anderson, Stephen 
 
1974 
On the typology of phonological rules. In Papers from the paras-
ession on Natural Phonology, A. Bruck, R. Fox and M. La Galy 
(eds.), 1-12. Chicago: Chicago Linguistic Society. 
Anderson, Stephen 
 
1981 
Why phonology Isn't "Natural". Linguistic Inquiry 12: 493-539. 
Anderson, Stephen 
 
1982 
Where's Morphology ? Linguistic Inquiry 13: 571-612. 
Anderson, Stephen 
 
1985 
Phonology in the Twentieth Century. Chicago: University of Chi-
cago Press. 
Anderson, Stephen 
 
1992 
A-Morphous Morphology. Cambridge: Cambridge University 
Press. 
Anttila, Arto 
 
2002 
Morphologically conditioned phonological alternations. Natural 
Language and Linguistic Theory 20: 1-42. 

References 719 
Anttila, Arto 
 
2009 
Derived environment effects in colloquial Helsinki Finnish. In 
The Nature of the Word: Studies in Honor of Paul Kiparsky, Kris-
tin Hanson and Sharon Inkelas (eds.), 433-460. Cambridge, MA.: 
MIT Press. 
Arad, M. 
 
2003 
Locality Constraints on the Interpretation of Roots: The Case of 
Hebrew Denominal Verbs. Natural Language & Linguistic The-
ory 21: 737-778. 
Archangeli, Diana 
 
1988 
Aspects of underspecification theory. Phonology 5: 183-208. 
Aronoff, Mark 
 
1976 
Word Formation in Generative Grammar. Cambridge, Mass.: 
MIT Press. 
Aronoff, Mark 
 
1980 
The Treatment of Juncture in American Linguistics. In Juncture,
Mark Aronoff and Mary-Louise Kean (eds.), 29-36. Saratoga: 
Anma Libri. 
Aronoff, Mark 
 
2003 
Juncture and Boundary. In International Encyclopedia of Linguis-
tics, William Frawley (ed.), 43. Oxford: OUP. 
Aronoff, Mark, and S. Sridhar 
 
1983 
Morphological levels in English and Kannada, or Atarizing 
Reagan. In Chicago Linguistics Society 19, Papers from the 
Parasession on the interplay of Phonology, Morphology and Syn-
tax, J. Richardson, M. Marks and A. Chukerman (eds.), 3-16. 
Chicago: Chicago Linguistics Society. 
Aronoff, Mark, and S. Sridhar 
 
1987 
Morphological levels in English and Kannada. In Rules and the 
Lexicon, Edmund Gussmann (ed.), 9-22. Lublin: Katolicki Uni-
versytet Lubelski. 
Balogné-Bérces, Katalin 
 
2004 
Connected speech phenomena in Strict CV phonology. The Even 
Yearbook 6: 1-10. 
Balogné-Bérces, Katalin 
 
2005 
Strict CV Phonology and the English Cross-Word Puzzle. Ph.D 
dissertation, Eötvös Loránd University, Budapest. 
Baltin, M. 
 
2007 
Deletion versus Pro-forms: a false dichotomy? Ms., New York 
University. 
Banich, M., and M. Mack (eds.) 
 
2003 
Mind, Brain and Language. Hillsdale: Erlbaum. 

720 
References 
Bao, Zhiming 
 
1996 
Local Tree Geometry and the Phonology-Syntax Interface. In 
Interfaces in Phonology, Ursula Kleinhenz (ed.), 27-45. Berlin: 
Akademie Verlag. 
Barkow, Jerome, Leda Cosmides, and John Tooby 
 
1992 
The Adapted Mind. Evolutionary Psychology and the Generation 
of Culture. Oxford: OUP. 
Barragan, L., and Heather Newell 
 
2003 
Cupeño morphology is(n't) inherently stressful. In Proceedings of 
the 32nd WECOL, B. Agbayani, V. Samiian and B.V. Tucker 
(eds.), 10-22. Fresno: Dept. of Linguistics, California State Uni-
versity. 
Basbøll, Hans 
 
1975 
Grammatical boundaries in phonology. Aripuc 9: 109-135. 
Basbøll, Hans 
 
1978a 
Schwa, jonctures et syllabification dans les représentations phono-
logiques du français. Acta Linguistica Hafniensia 16: 147-182. 
Basbøll, Hans 
 
1978b 
Boundaries and the ranking of rules in French phonology. In Etu-
des de phonologie française, Benoît de Cornulier and François 
Dell (eds.), 3-18. Marseille: Editions du CNRS. 
Basbøll, Hans 
 
1981 
On the function of boundaries in phonological rules. In Phonology 
in the 1980's, Didier Goyvaerts (ed.), 245-269. Ghent: Story-
Scientia. 
Basbøll, Hans 
 
1986 
Stød-sandhi. In Sandhi Phenomena in the Languages of Europe,
Henning Andersen (ed.), 75-83. Berlin: Mouton de Gruyter. 
Bastian, Charlton 
 
1880 
The brain as an organ of mind. London: Kegan Paul. 
Bates, Elizabeth 
 
1994 
Modularity, domain specificity and the development of language. 
Discussions in Neuroscience 10: 136-149. 
Beckman, Mary, and Janet Pierrehumbert 
 
1986 
Intonational Structure in Japanese and English. Phonology Year-
book 3: 15-70. 
Beckman, Mary, and Janet Pierrehumbert 
 
1988 
Japanese Tone Structure. Cambridge, MA: MIT Press. 
Bendjaballah, Sabrina 
 
2001 
The negative preterite in Kabyle Berber. Folia Linguistica 34: 
185-223. 

References 721 
Bendjaballah, Sabrina, and Martin Haiden 
 
2002 
The Strong Template in German. Paper presented at 4e Ren-
contres Internationales du GDR 1954 "Phonologies", Grenoble 6-
8 June. 
Bendjaballah, Sabrina, and Martin Haiden 
 
2003a 
Templatic Architecture. Recherches Linguistiques de Vincennes 
32: 157-168. 
Bendjaballah, Sabrina, and Martin Haiden 
 
2003b 
Meaningful vowels. In Proceedings of the XXVIII Incontro di 
Grammatica Generativa, Piero Bottari (ed.). Lecce: Congedo Edi-
tore. 
Bendjaballah, Sabrina, and Martin Haiden 
 
2003c 
Templatic Inflection in German. Penn Working Papers in Linguis-
tics 8: 29-41. 
Bendjaballah, Sabrina, and Martin Haiden 
 
2005 
Berber prepositions, templates and the PF interface. Paper pre-
sented at GLOW 28, Geneva 31 March - 2 April. 
Bendjaballah, Sabrina, and Martin Haiden 
 
2007 
A Typology of Emptiness in Templates. In Sounds of Silence: 
Empty Elements in Syntax and Phonology, Jutta Hartmann, Vera 
Hegedus and Henk van Riemsdijk (eds.), 21-57. Amsterdam: El-
sevier North Holland. 
Bendjaballah, Sabrina, and Martin Haiden 
 
forth 
Berber Prepositions: Phonology and Syntax of Templates. Ms, 
University of Lille. 
Benua, Laura 
 
1995 
Identity effects in morphological truncation. University of Massa-
chusetts Occasional Papers in Linguistics 18: 77-136. 
Benua, Laura 
 
1997 
Transderivational identity: phonological relations between words. 
Ph.D dissertation, University of Massachusetts at Amherst. 
Berman, A., and M. Szamosi 
 
1972 
Observations on sentential stress. Language 48: 304-325. 
Bermúdez-Otero, Ricardo 
 
1999 
Constraint interaction in language change: quantity in English and 
German. Ph.D dissertation, University of Manchester. 
Bermúdez-Otero, Ricardo 
 
2003 
The acquisition of phonological opacity. In Variation within Op-
timality Theory: Proceedings of the Stockholm Workshop on 
Variation within Optimality Theory, J. Spenader, J. Eriksson and 
A. Dahl (eds.), 25-36. Stockholm: Department of Linguistics, 
Stockholm University [longer version at ROA #593]. 

722 
References 
Bermúdez-Otero, Ricardo 
 
2006 
Phonological domains and opacity effects: a new look at voicing 
and continuancy in Catalan. In the Workshop on Approaches to 
phonological opacity at GLOW. Barcelona. 
Bermúdez-Otero, Ricardo 
 
2008 
Evidence for Chung's generalization. Paper presented at 16th 
Manchester Phonology Meeting, Manchester 22-24 May. 
Bermúdez-Otero, Ricardo 
 
forth a 
Stratal Optimality Theory. Oxford: Oxford University Press. 
Bermúdez-Otero, Ricardo 
 
forth b 
Cyclicity. In The Blackwell companion to phonology, Marc van 
Oostendorp, Colin Ewen, Elizabeth Hume and Keren Rice (eds.). 
Malden, MA: Wiley-Blackwell. 
Bermúdez-Otero, Ricardo, and April McMahon 
 
2006 
English Phonology and Morphology. In The Handbook of English 
linguistics, Bas Aarts and April McMahon (eds.), 382-410. Ox-
ford: Blackwell. 
Bertinetto, Pier Marco 
 
1999 
Boundary strength and linguistic ecology (Mostly exemplified on 
intervocalic /s/-voicing in Italian). Folia Linguistica 33: 267-286. 
Bethin, Christina 
 
1984 
Voicing assimilation in Polish. International Journal of Slavic 
Linguistics and Poetics 29: 17-32. 
Bickmore, Lee 
 
1990 
Branching nodes and prosodic categories. In The Phonology-
Syntax Connection, Sharon Inkelas and Draga Zec (eds.), 1-17. 
Chicago: University of Chicago Press. 
Blaho, Sylvia, Patrick Bye, and Martin Krämer (eds.) 
 
2007 
Freedom of analysis? Berlin: Mouton de Gruyter. 
Bloomfield, Leonard 
 
1939 
Menomini morphophonemics. Travaux du Cercle Linguistique de 
Prague 8: 105-115. 
Bobaljik, Jonathan 
 
2002 
A-Chains at the PF-Interface: Copies and µCovert¶ Movement. 
Natural Language & Linguistic Theory 20: 197-267. 
Bobaljik, Jonathan, and Susi Wurmbrand 
 
2005 
The domain of agreement. Natural Language & Linguistic Theory 
23: 809-865. 
Boeckx, Cedric 
 
2010 
Language in Cognition. Uncovering mental structures and the 
rules behind them. Oxford: Wiley-Blackwell. 
Boeckx, Cedric, and Kleanthes Grohmann 
 
2007 
Putting Phases in Perspective. Syntax 10: 204-222. 

References 723 
Boersma, Paul 
 
1998 
Functional phonology: formalizing the interactions between ar-
ticulatory and perceptual drives. The Hague: Holland Academic 
Graphics. 
Boersma, Paul 
 
2005 
Some listener-oriented accounts of hache aspire in French. Ms, 
University of Amsterdam, ROA #730. 
Bolinger, Dwight, and Louis Gerstman 
 
1957 
Disjuncture as a cue to constructs. Word 13: 246-255. 
Booij, Geert 
 
1977 
Dutch Morphology. Lisse: de Ridder. 
Booij, Geert 
 
1981 
Rule ordering, rule application and the organization of grammars. 
In Phonologica 1980, Wolfgang Dressler, Oskar Pfeiffer and John 
Rennison (eds.), 45-56. Innsbruck: Institut für Sprachwissen-
schaft. 
Booij, Geert 
 
1983 
Principles and parameters in Prosodic Phonology. Linguistics 21: 
249-280. 
Booij, Geert 
 
1985a 
The Interaction of Phonology and Morphology in Prosodic Pho-
nology. In Phono-morphology. Studies in the Interaction of Pho-
nology and Morphology, Edmund Gussmann (ed.), 23-34. Lublin: 
Katolicki Universytet Lubelski. 
Booij, Geert 
 
1985b 
Coordination reduction in complex words: a case for Prosodic 
Phonology. In Advances in nonlinear phonology, Harry van der 
Hulst and Norval Smith (eds.), 143-160. Dordrecht: Foris. 
Booij, Geert 
 
1986 
Two cases of external sandhi in French: enchaînement and liaison. 
In Sandhi Phenomena in the Languages of Europe, Henning An-
dersen (ed.), 93-103. Berlin: Mouton de Gruyter. 
Booij, Geert 
 
1987 
Lexical phonology and the organization of the morphological 
component. In Rules and the lexicon, Edmund Gussmann (ed.), 
43-65. Lublin: Katolicki Universytet Lubelski. 
Booij, Geert 
 
1988 
On the relation between lexical and prosodic phonology. In 
Certamen Phonologicum, Pier Marco Bertinetto and Michele 
Loporcaro (eds.), 63-75. Torino: Rosenberg & Sellier. 
Booij, Geert 
 
1992 
Lexical Phonology and Prosodic Phonology. In Phonologica 
1988, Wolfgang Dressler, Hans Luschützky, Oskar Pfeiffer and 
John Rennison (eds.), 49-62. Cambridge: CUP. 

724 
References 
Booij, Geert 
 
1995 
The Phonology of Dutch. Oxford: Clarendon Press. 
Booij, Geert 
 
1996 
Cliticization as prosodic integration: The case of Dutch. The 
Linguistic Review 13: 219-242. 
Booij, Geert 
 
1997 
Non-derivational phonology meets Lexical Phonology. In 
Derivations and Constraints in Phonology, Iggy Roca (ed.), 261-
288. Oxford: Oxford University Press. 
Booij, Geert 
 
2000 [1996] The phonology-morphology interface. In The First Glot 
International State-of-the-Article Book, Lisa Cheng and Rint 
Sybesma (eds.), 287-305. Berlin: Mouton de Gruyter. 
Booij, Geert, L. Ducceschi, Bernard Fradin, E. Guevara, Angela Ralli, and Sergio 
Scalise (eds.) 
 
2007 
Proceedings of the Fifth Mediterranean Morphology Meeting.
Bologna: Università degli Studi di Bologna. 
Booij, Geert, and Rochelle Lieber 
 
1993 
On the simultaneity of morphological and prosodic structure. In 
Studies in Lexical Phonology, Sharon Hargus and Ellen Kaisse 
(eds.), 23-44. San Diego: Academic Press. 
Borowsky, Toni 
 
1986 
Topics in the lexical phonology of English. Ph.D dissertation, 
University of Massachusetts, Amherst. 
Borowsky, Toni 
 
2000 
Word-faithfulness and the direction of assimilation. The 
Linguistic Review 17: 1-28. 
Boãković, äeljko 
 
2001 
On the nature of the syntax-phonology interface. Cliticization and 
related phenomena. Amsterdam: Elsevier. 
Boãković, äeljko 
 
2005a 
On null elements in syntax. Paper presented at Sounds of Silence, 
Tilburg 19-22 October. 
Boãković, äeljko 
 
2005b 
On the locality of left branch extraction & the structure of NP. 
Studia Linguistica 59: 1-45. 
Boãković, äeljko 
 
2007 
Agree, Phases, and Intervention Effects. Linguistic Analysis 33: 
54-96. 
Bresnan, Joan 
 
1971 
Sentence stress and syntactic transformations. Language 47: 257-
281. 

References 725 
Broca, Paul 
 
1861 
Remarques sur le siège de la faculté du langage articulé, suivies 
d'une observation d'aphémie (perte de la parole). Bulletin de la 
Société d'Anatomie de Paris 6: 330-357. 
Bromberger, Sylvain, and Morris Halle 
 
1989 
Why Phonology Is Different. Linguistic Inquiry 20: 51-70. 
Broselow, Ellen 
 
2003 
Marginal phonology: phonotactics at the edge. The Linguistic 
Review 20: 159-193. 
Brun-Trigaud, Guylaine, and Tobias Scheer 
 
2010 
Lenition in branching onsets in French and in ALF dialects. In 
Development of Language through the Lens of Formal 
Linguistics, Petr Karlík (ed.), 15-28. Munich: Lincom. 
Burzio, Luigi 
 
2000a 
Cycles, non-derived environment blocking and correspondence. 
In Optimality Theory: Phonology, Syntax, and Acquisition, Joost 
Dekkers, Frank van der Leeuw and Jeroen van de Weijer (eds.), 
47-87. Oxford: Oxford University Press. 
Burzio, Luigi 
 
2000b 
Segmental contrast meets output-to-output faithfulness. The 
Linguistic Review 17: 368-384. 
Burzio, Luigi 
 
2001 
Zero Derivations. Linguistic Inquiry 32: 658-677. 
Burzio, Luigi 
 
2007 
Phonetically conditioned syncretism. In Selected proceedings of 
the 
5th 
Décembrettes: 
Morphology 
in 
Toulouse,
Fabio 
Montermini, Gilles Boyé and Nabil Hathout (eds.), 1-19. 
Somerville, MA: Cascadilla. 
Bybee, Joan 
 
2001 
Phonology and Language Use. Cambridge: Cambridge University 
Press. 
Caha, Pavel 
 
2009 
The Nanosyntax of Case. Ph.D dissertation, Universtiy of 
Tromsø. 
Caha, Pavel, and Tobias Scheer 
 
2008 
The Syntax and Phonology of Czech Templatic Morphology. In 
Annual Workshop on Formal Approaches to Slavic Linguistics. 
The Stony Brook Meeting 2007, Andrei Antoneko, John Bailyn 
and Christina Bethin (eds.), 68-83. Ann Arbor: Michigan Slavic 
Publications. WEB. 

726 
References 
Cairns, Charles, and Charles Reiss 
 
2009 
Architecture and Representations in Phonology. In Contemporary 
Views on Architecture and Representations in Phonology, Eric 
Raimy and Charles Cairns (eds.), 1-16. Cambridge, Mass., Lon-
don: Bradford, MIT Press. 
Carvalho, Joaquim Brandão de 
 
2002 
De la syllabation en termes de contours CV. Habilitation Thesis, 
Ecole des Hautes Etudes en Sciences Sociales, Paris. WEB. 
Carvalho, Joaquim Brandão de 
 
2006 
Markedness gradient in the Portuguese verb: how morphology 
and phonology interact. In Prosody and Syntax, Ivan Fónagy, Yuji 
Kawaguchi 
and 
Tsunekazu 
Moriguchi 
(eds.), 
157-174. 
Amsterdam: Benjamins. 
Cattell, Ray 
 
2006 
An Introduction to Mind, Consciousness and Language. London: 
Continuum. 
Charette, Monik 
 
1989 
The Minimality Condition in Phonology. Journal of Linguistics 
25: 159-189. 
Charette, Monik, and Asli Göksel 
 
1994 
Vowel Harmony and Switching in Turkic languages. SOAS 
Working Papers in Linguistics and Phonetics. 4: 31-52. Also in 
Kardela, Henryk, Bogdan Szymanek (eds.), A Festschrift for 
Edmund Gussmann, 29-56. Lublin 1996: University Press of the 
Catholic University of Lublin. WEB. 
Charette, Monik, and Asli Göksel 
 
1996 
Licensing constraints and vowel harmony in Turkic languages. 
SOAS Working Papers in Linguistics and Phonetics 6: 1-25. Also 
in Cyran, Eugeniusz (ed), Structure and Interpretation. Studies in 
Phonology, 65-88. Lublin 1998: Folium. WEB. 
Chen, Matthew 
 
1985 
The syntax of phonology: Xiamen tone sandhi. Ms., University of 
California at San Diego. 
Chen, Matthew 
 
1990 
What must phonology know about syntax? In The Phonology-
Syntax Connection, Sharon Inkelas and Draga Zec (eds.), 19-46. 
Chicago: University of Chicago Press. 
Cheng, Lisa, and Laura Downing 
 
2007 
The prosody and syntax of Zulu relative clauses. SOAS Working 
Papers in Linguistics and Phonetics 15: 51-63. 
Chien, Yu-Chin, and Kenneth Wexler 
 
1990 
Children's Knowledge of Locality Conditions in Binding as 
Evidence for the Modularity of Syntax and Pragmatics. Language 
Acquisition 1: 225-295. 

References 727 
Cho, Young-Mee Yu 
 
1990 
Syntax and Phrasing in Korean. In The Phonology-Syntax 
Connection,
Sharon Inkelas and Draga Zec (eds.), 47-62. 
Chicago: University of Chicago Press. 
Cho, Young-Mee Yu 
 
2009 
A historical perspective on nonderived environment blocking: the 
case of Korean palatalization. In The Nature of the Word: Studies 
in Honor of Paul Kiparsky, Kristin Hanson and Sharon Inkelas 
(eds.), 461-486. Cambridge, MA.: MIT Press. 
Chomsky, Noam 
 
1955-56 
The Logical Structure of Linguistic Theory. New York: Published 
1975, Plenum. 
Chomsky, Noam 
 
1959 
Review of Skinner's Verbal Behavior. Language 35: 26-58. 
Chomsky, Noam 
 
1965 
Aspects of the Theory of Syntax. Cambridge, Mass.: MIT Press. 
Chomsky, Noam 
 
1965 [2006] The formal Nature of Language. In Language and Mind, Noam 
Chomsky (ed.), 102-142. Cambridge: CUP. 
Chomsky, Noam 
 
1970 
Remarks 
on 
nominalisation. 
In 
Readings 
in 
English 
Transformational Grammar, R. Jacobs and P. Rosenbaum (eds.), 
184-221. Walthamm, Mass.: Ginn. 
Chomsky, Noam 
 
1972 
Language and Mind. New York: Jovanovich. 
Chomsky, Noam 
 
1973 
Conditions on Transformations. In A Festschrift for Morris Halle,
Stephen Anderson and Paul Kiparsky (eds.), 232-286. New York: 
Holt, Rinehart & Winston. 
Chomsky, Noam 
 
1975 
Reflections on Language. New York: Pantheon. 
Chomsky, Noam 
 
1980 
Rules and Representations. New York: Columbia University 
Press. 
Chomsky, Noam 
 
1981 
Lectures on Government and Binding.
7th edition 1993, 
Dordrecht: Foris. 
Chomsky, Noam 
 
1982 
Some concepts and consequences of the theory of Government 
and Binding. Cambridge, Mass.: MIT Press. 
Chomsky, Noam 
 
1984 
Modular Approaches to the Study of Mind. San Diego: San Diego 
University Press. 

728 
References 
Chomsky, Noam 
 
1986 
Barriers. Cambridge, Mass.: MIT Press. 
Chomsky, Noam 
 
1988 
Problems of Knowledge. Cambridge, Mass.: MIT Press. 
Chomsky, Noam 
 
1993a 
A minimalist program for linguistic theory. In The view from 
Building 20. Essays in Linguistics in Honor of Sylvain 
Bromberger, Kenneth Hale and Samuel Keyser (eds.), 1-52. 
Cambridge, Mass.: MIT Press. 
Chomsky, Noam 
 
1993b 
On the Nature, Use, and Acquisition of Language. In Readings in 
Philosophy and Cognitive Science, Alvin Goldman (ed.), 511-534. 
Cambridge, Mass.: MIT Press. 
Chomsky, Noam 
 
1995a 
The Minimalist Program. Cambridge, MA: MIT Press. 
Chomsky, Noam 
 
1995b 
Language and Nature. Mind 104: 1-61. 
Chomsky, Noam 
 
2000a 
Minimalist inquiries: the framework. In Step by Step. Essays on 
Minimalist Syntax in Honor of Howard Lasnik, Roger Martin, 
David Michaels and Juan Uriagereka (eds.), 89-155. Cambridge, 
Mass.: MIT Press. 
Chomsky, Noam 
 
2000b 
New Horizons in the Study of Language and Mind. Cambridge: 
Cambridge University Press. 
Chomsky, Noam 
 
2001 
Derivation by Phase. In Ken Hale: A Life in Language, Michael 
Kenstowicz (ed.), 1-52. Cambridge, Mass.: MIT Press. 
Chomsky, Noam 
 
2002 
On Nature and Language. Cambridge: Cambridge University 
Press. 
Chomsky, Noam 
 
2004 
Beyond explanatory adequacy. In Structures and Beyond. The 
cartography of syntactic structures, Volume 3, Adriana Belletti 
(ed.), 104-131. Oxford: Oxford University Press. 
Chomsky, Noam 
 
2005 
Three factors in language design. Linguistic Inquiry 36: 1-22. 
Chomsky, Noam 
 
2008 
On Phases. In Foundational Issues in Linguistic Theory, Robert 
Freidin, Carlos Otero and Maria-Luisa Zubizaretta (eds.), 133-
166. Cambridge, MA.: MIT Press. 
Chomsky, Noam, and Morris Halle 
 
1968 
The Sound Pattern of English. Cambridge, Mass.: MIT Press. 

References 729 
Chomsky, Noam, Morris Halle, and Fred Lukoff 
 
1956 
On Accent and Juncture in English. In For Roman Jakobson. 
Essays on the occasion of his sixtieth birthday, Morris Halle, 
Horace Lunt, Hugh McLean and Cornelis van Schooneveld (eds.), 
65-80. The Hague: Mouton. 
Chomsky, Noam, and George Miller 
 
1963 
Introduction to the formal analysis of natural languages. In 
Handbook of Mathematical Psychology, Vol.2, P. Luce, R. Bush 
and E. Galanter (eds.), 269-322. New York: Wiley. 
Chung, Sandra 
 
1983 
Transderivational constraints in Chamorro phonology. Language 
59: 35-66. 
Churchland, Patricia 
 
1993 
Can Neurobiology teach us anything about consciousness? 
Proceedings and Addresses of the American Philosophical 
Association 67.3: 23-40. 
Cinque, Guglielmo 
 
1993 
A null theory of phrasal and compound stress. Linguistic Inquiry 
24: 239-297. 
Circle, Prague Linguistic 
 
1931 
Projet de terminologie phonologique standardisée. Travaux du 
Cercle Linguistique de Prague 4: 309-323. 
Clapin, Hugh 
 
2002 
Content and Cognitive Science. Language & Communication 22: 
231-242. 
Clayton, Mary 
 
1981 
Word boundaries and sandhi rules in natural generative 
phonology. Language 57: 571-590. 
Clements, George N. 
 
1978 
Tone and syntax in Ewe. In Elements of stress, tone and 
intonation, Donna Jo Napoli (ed.), 21-99. Washington, D.C.: 
Georgetown University Press. 
Clements, George N. 
 
1990 
The role of the sonority cycle in core syllabification. In Papers in 
Laboratory Phonology I, John Kingston and Mary Beckmann 
(eds.), 283-333. Cambridge: Cambridge University Press. 
Cobb, Margaret 
 
1996 
Clitics in Basque: a phonological approach. SOAS Working 
Papers in Linguistics and Phonetics 6: 26-39. 
Cobb, Margaret 
 
1997 
Conditions on Nuclear Expressions in Phonology. Ph.D 
dissertation, SOAS, London. 

730 
References 
Cole, Jennifer 
 
1995 
The Cylcle in Phonology. In The Handbook of Phonological The-
ory, John Goldsmith (ed.), 70-113. Oxford: Blackwell. 
Cole, Jennifer, and John Coleman 
 
1992 
No need for cyclicity within generative grammar. In CLS 28: 
Parasession of the Cycle in Linguistic Theory, J. Denton, G. Chan 
and C. Canakis (eds.), 36-50. Chicago: Chicago Linguistics 
Society. 
Coleman, John 
 
1995 
Declarative lexical phonology. In Frontiers in Phonology. Atoms, 
Structures, Derivations, Jacques Durand and Francis Katamba 
(eds.), 333-382. London & New York: Longman. 
Coleman, John 
 
2005 
Phonological Representations. Cambridge: Cambridge University 
Press. 
Condoravdi, Cleo 
 
1990 
Sandhi rules of Greek and Prosodic Phonology. In The 
Phonology-Syntax Connection, Sharon Inkelas and Draga Zec 
(eds.), 63-84. Chicago: University of Chicago Press. 
Cosmides, Leda, and John Tooby 
 
1992a 
Cognitive adaptations for social exchange. In The adapted mind. 
Evolutionary psychology and the generation of culture, J. 
Barkow, Leda Cosmides and John Tooby (eds.), 163-228. Oxford: 
OUP. 
Cosmides, Leda, and John Tooby 
 
1992b 
The Psychological Foundations of Culture. In The adapted mind. 
Evolutionary psychology and the generation of culture, J. 
Barkow, Leda Cosmides and John Tooby (eds.), 19-136. Oxford: 
OUP. 
Cosmides, Leda, and John Tooby 
 
1994 
Origins of domain specificity: the evolution of functional 
organization. In Mapping the Mind, L.A. Hirschfeld and S.A. 
Gelman (eds.), 85-116. Cambridge: CUP. 
Cowper, Elizabeth, and Keren Rice 
 
1987 
Are phonosyntactic rules necessary? Phonology 4: 185-194. 
Culicover, P., and Kenneth Wexler 
 
1973 
Three further applications of the freezing principle in English. 
Social Sciences Working Papers of the University of California at 
Irvine 48. 
Curtiss, S. 
 
1981 
Dissociations between language and cognition: cases and 
implications. Journal of Autism and Developmental Disorders 11: 
15-30. 

References 731 
Cutler, Anne 
 
1996 
Prosody and the Word Boundary Problem. In Signal to Syntax: 
Bootstrapping from Speech to Grammar in Early Acquisition,
James Morgan and Katherine Demuth (eds.), 87-99. Mahwah, NJ: 
Erlbaum. 
Cyran, Eugeniusz, and Edmund Gussmann 
 
1998 
Polish consonantal sequences: a phonological testing ground. In 
Structure and Interpretation, Eugeniusz Cyran (ed.), 127-138. 
Lublin: Pase. WEB. 
Cyran, Eugeniusz, and Edmund Gussmann 
 
1999 
Consonant clusters and governing relations: Polish initial 
consonant sequences. In The syllable, Views and Facts, Harry van 
der Hulst and Nancy Ritter (eds.), 219-248. Berlin, New York: de 
Gruyter. 
De Schutter, G., and J. Taeldeman 
 
1986 
Assimilatie van Stem in de Zuidelijke Nederlandse Dialekten. In 
Vruchten van z¶n akker: opstellen van (oud-) medewerkers en 
oud-studenten voor Prof. V.F. Vanacker, M. Devos and J. 
Taeldeman (eds.), 91-133. Ghent: Seminarie voor Nederlandse 
Taalkunde. 
Dehaene, Stanislas 
 
1997 
The Number Sense. How the Mind Creates Mathematics. Oxford: 
Oxford University Press. 
Dehaene, Stanislas, Ghislaine Dehaene-Lambertz, and Laurent Cohen 
 
2001 
On Language, Biology and Reductionism. In Language, Brain 
and Cognitive Development. Essays in Honor of Jacques Mehler,
Emmanuel Dupoux (ed.), 397-401. Cambridge, Mass.: MIT Press. 
Dell, François 
 
1976 
Schwa précédé d'un groupe obstruante-liquide. Recherches 
Linguistiques de Vincennes 4: 75-111. 
Dell, François 
 
1986 
L'accentuation dans les phrases en français. In Les représentations 
en phonologie, François Dell, Daniel Hirst and Jean-Roger 
Vergnaud (eds.), 65-122. Paris: Hermann. 
Démonet, Jean-François, Guillaume Thierry, and Jean-Luc Nespoulos 
 
2002 
Towards Imaging the neural Correlates of Language Functions. In 
Phonetics, Phonology and Cognition, Jacques Durand and 
Bernard Laks (eds.), 244-253. Oxford: Oxford University Press. 
den Dikken, Marcel 
 
2007 
Phase Extension: Contours of a theory of the role of head 
movement in phrasal extraction. Theoretical Linguistics 33: 1-41. 

732 
References 
Devine, Andrew, and Laurence Stephens 
 
1976 
The Function and Status of Boundaries in Phonology. In Linguis-
tic Studies offered to Joseph Greenberg on the occasion of his six-
tieth birthday, Alphonse Juilland (ed.), 285-312. Saratoga, Cal.: 
Anma Libri. 
Devine, Andrew, and Laurence Stephens 
 
1980 
On the Phonological Definition of Boundaries. In Juncture, Mark 
Aronoff and Mary-Louise Kean (eds.), 57-78. Saratoga: Anma 
Libri. 
Devitt, Michael, and Kim Sterelny 
 
1989 
Linguistics: what's wrong with the 'right view'. In Philosophical 
Perspectives, Vol.3, J. Tomberlin (ed.), 497-531. Atascadero: 
Ridgeview. 
Dinsmore, John (ed.) 
 
1992 
The symbolic and connectionist paradigms: closing the gap.
Hillsdale: Erlbaum. 
Dobashi, Yoshihito 
 
2003 
Phonological Phrasing and syntactic derivation. Ph.D thesis, 
Cornell University. 
Donegan, Patricia 
 
1978 
The natural phonology of vowels. Ph.D dissertation, Ohio State 
University. Published by Garland Press, New York 1985. 
Donegan, Patricia, and David Stampe 
 
1978 
The Syllable in Phonological and Prosodic Structure. In Syllables 
and Segments, Alan Bell and Joan Bybee Hooper (eds.), 25-43. 
Amsterdam: North Holland. 
Donegan, Patricia, and David Stampe 
 
1979 
The study of natural phonology. In Current approaches to 
phonological 
theory,
Daniel 
Dinnsen 
(ed.), 
126-173. 
Bloomington: Indiana University Press. 
Downing, Laura 
 
2006 
Canonical Forms in Prosodic Morphology. Oxford: Oxford 
University Press. 
Dresher, Elan 
 
1994 
The prosodic basis of the Tiberian Hebrew system of accents. 
Language 70: 1-52. 
Dresher, Elan 
 
1996 
Introduction to Metrical and Prosodic Phonology. In Signal to 
Syntax: Bootstrapping from Speech to Grammar in Early 
Acquisition, James Morgan and Katherine Demuth (eds.), 41-54. 
Mahwah, NJ: Erlbaum. 

References 733 
Dressler, Wolfgang 
 
1974 
Diachronic Puzzles for Natural Phonology. In Papers from the 
parasession on Natural Phonology, A.Bruck, R.Fox and M.La 
Galy (eds.), 95-102. Chicago: Chicago Linguistic Society. 
Dressler, Wolfgang 
 
1984 
Explaining Natural Phonology. Phonology Yearbook 1: 29-51. 
Dupoux, Emmanuel (ed.) 
 
2001 
Language, Brain and Cognitive Development. Essays in Honor of 
Jacques Mehler. Cambridge, Mass.: MIT Press. 
Durand, Jacques 
 
1995 
Universalism in phonology: atoms, structures and derivations. In 
Frontiers in Phonology. Atoms, Structures, Derivations, Jacques 
Durand and Francis Katamba (eds.), 267-288. London & New 
York: Longman. 
Durand, Jacques 
 
2006 
La phonologie générative jusqu'en 1975. In History of the 
Language Sciences, vol.3 (HSK 18.3), Sylvain Auroux, E.F.K. 
Koerner, Hans-Josef Niederehe and Kees Versteegh (eds.), 2265-
2270. Berlin: de Gruyter. 
Durand, Jacques, and Bernard Laks (eds.) 
 
2002 
Phonetics, Phonology and Cognition. Oxford: Oxford University 
Press. 
Dziubalska-Kołaczyk, Katarzyna 
 
2001a 
Phonotactic constraints are preferences. In Constraints and 
Preferences,
Katarzyna Dziubalska-Kołaczyk (ed.), 69-100. 
Berlin, New York: Mouton de Gruyter. 
Dziubalska-Kołaczyk, Katarzyna 
 
2001b 
On the phonotactics of consonantal clusters. In Naturally! 
Linguistic studies in honour of Wolfgang Ulrich Dressler 
presented on the occasion of his 60th birthday, M. Schaner-
Wolles, John Rennison and Friedrich Neubarth (eds.), 111-119. 
Torino: Rosenberg & Sellier. 
Dziubalska-Kołaczyk, Katarzyna 
 
2002 
Beats-and-binding phonology. Frankfurt am Main: Lang. 
Elman, Jeffrey 
 
1994 
Learning and development in neural networks: the importance of 
starting small. Cognition 48: 71-99. 
Elordieta, Gorka 
 
1997 
Morphosyntactic Feature Chains and Phonological Domains. 
Ph.D dissertation, University of Southern California. 
Elordieta, Gorka 
 
2007 
Segmental Phonology and Syntactic Structure. In The Oxford 
Handbook of Linguistic Interfaces, Gillian Ramchand and Charles 
Reiss (eds.), 125-177. Oxford: OUP. 

734 
References 
Elordieta, Gorka 
 
2008 
An overview of theories of the syntax-phonology interface. 
Journal of Basque Linguistics and Philology 42: 209-286. 
Embick, David 
 
2003 
Locality, Listedness, and Morphological Information. Studia 
Linguistica 57: 143-169. 
Embick, David 
 
2007 
Linearization and local dislocation: derivational mechanics and 
interactions. Linguistic Analysis 33: 303-336. 
Embick, David 
 
forth 
Localism versus Globalism in Morphology and Phonology. Ms., 
University of Pennsylvania. 
Embick, David, and Alec Marantz 
 
2008 
Architecture and Blocking. Linguistic Inquiry 39: 1-53. 
Embick, David, and Rolf Noyer 
 
2001 
Movement Operations after Syntax. Linguistic Inquiry 32: 555-
595. 
Embick, David, and Rolf Noyer 
 
2007 
Distributed Morphology and the Syntax - Morphology Interface. 
In The Oxford Handbook of Linguistic Interfaces, Gillian 
Ramchand and Charles Reiss (eds.), 289-324. Oxford: OUP. 
Embick, David, and David Poeppel 
 
2005 
Mapping syntax using imaging: prospects and problems for the 
study of neurolinguistic computation. In Encyclopedia of 
language and linguistics (2nd edition), Keith Brown (ed.). 
Oxford: Elsevier. 
Encrevé, Pierre 
 
1988 
La 
liaison 
avec 
et 
sans 
enchaînement: 
phonologie 
tridimensionnelle et usages du français. Paris: Seuil. 
Encrevé, Pierre 
 
2000 
The Old and the New: Some Remarks on Phonology and its 
History. Folia Linguistica 34: 57-85. This article is a translation 
of Encrevé, Pierre 1997. L'ancien et le nouveau. Quelques 
remarques sur la phonologie et son histoire. Langages 125: 100-
123. 
Epstein, Samuel 
 
1999 
Un-principled syntax: the derivation of syntactic relations. In 
Working Minimalism, Samuel Epstein and Norbert Hornstein 
(eds.), 317-345. Cambridge, Mass.: MIT Press. 
Epstein, Samuel 
 
2006 
On I(nternalist)-Functional Explanation in Minimalism. Linguistic 
Analysis 33: 20-53. 
Epstein, Samuel, E.M. Groat, R. Kawashima, and H. Kitahara 
 
1998 
A Derivational Approach to Syntactic Relations. Oxford: OUP. 

References 735 
Epstein, Samuel, and T. Daniel Seely 
 
2002 
Rule Applications as Cycles in Level-Free Syntax. In Derivation 
and Explanation in the Minimalist Program, Samuel Epstein and 
T.Daniel Seely (eds.), 65-89. Oxford: Blackwell. 
Epstein, Samuel, and T. Daniel Seely 
 
2006 
Derivation in Minimalism. Cambridge: CUP. 
Fabb, Nigel 
 
1988 
English suffixation is constrained only be selectional restrictions. 
Natural Language and Linguistic Theory 6: 527-539. 
Farmer, Ann 
 
1984 
Modularity in Syntax: A Study of Japanese and English.
Cambridge, Mass.: MIT Press. 
Feldman, J. A. 
 
1985 
Connectionist models and their applications: introduction. 
Cognitive Science 9: 1-2. 
Felser, Claudia 
 
2004 
Wh-copying, phases, and successive cyclicity. Lingua 114: 543-
574. 
Féry, Caroline, and Shinichiro Ishihara 
 
2009 
How Focus and Givenness Shapes Prosody. In Information 
Structure from Different Perspectives, Malte Zimmermann and 
Caroline Féry (eds.), 36-63. Oxford: OUP. 
Fitch, Tecumseh, Marc Hauser, and Noam Chomsky 
 
2005 
The evolution of the language faculty: Clarifications and 
implications. Cognition 97: 179-210. 
Fitzpatrick-Cole, Jennifer 
 
1996 
Reduplication meets the phonological phrase in Bengali. The 
Linguistic Review 13: 305-356. 
Fodor, Jerry 
 
1975 
The Language of Thought. New York: Crowell. 
Fodor, Jerry 
 
1981 
Some notes on what linguistics is about. In Readings in the 
Philosophy of Psychology, Ned Block (ed.), 197-207. Cambridge, 
Mass.: Harvard University Press. 
Fodor, Jerry 
 
1983 
The modularity of the mind. Cambridge, Mass.: MIT-Bradford. 
Fodor, Jerry 
 
1985 
Fodor's Guide to Mental Representation: The Intelligent Auntie's 
Vade-Mecum. Mind 94: 55-97. 
Fodor, Jerry 
 
1987 
Modules, Frames, Fridgeons, Sleeping Dogs, and the Music of the 
Spheres. In Modularity in knowledge representation and natural 
language understanding, Jay Garfield (ed.), 25-36. Cambridge, 
Mass.: MIT Press. 

736 
References 
Fodor, Jerry 
 
1998 
The Trouble with Psychological Darwinism. London Review of 
Books 20.2: 11-13. 
Fodor, Jerry 
 
2000 
The mind doesn't work that way: The scope and limits of 
computational psychology. Cambridge, Mass.: MIT Press. 
Fodor, Jerry, and B. McLaughlin 
 
1990 
Connectionism 
and 
the 
problem 
of 
systematicity: 
why 
Smolensky's solution doesn't work. Cognition 35: 182-204. 
Fodor, Jerry, and Zenon Pylyshyn 
 
1988 
Connectionism and Cognitive Architecture: A Critical Analysis. 
Cognition 28: 3-71. 
Fox, Danny, and Howard Lasnik 
 
2003 
Successive-Cyclic Movement and Island Repair: The Difference 
between Sluicing and VP-Ellipsis. Linguistic Inquiry 34: 143-154. 
Fox, Danny, and David Pesetsky 
 
2004 
Cyclic linearization of syntactic structure. Theoretical Linguistics 
31: 1-45. 
Franks, Steven, and äeljko Boãković
2001 
An argument for multiple spell-out. Linguistic Inquiry 32: 174-
183. 
Frascarelli, Mara 
 
2006 
Phases and Interpretation. In Phases of Interpretation, Mara 
Frascarelli (ed.), 1-14. Berlin: Mouton de Gruyter. 
Freidin, Robert, and Howard Lasnik 
 
forth 
Some roots of minimalism in generative grammar. In The Oxford 
Handbook of Linguistic Minimalism,
Cedric Boeckx (ed.). 
Oxford: OUP. 
Gallego, Angel J. 
 
2007 
Phase Theory and Parametric Variation. Ph.D dissertation, 
Universitat Autònoma de Barcelona. 
Gallego, Angel J. 
 
2010 
Phase Theory. Amsterdam: Benjamins. 
Gardner, Howard 
 
1985 
The Mind's New Science: A History of the Cognitive Revolution.
New York: Basic Books. 
Garfield, Jay (ed.) 
 
1987 
Modularity in Knowledge Representation and Natural Language 
Understanding. Cambridge, Mass.: MIT Press. 
Gengel, Kirsten 
 
2009 
Phases and Ellipsis. Linguistic Analysis 35: 21-42. 
Gerrans, Philip 
 
2002 
Modularity reconsidered. Language and Communication 22: 259-
268. 

References 737 
Ghini, Mirco 
 
1993 
Phonological Phrase formation in Italian: a new proposal. Toronto 
Working Papers in Linguistics 12: 41-77. 
Giegerich, Heinz 
 
1999 
Lexical Strata in English. Cambridge: Cambridge University 
Press. 
Göbbel, Edward 
 
2007 
Extraposition as PF Movement. To appear in Proceedings of 
WECOL 2006. 
Goldsmith, John 
 
1990 
Autsegmental and Metrical Phonology. Oxford: Blackwell. 
Goldsmith, John 
 
1992 
Local modelling in phonology. In Connectionism: Theory and 
practice, Steven Davis (ed.), 229-246. Oxford: OUP. 
Goldsmith, John 
 
1993 
Harmonic Phonology. In The last phonological rule, John 
Goldsmith (ed.), 21-60. Chicago: University of Chicago Press. 
Goldsmith, John 
 
2008 
Generative Phonology in the late 40s. Phonology 25: 37-59. 
Golston, Chris 
 
1996 
Prosodic constraints on roots, stems and words. In Interfaces in 
Phonology, Ursula Kleinhenz (ed.), 172-193. Berlin: Akademie 
Verlag. 
Green, Anthony 
 
2007 
Phonology Limited. Ms., University of Surrey Roehampton. 
[ROA#605]. 
Greenberg, Joseph 
 
1970 
On the 'language of observation' in linguistics. Working Papers on 
Language Universals (Stanford University) 4: 1-15. 
Grohmann, Kleanthes 
 
2003 
Prolific domains: On the anti-locality of movement dependencies.
Amsterdam: Benjamins. 
Grohmann, Kleanthes 
 
2007a 
Deriving Dynamic Interfaces. Linguistic Analysis 33: 3-19. 
Grohmann, Kleanthes 
 
2007b 
Spelling out Dynamic Interfaces. Linguistic Analysis 33: 197-208. 
Guasti, Theresa, and Marina Nespor 
 
1999 
Is syntax Phonology-free? In Phrasal Phonology, René Kager and 
Wim Zonneveld (eds.), 73-97. Nijmegen: Nijmegen University 
Press. 
Guerssel, Mohand, and Jean Lowenstamm 
 
1990 
The derivational morphology of the Classical Arabic Verb. Ms., 
UQAM and University Paris 7. 

738 
References 
Gussenhoven, Carlos 
 
1992 
Intonational phrasing and the prosodic hierarchy. In Phonologica 
1988, Wolfgang Dressler, Hans Luschützky, Oskar Pfeiffer and 
John Rennison (eds.), 89-99. Cambridge: Cambridge University 
Press. 
Gussenhoven, Carlos 
 
2004 
The phonology of tone and intonation. Cambridge: Cambridge 
University Press. 
Gussmann, Edmund 
 
1998 
Domains, relations, and the English agma. In Structure and 
Interpretation. Studies in Phonology, Eugeniusz Cyran (ed.), 101-
126. Lublin: Folium. WEB. 
Gussmann, Edmund 
 
2002 
Phonology: Analysis and Theory.
Cambridge: Cambridge 
University Press. 
Gussmann, Edmund 
 
2007 
The Phonology of Polish. Oxford: Oxford University Press. 
Gussmann, Edmund, and Jonathan Kaye 
 
1993 
Polish notes from a Dubrovnik Café: I. The yers. SOAS Working 
Papers in Linguistics and Phonetics 3: 427-462. 
Gvozdanović, Jadranka 
 
1986 
Phonological domains. In Sandhi Phenomena in the Languages of 
Europe, Henning Andersen (ed.), 27-54. Berlin: Mouton de 
Gruyter. 
Haiden, Martin 
 
2005 
Concatenation and interpretation. In Organizing Grammar. 
Studies in Honor of Henk van Riemsdijk, Hans Broekhuis, Norbert 
Corver, Riny Huybregts, Ursula Kleinhenz and Jan Koster (eds.), 
162-170. Berlin: Mouton de Gruyter. 
Hale, Kenneth, and Elisabeth Selkirk 
 
1987 
Government and tonal phrasing in Papago. Phonology 4: 151-183. 
Hale, Mark, and Charles Reiss 
 
2008 
The Phonological Enterprise. Oxford: OUP. 
Hall, R. A. Jr. 
 
1946 
Colloquial French Phonology. Studies in Linguistics 4: 70-90. 
Hall, R. A. Jr. 
 
1948 
Schismeme, open juncture, disjuncture. Studies in Linguistics 6: 
21. 
Hall, Tracy 
 
1992 
Syllable Structure and Syllable-Related Processes in German.
Tübingen: Niemeyer. 
Halle, Morris 
 
1959 
The Sound Pattern of Russian. The Hague: Mouton. 

References 739 
Halle, Morris 
 
1964 
On the Bases of Phonology. In Readings in the philosophy of 
language, Jerrold Katz and Jerry Fodor (eds.), 324-333. New 
York: Prentice-Hall. 
Halle, Morris 
 
1973a 
Stress rules in English: a new version. Linguistic Inquiry 5: 451-
464. 
Halle, Morris 
 
1973b 
The accentuation of Russian words. Language 49: 312-348. 
Halle, Morris 
 
1978 
Formal vs. functional considerations in phonology. Studies in the 
Linguistic Sciences 8: 123-134. Reprinted in Brogyányi, Bela 
(ed.) 1979. Studies in diachronic, synchronic and typological 
linguistics: Festschrift for O. Szemerényi, 325-341. Amsterdam: 
Benjamins. 
Halle, Morris 
 
1986 
On the Phonology-Morphology Interface. Ms, MIT. 
Halle, Morris 
 
1990 
Respecting metrical structure. Natural Language and Linguistic 
Theory 8: 149-176. 
Halle, Morris 
 
1997a 
Distributed Morphology: Impoverishment and Fission. MIT 
Working Papers in Linguistics 30: 425-449. 
Halle, Morris 
 
1997b 
On stress and accent in Indo-European. Language 73: 275-313. 
Halle, Morris 
 
2005 
Palatalization/velar softening: what it is and what it tells us about 
the nature of language. Linguistic Inquiry 36: 23-41. 
Halle, Morris, James Harris, and Jean-Roger Vergnaud 
 
1991 
A reexamination of the stress erasure convention and Spanish 
stress. Linguistic Inquiry 22: 141-159. 
Halle, Morris, and Michael Kenstowicz 
 
1991 
The Free Element Condition and cyclic versus non-cyclic stress. 
Linguistic Inquiry 22: 457-501. 
Halle, Morris, and Alec Marantz 
 
1993 
Distributed Morphology and the Pieces of Inflection. In The view 
from Building 20. Essays in Linguistics in Honor of Sylvain 
Bromberger, Kenneth Hale and Samuel Keyser (eds.), 111-176. 
Cambridge, Mass.: MIT Press. 
Halle, Morris, and Ora Matushansky 
 
2006 
The 
Morphophonology 
of 
Russian 
Adjectival 
Inflection. 
Linguistic Inquiry 37: 351-404. 

740 
References 
Halle, Morris, and Karuvannur Mohanan 
 
1985 
Segmental Phonology of Modern English. Linguistic Inquiry 16: 
57-116. 
Halle, Morris, and Andrew Nevins 
 
2009 
Rule Application in Phonology. In Contemporary Views on 
Architecture and Representations in Phonological Theory, Eric 
Raimy and Charles E. Cairns (eds.), 335-382. Cambridge, Mass.: 
MIT Press. 
Halle, Morris, and Jean-Roger Vergnaud 
 
1987a 
An Essay on Stress. Cambridge, Mass.: MIT Press. 
Halle, Morris, and Jean-Roger Vergnaud 
 
1987b 
Stress and the Cycle. Linguistic Inquiry 18: 45-84. 
Hamburger, H., and Kenneth Wexler 
 
1975 
A mathematical theory of learning transformational grammar. 
Journal of Mathematical Psychology 12: 137-177. 
Hammond, Michael 
 
1995 
There is no lexicon! Coyote Papers 10: 55-77. 
Hannahs, Stephen 
 
1995 
Prosodic Structure and French Morphophonology. Tübingen: 
Niemeyer. 
Hannahs, Stephen 
 
1996 
Phonological Structure and Soft Mutation in Welsh. In Interfaces 
in Phonology, Ursula Kleinhenz (ed.), 46-59. Berlin: Akademie 
Verlag. 
Hargus, Sharon 
 
1993 
Modeling the Phonology - Morphology Interface. In Studies in 
Lexical Phonology, Sharon Hargus and Ellen Kaisse (eds.), 45-74. 
New York: Academic Press. 
Hargus, Sharon, and Ellen Kaisse (eds.) 
 
1993 
Studies in Lexical Phonology. New York: Academic Press. 
Harley, Heidi, and Rolf Noyer 
 
1999 
Distributed Morphology. Glot 4: 3-9. 
Harnad, Steven 
 
1990 
The Symbol Grounding Problem. Physica D: Nonlinear 
Phenomena 42: 335-346. 
Harris, James 
 
1993 
Integrity 
of 
prosodic 
constituents 
and 
the 
domain 
of 
syllabification in Spanish and Catalan. In The view from Building 
20. Essays in Linguistics in Honor of Sylvain Bromberger,
Kenneth Hale and Samuel Keyser (eds.), 177-193. Cambridge, 
Mass.: MIT Press. 
Harris, John 
 
1994 
English sound structure. Oxford: Blackwell. WEB. 
Harris, Randy 
 
1993 
The Linguistics wars. Oxford: Oxford University Press. 

References 741 
Harris, Zellig 
 
1951 
Methods in Structural Linguistics. Edition 1960 entitled 
Structural Linguistics. Chicago & London: University of Chicago 
Press. 
Haugeland, John 
 
1989 
Artificial Intelligence. The Very Idea. Cambridge, Mass.: MIT 
Press. 
Hauser, Marc, Noam Chomsky, and Tecumseh Fitch 
 
2002 
The faculty of language: what is it, who has it, and how did it 
evolve ? Science 298: 1569-1579. 
Hay, Jennifer 
 
2002 
From speech perception to morphology: affix ordering revisited. 
Language 78: 527-555. 
Hay, Jennifer, and Ingo Plag 
 
2004 
What constrains possible suffix combinations? On the interaction 
of grammatical and processing restrictions in derivational 
morphology. Natural Language & Linguistic Theory 22: 565-596. 
Hayes, Bruce 
 
1982 
Extrametricality and English stress. Linguistic Inquiry 13: 227-
276. 
Hayes, Bruce 
 
1984 
The phonology of rhythm in English. Linguistic Inquiry 15: 33-
74. 
Hayes, Bruce 
 
1989 [1984] The Prosodic Hierarchy in Meter. In Manuscript circulated since 
1984, published 1989 in Rhythm and Meter, Paul Kiparsky and G. 
Youmans (eds.), 201-260. Orlando, Florida: Academic Press. 
Hayes, Bruce 
 
1990 
Precompiled Phrasal Phonology. In The Phonology-Syntax 
Connection, Sharon Inkelas and Draga Zec (eds.), 85-108. 
Chicago: University of Chicago Press. 
Hayes, Bruce 
 
1995a 
On what to teach undergraduates: some changing orthodoxies in 
phonological theory. In Linguistics in the Morning Calm 3, Ik-
Hwan Lee (ed.), 59-77. Seoul: Hanshin. 
Hayes, Bruce 
 
1995b 
Metrical Stress Theory. Principles and Case Studies. Chicago, 
London: University of Chicago Press. 
Hayes, Bruce, Robert Kirchner, and Donca Steriade (eds.) 
 
2004 
Phonetically-Based 
Phonology.
Cambridge: 
Cambridge 
University Press. 
Herken, R. (ed.) 
 
1995 
The Universal Turing Machine: A Half-Century Survey. Wien: 
Springer. 

742 
References 
Hermans, Ben, and Marc van Oostendorp (eds.) 
 
1999 
The Derivational Residue in Phonological Optimality Theory.
Amsterdam: Benjamins. 
Hermer, Linda, and Elizabeth Spelke 
 
1996 
Modularity and development: the case of spatial reorientation. 
Cognition 61: 195-232. 
Hermon, Gabriella 
 
1985 
Syntactic Modularity. Dordrecht: Foris. 
Hickok, Gregory 
 
2004 
Dorsal and ventral streams: a framework for understanding as-
pects of the functional anatomy of language. Cognition 92: 67-99. 
Hickok, Gregory, and David Poeppel 
 
2007 
The cortical organization of speech perception. Nature Reviews 
Neuroscience 8: 393-402. 
Higginbotham, James 
 
1987 
The Autonomy of Syntax and Semantics. In Modularity in 
Knowledge Representation and Natural Language Understand-
ing, Jay Garfield (ed.), 119-131. Cambridge, Mass.: MIT Press. 
Hill, Archibald 
 
1954 
Juncture and syllable division in Latin. Language 30: 439-447. 
Hinterhölzl, Roland 
 
2006 
The Phase Condition and cyclic Spell-out: Evidence from VP-
topicalization. In Phases of Interpretation, Mara Frascarelli (ed.), 
237-259. Berlin: de Gruyter. 
Hirschfeld, Lawrence, and Susan Gelman (eds.) 
 
1994 
Mapping the mind: Domain specificity in cognition and culture.
Cambridge: CUP. 
Hirschfeld, Lawrence, and Susan Gelman 
 
1994 
Toward a topography of mind: an introduction to domain specific-
ity. In Mapping the mind: Domain specificity in cognition and 
culture, Lawrence Hirschfeld and Susan Gelman (eds.), 3-35. 
Cambridge: CUP. 
Hoard, James 
 
1966 
Juncture and Syllable Structure in English. Phonetica 15: 96-109. 
Hoard, James 
 
1973 
On incorporating Grassmann's Law into Sanskrit phonology. 
Paper presented at the Western Conference on Linguistics, Octo-
ber 1973. 
Hockett, Charles 
 
1942 
A System of Descriptive Phonology. Language 18: 3-21. 
Hockett, Charles 
 
1949 
Two fundamental problems in phonemics. Studies in Linguistics 
7: 29-51. 

References 743 
Hockett, Charles 
 
1955 
A Manual of Phonology. Baltimore: Waverly Press. 
Hockett, Charles 
 
1958 
A Course in Modern Linguistics. New York: Macmillan. 
Hooper, Joan 
 
1975 
The archi-segment in Natural Generative Phonology. Language 
51: 536-560. 
Hooper, Joan 
 
1976 
An Introduction to Natural Generative Phonology. New York: 
Academic Press. 
Hornstein, Norbert 
 
2009 
A Theory of Syntax. Cambridge: CUP. 
Hornstein, Norbert, Jairo Nunes, and Kleanthes Grohmann 
 
2005 
Understanding Minimalism. Cambridge: CUP. 
Huddleston, Rodney 
 
1972 
The development of a non-process model in American structural 
linguistics. Lingua 30: 333-384. 
Hulst, Harry van der 
 
2000 
Modularity and Modality in Phonology. In Phonological 
Knowledge. Conceptual and Empirical Issues, Noel Burton-
Roberts, Philip Carr and Gerard Docherty (eds.), 207-243. 
Oxford: Oxford University Press. 
Hulst, Harry van der 
 
2010 
A note on recursion in phonology. In Recursion and Human 
Language, Harry van der Hulst (ed.), 301-341. Berlin: de Gruyter. 
Hume, Elizabeth, and Keith Johnson (eds.) 
 
2001 
The Role of Speech Perception in Phonology. New York: 
Academic Press. 
Hurch, Bernhard, and Richard Rhodes (eds.) 
 
1996 
Natural Phonology: The State of the Art. Berlin: Mouton de 
Gruyter. 
Hyman, Larry 
 
1975 
Phonology: theory and analysis. New York: Holt, Rinehart & 
Winston. 
Hyman, Larry 
 
1978 
Word Demarcation. In Universals of Human Language, Vol 2,
Joseph Greenberg (ed.), 443-470. Stanford: Stanford University 
Press. 
Hyman, Larry, Francis Katamba, and Livingstone Walusimbi 
 
1987 
Luganda and the strict layer hypothesis. Phonology Yearbook 4: 
87-108. 

744 
References 
Hyman, Larry, and K. Kim 
 
1973 
On the non-status of morpheme boundaries in phonology. Paper 
presented at the Winter Meeting of the Linguistic Society of 
America, San Diego. 
Idsardi, William, and Eric Raimy 
 
forth 
Three types of linearization and the temporal aspects of speech. In 
Principles of linearization, Ian Roberts and M. T. Biberauer 
(eds.). Berlin: Mouton de Gruyter. WEB. 
Inkelas, Sharon 
 
1990 
Prosodic Constituency in the Lexicon. New York: Garland. 
Inkelas, Sharon 
 
1993 
Deriving Cyclicity. In Studies in Lexical Phonology, Sharon 
Hargus and Ellen Kaisse (eds.), 75-110. New York: Academic 
Press. 
Inkelas, Sharon 
 
1996 
Dominant affixes and the phonology-morphology interface. In 
Interfaces in Phonology, Ursula Kleinhenz (ed.), 128-154. Berlin: 
Akademie Verlag. 
Inkelas, Sharon 
 
1998 
The theoretical status of morphologically conditioned phonology: 
a case study of dominance effects. Yearbook of Morphology 1997:
121-155. 
Inkelas, Sharon 
 
1999 
Exceptional stress-attracting suffixes in Turkish: representations 
versus the grammar. In The Prosodiy-Morphology Interface, René 
Kager, Harry van der Hulst and Wim Zonneveld (eds.), 134-187. 
Cambridge: CUP. 
Inkelas, Sharon 
 
2000 
Phonotactic blocking through structural immunity. In Lexicon in 
Focus, B. Stiebels and D. Wunderlich (eds.), 7-40. Berlin: 
Akademie Verlag. 
Inkelas, Sharon, and Young-Mee Yu Cho 
 
1993 
Inalterability as prespecification. Language 69: 529-574. 
Inkelas, Sharon, and Cemil Orhan Orgun 
 
1995 
Level ordering and economy in the lexical phonology of Turkish. 
Language 71: 763-793. 
Inkelas, Sharon, and Draga Zec (eds.) 
 
1990c 
The Phonology-Syntax Connection. Chicago & London: Chicago 
University Press. 
Inkelas, Sharon, and Draga Zec 
 
1988 
Serbo-Croatian pitch accent: the interactions of tone, stress and 
intonation. Language 64: 227-248. 

References 745 
Inkelas, Sharon, and Draga Zec 
 
1990a 
Introduction. In The Phonology-Syntax Connection, Sharon Inke-
las and Draga Zec (eds.), xiii-xv. Chicago: University of Chicago 
Press. 
Inkelas, Sharon, and Draga Zec 
 
1990b 
Prosodically constrained syntax. In The Phonology-Syntax 
Connection, Sharon Inkelas and Draga Zec (eds.), 365-378. 
Chicago: Chicago University Press. 
Inkelas, Sharon, and Draga Zec 
 
1995 
Syntax-phonology Interface. In The Handbook of Phonological 
Theory, John Goldsmith (ed.), 535-549. Oxford: Blackwell. 
Isac, Daniela, and Charles Reiss 
 
2008 
I-Language. An Introduction to Linguistics as Cognitive Science.
Oxford: OUP. 
Ishihara, Shinichiro 
 
2007 
Major phrase, focus intonation, multiple spell-out. The Linguistic 
Review 24: 137-167. 
Itô, Junko 
 
1986 
Syllable Theory in Prosodic Phonology. Ph.D dissertation, 
University of Massachusetts at Amherst. 
Itô, Junko, and Armin Mester 
 
1995 
Japanese Phonology. In The Handbook of Phonological Theory,
John Goldsmith (ed.), 816-838. Oxford: Blackwell. 
Itô, Junko, and Armin Mester 
 
1999a 
Realignment. In The prosody-morphology interface, René Kager, 
Harry van der Hulst and Wim Zonneveld (eds.), 188-217. 
Cambridge: Cambridge University Press. 
Itô, Junko, and Armin Mester 
 
1999b 
The phonological lexicon. In The Handbook of Japanese 
Linguistics, Natsuko Tsujimura (ed.), 62-100. Oxford: Blackwell. 
Itô, Junko, and Armin Mester 
 
2001 
Covert Generalizations in Optimality Theory: the role of stratal 
faithfulness constraints. Studies in Phonetics, Phonology and 
Morphology 7: 273-299. 
Itô, Junko, and Armin Mester 
 
2003 [1992] Weak Layering and Word Binarity. In Manuscript circulated 
since 1992, published 2003 in A New Century of Phonology and 
Phonological Theory. A Festschrift for Professor Shosuke 
Haraguchi on the Occasion of His Sixtieth Birthday, Takeru 
Honma, Masao Okazaki, Toshiyuki Tabata and Shin-ichi Tanaka 
(eds.), 26-65. Tokyo: Kaitakusha. 

746 
References 
Itô, Junko, Armin Mester, and Jaye Padgett 
 
2004 
Licensing and Underspecification in Optimality Theory. In Opti-
mality Theory in Phonology, John McCarthy (ed.), 533-541. Ox-
ford: Blackwell. 
Iverson, Gregory 
 
2004 
Deriving the Derived Environment Constraint in Nonderivational 
Phonology. Studies in Phonetics, Phonology and Morphology 11: 
1-23. 
Iverson, Gregory, and Deirdre Wheeler 
 
1988 
Blocking 
and 
the 
Elsewhere 
Condition. 
In 
Theoretical 
Morphology: Approaches in Modern Linguistics,
Michael 
Hammond and M. Noonan (eds.), 325-338. San Diego: Academic 
Press. 
Jackendoff, Ray 
 
1969 
Some rules of semantic interpretation for English. Ph.D 
dissertation, MIT. 
Jackendoff, Ray 
 
1987 
Consciousness and the computational mind. Cambridge, Mass.: 
MIT Press. 
Jackendoff, Ray 
 
1992 
Languages of the mind. Cambridge, Mass.: MIT Press. 
Jackendoff, Ray 
 
1994 
Patterns in the Mind. Language and human nature. New York: 
BasicBooks. 
Jackendoff, Ray 
 
1997 
The Architecture of the Language Faculty.
Cambridge, 
Massachusetts: MIT Press. 
Jackendoff, Ray 
 
2002 
Foundations of Language. Brain, Meaning, Grammar, Evolution.
Oxford: Oxford University Press. 
Jenkins, Lyle 
 
2000 
Biolinguistics. Exploring the Biology of Language. Cambridge: 
CUP. 
Joos, Martin (ed.) 
 
1957 
Readings in Linguistics: The development of descriptive 
linguistics in America since 1925. Washington D.C.: American 
Council of Learned Societies. 
Joos, Martin 
 
1964 
A chapter of semology in the English verb. In Report of the 15th 
Annual (1st International) Round Table Meeting on Linguistics 
and Language Studies, C. Stuart (ed.), 59-72. Washington, D. C.: 
Georgetown University Press. 
Julien, Marit 
 
2006 
On argument displacement in English and Scandinavian. Working 
Papers in Scandinavian Syntax 77: 1-69. 

References 747 
Julien, Marit 
 
2007 
On the Relation between Morphology and Syntax. In The Oxford 
Handbook of Linguistic Interfaces, Gillian Ramchand and Charles 
Reiss (eds.), 209-238. Oxford: OUP. 
Junković, Zvonimir 
 
1980 
Mot et unité accentuelle. Travaux du cercle linguistique de Nice 
2: 117-126. 
Junković, Zvonimir 
 
1990 
Accentologie théorique et accentologie comparée. Travaux du 
cercle linguistique de Nice 12: 5-14. 
Kager, René 
 
1999 
Optimality Theory. Cambridge: Cambridge University Press. 
Kager, René 
 
2000 
Stem Stress and Peak Correspondence in Dutch. In Optimality 
Theory, Joost Dekkers, Frank van der Leeuw and Jeroen van de 
Weijer (eds.), 121-150. Oxford: Oxford University Press. 
Kahn, Daniel 
 
1976 
Syllable-based generalizations in English phonology. Ph.D 
dissertation, MIT. Published by Garland Press, New York 1980. 
Kahnemuyipour, Arsalan 
 
2009 
The Syntax of Sentential Stress. Oxford: OUP. 
Kaisse, Ellen 
 
1983 
The syntax of auxiliary reduction in English. Language 59: 93-
122. 
Kaisse, Ellen 
 
1985 
Connected Speech. The interaction of Syntax and Phonology.
London, New York: Academic Press. 
Kaisse, Ellen 
 
1990 
Toward a Typology of Postlexical Rules. In The Phonology-
Syntax Connection, Sharon Inkelas and Draga Zec (eds.), 127-
143. Chicago: Chicago University Press. 
Kaisse, Ellen, and Sharon Hargus 
 
1993 
Introduction. In Studies in Lexical Phonology, Sharon Hargus and 
Ellen Kaisse (eds.), 1-19. New York: Academic Press. 
Kaisse, Ellen, and Patricia Shaw 
 
1985 
On the theory of Lexical Phonology. Phonology Yearbook 2: 1-
30. 
Kaisse, Ellen, and Arnold Zwicky 
 
1987 
Introduction: 
syntactic 
influences 
on 
phonological 
rules. 
Phonology 4: 3-11. 
Kanerva, Jonni 
 
1990 
Focusing on Phonological Phrases in Chichewa. In The 
Phonology-Syntax connection, Sharon Inkelas and Draga Zec 
(eds.), 145-161. Chicago: Chicago University Press. 

748 
References 
Karmiloff-Smith, Annette 
 
1998 
Development itself is the key to understanding developmental 
disorders. Trends in Cognitive Sciences 2: 389-398. 
Karmiloff-Smith, Annette, Edward Klima, Ursula Bellugi, Julia Grant, and Simon 
Baron-Cohen 
 
1995 
Is There a Social Module? Language, Face Processing, and 
Theory of Mind in Individuals with Williams Syndrome. Journal 
of Cognitive Neuroscience 7: 196-208. 
Karttunen, Lauri 
 
1993 
Finite-State Constraints. In The last phonological rule, John 
Goldsmith (ed.), 173-194. Chicago: University of Chicago Press. 
Kasher, Asa (ed.) 
 
1991 
The Chomskyan Turn. Oxford: Blackwell. 
Katz, Jerrold 
 
1984 
An outline of a Platonist grammar. In Talking Minds: The Study of 
Language in Cognitive Science, Thomas G. Bever, John M. 
Carroll and Lance A. Miller (eds.), 17-48. Cambridge, Mass.: 
MIT Press. 
Katz, Jerrold, and Thomas Bever 
 
1974 
The fall and rise of empiricism. Bloomington: Indiana University 
Linguistics Club. WEB. 
Kaye, Jonathan 
 
1989 
Phonology. A cognitive view. Hillsdale: Erlbaum. WEB. 
Kaye, Jonathan 
 
1990a 
'Coda' licensing. Phonology 7: 301-330. WEB. 
Kaye, Jonathan 
 
1990b 
What ever happened to dialect B ? In Grammar in Progress: 
GLOW Essays for Henk van Riemsdijk, Joan Mascaró and Marina 
Nespor (eds.), 259-263. Dordrecht: Foris. 
Kaye, Jonathan 
 
1992a 
On the interaction of theories of Lexical Phonology and theories 
of phonological phenomena. In Phonologica 1988, Uli Dressler, 
Hans Luschützky, Oskar Pfeiffer and John Rennison (eds.), 141-
155. Cambridge: Cambridge University Press. WEB. 
Kaye, Jonathan 
 
1992b 
Do you believe in magic? The story of s+C sequences. SOAS 
Working Papers in Linguistics and Phonetics 2: 293-313. 
Reprinted in A Festschrift for Edmund Gussmann, edited by 
Henryk Kardela & Bogdan Szymanek, 155-176. Lublin 1996: 
Lublin University Press. WEB. 

References 749 
Kaye, Jonathan 
 
1995 
Derivations and Interfaces. In Frontiers of Phonology, Jacques 
Durand and Francis Katamba (eds.), 289-332. London & New 
York: Longman. Also in SOAS Working Papers in Linguistics 
and Phonetics 3, 1993, 90-126. WEB. 
Kaye, Jonathan 
 
2001 
Working with licensing constraints. In Constraints and 
Preferences, Katarzyna Dziubalska-Kołaczyk (ed.), 251-268. 
Berlin & New York: Mouton de Gruyter. WEB. 
Kaye, Jonathan 
 
2005 
"GP, I'll have to put your flat feet on the ground". In Organizing 
Grammar. Studies in Honor of Henk van Riemsdijk, Hans 
Broekhuis, Norbert Corver, Riny Huybregts, Ursula Kleinhenz 
and Jan Koster (eds.), 283-288. Berlin: Mouton de Gruyter. 
Kaye, Jonathan 
 
2008 
Canadian Raising, eh? Ms.
Kaye, Jonathan, Jean Lowenstamm, and Jean-Roger Vergnaud 
 
1985 
The internal structure of phonological representations: a theory of 
Charm and Government. Phonology Yearbook 2: 305-328. WEB. 
Kaye, Jonathan, Jean Lowenstamm, and Jean-Roger Vergnaud 
 
1990 
Constituent structure and government in phonology. Phonology 7: 
193-231. WEB. 
Kaye, Jonathan, and Jean-Roger Vergnaud 
 
1990 
Phonology, morphology and the lexicon. Paper presented at 
GLOW, St. John's College, Cambridge University. 
Kayne, Richard S. 
 
1994 
The Antisymmetry of Syntax. Cambridge, Mass.: MIT Press. 
Kean, Mary-Louise 
 
1971 
Strict Cyclicity. Ms., MIT. 
Kean, Mary-Louise 
 
1974 
The Strict Cycle in Phonology. Linguistic Inquiry 5: 179-203. 
Kennedy, Chris 
 
2001 
Polar Opposition and the Ontology of µDegrees¶. Linguistics and 
Philosophy 24: 33-70. 
Kenstowicz, Michael 
 
1996 
Base-identity and uniform exponence: alternatives to cyclicity. In 
Current Trends in Phonology. Models and Methods, Jacques 
Durand and Bernard Laks (eds.), 363-393. Salford: ESRI. 
Kenstowicz, Michael, and Charles Kisseberth 
 
1977 
Topics in Phonological Theory. New York: Academic Press. 
Kenstowicz, Michael, and Charles Kisseberth 
 
1979 
Generative Phonology. Description and Theory. San Diego: 
Academic Press. 

750 
References 
Kepke, John 
 
1948 
A comment on terminology. Studies in Linguistics 6: 20. 
Kidima, Lukowa 
 
1990 
Tone and Syntax in Kiyaka. In The Phonology-Syntax 
Connection, Sharon Inkelas and Draga Zec (eds.), 195-216. 
Chicago: Chicago University Press. 
Kingston, John 
 
2007 
The phonetics-phonology interface. In The Cambridge Handbook 
of Phonology, Paul De Lacy (ed.), 435-456. Cambridge: CUP. 
Kiparsky, Paul 
 
1968-1973 
How abstract is phonology? In Manuscript circulated since 1968 
and published 1973 in: Three Dimensions of Linguistic Theory,
Osamu Fujimura (ed.), 5-56. Tokyo: TEC. 
Kiparsky, Paul 
 
1973a 
Abstractness, opacity and global rules. In Three Dimensions in 
Phonological Theory, Osamu Fujimura (ed.), 57-86. Tokyo: TEC. 
Kiparsky, Paul 
 
1973b 
Productivity in Phonology. In Issues in Phonological Theory,
Michael Kenstowicz and Charles Kisseberth (eds.), 169-176. The 
Hague: Mouton. 
Kiparsky, Paul 
 
1973c 
'Elsewhere' in Phonology. In A Festschrift for Morris Halle,
Stephen Anderson and Paul Kiparsky (eds.), 93-106. New York: 
Holt, Rinehart & Winston. 
Kiparsky, Paul 
 
1974 
On the Evaluation Measure. In Papers from the parasession on 
Natural Phonology, A.Bruck, R.Fox and M.La Galy (eds.), 328-
337. Chicago: Chicago Linguistic Society. 
Kiparsky, Paul 
 
1979 
Metrical Structure Assignment is Cyclic. Linguistic Inquiry 10: 
421-441. 
Kiparsky, Paul 
 
1982a 
Lexical morphology and phonology. In Linguistics in the morning 
calm, In-Seok Yang (ed.), 3-91. Seoul: Hanshin. 
Kiparsky, Paul 
 
1982b 
From Cyclic Phonology to Lexical Phonology. In The structure of 
phonological representations I, Harry van der Hulst and Norval 
Smith (eds.), 131-175. Dordrecht: Foris. WEB. 
Kiparsky, Paul 
 
1982c 
Explanation in Phonology. Dordrecht: Foris. 
Kiparsky, Paul 
 
1985a 
Some Consequences of Lexical Phonology. Phonology Yearbook 
2: 85-138. 

References 751 
Kiparsky, Paul 
 
1985b 
On the lexical phonology of Icelandic. In Nordic Prosody 3, C. 
Elert, I. Johansson and E. Stangert (eds.), 135-164. Umeå: 
University of Umeå. 
Kiparsky, Paul 
 
1993 
Blocking in nonderived environments. In Studies in Lexical 
Phonology, Sharon Hargus and Ellen Kaisse (eds.), 277-313. San 
Diego: Academic Press. 
Kiparsky, Paul 
 
2000 
Opacity and cyclicity. The Linguistic Review 17: 351-365. 
Kisseberth, Charles, and Mohammad Imam Abasheikh 
 
1974 
Vowel Length in Chi-Mwi:ni -- a Case Study of the Role of 
Grammar in Phonology. In Papers from the parasession on 
Natural Phonology, Anthony Bruck, Robert Fox and Michael La 
Galy (eds.), 193-209. Chicago: Chicago Linguistic Society. 
Kleinhenz, Ursula (ed.) 
 
1996 
Interfaces in Phonology. Berlin: Akademie Verlag. 
Kleinhenz, Ursula 
 
1998 
On Words and Phrases in Phonology. A comparative study with 
focus on German. Ph.D thesis, University of Tübingen. 
Koerner, E.F.K. 
 
2002 
The Chomskyan 'Revolution' and its historiography. In Toward a 
History of American Linguistics, E.F.K. Koerner (ed.), 151-209. 
London: Routledge. 
Koerner, E.F.K. 
 
2004 
On "influence" in linguistic historiography: morphohonemics in 
American structuralism. In Essays in the History of Linguistics,
E.F.K. Koerner (ed.), 65-101. London: Benjamins. 
Kratzer, Angelika, and Elisabeth Selkirk 
 
2007 
Phase theory and prosodic spellout: the case of verbs. The 
Linguistic Review 24: 93-135. 
Kula, Nancy 
 
2008 
Derived environment effects: a representational approach. Lingua 
118: 1328-1343. 
Ladd, Robert 
 
1986 
Intonational phrasing: the case for recursive prosodic structure. 
Phonology 3: 311-340. 
Ladd, Robert 
 
1996 
Intonational Phonology. Cambridge: CUP. 
Ladd, Robert 
 
2000 
Bruce, Pierrehumbert, and the Elements of Intonational 
Phonology. In The interaction of constraints on prosodic 
phrasing. Prosody: Theory and Experiments, Merle Horne (ed.), 
37-50. Dordrecht: Kluwer. 

752 
References 
Lahrouchi, Mohamed 
 
2001 
Aspects morpho-phonologiques de la dérivation verbale en 
berbère (parler chleuh d'Agadir). Ph.D dissertation, Université 
Paris 7. 
Lakoff, George 
 
1993 
Cognitive Phonology. In The last phonological rule, John 
Goldsmith (ed.), 117-145. Chicago: University of Chicago Press. 
Laks, Bernard 
 
1996 
Langage et cognition, l'approche connexionniste. Paris: Hermès. 
Laks, Bernard 
 
2006 
La phonologie générative naturelle et la phonologie naturelle. In 
History of the Language Sciences, vol.3 (HSK 18.3), Sylvain 
Auroux, E.F.K. Koerner, Hans-Josef Niederehe and Kees 
Versteegh (eds.), 2271-2280. Berlin: de Gruyter. 
Lampitelli, Nicola 
 
forth a 
The basic elements of a noun: morphosyntax of the Bosnian 
declensional system. Ms., Université Paris 7. Available at 
www.linguist.univ-paris-
diderot.fr/~nlampitelli/drafts&papers.html. 
Lampitelli, Nicola 
 
forth b 
On the abstractness of the phonological component in a piece-
based morphological theory. Ms., Université Paris 7. Available at 
www.linguist.univ-paris-
diderot.fr/~nlampitelli/drafts&papers.html. 
Langacker, Ronald 
 
1987 
Foundations of Cognitive Grammar, 2 Vols. Stanford: Stanford 
University Press. 
Langendoen, Terence 
 
1975 
Finite state parsing of phrase structure languages and the status of 
readjustment rules in the grammar. Linguistic Inquiry 6: 533-554. 
Larson, G. 
 
1992 
Dynamic computational networks and the representation of 
phonological information. Ph.D dissertation, University of 
Chicago. 
Lasnik, Howard 
 
1972 
Analysis of negation in English. Ph.D dissertation, MIT. 
Lasnik, Howard, and Terje Lohndal 
 
2009 
Government-binding/principles and parameters theory. Wiley 
Interdisciplinary Reviews: Cognitive Science 1: 40-50. 
Lass, Roger 
 
1971 
Boundaries as obstruents: Old English voicing assimilation and 
universal strength hierarchies. Journal of Linguistics 7: 15-30. 
Lebeaux, David 
 
1988 
Language Acquisition and the Form of the Grammar. Ph.D 
dissertatioan, University of Massachusetts. 

References 753 
Legate, Julie Anne 
 
2003 
Some Interface Properties of the Phase. Linguistic Inquiry 34: 
506-516. 
Legendre, Geraldine, Yoshiro Miyata, and Paul Smolensky 
 
1990 
Harmonic Grammar - a formal multi-level connectionist theory of 
linguistic 
well-formedness: 
theoretical 
foundations. 
In 
Proceedings of the twelfth annual conference of the Cognitive 
Science Society, the Cognitive Science Society (ed.), 388-395. 
Cambridge, MA.: Erlbaum. 
Lehiste, Ilse 
 
1960 
An Acoustic-Phonetic Study of Internal Open Juncture. Basel, 
New York: Karger (supplement to Phonetica 5). 
Lehiste, Ilse 
 
1962 
Acoustic Studies of Boundary Signals. In Proceedings of the 
Fourth International Congress of Phonetic Sciences, Antti 
Sovijärvi and Pentti Aalto (eds.), 178-187. The Hague: Mouton. 
Lehiste, Ilse 
 
1965 
Juncture. In Proceedings of the Fifth International Congress of 
Phonetic Sciences, Eberhard Zwirner and Wolfgang Bethge 
(eds.), 172-200. Basel: Karger. 
Leopold, Werner F. 
 
1948 
German CH. Language 24: 179-180. 
Li, Yafei 
 
2005 
X°: a Theory of the Morphology-syntax Interface. Cambridge, 
MA: MIT Press. 
Liberman, Mark 
 
1975 
The Intonational System of English. Ph.D dissertation, MIT. 
Liberman, Mark, and Alan Prince 
 
1977 
On Stress and Linguistic Rhythm. Linguistic Inquiry 8: 249-336. 
Lieber, Rochelle 
 
1981 
On the organization of the lexicon. Ph.D dissertation, MIT. 
Lieber, Rochelle, and Sergio Scalise 
 
2007 
The Lexical Integrity Hypothesis in a new Theoretical Universe. 
In Proceedings of the Fifth Mediteranean Morphology Meeting,
Geert Booij, L. Ducceschi, Bernard Fradin, E. Guevara, Angela 
Ralli and Sergio Scalise (eds.), 1-24. Bologna: Università degli 
Studi di Bologna. 
Lightner, Theodore 
 
1978 
Generative Phonology. In A Survey of Linguistic Science, William 
Orr Dingwall (ed.), 1-32. 2nd edition Stamford, Connecticut: 
Greylock. 
Lightner, Theodore 
 
1981 
New explorations into Derivational Morphology. In Phonology in 
the 80's, Didier Goyvaerts (ed.), 93-99. Ghent: Story-Scientia. 

754 
References 
Lightner, Theodore 
 
1985 
On universal rules. Lingvisticae Investigationes 9: 419-420. 
Lobeck, Anne, and Ellen Kaisse 
 
1984 
On the domain of locality conditions. Proceedings of the West 
Coast Conference on Formal Linguistics 3: 170-178. 
Loevenbruck, H., Monica Baciu, C. Segebarth, and Christian Abry 
 
2005 
Broca's region under focus: An fMRI study of the production of 
deixis via syntactic extraction and prosodic focus. Journal of 
Neurolingustics, 18: 237-258. 
Lombardi, Linda 
 
2001 
Introduction. In Segmental phonology in Optimality Theory. 
Constraints and Representations, Linda Lombardi (ed.), 1-9. 
Cambridge: Cambridge University Press. 
Loporcaro, Michele 
 
1999 
Teoria fonologica e ricerca empirica sull'italiano e i suoi dialetti. 
In Fonologia e morfologia dell'italiano e dui dialetti d'Italia. Atti 
del 31° Congresso della Società di Linguistica Italiana, Paola 
Benincà, Alberto Mioni and Laura Vanelli (eds.), 117-151. Roma: 
Bulzoni. 
Lowenstamm, Jean 
 
1989 
Prosodic Government. Langues Orientales Anciennes, Philologie 
et Linguistique 2: 221-223. 
Lowenstamm, Jean 
 
1996 
CV as the only syllable type. In Current trends in Phonology. 
Models and Methods, Jacques Durand and Bernard Laks (eds.), 
419-441. Salford, Manchester: ESRI. WEB. 
Lowenstamm, Jean 
 
1999 
The beginning of the word. In Phonologica 1996, John Rennison 
and Klaus Kühnhammer (eds.), 153-166. La Hague: Holland 
Academic Graphics. WEB. 
Lowenstamm, Jean 
 
2008 
On Little n, √, and Types of Nouns. In Sounds of Silence: Empty 
Elements in Syntax and Phonology, Jutta Hartmann, Veronika 
Hegedüs and Henk van Riemsdijk (eds.), 105-143. Amsterdam: 
Elsevier. 
Lowenstamm, Jean, and Jonathan Kaye 
 
1986 
Compensatory Lengthening in Tiberian Hebrew. In Studies in 
Compensatory Lengthening, Leo Wetzels and Engin Sezer (eds.), 
97-132. Dordrecht: Foris. 
Łubowicz, Anna 
 
2002 
Derived environment effects in Optimality Theory. Lingua 112: 
243-280. 

References 755 
Łubowicz, Anna 
 
2004 
Derived Environment Effects in Optimality Theory. In Optimality 
Theory in Phonology, John McCarthy (ed.), 523-532. Oxford: 
Blackwell. 
Łubowicz, Anna 
 
2005 
Locality of conjunction. In Proceedings of the 24th West Coast 
Conference on Formal Linguistics, John Alderete, Chung-hye 
Han and Alexei Kochetov (eds.), 254-262. Somerville, Mass.: 
Cascadilla. 
Macdonald, Cynthia, and Graham Macdonald 
 
1995 
Connectionism: Debates on Psychological Explanation. Oxford: 
Blackwell. 
Manfredi, Victor 
 
forth 
The referential prosody of bare arguments. Ms., Boston 
University. 
Available 
at 
http://people.bu.edu/manfredi/writing.html. 
Manzini, Rita 
 
1983 
Syntactic conditions on phonological rules. MIT Working Papers 
in Linguistics 5: 1-9. 
Marantz, Alec 
 
1984 
On the nature of grammatical relations. Cambridge, Mass.: MIT 
Press. 
Marantz, Alec 
 
1997a 
No escape from syntax: don't try morphological analysis in the 
privacy of your own lexicon. University of Pennsylvania Working 
Papers in Linguistics 4.2: 201-225. 
Marantz, Alec 
 
1997b 
Cat as a phrasal idiom: stem suppletion, or the arbitrariness of the 
sign. Paper presented at Paper presented at the University Paris 8. 
Marantz, Alec 
 
2000 
Roots. Paper presented at the Conference on Afro-Asiatic 
languages, Paris. 
Marantz, Alec 
 
2001 
Words. Handout from the 20th West Coast Conference on Formal 
Linguistics. 
Marantz, Alec 
 
2007 
Phases and words. In Phases in the theory of grammar, S.-H. 
Choe (ed.), 191-222. Seoul: Dong In. 
Marcus, Gary 
 
1993 
Negative evidence in language acquisition. Cognition 46: 53-85. 
Marlo, Michael 
 
2008 
Post-syntactic phonology: evidence from Bantu. Paper presented 
at the 5th North American Phonology Conference, Montreal 9-11 
May. 

756 
References 
Marr, David 
 
1982 
Vision. San Francisco: Freeman. 
Marshall, John 
 
2001 
Cognition and Neuroscience: Where Were We? In Language, 
Brain and Cognitive Development. Essays in Honor of Jacques 
Mehler, Emmanuel Dupoux (ed.), 503-512. Cambridge, Mass.: 
MIT Press. 
Maruãič, Franc 
 
2005 
On non-simultaneous phases. Ph.D. dissertation, SUNY, Stony 
Brook. 
Maruãič, Franc, and Rok äaucer 
 
2006 
On the intensional feel-like construction in Slovenian. Natural 
Language and Linguistic Theory 24: 1093-1159. 
Marvin, Tatjana 
 
2002 
Topics in the Stress and Syntax of Words. Ph.D dissertation, MIT. 
Marvin, Tatjana 
 
2008 
The interaction between stress, syntax and meaning in Slovenian 
priscianic formations. In Studies in Formal Slavic Linguistics,
Franc Maruãic and Rok äaucer (eds.), 191-212. Frankfurt am 
Main: Peter Lang. 
Mascaró, Joan 
 
1976 
Catalan 
Phonology 
and 
the 
Phonological 
Cycle. 
Ph.D. 
dissertation. 
Matushansky, Ora 
 
2005 
Going through a phase. MIT Working Papers in Linguistics 49: 
157-181. 
Mazzola, Michael 
 
1999 
On the independence of suprasegmental constituency. In Issues in 
phonological structure, S.J. Hannahs and Mike Davenport (eds.), 
181-193. Amsterdam: Benjamins. 
McCarthy, John (ed.) 
 
2004 
Optimality Theory in Phonology. A Reader. Oxford: Blackwell. 
McCarthy, John 
 
1979 
Formal problems in Semitic phonology and morphology. Ph.D 
dissertation, MIT. PubliéeàNewYork1985:GarlandPress. 
McCarthy, John 
 
1980 
A note on the accentuation of Damascene Arabic. Studies in the 
Linguistic Sciences 10: 77-98. 
McCarthy, John 
 
1999 
Sympathy and phonological opacity. Phonology 16: 331-399. 
McCarthy, John 
 
2003a 
Comparative Markedness. Theoretical Linguistics 29: 1-51. 

References 757 
McCarthy, John 
 
2003b 
Sympathy, Cumulativity, and the Duke-of-York Gambit. In The 
Syllable in Optimality Theory, Caroline Féry and Ruben van de 
Vijver (eds.), 23-76. Cambridge: CUP. 
McCarthy, John 
 
2005 
Optimal Paradigms. In Paradigms in phonological theory, Laura 
Downing, Tracy Hall and Renate Raffelsiefen (eds.), 295-371. 
Oxford: Oxford University Press. 
McCarthy, John 
 
2007 
Hidden Generalizations: Phonological Opacity in Optimality 
Theory. London: Equinox. 
McCarthy, John, and Alan Prince 
 
1986 
Prosodic Morphology. Ms. 
McCarthy, John, and Alan Prince 
 
1988 
Quantitative transfer in reduplicative and templatic morphology. 
In Linguistics in the morning calm, Vol.2, Linguistic Society of 
Korea (ed.), 3-35. Seoul: Hanshin. 
McCarthy, John, and Alan Prince 
 
1990 
Foot and word in Prosodic Morphology: the Arabic broken plural. 
Natural Language and Linguistic Theory 8: 209-283. 
McCarthy, John, and Alan Prince 
 
1993 
Generalized Alignment. In Yearbook of Morphology 1993, Geert 
Booij and Jaap van Marle (eds.), 79-153. Dordrecht: Kluwer. 
Abridged version in McCarthy, John (ed.) 2004. Optimality 
Theory in Phonology, 451-463. Oxford: Blackwell. 
McCarthy, John, and Alan Prince 
 
1994 
The Emergence of the Unmarked: Optimality in Prosodic 
Morphology. In Proceedings of the North-East Linguistic Society 
24, Merce Gonzalez (ed.), 333-379. Amherst: Graduate Linguistic 
Student Association. Downloadable at http://roa.rutgers.edu/ 
(#261). 
McCarthy, John, and Alan Prince 
 
1995a 
Faithfulness and Reduplicative Identity. In Papers in Optimality 
Theory,
Jill Beckman, Laura Walsh Dickey and Suzanne 
Urbanczyk (eds.), 249-384. Amherst: GLSA University of 
Massachusetts. 
McCarthy, John, and Alan Prince 
 
1995b 
Prosodic Morphology. In The handbook of Phonological Theory,
John Goldsmith (ed.), 318-366. Cambridge, Mass.: Blackwell. 
McCarthy, John, and Alan Prince 
 
1996 
Prosodic Morphology 1986. Ms., University of Massachusetts, 
Rutgers University. 

758 
References 
McCarthy, John, and Alan Prince 
 
2001 
Prosodic Morphology. Constraint Interaction and Satisfaction. 
Ms, ROA #482. 
McCawley, James 
 
1968 
The Phonological Component of a Grammar of Japanese. The 
Hague: Mouton. 
McMahon, April 
 
2000 
Lexical Phonology and the history of English. Cambridge: 
Cambridge University Press. 
McMahon, April 
 
2007 
Who's afraid of the vowel shift rule? Language Sciences 29: 341-
359. 
Megerdoomian, Karine 
 
2003 
Asymmetries in Form and Meaning: Surface Realization and the 
Interface Conditions. Paper presented at Approaching Asymmetry 
at the Interfaces, UQAM, Montreal. 
Mehler, Jacques, John Morton, and Peter Jusczyk 
 
1984 
On reducing language to biology. Cognitive Neuropsychology 1: 
83-116. 
Merchant, Jason 
 
2001 
The Syntax of Silence: Sluicing, islands, and identity in ellipsis. 
Ph.D dissertation, University of California at Santa Cruz. 
Michalski, Grzegorz 
 
2009 
Phonology with interfaces: The morphophonology and post-
lexical phonology of English and Polish. Ph.D dissertation, 
University of Poznań.
Miller, Philip, Geoffrey Pullum, and Arnold Zwicky 
 
1997 
The Principle of Phonology-Free Syntax: four apparent 
counterexamples in French. Journal of Linguistics 33: 67-90. 
Mohanan, Karuvannur 
 
1982 
Lexical Phonology. Ph.D dissertation, MIT. 
Mohanan, Karuvannur 
 
1986 
The Theory of Lexical Phonology. Dordrecht: Reidel. 
Mohanan, Karuvannur, and Tara Mohanan 
 
1984 
Lexical Phonology of the consonant system in Malayalam. 
Linguistic Inquiry 15: 575-602. 
Monachesi, Paola 
 
1996 
On the representation of Italian clitics. In Interfaces in Phonology,
Ursula Kleinhenz (ed.), 83-101. Berlin: Akademie Verlag. 
Moravcsik, Edith 
 
2000 
Infixation. In Morphology. An international handbook on 
inflection and word-formation, Vol.1, Geert Booij (ed.), 545-552. 
Berlin: de Gruyter. 

References 759 
Moscovitch, M., G. Winocur, and M. Behrmann 
 
1997 
What Is Special about Face Recognition? Nineteen Experiments 
on a Person with Visual Object Agnosia and Dyslexia but Normal 
Face Recognition. Journal of Cognitive Neuroscience 9: 555-604. 
Moulton, William 
 
1947 
Juncture in Modern Standard German. Language 23: 212-226. 
Müller, Gereon 
 
2004 
Phase Impenetrability and Wh-Intervention. In Minimality Effects 
in Syntax, Arthur Stepanov, Gisbert Fanselow and Ralf Vogel 
(eds.), 289-325. Berlin: Mouton de Gruyter. 
Myers, Scott 
 
1987 
Vowel shortening in English. Natural Language and Linguistic 
Theory 5: 485-518. 
Napoli, Donna Jo, and Marina Nespor 
 
1979 
The syntax of word-initial consonant gemination in Italian. 
Language 55: 812-841. 
Neeleman, Ad, and Tanya Reinhart 
 
1998 
Scrambling and the PF-interface. In The Projection of Arguments: 
Lexical and Compositional Factors, Miriam Butt and Wilhelm 
Geuder (eds.), 309-353. Chicago: CSLI. 
Neeleman, Ad, and Hans van de Koot 
 
2006 
On syntactic and phonological representations. Lingua 116: 1524-
1552. 
Neijt, Anneke 
 
1985 
Clitics in arboreal phonology. In Advances in nonlinear 
phonology, Harry van der Hulst and Norval Smith (eds.), 179-192. 
Dordrecht: Foris. 
Nespor, Marina 
 
1985 
The phonological word in Italian. In Advances in Nonlinear 
Phonology, Harry van der Hulst and Norval Smith (eds.), 193-
204. Dordrecht: Foris. 
Nespor, Marina 
 
1986 
The phonological word in Greek and Italian. In Sandhi 
Phenomena in the Languages of Europe, Henning Andersen (ed.), 
65-74. Berlin: Mouton de Gruyter. 
Nespor, Marina 
 
1987 
Vowel degemination and fast speech rules. Phonology 4: 61-85. 
Nespor, Marina 
 
1988 
Aspects of the interaction between prosodic phonology and the 
phonology of rhythm. In Certamen Phonologicum, Pier Marco 
Bertinetto and Michele Loporcaro (eds.), 189-230. Torino: 
Rosenberg & Sellier. 

760 
References 
Nespor, Marina 
 
1990 
On the separation of prosodic and rhythmic phonology. In The 
Phonology Syntax Connection, Sharon Inkelas and Draga Zec 
(eds.), 243-258. Chicago: University of Chicago Press. 
Nespor, Marina 
 
1999 
Stress Domains. In Word Prosodic Systems in the Languages of 
Europe, Harry van der Hulst (ed.), 117-159. Berlin: Mouton de 
Gruyter. 
Nespor, Marina, Theresa Guasti, and Anne Christophe 
 
1996 
Selecting word order: the Rhythmic Activation Principle. In 
Interfaces in Phonology, Ursula Kleinhenz (ed.), 1-26. Berlin: 
Akademie Verlag. 
Nespor, Marina, and Angela Ralli 
 
1996 
Morphology-phonology interface: phonological domains in Greek 
compounds. The Linguistic Review 13: 357-382. 
Nespor, Marina, and Irene Vogel 
 
1979 
Clash Avoidance in Italian. Linguistic Inquiry 10: 467-482. 
Nespor, Marina, and Irene Vogel 
 
1982 
Prosodic domains of external sandhi rules. In The Structure of 
Phonological Representations, Part I, Harry van der Hulst and 
Norval Smith (eds.), 225-255. Dordrecht: Foris. 
Nespor, Marina, and Irene Vogel 
 
1983 
Prosodic structure above the word. In Prosody: Models and 
Measurements, Anne Cutler and Robert Ladd (eds.), 123-140. 
Berlin: Springer. 
Nespor, Marina, and Irene Vogel 
 
1986 
Prosodic Phonology. Dordrecht: Foris. 
Nespor, Marina, and Irene Vogel 
 
1989 
On clashes and lapses. Phonology 6: 69-116. 
Newell, Allen 
 
1980 
Physical Symbol Systems. Cognitive Science 4: 135-183. 
Newell, Allen, Paul Rosenblom, and John Laird 
 
1989 
Symbolic Architectures for Cognition. In Foundations of 
Cognitive Science, Michael Posner (ed.), 93-131. Cambridge, 
Mass.: MIT Press. 
Newell, Allen, and Herbert Simon 
 
1972 
Human Problem Solving. Englewood Cliffs: Prentice-Hall. 
Newell, Heather 
 
2005a 
Bracketing paradoxes and particle verbs: a late adjunction 
analysis. In Proceedings of Console XIII, Sylvia Blaho, Luis 
Vicente and Erik Schoorlemmer (eds.), 249-272: Student 
Organization of Linguistics in Europe. 

References 761 
Newell, Heather 
 
2005b 
The phonological phase. McGill Working Papers in Linguistics 
19: 21-64. 
Newell, Heather 
 
2008 
Aspects of the morphology and phonology of phases. Ph.D 
dissertation, McGill University Montreal. 
Newell, Heather, and Tobias Scheer 
 
2007 
Procedural First. Paper presented at the 38th Poznań Linguistic 
Meeting, Poznań 13-16 September. 
Newman, Stanley 
 
1946 
On the stress system of English. Word 2: 171-187. 
Newmeyer, Frederick 
 
1986 
Linguistic theory in America. 2nd edition New York: Academic 
Press. 
Newmeyer, Frederick 
 
1996 
Generative linguistics: a historical perspective. London: Rout-
ledge. 
Newmeyer, Frederick 
 
1998 
Language Form and Language Function. Cambridge, Mass.: MIT 
Press. 
Newmeyer, Frederick 
 
2005 
Some Remarks on Roeper¶s Remarks on Chomsky¶s ³Remarks". 
SKASE Journal of Theoretical Linguistics (www.skase.sk) 2: 26-
39. 
Newmeyer, Frederick 
 
2006 
Negation and modularity. In Drawing the boundaries of meaning: 
neo-gricean studies in pragmatics and semantics in honor of 
Laurence R. Horn, Betty Birner and Gregory Ward (eds.), 247-
268. Amsterdam: Benjamins. 
Newport, Elissa, Daphne Bavelier, and Helen Neville 
 
2001 
Critical Thinking about Critical Periods: Perspectives on a Critical 
Perion for Language Acquisition. In Language, Brain and 
Cognitive Development. Essays in Honor of Jacques Mehler,
Emmanuel Dupoux (ed.), 481-502. Cambridge, Mass.: MIT Press. 
Nicolas, S. 
 
2007 
La localisation cérébrale des facultés mentales. Psychologie 
Française 52: 267-277. 
Nunes, Jairo 
 
1999 
Linearization of Chains and Phonetic Realization of Chain Links. 
In Working Minimalism, Samuel Epstein and Norbert Hornstein 
(eds.), 217-249. Cambridge, MA: MIT Press. 
Odden, David 
 
1987 
Kimatuumbi phrasal phonology. Phonology 4: 13-26. 

762 
References 
Odden, David 
 
1990 
Syntax, lexical rules and postlexical rules in Kimatuumbi. In The 
Phonology-Syntax Connection, Sharon Inkelas and Draga Zec 
(eds.), 259-277. Chicago: University of Chicago Press. 
Odden, David 
 
1993 
Interaction between Modules in Lexical Phonology. In Studies in 
Lexical Phonology, Sharon Hargus and Ellen Kaisse (eds.), 111-
144. New York: Academic Press. 
Oh, Mira 
 
1995 
A prosodic analysis of nonderived-environment blocking. Journal 
of East Asian Linguistics 4: 261-279. 
Oostendorp, Marc van 
 
1994 
Affixation and integrity of syllable structure in Dutch. In 
Linguistics in the Netherlands 1994, Reineke Bok-Bennema and 
Crit Cremers (eds.), 151-162. Amsterdam: Benjamins. 
Oostendorp, Marc van 
 
1999 
Italian s-voicing and the structure of the phonological word. In 
Issues in phonological structure,
S.J. Hannahs and Mike 
Davenport (eds.), 195-212. Amsterdam: Benjamins. 
Oostendorp, Marc van 
 
2002 
The phonological and morphological status of the Prosodic Word 
Adjunct. Linguistische Berichte, Sonderheft 11: 209-235. 
Oostendorp, Marc van 
 
2004 
Crossing morpheme boundaries in Dutch. Lingua 114: 1367-1400. 
Oostendorp, Marc van 
 
2005 
The Theory of Faithfulness. Ms., Meertens Instituut. 
Oostendorp, Marc van 
 
2006a 
A theory of morphosyntactic colours. Ms., Meertens Instituut. 
Oostendorp, Marc van 
 
2006b 
Transparent Morphology causes Phonological Opacity. Paper 
presented at GLOW 29, Barcelona 5-8 April. 
Oostendorp, Marc van 
 
2007 
Derived Environment Effects and Consistency of Exponence. In 
Freedom of Analysis?, Sylvia Blaho, Patrick Bye and Martin 
Krämer (eds.), 123-148. Berlin: Mouton deGruyter. 
Oostendorp, Marc van, and Merle Horne (eds.) 
 
2005 
Boundaries in intonational phonology. Special issue of Studia 
Linguistica 59, issues 2-3. 
Orgun, Cemil Orhan 
 
1996a 
Sign-based morphology and phonology with special attention to 
Optimality Theory. Ph.D dissertation, University of California at 
Berkeley. 

References 763 
Orgun, Cemil Orhan 
 
1996b 
Sign-Based Morphology: a declarative theory of phonology-
morphology interleaving. Ms., University of San Diego. ROA 
#122 (abridged version published as Orgun 1999). 
Orgun, Cemil Orhan 
 
1998 
Cyclic and noncyclic phonological effects in a declarative gram-
mar. In Yearbook of Morphology 1987, Geert Booij and Jaap van 
Marle (eds.), 179-218. Amsterdam: Kluwer. 
Orgun, Cemil Orhan 
 
1999 
Sign-Based Morphology: A Declarative Theory of Phonology-
Morphology interleaving. In The Derivational Residue in Phono-
logical Optimality Theory, Ben Hermans and Marc van Oosten-
dorp (eds.), 247-268. Amsterdam: Benjamins. 
Orgun, Cemil Orhan, and Sharon Inkelas 
 
2002 
Reconsidering bracket erasure. In Yearbook of Morphology 2001,
Geert Booij and Jaap van Marle (eds.), 115-146. Dordrecht & 
London: Kluwer. 
Orr, Carolyn 
 
1962 
Ecuador Quichua phonology. In Studies in Ecuadorian Indian 
languages I, B. Elson (ed.), 60-77. Norman, Oklahoma: SIL. 
Pagliano, Claudine 
 
2003 
L'épenthèse consonantique en français. Ce que la syntaxe, la sé-
mantique et la morphologie peuvent faire à la phonologie. Ph.D 
dissertation, Université de Nice. 
Pak, Majorie 
 
2008 
The postsyntactic derivation and its phonological reflexes. Ph.D 
dissertation, University of Pennsylvania. 
Pater, Joe 
 
2000 
Nonuniformity in English stress: the role of ranked and lexically 
specific constraints. Phonology 17: 237-274. 
Pater, Joe 
 
2009 
Morpheme-specific phonology: constraint indexation and incon-
sistency resolution. In Phonological argumentation: essays on 
evidence and motivation, Steve Parker (ed.), 123-154. London: 
Equinox. 
Peperkamp, Sharon 
 
1995 
Prosodic constraints in the derivational morphology of Italian. 
Yearbook of Morphology 1994: 207-244. 
Peperkamp, Sharon 
 
1996 
On the prosodic representation of clitics. In Interfaces in Phono-
logy, Ursula Kleinhenz (ed.), 102-127. Berlin: Akademie Verlag. 
Peperkamp, Sharon 
 
1997 
Prosodic Words. The Hague: Holland Academic Graphics. 

764 
References 
Peretz, Isabelle 
 
2001 
The Biological Foundations of Music. In Language, Brain and 
Cognitive Development. Essays in Honor of Jacques Mehler,
Emmanuel Dupoux (ed.), 435-445. Cambridge, Mass.: MIT Press. 
Pesetsky, David 
 
1979 
Russian Morphology and Lexical Theory. Ms, MIT. Available at 
http://web.mit.edu/linguistics/www/pesetsky/russmorph.pdf. 
Pierrehumbert, Janet 
 
1980 
The phonology and phonetics of English intonation. Ph.D 
dissertation, MIT. 
Pierrehumbert, Janet 
 
2000 
Tonal Elements and their Alignment. In The interaction of 
constraints on prosodic phrasing. Prosody: Theory and 
Experiments, Merle Horne (ed.), 11-36. Dordrecht: Kluwer. 
Piggott, Glyne 
 
1999 
At the right edge of words. The Linguistic Review 16: 143±185. 
Piggott, Glyne 
 
2007 
Deriving word minimality by phase. Ms., McGill University. 
Piggott, Glyne, and Heather Newell 
 
2006 
Syllabification and the spell-out of phases in Ojibwa words. 
McGill Working Papers in Linguistics 20: 39-64. 
Pike, Kenneth 
 
1947 
Grammatical prerequisites to phonemic analysis. Word 3: 155-
172. 
Pike, Kenneth 
 
1952 
More on Grammatical Prerequisites. Word 8: 106-121. 
Pinker, Steven 
 
1997 
How the mind works. New York: Norton. 
Pinker, Steven, and Ray Jackendoff 
 
2005a 
The faculty of language: what's special about it ? Cognition 95: 
201-236. 
Pinker, Steven, and Ray Jackendoff 
 
2005b 
The nature of the language faculty and its implications for the 
evolution of language (Reply to Fitch, Hauser and Chomsky). 
Cognition 97: 211-225. 
Pinker, Steven, and Jacques Mehler (eds.) 
 
1988 
Connections and Symbols. Cambridge, Mass.: MIT Press. 
Plag, Ingo, and Harald Baayen 
 
2009 
Suffix ordering and morphological processing. Language 85: 109-
152. 
Plaut, David 
 
2003 
Connectionist Modeling of Language: Examples and Implications. 
In Mind, Brain and Language, M. Banich and M. Mack (eds.), 
143-167. Hillsdale: Erlbaum. 

References 765 
Ploch, Stefan 
 
1996 
The Role of Parsing. SOAS Working Papers in Linguistics and 
Phonetics 6: 76-105. 
Ploch, Stefan 
 
2003 
Can phonological 'nasality' be derived from phonetic nasality? In 
The Phonological Spectrum. Vol I: Segmental Structure, Harry 
van der Hulst, Vincent van Heuven and Jeroen van de Weijer 
(eds.), 73-116. Amsterdam & Philadelphia: Benjamins. 
Plotkin, Henry 
 
1998 
Evolution in mind. Cambridge, Mass.: Harvard University Press. 
Poeppel, David, and David Embick 
 
2005 
Defining the relation between linguistics and neuroscience. In 
Twenty-first century psycholinguistics: Four cornerstones, Anne 
Cutler (ed.), 103-118. Mahwah, NY: Erlbaum. 
Poeppel, David, and Gregory Hickok 
 
2004 
Towards a new functional anatomy of language. Cognition 92: 1-
12. 
Poeppel, David, William Idsardi, and Virginie van Wassenhove 
 
2008 
Speech perception at the interface of neurobiology and linguistics. 
Philosophical Transactions of the Royal Society 363: 1071-1086. 
Pollard, Carl, and Ivan Sag 
 
1994 
Head-Driven Phrase Structure Grammar. Chicago: CSLI & 
University of Chicago Press. 
Poser, William 
 
1986 
Diyari stress, metrical structure assignment and the nature of 
metrical representation. Proceedings of the West Coast 
Conference on Formal Linguistics 5: 178-191. 
Poser, William 
 
1989 
The metrical foot in Diyari. Phonology 6: 117-148. 
Poser, William 
 
1990 
Word-Internal Phrase Boundary in Japanese. In The Phonology-
Syntax Connection, Sharon Inkelas and Draga Zec (eds.), 279-
287. Chicago: University of Chicago Press. 
Posner, Michael 
 
1981 
Chronometric explorations of mind. Hillsdale: Erlbaum. 
Posner, Michael 
 
2001 
Cognitive Neuroscience: The Synthesis of Mind and Brain. In 
Language, Brain and Cognitive Development. Essays in Honor of 
Jacques Mehler, Emmanuel Dupoux (ed.), 403-416. Cambridge, 
Mass.: MIT Press. 
Potter, Simeon 
 
1962 
Syllabic Juncture. In Proceedings of the Fourth International 
Congress of Phonetic Sciences, Antti Sovijärvi and Pentti Aalto 
(eds.), 728-730. The Hague: Mouton. 

766 
References 
Prince, Alan 
 
1983 
Relating to the Grid. Linguistic Inquiry 14: 19-100. 
Prince, Alan 
 
1985 
Improving Tree Theory. In Proceedings of the 11th Annual 
Meeting of the Berkeley Linguistics Society, M. Niepokuj, M. van 
Clay, V. Nikiforidou and D. Feder (eds.), 471-490. Berkeley: 
University of California, Berkeley. 
Prince, Alan, and Paul Smolensky 
 
1993 
Optimality 
Theory. 
Constraint 
Interaction 
in 
Generative 
Grammar. Ms, Rutgers University, University of Colorado (ROA 
version August 2002). 
Prunet, Jean-François 
 
1986 
Spreading and Locality Domains in Phonology. Ph.D dissertation, 
McGill University at Montreal. 
Prunet, Jean-François 
 
1987 
Liaison and Nasalization in French. In Studies in Romance 
Languages, Carol Neidle and Rafael Nuñez Cedeño (eds.), 225-
235. Dordrecht: Foris. 
Pullum, Geoffrey, and Arnold Zwicky 
 
1988 
The syntax-phonology interface. In Linguistics: the Cambridge 
survey. Vol. I, Frederick Newmeyer (ed.), 255-280. Cambridge: 
Cambridge University Press. 
Pyle, Charles 
 
1972 
On Eliminating BM's. In Papers from the eighth regional meeting 
of the Chicago Linguistic Society, Paul Peranteau, Judith Levi and 
Gloria Phares (eds.), 516-532. Chicago: Chicago Linguistic 
Society. 
Pylyshyn, Zenon 
 
1984 
Computation and Cognition. Cambridge, Mass.: MIT Press. 
Pylyshyn, Zenon 
 
1989a 
On computation and cognition: Toward a foundation of cognitive 
science : A response to the reviews by A.K. Mackworth and M.J. 
Stefik. Artificial Intelligence 38: 248-251. 
Pylyshyn, Zenon 
 
1989b 
Computing in Cognitive Science. In Foundations of Cognitive 
Science, William Posner (ed.), 51-91. Cambridge, Mass.: MIT 
Press. 
Pylyshyn, Zenon 
 
1999 
What's in your Mind? In What is Cognitive Science?, Zenon 
Pylyshyn and Ernest Lepore (eds.), 1-25. Oxford: Blackwell. 
Pylyshyn, Zenon, and Ernest Lepore (eds.) 
 
1999 
What is Cognitive Science? Oxford: Blackwell. 

References 767 
Raffelsiefen, Renate 
 
1996 
Gaps in Word Formation. In Interfaces in Phonology, Ursula 
Kleinhenz (ed.), 194-209. Berlin: Akademie Verlag. 
Raimy, Eric 
 
2000a 
The phonology and morphology of reduplication. Berlin: Mouton 
de Gruyter. 
Raimy, Eric 
 
2000b 
Remarks on backcopying. Linguistic Inquiry 31: 541-552. 
Raimy, Eric 
 
2003 
Asymmetry and linearization in phonology. In Asymmetry in 
Grammar, Vol.2,
Anna Maria Di Sciullo (ed.), 129-146. 
Amsterdam: Benjamins. 
Reber, Paul, and Larry Squire 
 
1998 
Encapsulation of Implicit and Explicit Memory in Sequence 
Learning. Journal of Cognitive Neuroscience 10: 248-263. 
Reiss, Charles 
 
2000 
Optimality Theory from a cognitive science perspective. The 
Linguistic Review 17: 291-301. 
Reiss, Charles 
 
2008 
Modularity in the "sound" domain: implications for the purview 
of Universal Grammar. In The Oxford Handbook of Linguistic 
Interfaces, Gillian Ramchand and Charles Reiss (eds.), 53-79. 
Oxford: OUP. WEB. 
Reiss, Charles 
 
forth 
Intermodular explanation in cognitive science: An example from 
phonology. In Pylyshyn Papers, Don Dedrick and Lana Trick 
(eds.). Cambridge, Mass.: MIT Press. 
Revithiadou, Anthi 
 
2006 
Prosodic filters on syntax: an interface account of second position 
clitics. Lingua 116: 79-111. 
Rhodes, Richard 
 
1974 
Non-phonetic Environments in Natural Phonology. In Papers 
from the parasession on Natural Phonology, A. Bruck, R. Fox 
and M. La Galy (eds.), 285-296. Chicago: Chicago Linguistic 
Society. 
Rice, Keren 
 
1987 
On defining the intonational phrase: evidence from Slave. 
Phonology Yearbook 4: 37-59. 
Rice, Keren 
 
1990 
Predicting Rule Domains in the Phrasal Phonology. In The 
Phonology-Syntax Connection, Sharon Inkelas and Draga Zec 
(eds.), 289-312. Chicago: Chicago University Press. 

768 
References 
Rice, Keren 
 
1993 
A Reexamination of the Feature [Sonorant]: The Status of "Sono-
rant Obstruents". Language 69: 308-344. 
Richards, Marc 
 
2004 
Object Shift and Scrambling in North and West Germanic: a Case 
Study in Symmetrical Syntax. Ph.D dissertation, University of 
Cambridge. 
Richards, Marc 
 
2007a 
Dynamic Linearization and the Shape of Phases. Linguistic 
Analysis 33: 209-237. 
Richards, Marc 
 
2007b 
On Feature Inheritance: An Argument from the Phase 
Impenetrability Condition. Linguistic Inquiry 38: 563-572. 
Riemsdijk, Henk van 
 
1978 
A Case Study in Syntactic Markedness: Peter de Ridder. 
Rizzi, Luigi 
 
1990 
Relativized Minimality. Linguistic Inquiry Monograph 16.
Cambridge, Mass.: MIT Press. 
Rizzi, Luigi 
 
2005 
Phase theory and the privilege of the root. In Organizing 
Grammar. Studies in Honor of Henk van Riemsdijk, Hans 
Broekhuis, Norbert Corver, Riny Huybregts, Ursula Kleinhenz 
and Jan Koster (eds.), 529-537. Berlin: Mouton de Gruyter. 
Rizzi, Luigi, and Leonardo Savoia 
 
1993 
Conditions on /u/ propagation in Southern Italian dialects: a 
locality parameter for phonosyntactic processes. In Syntactic 
theory and the dialects of Italy, Adriana Belletti (ed.), 252-318. 
Torino: Rosenberg & Sellier. 
Roeper, Thomas 
 
2005 
Chomsky's Remarks and the Transformationalist Hypothesis. In 
Handbook of English Word-Formation, Rochelle Lieber and P. 
Stekauer (eds.), 125-146. Dordrecht: Kluwer. 
Romportl, Simeon 
 
1984 
Úloha rázu a jeho ekvivalentů při signalizování předĕlu. Slovo a 
slovesnost 45: 104-119. 
Rotenberg, Joel 
 
1978 
The Syntax of Phonology. Ph.D dissertation, MIT. 
Rubach, Jerzy 
 
1981 
Cyclic Phonology and Palatalization in Polish and English.
Warsaw: Wydawnictwa Universytetu Warszawskiego. 
Rubach, Jerzy 
 
1984 
Cyclic and Lexical Phonology: The Structure of Polish.
Dordrecht: Foris. 

References 769 
Rubach, Jerzy 
 
1985 
Lexical Phonology: lexical and postlexical derivations. Phonology 
Yearbook 2: 157-172. 
Rubach, Jerzy 
 
1986 
Abstract vowels in three dimensional phonology: the yers. The 
Linguistic Review 5: 247-280. WEB. 
Rubach, Jerzy 
 
1990 
Final Devoicing and Cyclic Syllabification in German. Linguistic 
Inquiry 21: 79-94. 
Rubach, Jerzy 
 
1993 
The Lexical Phonology of Slovak. Oxford: Clarendon Press. 
Rubach, Jerzy 
 
1996a 
Shortening and ambisyllabicity in English. Phonology 13: 197-
237. 
Rubach, Jerzy 
 
1996b 
Nonsyllabic analysis of voice assimilation in Polish. Linguistic 
Inquiry 27: 69-110. 
Rubach, Jerzy 
 
1997 
Extrasyllabic consonants in Polish: Derivational Optimality 
Theory. In Derivations and Constraints in Phonology, Iggy Roca 
(ed.), 551-581. Oxford: Clarendon. 
Rubach, Jerzy 
 
2000a 
Glide and Glottal Stop Insertion in Slavic Languages: A DOT 
Analysis. Linguistic Inquiry 31: 271-317. 
Rubach, Jerzy 
 
2000b 
Backness switch in Russian. Phonology 17: 39-64. 
Rubach, Jerzy 
 
2003 
Polish palatalization in derivational optimality theory. Lingua 
113: 197-237. 
Rubach, Jerzy, and Geert Booij 
 
1984 
Morphological and prosodic domains in Lexical Phonology. 
Phonology Yearbook 1: 1-27. 
Rubach, Jerzy, and Geert Booij 
 
1987 
Postcyclic versus postlexical rules in Lexical Phonology. 
Linguistic Inquiry 18: 1-44. 
Rubach, Jerzy, and Geert Booij 
 
1990 
Edge of constituent effects in Polish. Natural Language and 
Linguistic Theory 8: 427-463. 
Rubach, Jerzy, and Geert Booij 
 
2003 
Lexical Phonology - Overview. In International Encyclopedia of 
Linguistics, William Frawley (ed.), 443-447. Second edition 
Oxford: Oxford University Press. 

770 
References 
Rucart, Pierre 
 
2006 
Morphologie gabaritique et interface phonosyntaxique. Aspects de 
la morphologie verbale en afar. Ph.D dissertation, Université Paris 
7. 
Rumelhart, David 
 
1989 
The Architecture of Mind: A Connectionist Approach. In 
Foundations of Cognitive Science, Michael Posner (ed.), 133-159. 
Cambridge, Mass.: MIT Press. 
Rumelhart, David E., James L. McClelland, and the PDP Research Group (eds.) 
 
1986 
Parallel Distributed Processing: Exploration in the Micro-
Structure of Cognition. 2 vols. Cambridge, Mass.: MIT Press. 
Russell, Kevin 
 
1997 
Optimality Theory and Morphology. In Optimality Theory. An 
overview, Diana Archangeli and D. Langendoen (eds.), 102-133. 
Oxford: Blackwell. 
Russell, Kevin 
 
1999 
MOT: sketch of an OT approach to morphology. Ms., University 
of Manitoba. 
Sabbatini, Renato 
 
1997 
Phrenology: the History of Brain Localization. Brain & Mind 1: 
[electronic resource: www.cerebromente.org.br/n01/index_i.htm]. 
Sag, Ivan 
 
1974 
The Grassmann's Law Ordering Pseudoparadox. Linguistic 
Inquiry 5: 591-607. 
Saltarelli, Mario 
 
1970 
A Phonology of Italian in a Generative Grammar. The Hague: 
Mouton. 
Samuels, Bridget 
 
2009a 
The structure of phonological theory. Ph.D dissertation, Harvard 
University. 
Samuels, Bridget 
 
2009b 
The third factor in phonology. Biolinguistics 3: 355-382. 
Samuels, Bridget 
 
forth 
The topology of infixation and reduplication. The Linguistic 
Review 27. 
Samuels, Richard, Stephen Stich, and Patrice Tremoulet 
 
1999 
Rethinking Rationality: From Bleak Implications to Darwinian 
Modules. In What is Cognitive Science?, Zenon Pylyshyn and 
Ernest Lepore (eds.), 74-120. Oxford: Blackwell. 
Sandalo, Filomena, and Hubert Truckenbrodt 
 
2002 
Some notes on phonological phrasing in Brazilian Portuguese. 
MIT Working Papers in Linguistics 42: 285-310. 

References 771 
Sauerland, Uli 
 
1998 
Scope reconstruction without reconstruction. In Proceedings of 
WCCFL 17, K. Shahin, S. Blake and E. Kim (eds.), 582-596. 
Stanford: Center for the Study of Language and Information. 
Sauerland, Uli, and Paul Elbourne 
 
2002 
Total Reconstruction, PF Movement, and Derivational Order. 
Linguistic Inquiry 33: 283-319. 
Schane, Sanford 
 
1984 
The fundamentals of particle phonology. Phonology Yearbook 1: 
129-155. 
Scheer, Tobias 
 
2001 
The Rhythmic Law in Czech: Vowel-final Prefixes. In Current 
Issues in Formal Slavic Linguistics, Gerhild Zybatow, Uwe 
Junghans, Grit Mehlhorn and Luka Szucsich (eds.), 37-48. 
Frankfurt am Main: Lang. WEB. 
Scheer, Tobias 
 
2003a 
The Key to Czech Vowel Length: Templates. In Investigations 
into Formal Slavic Linguistics, Petr Kosta, Joanna Blaszczak, Jens 
Frasek, Ljudmila Geist and Marzena Żygis (eds.), 97-118. 
Frankfurt am Main: Lang. WEB. 
Scheer, Tobias 
 
2003b 
Structure and Process: Computation is not King. Paper presented 
at the conference From representations to constraints and from 
constraints to representations, Toulouse 9-11 July 2003. 
Scheer, Tobias 
 
2004a 
A Lateral Theory of Phonology. Vol.1: What is CVCV, and why 
should it be? Berlin: Mouton de Gruyter. 
Scheer, Tobias 
 
2004b 
En quoi la phonologie est vraiment différente. Corpus 3: 5-84. 
WEB. 
Scheer, Tobias 
 
2004c 
O samohláskové délce při derivaci v čeãtinĕ. In Čeãtina - 
univerzália a specifika 5, Zdeňka Hladká and Petr Karlík (eds.), 
224-239. Praha: Lidové noviny. WEB. 
Scheer, Tobias 
 
2005 
We need a translator's office, but the buffer has to go: Direct 
Interface. Paper presented at the 36th Poznań Linguistic Meeting, 
Poznań 22-24 April. 
Scheer, Tobias 
 
2006a 
Interface Dualism. Paper presented at the 37th Poznań Linguistic 
Meeting, Poznań 20-23 April. 

772 
References 
Scheer, Tobias 
 
2006b 
The balance of representation and computation at the Interface. 
Paper presented at the 14th Manchester Phonology Meeting, 
Manchester 25-27 May. 
Scheer, Tobias 
 
2007 
On the Status of Word-Initial Clusters in Slavic (And Elsewhere). 
In Annual Workshop on Formal Approaches to Slavic Linguistics. 
The Toronto Meeting 2006,
Richard Compton, Magdalena 
Goledzinowska and Ulyana Savchenko (eds.), 346-364. Ann 
Arbor: Michigan Slavic Publications. WEB. 
Scheer, Tobias 
 
2008a 
Why the Prosodic Hierarchy is a diacritic and why the Interface 
must be Direct. In Sounds of Silence: Empty Elements in Syntax 
and Phonology, Jutta Hartmann, Veronika Hegedüs and Henk van 
Riemsdijk (eds.), 145-192. Amsterdam: Elsevier. WEB. 
Scheer, Tobias 
 
2008b 
Syllabic and Trapped Consonants in (Western) Slavic: the Same 
but yet Different. In Formal Description of Slavic Languages: 
The Fifth Conference, Leipzig 2003, Gerhild Zybatow, Luka 
Szucsich, Uwe Junghanns and Roland Meyer (eds.), 149-167. 
Frankfurt am Main: Lang. WEB. 
Scheer, Tobias 
 
2008c 
Spell out your Sister! In Proceedings of the 27th West Coast 
Conference on Formal Linguistics, Natasha Abner and Jason 
Bishop (eds.), 379-387. Somerville: Cascadilla. WEB. 
Scheer, Tobias 
 
2009a 
External sandhi: what the initial CV is initial of. Studi e Saggi 
Linguistici 47: 43-82. WEB. 
Scheer, Tobias 
 
2009b 
Intermodular Argumentation and the Word-Spell-Out-Mystery. In 
Explorations of Phase Theory: Interpretation at the Interfaces,
Kleanthes Grohmann (ed.), 23-65. Berlin: Mouton de Gruyter. 
WEB. 
Scheer, Tobias 
 
2009c 
Representational and procedural sandhi killers: diagnostics, 
distribution, behaviour. In Czech in Formal Grammar, Mojmír 
Dočekal and Markéta Ziková (eds.), 155-174. München: Lincom. 
WEB. 
Scheer, Tobias 
 
2009d 
Syllabic and trapped consonants in the light of branching onsets 
and licensing scales. In Studies in Formal Slavic Phonology, 
Morphology, Syntax, Semantics and Information Structure,
Gerhild Zybatow, Uwe Junghanns, Denisa Lenertová and Petr 
Biskup (eds.), 411-426. Frankfurt am Main: Lang. WEB. 

References 773 
Scheer, Tobias 
 
2010a 
What OT is, and what it is not. Review of The Cambridge 
Handbook of Phonology, ed. by Paul de Lacy. Journal of 
Linguistics 46: 193-218. WEB. 
Scheer, Tobias 
 
2010b 
Intermodular argumentation: morpheme-specific phonologies are 
out of business in a phase-based architecture. In The Sound 
Pattern of Syntax, Nomi Shir and Lisa Rochman (eds.), 333-351. 
Oxford: OUP. 
Scheer, Tobias 
 
2010c 
Review of Gussmann (2007) The Phonology of Polish. Studies in 
Polish Linguistics 5: 109-158. 
Scheer, Tobias 
 
forth 
Aspects of the development of generative phonology. In The 
Continuum Companion to Phonology, Bert Botma, Nancy Kula 
and Kuniya Nasukawa (eds.). London: Continuum. 
Scheer, Tobias, and Markéta Ziková 
 
forth 
The Coda Mirror v2. Acta Linguistica Hungarica.
Schwartz, Jean-Luc, Christian Abry, Louis-Jean Boë, and Marie Cathiard 
 
2002 
Phonology in a Theory of Perception-for-Action-Control. In 
Phonetics, Phonology and Cognition, Jacques Durand and 
Bernard Laks (eds.), 254-280. Oxford: Oxford University Press. 
Scobbie, James 
 
1991 
Towards Declarative Phonology. Edinburgh Working Papers in 
Cognitive Science 7: 1-26. 
Scobbie, James, John Coleman, and Steven Bird 
 
1996 
Key aspects of declarative phonology. In Current Trends in 
Phonology: Models and Methods. Vol.2, Jacques Durand and 
Bernard Laks (eds.), 685-709. Salford, Manchester: ESRI. 
Segal, Gabriel 
 
1996 
The modularity of theory of mind. In Theories of Theories of 
Mind, P. Carruthers and P. Smith (eds.). Cambridge: CUP. 
Ségéral, Philippe, and Tobias Scheer 
 
2001 
La Coda-Miroir. Bulletin de la Société de Linguistique de Paris 
96: 107-152. WEB. 
Ségéral, Philippe, and Tobias Scheer 
 
2005 
What lenition and fortition tells us about Gallo-Romance Muta 
cum Liquida. In Romance Languages and Linguistic Theory 2003,
Twan Geerts, Ivo van Ginneken and Haike Jacobs (eds.), 235-267. 
Amsterdam: Benjamins. WEB. 

774 
References 
Ségéral, Philippe, and Tobias Scheer 
 
2007 
Le statut syllabique multiple des séquences muta cum liquida : 
l'exemple du gallo-roman. In Etudes sur le changement linguisti-
que en français, Bernard Combettes, Christiane Marchello-Nizia 
and Sophie Prévost (eds.), 261-282. Nancy: Presses Universitaires 
de Nancy. WEB. 
Ségéral, Philippe, and Tobias Scheer 
 
2008 
The Coda Mirror, stress and positional parameters. In Lenition 
and Fortition, Joaquim Brandão de Carvalho, Tobias Scheer and 
Philippe Ségéral (eds.), 483-518. Berlin: Mouton de Gruyter. 
WEB. 
Seidl, Amanda 
 
2001 
Minimal Indirect Reference: a theory of the syntax-phonology 
interface. London: Routledge. 
Selkirk, Elisabeth 
 
1972 
The phrase phonology of English and French. Ph.D. dissertation 
MIT, published 1980 by Garland Press. 
Selkirk, Elisabeth 
 
1974 
French liaison and the X-bar notation. Linguistic Inquiry 5: 573-
590. 
Selkirk, Elisabeth 
 
1978 
The French foot: on the status of "mute" e. Studies in French 
Linguistics 1: 141-150. 
Selkirk, Elisabeth 
 
1980a 
Prosodic Domains in Phonology: Sanskrit Revisited. In Juncture,
Mark Aronoff and Mary-Louise Kean (eds.), 107-129. Saratoga: 
Anma Libri. 
Selkirk, Elisabeth 
 
1980b 
The Role of Prosodic Categories in English Word Stress. 
Linguistic Inquiry 11: 563-605. 
Selkirk, Elisabeth 
 
1981 
On the nature of phonological representation. In The cognitive 
representation of speech, J. Anderson, J. Laver and T. Meyers 
(eds.), 379-388. Amsterdam: North Holland. 
Selkirk, Elisabeth 
 
1981 [1978] On prosodic structure and its relation to syntactic structure. In 
Nordic Prosody II, Thorstein Fretheim (ed.), 111-140. Trondheim: 
TAPIR. 
Selkirk, Elisabeth 
 
1984 
Phonology and Syntax: The Relation between Sound and 
Structure. Cambridge, Mass.: MIT Press. 
Selkirk, Elisabeth 
 
1986 
On derived domains in sentence phonology. Phonology 3: 371-
405. 

References 775 
Selkirk, Elisabeth 
 
1996 
The prosodic structure of function words. In Signal to syntax: 
bootstrapping from syntax to grammar in early acquisition, James 
Morgan and Katherine Demuth (eds.), 187-213. Mahwah, NJ: 
Erlbaum. 
Selkirk, Elisabeth 
 
2000 
The interaction of constraints on prosodic phrasing. In Prosody: 
Theory and Experiments, Merle Horne (ed.), 231-261. Dordrecht: 
Kluwer. 
Selkirk, Elisabeth 
 
2001 
Phonological weight in sentence grammar: reexamining heavy 
noun phrase shift. Paper presented at the Workshop on prosody in 
processing, Utrecht 5-6 July. 
Selkirk, Elisabeth 
 
2007 
Focus prominence drives focus phrasing: Bengali intonation 
revisited. In Topic and focus: a cross-linguistic perspective,
Chung-min Lee, Matthew Gordon and Daniel Büring (eds.), 217-
246. Dordrecht: Kluwer. 
Selkirk, Elisabeth 
 
2008 
Contrastive focus, givenness and the unmarked status of 
"discourse-new´. Acta Linguistica Hungarica 55: 331-346. 
Selkirk, Elisabeth, and Tong Shen 
 
1990 
Prosodic domains in Shanghai Chinese. In The Phonology-Syntax 
Connection, Sharon Inkelas and Draga Zec (eds.), 313-337. 
Chicago: University of Chicago Press. 
Selkirk, Elisabeth, and Koichi Tateishi 
 
1988 
Minor phrase formation in Japanese. Papers from the Annual 
Regional Meeting of the Chicago Linguistic Society 24: 316-336. 
Shallice, Tim 
 
1988 
From neuropsychology to mental structure. Cambridge: CUP. 
Siegel, Dorothy 
 
1974 
Topics in English Morphology. Ph.D. dissertation, MIT. 
Siegel, Dorothy 
 
1980 
Why there is no = Boundary. In Juncture, Mark Aronoff and 
Mary-Louise Kean (eds.), 131-134. Saratoga: Anma Libri. 
Simon, Herbert, and Craig Kaplan 
 
1989 
Foundations of Cognitive Science. In Foundations of Cognitive 
Science, Michael Posner (ed.), 1-47. Cambridge, Mass.: MIT 
Press. 
Smith, Jennifer 
 
1997 
Noun faithfulness: On the privileged behavior of nouns in 
phonology. Ms., University of Massachusetts, Amherst. ROA 
#242. 

776 
References 
Smith, Jennifer 
 
1999 
Noun faithfulness and accent in Fukuoka Japanese. In Proceed-
ings of WCCFL 18, Sonya Bird, Andrew Carnie, Jason Haugen 
and Peter Norquest (eds.), 519-531. Somerville, MA: Cascadilla. 
Smith, Jennifer 
 
2001 
Lexical category and phonological contrast. In Papers in 
Experimental and Theoretical Linguistics 6: Workshop on the 
Lexicon in Phonetics and Phonology, Robert Kirchner, Joe Pater 
and Wolf Wikely (eds.), 61-72. Edmonton: University of Alberta. 
ROA #728. 
Smith, Neil 
 
1998 
Dissociations. Glot International 3.9: 9. 
Smith, Neil 
 
2002 
Modules, modals, maths and the mind. Glot International 6.8: 
248-250. 
Smith, Neil 
 
2003 
Dissociation and modularity: Reflections on language and mind. 
In Mind, Brain and Language, M. Banich and M. Mack (eds.), 87-
111. Hillsdale: Erlbaum. 
Smith, Neil, and Ianthi-Maria Tsimpli 
 
1991 
Linguistic Modularity? A case study of a "savant" linguist. Lingua 
84: 315-351. 
Smith, Neil, and Ianthi-Maria Tsimpli 
 
1995 
The mind of a savant. Language-learning and modularity.
Oxford: Blackwell. 
Smith, Neil, and Ianthi-Maria Tsimpli 
 
1999 
Modules and quasi-modules: Language and Theory of Mind in a 
Polyglot Savant. Learning and Individual Differences 10: 193-
215. 
Smolensky, Paul 
 
1987 
Connectionist AI, symbolic AI, and the brain. Artificial 
Intelligence Review 1: 95-109. 
Smolensky, Paul 
 
1988a 
On the proper treatment of connectionism. Brain and Behavioural 
Sciences 11: 1-74. 
Smolensky, Paul 
 
1988b 
Putting Together Connectionism ± again. Behavioral and Brain 
Sciences 11: 59-74. 
Smolensky, Paul 
 
1991 
Connectionism, constituency and the language of thought. In 
Meaning in Mind: Fodor and his critics, B. Loewer and G. Rey 
(eds.), 201-227. Oxford: Blackwell. 

References 777 
Smolensky, Paul 
 
2003 
Connectionism. In International Encyclopedia of Linguistics,
William Frawley (ed.), 383-386. Oxford: OUP. 
Smolensky, Paul, and Geraldine Legendre 
 
2006 
The Harmonic Mind. From Neural Computation to Optimality-
Theoretic Grammar, 2 Vols. Cambridge, Mass.: MIT Press. 
Sperber, Dan 
 
1994 
The 
modularity 
of 
thought 
and 
the 
epidemiology 
of 
representations. In Mapping the mind: Domain specificity in 
cognition and culture, L.A. Hirschfeld and S.A. Gelman (eds.), 
39-67. Cambridge: CUP. 
Sperber, Dan 
 
2001 
In Defense of Massive Modularity. In Language, Brain and 
Cognitive Development,
Emmanuel Dupoux (ed.), 47-57. 
Cambridge, Mass.: MIT Press. 
Sproat, Richard 
 
1985 
On deriving the lexicon. Ph.D dissertation, MIT. 
Sproat, Richard 
 
1992 
Morphology and Computation. Cambridge, MA: MIT Press. 
Sprouse, Ronald 
 
1997 
A case for enriched inputs. Ms., University of California at 
Berkeley. 
Squire, Larry 
 
1987 
Memory and brain. New York: OUP. 
Stampe, David 
 
1972 
How I Spent my Summer Vacation. Ph.D dissertation, University 
of Chicago. Reproduced by the Indiana Linguistics Club in 1979. 
Stanley, Richard 
 
1969 
The Phonology of the Navaho Verb. Ph.D dissertation, MIT. 
Stanley, Richard 
 
1973 
Boundaries in phonology. In A Festschrift for Morris Halle,
Stephen Anderson and Paul Kiparsky (eds.), 185-206. New York: 
Holt, Rinehart & Winston. 
Starke, Michal 
 
2004 
On the inexistence of specifiers and the nature of heads. In 
Structures and Beyond. The Cartography of Syntactic Structures, 
Volume 3, Adriana Belletti (ed.), 252-268. Oxford: OUP. 
Stepanov, A. 
 
2001 
Late Adjunction and Minimalist Phrase Structure. Syntax 4: 94-
125. 
Steriade, Donca 
 
1982 
Greek Prosodies and the Nature of Syllabification. Ph.D 
dissertation, MIT. 

778 
References 
Steriade, Donca 
 
1984 
Glides and vowels in Romanian. In Proceedings of the 10th 
Annual Meeting of the Berkeley Linguistics Society, C. Brugman 
and M. Macaulay (eds.), 47-64. Berkeley: University of Berkeley. 
Steriade, Donca 
 
1987 
Redundant Values. In Papers from the 23rd Annual Regional 
Meeting of the Chicago Linguistic Society. Vol II, Parasession on 
Autosegmental and Metrical Phonology, Anna Bosch, Barbara 
Need and Eric Schiller (eds.), 339-362. Chicago: Chicago 
Linguistic Society. 
Steriade, Donca 
 
1988 
Greek Accent: A Case for Preserving Structure. Linguistic Inquiry 
19: 271-314. 
Stevens, Alan 
 
1980 
Formative Boundary in Phonological Rules. In Juncture, Mark 
Aronoff and Mary-Louise Kean (eds.), 135-141. Saratoga: Anma 
Libri. 
Stevenson, Suzanne 
 
1999 
Bridging the Symbolic- Connectionist Gap in Language. In What 
is Cognitive Science, Ernest Lepore and Zenon Pylyshyn (eds.), 
336-355. Oxford: Blackwell. 
Stich, Stephen 
 
1972 
Grammar, Psychology and Indeterminacy. Journal of Philosophy 
69: 799-818. 
Stillings, Neil, Steven Weisler, Christopher Chase, Mark Feinstein, Jay Garfield, 
and Edwina Rissland 
 
1995 
Cognitive Science. An Introduction. Cambridge, Mass.: MIT 
Press. 
Stockwell, Robert, Donald Bowen, and I. Silva-Fuenzalida 
 
1956 
Spanish juncture and intonation. Language 32: 641-665. 
Strauss, Steven 
 
1979 
Against Boundary Distinctions in English Morphology. Linguistic 
Analysis 5: 387-419. 
Strycharczuk, Patrycja 
 
2010 
Phonetics, phonolgoy and Poznań /d/-voicing. In the Workshop on 
Positional phenomena in phonology and phonetics at GLOW 33.
Wrocław. 
Svenonius, Peter 
 
2001 
On object shift, scrambling and the PIC. MIT Working Papers in 
Linguistics 39: 267-289. 
Svenonius, Peter 
 
2004 
On the edge. In Peripheries: syntactic edges and their effects,
David Adger, Cécile de Cat and Georges Tsoulas (eds.), 259-287. 
Dordrecht: Kluwer. 

References 779 
Szendrői, Kriszta 
 
2001 
Focus and the Syntax-Phonology Interface. Ph.D dissertation, 
University College London. 
Szendrői, Kriszta 
 
2003 
A stress-based approach to the syntax of Hungarian focus. The 
Linguistic Review 20: 37-78. 
Szendrői, Kriszta 
 
2004 
A stress-based approach to climbing. In Verb clusters. A study of 
Hungarian, German and Dutch, Katalin É.Kiss and Henk van 
Riemsdijk (eds.), 205-233. Amsterdam: Benjamins. 
Szigetvári, Péter, and Tobias Scheer 
 
2005 
Unified representations for the syllable and stress. Phonology 22: 
37-75. 
Szpyra, Jolanta 
 
1987 
Inputs to WFRs - phonological, intermediate or phonetic ? The 
case of verbs and deverbal nouns in Polish. In Rules and the 
Lexicon, Edmund Gussmann (ed.), 169-203. Lublin: Katolicki 
Universytet Lubelski. 
Szpyra, Jolanta 
 
1989 
The Phonology - Morphology Interface. London & New York: 
Routledge. 
Szymanek, Bogdan 
 
1980 
Phonological conditioning of word formation rules. Folia 
Linguistica 14: 413-425. 
Tager-Flusberg, Helen, and Kate Sullivan 
 
2000 
A componential view of theory of mind: evidence from Williams 
syndrome. Cognition 76: 59-89. 
Takahashi, Toyomi 
 
1993 
A farewell to constituency. UCL Working Papers in Linguistics 5: 
375-410. 
Taylor, John 
 
2002 
Cognitive Grammar. Oxford: Oxford University Press. 
Thagard, Paul 
 
2005 
Mind. Introduction to Cognitive Science. Cambridge, Mass.: MIT 
Press. 
Trager, George 
 
1962 
Some Thoughts on 'Juncture'. Studies in Linguistics 16: 11-22. 
Trager, George 
 
1972 
Language and Languages. San Francisco: Chandler. 
Trager, George, and Bernard Bloch 
 
1941 
The syllabic phonemes of English. Language 17: 223-246. 
Trevian, Ives 
 
2007 
Stress-neutral endings in contemporary British English: an 
updated overview. Language Sciences 29: 426-450. 

780 
References 
Trnka, Bohumil 
 
1940 
Slovné a mezislovné signály v angličtinĕ, francouzãtinĕ a čeãtinĕ.
Listy Filologické 67: 223-232. 
Trubetzkoy, Nikolai Sergeyevich 
 
1935 
Anleitung zu phonologischen Beschreibungen. Brno: Edition du 
Cercle Linguistique de Prague. 
Trubetzkoy, Nikolai Sergeyevich 
 
1936 
Die phonologischen Grenzsignale. In Proceedings of the Second 
International Congress of Phonetic Sciences, Daniel Jones and D. 
B. Fry (eds.), 45-49. Cambridge: Cambridge University Press. 
Trubetzkoy, Nikolai Sergeyevich 
 
1939 
Grundzüge der Phonologie.
6th edition 1977, Göttingen: 
Vandenhoeck & Ruprecht. 
Truckenbrodt, Hubert 
 
1995 
Phonological phrases: their relation to syntax, focus and 
prominence. Ph.D dissertation, MIT. 
Truckenbrodt, Hubert 
 
1999 
On the Relation between Syntactic Phrases and Phonological 
Phrases. Linguistic Inquiry 30: 219-255. 
Truckenbrodt, Hubert 
 
2007 
The syntax-phonology interface. In The Cambridge Handbook of 
Phonology, Paul de Lacy (ed.), 435-456. Cambridge: CUP. 
Uriagereka, Juan 
 
1999 
Multiple spell-out. In Working Minimalism, Samuel Epstein and 
Norbert Hornstein (eds.), 251-282. Cambridge, Mass.: MIT Press. 
Vachek, Josef 
 
1970 
Some remarks on "juncture" in phonological analysis. In 
Proceedings of the sixth International Congress of Phonetic 
Sciences, Bohuslav Hála, Milan Romportl and Přemysl Janota 
(eds.), 963-965. Prague: Academia. 
van Wyhe, John 
 
2004 
Phrenology and the Origins of Victorian Scientific Naturalism.
London: Ashgate. 
van Wyhe, John 
 
[no year] 
Phrenology: 
An 
Overview. 
The 
Victorian 
Web 
[www.victorianweb.org/science/phrenology/phrenologyov.html], 
June 2010. 
Vennemann, Theo 
 
1974 
Words and syllables in natural generative grammar. In Papers 
from the parasession on Natural Phonology, A.Bruck, R.Fox and 
M.La Galy (eds.), 346-374. Chicago: Chicago Linguistic Society. 

References 781 
Vennemann, Theo 
 
1976 [1971] Vowel alternations in English, German and Gothic: remarks on 
realism in phonology. In Linguistic and Literary Studies in Honor 
of Archibald A. Hill, vol. I: General and Theoretical Linguistics,
Muhammad Ali Jazayery, Edgar C. Polomé and Werner Winter 
(eds.), 337-359. Lisse: de Ridder. 
Vogel, Irene 
 
1982 
La sillaba come unità fonologica. Bologna: Zanichelli. 
Vogel, Irene 
 
1985 
On constraining prosodic rules. In Advances in nonlinear phonol-
ogy, Harry van der Hulst and Norval Smith (eds.), 217-233. 
Dordrecht: Foris. 
Vogel, Irene 
 
1986 
External sandhi rules operating between sentences. In Sandhi 
Phenomena in the Languages of Europe, Henning Andersen (ed.), 
55-64. Berlin: Mouton de Gruyter. 
Vogel, Irene 
 
1988 
Prosodic constituents in Hungarian. In Certamen Phonologicum,
Pier Marco Bertinetto and Michele Loporcaro (eds.), 231-250. 
Torino: Rosenberg & Sellier. 
Vogel, Irene 
 
1990 
The clitic group in Prosodic Phonology. In Grammar in Progress. 
Glow essays for Henk van Riemsdijk, Joan Mascaró and Marina 
Nespor (eds.), 447-454. Dordrecht: Foris. 
Vogel, Irene 
 
1991 
Level ordering in Italian Lexical Phonology? In Certamen 
Phonologicum II, Pier Marco Bertinetto, Michael Kenstowicz and 
Michele Loporcaro (eds.), 81-101. Torino: Sellier & Rosenberg. 
Vogel, Irene 
 
1999 
Subminimal constituents in prosodic phonology. In Issues in pho-
nological structure, Stephen Hannahs and Mike Davenport (eds.), 
249-267. Amsterdam: Benjamins. 
Vogel, Irene, and István Kenesei 
 
1987 
The interface between phonology and other components of 
grammar: the case of Hungarian. Phonology Yearbook 4: 243-
263. 
Vogel, Irene, and István Kenesei 
 
1990 
Syntax and semantics in phonology. In The Phonology-Syntax 
Connection, Sharon Inkelas and Draga Zec (eds.), 339-363. Chi-
cago: University of Chicago Press. 
Wagner, Michael 
 
2005a 
Prosody and Recursion. PhD. dissertation, MIT. 

782 
References 
Wagner, Michael 
 
2005b 
Long-distance effects on prosody. Paper presented at CUNY 
sentence processing, University of Arizona 21 March - 2 April. 
Watson, Duane, and Edward Gibson 
 
2004 
The relationship between intonational phrasing and syntactic 
structure in language production. Language and Cognitive Proc-
esses 19: 713-755. 
Watson, Duane, and Edward Gibson 
 
2005 
 Intonational phrasing and constituency in language production 
and comprehension. Studia Linguistica 59: 279-. 
Wauquier, Sophie 
 
2005 
Statut des représentations phonologiques en acquisition, traite-
ment de la parole continue et dysphasie développementale. Habili-
tation thesis, EHESS Paris. 
Wells, Rulon S. 
 
1947 
Immediate Constituents. Language 23: 81-117. 
Wells, Rulon S. 
 
1949 
Automatic alternations. Language 25: 99-116. 
Welmers, W. E. 
 
1947 
Hints from morphology for phonemic analysis. Studies in Linguis-
tics 5: 91-100. 
Wexler, Kenneth, and Peter Culicover 
 
1980 
Formal Principles of Language Acquisition. Cambridge, MA.: 
MIT Press. 
Wheeler, M. W. 
 
1986 
Catalan sandhi phenomena. In Sandhi phenomena in the lan-
guages of Europe, Henning Andersen (ed.), 475-488. Berlin: 
Mouton de Gruyter. 
Wilkinson, Robert W. 
 
1974 
Tense/Lax vowel harmony in Telugu: the influence of derived 
contrast on rule application. Linguistic Inquiry 5: 251-270. 
Williams, Edwin 
 
1981 
On the notions "Lexically Related" and "Head of a Word". Lin-
guistic Inquiry 12: 245-274. 
Williams, Edwin 
 
2003 
Representation Theory. Cambridge, Mass.: MIT Press. 
Williams, Edwin 
 
2007 
Dumping Lexicalism. In The Oxford Handbook of Linguistic 
Interfaces, Gillian Ramchand and Charles Reiss (eds.), 353-381. 
Oxford: OUP. 
Wilson, Colin 
 
2000 
Targeted constraints: an approach to to contextual neutralization 
in Optimality Theory. Ph.D dissertation, Johns Hopkins Univer-
sity at Baltimore. 

References 783 
Wilson, Colin 
 
2001 
Consonant cluster neutralization and targeted constraints. Phonol-
ogy 18: 147-197. 
Wolf, Matthew 
 
2008 
Optimal Interleaving: Serial Phonology-Morphology Interaction 
in a Constraint-Based Model. Ph.D dissertation, University of 
Massachusetts. 
Yip, Moira 
 
1998 
Identity Avoidance in Phonology and Morphology. In Morphol-
ogy and its Relation to Phonology and Syntax, Steven Lapointe, 
Diane Brentari and Patrick Farrell (eds.), 216-246. Stanford: CSLI 
Publications. 
Yu, Alan 
 
2000 
Stress assignment in Tohono O'odham. Phonology 17: 117-135. 
Zec, Draga 
 
1988 
Sonority constraints on prosodic structure. Ph.D dissertation, 
Stanford University. 
Zec, Draga 
 
1993 
Rule domains and phonological change. In Studies in Lexical 
Phonology, Sharon Hargus and Ellen Kaisse (eds.), 365-405. New 
York: Academic Press. 
Ziková, Markéta 
 
2008 
Alternace e-nula v současné čeãtině. Autosegmentální laterální 
analýza. Ph.D dissertation, Masarykova univerzita v Brně.
Zuraw, Kie 
 
2007 
The Role of Phonetic Knowledge in Phonological Patterning: 
Corpus and Survey Evidence from Tagalog Infixation. Language 
83: 277-316. 
Zwicky, Arnold, and Geoffrey Pullum 
 
1986a 
The Principle of Phonology-free Syntax: introductory remarks. 
Ohio State University Working Papers in Linguistics 32: 63-91. 
Zwicky, Arnold, and Geoffrey Pullum 
 
1986b 
Two spurious counterexamples to the Principle of Phonology-Free 
Syntax. Ohio State University Working Papers in Linguistics 32: 
92-99. 
 


864 
Subject index 
 
± this index refers to paragraphs §, that is the running number in the page 
margins. 
± reference to a § that identifies the beginning of a chapter or a section 
refers to this chapter or section and to all of its sub-sections.
± cross-reference to other entries of the subject index are introduced by 
"→": look up here. 
± cross-reference to a sub-entry of the subject index uses the structure of 
computer files: the sub-entry "anti-cyclicity" of the entry "Optimality 
Theory" identifies as "→Optimality Theory/ anti-cyclicity ". 
± boldfaced § numbers indicate that the subject is most prominently stud-
ied there. 
± reference to footnotes is made by indicating their number, but also by 
mentioning the number of the § in which they occur: "note 258 (415)" 
refers to footnote 258 which occurs in §415. 
 
A
absolute neutralisation 184 
abstractness debate 
 
absolute neutralisation (SPE: nightin-
gale) 184 
 
and derived environment effects 184 
 
and Lexical Phonology 144 
 
conditions on the relationship between 
underlying and surface forms 184
electri[k] vs. electri[s]ity etc. 570 
 
free ride (SPE: Pamela) 184 
acquisition 
 
and lexical access (Kaye 1995) 358 
activation value of a neuron 
 
neural network 595 
active →memory 
addressing space 
 
lexical access (Kaye 1995) 350 
adjuncts, morphological 
 
Kaye (1995): independent spell-out of 
terminal 318 
affix class-based phenomena 
 
testing ground for theories of the inter-
face: summary of the English fact 
311 
 
are independent from derived envi-
ronment effect 838 
 
organisation of →underapplication 
 
comparison Lexical Phonology, 
Halle & Vergnaud, Kay 303 
 
analysis in Lexical Phonology: strata, 
level orderin 147, 150, 163, 166 
analysis by Fabb (1988) and Hay 
(2002): selectional properties of af-
fixes, perception, parsing 247 
 
analysis by Halle & Vergnaud (1987a)
248 
 
analysis by Kaye (1995) with no look-
back 279, 310 
 
representational (SPE) vs. procedural 
(Lexical Phonology) management 
106, 162 

786 
Subject index 
affix class-based phenomena (continued) 
 
representational analysis by Selkirk 
(1984) 540 
 
analysis with co-phonologies 480 
 
Distributed Morphology 557 
 
→underapplication and hence affix 
class-based phenomena cannot 
be done 559 
 
direct merge analysis not viable 
561 
 
distinct representations (vs. distinct 
computation elsewhere) 560 
 
empirical coverage of the three com-
peting theories (overall summary) 
832 
 
coverage by competing theories 
(summary) 
 
rule-blocking pattern 834 
 
rule-triggering pattern 835 
 
the rule-triggering pattern is not 
less real 836 
 
interpretation-triggering affixes spell 
out their own node (Halle & Verg-
naud 1987a) vs. their sister (Kaye 
1995) 282 
 
Kaye (1995): class 2 does, class 1 does 
not trigger interpretation (reverse 
of Halle & Vergnaud 1987a) 281 
affix classes 
 
SPE 92 
 
representational vs. Lexical Pho-
nology's procedural manage-
ment 106, 162 
 
analysis: →affix class-based phenom-
ena 
 
cross-linguistic reality 143 
 
Romance vs. Germanic heritage 143 
 
bound stems 142 
 
called into doubt by dual membership, 
optionality, overgeneration 245 
 
incidence on stress placement 142 
 
vs. derived environment effects: or-
thogonal 182 
affix ordering 
 
Siegel (1974): foundations of Lexical 
Phonology 142 
 
strata-based account in Lexical Pho-
nology 147 
affix ordering (continued) 
 
Kaye (1995) 315, 556 
 
turns out to be wrong 244 
 
is wrong (summary) 671 
 
analysis of strings that violate affix 
ordering (govern-ment-al) (sum-
mary) 834 
affix, category-forming 
 
roots do not possess category (Distrib-
uted Morphology) 544 
affix-triggered interpretation 
 
→interpretation-triggering affixes 
 
birth of the idea in →Halle & Verg-
naud (1987a) 220, 226 
 
in Kaye (1995), interpretation-
triggering is a lexical property of 
affixes 273 
 
Kaye (1995): affixes that determine the 
spell-out of their own body vs. of 
their sister 274 
alignment (OT) 
 
constraint-based mapping 457 
 
ALIGN and WRAP, interaction of cre-
ates parametric variation 460 
 
origins (a development of Selkirk's 
1986 end-based mapping), defini-
tion 395, 458 
 
also competent for units of the Pro-
sodic Hierarchy below the word 
level (→Generalized Template 
Theory) 448 
allomorphy, suppletion 
 
in Distributed Morphology 571 
Alternation Condition 
 
introduction 185 
 
exceptions: automatic, low level, 
"phonetic" processes 186 
 
empirically valid? 186 
 
instrument for the reduction of ab-
stractness 129 
 
also →Revised Alternation Condition 
analogy 
 
→Output-Output 
analytic vs. non-analytic (domains, mor-
phology, affixes) 
 
→Kaye (1995) 272 
anti-cyclicity 
 
→Optimality Theory/ anti-cyclicity 

Subject index 787 
anti-interactionism 
 
in →Halle & Vergnaud 
 
in →Optimality Theory/ anti-cyclicity
anti-lexicalism 
 
of Distributed Morphology 550, 552,
539 
 
vs. lexicalism in phonology 570 
antisymmetry (Kayne 1994) 
 
and linearisation 744 
arboreal structure 
 
→deforestation 
Artificial Intelligence 596, 603 
artificial neural networks 
 
connectionism 591 
asymmetric PF-LF spell-out? 567 
atom (nuclear physics) 592 
automatic processes 
 
→Alternation condition/ exceptions of
186 
autonomous morphology →syntax ≠mor-
phology 539 
autonomous word →word/ autonomous 
unit 
 
B
balance of procedural and representational 
analyses 
 
too hard: this book gives up on the 
ambition 6 
 
summary 748 
 
relationship Lexical Phonology - Pro-
sodic Phonology 429, 435, 440 
 
competing procedural vs. representa-
tional analyses: McCawley (1968)
114 
 
→procedural first 320 
bare output conditions 728 
barriers 
 
atomisation of phasehood marshalled 
by the anti-locality of movement 
777 
 
cyclic movement in GB 298 
 
and →bounding nodes: forerunners of 
Phase Theory 679 
Basic Beat Rules 
 
Selkirk (1984) 426 
behaviourism 
 
opposed by the cognitive revolution 
590 
biolinguistics 
 
language is perfect 728 
 
and language organ 627 
 
and modularity 609 
 
grammar reduces to morpho-syntax, 
PF and LF are neither language- 
nor species-specific 37, 639 
 
Language Faculty due to one or two 
evolutionary innovations 633 
 
third factor explanations 638 
black box 
 
→Prosodic Phonology/ black box 
bound stems 
 
diagnostic for affix classes 142 
boundary 
 
general 
 
introduction of the word "bound-
ary" by Halle (1959) 78 
 
logically possible effects: trigger-
ing, blocking, no 50 
 
are diacritic and local 366 
 
argument against: they are a dia-
critic 373 
 
bankruptcy of: demonstration by 
Pyle (1972) 136 
 
wrong predictions: boundaries are 
not segments (Pyle 1972) 136
boundary contrast, minimal pairs 
118 
 
distinguished by variable phono-
logical permeability 118 
 
external evidence (Basbøll) 122 
 
socio-linguistic function: the less 
formal the style, the smaller 
their influence 112 
 
boundary detectors (→parsing 
cues, →Kaye 1995) 265 
 
disjunction in English: word-
finally and before class 2 af-
fixes (sign, sign-ing2 vs. sign-
ature1) 94 
 
non-diacritic boundaries exist: 
empty CV units 713 
 
summary 
 
translation into a diacritic 695 
 
there are no boundaries inside 
morphemes 667 
 
transition boundaries > prosodic 
constituency 711 

788 
Subject index 
boundary (continued) 
 
boundary strength 
 
absent in SPE 89 
 
boundaries ranked: McCawley 
(1968) 114 
 
diagnostic for boundary abuse 121
in post-SPE and general overview 
117 
 
Prosodic Phonology: attitude of 
Selkirk (1980a) 373 
 
SPE, Selkirk (1972), clusters of # 
112 
 
with structuralist juncture: Choms-
ky et al. (1956) 75 
 
prefix vs. suffix 52 
 
SPE 
 
[-segment] segments, no phonetic 
correlate 88 
 
different types: +, =, # 89 
 
= boundary without posterity 89 
 
# boundaries and brackets not 
redundant 97 
 
boundary-sensitive rules 92 
 
invisibility of boundaries 136 
 
unrestricted: no guidelines for use 
in SPE 120 
 
boundary erasure 90 
 
Natural Generative Phonology 
 
have a phonetic correlate 127, 
669f 
 
in the middle of morphemes 127 
 
failure to eliminate word boundary 
from P-rules 128 
 
post-SPE 
 
boundary mutation rules (read-
justment rules) 112 
 
# = [-voice] (Lass 1971) 135, 713
against boundaries (Rotenberg 
1978) 137 
 
are unwarranted diacritics, partly 
eliminated by autosegmental-
ism 130 
 
are phonological aliens: diacritics 
(post-SPE) 132 
 
boundary zoo in post-SPE times 
117 
 
boundary zoo, attempts to restrict 
it 119 
boundary (continued) 
 
post-SPE (continued) 
 
consequence of autosegmentalism: 
proceduralisation of bounda-
ries 130 
 
define domains of rule application 
(McCawley 1968) 114 
 
frustration with, therefore →direct 
syntax 132, 138 
 
if not segments, what then? 134 
 
only boundaries, no consideration 
of procedural influence 138 
 
segmental status called into doubt 
(McCawley 1968) 134 
 
Typology and strength in post-SPE
116 
 
boundary abuse 
 
diagnostics 121 
 
in structuralism 69 
 
in Natural Generative Phonology 
127 
 
fighting boundary abuse in post-
SPE 119 
 
boundary economy 
 
boundaries are last resort (Basbøll)
122 
 
elimination of + 123 
 
Lexical Phonology 
 
eliminated by procedural manage-
ment 162 
 
target for elimination in Lexical 
Phonology and Prosodic Pho-
nology, but not for the same 
reasons 367 
 
Prosodic Phonology 
 
(non-)discussion of in Prosodic 
Phonology 369, 376 
 
are the non-autosegmental version 
of the Prosodic Hierarchy 403
are the primitive currency for 
mapping: prosodic domains are 
built on the basis of boundary 
grouping 397 
 
arguments against, made by Pro-
sodic Phonology 369 
 
from boundaries to domains: a 
historical choice that has gone 
almost unnoticed 365 

Subject index 789 
boundary (continued) 
 
Prosodic Phonology (continued) 
 
replaced by autosegmental do-
mains 361 
 
share all formal properties with 
prosodic constituents 404 
 
the local baby was thrown out with 
the diacritic bathwater 373 
bounding nodes 
 
atomisation of phasehood marshalled 
by the anti-locality of movement 
777 
 
(or cyclic nodes): movement in the 
Extended Standard Theory 298 
 
and Barriers: forerunners of Phase 
Theory 679 
bracket erasure 
 
in SPE 102 
 
in Lexical Phonology ≠in SPE 176 
 
and →Praguian segregation in Lexical 
Phonology 175 
 
and no look-back effect in Lexical 
Phonology 174 
 
in Lexical Phonology: needed for the 
→rule-triggering pattern 168 
 
Lexical Phonology: internal structure 
of words invisible to syntax 157 
brackets and bracket erasure 
 
SPE vs. Lexical Phonology 168, 171 
bracket erasure 
 
relation of Mohanan's version with 
other no look-back devices 292 
bracketing paradoxes 
 
Rubach & Booij (1984): solution based 
on prosodic constituency 440 
 
analysis by Halle & Vergnaud (1987a)
246 
 
anti-interactionist ammunition (Halle 
& Vergnaud 1987a) 243 
 
cannot be done by Kaye (1995) 315 
 
with English un- 319 
brackets 
 
SPE: represent morpho-syntactic 
structure 96 
 
status in SPE (summary) 675 
 
SPE: brackets and # boundaries not 
redundant 97 
brackets (continued) 
 
labelled brackets in SPE, label-
sensitive rules 96 
 
and interactionism 98 
 
brackets vs. interactionism (summary)
673 
 
bracket erasure: SPE vs. Lexical Pho-
nology 168, 171 
Lexical Phonology 165 
 
elimination by interactionism 161
are boundaries through the back 
door 172 
 
relation of Mohanan's bracket 
erasure with other no look-
back devices 292 
 
Mohanan: competitor of the SCC-
K 203 
 
needed for the rule-triggering 
pattern 168 
 
undo what was gained by interac-
tionism 170 
 
how to distinguish class 1 and 
class 2 boundaries 173 
 
bracket-sensitive rules can do 
derived environment effects 
202 
 
bracket-sensitive rules (Mohanan) 
168 
 
reintroduction in Halle & Vergnaud 
(1987a) 219 
 
in Kaye (1995): do not exist, only 
shorthand for the linear notation 
275 
brain 
 
mind and brain 588 
 
localisation of cognitive functions in 
the brain 614 
buffer 
 
→Prosodic Phonology/ buffer 
 
C
calendrical calculation 
 
double dissociation, savants 621 
category 
 
roots do not possess category (Distrib-
uted Morphology) 544 

790 
Subject index 
category-sensitive phonology 
 
récord (noun) vs. recórd (verb) etc. 
438 
c-command 
 
in phonology 705 
 
linearisation 745 
Central Dogma (J. Kaye) 
 
all related forms are derived from the 
same UR 126 
central system (Fodor) 
 
modularity 605f 
 
not the result of adaptive evolution 
633 
chunk-specific phonologies 
 
→computational systems, →no look-
back devices/ PIC à la carte 
(chunk-specific), →Phase Impene-
trability 
circuits 
 
Poeppel: levels intermediate between 
symbolic representations and neu-
robiology 616 
clean syntax, dirty phonology 
 
unloading displeasing syntactic phe-
nomena into PF 575, 580 
 
summary 727 
Clitic Group 
 
abandoned in Prosodic Phonology, 
note 96 (382) 
clitic placement 
 
outsourced into PF 730 
cognitive functions 
 
higher (horizontal) and lower (verti-
cal), how are they identified? 605 
 
localisation in the brain 614 
Cognitive Neuroscience 
 
synthesis of mind and brain 617 
cognitive realism 
 
cognitive revolution 590, 624 
cognitive resources 
 
→memory (active) 
 
morpheme identification: different 
paths to identification are more or 
less costly 357f 
cognitive revolution 
 
of the 50s-60s 590 
Cognitive Science 
 
standard model 590, 603 
 
symbolic vs. anti-symbolic views of 
the cognitive system 591 
 
levels of representation 590 
 
mind-brain relationship 615f 
 
modularity in 40 
 
language of thought 591 
 
generative linguistics, the spearhead of 
von Neumann-Turing computation 
in language 624 
 
connectionist roots of OT 529 
 
symbolic representations in OT 529 
"Cognitive" Grammar 
 
linguistic incarnation of empiricist 
thought 591, 596 
cohering vs. non-cohering affixes 
 
→affix classes, note 32 (142) 
Coloured Containment (Oostendorp) 503 
 
monostratal = representational, anti-
derivational orientation 510 
 
faithfulness between morphology and 
phonology 504 
 
phonological action restricted by mor-
phological affiliation 508 
 
recoverability constraints 508 
 
GEN marshalled by Consistency of 
Exponence 507 
 
information transmission: representa-
tional (colours) vs. procedural 
(mapping) 506 
 
old vs. new (strings, properties) 505f, 
509 
 
opacity 508 
 
derived environment effects 509 
 
prosodic constituency, double mapping
511 
cómparable vs. compárable 
affix classes: dual membership 245 
 
analysis in Distributed Morphology: 
direct vs. indirect merge 545 
Comparative Markedness (McCarthy 
2003a) 
 
used for derived environment effects in 
OT 519 
compensation vs. condensation 
→condensation vs. compensation 

Subject index 791 
competence vs. performance 590 
complexity, computational 
 
→computational complexity 
compositionality, non-compositionality 
 
LF opacity (Distributed Morphology) 
545 
computation 
 
in phonological theory 269 
 
von Neumann-Turing model 603 
 
Fodor's faculty psychology married 
with computation theory (Turing-
von Neumann) 603 
 
Parallel Distributed Processing (PDP) 
vs. serial 597 
 
all-purpose (content-free) vs. special-
ised 597f 
 
modularity: computation is computa-
tion of something (domain-
specificity) 598 
 
connectionism vs. modularity 597f 
 
generative linguistics, the spearhead of 
von Neumann-Turing computation 
in language 624 
 
intalterability of phonological compu-
tation predicted by modularity 659
morpho-syntactic information cannot 
modify the content of phonological 
computation (phonological instruc-
tions) 659 
 
SPE definition of phonology, a fore-
runner of Fodorian modules 613 
 
argument for parallel computation 
(connectionism): serial computa-
tion is not quick enough 597 
 
in Government Phonology 267 
computational complexity 
 
unwarranted in minimalism: motiva-
tion for derivation by phase 305 
computational economy 
 
→economy (computational) 
Computational Neuroscience 
 
Marr (1982) 603 
computational systems 
 
summary and typology 234-36 
 
→chunk-specific phonologies 
 
SPE: cyclic vs. word-level rules 
105 
 
specific word-level phonology 
undisputed 824 
 
for morphemes vs. words 22 
 
Kaye (1995) recognises specific 
word-level rules 338 
 
chunk-specific phonologies (summary)
811 
 
specific word-level phonology 
812 
 
Praguian segregation (specific 
sentence-level phonology) 815
word-level phonology: role of 
English stress 814 
 
chunk-specific vs. morpheme-specific 
phonologies 
 
in Lexical Phonology 154, 234 
 
in Distributed Morphology 535 
 
summary 257 
 
→no look-back devices/ PIC à la 
carte (chunk-specific) 
 
morpheme-specific phonologies 
 
vs. no look-back: a major front line
829 
 
vs. no look-back (PIC): refereed in 
favour of the PIC 830 
 
in OT 473 
 
in OT: parallel vs. reranked incar-
nations 476 
 
and →selective spell-out are in-
compatible 303 
 
vs. selective spell-out, summary 
303 
 
rejected by Distributed Morpholo-
gy 534 
 
PIC à la carte 
 
= computational economy à la 
carte 780, 797, 826 
vs. Praguian segregation 818-27 

792 
Subject index 
computational systems (continued) 
 
syntax = or ≠morphology? 
 
Selkirk (1984) vs. Lexical Phono-
logy 540 
 
Sproat (1985), Halle & Vergnaud 
(1987a) 223 
 
Distributed Morphology 534f, 
537, 539 
 
SPE: one single computational system 
due to a representational definition 
of words and affix classes 107 
 
Lexical Phonology 
 
level 1 vs. level 2 149-51 
 
morphology vs. syntax 155 
 
word- (lexical) vs. sentence (pos-
tlexical) phonology 154f 
 
Halle & Vergnaud (1987a) 
 
no distinct lexical vs. postlexical 
phonology 248 
 
only one computational system 
219 
 
cognitive functions, double dissocia-
tion 618 
 
definition of "phonology": is phono-
logical what is the output of pho-
nological computation 804, 806 
 
different systems for syntax and the PF 
movement-intermundia undermine 
DM 580 
 
just one spell-out mechanism (mor-
phology and syntax are the same 
computational system), or two 
(they are not)? 858 
 
the interface and phonology are dis-
tinct (but OT scrambles them) 
(summary) 678 
concat function 
 
→Kaye (1995), akin to Merge 268 
conceptual device 
 
module interacting with grammar 629
evidence from double dissociation 642
condensation vs. compensation 
SPE 97 
 
Halle & Vergnaud (1987a), Stress 
Erasure, Stress Copy 231 
 
→Distributed Morphology 
connection weight 
 
(artificial) →neural networks 591, 595
connectionism 588 
 
vs. →modularity 
 
two competing theories of how the 
cognitive system works 588 
 
early days: complementary (a 
question of levels), rather than 
incompatible 599 
 
mind - brain relationship 588, 614 
 
is empiricist, monistic (philosophy), 
reductionist in kind 591 
 
Parallel Distributed Processing (PDP) 
vs. serial computation 597 
 
denies symbolic representations and 
hence the mind 591 
 
no distinction between storage and 
computation (rule-list fallacy) 596
all-purpose (content-free) vs. special-
ised computation 597f 
 
argument for parallel computation: 
serial computation is not quick 
enough 597 
 
and memory 596 
 
linguistic implementation of the non-
distinction between computation 
and storage: "Cognitive" Gram-
mar, usage-based theories (Bybee)
596 
 
connectionist roots of →OT 529 
 
contributes to blur the modular con-
tours of OT 678 
Consistency of Exponence 507 
Constraint Conjunction 
 
used for derived environment effects in 
OT (Łubowicz) 518 
constraint-based (vs. rule-based) mapping 
 
in OT 457 
containment 
 
→Coloured Containment (Oostendorp)
convergence-based phasehood 
 
Svenonius (2001), note 178 (781) 
co-phonologies 
 
lexical material selects a specific 
computational system 478 
 
analysis of affix class-based phenom-
ena 480 
 
comparison with Halle & Vergnaud 
(1987) 481 

Subject index 793 
co-phonologies (continued) 
 
cophonology proliferation problem 
492 
 
morpheme-specific mini-phonologies 
in OT: parallel vs. reranked incar-
nations 476 
copy and delete 
 
clitic placement outsourced into PF 
730 
correspondence rules 
 
Representational Modularity (Jacken-
doff) 723 
counter-cyclic merger 
 
Kaye (1995): independent spell-out of 
terminals 318 
cross-word phonology 
 
→sandhi (external) 
cycle 
 
→phase theory 
 
definition in SPE: by major categories
103 
 
terminological confusion/pitfalls 236 
cyclic (vs. non-cyclic) affixes 
 
Halle & Vergnaud (1987a), →affix-
triggered interpretation, note 32 
(142), 226f 
cyclic constituent 
 
Halle & Vergnaud (1987a) 227 
cyclic derivation (inside-out) 
 
introduction 5 
 
procedural (interactionism, phases) or 
representational (brackets)? 675 
 
invention by Chomsky et al. (1956) 80
unprecedented in structuralism 80 
 
evidence for 686 
 
implementation of: brackets vs. inter-
actionism (summary) 673 
 
cyclic derivation (interface) ≠phono-
logical computation 470 
 
intimate relationship with English 
stress 102 
 
cyclic spell-out of words (external 
sandhi): no phonological traces: 
→word-spell-out-mystery 
cyclic derivation (inside-out) (continued) 
 
anti-cyclic phenomena: apply to a 
morpho-syntactically complex 
chunk, but not to the pieces that it 
is made of: →derived environment 
effects (word level)/ Cracow voic-
ing (sentence level) 822, 840 
 
overview and implementation in SPE 
102 
 
definition of cycles in SPE: by major 
categories 103 
 
Lexical Phonology 
 
expressed by strata 147 
 
definition of cycles in 160 
 
cyclic (=lexical) vs. non-cyclic 
(=postlexical) rules 158 
 
of words: yes in Kaye (1995), who 
follows SPE and Halle & Verg-
naud (1987a) 285 
 
and Indirect Reference: phonology 
applies to chunks, but does not se-
lect them 434 
 
anti-cyclicity in OT 28, 468 
 
(and elsewhere): overview 465 
 
summary 686 
cyclic linearisation 
 
linearity-driven movement (Fox & 
Pesetsky 2004) 744 
cyclic movement (successive) 
 
linearity-driven (Fox & Pesetsky 2004)
744 
cyclic movement (syntax) 
 
early modification-inhibiting →no 
look-back 298 
cyclic nodes 
 
cyclic movement in the Extended 
Standard Theory 298 
cyclic rules 
 
in SPE 105 
 
in Lexical Phonology: interactionist 
application 158 
 
in Halle & Vergnaud (1987a), com-
parison with SPE 219, 233 
 
split into structure-building vs. struc-
ture-changing rules 193 

794 
Subject index 
cyclicity killers (OT) 454, 467, 475 
→co-phonologies 
 
→indexed constraints 
 
enriched representations (Oostendorp)
500 
 
D
Darwinian adaptation 
 
is the mind (are modules) the result of 
Darwinian adaptation? 609 
Declarative Phonology 
 
phonological affiliate of →HPSG 27 
 
computation in 269 
 
Sign-Based Morphology 513 
deforestation 42 
 
and recursion 805 
 
lateral structure predicts the absence of 
recursion 46 
 
trees make wrong predictions: there is 
no recursion in phonology 45 
 
arboreal and lateral structure are in-
compatible 44 
demarcative function of phonology 
 
→Grenzsignale (Trubetzkoy) 
 
→Kaye (1995), parsing cues 
Demi-Beat Alignment DBA 
 
Selkirk (1984) 426 
Dependency Phonology 
 
Structural Analogy 705 
derivation by phase 
 
general presentation 304, 771 
 
history 
 
how it was introduced in the late 
90s 305 
 
emergence of, favoured by the 
abandon of deep structure and 
a return to the derivationalism 
of the 70s 305 
 
motivated by minimalist economy
305 
 
(interactionism) early cases of: 
Bresnan (1971) 308 
 
early modification-inhibiting no 
look-back: Head Constraint 
(Riemsdijk 1978) 298 
 
Head Constraint (Riemsdijk 1978) 
vs. PIC: interpretation and 
hence PF played no role in the 
70s 298 
derivation by phase 
 
extreme version of: spell-out-as-you-
merge (Epstein et al. 1998) 305 
 
violation of encapsulation? 632 
 
edge of the phase 298 
 
→interactionism 
 
modern implementation of →cyclic 
derivation 
 
no reference to the fact that this idea 
was born in phonology: 
→interactionism 305 
 
→selective spell-out: invented by 
Halle & Vergnaud (1987a) 220 
 
initiated by Halle & Vergnaud (1987a)
228 
 
Chomsky's "spell-out and forget" too 
strong for phonology: two candi-
dates for a weaker version 302 
 
the PIC was generalised by Kaye 
(1995) 359 
derivational syllable 
 
Guerssel & Lowenstamm (1990) 713 
derivational vs. inflectional morphology 
 
contrast rejected by Distributed Mor-
phology 546 
derived environment effects 177, 516 
 
theories of (summary) 837 
 
an important phenomenon that is 
poorly understood 208 
 
morphologically vs. phonologically 
derived 179 
 
phonologically derived environ-
ment effect: Finnish t →s / __i
180 
 
morphologically derived environ-
ment effect: Polish palatalisa-
tion 181 
 
empirically valid? 186 
 
vs. affix classes: orthogonal 182 
 
anti-cyclic phenomena: apply to a 
morpho-syntactically complex 
chunk, but not to the pieces that it 
is made of: →derived environment 
effects (word level)/ Cracow voic-
ing (sentence level) 822, 840 
 
are independent from affix class-based 
phenomena 838 

Subject index 795 
derived environment effects 177, 516 
(continued) 
 
at the sentence level: apply across 
word-, but not across morpheme 
boundaries (Cracow voicing) 822 
 
and the abstractness debate 183 
 
free rides (SPE: Pamela) 184 
 
solution 1: Strict Cycle Condition 
(SCC) 188 
 
solution 2: lexical contrast (Kiparsky 
1993) 196 
 
solution 3: bracket-sensitive rules 
(Mohanan 1982) 201 
 
solution 4: a non-linguistic 
phenomenon (Anderson 1981) 
204 
 
genesis of: acquisitional scenario 
(Anderson 1981) 206 
 
a scenario for their genesis is not good 
enough 206 
 
→Strict Cycle Condition (SCC) 
 
SCC-K and its violation 
 
only produced by 1) obligatory and 
2) neutralising rules: why? 
199 
 
Kiparsky's Alternation Condition 
185 
 
Revised Alternation Condition 
(RAC) 187 
 
Revised Alternation Condition 
falsified by Anderson's (1981) 
Fultonians 205 
 
automatic, low level processes are 
postlexical 189, 192 
automatic, low level, "phonetic" 
processes 186 
 
derived environment created by 
structure-building rules? 193 
 
derived environment sensitivity à 
la carte according to individual 
processes can be done by 
bracket-sensitive rules 202, 
210 
 
different lexical representations of 
identical segments (Kiparsky 
1993) 198 
 
Kiparsky's (1993) solution ≈SPE 
209 
derived environment effects 177, 516 
(continued) 
 
SCC-K and its violation (continued) 
 
SCC and Kiparsky's (1993) lexical 
option not viable 209 
 
posterity of Kiparsky's solution 
based on lexical contrast 200 
 
in Kaye (1995): a separate issue, no 
relation with no look-back 284 
 
in OT 516 
 
Comparative Markedness (McCar-
thy 2003a) 519 
 
Constraint Conjunction (Łubo-
wicz) 518 
 
co-phonologies (Yu 2000) 522 
 
revival of the Elsewhere Condition 
(Cho 2008) 521 
 
Root Faithfulness (→direct syntax, 
Anttila) 520 
 
in Coloured Containment (Oostendorp)
509 
desymmetrisation 
 
→linearisation: Richards (2004, 2007)
745 
developmental psychology 
 
→encapsulation (informational) 612 
diacritics 
 
→Prosodic Hierarchy/ is a diacritic 
(from the PrWd upwards) 
 
→Prosodic Phonology/ domains are 
necessarily diacritic 
 
definition 405 
 
do not qualify 44 
 
birth and variable incarnation of 
(summary) 667, 694 
 
diacritics sold as "true phonological 
objects" 
 
variable camouflage: juncture 
phonemes and boundaries 
(summary) 695 
 
various degrees of awareness that 
items are diacritics 697 
 
settled in verb, but not in practice: 
No Diacritics! 690 
 
illusion of a diacritic-free phonol-
ogy since the 80s 698 

796 
Subject index 
diacritics (continued) 
 
history 
 
born from the abandon of Level 
Independence 696 
 
Trubetzkoyan Grenzsignale: im-
material, hence not diacritic 
58 
 
diacritic definition of boundaries 
due to the absence of phone-
mic status of juncture (Chom-
sky et al. 1956) 78 
 
the status of boundaries as seg-
ments called into doubt 
(McCawley 1968) 134 
 
critique by Rotenberg (1978) 137 
 
boundaries are phonological 
aliens: diacritics (post-SPE) 
132 
 
partly eliminated by autosegmen-
talism 130 
 
alternative 
 
translation into non-diacritic items, 
a structuralist invention 72 
 
→direct syntax 132 
 
→Direct Interface 
Direct Effect 685 
Direct Interface 
 
overview 2, 5, 49 
summary of issues relevant for 718 
 
output of translation must be vocabu-
lary items that are used in phonol-
ogy in absence of extra-
phonological factors 655 
 
diacritics make no predictions 58 
 
translation into truly phonological 
objects: logical option not pursued 
in post-SPE 134 
 
logical option, but explored only by 
Lass (1971) 134, 138 
direct merge (to the root) 
 
source of opacity in →Distributed 
Morphology 543 
 
vs. selective spell-out (summary) 582
is pointless in a lexicalist perspective: 
cómparable - compárable 573 
direct syntax 
 
alternative to translation 702 
 
alternative to diacritic boundaries 132
direct syntax (continued) 
 
and privativity 759 
 
introduction of this option by 
Kenstowicz & Kisseberth 132 
 
early and erratic proposals in post-SPE 
(Hyman, Pyle, Rotenberg) 123 
 
out of frustration with boundaries 132, 
138 
 
way chosen when boundaries were 
found to be bankrupt (post-SPE) 
137 
 
vs. Prosodic Phonology & Indirect 
Reference 407 
 
in OT 525 
 
interface constraints in OT 494 
 
Root Faithfulness in OT 520 
 
in Sign-Based Morphology (Orgun) 
512 
 
in Coloured Containment (Oostendorp)
503 
 
in Distributed Morphology 580 
directed graphs (Raimy) 
 
linearisation in phonology? 746 
 
loop-containing representations are 
called phonology in 2003, but 
"morphophonology" later on 740, 
746 
directionality of communication 
 
scope of the book: from morpho-
syntax to phonology 25 
discovery procedure 
 
fieldwork-based method in structural-
ism 62 
dissociation (double) 
 
→double dissociation 
Distributed Morphology 531 
 
overall picture 532 
 
summary properties and problems 581
a more complete theory of the inter-
face: LF and PF effects 542 
 
general architecture 536 
 
internal structure of PF: the "PF 
branch" 734 
 
late insertion 536 
 
vocabulary (items) 536 
 
no position taken regarding the 
representational communica-
tion with phonology 585 

Subject index 797 
Distributed Morphology 531 (continued) 
 
general architecture 536 (continued) 
 
agnostic with respect to multiple 
computational systems in pho-
nology 535 
 
DM is a strong modularity of-
fender: phonology interleaved 
with non-phonological PF op-
erations (linearisation) 739 
 
idiom (phrasal), note 136 (536), 
544 
 
word-formation based on roots vs. 
on existing words (trans-
port-at-ion derived from 
*transport-ate) 550 
 
→PF movement 
 
allomorphy, suppletion 571 
 
no rationale for deciding between 
allomorphy and phonological 
activity 572 
 
vs. Lexical Phonology 533 
 
anti-lexicalism 550, 569, 552 
radically anti-lexicalist, but allo-
morphy/suppletion and lexical-
ist analyses are possible 573 
 
rejects morpheme-specific mini-
phonologies 534 
 
rejects the Lexicon of Lexical 
Phonology 534f 
 
rejects the two-place approach of 
Lexical Phonology 534f 
 
reproduces lexicalism with anti-
lexicalist tools 552 
 
resumes Halle & Vergnaud's 
(1987a) attack against Lexical 
Phonology 534 
 
root-based vs. word-based mor-
phology in a single engine per-
spective 546 
 
single engine hypothesis: 
→morphology = syntax 534f, 
537 
Distributed Morphology 531 (continued) 
 
does not live up to its single engine 
ambition (syntax = morphology) 
538, 584 
 
different computational systems 
for syntax and the PF move-
ment-intermundia undermine 
DM 580 
 
different distribution of phasehood 
below and above the word 559
→derivation by phase 
 
subscribes to →interactionism 534
→Phase Impenetrability 555 
 
is forced into PIC à la carte: the 
PIC does not apply to primary 
stress in English 555 
 
problem with phasehood and the 
PIC: DM has a peculiar way to 
do selective spell-out (func-
tional vs. non-functional 
heads) 558f 
 
two possible origins of phonologi-
cal opacity: direct merge and 
→Phase Impenetrability 542 
 
affix class-based phenomena 
 
distinct representations (vs. distinct 
computation elsewhere) 560 
 
underapplication and hence affix 
class-based phenomena cannot 
be done 559 
 
every xP is a phase head 544, 
551f, 558f 
 
spell-out at every xP is much too 
strong a claim if Phase Im-
penetrability is applied 555 
 
direct merge and opacity 541 
 
tree-geometry is the origin of 
opacity 542, 544, 546 
idiosyncrasy is a property of 
"lower" items in the tree 546 
 
opacity = (direct) merge to a root, 
transparency = merge to an xP
544 

798 
Subject index 
Distributed Morphology 531 (continued) 
 
direct merge and opacity 541 (contin-
ued) 
 
direct merge may, but does not 
have to produce opacity 546, 
553 
 
condensation vs. compensation,
SPE's classical take: two dif-
ferent suffixes 548 
 
condensation vs. compensation,
analysis by Halle & Kensto-
wicz (1991) 549 
 
condensation vs. compensation,
analysis by Marvin (2002) 
550f 
 
condensation vs. compensation,
existence of two groups of 
words with contrasting behav-
iour 549 
 
in a lexicalist perspective there is 
no opacity in cómparable - 
compárable at all 573 
 
PF-LF opacity 
 
asymmetric PF-LF spell-out? 567
combinations of PF - LF opacity: 
neither the PIC nor direct 
merge can account for all pat-
terns 566 
 
concordance: cómparable vs. 
compárable 545 
 
all combinations attested 565 
 
maybe not the same thing 562 
domain assignment 
 
Lexical Phonology: a given rule ap-
plies only at a given stratum 151 
domain juncture-, domain limit-, domain 
span  rules 
 
Prosodic Phonology 384, 709 
domain specificity 
 
modularity 611 
 
identifies modules 613 
 
diagnostic for modular status of GB-
subtheories 632 
 
diagnostic for language-internal modu-
lar structure 643-46 
 
in early generative grammar: LSLT 
(Chomsky 1955-56) 625 
 
syntax, morphology, semantics vs. 
phonology 413 
domain structure (→Kaye 1995) 
 
betrayed by parsing cues (consonant 
clusters) 337, 339 
 
betrayed by vowel (non-)reduction 
337 
 
consequences of for stress and vowel 
reduction (English) 334 
 
contrast between [[X] [Y]] and [[X] Y]
337 
 
contrast between [[X] [Y]] and [X Y] 
336f 
 
diachronic erosion of 339 
 
dialectal and idiolectal variation due to 
variable domain structure 335 
domain-based carriers vs. local carriers 
 
→local vs. domain-based carriers 
domain-final 
 
condition on rule application: Kaye 
(1995), rule-triggering pattern 322
reference to the domain-final location: 
no violation of modularity 323 
domain-final empty nuclei 
 
in Government Phonology 329 
 
from word-final to domain-final empty 
nuclei 331 
 
detected by parsing cues 344 
 
several in a row 332 
 
are phase-initial and special for that 
reason 333 
 
are subject to no look-back: licensed 
also on later cycles 332 
 
Kaye's (1995) analysis of nasal assimi-
lation (un- vs. in-) 314 
 
Kaye's (1995) analysis of nasal cluster 
simplification 324 
domains 
 
hierarchical structure, built on juncture 
(Chomsky et al. 1956) 75 
 
of rule application, defined by bounda-
ries (McCawley 1968) 114 
domains (prosodic) 
 
→Prosodic Phonology 
DOT 
 
→Stratal OT 483 
double dissociation 618 
 
modularity vs. connectionism: differ-
ent predictions 619 
 
identifies modules 613 
 
of language 621 

Subject index 799 
double dissociation 618 (continued) 
 
identification of language-related 
modules 642 
 
face recognition, number sense 620 
 
diagnostic for modular status of GB-
subtheories 632 
 
applied to Praguian segregation 818 
dualism vs. monism 591 
 
E
economy 
 
phoneme economy 60, 65 
 
generative ideas in a structuralist guise 
(Chomsky et al. 1956) 74f 
 
motivation for →derivation by phase 
305 
economy (computational) 
 
in minimalism: is always obeyed 797 
 
PIC à la carte = computational econo-
my à la carte 780, 797, 826, 830 
edge of the phase 
 
→phase edge 
edge phonology 
 
distinct from morpheme-internal pho-
nology 667 
edge-based mapping 
 
→end-based mapping 
ellipsis, sluicing 
 
outsourced into PF (non-pronunciation 
"at PF") 731 
Elsewhere Condition 
 
derivation of Kiparsky's Strict Cycle 
Condition (SCC) by 191 
 
revival in OT (derived environments, 
Cho 2008) 521 
empiricism 
 
vs. rationalism 591 
Empty Category Principle (ECP) 
 
Government Phonology 330, 344 
 
Kaye's (1995) analysis of nasal assimi-
lation (un- vs. in-) 314 
empty nuclei 
 
→domain-final empty nuclei 
 
detected by parsing cues 343 
 
identified as domain-final by parsing 
cues 344 
 
that are string-final upon computation 
(= domain-final empty nuclei) 329
word-final 330 
encapsulation (informational) 
 
core property of modules 612 
 
enhanced language skills of Christo-
pher (Smith & Tsimpli) 621 
 
is called inclusiveness in syntax 
(Chomsky) 648 
 
diagnostic for modular status of GB-
subtheories 632 
 
violated by nested modules (derivation 
by phase, GB-subtheories)? 632 
end-based mapping (Selkirk 1986) 394 
 
puts to use the technology of the 80s: 
X-bar-based mapping 395 
 
no advance regarding the mapping 
puzzle 392, 396 
ERPs (Event-Related Potentials) 
 
localisation of cognitive functions in 
the brain 617 
escape hatch (→phase edge) 
 
cyclic movement in the Extended 
Standard Theory 298 
evaluation measure 
 
derived environment effects 198 
evolutionary psychology 
 
modularity 609 
 
Language Faculty due to adaptive 
evolution? 633 
exceptionless rules 
 
Natural Generative Phonology: P-rules 
(vs. MP-rules) 127 
 
in Lexical Phonology: postlexical rules
156 
exemplar-based theories 596 
Extension Condition 
 
Chomsky (1995) 319 
external sandhi 
 
→sandhi (external) 
 
→word-spell-out-mystery 
extra-linguistic factors in language design 
 
comparison Head Constraint (Riems-
dijk 1978) and PIC 298 
 
motivation for derivation by phase 
305 
 
minimalism and biolinguistics (third 
factor explanations) 633, 638f 
 
applied to phonology (Samuels 
2009a,b) 639 
extrametricality 
 
in Latin stress assignment 295 

800 
Subject index 
extraposition 
 
motivation for PF movement 575 
 
F
face recognition 
 
double dissociation 620 
Faculty of Language 
 
→Language Faculty 
faculty psychology (Fodor 1983) 
 
modularity is the heir of phrenology 
602 
 
married with computation theory 
(Turing-von Neumann) 603 
faithfulness 
 
Containment vs. Correspondence 505
final 
 
→domain-final 
final empty nuclei 
 
→domain-final empty nuclei 
fission 
 
Distributed Morphology 536, 538 
FLB (Faculty of Language in the Broad 
sense) 
 
animal-based, includes PF and LF 633
does not include PF and LF 639 
 
modularity 609 
 
not the result of adaptive evolution 
633 
fMRI (functional Magnetic Resonance 
Imaging) 
 
localisation of cognitive functions in 
the brain 617 
foot structure 
 
early modification-inhibiting no look-
back 295 
Free Element Condition (FEC) 
 
early modification-inhibiting no look-
back (stress) 295-97 
 
is weak no look-back: process-
specificity, restriction to structure 
that is absent from the lexicon 296
Chomsky's "spell-out and forget" too 
strong for phonology: two candi-
dates for a weaker version 302 
free ride 
 
SPE 184f 
Fultonians 
 
why phonology isn't natural (Anderson 
1981) 205 
functional anatomy 
 
localisation of cognitive functions in 
the brain 616 
 
strategy: levels intermediate between 
symbolic representations and neu-
robiology: connectionism, Poep-
pel's circuits 616 
functional theories of the interface 
 
→Grenzsignale (Trubetzkoy) 
 
→Kaye (1995) & overview 263f 
fusion 
 
Distributed Morphology 536, 538 
 
G
Gall, Franz-Joseph 
 
founder of phrenology, origins of 
modularity 601f 
GB-subtheories 
 
are cognitive modules? Violate encap-
sulation? 632 
 
introduced without reference to the 
modularity of the cognitive system
630 
 
GB subtheories and their perception as 
cognitive modules 628, 635 
 
against language-internal modularity 
(Hornstein 2009) 633 
generalisations (empirical) 
 
morpho-syntax and melody are in-
communicado 660 
Generalized Template Theory 
 
OTed version of Prosodic Morphology
448 
Generative Semantics 12 
 
alternative to the inverted T model 
721 
 
did not follow "all concatenation be-
fore all interpretation" 359 
 
return of the 60s 679 
generativism and structuralism 
 
continuity or rupture? 80 
government 
 
(and licensing) 43 
 
Government Phonology 705 
 
interconstituent government 343 
 
Kaye's (1995) analysis of nasal assimi-
lation (un- vs. in-) 314 

Subject index 801 
Government Phonology 
 
also →Kaye (1995) 
 
Standard GP 
 
a hybrid arboreal-lateral model 43
Magic Licensing, note 82 (344) 
 
Interonset Government, note 82 
(344) 
 
projection principle 705 
 
prosodic government 705 
 
computation in 
 
the φ-function 267 
 
and Harmonic Serialism 269 
 
strict CV: strings are computed right-
to-left 333 
 
→government 
 
licensing 705 
 
→domain-final empty nuclei 
 
→empty nuclei 
 
Structural Analogy 705 
Grenzsignale 
 
alert listener, help parsing 55 
 
cradle of the functional perspective 56
positive vs. negative 57 
 
are immaterial and not diacritics 58 
 
are under morpho-syntactic control 58
and the →mapping puzzle: no predic-
tions made 58 
grid 
 
→metrical grid 
 
H
Halle & Vergnaud (1987a) 
 
non-interactionist version of Lexical 
Phonology 215 
 
relevant literature 221 
 
summary 254 
 
anti-interactionism 
 
comparison with classical LP 
217f, 235 
 
directed against LP 219 
 
arguments against interactionism 
223 
 
anti-interactionist strategy: attack 
affix ordering 244 
 
stratal vs. non-interactionist archi-
tecture, two testing grounds 
251 
Halle & Vergnaud (1987a) (continued) 
 
general architecture 
 
partial picture 235 
 
complete picture 238 
 
selective spell-out, a groundbreak-
ing idea 220, 256 
 
heralded by Halle & Mohanan 
(1985) 233 
 
Distinct pre- vs. post-word pho-
nology yes, Praguian segrega-
tion no 248 
 
multiple computational systems 
234 
 
Praguian segregation dismissed 
219 
 
takes morpho-syntactic trees seri-
ously 226f 
 
the root is always an interpreta-
tional unit (a cycle) 230 
 
both spell-out and interpretation 
are cyclic 792 
 
restoration of SPE 217, 219 
 
cyclic interpretation of all chunk 
sizes 238 
 
dismissal of Praguian segregation 
238 
 
interpretational units 242 
 
pre-word allomorphy = readjust-
ment 235 
 
summary: more akin with SPE 
than with LP 255 
 
affix-triggered interpretation 
 
percolation of lexical properties of 
affixes to the morpho-syntactic 
tree 227 
 
cyclic vs. non-cyclic affixes 226 
 
cyclic vs. non-cyclic rules 219, 
233 
 
interpretational units 242 
 
interpretation-triggering affixes 
220 
 
proceduralisation of the interface 235 
 
elimination of boundaries 235 
 
→SCC-K 237 
 
comparison with Kaye (1995) 
 
overview 286 
 
roots are, words are not interpreta-
tional units (reverse of Kaye 
1995) 280 

802 
Subject index 
Halle & Vergnaud (1987a) (continued) 
 
comparison with Kaye (1995) (conti-
nued) 
 
underapplication to class 2 strings 
279 
 
what exactly is spelled out 226 
 
empirical coverage 
 
rule-blocking & -triggering pattern
248 
 
→affix class-based phenomena 
 
analysis of rule-blocking pattern 
(level 1 rules) 227f 
 
unable to do the rule-triggering 
pattern 250 
 
analysis of bracketing paradoxes 
246 
 
analysis of stress 
 
metrical grid 237 
 
Stress Copy 231 
 
Stress Erasure Convention 230 
 
structure-changing vs. structure-
building rules 237 
Harmonic Serialism (OT-CC), note 68 
(269), 686 
 
Optimal Interleaving (Wolf 2008): 
revival of interactionism with one 
single constraint hierarchy that 
merges morphology and phonol-
ogy 472 
Harmonic Grammar (Smolensky & Le-
gendre 2006) 
 
peaceful coexistence of connectionist 
and symbolic levels 599 
Head Constraint (Riemsdijk 1978) 
 
early modification-inhibiting no look-
back 298 
 
vs. PIC: interpretation and hence PF 
played no role in the 70s 298 
head parameter 
 
linearisation 743 
 
revived in PF-based linearisation 
strategies 745 
helix (double, biology) 592 
historiographic cherry-picking 9 
 
looking at the interface through the 
prism of its history produces dif-
ferent results 843 
history 
 
instrument for independent assessment
35, 843 
homomorphemic 
 
parallel modules are (Bendjaballah & 
Haiden) 724 
HPSG 27 
 
Sign-Based Morphology (Orgun) 513
hundred-step programme (Feldman 1985) 
 
argument for parallel computation 
(connectionism): serial computa-
tion is not quick enough 597 
 
I
idiom (phrasal), idiom(atic) expression 
 
in →Distributed Morphology, note 136 
(536), 544 
impoverishment 
 
→Distributed Morphology 536, 538 
inclusiveness 
 
application of (informational) 
→encapsulation to syntax (Chom-
sky 1995a) 612, 648 
indexed constraints 
 
morpheme-specific mini-phonologies 
in OT: parallel vs. reranked incar-
nations 476, 482 
Indirect Reference 
 
→Prosodic Phonology 
 
Prosodic Phonology, but roots in SPE-
readjustment 385 
 
in SPE (cat-rat-cheese) 84 
 
a bad reason: non-isomorphism 416 
 
a good reason for (and against direct 
syntax): modularity 410 
 
and Level Independence 415 
 
modular argument in favour of, absent 
from the literature 414 
 
domain-specificity: syntax, morphol-
ogy, semantics vs. phonology 413
goal for further study: to make carriers 
of morpho-syntactic information 
local AND non-diacritic 366 
inflectional vs. derivational morphology 
 
contrast rejected by →Distributed 
Morphology 546 

Subject index 803 
initial CV 
 
non-diacritic →boundaries exist 44, 
49, 713 
innateness 
 
of modules 627 
inner vs. outer morphology 
 
→Distributed Morphology (Marantz) 
546 
inside-out interpretation 
 
→cyclic derivation 
interactionism 
 
a new idea introduced by Lexical 
Phonology 146 
 
historical overview in syntax and 
phonology 14 
 
in interface theories since SPE: sum-
mary 305, 676 
 
SPE: all concatenation before all inter-
pretation 86 
 
early cases of: Bresnan (1971) 308 
 
Distributed Morphology subscribes: 
derivation by phase 534 
 
when syntax became interactionist: 
derivation by phase 679 
 
enforced by the minimalist concern for 
cognitive resources (active mem-
ory) 305 
 
Optimal Interleaving (Wolf 2008): 
interactionism in OT-CC with one 
single constraint hierarchy that 
merges morphology and phonol-
ogy 472 
 
no contradiction with anti-
derivationalism (summary) 678 
 
anti-interactionism (→Halle & Ver-
gnaud 1987a) 
 
summary 223, 677 
 
anti-interactionist ammunition: 
bracketing paradoxes 243 
 
anti-interactionist strategy: attack 
affix ordering 244 
 
stratal vs. non-interactionist architec-
ture 
 
testing ground 1: lexical phonol-
ogy sensitive to syntactic in-
formation? 252 
 
testing ground 2:  phonology-free 
syntax 253 
interactionism (continued) 
 
anti-interactionism (OT) 
 
→anti-cyclicity in →OT (sum-
mary) 686 
 
and brackets 98 
 
brackets in Lexical Phonology 
undo what was gained by in-
teractionism 170 
 
brackets vs. interactionism (sum-
mary) 673 
 
and modularity 
 
reconciles cyclic derivation and 
modularity 161, 275 
 
makes inside-out interpretation 
compatible with modularity 
(summary) 681 
 
intermodular argument against 
anti-cyclicity in orthodox OT 
856 
interactive 
 
Odden (1993), →interactionism 223 
interface conditions 
 
in minimalism 305 
interface constraints 
 
OT, revival of direct syntax 495 
 
appeal to SPE-type morphological 
diacritics 496 
Interface Dualism 
 
both procedural and representational 
communication is needed 6, 844 
 
parallel with representation vs. compu-
tation in phonology (Anderson 
1985) 8 
 
(summary) 684 
 
why a representational channel is 
needed 685 
 
why a procedural channel is needed 
686 
 
no procedural communication in pre-
generative times 80 
 
idea introduced in SPE 83 
 
post-SPE: only boundaries, no consid-
eration of procedural influence 
138 
 
the general plot was set by the end of 
the 70s 138 
 
dismissed by Kaye (1995): no repre-
sentational channel 276 

804 
Subject index 
Interface Dualism (continued) 
 
random use of both channels is current 
practice in (almost) all theories, 
but probably not the right way to 
go 750f 
 
balance of procedural and representa-
tional analyses: which channel for 
which phenomenon? 320, 749 
 
morpho-syntactic structure may, but 
content (labels) may not bear on 
phonology (?) 752 
 
privativity (representational and pro-
cedural) 756 
interface events 
 
pre-theoretical classification 50 
interface processors 
 
Representational Modularity (Jacken-
doff) 723 
intermodular communication 
 
overview 17 
 
translation 649 
intermodular argumentation 
 
summary 846 
 
can only be made through the proce-
dural channel 850 
 
conditions of: we need to know 
whether morphology and syntax 
are one and the same or two dis-
tinct computational systems 851 
 
potential of interactionist derivation by 
phase: syntax as a referee for com-
peting phonological theories 847 
 
procedural first 320 
 
three referees: the PIC, selective spell-
out and the phase edge 857 
 
convergence of 6 syntactic and phono-
logical mechanisms 853f 
 
interactionism 856 
 
spell-out is selective in syntax, hence it 
must be selective in phonology as 
well 769, 776 
 
import of phonology-based mecha-
nisms into syntax: piece-driven 
phase and the spell-out of termi-
nals 855 
intermodular argumentation (continued) 
 
just one spell-out mechanism (mor-
phology and syntax are the same 
computational system), or two 
(they are not)? 858 
 
morpheme-specific mini-phonologies 
vs. no look-back (PIC): refereed in 
favour of the PIC 830 
intermundia 
 
→PF 
Interonset Government 
 
→Government Phonology, note 82 
(344) 
interpretational units 
 
in SPE: delineated by →brackets 
(→cycles) 103 
 
SPE vs. Lexical Phonology, →phase 
theory (example origin-al-ity) 160
representational (SPE) vs. procedural 
(Lexical Phonology) definition 
161 
 
in Lexical Phonology: defined by 
→strata 160 
 
Halle & Vergnaud (1987a) 226, 242 
 
the root is always one (Halle & Verg-
naud 1987) 230 
 
Kaye (1995): defined by selective 
spell-out 273 
 
Kaye (1995): domains 271 
 
Kaye (1995): words are, roots are not 
(reverse of Halle & Vergnaud 
1987a) 280 
interpretation-neutral affixes 
 
→affix-triggered interpretation 226, 
272f 
interpretation-triggering affixes 
 
→affix-triggered interpretation 
 
idea introduced by Halle & Vergnaud 
(1987a) 220, 226 
 
Kaye (1995) 272f 
 
Kaye (1995): affixes determine the 
spell-out of their sister 274 
 
spell out their mother (Halle & Verg-
naud 1987a) vs. their sister (Kaye 
1995) 282 

Subject index 805 
interpretation-triggering affixes (conti-
nued) 
 
two options: spell-out of the sister or 
of the mother 764 
 
Kaye (1995): class 2 does, class 1 does 
not trigger (reverse of Halle & 
Vergnaud 1987a) 281 
intonation 800 
 
confusion: recursion is a phenomenon 
whose existence is established by 
pre-theoretical properties, not by 
analyses that happen to use recur-
sive constructions 803 
 
intonation may require recursive struc-
ture, but this structure is not built 
by phonological computation 801f
is the calculus of intonation done by 
phonological computation? 801 
 
is not phonological: phonological 
computation does not contribute 
anything (Cinque 1993) 806 
 
absence of mutual conditioning with 
phonology (segmental, word stress 
etc.) 806 
 
can be predicted without knowing 
which lexical material will be in-
serted 806 
 
tone-based analysis (Pierrehumbert) 
802 
inverted T model 
 
general introduction 86 
 
syntactico-centrism: privilege of con-
catenation 25 
 
defines the scope of the book 12, 25 
 
logically independent from "all con-
catenation before all interpreta-
tion" 86, 224 
 
restoration of "all concatenation before 
all interpretation" by Halle & 
Vergnaud (1987a) 223 
 
interface theories beyond the inverted 
T 26 
 
(generative) alternatives: generative 
semantics and Jackendoff's parallel 
modules 29, 720 
 
contrast with LSLT (Chomsky 1955-
56) where all modules have the 
concatenative privilege 625 
inverted T model (continued) 
 
SPE vs. interactionist Lexical Phono-
logy 223 
 
summary interactionist vs. non-
interactionist implementations 305
in GB: subcomponents (inverted T) vs. 
subsystems (GB modules) 631 
 
restored in minimalism after the GB 
interlude 641f 
 
untouched by the new biolinguistic 
delineation of grammar 639 
 
J
junctural minimal pairs 
 
night rate vs. nitrate 63 
 
German (Moulton) 64 
juncture (structuralism) 
 
is multifunctional (simplification): 
serves phonological and morpho-
syntactic purposes (Chomsky et al. 
1956) 77 
 
abuse of 
 
juncture in the middle of mor-
phemes: summary 667 
 
morpho-syntactic control over 
juncture restored: Chomsky et 
al. (1956) 77f 
 
phonetic correlate? 
 
debate in structuralism 70 
 
no: Chomsky et al. (1956), SPE 
78, 88 
 
no: summary 668 
 
open juncture 64 
 
revival of in →Natural Generative 
Phonology 127 
juncture phoneme 
 
motivation: →Level Independence 60
diacritic →translation (summary) 695
phoneme economy 60, 65 
 
environment for predicting allophones
60 
 
different names of (transition, disjunc-
ture, schismeme etc.) 71 
 
suprasegmental phoneme? 70 
 
abuse: in the middle of morphemes? 
 
"accidental" coincidence with 
morpho-syntactic divisions 65
yes: Hill (1954) 69, 667 
 
no: Chomsky et al. (1956) 78 

806 
Subject index 
K
Kaye (1995) 
 
(written) sources are sparse for Kaye's 
theory 260 
 
is modern: modification-inhibiting 
(freezing) →no look-back, 
→phase edge 359 
 
→Interface Dualism dismissed: proce-
dural-only 276 
 
phonetic hypothesis rejected, note 66 
(263) 
 
vowel reduction in English: follows 
SPE, secondary stress protects 336
restoration of SPE (like Halle & Verg-
naud 1987a) 359 
 
summary comparison with Halle & 
Vergnaud (1987a) 286 
 
Licensing Constraints 269 
 
functional and perception-oriented 
approach to the interface 263f 
 
why does phonology exist? Faster, 
more effective and reliable 
communication 263 
 
demarcative function of stress 265
parsing cues 
 
definition 263 
 
theory-dependent (GP): detection 
of empty nuclei 342 
 
theory-independent (clusters) 341
undetected morpheme breaks 345
concat- and φ-function 267 
 
concat function 
 
akin to Merge 268 
 
concat- and φ-function interleaved 
 
contrast between [[X] [Y]] and 
[[X] Y] 337 
 
contrast between [[X] [Y]] and 
[X Y] 336f 
 
φ-function 
 
general properties 269f 
 
no multiple mini-grammars 270 
 
interface-relevant properties of 
270 
Kaye (1995) (continued) 
 
φ-function (continued) 
 
morpho-phonology: most is not 
done by the φ-function, i.e. lies 
outside of phonology 276 
 
selective spell-out 
 
defines interpretational units 273 
 
Kaye's vs. Halle & Vergnaud's 
implementation 277 
 
independent spell-out of terminals: 
a problem 317 
 
multiple mini-grammars (morpheme-
specific and chunk specific) 283 
 
morpheme-specific phonologies 
and selective spell-out are in-
compatible 303 
 
recognises specific word-level 
rules 338 
 
cyclic structure 
 
both spell-out and interpretation 
are cyclic 792 
 
calls on Chomsky's (1973) →Strict 
Cyclicity, but applies some-
thing else 300 
 
cyclic spell-out of words: yes, 
following SPE and Halle & 
Vergnaud (1987a) 285 
 
domain structure 
 
general introduction 266 
 
is the result of selective spell-out 
273 
 
logical possibilities with two mor-
phemes 271 
 
analytic vs. non-analytic do-
mains/morphology/affixes 272
brackets do not exist, they are only 
shorthand for the linear nota-
tion 275 
 
affixes may be lexically defined as 
domains 274 
 
domains that are not created by 
spell-out 274 
 
diachronic erosion of domain 
structure (compounds) 339 

Subject index 807 
Kaye (1995) (continued) 
 
domain structure (continued) 
 
dialectal and idiolectal variation 
due to variable domain struc-
ture 335 
 
interpretational units 271 
 
interpretation-triggering affixes 
spell out their sister (rather 
than their own node as in Halle 
& Vergnaud (1987a) 282 
 
nasal assimilation requires inde-
pendent spell-out of terminals 
314 
 
independent spell-out of terminals
274 
 
independent spell-out of terminals: 
morphological adjuncts and 
counter-cyclic merger 318 
 
words are, roots are not interpreta-
tional units (reverse of Halle & 
Vergnaud 1987a) 280 
 
lexical entries 
 
lexical entries are ordered accord-
ing to phonological structure 
347 
 
full addressing space is created, 
including "empty" slots 350 
 
possible word: blick vs. lbick 349 
 
role of phonological relatedness in 
lexical storage and look-up 
354 
 
structure of lexical entries: keep - 
kept vs. table - house 352f 
 
suppletion: lexical structure of go -
went, look-up 354 
 
lexical access 
 
identification by computation is 
less costly than look-up 355 
 
and acquisition 358 
 
lexical access: look-up vs. com-
pute 351 
 
lexical pointer (= via-rules in 
→Natural Generative Phonol-
ogy) 353 
 
morpheme identification by pars-
ing cues (compute) vs. look-up 
in the lexicon 353 
Kaye (1995) (continued) 
 
lexical access (continued) 
 
morpheme identification with 
hidden morphology (stepped)
356 
 
morpheme identification: different 
paths to identification are more 
or less costly 357f 
 
role of phonological relatedness in 
lexical storage and look-up 
354 
 
affix classes: empirical coverage 310 
 
rule-triggering pattern: cannot be 
done (but English nasal cluster 
simplification can be done) 
322 
 
rule-triggering pattern: the do-
main-final condition 322 
 
rule-triggering pattern, domain-
final condition: no violation of 
modularity (unlike Mohanan's 
→brackets) 323 
 
underapplication: achieved by no 
look-back, comparison with 
other models 279 
 
→affix class-based phenomena 
 
class 2 does, class 1 does not 
trigger interpretation (reverse 
of Halle & Vergnaud 1987a) 
281 
 
cannot do class 2 - class 1 strings 
(bracketing paradoxes,  
govern-mént2-al1) 315, 556 
 
correctly predicts the word-final - 
class 2 disjunction 326 
 
PIC: modification-inhibiting no look-
back 299 
 
how it works 301 
 
Chomsky's "spell-out and forget" 
too strong for phonology: two 
candidates for a weaker ver-
sion 302 
 
derived environment effects are a 
separate issue, no relation with 
no look-back 284 
 
robustness (=no look-back) 279 
 

808 
Subject index 
L
labelled brackets 
 
SPE 95 
labels vs. structure 
 
morpho-syntactic structure may, but 
content (labels) may not bear on 
phonology (?) 752 
language and mind 
 
cognitive realism 624 
Language Faculty 
 
→language organ 
 
linguistics is a subfield of psychology 
(Chomsky) 627 
 
language-internal modularity 
 
→modularity, grammar-internal 
modules and their identifica-
tion 
 
in GB 630 
 
against (Hornstein 2009) 633 
 
→nested modules violate (infor-
mational) →encapsulation 632
language of thought 
 
Fodor (1975) 591 
language organ (Chomsky) 
 
modules are innate 627 
 
double dissociation of language 621 
 
→biolinguistics 
late adjunction 
 
Kaye (1995): independent spell-out of 
terminals 318 
late insertion 
 
argument for a phonological module 
646 
 
in →Distributed Morphology 536 
lateral structure (in phonology) 
 
→deforestation 
length of the string 
 
is prosodic phrasing sensitive to the 
length of the string? 421, note 142 
(577) 
level 
 
also →strata 
 
level 1 rules 
 
→rule-blocking pattern 
 
→Lexical Phonology/ rule-
blocking boundaries 164 
level (continued) 
 
level 2 rules 
 
→rule-triggering pattern 
 
in English, Kaye's (1995) analysis 
based on the domain-final con-
dition 322 
 
Lexical Phonology, rule-triggering 
boundaries 168 
 
level 1 vs. level 2 rules 
 
in Lexical Phonology 149-51 
 
→affix classes, note 32 (142) 
Level Independence 667 
 
survey 60 
 
enforces translation, birth of modular-
ity 700 
 
early expression of (Fodorian) modu-
larity 72 
 
and Indirect Reference 415 
 
induces →juncture phonemes (sum-
mary) 695f 
 
more and less strict application 62 
 
orthodox position (Hockett, Joos, 
Trager) 67 
 
more tolerant views (Pike, Vachek) 68
Z. Harris' ambiguous position 67 
 
abolished by Chomsky et al. (1956) 
(and Halle 1959) 76 
 
revival in →Natural Generative Pho-
nology 127 
level ordering 
 
Lexical Phonology: prohibition to loop 
back to previous →strata 147 
levels of representation 
 
in Cognitive Science 590 
lexical access (→Kaye 1995) 
 
morpheme identification by parsing 
cues 355 
 
morpheme identification with hidden 
morphology (stepped) 356 
 
morpheme identification: different 
paths to identification are more or 
less costly 357f 
 
organised by phonological structure 
347 
lexical entries (→Kaye 1995) 
 
structure of: keep - kept vs. table - 
house 352f 

Subject index 809 
Lexical Faithfulness 
 
revival of the →Elsewhere Condition 
in OT (Cho 2008) 521 
lexical identity rules 
 
→Elsewhere Condition, derived envi-
ronment effects 191 
 
in OT: Elsewhere Condition, derived 
environments 521 
lexical insertion 
 
in Distributed Morphology 536 
Lexical Integrity Hypothesis 
 
offspring of Lexical Phonology: mor-
phology ≠syntax 539 
Lexical Phonology 139 
 
two achievements: →interactionism 
and multiple mini-grammars 212 
 
anti-interactionist version: →Halle & 
Vergnaud (1987a) 215 
 
vs. Distributed Morphology 533 
 
→affix class-based phenomena 
 
→derived environment effects 177 
 
→Strict Cycle Condition (SCC) 
 
relations with Prosodic Phonology: 
→Prosodic Phonology/ relations 
with Lexical Phonology 
 
general architecture 145 
 
general architecture 
 
summary 152 
 
summary: the disastrous patches of 
the 80s (SCC-K, brackets) 214
→interactionism 146 
 
lexical vs. postlexical phonology 
 
general 153 
 
postlexical phonology: birth of the 
idea 154 
 
morphologically conditioned vs. 
automatic application of rules 
156 
 
respective conditioning factors 
157 
 
why is →postlexical phonology 
non-cyclic? 156, 158 
 
→cyclic (=lexical) vs. →non-
cyclic (=postlexical) rules 158
non-cyclic interpretation of word 
sequences imposed without ar-
gument or discussion 791 
Lexical Phonology 139 (continued) 
 
lexical vs. postlexical phonology 
(continued) 
 
lexical →post-cyclic rules (Rubach 
& Booij 1984), →Strict Cycle 
Condition (SCC) 194 
 
maximisation of procedural manage-
ment 140 
 
summary 213 
 
procedural management of affix 
class-based phenomena 162 
 
rule-blocking boundaries = 
→level 1 rules 164 
 
elimination of rule blocking 
boundaries 165 
 
trade-off: elimination of bounda-
ries against domain assignment 
and brackets 165 
 
hybrid representational - proce-
dural theory because of the 
rule-triggering pattern 169 
 
summary: the representational 
residue 214 
 
alliance with Direct Syntax against 
Prosodic Phonology, note 121 
(432) 
 
→derived environment effects and 
→affix classes: orthogonal 182 
 
wrongly accused to violate →Indirect 
Reference (by Inkelas 1990) 433f 
 
→opacity 156f 
 
interpretational units: comparison SPE, 
Lexical Phonology, phase theory 
160 
 
multiple mini-grammars 
 
morpheme-specific (one for class 1 
strings, another for class 2 
strings) 148 
 
one single pool of rules 151 
 
→Lexical Phonology/ lexical vs. 
postlexical phonology 
 
strata (levels) 147 
 
definition 147-52 
 
selective rule application (domain 
assignment): a given rule ap-
plies only at a given stratum 
149 

810 
Subject index 
Lexical Phonology 139 (continued) 
 
strata (levels) 147 (continued) 
 
domain assignment (Stratum Do-
main Hypothesis) 151 
 
level 1 vs. level 2 rules 149-51 
 
underapplication to class 2 strings 
164 
 
level ordering (prohibition to loop 
back into previous strata) 147
classical vs. Halle & Vergnaud 
218 
 
no look-back devices 
 
→Strict Cycle Condition (SCC) 
 
no look-back device: →bracket 
erasure 175 
 
summary no look-back devices 
214 
 
bracket erasure: internal structure 
of words invisible to syntax 
157 
 
brackets & bracket erasure: needed 
for the rule-triggering pattern 
168 
lexical post-cyclic rules (Rubach & Booij 
1984) 
 
→Strict Cycle Condition (SCC) 194 
lexical vs. postlexical phonology 
 
→Lexical Phonology, lexical vs. pos-
tlexical phonology 153 
lexicalism 
 
→anti-lexicalism 
 
initiated by Chomsky (1970), note 34 
(144) 
 
in Lexical Phonology 155 
 
Distributed Morphology 539 
 
in phonology and syntax (of the 80s) 
126 
 
position of Kaye (1995) regarding 
cyclic spell-out of words 285 
 
relations with no look-back: antidotes 
against overgeneration in the 70s 
288 
 
→Strict Cycle Condition (SCC) 192 
Lexicon 
 
in Lexical Phonology: rejected by 
Distributed Morphology 534f 
licensing 
 
→government 
 
→Government Phonology 705 
Licensing Constraints 
 
Kaye (1995) 269 
Linear Correspondence Axiom (LCA, 
Kayne 1994) 742, 744f 
linearisation 741 
 
→PF 
 
the input to phonological computation 
is linear 742 
 
both syntax-internal and syntax-
external linearisation is minimal-
ism-compatible 744 
 
in →minimalism: no business of syn-
tax 743 
 
no business of phonology, therefore 
not discussed in syntactic quarters, 
but not in interface theories (which 
are made by phonologists) 742 
 
everybody but Kayne does linearisa-
tion "at PF" 745 
 
until GB: a function of constituent 
order, the head parameter 743 
 
head parameter revived in PF-based 
linearisation strategies 745 
 
if spell-out from narrow syntax linear-
ises, in which way can the result be 
a PF-movement tree? 738 
 
broad consensus: result of different 
serially ordered operations 745 
 
Distributed Morphology 
 
concomitant with vocabulary 
insertion (DM) 745 
 
Lin and Concatenate 745 
 
Richards (2004, 2007) 
 
desymmetrisation 745 
 
Epstein et al. (1998), Richards (2004, 
2007) 
 
Precedence Resolution Principle 
745 
 
Bobaljik (2002) 
 
precedence rules 745 
 
Idsardi & Raimy (forth) 
 
in three steps: phonology plus two 
distinct PF-modules 740 

Subject index 811 
linearisation 741 (continued) 
 
of phonological structure (Raimy)? 
746 
loanword phonology, note 54 (212) 
 
analysis with co-phonologies 479 
local vs. domain-based carriers of morpho-
syntactic information 
 
definition and properties of the two 
world views 707 
 
juncture phonemes & boundaries vs. 
prosodic constituency (summary) 
706 
 
transition boundaries > prosodic con-
stituency (summary) 711 
 
representational intervention in pho-
nology: McCawley's (1968) early 
linear notation of domains 115 
 
alternatives to prosodic constituency 
never discussed 689 
 
translation of one into the other always 
possible 708 
 
just notational variants? 115 
 
arguments against domains 712-17 
 
domains are necessarily diacritic 
 
prosodic word and higher prosodic 
constituents are the projection 
of nothing 715 
 
top-down constructions are dia-
critic by definition 714 
 
syllable and feet are entirely de-
termined by their terminals 
716 
 
only local boundaries can be non-
diacritic: syllabic space is the solu-
tion 717 
localisation of cognitive functions 614 
 
origins: phrenology (F-J Gall), correla-
tion with areas on the skull bone 
601f 
 
strategy: levels intermediate between 
symbolic representations and neu-
robiology: connectionism, Poep-
pel's circuits 616 
locality conditions 
 
in phonology and syntax 705 
long term (declarative) memory 596 
look-ahead 
 
prohibited in structuralist discovery 
procedure 667 
loop 
 
back to previous strata: prohibition in 
Lexical Phonology 147 
low level processes 
 
→Alternation Condition/ exceptions 
of: automatic, low level, "pho-
netic" processes 186 
 
M
Magic Licensing 
 
Government Phonology, note 82 (344)
mapping 
 
→Prosodic Phonology 
 
in SPE: general mapping algorithm 90
comparison SPE - Prosodic Phonology
385 
 
split mapping enforced by Nespor & 
Vogel's (1986) peaceful coexis-
tence with Lexical Phonology 439
phonology can see morpho-syntactic 
(tree) structure, but not its labels 
398 
 
in Prosodic Phonology (rule-based) 
386 
 
mapping and cross-linguistic varia-
tion: progressive parameterisa-
tion of mapping rules 388 
 
variation regarding ω and φ 390f 
 
extended to units of the Prosodic Hier-
archy below the word level: moras, 
syllables, feet 448 
 
OT: constraint-based (parallel) map-
ping 457 
 
effect achieved by interspersing 
ALIGN with regular phonologi-
cal constraints 459 
 
overgeneration not discussed 460, 
463 
 
variation: factorial typology of 
ALIGN and WRAP 460, 463 
 
phase-based mapping (Kratzer & 
Selkirk 2007) 462 
mapping puzzle 
 
general introduction 111 
 
summary 753 
 
and (functional) →Grenzsignale 57 
 
post-SPE: alas, there are no natural 
classes of boundaries 111 
 
Prosodic Phonology 387, 393, 396 

812 
Subject index 
mapping puzzle (continued) 
 
in Prosodic Phonology: the black box 
380 
 
OT: no advance, but focus on new 
factors 463, 530 
melody 
 
incommunicado with morpho-syntax 
660 
 
privative representations 44 
melody-free syntax 
 
rather than →phonology-free syntax 
412 
memory 
 
short/long term, working, declarative 
596 
 
active, short term 
 
limitations of: motivation for 
→derivation by phase 305 
 
→minimalist perspective: concern 
for extra-linguistic factors and 
the →economy of cognitive re-
sources 305 
 
role in →lexical access (look-up) 
(Kaye 1995) 354 
 
trade-off between active memory 
economy achieved by the →PIC 
and the need for a memory-keeper
799 
memory keeper 
 
who decides to ignore "old" strings? 
(→spell-out mechanism) 21, 307, 
799 
mentalism (rationalism) 
 
vs. empiricism 591 
Merge 
 
direct merge in →Distributed Mor-
phology 543 
 
early expression in LSLT (Chomsky 
1955-56) 625f 
 
concat function, →Kaye (1995) 268 
metrical grid 
 
Halle & Vergnaud (1987a) 237 
 
Halle & Vergnaud (1987a), →Stress 
Copy 231 
 
Halle & Kenstowicz (1991), compen-
sation vs. condensation 549 
metrical structure (foot structure) 
 
early modification-inhibiting no look-
back: Free Element Condition 295
metrical trees (s/w) 
 
competition with the metrical grid, 
note 119 (424) 
mind and brain 
 
relationship 588, 590, 615f, note 156 
(627) 
Minimal Indirect Reference 
 
Seidl (2001): hybrid model allowing 
for both direct syntax and prosodic
constituency 
minimalism 
 
shrinks syntax 728 
 
effects on →PF 
 
pumps up PF 729 
 
PF is the minimalist dustbin 31 
 
the minimalism-born intermundia 
(the part of PF that is not pho-
nology) violates domain speci-
ficity 738 
 
concern for cognitive resources (active 
→memory) enforces 
→interactionism (i.e. →derivation 
by phase) 305 
 
does away with GB-modules 638 
 
linearity is not a property of syntax 
743 
 
third factor explanations 638 
Minimality Condition 
 
in phonology 705 
mini-phonologies 
 
→computational systems 
modification-inhibiting no look-back 
 
→no look-back devices 
modularity 586 
 
vs. →connectionism 
 
two competing theories of how the 
cognitive system works 588 
 
bridging literature that aims at 
reconciliation 599 
 
early days: complementary (a 
question of levels), rather than 
incompatible 599 
 
→intermodular argumentation 
 
prism used in this book in order to 
look at the interface 844 
 
core properties of modules 610 
 
is dualistic and rationalist/mentalist 
(philosophy) 591 
 
mind - brain relationship 588, 614 

Subject index 813 
modularity 586 (continued) 
 
offers control that is maximally inde-
pendent from phonology 40 
 
phonology-free syntax 645 
 
localisation of cognitive functions in 
the brain 614 
 
how are modules identified? 
 
→domain specificity, 
→encapsulation 610 
 
→double dissociation 618 
 
properties of modules: input-
output, non-teleological etc. 
605 
 
(informational) encapsulation 612 
 
nested modules: violation of en-
capsulation? 632 
 
PF as a set of nested modules 
violates encapsulation 738 
 
domain specificity 611 
 
in Rotenberg (1978): phonology 
interprets phonological objects, 
not bananas 373 
 
computation is computation of 
something 598 
 
origins: phrenology (F-J Gall) 600ff 
 
modularity is the heir of phrenol-
ogy (Fodor 1983) 602 
 
cognitive functions, higher (hori-
zontal) and lower (vertical), 
how are they identified? 605 
 
Fodor (1983) 
 
Fodor's faculty psychology mar-
ried with →computation the-
ory (Turing-von Neumann) 
603 
 
language is a modular cognitive 
function (as opposed to a cen-
tral system) 624 
 
modules are biologically real and 
innate 627 
 
Descartes, Fodor & Chomsky vs. 
Darwin, Pinker & Jackendoff 
 
two camps: some properties of the 
mind remain forever unintelli-
gible (Descartes, Fodor, 
Chomsky) vs. everything is ac-
cessible to human reason 
(Pinker, Plotkin, Sperber, 
Smith) 608 
modularity 586 (continued) 
 
Descartes, Fodor & Chomsky vs. 
Darwin, Pinker & Jackendoff (con-
tinued) 
 
peripheral (Fodor, Chomsky) vs. 
massive (Pinker, Plotkin, evo-
lutionary psychology) modu-
larity: is there a non-modular 
core? 606 
 
central system made of modules? 
605 
 
evolutionary psychology 609 
 
is the mind (are modules) the result 
of Darwinian adaptation? 609
communication among modules 649 
 
translation always practised, even 
in absence of modular back-
ground 693 
 
is the →spell-out mechanism a 
module? 799 
 
is the interface a(n) (intelligent) 
module (Jackendoff)? 23 
 
of vocabulary (input) vs. structure 
(result of modular activity) 
652 
 
phonology can see morpho-
syntactic (tree) structure, but 
not its labels 398 
 
of and in language 622 
 
grammar-internal modules and their 
identification 628 
 
→Language Faculty 
 
→nested modules 
 
identification of language-related 
modules by double dissocia-
tion 642 
 
baseline of the 60s: the inverted T 
629 
 
phonology is distinct: domain 
specificity (Jackendoff, Chom-
sky) 644 
 
syntax vs. semantics, two distinct 
modules (Newmeyer 2006, 
Higginbotham 1987) 642 
 
two macro-modules: phonology vs. 
morpho-syntax-semantics 
(Starke) 643 

814 
Subject index 
modularity 586 (continued) 
 
referee for interface theories 33, 37, 
39 
refereeing potential of lies waste in 
the 80s (summary) 682 
 
settled in verb, but not in practice 
690 
 
is the generative baseline 725 
 
if wrong, the generative enterprise 
must be rethought 524 
 
one of the deepest layers of gen-
erative thinking 37 
 
surprisingly absent from the (gen-
erative) interface literature and 
theory design 587, 844 
 
in the history of generative grammar 
38 
 
in early generative grammar 623 
 
early expression in generative 
linguistics: the "levels" of 
LSLT 625 
 
input-output device (Chomsky & 
Miller 1963) 626 
 
from LSLT (Chomsky 1955-56) to 
the inverted T and SPE 625f 
 
all modules have the concatenative 
privilege in LSLT (Chomsky 
1955-56) 625 
 
in SPE 84 
 
definition of phonology, a forerun-
ner of Fodorian modules 613 
 
in Lexical Phonology 
 
violated by the reintroduction of 
brackets 170 
 
in GB 
 
subcomponents (→inverted T) vs. 
subsystems (GB modules) 631
are GB-subtheories cognitive 
modules? 632 
 
GB modules introduced without 
reference to the modularity of 
the cognitive system 630 
 
GB subtheories and their percep-
tion as cognitive modules 628, 
635 
 
perception of GB-modules in non-
linguistic quarters: puzzlement
636 
modularity 586 (continued) 
 
in OT 523 
 
OT is a strong modularity offender
524 
 
connectionist roots of OT: the D of 
PDP (→Parallel Distributed 
Processing) induces the viola-
tion of modularity 599 
 
radical scrambling in OT-CC: one 
ranking for phonology and 
morphology (Wolf 2008) 472 
 
rarely discussed in OT 524 
 
violation: direct syntax 525 
 
violation: mapping done in the 
phonology 454, 526 
 
violation: morpho-phonological 
scrambling among constraints 
and within their body 527 
 
in Distributed Morphology 
 
DM is a strong modularity of-
fender: PF movement, phonol-
ogy interleaved with non-
phonological PF operations 
(→linearisation) 32, 580, 739 
 
in minimalism & biolinguistics 
 
minimalism does away with GB-
modules 638 
 
against language-internal modular-
ity (Hornstein 2009) 633 
 
biolinguistics: grammar reduces to 
morpho-syntax, PF and LF are 
neither language- nor species-
specific 639 
 
→inverted T untouched by the 
new biolinguistic delineation 
of grammar 639 
 
trying to make sense of PF from 
the modular point of view 736
the minimalism-born PF intermun-
dia violates →domain specific-
ity 738 
 
Idsardi & Raimy (forth) 
 
modules after syntax: phonology 
plus two distinct PF-modules, 
related by a three-step 
→linearisation 740 

Subject index 815 
modularity 586 (continued) 
 
generative modularity offenders 
 
summary 702 
 
typology of modularity offenders 
704 
 
modularity offenders: labelled 
brackets (SPE) 98f 
 
violated by the reintroduction of 
brackets (Lexical Phonology) 
170 
 
OT is a strong modularity offender
524 
 
OT, induced by the D of PDP 
(Parallel Distributed Process-
ing) 599 
 
violated in OT: →direct syntax 
525 
 
violated in OT: mapping done in 
the phonology 454, 526 
 
violated in OT: morpho-
phonological scrambling 
among constraints and within 
their body 527 
 
radical scrambling in OT-CC: one 
ranking for phonology and 
morphology (Wolf 2008) 472 
 
DM is a strong modularity of-
fender: phonology interleaved 
with non-phonological PF op-
erations (→linearisation) 739 
 
PF movement 32, 580 
 
the minimalism-born PF intermun-
dia violates domain specificity
738 
 
violated by Structural Analogy? 
705 
modularity offenders 
 
summary 702 
 
→modularity/ generative modularity 
offenders 
monism vs. dualism 591 
monostratalism 
 
in Sign-Based Morphology 513 
 
Coloured Containment (Oostendorp) 
510 
 
in OT: radical scrambling, one ranking 
for everything (Russell) 528 
morpheme recognition 
 
→parsing cues (→Kaye 1995) 263 
morpheme-specific phonologies 
 
→computational systems 
morphological adjuncts 
 
Kaye (1995): independent spell-out of 
terminals 318 
Morphological Merger 
 
Marantz (1984), forerunner of →PF 
Movement 580 
morphology vs. syntax 
 
morphology ≠syntax 
 
Lexical Phonology: distinct com-
putational systems 155 
 
same computational system: 
Sproat (1985), Halle & Verg-
naud (1987a) 223 
 
distinct engines enforced by Nes-
por & Vogel's (1986) peaceful 
coexistence with Lexical Pho-
nology 439 
 
morphology = syntax 
 
Distributed Morphology 534f, 537
Lexical Integrity Hypothesis, 
contra Distributed Morphology
539 
 
ancestor of DM: Selkirk (1984) 
(contra Lexical Phonology) 
432, 540 
 
phonology-free syntax or morpho-
syntax? 412 
 
just one spell-out mechanism (mor-
phology and syntax are the same 
computational system), or two 
(they are not)? 858 
 
one or two engines is decisive for an 
argument against non-selective 
spell-out 769 
 
spell-out your sister! (→phase edge) 
applies to all chunk sizes 766 
morpho-phoneme 
 
structuralism 62 
morpho-phonology 
 
SPE: common underlying form for 
heart - cardiac etc. 126 
 
position of Lexical Phonology 156 
 
Kaye's (1995) take in his procedural-
only system 276 
multiple exponence 
 
allomorphy (Lowenstamm 2008), note 
140 (571) 

816 
Subject index 
multiple mini-grammars 
 
→computational systems 
multiple spell-out 
 
→derivation by phase 
 
N
natural classes of boundaries 
 
→mapping puzzle 111 
Natural Generative Phonology 
 
phonetic boundaries 127 
 
boundaries have a phonetic correlate 
669f 
 
boundary abuse in Natural Generative 
Phonology 127 
 
reference to in OT (Green 2007) 527 
 
revival of structuralist →Level Inde-
pendence 127 
NDEB (nonderived environment blocking, 
Kiparsky 1993) 
 
→Strict Cycle Condition, →derived 
environment effects 196 
nested modules 
 
violate (informational) encapsulation 
632, 738 
 
language-internal modularity 
 
→modularity/ grammar-internal 
modules and their identifica-
tion 
 
→Language Faculty 
Neumann, John von 
 
improved the Turing machine 595f, 
603 
neural networks (→connectionism) 
 
artificial neural networks 591 
 
how they work 595 
 
activation value of a neuron 595 
 
connection weight 595 
neuropsychology 611 
New Synthesis Psychology 
 
Pinker, Plotkin 607 
new vs. old (strings, properties) 
 
→no look-back devices/ modification-
inhibiting no look-back 307 
no escape from syntax 
 
slogan of Marantz' (Distributed Mor-
phology) 535 
no look-back devices 
 
→computational systems/ chunk-
specific phonologies 
 
→Strict Cycle Condition (SCC) 
 
→Phase Impenetrability Condition/ 
PIC à la carte (chunk-specific) 
 
→Phase Impenetrability Condition/ 
PIC à la carte (process-specific) 
 
overview 16 
 
summary 783 
 
vs. →morpheme-specific mini-
phonologies (LP): a major front 
line 829 
 
→morpheme-specific mini-
phonologies vs. no look-back 
(PIC): refereed in favour of the 
→PIC 830 
 
the old vs. the new 
 
overview 307 
 
who identifies old and new por-
tions of the string? 797-99 
 
history since Chomsky (1973) 287 
 
absent in SPE 176 
 
origin in the early 70s: reaction 
against overgeneration 288 
 
Chomsky's (1973) →Strict Cycle 
Condition imported into pho-
nology: Kean (1974), Mascaró 
(1976) 189f 
 
Head Constraint (Riemsdijk 1978)
298 
 
in Lexical Phonology: bracket 
erasure 157, 175 
 
Mohanan's brackets vs. Kiparsky's 
→SCC-K 203 
 
summary in Lexical Phonology 
214 
 
relation of Mohanan's bracket 
erasure with other no look-
back devices 292 

Subject index 817 
no look-back devices (continued) 
 
history since Chomsky (1973) 287 
(continued) 
 
SCC-K in Halle & Vergnaud 
(1987a) 237 
 
general presentation of →Phase 
Impenetrability 304 
 
modification-inhibiting no look-back 
 
first timid steps in the 70s and 80s
293 
 
early (70s): Riemsdijks' (1978) 
Head Constraint 298 
 
early (80s): Free Element Condi-
tion (FEC) 295 
 
early (80s): structure preservation 
295 
 
→Kaye (1995): "don't undo!" 299
and domain-final empty nuclei 
332 
 
motivates the phase edge in syntax 
and phonology (→Kaye 1995)
766 
 
process-specific no look-back 
 
which processes do, which do not 
violate the SCC and no look-
back? 186, 315 
 
typically violated by stress as-
signment 315 
 
Chomsky's "spell-out and forget" 
too strong for phonology: two 
candidates for a weaker ver-
sion 302 
 
stress: Free Element Condition 
(FEC) 296 
 
stress: Marvin (2002) in Distrib-
uted Morphology 554 
 
English: stress (word-bound) vs. 
flapping (cross-word) 241 
 
relevant barrier: the word 239, 
257 
 
PIC 
 
also applies to phonology, but 
Chomsky senses it is too 
strong a condition on phono-
logical computation 306, 780, 
797, 826 
no look-back devices (continued) 
 
PIC (continued) 
 
Chomsky's "spell-out and forget" 
too strong for phonology: two 
candidates for a weaker ver-
sion, process-specific PIC and 
Kaye's "don't undo!" 302, 825
no reference made by modern 
phase theory to previous pho-
nological (and syntactic) im-
plementations 309 
 
no confusion with Kiparsky's SCC
195 
 
PIC à la carte 
 
summary 823 
 
process- and chunk-specificity 
826 
 
is computational →economy à la 
carte, not a very minimalistic 
take 780, 797, 826, 830 
non-analytic vs. analytic (domains, mor-
phology, affixes) 
 
→Kaye (1995) 272 
non-cyclic affixes 
 
→Halle & Vergnaud (1987a), affix-
triggered interpretation 
 
Halle & Vergnaud (1987a), = word-
level rules in SPE 219, 233 
non-isomorphism 
 
→Prosodic Phonology 416, 580, 709 
 
the classical example: cat-rat-cheese 
418 
 
in the Prosodic Phonology literature, 
motivation for Indirect Reference 
417 
 
is a fact about domains, not about 
language: it evaporates when (lo-
cal) boundaries are used 419 
 
and privativity 759 
 
domain abuse: confusing data and 
domain-based interpretation 420 
Nuclear Stress Rule (NSR) 
 
early cases of →selective spell-out: 
Bresnan (1971) 308 
 
eliminated by Cinque (1993): 
→intonation is a purely syntactic 
matter 806 

818 
Subject index 
number sense 
 
→double dissociation 620 
 
O
old vs. new (strings, properties) 
 
→no look-back devices/ modification-
inhibiting no look-back, →Phase 
Impenetrability 307, 797-99 
 
Coloured Containment (Oostendorp) 
505, 507 
One-channel translation 
 
→Direct Interface 23, 49 
opacity 
 
predictable vs. unpredictable 561f, 
568 
 
result of distinct geometric properties 
(DM) vs. distinct computation 
(everywhere else) 582 
 
selective spell-out and the PIC fare 
better than Marantz' →direct 
merge 563 
 
in Lexical Phonology 156f 
 
in OT 
 
opacity killers (and cyclicity) 
killers 475 
 
in Distributed Morphology 541 
 
result of structure, rather than of 
computation (Distributed Mor-
phology, Marantz) 542 
 
result of direct merge to a root 
(merge to an xP produces 
transparency) 544 
 
direct merge vs. selective spell-out 
+ PIC (summary) 542, 582 
 
concomitance of LF- and PF opac-
ity (summary) 583 
 
PF - LF opacity: all combinations 
attested 565 
 
combinations of PF - LF opacity: 
neither the PIC nor direct 
merge can account for all pat-
terns 566 
 
PF vs. LF opacity: maybe not the 
same thing 562 
 
LF opacity 542 
 
does not exist in a lexicalist per-
spective: cómparable - com-
párable 573 
opacity (continued) 
 
in Distributed Morphology 541 
(continued) 
 
predictable = PIC, unpredictable = 
direct merge? 568 
 
in Coloured Containment (Oostendorp)
508 
Opacity Principle 
 
Mohanan (1982), note 44 (168) 
opaque 
 
stress placement (English) 311 
open juncture 
 
→juncture 
Optimal Interleaving 
 
Wolf (2008) (OT-CC): revival of 
interactionism with one single con-
straint hierarchy that merges mor-
phology and phonology 472 
Optimality Theory 
 
connectionist roots 28, 529, 678 
 
like connectionism, has no genuine 
symbolic vocabulary 28, 452 
 
mapping 
 
constraint-based (vs. rule-based) 
455, 457 
 
phase-based (Kratzer & Selkirk 
2007) 462 
 
status of representations 
 
representations marshalled by 
constraints 453 
 
non-mainstream work where rep-
resentations (which are not 
"emergent") are independent of 
computation 8 
 
computation in OT 269 
 
anti-cyclicity (anti-derivationalism) 28
overview 454 
 
cyclic derivation rejected 466, 468
cyclic derivation (interface) ≠
phonological computation 470
OT less anti-derivational now than 
it used to be note 127 (454), 
686 
 
opacity killers and cyclicity killers
475 
 
cyclicity killers 
 
co-phonologies 478 
 
indexed constraints 482 

Subject index 819 
Optimality Theory (continued) 
 
cyclicity killers (continued) 
 
Interface Constraints 494 
 
OO-correspondence 497 
 
direct syntax 494, 501 
 
→derived environment effects 516 
 
violates modularity 
 
summary 523 
 
misty relationship with modularity
28 
 
systematic violation of →Indirect 
Reference 28 
 
multiple, unreflected and system-
atic violation of modularity 
471 
 
happy coexistence of prosodic 
constituency and direct syntax
525 
 
issue rarely discussed 524 
 
Stratal OT favours clear-cut modu-
lar contours, but still violates 
modularity 527 
 
direct syntax 525 
 
scrambling trope: morpho-
phonological scrambling 
among constraints and within 
their body 28, 527 
 
scrambling trope in OT-CC: one 
ranking for phonology and 
morphology (Wolf 2008) 472 
 
scrambling trope: mapping done 
IN the phonological computa-
tion: ALIGN 28, 457, 526 
radical scrambling: one ranking for 
phonology, morphology and 
syntax (Russell) 528 
 
morpheme-specific mini-phonologies 
473 
 
parallel (co-phonologies, indexed 
constraints) vs. reranked incar-
nations (Stratal OT/DOT) 476
reranking (Stratal OT, DOT) 476 
 
serial vs. parallel implementations 
of morpheme-specific pho-
nologies: arguments are miss-
ing 484 
 
co-phonologies 478 
 
indexed constraints 482 
 
reranked (Stratal OT, DOT) 483 
OT-CC 
 
OT less anti-derivational now than it 
used to be, note 68 (269), 686 
 
Optimal Interleaving (Wolf 2008): 
revival of interactionism with one 
single constraint hierarchy that 
merges morphology and phonol-
ogy 472 
outer vs. inner morphology 
 
Distributed Morphology (Marantz) 
546 
Output-Output correspondence 
 
designed as a cyclicity killer, but 
cannot do the job alone 497 
 
used for derived environment effects in 
OT 519 
overgeneration 
 
→abstractness debate 144 
 
Kiparsky's revisionist position 144 
 
antidote in the early 70s: →no look-
back 288 
 
of →PF movement 580 
 
P
paradigmatic gaps 
 
produced by root-based (as opposed to 
word-based) morphology 546 
Parallel Distributed Processing (PDP) 
 
connectionism 597, 599 
parallel modules (Jackendoff) 
 
contrast with inverted T 29 
 
alternative to the inverted T model 
722 
 
implementation by Bendjaballah & 
Haiden 724 
parsing 
 
analysis of →affix class-based phe-
nomena by Fabb (1988) and Hay 
(2002) based on selectional proper-
ties of affixes, perception, parsing 
247 
parsing cues 
 
→Grenzsignale (Trubetzkoy) 
 
functional and perception-oriented 
approach to the interface 263f 
 
Kaye (1995) 263 
 
theory-independent (clusters) 341
theory-dependent (GP): detection 
of empty nuclei 342 

820 
Subject index 
parsing cues (continued) 
 
Kaye (1995) 263 (continued) 
 
undetected morpheme breaks 345
morpheme identification by (com-
pute) vs. look-up in the lexicon
353 
 
processes that typically act as 
boundary detectors 265 
parsing device 
 
cyclic derivation (inside-out) 675 
particle physics 592 
perception 
 
analysis of affix class-based phenom-
ena by Fabb (1988) and Hay 
(2002) based on selectional proper-
ties of affixes, perception, parsing 
247 
perception-oriented theories of phonology 
and the interface 
 
→Kaye (1995), →Grenzsignale (Tru-
betzkoy) 264 
percolation of lexical properties of affixes 
to the morpho-syntactic tree 
 
Halle & Vergnaud (1987a) 227 
performance 
 
→competence 
Peripherality Condition 
 
no extra-Xal elements morpheme-
internally, note 106 (400) 
PET (Positron Emission Tomography) 
 
localisation of cognitive functions in 
the brain 617 
PF 726 
 
clean syntax, dirty PF (phonology)? 
727 
 
what exactly do we gain? 31, 747 
 
genesis and evolution 
 
summary: a minimalism-born 
monster whose contours and 
function are murky 31, 747 
 
the minimalism-born intermundia 
violates →domain specificity 
738 
 
evolution of: coextensive with 
phonology until minimalism, 
then loaded with a lot of non-
phonological things 729 
 
minimalism shrinks (narrow) 
syntax and pumps up PF 728f
PF 726 (continued) 
 
definition 
 
PF ≠phonology 23, 31 
 
(minimalist) PF = phonology + 
"something", but nobody 
knows what the "something" 
really is 729 
 
(minimalist) PF ≠what phonolo-
gists call phonology 729 
 
incommunication and misunder-
standing: the syntacticians' 
phonology has got nothing to 
do with what phonologists call 
phonology 730f 
 
confusion and mistiness in Chom-
sky's writings: what does PF 
mean, what does it contain? 
732 
 
Phonetic Form or Phonological 
Form? a confusion that is not 
innocent 732 
 
content 
 
operations that syntacticians want 
PF to do, and restrictions on 
these operations 735 
 
case of PF-outsourcing: clitic 
placement 730 
 
used as a dustbin by syntacticians 
729f 
 
properties of PF: what kind of 
animals live in the intermun-
dia? 733 
 
if spell-out from narrow syntax 
linearises, in which way can 
the result be a PF-movement 
tree? 738 
 
internal structure 
 
is a set of serially ordered compu-
tational systems 737 
 
the "PF branch" (Distributed Mor-
phology) 734 
 
Idsardi & Raimy (forth): phonol-
ogy plus two distinct PF-
modules, related by a three-
step linearisation 740 
 
and modularity 
 
trying to make sense of PF from 
the modular point of view 736

Subject index 821 
PF 726 (continued) 
 
and modularity (continued) 
 
DM is a strong modularity of-
fender: phonology interleaved 
with non-phonological PF op-
erations 739 
PF movement (DM) 
 
Distributed Morphology 574 
 
instrument of the →minimalist phi-
losophy: (narrow) syntax shrunk, 
→PF pumped up 575 
 
syntactic motivation 575 
 
phonological motivation: phonology 
impacts syntax 577 
 
violates modularity (domain specifici-
ty) 580, 738 
 
challenges phonology-free syntax 577
undermines DM's claim that syntax = 
morphology 
 
introduces distinct syntactic and 
morphological Merge 538, 
580 
 
if spell-out from narrow syntax linear-
ises, in which way can the result be 
a PF-movement tree? 738 
 
morpho-syntactic well-formedness is 
determined by phonological con-
tent (Lowenstamm 2008) 579 
 
syntactic trees with phonological 
terminals: Lowenstamm (2008) 
579 
 
phonology-internal triggers (syntacti-
cally undetectable, Piggott & 
Newell 2006 on Ojibwa) 578 
phase boundary 
 
→phase theory 
phase edge 
 
early modification-inhibiting no look-
back: Head Constraint (Riemsdijk 
1978) 298 
 
in syntax and in phonology (Kaye 
1995): spell-out your sister! 765 
 
referee for competing phonological 
theories (intermodular argumenta-
tion) 857 
Phase Extension (den Dikken 2007) 
 
→phase theory 781 
phase head 
 
→phase theory 
phasehood 
 
→phase theory 
Phase Impenetrability Condition (PIC) 
 
→no look-back devices 
 
→computational systems 
 
history of: modification-inhibiting no 
look-back 
 
→no look-back devices/ modifica-
tion-inhibiting no look-back 
 
general presentation 304 
 
instrument of active memory 
economy 306 
 
managed by the spell-out mecha-
nism (not by syntax or phonol-
ogy) 799 
 
the old vs. the new, memory-
keeper: who identifies old and 
new portions of the string? 
307, 797-99 
 
no reference made by modern 
phase theory to previous pho-
nological (and syntactic) im-
plementations 309 
 
no confusion with Kiparsky's SCC
195 
 
also applies to phonology, but Chom-
sky senses it is too strong a condi-
tion on phonological computation 
306, 780, 797, 826 
 
Chomsky's "spell-out and forget" 
too strong for phonology: two 
candidates for a weaker ver-
sion, process-specific PIC and 
Kaye's "don't undo!" 302, 825
referee for competing phonological 
theories (→intermodular argumen-
tation) 857 
 
argument in favour of →selective 
spell-out 770 
 
in Distributed Morphology: spell-out 
at every xP is much too strong a 
claim 555 

822 
Subject index 
Phase Impenetrability Condition (PIC) 
(continued) 
 
PIC à la carte 
 
two types of PIC à la carte: proc-
ess-specific and chunk-specific
797-99 
 
process- and chunk-specificity: 
summary 823, 826 
 
is computational →economy à la 
carte: not a very minimalistic 
move? 780, 797, 826, 830 
 
PIC à la carte (process-specific) 
 
→no look-back devices/ process-
specific no look-back 
 
summary 780 
 
in syntax: long distance Agree 780
Distributed Morphology (Marvin 
2002) 555 
 
PIC à la carte (chunk-specific) 
 
summary 809 
 
PIC à la carte vs. →Praguian 
segregation 818-27 
 
(chunk-specific) PIC à la carte in 
Samuels (2009a), but hidden 
by a specific formulation 798 
phase theory 
 
→no look-back devices 
 
→Phase Impenetrability Condition 
(PIC) 
 
→derivation by phase 
 
→interactionism 
 
→selective spell-out 
 
general presentation 304, 771 
 
convergence between phonological 
and morpho-syntactic evidence for 
phase boundaries? 19 
 
independent PF and LF phases (asym-
metric spell-out)? 567, 779 
 
voices against phase theory 772 
 
history 
 
phase in early generative grammar: 
LSLT (Chomsky 1955-56) 
625 
 
delineation of interpretational 
units: SPE and Lexical Pho-
nology 160 
phase theory (continued) 
 
history (continued) 
 
no reference made by modern 
phase theory to previous pho-
nological (and syntactic) im-
plementations 309 
 
evolution in syntax 19, 771 
 
phasehood (phase head) 
 
trend towards atomisation 775 
 
atomisation marshalled by the anti-
locality of movement 777 
 
convergence-based phasehood 
(Svenonius 2001), note 178 
(781) 
 
extra-syntactic control called into 
question 774 
 
extra-syntactic criteria for identify-
ing phases ("independence", 
propositionality) 774 
 
is there a lower limit for atomisa-
tion? 776 
 
node-driven phase 774 
 
parameterised (Gallego 2010) 775
Phase Extension (den Dikken 
2007) 781 
 
phasehood as a projection of a 
lexical (phasehood) feature 
782 
 
phasehood in Distributed Morphology
DM has a peculiar way to do 
→selective spell-out: func-
tional (yes) vs. non-functional 
heads (no) 558 
 
all xPs (categorisers) are phase 
heads 555 
 
functional heads (VoiceP etc.) are 
not phase heads, hence DM ≠
spell-out-as-you-merge (Ep-
stein) 555 
 
the DM take (every xP is a phase 
head) does not allow to ac-
count for affix class-based 
phenomena 583 
 
different distribution of phasehood 
below and above the word 
level 559 

Subject index 823 
phase theory (continued) 
 
phase boundaries 
 
convergence between phonological 
and morpho-syntactic evidence 
for phase boundaries? 19 
 
phase-based mapping (Kratzer & 
Selkirk 2007) 462 
 
phase edge 
 
early modification-inhibiting no 
look-back: Head Constraint 
(Riemsdijk 1978) 298 
 
in syntax and in phonology (Kaye 
1995): spell-out your sister! 
765 
 
referee for competing phonological 
theories (intermodular argu-
mentation) 857 
 
node-driven vs. piece-driven phase 
767 
 
Phase Extension (den Dikken 
2007) 781 
 
unification by a phasehood feature
782 
phi-function 
 
→Kaye (1995) 267 
phone 
 
structuralism 62 
phoneme 
 
structuralism 62 
phonemic clause 
 
phonological domain (Chomsky et al. 
1956) 75 
phonetic boundaries 
 
Natural Generative Phonology 127 
phonetic correlate of morpho-syntactic 
information 
 
→juncture 
 
there is no (summary) 668 
phonetic hypothesis 
 
rejected by Kaye (1995), note 66 (263)
phonetics vs. phonology 
 
the same or distinct modules? Domain 
specificity 647 
"phonetic" rules 
 
→Alternation condition/ exceptions of
→Strict Cycle Condition (SCC) 186, 
193 
phonological cycle 
 
→cyclic derivation 
 
term coined by Mascaró (1976), re-
placing SPE's Transformational 
Cycle 102, 189, 290, 673 
phonology 
 
definition: is phonological what is the 
output of phonological computa-
tion 804, 806 
phonology-free syntax 412 
 
is in fact melody-free syntax: holds 
only for phonological properties 
below the skeleton 412 
 
melody and morpho-syntax are in-
communicado in both directions 
660 
 
is morphological concatenation sensi-
tive to derived phonological prop-
erties? 253 
 
explained if structure, but not vocabu-
lary, is translated 653 
 
and intonation 801 
 
challenged by →PF movement 577 
 
identifies a phonological module 645 
phrasal idiom 
 
in Distributed Morphology 544 
phrase structure rules 625 
phrenology 
 
→modularity, origins 601 
PIC 
 
→Phase Impenetrability Condition 
plasticity of the brain 616 
pool of rules 
 
Lexical Phonology: one single pool of 
rules that "intervene" at different 
strata or postlexically 151 
possible word 
 
blick vs. lbick (→Kaye 1995) 349 
post-cyclic lexical rules (Lexical Phonol-
ogy) 
 
(Rubach & Booij (1984), = SPE's 
→word level rules 194 
postlexical phonology 
 
birth of the idea in Lexical Phonology 
154f 
post-SPE 109 

824 
Subject index 
pragmatics 
 
module interacting with grammar 629
evidence for independent status from 
→double dissociation 642 
Praguian segregation 
 
word- vs. sentence phonology, 
→postlexical phonology 154f 
 
summary 816 
 
and the →Strict Cycle Condition 
(SCC) 192 
 
motivation: process-specific no look-
back (→PIC à la carte) 240 
 
dismissed by Halle & Vergnaud 
(1987a) 219, 248 
 
dismissed by Kaye (1995) 283 
 
vs. PIC à la carte 818-27 
 
assessed by →double dissociation 818
→word-spell-out-mystery 
 
supported by the word-spell-out-
mystery 817 
 
not good enough to explain what is 
going on with the word-spell-
out-mystery 808 
precedence relationships 
 
→directed graphs (Raimy) 
Precedence Resolution Principle 
 
→linearisation: Epstein et al. (1998), 
Richards (2004, 2007) 745 
precedence rules 
 
→linearisation: Bobaljik (2002) 745 
precompilation theory 
 
Hayes (1990) 408 
privativity 
 
five arguments in favour of privativity 
(representational and procedural) 
761 
 
on the procedural side: selective vs. 
non-selective spell-out 760 
 
on the representational side: under-
feeding of phonology is an undis-
puted fact, but all theories since 
SPE are non-privative 757 
 
not every morpho-syntactic division is 
projected onto phonology (Chom-
sky et al. 1956) 79 
privativity (continued) 
 
SPE is non-privative: →boundaries 
present without phonological ef-
fect 90 
 
the non-privativity of SPE led to con-
fusion 132 
 
Lexical Phonology is non-privative 
173 
 
Prosodic Phonology is non-privative: 
all layers of the Prosodic Hierar-
chy are always constructed 383, 
400 
procedural vs. representational analyses 
 
→balance of procedural and represen-
tational analyses, →Interface Du-
alism 320 
Procedural First 
 
if both representational and procedural 
analyses are available, choose the 
latter 6, 18, 316, 320, 850 
procedural management of interface phe-
nomena 
 
→Interface Dualism 
proceduralisation of the interface 
 
Lexical Phonology 213 
 
Halle & Vergnaud (1987a) 255 
processors 
 
Jackendoff's name for modules 644 
process-specific external sandhi 
 
→sandhi (external) 239 
process-specific no look-back 
 
→no look-back devices/ PIC à la carte, 
→Phase Impenetrability/ PIC à la 
carte 
projection principle 
 
→Government Phonology 705 
prosodic government 
 
→Government Phonology 705 
Prosodic Hierarchy 
 
→Prosodic Phonology 
 
properties and function 378f , 399 
 
resounding success of 361, 364 
 
transition boundaries > prosodic con-
stituency (summary, →Prosodic 
Phonology) 711 

Subject index 825 
Prosodic Hierarchy (continued) 
 
superfluous? Issue with →direct syn-
tax (→Prosodic Phonology) 409 
 
internal structure 
 
its six layers 382 
 
Strict Layer Hypothesis: classical 
(monolithic) and OTed (made 
of 4 independent constraints) 
383 
 
the Prosodic Hierarchy is a hetero-
geneous blend of bottom-up 
(moras, syllables, feet) and 
top-down constructions (the 
rest) 374 
 
Clitic Group, abandoned, note 96 
(382) 
 
is non-privative: all layers of the 
Prosodic Hierarchy are always 
constructed 383, 400 
 
the Prosodic Hierarchy is a heteroge-
neous blend of bottom-up (moras, 
syllables, feet) and top-down con-
structions (the rest) 374, 401 
 
domains are necessarily diacritic: 
→Prosodic Phonology 
 
is a diacritic (from the PrWd upwards)
definition of diacritics 405 
 
→diacritics do not qualify 449 
 
diacritic →translation (summary) 
697 
 
illusion of a diacritic-free phonol-
ogy since the 80s 698 
 
diacritic issue settled in verb, but 
not in practice: No Diacritics! 
690 
 
prosodic constituents are diacritics, 
if autosegmental ones 361, 
402 
 
prosodic constituents are the auto-
segmental version of bounda-
ries 403 
 
prosodic constituents share all 
formal properties with bounda-
ries 404 
 
only purpose: storage of morpho-
syntactic information (the 
buffer) 400 
Prosodic Hierarchy (continued) 
 
is a diacritic (from the PrWd upwards) 
(continued) 
 
prosodic constituents are wrongly 
sold as "truly phonological ob-
jects" 405 
 
non-diacritic carriers of morpho-
syntactic information exist 
 
goal for further study: to make 
carriers of morpho-syntactic 
information local AND non-
diacritic (→Indirect Interface) 
366 
 
→initial CV 44, 49, 713 
Prosodic Lexical Phonology 
 
Inkelas' (1990) compromise 433 
Prosodic Morphology 442 
 
forerunner of OT 361 
 
transposed into OT: Generalized Tem-
plate Theory 448 
 
two periods: representational and anti-
representational 443 
 
typical phenomena covered: reduplica-
tion, templatic morphology 444 
Prosodic Phonology 360 
 
→non-isomorphism 
 
→Prosodic Hierarchy 
 
diacritic character of: →Prosodic 
Hierarchy 
 
overview/summary 361, 449, 697 
 
general architecture 379 
 
has made translation systematic 
and consensual 361 
 
black box (non-isomorphism) 378, 
380 
 
buffer (=Prosodic Hierarchy) 378 
 
three ways to make reference to 
the PH: domain span, domain 
juncture and domain limit rules
384, 709 
 
history, genesis 
 
overview of its roots in the 70s 
110 
 
all architectural properties come 
from SPE 385 
 
Indirect Reference 385 

826 
Subject index 
Prosodic Phonology 360 (continued) 
 
history, genesis (continued) 
 
continuity with SPE, but a tabula 
rasa self-understanding 361 
 
ancestors: Selkirk adapts Liberman 
& Prince (1977) to the inter-
face 363 
 
is a child of autosegmentalism 368
major historical break: boundaries, 
not domains, have always been 
the carriers of morpho-
syntactic information since the 
19th century 361, 366 
 
early period (up to 1986) 362 
 
summary of Selkirk's early work 
363 
 
summary of the second strand: 
Nespor & Vogel 364 
 
vs. direct syntax: Indirect Reference 
378, 385 
 
why Indirect Reference? 407 
 
phonology can see morpho-
syntactic (tree) structure, but 
not its labels 398 
 
alliance of Lexical Phonology and 
Direct Syntax against Prosodic 
Phonology, note 121 (432) 
 
mapping 
 
how it works 387 
 
mapping rules 378, 380 
 
is done in modular no man's land 
381 
 
for rhetorical purposes, mushy and 
uncontrolled mapping is hid-
den by a clean and universal 
Prosodic Hierarchy 393 
 
is prosodic phrasing sensitive to 
the length of the string? 421, 
note 142 (577) 
 
Nespor & Vogel (1986): two sets 
of mapping rules 439 
 
Selkirk's (1986) end-based map-
ping 394 
 
Selkirk's (1986) end-based map-
ping: origin of alignment in 
OT 395 
Prosodic Phonology 360 (continued) 
 
mapping (continued) 
 
Selkirk's (1986) end-based map-
ping puts to use the technology 
of the 80s: X-bar-based map-
ping 395 
 
mapping puzzle 
 
poorly understood 387 
 
mapping: mechanics, atomising 
parametric evolution, absence 
of cross-linguistic generalisa-
tions 386 
 
and cross-linguistic variation: 
progressive parameterisation of 
mapping rules 388 
 
variation regarding ω and φ 390f 
 
Selkirk's (1986) end-based map-
ping: no advance 392, 396 
 
(local) boundaries vs. (non-local) 
domains (→translation) 
 
local boundaries vs. non-local 
domains (overview) 361 
 
boundaries are the primitive cur-
rency for mapping: prosodic 
domains are built on the basis 
of boundary grouping 397 
 
boundaries replaced by autoseg-
mental domains 361 
 
boundaries not an issue anymore 
for Nespor & Vogel (1986) 
370 
 
domains have an independent 
motivation: stress, rhythm, 
musical properties 374f 
 
(non-)discussion of boundaries 
369 
 
major historical break (that went 
almost unnoticed): boundaries, 
not domains, have always been 
the carriers of morpho-
syntactic information since the 
19th century 361, 366f 
 
non-arguments against boundaries
371f 
 
nothing is gained when boundaries 
are replaced by prosodic con-
stituency since both are diacrit-
ics 373 

Subject index 827 
Prosodic Phonology 360 (continued) 
 
(local) boundaries vs. (non-local) 
domains (→translation) (contin-
ued) 
 
the diacritic argument against 
boundaries 373 
 
domains are necessarily diacritic 
 
→Prosodic Hierarchy 
 
definition of diacritics 405 
 
diacritic translation (summary) 
697 
 
illusion of a diacritic-free phonol-
ogy since the 80s 698 
 
settled in verb, but not in practice: 
No Diacritics! 690 
 
prosodic word and higher prosodic 
constituents are the projection 
of nothing 715 
 
top-down constructions are dia-
critic by definition 714 
 
syllable and feet are entirely de-
termined by their terminals 
716 
 
only local boundaries can be non-
diacritic: syllabic space is the 
solution 717 
 
non-diacritic carriers of morpho-
syntactic information exist 
 
goal for further study: to make 
carriers of morpho-syntactic 
information local AND non-
diacritic (→Indirect Interface) 
366 
 
→initial CV 44, 49, 713 
relations with Lexical Phonology and 
the metrical grid: overview 424 
 
relations with Lexical Phonology 
 
summary competition and outlook 
(Stratal OT) 441 
 
officially peaceful cohabitation, 
but a conflict in actual fact 
361 
 
above vs. below the word level: no 
concurrence above 401, 430 
Prosodic Phonology 360 (continued) 
 
relations with Lexical Phonology 
(continued) 
 
Nespor & Vogel (1986): peaceful 
coexistence, but no rationale 
for dividing labour 435 
 
Rubach & Booij: peaceful scram-
bling of everything, happy vio-
lation of Indirect Reference 
440 
 
Hayes (1989 [1984]): no Prosodic 
Phonology below the word 
level 431 
 
Selkirk (1984): Lexical Phonology 
is redundant and has to go 432
Inkelas (1990): reducing Lexical 
Phonology to an empty shell 
433 
 
alliance of Lexical Phonology and 
Direct Syntax against Prosodic 
Phonology, note 121 (432) 
 
elimination of boundaries in Lexi-
cal Phonology remains unre-
flected 367 
 
Nespor & Vogel (1986): two sets 
of mapping rules 439 
 
relations with the metrical grid 425 
 
Nespor & Vogel (1986): peaceful 
cohabitation with the grid 428
Selkirk (1984): the grid is superior
426 
 
Selkirk (1986): the grid is derived 
from prosodic constituency 
427 
prosodic phrasing 
 
sensitive to the length of the string? 
421, note 142 (577) 
prosopagnosia 
 
→double dissociation 620 
psychology 
 
study of language is a sub-discipline of 
psychology (Chomsky) 627 
 
Q
quarks (physics) 592 
 

828 
Subject index 
R
rationalism 
 
vs. empiricism 591 
readjustment 
 
SPE: ancestor of →non-isomorphism 
and →Indirect Reference 
(→Prosodic Phonology) 91 
 
SPE, replicated in Prosodic Phonology 
as the Black Box 380, 385 
 
in Distributed Morphology: allomor-
phy/suppletion 571 
readjustment rules 
 
→boundary mutation rules, 
→readjustment 
recursion 
 
also →intonation 
 
privilege of morpho-syntax, absent in 
phonology: no phonological phe-
nomenon qualifies 45f, 801, 803 
 
absence in phonology predicted by flat 
CVCV (Vol.1) 805 
 
definition: repetition of the same item, 
limited only by performance re-
strictions 803 
 
confusion: recursion is a phenomenon 
whose existence is established by 
pre-theoretical properties, not by 
analyses that happen to use recur-
sive constructions, note 5 (46), 803
recursive prosodic structure is no 
evidence for recursion in phonol-
ogy because it is not created by 
phonological computation 804 
 
is the result of concatenation: since 
phonology does not concatenate 
anything, there can be no recursion 
in phonology 803, 805 
 
Merge must be absent from phonol-
ogy: Neeleman & van de Koot 
(2006) 805 
 
Strict Layer Hypothesis allows for 
recursive prosodic structure since 
Selkirk (1996) 802 
reductionism 
 
reduces the mind to the brain 591 
relation-based mapping 
 
vs. end-based mapping (Selkirk 1986) 
396 
Relative Access Memory (RAM) 
 
→Turing (von Neumann) machine 
Relativized Minimality 
 
atomisation of phasehood marshalled 
by the anti-locality of movement 
777 
 
in phonology 705 
Representation Theory 
 
Williams (2003) 632 
representational 
 
vs. procedural analyses: →balance of 
representational intervention 
 
→local vs. domain-based intervention 
representational management of interface 
phenomena 
 
→Interface Dualism 
Representational Modularity (Jackendoff) 
 
alternative to the inverted T model 
644, 723 
representations 
 
independent of constraint action 507 
reranking 
 
Stratal OT, DOT 476 
Revised Alternation Condition (RAC) 
 
also →Alternation Condition 129, 187
against overgeneration 144 
 
back to, after the bankruptcy of the 
SCC 197 
Rhythm Rule 
 
→stress clash 
rhythmic properties of the linear string 
 
ancestors of Prosodic Phonology: 
Liberman & Prince (1977) 363 
robustness 
 
→Kaye (1995) 279 
Root Faithfulness 
 
used for derived environment effects in 
OT (Anttila) 520 
roots 
 
do not possess category (Distributed 
Morphology) 544 

Subject index 829 
rule types 
 
also →computational systems 
 
summary 234-36 
 
equivalences 
 
between SPE and Lexical Phonol-
ogy: →cyclic, →word-level, 
→level 1, →level 2, →post-
cyclic lexical, →non-cyclic 
106 
 
→word-level rules (SPE) = →non-
cyclic rules (Halle & Vergnaud 
1987a) = →post-cyclic lexical 
rules (Lexical Phonology) 
219, 233 
 
→post-cyclic lexical rules (Rubach 
& Booij 1984) = →non-cyclic 
rules (Halle & Vergnaud 
1987a) = SPE's →word-level 
rules 154 
 
cyclic rules 
 
summary 236 
 
SPE 105 
 
Lexical Phonology 158, 193 
 
Halle & Vergnaud (1987a) 219, 
233 
 
lexical rules 153 
 
level 1 rules (→rule-blocking 
pattern) 149-51 
 
level 2 rules (→rule-triggering 
pattern) 149-51 
rule-blocking boundaries 
 
SPE 93 
rule-blocking pattern 
 
definition: Kenstowicz & Kisseberth 
(1977, 1979) 50 
 
summary English processes 311 
 
analysis in SPE 93 
 
in Lexical Phonology 163 
 
level 1 rules 164 
 
(unintended) elimination by proce-
dural management 165 
 
analysis by Halle & Vergnaud (1987a)
227-29, 249 
 
analysis by Kaye (1995): underappli-
cation achieved by no look-back 
312f 
rule-list fallacy 
 
→"Cognitive" Linguistics (Langacker 
1987), usage-based (Bybee 2001) 
596 
rules 
 
ranked by →boundary strength 
(McCawley 1968) 114 
rule-triggering boundaries 
 
SPE 94 
rule-triggering pattern 
 
definition: Kenstowicz & Kisseberth 
(1977, 1979) 50 
 
summary English processes 311 
 
analysis in SPE 94 
 
in Lexical Phonology 166 
 
level 2 rules 168 
 
brackets and bracket erasure 
needed 168 
 
can be done by the SCC (but this is 
ignored in the literature) 203 
 
cannot be done by Halle & Vergnaud 
(1987a) 250 
 
cannot be done by Kaye (1995) in 
absence of additional conditions 
325 
 
S
s+C clusters 
 
lexical access (→Kaye 1995) 347 
sandhi 
 
expression of →local (rather than 
domain-based) intervention 707 
sandhi (external) 
 
process-specific, →no look-back 
devices, PIC à la carte, →Phase 
Impenetrability, PIC à la carte 239
and modification-inhibiting no look-
back 302 
 
English: flapping 241 
 
function in perception: I know what 
ewe I want (→Kaye 1995) 263 
savant syndrome 
 
double dissociation 621 
SCC-K (Kiparsky's / Halle's version) 
 
→Strict Cycle Condition, →derived 
environment effects 190 

830 
Subject index 
SCC-M (Mascaró's version) 
 
→Strict Cycle Condition, →derived 
environment effects 189 
scrambling trope 
 
→Optimality Theory, violates modula-
rity 
sealed suitcases 
 
vs. late insertion 536, 646 
selectional properties of affixes 
 
analysis of affix class-based phenom-
ena by Fabb (1988) and Hay 
(2002) based on selectional proper-
ties of affixes, perception, parsing 
247 
selective rule application 
 
Lexical Phonology: a given rule ap-
plies only at a given stratum 
 
→domain assignment, 
→computational systems 149, 
151 
selective spell-out 
 
→computational systems 
 
overview 15 
 
summary, two options: spell-out of the 
sister or of the mother 764 
 
and privativity 760 
 
unifying perspective with syntax 770 
 
referee for competing phonological 
theories (intermodular argumenta-
tion) 857 
 
argument against non-selective spell-
out: spell-out is selective in syntax
769 
 
Halle & Vergnaud (1987a) 
 
birth of a groundbreaking idea 
220, 225 
 
= derivation by phase 220 
 
what exactly is spelled out 226 
 
early cases of: Bresnan (1971) 308 
 
in Kaye (1995) 273 
 
comparison Kaye's vs. Halle & Ver-
gnaud's implementation 277 
 
Distributed Morphology 
 
spell-out at every xP 559 
 
peculiar: categorisers (nP, vP, aP) 
are phase heads, but functional 
heads (VoiceP etc.) are not 
555 
selective spell-out (continued) 
 
Distributed Morphology (continued) 
 
distinct computation (selective 
spell-out) vs. distinct represen-
tations (DM, →direct vs. indi-
rect Merge)) 560 
serial computation 
 
vs. →Parallel Distributed Processing 
(PDP, →connectionism) 597 
short term (working) memory 596 
Sign-Based Morphology (Orgun) 512 
 
monostratalism 513 
 
everything is melted into one, no 
interface left 515 
 
cyclic effects 514 
 
instantiation of →direct syntax 502 
Silent Demibeat Addition SDA 
 
Selkirk (1984) 426 
simplicity 
 
derived environment effects 198 
single engine hypothesis 
 
→Distributed Morphology, 
→morphology vs. syntax 534f 
sister 
 
spell-out your sister! (→Kaye 1995, 
→phase edge) 282 
SLI (Specific Language Impairment) 
 
→double dissociation of language 621
sonority sequencing 
 
of word-final clusters 331 
spatial reorientation 
 
→double dissociation 620 
SPE 81 
 
→boundaries 
 
→computational systems 
 
general architecture 86 
 
general architecture 
 
is an implementation of 
→modularity 84, 99 
 
practises (intermodular) 
→translation 84 
 
inverted T model and its plug-in 
"all concatenation before all 
interpretation" 13, 86 
 
readjustment (component) 91 
 
absence of →no look-back device 
(PIC) 83 
 
labelled brackets 95 

Subject index 831 
SPE 81 (continued) 
 
general architecture (continued) 
 
→cyclic derivation 100 
 
definition of the cycle by major 
categories (N,V,A) 103 
 
one single →computational system 
(due to the representational 
definition of words and affix 
classes) 107 
 
→rule types 
 
cyclic vs. word level rules 105 
 
word-level rules ≈lexical post-
cyclic rules (Rubach & Booij 
1984) 194 
 
word-level rules ≠postlexical rules 
in Lexical Phonology 106 
 
→boundaries 
 
are [-segment] segments without 
→phonetic correlate 88 
 
feature [±segmental] heralded in 
Chomsky et al. (1956) and 
Halle (1959) 78 
 
different types: #, +, = 89 
 
boundary erasure (at the end of the 
derivation) 90 
 
boundary mutation rules (read-
justment rules) 112 
 
non-privative boundary manage-
ment (boundaries present 
without phonological effect) 
90 
 
= boundary without posterity 89 
 
reduction of boundary clusters to 
two 89f 
 
reduction of the number of 
boundaries in post-SPE 
(boundary economy / abuse) 
129 
 
mapping 
 
mapping algorithm (insertion of #)
90 
 
mapping: # restores full morpho-
syntactic information except 
for consecutive affixes of the 
same major category 90 
SPE 81 (continued) 
 
affix classes 
 
representational management 92 
 
rule-blocking boundaries 93 
 
rule-triggering boundaries 94 
 
representational vs. Lexical Pho-
nology's procedural manage-
ment 106 
 
post-SPE 
 
frustration with boundaries 110, 
138 
 
overview main strands until the 
80s 110 
 
socialist revision (Kiparsky) vs. 
communist revolution 
(Stampe) 125f 
 
restoration by Halle & Vergnaud 
(1987a) 217, 219 
 
dismissal of Praguian segregation 
238 
 
interpretational units 242 
spell-out 
 
→selective spell-out 
 
→affix-triggered interpretation 
 
→phase theory/ phasehood 
 
Kaye (1995): domain structure is 
richer than what spell-out can pro-
duce 274 
 
of terminals: procedural first 316 
 
asymmetric spell-out (independent LF-
PF), summary 779 
spell-out mechanism 
 
→word-spell-out mystery 
 
→Phase Impenetrability/ PIC à la carte
asymmetric spell-out (independent LF-
PF), summary 779 
 
common properties of morpho-syntax 
and phonology due to spell-out? 
21 
 
just one (morphology and syntax are 
the same computational system), 
or two (they are not)? 858 
 
→Phase Impenetrability, a property of 
the spell-out mechanism, rather 
than of syntax or phonology 799 

832 
Subject index 
spell-out mechanism (continued) 
 
who decides to ignore "old" strings 
(memory keeper)? 21, 307, 799 
spell-out-as-you-merge 
 
Epstein et al. (1998), extreme version 
of →derivation by phase 305, 
775-77 
spurious cluster 
 
Kaye (1995) 343 
storage vs. computation 
 
no distinction in →connectionism 596
strata 
 
(lexical) in →Lexical Phonology: 
general introduction 147 
 
definition 147-52 
 
procedurally ordered (level ordering) 
147 
 
stratal (Lexical Phonology) vs. non-
interactionist (Halle & Vergnaud 
1987a) architecture 218, 235 
 
stratal (Lexical Phonology) vs. non-
interactionist (Halle & Vergnaud 
1987a) architecture 251 
 
testing ground 1: lexical phonol-
ogy sensitive to syntactic in-
formation? 252 
 
testing ground 2: phonology-free 
syntax 253 
Stratal OT 
 
general presentation 483 
 
morpheme-specific mini-phonologies 
in OT: parallel vs. reranked incar-
nations 476 
 
does away with the →SPE-legacy of 
→Lexical Phonology 489 
 
concern for unrestricted access to 
morpho-syntactic information 490
and modularity 
 
Indirect Reference yes, but ALIGN 
is allowed to violate this prin-
ciple 491 
 
favours clear-cut modular con-
tours, but still violates modu-
larity 527 
 
how different can mini-grammars be? 
492 
Stratum Domain Hypothesis 
 
→domain assignment (→Lexical 
Phonology) 
stress 
 
a strange guy: strategies devised to 
cope with it 556 
 
and structure preservation: the Free 
Element Condition 295 
stress clash 233, note 64 (240), 302 
 
evidence for process-specific PIC 
(→phase theory, PIC à la carte) 
556 
 
independent of word stress assign-
ment: two distinct processes, note 
64 (240), 820 
 
not necessarily a modification of word 
stress 820 
Stress Copy 
 
Halle & Vergnaud (1987a) 231 
 
Halle & Kenstowicz (1991), compen-
sation vs. condensation 549 
Stress Erasure Convention 
 
Halle & Vergnaud (1987a) 230 
 
Halle & Kenstowicz (1991), compen-
sation vs. condensation 549 
stress placement 
 
problem child: particularly apt to 
violate →no look-back and the 
→Strict Cycle Condition 315, 
556, 814 
transparent vs. opaque 311 
stress-shifting vs. stress-neutral affixes 
 
→affix classes, note 32 (142) 
Strict Cycle Condition (SCC) 
 
→derived environment effects 
 
→no look-back devices 
 
→Lexical Phonology 
 
properties 
 
Chomsky's (1973) original version: 
"use new material!" 289 
 
fusion of Chomsky's SCC and 
derived environments 178, 
188 
 
genesis and birth 
 
Chomsky's (1973) original version: 
"use new material!" 289 

Subject index 833 
Strict Cycle Condition (SCC) (continued) 
 
genesis and birth (continued) 
 
overview and properties 188 
 
import of Chomsky's (1973) device 
into phonology: Kean (1974), 
Mascaró (1976) 189, 290 
 
Kiparsky sells Mascaró's SCC for 
what it isn't (Mascaró's SCC 
has got nothing to do with de-
rived environments) 190 
 
Halle (1978) combines Chomsky's 
SCC and derived environ-
ments, but his contribution 
went unnoticed 190 
 
birth: fusion of Chomsky's SCC 
(→no look-back) and derived 
environments 190, 291 
 
confusion disentangled: 
SCC-K(iparsky) vs. SCC-
M(ascaró) 195 
 
often confused: Chomsky's (1973) 
original and Halle/Kiparsky's 
version 291 
 
instrument against overgeneration 
144 
 
further career 
 
posterity of 200 
 
adopted by Halle & Vergnaud 
(1987a) 237 
 
Kiparsky's SCC is void of empiri-
cal content 195 
 
bankruptcy of, declared by Kipar-
sky (1993) 197 
 
eliminated in Stratal OT 489 
 
in the architecture of Lexical Phonol-
ogy 
 
and lexicalism 192 
 
and Praguian segregation 192 
 
lexical post-cyclic rules (Rubach & 
Booij 1984) 194 
 
can do the rule-triggering pattern 
(but this is ignored in the lit-
erature) 203 
 
stratum-specific cyclicity / respect 
of the SCC 194, 233 
 
violation of and derived environments 
 
correlation between derived envi-
ronments and lexical vs. pos-
tlexical rules 192 
Strict Cycle Condition (SCC) (continued) 
 
violation of and derived environments 
(continued) 
 
counterevidence for "lexical = 
applies only to derived envi-
ronments" 192 
 
no correlation between the lexical 
character of rules and their ap-
plication to underived items 
194 
 
violated by stress assignment 
(English) 556 
 
violation of: structure-building vs. 
structure-changing rules 
 
SCC-K weakened 193, note 53 
(199) 
 
derived environment created by 
structure-building rules? 193 
 
structure-changing rules that apply 
in the Lexicon and to un-
derived items 194 
 
Halle & Vergnaud (1987a) 237 
 
English →stress placement is a 
problem child 556, 814 
Strict Cyclicity 
 
Chomsky (1973), →Strict Cycle Con-
dition, genesis and birth 
Strict Layer Hypothesis 
 
classical (monolithic) and OTed (made 
of 4 independent constraints) 383 
 
and privativity 759 
 
in OT: decomposed into four con-
straints (Selkirk 1996) 461 
 
allows for recursive prosodic structure 
since Selkirk (1996) 802 
 
argument by Hayes (1989 [1984]) 
against boundaries based on the 
SLH 373 
string theory (physics) 592 
Structural Analogy 
 
Dependency Phonology, Government 
Phonology 705 
 
morpheme-specific mini-phonologies 
vs. no look-back (PIC): refereed in 
favour of the PIC 830 
 
violation of modularity? 705 
structuralism (American) 59 

834 
Subject index 
structure preservation 
 
→Lexical Phonology (eliminated in 
→Stratal OT) 489 
 
early modification-inhibiting no look-
back (stress, syllabification) 193, 
295-97 
 
Chomsky's "spell-out and forget" too 
strong for phonology: two candi-
dates for a weaker version 302 
structure vs. labels 
 
morpho-syntactic structure may, but 
content (labels) may not bear on 
phonology (?) 752 
structure-building vs. structure-changing 
rules 
 
→Strict Cycle Condition/ violation of 
Structure-Constrained Modularity (Jac-
kendoff) 
 
alternative to the inverted T model 
644, 723 
structured modular programming 
 
modern computers based on the stan-
dard model of Cognitive Science 
603 
subcomponents (→inverted T) vs. subsys-
tems (GB modules) 
 
→modularity/ in GB 631 
successive cyclic movement 
 
linearity-driven (Fox & Pesetsky 2004)
744 
superheavy rhymes 
 
banned in Government Phonology, 
parsing cue for empty nuclei 343 
suppletion 
 
lexical structure of go - went: look-up 
(→Kaye 1995) 354 
suppletion, allomorphy 
 
in →Distributed Morphology 571 
syllabification algorithm 
 
in →Government Phonology, note 165 
(714) 
syllable structure 
 
arboreal vs. lateral account 
(→deforestation) 43 
 
early modification-inhibiting →no 
look-back 297 
symbolic representations 
 
in OT (connectionist roots of) 529 
symbolic vs. anti-symbolic views of the 
cognitive system 
 
introduction 591 
 
adult science without symbols? 592, 
594 
syntactic hierarchical structure all the way 
down 
 
a slogan of Marantz' (DM) 535 
syntactico-centrism 
 
Jackendoff argues against 723 
syntax vs. morphology 
 
→morphology vs. syntax (one or two 
computational systems?) 
syntax-first model 
 
Selkirk (1984), syntax = morphology, 
contra Lexical Phonology 540 
Synthesis Psychology 
 
New Synthesis Psychology: Pinker, 
Plotkin 607 
 
T
templates 
 
work by Bendjaballah & Haiden 724 
terminal nodes 
 
spell-out in isolation of 274 
 
spell-out in isolation of: procedural 
first 316 
theory-external ways to get a handle on 
interface theory 
 
history, modularity, intermodular 
argumentation 845 
third factor explanations 
 
→biolinguistics empties UG 633 
 
eliminate GB-modules (→modularity/ 
in GB) 638f 
 
minimalism: extra-linguistic explana-
tions 298 
 
applied to phonology (Samuels 
2009a,b) 639 
tone 
 
is not melodic: it can be the output of 
translation (Manfredi 2010) 662 
traces (syntactic) 
 
are able to influence phonology? 372 
transformational cycle 
 
→cyclic derivation (inside-out) 673 
transistor (computer) 592 

Subject index 835 
translation (insertion of a carrier of mor-
pho-syntactic information) 
 
summary 692 
 
doing away with: →direct syntax 134
phonological theories refereed by their 
(absurd) behaviour at the interface
701 
 
among cognitive modules 
 
by computation (Translator's Of-
fice) vs. by lexical access (dic-
tionary) 652, 655 
 
is selective, the choice of trans-
lated pieces is arbitrary 654 
 
vocabulary (as opposed to struc-
ture) excluded from transla-
tion? 661 
 
translation of vocabulary (input) 
vs. structure (result of modular 
activity) 652 
 
structure, but not vocabulary, is 
translated 653 
 
enforced by domain specificity 
413 
 
of morpho-syntax into phonology 
 
local vs. non-local encoding of 
morpho-syntactic information 
405 
 
Indirect Reference is a conse-
quence of domain specificity 
650 
 
outlook Vol.2: One Channel 
Translation 655 
 
history and evolution 
 
invented by structuralism (→Level 
Independence) 699 
 
always practised, even in absence 
of modular background 693 
 
output: always the representational 
vocabulary of the current the-
ory 5, 72 
 
in SPE 84f 
 
post-SPE, output: non-diacritics, 
i.e. truly phonological objects 
134 
 
summary post-SPE 138 
 
output has always been a →diacritic 
 
overview: juncture phonemes, 
boundaries 695 
translation (insertion of a carrier of mor-
pho-syntactic information) (continued)
output has always been a →diacritic 
(continued) 
 
a non-diacritic output enforces 
privative translation 761 
 
privativity: underfeeding of pho-
nology is an undisputed fact, 
but all theories since SPE are 
non-privative 757 
 
generative modularity offenders: 
reference to untranslated in-
formation (summary) 702 
 
into non-diacritic phonological objects
nature of the output: diacritics do 
not qualify 655 
 
a structuralist invention 72 
 
→Direct Interface: output of trans-
lation must be vocabulary 
items that are used in phonol-
ogy in absence of extra-
phonological factors 655 
 
possible outputs reduce to syllabic 
space 717 
 
morpho-syntax and melody are in-
communicado 660 
 
morpho-syntax cannot read or 
parse melody 662 
 
carriers of morpho-syntactic in-
formation do not include mel-
ody 663 
 
(phonological) melody is never the 
output of 653 
 
tone is not melodic: it can be the 
output of translation (Manfredi 
2010) 662 
trees 
 
→deforestation 
 
two different tree-building devices 
(morpho-syntax and phonology)? 
(→morphology vs. syntax) 45 
Trubetzkoy's Grenzsignale 55 
Turing (von Neumann) machine (univer-
sal) 595f, 603 
two-place approach 
 
of Lexical Phonology (Marantz 2000) 
(→Distributed Morphology, 
→morphology vs. syntax) 534f 
 

836 
Subject index 
U
underapplication 
 
morpheme-specific phonologies and 
selective spell-out are incompati-
ble 303 
 
in →Lexical Phonology 156 
 
→affix class-based phenomena 
derived by the underapplica-
tion to →morpheme-specific 
strings 
 
comparison analyses in →Lexical 
Phonology, →Halle & Vergnaud 
(1987a), →Kaye (1995) 303 
 
impossible to achieve in Distributed 
Morphology 559 
 
→rule-blocking pattern (→level 1 
strings) 
 
Lexical Phonology 168 
 
Halle & Vergnaud (1987a): 
achieved by →selective spell-
out 227f, 249 
 
Kaye (1995): achieved by no look-
back, comparison with other 
models 279, 312 
 
Lexical Phonology 164 
 
→rule-triggering pattern (→level 2 
strings) 
 
Kaye (1995): impossible without 
additional condition (string-
finality in English) 322 
 
Halle & Vergnaud (1987a): cannot 
be done 250 
 
in Lexical Phonology: eliminated in 
Stratal OT 489 
 
→derived environments created by 
structure-building rules? 193 
 
Kiparsky's (1993) solution for 
→derived environment effects 
198 
Universal Turing machine 595f, 603 
usage-based theories 596 
 
V
via-rules 
 
Natural Generative Phonology and 
Kaye (1995): structure of lexical 
entries keep - kept 353 
vocabulary (items) 
 
in →Distributed Morphology 536 
vocabulary insertion 
 
in →Distributed Morphology 536 
von Neumann-Turing model 
 
computation 603 
 
W
Williams Syndrome 
 
double dissociation of language 621 
word 
 
possible word: blick vs. lbick (Kaye 
1995) 349 
 
SPE: representational definition 
(##...##) 105 
 
autonomous unit 
 
the word a natural barrier? 238f,
257, 302 
 
absence of a sealing mechanism 
for words in theories where 
word phonology also applies to 
word sequences 240 
 
and modification-inhibiting →no 
look-back 302 
 
SPE 105 
 
Lexical Phonology 153 
 
Halle & Vergnaud (1987a) 239 
 
process-specific treatment by 
Praguian segregation 240 
word formation 
 
phonology sensitive to syntactic in-
formation? 252 
word phonology 
 
→computational systems, →word/ 
autonomous unit 
word-final clusters 
 
heteromorphemic: analysis with 
→domain-final →empty nuclei 
331 
 
unlimited by the phonology: only 
morphology imposes restrictions 
(→Kaye 1995) 332 
word-formation 
 
based on roots vs. on existing words 
546 
word-level phonology 
 
→computational systems, →no look-
back devices, PIC à la carte 
(chunk-specific), →Phase Impene-
trability 

Subject index 837 
word-level rules 
 
→SPE 105 
 
SPE, (absence of) in Lexical Phonol-
ogy 154 
 
SPE: representational definition of the 
word (##...##) 105 
 
= non-cyclic rules in Halle & Verg-
naud (1987a) 219 
 
Lexical Phonology: ≠postlexical rules
106 
 
Kaye (1995) 283, 338 
word-spell-out mystery 786, 794 
 
overview 22 
 
stands in the way of →intermodular 
argumentation 861 
 
facts: what the mystery is 
 
absence of cyclicity-induced exter-
nal sandhi: a fact that nobody 
talks about 787 
 
empirical generalisation wrong? 
796 
 
external →sandhi has only repre-
sentational treatments (Pro-
sodic Phonology) 787 
 
the paradox: why does phonology 
refuse to react on piecemeal 
fire? 795 
 
cyclic interpretation of word se-
quences? 
 
baseline position of SPE: both 
spell-out and interpretation are 
cyclic 789 
 
Lexical Phonology: non-cyclic 
interpretation of word se-
quences imposed without ar-
gument or discussion 158, 
790f 
word-spell-out mystery 786, 794 (contin-
ued) 
 
cyclic interpretation of word se-
quences? (continued) 
 
Halle & Vergnaud (1987a) and 
Kaye (1995) restore SPE: both 
spell-out and interpretation are 
cyclic 792 
 
DM is agnostic 793 
 
how theories react 
 
in Lexical Phonology: why is 
postlexical phonology non-
cyclic? 156, 158, 790f 
Strict Cycle Condition (SCC) 192
an argument in favour of Praguian 
segregation 817 
word-spell-out mystery 786, 794 (contin-
ued) 
 
how theories react (continued) 
 
Praguian segregation is not good 
enough to explain what is go-
ing on 808 
 
analysis: PIC à la carte 
 
chunk-specific PIC (summary) 
796f, 809 
 
(chunk-specific) PIC à la carte in 
Samuels (2009a), but hidden 
by a specific formulation 798 
 
the PIC is managed by the spell-
out mechanism 799 
working (workbench, active) memory 596
Wrap (OT) 
 
→alignment (OT) 
 
X, Y, Z 
Y model 
 
→inverted T 
 

865 
Language index 
 
± this index refers to paragraphs §, that is the running number in the page 
margins. 
± reference to a § that identifies the beginning of a chapter or a section 
refers to this chapter or section and to all of its sub-sections.
± cross-reference to other entries of the language index are introduced by 
"→": look up here. 
± reference to footnotes is made by indicating their number, but also by 
mentioning the number of the § in which they occur: "note 258 (415)" 
refers to footnote 258 which occurs in §415. 
 
A, B 
Berber (Kabyle) 
 
negative marker, analysis by Bendja-
ballah (2001) 713 
Bulgarian 
 
clitic placement, (PF-based) analysis 
by Franks & Boãković (2001) 730
C, D 
Catalan 
 
voicing (like Cracow/Poznań voicing 
→Polish): anti-cyclic (outside-in) 
processes 822 
Chi Mwi:ni (Bantu) 
 
prosodic phrasing, analyses by Kisse-
berth & Abasheikh (1974), Hayes 
(1989 [1984]), Selkirk (1986) 396
E
English 
 
affix class-based phenomena 
 
→process-blocking pattern (level 1 
rules) 
English (continued) 
 
affix class-based phenomena (contin-
ued) 
 
process-triggering pattern (level 2 
rules): →nasal cluster simplifi-
cation - four varieties:  
 
1) →n-deletion (damn, damn-
ing2 vs. damn-ation1),  
 
2) →g-deletion (sign, sign-ing2
vs. sign-ature1),  
 
3) →post-nasal b-deletion 
(bomb, bomb-ing2 vs. bomb-
ard1),  
 
4) →post-nasal g-deletion 
(sing, sing-ing2 vs. long-er1)
aspiration 
 
example of an "automatic process"
186 
 
Kiparsky (1993) 199 
 
bracketing paradoxes, allomorph selec-
tion: un-happier vs. *beautifuller 
anti-interactionist ammunition 243
and independent spell-out of ter-
minals 319 

Language index 839 
English (continued) 
 
bracketing paradoxes, allomorph selec-
tion: un-happier vs. *beautifuller 
(continued) 
 
analysis by Rubach & Booij 
(1984) 440 
 
category-sensitive stress: récord 
(noun) vs. recórd (verb) 
 
analysis by Nespor & Vogel 
(1986) 438 
 
melody-free syntax 752 
 
complex word-final clusters (sixths,
röntgst)
analysis in Government Phonology 
with empty nuclei 331 
 
compounds 
 
progressive erosion of internal 
structure 339 
 
stress and vowel reduction: dialec-
tal and idiolectal variation due 
to variable domain structure 
(Kaye 1995) 335-37 
 
black bóard vs. bláckboard, analy-
sis in SPE 96 
 
epenthesis of schwa: wickəd, nakəd
analysis by Kaye (1995) 344 
 
flapping (cross-word phonology) 241 
 
g-deletion gn-n: sign, sign-ing2 vs. 
sign-ature1
SPE: boundary contrast longer vs. 
longer "person who is longing"
118 
 
analysis in SPE 94 
 
facts and analysis in Lexical Pho-
nology 167 
 
great vowel shift 
 
Kiparsky: example of an "auto-
matic process" 186 
 
intonation (sentence stress) 
 
Nuclear Stress Rule (NSR), analy-
sis by Bresnan (1971) 308 
 
cat-rat-cheese: readjustment in 
SPE 91 
 
cat-rat-cheese, analysis by SPE 
and Nespor & Vogel (1986) 
418 
English (continued) 
 
linking r 
 
across sentence boundaries, analy-
sis by Nespor & Vogel (1986) 
418 
 
nasal assimilation in- vs. un- 
facts and analysis in SPE and 
Lexical Phonology 164 
 
sensitive to affix classes, but not to 
derived environments 182 
 
phonological and morpho-syntactic 
effects of the asymmetry 319 
 
analysis by Nespor & Vogel 
(1986) 438 
 
analysis by Halle & Vergnaud 
(1987a) 249 
 
analysis in Kaye's system 314 
 
nasal cluster simplification 
 
four varieties:  
 
1) →n-deletion (damn, damn-
ing2 vs. damn-ation1),  
 
2) →g-deletion (sign, sign-ing2
vs. sign-ature1),  
 
3) →post-nasal b-deletion 
(bomb, bomb-ing2 vs. bomb-
ard1),  
 
4) →post-nasal g-deletion 
(sing, sing-ing2 vs. long-er1)
post-nasal plosive deletion (post-
nasal b- and g-deletion): pat-
tern suffers exceptions, note 43 
(167) 
 
analysis by Halle & Mohanan 
(1985): stratum-specific cyclic-
ity/SCC 194 
 
analysis by Kaye (1995): based on 
the domain-final condition 
322 
 
analysis by Kaye (1995): why do 
the clusters implode? 324 
 
n-deletion mn-m: damn, damn-ing2 vs. 
damn-ation1
SPE 94 
 
facts and analysis in Lexical Pho-
nology 167f 
 
night rate vs. nitrate 63 

840 
Language index 
English (continued) 
 
opacity, simultaneous PF and LF 
(cómparable vs. compárable)
analysis in Distributed Morpholo-
gy 545 
 
no opacity in a lexicalist perspec-
tive 573 
 
post-nasal b-deletion mb-m: bomb,
bomb-ing2 vs. bomb-ard1
analysis in SPE 94 
 
facts and analysis in Lexical Pho-
nology 167f 
 
pattern suffers exceptions, note 43 
(167) 
 
post-nasal g-deletion ŋg-ŋ: sing,
sing-ing2 vs. long-er1
facts and analysis in Lexical Pho-
nology 167f 
 
Kiparsky: example of an "auto-
matic process" 186 
 
cannot be done by Halle & Verg-
naud (1987a) 250 
 
pattern suffers exceptions, note 43 
(167) 
 
process-blocking pattern (párent - 
parént-al - párent-hood)
summary triggering conditions 
311 
 
boundary invisible 51 
 
analysis in SPE 93 
 
strata-based analysis in Lexical 
Phonology 147 
 
analysis in Halle & Vergnaud 
(1987a) 227-29 
 
analysis by Kaye (1995): no look-
back 279 
 
Rhythmic Rule 
 
→stress clash 
 
sandhi (external) 
 
t →tÉʃ / __ j: I know what you want
vs. I know what ewe I want,
Kaye (1995) 263 
 
flapping 241 
 
linking r, analysis by Nespor & 
Vogel (1986) 418 
 
stress (sentence) 
 
→intonation 
English (continued) 
 
stress (word) 814 
 
4 stress phonemes (Chomsky et al. 
1956) 74 
 
black bóard vs. bláckboard, analy-
sis in SPE (→compounds) 96 
 
and →vowel reduction: dialectal 
and idiolectal variation due to 
variable domain structure 
(Kaye 1995) 335-37 
 
English stress (predictable) vs. 
Vedic stress (lexical), analysis 
by Halle & Vergnaud (1987a) 
237 
 
not frozen when class 1 affixes are 
added (órigin - oríginal), 
analysis in Distributed Mor-
phology (Marvin 2002) 555 
 
secondary stress (compensation vs. 
condensation, →vowel reduc-
tion), analysis in SPE 97 
 
→process-blocking pattern 
 
sealed at the word level 240 
 
example of an "automatic process"
186 
 
→stress clash 
 
stress clash 
 
not the same process as stress 
placement, note 64 (240) 
 
evidence for process-specific PIC 
556 
 
trouble for "don't undo" (process-
specific no look-back) 302 
 
domains vs. boundaries 374 
 
incidence on Marvin's (2002) 
analysis of word stress 556 
 
redistribution of prominence 
among primary, secondary etc. 
word stresses, rather than 
change of primary stress 820 
 
theatricality 
 
derivation in SPE (3 cycles) 103 
 
trisyllabic shortening 
 
literature, note 28 (127) 
 
sensitive to both derived environ-
ments and affix classes 182 
 
SPE, reanalysis by Kiparsky 
(1982) 129 

Language index 841 
English (continued) 
 
trisyllabic shortening (continued) 
 
facts and analysis in SPE and 
Lexical Phonology 164 
 
derived by the Elsewhere Condi-
tion 191 
 
analysis by Halle & Vergnaud 
(1987a) 237, 249 
 
analysis by Kaye (1995): lies 
outside of phonology 276 
 
analysis in Kaye's system 313 
 
velar softening (electri[k] vs. elec-
tri[s]ity)
literature, note 28 (127) 
 
abstractness debate, 
(anti-)lexicalism 570 
 
Kiparsky: example of an "auto-
matic process" 186 
 
analysis by Kaye (1995): not pho-
nology 276 
 
vowel reduction 
 
analysis in SPE (word-level rule) 
105 
 
and stress: dialectal and idiolectal 
variation due to variable do-
main structure (Kaye 1995) 
335-37 
 
vowel reduction, stress-conditioned 
(condensation vs. compensation)
analysis in SPE 548 
 
analysis by Halle & Kenstowicz 
(1991) 549 
 
analysis in Distributed Morphol-
ogy (Marvin 2002) 550f 
 
vowel shortening 
 
mean - meant vs. paint, pint (Ki-
parsky 1985a) 129 
 
word stress 
 
→stress (word) 
 
F
Finnish 
 
t →s / __i 
 
derived environment effect, analy-
sis by Kiparsky (1973a,b) 180
analysis by Kiparsky (1993) 198 
Flemish (West) 
 
voicing (like Cracow/Poznań voicing 
→Polish): anti-cyclic (outside-in) 
processes 822 
French 
 
gender markers, possessive pronouns 
(mon armoire, *m'armoire)
analysis by Lowenstamm (2008) 
579 
 
gliding: prefix-suffix asymmetry 
 
li-j-a vs. *anti-j-alcoolique 53 
 
intrusive t in French (tennis-t-ique)
analysis by Pagliano (2003) 713 
 
liaison 
 
Selkirk (1972), boundary mutation 
rules 112 
 
nasal deletion in in-: /in-légal/ →
illégal 
SPE, Selkirk (1972) 122 
 
vowel nasalisation: mon ami vs. bon 
ami 
analysis by Prunet (1986) / Kaye 
(1995) 295 
 
G, H, I, J 
German 
 
aspiration 
 
analysis by Moulton (1947) 64 
 
complex word-final clusters (sixths,
röntgst)
analysis in Government Phonology 
with empty nuclei 331 
 
distribution of X-ç 
 
analysis by Moulton (1947) 64 
 
glottal stop 
 
analysis by Moulton (1947) 64 
 
glottal stop insertion at prefix bound-
ary (auf-ʔessen)
analysis by Kleinhenz (1998) 448, 
459 
 
tense marker in German strong verbs 
 
analysis by Bendjaballah & Haiden 
(2003a,b) 713 
 
voicing 
 
eliminated: Teil = /d#eil/ (Harris 
1951) 67 

842 
Language index 
Greek 
 
agreement 
 
PIC-violating long-distance 
agreement 780 
 
K
Korean 
 
(word-initial) stop voicing in external 
sandhi 
 
analysis by Cho (1990) 391 
 
affrication before i 
 
analysis by Oostendorp (2006) 
508 
 
L
Latin 
 
gemination 
 
due to morpheme-internal juncture 
(Hill 1954, juncture abuse) 69
stress placement 
 
with enclitic elements: liminá-que 
295 
 
M, N 
Macedonian 
 
clitic placement, (PF-based) analysis 
by Franks & Boãković (2001) 730
O
Ojibwa (Eastern Algonquian) 
 
hiatus avoidance 
 
analysis by Piggott & Newell 
(2006) 578 
Old English 
 
fricative voicing 
 
Lass (1971): # = [-voice] 135 
 
P, Q 
Polish 
 
Cracow (Poznań) voicing 
 
anti-cyclic (outside-in) processes 
822 
 
palatalisation 
 
derived environment effect, analy-
sis by Kiparsky (1973a,b) 181
analysis with bracket-sensitive 
rules (Mohanan) 202 
Polish (continued) 
 
velar palatalisation 
 
in (phonologically) derived envi-
ronments: analysis by Rubach-
Łubowicz (brydż-ek) 518 
Puyo Pongo (Quicha, Eastern Ecuador) 
 
obstruent voicing after heteromor-
phemic nasals 54 
 
R
Romanian 
 
agreement 
 
PIC-violating long-distance 
agreement 780 
 
S
Spanish 
 
nasal assimilation in external sandhi in 
Spanish 
 
analysis by Nespor & Vogel 
(1986) 420 
 
s →h in codas 
 
analysis by Harris (1993): structure 
preservation 297 
 
T, U 
Tagalog (Austronesian, Philippines) 
 
infixation in CC-initial loans 
 
analysis by Zuraw (2007) 412 
Turkish 
 
disharmonic roots 
 
analysis by Oostendorp (2006) 
508 
 
minimal word constraint 
 
analysis by Orgun 514 
Tzeltal (Maya) 
 
infixation 
 
analysis by Samuels (2009) 746 
 
V, W, X, Y, Z 
Vedic 
 
stress (word) 
 
English stress (predictable) vs. 
Vedic stress (lexical), analysis 
by Halle & Vergnaud (1987a) 
237 
 

866 
Index of phenomena 
 
± this index refers to paragraphs §, that is the running number in the page 
margins. 
± reference to a § that identifies the beginning of a chapter or a section 
refers to this chapter or section and to all of its sub-sections.
± cross-reference to other entries of the index of phenomena are intro-
duced by "→": look up here. 
± reference to footnotes is made by indicating their number, but also by 
mentioning the number of the § in which they occur: "note 258 (415)" 
refers to footnote 258 which occurs in §415. 
 
A
affix class-based phenomena (in English) 
 
→process-blocking pattern (level 1 
rules) 
 
process-triggering pattern (level 2 
rules,  →nasal cluster simplifica-
tion): 
 
four varieties 
 
1) →deletion of n (damn, damn-
ing2 vs. damn-ation1)
2) →deletion of g (sign, sign-ing2
vs. sign-ature1)
3) →deletion of b in post-nasal 
position (bomb, bomb-ing2 vs. 
bomb-ard1)
4) →deletion of g in post-nasal 
position (sing, sing-ing2 vs. 
long-er1)
affrication before i in Korean 
 
analysis by Oostendorp (2006) 508 
agreement in (Mod.) Greek and Romanian
PIC-violating long-distance agreement
780 
anti-cyclic (outside-in) processes 
 
Cracow/Poznań voicing, also in Cata-
lan and West Flemish 822 
aspiration (English) 
 
example of an "automatic process" 
186 
 
Kiparsky (1993) 199 
aspiration (German) 
 
analysis by Moulton (1947) 64 
aspiration (s →h) in codas (Spanish) 
 
analysis by Harris (1993): structure 
preservation 297 
assibilation in Finnish: t →s / __i 
 
analysis by Kiparsky (1993) 198 
 
derived environment effect, analysis 
by Kiparsky (1973a,b) 180 
 
B
bracketing paradoxes, allomorph selection 
in English: un-happier vs. 
*beautifuller 
anti-interactionist ammunition 243 
 
and independent spell-out of terminals
319 
 
analysis by Rubach & Booij (1984) 
440 
 
C
category-sensitive stress in English: récord
(noun) vs. recórd (verb) 
 
analysis by Nespor & Vogel (1986) 
438 
 
melody-free syntax 752 
clitic placement in Bulgarian and Macedo-
nian 
 
(PF-based) analysis by Franks & 
Boãković (2001) 730 

844 
Index of phenomena 
compounds (English) 
 
black bóard vs. bláckboard, analysis in 
SPE 96 
 
progressive erosion of internal struc-
ture 339 
 
stress and vowel reduction: dialectal 
and idiolectal variation due to 
variable domain structure (Kaye 
1995) 335-37 
 
D
deletion  
 
of b in post-nasal position (English): 
mb-m bomb, bomb-ing2 vs. bomb-
ard1
analysis in SPE 94 
 
facts and analysis in Lexical Pho-
nology 167f 
 
pattern suffers exceptions, note 43 
(167) 
 
of g in post-nasal position (English): 
ŋg-ŋ sing, sing-ing2 vs. long-er1
facts and analysis in Lexical Pho-
nology 167f 
 
Kiparsky: example of an "auto-
matic process" 186 
 
cannot be done by Halle & Verg-
naud (1987a) 250 
 
pattern suffers exceptions, note 43 
(167) 
 
of g: gn-n sign, sign-ing2 vs. sign-
ature1 (English) 
 
SPE: boundary contrast longer vs. 
longer "person who is longing"
118 
 
analysis in SPE 94 
 
facts and analysis in Lexical Pho-
nology 167 
 
of n: mn-m damn, damn-ing2 vs. 
damn-ation1 (English) 
 
SPE 94 
 
facts and analysis in Lexical Pho-
nology 167f 
disharmonic roots in Turkish 
 
analysis by Oostendorp (2006) 508 
 
E
ellipsis, sluicing 
 
(PF-based) analyses 731 
epenthesis of schwa in English: wickəd,
nakəd
analysis by Kaye (1995) 344 
extraposition 
 
motivation for PF movement 575, 577
F
first vowel of words 
 
alternation with zero of, analysis with 
an empty CV unit 685 
flapping in English (cross-word phonol-
ogy) 241 
fricative voicing in Old English 
 
Lass (1971): # = [-voice] 135 
 
G
gemination (Latin > Italian) 
 
due to morpheme-internal juncture 
(Hill 1954, juncture abuse) 69 
gender markers, possessive pronouns in 
French (mon armoire, *m'armoire)
analysis by Lowenstamm (2008) 579 
gliding in French: prefix-suffix asymmetry
li-j-a vs. *anti-j-alcoolique 53 
glottal stop in German 
 
analysis by Moulton (1947) 64 
glottal stop insertion at prefix boundary in 
German(auf-ʔessen)
analysis by Kleinhenz (1998) 448, 459
great vowel shift (English) 
 
Kiparsky: example of an "automatic 
process" 186 
 
H
heavy NP shift 
 
motivation for PF movement, note 142 
(577) 
hiatus avoidance in Ojibwa (Eastern Al-
gonquian) 
 
analysis by Piggott & Newell (2006) 
578 
 

Index of phenomena 845 
I, J, K 
ich- [ç] and ach [X] Laut in German: dis-
tribution 
 
analysis by Moulton (1947) 64 
infixation 
 
cross-linguistic 
 
conditioned by phonology (but not 
by melody) 412 
 
in CC-initial loans in Tagalog (Aus-
tronesian, Philippines) 
 
analysis by Zuraw (2007) 412 
 
in Tzeltal (Maya) 
 
analysis by Samuels (2009) 746 
intervocalic voicing 
 
boundary-defined domains of rule 
application (McCawley 1968) 114
intonation (sentence stress) 
 
Nuclear Stress Rule (NSR) in English, 
analysis by Bresnan (1971) 308 
 
cat-rat-cheese (English): readjustment 
in SPE 91 
 
cat-rat-cheese (English), analysis by 
SPE and Nespor & Vogel (1986) 
418 
intrusive t in French (tennis-t-ique)
analysis by Pagliano (2003) 713 
 
L
liaison (in French) 
 
Selkirk (1972), boundary mutation 
rules 112 
linking r in English 
 
across sentence boundaries, analysis 
by Nespor & Vogel (1986) 418 
locality conditions 
 
in phonology, similar to syntax 
(Truckenbrodt 1995) 577 
 
M
minimal pairs (in structuralism): night rate
vs. nitrate (English) 63 
minimal word constraint in Turkish 
 
analysis by Orgun 514 
 
N
nasal assimilation  
 
in English: in- vs. un- 
facts and analysis in SPE and 
Lexical Phonology 164 
 
sensitive to affix classes, but not to 
derived environments 182 
 
phonological and morpho-syntactic 
effects of the asymmetry 319 
 
analysis by Nespor & Vogel 
(1986) 438 
 
analysis by Halle & Vergnaud 
(1987a) 249 
 
analysis in Kaye's system 314 
 
in external sandhi in Spanish 
 
analysis by Nespor & Vogel 
(1986) 420 
nasal cluster simplification (English) 
 
four varieties 
 
1) →deletion of n (damn, damn-
ing2 vs. damn-ation1)
2) →deletion of g (sign, sign-ing2
vs. sign-ature1)
3) →deletion of b in post-nasal 
position (bomb, bomb-ing2 vs. 
bomb-ard1)
4) →deletion of g in post-nasal 
position (sing, sing-ing2 vs. 
long-er1)
post-nasal plosive deletion (post-nasal 
b- and g-deletion): pattern suffers 
exceptions, note 43 (167) 
 
analysis by Halle & Mohanan (1985): 
stratum-specific cyclicity/SCC 
194 
 
analysis by Kaye (1995): based on the 
domain-final condition 322 
 
analysis by Kaye (1995): why do the 
clusters implode? 324 
nasal deletion in French in-: /in-légal/ →
illégal 
SPE, Selkirk (1972) 122 
nasalisation of vowels in French: mon ami 
vs. bon ami 
analysis by Kaye (1995) 295 

846 
Index of phenomena 
negative marker in Kabyle Berber 
 
analysis by Bendjaballah (2001) 713 
 
O
opacity, simultaneous PF and LF (English: 
cómparable vs. compárable)
analysis in Distributed Morphology 
545 
 
no opacity in a lexicalist perspective 
573 
 
P, Q 
palatalisation in Polish 
 
analysis with bracket-sensitive rules 
(Mohanan) 202 
 
derived environment effect, analysis 
by Kiparsky (1973a,b) 181 
possessive pronouns, gender markers in 
French (mon armoire, *m'armoire)
analysis by Lowenstamm (2008) 579 
process-blocking pattern (English párent - 
parént-al - párent-hood)
summary triggering conditions 311 
 
boundary invisible 51 
 
analysis in SPE 93 
 
strata-based analysis in Lexical Pho-
nology 147 
 
analysis in Halle & Vergnaud (1987a) 
227-29 
 
analysis by Kaye (1995): no look-back
279 
prosodic phrasing in Chi Mwi:ni (Bantu) 
 
analyses by Kisseberth & Abasheikh 
(1974), Hayes (1989 [1984]), Sel-
kirk (1986) 396 
 
R
Rhythmic Rule (in English) 
 
→stress clash 
 
S
sandhi (external) 
 
English t →tÉʃ / __ j: I know what you 
want vs. I know what ewe I want,
Kaye (1995) 263 
 
flapping in English 241 
 
linking r in English, analysis by Nes-
por & Vogel (1986) 418 
sluicing, ellipsis 
 
(PF-based) analyses 731 
stress (sentence) 
 
→intonation 
stress (word) in English 814 
 
→process-blocking pattern 
 
→stress clash 
 
4 stress phonemes (Chomsky et al. 
1956) 74 
 
black bóard vs. bláckboard, analysis in 
SPE (→compounds) 96 
 
and →vowel reduction: dialectal and 
idiolectal variation due to variable 
domain structure (Kaye 1995) 
335-37 
 
English stress (predictable) vs. Vedic 
stress (lexical), analysis by Halle 
& Vergnaud (1987a) 237 
 
example of an "automatic process" 
186 
 
not frozen when class 1 affixes are 
added (órigin - oríginal), analysis 
in Distributed Morphology 
(Marvin 2002) 555 
 
sealed at the word level 240 
 
secondary stress (compensation vs. 
condensation, →vowel reduction), 
analysis in SPE 97 
stress clash (in English) 
 
domains vs. boundaries 374 
 
evidence for process-specific PIC 556
incidence on Marvin's (2002) analysis 
of word stress 556 
 
not the same process as stress place-
ment, note 64 (240) 
 
redistribution of prominence among 
primary, secondary etc. word 
stresses, rather than movement of 
primary stress 820 
 
trouble for "don't undo" (process-
specific no look-back) 302 
stress placement in Latin 
 
with enclitic elements: liminá-que 295
T, U 
tense marker in German strong verbs 
 
analysis by Bendjaballah & Haiden 
(2003a,b) 713 

Index of phenomena 847 
trisyllabic shortening (English) 
 
literature, note 28 (127) 
 
sensitive to both derived environments 
and affix classes 182 
 
SPE, reanalysis by Kiparsky (1982) 
129 
 
facts and analysis in SPE and Lexical 
Phonology 164 
 
derived by the Elsewhere Condition 
191 
 
analysis by Halle & Vergnaud (1987a)
237, 249 
 
analysis by Kaye (1995): lies outside 
of phonology 276 
 
analysis in Kaye's system 313 
 
V
velar palatalisation in Polish 
 
in (phonologically) derived environ-
ments: analysis by Rubach-
Łubowicz (brydż-ek) 518 
velar softening (English: electri[k] vs. 
electri[s]ity)
literature, note 28 (127) 
 
abstractness debate, (anti-)lexicalism 
570 
 
Kiparsky: example of an "automatic 
process" 186 
 
analysis by Kaye (1995): not phonol-
ogy 276 
voicing 
 
in German 
 
eliminated: Teil = /d#eil/ (Harris 
1951) 67 
 
in Korean: word-initial stops in exter-
nal sandhi 
 
analysis by Cho (1990) 391 
 
in Polish (Cracow / Poznań voicing), 
Catalan and West Flemish 
 
anti-cyclic (outside-in) processes 
822 
 
of obstruents after heteromorphemic 
nasals in Puyo Pongo (Quicha, 
Eastern Ecuador) 54 
vowel nasalisation in French: mon ami vs. 
bon ami 
analysis by Prunet (1986) / Kaye 
(1995) 295 
vowel reduction 
 
in English 
 
analysis in SPE (word-level rule) 
105 
 
and stress: dialectal and idiolectal 
variation due to variable do-
main structure (Kaye 1995) 
335-37 
 
in English, stress-conditioned (conden-
sation vs. compensation)
analysis in SPE 548 
 
analysis by Halle & Kenstowicz 
(1991) 549 
 
analysis in Distributed Morphol-
ogy (Marvin 2002) 550f 
vowel shortening (English) 
 
mean - meant vs. paint, pint (Kiparsky 
1985a) 129 
 
W, X, Y, Z 
Weight Increase 
 
analysis of heavy NP movement (Sel-
kirk 2001), note 142 (577) 
word stress (in English) 
 
→stress (word) 
word-final clusters, complex (e.g. English, 
German: sixths, röntgst)
analysis in Government Phonology 
with empty nuclei 331 
word-initial consonant clusters 
 
restrictions of, analysis with an empty 
CV unit 685 
word-initial consonants, strength of 
 
analysis with an empty CV unit 685 
 


