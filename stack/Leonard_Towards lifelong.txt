Towards lifelong feature-based
mapping in semi-static environments
The MIT Faculty has made this article openly available. Please share 
how this access benefits you. Your story matters.
Citation
Rosen, David M., Julian Mason, and John J. Leonard. “Towards
Lifelong Feature-Based Mapping in Semi-Static Environments.”
IEEE, 2016. 1063–1070.
As Published
http://dx.doi.org/10.1109/ICRA.2016.7487237
Publisher
Institute of Electrical and Electronics Engineers (IEEE)
Version
Author's final manuscript
Citable link
http://hdl.handle.net/1721.1/107620
Terms of Use
Creative Commons Attribution-Noncommercial-Share Alike
Detailed Terms
http://creativecommons.org/licenses/by-nc-sa/4.0/

Towards Lifelong Feature-Based Mapping in Semi-Static Environments
David M. Rosen, Julian Mason, and John J. Leonard
Abstract—The feature-based graphical approach to robotic
mapping provides a representationally rich and computationally
efﬁcient framework for an autonomous agent to learn a model
of its environment. However, this formulation does not naturally
support long-term autonomy because it lacks a notion of envi-
ronmental change; in reality, “everything changes and nothing
stands still,” and any mapping and localization system that aims
to support truly persistent autonomy must be similarly adaptive.
To that end, in this paper we propose a novel feature-based model
of environmental evolution over time. Our approach is based
upon the development of an expressive probabilistic generative
feature persistence model that describes the survival of abstract
semi-static environmental features over time. We show that this
model admits a recursive Bayesian estimator, the persistence
ﬁlter, that provides an exact online method for computing,
at each moment in time, an explicit Bayesian belief over the
persistence of each feature in the environment. By incorporating
this feature persistence estimation into current state-of-the-art
graphical mapping techniques, we obtain a ﬂexible, computation-
ally efﬁcient, and information-theoretically rigorous framework
for lifelong environmental modeling in an ever-changing world.
I. INTRODUCTION
The ability to learn a map of an initially unknown envi-
ronment through exploration, a procedure known as simulta-
neous localization and mapping (SLAM), is a fundamental
competency in robotics [1]. Current state-of-the-art SLAM
techniques are based upon the graphical formulation of the
full or smoothing problem [2] proposed in the seminal work
of Lu and Milios [3]. In this approach, the mapping problem
is cast as an instance of maximum-likelihood estimation over
a probabilistic graphical model [4] (most commonly a Markov
random ﬁeld [5] or a factor graph [6]) whose latent variables
are the sequence of poses in the robot’s trajectory together
with the states of any interesting features in the environment.
This formulation of SLAM enjoys several attractive prop-
erties. First, it provides an information-theoretically rigor-
ous framework for explicitly modeling and reasoning about
uncertainty in the inference problem. Second, because it is
abstracted at the level of probability distributions, it provides
a convenient modular architecture that enables the straight-
forward integration of heterogeneous data sources, including
both sensor observations and prior knowledge (speciﬁed in the
form of prior probability distributions). This “plug-and-play”
framework provides a formal model that greatly simpliﬁes the
design and implementation of complex systems while ensuring
D.M. Rosen and J.J. Leonard are with the Computer Science and Artiﬁcial
Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge,
MA 02139 USA. {dmrosen,jleonard}@mit.edu
J. Mason is with Google, 1600 Amphitheatre Parkway, Mountain View, CA
94043 USA. jmason@google.com
This work was partially supported by the Ofﬁce of Naval Research under
grant N00014-11-1-0688 and by the National Science Foundation under grant
IIS-1318392, which we gratefully acknowledge.
0
20
40
60
80
100
120
140
Time (t)
0.0
0.2
0.4
0.6
0.8
1.0
Persistence ﬁlter output
True state
Observation
Filter belief
Fig. 1.
Recursive Bayesian estimation of feature persistence. This plot
shows the (continuous-time) temporal evolution of the persistence ﬁlter belief
p(Xt
= 1|Y1:N) (the belief over the continued existence of a given
environmental feature) given a sequence Y1:N ≜{yti}N
i=1 of intermittent,
error-prone outputs from a feature detector with missed detection and false
alarm probabilities PM = .2, PF = .2, respectively. Note the decay of the
belief in the absence of any signal from the detector (for t ∈(25, 75)) and
the rapid adaptation of the ﬁlter belief in response to both newly-available
data (at t = 75) and change in the hidden state (at t = 115).
the correctness of the associated inference procedures. Finally,
this formulation admits computationally efﬁcient inference;
there exist mature algorithms and software libraries that can
solve graphical SLAM problems involving tens of thousands
of variables in real time on a single processor [7–10].
However, while graphical SLAM approaches have proven
very successful at reconstructing the geometry of environments
explored over relatively short timescales, they do not naturally
support long-term robotic autonomy because their underlying
models assume a static world. In reality, “everything changes
and nothing stands still,”1 and any SLAM system that aims to
support truly persistent autonomy must be similarly adaptive.
To that end, in this paper we propose a novel feature-
based model of environmental change over time. Our ap-
proach is grounded in the ﬁelds of survival analysis and
information theory, and is based upon the development of
a probabilistic generative model to describe the temporal
persistence of abstract semi-static environmental features. We
show that this feature persistence model admits a recursive
Bayesian estimator, the persistence ﬁlter, that provides an
exact real-time online method for computing, at each moment
in time, an explicit Bayesian belief over the persistence of
each feature in the environment (Fig. 1). By incorporating this
feature persistence estimation into existing graphical SLAM
1Heraclitus of Ephesus (c. 535 – c. 475 BCE)

techniques, we obtain a ﬂexible, computationally efﬁcient,
and information-theoretically sound framework for lifelong
environmental modeling in an ever-changing world.
II. RELATED WORK
The principal technical challenge that distinguishes semi-
static environmental modeling from the well-studied static case
is the need for an additional mechanism to update an existing
map in response to changes in the world. Several novel map
representations have been proposed to facilitate this procedure.
In sample-based representations, the map consists of a set of
places, each of which is modeled by a collection of raw sensor
measurements; updating a place in response to environmental
change is then achieved by simply updating its associated
observations. This approach was originally proposed by Biber
and Duckett [11, 12], who considered maps comprised of 2D
laser scans, and performed updates by replacing a randomly-
selected ﬁxed fraction of the scans at each place every time
it is revisited. More recently, Churchill and Newman [13]
have proposed plastic maps, in which a place is modeled
as a collection of experiences (temporal sequences of sensor
observations associated with a small physical area). In contrast
to our approach, these methods are intended only to support
reliable long-term localization in semi-static environments,
and do not actually attempt to produce a temporally coherent
or geometrically consistent environmental reconstruction.
Konolige and Bowman [14] proposed an extension of Kono-
lige et al.’s view-based maps [15] for semi-static environments.
In this approach, a place is modeled as a collection of
stereocamera frames captured near a single physical location,
and the global map is modeled as a graph of places whose
edges encode six-degree-of-freedom transforms between cam-
era views. Similarly, Walcott-Bryant et al. [16] extended the
pose graph model to support 2D semi-static environment
modeling using laser scanners. While these approaches do
enable temporally and geometrically consistent environmental
reconstruction, they are algorithmically tailored to speciﬁc
classes of sensors and map representations, and lack a uniﬁed
underlying information-theoretic model for reasoning about
environmental change.
As an alternative to sample-based representations, Meyer-
Delius et al. [17] and Saarinen et al. [18] independently pro-
posed dynamic occupancy grids, which generalize occupancy
grid maps [19] to the case of semi-static environments by
modeling the occupancy of each cell as a stationary two-state
Markov process. Tipaldi et al. [20] subsequently incorporated
this model into a generalization of the Rao-Blackwellized
particle ﬁltering framework for grid mapping [21], thereby
producing a fully Bayesian model-based mapping technique.
However, this restriction to the occupancy grid model admits
capturing only the volumetric geometry of the environment,
which is only one of many potential properties of interest (for
example, visual appearance is a highly informative environ-
mental signal for mapping and navigation systems [22]).
Most recently, Krajn´ık et al. [23] have proposed a method
for predicting future states of semi-static environments using
Fourier analysis; this prior work is perhaps the most similar
to our own, as it combines a feature-abstracted environmental
representation with an explicit model of environmental change.
However, it is designed to capture only long-term periodic
patterns of activity in the environment, and appears to lack
an information-theoretically grounded approach for addressing
sensing errors or quantifying the uncertainty of prediction.
In contrast to this prior work, our formulation pro-
vides a uniﬁed, feature-abstracted, model-based, information-
theoretically grounded framework for temporally coherent
and geometrically consistent modeling of generic unstructured
semi-static environments.
III. MODELING SEMI-STATIC ENVIRONMENTAL FEATURES
In feature-based mapping, the environment is modeled as
a collection of abstract entities called features, which encode
whatever environmental information is considered relevant to
the mapping task (examples of such features include points,
lines, planes, objects, and visual interest points). The mapping
problem then consists of identifying the set of features that are
present in the environment and estimating their states (e.g.
position, orientation, or color), given a collection of noisy
observations of the environment.
In static environments, the set of environmental features is
ﬁxed for all time by hypothesis, and therefore constructing
a map requires only that features be added to it as they are
discovered. In contrast, in semi-static environments the feature
set itself evolves in time due to environmental change, and
therefore mapping requires both the ability to add newly-
discovered features into the map and to remove features that
are no longer present.
Ideally, it would sufﬁce to remove a feature from the
map if that feature’s location is reobserved and the feature
is not detected. In reality, however, a “feature observation”
is usually the output of a detector (e.g. an object detector),
which may fail to detect features that are present, or generate
false detections due to noise in the sensor data. The detector
outputs alone are thus insufﬁcient to unambiguously determine
whether a feature is still present; the best we can hope for is
to estimate a belief over feature persistence given this data.
Another complication arises from the passage of time: it
seems intuitively clear that our belief about the state of a
feature that has not been observed for ﬁve minutes should
differ from our belief about the state of a feature that has not
been observed for ﬁve days.
Given these considerations, it is natural to consider the
feature persistence problem in terms of survival analysis [24],
the branch of statistics that studies the waiting time until some
event of interest occurs. In this application, we consider a
feature that is ﬁrst detected at time t = 0, and are interested in
estimating its survival time T ∈[0, ∞) (the length of time that
it exists in the environment before vanishing), given a sequence
of Boolean random variables {Yti}N
i=1 ⊆{0, 1} indicating the
(possibly erroneous) output of a feature detector sampled at
the times {ti}N
i=1 ⊂[0, ∞). We formalize this scenario using

the following feature persistence model:
T ∼pT (·),
Xt|T =
(
1,
t ≤T,
0,
t > T,
Yt|Xt ∼pYt(·|Xt);
(1)
here pT : [0, ∞) →[0, ∞) is the probability density function
for a prior distribution over the survival time T, Xt ∈{0, 1}
is a variable indicating whether the feature is still present at
time t ∈[0, ∞), and pYt(Yt|Xt) is a conditional distribution
modeling the feature detector’s measurement process.
We observe that the detector measurement model pYt(·|·)
in (1) is a conditional distribution over two Boolean random
variables Xt, Yt ∈{0, 1}, for which there is a single paramet-
ric class with two free parameters: the probability of missed
detection PM and the probability of false alarm PF :
PM = pYt(Yt = 0 | Xt = 1; PM, PF )
PF = pYt(Yt = 1 | Xt = 0; PM, PF )
(2)
with PM, PF ∈[0, 1].2 Since PM and PF are innate charac-
teristics of the feature detector, the only freedom in the design
of the model (1) is in the selection of the survival time prior
pT (·), which encodes a prior belief about the dynamics of
feature persistence in the environment. In Section V we will
show how one can design appropriate priors pT (·) in practice.
IV. ESTIMATING FEATURE PERSISTENCE
In this section we describe methods for performing infer-
ence within the feature persistence model (1), assuming access
to a sequence of noisy observations3 Y1:N ≜{yti}N
i=1 sampled
from the feature detector at times {ti}N
i=1 ⊆[0, ∞) (with
ti < tj for all i < j) and a method for evaluating pT (·)’s
cumulative distribution function FT (·):
FT (t) ≜p(T ≤t) =
Z t
0
pT (x) dx.
(3)
Speciﬁcally, we will be interested in computing the posterior
probability of the feature’s persistence at times in the present
and future (i.e. the posterior probability p(Xt = 1|Y1:N)
for times t ∈[tN, ∞)), as this is the relevant belief for
determining whether to maintain a feature in the map.
A. Computing the posterior persistence probability
We begin by deriving a closed-form solution for the poste-
rior probability p(Xt = 1|Y1:N) for t ∈[tN, ∞).
Observe that the event Xt = 1 is equivalent to the event
t ≤T in (1). We apply Bayes’ Rule to compute the posterior
2We use constant detector error probabilities (PM, PF ) in equation (2) in
order to avoid cluttering the notation with multiple subscripts; however, all of
the equations in Section IV continue to hold if each instance of (PM, PF )
is replaced with the appropriate member of a temporally-varying sequence of
error probabilities {(PM, PF )ti}N
i=1.
3Here we follow the lower-case convention for the yti to emphasize that
these are sampled realizations of the random variables Yti.
persistence probability p(Xt = 1|Y1:N) in the equivalent form:
p(Xt = 1|Y1:N) = p(Y1:N|T ≥t)p(T ≥t)
p(Y1:N)
.
(4)
The prior probability p(T ≥t) follows from (3):
p(T ≥t) = 1 −FT (t).
(5)
The same equivalence of events also implies that the like-
lihood function p(Y1:N|T) has the closed form:
p(Y1:N|T) =
Y
ti≤T
P
1−yti
M
(1−PM)yti Y
ti>T
P
yti
F (1−PF )1−yti.
(6)
We observe that p(Y1:N|T) as deﬁned in (6) is right-
continuous and constant on the intervals [ti, ti+1) for all
i = 0, . . . , N (where here we take t0 ≜0 and tN+1 ≜∞) as
a function of T. These properties can be exploited to derive a
simple closed-form expression for the evidence p(Y1:N):
p(Y1:N) =
Z ∞
0
p(Y1:N|T) · p(T) dT
=
N
X
i=0
Z ti+1
ti
p(Y1:N|ti) · p(T) dT
=
N
X
i=0
p(Y1:N|ti) [FT (ti+1) −FT (ti)] .
(7)
Finally, if t ∈[tN, ∞), then equation (6) shows that:
p(Y1:N|T ≥t) = p(Y1:N|tN) =
N
Y
i=1
P
1−yti
M
(1 −PM)yti.
(8)
By (4), we may therefore recover the posterior persistence
probability p(Xt = 1|Y1:N) as:
p(Xt = 1|Y1:N) = p(Y1:N|tN)
p(Y1:N)
(1 −FT (t)) ,
t ∈[tN, ∞)
(9)
where the likelihood p(Y1:N|tN) and the evidence p(Y1:N)
are computed using (8) and (6)–(7), respectively.
B. Recursive Bayesian estimation
In this subsection we show how to compute p(Xt = 1|Y1:N)
online in constant time through recursive Bayesian estimation.
Observe that if we append an additional observation ytN+1
to the data Y1:N (with tN+1 > tN), then the likelihood
functions p(Y1:N+1|T) and p(Y1:N|T) in (6) satisfy:
p(Y1:N+1|T) =
(
P
ytN+1
F
(1 −PF )1−ytN+1p(Y1:N|T),
T < tN+1,
P
1−ytN+1
M
(1 −PM)ytN+1p(Y1:N|T),
T ≥tN+1.
(10)
In particular, (8) and (10) imply that
p(Y1:N+1|tN+1) = P
1−ytN+1
M
(1 −PM)ytN+1p(Y1:N|tN).
(11)

Algorithm 1 The Persistence Filter
Input: Feature detector error probabilities (PM, PF ),
cumulative distribution function FT (·), feature
detector outputs {yti}.
Output: Persistence beliefs p(Xt = 1|Y1:N) for t ∈[tN, ∞).
1: Initialization: Set t0 ←0, N ←0, p(Y1:0|t0) ←1,
L(Y1:0) ←0, p(Y1:0) ←1.
// Loop invariant: the likelihood p(Y1:N|tN), partial evi-
dence L(Y1:N), and evidence p(Y1:N) are known at entry.
2: while ∃new data ytN+1 do
Update:
3:
Compute the partial evidence L(Y1:N+1) using (14).
4:
Compute the likelihood p(Y1:N+1|tN+1) using (11).
5:
Compute the evidence p(Y1:N+1) using (13).
6:
N ←(N + 1).
Predict:
7:
Compute the posterior persistence probability
p(Xt = 1|Y1:N) for t ∈[tN, ∞) using (9).
8: end while
Similarly, consider the following lower partial sum for the
evidence p(Y1:N) given in (7):
L(Y1:N) ≜
N−1
X
i=0
p(Y1:N|ti) [FT (ti+1) −FT (ti)] .
(12)
From (7) we have:
p(Y1:N) = L(Y1:N) + p(Y1:N|tN) [1 −FT (tN)] ,
(13)
and L(Y1:N+1) and L(Y1:N) are related according to:
L(Y1:N+1) = P
ytN+1
F
(1 −PF )1−ytN+1
× (L(Y1:N) + p(Y1:N|tN) [FT (tN+1) −FT (tN)])
(14)
(this can be obtained by splitting the ﬁnal term from the
sum for L(Y1:N+1) in (12) and then using (10) to write the
likelihoods p(Y1:N+1|ti) in terms of p(Y1:N|ti)).
Equations (11)–(14) admit the implementation of a recur-
sive Bayesian estimator for computing the posterior feature
persistence probability p(Xt = 1|Y1:N) with t ∈[tN, ∞).
The complete algorithm, which we refer to as the persistence
ﬁlter, is summarized as Algorithm 1. An example application
of this ﬁlter is shown in Fig. 1.
V. DESIGNING THE SURVIVAL TIME PRIOR
In this section we describe a practical framework for design-
ing survival time priors pT (·) in (1) using analytical techniques
from survival analysis.
A. Survival analysis
Here we brieﬂy introduce some analytical tools from sur-
vival analysis; interested readers may see [24] for more detail.
A distribution pT (·) over survival time T ∈[0, ∞) is often
characterized in terms of its survival function ST (·):
ST (t) ≜p(T > t) =
Z ∞
t
pT (x) dx = 1 −FT (t);
(15)
this function directly reports the probability of survival beyond
time t, and is thus a natural object to consider in the context
of survival analysis. Another useful characterization of pT (·)
is its hazard function or hazard rate λT (·):
λT (t) ≜lim
∆t→0
p(T < t + ∆t|T ≥t)
∆t
;
(16)
this function reports the probability of failure (or “death”) per
unit time at time t conditioned upon survival until time t (i.e.
the instantaneous rate of failure at time t), and so provides
an intuitive measure of how “hazardous” time t is. We also
deﬁne the cumulative hazard function ΛT (·):
ΛT (t) ≜
Z t
0
λT (x) dx.
(17)
By expanding the conditional probability in (16) and apply-
ing deﬁnition (15), we can derive a pair of useful expressions
for the hazard rate λT (·) in terms of the survival function
ST (·) and the probability density function pT (·):
λT (t) = lim
∆t→0
1
∆t
p(t ≤T < t + ∆t)
p(T ≥t)

= pT (t)
ST (t) = −S′
T (t)
ST (t).
(18)
We recognize the right-hand side of (18) as
d
dt [−ln ST (t)];
by integrating both sides and enforcing the condition that
ST (0) = 1, we ﬁnd that
ST (t) = e−ΛT (t).
(19)
Finally, differentiating both sides of (19) shows that
pT (t) = λT (t)e−ΛT (t),
(20)
which expresses the original probability density function pT (·)
in terms of its hazard function λT (·).
Equations (16) and (19) show that every hazard function
satisﬁes λT (t) ≥0 and limt→∞
R t
0 λT (x)dx = ∞; conversely,
it is straightforward to verify that any function λT : [0, ∞) →
R satisfying these two properties deﬁnes a valid probability
density function pT (·) on [0, ∞) (by means of (20)) for which
it is the hazard function. In the next subsection, we will use this
result to design survival time priors pT (·) for (1) by specifying
their hazard functions λT (·).
B. Survival time belief shaping using the hazard function
While the probability density, survival, hazard, and cumu-
lative hazard functions are all equivalent representations of
a probability distribution over [0, ∞), the hazard function
provides a dynamical description of the survival process (by
specifying the instantaneous event rate), and is thus a natural
domain for designing priors pT (·) that encode information
about how the feature disappearance rate varies over time.
This enables the construction of survival time priors that,
for example, encode knowledge of patterns of activity in the
environment, or that induce posterior beliefs about feature
persistence that evolve in time in a desired way. By analogy
with loop shaping (in which a control system is designed
implicitly by specifying its transfer function), we can think

0
1
2
3
4
5
6
Time (t)
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4
1.6
λT (t)
(a) Hazard function
0
1
2
3
4
5
6
Time (t)
0
1
2
3
4
5
6
7
8
ΛT (t)
(b) Cumulative hazard function
0
1
2
3
4
5
6
Time (t)
0.0
0.2
0.4
0.6
0.8
1.0
ST (t)
(c) Survival function
0
1
2
3
4
5
6
Time (t)
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4
1.6
pT (t)
(d) Probability density function
Fig. 2.
Survival time belief shaping using the hazard function. (a)–(d) show the corresponding hazard, cumulative hazard, survival, and probability density
functions, respectively, for three survival time distributions (colored red, blue, and cyan). Note that even visually quite similar probability density functions
may encode very different rates of feature disappearance as functions of time (compare the red and cyan functions in (a) and (d)), thus illustrating the utility
of analyzing and constructing survival time priors using the hazard function.
of this process of designing the prior pT (·) by specifying its
hazard function λT (·) as survival time belief shaping.
As an illustrative concrete example, Fig. 2 shows several
hazard functions and their corresponding cumulative hazard,
survival, and probability density functions. Consider the red
hazard function in Fig. 2(a), which has a high constant failure
rate for t ∈[0, 3] and falls off rapidly for t > 3. Interpreting
this in terms of feature persistence, this function encodes the
idea that any feature that persists until time t = 3 is likely
static (e.g. part of a wall). Similarly, the blue hazard function
in Fig. 2(a) shows a periodic alternation between high failure
rates over the intervals (k, k + 1
2), k = 0, 1, . . . and zero risk
over the intervals [k + 1
2, k + 1] (i.e. any feature that survives
until k + 1
2 is guaranteed to survive until k +1). This provides
a plausible model of areas which are known to be static at
certain times, e.g. an ofﬁce environment that closes overnight.
This example also serves to illustrate the utility of the
belief-shaping approach. It may not always be clear how to
directly construct a survival-time prior that encodes a given
set of environmental dynamics; for example, comparing the
red and cyan curves in Figs. 2(a) and 2(d) reveals that
even visually-similar probability density functions may encode
radically different environmental properties. In contrast, the
dynamical description provided by the hazard function is
easily interpreted, and therefore easily designed.
C. General-purpose survival time priors
Survival time belief shaping provides an expressive model-
ing framework for constructing priors pT (·) that incorporate
knowledge of time-varying rates of feature disappearance;
however, this approach is only useful when such information is
available. In this subsection, we describe methods for selecting
non-informative priors pT (·) that are safe to use when little is
known in advance about the environmental dynamics.
Our development is motivated by the principle of maximum
entropy [25], which asserts that the epistemologically correct
choice of prior pθ(·) for a Bayesian inference task over a
latent state θ is the one that has maximum entropy (and is
therefore the maximally uncertain or minimally informative
prior), subject to the enforcement of any conditions on θ that
are actually known to be true. The idea behind this principle
is to avoid the selection of a prior that “accidentally” encodes
additional information about θ beyond what is actually known,
and may therefore improperly bias the inference.
From the perspective of belief shaping using the hazard
function, this principle suggests the use of a constant haz-
ard rate (since the use of any non-constant function would
encode the belief that there are certain distinguished times
at which features are more likely to vanish). And indeed,
setting λT (t) ≡λ ∈(0, ∞) corresponds (by means of (20))
to selecting the exponential distribution:
pT (t; λ) = λe−λt,
t ∈[0, ∞)
(21)
which is the maximum entropy distribution amongst all dis-
tributions on [0, ∞) with a speciﬁed expectation E[T]. In the
case of the exponential distribution (21), this expectation is:
E[T] = λ−1
(22)
so we see that the selection of the (hazard) rate parameter λ
in (21) encodes the expected feature persistence time.
We propose several potential methods for selecting this
parameter in practice:
1) Engineering the persistence ﬁlter belief: As can be seen
from (9), the survival function ST (t) = 1−FT (t) controls the
rate of decay of the persistence probability p(Xt = 1|Y1:N)
in the absence of new observations (cf. Fig. 1). The survival
function corresponding to the exponential distribution (21) is
ST (t; λ) = e−λt,
(23)
so that λ has an additional interpretation as a parameter that
controls the half-life τ1/2 of the decay process (23):
τ1/2 = ln(2)/λ.
(24)
Thus, one way of choosing λ is to view it as a design parameter
that enables engineering the evolution of the persistence ﬁlter
belief p(Xt = 1|Y1:N) so as to enforce a desired decay or
“forgetting” rate in the absence of new data.
2) Class-conditional learning: A second approach follows
from the use of a feature detector to generate the observations
in the feature persistence model. For cases in which features
are objects (e.g. chairs or coffee cups) and their detectors are

trained using machine learning techniques, one could use the
training corpus to learn class-conditional hazard rates λ that
characterize the empirical “volatility” of a given class.
3) Bayesian representation of parameter uncertainty: Fi-
nally, in some cases it may not be possible to determine the
“correct” value of the rate parameter λ, or it may be possible to
do so only imprecisely. In these instances, the correct Bayesian
procedure is to introduce an additional prior pλ(·) to model the
uncertainty in λ explicitly; one can then recover the marginal
distribution pT (·) for the survival time (accounting for the
uncertainty in λ) by marginalizing over λ according to:
pT (t) =
Z ∞
0
pT (t; λ) · pλ(λ) dλ.
(25)
Once again we are faced with the problem of selecting a
prior, this time over λ. However, in this instance we know
that λ parameterizes the sampling distribution (21) as a rate
parameter, i.e. we have pT (t; λ) = λf(λt) for some ﬁxed
normalized density f(·) (in this case, f(x) = e−x). Since t
enters the distribution pT (t; λ) in (21) only through the product
λt, we might suspect that pT (t; λ) possesses a symmetry under
the multiplicative group R+ ≜(0, ∞) with action (λ, t) 7→
(qλ, t/q) for q ∈R+. Letting λ′ ≜qλ and t′ ≜t/q, we
ﬁnd that pT (t′; λ′) dt′ = pT (t; λ) dt, which proves that the
probability measure encoded by the density pT (t; λ) is indeed
invariant under this action.
The principle of transformation groups [25] asserts that
any prior pθ(·) expressing ignorance of the parameter of a
sampling distribution py(y|θ) that is invariant under the action
of a group G should likewise be invariant under the same
action. (This principle is closely related to the principle of
indifference, and can be thought of as a generalization of
this principle to the case of priors over continuous parameter
spaces that are equipped with a speciﬁed symmetry group.)
Enforcing this requirement in the case of our rate parameter
λ, it can be shown (cf. [25, Sec. 7]) that the prior we seek
satisﬁes pλ(λ) ∝λ−1. While this is formally an improper
prior, if we incorporate the additional (weak) prior information
that the feature survival processes we wish to model evolve
over timescales (24) on the order of, say, seconds to decades,
we may restrict λ ∈[λl, λu] using (conservative) lower and
upper bounds λl, λu, and thereby recover:
pλ(λ; λl, λu) =
1
λ ln(λu/λl),
λ ∈[λl, λu].
(26)
The marginal density pT (·) obtained from (25) using (21) and
(26) is then:
pT (t; λl, λu) = e−λlt −e−λut
t ln(λu/λl)
(27)
with corresponding survival function:
ST (t; λl, λu) = E1(λlt) −E1(λut)
ln(λu/λl)
,
(28)
where E1(x) is the ﬁrst generalized exponential integral:
E1(x) ≜
Z ∞
1
t−1e−xt dt.
(29)
Equations (27)–(29) deﬁne a class of minimally-informative
“general-purpose” survival time priors that can be safely
applied when little information is available in advance about
rates of feature disappearance in a given environment.
VI. GRAPHICAL SLAM IN SEMI-STATIC ENVIRONMENTS
Finally, we describe how to incorporate the feature per-
sistence model (1) into the probabilistic graphical model
formulation of SLAM to produce a framework for feature-
based mapping in semi-static environments.
The approach is straightforward. Our operationalization
of features as having a ﬁxed geometric conﬁguration but
ﬁnite persistence time enforces a clean separation between
the estimation of environmental geometry and feature persis-
tence. Existing graphical SLAM techniques provide a mature
solution for geometric estimation, and the persistence ﬁlter
provides a solution to persistence estimation. Thus, to extend
the graphical SLAM framework to semi-static environments,
we simply associate a persistence ﬁlter with each feature. In
practice, newly-discovered environmental features are initial-
ized and added to the graph in the usual way, while features
that have “vanished” (those for which p(Xt = 1|Y1:N) < PV
for some threshold probability PV ) can be removed from the
graph by marginalization [26, 27].
VII. EXPERIMENTS
One of the principal motivations for developing the persis-
tence ﬁlter is to support long-term autonomy by enabling a
robot to update its map in response to environmental change.
To that end, consider a robot operating in some environment
for an extended period of time. As it runs, it will from
time to time revisit each location within that environment
(although not necessarily at regular intervals or equally often),
and during each revisitation, it will collect some number of
observations of the features that are visible from that location.
We are interested in characterizing the persistence ﬁlter’s
estimation performance under these operating conditions.4
A. Experimental setup
We simulate a sequence of observations of a single envi-
ronmental feature using the following generative procedure:
1) For a simulation of length L, begin by sampling a feature
survival time T uniformly randomly: T ∼U([0, L]).
2) Sample the time R until revisitation from an exponential
distribution with rate parameter λR: R ∼Exp(λR).
3) Sample the number N ∈{1, 2, . . . , } of observations
collected during this revisitation from a geometric dis-
tribution with success probability pN: N ∼Geo(PN).
4) For each i ∈{1, . . . , N}, sample an observation yi
according to the detector model (2), and a waiting time
Oi until the next observation yi+1 from an exponential
distribution with rate parameter λO: Oi ∼Exp(λO).
4A C++ implementation (with Python bindings) of the persistence ﬁlter,
together with the code used to perform the following experiments, is available
through http://groups.csail.mit.edu/marine/persistence ﬁlter/.

0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40
Probability of missed detection (PM)
0.05
0.10
0.15
0.20
0.25
0.30
0.35
0.40
Probability of false alarm (PF )
0.0
0.1
0.2
0.3
0.4
0.5
(a) Uniform-prior persistence ﬁlter
0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40
Probability of missed detection (PM)
0.05
0.10
0.15
0.20
0.25
0.30
0.35
0.40
Probability of false alarm (PF )
0.0
0.1
0.2
0.3
0.4
0.5
(b) General-purpose persistence ﬁlter
0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40
Probability of missed detection (PM)
0.05
0.10
0.15
0.20
0.25
0.30
0.35
0.40
Probability of false alarm (PF )
0.0
0.1
0.2
0.3
0.4
0.5
(c) Empirical estimator
0.00
0.05
0.10
0.15
0.20
Revisitation rate (λR)
0.00
0.05
0.10
0.15
0.20
0.25
Mean L1 error
Mean absolute error vs. revisitation rate
Uniform-prior PF
General-purpose PF
Empirical estimator
(d) Mean L1 error vs. revisitation rate
Fig. 3.
Feature persistence estimation performance under the average L1 error metric. (a)–(c) plot the mean value of E(Xt, p(Xt = 1|Y1:N)) as
deﬁned in (30) over 100 observation sequences sampled from the generative model of Section VII-A as a function of the detector error rates (PM, PF ) ∈
{.01, .05, .1, .15, .20, .25, .30, .35, .40}2 (holding L = 1000, λR = 1/50, λO = 1, and PN = .2 constant) for the uniform-prior persistence ﬁlter,
general-purpose prior persistence ﬁlter, and empirical estimator, respectively. (d) plots the the mean value of the error E(Xt, p(Xt = 1|Y1:N)) over 100
observation sequences sampled from the generative model of Section VII-A as a function of the revisitation rate λR ∈{1/100, 1/50, 1/25, 1/10, 1/5}
(holding L = 1000, λO = 1, PN = .2, and (PM, PF ) = (.1, .1) constant).
5) Repeat steps 2) through 4) to generate a sequence of
observations {yti} of temporal duration at least L.
We consider the performance of three feature persistence
estimators on sequences drawn from the above model:
• The persistence ﬁlter constructed using the true (uniform)
survival time prior U([0, L]);
• The persistence ﬁlter constructed using the general-
purpose survival time prior deﬁned in (27)–(29) with
(λl, λu) = (.001, 1); and
• The empirical estimator, which reports the most recent
observation ytN as the true state Xt with certainty.
B. Evaluation
We consider two metrics for evaluating the performance of
our estimators: average L1 error and classiﬁcation accuracy.
1) Average L1 error: In our ﬁrst evaluation, we consider
both the ground-truth state indicator variable Xt and the
posterior persistence belief p(Xt = 1|Y1:N) as functions of
time t ∈[0, L] taking values in [0, 1], and adopt as our error
metric E(·, ·) the mean L1 distance between them:
E(f, g) ≜1
L
Z L
0
|f(t) −g(t)| dt,
f, g ∈L1([0, L]).
(30)
Intuitively, the error E(Xt, p(Xt = 1|Y1:N)) measures how
closely an estimator’s persistence belief p(Xt = 1|Y1:N)
tracks the ground truth state Xt over time (graphically, this
corresponds to the average vertical distance between the green
and blue curves in Fig. 1 over the length of the simulation.)
Fig. 3 plots the mean of the error E(Xt, p(Xt = 1|Y1:N))
over 100 observation sequences sampled from the generative
model of Section VII-A as a function of both the feature
detector error rates (PM, PF ) and the revisitation rate λR
for each of the three persistence estimators. We can see that
the uniform-prior persistence ﬁlter strictly dominates the other
two estimators. The general-purpose persistence ﬁlter also
outperforms the empirical estimator across the majority of
the test scenarios; the exceptions are in the low-detector-error-
rate and infrequent-revisitation regimes, in which the L1 error
metric penalizes the decay in the persistence ﬁlter’s belief over
time (cf. Fig. 1), while the empirical estimator always reports
0.0
0.1
0.2
0.3
0.4
0.5
Removal threshold (PV )
0.82
0.84
0.86
0.88
0.90
0.92
0.94
0.96
0.98
1.00
Mean precision
Uniform-prior PF
General-purpose PF
Empirical estimator
(a) Removal precision vs. PV
0.0
0.1
0.2
0.3
0.4
0.5
Removal threshold (PV )
0.74
0.76
0.78
0.80
0.82
0.84
0.86
0.88
0.90
Mean recall
Uniform-prior PF
General-purpose PF
Empirical estimator
(b) Removal recall vs. PV
Fig. 4. Feature removal classiﬁcation performance. (a) and (b) show the mean
removal precision and recall over 100 observation sequences sampled from the
generative model of Section VII-A (with L = 1000, (PM, PF ) = (.1, .1),
λR = 1/50 and λO = 1) as a function of the removal threshold PV ∈
{.01, .05, .1, .15, .2, .25, .3, .35, .4, .45, .5}. For each observation sequence,
the removal precision and recall are computed by querying the persistence
belief p(Xt = 1|Y1:N) at .1-time intervals, thresholding the belief at PV to
obtain a {0, 1}-valued prediction, and computing the precision and recall of
the sequence of “removal” decisions (0-valued predictions).
its predictions with complete certainty. We will see in the next
evaluation that the empirical estimator’s gross overconﬁdence
in its beliefs actually leads to much poorer performance on
feature removal decisions versus the persistence ﬁlter.
2) Classiﬁcation accuracy: In practice, we would use the
persistence belief to decide when a feature should be removed
from a map. While the belief is in [0, 1], the decision to
remove a feature is binary, which means that we must select a
belief threshold PV for feature removal (see Section VI). The
threshold PV thus parameterizes a family of binary classiﬁers
for feature removal, and we would like to characterize the
performance of this family as a function of PV .
Fig. 4 plots the mean precision and recall of these feature
removal decisions over 100 observation sequences sampled
from the generative model of Section VII-A as a function of
PV . We can see that both persistence ﬁlter implementations
signiﬁcantly outperform the empirical estimator in precision
and recall for feature removal decisions. Furthermore, the
loss in performance introduced by using the general-purpose
prior in place of the true (uniform) prior is relatively modest,
validating our earlier development in Section V-C3.

VIII. CONCLUSION
In this paper we proposed the feature persistence model,
a novel feature-based model of environmental temporal evo-
lution, and derived its associated inference algorithm, the
persistence ﬁlter. Our formulation improves upon prior work
on modeling semi-static environments by providing a uniﬁed,
feature-abstracted, information-theoretically rigorous model of
environmental change that can be used in conjunction with any
feature-based environmental representation. Our approach also
provides a remarkably rich modeling framework versus prior
techniques, as it supports the use of any valid survival time
prior distribution (including non-Markovian priors), while still
admitting exact, constant-time online inference.
REFERENCES
[1] S. Thrun, W. Burgard, and D. Fox.
Probabilistic
Robotics. The MIT Press, Cambridge, MA, 2008.
[2] G. Grisetti, R. K¨ummerle, C. Stachniss, and W. Burgard.
A tutorial on graph-based SLAM.
IEEE Intelligent
Transportation Systems Magazine, 2(4):31–43, 2010.
[3] F. Lu and E. Milios. Globally consistent range scan align-
ment for environmental mapping. Autonomous Robots,
4:333–349, April 1997.
[4] D. Koller and N. Friedman.
Probabilistic Graphical
Models: Principles and Techniques.
The MIT Press,
Cambridge, MA, 2009.
[5] S. Thrun and M. Montemerlo. The GraphSLAM algo-
rithm with applications to large-scale mapping of urban
structures. Intl. J. of Robotics Research, 25(5–6):403–
429, 2006.
[6] F. Dellaert. Factor graphs and GTSAM: A hands-on in-
troduction. Technical Report GT-RIM-CP&R-2012-002,
Institute for Robotics & Intelligent Machines, Georgia
Institute of Technology, September 2012.
[7] G. Grisetti, C. Stachniss, and W. Burgard.
Nonlinear
constraint network optimization for efﬁcient map learn-
ing. IEEE Trans. on Intelligent Transportation Systems,
10(3):428–439, September 2009.
[8] R. K¨ummerle, G. Grisetti, H. Strasdat, K. Konolige,
and W. Burgard. g2o: A general framework for graph
optimization.
In IEEE Intl. Conf. on Robotics and
Automation (ICRA), pages 3607–3613, May 2011.
[9] M. Kaess, H. Johannsson, R. Roberts, V. Ila, J.J. Leonard,
and F. Dellaert.
iSAM2: Incremental smoothing and
mapping using the Bayes tree.
Intl. J. of Robotics
Research, 31(2):216–235, February 2012.
[10] D.M. Rosen, M. Kaess, and J.J. Leonard.
RISE: An
incremental trust-region method for robust online sparse
least-squares estimation. IEEE Trans. Robotics, 30(5):
1091–1108, October 2014.
[11] P. Biber and T. Duckett. Dynamic maps for long-term
operation of mobile service robots. In Robotics: Science
and Systems (RSS), Cambridge, MA, USA, June 2005.
[12] P. Biber and T. Duckett.
Experimental analysis of
sample-based maps for long-term SLAM.
Intl. J. of
Robotics Research, 28(1):20–33, January 2009.
[13] W. Churchill and P. Newman. Practice makes perfect?
Managing and leveraging visual experiences for lifelong
navigation. In IEEE Intl. Conf. on Robotics and Automa-
tion (ICRA), pages 4525–4532, St. Paul, MN, May 2012.
[14] K. Konolige and J. Bowman.
Towards lifelong visual
maps. In IEEE/RSJ Intl. Conf. on Intelligent Robots and
Systems (IROS), pages 1156–1163.
[15] K. Konolige, J. Bowman, J.D. Chen, P. Mihelich,
M. Calonder, V. Lepetit, and P. Fua. View-based maps.
Intl. J. of Robotics Research, 29(8):941–957, July 2010.
[16] A. Walcott-Bryant, M. Kaess, H. Johannsson, and J.J.
Leonard. Dynamic pose graph SLAM: Long-term map-
ping in low dynamic environments. In IEEE/RSJ Intl.
Conf. on Intelligent Robots and Systems (IROS), pages
1871–1878, Vilamoura, Algarve, Portugal, October 2012.
[17] D. Meyer-Delius, M. Beinhofer, and W. Burgard. Occu-
pancy grid models for robot mapping in changing envi-
ronments. In Proc. AAAI Conf. on Artiﬁcial Intelligence,
pages 2024–2030, Toronto, Canada, July 2012.
[18] J. Saarinen, H. Andreasson, and A.J. Lilienthal. Indepen-
dent Markov chain occupancy grid maps for representa-
tion of dynamic environments. In IEEE/RSJ Intl. Conf.
on Intelligent Robots and Systems (IROS), pages 3489–
3495, Vilamoura, Algarve, Portugal, October 2012.
[19] H. Moravec and A. Elfes. High resolution maps from
wide angle sonar.
In IEEE Intl. Conf. on Robotics
and Automation (ICRA), pages 116–121, St. Louis, MO,
USA, March 1985.
[20] G.D. Tipaldi, D. Meyer-Delius, and W. Burgard. Lifelong
localization in changing environments. Intl. J. of Robotics
Research, 32(14):1662–1678, December 2013.
[21] G. Grisetti, C. Stachniss, and W. Burgard.
Improved
techniques for grid mapping with Rao-Blackwellized par-
ticle ﬁlters. IEEE Trans. Robotics, 23(1):34–46, February
2007.
[22] M. Cummins and P. Newman. Appearance-only SLAM
at large scale with FAB-MAP 2.0. Intl. J. of Robotics
Research, 30(9):1100–1123, August 2011.
[23] T. Krajn´ık, J.P. Fentanes, G. Cielniak, C. Dondrup, and
T. Duckett. Spectral analysis for long-term robotic map-
ping. In IEEE Intl. Conf. on Robotics and Automation
(ICRA), pages 3706–3711, May 2014.
[24] J.G. Ibrahim, M.-H. Chen, and D. Sinha.
Bayesian
Survival Analysis.
Springer Science+Business Media,
2001.
[25] E.T. Jaynes. Prior probabilities. IEEE Transactions on
Systems Science and Cybernetics, 4(3):227–241, Septem-
ber 1968.
[26] G. Huang, M. Kaess, and J.J. Leonard.
Consistent
sparsiﬁcation for graph optimization. In European Conf.
on Mobile Robotics (ECMR), pages 150–157, Barcelona,
Spain, September 2013.
[27] M. Mazuran, G.D. Tipaldi, L. Spinello, and W. Burgard.
Nonlinear graph sparsiﬁcation for SLAM. In Robotics:
Science and Systems (RSS), Berkeley, CA, USA, 2014.

