ON
LEARNING
HO
W
TO
LEARN
LEARNING
STRA
TEGIES
T
ec
hnical
Rep
ort
FKI-	-	
(revised)
J

urgen
Sc
hmidh
ub
er
F
akult
at
f

ur
Informatik
T
ec
hnisc
he
Univ
ersit
at
M

unc
hen
0	0
M

unc
hen,
German
y
schmidhu@
inf
orm
ati
k.
tu-
mue
nc
hen
.de
http://pap
a.i
nfo
rm
ati
k.t
u-m
ue
nch
en.
de
/mi
tar
bei
te
r/s
chm
idh
u.
htm
l
Revised
Jan
uary
,
		
Abstract
This
pap
er
in
tro
duces
the
\incremen
tal
self-impro
v
emen
t
paradigm".
Unlik
e
previous
metho
ds,
incremen
tal
self-impro
v
emen
t
encourages
a
reinforcemen
t
learning
system
to
impro
v
e
the
w
a
y
it
learns,
and
to
impro
v
e
the
w
a
y
it
impro
v
es
the
w
a
y
it
learns
...,
without
signican
t
theoretical
limi-
tations
|
the
system
is
able
to
\shift
its
inductiv
e
bias"
in
a
univ
ersal
w
a
y
.
Its
ma
jor
features
are:
()
There
is
no
explicit
dierence
b
et
w
een
\learning",
\meta-learning",
and
other
kinds
of
informa-
tion
pro
cessing.
Using
a
T
uring
mac
hine
equiv
alen
t
programming
language,
the
system
itself
o
cca-
sionally
executes
self-delimiti
ng,
initiall
y
highly
random
\self-mo
dicatio
n
programs"
whic
h
mo
dify
the
con
text-dep
enden
t
probabili
ties
of
future
action
sequences
(includin
g
future
self-mo
dication
programs).
()
The
system
k
eeps
only
those
probabili
t
y
mo
dications
computed
b
y
\useful"
self-
mo
dication
programs:
those
whic
h
bring
ab
out
more
pa
y
o
(rew
ard,
reinforcemen
t)
p
er
time
than
all
previous
self-mo
dication
programs.
()
The
computation
of
pa
y
o
p
er
time
tak
es
in
to
accoun
t
all
the
computation
time
required
for
learning
|
the
entir
e
system
life
is
considered:
b
oundaries
b
et
w
een
learning
trials
are
ignored
(if
there
are
an
y).
A
particular
implemen
tation
based
on
the
no
v
el
paradigm
is
presen
ted.
It
is
designed
to
exploit
what
con
v
en
tional
digital
mac
hines
are
go
o
d
at:
fast
storage
addressing,
arithmetic
op
erations
etc.
Exp
erimen
ts
illustrate
the
system's
mo
de
of
op
eration.
Keyw
ords:
Self-impr
ovement,
self-r
efer
enc
e,
intr
osp
e
ction,
machine-le
arning,
r
einfor
c
ement
le
arning.
Note:
This
is
the
r
evise
d
and
extende
d
version
of
an
e
arlier
r
ep
ort
fr
om
Novemb
er
,
		.



Intr
oduction
A
recen
t
debate
in
the
mac
hine-learning
comm
unit
y
highligh
ted
a
fact
that
app
ears
discouraging
at
rst
glance:
in
general,
generalization
cannot
b
e
exp
ected,
inductiv
e
inference
is
imp
ossible,
and
nothing
can
b
e
learned.
See,
e.g.,
(Dietteric
h,
		;
Sc
haer,
		;
W
olp
ert,
		;
Sc
hmidh
ub
er,
		).
P
araphrasing
from
a
previous
argumen
t
(Sc
hmidh
ub
er,
		):
let
the
task
b
e
to
learn
some
relation
b
et
w
een
nite
bitstrings
and
nite
bitstrings.
Someho
w,
a
training
set
is
c
hosen.
In
almost
all
cases,
the
shortest
algorithm
computing
a
(non-o
v
erlapping)
test
set
essen
tially
has
the
same
size
as
the
whole
test
set.
This
is
b
ecause
most
computable
ob
jects
are
irregular
and
incompressible
(Kolmogoro
v,
	;
Chaitin,
		).
The
shortest
algorithm
computing
the
test
set,
giv
en
the
training
set,
isn't
an
y
shorter.
In
other
w
ords,
the
relativ
e
algorithmic
complexit
y
of
the
test
set,
giv
en
the
training
set,
is
maxim
al
,
and
the
m
utual
algorithmic
information
b
et
w
een
test
set
and
training
set
is
zero
(ignoring
an
additiv
e
constan
t
indep
enden
t
of
the
problem
|
see
e.g.
Kolmogoro
v,
	;
Chaitin,
		;
Solomono,
	;
Li
and
Vit
an
yi,
		).
Therefore,
in
almost
all
cases,
()
kno
wledge
of
the
training
set
do
es
not
pro
vide
an
y
clues
ab
out
the
test
set,
()
there
is
no
hop
e
for
generalization,
and
()
inductiv
e
inference
do
es
not
mak
e
an
y
sense.
A
t
ypical
real
w
orld
/
Previous
learning
algorithms
.
Apparen
tly
,
ho
w
ev
er,
generalization
and
inductiv
e
inference
do
mak
e
sense
in
the
real
w
orld!
One
reason
for
this
ma
y
b
e
that
the
real
w
orld
is
run
b
y
a
short
algorithm.
See
(Sc
hmidh
ub
er,
		).
An
yw
a
y
,
problems
that
h
umans
consider
to
b
e
typic
al
are
atypic
al
when
compared
to
the
general
set
of
all
w
ell-dened
problems.
Otherwise,
things
lik
e
\learning
b
y
analogy",
\learning
b
y
c
h
unking",
\incremen
tal
learning",
\con
tin
ual
learning",
\learning
from
in
v
ariances",
\learning
b
y
kno
wledge
transfer"
etc.
w
ould
not
b
e
p
ossible,
and
exp
erience
with
previous
problems
could
not
sensibly
adjust
the
prior
distribution
of
solution
candidates
in
the
searc
h
space
for
a
new
problem
(shift
of
inductiv
e
bias,
e.g.
Utgo,
	).
In
fact,
al
l
previous
learning
systems
are
implicitly
or
explicitly
designed
to
exploit
task-sp
ecic
regularities
of
some
kind
or
another.
No
previous
learning
system,
ho
w
ev
er,
is
designed
to
mak
e
optimal
use
of
its
computational
time/space
resources,
b
y
exploiting
arbitr
ary,
task-sp
ecic
regularities
(if
there
are
an
y).
Suc
h
a
system
w
ould
ha
v
e
to
b
e
able
()
to
dev
elop
arbitr
ary
problem-sp
ecic
represen
tations,
()
to
run
arbitr
ary
learning
al-
gorithms,
and
()
to
nd
the
\go
o
d",
problem-sp
ecic
learning
algorithms,
as
quic
kly
as
p
ossible.
In
particular,
it
w
ould
ha
v
e
to
b
e
able
to
nd
algorithms
for
nding
learning
algorithms
etc.
Self-impro
v
emen
t
.
Is
it
p
ossible
to
build
suc
h
a
system?
A
system
that
can
tailor
its
learning
b
eha
vior
to
the
requiremen
ts
of
a
giv
en
en
vironmen
t
with
arbitrary
,
initially
unkno
wn,
problem-sp
ecic
regularities?
A
system
that
can
learn
to
impro
v
e
its
o
wn
learning
strategy
in
a
univ
ersal
w
a
y
,
with-
out
an
y
signican
t
theoretical
limitati
ons
other
than
those
imp
osed
b
y
the
niteness
of
the
hardw
are?
In
principle,
the
answ
er
is
y
es.
The
system
describ
ed
in
this
pap
er
uses
the
no
v
el
\incr
emental
self-
impr
ovement
p
ar
adigm"
to
exploit
\b
enign"
en
vironmen
ts
in
a
more
general
w
a
y
than
previous
systems.
Some
of
its
prop
erties
are:
()
Unlik
e
e.g.
hillclim
bing/
ev
olutio
nary/genetic/other
algorithms,
it
p
o-
ten
tially
can
ev
olv
e
its
o
wn
\smart"
searc
h
strategies
(as
opp
osed
to
\dum
b",
non-adaptiv
e
strategies
lik
e
the
ones
em
b
o
died
b
y
random
m
utation,
\crosso
v
er"
etc.).
()
Unlik
e
with
previous,
less
realistic
approac
hes,
eac
h
ev
en
t
in
system
life
is
view
ed
as
a
singular
ev
en
t
|
learning
is
inductiv
e
inference
from
non-rep
eatable
exp
eriences.
()
Unlik
e
with
previous
approac
hes,
the
system's
ob
jectiv
e
function
tak
es
in
to
accoun
t
the
computation
time
required
for
learning.
Outline.
Section

lists
essen
tial
ingredien
ts
of
the
incremen
tal
self-impro
v
emen
t
paradigm.
Sec-
tion

exemplies
the
basic
principles,
b
y
describing
and
justifying
a
concrete
(w
orking)
implemen
ta-
tion.
Tw
en
t
y
commen
ts
on
b
oth
general
and
implemen
tatio
n-sp
ecic
prop
erties
of
incremen
tal
self-
impro
v
emen
t
can
b
e
found
in
section
.
Illustrativ
e
applications
to
to
y
problems
(including
a
simple
\non-Mark
o
vian"
maze
task)
will
follo
w
in
section
.
Section

will
then
briey
describ
e
the
history
of
related
ideas.



The
Increment
al
Self-Impr
o
vement
P
aradigm
Incremen
tal
self-impro
v
emen
t
is
a
mac
hine-learning
paradigm
designed
for
a
system
executing
a
lifelong
sequence
of
actions
in
an
arbitrary
en
vironmen
t.
The
system's
goal
is
to
maxim
ize
cum
ulativ
e
pa
y
o
(reinforcemen
t,
rew
ard)
to
b
e
obtained
throughout
its
en
tire
span
of
life.
T
o
ac
hiev
e
its
goal,
the
system
con
tin
ually
attempts
to
create
action
subsequences
leading
to
faster
and
faster
pa
y
o
in
tak
e.
The
cen
tral
ideas
are
as
follo
ws:
.
Computing
self-mo
dicati
on
s.
The
initially
highly
random
actions
of
the
system
actually
are
primitiv
e
instructions
of
a
T
uring
mac
hine
equiv
alen
t
programmi
ng
language,
whic
h
allo
ws
for
implemen
ting
arbitrary
learning
algorithms.
Action
subsequences
represen
t
either
()
\nor-
mal"
in
teractions
with
the
en
vironmen
t,
or
()
\self-mo
dication
programs".
Self-mo
dication
programs
can
arbitrarily

mo
dify
the
probabilities
of
future
action
subsequences,
including
fu-
ture
self-mo
dication
programs:
the
learning
system
is
able
to
mo
dify
itself
in
a
univ
ersal
w
a
y
.
There
is
no
explicit
dierence
b
et
w
een
\learning",
\meta-learning",
and
other
kinds
of
information
pro
cessing.
.
Life
is
one-w
a
y
.
Eac
h
action
of
the
learning
system
(including
probabilit
y
mo
difying
actions
executed
b
y
self-mo
dication
programs)
is
view
ed
as
a
singular
ev
en
t
in
the
history
of
system
life.
Unrealistic
concepts
suc
h
as
\exactly
rep
eatable
training
iterations",
\b
oundaries
b
et
w
een
trials",
\ep
o
c
hs",
etc.
are
thro
wn
o
v
erb
oard.
In
general,
the
en
vironmen
t
cannot
b
e
reset.
Life
is
one-w
a
y
.
Learning
is
inductiv
e
inference
from
non-rep
eatable
exp
eriences.
.
Ev
aluations
of
self-mo
dicati
on
programs.
The
system
has
a
time-v
arying
utilit
y
v
alue,
whic
h
is
the
a
v
erage
pa
y
o
p
er
time
since
system
start-up.
Eac
h
self-mo
dication
program
also
has
a
time-v
arying
utilit
y
v
alue.
This
v
alue
is
the
a
v
erage
amoun
t
of
pa
y
o
p
er
time
measured
since
the
program
b
egan
execution.
Ev
aluations
of
utilit
y
tak
e
in
to
accoun
t
all
the
computation
time
required
for
learning,
including
the
time
required
for
ev
aluating
utilit
y
.
.
Useful
self-mo
dicati
on
programs
accelerate
pa
y
o
in
tak
e.
The
system
k
eeps
trac
k
of
probabilit
y
mo
dications
computed
b
y
self-mo
dication
programs
that
it
considers
useful.
Use-
fulness
is
dened
recursiv
ely
.
If
there
are
no
previous
useful
self-mo
dication
programs
(e.g.
at
system
start-up),
a
new
self-mo
dication
program
is
considered
useful
only
for
as
long
as
its
utilit
y
v
alue
exceeds
the
system's
utilit
y
v
alue.
More
recen
t
self-mo
dication
programs
are
considered
useful
for
as
long
as
they
ha
v
e
higher
utilit
y
v
alues
than
all
preceding
self-mo
dication
programs
curren
tly
considered
useful.
Essen
tially
,
the
system
only
k
eeps
mo
dications
to
its
probabilit
y
v
alues
that
originated
from
useful
self-mo
dication
programs.
The
result
is
that
pa
y
o
in
tak
e
is
constan
tly
accelerated.
Ov
er
time,
the
system
tends
to
mak
e
b
etter
and
b
etter
use
of
its
computational
resources.

A
Concrete,
W
orking
Implement
a
tion
This
section
presen
ts
one
of
man
y
p
ossible
implemen
tations
of
the
incremen
tal
self-impro
v
emen
t
paradigm.
The
implem
en
tation
mak
es
use
of
an
in
teger-based
programmi
ng
language.
The
language
is
assem
bler-
lik
e
and
has
primitiv
e
instructions
designed
to
exploit
what
con
v
en
tional
digital
mac
hines
are
go
o
d
at:
fast
storage
addressing,
jumping,
basic
arithmetic
op
erations,
etc.
The
language
is
univ
ersal
(i.e.,
T
ur-
ing
mac
hine
equiv
alen
t).
It
is
related
to
one
previously
published
(Sc
hmidh
ub
er,
		),
but
there
are
signican
t
dierences
and
extensions.
In
particular,
this
language
is
\self-referen
tial"
in
a
manner
that
will
b
e
describ
ed
b
elo
w.

Throughout
this
pap
er,
when
referring
to
\arbitrary"
mo
dicatio
ns,
functions,
etc.,
there
is
only
one
essen
tial
require-
men
t
of
these
mo
dicatio
ns
or
functions:
they
m
ust
b
e
computable.


.
O
ver
view
The
system
has
a
nite
amoun
t
of
addressable
storage
brok
en
in
to
t
w
o
groups:
work
c
el
ls
and
pr
o
gr
am
c
el
ls.
The
system
exists
in
an
envir
onment
,
that
o
ccasionally
writes
inputs
in
to
certain
w
ork
cells.
No
assumptions
are
made
ab
out
the
en
vironmen
t
(it
ma
y
or
ma
y
not
b
e
non-deterministic,
for
example).
There
is
a
xed
set
I
of
in
teger
instruction
v
alues
and
in
teger
argumen
t
v
alues.
There
is
also
an
in
ternal
v
ariable
(not
stored
in
an
addressable
cell)
called
the
Instruction
Pointer
(IP),
whic
h
alw
a
ys
p
oin
ts
to
one
of
the
program
cells
(initially
to
the
rst
one).
F
or
eac
h
program
cell
and
for
ev
ery
p
ossible
instruction
and
instruction
argumen
t,
there
is
a
proba-
bilit
y
v
alue
P
ij
;
where
i
is
the
index
of
a
program
cell,
and
j

I
.
P
ij
sp
ecies
for
cell
i
the
conditional
probabilit
y
that,
when
p
oin
ted
to
b
y
IP,
its
con
ten
ts
will
b
e
j
.
If
IP
=
i
and
the
con
ten
ts
of
i
is
in
ter-
preted
as
an
instruction,
then
the
cells
that
imm
ediately
follo
w
i
will
b
e
in
terpreted
as
the
instruction's
argumen
ts.
If
the
instruction
and
its
argumen
ts
pass
a
syn
tax
c
hec
k,
the
instruction
is
executed.
This
ma
y
result
in
mo
dications
of
IP
and/or
en
vironmen
t
and/or
storage.
If
the
test
is
not
passed,
the
IP
is
reset
to
the
rst
program
cell.
If
the
instruction
do
es
not
itself
mo
dify
IP
(with
a
\jump"
instruction),
then
IP
is
incremen
ted
to
p
oin
t
to
the
follo
wing
cell.
This
instruction
cycle
is
rep
eated
o
v
er
and
o
v
er
again
and
represen
ts
the
basic
op
eration
of
the
system.
Some
instructions
are
sp
ecial
\self-r
efer
ential"
instructions.
Tw
o
of
them
can
address
and
mo
dify
arbitrary
P
ij
v
alues
(and
they
are
the
only
instructions
that
can
do
this).
There
is
also
another
self-
referen
tial
instruction
that
groups
a
sequence
of
probabilit
y-modifyi
ng
instructions
and
other
instructions
in
to
a
self-delimiting
self-mo
dic
ation
pr
o
gr
am
|
so
named
b
ecause
the
end
of
suc
h
a
program
is
com-
puted
b
y
itself.
Some
of
the
(initially
highly
random)
action
subsequences
executed
during
system
life
will
indeed
b
e
self-delimiting
self-mo
dication
programs.
They
can
compute
arbitrary
sequences
of
mo
d-
ications
of
P
ij
v
alues,
resulting
in
arbitrary
mo
dications
of
con
text-dep
enden
t
probabilities
of
future
action
subsequences,
including
future
self-mo
dication
programs.
Occasionally
the
en
vironmen
t
ma
y
pro
vide
\pa
y
o
"
|
a
real
n
um
b
er
indicating
ho
w
w
ell
the
system
has
done.
The
system's
goal
is
to
maximi
ze
the
sum
of
all
pa
y
os
to
b
e
obtained
throughout
its
en
tire
(initially
unkno
wn)
life
span.
This
is
done
as
follo
ws:
The
pa
y
o/time
ratio
is
constan
tly
monitored
and
up
dated
after
ev
ery
instruction.
There
is
an
unmo
diable
top-level
cr
e
dit
assignment
str
ate
gy
.
It
also
executes
after
eac
h
instruction
except
when
a
self-mo
dication
program
is
running.
The
task
of
the
top-lev
el
is
to
coun
termand
the
mo
dications
to
the
P
ij
v
alues
that
w
ere
made
b
y
self-mo
dication
programs
no
longer
considered
useful
(see
recursiv
e
description
in
section
).
This
coun
termanding
is
done
b
y
restoring
\old"
probabilit
y
distributions
sa
v
ed
on
to
a
stac
k
b
efore
the
corresp
onding
self-mo
dication
programs
mo
died
them.
The
computation
time
required
for
top-lev
el
managemen
t
is
tak
en
in
to
accoun
t
when
measuring
usefulness.
It
will
b
e
seen
that
this
sc
heme
fa
v
ors
sequences
of
useful
self-mo
dication
programs
leading
to
faster
and
faster
pa
y
o
in
tak
e.
In
particular,
self-mo
dication
programs
can
pro
v
e
their
long
term
usefulness
b
y
setting
the
stage
for
additional,
useful
self-mo
dication
programs,
whic
h
p
oten
tially
include
programs
executing
kno
wn
(and
not
y
et
kno
wn)
learning
algorithms.
This
encourages
\learning
ho
w
to
learn".
.
Technical
Det
ails
Span
of
system
life.
F
or
simplicit
y
,
w
e
assume
discrete
time.
System
life
b
egins
at
\birth,"
time
step
zero.
It
ends
at
\death,"
time
step
T
.
T
is
not
necessarily
kno
wn
in
adv
ance.
Goal
/
P
a
y
o.
Occasionally
,
the
en
vironmen
t
pro
vides
\pa
y
o
".
P
a
y
o
is
an
in
teger
n
um
b
er
dep
ending
on
the
tasks
to
b
e
solv
ed.
The
sum
of
al
l
pa
y
os
obtained
b
et
w
een
birth
and
time
t
>
0
is
denoted
b
y
R(t).
Throughout
its
lifetime,
the
system's
goal
is
to
maxim
ize
R(T
),
the
cum
ulativ
e
pa
y
o
at
\death".
A
t
a
giv
en
time,
the
system
can
only
maxim
ize
future
pa
y
o
|
the
past
is
already
gone.
Storage.
The
system's
stor
age
is
a
single
arra
y
of
cells.
Eac
h
cell
has
an
in
teger
address
in
the
in
terv
al
[M
in;
M
ax].
Max
is
a
p
ositiv
e
in
teger.
Min
is
a
negativ
e
in
teger.
a
i
denotes
the
cell
with
address
i.
The
v
ariable
con
ten
ts
of
a
i
are
denoted
b
y
c
i

[ M
axint;
M
axint],
and
are
of
t
yp
e
in
teger
as
w
ell
(M
axint

M
ax;
M
axint

abs(M
in)).
Sp
ecial
addresses,
I
nputS
tar
t,
I
nputE
nd,
Reg
ister
S
tar
t,
and


Primitiv
e
Seman
tics
Stop()
Halt
curren
t
run
Jmp(a)
IP
 
c
a
Jmpleq(a,
a,
a)
If
c
c
a
<
c
c
a
IP
 
c
a
Jmp
eq(a,
a,
a)
If
c
c
a
=
c
c
a
IP
 
c
a
Add(a,
a,
a)
c
c
a
 
c
c
a
+
c
c
a
Sub(a,
a,
a)
c
c
a
 
c
c
a
 c
c
a
Mul(a,
a,
a)
c
c
a
 
c
c
a

c
c
a
Div(a,
a,
a)
c
c
a
 
c
c
a
=c
c
a
(in
teger
division)
Rem(a,
a,
a)
c
c
a
 
remainder(c
c
a
=c
c
a
)
Inc(a)
c
c
a
 
c
c
a
+

Dec(a)
c
c
a
 
c
c
a
 
Mo
v(a,
a)
c
c
a
 
c
c
a
Init(a,
a)
c
a P
r
og
r
amS
tar
t 
 
a
Output
i
(...)
i-th
problem
sp
ecic
primitiv
e
for
inuencing
the
en
vironmen
t
Input
i
(...)
i-th
primitiv
e
for
p
erceiving
en
vironmen
tal
input
GetP(a,
a,
a)
c
c
a
 
r
ound(M
axint

P
c
a
;c
a
)
IncP(a,
a,
a)
k
=
c
a
:
P
c
a
;k
 
0:0c
c
a
P
c
a
;k
;
P
c
a
;c
a
 

 0:0c
c
a
(
 P
c
a
;c
a
)
DecP(a,
a,
a)
k
=
c
a
:
P
c
a
;k
 
 0:0c
c
a
P
c
a
;c
a
 P
c
a
;c
a
P
c
a
;k
;
P
c
a
;c
a
 
0:0c
c
a
P
c
a
;c
a
EndSelfMo
d()
Enable
top
lev
el
strategy
for
restoring
probabilities
(see
text)
T
able
:
Semantics
of
primitives
and
their
p
ar
ameters.
The
\normal"
primitives
ar
e
shown
in
the
top
blo
ck;
the
\self-r
efer
ential"
primitives
ar
e
shown
in
the
b
ottom
blo
ck.
Note
the
extensive
use
of
double-
indexe
d
indir
e
ct
addr
essing.
R
esults
of
arithmetic
op
er
ations
le
ading
to
underow/overow
ar
e
r
eplac
e
d
by
 M
axint/M
axint,
r
esp
e
ctively.
The
same
holds
for
p
ositive
and
ne
gative
divisions
by
zer
o.
DecP
and
IncP
have
no
ee
ct
if
the
indir
e
ctly
addr
esse
d
c
el
l
c
ontents
c
c
a
ar
e
not
an
inte
ger
b
etwe
en

and
		,
or
if
the
c
orr
esp
onding
pr
ob
ability
mo
dic
ation
would
le
ad
to
at
le
ast
one
P
value
b
elow
MinP.
Rules
for
syn
tactic
correctness:
IP
may
p
oint
to
any
pr
o
gr
am
c
el
l
a
i
,
i
<
M
ax
 
(enough
sp
ac
e
has
to
b
e
left
for
ar
guments).
Op
er
ations
that
r
e
ad
c
el
l
c
ontents
(such
as
Add,
Mo
v
e,
Jumpleq
etc.)
may
r
e
ad
only
fr
om
existing
addr
esses
in
stor
age.
Op
er
ations
that
write
c
el
l
c
ontents
(such
as
Add,
Mo
v
e,
GetP
etc.)
may
write
only
into
work
ar
e
a
addr
esses
in
[M
in;
P
r
og
r
amS
tar
t
 ].
P
r
og
r
amS
tar
t,
are
used
to
further
divide
storage
in
to
segmen
ts:
Min
<
InputStart

InputEnd
<
0
=
R
e
gisterStart
<
Pr
o
gr
amStart
<
Max.
The
input
ar
e
a
is
the
set
of
input
c
el
ls
fa
i
:
I
nputS
tar
t

i

I
nputE
ndg.
The
r
e
gister
ar
e
a
is
the
set
of
r
e
gister
c
el
ls
fa
i
:
0

i
<
P
r
og
r
amS
tar
tg.
\Registers"
are
con
v
enien
t
for
indirect-addressing
purp
oses.
The
pr
o
gr
am
ar
e
a
is
the
set
of
pr
o
gr
am
c
el
ls
fa
i
:
P
r
og
r
amS
tar
t

i
<
M
axg.
In
teger
sequences
in
the
program
area
are
in
terpreted
as
executable
co
de.
The
work
ar
e
a
is
the
set
of
work
c
el
ls
fa
i
:
M
in

i
<
P
r
og
r
amS
tar
tg.
Instructions
executed
in
the
program
area
ma
y
read
from
and
write
to
the
w
ork
area.
Both
register
area
and
input
area
are
subsets
of
the
w
ork
area.
En
vironmen
tal
inputs.
A
t
ev
ery
time
step,
new
inputs
from
the
en
vironmen
t
ma
y
b
e
written
in
to
the
input
cells.
Primitiv
e
s.
The
n
um
b
er
of
instructions
is
n
ops
(n
ops
<<
M
axint).
Eac
h
suc
h
\primitiv
e"
is
rep-
resen
ted
b
y
a
unique
n
um
b
er
in
the
set
f0;
;
:
:
:
;
n
ops
 g
(due
to
the
co
de
b
eing
written
in
C).
The
primitiv
e
with
n
um
b
er
j
is
denoted
b
y
p
j
.
Primitiv
es
ma
y
ha
v
e
from
zero
to
three
argumen
ts,
eac
h
of
whic
h
has
a
v
alue
in
f0;
;
:
:
:
;
n
ops
 g.
The
seman
tics
of
the
primitiv
es
and
their
corresp
onding
argumen
ts
are
giv
en
in
T
able
.
The
non-self-referen
tial
(\normal")
primitiv
es
include
actions
for
com-
parisons,
and
conditional
jumps,
for
cop
ying
storage
con
ten
ts,
for
initializing
certain
storage
cells
with


small
in
tegers,
and
for
adding,
m
ultiplying
,
dividing,
and
halting.
They
also
include
output
actions
for
mo
difying
the
en
vironmen
t,
and
input
actions
for
p
erceiving
en
vironmen
tal
states.
The
\self-referen
tial"
primitiv
es
will
b
e
describ
ed
in
detail
b
elo
w.
Primitiv
e
and
argumen
t
probabili
t
ies
.
F
or
eac
h
cell
a
i
in
the
program
area,
there
is
a
discrete
probabilit
y
distribution
P
i
o
v
er
the
set
of
p
ossible
cell
con
ten
ts.
The
v
ariable
InstructionPointer
(IP)
alw
a
ys
p
oin
ts
to
one
of
the
program
cells.
If
IP
=
i
and
i
<
M
ax
 ,
then
P
ij
denotes
the
probabilit
y
of
selecting
primitiv
e
p
j
as
the
next
instruction.
The
restriction
i
<
M
ax
 
is
needed
to
lea
v
e
ro
om
for
the
instruction's
p
ossible
argumen
ts
should
it
require
an
y
.
Once
p
j
is
selected:
c
i
 
j
.
If
p
j
has
a
rst
argumen
t,
then
P
i+;k
is
the
probabilit
y
of
k
b
eing
c
hosen
as
its
actual
v
alue,
for
k

f0;
;
:
:
:
;
n
ops
 g.
Once
some
k
is
selected:
c
i+
 
k
.
Analoguously
,
if
p
j
has
a
second
argumen
t,
then
P
i+;l
is
the
probabilit
y
of
l
b
eing
c
hosen
as
its
actual
v
alue,
for
l

f0;
;
:
:
:
;
n
ops
 g.
Once
some
l
is
selected:
c
i+
 
l
.
And
nally
,
if
p
j
has
a
third
argumen
t,
then
P
i+;m
is
the
probabilit
y
of
m
b
eing
c
hosen
as
its
actual
v
alue,
for
m

f0;
;
:
:
:
;
n
ops
 g.
Once
some
m
is
selected:
c
i+
 
m.
Argumen
ts
p
oin
t
to
storage
addresses.
T
o
reduce
the
n
um
b
er
of
probabilit
y
v
alues
for
eac
h
program
cell,
primitiv
e
argumen
ts
are
restricted
to
only
n
ops
dieren
t
v
alues.
Therefore,
to
allo
w
all
storage
cells
to
b
e
addressed,
double
indexed
indirect
addressing
is
used
for
most
instructions.
That
is,
(for
most
instructions)
the
argumen
ts
p
oin
t
to
cells
in
the
register
area,
whic
h
in
turn
p
oin
t
to
cells
in
storage.
Recall
that
the
range
of
v
alues
a
v
ailable
to
registers
(and
other
w
ork
cells)
is
far
less
restricted,
whic
h
eectiv
ely
allo
ws
all
storage
cells
to
b
e
addressed.
Self-referen
ti
al
primiti
v
es.
Tw
o
sp
ecial
primitiv
es,
De
cP
and
IncP,
ma
y
b
e
used
to
address
and
mo
dify
the
curren
t
probabilit
y
distribution
of
an
y
program
cell
(see
T
able
).
With
the
action
De
cP,
the
P
ij
v
alue
for
a
particular
cell/v
alue
pair
(a
i
;
j
)
can
b
e
decreased
b
y
some
factor
in
f0:0,
0:0,
:
:
:
,
0:		g.
The
probabilities
for
that
cell
are
then
normalized.
Lik
ewise,
with
the
action
IncP,
the
c
omplement
(
 P
ij
)
of
the
P
ij
v
alue
for
a
particular
cell
a
i
and
v
alue
j
can
b
e
decreased
b
y
a
factor
in
f0:0;
0:0;
:
:
:
;
0:		g
(and
the
cell
probabilities
are
again
renormalized).
De
cP
and
IncP
ha
v
e
no
eect
if
the
indirectly
addressed
cell
con
ten
ts
c
c
a
(see
T
able
)
are
not
an
in
teger
b
et
w
een

and
		,
or
if
the
corresp
onding
probabilit
y
mo
dication
w
ould
lead
to
at
least
one
P
v
alue
b
elo
w
MinP
(a
small
p
ositiv
e
constan
t).
The
primitiv
e
GetP
can
b
e
used
to
write
scaled
v
ersions
of
curren
t
probabilit
y
v
alues
in
to
w
ork
cells.
GetP
is
p
oten
tially
useful
for
purp
oses
of
in
trosp
ection.
Instruction
cycle.
A
single
step
of
the
interpr
eter
w
orks
as
follo
ws:
if
IP
p
oin
ts
to
program
cell
a
i
,
a
primitiv
e
and
the
corresp
onding
argumen
ts
are
c
hosen
randomly
according
to
the
curren
t
probabilit
y
distributions,
as
already
describ
ed.
They
are
sequen
tially
written
on
to
the
program
area,
starting
from
a
i
.
Syn
tax
c
hec
ks
are
p
erformed.
Rules
for
syn
tactic
correctness
are
giv
en
in
the
caption
of
T
able
.
If
syn
tactically
correct,
the
instruction
gets
executed.
Otherwise,
the
curren
t
\run"
(see
next
paragraph)
is
halted.
If
the
program
did
not
halt
nor
c
hange
the
v
alue
of
IP
(e.g.
b
y
causing
a
jump),
IP
is
set
to
the
address
of
the
cell
follo
wing
the
last
argumen
t
of
the
curren
t
instruction.
Runs.
In
the
b
eginning
of
a
\run",
IP
is
set
equal
to
P
r
og
r
amS
tar
t,
and
the
instruction
cycle
is
rep
eated
un
til
a
halt
situation
(e.g.
syn
tax
error)
is
encoun
tered.
Due
to
MinP
b
eing
p
ositiv
e,
there
is
alw
a
ys
a
non-v
anishing
halting
probabilit
y
.
System
life.
A
t
time
step
0,
storage
is
initialized
with
zeros.
The
probabilit
y
distributions
of
all
program
cells
are
initialized
with
maxim
um
en
trop
y
distributions
(Shannon,
	).
That
is,
all
P
ij
v
alues
are
initialized
to
the
same
v
alue,
so
that
there
is
no
bias
for
a
particular
v
alue
in
an
y
cell.
After
initialization,
runs
are
rep
eated
o
v
er
and
o
v
er
again
un
til
time
T
.
Recall
that
T
do
es
not
ha
v
e
to
b
e
kno
wn
in
adv
ance.
W
ork
area
as
part
of
the
en
vironmen
t
.
Neither
storage
nor
en
vironmen
t
are
re-initialized
after
eac
h
run.
The
system
migh
t
use
the
en
vironmen
t
to
store
represen
tations
of
previous
ev
en
ts,
b
y
executing
actions
that
mo
dify
the
en
vironmen
t

.
Lik
ewise,
the
program
area
ma
y
use
the
w
ork
area
to
store
represen
tations
of
previous
ev
en
ts.
Th
us,
the
w
ork
area
ma
y
b
e
view
ed
as
part
of
the
total
en
vironmen
t
of
the
program
area.

Leslie
Kaelbling
sometimes
refers
to
this
as
\writing
on
the
wal
ls"
but
sa
ys
that
the
\real"
name
is
\stigmer
gy"
(p
ersonal
comm
unicat
ion
,
		/		)
.


Programs.
Eac
h
subsequence
of
primitiv
es
executed
during
system
life
is
called
a
pr
o
gr
am.
Prim-
itiv
es
can
b
e
com
bined
to
form
programs
for
p
erforming
arbitrary
computations.
The
only
limitations
are
those
imp
osed
b
y
the
necessarily
nite
hardw
are.
Self-deli
mi
ti
ng
self-mo
dicati
on
programs.
Occasionally
,
the
system
will
mo
dify
one
of
its
probabilit
y
distributions,
b
y
using
I
ncP
or
D
ecP
.
Occasionally
,
it
will
execute
the
EndSelfMo
d
primitiv
e.
The
rst
probabilit
y
mo
dication
after
an
EndSelfMo
d
action
or
after
system
\birth"
b
egins
a
self-
mo
dication
program.
The
self-mo
dication
program
ends
itself
b
y
executing
the
EndSelfMo
d
action.
Due
to
the
univ
ersalit
y
of
the
underlying
programmi
ng
language,
self-mo
dication
programs
ma
y
result
in
sp
ecic,
arbitrary
mo
dications
of
con
text-dep
enden
t
probabilities
of
future
programs.
Ho
w
ev
er,
due
to
MinP
b
eing
p
ositiv
e,
the
probabilit
y
of
selecting
and
executing
a
particular
instruction
at
a
particular
time
cannot
en
tirely
v
anish.
The
remainder
of
this
section
is
dev
oted
to
basic
concepts
required
to
ensure
that
the
system
k
eeps
only
probabilit
y
mo
dications
computed
b
y
\useful"
self-mo
dication
programs:
essen
tially
those
whic
h
bring
ab
out
more
pa
y
o
p
er
time
than
all
previous
self-mo
dication
programs.
P
a
y
o/time
ratios.
Supp
ose
a
self-mo
dication
program
s
started
execution
at
time
t

and
com-
pleted
itself
at
time
t

.
F
or
t

t

and
t

T
,
the
pa
y
o/time
ratio
Q(s;
t)
is
dened
as
Q(s;
t)
=
R(t)
 R(t

)
t
 t

:
DEFINITION:
useful
self-mo
dicati
on
programs.
The
usefulness
of
a
self-mo
dication
program
is
dened
recursiv
ely:
at
birth,
there
are
no
useful
self-mo
dication
programs.
A
t
some
later
p
oin
t
t
in
system
life,
w
e
consider
t
w
o
cases:
a
self-mo
dication
program
s
that
ended
itself
at
time
t

is
considered
useful
if
()
(a)
there
are
no
previous
self-mo
dication
programs
that
are
considered
useful,
and
(b)
for
all
t
x

t

;
t
x

t:
Q(s;
t
x
)
>
R(t
x
)
t
x
(the
total
pa
y
o/time
ratio
at
time
t
x
).
Or
()
(a)
there
ar
e
previous
self-mo
dication
programs
considered
useful,
and
(b)
for
all
t
x

t

;
t
x

t:
Q(s;
t
x
)
>
Q(s
0
;
t
x
),
where
s
0
is
the
most
recen
t
useful
self-modication
program
preceding
s.
The
computation
of
pa
y
o/time
ratios
alw
a
ys
tak
es
in
to
accoun
t
all
computation
time,
includin
g
time
required
for
learning.
F
A
CT
.
A
t
a
giv
en
time,
to
decide
whether
the
most
recen
t
useful
self-mo
dication
pro-
gram
remains
useful,
one
needs
to
compare
its
curren
t
pa
y
o/time
ratio
only
to
the
curren
t
pa
y
o/time
ratio
of
the
most
recen
t
pr
evious
useful
self-mo
dication
program.
F
A
CT
.
A
completed
self-mo
dication
program
is
considered
useful
as
long
as
a
v
erage
pa
y
o
in
tak
e
since
its
b
eginning
o
ccurred
faster
than
with
al
l
previous
self-mo
dication
programs
still
considered
useful.
Pro
of.
See
denition
of
usefulness
ab
o
v
e.
Keeping
trac
k
of
useful
self-mo
di
catio
ns.
In
order
to
ev
aluate
whether
life
after
the
b
eginning
of
some
self-mo
dication
program
w
as
\b
etter"
or
\w
orse"
than
b
efore,
and
to
b
e
able
to
coun
termand
probabilit
y
mo
dications
computed
b
y
self-mo
dication
programs
that
seem
useless
or
ev
en
harmful,
a
stac
k,
S
,
is
in
tro
duced.
The
k
-th
en
try
of
S
,
k

f0;
;
:
:
:
;
S
tack
S
iz
eg,
is
denoted
S
(k
).
S
(k
)
consists
of
the
follo
wing
v
ariables:
S
(k
):t,
S
(k
):R,
S
(k
):addr
ess,
S
(k
):f
ir
st,
and
S
(k
):ol
dP
(a
v
ector
of
n
ops
v
ariables).
The
v
ariable
sp
p
oin
ts
to
the
curren
t
topmost
stac
k
en
try
.
If
sp
=
0
(the
v
alue
at
system
startup),
the
stac
k
is
empt
y
.
If
the
system
mo
dies
some
probabilit
y
distribution
P
i
at
time


t
(b
y
using
I
ncP
or
D
ecP
),
sp
is
incremen
ted,
and
the
follo
wing
v
alues
are
pushed
on
to
the
stac
k:
the
curren
t
time,
the
total
pa
y
o
so
far,
the
address
of
the
mo
died
program
cell,
its
old
probabilit
y
distribution
righ
t
b
efore
the
curren
t
mo
dication
(represen
ted
b
y
n
ops
real
v
alues),
and
a
p
oin
ter
to
the
stac
k
en
try
corresp
onding
to
the
rst
probabilit
y
mo
dication
computed
b
y
the
curren
t
self-mo
dication
program.
More
formally:
S
(sp):t
 
t;
S
(sp):R
 
R(t);
S
(sp):addr
ess
 
i;
S
(sp):ol
dP
 
P
i
b
efor
e
the
mo
dication
(represen
ted
b
y
n
ops
real
v
alues).
If
t
marks
the
b
eginning
of
a
self-mo
dication
program,
then
S
(sp):f
ir
st
 
sp.
Otherwise
(in
the
middle
of
a
self-mo
dication
program),
S
(sp):f
ir
st
 
S
(sp
 ):f
ir
st.
The
zeroth
stac
k
en
try
,
whic
h
cannot
b
e
p
opp
ed,
is
initialized
as
follo
ws:
S
(0):t
 
0;
S
(0):R
 
0;
S
(0):f
ir
st
 
0.
The
remaining
v
alues
are
undened.
UNMODIFIABLE
TOP-LEVEL
CREDIT
ASSIGNMENT
STRA
TEGY:
inductiv
e
infer-
ence
based
on
single
exp
eriences.
It
is
v
ery
simple.
If
there
is
no
self-mo
dication
program
running,
then
after
eac
h
completed
instruction
cycle,
a
decision
is
made
as
to
whether
probabilit
y
distributions
mo
died
b
y
previous
self-mo
dication
programs
should
b
e
k
ept
or
replaced
b
y
their
old
v
alues
from
the
stac
k.
The
pro
cess
w
orks
as
follo
ws.
After
eac
h
completed
instruction
cycle,
do:
()
If
there
curren
tly
is
an
incomplete
self-mo
dicati
on
program
(not
y
et
ended
b
y
an
EndSelfMo
d
action),
do
nothing.
()
Else
successiv
ely
p
op
and
restore
sa
v
ed
probabilit
y
distribu
ti
ons,
un
til
the
pa
y
o/time
ratio
since
the
b
eginning
of
the
most
recen
t
self-mo
di
cation
pro-
gram
that
computed
mo
dications
of
probabilit
y
distrib
ut
io
ns
curren
tly
sa
v
ed
on
the
stac
k
exceeds
the
pa
y
o/time
ratio
of
the
preceding
suc
h
self-mo
dicati
on
program
(if
there
is
an
y
{
otherwise
compare
with
the
total
pa
y
o/time
ratio).
More
formally
(t
denotes
the
curren
t
time):
While
sp
=
0
and
R(t)
 S
(S
(sp):f
ir
st):R
t
 S
(S
(sp):f
ir
st)
:t

R(t)
 S
(S
(S
(sp):f
i
r
st
 ):f
ir
st):R
t
 S
(S
(S
(s
p):f
ir
st
 ):f
ir
st):t
do:
P
S
(sp):i
 
S
(sp):ol
dP
;
sp
 
sp
 .
F
A
CT

ab
o
v
e
sa
ys
that
at
a
giv
en
time,
the
top-lev
el
strategy
needs
to
consider
only
the
t
w
o
most
recen
t
self-mo
dication
programs
whose
direct
eects
ha
v
e
not
y
et
b
een
coun
termanded,
in
order
to
decide
whether
to
p
op
the
stac
k.
Then
wh
y
do
w
e
need
a
while
lo
op
as
ab
o
v
e?
The
reason
is
that
p
opping
and
restoring
probabilit
y
distributions
tak
es
time
(t
increases
during
execution
of
the
while
lo
op),
p
ossibly
causing
utilit
y
v
alues
to
drop.
Therefore,
in
the
pro
cess
of
p
opping
and
restoring
distributions
mo
died
b
y
one
program,
the
pa
y
o/time
ratio
of
the
preceding
program
ma
y
fall
enough
so
that
the
distributions
it
mo
died
m
ust
b
e
restored,
to
o.
The
pro
cess
can
p
oten
tially
con
tin
ue
un
til
the
stac
k
is
completely
empt
y
.
F
A
CT
.
After
eac
h
instruction
(except
during
the
execution
of
a
self-mo
dication
program),
the
top-lev
el
ensures
that
the
b
eginning
of
eac
h
completed
self-mo
dication
program
that
computed
v
alid
probabilit
y
mo
dications
has
b
een
follo
w
ed
b
y
faster
pa
y
o
in
tak
e
than
the
b
eginnings
of
all
previous
suc
h
self-mo
dication
programs.
A
l
l
curr
ently
valid
pr
ob
ability
mo
dic
ations
wer
e
c
ompute
d
by
curr
ently
useful
self-mo
dic
ation
pr
o
gr
ams.
The
nature
of
the
en
vironmen
t
do
es
not
matter.
Pro
of.
See
formal
top-lev
el
description
and
F
A
CT
.



Twenty
Comments
The
exp
erimen
ts
are
describ
ed
in
section
.
If
y
ou
are
in
a
h
urry
,
y
ou
can
skip
these
(mostly
rather
ob
vious)
commen
ts.
.
Wh
y
self-deli
mi
ti
n
g
self-mo
dicati
on
programs?
The
EndSelfMo
d
primitiv
e
allo
ws
the
sys-
tem
to
dela
y
top-lev
el
ev
aluations
of
probabilit
y
mo
dications
arbitrarily
.
The
exp
ectation
of
the
dela
y
remains
nite,
ho
w
ev
er,
due
to
M
inP
b
eing
p
ositiv
e.
The
system's
dela
ying
capabilities
are
imp
ortan
t,
for
t
w
o
reasons:
()
In
general,
pa
y
o
ev
en
ts
will
b
e
separated
b
y
long
(unkno
wn)
time
lags.
Hence,
no
v
el
probabilit
y
mo
dications
are
not
necessarily
bad
if
they
do
not
lead
to
imm
ediate
pa
y
o.
The
system
itself
should
b
e
able
to
learn
ho
w
m
uc
h
time
to
sp
end
on
w
aiting
for
rst
pa
y
o
ev
en
ts.
()
Tw
o
successiv
e
mo
dications
of
t
w
o
particular
probabilit
y
distributions
ma
y
turn
out
to
b
e
b
enecial,
while
eac
h
b
y
itself
ma
y
b
e
harmful.
Therefore,
the
system
should
b
e
able
to
compute
arbitrary
sequences
of
probabilit
y
mo
dications,
b
efore
facing
top-lev
el
ev
aluations.
Dela
ying
top-lev
el
ev
aluations
do
es
cost
time,
though,
whic
h
is
tak
en
in
to
accoun
t
when
usefulness
is
measured.
In
the
long
run,
the
system
is
encouraged
to
create
useful
self-mo
dication
programs
of
the
appropriate
size.
.
Non-decreasing
searc
h
space.
Due
to
MinP
b
eing
p
ositiv
e,
there
will
alw
a
ys
b
e
a
non-v
anishing
(p
ossibly
tin
y)
probabilit
y
of
executing
any
program
at
any
time.
Th
us,
the
space
of
p
ossible
action
subsequences
will
nev
er
really
decrease.
Only
the
probabilit
y
distribution
on
this
space
(the
bias)
can
c
hange.
But
there
cannot
b
e
total
determinism
corresp
onding
to
total
lac
k
of
exploration.
.
Sp
eeding
up
pa
y
o
in
tak
e
/
Learning
ho
w
to
learn.
The
top-lev
el
tak
es
the
en
tire
learning
history
in
to
accoun
t:
note
that
at
time
t,
the
v
alue
t
 S
(S
(sp):f
i
r
st):t
stands
for
al
l
the
time
since
the
b
eginning
of
the
most
recen
t
self-mo
dication
program
whose
eects
ha
v
e
not
y
et
b
een
coun
termanded.
The
utilit
y
v
alue
of
a
self-mo
dication
program
is
based
on
total
elapsed
time
since
the
program
b
egan.
This
includes
the
computation
time
required
for
learning.
Ov
er
time,
the
system
tends
to
mak
e
b
etter
and
b
etter
use
of
its
limited
temp
oral
and
spatial
resources:
due
to
F
A
CT
,
self-mo
dications
that
sp
eed
up
pa
y
o
in
tak
e
in
the
long
run
are
preferred.
So
are
self-mo
dications
sp
eeding
up
the
searc
h
for
self-mo
dications
sp
eeding
up
pa
y
o
in
tak
e.
This
encourages
\learning
ho
w
to
learn",
and
\learning
ho
w
to
learn
ho
w
to
learn"...,
and
represen
ts
an
essen
tial
dierence
to
previous
approac
hes
to
con
tin
ual
learning,
see
(Ring,
		).
.
Directed
m
utation
s
as
opp
osed
to
random
m
utations.
Unlik
e
ev
olutionary
and
genetic
algorithms
(Rec
hen
b
erg,
	;
Sc
h
w
efel,
	;
Holland,
	;
Homeister
and
B
ac
k,
		;
Koza,
		),
self-mo
dication
programs
ma
y
lead
to
v
ery
sp
ecic,
dir
e
cte
d
sequences
of
strategy
m
uta-
tions,
as
opp
osed
to
undir
e
cte
d,
totally
random
m
utations.
The
system
can
arbitrarily
mo
dify
its
prior
distribution
on
the
space
of
solution
candidates.
Just
as
ev
olution
\disco
v
ered"
that
ha
ving
the
\genetic
crosso
v
er
op
erator"
w
as
a
\go
o
d
thing",
the
system
is
p
oten
tially
able
to
disco
v
er
that
v
arious
more
directed
searc
h
strategies
are
\go
o
d
things".
.
Life
is
one-w
a
y
.
Note
that
only
dir
e
ct
eects
of
self-mo
dication
programs
on
primitiv
e
proba-
bilit
y
distributions
can
b
e
coun
termanded
b
y
the
top-lev
el
strategy
.
In
realistic
en
vironmen
ts,
it
is
not
p
ossible
to
coun
termand
all
indir
e
ct
eects
and
eects
of
the
system
b
eha
vior
on
the
un-
kno
wn
en
vironmen
t
|
life
is
one-w
a
y
.
Ho
w
ev
er,
the
top
lev
el
ma
y
encourage
the
dev
elopmen
t
of
en
vironmen
t-sp
ecic
strategies
for
coun
termanding
certain
indirect
eects.
Suc
h
strategies
will
b
e
k
ept
as
long
as
they
app
ear
to
b
e
more
useful
than
previous
strategies.
By
fo
cusing
on
the
obser-
v
ation
and
con
trol
of
c
hanges
of
probabilit
y
distributions
(as
opp
osed
to
general
c
hanges
in
v
olving
in
ternal
state
and
en
vironmen
t),
the
top
lev
el
attempts
to
con
trol
a
complex
w
orld
b
y
con
trolling
a
small
part
of
it,
namely
,
the
v
ariable
probabilit
y
distributions.
The
latter,
ho
w
ev
er,
ma
y
ha
v
e
an
arbitrary
inuence
on
themselv
es
and
the
rest
of
the
w
orld.
	

.
\Usefulness"
and
\true
usefulness".
Incremen
tal
self-impro
v
em
en
t
k
eeps
useful
self-modi-
cations
only
in
the
sense
that
\useful"
w
as
dened
ab
o
v
e.
Ho
w
ev
er,
the
system
will
nev
er
ha
v
e
a
pro
of
that
a
particular
self-mo
dication
program
w
as
the
\true"
reason
for
more
pa
y
o.
In
fact,
what
the
system
actually
do
es
is
inductiv
e
inference
based
on
single
exp
eriences:
at
one
p
oin
t
in
its
life
it
did
something,
and
at
some
later
p
oin
t
it
measures
apparen
t
o
v
erall
eects
on
its
p
erformance.
What
app
eared
to
b
e
\useful"
up
un
til
no
w
is
assumed
to
remain
\useful"
in
the
future,
though
it
ma
y
ha
v
e
b
een
just
a
uk
e
that
migh
t
later
turn
out
actually
to
ha
v
e
harmful
consequences:
\shifts
of
inductiv
e
bias"
generated
b
y
the
system
itself
ma
y
b
e
ev
aluated
as
harmful
in
the
ey
es
of
a
\go
d-lik
e"
external
observ
er
with
additional
prior
kno
wledge.
But
without
access
to
complete
kno
wledge
of
the
en
vironmen
t,
the
system
is
forced
to
rely
up
on
its
previous
exp
erience
to
decide
what's
harmful
and
what's
not.
This
is
what
inductiv
e
inference
is
all
ab
out

.
.
What
ab
out
self-mo
di
catio
ns
\useful
just
b
y
c
hance"?
This
question
is
related
to
the
last
commen
t.
F
or
the
sak
e
of
the
argumen
t,
supp
ose
a
self-mo
dication
program
is
considered
useful
b
y
the
system,
but
not
b
y
a
go
d-lik
e
external
observ
er.
This
do
es
not
at
all
imply
a
fatal
catastroph
y:
t
ypically
,
the
reason
for
the
apparen
t
usefulness
of
the
actually
useless
(or
ev
en
harmful)
self-mo
dication
program
will
b
e
that
its
long-term
eects
w
ere
o
v
ercomp
ensated
(b
efore
the
corresp
onding
probabilit
y
mo
dications
w
ere
cancelled)
b
y
later,
\truly"
useful
self-
mo
dication
programs.
And
note
that
the
system
will
alw
a
ys
ha
v
e
a
c
hance
to
undo
previous
probabilit
y
mo
dications,
b
y
executing
appropriate
additional
self-mo
dications.
.
Univ
ersali
t
y
/
Learning
to
remem
b
er.
It
is
not
dicult
to
sho
w
that
the
primitiv
es
in
T
able

form
a
univ
ersal
set
in
the
follo
wing
sense:
they
can
b
e
comp
osed
to
form
programs
writing
an
y
computable
in
teger
sequence
on
to
the
w
ork
area,
within
the
hardwired
size
and
range
limitati
ons.
Note
that
the
primitiv
es
mak
e
it
easy
to
create
action
sequences
for
handling
stac
ks,
recursion,
etc.
The
sc
heme
allo
ws
for
v
ery
general
sequen
tial
in
teraction
with
the
en
vironmen
t
(giv
en
appropriate
problem-sp
ecic
actions
that
translate
storage
con
ten
ts
in
to
output
actions
and
en
vironmen
tal
c
hanges).
The
self-referen
tial
primitiv
es
are
designed
to
allo
w
for
sp
ecic
c
hanges
of
probabilit
y
distributions
of
all
program
cells
(p
ossibly
done
v
ery
quic
kly
,
making
things
lik
e
\one-shot
learning"
p
ossible).
Univ
ersalit
y
implies
that
the
system
is
in
principle
capable
of
creating
programs
for
storing
repre-
sen
tations
of
en
vironmen
tal
ev
en
ts.
Unlik
e
with
most
previous
reinforcemen
t-learning
algorithms,
see
e.g.
(Barto,
		;
W
atkins,
		;
Da
y
an
and
Sejno
wski,
		;
Williams,
		;
Sutton,
		),
there
is
no
need
for
a
Markovian
interfac
e
(Sc
hmidh
ub
er,
		)
b
et
w
een
the
en
vironmen
t
and
the
learning
system.
Also,
there
is
no
need
for
a
\discoun
t
factor"
discoun
ting
the
system's
exp
ectation
of
future
pa
y
o
in
case
of
p
oten
tially
innite
life
spans.
	.
Do
esn't
the
system
start
with
a
h
uge
disadv
an
tage?
Con
v
en
tional
learning
systems
ha
v
e
a
xed
learning
strategy
for
selecting
and
testing
solution
candidates
from
some
\non-univ
ersal"
searc
h
space.
Incremen
tal
self-impro
v
emen
t,
ho
w
ev
er,
do
es
not
only
searc
h
for
solutions
to
some
sp
ecic
task,
but
also
for
learning
strategies
for
nding
solutions.
Do
esn't
the
system's
univ
ersalit
y
increase
its
searc
h
space?
In
general,
it
do
es.
With
man
y
to
y
tasks,
an
external
user
will
b
e
able
to
pro
vide
a
con
v
en
tional
learning
algorithm
with
enough
problem-sp
ecic
bias
to
solv
e
a
certain
task
more
quic
kly
than
(initially
less
informed)
searc
h
based
on
incremen
tal
self-impro
v
emen
t.
On
the
other
hand,
ho
w
ev
er,
unlik
e
previous
learning
metho
ds,
incremen
tal
self-impro
v
emen
t
can
use
exp
erience
to
mo
dify
its
searc
h
in
a
univ
ersal
w
a
y
,
b
y
exploiting
arbitrary
task-sp
ecic
regularities
if
there
are
an
y
,
and
b
y
creating
its
o
wn
problem-sp
ecic
bias.
In
the
long
run,
this
adv
an
tage
ma
y
out
w
eigh
initial
disadv
an
tages
due
to
univ
ersalit
y
.

P
erhaps,
tomorro
w
y
ou
will
b
e
punished
for
scratc
hing
y
our
ear
0
y
ears
ago
|
ma
yb
e
this
is
in
the
nature
of
the
algorithm
running
the
univ
erse.
There
is
no
pro
of
that
this
is
not
going
to
happ
en
(though
our
en
vironmen
t
app
ears
to
b
e
somewhat
more
b
enign
than
this).
In
general,
y
ou
w
ould
not
ha
v
e
a
c
hance
to
disco
v
er
the
\true"
reason
for
the
punishmen
t.
0

0.
Inserting
prior
bias
/
Eciency
consideration
s.
Primitiv
e
instructions
need
not
b
e
lo
w-lev
el
instructions
lik
e
those
in
T
able
.
They
ma
y
corresp
ond
to
complex
submo
dules
reecting
the
user's
prior
kno
wledge.
Informally
,
there
is
one
general
constrain
t
to
ob
ey
(Sc
hmidh
ub
er,
		):
whatev
er
is
computable
on
the
used
hardw
are,
should
b
e
computable
just
as
eciently
(up
to
a
small
constan
t
factor)
b
y
a
program
written
in
the
programmi
ng
language.
F
or
instance,
on
a
t
ypical
serial
digital
mac
hine
w
e
w
ould
lik
e
to
ha
v
e
instructions
exploiting
fast
storage
addressing
mec
hanisms.
W
e
w
ould
not
w
an
t
to
limit
ourselv
es
to
the
sim
ulation
of,
sa
y
,
a
slo
w
one
tap
e
T
uring
mac
hine.
Lik
ewise,
on
a
mac
hine
with
man
y
parallel
pro
cessors
w
e
w
ould
lik
e
to
use
a
set
of
instructions
allo
wing
for
pro
cesses
with
maxim
al
parallelism.
.
Bias
to
w
ards
short
runs.
Unlik
e
Levin's
univ
ersal
searc
h
algorithm
(whic
h
is
optimal
for
a
wide
v
ariet
y
of
non-incremen
tal
searc
h
problems
based
on
trials
with
exactly
rep
eatable
initial
conditions;
see
Levin,
	),
the
system
presen
ted
here
has
no
explicit
bias
to
w
ards
runs
with
lo
w
Kolmogoro
v
complexit
y
or
lo
w
Levin
complexit
y
(Kolmogoro
v,
	;
Chaitin,
		;
Solomono,
	;
Levin,
	)
|
e.g.
runs
based
on
only
few
instructions
rep
eated
o
v
er
and
o
v
er
again.
In
principle,
ho
w
ev
er,
it
ma
y
create/strengthen
suc
h
a
bias,
and
the
bias
will
stic
k
if
it
app
ears
to
b
e
useful.
Of
course,
a
priori
bias
of
this
kind
can
b
e
explicitly
in
tro
duced
b
y
the
programmer.
One
p
ossibilit
y
is
to
rew
ard
lo
w-complexit
y
runs
more
than
others
(b
y
pro
viding
more
external
pa
y
o
).
Another
p
ossibilit
y
is
this:
instead
of
selecting
primitiv
es
randomly
(according
to
the
curren
t
probabilit
y
distributions)
at
eac
h
time
step
of
eac
h
run,
mak
e
random
selections
only
if
IP
p
oin
ts
to
a
program
cell
that
has
not
y
et
b
een
used
during
the
curren
t
run.
Otherwise
use
the
instruction
executed
during
the
most
recen
t
visit
of
the
program
cell.
This
leads
to
an
explicit
bias
to
w
ards
lo
w
algorithmic
probabilit
y
(Solomono,
	),
and
has
b
een
done
previously
in
(Sc
hmidh
ub
er,
		).
Occasionally
,
this
will
lead
to
non-halting
programs.
F
or
suc
h
cases,
upp
er
run
time
b
ounds
need
to
b
e
in
tro
duced.
In
the
spirit
of
the
incremen
tal
self-impro
v
emen
t
paradigm,
suc
h
time
b
ounds
should
b
e
computed
b
y
the
system
itself
(using
appropriate
sp
ecial
primitiv
es).
F
or
an
additional
commen
t
on
inserting
prior
bias,
see
section
..
.
Exploration/expl
oi
t
atio
n
tradeo.
The
system
itself
can
decide
ho
w
m
uc
h
time
it
w
an
ts
to
sp
end
on
exploring
eects
of
new
action
sequences,
and
ho
w
m
uc
h
time
it
w
an
ts
to
sp
end
on
exploiting
b
enecial
eects
of
action
sequences
that
it
tried
b
efore.
In
the
long
run,
the
system
will
prefer
those
strategies
that
led
to
the
b
est
(en
vironmen
t-sp
ecic)
balance
b
et
w
een
exploration
and
exploitation.
.
One
task,
man
y
tasks.
An
external
user
ma
y
c
ho
ose
a
w
a
y
of
translating
tasks
and
system
p
erformance
in
to
pa
y
o.
F
rom
the
user's
p
oin
t
of
view,
there
ma
y
b
e
man
y
tasks,
and
the
system
itself
ma
y
c
ho
ose
whic
h
to
attac
k
rst.
F
rom
the
system's
p
oin
t
of
view,
there
is
only
one
task,
namely
,
to
maxim
ize
cum
ulativ
e
pa
y
o.
Note
that
ev
ery
task
that
requires
the
maxim
izatio
n
of
some
kind
of
rew
ard
ma
y
b
e
view
ed
as
b
eing
decomp
osable
in
to
man
y
tasks:
the
rst
task
is
to
generate
actions
leading
to
a
little
bit
of
rew
ard.
The
next
task
is
to
generate
actions
leading
to
more
rew
ard,
etc.
.
What
if
\the
task
c
hanges?"
In
the
ligh
t
of
what
has
b
een
said
ab
o
v
e,
this
is
actually
a
misleading
question.
It
is
tinged
b
y
the
idea
of
\exactly
rep
eatable
training
ev
en
ts"
suddenly
b
eing
replaced
b
y
dieren
t
\exactly
rep
eatable
training
ev
en
ts".
But,
in
this
pap
er
there
is
no
unrealistic
a
priori
assumption
of
exactly
rep
eatable
training
ev
en
ts.
F
rom
the
system's
p
oin
t
of
view,
there
is
only
one
task,
namely
,
to
maximi
ze
cum
ulativ
e
pa
y
o
(see
previous
commen
t).
The
system
alw
a
ys
tends
to
k
eep
the
strategy
that
led
to
the
b
est
o
v
erall
results
so
far.
Without
additional
prior
kno
wledge,
there
are
no
alternativ
es:
the
system
cannot
kno
w
whether
pa
y
o
c
hanges
are
due
to
external
\task
c
hanges",
or
whether
they
are
due
to
long
term
eects
of
its
o
wn
previous
actions
(as
discussed
in
commen
ts

and

ab
o
v
e).
Life
is
one-w
a
y
,
and
c
hange
is
in
the
nature
of
a
dynamic
en
vironmen
t.
F
or
the
sak
e
of
the
argumen
t,
ho
w
ev
er,
supp
ose
a


particular
sequence
of
probabilit
y
mo
dications
app
ears
justied
at
a
certain
p
oin
t
t

,
and
the
external
observ
er
decides
that
the
\rst
task
is
solv
ed".
A
t
time
t

>
t

,
ho
w
ev
er,
the
system
fails
to
k
eep
its
old
pa
y
o/time
ratio
b
ecause
the
\task
has
c
hanged"
in
the
ey
es
of
the
external
observ
er.
Then,
o
v
er
time,
direct
eects
of
previously
\useful"
self-mo
dication
programs
will
tend
to
b
e
coun
termanded
in
in
v
erse
order
of
their
o
ccurrence
(unless
they
don't
get
protected
b
y
additional
useful
self-mo
dication
programs),
un
til
the
curren
t
probabilit
y
distributions
reect
kno
wledge
useful
for
solving
b
oth
tasks.
A
l
l
probabilit
y
mo
dications
will
b
e
coun
termanded
only
if
the
initial
strategies
dev
elop
ed
for
solving
the
rst
task
are
useless
for
solving
the
second
task.
But
without
additional
prior
kno
wledge,
this
do
es
mak
e
sense
from
the
learning
system's
p
oin
t
of
view.
.
T
eac
her
as
part
of
the
en
vironmen
t
.
()
Of
course,
an
external
teac
her
ma
y
pro
vide
task-
sp
ecic
inputs
con
v
eying
information
ab
out
task
c
hanges.
But
the
system
has
rst
to
learn
to
mak
e
use
of
these
inputs.
Analoguously
,
c
hildren
rst
ha
v
e
to
learn
to
in
terprete
sound
w
a
v
es
emitted
b
y
their
paren
ts
as
teac
her
signals.
They
will
learn
this
if
it
turns
out
to
b
e
useful
in
the
long
run.
()
T
o
ac
hiev
e
his
teac
hing
goals,
the
teac
her
ma
y
directly
inuence
the
w
a
y
pa
y
o
is
generated,
th
us
inuencing
the
con
text
sensitivit
y
of
the
rew
ard.
In
b
oth
cases,
it
is
natural
to
view
the
teac
her
as
part
of
the
en
vironmen
t.
.
Direct
teac
her
forcing.
The
teac
her
ma
y
decide
that
the
curren
t
strategy
of
the
system
(at
time
t

)
is
actually
a
v
aluable
one
and
should
not
b
e
coun
termanded.
Instead
of
inuencing
pa
y
o
generation
(see
previous
commen
t),
he
ma
y
decide
to
inuence
the
learning
pro
cess
directly
,
b
y
prev
en
ting
the
top-lev
el
strategy
from
coun
termanding
probabilit
y
mo
dications
generated
b
y
self-
mo
dication
programs
considered
useful
at
time
t

.
This
w
ould
b
e
one
w
a
y
to
insert
additional
prior
kno
wledge.
.
Success
history
in
stac
k.
A
t
a
giv
en
time,
the
curren
t
history
of
useful
self-mo
dications
is
reected
b
y
the
curren
t
stac
k
en
tries.
Eac
h
self-mo
dication
program
\on
the
stac
k"
w
as
follo
w
ed
b
y
faster
pa
y
o
in
tak
e
than
all
previous
self-mo
dication
programs
\on
the
stac
k".
This
is
true
despite
the
fact
that
time
for
computing
and
testing
later
self-mo
dication
programs
is
tak
en
in
to
accoun
t.
.
Useful
self-mo
dicati
on
programs
are
rare.
Eac
h
self-mo
dication
program
undergo
es
a
test
whic
h
ma
y
last
for
the
en
tire
remaining
system
life,
pro
vided
the
program
is
considered
useful
for
suc
h
a
long
time.
T
ypically
,
only
few
self-mo
dication
programs
will
b
e
follo
w
ed
b
y
faster
pa
y
o
in
tak
e
than
al
l
previous
useful
self-mo
dication
programs.
Therefore,
the
costs
of
sa
ving
\old"
probabilit
y
distributions
in
the
stac
k
t
ypically
will
tend
to
remain
comparativ
ely
small.
This
is
b
orne
out
b
y
the
exp
erimen
ts
in
section
.
	.
Limited
stac
ksize
|
\circular"
stac
k.
In
practical
applications,
the
stac
k
will
b
e
nite.
A
circular
stac
k
that
o
v
erwrites
earlier
stac
k
en
tries
(starting
from
the
b
ottom
en
tries)
could
k
eep
trac
k
of
self-mo
dications
after
stac
k
o
v
ero
w
(circular
stac
k).
Only
the
StackSize
most
recen
t
probabilit
y
mo
dications
could
then
b
e
directly
restored
b
y
p
opping.
Ho
w
ev
er,
ev
ery
probabilit
y
distribution
can
b
e
indirectly
restored
b
y
additional
self-mo
dication
programs
executed
b
y
the
system
itself.
In
the
exp
erimen
ts
conducted
so
far,
there
nev
er
w
as
a
danger
of
stac
k
o
v
ero
w.
See
section
.
It
is
in
tended
to
in
tro
duce
additional
in
trosp
ectiv
e
primitiv
es
for
addressing
and
examining
stac
k
en
tries
(in
the
st
yle
of
GetP
).
This
is
not
y
et
implemen
ted,
ho
w
ev
er.
0.
When
to
apply
incremen
tal
self-impr
o
v
em
en
t?
It
is
alw
a
ys
p
ossible
to
construct
\cruel"
en
vironmen
ts,
where
previous
exp
eriences
are
necessarily
useless
for
future
planning.
Indeed,
as
can
b
e
seen
from
what
has
b
een
said
in
the
in
tro
duction,
almost
all
think
able
en
vironmen
ts
are
of
this
kind
(except
those
whic
h
w
e
generally
are
most
in
terested
in:
those
with
regularities).
The
incremen
tal
self-impro
v
emen
t
paradigm
w
on't
b
e
of
an
y
help
in
the
general
case.
The
same


Primitiv
e
Seman
tics
W
rite(a,
a)
C
c
a
 
c
c
a
Read(a,
a)
c
c
a
 
C
c
a
T
able
:
Semantics
of
pr
oblem
sp
e
cic
primitives
and
their
p
ar
ameters.
A
gain,
double-indexe
d
indir
e
ct
addr
essing
is
employe
d.
Se
e
text
for
rules
for
syntactic
c
orr
e
ctness.
Comp
ar
e
with
T
able
.
holds
for
any
other
le
arning
p
ar
adigm,
though.
Ho
w
ev
er,
if
certain
asp
ects
of
the
en
vironmen
t
\rep
eat
themselv
es",
if
exp
erimen
ts
conducted
in
the
en
vironmen
t
do
not
c
hange
it
suc
h
that
previous
kno
wledge
b
ecomes
totally
useless,
if
the
tasks
to
b
e
solv
ed
do
exhibit
\regularities",
then
the
incremen
tal
self-impro
v
em
en
t
paradigm
app
ears
to
b
e
a
v
ery
general
w
a
y
of
exploiting
this.
Incremen
tal
self-impro
v
emen
t
should
b
e
of
in
terest
in
cases
where
the
user's
bias
is
already
captured
b
y
the
c
hoice
of
the
initial
programmi
ng
language,
and
where
the
user
exp
ects
additional
(y
et
unkno
wn)
problem-sp
ecic
regularities.

Illustra
tive
Experiments
The
follo
wing
brief
case
studies
are
not
designed
to
impress
but
to
illustrate
basic
asp
ects
of
the
system.
The
rst
task
requires
to
compute
regular
in
teger
strings.
The
second
task
is
a
maze
task
from
(Sutton,
		).
With
b
oth
tasks,
the
system
uses
lo
w-lev
el
problem-sp
ecic
primitiv
es
in
addition
to
the
general
primitiv
es
from
T
able
.
The
primitiv
es
reect
the
system's
initial
(w
eak)
bias.
Of
course,
dieren
t
problem-sp
ecic
primitiv
es
lead
to
dieren
t
initial
bias
and
p
erformance.
A
task
that
can
b
e
solv
ed
within
a
few
min
utes
using
one
set
of
primitiv
es
ma
y
require
a
da
y
of
computation
time
using
a
dieren
t
set
of
primitiv
es.
The
purp
ose
of
this
section,
ho
w
ev
er,
is
not
to
p
erform
a
statistically
signican
t
exp
erimen
tal
ev
aluation
of
the
system's
initial
bias,
or
to
study
eects
of
in
tro
ducing
dieren
t
kinds
of
initial
bias,
or
to
compare
the
system
to
other
learning
systems
with
dieren
t
initial
bias.
Instead,
this
section's
purp
ose
is
to
describ
e
t
ypical
asp
ects
of
system
liv
es
illustrating
the
system's
basic
(bias
indep
enden
t)
mo
de
of
op
eration.
.
Writing
V
ariable
Sequences
T
ask.
The
external
en
vironmen
t
consists
of
an
arra
y
of
0
v
ariables
V
0
;
V

;
:
:
:
;
V
	
.
The
i-th
v
ariable
is
denoted
b
y
V
i
.
Its
curren
t
con
ten
ts
are
denoted
b
y
C
i

[ M
axint;
M
axint].
Time
is
measured
in
discrete
time
steps.
A
t
time
step
0,
all
v
ariables
are
initialized
with
zeros.
Ev
ery
000
time
steps,
the
n
um
b
er
of
v
ariables
whose
v
alues
equal
their
addresses
is
written
in
to
a
sp
ecial
input
cell.
This
n
um
b
er
is
the
curren
t
pa
y
o.
Then,
all
v
ariables
are
re-initialized
with
zeros.
The
goal
is
to
maximi
ze
cum
ulativ
e
pa
y
o.
Details.
In
addition
to
the

general
primitiv
es
from
T
able

(not
coun
ting
input/output
primi-
tiv
es),
there
are
t
w
o
problem-sp
ecic
primitiv
es.
Eac
h
has
t
w
o
in
teger
argumen
ts:
W
r
ite(a;
a)
writes
the
con
ten
ts
of
the
storage
cell
indirectly
addressed
b
y
the
rst
argumen
t
in
to
the
v
ariable
indirectly
addressed
b
y
the
second
argumen
t.
Read(a;
a)
writes
the
con
ten
ts
of
the
v
ariable
indirectly
addressed
b
y
the
second
argumen
t
in
to
the
w
ork
cell
indirectly
addressed
b
y
the
second
argumen
t.
See
T
able
.
W
rite
and
read
op
erations
outside
the
v
alid
ranges
halt
the
curren
t
run.
Since
n
ops
=

+

=
	,
all
initial
probabilities
of
all
p
ossible
con
ten
ts
of
all
program
cells
are
equal
to

	
.
P
arameters
for
storage
size
etc.
are:
M
in
=
 000,
M
ax
=
00,
P
r
og
r
amS
tar
t
=
bottom(
n
ops

),
M
inP
=
0:00,
S
tack
S
iz
e
=
0;
000,
M
axint
=
0;
000.
T
o
inform
the
system
ab
out
what
is
going
on,
the
follo
wing
v
alues
are
written
in
to
sp
ecial
input
cells
whenev
er
they
c
hange:
IP,
sp,
and
the
remainder
of
t=
M
axint
(in
teger
division,
where
t
denotes
the
curren
t
time).


Measuring
time.
By
denition,
eac
h
computation
that
requires
the
consideration
of
all
n
ops
proba-
bilities
of
some
program
cell
(suc
h
as
selecting
an
instruction,
selecting
a
parameter,
pushing
or
p
opping
probabilit
y
distributions
during
top-lev
el
managemen
t,
etc.)
costs
one
time
step.
Other
computations
do
not
cost
an
ything.
This
ensures
that
measured
time
is
of
the
order
of
total
cpu-time.
The
somewhat
unelegan
t
w
a
y
of
measuring
time
w
as
in
tro
duced
b
ecause
measuring
cpu-time
dir
e
ctly
turned
out
to
b
e
somewhat
unreliable.
Ho
w
dicult
is
this
task?
F
or
a
n
um
b
er
of
reasons,
the
task
is
non-trivial
|
the
system
do
es
not
app
ear
to
ha
v
e
m
uc
h
built-in
bias
to
w
ards
the
task:
()
Only
one
of
the
	
primitiv
es
(W
r
ite)
ma
y
aect
v
ariable
con
ten
ts
at
all.
But
initially
,
the
system
do
es
not
ev
en
ha
v
e
suc
h
seemingly
trivial
kno
wledge
|
there
is
no
built-in
idea
ab
out
whic
h
actions
ma
y
lead
to
pa
y
o.
Therefore,
it
has
to
nd
out
on
its
o
wn.
()
The
v
alues
referred
to
b
y
the
t
w
o
argumen
ts
of
W
r
ite
ha
v
e
to
b
e
iden
tical
and
within
the
required
ranges
to
lead
to
a
useful
result.
()
There
are
0
dier
ent
v
ariables
with
0
dieren
t
v
alues.
Only
one
of
them,
namely
V
0
,
is
correctly
re-initialized
with
its
o
wn
address
after
eac
h
pa
y
o
ev
en
t.
()
There
is
no
explicit
a
priori
bias
to
w
ards
short
programs,
suc
h
as
the
one
in
(Sc
hmidh
ub
er,
		)
for
a
related
task.
()
Finally
,
recall
that
the
w
ork
area
is
nev
er
re-initialized
after
system
birth.
Hence,
as
men
tioned
ab
o
v
e,
it
ma
y
b
e
view
ed
as
part
of
the
en
vironmen
t
of
the
program
area.
The
en
vironmen
t
is
c
hanging
quite
unpredictably
,
due
to
actions
executed
b
y
the
system
itself.
P
erformance
w
as
measured
with
and
without
self-mo
dication
capabilities.
In
the
latter
case,
the
primitiv
es
I
ncP
and
D
ecP
had
no
eect.
Both
v
ersions
w
ere
run
for
0
	
time
steps,
corresp
onding
to
0

pa
y
o
ev
en
ts,
or
ab
out
half
a
da
y
of
computation
time
on
a
SUN
SP
AR
C
0.
Note
that
the
optimal
cum
ulativ
e
pa
y
o
is
:0

0

.
This
v
alue
can
b
e
ac
hiev
ed
only
b
y
a
system
with
\optimal"
prior
bias
|
starting
at
birth,
suc
h
a
system
k
eeps
executing
optimal
actions
without
ha
ving
to
learn
an
ything.
..
Resul
ts
Without
Self-Modifica
tions.
A
t
system
death,
total
pa
y
o
equaled
ab
out
:

0

.
Av
erage
pa
y
o
p
er
pa
y
o
ev
en
t
w
as
ab
out
..
Most
of
the
total
pa
y
o
(ab
out
:0

0

)
could
b
e
attributed
to
the
fact
that
V
0
w
as
correctly
re-initialized
after
eac
h
pa
y
o
ev
en
t:
the
system
receiv
ed
a
little
bit
of
pa
y
o
ev
en
in
cases
where
it
did
not
execute
an
y
w
r
ite
op
erations.
As
exp
ected,
a
v
erage
pa
y
o
in
tak
e
did
not
signican
tly
increase
or
decrease
during
the
lifetime
of
the
system.
Ho
w
ev
er,
this
w
as
not
safely
predictable
in
adv
ance,
due
to
the
c
hanging
en
vironmen
t.
..
Resul
ts
With
Self-Modifica
tions.
A
t
system
death,
total
pa
y
o
w
as
ab
out
:

0

.
T
o
nd
out
whether
the
incremen
tal
self-impro
v
em
en
t
paradigm
did
indeed
lead
to
incremen
tal
self-impro
v
emen
t,
let
us
ha
v
e
a
lo
ok
at
the
learning
history
.
Self-generated
reduction
of
n
um
b
ers
of
probabili
t
y
mo
dications.
In
the
b
eginning,
the
system
computed
a
lot
of
probabilit
y
mo
dications
but
so
on
preferred
to
decrease
the
n
um
b
er
of
prob-
abilit
y
mo
dications
p
er
time
in
terv
al.
There
w
ere
,	
probabilit
y
mo
dications
during
the
rst
0

time
steps.
There
w
ere
	,0
probabilit
y
mo
dications
during
the
second
0

time
steps.
Almost
all
probabilit
y
c
hanges
w
ere
coun
termanded
b
y
the
top-lev
el
strategy;
b
y
this
time,
the
stac
k
had
only
	
en
tries
corresp
onding
to

useful
self-mo
dication
programs.
Most
of
the
useful
self-mo
dication
programs
computed
either
one
or
t
w
o
probabilit
y
mo
dications.
After
0

time
steps,
there
w
ere
only
ab
out
,000
probabilit
y
mo
dications
p
er
0

time
steps.
Sp
eed-up
of
pa
y
o
in
tak
e.
By
then,
the
system
b
eha
v
ed
m
uc
h
more
deterministically
.
Av
erage
pa
y
o
p
er
pa
y
o
ev
en
t
had
increased
from
.
to
0.
(the
optimal
v
alue
b
eing
0.0,
of
course),
and
the
stac
k
had

en
tries.
These
en
tries
corresp
onded
to

mo
dications
of
single
cell
probabilit
y
distributions,
computed
b
y
0
self-mo
dication
programs
|
eac
h
b
eing
more
\useful"
than
all
the
previous
ones.
Storage
already
lo
ok
ed
v
ery
messy.
F
or
instance,
almost
all
cells
in
the
w
ork
area
w
ere
lled
with
(partly
big)
in
tegers
quite
dieren
t
from
the
initial
v
alues.
Recall
that
the
w
ork
area
is
nev
er
re-initialized
and
ma
y
b
e
view
ed
as
part
of
the
en
vironmen
t
of
the
program
area.
First
maximal
pa
y
o.
After
,	
pa
y
o
ev
en
ts,
the
system
correctly
had
written
al
l
0
v
ariables
for
the
rst
time,
and
receiv
ed
maxima
l
pa
y
o
0.0.
Due
to
remaining
non-determinism
in
the
system,


the
curren
t
aver
age
pa
y
o
p
er
pa
y
o
ev
en
t
(measured
shortly
afterw
ards,
at
time
step
00,000,000)
w
as
ab
out
..
After
00,000
pa
y
o
ev
en
ts,
curren
t
a
v
erage
pa
y
o
p
er
pa
y
o
ev
en
t
w
as
	..
By
no
w,
the
n
um
b
er
of
probabilit
y
mo
dications
p
er
0

time
steps
w
as
up
to
00
again.
But
the
stac
k
had
only

en
tries
(corresp
onding
to
	0
\useful"
self-mo
dication
programs).
After
00,000
pa
y
o
ev
en
ts,
curren
t
a
v
erage
pa
y
o
p
er
pa
y
o
ev
en
t
w
as
0.
(
stac
k
en
tries).
After
,000,000
pa
y
o
ev
en
ts
(at
\system
death"),
it
w
as
ab
out
.,
with
tendency
to
increase.
By
then,
there
w
ere

stac
k
en
tries.
They
corresp
onded
to

self-mo
dication
programs,
eac
h
b
eing
more
\useful"
than
all
the
previous
ones.
T
emp
orary
sp
eed-ups
of
p
erformance
impro
v
emen
t.
P
erformance
did
not
increase
smo
othly
during
the
lifetime
of
the
system.
F
or
instance,
at
time
step
0	,	,000,
the
system
correctly
had
written
more
than
0
v
ariables
for
the
rst
time
(namely
).
This
record
w
as
not
brok
en
for
a
long
time
|
for
nearly
0

additional
time
steps.
This
time
in
terv
al
is
comparable
to
the
en
tire
previous
learning
time.
Then,
an
unexp
ected
sequence
of
rather
quic
k
impro
v
emen
ts
b
egan.
A
t
time
0,0,000,
the
new
record
w
as

correct
v
ariables.
A
t
time
,	,000
,
the
new
record
w
as
.
A
t
time
,,000,
the
new
record
w
as
.
Nearly
immediately
afterw
ards,
at
time
,,000
,
the
new
record
w
as
.
Th
us,
within
less
than


0

time
steps,
the
record
w
as
brok
en

times.
Then
progress
slo
w
ed
do
wn
again.
Suc
h
temp
orary
sp
eed-ups
of
p
erformance
impro
v
emen
t
indicate
useful
shifts
of
inductiv
e
bias,
whic
h
ma
y
later
b
e
replaced
b
y
inductiv
e
bias
created
b
y
the
next
\breakthrough".
Automatic
ne-tunin
g
of
searc
h
space
structure.
A
lo
ok
at
the
stac
k
en
tries
rev
ealed
that
man
y
(but
far
from
all)
useful
probabilit
y
mo
dications
fo
cused
on
few
program
cells.
Often,
self-
mo
dication
programs
directly
c
hanging
the
probabilities
of
certain
additional
self-mo
dication
programs
w
ere
considered
useful.
F
or
instance,

of
the

stac
k
en
tries
at
time
step


0

corresp
onded
to
\useful"
probabilit
y
mo
dications
of
the
(self-referen
tial)
I
ncP
action
of
the
program
cell
with
address
.

en
tries
corresp
onded
to
\useful"
mo
dications
of
the
EndSelfMo
d
probabilit
y
of
v
arious
cells.
Suc
h
stac
k
en
tries
ma
y
b
e
in
terpreted
as
results
of
\adjusting
the
prior
on
the
space
of
solution
candidates"
or
\ne-tuning
searc
h
space
structure"
or
\learning
to
create
directed
m
utations"
or
\learning
ho
w
to
learn".
.
A
Na
viga
tion
T
ask
T
ask
(follo
wing
Sutton,
		).
The
external
en
vironmen
t
consists
of
a
t
w
o-dimensional
grid
with
	
b
y

elds.
F
i;j
denotes
the
eld
in
the
i-th
ro
w
and
the
j
-th
column.
The
follo
wing
elds
are
blo
c
k
ed
b
y
obstacles:
F
;
,
F
;
,
F
;
,
F
;
,
F
;
,
F
;
,
F
;
.
In
the
b
eginning,
an
articial
agen
t
is
placed
on
F
;
(the
start
eld).
In
addition
to
the

general
primitiv
es
from
T
able

(not
coun
ting
input/output
primitiv
es),
there
are
four
problem-sp
ecic
primitiv
es
with
ob
vious
meaning:
one-step-north(),
one-step-
south(),
one-step-e
ast(),
one-step-west().
The
system
cannot
execute
actions
that
w
ould
lead
outside
the
grid
or
in
to
an
obstacle.
Again,
the
follo
wing
v
alues
are
written
in
to
sp
ecial
cells
in
the
input
area
whenev
er
they
c
hange:
IP,
sp,
r
emainder(t=
M
axint).
Another
input
cell
is
lled
with
a

whenev
er
the
agen
t
is
on
the
goal
eld,
otherwise
it
is
lled
with
a
0.
F
our
additional
input
cells
are
rewritten
after
eac
h
execution
of
some
problem-sp
ecic
primitiv
e:
the
rst
(second,
third,
fourth)
cell
is
lled
with
M
axint
if
the
eld
to
the
north
(south,
east,
w
est)
of
the
agen
t
is
blo
c
k
ed
or
do
es
not
exist,
otherwise
the
cell
is
lled
with
 M
axint.
Whenever
the
agent
r
e
aches
F
	;
(the
go
al
eld),
the
system
r
e
c
eives
a
c
onstant
p
ayo
(00),
and
the
agent
is
tr
ansferr
e
d
b
ack
to
F
;
(the
start
eld).
P
arameters
for
storage
size
etc.
are
the
same
as
with
the
previous
task,
and
time
is
measured
the
same
w
a
y
.
Clearly
,
to
maxim
ize
cum
ulativ
e
pa
y
o,
the
system
has
to
nd
short
paths
from
start
to
goal.
Ho
w
dicult
is
this
task?
Again,
the
system
do
es
not
app
ear
to
ha
v
e
m
uc
h
built-in
bias
to
w
ards
the
task:
()
Unlik
e
with
previous
reinforcemen
t
learning
algorithms,
the
system
do
es
not
ha
v
e
a
smart
initial
strategy
for
temp
oral
credit
assignmen
t
|
it
has
to
dev
elop
its
o
wn
suc
h
strategies.
()
Unlik
e
with
Sutton's
original
set-up
(		),
the
system
do
es
not
see
a
built-in
unique
represen
tation
of
its
curren
t
p
osition
on
the
grid.
F
rom
the
system's
p
oin
t
of
view,
its
interfac
e
to
the
envir
onment
is
non-
Markovian
(Sc
hmidh
ub
er,
		):
the
curren
t
input
do
es
not
pro
vide
all
information
ab
out
the
agen
t's
curren
t
p
osition.
()
T
o
mak
e
use
of
the
few
inputs
it
gets,
the
system
rst
has
to
disco
v
er
that
certain


input
cells
ma
y
b
e
relev
an
t
for
solving
its
task.
()
The
total
en
vironmen
t
(including
the
w
ork
area)
is
c
hanging
quite
unpredictably
,
due
to
actions
executed
b
y
the
system
itself.
..
Resul
ts
without
Self-Modifica
tions.
As
with
the
previous
task,
the
system
w
as
rst
tested
with
self-referen
tial
primitiv
es
I
ncP
and
D
ecP
b
eing
switc
hed
o.
A
t
system
death
at
time
0
	
,
total
pa
y
o
w
as
ab
out
0:	

0

.
Av
erage
\trial
length"
(n
um
b
er
of
time
steps
required
to
mo
v
e
from
start
to
goal)
w
as
,.
The
shortest
trial
ev
er
o
ccurred
around
time
step
:

0

and
to
ok

time
steps.
..
Resul
ts
with
Self-Modifica
tions.
A
t
system
death
(at
time
0
	
),
total
pa
y
o
w
as
ab
out
	:

0

.
By
then,
a
v
erage
trial
length
(including
time
required
for
top-lev
el
managemen
t,
of
course)
w
as
do
wn
to
	.
time
steps
(as
opp
osed
to
more
than
,000
time
steps
without
self-mo
dications),
with
ongoing
tendency
to
decrease.
As
with
the
previous
task,
p
erformance
did
not
impro
v
e
smo
othly
.
The
history
of
brok
en
records
reects
the
history
of
p
erformance
impro
v
emen
ts:
First,
there
w
as
a
rather
quic
k
sequence
of
impro
v
em
en
ts
whic
h
lasted
un
til
time
:

0

.
By
then
(after
	
pa
y
o
ev
en
ts),
the
shortest
trial
so
far
had
tak
en

time
steps.
Then,
the
\curren
t
record"
did
not
impro
v
e
an
y
more
for
a
comparativ
ely
long
time
in
terv
al:
:

0

time
steps
|
the
length
of
this
\b
oring"
time
in
terv
al
b
y
far
exceeded
the
en
tire
previous
learning
time.
Sudden
impro
v
emen
t
sp
eed-up.
Then,
quite
unexp
ected
to
the
observ
er,
the
system
started
to
create
a
new
sequence
of
additional
impro
v
emen
ts
around
time
step


0

.
A
t
time
:0

0

,
the
record
w
as
do
wn
to
.
A
t
time
:

0

,
the
record
w
as
do
wn
to
.
A
t
time
	:

0

,
the
record
w
as
do
wn
to
.
A
t
time
	:

0

,
the
record
w
as
do
wn
to
.
A
t
time
0:

0

,
the
record
w
as
do
wn
to
0.
A
t
time
0:

0

,
the
record
w
as
do
wn
to
.
Th
us,
within
ab
out
:

0

time
steps,
the
record
w
as
brok
en

times,
sometimes
dramatically
.
Then,
p
erformance
impro
v
em
en
t
slo
w
ed
do
wn
again.
Throughout
this
urry
of
brok
en
records
starting
at
time
:0

0

,
the
n
um
b
er
of
stac
k
en
tries
increased
quite
steadily
from

(corresp
onding
to

useful
self-mo
dication
programs)
to

(corre-
sp
onding
to

self-mo
dication
programs).
Apparen
tly
,
around
time
step


0

,
the
system
made
a
\rev
olutionary"
disco
v
ery
that
p
ermitted
a
sequence
of
more
\ev
olutionary"
additional
directed
self-
m
utations.
A
t
system
death
(time
step
0
	
),
the
record
w
as
do
wn
to
.
The
system's
a
v
erage
pa
y
o
in
tak
e
p
er
time
in
terv
al
still
had
a
tendency
to
increase.
In
the
end,
there
w
ere
0
useful
self-mo
dication
programs,
eac
h
leading
to
\b
etter"
results
than
all
previous
ones.
As
with
the
previous
task,
man
y
useful
self-mo
dication
programs
directly
mo
died
the
probabilities
of
additional
self-mo
dication
programs.
Compare
the
paragraph
en
titled
\automatic
ne-tuning
searc
h
space
structure"
in
section
...
Exp
erimen
t
:
corrupted
inputs.
In
another
exp
erimen
t,
the
system
w
as
applied
to
the
same
task,
but
inputs
w
ere
corrupted
and
unreliable.
In
the
b
eginning,
it
to
ok
the
system
m
uc
h
longer
to
come
up
with
short
trials.
A
t
time
:

0

,
the
curren
t
record
w
as
.
Then,
not
m
uc
h
happ
ened
for
a
long
time:
there
w
as
only
one
minor
impro
v
emen
t
(0)
during
the
next
:

0

time
steps.
Again,
the
length
of
this
\b
oring"
time
in
terv
al
b
y
far
exceeded
the
en
tire
previous
learning
time.
Then,
around
time
step
	:

0

(corresp
onding
to
half
a
da
y
of
computation
time),
a
\rev
olution"
o
ccurred:
within
only
ab
out
0

additional
time
steps,
the
record
w
as
brok
en

times:
at
time
0:

0

,
the
record
w
as
do
wn
to
0.
Throughout
this
sudden
urry
of
brok
en
records
starting
at
time
	:

0

,
the
n
um
b
er
of
stac
k
en
tries
increased
quite
steadily
from

(corresp
onding
to
	
useful
self-mo
dication
programs)
to
	
(corresp
onding
to

self-mo
dication
programs).
Then,
p
erformance
impro
v
emen
t
slo
w
ed
do
wn
again.
System
life
ended
at
time
step
:

0
	
.
By
this
time,
the
record
w
as
do
wn
to
.
The
system's
a
v
erage
pa
y
o
in
tak
e
p
er
time
in
terv
al
still
had
a
tendency
to
increase.


.
Three
Comments
.
Stabili
t
y
of
probabil
it
y
mo
dications.
With
the
exp
erimen
ts
conducted
so
far,
the
top
lev
el
hardly
ev
er
coun
termanded
probabilit
y
mo
dications
other
than
those
computed
b
y
the
0
most
recen
t
useful
self-mo
dication
programs.
F
or
instance,
once
there
w
ere
0
stac
k
en
tries,
the
00
oldest
stac
k
en
tries
app
eared
extremely
safe
and
had
a
go
o
d
c
hance
to
surviv
e
the
en
tire
system
life.
This
empirically
justies
the
metho
d
suggested
in
the
commen
t
on
limited,
circular
stac
ks
in
section
.
.
Rev
olution
s
and
ev
olution
s.
In
the
tasks
ab
o
v
e,
unexp
ected
temp
orary
sp
eed-ups
of
p
erfor-
mance
impro
v
emen
ts
w
ere
observ
ed.
Ev
en
if
the
system
app
ears
to
b
e
stuc
k
for
a
long
time,
the
external
observ
er
nev
er
can
b
e
sure
that
it
will
not
suddenly
disco
v
er
a
new,
\rev
olutionary"
shift
of
bias
that
builds
the
basis
for
additonal,
smo
other,
\ev
olutionary"
p
erformance
impro
v
emen
ts.
This
is
analoguous
to
the
history
of
science
itself.
One
nice
thing
ab
out
op
en-ended
incremen
tal
self-impro
v
em
en
t
is
that
there
is
no
signican
t
theoretical
limit
to
what
the
system
ma
y
learn.
This
is,
of
course,
due
to
the
univ
ersal
nature
of
the
underlying
programmi
ng
language.
Informally
,
a
\rev
olution"
corresp
onds
to
a
self-impro
v
emen
t
with
high
\c
onc
eptual
jump
size"
(an
expression
coined
b
y
Solomono,
		0),
while
\ev
olution"
corresp
onds
to
a
sequence
of
self-
impro
v
emen
ts
with
lo
w
conceptual
jump
sizes.
.
Inserting
prior
bias.
The
exp
erimen
ts
ab
o
v
e
certainly
are
not
mean
t
to
con
vince
the
reader
that
from
no
w
on,
he
should
com
bine
the
incremen
tal
self-impro
v
emen
t
paradigm
with
the
lo
w-
lev
el
programmi
ng
language
from
section

and
apply
it
to
real
w
orld
problems.
Instead,
the
exp
erimen
ts
are
mean
t
to
illustrate
basic
principles
of
the
paradigm.
Of
course,
with
large
scale
problems,
it
is
desirable
to
insert
prior
kno
wledge
in
to
the
system
(if
suc
h
kno
wledge
is
indeed
a
v
ailable).
With
incremen
tal
self-impro
v
emen
t,
a
priori
kno
wledge
resides
in
the
programmer's
selection
of
primitiv
es
with
problem-sp
ecic
built-in
bias
(and
in
the
pa
y
o
function
he
c
ho
oses).
Ther
e
is
no
r
e
ason
why
c
ertain
primitives
should
not
b
e
c
omplex,
time
c
onsuming
pr
o
gr
ams
by
themselves,
such
as
statistic
classiers,
neur
al
net
le
arning
algorithms,
lo
gic
pr
o
gr
ams,
etc.
F
or
instance,
using
dieren
t
primitiv
es
for
the
na
vigation
task
from
section
.
can
greatly
reduce
the
time
required
to
ac
hiev
e
near-optimal
trials.
This
pap
er,
ho
w
ev
er,
is
not
a
study
of
the
eects
of
dieren
t
kinds
of
initial
bias.

Histor
y
of
Ideas
/
Previous
W
ork
In
what
follo
ws,
I
will
briey
describ
e
earlier
w
ork
and
the
train
of
though
t
leading
to
this
pap
er.
Meta-ev
olution.
My
rst
attempts
to
come
up
with
sc
hemes
for
\true"

self-referen
tial
learning
based
on
univ
ersal
languages
date
bac
k
to
	.
They
w
ere
partly
inspired
b
y
a
collab
oration
with
Dic
kmanns
and
Winklhofer
(	).
W
e
used
a
genetic
algorithm
(GA)
to
ev
olv
e
v
ariable
length
Prolog
programs
for
solving
simple
tasks

.
So
on
there
w
as
a
desire
to
impro
v
e
the
trivial
m
utation
and
crosso
v
er
strategies
used
to
construct
new
programs
from
old
ones.
This
led
to
an
algorithmic
sc
heme
(called
\meta-evolution
")
for
letting
more
sophisticated
strategies
b
e
learned
b
y
a
p
oten
tially
innite
hierarc
h
y

I
am
not
talking
ab
out
xed
learning
algorithms
for
adjusting
the
parameters
of
others.
F
or
instance,
GAs
are
sometimes
used
to
adjust
learning
rates
of
gradien
t
based
neural
nets,
etc.
Or
a
neural
net
is
used
to
compute
the
w
eigh
ts
of
another
neural
net.
In
the
literature,
one
can
nd
quite
a
few
approac
hes
of
this
kind
(to
o
man
y
to
cite
them
all
|
I
settle
b
y
citing
none,
not
ev
en
m
y
o
wn).
Although
suc
h
approac
hes
sometimes
ma
y
ha
v
e
their
merits,
they
do
not
deserv
e
the
attribute
\self-referen
tia
l"
|
the
additional
lev
el
t
ypically
just
defers
the
credit
assignmen
t
problem.
There
w
ere
a
few
apparen
tly
more
general
approac
he
s.
F
or
instance,
Lenat
(	)
rep
orts
that
his
Eurisk
o
system
w
as
able
to
disco
v
er
certain
heuristics
for
disco
v
ering
heuristics.
Ho
w
ev
er,
his
approac
h,
as
w
ell
as
all
other
previous
approac
hes
I
am
a
w
are
of,
w
ere
either
quite
limited
(man
y
essen
tial
asp
ects
of
system
b
eha
vior
b
eing
unmo
diab
le)
,
and/or
lac
k
ed
a
con
vincing
global
credit
assignmen
t
strategy
(as
em
b
o
died
b
y
the
top-lev
el
strategy
of
the
incremen
ta
l
self-impro
v
em
en
t
paradigm).

T
o
da
y
,
this
approac
h
w
ould
b
e
classied
as
\Genetic
Programming
",
e.g.
(Koza,
		).


of
higher
lev
el
GAs
whose
domains
w
ere
to
construct
construction
strategies
(Sc
hmidh
ub
er,
	).
Meta-
evolution
recursiv
ely
creates
a
gro
wing
hierarc
h
y
of
p
o
ols
of
programs
|
higher-lev
el
p
o
ols
con
taining
program
mo
difying
programs
b
eing
applied
to
lo
w
er-lev
el
programs
and
b
eing
rew
arded
based
on
lo
w
er-
lev
el
p
erformance.
Collapsing
meta-lev
els.
The
explicit
creation
of
\meta-lev
els"
and
\meta-meta-lev
els"
seemed
unnatural,
ho
w
ev
er.
F
or
this
reason,
alternativ
e
systems
based
on
\self-referen
tial"
languages
w
ere
explored,
the
goal
b
eing
to
collapse
all
meta-lev
els
in
to
one
(Sc
hmidh
ub
er,
	).
A
t
that
time,
ho
w
ev
er,
no
con
vincing
global
credit
assignmen
t
strategy
w
as
pro
vided.
Self-referen
ti
al
neural
nets.
Later
w
ork
presen
ted
a
neural
net
w
ork
with
the
p
oten
tial
to
run
its
o
wn
w
eigh
t
c
hange
algorithm
(Sc
hmidh
ub
er
		,
		a,
		b).
With
this
system,
top-lev
el
credit
assignmen
t
is
p
erformed
b
y
gradien
t
descen
t.
This
is
unsatisfactory
,
ho
w
ev
er,
due
to
problems
with
lo
cal
minim
a,
and
b
ecause
rep
eatable
training
sequences
are
required.
In
general,
this
mak
es
it
imp
ossible
to
tak
e
the
en
tire
learning
history
in
to
accoun
t.
Algorithmi
c
probabili
t
y
/
Univ
ersal
searc
h.
Levin's
univ
ersal
searc
h
algorithm
is
theoreti-
cally
optimal
for
certain
\non-incremen
tal"
searc
h
tasks
with
exactly
rep
eatable
initial
conditions.
See
Levin
(	,
	);
see
also
Adleman
(		).
There
w
ere
a
few
attempts
to
extend
univ
ersal
searc
h
to
incremen
tal
learning
situations,
where
previous
\trials"
ma
y
pro
vide
information
ab
out
ho
w
to
sp
eed
up
further
learning,
see
e.g.
(Solomono,
		0;
P
aul
and
Solomono,
		;
Sc
hmidh
ub
er,
		).
F
or
instance,
to
impro
v
e
future
p
erformance,
Solomono
(	,
		0)
describ
es
more
traditional
(as
opp
osed
to
self-impro
ving)
metho
ds
for
assigning
probabilities
to
successful
\subprograms".
Alternativ
ely
,
one
of
the
actually
implemen
ted
systems
in
(Sc
hmidh
ub
er,
		)
simply
k
eeps
successful
co
de
in
its
pro-
gram
area.
This
system
w
as
a
conceptual
starting
p
oin
t
for
the
one
in
the
curren
t
pap
er.
With
rst
attempts
(in
Septem
b
er
		),
the
probabilit
y
distributions
underlying
the
T
uring
mac
hine
equiv
alen
t
language
required
for
univ
ersal
searc
h
w
ere
mo
died
heuristically
.
One
strategy
w
as
to
sligh
tly
increase
the
con
text-dep
enden
t
probabilities
of
program
cell
con
ten
ts
used
in
successful
programs,
and
then
con-
tin
ue
univ
ersal
searc
h
based
on
the
new
probabilit
y
distributions.
With
a
n
um
b
er
of
exp
erimen
ts,
this
actually
led
to
go
o
d
results
(at
rst
glance,
more
impressiv
e
results
than
those
in
the
curren
t
pap
er,
at
least
if
one
do
es
not
tak
e
the
lac
k
of
bias
in
to
accoun
t,
as
one
should
alw
a
ys
do).
The
system,
ho
w
ev
er,
w
as
unsatisfactory
,
precisely
b
ecause
there
w
as
no
principled
w
a
y
of
adjusting
probabilit
y
distributions.
This
criticism
led
to
the
ideas
expressed
in
the
curren
t
pap
er.
Meta-v
ersion
of
univ
ersal
searc
h.
Without
going
in
to
details,
Solomono
(		0)
men
tions
that
self-impro
v
emen
t
ma
y
b
e
form
ulated
as
a
time-lim
ited
optimization
problem,
th
us
b
eing
solv
able
b
y
univ
ersal
searc
h.
Ho
w
ev
er,
the
straigh
t-forw
ard
meta-v
ersion
of
univ
ersal
searc
h
(generating
and
ev
al-
uating
probabilit
y
distributions
in
order
of
their
Levin
complexities
|
see
Levin,
	)
just
defers
the
credit
assignmen
t
problem
to
the
meta-lev
el,
and
do
es
not
necessarily
mak
e
optimal
incremen
tal
use
of
computational
resources
and
previous
exp
erience

.
Note
that
incremen
tal
self-impro
v
em
en
t
is
not
a
meta-v
ersion
of
univ
ersal
searc
h.
In
fact,
incremen
tal
self-impro
v
emen
t
do
es
not
mak
e
a
dierence
b
et
w
een
\searc
h"
and
\meta-searc
h".
Ongoing/futu
re
w
ork.
The
concrete
implemen
tation
describ
ed
in
section

represen
ts
only
one
out
of
man
y
w
a
ys
of
implemen
ting
the
incremen
tal
self-impro
v
emen
t
paradigm.
It
is
in
tended
to
apply
incremen
tal
self-impro
v
emen
t
to
more
complex
tasks,
including
prediction
and
con
trol
tasks,
using
a
v
ariet
y
of
univ
ersal,
\self-referen
tial"
sets
of
primitiv
es,
including
sets
designed
to
exploit
the
b
enets
of
parallel,
neural
net-lik
e
hardw
are.

Solomono

app
ears
to
b
e
w
ell
a
w
are
of
problems
with
the
meta-v
ersion
:
at
the
end
of
his
		0
pap
er,
he
refers
to
self-impro
v
e
men
t
as
a
\more
distan
t
goal":
\The
kind
of
tr
aining
ne
e
de
d
involves
mor
e
mathematics
and
work
on
various
kinds
of
optimization
pr
oblems
|
ultimately
pr
oblems
of
impr
oving
c
omputer
pr
o
gr
ams."
Another
\more
distan
t
goal"
men
tioned
b
y
Solomono
is
to
let
the
system
w
ork
\on
an
unor
der
e
d
b
atch
of
pr
oblems
|
de
ciding
itself
which
ar
e
the
e
asiest,
and
solving
them
rst".
Note
that
the
incremen
ta
l
self-impro
v
em
en
t
paradigm
addresses
b
oth
goals,
without
dep
ending
on
a
meta-v
ersion
of
univ
ersal
searc
h.
See
e.g.
commen
t

in
section
.



A
ckno
wledgements
I
am
grateful
to
Ra
y
Solomono,
P
eter
Da
y
an,
Mik
e
Mozer,
Don
Matthis,
Cla
yton
McMillan,
and
v
arious
NIPS*	
participan
ts,
for
v
aluable
commen
ts/discussions
on
the
rst
v
ersion
of
this
rep
ort
(from
No
v
em
b
er
,
		).
Man
y
thanks
to
Sepp
Ho
c
hreiter,
Gerhard
W
ei,
Martin
Eldrac
her,
Margit
Kinder,
and
Daniel
Prelinger,
for
critical
remarks
on
earlier
drafts,
and
to
Leslie
Kaelbling,
Da
vid
Cohn,
and
T
omm
i
Jaakk
ola,
for
useful
commen
ts
on
later
v
ersions.
I
am
particularly
indebted
to
Mark
Ring
for
extensiv
e
and
constructiv
e
criticism.
References
Adleman,
L.
(		).
Time,
space,
and
randomness.
T
ec
hnical
Rep
ort
MIT/LCS/	/TM-,
Lab
oratory
for
Computer
Science,
MIT.
Barto,
A.
G.
(		).
Connectionist
approac
hes
for
con
trol.
T
ec
hnical
Rep
ort
COINS
T
ec
hnical
Rep
ort
	-	,
Univ
ersit
y
of
Massac
h
usetts,
Amherst
MA
000.
Chaitin,
G.
(		).
On
the
length
of
programs
for
computing
nite
binary
sequences:
statistical
consid-
erations.
Journal
of
the
A
CM,
:{	.
Da
y
an,
P
.
and
Sejno
wski,
T.
(		).
TD():
Con
v
ergence
with
probabilit
y
.
Machine
L
e
arning,
:	{
0.
Dic
kmanns,
D.,
Sc
hmidh
ub
er,
J.,
and
Winklhofer,
A.
(	).
Der
genetisc
he
Algorithm
us:
Eine
Imple-
men
tierung
in
Prolog.
F
ortgesc
hrittenenpraktikum,
Institut
f

ur
Informatik,
Lehrstuhl
Prof.
Radig,
T
ec
hnisc
he
Univ
ersit
at
M

unc
hen.
Dietteric
h,
T.
G.
(		).
Limitations
of
inductiv
e
learning.
In
Pr
o
c
e
e
dings
of
the
Sixth
International
Workshop
on
Machine
L
e
arning,
Ithac
a,
NY,
pages
{.
San
F
rancisco,
CA:
Morgan
Kaufmann.
Homeister,
F.
and
B
ac
k,
T.
(		).
Genetic
algorithms
and
ev
olution
strategies:
Similarities
and
dierences.
In
M
anner,
R.
and
Sc
h
w
efel,
H.
P
.,
editors,
Pr
o
c.
of
st
International
Confer
enc
e
on
Par
al
lel
Pr
oblem
Solving
fr
om
Natur
e,
Berlin.
Springer.
Holland,
J.
H.
(	).
A
daptation
in
Natur
al
and
A
rticial
Systems.
Univ
ersit
y
of
Mic
higan
Press,
Ann
Arb
or.
Kolmogoro
v,
A.
(	).
Three
approac
hes
to
the
quan
titativ
e
denition
of
information.
Pr
oblems
of
Information
T
r
ansmission,
:{.
Koza,
J.
R.
(		).
Genetic
ev
olution
and
co-ev
olution
of
computer
programs.
In
Langton,
C.,
T
a
ylor,
C.,
F
armer,
J.
D.,
and
Rasm
ussen,
S.,
editors,
A
rticial
Life
II,
pages
{.
Addison
W
esley
Publishing
Compan
y
.
Lenat,
D.
(	).
Theory
formation
b
y
heuristic
searc
h.
Machine
L
e
arning,
.
Levin,
L.
A.
(	).
La
ws
of
information
(nongro
wth)
and
asp
ects
of
the
foundation
of
probabilit
y
theory
.
Pr
oblems
of
Information
T
r
ansmission,
0():0{0.
Levin,
L.
A.
(	).
Randomness
conserv
ation
inequalities:
Information
and
indep
endence
in
mathe-
matical
theories.
Information
and
Contr
ol,
:{.
Li,
M.
and
Vit
an
yi,
P
.
M.
B.
(		).
A
n
Intr
o
duction
to
Kolmo
gor
ov
Complexity
and
its
Applic
ations.
Springer.
P
aul,
W.
and
Solomono,
R.
J.
(		).
Autonomous
theory
building
systems.
Man
uscript,
revised
		.
	

Rec
hen
b
erg,
I.
(	).
Ev
olutionsstrategie
-
Optimierung
tec
hnisc
her
Systeme
nac
h
Prinzipien
der
biol-
ogisc
hen
Ev
olution.
Dissertation.
Published
	
b
y
F
romman-Ho
lzb
o
og.
Ring,
M.
B.
(		).
Continual
L
e
arning
in
R
einfor
c
ement
Envir
onments.
PhD
thesis,
Univ
ersit
y
of
T
exas
at
Austin,
Austin,
T
exas
.
Sc
haer,
C.
(		).
Ov
ertting
a
v
oidance
as
bias.
Machine
L
e
arning,
0:{.
Sc
hmidh
ub
er,
J.
H.
(	).
Ev
olutionary
principles
in
self-referen
tial
learning,
or
on
learning
ho
w
to
learn:
the
meta-meta-..
.
ho
ok.
Institut
f

ur
Informatik,
T
ec
hnisc
he
Univ
ersit
at
M

unc
hen.
Sc
hmidh
ub
er,
J.
H.
(		).
Reinforcemen
t
learning
in
Mark
o
vian
and
non-Mark
o
vian
en
vironmen
ts.
In
Lippman,
D.
S.,
Mo
o
dy
,
J.
E.,
and
T
ouretzky
,
D.
S.,
editors,
A
dvanc
es
in
Neur
al
Information
Pr
o
c
essing
Systems
,
pages
00{0.
San
Mateo,
CA:
Morgan
Kaufmann.
Sc
hmidh
ub
er,
J.
H.
(		).
Steps
to
w
ards
\self-referen
tial"
learning.
T
ec
hnical
Rep
ort
CU-CS--	,
Dept.
of
Comp.
Sci.,
Univ
ersit
y
of
Colorado
at
Boulder.
Sc
hmidh
ub
er,
J.
H.
(		a).
A
neural
net
w
ork
that
em
b
eds
its
o
wn
meta-lev
els.
In
Pr
o
c.
of
the
Inter-
national
Confer
enc
e
on
Neur
al
Networks
'	,
San
F
r
ancisc
o.
IEEE.
Sc
hmidh
ub
er,
J.
H.
(		b).
A
self-referen
tial
w
eigh
t
matrix.
In
Pr
o
c
e
e
dings
of
the
International
Con-
fer
enc
e
on
A
rticial
Neur
al
Networks,
A
mster
dam,
pages
{.
Springer.
Sc
hmidh
ub
er,
J.
H.
(		).
Disco
v
ering
problem
solutions
with
lo
w
Kolmogoro
v
complexit
y
and
high
generalization
capabilit
y
.
T
ec
hnical
Rep
ort
FKI-	-	,
F
akult
at
f

ur
Informatik,
T
ec
hnisc
he
Uni-
v
ersit
at
M

unc
hen.
Sc
h
w
efel,
H.
P
.
(	).
Numerisc
he
Optimierung
v
on
Computer-Mo
dellen.
Dissertation.
Published
	
b
y
Birkh
auser,
Basel.
Shannon,
C.
E.
(	).
A
mathematical
theory
of
comm
unication
(parts
I
and
I
I).
Bel
l
System
T
e
chnic
al
Journal,
XXVI
I:	{.
Solomono,
R.
(	).
A
formal
theory
of
inductiv
e
inference.
P
art
I.
Information
and
Contr
ol,
:{.
Solomono,
R.
(		0).
A
system
for
incremen
tal
learning
based
on
algorithmic
probabilit
y
.
In
P
ednault,
E.
P
.
D.,
editor,
The
The
ory
and
Applic
ation
of
Minimal-L
ength
Enc
o
ding
(Pr
eprint
of
Symp
osium
p
ap
ers
of
AAAI
		0
Spring
Symp
osium).
Sutton,
R.
S.
(		).
In
tegrated
mo
deling
and
con
trol
based
on
reinforcemen
t
learning
and
dynamic
programming
.
In
Lippman,
D.
S.,
Mo
o
dy
,
J.
E.,
and
T
ouretzky
,
D.
S.,
editors,
A
dvanc
es
in
Neur
al
Information
Pr
o
c
essing
Systems
,
pages
{.
San
Mateo,
CA:
Morgan
Kaufmann.
Utgo,
P
.
(	).
Shift
of
bias
for
inductiv
e
concept
learning.
In
Machine
L
e
arning,
v
olume
.
Morgan
Kaufmann,
Los
Altos,
CA.
W
atkins,
C.
(		).
L
e
arning
fr
om
Delaye
d
R
ewar
ds.
PhD
thesis,
King's
College.
William
s,
R.
J.
(		).
Simple
statistical
gradien
t-follo
wing
algorithms
for
connectionist
reinforcemen
t
learning.
Machine
L
e
arning,
:	{.
W
olp
ert,
D.
H.
(		).
On
o
v
ertting
a
v
oidance
as
bias.
T
ec
hnical
Rep
ort
SFI
TR
	-0-0,
San
ta
F
e
Institute,
NM
0.
0

