“I Want It That Way”: Enabling Interactive Decision Support Using Large
Language Models and Constraint Programming
CONNOR LAWLESS, Cornell University, USA
JAKOB SCHOEFFER, Karlsruhe Institute of Technology, Germany
LINDY LE, Microsoft, USA
KAEL ROWAN, Microsoft Research, USA
SHILAD SEN, Microsoft, USA
CRISTINA ST. HILL, Microsoft, USA
JINA SUH, Microsoft Research, USA
BAHAR SARRAFZADEH, Microsoft, USA
A critical factor in the success of decision support systems is the accurate modeling of user preferences. Psychology research has
demonstrated that users often develop their preferences during the elicitation process, highlighting the pivotal role of system-user
interaction in developing personalized systems. This paper introduces a novel approach, combining Large Language Models (LLMs)
with Constraint Programming to facilitate interactive decision support. We study this hybrid framework through the lens of meeting
scheduling, a time-consuming daily activity faced by a multitude of information workers. We conduct three studies to evaluate the
novel framework, including a diary study (n=64) to characterize contextual scheduling preferences, a quantitative evaluation of the
system’s performance, and a user study (n=10) with a prototype system. Our work highlights the potential for a hybrid LLM and
optimization approach for iterative preference elicitation and design considerations for building systems that support human-system
collaborative decision-making processes.
1
INTRODUCTION
Understanding what a user likes and dislikes, i.e., their preferences, is crucial for the success of intelligent systems that
provide decision and negotiation support across many domains. Decision support systems target the decision-making
process itself, helping the user discover and articulate their preferences, understand the link between preferences and
decision outcomes, and analyze the steps taken in the process. However, eliciting preference information from a user to
inform such a decision process is challenging. This challenge manifests not only as a limitation of the algorithms for
elicitating or representing preferences but also as an inherent difficulty of users knowing about or expressing their
desired solutions.
Individuals are often unsure of their preferences, hold inconsistent preferences, and change their preferences as they
go about making decisions which can be attributed to the inherent limitations of individuals’ memory, attention, and
knowledge [42, 53, 54, 68]. These challenges are shared across widespread decision-making scenarios, such as meeting
scheduling, travel planning or purchasing a house. Preference elicitation tools and techniques [28] are known to assist
human decision-makers in overcoming some of their inherent memory or knowledge limitations, extracting information
from the user’s mental representation of that preference and translating it into a representation through which the
Authors’ addresses: Connor Lawless, Cornell University, Ithaca, NY, USA, 14850, cal379@cornell.edu; Jakob Schoeffer, Karlsruhe Institute of Technology,
Karlsruhe, Germany, jakob.schoeffer@gmail.com; Lindy Le, Microsoft, Redmond, WA, USA, lindy.le@microsoft.com; Kael Rowan, Microsoft Research,
Redmond, WA, USA, kael.rowan@microsoft.com; Shilad Sen, Microsoft, Redmond, WA, USA, shilad.sen@microsoft.com; Cristina St. Hill, Microsoft,
Redmond, WA, USA, crdaes@microsoft.com; Jina Suh, Microsoft Research, Redmond, WA, USA, jinasuh@microsoft.com; Bahar Sarrafzadeh, Microsoft,
Redmond, WA, USA, basarraf@microsoft.com.
1
arXiv:2312.06908v1  [cs.HC]  12 Dec 2023

2
Lawless et al.
system can reason. However, the constructive nature of human preferences implies that the interaction between the
system and a user can greatly influence the quality of the preference information [19, 35, 57] and the user’s acceptance
of the results provided by the system [8, 14]. Prior work has shown that such preference elicitation systems need to be
collaborative to facilitate seamless information exchange between the user and the system [56], contextualized to the
decision-making process [14, 54, 59, 68], and incremental to account for evolving preferences [4, 57, 59].
However even once preferences are elicited, finding a solution that best meets them represents a challenging
decision making task. Optimization models such as Constraint Programming (CP) are a natural fit for solving this
complex reasoning problem and have been successfully applied in a range of multi-attribute decision problems. CP
specifically aligns with multi-attribute decision theory [26, 30, 36] where preferences are represented as utility functions
or embedded as constraints, and constraint satisfaction techniques are leveraged to manage trade-offs [67]. However,
traditional optimization approaches require full knowledge of the model’s specification—including a fully specified
objective and all relevant constraints. This is at odds with how users approach complex and contextual decision-making
tasks where they often do not know relevant preferences unless presented with candidate solutions. Furthermore,
customizing optimization models requires expertise in coding and optimization, an unrealistic barrier for most users.
Finally, these optimization approaches must function as dynamic and incremental reasoning engines: users actively
construct and adjust their preferences while the system continuously learns and embeds their preferences, offering
increasingly improved suggestions until a satisfactory one is achieved.
In this paper, we explore an innovative framework that supports iterative preference elicitation, aligning with how
humans develop or construct preferences in their decision-making. Elicited preferences are embedded into specific
constraints that can be solved within an optimization setting. We leverage (1) Large Language Models (LLMs) to facilitate
natural and intuitive communication of preferences and suggestions as well as to reason about how preferences should
be incorporated and translated into structured constraint functions and (2) CP techniques to reason over the space of
outcomes and find optimal solutions given incorporated constraints.
We evaluate this framework for interactive decision support systems through the lens of meeting scheduling—a
routine, tedious, and time-consuming daily activity faced by a multitude of information workers. At its core, scheduling
a meeting is a complex spatial-temporal task that is highly contextual, and finding a suitable meeting time may require
reasoning over conflicting preferences, constraints, and priorities [27]. It is also an incremental and continuous process
that requires iteratively refining candidate solutions in a more or less greedy fashion [12]. Therefore, interactive decision
support tools are a natural fit for scheduling as they can provide contextualized and interactive support for the complex
reasoning that is necessary to complete the task.
We introduce MeetMate, a hybrid LLM and CP approach that capitalizes on the benefits of both technologies to
build an interactive decision support system for meeting scheduling. MeetMate is designed to facilitate human-system
collaboration that encompasses two key components: Preference Construction and Preference Incorporation. Preference
Construction is the process by which users of the system evaluate candidate decisions (i.e., suggested meeting times)
and express new preferences and constraints that need to be integrated into the system. Preference Incorporation is a
mirror of the construction process from the system perspective and involves embedding expressed user preferences in a
form that can be used by the system to generate new suggested decisions. We refer to the entire process of iteratively
eliciting preferences via generating and critiquing suggestions as Preference Elicitation. Because preference elicitation is
an iterative process, MeetMate unifies Preference Construction and Preference Incorporation into one dynamic loop
where preferences are elicited in conjunction with refined suggestion generations. Figure 1 outlines the key components
of our interactive decision support system for meeting scheduling.

“I Want It That Way”: Enabling Interactive Decision Support Using Large Language Models and Constraint
Programming
3
Fig. 1. An overview of the interactive loop for conversational decision support. The loop is initiated via an initial time suggestion (or
set of suggestions) by the system presented to the user (A). During Preference Construction users evaluate a proposed suggestion
(C) and either express a new preference (D) to improve the given suggestion, or accept the current suggestion. New preferences are
integrated into the system during Preference Incorporation which requires the system to both embed the stated preference into the
system (W) and then use it to generate a new time suggestion (F). This process is iterated until a suitable time is found.
We conducted three studies to better understand preference elicitation in the context of meeting scheduling. First,
we study how preferences are constructed via a diary study that collected naturalistic preferences in the moment of
scheduling (n=64, Section 3). Informed by the results of the diary study, we then introduce MeetMate (Section 4) and
quantitatively evaluate the system’s capabilities for preference incorporation (Section 5). Finally, we conduct a user
study (n=10, Section 6) with a prototype system to observe the iterative preference elicitation flow in situ and to inform
future design improvements for interactive decision support systems. Through our study, we confirm that participants’
preferences are indeed constructed through the iterative preference elicitation process of evaluating dynamic time
suggestions that incorporate their feedback. We also identify that system explanations play a huge role in bridging the
gap between understanding the system and expressing preferences, and contrasted suggestions not only give users a
sense of agency but also help make the decision-making process efficient. Our work highlights the potential for a hybrid
LLM and optimization approach for iterative preference elicitation and design considerations for building systems that
support human-system collaborative decision-making processes.
2
BACKGROUND AND RELATED WORK
Our paper connects to a long line of work on both human preferences, and approaches by which to elicit them. From a
methodological perspective, we build upon recent work at the intersection of large language models, mathematical
optimization, and mechanisms by which they interact.
2.1
Human Preferences and Design Implications
In 2002, Carenini and Poole [14] described a shift in classical decision theory towards constructive preferences, contrary
to the prevailing view of stable and rational preferences (e.g., [25]). Psychological studies have shown that preferences
are often constructed rather than stable, and individuals may hold inconsistent or evolving preferences [35, 42, 68].
This constructive nature of preferences has been emphasized, suggesting that preferences are more like architectural
creations than archaeological discoveries [29, 55]. In various decision-making theories [33, 47, 49, 64], it has been
posited that people construct preferences when faced with decisional conflicts. Preferences are not well-defined in most
situations but are constructed in the context of decision-making, particularly when conflicts arise. This process allows

4
Lawless et al.
individuals to adjust their initial preferences to make confident decisions, especially when one option clearly outweighs
others [66]. Incremental preference elicitation has received attention [4, 57, 59] due to the uncertain nature of user
goals and preferences. It involves improving a user’s preference model over time as they interact with the system.
Preference construction has also been explored within the framework of multi-attribute decision theory (MAUT) [26,
30, 36], where preferences are represented as utility functions. Research in this area has shown that people tend to
increase their preferences for attributes of chosen options while decreasing preferences for attributes of rejected options.
Similar effects have been observed in negotiation settings [22]. These findings align with the goal of maximizing
the ease of justifying a decision, as identified by Bettman et al. [8]. This research on decision-making by constraint
satisfaction has identified coherence shifts in various tasks, including high-level reasoning, social reasoning, and factual
inferences [67].
To develop an effective decision support system, designers must take into account the process of human preference
development [18, 57, 59]. Relevant literature provides key insights for designing effective decision support systems in
two main areas. First, a wealth of research in HCI and user-centered design highlights the paramount significance of
interactivity and collaboration within decision support systems. Effective decision support necessitates a collaborative
environment wherein both the user and the system can seamlessly exchange information and jointly tackle decision-
making challenges. Second, studies in supporting preference construction offer further guidance on structuring this
collaborative process. This collaboration involves two critical elements: (1) natural interaction, i.e., the system UI should
offer user-friendly tools for users to express, revise, and provide feedback on their preferences and constraints, as well as
critique system suggestions; (2) iterative and transparent system recommendations, i.e., the system should contextualize
the decision-making, enabling users to understand decision consequences [54, 59, 68]. Providing concrete examples for
user critique [20, 44, 59], along with immediate feedback and explanations, helps users grasp the correlation between
preferences, constraints, and proposed solutions [14].
Our work primarily centers on the information flow from the system to the user, aligning with the process of human
preference development and decision-making. It underscores the significance of contextualized elicitation mechanisms,
concrete examples for user critique, immediate feedback with explanations, incremental suggestion generation, and the
utilization of constraint satisfaction as the reasoning algorithm.
2.2
Preference Elicitation Techniques
To create a user-friendly system, designers must consider the development of human preferences, and as such, preference
elicitation is a well-explored topic in artificial intelligence, recommender systems, and human-computer interaction [28].
Various techniques exist for inferring user preferences, including rankings, corrections, critiques, ratings, queries, and
past behavior. Preference elicitation methods can be broadly categorized into two types: implicit and explicit. Implicit
methods involve learning user preferences from behavior, aligning with Revealed Preference Theory [62]. In contrast,
explicit methods, such as collecting ratings, actively involve users in constructing and reflecting on their preferences.
Our approach falls into the explicit category, allowing users to specify their preferences during the process. Our method
draws inspiration from techniques like Similarity and Tweaking [15, 34]; and Example-Critiquing Interaction [20]. These
approaches involve users in the recommendation process by having them specify attributes or critique candidate options.
Similarly, our system follows an iterative approach, enabling users to critique time recommendations within the chat
interface.
Our work is also related to preference elicitation in Decision Support Systems (DSS), where interactive tools assist
users in decision-making. Most DSS rely on multi-attribute utility theory [36] to represent preferences as utility functions.

“I Want It That Way”: Enabling Interactive Decision Support Using Large Language Models and Constraint
Programming
5
However, constructing these utility functions in collaboration with users is challenging. Traditional methods like absolute
measurement and pairwise comparison (active elicitation) [3] may lead to misalignment between users’ qualitative
mental models of preferences and the system’s quantitative representation. In the context of calendar scheduling,
understanding user preferences is essential. Previous research has used various approaches, including machine learning
on existing calendars [48], showing users sample schedules [12], and allowing direct input of parameters [31]. Our
approach stands out by allowing users to specify new preferences flexibly, accommodating more diverse contextual
scheduling preferences.
2.3
LLMs and Optimization
Large Language Models (LLMs) have emerged as a promising tool for helping accomplish a number of tasks such as
generating code [21], writing [80], and visualizing data [24]. However, they are well known to suffer from hallucinations,
seemingly plausible text predictions that are in fact non-factual [76], and poor mathematical reasoning ability [60].
Recent work have aimed to address these shortcomings by helping LLMs decompose complex tasks into simpler steps
(e.g., [75, 78, 79]) and augmenting them with external tools (e.g., [50, 65, 73]) such as a code interpreter (see Mialon
et al. [45] for a survey of other related approaches). Our work builds upon this line of work by decomposing the
complex problem of suggesting meeting times into structured sub-components (detailed in Section 4). We also employ
an optimization solver as an external tool to perform complex reasoning over meeting times. This is in contrast to other
existing working on collaborative decision making between LLMs and humans such as Lin et al. [43] which requires
the LLM to generate the solutions.
Mathematical optimization is a powerful tool used in various industrial applications [7]. In this paper, our focus is
on (Weighted) Constraint Programming [63], a modeling paradigm where the optimization problem involves a set of
arbitrary constraints with different weights. The objective is to find a solution with the optimal score, determined by
the total weight of satisfied constraints. Traditionally, constraint programming demands a complete specification of the
optimization model, including all constraints and their coefficients. This poses challenges for preference elicitation, where
users’ constraints and preferences are often unknown and expressed within the context of proposed solutions. Recent
research has addressed this by tackling constraint programming problems with incomplete information, requiring the
elicitation of certain data and preferences [69–72, 77]. However, existing approaches primarily focus on the algorithmic
aspects of what information to elicit, rather than the mechanism for eliciting it. This distinction is crucial, particularly in
settings like meeting scheduling, where non-expert users may lack the modeling expertise to formulate the constraints
they want in the model.
Natural language processing (NLP) holds promise in simplifying interactions with optimization models for non-expert
users. Recent work has employed LLMs for users to query models in areas like supply chain management [41] and
identifying infeasible subsystems [17]. However, these chat-based systems primarily aid in understanding existing
models, not constructing new ones. To address the challenge of formulating optimization problems, recent research
focuses on translating natural language descriptions into formal optimization models. Ramamonjison et al. [61])
initiated this effort, leading to the NL4Opt competition at NeurIPS and related work on named entity recognition and
semantic parsing [23, 51, 58, 74]. These approaches typically address static contexts, translating a single text paragraph
into an optimization model. In contrast, our study focuses on an interactive model, capturing user preferences during
optimization model construction. We emphasize translating natural language into Python constraints within a constraint
programming framework, distinct from traditional named entity recognition for linear and integer programming.

6
Lawless et al.
3
PREFERENCE CONSTRUCTION: UNDERSTANDING CONTEXTUAL SCHEDULING PREFERENCES
We first investigated preference construction in the context of meeting scheduling. Specifically, we aimed to identify and
characterize the types of contextualized preferences elicited in response to given time suggestions. In the absence of an
existing interactive system through which we could analyze users preferences in response to dynamic time suggestions,
we conducted a diary study at a large technology company that elicited user preferences in response to static time
suggestions from an existing calendar tool. The findings of our diary study were used to inform the design of the system
(Section 4) and create a new quantitative benchmark for its performance (Section 5). We also evaluate the system in the
context of dynamic time suggestions in the user study outlined in Section 6.
3.1
Study Protocol
To capture contextual scheduling preferences for a given meeting, participants were asked to complete a diary entry
for each meeting they scheduled during a one-week study period. Participants were instructed to first phrase their
initial meeting scheduling request to a pretend chat-based interface (e.g., “I want to schedule a 30 minute 1:1 with my
manager within the next week"), and then enter the needed information into a widely used commercial calendaring
tool that generates time suggestions for a meeting. In response to the suggested times, participants were then asked to
express any preferences up to 5 times (e.g., “I can’t meet before 10am so that I can drop my kids off at work"). They
were also asked to reflect on whether there was information missing from their calendar that could have captured their
stated preference. Finally, participants were also asked to include information about the meeting they were scheduling
including the number of attendees, its duration, and the time horizon in which it was to be scheduled.
We recruited 64 participants through an e-mail advertisement at a large technology company who scheduled their
own meetings (i.e. did not have an administrative assistant) and had at least 2 meetings per week. Participants self-
reported as working in the roles of a manager (39%), program manager (30%), developer (17%), and researcher (9%).
39% of participants reported attending under 20 meetings per week, 37% attended between 20-30, and the remainder
reported over 30 meetings per week. We collected diary entries for 114 unique meetings with averages of 3.95 attendees
and 35 minutes. 58% of the meetings were expected to be fully virtual, 20% hybrid, and 4% fully in-person. In total,
we collected 114 initial phrasing of the scheduling request, 211 contextual preference expressions, and 197 missing
information descriptions. We donated $300 to charity for participation in the study. The study design and protocol were
approved by the leading institution’s Institutional Review Board (IRB).
3.2
Analysis & Findings
We qualitatively analyzed all preference and missing information entries [16]. Researchers conducted open-coding of
30% of the entries. Initial codes were iterated and grouped into coarser categories of preferences and missing information
to develop a codebook which was subsequently used to conduct closed-coding of the remainder of the data. While our
survey asked users to express preferences in response to suggested times, we also observed users requesting additional
actions such as querying calendar data (e.g., “Are [external participants] available during this time?"), drafting an
agenda (e.g., “Draft the agenda based on AIs from previous meeting with the person"), or sending messages (e.g., “send a
message asking to move the meeting earlier rather than later"). We restricted our analysis to focus only on preferences,
as opposed to these auxiliary actions. We also labeled each of the initial phrasings of the scheduling requests for the
presence of the duration of the meeting, the attendees, and the expected time frame. We then reviewed the labeled and
coded entries to highlight four key takeaways from our analysis.

“I Want It That Way”: Enabling Interactive Decision Support Using Large Language Models and Constraint
Programming
7
0
10
20
30
40
50
Percentage of Responses (%)
Temporal
Existing Calendar
External Information
Relational
Attendance
Duration
Facility
(a) Contextual Preferences
0
5
10
15
20
Percentage of Responses (%)
Attendee Calendar
Personal Preference
Attendee Preference
Personal Commitment
Meeting Context
Timezone
Other
(b) Missing Information
Fig. 2. Breakdown of the percentage of diary study responses for (a) categories of contextual scheduling preferences and constraints,
and (b) information missing from the calendar tool that inform the preference or constraint.
3.2.1
Scheduling preferences are diverse. In our analysis of the stated preferences, we identified 7 key types of contextual
preferences for scheduling a meeting:
• Temporal: Preferences for the time of day or day a week a meeting is scheduled (e.g., “I prefer Tuesday or
Wed next week because we need a day of prep (P9)”).
• Existing Calendar: Preferences related to how to handle existing items on a user’s calendar (e.g., “It’s ok to
propose times during the learning day all day event (P138)” .
• External Information: Preferences related to events external of the user’s work calendar (e.g., “I need to
meet before I pick my child up (P52)”).
• Relational: Preferences for how the new meeting is scheduled in relation to existing items on the calendar
(e.g., “I need at least a 5 minute gap between meetings for a break (P1)”).
• Attendance: Preference over the relative importance of different attendees availability for the meeting (e.g.,
“Both [co-worker 1] and [co-worker 2] are required to be available at this meeting (P27)”).
• Duration: Preferences related to the duration of the meeting (e.g., “I need this working session to be 1 hour
long (P40)”).
• Facility: Preferences related to physical meeting space required for the meeting (e.g., “I need a meeting room
in my building that is free and can accommodate all in-person attendees (P70)”).
Figure 2a shows a breakdown of the expressed preferences categorized along these types. We found that a majority
(54%) of the elicited preferences are temporal, highlighting that providing a way to adjust suggested times to simple time
and day requests could satisfy a large fraction of users’ unmet scheduling preferences. However, even within temporal
preferences, participants exhibited a wide range of preferences in terms of both preferred meeting time and how the
preferences were phrased. This underscores the limitations of graphical interfaces: the wide scope of user preferences
makes it difficult to fully capture all possible preferences within a form or pre-fixed set of options. Preference elicitation
systems need to be able to flexibly capture diverse user preferences via mediums such as natural language in chat.
3.2.2
Scheduling requests are vague. When scheduling a meeting, many existing time suggestion features require a list
of attendees, a duration, and a time frame (e.g., the next two weeks). However, we found that the initial scheduling
requests in our data did not include the duration of the meeting 57% of the time, the expected time frame 28% of the

8
Lawless et al.
time, and even the attendees of the meeting 4% of the time. This highlights a key challenge in performing scheduling
via chat. Chat-based scheduling tools need to elicit key pieces of information from the user before generating an initial
time suggestion or provide a means for users to validate assumptions generated by the system (e.g., default durations
for meetings).
3.2.3
Calendars are incomplete. A key finding of the diary study is that users’ calendars rarely reflect the complexities
of their true scheduling preferences and considerations. In our analysis of missing information entries, we identified 6
types of missing information:
• Attendee Calendar: Information on attendees’ availability including both existing events and their relative
importance (e.g., “Whether the meetings on their calendar are actual meetings or self-imposed work blocks
(P122)”).
• Personal Preference: Information on user’s personal scheduling preferences (e.g., “My personal preference is
that meeting align into up to 2 hour blocks, not be spread throughout the day breaking up the rest of my focus
time. this is implicit knowledge about my preferences (P38)”).
• Attendee Preference: Inferred preferences about the attendees of the meeting (e.g., “Coworker’s working
hours shown in her calendar does not accurately reflect the actual working hours (P34)”).
• Personal Commitment: Scheduled events or obligations that were missing from the user’s work calendar
(e.g., “I was planning to be oof but didn’t make it in the calendar (P70)”).
• Meeting Context: Details about the meeting to be scheduled that inform how the meeting should be scheduled
(e.g., “I have a 1:1 with one of the attendees at 2 so i’d like to have the meeting earlier so we can focus on other
topics at the 1:1 (P86)”).
• Timezone: Information about the timezone of various participants and what an appropriate meeting time is
for their working hours (e.g., “My colleague is on the east coast (P66)”).
Figure 2b shows a breakdown of the missing information expressed during the diary study along these axes. While
an ideal calendar system may be able to internalize some of this missing information (i.e. by asking users to input all
their personal commitments), the scope and diversity of the missing information makes capturing it all in existing
systems near impossible. This highlights the importance of a flexible interface through which users can inform the
scheduling system of context and information missing from a user’s calendar.
3.2.4
Users value temporal diversity. Our analysis of the preference expressions also revealed that participants desire
multiple diverse time suggestions to help speed up the scheduling process. For instance, P3 mentioned that suggestions
that are “back to back on the same day is not helpful.” P99 wanted “time slots for 3 days” to “make scheduling much
faster.” Notably in these responses, participants characterized diversity with respect to the time and day of the meeting,
underscoring the importance of temporal diversity in meeting time suggestions.
4
PREFERENCE INCORPORATION: MEETMATE SYSTEM
We now introduce a novel framework for performing preference incorporation in the context of meeting scheduling.
Given the diversity of user preferences discovered in the diary study, such a system needs to be able to flexibly incorporate
a wide range of preferences. Furthermore, prior work in preference elicitation has highlighted the importance of such a
system being both contextual and interactive.

“I Want It That Way”: Enabling Interactive Decision Support Using Large Language Models and Constraint
Programming
9
Towards a flexible, contextual, and interactive decision support system, we introduce MeetMate, a chat-based meeting
scheduling tool built in Python that allows users to interactively refine meeting time suggestions via natural language
requests. A key component of our approach is an underlying constraint programming optimization model to generate
new time suggestions (detailed in Section 4.3), which performs the complex mathematical reasoning required to find
suitable times. We model each scheduling preference as a function, called a constraint, that checks whether a candidate
meeting time meets the preference (i.e., “Not scheduled before 2pm"). Each constraint also has an associated weight.
Intuitively, higher weights correspond to constraints that are more important. Instead of requiring users to specify an
exact numerical weight for each preference, the system instead keeps an underlying prioritized list of the constraints
which are then translated into weights such that constraints with higher priority are always satisfied before those
of lower priority. Each constraint is formalized as a Python function that is used by a solver to generate new time
suggestions. To embed natural language scheduling preferences into Python functions, we leverage LLMs to translate
user chat messages to operations on the weighted list of scheduling constraints. This hybrid framework capitalizes
on the benefits of both LLMs and Optimization, using LLMs to flexibly embed naturalistic scheduling constraints
into Python functions and using optimization to generate new time suggestions that are responsive to the embedded
preferences. This occurs within an interactive chat environment which allows the system to be both contextualized to a
given scheduling instance and interactive.
When a user goes to schedule a meeting, they must first enter the list of attendees, the duration, and the time horizon
for the meeting into a form. Using a form ensures that users include the minimum viable amount of information to
schedule a meeting, and alleviates the vague scheduling behavior we discovered during the diary study. Once a user
enters the information, the system generates an initial time suggestion that maximizes the availability of the desired
attendees. The system returns the time suggestion and initiates a chat so that users can interact with the system to refine
the suggested meeting time. For every new chat message entered in the chat, the Constraint Management Component
(Section 4.1) translates the request into an action for the system to take. One such action is the addition of a new
constraint (see Section 4.2), which requires translating a natural language preference into a Python function. These
Python functions are then used within a constraint programming solver (Section 4.3) to generate new time suggestions.
An overview of the system is included in Figure 5.
4.1
Constraint Management
When a user enters a new chat message, an LLM-powered Constraint Management component is prompted (see Figure
4) to select one of five actions to take:
• Add Constraint: This action generates a new scheduling constraint and calls the constraint generation
functionality outlined in Section 4.2.
• Change Priority: Change the priority of a specified constraint.
• Delete Constraint: Removes a given scheduling constraint.
• Message User: Sends a message back to the user.
• Generate Suggestion: Calls the CP solver to generate a new time suggestion (detailed in Section 4.3), and
returns it to the user.
Notably, the constraint management component is given as input the entire chat history between the user and
the agent, and the current list of scheduling constraints. This allows the actions to be informed by not only the most
recent chat message but the context in which the message is taking place. For instance, if a user tries out a scheduling

10
Lawless et al.
Fig. 3. Overview of MeetMate system architecture. Chat messages from users are translated into actions by the Constraint Manager
Component (A), which selects from 5 actions including the Add Constraint Action (B) which translates natural language scheduling
preferences into python functions. The system maintains an ordered list of scheduling constraints with priorities (C) that are used by
the Constraint Programming Solver (D) to generate new time suggestions.
constraint (e.g., “How about meeting on thursday?") and decides against it (e.g., “Ah nevermind") the system is able to
remove the correct scheduling constraint without additional follow-up questions.
Fig. 4. Sample prompt for the constraint management component. Orange highlight reflects scheduling instance-specific inputs.
Green highlights the output of the LLM.

“I Want It That Way”: Enabling Interactive Decision Support Using Large Language Models and Constraint
Programming
11
4.2
Constraint Generation
When the system decides to add a new scheduling constraint, the system calls two LLM-powered components. The first,
dubbed Information Checker, checks whether the given scheduling constraint can be handled by the system. Given the
diversity of user scheduling preferences and the wide range of external information needed to integrate them, it is
unlikely that any system will be able to handle all scheduling constraints. The Information Checker acts as a safeguard
to check whether the system has sufficient information to be able to handle the constraint. If it cannot, it identifies
missing information that can either be queried from the user or states why the given constraint cannot be handled by
the system. If the system can handle the constraint, it is then given to a Coder module that translates the scheduling
constraint into Python code that can be used to check whether a candidate meeting time meets the constraint. Figure 6
shows a sample prompt for generating a new scheduling constraint.
Fig. 5. Sample prompt for the constraint generation coder component. Orange highlight reflects scheduling instance-specific inputs.
Green highlights the output of the LLM.
4.3
Constraint Programming Solver
Given a list of scheduling constraints and their associated priorities, the Meeting Scheduling Problem aims to find a
candidate meeting time with the highest score, defined as the weighted sum of the constraints satisfied. We now briefly
formally define the associated constraint programming problem, and show that the problem can be solved efficiently. Let
T be the set of candidate times or a meeting. For instance, for a one-hour meeting on Tuesday, we may list all one-hour
blocks starting on the hour or half-hour between 8am and 6pm (i.e. T = {8-9am, 8:30-9:30am, 9-10am, . . . , 5-6pm}). Let
𝑓: T →{0, 1} be a scheduling constraint that maps a candidate time 𝑡∈T to a boolean value representing whether or
not the time satisfies it. As outlined in Section 4.2 these constraints are represented by Python functions as generated
by a LLM. As input to the Meeting Scheduling Problem, we have a set of candidate times T, 𝑛scheduling constraints
F = {𝑓1, . . . , 𝑓𝑛} each with associated weight (or priority) 𝑤1, . . . ,𝑤𝑛. Formally, the goal of the Meeting Scheduling

12
Lawless et al.
Problem is to solve the optimization problem:
𝑡∗= argmax𝑡∈T
∑︁
𝑓𝑖∈F
𝑤𝑖𝑓𝑖(𝑡)
Luckily, for practical meeting scheduling instances, the size of the candidate time set T is small enough that we can
use a brute-force approach to score all candidate times and return the best. For reference, a meeting scheduling instance
with 100,000 candidate times and 10,000 scheduling constraints can be solved on a single thread in under 10 seconds.
This allows us to avoid the need of a formal constraint programming solver such as Google OR-Tools. Integrating such
a solver for more complicated or computationally demanding optimization problems is a promising direction for future
work.
In response to feedback from the diary study, the MeetMate system was also designed to return diverse time
suggestions. Instead of returning only a single-time suggestion with the best weighted score, we return a set of 𝑘diverse
times. We define diversity as the sum of the pairwise distance between each time in the returned set {𝑡1, . . . ,𝑡𝑘}:
𝑘−1
∑︁
𝑖=1
𝑘
∑︁
𝑗=𝑖+1
𝑑(𝑡𝑖,𝑡𝑗)
where 𝑑(𝑡1,𝑡2) is a distance function between two suggested times. Motivated by the results of the diary study which
highlighted the importance of temporal diversity, we define the distance between two candidate times as the logarithm
of their difference in minutes plus one. Finding diverse subsets is known to be a computationally demanding problem
[2]. To construct diverse time suggestions we employ a simple greedy algorithm that we found works well in practice.
We start by filtering the candidate times to only times within 𝜖of the best score. We select 𝜖to be the smallest value
such that there are at least 𝑘times that meet the criteria. After filtering the times, we greedily construct the set by first
selecting the earliest high-scoring time and iteratively adding a new time to the set that maximizes the diversity of the
current set.
To help provide transparency over the suggested meeting times, we return each meeting time with a one-sentence
summary of its pros and cons. To generate this summary, we give an LLM the list of scheduling preferences met
and unmet by each suggested time and prompt it to generate a one-sentence summary. For instance here is a sample
explanation for a time that met two user preferences but failed to include one attendee: This time is before 11am
on Tuesday, but Anton cannot attend. While LLMs are known to hallucinate and generate text not supported by the
inputs [13], we found that summarizing small lists of preferences rarely led to hallucinations.
4.4
System Limitations
This system was designed as a prototype to test the viability of our hybrid LLM and constraint programming framework,
not as a full calendar scheduling system. As such, we include only the minimum viable amount of functionality to
test the interactive component between the user and the system and exclude any additional functionality that may be
present in other calendar tools. When scheduling a meeting, our system requires the meeting characteristics to be input
in a form as opposed to a naturalistic chat. These characteristics are fixed for the remainder of the interaction (i.e., the
user cannot dynamically change the attendees or length of the meeting during chat). The system only supports meetings
that begin at increments of 15 minutes (i.e., on the hour, and fifteen-minute increments thereafter). The system is also
limited in what it can communicate to users. Specifically, it can communicate suggested meeting times, explanations

“I Want It That Way”: Enabling Interactive Decision Support Using Large Language Models and Constraint
Programming
13
Fig. 6. Processing pipeline for preferences from the diary study.
of those times, and some limited follow-up questions. The system can not interface with external tools or APIs (e.g.,
sending e-mails to participants, querying weather data, or accessing conference room availability).
5
QUANTITATIVE EVALUATION OF PREFERENCE INCORPORATION
To gauge the feasibility of the MeetMate hybrid LLM and CP approach for preference incorporation we provide a
comprehensive numerical evaluation of two key system components: the information checker, and the coder.
5.1
Datasets
To quantitatively evaluate the system components we create a novel evaluation benchmark that leverages both a
synthetic calendar universe and real scheduling preferences captured during the diary study. The synthetic calendar
universe is used to create sample meeting scheduling scenarios without the use of users’ personally identifiable private
calendar data. To generate the calendar universe we use GPT4 [52] to create a synthetic organization with 32 employees
spread over 4 distinct teams. We also use the LLM to generate a suite of existing meetings between the employees to
populate their calendars. The number of meetings for each employee were commensurate with their position with
managers having a higher meeting load, and calibrated to be in line with the self-reported number of attended meetings
in the diary study. We also generate a dataset of 75 new meeting instances that represent meetings that need to be
scheduled.
To generate a dataset of scheduling preferences we process the results of the diary study. We first extracted all
scheduling preferences and constraints elicited during the diary study and removed any inadvertantly shared personally
identifiable information (PII). To help generalize the preferences elicited during the diary study we also remove any
specific times, days of the week, or meeting specific information (i.e. attendees, project title) and replace them with
special placeholders. These placeholders are later in-filled by either sampling the inputs from a uniform distribution
over potential inputs (i.e., randomnly sample one of the five different workdays) or entering the relevant meeting
characteristic (i.e., inputting the name of the organizer for the meeting instance). For every original preference from the
diary study, we generate 3 new preferences by in-filling the placeholder values for new meeting scheduling instances.
Figure 6 shows a sample processing pipeline for a final scheduling preference.

14
Lawless et al.
Table 1. Comparison of LLM performance on information checking and code generation components on datasets generated from the
results of the diary study. All numbers are reported as percentages.
Correctness (General)
Correctness (Example)
LLM
Rephraser
Safeguard Accuracy
Compilation
Precision
Recall
Precision
Recall
GPT-3
Y
81.8%
95.3%
95.5%
92.6%
94.4%
92.4%
N
77.9%
90.7%
94.6%
86.0%
93.8%
87.2%
GPT-4
Y
79.8%
97.2%
95.8%
94.0%
94.7%
93.8%
N
72.7%
93.4%
95.2%
89.6%
94.2%
90.3%
We categorize all the processed preferences from the diary study into two categories: requests that can be handled
given the limitations of the synthetic calendar universe and those that cannot. For instance, since the synthetic universe
does not have any facility information, any preference related to the availability of conference rooms is marked as not
handled. These categories form the basis of a binary classification dataset, which we call the Safeguard Dataset, through
which we evaluate the information checker component of the system. We also take the subset of the dataset that can be
handled by the current system and use it to form a dataset, called the Code Generation Dataset, for the coder component.
5.2
Information Checker
We use the Safeguard dataset to benchmark the performance of current LLMs for the Information Checker component of
the MeetMate system. We evaluate two different LLMs: GPT-3 (text-davinci-003) [11] and GPT-4 [52]. We also evaluate
two different phrasing strategies. During initial experiments we noticed that the LLMs struggled to extract correct
scheduling preferences when given long sentences with rationale. We add a LLM-powered rephraser component that,
given the initial scheduling preference, is asked to rephrase it as a succinct scheduling constraint. We note that this is
not necessary in the full implementation of the MeetMate system as the constraint manager component rephrases the
chat message into scheduling constraints. We report the classification accuracy of the models and phrasing strategies
on the reference dataset, defined as the fraction of the instances the model correctly predicts can and cannot be handled
by the current system.
Table 1 (Safeguard Accuracy column) summarizes the accuracy for the two different models and prompting strategies.
Both models have around 80% accuracy for the information checking task when using the rephraser. The rephraser does
indeed lead to a small increase in performance for both models, highlighting the importance of translating complex user
queries into clear requests before generating code. Interestingly, GPT-3 slightly outperforms GPT-4. We hypothesize
that this discrepancy is due to GPT-4 over-estimating its ability to handle constraint requests.
5.3
Code Generation
To evaluate the coder component of the MeetMate system we compare the LLM generated code to ground-truth correct
implementations of each function generated by human software developers. The correct implementations follow a
similar processing strategy as the original dataset. An implementation is generated only for each processed preference
with placeholders from the diary study, and the placeholders are in-filled for the specific meeting context or sampled
values. We evaluate three different metrics for the code generation component:
• Compilation: The fraction of functions generated by each component that can successfully be imported by a
python interpreter.

“I Want It That Way”: Enabling Interactive Decision Support Using Large Language Models and Constraint
Programming
15
• Correctness - Precision: Of the code that runs successfully, what fraction of the candidate times marked as
satisfying the given preference do in fact meet the preference.
• Correctness - Recall: Of the code that runs successfully, what fraction of the candidate times that should be
marked as satisfying the given preference are marked as such by the code.
To compute the precision and recall of the generated code, we first generate two sets of candidate times for each
preference in the code generation dataset. The first set, which we call the general dataset, includes every meeting time
of the correct duration over the next 50 days. The second, which we call the example dataset, restricts the candidate
times to only times with the correct duration over the time horizon of the synthetic meeting scheduling example which
varied from 2 to 14 days depending on the example. We evaluate both sets to account for instances where an error in
the code generation component may not appear over a small time horizon. Table 1 (right side) reports the performance
of both models and prompting strategies over the five metrics. Both LLMs are able to generate code that compiles
correctly over 95% of the time and have high precision and recall (over 90%). This showcases the viability of using LLMs
to generate correct python representations of user scheduling preferences.
6
USER STUDY
To evaluate the feasibility of MeetMate we conducted a user study with 10 participants who used the MeetMate user
interface to schedule meetings as a member of a fictitious organization. In this user study, we evalute the MeetMate system
not as a finished product but as a probe [9] to observe the interactive preference elicitation process in real-world
scheduling scenarios and to uncover design implications and unforeseen challenges for further improving the system
design. Our study tasks are, therefore, intentionally designed to push the limits of the current system design.
6.1
MeetMate UI
We prototyped a UI for MeetMate to allow users to interact with the underlying system. The main goal of the prototype
is to provide a minimal set of capabilities that lets us exercise the underlying system components rather than to provide
a full set of functionalities of a typical calendar. The UI consists of a calendar component on the left (Figure 7A) and a
chatbot component on the right (Figure 7B). The calendar component resembles a typical calendar client and displays
the current user’s weekly schedule. The chatbot component allows for naturalistic conversations with the system with
a chat history and a message box.
The prototype UI was designed to support only allowable interactions with the underlying components. As such, the
user started the interaction by first specifying a list of attendees and the duration of the desired meeting (Figure 7C),
and the system responded with an initial suggestion with a short explanation (Figure 7E). All meetings were set to be
scheduled in a default time horizon of one week. If the suggested time is satisfactory, the user can schedule the meeting
by clicking on the “Schedule” button. If the suggested time is unsatisfactory, the user can freely interact with the system
through the message box (Figure 7E). Each time a user sends a message, the system responds with a suggested time
and/or a message, in which case the user either accepts the suggestion or iterates by interacting with the system. The
system could be configured to return multiple suggestions at a time (Figure 7F).
6.2
Study Design
Each consented participant attended a 1-hour user study session conducted remotely via a video conferencing tool,
and the sessions were video-recorded and transcribed for analysis. During the study, participants were asked to use

16
Lawless et al.
A
B
C
D
E
F
Fig. 7. MeetMate user interface consists of the calendar component on the left (A) and the chatbot component on the right (B). Users
enter meeting scheduling details into a form (C). Upon submission, the system generates an initial time suggestion (D), which users
can refine via naturalistic chat (E). The system can also be configured to return multiple diverse time suggestions (F).
MeetMate UI to schedule meetings for a fictitious healthcare software start-up while assuming various personas
with different preferences and constraints for meetings. In total, we recruited 10 people on a first-come-first-serve
basis from a sample that participated in our diary study and agreed to be contacted for future studies. Participants
self-reported as working in the roles of a product manager (40%), manager (20%), developer (10%), and researcher (10%).
60% of participants reported attending 10-19 meetings per week, with the remaining 40% attending over 20 meetings.
Each participant was compensated with a $50 gift card. The study design and protocol were approved by the leading
institution’s Institutional Review Board (IRB).
Each study session consisted of four scheduling tasks crafted to challenge the system’s capabilities. The tasks and the
calendars that participants interacted with were set up either to make it difficult for the system to satisfy all preferences
or to allow users to engage with the system in unanticipated ways that would potentially break the system. The first
task involved a 40-minute meeting with three other attendees with preferences for it being after 11am, a 30-minute
break before the meeting, and allowing for a meeting over lunch, which were preferences that MeetMate was designed
to support. The task was designed to also test the Information Checker by adding a preference for a sunny day, which
the system was not designed to support. The second task involved scheduling an urgent, next-day, 60-minute meeting
with two required attendees and two optional attendees, including the organizer. The third task involved scheduling a
60-minute meeting with three other attendees, and the participant was allowed to bring in any meeting preferences
or constraints they wanted to exercise to evaluate the system. The fourth task was identical to the third task, except
that the first three tasks returned one suggestion at a time and the fourth task returned three suggestions at a time.

“I Want It That Way”: Enabling Interactive Decision Support Using Large Language Models and Constraint
Programming
17
The third task was optional if there was not enough time to complete all four tasks within one hour. Each task was
considered done when the participant found a satisfactory meeting time or when they expressed that they could not
complete the task. With the exception of the first task, all tasks were designed to be challenging to complete with the
current system to help expose new challenges within the interactive decision support framework. Participants were
not taught about the limitations of the systems and what scenarios were not supported (e.g., calendar question and
answering, dynamically changing meeting time). This was to gauge the types of features participants expected in a
dynamic setting and to evaluate how well participants could recover from shortcomings in the system.
Throughout the study, participants were asked to verbalize their thoughts (i.e., think-aloud protocol). During the
tasks, the facilitators asked follow-up questions probing the participants’ comments or behaviors. After each task, we
asked participants about their ability to find a suitable meeting time, the ease of expressing preferences, the ease of
using the system to schedule a meeting, and their understanding of the limits of the system’s abilities. We also asked
them for overall feedback about their scheduling experience, a comparison between their current scheduling practice
and using MeetMate, and any feedback about the number of suggestions provided.
6.3
Analysis
We reviewed the qualitative texts using reflexive thematic analysis [10]. The recordings and transcripts were uploaded
to Marvin1, and each recorded session was open-coded by three researchers who either facilitated or attended that
session on a line-by-line basis, and the codes were iterated and grouped into higher-level themes. Throughout and after
coding, researchers met to resolve disagreements and iteratively reach a consensus on the overarching themes.
6.4
Findings
Throughout our study, we observed the iterative preference elicitation process, between the user and the system,
to arrive at a desired scheduling outcome: participants constructed their preferences based on system output (i.e.,
preference construction), and the system incorporated them into newly generated suggestions for participants to
re-evaluate (i.e., preference incorporation). When our participants verbalized their reasoning, we were able to peek into
the mental steps that occurred during these iterations.
Overall, users found the interactive decision support system easy to use and responsive to their preferences. Specifi-
cally, users highlighted the ease at which they could communicate their preferences to the system: “The natural language
input was easy to use. Right. I don’t have to learn syntax or much of anything (P6)”, “I would schedule this way. I’m
real partial to chatting, so I’m very used to it (P4)”. Users also remarked how flexible the agent was in responding
to their preferences: “When I picked only the first names it was able to understand and that’s a great thing (P9)", “It
totally understood what I meant, so the suggestions it gave me actually works. (P10)”, “I liked that it was able to meet
preferences (P5)". Multiple users expressed wanting to use the current system further (P1, P4, P8).
Our findings also underscored the importance of an interactive and contextualized system for decision support.
Participants noted that some scheduling preferences were only revealed within the iterative process of scheduling the
meeting. For instance, throughout their interview P7 asserted that they prefer scheduling meetings at the first available
time for all required attendees. However, at the end of the interview, they revealed that they “subconsciously prioritize”
to avoid booking out their entire calendar, e.g. “I don’t really want to do; they’re only available at 5PM. Yeah, I got in at
seven. I’m not doing a 5:30PM meeting (P7).” We saw that this fluid and subliminal nature of preferences was a large
1https://heymarvin.com/

18
Lawless et al.
reason why several participants (P1, P2, P3, P6, P7, P8, P10) preferred receiving multiple suggestions. P6 elaborated on
the benefit of having options to help refine preferences: “Maybe none of them are perfect, but maybe they’re close.
Is there a compromise?” Participants also reevaluated preferences based on contextual information in the scheduling
tasks. For instance, P10 expressed a preference for a 15 minute break before the meeting if they’ve been in back-to-back
meetings for at least 2 hours. When asked if this is how they typically handle breaks, they described scenarios where
they would relax this constraint, including “if it’s just 2 hours and then after that I’m completely free” or “if one of
those 2 hour meetings is one where I’m just listening in.”
During the preference construction process, we observed two mental steps that helped participants interact with the
system – evaluation and expression. When presented with scheduling suggestions, we saw that participants (1) evaluated
the system suggestions to see if their preferences were incorporated and if they matched their desired outcome. In this
step, they first tried to interpret the system suggestions, explanations, and messages, by formulating mental models of
how the system presents information. Then, they decided whether they were satisfied with the suggestions, or they
realized a different constraint and proceeded to construct new preferences. Afterward, participants (2) expressed their
newly constructed preferences. In formulating their preferences as written expressions, they ideated how the system
might interpret these preferences. Based on their mental model of how the system operates, participants adjusted their
expression of preferences. While exercising these mental steps, participants suggested opportunities to make iteration
with the system easier. In this section, we focus our discussion on these two mental steps that support the preference
construction process: suggestion evaluation (i.e., how people evaluated the suggestions) and preference expression (i.e.,
how people expressed their preferences). Subsequently, we present additional considerations for improving the system
design.
6.4.1
Suggestion Evaluation. We observed that understanding the system and its capabilities is necessary to evaluate the
quality and appropriateness of the suggestion. Because the MeetMate UI was limited in its ability to respond (i.e., only
with suggestions, short explanations, and occasional messages), understanding the system capabilities required some
trial and error: “This seems to be with four or five questions I could understand what is it trying to do in the background
(P8).” When participants were unsure about the system, they made incorrect assumptions about the underlying logic
or second-guessed themselves. For example, when the system generated an inaccurate code for an “within 24-hour”
constraint by inverting the inequality sign, P4 assumed a different explanation for the system’s behavior: “So it’s not
really looking at the moment in time of where we are and then backing from the 24 hours to find that window right. Is
how it appears to me.” Participants were at times confused about which preferences were satisfied, especially when
the system provided the same suggestion: “I said I must attend and it still gave me the same suggestions. So it didn’t
remember my initial question or something? (P7)” Without an adequate understanding of the system, when suggestions
did not align with their expectations or were perceived as incorrect, participants gave up their scheduling tasks (P7),
did not have trust in the system (P2), and would not use the system (P10).
How the system presented its explanations affected participants’ understanding of system suggestions and which
preferences were met. Some participants found that the explanations helped them troubleshoot their preferences: “It
was upfront when it couldn’t do something. Right. We asked about to take into consideration weather, and it told me
right off, I don’t have that (P6)”. However, P2 reported that text-based explanations made it difficult to comprehend
the suggestion compared to when it is visually positioned in the calendar. Several participants (P4, P7, P10) simply
missed reading the explanations. To help with understanding their own preferences, some participants (P6, P7, P8)
wanted the system to explicitly specify why some preferences were satisfied or not, and the lack of such adequate

“I Want It That Way”: Enabling Interactive Decision Support Using Large Language Models and Constraint
Programming
19
explanations was sometimes a reason for participants to engage in trial and error. For example, P6 mentioned that “it’s
not really telling me why it won’t put on the 6th” and proceeded to investigate the reasoning by interacting with the
bot. Receiving the same suggestion without adequate adjustments to the explanation was especially frustrating to some
participants (P3, P5, P6, P7). Explaining the suggestion’s impact on attendance was a high priority for some participants
(P2, P6): “if I have to schedule with ten people, it’s just helpful to understand who cannot attend. (P2)” Instead of an
explanation, P5 suggested the system should ask if the unmet constraint could be relaxed: “if it couldn’t find it on that
date, maybe it should have asked, if I’m flexible on the time.” In general, understanding the why behind suggestions
helped participants focus their attention on making adjustments to their preferences.
Being presented with multiple suggestions was a popular feature among participants: “It’s in some way more efficient.
You’re given multiple at once. It saves me a little time right. (P6)”). However, some participants weighed the cost of
iterating with the system (e.g., “if you always have to dive into specifics (P3)”) as a potential barrier to using the system.
Several participants made suggestions for how the system could present its suggestions and explanations in a way
that helped them understand the system, reason about the preferences, and arrive at their decisions quickly. Many
participants (P2, P3, P6, P7, P8) suggested a simple explanation when important preferences were not satisfied or
different suggestions could not be found (e.g., “Sorry, this is your only option (P7)”). Some participants suggested the
system provide diverging or alternate paths as a way to iterate on their preferences quickly. For example, P3 suggested
making most interactions decision-making oriented, such as juxtaposing different suggestions that satisfy a subset
of preferences would help them weigh different options and reduce the number of iterations: “Because that answers
two questions rather than me having to prompt the second question.” P7 suggested diverging options that prioritized
certain preferences over others. Furthermore, in explaining diverging options, participants suggested explanations that
describe candidate meeting times in relation to each other as well as how their preferences were met (e.g., “if you want
it sooner, this is your option (P7).”) or to highlight differences (e.g., “In which dimensions are they different to make you
choose about, okay, this one is better than this one, or this one is closer to what I’m looking for than that one (P1).”).
Participants also suggested visualizing the suggestions in a different way to optimize decision-making. For example,
P1 wanted a better visual connection between individual suggestions, and P4 preferred “swim lanes” of attendees’
availabilities to see the suggestions in context.
In general, participants wanted the system to present suggestions and explanations in a way that would give them
more control and agency. P2 expressed that the current suggestion-based responses from the system made them feel
like “it’s dictating terms and it’s not flexible enough for me.” The MeetMate system did not support changing the
meeting duration after the initial configuration. When the system suggested restarting the scheduling session due to
this limitation, P4 explained that “That will be a hard stop for a lot of people” because they would not know how to
proceed. Instead, P4 suggested helping people “restate [their] desire” to regain control. Instead of exercising control, P4
found themselves “accommodating” to system limitations.
6.4.2
Preference Expression. Many participants enjoyed the flexibility to express their preferences in natural language:
“I think it definitely allows for more free form. Right. I think it allows a lot more flexibility with being able to just chat
with the bot over being locked into a specific clickable response (P6)”. Preference expression occurred in two phases:
(1) at the start of interacting with the system and (2) in response to a system’s suggestion, explanation, or message.
During the initial setup and communication with the bot, participants suggested other interaction modalities beyond
chat-based text. Some participants (P3, P5, P7, P10) thought the “back-and-forth” nature of chat could be inefficient,
especially when the system’s understanding did not align with their own. For example, P5 expressed discontent over

20
Lawless et al.
needing to rewrite the same preference in four different ways. To circumvent these issues, people suggested the use of
a form to capture non-negotiable information upfront, including meeting location (P3, P5, P9), required versus optional
attendees (P3, P5, P7, P8, P9), and working hours (P2, P4, P5, P6, P10). Additionally, P1 stated that “using words to
express constraints can get tiring,” and P7 suggested incorporating audio for blind people.
When responding to the system’s suggestion, participants sometimes struggled to formulate preferences, because
they lacked insight into how the system embedded preferences and generated suggestions. P1 explicated the importance
of establishing a common language with the system and the friction experienced “because I don’t see a lot about what
the system understood and how they interpret things.” Sometimes this confusion was complicated by the limitations
of LLMs: P8 acknowledged that longer text can be hard for the system to process—“even when I read it, it takes me a
second to really understand what I typed.” Additionally, participants could not differentiate between when the system
did not understand a preference and when the system lacked the ability to act on a preference, leading participants to
spend time “thinking about how to say what [they] need (P6).” P10 explained, “My first reaction was, ‘I may have asked
it wrong. Maybe if I ask it a different way,’ which is why I asked it a second time slightly differently.” Many people
(P2, P3, P5, P7, P9, P10) suggested that the system should be able to refine previous suggestions instead of providing
entirely new ones. For example, P7 asked the system to “start the meeting at the bottom of the hour,” intending to
adjust the previous suggestion from 2:45PM to 3:00PM, but the bot returned a new suggestion for 11:00AM. However,
within a chat log, correctly attributing which preferences are meant to refine a current suggestion versus generate a
new suggestion is a challenging problem for both LLMs and humans.
In either phase, we noted that participants assumptions and prior experiences could result in a misalignmnet between
the system and user. For example, when P1 requested afternoon options, they had to assert that “afternoons start at
1PM” because the system believed afternoons to be “between 12PM and 3PM.” Participants suggested the system should
have knowledge of common scheduling conventions, such as “the next business day” (P3, P5, P6) or blocking off lunch
(P3, P4). Both P2 and P7 mentioned organizational norms such as implicitly understanding that 30-minute meetings
“start 5 minutes after, and we do it for 25 minutes (P2).” Participants expressed a desire for an intelligent system that
could learn from prior behavior and automate what must be manually encoded today (P2, P3, P6, P7, P10), while giving
users the ability to adjust learned constraints (P3, P6).
6.4.3
Other considerations. Our study uncovered findings that applied beyond the preference elicitation process and
could benefit future system design. We found that simply supporting preference elicitation and scheduling meetings
was not enough and that participants wanted seamless integration of other aspects of meetings to be a part of this
process. For a meeting where the organizer could not attend, P8 suggested support for setting an agenda for others
that can attend the meeting: “since it said I cannot join as part of the schedule itself, it can give me some suggestions
about like add agenda.” P3, who self-described as having many meetings, wanted the system to support setting agendas,
scheduling breakouts, pulling action items from prior meetings, or pulling in relevant documents. Completing the
meeting scheduling experience also included searching for available office or meeting space (P3, P6), incorporating
commute or transition time (P8, P10), and accommodating multiple time zones and business hours (P8). We also found
that, since attendees are a core part of scheduling meetings, participants (P2, P7, P8, P10) sought a feature that allows
searching and resolving attendees as part of the UI.
Leveraging LLMs for incorporating user preferences presented both benefits and challenges. As we already described,
LLMs enabled all of the participants to freely interact with the system to express their preferences and questions.
The system was especially good at handling misspellings that enhanced user experience: “I’m satisfied to verify my

“I Want It That Way”: Enabling Interactive Decision Support Using Large Language Models and Constraint
Programming
21
hypothesis that it’s kind of resilient to me being sloppy while typing. So that’s a neat thought about experience. (P1)”
However, the system also hallucinated or made errors in some components of the system. The system sometimes
generated erroneous Python functions such as the example above where it inverted the inequality sign. In another case,
the system generated an erroneous explanation. For example, for a 10 am meeting suggestion, the system explained
said that the meeting “is not in the morning.” In both of these error cases, the participants were not given enough
information about the underlying system (e.g., generated code, list of constraints) to troubleshoot.
7
DISCUSSION
Eliciting preferences in the context of decision support is a challenging task that requires systems that can help users
construct their preferences in an interactive contextual manner. In this paper we introduced a novel framework for
interactive decision support that leverages LLMs and constraint programming to provide a flexible naturalistic interface.
We studied this framework in the context of meeting scheduling, a complex spatial-temporal decision making process.
To better understand users’ preference construction process during meeting scheduling, we ran a diary study to capture
contextualized scheduling preferences and characterize preference construction in the context of meeting scheduling.
The results revealed the diversity of contextual user scheduling preferences and the need for a flexible interactive
system that can accommodate them.
We used these preferences to design an interactive system for preference incorporation that can refine suggested
meeting times in response to user feedback. The system capitalized on the flexibiliy of LLMs to embed natural language
scheduling preferences into Python functions that could then be leveraged by a CP solver to generate refined time
suggestions. To validate the technical feasibility of this system for preference incorporation we evaluated it on a
quantitative benchmark dataset comprised of results from the diary study. The results showed the viability of this hybrid
framework, with the LLM components being able to generate valid python code with high precision and recall with
respect to the correct underlying scheduling preference. To evaluate the broader interaction between user’s internal
preference construction process and the preference incorporation system we ran a small scale user study. While users
found the system intuitive and lauded its flexibility, the study highlgihted key challenges in the design of interactive
decision support systems. Namely, users found it difficult to use the system without an understanding of the underlying
system and the ability to correct system mistakes. Within the context of meeting scheduling, users also noted that
communication by chat could at times be slow and burdensome and recommended features that could allow them to
get the feedback and preferences of additional attendees. The remainder of this section elaborates on these important
design implications for future interactive decision support systems and discusses limitations of our work.
7.1
Implications for Design
Throughout the user study, participants highlighted expectations, pain points, and suggestions regarding the Meet-
Mate system. We consolidate these suggestions to provide design recommendations and considerations for future
interactive decision support systems.
7.1.1
System Transparency. The MeetMate system offers concise summaries of the pros and cons of suggested meeting
times (e.g., “This time is before 11am on Tuesday, but Anton cannot attend”). Through our user study, we discovered
that additional transparency measures could enhance user comprehension of the system’s operations and, ultimately,
improve decision-making in finding suitable meeting times. This aligns with the concept of explainable AI [1, 5], which
highlights the importance of transparency interventions in enhancing system acceptance, trust, human control, and

22
Lawless et al.
efficiency in working with the system [37]—topics that were addressed during our system evaluation. According to
Lazar [38], the overarching goal of system transparency is “justified understanding,” tailored to the unique goals and
capabilities of stakeholders. This underscores the need to effectively convey relevant information that users seek and
present it in a comprehensible manner. Our user study suggested that incorporating explanations about the system’s
internal workings, including its assumptions and accessible information, could help users grasp how the system
functions and use it more effectively. Such explanations may also assist users in understanding why the system made
specific suggestions, which is particularly vital when the suggestions deviate from user expectations [1].
Building on this, Lebovitz et al. [39] have emphasized the significance of interrogation practices that allow users
to connect their own knowledge with AI predictions. Other research has explored interventions that aid humans in
reasoning about the information available to AI systems [32]. These interventions may be valuable in our system,
enabling users to learn more about what is feasible and what is not as they interact with the system and rely on it
appropriately [40]. Finally, when the MeetMate system presents multiple time suggestions, incorporating contrastive
explanations [46]—explanations that compare different time options—could be a valuable addition. This approach can
help users make more informed choices by highlighting the differences, including pros and cons, between various
suggestions.
7.1.2
Human-in-the-loop Error Recovery. Multiple participants in the user study noted inconsistencies between their
internal preferences and how the system embedded them (e.g., different time ranges for afternoon), however the current
system made it challenging for users to correct implicit assumptions made by the system. This was also validated
numerically in the quantitative evaluation where even the current state-of-the-art LLM, GPT-4, was unable to have
perfect precision, recall, or safeguard accuracy. Given the potential for errors, interactive decision support systems
need intuitive ways for users to diagnose and correct mistakes from the system. This presents a challenging technical
problem within the current framework as understanding the underlying representation of user preferences, Python
functions, presents a high technical barrier for most users. Future work is needed to bridge this technical gap and
provide easy accessible ways to diagnose and correct model errors.
7.1.3
Reducing Elicitation Time. While the system enabled users to express actionable preferences directly to the system,
many users noted the back-and-forth effort of chat to be inefficient and burdensome. Users also voiced frustrations with
the system being unaware of scheduling conventions such as lunch times. To help reduce the amount of negotiation
time between users and the system to find a meeting time, future systems need to be able to incorporate consistent user
preferences and scheduling conventions so that users can focus on fine-tuning suggestions based on new contextual
preferences. For instance, this could involve additional form options to capture non-negotiable meeting characteristics
like working hours and lunch times as suggested by a number of participants. This could also involve leveraging
information about past interactions with the system, including retaining preferences from previous scheduling instances
to warm-start the current list of preferences. However, future work is needed to understand how to best leverage
preferences across sessions as previous work have shown (scheduling) preferences to be highly transient and contextual
[27, 66].
7.1.4
Multi-User Preference Construction. Both the diary study and the user study highlighted the limitations of
approaching meeting scheduling solely from the organizer’s perspective. Participants noted wanting to query attendees
for information such as scheduling preferences, timezone, calendar availability, and feedback on the suggested meeting
time. Future work is needed to extend this framework for interactive decision support to a distributed setting where

“I Want It That Way”: Enabling Interactive Decision Support Using Large Language Models and Constraint
Programming
23
meetings can be scheduled collaboratively between an AI system and multiple attendees. However, such a distributed
system presents a number of technical challenges in terms of how to aggregate and weight preferences across users,
and how to deal with asynchronous communication between multiple attendees. While previous work has studied this
problem in static settings using LLMs [6], future work is needed to adapt these methods to iterative settings such as
meeting scheduling.
7.2
Limitations
While our diary study included participants with a diverse set of roles, they were all employees of the same large
technology company. Future work is needed to see if our findings on contextual scheduling preferences generalize
beyond the technology sector. The study was also conducted during the summer, which may have limited our ability to
capture seasonal variations in scheduling preferences (e.g., those related to the school year or weather). Our user study
utilized synthetic scheduling tasks on fake calendar data. While one task required users to use their own scheduling
preferences, the manufactured nature of the task might have elicited different preferences than a real scheduling task
on the user’s own calendar data. We also highlight the limitations of the scale of the user study. Future work is needed
to do larger scale analysis of the system’s usability with personal contextual scheduling tasks.
8
CONCLUSION
We belive this paper provides a promising first investigation of a new paradigm for interactive decision support, and
highlights a number of important design implications for future systems. Though this paper focused on its application to
meeting scheduling, we believe this framework has broader potential in other interactive decision support applications
such as personalized desk booking, route planning, and supply chain management. Incorporating more sophisticated
optimization tools such as commercial solvers (e.g., gurobi, cplex) is a promising future direction for more complicated
decision making settings. Interactive decision support is an inherently cross-disciplinary challenge that requires
expertise from optimization, human-computer interaction, and machine learning. We encourage others to continue
exploring this challenging and potentially transformative new paradigm for decision support.
REFERENCES
[1] Amina Adadi and Mohammed Berrada. 2018. Peeking inside the black-box: A survey on explainable artificial intelligence (XAI). IEEE Access 6
(2018), 52138–52160.
[2] Rakesh Agrawal, Sreenivas Gollapudi, Alan Halverson, and Samuel Ieong. 2009. Diversifying search results. In Proceedings of the second ACM
international conference on web search and data mining. 5–14.
[3] John A Aloysius, Fred D Davis, Darryl D Wilson, A Ross Taylor, and Jeffrey E Kottemann. 2006. User acceptance of multi-criteria decision support
systems: The impact of preference elicitation techniques. European Journal of Operational Research 169, 1 (2006), 273–285.
[4] Liliana Ardissono, Alexander Felfernig, Gerhard Friedrich, Anna Goy, Dietmar Jannach, Giovanna Petrone, Ralph Schafer, and Markus Zanker. 2003.
A framework for the development of personalized, distributed web-based configuration systems. Ai Magazine 24, 3 (2003), 93–93.
[5] Alejandro Barredo Arrieta, Natalia Díaz-Rodríguez, Javier Del Ser, Adrien Bennetot, Siham Tabik, Alberto Barbado, Salvador García, Sergio Gil-López,
Daniel Molina, Richard Benjamins, et al. 2020. Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward
responsible AI. Information Fusion 58 (2020), 82–115.
[6] Michiel Bakker, Martin Chadwick, Hannah Sheahan, Michael Tessler, Lucy Campbell-Gillingham, Jan Balaguer, Nat McAleese, Amelia Glaese, John
Aslanides, Matt Botvinick, et al. 2022. Fine-tuning language models to find agreement among humans with diverse preferences. Advances in Neural
Information Processing Systems 35 (2022), 38176–38189.
[7] Dimitris Bertsimas and John N Tsitsiklis. 1997. Introduction to linear optimization. Vol. 6. Athena scientific Belmont, MA.
[8] James R Bettman, Mary Frances Luce, and John W Payne. 1998. Constructive consumer choice processes. Journal of consumer research 25, 3 (1998),
187–217.
[9] Kirsten Boehner, Janet Vertesi, Phoebe Sengers, and Paul Dourish. 2007. How HCI interprets the probes. In Proceedings of the SIGCHI conference on
Human factors in computing systems. 1077–1086.

24
Lawless et al.
[10] Virginia Braun, Victoria Clarke, and Nikki Hayfield. 2023. Thematic analysis: A reflexive approach. SAGE Publications.
[11] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877–1901.
[12] Mike Brzozowski, Kendra Carattini, Scott R Klemmer, Patrick Mihelich, Jiang Hu, and Andrew Y Ng. 2006. groupTime: preference based group
scheduling. In Proceedings of the SIGCHI conference on Human Factors in computing systems. 1047–1056.
[13] Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott
Lundberg, et al. 2023. Sparks of artificial general intelligence: Early experiments with GPT-4. arXiv preprint arXiv:2303.12712 (2023).
[14] Giuseppe Carenini and David Poole. 2002. Constructed preferences and value-focused thinking: Implications for ai research on preference elicitation.
In AAAI-02 Workshop on Preferences in AI and CP: symbolic approaches. Citeseer, 1–10.
[15] Giuseppe Carenini, Jocelyin Smith, and David Poole. 2003. Towards more conversational and collaborative recommender systems. In Proceedings of
the 8th International Conference on Intelligent User Interfaces. 12–18.
[16] Kathy Charmaz. 2006. Constructing grounded theory: A practical guide through qualitative analysis. sage.
[17] Hao Chen, Gonzalo E Constante-Flores, and Can Li. 2023. Diagnosing Infeasible Optimization Problems Using Large Language Models. arXiv
preprint arXiv:2308.12923 (2023).
[18] Li Chen and Pearl Pu. 2004. Survey of preference elicitation methods. Technical Report.
[19] Li Chen and Pearl Pu. 2009. Interaction design guidelines on critiquing-based recommender systems. User Modeling and User-Adapted Interaction 19
(2009), 167–206.
[20] Li Chen and Pearl Pu. 2012. Critiquing-based recommenders: Survey and emerging trends. User Modeling and User-Adapted Interaction 22 (2012),
125–150.
[21] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph,
Greg Brockman, et al. 2021. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374 (2021).
[22] Jared R Curhan, Margaret A Neale, and Lee Ross. 2004. Dynamic valuation: Preference changes in the context of face-to-face negotiation. Journal of
Experimental Social Psychology 40, 2 (2004), 142–151.
[23] Parag Pravin Dakle, Serdar Kadıoğlu, Karthik Uppuluri, Regina Politi, Preethi Raghavan, SaiKrishna Rallabandi, and Ravisutha Srinivasamurthy. 2023.
Ner4Opt: Named Entity Recognition for Optimization Modelling from Natural Language. In International Conference on Integration of Constraint
Programming, Artificial Intelligence, and Operations Research. Springer, 299–319.
[24] Victor Dibia. 2023. LIDA: A Tool for Automatic Generation of Grammar-Agnostic Visualizations and Infographics using Large Language Models.
arXiv preprint arXiv:2303.02927 (2023).
[25] Jon Doyle. 2004. Prospects for preferences. Computational Intelligence 20, 2 (2004), 111–136.
[26] Ward Edwards and J. Robert Newman. 1982. Multiattribute Evaluation. Quantitative Applications in the Social Sciences (1982).
[27] Excluded for double-blind review. 2023. Rhythm of Work: Mixed-methods Characterization of Information Workers Scheduling Preferences and
Practices. Under Submission. (2023).
[28] Judy Goldsmith and Ulrich Junker. 2008. Preference handling for artificial intelligence. AI Magazine 29, 4 (2008), 9–9.
[29] Robin Gregory, Sarah Lichtenstein, and Paul Slovic. 1993. Valuing environmental resources: A constructive approach. Journal of Risk and Uncertainty
7, 2 (1993), 177–197.
[30] John S Hammond, Ralph L Keeney, and Howard Raiffa. 2015. Smart choices: A practical guide to making better decisions. Harvard Business Review
Press.
[31] Thomas Haynes, Sandip Sen, Neeraj Arora, and Rajani Nadella. 1997. An automated meeting scheduling system that utilizes user preferences. In
Proceedings of the First International Conference on Autonomous Agents. 308–315.
[32] Kenneth Holstein, Maria De-Arteaga, Lakshmi Tumati, and Yanghuidi Cheng. 2023. Toward supporting perceptual complementarity in human-AI
collaboration via reflection on unobservables. Proceedings of the ACM on Human-Computer Interaction 7, CSCW1 (2023), 1–20.
[33] Irving L Janis and Leon Mann. 1977. Decision making: A psychological analysis of conflict, choice, and commitment. Free press.
[34] Dietmar Jannach, Ahtsham Manzoor, Wanling Cai, and Li Chen. 2021. A survey on conversational recommender systems. ACM Computing Surveys
(CSUR) 54, 5 (2021), 1–36.
[35] Eric J Johnson, Mary Steffel, and Daniel G Goldstein. 2005. Making better decisions: from measuring to constructing preferences. Health Psychology
24, 4S (2005), S17.
[36] Ralph L Keeney and Howard Raiffa. 1993. Decisions with multiple objectives: Preferences and value trade-offs. Cambridge University Press.
[37] Markus Langer, Daniel Oster, Timo Speith, Holger Hermanns, Lena Kästner, Eva Schmidt, Andreas Sesing, and Kevin Baum. 2021. What do we want
from Explainable Artificial Intelligence (XAI)?–A stakeholder perspective on XAI and a conceptual model guiding interdisciplinary XAI research.
Artificial Intelligence 296 (2021), 103473.
[38] Seth Lazar. 2022. Legitimacy, Authority, and the Political Value of Explanations. arXiv preprint arXiv:2208.08628 (2022).
[39] Sarah Lebovitz, Hila Lifshitz-Assaf, and Natalia Levina. 2022. To engage or not to engage with AI for critical judgments: How professionals deal
with opacity when using AI for medical diagnosis. Organization Science 33, 1 (2022), 126–148.
[40] John D Lee and Katrina A See. 2004. Trust in automation: Designing for appropriate reliance. Human Factors 46, 1 (2004), 50–80.
[41] Beibin Li, Konstantina Mellou, Bo Zhang, Jeevan Pathuri, and Ishai Menache. 2023. Large language models for supply chain optimization. arXiv
preprint arXiv:2307.03875 (2023).

“I Want It That Way”: Enabling Interactive Decision Support Using Large Language Models and Constraint
Programming
25
[42] Sarah Lichtenstein and Paul Slovic. 2006. The construction of preference: An overview. The construction of preference 1 (2006).
[43] Jessy Lin, Nicholas Tomlin, Jacob Andreas, and Jason Eisner. 2023. Decision-Oriented Dialogue for Human-AI Collaboration. arXiv preprint
arXiv:2305.20076 (2023).
[44] Lorraine McGinty and James Reilly. 2010. On the evolution of critiquing recommenders. In Recommender systems handbook. Springer, 419–453.
[45] Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste Rozière, Timo Schick, Jane
Dwivedi-Yu, Asli Celikyilmaz, et al. 2023. Augmented language models: a survey. arXiv preprint arXiv:2302.07842 (2023).
[46] Tim Miller. 2019. Explanation in artificial intelligence: Insights from the social sciences. Artificial intelligence 267 (2019), 1–38.
[47] Judson Mills and Edgar O’neal. 1971. Anticipated choice, attention, and halo effect. Psychonomic Science 22, 4 (1971), 231–233.
[48] Tom M Mitchell, Rich Caruana, Dayne Freitag, John McDermott, David Zabowski, et al. 1994. Experience with a learning personal assistant.
Commun. ACM 37, 7 (1994), 80–91.
[49] Henry Montgomery and Helena Willén. 1999. Decision making and action: The search for a good structure. Judgment and decision making:
Neo-Brunswikian and process-tracing approaches (1999), 147–173.
[50] Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William
Saunders, et al. 2021. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332 (2021).
[51] Yuting Ning, Jiayu Liu, Longhu Qin, Tong Xiao, Shangzi Xue, Zhenya Huang, Qi Liu, Enhong Chen, and Jinze Wu. 2023. A Novel Approach for
Auto-Formulation of Optimization Problems. arXiv preprint arXiv:2302.04643 (2023).
[52] OpenAI. 2023. GPT-4 Technical Report. arXiv:2303.08774 [cs.CL]
[53] John W Payne, James R Bettman, and Eric J Johnson. 1992. Behavioral decision research: A constructive processing perspective. Annual Review of
Psychology 43, 1 (1992), 87–131.
[54] John W Payne, James R Bettman, and Eric J Johnson. 1993. The adaptive decision maker. Cambridge University Press.
[55] John W Payne, James R Bettman, David A Schkade, Norbert Schwarz, and Robin Gregory. 2000. Measuring constructed preferences: Towards a
building code. Elicitation of preferences (2000), 243–275.
[56] Bart Peintner, Paolo Viappiani, and Neil Yorke-Smith. 2008. Preferences in interactive systems: Technical challenges and case studies. AI Magazine
29, 4 (2008), 13–13.
[57] Alina Pommeranz, Joost Broekens, Pascal Wiggers, Willem-Paul Brinkman, and Catholijn M Jonker. 2012. Designing interfaces for explicit preference
elicitation: a user-centered investigation of preference representation and elicitation process. User Modeling and User-Adapted Interaction 22 (2012),
357–397.
[58] Ganesh Prasath and Shirish Karande. 2023. Synthesis of Mathematical programs from Natural Language Specifications. arXiv preprint arXiv:2304.03287
(2023).
[59] Pearl Pu, Boi Faltings, and Marc Torrens. 2003. User-involved preference elicitation. Technical Report.
[60] Jing Qian, Hong Wang, Zekun Li, Shiyang Li, and Xifeng Yan. 2022. Limitations of language models in arithmetic and symbolic induction. arXiv
preprint arXiv:2208.05051 (2022).
[61] Rindranirina Ramamonjison, Haley Li, Timothy T Yu, Shiqi He, Vishnu Rengan, Amin Banitalebi-Dehkordi, Zirui Zhou, and Yong Zhang. 2022.
Augmenting operations research with auto-formulation of optimization models from problem descriptions. arXiv preprint arXiv:2209.15565 (2022).
[62] Marcel K Richter. 1966. Revealed preference theory. Econometrica: Journal of the Econometric Society (1966), 635–645.
[63] Francesca Rossi. 1999. Constraint (logic) programming: A survey on research and applications. In Compulog Net/ERCIM Workshop on Constraints.
Springer, 40–74.
[64] J Edward Russo, Victoria Husted Medvec, and Margaret G Meloy. 1996. The distortion of information during decisions. Organizational behavior and
human decision processes 66, 1 (1996), 102–110.
[65] Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023.
Toolformer: Language models can teach themselves to use tools. arXiv preprint arXiv:2302.04761 (2023).
[66] Dan Simon, Daniel C Krawczyk, Airom Bleicher, and Keith J Holyoak. 2008. The transience of constructed preferences. Journal of Behavioral
Decision Making 21, 1 (2008), 1–14.
[67] Dan Simon, Daniel C Krawczyk, and Keith J Holyoak. 2004. Construction of preferences by constraint satisfaction. Psychological Science 15, 5 (2004),
331–336.
[68] Paul Slovic. 1995. The construction of preference. American Psychologist 50 (1995), 364–371.
[69] Atena M Tabakhi. 2017. Preference elicitation in DCOPs for scheduling devices in smart buildings. In Proceedings of the AAAI Conference on Artificial
Intelligence, Vol. 31.
[70] Atena M Tabakhi. 2021. Preference Elicitation in Constraint-Based Models: Models, Algorithms, and Applications. Ph. D. Dissertation. Washington
University in St. Louis.
[71] Atena M Tabakhi, Tiep Le, Ferdinando Fioretto, and William Yeoh. 2017. Preference elicitation for DCOPs. In Principles and Practice of Constraint
Programming: 23rd International Conference, CP 2017, Melbourne, VIC, Australia, August 28–September 1, 2017, Proceedings 23. Springer, 278–296.
[72] Atena M Tabakhi, William Yeoh, and Roie Zivan. 2022. Incomplete Distributed Constraint Optimization Problems: Model, Algorithms, and Heuristics.
In Distributed Artificial Intelligence: Third International Conference, DAI 2021, Shanghai, China, December 17–18, 2021, Proceedings 3. Springer, 64–78.
[73] Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du,
et al. 2022. Lamda: Language models for dialog applications. arXiv preprint arXiv:2201.08239 (2022).

26
Lawless et al.
[74] Dimos Tsouros, Hélène Verhaeghe, Serdar Kadıoğlu, and Tias Guns. 2023. Holy Grail 2.0: From Natural Language to Constraint Models. arXiv
preprint arXiv:2308.01589 (2023).
[75] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting
elicits reasoning in large language models. Advances in Neural Information Processing Systems 35 (2022), 24824–24837.
[76] Sean Welleck, Ilia Kulikov, Stephen Roller, Emily Dinan, Kyunghyun Cho, and Jason Weston. 2019. Neural text generation with unlikelihood
training. arXiv preprint arXiv:1908.04319 (2019).
[77] Yuanming Xiao. 2020. Embedding preference elicitation within the search for DCOP solutions. (2020).
[78] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, and Karthik Narasimhan. 2023. Tree of thoughts: Deliberate
problem solving with large language models. arXiv preprint arXiv:2305.10601 (2023).
[79] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2022. React: Synergizing reasoning and acting in
language models. arXiv preprint arXiv:2210.03629 (2022).
[80] Ann Yuan, Andy Coenen, Emily Reif, and Daphne Ippolito. 2022. Wordcraft: story writing with large language models. In 27th International
Conference on Intelligent User Interfaces. 841–852.

