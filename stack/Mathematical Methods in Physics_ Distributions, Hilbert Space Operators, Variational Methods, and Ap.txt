

Progress in Mathematical Physics
Volume 69
Editors-in-chief
Anne Boutet de Monvel, Université Paris VII UFR de Mathematiques,
Paris CX 05, France
Gerald Kaiser, Center for Signals and Waves, Portland, Oregon, USA
Editorial Board
C. Berenstein, University of Maryland, College Park, USA
Sir M. Berry, University of Bristol, UK
P. Blanchard, University of Bielefeld, Germany
M. Eastwood, University of Adelaide, Australia
A.S. Fokas, University of Cambridge, UK
F. W. Hehl, University of Cologne, Germany
and University of Missouri-Columbia, USA
D. Sternheimer, Université de Bourgogne, Dijon, France
C. Tracy, University of California, Davis, USA
For further volumes:
http://www.springer.com/series/4813

Philippe Blanchard • Erwin Brüning
Mathematical Methods
in Physics
Distributions, Hilbert Space Operators,
Variational Methods, and Applications
in Quantum Physics
Second Edition

Philippe Blanchard
Erwin Brüning
Abt. Theoretische Physik
School of Mathematics, Statistics,
Universität Bielefeld Fak. Physik
and Computer Science
Bielefeld
University of KwaZulu-Natal
Germany
Durban
South Africa
ISSN 1544-9998
ISSN 2197-1846 (electronic)
Progress in Mathematical Physics
ISBN 978-3-319-14044-5
ISBN 978-3-319-14045-2 (eBook)
DOI 10.1007/978-3-319-14045-2
Library of Congress Control Number: 2015931210
Mathematics Subject Classiﬁcation (MSC): 46-01, 46C05, 46F05, 46N50, 47A05, 47L90, 49-01, 60E05,
81Q10
Springer Cham Heidelberg New York Dordrecht London
© Springer International Publishing Switzerland 2003, 2015
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the
material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation,
broadcasting, reproduction on microﬁlms or in any other physical way, and transmission or information
storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology
now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this book
are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the
editors give a warranty, express or implied, with respect to the material contained herein or for any errors
or omissions that may have been made.
Printed on acid-free paper
Springer is part of Springer Science+Business Media (www.springer.com)

Dedicated to the memory of
Yurko Vladimir Glaser and Res Jost,
mentors and friends

Preface to the Second Edition
The ﬁrst edition of this book was published in 2003. Let us ﬁrst thank everyone
who, over the past 11 years, has provided us with suggestions and corrections for
improving this ﬁrst edition. We are extremely grateful for this help.
The past decade has brought many changes, but the aim of this book remains the
same. It is intended for graduate students in physics and mathematics and it may also
be useful for theoretical physicists in research and in industry. As the extended title
of this second edition indicates, we have focused our attention to a large extent on
topical applications to Quantum Physics.
With the hope that this book would be a useful reference for people applying math-
ematics in their work, we have emphasized the results that are important for various
applications in the areas indicated above. This book is essentially self-contained.
Perhaps some readers will use this book as a compendium of results; this would be a
pity, however, because proofs are often as important as results. Mathematical physics
is not a passive activity, and therefore the book contains more than 220 exercises to
challenge readers and to facilitate their understanding.
This second edition differs from the ﬁrst through the reorganization of certain
material and the addition of ﬁve new chapters which have a new range of substantial
applications.
The ﬁrst addition is Chap. 13 “Sobolev spaces” which offers a brief introduction
to the basic theory of these spaces and thus prepares their use in the study of linear
and nonlinear partial differential operators and, in particular, in the third part of this
book dedicated to “Variational Methods.”
While in the ﬁrst edition Hilbert–Schmidt and trace class operators were only
discussed brieﬂy in Chap. 22 “Special classes of bounded operators,” this edition
contains a new Chap. 26 “Hilbert–Schmidt and trace class operators.” The remainder
of Chap. 22 has been merged with the old, shorter Chap. 23 “Self-adjoint Hamilton
operators” to form the new Chap. 23 “Special classes of linear operators,” which now
also contains a brief section on von Neumann’s beautiful application of the spectral
theory for unitary operators in ergodic theory.
Chapter 26 “Hilbert–Schmidt and trace class operators” gives a fairly compre-
hensive introduction to the theory of these operators. Furthermore, the dual spaces
of the spaces of compact and of trace class operators are determined, which allows
vii

viii
Preface to the Second Edition
a thorough discussion of several locally convex topologies on the space B(H) of all
bounded linear operators on a separable Hilbert space H. These are used later in
the chapter “Operator algebras and positive mappings” to characterize normal states
on von Neumann algebras. This chapter also contains the deﬁnition of the partial
trace of trace class operators on the tensor products of two separable inﬁnite dimen-
sional Hilbert spaces and studies its main properties. These results are of particular
importance in the theory of open quantum systems and the theory of decoherence.
The motivation for the new Chap. 29 “Spectral analysis in rigged Hilbert spaces”
comes from the fact that, on one side, Dirac’s bra and ket formalism is widely and
successfully employed in theoretical physics, but its mathematical foundation is not
easily accessible. This chapter offers a nearly self-contained mathematical basis for
this formalism and proves in particular the completeness? there is a word missing in
this sentence completeness of the set of generalized eigenfunctions.
In Chap. 30 “Operator algebras and positive mappings,” we study in detail pos-
itive and completely positive mappings on the algebra B(H) of all bounded linear
operators on a Hilbert space H respectively on its subalgebras. We explain the GNS
construction for positive linear functionals in detail and characterize states, i.e.,
normalized positive linear functionals, in terms of their equivalent continuity proper-
ties (normal, completely additive, tracial). Next, Stinespring’s factorization theorem
characterizes completely positive maps in terms of representations. Since all repre-
sentations of B(H) are determined too, we can give a self-contained characterization
of all completely positive mappings on B(H).
The last new chapter, Chap. 31 “Positive mappings in quantum physics,” presents
several results which are very important for the foundations of quantum physics and
quantum information theory. We start with a detailed discussion of Gleason’s the-
orem on the general form of countable additive probability measures on the set of
projections of a separable Hilbert space. Using some of the results of the previous
chapter, we then give a self-contained characterization of quantum operations specif-
ically, quantum channel maps (Kraus form) and conclude with a brief discussion of
the stronger form of these results if the underlying Hilbert space is ﬁnite dimensional
(Choi’s characterization of quantum operations).
On the basis of the mathematical results obtained in this and earlier chapters, it
is straightforward to introduce some quite prominent concepts in quantum physics,
namely open quantum systems, reduced dynamics, and decoherence. This is done in
the last section of this chapter.
Bielefeld and Durban
Ph. Blanchard
May 2014
E. Brüning

Preface
Courses in modern theoretical physics have to assume some basic knowledge of
the theory of generalized functions (in particular distributions) and of the theory
of linear operators in Hilbert spaces. Accordingly, the faculty of physics of the
University of Bielefeld offered a compulsory course Mathematische Methoden der
Physik for students in the second semester of the second year, which now has been
given for many years. This course has been offered by the authors over a period
of about 10 years. The main goal of this course is to provide basic mathematical
knowledge and skills as they are needed for modern courses in quantum mechanics,
relativistic quantum ﬁeld theory, and related areas. The regular repetitions of the
course allowed, on the one hand, testing of a number of variations of the material
and, on the other hand, the form of the presentation. From this course, the book
Distributionen und Hilbertraumoperatoren. Mathematische Methoden der Physik.
Springer-Verlag Wien, 1993 emerged. The present book is a translated, considerably
revised, and extended version of this book. It contains much more than this course
since we added many detailed proofs, many examples, and exercises as well as hints
linking the mathematical concepts or results to the relevant physical concepts or
theories.
This book addresses students of physics who are interested in a conceptually
and mathematically clear and precise understanding of physical problems, and it
addresses students of mathematics who want to learn about physics as a source and
as an area of application of mathematical theories, i.e., all those students with interest
in the fascinating interaction between physics and mathematics.
It is assumed that the reader has a solid background in analysis and linear algebra
(in Bielefeld this means three semesters of analysis and two of linear algebra). On
this basis the book starts in Part A with an introduction to basic linear functional
analysis as needed for the Schwartz theory of distributions and continues in Part B
with the particularities of Hilbert spaces and the core aspects of the theory of linear
operators in Hilbert spaces. Part C develops the basic mathematical foundations for
modern computations of the ground state energies and charge densities in atoms
and molecules, i.e., basic aspects of the direct methods of the calculus of variations
including constrained minimization. A powerful strategy for solving linear and non-
linear boundary and eigenvalue problems, which covers the Dirichlet problem and
ix

x
Preface
its nonlinear generalizations, is presented as well. An appendix gives detailed proofs
of the fundamental principles and results of functional analysis to the extent they are
needed in our context.
With great pleasure we would like to thank all those colleagues and friends who
have contributed to this book through their advice and comments, in particular G.
Bolz, J. Loviscach, G. Roepstorff, and J. Stubbe. Last but not least we thank the
editorial team of Birkhäuser—Boston for their professional work.
Bielefeld and Durban
Ph. Blanchard
June 2002
E. Brüning

Acknowledgements
It is with great pleasure that we thank our colleague and friend Shigeaki Nagamachi
(Tokushima, Japan) for his help with the proof reading of the new chapters and a
number of suggestions for improving our presentation. Our thanks go also to our
colleagues Florian Scheck and Ludwig Streit and to many students. They helped us
to eliminate quite a number of (small) errors.
Last, but not least, we thank the editorial team of Birkhäuser for their professional
work.
Bielefeld and Durban
Ph. Blanchard
May 2014
E. Brüning
xi

Contents
Part I Distributions
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
Reference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
2
Spaces of Test Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
2.1
Hausdorff Locally Convex Topological Vector Spaces . . . . . . . . . . . .
7
2.1.1
Examples of HLCTVS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
13
2.1.2
Continuity and Convergence in a HLCVTVS . . . . . . . . . . . . .
15
2.2
Basic Test Function Spaces of Distribution Theory . . . . . . . . . . . . . . .
18
2.2.1
The Test Function Space D(Ω) of C∞Functions of Compact
Support . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
18
2.2.2
The Test Function Space S(Ω) of Strongly Decreasing
C∞-Functions on Ω . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
2.2.3
The Test Function Space E(Ω) of All C∞-Functions on Ω . .
21
2.2.4
Relation Between the Test Function Spaces D(Ω), S(Ω), and
E(Ω) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
2.3
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
Reference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
24
3
Schwartz Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
3.1
The Topological Dual of an HLCTVS. . . . . . . . . . . . . . . . . . . . . . . . . .
25
3.2
Deﬁnition of Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
3.2.1
The Regular Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
3.2.2
Some Standard Examples of Distributions . . . . . . . . . . . . . . . .
31
3.3
Convergence of Sequences and Series of Distributions . . . . . . . . . . . .
33
3.4
Localization of Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
3.5
Tempered Distributions and Distributions with Compact Support . . .
40
3.6
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
42
xiii

xiv
Contents
4
Calculus for Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
45
4.1
Differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
46
4.2
Multiplication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
49
4.3
Transformation of Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
52
4.4
Some Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
55
4.4.1
Distributions with Support in a Point . . . . . . . . . . . . . . . . . . . .
55
4.4.2
Renormalization of
 1
x

+ = θ(x)
x
. . . . . . . . . . . . . . . . . . . . . . . .
57
4.5
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
59
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
60
5
Distributions as Derivatives
of Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
63
5.1
Weak Derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
63
5.2
Structure Theorem for Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . .
65
5.3
Radon Measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
67
5.4
The Case of Tempered and Compactly Supported Distributions . . . .
69
5.5
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
71
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
71
6
Tensor Products . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
73
6.1
Tensor Product for Test Function Spaces . . . . . . . . . . . . . . . . . . . . . . .
73
6.2
Tensor Product for Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
77
6.3
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
84
Reference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
84
7
Convolution Products . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
85
7.1
Convolution of Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
85
7.2
Regularization of Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
89
7.3
Convolution of Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
93
7.4
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
8
Applications of Convolution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
8.1
Symbolic Calculus—Ordinary Linear Differential Equations . . . . . . 102
8.2
Integral Equation of Volterra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106
8.3
Linear Partial Differential Equations with Constant Coefﬁcients . . . . 107
8.4
Elementary Solutions of Partial Differential Operators . . . . . . . . . . . . 110
8.4.1
The Laplace Operator Δn = n
i=1
∂2
∂x2
i in Rn . . . . . . . . . . . . . . 111
8.4.2
The PDE Operator ∂
∂t −Δn of the Heat Equation in Rn+1 . . . 112
8.4.3
The Wave Operator 24 = ∂2
0 −Δ3 in R4 . . . . . . . . . . . . . . . . . 114
8.5
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117

Contents
xv
9
Holomorphic Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
9.1
Hypoellipticity of ∂. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
9.2
Cauchy Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
9.3
Some Properties of Holomorphic Functions. . . . . . . . . . . . . . . . . . . 125
9.4
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
10
Fourier Transformation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
10.1
Fourier Transformation for Integrable Functions . . . . . . . . . . . . . . . 134
10.2
Fourier Transformation on S(Rn) . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
10.3
Fourier Transformation for Tempered Distributions . . . . . . . . . . . . 144
10.4
Some Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
10.4.1
Examples of Tempered Elementary Solutions . . . . . . . . . . 155
10.4.2
Summary of Properties of the Fourier Transformation . . . 159
10.5
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
11
Distributions as Boundary Values of Analytic Functions . . . . . . . . . . . 163
11.1
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 168
12
Other Spaces of Generalized Functions . . . . . . . . . . . . . . . . . . . . . . . . . . 169
12.1
Generalized Functions of Gelfand Type S . . . . . . . . . . . . . . . . . . . . 170
12.2
Hyperfunctions and Fourier Hyperfunctions . . . . . . . . . . . . . . . . . . 173
12.3
Ultradistributions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178
13
Sobolev Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
13.1
Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
13.2
Basic Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
13.3
The Basic Estimates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184
13.3.1
Morrey’s Inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184
13.3.2
Gagliardo-Nirenberg-Sobolev Inequality . . . . . . . . . . . . . . 188
13.4
Embeddings of Sobolev Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193
13.4.1
Continuous Embeddings . . . . . . . . . . . . . . . . . . . . . . . . . . . 193
13.4.2
Compact Embeddings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195
13.5
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
Part II Hilbert Space Operators
14
Hilbert Spaces: A Brief Historical Introduction . . . . . . . . . . . . . . . . . . . 201
14.1
Survey: Hilbert Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201
14.2
Some Historical Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208
14.3
Hilbert Spaces and Physics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211

xvi
Contents
15
Inner Product Spaces and Hilbert Spaces . . . . . . . . . . . . . . . . . . . . . . . . 213
15.1
Inner Product Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213
15.1.1
Basic Deﬁnitions and Results . . . . . . . . . . . . . . . . . . . . . . . 214
15.1.2
Basic Topological Concepts . . . . . . . . . . . . . . . . . . . . . . . . 218
15.1.3
On the Relation Between Normed Spaces and Inner
Product spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
219
15.1.4
Examples of Hilbert Spaces . . . . . . . . . . . . . . . . . . . . . . . . 221
15.2
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225
16
Geometry of Hilbert Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227
16.1
Orthogonal Complements and Projections . . . . . . . . . . . . . . . . . . . . 227
16.2
Gram Determinants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231
16.3
The Dual of a Hilbert Space . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233
16.4
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237
17
Separable Hilbert Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239
17.1
Basic Facts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239
17.2
Weight Functions and Orthogonal Polynomials . . . . . . . . . . . . . . . . 245
17.3
Examples of Complete Orthonormal Systems for L2(I, ρdx) . . . . 249
17.4
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254
18
Direct Sums and Tensor Products . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
18.1
Direct Sums of Hilbert Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
18.2
Tensor Products . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258
18.3
Some Applications of Tensor Products and Direct Sums . . . . . . . . 261
18.3.1
State Space of Particles with Spin . . . . . . . . . . . . . . . . . . . 261
18.3.2
State Space of Multi Particle Quantum Systems . . . . . . . . 261
18.4
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
19
Topological Aspects. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 265
19.1
Compactness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 265
19.2
The Weak Topology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267
19.3
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 275
Reference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 276
20
Linear Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277
20.1
Basic Facts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277
20.2
Adjoints, Closed and Closable Operators . . . . . . . . . . . . . . . . . . . . . 280
20.3
Symmetric and Self-Adjoint Operators. . . . . . . . . . . . . . . . . . . . . . . 286
20.4
Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289
20.4.1
Operator of Multiplication. . . . . . . . . . . . . . . . . . . . . . . . . . 289
20.4.2
Momentum Operator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290
20.4.3
Free Hamilton Operator . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291
20.5
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 292

Contents
xvii
21
Quadratic Forms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 295
21.1
Basic Concepts. Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 295
21.2
Representation of Quadratic Forms . . . . . . . . . . . . . . . . . . . . . . . . . . 298
21.3
Some Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 302
21.4
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 304
22
Bounded Linear Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 307
22.1
Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 307
22.2
Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309
22.3
The Space B(H, K) of Bounded Linear Operators . . . . . . . . . . . . . 313
22.4
The C∗-Algebra B(H) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 315
22.5
Calculus in the C∗-Algebra B(H) . . . . . . . . . . . . . . . . . . . . . . . . . . . 318
22.5.1
Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 318
22.5.2
Polar Decomposition of Operators . . . . . . . . . . . . . . . . . . . 320
22.6
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 321
Reference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 323
23
Special Classes of Linear Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325
23.1
Projection Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325
23.2
Unitary Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 329
23.2.1
Isometries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 329
23.2.2
Unitary Operators and Groups of Unitary Operators . . . . 330
23.2.3
Examples of Unitary Operators. . . . . . . . . . . . . . . . . . . . . . 333
23.3
Some Applications of Unitary Operators in Ergodic Theory . . . . . 333
23.3.1
Poincaré Recurrence Results . . . . . . . . . . . . . . . . . . . . . . . . 334
23.3.2
The Mean Ergodic Theorem of von Neumann . . . . . . . . . 335
23.4
Self-Adjoint Hamilton Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . 337
23.4.1
Kato Perturbations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 337
23.4.2
Kato Perturbations of the Free Hamiltonian . . . . . . . . . . . 339
23.5
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 341
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342
24
Elements of Spectral Theory. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343
24.1
Basic Concepts and Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344
24.2
The Spectrum of Special Operators . . . . . . . . . . . . . . . . . . . . . . . . . . 348
24.3
Comments on Spectral Properties of Linear Operators . . . . . . . . . . 350
24.4
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352
Reference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353
25
Compact Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 355
25.1
Basic Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 355
25.2
Spectral Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 359
25.2.1
The Results of Riesz and Schauder . . . . . . . . . . . . . . . . . . 359
25.2.2
The Fredholm Alternative . . . . . . . . . . . . . . . . . . . . . . . . . . 361
25.3
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 363
Reference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 363

xviii
Contents
26
Hilbert–Schmidt and Trace Class Operators . . . . . . . . . . . . . . . . . . . . . 365
26.1
Basic Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 365
26.2
Dual Spaces of the Spaces of Compact and of Trace Class
Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
373
26.3
Related Locally Convex Topologies on B(H) . . . . . . . . . . . . . . . . . 377
26.4
Partial Trace and Schmidt Decomposition in Separable Hilbert
Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
382
26.4.1
Partial Trace . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 382
26.4.2
Schmidt Decomposition . . . . . . . . . . . . . . . . . . . . . . . . . . . 386
26.5
Some Applications in Quantum Mechanics . . . . . . . . . . . . . . . . . . . 387
26.6
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 390
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 391
27
The Spectral Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 393
27.1
Geometric Characterization of Self-Adjointness . . . . . . . . . . . . . . . 394
27.1.1
Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 394
27.1.2
Subspaces of Controlled Growth . . . . . . . . . . . . . . . . . . . . 395
27.2
Spectral Families and Their Integrals . . . . . . . . . . . . . . . . . . . . . . . . 402
27.2.1
Spectral Families . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 402
27.2.2
Integration with Respect to a Spectral Family . . . . . . . . . . 404
27.3
The Spectral Theorem. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 410
27.4
Some Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 414
27.5
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 416
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 417
28
Some Applications of the Spectral Representation . . . . . . . . . . . . . . . . . 419
28.1
Functional Calculus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 419
28.2
Decomposition of the Spectrum—Spectral Subspaces . . . . . . . . . . 421
28.3
Interpretation of the Spectrum of a Self-Adjoint Hamiltonian . . . . 429
28.4
Probabilistic Description of Commuting Observables . . . . . . . . . . 435
28.5
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 435
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 436
29
Spectral Analysis in Rigged Hilbert Spaces . . . . . . . . . . . . . . . . . . . . . . . 439
29.1
Rigged Hilbert Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 439
29.1.1
Motivation for the Use of Generalized Eigenfunctions . . 439
29.1.2
Rigged Hilbert Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 440
29.1.3
Examples of Nuclear Spaces . . . . . . . . . . . . . . . . . . . . . . . . 442
29.1.4
Structure of the Natural Embedding in a Gelfand Triple . 443
29.2
Spectral Analysis of Self-adjoint Operators and Generalized
Eigenfunctions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
445
29.2.1
Direct Integral of Hilbert Spaces . . . . . . . . . . . . . . . . . . . . 445
29.2.2
Classical Versions of Spectral Representation . . . . . . . . . . 447
29.2.3
Generalized Eigenfunctions . . . . . . . . . . . . . . . . . . . . . . . . 449
29.2.4
Completeness of Generalized Eigenfunctions . . . . . . . . . . 450
29.3
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 453
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 453

Contents
xix
30
Operator Algebras and Positive Mappings . . . . . . . . . . . . . . . . . . . . . . . 455
30.1
Representations of C∗-Algebras . . . . . . . . . . . . . . . . . . . . . . . . . . . . 455
30.1.1
Representations of B(H) . . . . . . . . . . . . . . . . . . . . . . . . . . . 456
30.2
On Positive Elements and Positive Functionals . . . . . . . . . . . . . . . . 460
30.2.1
The GNS-Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . 462
30.3
Normal States . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 465
30.4
Completely Positive Maps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 470
30.4.1
Positive Elements in Mk(A) . . . . . . . . . . . . . . . . . . . . . . . . 470
30.4.2
Some Basic Properties of Positive Linear Mappings . . . . 472
30.4.3
Completely Positive Maps Between C∗-Algebras. . . . . . . 473
30.4.4
Stinespring Factorization Theorem for Completely
Positive Maps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
475
30.4.5
Completely Positive Mappings on B(H) . . . . . . . . . . . . . . 479
30.5
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 482
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 482
31
Positive Mappings in Quantum Physics . . . . . . . . . . . . . . . . . . . . . . . . . . 483
31.1
Gleason’s Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 483
31.2
Kraus Form of Quantum Operations . . . . . . . . . . . . . . . . . . . . . . . . . 486
31.2.1
Operations and Effects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 487
31.2.2
The Representation Theorem for Operations . . . . . . . . . . . 490
31.3
Choi’s Results for Finite Dimensional Completely Positive Maps
493
31.4
Open Quantum Systems, Reduced Dynamics and Decoherence . . 496
31.5
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 498
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 499
Part III Variational Methods
32
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 503
32.1
Roads to Calculus of Variations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 504
32.2
Classical Approach Versus Direct Methods . . . . . . . . . . . . . . . . . . . 505
32.3
The Objectives of the Following Chapters . . . . . . . . . . . . . . . . . . . . 508
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 508
33
Direct Methods in the Calculus of Variations . . . . . . . . . . . . . . . . . . . . . 511
33.1
General Existence Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 511
33.2
Minimization in Banach Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . 513
33.3
Minimization of Special Classes of Functionals . . . . . . . . . . . . . . . 515
33.4
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 516
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 517
34
Differential Calculus on Banach Spaces and Extrema of Functions. . 519
34.1
The Fréchet Derivative . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 520
34.2
Extrema of Differentiable Functions . . . . . . . . . . . . . . . . . . . . . . . . . 526
34.3
Convexity and Monotonicity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 528

xx
Contents
34.4
Gâteaux Derivatives and Variations . . . . . . . . . . . . . . . . . . . . . . . . . . 530
34.5
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 534
Reference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 535
35
Constrained Minimization Problems (Method of Lagrange
Multipliers) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 537
35.1
Geometrical Interpretation of Constrained Minimization . . . . . . . . 538
35.2
Tangent Spaces of Level Surfaces . . . . . . . . . . . . . . . . . . . . . . . . . . . 539
35.3
Existence of Lagrange Multipliers . . . . . . . . . . . . . . . . . . . . . . . . . . 541
35.3.1
Comments on Dido’s Problem . . . . . . . . . . . . . . . . . . . . . . 543
35.4
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 545
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 546
36
Boundary and Eigenvalue Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 547
36.1
Minimization in Hilbert Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 547
36.2
The Dirichlet–Laplace Operator and Other Elliptic Differential
Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
551
36.3
Nonlinear Convex Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 554
36.4
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 560
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 562
37
Density Functional Theory
of Atoms and Molecules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 563
37.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 563
37.2
Semiclassical Theories of Density Functionals . . . . . . . . . . . . . . . . 565
37.3
Hohenberg–Kohn Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 566
37.3.1
Hohenberg–Kohn Variational Principle . . . . . . . . . . . . . . . 570
37.3.2
The Kohn–Sham Equations . . . . . . . . . . . . . . . . . . . . . . . . . 571
37.4
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 572
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 573
Appendix A Completion of Metric Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . 575
Appendix B Metrizable Locally Convex Topological Vector Spaces . . . . . . 579
Appendix C The Theorem of Baire . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 581
Appendix D Bilinear Functionals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 589
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 591

Notation
N
the natural numbers
N0
N ∪{0}
R
ﬁeld of real numbers
C
ﬁeld of complex numbers
K
ﬁeld of real or of complex numbers
R+
the set of nonnegative real numbers
Kn
K vector space of n-tuples of numbers in K
A ± B
{c ∈V ; c = a ± b; a ∈A; b ∈B} for subsets A and B of a
vector space V
ΛM
{λ · u; λ ∈Λ, u ∈M} for a subset Λ ⊂K and a subset M of a
vector space V over K
A\B
the set of all points in a set A which do not belong to the subset
B of A
ℜz
real part of z ∈C
ℑz
imaginary part of z ∈C
C(Ω) = C(Ω; K)
vector space of all continuous functions f : Ω →K, for an
open set Ω ⊂Kn
Cb(Ω)
all bounded functions f ∈C(Ω) equipped with sup-norm
C0(Ω)
vector space of all continuous functions f : Ω →K with
compact support in Ω
xxi

xxii
Notation
Ck(Ω)
vector space of all functions which have continuous derivatives
up to order k, for k = 0, 1, 2, . . .
Dα =
∂|α|
∂xα1
1 ···∂xαn
n
derivative monomial of order |α| = α1 + · · · + αn, deﬁned on
spaces Ck(Ω), for open sets Ω ⊂Rn and k ≥|α|
C0,α(Ω)
space of all f ∈Cb(Ω) for which Qα(f ) =
sup
x,y∈Ω,x̸=y
|f (x)−f (y)|
|x−y|α
<
∞for 0 < α ≤1, Hölder space of exponent α
Ck
b(Ω)
space of all f ∈Ck(Ω) for which Dβf ∈Cb(Ω) for all |β| ≤k,
for k ∈N0 with norm ∥f ∥Ck
b = max|β|≤k supx∈Ω |Dβf (x)|
Ck,α(Ω)
for k ∈N0 and 0 < α ≤1, space of all f ∈Ck
b(Ω) for which
∥f ∥Ck,α = ∥f ∥Ck
b + max
|β|=kQα(Dβf ) < ∞
supp f
support of the function f
DK(Ω)
vector space of all functions f : Ω →K which have continuous
derivatives of any order and which have a compact support supp f
contained in the compact subset K of Ω ⊂Rn, equipped with
the topology of uniform convergence of all derivatives
pK,m
for m = 0, 1, 2, . . . , K ⊂Ω, K compact, Ω ⊆Rn open, the
semi-norm on DK(Ω) deﬁned by pK,m(f ) =
sup
|α|≤m, x∈K
|Dαf (x)|
qK,m
the
semi-norm
on
DK(Ω)
deﬁned
by
qK,m(f )
=

|α|≤m

K |Dαf (x)|2dx
1/2
K, m, Ω as above
D(Ω)
inductive limit of the spaces DK(Ω) with respect to all subsets
K ⊂Ω, K compact; test function space of all C∞-functions f :
Ω →K which have a compact support in the open set Ω ⊂Rn
C∞
c (Rn)
the vector space of all compactly supported C∞functions on Rn
|x|
Euclidean norm

x2
1 + · · · + x2n of the vector x = (x1, . . . , xn) ∈
Rn
S(Ω)
test function space of all C∞-functions f : Ω →K which, to-
gether with all their derivatives decrease faster than const. (1 +
|x|)−k for k = 0, 1, 2, . . . , for some constant and x ∈Ω
pm,k
the norm on S(Rn) deﬁned by pm,k(f )
=
sup
x∈Rn, |α|≤k
(1 +
x2)
m
2 |Dαf (x)| for m, k = 0, 1, 2, . . .
E(Ω)
test function space of all C∞-functions f : Ω →K, equipped
with the topology of uniform convergence of all derivatives f α =
D(α)f on all compact subsets K of Ω

Notation
xxiii
lctvs
locally convex topological vector space
hlctvs
Hausdorff locally convex topological vector space
X∗
algebraic dual of a vector space X
X′
topological dual of a topological vector space X
D′(Ω) ≡D(Ω)′
space of all distributions on the open set Ω ⊆Rn
S′(Ω) ≡S(Ω)′
space of all tempered (i.e., slowly growing) distributions on
Ω ⊆Rn
E′(Ω) ≡E(Ω)′
space of all distributions on Ω ⊆Rn with compact support
If
the regular distribution deﬁned by the locally integrable function
f
D′reg(Ω)
the space of all regular distributions on the open set Ω ⊆Rn
D′+(R)
space of all distributions on R with support in R+
Lp(Ω)
space of equivalence classes of Lebesgue measurable functions
on Ω ⊆Rn for which |f |p is Lebesgue integrable over Ω;
1 ≤p < ∞, Ω Lebesgue measurable
∥f ∥p
norm of Lp(Ω) deﬁned by ∥f ∥p
p =

Ω |f (x)|pdx
L∞(Ω)
space of all equivalence classes of Lebesgue measurable func-
tions on Ω which are essentially bounded; Ω ⊆Rn Lebesgue
measurable
Lp
loc(Ω)
all f as for Lp(Ω), but |f |P only integrable over every compact
set K in Ω, with system of semi-norms ∥f ∥p
K = ∥χKf ∥p,
K ⊂Ω compact, χK = characteristic function of K
Bp,r(x0)
open ball of radius r > 0 and centre x0, with respect to the
semi-norm p
δa
Dirac’s delta distribution centered at x = a ∈Rn; for a = 0 we
write δ instead of δ0
θ
Heaviside function
vp 1
x
Cauchy’s principal value
1
x± io
limε↘0
1
x± iε in D′(R)

xxiv
Notation
supp T
support of a distribution T
supp sing T
singular support of a distribution T
f ⊗g
tensor product of two functions f and g
T ⊗S
tensor product of two distributions T and S
D(Rn) ⊗D(Rm)
algebraic tensor product of the test function spaces D(Rn) and
D(Rm)
D(Rn) ⊗π D(Rm)
the space D(Rn) ⊗D(Rm) equipped with the projective tensor
product topology
D(Rn) ˜⊗πD(Rm)
completion of the space D(Rn) ⊗π D(Rm)
u ∗v
convolution of two functions u and v
T ∗u
the convolution of a distribution T ∈D′(Ω) with a test function
u ∈D(Ω); regularization of T
T ∗S
convolution of two distributions T and S, if deﬁned
¯∂
the differential operator 1
2( ∂
∂x + i ∂
∂y ) on D′(R2)
F
operator of Fourier transform, on L1(Rn) or S(Rn)
F2
unitary operator of Fourier transform on the Hilbert space
L2(Rn)
F′
Fourier transform on S′(Rn)
C[k,p](Ω)
vector space of all functions f ∈Ck(Ω) which have derivatives
Dαf ∈Lp(Ω) up to order k, for k = 0, 1, 2, . . . and 1 ≤p ≤∞
W k,p(Ω)
Sobolev space of order (k, p), for k = 0, 1, 2, . . . and 1 ≤
p ≤∞, completion of C[k,p](Ω) with respect to the norm ∥·∥k,p
deﬁned by ∥u∥p
k,p = 
|α|≤k ∥Dαu∥p
Lp(Ω), or
W k,p(Ω)
according to Meyers–Serrin: the space of all u ∈Lp(Ω) which
have weak derivatives Dαu in Lp(Ω) for |α| ≤k
W k,p
loc (Ω)
as W k,p(Ω) with Lp(Ω) replaced by Lp
loc(Ω)
H k(Ω)
the Hilbert space W k,2(Ω) with inner product ⟨f , g⟩H k(Ω) =

|α|≤k ⟨Dαf , Dαg⟩L2(Ω)

Notation
xxv
p∗
Sobolev conjugate exponent of p deﬁned by p∗=
np
n−p for
1 < p < n and p∗= ∞for p = n
< ·, · >
inner product on a vector space
∥·∥
norm on a vector space
l2(K)
Hilbert space of square summable sequences of numbers in K
M⊥
orthogonal complement of a set M in a Hilbert space
lin M
the linear span of the set M in a vector space
[M]
the closure of lin M in a topological vector space, i.e., the
smallest closed subspace which contains M
ONS
orthonormal system in a Hilbert space
ONB
orthonormal basis in a (separable) Hilbert space
dimV
dimension of a vector space V
D(A)
domain (of deﬁnition) of the (linear) operator A
kerA = N(A)
the kernel or null-space of a linear operator A
ran A
the range or set of values of a linear operator A
Γ (A)
graph of a linear operator A
A∗
the adjoint of the densely deﬁned linear operator A
AF
Friedrichs extension of the densely deﬁned nonnegative linear
operator A
A + B
form sum of the linear operators A and B
L(X, Y)
space of continuous linear operators X →Y, X and Y topolog-
ical vector spaces over the ﬁeld K
B(H) = B(H, H)
space of bounded linear operators on a Hilbert space H
ˆA = (D, A)
linear operator with domain D and rule of assignment A
Bc(H)
space of compact operators on a Hilbert space H
B1(H)
the space of all trace class operators on H

xxvi
Notation
B2(H)
the space of all Hilbert–Schmidt operators on H
[e, f ]
the ﬁniterankoperatoronaHilbertspaceH deﬁnedby[e, f ]x =
⟨f , x⟩e for x ∈H, for any given (unit) vectors e, f ∈H
U(H)
space of all unitary operators on a Hilbert space H
ρ(A)
resolvent set of a linear operator A
RA(z)
resolvent operator at the point z ∈ρ(A) for the linear operator
A
σ(A)
= C\ρ(A), spectrum of the linear operator A
σp(A)
point spectrum of A
σc(A)
= σ(A)\σp(A), continuous spectrum of A
σd(A)
discrete spectrum of A
σac(A)
absolutely continuous spectrum of A
σsc(A)
singular continuous spectrum of A
Hp(A)
discontinuous subspace of A
Hc(A)
continuous subspace of A
Hsc(A)
singular continuous subspace of a self-adjoint operator A
Hac(A)
= Hc(A) ∩Hsc(A)⊥, absolute continuous subspace of a self-
adjoint operator A
Hs(A)
= Hp(A)⊕Hsc(A), singular subspace of a self-adjoint operator
A
Mb(H)
subspace of bounded states of a self-adjoint Schrödinger opera-
tor H
M∞(H)
subspace of scattering states of H, H as above
projM
orthogonal projection operator onto the closed subspace M of a
Hilbert space
[f ≤r]
for a function f
: M →R and r ∈R the sub-level set
{x ∈M : f (x) ≤r}
projK
projection onto the closed convex subset K of a Hilbert space H

Notation
xxvii
[f = c]
for a function f
: M →R and c ∈R the level set
{x ∈M : f (x) = c}
f ′(x) = Dxf = Df (x)
the Fréchet derivative of a function f : U →F at a point
x ∈U, for U ⊂E open, E, F Banach spaces
B(E×n, F)
the Banach space of all continuous n-linear operators
E×n = E × · · · × E →F, for Banach spaces E, F
δf (x0, h)
Gâteaux differential of a function f : U→F at a point
x0 ∈U in the direction h ∈E, U ⊂E open, E, F
Banach spaces
δx0f (h)
Gâteaux derivative of f at x0 ∈U, applied to h ∈E
△nf (x0, h)
= dn
dtn f (x0 + th)|t=0, nth variation of a function f at the
point x0 in the direction h
TxM
tangent space of the differential manifold M at the point
x ∈M

Part I
Distributions

Chapter 1
Introduction
One of the earliest andmostfamousexamplesofageneralizedfunctionordistribution
is “Dirac’s delta function.” It was originally deﬁned by Dirac (1926–1927) as a
function
R ∋x −→δx0(x) ∈¯R ≡R ∪{∞}
with the following properties (x0 is a given real number):
(a)
δx0(x) =
⎧
⎨
⎩
0 :
x ∈R, x ̸= x0,
+∞:
x = x0.
(b)

R f (x)δx0(x)dx = f (x0) for all sufﬁciently smooth functions f : R →R.
However, elementary results from integration theory show that the conditions (a) and
(b) contradict each other. Indeed, by (a), f (x)δx0(x) = 0 for almost all x ∈R (with
to the Lebesgue measure on R), and thus the Lebesgue integral f (x)δx0(x) vanishes:

R
f (x)δx0(x)dx = 0
and this contradicts (b) for all f with f (x0) ̸= 0. An appropriate reading of condition
(b) is to interpret f (x)δx0(x)dx as a measure of total mass 1 which is concentrated
in x = x0. But this is in conﬂict with condition (a).
Nevertheless, physicists continued to work with this contradictory object quite
successfully, in the sense of formal calculations. This showed that this mathematical
object was useful in principle. In addition numerous other examples hinted at the
usefulness of mathematical objects similar to Dirac’s distribution. These objects,
respectively concepts, were introduced initially in an often rather vague way in order
to deal with concrete problems. The concepts we have in mind here were mainly those
which later in the theory of generalized functions found their natural formulation
as weak derivative, generalized solution, Green’s function etc. This is to say that
distribution theory should be considered as the natural result, through a process of
© Springer International Publishing Switzerland 2015
3
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_1

4
1
Introduction
synthesis and simpliﬁcation, of several attempts to extend classical analysis which
arose from various concrete problems. With the formulation of distribution theory
one had an analogous situation to the invention of differential and integral calculus
by Leibniz and Newton. In both cases many, mainly ad-hoc methods, were known
for the solutions of many concrete problems which then found their “synthesis and
simpliﬁcation” in a comprehensive theory.
The main contributions to the development of distribution theory came from S.
Bochner, J. Leray, K. Friedrichs, S. Sobolev, I. M. Gelfand, and, in particular, Lau-
rent Schwartz (1945–1949). New general ideas and methods from topology and
functional analysis were used, mainly by L. Schwartz, in order to solve many, often
old, problems and to extract their common general mathematical framework. Dis-
tribution theory, as created through this process, allows us to consider well-deﬁned
mathematical objects with the conditions (a) and (b) from above by giving these
conditions a new interpretation. In a ﬁrst step, condition (b) becomes the deﬁnition
of an object δx0 which generalizes the concept of the Lebesgue integral in the original
formulation, i.e., our preliminary deﬁnition for δx0 reads (F denotes the vector space
of all functions f : R →C):
δx0 : {f ∈F; f sufﬁciently smooth} →C deﬁned by
δx0(f ) = f (x0).
According to this δx0 assigns numbers to sufﬁciently smooth functions f in a linear
way, just as ordinary integrals
Ig(f ) =

R
g(x)f (x)dx
if they do exist (here g is a given function). Property (a) then becomes a “sup-
port property” of this newly deﬁned object on a vector space of sufﬁciently smooth
functions:
δx0(f ) = 0
whenever
f (x0) = 0.
In this sense one can also consider functions as “linear functions” or “functionals” on
a suitable vector space of functions φ. The idea is quite simple: Consider the vector
space C0(Rn) of continuous functions φ : Rn →C with compact support supp φ.
Recall: The support of a function is by deﬁnition the closure of the set of those points
where the function does not vanish, i.e.,
supp φ = {x ∈Rn : φ(x) ̸= 0}.
Then every continuous function g on Rn can be considered, in a natural way, as a
linear functional Ig on the vector space C0(Rn) by deﬁning
Ig(φ) ≡

Rn g(x)φ(x)dx.
(1.1)

1
Introduction
5
When we think about the fact that the values of measurements of physical quantities
are obtained by an averaging process, then the interpretation appears reasonable that
many physical quantities can be described mathematically only by objects of the
type (1.1). Later, when we have progressed with the precise formulation, we will
call objects of the type (1.1) regular distributions. Distributions are a special class of
generalized functions which indeed generalize functions along the lines indicated in
(1.1). This will be discussed in more detail later. The theory of generalized functions
has been developed to overcome various difﬁculties in classical analysis, in particular
the following problems:
(i) the existence of continuous but not differentiable functions (B. Riemann 1861,
K. Weierstraß 1872), e.g., f (x) = ∞
n=0
sin 3nx
2n
;
(ii) the problem of interchangeability of limit operations.
A brief illustration of the kind of problems we have in mind in (ii) is the existence of
sequences of C∞-functions fn which converge uniformly to a limit function which
is of class C∞too, but the sequence of derivatives does not converge (in the sense
of classical analysis). A simple example is the sequence fn(x) =
1
n sin nx which
converges to 0 uniformly on R, but the sequence of derivatives f ′
n(x) = cos nx does
not converge, not even point-wise.
Our focus will be the distribution theory as developed mainly by L. Schwartz.
The Sect. 12 discusses some other important classes of generalized functions.
Distribution theory addresses the problem of generalizing the classical concept
of a function in such a way that the difﬁculties related to this classical concept are
resolved in the new theory. In concrete terms, this envisaged generalization of the
classical concept of functions should satisfy the following four conditions:
1. Every (locally integrable) function is a distribution.
2. Every distribution is differentiable, and the derivative is again a distribution.
3. As far as possible, the rules of calculation of classical analysis remain valid.
4. In distribution theory the interchangeability of the main limit operations is
guaranteed “automatically.”
As mentioned above, the realization of this program leads to a synthesis and a sim-
pliﬁcation. Nevertheless, we do not get mathematically well-deﬁned objects with the
very convenient properties (1), (2), (3), (4) for free. The mathematical work has to
be done at the level of deﬁnition of these objects. At this point distribution theory
might appear to be difﬁcult. However, in reality it is quite simple, and for practical
applications only a rather limited amount of mathematical knowledge is required.
There are different ways to deﬁne distributions; we mention the main three. One
can deﬁne distributions as:
D1 continuous linear functions on suitable spaces of smooth functions (“test
functions”);
D2 certain equivalence classes of suitable Cauchy sequences of (smooth) functions;
D3 “weak” derivatives of continuous functions (locally).

6
1
Introduction
Weconsidertheﬁrstwayasthemostconvenientandmostpowerfulsincemanyresults
from functional analysis can be used directly. Accordingly we deﬁne distributions
according to D1 and derive D2 and D3 as important characterizations of distributions.
Remark 1.1
Many details about the historical development of distribution theory
can be found in the book by J. Lutzen “The Prehistory of the Theory of Distributions,”
Springer-Verlag 1982. Here we mention only two important aspects very brieﬂy: It
was not in order to give the Dirac function a mathematical meaning that L. Schwartz
was interested in what later became the theory of distributions, but in order to solve
a relatively abstract problem formulated by Choquet and Deny (1944). But without
hesitation L. Schwartz addressed also practical problems in his new theory. As early
as 1946 he gave a talk entitled “Generalization of the concepts of functions and
derivatives” addressing an audience of electrical engineers.
For a much broader perspective on this subject as part of the theory of topological
vector space we recommend the book [1].
As we will learn later Schwartz distributions provide a suitable mathematical
framework for a solution theory of constant coefﬁcient partial differential operators.
Nevertheless there are many problems in analysis where this framework is too narrow,
for instance for a solution theory of linear partial differential operators with real
analytic coefﬁcients. Accordingly various other spaces of generalized functions have
been introduced and studied. In Chap. 12 we give a very short overview of the most
prominent spaces of generalized functions. Not all of them are deﬁned via duality.
Often in problems of (nonlinear) analysis one has to control the growth of a
function and the growth of a ﬁnite number of its derivatives. Thus for such problems
it is natural to work in a function space where this control is provided by the deﬁnition
of its norm. One of the simplest but widely used class of function spaces is the class
of Sobolev spaces which we introduce and study in Chap. 13. The last part of this
book relies on this class of spaces.
Reference
1. Bourbaki N. Eléments d’histoire des mathématiques. Espace vectoriels topologiques. Paris:
Hermann; 1960.

Chapter 2
Spaces of Test Functions
The spaces of test functions we are going to use are vector spaces of smooth (i.e.,
sufﬁciently often continuously differentiable) functions on open nonempty subsets
Ω ⊆Rn equipped with a “natural” topology. Accordingly we start with a general
methodtoequipavectorspaceV withatopologysuchthatthevectorspaceoperations
of addition and scalar multiplication become continuous, i.e., such that
A : V × V →V ,
A(x, y) = x + y,
x, y ∈V ,
M : K × V →V ,
M(λ, x) = λx,
λ ∈K, x ∈V
become continuous functions for this topology. This can be done in several different
but equivalent ways. The way we describe has the advantage of being the most
natural one for the spaces of test functions we want to construct. A vector space V
which is equipped with a topology T such that the functions A and M are continuous
is called a topological vector space, usually abbreviated as TVS. The test function
spaces used in distribution theory are concrete examples of topological vector spaces
where, however, the topology has the additional property that every point has a
neighborhood basis consisting of (absolutely) convex sets. These are called locally
convex topological vector spaces, abbreviated as LCVTVS.
2.1
Hausdorff Locally Convex Topological Vector Spaces
To begin we recall the concept of a topology. To deﬁne a topology on a set X means
to deﬁne a system T of subsets of X which has the following properties:
T1 X, ∅∈T (∅denotes the empty set);
T2 Wi ∈T , i ∈I ⇒
i∈I Wi ∈T (I any index set);
T3 W1, . . . , WN ∈T , N ∈N ⇒N
j=1 Wj ∈T .
The elements of T are called open and their complements closed sets of the
topological space (X, T ).
© Springer International Publishing Switzerland 2015
7
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_2

8
2
Spaces of Test Functions
Example 2.1
1. Deﬁne Tt = {∅, X}. Tt is called the trivial topology on X.
2. Deﬁne Td to be the system of all subsets of X including X and ∅. Td is called the
discrete topology on X.
3. The usual topology on the real line R has as open sets all unions of open intervals
]a, b[ = {x ∈R : a < x < b}.
Note that according to T3 only ﬁnite intersections are allowed. If one would take here
the intersection of inﬁnitely many sets, the resulting concept of a topology would not
be very useful. For instance, every point a ∈R is the intersection of inﬁnitely many
open intervals In = ]a −1
n, a + 1
n[, a = ∩n∈N. Hence, if in T3 inﬁnite intersections
were allowed, all points would be open, thus every subset would be open (see discrete
topology), a property which in most cases is not very useful.
If we put any topology on a vector space, it is not assured that the basic vector
space operations of addition and scalar multiplication will be continuous. A fairly
concrete method to deﬁne a topology T on a vector space V so that the resulting
topological space (V , T ) is actually a topological vector space, is described in the
following paragraphs. The starting point is the concept of a seminorm on a vector
space as a real valued, subadditive, positive homogeneous and symmetric function.
Deﬁnition 2.1 Let V be a vector space over K. Any function q : V →R with the
properties
(i) ∀x, y ∈V : q(x + y) ≤q(x) + q(y) (subadditive),
(ii) ∀λ ∈K, ∀x ∈V q(λx) = |λ|q(x), (symmetric and positive homogeneous),
is called a seminorm on V . If a seminorm q has the additional property
(iii) q(x) = 0 ⇒x = 0,
then it is called a norm.
There are some immediate consequences which are used very often:
Lemma 2.1 For every seminorm q on a vector space V one has
1. q(0) = 0;
2. ∀x, y ∈V : |q(x) −q(y)| ≤q(x −y);
3. ∀x ∈V : 0 ≤q(x).
Proof The second condition in the deﬁnition of a seminorm gives for λ = 0 that
q(0x) = 0. But for any x ∈V one has 0x = 0 ≡the neutral element 0 in V
and the ﬁrst part follows. Apply subadditivity of q to x = y + (x −y) to get
q(x) = q(y + (x −y)) ≤q(y) + q(x −y). Similarly one gets for y = x + (y −x)
that q(y) ≤q(x) + q(y −x). The symmetry condition ii) of a seminorm says in
particular q(−x) = q(x), hence q(x −y) = q(y −x), and thus the above two
estimates together say ±(q(x) −q(y)) ≤q(x −y) and this proves the second part.
For y = 0 the second part says |q(x) −q(0)| ≤q(x), hence by observing q(0) = 0

2.1
Hausdorff Locally Convex Topological Vector Spaces
9
we get |q(x)| ≤q(x) and therefore a seminorm takes only nonnegative values and
we conclude.
2
Example 2.2
1. It is easy to show that the functions qi : Rn →R deﬁned by qi(x) = |xi| for
x = (x1, . . . , xn) ∈Rn are seminorms on the real vector space Rn but not norms
if n > 1. And it is well known that the system P = {q1, . . . , qn} can be used to
deﬁne the usual Euclidean topology on Rn.
2. More generally, consider any vector space V over the ﬁeld K and its algebraic
dual space V ∗= L(V ; K) deﬁned as the set of all linear functions T : V →K,
i.e. those functions which satisfy
T (αx + βy) = αT (x) + βT (y)
∀x, y ∈V ,
∀α, β ∈K.
Each such T ∈V ∗deﬁnes a seminorm qT on V by
qT (x) = |T (x)|
∀x ∈V.
3. For an open nonempty set Ω ⊂Rn, the set Ck(Ω) of all functions f : Ω →
K which have continuous derivatives up to order k is actually a vector space
over K and on it the following functions pK,m and qK,m are indeed seminorms.
Here K ⊂Ω is any compact subset and k ∈N is any nonnegative integer. For
0 ≤m ≤k and φ ∈Ck(Ω) deﬁne
pK,m(φ)
=
sup
x∈K, |α|≤m
|Dαφ(x)|,
(2.1)
qK,m(φ)
=
⎛
⎝
|α|≤m

K
|Dαφ(x)|2dx
⎞
⎠
1/2
.
(2.2)
The notation is as follows. For a multi-index α = (α1, . . . , αn) ∈Nn we denote
by Dα =
∂|α|
∂xα1
1 ···xαn
n
the derivative monomial of order |α| = α1 + · · · + αn, i.e.,
Dαφ(x) =
∂|α|φ
∂xα1
1 ···xαn
n (x), x = (x1, . . . , xn). Thus, for example for f ∈C3(R3), one
has in this notation: If α = (1, 0, 0), then |α| = 1 and Dαf = ∂f
∂x1 ; if α = (1, 1, 0),
then |α| = 2 and Dαf =
∂2f
∂x1∂x2 ; if α = (0, 0, 2), then |α| = 2 and Dαf = ∂2f
∂2x3 ;
if α = (1, 1, 1) then |α| = 3 and Dαf =
∂3f
∂x1∂x2∂x3 .
A few comments on these examples are in order. The seminorms given in the second
example play an important role in general functional analysis, those of the third will
be used later in the deﬁnition of the topology on the test function spaces used in
distribution theory.

10
2
Spaces of Test Functions
Recall that in a Euclidean space Rn the open ball Br(x) with radius r > 0 and
centre x is deﬁned by
Br(x) =

y ∈Rn : |y −x| < r

where |y −x| =
n
i=1 (yi −xi)2 is the Euclidean distance between the points
y = (y1, . . . , yn) and x = (x1, . . . , xn). Similarly one proceeds in a vector space
V on which a seminorm p is given: The open p-ball in V with centre x and radius
r > 0 is deﬁned by
Bp,r(x) = {y ∈V : p(y −x) < r} .
In this deﬁnition the Euclidean distance is replaced by the semidistance dp(y, x)
= p(y −x) between the points y, x ∈V . Note: If p is not a norm, then one can have
dp(y, x) = 0 for y ̸= x. In this case the open p-ball Bp,r(0) contains the nontrivial
subspace N(p) = {y ∈V : p(y) = 0}. Nevertheless these p-balls share all essential
properties with balls in Euclidean space.
1. Bp,r(x) = x + Bp,r, i.e., every point y ∈Bp,r(x) has the unique representation
y = x + z with z ∈Bp,r ≡Bp,r(0);
2. Bp,r is circular, i.e., y ∈Bp,r, α ∈K, |α| ≤1 implies αx ∈Bp,r;
3. Bp,r is convex, i.e., x, y ∈Bp,r and 0 ≤λ ≤1 implies λx + (1 −λ)y ∈Bp,r;
4. Bp,r absorbs the points of V , i.e., for every x ∈V there is a λ > 0 such that
λx ∈Bp,r;
5. The nonempty intersection Bp1,r1(x1) ∩Bp2,r2(x2) of two open p-balls contains
an open p-ball: Bp,r(x) ⊂Bp1,r1(x1) ∩Bp2,r2(x2).
For the proof of these statements see the Exercises.
In a ﬁnite dimensional vector space all norms are equivalent, i.e., they deﬁne the
same topology. However, this statement does not hold in an inﬁnite dimensional
vector space (see Exercises). As the above examples indicate, in an inﬁnite dimen-
sional vector space there are many different seminorms. This raises naturally two
questions: How do we compare seminorms? When do two systems of seminorms
deﬁne the same topology? A natural way to compare two seminorms is to compare
their values in all points. Accordingly one has:
Deﬁnition 2.2 For two seminorms p and q on a vector space V one says
a) p is smaller than q, in symbols p ≤q if, and only if, p(x) ≤q(x) ∀x ∈V ;
b) p and q are comparable if, and only if, either p ≤q or q ≤p.
The seminorms qi in our ﬁrst example above are not comparable. Among the
seminorms qK,m and pK,m from the third example there are many which are compa-
rable. Suppose two compact subsets K1 and K2 satisfy K1 ⊂K2 and the nonnegative
integers m1 is smaller than or equal to the nonnegative integer m2, then obviously
pK1,m1 ≤pK2,m2
and
qK1,m1 ≤qK2,m2.
In the Exercises we show the following simple facts about seminorms: If p is
a seminorm on a vector space V and r a positive real number, then rp deﬁned by

2.1
Hausdorff Locally Convex Topological Vector Spaces
11
(rp)(x) = rp(x) for all x ∈V is again a seminorm on V . The maximum p =
max {p1, . . . , pn} of ﬁnitely many seminorms p1, . . . , pn on V , which is deﬁned by
p(x) = max {p1(x), . . . , pn(x)} for all x ∈V , is a seminorm on V such that pi ≤p
for i = 1, . . . , n. This prepares us for a discussion of systems of seminorms on a
vector space.
Deﬁnition 2.3 A system P of seminorms on a vector space V is called ﬁltering if,
and only if, for any two seminorms p1, p2 ∈P there is a seminorm q ∈P and there
are positive numbers r1, r2 ∈R+ such that r1p1 ≤q and r2p2 ≤q hold.
Certainly, not all systems of seminorms are ﬁltering (see our ﬁrst ﬁnite-
dimensional example). However it is straightforward to construct a ﬁltering system
which contains a given system: Given a system P0 on a vector space V one deﬁnes
the system P = P(P0) generated by P0 as follows:
q ∈P ⇔∃p1, . . . , pn ∈P0 ∃r1, . . . , rn ∈R+ : q = max {r1p1, . . . , rnpn} .
One can show that P(P0) is the minimal ﬁltering system of seminorms on V that
contains P0. In our third example above we considered the following two systems
of seminorms on V = Ck(Ω):
Pk(Ω)
=

pK,m : K ⊂Ω, K compact, 0 ≤m ≤k

,
Qk(Ω)
=

qK,m : K ⊂Ω, K compact, 0 ≤m ≤k

.
In the Exercises it is shown that both are ﬁltering.
Our ﬁrst use of the open p-balls is to deﬁne a topology.
Theorem 2.1 Suppose that P is a ﬁltering system of seminorms on a vector space
V . Deﬁne a system TP of subsets of V as follows: A subset U ⊂V belongs to TP, if
and only if, either U = ∅or
∀x ∈U ∃p ∈P, ∃r > 0 : Bp,r(x) ⊂U.
Then TP is a topology on V in which every point x ∈V has a neighborhood basis
Vx consisting of open p-balls, Vx =

Bp,r(x) : p ∈P, r > 0

.
Proof
Suppose we are given Ui ∈TP, i ∈I. We are going to show that U =
∪i∈IUi ∈TP. Take any x ∈U, then x ∈Ui for some i ∈I. Thus Ui ∈TP implies:
There are p ∈P and r > 0 such that Bp,r(x) ⊂Ui. It follows that Bp,r(x) ⊂U,
hence U ∈TP. Next assume that U1, . . . , Un ∈TP are given. Denote U = ∩n
i=1Ui
and consider x ∈U ⊂Ui, i = 1, . . . , n. Therefore, for i = 1, . . . , n, there are
pi ∈P and ri > 0 such that Bpi,ri(x) ⊂Ui. Since the system P is ﬁltering, there
is a p ∈P and there are ρi > 0 such that ρipi ≤p for i = 1, . . . , n. Deﬁne
r = min {ρ1r1, . . . , ρnrn}. It follows that Bp,r(x) ⊂Bpi,ri(x) for i = 1, . . . , n and
therefore Bp,r(x) ⊂∩n
i=1Ui = U. Hence the system TP satisﬁes the three axioms
of a topology. By deﬁnition TP is the topology deﬁned by the system Vx of open
p-balls as a neighborhood basis of a point x ∈V .
2
This result shows that there is a unique way to construct a topology on a vector
space as soon as one is given a ﬁltering system of seminorms. Suppose now that two

12
2
Spaces of Test Functions
ﬁltering systems P and Q of seminorms are given on a vector space V . Then we get
two topologies TP and TQ on V and naturally one would like to know how these
topologies compare, in particular when they are equal. This question is answered in
the following proposition.
Proposition 2.1 Given two ﬁltering systems P and Q on a vector space V , construct
the topologies TP and TQ on V according to Theorem (2.1). Then the following two
statements are equivalent:
(i) TP = TQ.
(ii) ∀p ∈P∃q ∈Q ∃λ > 0 : p ≤λq and ∀q ∈Q ∃p ∈P ∃λ > 0 : q ≤λp.
Two systems P and Q of seminorms on a vector space V are called equivalent, if,
and only if, any of these equivalent conditions holds.
The main technical element of the proof of this proposition is the following ele-
mentary but widely used lemma about the relation of open p-balls and their deﬁning
seminorms. Its proof is left as an exercise.
Lemma 2.2 Suppose that p and q are two seminorms on a vector space V . Then,
for any r > 0 and R > 0, the following holds:
p ≤r
R q
⇔
for any x ∈V : Bq,R(x) ⊆Bp,r(x).
(2.3)
Proof (Proof of 2.1) Assume condition (i). Then every open p-ball Bp,r(x) is open
for the topology TQ, hence there is an open q-ball Bq,R(x) ⊂Bp,r(x). By the lemma
we conclude that p ≤r
Rq. Condition (i) also implies that every open q-ball is open
for the topology TP, hence we deduce p ≤λq for some 0 < λ. Therefore condition
(ii) holds.
Conversely, suppose that condition (ii) holds. Then, using again the lemma one
deduces: For every open p-ball Bp,r(x) there is an open q-ball Bq,R(x) ⊂Bp,r(x)
and for every open q-ball Bq,R(x) there is an open p-ball Bp,r(x) ⊂Bq,R(x). This
then implies that the two topologies TP and TQ coincide.
2
Recall that a topological space is called Hausdorff if any two distinct points can
be separated by disjoint neighborhoods. There is a convenient way to decide when
the topology TP deﬁned by a ﬁltering system of seminorms is Hausdorff.
Proposition 2.2
Suppose P is a ﬁltering system of seminorms on a vector space
V . Then the topology TP is Hausdorff if, and only if, for every x ∈V , x ̸= 0, there
is a seminorm p ∈P such that p(x) > 0.
Proof Suppose that the topological space (V , TP) is Hausdorff and x ∈V is given,
x ̸= 0. Then there are two open balls Bp,r(0) and Bq,R(x) which do not intersect.
By deﬁnition of these balls it follows that p(x) ≥r > 0 and the condition of
the proposition holds. Conversely assume that the condition holds and two points
x, y ∈V , x −y ̸= 0 are given. There is a p ∈P such that 0 < 2r = p(x −y).
Then the open balls Bp,r(x) and Bp,r(y) do not intersect. (If z ∈V were a point
belonging to both balls, then we would have p(z −x) < r and p(z −y) < r and

2.1
Hausdorff Locally Convex Topological Vector Spaces
13
therefore 2r = p(x −y) = p(x −z + z −y) ≤p(x −z) + p(z −y) < r + r = 2r,
a contradiction). Hence the topology TP is Hausdorff.
2
Finally, we discuss the continuity of the basic vector space operations of addition
and scalar multiplication with respect to the topology TP deﬁned by a ﬁltering system
P of seminorms on a vector space V . Recall that a function f : E →F from a
topological space E into a topological space F is continuous at a point x ∈E if, and
only if, the following condition is satisﬁed: For every neighborhood U of the point
y = f (x) in F there is a neighborhood V of x in E such that f (V ) ⊂U, and it is
enough to consider instead of general neighborhoods U and V only elements of a
neighborhood basis of f (x), respectively x.
Proposition 2.3 Let P be a ﬁltering system of seminorms on a vector space V . Then
addition (A) and scalar multiplication (M) of the vector space V are continuous
with respect to the topology TP, hence (V , TP) is a topological vector space. This
topological vector space is usually denoted by
(V , P)
or
V [P].
Proof We show that the addition A : V ×V →V is continuous at any point (x, y) ∈
V ×V . Naturally, the product space V ×V is equipped with the product topology of
TP. Given any open p-ball Bp,2r(x +y) for some r > 0, then A(Bp,r(x)×Bp,r(y)) ⊂
Bp,2r(x+y) since for all (x′, y′) ∈Bp,r(x)×Bp,r(y) we have p(A(x′, y′)−A(x, y)) =
p((x′ + y′) −(x + y)) = p(x′ −x + y −y′) ≤p(x′ −x) + p(y′ −y) < r + r = 2r.
Continuity of scalar multiplication M is proved in a similar way.
2
We summarize our results in the following theorem.
Theorem 2.2 Let P be a ﬁltering system of seminorms on a vector space V . Equip V
with the induced topology TP. Then (V , TP) = V [TP] is a locally convex topological
vector space. It is Hausdorff or a HLCVTVS if, and only if, for every x ∈V , x ̸= 0,
there is a p ∈P such that p(x) > 0.
Proof By Theorem 2.1 every point x ∈V has a neighbourhood basis Vx consisting
of open p-balls. These balls are absolutely convex (i.e. y, z ∈Bp,r(x), α, β ∈K,
α + β = 1, |α| + |β| ≤1 implies αy + βz ∈Bp,r(x)) by the properties of p-balls
listed earlier. Hence by Proposition 2.3 V [TP] is a LCTVS. Finally by Proposition
2.2 we conclude.
2
2.1.1
Examples of HLCTVS
The examples of HLCTVS which we are going to discuss serve a dual purpose.
Naturally they are considered in order to illustrate the concepts and results introduced
above. Then later they will be used as building blocks of the test function spaces used
in distribution theory.
1. Recall the ﬁltering systems of seminorms Pk(Ω) and Qk(Ω) introduced earlier
on the vector space Ck(Ω) of k times continuously differentiable functions on

14
2
Spaces of Test Functions
an open nonempty subset Ω ⊆Rn. With the help of Theorem 2.2 it is easy to
show that both (Ck(Ω), Pk(Ω)) and (Ck(Ω), Qk(Ω)) are Hausdorff locally convex
topological vector spaces.
2. Fix a compact subset K of some open nonempty set Ω ⊆Rn and consider the
space C∞
K (Ω) of all functions φ : Ω →K which are inﬁnitely often differentiable
on Ω and which have their support in K, i.e., supp f ⊆K. On C∞
K (Ω) consider
the systems of semi-norms
PK(Ω) =

pK,m : m = 0, 1, 2, . . .

QK(Ω) =

qK,m : m = 0, 1, 2, . . .

introduced in Eq. (2.1), respectively in Eq. (2.2). Both systems are obviously
ﬁltering, and both pK,m and qK,m are norms on C∞
K (Ω). In the Exercises it is
shown that both systems are equivalent and thus we get that
DK(Ω) = (C∞
K (Ω), PK(Ω)) = (C∞
K (Ω), QK(Ω))
(2.4)
is a Hausdorff locally convex topological vector space.
3. Now let Ω ⊆Rn be an open nonempty subset which may be unbounded. Consider
the vector space Ck(Ω) of functions φ : Ω →K which have continuous deriva-
tives up to order k. Introduce two families of symmetric and subadditive functions
Ck(Ω) →[0, +∞] by deﬁning, for l = 0, 1, 2, . . . , k and m = 0, 1, 2, . . . ,
pm,l(φ)
=
supx∈Ω, |α|≤l (1 + x2)m/2|Dαφ(x)|,
qm,l(φ)
=
( 
|α|≤l

Ω (1 + x2)m/2|Dαφ(x)|2dx)1/2.
For x = (x1, . . . , xn) ∈Rn we use the notation x2 = x2
1 +· · ·+x2
n and |x| =
√
x2.
Deﬁne the following subspace of Ck(Ω):
Ck
m(Ω) =

φ ∈Ck(Ω) : pm,l(φ) < ∞, l = 0, 1, . . . , k

.
Then the system of norms

pm,l : 0 ≤l ≤k

is ﬁltering on this subspace and thus

Ck
m(Ω),

pm,l : 0 ≤l ≤k

is a HLCTVS. Ck
m(Ω) is the space of continuously
differentiable functions which decay at inﬁnity (if Ω is unbounded), with all
derivatives of order ≤k, at least as |x|−m. Similarly one can build a HLCTVS
space by using the system of norms qm,l, 0 ≤l ≤k.
4. In this example we use some basic facts from Lebesgue integration theory [1].
Let Ω ⊂Rn be a nonempty measurable set. On the vector space L1
loc(Ω) of all
measurable functions f : Ω →K which are locally integrable, i.e., for which
∥f ∥K =

K
|f (x)|dx
is ﬁnite for every compact subset K ⊂Ω, consider the system of seminorms
P = {∥·∥K : K ⊂Ω, K compact}. Since the ﬁnite union of compact sets is
compact, it follows easily that this system is ﬁltering. If f ∈L1
loc(Ω) is given and
if f ̸= 0, then there is a compact set K such that ∥f ∥K > 0, since f ̸= 0 means

2.1
Hausdorff Locally Convex Topological Vector Spaces
15
that f is different from zero on a set of positive Lebesgue measure. Therefore,
by Theorem 2.2, the space
(L1
loc(Ω), {∥·∥K : K ⊂Ω, K compact} )
is a HLCTVS.
2.1.2
Continuity and Convergence in a HLCVTVS
Since the topology of a LCTVS V [P] is deﬁned in terms of a ﬁltering system P
of seminorms it is, in most cases, much more convenient to have a characterization
of the basic concepts of convergence, of a Cauchy sequence, and of continuity in
terms of the seminorms directly instead of having to rely on the general topological
deﬁnitions. Such characterizations will be given in this subsection.
Recall: A sequence (xi)i∈N of points xi = (xi
1, . . . , xi
n) ∈Rn is said to converge
if, and only if, there is a point x ∈Rn such that for every open Euclidean ball
Br(x) = {y ∈Rn : |y −x| < r} only a ﬁnite number of elements of the sequence
are not contained in this ball, i.e., there is an index i0, depending on r > 0, such
that xi ∈Br(x) for all i ≥i0, or expressed directly in terms of the Euclidean norm,
|xi −x| < r for all i ≥i0.
Similarly one proceeds in a general HLCTVS V [P] where now however instead
of the Euclidean norm | · | all the seminorms p ∈P have to be taken into account.
Deﬁnition 2.4 Let V [P] be a HLCTVS and (xi)i∈N a sequence in V [P]. Then one
says:
1. The sequence (xi)i∈N converges (in V [P]) if, and only if, there is an x ∈V
(called a limit point of the sequence) such that for every p ∈P and for every
r > 0 there is an index i0 = i0(p, r) depending on p and r such that p(x−xi) < r
for all i ≥i0.
2. The sequence (xi)i∈N is a Cauchy sequence if, and only if, for every p ∈P
and every r > 0 there is an index i0 = i0(p, r) such that p(xi −xj) < r for all
i, j ≥i0.
The following immediate results are well known in Rn.
Theorem 2.3
(a) Every convergent sequence in a LCTVS V [P] is a Cauchy sequence.
(b) In a HLCTVS V [P] the limit point of a convergent sequence is unique.
Proof Suppose a sequence (xi)i∈N converges in V [P] to x ∈V . Then, for any p ∈P
and any r > 0, there is an i0 ∈N such that p(x −xi) < r/2 for all i ≥i0. Therefore,
for all i, j ≥i0, one has p(xi−xj) = p((x−xj)+(xi−x)) ≤p(x−xj)+p(xi−x) <
r
2 + r
2 = r, hence (xi)i∈N is a Cauchy sequence and part (a) follows.

16
2
Spaces of Test Functions
Suppose V [P] is a HLCTVS and (xi)i∈N is a convergent sequence in V [P].
Assume that for x, y ∈V the condition in the deﬁnition of convergence holds, i.e.,
for every p ∈P and every r > 0 there is an i1 such that p(x −xi) < r for all i ≥i1
and there is an i2 such that p(y −xi) < r for all i ≥i2. Then, for all i ≥max {i1, i2},
p(x −y) = p(x −xi + xi −y) ≤p(x −xi) + p(xi −y) < r + r = 2r, and since
r > 0 is arbitrary, it follows that p(x −y) = 0. Since this holds for every p ∈P
and V [P] is Hausdorff, we conclude (see Proposition 2.2) that x = y and thus part
(b) follows.
2
Part (a) of Theorem 2.3 raises naturally the question whether the converse holds
too, i.e. whether every Cauchy sequence converges. In general, this is not the case.
Spaces in which this statement holds are distinguished according to the following
deﬁnition.
Deﬁnition 2.5 A HLCTVS in which every Cauchy sequence converges is called
sequentially complete.
Example 2.3
1. Per construction, the ﬁeld R of real numbers equipped with the absolute value |·|
as a norm is a sequentially complete HLCTVS.
2. The Euclidean spaces (Rn, | · |), n=1,2, . . . are HLCTVS. Here | · | denotes the
Euclidean norm.
3. For any Ω ⊂Rn, Ω open and nonempty, and k=0,1,2, . . . , the space
Ck(Ω)[Pk(Ω)]
is a sequentially complete HLCTVS. This is shown in the Exercises. Recall the
deﬁnition
Pk(Ω) =

pK,m : K ⊂Ω, K compact, 0 ≤m ≤k

.
Note that Ck(Ω)[Pk(Ω)] is equipped with the topology of uniform convergence
of all derivatives of order ≤k on all compact subsets of Ω.
Compared to a general topological vector space one has a fairly explicit description of
the topology in a locally convex topological vector space. Here, as we have learned,
each point has a neighborhood basis consisting of open balls, and thus formulating
the deﬁnition of continuity one can completely rely on these open balls. This then has
an immediate translation into conditions involving only the systems of seminorms
which deﬁne the topology. Suppose that X[P] and Y[Q] are two LCTVS. Then a
function f : X →Y is said to be continuous at x0 ∈X if, and only if, for every
open q-ball Bq,R(f (x0)) in Y[Q] there is an open p-ball Bp,r(x) in X[P] which is
mapped by f into Bq,R(f (x0)). This can also be expressed as follows:
Deﬁnition 2.6 Assume that X[P] and Y[Q] are two LCTVS. A function
f : X →Y is said to be continuous at x0 ∈X if, and only if, for every seminorm
q ∈Q and every R > 0 there are p ∈P and r > 0 such that for all x ∈X the
condition p(x −x0) < r implies q(f (x) −f (x0)) < R. f is called continuous on
X if, and only if, f is continuous at every point x0 ∈X.

2.1
Hausdorff Locally Convex Topological Vector Spaces
17
Our main interest, however, are linear functions from one locally convex topological
vector space to another. For them one can give a characterization of continuity which
in most cases, in particular in concrete examples, is much easier to verify. This
characterization is prepared by the following deﬁnition.
Deﬁnition 2.7
Assume that X[P] and Y[Q] are two LCTVS. A linear function
f : X →Y is said to be bounded if, and only if, for every seminorm q ∈Q there
are p ∈P and λ ≥0 such that for all x ∈X one has
q(f (x)) ≤λp(x).
(2.5)
The announced characterization of continuity now has a simple formulation.
Theorem 2.4 Let V [P] and Y[Q] be two LCTVS and f : X →Y a linear function.
Then f is continuous if, and only if, it is bounded.
Proof
Suppose that f is bounded, i.e., given q ∈Q there are p ∈P and λ ≥0
such that q ◦f ≤λp. It follows for any x, y ∈X: q(f (y) −f (x)) = q(f (x −y)) ≤
λp(y −x). Continuity of f at x is now evident: Given q ∈Q and R > 0, take r = R
λ
and the seminorm p ∈P from the boundedness condition.
Conversely assume that f is continuous. Then f is continuous at 0 ∈X. Hence,
given q ∈Q and R > 0 there are p ∈P and r > 0 such that p(x) < r implies
q(f (x)) < R (we use here that f (0) = 0 for a linear function). This shows: Bp,r(0) ⊆
Bq◦f ,R(0) and therefore by Lemma 2.2 we conclude that q ◦f ≤
R
r p, i.e., f is
bounded.
2
The proof of this theorem shows actually some further details about continuity of
linear functions on LCTVS. We summarize them as a corollary.
Corollary 2.1
Let X[P] and Y[Q] be two LCTVS and f : X →Y a linear
function. Then the following statements are equivalent.
1. f is continuous at the origin x = 0.
2. f is continuous at some point x ∈X.
3. f is continuous.
4. f is bounded.
5. f is bounded on some open ball Bp,r(0) in X[P].
Deﬁnition 2.8 The topological dual X′[P] of a Hausdorff toplogical vector space
X[P] over the ﬁeld K is by deﬁnition the space of all continuous linear functions
X[P] →K.
We conclude this subsection with a discussion of an important special case of a
HLCTVS. Suppose that X[P] is a HLCTVS and that the ﬁltering system of semi-
norms P is countable, i.e., P = {pi : i ∈N} with pi ≤pi+1 for all i = 0, 1, 2, . . . .
Then the topology TP of X[P] can be deﬁned in terms of a metric d, i.e., a function
d : X × X →R with the following properties:
1. d(x, y) ≥0 for all x, y ∈X;
2. d(x, y) = d(y, x) for all x, y ∈X;

18
2
Spaces of Test Functions
3. d(x, y) ≤d(x, z) + d(z, y) for all x, y, z ∈X;
4. d(x, y) = 0 ⇔x = y.
In terms of the given system of seminorms, the metric can be expressed as:
d(x, y) =
∞

i=0
1
2i
pi(x −y)
1 + pi(x −y).
(2.6)
In the Exercises we show that this function is indeed a metric on X which deﬁnes
the given topology by using as open balls with centre x and radius r > 0 the sets
Bd,r(x) = y ∈X : d(y, x) < r. A HLCTVS X[P] is called metrizable if, and only
if, its topology TP can be deﬁned in terms of a metric. Some other special cases are
addressed in the Exercises as well.
We conclude this section with an example of a complete metrizable HLCTVS
which will play an important role in the deﬁnition of the basic test function spaces.
Proposition 2.4 Let Ω ⊂Rn be any nonempty open set and K ⊂Ω any compact
subset. Then the space DK(Ω) introduced in (2.4) is a complete metrizable HLCTVS.
Proof
That this space is metrizable is clear from the deﬁnition. The proof of
completeness is left as an exercise.
2
2.2
Basic Test Function Spaces of Distribution Theory
The previous sections provide nearly all concepts and results which are needed for the
deﬁnition of the standard test function spaces and the study of their basic properties.
The important items that are missing are the concepts of inductive and projective
limits of TVS. Here we take a practical approach by deﬁning these concepts not
abstractly but only in the context where they are used. We discuss now the underlying
test function spaces of general (Schwartz) distributions, of tempered distributions,
and of distributions with compact support.
2.2.1
The Test Function Space D(Ω) of C∞Functions of Compact
Support
For a nonempty open subset Ω ⊂Rn recall the spaces DK(Ω), K ⊂Ω compact, as
introduced in Eq. (2.4) and note the following:
K1 ⊂K2 ⊂Ω,
K1, K2 compact ⇒DK1(Ω) ⊂DK2(Ω).
The statement “DK1(Ω) ⊂DK2(Ω)” actually means two things:
1. The vector space C∞
K1(Ω) is a subspace of the vector space C∞
K2(Ω).

2.2
Basic Test Function Spaces of Distribution Theory
19
2. The restriction of the topology of DK2(Ω) to the subspace DK1(Ω) equals the
original topology of DK1(Ω) as deﬁned in Eq. (2.4).
Now denote by K = K(Ω) the set of all compact subsets of Ω and deﬁne
D(Ω) =

K∈K
DK(Ω).
(2.7)
Then D(Ω) is the set of functions φ : Ω →K of class C∞which have a compact
support in Ω. It is easy to show that this set is actually a vector space over K. In order
to deﬁne a topology on D(Ω) denote, for K ⊂Ω, K compact, by iK : DK(Ω) →
D(Ω) the identical embedding of DK(Ω) into D(Ω). Deﬁne on D(Ω) the strongest
locally convex topology such that all these embeddings iK, K ⊂Ω compact, are
continuous. Thus D(Ω) becomes a HLCTVS (see Exercises). In this way the test
function space D(Ω) of C∞-functions of compact support is deﬁned as the inductive
limit of the spaces DK(Ω), K ⊂Ω compact. According to this deﬁnition a function
φ ∈C∞(Ω) belongs to D(Ω) if, and only if, it vanishes in some neighborhood of
the boundary ∂Ω of Ω.
In the Exercises it is shown that given Ω ⊂Rn, Ω open and nonempty, there is a
sequence of compact sets Ki, i ∈N, with nonempty interior such that
Ki ⋐Ki+1 ⊂Ω
∀i ∈N,
∪∞
i=1Ki = Ω.
It follows that, for all i ∈N,
DKi(Ω) ⋐DKi+1(Ω)
(2.8)
with the understanding that DKi(Ω) is a proper subspace of DKi+1(Ω) and that the
restriction of the topology of DKi+1(Ω) to DKi(Ω) is just the original topology of
DKi(Ω).
One deduces that D(Ω) is actually the strict (because of (2.8)) inductive limit of
the sequence of complete metrizable spaces DKi(Ω), i ∈N:
D(Ω) = ∪∞
i=1DKi(Ω).
(2.9)
We collect some basic properties of the test function space D(Ω).
Theorem 2.5
The following statements hold for the test function space D(Ω) of
compactly supported C∞-functions on Ω ⊂Rn, Ω open and not empty:
1. D(Ω) is the strict inductive limit of a sequence of complete metrizable Hausdorff
locally convex topological vector spaces DKi(Ω).
2. D(Ω) is a HLCTVS.
3. A subset U ⊂D(Ω) is a neighborhood of zero if, and only if, U ∩DK(Ω) is a
neighborhood of zero in DK(Ω), for every compact subset K ⊂Ω.
4. D(Ω) is sequentially complete.
5. D(Ω) is not metrizable.

20
2
Spaces of Test Functions
Proof The ﬁrst statement has been established above. After further preparation the
remaining statements are shown in the Appendix.
2
For many practical purposes it is important to have a concrete description of the
notion of convergence in D(Ω). The following characterization results from basic
properties of inductive limits and is addressed in the Appendix.
Proposition 2.5
Let Ω ⊂Rn be a nonempty open set. Then a sequence (φi)i∈N
converges in the test function space D(Ω) if, and only if, there is a compact subset
K ⊂Ω such that φi ∈DK(Ω) for all i ∈N and this sequence converges in the
space DK(Ω).
According to the deﬁnition given earlier, a sequence (φi)i∈N converges in DK(Ω)
to φ ∈DK(Ω) ⇔∀r>0 ∀m∈N ∃i0 ∀i≥i0 pK,m(φ −φi) < r.
Proposition 2.6
Let Y[Q] be a locally convex topological vector space and f :
D(Ω) →Y[Q] a linear function. Then f is continuous if, and only if, for every
compact set K ⊂Ω the map f ◦iK : DK(Ω) →Y[Q] is continuous.
Proof
By deﬁnition the test function space carries the strongest locally convex
topology such that all the embeddings iK : DK(Ω) →D(Ω), K ⊂Ω compact, are
continuous. Thus, if f is continuous, all maps f ◦iK are continuous as compositions
of continuous maps. Conversely assume that all maps f ◦iK are continuous; then
given any neighborhood of zero U in Y[Q], we know that (f ◦iK)−1(U) = f −1(U)∩
DK(Ω) is a neighborhood of zero in DK(Ω). Since this holds for every compact
subsetK itfollows, bypart3ofTheorem2.5, thatf −1(U) ⊂D(Ω)isaneighborhood
of zero, hence f is continuous.
2
2.2.2
The Test Function Space S(Ω) of Strongly Decreasing
C∞-Functions on Ω
Again, Ω is an open nonempty subset of Rn, often Ω = Rn. A function φ ∈C∞(Ω)
is called strongly decreasing if, and only if, it and all its derivatives decrease faster
than C(1 + x2)−k, for any k ∈N, i.e., if, and only if, the following condition holds:
∀α∈Nn ∀m∈N0 ∃C ∀x∈Ω
|Dαφ(x)| ≤
C
(1 + x2)
m
2 .
(2.10)
Certainly, in this estimate the constant C depends in general on the function φ, the
order α of the derivative, and the exponent m of decay. Introduce
S0(Ω) =

φ ∈C∞(Ω) : φ is strongly decreasing

.
It is straightforward to show that S0(Ω) is a vector space. The norms
pm,l(φ) =
sup
x∈Ω, |α|≤l
(1 + x2)m/2|Dαφ(x)|
are naturally deﬁned on it for all m, l = 0, 1, 2, . . . . Equip this space with the topology
deﬁned by the ﬁltering system P(Ω) =

pm,l : m, l = 0, 1, 2, . . .

and introduce

2.2
Basic Test Function Spaces of Distribution Theory
21
the test function space of strongly decreasing C∞-functions as the Hausdorff locally
convex topological vector space
S(Ω) = (S0(Ω), P(Ω)).
(2.11)
NotethatS0(Ω)canbeexpressedintermsofthefunctionspacesCk
m(Ω)introduced
earlier as:
S0(Ω) = ∩∞
k,m=0 Ck
m(Ω).
Elementary facts about S(Ω) are collected in the following theorem.
Theorem 2.6 The test function space S(Ω) of strongly decreasing C∞-functions,
for any open and nonempty subset Ω ⊆Rn, is a complete metrizable HLCTVS.
Proof
Since the ﬁltering system of norms of this space is countable, S(Ω) is a
metrizable HLCTVS. Completeness of this space is shown in the Exercises. Further
properties will be presented in the Appendix.
2
2.2.3
The Test Function Space E(Ω) of All C∞-Functions on Ω
On the vector space C∞(Ω) we use the ﬁltering system of seminorms P∞(Ω) =
{pK,m: K ⊂Ω compact, m = 0, 1, 2, . . . } and then introduce
E(Ω) = (C∞(Ω), P∞(Ω))
(2.12)
as the test function space of all C∞-functions with uniform convergence for all
derivatives on all compact subsets.
Note that in contrast to elements in S(Ω) or D(Ω), elements in E(Ω) are not
restricted in their growth near the boundary of Ω. Again we give the basic facts
about this test function space.
Theorem 2.7 The test function space E(Ω) is a complete metrizable HLCTVS.
Proof By taking an increasing sequence of compact subsets Ki which exhaust Ω
(compare problem 14 of the Exercises) one shows that the topology can be deﬁned in
terms of a countable set of seminorms; hence this space is metrizable. Completeness
of the spaces Ck(Ω)[Pk(Ω)] for all k = 0, 1, 2, . . . easily implies completeness of
E(Ω).
2
2.2.4
Relation Between the Test Function Spaces D(Ω), S(Ω),
and E(Ω)
It is fairly obvious from their deﬁnitions that as sets one has
D(Ω) ⊂S(Ω) ⊂E(Ω).
(2.13)

22
2
Spaces of Test Functions
The following result shows that this relation also holds for the topological structures
as well.
Theorem 2.8
Let Ω ⊂Rn be a nonempty open subset. Then for the three test
function spaces introduced in the previous subsections the following holds: D(Ω) is
continuously embedded into S(Ω) and S(Ω) is continuously embedded into E(Ω).
Proof Denote i : D(Ω) →S(Ω) and j : S(Ω) →E(Ω) the identical embeddings.
We have to show that both are continuous. According to Proposition 2.6 the embed-
ding i is continuous if, and only if, the embeddings i ◦iK : DK(Ω) →S(Ω) are
continuous, for every compact subset K ⊂Ω. By Theorem 2.4 it sufﬁces to show
that these linear maps are bounded. Given any seminorm pm,l ∈P(Ω) we estimate,
for all φ ∈DK(Ω), as follows:
pm,l(i ◦iK(φ)) =
sup
x ∈Ω
|α| ≤l
(1 + x2)m/2|Dαφ(x)| =
sup
x ∈K
|α| ≤l
(1 + x2)m/2|Dαφ(x)|.
We deduce that, for all φ ∈DK(Ω), all K ⊂Ω compact, and all m, l = 0, 1, 2, . . . ,
pm,l(i ◦iK(φ) ≤CpK,l(φ)
where C = supx∈K (1 + x2)m/2 < ∞. Hence the map i ◦iK is bounded and we
conclude continuity of the embedding i.
Similarly we proceed for the embedding j. Take any seminorm pK,L ∈P∞(Ω)
and estimate, for all φ ∈S(Ω),
pK,l(j(φ)) =
sup
x ∈K
|α| ≤l
|Dαφ(x)| ≤
sup
x ∈Ω
|α| ≤l
(1 + x2)m/2|Dαφ(x)|,
i.e. pK,l(j(φ)) ≤pm,l(φ) for all φ ∈S(Ω), for all K ⊂Ω compact and all m, l =
0, 1, 2, . . . . Hence the embedding j is bounded and thus continuous.
2
2.3
Exercises
1. Let p be a seminorm on a vector space V . Show: The null space N(p) =
{x ∈V : p(x) = 0} is a linear subspace of V . N(p) is trivial if, and only if, p is
a norm on V .
2. Show: If p is a seminorm on a vector space V and r > 0, then rp, deﬁned
by (rp)(x) = rp(x) for all x ∈V , is again a seminorm on V . If p1, . . . , pn
are seminorms on V , then their maximum p = max {p1, . . . , pn}, deﬁned by
p(x) = max {p1(x), . . . , pn(x)} for all x ∈V , is a seminorm such that pi ≤p
for i = 1, . . . , n.

2.3
Exercises
23
3. Prove the ﬁve properties of open p-balls stated in the text.
4. Let p and q be two norms on Rn. Show: There are positive numbers r > 0 and
R > 0 such that rq ≤p ≤Rq. Thus on a ﬁnite dimensional space all norms are
equivalent.
5. Prove: The systems of seminorms Pk(Ω) and Qk(Ω) on Ck(Ω) are ﬁltering.
6. Let P be a ﬁltering system of seminorms on a vector space V . Deﬁne the p-balls
Bp,r(x) for p ∈P and r > 0 and the topology TP as in Theorem 2.1. Show:
Bp,r(x) ∈TP, i.e., the balls Bp,r(x) are open with respect to the topology TP
and thus it is consistent to call them open p-balls.
7. Prove Lemma 2.2.
Hints: Observe that Bq,R(x) ⊆Bp,r(x) implies: Whenever z ∈V satisﬁes
q(z) < R, then it follows that p(z) < r. Now ﬁx any y ∈V and deﬁne,
for any σ > 0, z =
R
q(y)+σ y; it follows that q(z) =
R
q(y)+σ q(y) < R, hence
p(z) =
R
q(y)+σ p(y) < r or p(y) <
r
R(q(y) + σ). Since σ > 0 is arbitrary, we
conclude that p(y) ≤
r
Rq(y) and since this holds for any y ∈V we conclude
that p ≤r
Rq. The converse direction is straightforward.
8. On the vector space V = Kn, deﬁne the following functions:
a) q(x) =
n
i=1 x2
i , x = (x1, . . . , xn) ∈Kn;
b) p(x) = max{|x1|, . . . , |xn|};
c) r(x) = |x1| + · · · + |xn|.
Show that these functions are actually norms on Kn and all deﬁne the same
topology.
9. Show that the two systems of seminorms Pk(Ω) and Qk(Ω) on C∞
K (Ω) (see
section “Examples of HLCVTVS”) are equivalent.
Hints: It is a straightforward estimate to get qK,l(φ) ≤CK,lpK,l(φ) for some
constant CK,l depending on l and |K| =

K dx. The converse estimate is
particularly simple for n = 1. There we use for φ ∈C∞
K (Ω) and α =
0, 1, 2, . . . the representation φ(α)(x) =
 x
−∞φ(α+1)(y)dy to estimate |φ(α)(x)| ≤
|K|1/2(

K |φ(α+1)(y)|2dy)1/2 and therefore pK,l(φ) ≤|K|1/2qK,l+1(φ). The
general case uses the same idea.
10. Using the fact that (R, | · |) is a sequentially complete HLCTVS, show that the
Euclidean spaces (Rn, | · |) are sequentially complete HLCTVS too, for any
n ∈N.
11. Show that Ck(Ω)[Pk(Ω)] is sequentially complete for Ω ⊂Rn, Ω open and
nonempty, k = 0, 1, 2, . . . .
Hints: The underlying ideas of the proof can best be explained for the case
Ω ⊂R and k = 1. Given a Cauchy sequence (fi)i∈N in C1(Ω)[P1(Ω)] and
any compact set K ⊂Ω and any r > 0, there is i0 ∈N such that pK,1(fi −
fj) < r for all i, j ≥i0. Observe, for m = 0 and m = 1 and every x ∈K:
|f (m)
i
(x)−f (m)
j
(x)| ≤pK,1(fi −fj). It follows, for m ∈{0, 1} and all x ∈K, that
(f (m)
i
(x))i∈N is a Cauchy sequence in K which is known to be complete. Hence
each of these Cauchy sequences converges to some number which we callf(m)(x),
i.e., f(m)(x) = lim i→∞f (m)
i
(x). Thus we get two functions f(m) : Ω →K. From

24
2
Spaces of Test Functions
the assumed uniform convergence on all compact subsets we deduce that both
functions are continuous. Apply uniform convergence again to show for any
x, y ∈Ω the following chain of identities: f(0)(x) −f(0)(y) = limi→∞(fi(x) −
fi(y)) = limi→∞
 x
y f (1)
i
(z)dz =
 x
y f(1)(z)dz. Deduce that f(0) is continuously
differentiable with derivative f(1) and that the given sequence converges to f(0)
in C1(Ω)[P1(Ω)].
12. Using the results of the previous problem show that the spaces DK(Ω) deﬁned
in (2.4) are complete.
13. Consider the spaces DK(Ω) and D(Ω) as introduced in (2.4), respectively (2.7)
and denote by ik : DK(Ω) →D(Ω) the identical embedding for K ⊂Ω
compact. Show: There is a strongest locally convex topology T on D(Ω) such
that all embeddings iK are continuous. This topology is Hausdorff.
14. Prove: For any open nonempty subset Ω ⊆Rn there is a sequence of compact
sets Ki ⊂Ω with the following properties: Each set Ki has a nonempty interior.
Ki is properly contained in Ki+1. ∪∞
i=1Ki = Ω.
Hints: For i ∈N deﬁne Ωi =

x ∈Ω : dist(x, ∂Ω) ≥1
i

and Bi = {x ∈Rn :
|x| ≤i}. Here dist(x, ∂Ω) denotes the Euclidean distance of the point x ∈Ω
from the boundary of Ω. Then show that the sets Ki = Bi ∩Ωi, for i sufﬁciently
large, have the properties as claimed.
15. Let Ω ⊆Rn be an open nonempty set. Show: For every closed ball Kr(x) =
{y ∈Rn : |y −x| ≤r} ⊂Ω with centre x ∈Ω and radius r > 0 there is a
φ ∈D(Ω), φ ̸= 0, with support suppφ ⊆Kr(x). Thus, in particular, D(Ω) is
not empty.
Hints: Deﬁne a function ρ : Rn →R by
ρ(x) =
⎧
⎨
⎩
0
:
for
|x| ≥1,
exp
−1
1−x2
:
for
|x| < 1,
(2.14)
and show that ρ ∈C∞(Rn). Then deﬁne φr(y) = ρ( y−x
r ) and deduce that
φr ∈D(Ω) has the desired support properties.
16. Prove: The space S(Ω) is complete.
Hints: One can use the fact that the spaces Ck(Ω)[Pk(Ω)] are complete, for any
k ∈N. The decay properties need some additional considerations.
Reference
1. GrauertH,FischerW.DifferentialundIntegralrechnungII.HeidelbergerTaschenbücher.Vol.36.
Berlin: Springer-Verlag; 1968.

Chapter 3
Schwartz Distributions
Aswehadmentionedintheintroduction, theSchwartzapproachtodistributiontheory
deﬁnes distributions as continuous linear functions on a test function space. The var-
ious classes of distributions are distinguished by the underlying test function spaces.
Before we come to the deﬁnition of the main classes of Schwartz distribution, we
collect some basic facts about continuous linear functions or functionals on a Haus-
dorff locally convex topological vector space (HLCTVS) and about spaces of such
functionals. Then the deﬁnition of the three main spaces of Schwartz distributions is
straightforward. Numerous examples explain this deﬁnition.
The remainder of this chapter introduces convergence of sequences and series of
distributions and discusses localization, in particular, support and singular support
of distributions.
3.1
The Topological Dual of an HLCTVS
Suppose that X is a vector space over the ﬁeld K on which a ﬁltering system P
of seminorms is given such that X[P] is an HLCTVS. The algebraic dual X∗of
X has been deﬁned as the set of all linear functions or functionals f : X →K.
The topological dual is deﬁned as the subset of those linear functions which are
continuous, i.e.,
X′ ≡X[P]′ =

f ∈X∗: f continuous

(3.1)
In a natural way, both X∗and X′ are vector spaces over K. As a special case of
Theorem 2.4, the following result is a convenient characterization of the elements of
the topological dual of a HLCTVS.
Proposition 3.1 SupposethatX[P]isaHLCTVSandf : X →Kalinearfunction.
Then the following statements are equivalent.
(a) f is continuous, i.e. f ∈X′.
(b) Thereisaseminormp ∈P andanonnegativenumberλsuchthat|f (x)| ≤λp(x)
for all x ∈X.
© Springer International Publishing Switzerland 2015
25
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_3

26
3
Schwartz Distributions
(c) There is a seminorm p ∈P such that f is bounded on the p-ball Bp,1(0).
Proof
The equivalence of statements (a) and (b) is just the special case Y[Q] =
K[{| · |}] of Theorem 2.4.
The equivalence of (b) and (c) follows easily from Lemma 2.2 if we introduce the
seminorm q(x) = |f (x)| on X and if we observe that then (b) says q ≤λp while (c)
translates into Bp,1(0) ⊆Bq,λ(0).
2
The geometrical interpretation of linear functionals is often helpful, in particular
in inﬁnite dimensional spaces. We give a brief review. Recall: A hyperplane through
the origin is a maximal proper subspace of a vector space X. If such a hyperplane is
given, there is a point a ∈X\H such that the vector space X over the ﬁeld K has
the representation
X = H + Ka,
i.e., every point x ∈X has the unique representation x = h + αa with h ∈H and
α ∈K. The announced geometrical characterization now is
Proposition 3.2 Let X[P] be a HLCTVS over the ﬁeld K.
(a) A linear functional f ∈X∗, f ̸= 0, is characterized by
(i) a hyperplane H ⊂X through the origin and
(ii) the value in a point x0 ∈X\H.
The connection between the functional f and the hyperplane is given by
H = ker f = {x ∈X : f (x) = 0}.
(b) A linear functional f on X is continuous if, and only if, in the geometric
characterization a) the hyperplane H is closed.
Proof
Given f ∈X∗, the kernel or null space ker f is easily seen to be a linear
subspace of X. Since f ̸= 0, there is a point in X at which f does not vanish.
By rescaling this point we get a point a ∈X\ker f with f (a) = 1. We claim that
H = ker f is a hyperplane. Given any point x ∈X observe x = x −f (x)a +f (x)a
where h = x−f (x)a ∈ker f since f (h) = f (x)−f (x)f (a) = 0 and f (x)a ∈Ka.
The representation x = h + αa with h ∈ker f and α ∈K is unique: If one has, for
some x ∈X, x = h1 + α1a = h2 + α2a with hi ∈ker f then h1 −h2 = (α1 −α2)a
and thus 0 = f (h1 −h2) = (α1 −α2)f (a) = α1 −α2, hence α1 = α2 and h1 = h2.
Conversely, assume that H is a hyperplane through the origin and a ∈X\H.
Then every point x ∈X has the unique representation x = h + αa with h ∈H
and α ∈K. Now deﬁne fH : X →K by fH(x) = fH(h + αa) = α. It is an
elementary calculation to show that fH is a well deﬁned linear function. Certainly
one has ker fH = H. This proves part (a).
In order to prove part (b), we have to show that H =
ker f is closed if, and
only if, the linear functional f is continuous. When f is continuous then ker f
is closed as the inverse image of the closed set {0}. Conversely, assume that H =
ker f is closed. Then its complement X\H is open and there is some open p-ball
Bp,r(a) ⊂X\H around the point a, f (a) = 1. In order to prove continuity of f it

3.2
Deﬁnition of Distributions
27
sufﬁces, according to Proposition 3.1, to show that f is bounded on the open ball
Bp,r(0). This is done indirectly. If there were some x ∈Bp,r(0) with |f (x)| ≥1
then y = a −
x
f (x) ∈Bp,r(a) and f (y) = f (a) −f (x)
f (x) = 1 −1 = 0, i.e., y ∈H, a
contradiction. Therefore, f is bounded on Bp,r(0) by 1 and we conclude.
2
3.2
Deﬁnition of Distributions
For an open nonempty subset Ω ⊂Rn, we have introduced the test function spaces
D(Ω), S(Ω), and E(Ω) as HLCTVSs. Furthermore the relation
D(Ω) ⊂S(Ω) ⊂E(Ω)
with continuous embeddings in both cases has been established (see Theorem 2.8).
This section gives the basic deﬁnitions of the three basic classes of distributions
as elements of the topological dual space of these test function spaces. Elements
of the topological dual D′(Ω) of D(Ω) are called distributions on Ω. Elements of
the topological dual S′(Ω) of S(Ω) are called tempered distributions and elements
of topological E′(Ω) of E(Ω) are called distributions of compact support. Later,
after further preparation, the names for the latter two classes of distributions will be
apparent. The continuous embeddings mentioned above imply the following relation
between these three classes of distributions and it justiﬁes calling elements in S′(Ω),
respectively in E′(Ω), distributions:
E′(Ω) ⊂S′(Ω) ⊂D′(Ω).
(3.2)
We proceed with a more explicit discussion of distributions.
Deﬁnition 3.1 A distribution T on an open nonempty subset Ω ⊂Rn is a contin-
uous linear functional on the test function space D(Ω) of C∞-functions of compact
support. The set of all distributions on Ω equals the topological dual D′(Ω) of
D(Ω).
Another way to deﬁne a distribution on a nonempty open subset Ω ⊂Rn is to
recall Proposition 2.6 and to deﬁne: A linear functional T on D(Ω) is a distribution
on Ω if, and only if, its restriction to the spaces DK(Ω) is continuous for every
compact subset K ⊂Ω. TakingTheorem 2.4 into account one arrives at the following
characterization of distributions.
Theorem 3.1
A linear functional T : D(Ω) →K is a distribution on the open
nonempty set Ω ⊂Rn if, and only if, for every compact subset K ⊂Ω there exist a
number C ∈R+ and a natural number m ∈N, both depending in general on K and
T , such that for all φ ∈DK(Ω) the estimate
|T (φ)| ≤CpK,m(φ)
(3.3)
holds.

28
3
Schwartz Distributions
An equivalent way to express this is the following:
Corollary 3.1 A linear function T : D(Ω) →K is a distribution on Ω if, and only
if, for every compact subset K ⊂Ω there is an integer m such that
p′
K,m(T ) = sup

|T (φ)| : φ ∈DK(Ω), pK,m(φ) ≤1

(3.4)
is ﬁnite and then
|T (φ)| ≤p′
K,m(T )pK,m(φ)
∀φ ∈DK(Ω).
The proof of the corollary is left as an exercise. This characterization leads to the
important concept of the order of a distribution.
Deﬁnition 3.2 Let T be a distribution on Ω ⊂Rn, Ω open and nonempty, and let
K ⊂Ω be a compact subset. Then the local order O(T , K) of T on K is deﬁned
as the minimum of all natural numbers m for which (3.3) holds. The order O(T ) of
T is the supremum over all local orders.
In terms of the concept of order, Theorem 3.1 says: Locally every distribution is
of ﬁnite order, i.e. a ﬁnite number of derivatives of the test functions φ are used in
the estimate (3.3) (recall the deﬁnition of the seminorms pK,m in Eq. (2.1)).
Remark 3.1
1. As the topological dual of the HLCTVS D(Ω), the set of all distributions on an
open set Ω ⊂Rn forms naturally a vector space over the ﬁeld K. Addition and
scalar multiplication are explicitly given as follows: For all T , Ti ∈D′(Ω) and
all λ ∈K,
∀φ∈D(Ω)
(T1 + T2)(φ) = T1(φ) + T2(φ),
(λT )(φ) = λT (φ).
Thus, (T , φ) #→T (φ) is a bilinear function D′ × D →K.
2. According to their deﬁnition, distributions assign real or complex numbers T (φ)
to a test function φ ∈D(Ω). A frequently used alternative notation for the value
T (φ) of the function T is
T (φ) = ⟨T , φ⟩= ⟨T (x), φ(x)⟩.
3. In physics textbooks one often ﬁnds the notation

Ω T (x)φ(x)dx for the value
T (φ) of the distribution T at the test function φ. This suggestive notation is rather
formal since when one wants to make sense out of this expression the integral
sign used has little to do with the standard integrals (further details are provided
in the section on representation of distributions as “generalized” derivatives of
continuous functions).
4. The axiom of choice allows us to show that there are linear functionals on DK(Ω)
which are not continuous. But nobody has succeeded in giving an explicit example
of such a noncontinuous functional. Thus, in practice one does not encounter these
exceptional functionals.

3.2
Deﬁnition of Distributions
29
5. One may wonder why we spoke about D(Ω) as the test function space of distri-
bution theory. Naturally, D(Ω) is not given à priori. One has to make a choice.
The use of D(Ω) is justiﬁed à posteriori by many successful applications. Nev-
ertheless, there are some guiding principles for the choice of test function spaces
(compare the introductory remarks on the goals of distribution theory).
a) The choice of test function spaces as subspaces of the space of C∞-functions
on which all derivative monomials Dα act linearly and continuously ensure
that all distributions will be inﬁnitely often differentiable too.
b) Further restrictions on the subspace of C∞-functions as a test function space
depends on the intended use of the resulting space of generalized functions.
For instance, the choice of C∞-functions on Ω with compact support ensures
that the resulting distributions on Ω are not restricted in their behavior at the
boundary of the set Ω. Later we will see that the test function space of C∞-
functions which are strongly decreasing ensures that the resulting space of
generalized functions admits the Fourier transformation as an isomorphism,
which has many important consequences.
A number of concrete Examples will help to explain how the above deﬁnition oper-
ates in concrete cases. The ﬁrst class of examples show furthermore how distributions
generalize functions so that it is appropriate to speak about distributions as special
classes of generalized functions. Later, we will give an overview of some other
classes of generalized functions.
3.2.1
The Regular Distributions
Supposethatf : Ω →KisacontinuousfunctionontheopennonemptysetΩ ⊂Rn.
Then, for every compact subset K ⊂Ω the (Riemann) integral

K |f (x)|dx = C is
known to exist. Hence, for all φ ∈DK(Ω) one has


K
f (x)φ(x)dx
 ≤

K
|f (x)φ(x)|dx ≤sup
x∈K
|φ(x)|

K
|f (x)|dx.
It follows that If : D(Ω) →K is well deﬁned by
⟨If , φ⟩=

f (x)φ(x)dx
∀φ ∈D(Ω)
and that for all φ ∈DK(Ω) one has the estimate
|⟨If , φ⟩| ≤CpK,0(φ).
Elementary properties of the Riemann integral imply that If is a linear functional on
D(Ω). Since we could establish the estimate (3.3) in Theorem 3.1, it follows that If
is continuous and thus a distribution on Ω. In addition this estimate shows that the
local order and the order of the distribution If is 0.

30
3
Schwartz Distributions
Obviously these considerations apply to any f ∈C(Ω). Therefore, f #→If
deﬁnes a map I : C(Ω) →D′(Ω) which is easily seen to be linear. In the Exercises
it is shown that I is injective and thus provides an embedding of the space of all
continuous functions into the space of distributions.
Note that the decisive property we used for the embedding of continuous functions
into the space of distributions was that, for f ∈C(Ω) and every compact subset,
the Riemann integral C =

K |f (x)|dx is ﬁnite. Therefore, the same ideas allow
us to consider a much larger space of functions on Ω as distributions, namely the
space L1
loc(Ω) of all locally integrable functions on Ω. L1
loc(Ω) is the space of
all (equivalence classes of) Lebesgue’s measurable functions on Ω for which the
Lebesgue integral
||f | |1,K =

K
|f (x)|dx
(3.5)
is ﬁnite for every compact subset K ⊂Ω. Thus, the map I can be extended to a
map I : L1
loc(Ω) →D′(Ω) by the same formula: For every f ∈L1
loc(Ω) deﬁne
If : D(Ω) →K by
If (φ) =

f (x)φ(x)dx
∀φ ∈D(Ω).
The bound |If (φ)| ≤|f |1,K pK,0(φ) for all φ ∈DK(Ω) proves as above that If ∈
D′(Ω) for all f ∈L1
loc(Ω). A simple argument implies that I is a linear map
and in the Exercises we prove that I is injective, i.e., If = 0 in D′(Ω) if, and
only if, f = 0 in L1
loc(Ω). Therefore, I is an embedding of L1
loc(Ω) into D′(Ω).
The space L1
loc(Ω) is an HLCTVS when it is equipped with the ﬁltering system of
seminorms

|·1,K| : K ⊂Ω, compact

.Withrespecttothistopology, theembedding
I is continuous in the following sense. If (fj)j∈N is a sequence which converges to
zero in L1
loc(Ω), then, for every φ ∈D(Ω), one has limj→∞Ifj (φ) = 0 which
follows easily from the bound given above. We summarize our discussion as the
so-called embedding theorem.
Theorem 3.2
The space L1
loc(Ω) of locally integrable functions on an open
nonempty set Ω ⊂Rn is embedded into the space D′(Ω) of distributions on Ω
by the linear and continuous injection I. The image of L1
loc(Ω) under I is called the
space of regular distributions on Ω:
D′
reg(Ω) = I(L1
loc(Ω)) ⊂D′(Ω).
(3.6)
Note that under the identiﬁcation of f and If we have established the following
chain of relations:
C(Ω) ⊂Lr
loc(Ω) ⊆L1
loc(Ω) ⊂D′(Ω)
for any r ≥1, since for r > 1 the space of measurable functions f on Ω for which
|f |r is locally integrable is known to be contained in L1
loc(Ω).

3.2
Deﬁnition of Distributions
31
3.2.2
Some Standard Examples of Distributions
3.2.2.1
Dirac’s Delta Distribution
For any point a ∈Ω ⊂Rn deﬁne a functional δa : D(Ω) →K by
δa(φ) = φ(a)
∀φ ∈D(Ω).
Obviously δa is linear. For any compact subset K ⊂Ω, one has the following
estimate:
|δa(φ)| ≤C(a, K)pK,0(φ)
∀φ ∈DK(Ω)
where the constant C(a, K) equals 1 if a ∈K and C(a, K) = 0 otherwise. Therefore,
the linear functional δa is continuous on D(Ω) and thus a distribution. Its order
obviously is zero. In the Exercises it is shown that δa is not a regular distribution,
i.e., there is no f ∈L1
loc(Ω) such that δa(φ) =

f (x)φ(x)dx for all φ ∈D(Ω).
3.2.2.2
Cauchy’s Principal Value
It is easy to see that x #→
1
x is not a locally integrable function on the real line
R, hence I 1
x does not deﬁne a regular distribution. Nevertheless, one can deﬁne a
distribution on R which agrees with I 1
x on R\ {0}. This distribution is called Cauchy’s
principal value and is deﬁned by
⟨vp 1
x , φ⟩= lim
r→0

|x|≥r
φ(x)
x
dx.
(3.7)
We have to show that this limit exists and that it deﬁnes a continuous linear functional
on D(R). For a > 0 consider the compact interval K = [−a, a]. Take 0 < r < a
and calculate, for all φ ∈DK(R),

|x|≥r
φ(x)
x
dx =
 a
r
φ(x) −φ(−x)
x
dx.
If we observe that φ(x) −φ(−x) = x
 +1
−1 φ′(xt)dt, we get the estimate

φ(x) −φ(−x)
x
 ≤2 sup
y∈K
|φ′(y)| ≤2pK,1(φ),
and thus |
 a
r
φ(x)−φ(−x)
x
dx| ≤2apK,1(φ) uniformly in 0 < r < a, for all φ ∈DK(R).
It follows that this limit exists and that it has the value:
lim
r→0

|x|≥r
φ(x)
x
dx =
 ∞
0
φ(x) −φ(−x)
x
dx.
Furthermore, the continuity bound
|⟨vp 1
x , φ⟩| ≤|K|pK,1(φ)

32
3
Schwartz Distributions
for all φ ∈DK(R) follows. Therefore, vp 1
x is a well-deﬁned distribution on R
according to Theorem 3.1. Its order obviously is 1.
The above proof gives the following convenient formula for Cauchy’s principal
value:
⟨vp 1
x , φ⟩=
 ∞
0
φ(x) −φ(−x)
x
dx.
(3.8)
Test functions in D(R\ {0} ) have the property that they vanish in some neighbor-
hood of the origin (depending on the function). Hence, for these test function the
singular point x = 0 of 1
x is avoided, and thus it follows that
lim
r→0

|x|≥r
φ(x)
x
dx =

R
φ(x)
x
dx = ⟨I 1
x , φ⟩
∀φ ∈D(R\ {0} ).
Sometimes one also ﬁnds the notation vp

R
φ(x)
x dx for ⟨vp 1
x , φ⟩. The letters “vp” in
the notation for Cauchy’s principal value stand for the original French name “valeur
principale.”
3.2.2.3
Hadamard’s Principal Values
Closely related to Cauchy’s principal value is a family of distributions on R which
can be traced back to Hadamard. Certainly, for 1 < β < 2 the function
1
xβ is not
locally integrable on R+. We are going to deﬁne a distribution T on R+ which agrees
on R+\ {0} = (0, ∞) with the regular distribution Ix−β. For all φ ∈D(R) deﬁne
⟨T , φ⟩=
 ∞
0
φ(x) −φ(0)
xβ
dx.
Since again φ(x) −φ(0) = x
 1
0 φ′(xt)dt we can estimate
|φ(x) −φ(0)
xβ
| ≤|x|1−βpK,1(φ)
if φ ∈DK(R). Since now the exponent γ = 1−β is larger than −1, the integral exists
over compact subsets. Hence, T is well deﬁned on D(R). Elementary properties of
integrals imply that T is linear and the above estimate implies, as in the previous
example, the continuity bound. Therefore, T is a distribution on R.
If φ ∈D(R\ {0} ), then in particular φ(x) = 0 for all x ∈R, |x| ≤r for some
r > 0, and we get ⟨T , φ⟩=
 ∞
0
φ(x)
xβ dx = I 1
xβ (φ). Hence, on R\ {0} the distribution
T is regular.
Distributions like Cauchy’s and Hadamard’s principal values are also called
pseudo functions, since away from the origin x = 0 they coincide with the cor-
responding regular distributions. Thus, we can consider the pseudo functions as
extensions of the regular distributions to the point x = 0.

3.3
Convergence of Sequences and Series of Distributions
33
3.3
Convergence of Sequences and Series of Distributions
Often the need arises to approximate given distributions by “simpler” distributions,
for instance functions. For this one obviously needs a topology on the space D′(Ω)
of all distributions on a nonempty open set Ω ⊂Rn. A topology which sufﬁces for
our purposes is the so-called weak topology which is deﬁned on D′(Ω) by the system
of seminorms Pσ =

ρφ : φ ∈D(Ω)

. Here ρφ is deﬁned by
ρφ(T ) = |⟨T , φ⟩| = |T (φ)|
for all T ∈D′(Ω).
This topology is usually denoted by σ ≡σ(D′, D).
If not stated explicitly otherwise we consider D′(Ω) always equipped with this
topology σ. Then, from our earlier discussions on HLCTVS, we know in principle
what convergence in D′ means or what a Cauchy sequence of distributions is. For
clarity we write down these deﬁnitions explicitly.
Deﬁnition 3.3 Let Ω ⊂Rn be open and nonempty and let (Tj)j∈N be a sequence
of distributions on Ω, i.e., a sequence in D′(Ω). One says:
1. (Tj)j∈N converges in D′(Ω) if, and only if, there is a T ∈D′(Ω) such that for
every φ ∈D(Ω) the numerical sequence (Tj(φ))j∈N converges in K to T (φ).
2. (Tj)j∈N is a Cauchy sequence in D′(Ω) if, and only if, for every φ ∈D(Ω) the
numerical sequence (Tj(φ))j∈N is a Cauchy sequence in K.
Several simple examples will illustrate these deﬁnitions and how these concepts
are applied to concrete problems. All sequences we consider here are sequences of
regular distributions deﬁned by sequences of functions which have no limit in the
sense of functions.
Example 3.1
1. The sequence of C∞-functions fj(x) = sin jx on R certainly has no limit in the
sense of functions. We claim that the sequence of regular distributions Tj = Ifj
deﬁned by these functions converges in D′(R) to zero. For the proof take any
φ ∈D(R). A partial integration shows that
⟨Tj, φ⟩=

sin (jx)φ(x)dx = 1
j

cos (jx)φ′(x)dx
and we conclude that limj→∞⟨Tj, φ⟩= 0.
2. Delta sequences: δ-sequences are sequences of functions which converge in D′
to Dirac’s delta distribution. We present three examples of such sequences.
a) Consider the sequence of continuous functions tj(x) =
sin (jx)
x
and denote
Tj = Itj . Then
lim
j→∞Tj = πδ
in D′(R).

34
3
Schwartz Distributions
For the proof take any φ ∈D(R). Then the support of φ is contained in [−a, a]
for some a > 0. It follows that
⟨Tj, φ⟩
=
 +a
−a
sin (jx)
x
φ(x)dx
=
 +a
−a
sin (jx)
x
[φ(x) −φ(0)]dx +
 +a
−a
sin (jx)
x
φ(0)dx.
.
As in the ﬁrst example, one shows that
 +a
−a
sin (jx)
x
[φ(x) −φ(0)]dx = 1
j
 +a
−a
cos (jx) d
dx (φ(x) −φ(0)
x
)dx
converges to zero for j →∞. Then recall the integral:
 +a
−a
sin (jx)
x
dx =
 +ja
−ja
sin y
y
dy →j→∞
 +∞
−∞
sin y
y
dy = π.
We conclude that limj→∞⟨Tj, φ⟩= πφ(0) for every φ ∈D(R) which proves
the statement.
b) Take any nonnegative function f ∈L1(Rn) with

Rn f (x)dx = 1. Introduce
the sequence of functions fj(x) = j nf (jx) and the associated sequence of
regular distributions Tj = Ifj . We claim:
lim
j→∞Tj = δ
in D′(Rn).
The proof is simple. Take any φ ∈D(Rn) and calculate as above,
⟨Tj, φ⟩
=

Rn fj(x)φ(x)dx
=

Rn fj(x)[φ(x) −φ(0)]dx +

Rn fj(x)φ(0)dx.
To the ﬁrst term

Rn fj(x)[φ(x) −φ(0)]dx =

Rn j nf (jx)[φ(x) −φ(0)]dx
=

Rn f (y)[φ(y
j ) −φ(0)]dy
we apply Lebesgue’s dominated convergence theorem to conclude that the
limit j
→
∞of this term vanishes. For the second term note that

Rn fj(x)dx =

Rn f (y)dy = 1 for all j ∈N and we conclude.
As a special case of this result we mention that we can take in particular
f ∈D(Rn). This then shows that Dirac’s delta distribution is the limit in D′
of a sequence of C∞-functions of compact support.
c) For the last example of a delta sequence we start with the Gauss function on
Rn: g(x) = (π)−n
2 e−x2. Certainly 0 ≤g ∈L1(Rn) and thus we can proceed
as in the previous example. The sequence of scaled Gauss functions gj(x) =

3.3
Convergence of Sequences and Series of Distributions
35
j ng(jx) converges in the sense of distributions to Dirac’s delta distribution,
i.e., for every φ ∈D(Rn):
lim
j→∞⟨Igj , φ⟩= φ(0) = ⟨δ, φ⟩.
This example shows that Dirac’s delta can also be approximated by a sequence
of strongly decreasing C∞-functions.
3. Now we prove the Breit–Wigner formula. For each ε > 0 deﬁne a function
fε →R by
fε(x) =
ε
x2 + ε2 = Im
1
x −iε = i
2

1
x + iε −
1
x −iε

.
We claim that
lim
ε→0 Ifε = πδ
in D′(R).
(3.9)
Often this is written as
lim
ε→0
ε
x2 + ε2 = πδ
(Breit–Wigner formula).
This is actually a special case of a delta sequence: The function h(x) =
1
1+x2
satisﬁes 0 ≤h ∈L1(R) and

R h(x)dx = π. Thus, one can take hj(x) =
jh(jx) = fε(x) for ε = 1
j and apply the second result on delta sequences..
4. Closely related to the Breit–Wigner formula is the Sokhotski–Plemelji formula.
It reads
lim
ε→0
1
x ± iε = ∓iπδ + vp 1
x
in D′(R).
(3.10)
Both formulas are used quite often in quantum mechanics.
For any ε > 0 we have
1
x ± iε = Re
1
x ± iε + i Im
1
x ± iε
where
Re
1
x ± iε =
x
x2 + ε2 ≡gε(x),
Im
1
x ± iε = ∓
ε
x2 + ε2 ≡∓fε(x).
The limit of fε for ε →0 has been determined for the Breit–Wigner formula. To
ﬁnd the same limit for the functions gε note ﬁrst that gε is not integrable on R. It

36
3
Schwartz Distributions
is only locally integrable. Take any φ ∈D(R) and observe that the functions gε
are odd. Thus, we get
⟨Igε, φ⟩=

R
gε(x)φ(x)dx =
 ∞
0
gε(x)[φ(x) −φ(−x)]dx.
Rewrite the integrand as
gε(x)[φ(x) −φ(−x)] = xgε(x)φ(x) −φ(−x)
x
and observe that the function φ(x)−φ(−x)
x
belongs to L1(R) while the functions
xgε(x) are bounded on R by 1 and converge, for x ̸= 0, pointwise to 1 as ε →0.
Lebesgue’s dominated convergence theorem thus implies that
lim
ε→0

R
gε(x)φ(x)dx =
 ∞
0
φ(x) −φ(−x)
x
dx,
or
lim
ε→0
x
x2 + ε2 = vp 1
x
in D′(R)
(3.11)
where we have taken Eq. (3.8) into account. Equation (3.11) and the Breit–Wigner
formula together imply easily the Sokhotski–Plemelj formula.
These concrete examples illustrate various practical aspects which have to be ad-
dressed in the proof of convergence of sequences of distributions. Now we formulate
a fairly general and powerful result which simpliﬁes the convergence proofs for
sequences of distributions in an essential way: It says that for the convergence
of a sequence of distributions, it sufﬁces to show that this sequence is a Cauchy
sequence, i.e., the space of distributions equipped with the weak topology is sequen-
tially complete. Because of the great importance of this result we present a detailed
proof.
Theorem 3.3
Equip the space of distributions D′(Ω) on an open nonempty set
Ω ⊂Rn with the weak topology σ = σ(D′(Ω), D(Ω)). Then D′(Ω) is a sequentially
complete HLCTVS.
In particular, for any sequence (Ti)i∈N ⊂D′(Ω) such that for each φ ∈D(Ω)
the numerical sequence (Ti(φ))i∈N converges, there are, for each compact subset
K ⊂Ω, a constant C and an integer m ∈N such that
|Ti(φ)| ≤CpK,m(φ)
∀φ ∈DK(Ω), ∀i ∈N;
(3.12)
i.e., the sequence (Ti)i∈N is equicontinuous on DK(Ω) for each compact set K ⊂Ω.
Proof
Since its topology is deﬁned in terms of a system of seminorms, the space
of all distributions on Ω is certainly a locally convex topological vector space. Now
given T ∈D′(Ω), T ̸= 0, there is a φ ∈D(Ω) such that T (φ) ̸= 0, thus pφ(T ) =

3.3
Convergence of Sequences and Series of Distributions
37
|T (φ)| > 0 and Proposition 2.2 implies that the weak topology is Hausdorff, hence
D′(Ω) is an HLCTVS.
In order to prove sequential completeness, we take any Cauchy sequence (Ti)i∈N
in D′(Ω) and construct an element T ∈D′(Ω) to which this sequence converges.
For any φ ∈D(Ω) we know (by deﬁnition of a Cauchy sequence) (Ti(φ))i∈N to be
a Cauchy sequence in the ﬁeld K which is complete. Hence, this Cauchy sequence of
numbers converges to some number which we call T (φ). Since this argument applies
to any φ ∈D(Ω), we can deﬁne a function T : D(Ω) →K by
T (φ) = lim
i→∞Ti(φ)
∀φ ∈D(Ω).
Since each Ti is linear, basic rules of calculation for limits of convergent sequences
of numbers imply that the limit function T is linear too.
In order to show continuity of this linear functional T it sufﬁces, according to
Theorem 3.1, to show that TK = T |DK(Ω) is continuous on DK(Ω) for every
compact subset K ⊂Ω. This is done by constructing a neighborhood U of zero in
DK(Ω) on which T is bounded and by using Corollary 2.1 to deduce continuity.
Since Ti is continuous on DK(Ω), we know that
Ui = {φ ∈DK(Ω) : |Ti(φ)| ≤1}
is a closed absolutely convex neighborhood of zero in DK(Ω) (see also the Exercises).
Now deﬁne
U = ∩∞
i=1Ui
and observe that U is a closed absolutely convex set on which the functional T is
bounded by 1. Hence, in order to deduce continuity of T , one has to show that U is
actually a neighborhood of zero in DK(Ω). This part is indeed the core of the proof
which relies on some fundamental properties of the space DK(Ω) which are proven
in the Appendix.
Take any φ ∈DK(Ω); since the sequence (Ti(φ))i∈N converges, it is bounded
and there is an n = n(φ) ∈N such that |Ti(φ)| ≤n for all i ∈N. It follows that
|T (φ)| = limi→∞|Ti(φ)| ≤n and thus φ = n · 1
nφ ∈nU. Since φ was arbitrary in
DK(Ω), this proves
DK(Ω) = ∪∞
n=1nU.
In Proposition 2.4 it is shown that DK(Ω) is a complete metrizable HLCTVS. Hence
the theorem of Baire (see Appendix, Theorem C.3) applies to this space, and it
follows that one of the sets nU and hence U itself must have a nonempty interior.
This means that some open ball B = φ0 + Bp,r ≡φ0 + {φ ∈DK(Ω) : p(φ) < r} is
contained in the set U. Here φ0 is some element in U, r some positive number and
p = pK,m is some continuous seminorm of the space DK(Ω). Since T is bounded
on U by 1 it is bounded on the neighborhood of zero Bp,r by 1 + |T (φ0)| and thus T
is continuous.

38
3
Schwartz Distributions
All elements of Ti and the limit element T are bounded on this neighborhood U
by 1. From the above it follows that there are a constant C and some integer m ∈N
such that
|Ti(φ)| ≤CpK,m(φ)
∀φ ∈DK(Ω), ∀i ∈N;
i.e., the sequence (Ti)i∈N is equicontinuous on DK(Ω) for each compact set K ⊂Ω,
and we conclude.
2
The convergence of a series of distributions is deﬁned in the usual way through
convergence of the corresponding sequence of partial sums. This can easily be
translated into the following concrete formulation.
Deﬁnition 3.4
Given a sequence (Ti)i∈N of distributions on a nonempty open set
Ω ⊂Rn one says that the series 
i∈N Ti converges if, and only if, there is a
T ∈D′(Ω) such that for every φ ∈D(Ω) the numerical series 
i∈N Ti(φ) converges
to the number T (φ).
As a ﬁrst important application of Theorem 3.3, one has a rather convenient
characterization of the convergence of a series of distributions.
Corollary 3.2 A series 
i∈N Ti of distributions Ti ∈D′(Ω) converges if, and only
if, for every φ ∈D(Ω) the numerical series 
i∈N Ti(φ) converges.
As a simple example consider the distributions Ti = ciδia for some a > 0 and
any sequence of numbers ci. Then the series

i∈N
ciδia
converges in D′(R). The proof is simple. For every φ ∈D(R) one has

i∈N
Ti(φ) =

i∈N
ciφ(ia) =
m

i=1
ciφ(ia)
for some m ∈N depending on the support of the test function φ (for ia > m the
point ia is not contained in supp φ).
3.4
Localization of Distributions
Distributions on a nonempty open set Ω ⊂Rn have been deﬁned as continuous
linear functionals on the test function space D(Ω) over Ω but not directly in points
of Ω. Nevertheless we consider these distributions to be localized. In this section we
explain in which sense this localization is understood.
Suppose Ω1 ⊂Ω2 ⊂Rn. Then every test function φ ∈D(Ω1) vanishes in
a neighborhood of the boundary of Ω1 and thus can be continued by 0 to Ω2 to
give a compactly supported test function iΩ2,Ω1(φ) on Ω2. This deﬁnes a mapping

3.4
Localization of Distributions
39
iΩ2,Ω1 : D(Ω1) →D(Ω2) which is evidently linear and continuous. Thus, we can
consider D(Ω1) to be embedded into D(Ω2) as iΩ2,Ω1(D(Ω1)), i.e.
iΩ2,Ω1(D(Ω1)) ⊂D(Ω2).
Hence, every continuous linear functional T on D(Ω2) deﬁnes also a continuous
linear functional T ◦iΩ2,Ω1 ≡ρΩ1,Ω2(T ) on D(Ω1). Therefore, every distribution T
on Ω2 can be restricted to any open nonempty subset Ω1 by
T |Ω1 = ρΩ1,Ω2(T ).
(3.13)
In particular this allows us to express the fact that a distribution T on Ω2 vanishes
on an open subset Ω1: ρΩ1,Ω2(T ) = 0, or in concrete terms
T ◦iΩ2,Ω1(φ) = 0
∀φ ∈D(Ω1).
For convenience of notation the trivial extension map iΩ2,Ω1 is usually omitted and
one writes
T (φ) = 0
∀φ ∈D(Ω1)
to express the fact that a distribution T on Ω2 vanishes on the open subset Ω1. As a
slight extension we state: Two distributions T1 and T2 on Ω2 agree on an open subset
Ω1 if, and only if,
ρΩ1,Ω2(T1) = ρΩ1,Ω2(T2)
or in more convenient notation if, and only if,
T1(φ) = T2(φ)
∀φ ∈D(Ω1).
The support of a function f : Ω →K is deﬁned as the closure of the set of those
points in which the function does not vanish, or equivalently as the complement of
the largest open subset of Ω on which f vanishes. The above preparations thus allow
us to deﬁne the support of a distribution T on Ω as the complement of the largest
open subset Ω1 ⊂Ω on which T vanishes. The support of T is denoted by supp T .
It is characterized by the formula
supp T =

A∈CT
A
(3.14)
where CT denotes the set of all closed subsets of Ω such that T vanishes on Ω\A.
Accordingly a point x ∈Ω belongs to the support of the distribution T on Ω if, and
only if, T does not vanish in every open neighborhood U of x, i.e., for every open
neighborhood U of x there is a φ ∈D(U) such that T (φ) ̸= 0.
In the Exercises one shows that this concept of support of distributions is com-
patible with the embedding of functions and the support deﬁned for functions, i.e.,
one shows
supp If = supp f
for all f ∈L1
loc(Ω).
A simple example shows that distributions can have a support consisting of one point:
The support of the distribution T on Ω deﬁned by
T (φ) =

|α|≤m
cαDαφ(x0)
(3.15)

40
3
Schwartz Distributions
is the point x0 ∈Ω, for any choice of the constants cα and any m ∈N. If a distribution
is of the form (3.15) then certainly T (φ) = 0 for all φ ∈D(Rn\ {x0} ) since such test
functions vanish in a neighborhood of x0 and thus all derivatives vanish there. And,
if not all coefﬁcients cα vanish, there are, in any neighborhood U of the point x0, test
functions φ ∈D(U) such that T (φ) ̸= 0. This claim is addressed in the Exercises.
Furthermore, this formula actually gives the general form of a distribution whose
support is the point x0. We show this later in Proposition 4.7.
Since we have learned above when two distributions on Ω agree on an open
subset, we know in particular when a distribution is equal to a C∞-function, or more
precisely when a distribution is equal to the regular distribution deﬁned by a C∞-
function, on some open subset. This is used in the deﬁnition of the singular support
of a distribution, which seems somewhat ad hoc but which has proved itself to be
quite useful in the analysis of constant coefﬁcient partial differential operators.
Deﬁnition 3.5
Let T be a distribution on a nonempty open set Ω ⊂Rn. The
singular support of T , denoted sing supp T , is the smallest closed subset of Ω in
the complement of which T is equal to a C∞-function.
We mention a simple one dimensional example, Cauchy’s principal value vp 1
x .
In the discussion following formula (3.8) we saw that vp 1
x = I 1
x on R\ {0}. Since
1
x is a C-function on R\ {0}, sing supp vp 1
x ⊆{0}. And since {0} is obviously the
smallest closed subset of R outside which the Cauchy principal value is equal to a
C-function, it follows that
sing supp vp 1
x = {0} .
3.5
Tempered Distributions and Distributions with Compact
Support
Tempered distributions are distributions which admit the Fourier transform as an iso-
morphism of topologicalvectorspacesandaccordinglywewilldevotelateraseparate
chapter to Fourier transformation and tempered distributions. This section just gives
the basic deﬁnitions and properties of tempered distributions and distributions with
compact support.
Recall the beginning of the section on the deﬁnition of distributions. What has
been done there for general distributions will be done here for the subclasses of
tempered and compactly supported distributions.
Deﬁnition 3.6
A tempered distribution T on an open nonempty subset Ω ⊂
Rn is a continuous linear functional on the test function space S(Ω) of strongly
decreasing C∞-functions on Ω. The set of all tempered distributions on Ω equals
the topological dual S′(Ω) of S(Ω).
In analogy with Theorem 3.1, we have the following explicit characterization of
tempered distributions.

3.5
Tempered Distributions and Distributions with Compact Support
41
Theorem 3.4 A linear functional T : S(Ω) →K is a tempered distribution on the
open nonempty set Ω ⊂Rn if, and only if, there exist a number C ∈R+ and natural
numbers m, k ∈N, depending on T , such that for all φ ∈S(Ω) the estimate
|T (φ)| ≤Cpm,k(φ)
(3.16)
holds.
Proof Recall the deﬁnition of the ﬁltering system of norms of the space S(Ω) and the
condition of boundedness for a linear function T : S(Ω) →K. Then it is clear that
the above estimate characterizes T as being bounded on S(Ω). Thus, by Theorem
2.4, this estimate characterizes continuity and we conclude.
2
According to relation (3.2), we know that every tempered distribution is a dis-
tribution and therefore all results established for distributions apply to tempered
distributions. Also, the basic deﬁnitions of convergence and of a Cauchy sequence
are formally the same as soon as we replace the test function space D(Ω) by the
smaller test function space S(Ω) and the topological dual D′(Ω) of D(Ω) by the
topological dual S′(Ω) of S(Ω). Hence, we do not repeat these deﬁnitions, but we
formulate the important counterpart of Theorem 3.3 explicitly.
Theorem 3.5 Equip the space of distributions S′(Ω) of tempered distributions on
an open nonempty set Ω ⊆Rn with the weak topology σ = σ(S′(Ω), S(Ω)). Then
S′(Ω) is a sequentially complete HLCTVS.
Proof
As in the proof of Theorem 3.3 one sees that S′(Ω) is an HLCTVS. By
this theorem one also knows that a Cauchy sequence in S′(Ω) converges to some
distribution T on Ω. In order to show that T is actually tempered, one proves that T
is bounded on some open ball in S(Ω). Since S(Ω) is a complete metrizable space
this can be done as in the proof of Theorem 3.3. Thus we conclude.
2
Finally, we discuss brieﬂy the space of distributions of compact support. Recall
that a distribution T ∈D′(Ω) is said to have a compact support if there is a compact
set K ⊂Ω such that T (φ) = 0 for all φ ∈D(Ω\K). The smallest of the compact
subsetsK forwhichthisconditionholdsiscalledthesupportofT , denotedbysupp T .
As we are going to explain now, distributions of compact support can be characterized
topologically as elements of the topological dual of the test function space E(Ω).
According to (C.3), the space E(Ω) is the space C∞(Ω) equipped with the ﬁlter-
ing system of semi-norms P∞(Ω) =

pK,m : K ⊂Ω compact, m = 0, 1, 2, . . .

.
Hence a linear function T : E(Ω) →K is continuous if, and only if, there are a
compact set K ⊂Ω, a constant C ∈R+ and an integer m such that
|T (φ)| ≤CpK,m(φ)
∀φ ∈E(Ω).
(3.17)
Now suppose T ∈E′(Ω) is given. Then T satisﬁes condition (3.17) and by relation
(3.2) we know that T is a distribution on Ω. Take any φ ∈D(Ω →K). Then φ
vanishes in some open neighborhood U of K and thus Dαφ(x) = 0 for all x ∈K
and all α ∈Nn. It follows that pK,m(φ) = 0 and thus T (φ) = 0 for all φ ∈D(Ω\K),
hence supp T ⊆K. This shows that elements in E′(Ω) are distributions with compact
support.

42
3
Schwartz Distributions
Conversely, suppose that T ∈D′(Ω) has a support contained in a compact set
K ⊂Ω. There are functions u ∈D(Ω) which are equal to 1 in an open neighborhood
of K and which have their support in a slightly larger compact set K′ (see Exercises).
Itfollowsthat(1−u)·φ ∈D(Ω\K)andthereforeT ((1−u)·φ) = 0 orT (φ) = T (u·φ)
for all φ ∈D(Ω). For any ψ ∈E(Ω), one knows u · ψ ∈DK′(Ω) and thus
T0(ψ) = T (u · ψ) is a well-deﬁned linear function E(Ω) →K. (If v ∈D(Ω)
is another function which is equal to 1 in some open neighborhood of K, then
u · ψ −v · ψ ∈D(Ω\K) and therefore T (u · ψ −v · ψ) = 0). Since T is a
distribution, there are a constant C ∈R+ and m ∈N such that |T (φ)| ≤cpK′,m(φ)
for all φ ∈DK′(Ω). For all ψ ∈E(Ω) we thus get
|T0(ψ)| = |T (u · ψ)| ≤CpK′,m(u · ψ) ≤CpK′,m(u)pK′,m(ψ).
This shows that T0 is continuous on E(Ω), i.e. T0 ∈E′(Ω). On D(Ω) the functionals
T0 and T agree: T0(φ) = T (u · φ) = T (φ) for all φ ∈D(Ω) as we have seen above
and therefore we can formulate the following result.
Theorem 3.6 The topological dual E′(Ω) of the test function space E(Ω) equals
the space of distributions on Ω which have a compact support. Equipped with the
weak topology σ = σ(E′(Ω), E(Ω)) the space E′(Ω) of distributions with compact
support is a sequentially complete HLCTVS.
Proof The proof that E′(Ω) is a sequentially complete HLCTVS is left as an exercise.
The other statements have been proven above.
2
3.6
Exercises
1. Let f : Ω →R be a continuous function on an open nonempty set Ω ⊂Rn.
Show: If

f (x)φ(x)dx = 0 for all φ ∈D(Ω), then f = 0, i.e., the map
I : C(Ω) →D′(Ω) of Theorem 3.2 is injective. Deduce that I is injective on all
of L1
loc(Ω).
2. Prove: There is no f ∈L1
loc(Ω) such that δa(φ) =

f (x)φ(x)dx for all φ ∈
D(Ω).
Hint: It sufﬁces to consider the case a = 0. Then take the function ρ : Rn →R
by
ρ(x) =
⎧
⎨
⎩
0
:
for
|x| ≥1,
e
−1
1−x2
:
for
|x| < 1,
and deﬁne ρr(x) = ρ( x
r ) for r > 0. Recall that ρr ∈D(Ω) and ρr(x) = 0 for all
x ∈Rn with |x| > r. Finally, observe that for f ∈L1
loc(Ω) one has
lim
r→0

x:|x|≤r
|f (x)|dx = 0.

3.6
Exercises
43
3. Consider the hyperplane H
= {x = (x1, . . . , xn) ∈Rn : x1 = 0}. Deﬁne a
function δH : D(Rn) →K by
⟨δH, φ⟩=

Rn−1 φ(0, x2, . . . , xn)dx2 · · · dxn
∀φ ∈D(Rn).
Show that δH is a distribution on Rn. It is called Dirac’s delta distribution on the
hyperplane H.
4. For any point a ∈Ω ⊂Rn, Ω open and not empty, deﬁne a functional T :
D(Ω) →K by
⟨T , φ⟩=
n

i=1
∂2φ
∂x2
i
(a) ≡△φ(a)
∀φ ∈D(Rn).
Prove: T is a distribution on Ω of order 2. On Ω\ {a} this distribution is equal to
the regular distribution I0 deﬁned by the zero function.
5. Let Sn−1 =

x ∈Rn : n
i=1 x2
i = 1

be the unit sphere in Rn and denote by dσ
the uniform measure on Sn−1. The derivative in the direction of the outer normal
of Sn−1 is denoted by
∂
∂n. Now deﬁne a function T : D(Rn) →K by
⟨T , φ⟩=

Sn−1
∂φ
∂n dσ
∀φ ∈D(Ω)
and show that T is a distribution on Rn of order 1 which is equal to the regular
distribution I0 on Rn\Sn−1.
6. GivenaCauchysequence(Ti)i∈N ofdistributionsonanonemptyopensetΩ ⊂Rn,
prove in detail that the (pointwise or weak) limit T is a linear function D(Ω) →K.
7. Let X[P] be an HLCTVS, T ∈X′[P] and r > 0. Show:
U = {x ∈X : |T (x)| ≤r}
is a closed absolutely convex neighborhood of zero.

Chapter 4
Calculus for Distributions
This chapter deals with the basic parts of calculus, i.e., with differentiation of
distributions, multiplication of distributions with smooth functions and with other
distributions, and change of variables for distributions. There are other parts which
will be addressed in separate chapters since they play a prominent role in distribu-
tion theory, viz., Fourier transform for a distinguished subclass of distributions and
convolution of distributions with functions and with other distributions.
It stands to reason that we deﬁne differentiation, multiplication, and variable
transformations for distributions, we insist that these deﬁnitions be consistent with
these operations on functions and the embedding of functions into the space of
distributions.
As preparation we mention a small but important observation. Let Ω ⊂Rn be
nonempty and open and A : D(Ω) →D(Ω) a continuous linear function of the
test function space on Ω into itself. Such a map induces a map on the space of
distributions on Ω: A′ : D′(Ω) →D′(Ω) according to the formula
A′(T ) = T ◦A
∀T ∈D′(Ω).
(4.1)
As a composition of two linear and continuous functions, A′(T ) is a continuous
linear function D(Ω) →K and thus a distribution. Therefore, A′ is well deﬁned
and is called the adjoint of A. Obviously A′ : D′(Ω) →D′(Ω) is linear, but
it is also continuous, since for every φ ∈D(Ω) we have, for all T ∈D′(Ω),
pφ(A′(T )) = pA(φ)(T ) so that Deﬁnition 2.7 and Theorem 2.4 imply continuity.
The adjoint itself (or a slight modiﬁcation thereof in order to ensure consis-
tency with the embedding of functions) will be used to deﬁne differentiation of
distributions, their multiplication and change of variables.
© Springer International Publishing Switzerland 2015
45
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_4

46
4
Calculus for Distributions
4.1
Differentiation
Let Dα be a derivative monomial of order α = (α1, . . ., αn) ∈Nn. It is certainly
a linear map D(Ω) →D(Ω) for any open nonempty set Ω ⊂Rn. Continuity of
Dα : D(Ω) →D(Ω) follows easily from the estimate
pK,m(Dαφ) ≤pK,m+|α|(φ)
∀φ ∈DK(Ω)
in conjunction with Deﬁnition 2.7 and Theorem 2.4. Therefore, the adjoint of the
derivative monomial Dα is a continuous linear map D′(Ω) →D′(Ω) and thus
appears to be a suitable candidate for the deﬁnition of the derivative of distributions.
However, since we insist on consistency of the deﬁnition with the embedding of
differentiable functions into the space of distributions, a slight adjustment has to be
made. To determine this adjustment take any f ∈C1(Rn) and calculate for every
φ ∈D(Rn),
⟨I∂1f , φ⟩=

Rn
∂f
∂x1
(x)φ(x)dx =

· · ·
 
R
∂f
∂x1
(x)φ(x)dx1

dx2 · · · dxn
= −

· · ·
 
R
f (x) ∂φ
∂x1
(x)dx1

dx2 · · · dxn = −⟨If , ∂1φ⟩.
Here we use the abbreviation ∂1 ≡
∂
∂x1 . Similarly, by repeated partial integration,
one obtains (see Exercises) for f ∈Ck(Rn),
⟨IDαf , φ⟩= (−1)|α|⟨If , Dαφ⟩
∀φ ∈D(Rn),
∀α ∈Nn, |α| ≤k.
Denoting the derivative of order α on D′(Ω) with the same symbol as for functions,
the condition of consistency with the embedding reads
DαIf = IDαf
∀α ∈Nn, |α| ≤k,
∀f ∈Ck(Ω).
Accordingly, one takes as the derivative monomial of order α on distributions the
following modiﬁcation of the adjoint of the derivative monomial on functions.
Deﬁnition 4.1 The derivative of order α = (α1, . . ., αn) ∈Nn is deﬁned on D′(Ω)
by the formula
DαT = (−1)|α|T ◦Dα
∀T ∈D′(Ω),
i.e., for each T ∈D′(Ω) one has
⟨DαT , φ⟩= (−1)|α|⟨T , Dαφ⟩
∀φ ∈D(Ω).
There are a number of immediate powerful consequences of this deﬁnition. The proof
of these results is straightforward.

4.1
Differentiation
47
Theorem 4.1
Differentiation on the space of distributions D′(Ω) on a nonempty
open set Ω ⊂Rn as deﬁned in Deﬁnition 4.1 has the following properties:
1. Every distribution has derivatives of all orders and the order in which derivatives
are calculated does not matter, i.e.,
Dα(DβT ) = Dβ(DαT ) = Dα+βT
∀T ∈D′(Ω),
∀α, β ∈Nn.
2. The local order of a distribution increases by the order of differentiation.
3. Differentiation on D′(Ω) is consistent with the embedding of C∞(Ω) into D′(Ω).
4. The derivative monomials Dα : D′(Ω) →D′(Ω) are linear and continuous,
hence in particular
a) If T = limi→∞Ti in D′(Ω), then
Dα( lim
i→∞Ti) = lim
i→∞DαTi.
b) If a series 
i∈N Ti converges in D′(Ω), then
Dα 
i∈N
Ti =

i∈N
DαTi.
Proof
The ﬁrst part has been shown in the deﬁnition of the derivative for distri-
butions. The order of differentiation does not matter since on C∞(Ω) the order of
differentiation can be interchanged.
If for some compact set K ⊂Ω we have |T (φ)| ≤CpK,m(φ) for all φ ∈DK(Ω),
we get |DαT (φ)| = |T (Dαφ)| ≤CpK,m(Dαφ) ≤CpK,m+|α|(φ) and the second part
follows easily from the deﬁnition of the local order (Deﬁnition 3.2).
The consistency of the derivative for distributions with the embedding of
differentiable functions has been built into the deﬁnition.
Since the derivative Dα on D′(Ω) equals the adjoint of the derivative on functions
multiplied by (−1)|α|, the continuity of the derivative follows immediately from that
of the adjoint of the linear continuous map on D(Ω) as discussed after Eq. (4.1).
2
Remark 4.1
1. Obviously, the fact that every distribution has derivatives of all orders comes
from the deﬁnition of the test function space as a subspace of the space of all
C∞-functions and the deﬁnition of a topology on this subspace which ensures
that all derivative monomials are continuous.
2. In the sense of distributions, every locally integrable function has derivatives of
all orders. But certainly, in general, the result will be a distribution and not a
function. We mention a famous example. Consider the Heaviside function θ on
the real line R deﬁned by
θ(x) =
⎧
⎨
⎩
0
:
for
x < 0,
1
:
for
x ≥0.

48
4
Calculus for Distributions
θ is locally integrable and thus has a derivative in the sense of distributions which
we calculate now. For all φ ∈D(R) one has
⟨DIθ, φ⟩
= −⟨Iθ, Dφ⟩= −

R θ(x)φ′(x)dx
= −
 ∞
0 φ′(x)dx = φ(0) = ⟨δ, φ⟩.
This shows that DIθ = δ, which is often written as
θ′(x) = δ(x),
i.e., the derivative (in the sense of distributions) of Heaviside’s function equals
Dirac’s delta function.
Some other examples of derivatives are given in the Exercises.
3. Part 4 ofTheorem 4.1 represents a remarkable contrast to classical analysis. Recall
the example of the sequence of C∞-functions fj(x) =
1
j sin (jx) on R which
converges uniformly on R to the C∞-function 0, but for which the sequence of
derivatives f ′
j(x) = cos (jx) does not converge (not even pointwise). In the sense
of distributions the sequence of derivatives also converges to 0: For all φ ∈D(R)
we have
⟨DIfj , φ⟩= −⟨Ifj , Dφ⟩= −1
j

R
sin (jx)φ′(x)dx →0
as j →∞.
One of the major goals in the development of distribution theory was to get a
suitable framework for solving linear partial differential equations with constant co-
efﬁcients. This goal has been achieved [6, 7]. Here we mention only a few elementary
aspects. Knowing the derivative monomials on D′(Ω) we can consider linear con-
stant coefﬁcient partial differential operators on this space, i.e., operators of the
form
P(D) =

|α|≤k
aαDα
(4.2)
with certain coefﬁcients aα ∈K and k = 1, 2, . . . . Now given f ∈C∞(Ω) we can
consider the equation
P(D)u = f
(4.3)
in two ways: A classical or strong solution is a function u ∈Ck(Ω) such that
this equation holds in the sense of functions. A distribution T ∈D′(Ω) for which
P (D)T = If holds in D′(Ω) is called a distributional or weak solution.
Since the space of distributions D′(Ω) is much larger than the space Ck(Ω) of
continuously differentiable functions, one expects that it is easier to ﬁnd a solution
in this larger space. This expectation has been proven to be correct in many impor-
tant classes of problems. However in most cases, in particular in those arising from

4.2
Multiplication
49
physics, one does not look for a weak but for a classical solution. So it is very im-
portant to have a theory which ensures that for special classes of partial differential
equations the weak solutions are actually classical ones. The so-called elliptic reg-
ularity theory provides these results also for “elliptic” partial differential equations
(see Part III). Here we discuss a very simple class of examples of this type.
Proposition 4.1
Suppose T ∈D′(R) satisﬁes the constant coefﬁcient ordinary
differential equation
DnT = 0
in
D′(R).
Then T is a polynomial Pn−1 of degree ≤n −1, i.e., T = IPn−1. Hence, the sets of
classical and of distributional solutions of this differential equation coincide.
Proof The proof is by induction on the order n of this differential equation. Hence,
in a ﬁrst step, we show: If a distribution T ∈D(R) satisﬁes DT = T ′ = 0, then T
is a constant, i.e., of the form T = Ic for some constant c.
Choose some test function ψ ∈D(R) which is normalized by the condition
I(ψ) ≡

ψ(x)dx = 1. Next consider any test function φ ∈D(R). Associate with it
the auxiliary test function χ = φ −I(φ)ψ which has the property I(χ) = 0. Hence,
χ is the derivative of a test function ρ deﬁned by ρ(x) =
 x
−∞χ(y)dy, ρ′ = χ (see
Exercises). T ′ = 0 in D′(R) implies that
T (χ) = T (ρ′) = −T ′(ρ) = 0
and therefore
T (φ) = T (ψ)I(φ) = Ic(φ)
with the constant c = T (ψ).
Now suppose that the conclusion of the proposition holds for some n ≥1. We are
going to show that then this conclusion also holds for n + 1.
Assume Dn+1T = 0 in D′(R). It follows that D(DnT ) = 0 in D′(R) and hence
DnT = Ic for some constant c. In the Exercises, we show the identity Ic = DnIPn
where Pn is a polynomial of degree n of the form Pn(x) = c
n!xn+Pn−1(x). Here Pn−1
is any polynomial of degree ≤n −1. Therefore, DnT = DnIPn or Dn(T −IPn) = 0
in D′(R). The induction hypothesis implies that
T −IPn = IQn−1
for some polynomial Qn−1 of degree ≤n−1 and we conclude that T is a polynomial
of degree ≤n.
In the Exercises, we will also show that any classical solution is also a
distributional solution.
2
4.2
Multiplication
As is well known from classical analysis, the (pointwise) product of two continuous
functions f , g ∈C∞(Ω), deﬁned by (f · g)(x) = f (x)g(x) for all x ∈Ω, is again a
continuous function on Ω. Similarly, the product of two continuously differentiable

50
4
Calculus for Distributions
functions f , g ∈C1(Ω) is again a continuously differentiable function, due to the
product rule of differentiation.
However, the product of two locally integrable functions f , g ∈L1
loc(Ω) is in
general not a locally integrable function. As a typical case we mention: f · g is not
locally integrable when both functions have a sufﬁciently strong singularity at the
same point. A simple example is the function
f (x) =
⎧
⎨
⎩
+∞
:
for
x = 0,
1
√|x|
:
for
x ̸= 0.
Obviously f ∈L1
loc(R), but f · f = f 2 is not locally integrable. Nevertheless, the
product of two locally integrable functions which have a singularity at the same point
will be locally integrable if these singularities are sufﬁciently weak; for example,
take the function
g(x) =
⎧
⎨
⎩
+∞
:
for
x = 0,
1
|x|s
:
for
x ̸= 0.
for some exponent s > 0. If 2s < 1, then g2 is locally integrable on R.
On the other hand, there are many subspaces of L1
loc(Ω) with the property that any
element in this subspace can multiply any element in L1
loc(Ω) such that the product is
again in L1
loc(Ω) (Ω ⊂Rn open and nonempty), for instance the subspace C∞(Ω) of
continuous functions on Ω or the bigger subspace L∞
loc(Ω) of those functions which
are essentially bounded on every compact subset K ⊂Ω.
These few examples show that in spaces of functions whose elements can have
singularities the multiplication cannot be done in general. Accordingly, we cannot
expect to have unrestricted multiplication in the space D′(Ω) of distributions and
therefore only some special but important cases of multiplication for distributions
are discussed.
Proposition 4.2 In the space D′(Ω) of distributions on a nonempty open set Ω ⊂
Rn, multiplication with C∞-functions is well deﬁned by
(u · T )(φ) = T (u · φ)
∀φ ∈D(Ω)
for every T ∈D′(Ω) and every u ∈C∞(Ω). This product has the following
properties:
1. For ﬁxed u ∈C∞(Ω) the map T #→u · T is linear and continuous on D′(Ω).
2. The product rule of differentiation holds:
∂
∂xj
(u · T ) = ∂u
∂xj
· T + u · ∂T
∂xj
(4.4)
for all j = 1, . . ., n, all u ∈C∞(Ω), and all T ∈D′(Ω).

4.2
Multiplication
51
3. This multiplication is compatible with the embedding of functions, i.e.,
u · If = Iuf
for all u ∈C∞(Ω) and all f ∈L1
loc(Ω).
Proof
For each u ∈C∞(Ω) introduce the mapping Mu : D(Ω) →D(Ω) which
multiplies a test function φ with the function u: Mu(φ) = u · φ (pointwise product).
Obviously we have supp u · φ ⊆supp φ. Hence, Mu(φ) has a compact support.
The product rule of differentiation for functions shows that Mu(φ) ∈C∞(Ω), and
therefore Mu(φ) ∈D(Ω) and Mu is well deﬁned. Clearly, Mu is a linear map
D(Ω) →D(Ω).
In order to prove continuity recall ﬁrst the Leibniz formula
Dα(f · g) =

β+γ =α
α!
β!γ !Dβ · Dγ g
∀f , g ∈C|α|(Ω).
(4.5)
Here we use the multi-index notation: For α = (α1, . . ., αn) ∈Nn one deﬁnes
α! = α1! · · · αn! and addition of multi-indices is as usual component-wise.
Now given any compact set K ⊂Ω and m ∈N we estimate as follows, for all
φ ∈DK(Ω):
pK,m(Mu(φ)) ≤CpK,m(u)pK,m(φ).
Here C is a constant depending only on m and n. The details of this estimate are left
as an Exercise. Since u ∈C∞(Ω) we know that pK,m(u) is ﬁnite for every compact set
K and every m ∈N. Proposition 2.6, thus, implies continuity of Mu. Therefore, its
adjoint M′
u is a continuous linear map D′(Ω) →D′(Ω) (see the arguments following
Eq. (4.1)). Hence, the multiplication with C∞-functions u,
u · T = T ◦Mu = M′
u(T )
acts continuously on D′(Ω).
The proof of the product rule for differentiation is a straightforward calculation.
Take any T ∈D′(Ω) and any u ∈C∞(Ω). Using the abbreviation ∂j =
∂
∂xj we have
for all φ ∈D(Ω),
⟨∂j(u · T ), φ⟩= −⟨(u · T ), ∂jφ⟩= −⟨T , u∂jφ⟩= −⟨T , ∂j(uφ) −φ∂ju⟩
= −⟨T , ∂j(uφ)⟩+ ⟨T , φ∂ju⟩= ⟨∂jT , uφ⟩+ ⟨T , φ∂ju⟩
= ⟨u · ∂jT , φ⟩+ ⟨∂ju · T , φ⟩= ⟨u · ∂jT + ∂ju · T , φ⟩,
and the product rule follows.
Finally, we prove compatibility of the multiplication for distribution with the
multiplication for L1
loc(Ω) under the embedding I. As we have seen earlier, u · f ∈

52
4
Calculus for Distributions
L1
loc(Ω) for all u ∈C∞(Ω) and all f ∈L1
loc(Ω). Thus, given f ∈L1
loc(Ω) and
u ∈C∞(Ω), we calculate, for all φ ∈D(Ω),
⟨u · If , φ⟩= ⟨If , uφ⟩=

f (x)u(x)φ(x)dx = ⟨Iuf , φ⟩,
and we conclude.
2
This proposition shows that the multiplicator space for distributions on Ω is
all of C∞(Ω), i.e., every T ∈D′(Ω) can be multiplied by every u ∈C∞(Ω) to
give a distribution u · T on Ω. In the case of tempered distributions, one has to take
growth restrictions into account and accordingly the multiplicator space for tempered
distributions on Ω is considerably smaller as the following proposition shows:
Proposition 4.3
Denote by Om(Rn) the space of all C∞-functions u on Rn such
that for every α ∈Nn there are a constant C and an integer m such that
|Dαu(x)| ≤C(1 + x2)
m
2
∀x ∈Rn.
Then every T ∈S′(Rn) can be multiplied by every u ∈Om(Rn) and u · T ∈S′(Rn).
Proof We have to show that multiplication by u ∈Om(Rn), φ #→u · φ is a contin-
uous linear map S(Rn) →S(Rn). Using Leibniz’ formula, this is a straightforward
calculation. For the details we refer to the Exercises.
2
4.3
Transformation of Variables
As in classical analysis it is often helpful to be able to work with distributions in
different coordinate systems. This amounts to a change of variables in which the
distributions are considered. Since in general distributions are deﬁned through their
action on test functions, these changes of variables have to take place ﬁrst on the
level of test functions and then by taking adjoints, on the level of distributions.
This requires that admissible transformations of variables have to take test function
spaces into test functions and in this way they are considerably more restricted than
in classical analysis.
Let Ωx ⊂Rn
x be a nonempty open set and σ : Ωx →Ωy, Ωy ⊂Rn
y, a dif-
ferentiable bijective mapping from Ωx onto the open set Ωy = σ(Ωx). Then the
determinant of the derivative of this mapping does not vanish: det ∂σ
∂x ̸= 0 on Ωx.
We assume σ ∈C∞(Ωx). It follows that the inverse transformation σ −1 is a C∞-
transformation from Ωy onto Ωx and compact subsets K ⊂Ωx are transformed onto
compact subsets σ(K) in Ωy. The chain rule for functions implies that φ ◦σ −1 is of
class C∞on Ωy for every φ ∈D(Ωx). Hence
φ #→φ ◦σ −1

4.3
Transformation of Variables
53
is a well-deﬁned mapping D(Ωx) →D(Ωy). In the Exercises, we show that this
mapping is actually continuous. In the Exercises, we also prove that
| det ∂σ −1
∂y | ∈C∞(Ωy).
The well-known formula for the change of variables in integrals will guide us to a
deﬁnition of the change of variables for distributions, which is compatible with the
embedding of functions into the space of distributions. Take any f ∈L1
loc(Ωy) and
calculate for all φ ∈D(Ωx),

Ωx
f (σ(x))φ(x)dx =

Ωy
f (y)φ(σ −1(y))| det ∂σ −1
∂y |dy,
i.e., ⟨If ◦σ, φ⟩= ⟨| det ∂σ −1
∂y | · If , φ ◦σ −1⟩. Accordingly, one deﬁnes the change of
variables for distributions.
Deﬁnition 4.2
Let σ : Ωx →Ωy be a bijective C∞-transformation from a
nonempty open set Ωx ⊂Rn onto a (nonempty open) set Ωy. To every distribu-
tion T on Ωy = σ(Ωx) one assigns a distribution T ◦σ of new variables on Ωx
which is deﬁned in the following formula for the transformation of variables:
⟨T ◦σ, φ⟩= ⟨| det ∂σ −1
∂y | · T , φ ◦σ −1⟩
∀φ ∈D(Ωx).
(4.6)
Proposition 4.4
For the transformation of variables as deﬁned above, the chain
rule holds, i.e., if T ∈D′(Ωy) and σ = (σ1, . . ., σn) is a bijective C∞-transformation,
then one has for j = 1, . . ., n,
Dj(T ◦σ) =
n

i=1
(∂iσ) · (DiT ) ◦σ.
Proof Since we will not use this rule in an essential way we refer for a proof to the
literature [1].
2
In applications in physics, typically, rather special cases of this general formula are
used, mainly to formulate symmetry or invariance properties of the system. Usually
these symmetry properties are deﬁned through transformations of the coordinate
space, such as translations, rotations, and Galileo or Lorentz transformations. We
give a simple concrete example.
Let A be a constant n × n matrix with nonvanishing determinant and a ∈Rn
some vector. Deﬁne a transformation σ : Rn →Rn by y = σ(x) = Ax + a for
all x ∈Rn. This transformation certainly satisﬁes all our assumptions. Its inverse is
x = σ −1(y) = A−1(y −a) for all y ∈Rn and thus ∂σ −1
∂y
= A−1. Given T ∈D′(Rn
y)
we want to determine its transform under σ. According to Eq. (4.6) it is given by
⟨T ◦σ, φ⟩= | det A−1|⟨T , φ ◦σ −1⟩for all φ ∈D(Rn
x). The situation becomes

54
4
Calculus for Distributions
more transparent when we write the different variables explicitly as arguments of the
distribution and the test function:
⟨(T ◦σ)(x), φ(x)⟩= ⟨T (Ax + a), φ(x)⟩=
1
| det A|⟨T (y), φ(A−1(y −a))⟩.
In particular for A = 1n (1n is the identity matrix in dimension n) this formula
describes translations by a ∈Rn. With the abbreviations Ta(x) = T (x + a) and
φa(y) = φ(y −a) we have
⟨Ta, φ⟩= ⟨Ta(x), φ(x)⟩= ⟨T (y), φa(y)⟩.
Knowing what the translation of a distribution by a ∈Rn is one can easily formulate
periodicity of distributions: A distribution T ∈D′(Rn) is said to be periodic with
period a ∈Rn if, and only if, Ta = T .
Another interesting application of the translation of distributions is to deﬁne the
derivative as the limit of difference quotients as is done for functions. One would
expect that this deﬁnition agrees with the deﬁnition of the derivative for distributions
given earlier. This is indeed the case as the following corollary shows.
Corollary 4.1 Let T be a distribution on a nonempty open set Ω ⊂Rn and a ∈Rn
some vector. Denote by Ta the translated distribution as introduced above. Then
lim
t→0
Tta −T
t
= a · DT
in D′(Ω).
(4.7)
Here DT
= (∂1T , . . ., ∂nT ) denotes the distributional derivative as given in
Deﬁnition 4.1.
Proof Given a ∈Rn and T ∈D′(Ω) choose any φ ∈D(Ω). Then, for t ∈R, t ̸= 0
and sufﬁciently small, we know that φta ∈D(Ω) too. For these numbers t we have
⟨Tta −T
t
, φ⟩= ⟨T , φta −φ
t
⟩.
In the Exercises, we show that
lim
t→0
φta −φ
t
= −a · Dφ
in D(Ω).
Here our notation is a · Dφ = a1∂1φ + · · · + an∂nφ. Using continuity of T on D(Ω)
in the ﬁrst step and Deﬁnition 4.1 in the last step, it follows that
lim
t→0⟨Tta −T
t
, φ⟩= −⟨T , a · Dφ⟩= ⟨a · DT , φ⟩,
and thus we conclude.
2

4.4
Some Applications
55
4.4
Some Applications
4.4.1
Distributions with Support in a Point
Thus far we have developed elementary calculus for distributions and we have learned
about the localization of distributions. This subsection discusses some related results.
A ﬁrst proposition states that the differentiation of distributions and the multiplication
of distributions with C∞-functions are local operations on distributions since under
these operations the support is “conserved.”
Proposition 4.5 Suppose Ω ⊂Rn is open and nonempty. Then:
1. supp (DαT ) ⊆supp T for every T ∈D′(Ω) and every α ∈Nn.
2. supp (u · T ) ⊆supp T for every T ∈D′(Ω) and every u ∈C∞(Ω).
The proof of these two simple statements is suggested as an exercise. Here we want
to point out that in both statements the relation ⊆cannot be replaced by =. This can
be seen by looking at some simple examples, for instance take T = Ic on R for some
constant c ̸= 0. Then supp T = R but for α ≥1 we have DαT = IDαc = I0 = 0.
And for u(x) = x, u ∈C∞(R), and T = δ ∈D′(R) one has u · δ = 0 while
supp δ = {0}.
It is also instructive to observe that φ(x) = 0 for all x ∈supp T does not imply
T (φ) = 0, in contrast to the situation for measures. Take, for example, T = Dαδ
with |α| ≥1 and a test function φ with φ(0) = 0 and φα(0) ̸= 0.
Recall Proposition 4.1 where we showed that the simple ordinary differential
equation DnT = 0 has also in D′(R) only the classical solutions. For ordinary
differential equations whose coefﬁcients are not constant the situation can be very
different. We look at the simplest case, the equation xn+1 · T = 0 on R. In L1
loc(R),
we only have the trivial solution, but not in D′(R) as the following proposition shows.
Proposition 4.6 T ∈D′(R) solves the equation
xn+1 · T = 0
in
D′(R)
(4.8)
if, and only if, T is of the form
T =
n

i=0
ciDiδ
(4.9)
with certain constants ci.
Proof
If T is of the form (4.9) then, for all φ ∈D(R), we have ⟨xn+1 · T , φ⟩=
⟨T , xn+1φ⟩= n
i=0 ci⟨Diδ, xn+1φ⟩= n
i=0 ci( −1)i(xn+1φ)(i)(0) = 0, since
(xn+1φ)(i)(0) = 0 for all i ≤n. hence T solves Eq. (4.8).
Now assume conversely that T is a solution of Eq. (4.8). In a ﬁrst step, we show
indirectly that T has a support contained in {0}. Suppose x0 ∈supp T and x0 ̸= 0.
Then there is a neighborhoodU of x0 which does not contain the pointx = 0 and there

56
4
Calculus for Distributions
is a test function ψ ∈D(U) such that T (ψ) ̸= 0. It follows that φ = x−(n+1)ψ ∈
D(U). Since xn+1 · T = 0 we get 0 = (xn+1 · T )(φ) = T (xn+1φ) = T (ψ), a
contradiction. Therefore, supp T ⊆{0}.
Now choose some test function ρr ∈D(R) with ρr(x) = 1 for all x ∈(−s, s) for
some s > 0, as constructed in the Exercises. Then, for any φ ∈D(R), we know that
ψ = (1 −ρr)φ has its support in R\ {0} and hence 0 = T (ψ) = T (φ) −T (ρrφ).
Using Taylor’s Theorem one can write
φ(x) =
n

i=0
xi
i! φ(i)(0) + xn+1φ1(x)
with
φ1(x) =
 1
0
(1 −t)n
n!
φ(n+1)(tx)dt
∈C∞(R).
This allows us to approximate the test function φ near x = 0 by a polynomial, and
the resulting approximation in D(R) is
ρrφ =
n

i=0
φ(i)(0)
i!
xiρrxn+1 + φ2
with φ2 = ρrφ1 ∈D(R). Thus
T (φ) = T (ρrφ) =
n

i=0
φ(i)(0)
i!
T (xiρr) + T (xn+1φ2) =
n

i=0
T (xiρr)
i!
(−1)iδ(i)(φ),
since T (xn+1φ2) = (xn+1T )(φ2) = 0. And we conclude that (4.9) holds with ci =
(−1)i
i! T (xiρr).
2
There is a multidimensional version of this result which will be addressed in
the Exercises. Though its proof relies on the same principle it is technically more
involved.
Proposition 4.7 A distribution T ∈D′(Rn) has its support in the point x0 ∈Rn if,
and only if, T is of the form (3.15) for some m ∈N and some coefﬁcients cα ∈K,
i.e.,
T =

|α|≤m
cαDαδx0.
Proof The proof that any distribution T ∈D′(Rn) which has its support in a point
x0 ∈Rn is necessarily of the form (3.15) is given here explicitly only for the case
n = 1 and x0 = 0. The general case is left as an exercise.
Thus, we assume that T ∈D′(R) has its support in {0}. And we will show that
then T solves the equation xm+1 · T = 0 for some m ∈N, and we conclude by
Proposition 4.6.
As in the proof of this proposition we choose some test function ρ ∈D(R) with
ρ(x) = 1 for all x ∈(−s, s) for some 0 < s < 1 and support in K = [−1, 1], as

4.4
Some Applications
57
constructed in the Exercises, and deﬁne for 0 < r < 1 the function ρr(x) = ρ( x
r ).
This function belongs to D(R), has its support in [−r, r] and is equal to 1 in (−rs, rs).
Then, for any ψ ∈D(R) the function φ = (1 −ρr)ψ belongs to D(R\ {0} ) and thus
T (φ) = 0 since supp T ⊆{0}, or by linearity of T , T (ψ) = T (ρrψ).
Since T is continuous on DK(R) there are a constant C ∈R+ and m ∈N such
that |T (φ)| ≤CpK,m(φ) for all φ ∈DK(R). Apply this estimate to ψ = xm+1ρrφ
for all φ ∈DK(R) to get
|T (xm+1ρrφ)| ≤CpK,m(xm+1ρrφ).
In the proof that multiplication by C∞-functions is continuous on D(Ω), we have
shown the estimate pK,m(uφ) ≤cpK,m(u)pK,m(φ) for all u ∈C∞(Ω) and all φ ∈
DK(Ω) with some constant c ∈R+ depending only on m and the dimension n. We
apply this here for u = xm+1ρr and get
|T (xm+1ρrφ)| ≤CpK,m(xm+1ρr)pK,m(φ)
∀φ ∈DK(R).
The ﬁrst factor we estimate as follows, using Leibniz’ formula and the identities
Dβxm+1 = (m+1)!
β!
xm+1−β and Dγ ρr(x) = r−γ (Dγ ρ)( x
r ):
pK,m(xm+1ρr)
≤supα≤msupx∈K

β+γ =α
α!
β!γ !|(m + 1)!
β!
xm+1−β|r−γ |Dγ ρ
x
r

|
≤supα≤msupx∈K

β+γ =α
α!
β!γ !|(m + 1)!
β!
rm+1−α|
x
r
m+1−β
(Dγ ρ)
x
r

|
≤rCpK,m(ρ).
Now collect all estimates to get, for each φ ∈DK(R) and all 0 < r < 1,
|T (xm+1φ)| = |T (xm+1ρrφ)| ≤CrpK,m(ρ)pK,m(φ).
Taking the limit r →0, it follows that T (xm+1φ) = 0 for every φ ∈DK(R) and
hence
xm+1 · T = 0
in
D′(R)
and we conclude.
2
4.4.2
Renormalization of
 1
x

+ = θ(x)
x
As an application of Proposition 4.7 we discuss a problem which plays a fundamental
role in relativistic quantum ﬁeld theory. Renormalization is about giving formal inte-
grals which do not exist in the Lebesgue sense a mathematically consistent meaning.
Here, the perspective given by distribution theory is very helpful.

58
4
Calculus for Distributions
Denote by θ as usual Heaviside’s function. As we have seen earlier, in the con-
text of introducing Cauchy’s principal value, the function ( 1
x )+ =
1
x θ(x) is not
locally integrable on R and thus ( 1
x )+ cannot be used directly to deﬁne a regular
distribution. Consider the subspace D0(R) = {φ ∈D(R) : φ(0) = 0} of the test
function space D(R). Every φ ∈D0(R) has the representation φ(x) = xψ(x) with
ψ(x) =
 1
0 φ′(tx)dt ∈D(R). Thus, we get a deﬁnition of ( 1
x )+ as a continuous
linear function D0(R) →K which agrees on (0, ∞), i.e., on the test function space
D(R\ {0} ), with the function 1
x θx, by the formula
⟨( 1
x )+, φ⟩=
 ∞
0
φ(x)
x
dx.
(4.10)
If K is any compact subset of R we get, for all φ ∈DK(R) ∩D0(R), the estimate
(|K| denotes the measure of the set K)
|⟨( 1
x )+, φ⟩| ≤|K|pK,1(φ)
which shows that Eq. (4.10) deﬁnes ( 1
x )+ = T0 as a continuous linear functional
of order 1 on D0(R). By the Hahn–Banach Theorem (see, for instance, [3, 2]) the
functional T0 has many continuous linear extensions T to all of D(R), of the same
order 1 as T0. This means the following: T is a continuous linear functional D(R) →
K such that |T (φ)| ≤|K|pK,1(φ) for all φ ∈DK(R) and T |D0(R) = T0. Such
extensions T of T0 are called renormalizations of ( 1
x )+. How many renormalizations
of ( 1
x )+ do we get? This can be decided with the help of Proposition 4.7. Since
T |D0(R) = T0 we ﬁnd that T can differ from T0 only by a distribution with support
in {0}, and since we know the orders of T and T0 it follows from Proposition 4.7 that
T = T0 + c0δ + c1δ′
with some constants ci ∈K.
In physics, a special 1-parameter family of renormalizations is considered. This
choice is motivated by the physical context in which the renormalization problem
occurs. For any 0 < M < ∞deﬁne for all φ ∈D(R),
⟨( 1
x )+,M, φ⟩=
 M
0
φ(x) −φ(0)
x
dx +
 ∞
M
φ(x)
x
dx.
It follows easily that ( 1
x )+,M is a distribution on R and ( 1
x )+,M|D0(R) = ( 1
x )+. Thus,
( 1
x )+,M is a renormalization of ( 1
x )+. If ( 1
x )+,M′ is another renormalization of this
family, a straightforward calculation shows that
( 1
x )+,M −( 1
x )+,M′ = −ln
 M
M′

δ.
Therefore, ( 1
x )+,M, 0 < M < ∞, is a 1-parameter family of renormalizations of
( 1
x )+. Now compare ( 1
x )+,M with any other renormalization T of ( 1
x )+. Since both

4.5
Exercises
59
renormalizations are equal to T0 on D0(R), and since we know T −T0 = c0δ + c1δ′,
we get 0 = c0φ(0) + c1φ′(0) for all φ ∈D0(R). But φ(0) = 0 for functions in
D0(R), hence c1 = 0. We conclude: Any renormalization of ( 1
x )+ differs from the
renormalization ( 1
x )+,M only by c0δ. Thus in this renormalization procedure only one
free constant appears.
Similar to the term ln ( M
M′ ) above, in the renormalization theory of relativistic
quantum ﬁeld theory free constants occur (as renormalized mass or renormalized
charge for instance ). In this way our simple example reﬂects the basic ideas of
the renormalization theory of relativistic quantum ﬁeld theory as developed by N.
Bogoliubov, O. S. Parasiuk, K. Hepp and later H. Epstein and V. Glaser [4–8].
4.5
Exercises
1. For f ∈Ck(Rn) show that
⟨IDαf , φ⟩= (−1)|α|⟨If , Dαφ⟩
∀φ ∈D(Rn).
2. Prove the following equation in the sense of distributions on R:
d
dx log |x| = vp 1
x .
Hints: Since log |x| ∈L1
loc(R) one has, for any φ ∈D(R),

R
log (|x|) φ(x)dx = lim
ε→0

|x|≥ε
log (|x|) φ(x)dx.
Recall in addition: limε→0 ε log ε = 0.
3. Using the relation log (x + iy) = log |x + iy| + i arg (x + iy) for x, y ∈R prove
that the following equation holds in the sense of distributions on R:
d
dx log(x + io) = vp 1
x −iπδ(x).
4. Show: A test function φ ∈D(R) is the derivative of some other test function
ψ ∈D(R), φ = ψ′ if, and only if, I(φ) =

R φ(x)dx = 0.
5. In calculus, we certainly have the identity c = DnPn with Pn(x) =
c
n!xn +
Pn−1(x) for any polynomial Pn−1 of degree ≤n −1. Show that this identity also
holds in D′(R), i.e., show the identity Ic = DnIPn.
6. Let u ∈Ck(Ω) be a classical solution of the constant coefﬁcient partial differ-
ential equation (4.3). Prove: P(D)Iu = If in D′(Ω), hence u solves this partial
differential equation in the sense of distributions.
7. For u ∈C∞(Ω), φ ∈D(Ω), K ⊂Ω compact, and m ∈N, show that
pK,m(Mu(φ)) ≤CpK,m(u)pK,m(φ)
for some constant C which depends only on m and n.

60
4
Calculus for Distributions
Hints: For all x ∈K and |α| ≤m, one can estimate as follows:


β+γ =α
α!
β!γ !Dβu(x)Dγ φ(x)

≤

β+γ =α
α!
β!γ ! sup
K
|Dβu(x)| sup
K
|Dγ φ(x)|.
8. Show: If u ∈Om(Rn) and φ ∈S(Rn), then Mu(φ) = u · φ ∈S(Rn) and
Mu : S(Rn) →S(Rn) is linear and continuous.
9. Let σ : Ωx →Ωy be a bijective C∞-transformation from a nonempty open set
Ωx ⊂Rn onto a (nonempty open) set Ωy. Show:
a) φ #→φ ◦σ −1 is a continuous linear mapping D(Ωx) →D(Ωy).
b) | det ∂σ −1
∂y | ∈C∞(Ωy).
10. Given any φ ∈D(Ω) and a ∈Rn prove that
lim
t→0
φta −φ
t
= −a · Dφ
in D(Ω).
Hints: Show ﬁrst:
(a · Dφ)(x) + φ(x −ta) −φ(x)
t
=
 1
0
a · [Dφ(x) −Dφ(x −sta)]ds
and then estimate the relevant semi-norms for t →0.
11. Given a closed interval [a, b] ⊂R and ε > 0, construct a function φ ∈D(R)
such that supp φ ⊆[a −ε, b + ε] and φ(x) = 1 for all x ∈(a + ε, b −ε). (We
assume ε ≪b −a.)
Hints: Normalize the function ρ in (2.14) such that

ρ(x)dx = 1 and deﬁne,
for 0 < r < 1, ρr(x) = 1
r ρ( x
r ). Then deﬁne a function ur on R by ur(x) =
 1
−1 ρr(x −y)dy. Show: ur ∈D(R), supp ur ⊆[−1 −r, 1 + r], and ur(x) = 1
for all x ∈(−1+r, 1−r). Finally, translation and rescaling produces a function
with the required properties.
12. Given a closed ball Br(x0) = {x ∈Rn : |x −x0| ≤r} and 0 < ε < r, construct
a function φ ∈D(Rn) such that φ(x) = 1 for all x ∈Rn with |x −x0| < r −ε
and supp φ ⊆Kr+ε(x0).
Hints: The strategy of the one-dimensional case applies.
13. Prove: For every u ∈Om(Rn) (see Proposition 4.3) the multiplication by u,
φ #→u · φ, is a continuous linear map from S(Rn) into S(Rn).
References
1. Bogolubov NN, Logunov AA, Oksak AI, Todorov IT. General principles of quantum ﬁeld
theory. Vol. 10 of mathematical physics and applied mathematics. Dordrecht: KluwerAcademic
Publishers; 1990.
2. Epstein H, Glaser V. The rôle of locality in perturbation theory. Ann Inst Henri Poincaré A.
1973;19:211.
3. Hepp K.Théorie de la renormalisation.Vol. 2 of lecture notes in physics. Berlin: Springer-Verlag;
1969.

References
61
4. Hörmander L. The analysis of linear partial differential operators. 1. Distribution theory and
Fourier analysis. Berlin: Springer-Verlag; 1983.
5. Hörmander L. The analysis of linear partial differential operators. 2. Differential operators of
constant coefﬁcients. Berlin: Springer-Verlag; 1983.
6. Reed M, Simon B. Functional analysis. Vol. 1 of methods of modern mathematical physics. 2nd
ed. New York: Academic Press; 1980.
7. Rudin W. Functional analysis. New York: McGraw Hill; 1973.
8. Zemanian AH. Distribution theory and transform analysis. An introduction to generalized
functions with applications. Dover books on mathematics. New York: McGraw-Hill; 1987.

Chapter 5
Distributions as Derivatives
of Functions
The general form of a distribution on a nonempty open set can be determined in
a relatively simple way as soon as the topological dual of a certain function space
is known. As we are going to learn in the second part, the dual of a Hilbert space
is easily determined. Thus, we use the freedom to deﬁne the topology on the test
function space through various equivalent systems of norms so that we can use the
simple duality theory for Hilbert spaces.
This chapter gives the general form of a distribution. Among other things the
results of this chapter show that the space of distribution D′(Ω) on a nonempty open
set Ω ⊂Rn is the smallest extension of the space C(Ω) of continuous functions on
Ω in which one can differentiate without restrictions in the order of differentiation,
naturally in the weak or distributional sense. Thus, we begin with a discussion
of weak differentiation and mention a few examples. Section 5.2 provides a result
which gives the general form of a distribution on a nonempty open set Ω ⊂Rn. How
measures and distributions are related and in which way they differ is explained in
Sect. 5.3. Section 5.4 presents tempered distributions and those which have a compact
support as weak derivatives of functions.
5.1
Weak Derivatives
In general, a locally integrable function f on a nonempty open set Ω ⊂Rn cannot
be differentiated. But we have learned how to interpret such functions as (regular)
distributions If , and we have learned to differentiate distributions. Thus, in this way
we know how to differentiate locally integrable functions.
Deﬁnition 5.1 The weak or distributional derivative Dαf of order α ∈Nn of a
function f ∈L1
loc(Ω) is a distribution on Ω deﬁned by the equation
⟨Dαf , φ⟩= (−1)|α|

f (x)Dαφ(x)dx
∀φ ∈D(Ω).
(5.1)
© Springer International Publishing Switzerland 2015
63
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_5

64
5
Distributions as Derivatives of Functions
From the section on the derivatives of distributions we recall that on the subspace
C|α|(Ω) of L1
loc(Ω) the weak and the classical derivative agree.
For m = 0, 1, 2, . . . introduce the space of all weak derivatives of order |α| ≤m
of all functions in L1
loc(Ω), i.e.,
D′
reg,m(Ω) =

Dαf : f ∈L1
loc(Ω), |α| ≤m

(5.2)
and then
D′
reg,∞(Ω) =
∞

m=0
D′
reg,m(Ω).
(5.3)
Certainly, the space D′
reg,∞(Ω) is a subspace of space D′(Ω) of all distributions
on Ω. In the following section, we show that both spaces are almost equal, more
precisely, we are going to show that locally every distribution T is a weak derivative
of functions in L1
loc(Ω). And this statement is still true if we replace L1
loc(Ω) by
the much smaller space C(Ω) of continuous functions on Ω. The term “locally” in
this statement means that the restriction TK of T to DK(Ω) is a weak derivative of
continuous functions.
Now let us look at some concrete examples. Suppose we are given m ∈N and a
set {fα : |α| ≤m} of continuous functions on Ω. Deﬁne a function T : D(Ω) →K
by
T (φ) =

|α|≤m

fα(x)Dαφ(x)dx
∀φ ∈D(Ω).
Elementary properties of Riemann integrals ensure that T is linear. On each
subspace DK(Ω) one has the estimate |T (φ)| ≤CpK,m(φ) with the constant
C = 
|α|≤m

K |fα(x)|dx. Thus, T is a distribution of constant local order m and
therefore the order of T is ﬁnite and equal to m.
Next, we consider a class of concrete examples of distributions for which the
local order is not constant. To this end recall the representation of D(Ω) as the strict
inductive limit of the sequence of complete metrizable spaces DKi(Ω), i ∈N:
D(Ω) =
∞

i=1
DKi(Ω).
(5.4)
Here Ki is a strictly increasing sequence of compact sets which exhaust Ω. Take a
strictly increasing sequence of integers mi and choose functions fα ∈L1
loc(Ω) with
the following speciﬁcations: supp fα ⊂K0 for |α| ≤m0 and supp fα ⊂Ki+1\Ki
for mi < |α| ≤mi+1, i = 1, 2, . . . . Then deﬁne linear functions Ti : DKi(Ω) →K

5.2
Structure Theorem for Distributions
65
by
Ti(φ) =

|α|≤mi

fα(x)Dαφ(x)dx
∀φ ∈DKi(Ω).
As above one sees that Ti is continuous on DKi(Ω) with the bound |Ti(φ)| ≤
CipKi,mi(φ) where Ci = 
|α|≤mi

Ki |fα(x)|dx. For all φ ∈DKi(Ω), we ﬁnd
Ti+1(φ) =

|α|≤mi

fα(x)Dαφ(x)dx = Ti(φ),
since

mi<|α|≤mi+1

fα(x)Dαφ(x)dx = 0,
because of the support properties of the functions fα. Hence, we get a well-deﬁned
continuous linear function T : D(Ω) →K by deﬁning T |DKi(Ω) = Ti for all i.
This distribution T is not of ﬁnite order on Ω.
5.2
Structure Theorem for Distributions
Again it is convenient to start with the representation of the test function space D(Ω)
as the strict inductive limit of the sequence of complete metrizable spaces DKi(Ω)
for a strictly increasing and exhaustive sequence of compact Ki. Then we can say
that T is a distribution on Ω if, and only if, Ti = T |DKi(Ω) ∈D′
Ki(Ω) for all i ∈N.
This leads to the ﬁrst step in analyzing the structure of distributions.
Proposition 5.1 Let Ω ⊂Rn be a nonempty open set. Represent the test functions
space D(Ω) as the strict inductive limit of the complete metrizable spaces DKi(Ω)
for a strictly increasing and exhaustive sequence of compact sets Ki (see Eq. (5.4)).
Then the following characterization of distribution holds.
1. A distribution T ∈D′(Ω) determines, in a unique way, a sequence of functionals
Ti ∈D′
Ki(Ω) which satisﬁes the compatibility condition
Ti+1|DKi(Ω) = Ti
∀i ∈N.
(5.5)
2. Conversely, any sequence of functionals Ti ∈D′
Ki(Ω) which satisﬁes the com-
patibility condition (5.5) determines in a unique way a distribution T on Ω by
deﬁning
T |DKi(Ω) = Ti
∀i ∈N.
(5.6)
Proof Since we know DKi(Ω) ⋐DKi+1(Ω), the proof of the ﬁrst part is obvious.
For the proof of the second part note that the compatibility condition (5.5) ensures
that a linear function T : D(Ω) →K is well deﬁned by Eq. (5.6). Continuity of T

66
5
Distributions as Derivatives of Functions
follows from the deﬁnition of the inductive topology on D(Ω) and the continuity of
the Ti.
2
According to this result, the general form of a distribution is known as soon as
we know the general form of continuous linear functionals on the spaces DK(Ω).
This can be achieved in a fairly easy way on the basis of a fundamental result from
the theory of Hilbert spaces which determines the general form of continuous linear
functionals on a Hilbert space. According to the Riesz–Fréchet Theorem of Part II
(Theorem 16.3), every continuous linear functional on a Hilbert space H is of the
form h #→⟨u, h⟩, ∀h ∈H, where ⟨·, ·⟩is the inner product of the Hilbert space and
the element u ∈H is determined uniquely by the functional.
As a second input we use the fact that the topology of the space DK(Ω) can be
deﬁned in terms of the ﬁltering system of seminorms qK,m(φ) =

⟨φ, φ⟩K,m where
⟨φ, ψ⟩K,m =

|α|≤m

K
Dαφ(x)Dαψ(x)dx
∀φ, ψ ∈DK(Ω),
is a scalar product on DK(Ω). (See the Subsect. 2.1.1). The completion of the space
DK(Ω) with respect to this scalar product produces a Hilbert space HK,m whose
scalar product is denoted in the same way.
Proposition 5.2
Let T be a continuous linear functional on the space DK(Ω),
Ω ⊂Rn open and nonempty, K ⊂Ω compact. Then there is an m ∈N and there
are elements uα in the Hilbert space L2(K) of square integrable functions on K such
that
T (φ) =

|α|≤m

K
uα(x)Dαφ(x)dx
∀φ ∈DK(Ω),
i.e., T is a sum of weak derivatives of square integrable functions on K:
T =

|α|≤m
(−1)|α|DαIuα.
Proof
By deﬁnition of the topology on DK(Ω), given T ∈D′
K(Ω), there are a
constant C and there is m ∈N such that |T | ≤CqK,m. Then T has a continuous and
linear extension TK to the Hilbert space HK,m which is obtained as the completion
of DK(Ω) with respect to the norm qK,m. As mentioned above, continuous linear
functions on the Hilbert space HK,m are deﬁned in terms of the scalar product ⟨·, ·⟩K,m
and some element u ∈HK,m. Therefore, we have TK(v) = ⟨u, v⟩K,m for all v ∈HK,m.
Taking the speciﬁc form of the scalar product into account, we thus get for all
φ ∈DK(Ω) ⊂HK,m, since TK is an extension of T
T (φ) = TK(φ) = ⟨u, φ⟩K,m =

|α|≤m

K
Dαu(x)Dαφ(x)dx.
Introducing the functions uα = Dαu the formula for T follows.
2

5.3
Radon Measures
67
Propositions 5.1 and 5.2 together determine the general form of distributions. In
terms of the results in Proposition 5.2 the compatibility condition of Proposition 5.1
could be evaluated more explicitly but we omit this since it is not used later.
Consider, for a moment, the case n = 1. If we integrate uα ∈L2(K) we get
a continuous function vα(x) =
 x
a uα(y)dy where a ∈K is arbitrary such that
Dvα = uα. Thus, in the representation formula for T ∈D′
K(Ω) in Proposition 5.2
we can use continuous functions instead of square integrable functions by increasing
the order of differentiation correspondingly. In particular, this representation is not
unique. Though formally more involved these statements hold for the general case
too.
Collecting the results from above we arrive at the structure theorem for
distributions.
Theorem 5.1 Let Ω ⊂Rn be a nonempty open set and Ki be a strictly increasing
sequence of compact sets which exhaust Ω. T is a distribution on Ω, if and only if,
there is a sequence of nonnegative integers mi and for each i ∈N there are elements
ui,α ∈L2(Ki), |α| ≤mi such that for i = 0, 1, 2, . . . ,
T (φ) = Ti(φ) ≡

|α|≤mi

Ki
ui,α(x)Dαφ(x)dx
∀φ ∈DKi(Ω)
(5.7)
and, for all φ ∈DKi(Ω),

|α|≤mi+1

Ki+1
ui+1,α(x)Dαφ(x)dx =

|α|≤mi

Ki
ui,α(x)Dαφ(x)dx.
(5.8)
Proof
Note that Eq. (5.8) is just the compatibility condition for the sequence of
functionals Ti ∈D′
Ki(Ω) deﬁned in Eq. (5.7) according to Proposition 5.2. Thus, by
Proposition 5.1 and Proposition 5.2 we conclude Theorem 5.1.
2
5.3
Radon Measures
As previously, Ω denotes a nonempty open subset of Rn. Introduce the space C0(Ω)
of all continuous functions f : Ω →R, which have a compact support in Ω. For a
compact subset K of Ω denoted by CK(Ω), the subspace of all functions in C0(Ω)
which have a support is contained in K. On the spaces CK(Ω), K ⊂Ω compact, we
use the norms pK,0 introduced in Chap. 2. Equip the space C0(Ω) with the inductive
limit topology of the spaces (CK(Ω), pK,0). A continuous linear functional on this
space C0(Ω) is called a real Radon measure on Ω. In more concrete terms one has
the following characterization.
Corollary 5.1 A linear functional μ : C0(Ω) →R is a real Radon measure on Ω
if, and only if, for every compact subset K ⊂Ω there is a constant C such that
|μ(f )| ≤CpK,0(f )
∀f ∈CK(Ω).

68
5
Distributions as Derivatives of Functions
Obviously, one has DK(Ω) ⊂CK(Ω) and D(Ω) ⊂C0(Ω) and the natural
embeddings are continuous. Hence, every real Radon measure is a distribution.
Now we discuss some order theoretic properties of the test function space C0(Ω)
for Radon measures which the test function space D(Ω) for distributions does not
have. Denote by C0,+(Ω) the set of all nonnegative functions in C0(Ω). Given f ∈
C0(Ω), deﬁne f±(x) = max {±f (x), 0}. It follows that f± ∈C0,+(Ω) and f =
f+ −f−. This shows
C0(Ω) = C0,+(Ω) −C0,+(Ω).
We deduce that every real Radon measure μ is the difference of two positive Radon
measuresμ+ andμ−: μ = μ+ −μ−. Suchdecompositionsdonotholdindistribution
theory, neither on the level of test functions nor on the level of distributions. In
general, a continuously differentiable real valued function cannot be written as the
differenceoftwononnegativedifferentiablefunctions(take, forinstance, theexample
of the sine function). Nevertheless, there is an interesting order theoretic implication
for distributions.
Theorem 5.2 Every nonnegative linear form T : D(Ω) →R, i.e., T (φ) ≥0 for
all nonnegative φ ∈D(Ω), is the restriction of a positive Radon measure μ to D(Ω),
and thus in particular is continuous.
Proof
Suppose that T is a nonnegative linear function D(Ω) →R. Introduce
the restrictions TK of T to DK(Ω). Clearly, TK is a nonnegative linear function
on DK(Ω) and the net TK, K ⊂Ω compact, satisﬁes the compatibility condition
TK2|DK1 = TK1 for all compact sets K1 ⊂K2 ⊂Ω.
Given a compact set K ⊂Ω, there are a compact set K′ ⊂Ω such that K ⋐K′
and a nonnegative function ψ ∈DK′(Ω) which is equal to 1 on K. Therefore, the
estimate
−ψ(x)pK,0(φ) ≤φ(x) ≤pK,0(φ)ψ(x)
holds for all x ∈Ω and all φ ∈DK(Ω). Since TK′ is nonnegative, it preserves this
estimate:
−TK′(ψ)pK,0(φ) ≤TK′(φ) ≤TK′(ψ)pK,0(φ)
and thus, since TK(φ) = TK′(φ) for all φ ∈DK(Ω),
|TK(φ)| = |TK′(φ)| ≤TK′(ψ)pK,0(φ)
for all φ ∈DK(Ω). This shows continuity of TK for every compact subset K ⊂Ω.
Hence, T is a distribution on Ω, of order 0.
This continuity estimate for TK allows us to extend TK to a nonnegative linear
function μK : CK(Ω) →R with the same bound. This extension process preserves
the compatibility condition of the net TK, K ⊂Ω compact. Thus, we can deﬁne a
continuous linear function μ : C0(Ω) →R by setting μ|CK(Ω) = μK for K ⊂Ω)
compact. Since each μK is nonnegative, μ is a nonnegative Radon measure on Ω,
and by construction one has μ|D(Ω) = T .
Further details of the proof are given in [1, 2].
2

5.4
The Case of Tempered and Compactly Supported Distributions
69
5.4
The Case of Tempered and Compactly
Supported Distributions
The results on the structure of distributions show that locally every distribution is a
weak derivative of functions. In the case of tempered distributions and those distri-
butions which have a compact support this result holds globally, as we are going to
prove.
For the case of distributions with compact support this is fairly obvious. We have
learned that a distribution T on a nonempty open set Ω with compact support is a
continuous linear functional on the test function space E(Ω), i.e., there is a compact
subset K ⊂Ω and there are a constant C ∈R+ and m ∈N such that |T (φ)| ≤
CqK,m(φ) for all φ ∈E(Ω). Here, we have used again the fact that the two ﬁltering
systems of seminorms {pK,m : m = 0, 1, 2, . . .} and {qK,m : m = 0, 1, 2, . . .} are
equivalent. Now we can proceed as in Proposition 5.2 and conclude. Note however,
that the distribution and the functions representing this distribution through a process
of taking weak derivatives need not have the same support. As an example consider
Dirac’s delta function δ which has its support in the point x = 0. And we have
learned that δ can be represented as the weak derivative θ′ of the Heaviside function
θ which has its support in R+.
By deﬁnition, a tempered distribution T on Ω ⊆Rn is a linear functional T :
S(Ω) →K for which there are constants C ∈R+ and m, k ∈N such that
|T (φ)| ≤Cpm,k(φ)
∀φ ∈S(Ω).
Again, the ﬁltering system of norms

pm,k : m, k = 0, 1, 2, . . .

is equivalent to the
ﬁltering system

qm,k : m, k = 0, 1, 2, . . .

of norms qm,k(φ) =

⟨φ, φ⟩m,k deﬁned
by the scalar product
⟨φ, ψ⟩m,k =

|α|≤k

Ω
Dαφ(x)Dαψ(x)(1 + x2)mdx
∀φ, ψ ∈S(Ω).
(5.9)
Thus, we can assume |T | ≤Cqm,k for some constant C and some nonnegative
integers m and k. This allows us to proceed as in the proof of Proposition 5.2. Thus,
there is an element u in the Hilbert space Hm,k deﬁned as the completion of S(Ω)
with respect to the norm qm,k such that
T (φ) = ⟨u, φ⟩m,k =

|α|≤k

Ω
Dαu(x)Dαφ(x)(1 + x2)mdx
∀φ ∈S(Ω).
Introduce the function uα(x) = (1 + x2)mDαu(x) on Ω. Since u ∈Hm,k, we know,
for all |α| ≤k, that

Ω
|uα(x)(1 + x2)−m
2 |2dx
(5.10)
is ﬁnite and thus we formulate the structure theorem for tempered distributions.

70
5
Distributions as Derivatives of Functions
Theorem 5.3 Let Ω ⊆Rn be an open nonempty set. T is a tempered distribution
on Ω if, and only if, there are nonnegative integers m, k and there are measurable
functions uα on Ω, |α| ≤k, for which the integrals (5.10) are ﬁnite such that
T (φ) =

|α|≤k

Ω
uα(x)Dαφ(x)dx
∀φ ∈S(Ω),
(5.11)
i.e.,
T =

|α|≤k
(−1)|α|DαIuα.
Proof IntheExercisesweshowthatEq.(5.11)indeeddeﬁnesatempereddistribution
on Ω. That conversely every tempered distribution is of this form we have shown
above. Thus we conclude.
2
Note that this theorem says that tempered distributions are globally of ﬁnite order.
Corollary 5.2 Every tempered distribution T on Rn is a ﬁnite order derivative of a
continuous polynomially bounded function t, i.e., there is some multi-index γ ∈Nn
such that for all φ ∈S(Rn)
T (φ) =

t(x)Dγ φ(x)dx
(5.12)
and one has suppT = supp t.
Proof According to Theorem 5.3, every T ∈S′(Rn) is of the form
T =

|α|≤k
(−1)|α|Dαuα
with measurable functions uα which satisfy condition (5.10) where we have omitted
the embedding mapping I. An inverse of differentiation is integration. So for some
reference point x0 = (x0
1, . . ., x0
n) introduce the partial integration Ij on integrable
functions f
Ijf (x1, . . ., xj, . . ., xn) =
 xj
x0
j
f (x1, . . ., ξj, . . ., xn)dξj.
Clearly, DjIjf = f and I1 · · · Inf is continuous for integrable f and polynomially
bounded if f is. Furthermore, using multi-index notation in a natural way we have
DβI βf = f . Now choose some multi-index γ = (γ1, . . ., γn) such that γj ≥
αj + 1, for j = 1, . . ., n for all multi-indices α which occur in (5.10) and then multi-
indices βα such that γ = α + βα. By choice of γ we ensure that for all α one has
βα ≥(1, 1, . . ., 1) (component-wise). Finally, deﬁne
t(x) = (−1)|γ | 
|α|≤k
(−1)|α|I βαuα .

References
71
It follows that t is a polynomially bounded continuous function which satisﬁes
(−1)|γ |Dγ t =

|α|≤k
(−1)|α|Dα+βαI βαuα =

|α|≤k
(−1)|α|DαDβαI βαuα
=

|α|≤k
(−1)|α|Dαuα = T.
The support condition can be shown indirectly using continuity of the function t.
2
5.5
Exercises
1. Prove: The two ﬁltering systems of norms P =

pm,k : m, k = 0, 1, 2, . . .

and
Q =

qm,k : m, k = 0, 1, 2, . . .

on S(Ω) are equivalent.
2. Show that Eq. (5.11) deﬁnes a tempered distribution.
3. Find an example of a distribution which is not a tempered distribution.
Hints: Try regular distributions.
4. Show: Every continuous polynomially bounded function on Rn deﬁnes a dis-
tribution in S′(Rn) ∩D′
reg(Rn), but not every continuous function on Rn which
deﬁnes a distribution in S′(Rn) ∩D′
reg(Rn) is polynomially bounded.
Hints: Try the function f (x) = ex sin ex = −d
dx ( cos ex) on R.
References
1. Donoghue WF. Distributions and Fourier transforms. New York: Academic; 1969.
2. Schwartz L. Théorie des distributions. Vol. 1, 2nd ed. Paris: Hermann; 1957.

Chapter 6
Tensor Products
The tensor product of distributions is a very important tool in the analysis of distri-
butions. We will use it mainly in the deﬁnition of the convolution for distributions
which in turn has many important applications, some of which we will discuss in later
chapters (approximation of distributions by smooth functions, analysis of partial dif-
ferential operators with constant coefﬁcients). The tensor product for distributions is
naturally based on the tensor product of the underlying test function spaces and their
completions. Accordingly, we start by developing the theory of tensor products of
test function spaces to the extent which is needed later. The following section gives
the deﬁnition and the main properties of the tensor product for distributions. We
assume that the reader is familiar with the deﬁnition of the algebraic tensor product
of general vector spaces. A short reminder is given in Sect. 18.2.
6.1
Tensor Product for Test Function Spaces
In the chapter on (elementary aspects of) calculus for distributions we discussed
among other things a product between functions, between distributions and certain
classes of functions, and between distributions if the distributions involved satisﬁed
certain restrictions. This pointwise product assigns to two functions (or distributions)
on a set Ω ⊂Rn a new function (distribution) on the same set Ω.
On the other side, the tensor product assigns to two functions (distributions) fi
on (in general) two different open sets Ωi, i = 1, 2, a new function (distribution) on
the product set Ω1 × Ω2. To be more speciﬁc, assume that Ω1 ⊂Rn1 and Ω2 ⊂Rn2
are two nonempty open sets and φi ∈D(Ωi) are two test functions on Ω1 and Ω2,
respectively. The tensor product of φ1 and φ2 is the function φ1⊗φ2 : Ω1×Ω2 →K
deﬁned by
φ1 ⊗φ2(x1, x2) = φ1(x1)φ2(x2)
∀(x1, x2) ∈Ω1 × Ω2.
(6.1)
Certainly, the tensor product φ1 ⊗φ2 is a C∞-function on Ω1 × Ω2 which has a
compact support; thus φ1 ⊗φ2 ∈D(Ω1 × Ω2) for all φi ∈D(Ωi). The vector space
© Springer International Publishing Switzerland 2015
73
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_6

74
6
Tensor Products
spanned by all these tensor products φ1⊗φ2 is denoted by D(Ω1)⊗D(Ω2).A general
element in D(Ω1) ⊗D(Ω2) is of the form
N

i=1
φi ⊗ψi,
φi ∈D(Ω1),
ψi ∈D(Ω2),
i = 1, 2, . . ., N;
(6.2)
and it follows that the algebraic tensor product D(Ω1) ⊗D(Ω2) of the test function
spaces D(Ω1) and D(Ω2) is contained in the test function space over the product set
Ω1 × Ω2:
D(Ω1) ⊗D(Ω2) ⊂D(Ω1 × Ω2).
As a subspace of the test function space D(Ω1 ×Ω2) the tensor product space carries
naturally the relative topology of D(Ω1 × Ω2). A ﬁrst important observation is that
this tensor product space is dense in the test function space D(Ω1 × Ω2).
Proposition 6.1 Suppose that Ωi ⊆Rni, i = 1, 2, are nonempty open sets. Then the
tensor product space D(Ω1)⊗D(Ω2) of the test function spaces D(Ωi) is sequentially
dense in the test function space D(Ω1 × Ω2) over the product set Ω1 × Ω2, i.e.,
D(Ω1) ⊗D(Ω2)
τ = D(Ω1 × Ω2),
(6.3)
where τ indicates that the closure is taken with respect to the topology of the space
D(Ω1 × Ω2).
Proof We have to show that any given ψ ∈D(Ω1 ×Ω2) is the limit of a sequence of
elements in D(Ω1) ⊗D(Ω2), in the sense of uniform convergence for all derivatives
on every compact subset K ⊂Ω1 × Ω2. This is done in several steps.
Given ψ ∈D(Ω1 × Ω2) we introduce in a ﬁrst step the sequence of auxiliary
functions ψk deﬁned by
ψk(z) =

Rn ek(z −ξ)ψ(ξ)dξ =

Rn ek(ξ)ψ(z −ξ)dξ.
Here the following notation is used: n = n1 + n2, z = (x1, x2) ∈Ω1 × Ω2 and
ek(z) =

k
√
2π
n
e−k2z2.
Observe that ek ∈C∞(Rn) and

Rn ek(z)dz = 1 for all k ∈N. Without giving the
details of the straightforward proof we state, for all α ∈Nn, for the derivatives,
Dαψk(z) =

Rn ek(ξ)(Dαψ)(z −ξ)dξ
for all k ∈N. Since all derivatives Dαψ of ψ are uniformly continuous on Rn,
given ε > 0 there is a δ > 0 such that |(Dαψ)(z) −(Dαψ)(z −ξ)| < ε for all
z ∈Rn and all ξ ∈Rn with |ξ| < δ. The normalization of ek allows us to write
(Dαψ)(z) −(Dαψ)k(z) as the integral

ek(ξ)[(Dαψ)(z) −(Dαψ)(z −ξ)]dξ which
can be estimated, in absolute value, by

6.1
Tensor Product for Test Function Spaces
75

|ξ|≤δ
ek(ξ)|(Dαψ)(z)−(Dαψ)(z−ξ)|dξ +

|ξ|>δ
ek(ξ)|(Dαψ)(x)−(Dαψ)(z−ξ)|dξ.
By choice of δ, using the notation ||Dαψ||∞= supz∈Rn |(Dαψ)(z)|, this estimate
can be continued by
≤ε

|ξ|≤δ
ek(ξ)dξ + 2∥(Dαψ)∥∞

|ξ|>δ|
ek(ξ)dξ.
The ﬁrst integral is obviously bounded by 1 while for the second integral we ﬁnd

|ξ|>δ
ek(ξ)dξ = π−n
2

|z|>kδ
e−z2dz ≤ε
for all k ≥k0 for some sufﬁciently large k0 ∈N. Therefore, uniformly in z ∈Rn,
for all k ≥k0,
|(Dαψ)(z) −(Dαψk)(z)| ≤2ε.
We deduce: Every derivative Dαψ of ψ is the uniform limit of the sequence of
corresponding derivatives Dαψk of the sequence ψk.
In a second step, by using special properties of the exponential function, we pre-
pare the approximation of the elements of the sequence ψk by functions in the tensor
product space D(Ω1) ⊗D(Ω2). To this end we use the power series representation
of the exponential function and introduce, for each k ∈N, the sequence of functions
deﬁned by the formula
ψk,N(z) =
 k
√π
n
N

i=0
1
i!

Rn [ −k2(z −ξ)2]iψ(ξ)dξ.
As in the ﬁrst step the derivative of these functions can easily be calculated. One
ﬁnds
Dαψk,N(z) =
N

i=0
1
i!
 k
√π
n 
Rn [ −k2(z −ξ)2]i(Dαψ)(ξ)dξ
and therefore we estimate, for all z ∈Rn such that |z−ξ| ≤R for all ξ in the support
of ψ for some ﬁnite R, as follows:
|Dαψk,N(z) −Dαψk(z)|
≤( k
√π )n ∞
i=N+1
1
i!|k2(z −ξ)2|i|(Dαψ)(ξ)|dξ
≤IN(k, R)

Rn |(Dαψ)(ξ)|dξ
where
IN(k, R) =
 k
√π
n
∞

i=N+1
(kR)2i
i!
→0
as N →∞.
Using the binomial formula to expand (z −ξ)2i and evaluating the resulting
integrals, we see that the functions ψk,N are actually polynomials in z of degree

76
6
Tensor Products
≤2N, and recalling that z stands for the pair of variables (x1, x2) ∈Rn1 × Rn2, we
see that these functions are of the form
ψk,N(x1, x2) =

|α|, |β|≤2N
Cα,βxα
1 xβ
2 .
Since ψ ∈D(Ω1 × Ω2), there are compact subsets Kj ⊂Ωj such that suppψ ⊆
K1 × K2. Now choose test functions χj ∈D(Ωj) which are equal to 1 on Kj,
j = 1, 2. It follows that (χ1 ⊗χ2) · ψ = ψ and
φk,N = (χ1 ⊗χ2) · ψk,N ∈D(Ω1) ⊗D(Ω2)
∀k, N ∈N,
since the ψk,N are polynomials.
For any compact set K ⊂Rn there is a positive real number R such that |z−ξ| ≤R
for all z ∈K and all ξ ∈K1 × K2. From the estimates of the second step, for all
α ∈Nn, we know that Dαψk,N(z) converges uniformly in z ∈K to Dαψk(z). Using
Leibniz’ rule we deduce
lim
N→∞φk,N = (χ1 ⊗χ2) · ψk ≡φk
in D(Ω1 × Ω2).
Again using Leibniz’ rule we deduce from the estimates of the ﬁrst step that
lim
k→∞φk = (χ1 ⊗χ2) · ψ = ψ
in D(Ω1 × Ω2)
and thus we conclude.
2
On the algebraic tensor product E ⊗F of two Hausdorff locally convex topo-
logical vector space E and F over the same ﬁeld, several interesting locally convex
topologies can be deﬁned. We discuss here brieﬂy the projective tensor product topol-
ogy which plays an important role in the deﬁnition and study of tensor products for
distributions. Let P (respectively Q) be the ﬁltering system of seminorms deﬁning
the topology of the space E (respectively of F). Recall that the general element χ in
E ⊗F is of the form
χ =
m

i=1
ei ⊗fi
with ei ∈E and fi ∈F, i = 1, . . ., m any m ∈N.
(6.4)
Note that this representation of the element χ in terms of factors ei ∈E and fi ∈F
is not unique. In the following deﬁnition of a semi-norm on E ⊗F, this is taken into
account by taking the inﬁmum over all such representations of χ. Now given two
seminorms p ∈P and q ∈Q, the projective tensor product p ⊗π q of p and q is
deﬁned by
p ⊗π q(χ) = inf
 m

i=1
p(ei)q(fi) : χ =
m

i=1
ei ⊗fi

.
(6.5)
In the Exercises we show that this formula deﬁnes indeed a seminorm on the tensor
product E ⊗F. It follows immediately that
p ⊗π q(e ⊗f ) = p(e)q(f )
∀e ∈E, ∀f ∈F.
(6.6)

6.2
Tensor Product for Distributions
77
From the deﬁnition it is evident that p⊗π q ≤p′ ⊗q and p⊗π q ≤p⊗q′ whenever
p, p′ ∈P satisfy p ≤p′ and q, q′ ∈Q satisfy q ≤q′. Therefore the system
P ⊗π Q = {p ⊗π q : p ∈P, q ∈Q}
(6.7)
of seminorms on E ⊗F is ﬁltering and thus deﬁnes a locally convex topology on
E ⊗F, called the projective tensor product topology. The vector space E ⊗F
equipped with this topology is denoted by
E ⊗π F
and is called the projective tensor product of the spaces E and F.
This deﬁnition applies in particular to the test function spaces E = D(Ω1), Ω1 ⊆
Rn1, and F = D(Ω2), Ω2 ⊆Rn2. Thus we arrive at the projective tensor product
D(Ω1) ⊗π D(Ω2) of these test function spaces. The following theorem identiﬁes the
completion of this space which plays an important role in the deﬁnition of tensor
products for distributions. The general construction of the completion is given in the
Appendix A.
Theorem 6.1 Assume Ωj ⊆Rnj are nonempty open sets. The completion of the
projective tensor product D(Ω1) ⊗π D(Ω2) of the test function spaces over Ωj is
equal to the test function space D(Ω1 × Ω2) over the product Ω1 × Ω2 of the sets
Ωj:
D(Ω1) ˜⊗πD(Ω2) = D(Ω1 × Ω2).
(6.8)
6.2
Tensor Product for Distributions
Knowing the tensor product of two functions f , g ∈L1
loc(Ωi), we are going to
deﬁne the tensor product for distributions in such a way that it is compatible with
the embedding of functions into the space of distributions and the tensor product for
functions. Traditionally the same symbol ⊗is used to denote the tensor product for
distributions and for functions. Thus our compatibility condition means If ⊗Ig =
If ⊗g for all f , g ∈L1
loc(Ω). Since we know how to evaluate If ⊗g we get
⟨If ⊗Ig, φ ⊗ψ⟩
= ⟨If ⊗g, φ ⊗ψ⟩
=

Ω1×Ω2 (f ⊗g)(x, y)(φ ⊗ψ)(x, y)dxdy
=

Ω1×Ω2 f (x)g(y)φ(x)ψ(y)dxdy = ⟨If , φ⟩⟨Ig, ψ⟩
for all φ ∈D(Ω1) and all ψ ∈D(Ω2). Hence the compatibility with the embedding
is assured as soon as the tensor product for distributions is required to satisfy the
following identity, for all T ∈D′(Ω1), all S ∈D′(Ω2), all φ ∈D(Ω1), and all
ψ ∈D(Ω2),
⟨T ⊗S, φ ⊗ψ⟩= ⟨T , φ⟩⟨S, ψ⟩.
(6.9)

78
6
Tensor Products
Since the tensor product is to be deﬁned in such a way that it is a continuous linear
functional on the test function space over the product set, this identity determines the
tensor product of two distributions immediately on the tensor product D(Ω1)⊗D(Ω2)
of the test function spaces by linearity:
⟨T ⊗S, χ⟩=
N

i=1
⟨T , φi⟩⟨S, ψi⟩
∀χ =
N

i=1
φi ⊗ψi ∈D(Ω1) ⊗D(Ω2).
(6.10)
Thus we know the tensor product on the dense subspace D(Ω1)⊗D(Ω2) of D(Ω1 ×
Ω2) and this identity allows us to read off the natural continuity requirement for
T ⊗S. Suppose Ki ⊂Ωi are compact subsets. Then there are constants Ci ∈R+
and integers mi such that |⟨T , φ⟩| ≤C1pK1,m1(φ) for all φ ∈DK1(Ω1) and |⟨S, ψ⟩| ≤
C2pK2,m2(ψ) for all ψ ∈DK2(Ω2) and thus, using the abbreviations pi = pKi,mi,
|⟨T ⊗S, χ⟩| ≤
N

i=1
|⟨T , φi⟩||⟨S, ψi⟩| ≤
N

i=1
C1C2p1(φi)p2(ψi)
for all representations of χ = N
i=1 φi ⊗ψi, and it follows that
|⟨T ⊗S, χ⟩| ≤C1C2 inf
 N

i=1
p1(φi)p2(ψi) : χ =
N

i=1
φi ⊗ψi

,
i.e.,
|⟨T ⊗S, χ⟩| ≤C1C2(p1 ⊗π p2)(χ).
(6.11)
Hence the tensor product T ⊗S of the distributions T on Ω1 and S on Ω2 is a con-
tinuous linear function D(Ω1)⊗π D(Ω2) →K which can be extended by continuity
to the completion of this space. In Theorem 6.1 this completion has been identiﬁed
as D(Ω1 × Ω2).
We prepare our further study of the tensor product for distributions by some
technical results. These results are also used for the study of the convolution for
distributions in the next chapter.
Lemma 6.1 Suppose Ωi ⊆Rni are nonempty open sets and φ : Ω1 × Ω2 →K is
a function with the following properties:
(a) For every y ∈Ω2 deﬁne φy(x) = φ(x, y) for all x ∈Ω1. Then φy ∈D(Ω1) for
all y ∈Ω2.
(b) For all α ∈Nn1 the function Dα
x φ(x, y) is continuous on Ω1 × Ω2.
(c) For every y0 ∈Ω2 there is a neighborhood V of y0 in Ω2 and a compact set
K ⊂Ω1 such that for all y ∈V the functions φy have their support in K.
Then, for every distribution T ∈D′(Ω1) on Ω1, the function y #→f (y) = ⟨T , φy⟩
is continuous on Ω2.

6.2
Tensor Product for Distributions
79
Proof
Suppose y0 ∈Ω2 and r > 0 are given. Choose a neighborhood V of y0
and a compact set K ⊂Ω1 according to hypothesis (c). Since T is a distribution on
Ω1 there are a constant C and an integer m such that |⟨T , φ⟩| ≤CpK,m(φ) for all
φ ∈DK(Ω1). By hypothesis (b) the derivatives Dα
x φ(x, y) are continuous on K×Ω2.
It follows (see the Exercises) that there is a neighborhood W of y0 in Ω2 such that
for all y ∈W,
pK,m(φy −φy0) ≤r
C .
Since for all y ∈V ∩W the functions φy belong to DK(Ω1) we get the estimate
|f (y) −f (y0)| = |⟨T , φy⟩−⟨T , φy0⟩| = |⟨T , φy −φy0⟩| ≤CpK,m(φy −φy0) ≤r.
Therefore f is continuous at y0 and since y0 was arbitrary in Ω2, continuity of f on
Ω2 follows.
2
Corollary 6.1 Under the hypotheses of Lemma 6.1 with hypothesis (b) replaced by
the assumption φ ∈C∞(Ω1 × Ω2), the function y #→f (y) = ⟨T , φy⟩is of class C∞
on Ω2 for every distribution T ∈D′(Ω1), and one has
Dβ
y ⟨T , φy⟩= ⟨T , Dβ
y φy⟩.
Proof Differentiation is known to be a local operation in the sense that it preserves
support properties. Thus we have
1. Dβ
y φy ∈D(Ω1) for all y ∈Ω2;
2. Dα
x Dβ
y φ(x, y) is continuous on Ω1 × Ω2 for all α ∈Nn1 and all β ∈Nn2;
3. For every β ∈Nn2 and every y0 ∈Ω2 there are a neighborhood V of y0 in Ω2
and a compact set K ⊂Ω1 such that suppDβ
y φy ⊆K for all y ∈V .
By Lemma 6.1 it follows that, for each T ∈D′(Ω1) and each β ∈Nn2, the functions
y #→⟨T , Dβ
y φy⟩are continuous on Ω2. In order to conclude we have to show that
the functions ⟨T , Dβ
y φy⟩are just the derivatives of order β of the function ⟨T , φy⟩.
This is quite a tedious step. We present this step explicitly for |β| = 1.
Take any y0 ∈Ω2 and choose a neighborhood V of y0 and the compact set
K ⊂Ω1 according to the third property above. Take any T ∈D′(Ω1). For this
compact set K and this distribution there are a constant C and an integer m such that
|⟨T , ψ⟩| ≤CpK,m(ψ) for all ψ ∈DK(Ω1). The neighborhood V contains an open
ball y0 + Br(0) around y0, for some r > 0. Abbreviate ∂i =
∂
∂yi and calculate for
h ∈Br(0), as an identity for C∞-functions of compact support in K ⊂Ω1,
φy0+h −φy0
=
 1
0
d
dt φy0+thdt =
= n2
i=1 (∂iφ)y0hi + n2
i=1
 1
0 [(∂iφ)y0+th −(∂iφ)y0]hidt.
Applying the distribution T to this identity gives
⟨T , φy0+h −φy0⟩= n2
i=1⟨T , (∂iφ)y0⟩hi
+ n2
i=1⟨T ,
 1
0 [(∂iφ)y0+th −(∂iφ)y0]⟩hidt.

80
6
Tensor Products
For all |α| ≤m and i = 1, 2, . . ., n2 the functions Dα
x (∂iφ)(x, y) are continuous on
Ω1 × Ω2 and have a compact support in the compact set K for all y ∈V . Thus, as
in the proof of Lemma 6.1, given ε > 0 there is δ > 0 such that for all i = 1, . . ., n2
and all |y −y0| < δ one has pK,m((∂iφ)y −(∂iφ)y0) ≤ε
C ; and we can assume δ ≤r.
It follows that
pK,m
 1
0
[(∂iφ)y0+th −(∂iφ)y0]dt

≤
 1
0
pK,m([(∂iφ)y0+th −(∂iφ)y0])dt ≤ε
C
and thus
|⟨T ,
 1
0
[(∂iφ)y0+th −(∂iφ)y0]dt⟩| ≤CpK,m
 1
0
[(∂iφ)y0+th −(∂iφ)y0]dt

≤ε.
We deduce that
⟨T , φy0+h −φy0⟩=
n2

i=1
⟨T , (∂iφ)y0⟩hi + o(h).
Therefore the function f (y) = ⟨T , φy⟩is differentiable at the point y0 and the
derivative is given by
∂i⟨T , φy0⟩= ⟨T , (∂iφ)y0⟩,
i = 1, . . ., n2.
The functions ∂iφ satisfy the hypotheses of Lemma 6.1, hence the functions y #→
⟨T , (∂iφ)y⟩are continuous and thus the function f (y) = ⟨T , φy⟩has continuous
ﬁrst-order derivatives.
Since with a function φ all the functions (x, y) #→Dβ
y φ(x, y), β ∈Nn2, satisfy
the hypothesis of the corollary, the above arguments can be iterated and thus we
conclude.
2
The hypotheses of the above corollary are satisﬁed in particular for test functions
on Ω1 × Ω2. This case will be used for establishing an important property of the
tensor product for distributions.
Theorem 6.2 Suppose that Ωi ⊂Rni, i = 1, 2, are nonempty open sets.
(a) For φ ∈D(Ω1 × Ω2) and T ∈D′(Ω1) deﬁne a function ψ on Ω2 by
ψ(y) = ⟨T , φy⟩.
Then ψ is a test function on Ω2: ψ ∈D(Ω2).
(b) Given compact subsets Ki ⊂Ωi and an integer m2, there is an integer m1
depending on K1 and the distribution T such that
pK2,m2(ψ) ≤p′
K1,m1(T )pK1×K2,m1+m2(φ)
(6.12)
for all φ ∈DK1×K2(Ω1 × Ω2).
(c) The assignment (T , φ) #→ψ deﬁned in part (a) deﬁnes a bilinear map F :
D′(Ω1) × D(Ω1 × Ω2) →D(Ω2) by F(T , φ) ≡ψ.

6.2
Tensor Product for Distributions
81
(d) The map F : D′(Ω1) × D(Ω1 × Ω2) →D(Ω2) has the following continuity
property: F is continuous in φ ∈D(Ω1 × Ω2), uniformly in T ∈B, B a weakly
bounded subset of D′(Ω1).
Proof It is straightforward to check that a test function φ ∈D(Ω1, Ω2) satisﬁes the
hypotheses of Corollary 6.1. Hence this corollary implies that ψ ∈C∞(Ω2). There
are compact subsets Ki ⊂Ωi such that supp φ ⊆K1 × K2. Thus the functions φy
are the zero function on Ω1 for all y ∈Ω2\K2 and therefore supp ψ ⊆K2. This
proves the ﬁrst part.
For φ ∈DK1×K2(Ω1 × Ω2) one knows that all the functions (Dβ
y φ)y, y ∈K2,
β ∈Nn2 belong to DK1(Ω1). Since T ∈D′(Ω1), there is an m1 ∈N such that
p′
K1,m1(T ) is ﬁnite and
|⟨T , (Dβ
y φ)y⟩| ≤p′
K1,m1(T )pK1,m1((Dβ
y φ)y)
for all y ∈K2 and all β. By Corollary 6.1 we know that
Dβψ(y) = ⟨T , (Dβ
y φ)y⟩,
therefore
|Dβψ(y)| ≤p′
K1,m1(T )pK1,m1((Dβ
y φ)y) = p′
K1,m1(T )
sup
x∈K1, |α|≤m1
|Dα
x Dβ
y φ(x, y)
and we conclude that
pK2,m2(ψ) ≤p′
K1,m1(T )pK1×K2,m1+m2(φ).
Thus the second part follows.
Since F(T , φ) = ⟨T , φ·⟩, F is certainly linear in T ∈D′(Ω1). It is easy to see
that for every ﬁxed y ∈Ω2 the map φ #→φy is a linear map D(Ω1 ×Ω2) →D(Ω1).
Hence F is linear in φ too and part (c) is proven.
Forpart(d)observethatbytheuniformboundednessprinciplea(weakly)bounded
set B ⊂D′(Ω1) is equicontinuous on DK1(Ω1) for every compact subset K1 ⊂Ω1.
This means that we can ﬁnd some m1 ∈N such that
sup
T ∈B
p′
K1,m1(T ) < ∞
and thus by estimate (6.12) we conclude.
2
Theorem 6.3 (TensorProductforDistributions)SupposethatΩi ⊆Rni, i = 1, 2,
are nonempty open sets.
(a) Given Ti ∈D′(Ωi) there is exactly one distribution T ∈D′(Ω1×Ω2) on Ω1×Ω2
such that
⟨T , φ1 ⊗φ2⟩= ⟨T1, φ1⟩⟨T2, φ2⟩
∀φi ∈D(Ωi), i = 1, 2.
T is called the tensor product of T1 and T2, denoted by T1 ⊗T2.

82
6
Tensor Products
(b) The tensor product satisﬁes Fubini’s Theorem (for distributions), i.e., for every
Ti ∈D′(Ωi), i = 1, 2, and for every χ ∈D(Ω1 × Ω2) one has
⟨T1 ⊗T2, χ⟩= ⟨(T1 ⊗T2)(x, y), χ(x, y)⟩
= ⟨T1(x), ⟨T2(y), χ(x, y)⟩⟩= ⟨T2(y), ⟨T1(x), χ(x, y)⟩⟩.
(c) Given compact subsets Ki ⊂Ωi there are integers mi ∈N such that p′
Ki,mi(Ti)
are ﬁnite for i = 1, 2 and for all χ ∈DK1×K2(Ω1 × Ω2),
|⟨T1 ⊗T2, χ⟩| ≤p′
K1,m1(T1)p′
K2,m2(T2)pK1×K2,m1+m2(χ).
(6.13)
Proof
Given Ti ∈D′(Ωi) and χ ∈D(Ω1 × Ω2) we 6.2 that F(T1, χ) ∈D(Ω2).
Thus
⟨T , χ⟩= ⟨T2, F(T1, χ)⟩
(6.14)
is well deﬁned for all χ ∈D(Ω1 ×Ω2). Since F is linear in χ, linearity of T2 implies
linearity of T . In order to show that T is a distribution on Ω1 × Ω2, it sufﬁces to
show that T is continuous on DK1×K2(Ω1 ×Ω2) for arbitrary compact sets Ki ⊂Ωi.
For any χ ∈DK1×K2(Ω1 × Ω2) we know by Theorem 6.2 that F(T1, χ) ∈DK2(Ω2).
Since T2 ∈D′(Ω2) there is m2 ∈N such that p′
K2,m2(T2) is ﬁnite, and we have the
estimate
|⟨T , χ⟩| = |⟨T2, F(T1, χ)⟩| ≤p′
K2,m2(T2)pK2,m2(F(T1, χ)).
Similarly, since T1 ∈D′(Ω1), there is an m1 ∈N such that p′
K1,m1(T1) is ﬁnite so
that the estimate (6.12) applies. Combining these two estimates yields
|⟨T , χ⟩| ≤p′
K1,m1(T1)p′
K2,m2(T2)pK1×K2,m1+m2(χ)
for all χ ∈DK1×K2(Ω1 × Ω2) with integers mi depending on Ti and Ki. Thus
continuity of T follows.
For χ = φ1 ⊗φ2, φi ∈D(Ωi), we have F(T1, χ) = ⟨T1, φ1⟩φ2 and therefore the
distribution T factorizes as claimed:
⟨T , φ1 ⊗φ2⟩= ⟨T1, φ1⟩⟨T2, φ2⟩.
By linearity this property determines T uniquely on the tensor product space D(Ω1)⊗
D(Ω2) which is known to be dense in D(Ω1×Ω2) by Proposition 6.1. Now continuity
of T on D(Ω1 ×Ω2) implies that T is uniquely determined by T1 and T2. This proves
part (a).
Above we deﬁned T = T1 ⊗T2 by the formula ⟨T , χ⟩= ⟨T2(y), ⟨T1(x), χ(x, y)⟩⟩
for all χ ∈D(Ω1 × Ω2). With minor changes in the argument one can show that
there is a distribution S on Ω1 × Ω2, well deﬁned by the formula
⟨S, χ⟩= ⟨T1(x), ⟨T2(y), χ(x, y)⟩⟩
for all χ ∈D(Ω1 × Ω2). Clearly, on the dense subspace D(Ω1) ⊗D(Ω2) the
continuous functionals S and T agree. Hence they agree on D(Ω1 × Ω2) and this
proves Fubini’s theorem for distributions.

6.2
Tensor Product for Distributions
83
The estimate given in part (c) has been shown in the proof of continuity of T =
T1 ⊗T2.
2
The following corollary collects some basic properties of the tensor product for
distributions.
Corollary 6.2 Suppose that Ti are distributions on nonempty open sets Ωi ⊂Rni.
Then the following holds:
(a) supp (T1 ⊗T2) = supp T1 ⊗supp T2.
(b) Dα
x (T1 ⊗T2) = (Dα
x T1) ⊗T2. Here x refers to the variable of T1.
Proof . The straightforward proof is done as an exercise.
2
Proposition 6.2 The tensor product for distributions is jointly continuous in both
factors, i.e., if T = limj→∞Tj in D′(Ω1) and S = limj→∞Sj in D′(Ω2), then
T ⊗S = lim
j→∞Tj ⊗Sj
in D′(Ω1 × Ω2).
Proof Recall that we consider spaces of distributions equipped with the weak topol-
ogy σ (compare Theorem 3.3). Thus, for every χ ∈D(Ω1 × Ω2), we have to show
that
⟨T ⊗S, χ⟩= lim
j→∞⟨Tj ⊗Sj, χ⟩.
By Proposition 6.1 and its proof we know: Given χ ∈DK(Ω1 × Ω2) there are
compact sets Ki ⊂Ωi, K ⊂K1 × K2, such that χ is the limit in DK1×K2(Ω1 × Ω2)
of a sequence in DK1(Ω1) ⊗DK2(Ω2).
Since T = limj→∞Tj, Eq. (3.12) of Theorem 3.3 implies that there is an m1 ∈N
such that
p′
K1,m1(Tj) ≤M1
∀j ∈N
and similarly there is an m2 ∈N such that
p′
K2,m2(Sj) ≤M2
∀j ∈N.
These bounds also apply to the limits T , respectively S.
Now, given ε > 0, there is a χε ∈DK1(Ω1) ⊗DK2(Ω2) such that
pK1×K2,m1+m2(χ −χε) <
ε
4M1M2
.
By part (c) of Theorem 6.3 this implies the following estimate:
|(Tj ⊗Sj)(χ −χε)| ≤M1M2pK1×K2,m1+m2(χ −χε) ≤ε/4
∀j ∈N.
And the same bound results for T ⊗S.
Finally we put all information together and get, for all j ∈N,
|(T ⊗S −Tj ⊗Sj)(χ)| ≤|(T ⊗S −Tj ⊗Sj)(χ −χε)| + |(T ⊗S −Tj ⊗Sj)(χε)|

84
6
Tensor Products
≤2M1M2pK1 ⊗K2,m1+m2(χ −χε) + |(T ⊗S −Tj ⊗Sj)(χε)|
≤ε/2 + |(T ⊗S −Tj ⊗Sj)(χε)|.
On D(Ω1) ⊗D(Ω2) the sequence (Tj ⊗Sj)j∈N certainly converges to T ⊗S (see
Exercises). Hence there is j0 ∈N such that |(T ⊗S −Tj ⊗Sj)(χε)| < ε/2 for all
j ≥j0. It follows that
|(T ⊗S −Tj ⊗Sj)(χ)| < ε
∀j ≥j0.
This concludes the proof.
2
6.3
Exercises
1. Prove: Formula 6.5 for the projective tensor product of two seminorms p, q on E
respectively on F deﬁnes indeed a seminorm on the tensor product E ⊗F.
2. Prove Theorem 6.1!
Hint: Consult the book [1].
3. Complete the proof of Lemma 6.1.
4. Prove the following: Assume that a sequence (φj)j∈N converges in D(Ω) to
φ ∈D(Ω) and the sequence of distributions (Tj)j∈N ⊂D′(Ω) converges weakly
to T ∈D′(Ω). Then the sequence of numbers (Tj(φj))j∈N converges to the
number T (φ), i.e.,
lim
j→∞Tj(φj) = T (φ).
Hint: In the Appendix C.1 it is shown that a weakly bounded set in D′(Ω) is
equicontinuous.
5. Prove Corollary 6.2.
6. Assume T = limj→∞Tj in D′(Ω1) and S = limj→∞Sj in D′(Ω2). Prove: For
every χ ∈D(Ω1) ⊗D(Ω2) one has limj→∞Tj ⊗Sj(χ) = T ⊗S(χ).
Reference
1. Trèves F. Topological vector spaces, distributions and kernels. New York: Academic; 1967.

Chapter 7
Convolution Products
Ourgoalistointroduceandtostudytheconvolutionproductfordistributions. Inorder
to explain the difﬁculties that will arise there, we discuss ﬁrst the convolution product
for functions.Also for functions the convolution product is only deﬁned under certain
restrictions. Thus we start with the class C0(Rn) of continuous functions on Rn which
has a compact support.
7.1
Convolution of Functions
Suppose u, v ∈C0(Rn); then for each x ∈Rn we know that y #→u(x −y)v(y) is
a continuous function of compact support and therefore the integral of this function
over Rn is well deﬁned. This integral then deﬁnes the convolution product u ∗v of u
and v at the point x:
u ∗v(x) =

Rn u(x −y)v(y)dy
∀x ∈Rn.
(7.1)
The following proposition presents elementary properties of the convolution product
on C0(Rn).
Proposition 7.1
The convolution (i.e., the convolution product) is a well-deﬁned
map C0(Rn) × C0(Rn) →C0(Rn). For u, v ∈C0(Rn) one has
i) u ∗v = v ∗u,
ii) supp (u ∗v) ⊆supp u + supp v.
Proof
We saw above that u ∗v is a well-deﬁned function on Rn. Note that
u(x −y)v(y) = 0 whenever y ̸∈supp v or x −y ̸∈supp u. It follows that the inte-
gral

Rn u(x −y)v(y)dy vanishes whenever x ∈Rn cannot be represented as the
sum of a point in supp u and a point in supp v. This implies that supp (u ∗v) ⊆
supp u + supp v = supp u + supp v, since supp u and supp v are compact sets (see
the Exercises). This proves part ii).
© Springer International Publishing Switzerland 2015
85
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_7

86
7
Convolution Products
Since (x, y) #→u(x −y)v(y) is a uniformly continuous function on Rn × Rn, the
integration over a compact set gives a continuous function (see the Exercises). Thus,
u ∗v is a continuous function of compact support.
The change of variables y #→x −z gives

Rn u(x −y)v(y)dy =

Rn u(z)v(x −z)dz = (v ∗u)(x)
and proves part i).
2
Corollary 7.1 If u ∈Cm
0 (Rn) and v ∈C0(Rn), then u∗v ∈Cm
0 (Rn) and Dα(u∗v) =
(Dαu)∗v for all |α| ≤m; similarly, if u ∈C0(Rn) and v ∈Cm
0 (Rn) then u∗v ∈Cm
0 (Rn)
and Dα(u ∗v) = u ∗(Dαv) for all |α| ≤m.
Proof For |α| ≤m the function (x, y) #→(Dαu)(x −y)v(y) is uniformly continuous
on Rn × Rn; integration with respect to y is over the compact set supp v and thus
gives the continuous function (Dαu) ∗v. Now the repeated application of the rules
of differentiation of integrals with respect to parameters implies the ﬁrst part. From
the commutativity of the convolution product the second part is obvious.
2
Naturally, the convolution of two functions u and v is deﬁned whenever the integral
in Eq. (7.1) exists. Obviously this is the case not only for continuous functions
of compact support but for a much larger class. The following proposition looks
at a number of cases for which the convolution product has convenient continuity
properties in the factors and which are useful in practical problems.
Proposition 7.2 Let u, v : Rn →K be two measurable functions. Denote |f |∞=
ess supx∈Rn |f (x)| and |f |1 =

Rn |f (x)|dx. Then the following holds.
a) If u ∈L∞(Rn) and v ∈L1(Rn), then u∗v ∈L∞(Rn) and ∥u ∗v∥∞≤∥u∥∞∥v∥1.
b) If u ∈L1(Rn) and v ∈L∞(Rn), then u∗v ∈L∞(Rn) and ∥u ∗v∥∞≤∥u∥1∥v∥∞.
c) If u, v ∈L1(Rn), then u ∗v ∈L1(Rn) and ∥u ∗v∥1 ≤∥u∥1∥v∥1.
Proof Considertheﬁrstcase. Onehas|

Rn u(x−y)v(y)dy| ≤

Rn |u(x−y)| |v(y)|dy
≤∥u∥∞∥v∥1 and part a) follows. Similarly one proves b). For the third part we have
to use Fubini’s theorem:
∥u ∗v∥1 =

Rn|(u ∗v)(x)|dx ≤

Rn

Rn |u(x −y)| |v(y)|dy

dx
≤

Rn

Rn |u(x −y)| |v(y)|dx

dy
=

Rn

Rn |u(z)| |v(y)|dzdy = ∥u∥1 ∥v∥1.
2
Another important case where the convolution product of functions is well deﬁned
and has useful properties is the case of strongly decreasing functions. The following
proposition collects the main results.

7.1
Convolution of Functions
87
Proposition 7.3
1. If u, v ∈S(Rn), then the convolution u ∗v is a well-deﬁned element in S(Rn).
2. Equipped with the convolution ∗as a product, the space S(Rn) of strongly
decreasing test functions is a commutative algebra.
Proof
Recall the basic characterization of strongly decreasing test functions: u ∈
C∞(Rn) belongs to S(Rn) if, and only if, for all m, l ∈N the norms pm,l(u) are ﬁnite.
It follows that for every α ∈Nn and every m ∈N one has
|Dαu(x)| ≤pm,|α|(u)
(1 + x2)
m
2
∀x ∈Rn.
Thus, for u, v ∈S(Rn), for all m, k ∈N and all α ∈Nn, the estimate

Rn |(Dαu)(x −y)v(y)|dy ≤

Rn
pm,|α|(u)
(1 + (x −y)2)
m
2
pk,0(v)
(1 + x2)
k
2
dy
is available, uniformly in x ∈Rn. If we choose k ≥n + 1, the integral on the right
hand side is ﬁnite; therefore in this case the convolution (Dαu) ∗v exists. As earlier
one shows Dα(u ∗v) = (Dαu) ∗v, and we deduce u ∗v ∈C∞(Rn).
In order to control the decay properties of the convolution u ∗v observe that
1 + x2
[1 + (x −y)2][1 + y2] ≤2
∀x, y ∈Rn.
For k = n + 1 + m we thus get
(1 + x2)
m
2 |Dα(u ∗v)(x)| ≤pm,|α|(u)pk,o(v)2
m
2

Rn
dy
(1 + y2)
n+1
2
.
The integral in this estimate has a ﬁnite value C. This holds for any m ∈N and any
α ∈Nn. We conclude that u ∗v ∈S(Rn) and
pm,l(u ∗v) ≤2
m
2 Cpm,l(u)pn+1+m,0(v).
(7.2)
This estimate also shows that the convolution is continuous on S(Rn). As earlier the
commutativity of the convolution is shown: u ∗v = v ∗u for all u, v ∈S(Rn). This
proves the second part and thus the proposition.
2
The main application of the convolution is in the approximation of functions by
smooth (i.e., C∞-) functions and in the approximation of distributions by smooth
functions. The basic technical preparation is provided by the following proposition.
Proposition 7.4 Suppose that (φi)i∈N is a sequence of continuous function on Rn
with support in the closed ball BR(0) = {x ∈Rn : ∥x∥≤R}. Assume furthermore
i) 0 ≤φi(x) for all x ∈Rn and all i ∈N;
ii)

Rn φi(x)dx = 1 for all i ∈N;
iii) For every r > 0 one has limi→∞

Br(0)c φi(x)dx = 0.

88
7
Convolution Products
For u ∈C(Rn) deﬁne an approximating sequence by the convolution
ui = u ∗φi
i ∈N.
Then the following statements hold:
a) The sequence ui converges to the given function u, uniformly on every compact
subset K ⊂Rn;
b) For u ∈Cm(Rn) and |α| ≤m the sequence of derivatives Dαui converges,
uniformly on every compact set K, to the corresponding derivative Dαu of the
given function u;
c) If in addition to the above assumptions the functions φi are of class C, then the
approximating functions ui = u ∗φi are of class C∞and statements a) and b)
hold.
Proof In order to prove part a) we have to show: given a compact set K ⊂Rn and
ε > 0 there is an i0 ∈N (depending on K and ε) such that for all i ≥i0,
∥u −ui∥K,∞≡sup
x∈K
|u(x) −ui(x)| ≤ε.
With K also the set H = K + BR(0) is compact in Rn. Therefore, as a continuous
function on Rn, u is bounded on H, by M let us say. Since continuous functions are
uniformly continuous on compact sets, given ε > 0 there is a δ > 0 such that for
all x, x′ ∈H one has |u(x) −u(x′)| < ε
2 whenever |x −x′| < δ. The normalization
condition ii) for the functions φi allows us to write
u(x) −ui(x) =

Rn [u(x) −u(x −y)]φi(y)dy
and thus, for all x ∈K, we can estimate as follows:
|u(x) −ui(x)| ≤

Bδ(0)
|u(x) −u(x −y)|φi(y)dy
+

Bδ(0)c |u(x) −u(x −y)|φi(y)dy
≤

Bδ(0)
ε
2φi(y)dy + 2M

Bδ(0)c φi(y)dy
≤ε
2 + 2M

Bδ(0)c φi(y)dy.
According to hypothesis iii) there is an i0 ∈N such that

Bδ(0)c φi(y)dy <
ε
4M for all
i ≥i0. Thus we can continue the above estimate by
|u(x) −ui(x)| < ε
2 + 2M ε
4M
∀x ∈K, ∀i ≥i0.
This implies statement a).

7.2
Regularization of Distributions
89
If u ∈Cm(Rn) and |α| ≤m, then Dαu ∈C(Rn) and by part a) we know (Dαu) ∗
φi →Dαu, uniformly on compact sets. Corollary 7.1 implies that Dαui = Dα(u ∗
φi) = (Dαu) ∗φi. Hence part b) follows.
This corollary also implies that ui = u ∗φi ∈C∞(Rn) whenever φi ∈C∞(Rn).
Thus we can argue as in the previous two cases.
2
Naturally the question arises how to get sequences of functions φi with the prop-
erties i)–iii) used in the above proposition. Recall the section on test function spaces.
There, in the Exercises we deﬁned a nonnegative function ρ ∈D(Rn) by Eq. (2.14).
Denote a =

Rn ρ(x)dx and deﬁne
φi(x) = in
a ρ(ix)
∀x ∈Rn ∀i ∈N.
(7.3)
Given ε > 0, choose i0 > 1
ε. Then for all i ≥i0 one has

Bε(0)c φi(x)dx = 1
a

|x|≥ε
inρ(ix)dx = 1
a

|y|≥iε
ρ(y)dy = 0,
since supp ρ ⊆{y ∈Rn : |y| ≤1}. Now it is clear that this sequence satisﬁes the
hypotheses of Proposition 7.4.
Corollary 7.2 Suppose Ω ⊆Rn is a nonempty open set and K ⊂Ω is compact.
Given ε, 0 < ε < dist(∂Ω, K), denote Kε = {x ∈Ω : dist(K, x) ≤ε}. Then, for
any continuous function f on Ω with support in K there is a sequence (ui)i∈N in
DKε(Ω) such that
lim
i→∞pK,0(f −ui) = 0.
If the function f is nonnegative, then also all the elements ui of the approximating
sequence can be chosen to be nonnegative.
Proof See the Exercises.
2
7.2
Regularization of Distributions
This section explains how to approximate distributions by smooth functions. This
approximation is understood in the sense of the weak topology on the space of
distributions and is based on the convolution of distributions with test functions.
Given a test function φ ∈D(Rn) and a point x ∈Rn, the function y #→φx(y) =
φ(x −y) is again a test function and thus every distribution on Rn can be applied to
it. Therefore one can deﬁne, for any T ∈D′(Rn),
(T ∗φ)(x) = ⟨T , φx⟩= ⟨T (y), φ(x −y)⟩
∀x ∈Rn.
(7.4)
This function T ∗φ : Rn →K is called the regularization of the distribution T by
the test function φ, since we will learn soon that T ∗φ is actually a smooth function.

90
7
Convolution Products
This deﬁnition of a convolution product between a distribution and a test function
is compatible with the embedding of functions into the space of distributions. To see
this take any f ∈L1
loc(Rn) and use the above deﬁnition to get
(If ∗φ)(x) = ⟨If , φx⟩=

Rn f (y)φx(y)dy = (f ∗φ)(x)
∀x ∈Rn,
where naturally f ∗φ is the convolution product of functions as discussed earlier.
Basic properties of the regularization are collected in the following theorem.
Theorem 7.1 (Regularization) For any T ∈D′(Rn) and any φ, ψ ∈D(Rn) one
has:
a) T ∗φ ∈C∞(Rn) and, for all α ∈Nn,
Dα(T ∗φ) = T ∗Dαφ = DαT ∗φ;
b) supp (T ∗φ) ⊆supp T + supp φ;
c) ⟨T , φ⟩= (T ∗ˇφ)(0)
where
ˇφ(x) = φ( −x)
∀x ∈Rn;
d) (T ∗φ) ∗ψ = T ∗(φ ∗ψ).
Proof For any test function φ ∈D(Rn) we know that χ(x, y) ≡φ(x −y) belongs
to C∞(Rn × Rn). Given any x0 ∈Rn take a compact neighborhood Vx0 of x0 in
Rn. Then K = Vx0 −supp φ ⊂Rn is compact, and for all x ∈Vx0 we know that
supp χx = {x} −supp φ ⊂K, χx(y) = χ(x, y). It follows that all hypotheses of
Corollary 6.1 are satisﬁed and hence this corollary implies T ∗φ ∈C∞(Rn) and
Dα(T ∗φ) = T ∗Dαφ.
Now observe Dα
y φ(x −y) = ( −1)|α|Dα
x φ(x −y), hence, for all x ∈Rn,
(T ∗Dαφ)(x) = ⟨T (y), (Dαφ)(x −y)⟩= ⟨T (y), ( −1)|α|Dα
y φ(x −y)⟩
= ⟨DαT (y), φ(x −y)⟩= (DαT ∗φ)(x).
This proves part a).
In order that (T ∗φ)(x) does not vanish, the sets {x} −supp T and supp φ must
have a nonempty intersection, i.e., x ∈supp T + supp φ. Since supp φ is compact
and supp T is closed, the vector sum supp T + supp φ is closed. It follows that
supp (T ∗φ) = {x ∈Rn : (T ∗φ)(x) ̸= 0} ⊆supp T + supp φ = supp T + supp φ,
and this proves part b).
The proof of part c) is a simple calculation.
(T ∗ˇφ)(0) = ⟨T (y), ˇφ(0 −y)⟩= ⟨T (y), φ(y)⟩= ⟨T , φ⟩.
Proposition 7.1 and Corollary 7.1 together show that φ ∗ψ ∈D(Rn) for all
φ, ψ ∈D(Rn). Hence, by part a) we know that T ∗(φ ∗ψ) is a well-deﬁned

7.2
Regularization of Distributions
91
C∞-function on Rn. For every x ∈Rn it is given by
⟨T (y),

Rn φ(x −y −z)ψ(z)dz⟩.
As we know that T ∗φ is a C-function, the convolution product (T ∗φ) ∗ψ has the
representation, for all x ∈Rn,

Rn (T ∗φ)(x −z)ψ(z)dz =

Rn⟨T (y), φ(x −y −z)⟩ψ(z)dz.
Hence the proof of part d) is completed by showing that the action of the distribution
T with respect to the variable y and integration over Rn with respect to the variable
z can be exchanged. This is done in the Exercises.
2
Note that in part b) the inclusion can be proper. A simple example is the constant
distribution T = I1 and test functions φ ∈D(R) with

R φ(x)dx = 0. Then we have
(T ∗φ)(x) =

R φ(x)dx = 0 for all x ∈R, thus supp T ∗φ = ∅while supp I1 = R.
As preparation for the main result of this section, namely the approximation
of distributions by smooth functions, we introduce the concept of a regularizing
sequence.
Deﬁnition 7.1 A sequence of smooth functions φj on Rn is called a regularizing
sequence if, and only if, it has the following properties.
a) There is a φ ∈D(Rn), φ ̸= 0, such that φj(x) = j nφ(jx) for all x ∈Rn,
j = 1, 2, . . . ;
b) φj ∈D(Rn) for all j ∈N;
c) 0 ≤φj(x) for all x ∈Rn and all j ∈N;
d)

Rn φj(x)dx = 1 for all j ∈N.
Certainly, if we choose a test function φ ∈D(Rn) which is nonnegative and which is
normalized by

Rn φ(x)dx = 1 and introduce the elements of the sequence as in part
a), then we get a regularizing sequence. Note furthermore that every regularizing
sequence converges to Dirac’s delta distribution δ since regularizing sequences are
special delta sequences, as discussed earlier.
Theorem 7.2 (Approximation of Distributions) For any T ∈D′(Rn) and any
regularizing sequence (φj)j∈N, the limit in D′(Rn) of the sequence of C∞-functions
Tj on Rn, deﬁned by Tj = T ∗φj for all j = 1, 2, . . . , is T , i.e.,
T = lim
j→∞Tj = lim
j→∞T ∗φj
in
D′(Rn).
Proof According to Theorem 7.1 we know that T ∗φj ∈C(Rn). If φ ∈D(Rn) is
the starting element of the regularizing sequence, we also know supp φj ⊂supp φ
for all j ∈N. Take any ψ ∈D(Rn), then K = supp φ −supp ψ is compact and
supp (φj ∗ˇψ) ⊂K for all j ∈N (see part ii) of Proposition 7.1). Part c) of Proposition
7.4 implies that the sequence Dα(φj ∗ψ) converges uniformly on K to Dα ˇψ, for all

92
7
Convolution Products
α ∈Nn, hence the sequence (φj ∗ˇψ)j∈N converges to ˇψ in DK(Rn). Now use part
c) of Theorem 7.1 to conclude through the following chain of identities using the
continuity of T on DK(Rn):
lim
j→∞

(T ∗φj)(x)ψ(x)dx = lim
j→∞((T ∗φj) ∗ˇψ)(0)
= lim
j→∞(T ∗(φ∗ˇψ))(0)
= lim
j→∞⟨T , (φj ∗ˇψ)⟩= ⟨T , ψ⟩.
2
Remark 7.1
a) The convolution gives a bi-linear mapping D′(Rn) × D(Rn)
→C∞(Rn) deﬁned by (T , φ) #→T ∗φ.
b) Theorem 7.1 shows that C∞(Rn) is dense in D′(Rn). In the Exercises we show that
also D(Rn) is dense in D′(Rn). We mention without proof that for any nonempty
open set Ω ⊂Rn the test function space D(Ω) is dense in the space D′(Ω) of
distributions on Ω.
c) The results of this section show that, and how, every distribution is the limit
of a sequence of C∞-functions. This observation can be used to derive another
characterization of distributions. In this characterization a distribution is deﬁned
as a certain equivalence class of Cauchy sequences of C∞-functions. Here a
sequence of C∞-functions fj is said to be a Cauchy sequence if, and only if,

fj(x)φ(x)dx is a Cauchy sequence of numbers, for every test function φ. And
two such sequences are called equivalent if, and only if, the difference sequence
is a null sequence.
d) We mention a simple but useful observation. The convolution product is transla-
tion invariant in both factors, i.e., for T ∈D′(Rn), φ ∈D(Rn), and every a ∈Rn
one has
(T ∗φ)a = Ta ∗φ = T ∗φa.
For the deﬁnition of the translation of functions and distributions compare
Eq. (4.6).
We conclude this section with an important result about the connection between
differentiation in the sense of distributions and in the classical sense. The key of the
proof is to use regularization.
Lemma 7.1 Suppose u, f ∈C(Rn) satisfy the equation Dju = f in the sense of
distributions. Then this identity holds in the classical sense too.
Proof Suppose two continuous functions u, f are related by f = Dju =
∂u
∂xj , in the
sense of distributions. This means that for every test function φ the identity
−

u(y)Djφ(y)dy =

f (y)φ(y)dy

7.3
Convolution of Distributions
93
holds.
Next choose a regularizing sequence.
Assume ψ ∈D(Rn) satisﬁes

ψ(y)dy = 1. Deﬁne, for ε > 0, ψε(x) = ε−nψ( x
ε ). (With ε = 1
i , i ∈N, we have
a regularizing sequence as above). Now approximate u and f by smooth functions:
uε = u ∗ψε,
fε = f ∗ψε.
uε and fε are C∞-functions, and as ε →0, they converge to u, respectively f ,
uniformly on compact sets (see Proposition 7.4). A small calculation shows that
Djuε(x) =

u(y)Djψε(x −y)dy = −

u(y)Dyj ψε(x −y)dy,
and taking the identity Dju = f in D′(Rn) into account we ﬁnd
Djuε(x) =

f (y)ψε(x −y)dy = fε(x).
Denote the standard unit vector in Rn in coordinate direction j by ej and calculate,
for h ∈R, h ̸= 0,
1
h[uε(x + hej) −uε(x)] =
 1
0
(Djuε)(x + thej)dt =
 1
0
fε(x + thej)dt.
Take the limit ε →0 of this equation. Since uε and fε converge uniformly on compact
sets to u, respectively f , we get in the limit for all |h| ≤1, h ̸= 0,
1
h[u(x + hej) −u(x)] =
 1
0
f (x + thej)dt.
It follows that we can take the limit h →0 of this equation and thus u has a partial
derivative Dju(x) at the point x in the classical sense, which is given by f (x). Since
x was arbitrary we conclude.
2
7.3
Convolution of Distributions
As we learned earlier, the convolution product u ∗v is not deﬁned for arbitrary pairs
of functions (u, v). Some integrability conditions have to be satisﬁed. Often these
integrability conditions are realized by support properties of the functions. Since the
convolutionproductfordistributionsistobedeﬁnedinsuchawaythatitiscompatible
with the embedding of functions, we will be able to deﬁne the convolution product
for distributions under the assumption that the distributions satisfy a certain support
condition which will be developed below.
In order to motivate this support condition we calculate, for f ∈C0(Rn) and
g ∈C(Rn), the convolution product f ∗g that is known to be a continuous function

94
7
Convolution Products
and thus can be considered as a distribution. For every test function φ the following
chain of identities holds:
⟨If ∗g, φ⟩=

Rn (f ∗g)(x)φ(x)dx =

Rn (

Rn f (x −y)g(y)dy)φ(x)dx
=

Rn

Rn f (x −y)g(y)φ(x)dy dx =

Rn×Rn f (z)g(y)φ(z + y)dy dz
= ⟨(If ⊗Ig)(z, y), φ(z + y)⟩
where we used Fubini’s theorem for functions and the deﬁnition of the tensor product
of regular distributions. Thus, in order to ensure compatibility with the embedding of
functions, one has to deﬁne the convolution product for distributions T , S ∈D′(Rn)
according to the formula
⟨T ∗S, φ⟩= ⟨(T ⊗S)(x, y), φ(x + y)⟩
∀φ ∈D(Rn)
(7.5)
whenever the right hand side makes sense. Given φ ∈D(Rn), the function ψ = ψφ
deﬁned on Rn × Rn by ψ(x, y) = φ(x + y), is certainly a function of class C∞but
never has a compact support in Rn × Rn if φ ̸= 0. Thus in general the right hand
side of Eq. (7.5) is not deﬁned. There is an obvious and natural way to ensure the
proper deﬁnition of the righthand side. Suppose supp (T ⊗S) ∩supp ψφ is compact
in Rn × Rn for all φ ∈D(Rn). Then one would expect that this deﬁnition will work.
The main result of this section will conﬁrm this. In order that this condition holds,
the supports of the distributions T and S have to be in a special relation.
Deﬁnition 7.2
Two distributions T , S ∈D′(Rn) are said to satisfy the support
condition if, and only if, for every compact set K ⊂Rn the set
KT ,S =

(x, y) ∈Rn × Rn : x ∈supp S, y ∈supp S, x + y ∈K

is compact in Rn × Rn.
Note that the set KT ,S is always closed, but it need not be bounded. To get an idea
about how this support condition can be realized, we consider several examples.
Given T , S ∈D′(Rn) denote F = supp T and G = supp S.
1. Suppose F ⊂Rn is compact. Since KT ,S is contained in the compact set F ×
(K −F) it is compact and thus the pair of distributions (T , S) satisﬁes the support
condition.
2. Consider the case n = 1 and suppose F = [a, +∞) and G = [b, +∞) for some
given numbers a, b ∈R. Given a compact set K ⊂R it is contained in some
closed and bounded interval [ −k, +k]. A simple calculation shows that in this
case KT ,S ⊆[a, k −b] × [b, k −a], and it follows that KT ,S is compact. Hence
the support condition holds.
3. For two closed convex cones C1, C2 ⊂Rn, n ≥2, with vertices at the origin
and two points aj ∈Rn, consider F = a1 + C1 and G = a2 + C2. Suppose
that the cones have the following property: given any compact set K ⊂Rn there
are compact sets K1, K2 ⊂Rn with the property that xj ∈Cj and x1 + x2 ∈K

7.3
Convolution of Distributions
95
implies xj ∈Kj ∩Cj for j = 1, 2. Then the support condition is satisﬁed. The
proof is given as an exercise.
4. Thisisaspecialcaseofthepreviousexample. Inthepreviousexampleweconsider
the cones C1 = C2 = C =
 
x ∈Rn : x1 ≥θ
n
j=2 x2
j
!
for some θ ≥0. Again
we leave the proof as an exercise that the support condition holds in this case.
Theorem 7.3 (Deﬁnition of Convolution) If two distributions T , S ∈D′(Rn) sat-
isfy the support condition, then the convolution product T ∗S is a distribution on
Rn, well deﬁned by the formula (7.5), i.e., by
⟨T ∗S, φ⟩= ⟨(T ⊗S)(x, y), φ(x + y)⟩
∀φ ∈D(Rn).
Proof
Given a compact set K ⊂Rn, there are two compact sets K1, K2 ⊂Rn
such that KT ,S ⊆K1 × K2, since the given distributions T , S satisfy the support
condition. Now choose a test function ψ ∈D(Rn × Rn) such that ψ(x, y) = 1 for
all (x, y) ∈K1 × K2. It follows that for all φ ∈DK(Rn) the function (x, y) #→
(1 −ψ(x, y))φ(x + y) has its support in Rn × Rn\K1 × K2 and thus, because of the
support condition,
⟨(T ⊗S)(x, y), φ(x + y)⟩= ⟨(T ⊗S)(x, y), ψ(x, y)φ(x + y)⟩
∀φ ∈DK(Rn).
By Theorem 6.3 we conclude that the right hand side of the above identity is a
continuous linear functional on DK(Rn). Thus we get a well-deﬁned continuous
linear functional (T ∗S)K on DK(Rn).
Let Ki, i ∈N, be a strictly increasing sequence of compact sets which exhaust
Rn. The above argument gives a corresponding sequence of functionals (T ∗S)Ki. It
is straightforward to show that these functionals satisfy the compatibility condition
(T ∗S)Ki+1|DKi(Rn) = (T ∗S)Ki, i ∈N and therefore this sequence of functionals
deﬁnes a unique distribution on Rn (see Proposition 5.1), which is denoted by T ∗S
and is called the convolution of T and S.
2
Theorem 7.4 (Properties of Convolution)
1. Suppose that two distributions T , S ∈D′(Rn) satisfy the support property. Then
the convolution has the following properties:
a) T ∗S = S ∗T , i.e., the convolution product is commutative;
b) supp (T ∗S) ⊆supp T + supp S;
c) For all α ∈Nn one has Dα(T ∗S) = DαT ∗S = T ∗Dα.
2. The convolution of Dirac’s delta distribution δ is deﬁned for every T ∈D′(Rn)
and one has
δ ∗T = T.
3. Suppose three distributions S, T , U ∈D′(Rn) are given whose supports satisfy
the following condition: For every compact set K ⊂Rn the set

(x, y, z) ∈R3n : x ∈supp S, y ∈supp T , z ∈supp U, x + y + z ∈K


96
7
Convolution Products
is compact in R3n. Then all the convolutions S ∗T , (S ∗T )∗U, T ∗U, S ∗(T ∗U)
are well deﬁned and one has
(S ∗T ) ∗U = S ∗(T ∗U).
Proof Note that the pair of distributions (S, T ) satisﬁes the support condition if, and
only if, the pair (T , S) does. Thus with T ∗S also the convolution S∗T is well deﬁned
by the above theorem. The right hand side of the deﬁning formula (7.5) of the tensor
product is invariant under the exchange of T and S. Therefore commutativity of the
convolution follows and proves part a) of 1).
DenoteC = supp T + supp S andconsideratestfunctionφ withsupportinRn\C.
Thenφ(x+y) = 0 forall(x, y) ∈supp T ×supp S andthus ⟨(T ∗S)(x, y), φ(x+y)⟩=
0 and it follows that supp (T ∗S) ⊆(Rn\C)c = C, which proves part b).
The formula for the derivatives of the convolution follows from the formula for
the derivatives of tensor products (part b) of Corollary 6.2 and the deﬁning identity
for the convolution. The details are given in the following chain of identities, for
φ ∈D(Rn):
⟨Dα(T ∗S), φ⟩= (−1)|α| ⟨T ∗S, Dαφ⟩
= (−1)|α| ⟨(T ⊗S)(x, y), (Dαφ(x + y)⟩
= (−1)|α| "
T (x),
"
S(y), Dα
y φ(x + y)
##
= ⟨T (x), ⟨(DαS)(y), φ(x + y)⟩⟩
= ⟨(T ∗DαS)(x, y), φ(x + y)⟩= ⟨T ∗DαS, φ⟩.
Thus Dα(T ∗S) = T ∗DαS and in the same way Dα(T ∗S) = DαT ∗S. This proves
part c)
Dirac’s delta distribution δ has the compact support {0}, hence for any distribution
T on Rn the pair (δ, T ) satisﬁes the support condition. Therefore the convolution δ∗T
is well deﬁned. If we evaluate this product on any φ ∈D(Rn) we ﬁnd, using again
Theorem 6.3,
⟨δ ∗T , φ⟩= ⟨(δ ⊗T )(x, y), φ(x + y)⟩= ⟨T (y), ⟨⟨δ(x), φ(x + y)⟩⟩= ⟨T (y), φ(y)⟩
and we conclude δ ∗T = T .
The proof of the third part about the threefold convolution product is left as an
exercise.
2
Remark 7.2
1. As we have seen above, the support condition for two distributions T , S on Rn
is sufﬁcient for the existence of the convolution product T ∗S. Note that this
condition is not necessary. This is easily seen on the level of functions. Consider
two functions f , g ∈L2(Rn). Application of the Cauchy–Schwarz’ inequality
(Corollary 15.1) implies, for almost all x ∈Rn, |f ∗g(x)| ≤∥f ∥2 ∥g∥2 and

7.3
Convolution of Distributions
97
hence the convolution product of f and g is well deﬁned as an essentially bounded
function on L2(Rn).
2. The simple identity Dα(T ∗δ) = (Dαδ) ∗T = DαT will later allow us to write
linear partial differential equations with constant coefﬁcients as a convolution
identity and through this a fairly simple algebraic formalism will lead to a solution.
3. If either supp T or supp S is compact, then supp T + supp S is closed and in
part 1.b) of Theorem 7.4 the closure sign can be omitted. However, when neither
supp T nor supp S is compact, then the sum supp T + supp S is in general not
closed as the following simple example shows: consider T , S ∈D′(R2) with
supp T =

(x, y) ∈R2 : 0 ≤x, +1 ≤xy

,
supp S =

(x, y) ∈R2 : 0 ≤x, xy ≤−1

.
Then the sum is
supp T + supp S =

(x, y) ∈R2 : 0 < x

and thus not closed.
The regularization T ∗φ of a distribution T by a test function φ is a C∞-function by
Theorem 7.1 and thus deﬁnes a regular distribution IT ∗φ. Certainly, the test function
φ deﬁnes a regular distribution Iφ and so one can ask whether the convolution product
of this regular distribution with the distribution T exists and what this convolution
is. The following corollary answers this question and provides important additional
information.
Corollary 7.3 Let T ∈D′(Rn) be a distribution on Rn.
a) For all φ ∈D(Rn) the convolution (in the sense of distributions) T ∗Iφ exists
and one has
T ∗Iφ = IT ∗φ.
b) Suppose T has a compact support. Then, for every f ∈C∞(Rn), the convolution
T ∗If exists and is a C∞-function. One has
T ∗If = IT ∗f ,
i.e., T ∗f is a C∞-function.
Proof Since the regular distribution Iφ has a compact support, the support condition
is satisﬁed for the pair (T , Iφ) and therefore Theorem 7.3 proves the existence of the
convolution T ∗Iφ, and for ψ ∈D(Rn) the following chain of identities holds.
⟨T ∗Iφ, ψ⟩= ⟨(T ⊗Iφ)(x, y), ψ(x + y)⟩= ⟨T (x), ⟨Tφ(y), ψ(x + y)⟩⟩
= ⟨T (x),

φ(y)ψ(x + y)dy⟩= ⟨T (x),

φ(z −x)ψ(z)dz⟩
=

⟨T (x), φ(z −x)⟩ψ(z)dz =

(T ∗φ(z)ψ(z)dz = ⟨IT ∗φ, ψ⟩.

98
7
Convolution Products
The key step in this chain of identities is the proof of the identity
⟨T (x),

φ(z −x)ψ(z)dz⟩=

⟨T (x), φ(z −x)⟩ψ(z)dz
(7.6)
and this is given in the Exercises. This proves part a).
If the support K of T is compact, we know by Theorem 7.3 that the convolution
T ∗If is a well-deﬁned distribution, for every f ∈C∞(Rn). In order to show that
T ∗If is actually a C∞-function, choose some ψ ∈D(Rn) such that ψ(x) = 1 for
all x ∈K. For all φ ∈D(Rn) we have supp (φ −ψφ) ⊆Kc ≡Rn\K and therefore
⟨T , φ −ψφ⟩= 0. This shows that T = ψ · T . Thus, for every φ ∈D(Rn) we can
deﬁne a function hφ on Rn by
hφ(x) = ⟨T (y), φ(x + y)⟩= ⟨T (y), ψ(y)φ(x + y)⟩
∀x ∈Rn.
Corollary 6.1 implies that hφ is a C∞-function with support in supp φ −K. Similarly,
Corollary 6 shows that the function
z #→g(z) = ⟨T (y), ψ(y)f (z −y)⟩
is of class C∞on Rn. Now we calculate, for all φ ∈D(Rn),
⟨T ∗If , φ⟩= ⟨(ψ · T ) ∗If , φ⟩= ⟨If (x), ⟨(ψ · T )(y), φ(x + y)⟩⟩
= ⟨If (x), ⟨T (y), ψ(y)φ(x + y)⟩⟩=

⟨T (y), ψ(y)f (z −y)⟩φ(z)dz.
Hence T ∗If is equal to Ig. Since obviously g = T ∗f , part b) follows.
2
From the point of view of practical applications of the convolution of distributions,
it is important to know distinguished sets of distributions such that, for any pair in
this set, the convolution is well deﬁned. We present here a concrete example of such
a set which later will play an important role in the symbolic calculus. Introduce the
set of all distributions on the real line that have their support on the positive half-line:
D′
+(R) =

T ∈D′(R)| supp T ⊆[0, +∞)

.
With regard to convolution this set has quite interesting properties as the following
theorem shows.
Theorem 7.5
a) D′
+(R), equipped with the convolution as a product, is an Abelian algebra with
Dirac’s delta distribution δ as the neutral element. It is however not a ﬁeld.
b) (D′
+(R), ∗) has no divisors of zero (Theorem of Titchmarsh).
Proof
It is easily seen that any two elements T , S ∈D′
+(R) satisfy the support
condition (compare the second example in the discussion of this condition). Hence
by Theorem 7.3 the convolution is well deﬁned on D′
+(R). By Theorem 7.4 this
product is Abelian and T ∗S has its support in [0, +∞) for all T , S ∈D′
+(R) and
the neutral element is δ. D′
+(R) is not a ﬁeld under the convolution since there are

7.3
Convolution of Distributions
99
elements in D′
+(R) that have no inverse with respect to the convolution product
though they are different from zero. Take for example a test function φ ∈D(R)
with support in R+ = [0, +∞), φ ̸= 0. Then the regular distribution Iφ belongs to
D′
+(R), and there is no T ∈D′
+(R) such that T ∗Iφ = δ, since by Corollary 7.3 one
has T ∗Iφ = IT ∗φ and by Theorem 7.1 it is known that T ∗φ ∈C(R). This proves
part a).
Statement b) means: if T , S ∈D′
+(R) are given and T ∗S = 0, then either T = 0
or S = 0. The proof is somewhat involved and we refer the reader to [1].
2
Remark 7.3
1. The convolution product is not associative. Here is a simple example. Observe
that δ′ ∗θ = D(δ ∗θ) = Dθ = δ, hence
1 ∗(δ′ ∗θ) = 1 ∗δ = 1.
Similarly, 1 ∗δ′ = D(1 ∗δ) = D1 = 0, hence
(1 ∗δ′) ∗θ = 0.
2. For the proof that (D′
+(R), ∗) has no divisors of zero, the support properties
are essential. In (D′(R), ∗) we can easily construct counterexamples. Since δ′ ∈
D′(R) has a compact support, we know that δ′ ∗1 is a well-deﬁned distribution
on R. We also know δ′ ̸= 0 and 1 ̸= 0, but as we have seen above, δ′ ∗1 = 0.
3. Fix S ∈D′(Rn) and assume that S has a compact support. Then we can consider
the map D′(Rn) →D′(Rn) given by T #→T ∗S. It is important to realize that
this map is not continuous. Take for example the distributions Tn = δn, n ∈N,
i.e., Tn(φ) = φ(n) for all φ ∈D(R). Then 1 ∗Tn = 1 for all n ∈N, but
lim
n→∞Tn = 0
in D′(R).
4. Recall the deﬁnition of Cauchy’s principal value vp 1
x in Eq. (3.7). It can be
used to deﬁne a transformation H, called the Hilbert transform, by convolution
f #→H(f ) = vp 1
x ∗f :
H(f )(x) = lim
ε→0

|x−y|≥ε
f (y)
x −y dy
∀x ∈R.
(7.7)
This transformation is certainly well deﬁned on test functions. It is not difﬁcult
to show that it is also well deﬁned on all f ∈C1(R) with the following decay
property: for every x ∈R there is a constant C and an exponent α > 0 such that
for all y ∈R, |y| ≥1, the estimate
|f (x −y) −f (x + y)| ≤C|y|−α
holds. This Hilbert transform is used in the formulation of “dispersion relations”,
which play an important role in various branches of physics (see [2]).

100
7
Convolution Products
7.4
Exercises
1. The sum A+B of two subsets A and B of a vector space V is by deﬁnition the set
A + B = {x + y ∈V : x ∈A, y ∈B}. For compact subsets A, B ⊂Rn prove
that the closure of the sum is equal to the sum:
A + B = A + B.
Give an example of two closed sets A, B ⊂Rn such that the sum A + B is not
closed.
2. Fill in the details in the proof of Proposition 7.1.
3. Prove Corollary 7.2.
4. For T ∈D′(Rn) and φ, ψ ∈D(Rn) prove the important identity (7.6)
⟨T (x),

φ(z −x)ψ(z)dz⟩=

⟨T (x), φ(z −x)⟩ψ(z)dz.
Hints: One can use, for instance, the representation theorem of distributions as
weak derivatives of integrable functions (Theorem 5.1).
5. Prove: D(Rn) is (sequentially) dense in D′(Rn).
6. Prove Part 3. of Theorem 7.4
References
1. Gel’fand IM, Šilov GE. Generalized functions I: properties and operations. 5th ed. New York:
Academic Press; 1977.
2. Thirring W. A course in mathematical physics: classical dynamical systems and classical ﬁeld
theory. Springer study edition. New York: Springer-Verlag; 1992.

Chapter 8
Applications of Convolution
The four sections of this chapter introduce various applications of the convolution
product, for functions and distributions. The common core of these sections is a
convolution equation, i.e., a relation of the form
T ∗X = S,
where T , S are given distributions and X is a distribution that we want to ﬁnd in a
suitable space of distributions. We will learn that various problems in mathematics
and physics can be written as convolution equations. As simple examples the case of
ordinary and partial linear differential equations with constant coefﬁcients as well as
a well-known integral equation is discussed . Of course, in the study of convolution
equations we encounter the following problems:
1. Existence of a solution: Given two distributions T , S, is there a distribution X in
a suitable space of distributions, such that T ∗X = S holds?
2. Uniqueness: If a solution exists, is it the only solution to this equation (in a given
space of distributions)?
An ideal situation would be if we could treat the convolution equation in a space of
distributions, which is an algebra with respect to the convolution product. Then, if T
is invertible in this convolution algebra, the unique solution to the equation T ∗X = S
obviously is X = T −1 ∗S. If however T is not invertible in the convolution algebra,
the equation might not have any solution, or it might have several solutions.
Unfortunately this ideal case hardly occurs in the study of concrete problems. We
discuss a few cases. Earlier we saw that the space of all distributions is not an algebra
with respect to convolution. The space L1(Rn) of Lebesgue integrable functions on
Rn is an algebra for the convolution but this space is not suitable for the study
of differential operators. The space E′ of distributions with compact support is an
algebra for the convolution, but not very useful since there is hardly any differential
operator that is invertible in E′. The space of distributions with support in a given
cone can be shown to be an algebra for the convolution. It can be used for the study
of special partial differential operators with constant coefﬁcients. Thus we are left
with the convolution algebra D′
+(R) studied in Theorem 7.5.
© Springer International Publishing Switzerland 2015
101
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_8

102
8
Applications of Convolution
8.1
Symbolic Calculus—Ordinary Linear
Differential Equations
Suppose we are given an ordinary linear differential equation with constant coefﬁ-
cients
N

n=0
any(n) = f ,
(8.1)
where the an are given real or complex numbers and f is a given continuous function
on the positive half-line R+. Here, y(n) = Dny denotes the derivative of order n of
the function y with respect to the variable x, D =
d
dx .
By developing a symbolic calculus with the help of the convolution algebra
(D′
+(R), ∗) of Theorem 7.5, we will learn how to reduce the problem of ﬁnding
solutions of Eq. (8.1) to a purely algebraic problem that is known to have solutions.
The starting point is to consider Eq. (8.1) as an equation in D′
+(R) and to write it as
a convolution equation
$ N

n=0
anδ(n)
%
∗y = f.
(8.2)
The rules for derivatives of convolution products and the fact that Dirac’s delta
distribution is the unit of the convolution algebra (D′
+(R), ∗) imply that
y(n) = δ ∗y(n) = δ(n) ∗y,
and thus by distributivity of the convolution product, Eqs. (8.1), (8.2), and (8.3) are
equivalent. In this way we assign to the differential operator
P(D) =
N

n=0
anDn,
the element
P(δ) =
N

n=0
anδ(n)
∈D′
+(R)
with support in {0} such that
P(D)y = P(δ) ∗y
(8.3)
on D′
+(R). Thus we can solve Eq. (8.1) by showing that the element P(δ) has an
inverse in (D′
+(R), ∗). We prepare the proof of this claim by a simple lemma.

8.1
Symbolic Calculus—Ordinary Linear Differential Equations
103
Lemma 8.1 The distribution δ′ −λδ ∈D′
+(R), λ ∈C, has a unique inverse given
by the regular distribution
eλ(x) = Iθ(x)eλx
∈D′
+(R).
Proof
The proof consists of a sequence of straightforward calculations using the
rules established earlier for the convolution. We have (δ′ −λδ) ∗eλ = δ′ ∗eλ −λδ ∗
e −λ = δ′ ∗eλ −λeλ and
δ′ ∗eλ = D(δ ∗eλ) = Deλ = eλxδ + λeλ = δ + λeλ
where we have used the differentiation rules of distributions and the fact that Dθ = δ.
It follows that
(δ′ −λδ) ∗eλ = δ
and therefore eλ is an inverse of δ′ −λδ in D′
+(R). Since D′
+(R) has no divisors of
zero, the inverse is unique.
2
Proposition 8.1 Let P(x) = a0 + a1x + · · · + anxn be a polynomial of degree n
(an ̸= 0) with complex coefﬁcients aj. Denote by

λ1, . . ., λp

the set of zeros (roots)
of P with multiplicities

k1, . . ., kp

, i.e.,
P(x) = an(x −λ1)k1 · · · (x −λp)kp.
Then
P (δ) = a0δ + a1δ(1) + · · · + anδ(n) = an(δ′ −λ1δ)∗k1 ∗· · · ∗(δ′ −λpδ)∗kp
has an inverse in D′
+(R), which is given by
P(δ)−1 = 1
an
e∗k1
λ1 ∗· · · ∗e
∗kp
λp ≡E.
(8.4)
Proof For λ, μ ∈C calculate (δ′−λδ)∗(δ′−μδ) = δ′∗δ′−λδ∗δ′−δ′∗μδ+λμδ∗δ =
δ′ ∗δ′ −(λ + μ)δ′ + λμδ where we used the distributive law for the convolution
and the fact that δ is the unit in (D′
+(R), ∗). Using the differentiation rules we ﬁnd
δ′ ∗δ′ = D(δδ′) = D(δ′) = δ(2). It follows that
(δ′ −λδ) ∗(δ′ −μδ) = δ(2) −(λ + μ)δ′ + λμ.
In particular for λ = μ, one has (δ′ −λδ)∗2 = δ(2) −2λδ′ +λ2 where for S ∈D′
+(R)
we use the notation S∗k = S ∗· · · ∗S (k factors). Repeated application of this
argument implies (see exercises)
a0δ + a1δ(1) + · · · + anδ(n) = an(δ′ −λ1δ)∗k1 ∗· · · ∗(δ′ −λpδ)∗kp.
Knowing this factorization of P(δ), it is easy to show that the given element E ∈
D′
+(R) is indeed the inverse of P(δ). Using the above lemma and the fact that
(D′
+(R), ∗) is an Abelian algebra, we ﬁnd
 1
an
e∗k1
λ1 ∗· · · ∗e
∗kp
λp

∗P(δ) = e∗k1
λ1 ∗(δ′ −λ1δ)∗k1 ∗· · · ∗e
∗kp
λp ∗(δ′ −λpδ)∗kp

104
8
Applications of Convolution
= [eλ1 ∗(δ′ −λ1δ)]∗k1 ∗· · · ∗[eλp ∗(δ′ −λpδ)]∗kp = δ∗k1 ∗· · · ∗δ∗kp = δ.
Hence, the element E ∈D′
+(R) is the inverse of P(δ).
2
After these preparations it is fairly easy to solve ordinary differential equations of
the form (8.1), even for all f ∈D′
+(R). To this end rewrite Eq. (8.1) using relation
(8.2), as
P(δ) ∗y = f ,
and thus by Proposition 8.1, a solution is
y = P(δ)−1 ∗f ,
(8.5)
in particular, for f = δ, E = P(δ)−1 is a special solution of the equation
P(D)T = δ
in
D′
+(R).
(8.6)
This special solution E is called a fundamental solution of the differential operator
P (D). The above argument shows: Whenever we have a fundamental solution E of
the differential operator P(D), a solution y of the equation P(D)y = f for general
inhomogeneous term f ∈D′
+(R) is given by
y = E ∗f.
Since the fundamental solution is expressed as a convolution product of explicitly
known functions, one can easily derive some regularity properties of solutions.
Theorem 8.1 Let P(D) = N
n=0 anDn be an ordinary constant coefﬁcient differ-
ential operator normalized by aN = 1, N > 1, and E = P(δ)−1 the fundamental
solution as determined above.
1. E is a function of class CN−2(R) with support in R+.
2. Given an inhomogeneous term f ∈D′
+(R), a solution of P(D)y = f is y =
E ∗f .
3. If the inhomogeneous term f is a continuous function on R with support in R+,
then the special solution y = E ∗f of P(D)y = f is a classical solution, i.e., a
function of class CN(R), which satisﬁes the differential equation.
Proof According to Proposition 8.1, the fundamental solution E has the represen-
tation E = ez1 ∗· · · ∗ezN where the N roots {z1, . . ., zN} are not necessarily distinct.
Thus we can write DN−2E = Dez1 ∗· · ·∗DezN−2 ∗ezN−1 ∗ezN . Previous calculations
have shown that Dez = δ + zez. It follows that
DN−2E = (δ + z1ez1) ∗· · · ∗(δ + zN−2ezN−2) ∗ezN−1 ∗ezN
= ezN ∗ezN−1 +
N−2
j=1 zjezj ∗ezN−1 ∗ezN + · · · + z1 · · · zNez1 ∗· · · ∗ezN .
Next we determine the continuity properties of the convolution product ez ∗ew of the
function ez and ew for arbitrary z, w ∈C. According to the deﬁnition of the functions
ez and the convolution, we ﬁnd
(ez ∗ew)(x) =

ez(y)ew(x −y)dy

8.1
Symbolic Calculus—Ordinary Linear Differential Equations
105
= θ(x)
 x
0
ezyew(x−y)dy = θ(x)ewx
 x
0
e(z−w)ydy.
According to this representation, ez ∗ew is a continuous function on R with support in
R+. It follows that also all convolution products with m ≥2 factors are continuous
functions on R with support in R+. Hence the formula for DN−2E shows that DN−2E
is continuous and thus E has continuous derivatives up to order N −2 on R and has
its support in R+. This proves the ﬁrst part.
The second part has been shown above. In order to prove the third part we evaluate
DN(E ∗f ) = (DNE) ∗f . As above we ﬁnd
DNE = Dez1 ∗· · · ∗DezN = (δ + z1ez1) ∗· · · ∗(δ + zNezN )
= δ +
N
j=1 zjezj +

i̸=j zizjezj ∗ezj + · · · + z1 · · · znez1 ∗· · · ∗ezN ,
and therefore
DNy = Dn(E ∗f ) = f +
N

j=1
zjezj ∗f + · · · + z1 · · · zNez1 ∗· · · ∗ezN ∗f.
This shows that the derivative of order N of y = E ∗f , calculated in the sense
of distributions, is actually a continuous function. We conclude that this solution
is an N-times continuously differentiable function on R with support in R+, i.e., a
classical solution.
2
Remark 8.1 Theorem 8.1 reduces the problem of ﬁnding a solution of the ordinary
differential equation P(D)y = f to the algebraic problem of ﬁnding all the roots

λ1, . . ., λp

of the polynomial P(x) and their multiplicities

k1, . . ., kp

.
A simple concrete example will illustrate how convenient the application of The-
orem 8.1 is in solving ordinary differential equations. Consider an electrical circuit
in which a capacitor C, an inductance L, and a resistance R are put in series and
connected to a power source of voltage V (t). The current I(t) in this circuit satisﬁes,
according to Kirchhoff’s law, the equation
V (t) = RI(t) + LdI(t)
dt
+ 1
C
 t
0
I(s)ds.
Differentiation of this identity yields, using D = d
dt ,
DV (t) = LP(D)I(t)
P(D) = D2 + R
LD +
1
LC .
The roots of the polynomial P(x) = x2 + R
Lx +
1
LC are λ1,2 = −R
2L ±

( R
2L)2 −
1
LC
and therefore, according to Theorem 8.1,
I(t) = 1
LP (δ)−1 ∗DV (t) = 1
Leλ1 ∗eλ2 ∗DV (t) = 1
L(Deλ1) ∗eλ2 ∗V (t).
Since we know Dez = δ + zez, a special solution of the above differential equation
is
I(t) = 1
L(eλ2 ∗V )(t) + λ1
L (eλ1 ∗eλ2 ∗V )(t).

106
8
Applications of Convolution
8.2
Integral Equation of Volterra
Given two continuous functions g, K on R+, we look for all functions f satisfying
Volterra’s linear integral equation
f (x) =
 x
0
K(x −y)f (y)dy = g(x)
∀x ∈R+.
(8.7)
Integral equations of this type are for instance used in optics for the description of
the distribution of brightness.
How can one solve such equations? We present here a simple method based on
our knowledge of the convolution algebra (D′
+(R), ∗). By identifying the functions
f , g, K with the regular distributions θf , θg, θK in D′
+(R), it is easy to rewrite
Eq. (8.7) as a convolution equation in D′
+(R):
(δ −K) ∗f = g.
(8.8)
In order to solve this equation, we show that the element δ−K is invertible in D′
+(R).
This is done in the following proposition.
Proposition 8.2 If K : R+ →R is a continuous function, then the element δ −K
has an inverse in D′
+(R). This inverse is of the form
(δ −K)−1 = δ + H,
where H is a continuous function R+ →R. Volterra’s integral equation has thus
exactly one solution that is of the form
f = g + H ∗g.
Proof We start with the well-known (in any ring with unit) identity
δ −K∗(n+1) = (δ −K) ∗(δ + K + K∗2 + · · · + K∗n),
(8.9)
and show that the series ∞
i=1 K∗i converges uniformly on every compact subset of
R+. For this it sufﬁces to show uniform convergence on every compact interval of
the form [0, r] for r > 0. Since K is continuous we know that Mr = sup0≤x≤r |K(x)|
is ﬁnite for every r > 0. Observe that
K∗2(x) =
 x
0
K(y)K(x −y)dy
(⇒
|K∗2(x)| ≤M2
r x,
and therefore by induction (see exercises),
|K∗i(x)| ≤Mi
r
xi−1
(i −1)!
∀x ∈[0, r].

8.3
Linear Partial Differential Equations with Constant Coefﬁcients
107
The estimate
∞

i=1
|K∗i(x)| ≤
∞

i=1
Mi
r
xi−1
(i −1)! = MreMrx
implies that the series ∞
i=1 K∗i(x) converges absolutely and uniformly on [0, r], for
every r > 0. Hence this series deﬁnes a continuous function H : R+ →R,
H =
∞

i=1
K∗i.
With this information we can pass to the limit n →∞in Eq. (8.9) and ﬁnd δ =
(δ −K) ∗(δ + H), hence (δ −K)−1 = δ + H, which proves the proposition since
the convolution algebra (D′
+(R), ∗) is without divisors of zeros and δ −K ̸= 0.
2
8.3
Linear Partial Differential Equations
with Constant Coefﬁcients
This section reports one of the main achievements of the theory of distributions,
namely providing a powerful framework for solving linear partial differential equa-
tions (PDEs) with constant coefﬁcients. Using the multi-index notation, a linear
partial differential operator with constant coefﬁcients will generically be written as
P (D) =

|α|≤m
aαDα,
aα ∈C,
m = 1, 2, . . . .
(8.10)
Suppose that Ω ⊆Rn is a nonempty open set. Certainly, operators of the form
(8.10) induce linear maps of the test function space over Ω into itself, and this map
is continuous (see exercises). Thus, by duality, as indicated earlier, the operators
P (D) can be considered as linear and continuous operators D′(Ω) →D′(Ω). Then,
given U ∈D′(Ω), the distributional form of a linear PDE with constant coefﬁcients
is
P(D)T = U
in D′(Ω).
(8.11)
Note that T ∈D′(Ω) is a distributional or weak solution of (8.11) if, and only if, for
all φ ∈D(Ω), one has
⟨U, φ⟩= ⟨P(D)T , φ⟩= ⟨T , P t(D)φ⟩,
where P t(D) = 
|α|≤m (−1)|α|aαDα. In many applications however one is not so
much interested in distributional solutions but in functions satisfying this PDE. If
the righthand side U is a continuous function, then a classical or strong solution of
Eq. (8.11) is a function T on Ω which has continuous derivatives up to order m and
which satisﬁes (8.11) in the sense of functions. As one would expect, it is easier to

108
8
Applications of Convolution
ﬁnd solutions to Eq. (8.11) in the much larger space D′(Ω) of distributions than in
the subspace C(m)(Ω) of m times continuously differentiable functions. Nevertheless,
the problems typically require classical and not distributional solutions and thus the
question arises: when, i.e., for which differential operators, a distributional solution
is actually a classical solution? This is known to be the case for the so-called elliptic
operators. In this elliptic regularity theory one shows that, for these elliptic operators,
weak solutions are indeed classical solutions. This also applies to nonlinear PDEs.
In Part III, Chap. 32, we present without proof some classes of typical examples. We
mention here the earliest and quite typical result of the elliptic regularity theory, due
to H. Weyl (1940), for the Laplace operator.
Lemma 8.2 (Lemma of Weyl) Suppose that T ∈D′
reg(Ω) is a solution of ΔT = 0
in D′(Ω), i.e.,

T (x)Δφ(x)dx = 0 for all φ ∈D(Ω). Then it follows that T ∈
C(2)(Ω) and ΔT (x) = 0 hold in the sense of functions.
We remark that in the special case of the Laplace operator Δ, one can actually
show T ∈C∞(Ω). We conclude: In order to determine classical solutions of the
equation ΔT = 0, T ∈C(2)(Ω), it is sufﬁcient to determine weak solutions in the
much larger space D′
reg(Ω).
Naturally, not all differential operators have this very convenient regularity prop-
erty. As a simple example we discuss the wave operator 22 =
∂2
∂t2 −
∂2
∂x2 in two
dimensions, which has many weak solutions that are not strong solutions. Denote by
f the characteristic function of the unit interval [0, 1] and deﬁne u(t, x) = f (x −t).
Then u ∈D′
reg(R2) and 22u = 0 in the sense of distributions. But u is not a strong
solution.
In the context of ordinary linear differential operators we have learned already
about the basic role that a fundamental solution plays in the process of ﬁnding
solutions. This will be the same for linear partial differential operators with constant
coefﬁcients. Accordingly, we repeat the formal deﬁnition.
Deﬁnition 8.1 Given a differential operator of the form (8.10), every distribution
E ∈D′(Rn) that satisﬁes the distributional equation
P(D)E = δ
is called a fundamental solution of this differential operator.
In the case of ordinary differential operators we saw that every constant coefﬁcient
operator has a fundamental solution and we learned how to construct them. For
partial differential operators the corresponding problem is much more difﬁcult. We
indicate brieﬂy the main reason. While for a polynomial in one variable the set of
zeros (roots) is a ﬁnite set of isolated points, the set of zeros of a polynomial in n > 1
variables consists in general of several lower dimensional manifolds in Rn.
It is worthwhile mentioning that some variation of the concept of a fundamental
solution is used in physics under the name Green’s function. A Green’s function is
a fundamental solution that satisﬁes certain boundary conditions. In the following
section and in the sections on tempered distributions we are going to determine
fundamental solutions of differential operators that are important in physics.

8.3
Linear Partial Differential Equations with Constant Coefﬁcients
109
Despite these complications, B. Malgrange (1953) and L. Ehrenpreis (1954)
proved independently of each other that every constant coefﬁcient partial differential
operator has a fundamental solution.
Theorem 8.2 Every partial differential operator P(D) = 
|α|≤m aαDα, aα ∈C,
has at least one fundamental solution.
The proof of this basic result is beyond the scope of this introduction and we have
to refer to the specialized literature, for instance [1]. Knowing the existence of a
fundamental solution for a PDE-operator (8.10), the problem of existence of solutions
of PDEs of the form (8.11) has an obvious solution.
Theorem 8.3 Every linear PDE in D′(Rn) with constant coefﬁcients

|α|≤m
aαDαT = U
has a solution in D′(Rn) for all those U ∈D′(Rn) for which there is a fundamental
solution E ∈D′(Rn) such that the pair (E, U) satisﬁes the support condition. In this
case a special solution is
T = E ∗U.
(8.12)
Such a solution exists in particular for all distributions U ∈E′(Rn) of compact
support.
Proof
If we have a fundamental solution E such that the pair (E, U) satisﬁes the
support condition, then we know that the convolution E ∗U is well deﬁned. The
rules of calculation for convolution products now yield
P(D)(E ∗U) = (P(D)E) ∗U = δ ∗U = U,
hence T = E ∗U solves the equation in the sense of distributions. If a distribution
U has a compact support, then the support condition for the pair (E, U) is satisﬁed
for every fundamental solution and thus we conclude.
2
Obviously, a differential operator of the form (8.10) leaves the support of a dis-
tribution invariant: supp (P(D)T ) ⊆supp T for all T ∈D′(Rn), but not necessarily
the singular support as deﬁned in Deﬁnition 3.5. Those constant coefﬁcient partial
differential operators that do not change the singular support of any distribution play
a very important role in the solution theory for linear partial differential operators.
They are called hypoelliptic for reasons that become apparent later.
Deﬁnition 8.2 A linear partial differential operator with constant coefﬁcients P(D)
is called hypoelliptic if, and only if,
sing supp P(D)T = sing supp T
∀T ∈D′(Rn).
(8.13)
Since one always has sing supp P(D)T ⊆sing supp T , this deﬁnition is equivalent to
the following statement: If P(D)T is of class C∞on some open subset Ω ⊂Rn, then
T itself is of class C∞on Ω. With this in mind, we present a detailed characterization

110
8
Applications of Convolution
of hypoelliptic partial differential operators in terms of regularity properties of its
fundamental solutions.
Theorem 8.4 Let P(D) be a linear constant coefﬁcient partial differential operator.
The following statements are equivalent:
(a) P (D) is hypoelliptic.
(b) P (D) has a fundamental solution E ∈C∞(Rn →{0}).
(c) Every fundamental solution E of P(D) belongs to C∞(Rn →{0}).
Proof We start with the observation that Dirac’s delta distribution is of class C∞
on Rn\ {0}. If we now apply condition (8.13) to a fundamental solution E of the
operator P (D), we get
sing supp E = sing supp (P(D)E) = sing supp δ = {0} ,
hence (a) implies (c). The implication (c) ⇒(b) is trivial. Thus we are left with
showing (b) ⇒(a).
Suppose E ∈C∞(Rn\ {0} ) is a fundamental solution of the operator P(D). As-
sume furthermore that Ω ⊂Rn is a nonempty open subset and T ∈D′(Rn) a
distribution such that P(D)T ∈C∞(Ω) holds. Now it sufﬁces to show that T itself
is of class C∞in a neighborhood of each point x in Ω. Given any x ∈Ω, there is
an r > 0 such that the open ball B2r(x) is contained in Ω. There is a test function
φ ∈D(Rn) such that supp φ ⊂Br(0) and φ(x) = 1 for all x in some neighborhood
V of zero.
Using Leibniz’ rule we calculate
P (D)(φE) =

|α|≤m aα

β≤α
α!
β!(α −β)!DβφDα−βE
= φP(D)E +

|α|≤m

0̸=β≤α aα
α!
β!(α −β)!DβφDα−βE
= φP(D)E + ψ = δ + ψ.
The properties of φ imply that the function ψ vanishes on the neighborhood V and
has its support in Br(0); by assumption (b), the function ψ is of class C∞on Rn\ {0},
hence ψ ∈D(Rn), and we can regularize the distribution T by ψ and ﬁnd
T + ψ ∗T = (δ + ψ) ∗T = [P(D)(φE)] ∗T = (φE) ∗(P(D)T ),
or T = φE ∗P (D)T −ψ ∗T .
2
8.4
Elementary Solutions of Partial Differential Operators
Theorems 8.3 and 8.4 of the previous section are the core of the solution theory
for linear partial equations with constant coefﬁcients and through them we learn
that, and why, it is important to know elementary solutions of constant coefﬁcient

8.4
Elementary Solutions of Partial Differential Operators
111
partial differential operators explicitly. Accordingly, we determine in this section the
elementary solutions of differential operators, which are important in physics. In
some cases we include a discussion of relevant physical aspects. Later in the section
on Fourier transforms and tempered distributions we learn about another method to
obtain elementary solutions.
8.4.1
The Laplace Operator Δn = n
i=1
∂2
∂x2
i in Rn
The Laplace operator occurs in a number of differential equations that play an im-
portant role in physics. After we have determined the elementary solution for this
operator we discuss some of the applications in physics.
Proposition 8.3 The function En : Rn\ {0} →R, deﬁned by
En(x) =
⎧
⎨
⎩
1
2π log |x|
for n = 2,
−1
(n−2)|Sn||x|2−n
for n ≥3,
(8.14)
where |Sn| = 2π n+1
2 Γ ( n+1
2 ) is the area of the unit sphere Sn in Rn, has the following
properties:
(a) En ∈L1
loc(Rn) ∩C∞(Rn\ {0} );
(b) ΔnEn(x) = 0 for all x ∈Rn\ {0};
(c) En is the elementary solution of the Laplace operator Δn in Rn, which is thus
hypoelliptic.
Proof
Using polar coordinates it is an elementary calculation to show that En is
locally integrable in Rn. Similarly, standard differentiation rules imply that En is of
class C∞on Rn\ {0}. This proves part (a). The elementary proof of part (b) is left as
an exercise. Uniqueness of the elementary solution for the Laplace operator follows
from Hörmander’s theorem (see Theorem 10.8). Thus we are left with proving that
the function En is an elementary solution.
For any test function φ ∈D(Rn), we calculate
⟨ΔnEn, φ⟩=

En(x)Δnφ(x)dx = lim
r→0

[r≤|x|≤R]
En(x)Δn(x)φ(x)dx,
since En is locally integrable and where R is chosen such that supp φ ⊂BR(0).
Here [r ≤|x| ≤R] denotes the set {x ∈Rn : r ≤|x| ≤R}. Observe that φ vanishes
in a neighborhood of the boundary of the ball BR(0) and that ΔnEn(x) = 0 in
[r ≤|x| ≤R]. Therefore, applying partial integration and Gauss’ theorem twice,
we get for the integral under the limit,
−

|x|=r
φ(x)∇nEn(x) · dS(x) +

|x|=r
En(x)∇nφ(x) · dS(x).

112
8
Applications of Convolution
In the exercises one shows that the limit r →0 of the ﬁrst integral gives φ(0) while
the limit of the second integral is zero. It follows ⟨Δn, φ⟩= φ(0) = ⟨δ, φ⟩for all
φ ∈D(Rn) and thus ΔnEn = δ.
2
The case n = 1 is elementary. We claim E1(x) = xθ(x) is the elementary solution
ofΔ1 =
d2
dx2 . Theproofisastraightforwarddifferentiationinthesenseofdistributions
and is left as an exercise.
Now we discuss the case n = 3 that is of particular importance for physics. The
fundamental solution for Δ3 is
E3(x) = −1
4π
1
|x|
∀x ∈R3\ {0} .
(8.15)
This solution is well known in physics in connection with the Poisson equation
Δ3U = ρ,
(8.16)
where ρ is a given density (of masses or electrical charges), and one is looking for
the potential U generated by this density. In physics we learn that this potential is
given by the formula
U(x) = −1
4π

R3
ρ(x)
|x −y|d3y
∀x ∈R3
(8.17)
whenever ρ is an integrable function. One easily recognizes that this solution formula
is just the convolution formula for this special case:
U(x) = E3 ∗ρ(x).
Certainly, the formula U = E3 ∗ρ gives the solution of Eq. (8.16) for all ρ ∈E′(R3),
not just for integrable densities.
8.4.2
The PDE Operator ∂
∂t −Δn of the Heat Equation
in Rn+1
We proceed as in the case of the Laplace operator but refer for a discussion of the
physical background of this operator to the physics literature.
Proposition 8.4 The function En deﬁned on the set (0, +∞) × Rn by the formula
En(t, x) =

1
2√πt
n
θ(t)e−|x|2
4t
(8.18)
has the following properties:
(a) En ∈L1
loc(Rn+1) ∩C∞((0, +∞) × Rn);
(b) ( ∂
∂t −Δn)En(t, x) = 0 for all (t, x) ∈(0, +∞) × Rn;

8.4
Elementary Solutions of Partial Differential Operators
113
(c) En is the elementary solution of the operator ∂
∂t −Δn, which is thus hypoelliptic.
Proof Since the statements of this proposition are quite similar to the result on the
elementary solution of the Laplace operator, it is natural that we can use nearly the
same strategy of proof. Certainly, the function (8.18) is of class C∞on (0, +∞)×Rn.
In order to show that this function is locally integrable on Rn+1, it sufﬁces to show
that the integral
I(t) =
 t
0

|x|≤R)
En(s, x)dx dt
is ﬁnite, for every t > 0 and every R > 0. For every s > 0, the integral with
respect to x can be estimated in absolute value by 1, after the change of variables
x = 2√sy. Thus it follows that I(t) ≤t and therefore En ∈L1
loc(Rn+1). Elementary
differentiationshowsthatpart(b)holds.Again, uniquenessoftheelementarysolution
follows from Hörmander’s theorem (Theorem 10.8).
Now take any φ ∈D(Rn+1); since En is locally integrable it follows, using
∂t = ∂
∂t , that
⟨(∂t −Δn)En, φ⟩= −⟨En, (∂t + Δn)φ⟩
= lim r→0
 ∞
r

Rn En(t, x)(∂+ Δn)φ(t, x)dx dt = lim r→0Ir(φ).
Since φ has a compact support, repeated partial integration in connection with Gauss’
theorem yields

Rn En(t, x)(Δnφ)(t, x)dx =

Rn (ΔnEn)(t, x)φ(t, x)dx
for every t > 0. Therefore, by partial integration with respect to t, we ﬁnd
Ir(φ) =
 ∞
r

Rn (ΔnEn)(t, x)φ(t, x)dx dt +

Rn En(t, x)φ(t, x)|t=+∞
t=r
dx
−
 ∞
r

Rn (∂tEn)(t, x)φ(t, x)dx dt
=
 ∞
r

Rn (( −∂t + Δn)En)(t, x)φ(t, x)dx dt −

Rn En(r, x)φ(r, x)dx
= −

Rn En(r, x)φ(r, x)dx.
Here we have used Fubini’s theorem for integrable functions to justify the exchange
of the order of integration, and in the last identity we have used part (b). This allows
the conclusion
⟨(∂t −Δn)En, φ⟩=

1
2√π
n
lim r→0

Rn r−n
2 e−|x|2
4r φ(r, x)dx

114
8
Applications of Convolution
=

1
2√π
n
lim r→0

Rn e−|y|2
4 φ(r, √ry)dy
= φ(0, 0),
where we used the new integration variable y =
x
√r , Lebesgue’s theorem of
dominated convergence, and the fact that

Rn e−y2
4 dy = (2√π)n.
Since φ ∈D(Rn+1) is arbitrary, this shows that (∂t −Δn)En = δ and hence the given
function is indeed the elementary solution of the operator ∂−Δn.
2
8.4.3
The Wave Operator 24 = ∂2
0 −Δ3 in R4
Here we use the notation ∂0 =
∂
∂x0 . In applications to physics, the variable x0 has the
interpretation of x0 = ct, c being the velocity of light and t the time variable. The
variable x ∈R3 stands for the space coordinate. For the wave operator, Hörmander’s
theorem does not apply and accordingly several elementary solutions for the wave
operator are known. We mention two solutions:
Er,a(x0, x) = 1
2π θ( ± x0)δ(x2
0 −x2).
(8.19)
These distributions are deﬁned as follows:
⟨θ( ± x0)δ(x2
0 −x2), φ(x0, x)⟩=

R3 φ( ± |x|, x) dx
2|x|.
Since the function x #→
1
|x| is integrable over compact sets in R3, these are indeed
well-deﬁned distributions.
Proposition 8.5 The distributions (8.19) are two elementary solutions of the wave
operator 24 in dimension 4. Their support properties are:
supp Er =

(x0, x) ∈R4 : x0 ≥0, x2
0 −x2 = 0

supp Ea =

(x0, x) ∈R4 : x0 ≤0, x2
0 −x2 = 0

.
Proof
The obvious invariance of the wave equation under rotations in R3 can be
used to reduce the number of dimensions that have to be considered. This can be
done by averaging over the unit sphere S2 in R3. Accordingly, to every φ ∈D(R4),
we assign a function ˜φ : R × R+ by the formula

8.4
Elementary Solutions of Partial Differential Operators
115
˜φ(t, s) =

S2 φ(t, sω)dω,
where dω denotes the normalized surface measure on S2. Introducing polar
coordinates in R3, we thus see
⟨Er,a, φ⟩=
 ∞
0
s ˜φ( ± s, s)ds.
In the exercises it is shown that
&
24φ(t, s) =
 ∂2
∂t2 −∂2
∂s2 −2
t
∂
∂s

˜φ(t, s).
Thus we get
⟨24Er,a, φ⟩= ⟨Er,a, 24φ⟩=
 ∞
0
t &
24φ(t, t)dt.
Introducing, for t > 0, the auxiliary function
u(t) = t ∂˜φ
∂t (t, t) −t ∂˜φ
∂s (t, t) −˜φ(t, t),
which has the derivative
u′(t) = t
'
∂2 ˜φ
∂t2 −∂2 ˜φ
∂s2 −2
t
∂˜φ
∂s
(
(t, t),
it follows that
⟨24Er, φ⟩=
 ∞
0
u′(t)dt = −u(0) = ˜φ(0, 0) = φ(0) = ⟨δ, φ⟩,
and thus we conclude that Er is an elementary solution of the wave operator. The
argument for Ea is quite similar.
2
Remark 8.2
1. Though the wave operator 24 is not hypoelliptic, it can be shown that it is hy-
poelliptic in the variable x0. This means that every weak solution u(x0, x) of the
wave equation is a C∞-function in x0 (see [1]).
2. Later with the help of Fourier transformation for tempered distributions, we will
give another proof for Er,a being elementary solutions of the wave operator.
3. In particular, in applications to physics, the support properties will play an impor-
tant role. According to these support properties, one calls Er a retarded and Ea
an advanced elementary solution. The reasoning behind these names is apparent
from the following discussion of solutions of Maxwell’s equation.

116
8
Applications of Convolution
8.4.3.1
Maxwell’s Equation in Vacuum
Introducing the abbreviations x0 = ct and ∂0 =
∂
∂x0 , Maxwell’s equation in vacuum
can be written as follows (see [2]):
curl E + ∂0B = 0 Faraday’s law
div B = 0 source-free magnetic ﬁeld
curl B + ∂0E = j Maxwell’s form of Ampère’s law
div E = ρ Coulomb’s law
In courses on electrodynamics it is shown: Given a density ρ of electric charges and
a density j of electric currents, the electric ﬁeld E and the magnetic ﬁeld B are given
by
B = curl A,
E = −∇Φ −∂0A,
where (Φ, A) are the electromagnetic potentials. In the Lorenz gauge, i.e., ∂0Φ +
div A = 0, these electromagnetic potentials are solutions of the inhomogeneous
wave equations
24Φ = ρ,
24A = j.
(The last equation is understood component-wise, i.e., 24Ai = ji for i = 1, 2, 3.)
Thus the problem of solving Maxwell’s equations in vacuum has been put into a
form to which our previous results apply since we know elementary solutions of the
wave operator.
In concrete physical situations, the densities of charges and currents are switched
on at a certain moment that we choose to be our time reference point t = 0. Then
one knows supp ρ, supp j ⊆

(x0, x) ∈R4 : x0 ≥0

.
It follows that the pairs (Er, ρ) and (Er, j) satisfy the support condition and thus
the convolution products Er ∗ρ and Er ∗j are well deﬁned. We conclude that the
electromagnetic potentials are given by
(Φ, A) = (Er ∗ρ, Er ∗j),
which in turn give the electromagnetic ﬁeld as mentioned above. Because of the
knownsupportpropertiesofEr andρ andtheformulaforthesupportofaconvolution,
we know: supp Φ ⊆

(x0, x) ∈R4 : x0 ≥0

and similarly for A. Hence our solution
formula shows causality, i.e., no electromagnetic ﬁeld before the charge and current
densities are switched on! The other elementary solution Ea of the wave operator
does not allow this conclusion.
Note that the above formula gives a solution for Maxwell’s equation not only for
proper densities (ρ ∈L1(R3)) but also for the case where ρ is any distribution with
the support property used earlier. The same applies to j.
Under well-known decay properties for ρ and j for |x| →+∞, one can show that
the electromagnetic ﬁeld (E, B) determined above is the only solution to Maxwell’s
equation in vacuum.

References
117
8.5
Exercises
1. Let f : R+ →R be a continuous function. In D′
+(R), ﬁnd a special solution of
the ordinary differential equation
y(4) −8y(2) + 16y = f
and verify that it is actually a classical solution.
2. Let K : R+ →R be a continuous function. For n = 2, 3, . . ., deﬁne
K∗n(x) =
 x
0
K∗(n−1)(y)K(x −y)dy,
∀x ∈R+
and show that for every 0 < r < ∞, one has
|K∗n(x)| ≤Mn
r
xn−1
(n −1)!
∀x ∈[0, r].
Here Mr = sup0≤x≤r |K(x)|.
3. Let △n be the Laplace operator in Rn (n = 2, 3, . . . ). For α ∈Nn, solve the PDE
△nu = δ(α).
4. For the function En of Eq. (8.18), show ( ∂
∂t −Δn)En(t, x) = 0 for all (t, x) ∈
(0, +∞) × Rn.
5. Find the causal solution of Maxwell’s equations in vacuum.
Hints: Use the retarded elementary solution of the wave operator and calculate
E and B according to the formulae given in the text.
References
1. Hörmander L. The analysis of linear partial differential operators 2. Differential operators of
constant coefﬁcients. Berlin: Springer-Verlag; 1983.
2. Thirring W. A course in mathematical physics : classical dynamical systems and classical ﬁeld
theory. Springer study edition. New York: Springer-Verlag; 1992.

Chapter 9
Holomorphic Functions
This chapter gives a brief introduction to the theory of holomorphic functions of one
complex variable from a special point of view which deﬁnes holomorphic functions
as elements of the kernel or null space of a certain hypoelliptic differential operator.
Thus, this chapter offers a new perspective of some aspects on the theory of functions
of one complex variable. A comprehensive modern presentation of this classical
subject is [1].
Our starting point will be the observation that the differential operator in D′(R2)
∂= 1
2
 ∂
∂x + i ∂
∂y

is hypoelliptic and some basic results about convergence in the sense of distributions.
Then holomorphic functions will be deﬁned as elements in the null space in D′(R2)
of this differential operator. Relative to the theory of distributions developed thus far,
this approach to the theory of holomorphic functions is fairly easy, though certainly
this is neither a standard nor too direct an approach.
9.1
Hypoellipticity of ∂
We begin by establishing several basic facts about the differential operator ∂in
D′(R2).
Lemma 9.1
The regular distribution on R2, (x, y) #→
1
π(x+iy) is an elementary
solution of the differential operator ∂in D′(R2), i.e., in D′(R2) one has
∂
1
π(x + iy) = δ.
Proof It is easy to see that the function (x, y) #→
1
π(x+iy) is locally integrable on R2
and thus it deﬁnes a regular distribution. On R2\ {0} a straightforward differentiation
© Springer International Publishing Switzerland 2015
119
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_9

120
9
Holomorphic Functions
shows ∂
1
π(x+iy) = 0. Now take any φ ∈D(R2) and calculate
⟨∂
1
π(x + iy), φ⟩= −⟨
1
π(x + iy), ∂φ⟩= −

R2
∂φ(x, y)
π(x + iy)dx dy.
Since the integrand is absolutely integrable this integral can be represented as
= −lim
r→0

r≤√
x2+y2≤R
∂φ(x, y)
π(x + iy)dx dy
where R is chosen large enough such that supp φ ⊂BR(0). For any 0 < r < R, we
observe that

r≤√
x2+y2≤R
∂φ(x, y)
π(x + iy)dx dy =

r≤√
x2+y2≤R
∂
 φ(x, y)
π(x + iy)

dx dy
since ∂
1
π(x+iy) = 0 in R2\ {0}. Recall the formula of Green–Riemann for a domain
Ω ⊂R2 with smooth boundary Γ = ∂Ω (see [2]):

Ω
∂udx dy =
1
2iπ
)
Γ
u(x, y)(dx + idy)
(9.1)
which we apply to the function u(x, y) = 1
π
φ(x,y)
x+iy to obtain
⟨∂
1
π(x + iy), φ⟩= −1
2iπ lim
r→0

√
x2+y2=r
φ(x, y)
x + iy (dx + idy).
Introducing polar coordinates x = r cos θ, y = r sin θ, this limit becomes
lim
r→0
1
2π
 2π
0
φ(r cos θ, r sin θ)dθ = φ(0, 0) = ⟨δ, φ⟩
and thus we conclude.
2
Corollary 9.1
The differential operator ∂in D′(R2) is hypoelliptic, i.e., every
distribution T ∈D′(R2) for which ∂T is of class C∞on some open set Ω ⊂R2 is
itself of class C∞on Ω.
Proof Lemma 9.1 gives an elementary solution of ∂which is of class C∞on R2\ {0}.
Thus by Theorem 8.4 we conclude.
2
If we apply this corollary to a distribution T on R2 which satisﬁes ∂T = 0, it
follows immediately that T is equal to a C∞-function g, T = Ig, for some g ∈
C∞(R2), since obviously the zero function is of class C∞everywhere. Therefore the
null space of the operator ∂on D′(R2) can be described as
ker ∂=

T ∈D′(R2) : ∂T = 0

=

g ∈C∞(R2) : ∂g = 0


9.1
Hypoellipticity of ∂
121
where as usual we identify the function g and the regular distribution Ig.
Now let Ω ⊂R2 be a nonempty open set. Similarly one deduces
ker (∂|D′(Ω)) =

T ∈D′(Ω) : ∂T = 0

=

g ∈C∞(Ω) : ∂g = 0

.
This says in particular that a complex-valued function g in L1
loc(Ω) which satisﬁes
∂g = 0 in the sense of distributions is actually a C∞-function on Ω.
As usual we identify the point (x, y) ∈R2 with the complex number z = x + iy.
Under this identiﬁcation we introduce
H(Ω) =

g ∈L1
loc(Ω) : ∂g = 0 in D′(Ω)

=

u ∈C∞(Ω) : ∂u = 0

.
(9.2)
Elements in H(Ω) are called holomorphic functions on Ω. The following theorem
lists the basic properties of the space of holomorphic functions.
Theorem 9.1 Let Ω ⊂C be a nonempty open set. The space H(Ω) of holomorphic
functions on Ω has the following properties:
1. H(Ω) is a complex algebra.
2. H(Ω) is complete for the topology of uniform convergence on all compact subsets
of Ω.
3. If u ∈H(Ω) does not vanish on Ω, then 1
u ∈H(Ω).
4. If a function u is holomorphic on Ω and a function v is holomorphic on an open
set ˜Ω which contains u(Ω), then the composition v ◦u is holomorphic on Ω.
Proof
The nullspace of a linear operator on a vector space H(Ω) is certainly a
complex vector space. The product rule of differentiation easily implies that with
u, v ∈H(Ω) also the (pointwise) product u · v belongs to H(Ω). The veriﬁcation
that with this product H(Ω) is indeed an algebra is straightforward and is left as an
exercise.
Suppose that (un) is a Cauchy sequence in H(Ω) for the topology of uniform
convergence on all compact sets K ⊂Ω. It follows that there is some continuous
function u on Ω such that the sequence un converges uniformly to u, on every compact
set K ⊂Ω. Take any φ ∈D(Ω). It follows, as n →∞, that

un(x + iy)φ(x, y)dx dy →

u(x + iy)φ(x, y)dx dy,
thus un →u in D′(Ω). As a linear differential operator with constant coefﬁcients
the operator ∂: D′(Ω) →D′(Ω) is continuous and therefore ∂u = limn→∞∂un =
limn→∞0 = 0. We conclude u ∈H(Ω). This proves the second part.
If u ∈H(Ω) has no zeroes in Ω, then 1
u is a well-deﬁned continuous function on
Ω and the differentiation rules imply ∂1
u = −1
u2 ∂u = 0, hence 1
u ∈H(Ω).
The ﬁnal part follows by a straightforward application of the chain rule and is in
the Exercises.
2
It is easy to give many examples of holomorphic functions. Naturally, every con-
stant function u = a ∈C satisﬁes ∂a = 0 and thus all constants belong to H(Ω).

122
9
Holomorphic Functions
Next consider the function z #→z. It follows that ∂z = 1
2(1 −1) = 0, hence this
function belongs to H(Ω) too. Since we learned in Theorem 9.1 that H(Ω) is a
complex algebra, it follows immediately that all polynomials P(z) = m
n=0 anzn,
an ∈C, belong to H(Ω).
According to Theorem 9.1 the algebra H(Ω) is complete for the topology of
uniform convergence on all compact sets K ⊂Ω. Therefore, all functions u : Ω →
C belong to H(Ω) which are the limit of a sequence of polynomials for this topology.
We investigate this case in more detail.
Recall some properties of power series (see for instance [1]). A power series
∞
n=0 an(z −c)n with center c ∈C and coefﬁcients an ∈C has a unique disk of
convergence BR(c) = {z ∈C : |z −c| < R} where the radius of convergence R is
determined by the coefﬁcients {an : n = 0, 1, 2, . . .}. On every compact subset K of
the disk of convergence the power series converges uniformly, and thus deﬁnes a
complex-valued function u on BR(c). From our earlier considerations it follows that
u is holomorphic on this disk.
Let Ω ⊂C be a nonempty open set. A function u : Ω →C is said to be analytic
on Ω, if, and only if, for every point c ∈Ω there is some disk Br(c) ⊂Ω such that on
this disk the function u is given by some power series, i.e., u(z) = ∞
n=0 an(z−c)n for
all z ∈Br(c). Since every compact subset K ⊂Ω can be covered by a ﬁnite number
of such disks of convergence, it follows that every analytic function is holomorphic,
i.e.,
A(Ω) ⊆H(Ω)
where A(Ω) denotes the set of all analytic functions on Ω. In the following section,
we will learn that actually every holomorphic function is analytic so that these two
sets of functions are the same.
9.2
Cauchy Theory
According to our deﬁnition a holomorphic function u on an open set is a function
which solves the differential equation ∂u = 0. If this is combined with a well-known
result from classical analysis, the Green–Riemann formula, the basic result of the
Cauchy theory follows easily.
Theorem 9.2 (Theorem of Cauchy) Let Ω ⊂C be a nonempty open set and B be
an open set such that the closure B of B is contained in Ω. Assume that the boundary
∂B of B is piecewise smooth (i.e., piecewise of class C1). Then, for all u ∈H(Ω),
)
∂B
u(z)dz = 0.
(9.3)
Proof The proof of Cauchy’s theorem is a simple application of the Green–Riemann
formula (9.1).
2

9.2
Cauchy Theory
123
Theorem 9.3 (Cauchy’s Integral Formula I) Let Ω ⊂C be a nonempty open set
and K ⊂Ω a compact subset whose boundary (with standard orientation) Γ = ∂K
is piecewise smooth. Then, for every u ∈H(Ω), one has
1
2iπ
)
Γ
u(z)
z −z0
dz =
⎧
⎨
⎩
0
if z0 ̸∈K,
u(z0)
if z0 ∈K\Γ.
(9.4)
Proof Denote by ˙K = K\Γ the interior of the compact set K and by χ the charac-
teristic function of ˙K. Now, given any u ∈H(Ω), introduce the regular distribution
T = χu. Using ∂u = 0 and again the Green–Riemann formula (9.1) we ﬁnd, for
any φ ∈D(Ω),
⟨∂T , φ⟩
= −⟨T , ∂φ⟩= −

˙K u(z)∂φ(z)dx dy
= −

˙K ∂(uφ)(z)dx dy = −1
2iπ
*
Γ u(z)φ(z)dz.
Lemma 9.1 says that ∂1
πz = δ. Since T has a compact support in K, the convolution
with
1
πz exists and the identity T =
1
π ∂T ∗1
z holds. Take a test function φ which
satisﬁes φ(z) = 1 for all z ∈K and which has its support in a sufﬁciently small
neighborhood U of K. For z0 ∈Ω\Γ the combination of these identities yields
T (z0) = 1
π

∂T ∗1
z

(z0) = 1
π ⟨(∂T )(z), φ(z)
z −z0
⟩
= −1
2iπ
)
Γ
u(z) φ(z)
z −z0
dz =
1
2iπ
)
Γ
u(z)
z −z0
dz,
and thus Cauchy’s integral formula follows.
2
Cauchy’s integral formula (9.4) has many applications, practical and theoretical.
We discuss now one of the most important applications which shows that every
holomorphic function has locally a power series expansion and thus is analytic.
Theorem 9.4 (Cauchy’s Integral Formulae II) Let Ω ⊂C be a nonempty open
set. For every c ∈Ω deﬁne
R = R(c) = sup
 
R′ > 0 : BR′(c) ⊂Ω
!
.
(9.5)
Then, for every u ∈H(Ω) and every r ∈(0, R) the following statements hold:
1. u has a power series expansion in Br(c),
u(z) =
∞

n=0
an(z −c)n
∀z ∈Br(c);
and this power series expansion converges uniformly on every compact subset
K ⊂Br(c).

124
9
Holomorphic Functions
2. The coefﬁcients an of this power series expansion are given by Cauchy’s integral
formulae
an = an(c) =
1
2iπ
)
|z−c|=r
u(z)
(z −c)n+1 dz
n = 0, 1, 2, . . .;
(9.6)
and these coefﬁcients depend on c and naturally on the function u but not on the
radius r ∈(0, R) which is used to calculate them.
Proof Take any c ∈Ω and determine R = R(c) as in the theorem. Then for every
r ∈(0, R) we know Br(c) ⊂Ω. Thus, Theorem 9.3 applies to K = Br(c) and
Γ = ∂Br(c) = {z ∈C : |z −c| = r} and hence for all z ∈Br(c) one has
u(z) =
1
2iπ
)
|z−c|=r
u(ξ)
ξ −zdξ.
Take any compact set K ⊂Br(c). Since |z −c| < r = |ξ −c| we can expand the
function ξ #→
1
ξ−z into a geometric series:
1
ξ −z =
1
ξ −c
1
1 −z−c
ξ−c
=
1
ξ −c
∞

n=0
 z −c
ξ −c
n
.
This series converges uniformly in ξ ∈∂Br(c) and z ∈K. Hence, we can exchange
the order of integration and summation in the above formula to get
u(z) =
∞

n=0
 1
2iπ
)
|ξ−c|=r
u(ξ)dξ
(ξ −c)n+1

(z −c)n.
Hence, the function u has a power series expansion in Br(c) with coefﬁcients an
given by formula (9.6). The proof that the coefﬁcients do not depend on r ∈(0, R)
is left as an exercise.
2
Corollary 9.2 Let Ω ⊂C be a nonempty open set.
1. A function u on Ω is holomorphic if, and only if, it is analytic:
H(Ω) = A(Ω).
2. The power series expansion of a holomorphic function u on Ω is unique in a given
disk Br(c) ⊂Ω of convergence.
3. Given c ∈Ω determine R = R(c) according to (9.5) and choose r ∈(0, R).
Then, for every u ∈H(Ω), the following holds:
a) For n = 0, 1, 2, . . . the coefﬁcient an of the power series expansion of u at the
point c and the nth complex derivative of u at c are related by
u(n)(c) = n!an.
(9.7)

9.3
Some Properties of Holomorphic Functions
125
b) The nth derivative of u at c is bounded in terms of the values of u on the
boundary of the disk Br(c) according to the following formula (Cauchy
estimates):
|an|rn ≤
sup
|z−c|=r
|u(z)|.
(9.8)
Proof In the discussion following Theorem 9.1, we saw that every analytic function
is holomorphic. The previous theorem shows that conversely every holomorphic
function is analytic. The uniqueness of the power series expansion of a holomorphic
function at a point c ∈Ω was shown in Theorem 9.4.
The Cauchy estimates are a straightforward consequence of the Cauchy formulae
(9.6):
|an| ≤1
2π
)
|z−c|=r
|u(z)||dz|
|z −c|n+1 ≤1
2π
1
rn+1
sup
|z−c|=r
|u(z)|2πr.
This estimate implies (9.8) and thus we conclude.
2
9.3
Some Properties of Holomorphic Functions
As a consequence of the Cauchy theory, we derive some very important properties
of holomorphic functions which themselves have many important applications.
Corollary 9.3 (Theorem of Liouville) The only bounded functions in H(C) are the
constants, i.e., if a function u is holomorphic on all of C and bounded there, then u
is a constant function.
Proof Suppose u ∈H(C) is bounded on C by M, i.e., supz∈C |u(z)| = M < +∞.
Since u is holomorphic on C the value of R = R(0) in (9.5) is +∞. Hence, in the
Cauchy estimates we can choose r as large as we wish. Therefore, in this case we
have |an| ≤M
rn for every r > 0. It follows that an = 0 for n = 1, 2, . . . , and thus
Theorem 9.4 shows that u is constant.
2
Corollary 9.4 (Fundamental Theorem of Algebra) Suppose P is a polynomial of
degree N ≥1 with coefﬁcients an ∈C, i.e., P(z) = N
n=0 anzn, aN ̸= 0. Then there
are complex numbers {z1, . . ., zN}, the roots of P, which are unique up to ordering
such that
P(z) = an(z −z1) · · · (z −zN)
∀z ∈C.
If all the coefﬁcients of the polynomial P are real, then P has either only real roots
or if complex roots exist, they occur as pairs of complex numbers which are complex
conjugate to each other and have the same multiplicity; in such a case the polynomial
factorizes as
P (z) = an(z −x1) · · · (z −xm)|z −z1|2 · · · |z −zk|2
∀z ∈C.
Here x1, . . ., xm are the real roots of P and z1, z1, . . ., zk, zk are the complex roots of
P ; hence m + 2k = N.

126
9
Holomorphic Functions
Proof In a ﬁrst and basic step, we show that a polynomial which is not constant has
at least one root. Suppose P is a polynomial of degree N ≥1 which has no roots in
C. Then we know that the function z #→
1
P(z) is holomorphic on C.
We write the polynomial in the form
P(z) = aNzN

1 + aN−1
aNz + · · · +
a0
aNzN

and choose R so large that

aN−1
aNz + · · · +
a0
aNzN
 ≤1
2
for all |z| ≥R. It follows that
|P(z)| ≥1
2|aN|RN
∀|z| ≥R.
On the compact set KR = {z ∈C : |z| ≤R} the continuous function |P| is strictly
positive (since we have assumed that P has no roots), i.e.,
b = bR = inf
z∈KR |P(z)| > 0.
It thus follows that
1
P(z) is bounded on C:
|P(z)| ≤max
+1
b,
2
|aN|RN
,
∀z ∈C.
By Liouville’s theorem (Corollary 9.3) we conclude that
1
P(z) and thus P(z) is constant
which is a contradiction to our hypothesis that the degree N of P is larger than or
equal to 1. We deduce that a polynomial of degree N ≥1 has at least one root, i.e.,
for at least one z0 ∈C, one has P(z0) = 0.
In order to complete the proof, a proof by induction with respect to the degree
N has to be done. For details we refer to the Exercises where the special case of
polynomials with real coefﬁcients is also considered.
2
Holomorphic functions differ from functions of class C∞in a very important
way: If all derivatives of two holomorphic functions agree in one point, then these
functions agree everywhere, if the domain is “connected.” As we have seen earlier
this is not all the case for C∞-functions which are not holomorphic.
Theorem 9.5 (Identity Theorem) Suppose that Ω ⊂C is a nonempty open and
connected set and f , g : Ω →C are two holomorphic functions. The following
statements are equivalent:
(a) f = g
(b) The set of all points in Ω at which f and g agree, i.e., the set
{z ∈Ω : f (z) = g(z)}

9.3
Some Properties of Holomorphic Functions
127
has an accumulation point c ∈Ω
(c) There is a point c ∈Ω in which all complex derivatives of f and g agree:
f (n)(c) = g(n)(c) for all n = 0, 1, 2, . . . .
Proof
The implication (a) ⇒(b) is trivial. In order to show that (b) implies (c),
introduce the holomorphic function h = f −g on Ω. According to (b) the set
M = {z ∈Ω : h(z) = 0} of zeroes of h has an accumulation point c ∈Ω. Suppose
that h(m)(c) ̸= 0 for some m ∈N. We can assume that m is the smallest number with
this property. Then in some open disk around c we can write h(z) = (z −c)mhm(z)
with hm(z) = ∞
i=m
h(i)(c)
i! (z −c)i−m and hm(c) ̸= 0. Continuity of hm implies that
hm(z) ̸= 0 for all points z in some neighborhood U of c, U ⊂B. It follows that the
only point in U in which h vanishes is the point c, hence this point is an isolated point
of M. This contradiction implies h(n)(c) = 0 for all n = 0, 1, 2 . . . and statement (c)
holds.
For the proof of the implication (c) ⇒(a), we introduce again the holomor-
phic function h = f −g and consider, for k = 0, 1, 2, . . . , the sets Nk =

z ∈Ω : h(k)(z) = 0

. Since the function h(k) is continuous, the set Nk is closed
in Ω. Hence, the intersection N = ∩∞
k=0Nk of these sets is closed too. But N is at
the same time open: Take any z ∈N. Since h(k) is holomorphic in Ω its Taylor series
at z converges in some open nonempty disk B with center z. Since z ∈N, all Taylor
coefﬁcients of this series vanish and it follows that h(k)|B = 0 for all k ∈N. This
implies B ⊂N and we conclude that N is open. Since Ω is assumed to be connected
and N is not empty (c ∈N because of c)) we conclude N = Ω and thus f = g.
2
There are other versions and some extensions of the identity theorem for
holomorphic functions, see [1].
Another important application of Cauchy’s integral formula (9.4) is the classiﬁca-
tion of isolated singularities of a function and the corresponding series representation.
Here, one says that a complex function u has an isolated singularity at a point c ∈C,
if, and only if, there is some R > 0 such that u is holomorphic in the set
K0,R(c) = {z ∈C : 0 < |z −c| < R} ,
which is a disk of radius R from which the center c is removed. If a function is
holomorphic in such a set it allows a characteristic series representation which gives
the classiﬁcation of isolated singularities. This series representation is in terms of
powers and inverse powers of z −c and is called the Laurent expansion of u.
Theorem 9.6 (Laurent Expansion) For 0 ≤r < R ≤+∞consider the annulus
Kr,R(c) = {z ∈C : r < |z −c| < R} with center c and radii r and R. Every function
u which is holomorphic in Kr,R(c) has the unique Laurent expansion
u(z) =
+∞

n=−∞
an(z −c)n
∀z ∈Kr,R(c),
(9.9)

128
9
Holomorphic Functions
which converges uniformly on every compact subset K ⊂Kr,R(c). The coefﬁcients
an of this expansion are given by
an =
1
2iπ
)
|t−c|=ρ
u(t)
(t −c)n+1 dt
∀n ∈Z,
(9.10)
where ρ ∈(r, R) is arbitrary. These coefﬁcients depend only on the function u and
on the annulus but not on the radius ρ ∈(r, R).
Proof Consider any compact set K ⊂Kr,R(c). There are radii ri such that for all
z ∈K,
r < r1 < |z −c| < r2 < R.
Apply Cauchy’s integral formula (9.4) to the annulus Kr,R(c) and a given function
u ∈H(Kr,R(c)). This yields
u(z) =
1
2iπ
)
|t−c|=r1
u(t)
t −zdt +
1
2iπ
)
|t−c|=r2
u(t)
t −zdt
∀z ∈K.
Uniformly in z ∈K and |t −c| = r1, respectively, |t −c| = r2, one has
|t −c|
|z −c| =
r1
|z −c| ≤α < 1
respectively
|z −c|
|t −c| = |z −c|
r2
≤β < 1.
The convergence of the geometric series ∞
n=0 qn for 0 ≤q < 1 ensures the uniform
convergence of the series
1
t −z = −
1
z −c
∞

n=0
t −c
z −c
n
∀|t −c| = r1; ∀z ∈K,
1
t −z =
1
t −c
∞

n=0
z −c
t −c
n
∀|t −c| = r2; ∀z ∈K.
Therefore, we may exchange the order of summation and integration in the above
integral representation of u and obtain uniformly in z ∈K,
u(z)
=
∞

n=0
 1
2iπ
)
|t−c|=r2
u(t)dt
(t −c)n+1

(z −c)n+
+
∞

n=0
 1
2iπ
)
|t−c|=r1
u(t)(t −c)ndt

(z −c)−n−1.
If we choose −n −1 as new summation index in the second series, we arrive at
the Laurent expansion (9.9) with coefﬁcients given by (9.10). A straightforward
application of (9.4) shows that the integrals
)
|t−c|=ρ
u(t)dt
(t −c)m
∀m ∈Z
are independent of the choice of ρ ∈(r, R) and thus we conclude.
2

9.3
Some Properties of Holomorphic Functions
129
The announced classiﬁcation of isolated singularities of a function u is based
on the Laurent expansion of u at the singularities and classiﬁes these singularities
according to the number of coefﬁcients an ̸= 0 for n ≤0 in the Laurent expansion.
In detail one proceeds in the following way.
Suppose c ∈C is an isolated singularity of a function u. Then there is an R =
R(u, c) > 0 such that u is holomorphic in the annulus K0,R(c) and thus has a unique
Laurent expansion there:
u(z) =
+∞

n=−∞
an(z −c)n
∀z ∈K0,R(c).
One distinguishes three cases:
a) an = 0 for all n < 0. Then c is called a removable singularity. Initially u is
not deﬁned at z = c, but the limit limz→c u(z) exists and is used to deﬁne the
value of u at z = c. In this way u becomes deﬁned and holomorphic in the disk
{z ∈C : |z −c| < R}. A well-known example is u(z) = sin z
z
for all z ∈C, z ̸= 0.
Using the power series expansion for sin z we ﬁnd easily the Laurent series for u
at z = 0 and see that limz→0 u(z) exists.
b) There is k ∈N, k > 0, such that an = 0 for all n ∈Z, n < −k and ak ̸= 0. Then
the point z = c is called a pole of order k of the function u. One has |u(z)| →+∞
as z →c. A simple example is the function u(z) = z−3 for z ∈C, z ̸= 0. It has a
pole of order 3 in z = 0.
c) an ̸= 0 for inﬁnitely many n ∈Z, n < 0. In this case the point c is called an
essential singularity of u. As an example we mention the function u(z) = e
1
z
deﬁned for all z ∈C →{0}. The well-known power series expansion of the
exponential function shows easily that the Laurent series of u at z = 0 is given
by ∞
n=0
1
n!
1
zn and thus u has an essential singularity at z = 0.
Assume that a function u has an isolated singularity at a point c. Then, in a certain
annulus K0,R(c) it has a unique Laurent expansion (9.9) where the coefﬁcients an have
the explicit integral representation (9.10). For n = −1 this integral representation is
a−1 =
1
2iπ
)
|z−c|=ρ
u(z)dz
(9.11)
for a suitable radius ρ. This coefﬁcient is called the residue of the function u at the
isolated singularity c, usually denoted as
a−1 = Res (u, c).
If c is a pole of order 1, the Laurent expansion shows that the residue can be calculated
in a simple way as
Res (u, c) = lim
z→c (z −c)u(z).
(9.12)

130
9
Holomorphic Functions
In most cases it is fairly easy to determine this limit and thus the residue. This offers
a convenient way to determine the value of the integral in (9.11) and is the starting
point for a method which determines the values of similar path integrals.
Theorem 9.7 (Theorem of Residues) Suppose Ω ⊂C is a nonempty open set
and D ⊂Ω a discrete subset (this means that in every open disk Kr(z) =
{ξ ∈C : |ξ −z| < r} there are only a ﬁnite number of points from D). Further-
more assume that K is a compact subset of Ω such that the boundary Γ = ∂K of K
with standard mathematical orientation is piecewise smooth and does not contain
any point from D. Then, for every u ∈H(Ω\D), the following holds:
a) The number of isolated singularities of u in K is ﬁnite.
b) Suppose {z0, z1, . . ., zN} are the isolated singularities of u in K, then one has
)
Γ
u(z)dz = 2πi
N

n=0
Res(u, zn).
(9.13)
Proof Given a point z ∈K, there is an open disk in Ω which contains at most one
point from D since D is discrete. Since K is compact, a ﬁnite number of such disks
cover K. This proves part (a).
Suppose that z0, z1, . . . , zN are the isolated singularities of u in K. One can ﬁnd
radii r0, r1, . . ., rN such that the closed disks Krj (zj) are pairwise disjoint. Now
choose the orientation of the boundaries ∂Krj (zj) = −γj of these disks in such a
way that Γ ∪∪N
j=0γj is the oriented boundary of some compact set K′ ⊂Ω. By
construction the function u is holomorphic in some open neighborhood of K′ and
thus (9.4) applies to give
)
Γ
u(t)dt +
N

j=0
)
γj
u(t)dt = 0,
i.e., by (9.11)
)
Γ
u(t)dt =
N

j=0
)
∂Krj (zj )
u(t)dt = 2πi
N

j=0
Res(u, zj)
and we conclude.
2
Remark 9.1
1. Only in the case of a pole of order 1 can we calculate the residue by the simple
formula (9.12). In general, one has to use the Laurent series.A discussion of some
other special cases in which it is relatively easy to ﬁnd the residue without going
to the Laurent expansion is explained in most textbooks on complex analysis.
2. In the case of u being the quotient of two polynomials P and Q, u(z) = P(z)
Q(z), one
has a pole of order 1 at a point z = c if Q(c) = 0, Q′(c) ̸= 0, and P(c) ̸= 0. Then

References
131
the residue of u at the point c can be calculated by formula (9.12). The result is a
convenient formula
Res(u, c) = lim
z→c (z −c)u(z) = lim
z→c
P(z)
Q(z)−Q(c)
z−c
= P(c)
Q′(c).
9.4
Exercises
1. Write a complex-valued function f : Ω →C on some open set Ω ⊂C in
terms of its real and imaginary parts, f (x + iy) = u(x, y) + iv(x, y) for all
z = x + iy ∈Ω where u and v are real-valued functions. Show: If ∂f (z) = 0 on
Ω, then the functions u, v satisfy the Cauchy–Riemann equations
∂u
∂x (x, y)
= + ∂v
∂y (x, y),
∂u
∂y (x, y)
= −∂v
∂x (x, y).
2. Prove Part 4 of Theorem 9.1.
3. Show: In Cauchy’s integral formula (9.6) the right-hand side is independent of r,
0 < r < R.
4. Complete the proof of Corollary 9.4.
Hint: For the case of a real polynomial prove ﬁrst that P(z) = 0 implies P(z) = 0
and observe that a complex root z and its complex conjugate z have the same
multiplicity.
References
1. Hörmander L.An introduction to complex analysis in several variables. Princeton:Van Nostrand;
1967.
2. Remmert R. Theory of complex functions. Graduate texts in mathematics, vol 122. 4th ed.
Berlin: Springer; 1998.

Chapter 10
Fourier Transformation
Our goal in this chapter is to deﬁne the Fourier transformation in a setting which is as
general as possible and to discuss the most important properties of this transforma-
tion. Thisisfollowedbysometypicalandimportantapplications, mainlyinthetheory
of partial differential operators with constant coefﬁcients as they occur in physics.
If one wants to introduce the Fourier transformation on the space D′(Rn) of all
distributions on Rn, one encounters a natural difﬁculty which has its origin in the
fact that general distributions are not restricted in their growth when one approaches
the boundary of their domain of deﬁnition. It turns out that the growth restrictions
whichcontroltempereddistributionsaresufﬁcienttoallowaconvenientandpowerful
Fourier transformation on the space S′(Rn) of all tempered distributions. As a matter
of fact, the space of tempered distributions was introduced for this purpose.
The starting point of the theory of Fourier transformation is very similar to that of
the theory of Fourier series. Under well-known conditions a periodic complex valued
function can be represented as the sum of exponential functions of the form aneinκx,
n ∈Z, an ∈C, where κ is determined by the period of the function in question. The
theory of Fourier transformation aims at a similar representation without assuming
periodicity, but allowing that the summation index n might have to vary continuously
so that the sum is replaced by an integral.
On a formal level the transition between the two representations is achieved in the
following way. Suppose that f : R →C is an integrable continuous function. For
each T > 0 introduce the auxiliary function fT with period 2T which is equal to f
on the interval [−T , T ]. Then fT has a representation in terms of a Fourier series
fT (x) = 1
2T

n∈Z
cnein π
T x
with
cn =
 +T
−T
f (x)e−in π
T xdx.
Now introduce ν = n π
T and aν = cn and rewrite the above representation as
fT (x) = 1
2T

ν
aνeiνx
with
aν =
 +T
−T
f (x)e−iνxdx.
© Springer International Publishing Switzerland 2015
133
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_10

134
10
Fourier Transformation
Two successive values of the summation index differ by π
T ; thus, formally, we get in
the limit T →+∞,
f (x) = 1
2π

R
aνeiνxdν
with
aν =

R
f (x)e−iνxdx.
The following section will give a precise meaning to these relations.
In order to be able to deﬁne and to study the Fourier transformation for distribu-
tions, we begin by establishing the basic properties of the Fourier transformation
on various spaces of functions. In the ﬁrst section we introduce and study the
Fourier transformation on the space L1(Rn) of Lebesgue integrable functions. Re-
call that L1(Rn) denotes the space (of equivalence classes) of measurable functions
f : Rn →C which are absolutely integrable, i.e., for which the norm
∥f ∥1 =

Rn |f (x)|dx
is ﬁnite. The main result of Sect. 10.2 is that the Fourier transformation is an iso-
morphism of the topological vector space S(Rn) which is the test function space for
tempered distributions. This easily implies that the Fourier transform can be deﬁned
on the space of tempered distributions by duality. Section 10.3 then establishes the
most important properties of the Fourier transformation for tempered distributions. In
the ﬁnal section on applications, we come back to the study of linear partial differen-
tial operators with constant coefﬁcients and the improvements of the solution theory
one has in the context of tempered distributions. There we will learn, among other
things, that with the help of the Fourier transformation it is often fairly easy to ﬁnd
elementary solutions of linear partial differential operators with constant coefﬁcients.
10.1
Fourier Transformation for Integrable Functions
For x = (x1, . . ., xn) ∈Rn and p = (p1, . . ., pn) ∈Rn, denote by p · x = p1x1 +
· · · + pnxn the Euclidean inner product. Since for all x, p ∈Rn one has |eip·x| = 1,
all the functions x #→eip·xf (x), p ∈Rn, f ∈L1(R), are integrable and thus we get
a well-deﬁned function ˜f : Rn →C by deﬁning, for all p ∈Rn,
˜f (p) = (2π)−n
2

Rn e−ip·xf (x)dx.
(10.1)
This function ˜f is called the Fourier transform of f and the map deﬁned on L1(Rn)
by Ff ≡F(f ) = ˜f is called the Fourier transformation (on L1(Rn)).
Remark 10.1 The choice of the normalization factor (2π)−n
2 and the choice of the
sign of the argument of the exponential function in the deﬁnition of the Fourier
transform are not uniform in the literature (see, for instance, [1–7]). Each choice has
some advantage and some disadvantage.

10.1
Fourier Transformation for Integrable Functions
135
In our normalization the Fourier transform of Dirac’s delta distribution on Rn will
be Fδ = (2π)−n
2 .
The starting point of our investigation of the properties of the Fourier transform
is the following basic result.
Lemma 10.1 (Riemann–Lebesgue) The Fourier transform
˜f
= Ff of f
∈
L1(Rn) has the following properties:
a)
˜f is a continuous and bounded function on Rn.
b) F : L1(Rn) →L∞(Rn) is a continuous linear map. One has the following bound:
∥Ff ∥∞≡sup
p∈Rn | ˜f (p)| ≤(2π)−n
2 ∥f ∥1 .
c)
˜f vanishes at inﬁnity, i.e.,
lim
|p|→∞
˜f (p) = 0.
Proof The bound given in part b) is evident from the deﬁnition (10.1) of the Fourier
transformation. The basic rules of Lebesgue integration imply that F is a linear map
from L1(Rn) into L∞(Rn). In order to prove continuity of ˜f at any point p ∈Rn,
for any f ∈L1(Rn), consider any sequence of points pk which converges to p. It
follows that
lim
k→∞
˜f (pk) = (2π)−n
2 lim
k→∞

Rn e−ipk·xf (x)dx = (2π)−n
2

Rn e−ip·xf (x)dx = ˜f (p)
sincee−ipk·xf (x) →e−ip·xf (x)ask →∞, foralmostallx ∈Rn and|e−ipk·xf (x)| ≤
|f (x)| for all x ∈Rn and all k ∈N, so that Lebesgue’s theorem on dominated
convergenceimpliestheconvergenceoftheintegrals. Thesequencetestforcontinuity
now proves continuity of ˜f at p. Thus continuity of ˜f follows. This proves parts a)
and b).
The proof of part c) is more involved. We start with the observation e−iπ = −1
and deduce, for all p ∈Rn, p ̸= 0:
(2π)
n
2 ˜f (p) = −

Rn e
−ip·(x+ πp
p2 )f (x)dx = −

Rn e−ip·xf

x −πp
p2

dx.
Recall the deﬁnition of translation by a vector a of a function f , fa(x) = f (x −a)
for all x ∈Rn. Then with a = πp
p2 for p ̸= 0, we can write
(Ff )(p) = 1
2[(Ff )(p) −(Ffa)(p)]|a= πp
p2 ,
hence, using linearity of F and the estimate of part b), it follows that
|(Ff )(p)| ≤1
2(2π)−n
2
---f −f πp
p2
---
1 .

136
10
Fourier Transformation
This shows that one can prove part c) by showing
lim
a→0 ∥f −fa∥1 = 0
∀f ∈L1(Rn),
i.e., translations act continuously on L1(Rn). This is a well-known result in the
theory of Lebesgue integrals. In the Exercises one is asked to prove this result, ﬁrst
for continuous functions with compact support and then for general elements in
L1(Rn). This concludes the proof.
2
In general, it is not so easy to calculate the Fourier transform
˜f of a func-
tion f in L1(Rn) explicitly. We give now a few examples where this calculation
is straightforward. A more comprehensive list will follow at the end of this chapter.
Example 10.1
1. Denote by χ[−a,a] the characteristic function of the symmetric interval [−a, a],
that is, χ[−a,a](x) = 1 for x ∈[−a, a] and χ[−a,a](x) = 0 otherwise. Clearly this
function is integrable and for Fχ[−a,a] we ﬁnd, for any p ∈R\ {0}:
˜χ[−a,a](p)
= (2π)−1
2 
R e−ipxχ[−a,a](x)dx = (2π)−1
2  +a
−a e−ipxdx
= (2π)−1
2 e−ipx
−ip
+a
−a =
2
√
2π
sin ap
p .
It is easy to see that the apparent singularity at p = 0 is removable.
2. Consider the function f (x) = e−x2. f is certainly integrable and one has

R e−x2dx = √π. In order to calculate the Fourier transform of this function, we
have to rely on Cauchy’s Integral Theorem 9.2 applied to the function z #→e−z2
which is holomorphic on the complex plane C.
(2π)
1
2 ˜f (p) =
 +∞
−∞
e−ipxe−x2dx = e−p2
4
 +∞
−∞
e−(x+ip)2dx
= e−p2
4

Cp
e−z2dz
Cp = {z = x + ip : x ∈R}
= e−p2
4

C0
e−z2dz
C0 = {z = x : x ∈R}
= e−p2
4 √π,
and thus we conclude that
F(e−x2)(p) =
1
√
2
e−p2
4 .
3. For some number a > 0 deﬁne the integrable function f (x) = e−a|x| for x ∈R.
Its L1-norm is ∥f ∥1 = 2
a . Its Fourier transform ˜f can be calculated as follows,

10.1
Fourier Transformation for Integrable Functions
137
for all p ∈R:
(2π)
1
2 ˜f (p) =
 +∞
−∞e−ipxe−a|x|dx =
 0
−∞e−ipx+axdx +
 +∞
0
e−ipx−axdx
= eax−ipx
a−ip
0
−∞+ e−ax−ipx
−a−ip
+∞
0
=
1
a−ip +
1
a+ip.
We rewrite this as
F

e−a|·|
(p) =
1
√
2π
2a
a2 + p2 .
The following proposition collects a number of basic properties of the Fourier
transformation. These properties say how the Fourier transformation acts on the
translation, scaling, multiplication, and differentiation of functions. In addition, we
learn that the Fourier transformation transforms a convolution product into an ordi-
nary pointwise product. These properties are the starting point of the analysis of the
Fourier transformation on the test function space S(Rn) addressed in the next section
and are deduced from the Riemann–Lebesgue lemma in a straightforward way.
Proposition 10.1
1. For f ∈L1(Rn) and a ∈Rn the translation by a is deﬁned as fa(x) = f (x−a) for
almost all x ∈Rn. These translations and the multiplication by a corresponding
exponential function are related under the Fourier transformation according to
the following formulae:
a) F(eiaxf )(p) = (Ff )a(p)
∀p ∈Rn,
b) (Ffa)(p) = eiap(Ff )(p)
∀p ∈Rn.
2. For any λ > 0 deﬁne the scaled function fλ by fλ(x) = f ( x
λ) for almost all
x ∈Rn. Then, for f ∈L1(Rn), one has
(Ffλ)(p) = λn(Ff )(p)
∀p ∈Rn.
3. For all f , g ∈L1(Rn) one has f ∗g ∈L1(Rn) and
F(f ∗g) = (2π)
n
2 (Fg) · (Fg).
4. Suppose that f ∈L1(Rn) satisﬁes xj · f ∈L1(Rn) for some j ∈{1, 2, . . . , n}.
Then the Fourier transform Ff of f is continuously differentiable with respect
to the variable pj and one has
∂
∂pj
(Ff ) (p) = F(−ixj · f )(p)
∀p ∈Rn.
5. Suppose that f ∈L1(Rn) has a derivative with respect to the variable xj which
is integrable, ∂f
∂xj ∈L1(Rn) for some j ∈{1, 2, . . . , n}. Then the following holds:
F
 ∂f
∂xj

(p) = ipj(Ff )(p)
and
|pj(Ff )(p)| ≤
----
∂f
∂xj
----
1
∀p ∈Rn.

138
10
Fourier Transformation
Proof
The proof of the ﬁrst two properties is straightforward and is done in the
Exercises.
To prove the relation for the convolution product we apply Fubini’s theorem on
the exchange of the order of integration to conclude ∥f ∗g∥1 ≤∥f ∥1 ∥g∥1 for all
f , g ∈L1(Rn), hence f ∗g ∈L1(Rn). The same theorem and the ﬁrst property
justify the following calculations for all ﬁxed p ∈Rn:
(2π)
n
2 F(f ∗g)(p) =

Rn e−ip·x(f ∗g)(x)dx
=

Rn

Rn f (x −y)g(y)dy

dx =

Rn

Rn e−ip·xf (x −y)dx

g(y)dy
= (2π)
n
2 
Rn e−ip·y(Ff )(p)g(y)dy = (2π)n(Ff )(p)(Fg)(p).
Now the third property follows easily.
In order to prove differentiability of Ff under the assumptions stated above, take
any p ∈Rn and denote by ej = (0, . . . , 0, 1, 0, . . . , 0) the standard unit vector in Rn
in coordinate direction j. By deﬁnition, for all h ∈R, h ̸= 0, we ﬁnd
(2π)
n
2 ˜f (p + hej) −˜f (p)
h
=

Rn
e−i(p+hej )·x −e−ip·x
h
f (x)dx.
For arbitrary but ﬁxed x ∈Rn we know
lim
h→0
e−i(p+hej )·x −e−ip·x
h
= −ixje−ip·x.
Furthermore, the estimate

e−i(p+hej )·x −e−ip·x
h
 ≤|xj|
∀x, p ∈Rn
is well known. Thus, a standard application of Lebesgue’s theorem of dominated
convergence implies, taking the hypothesis xjf ∈L1(Rn) into account,
lim
h→0
˜f (p + hej) −˜f (p)
h
= (2π)−n
2

Rn (−ixj)e−ip·xf (x)dx,
and we conclude
∂˜f
∂pj
(p) = F(−ixjf )(p)
∀p ∈Rn.
This partial derivative is continuous by the Riemann–Lebesgue lemma and thus the
fourth property follows.

10.1
Fourier Transformation for Integrable Functions
139
In order to prove the ﬁfth property, we start with the observation
f ∈L1(R)
and
f ′ ∈L1(R)
⇒lim
|x|→∞f (x) = 0.
This is shown in the Exercises. Now we calculate
ipj(Ff )(p) = (2π)−n
2

Rn ipje−ip·xf (x)dx = −(2π)−n
2

Rn
∂
∂xj
(e−ip·x)f (x)dx
and perform a partial integration with respect to xj. By the above observation the
boundary terms vanish under our hypotheses and thus this partial integration yields
(2π)−n
2

Rn e−ip·x ∂f
∂xj
(x)dx = F
 ∂f
∂xj

(p).
We conclude by Lemma 10.1.
2
Denote by Cb(Rn) the space of all bounded continuous functions f : Rn →C
which vanish at inﬁnity as expressed in the Riemann–Lebesgue lemma. Then this
lemma shows that the Fourier transformation F maps the space L1(Rn) into Cb(Rn).
A natural and very important question is whether this map has an inverse and what
this inverse is. In order to answer these questions some preparations are necessary.
Lemma 10.2
1. For all f , g ∈L1(Rn) the following identity holds:

Rn f (x)(Fg)(x)dx =

Rn (Ff )(y)g(y)dy.
2. Suppose f, g ∈L1(Rn) are continuous and bounded and their Fourier transforms
Ff , Fg belong to L1(Rn) too. Then one has
f (0)

Rn (Fg)(x)dx = g(0)

Rn (Ff )(y)dy.
Proof If f , g ∈L1(Rn), then the function (x, y) #→e−ix·yf (x)g(y) belongs to
L1(Rn × Rn) and thus Fubini’s theorem implies
I1 =(2π)−n
2 
Rn

Rn e−ix·yf (x)g(y)dy

dx = (2π)−n
2 
Rn

Rn e−ix·yf (x)g(y)dx dy
= (2π)−n
2 
Rn

Rn e−ix·yf (x)g(y)dx

dy = I2.
According to the deﬁnition of the Fourier transformation, we have
I1 =

Rn f (x)(Fg)(x)dx,
I2 =

Rn (Ff )(y)g(y)dy.
Thus, the identity I1 = I2 proves the ﬁrst part.

140
10
Fourier Transformation
Next apply the identity of the ﬁrst part to f , gλ ∈L1(Rn), for g ∈L1(Rn) and
gλ(y) = g( y
λ), λ > 0, to get

Rn f (x)(Fgλ)(x)dx =

Rn (Ff )(y)gλ(y)dy
∀λ > 0.
The second part of Proposition 10.1 says (Fgλ(x) = λn(Fg)(λx). This implies

Rn f (x)λn(Fg)(λx)dx =

Rn (Ff )(y)g
y
λ

dy
∀λ > 0.
Now, we use the additional assumptions on f , g to determine the limit λ →∞of
this identity. Since f is continuous and bounded and since Fg ∈L1(Rn), a sim-
ple application of Lebesgue’s dominated convergence theorem proves, by changing
variables, ξ = λx,
lim
λ→∞

Rn f (x)λn(Fg)(λx)dx = lim
λ→∞

Rn f
ξ
λ

(Fg)(ξ)dξ =

Rn f (0)(Fg)(ξ)dξ.
Similarly, the limit of the right-hand side is determined:
lim
λ→∞

Rn (Ff )(y)g
y
λ

dy =

Rn (Ff )(y)g(0)dy.
Thus the identity of the second part follows.
2
Theorem 10.1 (Inverse Fourier Transformation).
1. On L1(Rn) deﬁne a map L by
(Lf )(x) = (2π)−n
2

Rn eix·pf (p)dp
∀p ∈Rn.
This map L maps L1(Rn) into Cb(Rn) and satisﬁes
(Lf )(x) = (Ff )(−x)
∀x ∈Rn.
(10.2)
2. On the space of continuous bounded functions f such that f and Ff belong to
L1(Rn) one has
LFf = f
and
FLf = f ,
hence on this space of functions, L is the inverse of the Fourier transformation F.
Proof The proof of the ﬁrst part is obvious. For the proof of the second part, we
observe that for every x ∈Rn the translated function f−x has the same properties as
the function f and that the relation F(f−x) = ex · (Ff ) holds where ex denotes the
exponential function ex(p) = eix·p. Now apply the second part of the Lemma to the

10.2
Fourier Transformation on S(Rn)
141
function f−x and any g ∈L1(Rn) which is bounded and continuous and for which
Fg belongs to L1(Rn) to obtain
f−x(0)

Rn (Fg)(p)dp = g(0)

Rn (Ff−x)(p)dp = g(0)

Rn ex(p)(Ff )(p)dp,
or, by taking f−x(0) = f (x) into account,
f (x)

Rn (Fg)(p)dp = g(0)

Rn eix·p(Ff )(p)dp = g(0)(2π)
n
2 (L(Ff ))(x).
Next choose a special function g which satisﬁes all our hypotheses and for which
we can calculate the quantities involved explicitly: We choose for instance (x =
(x1, . . . , xn))
g(x) =
n
.
k=1
e−a|xk|
a > 0.
In the Exercises, we show I(g) =

(Fg)(p)dp = (2π)
n
2 and thus we deduce
f (x) = (L(Ff ))(x) for all x ∈Rn. With the help of the ﬁrst part the second identity
follows easily: For all p ∈Rn one has
(F(Lf ))(p)
= (2π)−n
2 
Rn e−ip·x(Lf )(x)dx
= (2π)−n
2 
Rn eip·x(Lf )(−x)dx = (L(Ff ))(p).
2
10.2
Fourier Transformation on S(Rn)
As indicated earlier our goal in this chapter is to extend the deﬁnition and the study
of the Fourier transformation on a suitable space of distributions. Certainly, this
extension has to be done in such a way that it is compatible with the embedding of
integrable functions into the space of distributions and the Fourier transformation
on integrable functions we have studied in the previous section. From the Riemann–
Lebesgue lemma it follows that ˜f = Ff ∈L1
loc(Rn) whenever f ∈L1(Rn). Thus,
the regular distribution IFf is well deﬁned. In the Exercises, we show
⟨IFf , φ⟩= ⟨If , Fφ⟩
∀φ ∈D(Rn).
If F′ denotes the Fourier transformation on distributions we want to deﬁne, the
compatibility with the embedding requires
F′If = IFf
∀f ∈L1(Rn).
Accordingly one should deﬁne F′ as follows:
⟨F′T , φ⟩= ⟨T , Fφ⟩
∀φ ∈T (Rn),
∀T ∈T ′(Rn),
(10.3)

142
10
Fourier Transformation
where T (Rn) denotes the test function space of the distribution space T ′(Rn) on
which one can deﬁne the Fourier transformation naturally.
In the Exercises, we show: If φ ∈D(Rn), φ ̸= 0, then Fφ is an entire analytic
function different from 0 and thus does not belong to D(Rn) so that the right-hand
side of Eq. (10.3) is not deﬁned in general in this case. We conclude that we cannot
deﬁne the Fourier transformation F′ naturally on D′(Rn).
Equation (10.3) also indicates that the test function space T (Rn) should have the
property that the Fourier transformation maps this space into itself and is continuous
in order that this deﬁnition be effective. In this section, we will learn that this is the
case for the test function space T (Rn) = S(Rn) and thus the space of tempered dis-
tributions becomes the natural and effective distribution space on which one studies
the Fourier transformation.
Recall that the elements of the test function space S(Rn) of strongly decreasing
C∞-functions are characterized by condition (2.10). An equivalent way is to say: A
function φ ∈C∞(Rn) belongs to S(Rn) if and only if
∀α∈Nn ∀β∈Nn ∃Cα, β∈R+ ∀x∈Rn |xβDαφ(x)| ≤Cα, β.
(10.4)
Recall furthermore that the topology on S(Rn) is deﬁned by the norms pm,l, m, l =
01, 2, . . . , where
pm,l(φ) = sup
 
(1 + x2)
m
2 |Dαφ(x)| : x ∈Rn, |α| ≤l
!
.
An easy consequence is the following invariance property of S(Rn):
φ ∈S(Rn), α, β ∈Nn ⇒xβDαφ ∈S(Rn)
and
pm,l(xβDαφ) ≤pm+|β|,l+|α|(φ).
(10.5)
In the previous section, we learned that the Fourier transformation is invertible on
a certain subspace of L1(Rn). Here we are going to show that the test function
space S(Rn) is contained in this subspace. As a ﬁrst step we observe that S(Rn) is
continuously embedded into L1(Rn) by the identity map:
S(Rn) ⊂L1(Rn),
∥φ1∥≤Cpn+1,0(φ)
∀φ ∈S(Rn).
(10.6)
Here the embedding constant C depends only on the dimension n:
C =

Rn
dx
(1 + x2)
n+1
2
.
This is shown in the Exercises.
Theorem 10.2 (Fourier Transformation on S(Rn))
1. The Fourier transformation F is an isomorphism on S(Rn), i.e., a continuous
bijective mapping with continuous inverse.

10.2
Fourier Transformation on S(Rn)
143
2. The inverse of F is the map L introduced in Eq. (10.2).
3. The following relations hold for all φ ∈S(Rn), p ∈Rn, and α ∈Nn:
a) Dα(Fφ)(p) = F((−ix)αφ)(p).
b) F(Dαφ)(p) = (ip)α(Fφ)(p).
Proof
In a ﬁrst step we show that the Fourier Transformation F is a continuous
linear map from S(Rn) into S(Rn). Take any φ ∈S(Rn) and any α, β ∈Nn. Then
we know xβDαφ ∈S(Rn) and the combination of the estimates (10.5) and (10.6)
implies
--xβDαφ
--
1 ≤Cpn+1+|β|,|α|(φ).
(10.7)
Hence, parts 4) and 5) of Proposition 10.1 can be applied repeatedly, to every order,
and thus it follows that
Dα(Fφ)(p) = F((−ix)αφ)(p)
∀p ∈Rn,
∀α ∈Nn.
We deduce Fφ ∈C∞(Rn) and relation a) of part 3) holds.
Similarly one shows for all α, β ∈Nn and all p ∈Rn,
pβDα(Fφ)(p) = pβF((−ix)αφ)(p) = F((−iD)β[(−ix)αφ])(p).
(10.8)
Choosing α = 0 in Eq. (10.8) implies relation (b) of part 3). Equation (10.8) also
implies
|pβDα(Fφ)(p)| ≤
--Dβ(xαφ)
--
1
and therefore by estimate (10.7), for all m, l = 0, 1, 2, . . . and all φ ∈S(Rn),
pm,l(Fφ) ≤Cpn+1+l,m(φ),
(10.9)
where the constant C depends only on m, n, l. This estimate implies Fφ ∈S(Rn). It
follows easily that F is linear. Hence, this estimate also implies that F is bounded
and thus continuous.
Since we know (Lφ)(p) = (Fφ)(−p) on S(Rn), it follows that the map L has the
same properties as F. The estimate above shows in addition that S(Rn) is contained
in the subspace of L1(Rn) on which F is invertible. We conclude that the continuous
linear map L on S(Rn) is the inverse of the Fourier transformation on this space.
This concludes the proof of the theorem.
2
On the test function space S(Rn) we have introduced two products, the standard
pointwise product and the convolution product. As one would expect on the basis
of part 3) of Proposition 10.1 the Fourier transformation transforms the convolution
product into the pointwise product and conversely. More precisely we have the
following.

144
10
Fourier Transformation
Corollary 10.1
1. The Fourier transformation F and its inverse L are related on S(Rn) as follows,
u ∈S(Rn):
Lu = F ˇu = (Fu)ˇ
LFu = FLu = u
FFu = ˇu = LLu,
where ˇu(x) = u(−x) for all x ∈Rn.
2. For all φ, ψ ∈S(Rn) the following relations hold:
F(φ ∗ψ) = (2π)
n
2 (Fφ) · (Fψ),
F(φ · ψ) = (2π)−n
2 (Fφ) ∗(Fψ).
Proof The ﬁrst identity in the ﬁrst part is immediate from the deﬁnitions of the maps
involved. The second repeats the fact that L is the inverse of F, on S(Rn). The third
identity is a straightforward consequence of the ﬁrst two.
In order to prove the second part, recall that by part 3) of Proposition 10.1 the ﬁrst
identity is known for functions in L1(Rn), and we know that S(Rn) is continuously
embedded into L1(Rn). Furthermore, we know from Proposition 7.3 that φ ∗ψ ∈
S(Rn). This proves that the ﬁrst identity is actually an identity in S(Rn) and not only
in L1(Rn).
Now replace in the ﬁrst identity of the second part the function φ with Lφ and
the function ψ with Lψ to obtain F((Lφ) ∗(Lψ)) = (2π)
n
2 (F(Lφ)) · (F(Lψ)) =
(2π)
n
2 φ · ψ. It follows that F(φ · ψ) = (2π)−n
2 F(F((Lφ) ∗(Lψ))) and thus, tak-
ing the ﬁrst part into account = (2π)−n
2 ((Lφ) ∗(Lψ))ˇ = (2π)−n
2 (Lφ)ˇ ∗(Lψ)ˇ =
(2π)−n
2 (Fφ) ∗(Fψ), hence F(φ · ψ) = (2π)−n
2 Fφ ∗Fψ.
2
10.3
Fourier Transformation for Tempered Distributions
According to the previous section the Fourier transformation is an isomorphism of
the test function space S(Rn), hence it can be extended to the space of tempered
distributions S′(Rn) by the standard duality method. After the formal deﬁnition has
been given we look at some simple examples to illustrate how this deﬁnition works
in practice. Then several important general results about the Fourier transformation
on S′(Rn) are discussed.
Deﬁnition 10.1 The Fourier transform ˜T = F′T of a tempered distribution T ∈
S′(Rn) is deﬁned by the relation
⟨F′T , φ⟩= ⟨T , Fφ⟩
∀φ ∈S(Rn).
(10.10)

10.3
Fourier Transformation for Tempered Distributions
145
Example 10.2
1. Dirac’s delta distribution is obviously tempered and thus it has a Fourier transform
according to the deﬁnition given above. The actual calculation is very simple: For
all φ ∈S(Rn) one has
⟨F′δ, φ⟩= ⟨δ, Fφ⟩= (Fφ)(0) = (2π)−n
2

Rn φ(x)dx = (2π)−n
2 ⟨I1, φ⟩,
hence
F′δ = (2π)−n
2 I1,
i.e., the Fourier transform of Dirac’s delta distribution is the constant distribution.
This is often written as F′δ = (2π)−n
2 .
2. Next we calculate the Fourier transform of a constant distribution Ic, c ∈C.
According to the previous example we expect it to be proportional to Dirac’s
delta distribution. Indeed one ﬁnds for all φ ∈S(Rn),
⟨F′Ic, φ⟩= ⟨Ic, Fφ⟩=

Rn c(Fφ)(p)dp = c(2π)
n
2 (LFφ)(0)
= c(2π)
n
2 φ(0) = ⟨c(2π)
n
2 δ, φ⟩,
i.e.,
F′Ic = c(2π)
n
2 δ.
3. Another simple example of a tempered distribution is the Heaviside function θ.
It certainly has no Fourier transform in the classical sense. We determine here its
Fourier transform in the sense of tempered distributions. The calculations contain
a new element, namely a suitable limit procedure. For all φ ∈S(R) we ﬁnd
F′θ, φ⟩= ⟨θ, Fφ⟩=
 ∞
0
(Fφ)(p)dp =
lim
r→0, r>0
 ∞
0
e−rp(Fφ)(p)dp.
For ﬁxed r > 0 we apply Fubini’s theorem to exchange the order of integration
so that one of the integrals can be calculated explicitly. The result is
 ∞
0 e−rp(Fφ)(p)dp =
 ∞
0 e−rp  +∞
−∞e−ip·xφ(x) dx
√
2π

dp,
 +∞
−∞φ(x)
 ∞
0 e−rp−ipxdp

dx
√
2π = (2π)−1
2 
R
i
x−ir φ(x)dx,
hence
(F′θ)(x) =
lim
r→o, r>0
i
√
2π
1
x −ir ≡
i
√
2π
1
x −io.
By duality the properties of the Fourier transformation on S(Rn) as expressed in
Theorem 10.2 are easily translated into similar properties of the Fourier transforma-
tion on the space of tempered distributions S′(Rn).
Theorem 10.3 (Fourier Transformation on S′(Rn))
1. The Fourier transformation F′ is an isomorphism of S′(Rn). It is compatible with
the embedding of integrable functions: For all f ∈L1(Rn) we have
F′If = IFf .

146
10
Fourier Transformation
2. The inverse of F′ is the dual L′ of the inverse L of F, i.e., F′−1 = L′.
3. The following rules hold, α ∈Nn:
F′(Dα
x T )(p) = (ip)α(F′T )(p),
Dα
p(F′T )(p) = F′((−ix)αT)(p).
Proof In the Exercises, we show: if I is an isomorphism of the HLCTVS E, then its
dual I ′ is an isomorphism of the topological dual space E′ equipped with the topology
of pointwise convergence (weak topology σ). Thus, we deduce from Theorem 10.2
that F′ is an isomorphism of S′(Rn).
Next consider any f ∈L1(Rn). We know that its Fourier transform Ff is a
bounded continuous and thus locally integrable function which deﬁnes the tempered
distribution IFf . For all φ ∈S(Rn) a simple application of Fubini’s theorem shows
that
⟨F′If , φ⟩= ⟨If , Fφ⟩=

Rn f (x)(Fφ)(x)dx =

Rn f (x)

Rn e−ix·pφ(p)
dp
(2π)
n
2

dx
=

Rn

Rn f (x)e−ip·x
dp
(2π)
n
2

φ(p)dp =

Rn (Ff )(p)φ(p)dp = ⟨IFf , φ⟩.
This implies compatibility of the Fourier transformations on L1(Rn) and on S′(Rn)
and thus part 1) has been shown.
In order to prove part 2) take any T ∈S′(Rn) and calculate for all φ ∈S(Rn) using
Theorem 10.2 ⟨L′F′T , φ⟩= ⟨F′T , Lφ⟩= ⟨T , FLφ⟩= ⟨T , φ⟩, thus L′F′ = id. It
follows that L′ is the inverse of F′.
Finally, we establish the rules of part 3) relying on the corresponding rules as
stated in Theorem 10.2: Take any T ∈S′(Rn) and any φ ∈S(Rn) and use the
deﬁnitions, respectively, the established rules, to get
⟨F′(Dα
x T ), φ⟩= ⟨Dα
x T , Fφ⟩= (−1)|α|⟨T , Dα
x (Fφ)⟩
= (−1)|α|⟨T , F((−ip)αφ)⟩= ⟨F′T , (ip)αφ⟩= ⟨(ip)αFT , φ⟩.
Since this identity holds for every φ ∈S(Rn) the ﬁrst relation is proven. Similarly
we proceed with the second.
⟨Dα
p(F′T ), φ⟩= (−1)|α|⟨F′T , Dα
pφ⟩= (−1)|α|⟨T , F(Dα
pφ)⟩
= (−1)|α|⟨T , (ix)αFφ⟩= ⟨(−ix)αT , Fφ⟩= ⟨F′((−ix)αT ), φ⟩.
2
As a simple illustration of the rules in part 3) we mention the following. Apply the
ﬁrst rule to Dirac’s delta distribution. Recalling the relation F′δ = (2π)−n
2 we get
F′(Dαδ)(p) = (2π)−n
2 (ip)α.
(10.11)
Similarly, applying the second rule to the constant distribution T = I1 produces the
relation
F′((−ix)α)(p) = (2π)
n
2 Dαδ(p).
(10.12)

10.3
Fourier Transformation for Tempered Distributions
147
Certainly, these convenient rules have no counterpart in the classical theory of
Fourier transformation. Further applications are discussed in the Exercises.
In Corollary 10.1, we learned that the Fourier transformation F transforms a
convolution of test functions φ, ψ into a pointwise product: F(φ∗ψ) = (2π)
n
2 (Fφ)·
(Fψ). Since we have also learned that the convolution and the pointwise product of
distributions is naturally deﬁned only in special cases, we cannot expect this relation
to hold for distributions in general. However, there is an important class for which one
can show this relation to hold for distributions too: One distribution is tempered and
the other has a compact support. As preparation we show that the Fourier transform
of a distribution of compact support is a multiplier for tempered distributions, i.e., a
C-function with polynomially bounded derivatives.
To begin we note
Lemma 10.3
For p ∈Rn deﬁne a function ep : Rn →C by ep(x) =
e−ip·x
(2π)
n
2 .
Suppose T ∈D′(Rn) is a distribution with support contained in the compact set
K ⊂Rn. For any function u ∈D(Rn) deﬁne a function Tu : Rn →C by
Tu(p) = ⟨T , ep · u⟩
∀p ∈Rn.
Then the following holds.
1. Tu ∈Om(Rn), i.e., Tu is a C∞-function with polynomially bounded derivatives.
2. If u, v ∈D(Rn) satisfy u(x) = v(x) = 1 for all x ∈K, then Tu = Tv.
Proof
Since for each p ∈Rn the function ep · u belongs to D(Rn) if u does, the
function Tu is well deﬁned for u ∈D(Rn). As in Theorem 7.1 it follows that Tu is a
C∞-function and
DαTu(p) = ⟨T , Dα
p(ep · u)⟩= ⟨T , ep · (−ix)α · u⟩
∀α ∈Nn.
Since T has its support in the compact set K, there are m ∈N and a constant C such
that |⟨T , φ⟩| ≤CpK,m(φ) for all φ ∈DK(Rn). It follows that, for all p ∈Rn,
|DαTu(p)| ≤CpK,m(ep · (−ix)α · u).
(10.13)
As we show in the Exercises, the right-hand side of this inequality is a polynomially
bounded function of p ∈Rn. It follows that Tu ∈Om(Rn). This proves the ﬁrst part.
If two functions u, v ∈D(Rn) are equal to 1 on K, then, for every p ∈Rn, the
function ep · (u −v) vanishes on a neighborhood of the support of the distribution T
and hence ⟨T , ep · (u −v)⟩= 0. Linearity of T implies Tu = Tv.
2
Theorem 10.4
A distribution T ∈D′(Rn) of compact support is tempered and its
Fourier transform ˜T = F′(T ) is a C∞-function such that all derivatives Dα ˜T (p) are
polynomially bounded, i.e., ˜T ∈Om(Rn) (see also Proposition 4.3).
Proof A distribution T with compact support is an element of the dual E′(Rn) of
the test function space E(Rn), according to Theorem 3.6. Since S(Rn) ⊂E(Rn) with

148
10
Fourier Transformation
continuous identity map, it follows that E′(Rn) ⊂S′(Rn). Therefore, a distribution
with compact support is tempered and thus has a well-deﬁned Fourier transform.
Suppose T ∈D′(Rn) has its support in the compact set K ⊂Rn. Choose any
u ∈D(Rn) with the property u(x) = 1 for all x ∈K and deﬁne the function Tu as in
the previous lemma. It follows that Tu ∈Om(Rn) and we claim
F′T = ITu,
i.e., for all φ ∈S(Rn),
⟨F′T , φ⟩=

Rn Tu(p)φ(p)dp.
According to the speciﬁcation of u we know
⟨u · T , Fφ⟩= ⟨T , Fφ⟩= ⟨F′T , φ⟩.
Now observe Fφ(x) =

Rn ep(x)φ(p)dp and thus
⟨u · T , Fφ⟩= ⟨(u · T )(x),

Rn ep(x)φ(p)dp⟩= ⟨T (x), u(x)

Rn ep(x)φ(p)dp⟩
=

Rn⟨T (x), u(x)ep(x)⟩φ(p)dp =

Rn Tu(p)φ(p)dp.
In the second but last step we used Eq. (7.6). This gives ⟨F′T , φ⟩=

Rn Tu(p)φ(p)dp
for all φ ∈S(Rn) and thus proves F′T = Tu. The previous lemma now gives the
conclusion.
2
As further preparation we present a result which is also of considerable interest
in itself since it controls the convolution of distributions, in S′(Rn) and in E′(Rn),
with test functions in S(Rn).
Proposition 10.2
The convolution of a tempered distribution T ∈S′(Rn) with a
test function ψ ∈S(Rn) is a tempered distribution T ∗ψ which has the Fourier
transform
F′(T ∗ψ) = (2π)
n
2 (F′T ) · (Fψ).
In particular, if T ∈E′(Rn), then T ∗ψ ∈S(Rn).
Proof The convolution T ∗ψ is deﬁned by
⟨T ∗ψ, φ⟩= ⟨T , ˇψ ∗φ⟩
∀φ ∈S(Rn).
Since we have learned that, for ﬁxed ψ ∈S(Rn), φ #→ˇψ ∗φ is a continuous linear
map from S(Rn) into itself (see Proposition 7.3) it follows that T ∗ψ is well deﬁned
as a tempered distribution. For its Fourier transform we ﬁnd, using Corollary 10.1

10.3
Fourier Transformation for Tempered Distributions
149
and Theorem 10.3,
⟨F′(T ∗ψ), φ⟩
= ⟨T ∗ψ, Fφ⟩= ⟨T , ˇψ ∗φ⟩
= ⟨F′T , L( ˇψ ∗Fφ)⟩= (2π)
n
2 ⟨F′T , L( ˇψ) · (LFφ)⟩
= (2π)
n
2 ⟨F′T , (Fψ) · φ⟩= (2π)
n
2 ⟨(Fψ) · (F′T ), φ⟩.
This implies
F′(T ∗ψ) = (2π)
n
2 (F′T ) · (Fψ)
∀T ∈S′(Rn), ∀ψ ∈S(Rn).
If T ∈E′(Rn), then F′T ∈Om(Rn) byTheorem 10.4 and thus (F′T )·(Fψ) ∈S(Rn),
hence F′(T ∗ψ) = F(T ∗ψ) ∈S(Rn).
2
Theorem 10.5 (Convolution Theorem) The convolution T ∗S of a tempered distri-
bution T ∈S′(Rn) and a compactly supported distribution S ∈E′(Rn) is a tempered
distribution whose Fourier transform is
F′(T ∗S) = (2π)
n
2 (F′T ) · (F′S).
(10.14)
Proof Since S ∈E′(Rn) Proposition 10.2 ensures that
x #→⟨S(y), φ(x + y)⟨= ( ˇS ∗φ)(x)
belongs to S(Rn) for every φ ∈S(Rn). Using Corollary 10.1 we calculate its inverse
Fourier transform:
L( ˇS ∗φ) = (2π)
n
2 (F′S) · (Lφ)
with F′S ∈Om(Rn) according to Theorem 10.4. Observe now that the deﬁnition of
the convolution of two distributions can be rewritten as ⟨T ∗S, φ⟩= ⟨T , ˇS ∗φ⟩, for
all φ ∈S(Rn). Hence, T ∗S is a well-deﬁned tempered distribution.
The inverse of F′ is L′. This implies
⟨T ∗S, φ⟩= ⟨F′T , L( ˇS ∗φ)⟩= (2π)
n
2 ⟨F′T , (F′S) · Lφ⟩
= (2π)
n
2 ⟨(F′S) · (F′T ), Lφ⟩
and therefore T ∗S = (2π)
n
2 L′((F′S) · (FT )). Now Eq. (10.14) follows and we
conclude.
2
Naturally one would like to extend the above convolution theorem to the case of
two tempered distributions, both not having a compact support. Then, in addition to
the problem of the existence of the convolution as a tempered distribution, one has
to solve the problem of multiplication of two tempered distributions. In analogy to
what we learned about the convolution in the space D′
+(R) of distributions on R with
support in [0, ∞) we formulate the following result which has many applications, in
particular in mathematical physics.

150
10
Fourier Transformation
Theorem 10.6 (Generalized Convolution Theorem) Let Γ ⊂Rn be a closed
convex cone such that x · y ≥0 for all x, y ∈Γ and denote by S′
Γ (Rn) the space of
all tempered distributions on Rn with support in Γ. Then the following holds.
1. For all T , S ∈S′
Γ (Rn) the convolution product T ∗S is a well-deﬁned element in
S′
Γ (Rn).
2. The product (FT )·(FS) is well deﬁned as a distribution in S′(Rn) by the Formula
(10.14)
(F′T ) · (F′S) = (2π)−n
2 F′(T ∗S).
(10.15)
Proof
According to Corollary 5.2, given T , S ∈S′
Γ (Rn), there are continuous
functions t, s with support in Γ , satisfying

|t(x)|(1 + x2)−m/2dx = C1 < ∞,
respectively,

|s(x)|(1 + x2)−k/2dx = C2 < ∞for some m, k ∈N, and some
multi-indices α, β such that T = (−1)|α|Dα t, respectively, S = (−1)|β|Dβ s.
Now for all φ ∈S(Rn) we estimate as follows using DαDβφ = φ(α+β)
|⟨T ⊗S(x, y), φ(x + y)⟩| =


Γ

Γ
t(x)s(y)φ(α+β)(x + y)dx dy

=


Γ

Γ
t(x)(1 + x2)−m/2s(y)(1 + y2)−k/2(1 + x2)m/2s(y)(1 + y2)k/2φ(α+β)(x + y)dx dy

≤

Γ
|t(x)|(1 + x2)−m/2dx

Γ
|s(y)|(1 + y2)−k/2dy
×sup(x,y)∈Γ ×Γ (1 + x2)m/2(1 + y2)k/2|φ(α+β)(x + y)| .
Since φ belongs to S(Rn) we know
|φ(x + y)| ≤pM,l(φ)(1 + (x + y)2)−M/2
for l = |α + β| and M = 1, 2, . . . . The assumed properties of the cone Γ imply that
for (x, y) ∈Γ × Γ one has 1 + x2 ≤1 + (x + y)2 and 1 + y2 ≤1 + (x + y)2 and
therefore on Γ × Γ
(1 + (x + y)2)−M/2 ≤(1 + x2)−M/4(1 + y2))−M/4 .
Now choose M ≥2max {m, k} so that m/2 ≤M/4 and k/2 ≤M/4 and the above
supremum over Γ × Γ is ﬁnite and estimated by CpM,l(φ) with a suitable constant
C. We conclude
|⟨T ⊗S(x, y), (φ)(x + y)⟩| ≤CC1C2pM,l(φ)
for all φ ∈S(Rn) and thus the convolution T ∗S is well deﬁned as a tempered
distribution by the standard formula
T ∗S(φ) = ⟨T ⊗S(x, y), (φ)(x + y)⟩.
This formula also shows that T ∗S has its support in Γ . Since the Fourier transform
is an isomorphism of the space of tempered distributions the second statement
follows immediately from the ﬁrst.
2

10.3
Fourier Transformation for Tempered Distributions
151
Remark 10.2
1. If a cone Γ satisﬁes our hypothesis, then the cone −Γ satisﬁes this condition
too. The light cone V + = {(x0, x) ∈R × Rn−1 : x0 ≥|x|} of physics certainly
satisﬁes our condition.
2. Given distributions T , S ∈S′
Γ (Rn) one can approximate S for instance by dis-
tributions SR = χRS of compact support by using a sequence of smooth cut-off
functions χR ∈D(Rn) such that χR(x) = 1 for all x with |x| ≤R. The convolu-
tion theorem applies to the pair (T , SR). The proof of the generalized convolution
theorem can be extended to show that the limit
lim
R→∞T ∗SR
exists in S′
Γ (Rn). Since the Fourier transform F′ of tempered distributions is
continuous it follows that the limit
lim
R→∞F′(T ) · F′(SR)
exists in S′(Rn).
We started the study of the Fourier transformation on the space L1(Rn). We found
that the domain and the range of F are not symmetric. However, when we restricted
F to the test function space S(Rn) we could prove that the domain and the range are
the same; actually we found that F is an isomorphism of topological vector spaces
and used this to extend the deﬁnition of the Fourier transformation to the space
of all tempered distributions S′(Rn), using duality. Certainly, the space L1(Rn) is
contained in S′(Rn), in the sense of the embedding L1(Rn) ∋f #→If ∈S′(Rn). In
this sense there are many other function spaces contained in S′(Rn), for instance the
space L2(Rn) of (equivalence classes of) square integrable functions which is known
to be a Hilbert space with inner product
⟨f , g⟩2 =

Rn f (x)g(x)dx
∀f , g ∈L2(Rn).
ThisisdiscussedinSect.14.1. TherewealsolearnthatthetestfunctionspaceS(Rn)is
dense in L2(Rn). Since L2(Rn) is ‘contained’in S′(Rn), the restriction of the Fourier
transformation F′ to L2(Rn) gives a deﬁnition of the Fourier transformation on
L2(Rn). More precisely this means the following: Denote the Fourier transformation
on L2(Rn) by F2; it is deﬁned by the identity
F′If = IF2f
∀f ∈L2(Rn).
In order to get a more concrete representation of F2 and to study some of its properties
we use our results on the Fourier transform on S(Rn) and combine them with Hilbert
space methods as developed in part II.

152
10
Fourier Transformation
To begin we show that the restriction of the inner product of L2(Rn) to S(Rn) is
invariant under F. First we observe that for all φ, ψ ∈S(Rn) one has
⟨Fφ, Fψ⟩2 = ⟨I1, Fφ · Fψ⟩.
Express the complex conjugate of the Fourier transform of φ as Fφ = L(φ) = F(ˇφ)
and apply Corollary 10.1 to get Fφ · Fψ = (2π)−n
2 F(ˇφ ∗ψ). It follows that, using
F′I1 = (2π)
n
2 δ, ⟨Fφ, Fψ⟩2 = ⟨I1, (2π)−n
2 F(ˇφ ∗ψ)⟩= ⟨(2π)−n
2 F′I1, ˇφ ∗ψ⟩=
⟨δ, ˇφ∗ψ⟩= (ˇφ∗ψ)(0) =

Rn φ(x)ψ(x)dx = ⟨φ, ψ⟩2, and thus we get the announced
invariance
⟨Fφ, Fψ⟩2 = ⟨φ, ψ⟩2
∀φ, ψ ∈S(Rn).
This nearly proves
Theorem 10.7 (Plancherel) The Fourier transformation F2 on L2(Rn) can be ob-
tained as follows: Given any f ∈L2(Rn) choose a sequence (uj)j∈N in S(Rn) which
converges to f (in L2(Rn)). Then the sequence (Fuj)j∈N is a Cauchy sequence in
L2(Rn) which thus converges to some element g ∈L2(Rn) which deﬁnes F2f , i.e.,
F2f = lim
j→∞Fuj.
F2 is a well-deﬁned unitary map of the Hilbert space L2(Rn).
Proof Since we know that S(Rn) is dense in L2(Rn) and that the inner product ⟨·, ·⟩2
is invariant under the Fourier transformation F on S(Rn), this follows easily from
Proposition 23.3.
2
The relation of the Fourier transformation on the various spaces can be summa-
rized by the following diagram:
All maps in the diagram are continuous and linear. F2 is unitary.
Remark 10.3 The fact that the Fourier transformation F2 is a unitary map of the
Hilbert space L2(Rn) is of particular importance to the quantum mechanics of local-
ized systems since it allows us to pass from the coordinate representation L2(R2
x) of
thestatespacetothemomentumrepresentation L2(Rn
p)withoutchangingexpectation
values.

10.4
Some Applications
153
Corollary 10.2 (Fourier Uncertainty Principle) For f ∈L2(R) with xf ∈L2(R)
and f ′ ∈L2(R) one has
1
2∥f ∥2
2 ≤∥pFf ∥2∥xf ∥2
(10.16)
with equality if f is a Gaussian, i.e., f (x) = ce−a2x2 with some nonzero constants
a, c.
Proof Write |f (x)| =
√
1 + x2|f (x)|×1/
√
1 + x2 and apply the Cauchy–Schwarz
inequality to conclude that xf ∈L2(Rn) implies f ∈L1(Rn). Thus, F2(f ) = F(f )
is a continuous function which vanishes at inﬁnity (Riemann–Lebesgue Lemma).
Similarly, the relation pF(f )(p) = −iF(f )(p) and the assumption f ′ ∈L2(Rn)
imply that pF(f )(p) is a continuous function which vanishes at inﬁnity. It follows
that the boundary term generated by partial integration in the following integral
vanishes and we get, using the abbreviation Dp =
d
dp

R
pDp|F(f )(p)|2dp = −

R
|F(f )(p)|2dp .
An elementary calculation shows

R
pDp|F(f )(p)|2dp = 2ℜ⟨pF(f ), Dp(F(f ))⟩2
and thus by Plancherel’s Theorem
∥f ∥2
2 = ∥F(f )∥2
2 = −2ℜ⟨pF(f ), Dp(F(f ))⟩2 .
The right-hand side is estimated by ∥pF(f )∥2∥Dp(F(f ))∥2 where we used Cauchy–
Schwarz inequality, and therefore, since Dp(F(f )) = F(−ixf ) we get all together,
using again Plancherels Theorem
∥f ∥2
2 ≤2∥pF(f )∥2∥Dp(F(f ))∥2 = ∥pF(f )2∥xf ∥2
which is (10.16).
2
10.4
Some Applications
This section deals with several aspects of the solution theory for linear partial differ-
ential operators with constant coefﬁcients in the framework of tempered distributions,
which arise from the fact that for tempered distributions the Fourier transformation
is available. The results will be considerably stronger.
Central to the solution theory for linear partial differential operators with con-
stant coefﬁcients in the space of tempered distributions is the following result by L.
Hörmander, see reference [7].

154
10
Fourier Transformation
Theorem 10.8 (L. Hörmander) Suppose P is a polynomial in n variables with
complex coefﬁcients, P ̸= 0. Then the following holds:
a) For every T ∈S′(Rn) there is an S ∈S′(Rn) such that
P · S = T.
b) If the polynomial P has no real roots, then the equation P · S = T has exactly
one solution S.
The proof of this core result is far beyond the scope of our elementary introduction,
and we have to refer to the book [7]. But we would like to give a few comments
indicating the difﬁculties involved.
Introduce the set of roots or zeros of the polynomial:
N(P) =

x ∈Rn : P(x) = 0

.
If the polynomial P has no real roots, then it is easy to see that 1
P belongs to the
multiplier space Om(Rn) of tempered distributions and thus the equation P · S = T
has the unique solution S = 1
P · T .
But we know that in general N(P) is not empty. In the case of one variable N(P)
is a discrete set (see the fundamental theorem of algebra, Corollary 9.4). For n ≥2
the set of roots of a polynomial can be a fairly complicated set embedded in Rn; in
some cases it is a differentiable manifold of various dimensions, in other cases it is
more complicated than a differentiable manifold. In the Exercises we consider some
examples.
On the set Rn\N(P) the solution S has to be of the form 1
P · T , in some way. But
1
P can fail to be locally integrable. Accordingly the problem is: deﬁne a distribution
[ 1
P ] ∈S′(Rn) with the properties
P ·
 1
P

= I1
and the product of the two tempered distributions
 1
P

· T
is a well-deﬁned tempered distribution.
As an illustration we look at the simplest nontrivial case, i.e., n = 1 and P(x) = x.
In the section on the convergence of sequences of distributions we have already
encountered tempered distributions [ 1
P ] which satisfy x · [ 1
P ] = 1, namely the
distributions
1
x ± io,
vp 1
x .
Then, given T ∈S′(R), it is not clear whether we can multiply T with these
distributions. Hörmander’s theorem resolves this problem.

10.4
Some Applications
155
Naturally, in the general case where the structure of the set of roots of P is much
more complicated these two steps are much more involved. There are a number of
important consequences of Hörmander’s theorem.
Corollary 10.3
Suppose that P(D) = 
|α|≤N aαDα, aα ∈C is a constant
coefﬁcient partial differential operator, P ̸= 0. Then the following holds.
a) P (D) has a tempered elementary solution EP ∈S′(Rn)
b) If P (ix) has no real roots, then there is exactly one tempered elementary
solution EP
c) For every T ∈S′(Rn) there is an S ∈S′(Rn) such that
P(D)S = T ,
i.e., every linear partial differential equation with constant coefﬁcients P(D)S =
T , T ∈S′(Rn), has at least one tempered solution
Proof We discuss only the easy part of the proof. For S ∈S′(Rn) we calculate ﬁrst
F′(P(D)S) =

|α|≤N
aαF′(DαS) =

|α|≤N
aα(ip)αF′S,
where in the last step we used the third part of Theorem 10.3. This implies: given T ∈
S′(RN), a distribution S ∈S′(Rn) solves the partial differential equation P(D)S = T
if, and only if, ˜S = F′S solves the algebraic equation
P(ip) ˜S = ˜T
with ˜T = F′T . Now recall F′δ = (2π)−n
2 I1. According to Theorem 10.8 there is
[
1
P (ip)] ∈S′(Rn) such that P(ip)[
1
P(ip)] = (2π)−n
2 I1 and [
1
P(ip)] is unique if P(ip)
has no real roots. By applying the inverse Fourier transformation we deduce that a
(exactly one) tempered elementary solution
EP = L′

1
P(ip)

exists. This proves parts a) and b). For the proof of the third part we have to refer
to Hörmander. In many cases one can ﬁnd a tempered elementary solution EP such
that the convolution product EP ∗T exists. Then a solution is
S = EP ∗T.
As we know this is certainly the case if T has compact support.
2
10.4.1
Examples of Tempered Elementary Solutions
For several simple partial differential operators with constant coefﬁcients, which
play an important role in physics, we calculate the tempered elementary solution
explicitly.

156
10
Fourier Transformation
10.4.1.1
The Laplace Operator △3 in R3
A fundamental solution E3 for the Laplace operator △3 satisﬁes the equation △3E3 =
δ. By taking the Fourier transform of this equation −p2F′E3 = F′δ = (2π)−n
2 I1,
we ﬁnd
F′E3(p) = (2π)
3
2 −1
p2 ,
p2 = p2
1 + p2
2 + p2
3.
Since p #→
1
p2 is locally integrable on R3, F′E3 is a regular distribution and its
inverse Fourier transform can be calculated explicitly. For φ ∈S(R3) we proceed as
follows:
⟨E3, φ⟩= ⟨F′E3, Lφ⟩=
−1
(2π)3

R3
1
p2

R3 eip·xφ(x)dx

dp
=
−1
(2π)3 limR→∞

|p|≤R
1
p2

R3 eip·xφ(x)dx

dp
=
−1
(2π)3 limR→∞

R3

|p|≤R
eip·xdp
p2

φ(x)dx
=
−1
(2π)3 limR→∞

R3
 R
0 2π
 π
0 sin θ ei|x|ρ cos θ
ρ2
ρ2dρ dθ

φ(x)dx
=
−1
(2π)2 limR→∞

R3
 R
0
ei|x|ρ−e−i|x|ρ
i|x|ρ
dρ

φ(x)dx
=
−1
(2π)2

R3
 ∞
0
eiλ−e−iλ
iλ
dλ

φ(x)
|x| dx.
The exchange of the order of integration is justiﬁed by Fubini’s theorem. Recalling
the integral
 ∞
0
eiλ −e−iλ
iλ
dλ = 2
 ∞
0
sin λ
λ dλ = 2π
2 = π
we thus get
⟨E3, φ⟩= −1
4π

R3
φ(x)
|x| dx
i.e.,
E3(x) = −
1
4π|x|.
10.4.1.2
Helmholtz’ Differential Operator △3 −μ2
Again, by Fourier transformation the partial differential equation for the fundamental
solution EH of this operator is transformed into an algebraic equation for the Fourier
transform: (△3 −λ)EH = δ implies (−p2 −λ) ˜E(p) = (2π)−3
2 with ˜E = F′EH.
Hence for λ = μ2 > 0 one ﬁnds that P(ip) = −(p2 +μ2) has no real roots and thus
the division problem has a simple unique solution
˜E(p) =
−1
(2π)
3
2
1
p2 + μ2 ∈L1
loc(R3).
The unique (tempered) fundamental solution of Helmholtz’ operator thus is, for all
x ∈R3\ {0},
EH(x) = L ˜E(x) =
−1
(2π)32

R3
eip·x
p2 + μ2 dp = −1
4π
e−|μ||x|
|x|
.
The details of this calculation are given in the Exercises.

10.4
Some Applications
157
10.4.1.3
The Wave Operator 24 in R4
In Proposition 8.5, it was shown that the distribution
Er(x0, x) = 1
2π θ(x0)δ(x2
0 −x2)
is an elementary solution of the wave operator. Here we illustrate the use of the
Fourier transformation to prove this fact, in the case of a partial differential operator
with more than one elementary solution.
It is a simple calculation to show that the assignment
S(R4) ∋φ #→1
2π

R3 φ(|x|, x) d3x
2|x| ≡⟨Er, φ⟩
deﬁnes a tempered distribution on R4. For any φ ∈S(R4), we calculate
⟨F′Er, φ⟩= ⟨Er, Fφ⟩= 1
2π

R3 (Fφ)(|x|, x) d3x
2|x|
and observe that this integral equals
1
4π lim
t↓0

R3 e−t|x|(Fφ)(|x|, x)d3x
|x| = lim
t↓0

R4 It(p0, p)φ(p0, p)dp0d3p,
where for t > 0
It(p0, p)
=
1
(2π)2

R3 e−i|x|(p0−it)−ip·x d3x
4π|x|
=
1
(2π)2
1
2|p|

1
p0+|p|−it −
1
p0−|p|−it

=
1
(2π)2
−1
(p0−it)2−|p|2 .
Since an elementary solution E of 24 satisﬁes 24E = (∂2
0 −Δ3)E = δ where
∂0 =
∂
∂x0 , its Fourier transform ˜E satisﬁes
(−p2
0 + p2) ˜E(p0, p) = (2π)−2I1.
The
polynomial
P(p0, p)
=
−p2
0
+
p2
vanishes
on
the
cone

(p0, p) ∈R4 : p0 = ±|p|

and therefore, by Hörmander’s results (Corollary
10.4.1) one expects that the wave operator has more than one elementary solution
according to the different possibilities to deﬁne
1
P as a tempered distribution.
Standard choices are
 1
P

±
= lim
t↓0
−1
(p0 ± it)2 −p2 = lim
t↓0
1
2|p|

1
(p0 ± it) + |p| −
1
(p0 ± it) −|p|

.
(10.17)

158
10
Fourier Transformation
And with the above expression for It(p0, p) we ﬁnd that Er corresponds to the choice
of the minus sign in (10.17), since
⟨(−p2
0 + p2)F′Er, φ⟩= ⟨F′Er, (−p2
0 + p2)φ⟩
= limt↓0

R4 It(p0, p)(−p2
0 + p2)φ(p0, p)dp0d3p
= (2π)−2 
R4 φ(p0, p)dp0d3p = (2π)−2⟨I1, φ⟩= ⟨F′δ, φ⟩,
and thus indeed 24Er = δ.
10.4.1.4
Operator of Heat Conduction, Heat Equation
Suppose E(t, x) ∈S′(Rn+1) satisﬁes the partial differential equation
(∂t −△n)E = δ,
where ∂t =
∂
∂t , i.e., E is an elementary solution of the differential operator of heat
conduction. Per Fourier transform one obtains the algebraic equation
(ip0 + p2)(F′E)(p0, p) = (2π)−n+1
2 I1
p0 ∈R,
p ∈Rn.
Since
1
ip0+p2 ∈L1
loc(Rn+1), the solution of this equation is the regular distribution
given by the function
˜E(p0, p) = (2π)−n+1
2 (ip0 + p2)−1.
Now consider the function
E(t, x) = θ(t)(4πt)−n
2 e−x2
4t
t ∈R,
x ∈Rn.
Its Fourier transform is easily calculated (in the sense of functions).
(FE)(p0, p)
= (2π)−n+1
2 (4π)−n
2  ∞
0

Rn e−ip0te−ip·xt−n
2 e−x2
4t dxdt
= (2π)−n+1
2 (4π)−n
2  ∞
0 e−ip0tt−n
2 (4πt)
n
2 e−tp2dt
= (2π)−n+1
2
1
ip0+p2 .
We conclude that E is a tempered elementary solution of the operator ∂t −△n.
10.4.1.5
Free Schrödinger Operator in Rn
The partial differential operator
i ∂
∂t −△n
is called the free Schrödinger operator of dimension n. In the Exercises it is shown
that the function
ES(t, x) = θ(t)(4πit)−n
2 e−x2
4it
deﬁnes a tempered distribution which solves the equation (i ∂
∂t −△n)ES = δ in
S′(Rn+1+) and therefore it is a tempered elementary solution.

10.4
Some Applications
159
Other examples of elementary solutions and Green functions are given in the
book [2].
10.4.1.6
Some Comments
There is an important difference in the behaviour of solutions of the heat equation
and the wave equation: The propagation speed of solutions of the wave equation
is ﬁnite and is determined by the ‘speed parameter’ in this equation. However, the
propagation speed of heat according to the heat equation is inﬁnite! Certainly this
is physically not realistic. Nevertheless, the formula u(t, x) = E ∗U0 (E is the
elementary solution given above) implies that an initial heat source U0 localized in
the neighbourhood of some point x0 will cause an effect u(t, x) ̸= 0 at a point x which
is at an arbitrary distance from x0, within a time t > 0 which is arbitrarily small.
10.4.2
Summary of Properties of the Fourier Transformation
Inashorttablewesummarizethebasicpropertiesandsomeimportantrelationsforthe
Fourier transformation. Following the physicists convention, we denote the variables
for the functions in the domain of the Fourier transformation by x and the variables for
functions in the range of the Fourier transformation by p. Though all statements have
a counterpart in the general case, we present the one-dimensional case in our table.
For a function f we denote by ˜f its Fourier transform Ff . In the table we use
the words ‘strongly decreasing’ to express that a function f satisﬁes the condition
deﬁned by Eq 2.10.
As a summary of the table one can mention the following rule of thumb: If f or
T ∈S′(R) decays sufﬁciently rapidly at “inﬁnity,” then ˜f , respectively ˜T , is smooth,
i.e., is a differentiable function, and conversely.
In the literature there are a good number of books giving detailed tables where the
Fourier transforms of explicitly given functions are calculated. We mention the book
by F. Oberhettinger, entitled “Fourier transforms of distributions and their inverses :
a collection of tables,” Academic Press, New York, 1973.

160
10
Fourier Transformation
Properties of Fourier transformation F
Properties in x-space
Properties in p-space
decay for |x| →∞
local regularity
1)
f ∈L1(R)
1)
˜f ∈C (R) and lim|p|→∞˜f(p) = 0
2)
f strongly decreasing
2)
˜f ∈C ∞(R)∩L1(R)
3)
f ∈S (Rx)
3)
˜f ∈S (Rp)
4)
f(x) = e−ax2, a > 0
4)
˜f(p) = e−p2
4a
5)
f ∈L1(R), supp f ⊆[−a,a], a > 0
5)
˜f analytic on C
bounded by constea|p|
6)
T ∈S ′(R), suppT ⊆[−a,a], a > 0 6)
˜T analytic on C, bounded
by Q(p)ea|p|, Q polynomial
7)
T ∈S ′(R)
7)
˜T ∈S ′(R)
growth for |x| →∞
local singularity
8)
1, eiax
8)
δ(p), δ(p−a)
9)
xm
9)
δ (m)(p)
10) multiplication with (ix)m
10) differential operator ( d
dp)m
11) θ(±x)
11)
1
p±io
12) signx
12) vp 1
p
13) θ(x)xm−1
13)
1
(p+io)m
10.5
Exercises
1. For f ∈L1(Rn) show:
∥f −fa∥1 →0
as
a →0.
Hints: Consider ﬁrst continuous functions of compact support. Then approxi-
mate elements of L1(Rn) accordingly.
2. Prove the ﬁrst two properties of the Fourier transformation mentioned in
Proposition 10.1:
a) For f ∈L1(Rn) and a ∈Rn the translation by a is deﬁned as fa(x) = f (x−a)
for almost all x ∈Rn. These translations and the multiplication by a corre-
sponding exponential function are related under the Fourier transformation
according to the following formulae:
a) F(eiaxf )(p) = (Ff )a(p)
∀p ∈Rn.
b) (Ffa)(p) = eiap(Ff )(p)
∀p ∈Rn.
b) For any λ > 0 deﬁne the scaled function fλ by fλ(x) = f ( x
λ) for almost all
x ∈Rn. Then, for f ∈L1(Rn) one has
(Ffλ)(p) = λn(Ff )(p)
∀p ∈Rn.
3. Prove: If f ∈L1(R) has a derivative f ′ ∈L1(R), then f (x) →0 as |x| →∞.
4. Show the embedding relation 10.6.
5. Prove: If I is an isomorphism of the Hausdorff locally convex topological vector
space E, then the adjoint I ′ is an isomorphism of the topological dual equipped
with weak topology σ.

10.5
Exercises
161
6. Show that the right-hand of inequality (10.13) is a polynomially bounded
function of p ∈Rn.
7. Prove the following relation:
⟨IFf , φ⟩= ⟨If , Fφ⟩
∀φ ∈D(Rn),
∀f ∈L1(Rn).
8. ShowthattheFouriertransformFφ ofatestfunctionφ ∈D(Rn)istherestriction
of an entire function to Rn, i.e., Fφ is the restriction to Rn of the function
Cn ∋z = (z1, . . . , zn) #→(2π)−n
2

Rn eiz·ξφ(ξ)dξ
which is holomorphic on Cn. Conclude: if φ ̸= 0, then Fφ cannot be a test
function in D(Rn) (it cannot have a compact support).
9. For any a > 0 introduce the function g(x) = /n
k=1 e−a|xk| and show that
I(Fg) =

(Fg)(p)dp = (2π)
n
2 .
10. Assume that we know F′I1 = (2π)
n
2 δ. Then show that L(Fφ)(x) = φ(x) for
all x ∈Rn and all φ ∈S(Rn), i.e., LF = id on S(Rn).
Hint: In a straightforward calculation use the relation eip·x(Fφ)(p)
=
(Fφ−x)(p).
11. Deﬁne the action of a rotation R of Rn on tempered distributions T on Rn by
R · T = T ◦R−1 where T ◦R−1 is deﬁned by Eq. (4.6). Prove that the Fourier
transformation F′ commutes with this action of rotations:
R · (F′T ) = F′(R · T )
∀T ∈S′(Rn).
Conclude: If a distribution T is invariant under a rotation R (i.e., R · T = T ),
so is its Fourier transform.
Hints: Show ﬁrst that (Fφ) ◦R = F(φ ◦R) for all test functions φ.
12. In the notation of Lemma 10.3 show that the function Rn ∋p #→pK,m(ep ·
(−ix)α · u) is polynomially bounded, for any α ∈Nn and any u ∈D(Rn).
13. Calculate the integral
1
(2π)32

R3
eip·x
p2 + μ2 dp = 1
4π
e−|μ||x|
|x|
.
Hints: Introduce polar coordinates and apply the Theorem of Residues 9.7.
14. For a > 0 introduce the function ga on R deﬁned by ga(p) =
1
√
2π
2a
a2+p2 and
show for that for a, b > 0 one has
ga ∗gb = ga+b .
Hint: Recall Example 10.1.3 and the convolution theorem for functions in L1(R).
15. Find a tempered elementary solution of the free Schrödinger operator.

162
10
Fourier Transformation
References
1. Chandrasekharan K. Classical Fourier transforms. Universitext. New York: Springer-Verlag;
1989.
2. Dewitt-Morette C, Dillard-Bleick M, Choquet-Bruhat Y. Analysis, manifolds and physics (2
Volumes). Amsterdam: North-Holland; 1982.
3. Donoghue WF. Distributions and Fourier transforms. New York: Academic; 1969.
4. Dunford N, Schwartz JT. Linear operators. Part I: general theory. New York: Interscience
Publisher; 1958.
5. Hörmander L. The analysis of linear partial differential operators. 1. Distribution theory and
Fourier analysis. Berlin: Springer-Verlag; 1983.
6. Hörmander L. The analysis of linear partial differential operators. 2. Differential operators of
constant coefﬁcients. Berlin: Springer-Verlag; 1983.
7. Mikusinski J, Sikorski K. The elementary theory of distributions. Warsaw: PWN; 1957.

Chapter 11
Distributions as Boundary Values of Analytic
Functions
For reasons explained earlier we introduced various classes of distributions as ele-
ments of the topological dual of suitable test function spaces. Later we learned that
distributions can also be deﬁned as equivalence classes of certain Cauchy sequences
of smooth functions or, locally, as ﬁnite order weak derivatives of continuous func-
tions. In this chapter we learn that distributions have another characterization, namely
as ﬁnite sums of boundary values of analytic functions.
This section introduces the subject for the case of one variable. We begin by
considering a simple example discussed earlier from a different perspective. The
function z #→1
z is analytic in C\ {0} and thus in particular in the upper and lower
half planes H+ and H−,
H± = {z = x + iy ∈C : x ∈C, ±y > 0} .
The limits in D′(R) of the function f (z) = 1
z =
1
x+ iy exist for y →0, z = x + iy ∈
H± as we saw earlier,
lim
y→0, y>0
1
x ± iy =
1
x ± io.
The distributions
1
x± io are called the boundary values of the analytic function z #→1
z
restricted to the half planes H±. In Sect. 3.2 we established the following relations
between these boundary values with two other distributions, namely
1
x + io −
1
x −io = −2πiδ,
1
x + io +
1
x −io = 2vp 1
x ,
i.e., Dirac’s delta distribution and Cauchy’s principal value are represented as ﬁnite
sums of boundary values of the function z #→1
z , z ∈C\ {0}. In this chapter we will
learn that every distribution can be represented as a ﬁnite sum of boundary values of
analytic functions.
© Springer International Publishing Switzerland 2015
163
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_11

164
11
Distributions as Boundary Values of Analytic Functions
Recall that A(H±) stands for the algebra of functions which are analytic on H±.
Every F ∈A(H+) deﬁnes naturally a family Fy, y > 0, of regular distributions on
R according to the formula
⟨Fy, φ⟩=

R
F(x + iy)φ(x) dx
∀φ ∈D(R).
(11.1)
The basic deﬁnition of a boundary value now reads as follows.
Deﬁnition 11.1 A function F ∈A(H+) is said to have a boundary value F+ ∈
D′(R), if and only if, the family of regular distributions Fy, y > 0, has a limit in
D′(R), for y →0, i.e., for every φ ∈D(R),
lim
y→0 ⟨Fy, φ⟩
exists in C. The boundary value F+ ∈D′(R) is usually denoted by F(x + io) ≡F+.
The following result is a concrete characterization of those analytic functions
which have a boundary value in the space of distributions.
Theorem 11.1
A holomorphic function F± ∈A(H±) has a boundary value in
D′(R) if it satisﬁes the following condition:
For every compact set K ⊂R there are a positive constant C and an integer
m ∈N such that for all x ∈K and all |y| ∈(0, 1] the estimate
|F±(x + iy)| ≤
C
|y|m
(11.2)
holds.
Proof
Consider the case of the upper halfplane. In order to show that the above
condition is sufﬁcient for the existence of a boundary value of F one has to show
that under this condition, for each φ ∈D(R), the auxiliary function
g(y) = ⟨Fy, φ⟩=

R
F(x + iy)φ(x) dx,
y > 0
has a limit for y →0.
It is clear (for instance by Corollary 6.1) that this function g is of class C∞((0, ∞)).
Since F is holomorphic, it satisﬁes the Cauchy–Riemann equations ∂yF = i∂xF
for all z = x + iy ∈H+. (Recall that ∂x stands for
∂
∂x ). This allows us to express
derivatives of g as follows, for n ∈N and any y > 0:
g(n)(y)
=

R (∂y)nF(x + iy)φ(x) dx
=

R ( i∂x)nF(x + iy)φ(x) dx = (−i)n 
R F(x + iy)φ(n)(x) dx.
The Taylor expansion of g at y = 1 reads
g(y) =
n

j=0
g(j)(1)
j!
(y −1)j + Rn(y),
Rn(y) = 1
n!
 y
1
(y −t)ng(n+1)(t) dt.
This expansion shows that g(y) has a limit for y →0, if and only if, the remainder
Rn(y) does, for some n ∈N. Apply the hypothesis on F for the compact set K =

11
Distributions as Boundary Values of Analytic Functions
165
supp φ. This then gives a constant C and an integer m ∈N such that the estimate of
our hypothesis holds. For this integer we deduce (|K| denotes the Lebesgue measure
of the set K)
|g(m+1)(t)| ≤

R
|F(x + it)||φ(m+1)(x)| dx ≤C
tm |K|pK,m+1(φ)
for all 0 < y ≤t ≤1, and this implies that for n = m the remainder has a limit for
t →0, and this limit is
lim
y→0, y>0 Rm(y) = (−1)m+1
m!
 1
0
tmg(m+1)(t) dt.
Since φ ∈D(R) is arbitrary, we conclude by Theorem 3.3 that F has a boundary
value in D′(R).
2
The restriction of the function z #→
1
z to H± certainly belongs to A(H±) and
clearly these two analytic functions satisfy the condition (11.2), hence by Theorem
11.1 they have boundary values
1
x± io. Thus we ﬁnd on the basis of a general result
what we have shown earlier by direct estimates. There we have also shown that the
difference of these two boundary values equals 2π iδ. In the section on convolution
we learned that T ∗δ = T for all T ∈D′(R). Thus one would conjecture that every
distribution on R is the difference of boundary values of analytic functions on the
upper, respectively lower, half plane. This conjecture is indeed true. We begin with
the easy case of distributions of compact support.
Theorem 11.2 If T ∈E′(R) has the compact support K, then there is a holomorphic
function ˆT on C\K such that for all f ∈D(R),
T (f ) = lim
ε↘0

R
[ ˆT (x + iε) −ˆT (x −iε)]f (x) dx .
(11.3)
Proof For every z ∈Rc = C\R the Cauchy kernel t #→
1
2 iπ
1
t−z belongs to E(R).
Hence a function ˆT : Rc →C is well deﬁned by
ˆT (z) =
1
2iπ ⟨T (t),
1
t −z⟩.
Since there is an m ∈N such that T satisﬁes the estimate
|T (f )| ≤C
sup
t∈K,ν≤m
|Dνf (t)|,
we ﬁnd immediately the estimate
| ˆT (x + iy)| ≤C|y|−m−1
∀x ∈R, ∀y ̸= 0.
Furthermore, the estimate for T implies that ˆT can be analytically continued to
Kc = C\K. For all z, ζ ∈Kc one has, for z ̸= ζ,
1
z −ζ [
1
t −z −
1
t −ζ ] =
1
(t −z)(t −ζ).

166
11
Distributions as Boundary Values of Analytic Functions
As ζ →z the right-hand side converges to
1
(t−z)2 in E(R). We conclude that
ˆT (z) −ˆT (ζ)
z −ζ
=
1
2 iπ ⟨T (t),
1
(t −z)(t −ζ)⟩→
1
2 iπ ⟨T (t),
1
(t −z)2 ⟩,
hence ˆT is complex differentiable on Kc.
Now for z = x + iy, y > 0, we calculate ˆT (z) −ˆT (z) = ⟨T (t), χy(t −x)⟩where
χy(t) = 1
π
y
t2+y2 . This allows us to write, for f ∈D(R),

R
[ ˆT (x + iy) −ˆT (x −iy)]f (x) dx =

R
⟨T (t), χy(t −x)⟩f (x) dx.
In the Exercises of the chapter on convolution products (Sect. 7.4) we have shown
that this equals
⟨T (t), (χy ∗f )(t)⟩.
According to the Breit–Wigner Formula (3.9) χy →δ as y ↘0, hence (χy ∗f ) →f
in D(R) as y ↘0, and it follows that ⟨T (t), (χy ∗f )(t)⟩→⟨T (t), f (t)⟩= T (f ) as
y ↘0. We conclude that the formula (11.3) holds.
2
Note that in Theorem 11.2 the condition f ∈D(R) cannot be replaced by f ∈
E(R). A careful inspection of the proof however shows that formula (11.3) can be
extended to all f ∈E(R) which are bounded and which have bounded derivatives.
In this case the convolution products occurring in the proof are well deﬁned too.
When one wants to extend Theorem 11.2 to the case of general distributions
T ∈D′(R) one faces the problem that the Cauchy kernel belongs to E(R) but not to
D(R). Thus a suitable approximation of T by distributions with compact support is
needed. As shown in Theorem 5.9 of the book [1] this strategy is indeed successful
(See also [2]).
Theorem 11.3 For every T ∈D′(R) there is an analytic function F on Kc, K =
supp T , satisfying the growth condition (11.2) on H± such that
T (f ) = lim
ε↘0

R
[F(x + iε) −F(x −iε)]f (x) dx
(11.4)
for all f ∈D(R). One writes T (x) = F(x + io) −F(x −io).
Similar results are available for distributions of more than one variable. This case
is much more difﬁcult than the one-dimensional case for a variety of reasons. Let
us mention the basic ones. (1) One has to ﬁnd an appropriate generalization of the
process of taking boundary values from above and below the real line. (2) In the
theory of analytic functions of more than one complex variable one encounters a
number of subtle difﬁculties absent in the one-dimensional theory.
We sketch the solution due toA. Martineau [5]. Suppose that U ⊂Cn is a pseudo-
convex open set (for the deﬁnition of this concept we have to refer to Deﬁnition 2.6.8
of the book [4]) and Γ ⊂Rn an open convex cone. Suppose furthermore that F
is a holomorphic function on UΓ = (Rn + iΓ ) ∩U which satisﬁes the following

11.1
Exercises
167
condition: For every compact subset K ⊂Ω = Rn ∩U and every closed subcone
Γ ′ ⊂Γ there are positive constants C and k such that
sup
x∈K
|F(x + iy)| ≤C|y|−k
∀y ∈Γ ′.
(11.5)
Then F(x + iy) has the boundary value F(x + iΓ 0) which is a distribution on Ω
and, as y tends to zero in a closed subcone Γ ′ ⊂Γ ,
F(x + iy) →F(x + iΓ 0)
in
D′(Ω).
(11.6)
For the converse suppose that a distribution T ∈D′(Ω) is given on Ω = Rn∩U. Then
there are open convex cones Γ1, . . . , Γm in Rn such that their dual cones Γ o
1 , . . . , Γ o
m
cover the dual space of Rn (Γ o
j =

ξ ∈Rn : ξ · x ≥0 ∀x ∈Γj

) and holomorphic
functions Fj on UΓj , j = 1, . . . , m, each satisfying the growth condition (11.5),
such that T is the sum of the boundary values of these holomorphic functions:
T (x) = F1(x + iΓ10) + · · · + Fm(x + iΓm0).
(11.7)
11.1
Exercises
1. For n = 1, 2, . . . deﬁne fn(z) =
1
zn , z ∈C\ {0} and show that the functions
f ±
n = fn|H± have boundary values
1
(x± io)n in D′(R). Then prove the formula
1
(x + io)n+1 = ( −1)n
n!
Dn
1
x + io
where D denotes the distributional derivative.
2. For f ∈L1(R) deﬁne two functions F± on H± by the formula
F±(z) =
1
2 iπ

R
f (x)
x −z dx
∀z ∈H±.
Show:
a) F± is well deﬁned and is estimated by
|F±(x + iy)| ≤
1
2π|y| ∥f ∥1
∀z ∈H±.
b) F± is holomorphic on H±.
c) F± has a boundary value f± ∈D′(R).
d) For a Hölder-continuous function f ∈L1(R) show that the boundary values
are given by
f± = ±1
2f +
1
2 iπ (vp 1
x ) ∗f
and deduce f = f+ −f−.

168
11
Distributions as Boundary Values of Analytic Functions
3. a) Suppose a function f ∈L1
loc(R) has its support in R+ and there are some
constants a, C such that |f (ξ)| ≤Ce aξ for almost all ξ ∈R+. Introduce the
half plane Ha = {z ∈C : Re z > a} and show that
ˆf (z) =
 ∞
0
e−zξf (ξ) dξ
(11.8)
is a well deﬁned analytic function on Ha.
b) Suppose a distribution u ∈E′(R) has its support in the interval [−a, a], for
some a > 0. Prove that
ˆu(z) = ⟨u(ξ), e−zξ⟩
(11.9)
is a well deﬁned analytic function on the complex plane C and show that there
is a constant C such that
|ˆu(z)| ≤Ce aRe z
∀z ∈C.
The function ˆf is called the Laplace transform of the function f usually written
as ˆf (z) = (Lf )(z) and similarly the function ˆu is called the Laplace transform
of the distribution u ∈E′(R), also denoted usually by ˆu(z) = (Lu)(z). For further
details on the Laplace transform and related transformations see [3, 6].
Hints: For the proof of the second part one can use the representation of
distributions as weak derivatives of functions.
References
1. Bremermann H. Complex variables and Fourier transforms. Reading: Addison-Wesley; 1965.
2. Cartan H. Elementary theory of analytic functions of one or several complex variables. Mineola,
NY: Dover Publications; 1995.
3. Davies B. Applied mathematical sciences. In: John F, Sirovich L, LaSalle JP, Whitham GB,
editors. Integral transforms and their applications, vol. 25, 3rd ed. Berlin: Springer; 2002.
4. Hörmander L.An introduction to complex analysis in several variables. Princeton:Van Nostrand;
1967.
5. Martineau A. Distributions et valeur au bord des fonctions holomorphes. In: Theory of
distributions, Proc. Intern. Summer Inst. Lisboa: Inst. Gulbenkian de Ciéncia; 1964.
pp. 193–326.
6. Widder DV. Pure and applied mathematics. In: Smith PA, Eilenberg S, editors. An introduction
to transform theory, vol. 42. New York: Academic; 1971.

Chapter 12
Other Spaces of Generalized Functions
For a nonempty open set Ω ⊆Rn, we have introduced three classes of distributions
or generalized functions, distributions with compact support E′(Ω), tempered distri-
butions S′(Ω), and general distributions D′(Ω) and we have found that these spaces
of distributions are related by the inclusions
E′(Ω) ⊂S′(Ω) ⊂D′(Ω).
These distributions are often called Schwartz distributions. They have found numer-
ous applications in mathematics and physics. One of the most prominent areas of
successful applications of Schwartz distributions and their subclasses has been the
solution theory of linear partial differential operators with constant coefﬁcients as it
is documented in the monograph of L. Hörmander [1, 2]. Though distributions do
not admit, in general, a product, certain subclasses have been successfully applied
in solving many important classes of nonlinear partial differential equations. These
classes of distributions are the Sobolev spaces W m,p(Ω), m ∈N, 1 ≤p < ∞,
Ω ⊆Rn open and nonempty and related spaces. We will use them in solving some
nonlinear partial differential equations through the variational approach in Part III.
In physics, mainly tempered distributions are used, since Fourier transformation
is a very important tool in connecting the position representation with the momentum
representation of the theory. The class of tempered distributions is the only class of
Schwartz distributions, which is invariant under the Fourier transformation. General
relativistic quantum ﬁeld theory in the sense of Gårding andWightman [3–6] is based
on the theory of tempered distributions.
All Schwartz distributions are localizable and the notion of support is well deﬁned
for them via duality and the use of compactly supported test functions. Furthermore
all these distributions are locally of ﬁnite order. This gives Schwartz distributions a
relatively simple structure but limits their applicability in an essential way. Another
severe limitation for the use of tempered distributions in physics is the fact that they
allow only polynomial growth,but in physics one often has to deal with exponen-
tial functions, for instance e x, x ∈R, which is a distribution but not a tempered
distribution on R. These are some very important reasons to look for more general
classes of generalized functions than the Schwartz distributions. And certainly a sys-
tematic point of view invites a study of other classes of generalized functions too.
© Springer International Publishing Switzerland 2015
169
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_12

170
12
Other Spaces of Generalized Functions
Accordingly, we discuss the most prominent spaces of generalized functions which
are known today from the point of view of their applicability to a solution theory of
more general partial differential operators and in physics. However, we do not give
proofs in this chapter since its intention is just to inform about the existence of these
other spaces of generalized functions and to stimulate some interest.
The ﬁrst section presents the generalized functions with test function spaces
of Gelfand type S. The next section introduces hyperfunctions and in particular
Fourier hyperfunctions and the ﬁnal section explains ultradistributions according to
Komatsu.
12.1
Generalized Functions of Gelfand Type S
The standard reference for this section is Chap. IV of [7] in which one ﬁnds all the
proofs for the statements.
Denote N0 = {0, 1, 2, 3, . . . } and introduce for 0 < a, L < ∞, j ∈N, m ∈N0
the following functions on C∞(Rn):
q(f ; a, m, L, j) = sup

|xkDαf (x)|
(L + 1
j )|k|kak : x ∈Rn, k, α ∈Nn
0, |α| ≤m

(12.1)
The set of all functions f ∈C∞(Rn) for which q(f ; a, m, L, j) is ﬁnite for all m ∈N0
and all j ∈N is denoted by
Sa,L(Rn).
(12.2)
Equipped with the system of norms q(·; a, m, L, j), m ∈N0, j ∈N, it is a Fréchet
space. Finally, we take the inductive limit of these spaces with respect to L to get
Sa(Rn) = ind limL>0 Sa,L(Rn).
(12.3)
For a nonempty open subset Ω ⊂Rn, the spaces Sa(Ω) are deﬁned in the same way
by replacing C∞(Rn) by C∞(Ω) and by taking the supremum over x ∈Ω instead of
x ∈Rn.
Some basic properties of the class of spaces Sa(Ω), a > 0, are collected in
Proposition 12.1
Suppose 0 < a ≤a′ and consider any open nonempty subset
Ω ⊆Rn, then
D(Ω) ⊂Sa(Ω) ⊂Sa′(Ω) ⊂S(Ω).
(12.4)
In this chain each space is densely contained in its successor and all the embeddings
are continuous.
Similarly we introduce another class of test function spaces Sb(Rn) distinguished
by a parameter b > 0. For f ∈C∞(Rn), m ∈N0 and j ∈N deﬁne
p(f ; b, m, M, j) = sup

|xkDαf (x)|
(M + 1
j )|α|αbα : x ∈Rn, k, α ∈Nn
0, |k| ≤m

.
(12.5)

12.1
Generalized Functions of Gelfand Type S
171
The set of all f ∈C∞(Rn) for which p(f ; b, m, M, j) is ﬁnite for all m ∈N0 and all
j ∈N is denoted by Sb,M(Rn). Equipped with the system of norms p(·; b, m, L, j),
j ∈N, m ∈N0, the spaces
Sb,M(Rn)
(12.6)
are Fréchet spaces (see Chap. IV of [7]). Again we take the inductive limit of these
spaces with respect to M > 0 to obtain
Sb(Rn) = ind limM>0 Sb,M(Rn).
(12.7)
Note the important difference in the deﬁnition of the spaces Sb(Rn) and the spaces
Sa(Rn). In the deﬁnition of the continuous norms for these spaces, the rôles of
multiplication with powers of the variable x and the derivative monomials Dα have
been exchanged and therefore according to the results on the Fourier transformation
(see Proposition 10.1), one would expect that the Fourier transform maps these spaces
into each other. Indeed the precise statement about this connection is contained in
the following proposition.
Proposition 12.2 The Fourier transformation F is a homeomorphism Sb(Rn) →
Sb(Rn).
Suppose 0 < b ≤b′, then
Sb(Rn) ⊂Sb′(Rn) ⊂S(Rn).
(12.8)
In this chain each space is densely contained in its successor and all the embeddings
are continuous.
The elements of S1(Rn) are analytic functions and those of Sb(Rn) for 0 < b < 1
are entire analytic.
A third class of test function spaces of type S is the intersection of the spaces
deﬁned above. They can be deﬁned directly as an inductive limit of spaces Sb,M
a,L (Rn)
with respect to L, M > 0. To this end, consider the following system of norms on
C∞(Rn), for L, M > 0 and j, m ∈N:
q(f ; a, b, m, j, L, M) =
= sup

|xkDαf (x)|
(L + 1
j )|k|kak(M + 1
m)|α|αbα : x ∈Rn, k, α ∈Nn
0

.
(12.9)
Denote the set of functions f ∈C∞(Rn) for which q(f ; a, b, m, j, L, M) is ﬁnite for
all m, j ∈N by
Sb,M
a,L (Rn).
(12.10)
Equipped with the system of norms q(·; a, b, m, j, L, M), m, j ∈N, the space
Sb,M
a,L (Rn) is a Fréchet space. The third class of test function spaces is now deﬁned
by
Sb
a(Rn) = ind limM>0, L>0 Sb,M
a,L (Rn)
(12.11)

172
12
Other Spaces of Generalized Functions
for a, b > 0. For a function f ∈C∞(Rn) to be an element of Sb
a(Rn), it has to satisfy
the constraints both from Sa(Rn) and Sb(Rn) with the effect that for certain values
of the parameters a, b > 0, only the trivial function f = 0 is allowed.
Proposition 12.3 The spaces Sb
a(Rn) are not trivial if, and only if,
a + b ≥1, a > 0, b > 0
or
a = 0, b > 1
or
a > 1, b = 0.
The Fourier transformation F is a homeomorphism Sb
a(Rn) →Sa
b (Rn).
Suppose 0 < a ≤a′ and 0 < b ≤b′ such that the space Sb
a(Rn) is not trivial, then
Sb
a(Rn) is densely contained in Sb′
a′ (Rn) and the natural embedding is continuous.
In addition, we have the following continuous embeddings:
Sb
a(Rn) ⊂S(Rn),
Sb
a(Rn) ⊂Sa(Rn),
Sb
a(Rn) ⊂Sb(Rn).
(12.12)
The elements in S1
a(Rn) are analytic functions and those in Sb
a(Rn) for 0 < b < 1
are entire analytic, i.e., they have extensions to analytic, respectively to entire
analytic, functions.
The topological dual Sb
a(Rn)′ of Sb
a(Rn) deﬁnes the class of generalized functions
of Gelfand type Sb
a. Thus we get a two-parameter family of spaces of generalized
functions. Since Sb
a(Rn) ⊂S(Rn) with continuous embedding, we know that these
new classes of generalized functions contain the space of tempered distributions:
S′(Rn) ⊂Sb
a(Rn)′.
There are three important aspects under which one can look at these various spaces
of generalized functions:
a) Does this space of generalized functions admit the Fourier transformation as a
homeomorphism (isomorphism)?
b) Are the generalized functions of this space localizable?
c) Are the Fourier transforms of the generalized functions of the space localizable?
These questions are relevant in particular for applications to the theory of partial
differential operators and in mathematical physics (relativistic quantum ﬁeld theory).
One can show that the spaces Sb
a(Rn), 1 < b, contain test functions of compact
support. Thus for generalized functions over these test function spaces the concept
of a support can be deﬁned as usual. Since the Fourier transformation maps the space
Sb
a(Rn) into Sa
b (Rn), all three questions can be answered afﬁrmatively for the spaces
Sb
a(Rn) 1 < a, b < ∞.
According to Proposition 12.3 the smaller the parameters a, b > 0, the smaller
the test function space Sb
a(Rn), and thus the larger is the corresponding space of the
generalized functions. Therefore, it is worthwhile to consider generalized functions
over the spaces Sb
a(Rn) with 0 < a ≤1 and/or 0 < b ≤1 too. However according to
Proposition 12.3, elements of the spaces Sb
a(Rn), 0 < b ≤1 are analytic functions.
Since there are no nontrivial analytic functions with compact support, the localization
of the generalized functions with this test function space cannot be deﬁned through

12.2
Hyperfunctions and Fourier Hyperfunctions
173
compactly supported test functions as in the case of Schwartz distributions. Thus it
is not obvious how to deﬁne the concept of support in this case.
The topological dual of a space of analytic functions is called a space of analytic
functionals. As we are going to indicate, analytic functionals admit the concept of a
carrier which is the counterpart of the concept of support of a Schwartz distribution.
Let Ω ⊂Cn be a nonempty open set, and consider the space O(Ω) of holomorphic
functions on Ω equipped with the system of seminorms
|f |K = sup
z∈K
|f (z)|,
K ⊂Ω
compact.
(12.13)
Since Ω can be exhausted by a sequence of compact sets, the space O(Ω) is actually
a Fréchet space. For T ∈O(Ω)′ there are a constant C, 0 ≤C < ∞, and a compact
set K ⊂Ω such that
|T (f )| ≤C|f |K
∀f ∈O(Ω).
(12.14)
The compact set K of relation (12.14) is called a carrier of the analytic functional T .
Naturally, one would like to proceed to deﬁne the support of an analytic functional as
the smallest of its carriers. But in general this does not exist and thus the concept of
support is not always available. In this context, it is worthwhile to recall the deﬁnition
E′ of Schwartz distributions of compact support where the same type of topology is
used.
With regard to our three questions, the space S1
1(Rn) plays a distinguished rôle
since it is invariant under the Fourier transform and elements of its topological dual
admit at least the concept of a carrier. As we will discuss in the next section, they
actually admit the concept of support as the smallest carrier.
12.2
Hyperfunctions and Fourier Hyperfunctions
Recall the representation
T (x) = F1(x + i Γ10) + · · · + Fm(x + i Γm0)
(12.15)
of a distribution T ∈D′(Ω) as a ﬁnite sum of boundary values of certain holomorphic
functions F1, . . . , Fm, each of which satisﬁes a growth condition of the form (11.5).
In a series of articles [8–10], M. Sato has shown how to give a precise mathematical
meaning to a new class of generalized functions when in the above representation
of distributions as a sum of boundary values of analytic functions all growth restric-
tions are dropped. For this, he used a cohomological method and called these new
generalized functions hyperfunctions on Ω. In this way a hyperfunction T on Ω
is identiﬁed with a class of m-tuples of holomorphic functions. When Eq. (12.15)
holds, one calls {F1, . . . , Fm} deﬁning functions of the hyperfunction T .

174
12
Other Spaces of Generalized Functions
The space of all hyperfunctions on Ω is denoted by B(Ω). From the above
deﬁnition it is evident that it contains all Schwartz distributions on Ω:
D′(Ω) ⊂B(Ω).
It has to be emphasized that in contrast to the other spaces of generalized functions
we have discussed thus far the space B(Ω) is not deﬁned as the topological dual of
some test function space.
Spaces of hyperfunctions are well suited for a solution theory of linear differential
operators with real analytic coefﬁcients (see [11]). Consider for example the ordinary
differential operator
P (x, D) = am(x)Dm + · · · + a1(x)D + a0(x),
D =
d
d x
with aj, j = 1, . . . , m, real analytic functions on some open interval Ω ⊂R,
am ̸= 0. In [11], it is shown how a comprehensive and transparent solution theory
for
P(x, D)u(x) = T (x)
(12.16)
can be given in the space B(Ω) of all hyperfunctions on Ω, for any given T ∈B(Ω).
As in the case of Schwartz distributions, one can characterize the subspace of those
hyperfunctions which admit the Fourier transformation as an isomorphism (for this
appropriate growth restrictions at inﬁnity are needed). This subspace is called the
space of Fourier hyperfunctions. Later the space of Fourier hyperfunctions on Rn was
recognized as the topological dual of the test function space of rapidly decreasing
analytic functions O
∼(Dn) which is isomorphic to the space S1
1(Rn) introduced in the
previous section. Brieﬂy the space O
∼(Dn) can be described as follows (see[12]).
First, we recall the radial compactiﬁcation Dn of Rn. Let Sn−1
∞
be the (n −1)-
dimensional sphere at inﬁnity, which is homeomorphic to the unit sphere Sn−1 =
{x ∈Rn; |x| = 1} by the mapping x →x∞, where the point x∞∈Sn−1
∞
lies on the
ray connecting the origin with the point x ∈Sn−1. The set Rn ∪Sn−1
∞, equipped with
its natural topology (a fundamental system of neighborhoods of x∞is the set of all
the sets OΩ,R(x∞) given by:
OΩ,R(x∞) = {ξ ∈Rn; ξ/|ξ| ∈Ω, |ξ| > R} ∪{ξ∞; ξ ∈Ω}
for every neighborhood Ω of x in Sn−1 and R > 0), is denoted by Dn, called the
radial compactiﬁcation of Rn. Equip the space Qn = Dn × i Rn with its natural
product topology. Clearly, Cn = Rn × i Rn is embedded in Qn. Let K be a compact
set in Dn, {Um} a fundamental system of neighborhoods of K in Qn and Om
c (Um) the
Banach space of functions f analytic in Um ∩Cn and continuous on ¯Um ∩Cn which
satisfy
∥f ∥m =
sup
z∈Um∩Cn |f (z)| e |z|/m < ∞.
Finally we introduce the inductive limit of these Banach spaces of analytic functions
O
∼(K) = ind lim
m→∞Om
c (Um).
It has the following properties:

12.2
Hyperfunctions and Fourier Hyperfunctions
175
Proposition 12.4 Let K ⊆Dn be compact. Then the space O
∼(K) is a DFS-space
(a dual Fréchet–Schwartz space), i.e., all the embedding mappings
Om
c (Um) →Om+1
c
(Um+1),
m = 1, 2, . . . ,
are compact.
The space O
∼(Dn) is dense in O
∼(K).
The Fourier transform F is well deﬁned on O
∼(Dn) by the standard formula
(Ff )(p) = (2π)−n/2

e i p·xf (x) d x.
It is an isomorphism of the topological vector space O
∼(Dn).
Note that, this inductive limit is not strict. Since O
∼(Dn) is dense in O
∼(K),
continuous extensions from O
∼(Dn) to O
∼(K) are unique if they exist at all.
The topological dual O
∼(Dn)′ of O
∼(Dn) is called the space of Fourier hyperfunctions
on Rn.
Suppose T ∈O
∼(Dn)′ is a Fourier hyperfunction. Introduce the class C(T ) of all
those compact subsets K ⊆Dn such that T has a continuous extension TK to O
∼(K).
As we have mentioned above each K ∈C(T ) is called a carrier of T .
On the basis of the Mittag–Lefﬂer theorem for rapidly decreasing analytic
functions (see [12, 13]), one proves the nontrivial.
Lemma 12.1 For any T ∈O
∼(Dn)′ one has
K1, K2 ∈C(T ) ⇒K1 ∩K2 ∈C(T ).
Corollary 12.1 Fourier hyperfunctions T admit the concept of support, deﬁned as
the smallest carrier of T :
supp T = ∩K∈C(T )K.
The localization of Fourier hyperfunctions means that for every open nonempty
subsetΩ ⊂Rn onehasthespaceofFourierhyperfunctionsonΩ. Thisissummarized
by stating that Fourier hyperfunctions form a (ﬂabby) sheaf over Rn [11, 12].
Fourier hyperfunctions have an interesting and quite useful integral representation
which uses analyticity of the test functions in a decisive way. For j = 1, . . . , n
introduce the open set Wj =

z ∈Qn : Im zj ̸= 0

. The intersection W = ∩n
j=1Wj
of all these sets consists of 2n open connected components of Qn separated by the
“real points.” For every z ∈W, it introduces the function hz deﬁned by
hz(t) =
n
.
j=1
e −(tj −zj )2
2π i (tj −zj).
One shows hz ∈O
∼(Dn) for every z ∈W. Hence, for every T ∈O
∼(Dn)′, we can deﬁne
a function ˆT : W →C by ˆT (z) = T (hz). It follows that ˆT actually is a “slowly
increasing” analytic function on W. Now given f ∈O
∼(Dn), there is an m ∈N such

176
12
Other Spaces of Generalized Functions
that f ∈Om
c (Um). Hence, we can ﬁnd δm > 0 such that Γ1×· · ·×Γn ⊂Um∩W ∩Cn
where Γj = Γ +
j + Γ −
j and Γ ±
j =

zj = ±xj ± i δm : −∞< xj < ∞

. Since hz is
a modiﬁed Cauchy kernel with appropriate decay properties at inﬁnity, an application
of Cauchy’s integral theorem implies

Γ1×···×Γn
f (z)hz(·) d z = f (·).
Now applying T ∈O
∼(Dn)′ to this identity, we get

Γ1×···×Γn
f (z) ˆT (z) d z = T (f ).
(12.17)
The integral on the left hand side exists since ˆT (z) is slowly increasing and f (z) is
“rapidly decreasing.” Certainly one has to prove that the application of the Fourier
hyperfunction T ‘commutes’with integration so that T can be applied to the integrand
of this path integral. Then in Eq. (12.17) one has a very useful structure theorem for
Fourier hyperfunctions: Every Fourier hyperfunction is represented by a path integral
over a slowly increasing analytic function on W. In this way the powerful theory of
analytic functions can be used in the analysis of Fourier hyperfunctions.
Most results known for (tempered) distributions have been extended to (Fourier)
hyperfunctions. And certainly there are a number of interesting results which are
characteristic for (Fourier) hyperfunctions and which are not available for distri-
butions. From a structural point of view and for applications the most important
difference between Schwartz distributions and hyperfunctions is that hyperfunctions
can locally be of inﬁnite order. For instance the inﬁnite series
∞

n=1
anδ(n),
lim
n→∞(|an|n)1/n = 0
has a precise meaning as a (Fourier) hyperfunction. Actually all hyperfunctions with
support in {0} are of this form. Hence the set of hyperfunctions with support in
{0} is much larger than the set of distributions with support in a point (compare
Proposition 4.7).
As an example consider the function e −1
z which is deﬁned and holomorphic on
C\ {0}. Hence one can consider e −1
z as a deﬁning function of a hyperfunction [ e −1
z ]
with support in {0} and one shows (see [12])
[ e −1
z ] =
∞

n=0
2π i
n(n + 1)δ(n).
In mathematical physics, Fourier hyperfunctions have been used successfully
to extend the Gårding–Wightman formulation of relativistic quantum ﬁeld theory
considerably (see [14–16]). For other applications of hyperfunctions, we refer to the
books [11, 12].

12.3
Ultradistributions
177
12.3
Ultradistributions
The standard reference for this section is the article [17]. The theory of ultradis-
tributions has been developed further in [18, 19]. Ultradistributions are special
hyperfunctions and the space of all ultradistributions on an open set Ω ⊂Rn is
the strong dual of a test function space, which is deﬁned in terms of a sequence
(Mp)p∈N0 of positive numbers Mp satisfying the following conditions:
(M1) Logarithmic convexity: M2
p ≤Mp−1Mp+1 for all p ∈N.
(M2) Stability under ultradifferential operators (deﬁned later): There are constants
C > 0, L > 1 such that for all p ∈N0,
Mp ≤CLp min
0≤q≤pMqMp−q.
(M3) Strong nonquasianalyticity: There is a constant C > 0 such that for all p ∈N,
∞

q=p+1
Mq−1
Mq
≤Cp Mp
Mp+1
.
For special purposes, some weaker conditions sufﬁce. Examples of sequences
satisfying these conditions are the Gevrey sequences
Mp = (p)s
or
pps
or
Γ (1 + ps)
for s > 1.
Now let Ω ⊂Rn be a nonempty open set. A function f ∈C∞(Ω) is called an
ultradifferentiable function of class Mp if, and only if, on each compact set K ⊂Ω
the derivatives of f are bounded according to the estimate
||Dαf ||K = sup
x∈K
|Dαf (x)| ≤Cr|α|M|α|,
α ∈Nn
0
(12.18)
for some positive constants C and r. In order to make such a class of functions
invariant under afﬁne coordinate transformations, there are two ways to choose the
constant r and accordingly, we get two classes of ultradifferentiable functions: f ∈
C∞(Ω) is called an ultradifferentiable function of class (Mp) (respectively of class
[Mp]) if condition (12.18) holds for every r > 0 (respectively for some r > 0).
E(Mp)(Ω) (E[Mp](Ω)) denotes the space of all ultradifferentiable functions of class
(Mp) (of class [Mp]) on Ω. The corresponding subspaces of all ultradifferentiable
functions with compact support are denoted by D(Mp)(Ω), respectively D[Mp](Ω).
All these spaces can be equipped with natural locally convex topologies, using the
construction of inductive and projective limits.
Under these topologies the functional analytic properties of these spaces are
well known (Theorem 2.6 of [17]), and we can form their strong duals E(Mp)(Ω)′,
E[Mp](Ω)′, D(Mp)(Ω)′, D[Mp](Ω)′.
D(Mp)(Ω)′ (D[Mp](Ω)′) is called the space of ultradistributions of class Mp of
Beurling type (of Roumieu type) or of class (Mp) (of class [Mp]).

178
12
Other Spaces of Generalized Functions
Ultradistributions of class (Mp) (of class [Mp]) each form a (soft) sheaf over
Rn. Multiplication by a function in E(Mp)(Ω) (in E[Mp](Ω)) acts as a sheaf
homomorphism.
These spaces of ultradistributions have been studied as comprehensively as
Schwartz distributions but they have found up to now nearly no applications in
physics or mathematical physics. The spaces of ultradistributions are invariant under
a by far larger class of partial differential operators than the corresponding spaces of
Schwartz distributions, and this was one of the major motivations for the construction
of the spaces of ultradistributions. Consider a differential operator of the form
P(x, D) =

|α|≤m
aα(x)Dα
aα ∈E∗(Ω).
(12.19)
It deﬁnes a linear partial differential operator P(x, D) : D∗(Ω)′ →D∗(Ω)′ as the
dual of the formal adjoint P ′(x, D) operator of the operator P(x, D) which is a
continuous linear operator D∗(Ω) →D∗(Ω). Here ∗stands for either (Mp) or [Mp].
In addition, certain partial differential operators of inﬁnite order leave the spaces
of ultradistributions invariant and thus provide the appropriate setting for a study of
such operators.
A partial differential operator of the form
P(D) =
∞

|α|=0
aαDα,
aα ∈C
(12.20)
is called an ultradifferential operator of class (Mp) (of class [Mp]) if there are
constants r and C (for every r > 0 there is a constant C) such that
|aα| ≤Cr|α|/M|α|,
|α| = 0, 1, 2, . . . .
An ultradifferential operator of class ∗maps the space of ultradistributions D∗(Ω)′
continuously into itself.
References
1. Hörmander L. The analysis of linear partial differential operators 1. Distribution theory and
Fourier analysis. Berlin: Springer-Verlag; 1983.
2. Hörmander L. The analysis of linear partial differential operators 2. Differential operators of
constant coefﬁcients. Berlin: Springer-Verlag; 1983.
3. WightmanAS, Gårding L. Fields as operator-valued distributions in relativistic quantum theory.
Arkiv för Fysik. 1964;28:129–84.
4. Streater RF, Wightman AS. PCT, spin and statistics, and all that. New York: Benjamin; 1964.
5. Jost R. The general theory of quantized ﬁelds. Providence: American Mathematical Society;
1965.
6. Bogolubov NN, et al. General principles of quantum ﬁeld theory. Mathematical physics and
applied mathematics. Vol. 10. Dordrecht: Kluwer Academic; 1990.

References
179
7. Gel’fand IM, Šilov GE. Generalized functions II: spaces of fundamental and generalized
functions. 2nd ed. New York: Academic; 1972.
8. Sato M. On a generalization of the concept of functions. Proc Japan Acad. 1958;34:126-
130;34:604-608.
9. Sato M. Theory of hyperfunctions I. J Fac Sci, Univ Tokyo, Sect I. 1959;8:139–193.
10. Sato M. Theory of hyperfunctions II. J Fac Sci, Univ Tokyo, Sect I. 1960;8:387–437.
11. Komatsu H, editor. Hyperfunctions and pseudo-differential equations. Springer lecture notes
287. Berlin: Springer-Verlag; 1973.
12. Kaneko A. Introduction to hyperfunctions. Mathematics and its applications (Japanese series).
Dordrecht: Kluwer Academic; 1988.
13. Nishimura T, Nagamachi S. On supports of Fourier hyperfunctions.
Math Japonica.
1990;35:293–313.
14. Nagamachi S, Mugibayashi N. Hyperfunction quantum ﬁeld theory. Commun Math Phys.
1976;46:119–34.
15. Brüning E, Nagamachi S. Hyperfunction quantum ﬁeld theory: basic structural results. J Math
Physics. 1989;30:2340–59.
16. Nagamachi S, Brüning E. Hyperfunction quantum ﬁeld theory: analytic structure, modular
aspects, and local observable algebras. J Math Phys. 2001;42(1):1–31.
17. Komatsu H. Ultradistributions I, Structure theorems and a characterization. J Fac Sci. Univ
Tokyo, Sect IA, Math. 1973;20:25–105.
18. Komatsu H. Ultradistributions II, The kernel theorem and ultradistributions with support in a
manifold. J Fac Sci. Univ Tokyo, Sect IA. 1977;24:607–28.
19. Komatsu H. Ultradistributions III. Vector valued ultradistributions and the theory of kernels. J
Fac Sci. Univ Tokyo, Sect IA. 1982;29: 653–717.

Chapter 13
Sobolev Spaces
13.1
Motivation
As we will learn in the introduction to Part C on variational methods, all major
developments in the calculus of variations were driven by concrete problems, mainly
in physics. In these applications, the underlying Banach space is a suitable function
space, depending on the context as we are going to see explicitly later. Major parts
of the existence theory of solutions of nonlinear partial differential equations use
variational methods (some are treated in Chap. 32). Many other applications can be
found for instance in the book [1]. Here the function spaces which are used are often
the so-called Sobolev spaces and the successful application of variational methods
rests on various types of embeddings for these spaces. Accordingly we present here
very brieﬂy the classical aspects of the theory of Sobolev spaces as they are used
in later applications. Some parts of our presentation will just be a brief sketch of
important results; this applies in particular to the results on the approximation of
elements of a Sobolev space by smooth functions. A comprehensive treatment can
for instance be found in the books [2, 3] and a short introduction in [1].
We assume that the reader is familiar with the basics aspects of the theory of
Lebesgue spaces and with Hölder’s inequality.
13.2
Basic Deﬁnitions
Let Ω ⊆Rn be a nonempty open set, and for k = 0, 1, 2, . . . and 1 ≤p ≤∞
introduce the vector space
C[k,p](Ω) =

u ∈Ck(Ω) : Dαu ∈Lp(Ω), |α| ≤k

.
Here α = (α1, . . . , αn) is an n-tuple of integers αi = 0, 1, 2, . . . and |α| = 
i=1 αi,
and Dαu =
∂|α|u
∂α1
x1 ···∂αn
xn . On this vector space deﬁne a norm for 1 ≤p < ∞by
© Springer International Publishing Switzerland 2015
181
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_13

182
13
Sobolev Spaces
∥u∥k,p =
⎛
⎝
|α|≤k
∥Dαu∥p
p
⎞
⎠
1/p
.
(13.1)
and for p = ∞by
∥f ∥k,∞=

|α|≤k
∥Dαf ∥L∞(Ω).
(13.2)
The Sobolev space W k,p(Ω) is by deﬁnition the completion of C[k,p](Ω) with respect
to this norm. These Banach spaces are naturally embedded into each other according
to
W k,p(Ω) ⊂W k−1,p(Ω) · · · ⊂W 0,p(Ω) = Lp(Ω).
Since the Lebesgue spaces Lp(Ω) are separable for 1 ≤p < ∞one can show
that these Sobolev spaces are separable too. For 1 < p < ∞the spaces Lp(Ω)
are reﬂexive, and it follows that for 1 < p < ∞the Sobolev spaces W k,p(Ω) are
separable reﬂexive Banach spaces.
There is another equivalent deﬁnition of the Sobolev spaces in terms of weak (or
distributional) derivatives due to Meyers and Serrin (1964) [3, 4]:
W k,p(Ω) =

f ∈Lp(Ω) : Dαf ∈Lp(Ω) (weakly) for all |α| ≤k

.
(13.3)
Here Dαf stands for the weak derivative of f , i.e., for all φ ∈C∞
c (Ω) one has in the
sense of Schwartz distributions on Ω
⟨Dαf , φ⟩= (−1)|α|

f (x)Dαφ(x) dx.
Theorem 13.1
Equipped with the norms (13.1) respectively (13.2) the set W k,p(Ω)
is a Banach space. In the case p = 2 the space W k,2(Ω) = H k(Ω) is actually a
Hilbert space with the inner product
⟨f , g⟩H k(Ω) =

|α|≤k

Ω
Dαf (x) · Dαg(x) dx.
(13.4)
The spaces W k,p(Ω) are called Sobolev spaces of order (k,p).
Proof Since the space Lp(Ω) is a vector space, the set W k,p(Ω) is a vector space too,
as a subspace of Lp(Ω). The norm properties of ∥·∥Lp(Ω) easily imply that ∥·∥W k,p(Ω)
is also a norm.
2
The local Sobolev spaces W k,p
loc (Ω) are obtained when in the above construction
the Lebesgue spaceLp(Ω)isreplacedbythelocalLebesguespace Lp
loc(Ω). Elements
in a Sobolev space can be approximated by smooth functions, i.e., these spaces allow
molliﬁcation. In details one has the following result.
Theorem 13.2 Let Ω be an open subset of Rn, k ∈N0 = N ∪{0} and 1 ≤p < ∞.
Then the following holds:

13.2
Basic Deﬁnitions
183
a) For u ∈W k,p
loc (Ω) there exists a sequence um ∈C∞
c (Ω) of C∞functions on Ω
with compact support such that um →u in W k,p
loc (Ω).
b) C∞(Ω) ∩W k,p(Ω) is dense in W k,p(Ω).
c) C∞
c (Rn) is dense in W k,p(Rn).
Proof Here we have to refer to the literature, for instance [2, 3].
2
Naturally, the space C∞
c (Ω) is contained in W k,p(Ω) for all k = 0, 1, 2, . . . and
all 1 ≤p < ∞. The closure of this space in W k,p(Ω) is denoted by W k,p
0
(Ω). In
general W k,p
0
(Ω) is a proper subspace of W k,p(Ω). For Ω = Rn however, equality
holds.
The fact that W k,p
0
(Ω) is, in general, a proper subspace of W k,p(Ω) plays a
decisive role in the formulation of boundary value problems. Roughly one can say
the following: If the boundary Γ = ∂Ω is sufﬁciently smooth, then elements u ∈
W k,p(Ω) together with their normal derivatives of order ≤k −1 can be restricted to
Γ .And elements in W k,p
0
(Ω) can then be characterized by the fact that this restriction
vanishes. (There is a fairly technical theory involved here [3]). A concrete example
of a result of this type is the following theorem.
Theorem 13.3 Let Ω ⊂Rn be a bounded open subset whose boundary Γ = ∂Ω
is piecewise C1. Then the following holds:
(a) Every u ∈H 1(Ω) has a restriction γ0u = u|Γ to the boundary;
(b) H 1
0 (Ω) = ker γ0 =

u ∈H 1(Ω) : γ0(u) = 0

.
Obviously, the Sobolev space W k,p(Ω) embeds naturally into the Lebesgue space
Lp(Ω). Depending on the value of the exponent p in relation to the dimension n of the
underlying space Rn it embeds also into various other functions spaces, expressing
various degrees of smoothness of elements in W k,p(Ω). The following few sections
present a number of (classical) estimates for elements in W k,p(Ω) which then allow
to prove the main results concerning Sobolev embeddings, i.e., embeddings of the
Sobolev spaces into various other function spaces.
A simple example shows what can be expected. Take ψ ∈C∞
c (Rn) such that
ψ(x) = 1 for all |x| ≤1 and deﬁne f (x) = |x|qψ(x) for x ∈Rn, for some q ∈R.
Then ∇f ∈Lp(Rn)n requires n + (q −1)p ≥0, or
q ≥1 −n
p.
Therefore, if 1 ≤p < n then q < 0 is allowed and thus f can have a singularity
(at x = 0). If however p ≥n, then only exponents q ≥0 are allowed, and then f
is continuous at x = 0. The following estimates give a much more accurate picture.
These estimates imply ﬁrst that we get continuous embeddings and at a later stage
we will show that for exponents 1 ≤p < n these embeddings are actually compact,
if Ω is bounded.

184
13
Sobolev Spaces
13.3
The Basic Estimates
13.3.1
Morrey’s Inequality
We start with the case n < p ≤+∞. Denote the unit sphere in Rn by S and introduce
for a Borel measurable set Γ ⊂S with σ(Γ ) > 0 (σ(Γ ) denotes the surface measure
of Γ ) the sets
Γx,r = {x + tω : ω ∈Γ , 0 ≤t ≤r} ,
x ∈Rn,
r > 0.
Γx,r is the set of all lines of length r from x in the direction ω ∈Γ . Note that for
measurable functions f one has

Γx,r
f (y) dy =
 r
0
dttn−1

Γ
f (x + tω) dσ(ω).
(13.5)
Choosing f = 1 we ﬁnd for the Lebesgue measure of Γx,r:
|Γx,r| = rnσ(Γ )/n.
(13.6)
Lemma 13.1 If S, x, r are as above and u ∈C1(Γx,r) then

Γx,r
|u(y) −u(x)| dy ≤rn
n

Γx,r
|∇u(y)|
|x −y|n−1 dy.
(13.7)
Proof For y = x + tω, 0 ≤t ≤r, and ω ∈Γ one has
u(x + tω) −u(x) =
 t
0
ω · ∇u(x + sω) ds,
thus integration over Γ yields

Γ
|u(x + tω) −u(x)| dσ(ω) ≤
 t
0

Γ
|∇u(x + sω)| dσ(ω) ds
=
 t
0
sn−1

Γ
|∇u(x + sω)|
|x + sω −x|n−1 dσ(ω) ds
=

Γx,t
|∇u(y)|
|y −x|n−1 dy ≤

Γx,r
|∇u(y)|
|y −x|n−1 dy.
If we multiply this inequality with tn−1, integrate from 0 to r and use Eq. (13.5) we
get (13.7).
2

13.3
The Basic Estimates
185
Corollary 13.1
For any n < p ≤+∞, any 0 < r < ∞, any x ∈Rn, and any
Borel measurable subset Γ ⊂S such that σ(Γ ) > 0, one has, for all u ∈C1(Γ x,r)
|u(x)| ≤C(σ(Γ ), r, n, p)∥u∥W 1,p(Γx,r)
(13.8)
with
C(σ(Γ ), r, n, p) = r1−n/p
σ(Γ )1/p max

n−1/p
r
,
p −1
p −n
1−1/p
.
Proof Clearly, |u(x)| ≤|u(y)| + |u(x) −u(y)|, for any y ∈Γx,r; integration over
Γx,r and application of (13.7) gives
|Γx,r||u(x)| =

Γx,r
|u(x)| dy ≤

Γx,r
|u(y)| dy + rn
n

Γx,r
|∇u(y)|
|x −y|n−1 dy.
Now apply Hölder’s inequality1 to continue this estimate by
≤∥u∥Lp(Γx,r)∥1∥Lq(Γx,r) + rn
n ∥∇u∥Lp(Γx,r)
----
1
|x −·|n−1
----
Lq(Γx,r)
(13.9)
where q is the Hölder conjugate exponent of p, i.e., q =
p
p−1. Calculate
----
1
| · |n−1
----
Lq(Γ0,r)
= r1−n/p

σ(Γ )p −1
p −n
 p−1
p
(13.10)
and insert the result into (13.9). A rearrangement and a simple estimate ﬁnally gives
(13.8).
2
Corollary 13.2 Consider n ∈N and p ∈(n, +∞]. There are constants A = An
and B = B−1
n
(Bn given by (13.12)) such that for any u ∈C1(Rn) and any x, y ∈Rn
one has (r = |x −y|, B(x, r) is the ball with center x and radius r)
|u(y) −u(x)| ≤2BA1/p
p −1
p −n
 p−1
p
∥∇u∥Lp(B(x,r)∩B(y,r))|x −y|1−n
p .
(13.11)
Proof Certainly, the intersection V = B(x, r)∩B(y, r) of the two balls is not empty.
Introduce the following subsets Γ , Λ of the unit sphere in Rn by the requirement
that x + rΓ = (∂B(x, r)) ∩B(y, r) and y + rΛ = (∂B(y, r)) ∩B(x, r), i.e., Γ =
1
r (∂B(x, r)∩B(y, r)−x) and Λ = 1
r (∂B(y, r)∩B(x, r)−y) = −Γ . It is instructive
to draw a picture of the sets introduced above (Fig. 13.1).
1 This inequality says: whenever f ∈Lp and g ∈Lq, 1 ≤p ≤∞, 1
p + 1
q = 1, then f · g ∈L1
and ∥f · g∥1 ≤∥f ∥p ∥g∥q; for p = 2 = q this is Schwarz inequality.

186
13
Sobolev Spaces
Fig. 13.1 Intersecting balls and the related sets Γx,r and Λy,r
Since Γx,r = rΓx,1 and Λy,r = rΛy,1, we ﬁnd that
Bn = |Γx,r ∩Λy,r|
|Γx,r|
= |Γx,1 ∩Λy,1|
|Γx,1|
(13.12)
is a number between 0 and 1 which only depends on the dimension n. It follows
|Γx,r| = |Λy,r| = B−1
n |W|, W = Γx,r ∩Λy,r.
Now we estimate, using Lemma 13.1 and Hölder’s inequality
|u(x) −u(y)||W| ≤

W
|u(x) −u(z)| dz +

W
|u(z) −u(y)| dz
≤

Γx,r
|u(x) −u(z)| dz +

Λy,r
|u(z) −u(y)| dz
≤rn
n

Γx,r
|∇u(z)|
|x −y|n−1 dz + rn
n

Λy,r
|∇u(z)|
|z −y|n−1 dz
≤rn
n
$
∥∇u∥Lp(Γx,r)
----
1
|x −·|n−1
----
Lq(Γx,r)
+ ∥∇u∥Lp(Λy,r)
----
1
|y −·|n−1
----
Lq(Λy,r)
%
≤2rn
n ∥∇u∥Lp(V )
----
1
| · |n−1
----
Lq(Γ0,r)
.

13.3
The Basic Estimates
187
Taking (13.10), (13.12), and (13.6) into account and recalling r = |x −y|, estimate
(13.11) follows with A = σ(Γ )−1.
2
Recall the deﬁnition of Hölder continuous functions: For 0 < α ≤1 and an open
set Ω ⊆Rn, C0,α(Ω) denotes the space of all bounded continuous functions f on Ω
for which
Qα(f ) =
sup
x,y∈Ω x̸=y
|f (x) −f (y)|
|x −y|α
< ∞.
Theorem 13.4 (Morrey’s Inequality) Suppose n < p ≤+∞and u ∈W 1,p(Rn).
Then there is a unique version u∗of u (i.e., u∗= u almost everywhere) which is
Hölder continuous of exponent 1 −n
p, i.e., u∗∈C0,1−n
p (Rn) and satisﬁes
∥u∥∗
C0,1−np (Rn) ≤C ∥u∥W 1,p(Rn)
(13.13)
where C = C(n, p) is a universal constant. In addition the estimates in (13.7), (13.8),
and (13.11) hold when u is replaced by u∗.
Proof At ﬁrst consider the case n < p < ∞. For u ∈C1
c(Rn) Corollaries 13.1 and
13.2 imply (Cb(Rn) denotes the space of bounded continuous functions on Rn)
∥u∥Cb(Rn) ≤C∥u∥W 1,p(Rn)
and
|u(y) −u(x)|
|y −x|1−n
p
≤C∥∇u∥Lp(Rn).
This implies
∥u∥C0,1−np (Rn) ≤C∥u∥W 1,p(Rn).
(13.14)
If u ∈W 1,p(Rn) is given, there is a sequence of functions uj ∈C1
c(Rn) such that uj →
u in W 1,p(Rn). Estimate (13.14) implies that this sequence is also a Cauchy sequence
in C0,1−n
p (Rn) and thus converges to a unique element u∗in this space. Clearly
Estimate (13.13) holds for this limit element u∗and u∗= u almost everywhere.
The case p = ∞and u ∈W 1,p(Rn) can be proven by using a similar approxima-
tion argument.
2
Corollary 13.3
(Morrey’s Inequality) Let Ω be an open bounded subset of Rn
with smooth boundary (C1) and n < p ≤∞. Then for every u ∈W 1,p(Ω) there
exists a unique version u∗in C0,1−n
p (Ω) satisfying
∥u∗∥C0,1−np (Ω) ≤C ∥u∥W 1,p(Ω) .
(13.15)
with a universal constant C = C(n, p, Ω).
Proof
Under the assumptions of the corollary the extension theorem for Sobolev
spaces applies according to which elements in W 1,p(Ω) are extended to all of Rn by
zero such that there exists a continuous extension operator J : W 1,p(Ω) →W 1,p(Rn)

188
13
Sobolev Spaces
(see for instance Theorem 48.35 of [1]). Then, given u ∈W 1,p(Ω), Theorem 13.4
implies that there is a continuous version U ∗∈C0,1−n
p (Rn) of Ju which satisﬁes
(13.13). Now deﬁne u∗= U ∗|Ω. It follows
∥u∗∥C0,1−np (Ω) ≤∥U ∗∥C0,1−np (Rn) ≤C∥Ju∥W 1,p(Rn) ≤C ∥u∥W 1,p(Ω) .
2
13.3.2
Gagliardo-Nirenberg-Sobolev Inequality
This important inequality claims that
∥u∥Lq ≤C∥∇u∥Lp,
u ∈C1
c(Rn)
(13.16)
for a suitable exponent q depending on the given exponent p, 1 ≤p ≤n. This
exponent is easily determined through the scale covariance of the quantities in this
inequality. For λ > 0 introduce uλ by setting uλ(x) = u(λx). A simple calculation
shows ∥uλ∥Lq = λ−n/q ∥u∥Lq and ∥∇uλ∥Lp = λ1−n/p∥∇u∥Lp. Thus inserting uλ into
(13.16) gives
λ−n/q ∥u∥Lq ≤Cλ1−n/p∥∇u∥Lp
for all λ > 0. This is possible for all u ∈C1
c(Rn) only if
1 −n/p + n/q = 0,
i.e.,
1
p = 1
n + 1
q.
(13.17)
It is a standard notation to denote the exponent q which solves (13.17 ) by p∗, i.e.,
p∗=
np
n −p
with the convention that p∗= ∞if p = n.
As we will show later, the case 1 < p < n can easily be reduced to the case
p = 1, thus we prove this inequality for p = 1, i.e., p∗= 1∗=
n
n−1.
Theorem 13.5 For all u ∈W 1,1(Rn) one has
∥u∥1∗= ∥u∥
n
n−1 ≤
n
.
i=1

Rn |∂iu(x)| dx
 1
n
≤n−1
2 ∥∇u∥1
(13.18)
Proof According to Theorem 13.2 every element u ∈W 1,1(Rn) is the limit of a
sequence of elements uj ∈C1
c(Rn). Hence we only need to prove this inequality for
u ∈C1
c(Rn), and this is done by induction on the dimension n.
We suggest that the reader proves this inequality for n = 1 and n = 2. Here we
present ﬁrst the case n = 3 before we come to the general case.

13.3
The Basic Estimates
189
Suppose that u ∈C1
c(R3) is given. Observe that now 1∗= 3/2. Introduce the
notation x1 = (y1, x2, x3), x2 = (x1, y2, x3), and x3 = (x1, x2, y3). The fundamental
theorem of calculus implies for i = 1, 2, 3
|u(x)| ≤
 xi
−∞
|∂iu(xi)| dyi ≤
 ∞
−∞
|∂iu(xi)| dyi,
hence multiplication of these three inequalities gives
|u(x)|
3
2 ≤
3
.
i=1
 ∞
−∞
|∂iu(xi)| dyi
 1
2
.
Now integrate this inequality with respect to x1 and note that the ﬁrst factor on the
right does not depend on x1:

R
|u(x)|
3
2 dx1 ≤
 ∞
−∞
|∂1u(x1)| dy1
 1
2 
R
3
.
i=2
 ∞
−∞
|∂iu(xi)| dyi
 1
2
dx1
Apply Hölder’s inequality (for p = q = 2) to the second integral, this gives the
estimate
≤
 ∞
−∞
|∂1u(x1)| dy1
 1
2
3
.
i=2
 ∞
−∞
|∂iu(xi)| dx1 dyi
 1
2
.
Next we integrate this inequality with respect to x2 and apply again Hölder’s
inequality to get

R2 |u(x)|
3
2 dx1 dx2
≤

R2 |∂2u(x2)| dx1 dy2
 1
2 
R
 ∞
−∞
|∂1u(x1)| dy1
 1
2
 ∞
−∞
|∂3u(x3)| dx1 dy3
 1
2
d x2 ≤

R2 |∂2u(x2)| dx1 dy2
 1
2

R2 |∂1u(x1)| dy1 dx2
 1
2 
R3 |∂3u(x3)| dx1 dx2 dy3
 1
2
.
A ﬁnal integration with respect to x3 and applying Hölder’s inequality as above
implies

R3 |u(x)|
3
2 dx1 dx2 dx3 ≤

R3 |∂1u(x1)| dy1 dx2 dx3
 1
2
×

R3 |∂2u(x2)| dx1 dy2 dx3
 1
2 
R3 |∂3u(x3)| dx1 dx2 dy3
 1
2
=

190
13
Sobolev Spaces
3
.
i=1

R3 |∂iu(x)| dx1 dx2 dx3
 1
2
≤

R3 |∇u(x)| dx1 dx2 dx3
 1
2
which is the claimed inequality for n = 3.
The general case uses the same strategy. Naturally some more steps are necessary.
Now we have 1∗=
n
n−1. For x = (x1, . . . , xn) ∈Rn introduce the variables xi =
(x1, . . . , xi−1, yi, xi+1, . . . , xn). The fundamental theorem of calculus implies for
i = 1, . . . , n
|u(x)| ≤

R
|∂iu(xi)| dyi
and thus
|u(x)|
n
n−1 ≤
n
.
i=1

R
|∂iu(xi)| dyi

1
n−1
.
(13.19)
Recall Hölder’s inequality for the product of n −1 functions in the form


n
.
i=2
fi


1
≤
n
.
i=2
∥fi∥n−1
(13.20)
and integrate (13.19) with respect to x1 to get

R
|u(x)|
n
n−1 dx1 ≤

R
|∂1u(x1)| dy1

1
n−1 
R
n
.
i=2

R
|∂iu(xi)| dyi

1
n−1
d x1
≤

R
|∂1u(x1)| dy1

1
n−1
n
.
i=2

R2 |∂iu(xi)| dx1 dyi

1
n−1
=

R
|∂1u(x1)| dy1

1
n−1 
R2 |∂2u(x2)| dx1 dy2

1
n−1
×
n
.
i=3

R2 |∂iu(xi)| dx1 dyi

1
n−1
where in the last step we isolated the x2 independent term from the product. Now
integrate this inequality with respect to x2 and apply (13.20) again. This implies,
after renaming the integration variable y2,

R
|u(x)|
n
n−1 dx1 dx2 ≤

R2 |∂2u(x)| dx1 dx2

1
n−1
×

R

R
|∂1u(x)| dx1

1
n−1
n
.
i=3

R2 |∂iu(xi)| dx1 dyi

1
n−1
dx2 ≤

13.3
The Basic Estimates
191

R2 |∂2u(x)| dx1 dx2

1
n−1 
R2 |∂1u(x)| dx1 dx2

1
n−1
×
n
.
i=3

R3 |∂iu(xi)| dx1 dx2 dyi

1
n−1
=
2
.
i=1

R2 |∂iu(x)| dx1 dx2

1
n−1
×
n
.
i=3

R3 |∂iu(xi)| dx1 dx2 dyi

1
n−1
.
Obviously, one can repeat these steps successively for x3, . . . , xn and one proves by
induction that for k ∈{1, . . . , n} we get the estimate

Rk |u(x)|
n
n−1 dx1 dx2 · · · dxk ≤
k.
i=1

Rk |∂iu(x)| dx1 d x2 · · · dxk

n
n−1
×
n
.
i=k+1

Rk+1 |∂iu(xi)| dx1 dx2 · · · dxk dyi

n
n−1
where naturally for k = n the second product does not occur. Thus for k = n one
has

Rn |u(x)|
n
n−1 dx1 dx2 · · · dxn ≤
n
.
i=1

Rn |∂iu(x)| dx1 dx2 · · · dxn

n
n−1
In order to improve this estimate recall Young’s inequality in the elementary form
/n
i=1 Ai ≤1
n
n
i=1 An
i , where Ai ≥0. Thus we get
∥u∥
n
n−1 ≤
n
.
i=1

Rn |∂iu(x)| dx
 1
n
≤1
n
n

i=1

Rn |∂iu(x)| dx
and by Hölder’s inequality one knows n
i=1 |∂iu(x)|
≤
√n |∇u(x)|, hence
∥u∥
n
n−1 ≤
1
√n∥∇u∥1.
2
Remark 13.1
The starting point of our estimates was the identity u(x)
=
 xi
−∞∂iu(xi) dyi and the resulting estimate
|u(x)| ≤

R
|∂iu(xi)| dyi,
i = 1, . . ., n.
If we write
u(x) = 1
2
 xi
−∞
∂iu(xi)dyi −
 ∞
xi
∂iu(xi) dyi

,
we can improve this estimate to
|u(x)| ≤1
2

R
|∂iu(xi)| dyi,
i = 1, . . ., n.
Next we look at the case 1 < p < n. As we will see it can easily be reduced to
the case p = 1.

192
13
Sobolev Spaces
Theorem 13.6 (Gagliardo-Nirenberg-Sobolev Inequality) If 1 ≤p < n then, for
all u ∈W 1,p(Rn), with p∗=
np
n−p,
∥u∥p∗≤
1
√n
p(n −1)
n −p ∥∇u∥p.
(13.21)
Proof
Since elements in W 1,p(Rn) can be approximated by elements in C1
c(Rn) it
sufﬁces to prove Estimate (13.21) for u ∈C1
c(Rn). For such a function u consider the
function v = |u|s ∈C1
c(Rn) for an exponent s > 1 to be determined later. We have
∇v = s|u|s−1sgn(u)∇u and thus by applying (13.18) to v we get
∥|u|s∥1∗≤
1
√n∥∇|u|s∥1 =
s
√n
--|u|s−1∇u
--
1 ≤
s
√n
--|u|s−1--
q∥∇u∥p
(13.22)
where q is the Hölder conjugate exponent of p. Note that this estimate can be written
as
∥u∥s
s1∗≤
s
√n∥u∥s−1
(s−1)q∥∇u∥p.
Now choose s such that s1∗= (s −1)q. This gives s =
q
q−1∗= p∗
1∗and accordingly
the last estimate can be written as
∥u∥s
p∗≤
s
√n∥u∥s−1
p∗∥∇u∥p.
Inserting the value s = p(n−1)
n−p of s now yields (13.21).
2
Corollary 13.4
Suppose that Ω ⊂Rn is a bounded open set with C1-boundary.
Then for all p ∈[1, n) and 1 ≤q ≤p∗there is a constant C = C(Ω, p, q) such
that for all u ∈W 1,p(Ω)
∥u∥q ≤C ∥u∥1,p .
Proof Under the given conditions on Ω one can show that every u ∈W 1,p(Ω) has
an extension to Ju ∈W 1,p(Rn) (i.e., Ju|Ω = u and J : W 1,p(Ω) →W 1,p(Rn) is
continuous). Then for u ∈C1( ¯Ω) ∩W 1,p(Ω)
∥u∥Lp∗(Ω) ≤C∥Ju∥Lp∗(Rn) ≤C∥∇(Ju)∥Lp(Rn) ≤C ∥u∥W 1,p(Ω) .
(13.23)
Since C1(Ω) is dense in W 1,p(Ω), this estimate holds for all u ∈W 1,p(Ω). If now
1 ≤q < p∗a simple application of Hölder’s inequality gives
∥u∥Lq(Ω) ≤∥u∥Lp∗(Ω)∥1∥Ls(Ω) = ∥u∥Lp∗(Ω)|Ω|1/s ≤C|Ω|1/s∥u∥W 1,p(Ω)
where 1
s +
1
p∗= 1
q .
2

13.4
Embeddings of Sobolev Spaces
193
13.4
Embeddings of Sobolev Spaces
13.4.1
Continuous Embeddings
In this short review of the classical theory of Sobolev spaces we can only discuss the
main embeddings results. In the literature, one ﬁnds many additional cases.
For convenience of notation let us introduce, for a given number r ≥0,
r+ =
⎧
⎨
⎩
r
if r /∈N0
r + δ
if r ∈N0
where δ > 0 is some arbitrary small number. For a number r = k + α with k ∈N0
and 0 < α ≤1 we write Cr(Ω) for Ck,α(Ω) (see List of Notation).
Lemma 13.2 For i ∈N and p ≥n and i > n/p (i.e., i ≥1 if p > n and i ≥2 if
p = n) one has
W i,p(Ω) →Ci−(n/p)+(Ω)
and there is a constant C > 0 such that for all u ∈W i,p(Ω)
∥u∥Ci−(n/p)+(Ω) ≤C ∥u∥i,p
(13.24)
Proof As earlier it sufﬁces to prove (13.24) for u ∈C∞(Ω). For such u and p > n
and |α| ≤i −1 apply Morrey’s inequality to get
∥Dαu∥C0,1−n/p(Ω) ≤C∥Dαu∥i,p
and therefore with Ci−n/p(Ω) ≡Ci−1,1−n/p(Ω), we get (13.24).
If p = n (and thus i ≥2) choose q ∈(1, n) close to n so that i > n/q and
q∗=
qn
n−q > n. Then, by the ﬁrst part of Theorem (13.7) and what we have just
shown
W i,n(Ω) →W i,q(Ω) →W i−1,q∗(Ω) →Ci−2,1−n/q∗(Ω).
As q ↑n implies n/q∗↓0, we conclude W i,n(Ω) →Ci−2,α(Ω) for any α ∈(0, 1)
which is written as
W i,n(Ω) →Ci−(n/n)+(Ω).
2
Theorem 13.7 (Sobolev Embedding Theorems) Assume that Ω = Rn or that
Ω is a bounded open subset of Rn with a C1-boundary; furthermore assume that
1 ≤p < ∞and k, m ∈N with m ≤k. Then one has:
(1) If p < n/m, then W k,p(Ω) →W k−m,q(Ω) for q =
np
n−pm or 1
q = 1
p −m
n > 0,
and there is a constant C > 0 such that
∥u∥k−m,q ≤C ∥u∥k,p
for all u ∈W k,p(Ω).
(13.25)

194
13
Sobolev Spaces
(2) If p > n/k, then W k,p(Ω) →Ck−(n/p)+(Ω) and there is a constant C > 0 such
that
∥u∥Ck−(n/p)+(Ω) ≤C ∥u∥k,p
for all u ∈W k,p(Ω).
(13.26)
Proof
Suppose p < n/m and u ∈W k,p(Ω); then Dαu ∈W 1,p(Ω) for all |α| ≤
k −1. Corollary 13.4 implies Dαu ∈Lp∗(Ω) for all |α| ≤k −1 and therefore
W k,p(Ω) →W k−1,p∗(Ω) and there is a constant C1 > 0 such that
∥u∥k−1,p1 ≤C1 ∥u∥k,p
(13.27)
for all u ∈W k,p(Ω), with p1 = p∗. Next deﬁne pj, j ≥2, inductively by pj = p∗
j−1.
Thus
1
pj =
1
pj−1 −1
n and since p < n/m we have
1
pm = 1
p −m
n > 0. Therefore,
we can apply (13.27) repeatedly and ﬁnd that the following inclusion maps are all
bounded:
W k,p(Ω) →W k−1,p1(Ω) →W k−2,p2(Ω) · · · →W k−m,pm(Ω)
and part (1) follows.
In order to prove part (2) consider p > n/k. For p ≥n the statement follows from
Lemma 13.2. Now consider the case n > p > n/k and choose the largest m such that
1 ≤m < k and n/m > p. Deﬁne q ≥n by q =
np
n−mp (i.e., 1
q = 1
p −m
n > 0). Then,
by what we have established above, the following inclusion maps are all bounded:
W k,p(Ω) →W k−m,q(Ω) →Ck−m−(n/q)+(Ω) = Ck−m−( n
p −m)+(Ω) = Ck−(n/p)+(Ω)
which is the estimate of Part (2).
2
In the case p = 2 and Ω = Rn the Fourier transform F is a unitary operator
on L2(Rn). This allows to give a convenient characterization of the Sobolev space
H k(Rn) = W k,2(Rn) and to prove a useful embedding result.
Recall that for u ∈H k(Rn) one has F(Dαu)(p) = i |α|pαF(u)(p). Hence we can
characterize this space by
H k(Rn) =

u ∈L2(Rn) : pαF(u) ∈L2(Rn), |α| ≤k

=

u ∈L2(Rn) : (1 + p2)k/2F(u) ∈L2(Rn)

.
This deﬁnition can be extended to arbitrary s ∈R and thus we can introduce the
spaces
H s(Rn) =

u ∈L2(Rn) : (1 + p2)s/2F(u) ∈L2(Rn)

.
As we are going to show, this space can be continuously embedded into the space
Ck
b(Rn) =

f ∈Ck(Rn) : ∥f ∥k,∞= sup
|α|≤k
sup
x∈Rn |Dαf (x)| < ∞

.

13.4
Embeddings of Sobolev Spaces
195
Theorem 13.8
For k ∈N and s > k + n/2 the Sobolev space H s(Rn) is
continuously embedded into the space Ck
b(Rn) and one has for all u ∈H s(Rn)
∥u∥k,∞≤C ∥u∥s,2 ,
lim
|x|→∞|Dαu(x)| = 0, |α| ≤k.
Proof Recall that the Lemma of Riemann–Lebesgue says that the Fourier transform
of an L1(Rn) function is continuous and vanishes at inﬁnity. For |α| ≤k and s >
k + n/2 one knows

Rn
|p2α|
(1 + p2)s dp = C2
α < ∞.
Thus, for u ∈H s(Rn) we can estimate

Rn |pα(Fu)(p)| dp ≤Cα

Rn (1 + p2)s|Fu(p)|2 dp
1/2
= Cα ∥u∥s,2
and therefore for all x ∈Rn
|Dαu(x)| =


Rn e i pxpα(Fu)(p) dp
 ≤Cα ∥u∥s,2 .
It follows ∥u∥k,∞≤∥u∥s,2. By applying the Lemma of Riemann–Lebesgue we
conclude.
2
Remark 13.2 For s > n/2 the Sobolev spaces H s(Rn) have the remarkable property
of being an algebra, i.e., if u, v ∈H s(Rn), then the point-wise product u · v belongs
to H s(Rn) and ∥u · v∥s,2 ≤∥u∥s,2 ∥v∥s,2. The proof relies on Young’s convolution
inequality2 and the estimate ∥F(u)∥1 ≤C ∥u∥s,2 which holds for s > n/2 with
C2 =

dp
(1+p2)s < ∞. Because of this fact these spaces are used naturally in the study
of nonlinear second order differential equations. For further details see [5, 6, 7].
13.4.2
Compact Embeddings
Here we show that some of the continuous embeddings established above are actually
compact, that is they map bounded subsets into precompact sets. There are various
ways to prove these compactness results. We present a proof which is based on the
characterization of compact subsets M ⊂Lq(Rn), due to Kolmogorov and Riesz
[8, 9].
2 If f ∈Lp and g ∈Lq, then the convolution f ∗g belongs to Lr, 1
p + 1
q = 1+ 1
r , 1 ≤p, q, r ≤∞
and ∥f ∗g∥r ≤∥f ∥p ∥g∥q

196
13
Sobolev Spaces
Theorem 13.9 (Kolmogorov-Riesz Compactness Criterion) Suppose 1 ≤q <
∞. Then a subset M ⊂Lq(Rn) is precompact if, and only if M satisﬁes the following
three conditions:
(a) M is bounded, i.e.,
∃C<∞∀f ∈M ∥f ∥≤C;
(b)
∀ε>0 ∃R<∞∀f ∈M
---π⊥
R f
---
q < ε;
(c)
∀ε>0 ∃r>0 ∀f ∈M ∀y∈Rn
|y|<r ∥τy(f ) −f ∥q < ε.
Here the following notation is used: π⊥
R is the operator of multiplication with the
characteristic function of the set {x ∈Rn : |x| > R} and τy denotes the operator of
translation by y ∈Rn, i.e., τy(f )(x) = f (x + y).
Remark 13.3
If Ω ⊂Rn is an open bounded subset we can consider Lq(Ω) as
a subset of Lq(Rn) by extending all elements f ∈Lq(Ω) by 0 to all of Rn. Then
the above characterization also provides a characterization of precompact subset
M ⊂Lq(Ω) where naturally condition (b) is satisﬁed always and where in condition
(c) we have to use these extensions.
There are several versions of compact embedding results depending on the as-
sumptions on the domain Ω ⊂Rn which are used. The following version is already
quite comprehensive though there are several newer results of this type.
Theorem 13.10 (Rellich–Kondrachov Compactness Theorem) Let Ω ⊂Rn be
a bounded domain. Assume that the boundary of Ω is sufﬁciently smooth and that
1 ≤p < ∞and k = 1, 2, . . . . Then the following holds:
(a) The following embeddings are compact:
(i) kp < n: W k,p(Ω) →Lq(Ω), 1 ≤q < p∗=
np
n−kp;
(ii) kp = n: W k,p(Ω) →Lq(Ω), 1 ≤q < ∞;
(iii) kp > n: W k,p(Ω) →C0
b(Ω).
(b) For the subspaces W k,p
0
(Ω) the embeddings (i–iii) are compact for arbitrary
open sets Ω.
Proof In some detail we present here only the proof of embedding (i) of part (a) for
k = 1. For the remaining proofs we refer to the specialized literature [2, 3].
According to Corollary 13.4 the inclusion mapping W k,p(Ω) →Lq(Ω) is con-
tinuous for 1 ≤q ≤p∗. We have to show that every bounded subset M ⊂W k,p(Ω)
is precompact in Lq(Ω) for 1 ≤q < p∗. This is done by the Kolmogorov–Riesz
compactness criterion. By Remark 13.3 only conditions (a) and (c) have to be veriﬁed
for M considered as a subset of Lq(Ω). Since we know that this inclusion map is
continuous, it follows that M is bounded in Lq(Ω) too and thus Condition (a) of the
Kolmogorov–Riesz criterion is veriﬁed and we are left with verifying Condition (c).

13.4
Embeddings of Sobolev Spaces
197
Observe that for 1 ≤q < p∗Hölder’s inequality implies
∥u∥q ≤∥u∥α
1 ∥u∥1−α
p∗
,
α = 1
q
p∗−q
p∗−1 ∈(0, 1).
Now let M ⊂W 1,p(Ω) be bounded; then this set is bounded in Lp∗(Ω) and hence
there is a constant C < ∞such that for all u ∈M we have
∥u∥q ≤C∥u∥α
1
and it follows
∥τyu −u∥q ≤2C∥τyu −u∥α
1,
∀u ∈M
(13.28)
where we assume that for u ∈W 1,p(Ω) the translated element τyu is extended by
zero outside Ω. Therefore, it sufﬁces to verify condition (c) of Theorem 13.9 for the
norm ∥·∥1. For i = 1, 2, . . . introduce the sets
Ωi = {x ∈Ω : d(x, ∂Ω) > 2/i} ,
where d(x, ∂Ω) denotes the distance of the point x from the boundary ∂Ω of Ω.
Another application of Hölder’s inequality gives, for all u ∈M,

Ω\Ωi
|u(x)| dx ≤

Ω\Ωi
|u(x)|p∗dx
1/p∗
Ω\Ωi
dx
1−1
p∗
≤∥u∥p∗|Ω\Ωi|1−1
p∗≤CM|Ω\Ωi|1−1
p∗
where CM is a bound for M in Lp∗(Ω). Given ε > 0 we can therefore ﬁnd i0 = i0(ε)
such that for i ≥i0

Ω\Ωi
|u(x)| dx < ε/4
holds for all u ∈M. Extend u ∈M outside Ω by 0 to get
ˆu(x) =

u(x),
x ∈Ω,
0,
otherwise.
For a ﬁxed i ≥i0 and y ∈Rn, |y| < 1/i, we estimate
∥τyu −u∥1 =

Ωi
|u(x + y) −u(x)| dx +

Ω\Ωi
|ˆu(x + y) −ˆu(x)| dx
≤

Ωi
|u(x + y) −u(x)| dx + ε/2
And the integral is estimated as follows (p′ denotes the Hölder conjugate exponent
of p):
=

Ωi

 1
0
d
dt u(x + ty) dt
 dx =

Ωi

 1
0
y · ∇u(x + ty) dt
dx ≤|y|

Ω2i
|∇u(x)|dx
≤|y||Ω2i|
1
p′ ∥∇u∥Lp(Ω2i) ≤|y||Ω2i|
1
p′C ≤|y||Ω|
1
p′C

198
13
Sobolev Spaces
It follows that there is r0 > 0 such that ∥τyu −u∥1 < ε for all |y| < r0. By estimate
(13.28) we conclude that Condition (c) of Theorem 13.9 holds and therefore by this
theorem M ⊂W 1,p(Ω) is precompact in Lq(Ω).
2
Remark 13.4 The general case of W k,p(Ω) with k > 1 follows from the following
observation which can be proven similarly.
For m ≥1 and 1
q > 1
p −m
n > 0 the inclusion of W k,p(Ω) into W k−m,q(Ω) is compact.
13.5
Exercises
1. Poincaré’s inequality for elements in W 1,p
0
(I), I = [a, b] ﬁnite interval 1 ≤p <
∞: For u ∈W 1,p
0
(I) prove |u(x)| ≤|x −a|1/p′∥u′∥p and conclude ∥u∥∞≤
|I|1/p′∥u′∥p.
2. Prove Part c) of Theorem 13.2, i.e., prove that C∞
c (Rn) is dense in the Sobolev
space W k,p(Rn) for 1 ≤p < ∞and k = 0, 1, 2, . . . .
Hints: Use suitable cut-off functions and regularization and take the techniques
of proof in Proposition 7.4 and Theorem 7.1 into account.
3. Prove the statements in Remark 13.2.
4. Prove: For solutions of the time-independent classical ﬁeld equation
−nφ(x) + m2φ(x) = φ2p−1(x)
in the Sobolev space H 1(Rn) Sobolev’s inequality states that the potential energy
of the solution ∥φ∥2p is estimated from above by the kinetic energy ∥∇φ∥2, for
p = n/n −2 if n ≥3. Formulate and prove the corresponding statements for
n = 2 and n = 1.
References
1. Driver BK. Analysis tools with applications. Berlin: Springer; 2003.
2. Adams RA. Sobolev spaces. Boston: Academic; 1975.
3. Adams RA, Fournier JF. Sobolev spaces. Amsterdam: Academic; 2003.
4. Meyers N, Serrin J. “H=W”. Proc Nat Acad Sci. 1964;51:1055–1056.
5. Strichartz R. A note on Sobolev algebras. Proc Am Math Soc. 1971;29(1):205–207.
6. Simpson H, Spector S. A product property of Sobolev spaces with application to elliptic
estimates. Rend Sem Mat Univ Padova. 2012 October.
7. Tao T. Lecture notes 3 for 254A. Tech Rep Department of Mathematics, UCLA, Los Angles;
2010.
8. Kolmogorov AN. Über Kompaktheit der Funktionenmengen bei der Konvergenz im Mittel.
Nachr Ges Wiss Göttingen. 1931;9:60–63.
9. Riesz M. Sur les ensembles compacts de fonctions sommables. Acta Szeged Sect Math.
1933;6:136–142.

Part II
Hilbert Space Operators

Chapter 14
Hilbert Spaces: A Brief Historical Introduction
14.1
Survey: Hilbert Spaces
The linear eigenvalue problem Au = λu in ﬁnite dimensional spaces was completely
solved at the end of the nineteenth century. At the beginning of the twentieth century,
thefocusshiftedtoeigenvalueproblemsforcertainlinearpartialdifferentialoperators
of second order (e.g., Sturm–Liouville problems) and one realized quickly that these
are eigenvalue problems in inﬁnite dimensional spaces, which presented completely
new properties and unexpected difﬁculties.
In an attempt to use, by analogy, the insight gathered in the ﬁnite dimensional
case, also in the inﬁnite dimensional case, one started with the problem of expanding
“arbitrary functions” in terms of systems of known functions according to the re-
quirements of the problem under consideration, for instance exponential functions,
Hermite functions, spherical functions, etc. The coefﬁcients of such an expansion
were viewed as the coordinates of the unknown function with respect to the given
system of functions (V. Volterra, I. Fredholm, E. Schmidt). Clearly, in this context,
many mathematical problems had to be faced, for instance:
1. Which sequences of numbers can be interpreted as the sequence of coefﬁcients
of which functions?
2. Which notion of convergence is suitable for such an expansion procedure?
3. Which systems of functions, besides exponential and Hermite functions, can be
used for such an expansion?
4. Given a differential operator of the type mentioned above, how do we choose the
system of functions for this expansion?
Accordingly, we start our introduction into the theory of Hilbert spaces and their
operators with some remarks on the history of this subject. The answers to the ﬁrst
two questions were given at the beginning of the twentieth century by D. Hilbert
in his studies of linear integral equations. They became the paradigm for this type
of problems. Hilbert suggested using the space ℓ2(R) of all sequences x = (xi)i∈N
of real numbers xi which are square summable and introduced new topological
concepts, which turned out to be very important later. Soon afterward, E. Schmidt,
M. Fréchet, and F. Riesz gave Hilbert’s theory a more geometrical form, which
© Springer International Publishing Switzerland 2015
201
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_14

202
14
Hilbert Spaces: A Brief Historical Introduction
emphasized the analogy with the ﬁnite dimensional Euclidean spaces Rn and Cn,
n = 1, 2, . . . . This analogy is supported by the concept of an inner product or scalar
product, which depends on the dimension of the space and provides the connection
between the metric and geometric structures on the space. This is well known for
Euclidean spaces, and one expects that the notions and results known from Euclidean
space remain valid in general. Indeed, this turned out to be the case. We mention
here the concepts of length, of angles, as well as orthogonality and results such as
the theorem of Pythagoras, the theorem of diagonals, and Schwarz’ inequality. This
will be discussed in the section on the geometry of Hilbert spaces. However we
will follow more the axiomatic approach to the theory of Hilbert spaces which was
developed later, mainly by J. von Neumann and F. Riesz. In this approach, a Hilbert
space is deﬁned as a vector space on which an inner product is deﬁned in such a way
that the space is complete with respect to the norm induced by the inner product. For
details, see Chap. 15, “Inner product spaces and Hilbert spaces.”
After the basic concepts of the theory of Hilbert spaces have been introduced,
a systematic study of the consequences of the concept of orthogonality follows in
the section on the geometry of Hilbert spaces. The main results are the “Projection
Theorem” 16.1 and its major consequences. Here it is quite useful to keep the analogy
with the Euclidean spaces in mind. Recall the direct orthogonal decomposition Rn =
Rp ⊕Rq, p+q = n. This decomposition has a direct counterpart in a general Hilbert
space H and reads H = M ⊕M⊥where M is any closed linear subspace of H and
M⊥its “orthogonal complement.”
A very important consequence of this decomposition is the characterization of the
continuous linear functionals on a Hilbert space (Theorem 16.3 of Riesz–Fréchet).
According to this theorem, a Hilbert space H and its topological dual space H
′ (as the
space of all continuous linear functionals on H) are “isometrically anti-isomorphic.”
Thus, in sharp contrast to the “duality theory” of a general complete normed space,
the “duality theory” of a Hilbert space is nearly as simple as that of the Euclidean
spaces. The reason is that the norm of a Hilbert space has a special form since it is
deﬁned by the inner product.
The expansion problem mentioned above receives a comprehensive solution in the
“theory of separable Hilbert spaces” which is based on the notions of an “orthonormal
basis” and “Hilbert space basis” (Chap. 16, “Separable Hilbert spaces”). Certainly,
in this context, it is important to have a characterization of an orthonormal basis and
a method to construct such a basis (Gram–Schmidt orthonormalization procedure).
Besides the sequence spaces ℓ2(K), K = R or C, examples of Hilbert spaces
which are important for us, are the Lebesgue spaces L2(Ω, dx) and the Sobolev
spaces H k(Ω), k = 1, 2, . . . , where Ω is a closed or an open subset of a Euclidean
spaceRn, n = 1, 2, . . . . ForsomeoftheLebesguespaces, theproblemofconstructing
an orthonormal basis is discussed in detail. It turns out that the system of exponential
functions en,
en(x) =
1
√
2π
e inx,
x ∈[0, 2π],
n ∈Z

14.1
Survey: Hilbert Spaces
203
is an orthonormal basis of the Hilbert space H = L2([0, 2π), dx). This means that
every “function” f ∈L2([0, 2π]), dx) has an expansion with respect to these basis
functions (Fourier expansion):
f =

n∈Z
cnen,
cn = ⟨en, f ⟩2 ≡
 2π
0
en(x)f (x) dx.
Here, naturally, the series converges with respect to the topology of the Hilbert space
L2([0, 2π), dx). This shows that Fourier series can be dealt with in a simple and
natural way in the theory of Hilbert spaces.
Next we construct an orthonormal basis for several “weighted Lebesgue spaces”
L2(I, ρ dx), for an interval I = [a, b] and a weight function ρ : I →R+. By
specializing the interval and the weight function one thus obtains several well-known
orthonormal systems of polynomials, namely the Hermite-, Laguerre- and Legendre
polynomials.
We proceed with some remarks related to the second question. For the Euclidean
spaces Rn one has a characterization of compact sets which is simple and conve-
nient in applications: A subset K ⊂Rn is compact if, and only if, it is bounded
and closed. However in an inﬁnite dimensional Hilbert space, as for instance the
sequence space ℓ2(R), a closed and bounded subset is not necessarily compact, with
respect to the “strong” or norm topology. This fact creates a number of new problems
unknown in ﬁnite dimensional spaces. D. Hilbert had recognized this, and therefore
he was looking for a weaker topology on the sequence space with respect to which
the above convenient characterization of compact sets would still be valid. He in-
troduced the “weak topology” and studied its main properties. We will discuss the
basic topological concepts for this weak topology and their relation to the corre-
sponding concepts for the strong topology. It turns out that a subset of a Hilbert
space is “weakly bounded,” i.e., bounded with respect to the weak topology, if, and
only if, it is ‘strongly bounded,” i.e., bounded with respect to the strong or norm
topology. This important result is based on the fundamental “principle of uniform
boundedness,” which is discussed in good detail in the Appendix C. An immediate
important consequence of the equivalence of weakly and strongly bounded sets is
that (strongly) bounded subsets of a Hilbert space are relatively sequentially compact
for the weak topology and this implies sequential completeness of Hilbert spaces for
the weak topology.
After we have learned the basic facts about the geometrical and topological
structure of Hilbert spaces we study mappings between Hilbert spaces which are
compatible with the linear structure. These mappings are called “linear operators.”
A linear operator is speciﬁed by a linear subspace D of a Hilbert space H and an
assignment A which assigns to each point x in D a unique point Ax in a Hilbert
space K. This linear subspace D is called the “domain of the operator.” If K = H
one speaks about a “linear operator in the Hilbert space H,” otherwise about a “linear
operator from H into K.” In order to indicate explicitly the dependence of a linear
operator on its domain, we write ˆA = (D, A) for a linear operator with domain D

204
14
Hilbert Spaces: A Brief Historical Introduction
and assignment A. In this notation, it is evident that the same assignment on different
linear subspaces D1 and D2 deﬁnes different linear operators.
Observe that in the above deﬁnition of a linear operator, no continuity require-
ments enter. If one takes also the topological structure of Hilbert spaces into account
one is lead to the distinction of different classes of linear operators. Accordingly
we discuss in Chap. 19 “Linear operators” the deﬁnition and the characterization
of the following classes of linear operators: Bounded, unbounded, closed, closable,
and densely deﬁned operators; for densely deﬁned linear operators one proves the
existence of a unique “adjoint operator,” which allows one to distinguish between
the classes of “symmetric,” “essentially self-adjoint,” and “self-adjoint” operators.
In applications, for instance in quantum mechanics, it is often important to decide
whether a given linear operator is self-adjoint or not. Thus some criteria for self-
adjointness are presented and these are illustrated in a number of examples which
are of interest in quantum mechanics.
If for two linear operators ˆAi = (Di, Ai), i = 1, 2, one knows D1 ⊆D2 and
A1x = A2x for all x ∈D1, one says that the linear operator ˆA2 is an “extension”
of the linear operator ˆA1, respectively that ˆA1 is a “restriction” of ˆA2. A standard
problem which occurs quite frequently is the following: Given a linear differential
operator on a space of “smooth” functions, construct all self-adjoint extensions of
this differential operator. Ideally one would like to prove that there is exactly one
self-adjoint extension (which one then could call the natural self-adjoint extension).
For the construction of self-adjoint extensions (for instance of a linear differential
operator) one can often use the “method of quadratic forms” since there is a funda-
mental result which states that “semi-bounded self-adjoint operators” and “closed
semi-bounded densely deﬁned quadratic forms” are in a one-to-one correspondence
(see Representation Theorem 21.2 and 21.3 of T. Kato). The method of quadratic
forms is also applied successfully to the deﬁnition of the sum of two unbounded
self-adjoint operators, even in some cases when the intersection of the domains of
the two operators is trivial, i.e. only contains the null vector. In this way one gets the
“form sum” of two unbounded operators.
Naturally, most of the problems addressed above do not occur for the class of
“bounded” linear operators. Two bounded linear operators can be added in the stan-
dard way since they are deﬁned on the whole space, and they can be multiplied by
scalars, i.e. by numbers in K. Furthermore one can deﬁne a product of two such
operators by the composition for mappings. Thus it turns out that the class of all
bounded linear operators on a Hilbert space H is an algebra B(H), in a natural way.
This algebra B(H) has a number of additional properties which make it the standard
example of a noncommutative “C∗-algebra.” On B(H), we consider three different
topologies, the “uniform’ or “operator-norm” topology, the “strong” topology, and
the “weak” topology and look at the relations between these topologies.
The algebra B(H) contains several important classes of bounded linear opera-
tors. Thus we discuss the class of “projection operators” or “projectors,” the class
of “isometries,” and the class of “unitary operators.” Projectors are in one-to-one
correspondence with closed subspaces of the Hilbert space. Isometric operators be-
tween two Hilbert spaces do not change the metric properties of these spaces. The

14.1
Survey: Hilbert Spaces
205
class of unitary operators can be considered as the class of those operators between
Hilbert spaces which respect the linear, the metric, and the geometric structures. This
can be expressed by saying that unitary operators are those bijective linear opera-
tors which do not change the inner products. As we will learn there is an important
connection between self-adjoint operators and “strongly continuous’ one-parameter
groups of unitary operators U(t), t ∈R: Such groups are “generated by self-adjoint
operators,” in analogy to the unitary group of complex numbers z(t) = e iat, t ∈R,
which is “generated’ by the real number a. The unitary groups and their relation to
self-adjoint operators play a very important role in quantum mechanics (time evolu-
tions, symmetries). Another class of bounded linear operators are the “trace class”
operators which are used in the form of “density matrices” in the description of states
for a quantum mechanical system. As an important application we present here the
“general uncertainty relations of Heisenberg.”
In more concrete terms and in greater detail we will discuss the above concepts
and results in the following section which is devoted to those self-adjoint operators
which play a fundamental role in the description of quantum systems, i.e. position,
momentum and energy or Hamilton operators. As in classical mechanics the Hamil-
ton operator of an interacting system is the “sum” of the operator corresponding to
the kinetic energy, the free Hamilton operator, and the operator describing the po-
tential energy. Typically both operators are unbounded and we are here in a concrete
situation of the problem of deﬁning the “sum” of two unbounded self-adjoint oper-
ators. A solution of this problem is due to T. Kato who suggested considering the
potential operator or interaction energy as a certain perturbation of the free Hamil-
ton operator (nowadays called “Kato perturbation”). In this way many self-adjoint
Hamilton operators can be constructed which are of fundamental importance for
quantum mechanics.
The ﬁnal sections of the part “Hilbert Spaces” come back to the class of problems
from which the theory of Hilbert spaces originated, namely ﬁnding “eigenvalues”
of linear operators in Hilbert spaces. It turns out that in inﬁnite dimensional Hilbert
spaces the concept of an eigenvalue is too narrow for the complexity of the problem.
As the suitable generalization of the set of all eigenvalues of linear maps in the ﬁnite
dimensional case to the inﬁnite dimensional setting, the concept of “spectrum” is
used. In an inﬁnite dimensional Hilbert space the spectrum of a self-adjoint operator
can have a much richer structure than in the ﬁnite dimensional situation where it
equals the set of all eigenvalues: Besides “eigenvalues of ﬁnite multiplicity” there
can be “eigenvalues of inﬁnite multiplicity” and a “continuous part,” i.e. a nonempty
open interval can be contained in the spectrum. Accordingly the spectrum of a linear
operator is divided into two parts, the “discrete spectrum” and the “essential spec-
trum.” H. Weyl found a powerful characterization of the discrete and the essential
spectrum and he observed a remarkable stability of the essential spectrum under cer-
tain perturbations of the operator: If the difference of the “resolvents” of two closed
linear operators is a “compact operator,” then both operators have the same essential
spectrum.
Recall the “spectral representation” of a symmetric n × n matrix. If σ(A) =
{λ1, . . . , λn} are the eigenvalues of A and {e1, . . . , en} ⊂Rn the corresponding

206
14
Hilbert Spaces: A Brief Historical Introduction
orthonormal eigenvectors, the matrix A has the spectral representation
A =

λ∈σ(A)
λPλ =
n

j=1
λj|ej⟩⟨ej|
where Pλj = |ej⟩⟨ej| is the orthogonal projector onto the space spanned by the
eigenvector ej, i.e. Pλj x = ⟨ej, x⟩ej for all x ∈Kn.
For a self-adjoint operator in an inﬁnite dimensional Hilbert space one must
take into account that the operator might have a nonempty continuous spectrum
and accordingly the general version of the spectral representation of a self-adjoint
operator A should be, in analogy with the ﬁnite dimensional case,
A =

σ(A)
λdPλ.
(14.1)
The proof of the validity of such a spectral representation for general self-adjoint
operators needs a number of preparations which we will give in considerable detail.
The proof of the spectral representation which we present has the advantage that
it relies completely on Hilbert space intrinsic concepts and methods, namely the
“geometric characterization of self-adjointness.” This approach has the additional
advantage that it allows us to prove the fact that every closed symmetric operator has
a “maximal self-adjoint part,” without any additional effort.
Early results in the “spectral theory” of self-adjoint operators concentrated on
the case where the operator is “compact.” Such operators do not have a continuous
spectrum. We discuss here brieﬂy the main results in this area, the “Riesz–Schauder
theory” including the “Fredholm alternative” and several examples.
The spectral representation of a self-adjoint operator A (14.1) has many applica-
tions some of which we discuss in detail, others we just mention brieﬂy. From the
point of view of applications to quantum mechanics the following consequences are
very important. Starting from the spectral representation (14.1) the classiﬁcation of
the different parts of the spectrum σ(A) of the operator A can be done in terms of
properties of the measures
dmψ(λ) = d⟨ψ, Pλψ⟩,
ψ ∈H
relative to the Lebesgue measure d λ. Here the most important distinction is whether
the measure dmψ is absolutely continuous with respect to the Lebesgue measure
or not. In this way one gets a decomposition of the Hilbert space H into different
“spectral subspaces.” This spectral decomposition plays an important role in the
“scattering theory” for self-adjoint “Schrödinger operators” H = H0 + V in the
Hilbert space H = L2(R3), for instance. According to physical intuition one expects
that every state of such a system is either a “bound state,” i.e. stays essentially
localized in a bounded region of R3, or a “scattering state,” i.e. a state which “escapes
to inﬁnity.” The ﬁner spectral analysis shows that this expectation is not always
correct. The ﬁnal section of this part discusses when precisely this statement is

14.1
Survey: Hilbert Spaces
207
correct and how it is related to the different spectral subspaces of the Schrödinger
operator H.
As we will learn the spectrum of a self-adjoint operator consists not only of
eigenvalues but often also has a continuous part. This means that to some parts of the
spectrum there are no eigenfunctions in the Hilbert space and thus the subspace gen-
erated by all eigenfunctions is a proper subspace of the Hilbert space, i.e. the system
of eigenfunctions is not complete. However in many applications of spectral theory,
also in quantum physics, it is desirable to have a complete set of eigenfunctions. This
requirement let to the concept of “generalized eigenfunctions” (in the sense of dis-
tribution theory). Chapter 29 “Spectral Analysis in rigged Hilbert spaces” develops
the appropriate framework in which one can prove the existence and completeness
of generalized eigenfunctions. This result is used very successfully in Dirac’s bra
and ket formalism.
In the theory of operator algebras and in quantum physics the concept of a positive
map plays a fundamental rôle. Accordingly we devote a chapter to the structural
analysis of positive mappings. The most prominent results are Naimark’s theorem on
representations of the C∗-algebra of all bounded linear operators on a Hilbert space,
the Gelfand–Naimark–Segal construction for positive normalized functionals, the
characterization of normal states, and the structural analysis of completely positive
mappings (Stinespring’s factorization theorem).
Though the concept of complete positivity was introduced in the context of a
mathematical theory it is of fundamental importance in those parts of quantum theory
which study composite quantum systems, in particular in the context of quantum
operations and entangled states (see Chaps. 30 and 31). The technical reason is that
the usual positivity condition for operators is not preserved under the formation of
tensor products (if Aj are positive bounded linear operators on the Hilbert space Hj
then the operator A1 ⊗A2 on H1 ⊗H2 is in general not positive). The deﬁnition
of complete positivity (Deﬁnition 30.6) involves the formation of tensor products
of operators in such a way that one could say that a linear map of an operator
algebra A is complete positive whenever it is positive as a map of the much larger
algebra Mk(C) ⊗A for any k = 1, 2, . . . where Mk(C) is the algebra of all complex
k × k-matrices.
The last chapter of this part applies the results of the structural analysis of pos-
itive mappings to three important problems of quantum physics. The general form
countable additive probability measures on the lattice of projections of a separable
Hilbert space of dimension greater than two is determined in Gleason’s theorem.
Then we present the general mathematical form of quantum operations (i.e. com-
pletely positive linear mappings of the space of trace class operators into itself which
do not increase the trace) in Kraus’ﬁrst representation theorem. In ﬁnite dimensional
spaces the structural analysis of completely positive mappings allows some stronger
statements then Stinespring’s factorization theorem; these results are due to Choi
and have many important applications in quantum information theory.

208
14
Hilbert Spaces: A Brief Historical Introduction
14.2
Some Historical Remarks
We sketch a few facts which led to the development of the theory of Hilbert spaces.
For those readers who are interested in further details of the history of this theory and
of functional analysis in general we recommend the book [1]. As mentioned above
the theory of Hilbert spaces has its origin in the theory of expansion of arbitrary
functions with respect to certain systems of orthogonal functions (with respect to a
given inner product). Such systems of orthogonal functions usually were systems of
eigenfunctions of certain linear differential operators. One can view these expansions
as an inﬁnite dimensional version of the Pythagorean theorem.
In the second half of the nineteenth century, under the inﬂuence of mathematical
physics, the focus of much research was on the linear partial differential equation
△3u(x) + λu(x) = 0
∀x ∈Ω,
u|∂Ω = 0,
(14.2)
where Ω ⊂R3 is a nonempty domain with smooth boundary and where △3 is the
Laplace operator in three dimensions. In this context the concept of Green’s function
or elementary solution was introduced by Schwarz, as a predecessor of the concept of
elementary solution as introduced and discussed in the the ﬁrst part on distribution
theory (Sect. 8.4). Around 1894, H. Poincaré proved the existence and the main
properties of the eigenfunctions of the eigenvalue problem (14.2).
As we will learn later, these results are closely related to the emergence of the
theory of linear integral equations, i.e. equations of the form
u(x) +
 b
a
K(x, y)u(y) dy = f (x),
(14.3)
in the case of one dimension, for an unknown function u, for a given kernel function
K and a given source term f . And this theory of linear integral equations in turn
played a decisive role in the development of those ideas which shaped functional
analysis, as we know it today. Many well-known mathematicians of that period, e.g.
C. Neumann, H. Poincaré, I. Fredholm, V. Volterra, and E. Schmidt studied this type
of equations and obtained many interesting results. Eventually, at the beginning of
the twentieth century, D. Hilbert introduced a good number of new and very fruitful
ideas. In his famous papers of 1906, he showed that solving the integral Eq. (14.3) is
equivalent, under certain conditions on K and f , to solving the inﬁnite linear system
for the unknown real sequence ui, i = 1, 2, . . . , for a given inﬁnite matrix with real
coefﬁcients Kij and a given real sequence fi:
ui +
∞

j=1
Kijuj = fi
i = 1, 2, . . . .
(14.4)
Furthermore he succeeded in showing that the only relevant solutions of this system
are those which satisfy the condition
∞

j=1
u2
j < ∞.
(14.5)

14.2
Some Historical Remarks
209
The set of all real sequences (ui)i∈N satisfying condition (14.5), i.e. the set of all
square summable real sequences, is denoted by ℓ2(R). We will learn later that it is a
real vector space with an inner product so that this space is complete with respect to
the norm deﬁned by this inner product. Thus ℓ2(R) is an example of a Hilbert space.
Naturally one would expect that this space plays a prominent role in the theory of
Hilbert spaces and this expectation will be conﬁrmed later when we learn that every
separable Hilbert space is isomorphic to ℓ2(R) or ℓ2(C).
All the Euclidean spaces Rn, n = 1, 2, . . . , are naturally embedded into ℓ2(R)
by assigning to the point x = (x1, . . . , xn) ∈Rn the sequence whose components
with index i > n all vanish. In this sense we can consider the space ℓ2(R) as the
natural generalization of the Euclidean space Rn to the case of inﬁnite dimensions.
On the space ℓ2(R), D. Hilbert introduced two important notions of convergence
which are known today as strong and weak convergence. These will be studied
later in considerable detail. These two notions of convergence correspond to two
differenttopologiesonthisinﬁnitedimensionalvectorspace. Linearmappings, linear
functionals and bilinear forms were classiﬁed and studied by Hilbert on the basis of
their continuity with respect to these two topologies. In such a space the meaning
and interpretation of many concepts of Euclidean geometry were preserved. This
is the case in particular for theory of diagonalization of quadratic forms which is
well established in Euclidean spaces. Hilbert proved that also in the space ℓ2(R)
every quadratic form can be given a normal (i.e. diagonal) form by a “rotation of the
coordinate system.” In his theory of diagonalization of quadratic forms in the inﬁnite
dimensional case, Hilbert discovered a number of new mathematical structures, e.g.
the possibility of a “continuous spectrum.”
Hilbert’s new theory was of great importance for the emerging quantum mechanics
since it offered, through Hilbert’s new concept of a “mathematical spectrum,” the
possibility of interpreting and understanding the energy spectra of atoms as they were
observed experimentally. Since then the theory of Hilbert spaces grew enormously,
mainly through its interaction with quantum physics.
The next important step in the development of the theory of Hilbert spaces came
through the ideas of M. Fréchet, E. Schmidt, and F. Riesz who introduced in the
years 1907–1908 the concepts of Euclidean geometry (length, angle, orthogonality,
basis, etc.) to the theory of Hilbert spaces. A remarkable early observation in these
studies by F. Riesz and M. Fréchet was the following: The Lebesgue space L2(R)
of all equivalence classes of square integrable functions on R has a very similar
geometry to the Hilbert space ℓ2(R). Several months later the analogy between the
two spaces L2(R) and ℓ2(R) was established completely when F. Riesz and E. Fischer
proved the completeness of the space L2(R) and the isomorphy of these spaces. Soon
one realized that many classical function spaces were also isomorphic to ℓ2(R). Thus
most of the important properties of Hilbert spaces were already known at that period.
Some of the most important contributions to this theory are contained in [2] and [3].
Later, around1920, theabstractandaxiomaticpresentationofthetheoryofHilbert
spaces emerged, mainly through the efforts of J. von Neumann [4] and R. Riesz who
also started major developments of the theory of linear operators on Hilbert spaces.

210
14
Hilbert Spaces: A Brief Historical Introduction
CertainlytherearemanyotherinterestingaspectsofhistoryofthetheoryofHilbert
spaces and their operators. These are addressed, for instance in J. Dieudonné’s book
“History of Functional analysis” [1] which we highly recommend, together with the
book [5].
14.3
Hilbert Spaces and Physics
The intuitive steps leading to the recognition that the mathematical structure (Hilbert
spaces, involutive algebras, representation theory of groups) offers the key to quantum
theory appear to me as a stiking corroboration of Einstein’s emphasis of free creation of the
mind and Dirac’s conviction that beauty and simplicity provide guidance.
Rudolf Haag
In our context Physics refers for the most part to “Quantum Physics.” In quantum
physics a system, for instance a particle or several particles in some force ﬁeld, is
described in terms of “states’, “observables,” and “expectation values.” States are
given in terms of vectors in a Hilbert space, more precisely in terms of “unit rays’
generated by a nonvanishing vector in a Hilbert space. The set of all states of a system
is called the state space. Observables are realized by self-adjoint operators in this
Hilbert space while expectation values are calculated in terms of the inner product
of the Hilbert space.
In quantum physics, a particle is considered as an object which is localizable in
(physical) space, i.e. in the Euclidean space R3. Its state space is the Hilbert space
L2(R3). The motivation for this choice is as follows. If the particle is in the state
given by ψ ∈L2(R3), the quantity |ψ(x)|2 has the interpretation of the probability
density of ﬁnding the particle at the point x ∈R3 when a measurement is performed.
This interpretation which is due to M. Born obviously requires

R3 |ψ(x)|2 d 3x = 1.
Thus the choice of L2(R3) as the state space of one localizable particle is consistent
with the probability interpretation of the “wave function’ ψ. Observables are then
self-adjoint operators in L2(R3) and the expectation value EA(ψ) of an observable
described by the self-adjoint operator A when the particle is in the state ψ ∈L2(R3)
is
EA(ψ) = ⟨ψ, Aψ⟩
⟨ψ, ψ⟩= ⟨ψ, Aψ⟩,
for normalized ψ. The self-adjoint operators of quantum mechanics are typically un-
bounded and thus not continuous. Therefore Hilbert’s original version of the theory
of Hilbert spaces and their operators could not cope with many important aspects and
problems arising in quantum mechanics. Thus, in order to provide quantum mechan-
ics with a precise mathematical framework, R. Riesz, M. H. Stone, and in particular
J. von Neumann developed around 1930 an axiomatic approach to the theory of

References
211
Hilbert spaces and their operators. While in Hilbert’s understanding quadratic forms
(or operators) were given in terms of concrete quantities, J. von Neumann deﬁned
this concept abstractly, i.e. in terms of precise mathematical relation to previously
deﬁned concepts. This step in abstraction allowed him to overcome the limitation of
Hilbert’s original theory and it enabled this abstract theory of Hilbert spaces to cope
with all mathematical demands from quantum physics. A more recent example of
the successful use of operator methods in quantum mechanics is the book [6].
Earlier we presented L. Schwartz’ theory of distributions as part of modern func-
tional analysis, i.e. the uniﬁcation in terms of concepts and methods of linear algebra
and analysis. It is worthwhile mentioning here that the deep results of D. Hilbert,
F. and R. Riesz, M. Fréchet, E. Fischer, J. von Neumann, and E. Schmidt were
historically the starting point of modern functional analysis.
Now we recall several applications of the theory of Hilbert spaces in classical
physics. There this theory is used mainly in the form of Hilbert spaces L2(Ω) of
square integrable functions on some measurable set Ω ⊂Rn, n = 1, 2, 3, . . . . If for
instance Ω is some interval in time and if |f (t)|2△t denotes the energy radiating off
some system, the total energy which is radiated off the system during this period in
time, is
E =

Ω
|f (t)|2 dt = ∥f ∥2
L2(Ω) .
In such a context physicists prefer to call the square integrable functions the “func-
tions with ﬁnite total energy.” Theorem 10. of Parseval–Plancherel states for this
case

|f (t)|2 dt =

| ˜f (ν)|2 dν
where ˜f denotes the Fourier transform of the function f . In this way one has two
equivalent expressions for the total energy of the system. The quantity | ˜f (ν)|2 has
naturally the interpretation of the radiated energy during a unit interval in frequency
space. The second integral in the above equation thus corresponds to a decomposition
into harmonic components. It says that the total energy is the sum of the energies of
all its harmonic components. This important result which is easily derived from the
theory of the L2 spaces was originally proposed by the physicist Lord Rayleigh.
The conceptual and technical aspects of the development of quantum theory are
well documented in the book [7] of M. Jammer. A quite comprehensive account of
the development of quantum theory can be found in the six volumes of Mehra and
Rechenberg [8].
References
1. Dieudonné JA. Foundations of modern analysis. New York: Academic Press; 1969.
2. Schmidt E. Zur Theorie der linearen und nichtlinearen Integralgleichungen. I. Teil: Enywicklung
willkürlicher Funktionen nach Systemen vorgeschriebener. Math Ann. 1907;LXIII:433–76.

212
14
Hilbert Spaces: A Brief Historical Introduction
3. Hilbert D. Grundzüge einer allgemeinen Theorie der Integralgleichungen. Leipzig: B. G.
Teubner; 1924.
4. von Neumann J. Mathematical foundations of quantum mechanics. Investigations in physics.
2nd print, editor. Vol. 2. Princeton: Princeton University. Press; 1967.
5. Kramer EE. Chapter 23: Royal roads to functional analysis. pp. 550–76. Chapter 26: The Leonar-
dos of modern mathematics. pp. 625–38. In: The nature and growth of modern mathematics.
Princeton: Princeton University Press; 1982. .
6. Schechter M. Operator methods in quantum mechanics. New York: North Holland; 1981.
7. Jammer M. The conceptual development of quantum mechanics. New York: Wiley; 1974.
8. Mehra J, Rechenberg H. The historical development of quantum theory. Vol. 1– 6. New York:
Springer-Verlag; 2001.

Chapter 15
Inner Product Spaces and Hilbert Spaces
In close analogy with the Euclidean spaces, we develop in this short chapter the
basis of the theory of inner product spaces or “pre-Hilbert spaces” and of “Hilbert
spaces.” Recall that a Euclidean space is a ﬁnite-dimensional real or complex vector
space equipped with an inner product (also called a scalar product). In the theory of
Euclidean space we have the important concepts of the length of a vector, of orthogo-
nality between two vectors, of an orthonormal basis, etc. Through the inner product it
is straightforward to introduce these concepts in the inﬁnite dimensional case too. In
particular we will learn in a later chapter that, and how, a Hilbert space can be identi-
ﬁed with its topological dual space. This, together with the fact that Hilbert spaces can
be considered as the natural extension of the concept of a Euclidean space to the inﬁ-
nite dimensional situation, gives Hilbert spaces a distinguished role in mathematical
physics, in particular in quantum physics, and in functional analysis in general.
15.1
Inner Product Spaces
Before we turn our attention to the deﬁnition of abstract inner product spaces and
Hilbert spaces we recall some basic facts about Euclidean spaces. We hope that thus
the reader gets some intuitive understanding of Hilbert spaces.
The distinguishing geometrical properties of the three-dimensional Euclidean
space R3 is the existence of the concept of the “angle between two vectors” of this
space, which has a concrete meaning.As is well known, this can be expressed in terms
of the inner product of this space. For x = (x1, x2, x3) ∈R3 and y = (y1, y2, y3) ∈R3
one deﬁnes
⟨x, y⟩=
3

j=1
xjyj.
Then
∥x∥= +

⟨x, x⟩
© Springer International Publishing Switzerland 2015
213
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_15

214
15
Inner Product Spaces and Hilbert Spaces
is the Eucidean length of the vector x ∈R3, and the angle θ between two vectors
x, y ∈R3 is determined by the equation
⟨x, y⟩= ∥x∥∥y∥cos θ.
θ is unique in the interval [0, π].
For the ﬁnite-dimensional Euclidean spaces Rn and Cn, n ∈N, the situation is
very similar; with the inner product
⟨x, y⟩=
n

j=1
xjyj
x, y ∈Cn
the angle θ between x, y is deﬁned in the same way.
Thus we have three fundamental concepts at our disposal in these spaces together
with their characteristic relation: vectors (linear structure), length of vectors (metric
structure), and angle between two vectors (geometric structure).
15.1.1
Basic Deﬁnitions and Results
The concept of an inner product space or pre-Hilbert space is obtained by abstraction,
by disregarding the restriction in the dimension of the underlying vector space. As
in the ﬁnite dimensional case, the metric and geometric structures are introduced
through the concept of an “inner” or “scalar” product.
Deﬁnition 15.1 For a vector space V over the ﬁeld K (of complex or real numbers)
every mapping
⟨·, ·⟩: V × V −→K
is called an inner product or a scalar product if this mapping satisﬁes the following
conditions:
(IP1) for all x ∈V : ⟨x, x⟩≥0 and ⟨x, x⟩= 0 implies x = 0 ∈V ;
(IP2) ⟨x, y + z⟩= ⟨x, y⟩+ ⟨x, z⟩for all x, y, z ∈V ;
(IP3) ⟨x, αy⟩= α⟨x, y⟩for all x, y ∈V and all α ∈K;
(IP4) ⟨x, y⟩= ⟨y, x⟩for all x, y ∈V ;
i.e., ⟨·, ·⟩is a positive deﬁnite sesquilinear form on V.
A vector space equipped with an inner product is called an inner product space
or a pre-Hilbert space.
There is an immediate consequence of this deﬁnition: For all x, y, z ∈V and all
α, β ∈K one has
⟨x, αy + βz⟩= α⟨x, y⟩+ β⟨x, z⟩,
⟨αx, y⟩= α⟨x, y⟩.
Note that in Deﬁnition 15.1 we have used the convention which is most popular
among physicists in requiring that an inner product is linear in the second argument

15.1
Inner Product Spaces
215
while it is antilinear in the ﬁrst argument. Among mathematicians, linearity in the
ﬁrst argument seems to be more popular.
We recall two well-known examples of inner products:
1) On the Euclidean space Kn the standard inner product is
⟨x, y⟩=
n

j=1
xjyj
for all x = (x1, . . ., xn) ∈Kn and all y = (y1, . . ., yn) ∈Kn.
2) On the vector space V = C(I, K) of continuous functions on the interval I =
[a, b] with values in K, the following formula deﬁnes an inner product as one
easily proves:
⟨f , g⟩=
 b
a
f (x)g(x) dx
∀f , g ∈V.
As in the Euclidean spaces the concept of orthogonality can be deﬁned in any inner
product space.
Deﬁnition 15.2 Suppose that (V , ⟨·, ·⟩) is an inner product space. One calls
a) an element x ∈V orthogonal to an element y ∈V , denoted x⊥y, if, and only
if, ⟨x, y⟩= 0;
b) a system (xα)α∈A ⊂V orthonormal or an orthonormal system if, and only if,
⟨xα, xβ⟩= 0 for α ̸= β and ⟨xα, xα⟩= 1 for all α, β ∈A. Here A is any index
set;
c) ∥x∥= +√⟨x, x⟩the length of the vector x ∈V .
A simple and well-known example of an orthonormal system in the inner product
space V = C(I, C), I = [0, 2π], mentioned above, is the system of functions fn,
n ∈Z, deﬁned by fn(x) =
1
√
2π e i nx, x ∈I. By an elementary integration one ﬁnds
⟨fn, fm⟩= 1
2π
 2π
0
e i (m−n)x d x = δnm.
In elementary geometry we learn the theorem of Pythagoras. The following lemma
shows that this result holds in any inner product space.
Lemma 15.1 (Theorem of Pythagoras) If {x1, . . ., xN}, N ∈N, is an orthonormal
system in an inner product space (V , ⟨·, ·⟩), then, for every x ∈V the following
identity holds:
∥x∥2 =
N

n=1
|⟨xn, x⟩|2 + ∥x −
N

n=1
⟨xn, x⟩xn∥2.
Proof Given any x ∈V introduce the vectors y = N
n=1⟨xn, x⟩xn and z = x −y.
Now we calculate, for j ∈{1, . . ., N}:
⟨xj, z⟩
= ⟨xj, x −N
n=1⟨xn, x⟩xn⟩= ⟨xj, x⟩−N
n=1⟨xn, x⟩⟨xj, xn⟩
= ⟨xj, x⟩−N
n=1⟨xn, x⟩δjn = 0.

216
15
Inner Product Spaces and Hilbert Spaces
It follows that ⟨y, z⟩= 0. This shows that x = y + z is the decomposition of the
vector x into a vector y which is contained in the space spanned by the orthonormal
system and a vector z which is orthogonal to this space. This allows us to calculate
∥x∥2 = ⟨y + z, y + z⟩= ⟨y, y⟩+ ⟨z, y⟩+ ⟨y, z⟩+ ⟨z, z⟩= ∥y∥2 + ∥z∥2 .
And a straightforward calculation shows that ⟨y, y⟩= N
n=1 |⟨xn, x⟩|2 and thus
Pythagoras’ theorem follows.
2
Pythagoras’ theorem has two immediate consequences which are used in many
estimates.
Corollary 15.1
1. Bessel’s inequality: If {x1, . . ., xN} is a countable orthonormal system (i.e., N ∈
N or N = +∞) in a pre-Hilbert space V , then, for every x ∈V , the following
estimate holds:
N

n=1
|⟨xn, x⟩|2 ≤∥x∥2 .
2. Schwarz’ inequality: For any two vectors x, y in a pre-Hilbert space V one has
|⟨x, y⟩| ≤∥x∥· ∥y∥.
Proof To prove the ﬁrst part take L ∈N, L ≤N. Pythagoras’ theorem implies
SL =
L

n=1
|⟨xn, x⟩|2 ≤∥x∥2 .
Thus, for N ∈N the ﬁrst part follows. If N = +∞one observes that (SL)L is a
monotone increasing sequence which is bounded by |x|2. Therefore this sequence
converges to a number which is smaller than or equal to |x|2:
∞

n=1
|⟨xn, x⟩|2 = lim
L−→∞SL ≤∥x∥2
which proves Bessel’s inequality in the second case.
Schwarz’ inequality is an easy consequence of Bessel’s inequality. Take any two
vectors x, y ∈V . If for instance x = 0, then ⟨x, y⟩= ⟨0, y⟩= 0 and ∥x∥= 0, and
Schwarz’ inequality holds in this case. If x ̸= 0, then ∥x∥> 0 and thus
 x
∥x∥

is an
orthonormal system in V . Hence for any y ∈V Bessel’s inequality implies
⟨x
∥x∥, y⟩

2
≤∥y∥2 .
Now Schwarz’ inequality follows easily.
2

15.1
Inner Product Spaces
217
Remark 15.1
1. In the literature Schwarz’ inequality is often called Cauchy–Schwarz–
Bunjakowski inequality. It generalizes the classical Cauchy inequality

n

j=1
ajbj

2
≤
n

j=1
a2
j
n

j=1
b2
j
∀aj, bj ∈R,
∀n ∈N.
2. Later in the section on the geometry of Hilbert spaces we will learn about
a powerful generalization of Schwarz’ inequality, in the form of the “Gram
determinants.”
3. Suppose that (V , ⟨·, ·⟩) is a real inner product space and suppose that x, y ∈V
are two nonzero vectors. Then Schwarz’ inequality says
−1 ≤⟨x, y⟩
∥x∥|y∥≤+1.
It follows that in the interval [0, π] there is exactly one number θ = θ(x, y) such
that cos θ =
⟨x,y⟩
∥x∥∥y∥. This number θ is called the angle between the vectors x
and y.
Finally we study the concept of length in a general inner product space, in analogy
to the Euclidean spaces.
Proposition 15.1 If (V , ⟨·, ·⟩) is a pre-Hilbert space, then the function V ∋x #→
|x| = +√⟨x, x⟩∈R+ has the following properties:
(N1) ∥x∥≥0 for all x ∈V ;
(N2) ∥λx∥= |λ| ∥x∥for all x ∈V and all λ ∈K;
(N3) ∥x + y∥≤∥x∥+ ∥y∥for all x, y ∈V (triangle inequality);
(N4) ∥x∥= 0 if, and only if, x = 0 ∈V .
This function ∥· ∥= √⟨·, ·⟩is thus a norm on V ; it is called the norm induced by
the inner product.
Proof It is a straightforward calculation to verify properties (N1), (N2), and (N3)
using the basic properties of an inner product. This is done in the Exercises. Property
(N3) follows from Schwarz’ inequality, as the following calculations show:
∥x + y∥2
= ⟨x + y, x + y⟩= ⟨x, x⟩+ ⟨y, x⟩+ ⟨x, y⟩+ ⟨y, y⟩
= ∥x∥2 + ∥y∥2 + 2ℜ⟨x, y⟩
≤∥x∥2 + ∥y∥2 + 2|⟨x, y⟩|
≤∥x∥2 + ∥y∥2 + 2 |x| |y| = ( ∥x∥+ ∥y∥)2,
hence the triangle inequality (N3) follows.
2

218
15
Inner Product Spaces and Hilbert Spaces
15.1.2
Basic Topological Concepts
Every inner product space (V , ⟨·, ·⟩) is a normed space under the induced norm
∥·∥= √⟨·, ·⟩and thus all results from the theory of normed spaces apply which we
have discussed in the ﬁrst part. Here we recall some basic results.
The system of neighborhoods of a point x ∈V is the system of all subsets of V
which contain some open ball Br(x) = {y ∈V : ∥y −x∥< r} with center x and
radius r > 0. This system of neighborhoods deﬁnes the norm topology on V . For this
topology one has: The addition (x, y) #→x+y is a continuous map V ×V −→V . The
scalar multiplication (λ, x) #→λx is a continuous map K×V −→V . In the following
deﬁnition we recall the basic concepts related to convergence of sequences with
respecttothenormtopologyandexpressthemexplicitlyintermsoftheinducednorm.
Deﬁnition 15.3
Equip the inner product space (V , ⟨·, ·⟩) with its norm topology.
One says:
a) A sequence (xn)n∈N ⊂V is a Cauchy sequence if, and only if, for every ε > 0
there is N ∈N such that ∥xn −xm∥< ε for all n, m ≥N;
b) A sequence (xn)n∈N ⊂V converges if, and only if, there is x ∈V such that for
every ε > 0 there is N ∈N such that ∥x −xn∥< ε for all n ≥N;
c) The inner product space (V , ⟨·, ·⟩) is complete if, and only if, every Cauchy
sequence in V converges.
Some immediate important consequences of these deﬁnitions are
Corollary 15.2
1. Every convergent sequence is a Cauchy sequence.
2. If a sequence (xn)n∈N converges to x ∈V , then
lim
n→∞∥xn∥= ∥x∥.
(15.1)
Proof The ﬁrst part is obvious and is left as exercise. Concerning the proof of the
second statement observe the basic estimate
|(∥x∥−∥y∥)| ≤∥x ± y∥
∀, x, y ∈V
(15.2)
which follows easily from the triangle inequality (see Exercises).
2
Remark 15.2
1. The axiom of completeness of the space of real numbers R plays a very important
role in (real and complex) analysis. There are two equivalent ways to formulate
the completeness of the set of real numbers. (a) Every nonempty subset M ⊂R
which is bounded from above (from below) has a supremum (an inﬁmum). (b)
Every Cauchy sequence of real numbers converges. The ﬁrst characterization of
completeness relies on the order structure of real numbers. Such an order is not
available in general. Therefore, we have deﬁned completeness of an inner product
space in terms of convergence of Cauchy sequences.

15.1
Inner Product Spaces
219
2. Finite-dimensionalandinﬁnite-dimensionalpre-Hilbertspacesdifferinaveryim-
portant way: Every ﬁnite-dimensional pre-Hilbert space is complete, but there are
inﬁnite-dimensional pre-Hilbert spaces which are not complete. This is discussed
in some detail in the Exercises.
3. If a space is complete we can deal with convergence of a sequence without a
priori knowledge of the limit. It sufﬁces to verify that the sequence is a Cauchy
sequence. Thus completeness often plays a decisive role in existence proofs .
4. InAppendixA it is shown that every metric space can be “completed” by “adding”
certain “limit elements.” This applies to pre-Hilbert spaces as well. We illustrate
this here for the pre-Hilbert space Q of rational numbers with the ordinary product
as inner product. In this case these limit elements are those real numbers which
are not rational, and thus rather different from the original rational numbers. In
this process of completion the (inner) product is extended by continuity to all real
numbers.
We mention another example illustrating the fact that these limit elements gener-
ated in the process of completion are typically very different from the elements
of the original space. If one completes the inner product space V of all poly-
nomials on an interval I = [a, b], a, b ∈R, a < b, with the inner product
⟨f , g⟩=

I f (t)g(t) d t, one obtains the Lebesgue space L2(I, d t) whose
elements differ in many ways from polynomials.
One has to distinguish clearly the concepts complete and closed for a space. A
topological space V which is not complete is closed, as is every topological space.
However as part of its completion ˜V , the space V is not closed. The closure of V in
the space ˜V is just ˜V . This will be evident when we look at the construction of the
completion of a metric space in some detail in Appendix A.
The basic deﬁnition of this part is
Deﬁnition 15.4 (J. von Neumann, 1925)A Hilbert space is an inner product space
which is complete (with respect to its norm topology).
Thus, in order to verify whether a given inner product space is a Hilbert space,
one has to show that every Cauchy sequence in this space converges. Therefore,
Hilbert spaces are examples of complete normed spaces, i.e., of Banach spaces. It is
interesting and important to know when a given Banach space is actually a Hilbert
space, i.e., when its norm is induced by an inner product. The following subsection
addresses this question.
15.1.3
On the Relation Between Normed Spaces and Inner
Product spaces
As we know, for instance from the example of Euclidean spaces, one can deﬁne on a
vector space many different norms. The norm induced by the inner product satisﬁes
a characteristic identity which is well known from elementary Euclidean geometry.

220
15
Inner Product Spaces and Hilbert Spaces
Lemma 15.2 (Parallelogram Law) In an inner product space (V , ⟨·, ·⟩) the
norm induced by the inner product satisﬁes the identity
∥x + y∥2 + ∥x −y∥2 = 2∥x∥2 + 2∥y∥2
∀x, y ∈V.
(15.3)
Proof The simple proof is done in the Exercises.
2
The intuitive meaning of the parallelogram law is as in elementary geometry. To
see this recall that x +y and x −y are the two diagonals of the parallelogram spanned
by the vectors x and y.
AccordingtoLemma15.2theparallelogramlaw(15.3)isanecessaryconditionfor
a norm to be induced by a scalar product, i.e., to be a Hilbertian norm. Naturally, not
every norm satisﬁes the parallelogram law as the following simple example shows.
Consider the vector space V = C([0, 3], R) of continuous real functions on the
interval I = [0, 3]. We know that
∥f ∥= sup
x∈I
|f (x)|
deﬁnes a norm on V . In the Exercises it is shown that there are functions f , g ∈V
such that ∥f ∥= ∥g∥= ∥f + g∥= ∥f −g∥= 1. It follows that this norm does not
satisfy (15.3). Hence this norm is not induced by an inner product.
The following proposition shows that the parallelogram law is not only necessary
but also sufﬁcient for a norm to be a Hilbertian norm.
Proposition 15.2 (Fréchet–von Neumann–Jordan) If in a normed space (V , ∥·∥)
the parallelogram law holds, then there is an inner product on V such that ∥x∥2 =
⟨x, x⟩for all x ∈V .
If V is a real vector space, then the inner product is deﬁned by the polarization
identity
⟨x, y⟩= 1
4(∥x + y∥2 −∥x −y∥2)
∀x, y ∈V ;
(15.4)
if V is a complex vector space the inner product is given by the polarization identity
⟨x, y⟩= 1
4(∥x + y∥2 −∥x −y∥2 + i ∥x + i y∥2 −i ∥x −i y∥2)
∀x, y ∈V.
(15.5)
Proof The proof is left as an exercise.
2
Without proof (see however [1, 2]) we mention two other criteria which ensure
that a norm is actually a Hilbertian norm. Here we have to use some concepts which
are only introduced in later sections.
Proposition 15.3 (Kakutani, 1939) Suppose that (V , ∥·∥) is a normed space of
dimension ≥3. If every subspace F ⊂V of dimension 2 has a projector of norm 1,
then the norm is Hilbertian.

15.1
Inner Product Spaces
221
Proposition 15.4 (de Figueiredo–Karlovitz, 1967) Let (V , ⟨·, ·⟩) be a normed
space of dimension ≥3; deﬁne a map T from V into the closed unit ball
B = {x ∈V : ∥x∥≤1} by
T x =
⎧
⎨
⎩
x
if ∥x∥≤1,
x
∥x∥
if ∥x∥≥1.
If ∥T x −Ty∥≤∥x −y∥for all x, y ∈V , then ∥·∥is a Hilbertian norm.
It is worthwhile to mention that in a normed space one always has ∥T x −T y∥≤
2∥x −y∥for all x, y ∈V . In general the constant 2 in this estimate cannot be
improved.
15.1.4
Examples of Hilbert Spaces
We discuss a number of concrete examples of Hilbert spaces which are used in many
applications of the theory of Hilbert spaces. The generic notation for a Hilbert space
is H.
1. The Euclidean spaces:As mentioned before, the Euclidean spaces Kn are Hilbert
spaces when they are equipped with the inner product ⟨x, y⟩= n
j=1 xjyj for all
x, y ∈Kn. Since vectors in Kn have a ﬁnite number of components, completeness
of the inner product space (Kn, ⟨·, ·⟩) follows easily from that of K.
2. Matrix spaces: Denote by Mn(K) the set of all n × n matrices with coefﬁcients
in K, n = 2, 3, . . . . Addition and scalar multiplication are deﬁned component-
wise. This gives Mn(K) the structure of a vector space over the ﬁeld K. In order
to deﬁne an inner product on this vector space recall the deﬁnition of the trace
of a matrix A ∈Mn(K). If Aij ∈K are the components of A, the trace of A
is deﬁned as Tr A = n
j=1 Ajj. The transpose of the complex conjugate matrix
A is called the adjoint of A and denoted by A∗= A
t. It is easy to show that
⟨A, B⟩= Tr (A∗B) = n
i,j=1 AijBij, A, B ∈Mn(K), deﬁnes a scalar product.
Again, completeness of this inner product space follows easily from completeness
of K since matrices have a ﬁnite number of coefﬁcients (see Exercises).
3. The sequence space: Recall that the space ℓ2(K) of all sequences in K which
are square summable was historically the starting point of the theory of Hilbert
spaces. This space can be considered as the natural generalization of the Euclidean
spaces Kn for n−→∞. Here we show that this set is a Hilbert space in the sense
of the axiomatic deﬁnition given above. Again, addition and scalar multiplication
are deﬁned componentwise. If x = (xn)n∈N and y = (yn)n∈N are elements in
ℓ2(K), then the estimate |xn + yn|2 ≤2(|xn|2 + |yn|2) implies that the sequence
x + y = (xn + yn)n∈N is square summable too and thus addition is well deﬁned.
Similarly it follows that scalar multiplication is well deﬁned and therefore ℓ2(K)
is a vector space over the ﬁeld K. The estimate |xnyn| ≤1
2(|xn|2 + |yn|2) implies

222
15
Inner Product Spaces and Hilbert Spaces
that the series ∞
n=1 xnyn converges absolutely for x, y ∈ℓ2(K) and thus can be
used to deﬁne
⟨x, y⟩=
∞

n=1
xnyn
(15.6)
as a candidate for an inner product on the vector space ℓ2(K). In the Exercises
we show that Eq. (15.6) deﬁnes indeed a scalar product on this space. Finally we
show the completeness of the inner product space (ℓ2(K), ⟨·, ·⟩).
Suppose that (xi)i∈N is a Cauchy sequence in this inner product space. Then each
xi is a square summable sequence (xi
n)n∈N and for every ε > 0 there is an i0 ∈N
such that for all i, j ≥i0 we have
∥xi −xj∥2 =
∞

n=1
|xi
n −xj
n|2 < ε2.
It follows that for every n ∈N the sequence (xi
n)i∈N is actually a Cauchy sequence
in K. Completeness of K implies that these Cauchy sequences converge, i.e., for
all n ∈N the limits xn = limi−→∞xi
n exist in K.
Next we prove that the sequence x = (xn)n∈N of these limits is square summable.
Given ε > 0 choose i0 ∈N as in the basic Cauchy estimate above. Then, for all
i, j ≥i0 and for all m ∈N,
m

n=1
|xi
n −xj
n|2 ≤∥xi −xj∥2 < ε2;
and we deduce, since limits can be taken in ﬁnite sums,
lim
i−→∞
m

n=1
|xi
n −xj
n|2 =
m

n=1
|xn −xj
n|2 ≤ε2
for all j ≥i0 and all m ∈N. Therefore, for each j ≥i0, sm = m
n=1 |xn −xj
n|2
is a monotone increasing sequence with respect to m ∈N which is bounded by
ε2. Hence this sequence has a limit, with the same upper bound:
∞

n=1
|xn −xj
n|2 =
lim
m−→∞sm ≤ε2,
i.e., for each j ≥i0, we know ∥x −xj∥≤ε. Since ∥x∥= ∥x −xj + xj∥≤
∥x −xj∥+ ∥xj∥≤ε + ∥xj∥, for ﬁxed j ≥i0, the sequence x belongs to ℓ2(K)
and the given Cauchy sequence (xi)i∈N converges (with respect to the induced
norm) to x. It follows that every Cauchy sequence in ℓ2(K) converges, thus this
space is complete.
Proposition 15.5 The space ℓ2(K) of square summable sequences is a Hilbert
space.

15.1
Inner Product Spaces
223
4. The Lebesgue space: Forthisexamplewehavetoassumefamiliarityofthereader
with the basic aspects of Lebesque’s integration theory. Here we concentrate on
the Hilbert space aspects.
Denote by L(Rn) the set of Lebesgue measurable functions f : Rn−→K which
are square integrable, i.e., for which the Lebesgue integral

Rn |f (x)|2 d x
is ﬁnite. Since for almost all x ∈Rn one has |f (x) + g(x)|2 ≤2(|f (x)|2 +
|g(x)|2), it follows easily that L(Rn) is a vector space over K. Similarly one
has 2|f (x)g(x)| ≤|f (x)|2 + |g(x)|2, for almost all x ∈Rn, and therefore
2

Rn |f (x)g(x)| d x ≤

Rn |f (x)|2 d x +

Rn |g(x)|2 d x, for all f , g ∈L(Rn).
Thus a function L(Rn) × L(Rn) ∋(f , g) #→⟨f , g⟩2 ≡

Rn f (x)g(x) d x ∈K is
well deﬁned. The basic rules for the Lebesgue integral imply that this function
satisﬁes conditions (IP2) – (IP4) of Deﬁnition 15.1. It also satisﬁes ⟨f , f ⟩2 ≥0
for all f ∈L(Rn). However ⟨f , f ⟩2 = 0 does not imply f = 0 ∈L(Rn).
Therefore one introduces the “kernel” N = {f ∈L(Rn) : ⟨f , f ⟩2 = 0} of ⟨·, ·⟩2
which consists of all those functions in L(Rn) which vanish almost everywhere
on Rn. As above it follows that N is a vector space over K. Now introduce the
quotient space
L2(Rn) = L(Rn)/N
with respect to this kernel which consists of all equivalence classes
[f ] = f + N,
f ∈L(Rn).
On this quotient space we deﬁne
⟨[f ], [g]⟩2 = ⟨f , g⟩2
where f , g ∈L(Rn) are any representatives of their respective equivalence class.
It is straightforward to show that now ⟨·, ·⟩2 is a scalar product on L2(Rn). Hence
H = (L2(Rn), ⟨·, ·⟩2) is an inner product space. That it is actually a Hilbert space
follows from the important theorem
Theorem 15.1 (Riesz–Fischer) The inner product space
H = (L2(Rn), ⟨·, ·⟩2)
is complete.
Following tradition we identify the equivalence class [f ] ≡f with its represen-
tative in L(Rn) in the rest of the book. Similarly one introduces the Lebesgue
spaces L2(Ω) for measurable subsets Ω ⊂Rn with nonempty interior. They too
are Hilbert spaces.
5. The Sobolev spaces: For an open nonempty set Ω ⊂Rn denote by W 2
k (Ω) the
space of all f ∈L2(Ω) which have “weak” or distributional derivatives Dαf

224
15
Inner Product Spaces and Hilbert Spaces
of all orders α, |α| ≤k, for k = 0, 1, 2, . . . , which again belong to L2(Ω).
Obviously one has
W 2
k+1(Ω) ⊂W 2
k (Ω) ⊂· · · ⊂W 2
0 (Ω) = L2(Ω),
k = 0, 1, 2, . . . .
On W 2
k (Ω) the natural inner product is
⟨f , g⟩2,k =

|α|≤k

Ω
Dαf (x)g(x) d x
∀f , g ∈W 2
k (Ω).
It is fairly easy to verify that this function deﬁnes indeed a scalar product on the
Sobolev space W 2
k (Ω). Finally, completeness of the Hilbert space L2(Ω) implies
completeness of the Sobolev spaces. Details of the proof are considered in the
Exercises.
Obviously these spaces W 2
k (Ω) are the special case p = 2 of the class of spaces
W p
k (Ω) introduced in Theorem 13.1.
15.2
Exercises
1. Let (V , ⟨·, ·⟩) be an inner product space. For x ∈V deﬁne ∥x∥= +√⟨x, x⟩and
show that V ∋x #→∥x∥is a norm on V .
2. Give an example of a pre-Hilbert space which is not complete.
Hint: Consider for instance the space V = C(I; R) of continuous real-valued
functions on the unit interval I = [−1, 1] and equip this inﬁnite-dimensional space
with the inner product ⟨f , g⟩2 =

I f (t)g(t) d t. Then show that the sequence
(fn)n∈N in V deﬁned by
fn(t) =
⎧
⎪⎪⎨
⎪⎪⎩
0
−1
≤t ≤0,
nt
0
< t ≤1
n,
1
1
n
< t ≤1,
is a Cauchy sequence in this inner product space which does not converge to an
element in V .
3. Show: For any two vectors a, b in a normed space (V , ∥· ∥) one has
±(∥a∥−∥b∥) ≤∥a ± b∥
for any combination of the ± signs.
4. Prove the parallelogram law (15.3).
5. On the vector space V = C([0, 3], R) of continuous real functions on the interval
I = [0, 3] deﬁne the norm
∥f ∥= sup
x∈I
|f (x)|
and show that there are functions f , g ∈V such that ∥f ∥= ∥g∥= ∥f + g∥=
∥f −g∥= 1. It follows that this norm does not satisfy the identity (15.3). Hence
this norm is not induced by an inner product.

References
225
Hint: Consider functions f , g ∈V with disjoint supports.
6. Prove Proposition 15.2.
7. Show that the space Mn(K) of n × n matrices with coefﬁcients in K is a Hilbert
space under the inner product ⟨A, B⟩= Tr (A∗B), A, B ∈Mn(K).
8. Prove: Equation 15.6 deﬁnes an inner product on the sequence space ℓ2(K).
9. Prove that the Sobolev spaces W 2
k (Ω), k ∈N, are Hilbert spaces.
Hint: Use completeness of the Lebesgue space L2(Ω).
References
1. Kakutani S. Some characterizations of Euclidean spaces. Jpn J Math. 1939;16:93–7.
2. de Figueiredo DG, Karlowitz L. On the radial projection in normed spaces. Bull Am Math Soc.
1967;73:364–8.

Chapter 16
Geometry of Hilbert Spaces
According to its deﬁnition a Hilbert space differs from a general Banach space in the
important aspect that the norm is derived from an inner product. This inner product
provides additional structure, mainly of geometric nature. This short chapter looks
at basic and mostly elementary consequences of the presence of an inner product in
a (pre-) Hilbert space.
16.1
Orthogonal Complements and Projections
In close analogy to the corresponding concepts in Euclidean spaces, the concepts
of orthogonal complement and projections are introduced and basic properties are
studied. This analogy helps to understand these results in the general inﬁnite dimen-
sional setting. Only very few additional difﬁculties occur in the inﬁnite dimensional
case as will become apparent later.
Deﬁnition 16.1 For any subset M in a pre-Hilbert space (V , ⟨·, ·⟩) the orthogonal
complement of M in V is deﬁned as
M⊥= {y ∈V : ⟨y, x⟩= 0
∀x ∈M}.
There are a number of elementary but important consequences of this deﬁnition.
Lemma 16.1 Suppose that (V , ⟨·, ·⟩) is an inner product space. Then the following
holds:
1. V ⊥= {0} and {0}⊥= V .
2. For any two subset M ⊂N ⊂V one has N⊥⊆M⊥.
3. The orthogonal complement M⊥of any subset M ⊂V is a linear subspace of V .
4. If 0 ∈M ⊂V , then M ∩M⊥= {0}.
The simple proof is done in the Exercises.
The following deﬁnition and subsequent discussion take into account that linear
subspaces are not necessarily closed in the inﬁnite dimensional setting.
© Springer International Publishing Switzerland 2015
227
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_16

228
16
Geometry of Hilbert Spaces
Deﬁnition 16.2
1. A closed subspace of a Hilbert space H is a linear subspace of H which is closed.
2. If M is any subset of a Hilbert space H the span or linear hull of M is deﬁned
by
lin M =
⎧
⎨
⎩x =
n

j=1
ajxj : xj ∈M, aj ∈K, n ∈N
⎫
⎬
⎭.
3. The closed subspace generated by a set M is the closure of the linear hull; it is
denoted by [M], i.e.,
[M] = lin M.
That these deﬁnitions, respectively notations, are consistent is the contents of the
next lemma.
Lemma 16.2 For a subset M in a Hilbert space H the following holds:
1. The linear hull lin M is the smallest linear subspace of H which contains M.
2. The closure of a linear subspace is again a linear subspace.
3. The orthogonal complement M⊥of a subset M is a closed subspace.
4. The orthogonal complement of a subset M and the orthogonal complement of the
closed subspace generated by M are the same:
M⊥= [M]⊥.
Proof The proof of the ﬁrst two items is left as an exercise.
For the proof of the third point observe ﬁrst that according to Lemma 16.1 M⊥is
a linear subspace. In order to show that this linear subspace is closed, take any y ∈H
in the closure of M⊥. Then there is a sequence (yn)n∈N ⊂M⊥which converges to y.
Therefore, for any x ∈M, we know ⟨y, x⟩= limn→∞⟨yn, x⟩, because of continuity
of the inner product. yn ∈M⊥implies ⟨yn, x⟩= 0 and thus ⟨y, x⟩= 0. We conclude
that y ∈M⊥. This proves M⊥⊆M⊥and thus M⊥= M⊥is closed and the third
point follows.
In a ﬁrst step of the proof of the fourth part we show: M⊥= (lin M)⊥. Since
M ⊂lin M the ﬁrst part of Lemma 16.1 proves (lin M)⊥⊆M⊥. If now y ∈M⊥and
x = n
j=1 ajxj ∈lin M are given, it follows that ⟨y, x⟩= n
j=1 aj⟨y, xj⟩= 0 since
all xj belong to M, thus y ∈(lin M)⊥and therefore the equality M⊥= (lin M)⊥.
Since M ⊆[M] we know by the ﬁrst part of Lemma 16.1 that [M]⊥is contained
in M⊥. In order to show the converse M⊥⊆[M]⊥, take any y ∈M⊥. Every point
x ∈[M] can be represented as a limit x = limj→∞xj of points xj ∈lin M. Since
we know M⊥= (lin M)⊥we deduce as above that ⟨y, x⟩= limj→∞⟨y, xj⟩= 0.
This proves y ∈[M]⊥and we conclude.
2
From elementary Euclidean geometry we know that given any line in R3, i.e., a one
dimensional subspace of R3, we can write any vector x ∈R3 in precisely one way as a
sum of two vectors where one vector is the projection of x onto this line and the other
vector is perpendicular to it. A similar statements holds if a two dimensional plane is

16.1
Orthogonal Complements and Projections
229
given in R3. The following important result extends this orthogonal decomposition
to any Hilbert space.
Theorem 16.1 (Projection Theorem) Suppose M is a closed subspace of a Hilbert
space H. Every vector x ∈H has the unique representation
x = u + v,
u = u(x) ∈M,
v = v(x) ∈M⊥,
and one has
∥v∥= inf
y∈M ∥x −y∥= d(x, M)
where d(x, M) denotes the distance of the vector x from the subspace M. Or
equivalently,
H = M ⊕M⊥,
i.e., the Hilbert space H is the direct orthogonal sum of the closed subspace M and
its orthogonal complement M⊥.
Proof Given any x ∈H we have, for u ∈M,
∥x −u∥≥inf
v∈M ∥x −v∥≡d(x, M).
There is a sequence (un)n∈N ⊂M such that
d ≡d(x, M) = lim ∥x −un∥.
The parallelogram law (Lemma 15.2) implies that this sequence is actually a Cauchy
sequence as the following calculation shows:
∥un −um∥2
= ∥(un −x) + (x −um)∥2
= 2∥un −∥2 + 2∥x −um∥2 −∥(un −x) −(x −um)∥2
= 2∥un −x∥2 + 2∥x −um∥2 −4∥1
2(un + um) −x∥2.
Since un and um belong to M their convex combination 1
2(un + um) is an element of
M too and thus, by deﬁnition of d, ∥1
2(un + um) −x∥2 ≥d2. It follows that
0 ≤∥un −um∥2 ≤2∥un −x∥2 + 2∥x −um∥2 −4d2 →n,m→∞0.
Hence (un)n∈N ⊂M is a Cauchy sequence in the Hilbert space H and thus converges
to a unique element u ∈M = M since M is closed. By construction one has
d = lim
n→∞∥x −un∥= ∥x −u∥.
Next we show that the element v = x −u belongs to the orthogonal complement
of M. For y ∈M, y ̸= 0, introduce α = −⟨y,v⟩
⟨y,y⟩. For arbitrary z ∈M, we know
z −αy ∈M and thus in particular d2 ≤∥x −(u −αy)∥2 = ∥v + αy∥2 = ∥v∥2 +
|α|2∥y∥2 + ⟨v, αy⟩+ ⟨αy, v⟩, hence d2 ≤d2 −|⟨y,v⟩|2
∥y∥2
and this estimate implies

230
16
Geometry of Hilbert Spaces
⟨y, v⟩= 0. Since this argument applies to every y ∈M, y ̸= 0, we deduce that v
belongs to the orthogonal complement M⊥of M.
Finally, we show uniqueness of the decomposition of elements x ∈H into a
component u parallel to the closed subspace M and a component v orthogonal to it.
Assume that x ∈H has two such decompositions:
x = u1 + v1 = u2 + v2,
ui ∈M,
vi ∈M⊥,
i = 1, 2.
It follows that u1 −u2 = v2 −v1 ∈M ∩M⊥. By part 4 of Lemma 16.1 we conclude
u1 −u2 = v2 −v1 = 0 ∈H, hence this decomposition is unique.
2
Recall that in the Euclidean space R2 the shortest distance between a point x and
a line M is given by the distance between x and the point u on the line M which is
the intersection of the line M and the line perpendicular to M, through the point x.
The projection theorem says that this result holds in any Hilbert space and for any
closed linear subspace M.
As an easy consequence of the projection theorem one obtains a detailed de-
scription of the bi-orthogonal complement M⊥⊥of a set M which is deﬁned as the
orthogonal complement of the orthogonal complement of M, i.e., M⊥⊥= (M⊥)⊥.
Corollary 16.1 For any subset M in a Hilbert space H one has
M⊥⊥= [M]
and
M⊥⊥⊥≡(M⊥⊥)⊥= M⊥.
(16.1)
In particular, if M is a linear subspace, M⊥⊥= M, and if M is a closed linear
subspace M⊥⊥= M.
Proof Obviously one has M ⊂M⊥⊥. By Lemma 16.2 the bi-orthogonal comple-
ment of a set M is known to be a closed linear subspace of H, hence the closed linear
hull [M] of M is contained in M⊥⊥: [M] ⊆M⊥⊥.
Given any x ∈M⊥⊥there are u ∈[M] and v ∈[M]⊥such that x = u + v
(projection theorem). Since x −u ∈M⊥⊥−[M] ⊆M⊥⊥and [M]⊥= M⊥(Lemma
16.2), it follows that v = x −u ∈M⊥⊥∩M⊥. But this intersection is trivial by
Lemma 16.1, therefore x = u ∈[M]; this proves M⊥⊥⊆[M] and together with
the opposite inclusion shown above, M⊥⊥= [M]. In order to show the second part
we take the orthogonal complement of the identity we have just shown and apply
Lemma 16.2 to conclude M⊥⊥⊥= [M]⊥= M⊥.
2
Remark 16.1 Naturally one can ask whether the assumptions in the projection the-
orem can be weakened. By considering examples we see that this is not possible in
the case of inﬁnite dimensional spaces.
a) For a linear subspace of an inﬁnite dimensional Hilbert space which is not closed
or for a closed linear subspace of an inﬁnite dimensional inner product space
which is not complete, one can construct examples which show that in these
cases the projection theorem does not hold (see Exercises).
b) The projection theorem also does not hold for closed linear subspaces of a Banach
space which are not Hilbert spaces. In these cases, the uniqueness statement in
the projection theorem is not assured (see Exercises).

16.2
Gram Determinants
231
There is, however, a direction in which the projection theorem can be generalized.
One is allowed to replace the closed linear subspace M by a closed convex set M.
Recall that a subset M of a vector space is called convex if all the convex combinations
λx + (1 −λ)y, 0 ≤λ ≤1, belong to M whenever x, y do. Thus one arrives at the
projection theorem for closed convex sets. According to the methods used for its
proof we present this result in Part C on variational methods, Theorem 36.1.
Recall that a subset D of a Hilbert space H is called dense in H if every open ball
Br(x) ⊂H has a nonempty intersection with D, i.e., if the closure D of D is equal
to H. Closely related to dense subsets are the “total” subsets, i.e., those sets whose
linear hull is dense. They play an important role in the study of linear functions. The
formal deﬁnition reads:
Deﬁnition 16.3 A subset M of a Hilbert space H is called total if, and only if, the
closed linear hull of M equals H, i.e., in the notation introduced earlier, if, and only
if, [M] = H.
The results on orthogonal complements and their relation to the closed linear hull
give a very convenient and much used characterization of total sets.
Corollary 16.2
A subset M of a Hilbert space H is total if, and only if, the
orthogonal complement of M is trivial: M⊥= {0}.
Proof
If M is total, then [M] = H and thus [M]⊥= H⊥= {0}. Lemma 16.2
implies M⊥= {0}.
If conversely M⊥= {0}, then M⊥⊥= {0}⊥= H. But by Corollary 16.1 we
know [M] = M⊥⊥. Thus we conclude.
2
16.2
Gram Determinants
If we are given a closed subspace M of a Hilbert space H and a point x ∈H there is,
according to the projection theorem, a unique element of best approximation u ∈M,
i.e., an element u ∈M such that ∥x −u∥is minimal. In concrete applications, one
often has to calculate this element of best approximation explicitly. In general, this
is a rather difﬁcult task. However, if M is a ﬁnite dimensional subspace of a Hilbert
space, there is a fairly simple solution to this problem, based on the concept of Gram
determinants.
Suppose that M is a subspace of dimension n and with basis {x1, . . . , xn}. The
projection theorem implies: Given x ∈H there are a unique u = u(x) ∈M and a
unique v = v(x) ∈M⊥such that x = u + v. u ∈M has a unique representation
in terms of the elements of the basis: u = λ1x1 + · · · + λnxn, λj ∈K. Since
v = x −u ∈M⊥we know for k = 1, . . ., n that ⟨xk, x −u⟩= 0 or ⟨xk, x⟩= ⟨xk, u⟩.
Inserting the above representation of u ∈M we get a linear system for the unknown
coefﬁcients λ1, . . ., λn:
n

j=1
λj⟨xk, xj⟩= ⟨xk, x⟩
k = 1, . . ., n.
(16.2)

232
16
Geometry of Hilbert Spaces
The determinant of this linear system is called the Gram determinant. It is deﬁned
in terms of the inner products of basis elements x1, . . ., xn:
G(x1, . . ., xn) = det
⎛
⎜⎜⎜⎜⎜⎝
⟨x1, x1⟩
⟨x1, x2⟩
· · ·
⟨x1, xn⟩
⟨x2, x1⟩
⟨x2, x2⟩
· · ·
⟨x2, xn⟩
...
...
...
...
⟨xn, x1⟩
⟨xn, x2⟩
· · ·
⟨xn, xn⟩
⎞
⎟⎟⎟⎟⎟⎠
.
(16.3)
Certainly, the function G is well deﬁned for any ﬁnite number of vectors of an inner
product space.
Next we express the distance d = d(x, M) = ∥x −u∥= ∥v∥of the point x from
the subspace M in terms of the coefﬁcients λj: A straightforward calculation gives:
d2 = ∥x −u∥2 = ⟨x −u, x −u⟩= ⟨x, x −u⟩= ⟨x, x⟩−⟨x, u⟩
= ∥x∥2 −
n
j=1
λj⟨x, xj⟩.
This identity and the linear system (16.2) is written as one homogeneous linear
system for the coefﬁcients (λ0 = 1, λ1, . . ., λn):
(d2 −∥x∥2)λ0 +
n
j=1
λj⟨x, xj⟩
= 0,
−⟨xk, x⟩λ0 +
n
j=1
λj⟨xk, xj⟩
= 0,
k = 1, . . ., n.
(16.4)
By the projection theorem it is known that this homogeneous linear system has a
nontrivial solution (λ0, λ1, . . ., λn) ̸= (0, 0, . . ., 0). Hence the determinant of this
system vanishes, i.e.,
det
⎛
⎜⎜⎜⎜⎜⎝
⟨d2 −⟨x, x⟩
⟨x, x1⟩
· · ·
⟨x, xn⟩
−⟨x1, x⟩
⟨x1, x1⟩
· · ·
⟨x1, xn⟩
...
...
...
...
−⟨xn, x⟩
⟨xn, x1⟩
· · ·
⟨xn, xn⟩
⎞
⎟⎟⎟⎟⎟⎠
= 0.
Elementary properties of determinants thus give
d2G(x1, . . ., xn) −G(x, x1, . . ., xn) = 0.
(16.5)
The Gram determinant of two vectors is:
G(x1, x2) = ∥x1∥2∥x2∥2 −|⟨x1, x2⟩|2.
Schwarz’ inequality shows G(x1, x2) ≥0. Now an induction with respect to n ≥2,
using Eq. (16.5), proves the following theorem which gives in particular an explicit
way to calculate the distance of a point from a ﬁnite dimensional subspace.

16.3
The Dual of a Hilbert Space
233
Theorem 16.2 (Gram Determinants) In a Hilbert space H deﬁne the Gram
determinants by Eq. (16.3). Then the following holds:
1. G(x1, . . ., xn) ≥0 for all x1, . . ., xn ∈H;
2. G(x1, . . ., xn) = 0 ⇔{x1, . . ., xn} is a linearly independent set;
3. If x1, . . ., xn are linearly independent vectors in H, denote by [{x1, . . ., xn}] the
closed linear subspace generated by {x1, . . ., xn}. Then the distance of any point
x ∈H from the subspace [{x1, . . ., xn}] is
d = d(x, [{x1, . . ., xn}]) =
6
G(x, x1, . . ., xn)
G(x1, . . ., xm) .
(16.6)
The proof of this result and some generalizations of Schwarz’ inequality given by
part 1 of Theorem 16.2 are discussed in the Exercises.
16.3
The Dual of a Hilbert Space
Recall that the (topological) dual of a topological vector space V is deﬁned as the
space of all continuous linear functions T : V →K. In general it is not known
how to determine the form of the elements of the topological dual explicitly, even in
the case of Banach spaces. However, in the case of a Hilbert space H the additional
information that the norm is induced by an inner product sufﬁces to easily determine
the explicit form of continuous linear functions T : H →K. Recall that a linear
function T : H →K is continuous if, and only if, it is bounded, i.e., if, and only
if, there is some constant CT such that |T (x)| ≤CT ∥x∥for all x ∈H. Recall
furthermore that under pointwise addition and scalar multiplication the set of all
linear functions T : H →K is a vector space over the ﬁeld K (see Exercises). For
bounded linear functions T : H →K one deﬁnes
∥T ∥′ = sup {|T (x)| : x ∈H, ∥x∥≤1} .
(16.7)
In the Exercises it is shown that this deﬁnes a norm on the space H′ of all bounded
linear functions on H. Explicit examples of elements of H′ are all Tu, u ∈H, deﬁned
by
Tu(x) = ⟨u, x⟩
∀x ∈H.
(16.8)
The properties of inner products easily imply that the functions Tu, u ∈H, are linear.
Schwarz’inequality |⟨u, x⟩| ≤∥u∥∥x∥shows that these linear functions are bounded
and thus continuous. And it follows immediately that ∥Tu∥′ ≤∥u∥, for all u ∈H.
Since Tu(u) = ∥u∥2 one actually has equality in this estimate:
∥Tu∥′ = ∥u∥
∀u ∈H.
(16.9)

234
16
Geometry of Hilbert Spaces
The following theorem characterizes continuous linear functions on a Hilbert space
explicitly. This representation theorem says that all elements of H′ are of the form
Tu with some u ∈H.
Theorem 16.3 (Riesz–Fréchet) Let H be a Hilbert space over the ﬁeld K. A linear
function T : H →K is continuous if, and only if, there is a u ∈H such that T = Tu,
and one has ∥T ∥′ = ∥u∥.
Proof According to the discussion preceding the theorem we have to show that every
continuous linear functional T on the Hilbert space H is of the form Tu for some
u ∈H. If T = 0 is the null functional, choose u = 0. If T ̸= 0, then
M = ker T = T −1(0) = {x ∈H : T (x) = 0}
is a closed linear subspace of H which is not equal to H. This is shown in the Exer-
cises. It follows that the orthogonal complement M⊥of M is not trivial (Corollary
16.1) and the projection theorem states that the Hilbert space has a decomposi-
tion into two nontrivial closed linear subspaces: H = M ⊕M⊥. Hence there is a
v ∈M⊥such that T (v) ̸= 0 and thus, for every x ∈H we can deﬁne the element
u = u(x) = x −T (x)
T (v) v. Linearity of T implies T (u) = 0 and thus u ∈M, therefore
⟨v, u(x)⟩= 0 for all x ∈H, or
T (x) = T (v)
⟨v, v⟩⟨v, x⟩
∀x ∈H.
This proves T = Tu for the element
u = T (v)
⟨v, v⟩v ∈( ker T )⊥.
It follows that ∥T ∥′ = ∥Tu∥= ∥u∥.
Finally we show uniqueness of the element u ∈H which deﬁnes the given con-
tinuous linear function T by T = Tu. Suppose u, v ∈H deﬁne T by this relation.
Then Tu = Tv or ⟨u, x⟩= ⟨v, x⟩for all x ∈H and hence u −v ∈H⊥= {0}, i.e.,
u = v.
2
Corollary 16.3 A Hilbert space H and its (topological) dual H′ are isometrically
anti-isomorphic, i.e., there is an isometric map J : H →H′ which is antilinear.
Proof Deﬁne a map J : H →H′ by J(u) = Tu for all u ∈H where Tu is deﬁned
by Eq. (16.8). Thus J is well deﬁned and we know ∥J(u)∥′ = ∥Tu∥′ = ∥u∥. Hence
the map J is isometric. The deﬁnition of Tu easily implies
J(αu + βv) = αJ(u) + βJ(v)
∀α, β ∈K, ∀u, v ∈H,
i.e., the map J is antilinear. As an isometric map J is injective, and by the
Riesz–Fréchet Theorem we know that it is surjective. Hence J is an isometric
antiisomorphism.
2

16.3
The Dual of a Hilbert Space
235
Remark 16.2
1. The theorem of Riesz and Fréchet relies in a decisive way on the assumption of
completeness. This theorem does not hold in inner product spaces which are not
complete. An example is discussed in the Exercises.
2. The duality property of a Hilbert space H, i.e., H ⋍H′ is used in the bra- and
ket- vector notation of Dirac. For vectors u ∈H Dirac writes a ket vector |u >
and for elements Tv ∈H′ he writes the bra vector < v|. Bra vectors act on ket
vectors according to the relation < v|u >= Tv(u), u, v ∈H. In this notation the
projector Pψ onto the subspace spanned by the vector ψ is Pψ = |ψ >< ψ|.
Every continuous linear function T : H →K is of the form T = Tu for a unique
element u in the Hilbert space H, by Theorem 16.3. This implies the following
orthogonal decomposition of the Hilbert space: H = ker T ⊕Ku, i.e., the kernel
or null space of a continuous linear functional on a Hilbert space is a closed linear
subspace of co-dimension 1. This says in particular that a continuous linear functional
“lives” on the one dimensional subspace Ku. This is actually the case in the general
setting of locally convex topological vector spaces as the Exercises show.
The Theorem of Riesz and Fréchet has many other applications. We discuss here
an easy solution of the extension problem, i.e., the problem of ﬁnding a continuous
linear functional T on the Hilbert space H which agrees with a given continuous
linear functional T0 on a linear subspace M of H and which has the same norm as
T0.
Theorem 16.4 (ExtensionTheorem) Let M be a linear subspace of a Hilbert space
H and T0 : M →K a continuous linear functional, i.e., there is some constant C
such that |T0(x)| ≤C∥x∥for all x ∈M. Then there is exactly one continuous linear
functional T : H →K such that T |M = T0 and ∥T ∥′ = ∥T0∥′ where the deﬁnition
∥T0∥′ = sup {|T0(x)| : x ∈M, ∥x∥≤1}
is used.
Proof
The closure M of the linear subspace M is itself a Hilbert space, when
we use the restriction of the inner product ⟨·, ·⟩of H to M. This is shown as an
exercise. We show next that T0 has a unique extension T1 to a continuous linear
function M →K. Given x ∈M there is a sequence (xn)n∈N in M which converges
to x. Deﬁne T1(x) = lim T0(x). This limit exists since the ﬁeld K is complete and
(T0(xn))n∈N is a Cauchy sequence in K: We have the estimate |T0(xn) −T0(xm)| =
|T0(xn −xm)| ≤C∥xn −xm∥, and we know that (xn)n∈N is a Cauchy sequence in the
Hilbert space M. If we take another sequence (yn)n∈N in M with limit x we know
|T0(xn) −T0(yn)| = |T0(xn −yn)| ≤C∥xn −yn∥→0 as n →∞and thus both
sequences give the same limit T1(x). It follows that
∥T1∥′ = sup

|T1(x)| : x ∈M, ∥x∥≤1

= sup

|T0(x)| : x ∈M, ∥x∥≤1 = ∥T0∥′
≤C.
The second identity is shown in the Exercises.

236
16
Geometry of Hilbert Spaces
The Theorem of Riesz–Fréchet implies: There is exactly one v ∈M such that
T1(u) = ⟨v, u⟩for all u ∈M and ∥T1∥′ = ∥v∥. Since the inner product is actually
deﬁned on all of H, we get an easy extension T of T1 to the Hilbert space H by
deﬁning T (x) = ⟨v, x⟩for all x ∈H and it follows that ∥T ∥′ = ∥v∥= ∥T0∥′.
This functional T is an extension of T0 since for all u ∈M one has T (u) =
⟨v, u⟩= T1(u) = T0(u), by deﬁnition of T1.
Suppose that S is a continuous linear extension of T0. As a continuous linear
functional on H this extension is of the form S(x) = ⟨y, x⟩, for all x ∈H, with a
unique y ∈H. And, since S is an extension of T0, we know S(u) = T0(u) = ⟨v, u⟩
for all u ∈M and thus for all u ∈M. This shows ⟨y −v, u⟩= 0 for all u ∈M,
hence y −v ∈M⊥, and we deduce ∥S∥′ = ∥y∥=

∥v∥2 + ∥y −v∥2. Hence this
extension S satisﬁes ∥S∥′ = ∥T0∥′ = ∥v∥if, and only if, y −v = 0, i.e., if, and only
if, S = T = Tv, and we conclude.
2
Methods and results from the theory of Hilbert spaces and their operators are used
in various areas of mathematics. We present here an application of Theorem 16.4 to
a problem from distribution theory, namely to prove the existence of a fundamental
solution for a special constant coefﬁcient partial differential operator. Earlier we
had used Fourier transformation for distributions to ﬁnd a fundamental solution for
this type of differential operator. The proof of the important Theorem 8.2 follows a
similar strategy.
Corollary 16.4 The linear partial differential operator with constant coefﬁcients
1 −△n
in
Rn
has a fundamental solution in S′(Rn).
Proof Consider the subspace M = (1−△n)D(Rn) of the Hilbert space H = L2(Rn)
and deﬁne a linear functional T0 : M →K by
T0((1 −△n)φ) = φ(0)
∀φ ∈D(Rn).
Applying Lemma 10.1 to the inverse Fourier transformation one has the estimate
|φ(0)| ≤∥φ∥∞≤(2π)−n
2 ∥Fφ∥1.
If 2m > n, then the function p #→(1 + p2)−m belongs to the Hilbert space L2(Rn),
and we can use Schwarz’ inequality to estimate the norm of ˜φ = Fφ as follows:
∥˜φ∥1 = ∥(1 + p2)−m · (1 + p2)m ˜φ∥1 ≤∥(1 + p2)−m∥2∥(1 + p2)m ˜φ∥2.
By theorems 10.7 and 10.2 we know ∥(1 + p2)m ˜φ∥2 = ∥(1 −△n)mφ∥2 and thus the
estimate
|φ(0)| ≤C∥(1 −△n)mφ∥2
∀φ ∈D(Rn)
follows, with a constant C which is given by the above calculations. This estimate
shows ﬁrst that the functional T0 is well deﬁned on M. It is easy to see that T0 is

16.4
Exercises
237
linear. Now the above estimate also implies that T0 is continuous. Hence the above
extension theorem can be applied, and thus there is u ∈L2(Rn) such that
T0((1 −△n)mφ) = ⟨u, (1 −△n)mφ⟩2 =

Rn u(x)(1 −△n)mφ(x) d x
for all φ ∈D(Rn). By deﬁnition of T0 this shows that

Rn u(x)(1 −△n)mφ(x) d x = φ(0),
i.e., the distribution E = (1 −△n)m−1u is a fundamental solution of the operator
1 −△n. Since u ∈L2(Rn) the distribution E = (1 −△n)m−1u is tempered, and we
conclude.
2
16.4
Exercises
1. Prove Lemma 16.1.
2. Prove the ﬁrst two parts of Lemma 16.2.
3. Find an example supporting the ﬁrst part of Remark 16.1.
4. Consider the Euclidean space R2, but equipped with the norm ∥x∥= |x1| + |x2|
for x = (x1, x2) ∈R2. Show that this is a Banach space but not a Hilbert space.
Consider the point x = (−r
2, r
2) for some r > 0 and the closed linear subspace
M =

x ∈R2 : x1 = x2

. Prove that this point has the distance r from the
subspace M, i.e., inf {∥x −u∥: u ∈M} = r and that there are inﬁnitely many
points u ∈M such that ∥x −u∥= r. Conclude that the projection theorem does
not hold for Banach spaces which are not Hilbert spaces (compare with part b)
of Remark 16.1).
5. Prove Theorem 16.2.
6. For three vectors x, y, z in a Hilbert space H, calculate the Gram determinant
G(x, y, z) explicitly and discuss in detail the inequality 0 ≤G(x, y, z). Consider
some special cases: x ⊥y, x⊥z, or y⊥z.
7. For a nontrivial continuous linear function T : H →K on a Hilbert space H
show that its null-space ker T is a proper closed linear subspace of H.
8. Consider the space of all terminating sequences of elements in K:
ℓ2
e(K) =

x = (x1, x2, . . . , xN, 0, 0, . . .) : xj ∈K, N = N(x) ∈N

.
Obviously one has ℓ2
e(K) ⊂ℓ2(K) and it is naturally a vector space over the ﬁeld
K; as an inner product on ℓ2
e(K) we take ⟨x, y⟩2 = ∞
j=1 xjyj. Consider the
sequence u = (1, 1
2, 1
3, . . . , 1
n, . . .) ∈ℓ2(K) and use it to deﬁne a linear function

238
16
Geometry of Hilbert Spaces
T = Tu : ℓ2
e(K) →K by
T (x) = ⟨u, x⟩2 =
∞

n=1
1
nxn.
This function is continuous by Schwarz’ inequality: |T (x)| ≤∥u∥2∥x∥2 for all
x ∈ℓ2
e(K). Conclude that the theorem of Riesz–Fréchet does not hold for the
inner product space ℓ2
e(K).
9. For a linear subspace M of a Hilbert space H with inner product ⟨·, ·⟩show:
The closure M of M is a Hilbert space when equipped with the restriction of the
inner product ⟨·, ·⟩to M.
10. Prove the identity
sup

|T1(x)| : x ∈M, ∥x∥≤1

= sup {|T0(x)| : x ∈M, ∥x∥≤1}
used in the proof of Theorem 16.4.
11. Give an example of a linear functional which is not continuous.
Hints: Consider the real vector space V of all real polynomials P on the interval
I = [0, 1], take a point a ̸∈I, for instance a = 2, and deﬁne Ta : V →R by
Ta(P ) = P (a) for all P ∈V . Show that Ta is not continuous with respect to the
norm ∥P ∥= supx∈I |P(x)| on V .

Chapter 17
Separable Hilbert Spaces
Up to now we have studied results which are available in any Hilbert space. Now
we turn our attention to a very important subclass which one encounters in many
applications, in mathematics as well as in physics. This subclass is characterized by
the property that the Hilbert space has a countable basis deﬁned in a way suitable
for Hilbert spaces. Such a “Hilbert space basis” plays the same role as a coordinate
system in a ﬁnite dimensional vector space.
Recall that two ﬁnite dimensional vector spaces are isomorphic if, and only if, they
have the same dimension. Similarly, Hilbert spaces are characterized up to isomorphy
by the cardinality of their Hilbert space basis. Those Hilbert spaces which have a
countable Hilbert space basis are called separable.
In a ﬁrst section we introduce and discuss the basic concepts and results in the
theory of separable Hilbert spaces. Then a special class of separable Hilbert spaces
is investigated. For this subclass the Hilbert space basis is deﬁned in an explicit way
through a given weight function and an orthogonalization procedure. These spaces
play an important role in the study of differential operators, in particular in quantum
mechanics.
17.1
Basic Facts
As indicated above, the concept of a Hilbert space basis differs from the concept of
a basis in a vector space. The point which distinguishes these two concepts is that
for the deﬁnition of a Hilbert space basis a limit process is used.
We begin by recalling the concept of a basis in a vector space V over the ﬁeld K.
A nonempty subset A ⊂V is called linearly independent if, and only if, every ﬁnite
subset {x1, . . ., xn} ⊂A, n ∈N, is linearly independent. A ﬁnite subset {x1, . . ., xn},
xi ̸= xj for i ̸= j is called linearly independent if, and only if, n
i=1 λixi = 0,
λi ∈K, implies λ1 = λ2 = · · · = λn = 0, i.e., the only way to write the null
vector 0 of V as a linear combination of the vectors x1, . . ., xn is the trivial one with
λi = 0 ∈K for i = 1, . . ., n.
© Springer International Publishing Switzerland 2015
239
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_17

240
17
Separable Hilbert Spaces
The set of all vectors in V , which can be written as some linear combination of
elements in the given nonempty subset A is called the linear hull lin A of A (see
Deﬁnition 16.2), i.e.,
lin A =

x ∈V : x =
n

i=1
λixi, xi ∈A, λi ∈K, n ∈N

.
It is the smallest linear subspace which contains A. A linearly independent subset
A ⊂V which generates V , i.e., lin A = V , is called a basis of the vector space V .
A linearly independent set A ⊂V is called maximal if, and only if, for any linearly
independent subset A′ the relation A ⊂A′ implies A = A′. In this sense a basis is a
maximal linearly independent subset. This means: If one adds an element x of V to
a basis B, then the resulting subset B ∪{x} is no longer linearly independent. With
the help of Zorn’s Lemma (or the axiom of choice) one can prove that every vector
space has a basis. Such a basis is a purely algebraic concept and is often called a
Hamel basis.
In 1927, J. Schauder introduced the concept of Hilbert space basis or a basis of a
Hilbert space, which takes the topological structure of a Hilbert space into account
as expressed in the following deﬁnition:
Deﬁnition 17.1 Let H be a Hilbert space over the ﬁeld K and B a subset of H.
1. B is called a Hilbert space basis of H if, and only if, B is linearly independent
in the vector space H and B generates H in the sense that [B] = lin B = H.
2. The Hilbert space H is called separable if, and only if, it has a countable Hilbert
space basis B = {xn ∈H : n ∈N} (or a ﬁnite basis B = {x1, . . ., xN} for some
N ∈N).
3. An orthonormal system B = {xα ∈H : α ∈A} in H, which is a Hilbert space
basis is called an orthonormal basis or ONB of H.
It is important to realize that in general a Hilbert space basis is not an algebraic basis!
For instance in the case of a separable Hilbert space a general element in H is known
to have a representation as a series ∞
n=1 λnxn in the elements xn of the basis but not
as a linear combination.
Often a separable Hilbert space is deﬁned as a Hilbert space, which has a countable
dense subset. Sometimes this deﬁnition is more convenient. The equivalence of both
deﬁnitions is shown in the Exercises.
In the original deﬁnition of a Hilbert space the condition of separability was
included. However in 1934 F. Rellich and F. Riesz pointed out that for most parts of
the theory the separability assumption is not needed.
Nevertheless, most Hilbert spaces that one encounters in applications are separa-
ble. In the Exercises we discuss an example of a Hilbert space which is not separable.
This is the space of almost-periodic functions on the real line R.
As we know from the Euclidean spaces Rn it is in general a great advantage in
many problems to work with an orthonormal basis {e1, . . ., en} instead of an arbitrary
basis. Here ei is the standard unit vector along coordinate axis i. In a separable inﬁnite

17.1
Basic Facts
241
dimensional Hilbert space the corresponding basis is an orthonormal Hilbert space
basis, or ONB. The proof of the following result describes in detail how to construct
an ONB given any Hilbert space basis. Only the case of a separable Hilbert space
is considered since this is the case which is needed in most applications. Using the
axiom of choice one can also prove the existence of an orthonormal basis in the
case of a nonseparable Hilbert space. In the second section of this chapter we use
this construction to generate explicitly ONB’s for concrete Hilbert spaces of square
integrable functions.
Theorem 17.1 (Gram–Schmidt Orthonormalization) Every separable Hilbert
space H has an orthonormal basis B.
Proof By deﬁnition of a separable Hilbert space there is a countable Hilbert space
basis B = {yn : n ∈N} ⊂H (or a ﬁnite basis; we consider explicitly the ﬁrst
case). Deﬁne z1 = y1; since B is a basis we know ∥y1∥> 0 and hence the vector
z2 = y2 −⟨z1,y2⟩
⟨z1,z1⟩z1 is well-deﬁned in H. One has z1 ⊥z2 since ⟨z1, z2⟩= 0. As
elements of the basis B the vectors y1 and y2 are linearly independent, therefore the
vector z2 is not the null vector, and certainly the set of vectors {z1, z2} generates the
same linear subspace as the set of vectors {y1, y2}: [{z1, z2}] = [{y1, y2}].
We proceed by induction and assume that for some N ∈N, N ≥2 the set of
vectors {z1, . . ., zN} is well-deﬁned and has the following properties:
a) ∥zj∥> 0 for all j = 1, . . ., N
b) ⟨zi, zj⟩= 0 for all i, j ∈{1, . . ., N}, i ̸= j
c) The set {z1, . . ., zN} generates the same linear subspace as the set {y1, . . ., yN},
i.e., [{z1, . . ., zN}] = [{y1, . . ., yN}].
This allows us to deﬁne
zN+1 = yN+1 −
N

i=1
⟨zi, yN+1⟩
⟨zi, zi⟩zi.
The orthogonality condition (b) easily implies ⟨zj, zN+1⟩= 0 for j = 1, . . ., N.
Hence, the set of vectors {z1, . . ., zN, zN+1} is pairwise orthogonal too. From the
deﬁnition of the vector zN+1 it is clear that [{z1, . . ., zN+1}] = [{y1, . . ., yN+1}] holds.
Finally, since the vector yN+1 is not a linear combination of the vectors y1, . . ., yN
the vector zN+1 is not zero. This shows that the set of vectors {z1, . . ., zN, zN+1} too
has the properties (a), (b), and (c). By the principle of induction we conclude: There
is a set of vectors {zk ∈H : k ∈N} such that ⟨zj, zk⟩= 0 for all j, k ∈N, j ̸= k and
[{zk : k ∈N}] = [{yk : k ∈N}] = H. Finally we normalize the vectors zk to obtain
an orthonormal basis B = {ek : k ∈N}, ek =
1
∥zk∥zk.
2
Theorem 17.2 (Characterization of ONB’s) Let B = {xn : n ∈N} be an or-
thonormal system in a separable Hilbert space H. The following statements are
equivalent.
a) B is maximal (or complete), i.e., an ONB.
b) For any x ∈H the condition “⟨xn, x⟩= 0 for all n ∈N” implies x = 0.

242
17
Separable Hilbert Spaces
c) Every x ∈H has the Fourier expansion
x =
∞

n=1
⟨xn, x⟩xn.
d) For all vectors x, y ∈H the completeness relation
⟨x, y⟩=
∞

n=1
⟨x, xn⟩⟨xn, y⟩
holds.
e) For every x ∈H the Parseval relation
∥x∥2 =
∞

n=1
|⟨xn, x⟩|2
holds.
Proof (a) ⇒(b): Suppose that there is a z ∈H, z ̸= 0, with the property ⟨xn, z⟩= 0
for all n ∈N. Then B′ = { z
∥z∥, x1, x2, . . . } is an orthonormal system in H in which
B is properly contained, contradicting the maximality of B. Hence there is no such
vector z ∈H and statement (b) follows.
(b) ⇒(c): Given x ∈H introduce the sequence x(N) = N
n=1⟨xn, x⟩xn. Bessel’s
inequality (Corollary 15.1) shows that ∥x(N)∥2 = N
n=1 |⟨xn, x⟩|2 ≤∥x∥2 for all
N ∈N. Hence, the inﬁnite series ∞
n=1 |⟨xn, x⟩|2 converges and its value is less than
or equal to ∥x∥2. For all M < N we have ∥x(N) −x(M)∥2 = N
n=M+1 |⟨xn, x⟩|2
and the convergence of the series ∞
n=1 |⟨xn, x⟩|2 implies that (x(N))N∈N is a Cauchy
sequence. Hence this sequence converges to a unique point y ∈H,
y = lim
N→∞x(N) =
∞

n=1
⟨xn, x⟩xn.
Since, the inner product is continuous we deduce that ⟨xn, y⟩= limN→∞⟨xn, x(N)⟩=
⟨xn, x⟩for all n ∈N. Therefore ⟨xn, x −y⟩= 0 for all n ∈N and hypothesis (b)
implies x −y = 0, hence statement (c) follows.
(c) ⇒(d): According to statement (c) any vector x ∈H has a Fourier expansion,
x = ∞
n=1⟨xn, x⟩xn, similarly for y ∈H: y = ∞
n=1⟨xn, y⟩xn. Continuity of the
inner product and orthonormality of {xn : n ∈N} imply the completeness relation:
⟨x, y⟩=
∞

n=1
⟨xn, x⟩⟨xn, y⟩=
∞

n=1
⟨x, xn⟩⟨xn, y⟩.
(d) ⇒(e): Obviously, statement (e) is just the special case x = y of statement (d).

17.1
Basic Facts
243
(e) ⇒(a): Suppose that the system B is not maximal. Then we can add one unit
vector z ∈H to it which is orthogonal to B. Now Parseval’s relation (e) gives the
contradiction
1 = ∥z∥2 =
∞

n=1
|⟨xn, z⟩|2 =
∞

n=1
0 = 0.
Therefore, when Parseval’s relation holds for every x ∈H, the system B is maximal.
2
As a ﬁrst application of the characterization of an orthonormal basis we deter-
mine explicitly the closed linear hull of an orthonormal system (ONS). As a simple
consequence one obtains a characterization of separable Hilbert spaces.
Corollary 17.1
Let {xn : n ∈N} be an orthonormal system in a Hilbert space
over the ﬁeld K. Denote the closed linear hull of this system by M, i.e., M =
[{xn : n ∈N}]. Then, the following holds:
1. M = {xc ∈H : xc = ∞
n=1 cnxn, c = (cn)n∈N ∈ℓ2(K)}.
2. The mapping U : ℓ2(K) →M, deﬁned by Uc = xc = ∞
n=1 cnxn, is an
isomorphism and one has
⟨Uc, Uc′⟩H = ⟨c, c′⟩ℓ2(K)
∀c, c′ ∈ℓ2(K).
Proof
For c = (cn)n∈N ∈ℓ2(K) deﬁne a sequence x(N) = N
n=1 cnxn ∈
lin {xn : n ∈N} in the Hilbert space H. Since {xn : n ∈N} is an orthonormal system
one has for all N, M ∈N, M < N, ∥x(N) −x(M)∥2 = N
n=M+1 |cn|2. It follows that
(x(N))N∈N is a Cauchy sequence in the Hilbert space H and thus it converges to
xc =
lim
N−→∞x(N) =
∞

n=1
cnxn ∈H.
Obviously, xc belongs to the closure M of the linear hull of the given orthonormal
system. Hence ℓ2(K) ∋c #→xc deﬁnes a map U from ℓ2(K) into M. This map
is linear as one easily shows. Under the restriction of the inner product of H the
closed linear subspace M is itself a Hilbert space which has, by deﬁnition, the given
ONS as a Hilbert space basis. Therefore, by Theorem 17.2, for every x ∈M one
has x = ∞
n=1⟨xn, x⟩Hxn and ∥x∥2
H = ∞
n=1 |⟨xn, x⟩H|2. Hence every x ∈M is
the image of the sequence c = (⟨xn, x⟩H)n∈N ∈ℓ2(K) under the map U, i.e., U is
a linear map from ℓ2(K) onto M, and the inverse map of U is the map M ∋x #→
U −1x = (⟨xn, x⟩H)n∈N ∈ℓ2(K).
For c = (cn)n∈N ∈ℓ2(K) we calculate ⟨xn, Uc⟩H = cn for all n ∈N and thus by
the completeness relation of Theorem 17.2
⟨Uc, Uc′⟩H =
∞

n=1
cnc′
n = ⟨c, c′⟩ℓ2(K)
∀c, c′ ∈ℓ2(K).
In particular one has ∥Uc∥H = ∥c∥ℓ2(K) for all c ∈ℓ2(K). Thus U is a bijective
continuous linear map with continuous inverse, which does not change the values of
the inner products, i.e., an isomorphism of Hilbert spaces.
2

244
17
Separable Hilbert Spaces
Corollary 17.2 Every inﬁnite dimensional separable Hilbert space H over the ﬁeld
K is isomorphic to the sequence space ℓ2(K).
Proof If{xn : n ∈N}isanorthonormalbasisweknowthattheclosedlinearsubspace
M generated by this basis is equal to the Hilbert space H. Hence, by the previous
corollary we conclude.
2
Later we will learn that, for instance, the Lebesgue space L2(Rn, dx) is a separable
Hilbert space. According to Corollary 17.2 this Lebesque space is isomorphic to the
sequence space ℓ2(K). Why then is it important to study other separable Hilbert
spaces than the sequence space ℓ2(K)? These other separable Hilbert spaces have,
just as the Lebesgue space, an additional structure which is lost if they are realized as
sequence spaces. While linear partial differential operators, for instance Schrödinger
operators, can be studied conveniently in the Lebesgue space, this is in general not
the case in the sequence space. In the second section of this chapter we will construct
explicitlyanorthonormalbasisforHilbertspacesL2(I)ofsquareintegrablefunctions
over some interval I. It turns out that the elements of the ONB’s constructed there,
are “eigenfunctions” of important differential operators.
The results on the characterization of an orthonormal basis are quite powerful. We
illustrate this with the example of the theory of Fourier expansions in the Hilbert
space L2([0, 2π], dx).
We begin by recalling some classical results. For integrable functions on the
interval [0, 2π] the integrals
cn = cn(f ) =
1
√
2π
 2π
0
e−inxf (x) dx = ⟨en, f ⟩2
are well-deﬁned. In the Exercises one shows that the system of functions en, n ∈Z,
en(x) = einx
√
2π , is an orthonormal system in the Hilbert space L2([0, π], dx). With the
above numbers cn one forms the Fourier series
+∞

n=−∞
cn(f )en
of the function f. A classical result from the theory of Fourier series reads (see [1]):
If f is continuously differentiable on the interval [0, 2π], then the Fourier series
converges uniformly to f , i.e., the sequence of partial sums of the Fourier series
converges uniformly to f . This implies in particular
lim
N→∞∥f −
N

n=−N
cn(f )en∥2 = 0
for all f ∈C1([0, π]).
We claim that the system {en : n ∈Z} is actually an orthonormal basis of
L2([0, 2π], dx). For the proof take any g ∈L2([0, 2π], dx) with the property

17.2
Weight Functions and Orthogonal Polynomials
245
⟨en, g⟩2 = 0 for all n ∈Z. From the above convergence result we deduce, for
all f ∈C1([0, 2π]),
⟨f , g⟩2 = lim
N→∞⟨
N

n=−N
cn(f )en, g⟩2 = 0.
Since C1([0, 2π]) is known to be dense in L2([0, 2π], dx) it follows that g = 0,
by Corollary 17.2, hence by Theorem 17.2, this system is an orthonormal basis
of L2([0, 2π], dx). Therefore, every f ∈L2([0, 2π], dx) has a Fourier expansion,
which converges (in the sense of the L2-topology). Thus, convergence of the Fourier
series in the L2-topology is “natural,” from the point of view of having convergence
of this series for the largest class of functions.
17.2
Weight Functions and Orthogonal Polynomials
Not only for the interval I = [0, 2π] are the Hilbert spaces L2(I, dx) separable,
but for any interval I = [a, b], −∞≤a < b ≤+∞, as the results of this section
will show. Furthermore an orthonormal basis will be constructed explicitly and some
interesting properties of the elements of such a basis will be investigated.
The starting point is a weight function ρ : I→R on the interval I which is assumed
to have the following properties:
1. On the interval I, the function ρ is strictly positive: ρ(x) > 0 for all x ∈I.
2. If the interval I is not bounded, there are two positive constants α and C such
that ρ(x) eα|x| ≤C for all x ∈I.
The strategy to prove that the Hilbert space L2(I, dx) is separable is quite simple. A
ﬁrst step shows that the countable set of functions ρn(x) = xnρ(x), n = 0, 1, 2, . . .
is total in this Hilbert space. The Gram–Schmidt orthonormalization then produces
easily an orthonormal basis.
Lemma 17.1 The system of functions {ρn : n = 0, 1, 2, . . . } is total in the Hilbert
space L2(I, dx), for any interval I.
Proof Fortheproofwehavetoshow: Ifanelementh ∈L2(I, dx)satisﬁes⟨ρn, h⟩2 =
0 for all n, then h = 0.
In the case I ̸= R we consider h to be be extended by 0 to R\I and thus get a
function h ∈L2(R, dx). On the strip Sα = {p = u + iv ∈C : u, v ∈R, |v| < α},
introduce the auxiliary function
F(p) =

R
ρ(x)h(x) eipx dx.
The growth restriction on the weight function implies that F is a well-deﬁned holo-
morphic function on Sα (see Exercises). Differentiation of F generates the functions

246
17
Separable Hilbert Spaces
ρn in this integral:
F (n)(p) = dnF
dpn (p) = in

R
h(x)ρ(x)xneipx dx
for n = 0, 1, 2, . . . , and we deduce F (n)(0) = in⟨ρn, h⟩2 = 0 for all n. Since F is
holomorphic in the strip Sα it follows that F(p) = 0 for all p ∈Sα (see Theorem
9.5) and thus in particular F(p) = 0 for all p ∈R. But F(p) =
√
2πL(ρh)(p)
where L is the inverse Fourier transform (see Theorem 10.1), and we know
⟨Lf , Lg⟩2 = ⟨f , g⟩2 for all f , g ∈L2(R, dx) (Theorem 10.7). It follows that
⟨ρh, ρh⟩2 = ⟨L(ρh), L(ρh)⟩2 = 0 and thus ρh = 0 ∈L2(R, dx). Since ρ(x) > 0
for x ∈I this implies h = 0 and we conclude.
2
Technically it is simpler to do the orthonormalization of the system of functions
{ρn : n ∈N} not in the Hilbert space L2(I, dx) directly but in the Hilbert space
L2(I, ρdx), which is deﬁned as the space of all equivalence classes of measurable
functions f : I→K such that

I |f (x)|2ρ(x) dx < ∞equipped with the inner prod-
uct ⟨f , g⟩ρ =

I f (x)g(x)ρ(x) dx. Note that the relation ⟨f , g⟩ρ = ⟨√ρf , √ρg⟩2
holds for all f , g ∈L2(I, ρdx). It implies that the Hilbert spaces L2(I, ρdx) and
L2(I, dx) are (isometrically) isomorphic under the map
L2(I, ρdx) ∋f #→√ρf ∈L2(I, dx).
This is shown in the Exercises. Using this isomorphism, Lemma 17.1 can be restated
as saying that the system of powers of x, {xn : n = 0, 1, 2, . . .} is total in the Hilbert
space L2(I, ρdx).
We proceed by applying the Gram–Schmidt orthonormalization to the system of
powers {xn : n = 0, 1, 2, . . . } in the Hilbert space L2(I, ρdx). This gives a sequence
of polynomials Pk of degree k such that ⟨Pk, Pm⟩ρ = δkm. These polynomials are
deﬁned recursively in the following way: Q0(x) = x0 = 1, and when for k ≥1 the
polynomials Q0, . . ., Qk−1 are deﬁned, we deﬁne the polynomial Qk by
Qk(x) = xk −
k−1

n=0
⟨Qn, xk⟩ρ
⟨Qn, Qn⟩ρ
Qn.
Finally, the polynomials Qk are normalized and we arrive at an orthonormal system
of polynomials Pk:
Pk =
1
∥Qk∥ρ
Qk,
k = 0, 1, 2, . . . .
Note that according to this construction, Pk is a polynomial of degree k with positive
coefﬁcient for the power xk. Theorem 17.1 and Lemma 17.1 imply that the system
of polynomials {Pk : k = 0, 1, 2, . . . } is an orthonormal basis of the Hilbert space
L2(I, ρdx). If we now introduce the functions
ek(x) = Pk(x)

ρ(x),
x ∈I
we obtain an orthonormal basis of the Hilbert space L2(I, dx). This shows Theorem
17.3.

17.2
Weight Functions and Orthogonal Polynomials
247
Theorem 17.3 For any interval I = (a, b), −∞≤a < b ≤+∞the Hilbert space
L2(I, dx) is separable, and the above system {ek : k = 0, 1, 2, . . .} is an orthonormal
basis.
Proof Only the existence of a weight function for the interval I has to be shown.
Then by the preceding discussion we conclude. A simple choice of a weight function
for any of these intervals is for instance the exponential function ρ(x) = e−αx2,
x ∈R, for some α > 0.
2
Naturally, the orthonormal polynomials Pk depend on the interval and the weight
function. After some general properties of these polynomials have been studied we
will determine the orthonormal polynomials for some intervals and weight functions
explicitly.
Lemma 17.2 If Qm is a polynomial of degree m, then ⟨Qm, Pk⟩ρ = 0 for all k > m.
Proof
Since {Pk : k = 0, 1, 2, . . .} is an ONB of the Hilbert space L2(I, ρdx) the
polynomial Qm has a Fourier expansion with respect to this ONB: Qm = ∞
n=0 cnPn,
cn = ⟨Pn, Qm⟩ρ. Since the powers xk, k = 0, 1, 2, . . . are linearly independent
functions on the interval I and since the degree of Qm is m and that of Pn is n, the
coefﬁcients cn in this expansion must vanish for n > m, i.e., Qm = m
n=0 cnPn and
thus ⟨Pk, Qm⟩ρ = 0 for all k > m.
2
Since, the orthonormal system {Pk : k = 0, 1, 2, . . . } is obtained by the Gram–
Schmidt orthonormalization from the system of powers xk for k = 0, 1, 2, . . . with
respect to the inner product ⟨·, ·⟩ρ, the polynomial Pn+1 is generated by multiplying
the polynomial Pn with x and adding some lower order polynomial as correction.
Indeed one has
Proposition 17.1
Let ρ be a weight for the interval I = (a, b) and denote the
complete system of orthonormal polynomials for this weight and this interval by
{Pk : k = 0, 1, 2, . . . }. Then, for every n ≥1, there are constants An, Bn, Cn such
that
Pn+1(x) = (Anx + Bn)Pn(x) + CnPn−1(x)
∀x ∈I.
Proof We know Pk(x) = akxk + Qk−1(x) with some constant ak > 0 and some
polynomial Qk−1 of degree smaller than or equal to k −1. Thus, if we deﬁne An =
an+1
an , it follows that Pn+1 −AnxPn is a polynomial of degree smaller than or equal
to n, hence there are constants cn,k such that
Pn+1 −AnxPn =
n

k=0
cn,kPk.
Now calculate the inner product with Pj, j ≤n:
⟨Pj, Pn+1 −AnxPn⟩ρ =
n

k=0
cn,k⟨Pj, Pk⟩ρ = cn,j.

248
17
Separable Hilbert Spaces
Since the polynomial Pk is orthogonal to all polynomials Qj of degree j ≤k −1
we deduce that cn,j = 0 for all j < n −1, cn,n−1 = −An⟨xPn−1, Pn⟩ρ, and cn,n =
−An⟨xPn, Pn⟩ρ. The statement follows by choosing Bn = cn,n and Cn = cn,n−1.
2
Proposition 17.2 For any weight function ρ on the interval I, the kth orthonormal
polynomial Pk has exactly k simple real zeroes.
Proof Per construction the orthonormal polynomials Pk have real coefﬁcients, have
the degree k, and the coefﬁcient ck is positive. The fundamental theorem of algebra
(Theorem 9.4) implies: The polynomial Pk has a certain number m ≤k of simple
real roots x1, . . ., xm and the roots which are not real occur in pairs of complex
conjugate numbers, (zj, zj), j = m + 1, . . ., M with the same multiplicity nj, m +
2 M
j=m+1 nj = k. Therefore the polynomial Pk can be written as
Pk(x) = ck
m
.
j=1
(x −xj)
M
.
j=m+1
(x −zj)nj (x −zj)nj .
Consider the polynomial Qm(x) = ck
/m
j=1 (x −xj). It has the degree m and ex-
actly m real simple roots. Since Pk(x) = Qm(x) /M
j=m+1 |x −zj|2nj , it follows that
Pk(x)Qm(x) ≥0 for all x ∈I and PkQm ̸= 0, hence ⟨Pk, Qm⟩ρ > 0. If the degree
m of the polynomial Qm would be smaller than k, we would arrive at a contradiction
to the result of the previous lemma, hence m = k and the pairs of complex conjugate
roots cannot occur. Thus we conclude.
2
In the Exercises, with the same argument, we prove the following extension of
this proposition.
Lemma 17.3 The polynomial Qk(x, λ) = Pk(x)+λPk−1(x) has k simple real roots,
for any λ ∈R.
Lemma 17.4 There are no points x0 ∈I and no integer k ≥0 such that Pk(x0) =
Pk−1(x0) = 0.
Proof Suppose that for some k ≥0 the orthonormal polynomials Pk and Pk−1 have a
common root x0 ∈I: Pk(x0) = Pk−1(x0) = 0. Since we know that these orthonormal
polynomials have simple real roots, we know in particular P ′
k−1(x0) ̸= 0 and thus
we can take the real number λ0 =
−P ′
k(x0)
P ′
k−1(x0) to form the polynomial Qk(x, λ0) =
Pk(x) + λ0Pk−1(x). It follows that Q(x0, λ0) = 0 and Q′
k(x0) = 0, i.e., x0 is a root
of Qk(·, λ) with multiplicity at least two. But this contradicts the previous lemma.
Hence there is no common root of the polynomials Pk and Pk−1.
2
Theorem 17.4 (Knotensatz) Let {Pk : k = 0, 1, 2, . . . } be the orthonormal basis for
some interval I and some weight function ρ. Then the roots of Pk−1 separate the
roots of Pk, i.e., between two successive roots of Pk there is exactly one root of Pk−1.
Proof
Suppose that α < β are two successive roots of the polynomial Pk so that
Pk(x) ̸= 0 for all x ∈(α, β). Assume furthermore that Pk−1 has no root in the open
interval (α, β). The previous lemma implies that Pk−1 does not vanish in the closed

17.3
Examples of Complete Orthonormal Systems for L2(I, ρdx)
249
interval [α, β]. Since the polynomials Pk−1 and −Pk−1 have the same system of roots,
we can assume that Pk−1 is positive in [α, β] and Pk is negative in (α, β). Deﬁne the
function f (x) = −Pk(x)
Pk−1(x). It is continuous on [α, β] and satisﬁes f (α) = f (β) = 0
and f (x) > 0 for all x ∈(α, β). It follows that λ0 = sup {f (x) : x ∈[α, β]} = f (x0)
for some x0 ∈(α, β). Now consider the family of polynomials Qk(x, λ) = Pk(x) +
λPk−1(x) = Pk−1(x)(λ −f (x)). Therefore, for all λ ≥λ0, the polynomials Qk(·, λ)
are nonnegative on [α, β], in particular Qk(x, λ0) ≥0 for all x ∈[α, β]. Since
λ0 = f (x0), it follows that Qk(x0, λ0) = 0, thus Qk(·, λ0) has a root x0 ∈(α, β).
Since f has a maximum at x0, we know 0 = f ′(x0). The derivative of f is easily
calculated:
f ′(x) = −P ′
k(x)Pk−1(x) −Pk(x)P ′
k−1(x)
Pk−1(x)2
.
Thus f ′(x0) = 0 implies P ′
k(x0)Pk−1(x0) −Pk(x0)P ′
k−1(x0) = 0, and therefore
Q′
k(x0) = P ′
k(x0)+f (x0)P ′
k−1(x0) = 0. Hence the polynomial Qk(·, λ0) has a root of
multiplicity 2 at x0. This contradicts Lemma 17.3 and therefore the polynomial Pk−1
has at least one root in the interval (α, β). Since Pk−1 has exactly k −1 simple real
roots according to Proposition 17.2, we conclude that Pk−1 has exactly one simple
root in (α, β) which proves the theorem.
2
Remark 17.1 Consider the function
F(Q) =

I
Q(x)2ρ(x) dx,
Q(x) =
n

k=0
akxk.
Since we can expand Q in terms of the orthonormal basis {Pk : k = 0, 1, 2, . . . },
Q = n
k=0 ckPk, ck = ⟨Pk, Q⟩ρ the value of the function F can be expressed in
terms of the coefﬁcients ck as F(Q) = n
k=0 c2
k and it follows that the orthonormal
polynomials Pk minimize the function Q #→F(Q) under obvious constraints (see
Exercises).
17.3
Examples of Complete Orthonormal Systems for
L2(I, ρdx)
For the intervals I = R, I = R+ = [0, ∞), and I = [−1, 1] we are going to
construct explicitly an orthonormal basis by choosing a suitable weight function and
applying the construction explained above. Certainly, the above general results apply
to these concrete examples, in particular the “Knotensatz.”
17.3.1
I = R, ρ(x) = e−x2:
Hermite Polynomials
Evidently, the function ρ(x) = e−x2 is a weight function for the real line. Therefore,
by Lemma 17.1, the system of functions ρn(x) = xne−x2
2 generates the Hilbert space

250
17
Separable Hilbert Spaces
L2(R, dx). Finally the Gram–Schmidt orthonormalization produces an orthonormal
basis {hn : n = 0, 1, 2, . . . }. The elements of this basis have the form (Rodrigues’
formula)
hn(x) = (−1)ncne
x2
2
 d
dx
n 
e−x2
= cnHn(x) e−x2
2
(17.1)
with normalization constants
cn = (2nn!√π)−1/2
n = 0, 1, 2, . . . .
Here the functions Hn are polynomials of degree n, called Hermite polynomials and
the functions hn are the Hermite functions of order n.
Theorem 17.5
The system of Hermite functions {hn : n = 0, 1, 2, . . . } is an or-
thonormal basis of the Hilbert space L2(R, dx). The statements of Theorem 17.4
apply to the Hermite polynomials.
Using Eq. (17.1) one deduces in the Exercises that the Hermite polynomials satisfy
the recursion relation
Hn+1(x) −2xHn(x) + 2nHn−1(x) = 0
(17.2)
and the differential equation (y = Hn(x))
y′′ −2xy′ + 2ny = 0.
(17.3)
These relations show that the Hermite functions hn are the eigenfunctions of the
quantum harmonic oscillator with the Hamiltonian H = 1
2(P 2 + Q2) for the eigen-
value n + 1
2, Hhn = (n + 1
2)hn, n = 0, 1, 2. . . . . For more details we refer to [2–4].
In these references one also ﬁnds other methods to prove that the Hermite functions
form an orthonormal basis.
Note also that the Hermite functions belong to the Schwartz test function space
S(R).
17.3.2
I = R+, ρ(x) = e−x:
Laguerre Polynomials
On the positive real line the exponential function ρ(x) = e−x certainly is a weight
function. Hence our general results apply here and we obtain
Theorem 17.6
The system of Laguerre functions {ℓn : n = 0, 1, 2, . . . } which
is constructed by orthonormalization of the system {xne−x
2 } : n = 0, 1, 2, . . . in
L2(R+, dx) is an orthonormal basis. These Laguerre functions have the following
form (Rodrigues’formula):
ℓn(x) = 1
n!Ln(x) e−x
2 ,
Ln(x) = ex
 d
dx
n
(xne−x,
n = 0, 1, 2, . . . .
(17.4)
For the system {Ln : n = 0, 1, 2, . . . } of Laguerre polynomials Theorem 17.4
applies.

17.3
Examples of Complete Orthonormal Systems for L2(I, ρdx)
251
In the Exercises we show that the Laguerre polynomials of different order are
related according to the identity
(n + 1)Ln+1(x) + (x −2n −1)Ln(x) + nLn−1(x) = 0,
(17.5)
and are solutions of the second order differential equation (y = Ln(x))
xy′′ + (1 −x)y′ + ny = 0.
(17.6)
In quantum mechanics this differential equation is related to the radial Schrödinger
equation for the hydrogen atom.
17.3.3
I = [−1, +1], ρ(x) = 1:
Legendre Polynomials
For any ﬁnite interval I = [a, b], −∞< a < b < ∞one can take any posi-
tive constant as a weight function. Thus, Lemma 17.1 says that the system of powers
{xn : n = 0, 1, 2. . . . }isatotalsystemoffunctionsintheHilbertspaceL2([a, b], dx).
It follows that every element f ∈L2([a, b], dx) is the limit of a sequence of polyno-
mials, in the L2-norm. Compare this with the Theorem of Stone–Weierstrass which
says that every continuous function on [a, b] is the uniform limit of a sequence of
polynomials.
For the special case of the interval I = [−1, 1] the Gram–Schmidt orthonormal-
ization of the system of powers leads to a well-known system of polynomials.
Theorem 17.7 The system of Legendre polynomials
Pn(x) =
1
2nn!
 d
dx
n
(x2 −1)n,
x ∈[−1, 1],
n = 0, 1, 2, . . .
(17.7)
is an orthogonal basis of the Hilbert space L2 ([−1, 1], dx). The Legendre
polynomials are normalized according to the relation
⟨Pn, Pm⟩2 =
2
2n + 1δnm.
Again one can show that these polynomials satisfy a recursion relation and a second
order differential equation (see Exercises):
(n + 1)Pn+1(x) −(2n + 1)xPn(x) + nPn−1(x) = 0,
(17.8)
(1 −x2)y′′ −2xy′ + n(n + 1)y = 0,
(17.9)
where y = Pn(x).

252
17
Separable Hilbert Spaces
Fig. 17.1 Legendre polynomials P3, P4, P5
Without further details we mention the weight functions for some other systems
of orthogonal polynomials on the interval [−1, 1]:
Jacobi P ν,μ
n
ρ(x) = (1 −x)μ,
ν, μ > −1,
Gegenbauer Cλ
n
ρ(x) = (1 −x2)λ−1
2 ,
λ > −1/2,
Tschebyschew 1st kind
ρ(x) = (1 −x)−1/2,
Tschebyschew 2nd kind
ρ(x) = (1 −x2)1/2.
We conclude this section by an illustration of the Knotensatz for some Legendre
polynomials of low order. This graph clearly shows that the zeros of the polynomial
Pk are separated by the zeros of the polynomial Pk+1, k = 3, 4. In addition the
orthonormal polynomials are listed explicitly up to order n = 6.

17.4
Exercises
253
17.4
Exercises
1. Prove: A Hilbert space H is separable if, and only if, H contains a countable
dense subset.
2. The space of almost-periodic functions: In the space of complex-valued mea-
surable functions on R consider the vector space F which is generated by the
exponential functions eλ, λ ∈R; here eλ : R→C is deﬁned by eλ(x) = eixλ
for all x ∈R. Thus elements g in F are of the form g = N
k=1 akeλk for some
choice of N ∈N, ak ∈C, and λk ∈R. On F we deﬁne
⟨g, f ⟩= lim
T →∞
1
2T
 +T
−T
g(x)f (x) dx.
a) Show that ⟨·, ·⟩deﬁnes an inner product on F.
b) Complete the inner product space (F, ⟨·, ·⟩) to get a Hilbert space Hap, called
the space of almost periodic functions on R.
c) Show that Hap is not separable.
Hints: Show that {eλ : λ ∈R} is an orthonormal system in Hap which is not
countable.
3. Consider the functions en, n ∈Z, deﬁned on the interval [0, 2π] by en(x) =
1
√
2π einx. Prove: This system is an orthonormal basis of the Hilbert space
L2([0, 2π], dx).
4. Prove that the function F in Lemma 17.1 is well-deﬁned and holomorphic in the
strip Sα.
Hints: For p = u + iv ∈Sα write i px = α|x| + ixu −|x|(α + vsign x), group
terms appropriately and estimate.
5. Let ρ be a weight function on the interval I. Show: The Hilbert spaces L2(I, ρdx)
and L2(I, dx) are isomorphic under the map f #→√ρf .
6. Let Pk, k = 0, 1, 2, . . . , be the system of orthonormal polynomials for the interval
I and the weight function ρ. Then the polynomial Qk(x, λ) = Pk(x)+λPk−1(x)
has k simple real roots, for any λ ∈R.
7. Under the assumptions of the previous problem show: The functional
f (u) =
 b
a
(u(x) −
n

k=0
akPk(x))2ρ(x) dx
is minimized by the choice ak = ⟨Pk, u⟩ρ, k = 0, 1, . . ., n. Here u is a given
continuous function.
8. Forn = 0, 1, 2, 3, 4calculatetheHermitefunctionshn, theLaguerrefunctionsℓn,
and the Legendre polynomials Pn explicitly in two ways, ﬁrst by going through
the Gram–Schmidt orthonormalization and then by using the representation of
these functions in terms of differentiation of the generating functions given in
the last section.
9. Show that the Hermite polynomials have the generating function e2xt−t2, i.e.,
e2xt−t2 =
∞

n=0
Hn(x)tn
n!

254
17
Separable Hilbert Spaces
Table 17.1 Orthogonal polynomials of order ≤6
n
Hn(x)
Ln(x)
Pn(x)
1
2x
1 −x
x
2
4x2 −2
1 −2x + 1
2x2
3
2x2 −1
2
3
8x3 −12x
1 −3x + 3
2x2 −1
6x3
5
2x3 −3
2x
4
16x4 −48x2 + 12
1 −4x + 3x2 −2
3x3 + 1
24x4
35
8 x4 −15
4 x2 + 3
8
5
32x5 −160x3 + 120x
1 −5x + 5x2 −5
3x3
+ 5
24x4 −
1
120x5
63
8 x5 −35
4 x3 + 15
8 x
6
64x6 −480x4+720x2 −120
1−6x + 15
2 x2 −10
3 x3+ 5
8x4
−1
20x5 +
1
720x6
231
16 x6 −315
16 x4+ 105
16 x2 −5
16
10. Use the last result to show that the Hermite functions are eigenfunctions of
the Fourier transform: F(hn)(p) = (−i )nhn(p)
n = 0, 1, 2 . . . . (See also
Proposition 24.2.2).
11. Prove the recursion relations (17.2), (17.5), and (17.8).
12. Prove the differential equations (17.3), (17.6), and (17.9) by using the rep-
resentation of these functions in terms of differentiation of the generating
functions.
References
1. Edwards RE. Fourier-series. A modern introduction. vol. 1. 2nd ed. NewYork: Springer-Verlag;
1979.
2. Amrein WO. Non-relativistic quantum dynamics. Dordrecht: Reidel; 1981.
3. GalindoA, Pascual P. Quantum mechanics I.Texts and Monographs in Physics. Berlin: Springer-
Verlag; 1990.
4. Thirring W. A course in mathematical physics : classical dynamical systems and classical ﬁeld
theory. Springer study edition. New York: Springer-Verlag; 1992.

Chapter 18
Direct Sums and Tensor Products
There are two often used constructions of forming new Hilbert spaces out of a ﬁnite
or inﬁnite set of given Hilbert spaces. Both constructions are quite important in
quantum mechanics and in quantum ﬁeld theory. This brief chapter introduces these
constructions and discusses some examples from physics.
18.1
Direct Sums of Hilbert Spaces
Recall the construction of the ﬁrst Hilbert space by D. Hilbert, the space of square
summable sequences ℓ2(K) over the ﬁeld K. Here we take inﬁnitely many copies
of the Hilbert space K and take from each copy an element to form a sequence of
elements and deﬁne this space as the space of all those sequences for which the
square of the norm of these elements forms a summable sequence of real numbers.
This construction will be generalized by replacing the inﬁnitely many copies of
the Hilbert space K by a countable set of given Hilbert spaces and do the same
construction.
Let us ﬁrst explain the construction of the direct sum of a ﬁnite number of Hilbert
spaces. Suppose we are given two Hilbert spaces H1 and H2 over the same ﬁeld K.
Consider the set H1 × H2 of ordered pairs (x1, x2), xi ∈Hi of elements in these
spaces and equip this set in a natural way with the structure of a vector space over
the ﬁeld K. To this end, one deﬁnes addition and scalar multiplication on H1 × H2
as follows:
(x1, x2) + (y1, y2) = (x1 + y1, x2 + y2)
∀xi, yi ∈Hi, i = 1, 2,
λ · (x1, x2) = (λx1, λx2)
∀xi ∈Hi, ∀λ ∈K.
It is straightforward to show that with this addition and scalar multiplication the set
H1 × H2 is a vector space over the ﬁeld K. Next we deﬁne a scalar product on this
vector space. If ⟨·, ·⟩i denotes the inner product of the Hilbert space Hi, i = 1, 2, one
© Springer International Publishing Switzerland 2015
255
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_18

256
18
Direct Sums and Tensor Products
deﬁnes an inner product ⟨·, ·⟩on the vector space H1 × H2 by
⟨(x1, x2), (y1, y2)⟩= ⟨x1, y1⟩1 + ⟨x2, y2⟩2
∀xi, yi ∈Hi, i = 1, 2.
In the exercises one is asked to verify that this expression deﬁnes indeed an inner
product on H1 × H2. In another exercise it is shown that the resulting inner product
space is complete and thus a Hilbert space. This Hilbert space is denoted by H1 ⊕H2
and is called the direct sum of the Hilbert spaces H1 and H2.
Now assume that a countable set Hi, i ∈N, of Hilbert spaces over the same ﬁeld
K is given. Consider the set H of all sequences x = (xi)i∈N with xi ∈Hi for all
i ∈N such that
∞

i=1
∥xi∥2
i < ∞,
(18.1)
where ∥·∥i denotes the norm of the Hilbert space Hi. On this set of all such sequences
the structure of a vector space over the ﬁeld K is introduced in a natural way by
deﬁning addition and scalar multiplication as follows:
(xi)i∈N + (yi)i∈N = (xi + yi)i∈N
∀xi, yi ∈Hi, i ∈N,
(18.2)
λ · (xi)i∈N = (λxi)i∈N
∀xi ∈Hi, i ∈N.
(18.3)
It is again an easy exercise to show that with this addition and scalar multiplication
the set H is indeed a vector space over the ﬁeld K. If ⟨·, ·⟩i denotes the inner product
of the Hilbert spaces Hi, i ∈N, an inner product on the vector space H is deﬁned by
⟨(xi)i∈N, (yi)i∈N⟩=
∞

i=1
⟨xi, yi⟩i
∀(xi)i∈N, (yi)i∈N ∈H.
(18.4)
The proof is left as an exercise. Equipped with this inner product, H is an inner
product space. The following theorem states that H is complete, and thus a Hilbert
space.
Theorem 18.1 Suppose that a countable set of Hilbert spaces Hi, i ∈N, over the
ﬁeld K is given. On the set H of all sequences x = (xi)i∈N satisfying condition (18.1),
deﬁne a vector space structure by relations (18.2), (18.3) and an inner product by
relation (18.4). Then H is a Hilbert space over K, called the Hilbert sum or direct
sum of the Hilbert spaces Hi, i ∈N, and is denoted by
H = ⊕∞
i=1Hi.
(18.5)
If all the Hilbert spaces Hi, i ∈N are separable, then the direct sum H is separable
too.
Proof
Only the proofs of completeness and of separability of the inner product
space are left. In its main steps the proof of completeness is the same as the proof of
completeness of the sequence space ℓ2(K) given earlier.

18.1
Direct Sums of Hilbert Spaces
257
Given a Cauchy sequence (x(n))n∈N in H and any ε > 0, there is an n0 ∈N such
that
∥x(n) −x(m)∥< ε
∀n, m ≥n0.
Each element x(n) of this sequence is itself a sequence (x(n)
i )i∈N. Thus, in terms of
the inner product (18.4), this Cauchy condition means
∞

i=1
∥x(n)
i
−x(m)
i
∥2
i < ε2
∀n, m ≥n0.
(18.6)
It follows that for every i ∈N the sequence (x(n)
i )n∈N is actually a Cauchy sequence
in the Hilbert space Hi and thus converges to a unique element xi in this space:
xi = lim
n→∞x(n)
i
∀i ∈N.
Condition (18.6) implies, for every L ∈N,
L

i=1
∥x(n)
i
−x(m)
i
∥2
i < ε2
∀n, m ≥n0,
(18.7)
and thus, by taking the limit n→∞in this estimate, it follows that
L

i=1
∥xi −x(m)
i
∥2
i ≤ε2
∀m ≥n0.
(18.8)
This estimate holds for all L ∈N and the bound is independent of L. Therefore it
also holds in the limit L→∞(which obviously exists)
∞

i=1
∥xi −x(m)
i
∥2
i ≤ε2
∀m ≥n0.
(18.9)
Introducing the sequence x = (xi)i∈N of limit elements xi of the sequence (x(n)
i )n∈N
estimate (18.9) reads
∥x −x(m)∥≤ε
∀m ≥n0.
Therefore, for any ﬁxed m ≥n0, ∥x∥≤∥x −x(m)∥+ ∥x(m)∥≤ε + ∥x(m)∥, and
it follows that the sequence x is square summable, i.e., x ∈H, and that the given
Cauchy sequence (x(n))n∈N converges in H to x. Thus the inner product space H is
complete.
The proof of separability is left as an exercise.
2

258
18
Direct Sums and Tensor Products
18.2
Tensor Products
Tensor products of Hilbert spaces are an essential tool in the description of multipar-
ticle systems in quantum mechanics and in relativistic quantum ﬁeld theory. There
are several other areas in physics where tensor products, not only of Hilbert spaces
but of vector spaces in general, play a prominent role. Certainly, in various areas of
mathematics, the concept of tensor product is essential. Accordingly, we begin this
section with a brief reminder of the tensor product of vector spaces and then discuss
the special aspects of the tensor product of Hilbert spaces.
Given two vector spaces E and F over the same ﬁeld K, introduce the vector
space Λ = Λ(E, F) of all linear combinations
N

j=1
aj(xj, yj),
aj ∈K,
xj ∈E,
yj ∈F,
j = 1, . . . , N ∈N
of ordered pairs (x, y) ∈E × F. Consider the following four types of elements of a
special form in Λ:
(x, y1 + y2) −(x, y1) −(x, y2)
x ∈E, y1, y2 ∈F
(x1 + x2, y) −(x1, y) −(x2, y)
x1, x2 ∈E, y ∈F
(λx, y) −λ(x, y)
x ∈E, y ∈F, λ ∈K
(x, λy) −λ(x, y)
x ∈E, y ∈F, λ ∈K.
These special elements generate a linear subspace Λ0 ⊂Λ. The quotient space of
Λ with respect to this subspace Λ0 is called the tensor product of E and F and is
denoted by E ⊗F:
E ⊗F = Λ(E, F)/Λ0.
(18.10)
By construction, E ×F is a subspace of Λ(E, F); the restriction of the quotient map
Q : Λ(E, F) →Λ(E, F)/Λ0 to this subspace (E, F) is denoted by χ and the image
of an element (x, y) ∈(E, F) under χ is accordingly called the tensor product of x
and y,
χ(x, y) = x ⊗y.
The calculation rules of the tensor product are
x ⊗(y1 + y2) = x ⊗y1 + x ⊗y2
x ∈E, y1, y2 ∈F
(18.11)
(x1 + x2) ⊗y = x1 ⊗y + x2 ⊗y
x1, x2 ∈E, y ∈F
(18.12)
(λx) ⊗y = λ(x ⊗y)
x ∈E, y ∈F, λ ∈K
(18.13)
x ⊗(λy) = λ(x ⊗y)
x ∈E, y ∈F, λ ∈K.
(18.14)
The proof of these rules is left as an exercise.

18.2
Tensor Products
259
The important role of the tensor product in analysis comes from the following
(universal) property, which roughly says that through the tensor product one can
“linearize” bilinear maps.
Theorem 18.2
Let E, F, G be vector spaces over the ﬁeld K. Then, for every
bilinear map b : E × F →G, there is a linear map ℓ: E ⊗F →G such that
b(x, y) = ℓ◦χ(x, y) = ℓ(x ⊗y)
∀x ∈E, y ∈F.
Proof The bilinear map b : E × F→G has a natural extension B : Λ(E, F)→G
deﬁned by B( N
i=1 ai(xi, yi)) = N
i=1 aib(xi, yi). By deﬁnition B is linear. It is a
small exercise to show that bilinearity of b implies B(t) = 0 for all t ∈Λ0. This
allows us to deﬁne a linear map ℓ: Λ(E, F)/Λ0→G by ℓ◦Q(t) = B(t) for all
t ∈Λ(E, F). (Q denotes again the quotient map.) Thus, for all (x, y) ∈E × F, one
has ℓ◦χ(x, y) = B(x, y) = b(x, y).
2
In the ﬁrst part on distribution theory, we introduced the tensor product of test
function spaces and of distributions, for instance the tensor product D(Ω1) ⊗D(Ω2)
for Ωi ⊆Rni, i = 1, 2, open and nonempty, in a direct way by deﬁning, for all
fi ∈D(Ωi), the tensor product f1 ⊗f2 as a function Ω1 × Ω2 →K with values
f1 ⊗f2(x1, x2) = f1(x1)f2(x2) for all (x1, x2) ∈Ω1 × Ω2. That this is a special case
of the general construction given above is shown in the exercises.
Now, given two Hilbert spaces Hi, i = 1, 2, we know what the algebraic tensor
product H1 ⊗H2 of the two vector spaces H1 and H2 is. If ⟨·, ·⟩i denotes the inner
product of the Hilbert space Hi, we introduce on the vector space H1 ⊗H2, the inner
product
⟨x1 ⊗x2, y1 ⊗y2⟩= ⟨x1, y1⟩1⟨x2, y2⟩2
∀xi, yi ∈Hi, i = 1, 2.
(18.15)
Using the calculation rules of tensor products, this deﬁnition is extended to generic
elements of the vector space H1 ⊗H2, and in the exercises we show that this deﬁnes
indeed an inner product.
In general the inner product space (H1 ⊗H2, ⟨·, ·⟩) is not complete. However,
according to the Corollary A.1, the completion of an inner product space is a Hilbert
space. This completion H1 ˜⊗H2 is called the tensor product of the Hilbert spaces
H1 and H2 and is usually denoted as
H1 ⊗H2.
Note that in this notation the symbol ˜ for the completion has been omitted.
For separable Hilbert spaces there is a direct construction of the tensor product
in terms of an orthonormal basis. Suppose that {ui : i ∈N} is an orthonormal basis
of the Hilbert space H1 and {vi : i ∈N} an orthonormal basis of H2. Now consider
the system S =

(ui, vj) : i, j ∈N

⊂H1 × H2. This system is orthonormal with

260
18
Direct Sums and Tensor Products
respect to the inner product (18.15):
⟨(ui, vj), (up, vq)⟩= ⟨ui, up⟩1⟨vj, vq⟩2 = δipδjq
∀i, j, p, q ∈N.
The idea now is to deﬁne the tensor product H1 ⊗H2 as the Hilbert space in which
the system S is an orthonormal basis, i.e.,
H1 ⊗H2 =
⎧
⎨
⎩T =
∞

i,j=1
aij(ui, vj) : aij ∈K,
∞

i,j=1
|aij|2 < ∞
⎫
⎬
⎭.
(18.16)
For two elements T1, T2 ∈H1 ⊗H2 with coefﬁcients aij and bij, respectively, it
follows easily that
⟨T1, T2⟩=
∞

i,j=1
aijbij,
as one would expect. According to this construction, the tensor product of two
separable Hilbert spaces is separable.
For every x
∈H1 and y
∈H2, one has x
= ∞
i=1 aiui with ai
=
⟨ui, x⟩1 and y = ∞
j=1 bjvj with bj = ⟨vj, y⟩2, and thus ⟨(ui, vj), (x, y)⟩=
⟨ui, x⟩1⟨vj, y⟩2 = aibj. Therefore the standard factorization follows:
∞

i,j=1
|⟨(ui, vj), (x, y)⟩|2 =
∞

i,j=1
|ai|2|bj|2 = ∥x∥2
1∥y∥2
2.
By identifying the elements (ui, vj) with ui ⊗vj, one can show that this construction
leads to the same result as the general construction of the tensor product of two
Hilbert spaces.
Without much additional effort the construction of the tensor product generalizes
to more than two factors. Thus, given a ﬁnite number of vector spaces E1, . . . , En
over the ﬁeld K, the n-fold tensor product
E1 ⊗· · · ⊗En
is well deﬁned and has similar properties as the tensor product of two vector spaces.
In particular, to any n-linear map b : E1 ×· · ·×En→G into some vector space over
the same ﬁeld, there is a linear map ℓ: E1 ⊗· · · ⊗En→G such that
b(x1, . . . , xn) = ℓ(x1 ⊗· · · ⊗xn)
∀xi ∈Ei, i = 1, . . . , n.
This applies in particular to the n-fold tensor product
H1 ⊗· · · ⊗Hn
of Hilbert spaces Hi, i = 1, . . . , n.

18.3
Some Applications of Tensor Products and Direct Sums
261
18.3
Some Applications of Tensor Products and Direct Sums
18.3.1
State Space of Particles with Spin
Originally, in quantum physics the state space (more precisely the space of wave
functions) H for an elementary localizable particle was considered to be the Hilbert
space of complex valued square integrable functions in conﬁguration space R3, i.e.,
H = L2(R3). Initially this state space was also used for the quantum mechanical
description of an electron. Later through several experiments (Stern–Gerlach, Zee-
man) one learned that the electron has an additional internal degree of freedom with
two possible values. This internal degree of freedom is called spin. Hence the state
space for the electron had to be extended by these two additional degrees of freedom
and accordingly the state space of the electron is taken to be
He = L2(R3) ⊗C2 = L2(R3, C2).
(18.17)
NotethatL2(R3, C2)istheHilbertspaceofallsquareintegrablefunctionsψ: R3→C2
with inner product ⟨ψ, φ⟩= 2
j=1

R3 ψj(x)φj(x)dx for all ψ, φ ∈L2(R3, C2).
Later, other elementary particles were discovered with p > 2 internal degrees of
freedom. Accordingly, their state space was taken to be
L2(R3) ⊗Cp = L2(R3, Cp).
The validity of this identity is shown in the exercises.
Actually the theory of these internal degrees of freedom or spins is closely related
to the representation theory of the group SU(2) (see [1]). C2 is the representation
space of the irreducible representation D1/2 of SU(2) and similarly, C2s+1 is the
representation space of the irreducible representation Ds of SU(2), s = n/2, n =
0, 1, 2, . . ..
18.3.2
State Space of Multi Particle Quantum Systems
In the quantum mechanical description of multiparticle systems, the question nat-
urally arises of how the states of the multiparticle system are related to the single
particle states of the particles that constitute the multiparticle system. The answer is
given by the tensor product of Hilbert spaces. According to the principles of quantum
mechanics, the state space Hn of an n-particle system of n identical particles with
state space H1 is
Hn = H1 ⊗· · · ⊗H1
n factors,
(18.18)
or a certain subspace thereof depending on the type of particle.
Empirically one found that there are two types of particles, bosons and fermions.
The spin of bosons has an integer value s = 0, 1, 2, . . . while fermions have a spin

262
18
Direct Sums and Tensor Products
with half-integer values, i.e., s = 1
2, 3
2, 5
2, . . . .The n-particle state space of n identical
bosons is the totally symmetric n-fold tensor product of the one particle state space,
i.e.,
Hn,b = H1 ⊗s · · · ⊗s H1
n factors,
(18.19)
and the n-particle state space of n identical fermions is the totally antisymmetric
tensor product of the one particle state space, i.e.,
Hn,f = H1 ⊗a · · · ⊗a H1
n factors.
(18.20)
Here we use the following notation: φ ⊗s ψ = 1
2(φ ⊗ψ + ψ ⊗φ), φ ⊗a ψ = 1
2(φ ⊗
ψ −ψ ⊗φ), respectively. In the exercises some concrete examples of multiparticle
state spaces are studied.
In the relativistic quantum ﬁeld theory, one considers systems in which elementary
particles can be created and annihilated. Thus one needs a state space that allows the
description of any number of particles and that allows a change of particle numbers.
Suppose we consider such a system composed of bosons with one particle state
space H1. Then the Boson Fock space over H1
HB = ⊕∞
n=0Hn,b
where H0,b = C, and Hn,b is given in (18.19), is a Hilbert space, which allows the
description of a varying number of bosons.
Similarly, the Fermion Fock space over the one particle state space H1
HF = ⊕∞
n=0Hn,f
where again H0,f = C, and Hn,f is given in (18.20), is a Hilbert space, which allows
the description of a varying number of fermions.
We conclude this chapter with the remark that in relativistic quantum ﬁeld theory
one can explain, on the basis of well established physical principles, why the n-
particle space of bosons has to be a totally symmetric and that of fermions a totally
antisymmetric tensor product of their one particle state space (for a theorem on the
connection between spin and statistics, see [1–4]).
18.4
Exercises
1. Prove: Through formula (18.15) a scalar product is well deﬁned on the tensor
product H1 ⊗H2 of two Hilbert spaces Hi, i = 1, 2.
2. Complete the proof of Theorem 18.1, i.e., show: If all the Hilbert spaces Hi,
i ∈N, are separable, so is the direct sum H = ⊕∞
i=1Hi.
3. Prove the calculation rules for tensor products.
4. Show that the deﬁnition of the tensor product D(Ω1) ⊗D(Ω2) of test function
spaces D(Ωi) is a special case of the tensor product of vector spaces.

References
263
5. Prove the statements in the text about the n-fold tensor product for n > 2.
6. On the Hilbert space C2 consider the matrices
σx =
⎛
⎝0
1
1
0
⎞
⎠,
σy =
⎛
⎝0
−i
i
0
⎞
⎠,
σz =
⎛
⎝1
0
0
−1
⎞
⎠.
(18.21)
Show that these matrices are self-adjoint on C2, i.e., σ ∗= σ (for the deﬁnition
of the adjoint σ ∗, see the beginning of Sect. 19.2) and satisfy the relations
σxσy = −σyσx = i σz
σyσz = −σzσy = i σx
σzσx = −σxσz = i σy.
(18.22)
The matrices σx, σy, σz are called the Pauli matrices. In quantum physics they are
used for the description of the spin of a particle.
7. Show that the 3 Pauli matrices together with the two dimensional unit matrix I2
form a basis of thespaceM2(C)ofall2×2 anddeducethateveryself-adjointA∗=
A ∈M2(C) can be represented in the form A = λI2 + a · σ with λ = Tr (A) ∈R
and a = (ax, ay, az) ∈R3 with the convention a · σ = axσx + ayσy + azσz.
Finally deduce that every projector on C2, i.e., every E ∈M2(C) that satisﬁes
E∗= E = E2 has the representation
E = 1
2(I2 + e · σ),
e ∈R3, |e| = 1 .
(18.23)
References
1. Thirring W. Quantum mathematical physics · atoms, molecules and large systems. Vol. 3.
Heidelberg: Springer-Verlag; 2002.
2. Reed M, Simon B. Fourier analysis. Self-adjointness. Methods of modern mathematical physics.
Vol. 2. New York: Academic; 1975.
3. Jost R. The general theory of quantized ﬁelds. Providence: American Mathematical Society;
1965.
4. Streater RF, Wightman AS. PCT, spin and statistics, and all that. New York: Benjamin; 1964.

Chapter 19
Topological Aspects
In our introduction, we stressed the analogy between Euclidean spaces and Hilbert
spaces. This analogy works well as long as only the vector space and the geometric
structures of a Hilbert space are concerned. But in the case of inﬁnite dimensional
Hilbert spaces there are essential differences when we look at topological structures
on these spaces. It turns out that in an inﬁnite dimensional Hilbert space the unit ball is
not compact (with respect to the natural or norm topology) with the consequence that
in such a case there are very few compact sets of interest for analysis. Accordingly
a weaker topology in which the closed unit ball is compact is of great importance.
This topology, called the weak topology, is studied in the second section to the extent
needed in later chapters.
19.1
Compactness
We begin by recalling some basic concepts related to compact sets. If M is a subset
of a normed space X, a system G of subsets G of X is called a covering of M if,
and only if, M ⊂∪G∈GG. If all the sets in G are open, such a covering is called an
open covering of M. A subset K of X is called compact if, and only if, every open
covering of K contains a ﬁnite subcovering, i.e., there are G1, . . . , GN ∈G such
that K ⊂∪N
i=1Gi.
It is important to be aware of the following basic facts about compact sets. A
compact set K ⊂X is closed and bounded in the normed space (X, ∥· ∥). A closed
subset of a compact set is compact.
Every inﬁnite sequence (xn)n∈N in a compact set K contains a subsequence, which
converges to a point in K (Theorem of Bolzano–Weierstrass). If K is a set such that
every inﬁnite sequence in K has a convergent subsequence, then K is called sequen-
tially compact. One shows (see Exercises) that in a normed space a set is compact if,
and only if, it is sequentially compact. This is very convenient in applications and is
used frequently. B. Bolzano was the ﬁrst to point out the signiﬁcance of this property
for a rigorous introduction to analysis.
© Springer International Publishing Switzerland 2015
265
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_19

266
19
Topological Aspects
A continuous real valued function is bounded on a compact set, attains its minimal
and maximal values (Theorem of Weierstrass), and is equi-continuous (Theorem of
Heine).
The covering theorem of Heine–Borel states that a subset K ⊂Kn is compact
if, and only if, it is closed and bounded. In inﬁnite dimensional normed spaces, this
equivalence is not true as the following important theorem shows:
Theorem 19.1 (Theorem of F. Riesz) Suppose (X, ∥· ∥) is a normed space and
B = B1(0) denotes the closed unit ball with centre 0. Then B is compact if, and only
if, X is ﬁnite dimensional.
Proof
If X is ﬁnite dimensional, then B is compact because of the Heine–Borel
covering theorem.
Conversely, assume that B is a compact ion in the normed space (X, ∥· ∥). The
open ball is denoted by B(a, r) with centre a ∈X and radius r > 0. Then G =
{B(a, r) : a ∈B} is an open covering of B for any r > 0. Compactness of B implies
that there is a ﬁnite subcover, i.e., there are points a1, . . . , aN ∈B such that
B ⊆∪N
i=1B(ai, r).
(19.1)
Now, observe B(ai, r) = ai + rB(0, 1) and denoted by V the linear subspace of X
generated by the vectors a1, . . . , aN. Certainly, V has a dimension smaller than or
equal to N and is thus closed in X. Relation (19.1) implies
B ⊆∪N
i=1(ai + rB(0, 1) ⊆V + rB(0, 1) ⊆V + rB.
(19.2)
By iterating this relation, we obtain, for n = 1, 2, . . .
B ⊆V + rnB.
(19.3)
Choose 0 < r < 1. It follows that
B ⊆∩n∈N(V + rnB) = V = V.
Since B is the closed unit ball of X, we know X = ∪∞
n=1nB and thus
X ⊆∪∞
n=1nV = V.
Therefore, X has a ﬁnite dimension smaller than or equal to N.
2
For an inﬁnite dimensional Hilbert space, there is another proof of the fact that
its closed unit ball is not compact. For such a Hilbert space, one can ﬁnd an or-
thonormal system with inﬁnitely many elements: {en : n ∈N} ⊂B. For n, m ∈N,
n ̸= m one has ∥en −em∥=
√
2. Thus no subsequence of the sequence (en)n∈N
is a Cauchy sequence; therefore no subsequence converges and hence B is not
sequentially compact.
Remark 19.1 An obvious consequence of Theorem 19.1 is that in an inﬁnite dimen-
sional normed space X, compact sets have an empty interior. Hence in such a case,
the only continuous function f : X→K with compact support is the null function.
Recall that a space is called locally compact if, and only if, every point has a
compact neighborhood. Hence, a locally compact normed space is ﬁnite dimensional.

19.2
The Weak Topology
267
19.2
The Weak Topology
As the theorem of F. Riesz shows, the closed unit ball in an inﬁnite dimensional
Hilbert space H is not (sequentially) compact. We are going to introduce a weaker
topology on H with respect to which the convenient characterization of compact sets
as we know it from the Euclidean spaces Kn is available. In particular, the theorem
of Bolzano–Weierstrass is valid for this weak topology. Though we introduced the
weak topology in the part on distributions, we repeat it for the present particular case.
Deﬁnition 19.1
Let X be a normed space and X′ its topological dual. The weak
topology on X, σ(X, X′), is the coarsest locally convex topology on X such that all
f ∈X′ are continuous. A basis of neighborhoods of a point x0 ∈X for the topology
σ(X, X′) is given by the following system of sets:
U(x0; f1, . . . , fn; r),
f1, . . . , fn ∈X′,
r > 0,
n ∈N,
U(x0; f1, . . . , fn; r) = {x ∈X : |fi(x −x0)| < r, i = 1, . . . , n} .
In particular, for a Hilbert space H, a basis of neighborhoods for the weak topology
is
U(x0; y1, . . . , yn; r),
y1, . . . , yn ∈H,
r > 0,
n ∈N,
U(x0; y1, . . . , yn; r) = {x ∈H : |⟨yi, x −x0⟩| < r, i = 1, . . . , n} .
Certainly, Corollary 19.3 has been used in the description of the elements of
a neighborhood basis for the weak topology of a Hilbert space. It is important to
be aware of the following elementary facts about the topology σ = σ(X, X′) of a
normed space X. It has fewer open and thus fewer closed sets than the strong or norm
topology. Hence, if a subset A ⊂X is closed for σ it is also closed for the strong
topology. But the converse does not hold in general. However, for convex sets, we
will learn later in this section that such a set is closed for σ if, and only if, it is closed
for the strong topology.
In case of a ﬁnite dimensional normed space X, the weak and the strong topology
coincide. One can actually show that this property characterizes ﬁnite dimensional
normed spaces. This is discussed in the exercises.
Though it should be clear from the above deﬁnition, we formulate the concepts
of convergence for the weak topology explicitly.
Deﬁnition 19.2
Let H be a Hilbert space with inner product ⟨·, ·⟩and (xn)n∈N a
sequence in H.
1. The sequence (xn)n∈N converges weakly to x ∈H if, and only if, for every u ∈H
the numerical sequence (⟨u, xn⟩)n∈N converges to the number ⟨u, x⟩. x is called
the weak limit of the sequence (xn)n∈N .
2. The sequence (xn)n∈N is a weak Cauchy sequence, i.e., a Cauchy sequence for
the weak topology, if, and only if, for every u ∈H the numerical sequence
(⟨u, xn⟩)n∈N is a Cauchy sequence.

268
19
Topological Aspects
Some immediate consequences of these deﬁnitions are:
Lemma 19.1 Suppose H is a Hilbert space with inner product ⟨·, ·⟩.
(a) A weakly convergent sequence is a weak Cauchy sequence.
(b) A sequence has at most one weak limit.
(c) Every inﬁnite orthonormal system converges weakly to zero.
Proof Part (a) is obvious from the deﬁnition. For Part (b) assume that a sequence
(xn)n∈N ⊂H has the points x, y ∈H as weak limits. For every u ∈H, it follows
that
⟨u, x −y⟩= lim
n→∞⟨u, xn −xn⟩= 0,
and hence x −y ∈H⊥= {0}, thus x = y.
Suppose {xn : n ∈N} is an inﬁnite orthonormal system in H. For every u ∈H
Bessel’s inequality (see Corollary 15.1) implies that
∞

n=1
|⟨xn, u⟩|2 ≤∥u∥2 < ∞
and therefore ⟨xn, u⟩→0. Since u ∈H is arbitrary we conclude.
2
Before we continue with some deeper results about the weak topology on a Hilbert
space, we would like to pause a little for a heuristic discussion of the intuitive meaning
of the concept of weak convergence.
Consider the wave equation in one dimension
∂2
t u −∂2
xu = 0
where ∂t =
∂
∂t and similarly ∂x =
∂
∂x and look for solutions u which are in the
Hilbert space H = L2(R) with respect to the space variable x for each time t, i.e.,
u(·, t) ∈L2(R) for each t ≥0, given a smooth initial condition u0 ∈C2(R) with
support in the interval [ −1, 1] which is symmetric, u0(−x) = u0(x):
u(·, 0) = u0,
∂tu(·, 0) = 0.
The solution is easily found to be u(x, t) = 1
2(u0(x −t) + u0(x + t)). Obviously, the
support of u(·, t) is contained in the set St = [ −1 −t, +1 −t] ∪[ −1 + t, +1 + t].
For t > 1, the two functions x #→u0(x −t) and x #→u0(x + t) have a disjoint
support and thus for all t > 1,
∥u(·, t)∥2
2 =

R
|u(x, t)|2 dx = 1
2∥u0∥2
2.
The support St of u(·, t) moves to “inﬁnity” as t→+ ∞. This implies that u(·, t)
converges weakly to 0 as t→∞: For every v ∈L2(R), one ﬁnds
|⟨v, u(·, t⟩2| = |

St
v(x)u(x, t) dx| ≤
6
St
|v(x)|2 d x
6
St
|u(x, t)|2 dx

19.2
The Weak Topology
269
≤∥u0∥
√
2
6
St
|v(x)|2 dx.
Since v ∈L2(R), given ε > 0 there is R > 0 such that

|x|≥R |v(x)|2 dx ≤ε2. For |t|
sufﬁciently large the support St is contained in {x ∈R : |x| ≥R}. Hence for such t
we can continue the above estimate by
≤∥u0∥2ε/
√
2
and we conclude that ⟨v, u(·, t)⟩2→0 as |t|→∞.
The way in which weak convergence is achieved in this example is not atypical
for weak convergence in L2(Rn)! Later in our discussion of quantum mechanical
scattering theory we will encounter a similar phenomenon. There, scattering states
in L2(Rn) will be deﬁned as those functions t #→φ(·, t) ∈L2(Rn) for which
lim
|t|−→∞

|x|≤R
|φ(x, t)|2 dx = 0
for every R ∈(0, ∞).
How are strong and weak convergence related? Certainly, if a sequence (xn)n∈N
converges strongly to x ∈H, then it also converges weakly and has the same limit.
This follows easily from Schwarz’ inequality: |⟨u, x −xn⟩| ≤∥u∥∥x −xn∥, for any
u ∈H. The relation between both concepts of convergence is fully understood as
the following theorem shows.
Theorem 19.2
Let H be a Hilbert space with inner product ⟨·, ·⟩and (xn)n∈N a
sequence in H. This sequence converges strongly to x ∈H if, and only if, it converges
weakly to x and limn→∞∥xn∥= ∥x∥.
Proof That weak convergence is necessary for strong convergence has been shown
above. The basic estimate for norms
| ∥x∥−∥xn∥| ≤∥x −xn∥
(see Corollary 15.2) implies that limn−→∞∥xn∥= ∥x∥.
In order to see that they are sufﬁcient, consider a sequence which converges
weakly to x ∈H and for which the sequence of norms converges to the norm of x.
Since the norm is deﬁned in terms of the inner product, one has
∥x −xn∥2 = ⟨x −xn, x −xn⟩= ∥x∥2 + ∥xn∥2 −⟨x, xn⟩−⟨xn, x⟩
∀n ∈N.
Weak convergence implies that
lim
n→∞⟨x, xn⟩= lim
n→∞⟨xn, x⟩= ∥x∥2.
Since also limn→∞∥xn∥= ∥x∥is assumed, we deduce ∥x −xn∥2→0 as n→∞and
strong convergence follows.
2

270
19
Topological Aspects
There are some simple but important facts implied by the these results.
•
The open unit ball B1 = {x ∈H : ∥x∥< 1} of an inﬁnite dimensional Hilbert
space H is not open for the weak topology. Since otherwise every set which is
open for the strong topology would be open for the weak topology and thus both
topologies would be identical.
•
The unit sphere S1 = {x ∈H : ∥x∥= 1} of an inﬁnite dimensional Hilbert space
H is closed for the strong but not for the weak topology. The weak closure of S1,
i.e., the closure of S1 with respect to the weak topology is equal to the closed unit
ball B1 = {x ∈H : ∥x∥≤1}. (See exercises)
A ﬁrst important step towards showing that the closed unit ball of a Hilbert space
is compact for the weak topology is to show that strongly bounded sequences have
weakly convergent subsequences.
Theorem 19.3
Every sequence (xn)n∈N in a Hilbert space H which is strongly
bounded, i.e., there is an M < ∞such that ∥xn∥≤M for all n ∈N, has a weakly
convergent subsequence.
Proof The given sequence generates a closed linear subspace H0 = [ {xn : n ∈N} ]
in H.
Consider the numerical sequence A1
n = ⟨x1, xn⟩, n = 1, 2, . . . . By Schwarz’
inequality it is bounded: |A1
n| ≤∥x1∥∥xn∥≤M2. The Bolzano–Weierstrass theorem
ensures the existence of a convergent subsequence A1
n1(j) = ⟨x1, xn1(j)⟩, j ∈N. Next
consider the numerical sequence A2
n1(j) = ⟨x2, xn1(j)⟩, j ∈N. It too is bounded
by M2 and again by Bolzano–Weierstrass we can ﬁnd a convergent subsequence
A2
n2(j) = ⟨x2, xn2(j)⟩, j ∈N.
This argument can be iterated and thus generates a sequence xni(j), i = 1, 2, . . .
of subsequences of our original sequence with the property that (xni+1(j))j∈N is a
subsequence of (xni(j))j∈N. Finally, we consider the diagonal sequence (xm(j))j∈N
where we use m(j) = nj(j). Then all numerical sequences ⟨xk, xm(j)⟩, j ∈N,
converge since for j > k this sequence is a subsequence of the convergent sequence
(Ak
nk(j))j∈N. It follows that limj→∞⟨x, xm(j)⟩exists for all x ∈V = lin {xn : n ∈N}.
Hence limj→∞⟨xm(j), x⟩exists for all x ∈V . We call this limit T (x). Basic rules of
calculation imply that T : V →K is linear. The estimate |⟨xm(j), x⟩| ≤∥x∥∥xm(j)∥≤
M∥x∥implies |T (x)| ≤M∥x∥and thus T is a continuous linear functional on the
subspace V . The Extension Theorem 16.4 implies that there is a unique continuous
linear functional ˆT on H such that ∥ˆT ∥= ∥T ∥. Furthermore, by Theorem 16.3, there
is a unique vector y ∈H0 such that ˆT (x) = ⟨y, x⟩for all x ∈H, and we deduce that y
istheweaklimitofthesequence(xm(j))j∈N (ﬁrst, wehave⟨y, x⟩= limj−→∞⟨xm(j), x⟩
for all x ∈V , then by continuous extension for all x ∈H; details are considered in
the exercises).
2
One of the fundamental principles of functional analysis is the uniform bounded-
ness principle. It is also widely used in the theory of Hilbert spaces. InAppendix 34.4
we prove this principle in the generality which is needed in the theory of generalized
functions. In this section we give a direct proof for Banach spaces. This version
obviously is sufﬁcient for the theory of Hilbert spaces.

19.2
The Weak Topology
271
Deﬁnition 19.3 Let X be a Banach space with norm ∥·∥and {Tα : α ∈A} a family
of continuous linear functionals on X (A an arbitrary index set). One says that this
family is
1. pointwise bounded if, and only if, for every x ∈X there is a real constant
Cx < ∞such that
sup
α∈A
|Tα(x)| ≤Cx;
2. uniformly bounded or norm bounded if, and only if
sup
α∈A
sup {|Tα(x)| : x ∈X, ∥x∥≤1} = C < ∞.
Clearly, every uniformly bounded family of continuous linear functionals is point-
wise bounded. For a certain class of spaces (see Appendix 34.4) the converse is also
true and is called the principle of uniform boundedness or the uniform boundedness
principle. It was ﬁrst proven by Banach and Steinhaus for Banach spaces.
We prepare for the proof of this fundamental result by an elementary lemma.
Lemma 19.2 A family {Tα : α ∈A} of continuous linear functionals on a Banach
space X is uniformly bounded if, and only if, this family is uniformly bounded on
some ball Br(x0) = {x ∈X : ∥x −x0∥< r}, i.e.,
sup
α∈A
sup
x∈Br(x0)
|Tα(x)| = C < ∞.
Proof If the given family is uniformly bounded we know that there is some positive
constant C0 such that |Tα(x)| ≤C0 for all x ∈B = B1(0) and all α ∈A. A ball
Br(x0) with centre x0 and radius r > 0 is obtained from the unit ball B by translation
and scaling: Br(x0) = x0 +rB. Thus every x ∈Br(x0) can be written as x = x0 +ry
with y ∈B and therefore
|Tα(x)| = |Tα(x0 + ry)| = |Tα(x0) + rTα(y)|
≤|Tα(x0)| + r|Tα(y)| ≤C0∥x0∥+ rC0.
Hence the family {Tα : α ∈A} is uniformly bounded on the ball Br(x0) by (r +
∥x0∥)C0.
Conversely, assume that the family {Tα : α ∈A} is uniformly bounded on some
ball Br(x0) with bound C. The points y in the unit ball B have the representation
y = (x −x0)/r in terms of the points x ∈Br(x0). It follows, for all y ∈B and all
α ∈A:
|Tα(y)| = 1
r |Tα(x −x0)| ≤1
r (|Tα(x)| + |Tα(x0)|) ≤2C
r
< ∞,
and we conclude.
2
Theorem 19.4 (Banach–Steinhaus) A family {Tα : α ∈A} of continuous linear
functionals on a Banach space X is uniformly bounded if, and only if, it is pointwise
bounded.

272
19
Topological Aspects
Proof Let T = {Tα : α ∈A} be a pointwise bounded family of continuous linear
functionals on X. We prove the uniform bound
sup
α∈A
∥Tα∥< ∞
indirectly.
Assume that T is not uniformly bounded. Lemma 19.2 implies that T is not
uniformly bounded on any of the balls Br(x0), x0 ∈X, r > 0. It follows that for
every p ∈N there are an index αp ∈A and a point xp ∈B = B1(0) such that
|Tαp(xp)| > p.
Begin with p = 1. Since Tα1 is continuous there is an ε1 > 0 such that |Tα1(x)| > 1
for all x ∈Bε1(x1). By choosing ε1 small enough we can ensure Bε1(x1) ⊂B. Again
by Lemma 19.2 we know that the family T is not uniformly bounded on the ball
Bε1(x1). Hence there are a point x2 ∈Bε1(x1) and an index α2 ∈A such that
|Tα2(x2)| > 2. Continuity of Tα2 implies the existence of ε2 ∈(0, ε1/2) such that
|Tα2(x)| > 2 for all x ∈Bε2(x2) ⊂Bε1(x1).
On the basis of Lemma 19.2 these arguments can be iterated. Thus, we obtain a
sequence of points (xp)p∈N ⊂B, a decreasing sequence of positive numbers εp and
a sequence of indices αp ∈A such that
(a) |Tαp(x)| > p for all x ∈Bεp(xp);
(b) Bαp+1(xp+1) ⊂Bαp(xp) for all p ∈N;
(c) 0 < εp+1 < εp
2 < ε1
2p .
Property (b) implies ∥xp+1 −xp∥< εp and thus by c), for all m ∈N:
∥xp+m −xp∥= ∥
m−1

i=0
(xp+i+1 −xp+i)∥≤
m−1

i=0
∥xp+i+1 −xp+i∥
<
m−1

i=0
εp+i <
m−1

i=0
ε1
2p+i →0
as p→∞.
This shows that (xp)p∈N is a Cauchy sequence in the Banach space X, hence it
converges to a point x ∈X. This point belongs to all the balls Bεp(xp) because of
(b). At this point x, the family T is bounded by assumption. This is a contradiction
to the construction according to property (a). We conclude that the family T is
uniformly bounded.
2
Remark 19.2
1. The statement of the Banach–Steinhaus theorem can be rephrased as follows: If a
family {Tα : α ∈A} of continuous linear functionals on a Banach space X is not
uniformly bounded, then there is a point x0 ∈X such that supα∈A |Tα(x0)| = +∞.
2. One can also prove the principle of uniform boundedness by using the fact that a
Banach space X is a Baire space, i.e., if X is represented as the countable union
of closed sets Xn, X = ∪n∈NXn, then at least one of the sets Xn must contain

19.2
The Weak Topology
273
an open nonempty ball (see Appendix C). Given a pointwise bounded family
{Tα : α ∈A} of continuous linear functionals of X, we apply this to the sets
Xn = {x ∈X : |Tα(x)| ≤n ∀α ∈A}
n ∈N.
The pointwise bounds ensure that the union of these sets Xn represents X. It thus
follows that the family is bounded on some open ball and by Lemma 19.2 we
conclude.
3. The theorem of Riesz–Fréchet (Theorem 16.3) states that the continuous linear
functionals T on a Hilbert space H can be identiﬁed with the points u ∈H:
T = Tu, u ∈H, Tu(x) = ⟨u, x⟩for all x ∈H. Theorem 19.4 implies: if a set
A ⊂H is weakly bounded, then it is uniformly bounded, i.e., bounded in norm.
(See the exercises for details).
4. In order to verify whether a set A is bounded (i.e., whether A is contained in
some ﬁnite ball) it sufﬁces, because of Theorem 19.4, to verify that it is weakly
bounded. As in the case of a ﬁnite dimensional Hilbert space, this amounts to
verifying that A is “bounded in every coordinate direction” and this is typically
much easier.
A weakly convergent sequence (xn)n∈N in a Hilbert space H is obviously pointwise
bounded and thus bounded in norm. This proves
Lemma 19.3 Every weakly convergent sequence in a Hilbert space is bounded in
norm.
Now we are well prepared to prove the second major result of this section.
Theorem 19.5 Every Hilbert space H is sequentially complete with respect to the
weak topology.
Proof
Suppose we are given a weak Cauchy sequence (xn)n∈N ⊂H. For every
u ∈H the numerical sequence (⟨xn, u⟩)n∈N then is a Cauchy sequence and thus
converges to some number in the ﬁeld K. Call this number T (u). It follows that
this sequence is pointwise bounded. Hence it is norm bounded, i.e., there is some
constant C ∈[0, ∞) such that ∥xn∥≤C for all n ∈N. Since T (u) = limn→∞⟨xn, u⟩
it follows by Schwarz’inequality |T (u)| ≤C∥u∥. Basic rules of calculation for limits
imply that the function T : H →K is linear. Thus T is a continuous linear functional
on H, and we know that such functionals are of the form T = Tx for a unique vector
x ∈H, Tx(u) = ⟨x, u⟩for all u ∈H. We conclude that ⟨x, u⟩= limn→∞⟨xn, u⟩for
u ∈H. Hence the Cauchy sequence (xn)n∈N converges weakly to the point x ∈H.
The Hilbert space H is weakly sequentially complete.
2
Theorem 19.6 (Banach–Saks) Suppose that (xn)n∈N is a weakly convergent se-
quence with limit x. Then there exists a subsequence (xn(j))j∈N such that the sequence
of arithmetic means of this subsequence converges strongly to x, i.e.,
lim
m→∞
1
m
m

j=1
xn(j) = x.

274
19
Topological Aspects
Proof
Since weakly convergent sequences are norm bounded, there is a constant
M such that ∥x −xn∥≤M for all n ∈N. We deﬁne the subsequence successively
and start with n(1) = 1. Due to weak convergence of the given sequence, there is an
n(2) ∈N such that |⟨xn(2) −x, xn(1) −x⟩| < 1. Suppose that n(1), . . . , n(k) have been
constructed. Since the given sequence converges weakly to x there is an n(k+1) ∈N
such that
|⟨xn(k+1) −x, xn(i) −x⟩| < 1
k ,
i = 1, . . . , k.
Now, we estimate 1
m
m
j=1 xn(j) −x in norm, taking the choice of the subsequence
into account in the last step:
∥1
k
k

i=1
(xn(i) −x)∥2 = 1
k2
k

i,j=1
⟨xn(j) −x, xn(i) −x⟩
= 1
k2
⎛
⎝
k

i=1
⟨xn(i) −x, xn(i) −x⟩+ 2

1≤i<j≤k
⟨xn(j) −x, xn(i) −x⟩
⎞
⎠
≤1
k2
⎛
⎝kM2 + 2
k

j=2
j−1

i=1
|⟨xn(j) −x, xn(i) −x⟩|
⎞
⎠
≤1
k2
⎛
⎝kM2 + 2
k

j=2
j−1

i=1
1
j −1
⎞
⎠= 1
k2 (kM2 + 2k).
Clearly, the upper bound in this estimate converges to zero as k−→∞and thus
proves strong convergence of the sequence of arithmetic means.
2
An immediate and very important consequence of the theorem of Banach and
Saks is the conclusion that the weak and the strong closure of convex sets coincide.
Corollary 19.1 For convex sets A of a Hilbert space H, the strong closure A
s and
the weak closure A
w are the same:
A ⊂H, A convex ⇒A
s = A
w.
(19.4)
Proof
Since the strong topology is ﬁner than the weak topology the closure with
respect to the strong topology is always contained in the closure with respect to the
weak topology: A
s ⊆A
w. Convexity implies that both closures actually agree.
Recall that a subset A of a vector space is called convex if, and only if, tx + (1 −
t)y ∈A whenever x, y ∈A and 0 < t < 1. Now take any point x ∈A
w. Then there
is a sequence (xn)n∈N ⊂A which converges weakly to x. We can ﬁnd a subsequence
(xn(i))i∈N such that the sequence (ξm)m∈N of arithmetic means
ξm = 1
m
m

i=1
xn(i)

19.3
Exercises
275
converges strongly to x. Since A is convex we know ξm ∈A for all m ∈N. Hence x
is also the limit of a strongly convergent sequence of points in A, thus x ∈A
s and
therefore A
w ⊆A
s. This proves equality of both sets.
2
The weak topology σ on a Hilbert space H is not metrizable. However, when
restricted to the closed unit ball, it is metrizable according to the following lemma
which we mention without proof.
Lemma 19.4
On closed balls Br(x0) in a Hilbert space, the weak topology σ
induces the topology of a metric space.
Gathering all the results of this section, the announced compactness of the closed
unit ball with respect to the weak topology follows easily.
Theorem 19.7 The closed balls Br(x0), r > 0, x0 ∈H, in a Hilbert space H, are
weakly compact.
Proof
Since the weak topology is metrizable on these balls it sufﬁces to show
sequential compactness. Given any sequence (xn)n∈N ⊂Br(x0), there is a weakly
convergent subsequence by Theorem 19.3 and the weak limit of this subsequence
belongs to the ball Br(x0) because of Corollary 19.1. This proves sequential
compactness.
2
Actually closed balls in any reﬂexive Banach space, not only in Hilbert spaces, are
weakly compact. This fact plays a very fundamental rôle in optimization problems
and will be discussed in more detail in Part C.
19.3
Exercises
1. Prove: On a ﬁnite dimensional-normed space, the weak and the norm topologies
coincide. And conversely, if the norm and the weak topologies of a normed space
coincide then this space has a ﬁnite dimension.
2. Fill in the details of the last step in the proof of Theorem 19.3.
Hints: It sufﬁces to show limj→∞⟨xm(j), x⟩= ⟨y, x⟩for x ∈H0. For x ∈H0
write ⟨y −xm(j), x⟩= ⟨y −xm(j), xε⟩+ ⟨y −xm(j), x −xε⟩with a suitable choice
of xε ∈V , given any ε > 0.
3. For a subset A of a Hilbert space H prove: If for every x ∈H there is a ﬁnite
constant Cx such that |⟨u, x⟩| ≤Cx for all u ∈A, then there is a constant C < ∞
such that ∥u∥≤C for all u ∈A.
4. For a bounded linear map T : X−→Y between two normed spaces X, Y show:
a) If B(x, r) denotes the open ball in X of center x and radius r > 0 then one has
r ∥T ∥≤
sup
ξ∈B(x,r)
∥T (ξ)∥Y.
(19.5)

276
19
Topological Aspects
b) Conclude on the basis of (19.5): Given any x ∈X, r > 0, and 0 < t < 1
there is ξ ∈B(x, r) such that
tr ∥T ∥≤∥T (ξ)∥Y .
(19.6)
Hints: Recall the deﬁnition of the norm of T : ∥T ∥= supx′∈B(0,1) ∥T (x′)∥Y and
conclude r ∥T ∥= supx′∈B(0,r) ∥T (x′)∥Y. Next observe that for any x ∈X one
has T (x′) = 1
2(T (x + x′) −T (x −x′). Two straightforward estimates now give
(19.5).
5. Give an alternative indirect proof of the Banach–Steinhaus theorem by using
(19.6) in the basic iteration step.
Hints: If the given family T is not uniformly bounded we can choose a strictly
increasing sequence of positive numbers Rn = Rn, n ∈N, R > 1, and then
can ﬁnd a sequence Tn of elements in T such that ∥Tn∥≥Rn. Now choose
a decreasing sequence of positive numbers rn = rn,
1
R < r < 1, such that
rnRn−→∞as n−→∞. Next construct a sequence of points xn as follows. Choose
x0 = 0 and r0 = 1. If x0, . . . , xk have been constructed ﬁnd a point xk+1 ∈
B(xk, rk) such that trk∥Tk∥≤∥Tk(xk+1)∥using (19.6).As in the proof ofTheorem
18.2.3 it follows that this sequence is a Cauchy sequence and thus converges to
a unique point x ∈X and one has ∥x −xn∥X ≤rn
1
1−r . Now estimate ∥Tnx∥Y
from below with a suitable choice of t and thus show ∥Tnx∥Y−→∞as n−→∞.
For instance, one could use Rn = 4n and rn = 3−n and t = 2/3 (compare [1]).
Reference
1. Sokal AD. A really simple elementary proof of the uniform boundedness theorem. Am Math
Mon. 2011;118:450–2.

Chapter 20
Linear Operators
For a Hilbert space one can distinguish three structures, namely the linear, the geo-
metric, and the topological structures. This chapter begins with the study of mappings
which are compatible with these structures. In this ﬁrst chapter on linear operators the
topological structure is not taken into account, and accordingly the operators studied
in this chapter are not considered to be continuous. Certainly, this will be relevant
only in the case of inﬁnite-dimensional Hilbert spaces, since on a ﬁnite dimensional
vector space every linear function is continuous.
Mappings which are compatible with the linear structure are called linear oper-
ators. The topics of Sect. 20.1 are dedicated to the basic deﬁnitions and facts about
linear operators. Section 20.2 takes the geometrical structure into account insofar as
consequences of the existence of an inner product are considered. Sect. 20.3 builds on
the results of Sect. 20.2 and develops the basic theory of a special class of operators
which play a fundamental role in quantum physics. These studies will be continued
in later chapters. Finally, Sect. 20.4 discusses some ﬁrst examples from quantum
mechanics.
20.1
Basic Facts
Recall that any mapping is speciﬁed by giving the following data: a domain, a target
space, and a rule which tells us how to assign to an element in the domain an element
in the target space. When the domain and the target space carry a linear structure,
one can consider those mappings which respect these structures. Such mappings are
called linear. Accordingly one deﬁnes linear operators in Hilbert spaces.
Deﬁnition 20.1
Let H and K be two Hilbert spaces over the ﬁeld K. A linear
operator from H into K is a mapping A : D(A) →K where D(A) is a linear
subspace of H such that
A(α1x1 + α2x2) = α1A(x1) + α2A(x2)
∀xi ∈D(A), ∀αi ∈K, i = 1, 2.
The linear subspace D(A) is called the domain of A.
If K = H, a linear operator A from H into K is called a linear operator in H.
© Springer International Publishing Switzerland 2015
277
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_20

278
20
Linear Operators
Following tradition we write Ax instead of A(x) for x ∈D(A) for a linear operator
A.
In many studies of linear operators A from H into K, the following two subspaces
play a distinguished role: The kernel or nullspace N(A) and the range ran A of A:
N(A) = {x ∈D(A) : Ax = 0},
ran A = {y ∈K : y = Ax for some x ∈D(A)}.
It is very easy to show that N(A) is a linear subspace of D(A) and ran A is a linear
subspace of K.
Recall that a mapping f : D(f ) →K, D(f ) ⊂H, is called injective if, and only
if, f (x1) = f (x2), x1, x2 ∈D(f ) implies x1 = x2. Thus, a linear operator A from
H into K is injective if, and only if, its nullspace N(A) is trivial, i.e., N(A) = {0}.
Similarly, a linear operator A is surjective if, and only if, its range equals the target
space, i.e., ran A = K.
Suppose that A is an injective operator from H into K. Then there is a linear
operator B from K into H with domain D(B) = ran A and ran B = D(A) such that
BAx = x for all x ∈D(A). B is called the inverse operator of A and is usually
written as A−1.
Let us consider some simple examples of operators in the Hilbert space H =
L2([0, 1], dx): First we specify several linear subspaces of H:
D0 = {f : (0, 1)→C : f continuous, supp f ⊂(0, 1)},
Dα = {ψ ∈H : ψ = xαφ, φ ∈H},
D∞=
+
ψ ∈H : 1
x ψ ∈H
,
.
Here α is some number ≥1. It is clear that these three sets are actually linear
subspaces of H = L2([0, 1], dx) and that they are all different:
D0 ⊊Dα ⊊D∞.
As the rule which assigns to an element ψ in any of these subspaces an element
in L2([0, 1], dx), we take the multiplication with 1
x . One checks that indeed 1
x ψ ∈
L2([0, 1], dx) in all three cases and that this assignment is linear. Thus we get three
different linear operators:
A0 :
D(A0) = D0,
D0 ∋ψ #→1
x ψ,
Aα :
D(Aα) = Dα,
Dα ∋ψ #→1
x ψ,
A∞:
D(A∞) = D∞,
D∞∋#→1
x ψ.

20.1
Basic Facts
279
Note that for the multiplication with 1
x one cannot have, as a domain, the whole
Hilbert space L2([0, 1], dx), since the function ψ = 1 is square-integrable but 1
x · 1
is not square integrable on the interval [0, 1].
For a situation as in this example an appropriate terminology is introduced in the
following deﬁnition.
Deﬁnition 20.2 Let H and K be two Hilbert spaces over the ﬁeld K and A, B two
linear operators from H into K. B is called an extension of A, in symbols, A ⊆B
if, and only if, D(A) ⊆D(B) and Ax = Bx for all x ∈D(A). Then A is also called
a restriction of B, namely to the subspace D(A) of D(B): A = B|D(A).
Using this terminology we have for our example:
A0 ⊂Aα ⊂A∞.
In the Exercises, further examples of linear operators are discussed. These examples
and the examples discussed above show a number of features one has to be aware of:
1. Linear operators from a Hilbert space H into another Hilbert space K are not
necessarily deﬁned on all of H. The domain as a linear subspace of H is an
essential part of the deﬁnition of a linear operator.
2. Even if the assignment H ∋ψ #→Aψ makes sense mathematically the vector ψ
might not be in the domain of A. Consider for example the case H = K = L2(R)
and the function ψ ∈L2(R), ψ(x) =
1
1+x2 and let A stand for the multiplication
with the function 1 + x2. Then the multiplication of ψ with this function makes
good mathematical sense and the result is the function f = 1, but ψ is not in
the domain of this multiplication operator since 1 ̸∈L2(R). Thus there are linear
operators which are only deﬁned on a proper subspace of the Hilbert space.
3. Whether or not a linear operator A can be deﬁned on all of the Hilbert space H
can be decided by investigating the set
+∥Aψ∥
∥ψ∥: ψ ∈D(A), ψ ̸= 0
,
.
If this set is not bounded, the operator A is called an unbounded linear operator.
These operators are not continuous and in dealing with them special care has to
be taken. (See later sections). If the above set is bounded the operator A is called
a bounded linear operator. They respect the topological structure too, since they
are continuous.
The fact that the domain of a linear operator is not necessarily equal to the whole
space causes a number of complications. We mention two. Suppose that A, B are
two linear operators from the Hilbert space H into the Hilbert space K. The addition
of A and B can naturally only be deﬁned on the domain D(A + B) = D(A) ∩D(B)
by (A + B)ψ = Aψ + Bψ. However, even if both domains are dense in H their
intersection might be trivial, i.e., D(A)∩D(B) = {0} and then the resulting deﬁnition
is not of interest.
Similarly, the natural deﬁnition of a product or the composition of two linear
operators can lead to a trivial result. Suppose A, B are two linear operators in the

280
20
Linear Operators
Hilbert space H. Then their product A · B is naturally deﬁned as the composition
on the domain D(A · B) = {ψ ∈D(B) : Bψ ∈D(A)} by (A · B)ψ = A(B(ψ)) for
all ψ ∈D(A · B). But again it can happen that D(A · B) is trivial though D(A) and
D(B) are dense in H.
In the next chapter on quadratic forms we will learn how one can improve on
some of these difﬁculties.
We conclude this section with a remark on the importance of the domain of a
linear operator in a Hilbert space. As we have seen, a linear operator can be usually
deﬁned on many different domains. Which domain is relevant? This depends on the
kind of problem in which the linear operator occurs. Large parts of the theory of
linear operators in Hilbert spaces have been developed in connection with quantum
mechanics where the linear operators are supposed to represent observables of a
quantum mechanical system and as such they should be self-adjoint (a property to
be addressed later). It turns out that typically linear operators are self-adjoint on
precisely one domain. Also the spectrum of a linear operator depends in a very
sensitive way on the domain. These statements will become obvious when we have
developed the corresponding parts of the theory.
20.2
Adjoints, Closed and Closable Operators
In the complex Hilbert space H = Cn with inner product ⟨x, y⟩= n
i=1 xiyi for all
x, y ∈Cn, consider a matrix A = (aij)i,j=1,... ,n with complex coefﬁcients. Let us
calculate, for x, y ∈Cn,
⟨x, Ay⟩=
n

i,j=1
xiaijyj =
n

i,j=1
xiaijyj = ⟨A∗x, y⟩
where we deﬁne the adjoint matrix A∗by (A∗)ji = aij, i.e. A∗= A
t is the transposed
complex conjugate matrix. This shows that for any n × n matrix A there exists an
adjoint matrix A∗such that for all x, y ∈Cn one has
⟨x, Ay⟩= ⟨A∗x, y⟩.
Certainly, in case of a linear operator in an inﬁnite-dimensional Hilbert space H
the elementary calculation in terms of components of the vector is not available.
Nevertheless, we are going to show that for any densely deﬁned linear operator A in
a Hilbert space H, there is a unique adjoint operator A∗such that
⟨x, Ay⟩= ⟨A∗x, y⟩
∀x ∈D(A∗), ∀y ∈D(A)
(20.1)
holds.
Theorem 20.1 (Existence and Uniqueness of the Adjoint Operator) For every
densely deﬁned linear operator A in a Hilbert space H there is a unique adjoint

20.2
Adjoints, Closed and Closable Operators
281
operator A∗such that relation (20.1) holds. The domain of the adjoint is deﬁned as
D(A∗) = {x ∈H : ∃Cx < ∞, |⟨x, Ay⟩| ≤Cx∥y∥∀y ∈D(A)} .
(20.2)
The adjoint is maximal among all linear operators B which satisfy ⟨Bx, y⟩= ⟨x, Ay⟩
for all x ∈D(B) and all y ∈D(A).
Proof
In the Exercises it is shown that the set D(A∗) is indeed a linear subspace
of H which contains at least the zero element of H. Take any x ∈D(A∗) and
deﬁne a function Tx : D(A) →C by Tx(y) = ⟨x, Ay⟩for all y ∈D(A). Linearity
of A implies that Tx is a linear function and this linear functional is bounded by
|Tx(y)| ≤Cx∥y∥, since x ∈D(A∗). Thus Theorems 16.3 and 16.4 apply and we get
a unique element x∗∈H such that Tx(y) = ⟨x∗, y⟩for all y ∈D(A). This deﬁnes
an assignment D(A∗) ∋x #→x∗∈H which we denote by A∗, i.e., A∗x = x∗for
all x ∈D(A∗).
By deﬁnition of Tx, the mapping D(A∗) ∋x #→Tx ∈H′ is antilinear; by our
convention the inner product is antilinear in the ﬁrst argument. We conclude that
A∗: D(A∗) →H is linear. By construction this linear operator A∗satisﬁes relation
(20.1) and is called the adjoint of the operator A.
Suppose that B is a linear operator in H which satisﬁes
⟨Bx, y⟩= ⟨x, Ay⟩
∀x ∈D(B),
∀y ∈D(A).
It follows immediately that D(B) ⊂D(A∗). If x ∈D(B) is given, take Cx = ∥Bx∥
for the constant in the deﬁnition of D(A∗). Therefore, for x ∈D(B) we have
⟨Bx, y⟩= ⟨A∗x, y⟩for all y ∈D(A), or Bx −A∗x ∈D(A)⊥= {0} since D(A)
is dense. We conclude that B is a restriction of the adjoint operator A∗, B ⊆A∗.
Therefore the adjoint operator A∗is the “maximal” operator which satisﬁes relation
(20.1).
2
Remark 20.1 The assumption in Theorem 20.1 that the operator is densely deﬁned
is essential for uniqueness of the adjoint. In case this assumption is not satisﬁed
one can still deﬁne an adjoint, but in many ways. Some details are discussed in the
Exercises.
Sometimes it is more convenient to use the equivalent deﬁnition (20.6) in the
Exercises for the domain of the adjoint of a densely deﬁned linear operator.
As Eqs. (20.1) and (20.2) clearly show, the adjoint depends in an essential way on the
inner product of the Hilbert space. Two different but topologically equivalent inner
products (i.e., both inner products deﬁne the same topology) give rise to two different
adjoints for a densely deﬁned linear operator. Again, some details are discussed in
the Exercises.
There is a simple relation (which is quite useful in many applications) between the
range of a densely deﬁned linear operator and the null space of its adjoint. The
relation reads as follows:
Lemma 20.1
For a densely deﬁned linear operator A in a Hilbert space H the
orthogonal complement of the range of A is equal to the nullspace of the adjoint A∗:
(ran A)⊥= N(A∗).
(20.3)

282
20
Linear Operators
Proof
The proof is simple. y ∈(ran A)⊥if, and only if, 0 = ⟨y, Ax⟩for all
x ∈D(A). This identity implies ﬁrst that y ∈D(A∗) and then 0 = ⟨A∗y, x⟩for all
x ∈D(A). Since D(A) is dense, we deduce y ∈(ran A)⊥if, and only if, A∗y = 0,
i.e. y ∈N(A∗).
2
As a ﬁrst straightforward application we state:
Lemma 20.2
Let A be a densely deﬁned injective linear operator in the Hilbert
space H with dense range ran A. Then the adjoint of A has an inverse which is given
by the adjoint of the inverse of A:
(A∗)−1 = (A−1)∗.
Proof See Exercises!
2
In the deﬁnition of the adjoint of a densely deﬁned linear operator A the explicit
deﬁnition (20.2) of the domain plays an important role. Even in concrete examples
it is not always straightforward to translate this explicit deﬁnition into a concrete
description of the domain of the adjoint, and this in turn has the consequence that
it is not a simple task to decide when a linear operator is equal to its adjoint, i.e.,
whether the linear operator is self-adjoint. We discuss a relatively simple example
where we can obtain an explicit description of the domain of the adjoint.
Example 20.1 In the Hilbert space H = L2([0, 1]) consider the linear operator of
multiplication with the function x−α for some α > 1/2 on the domain D(A) =

f ∈L2([0, 1]) : f = χn · g, g ∈L2([0, 1]), n ∈N

where χn is the characteristic
function of the subinterval [ 1
n, 1], i.e., D(A) consists of those elements in L2([0, 1])
which vanish in some neighborhood of zero. It is easy to verify that limn→∞χn·g = g
in L2([0, 1]). Hence A is densely deﬁned and thus has a unique adjoint. If g ∈D(A∗),
then there is some constant such that for all n ∈N and all f ∈L2([0, 1])
|⟨g, Aχn · f ⟩2| ≤C∥χn · f ∥2.
Now we use the fact that the multiplication of functions is commutative and obtain
⟨g, Aχn · f ⟩2 =
 1
0
g(x)x−αf (x) dx = ⟨χn · Ag, f ⟩2.
Since obviously ∥χn · f ∥2 ≤∥f ∥2 the estimate
|⟨χn · Ag, f ⟩2| ≤C∥f ∥2
results for all n ∈N and all f ∈L2([0, 1]). It follows that ∥χn · Ag∥2 ≤C for all
n ∈N, i.e.,
 1
1
n
|x−αg(x)|2 dx ≤C2
∀n ∈N
and thus in the limit n→∞we deduce x−αg ∈L2([0, 1]) and therefore the explicit
characterization of the domain of the adjoint reads
D(A∗) =

g ∈L2([0, 1]) : x−αg ∈L2([0, 1])

.

20.2
Adjoints, Closed and Closable Operators
283
In this example the domain of the operator is properly contained in the domain of
the adjoint.
Other examples are studied in the Exercises.
As is well known from analysis, the graph of a function often reveals important
details. This applies in particular to linear operators and their graphs. Let us recall
the deﬁnition of the graph Γ (A) of a linear operator from a Hilbert space H into a
Hilbert space K, with domain D(A):
Γ (A) = {(x, y) ∈H × K : x ∈D(A), y = Ax}.
(20.4)
Clearly, Γ (A) is a linear subspace of H×K. It is an important property of the operator
A whether the graph is closed or not. Accordingly these operators are singled out in
the following deﬁnition.
Deﬁnition 20.3 A linear operator A from H into K is called closed if, and only if,
its graph Γ (A) is a closed subspace of H × K.
When one has to use the concept of a closed linear operator the following
characterization is very helpful.
Theorem 20.2 Let A be a linear operator from a Hilbert space H into a Hilbert
space K. The following statements are equivalent.
a) A is closed.
b) For every sequence (xn)n∈N ⊂D(A) which converges to some x ∈H and for
which the sequence of images (Axn)n∈N converges to some y ∈K, it follows that
x ∈D(A) and y = Ax.
c) For every sequence (xn)n∈N ⊂D(A) which converges weakly to some x ∈H and
for which the sequence of images (Axn)n∈N converges weakly to some y ∈K, it
follows that x ∈D(A) and y = Ax.
d) Equipped with the inner product,
⟨(x, Ax), (y, Ay)⟩= ⟨x, y⟩H + ⟨Ax, Ay⟩K ≡⟨x, y⟩A
(20.5)
for (x, Ax), (y, Ay) ∈Γ (A), the graph Γ (A) is a Hilbert space.
Proof The graph Γ (A) is closed if, and only if, every point (x, y) ∈H × K in
the closure of Γ (A) actually belongs to this graph. And a point (x, y) belongs to
closure of Γ (A) if, and only if, there is a sequence of points (xn, Axn) ∈Γ (A)
which converges to (x, y) in the Hilbert space H × K. The hypothesis in statement
a) says that we consider a sequence in the graph of A which converges to the point
(x, y) ∈H × K. The conclusion in this statement expresses the fact that this limit
point is a point in the graph of A. Hence statements (a) and (b) are equivalent.
Since a linear subspace of the Hilbert space H × K is closed if, and only if, it is
weakly closed, the same reasoning proves the equivalence of statements (a) and (c).
Finally consider the graph Γ (A) as an inner product space with the inner product
⟨·, ·⟩A. A Cauchy sequence in this space is a sequence ((xn, Axn))n∈N ⊂Γ (A) such

284
20
Linear Operators
that for every ε > 0 there is an n0 ∈N such that
∥(xn, Axn) −(xm, Axm)∥A =

∥xn −xm∥2
H + ∥Axn −Axm∥2
K ≤ε
∀n, m ≥n0.
Completeness of this inner product space expresses the fact that such a sequence
converges to a point (x, Ax) ∈Γ (A).
According to the above Cauchy condition the sequence (xn)n∈N ⊂D(A) is a
Cauchy sequence in the Hilbert space H and the sequence (Axn)n∈N is a Cauchy
sequence in the Hilbert space K. Thus these sequences converge to a point x ∈H,
respectively to a point y ∈K. Now A is closed if, and only if, this limit point
(x, y) belongs to the graph Γ (A), i.e., if and only if, this inner product space is
complete.
2
It is instructive to compare the concept of a closed linear operator with that of a
continuous linear operator. One can think of a closed operator A from H into K as
a “quasicontinuous” operator in the following sense: If a sequence (xn)n∈N ⊂D(A)
converges in H and if the sequence of images (Axn)n∈N converges in K, then
lim
n→∞Axn = A( lim
n→∞xn).
In contrast continuity of A means: Whenever the sequence (xn)n∈N ⊂D(A) con-
verges in H, the sequence of images (Axn)n∈N converges in K and the above relation
between both limits is satisﬁed.
As one would expect, not all linear operators are closed. A simple example of
such an operator which is not closed is the operator of multiplication with x−α in
L2([0, 1]) discussed earlier in this section. To see that this operator is not closed take
the following sequence (fn)n∈N ⊂D(A) deﬁned by
fn(x) =
⎧
⎨
⎩
xα,
1
n < x ≤1,
0,
0 ≤x ≤1
n.
The sequence of images then is
gn(x) = Afn(x) =
⎧
⎨
⎩
1,
1
n < x ≤1,
0,
0 ≤x ≤1
n.
Clearly, both sequences have a limit f , respectively g, in L2([0, 1]), f (x) = xα,
g(x) = 1, for all x ∈[0, 1]. Obviously g = Af , but f ̸∈D(A); hence this operator
is not closed.
Thus there are linearoperatorswhicharenotclosed. Someoftheselinearoperators
might have extensions which are closed. This is addressed in the following deﬁnition.
Deﬁnition 20.4 A linear operator A from H into K is called closable if, and only
if, A has an extension B which is a closed linear operator from H into K.
The closure of a linear operator A, denoted by A, is the smallest closed extension
of A, if it exists.

20.2
Adjoints, Closed and Closable Operators
285
Naturally, in the deﬁnition of closure the natural ordering among linear operators is
used. This means: If B is a closed extension of A, then A ⊆B.
For densely deﬁned linear operators one has a convenient characterization of those
operators which are closable as we learn in the following
Theorem 20.3 (Closability of Densely Deﬁned Operators) Suppose A is a densely
deﬁned linear operator in the Hilbert space H. It follows that
a) If B is an extension of A, then the adjoint A∗of A is an extension of the adjoint
B∗of B: A ⊆B ⇒B∗⊆A∗.
b) The adjoint A∗of A is closed: A∗= A∗.
c) A is closable if, and only if, its adjoint A∗is densely deﬁned, and in this case the
closure of A is equal to the bi-adjoint A∗∗= (A∗)∗of A: A = A∗∗.
Proof
Suppose A ⊆B and y ∈D(B∗), i.e., there is a constant C such that
|⟨y, Bx⟩| ≤C∥x∥for all x ∈D(B). Since D(A) ⊆D(B) and Ax = Bx
for all x ∈D(A), we deduce y ∈D(A∗) (one can use the same constant C)
and ⟨B∗y, x⟩= ⟨y, Bx⟩= ⟨y, Ax⟩= ⟨A∗y, x⟩for all x ∈D(A). Hence
B∗y −A∗y ∈D(A)⊥= {0} since D(A) is dense. Therefore D(B∗) ⊆D(A∗)
and B∗y = A∗y for all y ∈D(B∗), i.e., B∗⊆A∗.
In order to prove part (b) take any sequence ((yn, A∗yn))n∈N ⊂Γ (A∗) which
converges in H × H to a point (y, z). It follows that, for all x ∈D(A),
⟨y, Ax⟩= lim
n→∞⟨yn, Ax⟩= lim
n−→∞⟨A∗yn, x⟩= ⟨z, x⟩,
and we deduce |⟨y, Ax⟩| ≤∥z∥∥x∥for all x ∈D(A), hence y ∈D(A∗) and
⟨z, x⟩= ⟨y, Ax⟩= ⟨A∗y, x⟩for all x ∈D(A) and thus z = A∗y, i.e., (y, z) =
(y, A∗y) ∈Γ (A∗). Therefore A∗is closed.
Finally, for the proof of part (c), observe that a linear operator A is closable if,
and only if, the closure Γ (A) of its graph Γ (A) is the graph of a linear operator.
Furthermore, an easy exercise shows that a linear subspace M ⊂H×H is the graph
of a linear operator in H if, and only if,
(0, y) ∈M ⇒y = 0.
We know (Corollary 16.1): Γ (A) = (Γ (A)⊥)⊥. Now
(x, y) ∈Γ (A)⊥⇔0 = ⟨(x, y), (z, Az)⟩H×H = ⟨x, z⟩+ ⟨y, Az⟩∀z ∈D(A),
i.e., ⇔y ∈D(A∗), x = −A∗y. Similarly,
(u, v) ∈(Γ (A)⊥)⊥⇔0 = ⟨(u, v), (x, y)⟩H×H = ⟨u, −A∗y⟩+ ⟨v, y⟩∀y ∈D(A∗),
i.e., ⇔⟨u, A∗y⟩= ⟨v, y⟩∀y ∈D(A∗). This shows: (0, v) ∈Γ (A) ⇔v ∈D(A∗)⊥.
Therefore Γ (A) is the graph of a linear operator if, and only if, D(A∗)⊥= {0} and
thus we conclude by Corollary 16.2 that Γ (A) is the graph of a linear operator if,
and only if, D(A∗) is dense.

286
20
Linear Operators
Now suppose that A∗is densely deﬁned. Then we know that its adjoint (A∗)∗=
A∗∗is well deﬁned. The above calculations show
(u, v) ∈Γ (A) ⇔⟨u, A∗y⟩= ⟨v, y⟩
∀y ∈D(A∗),
i.e., ⇔u ∈D(A∗∗), v = A∗∗u, and therefore
Γ (A) = Γ (A∗∗).
Since the closure A is deﬁned through the relation Γ (A) = Γ (A) this proves
Γ (A) = Γ (A∗∗)
and the proof is complete.
2
20.3
Symmetric and Self-Adjoint Operators
In the previous section, for densely deﬁned linear operators in a Hilbert space the
adjoints were deﬁned. In general, one can not compare a densely deﬁned linear
operator A with its adjoint A∗. However there are important classes of such operators
where such a comparison is possible. If we can compare the operators A and A∗,
there are two prominent cases to which we direct our attention in this section: (1)
The adjoint A∗is equal to A. (2) The adjoint is an extension of A. These two classes
of operators are distinguished by proper names according to the
Deﬁnition 20.5 A densely deﬁned linear operator A in a Hilbert space H is called
a) symmetric if, and only if, A ⊆A∗;
b) self-adjoint if, and only if, A = A∗;
c) essentially self-adjoint if, and only if, A is symmetric and its closure A is self-
adjoint.
In the deﬁnition of an essentially self-adjoint operator we obviously rely on the
following result.
Corollary 20.1 A symmetric operator A is always closable. Its closure is the bi-
adjoint of A: A = A∗∗and the closure is symmetric too.
Proof For a symmetric operator the adjoint is densely deﬁned so that Theorem 20.3
applies. Since the adjoint is always closed, the relation A ⊆A∗implies A ⊆A∗and
hence the closure is symmetric: A = A∗∗⊆(A)∗
2
Another simple but useful observation about the relation between closure and
adjoint is
Corollary 20.2
Let A be a densely deﬁned linear operator with closure A. Then
the adjoint of the closure is equal to the adjoint:
(A)∗= A∗.
Proof The simple proof is left as an exercise.
2

20.3
Symmetric and Self-Adjoint Operators
287
Thus for symmetric operators we can assume that they are closed. By deﬁnition,
the closure of an essentially self-adjoint operator is self-adjoint. From the discussion
above we deduce for such an operator that
A∗= A∗∗= A
and conversely, if this relation holds for a symmetric operator it is essentially self-
adjoint.
Certainly, a self-adjoint operator is essentially self-adjoint (A∗= A implies
A∗∗= A∗). However, in general, an essentially self-adjoint operator is not self-
adjoint, but such an operator has a unique self-adjoint extension, namely its closure.
The proof is easy: Suppose that B is a self-adjoint extension of A. A ⊆B implies
ﬁrst B∗⊆A∗and then A∗∗⊆B∗∗. Since B∗= B and A∗= A∗∗we get B = B∗⊆
A∗= A∗∗⊆B∗∗= B, i.e., B = A∗= A.
The importance of the concept of an essentially self-adjoint operator is based on
the fact that an operator can be essentially self-adjoint on many different domains
while it is self-adjoint on precisely one domain. The ﬂexibility in the domain of
an essentially self-adjoint operator is used often in the construction of self-adjoint
operators, for instance, in quantum mechanics. For differential operators such as
Schrödinger operators it is not very difﬁcult to ﬁnd a dense domain D0 on which
this operator is symmetric. If one succeeds in showing that the operator is essentially
self-adjoint on D0, one knows that it has a unique self-adjoint extension, namely its
closure. This requires that the domain D0 is large enough. If one only knows that the
operator is symmetric on this domain, the problem of constructing all different self-
adjoint extensions arises. Even more ﬂexibility in the initial choice of the domain is
assured through the use of the concept of core of a closed operator.
Deﬁnition 20.6 Suppose that A is a closed linear operator.A subset D of the domain
D(A) of A is called a core of A if, and only if, the closure of the restriction of A to
the linear subspace lin D is equal to A: A|lin D = A.
It is important to be aware of the ﬁne differences of the various classes of linear
operators we have introduced. The following table gives a useful survey for a densely
deﬁned linear operator A.
Operator A
Properties
Symmetric
A ⊆A = A∗∗⊆A∗
Closed and symmetric
A = A = A∗∗⊆A∗
Essentially self-adjoint
A ⊆A = A∗∗= A∗
Self-adjoint
A = A = A∗∗= A∗.
Thedirectproofofself-adjointnessofagivenlinearoperatorisusuallyimpossible.
Fortunately there are several quite general criteria available. Below the two basic
characterizations of self-adjointness are proven.
Theorem 20.4 (Self-adjointness) For a symmetric operator A in a Hilbert space
H, the following statements are equivalent.

288
20
Linear Operators
a) A is self-adjoint: A∗= A;
b) A is closed and N(A∗± iI) = {0};
c) ran (A ± iI) = H.
Proof We proceed with the equivalence proof in the following order: (a) ⇒(b) ⇒
(c) ⇒(a).
Suppose A is self-adjoint. Then A is certainly closed. Consider φ± ∈N(A∗± iI).
A∗φ± = ∓iφ± implies
∓i⟨φ±, φ±⟩= ⟨φ±, A∗φ±⟩= ⟨Aφ±, φ±⟩= ⟨A∗φ±, φ±⟩= ±i⟨φ±, φ±⟩,
and thus ⟨φ±, φ±⟩= ∥φ±∥2 = 0, i.e., φ± = 0.
Next assume that A is a closed symmetric operator such that N(A∗± iI) = {0}.
Relation (20.3) gives N(A∗+ zI) = (ran (A + zI))⊥and therefore ran (A ± iI) =
(N(A∗± iI))⊥= H. Hence for the proof of (c) it sufﬁces to show that ran (A ± iI)
is closed. Suppose x = limn→∞xn, xn = (A ± iI)yn, yn ∈D(A), n ∈N. It is
straightforward to calculate, for all n, m ∈N,
∥xn −xm∥2 = ∥(A ± iI)(yn −ym)∥2 = ∥Ayn −Aym∥2 + ∥yn −ym∥2.
Therefore, with (xn)n∈N also, the two sequences (yn)n∈N and (Ayn)n∈N are Cauchy
sequences in the Hilbert space H and thus they converge too, to y, respectively z.
Since A is closed, y ∈D(A) and z = Ay, hence x = (A ± iI)y ∈ran (A ± iI),
and this range is closed. Statement (c) follows.
Finally assume (c). Since A is symmetric it sufﬁces to show that the domain
of the adjoint is contained in the domain of A. Consider any y ∈D(A∗), then
(A∗−iI)y ∈H. Hypothesis (c) implies that there is some ξ ∈D(A) such that
(A∗−
iI)y = (A −
iI)ξ = (A∗−
iI)ξ, hence (A∗−
iI)(y −ξ) = 0 or
y −ξ ∈N(A∗−iI) = (ran (A + iI)))⊥= {0}. This proves y = ξ ∈D(A) and
ﬁnally D(A∗) = D(A), i.e., A∗= A.
2
The proof of this theorem has also established the following relation between
the closure of the range of a symmetric operator and the range of the closure of the
operator:
ran (A ± iI) = ran (A ± iI).
Together with Corollary 20.2 this observation implies
Corollary 20.3
For a symmetric operator A in a Hilbert space H the following
statements are equivalent:
a) A is essentially self-adjoint;
b) N(A∗± iI) = {0};
c) ran (A ± iI) = H.
In particular one knows for a closed symmetric operator that
ran (A + iI)
and
ran (A −iI)
are closed linear subspaces of H. Without proof we mention that a closed symmetric
operator has self-adjoint extensions if, and only if, the orthogonal complements of

20.4
Examples
289
these subspaces have the same dimension:
dim (ran (A + iI))⊥= dim (ran (A −iI))⊥
or
dim N(A∗+ iI) = dim N(A∗−iI).
The main difﬁculty in applying these criteria for self-adjointness is that one usually
does not know the explicit form of the adjoint so that it is not obvious at all to check
whether N(A∗± iI) is trivial. Later, in connection with our study of Schrödinger
operators we will learn how in special cases one can master this difﬁculty.
20.4
Examples
The concepts and the results of the previous three sections are illustrated by several
examples which are discussed in some detail.
20.4.1
Operator of Multiplication
Suppose that g : Rn →C is a continuous (but not necessarily bounded) function.
We want to deﬁne the multiplication with g as a linear operator in the Hilbert space
H = L2(Rn). To this end the natural domain
Dg =

f ∈L2(Rn) : g · f ∈L2(Rn)

is introduced. With this domain we denote the operator of multiplication with g by
Mg, (Mgf )(x) = g(x)f (x) for almost all x ∈Rn and all f ∈Dg. This operator is
densely deﬁned since it contains the dense subspace
D0 =

χr · f : f ∈L2(Rn), r > 0

⊂L2(Rn).
Here χr denotes the characteristic function of the closed ball of radius r and center 0.
The reader is asked to prove this statement as an exercise. As a continuous function,
g is bounded on the closed ball with radius r, by a constant Cr let us say. Thus the
elementary estimate
∥g · χrf ∥2 =

|x|≤r
|g(x)|2|f (x)|2 dx ≤C2
r ∥f ∥2
2
∀f ∈L2(Rn), ∀r > 0
proves D0 ⊆Dg and the operator Mg is densely deﬁned. In order to determine
the adjoint of Mg, take any h ∈D(M∗
g); then h∗= M∗
gh ∈L2(Rn) and for all
f ∈Dg one has ⟨h, Mgf ⟩= ⟨h∗, f ⟩, in particular for all χrf , f ∈L2(Rn), r > 0,

290
20
Linear Operators
⟨h∗, χrf ⟩= ⟨h, Mgχrf ⟩. Naturally, the multiplication with χr commutes with the
multiplication with g, thus
⟨h, Mgχrf ⟩= ⟨h, χrMgf ⟩= ⟨χrh, Mgf ⟩= ⟨χrMgh, f ⟩,
or ⟨χrh∗, f ⟩= ⟨χrMgh, f ⟩for all f ∈L2(Rn) and all r > 0. It follows that
χrh∗= χrgh for all r > 0 and therefore

|x|≤r
|(gh)(x)|2 dx =

|x|≤r
|h∗(x)|2 dx ≤∥h∗∥2
2
for all r > 0. We deduce g ·h ∈L2(Rn) and h∗= g ·h = Mgh, hence h ∈Dg = Dg
and M∗
g = Mg. This shows that the adjoint of the operator of multiplication with
the continuous function g is the multiplication with the complex conjugate function
g, on the same domain. Therefore, this multiplication operator is always closed. In
particular the operator of multiplication with a real valued continuous function is
self-adjoint.
Our arguments are valid not only for continuous functions but for all measurable
functions g which are bounded on all compact subsets of Rn. In this case the operator
of multiplication with g is the prototype of a self-adjoint operator, as we will learn
in later chapters.
20.4.2
Momentum Operator
As a simple model of the momentum operator in a one-dimensional quantum
mechanical system we discuss the operator
P = i d
dx
in the Hilbert space H = L2([0, 1]). Recall that a function f ∈L2([0, 1]) is called
absolutely continuous if, and only if, there is a function g ∈L1([0, 1]) such that for
all 0 ≤x0 < x ≤1 one has f (x) −f (x0) =
 x
x0 g(y) dy. It follows that f has a
derivative f ′ = g almost everywhere. Initially we are going to use as a domain for
P the subspace
D =

f ∈L2([0, 1]) : f is absolutely continuous, f ′ ∈L2([0, 1])

.
This subspace is dense in L2([0, 1]) and clearly P is well deﬁned by
(Pf )(x) = if ′(x)
for almost all x ∈[0, 1], ∀f ∈D.
For arbitrary f, g ∈D one has
⟨f , Pg⟩2 =
 1
0
f (x) ig′(x) dx = if (x)g(x)|1
0 −i
 1
0
f ′(x)g(x) dx

20.4
Examples
291
= i [f (1)g(1) −f (0)g(0)] + ⟨Pf , g⟩2.
Hence P will be symmetric on all domains D′ for which
f (1)g(1) −f (0)g(0) = 0
∀f, g ∈D′
holds. These are the subspaces
Dγ =

f ∈D : f (1) = e i γ f (0)

,
γ ∈R
as one sees easily. In this way we have obtained a one parameter family of symmetric
operators
Pγ = P|Dγ ,
D(Pγ ) = Dγ ,
γ ∈R.
These operators are all extensions of the symmetric operator P∞= P|D∞, D∞=
{f ∈D : f (1) = f (0) = 0}.
Lemma 20.3 For all γ ∈R the symmetric operator Pγ is self-adjoint.
Proof
For f ∈D(P ∗
γ ) we know f ∗= P ∗
γ f ∈L2([0, 1]) ⊂L1([0, 1]), hence
hc(x) =
 x
0 f ∗(y) dy + c is absolutely continuous and satisﬁes h′
c(x) = f ∗(x)
almost everywhere. Clearly hc belongs to L2([0, 1]), thus hc ∈D. Now calculate,
for all g ∈Dγ :
⟨f , Pγ g⟩2 = ⟨f ∗, g⟩2 =
 1
0
h′c(x)g(x) dx = hc(x)g(x)|1
0 −
 1
0
hc(x)g′(x) dx
= [hc(1) eiγ −hc(0)]g(0) −⟨ihc, Pγ g⟩2,
or
⟨f + ihc, Pγ g⟩2 = [hc(1) eiγ −hc(0)]g(0)
∀g ∈Dγ .
Observe that the subspace

u ∈L2([0, 1]) : u = g′, g ∈Dγ , g(0) = 0

is dense in
L2([0, 1]). This implies f (x) + ihc(x) = 0 almost everywhere and thus f ∈D and
if ′ = h′
c = f ∗. From the above identity we now deduce [hc(1) eiγ −hc(0)]g(0) = 0
for all g ∈Dγ , and it follows that hc(1) e −iγ −hc(0) = 0, hence f ∈Dγ . Since
f ∈D(P ∗
γ ) was arbitrary, this shows that D(P ∗
γ ) = Dγ and P ∗
γ f = Pγ f for all
f ∈Dγ . Hence, for every γ ∈R, the operator Pγ is self-adjoint.
2
We conclude that the operator P∞has a one parameter family of self-adjoint ex-
tensions Pγ , γ ∈R. Our argument shows moreover that every self-adjoint extension
of P∞is of this form.
20.4.3
Free Hamilton Operator
In suitable units the Hamilton operator of a free quantum mechanical particle in
Euclidean space R3 is
H0 = −△3
on a suitable domain D(H0) ⊂L2(R3). Recall Plancherel’s Theorem 10.7. It says
that the Fourier transform F2 is a “unitary” mapping of the Hilbert space L2(R3).

292
20
Linear Operators
Theorem 10.3 implies that for all f in
D(H0) =
 
f = F2 ˜f ∈L2(R3) : p2 ˜f ∈L2(R3)
!
= H 2(R3)
one has
H0f = F2(Mp2 ˜f ).
Here ˜f denotes the inverse Fourier transform of f . Since we know from our ﬁrst
example that the operator of multiplication with the real valued function g(p) = p2
is self-adjoint on the domain

g ∈L2(R3) : p2g ∈L2(R3)

, unitarity of F2 implies
that H0 is self-adjoint on the domain D(H0) speciﬁed above. This will be evident
when we have studied unitary operators in some details later (Sect. 22.2).
20.5
Exercises
1. Let g : R→C be a bounded continuous function. Denote by Mg the multiplication
of a function f : R→C with the function g. Show: Mg deﬁnes a linear operator
in the Hilbert space H = L2(R) with domain D(Mg) = L2(R).
2. Denote by Dn the space of all continuous functions f : R→C for which
p0,n(f ) = sup
x∈R
(1 + x2)n/2|f (x)|
is ﬁnite. Show: Dn+1 ⊊Dn for n = 0, 1, 2, . . . and for n = 1, 2, . . . Dn is a dense
linear subspace of the Hilbert space H = L2(R). Denote by Q multiplication
with the variable x, i.e., (Qf )(x) = xf (x) for all x ∈R. Show that Q deﬁnes
a linear operator Qn in L2(R) with domain D(Qn) = Dn and Qn+1 ⊆Qn for
n = 2, 3, . . . .
3. Denote by Ck(R) the space of all functions f : R→C which have contin-
uous derivatives up to order k. Deﬁne (Pf )(x) =
i df
dx (x) for all x ∈R
and all f ∈Ck(R) for k ≥1. Next deﬁne the following subset of L2(R):
Dk =
 
f ∈L2(R) ∩Ck(R) : df
dx ∈L2(R)
!
. Show that Dk is a dense linear sub-
space of L2(R). Then show that P deﬁnes a linear operator Pk in L2(R) with
domain D(Pk) = Dk and that Pk+1 ⊆Pk for k = 1, 2, . . . .
4. Show that the set (20.2) is a linear subspace of the Hilbert space.
5. Prove: The domain D(A∗) of the adjoint of a densely deﬁned linear operator A
(see (20.2) is a linear subspace of H which can also be deﬁned as
D(A∗) =
⎧
⎪⎨
⎪⎩
x ∈H :
sup
y∈D(A)
∥y∥=1
|⟨x, Ay⟩| < ∞
⎫
⎪⎬
⎪⎭
.
(20.6)
6. Let A be a linear operator in a Hilbert space H whose domain D(A) is not dense
in H. Characterize the nonuniqueness in the deﬁnition of an adjoint.

20.5
Exercises
293
7. Let H be a Hilbert space with inner product ⟨·, ·⟩. Suppose that there is another
inner product ⟨·, ·⟩1 on the vector space H and there are two positive numbers
α, β such that
α⟨x, x⟩≤⟨x, x⟩1 ≤β⟨x, x⟩
∀x ∈H.
Consider the antilinear canonical isomorphisms J (respectively J1) between H
and its topological dual H′, deﬁned by J(x)(y) = ⟨x, y⟩(respectively J1(x)(y) =
⟨x, y⟩1) for all x, y ∈H. Prove:
a) Both inner products deﬁne the same topology on H.
b) Both (H, ⟨·, ·⟩) and (H, ⟨·, ·⟩1) are Hilbert spaces.
c) Let A be a linear operator in H with domain D(A) = H and ∥Ax∥≤C∥x∥
for all x ∈H, for some constant 0 ≤C < ∞. This operator then deﬁnes an
operator A′ : H′ →H′ by ℓ#→A′ℓ, A′ℓ(x) = ℓ(Ax) for all ℓ∈H′ and all
x ∈H. Use the maps J and J1 to relate the adjoints A∗(respectively A∗
1) of
A with respect to the inner product ⟨·, ·⟩(respectively with respect to ⟨·, ·⟩1) to
the operator A′.
d) Show the relation between A∗and A∗
1.
8. Prove Lemma 20.2.
9. Prove Corollary 20.2.

Chapter 21
Quadratic Forms
Quadratic forms are a powerful tool for the construction of self-adjoint operators, in
particular in situations when the natural strategy fails (for instance for the addition
of linear operators). For this reason we give a brief introduction to the theory of
quadratic forms. After the basic concepts have been introduced and explained by
some examples, we give the main results of the representation theory of quadratic
forms including detailed proofs. The power of these representation theorems is il-
lustrated through several important applications (Friedrich’s extension, form sum of
operators).
21.1
Basic Concepts. Examples
We begin by collecting the basic concepts of the theory of quadratic forms on a
Hilbert space.
Deﬁnition 21.1
Let H be a complex Hilbert space with inner product ⟨·, ·⟩. A
quadratic form E with domain D(E) = D, where D is a linear subspace of H is
a mapping E : D × D →C which is antilinear in the ﬁrst and linear in the second
argument. A quadratic form E in H is called
a) symmetric if, and only if, E(φ, ψ) = E(ψ, φ) for all φ, ψ ∈D(E)
b) densely deﬁned if, and only if, its domain D(E) is dense in H
c) semibounded (from below) if, and only if, there is a λ ∈R such that for all
ψ ∈D(E),
E(ψ, ψ) ≥−λ∥ψ∥2
this number λ is called a lower bound of E.
d) positive if, and only if, E is semibounded with lower bound λ = 0.
e) continuous if, and only if, there is a constant C such that
|E(φ, ψ)| ≤C∥φ∥∥ψ∥
∀φ, ψ ∈D(E).
Based on these deﬁnitions, one introduces several other important concepts.
© Springer International Publishing Switzerland 2015
295
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_21

296
21
Quadratic Forms
Deﬁnition 21.2
a) A semibounded quadratic form E with lower bound λ is called closed if, and only
if, the form domain D(E) is complete when it is equipped with the form norm
∥ψ∥E =

E(ψ, ψ) + (λ + 1)∥ψ∥2.
b) A quadratic form F with domain D(F) is called an extension of a quadratic form
E with domain D(E) if, and only if, D(E) ⊂D(F) and F(φ, ψ) = E(φ, ψ) for
all φ, ψ ∈D(E).
c) A quadratic form is called closable if, and only if, it has a closed extension.
d) A subset D′ ⊂D(E) of the domain of a closed quadratic form E is called a core
if, and only if, D′ is dense in the form domain D(E) equipped with the form norm
∥· ∥E.
These deﬁnitions are illustrated by several not atypical examples.
1. The inner product ⟨·, ·⟩of a complex Hilbert space H is a positive closed quadratic
form with domain H.
2. Suppose that A is a linear operator in the complex Hilbert space H with domain
D(A). In a natural way we can associate with A two quadratic forms with form
domain D(A):
E1(φ, ψ) = ⟨φ, Aψ⟩,
E2(φ, ψ) = ⟨Aφ, Aψ⟩.
We now relate properties of these quadratic forms to properties of the linear op-
erator A. The form E2 is always positive and symmetric. The quadratic forms are
densely deﬁned if, and only if, the operator A is. If the operator A is symmetric,
the quadratic form E1 is densely deﬁned and symmetric. The form E1 is semi-
bounded if, and only if, the operator A is bounded from below, i.e., if, and only
if, there is some λ ∈R such that ⟨ψ, Aψ⟩≥λ⟨ψ, ψ⟩for all ψ ∈D(A).
Since the form norm ∥· ∥E2 is equal to the graph norm of the operator A, the
quadratic form E2 is closed if, and only if, the operator A is closed.
It is important to note that even for a closed operator A the quadratic form E1 is
not necessarily closed.
Both quadratic forms E1 and E2 are continuous if A is continuous, i.e., if there
is some constant C such that ∥Aψ∥≤C∥ψ∥for all ψ ∈D(A).
The proof of all these statements is left as an exercise.
3. Suppose Ω ⊂Rn is an open nonempty set. We know that D = C∞
0 (Ω) is a dense
subspace in the complex Hilbert space H = L2(Ω). On D a quadratic form E is
well deﬁned by
E(φ, ψ) =

Ω
∇φ · ∇ψ d x =

Ω
n

i=1
∂φ
∂xi
(x)∂ψ
∂xi
(x) d x
∀φ, ψ ∈D.
This quadratic form is called the Dirichlet form on Ω. It is densely deﬁned and
positive, but not closed. However, the Dirichlet form has a closed extension. The

21.1
Basic Concepts. Examples
297
completion of the domain C∞
0 (Ω) with respect to the form norm ∥· ∥E,
∥ψ∥2
E =

Ω
[|ψ(x)|2 + |∇ψ(x)|2]d x
is just the Sobolev space H 1
0 (Ω) which is a Hilbert space with the inner product
⟨φ, ψ⟩1,2 = ⟨φ, ψ⟩2 +
n

i=1
⟨∂iφ, ∂iψ⟩2.
Here we use the abbreviation ∂i =
∂
∂xi and ⟨·, ·⟩2 is the inner product of the Hilbert
space L2(Ω). (Basic facts about completions are given in Appendix 34.1).
4. As in the previous example we are going to deﬁne a quadratic form E with domain
D(E) = C∞
0 (Ω) in the Hilbert space H = L2(Ω). Suppose we are given real
valued functions Aj ∈L2
loc(Ω), j = 1, . . . , n. On D(E) we deﬁne
E(φ, ψ) =

Ω
n

j=1
( −i ∂jφ + Ajφ)( −i ∂jψ + Ajψ) d x.
(Note that the assumption Aj ∈L2
loc(Ω) ensures Ajφ ∈L2(Ω) for all φ ∈D(E).)
This quadratic form is densely deﬁned and positive, but not closed. Later we will
come back to this example.
5. In the Hilbert space H = L2(R) the subspace D = C∞
0 (R) is dense. On this
subspace we deﬁne a quadratic form Eδ,
Eδ(f , g) = f (0)g(0).
It is trivial to see that Eδ is a positive quadratic form. It is also trivial to see that Eδ
is not closed. We show now that Eδ does not have any closed extension. To this end
consider a sequence of functions fn ∈D which have the following properties: (i)
0 ≤fn(x) ≤1 for all x ∈R; (ii) fn(0) = 1; (iii) supp fn ⊆[ −1
n, 1
n], for all n ∈N.
It follows that, as n →∞,
∥fn∥2
2 ≤2
n →0,
∥fn∥2
Eδ = |fn(0)|2 + ∥fn∥2
2 ≤1 + 2
n→1.
Property (i) implies that (fn)n∈N is a Cauchy sequence with respect to the form norm
∥· ∥Eδ. Suppose F is a closed extension of Eδ. Then we have the contradiction
0 = F(0, 0) = lim
n→∞F(fn, fn) = lim
n→∞Eδ(fn, fn) = 1,
hence Eδ has no closed extension.
These examples show:
1. There are closed, closable, nonclosable, symmetric, semibounded, densely
deﬁned, and continuous quadratic forms.

298
21
Quadratic Forms
2. Even positive and symmetric quadratic forms are not necessarily closable (see
Example 5), in contrast to the situation for symmetric operators.
3. Positive quadratic forms are closable in special cases when they are deﬁned in
terms of linear operators.
4. There are positive quadratic forms which cannot be deﬁned in terms of a linear
operator in the sense of Example 2 (see the Exercises).
21.2
Representation of Quadratic Forms
We have learned in the previous section that linear operators can be used to deﬁne
quadratic forms (Example 2) and we have mentioned an example of a densely deﬁned
positive quadratic form which cannot be represented by a linear operator in the
sense of this example. Naturally the question arises which quadratic forms can be
represented in terms of a linear operator. The main result of this section will be
that densely deﬁned, semi-bounded, closed quadratic forms can be represented by
self-adjoint operators bounded from below, and this correspondence is one-to-one.
We begin with the simplest case.
Theorem 21.1 Let E be a densely deﬁned continuous quadratic form in the Hilbert
space H. Then there is a unique continuous linear operator A : H→H such that
E(x, y) = ⟨x, Ay⟩
∀x, y ∈D(E).
In particular this quadratic form can be extended to the quadratic form F(x, y) =
⟨x, Ay⟩with domain H.
Proof
Since E is supposed to be continuous the estimate |E(x, y)| ≤C∥x∥∥y∥
is available for all x, y ∈D(E). Since D(E) is dense in H, every x ∈H is the
limit of a sequence (xn)n∈N ⊂D(E). Thus, given x, y ∈H, there are sequences
(xn)n∈N, (yn)n∈N ⊂D(E) such that x = limn→∞xn and y = limn→∞yn. As conver-
gent sequences in the Hilbert space H these sequences are bounded, by some M1,
respectively M2. For all n, m ∈N we estimate the quadratic form as follows:
|E(xn, yn) −E(xm, ym)| = |E(xn −xm, yn) + E(xm, yn −ym)|
≤|E(xn −xm, yn)| + |E(xm, yn −ym)|
≤C∥xn −xm∥∥yn∥+ C∥xm∥∥yn −ym∥
≤CM2∥xn −xm∥+ CM1∥yn −ym∥.
This shows that (E(xn, yn))n∈N is a Cauchy sequence in the ﬁeld C. We denote its
limit by F(x, y).As above, one shows that this limit does not depend on the sequences
(xn)n∈N and (yn)n∈N but only on their limits x, respectively y. Thus, F : H × H→C
is well deﬁned.
Basic rules of calculation for limits imply that F too is a quadratic form, i.e.,
antilinear in the ﬁrst and linear in the second argument. Furthermore, F satisﬁes the

21.2
Representation of Quadratic Forms
299
same estimate |F(x, y)| ≤C∥x∥∥y∥on H×H. Hence, for every x ∈H the mapping
H ∋y #→F(x, y) ∈C is a continuous linear functional. The Riesz–Fréchet theorem
(Theorem 16.3) implies that there is a unique x∗∈H such that F(x, y) = ⟨x∗, y⟩
for all y ∈H. Since F is antilinear in the ﬁrst argument as the inner product, the
mapping H ∋x #→x∗is linear, and thus deﬁnes a linear operator B : H→H by
Bx = x∗for all x ∈H. This shows that F(x, y) = ⟨Bx, y⟩for all x, y ∈H and thus,
deﬁning A = B∗, we get
F(x, y) = ⟨x, Ay⟩
∀x, y ∈H.
Since F is continuous, the bound |⟨x, Ay⟩| ≤C∥x∥∥y∥is available for all x, y ∈H.
We deduce easily that ∥Ax∥≤C∥x∥for all x ∈H and hence the operator A is
continuous.
2
Considerably deeper are the following two results which represent the core of the
representation theory for quadratic forms.
Theorem 21.2 (First Representation Theorem) Let H be a complex Hilbert space
and E a densely deﬁned, closed, and semibounded quadratic form in H. Then there
is a self-adjoint operator A in H which is bounded from below and which deﬁnes the
quadratic form in the following sense:
a)
E(x, y) = ⟨x, Ay⟩
∀x ∈D(E), ∀y ∈D(A) ⊂D(E).
(21.1)
b) The domain D(A) of the operator is a core of the quadratic form E.
c) If for y ∈D(E) there exists y∗∈H such that E(x, y) = ⟨x, y∗⟩for all elements
x of a core of E, then it follows: y ∈D(A) and y∗= Ay, i.e.,
i) the operator A is uniquely determined by Eq. 21.1;
ii) if D′ is a core of the quadratic form E, then the domain of the operator A is
characterized by
D(A) =

y ∈D(E) : ∃Cy ∈R+, |E(x, y)| ≤Cy∥x∥∀x ∈D′
.
Proof If λ ≥0 is a bound of the quadratic form E, the form norm ∥·∥E of E comes
from the inner product
⟨x, y⟩E = E(x, y) + (λ + 1)⟨x, y⟩
(21.2)
on D(E). Since E is closed, the form domain D(E) equipped with the inner product
⟨·, ·⟩E is a complex Hilbert space which we call HE. E(x, x) + λ∥x∥2 ≥0 implies
that
∥x∥≤∥x∥E
∀x ∈D(E).
(21.3)
Thus, for ﬁxed x ∈H, the mapping HE ∋y #→⟨x, y⟩∈C deﬁnes a continuous
linear functional on the Hilbert space H. Apply the theorem of Riesz–Fréchet to get

300
21
Quadratic Forms
a unique x∗∈HE such that ⟨x, y⟩= ⟨x∗, y⟩E for all y ∈H. As in the proof of
the representation theorem for continuous quadratic forms, it follows that the map
x #→x∗deﬁnes a linear operator J : H→HE. Hence, J is characterized by the
identity
⟨x, y⟩= ⟨Jx, y⟩E
∀x ∈H, ∀y ∈HE.
(21.4)
Since E is densely deﬁned, the domain D(E) is dense in H. Suppose Jx = 0, then
⟨x, y⟩= 0 for all y ∈D(E) and therefore x = 0, i.e., the operator J is injective. Per
construction we have
JH ⊆HE ⊆H.
This allows us to calculate, for all x, y ∈H, using Eq. (21.4),
⟨x, Jy⟩= ⟨Jx, Jy⟩E = ⟨Jy, Jx⟩E = ⟨y, Jx⟩= ⟨Jx, y⟩,
i.e., the operator J is symmetric. It is also bounded since
∥Jy∥≤∥Jy∥E = sup {|⟨x, Jy⟩E| : x ∈HE, ∥x∥E ≤1}
= sup {|⟨x, y⟩| : x ∈HE, ∥x∥E ≤1} ≤∥y∥.
Hence, J is a self-adjoint continuous operator with trivial null space N(J) = {0},
ran J ⊆HE, and ∥J∥′ = sup {∥Jy∥: y ∈H, ∥y∥≤1} ≤1. The range of J is dense
in H since its orthogonal complement is trivial: (ran J)⊥= N(J ∗) = N(J) = {0}.
Here Lemma 20.2 is used.
Now we can deﬁne a linear operator A as a simple modiﬁcation of the inverse
of J:
Ay = J −1y −(λ + 1)y
∀y ∈D(A) ≡ran J.
(21.5)
By Lemma 20.2 or Theorem 20.4 the operator J −1 is self-adjoint, hence A is
self-adjoint. This operator A indeed represents the quadratic form E as claimed
in Eq. (21.1). To see this take any x ∈D(E) and any y ∈D(A) ⊂D(E) and
calculate
E(x, y) = ⟨x, y⟩E −(λ + 1)⟨x, y⟩= ⟨x, J −1y⟩−(λ + 1)⟨x, y⟩= ⟨x, Ay⟩.
Since λ is a bound of the quadratic form E, the operator A is bounded from below:
For all y ∈D(A) the estimate ⟨y, Ay⟩+λ⟨y, y⟩= E(y, y)+λ⟨y, y⟩≥0 is available.
Next, we show that the domain of the operator A is a core of the quadratic
form E by showing that D(A) = ran J is dense in the Hilbert space HE. Take any
x ∈(ran J)⊥⊆HE. Equation (21.4) implies that
⟨x, y⟩= ⟨x, Jy⟩E = 0
∀y ∈H,
and thus x = 0 and accordingly D(A) is dense in HE.

21.2
Representation of Quadratic Forms
301
Finally, we prove part (c). Suppose D′ is a core of E and suppose that for some
y ∈D(E) there is a y∗∈H such that
E(x, y) = ⟨x, y∗⟩
∀x ∈D′.
Since ∥x∥≤∥x∥E, both sides of this identity are continuous with respect to the form
norm and thus this identity has a unique ∥·∥E-continuous extension to all of the form
domain D(E). In particular, for all x ∈D(A) ⊂D(E), we know E(x, y) = ⟨x, y∗⟩.
But for x ∈D(A) and y ∈D(E) the representation E(x, y) = ⟨Ax, y⟩holds
according to Eq. (21.1). This shows that
⟨Ax, y⟩= E(x, y) = ⟨x, y∗⟩
∀x ∈D(A),
and it follows that y ∈D(A∗) and y∗= A∗y. But A is self-adjoint. The characteri-
zation of the domain D(A) then is obvious from the above considerations. Thus we
conclude.
2
Theorem 21.3 (Second Representation Theorem) Under the same assumption as
in the ﬁrst representation theorem, let λ be a bound of E and let A be the self-adjoint
operator determined by E according to Theorem 21.2. Then it follows:
a) A + λI ≥0;
b) D(√A + λI) = D(E) and for all x, y ∈D(E) the identity
E(x, y) + λ⟨x, y⟩= ⟨
√
A + λIx,
√
A + λIy⟩
(21.6)
holds;
c) a subset D′ ⊂D(E) is a core of the quadratic form E if, and only if, it is a core
of the operator √A + λI.
Proof The fact that a positive self-adjoint operator B has a unique square root
√
B,
which is a self-adjoint operator with domain D(
√
B) ⊇D(B) and characteristic
identity (
√
B)2 = B, will be shown in Theorem 28.1 (and for bounded operators
B in the next chapter, Theorem 22.4). D(B) is a core of the square root
√
B. Here,
we simply use these results for an interesting and important extension of the ﬁrst
representation theorem of quadratic forms.
Thus, the positive operator A+λI has a unique self-adjoint square root √A + λI
on a domain D = D(√A + λI) ⊇D(A). As in Example 2 of the previous section,
deﬁne a quadratic form E′ on this domain by E′(x, y) = ⟨√A + λIx, √A + λIy⟩.
Since √A + λI is self-adjoint we know from Example 2 that E′ is a positive, closed,
and densely deﬁned quadratic form. On D(A) ⊆D(E′) we can relate this form to
the operator A itself and thus to the original quadratic form E:
E′(x, y) = ⟨
√
A + λIx,
√
A + λIy⟩= ⟨x,
√
A + λI
√
A + λIy⟩
= ⟨x, (A + λI)y⟩= E(x, y) + ⟨x, y⟩.
According to the results from spectral theory the domain of A is a core of the operator
√A + λI. Hence, D(A) is a core of the quadratic form E′. According to part (b) of

302
21
Quadratic Forms
Theorem 21.2, D(A) is also a core of the quadratic form E. Hence, the quadratic
forms E′ and E + λ⟨·, ·⟩agree. This proves part (b). Part (c) follows immediately
from part (b).
2
21.3
Some Applications
Given two densely deﬁned operators we will construct, under certain assumptions
about these operators, self-adjoint operators using the representation theorems of
quadratic forms, for three important cases. The results which we obtain in this way
have many applications, in particular in quantum mechanics, but not only there.
Theorem 21.4
Suppose that B is a densely deﬁned closed linear operator in the
complex Hilbert space H. Then, on the domain
D(B∗B) =

x ∈D(B) : Bx ∈D(B∗)

,
the operator B∗B is positive and self-adjoint. The domain D(B∗B) is a core of the
operator B.
Proof On the domain of the operator deﬁne a quadratic form E(x, y) = ⟨Bx, By⟩
for all x, y ∈D(B). One proves (see Example 2 above) that this is a densely deﬁned,
positive, and closed quadratic form. So the ﬁrst representation theorem applies:
There is a unique self-adjoint operator A with domain D(A) ⊆D(B) such that
⟨Bx, By⟩= ⟨x, Ay⟩for all x ∈D(B) and all y ∈D(A). This implies ﬁrst that
By ∈D(B∗) for y ∈D(A) and then that B∗B is an extension of A: A ⊆B∗B.
Hence, B∗B is a densely deﬁned linear operator. Now it follows easily that B∗B is
symmetric and thus A ⊆B∗B ⊂(B∗B)∗⊆A∗= A, i.e., A = B∗B. The second
part of the ﬁrst representation ﬁnally proves that D(B∗B) = D(A) is a core of the
operator B.
2
As we had argued earlier a symmetric operator can have, in some cases, many self-
adjoint extensions. For positive symmetric operators one can construct a “smallest”
self-adjoint extension, using again the representation results for quadratic forms.
Theorem 21.5 (Friedrichs Extension) Let A be a positive (or lower bounded)
symmetric linear operator in a complex Hilbert space H. Then A has a positive self-
adjoint extension AF which is the smallest among all positive self-adjoint extensions
in the sense that it has the smallest form domain. This extension AF is called the
Friedrichs extension of A.
Proof We give the proof for the case of a positive symmetric operator. The neces-
sary modiﬁcations for the case of a lower bounded symmetric operator are obvious
(compare the proofs of the representation theorems).
On the domain of the operator deﬁne a quadratic form E(x, y) = ⟨x, Ay⟩for all
x, y ∈D(E) = D(A). E is a densely deﬁned positive quadratic form and ⟨x, y⟩E =
E(x, y) + ⟨x, y⟩deﬁnes an inner product on D(E). This inner product space has a
completion HE which is a Hilbert space and in which the space D(E) is sequentially

21.3
Some Applications
303
dense. The quadratic form E has an extension E1 to this Hilbert space which is
deﬁned as E1(x, y) = limn→∞E(xn, yn) whenever x = limn→∞xn, y = limn→∞yn,
xn, yn ∈D(E) for all n ∈N. The resulting quadratic form E1 is a closed densely
deﬁned positive quadratic form. It is called the closure of the quadratic form E.
The ﬁrst representation theorem, applied to the quadratic form E1, gives a unique
positive self-adjoint operator AF such that
E1(x, y) = ⟨x, AFy⟩
∀x ∈D(E1), ∀y ∈D(AF) ⊆D(E1).
For x, y ∈D(A) one has ⟨x, Ay⟩= E(x, y) = E1(x, y) and hence AF is an extension
of A.
Finally, we prove that AF is the smallest self-adjoint positive extension of A.
Suppose B ≥0 is a self-adjoint extension of A. The associated quadratic form
EB(x, y) = ⟨x, By⟩on D(B) then is an extension of the form E. Hence, the closure
˜
EB of the quadratic form EB is an extension of the closure E1 of the quadratic
form E. The second representation theorem implies: The form domain of
˜
EB is
the domain D(
√
B) and the form domain of E1 is the domain D(√AF), hence
D(√AF) ⊆D(
√
B) and thus we conclude.
2
Note that in this proof we have used the following facts about positive self-adjoint
operators B which are of interest on their own. Recall ﬁrst that the domain D(B) is
contained in the domain of the square root
√
B of B and that D(B) is a core for the
operator
√
B. With B we can associate two densely deﬁned positive quadratic forms:
E1(x, y) = ⟨x, By⟩with domain D(E1) = D(B) and E2(x, y) = ⟨
√
Bx,
√
By⟩with
domain D(E2) = D(
√
B). E2 is a closed extension of E1 and actually the closure of
E1 (seeExercises). Thus, D(
√
B)iscalledtheformdomainofthepositiveself-adjoint
operator B.
Our last application of the representation theorems for quadratic forms is con-
cerned with the sum of two positive self-adjoint operators. There are examples of
such operators for which the intersection of their domains is trivial and thus the nat-
ural way to deﬁne their sum gives an uninteresting result. In some cases quadratic
forms and their representation can help to deﬁne the form sum of such operators.
Suppose A and B are two positive self-adjoint operators in the Hilbert space H
such that D = D(
√
A) ∩D(
√
B) is dense in H. Then a densely deﬁned positive
quadratic form E is naturally deﬁned on D by
E(x, y) = ⟨
√
Ax,
√
Ay⟩+ ⟨
√
Bx,
√
By⟩.
The closure E1 of this quadratic form is then a closed positive densely deﬁned
quadratic form to which the ﬁrst representation theorem can be applied. Hence, there
is a unique positive self-adjoint operator C with domain D(C) ⊂D(E1) such that
for all x ∈D(E1) and all y ∈D(C) the standard representation E1(x, y) = ⟨x, Cy⟩
holds. This self-adjoint operator C is called the form sum of A and B. One writes
C = A ˙+B.
(21.7)
Typically, the construction of the form sum is used in the theory of Schrödinger
operators in those cases where the potential V has a too strong local singularity

304
21
Quadratic Forms
which prevents V to be locally square integrable. A simple case for this construction
is considered below.
Let H0 =
1
2mP 2 be the free Hamilton operator in the Hilbert space H = L2(Rn).
On D0 = C0(Rn) the momentum operator P is given by i ∇. (Some details of the
construction of the free Hamilton operator as a self-adjoint operator in L2(Rn) are
considered in the exercise using Theorem 21.4.) Suppose that the potential V is a
nonnegative function in L1
loc(Rn) which does not belong to L2
loc(Rn). Then V · φ is
not necessarily square-integrable for φ ∈D0 so that we cannot deﬁne the interacting
Schrödinger operator H0 + V on D0 by (H0 + V )φ = H0φ + V φ. However, the
assumption 0 ≤V ∈L1
loc(Rn) ensures that the interacting Schrödinger operator can
be constructed as a self-adjoint operator as the form sum of the free Schrödinger
operator H0 and the interaction V .
On D0 a positive quadratic form E0 is well deﬁned by
E0(φ, ψ) = 1
2m
n

j=1
⟨∂jφ, ∂ψ⟩2 + ⟨
√
V φ,
√
V ψ⟩2.
Here, as usual, we use the notation ∂j =
∂
∂xj and ⟨·, ·⟩2 is the inner product of the
Hilbert space L2(Rn). This quadratic form is closable. Applying the ﬁrst representa-
tion theorem to the closure E of this quadratic form E0 deﬁnes the form sum H0 ˙+V
of H0 and V as a self-adjoint positive operator. Thus, we get for all φ, ψ ∈D0,
⟨φ, (H0 ˙+V )ψ⟩2 = 1
2m
n

j=1
⟨∂jφ, ∂ψ⟩2 + ⟨
√
V φ,
√
V ψ⟩2.
(21.8)
21.4
Exercises
1. Prove: A semi-bounded quadratic form is not necessarily symmetric.
2. Let A be a linear operator in the complex Hilbert space H and associate to it the
quadratic forms E1 and E2. Prove all the statements of the second example of the
ﬁrst section about the relation between the operator A and these quadratic forms.
3. Prove: There is no linear operator A in L2(R) with domain D(A) ⊇C∞
0 (R) such
that
⟨f , Ag⟩2 = f (0)g(0)
or
⟨Af , Ag⟩2 = f (0)g(0)
∀f , g ∈C∞
0 (R).
4. On the subspace D0 = C∞
0 (R) ⊂L2(R) the momentum operator P0 is deﬁned
by P0φ = −i d φ
d x . Show: P0 is symmetric. Determine the domain D(P ∗
0 ) of the
adjoint of P0 and the adjoint P ∗
0 itself. Finally show that P ∗
0 is self-adjoint.
Hint: Use the Fourier transform on L2(R) and recall the example of the free
Hamilton operator in the previous chapter.
5. Using the results of the previous problem andTheorem 21.4 determine the domain
on which the free Hamilton operator H0 =
1
2mP 2 is self-adjoint.

21.4
Exercises
305
6. Give the details of the proof of the fact that a densely deﬁned positive quadratic
form E0 is closable and characterize its closure E, i.e., characterize the elements
of the domain of the closure and the values of E at elements of its domain D(E),
in terms of certain limits.
7. Find the closure of the quadratic form of Example 4 in Sect. 21.1. Which self-
adjoint operator does this closed quadratic form represent?

Chapter 22
Bounded Linear Operators
Linear operators from a Hilbert space H into a Hilbert space K are those mappings
H→K, which are compatible with the vector space structure on both spaces. Sim-
ilarly, the bounded or continuous linear operators are those which are compatible
with both the vector space and the topological structures on both spaces. The fact that
a linear map H→K is continuous if, and only if, it is bounded follows easily from
Corollary 2.1. (A linear map between topological vector spaces is continuous if, and
only if, it is continuous at the origin which in turn is equivalent to the linear map
being bounded). This chapter studies the fundamental properties of single bounded
linear operators and of the set of all bounded linear operators B(H) on a Hilbert space
H. In particular, a product and various important topologies will be introduced in
B(H)). Also examples of bounded operators which are important in quantum physics
will be presented.
22.1
Preliminaries
Let H and K be two Hilbert spaces over the same ﬁeld K and A a linear operator
from H into K. A is called bounded if, and only if, the set
{∥Ax∥K} : x ∈D(A), ∥x∥H≤1}
(22.1)
is bounded. If A is bounded its norm is deﬁned as the least upper bound of this set:
∥A∥= sup {∥Ax∥K : x ∈D(A), ∥x∥H ≤1.}
(22.2)
We will show later that A #→∥A∥is indeed a norm on the vector space of all bounded
linear operators from H into K.
Linear operators which are not bounded are called unbounded.
There are several different ways to express that a linear operator is bounded.
Lemma 22.1
Let A be a linear operator from a Hilbert space H into a Hilbert
space K. The following statements are equivalent:
a) A is bounded.
© Springer International Publishing Switzerland 2015
307
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_22

308
22
Bounded Linear Operators
b) The set {∥Ax∥K} : x ∈D(A), ∥x∥H = 1 is bounded and the norm of A is ∥A∥=
sup {∥Ax∥K : x ∈D(A), ∥x∥H = 1}.
c) The set
 
∥Ax∥K
∥x∥H : x ∈D(A), x ̸= 0
!
is bounded and the norm of A is ∥A∥=
sup
 
∥Ax∥K
∥x∥H : x ∈D(A), x ̸= 0
!
.
d) There is a C ∈R+ such that ∥Ax∥K ≤C∥x∥H for all x ∈D(A) and the norm
is ∥A∥= inf

C ∈R+ : ∥Ax∥K

≤C∥x∥H ∀x ∈D(A).
Proof This is a straightforward exercise.
2
Corollary 22.1
If A is a bounded linear operator from a Hilbert space H into a
Hilbert space K, then
∥Ax∥K ≤∥A∥∥x∥H
∀x ∈D(A).
(22.3)
Thus A has always a unique continuous extension to the closure D(A) of its domain.
In particular, if A is densely deﬁned, this extension is unique on all of H; if D(A) is
not dense, then one can extend A on D(A)⊥for instance by 0. Hence in all cases, a
bounded linear operator A can be considered to have the domain D(A) = H.
Proof
For x ∈D(A), x ̸= 0, estimate (22.3) is evident from Part (c) of Lemma
22.1. For x = 0 we have Ax = 0 and thus (22.3) is satisﬁed.
Concerning the extension observe that the closure of a linear subspace is again a
linear subspace. If D(A) ∋x = limn→∞xn, (xn)n∈N ⊂D(A), then estimate (22.3)
implies immediately that (Axn)n∈N is a Cauchy sequence in K and thus has a unique
limit which is called Ax, i.e.,
A( lim
n→∞xn) = lim
n→∞Axn.
Finally, one shows that the limit lim Axn does not depend on the approximating
sequence (xn)n∈N, but only on its limit x.
2
However, there are linear operators in an inﬁnite dimensional Hilbert space, which
are deﬁned on all of the space but which are not bounded. Thus the converse of the
above corollary does not hold.
Proposition 22.1
In inﬁnite dimensional Hilbert spaces H there are linear
operators A with domain D(A) = H which are not bounded.
Proof
Since, we will not use this result we only give a sketch of the proof. The
axiom of choice (or Zorn’s Lemma) implies that there exists a maximal set H of
linearly independent vectors in H, i.e., a Hamel basis. This means that every x ∈H
has a unique representation as a linear combination of elements hj of the Hamel
basis H:
x =
n

j=1
ajhj
aj ∈K, j = 1, . . . , n ∈N.

22.2
Examples
309
Choose a sequence (hn)n∈N ⊂H and deﬁne Ahn = nhn for all n ∈N and extend A
by linearity to all of H:
Ax =
n

j=1
ajAhj.
If in the linear combination an element hj occurs, which does not belong to the
sequence chosen above deﬁne Ahj = hj or = 0. Then the domain of A is H and A
is not bounded.
2
In practice these everywhere deﬁned but unbounded linear operators are not im-
portant. Usually, one has some more information about the linear operator than
just the fact that it is deﬁned everywhere. And indeed, if such a linear operator is
symmetric, then it follows that it is bounded.
Theorem 22.1 (Hellinger–Toeplitz Theorem). Suppose A is a linear operator in the
Hilbert space H with domain D(A) = H. If A is symmetric, i.e., if ⟨x, Ay⟩= ⟨Ax, y⟩
for all x, y ∈H, then A is bounded.
Proof For the indirect proof assume that A is unbounded. Then there is a sequence
(yn)n∈N ⊂H, ∥yn∥= 1 for all n ∈N such that ∥Ayn∥→∞as n→∞. Now deﬁne
a sequence of linear functionals Tn : H→K by Tn(x) = ⟨yn, Ax⟩= ⟨Ayn, x⟩for all
x ∈H. The second representation of Tn implies by Schwarz’ inequality that every
functional Tn is continuous. For ﬁxed x ∈H we can use the ﬁrst representation of Tn
to show that the sequence (Tn(x))n∈N is bounded: |⟨yn, Ax⟩| ≤∥yn∥∥Ax∥≤∥Ax∥
for all n ∈N. Thus the uniform boundedness principle (Theorem 19.6) implies that
there is a C ∈R+ such that ∥Tn∥≤C for all n ∈N. But this gives a contradiction
to the construction of the yn: ∥Ayn∥2 = Tn(Ayn) ≤∥Tn∥∥Ayn∥≤C∥Ayn| implies
∥Ayn∥≤C.
2
22.2
Examples
In order to gain some insight into the various ways in which a linear operator in
a Hilbert space is bounded, respectively unbounded, we study several examples in
concrete Hilbert spaces of square integrable functions.
1. Linear operators of differentiation such as the momentum operator are un-
bounded in Hilbert spaces of square integrable functions. Consider for example
the momentum operator P =
i
d
d x in the Hilbert space H = L2([0, 1]). The
functions en(x) = e inx obviously have the norm 1, ∥en∥2
2 =
 1
0 | e inx|2d x = 1
and for P en we ﬁnd ∥Pen∥2
2 =
 1
0 |−ie′
n(x)|2 dx = n2, hence ∥Pen∥2
∥en∥2 = n and the
linear operator P is not bounded (on any domain which contains these exponential
functions).
2. Boundedmultiplicationoperators. Supposeg isanessentiallyboundedmeasur-
able function on Rn. Then the operator of multiplication Mg with g is a bounded
operator in the Hilbert space L2(Rn) since in this case, for almost all x ∈Rn,

310
22
Bounded Linear Operators
|g(x)| ≤∥g∥∞, and thus
∥Mgf ∥2
2 =

Rn |g(x)f (x)|2 dx ≤

Rn ∥g∥2
∞|f (x)|2 dx = ∥g∥2
∞∥f ∥2
2
for all f ∈L2(Rn).
3. Unboundedoperatorsofmultiplication. Considertheoperatorofmultiplication
with a function, which has a sufﬁciently strong local singularity, for instance the
function g(x) = x−α for2α > 1intheHilbertspaceL2([0, 1]). Intheexerciseswe
show that this operator is unbounded. Another way that a multiplication operator
Mg in L2(R) is not bounded is that the function g is not bounded at “inﬁnity”. A
very simple example is g(x) = x for all x ∈R on the domain
Dn =
+
f ∈C(R) : p0,n(f ) = sup
x∈R
(1 + x2)n/2|f (x)| < ∞
,
.
Consider the sequence of functions
fj(x) =
⎧
⎪⎪⎨
⎪⎪⎩
1
for x ∈[ −j, j],
0
for x ̸∈[ −j −1, j + 1],
linear and continuous otherwise.
Certainly, for every j ∈N, fj ∈Dn (n ∈N ﬁxed). A straightforward calculation
shows
∥fj∥2
2 ≤2(j + 1)
and
∥Mg∥2
2 ≥2
3j 3,
hence ∥Mgfj∥2 ≥
j
√
6∥fj∥2. We conclude that this multiplication operator is not
bounded.
4. Integral operators of Hilbert–Schmidt. Let k ∈L2(Rn × Rn) be given. Then
∥k∥2
2 =

Rn

Rn |k(x, y)|2 dx dy is ﬁnite and thus, for almost all x ∈Rn the
integral

Rn |k(x, y)|2 d y is ﬁnite and thus allows us to deﬁne a linear map K :
L2(Rn)→L2(Rn) by
(Kψ)(x) =

Rn k(x, y)ψ(y) dy
for almost all x ∈Rn.
Again for almost all x ∈Rn this image is bounded by
|(Kψ)(x)|2 ≤

Rn |k(x, y)|2 dy

Rn |ψ(y)|2 dy =

Rn |k(x, y)|2 d y∥ψ∥2
2
where Schwarz’ inequality is used. We deduce ∥Kψ∥2 ≤∥k∥2∥ψ∥2 for all ψ ∈
L2(Rn) and the integral operator K with kernel k is bounded. Such integral
operators are called Hilbert–Schmidt operators. They played a very important
role in the initial stage of the theory of Hilbert spaces. We indicate brieﬂy some
basic aspects. A comprehensive study of these operators is presented in Chap. 26.

22.2
Examples
311
If

ej : j ∈N

is an orthonormal basis of the Hilbert space L2(Rn), every ψ ∈
L2(Rn) has a Fourier expansion with respect to this basis: ψ = ∞
j=1⟨ej, ψ⟩2ej,
∞
j=1 |⟨ej, ψ⟩2|2 = ∥ψ∥2
2. Similarly, Kψ = ∞
i=1⟨ei, Kψ⟩2ei and ∥Kψ∥2
2 =
∞
i=1 |⟨ei, Kψ⟩2|2. Continuity of the operator K and of the inner product imply
⟨ei, Kψ⟩2 = ⟨ei, K(
∞

j=1
⟨ej, ψ⟩2ej)⟩2 =
∞

j=1
⟨ei, Kej⟩2⟨ej, ψ⟩2.
Hence, the action of the integral operator K on ψ ∈L2(Rn) can be represented as
the action of the inﬁnite matrix (Kij)i,j∈N on the sequence ψ = (ψj)j∈N ∈ℓ2(K)
of expansion coefﬁcients of ψ, where Kij = ⟨ei, Kej⟩2 and ψj = ⟨ej, ψ⟩2.
Because of Parseval’s relation, since eij = ei ⊗ej, i, j ∈N, is an orthonormal
basis of the Hilbert space L2(Rn×Rn), the matrix elements are square summable,
∞
i,j=1 |Kij|2 = ∥K∥2
2.
Now this matrix representation for the integral operator K allows us to rewrite
the integral equation as inﬁnite linear system over the space ℓ2(K) of square
summable numerical sequences.
Given f ∈L2(Rn), consider for instance the integral equation
u + Ku = f
for an unknown function u ∈L2(Rn). As a linear system over ℓ2(K) this integral
equation reads
ui +

j=1
Kijuj = fi,
i = 1, 2, . . .
where naturally ui = ⟨ei, u⟩2 and fi = ⟨ei, f ⟩2 for all i ∈N are square summable
sequences.
5. Spin operators. In quantum physics the spin as an internal degree of freedom
plays a very important role. In mathematical terms it is described by a bounded
operator, more precisely by a triple S = (S1, S2, S3) of bounded operators. These
operators will be discussed brieﬂy.
We had mentioned before that the state space of an elementary localizable particle
with spin s = j
2, j = 0, 1, 2, . . . , is the Hilbert space
Hs = L2(R3) ⊗C2s+1 = L2(R3, C2s+1).
The elements of Hs are 2s + 1-tuples of complex valued functions fm, m =
−s, −s + 1, . . . , s −1, s, in L2(R3). The inner product of Hs is
⟨f , g⟩=
s

m=−s

R3 fm(x)gm(x) dx
∀f , g ∈Hs.
The spin operators Sj act on this space according to the following rules.
S1 = 1
2(S+ + S−), S2 = −i
2 (S+ + S−),

312
22
Bounded Linear Operators
(S3f )m(x) = mfm(x), m = −s, −s + 1, . . . , s −1, s,
(S+f )m(x) =

(s + m)(s −m + 1)fm−1(x),
(S−f )m(x) =

(s −m)(s + m + 1)f+(x).
Clearly these operators are linear and bounded in Hs. In the Exercises we show
that they are self-adjoint: S∗
j = Sj for j = 1, 2, 3. Introducing the commutator
notation[A, B] = AB−BAfortwoboundedlinearoperatorsoneﬁndsinteresting
commutation relations for these spin operators:
[S1, S2] = iS3, [S2, S3] = iS1, [S3, S1] = iS2.
Furthermore, the operator S2 = S2
1 + S2
2 + S2
3 = S+S−−S2
3 + S3 turns out to be
proportional to the identity operator IHs on Hs:
(S2f )m(x) = s(s + 1)fm(x),
i.e., S2 = s(s + 1)IHs.
Without going into further details we mention that the operators given above are
a realization or “representation” of the commutation relations for the Sj.
6. Wiener–Hopf operators. For a given function g ∈L1(R) deﬁne a map Kg :
L2(R+)→L2(R+) by
(Kgf )(x) =
 ∞
0
g(x −y)f (y) d y
for almost all x ∈R+, ∀f ∈L2(R+).
It is not quite trivial to show that this operator is indeed a bounded linear operator.
It is done in the Exercises. These Wiener–Hopf operators have a wide range
of applications. They are used for instance in the analysis of boundary value
problems, in ﬁltering problems in information technology and metereology, and
time series analysis in statistics.
We conclude this section with a discussion of the famous Heisenberg commu-
tation relations
[Q, P] ⊆i I
for the position operator Q and momentum operator P in quantum mechanics.
The standard realization of these commutation relations in the Hilbert space L2(R)
we had mentioned before: Q is realized as the multiplication operator with the
coordinate variable x while the momentum operator then is P = −i
d
d x , both on
suitable domains which have been studied in detail earlier. Recall that both oper-
ators are unbounded. It is an elementary calculation to verify these commutation
relations for this case, for instance on the dense subspace C∞
0 (R).
Now, we ask the question whether there are other realizations of these commu-
tation relations in terms of bounded operators. A clear answer is given in the
following lemma.
Lemma 22.2 (Lemma ofWielandt)There are no bounded linear operators Q and P
in a Hilbert space H which satisfy the commutation relations [Q, P] = QP −PQ =
i I where I is the identity operator in H.

22.3
The Space B(H, K) of Bounded Linear Operators
313
Proof We are going to derive a contradiction from the assumption that two bounded
linear operators satisfy these commutation relations.
Observe ﬁrst that P n+1Q −QP n+1 = P n[PQ −QP] + [P nQ −QP n]P =
−iP + [P n, Q]P. A proof of induction with respect to n gives [P n+1, Q] =
−i (n + 1)P n and thus
(n + 1)∥P n∥= ∥[P n+1, Q]∥≤∥P n+1Q∥+ ∥QP n+1∥.
In the following section one learns that ∥AB∥≤∥A∥∥B∥holds for bounded linear
operators A, B. Thus we continue the above estimate
(n + 1)∥P n∥≤∥P n∥∥PQ∥+ ∥QP∥∥P n∥≤2∥P n∥∥Q∥∥P∥.
According to the commutation relation we know ∥P∥> 0. The relation [P 2, Q] =
−iP implies ∥P 2∥> 0 and per induction, ∥P n∥> 0 for all n ∈N, hence
we can divide our estimate by ∥P n∥to get n + 1 ≤2∥Q∥∥P∥for all n ∈N, a
contradiction.
2
22.3
The Space B(H, K) of Bounded Linear Operators
Given two Hilbert spaces H and K over the ﬁeld K, the set of all bounded linear
operators A : H→K is denoted by B(H, K). This section studies the basic properties
of this set.
First of all, on this set B(H, K) the structure of a K-vector space can naturally
be introduced by deﬁning an addition and a scalar multiplication according to the
following rules. For A, B ∈B(H, K) deﬁne a map A + B : H→K by
(A + B)x = Ax + Bx
∀x ∈H,
i.e., weaddtwoboundedoperatorsbyadding, ateachpointx ∈H, theimagesAx and
Bx. It is straightforward to show that A + B, deﬁned in this way, is again a bounded
linear operator. The veriﬁcation is left as an exercise. Similarly, one multiplies a
bounded linear operator A ∈B(H, K) with a number λ ∈K by multiplying, at every
point x ∈H, the value Ax with λ,
(λ · A)x = λ · (Ax)
∀x ∈H.
In future we will follow the tradition and write this scalar multiplication λ·A simply
as λA. Since the target space K is a vector space it is clear that with this addition
and scalar multiplication the set B(H, K) becomes a vector space over the ﬁeld K.
The details are ﬁlled in as an exercise.
Proposition 22.2 For two Hilbert spaces H and K over the ﬁeld K the set B(H, K)
of all bounded linear operators A : H→K is a vector space over the ﬁeld K. The
function A #→∥A∥deﬁned by
∥A∥= sup {∥Ax∥K : x ∈H, ∥x∥H = 1}

314
22
Bounded Linear Operators
is a norm on B(H, K).
Proof The ﬁrst part of the proof has been given above. In order to prove that the
function A #→∥A∥actually is a norm on the vector space B(H, K), recall that
for any A, B ∈B(H, K) and any x ∈H one knows ∥Ax∥K ≤∥A∥∥x∥H and
∥Bx∥K ≤∥B∥∥x∥H, and it follows that
∥(A + B)x∥K = ∥Ax + Bx∥K ≤∥Ax∥K + ∥Bx∥K ≤∥A∥∥x∥H + ∥B∥∥x∥H.
Hence,
∥A + B∥= sup {|(A + B)x∥K: x ∈H, ∥x∥H = 1} ≤∥A∥+ ∥B∥
is immediate. The rule ∥λA∥= |λ| ∥A∥for all λ ∈K and all A ∈B(H, K) is obvious
from the deﬁnition. Finally, if ∥A∥= 0 for A ∈B(H, K) then ∥Ax∥K = 0 for all
x ∈H, and hence Ax = 0 for all x ∈H, i.e., A = 0. We conclude that ∥· ∥is a
norm on B(H, K).
2
Proposition 22.3
Let H and K be two Hilbert spaces over the ﬁeld K. Every
operator A ∈B(H, K) has an adjoint A∗which is a bounded linear operator K→H.
The map A #→A∗has the following properties:
a) A∗∗= A for all A ∈B(H, K)
b) (A + B)∗= A∗+ B∗for all A, B ∈B(H, K)
c) (λA)∗= λA∗for all A ∈B(H, K) and all λ ∈K
d) ∥A∗∥= ∥A∥
Proof Take any A ∈B(H, K). For all x ∈H and all y ∈K the estimate
|⟨y, Ax⟩K| ≤∥A∥∥x∥H ∥y∥K
holds. Fix y ∈K. Then this estimate says that x #→⟨y, Ax⟩K is a continuous linear
functional on H, hence by the Theorem of Riesz–Fréchet, there is a unique y∗∈H
such that this functional is of the form x #→⟨y∗, x⟩H, i.e.,
⟨y, Ax⟩K = ⟨y∗, x⟩H
∀x ∈H.
In this way we get a map y #→y∗from K into H, which is called the adjoint A∗of
A, i.e., A∗y = y∗. This gives, for all x ∈H and all y ∈K the identity
⟨y, Ax⟩K = ⟨A∗y, x⟩H.
Linearity of A∗is evident from this identity. For the norm of A∗one ﬁnds
∥A∗∥= sup

∥A∗y∥H : y ∈K, ∥y∥K = 1

= sup

|⟨A∗y, x⟩H| : x ∈H, ∥x∥H = 1, y ∈K, ∥y∥K = 1

= sup {|⟨y, Ax⟩K| : x ∈H, ∥x∥H = 1, y ∈K, ∥y∥K = 1}
= ∥A∥.

22.4
The C∗-Algebra B(H)
315
Hence A∗is bounded and Part (d) follows.
Thebi-adjoint A∗∗= (A∗)∗isdeﬁnedinthesamewayasaboundedlinearoperator
H→K through the identity
⟨y, A∗∗x⟩K = ⟨A∗y, x⟩H
for all y ∈K and all x ∈H. But by deﬁnition of the adjoint A∗both terms are equal
to ⟨y, Ax⟩K. We deduce A∗∗= A. Parts (b) and (c) are easy calculations and are left
as an exercise.
2
In Proposition 22.2 we learned that the space of all bounded linear operators from
a Hilbert space H into a Hilbert space K is a normed space. This is actually true
under considerably weaker assumptions when the Hilbert spaces are replaced by
normed spaces X and Y over the same ﬁeld. In this case a linear map A : X→Y
is bounded if, and only if, there is a C ∈R+ such that ∥Ax∥Y ≤C∥x∥X for all
x ∈X. Then the norm of A is deﬁned as in the case of Hilbert spaces: ∥A∥=
sup {∥Ax∥Y : x ∈X, ∥x∥X = 1}. Thus we arrive at the normed space L(X, Y) of
bounded linear operators X→Y. If the target space Y is complete, then this space
is complete too, a very widely used result. Certainly, this applies also to the case
B(H, K) of Hilbert spaces.
Theorem 22.2 Let X and Y be normed spaces over the ﬁeld K. If Y is complete,
then the normed space L(X, Y) is also complete.
Proof The proof that L(X, Y) is a normed space is the same as for the case of Hilbert
spaces. Therefore we prove here completeness of this space.
If (An)n∈N ⊂L(X, Y) is a Cauchy sequence, then for every ε > 0 there is an
n0 ∈N such that ∥An −Am∥≤ε for all n, m ≥n0. Now take any x ∈X and
consider the sequence (Anx)n∈N ⊂Y. Since ∥Anx −Amx∥Y = ∥(An −Am)x∥Y ≤
∥An −Am∥∥x∥X, this sequence is a Cauchy sequence in Y and thus converges to
a unique element y = y(x) ∈Y, y(x) = limn→∞Anx. The rules of calculation for
limits imply that x #→y(x) is a linear function A : X→Y, Ax = limn →∞Anx. A
is bounded too: Since ∥Anx −Amx∥Y ≤ε∥x∥X for all n, m ≥n0 it follows that, by
taking the limit n→∞, ∥Ax −Amx∥Y ≤ε∥x∥X and thus for ﬁxed m ≥n0
∥Ax∥Y ≤∥Ax −Amx∥Y ∥x∥X + ∥Amx∥Y ≤(ε + ∥Am∥)∥x∥X,
i.e., A is bounded and the proof is complete.
2
Corollary 22.2
Let X be a normed space over the ﬁeld K. Then the topological
dual X′ = L(X, K) is complete.
Proof The ﬁeld K = R, C is complete so that the previous theorem applies.
2
22.4
The C∗-Algebra B(H)
The case of the Banach space B(H, K) of bounded linear operators from a Hilbert
space H into a Hilbert space K in which K = H deserves special attention since
there some additional important structure is available, namely one can naturally

316
22
Bounded Linear Operators
deﬁne a product through the composition. Following the tradition, the Banach space
B(H, H) is denoted by B(H). For A, B the composition A ◦B : H→H is again a
bounded linear operator from H into itself since for all x ∈H we have ∥A◦Bx∥H =
∥A(Bx)∥H ≤∥A∥∥Bx∥H ≤∥A∥∥B∥∥x∥H. This composition is used to deﬁne a
product on B(H):
A · B = A ◦B
∀A, B ∈B(H).
The standard rules of composition of functions and the fact that the functions involved
are linear imply that this product satisﬁes the following relations, for all A, B, C ∈
B(H):
(A · B) · C = A · (B · C), (A + B) · C = A · C + B · C, A · (B + C) = A · B + A · C,
i.e., this product is associative and distributive but not commutative. One also has
A·(λB) = λ(A·B). Equipped with this product the Banach space B(H) is a normed
algebra.
According to Proposition 22.3 every A ∈B(H) has an adjoint A∗∈B(H).
Products in B(H) are transformed according to the following rule, which is shown
in the Exercises:
(A · B)∗= B∗· A∗
∀A, B ∈B(H).
As a matter of convenience we omit the ‘·’ for this product and write accordingly
AB ≡A · B.
Theorem 22.3
Let H be a Hilbert space. Then the space B(H) of all bounded
linear operators A : H→H is a C∗-algebra, i.e., a complete normed algebra with
involution ∗. For all A, B ∈B(H) one has
a) ∥AB∥≤∥A∥∥B∥
b) ∥A∗∥= ∥A∥
c) ∥AA∗∥= ∥A∗A∥= ∥A∥2
d) ∥IH∥= 1
If the dimension of H is larger than 1, then the algebra B(H) is non-Abelian.
Proof Parts (a) and (b) have been shown above. Part (d) is trivial.
By (a) and (b) we know ∥AA∗∥≤∥A∥∥A∗∥= ∥A∥2. The estimate
∥Ax∥2 = ⟨Ax, Ax⟩= ⟨x, A∗Ax⟩≤∥x∥∥A∗Ax∥≤∥A∗A∥∥x∥2
implies ∥A∥2 ≤∥A∗A∥and thus ∥A∥2 = ∥A∗A∥. Because of (b) we can ex-
change A∗and A and Part (c) holds. Multiplication of 2 × 2-matrices is already not
commutative.
2
Theorem 22.3 states that B(H) is a complete normed algebra with involution. In
this statement it is the norm or uniform topology to which we refer. However, there
are important problems when weaker topologies on B(H) are needed. Accordingly,
we discuss brieﬂy weaker topologies on this space.

22.4
The C∗-Algebra B(H)
317
In order to put these topologies into perspective we recall the deﬁnition of neigh-
borhoods for the norm topology. Neighborhoods of a point A ∈B(H) for the norm
topology are all sets which contain a set of the form
Ur(A) = {B ∈B(H) : ∥B −A∥< r}
for some r > 0. A basis of neighborhoods at the point A ∈B(H) for the strong
topology on B(H) are the sets
Ur,y1,... ,yn(A) =

B ∈B(H) : ∥(B −A)yj∥H<r, j=1, . . . , n

with r > 0 and any ﬁnite collection of points y1, . . . , yn ∈H. Finally a basis of
neighborhoods at A ∈B(H) for the weak topology on B(H) are the sets
Ur,y1,... ,yn,x1,... ,xn(A) =

B ∈B(H) : |⟨xj, (B −A)yj⟩| < r, j = 1, . . . , n

for any ﬁnite collection of points xj, yj ∈H, j = 1, . . . , n.
In practice we will not be using the deﬁnitions of these topologies in terms of a
neighborhood basis but the notions of convergence which these deﬁnitions imply.
Therefore, we state these explicitly.
Deﬁnition 22.1 A sequence (An)n∈N ⊂B(H) converges to A ∈B(H) with respect
to the
a) Norm topology if, and only if, limn→∞∥A −An∥= 0
b) Strong topology if, and only if, limn→∞∥Ax −Anx∥H = 0 for every x ∈H
c) Weak topology if ,and only if, limn→∞|⟨y, Ax⟩−⟨y, Anx⟩| = 0 for every pair
of points x, y ∈H
The estimate ∥Ax −Anx∥H ≤∥A −An∥∥x∥H shows that norm convergence al-
ways implies strong convergence and similarly, according to the estimate |⟨y, Ax⟩−
⟨y, Anx⟩| ≤∥y∥H∥Ax −Anx∥H, strong convergence always implies weak conver-
gence. The converses of these statements do not hold. The norm topology is really
stronger than the strong topology, which in turn is stronger than the weak topology.
The terminology is thus consistent.
Some examples will help to explain the differences between these topologies. On
the Hilbert space H = ℓ2(C) consider the operator Sn which replaces the ﬁrst n
elements of the sequence x = (x1, . . . , xn, xn+1, . . . ) by 0,
Snx = (0, . . . , 0, xn+1, xn+2, . . . ).
The norm of Sn is easily calculated: ∥Sn∥= 1 for all n ∈N. Thus (Sn)n∈N does not
converge to 0 in norm. But this sequence converges to 0 in the strong topology since
for any x ∈ℓ2(C) we ﬁnd ∥Snx∥2
2 = ∞
j=n+1 |xj|2→0 as n→∞.
Next deﬁne a bounded operator Wn : ℓ2(C)→ℓ2(C) by
Wnx = (0, . . . , 0, x1, x2, . . . ),
i.e., Wn shifts x = (x1, x2, . . . ) by n places to ∞. Clearly ∥Wnx∥2 = ∥x∥2 for
all x ∈ℓ2(C). Now take any y ∈ℓ2(C) and calculate ⟨y, Wnx⟩2 = ∞
j=n+1 yjxj−n,

318
22
Bounded Linear Operators
hence |⟨y, Wnx⟩|2 ≤∞
j=n+1 |yj|2∥x∥2
2→0 as n→∞. This implies that the sequence
(Wn)n∈N converges to 0 in the weak but not in the strong topology.
Finally we address the question whether these three topologies we have introduced
on the C∗-algebra B(H) are compatible with the algebra operations. The answer is
given in Proposition 22.4.
Proposition 22.4
Let B(H) be the C∗-algebra of bounded linear operators on a
Hilbert space H. Then the following holds:
a) Addition and scalar multiplication are continuous with respect to the norm, the
strong and the weak topology on B(H)
b) The product (A, B) #→AB is continuous with respect to the norm topology.
c) The involution A #→A∗is continuous with respect to the weak topology.
Continuity with respect to a topology not mentioned in statements a) – c) is in general
not given.
Proof AllthreetopologieswehaveintroducedonB(H)arelocallyconvextopologies
on a vector space. Thus Part (a) is trivial. The estimate ∥AB∥≤∥A∥∥B∥for all
A, B ∈B(H) implies continuity of the product with respect to the norm topology.
Suppose a sequence (An)n∈N ⊂B(H) converges weakly to A ∈B(H). Then the
sequence of adjoints (A∗
n)n∈N converges to A∗since for every pair x, y ∈H we have,
as n→∞,
⟨A∗
nx, y⟩= ⟨x, Any⟩→⟨x, Ay⟩= ⟨A∗x, y⟩.
Explicit examples in inﬁnite dimensional Hilbert spaces show that the involution
A #→A∗is not continuous with respect to the strong and the norm topology and that
the multiplication is not continuous with respect to the strong and the weak topology.
These counterexamples are done as exercises.
2
The fundamental role which C∗-algebras play in local quantum physics is
explained in full detail in [1].
22.5
Calculus in the C∗-Algebra B(H)
22.5.1
Preliminaries
On the C∗-algebra B(H) one can do calculus since we can add and multiply elements
and one can take limits. With these operations one can calculate certain functions
f (A) of elements A ∈B(H). Suppose that f is analytic in the disk |z| < R for
some R > 0. Then f has a power series expansion ∞
n=0 anzn, which converges for
|z| < R, i.e., f (z) = limN→∞fN(z) where fN(z) = N
n=0 anzn is a partial sum. For
any A ∈B(H) the polynomial
fN(A) =
N

n=0
anAn

22.5
Calculus in the C∗-Algebra B(H)
319
is certainly a well-deﬁned element in B(H). And so is the limit in the norm topology
of B(H) if it exists. We claim: For A ∈B(H), ∥A∥< R, this sequence of partial
sums has a limit in B(H). It sufﬁces to show that this sequence is a Cauchy sequence.
Since the power series converges, given ε > 0 and ∥A∥≤r < R there is n0 ∈N
such that m
j=n |aj| |z|j < ε for all m > n ≥n0 and all |z| ≤r. Therefore,
∥fm(A) −fn(A)∥= ∥m
j=n ajAj∥≤m
j=n |aj| ∥A∥j < ε for all m > n ≥n0, and
this sequence is indeed a Cauchy sequence and thus converges to a unique element
f (A) ∈B(H), usually written as
f (A) =
∞

n=0
anAn.
Let us consider two well-known examples. The geometric series ∞
n=0 zn is known
to converge for |z| < 1 to the function (1 −z)−1. Hence, for every A ∈B(H),
∥A∥< 1, we get (I = IH, the identity operator on H)
(I −A)−1 =
∞

n=0
An.
(22.4)
The operator series ∞
n=0 An is often called the Neumann series. It was ﬁrst
introduced in the study of integral equations to calculate the inverse of I −A.
Another important series is the exponential series ∞
n=0
1
n!zn, which is known to
have a radius of convergence R = ∞. Hence for every A ∈B(H)
e A =
∞

n=0
1
n!An
(22.5)
is a well-deﬁned element in B(H). If A, B ∈B(H) commute, i.e., AB = BA, then
one can show, as for complex numbers, e A+B = e A e B. As a special case consider
U(t) = e tA for t ∈C for some ﬁxed A ∈B(H). One ﬁnds
U(t + s) = U(t)U(s)
∀t, s ∈C,
U(0) = I.
This family of operators U(t) ∈B(H), t ∈C has interesting applications for the
solution of differential equations in H. Take some x0 ∈H and consider the function
x : C→H,
x(t) = U(t)x0 = e tAx0
t ∈C.
We have x(0) = x0 and for t, s ∈C
x(t) −x(s) = e sA[ e (t−s)Ax0 −x0].
In the Exercises one proves, as an identity in H,
lim
t→s
x(t) −x(s)
t −s
= Ax(s),

320
22
Bounded Linear Operators
i.e., the function x(t) is differentiable (actually it is analytic) and satisﬁes the
differential equation
x′(t) = Ax(t),
t ∈C,
x(0) = x0.
Therefore, x(t) = e tAx0 is a solution of the initial value problem x′(t) = Ax(t),
x(0) = x0.
Such differential equations are used often for the description of the time evolution
of physical systems. Compared to the time evolution of systems in classical mechan-
ics the exponential bound ∥x(t)∥≤e |t|∥A∥∥x0∥H for all t ∈R corresponds to the
case of bounded vector ﬁelds governing the time evolution.
22.5.2
Polar Decomposition of Operators
Recallthepolarrepresentationofacomplexnumberz = e i arg z|z|wherethemodulus
of z is the positive square root of the product of the complex number and its complex
conjugate: |z| =
√
zz. In this section we will present an analog for bounded linear
operators on a Hilbert space, called the polar decomposition. In a ﬁrst step the
square root of a positive operator is deﬁned using the power series representation of
the square root, a result which is of great interest on its own. Thus one can deﬁne
the modulus |A| of a bounded linear operator A as the positive square root of A∗A.
The phase factor in the polar decomposition of complex numbers will be replaced
in the case of operators by a partial isometry, i.e., an operator which is isometric on
the orthogonal complement of its null space.
It is a well-known fact (see also the Exercises) that the Taylor expansion at z = 0
of the function z #→√1 −z converges absolutely for |z| ≤1:
√
1 −z = 1 −
∞

j=1
ajzj
∀|z| ≤1.
(22.6)
The coefﬁcients aj of this expansion are all positive and known explicitly.
Similarly to the previous two examples this power series will be used to deﬁne
the square root of a positive linear operator.
Theorem 22.4 (Square Root Lemma) Let A ∈B(H) be positive, i.e., 0 ≤⟨x, Ax⟩
for all x ∈H. Then there is a unique positive operator B ∈B(H) such that B2 = A.
This operator B commutes with every bounded linear operator which commutes with
A. One calls B the positive square root of A and writes B =
√
A.
If ∥A∥≤1, then
√
A has the norm convergent power series expansion
√
A =

I −(I −A) = I −
∞

j=1
aj(I −A)j
(22.7)
where the coefﬁcients are those of Eq. (22.6). The general case is easily reduced to
this one.

22.6
Exercises
321
Proof For a positive operator A of norm ≤1 one has ∥I −A∥= sup∥x∥=1 |⟨x, (I −
A)x⟩| ≤1. Hence we know that the series in Eq. (22.7) converges in norm to some
bounded linear operator B. Since the square of the series (22.6) is known to be 1−z,
the square of the series (22.7) is I −(I −A) = A, thus B2 = A.
In order to show positivity of B observe that 0 ≤I −A ≤I implies 0 ≤
⟨x, (I −A)nx⟩≤1 for all x ∈H, ∥x∥= 1. The series (22.7) for B implies that
⟨x, Bx⟩= ⟨x, x⟩−
∞

j=1
aj⟨x, (I −A)jx⟩≥1 −
∞

j=1
aj ≥0
where in the last step the estimate ∞
j=1 aj ≤1 is used (see Exercises). Therefore
B ≥0.
The partial sums of the series (22.7 ) commute obviously with every bounded
operator which commutes with A. Thus the norm limit B does the same.
Suppose 0 ≤C ∈B(H) satisﬁes C2 = A. Then CA = CC2 = AC, thus C
commuteswithAandhencewithB. Calculate(B−C)B(B−C)+(B−C)C(B−C) =
(B2 −C2)(B −C) = 0 and note that the two summands are positive operators, hence
both of them vanish and so does their difference (B −C)B(B −C)−(B −C)C(B −
C) = (B −C)3 = 0. It follows that ∥B −C∥4 = ∥(B −C)4∥= 0, since B −C is
self-adjoint. We conclude B −C = 0.
2
Deﬁnition 22.2 The function | · | : B(H)→B(H) deﬁned by |A| =
√
A∗A for all
A ∈B(H) is called the modulus. Its values are positive bounded operators.
Theorem 22.5 (Polar Decomposition) For every bounded linear operator A on the
Hilbert space H the polar decomposition
A = U|A|
(22.8)
holds. Here |A| is the modulus of A and U is a partial isometry with null space
N(U) = N(A). U is uniquely determined by this condition and its range is ran A.
Proof The deﬁnition of the modulus implies for all x ∈H
∥|A|x∥2 = ⟨x, |A|2x⟩= ⟨x, A∗Ax⟩= ∥Ax∥2,
hence N(A) = N(|A|) = (ran |A|)⊥, and we have the orthogonal decomposition
H = N(|A|) ⊕ran |A| of the Hilbert space. Now deﬁne a map U : H→H with
N(U) = N(|A|) by continuous extension of U(|A|x) = Ax for all x ∈H. Because
of the identity given above, U is a well-deﬁned linear operator which is isometric on
ran |A|. Its range is ran A. On the basis of Eq. (22.8) and the condition N(U) = N(A)
the proof of uniqueness is straightforward.
2
22.6
Exercises
1. Prove Lemma 22.1.
2. Prove that the operator of multiplication with the function g(x) = x−α, 2α > 1,
is unbounded in the Hilbert space L2([0, 1]).

322
22
Bounded Linear Operators
Hints: Consider the functions
fn(x) =
⎧
⎨
⎩
1
1
n ≤x ≤1,
0
0 ≤x < 1
n.
For these functions one can calculate the relevant norms easily.
3. Prove all the statements about the spin operators in the section on examples of
bounded linear operators.
4. Prove that the Wiener–Hopf operators are well-deﬁned bounded linear operators
in L2(R+).
Hints: Consider the space L2(R+) as a subspace of L2(R) and use the re-
sults on the relations between multiplication and convolution under Fourier
transformation given in Part A, Chap. 10.
5. Prove parts (b) and (c) of Proposition 22.3.
6. For A, B ∈B(H) prove: (A + B)∗= A∗+ B∗and (A · B)∗= B∗· A∗.
7. For A ∈B(H) and x0 ∈H, deﬁne x(t) = etAx0 for t ∈C and show that this
function C→H is differentiable on C. Calculate its (complex) derivative.
8. In the Hilbert space H = ℓ2(C), denote by ej j ∈N the standard basis vectors
(the sequence ej has a 1 at position j, otherwise all elements are 0). Then every
x ∈ℓ2(C) has the Fourier expansion x = ∞
j=1 xjej with (xj)j∈N a square
summable sequence of numbers. Deﬁne a bounded linear operator A ∈B(H) by
A
∞

j=1
xjej =
∞

j=2
xjej−1
and show:
a) A∗∞
j=1 xjej = ∞
j=1 xjej+1
b) The sequence An = An converges to 0 in the strong topology
c) A∗
n = (A∗)n does not converge strongly to 0
d) AnA∗
n = I for all n ∈N
e) deduce that the product is continuous neither with respect to the strong nor
with respect to the weak topology.
9. Though in general the involution is not strongly continuous on B(H) it is strongly
continuous on a linear subspace N of normal operators in B(H), i.e., bounded
operators with the property
A∗A = AA∗.
Prove: If (An)n∈N ⊂N converges strongly to A ∈N then the sequence of
adjoints (A∗
n)n∈N converges strongly to A∗.
Hints: Show ﬁrst that ∥(A∗−A∗
n)x∥2
H = ∥(A −An)x∥2
H for x ∈H.
10. Show: The algebra Q = M2(C) of complex 2 × 2 matrices is not a C∗-algebra
when it is equipped with the norm
∥A∥=

Tr (AA∗) =
7
8
8
9
2

k,j=1
|Akj|2.

Reference
323
Hints: Take the matrix A =
⎛
⎝1
i
0
1
⎞
⎠and calculate ∥A∗∥2 and ∥AA∗∥2.
11. Show that the Taylor series of the function f (z) = √1 −z at z = 0 is of the form
√
1 −z = 1 −
∞

j=1
ajzj
|z| < 1
where the coefﬁcients aj are given by
aj =
1
2j!
j−1
.
i=1
(i −1
2).
Prove: ∞
j=1 aj ≤1. Deduce that the above power series for √1 −z converges
for |z| ≤1.
Hints: For any N ∈N write N
j=1 aj = limx→1
N
j=1 ajxj with 0 < x < 1.
Since the coefﬁcients are positive, one has N
j=1 ajxj < ∞
j=1 ajxj = 1 −
√1 −x.
Reference
1. Haag R. Local quantum physics : ﬁelds, particles, algebras. 2nd ed. Texts and monographs in
physics. Berlin: Springer-Verlag; 1998.

Chapter 23
Special Classes of Linear Operators
23.1
Projection Operators
Let e be a unit vector in a Hilbert space H over the ﬁeld K with inner product ⟨·, ·⟩.
Deﬁne Pe : H→H by Pex = ⟨e, x⟩e for all x ∈H. Evidently, Pe is a bounded linear
operator with null space (kernel) N(Pe) = {e}⊥and range ranPe = Ke. In addition
Pe satisﬁes P ∗
e = Pe and P 2
e = Pe which is also elementary to prove. The operator
Pe is the simplest example of the class of projection operators or projectors to be
studied in this section.
Deﬁnition 23.1 A bounded linear operator P on a Hilbert space H which is sym-
metric, P ∗= P , and idempotent, P 2 = P, is called a projector or projection
operator.
The set of all projection operators on a Hilbert space H is denoted by P(H), i.e.,
P(H) =

P ∈B(H) : P ∗= P = P 2
.
With the help of the following proposition one can easily construct many examples
of projectors explicitly.
Proposition 23.1 Let H be a Hilbert space over the ﬁeld K. Projectors on H have
the following properties:
a) For every P ∈P(H), P ̸= 0, ∥P∥= 1;
b) a bounded operator P ∈B(H) is a projector if, and only if, P ⊥= I −P is a
projector;
c) if P ∈P(H), then
H = ranP ⊕ranP ⊥,
P|ranP = IranP ,
P|ranP ⊥= 0;
d) there is a one-to-one correspondence between projection operators P on H and
closed linear subspaces M of H, i.e., the range ranP of a projector P is a closed
linear subspace of H, and conversely to every closed linear subspace M ⊂H
there is exactly one P ∈P(H) such that the range of this projector is M;
© Springer International Publishing Switzerland 2015
325
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_23

326
23
Special Classes of Linear Operators
e) Suppose that {en : n = 1, . . ., N}, N ∈N or N = ∞is an orthonormal
system in H, then the projection operator onto the closed linear subspace
M = [ {en : n = 1, . . ., N} ] generated by the orthonormal system is
PNx =
N

n=1
⟨en, x⟩en
∀x ∈H.
(23.1)
Proof By deﬁnition any projector satisﬁes P = P ∗P, thus by Theorem 22.3 ∥P∥=
∥P ∗P ∥= ∥P ∥2, and therefore ∥P∥∈{0, 1} and Part a) follows.
To prove b) we show that the operator I −P satisﬁes the deﬁning relations of a
projector (Q = Q∗= Q2) if, and only if, P does: I −P = (I −P)∗= I −P ∗⇔
P = P ∗and I −P = (I −P)2 = I −P −P + P 2 ⇔−P + P 2 = 0.
For the proof of Part c) observe that the relation I = P +P ⊥implies immediately
that every x ∈H is the sum of an element in the range ofP and an element in the range
of P ⊥. In Part d) we prove that the range of a projector is a closed linear subspace.
Thus ranP ⊕ranP ⊥gives indeed a decomposition of H into closed orthogonal
subspaces. The image of Px ∈ranP under P is PPx = Px, since P 2 = P and
similarly, the image of P ⊥x ∈ranP ⊥under P is PP ⊥x = P(I −P)x = 0, thus
the second and third statement in Part c) follow.
Let P be a projector on H and y an element in the closure of the range of P,
i.e., there is a sequence (xn)n∈N ⊂H such that y = lim Pxn. Since a projector is
continuous we deduce Py = limn→∞PPxn = lim Pxn = y, thus y ∈ranP and
the range of a projector is a closed linear subspace.
Now given a closed linear subspace M ⊂H, we apply to each x ∈H the
Projection Theorem 16.1 to get a unique decomposition of x into ux ∈M and
vx ∈M⊥, x = ux + vx. The uniqueness condition allows us to conclude that the
mapping x #→ux is linear. Since ∥x∥2 = ∥ux∥2 + ∥vx∥2 ≥∥ux∥2 the linear map
PM : H→M deﬁned by PMx = ux is bounded. Next apply the projection theorem
to x, y ∈H to get
⟨x, PMy⟩= ⟨ux + vx, uy⟩= ⟨ux, uy⟩= ⟨PMx, PMy⟩= ⟨PMx, y⟩,
hence PM = P ∗
M = P ∗
MPM = P 2
M and thus PM is a projector. Per construction its
range is the given closed subspace M. This proves Part d).
The proof of Part e) is done explicitly for the case N = ∞. Then the closed
linear hull M of the linear subspace generated by the given orthonormal system is
described in Corollary 17.1 as
M =

x ∈H : x =
∞

n=1
cnen, cn ∈K,
∞

n=1
|cn|2 < ∞

.
Givenx ∈H, Bessels’inequality(Corollary15.1)statesthat∞
n=1 |⟨en, x⟩|2 ≤∥x∥2,
hence PMx = ∞
n=1⟨en, x⟩en ∈M and ∥PMx∥≤∥x∥. It follows that PM is a
bounded linear operator into M. By deﬁnition PMen = en and thus P 2
Mx = PMx for

23.1
Projection Operators
327
all x ∈H and we conclude P 2
M = PM. Next we prove symmetry of the operator PM.
For all x, y ∈H the following chain of identities holds using continuity of the inner
product:
⟨x, PMy⟩= ⟨x,
∞

n=1
⟨en, y⟩en⟩=
∞

n=1
⟨x, en⟩⟨en, y⟩=
∞

n=1
⟨⟨en, x⟩en, y⟩= ⟨PMx, y⟩,
hence P ∗
M = PM and the operator PM is a projector. Finally from the characterization
of M repeated above it is clear that PM maps onto M.
2
This proposition allows us, for instance, to construct projection operators Pj =
PMj such that
P1 + P2 + · · · + PN = I
for any given family M1, . . ., MN of pair-wise orthogonal closed linear subspaces Mj
of a Hilbert space H such that H = M1⊕M2⊕· · ·⊕MN. Such a family of projection
operators is called a resolution of the identity. Later in connection with the spectral
theorem for self-adjoint operators we will learn about a continuous analogue. Thus,
intuitively, projectors are the basic building blocks of self-adjoint operators.
Recall that a bounded monotone increasing sequence of real numbers converges.
The same is true for sequences of projectors if the appropriate notion of monotonicity
is used.
Deﬁnition 23.2
Let H be a Hilbert space with inner product ⟨·, ·⟩. We say that a
bounded linear operator A on H is smaller than or equal to a bounded linear operator
B on H, in symbols A ≤B if, and only if, for all x ∈H one has ⟨x, Ax⟩≤⟨x, Bx⟩.
We prepare the proof of the convergence of a monotone increasing sequence of
projectors by
Lemma 23.1
For two projectors P, Q on a Hilbert space H the following
statements are equivalent:
a) P ≤Q;
b) ∥P x∥≤∥Qx∥for all x ∈H;
c) ranP ⊆ran Q;
d) P = P Q = QP.
Proof
Since any projector satisﬁes P = P ∗P, the inequality ⟨x, Px⟩≤⟨x, Qx⟩
holds if, and only if, ⟨Px, Px⟩≤⟨Qx, Qx⟩holds, for all x ∈H, thus a) and b) are
equivalent.
Assume ranP ⊆ran Q and recall that y ∈H is an element of the range of the
projector Q if, and only if, Qy = y. The range of P is PH which by assumption
is contained in ran Q, hence QPx = Px for all x ∈H which says QP = P; and
conversely, if QP = P holds, then clearly ranP ⊆ran Q. Since projectors are
self-adjoint we know that P = QP = (QP)∗= P ∗Q∗= PQ, therefore statements
c) and d) are equivalent.
If d) holds, then Px = PQx and thus ∥Px∥= ∥PQx∥≤∥Qx∥for all x ∈H,
and conversely if ∥Px∥≤∥Qx∥for all x ∈H, then Px = QPx + Q⊥Px implies

328
23
Special Classes of Linear Operators
∥Px∥2 = ∥QP x∥2 + ∥Q⊥Px∥2 and hence Q⊥Px = 0 for all x ∈H, therefore
P = QP and b) and d) are equivalent.
2
Theorem 23.1 A monotone increasing sequence (Pj)j∈N of projectors on a Hilbert
space H converges strongly to a projector P on H.
The null space of the limit is N(P) = ∩∞
j=1N(Pj) and its range is ranP =
∪∞
j=1ranPj.
Proof Pj ≤Pj+1 means according to Lemma 23.1 that ∥Pjx∥≤∥Pj+1x∥≤∥x∥
for all x ∈H. Thus the monotone increasing and bounded sequence (∥Pjx∥)j∈N of
numbers converges. Lemma 23.1 implies also that Pk = PkPj = PjPk for all k ≤j
and therefore
∥Pjx −Pkx∥2 = ⟨Pjx, Pjx⟩−⟨Pjx, Pkx⟩−⟨Pkx, Pjx⟩+ ⟨Pkx, Pkx⟩
= ⟨x, Pjx⟩−⟨x, Pkx⟩= ∥Pjx∥2 −∥Pkx∥2
for all j ≥k. Since the numerical sequence (∥Pjx∥)j∈N converges, we deduce that
the sequence of vectors (Pjx)j∈N is a Cauchy sequence in H and thus converges to
some vector in H which we denote by Px,
Px = lim
j→∞Pjx.
Since this applies to every x ∈H, a map H ∋x→Px ∈H is well deﬁned. Standard
rules of calculation for limits imply that this map P is linear. The bound ∥Pjx∥≤∥x∥
for all j ∈N implies that ∥Px∥≤∥x∥holds for every x ∈H, i.e., P is a bounded
linear operator on H.
Next we show that this operator is symmetric and idempotent. Continuity of the
inner product implies for all x, y ∈H,
⟨x, Py⟩= lim
j→∞⟨x, Pjy⟩= lim
j→∞⟨Pjx, y⟩= ⟨Px, y⟩
and P is symmetric.
Our starting point of the proof of the relation P = P 2 is the observation that
limj→∞⟨Pjx, Pjy⟩= ⟨Px, Py⟩which follows from the estimate
|⟨P x, Py⟩−⟨Pjx, Pjy⟩| = |⟨Px −Pjx, Pjy⟩+ ⟨Px, Py −Pjy⟩|
≤|⟨Px −Pjx, Pjy⟩| + |⟨Px, Py −Pjy⟩|
≤∥y∥∥Px −Pjx∥+ ∥Px∥∥Py −Pjy∥
and the strong convergence of the sequence (Pj)j∈N. With this result the identity
P = P 2 is immediate: For all x, y ∈H it implies that ⟨x, Py⟩= limj→∞⟨x, Pjy⟩=
limj→∞⟨Pjx, Pjy⟩= ⟨Px, Py⟩and thus P = P 2.
If a vector x belongs to the kernel of all the projectors Pj, then Px
=
limj→∞Pjx = 0 implies x ∈N(P). Conversely Pj ≤P implies Pjx = 0 for
all j ∈N if P x = 0.

23.2
Unitary Operators
329
By monotonicity we know ∥Pjx∥≤limk→∞∥Pkx∥= ∥Px∥for all j ∈N, hence
by Lemma 23.1 ranPj ⊆ranP for all j ∈N, and therefore the closure of union of the
ranges of the projectors Pj is contained in the range of P. Since Px = limj→∞Pjx
it is obvious that the range of the limit P is contained in the closure of the union of
the ranges ranPj.
2
23.2
Unitary Operators
23.2.1
Isometries
The subject of this subsection is the linear maps between two Hilbert spaces which
do not change the length or norm of vectors. These bounded operators are called
isometries.
Deﬁnition 23.3 For two Hilbert spaces H and K over the same ﬁeld K any linear
map A : H→K with the property
∥Ax∥K = ∥x∥H
∀x ∈H
is called an isometry (between H and K).
Since the norm of a Hilbert space is deﬁned in terms of an inner product the
following convenient characterization of isometries is easily available.
Proposition 23.2 Given two Hilbert spaces H, K over the ﬁeld K and a bounded
linear operator A : H→K, the following statements hold.
a) A is an isometry ⇔A∗A = IH;
b) Every isometry A has an inverse operator A−1 : ran A→H and this inverse is
A−1 = A∗|ran A;
c) If A is an isometry, then AA∗= Pran A is the projector onto the range of A.
Proof The adjoint A∗: K→H of A is deﬁned by the identity ⟨A∗y, x⟩H = ⟨y, Ax⟩K
for all x ∈H and all y ∈K. Thus using the deﬁnition of an isometry we get
⟨x, A∗Ax⟩H = ⟨Ax, Ax⟩K = ⟨x, x⟩H for all x ∈H. The polarization identity
implies that ⟨x1, x2⟩H = ⟨x1, A∗Ax2⟩H for all x1, x2 ∈H and therefore A∗A = IH.
The converse is obvious.
Certainly, an isometry is injective and thus on its range it has an inverse A−1 :
ran A→H. The characterization A∗A = IH of Part a) allows us to identify the inverse
as A∗|ran A.
For Part c) we use the orthogonal decomposition K = ran A ⊕(ran A)⊥and
determine AA∗on both subspaces. For y ∈(ran A)⊥the equation 0 = ⟨y, Ax⟩K =
⟨A∗y, x⟩H for all x ∈H implies A∗y = 0 and thus AA∗y = 0. For y ∈ran A, Part
b) gives AA∗y = AA−1y = y and we conclude.
2

330
23
Special Classes of Linear Operators
23.2.2
Unitary Operators and Groups of Unitary Operators
According to Proposition 23.2 the range of an isometric operator A : H→K con-
tains characteristic information about the operator. In general the range is a proper
subspace of the target space K. The case where this range is equal to the target space
deserves special attention. These operators are discussed in this subsection.
Deﬁnition 23.4 A surjective isometry U : H→K is called a unitary operator.
On the basis of Proposition 23.2 unitary operators can be characterized as follows.
Proposition 23.3 For a bounded linear operator U : H→K these statements are
equivalent:
a) U is unitary;
b) U ∗U = IH and UU ∗= IK;
c) UH = K and ⟨Ux, Uy⟩K = ⟨x, y⟩H for all x, y ∈H.
Note that Part c) of this proposition identiﬁes unitary operators as those surjective
bounded linear operators which do not change the value of the inner product. Thus
unitary operators respect the full structure of Hilbert spaces (linear, topological,
metric and geometric structure). Accordingly unitary operators are the isomorphisms
of Hilbert spaces. In the chapter on separable Hilbert spaces (Chap. 16) we had
constructed an important example of such an isomorphism of Hilbert spaces: There
we constructed a unitary map from a separable Hilbert space over the ﬁeld K onto
the sequence space ℓ2(K).
Note also that in the case of ﬁnite dimensional spaces every isometry is a unitary
operator. The proof is done as an exercise. In the case of inﬁnite dimensions there
are many isometric operators which are not unitary. A simple example is discussed
in the Exercises.
For unitary operators of a Hilbert space H onto itself the composition of mappings
is well deﬁned. The composition of two unitary operators U, V on the Hilbert space
H is again a unitary operator since by Part b) of Proposition 23.3 (UV )∗(UV ) =
V ∗U ∗UV = V ∗V = IH and (UV )(UV )∗= UV V ∗U ∗= UU ∗= IH. Thus the
unitary operators of a Hilbert space H form a group, denoted by U(H).
ThisgroupU(H)containsmanyimportantandinterestingsubgroups. Forquantum
mechanics the one-parameter groups of unitary operators play a prominent rôle.
Deﬁnition 23.5 A family of unitary operators {U(t) : t ∈R} ⊂U(H) is called a
one-parameter group of unitary operators in H if, and only if, U(0) = IH and
U(s)U(t) = U(s + t) for all s, t ∈R.
Naturally one can view a one-parameter group of unitary operators on H as a
representation of the additive group R by unitary operators on H. The importance of
these groups for quantum mechanics comes from the fact that the time evolution of
quantum systems is typically described by such a group.
Under a weak continuity hypothesis the general form of these groups is known.

23.2
Unitary Operators
331
Theorem 23.2 (Stone). Let {U(t) : t ∈R} be a one-parameter group of unitary
operators on the complex Hilbert space H which is strongly continuous, i.e., for
every x ∈H the function R ∋t→U(t)x ∈H is continuous. Then the set
D =
+
x ∈H : lim
t→0
1
t [U(t)x −x]
exists
,
is a dense linear subspace of H and on D a linear operator A is well deﬁned by
iAx = lim
t→0
1
t [U(t)x −x]
∀x ∈D.
This operator A is self-adjoint (on D). It is called the inﬁnitesimal generator of the
group which often is expressed in the notation
U(t) = e itA,
t ∈R.
Proof Since the group U is strongly continuous, the function R ∋t→U(t)x ∈H
is continuous and bounded (by ∥x∥) for every x ∈H. For every function f ∈D(R),
the function t #→f (t)U(t)x is thus a continuous function of compact support for
which the existence of the Riemann integral and some basic estimates are shown in
the Exercises. This allows us to deﬁne a map J : D(R) × H→H by this integral:
J(f, x) =

R
f (t)U(t)xdt.
Since U is strongly continuous, given ε > 0, there is r > 0 such that
sup−r≤t≤r ∥U(t)x −x∥≤ε. Choose a nonnegative function ρr ∈D(R) with the
properties

R ρr(t) dt = 1 and supp ρr ⊆[−r, r] (such functions exist according to
the chapter on test functions) and estimate
∥J(ρr, x) −x∥= ∥

R
ρr(t)[U(t)x −x] dt∥≤

R
∥ρr(t)[U(t)x −x]∥dt
≤∥ρr∥1 sup
−r≤t≤r
∥U(t)x −x∥≤ε.
Therefore the set D0 = {J(f , x) : f ∈D(R), x ∈H} is dense in the Hilbert space
H. By changing the integration variables we ﬁnd the transformation law of the vectors
J(f , x) under the group U:
U(t)J(f , x) = J(f−t, x),
fa(x) = f (x −a) ∀x ∈R.
This transformation law and the linearity of J with respect to the ﬁrst argument
imply that the group U is differentiable on D0: The relation U(s)J(f , x)−J(f , x) =
J(fs −f , x) gives
lim
s→0
1
s [U(s)J(f , x) −J(f , x)] = lim
s→0 J(f−s −f
s
, x) = J(−f ′, x)
where we have used that (f−s −f )/s converges uniformly to −f ′ and that uniform
limits and Riemann integration commute.

332
23
Special Classes of Linear Operators
Deﬁne a function A : D0→D0 by AJ(f , x) = −i J(−f ′, x) and extend this
deﬁnition by linearity to the linear hull D of D0 to get a densely deﬁned linear
operator A : D→D. Certainly, the linear subspace D is also left invariant by the
action of the group, U(t)D ⊂D for all t ∈R and a straightforward calculation
shows
AU(t)ψ = U(t)Aψ
∀t ∈R, ∀ψ ∈D.
The symmetry of the operator A follows from the fact that this operator is deﬁned
as the derivative of a unitary group (modulo the constant −i ): For all f , g ∈D(R)
and all x, y ∈H the following chain of equations holds:
⟨AJ(f , x), J(g, y)⟩= ⟨lim
s→0
U(s) −I
i s
J(f , x), J(g, y)⟩
= lim
s→0⟨U(s) −I
i s
J(f , x), J(g, y)⟩
= lim
s→0⟨J(f , x), (U(s) −I
i s
)∗J(g, y)⟩
= lim
s→0⟨J(f , x), U(−s) −I
−i s
J(g, y)⟩
= ⟨J(f , x), AJ(g, y)⟩.
Certainly by linearity this symmetry relation extends to all of D.
Next, using Corollary 20.3 we show that A is actually essentially self-adjoint
on D. This is done by proving N(A∗± i I) = {0}. Suppose φ ∈D(A∗) satisﬁes
A∗φ = i φ. Then, for all ψ ∈D,
d
dt ⟨U(t)ψ, φ⟩= ⟨i AU(t)ψ, φ⟩= ⟨U(t)ψ, −i A∗φ⟩= ⟨U(t)ψ, φ⟩,
i.e., the function h(t) = ⟨U(t)ψ, φ⟩satisﬁes the differential equation h′(t) = h(t)
for all t ∈R and it follows that h(t) = h(0) et. Since the group U is unitary the
function h is bounded and this is the case only if h(0) = ⟨ψ, φ⟩= 0. This argument
applies to all ψ ∈D, hence φ ∈D⊥= {0} (D is dense). Similarly one shows
that A∗φ = −i φ is satisﬁed only for φ = 0. Hence Corollary 20.3 proves A to be
essentially self-adjoint, thus the closure A of A is self-adjoint.
When spectral calculus has been developed we will be able to deﬁne the expo-
nential function e itA of an unbounded self-adjoint operator and then we can show
that this exponential function indeed is equal to the given unitary group.
2
The continuity hypothesis in Stone’s theorem can be relaxed. It sufﬁces to assume
that the group is weakly continuous, i.e., that R ∋t #→⟨x, U(t)y⟩is continuous
for every choice of x, y ∈H. This is so since on the class U(H) the weak and
strong topology coincide (see Exercises). In separable Hilbert spaces the continuity
hypothesis can be relaxed even further to weak measurability, i.e., the map R ∋t #→
⟨x, U(t)y⟩∈K is measurable, for every x, y ∈H.

23.3
Some Applications of Unitary Operators in Ergodic Theory
333
23.2.3
Examples of Unitary Operators
In the section on Fourier transformation for tempered distributions we learned that the
Fourier transform F2 on the Hilbert space L2(Rn) is a unitary operator. In the same
Hilbert space we consider several other examples of unitary operators, respectively
groups of such operators.
For f ∈L2(Rn) and a ∈Rn, deﬁne fa(x) = f (x −a) for all x ∈Rn and then
deﬁne Ua : L2(Rn)→L2(Rn) by Uaf = fa for all f ∈L2(Rn). For all f , g ∈L2(Rn)
one has
⟨U(a)f , U(a)g⟩2 =

Rn f (x −a)g(x −a) d x =

Rn f (y)g(y) dy = ⟨f , g⟩2
and U(a) is an isometry. Given f ∈L2(Rn), deﬁne g = f−a and calculate U(a)g =
ga = f , hence U(a) is surjective and thus a unitary operator, i.e., U(a) ∈U(L2(Rn))
for all a ∈Rn. In addition we ﬁnd
U(0) = IL2(Rn),
U(a)U(b) = U(a + b),
∀a, b ∈Rn,
i.e., {U(a) : a ∈Rn} is an n-parameter group of unitary operators on L2(Rn).
Naturally, U(a) has the interpretation of the operator of translation by a.
23.3
Some Applications of Unitary Operators in Ergodic Theory
Ergodic theory generalizes the law of large numbers to random variables which are
identically distributed but not necessarily independent. It started from problems of
statistical physics and nowadays it is a well developed mathematical theory with
many impressive results [1]. Basically ergodic theory is the study of dynamical
systems with an invariant measure, typically the long time behaviour is investigated.
The earliest result of note is the Poincaré recurrence theorem [23.3]. The central
results of ergodic theory state that under suitable assumptions the time average of a
function along the trajectory of a dynamical system exists and is related to the space
average in a speciﬁc way. Here the prominent early results are those of Birkhoff
[23.7] and von Neumann [23.6]. In important special cases the time development of
a dynamical systems is described by a strongly continuous one-parameter group of
unitary operators V (t), t ∈R, in a separable Hilbert space H. A much used measure
for this long time behaviour is the limit T −→∞of the time average
1
T
 T
0
V (t) dt.
Ify ∈H isinvariantunderthegroup, i.e., V (t)y = y forallt, then 1
T
 T
0 V (t) dty = y
for all T > 0 and thus one would expect that this time average converges to
the projector P onto the invariant subspace for the unitary group: Hinv
=

334
23
Special Classes of Linear Operators
{y ∈H : V (t)y = y, ∀t}. Similarly, the following mean ergodic theorem states that
the average
1
N
N−1

n=0
U n
for a unitary operator U converges strongly to the projection operator P onto the
invariant subspace of U.
23.3.1
Poincaré Recurrence Results
Given a probability space (X, Σ, μ) and a measurable and measure preserving map
T : X→X, i.e., μ(T −1(A)) = μ(A) for all A ∈Σ, introduce for A ∈Σ the sets
T n(A) =

y ∈X : y = T n(x), x ∈A

and
T−n(A) =

x ∈X : Tn(x) ∈A

of those points which occur as images under n iterations of T respectively the set of
those points in X which under n iterations are elements of A.
There is an elementary observation about ﬁnite collections T −n(A), n = 0, . . ., m
of these sets:
If μ(A) > 0 and if m ∈N satisﬁes m >
1
μ(A) then at least two sets of this collection have an
intersection with positive measure; μ(T −n(A) ∩T −k(A)) > 0 for 0 ≤n, k ≤m, k ̸= n.
If this would not be the case the (ﬁnite) additivity of the measure μ implies μ( ∪m
n=0
T −n(A)) = m
n=0 μ(T −n(A)) and thus, since T is measure preserving, this equals
m
n=0 μ(A) = μ(A)(m + 1) > 1, a contradiction.
Since T is measure preserving we know for all k ≥n ≥0
μ(T −n(A) ∩T −k(A)) = μ(A ∩T −(k−n)(A)).
Therefore our observation proves the basic version of the Poincaré recurrence
theorem.
Theorem 23.3 (Poincaré Recurrence Theorem—BasicVersion). Let (X, Σ, μ) be
a probability space and T : X−→X a measure preserving map. Then, for any A ∈Σ
with μ(A) > 0 there is m ∈N such that μ(A ∩T −m(A)) > 0, i.e., the set of points
in A which after m iterations of T return to A has positive measure.
A modern and much stronger version of this result is
Theorem 23.4 (Poincaré Recurrence Theorem). Let (X, Σ, μ) be a probability
space and T : X→X a measure preserving map. Then, for any A ∈Σ
μ

x ∈A : ∃n ∈N ∀k≥n T k(x) /∈A

= 0;
(23.2)
i.e., the set of points x ∈A such that T k(x) /∈A for all but ﬁnitely many k has zero
measure, in other words almost every point of A returns to A under T , inﬁnitely

23.3
Some Applications of Unitary Operators in Ergodic Theory
335
often; and
μ
$
A ∩
∞

n=1
∞

k=n
T −k(A)
%
= μ(A),
(23.3)
i.e., the set of x ∈A which return to A inﬁnitely often has the same measure as A.
Proof Given A ∈Σ introduce the set B =

x ∈A : ∃n ∈N ∀k>n T k(x) /∈A

.
Observe that for n ∈N and x ∈A one has

∀k≥n T k(x) /∈A

⇔

∀k≥n x /∈T −k(A)

⇔(x /∈An)
when we deﬁne for n = 0, 1, 2, . . .
An =
∞

k=n
T −k(A).
It follows
B =
∞

n=1
(A\An) = A\
∞

n=1
An.
Clearly A ⊆A0 and An ⊆Am for m ≤n, furthermore one has An = T m−n(Am)
and since T is measure preserving it follows μ(An) = μ(Am). Now A\An ⊆A0\An
implies 0 ≤μ(A\An) ≤μ(A0\An) = μ(A0) −μ(An) = 0, hence μ(A\An) = 0
for n ∈N and therefore
μ(B) = μ
$ ∞

n=1
(A\An)
%
≤
∞

n=1
μ(A −An) = 0.
With the above representation of the set B statement (23.3) follows immediately
from (23.2).
2
Observe that these results can be extended to all ﬁnite positive measures.
23.3.2
The Mean Ergodic Theorem of von Neumann
Theorem 23.5 (Mean Ergodic Theorem—von Neumann) For any unitary opera-
tor U on a separable Hilbert space H one has for all x ∈H
lim
N→∞
1
N
N−1

n=0
U nx = Px
(23.4)
where P is the orthogonal projector onto the closed linear subspace
Hinv = {y ∈H : Uy = y}
of all invariant vectors in H.

336
23
Special Classes of Linear Operators
Proof Clearly, the set Hinv of all vectors in H which are invariant under U is a closed
linear subspace of H and thus there is a unique orthogonal projector P : H−→Hinv.
The linear operator
SN = 1
N
N−1

n=0
U n
is bounded with norm smaller or equal to 1. For all x ∈Hinv and all N ∈N we ﬁnd
SNx = x and thus Eq 23.4 holds for these vectors and we are left with proving this
equation for all x ∈H⊥
inv.
In order to determine H⊥
inv introduce the set H0 = {Uy −y : y ∈H} and ﬁnd its
orthogonal complement. If x ∈H⊥
0 , then for all y ∈H we have 0 = ⟨x, Uy −y⟩=
⟨U ∗x −x, y⟩and thus U ∗x −x = 0, hence Ux = x, i.e., x ∈Hinv. This shows
H⊥
0 ⊆Hinv.
If x ∈Hinv, then also x = U ∗x and thus for all y ∈H, 0 = ⟨y, U ∗x −x⟩=
⟨Uy −y, x⟩, hence x ∈H⊥
0 . This shows Hinv ⊆H⊥
0 and therefore Hinv = H⊥
0 or
H⊥
inv = ¯H0, the closure of H0 in H.
For x = Uy −y ∈H0 one has
SNx = 1
N (U Ny −y).
We conclude ∥SNx∥≤
2
N ∥y∥−→0 for N−→∞. Since the sequence of operators
SN is uniformly bounded, it follows immediately that ∥SNx∥−→0 also holds for
points x in the closure of H0 and therefore
lim
N→∞SNx = 0,
x ∈H⊥
inv,
and this completes the proof of Eq 23.4.
2
Now consider again a probability space (X, Σ, μ) with a measure preserving map
T : X−→X. Then it is easy to see that the operator U = UT deﬁned by Uf = f ◦T
is unitary on the Hilbert space H = L2(X, μ). In this case the space of all invariant
vectors is the space of all f ∈L2(X, μ) such that f ◦T = f and we arrive at the
original version of von Neumann.
Theorem 23.6 (von Neumann) Under the assumptions formulated above, for every
f ∈L2(X, μ) the sequence 1
N
N−1
n=0 U n
T f converges in L2(X, μ) to the projection
of f to the subspace of invariant functions.
In this theorem convergence is in the L2(X, μ) -sense. Naturally one could ask
under which conditions one has pointwise convergence. This question has been
answered by Birkhoff [2] in his strong ergodic theorem. For this we need to recall
the deﬁnition of ergodicity of a measure preserving map.
Deﬁnition 23.6
Let T be a measure preserving transformation on a probability
space (X, Σ, μ). T is called ergodic if, and only if, for every T -invariant set A ∈Σ
(i.e., T −1(A) = A) one has μ(A) = 0 or μ(A) = 1.
Theorem 23.7 (Birkhoff’s Pointwise Ergodic Theorem) Under the assumptions
formulated above, for every f ∈L1(X, μ) the sequence
1
N
N−1
n=0 U n
T f converges

23.4
Self-Adjoint Hamilton Operators
337
pointwise μ-almost everywhere to a T -invariant function ˆf . If T is ergodic, then ˆf
is constant and for μ-almost all x ∈X one has
ˆf (x) =

f(y) d μ(y).
Since obviously the proof of this result can not be done by Hilbert space methods
we do not present it here and refer to the literature, for instance [4, 5].
23.4
Self-Adjoint Hamilton Operators
The time evolution of a classical mechanical system is governed by the Hamilton
function. Similarly, the Hamilton operator determines the time evolution of a quan-
tum mechanical system and this operator provides information about the total energy
of the system in speciﬁc states. In both cases it is important that the Hamilton oper-
ator is self-adjoint in the Hilbert space of the quantum mechanical system. Thus we
are faced with the mathematical task of constructing a self-adjoint Hamilton operator
out of a given classical Hamilton function. The Hamilton function is the sum of the
kinetic and the potential energy. For the construction of the Hamilton operator this
typically means that we have to add two unbounded self-adjoint operators.
In the chapter on quadratic forms we have explained a strategy which allows to
add two unbounded positive operators even if the intersection of their domains of def-
inition is too small for the natural addition of unbounded operators to be meaningful.
Now we consider the case where the domain of the potential operator contains the do-
main of the free Hamilton operator. Then obviously the addition of the two operators
is not a problem. But the question of self-adjointness of the sum remains. The key to
the solution of this problem is to consider the potential energy as a small perturbation
of the free Hamilton operator, in a suitable way. Then indeed self-adjointness of the
sum on the domain of the free Hamilton operator follows.
A ﬁrst section introduces the basic concepts and results of the theory of Kato
perturbations (see the book of T. Kato, [6]) which is then applied to the case of
Hamilton operators discussed above.
23.4.1
Kato Perturbations
As in most parts of this book related to quantum mechanics, in this section H is
assumed to be a complex Hilbert space. The starting point is
Deﬁnition 23.7 Suppose A, B are two densely deﬁned linear operators in H. B is
called a Kato perturbation of A if, and only if, D(A) ⊂D(B) and there are real
numbers 0 ≤a < 1 and b such that
∥Bx∥≤a∥Ax∥+ b∥x∥
∀x ∈D(A).
(23.5)

338
23
Special Classes of Linear Operators
This notion of a Kato perturbation is very effective in solving the problem of self-
adjointness of the sum, under natural restrictions.
Theorem 23.8 (Kato–Rellich Theorem) Suppose A is a self-adjoint and B is a
symmetric operator in H. If B is a Kato perturbation of A, then the sum A + B is
self-adjoint on the domain D(A).
Proof According to Part c) of Theorem 20.4 it sufﬁces to show that for some number
c > 0 we have ran (A + B + icI) = H. For every x ∈D(A) and c ∈R a simple
calculation gives
∥(A + icI)x∥2 = ∥Ax∥2 + c2∥x∥2.
(23.6)
Hence, for c ̸= 0, the operator A + icI is injective and thus has an inverse on its
range which is equal to H by Theorem 20.4 and which has values in the domain of A.
Therefore the elements x ∈D(A) can be represented as x = (A + icI)−1y, y ∈H
and the above identity can be rewritten as
∥y∥2 = ∥A(A + icI)−1y∥2 + c2∥(A + icI)−1y∥2
∀y ∈H.
And this identity has two implications:
∥A(A + icI)−1∥≤1,
∥(A + icI)−1∥≤1
|c|, c ̸= 0.
Now use the assumption that B is a Kato perturbation of A. For c > 0 and x =
(A + icI)−1y ∈D(A) the following estimate results:
∥B(A + icI)−1y∥≤a∥A(A + icI)−1y∥+ b∥(A + icI)−1y∥≤(a + b
c )∥y∥.
We deduce ∥B(A + icI)−1∥≤(a + b
c ). Since a < 1 is assumed there is a c0 > 0
such that (a + b
c0 ) < 1. Thus C = B(A+ icI)−1 is a bounded operator with ∥C∥< 1
and therefore the operator I + C is invertible with inverse given by the Neumann
series (see Eq. (22.4)). This means in particular that the operator I + C has the
range ran (I + C) = H. Since A is self-adjoint one knows ran (A ± ic0I) = H and
therefore that the range of A + B ± ic0I = (I + C)(A ± ic0I) is the whole Hilbert
space. Thus we conclude.
2
One can read the Kato–Rellich theorem as saying that self-adjointness of operators
is a property which is stable against certain small symmetric perturbations. But
naturally in a concrete case it might be quite difﬁcult to establish whether or not
a given symmetric operator is a Kato perturbation of a given self-adjoint operator.
Thus the core of the following section is to prove that certain classes of potential
operators are indeed Kato perturbations of the free Hamilton operator.

23.4
Self-Adjoint Hamilton Operators
339
23.4.2
Kato Perturbations of the Free Hamiltonian
Though it can be stated more generally, we present the case of a three dimensional
system explicitly. The Hamilton function of a particle of mass m > 0 in the force
ﬁeld associated with a potential V is
H(p, q) = 1
2mp2 + V (q)
where q ∈R3 is the position variable and p ∈R3 the momentum of the particle.
Recall the realization of the position operator Q = (Q1, Q2, Q3) and of the
momentum operator P = (P1,P2,P3) in the Hilbert space H = L2(R3) of such a
system. The domain of Q is
D(Q) =

ψ ∈L2(R3) : xjψ ∈L2(R3), j = 1, 2, 3

and on this domain the component Qj is deﬁned as the multiplication with the
component xj of the variable x ∈R3. Such multiplication operators have been
shown to be self-adjoint. Then the observable of potential energy V (Q) is deﬁned
on the domain
D(V ) =

ψ ∈L2(R3) : V · ψ ∈L2(R3)

by
(V (Q)ψ)(x) = V (x)ψ(x)
for almost all x ∈R3, ∀ψ ∈D(V ). We assume V to be a real valued function which
is locally square integrable. Then, as we have discussed earlier, V is self-adjoint.
The momentum operator P is the generator of the three parameter group of
translations deﬁned by the unitary operators U(a), a ∈R3, U(a)ψ = ψa, for
all ψ ∈L2(R3). As in the one dimensional case discussed explicitly, this group is
strongly continuous and thus Stone’s Theorem 23.2 applies and according to this
theorem the domain of P is characterized by
D(P ) =
+
ψ ∈L2(R3) : lim
s→0
1
s [ψsej −ψ] ∈L2(R3), j = 1, 2, 3
,
where ej is the unit vector in coordinate direction j. Representing the elements ψ
of L2(R3) as images under the Fourier transform F2, ψ = F2( ˜ψ), the domain D(P)
is conveniently described as D(P) =
 
ψ = F2( ˜ψ) : ˜ψ ∈D( ˜Q)
!
where D( ˜Q) =
 
˜ψ ∈L2(R3) : qj ˜ψ(q) ∈L2(R3), j = 1, 2, 3
!
. Then the action of the momentum
operator is P ψ = F2( ˜Q ˜ψ).
Similarly the domain of the free Hamilton operator
H0 = 1
2mP 2
is D(H0) =
 
ψ = F2( ˜ψ) : q2 ˜ψ(q) ∈L2(R3)
!
. H0 is self-adjoint on this domain.

340
23
Special Classes of Linear Operators
The veriﬁcation that large classes of potential operators V are Kato perturbations
of the free Hamiltonian is prepared by
Lemma 23.2 All ψ ∈D(H0) ⊂L2(R3) are bounded by
∥ψ∥∞≤2−3/2π−1/2(r−1/22m ∥H0ψ∥2 + r3/2 ∥ψ∥2 ),
any r > 0.
(23.7)
Proof For every ψ ∈D(H0) we know (1 + q2) ˜ψ(q) ∈L2(R3) and (1 + q2)−1 ∈
L2(R3) and thus deduce ˜ψ(q) = (1 + q2)−1(1 + q2) ˜ψ(q) ∈L1(R3). The Cauchy–
Schwarz inequality implies
∥˜ψ∥1 =

R3 (1 + q2)−1(1 + q2)| ˜ψ(q)| dq
≤∥(1 + q2)−1∥2 ∥(1 + q2) ˜ψ(q)∥2 ≤π(∥q2 ˜ψ∥2 + ∥˜ψ∥2).
Now scale the function with r > 0, i.e., consider ˜ψr(q) = r3 ˜ψ(rq). A simple
integration shows
∥˜ψr∥1 = ∥˜ψ∥1,
∥˜ψr∥2 = r3/2∥˜ψ∥2,
∥q2 ˜ψr∥2 = r−1/2∥q2 ˜ψ∥2
and thus implies
∥˜ψ∥1 = ∥˜ψr∥1 ≤π(r−1/2∥q2 ˜ψ∥2 + r3/2∥˜ψ∥2).
For the Fourier transformation the estimate ∥ψ∥∞≤∥˜ψ∥1 is well known and
estimate (23.7) follows.
2
Theorem 23.9 Any potential of the form V = V1 + V2 with real valued functions
V1 ∈L2(R3) and V2 ∈L∞(R3) is a Kato perturbation of the free Hamilton operator
and thus the Hamilton operator H = H0 + V (Q) is self-adjoint on the domain
D(H0).
Proof For every ψ ∈D(H0) we estimate as follows:
∥V ψ∥2 ≤∥V1ψ∥2 + ∥V2ψ∥2 ≤∥V1∥2 ∥ψ∥∞+ ∥V ∥∞∥ψ∥2.
Now the term ∥ψ∥∞is estimated by our lemma and thus
∥V ψ∥2 ≤a(r) ∥H0ψ∥2 + b(r) ∥ψ∥2
with
a(r) = (2π)−1/2m ∥V1∥2 r−1/2,
b(r) = 2−3/2π−1/2r3/2 ∥V1∥2 + ∥V2∥∞.
For sufﬁciently large r the factor a(r) is smaller than 1 so that Theorem 23.8 applies
and proves self-adjointness of H0 + V (Q).
2

23.5
Exercises
341
23.5
Exercises
1. Consider the Hilbert space H = Kn and an isometric map A : Kn→Kn. Prove:
A is unitary.
2. In the Hilbert space H = ℓ2(K) with canonical basis {en : n ∈N} deﬁne a linear
operator A by A( ∞
n=1 cnen) = ∞
n=1 cnen+1, cn ∈K, ∞
n=1 |cn|2 < ∞. Show:
A is isometric but not unitary.
3. Show: The weak and strong operator topologies coincide on the space U(H) of
unitary operators on a Hilbert space H.
4. For a continuous function x : R→H on the real line with values in a Hilbert space
H which has a compact support, prove the existence of the Riemann integral

R
x(t) dt
and the estimate
----

R
x(t) dt
---- ≤

R
∥x(t)∥dt.
Hints: As a continuous real valued function of compact support the function
t #→∥x(t)∥is known to be Riemann integrable, hence

R
∥x(t)∥dt = lim
N→∞
N

i=1
∥x(tN,i)∥L
N
where

tN,i : i = 1, . . ., N

is an equidistant partition of the support of the
function x of length L. From the existence of this limit deduce that the sequence
SN =
N

i=1
x(tN,i) L
N ,
N ∈N
is a Cauchy sequence in the Hilbert space H and thus this sequence has a limit in
H which is the Riemann integral of the vector valued function x:

R
x(t) dt = lim
N→∞
N

i=1
x(tN,i) L
N .
The estimate for the norm of the Riemann integral follows easily.
Deduce also the standard properties of a Riemann integral, i.e., show that it is lin-
ear in the integrand, additive in its domain of integration and that the fundamental
theorem of calculus holds also for the vector-valued version.
5. Complete the proof of Theorem 25.4.
Hints: For the proof of Part b) see also [3].
6. Show that (1 + q2)−1 ∈L2(R3) and calculate
--(1 + q2)−1--
2.
7. Prove: Potentials of the form V (x) =
a
|x|ρ with some constant a are Kato
perturbations of the free Hamilton operator in L2(R3) if 0 < ρ ≤1.
Hints: Denote by χR the characteristic function of the ball with radius R > 0 and
deﬁne V1 = χRV and V2 = (1 −χR)V .

342
23
Special Classes of Linear Operators
References
1. Billingsley P. Ergodic theory and information. New York: Wiley; 1965.
2. Birkhoff GD. Proof of the ergodic theorem. Proc Natl Acad Sci U S A. 1931;17(12):656–660.
3. Kato T. Perturbation theory for linear operators. Berlin: Springer-Verlag; 1966.
4. Mackey GW. Ergodic theory and its signiﬁcance for statistical mechanics and probability theory.
Adv Math. 1974;12:178–268.
5. Reed M, Simon B. Functional analysis. vol. 1 of Methods of Modern Mathematical Physics.
2nd ed. New York: Academic Press; 1980.
6. Walters P. An introduction to ergodic theory. vol. 79 of Gaduate Texts in Mathematics. New
York: Springer-Verlag; 1982.

Chapter 24
Elements of Spectral Theory
The spectrum of a (closed) linear operator on an inﬁnite dimensional Hilbert space
is the appropriate generalization of the set of all eigenvalues of a linear operator
in a ﬁnite dimensional Hilbert space. It is deﬁned as the complement (in C) of the
resolvent set. The resolvent set of a linear operator A with domain D in a Hilbert space
H is deﬁned as the set of all numbers λ ∈C for which the inverse operator of A−λI
exists as a bounded linear operator H→D. For closed linear operators the resolvent
set is open. On it the resolvent identity holds. The Weyl criterium characterizes those
real numbers which belong to the spectrum σ(A) of a self-adjoint operator A. The
point spectrum consists of the set of all eigenvalues of an operator and the continuous
spectrum is the complement of the point spectrum (in σ(A)). As an illustration the
spectrum of unitary operators is determined. In particular, the spectrum of the Fourier
transformation F2 on L2(R) is the set {1, i , −1, −i }. Through examples it is shown
that the spectrum of an operator depends sensitively on its domain.
The spectrum σ(A) of a linear operator in an inﬁnite dimensional Hilbert space
H is the appropriate generalization of the set of all eigenvalues of a linear operator in
a ﬁnite dimensional Hilbert space. We intend to establish this statement in this and
in the later chapters.
If A is a complex N × N matrix, i.e., a linear operator in the Hilbert space CN,
one has a fairly simple criterium for eigenvalues: λ ∈C is an eigenvalue of A if, and
only if, there is a ψλ ∈CN, ψλ ̸= 0, such that Aψλ = λψλ or (A −λI)ψλ = 0. This
equation has a nontrivial solution if, and only if, the matrix A −λI is not invertible.
In the space of matrices, one has a convenient criterium to decide whether or not a
matrix is invertible. On this space the determinant is well deﬁned and convenient to
use: Thus A −λI is not invertible if, and only if, det (A −λI) = 0. Therefore the
set σ(A) of eigenvalues of the N × N matrix A is given by
σ(A) = {λ ∈C : A −λI is not invertible}
(24.1)
= {λ ∈C : det (A −λI) = 0} = {λ1, . . ., λN},
(24.2)
since the polynomial det (A −λI) of degree N has exactly N roots in C.
In an inﬁnite dimensional Hilbert space one does not have a substitute for the
determinant function which is general enough to cover all cases of interest (in special
cases one can deﬁne such a function, and we will mention it brieﬂy later). Thus, in
© Springer International Publishing Switzerland 2015
343
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_24

344
24
Elements of Spectral Theory
inﬁnite dimensional Hilbert space one can only use the ﬁrst characterization of σ(A)
which is independent of the dimension of the space. If we proceed with this deﬁnition
the above identity ensures consistency with the ﬁnite dimensional case.
24.1
Basic Concepts and Results
Suppose that H is a complex Hilbert space and D is a linear subspace of this space.
Introduce the set of bounded linear operators on H which map into D:
B(H, D) = {A ∈B(H) : ran A ⊆D}.
Our basis deﬁnition now reads:
Deﬁnition 24.1
Given a linear operator A with domain D in a complex Hilbert
space H, the set
ρ(A) =

z ∈C : A −zI has an inverse operator (A −zI)−1 ∈B(H, D)

(24.3)
is called the resolvent set of A and its complement
σ(A) = C\ρ(A)
(24.4)
the spectrum of A. Finally the function
RA : σ(A)→B(H, D),
RA(z) = (A −zI)−1
(24.5)
is the resolvent of A.
Given a point z ∈C, it is in general not straightforward to decide when the
operator A −zI has an inverse in B(H, D). Here the auxiliary concept of a regular
point is a good help.
Deﬁnition 24.2 Suppose that A is a linear operator in H with domain D. The set
of regular points of A is the set
ρr(A) = {z ∈C : ∃δ(z) > 0 such that ∥(A −zI)x∥≥δ(z)∥x∥∀x ∈D}.
(24.6)
The relation between regular points and points of the resolvent set is obvious and it
is also clear that the set of regular points is open. For a closed operator the resolvent
set is open too.
Lemma 24.1
Suppose A is a linear operator in H with domain D. Then the
following holds:
a) ρ(A) ⊆ρr(A);
b) ρr(A) ⊂C is open;
c) if A is closed the resolvent set is open too.

24.1
Basic Concepts and Results
345
Proof If z ∈ρ(A) is given, then the resolvent RA(z) is a bounded linear operator
H→D such that x = RA(z)(A −zI)x for all x ∈D, hence ∥x∥≤∥RA(z)∥∥(A −
zI)x∥for all x ∈D. For arbitrary ε > 0 deﬁne δ(z) = (∥RA(z)∥+ ε)−1. With this
choice of δ(z) we easily see that z ∈ρr(A) and Part a) is proven.
Given z0 ∈ρr(A) there is a δ(z0) > 0 such that ∥(A −z0I)x∥≥δ(z0)∥x∥for all
x ∈D. For all z ∈C with |z −z0| < 1
2δ(z0) we estimate
∥(A −zI)x∥= ∥(A −z0)x −(z −z0)x∥≥| ∥(A −z0)x∥−∥(z −z0)x∥|
≥∥(A −z0)x∥−1
2δ(z0)∥x∥≥1
2δ(z0)∥x∥
∀x ∈D,
hence with the point z0 the disk z ∈C : |z −z0| < 1
2δ(z0) is contained in ρr(A) too.
Thus this set is open.
Now we assume that the operator A is closed and z0 is a point in the resolvent
set of A. Then RA(z0) is a bounded linear operator and thus r = ∥RA(z0)∥−1 > 0.
For all z ∈C with |z −z0| < r this implies that C = (z −z0)RA(z0) is a bounded
operator H→D with ∥C∥< 1. Hence the Neumann series for C converges and it
deﬁnes the inverse of I −C:
(I −C)−1 =
∞

n=0
Cn.
For z ∈C observe that A−zI = A−z0I −(z−z0)I = (A−z0)[I −(z−z0)RA(z0)],
and it follows that for all points z ∈C with |z −z0| < r the inverse of A −zI exists
and is given by
(A −zI)−1 = (I −C)−1RA(z0) =
∞

n=0
(z −z0)nRA(z0)n+1.
In order to show that this inverse operator maps into the domain D, consider the
partial sum SN = N
n=0 (z −z0)nRA(z0)n+1 of this series. As a resolvent the operator
RA(z0) maps into D, hence all the partial sums SN map into D. For x ∈H we know
that
y = (A −zI)−1x = lim
N→∞SNx
in the Hilbert space H. We claim y ∈D. To see this calculate
(A −zI)SNx = [I −(z −z0)RA(z0)](A −z0I)
∞

n=0
(z −z0)nRA(z0)n+1x
= (I −C)
N

n=0
Cnx.
We deduce limN →∞(A −zI)SNx = x. Since A is closed, it follows that y ∈D and
(A −zI)y = x. This proves that (A −zI)−1 maps into D and thus is equal to the
resolvent RA(z), for all |z −z0| < r. And the resolvent set is therefore open.
2

346
24
Elements of Spectral Theory
Corollary 24.1 For a closed linear operator A in a complex Hilbert space H the
resolvent is an analytic function RA : ρ(A)→B(H). For any point z0 ∈ρ(A) one
has the power series expansion
RA(z) =
∞

n=0
(z −z0)nRA(z0)n+1
(24.7)
which converges in B(H) for all z ∈C with |z −z0| < ∥RA(z0)∥−1.
Furthermore the resolvent identity
RA(z) −RA(ζ) = (z −ζ)RA(z)RA(ζ)
∀z, ζ ∈ρ(A)
(24.8)
holds and shows that the resolvents at different points commute.
Proof The power series expansion has been established in the proof of Lemma 24.1.
Since the resolvent maps into the domain of the operator A one has
RA(z) −RA(ζ) = RA(z)(A −ζI)RA(ζ) −RA(z)(A −zI)RA(ζ)
= RA(z)[(A −ζI) −(A −zI)]RA(ζ) = (z −ζ)RA(z)RA(ζ)
which proves the resolvent identity.
Note that a straightforward iteration of the resolvent identity also gives the power
series expansion of the resolvent.
2
Note that according to our deﬁnitions the operator A−zI is injective for a regular
point z ∈C and has thus a bounded inverse on its range. For a point z in the resolvent
set ρ(A) the operator A−zI is in addition surjective and its inverse maps the Hilbert
space H into the domain D. Since regular points have a simple characterization one
would like to know when a regular point belongs to the resolvent set. To this end we
introduce the spaces HA(z) = ran (A −zI) = (A −zI)D ⊆H. If the operator A is
closed these subspaces are closed. For a regular point z the operator A −zI has an
inverse operator (A −zI)−1 : HA(z)→D which is bounded in norm by
1
δ(z). After
these preparations we can easily decide when a regular point belongs to the resolvent
set. This is the case if, and only if, HA(z) = H. In the generality in which we have
discussed this problem thus far one cannot say much. However, for densely deﬁned
closed operators and then for self-adjoint operators we know how to proceed.
Recall that a densely deﬁned operator A has a unique adjoint A∗and that the
relation (ran (A −zI))⊥= N(A∗−zI) holds; therefore
ρr(A) ⊆ρ(A) ⇔N(A∗−zI) = {0}.
For a self-adjoint operator this criterion is easily veriﬁed. Suppose z ∈ρr(A) and
x ∈N(A∗−zI), i.e., A∗x = zx. Since A is self-adjoint it follows that x ∈D and
Ax = zx and therefore z⟨x, x⟩= ⟨x, Ax⟩= ⟨Ax, x⟩= z⟨x, x⟩. We conclude that
either x = 0 or z = z. The latter case implies (A −zI)x = 0 which contradicts the
assumption that z is a regular point, hence x = 0. This nearly proves

24.1
Basic Concepts and Results
347
Theorem 24.1
For a self-adjoint operator A in a complex Hilbert space H the
resolvent set ρ(A) and the set ρr(A) of regular points coincide and the spectrum
σ(A) is a nonempty closed subset of R.
Proof As the complement of the open resolvent set, the spectrum σ(A) is closed. For
the proof of σ(A) ⊆R we use the identity ρ(A) = ρr(A). For all points z = α + iβ
one has for all x ∈D,
∥(A −zI)∥x2 = ∥(A −αI)x + i βx2∥= ∥(A −αI)x∥2 + ∥βx∥2 ≥|β|2 ∥x∥2,
and this lower bound shows that all points z = α + iβ with β ̸= 0 are regular points.
Here we prove that the spectrum of a bounded operator is not empty. The general
case of an unbounded self-adjoint operator follows easily from the spectral theorem
which is discussed in a later chapter (see Theorem 27.5).
Suppose that the spectrum σ(A) of the bounded self-adjoint operator is empty.
Then the resolvent RA is an entire analytic function with values in B(H) (see
Corollary 24.1). For all points z ∈C, |z| > 2 ∥A∥, the resolvent is bounded:
RA(z) = −z−1(I −1
z A)−1 = −1
z
∞
n=0 ( A
z )n implies the bound
∥RA(z)∥≤
∞

n=0
∥A∥n |z|−n−1 =
1
|z| −∥A∥≤
1
∥A∥.
As an analytic function, RA is bounded on the compact set z ∈C : |z| ≤2 ∥A∥and
hence RA is a bounded entire function. The theorem of Liouville (Corollary 9.3)
implies that RA is constant. This contradiction implies that the spectrum is not
empty.
2
Since for a self-adjoint operator the resolvent set and the set of regular points are
the same, a real number belongs to the spectrum if, and only if, it is not a regular
point. Taking the deﬁnition of a regular point into account, points of the spectrum
can be characterized in the following way.
Theorem 24.2 (Weyl’s criterion). A real number λ belongs to the spectrum of a self-
adjoint operator A in a complex Hilbert space H if, and only if, there is a sequence
(xn)n∈N ⊂D(A) such that ∥xn∥= 1 for all n ∈N and
lim
n→∞∥(A −λI)xn∥= 0.
In the following section we study several explicit examples. These examples show
that in inﬁnite dimensional Hilbert spaces the spectrum does not only consist of
eigenvalues, but contains various other parts which have no analogue in the ﬁnite
dimensional case. The following deﬁnition gives a ﬁrst division of the spectrum into
the set of all eigenvalues and some remainder. Later, with the help of the spectral
theorem, a ﬁner division of the spectrum will be introduced and investigated.

348
24
Elements of Spectral Theory
Deﬁnition 24.3 Let A be a closed operator in a complex Hilbert space H and σ(A)
its spectrum. The point spectrum σp(A) of A is the set of all eigenvalues, i.e.,
σp(A) = {λ ∈σ(A) : N(A −λI) ̸= {0}}.
The complement σ(A)\σp(A) of the point spectrum is the continuous spectrum
σc(A). Finally, the discrete spectrum σd(A) of A is the set of all eigenvalues λ of
ﬁnite multiplicity which are isolated in σ(A), i.e.,
σd(A) =

λ ∈σp(A) : dim N(A −λI) < ∞, λ isolated in σ(A)

.
As in the ﬁnite dimensional case the eigenspaces to different eigenvalues of a self-
adjoint operator are orthogonal.
Corollary 24.2
Suppose A is a self-adjoint operator in a complex Hilbert space
and λj ∈σp(A), j = 1, 2 are two eigenvalues. If λ1 ̸= λ2, then the corresponding
eigenspaces are orthogonal: N(A −λ1I) ⊥N(A −λ2).
Proof
If Aψj = λjψj, then (λ1 −λ2)⟨ψ1, ψ2⟩= ⟨λ1ψ1, ψ2⟩−⟨ψ1, λ2ψ2⟩=
⟨Aψ1, ψ2⟩−⟨ψ1, Aψ2⟩= 0, hence ⟨ψ1, ψ2⟩= 0 since λ1 ̸= λ2.
2
We conclude this section with the observation that the spectrum of linear operators
does not change under unitary transformations, more precisely:
Proposition 24.1
If Aj is a closed operator in the complex Hilbert space Hj,
j = 1, 2, and if there is a unitary map U : H1→H2 such that D(A2) = UD(A1)
and A2 = UA1U −1, then both operators have the same spectrum: σ(A1) = σ(A2).
Proof See Exercises.
2
24.2
The Spectrum of Special Operators
In general, it is quite a difﬁcult problem to determine the spectrum of a closed or
self-adjoint operator. The best one can do typically is to give some estimate in those
cases where more information about the operator is available. In special cases, for
instance in cases of self-adjoint realizations of certain differential operators, one can
determine the spectrum exactly. We consider a few examples.
Proposition 24.2 The spectrum σ(U) of a unitary operator U on a complex Hilbert
space H is contained in the unit circle {z ∈C : |z| = 1}.
Proof If |z| < 1, then we write U −zI = U(I −zU −1). Since the operator zU −1
has a norm smaller than 1, the Neumann series can be used to ﬁnd the bounded
inverse of U −zI. Similarly, for |z| > 1, we write U −zI = −z(I −1
z U). This time
the Neumann series for the operator 1
z U allows us to calculate the inverse. Thus all
points z ∈C with |z| < 1 or |z| > 1 belong to the resolvent set and therefore the
spectrum is contained in the unit circle.
2

24.2
The Spectrum of Special Operators
349
It is somewhat surprising that the spectrum of the Fourier Transformation F2 on
the Hilbert space L2(R) can be calculated.
Proposition 24.3
The spectrum of the Fourier transformation F2 on the Hilbert
space L2(R) is σ(F2) = {1, i , −1, −i }.
Proof
The system of Hermite functions {hn : n = 0, 1, 2, . . . } is an orthonormal
basis of L2(R) (see Eq. (17.1)). In the Exercises we show by induction with respect
to the order n that
F2(hn) = ( −i )nhn,
n = 0, 1, 2, . . .
holds. Thus we know a complete set of orthonormal eigenfunctions together with the
corresponding eigenvalues. Therefore we can represent the Fourier transformation
as
F2 =
∞

n=0
( −i )nPn
where Pn is the projector onto the subspace generated by the eigenfunction hn. In the
following example we determine the spectrum of operators which are represented
as a series of projectors onto an orthonormal basis with any arbitrary coefﬁcients sn.
One ﬁnds that the spectrum of such an operator is the closure of the set of coefﬁcients
which in the present case is {1, i , −1, −i }.
2
Example 24.1
1. en : n ∈N is an orthonormal basis of the complex Hilbert space H and {sn : n ∈
N} ⊂C is some sequence of complex numbers. Introduce the set
D =

x ∈H :
∞

n=1
|sn|2|⟨en, x⟩|2 < ∞

and for x ∈D deﬁne
Ax =
∞

n=1
sn⟨en, x⟩en.
(24.9)
In the Exercises we show that A is a densely deﬁned closed linear operator with
adjoint
A∗y =
∞

n=1
sn⟨en, y⟩en
∀y ∈D.
We claim:
σ(A) = {sn : n ∈N}.
If z ∈C and z ̸∈{sn : n ∈N}, then δ(z) = inf{|sn −z| : n ∈N} > 0 and thus for
all x ∈D,
∥(A −zI)x∥2 =
∞

n=1
|sn −z|2|⟨en, x⟩|2 ≥δ(z)2
∞

n=1
|⟨en, x⟩|2 = δ(z)2 ∥x∥2.

350
24
Elements of Spectral Theory
Thus these points are regular points of the operator A. They are actually points
of the resolvent set since one shows that the inverse of A −zI is given by
(A −zI)−1x =
∞

n=1
1
sn −z⟨en, x⟩en
and this operator maps H into D. We conclude ρ(A) = C →{sn : n ∈N} and
this proves our claim.
2. For a continuous function g : Rn→C deﬁne the domain
Dg =

f ∈L2(Rn) : gf ∈L2(Rn)

.
As we have shown earlier the operator Mg of multiplication with the function g
is a densely deﬁned closed linear operator in the Hilbert space H = L2(Rn) and
its adjoint is the operator of multiplication with the complex conjugate function
g. We claim that the spectrum of the operator Mg is the closure of the range of
the function g,
σ(Mg) = ran g
where ran g = {λ ∈C : λ = g(x) for some x ∈Rn}. Since C\ran g is open,
every point z ∈C →ran g has a positive distance from ran g, i.e.,
δ(z) = inf

|g(x) −z| : x ∈Rn
> 0.
Therefore x #→(g(x) −z)−1 is a continuous function on Rn which is bounded by
1
δ(z). It follows that (Mg −zI)−1, deﬁned by (Mg −zI)−1f =
f
g−z is a bounded
linear operator on L2(Rn). Since the integral

Rn |
g(x)
g(x) −zf (x)|2 d x
is ﬁnite for all f ∈L2(Rn) the operator (Mg −zI)−1 maps L2(Rn) into the domain
Dg of Mg. This proves that ρ(Mg) = C\ran g and we conclude.
In the case that the function g is real valued and not constant this is an example of
an operator whose spectrum contains open intervals, i.e., the continuous spectrum
is not empty in this case. In this case the operator Mg has no eigenvalues (see
Exercises).
24.3
Comments on Spectral Properties of Linear Operators
In Deﬁnition 24.3 the complement σc(A) = σ(A)\σp(A) of the point spectrum
has been called the continuous spectrum of A. This terminology is quite unfortu-
nate since it is often rather misleading: The continuous spectrum can be a discrete
set. To see this, consider Example 24.2.1 and choose there the sequence sn = 1
n.

24.3
Comments on Spectral Properties of Linear Operators
351
Then the spectrum of the operator A deﬁned through this sequence is σ(A) =
 1
n : n ∈N

=

1, 1
2, 1
3, . . ., 0

while the point spectrum is σp(A) =

1, 1
2, 1
3, . . .

,
hence the continuous spectrum is just one point: σc(A) = σ(A)\σp(A) = {0}.
It is very important to be aware of the fact that the spectrum of an operator depends
on its domain in a very sensitive way. To illustrate this point we are going to construct
two unbounded linear operators which consist of the same rule of assignment but on
different domains. The resulting operators have completely different spectra.
In the Hilbert space H = L2([0, 1]) introduce two dense linear subspaces
D1 =

f ∈L2([0, 1]) : f is absolutely continuous, f ′ ∈L2([0, 1])

,
D2 = {f ∈D1 : f (0) = 0}.
Denote by Pj the operator of differentiation i
d
d x on the domain Dj, j = 1, 2. Both
operators P1, P2 are closed.
For every λ ∈C the exponential function eλ, eλ(x) = e −i λx, belongs to the
domain D1 and clearly (P1 −λI)eλ = 0. We conclude that σ(P1) = C.
Elementary calculations show that the operator Rλ deﬁned by
(Rλf )(x) = i
 x
0
e −i λ(x−y)f (y) dy
∀f ∈L2([0, 1])
has the following properties: Rλ maps L2([0, 1]) into D2 and
(λI −P2)Rλ = I,
Rλ(λI −P2) = I|D2.
Clearly Rλ is a bounded operator on L2([0, 1]), hence Rλ ∈B(L2([0, 1]), D2). This
is true for every λ ∈C and we conclude that ρ(P2) = C, hence σ(P2) = ∅.
Without proof we mention an interesting result about the spectrum of a closed
symmetric operator. The spectrum determines whether such an operator is self-
adjoint or not!
Theorem 24.3
A closed symmetric operator A in a complex Hilbert space H is
self-adjoint if, and only if, its spectrum σ(A) is a subset of R.
This result is certainly another strong motivation why in quantum mechanics ob-
servables should be represented by self-adjoint operators and not only by symmetric
operators, since in quantum mechanics the expectation values of observables have
to be real.
One can also show that the spectrum of an essentially self-adjoint operator is
contained in R. The converse of these results reads: If the spectrum σ(A) of a sym-
metric operator A in a complex Hilbert space H is contained in R, then the operator
is either self-adjoint or essentially self-adjoint. This implies that the spectrum σ(A)
of a symmetric but neither self-adjoint nor essentially self-adjoint operator contains
complex points.

352
24
Elements of Spectral Theory
But clearly there are nonsymmetric operators with purely real spectrum. For
instance, in the complex Hilbert space H = C2 take the real matrix
A =
$
a c
0 b
%
a, b ∈R, c ̸= 0.
Obviously, σ(A) = {a, b}.
When we stated and proved earlier that the spectrum of a bounded linear operator
in a complex Hilbert space is not empty, it was essential that we considered a Hilbert
space over the ﬁeld of complex numbers. A simple example of a bounded operator
in a real Hilbert space with empty spectrum is
H = R2,
A =
$
0
a2
−b2 0
%
,
a, b ∈R, ab ̸= 0.
The proof is obvious.
Finally, we comment on the possibility to deﬁne a substitute for the determinant
for linear operators in an inﬁnite dimensional space. If the self-adjoint bounded linear
operator A in a complex Hilbert space H has suitable spectral properties, then indeed
a kind of determinant function det A can be deﬁned. Suppose A can be written as
A = I + R with a self-adjoint trace class operator R. Then one deﬁnes
det A = e Tr log A.
The book [1] contains a fairly detailed discussion of this problem.
24.4
Exercises
1. Prove Proposition 24.1.
2. Consider the Hermite functions hn, n = 0, 1, 2 . . . . Use the recursion relation
(17.2) for the Hermite polynomials to deduce the recursion relation
hn+1(x) = (2n + 2)−1/2[xhn(x) −h′
n(x)]
for the Hermite functions. Then prove by induction: F2hn = ( −i )nhn .
3. Prove that the operator deﬁned by Eq. (24.9) is densely deﬁned and closed and
determine its adjoint.
4. Show: The self-adjoint operator of multiplication with a real-valued continuous
function which is not constant has no eigenvalues.
5. Prove the details in the examples of Sect. 24.3 on spectral properties of linear
operators.

Reference
353
Reference
1. Reed M, Simon B. Analysis of operators. In: Methods of modern mathematical physics. Vol. 4.
San Diego: Academic; 1978.

Chapter 25
Compact Operators
25.1
Basic Theory
In the introduction to the theory of Hilbert spaces, we mentioned that a substantial
part of this theory has its origin in D. Hilbert’s research on the problem to extend the
well-known theory of eigenvalues of matrices to the case of “inﬁnite dimensional
matrices” or linear operators in an inﬁnite dimensional space. A certain limit (to be
speciﬁed later) of ﬁnite dimensional matrices gives a class of operators, which are
called compact. Accordingly, the early results in the theory of bounded operators on
inﬁnite dimensional Hilbert spaces were mainly concerned with this class of compact
operators, which were typically investigated in separable spaces. We take a slightly
more general approach.
Deﬁnition 25.1
Let H and K be two Hilbert spaces over the ﬁeld K. A bounded
linear operator K : H→K is called compact (or completely continuous), if and
only if, it maps every bounded set in H onto a precompact set of K (this means that
the closure of the image of a bounded set is compact), i.e., if and only if, for every
bounded sequence (en)n∈N ⊂H the sequence of images (Ken)n∈N ⊂K contains a
convergent subsequence.
In particular, in concrete problems, the following characterization of compact
operators is very helpful.
Theorem 25.1 (Characterization of Compact Operators) Let H and K be two
Hilbert spaces over the ﬁeld K and A : H→K a bounded linear operator. A is
compact if it satisﬁes one (and thus all) of the following equivalent conditions.
a) The image of the open unit ball B1(0) ⊂H under A is precompact in K.
b) The image of every bounded set B ⊂H under A is precompact in K.
c) For every bounded sequence (xn)n∈N ⊂H the sequence of images (Axn)n∈N in K
contains a convergent subsequence.
d) The operator A maps weakly convergent sequences in H into norm convergent
sequences in K.
© Springer International Publishing Switzerland 2015
355
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_25

356
25
Compact Operators
Proof The proof proceeds according the following steps: a) ⇒b) ⇒c) ⇒d) ⇒a).
Assume a), that is assume A(B1(0)) is precompact in K and consider any bounded
set B ⊂H. It follows that B is contained in some ball Br(0) = rB1(0) for suitable
r > 0, hence A(B) ⊆A(rB1(0)) = rA(B1(0)), thus A(B) is precompact and b)
follows.
Next assume b) and recall the Bolzano–Weierstrass result that a metric space is
compact, if and only if, every bounded sequence contains a convergent subsequence.
Hence statement c) holds.
Now assume c) and consider a sequence (xn)n∈N ⊂H, which converges weakly
to x ∈H. For any z ∈K we ﬁnd ⟨z, Axn⟩K = ⟨A∗z, xn⟩H→⟨A ∗z, x⟩H = ⟨z, Az⟩K
as n→∞, i.e., the sequence of images converges weakly to the image of the weak
limit.
Suppose that the sequence (yn = Axn)n∈N does not converge in norm to y = Ax.
Then there are ε > 0 and a subsequence (Axn(j))j∈N such that ∥y −yn(j)∥K ≥ε
for all j ∈N. Since (xn(j))j∈N is a bounded sequence there is a subsequence (xn(ji))i∈N
for which (yn(ji) = Axn(ji))i∈N converges in norm, because c) is assumed. The limit of
this sequence is y = Ax since the weak limit of this sequence is y, but this is a contra-
diction to the construction of the subsequence (yn(j))j∈N and thus limn→∞Axn = Ax
in norm. This proves part d).
Finallyassumed). Takeanysequence(xn)n∈N ⊂B1(0). ByTheorem19.3thereisa
weakly convergent subsequence (xn(j))j∈N. According to assumption d) the sequence
(Axn(j))j∈N ⊂A(B1(0)) of images converges in norm. The Theorem of Bolzano–
Weierstrass implies that A(B1(0)) is precompact. Thus, we conclude.
2
Deﬁnition 25.2 A bounded linear operator A : H→K with ﬁnite dimensional range
is called an operator of ﬁnite rank.
The general form of an operator A of ﬁnite rank is easily determined. The result
is (see Exercise)
Ax =
N

j=1
⟨fj, x⟩Hej
∀x ∈H,
where {e1, . . . , eN} is some ﬁnite orthonormal system in K and f1, . . . , fN are some
vectors in H. If now a sequence (xn)n∈N ⊂H converges weakly to x ∈H then, for
j = 1, . . . , N, ⟨fj, xn⟩H→⟨fj, x⟩H and thus, as n→∞,
Axn =
N

j=1
⟨fj, xn⟩Hej→
N

j=1
⟨fj, x⟩Hej = Ax.
We conclude that operators of ﬁnite rank are compact.
The announced approximation of compact operators by matrices takes the
following precise form.
Theorem 25.2
In a separable Hilbert space H every compact operator A is the
norm limit of a sequence of operators of ﬁnite rank.

25.1
Basic Theory
357
Proof Let {ej : j ∈N} be an orthonormal basis of H and introduce the projectors Pn
onto the subspace [e1, . . . , en] spanned by the ﬁrst n basis vectors. Proposition 23.1
implies that the sequence of projectors Pn converges strongly to the identity I. Deﬁne
dn = sup

∥AP ⊥
n x∥: ∥x∥= 1

= sup {|Ay| : y ∈Sn} ,
where Sn =

y ∈[e1, . . . , en]⊥: ∥y∥= 1

. Clearly (dn)n∈N is a monotone decreas-
ing sequence of positive numbers. Thus, this sequence has a limit d ≥0. For every
n ∈N there is yn ∈Sn such that ∥Ayn∥≥
dn
2 . yn ∈Sn means: ∥yn∥= 1 and
yn = P ⊥
n yn, hence ⟨x, yn⟩= ⟨P ⊥
n x, yn⟩→0 as n→∞since P ⊥
n x→0 in H, for every
x ∈H, i.e., the sequence (yn)n∈N converges weakly to 0. Compactness of A implies
that ∥Ayn∥→0 and thus d = 0. Finally observe
dn = ∥A −APn∥
∀n ∈N,
hence the compact operator A is the norm limit of the sequence of operators APn,
APnx =
n

j=1
⟨ej, x⟩Aej
∀x ∈H,
which are of ﬁnite rank.
2
The set of compact operators is stable under uniform limits:
Theorem 25.3 Suppose H and K are Hilbert spaces over the ﬁeld K and An:H→K,
n ∈N, are compact operators, and suppose that A is the norm limit of this sequence.
Then A is compact.
Proof Take any sequence (xj)j∈N in H which converges weakly to x ∈H. Such a
sequence is strongly bounded: There is 0 ≤C < ∞such that
--xj
--
H , ∥x∥H ≤C
for all j ∈N. Since A is the norm limit of the compact operators An, given ε > 0
there is n0 ∈N such that for all n ≥n0 we know ∥A −An∥≤ε/4C. Fix n ≥n0
and estimate for j ∈N
--Ax −Axj
--
K ≤
--(A −An)(x −xj)
--
K +
--Anx −Anxj
--
K
≤∥A −An∥
--x −xj
--
H +
--Anx −Anxj
--
K
≤ε
4C 2C +
--Anx −Anxj
--
K = ε/2 +
--Anx −Anxj
--
K .
Since An is compact, there is j0 ∈N such that for all j
≥j0 we know
--Anx −Anxj
--
K < ε/2 and therefore for these j ≥j0 one has
--Ax −Axj
--
K < ε;
thus A maps weakly convergent sequences to norm convergent sequences and we
conclude by Theorem 25.1.
2
Some important properties of compact operators are collected in
Theorem 25.4
For a Hilbert space H denote the set of all compact operators
A : H→H by Bc(H). Then
a) Bc(H) is a linear subspace of B(H)
b) A ∈B(H) is compact, if and only if, its adjoint A∗is compact

358
25
Compact Operators
c) A ∈Bc(H), λ ∈K, λ ̸= 0, ⇒dim N(A −λI) < ∞, i.e., the eigenspaces of
compact operators for eigenvalues different from zero are ﬁnite dimensional
d) Bc(H) is a closed subalgebra of the C∗-algebra B(H) and thus itself a C∗-algebra
e) Bc(H) is a closed ideal in B(H), i.e.,
B(H) · Bc(H) ⊂Bc(H)
and
Bc(H) · B(H) ⊂Bc(H).
Proof With the exception of part b) the proofs are relatively simple. Here we only
prove part c), the other parts are done as an exercise.
Suppose λ ̸= 0 is an eigenvalue of A. Then we have I|N(A−λI) = 1
λA|N(A−λI).
Thus, theidentityoperatoronthesubspaceN(A−λI)iscompact, hencethissubspace
must have a ﬁnite dimension.
2
As a conclusion of this section a simple example of a compact operator in an
inﬁnite dimensional Hilbert space is discussed.
Suppose that

ej : j ∈N

is an orthonormal basis of the Hilbert space H. Deﬁne
a linear operator by continuous linear extension of Aej = 1
j ej, j ∈N, i.e., deﬁne
Ax =
∞

j=1
aj
j ej,
x =
∞

j=1
ajej,
∞

j=1
|aj|2 = ∥x∥2.
It follows that the open unit ball B1(0) ⊂H is mapped by A onto a subset, which
is isomorphic to a subset of the Hilbert cube W (under the standard isomorphism
between a separable Hilbert space over K and ℓ2(K)),
W =
+
(vn)n∈N ∈ℓ2(K) : |vn| ≤1
n, ∀n ∈N
,
.
The following lemma shows compactness of the Hilbert cube, hence A is a compact
operator.
Lemma 25.1 The Hilbert cube W is a compact subset of the Hilbert space ℓ2(K).
Proof
In an inﬁnite dimensional Hilbert space the closed bounded sets are not
compact (in the norm topology) but always weakly compact (see Theorem 19.7).
Compactness of W follows from the observation that the strong and the weak topol-
ogy coincide on W. For this it sufﬁces to show that every weakly convergent sequence
(xn)n∈N ⊂W with weak limit x ∈W also converges strongly to x. Given ε > 0 there
is p ∈N such that ∞
j=p+1
1
j2 < ε. Because of weak convergence of the sequence
we can now ﬁnd N ∈N such that p
j=1 |xn,j −xj|2 < ε for all n ≥N (we use the
notation xn = (xn,j)j∈N). This gives ∞
j=1 |xn,j −xj|2 < 3ε for all n ≥N and thus
x is the strong limit of the sequence (xn)n∈N ⊂W.
2

25.2
Spectral Theory
359
25.2
Spectral Theory
Compact operators are deﬁned as linear operators with very strong continuity require-
ments. They are those continuous operators which map weakly convergent sequences
into strongly convergent ones (see Theorem 25.1). As a consequence their generic
form is relatively simple and their spectrum consists only of eigenvalues. These re-
sults and some applications are discussed in this chapter. Compact operators were
studied intensively in the early period of Hilbert space theory (1904–1940).
25.2.1
The Results of Riesz and Schauder
The key to the spectral theory of self-adjoint compact operators A is a lemma which
states that either ∥A∥or −∥A∥is an eigenvalue of A. This lemma actually solves
the extremal problem: Find the maximum of the function x #→⟨x, Ax⟩on the set
S1 = {x ∈H : ∥x∥= 1}. In the last part of this book a general theory for such
extremal problems under constraints (and many other similar problems) will be
presented. Here, however, we present a direct proof which is independent of these
results.
Lemma 25.2
Suppose that A is a compact self-adjoint operator in a complex
Hilbert space H. Then at least one of the two numbers ± |A| is an eigenvalue of
A.
Proof By deﬁnition the norm of the operator can be calculated as
∥A∥= sup {|⟨x, Ax⟩| : ∥x∥= 1}.
Thus, there is a sequence (xn)n∈N in S1 such that |A| = limn→∞|⟨xn, Axn⟩|. We can
assume that limn→∞⟨xn, Axn⟩exists, otherwise we would take a subsequence. Call
this limit a. Then we know |a| = ∥A∥. Since A is self-adjoint this limit is real. Since
the closed unit ball of H is weakly compact (Theorem 19.7) there is a subsequence
(xn(j))j∈N, which converges weakly and for which the sequence of images (Axn(j))j∈N
converges strongly to x, respectively to y. The estimate
0 ≤
--Axn(j) −axn(j)
--2 =
--Axn(j)
--2 −2a⟨xn(j), Axn(j)⟩+ a2 ≤2a2 −2a⟨xn(j), Axn(j)⟩
shows that the sequence (Axn(j) −axn(j))j∈N converges strongly to 0. Since we
know strong convergence of the sequence (Axn(j))j∈N we deduce that the sequence
(axn(j))j∈N converges not only weakly but strongly to ax, hence ∥x∥= 1. Continuity
of A implies limj→∞Axn(j) = Ax and thus Ax = ax. Hence, a is an eigenvalue of
A.
2
Repeated application of this lemma determines the spectrum of a compact self-
adjoint operator.
Theorem 25.5 (Riesz–Schauder Theorem) Suppose A is a self-adjoint compact
operator on a complex Hilbert space. Then

360
25
Compact Operators
a) A has a sequence of real eigenvalues λj ̸= 0 which can be enumerated in such a
way that |λ1| ≥|λ2| ≥|λ3| ≥· · · .
b) If there are inﬁnitely many eigenvalues, then limj→∞λj = 0, and the only
accumulation point of the set of eigenvalues is the point 0.
c) The multiplicity of every eigenvalue λj ̸= 0 is ﬁnite.
d) If ej is the eigenvector for the eigenvalue λj, then every vector in the range of A
has the representation
Ax =
∞

j=1
λj⟨ej, x⟩ej
e) σ(A) = {λ1, λ2, . . . , 0} but 0 is not necessarily an eigenvalue of A.
Proof
Lemma 25.2 gives the existence of an eigenvalue λ1 with |λ1| = ∥A∥and
a normalized eigenvector e1. Introduce the orthogonal complement H1 = {e1}⊥of
this eigenvector. The operator A maps the space H1 into itself: For x ∈H1 we ﬁnd
⟨e1, Ax⟩= ⟨Ae1, x⟩= λ1⟨e1, x⟩= 0, hence Ax ∈H1. The restriction of the inner
product of H to H1 makes this space a Hilbert space and the restriction A1 = A|H1
of A to this Hilbert space is again a self-adjoint compact operator. Clearly, its norm
is bounded by that of A: ∥A1∥≤∥A∥.
Now, apply Lemma 25.2 to the operator A1 on the Hilbert space H1 to get an
eigenvalue λ2 and a normalized eigenvector e2 ∈H1 such that |λ2| = ∥A1∥≤
∥A∥= |λ1|.
Next, introduce the subspace H2 = {e1, e2}⊥. Again, the operator A leaves this
subspace invariant and thus the restriction A2 = A|H2 is a self-adjoint compact
operator in the Hilbert space H2.
Since we assume that the Hilbert space H is inﬁnite dimensional, this argument
can be iterated inﬁnitely often and thus leads to a sequence of eigenvectors ej and
of eigenvalues λj with |λj+1| ≤|λj|. If there is an r > 0 such that r ≤|λj|, then
the sequence of vectors yj = ej/λj is bounded, and hence there is a weakly con-
vergent subsequence yj(k). Compactness of A implies convergence of the sequence
of images Ayj(k) = ej(k), a contradiction since for an orthonormal system one has
--ej(k) −ej(m)
-- =
√
2 for k ̸= m. This proves parts a) and b).
To prove c) observe that on the eigenspace Ej = N(A−λjI) the identity operator
I|Ej is equal to the compact operator
1
λh A|Ej and thus this space has to be ﬁnite
dimensional.
The projector onto the subspace [e1, . . . , en] spanned by the ﬁrst n eigenvectors
is Pnx = n
j=1⟨ej, x⟩ej. Then I −Pn is the projector onto [e1, . . . , en]⊥= Hn+1
and hence ∥A(I −Pn)x∥≤|λn+1| ∥(I −Pn)x∥≤|λn+1| ∥x∥→0 as n→∞. Since
APnx = n
j=1 λj⟨ej, x⟩ej part d) follows.
Finally, Example 24.2.1 gives immediately that the spectrum of A is σ(A) =

λj : j ∈N

= {λ1, λ2, . . . , 0} according to part b).
2
Corollary 25.1 (Hilbert–Schmidt Theorem) The orthonormal system of eigen-
functions ej of a compact self-adjoint operator A in a complex Hilbert space is
complete, if and only if, A has a trivial null space: N(A) = {0}.

25.2
Spectral Theory
361
Proof Because of part d) of Theorem 25.5 the system of eigenfunctions is complete,
if and only if, the closure of the range of A is the whole Hilbert space: ran A = H.
Taking the orthogonal decomposition H = N(A) ⊕N(A)⊥and N(A) = N(A∗) =
(ran A)⊥into account we conclude.
2
25.2.2
The Fredholm Alternative
Given a compact self-adjointoperator AonacomplexHilbertspace H andanelement
g ∈H, consider the equation
f −μAf = (I −μA)f = g.
(25.1)
Depending on the parameter μ ∈C one wants to ﬁnd a solution f ∈H. Our starting
point is the important
Lemma 25.3 (Lemma of Riesz) If A is a compact operator on the Hilbert space
H and μ ̸= 0 a complex number, then the range of I −μA is closed in H.
Proof Since a scalar multiple of a compact operator is again compact we can and
will assume μ = 1. As an abbreviation we introduce the operator B = I −A and
have to show that its range is closed. Given an element f ̸= 0 in the closure of the
range of B, there is a sequence (gn)n∈N in H such that f = limn→∞Bgn. According
to the decomposition H = N(B)⊕N(B)⊥we can and will assume that gn ∈N(B)⊥
and gn ̸= 0 for all n ∈N.
Suppose that the sequence (gn)n∈N is bounded in H. Then there is a subsequence
which converges weakly to some element g ∈H. We denote this subsequence in the
same way as the original one. Compactness of A implies that the sequence (Agn)n∈N
converges strongly to some h ∈H. Weak convergence of the sequence (gn)n∈N
ensures that h = Ag (⟨u, Agn⟩= ⟨A∗u, gn⟩→⟨A∗u, g⟩= ⟨u, Ag⟩for all u ∈H
implies h = Ag). Since Bgn→f as n→∞it follows that gn = Bgn+Agn→f +Ag.
Thus, (gn)n∈N converges strongly to g and the identity g = f +Ag holds. This proves
f ∈ran (I −A).
Now consider the case that the sequence (gn)n∈N is not bounded. By taking a
subsequence which we denote in the same way, we can assume limn→∞∥gn∥= ∞.
Form the auxiliary sequence of elements un =
1
∥gn∥gn. This sequence is certainly
bounded and thus contains a weakly convergent subsequence, which we denote again
in the same way. Denote the weak limit of this sequence by u. Since A is compact we
conclude that Aun→Au as n→∞. Now recall Bgn→f and ∥gn∥→∞as n→∞. We
deduce Bun =
1
∥gn∥Bgn→0 as n→∞, and therefore, the sequence un = Bun + Aun
converges strongly. Since, the weak limit of the sequence is u it converges strongly
to u. On the other side, Bun + Aun converges to Au as we have shown. We deduce
u = Au, i.e., u ∈N(B). By construction, gn ∈N(B)⊥, hence un ∈N(B)⊥, and this
implies u ∈N(B)⊥since N(B)⊥is closed. This shows u ∈N(B) ∩N(B)⊥= {0},
and we conclude that un→0 as n→∞. This contradicts ∥un∥= 1 for all n ∈N.

362
25
Compact Operators
Thus, the case of an unbounded sequence (gn)n∈N does not occur. This completes the
proof.
2
Now we can formulate and prove
Theorem 25.6 (Fredholm Alternative) Suppose A is a self-adjoint compact oper-
ator on a complex Hilbert space H, g a given element in H and μ a complex number.
Then either μ−1 ̸∈σ(A) and the equation
(I −μA)f = g
has the unique solution
f = (I −μA)−1g
or μ−1 ∈σ(A) and the equation (I −μA)f = g has a solution, if and only if,
g ∈ran (I −μA). In this case, given a special solution f0, the general solution is
of the form f = f0 + u, with u ∈N(I −μA), and thus the set of all solutions is a
ﬁnite dimensional afﬁne subspace of H.
Proof Lemma 25.3 gives
ran (I −μA) = N(I −(μA)∗)⊥= N(I −μA)⊥.
If μ−1 ̸∈σ(A), then μ−1 ̸∈σ(A) (σ(A) ⊂R) and thus ran (I −μA) = N(I −
μA)⊥= {0}⊥= H and the unique solution is f = (I −μA)−1g.
Now consider the case μ−1 ∈σ(A). Then N(I −μA) ̸= {0}. 1
μ is an eigenvalue
of ﬁnite multiplicity (Theorem 25.5, part c)). In this case, ran (I −μA) is a proper
subspace of H and the equation (I −μA)f = g has a solution, if and only if,
g ∈ran (I −μA). Since the equation is linear it is clear that any solution f differs
from a special solution f0 by an element u in the null space of the operator (I −μA),
and we conclude.
2
Remark 25.1
1. The Fredholm alternative states that the eigenvalue problem for a compact self-
adjoint operator in an inﬁnite dimensional Hilbert space and that of self-adjoint
operators in a ﬁnite dimensional Hilbert space have the same type of solutions.
According to this theorem one has the following alternative: Either the equation
Af = λf has a solution, i.e., λ ∈σp(A), or (λI −A)−1 exists, i.e., λ ∈ρ(A), in
other words, σ(A)\ {0} = σp(A) = σd(A). Note that for self-adjoint operators,
which are not compact, this alternative does not hold. An example is discussed
in the Exercises.
2. In applications one encounters the ﬁrst case rather frequently. Given r > 0
consider those μ ∈C with |μ| < r. Then there are only a ﬁnite number of
complex numbers μ for which one cannot have existence and uniqueness of the
solution.
3. Every complex N ×N matrix has at least one eigenvalue (fundamental theorem of
algebra). The corresponding statement does not hold in the inﬁnite dimensional
case. There are compact operators which are not self-adjoint and which have no
eigenvalues. The Exercises offer an example.

Reference
363
25.3
Exercises
1. Prove: For noncompact self-adjoint operators the Fredholm alternative does not
hold: In L2(R) the equation Af = f has no solution and (I −A)−1 does not
exist for the operator (Af )(x) = xf (x), for all f ∈D(A) where D(A) = {f ∈
L2(R) : xf ∈L2(R)}.
2. On the Hilbert space H = ℓ2(C) consider the operator A deﬁned by
A(x1, x2, x3, . . .) = (0, x1, x2
2 , . . . , xn
n , . . . , ).
Show that A is compact and not self-adjoint and has no eigenvalues.
3. This problem is about the historical origin of the Fredholm alternative. It was
developed in the study of integral equations. We consider the Fredholm integral
equation of second kind:
f (x) −μ

k(x, y)f (y) dy = g(x).
Show: For k ∈L2(Rn × Rn) with k(x, y) = k(y, x) the operator A deﬁned
by (Af )(x) =

k(x, y)f (y) d y is compact and self-adjoint and the Fredholm
alternative applies.
As a concrete case of the above integral equation consider the case n = 1 and
k = G, where G is the Green’s function of Sturm–Liouville problem: On the
interval [a, b] ﬁnd the solution of the following second-order linear differential
equations with the given boundary conditions:
y′′(x) −q(x)y′(x) + μy(x) = f (x),
h1y(a) + k1y′(a) = 0,
h2y(b) + k2y′(b) = 0,
with hj, kj ∈R, and where the hj and kj are not simultaneously equal to zero.
Every solution y of the Sturm–Liouville problem is a solution of the Fredholm
integral equation
y(x) −μ
 b
a
G(x, z)y(z) d z = g(x),
where g(x) = −
 b
a G(x, z)f (z) d z and conversely.
Hints: See Sect. 20 of [1] for further details.
Reference
1. Vladimirov VS. Equations of mathematical physics. Pure and applied mathematics. Vol. 3. New
York: Dekker; 1971.

Chapter 26
Hilbert–Schmidt and Trace Class Operators
26.1
Basic Theory
Since they are closely related, we discuss Hilbert–Schmidt and trace class operators
together.
Deﬁnition 26.1 A bounded linear operator A on a separable Hilbert space H is
called a Hilbert–Schmidt operator respectively a trace class operator if, and only
if, for some orthonormal basis {en : n ∈N} the sum
∞

n=1
∥Aen∥2 =
∞

n=1
⟨en, A∗Aen⟩,
respectively, the sum
∞

n=1
⟨en, |A|en⟩=
∞

n=1
--|A|1/2en
--2
is ﬁnite, where |A| is the modulus of A (Deﬁnition 21.5.1).
The set of all Hilbert–Schmidt operators (trace class operators) on H is denoted
by B2(H) (B1(H)).
Lemma 26.1 The two sums in Deﬁnition 26.1 are independent of the choice of the
particular basis and thus one deﬁnes the trace norm ∥·∥1 of a trace class operator
A by
∥A∥1 =
∞

n=1
⟨en, |A|en⟩
(26.1)
and the Hilbert–Schmidt norm ∥·∥2 of a Hilbert–Schmidt operator A by
∥A∥2 =
--A∗A
--1/2
1
=
$ ∞

n=1
∥Aen∥2
%1/2
.
(26.2)
© Springer International Publishing Switzerland 2015
365
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_26

366
26
Hilbert–Schmidt and Trace Class Operators
Proof
Parseval’s identity implies for any two orthonormal bases {en : n ∈N} and
{fn : n ∈N} of H and any bounded linear operator B
∞

n=1
∥Ben∥2 =
∞

n=1
∞

m=1
|⟨Ben, fm⟩|2 =
∞

m=1
--B∗fm
--2.
Take another orthonormal basis {hn : n ∈N}, the same calculation then shows that
we can continue the above identity by
∞

n=1
--B∗∗hn
--2 =
∞

m=1
∥Ben∥2 ,
since B∗∗= B, and hence this sum is independent of the particular basis. If we
apply this identity for B = |A|1/2 we see that the deﬁning sum for trace class is
independent of the particular choice of the basis.
2
Corollary 26.1 For every A ∈B2(H) one has ∥A∥2 = ∥A∗∥2.
Proof This is immediate from the proof of Lemma 26.1.
2
Basic properties of the set of all Hilbert–Schmidt operators and of the Hilbert–
Schmidt norm are collected in the following theorem.
Theorem 26.1
a) B2(H) is a vector space which is invariant under taking adjoints, i.e., A ∈B2(H)
if, and only if, A∗∈B2(H); furthermore, for all A ∈B2(H),
--A∗--
2 = ∥A∥2 .
b) The Hilbert–Schmidt norm ∥·∥2 dominates the operator norm ∥·∥, i.e.,
∥A∥≤∥A∥2
for all A ∈B2(H).
c) For all A ∈B2(H) and all B ∈B(H) one has AB ∈B2(H) and BA ∈B2(H)
with the estimates
∥AB∥2 ≤∥A∥2 ∥B∥,
∥BA∥2 ≤∥B∥∥A∥2,
i.e., B2(H) is a two-sided ideal in B(H).
d) The vector space B2(H) is a Hilbert space with the inner product
⟨A, B⟩HS =
∞

n=1
⟨Aen, Ben⟩= Tr(A∗B),
A, B ∈B2(H)
(26.3)
and the Hilbert–Schmidt norm is deﬁned by this inner product by ∥A∥2 =
√⟨A, A⟩HS.

26.1
Basic Theory
367
Proof
(a) It is obvious that scalar multiples λA of elements A ∈B2(H) again belong to
B2(H). If A, B ∈B2(H) and if {en} is an ONB then the estimate
∥(A + B)en∥2 ≤2
∥Aen∥2 + ∥Ben∥2
immediately implies A + B ∈B2(H). Thus, B2(H) is a vector space. Corollary
26.1 now implies that for A ∈B2(H) also A∗∈B2(H) and ∥A∗∥2 = ∥A∥2.
(b) Any given unit vector h ∈H can be considered as an element of an ONB {en},
therefore we can estimate for A ∈B2(H)
∥Ah∥2 ≤

n
∥Aen∥2 = ∥A∥2
2,
and it follows
∥A∥= sup {∥Ah∥: h ∈H, ∥h∥= 1} ≤∥A∥2 .
(c) For A ∈B2(H) and B ∈B(H) and every basis vector en one has ∥BAen∥2 ≤
∥B∥2 ∥Aen∥2 and thus (26.2) implies ∥BA∥2 ≤∥B∥∥A∥2. Next part (a) says
∥AB∥2 = ∥(AB)∗∥2 = ∥B∗A∗∥2 ≤∥B∗∥∥A∗∥2 = ∥B∥∥A∥2. And it follows
AB, BA ∈B2(H).
(d) For an ONB {en} and any A, B ∈B2(H) one has, using Schwarz’ inequality
twice,

n
|⟨Aen, Ben⟩| ≤∥A∥2 ∥B∥2.
We conclude that (26.3) is well deﬁned on B2(H) and then that it is antilinear
in the ﬁrst and linear in the second argument. Obviously ⟨A, A⟩HS ≥0 for all
A ∈B2(H) and ⟨A, A⟩HS = 0 if, and only if, Aen = 0 for all elements en of an
ONB of H, hence A = 0. Therefore, (26.3) is an inner product on B2(H) and
clearly this inner product deﬁnes the Hilbert–Schmidt norm.
Finally, we show completeness of this inner product space. Suppose that {An}
is a Cauchy sequence in B2(H). Then, given ε > 0, there is n0 such that
∥Am −An∥2 ≤ε for all m, n ≥n0. Since ∥A∥≤∥A∥2, this sequence is
also a Cauchy sequence in B(H), and hence it converges to a unique A ∈B(H),
by Theorem 21.3.3. For an ONB

ej

, n ≥n0, and all N ∈N, we have
N

j=1
--(A −An)ej
--2 =
lim
m−→∞
N

j=1
--(Am −An)ej
--2 ≤
lim
m−→∞∥Am −An∥2
2 ≤ε2
and conclude
∞

j=1
--(A −An)ej
--2 ≤ε2.
This shows A −An ∈B2(H), hence A = An + (A −An) ∈B2(H) and
∥A −An∥2 ≤ε for n ≥n0 and A is the limit of the sequence {An} in the
Hilbert–Schmidt norm.
2

368
26
Hilbert–Schmidt and Trace Class Operators
Though trace class operators share many properties with Hilbert–Schmidt operators,
some of the proofs are more complicated. For instance, the fact that the modulus of a
bounded linear operator is not subadditive does not allow such a simple proof of the
fact that the set of all trace class operators is closed under addition of operators, as in
the case of Hilbert–Schmidt operators. For this and some other important properties,
the following proposition will provide substantial simpliﬁcations in the proofs (see
also [2]).
Proposition 26.1 For a bounded linear operator A on H, the following statements
are equivalent:
(a) For some (and then for every) ONB {en} one has S1(A) = 
n⟨en, |A|en⟩< ∞.
(b) S2(A) = inf {∥B∥2 ∥C∥2 : B, C ∈B2(H), A = BC} < ∞.
(c) S3(A) = sup

n |⟨en, Afn⟩| : {en} , {fn} are ONS in H

< ∞
For A ∈B1(H) one has S1(A) = S2(A) = S3(A) = ∥A∥1.
Proof Suppose S1(A) < ∞. Write the polar decomposition A = U|A| as A = BC
with B = U|A|1/2 and C = |A|1/2. Then
∥B∥2
2 =

n
--U|A|1/2en
--2 ≤

n
--|A|1/2en
--2 = S1(A) < ∞
and ∥C∥2
2 = S1(A) < ∞and thus S2(A) ≤S1(A) < ∞.
Next suppose that S2(A) < ∞and take any ONS {en} and {fn} in H. Write
A = BC with B, C ∈B2(H) and estimate

n
|⟨en, Afn⟩| =

n
|⟨B∗en, Cfn⟩| ≤
$
n
--B∗en
--2
%1/2 $
n
∥Cfn∥2
%1/2
≤
--B∗--
2 ∥C∥2 = ∥B∥2 ∥C∥2.
It follows S3(A) ≤S2(A) < ∞.
Finally, assume that S3(A) < ∞and take an ONB {en} for Ran(|A|). Then
fn = Uen is an ONB for Ran(A) and thus we can estimate
S1(A) =

n
⟨en, |A|en⟩=

n
⟨en, U ∗Aen⟩=

n
⟨fn, Aen⟩≤S3(A),
and therefore S1(A) ≤S3(A) < ∞.
If A ∈B1(H), then by deﬁnition S1(A) < ∞. The above chain of estimates shows
S3(A) ≤S2(A) ≤S1(A) ≤S3(A) and thus we have equality.
2
Theorem 26.2.
(a) B1(H) is a vector space which is invariant under taking adjoints, i.e., A ∈B1(H)
if, and only if, A∗∈B1(H); furthermore, for all A ∈B1(H),
--A∗--
1 = ∥A∥1.

26.1
Basic Theory
369
(b) The trace norm ∥·∥1 dominates the operator norm ∥·∥, i.e.,
∥A∥≤∥A∥1
for all A ∈B1(H).
(c) For all A ∈B1(H) and all B ∈B(H) one has AB ∈B1(H) and BA ∈B1(H)
with the estimates
∥AB∥1 ≤∥A∥1 ∥B∥,
∥BA∥1 ≤∥B∥∥A∥1,
i.e., B1(H) is a two-sided ideal in B(H).
(d) The vector space B1(H) is a Banach space under the trace norm ∥·∥1.
Proof
(a) For a scalar multiple λA of A ∈B1(H) one obviously has S1(λA) = |λ|S1(A)
and thus λA ∈B1(H) and ∥λA∥1 = |λ| ∥A∥1. A simple calculation shows
S3(A∗) = S3(A) and therefore by Proposition 26.1, A∗∈B1(H) whenever
A ∈B1(H) and ∥A∗∥1 = ∥A∥1.
For A, B ∈B1(H) we know by Proposition 26.1 that S3(A) and S3(B) are ﬁnite.
From the deﬁnition of S3(·) we read off S3(A + B) ≤S3(A) + S3(B), thus
S3(A + B) is ﬁnite, i.e., A + B ∈B1(H).
If for A ∈B1(H) one has ∥A∥1 = 0, then |A|1/2en = 0 for all elements of an
ONB {en} of H, hence |A|1/2 = 0 and thus A = 0. Therefore, the trace norm
∥·∥1 is indeed a norm on the vector space B1(H).
(b) Given unit vectors e, f ∈H we can consider them as being an element of an
ONS {en}, respectively, of an ONS {fn}; then,
|⟨e, Af ⟩| ≤

n
|⟨en, Afn⟩| ≤S3(A),
it follows
∥A∥= sup {|⟨e, Af ⟩| : e, f ∈H, ∥e∥= ∥f ∥= 1} ≤S3(A) = ∥A∥1 .
(c) If A ∈B1(H) has a decomposition A = CD with C, D ∈B2(H), then for any
B ∈B(H), BA has a decomposition BA = BCD with BC, D ∈B2(H), by
Theorem 26.1, part (c). We conclude
S2(BA) ≤∥BC∥2 ∥D∥2 ≤∥B∥∥C∥2 ∥D∥2
and thus S2(BA) ≤∥B∥S2(A) < ∞. It follows ∥BA∥1 ≤∥B∥∥A∥1. Since
we have established that B1(H) is invariant under taking adjoints, we can prove
AB ∈B1(H) as in the case of Hilbert–Schmidt operators.
(d) Finally, we show completeness of the normed space B1(H). Suppose that {An}
is a Cauchy sequence in B1(H). Then, given ε > 0, there is n0 such that
∥Am −An∥1 ≤ε for all m, n ≥n0. Since ∥A∥≤∥A∥1 this sequence is also
a Cauchy sequence in B(H) and hence it converges to a unique A ∈B(H), by

370
26
Hilbert–Schmidt and Trace Class Operators
Theorem 21.3.3. Fix n ≥n0; for any ONS

ej

and

fj

in H and any N ∈N
we have
N

j=1
|⟨ej, (A−An)fj⟩| =
lim
m−→∞
N

j=1
|⟨ej, (Am−An)fj⟩| ≤
lim
m−→∞S3(Am−An) ≤ε
and conclude
∞

j=1
|⟨ej, (A −An)fj⟩| ≤ε.
This shows A −An ∈B1(H), hence A = An + (A −An) ∈B1(H) and
∥A −An∥1 ≤ε.
2
Corollary 26.2 The space of trace class operators is continuously embedded into
the space of Hilbert–Schmidt operators:
B1(H) →B2(H).
Proof According to the deﬁnitions one has ∥A∥2
2 = ∥A∗A∥1. When we apply parts
(c), (b), and (a) in this order we can estimate
--A∗A
--
1 ≤
--A∗-- ∥A∥1 ≤
--A∗--
1 ∥A∥1 = ∥A∥2
1
and thus ∥A∥2 ≤∥A∥1 which implies our claim.
2
Corollary 26.3. On the space of all trace class operators the trace is well deﬁned
by ( {en} is any ONB of H)
Tr(A) =

n
⟨en, Aen⟩,
A ∈B1(H).
(26.4)
This function Tr : B1(H) −→K is linear and satisﬁes for all A ∈B1(H)
a) |Tr(A)| ≤∥A∥1
b) Tr(A∗) = Tr(A)
c) Tr(AB) = Tr(BA), for all B ∈B1(H)
d) Tr(UAU∗) = Tr(A) for all unitary operators U on H
Proof We know that A ∈B1(H) can be written as A = BC with B, C ∈B2(H).
For any ONB {en}, we estimate

n
|⟨en, Aen⟩| ≤

n
--B∗en
-- ∥Cen∥≤
--B∗--
2 ∥C∥2 = ∥B∥2 ∥C∥2 < ∞
and conclude

n
|⟨en, Aen⟩| ≤S2(A) = ∥A∥1.
As earlier one proves that the sum in (26.4) does not depend on the choice of the
particular basis. Linearity in A ∈B1(H) is obvious. Thus (a) holds. The proof of (b)
is an elementary calculation.

26.1
Basic Theory
371
If A, B ∈B1(H) choose another ONB {fm} and use the completeness relation to
calculate

n
⟨en, ABen⟩=

n
⟨A∗en, Ben⟩=

n

m
⟨A∗en, fm⟩⟨fm, Ben⟩=
=

m

n
⟨B∗fm, en⟩⟨en, Afm⟩=

m
⟨B∗fm, Afm⟩=

m
⟨fm, BAfm⟩,
hence (c) holds, since we know that the above series converge absolutely so that the
order of summation can be exchanged. Part (d) is just a reformulation of the fact that
the trace is independent of the basis which is used to calculate it.
2
Theorem 26.3 (Spectral Representation of Hilbert–Schmidt and Trace Class Op-
erators ). Let H be a separable Hilbert space and denote by Bc(H) the space of all
compact operators on H (see Theorem 22.3.1). Then
(a) B2(H) ⊂Bc(H), i.e., Hilbert–Schmidt and thus trace class operators are
compact.
(b) A bounded operator A on H is a Hilbert–Schmidt operator, respectively, a trace
class operator if, and only if, there are two orthonormal bases {en} and {xn} of
H and there is a sequence {λn} in K with

n
|λn|2 < ∞,
respectively,

n
|λn| < ∞
such that
Ax =

n
λn⟨en, x⟩xn
for all
x ∈H
(26.5)
and then one has
∥A∥2 =
$
n
|λn|2
%1/2
,
respectively,
∥A∥1 =

n
|λn|.
Proof
(a) Suppose that {en} is an ONB of H; denote by PN the orthogonal projector onto
the closed subspace [e1, . . ., eN] spanned by e1, . . ., eN. Then for A ∈B2(H) one
has
∥A −APN∥2
2 =

n
∥(A −APN)en∥2 =
∞

n=N+1
∥Aen∥2 ,
hence ∥A −APN∥≤∥A −APN∥2 −→0 as N →∞. Therefore, A is the norm
limit of the sequence of ﬁnite rank operators APN and thus compact by Theorem
22.3.2.
By Corollary 26.2, we know B1(H) ⊂B2(H), hence trace class operators are
compact.

372
26
Hilbert–Schmidt and Trace Class Operators
(b) Suppose that A ∈Bj(H), j = 1 or j = 2, is given. By part (a) we know that
A and its modulus |A| are compact. The polar decomposition (Theorem 21.5.2)
relates A and |A| by A = U|A| where U is a partial isometry from ran |A| to
ran A.
According to the Riesz–Schauder Theorem (25.5) the compact operator |A| has
the following spectral representation:
|A|x =

j
λj⟨ej, x⟩ej
for all
x ∈H
(26.6)
with the speciﬁcations:
(i) λ1 ≥λ2 ≥· · · ≥λn−1 ≥λn ≥0 are the eigen-values of |A| enumerated in
decreasing order and repeated in this list according to their multiplicity,
(ii) ej is the normalized eigen-vector for the eigen-value λj
(iii) the multiplicity of every eigen-value λj > 0 is ﬁnite, and if there are inﬁnitely
many eigen-values then λj −→0 as j →∞.
If the ONS

ej

is not complete, we can extend it to an ONB

e′
n

of H and
calculate, using (26.6),
∥A∥1 =

n
⟨e′
n, |A|e′
n⟩=

j
λj < ∞
for
A ∈B1(H),
respectively
∥A∥2
2 =

n
--|A|e′
n
--2 =

j
λ2
j < ∞
for
A ∈B2(H).
If we apply the partial isometry U to the representation (26.6), we get (26.5)
with xn = Uen.
Conversely suppose that an operator A has the representation (26.5). If

n |λn|2 < ∞holds one has

j
--Axj
--2 =

j

n
|λn⟨en, xj⟩|2 =

n
|λn|2 
j
|⟨en, xj⟩|2 =

n
|λn|2,
thus ∥A∥2
2 = 
n |λn|2 < ∞and therefore A ∈B2(H).
Suppose that 
n |λn| < ∞holds. In the Exercises, we show that (26.5) implies
|A|x =

n
|λn|⟨en, x⟩en,
x ∈H.
It follows ∥A∥1 = Tr(|A|) = 
n |λn| < ∞, hence A ∈B1(H) and we
conclude.
2
Remark 26.1 One can deﬁne Hilbert–Schmidt and trace class operator also for the
case of operators between two different Hilbert spaces as follows: For two separable

26.2
Dual Spaces of the Spaces of Compact and of Trace Class Operators
373
Hilbert spaces H1 and H2 a bounded linear operator A : H1 −→H2 is called a
Hilbert–Schmidt operator if, and only if, there is an orthonormal basis {en} of H1
such that
∞

n=1
∥Aen∥2
2 < ∞,
where ∥·∥2 is the norm of H2.
A bounded linear operator A : H1 −→H2 is called a trace class operator or a
nuclear operator if, and only if, its modulus |A| =
√
A∗A is a trace class operator
on H1.
With this slightly more general deﬁnitions the results presented above still hold
with obvious modiﬁcations. We mention the spectral representation ofTheorem 26.3.
A bounded linear operator A : H1 −→H2 is a Hilbert–Schmidt, respectively, a
trace class operator if, and only if, it is of the form
Ax =
∞

n=1
λn⟨e1
n, x⟩1e2
n,
for all x ∈H1,
(26.7)
where

ei
n

is an orthonormal system in Hi, i = 1, 2 and where the sequence of
numbers λn ̸= 0 satisﬁes 
n |λn|2 < ∞and 
n |λn| < ∞, respectively.
26.2
Dual Spaces of the Spaces of Compact and of Trace Class
Operators
The space of linear operators on H which have a ﬁnite rank is denoted by Bf (H). The
following corollary highlights important results which in essence have been proven
already in the last few theorems.
Corollary 26.4 For any separable Hilbert space H, one has
Bf (H) ⊂B1(H) ⊂B2(H) ⊂Bc(H) ⊂B(H)
and all the embeddings are continuous and dense. Bf (H) is dense in Bj(H), j = 1, 2
and in Bc(H).
Proof In the proof of the last two results, it was shown in particular that
Bf (H) ⊂Bj(H) ⊂Bc(H),
j = 1, 2
holds and that the ﬁnite rank operators are dense in Bc(H) and in Bj(H) for j = 1, 2.
Parts (b) of Theorem 26.1, respectively, Theorem 26.2. imply that the embeddings
Bj(H) →Bc(H), j = 1, 2, arecontinuouswhenBc(H)isequippedwiththeoperator
norm. By Corollary 26.2 we conclude.
2

374
26
Hilbert–Schmidt and Trace Class Operators
According to Theorem 26.1, the space of Hilbert–Schmidt operators B2(H) is a
Hilbert space. Hence, according to the deﬁnition of the inner product (26.3) the
continuous linear functionals f on this space are given by
f (A) = Tr(BA)
for all
A ∈B2(H),
for some
B = Bf ∈B2(H).
(26.8)
Part (c) of Theorem 26.2. says that the space of the trace class operators is a two-sided
ideal in B(H), hence Tr(BA) is well deﬁned for all B ∈B(H) and all A ∈B1(H)
and Part (a) of Corollary 26.3. allows to estimate this trace by
|Tr(BA)| ≤∥B∥∥A∥1.
(26.9)
Therefore, for ﬁxed B ∈B(H), fB(A) = Tr(BA) is a continuous linear functional on
B1(H), andforﬁxedA ∈B1(H), gA(B) = Tr(BA)isacontinuouslinearfunctionalon
B(H). Here we are interested in the space B1(H)′ of all continuous linear functionals
on B1(H) and in the space Bc(H)′ of all continuous linear functionals on Bc(H) ⊂
B(H). Note that according to Corollary 26.4 the restriction of a continuous linear
functional on Bc(H) to B2(H) is a continuous linear functional on B2(H) and thus
given by the trace, i.e., formula (26.8).
Theorem 26.4 For a separable Hilbert H the space of all continuous linear func-
tionals Bc(H)′ on the space Bc(H) of all compact operators on H and the space
B1(H) of all trace class operators are (isometrically) isomorphic, i.e.,
Bc(H)′ ∼= B1(H).
The isomorphism B1(H) −→Bc(H)′ is given by B #→φB with
φB(A) = Tr(BA) for all A ∈Bc(H).
(26.10)
Proof As mentioned above, given F ∈Bc(H)′, we know F|B2(H) ∈B2(H)′ and
thus there is a unique B ∈B2(H) such that
F(A) = Tr(BA)
for all
A ∈B2(H).
In order to show that actually B ∈B1(H) we use the characterization of trace class
operators as given in Proposition 26.1 and estimate S3(B). To this end take any two
ONS {en} and {fn} in H and observe that there is αn ∈R such that
e iαn⟨fn, Ben⟩= |⟨fn, Ben⟩|.
Introduce the ﬁnite rank operators [en, fn] deﬁned by [en, fn]x = ⟨fn, x⟩en and then
the ﬁnite rank operators
Am =
m

n=1
e iαn[en, fn].

26.2
Dual Spaces of the Spaces of Compact and of Trace Class Operators
375
Since ∥Amx∥2 = m
n=1 |⟨fn, x⟩|2 ≤∥x∥2, one has ∥Am∥≤1. Thus we write, for
any m ∈N,
m

n=1
|⟨fn, Ben⟩| =
m

n=1
eiαn⟨fn, Ben⟩= Tr(BAm) = F(Am)
since ⟨fn, Ben⟩= Tr(B[en, fn]). We conclude
m

n=1
|⟨fn, Ben⟩| ≤∥F∥′,
thus S3(B) ≤∥F∥′ and hence B ∈B1(H). Introduce the continuous linear functional
φB : Bc(H) −→K by
φB(A) = Tr(BA)
for all
A ∈Bc(H).
We conclude that every F ∈Bc(H)′ is of the form F = φB with a unique B ∈B1(H).
Now by (26.9), it follows
∥F∥′ = sup {|F(A)| : A ∈Bc(H), ∥A∥≤1} ≤∥B∥1.
In order to show ∥F∥′ = ∥φB∥′ = ∥B∥1 recall that ∥B∥1 = Tr(|B|) when B has the
polar decomposition B = U|B| with a partial isometry U. For an ONB {en} of H
form the ﬁnite rank operator Am = m
n=1 [en, en]U ∗and calculate
Tr(BAm)=Tr(AmB)=Tr
$ m

n=1
[en, en]U ∗B
%
=
m

n=1
Tr([en, en]|B|)=
m

n=1
⟨en, |B|en⟩.
It follows
∥φB∥′ ≥|Tr(BAm)| ≥
m

n=1
⟨en, |B|en⟩
for all m ∈N and thus ∥φB∥′ ≥∥B∥1, and we conclude. Basic properties of the trace
show that the map B −→φB is linear. Hence, this map is an isometric isomorphism
form B1(H) to Bc(H)′.
2
In a similar way one can determine the dual space of the space of all trace class
operators.
Theorem 26.5 For a separable Hilbert H the space of all continuous linear func-
tionals B1(H)′ on the space B1(H) of all trace class operators on H and the space
B(H) of all bounded linear operators are (isometrically) isomorphic, i.e.,
B1(H)′ ∼= B(H).
The isomorphism B(H) −→B1(H)′ is given by B #→ΨB where
ΨB(A) = Tr(BA) for all A ∈B1(H).
(26.11)

376
26
Hilbert–Schmidt and Trace Class Operators
Proof In the ﬁrst step, we show that given f ∈B1(H)′, there is a unique B = Bf ∈
B(H) such that f = ψB where again ψB is deﬁned by the trace, i.e., ΨB(A) = Tr(BA)
for all A ∈B1(H). For all x, y ∈H deﬁne
bf (x, y) = f ([y, x])
where the operator [y, x] is deﬁned as above. Since [y, x] ∈Bf (H) ⊂B1(H), bf is
well deﬁned on H × H. Linearity of f implies immediately that bf is a sesquilinear
form on H. This form is continuous: For all x, y ∈H the estimate
|bf (x, y)| = |f ([y, x])| ≤∥f ∥′ ∥[y, x]∥1 ≤∥f ∥′ ∥x∥∥y∥
holds, since by Proposition 26.1 one has, using Schwarz’ and Bessel’s inequality,
∥[y, x]∥1 = S3([y, x]) ≤∥x∥∥y∥. Therefore by Theorem 20.2.1, there is a unique
bounded linear operator B such that bf (x, y) = ⟨x, By⟩, i.e.,
f ([y, x]) = ⟨x, By⟩= Tr(B[y, x])
for all x, y ∈H.
The last identity follows from the completeness relation for an ONB {en} of H:
Tr(B[y, x]) = 
n⟨en, B[y, x]en⟩= 
n⟨en, By⟨x, en⟩⟩= 
n⟨en, By⟩⟨x, en⟩=
⟨x, By⟩. By linearity this representation of f is extended to Bf (H) ⊂B1(H). And
since both f and Tr are continuous with respect to the trace norm this representation
has a unique extension to all of B1(H) (Bf (H) is dense in B1(H)):
f (A) = Tr(BA) = ΨB(A)
for all A ∈B1(H).
Linearity of Tr implies easily that B −→ΨB is a linear map from B(H) to B1(H)′.
Finally, we show that this map is isometric.
The continuity estimate (26.9) for the trace gives for B ∈B(H)
∥ΨB∥′ = sup {|ΨB(A)| : A ∈B1(H), ∥A∥1 ≤1} ≤∥B∥.
We can assume B ̸= 0. Then ∥B∥> 0 and there is x ∈H, ∥x∥≤1 such that
∥Bx∥≥∥B∥−ε for any ε ∈(0, ∥B∥). Introduce ξ =
Bx
∥Bx∥and calculate as above
ΨB([x, ξ]) = Tr(B[x, ξ]) = ⟨ξ, Bx⟩= ∥Bx∥≥∥B∥−ε,
hence ∥ΨB∥′ ≥∥B∥−ε. This holds for any 0 < ε < ∥B∥. We conclude
∥ΨB∥′ ≥∥B∥
and thus ∥ΨB∥′ = ∥B∥and B −→ΨB is an isometric map from B(H) onto B1(H)′.
2
Remark 26.2 According to this result one has the following useful expressions for
the trace norm and the operator norm: The trace norm of T ∈B1(H) is given by
∥T ∥1 = sup |Tr(BT )|,
(26.12)

26.3
Related Locally Convex Topologies on B(H)
377
where the sup is taken over all B ∈B(H) with ∥B∥= 1 and similarly the norm of
B ∈B(H) is
∥B∥= sup |Tr(BT )|,
(26.13)
where the sup is taken over all T ∈B1(H) with ∥T ∥1 = 1. Since B1(H) is generated
by the cone of its positive elements one also has
∥B∥= sup |Tr(BW)|,
(26.14)
where the sup is taken over all density matrices W, i.e., W ∈B1(H), W ≥0, and
∥W∥1 = Tr(W) = 1.
Remark 26.3 It is instructive to compare the chain of continuous dense embeddings
Bf (H) →B1(H) →B2(H) →Bc(H) →B(H)
(26.15)
for the spaces of bounded linear operators on a separable Hilbert space H over the
ﬁeld K with the chain of embeddings for the corresponding sequence spaces
ℓf (K) →ℓ1(K) →ℓ2(K) →c0(K) →ℓ∞(K),
(26.16)
where ℓf (K) denotes the space of terminating sequences and c0(K) the space of null
sequences. And our results on the spectral representations of operators in B1(H),
B2(H), and Bc(H) indicate how these spaces are related to the sequence spaces
ℓ1(K), ℓ2(K), and c0(K).
For these sequence spaces it is well known that ℓ∞(K) is the topological dual of
ℓ1(K), ℓ1(K)′ ∼= ℓ∞(K), and that ℓ1(K) is the dual of c0(K), c0(K)′ ∼= ℓ1(K), as the
counterpart of the last two results: B1(H)′ ∼= B(H) and Bc(H)′ ∼= B1(H).
26.3
Related Locally Convex Topologies on B(H)
RecallthatinSect.21.4, weintroducedtheweakandthestrongoperatortopologieson
B(H) as the topology of pointwise weak, respectively, pointwise norm convergence.
In the study of operator algebras some further topologies play an important role. Here
we restrict our discussion to the operator algebra B(H), respectively, subalgebras of
it. Recall also that in the second chapter we had learned how to deﬁne locally convex
topologies on vector spaces in terms of suitable systems of seminorms. This approach
we use here again. We begin by recalling the deﬁning seminorms for the strong and
the weak topology.
The strong topology on B(H) is deﬁned by the system of seminorms px, x ∈H,
with
px(A) = ∥Ax∥,
A ∈B(H).
Sometimes it is important to have a topology on B(H) with respect to which the
involution ∗on B(H) is continuous. This is the case for the strong* topology deﬁned

378
26
Hilbert–Schmidt and Trace Class Operators
by the system of seminorms p∗
x, x ∈H, with
p∗
x(A) =

∥Ax∥2 + ∥A∗x∥2,
A ∈B(H).
The weak topology on B(H) is deﬁned by the system of seminorms px,y, x, y ∈H,
with
px,y(A) = |⟨x, Ay⟩|,
A ∈B(H).
Similarly, one deﬁnes the σ-weak and σ-strong topologies on B(H). Often these
topologies are also called ultraweak and ultrastrong topologies, respectively.
The σ-strong topology on B(H) is deﬁned in terms of a system of seminorms
q = q{en}, {en} ⊂H, 
n ∥en∥2 < ∞, with
q(A) =
$
n
∥Aen∥2
%1/2
,
A ∈B(H).
And the σ-strong* topology is deﬁned by the system of seminorm q∗, q as above,
with
q∗(A) = (q(A)2 + q(A∗)2)1/2,
A ∈B(H).
Next suppose that {en} and {gn} are two sequences in H satisfying 
n ∥en∥2 < ∞
and 
n ∥gn∥2 < ∞. Then a continuous linear functional T = T{en},{gn} is well
deﬁned on B(H) by (see Exercises)
T (A) =

n
⟨gn, Aen⟩,
A ∈B(H).
(26.17)
Now the σ-weak topology on B(H) is deﬁned by the system of seminorms pT , T
as above, by
pT (A) = |T (A)| = |

n
⟨gn, Aen⟩|.
Using the ﬁnite rank operators [en, gn] introduced earlier we can form the operator
ˆT = 
n [en, gn]. For any two orthonormal systems

xj

and

yj

in H, we estimate
by Schwarz’ and Bessel’s inequalities

j
|⟨xj, [en, gn]yj⟩| =

j
|⟨xj, en⟩⟨gn, yj⟩| ≤∥en∥∥gn∥
and thus

j
|⟨xj, ˆT yj⟩| ≤

n
∥en∥∥gn∥< ∞.
Proposition 26.1 implies that ˆT is a trace class operator on H. In the Exercises, we
show that for all A ∈B(H)
Tr(A ˆT ) =

n
⟨gn, Aen⟩= T (A),
(26.18)

26.3
Related Locally Convex Topologies on B(H)
379
hence the functional T of (26.17) is represented as the trace of the trace class operator
ˆT multiplied by the argument of T.
According to Theorem 26.4, the Banach space dual of the space of compact opera-
tors Bc(H) is isometrically isomorphic to the space B1(H) of trace class operators on
H and according to Theorem 26.5, the Banach space dual of B1(H) is isometrically
isomorphic to the space B(H) of all bounded linear operators on H.
Thus, we can state:
The σ-weak or ultraweak topology on B(H) is the weak∗-topology from the identiﬁcation
of B(H) with the dual of B1(H), i.e., the topology generated by the family of seminorms

p ˆT : ˆT ∈B1(H)

deﬁned by p ˆT (A) = |Tr( ˆT A)| = |T (A)| for A ∈B(H).
It is easy to verify that the weak topology on B(H) is the dual topology σ(B(H),
Bf (H)).
Recall also that nonnegative trace class operators are of the form ˆT = 
n [en, en]
with 
n ∥en∥2 < ∞. For A ∈B(H) we ﬁnd
Tr(A∗A ˆT ) =

n
∥Aen∥2 = T (A∗A),
where T is the functional on B(H) which corresponds to ˆT according to (26.18).
Hence, the deﬁning seminorms q for the σ-strong topology are actually of the form
q(A) = (T (A∗A))1/2 = (Tr(A∗A ˆT ))1/2.
From these deﬁnitions it is quite obvious how to compare these topologies on
B(H): The σ-strong* topology is ﬁner than the σ-strong topology which in turn is
ﬁner than the σ-weak topology. And certainly the σ-strong* topology is ﬁner than
the strong* topology and the σ-strong topology is ﬁner than the strong topology
which is ﬁner than the weak topology. Finally, the σ-weak topology is ﬁner than the
weak topology. Obviously the uniform or norm topology is ﬁner than the σ-strong*
topology.
uniform
σ-strong
σ-weak
strong
weak
direction of ﬁner topology
direction of implied convergence
Main topologies on

380
26
Hilbert–Schmidt and Trace Class Operators
Nevertheless one has the following convenient result:
Lemma 26.2
On the closed unit ball B = {A ∈B(H) : ∥A∥≤1}, the following
topologies coincide:
a) The weak and the σ-weak
b) The strong and the σ-strong
c) The strong* and the σ-strong*
Proof Since the proofs of these three statements are very similar, we offer explicitly
only the proof of (b).
Clearly it sufﬁces to show that for every neighborhood U of the origin for
the σ-strong topology there is a neighborhood V of the origin for the strong
toplogy such that V ∩B ⊂U ∩B. Such a neighborhood U is of the form
U = {A ∈B(H) : q(A) < r} with r > 0 and q(A)2 = 
n ∥Aen∥2 for some
sequence en
∈H with 
n ∥en∥2
< ∞. Thus there is m ∈N such that
∞
n=m+1 ∥en∥2 < r2/2. Deﬁne a neighborhood V of the origin for the strong
topology by V
= {A ∈B(H) : p(A) < r/
√
2} with the norm p given by
p(A)2 = m
n=1 ∥Aen∥2. Now for A ∈V ∩B, we estimate
q(A)2 =
m

n=1
∥Aen∥2+
∞

n=m+1
∥Aen∥2 ≤
m

n=1
∥Aen∥2+
∞

n=m+1
∥en∥2 <r2/2+r2/2=r2
and conclude A ∈U ∩B.
2
In addition continuity of linear functionals are the same within two groups of these
topologies as the following theorem shows.
Theorem 26.6
Suppose that K ⊂B(H) is a linear subspace which is σ-weakly
closed. Then for every bounded linear functional T on K the following groups of
equivalence statements hold.
1) The following statements about T are equivalent:
a) T is of the form T (·) = m
j=1⟨yj, ·xj⟩for some points xj, yj ∈H
b) T is weakly continuous
c) T is strongly continuous
d) T is strongly* continuous
2) The following statements about T are equivalent (B is the closed unit ball in
B(H)):
a) T is of the form T (·) = ∞
j=1⟨yj, ·xj⟩for some sequences xj, yj ∈H with

j
--xj
--2 < ∞and 
j ∥yj∥2 < ∞
b) T is σ-weakly continuous
c) T is σ-strongly continuous
d) T is σ-strongly* continuous
e) T is weakly continuous on K ∩B
f) T is strongly continuous on K ∩B
g) T is strongly* continuous on K ∩B

26.3
Related Locally Convex Topologies on B(H)
381
Proof Since the ﬁrst group of equivalence statements is just a ‘ﬁnite’ variant of the
second we do not prove it explicitly.
For the proof of (2) we proceed in the order a. ⇒b.⇒c. ⇒d. ⇒a. If a. is
assumed then
A #→|T (A)| = |

j
⟨yj, Axj⟩|
is obviously a deﬁning seminorm for the σ-weak topology. If we apply the Cauchy–
Schwarz inequality twice this seminorm is estimated by
⎛
⎝
j
--yj
--2
⎞
⎠
1/2 ⎛
⎝
j
--Axj
--2
⎞
⎠
1/2
which is a continuous seminorm for the σ-strong topology and thus T is also σ-
strongly continuous. Another elementary estimate now proves d.
The only nontrivial part of the proof is the implication d. . ⇒a. If T is σ-strongly*
continuous there is a sequences {xj} with 
j ∥xj∥2 < ∞such that for all A ∈K
|T (A)|2 ≤
∞

j=1
--Axj
--2 +
--A∗xj
-- |2
.
(26.19)
Form the direct sum Hilbert space
˜H =
∞
:
j=1
(Hj ⊕H′
j) = ℓ2(H ⊕H′),
where H′
j is the dual of Hj = H for all j ∈N. For A ∈B(H) deﬁne an operator ˜A
on ˜H by setting for ˜y ∈˜H with components yj ⊕y′
j ∈Hj ⊕H′
j
( ˜A ˜y)j = Ayj ⊕(A∗yj)′,
j ∈N.
A straightforward estimate shows
∥˜A ˜y∥˜H ≤

∥A∥2 +
--A∗--21/2
∥˜y∥˜H .
On the subspace
˜K =
 
˜A˜x : A ∈K
!
of ˜H where ˜x is deﬁned by the sequence

xj

of the estimate (26.19), deﬁne the map
˜T by setting
˜T ( ˜A˜x) = T (A).
By(26.19)itfollowsthat ˜T isawell-deﬁnedboundedlinearmap ˜K −→K(recallthat
Hj →H′
j is antilinear). Theorems 15.3.2 (extension theorem) and 15.3.1 (Riesz–
Fréchet) imply that there is an element ˜y in the closure of the subspace ˜K in ˜H such

382
26
Hilbert–Schmidt and Trace Class Operators
that
˜T ( ˜A˜x) = ⟨˜y, ˜A˜x⟩˜H
for all A ∈K, thus by expanding the inner product of ˜H
T (A) = ˜T ( ˜A˜x) =

j
(⟨yj, Axj⟩H + ⟨y′
j, (A∗xj)′⟩H′)
=

j
(⟨yj, Axj⟩H + ⟨xj, Ayj⟩H)
and therefore T is of the form given in statement a..
The remaining part of the proof follows with the help of Lemma 26.2 and
Corollary 2.1 which says that a linear functional is continuous if, and only if, it is
continuous at the origin (see also the Exercises).
2
Remark 26.4 A considerably more comprehensive list of conditions under which
these various locally convex topologies on B(H) agree is available in Chap. II of [7].
26.4
Partial Trace and Schmidt Decomposition in Separable
Hilbert Spaces
26.4.1
Partial Trace
The ﬁrst guess for deﬁning the partial trace in the case of inﬁnite dimensional Hilbert
spaces Hj would be, in analogy to the the case of ﬁnite dimensional Hilbert spaces,
to start with the matrix representation of A ∈B1(H1 ⊗H2) with respect to an or-
thonormal basis

ej ⊗fk

of H1⊗H2 and to calculate the usual sums with respect to
one of the ONBs

ej
 {fk}, respectively. However, inﬁnite sums might be divergent,
and we have not found any useful way to express the fact that A is of trace class in
terms of properties of the matrix entries
Aj1k1;j2k2
j1, j2, k1, k2 ∈N.
But such a procedure can be imitated by introducing a suitable quadratic form
and investigate its properties (see [8]).
Theorem 26.7. (Existence, Deﬁnition and Basic Properties of Partial Trace) Let
H1 and H2 be two separable complex Hilbert spaces. Then there is a linear map
T : B1(H1 ⊗H2) −→B1(H1)
from the space of trace class operators on H1 ⊗H2 into the space of trace class
operators on H1 which is continuous with respect to the trace norm. It has the
following properties
T (A1 ⊗A2) = A1TrH2(A2)
for all Ai ∈B1(Hi), i = 1, 2;
(26.20)

26.4
Partial Trace and Schmidt Decomposition in Separable Hilbert Spaces
383
TrH1(T(A)) = TrH1⊗H2(A)
for all A ∈B1(H1 ⊗H2);
(26.21)
T ((A1 ⊗I2)A) = A1T (A)
for all A1 ∈B(H1), and all A ∈B1(H1 ⊗H2),
(26.22)
where I2 denotes the identity operator on H2 and B(H1) the space of bounded linear
operators on H1.
On the basis of Property (26.20) the map T is usually denoted by TrH2 and
called the partial trace with respect to H2. Later in Proposition 26.2 an enhanced
characterization of the partial trace will be offered. Actually this map T is surjective
(in Formula (26.20) take any ﬁxed A2 ∈B1(H2) with Tr(A2) = 1.) In applications
to quantum physics the partial trace allows to calculate the ‘marginals’ of states of
composite systems and is therefore also called conditional expectation.
Proof
Let {fj; j ∈N} be an orthonormal basis of H2. For a given operator A ∈
B1(H1 ⊗H2) deﬁne a sesquilinear form QA on H1 by setting for u, v ∈H1
QA(u, v) =
∞

j=1
⟨u ⊗fj, A(v ⊗fj)⟩1⊗2.
(26.23)
By inserting the spectral representation (26.5) for H = H1 ⊗H2 we can write this
as
QA(u, v) =
∞

j=1
∞

n=1
λn⟨u ⊗fj, xn⟩1⊗2⟨en, v ⊗fj⟩1⊗2.
For u, v ∈H1 with ∥u∥= ∥v∥= 1 we know that

u ⊗fj

and

v ⊗fj

are ONS in
H1 ⊗H2 and thus we can estimate, using ﬁrst Schwarz’inequality and then Bessel’s
inequality for these ONS,
|QA(u, v)| ≤

n
|λn|

j
|⟨u ⊗fj, xn⟩1⊗2⟨en, v ⊗fj⟩1⊗2|
≤

n
|λn| ∥en∥∥xn∥=

n
|λn| = ∥A∥1.
This implies for general u, v ∈H1
|QA(u, v)| ≤∥A∥1 ∥u∥1 ∥v∥1,
and thus the sesquilinear form QA is well deﬁned and continuous. Therefore, the
representation formula for continuous sesqulinear forms applies and assures the
existence of a unique bounded linear operator T (A) on H1 such that
QA(u, v) = ⟨u, T (A)v⟩1
for all u, v ∈H1
(26.24)
and ∥T (A)∥≤∥A∥1.
In order to show T (A) ∈B1(H1), we use the characterization of trace class
operators as given in Proposition 26.1 and estimate S3(T (A)) by inserting the spectral

384
26
Hilbert–Schmidt and Trace Class Operators
representation (26.5) for A ∈B1(H1 ⊗H2). To this end take any orthonormal
sequences {un} and {vm} in H1. Since then

un ⊗fj

and

vm ⊗fj

are orthonormal
sequences in H1 ⊗H2 we can estimate as follows, again applying ﬁrst Schwarz’and
then Bessel’s inequality:

k
|⟨un, T (A)vk⟩1| =

k
|

n,j
λn⟨uk ⊗fj, xn⟩1⊗2⟨en, vk ⊗fj⟩1⊗2|
≤

n
|λn|

k,j
|⟨uk ⊗fj, xn⟩1⊗2⟨en, vk ⊗fj⟩1⊗2|
≤

k
|λn| ∥en∥1⊗2 ∥xn∥1⊗2 =

k
|λn| = ∥A∥1 < ∞.
We conclude T (A) ∈B1(H1) and
∥T (A)∥1 ≤∥A∥1.
(26.25)
The above deﬁnition of T (A) is based on the choice of an orthonormal basis

fj; j ∈N

. However, as in the case of a trace, the value of T (A) does actually
not depend on the basis which is used to calculate it. Suppose that

hj; j ∈N

is
another orthonormal basis of H2. Express the fj in terms of the new basis, i.e.,
fj =

ν
ujνhν,
ujν ∈C.
Since the transition from one orthonormal basis to another is given by a unitary
operator, one knows 
j ujνujμ = δνμ. Now calculate for u, v ∈H1

j
⟨u ⊗fj, A(v ⊗fj)⟩1⊗2 =

j,ν,μ
ujνujμ⟨u ⊗hν, A(v ⊗hμ)⟩1⊗2
=

ν,μ

j
ujνujμ⟨u ⊗hν, A(v ⊗hμ)⟩1⊗2 =

ν
⟨u ⊗hν, A(v ⊗hν)⟩1⊗2.
Therefore, the sesquilinear form QA does not depend on the orthonormal basis which
is used to calculate it. We conclude that the deﬁnition of T (A) does not depend on
the basis.
Equations (26.23) and (26.24) imply immediately that our map T is linear and
thus by (26.25) continuity with respect to the trace norms follows.
Next, we verify the basic properties (26.20), (26.21), and (26.22). For Ai ∈
B1(Hi), i = 1, 2 one ﬁnds by applying the deﬁnitions for all u, v ∈H1
⟨u, T (A1 ⊗A2)v⟩1 =

j
⟨u ⊗fj, (A1 ⊗A2)(v ⊗fj)⟩1⊗2
=

j
⟨u, A1v⟩1⟨fj, A2fj⟩2 = ⟨u, A1v⟩1TrH2(A2),

26.4
Partial Trace and Schmidt Decomposition in Separable Hilbert Spaces
385
hence T (A1 ⊗A2) = A1TrH2(A2), i.e., (26.20) holds.
For A ∈B1(H1 ⊗H2) we calculate, using an orthonormal basis {ei; i ∈N}
of H1
TrH1(T (A)) =

i
⟨ei, T (A)ei⟩1 =

i

j
⟨ei ⊗fj, Aei ⊗fj⟩1⊗2 = TrH1⊗H2(A)
and ﬁnd that (26.21) holds.
Finally, take any bounded linear operator A1 on H1, any A ∈B1(H1 ⊗H2), and
any vectors u, v ∈H1. Our deﬁnition gives
⟨u, T ((A1 ⊗I2)A)v⟩1 =

j
⟨u ⊗fj, (A1 ⊗I2)A(v ⊗fj)⟩1⊗2
=

j
⟨A∗
1u ⊗fj, A(v ⊗fj)⟩1⊗2 = ⟨A∗
1u, T (A)v⟩1 = ⟨u, A1T (A)v⟩1,
and thus T ((A1 ⊗I2)A) = A1T (A), i.e., (26.22) is established.
2
Corollary 26.5. For all bounded linear operators A1 on H1 and all A ∈B1(H1 ⊗
H2) one has
TrH1⊗H2((A1 ⊗I2)A) = TrH1(A1TrH2(A)).
(26.26)
Proof Apply ﬁrst (26.21) and then (26.22) and observe that the product of a trace
class operator with a bounded linear operator is again a trace class operator (see
Theorem 26.2.).
2
Proposition 26.2 (Partial Trace Characterization) Suppose that H1 and H2 are
two separable Hilbert spaces and that a linear map L : B1(H1 ⊗H2) −→B1(H1)
satisﬁes
TrH1(PL(A)) = TrH1⊗H2(P ⊗I2A)
(26.27)
for all ﬁnite rank orthogonal projectors P on H1 and all A ∈B1(H1 ⊗H2). Then L
is the partial trace with respect to H2:
L(A) = TrH2(A).
(26.28)
Proof
By taking linear combinations of (26.27) of ﬁnite rank projectors Pj we
conclude that
TrH1(BL(A)) = TrH1⊗H2((B ⊗I2)A)
holds for all B ∈Bf (H1) and all A ∈B1(H1 ⊗H2). Hence, by Eq 26.26, we ﬁnd
TrH1(BL(A)) = TrH1(BTrH2(A))
or, observing Corollary 26.4 and taking the deﬁnition of the inner product on B2(H2)
in (26.3) into account,
⟨B, L(A)⟩2 = ⟨B, TrH2(A)⟩2
all B ∈Bf (H1) and all A ∈B1(H1 ⊗H1). Since Bf (H1) is dense in B2(H1) we
conclude.
2

386
26
Hilbert–Schmidt and Trace Class Operators
26.4.2
Schmidt Decomposition
The elements of H = H1 ⊗H2 can be described explicitly in terms of orthonormal
basis of Hi, i = 1, 2: Suppose ej, j ∈N is an orthonormal basis of H1 and fj, j ∈N
is an orthonormal basis of H2. Then every element x ∈H is of the form (see for
instance [3])
x =
∞

i,j=1
ci,jei ⊗fj,
ci,j ∈C,
∞

i,j=1
|ci,j|2 = ∥x∥2.
(26.29)
However, in the discussion of entanglement in quantum physics and quantum infor-
mation theory (see [1]), it has become the standard to use the Schmidt representation
of vectors in H which reduces the double sum in (26.29) to a simple biorthogonal
sum.
Theorem 26.8 (Schmidt Decomposition) For every x ∈H = H1 ⊗H2 there are
nonnegative numbers pn and orthonormal bases gn; n ∈N, of H1 and hn, n ∈N,
of H2 such that
x =
∞

n=1
pngn ⊗hn,
∞

n=1
p2
n = ∥x∥2 .
(26.30)
Proof We use the standard isomorphism I between the Hilbert tensor product H1 ⊗
H2 and the space LHS(H1; H2) of Hilbert–Schmidt operators H1 −→H2. In Dirac
notation I is given by I(x) = ∞
i,j=1 ci,j|fj⟩⟨ei|, i.e., for all y ∈H1 we have
I(x)(y) =
∞

i,j=1
ci,j⟨ei, y⟩1fj,
where ⟨·, ·⟩1 denotes the inner product of H1 and where x is given by (26.29). It is
easily seen that I(x) is a well-deﬁned bounded linear operator H1 −→H2. Hence,
I(x)∗I(x) is a bounded linear operator H1 −→H1 which is of trace class since
TrH1(I(x)∗I(x)) =
∞

i=1
⟨I(x)ei, I(x)ei⟩2 =
∞

i,j=1
|ci,j|2 = ∥x∥2.
Thus, I(x) is a Hilbert–Schmidt operator with norm
∥I(x)∥2 = +

TrH1(I(x)∗I(x)) = ∥x∥.
(26.31)
Since I(x)∗I(x) is a positive trace class operator on H1, it is of the form
I(x)∗I(x) =
∞

n=1
λnPgn,
∞

n=1
λn = ∥x∥2,
(26.32)

26.5
Some Applications in Quantum Mechanics
387
where Pgn = |gn⟩⟨gn| is the orthogonal projector onto the subspace spanned by the
element gn of an orthonormal basis gn, n ∈N, of H1.
This spectral representation allows easily to calculate the square root of the
operator I(x)∗I(x):
|I(x)|
def= +

I(x)∗I(x)) =
∞

n=1

λnPgn.
(26.33)
This prepares for the polar decomposition (see, for instance, [3]) of the operator
I(x) : H1 −→H2, according to which this operator can be written as
I(x) = U|I(x)|,
U = partial isometry H1 −→H2,
(26.34)
i.e., U is an isometry from (ker I(x))⊥⊂H1 onto ran I(x) ⊂H2.
Finally denote by hn, n ∈N, the orthonormal system obtained from the basis
gn, n ∈N, under this partial isometry, hn = Ugn. Hence, from (26.33) and (26.34)
we get
I(x) =
∞

n=1

λn |hn⟩⟨gn|.
If we identify pn with √λn and if we apply I −1 to this identity, then Eq (26.30)
follows.
2
Remark 26.5 A (vector) state x of a composite system with Hilbert space H =
H1 ⊗H2 is called entangled if its Schmidt decomposition (26.30) contains more
than one term. Otherwise such a state is called separable or a product state, and
thus is of the form e ⊗f , e ∈H1, f ∈H2.
26.5
Some Applications in Quantum Mechanics
Remark 26.6 In the case of concrete Hilbert spaces, the trace can often be evaluated
explicitly without much effort, usually easier than for instance the operator norm.
Consider the Hilbert–Schmidt integral operator K in L2(Rn) discussed earlier. It is
deﬁned in terms of a kernel k ∈L2(Rn × Rn) by
Kψ(x) =

Rn k(x, y)ψ(y) dy
∀ψ ∈L2(Rn).
In the Exercises, we show that
T r(K∗K) =

Rn

Rn k(x, y)k(x, y) dxdy.
A special class of trace class operators is of great importance for quantum mechanics,
which we brieﬂy mention.

388
26
Hilbert–Schmidt and Trace Class Operators
Deﬁnition 26.2 A density matrix or statistical operator W on a separable Hilbert
space H is a trace class operator which is symmetric (W ∗= W), positive (⟨x, Wx⟩≥
0 for all x ∈H), and normalized (TrW = 1).
Note that in a complex Hilbert space symmetry is implied by positivity. In quan-
tum mechanics density matrices are usually denoted by ρ. Density matrices can be
characterized explicitly.
Theorem 26.9 A bounded linear operator W on a separable Hilbert space H is a
density matrix if, and only if, there are a sequence of nonnegative numbers ρn ≥0
with ∞
n=1 ρn = 1 and an orthonormal basis {en : n ∈N} of H such that for all
x ∈H,
Wx =
∞

n=1
ρn⟨en, x⟩en,
(26.35)
i.e., W = ∞
n=1 ρnPen, Pen =projector onto the subspace K en.
Proof Using the spectral representation (26.3) of trace class operators the proof is
straight forward and is left as an exercise.
2
The results of this chapter have important applications in quantum mechanics, but
also in other areas. We mention, respectively sketch, some of these applications
brieﬂy.
We begin with a reminder of some of the basic principles of quantum mechanics
(see, for instance, [4, 5]).
1. The states of a quantum mechanical system are described in terms of density
matrices on a separable complex Hilbert space H.
2. The observables of the systems are represented by self-adjoint operators in H.
3. The mean value or expectation value of an observable a in a state z is equal to the
expectation value E(A, W) of the corresponding operators in H; if the self-adjoint
operator A represents the observable a and the density matrix W represents the
state z, this means that
m(a, z) = E(A, W) = Tr(AW).
Naturally, the mean value m(a, z) is considered as the mean value of the results
of a measurement procedure. Here we have to assume that AW is a trace class
operator, reﬂecting the fact that not all observables can be measured in all states.
4. Examples of density matrices W are projectors Pe on H, e ∈H, ∥e∥= 1, i.e.,
Wx = ⟨e, x⟩e. Such states are called vector states and e the representing vector.
Then clearly E(A, Pe) = ⟨e, Ae⟩= Tr(PeA).
5. Convex combinations of states, i.e., n
j=1 λjWj of states Wj are again states (here
λj ≥0 for all j and n
j=1 λj = 1). Those states which cannot be represented as
nontrivial convex combinations of other states are called extremal or pure states.
Under quite general conditions one can prove: There are extremal states and the
set of all convex combinations of pure states is dense in the space of all states
(Theorem of Krein–Milman, [6], not discussed here).

26.5
Some Applications in Quantum Mechanics
389
Thus we learn, that and how, projectors and density matrices enter in quantum
mechanics.
Next we discuss a basic application of Stone’s Theorem 23.2 on groups of
unitary operators. As we had argued earlier, the Hilbert space of an elementary
localizable particle in one dimension is the separable Hilbert space L2(R). The
translation of elements f ∈L2(R) is described by the unitary operators U(a),
a ∈R: (U(a)f )(x) = fa(x) = f (x −a). It is not difﬁcult to show that this
one-parameter group of unitary operators acts strongly continuous on L2(R): One
shows lima−→0 ∥fa −f ∥2 = 0. Now Stone’s theorem applies. It says that this group
is generated by a self-adjoint operator P which is deﬁned on the domain
D =
+
f ∈L2(R) : lim
a−→0
1
a (fa −f )
exists in L2(R)
,
by
Pf = 1
i lim
a−→0
1
a (fa −f )
∀f ∈D.
The domain D is known to be D = W 1(R) ≡

f ∈L2(R) : f ′ ∈L2(R)

and clearly
Pf = −if ′ = −i df
d x . This operator P represents the momentum of the particle
which is consistent with the fact that P generates the translations:
U(a) = e −iaP .
As an illustration of the use of trace class operators and the trace functional we discuss
a general form of the Heisenberg uncertainty principle. Given a density matrix W
on a separable Hilbert space H, introduce the set
OW =

A ∈B(H) : A∗AW ∈B1(H)

and a functional on OW × OW,
(A, B) #→⟨A, B⟩W = Tr(A∗BW).
One shows (see Exercises) that this is a sesquilinear form on OW which is positive
semi-deﬁnite (⟨A, A⟩W ≥0), hence the Cauchy–Schwarz inequality applies, i.e.,
|⟨A, B⟩W| ≤

⟨A, A⟩W

⟨B, B⟩W
∀A, B ∈OW.
Now consider two self-adjoint operators such that all the operators AAW, BBW, AW,
BW, ABW, BAW are of trace class. Then the following quantities are well deﬁned:
A = A −⟨A⟩WI,
B = B −⟨B⟩WI
and then
△W(A) =

Tr(AAW) =

Tr(A2W) −⟨A⟩2
W,

390
26
Hilbert–Schmidt and Trace Class Operators
△W(B) =

Tr(BBW) =

Tr(B2W) −⟨B⟩2
W.
The quantity △W(A) is called the uncertainty of the observable ‘A’ in the state ‘W’.
Next calculate the expectation value of the commutator [A, B] = AB −BA. One
ﬁnds
Tr([A, B]W) = Tr([A, B]W) = Tr(ABW) −Tr(BAW) = ⟨A, B⟩W −⟨B, A⟩W
and by the above inequality this expectation value is bounded by the product of the
uncertainties:
|Tr([A, B]W)| ≤|⟨A, B⟩W + |⟨B, A⟩W| ≤△W(A)△W(B) + △W(B)△W(A).
Usually this estimate of the expectation value of the commutator in terms of the
uncertainties is written as
1
2|Tr([A, B]W)| ≤△W(A)△W(B)
and called the Heisenberg uncertainty relations (for the ‘observables’ A, B).
Actually in quantum mechanics many observables are represented by unbounded
self-adjoint operators. Then the above calculations do not apply directly and thus typ-
ically they are not done for a general density matrix as above but for pure states only.
Originally they were formulated by Heisenberg for the observables of position and
momentum, represented by the self-adjoint operators Q and P with the commutator
[Q, P ] ⊆iI and thus on suitable pure states ψ the famous version
1
2 ≤△ψ(Q)△ψ(P)
of these uncertainty relations follows.
26.6
Exercises
1. Using Theorem 26.3, determine the form of the adjoint of a trace class operator
A on H explicitly.
2. For a Hilbert–Schmidt operator K with kernel k ∈L2(Rn × Rn), show that
T r(K∗K) =

Rn

Rn k(x, y)k(x, y) dxdy.
3. Prove that statements e.–g. in the second part of Theorem 26.6 are equivalent to
the corresponding statements b.–d..
4. Show: If Aj ∈B1(H), j = 1, 2, . . ., N then
Tr (A1A2 · · · AN) = Tr (A2 · · · ANA1) = Tr (ANA1A2 · · · AN−1)
and in general no further permutations are allowed.

References
391
5. Prove the characterization (26.35) of a density matrix W.
Hints: One can use W ∗= W = |W| =
√
W ∗W and the explicit representation
of the adjoint of a trace class operator (see the previous problem).
6. Show:A density matrix W on a Hilbert space H represents a vector state, i.e., can
be written as the projector Pψ onto the subspace generated by a vector ψ ∈H
if, and only if, W 2 = W.
7. Show: If a bounded linear operator A has the representation (26.5), then its
absolute value is given by
|A|x =

n
|λn|⟨en, x⟩en,
x ∈H.
8. Prove that (26.17) deﬁnes a continuous linear functional on B(H), under the
assumption stated with this formula.
9. Prove Formula (26.18).
10. Prove: The partial trace TrH2 maps density matrices on H1 ⊗H2 to density
matrices on H1.
References
1. Blanchard Ph, Brüning E. Mathematical methods in physics—distributions, Hilbert space oper-
ators and variational methods. vol. 26 of Progress in Mathematical Physics. Boston: Birkhäuser;
2003.
2. Blanchard Ph, Brüning E. Reply to “Comment on ‘Remarks on the structure of states of
composite quantum systems and envariance’ [Phys. Lett. A 355 (2006)180]”. Phys Lett A.
2011;375:1163–5. ([Phys. Lett. A 375 (2011) 1160]).
3. Davies EB. Linear Operator and their Sprectra. vol. 106 of Cambridge studies in advanced
mathematics. Cambridge: Cambridge University Press; 2007.
4. Haroche S, Raimond JM. Exploring the quantum: atoms, cavities, and photons. Oxford Graduate
Texts. Oxford: Oxford University Press; 2006.
5. Jauch JM. Foundations of quantum mechanics. Reading: Addison-Wesley; 1973.
6. Isham CJ. Lectures on quantum theory: mathematical and structural foundations. London:
Imperial College Press; 1995.
7. Rudin W. Functional analysis. New York: McGraw Hill; 1973.
8. Takesaki M. Theory of operator algebras I.Vol. 124 of encyclopedia of mathematical sciences—
operator algebras and non-commutative geometry. Berlin: Springer; 2002.

Chapter 27
The Spectral Theorem
Recall: Every symmetric N × N matrix A (i.e., every symmetric operator A in the
Hilbert space CN) can be transformed to diagonal form, that is there are real numbers
λ1, . . . , λN and an orthonormal system {e1, . . . , eN} in CN such that Aek = λkek,
k = 1, . . . , N. If Pk denotes the projector onto the subspace C ek spanned by the
eigenvector ek, we can represent the operator A in the form
A =
N

k=1
λkPk.
In this case, the spectrum of the operator A is σ(A) = {λ1, . . . , λN} where we use the
convention that eigenvalues of multiplicity larger than one are repeated according to
their multiplicity. Thus, we can rewrite the above representation of the operator A as
A =

λ∈σ(A)
λ Pλ,
(27.1)
where Pλ is the projector onto the subspace spanned by the eigenvector corresponding
to the eigenvalue λ ∈σ(A). The representation (27.1) is the simplest example of the
spectral representation of a self-adjoint operator.
We had encountered this spectral representation also for self-adjoint operators in
an inﬁnite dimensional Hilbert space, namely for the operator A deﬁned in Eq. (24.9)
for real sj, j ∈N. There we determined the spectrum as σ(A) =

sj : J ∈N

. In
this case too the representation (24.9) of the operator A can be written in the form
(27.1).
Clearly the characteristic feature of these two examples is that their spectrum
consists of a ﬁnite or a countable number of eigenvalues. However, we have learned
that there are examples of self-adjoint operators which have not only eigenvalues but
also a continuous spectrum (see the second example in Sect. 24.2). Accordingly, the
general form of a spectral representation of self-adjoint operators must also include
the possibility of a continuous spectrum and therefore one would expect that the
general form of a spectral representation is something like
A =

σ(A)
λ dPλ.
(27.2)
© Springer International Publishing Switzerland 2015
393
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_27

394
27
The Spectral Theorem
It is the goal of this chapter to give a precise meaning to this formula and to prove it
for arbitrary self-adjoint operators in a separable Hilbert space. That such a spectral
representation is possibleandhowthisrepresentationhastobeunderstoodwasshown
in 1928 by J. von Neumann. Later several different proofs of this “spectral theorem”
were given. We present a version of the proof which is not necessarily the shortest one
but which only uses intrinsic Hilbert space arguments. Moreover, this approach has
the additional advantage of giving another important result automatically, namely this
proof allows us to determine the “maximal self-adjoint part” of any closed symmetric
operator. Furthermore, it gives a concrete deﬁnition of the projectors Pλ as projectors
onto subspaces which are deﬁned explicitly in terms of the given operator. This proof
is due to Lengyel and Stone for the case of bounded self-adjoint operators (1936). It
was extended to the general case by Leinfelder in 1979 [1].
The starting point of this proof is the so-called “geometric characterization of
self-adjointness.” It is developed in the ﬁrst section. The second section will answer
the following questions: What does dPλ mean and what type of integration is used
in formula (27.2)? Finally, using some approximation procedure and the results of
the preceding sections, the proof of the spectral theorem and some other conclusions
are given in the third section.
27.1
Geometric Characterization of Self-Adjointness
27.1.1
Preliminaries
Lemma 27.1
Suppose A is a closed symmetric operator with domain D, in a
complex Hilbert space H, and (Pn)n∈N a sequence of orthogonal projectors with the
following properties:
a) Pn ≤Pn+1,
b) ran Pn ⊆D,
c) APn = PnAPn
for all n ∈N,
and d) limn→∞Pnx = x for all x ∈H. Then
D = {x ∈H : (APnx)n∈N converges in H}
(27.3)
= {x ∈H : ( ∥APnx| )n∈N converges in R}
(27.4)
and for all x ∈D,
Ax = lim
n→∞APnx
in H.
(27.5)
Proof Condition a) and Lemma 23.1 imply PmPn = Pn for all m ≥n. Therefore,
by an elementary calculation using condition c) and the symmetry of A, one ﬁnds
⟨APmx, APnx⟩= ⟨APnx, APnx⟩= ⟨APnx, APmx⟩
∀m ≥n, ∀x ∈H,
and similarly
⟨Ax, APn⟩= ⟨APnx, APn⟩= ⟨APnx, Ax⟩
∀n, ∀x ∈D.

27.1
Geometric Characterization of Self-Adjointness
395
Evaluating the norm in terms of the inner product gives
∥APmx −APnx∥2 = ∥APmx∥2 −∥APnx∥2
∀m ≥n, ∀x ∈H
(27.6)
and
∥Ax −APnx∥2 = ∥Ax∥2 −∥APnx∥2
∀n, ∀x ∈D.
(27.7)
Equation (27.6) shows that the sequence (APnx)n∈N converges in H if, and only if,
the sequence ( ∥APnx∥)n∈N converges in R. Thus, the two domains (27.3) and (27.4)
are the same.
Now assume x ∈H and (APnx)n∈N converges. Condition d) and the fact that A
is closed imply x ∈D and Ax = limn→∞APnx. Hence, x belongs to the set (27.3).
Conversely assume x
∈
D. The identities (27.6) and (27.7) imply that
( ∥APnx∥)n∈N is a monotone increasing sequence which is bounded by ∥Ax∥. We
conclude that this sequence converges and the above characterization of the domain
D of A is established.
The identity (27.5) results from the characterization (27.3) of the domain and the
fact that A is closed.
2
Lemma 27.2
Suppose H is a ﬁnite dimensional Hilbert space and F is a linear
subspace of H. For a given symmetric operator A on H deﬁne the function f (x) =
⟨x, Ax⟩and denote μ = inf {f (x) : x ∈F, ∥x∥= 1}. Then μ is an eigenvalue of A
and the corresponding eigenvector e0 satisﬁes f (e0) = μ.
Proof f is a continuously differentiable function on H with derivative f ′(x) = 2Ax,
since A is symmetric (see Chap. 30). The set {x ∈F : |x| = 1} is compact and hence
f attains its minimum on this set. This means that there is e0 ∈F, ∥e0∥= 1 such
that f (e0) = μ > −∞.
This is a minimization problem with constraint, namely to minimize the values
of the function f on the subspace F under the constraint g(x) = ⟨x, x⟩= 1. The
theorem about the existence of a Lagrange multiplicator (see Theorem 35.2) implies:
There is an r ∈R such that f ′(e0) = rg′(e0). The derivative of g is g′(x) = 2x,
hence f ′(e0) = re0 and therefore f (e0) = ⟨e0, Ae0⟩= r⟨e0, e0⟩= r. The Lagrange
multiplier r is equal to the minimum and we conclude.
2
27.1.2
Subspaces of Controlled Growth
Given a closed symmetric operator A in an inﬁnite dimensional Hilbert space H, we
introduce and characterize a certain family of subspaces on which the operator A
grows in a way determined by the characteristic parameter of the subspace. To begin,
we introduce the subspace of those elements on which any power of the operator can
be applied
D∞= D∞(A) = ∩n∈ND(An).
(27.8)

396
27
The Spectral Theorem
This means Anx ∈H for all x ∈D∞. For every r > 0 deﬁne a function qr : D∞→
[0, ∞] by
qr(x) = sup
n∈N
r−n --Anx
--
∀x ∈D.
(27.9)
This function has the following properties:
qr(αx) = |α|qr(x),
qr(x + y) ≤qr(x) + qr(y)
∀x, y ∈D∞, ∀α ∈C.
Therefore, for every r > 0, the set
G(A, r) =

x ∈∞: qr(x) < ∞

is a linear subspace of H. For r = 0 we use G(A, 0) = N(A). Next the subsets of
controlled growth are introduced. For r ≥0 denote
F(A, r) =

x ∈D∞:
--Anx
-- ≤rn ∥x∥, ∀n ∈N

.
(27.10)
The most important properties of these sets are described in
Lemma 27.3 For a closed symmetric operator A in the complex Hilbert space H
the subsets F(A, r) and G(A, r) are actually closed subspaces of H which satisfy
a) F(A, r) = G(A, r) for all r ≥0
b) AF(A, r) ⊆F(A, r)
c) If B is a bounded operator on H which commutes with A in the sense that
BA ⊆AB, then, for all r ≥0
BF(A, r) ⊆F(A, r),
B∗F(A, r)⊥⊆F(A, r)⊥.
(27.11)
Proof From the deﬁnition of these sets the following is evident: G(A, r) is a linear
subspace which contains F(A, r). The set F(A, r) is invariant under scalar multipli-
cation but it is not evident that the sum of two of its elements again belongs to it.
Therefore, in a ﬁrst step, we show the equality of these two sets.
Suppose that there is a z ∈G(A, r) which does not belong to F(A, r). We can
assume ∥z∥= 1. Then there is some m ∈N such that ∥Amz∥> rm ∥z∥. Introduce
the auxiliary operator S = r−mAm. It is again symmetric and satisﬁes ∥Sz∥> 1. For
every j ∈N we estimate
--Sjz
--2 = ⟨z, S2jz⟩≤
--S2jz
--, hence
---S2j z
--- ≥∥Sz∥2j →
∞as j →∞, but this contradicts z ∈G(A, r), i.e.,
---S2j z
--- ≤qr(z) < ∞. Hence
both sets are equal and part a) holds.
For x ∈G(A, r) the obvious estimate qr(Ax) ≤rqr(x) holds and it implies that
G(A, r) = F(A, r) is invariant under the operator A, thus part b) holds.
Next, we prove that this subspace is closed. Given y0 ∈F(A, r) there is a sequence
(xn)n∈N ⊂F(A, r)suchthaty0 = limn→∞xn. SinceF(A, r)isalinearsubspace, xn−
xm ∈F(A, r) for all n, m ∈N and therefore
--Ajxn −Ajxm
-- =
--Aj(xn −xm)
-- ≤
rj ∥xn −xm∥for every j ∈N. This shows that (Ajxn)n∈N is a Cauchy sequence

27.1
Geometric Characterization of Self-Adjointness
397
in H for every j. Therefore, these sequences have a limit in the Hilbert space:
yj = limn→∞Ajxn, j = 0, 1, 2, . . . .
Now observe (xn)n∈N ⊂F(A, r) ⊂D(A) and the operator A is closed. Therefore,
the identities yj = limn→∞Ajxn for j = 0 and j = 1 imply: y0 ∈D(A) and
y1 = Ay0. Because of part b) we know F(A, r) to be invariant under A, hence
Ajxn ∈F(A, r) for all n, j ∈N. Hence, a proof of induction with respect to j
applies and proves
yj ∈D(A),
yj = Ajy0,
j = 0, 1, 2, . . . .
We deduce y0 ∈D∞and
--Ajy0
-- = lim
n→∞
--Ajxn
-- ≤lim sup rj
n→∞
∥xn∥= rj ∥y0∥
∀j ∈N.
It follows that y0 ∈F(A, r) and this subspace is closed.
If B is a bounded operator on H which commutes with A in the sense of BA ⊆AB
we know AnBx = BAnx for all x ∈G(A, r) and all n ∈N and therefore qr(Bx) ≤
|B| qr(x) for every r > 0, hence BG(A, r) ⊆G(A, r) for r > 0. For r = 0 the
subspace G(A, 0) is by deﬁnition the null space of A which is invariant under B
because of the assumed commutativity with A, therefore BG(A, r) ⊆G(A, r) for
all r ≥0.
Finally suppose x ∈G(A, r)⊥. For all y ∈G(A, r) we ﬁnd ⟨B∗x, y⟩= ⟨x, By⟩=
0, since BG(A, r) ⊆G(A, r), and therefore B∗x ∈G(A, r)⊥. This proves part
c).
2
The restriction of the operator A to the closed subspace F(A, r) is bounded by r,
∥Ax∥≤r ∥x∥for all x ∈F(A, r). Hence the family of closed subspaces F(A, r),
r ≥0 controls the growth of the operator A. It does so actually rather precisely
since there are also lower bounds characterized by this family as we are going to
show. These lower bounds are deduced in two steps: First they are shown for ﬁnite
dimensional subspaces. Then an approximation lemma controls the general case.
Lemma 27.4 For a symmetric operator A in a ﬁnite dimensional complex Hilbert
space H one has for all r ≥0 and all x ∈F(A, r)⊥, x ̸= 0:
∥Ax∥> r ∥x∥
and
⟨x, Ax⟩> r ∥x∥2
if
A ≥0.
Proof The proof for the general case will be reduced to that of a positive operator.
So we start with the case A ≥0. Denote S1 = {x ∈H : ∥x∥= 1} and consider the
function f (x) = ⟨x, Ax⟩. Since S1 ∩F(A, r)⊥is compact f attains its minimum
μ = inf

f (x) : x ∈S1 ∩F(A, r)⊥
on this set, i.e., there is an e0 ∈S1 ∩F(A, r)⊥
such that f (e0) = μ. By Lemma 27.2 the minimum μ is an eigenvalue of A and
e0 is the corresponding eigenvector: Ae0 = μe0. This proves e0 ∈F(A, μ). If we
had μ ≤r, then F(A, μ) ⊂F(A, r) and thus e0 ∈F(A, r) ∩F(A, r)⊥= {0}, a
contradiction since ∥e0∥= 1. Hence, the minimum must be larger than r: μ > r.
The lower bound is now obvious: For x ∈F(A, r)⊥, x ̸= 0, write ⟨x, Ax⟩=
∥x∥2 ⟨y, Ay⟩with y ∈S1 ∩F(A, r)⊥, thus ⟨x, Ax⟩≥∥x∥2 μ > r ∥x∥2 which is
indeed the lower bound of A for A ≥0.

398
27
The Spectral Theorem
Since A is symmetric it leaves the subspaces F(A, r) and F(A, r)⊥invariant.
It follows that the restriction B = A|F(A,r)⊥is a symmetric operator F(A, r)⊥→
F(A, r)⊥which satisﬁes ∥Ax∥2 = ⟨x, B2x⟩for all x ∈F(A, r)⊥. As above we
conclude that
μ2 = inf
∥Ax∥2 : x ∈S(r)

= inf

⟨x, B2x⟩: x ∈S(r)

is an eigenvalue of B2 (we use the abbreviation S(r) = S1 ∩F(A, r)⊥). Elementary
rules for determinants say
0 = det (B2 −μ2I) = det (B −μI) det (B + μI)
and therefore either +μ or −μ is an eigenvalue of B. As above we prove |μ| > r
and for x ∈F(A, r)⊥, x ̸= 0, write ∥Ax∥= ∥x∥∥Ay∥with y ∈S(r) and thus
∥Ax∥≥∥x∥|μ| > r |x|.
2
Lemma 27.5
Let A be a closed symmetric operator in a complex Hilbert space
H. Introduce the closed subspace of controlled growth F(A, r) as above and choose
any 0 ≤r < s. Then, for every given x ∈F(A, s) ∩F(A, r)⊥there are a sequence
(Hn)n∈N of ﬁnite dimensional subspaces of H, a sequence of symmetric operators
An : Hn →Hn, and a sequence of vectors xn ∈Hn, n ∈N, such that
xn ∈F(An, s) ∩F(An, r)⊥
∀n ∈N,
lim
n→∞∥x −xn∥= 0 = lim
n→∞∥Ax −Anxn∥.
Proof According to Lemma 27.3 the subspaces F(A, s) and F(A, r)⊥are invariant
under the symmetric operator A. Therefore, given x ∈F(A, s) ∩F(A, r)⊥⊂D∞,
we know that
Hn = Hn(x) = [x, Ax, . . . , Anx] ⊆F(A, s) ∩F(A, r)⊥⊂D∞.
Clearly the dimension of Hn is smaller than or equal to n + 1. From Lemma 27.3,
we also deduce
Hn ⊆Hn+1 ⊆H∞= ∪n∈NHn ⊆F(A, s) ∩F(A, r)⊥.
Introduce the orthogonal projectors Pn onto Hn and P onto H∞and observe
limn→∞Pny = Py for every y ∈H. Next, we deﬁne the reductions of the op-
erator A to these subspaces: An = (PnAPn)|Hn. It follows that An is a symmetric
operator on Hn and if A ≥0 is positive so is An.
We prepare the proof of the approximation by an important convergence property
of the reduced operators An:
lim
n→∞(PnAPn)jy = (PAP)jy
∀j ∈N,
∀y ∈H.
(27.12)

27.1
Geometric Characterization of Self-Adjointness
399
Equation (27.12) is shown by induction with respect to j. Since H∞⊆F(A, s) ⊆
D∞we know Py ∈D∞and thus
∥PAPy −PnAPny∥≤∥(P −Pn)APy∥+ ∥PnA(Py −Pny)∥
≤∥(P −Pn)APy∥+ ∥A(Py −Pny)∥
≤∥(P −Pn)APy∥+ s ∥(Py −Pny)∥.
Since ∥(P −Pn)z∥→0 as n →∞, Eq. (27.12) holds for j = 1. Now suppose that
Eq. (27.12) holds for all j ≤k for some k ≥1. Then we estimate as follows:
--(PAP)k+1y −(PnAPn)k+1y
--
=
--(PnAPn)[(PAP)k −(PnAPn)k]y + (PAP −PnAPn)(PAP)ky
--
≤
--(PnAPn)[(PAP)k −(PnAPn)k]y
-- +
--(PAP −PnAPn)(PAP)ky
--
≤s
--[(PAP)k −(PnAPn)k]y
-- +
--(PAP −PnAPn)(PAP)ky
-- .
As n →∞the upper bound in this estimate converges to zero, because of our
induction hypothesis. Therefore, Eq. (27.12) follows for all j.
After these preparations the main construction of the approximations can be done.
Since H∞is invariant under the operator A, Eq. (27.12) implies for all y ∈H∞,
lim
n→∞(PnAPn)jy = (PAP)jy = Ajy
∀j ∈N.
(27.13)
The given x ∈F(A, s)∩F(A, r)⊥satisﬁes x ∈Hn for all n ∈N. Thus, we can project
it onto the subspaces F(An, r) ≡F(A, r) ∩Hn and their orthogonal complement:
x = xn ⊕yn,
xn ∈F(An, r)⊥,
yn ∈F(An, r),
∀n ∈N.
Since ∥x∥2 = ∥xn∥2 + ∥yn∥2 the sequence (yn)n∈N contains a weakly convergent
subsequence (yn(i))i∈N with a limit denoted by y. Since all elements of the subse-
quence belong to the space H∞which is strongly closed and thus weakly closed, this
weak limit y belongs to H∞⊂F(A, s) ∩F(A, r)⊥. We are going to show y = 0 by
showing that this weak limit y also belongs to F(A, r).
For any k ∈N, Eq. (27.13) implies
--Aky
--2 = ⟨y, A2ky⟩= lim
n→∞⟨y, (PnAPn)2ky⟩= lim
i→∞⟨y, (Pn(i)APn(i))2kyn(i)⟩,
since (Pn(i)APn(i))2ky converges strongly to A2ky and yn(i) weakly to y. We can estimate
now as follows, using yn(i) ∈F(An(i), r):
--Aky
--2 ≤lim sup
i→∞
∥y∥
--(Pn(i)APn(i))2kyn(i)
 ≤lim sup
i→∞
∥y∥r2k --yn(i)
-- ≤r2k ∥y∥∥x∥,
hence y ∈F(A, r), and we conclude y = 0.

400
27
The Spectral Theorem
Finally, we can establish the statements of the lemma for the sequence (xn(i))i∈N
corresponding to the weakly convergent subsequence (yn(i))i∈N. For simplicity of notation
we denote these sequences (xn)n∈N, respectively (yn)n∈N. The elements xn have been
deﬁned as the projections onto F(An, r)⊥⊂Hn ⊂F(A, s). Hence, the ﬁrst part of the
statement follows, since Hn ∩F(A, s) = F(An, s). Note ∥x −xn∥2 = ⟨x −xn, yn⟩=
⟨x, yn⟩andrecallthatthesequence(yn)n∈N convergesweaklytozero, thus∥x −xn∥2 →0
as n →∞. According to the construction of the spaces Hn, the elements x, Ax are
contained in them, thus the identity Ax = PnAPnx holds automatically. This gives the
estimate
∥Ax −Anxn∥= ∥Anx −Anxn∥= ∥(PnAPn)(x −xn)∥≤s ∥x −xn∥,
and the approximation for the operator A follows.
2
The combination of the two last lemmas allows us to control the growth of the
operator A on the family of subspaces F(A, r), r ≥0.
Theorem 27.1 Let A be a closed symmetric operator on the complex Hilbert space
H and introduce the family of subspaces F(A, r), r ≥0 according to Eq. (27.10).
Choose any two numbers 0 ≤r < s. Then for every x ∈F(A, s) ∩F(A, r)⊥the
following estimates hold:
r ∥x∥≤∥Ax∥≤s ∥x∥
and
r ∥x∥2 ≤⟨x, Ax⟩≤s ∥x∥2
if
A ≥0. (27.14)
Proof
If x ∈F(A, s) ∩F(A, r)⊥, approximate it according to Lemma 27.5 by
elements xn ∈F(An, s) ∩F(An, r)⊥and the operator A by symmetric operators An
in the ﬁnite dimensional Hilbert space Hn. Now apply Lemma 27.4 to get, for all
n ∈N,
r ∥xn∥≤∥Anxn∥
and
r ∥xn∥2 ≤⟨xnAnxn⟩
if
A ≥0.
To conclude, take the limit n →∞in these estimates which is possible by Lemma
27.5.
2
The family of subspaces F(A, r), r ≥0, thus controls the growth of the operator A
with considerable accuracy (choose r < s close to each other). This family can also
be used to decide whether the operator A is self-adjoint.
Theorem 27.2 (Geometric Characterization of Self-Adjointness) A closed sym-
metric operator A in a complex Hilbert space H is self-adjoint if, and only
if,

n∈N
F(A, n)
is dense in H. Here the subspaces of controlled growth F(A, n) are deﬁned in
Eq. (27.10).
Proof According to Lemma 27.3 the closed subspaces F(A, n) satisfy F(A, n) ⊆
F(A, n+1) for all n ∈N, hence their union is a linear subspace too. Denote by Pn the
orthogonal projector onto F(A, n). It follows that (Pn)n∈N is a monotone increasing

27.1
Geometric Characterization of Self-Adjointness
401
family of projectors on H. Thus, if 
n∈N F(A, n) is assumed to be dense in H this
sequence of projectors converges strongly to the identity operator I. In order to show
that the closed symmetric operator A is self-adjoint it sufﬁces to show that the domain
D(A∗) of the adjoint A∗is contained in the domain D(A) of the operator A.
Consider any x ∈D(A∗). Since Pn projects onto F(A, n) ⊂D(A) ⊂D(A∗),
we can write A∗x = A∗(x −Pnx) + A∗Pnx = A∗(I −Pn)x + APnx. Since the
subspace F(A, n) is invariant under A and since I −Pn projects onto F(A, n)⊥, one
has ⟨A∗(I −Pn)x, APnx⟩= ⟨(I −Pn)x, A2Pnx⟩= 0. This implies
--A∗x
--2 =
--A∗(I −Pn)x
--2 + ∥APnx∥2 .
Therefore, the sequence (APnx)n∈N is norm bounded, and thus there is a weakly
convergent subsequence (APn(i)x)i∈N. Since (Pn(i)x)i∈N is weakly convergent too
and since an operator is closed if, and only if, it is weakly closed, we conclude that
the weak limit x of the sequence (Pn(i)x)i∈N belongs to the domain D(A) of A and
the sequence (APn(i)x)i∈N converges weakly to Ax. This proves D(A∗) ⊆D(A) and
thus self-adjointness of A.
Conversely assume that the operator A is self-adjoint. We assume in addition that
A ≥I. In this case, the proof is technically much simpler. At the end we comment
on the necessary changes for the general case which uses the same basic ideas. As
we know the space ∪n∈NF(A, n) is dense in H if, and only if,
( ∪n∈N F(A, n))⊥= ∩n∈NF(A, n)⊥= {0} .
The assumption A ≥I implies that A−1 is a bounded self-adjoint operator H →
D(A) which commutes with A. Form the spaces F(A−1, r), r ≥0. Lemma 27.3
implies that A−1 maps the closed subspace Hr = F(A−1, r−1)⊥into itself. Hence,
Br = (A−1)|Hr is a well-deﬁned bounded linear operator on Hr. Theorem 27.1 applies
to the symmetric operator Br. Therefore, for all x ∈F(A−1, r−1)⊥∩F(A−1, s),
s = ∥Br∥, the lower bound ∥Brx∥=
--A−1x
-- ≥1
r ∥x∥is available. We conclude that
Br : Hr →Hr is bijective. Hence for every x0 ∈Hr there is exactly one x1 ∈Hr such
that x0 = Brx1 = A−1x1. This implies x0 ∈D(A) and x1 = Ax0 ∈Hr. Iteration of
thisargumentproducesasequencexn = Anx0 ∈Hr∩D(A) = F(A−1, r−1)⊥∩D(A),
n ∈N.This implies x0 ∈D∞and ∥xn∥=
--A−1xn+1
-- ≥r−1 ∥xn+1∥= r−1 ∥Axn∥,
hence ∥Axn∥≤rn ∥x0∥for all n ∈N, or x0 ∈F(A, r) and thus
F

A−1, r−1⊥⊂F (A, r)
∀r > 0.
This holds in particular for r = n ∈N, hence

n∈N
F(A, n)⊥⊆

n∈N
F

A−1, 1
n

= N

A−1
= {0} .
This concludes the proof for the case A ≥I.
Now we comment on the proof for the general case. For a self-adjoint operator
A the resolvent RA(z) = (A −zI)−1 : H →D(A) is well deﬁned for all z ∈C\R.

402
27
The Spectral Theorem
Clearly, the resolvent commutes with A and is injective. In the argument given
above replace the operator A−1 by the operator B = RA(z)∗RA(z) = RA(z)RA(z).
This allows us to show, for all r > 0,
F(B, r)⊥⊆F(A, |z| + 1
r ∥RA(z)∥).
Now, for n > |z| denote rn =
1
n−|z| ∥RA(z)∥, then F(B, rn)⊥⊂F(A, n) and therefore

n>|z|
F(A, n)⊥⊂

n>|z|
F(B, rn) = N(B) = {0} ,
and we conclude as in the case A ≥I.
2
27.2
Spectral Families and Their Integrals
In Proposition 23.1, we learned that there is a one-to-one correspondence between
closed subspaces of a Hilbert space and orthogonal projections. In the previous
section, the family of subspaces of controlled growth were introduced for a closed
symmetric operator A. Thus, we have a corresponding family of orthogonal projec-
tions on the Hilbert space which will ﬁnally lead to the spectral representation of
self-adjoint operators. Before this can be done the basic theory of such families of
projectors and their integrals have to be studied.
27.2.1
Spectral Families
The correspondence between a family of closed subspaces of a complex Hilbert space
and the family of projectors onto these subspaces is investigated in this section in
some detail. Our starting point is
Deﬁnition 27.1
Let H be a complex Hilbert space and E a function on R with
values in the space P(H) of all orthogonal projection operators on H. E is called
a spectral family on H or resolution of the identity if, and only if, the following
conditions are satisﬁed.
a) E is monotone: EtEs = Et∧s for all t, s ∈R, where t ∧s = min {t, s}
b) E is right continuous with respect to the strong topology, i.e.,
lims→t, s>t ∥Esx −Etx∥= 0 for all x ∈H and all t ∈R
c) E is normalized, i.e., limt→−∞Etx = 0 and limt→+∞Etx = x for every x ∈H.
The support of a spectral family E is supp E = {t ∈R : Et ̸= 0, Et ̸= I}.

27.2
Spectral Families and Their Integrals
403
Given a spectral family E on H we get a family of closed subspaces Ht of H by
deﬁning
Ht = ran Et,
∀t ∈R.
In the following proposition the deﬁning properties a)–(c) of a spectral family are
translated into properties of the family of associated closed subspaces.
Proposition 27.1 Let {Et}t∈R be a spectral family on H. Then the family of closed
subspaces Ht = ran Et has the following properties:
a) Monotonicity: Hs ⊆Ht for all s ≤t
b) Right continuouity: Hs = ∩t>sHt
c) Normalization: ∩t∈RHt = {0} and ∪t∈RHt = H
Conversely, given a family of closed subspaces Ht, t ∈R, of H with the properties
a)–c) then the family of orthogonal projectors Et onto Ht, t ∈R, is a spectral family
on H.
Proof The monotonicity condition a) for the spectral family is easily translated into
that of the family of ranges Ht by Lemma 23.1. This implies Hs ⊆Ht for all s < t
and therefore Hs ⊆∩s<tHt. For any x ∈∩s<tHt we know Etx = x for all s < t,
hence x = limt→s,s<t Etx = Esx, i.e., x ∈ran Es = Hs since a spectral family is
right continuous. This proves b) for the family Ht, t ∈R.
The normalization for the spectral family limt→∞Etx = x for all x ∈H implies
immediately that the closure of the union of all the subspaces Ht gives the whole
Hilbert space. Next consider x ∈∩t∈RHt, then x = Etx for all t ∈R and thus
x = limt→−∞Etx = 0 because of the normalization for the spectral family. This
proves the normalization for the family of subspaces Ht.
If a family of closed subspaces Ht, t ∈R, with the properties a)–c) is given,
deﬁne a family of orthogonal projectors by deﬁning Et as the orthogonal projector
onto the subspace Ht for all t ∈R. Suppose s ≤t, then Hs ⊆Ht and Lemma 23.1
implies Es = EsEt = EtEs ≤Et and thus monotonicity of the family of projectors.
According to Theorem 23.1, a monotone increasing family of projectors has a strong
limit which is again an orthogonal projector. Hence, for every x ∈H we know
limt→s,t>s Etx = Px for some orthogonal projector P on H. The condition b) for
the family of subspaces Ht implies
ran P = ∩t>sran Et = ∩t>sran Ht = Hs = ran Es,
thus P = Es by part d) of Proposition 23.1. Therefore, the function t #→Et ∈P(H)
is right continuous.
Since t #→Et is monotone the following strong limits exist (Theorem 23.1):
limt→−∞Et = Q−and limt→+∞Et = Q+ with ran Q−= ∩t>−∞ran Et =
∩t>−∞Ht = {0} and ran Q+ = ∪t∈Rran Et = ∪t∈RHt = H and again by Proposi-
tion 23.1 we conclude Q−= 0 and Q+ = I which are the normalization conditions
of a spectral family.
2

404
27
The Spectral Theorem
27.2.2
Integration with Respect to a Spectral Family
Given a spectral family Et on a complex Hilbert space H and a continuous function
f : [a, b] →R, we explain the deﬁnition and the properties of the integral of f with
respect to the spectral family:
 b
a
f (t)dEt.
(27.15)
The deﬁnition of this integral is done in close analogy to the Stieltjes integral. Ac-
cordingly we strongly recommend studying the construction of the Stieltjes integral
ﬁrst.
There is naturally a close connection of the Stieltjes integral with the integral
(27.15). Given any x ∈H deﬁne ρx(t) = ⟨x, Etx⟩for all t ∈R. Then ρx is a
monotone increasing function of ﬁnite total variation and thus a continuous function
f has a well-deﬁned Stieltjes integral
 b
a f (t)dρx(t) with respect to ρx and one ﬁnds
according to the deﬁnition of the integral (27.15)
 b
a
f (t)dρx(t) = ⟨x,
 b
a
f (t)dEtx⟩.
For a given spectral family Et on the complex Hilbert space H and any s < t
introduce
E(s, t] = Et −Es.
(27.16)
In the Exercises, we show that E(s, t] is an orthogonal projector on H with range
ran E(s, t] = Ht ∩H ⊥
s = Ht ⊖Hs.
Since a spectral family is not necessarily left continuous, the operator
P(t) =
lim
s→t,s<t E(s, t] = Et −Et−0
(27.17)
is in general a projector ̸= 0. Indeed, P(t) ̸= 0 if, and only if, Et is discontinuous at
t (for the strong topology). If (s1, t1] and (s2, t2] are two disjoint intervals, then
E(s1, t1]E(s2, t2] = 0.
(27.18)
A partition Z of the interval [a, b] is a decomposition of [a, b] into a ﬁnite number
of disjoint subintervals together with a choice of one point in each subinterval:
a = t0 < t1 < · · · < tn = b,
t′
j ∈(tj−1, tj],
j = 1, 2, . . . , n.
(27.19)

27.2
Spectral Families and Their Integrals
405
This is denoted as Z = Z(tj, t′
j, n). The number
|Z| = max

|tj −tj−1| : j = 1, . . . , n

is called the width of the partition Z. It is the length of the largest subinterval. Given
two partitions Z(tj, t′
j, n) and Z(si, s′
i, m) we can form their union
Z(tj, t′
j, n) ∨Z(si, s′
i, m) = Z(τk, τ ′
k, p)
where τ1, . . . , τp is an enumeration of the points {t1, . . . , tn, s1, . . . , sm} in their
natural order with the corresponding selection of τ ′
k ∈

t′
1, . . . , s′
m

. Obviously the
width of this union is smaller than or equal to the widths of the original partitions.
Thus this union is also called the joint reﬁnement of the two partitions.
For a partition Z = Z(tj, t′
j, n) of the interval [a, b] and a continuous function
f : [a, b] →R, form the sum
Σ(f , Z) =
n

j=1
f (t′
j)E(tj−1, tj].
(27.20)
Relation (27.18) implies E(tj−1, tj]E(ti−1, ti] = δijE(tj−1, tj] and thus for all x ∈H,
n

j=1
--E(tj−1, tj]x
--2 =
------
n

j=1
E(tj−1, tj]x
------
2
= ∥E(a, b]x∥2 ≤∥x∥2 .
(27.21)
Apply the identity (27.20) to any x ∈H. Then the orthogonality relation (27.18)
implies
∥Σ(f , Z)x∥2 =
n

j=1
|f (t′
j)|2 --E(tj−1, tj]x
--2
(27.22)
which according to the relation (27.21) leads to the estimate
∥Σ(f , Z)x∥≤sup {|f (t)| : t ∈[a, b]} ∥E(a, b]x∥.
(27.23)
This proves that Σ(f , Z) is a bounded linear operator on H. Now we study the limit
of these bounded operators when the partition Z gets ﬁner and ﬁner, i.e., the limit
|Z| →0. Suppose Z = Z(tj, t′
j, n) and Z′ = Z(si, s′
i, m) are two given partitions
and Z(τk, τ ′
k, p) is their joint reﬁnement, then, for any x ∈H,
Σ(f , Z)x −Σ(f , Z′)x =
n

j=1
f (t′
j)E(tj−1, tj]x −
m

i=1
f (s′
i)E(si−1, si]x
=
p

k=1
εkE(τk−1, τk]x,

406
27
The Spectral Theorem
where εk = ±[f (τ ′
k+1) −f (τ ′
k)], and because of the orthogonality of the projectors
E(τk−1, τk],
--Σ(f , Z)x −Σ(f , Z′)x
--2 =
p

k=1
|εk|2 ∥E(τk−1, τk]x∥2 .
Given any ε > 0, there is a δ > 0 such that |f (t) −f (s)| < ε whenever |s −t| ≤δ
since f is uniformly continuous. If the widths of the partitions Z, Z′ are both smaller
than or equal to δ, the width of their joint reﬁnement is also smaller than or equal to
δ and thus we can estimate
|εk| = |f (τ ′
k+1) −f (τ ′
k)| ≤|f (τ ′
k+1) −f (τk)| + |f (τk) −f (τ ′
k)| < 2ε,
since |τ ′
k+1 −τk| ≤δ and |τ ′
k −τk| ≤δ. As in estimate (27.21) we obtain
--Σ(f , Z)x −Σ(f , Z′)x
-- ≤2ε ∥E(a, b]x∥
(27.24)
and conclude that the bounded operators Σ(f , Z) have a strong limit as |Z| →0
and that this limit does not depend on the particular choice of the net of partitions Z
which is used in its construction. We summarize our results in
Theorem 27.3 Let Et, t ∈R, be a spectral family on the complex Hilbert space H
and [a, b] some ﬁnite interval. Then for every continuous function f : [a, b] →R
the integral of f with respect to the spectral family Et,
 b
a
f (t)dEt
(27.25)
is well deﬁned by
 b
a
f (t)dEtx = lim
|Z|→0 Σ(f , Z)x.
(27.26)
It is a bounded linear operator on H with the following properties:
a)
---
 b
a f (t)dEtx
--- ≤sup {|f (t)| : t ∈[a, b]} ∥E(a, b]x∥
∀x ∈H
b) f #→
 b
a f (t)dEt is linear on C([a, b]; R)
c) for every a < c < b:
 b
a f (t)dEt =
 c
a f (t)dEt +
 b
c f (t)dEt
d) (
 b
a f (t)dEt)∗=
 b
a f (t)dEt
e)
---
 b
a f (t)dEtx
---
2
=
 b
a |f (t)|2dρx(t)
for all x ∈H where ρx(t) = ⟨x, Etx⟩= ∥Etx∥2
Proof We have shown above that the limit (27.26) exists for every x ∈H. Taking
this limit in estimate (27.23) gives Property a). Since Σ(f , Z) is a bounded linear
operator on H we deduce that
 b
a f (t)dEt is a bounded linear operator. Properties b)–
d) follow from the corresponding properties of the approximations Σ(f , Z) which
are easy to establish. The details are left as an exercise.

27.2
Spectral Families and Their Integrals
407
The starting point for the proof of part e) is Eq. (27.22) and the observation
--E(tj−1, tj]x
--2 = ρx(tj) −ρx(tj−1),
which allows one to rewrite this equation as
∥Σ(f , Z)x∥2 =
n

j=1
|f (t′
j)|2[ρx(tj) −ρx(tj−1)].
Now in the limit |Z| →0 the identity of part e) follows since the right-hand side is
just the approximation of the Stieltjes integral
 b
a |f (t)|2dρx(t) for the same partition
Z.
2
Lemma 27.6 Suppose Et, t ∈R, is a spectral family in the complex Hilbert space
H and f : [a, b] →R a continuous function. Then for any s < t the integral
 b
a f (t)dEt commutes with the projectors E(s, t] and one has
E(s, t]
 b
a
f (u)dEu =
 b
a
f (u)dEuE(s, t] =

(a,b]∩(s,t]
f (u)dEu.
(27.27)
Proof Since E(s, t] is a continuous linear operator Eq. (27.26) implies
E(s, t]
 b
a
f (u)dEu = lim
|Z|→0 E(s, t]Σ(f , Z),
where Z denotes a partition of the interval [a, b]. The deﬁnition of these approximat-
ing sums gives E(s, t]Σ(f , Z) = E(s, t] n
j=1 f (t′
j)E(tj−1, tj]. Taking the deﬁning
properties of a spectral family into account we calculate
E(s, t]E(tj−1, tj] = E(tj−1, tj]E(s, t] = E((tj−1, tj] ∩(s, t]).
We deduce lim|Z|→0 E(s, t]Σ(f , Z) = lim|Z|→0 Σ(f , Z)E(s, t] and the ﬁrst identity
in Eq. (27.27) is established.
For the second identity some care has to be taken with regard to the interval to
which the partitions refer. Therefore, we write this explicitly in the approximating
sums Σ(f , Z) ≡Σ(f , Z, [a, b]) when partitions of the interval [a, b] are used. In
this way we write
Σ(f , Z)E(s, t] = Σ(f , Z, [a, b])E(s, t] =
n

j=1
f (t′
j)E(tj−1, tj]E(s, t]
=
n

j=1
f (t′
j)E((tj−1, tj] ∩(s, t]) = Σ(f , Z′, [a, b] ∩(s, t]),

408
27
The Spectral Theorem
where Z′ is the partition induced by the given partition Z on the subinterval [a, b] ∩
(s, t]. Clearly, |Z| →0 implies |Z′| →0 and thus
lim
|Z|→0 Σ(f , Z)E(s, t] = lim
|Z′|→0 Σ(f , Z′, [a, b] ∩(s, t]) =

(a,b]∩(s,t]
f (u)dEu
and we conclude.
2
For the spectral representation of self-adjoint operators and for other problems one
needs not only integrals over ﬁnite intervals but also integrals over the real line R
which are naturally deﬁned as the limit of integrals over ﬁnite intervals [a, b] as
a →−∞and b →+∞:
 ∞
−∞
f (t)dEtx = lim
b→+∞
a→−∞
 b
a
f (t)dEtx ≡lim
a,b
 b
a
f (t)dEtx
(27.28)
for all x ∈H for which this limit exists. The existence of this vector valued integral
is characterized by the existence of a numerical Stieltjes integral:
Lemma 27.7 Suppose Et, t ∈R, is a spectral family in the complex Hilbert space
H and f : R →R a continuous function. For x ∈H the integral
 ∞
−∞
f (t)dEtx
exists if, and only if, the numerical integral
 ∞
−∞
|f (t)|2d ∥Etx∥2
exists.
Proof The integral
 b
a f (t)dEtx has a limit for b →+∞if, and only if, for every
ε > 0 there is b0 such that for all b′ > b ≥b0,
-----
 b′
b
f (t)dEtx
-----
2
≤ε2.
Part e) of Theorem 27.3 implies
-----
 b′
b
f (t)dEtx
-----
2
=
 b′
b
|f (t)|2dρx(t),
where dρx(t) = d ∥Etx∥2. Thus, the vector valued integral has a limit for b →∞
if, and only if, the numerical, i.e., real valued integral does.
In the same way the limit a →−∞is handled.
2
Finally, the integral of a continuous real valued function on the real line with respect
to a spectral family is deﬁned and its main properties are investigated.

27.2
Spectral Families and Their Integrals
409
Theorem 27.4 Let Et, t ∈R, be a spectral family on the complex Hilbert space H
and f : R →R a continuous function. Deﬁne
D =
+
x ∈H :
 +∞
−∞
|f (t)|2d ∥Etx∥2 < ∞
,
(27.29)
=
+
x ∈H :
 +∞
−∞
f (t)dEtx exists
,
(27.30)
and on this domain D deﬁne an operator A by
Ax =
 +∞
−∞
f (t)dEtx
∀x ∈D.
(27.31)
Then this operator A is self-adjoint and satisﬁes
E(s, t]A ⊆AE(s, t]
∀s < t.
(27.32)
Proof According to Lemma 27.7, the two characterizations of the set D are equiv-
alent. The second characterization and the basic rules of calculation for limits show
that the set D is a linear subspace of H. In order to prove that D is dense in the
Hilbert space we construct a subset D0 ⊂D for which it is easy to show that it is
dense.
Denote Pn = En −E−n for n ∈N and recall the normalization of a spectral
family: Pnx = Enx −E−nx →x −0 as n →∞, for every x ∈H. This implies that
D0 = ∪n∈NPnH is dense in H. Now take any x = Pnx ∈D0 for some ﬁxed n ∈N.
In order to prove x ∈D we rely on the second characterization of the space D and
then have to show that lima,b
 b
a f (u)dEux exists in H. This is achieved by Lemma
27.6 and Theorem 27.3:
lim
a,b
 b
a
f (u)dEux = lim
a,b

(a,b]
f (u)dEuE( −n, n]x
= lim
a,b

(a,b]∩(−n,n]
f (u)dEux =

(−n,n]
f (u)dEux.
Since the last integral exists, x = Pnx belongs to the space D. We conclude that A
is a densely deﬁned linear operator.
Similarly, for x ∈D, Lemma 27.6 implies
PnAx = Pn lim
a,b
 b
a
f (u)dEux = lim
a,b Pn
 b
a
f (u)dEux = lim
a,b
 b
a
f (u)dEuPnx = APnx,
i.e., PnA ⊂APn and thus APn = PnAPn for all n ∈N. In the same way we can prove
relation (27.32).
For all x, y ∈D one has, using self-adjointness of
 b
a f (u)dEu according to part d)
of Theorem 27.3,
⟨x, Ay⟩= ⟨x, lim
a,b
 b
a
f (u)dEuy⟩= lim
a,b ⟨x,
 b
a
f (u)dEuy⟩

410
27
The Spectral Theorem
= lim
a,b ⟨
 b
a
f (u)dEux, y⟩= ⟨lim
a,b
 b
a
f (u)dEux, y⟩= ⟨Ax, y⟩,
hence A ⊂A∗and A is symmetric.
In order to prove that A is actually self-adjoint take any element y ∈D(A∗). Then
y∗= A∗y ∈H and A∗y = limn→∞PnA∗y. For all x ∈H we ﬁnd ⟨PnA∗y, x⟩=
⟨A∗y, Pnx⟩= ⟨y, APnx⟩= ⟨y, PnAPnx⟩= ⟨PnAPny, x⟩where we used Pnx ∈D, the
symmetry of A and the relation APn = PnAPn established earlier. It follows that
PnA∗y = PnAPny = APny
∀n ∈N.
According to the deﬁnition of the operator A and our earlier calculations, APny is
expressed as
APny =
 n
−n
f (u)dEuy
∀n ∈N.
The limit n →∞of this integral exists because of the relation APny = PnA∗y. The
second characterization of the domain D thus states y ∈D and therefore APny →Ay
as n →∞. We conclude that A∗y = Ay and A is self-adjoint.
2
27.3
The Spectral Theorem
Theorem 27.5 (Spectral Theorem) Every self-adjoint operator A on the complex
Hilbert space H has a unique spectral representation, i.e., there is a unique spectral
family Et = EA
t , t ∈R, on H such that
D(A) =
+
x ∈H :

R
t2d ∥Etx∥2 < ∞
,
,
Ax =

R
t dEtx
∀x ∈D(A).
(27.33)
Proof At ﬁrst we give the proof for the special case A ≥0 in detail. At the end the
general case is addressed by using an additional limiting procedure.
For the self-adjoint operator A ≥0 introduce the subspaces of controlled growth
F(A, t), t ≥, as in Eq. (27.10) and then deﬁne for t ∈R,
Ht =
⎧
⎨
⎩
F(A, t)
t ≥0,
{0}
t < 0.
(27.34)
According to Lemma 27.3, this is a family of closed linear subspaces of H where each
subspace is invariant under the operator A. We claim that this family of subspaces
satisﬁes conditions a)–c) of Proposition 27.1. Condition a) of monotonicity is evident
from the deﬁnition of the spaces Ht. Condition b) of right continuity Hs = ∩s<tHt
is obtained in the following way: By monotonicity we know F(A, s) ⊆∩s<tF(A, t)
for s ≥0. Conversely suppose that x ∈∩s<tF(A, t) ⊂D∞(A) is given; then

27.3
The Spectral Theorem
411
∥Anx∥≤tn ∥x∥for all t > s and all n ∈N and thus ∥Anx∥≤sn ∥x∥for all n ∈N,
i.e., x ∈F(A, s). For s < 0 this is trivial.
Finally, we prove the normalization condition c). ∩t∈RHt = {0} trivially holds
because of the deﬁnition (27.34). The second part of the normalization condition
∪t∈RHt = H
follows from the geometric characterization of self-adjointness, Theorem 27.2.
Now we can use Proposition 27.1 to deﬁne a spectral family Et, t ∈R, such that
ran Et = Ht
∀t ∈R.
(27.35)
In particular the choice t = n ∈N gives a sequence of projectors En with strong limit
I and with range Hn = F(A, n) ⊆D∞(A) which is invariant under the operator A.
It follows that EnA ⊆AEn, hence AEn = EnAEn and therefore the domain of A
is characterized by Lemma 27.1, i.e., x ∈D(A) ⇔(AEnx)n∈N converges in H ⇔
( ∥AEnx∥)n∈N converges in R and then
Ax = lim
n→∞AEnx
∀x ∈D(A).
Denote the restriction of the operator EnAEn to the invariant subspace Hn by An. An
is a self-adjoint positive operator for which we will show the spectral representation
with respect to the spectral family E(n)
t
= EtEn on Hn. Given a partition Z =
Z(tj, t′
j) of the interval [0, n] and x ∈Hn introduce the points xj = E(tj−1, tj]x ∈
F(An, tj)∩F(An, tj−1)⊥, j = 1, . . . , m. Since different subintervals of the partitions
are disjoint, x is the orthogonal sum of the points xj. Note also that the operator An
leaves the subspaces F(n, j) = F(An, tj) ∩F(An, tj−1)⊥invariant and that different
of these subspaces are orthogonal to each other. This implies
⟨x, Anx⟩=
m

j=1
⟨xj, Anxj⟩
and
∥Anx∥2 =
m

j=1
--Anxj
--2 .
Theorem 27.1 allows us to estimate ⟨xj, Anxj⟩and
--Anxj
--2 as follows:
tj−1
--xj
--2 ≤⟨xj, Anxj⟩≤tj
--xj
--2 ,
tj−1
--xj
-- ≤
--Anxj
-- ≤tj
--xj
-- .
These estimates hold for j = 1, . . . , m and therefore
⟨x, Anx⟩−
m

j=1
tj⟨xj, xj⟩| = |
m

j=1
[⟨xj, Anxj⟩−tj⟨xj, xj⟩]

≤
m

j=1
|⟨xj, Anxj⟩−tj⟨xj, xj⟩| ≤
m

j=1
(tj −tj−1)
--xj
--2 ≤|Z|
m

j=1
--xj
--2 ≤|Z| |x|2
and

∥Anx∥2−
m

j=1
t2
j
--xj
--2

=|
m

j=1
[
--Anxj
--2−t2
j
--xj
--2]|

412
27
The Spectral Theorem
≤
m

j=1
|
--Anxj
--2−t2
j
--xj
--|≤
m

j=1
(t2
j −t2
j−1)
--xj
--2 ≤2n|Z|
m

j=1
--xj
--2 ≤2n|Z| ∥x∥2 .
Since xj
=
E(tj−1, tj]x we have ∥xj∥2
=
ρx(tj) −ρx(tj−1) and thus
m
j=1 t2
j
--xj
--2 = Σ(t2, Z, ρx) is the approximating sum for the Stieltjes integral
 n
0 t2dρx(t). The above estimate implies
∥Anx∥2 = lim
|Z|→0 Σ(t2, Z, ρx) =
 n
0
t2dρx(t) =
 n
0
t2d∥Etx∥2
and similarly
⟨x, Anx⟩= lim
|Z|→0 Σ(t, Z, ρx) =
 n
0
t dρx(t) =
 n
0
t d⟨x, Etx⟩.
The polarization identity (see Proposition 15.2) implies ⟨y, Anx⟩=
 n
0 t d⟨y, Etx⟩
for all y ∈H and therefore
Anx =
 n
0
t dEtx
∀x ∈Hn.
Recall Anx = EnAEnx = AEnx for all x ∈Hn and thus the above calculations
show that
∥AEnx∥2 =
 n
0
t2d∥Etx∥2
AEnx =
 n
0
t dEtx
(27.36)
for all n ∈N and all x ∈H. For the sequence of projectors En the hypotheses
of Lemma 27.1 have been veriﬁed. Hence, x ∈D(A) if, and only if, AEnx has
a limit and if x ∈D(A) then the limit for n →∞is Ax. Therefore, the vector
valued integral
 n
0 t dEtx has a limit for n →∞, and we conclude by Eq. (27.36)
that Eq. (27.33) holds for the spectral family deﬁned by the family of subspaces of
controlled growth.
Finally, we show that there is only one spectral family which represents the self-
adjoint operator A according to Eq. (27.33) by showing: If E′
t, t ∈R, is a spectral
family on H which represents the operator A according to this equation, then
ranE′
t = F(A, t)
∀t ≥0.
Suppose x ∈ran E′
t for some t ≥0. Then x = E′
tx and thus E′
sx = E′
s∧t for all
s ≥0. Now calculate for any n ∈N,
∥Anx∥2 =
 ∞
0
s2nd∥E′
sx∥2 =
 ∞
0
s2nd∥E′
s∧tx∥2 =
 t
0
s2nd∥E′
sx∥2
≤t2n
 ∞
0
d∥E′
sx∥2 = t2n∥x∥2.

27.3
The Spectral Theorem
413
It follows that x ∈F(A, t) and thus ran E′
t ⊆F(A, t). Since F(A, 0) = N(A) it
sufﬁces to consider the case t > 0. Thus suppose t > 0 and x ∈F(A, t)∩ran (I −E′
t);
then x = (I −E′
t)x = limN→∞E′(t, N]x. As earlier we ﬁnd
AnE(t, N]x =
 ∞
0
sndE′
sE′(t, N]x =
 N
t
sndE′
sx
and therefore
∥Anx∥2 =
 ∞
t
s2nd∥E′
sx∥2 ≥t2n
 ∞
t
d∥E′
sx∥2 = t2n∥x∥2,
where in the last step x = (I −E′
t)x was taken into account. x ∈F(A, t) implies
∥Anx∥2 ≤t2n∥x∥2 for all n ∈N. We conclude ∥Anx∥2 = t2n∥x∥2 for all n ∈N.
In terms of the spectral family this reads
 ∞
t
(s2n −t2n)d∥E′
sx∥2 = 0, hence x =
(I −E′
t)x = 0 and ran E′
t = F(A, t) follows. This concludes the proof for the case
A ≥0.
Comments on the proof for the general case: a) If A is a lower bounded self-
adjoint operator, i.e., for some c ∈R one has A ≥−cI, then Ac = A + cI is
a positive self-adjoint operator for which the above proof applies and produces the
spectral representation Ac =

R t dEt. In the Exercises, we deduce the spectral
representation for the operator A itself.
b) The proof of the spectral representation of a self-adjoint operator A which is
not lower bounded needs an additional limit process which we indicate brieﬂy.
As in the case of lower bounded self-adjoint operators the subspaces of controlled
growth F(A, t) are well deﬁned and have the properties as stated in Lemma 27.3. In
particular for t = n ∈N we have closed subspaces of H which are contained in the
domain of A and which are invariant under the operator A. Hence, the orthogonal
projectors Pn onto these subspaces satisfy ran Pn ⊂D(A) and APn = PnAPn.
Furthermorebythegeometriccharacterizationofself-adjointness(Theorem27.2)the
union of the ranges of these projectors is dense in H and therefore limn→∞Pnx = x
for all x ∈H. Under the inner product of the Hilbert space H the closed subspaces
F(A, n) are Hilbert spaces too and An = A|F(A,n) is a self-adjoint operator which is
bounded from below: An + nI ≥0. Hence for the operator An our earlier results
apply.
In the Hilbert space F(A, n) deﬁne a spectral family En(t), t ∈R, by
ran En(t) =
⎧
⎨
⎩
{0}
t < −n,
F(An + nI, t + n)
−n ≤t.
Then the spectral representation for the operator An in the space F(A, n) reads
An =

R
tdEn(t).
(27.37)

414
27
The Spectral Theorem
This holds for each n ∈N. A suitable limit of the spectral families En( · ), n ∈N
will produce the spectral representation for the operator A. To this end one observes
Ek(t)Pn = En(t)Pn = PnEn(t) = En(t),
ran Ek([ −n, n]) = F(Ak, n) = F(A, n)
for all t ∈R, and all k ≥n and then proves that the sequence of spectral families En
has a strong limit E( · ) which is a spectral family in the Hilbert space H:
E(t)x = lim
n→∞En(t)x
∀x ∈H,
uniformly in t ∈R. And this spectral family satisﬁes E([ −n, n]) = Pn.
The spectral representation (27.37) implies for all x, y ∈H and all n ∈N and all
k ≥n,
⟨x, APny⟩= ⟨Pnx, AnPny⟩=

R
t d⟨Pnx, En(t)Pny⟩
=

R
t d⟨Pnx, Ek(t)Pny⟩=

[−n,n]
t d⟨x, E(t)y⟩
and similarly, for all x ∈H and all n ∈N
∥APnx∥2 =

[−n,n]
t2d⟨x, E(t)x⟩.
Finally, another application of Lemma 27.1 proves the spectral representation (27.33)
for the general case.
c) The proof that the spectral family is uniquely determined by the self-adjoint
operator A uses also in the general case the same basic idea as in the case of positive
self-adjoint operators. In this case, one proves (see Exercises): If a spectral family
E′ represents the self-adjoint operator A, then
ran E′(s, t] = F(A −s + t
2
I, t −s
2
)
for all s < t. Since projectors are determined by their range, uniqueness of the
spectral family follows.
2
27.4
Some Applications
For a closed symmetric operator A in the complex Hilbert space H we can form the
subspaces F(A, r), r ≥0, of controlled growth. These subspaces are all contained
in the domain D(A) and are invariant under the operator A. The closure of the union
M = ∪n∈NF(A, n) of these subspaces is a subspace H0 of the Hilbert space and

27.4
Some Applications
415
according to the geometric characterization of self-adjointness, the operator A is
self-adjoint if, and only if, H0 = H.
Now suppose that A is not self-adjoint. Then H0 is a proper subspace of H. Since
the space M is invariant under A and dense in H0 one would naturally expect that
the restriction A0 of the operator A to the subspace H0 is a self-adjoint operator in
the Hilbert space H0. This is indeed the case and the self-adjoint operator A0 deﬁned
in this way is called the maximal self-adjoint part of the closed symmetric operator
A. With the help of the geometric characterization of self-adjointness the proof is
straightforward but some terminology has to be introduced.
Deﬁnition 27.2 Let A be a linear operator in the complex Hilbert space H and H0
a closed linear subspace. H0 is an invariant subspace of the operator A if, and
only if, the operator A maps D(A) ∩H0 into H0.
A closed linear subspace H0 is a reducing subspace of the operator A if, and
only if, H0 is an invariant subspace of A and the orthogonal projector P0 onto the
subspace H0 maps the domain D(A) into itself, P0D(A) ⊆D(A).
Thus a closed linear subspace H0 reduces the linear operator A if, and only if, a)
P0x ∈D(A) and b) AP0x ∈H0 for all x ∈D(A). Both conditions can be expressed
through the condition that AP0 is an extension of the operator P0A, i.e.,
P0A ⊆AP0.
(27.38)
Clearly, if H0 is a reducing subspace of the operator A, the restriction A0 to the
subspace H0 is a well-deﬁned linear operator in the Hilbert space H0.
Deﬁnition 27.3 Let A be a linear operator in the Hilbert space H0. The restriction
A0 of A to a reducing subspace H0 is called the maximal self-adjoint part of A if,
and only if, A0 is self-adjoint in the Hilbert space H0, and if H1 is any other reducing
subspace of A on which the restriction A1 of A is self-adjoint, then H1 ⊆H0 and
A1 ⊆A0.
Theorem 27.6 (Maximal Self-Adjoint Part) Every closed symmetric operator A in
a complex Hilbert space H has a maximal self-adjoint part A0. A0 is deﬁned as the
restriction of A to the closure H0 of the union M = ∪n∈NF(A, n) of the subspaces
of controlled growth.
Proof
Denote by Pn the orthogonal projector onto the closed invariant subspace
F(A, n), n ∈N. The sequence of projectors is monotone increasing and thus has a
strong limit Q0, Q0x = limn→∞Pnx for all x ∈H. The range of Q0 is the closure
of the union of the ranges of the projectors Pn, i.e., ran Q0 = H0.
In order to show that H0 is a reducing subspace of A, recall that PnAx = APnx
for all x ∈D(A), a property which has been used before on several occasions. For
n →∞the left-hand side of this identity converges to Q0Ax, hence the right-hand
side APnx converges too for n →∞. We know limn→∞Pnx = Q0x and A is closed,
hence Q0x ∈D(A) and AQ0x = Q0Ax for all x ∈D(A). Thus, H0 is a reducing
subspace.
Consider the restriction A0 = A|D(A)∩H0 of A to the reducing subspace H0. It
follows easily that A0 is closed and symmetric and that the subspaces of controlled

416
27
The Spectral Theorem
growth coincide: F(A0, n) = F(A, n) for all n ∈N (see Exercises). Hence, the
geometric characterization of self-adjointness proves A0 to be self-adjoint.
Now let H1 be another reducing subspace of A on which the restriction A1 =
A|D(A)∩H1 is self-adjoint. Theorem 27.2 implies
H1 = ∪n∈NF(A1, n).
Since A1 is a restriction of A we know F(A1, n) ⊆F(A, n) for all n ∈N and thus
H1 ⊆H0 and therefore A1 ⊆A0. We conclude that A0 is the maximal self-adjoint
part of A.
2
Another powerful application of the geometric characterization of self-adjoint-ness
are convenient sufﬁcient conditions for a symmetric operator to be essentially self-
adjoint. The idea is to use lower bounds for the subspaces of controlled growth. And
here considerable ﬂexibility is available. This is very important since in practice it is
nearly impossible to determine the subspaces of controlled growth explicitly.
Theorem 27.7
Let A ⊂A∗be a symmetric operator in the Hilbert space H. If
for every n ∈N there is a subset D(A, n) ⊂F(A, n) of the subspaces of controlled
growth such that their union D0(A) = ∪n∈ND(A, n) is a total subset of the Hilbert
space H, then A is essentially self-adjoint.
Proof
The closure A of A is a closed symmetric operator. It is self-adjoint if,
and only if, H0(A) = ∪n∈NF(A, n) is a dense subspace of H. Obviously one has
F(A, n) ⊂F(A, n) and thus D0(A) ⊆H0(A). By assumption the set D0(A) is total
in H, hence H0(A) is dense and thus A is self-adjoint.
2
We conclude this section by pointing out an interesting connection of the geomet-
ric characterization of self-adjointness with a classical result of Nelson which is
discussed in detail in the book [2].
Let A be a symmetric operator in the complex Hilbert space H. x ∈D∞(A) is
called an analytic vector of A if, and only if, there is a constant Cx < ∞such that
--Anx
-- ≤Cn
xn!
∀n ∈N.
Denote by Dω(A) the set of all analytic vectors of A. Then Nelson’s theorem states
that A is essentially self-adjoint if, and only if, the space of all analytic vectors Dω(A)
is dense in H. Furthermore, a closed symmetric operator A is self-adjoint if, and
only if, Dω(A) is dense in H. In the Exercises, we show
H0(A) = ∪n∈NF(A, n) ⊆Dω(A).
Thus, Nelson’s results are easily understood in terms of the geometric characteriza-
tion of self-adjointness.
27.5
Exercises
1. For a spectral family Et, t ∈R, on a Hilbert space H prove
E(I1)E(I2) = E(I1 ∩I2)

References
417
for any intervals Ij = (sj, tj]. Here we use E(∅) = 0.
2. Prove parts b)–d) of Theorem 27.3.
3. Suppose a self-adjoint operator A in a complex Hilbert space H has the spectral
representation A =

R tdEt with spectral family Et, t ∈R. Let c ∈R be a
constant. Then ﬁnd the spectral representation for the operator A + cI.
4. Let A be a self-adjoint operator in the complex Hilbert space H which is
represented by the spectral family E′
t, t ∈R. Prove:
ran E′(s, t] = F(A −s + t
2
I, t −s
2
)
for all s < t and conclude uniqueness of the spectral family.
Hints: Recall that ran E′(s, t] = ran E′
t ∩(ran E′
s)⊥and prove ﬁrst
∥(A −s + t
2
I)n∥2 =
 t
s
(τ −s + t
2
)2nd∥E′
τx∥2
for all x ∈ran E′(s, t]. Then one can proceed as in the case of a positive operator.
5. Let A be a closed symmetric operator in the Hilbert space H and let H0 be the
closure of the union of the subspaces of controlled growth F(A, n), n ∈N. H0 is
known to be a reducing subspace of A. Prove: a) The restriction A0 of A to H0 is
a closed and symmetric operator in H0; b) F(A, n) = F(A0, n) for all n ∈N.
6. Denote by Mg the operator of multiplication with the real valued piece-wise con-
tinuous function g in the Hilbert space H = L2(R). Assume that for every n ∈N
there are nonnegative numbers rn, Rn such that [−rn, Rn] ⊆{x ∈R : |g(x)| ≤n}.
Prove: Mg is self-adjoint on D(Mg) =

f ∈L2(R) : g · f ∈L2(R)

if rn →∞
and Rn →∞as n →∞.
Hints: In Theorem 27.7, try the sets
D(Mg, n) =

f ∈L2(R) : supp f ⊆[ −rn, Rn]

.
7. Consider the free Hamilton operator H0 in momentum representation in the
Hilbert space H = L2(R3), i.e., (H0ψ)(p) =
p2
2mψ(p) for all p ∈R3 and all
ψ ∈D(H0). Since we had shown earlier that H0 is self-adjoint we know that it
has a spectral representation. Determine this spectral representation explicitly.
References
1. Leinfelder H. A geometric proof of the spectral theorem for unbounded self-adjoint operators.
Math Ann. 1979;242:85–96.
2. Reed M, Simon B. Fourier analysis. Self-adjointness. vol. 2 of Methods of modern mathematical
physics. New York: Academic Press; 1975.

Chapter 28
Some Applications of the Spectral
Representation
For a self-adjoint operator A in a complex Hilbert space H, the spectral representation
A =

R
t dEt
has many interesting consequences. We discuss some of these in this chapter. For a
more comprehensive discussion of the meaning of the spectral theorem we refer to
[1].
In Theorem 27.4 we learned to integrate functions with respect to a spectral family
Et, t ∈R. This applies in particular to the spectral family of a self-adjoint operator
and thus allows us to deﬁne quite general functions f (A) of a self-adjoint operator
A. Some basic facts of this functional calculus are presented in the ﬁrst section.
The next section introduces a detailed characterization of the different parts of the
spectrum of a self-adjoint operator in terms of its spectral family. The different parts
of the spectrum are distinguished by the properties of the measure dρx(t) = d⟨x, Etx⟩
in relation to the Lebesgue measure and this leads to the different spectral subspaces
of the operator.
Finally, we discuss the physical interpretation of the different parts of the spectrum
for a self-adjoint Hamilton operator.
28.1
Functional Calculus
We restrict ourselves to the functional calculus for continuous functions though it
can be extended to a much wider class, the Borel functions, through an additional
limit process.
Theorem 28.1
Let A be a self-adjoint operator in the complex Hilbert space H
and Et, t ∈R, its spectral family. Denote by Cb(R) the space of bounded continuous
functions g : R →C. Then for every g ∈Cb(R),
g(A) =

R
g(u)dEu
(28.1)
© Springer International Publishing Switzerland 2015
419
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_28

420
28
Some Applications of the Spectral Representation
is a well-deﬁned bounded linear operator on H and g #→g(A) is a continuous
algebraic *-homomorphism Cb(R) →B(H), i.e.,
a) (a1g1 + a2g2)(A) = a1g1(A) + a2g2(A) for all gj ∈Cb(R) and all aj ∈C
b) 1(A) = I
c) g(A)f (A) = (g · f )(A) for all f , g ∈Cb(R)
d) g(A)∗= g(A) for all g ∈Cb(R)
e) ∥g(A)∥≤∥g∥∞for all g ∈Cb(R)
In addition the following holds:
1) id(A) = A
2) g ∈Cb(R) and g ≥0 implies g(A) ≥0
3) If g ∈Cb(R) is such that 1
g ∈Cb(R), then g(A)−1 = 1
g(A)
4) σ(g(A)) = g(σ(A)) = {g(λ) : λ ∈σ(A)} (spectral mapping theorem)
Proof
Theorem 27.3 and Lemma 27.7 easily imply that for every g ∈Cb(R) the
operator g(A) is a well-deﬁned bounded linear operator on H, since for all x ∈H
one has

R |g(u)|2d ∥Eux∥2 ≤∥g∥2
∞

R |d ∥Eux∥2 = ∥g∥2
∞∥x∥2. Part (e) follows
immediately. Parts (a), (b) and (d) also follow easily from a combination of Theorem
27.3 and Lemma 27.7. The proof of Part (c) is left as an exercise where some hints
are given.
The ﬁrst of the additional statements is just the spectral theorem. For the second
we observe that for all x ∈H one has ⟨x, g(A)x⟩=

R g(u)d ∥Eux∥2 ≥0 and hence,
g(A) ≥0. The third follows from the combination of (b) and (c). The proof of the
spectral mapping theorem is left as an exercise for the reader.
2
Corollary 28.1
Let A be a self-adjoint operator in the Hilbert space H and Et,
t ∈R its spectral family. Deﬁne
V (t) = e itA =

R
e itudEu
∀t ∈R.
(28.2)
Then V (t) is a strongly continuous one-parameter group of unitary operators on H
with generator A.
Proof V (t) is deﬁned as et(A) where et is the continuous bounded functions et(u) =
e itu for all u ∈R. These exponential functions et satisfy et = e−t = 1
et . Hence, parts
(d) and (3) imply (et(A))∗et(A) = et(A)(et(A))∗= I. Furthermore, these functions
satisfy et · es = et+s for all t, s ∈R and e0 = 1. Hence parts (b) and (c) imply
V (t)V (s) = V (t + s) and V (0) = I, thus V (t) is a one-parameter group of unitary
operators on H.
For x ∈H and s, t ∈R we have ∥V (t + s)x −V (t)x∥= ∥V (t)(V (s)x −x)∥=
∥V (s)x −x∥and
∥V (s)x −x∥2 =

R
|( e isu −1)|2d ∥Eux∥2 .

28.2
Decomposition of the Spectrum—Spectral Subspaces
421
Since |( e isu −1)| ≤2 and |( e isu −1)| →0 as s →0 for every u, a simple
application of Lebesgue’s dominated convergence theorem implies ∥V (s)x −x∥→
0 for s →0. Therefore, the group V (t) is strongly continuous.
According to Stone’s Theorem 23.2, this group has a self-adjoint generator B
deﬁned on D =

x ∈H : ∃limt→0 1
t (V (t)x −x)

by iBx = limt→0 1
t (V (t)x −x).
According to the spectral Theorem 27.5, a vector x ∈H belongs to the domain of
A if, and only if,

R u2d ∥Eux∥2 < ∞. Thus, by another application of Lebesgue’s
dominated convergence theorem, we ﬁnd that
----
1
t [V (t)x −x]
----
2
=

R
| e itu −1
t
|2d ∥Eux∥2
has a limit for t →0 since | e itu−1
t
|2 ≤u2. We conclude that D(A) ⊆D and A ⊆B.
Since A is self-adjoint this implies A = B.
2
The following corollary completes the proof of Stone’s theorem.
Corollary 28.2 Let U(t) be a strongly continuous one-parameter group of unitary
operators on the complex Hilbert space H and A its self-adjoint generator. Then
U(t) = et(A) ≡e itA
∀t ∈R.
Proof We know already that the strongly continuous one-parameter group of unitary
operators V (t) = et(A) has the generator A and that both U(t) and V (t) leave the
domain D of the generator A invariant. For x ∈D, introduce x(t) = U(t)x −
V (t)x ∈D for all t ∈R. Thus, this function has the derivative d
dt x(t) = iAU(t)x −
iAV (t)x = iAx(t), and therefore,
d
dt ∥x(t)∥2 = ⟨d
dt x(t), x(t)⟩+ ⟨x(t), d
dt x(t)⟩= ⟨iAx(t), x(t)⟩+ ⟨x(t), iAx(t) = 0
for all t ∈R. Since, x(0) = 0 we conclude that x(t) = 0 for all t ∈R and therefore
the groups U(t) and V (t) agree on D. Since D is dense this proves that U(t) and
V (t) agree on H.
2
28.2
Decomposition of the Spectrum—Spectral Subspaces
According to Weyl’s criterion (Theorem 28.5), a real number λ belongs to the spec-
trum of a self-adjoint operator A if and only if, there is a sequence of unit vectors xn
such that ∥(A −λI)xn∥→0 as n →∞. The spectral theorem allows us to translate
this criterion into a characterization of the points of the spectrum of A into proper-
ties of its spectral family E. This will be our starting point for this section. Then a
number of consequences are investigated. When we relate the spectral measure dρx,
associated to the spectral family of A, and a vector x ∈H to the Lebesgue measure
dλ on the real numbers we will obtain a ﬁner decomposition of the spectrum σ(A).

422
28
Some Applications of the Spectral Representation
Theorem 28.2 Let A be a self-adjoint operator in a complex Hilbert space H and
Et, t ∈R, its spectral family. Then the following holds:
a) μ ∈σ(A) ⇔Eμ+ε −Eμ−ε ̸= 0
∀ε > 0.
b) μ ∈R is an eigenvalue of A ⇔E({μ}) = Eμ −Eμ−0 ̸= 0.
Proof Suppose that there is an ε > 0 such that P = Eμ+ε −Eμ−ε = 0. Then for
any x ∈D(A) with ∥x∥= 1 we ﬁnd by the spectral theorem that
∥(A −μI)x∥2 =

|t−μ|≥ε
|t −μ|2d ∥Etx∥2 ≥ε2

|t−μ|≥ε
d ∥Etx∥2 =ε2 ∥x∥2 =ε2>0,
since we can write x = Px + (I −P)x = (I −P)x. Thus, no sequence of unit
vectors in D(A) can satisfy Weyl’s criterion, hence μ ̸∈σ(A).
Conversely, if Pn = Eμ+ 1
n −Eμ−1
n ̸= 0 for all n ∈N, then there is a sequence
xn = Pnxn in D(A) with ∥xn∥= 1. For this sequence we have by the spectral
theorem
∥(A −μI)xn∥2 =

|t−μ|≤1
n
|t −μ|2d ∥Etxn∥2 ≤1
n2 ∥xn∥2 = 1
n2
and thus this sequence satisﬁes Weyl’s criterion and therefore μ belongs to the
spectrum of A. This proves Part (a).
Next, suppose that μ ∈R is an eigenvalue of A. Let x ∈D(A) be a normalized
eigenvector. Again by the spectral representation, the identity
0 = ∥(A −μI)x∥2 =

R
|t −μ|2d ∥Etx∥2
holds. In particular, for all N ∈N and all ε > 0,
0 =
 N
μ+ε
|t −μ|2d ∥Etx∥2 ≥ε2
 N
μ+ε
d ∥Etx∥2 = ε2 ∥E(μ + ε, N]x∥2 .
We conclude that 0 = ENx −Eμ+εx and similarly 0 = E−Nx −Eμ−εx for all
N ∈N and all ε > 0. Now apply the normalization condition of a spectral family
to conclude x = Eμ+εx and 0 = Eμ−εx for all ε > 0. This implies that, using right
continuity of a spectral family, x = (Eμ −Eμ−0)x and the projector Eμ −Eμ−0 is
not zero.
When we know that the projector P = Eμ −Eμ−0 is not zero, then there is a
y ∈H such that y = Py and ∥y∥= 1. It follows that y ∈D(A) and Ety = y for
t > μ and Ety = 0 for t < μ, hence ∥(A −μI)y∥2 =

R |t −μ|2d ∥Ety∥2 = 0,
i.e. (A −μI)y = 0 and μ is an eigenvalue of A.
2
The set De = {x ∈D(A) : x ̸= 0, Ax = λx for some λ ∈R} of all eigenvectors
of the self-adjoint operator A generates the closed subspace [De] = Hp = Hp(A)

28.2
Decomposition of the Spectrum—Spectral Subspaces
423
called the discontinuous subspace of A. Its orthogonal complement H⊥
p is the
continuous subspace Hc(A) of A, and thus one has the decomposition
H = Hp(A) ⊕Hc(A)
of the Hilbert space.
With every spectral family Et, t ∈R, one associates a family of spectral measures
(dρx)x∈H on the real line R, which are deﬁned by
 b
a dρx(t) = ⟨x, E(a, b]x⟩. In
terms of these spectral measures the continuous and discontinuous subspaces are
characterized by
Proposition 28.1 Let A be a self-adjoint operator in the complex Hilbert space H
with spectral family Et, t ∈R. For x ∈H, denoted by dρx, the spectral measure is
deﬁned by the spectral family of A. Then
a) x ∈Hp(A) if, and only if, there is a countable set a ⊂R such that E(a)x = x or
equivalently ρx(ac) = 0.
b) x ∈Hc(A) if, and only if, t #→∥Etx∥2 is continuous on R or equivalently
ρx({t}) = 0 for every t ∈R.
Proof
If a ⊂R is a Borel set, then E(a)x = x if, and only if, E(ac)x = 0
if and only if, ρx(ac) = ∥E(ac)x∥2 = 0. Therefore, the two characterizations
of Hp(A) are equivalent. Since Hp(A) is deﬁned as the closure of the set of all
eigenvectors of A, every point x ∈Hp(A) is of the form x = limn→∞
n
j=1 cjej
with coefﬁcients cj ∈C and eigenvectors ej of A corresponding to eigenvalues
λj. The list of all different eigenvalues is a countable set a =

λj(i) : i ∈N

and
the corresponding projectors E(

λj

) are orthogonal and satisfy E(

λj

)ej = ej
according to Theorem 28.2. For every k ∈N, we thus ﬁnd E(a)ek = ek and therefore
E(a)x = limn→∞E(a) n
k=1 ckek = x.
Conversely, if x ∈H satisﬁes E(a)x = x for some countable set a =

λj : j ∈N

, then x = limn→∞
n
j=1 E(

λj

)x and E(

λj

) is not zero if, and
only if, λj is an eigenvalue (Theorem 28.2). This proves Part (a).
For every x ∈Hp(A)⊥and every λ ∈R we ﬁnd ρx({λ}) = ⟨x, E({λ})x⟩= 0,
since by the ﬁrst part E({λ})x ∈Hp(A).
If for x ∈H we know ρx({λ}) = 0 for every λ ∈R, then ∥E(a)x∥2 = ρx(a) = 0
for every countable set a ⊂R. For every y ∈Hp(A) there is a countable set a ⊂R
such that E(a)y = y, hence ⟨x, y⟩= ⟨x, E(a)y⟩= ⟨E(a)x, y⟩= 0 and thus
x ∈Hp(A)⊥. The deﬁnition of the spectral measure dρx implies easily that the two
characterizations of Hc(A) are equivalent.
2
A further decomposition of the continuous subspace of a self-adjoint operator A
is necessary for an even ﬁner analysis.
Deﬁnition 28.1
For a self-adjoint operator A in a complex Hilbert space H with
spectral family Et, t ∈R, the following spectral subspaces are distinguished:
a) Singularly continuous subspace Hsc(A) of A: x ∈Hsc(A) if, and only if, there
exists a Borel set a ⊂R of Lebesgue measure zero (|a| = 0) such that E(a)x = x

424
28
Some Applications of the Spectral Representation
b) Absolutely continuous subspace Hac(A) of A: Hac(A) = Hc(A) ⊖Hsc(A)
c) Singular subspace Hs(A) = Hp(A) ⊕Hsc(A)
In the Exercises we show that Hsc(A) is indeed a closed linear subspace of H.
Evidently these deﬁnitions imply the following decomposition of the Hilbert space
into spectral subspaces of the self-adjoint operator A.
H = Hp(A) ⊕Hc(A) = Hp(A) ⊕Hsc(A) ⊕Hac(A) = Hs(A) ⊕Hac(A). (28.3)
Again these spectral subspaces have a characterization in terms of the associated
spectral measures.
Proposition 28.2 For a self-adjoint operator A in the complex Hilbert space H the
singular and the absolutely continuous subspaces are characterized by
Hs(A) =

x ∈H : ∃Borel set a ⊂R such that |a| = 0 and ρx(ac) = 0

= {x ∈H : ρx is singular with respect to the Lebesgue measure},
Hac(A) = {x ∈H : for every Borel set a ⊂R with |a| = 0one has ρx(a) = 0}
= {x ∈H : ρx is absolutely continuous w. resp. to the L-measure}.
Proof Every x ∈Hs(A) is the sum of a unique y ∈Hp(A) and a unique z ∈Hsc(A).
According to Proposition 28.1, there is a countable set a ⊂R such that E(a)y = y
and by deﬁntion of the singularly continuous subspace there is a Borel set b ⊂R
with |b| = 0 and E(b)z = z. m = a ∪b is again a Borel set with Lebesgue measure
zero and we have E(m)x = E(m)E(a)y +E(m)E(b)z = E(a)y +E(b)z = x. Then
clearly ρx(mc) = 0.
Conversely, if x ∈H satisﬁes ρx(mc) = 0 for some Borel set m of measure
zero, then E(m)x = x. Recall that t #→∥Et∥2 is a monotone increasing function of
bounded total variation. Thus, it has a jump at, at most, countably many points tj.
Introduce the set a =

tj : j ∈N

. The last proposition implies that E(a)x ∈Hp(A).
In the Exercises we show
E({t})E(ac)x = 0
∀t ∈R.
We deduce E(b)E(ac)x = 0 for every countable set b ⊂R. If y ∈Hp(A) is given,
there is a countable set b ⊂R such that E(b)y = y; we calculate ⟨y, E(ac)x⟩=
⟨E(b)y, E(ac)x⟩= ⟨y, E(b)E(ac)x⟩= 0 and see E(ac)x ∈Hp(A)⊥= Hc(A). Fur-
thermore, the identity E(m)x = x implies E(m)E(ac)x = E(m)x −E(m)E(a)x =
E(ac)x. Therefore, the vector E(ac)x belongs to the singularly continuous subspace.
The identity x = E(a)x + E(ac)x ∈Hp(A) ⊕Hsc(A) ﬁnally proves the ﬁrst part.
To prove the second part take any x ∈H and suppose that for every Borel set
a ⊂R with |a| = 0 we know ρx(a) = 0 and therefore E(a)x = 0. For every
y ∈Hp(A), there is a countable set a ⊂R such that E(a)y = y and for every
z ∈Hsc(A), there is a Borel set b ⊂R such that |b| = 0 and E(b)z = z. This implies
⟨x, y +z⟩= ⟨x, E(a)y⟩+⟨x, E(b)z⟩= ⟨E(a)x, y⟩+⟨E(b)x, z⟩= 0 +0 = 0, hence
x ∈Hs(A)⊥= Hac(A).

28.2
Decomposition of the Spectrum—Spectral Subspaces
425
For x ∈H and any Borel set b ⊂R with |b| = 0, one knows E(b)x ∈Hs(A)
according to the ﬁrst part. If now x ∈Hac(A) is given and b ⊂R any Borel set
with |b| = 0, we ﬁnd ρx(b) = ∥E(b)x∥2 = ⟨x, E(b)x⟩= 0, which proves the
characterization of Hac(A).
2
There is another way to introduce these spectral subspaces of a self-adjoint op-
erator A in a Hilbert space H. As we know, for every x ∈H the spectral measure
dρx is a Borel measure on the real line R. Lebesgue’s decomposition theorem (see
for instance [2]) for such measures states that dρx has a unique decomposition into
pairwise singular measures
dρx = dρx,pp + dρx,sc + dρx,ac
(28.4)
with the following speciﬁcation of the three measures: dρx,pp is a pure point measure,
i.e., there are at most countably many points tj such that ρx,pp(

tj

) ̸= 0. dρx,sc is a
continuous measure, i.e., ρx,ac({t}) = 0 for all t ∈R, which is singular with respect
to the Lebesgue measure, i.e., there is a Borel set a ⊂R such that ρx,sc(a) = 0
while |ac| = 0. Finally, dρx,ac is a Borel measure which is absolutely continuous
with respect to the Lebesgue measure, i.e., for every Borel set b ⊂R with |b| = 0,
one has ρx,ac(b) = 0.
As a consequence, we have the following decomposition of the corresponding
L2-space:
L2(R, dρx) = L2(R, dρx,pp) ⊕L2(R, dρx,sc) ⊕L2(R, dρx,ac).
(28.5)
In the terminology of Lebesgue’s decomposition theorem we can reformulate the
deﬁnition of the various spectral subspaces:
Hp(A) = {x ∈H : dρx is a pure point measure on R};
Hsc(A) = {x ∈H : dρx is continuous and singular w. resp. to the L-measure};
Hac(A) = {x ∈H : dρx is absolutely continuous w. resp. to the L-measure}.
Therefore, because of the spectral theorem and our previous characterization of the
spectral subspaces, the decompositions (28.3) and (28.5) correspond to each other
and thus in the sense of Lebesgue measure theory this decomposition is natural.
We proceed by showing that the given self-adjoint operator A has a restriction
Ai = A|Di, Di = D(A) ∩Hi, to its spectral subspace Hi = Hi(A) where i stands
for p, c, sc, ac, s. This is done by proving that these spectral subspaces are reducing
for the operator A.
Theorem 28.3
Let A be a self-adjoint operator in the complex Hilbert space H.
Then the restriction Ai of A to the spectral subspace Hi is a self-adjoint operator in
the Hilbert space Hi, i = p, c, sc, ac, s.

426
28
Some Applications of the Spectral Representation
Proof Denote by Pi the orthogonal projector from H onto the spectral subspace Hi.
Recall that Hi is a reducing subspace for the operator A if
PiD(A) ⊂D(A)
and
APix = PiAx
∀x ∈D(A).
We verify this condition explicitly for the case i = p, i.e., for the restriction to the
discontinuous subspace.
According to Proposition 28.1, a point x ∈H belongs to the discontinuous sub-
space Hp(A) if, and only if, there is a countable set a ⊂R such that E(a)x = x. The
projector E(a) commutes with all the projectors Et, t ∈R, of the spectral family E of
A. Thus, x ∈Hp(A) implies Etx ∈Hp(A) for all t ∈R and therefore EtPp = PpEt
for all t ∈R.
The spectral theorem says: x ∈D(A) if, and only if,

R t2d∥Etx∥2 < ∞. For
x ∈D(A), we thus ﬁnd

R
t2d∥EtPpx∥2 =

R
t2d∥PpEtx∥2 ≤

R
t2d∥Etx∥2 < ∞.
This proves Ppx ∈D(A). Now we apply again the spectral theorem to calculate for
x ∈D(A)
APpx =

R
t dEtPpx =

R
t dPpEtx =

R
t PpdEtx = Pp

R
t dEtx = PpAx.
It follows that Hp(A) is a reducing subspace for the self-adjoint operator A. We
conclude that the restriction of A to this reducing subspace is self-adjoint.
In the Exercises the reader is asked to ﬁll in some details and to prove the remaining
cases.
2
The last result enables the deﬁnition of those parts of the spectrum of a self-adjoint
operator A which correspond to the various spectral subspaces.
σc(A) = σ(Ac)
= continuous
σsc(A) = σ(Asc) = singularly continuous
σac(A) = σ(Aac) = absolutely continuous
σs(A) = σ(As)
= singular
⎫
⎪⎪⎪⎪⎪⎬
⎪⎪⎪⎪⎪⎭
spectrum of A.
The point spectrum σp(A), however, is deﬁned as the set of all eigenvalues of A.
This means that in general we only have
σp(A) = σ(Ap).
Corresponding to the deﬁnition of the various spectral subspaces (Deﬁnition 28.1),
the spectrum of a self-adjoint operator A can be decomposed as follows:
σ(A) = σp(A) ∪σsc(A) ∪σac(A) = σs(A) ∪σac(A) = σp(A) ∪σc(A).
(28.6)

28.2
Decomposition of the Spectrum—Spectral Subspaces
427
There is a third way to decompose the spectrum of a self-adjoint operator into two
parts. Denote by σd(A) the set of those isolated points of σ(A) which are eigenvalues
of ﬁnite multiplicity. This set is the discrete spectrum σd(A). The remaining set
σe(A) = σ(A)\σd(A) is called the essential spectrum of A,
σ(A) = σd(A) ∪σe(A).
(28.7)
As we are going to show, the essential spectrum has remarkable stability properties
with regard to certain changes of the operator. But ﬁrst the essential spectrum has to
be characterized more explicitly.
Theorem 28.4
For a self-adjoint operator A in a complex Hilbert space H with
spectral family E, the following statements are equivalent.
a) λ ∈σe(A)
b) There is a sequence (xn)n∈N ⊂D(A) such that
b1) (xn)n∈N converges weakly to 0
b2) lim infn→∞∥xn∥> 0
b3) limn→∞(A −λI)xn = 0
c) dim (ran (Eλ+r −Eλ−r0)) = ∞for every r > 0
Proof Suppose λ ∈σe(A). If λ is an eigenvalue of inﬁnite multiplicity, then there
is an inﬁnite orthonormal system of eigenvectors xn. Such a system is known to
converge weakly to 0 and thus (b) holds in this case. Next, suppose that λ is an
accumulation point of the spectrum of A. Then there is a sequence (λn)n∈N ⊂σ(A)
with the following properties:
lim
n→∞λn = λ,
λn ̸= λ,
λn ̸= λm
∀n, n ∈N, n ̸= m.
Hence, there is a sequence of numbers rn > 0, which converges to zero such that
the intervals (λn −rn, λn + rn) are pair-wise disjoint. Points of the spectrum have
been characterized in Theorem 28.2. Thus, we know for λn ∈σ(A) that Eλn+rn −
Eλn−rn ̸= 0. Therefore, we can ﬁnd a normalized vector xn in the range of the
projector Eλn+rn −Eλn−rn for all n ∈N. Since the intervals (λn −rn, λn + rn) are
pair-wise disjoint, the projectors Eλn+rn −Eλn−rn are pair-wise orthogonal and we
deduce ⟨xn, xm⟩= δnm. The identity
∥(A −λI)xn∥2 =

R
(t −λ)2d∥Etxn∥2 =
 λn+rn
λn−rn
(t −λ)2d∥Etxn∥2
implies limn→∞(A−λI)xn = 0, since, limn→∞λn = λ and limn→∞rn = 0. Again,
since inﬁnite orthonormal systems converge weakly to 0, statement (b) holds in this
case too. Thus, (a) implies (b).
Nowassume(b).Anindirectproofwillshowthatthen(c)holds. Supposethatthere
issomer > 0 suchthattheprojectorEλ+r−Eλ−r hasaﬁnitedimensionalrange. Then
this projector is compact. Since compact operators map weakly convergent sequences

428
28
Some Applications of the Spectral Representation
onto strongly convergent ones, we know for any sequence (xn)n∈N satisfying (b) that
limn→∞(Eλ+r −Eλ−r)xn = 0. Now observe the lower bound
∥(A −λI)xn∥2 =

R
(t −λ)2d∥Etxn∥2 ≥r2

R
d∥Etxn∥2 −
 λ+r
λ−r
d∥Etxn∥2

= r2(∥xn∥2 −∥(Eλ+r −Eλ−r)xn∥2)
which gives
∥xn∥2 ≤∥(Eλ+r −Eλ−r)xn∥2 + 1
r2 ∥(A −λI)xn∥2,
and thus a contradiction between (b2), (b3) and the implication of (b1) given above.
Finally suppose (c). We have to distinguish two cases:
α)
dim (ran (Eλ −Eλ−0)) = ∞,
β)
dim (ran (Eλ −Eλ−0)) < ∞.
In the ﬁrst case we know by Theorem 28.2 that λ is an eigenvalue of inﬁnite
multiplicity and therefore λ ∈σe(A).
Now consider the second case. By assumption we know that
Eλ+r −Eλ−r = (Eλ+r −Eλ) + (Eλ −Eλ−0) + (Eλ−0 −Eλ−r)
is a projector of inﬁnite dimensional range for every r > 0. The three projectors of
this decomposition are orthogonal to each other since the corresponding intervals are
disjoint. Therefore, the sum of the projectors (Eλ+r −Eλ)+(Eλ−0−Eλ−r) has an inﬁ-
nite dimensional range and thus (Theorem 28.2) in particular [(λ−r, λ)∪(λ, λ+r)]
∩σ(A) ̸= ∅for every r > 0. This means that λ is an accumulation point of the
spectrum of A, i.e., λ ∈σe(A). We conclude that (c) implies (a).
2
Remark 28.1 From the proof of this theorem it is evident that condition (b) could
be reformulated as
Thereisaninﬁniteorthonormalsystem{xn :n ∈N}withthepropertylimn→∞(A−λI)xn =0.
This characterization (b) of the points of the essential spectrum is the key to the
proof of the following theorem on the “invariance” of the essential spectrum under
“perturbations” of the operator A.
Theorem 28.5 (Theorem of Weyl) Suppose that A and B are two self-adjoint
operators in the complex Hilbert space H. If there is a z ∈ρ(A) ∩ρ(B) such
that
T = (A −zI)−1 −(B −zI)−1
is a compact operator, then the essential spectra of A and B agree: σe(A) = σe(B).
Proof We show ﬁrst σe(A) ⊂σe(B). Take any λ ∈σe(A). Then there is a sequence
(xn)n∈N which satisﬁes condition (b) of Theorem 28.4 for the operator A. For all
n ∈N, deﬁne yn = (A −zI)xn = (A −λI)xn + (λ −z)xn. It follows that this

28.3
Interpretation of the Spectrum of a Self-Adjoint Hamiltonian
429
sequence converges weakly to 0 and the estimate ∥yn∥≥|λ−z|∥xn|−∥(A−λI)xn∥,
valid for sufﬁciently large n ∈N, implies lim infn→∞∥yn∥> 0. Next, we take the
identity
[(B −zI)−1 −(λ −z)−1I]yn = −Tyn −(λ −z)−1(A −λI)xn
into account. Since T is compact and the sequence (yn)n∈N converges weakly to 0,
we deduce from condition (b3) that
lim
n→∞[(B −zI)−1 −(λ −z)−1I]yn = 0.
Now introduce the sequence zn = (B −zI)−1yn, n ∈N. Clearly zn ∈D(B) for all
n ∈N and this sequence converges weakly to 0. From the limit relation given above
we see lim infn→∞∥zn∥> 0. This limit relation also implies
lim
n→∞(B −λI)zn = 0
since (B −λI)zn = (B −zI)zn + (z −λ)zn = yn + (z −λ)(B −zI)−1yn and since
yn = (A −zI)xn converges to 0 by condition (b3).
Therefore, the sequence (zn)n∈N satisﬁes condition (b) for the operator B and our
previous theorem implies that λ is a point of the essential spectrum of the operator B.
Since, with T also the operator −T is compact, we can exchange in the above
proof the role of the operators A and B. Then we get σe(B) ⊂σe(A), and thus
equality of the essential spectra.
2
28.3
Interpretation of the Spectrum of a Self-Adjoint
Hamiltonian
For a self-adjoint operator A in a complex Hilbert space, one can form the one-
parameter group of unitary operators U(t) = e −itA, and one can identify several
spectral subspaces Hi(A) for this operator. It follows that this unitary group leaves
the spectral subspaces invariant but it behaves quite differently on different spectral
subspaces. This behavior we study in this section, but for the more concrete case of a
self-adjoint Hamiltonian in the Hilbert space H = L2(R3) where a concrete physical
and intuitive interpretation is available. These investigations lead naturally to the
quantum mechanical scattering theory for which there are quite a number of detailed
expositions, for instance the books [3, 4]. Certainly, we cannot give a systematic
presentation of scattering here, we just mention a few basic and important facts in a
special context, thus indicating some of the major difﬁculties.
In quantum mechanics the dynamics of a free particle of mass m > 0 is governed
by the free Hamilton operator H0 =
1
2mP 2. Its spectrum has been determined to
be σ(H0) = σc(H0) = [0, ∞). In case of an interaction the dynamic certainly

430
28
Some Applications of the Spectral Representation
is changed. If V (Q) is the interaction operator the dynamic is determined by the
Hamilton operator
H = H0 + V (Q).
We have discussed several possibilities to ensure that this Hamilton operator is self-
adjoint (see Theorem 23.9). Here we work under the following assumptions:
V (Q) is deﬁned and symmetric on the domain D of the free Hamilton operator.
H = H0 + V (Q) is self-adjoint and lower bounded on D.
These two self-adjoint operators generate two one-parameter groups of unitary
operators in L2(R3):
U 0
t = e −i
¯h tH0,
Ut = Ut(V ) = e −i
¯h tH,
∀t ∈R.
Recall: If φ0 ∈D(H), then φ(t) = Utφ0 is the solution of the Schrödinger equation
i¯h d
dt φ(t) = Hφ(t)
for the initial condition φ(t = 0) = φ0. This change with time of states can also be
expressed as a time change of observables At according to the Heisenberg equation
At = e
it
¯h HA e −it
¯h H.
Quantum scattering theory studies the long-term behavior of solutions of the
Schrödinger equation. If λ is an eigenvalue of H with eigenvector φ0, then by func-
tional calculus Utφ0 = e −i
¯h tλφ0 and the localization properties of this eigenvector
do not change under the dynamics.
For potentials V ̸= 0 which decay to 0 for |x| →∞, one expects that the particle
can “escape to inﬁnity” for certain initial states φ0 and that its time evolution Ut(V )φ0
approaches that of the free dynamics Ut(V = 0)ψ0 for a certain initial state ψ0, since
“near inﬁnity” the effect of the potential should be negligible. This expectation can
be conﬁrmed, in a suitable framework.
According to classical mechanics, we expect to ﬁnd two classes of states for the
dynamics described by the Hamilton operator H:
a) In some states the particle remains localized in a bounded region of R3, for all
times t ∈R (as the eigenstate mentioned above). States describing such behavior
are called bound states.
b) In certain states φ the particle can “escapes to inﬁnity” under the time evolution
Ut. Such states are called scattering states.
Certainly, we have to give a rigorous meaning to these two heuristic concepts
of a bound and of a scattering state. This is done in terms of Born’s probability
interpretation of quantum mechanics. Given φ ∈L2(R3) with ∥φ∥= 1 deﬁne
m(Utφ, △) =

△
|(Utφ)(x)|2dx = ∥χ△Utφ∥2
2.
(28.8)

28.3
Interpretation of the Spectrum of a Self-Adjoint Hamiltonian
431
m(Utφ, △) is the probability of ﬁnding the particle at time t in the region △⊂R3.
χ△is the characteristic function of the set △.
Deﬁnition 28.2 φ ∈L2(R3) is called a bound state for the Hamilton operator H
if, and only if, for every ε > 0 there is a compact set K ⊂R3 such that m(Utφ, K) ≥
1 −ε for all t ∈R.
ψ ∈L2(R3) is called a scattering state for the Hamilton operator H if, and only
if, for every compact set K ⊂R3 one has m(Utψ, K) →0 as |t| →∞.
Bound states and scattering states have an alternative characterization which in
most applications is more convenient to use.
Lemma 28.1 a) φ ∈L2(R3) is a bound state for the Hamiltonian H if, and only if,
lim
R→∞sup
t∈R
∥F>RUtφ∥2 = 0
(28.9)
where F>R is the characteristic function of the set

x ∈R3 : |x∥> R

.
b) φ ∈L2(R3) is a scattering state for the Hamiltonian H if, and only if, for every
R ∈(0, ∞),
lim
|t|→∞
--F≤RUtφ
--
2 = 0
(28.10)
where F≤R is the characteristic function of the set

x ∈R3 : |x∥≤R

.
Proof The proof is a straightforward exercise.
2
Denote the set of all bound states for a given Hamiltonian H in L2(R3) by Mb(H)
and by Ms(H) the set of all scattering states for this Hamilton operator. The following
lemma describes some basic facts about these sets.
Lemma 28.2 The sets of all bound states, respectively of all scattering states of a
Hamilton operator H are closed subspaces in L2(R3) which are orthogonal to each
other: Mb(H)⊥Ms(H). Both subspaces are invariant under the group Ut.
Proof The characterization (28.9) of bound states and the basic rules of calculation
for limits immediately imply that Mb(H) is a linear subspace. The same applies to the
Ms(H). Also, invariance under the group Ut is evident from the deﬁning identities
for these subspaces.
Suppose that φ ∈L2(R3) is an element of the closure of Mb(H). Then there is a
sequence (φn)n∈N ⊂Mb(H) with limit φ. For R > 0 and t ∈R we estimate with
arbitrary n ∈N,
∥F>RUtφ∥2 ≤∥F>RUt(φ −φn)∥2 + ∥F>RUtφn∥2 ≤∥φ −φn∥2 + ∥F>RUtφn∥2 .
For a given ε > 0, there is an n ∈N such that ∥φ −φn∥2 < ε/2, and since
φn ∈Mb(H) there is an Rn ∈(0, ∞) such that ∥F>RUtφn∥2 < ε/2 for all R > Rn
and all t ∈R. Therefore, ∥F>RUtφ∥2 < ε for all t ∈R and all R > Rn and thus
condition (28.9) holds. This proves that the linear space of all bound states is closed.
The proof that the space of all scattering states is closed is similar (See Exercises).

432
28
Some Applications of the Spectral Representation
Since Ut is unitary, we ﬁnd for φ ∈Mb(H) and ψ ∈Ms(H),
⟨φ, ψ⟩2 = ⟨Utφ, Utψ⟩2 = ⟨F>RUtφ, Utψ⟩2 + ⟨Utφ, F≤RUtψ⟩2
and thus for all t ∈R and all 0 < R < ∞,
|⟨φ, ψ⟩2| ≤∥F>RUtφ∥2 ∥ψ∥2 + ∥φ∥2
--F≤RUtψ
--
2 .
In the ﬁrst term take the limit R →∞and in the second term the limit |t| →∞and
observe Eq. (28.9), respectively Eq. (28.10) to conclude ⟨φ, ψ⟩2 = 0. This proves
orthogonality of the spaces Mb(H) and Ms(H).
2
There is a fundamental connection between the spaces of bound states, respec-
tively scattering states, on one side and the spectral subspaces of the Hamiltonian on
the other side. A ﬁrst step in establishing this connection is taken in the following
proposition.
Proposition 28.3
For a self-adjoint Hamilton operator H in L2(R3), every nor-
malized vector of the discontinuous subspace is a bound state and every scattering
state belongs to the continuous subspace, i.e.
Hp(H) ⊆Mb(H),
Ms(H) ⊆Hc(H).
(28.11)
Proof
For an eigenvector φ of the Hamiltonian H with eigenvalue E, the time
dependence is Utφ = e −i
¯h Etφ and thus ∥F>RUtφ∥2
2 =

|x|>R |φ(x)|2dx →0 as
R →∞, for every t ∈R and condition (28.9) follows, i.e., φ ∈Mb(H). Since,
Mb(H) is closed this proves Hp(H) ⊆Mb(H). By taking the orthogonal comple-
ments we ﬁnd Mb(H)⊥⊆Hp(H)⊥= Hc(H). Finally, recall Ms(H) ⊆Mb(H)⊥.
And the proof is complete.
2
Heuristic considerations seem to indicate that the state of a quantum mechanical
particle should be either a bound state or a scattering state, i.e., that the total Hilbert
spaces H = L2(R3) has the decomposition
H = Mb(H) ⊕Ms(H).
Unfortunately this is not true in general. Nevertheless, a successful strategy is known
which allows us to establish this decomposition under certain assumptions on the
Hamilton operator.
Suppose that we can show
A.
Hac(H) ⊆Ms(H),
B.
Hsc(H) = ∅.
(28.12)
Then, because of H = Hp(H) ⊕Hc(H), Hc = Hac(H) ⊕Hsc(H), and the general
relations shown above, one has indeed
Hp(H) = Mb(H),
Hac(H) = Ms(H),
H = Mb(H) ⊕Ms(H). (28.13)
While the veriﬁcation of Part A) of (28.12) is relatively straightforward, the imple-
mentation of Part B) is quite involved. Thus, for this part we just mention some basic

28.3
Interpretation of the Spectrum of a Self-Adjoint Hamiltonian
433
results and have to refer to the specialized literature on (mathematical scattering) for
the proofs.
The starting point for the proof of Hac(H) ⊆Ms(H) is the following lemma.
Lemma 28.3 For all ψ ∈Hac(H) the time evolution Utψ converges weakly to 0
for |t| →∞.
Proof The strategy of the proof is to show with the help of the spectral theorem and
the characterization of elements ψ in Hac(H) in terms of properties of the spectral
measure dρψ that for every φ ∈H the function t #→⟨φ, Utψ⟩is the Fourier transform
of a function Fφ,ψ ∈L1(R) and then to apply the Riemann–Lebesgue Lemma (which
states that the Fourier transform of a function in L1(R) is a continuous function which
vanishes at inﬁnity, see Lemma 10.1).
For arbitrary φ ∈H spectral calculus allows us to write
⟨φ, Utψ⟩=

R
e −i
¯h tsd⟨φ, Esψ⟩
for all t ∈R. Let △⊂R be a Borel set. Then

△d⟨φ, Esψ⟩= ⟨φ, E(△)ψ⟩. Denote
by Pac the orthogonal projector onto the subspace Hac(H). It is known to commute
with E(△) and therefore we have ⟨φ, E(△)ψ⟩= ⟨φ, E(△)Pacψ⟩= ⟨Pacφ, E(△)ψ⟩.
Thus, the estimate |⟨φ, E(△)ψ⟩| ≤∥E(△)Pacφ∥∥E(△)ψ∥follows. According to
Proposition 28.2, ψ ∈Hac(H) is characterized by the fact that the spectral measure
dρψ(s) = d ∥Esψ∥2 is absolutely continuous with respect to the Lebesgue measure
on R, i.e., there is a nonnegative function fψ such that dρψ(s) = fψ(s)ds. Since

R dρψ(s) = ∥ψ∥2, we ﬁnd 0 ≤fψ ∈L1(R).
The estimate |⟨φ, E(△)ψ⟩| ≤∥E(△)Pacφ∥∥E(△)ψ∥implies that the measure
d⟨φ, Esψ⟩too is absolutely continuous with respect to the Lebesgue measure; hence,
there is a function Fφ,ψ on R such that d⟨φ, Esψ⟩= Fφ,ψ(s)ds. The above estimate
also implies |Fφ,ψ(s)| ≤fPacφ(s)fψ(s), thus Fφ,ψ ∈L1(R). We conclude that
⟨φ, Utψ⟩=

R
e −i
¯h tsFφ,ψ(s)ds
is the Fourier transform of an absolutely integrable function, and therefore is a
continuous function, which vanishes for |t| →∞.
2
Lemma 28.4
Let E be the spectral family of the self-adjoint operator H and
introduce the projector Pn = En −E−n. If all the operators
F>RPn,
n ∈N,
0 < R < ∞
are compact in H = L2(R3), then Hac(H) ⊆Ms(H).
Proof Suppose ψ ∈Hac(H) is given. Then, by the previous lemma, Utψ converges
weakly to 0. Since F>RPn is assumed to be a compact operator, it maps this sequence

434
28
Some Applications of the Spectral Representation
onto a strongly convergent sequence, therefore
lim
|t|→∞∥F>RPnUtψ∥= 0.
Given ε > 0 there is an n ∈N such that ∥(I −Pn)ψ∥< ε/2. This number n we use
in the following estimate, for any 0 < R < ∞:
∥F>RUtψ∥≤∥F>R(I −Pn)Utψ∥+ ∥F>RPnUtψ∥
≤∥(I −Pn)ψ∥+ ∥F>RPnUtψ∥≤ε/2 + ∥F>RPnUtψ∥.
Now we see that ψ satisﬁes the characterization (28.10) of scattering states and we
conclude.
2
Certainly, it is practically impossible to verify the hypothesis of the last lemma
directly. But this lemma can be used to arrive at the same conclusion under more
concrete hypotheses. The following theorem gives a simple example for this.
Theorem 28.6
Suppose that for the self-adjoint Hamiltonian H in H = L2(R3)
there are q ∈N and z ∈ρ(H) such that the operator
F>R(H −zI)−q
is compact for every 0 < R < ∞. Then Hac(H) ⊆Ms(H) holds.
Proof Write
F>RPn = F>R(H −zI)−q(H −zI)qPn
and observe that (H −zI)qPn is a bounded operator (this can be seen by functional
calculus). The product of a compact operator with a bounded operator is compact
(Theorem 25.4). Thus, we can apply Lemma 28.4 and conclude.
2
There are by now quite a number of results available, which give sufﬁcient con-
ditions on the Hamiltonian H, which ensure that the singular continuous subspace
Hsc(H) is empty. But the proof of these results is usually quite involved and is be-
yond the scope of this introduction. A successful strategy is to use restrictions on H,
which imply estimates for the range of its spectral projections, for instance
ran E(a, b) ⊆Hac(H).
A detailed exposition of this and related theories is given in the books [3, 5–7]. We
mention without proof one of the earliest results in this direction.
Theorem 28.7
For the Hamilton operator H = H0 + V in the Hilbert space
H = L2(R3) assume
a) ∥V ∥2
R =
  |V (x)V (y)|
|x−y|2 dxdy < (4π)2 or
b)
--ea|·|V
--
R < ∞for some a > 0.
ThenthesingularsubspaceofH isempty: Hs(H) = ∅, henceinparticularHsc(H) =
∅, and there are no eigenvalues.
A more recent and fairly comprehensive discussion of the existence of bound
states and on the number of bound states of Schrödinger operators is given in [8, 9].

28.5
Exercises
435
28.4
Probabilistic Description of Commuting Observables
Recall from our discussion of the spectral representation
A =

σ(A)
λdEλ
of a self-adjoint operator A. If A represents an observable a of a quantum mechanical
system, which is in the state ψ then
⟨A⟩ψ = ⟨ψ, Aψ⟩=

σ(A)
λd⟨ψ, Eλψ⟩,
is the expectation value of a in the state ψ, and thus ⟨ψ, Eλψ⟩is the probability for
a value of a in the state ψ which is smaller than or equal to λ. And the observable a
has a value λ with probability one if ψ is an eigenvector of A for the eigenvalue λ.
Given a state ψ, an observable a may be regarded as a random variable on the
probability space (Ω = R, B, P A
ψ (dλ)) where B denotes the Borel σ-algebra on R
and P A
ψ (dλ) = ⟨ψ, dEλψ⟩. Similarly, any number of (strongly) commuting self-
adjoint operators can be regarded as random variables on an appropriate probability
space. But not all observables of a quantum system are commuting and a famous
theorem of von Neumann [10] shows that the set of all observables of a quantum
system in a given state ψ cannot be regarded as a family of random variables on a
common probability space (for a short proof see [11]).
28.5
Exercises
1. Prove Part (c) of Theorem 28.1.
Hints: Given f , g ∈Cb(R) and x, y ∈H show ﬁrst that ⟨x, g(A)f (A)y⟩=
⟨g(A)x, f (A)y⟩= limn→∞⟨gn(A)x, fn(A)y⟩with continuous functions fn, gn
with support in [−n, n]. Then prove
⟨gn(A)x, fn(A)y⟩= lim
|Z|→0⟨Σ(gn, Z)x, Σ(fn, Z)y⟩
where the approximations Σ(fn, Z) are deﬁned in Eq. (27.20). Z is a partition of
the interval [−n, n]. Then use orthogonality of different projectors E(tj−1, tj] to
show
⟨Σ(gn, Z)x, Σ(fn, Z)y⟩= ⟨x, Σ(gn · fn, Z)y.⟩
2. Prove the spectral mapping theorem, Part (4) of Theorem 28.1.
Hints: For z ̸∈σ(g(A)) the resolvent has the representation Rg(A)(z) =

R
1
g(t)−zdEt.
3. Denote by a the countable set of all points tj at which the spectral family E has
a jump. Show: E({t})E(ac)x = 0
∀t ∈R.

436
28
Some Applications of the Spectral Representation
4. Let A be a self-adjoint operator in the complex Hilbert space H. Show that Hsc(H)
is a closed linear subspace of H.
5. Let A be a self-adjoint operator in the complex Hilbert space H and H0 a reducing
subspace. Prove that the restriction A0 of A to this subspace is a self-adjoint
operator in H0.
6. Complete the proof of Theorem 28.3.
7. Prove Lemma 28.1.
8. For a self-adjoint Hamiltonian H in the Hilbert space L2(R3) prove that the set
of all scattering states is a closed linear subspace.
9. Let E be the spectral family of a self-adjoint operator H in the complex Hilbert
space H. Prove Stone’s formula:
π
2 ⟨x, [E[a, b] + E(a, b)]x⟩=
lim
r→0, r>0
 b
a
Im ⟨x, (H −(t + ir)I)−1x⟩dt
for all x ∈H and all −∞< a < b < ∞.
Hints: Prove ﬁrst that the functions gr, r > 0, deﬁned by
gr(t) =
1
2iπ
 b
a

1
s −t −ir −
1
s −t + ir

ds
have the following properties: This family is uniformly bounded and
lim
r→0, r>0 gr(t) =
⎧
⎪⎪⎨
⎪⎪⎩
0
if t ̸∈[a, b],
1/2
if t ∈{a, b} ,
1
if t ∈(a, b).
References
1. Halmos PR. What does the spectral theorem say? Am Math Mon. 1963;70:246–7.
2. Rudin W. Principles of mathematical analysis. Weinheim: Physik-Verlag; 1980.
3. Reed M, Simon B. Scattering theory. Methods of modern mathematical physics. Vol. 3. New
York: Academic Press; 1979.
4. Baumgaertel H, Wollenberg M. Mathematical scattering theory. Basel: Birkhäuser; 1983.
5. Reed M, Simon B. Analysis of operators. Methods of modern mathematical physics. Vol. 4.
New York: Academic Press; 1978.
6. Amrein WO, Sinha KB. Scattering theory in quantum mechanics : physical principles and
mathematical methods. Lecture notes and supplements in physics. Vol. 16. Reading: Benjamin;
1977.
7. Pearson DB. Quantum scattering and spectral theory. Techniques of physics. Vol. 9. London:
Academic Press; 1988.
8. Blanchard Ph, Stubbe J. Bound states for Schrödinger Hamiltonians: phase space methods and
applications. Rev Math Phys. 1996;8:503–47.
9. Grosse H, Martin A. Particle physics and the Schrödinger equation. Cambridge monographs
on particle physics, nuclear physics and cosmology. Vol. 6. Cambridge: Cambridge University
Press; 1997.

References
437
10. von Neumann J. Mathematical foundations of quantum mechanics. Investigations in physics.
2nd print, editor. vol. 2. Princeton: Princeton University Press; 1967.
11. Blanchard Ph, Combe P, ZhengW. Mathematical and physical aspects of stochastic mechanics.
Lecture notes in physics.Vol. 281. Berlin: Springer; 1987.

Chapter 29
Spectral Analysis in Rigged Hilbert Spaces
29.1
Rigged Hilbert Spaces
29.1.1
Motivation for the Use of Generalized Eigenfunctions
In Chaps. 24–27 we have presented various details of the spectral analysis of bounded
and unbounded linear operators in a separable Hilbert space H. According to the
Spectral Theorem of Chap. 27 every self-adjoint operator A has a unique spectral
representation
Ax =

R
tdEtx
for all x ∈H for which

R t2d ∥Etx∥2 is ﬁnite with a unique spectral family Et = EA
t ,
t ∈R. And in Chapts. 24 and 28 we investigated the various parts of the spectrum
σ(A) of a self-adjoint operator A. As a ﬁrst splitting of the spectrum we found one
into two parts, namely into the point spectrum σp(A) and the continuous spectrum
σc(A). In concrete application it is often important to have a complete system of
eigenfunctions as in the ﬁnite dimensional case, hence in particular eigenfunctions
for all points in the spectrum and we saw that for λ ∈σp(A) there is an eigenfunction
ψλ ∈D(A) ⊂H such that Aψλ = λψλ, but not for points in the continuous
spectrum.
In Physics there is an elegant and much used formalism to use eigenfunctions as-
sociated with all points in the spectrum, namely the famous bra and ket formalism
of Dirac. This formalism associates eigenfunctions also to points which do not be-
long to the point spectrum and thus have no proper interpretation in the Hilbert space
context. But these “improper” eigenfunctions have been used with great success for
quite some time. This indicates that the purely Hilbert space framework for spectral
analysis might be too narrow. Recall: An important rôle of (rigorous) mathematics
in physics is to make good sense of heuristic ideas, i.e., to help to ﬁnd appropriate
settings in which to formulate these ideas in precise terms and to establish their con-
sistency. Two famous examples of mathematicians who have created paradigmatic
© Springer International Publishing Switzerland 2015
439
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_29

440
29
Spectral Analysis in Rigged Hilbert Spaces
examples for this statement are L. Schwartz and his treatment of Dirac’s delta func-
tion and J. von Neumann and his introduction of operator algebras in connection
with the (mathematical) foundations of quantum physics.
A simple concrete example can guide us how to extend the Hilbert space frame-
work. Consider the momentum operator P = 1
i
d
dx in H = L2(R) the Sobolev space
H 1(R) = {f ∈L2(R) : p ˜f (p) ∈L2(R)} as its natural domain: D(P) = H 1(R)
where ˜f denotes the Fourier transform of f . It is known that P is self-adjoint on
this domain. Note also that P maps the test function space S(R) continuously into
itself and that S(R) is densely and continuously embedded into the Hilbert space
H = L2(R). The operator P is unitarily equivalent to the operator of multiplication
with the variable Mid via Fourier transformation F2 on L2(R), i.e., F2PF−1
2
= Mid
and hence its spectrum is the real line σ(P) = R (see Part 2 of Example 24.2.1).
But for no q ∈R there is ψq ∈D(P) such that Pψq(x) =
1
i
d
dx ψq(x) = qψq(x).
Certainly, this simple differential equation has the solutions eq(x) = ce i qx with
constants c. This system of eigenfunctions is complete in L2(R) in the sense that
every f ∈L2(R) has a representation in terms of these eigenfunctions, namely in
terms of the Fourier transform.
So one should enlarge the Hilbert space L2(R) so that this enlargement can ac-
commodate these solutions. This is done by introducing a suitable rigged Hilbert
space. These eigenfunctions eq can be considered as regular distributions Fq = Ieq
in the space S′(R) of tempered distributions. Then one has for all φ ∈S(R)
PFq(φ) = Fq(P ′φ) = Fq( −Pφ) = qFq(φ)
where P ′ is the adjoint of P in the sense of Sect. 8.3. Thus Fq is an eigenfunction of
P in the sense of tempered distributions.
29.1.2
Rigged Hilbert Spaces
The following deﬁnition of a rigged Hilbert space or Gelfand triple is modelled on
the above example. In this deﬁnition one important property enters which we have
not yet mentioned for the test function space S(R) and not for the other test function
spaces which were discussed in the ﬁrst part of this volume, namely that these spaces
are nuclear, but nuclearity is essential in the deﬁnition and successful application of
a Gelfand triple. Accordingly we start with presenting basic facts of nuclear spaces.
Consider a Hausdorff locally convex topological vector space Φ (in the sense
of Chap. 2 of Part I) whose ﬁltering system of seminorms is countable and each
seminorm is actually a norm which is deﬁned by a scalar product hn on Φ, n ∈N.
Without loss of generality we can assume that these scalar products are ordered in
the sense that
hn(f , f ) ≤hn+1(f , f )
for all
f ∈Φ, n ∈N.
Then the completion of Φ with respect to the norm ∥·∥n = √hn(·, ·) is a Hilbert space
Φn (see Appendix A) whose scalar product is still denoted by hn and for n ≥m one

29.1
Rigged Hilbert Spaces
441
has continuous dense embeddings
Φn →Φm
denoted by Tmn. Such a space Φ is called nuclear1 if, and only if, for any m ∈N
there is n > m such that the embedding map Tmn is of trace class or nuclear, i.e. is
of the form
Tmn(f ) =
∞

k=1
λkhn(ek, f )fk
(29.1)
where (ek) respectively (fk) are orthonormal sequences in Φn respectively in Φm and
where the series ∞
k=1 λk converges and λk > 0.
Note that f #→hn(ek, f ) deﬁnes a continuous linear functional Fk : Φn −→C,
i.e., an element in the dual space Φ′
n of the Hilbert space Φn and thus Φ′
n is itself a
Hilbert space, often denoted by Φ−n: Φ′
n ≡Φ−n, with norm
∥Fk∥−n = sup

|Fk(f )| : f ∈Φn, ||f ||n = 1

= 1.
Next consider a scalar product h0 on Φ such that h0(f , f ) ≤h1(f , f ) for all f ∈Φ.
Deﬁne a Hilbert space H as the completion of Φ with respect to the norm ∥·∥0 deﬁned
by this scalar product. Thus we have the chain of continuous and dense embeddings
Φn+1 →Φn →. . . →Φ1 →H, n ∈N.
Note that by construction
Φ = ∩n∈NΦn.
Since Φ is continuously embedded into H, every continuous linear functional on H
is also a continuous linear functional on Φ, i.e.,
H′ →Φ′.
If T denotes the embedding of Φ into H, its adjoint T ′ gives the embedding of the
dual spaces. By Corollary 15.3.1 the Hilbert space H and its dual H′ are isometrically
anti-isomorphic. Here it is convenient to identify H and H′. Then the embedding
T ′ : H −→Φ′ has to be an antilinear map and we arrive at the chain of embeddings
Φ →H →Φ′
(29.2)
where the second embedding is antilinear.
Deﬁnition 29.1 A triple of spaces Φ, H, Φ′ where Φ is a nuclear space and H a
Hilbert for which the embedding relation (29.2) holds, is called a rigged Hilbert
space or a Gelfand triple.
1 nuclear spaces were introduced in [1] and are studied in detail in many modern books on functional
analysis.

442
29
Spectral Analysis in Rigged Hilbert Spaces
29.1.3
Examples of Nuclear Spaces
Many of the (function) spaces used in (functional) analysis are actually nuclear. Here
we just illustrate this important concept with some basic examples. For details we
have to refer to specialized literature: [2–5].
29.1.3.1
The Sequence Space S
Denote by S = S(C) the space of all sequences c = (cn) of complex numbers cn
such that for every s ∈N
sup ns|cn| < ∞.
On S deﬁne a sequence of scalar products hn by
hn(c, c′) =
∞

j=1
j ncjc′
j.
Obviously these scalar products satisfy hn(c, c) ≤hn+1(c, c) for all n = 1, 2, . . . .
Denote by Sn the Hilbert space obtained by completion of S with respect to the
scalar product hn. This give the chain of embeddings
Sn+1 →Sn →· · · →S0 = ℓ2(C)
and
S = ∩∞
n=1Sn.
An orthonormal basis of Sn is e(n)
k
= (δjkj −n
2 ), k = 1, 2, . . . . Now given m ∈N
choose n ≥m + 2. We claim that the embedding Tmn of Sn into Sm is a Hilbert–
Schmidt operator. To prove this calculate
∞

k=1
---Tmne(n)
k
---
2
m =
∞

k=1
∞

j=1
j mδkjj −n =
∞

k=1
km−n < ∞,
hence Tmn is a Hilbert–Schmidt operator for n ≥m + 2. Since the product of two
Hilbert–Schmidt operators is nuclear, nuclearity of the sequence space S follows.
29.1.3.2
The Test Function Space S(R)
Recall that we had introduced this test function space as the space of strongly
decreasing C∞functions on R with the ﬁltering system of norms
pm,k(f ) =
sup
x∈R,|α|≤k
(1 + x2)m/2|Dαf (x)|,
m, k ∈N.
Recall the Hamilton operator of the quantum harmonic oscillator (see Sect. 16.3)
H0 = 1
2(−
d2
dx2 + x2) and deﬁne H = 2H0. Clearly this operator maps S(R) into

29.1
Rigged Hilbert Spaces
443
itself and is bounded from below: H ≥I. Now deﬁne a sequence of scalar products
on S(R) by
hn(f , g) = ⟨f , H ng⟩
f , g ∈S(R)
where ⟨·, ·⟩denotes the scalar product of L2(R). It requires some lengthy calculations
to show explicitly that the ﬁltering system of norms deﬁned by these scalar products
is equivalent to the original ﬁltering system of the pm,k, though intuitively this is
quite obvious.
Since H ≥I it follows easily that hn(f , f ) ≤hn+1(f , f ) for all f ∈S(R) and
all n. The completion of S(R) with respect to hn yields a Hilbert space Sn(R) and
the chain of embeddings
Sn+1(R) →Sn(R) →· · · →S0(R) = L2(R).
According to Sect. 16.3 the Hermite functions ψj are the eigenfunctions of H0 for
the eigenvalue j + 1/2, j = 0, 1, 2, . . . . They form an orthonormal basis of L2(R)
and are elements of S(R). It follows that the sequence of functions
e(n)
j
= H −n
2 ψj,
j = 0, 1, 2 . . .
are an orthonormal basis of the Hilbert space Sn(R). For given m ∈N choose
n ≥m + 2 and calculate
∞

j=0
---Tmne(n)
j
---
2
m =
∞

j=0
hm(e(n)
j , e(n)
j ) =
∞

j=0
⟨H −n
2 ψj, H mH −n
2 ψj⟩=
∞

j=0
(2j+1)m−n.
Since n ≥m + 2 this series converges and thus Tmn is a Hilbert–Schmidt operator
Sn(R) −→Sm(R) and we conclude that S(R) is nuclear.
29.1.4
Structure of the Natural Embedding in a Gelfand Triple
The assumption of nuclearity of the space Φ in the deﬁnition of a rigged Hilbert
space Φ →H →Φ′ has a very important implication for the structure of the
natural embedding T : Φ →H which we investigate now.
Theorem 29.1 Suppose that Φ →H →Φ′ is a rigged Hilbert space and denote
by T the natural embedding of Φ into H. Then there is n ∈N and there are an
orthonormal basis {fk} of H, an orthonormal basis {Fk} of Φ′
n, and there are numbers
λk ≥0 with 
k λk < ∞such that for every φ ∈Φ
T (φ) =
∞

k=1
λkFk(φ)fk .
(29.3)
Proof According to our deﬁnition of a Gelfand triple the space Φn is the completion
of Φ with respect to the norm deﬁned by the inner product hn, in particular Φ0 = H.

444
29
Spectral Analysis in Rigged Hilbert Spaces
Since Φ is assumed to be nuclear there is n ∈N such that the embedding T0n :
Φn →Φ0 is nuclear, i.e., of the form (29.1):
T0n(φ) =
∞

k=1
λkhn(ek, φ)fk
where {ek} is an orthonormal basis of Φn and {fk} an orthonormal basis of Φ0
and where the nonnegative numbers λk satify 
k λk < ∞. As remarked before
Fk(φ) = hn(ek, φ) deﬁnes a continuous linear functional on the Hilbert space Φn and
by construction the set {Fk} is an orthonormal basis of Φ′
n. Since for every φ ∈Φ
one has T (φ) = T0n(φ) the representation formula (29.3) follows.
2
Theorem 29.2 Suppose that in a rigged Hilbert space Φ →H →Φ′ the Hilbert
space has a realization as a space of square integrable functions with respect to some
Borel measure μ on some set X, i.e., there is a unitary map U : H −→L2(X, μ).
Then there is a map F : X −→Φ′, x #→Fx such that for all φ ∈Φ one has for
μ-almost all x ∈X
Fx(φ) = (Uφ)(x).
(29.4)
Proof
Formula 29.3 implies that the embedding UT : Φ −→L2(X, μ) is of the
form
UT (φ) =
∞

k=1
λkFk(φ)hk .
(29.5)
where {hk = Ufk} is an orthonormal basis of L2(X, μ).
Statement 1: For μ-almost all x ∈X the series
Fx =
∞

k=1
λkhk(x)Fk
(29.6)
converges in Φ′
n.
Since Φ′
n is complete it sufﬁces to show that the sequence of partial sums SL(x)
is a Cauchy sequence in Φ′
n for μ-almost all x ∈X. For M > L we estimate
∥SM(x) −SL(x)∥′
n ≤
M

k=L+1
λk|hk(x)| ∥Fk∥′
n .
Thus, since ∥Fk∥′
n = 1, it sufﬁces to show that the numerical series

k
λk|hk(x)|
converges for μ-almost all x ∈X. Recall that {hk} is an orthonormal sequence in
L2(X, μ), therefore we know

X
$
k
λk|hk(x)|2
%
dμ(x) =

k
λk

X
|hk(x)|2dμ(x) =

k
λk < ∞.,

29.2
Spectral Analysis of Self-adjoint Operators and Generalized Eigenfunctions
445
hence the series 
k λk|hk(x)|2 of positive terms converges for μ-almost all x ∈X.
The Cauchy–Schwarz inequality implies
$
k
λk|hk(x)|
%2
≤

k
λk

k
λk|hk(x)|2
which shows that the series 
k λk|hk(x)| converges for μ-almost all x ∈X. This
proves Claim 1.
Statement 2: Statement (29.4) holds.
As a consequence of Statement 1 we know for every φ ∈Φ and for μ-almost all
x ∈X
Fx(φ) =
∞

k=1
λkhk(x)Fk(φ)
and, since the hk are an orthonormal system in L2(X, μ), it follows Fx(φ) ∈L2(X, μ)
and

X
|Fx(φ)|2dμ(x) =

k
λ2
k|Fk(φ)|2.
Since T is an embedding we know Uφ = UT φ and thus by (29.5), for μ-almost all
x ∈X
(Uφ)(x) =
∞

k=1
λkFk(φ)hk(x).
Hence Fx(φ) and (Uφ)(x) agree as elements of L2(X, μ) and thus (29.4) follows.
2
29.2
Spectral Analysis of Self-adjoint Operators
and Generalized Eigenfunctions
29.2.1
Direct Integral of Hilbert Spaces
Recall the construction of direct sums of (a countable family of) separable Hilbert
spaces in Chap. 18. For the general eigenfunction expansion for self-adjoint operators
we need a continuous analogue, called the direct integral of (a continuous family of)
Hilbert spaces. For this construction some basic measure theory is needed.
For a topological space Λ the Borel σ-algebra Σ = Σ(Λ) is the family of all
subsets of Λ generated by countable unions and intersections, and relative comple-
ments of open sets. Any measure μ on Σ is called a Borel measure and (Λ, μ) a
Borel space. A Borel measure on Λ is σ-ﬁnite if Λ has a countable decomposition
into measurable sets of ﬁnite measure.
For further details and proofs of the following deﬁnitions and results we have to
refer to Sect. IV.8 of [6]. A slightly different approach is presented in [2], Sect. I.4.

446
29
Spectral Analysis in Rigged Hilbert Spaces
Deﬁnition 29.2 Suppose that a Borel space Λ with a σ-ﬁnite Borel measure μ is
given. A measurable ﬁeld of Hilbert spaces on (Λ, μ) is a family {H(λ) : λ ∈Λ}
of Hilbert spaces indexed by Λ together with a subspace M of the product vector
space /
λ∈Λ H(λ) with the following speciﬁcations:
(a) For any x ∈M the numerical function on Λ, λ #→∥x(λ)∥is μ-measurable
where ∥·∥is the norm on H(λ).
(b) If for any y ∈/
λ∈Λ H(λ) the numerical function λ #→⟨y(λ), x(λ)⟩is μ-
measurable for every x ∈M, then y belongs to M. Naturally, ⟨·, ·⟩denotes
here the scalar product of the Hilbert space H(λ).
(c) Existence of a fundamental sequence of μ-measurable vector ﬁelds: There ex-
ists a countable subset {xn : n ∈N} of M such that for every λ ∈Λ the set
{xn(λ) : n ∈N} is total in the Hilbert space H(λ).
The elements of M are called μ-measurable vector ﬁelds.
Lemma 29.1 Suppose that {H(λ) : λ ∈Λ} is a measurable ﬁeld of Hilbert spaces
on the Borel space (Λ, μ). Then the function λ #→N(λ) = dim H(λ) is measurable
on Λ and there exists a fundamental sequence {xn} of measurable vector ﬁelds such
that
(a)

x1(λ), . . . , xN(λ)(λ)

is an orthonormal basis of H(λ) for every λ ∈Λ,
(b) if N(λ) is ﬁnite, then xN(λ)+k(λ) = 0 for all k = 1, 2, . . . .
Assume now that {H(λ) : λ ∈Λ} is a measurable ﬁeld of Hilbert spaces on the Borel
space (Λ, μ) with a positive σ-ﬁnite measure μ. Denote by H the family of all
measurable vector ﬁelds x such that
∥x∥=

Λ
∥x(λ)∥2 dμ(λ)
1/2
< ∞
(29.7)
where naturally the norm of the integrand is the norm of the Hilbert space H(λ). As
usual in L2 spaces addition and scalar multiplication are deﬁned pointwise; thus H
becomes a vector space on which a scalar product is naturally deﬁned by
⟨x, y⟩=

Λ
⟨x(λ), y(λ)⟩dμ(λ),
x, y ∈H.
(29.8)
Clearly the scalar product of the integrand is that of H(λ). If we identify two vector
ﬁelds x and y whenever x(λ) = y(λ) μ-almost everywhere then one shows as for
standard L2 spaces that H is complete with respect to the scalar product (29.8) ; thus
H is a Hilbert space.
Deﬁnition 29.3 The Hilbert space H constructed above is called the direct integral
of the measurable ﬁeld of Hilbert spaces H(λ) and written as
H = Hμ,N =
 ⊕
Λ
H(λ)dμ(λ)

29.2
Spectral Analysis of Self-adjoint Operators and Generalized Eigenfunctions
447
and accordingly its element x ∈H are written as
x =
 ⊕
Λ
x(λ)dμ(λ).
29.2.2
Classical Versions of Spectral Representation
Recall the Spectral Theorem 27.5 for a self-adjoint operator A in a separable Hilbert
space H. Then, given any Borel function f : σ(A) −→C the operator f (A) is
deﬁned with the help of Theorem 27.4 by
f (A) =

σ(A)
f (λ)dEλ on D(f(A)) =
+
x ∈H :

σ(A)
|f(λ)|2d ∥Eλx∥2 < ∞
,
.
(29.9)
This classical version can be used to prove the functional version of the spectral
theorem [7, 8] which we recall without proof.
Theorem 29.3 (Spectral Theorem—Functional Form) Given a self-adjoint oper-
ator A on a separable Hilbert space H there exist a nonnegative Borel measure μ
on the spectrum σ(A) of A, a direct integral of separable Hilbert spaces Hλ
Hμ,N =
 ⊕
σ(A)
Hλdμ(λ),
N(λ) = dim (Hλ),
and a unitary operator U : H −→Hμ,N such that the operator UAU −1 is diagonal
on Hμ,N, i.e.
UAU −1 =

σ(A)
λIλdμ(λ),
Iλ = idHλ.
(29.10)
Borel functions f (A) of A have the now the convenient representation
Uf (A)U −1 =

σ(A)
f (λ)Iλdμ(λ),
(29.11)
i.e., for all x ∈H and all y ∈D(f (A)) one has
⟨x, f (A)y⟩H = ⟨Ux, Uf (A)U −1Uy⟩Hμ,N =

σ(A)
f (λ)⟨(Ux)(λ), (Uy)(λ)⟩Hλdμ(λ),
where the scalar products in the various Hilbert spaces are indicated explicitly.
Remark 29.1 If a self-adjoint operator A has a cyclic vector, i.e., a vector x0 ∈H
such {E(Δ)x0 : Δ ⊂σ(A), interval} is dense in H2 then Theorem 29.3 has a much
2 in Proposition 5.20 of [9] it is shown that this condition is equivalent to the existence of a vector
x0 ∈∩nD(An) such that the linear span of {Anx0 : n = 0, 1, 2, 3, . . . } is dense in H.

448
29
Spectral Analysis in Rigged Hilbert Spaces
simpler form and the data in this theorem can be constructed easily. Deﬁne the
measure μ by
μ(Δ) = ∥E(Δ)x0∥2 = ⟨x0, E(Δ)x0⟩
and U : H −→L2(μ) by continuous linear extension of the isometric mapping
E(Δ)x0 #→χΔ where χΔ is the characteristic function of the interval Δ ⊂σ(A):
∥E(Δ)x0∥2 = μ(Δ) =

|χΔ(λ)|2dμ(λ).
A similar calculation shows that for pairwise disjoint sets Δj and complex numbers
aj respectively sets Δ′
i and complex numbers bi one has
; n

j=1
ajE(Δj)x0,
m

i=1
biE(Δ′
i)x0
<
=

n

j=1
¯ajχΔj (λ)
m

i=1
biχΔ′
i(λ)dμ(λ)
so that U is actually deﬁned by continuous linear extension of the mapping U0,
U0
⎛
⎝
n

j=1
ajE(Δj)x0
⎞
⎠=
n

j=1
ajχΔj .
Then, by inserting the spectral representation of A, we ﬁnd for any interval Δ
⟨x0, AE(Δ)x0⟩H =

λχΔ(λ)dμ(λ).
Since arbitrary y ∈H are the limit of sums of the form m
i=1 aiE(Δi)x0 with ai ∈C
and intervals Δi ⊂σ(A) this formula can be extended to the following
⟨y, Ax⟩H =

σ
(Uy)(λ)λ(Ux)(λ)dμ(λ)
for all y ∈H and x ∈D(A) which shows
UAU −1 = λI,
I = idL2(σ(A),μ).
Thus in this case one has Hλ = C for all λ ∈σ(A) and the direct integral of Hilbert
spaces in Theorem 29.3 reduces to a simple Lebesque space L2(μ) = L2(σ(A), dμ)
over the spectrum with a measure deﬁned in terms of the spectral family of the
self-adjoint operator A.
Remark 29.2
In general a self-adjoint operator A on a separable Hilbert space
H has no cyclic vector. Then a much more involved construction is needed since
now substantial parts of spectral multiplicity theory for self-adjoint operators are
required. This naturally is beyond the scope of our brief discussion.A comprehensive
exposition of this theory can for instance be found in [8]. This general case relies on
the use of a direct integral of Hilbert spaces. Here we indicate the ﬁrst steps. At ﬁrst
the given separable Hilbert space H is decomposed into spectral subspaces:

29.2
Spectral Analysis of Self-adjoint Operators and Generalized Eigenfunctions
449
Choose a unit vector x1 ∈H and deﬁne a Borel measure μ1 as above by μ1(Δ) =
∥E(Δ)x1∥2 and a Hilbert space H1 as the closed linear subspace of H generated by
{E(Δ)x1 : Δ ⊂σ(A), interval}. Again there is a unitary map U1 : H1 −→L2(μ1).
Next select a unit vector x2 ∈H⊥
1 and do the same construction with x2 replacing x1
to get a Hilbert subspace H2, a Borel measure μ2 and a unitary map U2 : H2 −→
L2(μ2). By repeating this construction we arrive at the decomposition
H =
N
:
j=1
Hj ∼=
N
:
j=1
L2(μj)
with N ∈N or N = ∞, since H is separable.
Then one has to deﬁne a suitable direct integral of Hilbert spaces Hμ,N and has
to construct a unitary map
U :
N
:
j=1
L2(μj) −→Hμ,N.
Here many (technical) details, mainly about measures and spectral measures, are
involved for which we have to refer to [8].
29.2.3
Generalized Eigenfunctions
Suppose we are given a Gelfand triple Φ →H →Φ′ and a linear operator A
on Φ which maps Φ continuously into itself and whose closure A is a self-adjoint
operator in H. An element Fλ ∈Φ′ is called a generalized eigenfunction of A
corresponding to the (generalized) eigenvalue λ ∈R if, and only if, for all φ ∈Φ
Fλ(Aφ) = λFλ(φ).
(29.12)
Since A maps Φ continuously into itself its dual is a well deﬁned map A′ : Φ′ −→Φ′
and the deﬁning equation for generalized eigenfunctions can be written as an equation
in Φ′:
A′Fλ = λFλ.
Note that for λ ∈σp(A) the eigenfunction ψλ ∈D(A) can also be considered as a
generalized eigenfunction ˆψλ via the (antilinear) embedding of H into Φ′: For all
φ ∈Φ one has
ˆψλ(Aφ) = ⟨ψλ, Aφ⟩= ⟨Aψλ, φ⟩= ⟨λψλ, φ⟩= λ ˆψλ(φ).
For given λ ∈σ(A) denote by Φ′
λ ≡Φ′
λ(A) =

F ∈Φ′ : A′F = λF

the space of
corresponding generalized eigenvectors and then for φ ∈Φ deﬁne ˜φλ : Φ′
λ −→C

450
29
Spectral Analysis in Rigged Hilbert Spaces
by ˜φλ(F) = F(φ). The assignment
φ #→˜φλ,
λ ∈σ(A)
is called the spectral decomposition of φ corresponding to the operator A. Naturally
the spectral decomposition of ψ = Aφ is ˜ψλ = λ ˜φλ since for all F ∈Φ′
λ
˜ψλ(F) = F(Aφ) = λF(φ) = λ ˜φλ(F).
Deﬁnition 29.4
As above let A be a self-adjoint operator in the Gelfand triple
Φ →H →Φ′. The set of generalized eigenvectors of A is called complete if, and
only if,
˜φλ ≡0 ⇒φ = 0
for φ ∈Φ.
Example 29.1
Consider again the operator A ≡P =
1
i
d
dx in the Gelfand triple
Φ →H →Φ′ with H = L2(R) and Φ = S(R). We know σ(P) = R and for q ∈R
the generalized eigenvector Fq ∈Φ′ for P is the regular distribution Ieq deﬁned by
the exponential eq(x) = e i xq, since, because of the antilinear embedding of H into
Φ′, one has
Fq(P φ) =

e −i qx 1
i
d
dx φ(x)dx = q

e −i qxφ(x)dx = qFq(φ)
for all φ ∈Φ. The corresponding spectral decomposition of φ ∈Φ is given by
˜φq, q ∈R where ˜φq(Fq) = Fq(φ) = (2π)1/2 ˜φ(q) is proportional to the Fourier
transform of φ. And we know that the Fourier transform is an isomorphism on S(R).
Thus the system of generalized eigenvectors of P is complete.
29.2.4
Completeness of Generalized Eigenfunctions
In order to proceed we need the counter part of Theorem 29.2 where the space
L2(X, μ) is replaced by a direct integral Hμ,N of Hilbert spaces Hλ, λ ∈Λ, Deﬁnition
29.3. Naturally this case is more involved.
Theorem 29.4 Suppose that in a rigged Hilbert space Φ →H →Φ′ the Hilbert
space has a realization as a direct integral Hμ,N of Hilbert spaces Hλ with respect
to a positive Borel measure μ on Λ, i.e., there is a unitary map
U : H −→Hμ,N =
 ⊕
Λ
Hλdμ(λ).
Then there exist n ∈N and a map F which assigns to every λ ∈Λ a continuous
linear map Fλ : Φn −→Hλ such that for all φ ∈Φ one has for μ-almost all λ ∈Λ
Fλ(φ) = (Uφ)(λ) ∈Hλ.
(29.13)

29.2
Spectral Analysis of Self-adjoint Operators and Generalized Eigenfunctions
451
Proof According to Theorem 29.1 there is n ∈N such that the natural embedding
T : Φ −→H is of the form (29.3). Hence the embedding of Φ into Hμ,N is of the
form
UT (φ) =
∞

k=1
λkFk(φ)hk
φ ∈Φ,
(29.14)
where {hk = Ufk} is an orthonormal basis of Hμ,N. It follows that
∥UT (φ)∥2
Hμ,N =
∞

k=1
λ2
k|Fk(φ)|2 < ∞
since |Fk(φ)| ≤∥φ∥n for all k and 
k λk < ∞. As an orthonormal system in Hμ,N
the elements hk satisfy

Λ ∥hk(λ)∥2
Hλ dμ(λ) = 1 and therefore, because the series
contains only nonnegative terms,
∞

k=1
λk
= ∞
k=1 λk

Λ ∥hk(λ)∥2
Hλ dμ(λ)
=

Λ
∞
k=1 λk ∥hk(λ)∥2
Hλ dμ(λ)
and we deduce that the series
∞

k=1
λk ∥hk(λ)∥2
Hλ
converges for μ-almost all λ ∈Λ. The Cauchy–Schwarz inequality implies that the
series
∞

k=1
λk ∥hk(λ)∥Hλ
converges for μ-almost all λ ∈Λ. Since |Fk(φ)| ≤∥φ∥n for all k, it follows that for
every φ ∈Φ the series
∞

k=1
λkFk(φ)hk(λ)
(29.15)
converges in Hλ for μ-almost all λ ∈Λ and deﬁnes an element Fλ(φ) ∈Hλ such
that
∥Fλ(φ)∥Hλ ≤
∞

k=1
λk ∥hk(λ)∥Hλ ∥φ∥n
Since T is an embedding we know φ = T φ and thus Uφ = UT φ and therefore by
(29.14) Uφ(λ) and Fλ(φ) have the same series representation (29.15), hence (29.13)
follows.
2

452
29
Spectral Analysis in Rigged Hilbert Spaces
Theorem 29.5 (Existence and Completeness of Generalized Eigenfunctions)
Suppose that A is a self-adjoint operator in a separable Hilbert space H for which
a rigging Φ →H →Φ′ exists such that Φ ⊂D(A) and such that A : Φ −→Φ
is continuous. Then A has a complete set of generalized eigenfunctions in Φ′.
Proof Apply Theorem 29.4 in the case where the direct integral of Hilbert spaces is
determined by the functional form of the spectral theorem (Theorem 29.3), i.e.,
Hμ,N =
 ⊕
σ(A)
Hλdμ(λ).
Thus there is n ∈N and a map F on σ(A) with values Fλ which are continuous
linear mappings Φn −→Hλ such that for all φ ∈Φ and for μ-almost all λ ∈σ(A)
Relation (29.13) holds. Taking (29.10) into account we ﬁnd for every φ ∈Φ and
μ-almost all λ ∈σ(A)
Fλ(Aφ) = U(Aφ)(λ) = (UAU −1)(Uφ)(λ) = λ(Uφ)(λ) = λFλ(φ).
Since A : Φ −→Φ is continuous its adjoint A′ is well deﬁned on Φ′ by duality
and for μ-almost all λ ∈σ(A) one has A′Fλ = λFλ, hence the Fλ are Hλ-valued
generalized eigenfunction of A and for x ∈Hλ the inner products ⟨x, Fλ⟩∈Φ′
λ are
generalized eigenfunctions of A.
Let
φ #→˜φλ,
λ ∈σ(A)
be the spectral decomposition of φ ∈Φ with respect to the operator A and suppose
˜φλ = 0 for μ-almost all λ ∈σ(A). By deﬁnition this means Uφ(λ) = Fλ(φ) = 0
for μ-almost all λ ∈σ(A) and thus
∥φ∥2
H = ∥Uφ∥2
Hμ,N =

σ(A)
∥Uφ(λ)∥2
Hλ dμ(λ) = 0,
hence φ = 0 and our system of generalized eigenfunctions of A is complete.
2
Remark 29.3 Since in Theorem 29.5 nuclearity plays a prominent rôle, it is often
called the nuclear spectral theorem. There are several approaches to prove the
existence and completeness of generalized eigenfunctions for self-adjoint operators.
A fairly comprehensive list of references for these approaches and for applications
in Physics can be found for instance in [10]. Our exposition is based on early results
by Gelfand [2].
Remark 29.4 It is a simple exercise to show that Theorem 29.5 applies to the mo-
mentum operator P considered in Example 29.1 and thus proves the existence and
completeness of the system of generalized eigenfunctions for P which had been
shown by elementary means in this case.
If we review the proof of Theorem 29.5 we see easily that the assumptions could
be weakened. Instead of assuming that the given Hilbert space H is rigged by a

References
453
nuclear space Φ it is enough to assume that there is some Hilbert space Φn which
is densely embedded into H by a nuclear map and on which the given self-adjoint
operator A acts continuously.
Such a version is important for instance if the given self-adjoint operator A is a
Schrödinger operator H = 1
2P 2 + V (Q) in H = L2(R3): If we would work in the
rigged Hilbert space S(R3) →L2(R3) →S′(R3), the condition that H maps S(R3)
continuously into itself, requires that the potential is a multiplicator for S(R3), i.e.,
a C∞function with all derivatives polynomially bounded. But often one has to deal
with potentials V with much less regularity. If one can ﬁnd a Sobolev-type space Φn
on which H acts continuously and which is embedded into L2(R3) by a nuclear map
then one could work under much weaker assumptions on V .
29.3
Exercises
1. Show that the system of Hilbertian norms deﬁned by the inner products hn on
S(R) in Sect. 29.1.3.2 is equivalent to the original system of norms on this space.
2. Complete the argument in Remark 29.2 and thus show Theorem 29.3.
Hint: Consult for instance the Appendix to Chap. I of [2].
3. Prove that the position operator Q in L2(R) has a complete set of generalized
eigenfunctions.
References
1. Grothendieck A. Produits tensoriels topologiques et espaces nucléaires. Memoirs AMS.
1955;16.
2. Gel’fand IM, Vilenkin NYa. Generalized functions Vol. 4: applications of harmonic analysis.
New York: Academic; 1964. (trans: A Feinstein).
3. Pietsch A. Nuclear locally convex spaces. Ergebnisse der Mathematik und ihrer Grenzgebiete.
vol. 66. Berlin: Springer-Verlag; 1965.
4. Schaefer HH. Topological vector spaces. GTM. vol. 3. New York: Springer-Verlag; 1971.
5. Robertson AP, Robertson WJ. Topological vector spaces. Cambridge: Cambridge University
Press; 1973.
6. Takesaki M. Theory of operator algebras I. Encyclopedia of mathematical sciences—operator
algebras and non-commutative geometry. vol. 124. Berlin: Springer; 2002.
7. von Neumann J. On rings of operators. Reduction theory. Ann Math. 1949;50:401–485.
8. Birman MS, Solomjak MZ. Spectral Theory of self-adjoint operators in Hilbert space. Boston:
Reidel; 1987.
9. Schmüdgen K. Unbounded self-adjoint operators on Hilbert space. Graduate texts in
mathematics. vol. 265. Dordrecht: Springer; 2012.
10. Gadella M, Gómez F. A measure-theoretic approach to the nuclear and inductive spectral
theorems. Bull Sci Math. 2005;129:567–590.

Chapter 30
Operator Algebras and Positive Mappings
30.1
Representations of C∗-Algebras
In quantum mechanics, in local quantum ﬁeld theory (Haag), in the functional ap-
proach to relativistic quantum ﬁeld theory (Gårding–Wightman), and in quantum
information theory positive functionals and completely positive mappings play a fun-
damental role, mainly in connection with the mathematical description of “states”
of quantum systems and their manipulation. For further details about the physical
background we recommend [1, 2].
In this chapter, we present the most important structural results for positive lin-
ear functionals and completely positive maps, namely the Gelfand–Naimark–Segal
representation for positive linear functionals (on C∗-algebras) and the Stinespring
factorization theorem. The natural mathematical framework for these results is the
theory of abstract C∗-algebras and we formulate these results in this framework,
but in our proofs we consider only the cases of C∗-algebras of operators on Hilbert
spaces. This allows to use some simpliﬁcation in the characterization of positive el-
ements in these algebras. For the general case we refer to the literature, for instance
[3]. In this and in the following chapter elements of a (general or abstract) algebra
are denoted by small Latin letters.
Deﬁnition 30.1 Let A be an algebra over the ﬁeld C. If A admits an involution ∗
which is compatible with the algebraic structure of A, i.e., a mapping a #→a∗such
that for all a, b ∈A the following holds:
(a∗)∗= a,
(λa)∗= λa∗, λ ∈C
(a + b)∗= a∗+ b∗
(ab)∗= b∗a∗
A is called an involutive algebra or a ∗-algebra. If A admits a norm ∥·∥under which
A is a Banach space such that
∥ab∥≤∥a∥∥b∥
for all
a, b ∈A
then A is called a Banach algebra. If a Banach algebra A has an involution ∗for
which the norm satiﬁes ∥a∗∥= ∥a∥for all a ∈A such that A is ∗-algebra then A is
called an involutive Banach algebra or a Banach ∗-algebra.
© Springer International Publishing Switzerland 2015
455
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_30

456
30
Operator Algebras and Positive Mappings
If in addition the norm of an involutive Banach algebra satisﬁes the Gelfand
condition
--a∗a
-- =
--aa∗-- = ∥a∥2
for all a ∈A
it is called a C∗-algebra.
Often an involutive Banach algebra or a C∗-algebra contains a unit I. Then we
assume that ∥I∥= 1.
Deﬁnition 30.2 Suppose that A, B are ∗-algebras. A map π : A −→B is called
a homomorphism of ∗-algebras or a ∗-homomorphism if, and only if, it respects
the structure of a ∗-algebra, i.e.,
π(αa + βb)
=
απ(a) + βπ(b),
∀a, b ∈A, ∀α, β ∈C;
(30.1)
π(ab)
=
π(a)π(b),
∀a, b ∈A;
(30.2)
π(a∗)
=
π(a)∗, ∀a ∈A .
(30.3)
Many results about abstract C∗-algebras are obtained by studying properties of their
representations by operators on a Hilbert space where one deﬁnes
Deﬁnition 30.3
Let A be a C∗-algebra. A representation (π, H) of A is a ∗-
homomorphism π of A into the C∗-algebra B(H) of all bounded linear operators on
a Hilbert space H.
A representation (π, H) of A is called cyclic if there exists a cyclic vector, i.e., a
vector x ∈H such that the closed linear subspace [π(A)x] generated by all π(a)x ∈
H equals the representation space H:
[π(A)x] = H.
30.1.1
Representations of B(H)
For the C∗-algebra of all bounded linear operators on a Hilbert space the general
form of its representations can be determined. This result will be used later in our
analysis of completely positive maps.
By Theorem 22.3.4 we know that the set of all compact operators Bc(H) on a (sep-
arable) Hilbert space H is a C∗-algebra (without unit, if H is inﬁnite dimensional).
The following result clariﬁes the structure of all its representations.
Theorem 30.1 Every continuous representation (π, Hπ) of the C∗-algebra Bc(H)
is equivalent to the direct sum =
n (πn, Hn) of the identity representation πn, A #→A,
A ∈Bc(H), and the zero representation A #→0, A ∈Bc(H).
Proof
Let {en} be an orthonormal basis of H and denote by Pn the orthogonal
projector onto the one-dimensional subspace [en] = Cen spanned by en. By Theorem

30.1
Representations of C∗-Algebras
457
22.3.2 we know that for A ∈Bc(H) the ﬁnite rank operators
A
N

n=1
Pn,
N ∈N
converge in (operator) norm to A. Since the sequence of projectors M
j=1 Pj, M ∈N
is bounded in norm (by 1) it follows that
A =
lim
M,N→∞
M

j=1
N

n=1
PjAPn
in B(H).
(30.4)
Now calculate for x ∈H
PjAPnx = ⟨ej, Aen⟩⟨en, x⟩ej
and deﬁne operators Ujn on H by
Ujnx = ⟨en, x⟩ej.
Then we can write
PjAPn = ajnUjn,
ajn = ⟨ej, Aen⟩.
(30.5)
TheoperatorsUjn arepartialisometriesfrom[en]to[ej]whichsatisfyforallj, n, m ∈
N
Unn = Pn, U ∗
jn = Unj, UjnUnm = Ujm
(30.6)
As ﬁnite rank operator all the operators Pn, Ujn belong to Bc(H). Note also that for
any ﬁxed n ∈N the closure of the ranges of all the operators

Ujn : j ∈N

is H.
Now let (π, Hπ) be a continuous representation of Bc(H). For every A ∈Bc(H),
it follows
π(A) =
lim
M,N→∞
M

j=1
N

n=1
π(Pj)π(A)π(Pn) =
lim
M,N→∞
M

j=1
N

n=1
ajnπ(Ujn).
(30.7)
Therefore, the knowledge of all the π(Ujn) allows to ﬁnd the representatives π(A)
for all A ∈Bc(H). Since π is a representation, the relations (30.6) also hold for the
representing operators π(Pn) and π(Ujn). For n ∈N deﬁne
Mn = ran (π(Pn)) ⊂Hπ.
Since π(Pn)π(Pj) = 0 for n ̸= j the closed subspaces Mn of Hπ are pairwise or-
thogonal for different indices. Relations (30.6) for π(Pn), π(Ujn) imply furthermore
that the operators π(Ujn) are partial isometries with initial domain Mn and range
Mj. Hence, all the subspaces {Mn} have the same dimension.

458
30
Operator Algebras and Positive Mappings
If π(Pn) = 0 for all n ∈N, then by (30.7) one has π(A) = 0 for all A ∈Bc(H)
and π is the zero representation. If π is not the zero representation, there is n ∈N
such that π(Pn) ̸= 0 and thus Mn ̸= {0}. Hence, there is a unit vector fn ∈Mn and
we can deﬁne an orthonormal system

fj

in Hπ by setting
fj = π(Ujn)fn,
for all j ∈N.
This orthonormal system generates a closed linear subspace Mπ ⊂Hπ:
Mπ = [

fj

].
We now show that this subspace is invariant under all π(A), A ∈Bc(H): Observe
ﬁrst that
π(Ujm)fk = π(Ujm)π(Ukn)fn = 0 for m ̸= k
π(Ujm)fm = π(Ujm)π(Umn)fn = π(Ujn)fn = fj
holds. Because of (30.5) this implies
π(Pj)π(A)π(Pm)fk = 0
for m ̸= k
(30.8)
π(Pj)π(A)π(Pm)fm = ajmfj.
(30.9)
Thus, all the operators π(Pj)π(A)π(Pm) are reduced by the subspace Mπ; now
(30.7) implies that all operators π(A), A ∈Bc(H), are reduced by this subspace too.
In the subspace Mπ the operator π(Pj) is the projection onto the subspace Cfj,
j ∈N, hence by (30.9) the matrix
[ajm] = [⟨ej, Aem⟩] = [⟨fj, π(A)fm⟩Mπ ]
(30.10)
is the matrix of π(A) with respect to the orthonormal basis

fj

of Mπ.
Next, deﬁne an isometric mapping V of H onto Mπ by setting
V ej = fj,
j ∈N
and extend it by linearity and continuity to all of H. Relation (30.10) implies
V ∗π(A)V = A
for all A ∈Bc(H)
and thus the representation π is unitarily equivalent to the identity representation.
If Mπ = Hπ, we are done. Otherwise look at the orthogonal complement M⊥
π of
Mπ in Hπ. Certainly, M⊥
π is invariant under all π(A), A ∈Bc(H). For all x ∈Mπ
and all y ∈M⊥
π we have
⟨x, π(A)y⟩Hπ = ⟨π(A∗)x, y⟩Hπ = 0
since π(A∗)x ∈Mπ. Thus, the restriction of π(A) to M⊥
π deﬁnes a representation of
Bc(H) in M⊥
π and we can proceed as above to ﬁnd an invariant subspace M′
π of M⊥
π

30.1
Representations of C∗-Algebras
459
on which this representation is unitarily equivalent to the identity representation.
Now by iteration of this argument we conclude.
2
Theorem 30.2 (Naimark) Every representation (π, Hπ) of the C∗-algebra B(H) of
all bounded operators on a separable Hilbert space H is the direct sum of identity
representations A #→A and a representation of the quotient algebra B(H)/Bc(H).
If the representation of this quotient algebra is not the zero representation, then
it is an isomorphism of B(H)/Bc(H) into the algebra of bounded linear operators
on a Hilbert space.
Proof Since B(H) is a C∗-algebra with unit Theorem 30.3 implies that every rep-
resentation of it is continuous. Therefore, a representation (π, Hπ) of B(H) is at
the same time a continuous representation of Bc(H) ⊂B(H). Thus Theorem 30.1
applies. Hence, modulo a unitary map the representation space Hπ is the direct sum
=
n Hn of copies Hn = H of H and a space H0. In each of the spaces Hn, the
representation π is the identity representation of Bc(H) while in H0 it is the zero
representation. We have to show that for arbitrary but ﬁxed n, the representation π
of B(H) also reduces to the identity representation in Hn.
With the orthogonal projector Qn : Hπ −→Hn introduce π(A)n = Qnπ(A)Qn,
i.e.,
π(A)nx = Qnπ(A)x
for all x ∈Hn.
Clearly, π(A)n is a well deﬁned bounded linear operator on Hn. We show π(A)n = A
by showing that their matrices coincide, calculated with respect to an ONB

ej

of
Hn = H. For the projection operator Pj onto Cej, we have as earlier for all i, j ∈N,
PiAPj = aijUij
and thus
π(Pi)π(A)π(Pj) = π(PiAPj) = aijUij.
Recall Pj, Uij, PiAPj ∈Bc(H) and thus we can calculate as follows:
⟨ei, π(A)nej⟩= ⟨Qnei, π(A)ej⟩= ⟨ei, π(A)ej⟩=
⟨Piei, π(A)Pjej⟩= ⟨ei, Piπ(A)Pjej⟩= aij⟨ei, Uijej⟩= aij
and we conclude π(A)n = A.
It follows, for all x ∈Hn, A, B ∈B(H),
Qnπ(A)π(B)x = (AB)x,
Qnπ(A)Qnπ(B)x = A(Bx),
and therefore Qnπ(A)(π(B)x) = Qnπ(A)Qn(π(B)x). Denote the closed linear hull
of the set {π(B)x : x ∈Hn, B ∈B(H)} by H′
n. Then the above argument shows that
in H′
n one has
Qnπ(A) = Qnπ(A)Qn.
(30.11)

460
30
Operator Algebras and Positive Mappings
Naturally Hn ⊂H′
n and therefore Qn = 0 on H′
n
⊥⊂Hπ. As earlier one shows that
H′
n and H′
n
⊥are invariant under all π(A), A ∈B(H), hence Qnπ(A) = 0 in H′
n
⊥
and (30.11) holds in all of Hπ.
Now apply the involution to (30.11) and in the result replace A∗by A. This gives
π(A)Qn = Qnπ(A)Qn and thus
Qnπ(A) = π(A)Qn,
i.e., the space Hn reduces all the operators π(A), A ∈B(H). In the space Hn the
identity π(A)n = A now takes the form
Ax = Qnπ(A)x = π(A)Qnx = π(A)x,
x ∈Hn
and thus in the space Hn the representation of all of B(H) reduces to the identity
representation.
2
30.2
On Positive Elements and Positive Functionals
An element a of a ∗-algebra A is called positive if, and only if, one of the following
equivalent conditions hold:
a = b∗b
for some
b ∈A;
(30.12)
a = c2
for some
c ∈Ah =

a ∈A : a∗= a

.
(30.13)
In the case that A is a C∗-algebra of operators on a Hilbert space H or a subspace of
such an algebra one has a third characterization of positive elements a, namely
⟨x, ax⟩≥0
for all
x ∈H.
(30.14)
In this case the proof of equivalence of these three conditions is straightforward
by using the square root lemma (Theorem 21.5.1) and the polar decomposition of
operators (Theorem 21.5.2). For the characterization of positive elements in abstract
C∗-algebras one has to refer to the spectral theory for these algebras (see Theorem
6.1 of [3]).
Using the characterization (30.14) of positive elements, it follows easily that the
set A+ of all positive elements in A is a closed convex cone, i.e., if a, b ∈A+ and
α, β ≥0 then αa + βb ∈A+. This cone satisﬁes A+ ∩(−A+) = {0}. Hence
A+ induces an order in the real Banach space Ah of hermitian elements in A. For
a, b ∈Ah we write a ≥b if, and only if, a −b ∈A+.
Deﬁnition 30.4 A linear map f : A −→C on a C∗-algebra A is called a positive
functional if its restriction to the cone A+ of positive elements has only nonnegative
values, i.e., if f (a) ≥0 for all a ∈A+.

30.2
On Positive Elements and Positive Functionals
461
The following proposition collects the basic facts about positive linear functionals.
Proposition 30.1 For a positive linear functional f on a C∗-algebra A with unit
one has:
(a) For all a, b ∈A
f (a∗b) = f (b∗a)
(30.15)
|f (a∗b)|2 ≤f (a∗a)f (b∗b)
(30.16)
(b) f is continuous and ∥f ∥= f (I).
Proof For the proof of the ﬁrst part of (a) take arbitrary a, b ∈A and apply f to the
two polarization identities
4a∗b =
3

j=0
i j(b + i ja)∗(b + i ja),
4ba∗=
3

j=0
i j(b + i ja)(b + i ja)∗
and compare the results. For the proof of the estimate take arbitrary a, b ∈A and
arbitrary α, β ∈C and observe
0 ≤f ((αa + βb)∗(αa + βb))
= |α|2f (a∗a) + αβf (a∗b) + αβf (b∗a) + |β|2f (b∗b),
thus, because of (30.15), the quadratic form on C
|α|2f (a∗a) + 2Re(αβf(a∗b)) + |β|2f(b∗b)
is nonnegative, hence its coefﬁcients have to satisfy (30.16).
For the proof of (b) observe for all a ∈A and all x ∈H
⟨x, a∗ax⟩= ∥ax∥2 ≤∥a∥2 ∥x∥2 ,
thus
a∗a ≤∥a∥2 I,
(30.17)
and hence for a positive functional f it follows f (a∗a) ≤∥a∥2 f (I). The Cauchy–
Schwarz inequality (30.16) implies |f (a)|2 ≤f (I ∗I)f (a∗a) and we ﬁnd for all
a ∈A
|f (a)| ≤f (I) ∥a∥
and this proves that f is continuous and that ∥f ∥= sup {|f (a)|; a ∈A, ∥a∥≤1} ≤
f (I). But clearly f (I) ≤∥f ∥and therefore ∥f ∥= f (I).
2

462
30
Operator Algebras and Positive Mappings
Let us consider some simple examples of positive functionals on a C∗-algebra
A of operators on a Hilbert space H:
For x ∈H deﬁne a function fx : A →C by
fx(a) = ⟨x, ax⟩
for all
a ∈A.
(30.18)
Clearly, by condition (30.14) this functional is positive when restricted to A+ .
Theorem 30.3
Every representation (π, H) of a C∗-algebra A with unit I is
continuous and for all a ∈A
∥π(a)∥≤∥a∥.
Proof
Given a representation (π, H) of A, take x ∈H and deﬁne a functional
fx : A −→C by
fx(a) = ⟨x, π(a)x⟩
for all a ∈A.
Since π is a ∗-homomorphism, fx is a positive functional on A: For all a ∈A one
has
fx(a∗a) = ∥π(a)x∥2 ≥0.
By Proposition 30.1 the norm of this functional is ∥fx∥= fx(I) = ∥x∥2. It follows
∥π(a)x∥2 = fx(a∗a) ≤∥fx∥
--a∗a
-- = ∥x∥2 ∥a∥2
and thus ∥π(a)x∥≤∥x∥∥a∥, hence ∥π(a)∥= sup {∥π(a)x∥: x ∈H, ∥x∥≤1} ≤
∥a∥.
2
30.2.1
The GNS-Construction
In this section we provide the answer to the question: What is the general form of
positive functionals on a C∗-algebra with unit?
The answer is well known since many years and is given by the GNS-construction
(Gelfand–Naimark–Segal) which we explain now. This construction can be done in
a much more general setting. In the algebraic framework of quantum physics this
construction allows to recover the Hilbert space of the theory.
Theorem 30.4 (GNS-Construction for A) Let f be a positive functional on a C∗-
algebra A with unit I with f (I) = 1. Then there is a Hilbert space Hf , a unit vector
Ωf ∈Hf , and a mapping πf on A with values in the space B(Hf ) of bounded
linear operators on Hf with the following properties:
1. πf : A −→B(Hf ) is linear;
2. πf (ab) = πf (a)πf (b) for all a, b ∈A;
3. πf (a∗) = πf (a)∗for all a ∈A;

30.2
On Positive Elements and Positive Functionals
463
such that
f (a) = ⟨Ωf , πf (a)Ωf ⟩
for all a ∈A
(30.19)
where ⟨·, ·⟩denotes the scalar product of Hf .
In addition one has [πf (A)Ωf ] = Hf , i.e., Ωf is cyclic so that πf is a cyclic
representation of A.
The triple (Hf , Ωf , πf ) is unique up to unitary equivalence, i.e., if we also have
f (a) = ⟨Ω, π(a)Ω⟩for all a ∈A where the triple (H, Ω, π) has the properties
speciﬁed above for (Hf , Ωf , πf ) then there is a unitary operator U : Hf →H such
that Ω = UΩf and π(a) = Uπf (a)U ∗for all a ∈A.
Proof Construction of Hf : Deﬁne
If =

a ∈A : f (a∗a) = 0

.
By Proposition 30.1 the given functional f is continuous on A; since a −→a∗a is
continuous on A, If is a closed subset. If a, b ∈If then,
f ((a + b)∗(a + b)) = f (a∗a) + 2Re(f(a∗b)) + f(b∗b) = 2Re(f(a∗b)) = 0
since by (30.16) 2Re(f(a∗b)) ≤f(a∗a)f(b∗b), hence a +b ∈If . Similarly, for a ∈A
and b ∈If the Cauchy–Schwarz inequality (30.16) implies that
f ((ab)∗(ab)) = f (b∗a∗ab)) ≤f (b∗b)1/2f ((a∗ab)∗(a∗ab))1/2 = 0,
hence ab ∈If . Since If is obviously invariant under multiplication with scalars we
conclude that If is a closed left ideal in A.
A · If ⊆If .
(30.20)
Form the quotient space H0
f of A with respect to If , i.e., the space of all equivalence
classes
[a]f = a + If ,
a ∈A;
(30.21)
H0
f = A/If =

[a]f : a ∈A

.
(30.22)
On H0
f deﬁne addition and scalar multiplication of equivalence classes through their
representatives, i.e.,
[a]f + [b]f = [a + b]f , λ[a]f = [λa]f ,
∀λ ∈C, a, b ∈A.
Thus, H0
f becomes a complex vector space.
Next one shows that the formula
⟨[a]f , [b]f ⟩= f (a∗b),
[a]f , [b]f ∈H0
f
(30.23)
deﬁnes a scalar product on the vector space H0
f . Finally, deﬁne Hf as the completion
of H0
f with respect to the norm deﬁned by this scalar product and extend the scalar

464
30
Operator Algebras and Positive Mappings
product (30.23) by continuity to Hf . Thus, Hf is a complex Hilbert space.
Construction of Ωf and πf : ﬁrst deﬁne
Ωf = [I]f .
(30.24)
Clearly, Ωf ∈Hf satisﬁes ⟨Ωf , Ωf ⟩= f (I ∗I) = f (I) = 1. Hence this is a unit
vector.
Next deﬁne
π0
f (a)[b]f = [ab]f ,
∀a, b ∈A.
(30.25)
Because of property (30.20), π0
f is well deﬁned. And it follows easily that π0
f (a) is
a linear operator on H0
f for all a ∈A. In order to prove boundedness of the linear
operator π0
f (a) we estimate as follows. For all b ∈A one has, using (30.17),
--π0
f (a)[b]f
--2
f = ⟨[ab]f , [ab]f ⟩= f ((ab)∗ab) = f (b∗a∗ab)
≤f (b∗∥a∥2 Ib) = ∥a∥2 f (b∗b) = ∥a∥2 ⟨[b]f , [b]f ⟩f ,
hence π0
f (A) is bounded and
---π0
f (a)
--- ≤∥a∥.
Thus, by continuity and density of H0
f , π0
f extends uniquely to a mapping πf :
A −→B(Hf ). It is straightforward to see that this mapping is linear. This proves
property 1.
Since the product in A is associative, property 2 of πf follows easily from its
deﬁnition:
πf (ab)[c]f = [(ab)c]f = [a(bc)]f = πf (a)[bc]f =
πf (a)(πf (b)[c]f ) = (πf (a)πf (b))[c]f ,
∀a, b, c ∈A.
In order to establish property 3. we calculate as follows, for arbitrary a, b, c ∈A:
⟨πf (a)∗[b]f , [c]f ⟩= ⟨[b]f , πf (a)[c]f ⟩= ⟨[b]f , [ac]f ⟩= f (b∗ac)
= f ((a∗b)∗c) = ⟨[a∗b]f , [c]f ⟩= ⟨πf (a∗)[b]f , [c]f ⟩,
hence πf (a∗) = πf (a)∗for all a ∈A.
Finally, note that our construction gives for all a ∈A
⟨Ωf , πf (a)Ωf ⟩= ⟨[I]f , πf (a)[I]f ⟩= f (I ∗aI) = f (a),
therefore the representation formula (30.19) holds.

30.3
Normal States
465
Uniqueness up to unitary equivalence: suppose that we also have f represented as
f (a) = ⟨Ω, π(a)Ω⟩. Deﬁne a linear mapping U : Hf −→H by
U 0[a]f = π(A)Ω,
∀a ∈A.
It follows that U 0 is linear and satisﬁes, for all a, b ∈A
⟨U 0[a]f , U 0[b]f ⟩= ⟨π(a)Ω, π(b)Ω⟩= ⟨Ω, π(a∗b)Ω⟩= f (a∗b) = ⟨[a]f , [b]f ⟩.
We conclude that U 0 is an isometry deﬁned on the dense subspace H0
f with
dense range π(A)Ω, hence it extends continuously to a unique unitary operator
U : Hf −→H. Next calculate
π(a)π(b)Ω = π(ab)Ω = U[ab]f = Uπf (a)[b]f =
= Uπf (a)U ∗U[b]f = Uπf (a)U ∗π(b)Ω
for all a, b ∈A. Since π(A)Ω is dense in H we conclude π(a) = Uπf (a)U ∗for
all a ∈A.
2
30.3
Normal States
In the last section we considered positive linear functionals f on a C∗-algebra A with
unit I satisfying f (I) = 1. Such functionals are called states of A. Here under an
addtional continuity assumption we determine the general form of states in the case
where A is a weakly closed subalgebra of B(H) (see Sect. 26.3), i.e., if A is a von
Neumann algebra. Such an algebras has the remarkable property of being equal to
its bi-commutant (see [3]), i.e., A = A′′ ≡(A′)′ where the commutant A′ is deﬁned
by
A′ = {B ∈B(H) : BA = AB for all A ∈A} .
By Proposition 30.1 states are continuous for the (operator) norm when A is a C∗-
algebra. Note that states generate the cone of positive linear functionals.
Simple examples of states are vector states μx, x ∈H, ∥x∥= 1, deﬁned by
μx(A) = ⟨x, Ax⟩
A ∈A.
(30.26)
Another class of examples is obtained as follows. In Formula 26.18 choose gn = en
with {en} ∈ℓ2(H) and 
n ∥en∥2 = 1. Then the operator ˆT = 
n [en, en] is a
positive trace class operator with Tr( ˆT ) = 
n ∥en∥2 = 1 and the formula
T (A) = Tr( ˆT A) =

n
⟨en, Aen⟩
(30.27)
deﬁnes a state on B(H).

466
30
Operator Algebras and Positive Mappings
It turns out that under the conditions we are considering every state on A will be
of this form. This result is used quite often in quantum physics and naturally in the
theory of operator algebras.
Deﬁnition 30.5 A positive linear functional μ on a von Neumann algebra A ⊆
B(H) is called
1. normal if for every bounded increasing net {Ai : i ∈I}
⊂
Ah
=
{A ∈A : A∗= A}1 one has
μ( sup
I
Ai) = sup
I
μ(Ai).
(30.28)
2. completely additive if for every orthogonal family of projections pi in A one
has
μ(

i∈I
pi) =

i∈I
μ(pi).
(30.29)
Note that a family of projections is called orthogonal if any two different projections
are orthogonal, i.e., pipj = 0 for i ̸= j. In this context it is important to be aware
of the following simple result.
Proposition 30.2 (Theorem of Vigier) If {Ai : i ∈I} ⊂B(H) is a bounded increas-
ing net of self-adjoint operators then there is a self-adjoint operator A = supI Ai
such that
A = lim
I Ai
in the strong topology on B(H).
Proof
Every x ∈H deﬁnes an increasing net ⟨x, Aix⟩in R which is bounded by
C ∥x∥2 if C denotes the bound for the given net (∥Ai∥≤C for all i ∈I), hence
the net converges. The polarization identity (Proposition 14.1.2) implies that the net
⟨y, Aix⟩converges for any ﬁxed x, y ∈H; denote the limit by B(y, x). It follows
that B(y, x) is a symmetric sesquilinear form on H bounded by C ∥y∥∥x∥. Such
forms deﬁne a unique self-adjoint operator A ∈B(H) by B(y, x) = ⟨y, Ax⟩for all
x, y ∈H. By construction ⟨y, Ax⟩= limI⟨y, Aix⟩, hence A = limI Ai for the weak
topology on B(H). Furthermore, for every x ∈H,
⟨x, Ax⟩= lim
I ⟨x, Aix⟩= sup
I
⟨x, Aix⟩,
hence A = supI Ai.
Since the net is bounded it follows that A = limI Ai for the strong topology on
B(H): for every x ∈H we can estimate Ax −Aix, using A −Ai ≥0,
∥(A −Ai)x∥2 =
--(A −Ai)1/2(A −Ai)1/2x
--2 ≤
--(A −Ai)1/2--2 --(A −Ai)1/2x
--2
1 a net in Ah is a function on some directed set I with values Ai ∈Ah, i ∈I, see [4].

30.3
Normal States
467
= ∥A −Ai∥⟨x, (A −Ai)x⟩≤2C⟨x, (A −Ai)x⟩;
thus weak convergence of the net implies strong convergence.
2
Note that in our context this result implies that supI Ai ∈A so that (30.28) is
meaningful. The main result of this section is
Theorem 30.5 (Characterization of Normal States) For a state μ on a von Neumann
algebra A ⊆B(H) the following statements are equivalent:
(a) μ is normal;
(b) μ is completely additive;
(c) μ is of the form
μ(A) = Tr(AW),
A ∈A
(30.30)
with a positive trace class operator W with Tr(W) = 1.
Proof For the proof we proceed in the order of the implications (a) ⇒(b) ⇒(c) ⇒
(a).
(a) ⇒(b): Let {pi : i ∈I} be any orthogonal family of projections in A. For
ﬁnite parts J of the index set I introduce the projection pJ = 
i∈J pi. Then
{pJ : J ⊂I, J ﬁnite} is a monotone increasing net which is bounded by id. Thus
by Proposition 30.2
lim
J pJ =

i∈I
pi.
Since μ is assumed to be normal it follows
μ(

i∈I
pi) = lim
J μ(pJ) = lim
J

i∈J
μ(pi) =

i∈I
μ(pi),
hence μ is completely additive.
(b) ⇒(c): This is the core of the proof. The main technical part of the argument
is formulated in the following Proposition 30.3. This proposition states that a com-
pletely additive state μ on A is strongly continuous when restricted to the unit ball
A1 of A. Then the second part of Theorem 26.6 implies that μ is of the form
μ(A) =

n
⟨gn, Aen⟩,
A ∈A
with {gn} , {en} ∈ℓ2(H) where we used (26.18). As in the introductory example the
form (30.30) of μ follows.
(c) ⇒(a): Again according to the second part of Theorem 26.6 μ is σ-weakly
continuous if (c) is assumed. On bounded sets the weak and σ-weak topology agree
according to Lemma 26.2. Thus by Proposition 30.2 we conclude.
2

468
30
Operator Algebras and Positive Mappings
Proposition 30.3
Every completely additive state μ on a von Neumann algebra
A ⊆B(H) is strongly continous when restricted to the unit ball A1 of A.
Proof For the proof we have to ﬁnd suitable seminorms for the strong topology by
which we can estimate the given state. This could be achieved by ﬁnding suitable
vector states which dominate μ. This idea can be realized ﬁrst on certain parts of A
and then on all of A.
Claim 1: There are a nonzero projection p ∈A and a vector x ∈H such that
μ ≤μx
on
pAp.
For the proof of this claim choose x ∈H, ∥x∥= 1. Then we have μx(I) = ⟨x, Ix⟩=
1 = μ(I). Introduce P0 = {p ∈A : p = projection, μx(p) < μ(p)}. If P0 is empty,
then μ(p) ≤μx(p) for all projections p in A and we are done.
If P0 is not empty consider the collection P of all subsets
P = {pi ∈P0 : pi mutually orthogonal} ⊂P0.
By set inclusion P is a partially ordered set in which every chain has an upper bound
(the union of the elements of this chain). Hence by Zorn’s lemma,2 P has a maximal
element P . Then p = 
pi∈P pi ≤I and thus, since μ is completely additive,
μx(p) =

pi∈P
μx(pi) <

pi∈P
μ(pi) = μ(

pi∈P
pi) = μ(p) ≤μ(I) = μx(I),
hence p < I and therefore q = I −p ̸= 0. Since every projection q′ ∈qAq is
orthogonal to each pi ∈P, by maximality of P we know q′ /∈P0, and thus for all
projections q′ ∈qAq it follows μ(q′) ≤μx(q′).
According to the spectral theorem (Theorem 27.3),3 every positive A ∈qAq
is the norm limit of linear combinations n
j=1 λjqj of projections qj ∈qAq with
positive coefﬁcients λj. The above estimate implies
μ(
n

j=1
λjqj) =
n

j=1
λjμ(qj) ≤
n

j=1
λjμx(qj) = μx(
n

j=1
λjqj).
Since μ and μx are continuous with respect to the norm topology we get in the limit
μ(A) ≤μx(A),
A ∈qAq, A ≥0
and Claim 1 follows.
2 This lemma says: Every partially ordered set P in which every linearly ordered subset has an
upper bound contains at least one maximal element.
3 Our version of the spectral theorem proves this claim only for the case A = B(H). For the general
case of A ⊂B(H), we have to refer to Theorem 5.2.2 of [5].

30.3
Normal States
469
Claim 2: There is a family {pi} of mutually orthogonal projections in A and of
points xi ∈H such that
μ ≤μxi
on
piApi
and

i
pi = I.
(30.31)
The proof of this claim relies again on Zorn’s lemma. According to the ﬁrst claim,
we know that the set
S0 = {(p, x) : p projection in A, x ∈H, μ ≤μx on pAp}
is not empty. Then consider the collection S of subsets
S = {(pi, xi) ∈S0 : {pi} mutually orthogonal} .
S is partially ordered by set inclusion and then every chain in S has an upper bound.
Zorn’s lemma implies that S has a maximal element Sm. Deﬁne p as the sum of
all projections pi for which (pi, xi) ∈Sm: p = 
i pi. If p < I then q = I −p
is a nontrivial projection. Apply the statement of the ﬁrst claim to qAq ⊆B(qH).
Hence, there is y ∈qH and a projection p0 ∈qAq such that μ ≤μy on p0qAqp0.
By construction p0 is mutually orthogonal to all projections pi with (pi, xi) ∈Sm.
This contradicts the maximality of Sm and therefore we get p = 
i pi = I and
(30.31) follows.
Claim 3: Given ε > 0 there is a neighborhood of zero U for the strong topology
such that |μ(A)| ≤ε for all A ∈U ∩A1.
The proof of this claim follows now easily from (30.31): Since μ is a completely
additive state we know
1 = μ(I) = μ(

i
pi) =

i
μ(pi);
thus, the index set of our maximal family Sm is countable and there is a ﬁnite subset
J of the index set of our maximal family Sm such that 
i∈J μ(pi) ≤1 −ε2
4 . For
q = I −
i∈J pi this gives μ(q) ≤ε2
4 . Deﬁne U =

A ∈A : 
i∈J ∥Apixi∥≤ε/2

and observe μ(A) = μ(Aq) + μ(A 
i∈J pi). For all A ∈A with ∥A∥≤1 we
estimate as follows:
|μ(Aq)| ≤μ(A∗A)1/2μ(q∗q)1/2 ≤μ(q)1/2 ≤ε/2
and similarly
|μ(A

i∈J
pi)| ≤

i∈J
|μ(Api)| ≤
n

i∈J
μ(I∗I)1/2μ((Api)∗Api)1/2 =

i∈J
μ(piA∗Api)1/2
≤

i∈J
μxi(piA∗Api)1/2 =

i∈J
∥Apixi∥.
Putting these estimates together gives our Claim 3 for the neighborhood U
introduced above.
2

470
30
Operator Algebras and Positive Mappings
30.4
Completely Positive Maps
In Sect. 30.2.1, the general form of positive linear maps
f : A −→C = M1(C)
has been determined for C∗-algebras.A natural extension of this problem is to look for
the general form of positive linear maps with values in the space Mk(C) of complex
k × k matrices
F : A −→Mk(C),
k > 1,
or even more general for mappings with values in a C∗-algebra of operators on a
Hilbert space H,
F : A −→B,
B ⊂B(H)
(30.32)
extending the representation formula (30.19). This problem was investigated and
solved by Stinespring in 1955 for the general case of C∗-algebras [6]. It was found
that one can arrive at a representation formula similar to (30.19) if one imposes on
F a stronger positivity requirement, namely that of complete positivity.
30.4.1
Positive Elements in Mk(A)
Let A be a C∗-algebra. For k = 1, 2, . . . introduce the space Mk(A) of k ×k matrices
[aij] with entries aij ∈A, i, j = 1, . . . , k. In a natural way this space is a C∗-algebra
(with unit if A has a unit) (see [3]).
According to our earlier discussion we call an element
a = [aij] =
⎛
⎜⎜⎜⎝
a11
· · ·
a1k
...
...
...
ak1
· · ·
akk
⎞
⎟⎟⎟⎠,
aij ∈A
positive, a ≥0 if, and only if, a = c∗c for some c ∈Mk(A).
If A is a C∗-algebra of operators on a Hilbert space H then a = [aij] ∈Mk(A)
acts naturally on
Hk =
 
ξ = (ξ1, . . . , ξk) : ξj ∈H, j = 1, . . . , k
!
(30.33)
according to the rule
([aij]ξ)i =
k

j=1
aijξj,
ξ ∈Hk .
(30.34)

30.4
Completely Positive Maps
471
The space (30.33) is a Hilbert space with the scalar product
⟨ξ, η⟩Hk =
k

j=1
⟨ξj, ηj⟩H,
∀ξ, η ∈Hk .
(30.35)
Positive elements in Mk(A) are characterized by the following lemma (see [3]):
Lemma 30.1 The following conditions are equivalent for an element a = [aij] ∈
Mk(A):
(1) a = b∗b for some b ∈Mk(A);
(2) ⟨ξ, aξ⟩Hk ≥0 for all ξ ∈Hk;
(3) a = [aij] is a sum of matrices of the form [a∗
i aj], a1, . . . , ak ∈Mk(A);
(4) For all x1, . . . , xk ∈A one has
k

i,j=1
x∗
i aijxj ≥0
in A.
Proof
(1) ⇒(3): If a = b∗b for some b ∈Mk(A), then aij = (b∗b)ij =
k
m=1 b∗
mibmj; cm = [b∗
mibmj] ∈Mk(A) is of the claimed form and a = k
m=1 cm.
Thus (3) holds.
(3) ⇒(4): If we know a = [a∗
i aj] for some aj ∈A and if any elements
x1, . . . , xk ∈A are given, then
k

i,j=1
x∗
i aijxj =
k

i,j=1
x∗
i a∗
i ajxj =
$ k

i=1
aixi
%∗$ k

i=1
ajxj
%
,
now b = k
i=1 aixi ∈A and
k

i,j=1
x∗
i aijxj = b∗b,
hence this sum is positive.
(4) ⇒(2): If (4) holds, then by condition (30.14), for all x ∈H and all xi ∈A,
⟨x,
⎛
⎝
k

i,j=1
x∗
i aijxj
⎞
⎠x⟩H ≥0 .
It follows
⟨ξ, aξ⟩Hk ≥0,
for all ξ ∈Hk which are of the form
ξ = (x1x, . . . , xkx),
x ∈H xj ∈A .
But this set equals Hk, hence (2) holds.

472
30
Operator Algebras and Positive Mappings
(2) ⇒(1): If (2) holds, the square root lemma (Theorem 21.5.1) implies that a
has a positive square root b = √a ∈Mk(A) such that a = b2 = b∗b and (1) follows.
Note that (1) ⇒(2) is trivial and also (3) ⇒(1) is simple. If a is of the form
[a∗
i aj], then
a =
⎛
⎜⎜⎜⎝
a∗
1a1
· · ·
a∗
1ak
...
...
...
a∗
ka1
· · ·
a∗
kak
⎞
⎟⎟⎟⎠=
⎛
⎜⎜⎜⎝
a∗
1
0
· · ·
0
...
...
...
...
a∗
k
0
· · ·
0
⎞
⎟⎟⎟⎠·
⎛
⎜⎜⎜⎜⎜⎝
a1
· · ·
ak
0
· · ·
0
...
...
...
0
· · ·
0
⎞
⎟⎟⎟⎟⎟⎠
= b∗b,
hence (1).
2
Elements in Mk(A) which satisfy any of the 4 equivalent conditions of Lemma
30.1 are called positive.
Lemma 30.2 Let A be a C∗-algebra of operators in a Hilbert space H. Then, given
any a1, . . . , ak ∈A one has for all a ∈A
[(aai)∗(aaj)] ≤∥a∥2 [a∗
i aj]
in Mk(A).
(30.36)
Proof The matrix of operators [(aai)∗(aaj)] acts on the Hilbert space Hk according
to (30.34) and for all x = (x1, . . . , xk) ∈Hk we have
⟨x, [(aai)∗(aaj)]x⟩Hk =
------

j
aajxj
------
2
H
≤∥a∥2
------

j
ajxj
------
2
H
= ∥a∥2 ⟨x, [a∗
i aj]x⟩Hk,
thus (30.36) follows.
2
30.4.2
Some Basic Properties of Positive Linear Mappings
In the proof of the Stinespring factorization theorem for completely positive maps,
we need some basic properties of positive linear maps. These are brieﬂy discussed
here.
Let A and B be ∗-algebras. Recall: Elements a in A are called positive (more
accurately, nonnegative), in symbols a ≥0, if there is b ∈A such that a = b∗b.
A corresponding characterization of positive elements applies to B. Furthermore, a
linear mapping T : A −→B is called positive if, and only if, for all a ∈A with
a ≥0 one has T (a) ≥0 (in B).
Knowing what positive elements are, we can deﬁne an order on A and B: For
a1, a2 ∈A one says that a1 is smaller or equal to a2, in symbols a1 ≤a2, if, and only
if, a2 −a1 ≥0.

30.4
Completely Positive Maps
473
For any positive linear mapping T : A −→B, the following holds:
a1, a2 ∈A, a1 ≤a2 ⇒T (a1) ≤T (a2) .
(30.37)
Positive linear maps T : A −→B satisfy the following important estimates:
Lemma 30.3 Suppose that A is a C*-algebra with unit I. Then any positive linear
map T : A −→B satisﬁes
T (x∗a∗ax) ≤∥a∥2 T (x∗x)
∀a, x ∈A .
(30.38)
In particular
T (a∗a) ≤∥a∥2 T (I)
∀a ∈A
and thus T (I) = 0 implies T = 0.
Proof From (30.17) we know for all a ∈A
a∗a ≤∥a∥2 I ,
(30.39)
hence for all x ∈A,
x∗a∗ax ≤∥a∥2 x∗x ,
and thus for any positive linear mapping T : A −→B estimate (30.38) follows.
If we choose x = I we get the estimate for T (a∗a). This estimate implies that T
vanishes on all positive elements of A if T (I) = 0. Now observe that every a ∈A
can be written as
a = 1
2(a + a∗) + i
1
2 i (a −a∗),
where the elements ar = 1
2(a+a∗) and ai =
1
2 i (a−a∗) are self-adjoint (Hermitian),
i.e., a∗
r,i = ar,i. From spectral theory it follows that every self-adjoint b ∈A can be
written as the difference of two positive elements in A, b = b+ −b−with b± ≥0.
By linearity of T we conclude that T vanishes on all of A.
2
30.4.3
Completely Positive Maps Between C∗-Algebras
Suppose that a linear map F : A −→B between two C∗-algebras A, B is given. For
k = 1, 2, . . . it induces a map
Fk : Mk(A) −→Mk(B),
Fk([aij]) = [F(aij)],
(30.40)
for all aij ∈A, i, j = 1, 2, . . . , k.
Deﬁnition 30.6 A linear map F : A −→B as above is called k-positive if, and
only if, Fk is positive, i.e., if Fk maps positive elements of Mk(A) to positive elements
of Mk(B), If F is k-positive for all k ∈N then F is called completely positive.

474
30
Operator Algebras and Positive Mappings
Remark 30.1 In physics literature, the map Fk is usually written as
Fk = Ik ⊗F : Mk(C) ⊗A −→Mk(C) ⊗B .
(30.41)
Naturally, our characterization of positive elements in Mk(A) of the previous
subsection implies a characterization of k-positive and completely positive maps.
Corollary 30.1 Let F : A −→B be as above. Then F is k-positive if, and only if,
∀xi∈A ∀yj ∈B
k

i,j=1
y∗
i F(x∗
i xj)yj ≥0
in B .
(30.42)
Proof By condition (3) of Lemma 30.1 every positive element [aij] in Mk(A) is a
sum elements of the form [x∗
i xj], x1, . . . , xk ∈A; hence F is k-positive if, and only
if, [F(x∗
i xj)] is positive in Mk(B). According to Condition (4) of Lemma 30.1, this
is the case if, and only if condition (30.42) holds. Thus we conclude.
2
Corollary 30.2
Let F : A −→B be as above with B = M1(C) = C. If F is
positive, then F is completely positive.
Proof
If F : A −→C is positive, then F(b∗b) ≥0 for all b ∈A. Using the
characterization (30.42) we show that F is k-positive for all k. For yj ∈C the sum
in (30.42) can be written as
k

i,j=1
y∗
i F(x∗
i xj)yj = F
$$ k

i=1
yixi
%∗$ k

i=1
yixi
%%
= F(b∗b).
Thus, by Corollary 30.1, F is k-positive and we conclude.
2
A ﬁrst example of a completely positive map: Any homomorphism F : A −→B of
C∗-algebras is completely positive.
The proof is simple. Using Corollary 30.1 we show that a homomorphism of ∗-
algebras is k-positive for every k ∈N. For all xi ∈A and all yj ∈B one has, using
the properties of a homomorphism of ∗-algebras and Lemma 30.1,
k

i,j=1
y∗
i F(x∗
i xj)yj =
k

i,j=1
y∗
i F(xi)∗F(xj)yj =
$ k

i=1
F(xi)yi
%∗⎛
⎝
k

j=1
F(xj)yj
⎞
⎠
which is certainly ≥0 in B. Hence F is k-positive for every k and therefore
completely positive.
Our next example is just a slight extension of the ﬁrst. Let π : A −→B a
∗-homomorphism of A and V some element in B; deﬁne F : A −→B by
F(a) = V ∗π(a)V ,
∀a ∈A .
(30.43)

30.4
Completely Positive Maps
475
A similar calculation as above shows that F is a completely positive map. For all
xi ∈A and all yj ∈B one has, using the properties of a homomorphism of ∗-algebras
and Lemma 30.1,
k

i,j=1
y∗
i F(x∗
i xj)yj =
k

i,j=1
y∗
i V ∗π(xi)∗π(xj)Vyj =
$ k

i=1
π(xi)Vyi
%∗⎛
⎝
k

j=1
π(xj)Vyj
⎞
⎠≥0 in B .
Note that if V is not unitary then the map F of (30.43) is not a representation of A.
30.4.4
Stinespring Factorization Theorem for Completely Positive
Maps
The Stinespring factorization theorem shows that essentially all completely positive
maps are of the form (30.43). The proof is a straightforward extension of the proof
for the GNS-construction.
We state and prove this result explicitly for the case where A and B are C∗-algebras
of operators on a Hilbert space. The general case is given in [3].
Theorem 30.6 (Stinespring Factorization Theorem) Let A be a C∗-algebra with
unit I and B ⊂B(H) be a C∗-algebra of operators in a Hilbert space H. Then
for every completely positive map f : A −→B there exist a Hilbert space Kf , a
representation πf of A in Kf , and a bounded linear operator V : H −→Kf such
that
f (a) = V ∗πf (a)V
∀a ∈A .
(30.44)
Furthermore, for all ξ ∈H, ∥V ξ∥f =
--f (I)1/2ξ
--
H.
Proof
Construction of Kf : On the algebraic tensor product A ⊗H deﬁne, for
elements ζ = k
i=1 ai ⊗ξi, χ = l
j=1 bj ⊗ηj in A ⊗H,
⟨ζ, χ⟩f =
k

i=1
l
j=1
⟨ξi, f (a∗
i bj)ηj⟩H .
(30.45)
One veriﬁes that this formula deﬁnes a sesquilinear form on A ⊗H. In particular, in
the notation of Sect. 4.1,
⟨ζ, ζ⟩f =
k

i=1,j
⟨ξi, f (a∗
i aj)ξj⟩H = ⟨ξ, [f (a∗
i aj)]ξ⟩Hk = ⟨ξ, fk([a∗
i aj])ξ⟩Hk.
According to Lemma 30.1 the element a = [a∗
i aj] ∈Mk(A) is positive and, since
f is completely positive, fk is a positive mapping from Mk(A) into Mk(B), hence

476
30
Operator Algebras and Positive Mappings
fk([a∗
i aj]) is a positive matrix on Hk and we conclude ⟨ζ, ζ⟩f ≥0. Therefore the
sesquilinear form (30.45) is positive semideﬁnite and hence it satisﬁes the Cauchy–
Schwarz inequality
|⟨ζ, χ⟩f |2 ≤⟨ζ, ζ⟩f ⟨χ, χ⟩f .
We conclude that the kernel
If =

ζ =
k

i=1
ai ⊗ξi ∈A ⊗H : ⟨ζ, ζ⟩f = 0

of this sesquilinear form is a linear subspace of A ⊗H. On the quotient space
K0
f = A ⊗H/If =

[ζ]f = ζ + If : ζ ∈A ⊗H

the formula
⟨[ζ]f , [χ]f ⟩= ⟨ζ, χ⟩f
then deﬁnes an inner product and thus the completion Kf of K0
f with respect to the
norm deﬁned by this inner product is a Hilbert space.
Construction of πf : For [ζ]f ∈K0
f , ζ = k
i=1 ai ⊗ξi ∈A ⊗H deﬁne
π0
f (a)[ζ]f = [
k

i=1
aai ⊗ξi]f
∀a ∈A.
(30.46)
At ﬁrst we calculate
⟨π0
f (a)[ζ]f , π0
f (a)[ζ]f ⟩= ⟨[
k

i=1
aai ⊗ξi]f , [
k

j=1
aaj ⊗ξj]f ⟩= ⟨
k

i=1
aai ⊗ξi,
k

j=1
aaj ⊗ξj⟩f =
k

i,j=1
⟨ξi, f ((aai)∗(aaj))ξj⟩H = ⟨ξ, fk([(aai)∗(aaj)])ξ⟩Hk
where ξ = (ξ1, . . . , ξk) ∈Hk. Lemma 30.2 says
[a∗
i a∗aaj] ≤∥a∥2 [a∗
i aj].
Since f is completely positive, the map fk is positive and therefore
fk([a∗
i a∗aaj]) ≤∥a∥2 fk([a∗
i aj]).
We conclude
⟨ξ, fk([(aai)∗(aaj)])ξ⟩Hk ≤∥a∥2 ⟨ξ, fk([a∗
i aj])ξ⟩Hk
and hence
⟨π0
f (a)[ζ]f , π0
f (a)[ζ]f ⟩f ≤∥a∥2 ⟨[ζ]f , [ζ]f ⟩f .
(30.47)

30.4
Completely Positive Maps
477
This estimate shows ﬁrst that π0
f (a) is well deﬁned (i.e., π0
f (a) is indeed a map
between equivalence classes and does not depend on the representatives of the
equivalence classes which are used in its deﬁnition).
Now, using (30.46), it is a straightforward calculation to show that π0
f : K0
f −→
K0
f is linear. Then (30.47) implies that this map is bounded and
---π0
f (a)
--- ≤∥a∥.
From the deﬁnition (30.46) it is immediate that π0
f satisﬁes
π0
f (ab) = π0
f (a)π0
f (b)
∀a, b ∈A .
In order to show
π0
f (a∗) = π0
f (a)∗
∀a ∈A
we calculate as follows: for ζ, χ as in (30.45) and a ∈A, using (30.46),
⟨π0
f (a)∗[ζ]f , [χ]f ⟩= ⟨[ζ]f , π0
f (a)[χ]f ⟩=
k

i=1
l
j=1
⟨ξi, f (a∗
i abj)ηj⟩H =
k

i=1
l
j=1
⟨ξi, f ((a∗ai)∗bj)ηj⟩H = ⟨[
k

i=1
(a∗ai) ⊗ξi]f , [
l
j=1
bj ⊗ηj]f ⟩
= ⟨π0
f (a∗)[ζ]f , [χ]f ⟩.
Since this identity is true for all [ζ]f , [χ]f ∈K0
f we conclude.
This establishes that π0
f is a representation of A on K0
f .
By continuity π0
f has a unique extension to a representation πf on the completion
Kf of K0
f .
Construction of V : Deﬁne V 0 : H −→K0
f by
V 0ξ = [I ⊗ξ]f
∀ξ ∈H .
(30.48)
An easy calculation shows that V 0 is linear. Now calculate
⟨V 0ξ, V 0ξ⟩= ⟨I ⊗ξ, I ⊗ξ⟩f = ⟨ξ, f (I ∗I)ξ⟩H ≤∥f (I)∥⟨ξ, ξ⟩H
∀ξ ∈H .
This shows that V 0 is bounded. Since f (I ∗I) = f (I) is positive we know f (I) =
(√f (I))2 and thus
--V 0ξ
-- ≤
---

f (I)ξ
---
H
ξ ∈H.
(30.49)
In the case of f (I) = I, V 0 is thus an isometry.
Now for a ∈A and ξ ∈H the identity
π0
f (a)V 0ξ = [a ⊗ξ]f
follows. We deduce
π0
f (A)V 0H = K0
f .
(30.50)

478
30
Operator Algebras and Positive Mappings
V 0 is extended by continuity to a bounded linear operator V : H −→Kf and
then the last condition reads
[πf (A)V H] = Kf ,
(30.51)
where [· · ·] denotes the closure of the linear hull of · · · in Kf .
Now all preparations for the proof of the Stinespring factorization formula have
been done. For η, ξ ∈H one ﬁnds for all a ∈A,
⟨V 0η, π0
f (a)V 0ξ⟩= ⟨[I ⊗η]f , [a ⊗ξ]f ⟩= ⟨I ⊗η, a ⊗ξ⟩f = ⟨η, f (I ∗a)ξ⟩H
and therefore f (a) = (V 0)∗π0
f (a)V 0 for all a ∈A. By continuous extension the
Stinespring factorization formula (30.44) follows.
2
Corollary 30.3 (Uniqueness Under Minimality Condition) Let f : A −→B be
a completely positive map as in Theorem 30.6 and let
f (a) = U ∗π(a)U,
a ∈A
(30.52)
be a Stinespring factorization of f with a representation π of A in a Hilbert space
K and a bounded linear operator U : H −→K. If this factorization satisﬁes the
minimality condition
[π(A)UH] = K
(30.53)
then, up to a unitary transformation, it is the factorization constructed in Theorem
30.6.
Proof We begin by deﬁning a linear operator W0 : πf (A)V H −→π(A)UH by the
formula
W0
$ k

i=1
πf (xi)V ξi
%
=
k

i=1
π(xi)Uξi
xi ∈A, ξi ∈H .
(30.54)
Now calculate the inner product of these images in K:
⟨W0
k

i=1
πf (xi)V ξi, W0
l
j=1
πf (yi)V ηj⟩K = ⟨
k

i=1
π(xi)Uξi,
l
j=1
π(yj)Uηj⟩K =
k

i=1
l
j=1
⟨Uξi, π(xi)∗π(yj)Uηj⟩K =
k

i=1
l
j=1
⟨ξi, U ∗π(x∗
i yj)Uηj⟩H =
k

i=1
l
j=1
⟨ξi, f (x∗
i yj)ηj⟩H =
k

i=1
l
j=1
⟨ξi, V ∗πf (xi)∗πf (yj)V ηj⟩H
= ⟨
k

i=1
πf (xi)V ξi,
l
j=1
πf (yi)V ηj⟩.

30.4
Completely Positive Maps
479
We conclude that W0 : πf (A)V H −→π(A)UH is isometric and thus extends by
continuity to a unitary operator
W : [πf (A)V H] −→[π(A)UH],
i.e., because of the minimality condition to a unitary operator W : Kf −→K. From
the above deﬁnition the relations
Wπf ( · )W ∗= π( · ),
WV = U
follow immediately.
2
Corollary 30.4 Let f : A −→B be a completely positive map as above. Then the
inequality
f (a)∗f (a) ≤∥f (I)∥f (a∗a)
(30.55)
holds for all a ∈A.
Proof
By Theorem 30.6 f has a Stinespring factorization f (a) = V ∗π(a)V and
thus
f (a)∗f (a) = (V ∗π(a)V )∗V ∗π(a)V = V ∗π(a)∗V V ∗π(a)V
≤∥V ∥2 V ∗π(a)∗π(a)V = ∥V ∥2 f (a∗a) .
The estimate ∥V ξ∥f ≤
--f (I)1/2ξ
--
H for ξ ∈H implies ∥V ∥≤
--f (I)1/2-- or
∥V ∥2 ≤
--f (I)1/2--2 = ∥f (I)∥.
2
30.4.5
Completely Positive Mappings on B(H)
Theorem 30.2 determines the structure of representations of the C∗-algebra B(H). If
we combine this result with Stinespring’s factorization theorem we arrive at a more
concrete form of completely positive mappings on B(H).
Suppose that operators a1, . . . , am ∈B(H) are given. Deﬁne fm : B(H) −→
B(H) by
fm(a) =
m

j=1
a∗
j aaj.
Using Corollary 30.1, one shows easily that this mapping is completely positive.
Next, suppose that we are given a sequence

aj

⊂B(H) of operators for which
there is a positive operator B such that for all m ∈N
Sm =
m

j=1
a∗
j aj ≤B.
(30.56)

480
30
Operator Algebras and Positive Mappings
Thus, we get a sequence of completely positive mappings fm on B(H) which
converges.
Lemma 30.4 (Completely Positive Maps on B(H)) For a sequence of operators
aj ∈B(H) which satisﬁes (30.56) the series
f (a) =
∞

j=1
a∗
j aaj,
a ∈B(H) ﬁxed
(30.57)
converges in the ultraweak operator topology on B(H) and deﬁnes a completely
positive mapping which satisﬁes
f (I) ≤B.
(30.58)
Proof Recall that every a ∈B(H) has a representation as a complex linear combina-
tion of four positive elements. Thus, it sufﬁces to show this convergence for positive
a ∈B(H). In this case we know that 0 ≤a ≤∥a∥I and it follows for arbitrary
x ∈H and m ∈N
m

j=1
--a1/2ajx
--2 =
m

j=1
⟨x, a∗
j aajx⟩≤
m

j=1
∥a∥⟨x, a∗
j ajx⟩≤∥a∥⟨x, Bx⟩,
hence this monotone increasing sequence is bounded from above and thus it
converges:
∞

j=1
⟨x, a∗
j aajx⟩≤∥a∥⟨x, Bx⟩.
The polarization identity (14.5) implies that for arbitrary x, y ∈H the numerical
series
∞

j=1
⟨x, a∗
j aajy⟩
converges. This shows that the series (30.57) converges in the weak operator topology
and thus deﬁnes f (a) ∈B(H). Since the partial sums of the series considered are
bounded, we also have ultraweak convergence by Lemma 26.2 (on bounded sets both
topologies coincide).
Finally, we show that f is completely positive by showing that it is k-
positive for every k
∈
N. According to Corollary 30.1, choose arbitrary
A1, . . . , Ak, B1, . . . , Bk ∈B(H). For every x ∈H we ﬁnd
⟨x,
k

i,j=1
b∗
i f (A∗
i aj)Bjx⟩= lim
m→∞⟨x,
k

i,j=1
b∗
i fm(A∗
i aj)Bjx⟩≥0
since fm is k-positive. We conclude that k
i,j=1 b∗
i f (A∗
i aj)Bj ≥0 in B(H) and
hence f is k-positive.
2

30.4
Completely Positive Maps
481
Combining Stinespring’s factorization theorem with Theorem 30.2 shows that
essentially all completely positive mappings on B(H) are of the form (30.57).
Theorem 30.7 Every completely positive mapping f : B(H) −→B(H) is of the
form
f (a) = V ∗
0 π0(a)V0 +

j∈J
a∗
j aaj,
a ∈B(H)
(30.59)
with the following speciﬁcations:
π0 is a representation of the quotient algebraB(H)/Bc(H) on a Hilbert space H0
(hence π0(b) = 0 for all b ∈Bc(H)), V0 is a bounded linear operator H −→H0, J
is a ﬁnite or countable index set, and aj ∈B(H) satisfy

j∈J
a∗
j aj ≤f (I).
(30.60)
Proof Theorem 30.6 implies that a given completely positive mapping on B(H) is
of the form (30.44) with a representation π of B(H) on a Hilbert space K and a
bounded linear operator V : H −→K, i.e.,
f (a) = V ∗π(a)V ,
a ∈B(H).
The general form of representations of B(H) has been determined in Theorem
30.2. According to this result π has the direct sum decomposition (J some ﬁnite
or countable index set)
π = π0 ⊕
:
j∈J
πj
where for j ∈J πj is the identity representation πj(a) = a in the Hilbert space
Hj = H and where π0 is a representation of the quotient algebra B(H)/Bc(H). This
means that there is a unitary operator U from the representation space K of π onto
the direct sum of the Hilbert spaces of these representations
H0 ⊕
:
j∈J
Hj.
Denote the projectors of UK onto H0 by P0, respectively onto Hj by Pj, j ∈J.
Thus, f (a) = V ∗π(a)V takes the form
f (a) = V ∗
0 π0(a)V0 +

j∈J
a∗
j aaj,
a ∈B(H)
where V0 = P0UV and aj = PjUV for j ∈J. Since π0(I) ≥0 one has the bound
(30.60).
2

482
30
Operator Algebras and Positive Mappings
30.5
Exercises
1. Denote the transposition on M2(C) by T , i.e., T (A) = At. Show that T is positive
and preserves unity. Consider the trivial extension I ⊗T : M2(C) ⊗M2(C) −→
M2(C) ⊗M2(C) given by A ⊗B →A ⊗Bt. Show that this extension is not
positive.
Hints: Choose special simple examples for A, B.
2. In M2(C) consider the linear map T deﬁned by its action on the basis elements

I2, σ = (σx, σy, σz)

of M2(C): T (I2) = I2, T (σ) = λσ. For which λ is T
positive, respectively completely positive?
3. Show that the space Bc(H) of compact operator is a ∗-algebra which is not weakly
closed, i.e., Bc(H) is not a von Neumann algebra.
Hints: Show Bc(H)′′ = B(H) and recall the “algebraic” characterization of a von
Neumann algebra.
4. Let T be a positive map of the Abelian ∗-algebra A into the Abelian ∗-algebra
B. Show that T is completely positive. Reﬂect on the meaning of this result for
quantum physics.
References
1. Buchholz D, Haag R. The quest for understanding in relativistic quantum physics. J Math Phys.
2000;41:3674–3697.
2. Jost R. The general theory of quantized ﬁelds. Providence: American Math Soc.; 1965.
3. Takesaki M. Theory of operator algebras I. Encyclopedia of mathematical sciences—operator
algebras and non-commutative geometry. Vol. 124. Berlin: Springer; 2002.
4. Kelly JL. General topology. New York: Springer; 1991.
5. Ringrose JR, Kadison RV. Fundamentals of the theory of operator algebras: elementary theory.
Vol. I. Academic Press; 1983.
6. Stinespring WF. Positive functions on C∗-algebras. Proc Am Math Soc. 1955;6(2):211–216.

Chapter 31
Positive Mappings in Quantum Physics
31.1
Gleason’s Theorem
In Theorem 26.4 we learned that the continuous linear functionals on the space
of all compact operators on a separable Hilbert space H are given by trace class
operators according to the Trace Formula (26.10). There is a profound related result
due to A. Gleason which roughly says that this trace formula holds when we start
with a countably additive probability measure on the projections of H instead of a
continuous linear functional on the compact operators on H (Recall that all ﬁnite
dimensional projections belong to the space of compact operators).
Gleason’s result [1] is very important for the (mathematical) foundation of quan-
tum mechanics. A historical perspective and some key ideas related to this work are
presented in [2].
Theorem 31.1 (Gleason’s Theorem) Let μ be a countable additive probability
measure on the projections of a separable Hilbert space H of dimension greater
than 2. Then there is a unique nonnegative trace class operator W of trace 1 such
that for every projection P on H one has
μ(P) = Tr(WP).
(31.1)
The original proof by Gleason relies on methods not related to topics presented in
this book. Moreover this proof is quite long. Accordingly, we do not present it here.
Instead, we discuss a weakened version due to P. Busch [3] which however is valid
in any Hilbert space, contrary to Gleason’s result.
A proof of Gleason’s original result which is more easily accessible is given in
[4, 7, 8].
In [5] the physical meaning of effects and their mathematical realization is ex-
plained. Intuitively the term effect refers to the “effect” of a physical object on a
measuring device. Projections are idempotent effects, i.e., they satisfy E2 = E, and
are interpreted as “properties.” Effects which are not properties can be interpreted
as “unsharp properties” (see [6]). Clearly, on any Hilbert space there are many more
effects than properties.
© Springer International Publishing Switzerland 2015
483
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_31

484
31
Positive Mappings in Quantum Physics
Denote by E(H) the set of all effects on the separable Hilbert space H, i.e., the
set of all A ∈B(H) which satisfy 0 ≤A ≤I.
Deﬁnition 31.1
A generalized probability measure on all effects on a seperable
Hilbert space H is a function μ : E(H) −→R which satisﬁes
1) 0 ≤μ(E) ≤1 for all E ∈E(H),
2) μ(I) = 1,
3) for any sequence (Ej) ⊂E(H) such that 
j Ej ≤I one has
μ(

j
Ej) =

j
μ(Ej).
Similar to Gleason’s result one would like to know the general form of generalized
probability measures on effects. It turns out that the analysis in this case is much
simpler, mainly due to the fact that now a more or less standard extension in the
ordered vector space of self-adjoint elements in B(H)
Bs(H) = B(H)+ −B(H)+
which is generated by the positive elements, is possible.
Lemma 31.1 Any generalized probability measure μ on E(H) is the restriction of
a positive linear functional f : B(H) −→C to the set of effects E(H): μ = f |E(H).
Proof Because of the deﬁning conditions 1) and 3), a generalized probability mea-
sure μ on effects is monotone, i.e., if E, F ∈E(H) satisfy E ≤F then μ(E) ≤μ(F).
If E ∈E(H) and n ∈N are given, condition 3) implies μ(E) = nμ( 1
nE), since
E = 1
nE + · · · + 1
nE (n summands). Next suppose m, n ∈N are given and m ≤n
so that m/n ≤1, thus m
n E ∈E(H) and the relation μ( 1
nE) = 1
nμ(E) implies (· · ·
means m summands)
m
n μ(E) = mμ(1
nE) = μ(1
nE + · · · + 1
nE) = μ(m
n E),
and therefore, μ(qE) = qμ(E) for all rational numbers q ∈[0, 1].
If 0 < r < 1 is any real number, there are sequences of rational numbers qj, pj ∈
(0, 1) such that pj ↓r and qj ↑r and for all j ∈N, 0 < qj ≤r ≤pj < 1. Then
we know qjE ≤rE ≤pjE and therefore by monotonicity of μ
qjμ(E) = μ(qjE) ≤μ(rE) ≤μ(pjE) = pjμ(E).
In the limit j →∞, we thus get rμ(E) ≤μ(rE) ≤rμ(E). This implies μ(rE) =
rμ(E) for all E ∈E(H) and all r ∈[0, 1].
Next, suppose that A ∈B(H) is given satisfying 0 ≤A but not A ≤I. Then
there is r ≥1 such that E = 1
r A ∈E(H). But clearly r and E are not unique. If
we have A = r1E1 = r2E2 we can assume that r2 > r1 ≥1 so that 0 < r1
r2 < 1. It
follows μ(E2) = μ( r1
r2 E1) = r1
r2 μ(E1) or r1μ(E1) = r2μ(E2). This allows to deﬁne

31.1
Gleason’s Theorem
485
μ1 : B(H)+ −→R by μ1(A) = rμ(E) whenever A = rE with E ∈E(H) and
r ≥1.
Clearly, μ1 is positive homogeneous on the convex cone B(H)+ of nonnegative
bounded linear operators on H.
In order to show that μ1 is additive on B(H)+ take A, B ∈B(H)+. Then there is
r > 1 such (A + B)/r ∈E(H). The deﬁnition of μ1 gives μ1(A + B) = rμ( 1
r (A +
B)) = rμ( 1
r A) + rμ( 1
r B) = μ1(A) + μ1(B).
Altogether we have shown that μ1 is an additive positive homogeneous function
on the convex cone B(H)+. Thus, according to a standard procedure in the theory of
ordered vector spaces, the functional μ1 can be extended to a linear functional μ2 on
Bs(H). If C = A −B ∈B(H)+ −B(H)+ deﬁne μ2(C) = μ1(A) −μ1(B). It is easy
to see that μ2 is well-deﬁned. If C is also represented as A′ −B′ ∈B(H)+ −B(H)+,
then it follows μ1(A) −μ1(B) = μ1(A′) −μ1(B′), since A′ + B = A + B′ implies
μ1(A′) + μ1(B) = μ1(A′ + B) = μ1(A + B′) = μ1(A) + μ1(B′). In order to
show that μ2 : Bs(H) −→R is additive, take C = A −B and C′ = A′ −B′ in
B(H)+ −B(H)+ and calculate μ2(C + C′) = μ2(A −B + A′ −B′) = μ2(A + A′ −
(B + B′)) = μ1(A + A′) −μ1(B + B′) = μ1(A) + μ1(A′) −μ1(B) −μ1(B′) =
μ2(A −B) + μ1(A′ −B′) = μ2(C) + μ2(C′).
Clearly, since μ1 is positive homogeneous, so is μ2. Next, suppose λ < 0 and C =
A−B ∈B(H)+−B(H)+ are given. Then λC = (−λ)B−(−λ)A ∈B(H)+−B(H)+
and so μ2(λC) = μ1(( −λ)B) −μ1(( −λ)A) = ( −λ)μ1(B) −( −λ)μ1(A) =
λ(μ1(A) −μ1(B)) = λμ2(C).
It follows that μ2 : Bs(H) −→R is a positive linear functional which agrees
with μ on E(H). Since B(H) = Bs(H) + i Bs(H) the real linear functional μ2
is extended to a complex linear functional f : B(H) −→C by setting for A =
a + i b ∈Bs(H) + i Bs(H), f (A) = μ2(a) + i μ2(b). A simple calculation shows
that f is indeed complex linear on B(H) and by construction μ = f |E(H).
2
Note that in the proof of this lemma, condition 2) has not been used and condition
3) has been used only for ﬁnitely many effects.
Theorem 31.2 (Busch) Any generalized probability measure μ on the set of effects
E(H) of a separable Hilbert space H is of the form
μ(E) = Tr(WE)
for all E ∈E(H)
for some density operator W.
Proof According to the extension Lemma 31.1, any generalized probability measure
μ on the set of effects is the restriction to this set of a positive linear functional
f on B(H). Such functionals are continuous according to Proposition 30.1. Now,
since projections are (special) effects, condition 3) says that the functional f is
completely additive (see (30.29)). Hence, we conclude by Theorem 30.5.
2
Remark 31.1 Technically, in a two-dimensional Hilbert space the condition of ad-
ditivity of μ on sets of pairwise orthogonal projection is not strong enough to enforce

486
31
Positive Mappings in Quantum Physics
linearity of μ. More concretely, let μ be a normalized additive measure on the pro-
jections E of C2, i.e., μ(E) + μ(E⊥) = 1. According to Eq. 18.23 every projection
is of the form E = 1
2(I2 + e · σ) with a unique unit vector e ∈R3. Introduce the
function f (e) = μ( 1
2(I2 + e · σ)). Deduce that f satisﬁes f (e) + f ( −e) = 1 for all
unit vectors e ∈R3. This condition is not strong enough to force f to be linear.
31.2
Kraus Form of Quantum Operations
A quantum mechanical systems undergoes various types of transformations, for
instance symmetry transformations, time evolution and transient interactions with
an environment for measurement purposes. These transformations are described by
the concept of a quantum operation and the nature of these mappings has been
discussed since about 50 years starting with a paper by Sudarshan et al. in 1961.
A mathematically rigorous and comprehensive study of quantum operations has
been published by K. Kraus in 1983 in [5]. Starting from ﬁrst (physical) principles
it is argued that quantum operations are given mathematically by linear mappings
φ : B1(H) −→B1(H)
of the space of trace class operators on a (separable) Hilbert space H into itself which
are completely positive and satisfy
Tr(φ(W)) ≤1
(31.2)
for all W ∈B1(H) with W ≥0 and Tr(W) = 1, i.e., for all density matrices on H.
In Deﬁnition 30.6 we had deﬁned completely positive mappings as mappings
between C∗-algebras which satisfy certain positivity conditions. Clearly B1(H) is
not a C∗-algebra with unit (if H is not ﬁnite dimensional) but it is a two-sided ideal
in the C∗-algebra B(H). Therefore, these positivity conditions can be formulated
for B1(H) in the same way as for the C∗-algebra B(H). And it is in this sense that
we understand complete positivity for a map φ : B1(H) −→B1(H), i.e., φ is
completely positive if, and only if, it is k-positive for k = 1, 2, . . . . However, in the
characterization of positive elements in B1(H) there is an important difference to
the characterization of positive elements in a C∗-algebra. According to the spectral
representation of trace class operators (Theorem 26.3), T ∈B1(H) is positive if, and
only if, T = τ ∗τ for some τ ∈B2(H) (not in B1(H)). The characterization of positive
elements in Mk(B1(H)) for k ≥2 is addressed explicitly later (see Lemma 31.4).

31.2
Kraus Form of Quantum Operations
487
31.2.1
Operations and Effects
Lemma 31.2 If a positive linear map φ : B1(H) −→B1(H) satisﬁes (31.2), then
it is continuous with respect to the trace norm:
∥φ(T )∥1 ≤C ∥T ∥1 ,
C = sup Tr(φ(W)) ≤1
(31.3)
where the sup is taken over all density matrices W on H.
Proof By (31.2) we obviously have that C = sup Tr(φ(W)) ≤1 where the sup is
taken over all density matrices. Write T = T ∗∈B1(H) as T = T+ −T−where
T± = (|T |±T )/2. We can assume that Tr(T±) > 0. Then W± =
1
Tr(T±)T± are density
matrices and it follows that
T = Tr(T+)W+ −Tr(T−)W−
and thus φ(T ) = Tr(T+)φ(W+) −Tr(T−)φ(W−). According to (30.16), the trace
norm of φ(T ) can be calculated as
∥φ(T )∥1 = sup
∥B∥=1
|Tr(Bφ(T ))|.
Insert the above expression for φ(T ) and estimate as follows:
|Tr(Tr(T+)Bφ(W+)) −Tr(T−)Bφ(W−))| ≤
Tr(T+)|Tr(Bφ(W+))| + Tr(T−)|Tr(Bφ(W−))|
Since φ is positive, we know
|Tr(Bφ(W±))| ≤∥B∥∥φ(W±)∥1 = ∥B∥Tr(φ(W±)) ≤∥B∥C
and thus
∥φ(T )∥1 ≤Tr(T+)C + Tr(T−)C = C ∥T ∥1 .
2
The adjoint φ∗of an operation φ in the duality between trace class operators and
bounded linear operators on H (see Theorem 26.5) is then a linear map
φ∗: B(H) −→B(H)
which is positive too (see Lemma 31.4). From a physical point of view this adjoint
is important since it gives the “effect” F = Fφ corresponding to an operation as
F = φ∗(I).
Lemma 31.3
Let φ : B1(H) −→B1(H) be a positive linear mapping such that
Tr(φ(W)) ≤1 for all density matrices W on H. Then its dual map φ∗(in the duality

488
31
Positive Mappings in Quantum Physics
established in Theorem 26.5) is a linear map B(H) −→B(H) which is well deﬁned
by
Tr(φ∗(B)T ) = Tr(Bφ(T ))
for all B ∈B(H), T ∈B1(H).
(31.4)
Proof Given such a map φ, it is continuous according to Lemma 31.2: ∥φ(T )∥1 ≤
C ∥T ∥1 for all T ∈B1(H). Fix B ∈B(H); since
|Tr(Bφ(T ))| ≤∥B∥∥φ(T )∥1 ≤∥B∥C ∥T ∥1 ,
T−→Tr(Bφ(T )) is a continuous linear functional on B1(H) and therefore according
to Theorem 26.5 of the form Tr(CT ) with a unique C ∈B(H). This element C is
called φ∗(B). This applies to every B ∈B(H) and thus deﬁnes the adjoint mapping
φ∗, and by construction Relation (31.4) holds. A straight forward calculation
establishes linearity of φ∗, using uniqueness in the duality between B1(H) and
B(H).
2
Corollary 31.1 For a positive linear mapping φ : B1(H) −→B1(H) the following
statements are equivalent:
a) Tr(φ(W)) ≤1 for all density matrices W on H;
b) φ is continuous and φ∗(I) ≤I.
Proof
Suppose a) holds. Then, by Lemma 31.2 the map φ is continuous. Thus,
according to Lemma 31.3 the dual mapping φ∗: B(H) −→B(H) is well deﬁned
and Relation (31.4) holds, in particular for all density matrice W and B = I,
Tr(φ∗(I)W) = Tr(φ(W)).
It follows Tr(φ∗(I)W) ≤1 for all W. For W = [x, x], x ∈H, ∥x∥= 1 this implies
Tr(φ∗(I)[x, x]) = ⟨x, φ∗(I)x⟩≤1 and hence ⟨x, φ∗(I)x⟩≤⟨x, x⟩for all x ∈H and
φ∗(I) ≤I follows.
Conversely assume b). Since φ is continuous, the dual map φ∗is well deﬁned
and (31.4) holds and thus again Tr(φ∗(I)W) = Tr(φ(W)) for all density matrices W.
Now φ∗(I) ≤I implies a)
Tr(φ(W)) = Tr(W 1/2φ∗(I)W 1/2) ≤Tr(W 1/2W 1/2) = Tr(W) = 1.
2
Lemma 31.4
A linear mapping φ : B1(H) −→B1(H) is completely positive if,
and only if, its adjoint mapping φ∗: B(H) −→B(H) is completely positive.
Proof Naturally the proof consists in showing that for all k ∈N, the mapping φ is
k-positive if, and only if, the adjoint mapping φ∗is k-positive. We do this explicitly
for the case k = 1 and indicate the necessary changes for k ≥2.

31.2
Kraus Form of Quantum Operations
489
If B ∈B(H) is given, deﬁne a linear functional FB on B1(H) by FB(T ) =
Tr(Bφ(T )). According to Theorem 26.5, the duality is given by the trace formula
Tr(Bφ(T )) = Tr(φ∗(B)T )
for all B ∈B(H), T ∈B1(H).
(31.5)
If φ is positive, then we know φ(T ) ≥0 for all T ∈B1(H), T ≥0, and we have
to show that φ∗(B) ≥0 for all B ∈B(H), B ≥0. According to Theorem 26.3,
φ(T ) ∈B1(H) is positive if, and only if, it is of the form φ(T ) = τ ∗τ for some
τ = τ ∗∈B2(H). In this case we have
Tr(Bφ(T )) = Tr(Bτ ∗τ) = Tr(τBτ ∗) ≥0
for all B ≥0.
The duality relation implies
Tr(φ∗(B)T ) ≥0
for all T ∈B1(H), T ≥0.
Now choose x ∈H and insert the positive ﬁnite rank operator T = [x, x] deﬁned by
[x, x]y = x⟨x, y⟩, y ∈H, into this estimate to get
0 ≤Tr(φ∗(B)T ) = ⟨x, φ∗(B)x⟩
and thus φ∗(B) ≥0 for B ≥0.
Conversely, assume that φ∗is a positive mapping so that φ∗(B) ≥0 for all
B ≥0. Then, by Lemma 30.1 (or the square root lemma) for some b ∈B(H) we
know φ∗(B) = b∗b and the duality relation yields
Tr(Bφ(T )) = Tr(φ∗(B)T ) = Tr(b∗bT ) = Tr(bT b∗) ≥0
for all T ≥0. As above insert B = [x, x] to get ⟨x, φ(T )x⟩≥0 whenever T ≥0
and hence the mapping φ is positive.
Now assume k ≥2; abbreviate A = B1(H) and B = B(H). We have to show
that φk : Mk(A) −→Mk(A) is positive if, and only if, φ∗
k : Mk(B) −→Mk(B)
is positive. Recall that A = [aij] ∈Mk(A) respectively B = [bij] ∈Mk(B) act
on the Hilbert space Hk = H × H × · · · × H (k components). Under standard
matrix operations we have Mk(B) = B(Hk) and similarly Mk(A) = B1(Hk) (see
the Exercises). For the relation of traces in H and in Hk one ﬁnds (see again the
Exercises for this chapter)
TrHk([Tij]) =
k

j=1
Tr(Tjj)
when Tr denotes the trace in H. Thus, we get the extended duality formula
TrHk([bij]φk([Tij])) = TrHk(φ∗
k([bij])[Tij]))
(31.6)
since
TrHk([bij]φk([Tij])) =
k

i,j=1
Tr(bijφ(Tji)) =
k

i,j=1
Tr(φ∗(bij)Tji).
Therefore, we can argue for φk : B1(Hk) −→B1(Hk) and φ∗
k : B(Hk) −→B(Hk)
as above for φ and φ∗.
2

490
31
Positive Mappings in Quantum Physics
31.2.2
The Representation Theorem for Operations
Naturally the question about the general mathematical form of a quantum operation
arises. The answer has been given in [5]. In Sect. 30.4.5, we had studied completely
positive maps on B(H). Here, we begin by investigating completely positive maps
on trace class operators and ﬁnd some extensions of the earlier results.
Proposition 31.1 For a sequence of operators aj ∈B(H) which satisﬁes (30.56)
with bound B the series
φ(T ) =
∞

j=1
ajT a∗
j ,
T ∈B1(H) ﬁxed
(31.7)
converges in trace norm and deﬁnes a completely positive mapping on B1(H). The
related series (30.57), i.e.,
f (a) =
∞

j=1
a∗
j aaj,
a ∈B(H) ﬁxed
converges ultraweakly and deﬁnes the adjoint of φ, i.e.,
φ∗(a) =
∞

j=1
a∗
j aaj,
a ∈B(H) ﬁxed.
(31.8)
Furthermore,
φ∗(I) ≤B.
Proof Given 0 ≤T ∈B1(H) deﬁne for m ∈N,
φm(T ) =
m

j=1
ajT a∗
j .
Clearly φm(T ) is nonnegative and of trace class; thus, for m > n we ﬁnd
∥φm(T ) −φn(T )∥1 =
------
m

j=n+1
ajT a∗
j
------
1
= Tr
⎛
⎝
m

j=n+1
ajT a∗
j
⎞
⎠
= Tr
⎛
⎝
m

j=n+1
a∗
j ajT
⎞
⎠= Tr(SmT ) −Tr(SnT )
where the operators Sm = m
j=1 a∗
j aj where introduced in (30.6). Because of the
ultraweak convergence Sm −→S according to Lemma 30.4 we know Tr(SmT ) −→
Tr(ST ) and we conclude that (φm(T )) is a Cauchy sequences with respect to the trace
norm and therefore this sequence converges in trace norm to a unique φ(T ) ∈B1(H).

31.2
Kraus Form of Quantum Operations
491
Since the trace norm dominates the operator norm, we also have convergence of
(31.7) in operator norm and thus also ultraweakly. Since every trace class operator is
the complex linear combination of four positive ones, the series (31.7) converges for
every T ∈B1(H) with respect to the topologies as indicated above. The complete
positivity of φ follows as in the proof of Lemma 30.4.
These continuity properties allow to determine the dual φ∗of φ easily. This dual
is determined by
Tr(Bφ(T )) = Tr(φ∗(B)T )
for all B ∈B(H), T ∈B1(H).
We have
Tr(Bφ(T )) = lim
m→∞Tr(Bφm(T ))
and by property c) of Corollary 26.3
Tr(B
m

j=1
ajT a∗
j ) = Tr(
m

j=1
a∗
j BajT ).
According to Lemma 30.4, we know limm→∞
m
j=1 a∗
j Baj = f (b) in the ultraweak
topology, hence Tr(φ∗(B)T ) = Tr(f (B)T ) for all T ∈B1(H). Thus we conclude.
2
Theorem 31.3 (First Representation Theorem of Kraus) Given an operation φ :
B1(H) −→B1(H), there exists a ﬁnite or countable family

aj : j ∈J

of bounded
linear operators on H, satisfying

j∈J0
a∗
j aj ≤I
for all ﬁnite J0 ⊂J,
(31.9)
such that for every T ∈B1(H) and every B ∈B(H) one has
φ(T ) =

j∈J
ajT a∗
j
(31.10)
respectively
φ∗(B) =

j∈J
a∗
j Baj.
(31.11)
The effect F corresponding to φ thus has the representation
F = φ∗(I) =

j∈J
a∗
j aj.
(31.12)
In the case that the index set J is inﬁnite, i.e., J = N, the series in (31.10) con-
verges with respect to the trace norm while the series (31.11–31.12) converge in the
ultraweak operator topology.

492
31
Positive Mappings in Quantum Physics
Conversely, if a countable family

aj : j ∈J

of bounded linear operators on H
is given which satisﬁes (31.9) then Eq. (31.10) deﬁnes an operation φ whose adjoint
φ∗is given by (31.11) and the effect F corresponding to this operation is (31.12).
Proof
Suppose we are given a completely positive map φ : B1(H) −→B1(H)
satisfying (31.2). Lemma 31.4 implies that the adjoint map φ∗: B(H) −→B(H) is
completely positive too, thus according to Theorem 30.7 φ∗is of the form (30.59)
φ∗(B) = V ∗
0 π0(B)V0 +

j∈J
a∗
j Baj,
B ∈B(H)
with bounded linear operators aj ∈B(H) satisfying

j∈J
a∗
j aj ≤φ∗(I)
and where the representation π0 vanishes for all B ∈Bc(H). According to Corollary
31.1, the bound φ∗(I) ≤I is known and hence condition (31.9) holds.
Proposition 31.1 implies that the map φ∗
1(B) = 
j∈J a∗
j Baj on B(H) is the
adjoint of the mapping φ1(T ) = 
j∈J ajT a∗
j on B1(H). In order to conclude,
we need to determine the map φ0 on B1(H) whose adjoint is the map φ∗
0(B) =
V ∗
0 π0(B)V0 on B(H). This map is deﬁned through the duality relation
Tr(φ∗
0(B)T ) = Tr(Bφ0(T ))
for all
B ∈B(H), T ∈B1(H).
Since the representation π0 of B(H) vanishes on the subspace Bc(H), we know
Tr(Bφ0(T )) = 0 for all B ∈Bc(H), hence in particular for all x, y ∈H setting
B = [xy],
⟨y, φ0(T )x⟩= Tr([xy]φ0(T )) = 0,
and therefore φ0(T ) = 0 for all T ∈B1(H) and thus φ∗
0 = 0 on B(H). It follows
φ∗(I) =

j∈J
a∗
j aj.
The converse has already been proven in Proposition 31.1 and Lemma 30.4 with the
bound B = I when we observe Corollary 31.1.
2
Remark 31.2
Sometimes one requires that an operation φ is trace preserving,
i.e., Tr(φ(W)) = 1 for all density matrices W. This will be the case when in our
representation (31.10) the operators aj satisfy

j∈J
a∗
j aj = I.
(31.13)

31.3
Choi’s Results for Finite Dimensional Completely Positive Maps
493
In order to prove this recall that according to (31.12) one has

j∈J
a∗
j aj = φ∗(I)
and that we know φ∗(I) ≤I. The duality relation says
Tr(φ(W)) = Tr(φ∗(I)W)
for all density matrices W. Thus, if φ∗(I) = I then Tr(φ(W)) = 1 for all density
matrices and φ is trace preserving. Conversely, suppose that the operation φ is trace
preserving but φ∗(I) ̸= I. Then, since φ∗(I) ≤I is known, there is x ∈H, |x| = 1
such that ⟨x, φ∗(I)x⟩< 1. If the density matrix W = [x, x] is inserted into the
duality relation one gets
Tr(φ([x, x])) = Tr(φ∗(I)[x, x]) = ⟨x, φ∗(I)x⟩< 1,
hence, a contradiction and therefore φ∗(I) = I holds.
31.3
Choi’s Results for Finite Dimensional Completely Positive
Maps
Naturallyinthecaseofmappingsf : A −→B withA = Mn(C)andB = Mm(C)we
can use additional structural information to strengthen the statements of Stinespring’s
factorization theorem (Theorem 30.6) and to simplify the proofs. This has been done
in 1975 by M. Choi [9] with inspiration from electrical circuit theory (n-port systems)
by using the simple fact that these matrix algebras Mn(C) have a basis
e(n;ij), i, j = 1, 2, . . . , n
(31.14)
where e(n;ij) denotes the n × n matrix with the entry 1 in the ith row and jth column
and all other entries are 0.
In terms of this basis we can write a ∈Mn(C) as follows:
a =
⎛
⎜⎜⎜⎝
a11
· · ·
a1n
...
...
...
an1
· · ·
ann
⎞
⎟⎟⎟⎠=
n

i,j=1
aije(n;ij),
aij ∈C .
(31.15)
And this allows to determine the general form of a linear map f : Mn(C) −→Mm(C)
easily. For a ∈Mn(C) as above one ﬁnds by linearity
f (a) =
n

i,j=1
aijf (e(n;ij)).

494
31
Positive Mappings in Quantum Physics
Since f (e(n;ij)) ∈Mm(C) it has a unique expansion with respect to the basis
e(m;kl), k, l = 1, 2, . . . , m ,
i.e.,
f (e(n;ij)) =
m

k,l=1
f (e(n;ij))kle(m;kl),
f (e(n;ij))kl ∈C .
Thus, we can say that there is a one-to-one correspondence between linear maps
f : Mn(C) −→Mm(C) and system of complex numbers F ij
kl , i, j = 1, . . . , n,
k, l = 1, . . . , m such that
f (a) =
m

k,l=1
n

i,j=1
aijF ij
kl e(m;kl)
(31.16)
with a as in (31.15).
Theorem 31.4 (Choi’s Characterization of Completely Positive Maps) For a
linear map f : Mn(C) −→Mm(C) the following statements are equivalent:
(a) f is n-positive, i.e., the map fn : Mn(Mn(C)) −→Mn(Mm(C)) deﬁned in (30.40)
is positive;
(b) the matrix Cf ∈Mn(Mm(C)) deﬁned by
Cf =
⎛
⎜⎜⎜⎝
f (e(n;11))
· · ·
f (e(n;1n))
...
· · ·
...
f (e(n;n1))
· · ·
f (e(n;nn))
⎞
⎟⎟⎟⎠
(31.17)
is positive where e(n;ij) is speciﬁed in (31.14); it is called the Choi -matrix of f .
(c) f has the form
f (a) =
nm

μ=1
VμaV ∗
μ , a ∈Mn(C)
(31.18)
with m × n matrices Vμ, and thus f is completely positive.
Proof If a linear map f is of the form (31.18), it is a straightforward calculation to
show that f is completely positive, just as in the case of the Stinespring factorization.
Thus it is clear that (c) implies (a).
(a) ⇒(b): Note that the matrix E ∈Mn(Mn(C)) given by
E =
⎛
⎜⎜⎜⎝
e(n;11)
· · ·
e(n;1n)
...
· · ·
...
e(n;n1))
· · ·
e(n;nn)
⎞
⎟⎟⎟⎠
(31.19)

31.3
Choi’s Results for Finite Dimensional Completely Positive Maps
495
satisﬁes E∗= E (since (e(n;ij))∗= e(n;ji) and E2 = E, thus E = E∗E is positive
in Mn(Mn(C)) by Lemma 30.1. Since f is assumed to be n-positive, fn(E) = Cf is
positive in Mn(Mm(C)).
(b) ⇒(c): By deﬁnition, the matrix Cf acts on Hn
m ∼= Cnm. If (b) is assumed
this matrix is positive and thus its spectrum is contained in [0,
--Cf
-- ]. Its spectral
representation is of the form
Cf =
nm

ν=1
λkQk,
0 ≤λk ≤
--Cf
--
where Qk is the projector onto the eigenspace corresponding to the eigenvalue λk.
Denote by Pi the projection from Hn
m = Hm × Hm × · · · × Hm (n times) to the
ith component Hm, i.e., Pi(z1, . . . , zi, . . . , zn) = zi, for all zj ∈Hm, j = 1, . . . , n.
Then (31.17) shows
f (e(n;ij)) = PiCf Pj,
i, j = 1, . . . , n ,
and the spectral representation thus implies
f (e(n;ij)) =
nm

k=1
λkPiQkPj .
The normalized eigenvector v(k) for the eigenvalue λk belongs to the space Hn
m and
thus has a decomposition v(k) = (v(k)
1 , . . . , v(k)
n ) with v(k)
i
∈Hm for i = 1, . . . , n.
With the standard convention for the tensor product the projector Qk can be realized
as Qk = v(k) ⊗(v(k))∗. This allows to rewrite the above formula for f (e(n;ij)) as
f (e(n;ij)) =
nm

k=1
λkPiv(k) ⊗(v(k))∗Pj =
nm

k=1
λkv(k)
i
⊗(v(k)
j )∗.
Denote by e(n;i), i = 1, . . . , n the standard basis of Hn. For k = 1, . . . , mn deﬁne
linear operators V (k) : Hn −→Hm by their action on this basis
V (k)e(n;i) =

λkv(k)
i ,
i = 1, . . . , n .
Hence, we can continue our chain of identities for f (e(n;ij)) by
f (e(n;ij)) =
nm

k=1
(V (k)e(n;i)) ⊗(V (k)e(n;j))∗=
nm

k=1
V (k)(e(n;i)) ⊗(e(n;j))∗)(V (k))∗
or, since e(n;i) ⊗(e(n;j))∗= e(n;ij),
f (e(n;ij)) =
nm

k=1
V (k)e(n;ij)(V (k))∗
(31.20)

496
31
Positive Mappings in Quantum Physics
and thus by (31.15) f has the form (31.18). This proves (c).
2
Remark 31.3
(a) This result of M. D. Choi is quite remarkable. It shows in particular that a linear
map on the matrix algebra Mn(C) with values in Mm(C) is already completely
positive when it is n-positive.
(b) In addition, it is shown that such a linear map is n-positive whenever it is n-
positive on the elements of the (standard) basis.
(c) It determines the explicit form of completely positive maps which is considerable
more speciﬁc than the Stinespring factorization.
(d) In the case of matrix algebras the proof of the Stinespring factorization indicates
that a linear map is completely positive if is is n2 × m-positive (the dimension
of the space Mn(C) ⊗Cm is n2m).
(e) The map f −→Cf deﬁned in Eq. (31.17) is often called Jamiolkowski
isomorphism or Choi-Jamiolkowski isomorphism. It appeared ﬁrst in [10].
Corollary 31.2 (Finite-Dimensional Representations of Mn(C)) Let π
:
Mn(C) −→Mm(C) be a ﬁnite-dimensional representation of the matrix algebra
Mn(C). Then there are m × n matrices V μ, μ = 1, . . . , mn satisfying
V μ∗V ν = δμ,νIn
such that
π(a) =
nm

k=1
V (k)a(V (k))∗
∀a ∈Mn(C).
31.4
Open Quantum Systems, Reduced Dynamics and
Decoherence
As an illustration of the importance of some of the mathematical results which we
have presented thus far (mainly tensor product of Hilbert spaces and of operators,
density matrices, partial trace, normal states, von Neumann algebras) we discuss in
this section brieﬂy open systems and decoherence. For further details and proofs we
refer to the literature [11–13].
A (quantum or classical) physical system is described by a von Neumann alge-
bra M of operators acting on some separable Hilbert space H and a subsystem is
described by a certain subalgebra N ⊂M. A physical system is practically never
in full isolation; some interaction with the environment takes place. In the theory of
open quantum systems this is modelled by forming a joint system consisting of the
system we are interested in and a second system modeling the environment. If the
ﬁrst system is modelled by the von Neumann algebra M1 and the second by the von

31.4
Open Quantum Systems, Reduced Dynamics and Decoherence
497
Neumann algebra M2, the joined system is modeled by the von Neumann algebra
M = M1 ⊗M2 which acts on the Hilbert space H = H1 ⊗H2 in a natural way.
If the joined system is in a state given by the density matrix ρ on H = H1 ⊗H2
then the state ρ1 of the ﬁrst system as viewed by an observer who observes only the
ﬁrst system is given by the partial trace of ρ with respect to the second system (see
Theorem 26.7):
ρ1 = Tr2(ρ).
The joined system is considered to be closed and often in applications its Hamilton
operator H is of the form
H = H1 ⊗I + I ⊗H2 + gHint
with free Hamiltonians Hj of system j, j = 1, 2, and an interaction Hamiltonian
Hint describing the coupling between the two systems and a coupling constant g.
The time evolution of the state of the total system then is
ρ(t) = e −i tHρ e i tH.
From this the time evolution of ﬁrst subsystem is obtained by taking the partial trace
ρ1(t) = Tr2(ρ(t)) = Tt(Tr2(ρ)).
Tt is called the reduced dynamics. One can show that in general it is irreversible.
In the Exercises to Chap. 26 it is shown that the partial trace maps density matrices
on H1 ⊗H2 to density matrices on H1. In addition it is known that the reduced
dynamics {Tt, t ≥0} is a family of normal completely positive and unital maps (i.e.,
Tt(I) = I) if the initial state is a product state, i.e., ρ = ρ1⊗ρ2 with density matrices
ρj on Hj, j = 1, 2.
Let M1 be the algebra of observables of the system to be investigated and M2
the algebra of observables of the environment E describing the rest of the physical
world which one intends to ignore eventually. In the algebraic framework of quantum
physics a notion of decoherence was ﬁrst introduced in [11]. Decoherence is a well
known concept in quantum theory. It does not involve any new physical laws or
assumptions beyond the established framework of quantum theory. On the contrary,
it is a consequence of the universal applications of quantum concepts.
We say that decoherence takes place if there exists a splitting
M1 = A1 ⊕A2
suchthatA1 isavonNeumannalgebraonwhichthereduceddynamicsactsreversibly,
i.e., is an automorphism group, and a complementing subspace with the property that
the expectations values of all observables in A2 become small as the time gets large:
lim
t→∞φ(Tt(a)) = 0
for all a ∈A2.
Any observable a = a∗∈M1 can thus be written as a = a1 + a2 with aj ∈Aj,
where a2 becomes unobservable if we wait long enough. After a sufﬁciently long

498
31
Positive Mappings in Quantum Physics
time the system is effectively described by the algebra A1 and behaves like a closed
system, but it may have properties different from the original one. By analyzing the
structure of the algebra of effective observables A1 and the dynamics αt = Tt|A1 we
can classify different scenarios of decoherence: Environment induced superselection
rules, pointer states, classical systems, new quantum behavior, ergodicity and the
role decoherence plays in the interpretation of measurements in quantum theory.
Environment induced decoherence is an asymptotic property of time evolution
in suppressing interference between possible events and their complements, thus
rendering them “for all practical purposes” mutually exclusive [14–16].
31.5
Exercises
1. For k = 2, 3, . . . and a separable Hilbert space H denote Hk = H×H×· · ·×H
(k components). With the standard operations and the natural scalar product Hk
is a Hilbert space in which the given Hilbert space is embedded by isometric
mappings J1 : H −→H×{0}×· · ·×{0}, J2 : H −→{0}×H×{0}×· · ·×{0},
. . . , Jk : H −→{0} × · · · × {0} × H. Show: If Bκ =
 
eκ
j : j ∈N
!
is an
orthonormal basis of H, then J1(B1) × J2(B2) × · · · × Jk(Bk) is an orthonormal
basis of Hk.
2. Using the notation introduced in the text show Mk(B(H)) = B(Hk) and
Mk(B1(H)) = B1(Hk).
Hints: In order to show Mk(B1(H)) ⊆B1(Hk), use a suitable characterization of
trace class operators as given in Proposition 26.1 and observe Exercise 1.
3. Observe Exercise 1 to prove the “trace formula”
TrHk([Tij]) =
k

j=1
Tr(Tjj)
for [Tij] ∈Mk(B1(H)).
4. Gleason’s theorem does not hold in C2: According to Remark 31.1, additive
measures μ on orthogonal projection of the Hilbert space C2 are in a one-to-one
correspondence with functions f on the unit vectors e ∈R3 with values in [0, 1]
satisfying f (e) + f ( −e) = 1. In this Exercise we construct a function f such
that the corresponding measure μ is not given by a trace.
Fix a unit vector e1 ∈R3 and deﬁne fe1 as follows: For a unit vector n deﬁne
fe1(n) =
⎧
⎨
⎩
0
if
n · e1 < 0
1
if
n · e1 > 0

References
499
Clearly, fe1satisﬁes fe1(n) + fe1( −n) = 1. Next take two unit vector e2 and e3
in the plane perpendicular to e1 such that e2 · e3 = 0 and deﬁne
fe2(n) =
⎧
⎨
⎩
0
if
n ∈e1⊥, n · e2 < 0
1
if
n ∈e1⊥, n · e2 > 0
.
Finally, deﬁne on unit vectors n ∈R3
f (n) =
⎧
⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎩
fe1(n)
if n · e1 ̸= 0
fe2(n)
if n · e1 = 0, n · e2 ̸= 0
1
if n = e3
0
if n = −e3
Now verify that f is well deﬁned on all unit vectors in R3, satisﬁes f (n) + f ( −
n) = 1, but is not of the form as stated in Gleason’s theorem for the case of Hilbert
spaces of dimension ≥3.
References
1. Gleason AM. Measures on the closed subspaces of a Hilbert space. J Math Mech. 1957;6:885–
893.
2. Chernoff PR. Andy Gleason and quantum mechanics. Notices AMS. 2009;56(10):1253–1259.
3. Busch P. Quantum states and generalized observables: a simple proof of Gleason’s theorem.
Phys Rev Lett. 2003;91(12/120403):1–4.
4. RichmanF,BridgesD.AconstructiveproofofGleason’stheorem. JFunctAnal. 1999;162:287–
312.
5. Kraus K. States, effects, and operations. Lecture notes in physics. Vol. 190. Berlin: Springer-
Verlag; 1983.
6. Busch P. Unsharp reality and joint measurements for spin observable. Phys Rev D.
1986;33:2253–2261.
7. Cook C, Keane M, Moran W. An elementary proof of Gleason’s theorem. Math Proc Camb
Philos Soc. 1985;98:117–128.
8. Hughes R. The structure and interpretation of quantum mechanics. Harvard University Press;
1989.
9. Choi MD. Completely positive linear maps on complex matrices. Linear Algebra Appl.
1975;10:285–290.
10. Jamiolkowski A. Linear transformations which preserve trace and positive semideﬁniteness of
operators. Rep Math Phys. 1972;3:275.
11. BlanchardP,OlkiewiczR.Decoherenceinducedtransitionfromquantumtoclassicaldynamics.
Rev Math Phys. 2003;15:217–243.
12. Blanchard P, Olkiewicz R. Decoherence as irreversible dynamical process in open qsystemssys-
tems. In: Joye A, Attal S, Pillet CA, editors. Open quantum systems III recent developments.
Lecture notes in mathematics. Vol. 1882. Berlin: Springer-Verlag; 2006. pp. 117–159.
13. Blanchard P, Hellmich M. Decoherence in inﬁnite quantum systems. In: Brüning E, Konrad
T, Petruccione F, editors. Quantum Africa 2010: theoretical and experimental foundations of
recent quantum technology. Vol. 1469. AIP Conference Proceedings; 2012. pp. 2–15.

500
31
Positive Mappings in Quantum Physics
14. Fröhlich J, Schubnel B. Do we understand quantum mechanics—ﬁnally? In: Reiter WL,Yng-
vason J, editors. Erwin Schrödinger—50 years after. ESI lectures in mathematics and physics.
Vol. 9. Zuerich, European Mathematical Society. American Mathematical Society; 2013.
15. Omnès R. The interpretation of quantum mechanics. Princeton, NJ Princeton University Press;
1994.
16. Schlosshauer M. Decoherence and the quantum-to-classical transition. 2nd ed. Berlin,
Springer; 2007.

Part III
Variational Methods

Chapter 32
Introduction
The ﬁrst two parts of this book were devoted to generalized functions and Hilbert
spaces whose operators are primarily of importance for quantum mechanics and
quantum ﬁeld theory. These two physical theories were born and developed in the
twentieth century. In sharp contrast to this are the variational methods which have a
much longer history. In 1744, L. Euler published a ﬁrst textbook on what soon after
was called the calculus of variations, with the title “A method for ﬁnding curves en-
joying certain maximum or minimum properties.” In terms of the calculus which had
recently been invented by Leibniz and Newton, optimal curves were determined by
Euler. Depending on the case which is under investigation optimal means “maximal”
or “minimal.” Though not under the same name, the calculus of variations is actually
older and closely related to the invention and development of differential calculus,
since already in 1684 Leibniz’ ﬁrst publication on differential calculus appeared un-
der the title Nova methodus pro maximis et minimis itemque tangentibus. This can be
considered as the beginning of a mathematical theory which intends to solve prob-
lems of “optimization” through methods of analysis and functional analysis. Later
in the twentieth century methods of topology were also used for this. Here “optimal”
can mean a lot of different things, for instance: shortest distance between two points
in space, optimal shapes or forms (of buildings, of plane wings, of natural objects),
largest area enclosed by a fence of given length, minimal losses (of a company in
difﬁcult circumstances), and maximal proﬁts (as a general objective of a company).
And in this wider sense of “ﬁnding optimal solutions” as part of human nature or as
part of human belief that in nature an optimal solution exists and is realized there, the
calculus of variations goes back more than 2000 years to ancient Greece. In short,
the calculus of variations has a long and fascinating history. However, “variational
methods” are not a mathematical theory of the past, related to classical physics, but
an active area of modern mathematical research as the numerous publications in this
ﬁeld show, with many practical or potential applications in science, engineering, and
economics. Clearly this means for us that in this short third part we will be able to
present only the basic aspects of one direction of the modern developments in the
calculus of variations, namely those with close links to the previous parts, mainly to
Hilbert space methods.
© Springer International Publishing Switzerland 2015
503
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_32

504
32
Introduction
32.1
Roads to Calculus of Variations
According to legend Queen Dido, ﬂeeing from Tyre, a Phoenician city ruled by
King Pygmalion, her tyrannical brother, and arriving at the site that was called later
Carthage, sought to purchase land from the natives. They asserted that they were
willing to sell only as much ground as she could surround with a bull’s hide. Dido
accepted the deal and cut a bull’s hide into very narrow strips which she pieced
together to form the longest possible strip. She reasoned that the maximal area
should be obtained by shaping the strip into the circumference of a circle.A complete
mathematical proof of Dido’s claim as the best possible choice was not achieved until
the nineteenth century. Today one still speaks of the general problem of Dido as an
isoperimetric problem but where this adjective has the much wider interpretation as
referring to any problem in which an extremum is to be determined subject to one
or more constraints, for instance the problem of ﬁnding the form which will give the
greatest volume within a ﬁxed surface area.
Heron of Alexandria postulated a minimum principle for optics and deduced the
law of reﬂection of light for a straight mirror. In 1662 Fermat generalized Heron’s
principle by postulating a principle of least time for the propagation of light. Later
several other principles of optimality (minima or maxima) were formulated about
fundamental physical quantities such as energy, action, entropy, separation in the
space–time of special relativity. In other ﬁelds of science one knows such principles
too. In probability and statistics we have “least square” and “maximum likelihood”
laws. Minimax principles are fundamental in game theory, statistical decision theory,
and mathematical economics.
In short, the calculus of variations can be described as the generalization of the
method to solve problems of minima and maxima by elementary calculus, a gener-
alization to the case of inﬁnitely many variables, i.e., to inﬁnite dimensional spaces.
In 1744, Euler explained and extended the maxi–minimal notions of Newton, of
Bernoulli and Maupertuis. His 1753 “Dissertatio de principio minimae actionis” as-
sociates him with Lagrange as one of the inventors of the calculus of variations, in its
analytic form. In 1696, Jean Bernoulli posed the problem of determining the path of
fastest descent of a point mass, i.e., the brachistochrone problem. This problem was
typical for the problems considered at that time since it required to ﬁnd an unknown
function y = f (x) which minimizes or maximizes an integral of the form
S(f ) =
 b
a
L(x, f (x), f ′(x)) dx.
Such an integral is a function on a function space or a functional, a name introduced
by J. Hadamard and widely used nowadays.
Another famous problem whose solution has been a paradigm in the calculus of
variations now for about a century is the so-called Dirichlet problem. In this problem
one is asked to ﬁnd a differentiable function f whose derivatives are square integrable
over a domain Ω ⊂R3 and which has prescribed values on the boundary ∂Ω, i.e.,

32.2
Classical Approach Versus Direct Methods
505
f|∂Ω = g where g is some given function on ∂Ω, so that the “Dirichlet integral”
I(f ) =

Ω
|Df (x)|2 dx
is minimal. (Such a problem arises, for instance, in electrostatics for the electric
potential f .) The existence of a solution of the Dirichlet problem was ﬁrst taken for
granted, since the integrand is nonnegative. It was only Weierstrass, around 1870,
who pointed out that there are variational problems without a solution, i.e., in modern
language for which there is no minimum though the functional has a ﬁnite inﬁmum.
Under natural technical assumptions, the existence of a minimizing function f
of the Dirichlet integral was proven by D. Hilbert in 1899. The decisive discoveries
which allowed Hilbert to prove this result were the notion of the “weak topology”
on spaces which today are called Hilbert spaces and precompactness with respect to
this weak topology of bounded sets (compare the introduction to Part B).
For readers who are interested in a more extensive exposition of the fascinating
history of the calculus of variations we recommend the books [1, 2] for a start.
An impressive account of the great diversity of variational methods is given in an
informal way in the recent book [3].
32.2
Classical Approach Versus Direct Methods
Historically, the calculus of variations started with one-dimensional problems. In
these cases one tries to ﬁnd an extremal point (minimum or maximum) of functionals
of the form
f (u) =
 b
a
F(t, u(t), u′(t)) d t
(32.1)
over all functions u ∈M =

v ∈C2([a, b], Rm) : u(a) = u0, u(b) = u1

where
u0, u1 ∈Rm are given points and m ∈N. The integrand F : [a, b] × Rm × Rm →R
is typically assumed to be of class C2 in all variables. A familiar example is the action
functional of Lagrangian mechanics. In this case the integrand F is just the Lagrange
function L which for a particle of mass m moving in the force ﬁeld of a potential V
is L(t, u, u′) = m
2 u′2 −V (u).
There is a counterpart in dimensions d > 1. Let Ω ⊆Rd be an open nonempty
set and F : Ω × Rm × Mmd →R a function of class C2 where Mmd is the space
of all m × d matrices; for u : Ω →Rm denote by Du(x) the m × d matrix of ﬁrst
derivatives of u. Then, under suitable integrability assumptions a functional f (u) is
well deﬁned by the integral
f (u) =

Ω
F(x, u(x), Du(x)) dx.
(32.2)
Such functionals are usually studied under some restrictions on u on the boundary
∂Ω of Ω, for instance the so-called Dirichlet boundary condition u|∂Ω = u0 where
u0 is some given function ∂Ω →Rm.

506
32
Introduction
In elementary calculus we ﬁnd extremal points of a function f (x), x ∈R, of
class C2 by determining ﬁrst the points xi at which the derivative of f vanishes, and
then deciding whether a point xi gives a local minimum or a local maximum or a
stationary point of f according to value f (2)(xi) of the second derivative.
The classical approach for functionals of the form (32.1) follows in principle
the same strategy, though the concepts of differentiation are more involved since
differentiation with respect to variables in an inﬁnite dimensional function space is
required. The necessary deﬁnitions and basic results about this differential calculus
in Banach spaces is developed in the next chapter. Thus, in a ﬁrst step we have to ﬁnd
the zeros of the ﬁrst derivative f ′, i.e., solutions of the Euler–Lagrange equation
f ′(u) = 0.
(32.3)
For functionals of the form (32.1), this equation is equivalent to a second order
ordinary differential equation for the unknown function u (see for instance [4] or
[2]). If the second derivative f (2)(u) is positive (in a sense which has to be deﬁned),
then the functional f has a local minimum at the function u. If this applies to the
functional −f , then f has a local maximum at u.
If only the problem of existence of an extremal point is considered there is another
strategy available. In order to understand it, it is important to recall Weierstraß’theo-
rem and its proof: A lower (upper) semicontinuous function f has a ﬁnite minimum
(a ﬁnite maximum) on a closed and bounded interval [a, b]. Here it is essential that
closed and bounded sets in R are compact, i.e., inﬁnite sequences in [a, b] have a
convergent subsequence.
This strategy too has a very successful counterpart for functionals of the form
(32.1) or (32.2). It is called the direct method of the calculus of variations. We give
a brief description of its basic steps.
1. Suppose M is a subset of the domain of the functional f and we want to ﬁnd a
minimum of f on M.
2. Through assumptions on f and/or M, assure that f has a ﬁnite inﬁmum on M,
i.e.,
inf
u∈M f (u) = I(f , M) = I > −∞.
(32.4)
Then, there is a minimizing sequence (un)n∈N ⊂M, i.e., a sequence in M such
that
lim
n→∞f (un) = I.
(32.5)
3. Suppose that we can ﬁnd one minimizing sequence (un)n∈N ⊂M such that
u = lim
n→∞un ∈M,
(32.6)
f (u) ≤lim inf
n→∞f (un);
(32.7)

32.2
Classical Approach Versus Direct Methods
507
then the minimization problem is solved since then we have
I ≤f (u) ≤lim inf
n→∞f (un) = I,
where the ﬁrst inequality holds because of u ∈M and where the second identity
holds because (un)n∈N is a minimizing sequence. Obviously, for Eq. (32.6) a
topology has to be speciﬁed on M.
4. Certainly, it is practically impossible to ﬁnd one minimizing sequence with the
two properties given above. Thus, in explicit implementations of this strategy
one works under conditions where the two properties hold for all convergent
sequences, with respect to a suitable topology. If one looks at the proof of Weier-
strass’ theorem one expects to get a convergent minimizing sequence by taking
a suitable subsequence of a given minimizing sequence. Recall: The coarser the
topology is, the easier it is for a sequence to have a convergent subsequence and
to have a limit point, i.e., to have Eq. (32.6). On the other hand, the stronger the
topology is the easier it is to satisfy inequality (32.7) which is a condition of lower
semicontinuity.
5. The paradigmatic solution of this problem in inﬁnite dimensional spaces is due
to Hilbert who suggested using the weak topology, the main reason being that
in a Hilbert space bounded sets are relatively sequentially compact for the weak
topology while for the norm topology there are not too many compact sets of
interest. Thus, suppose that M is a weakly closed subset of a reﬂexive Banach
space and that minimizing sequences are bounded (with respect to the norm).
Then there is a weakly convergent subsequence whose weak limit belongs to M.
Thus in order to conclude one veriﬁes that inequality (32.7) holds for all weakly
convergent sequences, i.e., that f is lower semicontinuous for the weak topology.
In the following chapter the concepts and results which have been used above will be
explained and some concrete existence results for extremal points will be formulated
where the above strategy is implemented.
Suppose that with the direct methods of the calculus of variations we managed to
show the existence of a local minimum of the functional f and that this functional
is differentiable (in the sense of the classical methods). Then, if the local mini-
mum occurs at an interior point u0 of the domain of f , the Euler–Lagrange equation
f ′(u0) = 0 holds and thus we have found a solution of this equation. If the functional
f has the form (32.1) (or 32.2), then the equation f ′(u0) = 0 is a nonlinear ordinary
(partial) differential equation and thus the direct methods become a powerful tool for
solving nonlinear ordinary and partial differential equations. Some modern imple-
mentations of this strategy with many new results on nonlinear (partial) differential
equations is described in good detail in the following books [2, 4–7], in a variety of
directions.
Note that a functional f can have other critical points than local extrema. These
other critical points are typically not obtained by the direct methods as described
above. However, there are other, often topological methods of global analysis by
which the existence of these other critical points can be established. We mention

508
32
Introduction
the minimax methods, index theory, and mountain pass lemmas. These methods are
developed and applied in [2, 7, 8]. But we cannot present them here.
32.3
The Objectives of the Following Chapters
The overall strategy of Part III has been explained in the Introduction. The next
chapter on direct methods is the abstract core of this part of the book. There we
present some general existence results for extrema of functionals which one can call
generalized Weierstraß theorems. Since the realization of all the hypotheses in these
results is not obvious, some concrete ways of implementing them are discussed in
some detail.
The following chapter introduces differential calculus on Banach spaces and
proves those results which are needed for the “classical approach” of the variational
methods.
On the basis of the differential calculus on Banach spaces, the third chapter
formulates in great generality the Lagrange multiplier method and proves in a fairly
general setting the existence of such a multiplier. When applied to linear or nonlinear
partial differential operators the existence of a Lagrange multiplier is equivalent to the
existence of an eigenvalue. Thus, this chapter is of particular importance for spectral
theory of linear and nonlinear partial differential operators. In the fourth chapter
we continue this topic and determine explicitly the spectrum of some linear second
order partial differential operators. In particular the spectral theorem for compact
self-adjoint operators is proven.
The ﬁnal chapter presents the mathematical basis of the Hohenberg–Kohn density
functional theory, which is the starting point of various concrete methods used mainly
in chemistry. It is based on the theory of Schrödinger operators for N-particle systems
which was introduced and discussed in Part II for N = 1.
References
1. Goldstine HH. A history of the calculus of variations from the 17th through the 19th century.
Studies in the history of mathematics and physical sciences. Vol. 5. New York: Springer; 1980.
2. Blanchard Ph, Brüning E. Variational methods in mathematical physics. A uniﬁed approach.
Texts and monographs in physics. Berlin: Springer; 1992.
3. Hildebrandt S, Tromba A. The parsimonious universe. Shape and form in the natural world.
Berlin: Springer; 1996.
4. Jost J, Li-Jost X. Calculus of variations. Cambridge Studies in advanced mathematics. Vol. 64.
Cambridge: Cambridge University Press; 1998.
5. Dacorogna B.Weak continuity and weak lower semicontinuity of non-linear functionals. Lecture
notes in mathematics. Vol. 922. Berlin: Springer; 1982.
6. Dacorogna B. Direct methods in the calculus of variations. Applied mathematical sciences.
Vol. 78. Berlin: Springer; 1989.

References
509
7. Struwe M. Variational methods: applications to nonlinear partial differential equations and
Hamiltonian systems. Ergebnisse der Mathematik und ihrer Grenzgebiete, Folge 3. Vol. 34,
3rd ed. Berlin: Springer; 2000.
8. Zeidler E. Variational methods and optimization. Nonlinear functional analysis and its
applications. Vol. 3. New York: Springer; 1985.

Chapter 33
Direct Methods in the Calculus of Variations
33.1
General Existence Results
From Chap. 1, we know that semicontinuity plays a fundamental role in direct meth-
ods in the calculus of variations. Accordingly, we recall the deﬁnition and the basic
characterization of lower semicontinuity. Upper semicontinuity of a function f is
just lower semicontinuity of −f .
Deﬁnition 33.1 Let M be a Hausdorff space. A function f : M →R ∪{+∞} is
called lower semicontinuous at a point x0 ∈M if, and only if, x0 is an interior
point of the set {x ∈M : f (x) > f (x0) −ε} for every ε > 0. f is called lower
semicontinuous on M if, and only if, f is lower semicontinuous at every point
x0 ∈M.
Lemma 33.1 Let M be a Hausdorff space and f : M →R ∪{+∞} a function on
M.
a) If f is lower semicontinuous at x0 ∈M, then for every sequence (xn/) ⟨⊂⟩M
converging to x0, one has
f (x0) ≤lim inf
n−→∞f (xn).
(33.1)
b) IfM satisﬁestheﬁrstaxiomofcountability, i.e., ifeverypointofM hasacountable
neighborhood basis, then the converse of (a) holds.
Proof For the simple proof we refer to the Exercises.
2
In Chap. 1, we also learned that compactness plays a fundamental role too, more
precisely, the direct methods use sequential compactness in a decisive way.
Deﬁnition 33.2 Let M be a Hausdorff space. A subset K ⊂M is called sequen-
tially compact if, and only if, every inﬁnite sequence in K has a subsequence which
converges in K.
© Springer International Publishing Switzerland 2015
511
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_33

512
33
Direct Methods in the Calculus of Variations
The following fundamental results proves the existence of a minimum. Replacing
f by −f it can easily be translated into a result on the existence of a maximum.
Theorem 33.1 (Existence of a Minimizer) Let f : M →R ∪{+∞} be a lower
semicontinuous function on the Hausdorff space M. Suppose that there is a real
number r such that
a) [f ≤r] = {x ∈M : f (x) ≤r} ̸= ∅and
b) [f ≤r] is sequentially compact.
Then there is a minimizing point x0 for f on M:
f (x0) = inf
x∈M f (x).
(33.2)
Proof We begin by showing indirectly that f is lower bounded. If f is not bounded
from below there is a sequence (xn)n∈N such that f (xn) < −n for all n ∈N. For
sufﬁciently large n the elements of the sequence belong to the set [f ≤r], hence
there is a subsequence yj = xn(j) which converges to a point y ∈M. Since f is
lower semicontinuous we know f (y) ≤lim infj→∞f (yj), a contradiction since
f (yj) < −n(j) →−∞. We conclude that f is bounded from below and thus has a
ﬁnite inﬁmum:
−∞< I = I(f , M) = inf
x∈M f (x) ≤r.
Therefore, there is a minimizing sequence (xn)n∈N whose elements belong to [f ≤r]
for all sufﬁciently large n. Since [f ≤r] is sequentially compact there is again a
subsequence yj = xn(j) which converges to a unique point x0 ∈[f ≤r]. Since f is
lower semicontinuous we conclude
I ≤f (x0) ≤lim inf
j→∞f (yj) = lim
j→∞f (yj) = I.
2
Undertheconditionofthefollowingtheoremonehasuniquenessoftheminimizer:
Theorem 33.2 (Uniqueness of Minimizer) Suppose M is a convex set in a vector
space E and f : M →R is a strictly convex function on M. Then f has at most one
minimizing point in M.
Proof
Suppose there are two different minimizing points x0 and y0 in M. Since
M is convex all points x(t) = tx0 + (1 −t)y0, 0 < t < 1, belong to M and
therefore f (x0) = f (y0) ≤f (x(t)). Since f is strictly convex we know f (x(t)) <
tf (x0)+(1−t)f (y0) = f (x0) and therefore the contradiction f (x0) < f (x0). Thus,
there is at most one minimizing point.
2

33.2
Minimization in Banach Spaces
513
33.2
Minimization in Banach Spaces
In interesting minimization problems we typically have at our disposal much more
information about the set M and the function f than we have assumed in Theo-
rem 33.1. If, for instance, one is interested in minimizing the functional (32.2) one
would prefer to work in a suitable Banach space of functions, usually a Sobolev
space. These function spaces and their properties are an essential input for applying
them in the direct methods. A concise introduction to the most important of these
function spaces can be found in [1].
Concerning the choice of a topology on Banach spaces which is suitable for the
direct methods (compare our discussion in Chap. 1) we begin by recalling the well-
known result of Riesz (see Theorem 19.1): The closed unit ball of a normed space
is compact (for the norm topology) if, and only if, this space is ﬁnite dimensional.
Thus, in inﬁnite-dimensional Banach spaces compact sets have an empty interior, and
therefore are not of much interest for most purposes of analysis, in particular not for
the direct methods. Which other topology can be used? Recall thatWeierstrass’result
on the existence of extrema of continuous functions on closed and bounded sets uses
in an essential way that in ﬁnite dimensional Euclidean spaces a set is compact if, and
only if, it is closed and bounded. A topology with such a characterization of closed
and bounded sets is known for inﬁnite dimensional Banach spaces too, the weak
topology. Suppose E is a Banach space and E′ is its topological dual space. Then
the weak topology σ = σ(E, E′) on E is deﬁned by the system

qu( · ) : u ∈E′
of
seminorms qu, q(x) = |u(x)| for all x ∈E. In most applications one can actually
use a reﬂexive Banach space and there the following important result is available.
Lemma 33.2
In a reﬂexive Banach space E every bounded set (for the norm) is
relatively compact for the weak topology σ(E, E′).
A fairly detailed discussion about compact and weakly compact sets in Banach
spaces, as they are relevant for the direct methods, is given in the Appendix of [2].
Prominent examples of reﬂexive Banach spaces are Hilbert spaces (see Chap. 18),
the Lebesgue spaces Lp for 1 < p < ∞, and the corresponding Sobolev spaces
W m,p, m = 1, 2, . . . , 1 < p < ∞.
Accordingly, we decide to use mainly reﬂexive Banach spaces for the direct
methods, whenever this is possible. Then, with the help of Lemma 33.2, we always
get weakly convergent minimizing sequences whenever we can show that bounded
minimizing sequences exist. Thus, the problem of lower semicontinuity of the func-
tional f for the weak topology remains. This is unfortunately not a simple problem.
Suppose we consider a functional of the form (32.2) and, according to the growth
restrictions on the integrand F, we decide to work in a Sobolev space E = W 1,p(Ω)
or in a closed subspace of this space, Ω ⊆Rd open. Typically, the restrictions on F,
which assure that f is well deﬁned on E, imply that f is continuous (for the norm
topology). However, the question when such a functional is lower semicontinuous
for the weak topology is quite involved, nevertheless a fairly comprehensive answer
is known (see [3]). Under certain technical assumptions on the integrand F the func-
tional f is lower semicontinuous for the weak topology on E = W 1,p(Ω) if, and

514
33
Direct Methods in the Calculus of Variations
only if, for (almost) all (x, u) ∈Ω × Rm the function y #→F(x, u, y) is convex (if
m = 1), respectively quasiconvex (if m > 1).
Though in general continuity of a functional for the norm topology does not
imply its continuity for the weak topology, there is a large and much used class of
functionals where this implication holds. This is the class of convex functionals and
for this reason convex minimization is relatively easy. We prepare the proof of this
important result with a lemma.
Lemma 33.3 Let E be a Banach space and M a weakly (sequentially) closed subset.
A function f : M →R is (sequentially) lower semicontinuous on M for the weak
topology if, and only if, the sublevel sets [f ≤r] are weakly (sequentially) closed
for every r ∈R.
Proof We give the proof explicitly for the case of sequential convergence. For the
general case one proceeds in the same way using nets.
Letf beweaklysequentiallylowersemicontinuousandforsomer ∈Rlet(xn)n∈N
be a sequence in [f ≤r] which converges weakly to some point x ∈M (since M
is weakly sequentially closed). By Lemma 33.1 we know f (x) ≤lim infn→∞f (xn)
and therefore f (x) ≤r, i.e., x ∈[f ≤r]. Therefore, [f ≤r] is closed.
Conversely assume that all the sublevel sets [f ≤r], r ∈R, are weakly
sequentially closed. Suppose f is not weakly sequentially lower semicontinu-
ous on M. Then there is a weakly convergent sequence (xn) ⟨⊂⟩M with limit
x ∈M such that lim infn→∞f (xn) < f (x). Choose a real number r such that
lim infn→∞f (xn) < r < f (x). Then there is a subsequence yj = xn(j) ⊂[f ≤r].
This subsequence too converges weakly to x and, since [f ≤r] is weakly se-
quentially closed, we know x ∈[f ≤r], a contradiction. We conclude that f is
sequentially lower semicontinuous for the weak topology.
2
Lemma 33.4 Let E be a Banach space, M a convex closed subset and f : M →R
a continuous convex function. Then f is lower semicontinuous on M for the weak
topology.
Proof Because f is continuous (for the norm topology) the sublevel sets [f ≤r],
r ∈R, are all closed. Since f is convex these sublevel sets are convex subsets of
E (x, y ∈[f ≤r], 0 ≤t ≤1 ⇒f (tx + (1 −t)y) ≤tf (x) + (1 −t)f (y) ≤
tr + (1 −t)r = r). As in Hilbert spaces one knows that a convex subset is closed
if, and only if, it is weakly closed. We deduce that all the sublevel sets are weakly
closed and conclude by Lemma 33.3.
2
As a conclusion to this section we present a summary of our discussion in the form
of two explicit results on the existence of a minimizer in reﬂexive Banach spaces.
Theorem 33.3 (Generalized Weierstraß Theorem I) A weakly sequentially lower
semicontinuous function f attains its inﬁmum on a bounded and weakly sequentially
closed subset M of a real reﬂexive Banach space E, i.e., there is x0 ∈M such that
f (x0) = inf
x∈M f (x).

33.3
Minimization of Special Classes of Functionals
515
Proof All the sublevel sets [f ≤r], r ∈R, are bounded and therefore relatively
weakly compact since we are in a reﬂexive Banach space (see Lemma 33.2). Now
Lemma 33.3 implies that all hypotheses of Theorem 33.1 are satisﬁed. Thus we
conclude by this theorem.
2
In Theorem 33.3, one can replace the assumption that the set M is bounded by an
assumption on the function f which implies that the sublevel sets of f are bounded.
Then one obtains another generalized Weierstraß theorem.
Theorem 33.4 (Generalized Weierstraß Theorem II) Let E be a reﬂexive Banach
space, M ⊂E a weakly (sequentially) closed subset, and f : M →R a weakly
(sequentially) lower semicontinuous function on M. If f is coercive, i.e., if ∥x∥→∞
implies f (x) →+∞, then f has a ﬁnite minimum on M, i.e., there is a x0 ∈M
such that
f (x0) = inf
x∈M f (x).
Proof Since f is coercive the sublevel sets [f ≤r] are not empty for sufﬁciently
large r and are bounded. We conclude as in the previous result.
2
For other variants of generalized Weierstraß theorems we refer to [4]. Detailed
results on the minimization of functionals of the form (32.2) can be found in [5–7].
33.3
Minimization of Special Classes of Functionals
For a self-adjoint compact operator A in the complex Hilbert space H consider the
sesquilinear function Q : H × H →C deﬁned by Q(x, y) = ⟨x, Ay⟩+ r⟨x, y⟩
for r = ∥A∥+ c for some c > 0. This function has the following properties:
Q(x, x) ≥c ∥x∥2 for all x ∈H and for ﬁxed x ∈H the function y #→Q(x, y)
is weakly continuous (since a compact operator maps weakly convergent sequences
onto norm convergent ones). Then f (x) = Q(x, x) is a concrete example of a
quadratic functional on H which has a unique minimum on closed balls Br of H. This
minimization is actually a special case of the following result on the minimization
of quadratic functionals on reﬂexive Banach spaces.
Theorem 33.5 (Minimization of Quadratic Forms) Let E be a reﬂexive Banach
space and Q a symmetric sesquilinear form on E having the following properties:
There is a constant c > 0 such that Q(x, x) ≥c ∥x∥2 for all x ∈E and for ﬁxed
x ∈E the functional y #→Q(x, y) is weakly continuous on E. Then, for every
u ∈E′ and every r > 0, there is exactly one point x0 = x0(u, r) which minimizes the
functional
f (x) = Q(x, x) −Re u(x),
x ∈E
on the closed ball Br = {x ∈E : ∥x∥≤r}, i.e.,
f (x0) = inf
x∈Br f (x).

516
33
Direct Methods in the Calculus of Variations
Proof Consider x, y ∈E and 0 < t < 1, then a straightforward calculation gives
f (tx+(1−t)y) = tf (x)+(1−t)f (y)−t(1−t)Q(x−y, x−y) < tf (x)+(1−t)f (y).
for all x, y ∈E, x ̸= y, since then t(1−t)Q(x −y, x −y) > 0, hence the functional
f is strictly convex and thus has at most one minimizing point by Theorem 33.2.
Suppose a sequence (xn)n∈N in E converges weakly to x0 ∈E. Since Q(xn, xn) =
Q(x0, x0) + Q(x0, xn −x0) + Q(xn −x0, x0) + Q(xn −x0, xn −x0) and since Q is
strictly positive it follows that
Q(xn, xn) ≥Q(x0, x0) + Q(xn −x0, x0) + Q(x0, xn −x0)
for all n ∈N. Since Q is symmetric and weakly continuous in the second argument
the last two terms converge to 0 as n →∞and this estimate implies
lim inf
n→∞Q(xn, xn) ≥Q(x0, x0).
Therefore, the function x #→Q(x, x) is weakly lower semicontinuous, thus, for
every u ∈E′, x #→f (x) = Q(x, x) −Re u(x) is weakly lower semicontinuous on
E and we conclude by Theorem 33.3. (Observe that the closed balls Br are weakly
closed, as closed convex sets.)
2
Corollary 33.1 Let A be a bounded symmetric operator in complex Hilbert space
H which is strictly positive, i.e., there is a constant c > 0 such that ⟨x, Ax⟩≥c⟨x, x⟩
for all x ∈H. Then, for every y ∈H the function x #→f (x) = ⟨x, Ax⟩−Re ⟨y, x⟩
has a unique minimizing point x0 = x0(y, r) on every closed ball Br, i.e., there is
exactly one x0 ∈Br such that
f (x0) = inf
x∈Br f (x).
Proof Using the introductoryremarktothissection oneveriﬁeseasilythatQ(x, y) =
⟨x, Ay⟩satisﬁes the hypothesis of Theorem 33.5.
2
33.4
Exercises
1. Prove Lemma 33.1.
2. Show without the use of Lemma 33.3 that the norm ∥·∥on a Banach space E is
weakly lower semicontinuous.
Hints: Recall that ∥x0∥= supu∈E′, ||u||′≤1 |u(x0)| for x0 ∈E. If a sequence (xn)n∈N
converges weakly to x0, then for every u ∈E′ one knows u(x0) = limn→∞u(xn).
3. Prove: The functional
f (u) =
 1
0
(tu′(t))2 d t,
deﬁned on all continuous functions on [0, 1] which have a weak derivative u′ ∈
L2(0, 1) and which satisfy u(0) = 0 and u(1) = 1, has 0 as inﬁmum and there is
no function in this class at which the inﬁmum is attained.

References
517
4. On the space E = C1([ −1, 1], R) deﬁne the functional
f (u) =
 1
−1
(tu′(t))2 d t
and show that it has no minimum under the boundary conditions u( ± 1) = ±1.
Hint: This variation of the previous problem is due to Weierstraß. Show ﬁrst that
on the class of functions uε, ε > 0, deﬁned by
uε(x) = arctan x
ε
arctan 1
ε
,
the inﬁmum of f is zero.
References
1. Lieb E, Loss M. Analysis. Graduate studies in mathematics, vol 14. 2nd ed. Providence:
American Mathematical Society; 2001.
2. Blanchard Ph, Brüning E. Variational methods in mathematical physics. A uniﬁed approach.
Texts and monographs in physics. Berlin: Springer; 1992.
3. Dacorogna B.Weak continuity and weak lower semicontinuity of non-linear functionals. Lecture
notes in mathematics, vol 922. Berlin: Springer; 1982.
4. Zeidler E. Variational methods and optimization. Nonlinear functional analysis and its
applications, vol 3. New York: Springer; 1985.
5. Dacorogna B. Direct methods in the calculus of variations. Applied mathematical sciences,
vol 78. Berlin: Springer; 1989.
6. Jost J, Li-Jost X. Calculus of variations. Cambridge studies in advanced mathematics, vol 64.
Cambridge: Cambridge University Press; 1998.
7. Struwe M. Variational methods: applications to nonlinear partial differential equations and
Hamiltonian systems. Ergebnisse der Mathematik und ihrer Grenzgebiete, Folge 3, vol 34.
3rd ed. Berlin: Springer; 2000.

Chapter 34
Differential Calculus on Banach Spaces
and Extrema of Functions
As is well known from calculus on ﬁnite-dimensional Euclidean spaces, the behavior
of a sufﬁciently smooth function f in a neighborhood of some point x0 is determined
by the ﬁrst few derivatives f (n)(x0), n ≤m, of f at this point, m ∈N depending on
f and the intended accuracy. For example, if f is a twice continuously differentiable
real-valued function on the open interval Ω ⊂R and x0 ∈Ω, the Taylor expansion
of order 2
f (x) = f (x0) + f (1)(x0)(x −x0) + 1
2!f (2)(x0)(x −x0)2 + (x −x0)2R2(x, x0)
(34.1)
with limx→x0 R2(x, x0) = 0 is available, and on the basis of this representation the
values of f (1)(x0) and f (2)(x0) determine whether x0 is a critical point of the function
f , or a local minimum, or a local maximum, or an inﬂection point.
In variational problems too, one has to determine whether a function f has crit-
ical points, local minima or maxima or inﬂection points, but in these problems the
underlying spaces are typically inﬁnite-dimensional Banach spaces. Accordingly an
expansion of the form (34.1) in this inﬁnite-dimensional case can be expected to be
an important tool too. Obviously one needs differential calculus on Banach spaces
to achieve this goal.
Recall that differentiability of a real-valued function f on an open interval Ω at
a point x0 ∈Ω is equivalent to the existence of a proper tangent to the graph of
the function through the point (x0, f (x0)) ∈R2. A proper tangent means that the
difference between the values of the tangent and of the function f at a point x ∈Ω
is of higher order in x −x0 than the linear term. Since the tangent has the equation
y(x) = f (1)(x0)(x −x0) + f (x0) this approximation means
f (x) −y(x) = f (x) −f (1)(x0)(x −x0) −f (x0) = o(x −x0),
(34.2)
where o is some function on R with the properties o(0) = o and limh→0,h̸=0
o(h)
h . In
the case of a real-valued function of several variables, the tangent plane takes the role
of the tangent line. As we are going to show, this way to look at differentiability has
a natural counterpart for functions deﬁned on inﬁnite-dimensional Banach spaces.
© Springer International Publishing Switzerland 2015
519
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_34

520
34
Differential Calculus on Banach Spaces and Extrema of Functions
34.1
The Fréchet Derivative
Let E, F be two real Banach spaces with norms ∥·∥E and ∥·∥F, respectively. As
usual L(E, F) denotes the space of all continuous linear operators from E into F.
By Theorem 22.2, the space L(E, F) is a real Banach space too. The order symbol
o denotes any function E →F which is of higher than linear order in its argument,
i.e., any function satisfying
o(0) = 0,
lim
h→0, h∈E\ {0}
∥o(h)∥F
∥h∥E
= 0.
(34.3)
Deﬁnition 34.1 Let U ⊂E be a nonempty open subset of the real Banach space E
and f : U →F a function from U into the real Banach space F. f is called Fréchet
differentiable at a point x0 ∈U if, and only if, there is an ℓ∈L(E, F) such that
f (x) = f (x0) + ℓ(x −x0) + o(x0; x −x0)
∀x ∈U.
(34.4)
If f is differentiable at x0 ∈U the continuous linear operator ℓ∈L(E, F) is called
the derivative of f at x0 and is denoted by
f ′(x0) ≡Dx0f ≡Df (x0) ≡ℓ.
(34.5)
If f is differentiable at every point x0 ∈U, f is called differentiable on U and the
function Df : U →L(E, F) which assigns to every point x0 ∈U the derivative
Df (x0) of f at x0 is called the derivative of the function f .
If the derivative Df : U →L(E, F) is continuous, the function f is called
continuously differentiable on U or of class C1, also denoted by f ∈C1(U, F).
This deﬁnition is indeed meaningful because of the following
Lemma 34.1
Under the assumptions of Deﬁnition 34.1 there is at most one ℓ∈
L(E, F) satisfying Eq. (34.4).
Proof Suppose there are ℓ1, ℓ2 ∈L(E, F) satisfying Eq. (34.4). Then, for all h ∈Br
where Br denotes an open ball in E with center 0 and radius r > 0 such that x0+Br ⊂
U, we have f (x0) + ℓ1(h) + o1(x0, h) = f (x0 + h) = f (x0) + ℓ2(h) + o2(x0, h),
and hence the linear functional ℓ= ℓ2 −ℓ1 satisﬁes ℓ(h) = o1(x0, h) −o2(x0, h)
for all h ∈Br. A continuous linear operator can be of higher than linear order on an
open ball only if it is the null operator (see Exercises). This proves ℓ= 0 and thus
uniqueness.
2
Deﬁnition 34.1 is easy to apply. Suppose f : U →F is constant, i.e., for some
a ∈F we have f (x) = a for all x ∈U ⊂E. Then f (x) = f (x0) for all x, x0 ∈U
and with the choice of ℓ= 0 ∈L(E, F) condition (34.4) is satisﬁed. Thus, f is
continuously Fréchet differentiable on U with derivative zero.
As another simple example consider the case where E is some real Hilbert space
with inner product ⟨·, ·⟩and F = R. For a continuous linear operator A : E →E
deﬁne a function f : E →R by f (x) = ⟨x, Ax⟩for all x ∈E. For x, h ∈E we

34.1
The Fréchet Derivative
521
calculate f (x +h) = f (x)+⟨A∗x +Ax, h⟩+f (h). h #→⟨A∗x +Ax, h⟩is certainly
a continuous linear functional E →R and f (h) = o(h) is obviously of higher than
linear order (actually second order) in h. Hence, f is Fréchet differentiable on E
with derivative f ′(x) ∈L(E, R) given by f ′(x)(h) = ⟨A∗x + Ax, h⟩for all h ∈E.
In the Exercises, the reader will be invited to show that the above deﬁnition of dif-
ferentiability reproduces the well-known deﬁnitions of differentiability for functions
of ﬁnitely many variables.
The Fréchet derivative has all the properties which are well known for the
derivative of functions of one real variable. Indeed the following results hold.
Proposition 34.1 Let U ⊂E be an open nonempty subset of the Banach space E
and F some other real Banach space.
a) The Fréchet derivative D is a linear mapping C1(U, F) →C(U, F), i.e., for all
f , g ∈C1(U, F) and all a, b ∈R one has
D(af + bg) = aDf + bDg.
b) The chain rule holds for the Fréchet derivative D: Let V ⊂F be an open set
containing f (U) and G a third real Banach space. Then for all f ∈C1(U, F)
and all g ∈C1(V , G) we have g ◦f ∈C1(U, G) and for all x ∈U
D(g ◦f )(x) = (Dg)(f (x)) ◦(Df )(x).
Proof The proof of the ﬁrst part is left as an exercise.
Since f is differentiable at x ∈U we know
f (x + h) −f (x) = f ′(x)(h) + o1(h)
∀h ∈Br,
x + Br ⊂U
and similarly, since g is differentiable at y = f (x) ∈V ,
g(y + k) −g(y) = g′(y)(k) + o2(k)
∀k ∈Bρ,
y + Bρ ⊂V.
Since f is continuous one can ﬁnd, for the radius ρ > 0 in the differentiability con-
dition for g, a radius r > 0 such that f (Br) ⊆Bρ and such that the differentiability
condition for f holds. Then, for all h ∈Br, the following chain of identities holds,
taking the above differentiability conditions into account:
g ◦f (x + h) −g ◦f (x) = g[f (x + h)] −g[f (x)]
= g[f (x) + f ′(x)(h) + o1(h)] −g[f (x)]
= g′(y)(f ′(x)(h) + o1(h)) + o2(f ′(x)(h) + o1(h))
= g′(y)(f ′(x)(h)) + o(h),
where
o(h) = g′(y)(o1(h)) + o2(f ′(x)(h) + o1(h))
is indeed a higher order term as shown in the Exercises. Thus, we conclude.
2

522
34
Differential Calculus on Banach Spaces and Extrema of Functions
Higher order derivatives can be deﬁned in the same way. Suppose E, F are two real
Banach spaces and U ⊂E is open and nonempty. Given a function f ∈C1(U, F)
we know f ′ ∈C(U, L(E, F)), i.e., the derivative is a continuous function on U with
values in the Banach space L(E, F). If this function f ′ is differentiable at x0 ∈U
(on U), the function f is called twice differentiable at x0 ∈U (on U) and is denoted
by
D2f (x0) = f (2)(x0) = D2
x0f ≡D(f ′)(x0).
(34.6)
According to Deﬁnition 34.1 and Eq. (34.6), the second derivative of f : U →
F is a continuous linear operator E →L(E, F), i.e., an element of the space
L(E, L(E, F)). There is a natural isomorphism of the space of continuous linear
operators from E into the space of continuous linear operators from E into F and
the space B(E × E, F) of continuous bilinear operators from E × E into F,
L(E, L(E, F)) ∼= B(E × E, F).
(34.7)
This natural isomorphism is deﬁned and studied in the Exercises. Thus, the second
derivative D2f (x0) at a point x0 ∈U is considered as a continuous bilinear map
E × E →F. If the second derivative D2f : U →B(E × E, F) exists on U and is
continuous, the function f is said to be of class C2 and we write f ∈C2(U, F).
The derivatives of higher order are deﬁned in the same way. The derivative of order
n ≥3 is the derivative of the derivative of order n −1, according to Deﬁnition 34.1:
Dnf (x0) = D(Dn−1f )(x0).
(34.8)
In order to describe Dnf (x0) conveniently we extend the isomorphism (34.7) to
higher orders. Denote by E×n = E × · · · × E (n factors) and by B(E×n, F) the
Banach space of all continuous n-linear operators E×n →F. In the Exercises, one
shows for n = 3, 4, . . .
L(E, B(E×n−1, F)) ∼= B(E×n, F).
(34.9)
Under this isomorphism the third derivative at some point x0 ∈U is then a continuous
3-linear map E×3 →F, D3f (x0) ∈B(E×3, F). Using the isomorphisms (34.9), the
higher order derivatives are
Dnf (x0) ∈B(E×n, F)
(34.10)
if they exist. If Dnf : U →B(E×n, F) is continuous the function f is called n-times
continuously differentiable or of class Cn. Then we write f ∈Cn(U, F).
As an illustration we calculate the second derivative of the function f (x) =
⟨x, Ax⟩on a real Hilbert space E with inner product ⟨·, ·⟩, A a bounded linear operator
onE. TheﬁrstFréchetderivativehasbeencalculated, f ′(x0)(h) = ⟨(A+A∗)x0, y⟩for
all y ∈E. In order to determine the second derivative we evaluate f ′(x0+h)−f ′(x0).
For all y ∈E one ﬁnds through a simple calculation
(f ′(x0 + h) −f ′(x0))(y) = ⟨(A + A∗)h, y⟩.
Hence, the second derivative of f exists and is given by the continuous bilinear form
(D2f )(x0)(y1, y2) = ⟨(A + A∗)y1, y2⟩, y1, y2 ∈E. We see in this example that the

34.1
The Fréchet Derivative
523
second derivative is actually a symmetric bilinear form. With some effort this can be
shown for every twice differentiable function.
As we have mentioned, the ﬁrst few derivatives of a differentiable function f :
U →F at a point x0 ∈U control the behavior of the function in a sufﬁciently small
neighborhood of this point. The key to this connection is the Taylor expansion with
remainder. In order to be able to prove this fundamental result in its strongest form
we need the fundamental theorem of calculus for functions with values in a Banach
space. And this in turn requires the knowledge of the Riemann integral for functions
on the real line with values in a Banach space.
Suppose E is a real Banach space and u : [a, b] →E a continuous function on
the bounded interval [a, b]. In Section 27.2 on the integration of spectral families,
we had introduced partitions Z of the interval [a, b]. Roughly, a partition Z of the
interval [a, b] is an ordered family of points a = t0 < t1 < t2 < · · · < tn = b
and of some points t′
j ∈(tj−1, tj], j = 1, . . . , n. For each partition we introduce the
approximating sums
Σ(u, Z) =
n

j=1
u(t′
j)(tj −tj−1).
By forming the joint reﬁnement of two partitions one shows, as in Sect. 26.2 on the
integration of spectral families, the following result: Given ε > 0 there is δ > 0 such
that
--Σ(u, Z) −Σ(u, Z′)
--
E < ε
for all partitions Z, Z′ with |Z′|, |Z| < δ, |Z| = max

tj −tj−1 : j = 1, . . . , n

.
This estimate implies that the approximating sums Σ(u, Z) have a limit with respect
to partitions Z with |Z| →0.
Theorem 34.1 Suppose E is a real Banach space and u : [a, b] →E a continuous
function. Then u has an integral over this ﬁnite interval, deﬁned by the following
limit in E:
 b
a
u(t) d t = lim
|Z|→0 Σ(u, Z).
(34.11)
This integral of functions with values in a Banach space has the standard properties,
i.e., it is linear in the integrand, additive in the interval of integration, and is bounded
by the maximum of the function multiplied by the length of the integration interval:
----
 b
a
u(t) d t
----
E
≤(b −a) max
a≤t≤b ∥u(t)∥E .
Proof It is straightforward to verify that the approximating sums Σ(u, Z) are linear
in u and additive in the interval of integration. The basic rules of calculation for limits

524
34
Differential Calculus on Banach Spaces and Extrema of Functions
then prove the statements for the integral. For the estimate observe
∥Σ(u, Z)∥E ≤
n

j=1
||u(t′
j)||E(tj −tj−1) ≤sup
a≤t≤b
∥u(t)∥E
n

j=1
(tj −tj−1),
which implies the above estimate for the approximating sums. Thus we conclude.
2
Corollary 34.1 (Fundamental Theorem of Calculus) Let E be a real Banach
space, [a, b] a ﬁnite interval and u : [a, b] →E a continuous function. For some
e ∈E deﬁne a function v : [a, b] →E by
v(t) = e +
 t
a
u(s) d s
∀s ∈[a, b].
(34.12)
Then v is continuously differentiable with derivative v′(t) = u(t) and one thus has
for all a ≤c < d ≤b,
v(d) −v(c) =
 d
c
v′(t) dt.
(34.13)
Proof
We prove differentiability of v at some interior point t ∈(a, b). At the
end points of the interval the usual modiﬁcations apply. Suppose τ > 0 such that
t + τ ∈[a, b]. Then, by deﬁnition of v,
v(t + τ) −v(t) =
 t+τ
a
u(s) d s −
 t
a
u(s) d s =
 t+τ
t
u(s) d s
since
 t+τ
a
u(s) d s =
 t
a
u(s) d s +
 t+τ
t
u(s) d s.
The basic bound for integrals gives
----
 t+τ
t
[u(s) −u(t)]ds
----
E
≤τ
sup
t≤s≤t+τ
∥u(s) −u(t)∥E
and thus proves that this integral is of higher order in τ. We deduce v(t + τ) =
v(t)+τu(t)+o(τ) and conclude that v is differentiable att with derivative v′(t) = u(t).
The rest of the proof is standard.
2
Theorem 34.2 (Taylor Expansion with Remainder) Suppose E, F are real Ba-
nach spaces, U ⊂E an open and nonempty subset, and f ∈Cn(U, F). Given
x0 ∈U choose r > 0 such that x0 + Br ⊂U, where Br is the open ball in E
with center 0 and radius r. Then for all h ∈Br we have, using the abbreviation
(h)k = (h, . . . , h), k terms,
f (x0 + h) =
n

k=0
1
k!f (k)(x0)(h)k + Rn(x0; h),
(34.14)

34.1
The Fréchet Derivative
525
where the remainder Rn has the form
Rn(x0; h) =
1
(n −1)!
 1
0
(1 −t)n−1[f (n)(x0 + th) −f (n)(x0)](h)n d t
(34.15)
and thus is of order o((h)n), i.e.,
lim
h→0,h∈E\{0}
∥Rn(x0; h)∥F
∥h∥n
E
= 0.
Proof Basically theTaylor formula is obtained by applying the fundamental theorem
of calculus repeatedly (n times) and transforming the multiple integral which is
generated in this process by a change of the integration order into a one-dimensional
integral.
However, there is a simpliﬁcation of the proof based on the following observation
(see [1]). Let v be a function on [0, 1] which is n times continuously differentiable,
then
d
d t
n−1

k=0
(1 −t)k
k!
v(k)(t) = (1 −t)n−1
(n −1)! v(n)(t)
∀t ∈[0, 1].
The proof of this identity follows simply by differentiation and grouping terms
together appropriately.
Integrate this identity for the function v(t) = f (x0 + th). Since f ∈Cn(U, F) the
application of the chain rule yields for h ∈Br,
v(k)(t) = f (k)(x0 + th)(h)k
and thus the result of this integration is, using Eq. (34.13),
f (x0 + h) =
n−1

k=0
1
k!f (k)(x0)(h)k + R
with remainder
R =
1
(n −1)!
 1
0
(1 −t)n−1f (n)(x0 + th)(h)n d t
which can be written as
R = 1
n!f (n)(x0)(h)n +
1
(n −1)!
 1
0
(1 −t)n−1[f (n)(x0 + th) −f (n)(x0)](h)n d t.
The differentiability assumption for f implies that the function h #→f (n)(x0 + th)
from Br into B(E×n, F) is continuous, hence
--[f (n)(x0 + th) −f (n)(x0)]
--
B(E×n,F) →0
as h →0. Thus we conclude.
2

526
34
Differential Calculus on Banach Spaces and Extrema of Functions
34.2
Extrema of Differentiable Functions
Taylor’s formula (34.14) says that a function f : U →F of class Cn is approximated
at each point of a neighborhood of some point x0 ∈U by a polynomial of degree n,
and the error is of order o((x −x0)n). We apply now this approximation for n = 2 to
characterize local extrema of a function of class C2 in terms of the ﬁrst and second
derivative of f . We begin with the necessary deﬁnitions.
Deﬁnition 34.2
Let E be a real Banach space, M ⊆E a nonempty subset, and
f : M →R a real valued function on M. A point x0 ∈M is called a local minimum
(maximum) of f on M if there is some r > 0 such that
f (x0) ≤f (x),
(f (x0) ≥f (x))
∀x ∈M ∩(x0 + Br).
A local minimum (maximum) is strict if
f (x0) < f (x),
(f (x0) > f (x))
∀x ∈M ∩(x0 + Br),
x ̸= x0.
If f (x0) ≤f (x), (f (x0) ≥f (x)) holds for all x ∈M, we call x0 a global minimum
(maximum).
Deﬁnition 34.3
Suppose E, F are two real Banach spaces, U ⊂E an open
nonempty subset, and f : U →F a function of class C1. A point x0 ∈U is called
a regular (critical) point of the function f if, and only if, the Fréchet derivative
Df (x0) of f at x0 is surjective (not surjective).
Remark 34.1
For the case F = R the Fréchet derivative Df (x0) = f ′(x0) ∈
L(E, R) is not surjective, if and only if, f ′(x0) = 0; hence, the notion of a critical
point introduced above is nothing else than the generalization of the corresponding
notion introduced in elementary calculus.
For extremal points which are interior points of the domain M of the function f
a fairly detailed description can be given. In this situation, we can assume that the
domain M = U is an open set.
Theorem 34.3 (Necessary Condition of Euler–Lagrange) Suppose U is an open
nonempty subset of the real Banach space E and f ∈C1(U, R). Then every extremal
point (i.e., every local or global minimum and every local or global maximum) is a
critical point of f .
Proof Suppose that x0 ∈U is a local minimum of f . Then there is an r > 0 such
that x0+Br ⊂U and f (x0) ≤f (x0+h) for all h ∈Br. Since f ∈C1(U, R) Taylor’s
formula applies, thus
f (x0) ≤f (x0 + h) = f (x0) + f ′(x0)(h) + R1(x0, h)
∀h ∈Br
or
0 ≤f ′(x0)(h) + R1(x0, h)
∀h ∈Br.
Choose any h ∈Br, h ̸= 0. Then all th ∈Br, 0 < t ≤1 and therefore 0 ≤
f ′(x0)(th)+R1(x0, th). Since limt→0 t−1R1(x0, th) = 0 we can divide this inequality

34.2
Extrema of Differentiable Functions
527
by t > 0 and take the limit t →0. This gives 0 ≤f ′(x0)(h). This argument applies
to any h ∈Br, thus in particular to −h and therefore 0 ≤f ′(x0)(−h) = −f ′(x0)(h).
We conclude that 0 = f ′(x0)(h) for all h ∈Br. The open nonempty ball Br absorbs
the points of E, i.e., every point x ∈E can be written as x = λh with some
h ∈Br and some λ ∈R. It follows that 0 = f ′(x0)(x) for all x ∈E and therefore
f ′(x0) = 0 ∈L(E, R) = E′.
If x0 ∈U is a local maximum of f , then this point is a local minimum of −f and
we conclude as above.
2
Theorem 34.4 (Necessary and Sufﬁcient Conditions for Local Extrema) Sup-
pose U ⊂E is a nonempty open subset of the real Banach space E and f ∈
C2(U, R).
a) If f has a local minimum at x0 ∈U, then the ﬁrst Fréchet derivative of f vanishes
at x0, f ′(x0) = 0, and the second Fréchet derivative of f is nonnegative at x0,
f (2)(x0)(h, h) ≥0 for all h ∈E.
b) If conversely f ′(x0) = 0 and if the second Fréchet derivative of f is strictly
positive at x0, i.e., if inf

f (2)(x0)(h, h) : h ∈E, ∥h∥E = 1

= c > 0, then f has
a local minimum at x0.
Proof Suppose x0 ∈U is a local minimum of f . Then by Theorem 34.3 f ′(x0) = 0.
Since f ∈C2(U, R) Taylor’s formula implies
f (x0) ≤f (x0 + h) = f (x0) + 1
2!f (2)(x0)(h, h) + R2(x0, h)
∀h ∈Br (34.16)
for some r > 0 such that x0 + Br ⊂U. Choose any h ∈Br. Then for all 0 < t ≤1
we know 0 ≤1
2!f (2)(x0)(th, th) + R2(x0, th) or, after division by t2 > 0.
0 ≤f (2)(x0)(h, h) + 2
t2 R2(x0, th)
∀0 < t ≤1.
Since R2(x0, th) is a higher order term we know t−2R2(x0, th) →0 as t →0.
This gives 0 ≤f (2)(x0)(h, h) for all h ∈Br and since open balls are absorbing,
0 ≤f (2)(x0)(h, h) for all h ∈E. This proves part (a).
Conversely assume that f ′(x0) = 0 and that f (2)(x0) is strictly positive. Choose
r > 0 such that x0 + Br ⊂U. The second-order Taylor expansion gives
f (x0 + h) −f (x0) = 1
2!f (2)(x0)(h, h) + R2(x0, h)
∀h ∈Br,
and thus for all h ∈E with ∥h∥E = 1 and all 0 < s < r,
f (x0 + sh) −f (x0) = 1
2!f (2)(x0)(sh, sh) + R2(x0, sh)
= s2[ 1
2!f (2)(x0)(h, h) + s−2R2(x0, sh)].
Since R2(x0, sh) is a higher order term there is an s0
∈
(0, r) such that
|s−2R2(x0, sh)| < c/2 for all 0 < s ≤s0, and since 1
2!f (2)(x0)(h, h) ≥c/2 for all

528
34
Differential Calculus on Banach Spaces and Extrema of Functions
h ∈E, ∥h∥E = 1, we get [ 1
2!f (2)(x0)(h, h) + s−2R2(x0, sh)] ≥0 for all 0 < s < s0
and all h ∈E, ∥h∥E = 1. It follows that f (x0 + h) −f (x0) ≥0 for all h ∈Bs0 and
therefore the function f has a local minimum at x0.
2
As we mentioned before a function f has a local maximum at some point x0 if,
and only if, the function −f has a local minimum at this point. Therefore, Theorem
34.4 easily implies necessary and sufﬁcient conditions for a local maximum.
34.3
Convexity and Monotonicity
We begin with the discussion of an interesting connection between convexity of a
functional and monotonicity of its ﬁrst Fréchet derivative which has far-reaching
implications for optimization problems. For differentiable real-valued functions of
one real variable these results are well known.
The following theorem states this connection in detail and provides the relevant
deﬁnitions.
Theorem 34.5 (Convexity–Monotonicity) Let U be a convex open subset of the
real Banach space E and f
∈C1(U, R). Then the following statements are
equivalent:
a) f is convex, i.e., for all x, y ∈U and all 0 ≤t ≤1 one has
f (tx + (1 −t)y) ≤tf (x) + (1 −t)f (y)
(34.17)
b) The Fréchet derivative f ′ : E →E′ is monotone, i.e., for all x, y ∈U one has
⟨f ′(x) −f ′(y), x −y⟩≥0,
(34.18)
where ⟨·, ·⟩denotes the canonical bilinear form on E′ × E.
Proof If f is convex inequality (34.17) implies, for x, y ∈U and 0 < t ≤1,
f (y + t(x −y)) −f (y) ≤tf (x) + (1 −t)f (y) −f (y) = t(f (x) −f (y)).
If we divide this inequality by t > 0 and then take the limit t →0 the result is
⟨f ′(y), x −y⟩≤f (x) −f (y).
If we exchange the roles of x and y in this argument, we obtain
⟨f ′(x), y −x⟩≤f (y) −f (x).
Now add the two inequalities to get
⟨f ′(y), x −y⟩+ ⟨f ′(x), y −x⟩≤0,
thus condition (34.18) follows and therefore f ′ is monotone.

34.3
Convexity and Monotonicity
529
Suppose conversely that the Fréchet derivative f ′ : E →E′ is monotone. For
x, y ∈U and 0 ≤t ≤1 consider the function p : [0, 1] →R deﬁned by p(t) =
f (tx +(1−t)y)−tf (x)−(1−t)f (y). This function is differentiable with derivative
p′(t) = ⟨f ′(x(t)), x −y⟩−f (x) + f (y), x(t) = tx + (1 −t)y, and satisﬁes
p(0) = 0 = p(1). The convexity condition is equivalent to the condition p(t) ≤0
for all t ∈[0, 1]. We prove this condition indirectly. Thus, we assume that there is
some point in (0, 1) at which p is positive. Then there is some point t0 ∈(0, 1) at
which p attains its positive maximum. For t ∈(0, 1) calculate
(t −t0)(p′(t) −p′(t0)) = (t −t0)⟨f ′(x(t)) −f ′(x(t0)), x −y⟩
= ⟨f ′(x(t)) −f ′(x(t0)), x(t) −x(t0)⟩.
Since f ′ is monotone it follows that (t −t0)(p′(t) −p′(t0) ≥0. Since p attains
its maximum at t0, p′(t0) = 0, and thus (t −t0)p′(t) ≥0, hence p′(t) ≥0 for all
t0 < t ≤1, a contradiction. We conclude p(t) ≤0 and thus condition (34.17).
2
Corollary 34.2 Let U be a nonempty convex open subset of the real Banach space
E and f ∈C1(U, R). If f is convex, then every critical point of f is actually a
minimizing point , i.e., a point at which f has a local minimum.
Proof If x0 ∈U is a critical point, there is an r > 0 such that x0 + Br ⊂U. Then
for every h ∈Br the points x(t) = x0 + th, 0 ≤t ≤1, belong to x0 + Br. Since f
is differentiable we ﬁnd
f (x0 + h) −f (x0) =
 1
0
d
d t f (x(t)) d t =
 1
0
⟨f ′(x(t)), h⟩d t.
Since x(t) −x0 = th the last integral can be written as
= lim
ε↓0
 1
ε
⟨f ′(x(t)) −f ′(x0), x(t) −x0⟩d t
t .
Theorem 34.5 implies that the integrand of this integral is nonnegative, hence f (x0 +
h)−f (x0) ≥0 for all h ∈Br and f has a local minimum at the critical point x0.
2
Corollary 34.3 Let U be a nonempty convex open subset of the real Banach space
E and f ∈C1(U, R). If f is convex, then f is weakly lower semicontinuous.
Proof Suppose that a sequence (xn)n∈N ⊂U converges weakly to x0 ∈U. Again
differentiability of f implies
f (xn) −f (x0) =
 1
0
d
d t f (x0 + t(xn −x0))dt =
 1
0
⟨f ′(x0 + t(xn −x0)), xn −x0⟩d t
=
 1
0
⟨f ′(x0 + t(xn −x0)) −f ′(x0), xn −x0⟩d t + ⟨f ′(x0), xn −x0⟩.

530
34
Differential Calculus on Banach Spaces and Extrema of Functions
As in the proof of the previous corollary, monotonicity of f ′ implies that the integral
is not negative, hence
f (xn) −f (x0) ≥⟨f ′(x0), xn −x0⟩.
As n →∞the right-hand side of this estimate converges to 0 and thus lim inf f (xn)−
f (x0) ≥0 or lim infn→∞f (xn) ≥f (x0). This shows that f is weakly lower
semicontinuous at x0. Since x0 ∈U was arbitrary, we conclude.
2
Corollary 34.4 Let U be a nonempty convex open subset of the real Banach space
E and f ∈C2(U, R). Then f is convex if, and only if, f (2)(x0) is nonnegative for all
x0 ∈U, i.e., f (2)(x0)(h, h) ≥0 for all h ∈E.
Proof
By Theorem 34.5 we know that f is convex if, and only if, its Fréchet
derivative f ′ is monotone. Suppose f ′ is monotone and x0 ∈U. Then there is an
r > 0 such that x0 + Br ⊂U and ⟨f ′(x0 + h) −f ′(x0), h⟩≥0 for all h ∈Br. Since
f ∈C2(U, R), Taylor’s Theorem implies that
⟨f ′(x0 + h) −f ′(x0), h⟩= f (2)(x0)(h, h) + R2(x0, h),
hence
0 ≤f (2)(x0)(h, h) + R2(x0, h)
∀h ∈Br.
Since R2(x0, h) = o((h)2) we deduce, as in the proof of Theorem 34.4, that 0 ≤
f (2)(x0)(h, h) for all h ∈E. Thus f (2) is nonnegative at x0 ∈U.
Conversely assume that f (2) is nonnegative on U. For x, y ∈U we know
⟨f ′(x) −f ′(y), x −y⟩=
 1
0
f (2)(y + t(x −y))(x −y, x −y) d t.
By assumption the integrand is nonnegative, and it follows that f ′ is monotone.
2
34.4
Gâteaux Derivatives and Variations
For functions f : Rn →R one has the concepts of the total differential and that of
partial derivatives. The Fréchet derivative has been introduced as the generalization
of the total differential to the case of inﬁnite-dimensional Banach spaces. Now we
introduce the Gâteaux derivatives as the counterpart of the partial derivatives.
Deﬁnition 34.4
Let E, F be two real Banach spaces, U ⊆E a nonempty open
subset, and f : U →F a mapping from U into F. The Gâteaux differential of f
at a point x0 ∈U is a mapping δf (x0, ·) : E →F such that, for all h ∈E,
lim
t→0,t̸=0
1
t (f (x0 + th) −f (x0)) = δf (x0, h).
(34.19)

34.4
Gâteaux Derivatives and Variations
531
δf (x0, h) is called the Gâteaux differential of f at the point x0 in the direction
h ∈E. If the Gâteaux differential of f at x0 is a continuous linear map E →F, one
writes
δf (x0, h) = δx0f (h)
and calls δx0f the Gâteaux derivative of f at the point x0.
Basic properties of the Gâteaux differential, respectively derivative, are collected
in the following
Lemma 34.2 Let E, F be two real Banach spaces, U ⊆E a nonempty open subset,
and f : U →F a mapping from U into F.
a) If the Gâteaux differential of f exists at a point x0 ∈U, it is a homogeneous map
E →F, i.e., δf (x0, λh) = λδf (x0, h) for all λ ∈R and all h ∈E;
b) If the Gâteaux derivatives exist at a point x ∈U, they are linear in f , i.e., for
f , g : U →F and α, β ∈R one has δx(αf + βg) = αδxf + βδxg;
c) If f is Gâteaux differentiable at a point x ∈U, then f is continuous at x in every
direction h ∈E;
d) Suppose G is a third real Banach space, V ⊆F a nonempty open subset such
that f (U) ⊆V and g : V →G a mapping from V into G. If f has a Gâteaux
derivative at x ∈U and g has a Gâteaux derivative at y = f (x), then g ◦f :
U →G has a Gâteaux derivative at x ∈U and the chain rule
δx(g ◦f ) = δyg ◦δxf
holds.
Proof Parts (a) and (b) follow easily from the basic rules of calculation for limits.
Part (c) is obvious from the deﬁnitions. The proof of the chain rule is similar but
easier than the proof of this rule for the Fréchet derivative and thus we leave it as an
exercise.
2
The following result establishes the important connection between Fréchet and
Gâteaux derivatives, as a counterpart of the connection between total differential and
partial derivatives for functions of ﬁnitely many variables.
Lemma 34.3 Let E, F be two real Banach spaces, U ⊆E a nonempty open subset,
and f : U →F a mapping from U into F.
a) If f is Fréchet differentiable at a point x ∈U, then f is Gâteaux differentiable
at x and both derivatives are equal: δxf = Dxf .
b) Suppose that f is Gâteaux differentiable at all points in a neighborhood V of
the point x0 ∈U and that x #→δxf ∈L(E, F) is continuous on V . Then f is
Fréchet differentiable at x0 and δx0f = Dx0f .
Proof If f is Fréchet differentiable at x ∈U we know, for all h ∈E, f (x + th) =
f (x) + (Dxf )(th) + o(th), hence
lim
t→0
1
t (f (x + th) −f (x)) = (Dxf )(h) + lim
t→0
o(th)
t
= (Dxf )(h),

532
34
Differential Calculus on Banach Spaces and Extrema of Functions
and part (a) follows.
If f is Gâteaux differentiable in the neighborhood V of x0 ∈U, there is an
r > 0 such that f is Gâteaux differentiable at all points x0 + h, h ∈Br. Given
h ∈Br it follows that g(t) = f (x0 + th) is differentiable at all points t ∈[0, 1] and
g′(t) = (δx0+thf )(h). This implies
g(1) −g(0) =
 1
0
g′(t) d t =
 1
0
(δx0+thf )(h) d t
and thus
f (x0 + h) −f (x0) −(δx0f )(h) = g(1) −g(0) −(δx0f )(h)
=
 1
0
[(δx0+thf )(h) −(δx0f )(h)] d t.
The integral can be estimated in norm by
sup
0≤t≤1
--(δx0+thf ) −(δx0f )
--
L(E,F) ∥h∥E
and therefore
--f (x0 + h) −f (x0) −(δx0f )(h)
--
F ≤sup
0≤t≤1
--(δx0+thf ) −(δx0f )
--
L(E,F) ∥h∥E .
Continuity of (δxf ) in x ∈x0 + Br implies f (x0 + h) −f (x0) −(δx0f )(h) = o(h)
and thus f is Fréchet differentiable at x0 and (Dx0f )(h) = (δx0f )(h) for all h ∈Br
and therefore for all h ∈E.
2
Lemma 34.3 can be very useful in ﬁnding the Fréchet derivative of functions. We
give a simple example. On the Banach space E = Lp(Rn), 1 < p < 2, consider the
functional
f (u) =

Rn |u(x)|p d x,
∀u ∈E.
To prove directly that f is continuously Fréchet differentiable on E is not so simple.
If, however, Lemma 34.3 is used the proof becomes a straightforward calculation.
We only need to verify the hypotheses of this lemma. In the Exercises the reader is
asked to show that there are constants 0 < c < C < ∞such that
c|s|p ≤|1 + s|p −1 −ps ≤C|s|p
∀s ∈R.
Insert s = t h(x)
u(x), for all points x ∈Rn with u(x) ̸= 0 and multiply with |u(x)|p. The
result is
c|th(x)|p ≤|u(x) + th(x)|p −|u(x)|p −pth(x)|u(x)|p−1sgn(u(x)) ≤C|th(x)|p.
Integration of this inequality gives
c|t|pf (h) ≤f (u + th) −f (u) −pt

Rn h(x)v(x) d x ≤C|t|pf (h),

34.4
Gâteaux Derivatives and Variations
533
where
v(x) = |u(x)|p−1sgn(u(x)).
Note that v ∈Lq(Rn), 1
q + 1
p = 1 and that Lq(Rn) is (isomorphic to) the topological
dual of E = Lp(Rn). This estimate allows us to determine easily the Gâteaux
derivative of f :
δf (u, h) = lim
t→0
1
t [f (u + th) −f (u)] = p

Rn v(x)h(x) d x.
Hölder’s inequality implies that the absolute value of this integral is bounded by
∥v∥q ∥h∥p, hence h #→δf (u, h) is a continuous linear functional on E and
∥δuf ∥L(E,R) = ∥v∥q = ∥u∥p/q
p
.
Therefore, u #→δuf is a continuous map from E →L(E, R) and Lemma 34.3
implies that f is Fréchet differentiable with derivative Duf (h) = δuf (h).
Suppose that M is a nonempty subset of the real Banach space E which is not
open, for instance M has a nonempty interior and part of the boundary of M belongs
to M. Suppose, furthermore, that a function f : M →R attains a local minimum at
the boundary point x0. Then we cannot investigate the behavior of f in terms of the
ﬁrst few Fréchet or Gâteaux derivatives of f at the point x0 as we did previously since
this required that a whole neighborhood of x0 is contained in M. In such situations
the variations of the function in suitable directions are a convenient tool to study the
local behavior of f .
Assumethath ∈E andthatthereissomer = rh > 0 suchthatx(t) = x0+th ∈M
for all 0 ≤t < r. Then we can study the function fh(t) = f (x(t)) on the interval
[0, r). Certainly, if f has a local minimum at x0, then fh(0) ≤fh(t) for all t ∈[0, r)
(if necessary we can decrease the value of r) and this gives restrictions on the ﬁrst
few derivatives of fh, if they exist. These derivatives are then called the variations
of f .
Deﬁnition 34.5 Let M ⊂E be a nonempty subset of the real Banach space E and
x0 ∈M. For h ∈E suppose that there is an r > 0 such that x0 + th ∈M for all
0 ≤t < r. Then the nth variation of f in the direction h is deﬁned as
△nf (x0, h) = d n
d tn f (x0 + th)|t=0
n = 1, 2, . . .
(34.20)
if these derivatives exist.
In favorable situations obviously the ﬁrst variation is just the Gâteaux derivative:
Lemma 34.4
Suppose that M is a nonempty subset of the real Banach space E,
x0 an interior point of M, and f a real valued function on M. Then the Gâteaux
derivative δx0f of f at x0 exists if, and only if, the ﬁrst variation △f (x0, h) exists
for all h ∈E and h #→△f (x0, h) is a continuous linear functional on E.
In this case, one has △f (x0, h) = δx0f .
Proof A straightforward inspection of the respective deﬁnitions easily proves this
lemma.
2

534
34
Differential Calculus on Banach Spaces and Extrema of Functions
34.5
Exercises
1. Complete the proof of Lemma 34.1.
2. Let E and F be two real normed spaces and A : E →F a continuous linear
operator such that Ax = o(x) for all x ∈E, |x| < 1. Prove: A = 0.
3. For a function f : U →Rm, U ⊂Rn open, assume that it is differentiable at a
point x0 ∈U. Use Deﬁnition 34.1 to determine the Fréchet derivative f ′(x0) of
f at x0 and relate it to the Jabobi matrix ∂f
∂x (x0) of f at x0.
4. Prove part (a) of Proposition 34.1.
5. Prove that o(h) = g′(y)(o1(h)) + o2(f ′(x)(h) + o1(h)) is a higher order term,
under the assumptions of Proposition 34.1, part (b).
6. Let I = [a, b] be some ﬁnite closed interval. Equip the space E = C1(I, R) of
all continuously differentiable real valued functions (one-sided derivatives at the
end points of the interval) with the norm
∥u∥I,1 = sup

|uj)(t)| : t ∈I, j = 0, 1

.
Under this norm E = C1(I, R) is a Banach space. For a given continuously
differentiable function F : I × R × R →R, deﬁne a function f : E →R by
f (u) =
 b
a
F(t, u(t), u′(t)) d t
and show that f is Fréchet differentiable on E. Show in particular
f ′(u)(v) =
 b
a
[F,u(t, u(t), u′(t)) −d
d t F,u′(t, u(t), u′(t))]v(t) d t
+ F,u′(t, u(t), u′(t))v(t)|b
a
for all v ∈E. F,u denotes the derivative of F with respect to the second argument
andsimilarly, F,u′ denotesthepartialderivativewithrespecttothethirdargument.
Now consider M = {u ∈E : u(a) = c, u(b) = d} for some given values c, d ∈
R and show that the derivative of the restriction of f to M is
f ′(u)(v) =
 b
a
[F,u(t, u(t), u′(t)) −d
d t F,u′(t, u(t), u′(t))]v(t) d t
(34.21)
for all v ∈E, v(a) = 0 = v(b). Deduce the Euler–Lagrange equation
F,u(t, u(t), u′(t)) −d
d t F,u′(t, u(t), u′(t)) = 0.
(34.22)
Hint: Use the Taylor expansion with remainder for F and the arguments for the
proof of Theorem 3.2.
7. Suppose that E, F are two real Banach spaces. Prove the existence of the natural
isomorphism L(E, L(E, F)) ∼= B(E × E, F).

Reference
535
Hint: For h ∈L(E, L(E, F)) deﬁne Hath ∈B(E × E, F) by ˆh(e1, e2) =
h(e1)(e2) for all e1.e2 ∈E and for b ∈B(E × E, F) let us deﬁne ˇb ∈
L(E, L(E, F)) by ˇb(e1)(e2) = b(e1, e2) and then show that these mappings are in-
verse to each other. Write the deﬁnition of the norms of the spaces L(E, L(E, F))
and B(E ×E, F) explicitly and show that the mappings h #→ˆh and b #→ˇb both
have a norm ≤1.
8. Prove the existence of the natural isomorphism (34.9) for n = 2, 3, 4, . . . .
9. Prove the chain rule for the Gâteaux derivative.
10. Complete the proof of part (d) of Lemma 34.3.
11. Let V be a function R3 →R of class C1. Find the Euler–Lagrange equation
(34.22) explicitly for the functional I(u) =
 b
a ( m
2 (u′(t))2 −V (u(t))) d t on dif-
ferentiable functions u : [a, b] →R3, u(a) = x, u(b) = y for given points
x, y ∈R3.
12. Consider the function g(s) = |1+s|p−1−ps
|s|p
, s ∈R\ {0}, and show g(s) →1 as
|s| →∞, g(s) →0 as s →0. Conclude that there are constants 0 < c < C <
∞such that c|s|p ≤g(s)|s|p ≤C|s|p for all s ∈R.
Reference
1. Dewitt-Morette C, Dillard-Bleick M, Choquet-Bruhat Y. Analysis, manifolds and physics.
Amsterdam: North-Holland; 1982.

Chapter 35
Constrained Minimization Problems (Method
of Lagrange Multipliers)
In the calculus of variations we have often to do with the following problem: Given
a real valued function f on a nonempty open subset U of a real Banach space
E, ﬁnd the minimum (maximum) of f on all those points x in U which satisfy a
certain restriction or constraint. A very important example of such a constraint is
that the points have to belong to a level surface of some function g, i.e., have to
satisfy g(x) = c where the constant c distinguishes the various level surfaces of the
function g. In elementary situations, and typically also in Lagrangian mechanics,
one introduces a so-called Lagrange multiplier λ as a new variable and proceeds to
minimize the function f (·) + λ(g(·) −c) on the set U. In simple problems (typically
ﬁnite dimensional) this strategy is successful. The problem is the existence of a
Lagrange multiplier.
As numerous successful applications have shown the following setting is an
appropriate framework for such constrained minimization problems:
Let E, F be two real Banach spaces, U ⊆E an open nonempty subset, g : U →F a
mapping of class C1, f : U →R a function of class C1, and y0 some point in F. The
optimization problem for the function f under the constraint g(x) = y0 is the problem of
ﬁnding extremal points of the function f|M : M →R where M = [g = y0] is the level
surface of g through the point y0.
In this chapter we present a comprehensive solution for the inﬁnite dimensional
case, mainly based on ideas of Ljusternik [1]. A ﬁrst section explains in a simple
setting the geometrical interpretation of the existence of a Lagrange multiplier. As
an important preparation for the main results the existence of tangent spaces to level
surfaces of C1-functions is shown in substantial generality. Finally the existence of
a Lagrange multiplier is proven and some simple applications are discussed.
In the following chapter, after the necessary preparations, we will use the results
on the existence of a Lagrange multiplier to solve eigenvalue problems, for linear
and nonlinear partial differential operators.
© Springer International Publishing Switzerland 2015
537
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_35

538
35
Constrained Minimization Problems (Method of Lagrange Multipliers)
[f = d1]
[g = c]
[f = d0]
[g = c]
[f = d2]
[g = c]
Fig. 35.1 Level surface [g = c] and [f = di], i = 0, 1, 2; d1 < d0 < d2; i = 1 two points of
intersection, i = 0 touching level surfaces; i = 2 no intersection
35.1
Geometrical Interpretation of Constrained Minimization
In order to develop some intuition about constrained minimization problems and
the rôle of the Lagrange multiplier we consider such a problem ﬁrst on a space
of dimension two and discuss heuristically in geometrical terms how to obtain the
solution. Let U ⊂R2 be a nonempty open subset. Our goal is to determine the
minimum of a continuous function f : U →R under the constraint g(x) = c
where the constraint function g : U →R is continuous. This means: Find x0 ∈U
satisfying g(x0) = c and f (x0) ≤f (x) for all x ∈U such that g(x) = c. In
this generality the problem does not have a solution. If however both f and g are
continuously differentiable on U, then the level surfaces of both functions have well-
deﬁned tangents, and then we expect a solution to exist, because of the following
heuristic considerations.
Introduce the level surface
[g = c] = {x ∈U : g(x) = c}
and similarly the family of level surfaces [f = d], d ∈R, for the function f . If a
level surface [f=d] does not intersect the level surface [g=c], then no point on this
level surface of f satisﬁes the constraint and is thus not relevant for our problem. If
for a certain value of d the level surfaces [f=d] and [g =c] intersect in exactly one
point (at some ﬁnite angle), then for all values d′ close to d the level surfaces [g = c]
and [f = d′] also intersect at exactly one point, and thus d is not the minimum
of f under the constraint g(x) = c. Next consider a value of d for which the level
surfaces [g = c] and [f = d] intersect in at least two distinct points (at ﬁnite angles).
Again for all values d′ sufﬁciently close to d the level surfaces [f = d′] and [g = c]
intersect in at least two distinct points and therefore d is not the minimum of f
under the given constraint. Finally consider a value d0 for which the level surfaces
[g = c] and [f = d0] “touch” in exactly one point x0, i.e., [g=c] ∩[f = d0] = {x0}
and the tangents to both level surfaces at this point coincide. In this situation small
changes of the value of d lead to an intersection which is either empty or consists
of at least two points, hence these values d′ ̸= d0 do not produce a minimum under
the constraint g(x) = c. We conclude that d0 is the minimum value of f under the
given constraint and that x0 is the minimizing point. The following ﬁgure shows in
a two dimensional problem three of the cases discussed above (Fig. 35.1). Given the
level surface [g =c] of the constraint function g, three different level surfaces of the
function f are considered.

35.2
Tangent Spaces of Level Surfaces
539
Consider the level surfaces [g = c] and [f = d] of smooth functions g, f over an
open set U ⊂R2. Assume (or prove under appropriate assumptions with the help of
the implicit function theorem) that in a neighborhood of the point x0 = (x0
1, x0
2) these
level surfaces have the explicit representation x2 = y(x1), respectively x2 = ξ(x1).
Under these assumptions it is shown in the Exercises that the tangent to these touching
level surfaces coincide if, and only if, for some λ ∈R ∼= L(R, R)
(Df )(x0) = λ(Dg)(x0) .
(35.1)
35.2
Tangent Spaces of Level Surfaces
In our setting a constraint minimization problem is a problem of analysis on level
surfaces of C1 mappings. It requires that we can do differential calculus on these
surfaces which in turn relies on the condition that these level surfaces are differen-
tial manifolds. The following approach does not assume this but works under the
hypothesis that one has, at the points of interest on these level surfaces, the essential
element of a differential manifold, namely a proper tangent space.
Recall that in inﬁnite dimensional Banach spaces E a closed subspace K does
not always have a topological complement, i.e., a closed subspace L such that E is
the direct sum of these two subspaces (see for instance [2]). Thus in our fundamental
result on the existence of a proper tangent space this property is assumed but later
we will show when and how it holds.
Theorem 35.1 (Existence of a Tangent Space) Let E, F be real Banach spaces,
U ⊆E a nonempty open subset, and g : U →F a mapping of class C1. Suppose
that x0 is a point of the level surface [g = y0] of the mapping g. If x0 is a regular
point of g at which the null-space N(g′(x0)) of the derivative of g has a topological
complement in E, then the set
Tx0[g = y0] =

x ∈E : ∃u ∈N(g′(x0)), x = x0 + u

= x0 + N(g′(x0))
(35.2)
is a proper tangent space of the level surface [g = y0] at the point x0, i.e., there is a
homeomorphism χ of a neighborhood U ′ of x0 in Tx0[g = y0] onto a neighborhood
V of x0 in [g = y0] with the following properties:
a) χ(x0 + u) = x0 + u + ϕ(u) for all x0 + u ∈U ′;
b) ϕ is continuous and of higher than linear order in u, ϕ(u) = o(h).
Proof Since x0 is a regular point of g, the derivative g′(x0) is a surjective continuous
linear mapping from E onto F. By assumption the null-space K = N(g′(x0)) of the
mapping has a topological complement L in E so that the Banach space E is the
direct sum of these two closed subspaces, E = K + L. It follows (see [2]) that there
are continuous linear mappings p and q of E onto K and L, respectively, which have
the following properties: K = ran p = N(q), L = N(p) = ran q, p2 = p, q2 = q,
p + q = id.

540
35
Constrained Minimization Problems (Method of Lagrange Multipliers)
Since U is open there is r > 0 such that the open ball Br in E with center 0 and
radius r satisﬁes x0+Br +Br ⊂U. Now deﬁne a mapping ψ : K∩Br ×L∩Br →F
by
ψ(u, v) = g(x0 + u + v)
∀u ∈K ∩Br,
∀v ∈L ∩Br.
(35.3)
By the choice of the radius r this map is well deﬁned. The chain rule implies that it
has the following properties: ψ(0, 0) = g(x0) = y0, ψ is continuously differentiable
and
ψ,u(0, 0) = g′(x0)|K = 0 ∈L(K, F),
ψ,v(0, 0 = g′(x0)|L ∈L(L, F).
On the complement L of its null-space the surjective mapping g′(x0) : E →F
is bijective, thus ψ,v(0, 0) is a bijective continuous linear mapping of the Banach
space L onto the Banach space F. The inverse mapping theorem (see Appendix
34.5) implies that the inverse ψ,v(0, 0)−1 : F →L is a continuous linear operator
too. Thus all hypotheses of the implicit function theorem (see, for example, [3]) are
satisﬁed for the problem
ψ(u, v) = y0.
This theorem implies that there is 0 < δ < r and a unique function ϕ : K ∩Bδ →L
which is continuously differentiable such that
y0 = ψ(u, ϕ(u))
∀u ∈K ∩Bδ
and
ϕ(0) = 0.
Since in general ϕ′(0) = −ψ,v(0, 0)−1 ψ,u(0, 0) we have here ϕ′(0) = 0 and thus
ϕ(u) = o(u).
Deﬁne a mapping χ : x0 + K ∩Bδ →M by χ(x0 + u) = x0 + u + ϕ(u). Clearly
χ is continuous. By construction, y0 = ψ(u, ϕ(u)) = g(x0 + u + ϕ(u)), hence χ
maps into M = [g = y0]. By construction, u and ϕ(u) belong to complementary
subspaces of E, therefore χ is injective and thus invertible on
V = {x0 + u + ϕ(u) : u ∈K ∩Bδ} ⊂M.
Its inverse is χ−1(x0 + u + ϕ(u)) = x0 + u. Since ran p = K and N(p) = L the
inverse can be represented as
χ−1(x0 + u + ϕ(u)) = x0 + p(u + ϕ(u))
and this shows that χ−1 is continuous too. Therefore χ is a homeomorphism from
U ′ = x0 + K ∩Bδ onto V ⊂M. This concludes the proof.
2
Apart from the natural assumption about the regularity of the point x0 this theorem
uses the technical assumption that the nullspace K = N(g′(x0)) of g′(x0) ∈L(E, F)
has a topological complement in E. We show now that this assumption is quite
adequate for the general setting by proving that it is automatically satisﬁed for three
large and frequent classes of special cases.

35.3
Existence of Lagrange Multipliers
541
Proposition 35.1
Let E, F be real Banach spaces and A : E →F a surjective
continuous linear operator. The nullspace K = N(A) has a topological complement
in E, in the following three cases:
a) E is a Hilbert space;
b) F is a ﬁnite dimensional Banach space;
c) N(A) is ﬁnite dimensional, for instance A : E →F is a Fredholm operator
(i.e., an operator with ﬁnite dimensional null-space and closed range of ﬁnite
codimension).
Proof
If K is a closed subspace of the Hilbert space E, the projection theorem
guarantees existence of the topological complement L = K⊥and thus proves Part
a).
If F is a ﬁnite dimensional Banach space, there exist linearly independent vectors
e1, . . ., em ∈E such that {f1 = Ae1, . . ., fm = Aem} is a basis of F. The vectors
e1, . . ., em generate a linear subspace V of E of dimension m and it follows that
A now is represented by Ax = m
j=1 aj(x)fj with continuous linear functionals
aj : E →R. Deﬁne px = m
j=1 aj(x)ej and qx = x −px. One proves easily that
p2 = p, q2 = q, p + q = id, V = pE and that both maps are continuous. Thus
V = pE is the topological complement of N(A) = qE. This proves b).
Suppose {e1, . . ., em} is a basis of N(A). There are continuous linear functionals
aj on E such that ai(ej) = δij for i, j = 1, . . ., m. (Use the Hahn–Banach theorem).
As above deﬁne px = m
j=1 aj(x)ej and qx = x −px for all x ∈E. Now we
conclude as in Part b). (See the Exercises)
2
Corollary 35.1
Suppose that E, F are real Banach spaces, U ⊂E a nonempty
open set and g : U →F a map of class C1. In each of the three cases mentioned in
Proposition 35.1 for A = g′(x0) the tangent space of the level surface [g = y0] at
every regular point x0 ∈[g = y0] of g is given by Eq. (35.2).
Proof Proposition 35.1 ensures the hypotheses of Theorem 35.1.
2
35.3
Existence of Lagrange Multipliers
The results on the existence of the tangent spaces of level surfaces allow us to translate
the heuristic considerations on the existence of a Lagrange multiplier into precise
statements. The result which we present now is primarily useful for the explicit
calculation of the extremal points once their existence has been established, say as a
consequence of the direct methods discussed earlier.
Theorem 35.2 (Existence of Lagrange Multipliers) Let E, F be real Banach
spaces, U ⊂E open and nonempty, g : U →F and f : U →R of class C1.
Suppose that f has a local extremum at the point x0 ∈U subject to the constraint
g(x) = y0 = g(x0). If x0 is a regular point of the map g and if the null-space

542
35
Constrained Minimization Problems (Method of Lagrange Multipliers)
K = N(g′(x0)) of g′(x0) has a topological complement L in E, then there exists a
continuous linear functional ℓ: F →R such that x0 is a critical point of the function
F = f −ℓ◦g : U →R, that is
f ′(x0) = ℓ◦g′(x0).
(35.4)
Proof The restriction H of g′(x0) to the topological complement L of its kernel K is
a continuous injective linear map from the Banach space L onto the Banach space F
since x0 is a regular point of g. The inverse mapping theorem (seeAppendix) implies
that H has an inverse H −1 which is a continuous linear operator F →L.
According to Theorem 35.1 the level surface [g = y0] has a proper tangent space
at x0. Thus the points x of this level surface, in a neighborhood V of x0, are given by
x = x0 + u + ϕ(u), u ∈K ∩Bδ where δ > 0 is chosen as in the proof of Theorem
35.1. Suppose that f has a local minimum at x0 (otherwise consider −f ). Then there
is an r ∈(0, δ) such that f (x0) ≤f (x0 + u + ϕ(u)) for all u ∈K ∩Br, hence by
Taylor’s theorem
0 ≤f ′(x0)(u) + f ′(x0)(ϕ(u)) + o(u + ϕ(u))
∀u ∈K ∩Br.
Since we know that ϕ(u) = o(u), this implies f ′(x0)(u) = 0 for all u ∈K ∩Br. But
u ∈K ∩Br is absorbing in K, therefore f ′(x0)(u) = 0 for all u ∈K, i.e.,
K = N(g′(x0)) ⊆N(f ′(x0)).
(35.5)
By assumption, E is the direct sum of the closed subspaces K, L, E = K + L.
Denote the canonical projections onto K and L by p respectively q. If x1, x2 ∈E
satisfy q(x1) = q(x2), then x1 −x2 ∈K and thus Eq. (35.5) implies f ′(x0)(x1) =
f ′(x0)(x2). Therefore a continuous linear functional ˆf ′(x0) : L →R is well deﬁned
by ˆf ′(x0)(qx) = f ′(x0)(x) for all x ∈E. This functional is used to deﬁne
ℓ= ˆf ′(x0) ◦H −1 : F →R
as a continuous linear functional on the Banach space F which satisﬁes Eq. (35.4),
since for every x ∈E
ℓ◦g′(x0)(x) = ℓ◦g′(x0)(qx) = ℓ◦H(qx) = ˆf ′(x0)(qx) = f ′(x0)(x).
We conclude that x0 is a critical point of the function F = f −ℓ◦g, by using the
chain rule.
2
To illustrate some of the strengths of this theorem we consider a simple example.
SupposeE is a real Hilbertspacewithinnerproduct ⟨·, ·⟩andAaboundedself-adjoint
operator on E. The problem is to minimize the function f (x) = ⟨x, Ax⟩under the
constraint g(x) = ⟨x, x⟩= 1. Obviously both functions are of class C1. Their
derivatives are given by f ′(x)(u) = 2⟨Ax, u⟩, respectively by g′(x)(u) = 2⟨x, u⟩for
all u ∈E. It follows that all points of the level surface [g = 1] are regular points
of g. Corollary 35.1 implies that Theorem 35.2 can be used to infer the existence of

35.3
Existence of Lagrange Multipliers
543
a Lagrange multiplier λ ∈R if x0 is a minimizing point of f under the constraint
g(x) = 1: f ′(x0) = λg′(x0) or Ax0 = λx0, i.e., the Lagrange multiplier λ is
an eigenvalue of the operator A and x0 is the corresponding normalized eigenvector.
This simple example suggests a strategy to determine eigenvalues of operators. Later
we will explain this powerful strategy in some detail, not only for linear operators.
InthecaseofﬁnitedimensionalBanachspacesweknowthatthetechnicalassump-
tions of Theorem 35.2 are naturally satisﬁed. In this theorem assume that E = Rn
and F = Rm. Every continuously linear functional ℓon Rm is characterized uniquely
by some m-tuple (λ1, . . ., λm) of real numbers. Explicitly Theorem 35.2 takes now
the form
Corollary 35.2
Suppose that U ⊂Rn is open and nonempty, and consider two
mappings f : U →R and g : U →Rm of class C1. Furthermore assume that the
function f attains a local extremum at a regular point x0 ∈U of the mapping g (i.e.,
the Jacobi matrix g′(x0) has maximal rank m) under the constraint g(x) = y0 ∈Rm.
Then there exist real numbers λ1, . . ., λm such that
∂f
∂xi
(x0) =
m

j=1
λj
∂gj
∂xi
(x0),
i = 1, . . ., n.
(35.6)
Note that Eq. (35.6) of Corollary 35.2 and the equation g(x0) = y0 ∈Rm give us
exactly n + m equations to determine the n + m unknowns (λ, x0) ∈Rm × U.
Theorem 35.2 can also be used to derive necessary and sufﬁcient conditions for
extremal points under constraints. For more details we have to refer to Chap. 4 of
the book [4].
35.3.1
Comments on Dido’s Problem
According to the brief discussion in the introduction to Part C Dido’s original prob-
lem is a paradigmatic example of constrained minimization. Though intuitively the
solution is clear (a circle where the radius is determined by the given length) a rigor-
ous proof is not very simple even with the help of the abstract results which we have
developed in this section. Naturally Dido’s problem and its solution have been dis-
cussed much in the history of the calculus of variations (see [5]). Weierstrass solved
this problem in his lectures in 1872 and 1879. There is also an elegant geometrical
solution based on symmetry considerations due to Steiner.
In the Exercises we invite the reader to ﬁnd the solution by two different methods.
The ﬁrst method suggests parametrizing the curve we are looking for by its arc length
and using Parseval’s relation in the Hilbert space H = L2([0, 2π]). This means
that we assume that this curve is given in parametric form by a parametrization
(x(t), y(t)) ∈R2, 0 ≤t ≤2π where x, y are differentiable functions satisfying
˙x(t)2 + ˙y(t)2 = 1 for all t ∈[0, 2π]. With this normalization and parametrization the
total length of the curve is L =
 2π
0

˙x(t)2 + ˙y(t)2 d t = 2π and the area enclosed

544
35
Constrained Minimization Problems (Method of Lagrange Multipliers)
by this curve is
A =
 2π
0
x(t) ˙y(t) d t.
Proposition 35.2
For all parametrizations of the form described above one has
A ≤π. Furthermore, A = π if, and only if, the curve is a circle of radius 1.
Proof See the Exercises.
2
The second approach uses the Lagrange multiplier method as explained above.
Suppose that the curve is to have the total length 2L0. Choose a parameter a such
that 2a < L0. In a suitable coordinate system the curve we are looking for is given
as y = u(x), −a ≤x ≤a, and u(x) ≥0, u( ± a) = 0 with a function u of class C1.
Its length is
 a
−a

1 + u′(x)2 d x = L(u) and the area enclosed by the x-axis and this
curve is A(u) =
 a
−a u(x) d x. The problem then is to determine u such that A(u) is
maximal under the constraint L(u) = L0.
Proposition 35.3
For the constrained minimization problem for A(u) under the
constraint L(u) = L0 there is a Lagrange multiplier λ satisfying
s
√
1+s2 =
a
λ for
some s ∈R and a solution u(x) = λ[

1 −( x
λ)2 −

1 −( a
λ)2], −a ≤x ≤a. One
has L0 = 2λθ(a) with θ(a) = arcsin a
λ ∈[0, π
2 ]. For this curve the area is
A(u) = λ2θ(a) −a

λ2 −a2.
Proof See the Exercises.
2
Since L0 = 2λ θ(a) the Lagrange multiplier λ is a function of a and hence one
can consider A(u) as a function of a. Now it is not difﬁcult to determine a so that the
enclosed area A(u) is maximal. For a = λ = L0
π this area is maximal and is given
by A(u) = a2π/2. This is the area enclosed by a half-circle of radius a = L0
π .
Remark 35.1 There is an interesting variation of Dido’s problem which has found
important applications in modern probability theory (see [6]) and which we mention
brieﬂy. Let A ⊂Rn be a bounded domain with a sufﬁciently smooth boundary and
for t > 0 consider the set
At =

x ∈Rn\A : ∥x −y∥≤t, ∀y ∈A

.
Now minimize the volume |At| of the set At under the constraint that the volume |A|
of A is ﬁxed. The answer is known: This minimum is attained when A is a ball in
Rn. This is of particular interest in the case of very high dimensions n →∞since
then it is known that practically the volume of At ∪A is equal to the volume of At.
For the proof of this result we refer to the book [7] and the article [8].

35.4
Exercises
545
35.4
Exercises
1. Let U ⊂R2 be open and nonempty. Suppose f , g ∈C1(U, R) have level surfaces
[g =c] and [f =d] which touch in a point x0 ∈U in which the functions f , g have
nonvanishing derivatives with respect to the second argument. Prove Eq. 35.1.
2. Prove in detail: A ﬁnite dimensional subspace V of a Banach space E has a
topological complement.
3. Prove Corollary 35.2.
4. Prove Proposition 35.2.
Hints: Use the Fourier expansion for x, y:
x(t) = a0
2 +
∞

k=1
(ak cos kt + bk sin kt)
y(t) = α0
2 +
∞

k=1
(αk cos kt + βk sin kt).
Calculate ˙x(t), ˙y(t) and calculate
 2π
0
[˙x(t)2 + ˙y(t)2] d t as
⟨˙x(t), ˙x(t)⟩2 + ⟨˙y(t), ˙y(t)⟩2
using ⟨cos kt, sin jt⟩2 = 0 and ⟨cos kt, cos kt⟩2 = ⟨sin kt, sin kt⟩2 = π. Similarly
one can calculate A = ⟨x, ˙y⟩2 = π ∞
k=1 k(akβk −bkαk). This gives
2π −2A = π
∞

k=1
(k2 −k)[a2
k +b2
k +α2
k +β2
k]+π
∞

k=1
k[(ak −βk)2 +(αk +bk)2].
Now it is straightforward to conclude.
5. Prove Proposition 35.3.
Hints: (1) Calculate the Fréchet derivative of the constraint functional L(u) and
show that all points of a level surface [L = L0] are regular points of the mapping
L, for 2a < L0. (2) Prove that |u(x)| ≤L(u) for all x ∈[−a, a] and hence
A(u) ≤2aL(u) = 2aL0. (3) Prove that A(u) is (upper semi-) continuous for
the weak topology on E = H 1
0 (−a, a). (4) Conclude that a maximizing element
u ∈E and a Lagrange multiplier λ exist. (5) Solve the differential equation
A′(u) = λL′(u) under the boundary condition u(−a) = u(a) = 0. (6) Calculate
L(u) for this solution and equate the result to L0. (7) Calculate the area A(u) for
this solution.
6. Another solution method for Dido’s problem: Suppose u(t) = (x(t), y(t)), 0 ≤
t ≤a is the parametrization of a closed differentiable curve in the plane.
a) Show that the length of the curve is given by ℓ(u) =
 a
0

˙x(t)2 + ˙y(t)2 d t
and the enclosed area by A(u) = 1
2
 a
0 (x(t) ˙y(t) −y(t)˙x(t)) d t. Then Dido’s
problem reads: Maximize A(u) under the constraint that the length ℓ(u) = L
has a given value.

546
35
Constrained Minimization Problems (Method of Lagrange Multipliers)
b) Introduce the Langrange function L(u, ˙u) = 1
2(x ˙y −y ˙x) + λ

˙x(t)2 + ˙y(t)2
with a Langrange multiplier λ to be determined later, corresponding to the
functional I(u) = A(u) + λℓ(u). Show that the Euler–Lagrange equations
d
dt
∂L
∂˙u = ∂L
∂u for this functional are
d
d t
$
−1
2y +
λ˙x

˙x(t)2 + ˙y(t)2
%
=
1
2 ˙y
d
d t
$
1
2x +
λ ˙y

˙x(t)2 + ˙y(t)2
%
=
−1
2 ˙x
c) Integrate this system and show that the solutions are circles of radius λ and
center (x0, y0) as integration constants. Then the Lagrange parameter λ is
determined by the condition that the curve has to have a given length ℓ(u) = L.
References
1. Ljusternik LA. On conditional extrema of functions. Mat Sbornik. 1934;41(3):390–401.
2. Robertson AP, Robertson WJ. Topological vector spaces. Cambridge: Cambridge University
Press; 1973.
3. Dieudonné JA. Foundations of modern analysis. New York: Academic; 1969.
4. Blanchard Ph, Brüning E. Variational methods in mathematical physics. A uniﬁed approach.
Texts and monographs in physics. Berlin: Springer-Verlag; 1992.
5. Goldstine HH. A history of the calculus of variations from the 17th through the 19th century.
Studies in the history of mathematics and physical sciences. vol. 5. NewYork: Springer-Verlag;
1980.
6. Ledoux M, Talagrand M. Probability in Banach spaces: isoperimetry and processes. Ergebnisse
der Mathematik und ihrer Grenzgebiete ; Folge 3. vol. 23. Berlin: Springer-Verlag; 1991.
7. Burago YD, Zalgaller VA. Geometric inequalities. Die Grundlehren der mathematischen
Wissenschaften in Einzeldarstellungen. vol. 285. Berlin: Springer-Verlag; 1988.
8. Osserman R. The isoperimetric inequality. Bull Am Math Soc. 1978;84:1182–1238.

Chapter 36
Boundary and Eigenvalue Problems
One of the ﬁrst areas in which variational concepts and methods have been applied
were linear boundary and eigenvalue problems. They can typically be solved in
concrete Hilbert spaces of functions. These and related problems will be the topic of
this chapter. Before we turn to these concrete problems, we discuss several abstract
minimization problems in Hilbert spaces, some of them have already been mentioned
in Part II on Hilbert spaces.
Inordertoprepareforthesolutionoflinearboundaryandeigenvalueproblems, the
connection of linear partial differential operators and quadratic forms is established
in Sect. 36.2. Since on a general level minimization of quadratic forms has been
well discussed, it is fairly easy then to solve these concrete boundary and eigenvalue
problems.
36.1
Minimization in Hilbert Spaces
According to our outline of the general strategy of the direct methods in the calculus
of variations, Hilbert spaces are well suited for problems of minimization since they
are spaces in which bounded sets are relatively compact for the weak topology.
Their additional geometric structure is often very helpful too. This advantage will be
evident from the following
Theorem 36.1 (Projection Theorem for Convex Sets) Suppose that K is a convex
closed subset of a Hilbert space H. Then, for any x ∈H, there is a unique u ∈K
which satisﬁes
∥x −u∥= inf
v∈K ∥x −v∥= d(x, K).
(36.1)
The element u ∈K is called the projection of x onto K: u = proj Kx. It is
characterized by the inequality
⟨x −u, v −u⟩≤0
∀v ∈K.
© Springer International Publishing Switzerland 2015
547
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_36

548
36
Boundary and Eigenvalue Problems
The mapping proj K : H →K deﬁned in this way is continuous, and one has
∥proj Kx −proj Ky∥≤∥x −y∥
∀x, y ∈H.
Proof
For ﬁxed x ∈H consider the function ψx : K →R deﬁned by ψx(z) =
∥x −z∥for all z ∈K. It is certainly continuous and as a small calculation shows
(see Exercises), strictly convex. Lemma 33.3 implies that ψx is weakly lower semi-
continuous on the closed convex and thus weakly closed convex set. Therefore, in
the case that K is bounded, Theorem 33.3 applies. If K is not bounded, then certainly
ψx is coercive, i.e., ψx(z) →∞as ∥z∥→∞, and thus Theorem 33.4 applies. In
both cases, we conclude that there is a point ux ∈K which minimizes ψx on K,
ψx(ux) = ∥x −ux∥= inf
z∈K ∥x −z∥.
The minimizing point is unique since ψx is strictly convex (Theorem 33.2). These
arguments apply to any x ∈H. Because x #→ux is one-to-one we get a well-deﬁned
map pK : H →K by
pK(x) =
⎧
⎨
⎩
ux,
x ∈H\K,
x,
x ∈K.
In order to prove the characteristic inequality for u = ux ∈K take any z ∈K. Since
K is convex tz + (1 −t)u ∈K and we know ∥x −u∥≤∥x −tz −(1 −t)u∥or
0 ≤∥x −u + t(u −z)∥2 −∥x −u∥2 = 2t⟨x −u, u −z⟩+ t2 ∥u −z∥2
for all 0 < t < 1. A standard argument implies ⟨x −u, u −z⟩≥0.
Conversely assume that u ∈K is a point for which this inequality holds for all
z ∈K. Then on the basis of this inequality we estimate as follows:
∥x −u∥2 = ⟨x −u, x −u⟩= ⟨x −u, x −z⟩+ ⟨x −u, x −u −(x −z)⟩
= ⟨x −u, x −z⟩+ ⟨x −u, z −u⟩≤⟨x −u, x −z⟩
= ⟨x −z, x −z⟩+ ⟨z −u, x −z⟩
≤∥x −z∥2 + ⟨z −u, x −u⟩−⟨z −u, z −u⟩≤∥x −z∥2 ,
hence ∥x −u∥≤∥x −z∥for all z ∈K and thus ∥x −u∥= infz∈K ∥x −z∥. We
conclude that the minimizing element ux = u is indeed characterized by the above
variational inequality.
Finally we prove Lipschitz continuity of the mapping pK. Given x, y ∈H denote
u = pK(x) and v = pK(y). Now apply the variational inequality ﬁrst for u and
z = v ∈K and then for v and z = u ∈K. This gives the two inequalities
⟨x −u, v −u⟩≤0,
⟨y −v, u −v⟩≤0

36.1
Minimization in Hilbert Spaces
549
which we add to get
⟨x −y + v −u, v −u⟩≤0
or
∥v −u∥2 ≤⟨y −x, v −u⟩≤∥y −x∥∥v −u∥,
and the estimate ∥v −u∥≤∥y −x∥follows, which is just the continuity estimate
and we conclude.
2
In Part II the spectral theory for compact operators (Riesz–Schauder theory, The-
orem 25.5) has been developed by using mainly Hilbert space intrinsic arguments.
We discuss this proof now as an application of the direct methods.
Let H be a separable Hilbert space and A ̸= 0 a self-adjoint compact operator on
H. Denote by B1 = {x ∈H : ∥x∥≤1} the closed unit ball of H and by S1 the unit
sphere of this space. Recall that the norm of the operator can be expressed as
∥A∥= sup
u∈B1
∥Au∥= sup
u∈S1
|⟨u, Au⟩|.
Thus, the calculation of the norm can be regarded as a problem of ﬁnding a
maximum of the function u #→∥Au∥on the closed unit ball B1 or of the function
u #→|⟨u, Au⟩| on the unit sphere S1. Since A is compact, it maps weakly conver-
gent sequences into norm convergent sequences and thus both functions are weakly
continuous. Since the closed unit ball B1 is weakly compact we can apply Theorem
33.3 and thus get a point e1 ∈B1 such that
∥A∥= ∥Ae1∥= sup
u∈B1
∥Au∥.
Since A ̸= 0 we know e1 ̸= 0 and thus ∥e1∥= 1 as a simple scaling argument
shows.
Consider the function f (u) = ⟨u, Au⟩on H. It is Fréchet differentiable with
derivative f ′(u)(x) = 2⟨Au, x⟩for all x ∈H. As we have shown above, this function
has a maximum on S1 given by
sup
u∈S1
f (u) = ± ∥A∥= ±f (e1).
The unit sphere S1 is the level surface [g = 1] of the constraint function g(x) = ⟨x, x⟩
on H which is Fréchet differentiable too, and its derivative is g′(u)(x) = 2⟨u, x⟩for
all x ∈H. Therefore, all points u ∈S1 are regular points of g. The results on
the existence of a Lagrange multiplier (Theorem 35.2 and Corollary 35.1) apply,
i.e., there is an λ1 ∈R such that f ′(e1) = λ1g′(e1) or Ae1 = λ1e1. It follows that
|λ1| = ∥A∥.
Then the proof is completed as it has been shown in Part B, Sect. 25.1. This
ends our remarks on the proof of the spectral theorem for compact operators as an
application of variational methods.
Theorem 25.5 establishes the existence and some of the properties of eigenvalues
of a compact self-adjoint operator. The above comments on the proof hint at a method

550
36
Boundary and Eigenvalue Problems
for calculating these eigenvalues. And indeed this method has been worked out in
full detail and leads to the classical minimax principle of Courant–Weyl–Fischer–
Poincaré–Rayleigh–Ritz.
Theorem 36.2 (Minimax Principle) Let H be a real separable Hilbert space and
A ≥0 a self-adjoint operator on H with spectrum σ(A) = {λm : m ∈N} ordered
according to size, λm ≤λm+1. For m = 1, 2, . . . denote by Em the family of all
m-dimensional subspaces Em of H. Then the eigenvalue λm can be calculated as
λm = min
Em∈Em max
v∈Em
⟨v, Av⟩
⟨v, v⟩.
(36.2)
Proof The proof is obtained by determining the lower bound for the values of the
Rayleigh quotient R(v) = ⟨v,Av⟩
⟨v,v⟩. In order to do this we expand every v ∈H in terms
of eigenvectors ej of A. This gives v = ∞
i=1 aiei and ⟨v, v⟩= ∞
i=1 a2
i . In this form
the Rayleigh quotient reads
R(v) =
∞
i=1 λia2
i
∞
i=1 a2
i
.
Denote by Vm the linear subspace generated by the ﬁrst m eigenvectors of A. It
follows that
max
v∈VmR(v) =
max
(a1,... ,am)∈Rm
m
i=1 λia2
i
m
i=1 a2
i
= λm = R(em),
and thus we are left with showing maxv∈EmR(v) ≥λm for every other subspace
Em ∈Em. Let Em ̸= Vm be such a subspace; then Em ∩V ⊥
m ̸= {0} and therefore
max
v∈EmR(v) ≥
max
v∈Em∩V ⊥
m
R(v).
Every v ∈Em ∩V ⊥
m is of the form v = 
i≥m+1 aiei and for such vectors we have
R(v) =

i≥m+1 λia2
i

i≥m+1 a2
i
≥λm+1 ≥λm.
This then completes the proof.
2
Theorem 36.2 implies for the smallest eigenvalue of the operator A the simple
formula
λ1 =
min
v∈E, v̸=0
⟨v, Av⟩
⟨v, v⟩.
(36.3)

36.2
The Dirichlet–Laplace Operator and Other Elliptic Differential Operators
551
36.2
The Dirichlet–Laplace Operator and Other Elliptic
Differential Operators
The goal of this section is to illustrate the application of the general strategy and the
results developed thus far. This is done by solving several relatively simple linear
boundary and eigenvalue problems. The typical example is the Laplace operator with
Dirichlet boundary conditions on a bounded domain Ω. Naturally, for these concrete
problems we have to use concrete function spaces, and we need to know a number
of basic facts about them. In this brief introduction, we have to refer the reader to
the literature for the proof of these facts. We recommend the books [1–3].
For a bounded domain Ω ⊂Rn with smooth boundary ∂Ω consider the real
Hilbert space L2(Ω) with inner product ⟨·, ·⟩2. Recall the deﬁnition of the Sobolev
space H 1(Ω) (see Chap. 13) as
H 1(Ω) =

u ∈L2(Ω) : ∂ju ∈L2(Ω), j = 1, . . ., n

.
(36.4)
Here naturally the partial derivatives ∂ju are understood in the weak (distributional)
sense. One shows that H 1(Ω) is a Hilbert space with the inner product
⟨u, v⟩= ⟨u, v⟩2 + ⟨Du, Dv⟩2
∀u, v ∈H 1(Ω)
(36.5)
where Du = (∂1u, . . ., ∂nu) and where in the second term the natural inner product of
L2(Ω)×n is used. This space is the Sobolev space W 1,2(Ω). Next deﬁne a subspace
of this space:
H 1
0 (Ω) = closure of D(Ω) in H 1(Ω).
(36.6)
Intuitively, H 1
0 (Ω) is the subspace of those u ∈H 1(Ω) whose restriction to the
boundary ∂Ω vanishes, u|∂Ω = 0.
The Sobolev space H 1(Ω) is by deﬁnition contained in the Hilbert space L2(Ω),
however, the following compact embeddings for 2 ≤n are of greater importance to
us,
H 1(Ω) →Lq(Ω),
1 ≤q < 2∗=
2n
n −2,
2 < n
(36.7)
and
H 1(Ω) →Lq(Ω),
1 ≤q < ∞,
2 = n.
(36.8)
This means that every weakly convergent sequence in H 1(Ω) converges strongly in
Lq(Ω). In addition we are going to use the important Sobolev inequality
∥u∥q ≤S ∥Du∥p = S
⎛
⎝
n

j=1
∥∂ju∥p
p
⎞
⎠
1/p
∀u ∈H 1(Ω),
(36.9)

552
36
Boundary and Eigenvalue Problems
where S is the Sobolev constant depending on q, n and where q is in the range
indicated in (36.7), respectively (36.8).
Now we are in the position to show that the famous Dirichlet problem has a
solution.
Theorem 36.3 (DirichletProblem)LetΩ ⊂Rn beaboundedopensetwithsmooth
boundary and v0 ∈H 1(Ω) some given element. Then the Dirichlet integral
f (v) =

Ω
|Dv(x)|2 d x =

Ω
n

j=1
|∂jv(x)|2 d x
(36.10)
is minimized on M = v0 + H 1
0 (Ω) by an element v ∈M satisfying
△v = 0
in Ω
and
v|∂Ω = v0|∂Ω.
(36.11)
Proof
Observe that f (u) = Q(u, u) with the quadratic functional Q(u, v) =
⟨Du, Dv⟩2. This quadratic form satisﬁes, because of inequality (36.9), the estimate
c ∥u∥2 ≤Q(u, u) ≤∥u∥2
for some c > 0. It follows that Q is a strictly positive continuous quadratic form
on H 1(Ω) and thus f is a strictly convex continuous function on this space (see the
proof of Theorem 33.5). We conclude, by Lemma 33.3 or Theorem 33.5, that f is
weakly lower semi-continuous on H 1(Ω).
As a Hilbert space, H 1
0 (Ω) is weakly complete and thus the set M = v0 + H 1
0 (Ω)
is weakly closed. Therefore, Theorem 33.4 applies and we conclude that there is a
minimizing element v for the functional f on M.
Since the minimizing element v ∈M satisﬁes f (v) = f (v0 + u) ≤f (v0 + w) for
all w ∈H 1
0 (Ω), we deduce as earlier that f ′(v)(w) = 0 for all w ∈H 1
0 (Ω) and thus
0 = f ′(v)(w) =

Ω
Dv(x) · Dw(x) d x
∀w ∈D(Ω).
Recalling the deﬁnition of differentiation in the sense of distributions, this means
−△v = 0 in the sense of D′(Ω). Now the Lemma of Weyl (see [2, 3]) implies that
−△v = 0 also holds in the classical sense, i.e., as an identity for functions of class
C2.
Because for u ∈H 1
0 (Ω) one has u|∂Ω = 0, the minimizer v satisﬁes the boundary
condition too. Thus we conclude.
2
As a simple application of the theory of constrained minimization, we solve the
eigenvalue problem for the Laplace operator on an open bounded domain Ω with
Dirichlet boundary conditions, i.e., the problem is to ﬁnd a number λ and a function
u ̸= 0 satisfying
−△u = λu
in
Ω,
u|∂Ω = 0.
(36.12)

36.2
The Dirichlet–Laplace Operator and Other Elliptic Differential Operators
553
The strategy is simple. On the Hilbert space H 1
0 (Ω), we minimize the functional
f (u) =
1
2⟨Du, Du⟩2 under the constraint g(u) =
1
2 for the constraint functional
g(u) = 1
2⟨u, u⟩2. The derivative of g is easily calculated; it is g′(u)(v) = ⟨u, v⟩2 for
all v ∈H 1
0 (Ω) and thus the level surface [g = 1
2] consists only of regular points of
the mapping g.
Since we know that f is weakly lower semi-continuous and coercive on H 1
0 (Ω),
we can prove the existence of a minimizer for the functional f on [g = 1
2] by verifying
that [g = 1
2] is weakly closed and then to apply Theorem 33.4.
Suppose a sequence (uj)j∈N converges to u weakly in H 1
0 (Ω). According to the
Sobolev embedding (36.7) the space H 1
0 (Ω) is compactly embedded into the space
L2(Ω) and thus this sequence converges strongly in L2(Ω) to u. It follows that
g(uj) →g(u) as j →∞, i.e., g is weakly continuous on H 1
0 (Ω) and its level
surfaces are weakly closed.
Theorem 33.4 implies the existence of a minimizer of f under the constraint
g(u) = 1/2. Using Corollary 35.1 and Theorem 35.2, we deduce that there is a
Lagrange multiplier λ ∈R for this constrained minimization problem, i.e., a real
number λ satisfying f ′(u) = λg′(u). In detail this identity reads

Ω
Du(x) · Dv(x) d x = λ

Ω
u(x)v(x) d x
∀v ∈H 1
0 (Ω),
and in particular for all v ∈D(Ω), thus −△u = λu in D′(Ω); and by elliptic
regularity theory (see for instance Sect. 9.3 of [3]) we conclude that this identity
holds in the classical sense. Since the solution u belongs to the space H 1
0 (Ω) it
satisﬁes the boundary condition u|∂Ω = 0. This proves:
Theorem 36.4 (Dirichlet Laplacian) Let Ω ⊂Rn be a bounded open set with
smooth boundary ∂Ω. Then the eigenvalue problem for the Laplace operator with
Dirichlet boundary conditions (36.12) has a solution.
The above argument which proved the existence of the lowest eigenvalue λ1 of
the Dirichlet–Laplace operator can be repeated on the orthogonal complement of the
eigenfunction u1 of the ﬁrst eigenvalue and thus gives an eigenvalue λ2 ≥λ1 (some
additional arguments show λ2 > λ1). In this way, one proves actually the existence of
an inﬁnite sequence of eigenvalues for the Dirichlet–Laplace operator. By involving
some reﬁned methods of the theory of Hilbert space operators, it can be shown that
these eigenvalues are of the order λk ≈constant ( k
|Ω|)
2
n (see for instance [1]).
Next we consider more generally the following class of second-order linear partial
differential operators A deﬁned on sufﬁciently smooth functions u by
Au = A0u −
n

j=1
∂j
$ n

i=1
aji∂iu
%
.
(36.13)
The matrix a of coefﬁcient functions aji = aij ∈L∞(Ω) satisﬁes for almost all
x ∈Ω and all ξ ∈Rn,
m
n

j=1
ξ 2
j ≤
n

i,j=1
ξjaji(x)ξi ≤M
n

j=1
ξ 2
j
(36.14)

554
36
Boundary and Eigenvalue Problems
for some constants 0 < m < M. A0 is a bounded symmetric operator in L2(Ω)
which is bounded from below, ⟨u, A0u⟩2 ≥−r ∥u∥2
2 for some positive number r
satisfying 0 ≤r <
m
c2 . Here m is the constant in condition (36.14) and c is the
smallest constant for which ∥u∥2 ≤c ∥Du∥2 holds for all u ∈H 1
0 (Ω).
As we are going to show, under these assumptions, the arguments used for the
study of the Dirichlet problem and the eigenvalue problem for the Dirichlet–Laplace
operator still apply. The associated quadratic form
Q(u, v) = ⟨u, A0v⟩2 +
n

i,j=1
⟨∂jv, aji∂iu⟩2
∀u, v ∈H 1
0 (Ω)
is strictly positive since the ellipticity condition (36.14) and the lower bound for A0
imply
Q(u, u) = ⟨u, A0u⟩2 +

Ω
n

i,j=1
∂jv(x)aji(x)∂iu(x) d x
≥−r ∥u∥2
2 +

Ω
m
n

j=1
(∂ju(x))2 d x = −r ∥u∥2
2 + m ∥Du∥2
2
≥(−rc2 + m) ∥Du∥2
2 = c0 ∥Du∥2
2 ,
c0 = −rc2 + m > 0.
As earlier we deduce that the functional f (u) = Q(u, u) is coercive and weakly lower
semi-continuous on H 1(Ω). Hence, Theorem 33.4 allows us to minimize f on M =
v0 +H 1
0 (Ω) and thus to solve the boundary value problem for a given v0 ∈H 1(Ω) or
on the level surface [g = 1
2] for the constraint function g(u) = 1
2⟨u, u⟩2 on H 1
0 (Ω).
The conclusion is that the linear elliptic partial differential operator (36.13) with
Dirichlet boundary conditions has an increasing sequence of eigenvalues, as it is the
case for the Laplace operator.
36.3
Nonlinear Convex Problems
In order to be able to minimize functionals of the general form (32.2), we ﬁrst have to
ﬁnd a suitable domain of deﬁnition and then to have enough information about it. We
begin with the description of several important aspects from the theory of Lebesgue
spaces. A good reference for this are paragraphs 18–20 of [4].
Let Ω ⊂Rn be a nonempty open set and h : Ω × R →R a function such
that h(·, y) is measurable on Ω for every y ∈R and y #→h(x, y) is continuous for
almost every x ∈Ω. Such functions are often called Carathéodory functions. If now
u : Ω →R is (Lebesgue) measurable, deﬁne ˆh(u) : Ω →R by ˆh(u)(x) = h(x, u(x))
for almost every x ∈Ω. Then ˆh(u) is measurable too. For our purpose it is enough to
consider ˆh on Lebesgue integrable functions u ∈Lp(Ω) and we need that the image
ˆh(u) is Lebesgue integrable too, for instance ˆh(u) ∈Lq(Ω) for some exponents
1 ≤p, q. Therefore the following lemma will be useful.

36.3
Nonlinear Convex Problems
555
Lemma 36.1 Suppose that Ω ⊂Rn is a bounded open set and h : Ω × R →R
a Carathéodory function. Then ˆh maps Lp(Ω) into Lq(Ω), if and only if, there are
0 ≤a ∈Lq(Ω) and b ≥0 such that for almost all x ∈Ω and all y ∈R,
|h(x, y)| ≤a(x) + b|y|p/q.
(36.15)
If this condition holds the map ˆh : Lp(Ω) →Lq(Ω) is continuous.
This result extends naturally to Carathéodory functions h : Ω × Rn+1 →R. For
uj ∈Lpj (Ω), j = 0, 1, . . ., n deﬁne ˆh(u0, . . ., un)(x) = h(x, u0(x), . . ., un(x)) for
almost every x ∈Ω. Then ˆh : Lp0(Ω) × · · · × Lpn(Ω) →Lq(Ω), if and only if,
there are 0 ≤a ∈Lq(Ω) and b ≥0 such that
|h(x, y0, . . ., yn)| ≤a(x) + b
n

j=0
|yj|pj /q.
(36.16)
And ˆh is continuous if this condition holds.
As a last preparation deﬁne, for every u ∈W 1,p(Ω), the functions y(u) =
(y0(u), y1(u), . . ., yn(u)) where y0(u) = u and yj(u) = ∂ju for j = 1, . . ., n. By
deﬁnition of the Sobolev space W 1,p(Ω) we know that
y : W 1,p(Ω) →Lp(Ω) × · · · × Lp(Ω) = Lp(Ω)×(n+1)
is a continuous linear map.
Now suppose that the integrand in formula (32.2) is a Carathéodory function and
satisﬁes the bound
|F(x, y)| ≤a(x) + b
n

j=0
|yj|p,
(36.17)
for all y ∈Rn+1 and almost all x ∈Ω, for some 0 ≤a ∈L1(Ω) and some
constant b ≥0. Then, as a composition of continuous mappings, ˆF ◦y is a well-
deﬁned continuous mapping W 1,p(Ω) →L1(Ω). We conclude that under the growth
restriction (36.17) the Sobolev space W 1,p(Ω) is a suitable domain for the functional
f (u) =

Ω
F(x, u(x), Du(x)) d x.
(36.18)
For 1 < p < ∞, the Sobolev spaces W 1,p(Ω) are known to be separable reﬂexive
Banach spaces, and thus well suited for the direct methods ([1]).
Proposition 36.1 Let Ω ⊂Rn be a bounded open set and F : Ω × Rn+1 →R a
Carathéodory function.
(a) If F satisﬁes the growth restriction (36.17), then a functional f : W 1,p(Ω) →R
is well deﬁned by (36.18). It is polynomially bounded according to
|f (u)| ≤∥a∥1 + b∥u∥p
p + b ∥Du∥p
p
∀u ∈W 1,p(Ω).
(36.19)

556
36
Boundary and Eigenvalue Problems
(b) If F satisﬁes a lower bound of the form
F(x, y) ≥−α(x) −β|y0|r + c|y|p
(36.20)
for all y = (y0, y) ∈Rn+1 and almost all x ∈Ω, for some 0 ≤α ∈L1(Ω),
β ≥0, c > 0 and 0 ≤r < p, then the functional f is coercive.
(c) If y #→F(x, y) is convex for almost all x ∈Ω, then f is lower semi-continuous
for the weak topology on W 1,p(Ω).
Proof
To complete the proof of Part (a) we note that the assumed bound for F
implies that |F ◦y(u)(x)| ≤a(x) + b n
j=0 |yj(u)(x)|p and thus by integration the
polynomial bound follows.
Integration of the lower bound F(x, u(x), Du(x)) ≥−α(x)−β|u(x)|r+c|Du(x)|p
for almost all x ∈Ω gives f (u) ≥−∥α∥1 −β∥u∥r
r +c ∥Du∥p
p. By inequality (36.9),
||u||r
r ≤Sr ∥Du∥r
p, hence f (u) →∞as ∥Du∥p →∞since r < p and c > 0.
For any u, v ∈W 1,p(Ω) and 0 ≤t ≤1 we have ˆF(y(tu + (1 −t)v)) = ˆF(ty(u) +
(1 −t)y(v)) ≤t ˆF(y(u)) + (1 −t) ˆF(y(v)) since F is assumed to be convex with
respect to y. Hence, integration over Ω gives f (tu+(1−t)v) ≤tf (u)+(1−t)f (v).
This shows that f is a convex functional. According to Part (a), f is continuous on
W 1,p(Ω), therefore Lemma 33.3 implies that f is weakly lower semi-continuous on
W 1,p(Ω).
2
Let us remark that the results presented in Part (c) of Proposition 36.1 are not
optimal (see for instance [2, 5, 6]). But certainly the result given above has the
advantage of a very simple proof. The above result uses stronger assumptions insofar
as convexity with respect to u and Du is used whereas in fact convexity with respect
to Du is sufﬁcient.
Suppose we are given a functional f of the form (36.18) for which parts (a) and
(c) of Proposition 36.1 apply. Then, by Theorem 33.3 we can minimize f on any
bounded weakly closed subset M ⊂W 1,p(Ω). If in addition f is coercive, i.e., if
Part (b) of Proposition 36.1 applies too, then we can minimize f on any weakly
closed subset M ⊂W 1,p(Ω).
In order to relate these minimizing points to solutions of nonlinear partial differ-
ential operators, we need differentiability of the functional f . For this we will not
consider the most general case but make assumptions which are typical and allow a
simple proof.
Let us assume that the integrand F of the functional f is of class C1 and that all
derivatives Fj =
∂F
∂yj are again Carathéodory functions. Assume furthermore that
there are functions 0 ≤aj ∈Lp′(Ω) and constants bj > 0 such that for all y ∈Rn+1
and almost all x ∈Ω,
|Fj(x, y)| ≤aj(x) + bj
n

i=0
|yi|p−1,
j = 0, 1, . . ., n
(36.21)
where p′ denotes the Hölder conjugate exponent, 1
p + 1
p′ = 1. Since (p −1)p′ = p
we get for all u ∈W 1,p(Ω) the simple identity
--|yj(u)|p−1--p′
p′ =
--yj(u)
--p
p and it

36.3
Nonlinear Convex Problems
557
follows that ˆFj(y(u)) ∈Lp′(Ω) for all u ∈W 1,p(Ω) and j = 0, 1, . . ., n. This implies
the estimates, for all u, v ∈W 1,p(Ω),
-- ˆFj(y(u))yj(v)
--
1 ≤
-- ˆFj(y(u))
--
p′
--yj(v)
--
p ,
j = 0, 1, . . ., n
and thus
v #→

Ω
n

j=0
Fj(x, y(u)(x))yj(v)(x) dx
(36.22)
is a continuous linear functional on W 1,p(Ω), for every u ∈W 1,p(Ω). Now it is
straightforward (see Exercises) to calculate the derivative of the functional f , by
using Taylor’s Theorem. The result is the functional
f ′(u)(v) =

Ω
n

j=0
Fj(x, y(u)(x))yj(v)(x) d x
∀u, v ∈W 1,p(Ω).
(36.23)
As further preparation for the solution of nonlinear eigenvalue problems we
specify the relevant properties of the class of constraint functionals
g(u) =

Ω
G(x, u(x)) d x,
u ∈W 1,p(Ω)
(36.24)
which we are going to use. Here G is a Carathéodory function which has a derivative
G0 =
∂G
∂u which itself is a Carathéodory function. Since we are working on the
space W 1,p(Ω) we assume the following growth restrictions. There are functions
0 ≤α ∈L1(Ω) and 0 ≤α0 ∈Lp′(Ω) and constants 0 ≤β, β0 such that for all
u ∈R and almost all x ∈Ω,
|G(x, u)| ≤α(x) + β|u|q,
|G0(x, u)| ≤α0(x) + β0|u|q−1
(36.25)
with an exponent q satisfying 2 ≤q < p∗. Because of Sobolev’s inequality (36.9)
the functional g is well deﬁned and continuous on W 1,p(Ω) and its absolute values
are bounded by |g(u)| ≤∥α∥1 + β∥u∥q
q.
Since 2 ≤q < p∗there is an exponent 1 ≤r < p∗such that (q −1)r′ < p∗
(in the Exercises the reader is asked to show that any choice of r with
p∗
p∗+1−q <
r < p∗satisﬁes this requirement). Then Hölder’s inequality implies
-- |u|q−1v
--
1 ≤
-- |u|q−1--
r′ ∥v∥r. Therefore the bound for G0 shows that for every u ∈W 1,p(Ω) the
functional v #→

Ω G0(x, u(x))v(x) d x is well deﬁned and continuous on W 1,p(Ω).
Now it is straightforward to show that the functional g is Fréchet differentiable on
W 1,p(Ω) with derivative
g′(u)(v) =

Ω
G0(x, u(x))v(x) d x
∀u, v ∈W 1,p(Ω).
(36.26)
Finally, we assume that g has a level surface [g = c] with the property that g′(u) ̸= 0
for all u ∈[g = c].

558
36
Boundary and Eigenvalue Problems
A simple example of a function G for which all the assumptions formulated above
are easily veriﬁed is G(x, u) = au2 for some constant a > 0. Then all level surfaces
[g = c], c > 0, only contain regular points of g.
The nonlinear eigenvalue problems which can be solved by the strategy indicated
above are those of divergence type , i.e., those which are of the form (36.27) below.
Theorem 36.5 [Nonlinear eigenvalue problem] Let Ω ⊂Rn be a bounded open set
with smooth boundary ∂Ω and F : Ω × Rn+1 →R a Carathéodory function which
satisﬁes all the hypotheses of Proposition 36.1 and in addition the growth restrictions
(36.21) for its derivatives Fj. Furthermore, let G : Ω × R →R be a Carathéodory
function with derivative G0 which satisﬁes the growth conditions (36.25). Finally,
assume that the constraint functional g deﬁned by G has a level surface [g = c]
which consists of regular points of g. Then the nonlinear eigenvalue problem
F0(x, u(x), Du(x)) −
n

j=1
∂jFj(x, u(x), Du(x)) = λG0(x, u(x))
(36.27)
with Dirichlet boundary conditions has a nontrivial solution u ∈W 1,p
0
(Ω).
Proof Because of the Dirichlet boundary conditions we consider the functionals f
and g on the closed subspace
E = W 1,p
0
(Ω) =
closure of D(Ω) in W 1,p(Ω).
(36.28)
Proposition 36.1 implies that f is a coercive continuous and weakly lower semi-
continuous functional on E. The derivative of f is given by the restriction of the
identity (36.23) to E.
Similarly, the functional g is deﬁned and continuous on E and its derivative is
given by the restriction of the identity (36.26) to E. Furthermore, the bound (36.25)
implies that g is deﬁned and thus continuous on Lq(Ω).
Now consider a level surface [g = c] consisting of regular points of g. Suppose
(un)n∈N is a weakly convergent sequence in E, with limit u. Because of the compact
embedding of E into Lq(Ω) this sequence converges strongly in Lq(Ω). Since g
is continuous on Lq(Ω) we conclude that (g(un))n∈N converges to g(u), thus g is
weakly continuous on E. Therefore all level surface of g are weakly closed.
Theorem 33.4 implies that the functional f has a minimizing element u ∈[g = c]
on the level surface [g = c]. By assumption, u is a regular point of g, hence Theorem
35.2 on the existence of a Lagrange multiplier applies and assures the existence of a
number λ ∈R such that
f ′(u) = λg′(u).
(36.29)
In detail this equation reads: f ′(u)(v) = λg′(u)(v) for all v ∈E and thus for all v in
the dense subspace D(Ω) of E = W 1,p
0
(Ω).
For v ∈D(Ω) we calculate
f ′(u)(v) =

Ω
F0(x, u(x), Du(x))v(x) d x +

Ω
n

j=1
Fj(x, u(x), Du(x))∂jv(x) d x

36.3
Nonlinear Convex Problems
559
=

Ω
F0(x, u(x), Du(x))v(x) d x +

Ω
n

j=1
∂j[Fj(x, u(x), Du(x))v(x)] d x
−

Ω
n

j=1
(∂jFj(x, u(x), Du(x)))v(x) d x
=

Ω
[F0(x, u(x), Du(x)) −
n

j=1
(∂jFj(x, u(x), Du(x))]v(x) d x
since the second integral vanishes because of the Gauss divergence theorem and
v ∈D(Ω). Hence Eq. (36.29) implies

Ω
[F0(x, u(x), Du(x)) −
n

j=1
(∂jFj(x, u(x), Du(x)) −λG0(x, u(x)]v(x) d x = 0
for all v ∈D(Ω). We conclude that u solves the eigenvalue Eq. (36.27). 2
Remark 36.1
1. A very important assumption in the problems we solved in this section was that
the domain Ω ⊂Rn on which we studied differential operators is bounded so
that compact Sobolev embeddings can be used. Certainly, this strategy breaks
down if Ω is not bounded. Nevertheless there are many important problems on
unbounded domains Ω and one has to modify the strategy presented above. In
the last 20 years considerable progress has been made in solving these global
problems. The interested reader is referred to the books [1, 3] and in particular to
the book [6] for a comprehensive presentation of the new strategies used for the
global problems.
2. As is well known, a differentiable function can have other critical points than
minima or maxima for which we have developed a method to prove their exis-
tence and in favorable situations to calculate them. For these other critical points
of functionals (saddle points or mountain passes) a number of other, mainly topo-
logical methods have been shown to be quite effective in proving their existence,
such as index theories, mountain pass lemmas, perturbation theory. Modern books
which treat these topics are [2, 6] where one also ﬁnds many references to original
articles.
3. The well-known mountain pass lemma of Ambrosetti and Rabinowitz is a
beautiful example of results in variational calculus where elementary intuitive
considerations have lead to a powerful analytical tool for ﬁnding critical points
of functionals f on inﬁnite dimensional Banach spaces E.
To explain this lemma in intuitive terms consider the case of a function f on
E = R2 which has only positive values. We can imagine that f gives the height
of the surface of the Earth over a certain reference plane. Imagine further a town
T0 which is surrounded by a mountain chain. Then, in order to get to another town
T1 beyond this mountain chain, we have to cross the mountain chain at some point

560
36
Boundary and Eigenvalue Problems
S. Certainly we want to climb as little as possible, i.e., at a point S with minimal
height f (S). Such a point is a mountain pass of minimal height which is a saddle
point of the function f .All other mountain passes M have a height f (M) ≥f (S).
Furthermore, we know f (T0) < f (S) and f (T1) < f (S). In order to get from
town T0 to town T1 we go along a continuous path γ which has to wind through
the mountain chain, γ (0) = T0 and γ (1) = T1. As described above we know
sup0≤t≤1 f (γ (t)) ≥f (S) and for one path γ0 we know sup0≤t≤1 f (γ0(t)) = f (S).
Thus, if we denote by Γ the set of all continuous paths γ from T0 to T1 we get
f (S) = inf
γ ∈Γ sup
0≤t≤1
f (γ (t)),
i.e., the saddle point S of f is determined by a “minimax” principle.
4. If u ∈E is a critical point of a differentiable functional f of the form (36.18) on a
Banach space E, then this means that u satisﬁes f ′(u)(v) = 0 for all v ∈E. This
means that u is a weak solution of the (nonlinear) differential equation f ′(u) = 0.
But in most cases we are actually interested in a strong solution of this equation,
i.e., a solution which satisﬁes the equation f ′(u) = 0 at least pointwise almost
everywhere. For a classical solution this equation should be satisﬁed in the sense
of functions of class C2. For the linear problems which we have discussed in
some detail we have used the special form of the differential operator to argue
that for these problems a weak solution is automatically a classical solution. The
underlying theory is the theory of elliptic regularity. The basic results of this
theory are presented in the books [2, 3].
36.4
Exercises
1. Let H be a real Hilbert space and K ⊂H a closed convex subset. For every
x ∈H show: The functional ψx : K →R deﬁned by ψx(z) = ∥x −z∥is strictly
convex and coercive (if K is not bounded).
2. Calculate the derivative of the functional f , Eq. (36.18) by using the assumptions
(36.17) and (36.21).
3. For the Sobolev space H 1
0 ([a, b]) prove:
a) |u(x) −u(y)| ≤||u′||2
√|x −y| for all u ∈H 1
0 ([a, b]) and all x, y ∈[a, b];
b) ∥u∥2 ≤b−a
√
2 ∥u′∥2 for all u ∈H 1
0 ([a, b]).
4. Suppose functions p, q ∈C([a, b]) are given which satisfy the lower bounds
p(x) ≥c > 0 and q(x) ≥−r with r ≥0 such that c0 = c −r(b −a) > 0. Prove:
a) Given any g ∈L2([a, b]), the functional
f (u) = 1
2
 b
a
p(x)u′(x)2 d x + 1
2
 b
a
q(x)u(x)2 d x −
 b
a
g(x)u(x) d x
= 1
2⟨u′, pu′⟩2 + 1
2⟨u, qu⟩2 −⟨g, u⟩2
has a unique minimum u0 on the Sobolev space H 1
0 ([a, b]);

36.4
Exercises
561
b) this unique minimum u0 solves the Sturm–Liouville problem for the interval
[a, b] and the coefﬁcient functions p, q, g, i.e., the problem of solving the
equation
−d
dx [p(x)du
dx (x)] + q(x)u(x) = g(x)u(x)
∀x ∈(a, b)
(36.30)
for the boundary conditions u(a) = 0 = u(b).
Hints: Observe the previous problem and show that f is a strictly convex coercive
functional on the Sobolev space H 1
0 ([a, b]). Conclude by our general results.
Deduce that under the assumptions g ∈C([a, b]) and p ∈C1([a, b]) the weak
solution u0 is actually a classical solution of the Sturm–Liouville problem (36.30).
5. Given an exponent 1 < p < n and an exponent q satisfying 2 ≤q < p∗ﬁnd
an exponent r, 1 ≤r < p∗, such that (q −1)p′ < p∗where p′ is the Hölder
conjugate exponent of the exponent p. Show that the Sobolev space W 1,p([a, b])
is contained in the space of continuous functions C([a, b]) on the closed interval
[a, b] and that the identical embedding is completely continuous, i.e., continuous
and compact.
Hints: For u ∈W 1,p([a, b]) and x, y ∈(a, b) show ﬁrst that |u(x) −u(y)| ≤
|x −y|1−1
p ∥u′∥p.
6. For a bounded open set Ω ⊂Rn with smooth boundary ∂Ω and an exponent p,
2 < p < 2∗=
2n
n−2, ﬁnd a solution of the following nonlinear boundary value
problem:
−△u + λu = u|u|p−2,
u > 0
in Ω,
and u = 0 on ∂Ω. Assume λ > −λ1, λ1 the smallest eigenvalue of the Dirichlet–
Laplace operator on Ω.
Hints: Consider the functional f (u) = 1
2⟨Du, Du⟩2 + 1
2⟨u, u⟩2 on the Sobolev
space E = H 1
0 (Ω) and minimize it under the constraint g(u) = 1 with the
constraint functional g(u) = 1
p

Ω |u(x)|p d x.Apply the theorem on the existence
of a Lagrange multiplier and show that the Lagrange multiplier is positive, using
the lower bound for the parameter λ. Finally use a rescaling argument.
7. For a bounded open set Ω ⊂Rn with smooth boundary ∂Ω and an exponent p,
2 < p < 2∗=
2n
n−2 solve the nonlinear eigenvalue problem
−△u + Au = λβ(x)u|u|p−2
in Ω
under Dirichlet boundaryconditions. AisaboundedsymmetricoperatorinL2(Ω)
with lower bound A ≥−λ1, λ1 the smallest eigenvalue of the Dirichlet–Laplace
operator on Ω. β is a nonnegative essentially bounded function on Ω, β ̸= 0.
Hints: Minimize the functional f (u) =
1
2⟨Du, Du⟩2 + 1
2⟨u, Au⟩2 on the
Sobolev space E = H 1
0 (Ω) on [g = 1] for the constraint functional g(u) =
1
p

Ω β(x)|u(x)|p d x.ApplythetheoremontheexistenceofaLagrangemultiplier.
8. For a bounded open set Ω ⊂Rn with smooth boundary ∂Ω and an exponent p,
2 ≤p < ∞, show that there exists a weak solution u ∈W 1,p
0
(Ω) of the boundary
value problem
−∇· (|∇u|p−2∇u) = g
in Ω,

562
36
Boundary and Eigenvalue Problems
u = 0
on ∂Ω
in the sense that u satisﬁes the equation

Ω
[∇u|∇u|p−2∇v −gv] d x = 0
∀v ∈D(Ω)
(36.31)
where g is any given element in W 1,p
0
(Ω)′.
Hints: Consider the functional
f (u) = 1
p

Ω
|∇u|p d x −

Ω
gu d x
and show that it is well deﬁned and of class C1 on the Banach space E = W 1,p
0
(Ω).
Furthermore, show that the left-hand side of Eq. (36.31) is just the directional
derivative of f in the direction v. Now verify the hypotheses of one of the gener-
alized Weierstrass theorems, i.e., show that f is weakly lower semi-continuous
on E and coercive. Deduce that a minimizer u of f on E exists and that it satisﬁes
Eq. (36.31).
References
1. Lieb E, Loss M.Analysis. vol. 14 of Graduate Studies in Mathematics. 2nd ed.AMS, Providence,
Rhode Island; 2001.
2. Jost J, Li-Jost X. Calculus of variations. vol. 64 of Cambridge Studies in advanced mathematics.
Cambridge: Cambridge University Press; 1998.
3. Blanchard Ph, Brüning E. Variational methods in mathematical physics. A uniﬁed approach.
Texts and Monographs in Physics. Berlin: Springer-Verlag; 1992.
4. Vainberg MM. Variational methods for the study of nonlinear operators. London: Holden Day;
1964.
5. Dacorogna B. Weak continuity and weak lower semicontinuity of non-linear functionals. vol.
922 of Lecture Notes in Mathematics. Berlin: Springer-Verlag; 1982.
6. Struwe M. Variational methods : applications to nonlinear partial differential equations and
Hamiltonian systems. vol. 34 of Ergebnisse der Mathematik und ihrer Grenzgebiete, Folge 3.
3rd ed. Berlin: Springer-Verlag; 2000.

Chapter 37
Density Functional Theory
of Atoms and Molecules
The Schrödinger equation is a (linear) partial differential equation that can be solved
exactly only in very few special cases such as the Coulomb potential or the har-
monic oscillator potential. For more general potentials or for problems with more
than two particles, the quantum mechanical problem is no easier to solve than the
corresponding classical one. In these situations, variational methods are one of the
most powerful tools for deriving approximate eigenvalues E and eigenfunctions ψ.
These approximations are done in terms of a theory of density functionals as pro-
posed by Thomas, Fermi, Hohenberg and Kohn. This chapter explains brieﬂy the
basic facts of this theory.
37.1
Introduction
Suppose that the spectrum σ(H) of a Hamilton operator H is purely discrete and can
be ordered according to the size of the eigenvalues, i.e., E1 < E2 < E3 < · · · . The
corresponding eigenfunctions ψi form an orthonormal basis of the Hilbert space H.
Consider a trial function
ψ =
∞

i=1
ciψi,
∞

i=1
|ci|2 = 1.
The expectation value of H in the mixed state ψ is
E = ⟨ψ, Hψ⟩=
∞

i=1
|ci|2Ei.
It can be rewritten as
E = E1 + |c2|2(E2 −E1) + |c3|2(E3 −E1) + · · · ≥E1.
Hence, E is an upper bound for the eigenvalue E1 which corresponds to the ground
state of the system. One basic idea of the variational calculations concerning spectral
© Springer International Publishing Switzerland 2015
563
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2_37

564
37
Density Functional Theory of Atoms and Molecules
properties of atoms and molecules is to choose trial functions depending on some
parameters and then to adjust the parameters so that the corresponding expectation
value E is minimized.
Application of this method to the helium atom by Hylleras played an important
role in 1928–1929 when it provided the ﬁrst test of the Schrödinger equation for
a system that is more complicated than the hydrogen atom. In the limit of inﬁnite
nuclear mass, the Hamilton operator for the helium atom is
H = −¯h2
2m(△1 + △2) −e2
r1
−e2
r2
+ e2
r12
,
where ri = |xi| and where r12 = |x1 −x2| is the electron–electron separation. The
term
e2
r12 describes the Coulomb repulsion between two electrons. Hylleras intro-
duced trial functions of the form ψ = 
i,j,k aijkri
1rj
2 rk
12 e −αr1−βr2 depending on the
parameters aijk, α and β.
The history of the density functional theory dates back to the pioneering work of
Thomas [1] and Fermi [2]. In the 1960s, Hohenberg and Kohn [3] and Kohn and
Sham [4] made substantial progress to give the density functional theory a foundation
based on the quantum mechanics of atoms and molecules. Since then an enormous
number of results has been obtained, and this method of studying solutions of many
electron problems for atoms and molecules has become competitive in accuracy with
up to date quantum chemical methods.
The following section gives a survey of the most prominent of these density func-
tional theories. These density functional theories are of considerable mathematical
interest since they present challenging minimization problems of a type which has
not been attended to before. In these problems, one has to minimize certain function-
als over spaces of functions deﬁned on unbounded domains (typically on R3) and
where nonreﬂexive Banach spaces are involved.
The last section reports on the progress in relating these density functional theories
to the quantum mechanical theory of many electron systems for atoms and molecules.
Here the results on self-adjoint Schrödinger operators obtained in Part B will be the
mathematical basis. The results on the foundation of density functional theories are
mainly due to Hohenberg–Kohn [3] and Kohn–Sham [4]. The original paper by
Hohenberg–Kohn has generated a vast literature, see, for instance, [5–9].
Fifty years after the starting point of density functional theory its applications in
chemistry and the study of electronic structures have been growing steadily, but the
precise form of the energy functional is still elusive. Recently, in the same spirit, a
formulation with phase space variables and Wigner functions has been suggested in
[10].

37.2
Semiclassical Theories of Density Functionals
565
37.2
Semiclassical Theories of Density Functionals
The main goal of these semiempirical models is to describe correctly the ground state
energy by minimizing various types of density functionals.
In all these density functional theories, we are looking for the energy and the
charge density of the ground state by solving directly a minimization problem of the
form
min
+
F(ρ) +

ρ(x)v(x) d x : ρ ∈DF
,
.
Here, F is a functional of the charge density and depends only on the number N of
electrons but not on the potential v generated by the nuclei. The minimum has to be
calculated over a set DF of densities which is either equal to or a subset of DN =

ρ ∈L1(R3) : 0 ≤ρ, ∥ρ∥1 = N

depending on the speciﬁc theory considered. Let
us mention some of the prominent models.
•
The model of Thomas and Fermi uses the functional
FTF(ρ) = cTF

R3 ρ(x)5/3 d x + D(ρ, ρ)
on the domain DTF = DN ∩L5/3(R3). In the simplest models of this theory, the
potential v is given by v(x) = −Z
|x|, where Z > 0 is a ﬁxed parameter representing
the charge of the atomic nucleus and
D(ρ, ρ) = 1
2

R3

R3
ρ(x)ρ(y)
|x −y| d x d y
is nothing else than the Coulomb energy for the charge density ρ. The constant
cTF has the value 3/5.
•
The model of Thomas–Fermi–von Weizsäcker is associated with the functional
FTFW(ρ) = cW

R3 (∇ρ(x)1/2)2 d x + FTF(ρ)
on the domain DTFW = DTF ∩H 1(R3).
•
The model of Thomas–Fermi–Dirac–von Weizsäcker leads to the functional
FTFDW(ρ) = FTFW(ρ) −cD

R3 ρ(x)4/3 d x
on the same domain DTFW. Note that for 1 ≤p1 < q < p2 one has Lq(R3) ⊂
Lp1(R3) ∩Lp2(R3) and ∥u∥q ≤||u||t
p1 ∥u∥1−t
p2 with t =
1
q −1
p2
1
p1 −1
p2
which we apply
for p1 = 1, p2 = 5/3 and q = 4/3. It follows that ∥ρ∥4/3 is ﬁnite on DTFW.
Therefore, the domain of FTFDW is DTFW.
All these models describe partially some observed natural phenomena but are nev-
ertheless rather rudimentary and are no longer in use in the practice of quantum

566
37
Density Functional Theory of Atoms and Molecules
chemistry. From a theoretical point of view these models are quite interesting since
weareconfrontedwiththesametypeof(mathematical)difﬁcultiesasinmorerealistic
approaches.
Though the Thomas–Fermi theory is quite old, a mathematically rigorous solution
of the minimization problem has been found only in 1977 by Lieb and Simon [11].
The basic aspects of this solution are discussed in [12, 13].
37.3
Hohenberg–Kohn Theory
The Hohenberg–Kohn theory is a successful attempt to link these semiclassical
density functional theories to the quantum mechanics of atoms and molecules. Never-
theless from a mathematical point of view there remain several challenging problems
as we will see later.
The N-particle Hamilton operators which are considered are assumed to be of the
form
HN = HN(v) = −
N

j=1
△j +

j<k
u(xj −xk) +
N

j=1
v(xj) ≡H0 + V ,
(37.1)
where v(x) is a real-valued function on R3 and V = N
j=1 v(xj). In typical situations
u denotes the Coulomb interaction, but many other interactions can be used in this
approach too. We restrict ourselves to the Coulomb case u(xj −xk) =
e2
|xj −xk|. In this
case, the operator H0 is well deﬁned and self-adjoint on the domain D(T ) of operator
T = −N
j=1 △j of the kinetic energy (compare Theorem 23.9 and the exercises for
this theorem). For the one-particle potential v we assume in the following always
v ∈L2(R3) + L∞(R3) so that for these potentials too Kato’s perturbation theory
applies and assures that HN is self-adjoint on D(T ). Note that L2(R3) + L∞(R3) is
a Banach space when equipped with the norm
∥v∥= inf
∥v1∥2 + ∥v2∥∞: v1 ∈L2(R3), v2 ∈L∞(R3), v = v1 + v2

.
However, this Banach space is not reﬂexive. It is actually the topological dual of the
Banach space X = L1(R3) ∩L2(R3) for the norm ∥u∥= ∥u∥1 + ∥u∥3, i.e.,
X′ = L2(R3) + L∞(R3).
In 1964, Hohenberg and Kohn proposed a method to solve the problem of ﬁnding
the ground state energy of HN through a varational principle. To explain this method
we need some preparation. The single-particle reduced density matrix γ of an N-
particle wave function ψ is given by the kernel
γ (z, z′) =

ψ(z, z2, . . ., zN)ψ(z′, z2, . . ., zN) d z2 · · · d zN,
(37.2)

37.3
Hohenberg–Kohn Theory
567
where zi = (xi, σi) denotes the space variable xi and the spin variable σi. This
formula deﬁnes a mapping ψ →γ . This density matrix allows us to express the
single particle density as
ρ(x) = N

σ
γ ((x, σ), (x, σ))
(37.3)
which deﬁnes a mapping γ →ρ and thus a mapping v →ρv = R(v) from potentials
v to one-particle densities ρ when ψ is a ground state of HN(v). This mapping R
plays a fundamental role in the Hohenberg–Kohn theory. Denote by GN the set of
all those potentials v for which the Hamiltonian HN(v) has a (unique) ground state
ψ ∈D(T ). Then we consider R as a mapping
R : GN ∩X′ →

ρ ∈L1(R3) : 0 ≤ρ

,
(37.4)
and one wants to know when this mapping has an inverse. In order to be able to
make progress in this problem one has to have a characterization of the range of the
mapping R, i.e., one has to know: Under which conditions on ρ there is a potential
v ∈GN ∩X′ such that the Hamilton operator HN(v) has a ground state ψ which
deﬁnes ρ = ρψ through Eqs. (37.2) and (37.3).
Up to now this problem has found only a partial solution which nevertheless allows
us to proceed. There are two conditions which are obviously necessary, namely
0 ≤ρ(x) for all x ∈R3 and ∥ρ∥1 = N, i.e., ρ ∈L1(R3). The following lemma
gives additional necessary conditions.
Lemma 37.1 Suppose ρ = ρψ is obtained by Eqs. (37.2) and (37.3) from a state
ψ the kinetic energy T . Then
a) ρ1/2 ∈H 1(R3) and
--∇ρ1/2--2
2 ≤T (ψ)
b) ρ ∈L3(R3) ∩L1(R3) and
--ρψ
--
3 ≤constant T (ψ)
Proof The kinetic energy is deﬁned by
T (ψ) =
N

i=1

|∇iψ(x1, . . ., xi, . . ., xN)|2 d x1 · · · d xN
= N

|∇1ψ(x1, . . ., xN)|2 d x1 · · · d xN.
For the density we calculate
∇ρ(x) = N(

[(∇ψψ)(x, x2, . . ., xN) + (ψ∇ψ)(x, x2, . . ., xN)] d x2 · · · d xN,
and Schwarz’ inequality implies
|∇ρ(x)|2 ≤4N

|(∇1ψ)(x, x2, . . ., xN)|2 d x2 · · · d xNρ(x).

568
37
Density Functional Theory of Atoms and Molecules
We deduce
--∇ρ1/2--2
2 = 1
4

(∇ρ(x))2 d x
ρ(x) ≤T (ψ).
This implies Part a).
Sobolev’s inequality in R3 states (see (36.9)) ||u||2
6 ≤S ∥∇u∥2
2 which we apply
for u = ρ1/2 to get ∥ρ∥3 =
--ρ1/2--2
6 ≤S
--∇ρ1/2--2
2 ≤S T (ψ) < ∞. Thus, the
statement of part b) follows.
2
Corollary 37.1
ran R ⊆

ρ ∈L1(R3) ∩L3(R3) : 0 ≤ρ, ρ1/2 ∈H 1(R3)

≡D
and for ρ ∈D there is a state ψ in the domain D(T ) such that ρ = ρψ.
Proof The ﬁrst part of the corollary is just a summary of the previous lemma. Given
ρ ∈D deﬁne ψ as a normalized symmetric N-fold tensor product of ρ1/2. Since

(∇ρ(x))2 d x
ρ(x) < ∞it follows that ψ ∈D(T ).
2
Note that this corollary only gives some estimate of the set of those densities ρ
for which there is v ∈GN ∩X′ such that ρ is the density of a ground state ψ of
HN(v). The problem is that the set GN is not known explicitly and thus the range of
the map R is not known precisely.
The map ψ #→ρ is clearly not bijective and different ψ can give the same ρ.
However, one can prove continuity though the proof is not too easy (see the appendix
of [14]). Part of the difﬁculty comes from the fact that this map is not linear. Observe
that the space H 1(R3N) is the form domain of the kinetic energy T .
Theorem 37.1 ψ #→ρ1/2 is a continuous map H 1(R3N) →H 1(R3).
Recall that we only consider one-particle potentials v ∈X′ so that the domain of
the N-particle Hamiltonian HN(v) is the domain
WN =

ψ ∈L2(R3N) : T (ψ) < ∞

= D(T )
of the kinetic energy T . This allows us to determine the ground state energy of HN(v)
as the solution of a minimization problem:
E(v) =
inf
ψ∈WN\{0}
⟨ψ, HN(v)ψ⟩
⟨ψ, ψ⟩
.
(37.5)
There may or may not be a minimizing element ψ for the minimization problem
(37.5) for the ground state energy. And if there exists one we do not always have
uniqueness. Accordingly, any minimizing element ψ of (37.5) is called a ground
state of HN(v). It satisﬁes HN(v)ψ = E(v)ψ at least in the sense of distributions.
E(v) has some important properties.

37.3
Hohenberg–Kohn Theory
569
Theorem 37.2 The ground state energy E(v) deﬁned by (37.5) has the following
properties.
a) E(v) is concave in v ∈X′, i.e., for all v1, v2 ∈X′ and all 0 ≤t ≤1 one has
E(tv1 + (1 −t)v2) ≥tE(v1) + (1 −t)E(v2)
b) E(v) is monotone increasing, i.e., if v1, v2 ∈X′ and v1(x) ≤v2(x) for all x ∈R3,
then E(v1) ≤E(v2)
c) E(v) is continuous with respect to the norm of X′ and it is locally Lipschitz.
Proof See the Exercises.
2
The key result of the Hohenberg–Kohn theory is the observation that under certain
conditions different potentials v1, v2 ∈GN ∩X′ lead to different densities ρ1, ρ2,
thus proving injectivity of the map R.
Theorem 37.3 (Uniqueness Theorem) Suppose v1, v2 ∈GN ∩X′ are potentials
for which the Hamilton operators HN(v1) and HN(v2), respectively, have different
ground states ψ1, ψ2. Then the densities ρψ1, ρψ2 deﬁned by these states are different,
ρψ1(x) ̸= ρψ2(x) for all points x in a set of positive Lebesgue measure.
Proof
We give the proof for the case where the ground state energies for both
operators HN(v1) and HN(v2) are not degenerate. For the general case, we refer to
the literature [7].
According to our deﬁnitions, we know E(vi) = ⟨ψi, HN(vi)ψi⟩, ψi ∈WN,
∥ψi∥= 1 and E(vi) ≤⟨ψ, HN(vi)ψ⟩for all ψ ∈WN, ∥ψ∥= 1 and E(vi) <
⟨ψ, HN(vi)ψ⟩for all ψ ∈WN, ∥ψ∥= 1, ψ ̸= ψi, i = 1, 2. Equations (37.1)–(37.3)
imply ⟨ψ, HN(vi)ψ⟩= ⟨ψ, H0ψ⟩+ N

vi(x)ρψ(x) d x, hence
E(v1) = ⟨ψ1, H0ψ1⟩+ N

v2(x)ρψ1(x) d x + N

(v1(x) −v2(x))ρψ1(x) d x
> E(v2) + N

(v1(x) −v2(x))ρψ1(x) d x
and similarly E(v2) > E(v1) + N

(v2(x) −v1(x))ρψ2(x) d x. By adding these two
inequalities we get
0 > N

(v1(x) −v2(x))(ρψ1(x) −ρψ1(x)) d x.
All the above integrals are well deﬁned because of part b) of Lemma 37.1 and the
interpolation estimate ∥ρ∥2 ≤∥ρ∥1/4
1
∥ρ∥3/4
3 .
2
Note that the assumption that HN(v1) and HN(v2) have different ground states ex-
cludes the case that the potentials differ by a constant. This assumption was originally
used by Hohenberg–Kohn.
Certainly one would like to have stronger results based on conditions on the
potentials v1, v2 which imply that the Hamilton operators HN(v1) and HN(v2) have
different ground states ψ1 and ψ2. But such conditions are not available here.
The basic Hohenberg–Kohn uniqueness theorem is an existence theorem. It claims
that there exists a bijective map R : v →ρ between an unknown set of potentials

570
37
Density Functional Theory of Atoms and Molecules
v and a corresponding set of densities which is unknown as well. Nevertheless,
this result implies that the ground state energy E can in principle be obtained by
using v = R−1(ρ), i.e., the potential v as a functional of the ground state density ρ.
However, there is a serious problem since nobody knows this map explicitly.
37.3.1
Hohenberg–Kohn Variational Principle
Hohenberg and Kohn assume that every one-particle density ρ is deﬁned in terms
of a ground state ψ for some potential v, i.e., HN(v)ψ = E(v)ψ. Accordingly, they
introduce the set
AN =

ρ ∈L1 ∩L3(R3) : 0 ≤ρ, √ρ ∈H 1(R3), ∃ground state ψ : ψ #→ρ

and on AN they considered the functional
FHK(ρ) = E(v) −

v(x)ρ(x) dx.
(37.6)
This deﬁnition of FHK requires Theorem 37.3 according to which there is a one-
particle potential v associated with ρ, v = R−1(ρ). Using this functional the
Hohenberg–Kohn variational principle reads
Theorem 37.4 (Hohenberg–Kohn Variational Principle) For any v ∈GN ∩X′,
the ground state energy is
E(v) = min
ρ∈AN[FHK(ρ) +

v(x)ρ(x) d x].
(37.7)
It must be emphasized that this variational principle holds only for v ∈GN ∩X′
and ρ ∈AN. But we have three major problems: The sets GN and AN and the form
of the functional FHK are unknown. On one hand the Hohenberg–Kohn theory is an
enormous conceptual simpliﬁcation since it gives some hints that the semiclassical
density functional theories are reasonable approximations. On the other hand, the
existence Theorem 37.3 does not provide any practical method for calculating phys-
ical properties of the ground state from the one electron density ρ. In experiments
we measure ρ but we do not know what Hamilton operator HN(v) it belongs to.
The contents of the uniqueness theorem can be illustrated by an example. Consider
the N2 and CO molecules. They have exactly the same numbers of electrons and
nuclei, but whereas the former has a symmetric electron density this is not the case for
the latter. We are, therefore, able to distinguish between the molecules. Imagine now
that we add an external electrostatic potential along the bond for the N2 molecule.
The electron density becomes polarized and it is no more obvious to distinguish
between N2 and CO. But according to the Hohenberg–Kohn uniqueness theorem it
is possible to distinguish between the two molecules in a unique way.
The Hohenberg–Kohn variational principle provides the justiﬁcation for the
variational principle of Thomas Fermi in the sense that ETF(ρ) is an approxima-
tion to the functional E(ρ) associated with the total energy. Let us consider the

37.3
Hohenberg–Kohn Theory
571
functional Ev(ρ) = FHK(ρ) +

v(x)ρ(x) d x. The Hohenberg–Kohn variational
principle requires that the ground state density is a stationary point of the functional
Ev(ρ) −μ[

ρ(x) d x −N] which gives the Euler–Lagrange equation (assuming
differentiability)
μ = DEv(ρ) = v + DFHK(ρ),
(37.8)
where μ denotes the chemical potential of the system.
If we were able to know the exact functional FHK(ρ) we would obtain by this
method an exact solution for the ground state electron density. It must be noted that
FHK(ρ) is deﬁned independently of the external potential v; this property means
that FHK(ρ) is a universal functional of ρ. As soon as we have an explicit form
(approximate or exact) for FHK(ρ) we can apply this method to any system and the
Euler–Lagrange Eq. (37.8) will be the basic working equation of the Hohenberg–
Kohn density functional theory.A serious difﬁculty here is that the functional FHK(ρ)
is deﬁned only for those densities which are in the range of the map R, a condition
which, as already explained, is still unknown.
37.3.2
The Kohn–Sham Equations
The Hohenberg–Kohn uniqueness theorem states that all the physical properties of
a system of N interacting electrons are uniquely determined by its one-electron
ground state density ρ. This property holds independently of the precise form of
the electron–electron interaction. In particular when the strength of this interaction
vanishes the functional FHK(ρ) deﬁnes the ground state kinetic energy of a system
of noninteracting electrons as a functional of its ground state density T0(ρ). This fact
was used by Kohn and Sham [4] in 1965 to map the problem of interacting electrons
for which the form of the functional FHK(ρ) is unknown onto an equivalent problem
for noninteracting particles. To this end FHK(ρ) is written in the form
FHK(ρ) = T0(ρ) + 1
2
 ρ(x)ρ(y)
|x −y| d x d y + Exc(ρ).
(37.9)
The second term is nothing else than the classical electrostatic self-interaction, and
the term Exc(ρ) is called the exchange–correlation energy.
Variations with respect to ρ under the constraint ∥ρ∥1 = N leads formally to
the same equation which holds for a system of N noninteracting electrons under the
inﬂuence of an effective potential Vscf , also called the self-consistent ﬁeld potential
whose form is explicitly given by
vscf (x) = v(x) +

ρ ∗1
|x|

(x) + vxc(x),
(37.10)
where the term vxc(x) = DρExc(ρ) is called the exchange–correlation potential, as
the functional derivative of the exchange–correlation energy.

572
37
Density Functional Theory of Atoms and Molecules
There have been a number of attempts to remedy the shortcomings of the
Hohenberg–Kohn theory. One of the earliest and best known is due to E. Lieb
[14]. The literature we have mentioned before offers a variety of others. Though
some progress is achieved major problems are still unresolved. Therefore we cannot
discuss them here in our short introduction.
A promising direction seems to be the following. By Theorem 37.2 we know
that −E(v) is a convex continuous functional on X′. Hence (see [15]), it can be
represented as the polar functional of its polar functional (−E)∗:
−E(v) = sup
u∈X′′ [⟨v, u⟩−(−E)∗(u)]
∀v ∈X′],
(37.11)
where the polar functional (−E)∗is deﬁned on X′′ by
(−E)∗(u) = sup
v∈X′ [⟨v, u⟩−(−E)(v)]
∀u ∈X′′.
(37.12)
Now X = L2(R3) ∩L1(R3) is contained in the bi-dual X′′ but this bi-dual is much
larger (L1(R3) is not a reﬂexive Banach space) and L3(R3) ∩L1(R3) ⊂L2(R3) ∩
L1(R3). But one would like to have a representation of this form in terms of densities
ρ ∈AN ⊂L3(R3) ∩L1(R3), not in terms of u ∈X′′.
Remark 37.1 In Theorem 37.4, the densities are integrable functions on all of R3
which complicates the minimization problem in this theorem considerably, as we
had mentioned before in connection with global boundary and eigenvalue problems.
However having the physical interpretation of the functions ρ in mind as one-particle
densities of atoms or molecules, it is safe to assume that all the relevant densities have
a compact support contained in some ﬁnite ball in R3. Thus, in practice, one considers
this minimization problem over a bounded domain B with the beneﬁt that compact
Sobolev embeddings are available. As an additional advantage we can then work in
the reﬂexive Banach space L3(B) since L1(B) ⊂L3(B) instead of L1(R3)∩L3(R3).
37.4
Exercises
1. Prove Theorem 37.2.
Hints: For v1, v2 ∈X′ and 0 ≤t ≤1 show ﬁrst that HN(tv1 + (1 −t)v2) =
tHN(v1)+(1−t)HN(v2). Part a) now follows easily. For part b) consider v1, v2 ∈
X′ such that v1(x) ≤v2(x) for almost all x ∈R3 and show as a ﬁrst step:
⟨ψ, HN(v1)ψ⟩≤⟨ψ, HN(v2)ψ⟩for all ψ ∈WN, ∥ψ∥= 1.
For part c) proceed similarly and show |⟨ψ, (HN(v1) −HN(v2))ψ⟩|
≤
N ∥v1 −v2∥∞for all ψ ∈WN, ∥ψ∥= 1. This implies ±(E(v1) −E(v2) ≤
N ∥v1 −v2∥∞.
2. Show that the Coulomb energy functional D is weakly lower semi-continuous on
the Banach space L6/5(R3).
3. Prove: The Thomas–Fermi energy functional ETF is well deﬁned on the cone
DTF =

ρ ∈L5/3 ∩L1(R3) : ρ ≥0

.

References
573
References
1. Thomas LH. The calculation of atomic ﬁelds. Proc Camb Philos Soc. 1927;23:542–8.
2. Fermi E. Un metodo statistico per la determinazione di alcune proprieta dell’atome. Rend
Accad Naz Lincei. 1927;6:602–7.
3. Hohenberg P, Kohn W. Inhomogeneous electron gas. Phys Rev B. 1964;136:864 – 71.
4. Kohn W, Sham LJ. Self consistent equations including exchange and correlation effects. Phys
Rev A. 1965;140:1133–8.
5. Davies EB. Quantum theory of open systems. London: Academic Press; 1976.
6. ParrRG,YangW.Densityfunctionaltheoryofatomsandmolecules. Oxford: OxfordUniversity
Press; 1989.
7. Dreizler RM, Gross EKU. Density functional theory. New York: Springer-Verlag; 1990.
8. NagyA. Density functional and application to atoms and molecules. Phys Rep. 1998;298:1–79.
9. Eschrig H. The fundamentals of density functional theory. Leipzig: Teubner Verlag; 1996.
10. Blanchard P, Gracia-Bondia J, Varilly J. Density functional theory on phase space. Int J
Quantum Chem. 2012;112(4):1134–64.
11. Lieb E, Simon B. The Thomas – Fermi theory of atoms, molecules and solids. Adv Math.
1977;23:22–116.
12. Blanchard Ph, Brüning E. Variational methods in mathematical physics. A uniﬁed approach.
Texts and monographs in physics. Berlin: Springer-Verlag; 1992.
13. Lieb E, Loss M.Analysis. Graduate studies in mathematics. Vol. 14, 2nd ed. AMS, Providence,
Rhode Island; 2001.
14. Lieb E. Density functionals for Coulomb systems. Int J Quantum Chem. 1983;XXIV:243–77.
15. Ekeland I, Turnbull T. Inﬁnite dimensional optimization and convexity. Chicago lectures in
mathematics. Chicago: University of Chicago Press; 1983.

Appendix A
Completion of Metric Spaces
A metric on a set X is a function d : X × X →R with these properties:
(D1)
d(x1, x2) ≥0,
(D2)
d(x1, x2) = d(x2, x1),
(D3)
d(x1, x2) ≤d(x1, x) + d(x, x2),
(D4)
d(x1, x2) = 0 ⇔x1 = x2.
for all x, x1, x2 ∈X. A set X on which a metric d is given is called a metric space
(X, d). Sets of the form
B(x, r) = {y ∈X : d(y, x) < r}
are called open balls in (X, d) with center x and radius r > 0. These balls are used
to deﬁne the topology Td on X.
A sequence (xn)n∈N in (X, d) is called a Cauchy sequence if, and only if, the
distance d(xn, xm) of the elements xn and xm of this sequence goes to zero as n, m →
∞. A metric space (X, d) is called complete if, and only if, every Cauchy sequence
has a limit x in (X, d), i.e., if, and only if, for every Cauchy sequence (xn)n∈N there
is a point x ∈X such that limn→∞d(x, xn) = 0.
In the text we encountered many examples of metric spaces and in many appli-
cations it was very important that these metric spaces were complete, respectively
could be extended to complete metric spaces. We are going to describe in some detail
the much used construction which enables one to “complete” every incomplete space
by “adding the missing points.” The model for this construction is the construction
of the space of real numbers as the space of equivalence classes of Cauchy sequences
of rational numbers. A complete metric space (Y, D) is called a completion of the
metric space (X, d) if, and only if, (Y, D) contains a subspace (Y0, D0) which is
dense in (Y, D) and which is isometric to (X, d). The following result ensures the
existence of a completion.
Theorem A.1 Every metric space (X, d) has a completion (Y, D). Every two com-
pletions of (X, d) are isomorphic under an isometry which leaves the points of X
invariant.
© Springer International Publishing Switzerland 2015
575
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2

576
Appendix A Completion of Metric Spaces
Proof Denote by S = S(X, d) the set of all Cauchy sequences x = (xn)n∈N in the
metric space (X, d). Given x, y ∈S one has the estimate
|d(xn, yn) −d(xm, ym)| ≤d(xn, xm) + d(yn, ym)
which shows that (d(xn, yn))n∈N is a Cauchy sequence in the ﬁeld R and thus
converges. This allows one to deﬁne a function d1 : S × S →R by
d1(x, y) = lim
n→∞d(xn, yn).
Obviously the function d1 has the properties (D1) and (D2) of a metric. To verify the
triangle inequality (D3) observe that for any x, y, z ∈S and all n ∈N we have
d(xn, yn) ≤d(xn, zn) + d(zn, yn).
The standard calculation rules for limits imply that this inequality also holds in the
limit n →∞and thus proves (D3) for the function d1. The separation property
(D4) however does not hold for the function d1. Therefore we introduce in S an
equivalence relation which expresses this separation property.
Two Cauchy sequences x, y ∈S are called equivalent if, and only if, d1(x, y) = 0.
We express this equivalence relation by x ∼y. The properties established thus far for
the function d1 imply that this is indeed an equivalence relation on S. The equivalence
class determined by the element x ∈S is denoted by [x], i.e., [x] = {y ∈S : y ∼x}.
The space of all these equivalence classes is called Y, Y = {[x] : x ∈S}. Next deﬁne
a function D : Y × Y →R by
d([x], [y]) = d1(x, y)
where x, y are any representatives of their respective classes. One shows that D is
well deﬁned, i.e., independent of the chosen representative: Suppose x′ ∼x, then
the triangle inequality for the function d1 gives
d1(x, y) ≤d1(x, x′) + d1(x′, y) = d1(x′, y) ≤d1(x′, x) + d1(x, y) = d1(x, y),
which shows that d1(x, y) = d1(x′, y) whenever x ∼x′. By deﬁnition, the function
D satisﬁes the separation property (D4):
d([x], [y]) = 0 ⇔[x] = [y].
We conclude that D is a metric on the set Y, hence (Y, D) is a metric space.
Next we embed the given metric space into (Y, D). For every x ∈X consider the
constant sequence x0 = (x, x, x, . . . ). Clearly x0 ∈S and thus a map τ : X →Y is
well deﬁned by
τ(x) = [x0]
∀x ∈X.

Appendix A Completion of Metric Spaces
577
By the deﬁnition of D, respectively d1, we have
D(τ(x), τ(y)) = d1(x0, y0) = d(x, y)
for all x, y ∈X, hence the map τ is isometric.
Given [x] ∈Y choose a representative x = (x1, x2, x3, . . .) of this class. Then the
sequence (τ(xn))n∈N converges to [x]:
lim
n→∞D(τ(xn), [x]) = lim
n→∞d1(xn
0, x) = lim
n→∞lim
m→∞d(xn, xm) = 0.
We conclude that the image Y0 = τ(X) of X under the isometry τ is dense in (Y, D).
Finally we prove completeness of the metric space (Y, D). Suppose ([yn])n∈N
is a Cauchy sequence in (Y, D). Since Y0 is dense in (Y, D) there is a sequence
(τ(xn))n∈N ⊂Y0 such that D(τ(xn), [yn]) ≤
1
n for each n. It is easy to see that
the sequences (τ(xn))n∈N and ([yn])n∈N either both converge or both diverge. Now
observe that x = (x1, x2, x3, . . .) is a Cauchy sequence in the given metric space
(X, d):
d(xn, xm) = D(τ(xn), τ(xm))
≤D(τ(xn), [yn]) + D([yn], [ym]) + D([ym], τ(xm))
≤1
n + D([yn], [ym]) + 1
m.
Since ([yn])n∈N is a Cauchy sequence in (Y, D) the statement follows immediately
and therefore [x] ∈Y. The identity
lim
n→∞D(τ(xn), [x]) = lim
n→∞lim
m→∞d(xn, xm) = 0
provesthatthesequence(τ(xn))n∈N convergesto[x]inthemetricspacein(Y, D). The
construction of the points xn implies that the given Cauchy sequence too converges
to [x] in (Y, D). Hence this space is complete.
Since we do not use the second part of the theorem we leave its proof as an
exercise.
2
Corollary A.1 Every normed space (X0, ∥·∥0) has a completion which is a Banach
space (X, ∥· ∥). Every inner product space (H0, ⟨·, ·⟩0) has a completion which is a
Hilbert space (H, ⟨·, ·⟩).
Proof We only comment on the proof. It is a good exercise to ﬁll in the details.
According to Theorem A.1 we only know that the normed space, respectively the
inner product space, have a completion as a metric space. But since the original space
X0, respectively H0, carries a vector space structure, the space of Cauchy sequences
of elements of these spaces too can be given a natural vector space structure. The
same applies to the space of equivalence classes of such Cauchy sequences. Finally
one has to show that the given norm, respectively the given inner product, has a
natural extension to this space of equivalence classes of Cauchy sequences which is
again a norm, respectively an inner product. Then the proof of completeness of these
spaces is as above.
2

Appendix B
Metrizable Locally Convex Topological Vector
Spaces
A Hausdorff locally convex topological vector space (X, P) is called metrizable if,
and only if, there is a metric d on X which generates the given topology TP, i.e., if
Td denotes the topology generated by the metric d, one has TP = Td. Recall that
two different metrics might generate the same topologies. In such a case the two
metrics are called equivalent. Important and big classes of Hausdorff locally convex
topological vector spaces are indeed metrizable.
Theorem B.1 Every Hausdorff locally convex topological vector space (X, P) with
countable system P = {pj : j ∈N} of continuous seminorms pj is metrizable. A
translation invariant metric which generates the given topology is
d(x, y) =
∞

j=1
1
2j
pj(x −y)
1 + pj(x −y)
∀x, y ∈X.
(B.1)
Proof All the seminorms pj are continuous for the topology TP and the series (B.1)
converges uniformly on X × X. Therefore this series deﬁnes a continuous function
d on (X, TP) × (X, TP). This function d obviously satisﬁes the deﬁning conditions
(D1) and (D2) of a metric. The separation property (D4) holds since the space (X, P)
is Hausdorff.
In order to show the triangle inequality (D3) observe ﬁrst that for any x, y, z ∈X
one has
pj(x −y)
1 + pj(x −y) ≤
pj(x −z)
1 + pj(x −z) +
pj(z −y)
1 + pj(z −y)
since all terms are nonnegative and pj(x −y) ≤pj(x −z) + pj(z −y). Summation
now implies the triangle inequality for the function d which thus is a metric on X.
Obviously this metric d is translation invariant:
d(x + z, y + z) = d(x, y)
∀x, y, z ∈X.
Since the metric d is continuous for the topology TP, the open balls Bd(x, r) for the
metric d are open in (X, TP). Since these open balls generate the topology Td, we
conclude that the topology TP is ﬁner than the metric topology Td, Td ⊆TP.
© Springer International Publishing Switzerland 2015
579
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2

580
Appendix B Metrizable Locally Convex Topological Vector Spaces
In order to show the converse TP ⊆Td we prove that every element V of a
neighborhood basis of zero for the topology TP contains an open ball Bd(0, r) with
respect to the metric d. Suppose
V = ∩k
i=1Bpi(0, ri)
with ri > 0 for i = 1, . . . , k is given. Choose some number r0,
0 < r0 < min
+
2−k, 2−iri
1 + ri
, i = 1, . . . , k
,
.
Then for ﬁxed r, 0 < r ≤r0, and every x ∈Bd(0, r) we know by Eq. (B.1) that
2−i
pi(x)
1 + pi(x) ≤d(x, 0) < r,
i = 1, . . . , k.
These inequalities together with the choice of r ≤r0 imply immediately pi(x) < ri,
i = 1, . . . , k, hence x ∈V and thus Bd(0, r) ⊆V which proves TP ⊆Td.
2
Two examples of Hausdorff locally convex topological vector spaces which are
metrizable and which were used in the text are the spaces DK(Ω) and S(Rn).
Recall that for an open and nonempty set Ω ⊂Rn and a compact subset K ⊂
Ω, the space DK(Ω) consists of all C∞-functions on Ω which have their support
in K. The topology of this space is generated by the countable system of norms
qK,m : m = 0, 1, 2, . . . ; the space DK(Ω) is metrizable according to Theorem B.1.
In Proposition 2.4 we had indicated a proof of its completeness. Hence DK(Ω) is a
complete metrizable Hausdorff locally convex topological vector space.
The space S(Rn) is deﬁned as the space of all those C∞-functions on Rn which,
with all their derivatives, decay faster than constant × (1 + x2)−k/2 for any k =
0, 1, 2 . . . . The countable system {pm,k : k, m = 0, 1, 2, . . . } of norms deﬁnes the
topology of S(Rn). It is a good exercise to prove that this space too is complete.
Therefore the space S(Rn) is a complete metrizable Hausdorff topological vector
space.

Appendix C
The Theorem of Baire
On an open nonempty set Ω ⊆Rn consider a sequence of continuous functions
fn : Ω →R and suppose that this sequence has a “pointwise” limit f , i.e., for every
x ∈Ω the limit limn→∞fn(x) = f (x) exists. Around 1897, Baire investigated the
question whether the limit function f is continuous on Ω. He found that this is not
the case in general and he found that the set of points in Ω at which the limit function
f is not continuous is a “rather small subset of Ω.” Naturally a precise meaning had
to be given to the expression of a “rather small subset of Ω.” In this context Baire
suggested the concept of subset of ﬁrst category in Ω, i.e., subsets of Ω which can
be represented as a countable union of nowhere dense sets. And a subset A ⊂Ω
is called nowhere dense in Ω if, and only if, the closure A in Ω has no interior
points. Later the subsets of ﬁrst category in Ω were given the more intuitive name
of a meager subset. All subsets which are not of the ﬁrst category are called subsets
of the second category or nonmeager subsets.
Note the following simple implication of the deﬁnition of a nowhere dense subset.
If B ⊂Ω is nowhere dense, then A = Ω\B is an open and dense subset of Ω,
Ω = A. Thus Baire reduced the above statement about the set of points of continuity
of the limit function f to the following statement.
Theorem C.1 (Theorem of Baire, Version 1) If Aj, j ∈N, is a countable family
of open and dense subsets of an open nonempty subset Ω ⊂Rn, then the intersection
A = ∩∞
j=1Aj
(C.1)
is also dense in Ω.
Proof
Given an open ball B0 = B(x0, r0) = {x ∈Rn : ∥x −x0∥< r0} in Ω we
have to show that A ∩B0 is not empty.
Since A1 is an open and dense subset of Ω we know that A1 ∩B0 is an open
nonempty subset of B0. Hence there is an open ball
B1 = B(x1, r1) = {x ∈Rn : ∥x −x1∥< r1}
with B1 ⊂A1 ∩B0. We can and will assume that 0 < r1 ≤r0/2. By the same
reasoning A2 ∩B1 is an open nonempty subset of B1. Hence there is an open ball
B2 = B(x2, r2) ⊂Ω with the property B2 ⊂A2 ∩B1 and 0 < r2 ≤r1/2.
© Springer International Publishing Switzerland 2015
581
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2

582
Appendix C The Theorem of Baire
These arguments can be iterated and thus produce a sequence of open balls Bk =
B(xk, rk) satisfying
Bk+1 ⊂Ak ∩Bk,
rk+1 ≤rk
2 , k = 1, 2, . . . .
Perconstructionrk ≤2−kr0 andxk+m ∈Bk forallm ≥0, hence∥xk+m−xk∥≤2−kr0
for all k, m = 0, 1, 2, . . . . We conclude that the sequence of centers xk of these balls
Bk is a Cauchy sequence in Rn and thus converges to a unique point
y = lim
k→∞xk ∈∩∞
k=1Bk = M.
According to the construction of these balls we get that M ⊂B0 and M ⊂Ak for
all k ∈N and thus we conclude that M ⊂A ∩B0.
2
Some years later Banach and Steinhaus realized that Baire’s proof did not use the
special structure of the Euclidean space Rn. The proof relies on two properties of
Rn: Rn is a metric space and Rn is complete (with respect to the metric). Thus Banach
and Steinhaus formulated the following result which nowadays usually is called the
theorem of Baire.
Theorem C.2 (Theorem of Baire, Version 2) Suppose that (X, d) is a complete
metric space and Ω ⊂X an open nonempty subset of X. Then the intersection
A = ∩i∈NAi of a countable family of open and dense subsets Ai of Ω is again dense
in Ω.
Proof The proof of Version 1 applies when we replace the Euclidean balls B(x, r)
by the open balls Bd(x, r) = {y ∈X : d(y, x) < r} of the metric space (X, d).
2
In most applications of Baire’s theorem however the following “complementary”
version is used.
Theorem C.3 (Theorem of Baire, Version 3) Suppose (X, d) is a complete metric
space and Bi, i ∈N, is a countable family of closed subsets of X such that
X = ∪∞
i=1Bi.
(C.2)
Then at least one of the sets Bi has a nonempty interior.
Proof
If all the closed sets Bi had an empty interior, then Ai = X\Bi, i ∈N,
would be a countable family of open and dense subsets of X. The second version of
Baire’s theorem implies that A = ∩i∈NAi is dense in X, thus Ac = X\A ̸= X, a
contradiction since Ac = ∪i∈NBi. Therefore, at least one of the sets Bi must have a
nonempty interior.
2
Deﬁnition C.1 A topological space X in which the third version of Baire’s theorem
holds, is called a Baire space.
Thus a Baire space X can be exhausted by a countable family of closed subsets
Bi only when at least one of the subsets Bi has a nonempty interior. Then the third
versionofBaire’stheoremcanberestatedassayingthatallcompletemetricspacesare
Baire spaces. It follows immediately that all complete metrizable Hausdorff locally

Appendix C The Theorem of Baire
583
convex topological vector spaces are Baire spaces. In particular, every Banach space
is a Baire space. The spaces of functions DK(Ω) and S(Rn) which play a fundamental
rôle in the theory of distributions are Baire spaces.
C.1
The Uniform Boundedness Principle
The results of Baire and Banach–Steinhaus have found many very important appli-
cations in functional analysis. The most prominent one is the uniform boundedness
principle which we are going to discuss in this section. It has been used in the text
for many important conclusions.
Deﬁnition C.2 Suppose (X, P) and (Y, Q) are two Hausdorff locally convex topo-
logical vector spaces over the ﬁeld K. Denote the set of linear functions T : X →Y
with L(X, Y). A subset Λ ⊂L(X, Y) is called
a) pointwise bounded if, and only if, for every x ∈X the set {T x : T ∈Λ} is
bounded in (Y, Q), i.e., for every seminorm q ∈Q,
sup{q(T x) : T ∈Λ} = Cx,q < ∞;
b) equi-continuous if, and only if, for every seminorm q ∈Q there is a seminorm
p ∈P and a constant C ≥0 such that
q(T x) ≤Cp(x)
∀x ∈X, ∀T ∈Λ.
Obviously, the elements of an equi-continuous family of linear mappings are con-
tinuous and such a family is pointwise bounded. For an important class of spaces
(X, P) the converse holds too, i.e., a pointwise bounded family of continuous linear
mappings Λ ⊂L(X, Y) is equi-continuous.
Theorem C.4 (Theorem of Banach–Steinhaus) Assume that two Hausdorff lo-
cally convex topological vector spaces over the ﬁeld K, (X, P) and (Y, Q), are given
and assume that (X, P) is a Baire space. Then every bounded family Λ of continuous
linear mappings T : X →Y is equi-continuous.
Proof For an arbitrary seminorm q ∈Q introduce the sets
UT ,q = {x ∈X : q(T x) ≤1},
T ∈Λ.
Since T is a continuous linear map, the set UT ,q is a closed absolutely convex subset
of (X, P). Hence
Uq =

T ∈Λ
UT ,q
is closed and absolutely convex too.
Now given a point x ∈X the family Λ is bounded in this point, i.e., for every
q ∈Q there is a Cx,q < ∞such that q(T x) ≤Cx,q for all T ∈Λ. Choose n ∈N,

584
Appendix C The Theorem of Baire
n ≥Cx,q; then for all T ∈Λ we ﬁnd q(T (x/n)) = 1
nq(T x) ≤1
nCx,q ≤1, hence
1
nx ∈Uq or x ∈nUq. Clearly, with Uq also the set nUq is closed (and absolutely
convex); thus X is represented as the countable union of the closed sets nUq:
X =

n∈N
nUq.
Since (X, P) is assumed to be a Baire space, at least one of the sets nUq must
have a nonempty interior, hence Uq has a nonempty interior, i.e., there are a point
x0 ∈Uq, seminorms p1, . . . , pN ∈P and positive numbers r1, . . . , rN such that V =
∩n
j=1Bpj (x0, rj) ⊂Uq. Nowchoosep = max{p1, . . . , pn}andr = min{r1, . . . , rN}.
We have p ∈P, r > 0, and Bp(x0, r) ⊂V ⊂Uq. The deﬁnition of Uq implies
q(T x) ≤1 for all x ∈Bp(x0, r) and all T ∈Λ. Hence for every ξ ∈Bp(0, r) and
every T ∈Λ: q(T ξ) ≤q(T (x0 + ξ)) + q(T x0) ≤1 + q(T x0) = C. Lemma 2.2 now
implies
q(T x) ≤C
r p(x)
∀x ∈X,
∀T ∈Λ
which proves that the family Λ is equi-continuous.
2
The Banach–Steinhaus theorem has many applications in functional analysis. We
mention some of them which are used in our text. They are just special cases for the
choice of the domain space (X, P) which has to be a Baire space.
Every Banach space X is a Baire space. Therefore Theorem C.4 applies. Given a
family {Tα : α ∈A} of continuous linear maps Tα : X →K which is pointwise or
weakly bounded, then, for every x ∈X, there is a constant Cx such that
sup{|Tα(x)| : α ∈A} ≤Cx < ∞.
According to the Banach–Steinhaus theorem such a family is equi-continuous, i.e.,
there is a constant C < ∞such that
|Tα(x)| ≤C∥x∥
∀x ∈X,
∀α ∈A
and therefore
sup
α∈A
∥Tα∥≤C.
Hence the family {Tα : α ∈A} is not only pointwise bounded, it is uniformly or
norm bounded: This is the uniform boundedness principle in Banach spaces, see
also Theorem C.4.
Earlier in this appendix we had argued that the spaces DK(Ω), Ω ⊆Rn, K ⊂Ω
compact, are Baire spaces. Thus the Banach–Steinhaus theorem applies to them.
Suppose {Tα : α ∈A} ⊂D′
K(Ω) is a pointwise bounded family of continuous
linear forms on DK(Ω), i.e., for every f ∈DK(Ω) there is a Cf < ∞such that
|Tα(f )| ≤Cf for all α ∈A. Theorem C.4 implies that this family is equi-continuous,
i.e., there is an m ∈N and a constant C such that
|Tα(f )| ≤CqK,m(f )
∀f ∈DK(Ω),
∀α ∈A.
Now we come back to the problem of continuity of the pointwise limit of contin-
uous functions which were the starting point of Baire’s investigations. We consider

Appendix C The Theorem of Baire
585
continuous linear functions on Hausdorff locally convex topological vector spaces.
For the case of continuous nonlinear functions on ﬁnite dimensional spaces we refer
to the Exercises (this case is more involved).
Theorem C.5 Suppose (Tj)j∈N is a sequence of continuous linear functionals on
a Hausdorff topological vector space (X, P) with the property that for every x ∈X
the numerical sequence (Tj(x))j∈N is a Cauchy sequence. Then:
a) A linear functional T is well deﬁned on X by
T (x) = lim
j→∞Tj(x)
∀x ∈X.
b) If (X, P) is a Baire space, then the functional T deﬁned in a) is continuous.
Proof Since the ﬁeld K is complete, the Cauchy sequence (Tj(x))j∈N converges in
K. We call its limit T (x). Thus a function T : X →K is well deﬁned. Basic rules of
calculations for limits now prove linearity of this function T .
Cauchy sequences in the ﬁeld K are bounded, hence, for every x ∈X there is a
ﬁnite constant Cx such that sup{|Tj(x)| : j ∈N} ≤Cx. The theorem of Banach–
Steinhaus implies that this sequence is equi-continuous, i.e., there is some p ∈P
and there is a ﬁnite constant C such that |Tj(x)| ≤Cp(x) for all x ∈X and all j ∈N.
Taking the limit j →∞in this estimate we get |T (x)| ≤Cp(x) for all x ∈X and
thus T is continuous.
2
Part b) of this theorem is often formulated in the following way.
Corollary C.1 The topological dual space X′ of a Hausdorff locally convex Baire
space (X, P) is weakly sequentially complete.
And as a special case of this result we have:
Corollary C.2 The spaces of distributions D′(Ω), Ω ⊂Rn open and nonempty,
and S′(Rn) are weakly sequentially complete.
Proof The main point of the proof is to establish that the spaces DK(Ω), K ⊂Ω
compact, and S(Rn) are complete metrizable and thus Baire spaces. But this has
already been done.
2
Finally we use Baire’s theorem to show in a relatively simple way that the test
function spaces D(Ω), Ω ⊂Rn open and nonempty, are not metrizable.
To this end we recall that the spaces DK(Ω), K ⊂Ω compact, are closed in
D(Ω). Furthermore there is a sequence of compact sets Kj ⊂Kj+1 for all j ∈N
such that Ω = ∪j∈NKj. It follows that
D(Ω) = ∪j∈NDKj (Ω).
If D(Ω) were metrizable, then according to the third version of Baire’s theorem one
of the spaces DKj (Ω) must have a nonempty interior which obviously is not the case
(to show this is a recommended exercise).
Proposition C.1 The test function spaces D(Ω), Ω ⊂Rn open and nonempty, are
complete nonmetrizable Hausdorff locally convex topological vector spaces.

586
Appendix C The Theorem of Baire
Proof
In the book [1] one ﬁnds a proof of this result which does not use Baire’s
theorem (see Theorem 28, page 71).
2
C.2
The Open Mapping Theorem
This section introduces other frequently used consequences of Baire’s results. These
consequences are the open mapping theorem and its immediate corollary, the inverse
mapping theorem.
Deﬁnition C.3 A mapping T : E →F between two topological spaces is called
open if, and only if, T (V ) is open in F for every open set V ⊂E.
Our main interest here are linear open mappings between Banach spaces. Thus
the following characterization of these mappings is very useful.
Lemma C.1 A linear map T : E →F between two normed spaces E, F is open
if, and only if,
∃r > 0 :
BF
r ⊆T (BE
1 )
(C.3)
where BE
1 is the open ball in E with radius 1 and center 0 and BF
r the open ball in
F with radius r > 0 and center 0.
Proof
If T is an open mapping, then T (BE
1 ) is an open set in F which contains
0 ∈F since T is linear. Hence there is an r > 0 such that relation (C.3) holds.
Conversely assume that relation (C.3) holds and that V ⊂E is open. Choose
any y = T x ∈T (V ). Since V is open there is a ρ > 0 such that x + BE
ρ ⊂V .
It follows that y + T (BE
ρ ) = T (x + BE
ρ ) ⊂T (V ). Relation (C.3) implies that
BF
ρr = ρBF
r
⊂ρT (BE
1 ) = T (BE
ρ ) and thus y + BF
ρr ⊂T (V ). Therefore y is an
interior point T (V ) and we conclude.
2
Theorem C.6 (Open Mapping Theorem) Let E, F be two Banach spaces and
T : E →F a surjective continuous linear mapping. Then T is open.
Proof For a proof one has to show relation (C.3). This will be done in two steps.
For simplicity of notation the open balls in E of radius r > 0 and center 0
are denoted by Br. Since obviously B1/2 −B1/2 ⊂B1 and since T is linear we
have T (B1/2) −T (B1/2) ⊂T (B1). In any topological vector space for any two
sets A, B the relation A −B ⊂A −B for their closures is known. This implies
T (B1/2) −T (B1/2) ⊂T (B1).
Surjectivity and linearity of T give
F = ∪∞
k=1 kT (B1/2).
As a Banach space, F is a Baire space and therefore at least one of the sets kT (B1/2),
k ∈N, must have a nonempty interior. Since y #→ky is a surjective homeomorphism
of F the set T (B1/2) has a nonempty interior, i.e., there is some open nonempty set V

Appendix C The Theorem of Baire
587
in F which is contained in T (B1/2), and hence V −V ⊂T (B1/2)−T (B1/2) ⊂T (B1).
V −V is an open set in F which contains 0 ∈F. Therefore there is some r > 0
such that BF
r ⊂V −V and we conclude
BF
r ⊂T (B1).
(C.4)
In the second step we use relation (C.4) to deduce Relation C.3. Pick any y ∈Vr ≡
BF
r , then ∥y∥F < r and we can choose some R ∈(∥y∥F, r). Now rescale y to
y′ =
r
Ry. Clearly ∥y′∥F < r and therefore y′ ∈Vr ⊂T (B1). Since 0 < R
r < 1
there is 0 < a < 1 such that R
r + a < 1, i.e., R
r
1
1−a < 1. Since y′ belongs to
the closure of the set T (B1) there is a y0 ∈T (B1) such that ∥y′ −y0∥F < ar. It
follows that z0 = 1
a (y′ −y0) ∈Vr and by the same reason there is a y1 ∈T (B1) such
that ∥z0 −y1∥F < ar, and again z1 = 1
a (z0 −y1) ∈Vr and there is a y2 ∈T (B1)
such that ∥z1 −y2∥F < ar. By induction this process deﬁnes a sequence of points
y0, y1, y2, . . . in T (B1) which satisﬁes
-----y′ −
n

i=0
aiyi
-----
F
< an+1r,
n = 1, 2, . . . .
(C.5)
Estimate (C.5) implies y′ = ∞
i=0 aiyi. By construction yi = T (xi) for some
xi ∈B1. Since ∥aixi∥< ai for all i and since E is complete, the series ∞
i=0 aixi
converges in E. Call the limit x′. A standard estimate gives
--x′--
E ≤
∞

i=0
ai =
1
1 −a .
Continuity of T implies T (x′) = ∞
i=0 ai T (xi) = y′ and if we introduce x = R
r x′
we get T (x) = R
r y′ = y. By choice of the parameter a the limit x actually belongs
to B1. This follows from ∥x∥E = R
r
--x′--
E < R
r
1
1−a < 1. We conclude that y ∈Vr
is the image under T of a point in B1. Since y was any point in Vr this completes the
proof.
2
Corollary C.3 (Inverse Mapping Theorem) A continuous linear map T from a
Banach space E onto a Banach space F which is injective has a continuous inverse
T −1 : F →E and there are positive numbers r and R such that
r ∥x∥E ≤∥T x∥F ≤R ∥x∥E
∀x ∈E.
Proof
Such a map is open and thus T satisﬁes relation (C.3) which implies im-
mediately that the inverse T −1 is bounded on the unit ball BF
1 by 1
r , hence T −1 is
continuous and its norm is ≤1
r . The two inequalities just express continuity of T
(upper bound) and of T −1 (lower bound).
2

588
Appendix C The Theorem of Baire
If E, F are two Banach spaces over the same ﬁeld, then E × F is a Banach space
too when the vector space E × F is equipped with the norm
∥(x, y)∥= ∥x∥E + ∥y∥F .
The proof is a straightforward exercise. If T : E →F is a linear mapping, then its
graph
G(T ) = {(x, y) ∈E × F : y = T x}
is a linear subspace of E × F. If the graph G(T ) of a linear mapping T is closed in
E×F the mapping T is called closed. Recall that closed linear mappings or operators
have been studied in some detail in the context of Hilbert spaces (Sect. 19.2).
Theorem C.7 (Closed Graph Theorem) If T : E →F is a linear mapping from
the Banach space E into the Banach space F whose graph G(T ) is closed in E ×F,
then T is continuous.
Proof As a closed subspace of the Banach space E ×F the graph G(T ) is a Banach
space too, under the restriction of the norm ∥·∥to it. Deﬁne the standard projection
mappings p : G(T ) →E and q : G(T ) →F by p(x, y) = x, respectively
q(x, y) = y. Since G(T ) is the graph of a linear mapping, both p and q are linear
and p is injective. By deﬁnition, p is surjective too. Continuity of p and q follow
easily from the deﬁnition of the norm on G(T ): ∥p(x, y)∥E = ∥x∥E ≤∥x∥E +∥y∥F
and similarly for q. Hence p is a bijective continuous linear map of the Banach
space G(T ) onto the Banach space E and as such has a continuous inverse, by the
inverse mapping theorem. Thus T is represented as the composition q ◦p−1 of two
continuous linear mappings, T (x) = q ◦p−1(x), for all x ∈E, and therefore T is
continuous.
2

Appendix D
Bilinear Functionals
A functional of two variables from two vector spaces is called bilinear if, and only
if, the functional is linear in one variable while the other variable is kept ﬁxed. For
such functionals there are two basic types of continuity. The functional is continuous
with respect to one variable while the other is kept ﬁxed, and the functional is con-
tinuous with respect to simultaneous change of both variables. Here we investigate
the important question for which Hausdorff locally convex topological vector spaces
both concepts of continuity agree.
Deﬁnition D.1 Let(X, P)and(Y, Q)betwoHausdorfflocallyconvexvectorspaces
over the ﬁeld K and B : X × Y →K a bilinear functional. B is called
a) separately continuous if, and only if, for every x ∈X there are a constant
Cx and a seminorm qx ∈Q such that |B(x, y)| ≤Cxqx(y) for all y ∈Y, and
for every y ∈Y there are a constant Cy and a seminorm py ∈P such that
|B(x, y)| ≤Cypy(x) for all x ∈X.
b) continuous if, and only if, there are a constant C and seminorms p ∈P and
q ∈Q such that |B(x, y)| ≤Cp(x)q(y) for all x ∈X and all y ∈Y.
Obviously, every continuous bilinear functional is separately continuous. The con-
verse statement does not hold in general. However for a special but very important
class of Hausdorff topological vector spaces one can show that separately continuous
bilinear functionals are continuous.
Theorem D.1
Suppose that (X, P) and (Y, Q) are two Hausdorff locally convex
metrizable topological vector spaces and assume that (X, P) is complete. Then every
separately continuous bilinear functional B : X × Y →K is continuous.
Proof For metrizable Hausdorff locally convex topological vector spaces continuity
and sequential continuity are equivalent. Thus we can prove continuity of B by
showing that B(xj, yj) →B(x, y) whenever xj →x and yj →y as j →∞.
Suppose such sequences (xj)j∈N and (yj)j∈N are given. Deﬁne a sequence of linear
functionals Tj : X →K by Tj(x) = B(x, yj) for all j ∈N. Since B is separately
continuous all the functionals Tj are continuous linear functionals on (X, P). Since
the sequence (yj)j∈N converges in (Y, Q) we know that Cq,x = supj∈N qx(yj) is ﬁnite
© Springer International Publishing Switzerland 2015
589
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2

590
Appendix D Bilinear Functionals
for every ﬁxed x ∈X. Hence separate continuity implies
sup
j∈N
|Tj(x)| ≤CxCq,x
where the constant Cx refers to the constant in the deﬁnition of separate continu-
ity. This shows that (Tj)j∈N is a point-wise bounded sequence of continuous linear
functionals on the complete metrizable Hausdorff locally convex topological vec-
tor space (X, P). The Theorem of Banach–Steinhaus implies that this sequence is
equi-continuous. Hence there are a constant C and a seminorm p ∈P such that
|Tj(x)| ≤Cp(x) for all x ∈X. This gives
|B(xj, yj) −B(x, y)| ≤|Tj(xj −x)| + |B(x, yj −y)| ≤Cp(xj −x)
+ |B(x, yj −y)| →0
as j →∞. Therefore B is sequential continuous and thus continuous.
2
An application which is of interest in connection with the deﬁnition of the tensor
product of distributions (see Sect. 6.2) is the following. Suppose Ωj ⊂Rnj are open
and nonempty subsets and Kj ⊂Ωj are compact, j = 1, 2. Then the spaces DKj (Ωj)
are complete metrizable Hausdorff locally convex topological vector spaces. Thus
every separately continuous bilinear functional DK1(Ω1) × DK2(Ω2) →K is
continuous.
Reference
1. Kirilov AA, Gvisbiani AD. Theorems and problems in functional analysis. NewYork: Springer-
Verlag; 1982.

Index
A
adjoint, 45
adjoint operator, 280
almost periodic functions, 253
angle
between two vectors, 217
B
Baire space, 582
Banach
reﬂexive
examples of, 513
Banach algebra
involutive or ∗, 455
bilinear form, 589
continuous, 589
separately continuous, 589
boundary value, 164
bounded
linear function, 17
pointwise, 271, 583
uniformly or norm, 271
Breit–Wigner formula, 35
C
C∗-algebra, 456
calculus of variations, 503
Carathéodory functions, 554
carrier, 173
Cauch–Riemann equations, 131
Cauchy estimates, 125
Cauchy sequence
in D′(Ω), 33
Cauchy’s integral formula I, 123
Cauchy’s integral formula II, 123
Cauchy’s principal value, 31
chain rule, 53
change of variables, 53
Choi matrix, 494
Choi-Jamiolkowski isomorphism, 496
class Cn, 522
coercive, 515
commutation relations
of Heisenberg, 312
compact
locally, 266
relatively, 513
sequentially, 511
compact operators
dual space of, 374
complete, 218, 241
sequentially, 16
completeness relation, 242
completion
of a normed space, 577
of an inner product space, 577
constraint, 537
continuous
at x0, 16
on X, 16
convergence
of sequences of distributions, 33
of series of distributions, 38
convex, 528
convex minimization, 514
convolution
- product of functions, 85
equation, 101
in S(Rn), 87
of distributions, 95
© Springer International Publishing Switzerland 2015
591
P. Blanchard, E. Brüning, Mathematical Methods in Physics,
Progress in Mathematical Physics 69, DOI 10.1007/978-3-319-14045-2

592
Index
core
of a linear operator, 287
of a quadratic form, 296
cyclic vector, 456
of a self-adjoint operator, 447
D
delta function
Dirac’s, 3
delta sequences, 33
density matrix
or statistical operator, 388
derivative, 520
of a distribution, 46
weak or distributional, 63
Dido, 504
Dido’s problem, 543
differentiable
twice, 522
direct method
of the calculus of variations, 506
direct orthogonal sum, 229
direct sum
of Hilbert spaces, 256
Dirichlet
boundary condition, 505
boundary conditions, 552
Laplacian, 553
Dirichlet form, 296
Dirichlet integral, 505
Dirichlet problem, 504, 552
distribution
Dirac’s delta, 31
local order, 28
order, 28
periodic, 54
regular, 5
tempered, 40
with support in x0, 56
distributions, 27
of compact support, 27, 41
regular, 29, 30
tempered, 27
divergence type, 558
domain
of a linear operator, 277
dual
algebraic, 9
topological, 17, 25
E
effects, 483
eigenfunction
generalized, 449
completeness of, 450, 452
eigenvalue problem
nonlinear, 558
elementary solution
advanced resp. retarded, 115
equi-continuous, 583
ergodic, 336
Euclidean spaces, 221
Euler, 503
Euler–Lagrange
necessary condition of, 526
Euler–Lagrange equation, 506, 534
existence of a minimum, 512
extension
of a linear operator, 279
of a quadratic form, 296
F
Fock space
Boson, 262
Fermion, 262
form domain, 296
form norm, 296
form sum, 303
Fourier
hyperfunction, 174
transform, 134
transformation, 134
inverse, 140
on L2(Rn), 152
on S(Rn), 142
on S′(Rn), 144
Fourier expansion, 242
Fréchet differentiable, 520
Friedrich’s extension, 302
Fubini’s theorem
for distributions, 82
function
Heaviside, 47
strongly decreasing, 20
functional, 504
positive, 460
analytic, 173
positive
examples, 462
functional calculus
of self-adjoint operators, 419
fundamental theorem of algebra, 125
fundamental theorem of calculus, 524
G
Gâteaux derivative, 531
Gâteaux differential, 530

Index
593
Gagliardo-Nirenberg-Sobolev inequality, 192
Gelfand triple, 441
generalized functions, 5
Gelfand type Sb
a, 172
Gram determinant, 232, 233
Gram–Schmidt orthonormalization, 241
Green’s function, 108
H
Hadamard’s principal value, 32
Hamilton operator
free, 291
heat equation, 112, 158
Heisenberg’s uncertainty relation, 390
Helmholtz differential operator, 156
Hermite
functions, 250
polynomials, 249
Hilbert cube, 358
Hilbert space, 219
rigged, 441
separable, 239, 240
Hilbert space basis, 240
Hilbert spaces
direct integral of, 446
measurable ﬁeld of, 446
Hilbert sum
or direct sum of Hilbert spaces, 256
Hilbert transform, 99
Hilbert-Schmidt norm, 365
Hilbert-Schmidt operator, 365
spectral representation, 371
hlctvs
metrizable, 579
holomorphic, 121
homomorphism
of ∗-algebras, 456
hyperfunctions, 173
hypo-elliptic, 109
hypo-ellipticity
of ∂, 120
I
inequality
Bessel’s, 216
Cauchy–Schwarz–Bunjakowski, 217
Schwarz’, 216
triangle, 217
inﬁnitesimal generator, 331
inner product space, 214
integral
with respect to a spectral family, 406
integral equation, 208
integral of functions, 523
integral operators
of Hilbert–Schmidt, 310
isometry, 329
isoperimetric problem, 504
K
Kato perturbation, 337
of free Hamiltonian, 340
Knotensatz, 248
Kolmogorov-Riesz compactness criterion, 196
L
Lagrange multiplier, 537
Lagrange multipliers
existence of, 541
Laguerre
functions, 250
polynomials, 250
Laplace operator, 156
fundamental solution, 111
Laplace transform
of distributions, 168
of functions, 168
Laurent expansion, 127
Lebesgue space, 223
Legendre
polynomials, 251
Leibniz, 503
Leibniz formula, 51
lemma
of Wielandt, 312
of Riemann–Lebesgue, 135
of Riesz, 361
of Weyl, 108
length, 215
level surface, 538
linear functional
positive
completely additive, 466
normal, 466
linear hull
or span, 228
linear map
k-positive, 473
completely positive, 473
examples, 474
in quantum physics, 486
on B(H), 480
positive, 472
linear operator
bounded, 279, 307
closable, 284
closed, 283

594
Index
closure of, 284
core of, 287
essentially self-adjoint, 286, 288
from H into K, 277
of multiplication, 289
positive, 320
product or composition, 280
self-adjoint, 286, 287
symmetric, 286
unbounded, 279, 307
local extrema
necessary and sufﬁcient conditions for, 527
locally integrable, 14
lower semi-continuous, 511
M
matrix spaces, 221
maximal, 241
maximal self-adjoint part
of A, 415
Maxwell’s equations
in vacuum, 116
metric, 17
metric space, 575
completion, 575
metrizable
HLCTVS, 18
minimax principle, 550
minimization
constrained, 537
minimizer
existence, 512
uniqueness, 512
minimizing point, 529
minimizing sequence, 506
minimum (maximum)
global, 526
local, 526
modulus
of an operator, 321
momentum operator, 290
monotone, 528
Morrey’s inequality, 187
muliplicator space, 52
multiplication operator
bounded, 309
unbounded, 310
N
Neumann series, 319
Newton, 503
norm, 8
Hilbertian, 220
induced by an inner product, 217
of a bounded linear operator, 307
norm topology, 218
normal states
characterization, 467
nuclear, 441
O
ONB
characterization of, 241
open ball, 575
operator
compact, 355
completely continuous, 355
inverse, 278
nuclear, 373
of ﬁnite rank, 356
order
in a ∗-algebra, 460
order symbol, 520
orthogonal, 215
complement M⊥, 227
orthonormal, 215
basis, 240
polynomials, 247
system, 215
P
parallelogram law, 220
Parseval relation, 242
partial differential operator
linear constant coefﬁcients, 48
linear elliptic, 554
partial trace, 382
characterization, 385
Pauli matrices, 263
Poisson equation, 112
polar decomposition, 321
polarization identity, 220
pole
of ﬁnite order, 129
positive element
in a ∗-algebra, 460
positive elements
in B(H), 460
pre-Hilbert space, 214
product
inner or scalar, 214
of distributions and functions, 50
rule, 50
projection theorem
for closed subspaces, 229
for convex sets, 547
projector

Index
595
or projection operator, 325
pseudo function, 32
Pythagoras
theorem of, 215
p-ball
open, 10
Q
quadratic form, 295
closable, 296
closed, 296
continuous, 295
densely deﬁned, 295
ﬁrst representation theorem, 299
lower bound, 295
minimization, 515
positive, 295
second representation theorem, 301
semi-bounded
from below, 295
symmetric, 295
quadratic functional, 515
quantum operation, 486
Kraus form, 491
R
Radon measure, 67
regular (critical) point, 526
regular points
of an operator A, 344
regularization
of distributions, 89
regularizing sequence, 91
renormalization, 57
representation
cyclic, 456
of a C∗-algebra, 456
residue, 129
resolution of the identity, 327, 402
resolvent, 344
identity, 346
set, 344
restriction
of a linear operator, 279
Riemann integral, 341
Rodrigues’ formula, 250
S
Schmidt decomposition, 386
Schrödinger operator
free, 158
Schwartz distributions, 169
self-adjoint
geometric characterization, 400
semi-metric, 17
semi-norm, 8
comparable, 10
smaller than, 10
semi-norms
system of, 11
ﬁltering, 11
systems of
equivalent, 12
sequence
Cauchy, 15, 218
converges, 15, 218
sequence space, 221
set
open, 7
singularity
essential, 129
isolated, 129
removable, 129
Sobolev
constant, 552
embeddings, 183, 551, 559
inequality, 551
space, 551
space of order (k, p), 182
Sobolev spaces, 223
Sokhotski–Plemelji formula, 35
solution
classical or strong, 48, 107
distributional or weak, 48, 107
fundamental, 104, 108
spectral family, 402
spectrum, 344
continuous, 348
discrete, 348
essential, 427
point, 348
square root lemma, 320
state
bound, 431
completely additive, 467
normal, 467
of a ∗-algebra with unit, 465
scattering, 431
Stone’s formula, 436
Sturm–Liouville problem, 561
subset
meager, 581
nonmeager, 581
nowhere dense, 581
of ﬁrst category, 581
of second category, 581
subspace

596
Index
absolutely continuous, 424
invariant, 415
reducing, 415
singular, 424
singularly continuous, 423
support
of a distribution, 39
of a spectral family, 402
of an analytic functional, 173
of Fourier hyperfunctions, 175
singular, 40
support condition, 94
T
tangent space
existence of, 539
Taylor expansion with remainder, 524
tensor product
for distributions, 81
of functions, 73
of Hilbert spaces, 259
totally anti-symmetric, 262
totally symmetric, 262
of vector spaces, 258, 259
projective
of E, F, 77
of p, q, 76
test function space
D(Ω), 19
E(Ω), 21
S(Ω), 21
theorem
Baire, version 1, 581
Baire, version 2, 582
Baire, version 3, 582
Banach–Saks, 273
Banach–Steinhaus, 271, 583
Busch-Gleason, 485
Cauchy, 122
Choi, 494
closed graph, 588
convolution, 149
generalized, 150
de Figueiredo–Karlovitz, 221
ergodic - von Neumann, 335
extension of linear functionals, 235
Fréchet–von Neumann–Jordan, 220
Fredholm alternative, 362
Gleason, 483
GNS construction, 462
Hörmander, 154
Hellinger–Toeplitz, 309
Hilbert–Schmidt, 360
identity of holomorphic functions, 126
inverse mapping, 587
Kakutani, 220
Kato–Rellich, 338
Liouville, 125
Naimark, 459
of F. Riesz, 266
of residues, 130
of Vigier, 466
open mapping, 586
Plancherel, 152
Rellich-Kondrachov compactness, 196
Riesz–Fischer, 223
Riesz–Fréchet, 234
Riesz–Schauder, 359
Sobolev embedding, 193
spectral, 410
functional form, 447
nuclear, 452
Stinespring factorization, 475
Stone, 331
Weyl, 428
topological complement, 541
topological space, 7
Hausdorff, 12, 13
topology, 7
σ-strong, 378
σ-strong*, 378
σ-weak, 378
deﬁned by semi-norms, 11
of uniform convergence, 16
strong, 377
strong*, 377
ultrastrong, 378
ultrawak, 378
weak, 378
topology on B(H)
norm or uniform, 317
strong, 317
weak, 317
total subset, 231
trace, 370
trace class operator, 365
spectral representation, 371
trace class operators
dual space of, 375
trace norm, 365
U
ultradifferentiable functions, 177
ultradifferential operator, 178
ultradistributions, 177
uniform boundedness principle, 271, 584
unitary operator, 330

Index
597
unitary operators
n-parameter group, 333
one-parameter group, 330
upper semi-continuity, 511
V
variation
nth, 533
vector space
locally convex topological, 7
topological, 7
vector state, 465
von Neumann algebra, 465
W
wave operator, 114
weak
Cauchy sequence, 267
convergence, 267
limit, 267
topology, 267
weak topology
D′(Ω), 33
Weierstraß theorem
Generalized II, 515
Weierstraß theorems
generalized, 508
Weierstrass theorem
Generalized I, 514
Weyl’s criterion, 347
Wiener–Hopf operators, 312

