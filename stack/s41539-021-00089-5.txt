REVIEW ARTICLE
OPEN
Metacognition: ideas and insights from neuro- and
educational sciences
Damien S. Fleur
1,2✉, Bert Bredeweg
1,3 and Wouter van den Bos2,4
Metacognition comprises both the ability to be aware of one’s cognitive processes (metacognitive knowledge) and to regulate
them (metacognitive control). Research in educational sciences has amassed a large body of evidence on the importance of
metacognition in learning and academic achievement. More recently, metacognition has been studied from experimental and
cognitive neuroscience perspectives. This research has started to identify brain regions that encode metacognitive processes.
However, the educational and neuroscience disciplines have largely developed separately with little exchange and communication.
In this article, we review the literature on metacognition in educational and cognitive neuroscience and identify entry points for
synthesis. We argue that to improve our understanding of metacognition, future research needs to (i) investigate the degree to
which different protocols relate to the similar or different metacognitive constructs and processes, (ii) implement experiments to
identify neural substrates necessary for metacognition based on protocols used in educational sciences, (iii) study the effects of
training metacognitive knowledge in the brain, and (iv) perform developmental research in the metacognitive brain and compare it
with the existing developmental literature from educational sciences regarding the domain-generality of metacognition.
npj Science of Learning  (2021) 6:13 ; https://doi.org/10.1038/s41539-021-00089-5
INTRODUCTION
Metacognition is deﬁned as “thinking about thinking” or the
ability to monitor and control one’s cognitive processes1 and plays
an important role in learning and education2–4. For instance, high
performers tend to present better metacognitive abilities (espe-
cially
control)
than
low
performers
in
diverse
educational
activities5–9. Recently, there has been a lot of progress in studying
the neural mechanisms of metacognition10,11, yet it is unclear at
this point how these results may inform educational sciences or
interventions. Given the potential beneﬁts of metacognition, it is
important to get a better understanding of how metacognition
works and of how training can be useful.
The interest in bridging cognitive neuroscience and educational
practices has increased in the past two decades, spanning a large
number
of
studies
grouped
under
the
umbrella
term
of
educational neuroscience12–14. With it, researchers have brought
forward issues that are viewed as critical for the discipline to
improve education. Recurring issues that may impede the
relevance of neural insights for educational practices concern
external validity15,16, theoretical discrepancies17 and differences in
terms of the domains of (meta)cognition operationalised (speciﬁc
or general)15. This is important because, in recent years, brain
research is starting to orient itself towards training metacognitive
abilities that would translate into real-life beneﬁts. However, direct
links between metacognition in the brain and metacognition in
domains such as education have still to be made. As for
educational sciences, a large body of literature on metacognitive
training is available, yet we still need clear insights about what
works and why. While studies suggest that training metacognitive
abilities results in higher academic achievement18, other inter-
ventions show mixed results19,20. Moreover, little is known about
the long-term effects of, or transfer effects, of these interventions.
A better understanding of the cognitive processes involved in
metacognition and how they are expressed in the brain may
provide insights in these regards.
Within cognitive neuroscience, there has been a long tradition
of studying executive functions (EF), which are closely related to
metacognitive processes21. Similar to metacognition, EF shows a
positive relationship with learning at school. For instance,
performance in laboratory tasks involving error monitoring,
inhibition and working memory (i.e. processes that monitor and
regulate cognition) are associated with academic achievement in
pre-school children22. More recently, researchers have studied
metacognition in terms of introspective judgements about
performance in a task10. Although the neural correlates of such
behaviour are being revealed10,11, little is known about how
behaviour during such tasks relates to academic achievement.
Educational and cognitive neuroscientists study metacognition
in different contexts using different methods. Indeed, while the
latter investigate metacognition via behavioural task, the former
mainly rely on introspective questionnaires. The extent to which
these different operationalisations of metacognition match and
reﬂect the same processes is unclear. As a result, the external
validity of methodologies used in cognitive neuroscience is also
unclear16. We argue that neurocognitive research on metacogni-
tion has a lot of potential to provide insights in mechanisms
relevant in educational contexts, and that theoretical and
methodological exchange between the two disciplines can beneﬁt
neuroscientiﬁc research in terms of ecological validity.
For these reasons, we investigate the literature through the
lenses of external validity, theoretical discrepancies, domain
generality and metacognitive training. Research on metacognition
in cognitive neuroscience and educational sciences are reviewed
separately. First, we investigate how metacognition is operatio-
nalised with respect to the common framework introduced by
Nelson and Narens23 (see Fig. 1). We then discuss the existing
1Informatics Institute, University of Amsterdam, Amsterdam, the Netherlands. 2Departement of Psychology, University of Amsterdam, Amsterdam, the Netherlands. 3Faculty of
Education, Amsterdam University of Applied Sciences, Amsterdam, the Netherlands. 4Center for Adaptive Rationality, Max Planck Institute for Human Development, Berlin,
Germany. ✉email: d.s.ﬂeur@uva.nl
www.nature.com/npjscilearn
Published in partnership with The University of Queensland
1234567890():,;

body of evidence regarding metacognitive training. Finally, we
compare ﬁndings in both ﬁelds, highlight gaps and shortcomings,
and propose avenues for research relying on crossovers of the two
disciplines.
In cognitive neuroscience, metacognition is divided into two
main components5,24, which originate from the seminal works of
Flavell on metamemory25,26. First, metacognitive knowledge
(henceforth, meta-knowledge) is deﬁned as the knowledge
individuals have of their own cognitive processes and their ability
to monitor and reﬂect on them. Second, metacognitive control
(henceforth, meta-control) consists of someone’s self-regulatory
mechanisms, such as planning and adapting behaviour based on
outcomes5,27. Following Nelson and Narens’ deﬁnition23, meta-
knowledge is characterised as the ﬂow and processing of
information from the object level to the meta-level, and meta-
control as the ﬂow from the meta-level to the object level28–30
(Fig. 1). The object-level encompasses cognitive functions such as
recognition
and
discrimination
of
objects,
decision-making,
semantic encoding, and spatial representation. On the meta-level,
information originating from the object level is processed and top-
down regulation on object-level functions is imposed28–30.
Educational researchers have mainly investigated metacognition
through the lens of Self-Regulated Learning theory (SRL)3,4, which
shares common conceptual roots with the theoretical framework
used in cognitive neuroscience but varies from it in several ways31.
First, SRL is constrained to learning activities, usually within
educational settings. Second, metacognition is merely one of three
components, with “motivation to learn” and “behavioural pro-
cesses”, that enable individuals to learn in a self-directed manner3.
In SRL, metacognition is deﬁned as setting goals, planning,
organising, self-monitoring and self-evaluating “at various points
during the acquisition”3. The distinction between meta-knowledge
and meta-control is not formally laid down although reference is
often made to a “self-oriented feedback loop” describing the
relationship between reﬂecting and regulating processes that
resembles Nelson and Narens’ model (Fig. 1)3,23. In order to
facilitate the comparison of operational deﬁnitions, we will refer to
meta-knowledge in educational sciences when protocols operatio-
nalise self-awareness and knowledge of strategies, and to meta-
control when they operationalise the selection and use of learning
strategies and planning. For an in-depth discussion on metacogni-
tion and SRL, we refer to Dinsmore et al. 31.
METACOGNITION IN COGNITIVE NEUROSCIENCE
Operational deﬁnitions
In cognitive neuroscience, research in metacognition is split into
two tracks32. One track mainly studies meta-knowledge by
investigating the neural basis of introspective judgements about
one’s own cognition (i.e., metacognitive judgements), and meta-
control with experiments involving cognitive ofﬂoading. In these
experiments, subjects can perform actions such as set reminders,
making notes and delegating tasks33,34, or report their desire for
them35. Some research has investigated how metacognitive
judgements can inﬂuence subsequent cognitive behaviour (i.e.,
a downward stream from the meta-level to the object level), but
only one study so far has explored how this relationship is
mapped in the brain35. In the other track, researchers investigate
EF, also referred to as cognitive control30,36, which is closely
related to metacognition. Note however that EF are often not
framed in metacognitive terms in the literature37 (but see ref. 30).
For the sake of concision, we limit our review to operational
deﬁnitions that have been used in neuroscientiﬁc studies.
Metacognitive judgements
Cognitive neuroscientists have been using paradigms in which
subjects make judgements on how conﬁdent they are with
regards to their learning of some given material10. These
judgements are commonly referred to as metacognitive judge-
ments, which can be viewed as a form of meta-knowledge (for
reviews see Schwartz38 and Nelson39). Historically, researchers
mostly resorted to paradigms known as Feelings of Knowing
(FOK)40 and Judgements of Learning (JOL)41. FOK reﬂect the belief
of a subject to knowing the answer to a question or a problem
and being able to recognise it from a list of alternatives, despite
being unable to explicitly recall it40. Here, metacognitive judge-
ment is thus made after retrieval attempt. In contrast, JOL are
prospective judgements during learning of one’s ability to
successfully recall an item on subsequent testing41.
More recently, cognitive neuroscientists have used paradigms in
which subjects make retrospective metacognitive judgements on
their performance in a two-alternative Forced Choice task (2-AFC)42.
In 2-AFCs, subjects are asked to choose which of two presented
options has the highest criterion value. Different domains can be
involved, such as perception (e.g., visual or auditory) and memory.
For example, subjects may be instructed to visually discriminate
which one of two boxes contains more dots43, identify higher
contrast Gabor patches44, or recognise novel words from words
that were previously learned45 (Fig. 2). The subjects engage in
metacognitive judgements by rating how conﬁdent they are
relative to their decision in the task. Based on their responses,
one can evaluate a subject’s metacognitive sensitivity (the ability to
discriminate one’s own correct and incorrect judgements), meta-
cognitive bias (the overall level of conﬁdence during a task), and
metacognitive efﬁciency (the level of metacognitive sensitivity when
controlling for task performance46; Fig. 3). Note that sensitivity and
bias are independent aspects of metacognition, meaning that two
subjects may display the same levels of metacognitive sensitivity,
but one may be biased towards high conﬁdence while the other is
biased towards low conﬁdence. Because metacognitive sensitivity is
affected by the difﬁculty of the task (one subject tends to display
greater metacognitive sensitivity in easy tasks than difﬁcult ones
and different subjects may ﬁnd a task more or less easy),
metacognitive efﬁciency is an important measure as it allows
researchers to compare metacognitive abilities between subjects
and between domains. The most commonly used methods to
assess metacognitive sensitivity during retrospective judgements
are the receiver operating curve (ROC) and meta-d′.46 Both derive
from signal detection theory (SDT)47 which allows Type 1 sensitivity,
or d’′ (how a subject can discriminate between stimulus alternatives,
i.e. object-level processes) to be differentiated from metacognitive
sensitivity (a judgement on the correctness of this decision)48.
Importantly, only comparing meta-d′ to d′ seems to give reliable
assessments metacognitive efﬁciency49. A ratio of 1 between meta-
d’′ and d’′, indicates that a subject was perfectly able to discriminate
between their correct and incorrect judgements. A ratio of
0.8 suggests that 80% of the task-related sensory evidence was
available for the metacognitive judgements. Table 1 provides an
overview of the different types of tasks and protocols with regards
to the type of metacognitive process they operationalise. These
operationalisations of meta-knowledge are used in combination
Meta-level
Object level
Knowledge
Control
Fig. 1
Model of metacognitive processes. Meta-knowledge is
characterised as the upward ﬂow from object-level to meta-level.
Meta-control is characterised as the downward ﬂow from meta-level
to object-level. Metacognition is therefore conceptualised as the
bottom-up
monitoring
and
top-down
control
of
object-level
processes. Adapted from Nelson and Narens’ cognitive psychology
model of metacognition23.
D.S. Fleur et al.
2
npj Science of Learning (2021)  13 
Published in partnership with The University of Queensland
1234567890():,;

with brain imaging methods (functional and structural magnetic
resonance imaging; fMRI; MRI) to identify brain regions associated
with metacognitive activity and metacognitive abilities10,50. Alter-
natively, transcranial magnetic stimulation (TMS) can be used to
temporarily deactivate chosen brain regions and test whether this
affects metacognitive abilities in given tasks51,52.
A recent meta-analysis analysed 47 neuroimaging studies on
metacognition and identiﬁed a domain-general network asso-
ciated with high vs. low conﬁdence ratings in both decision-
making tasks (perception 2-AFC) and memory tasks (JOL, FOK)11.
This network includes the medial and lateral prefrontal cortex
(mPFC and lPFC, respectively), precuneus and insula. In contrast,
the right anterior dorsolateral PFC (dlPFC) was speciﬁcally involved
in decision-making tasks, and the bilateral parahippocampal cortex
was speciﬁc to memory tasks. In addition, prospective judgements
were associated with the posterior mPFC, left dlPFC and right
insula, whereas retrospective judgements were associated with
bilateral parahippocampal cortex and left inferior frontal gyrus.
Finally, emerging evidence suggests a role of the right rostrolateral
PFC (rlPFC)53,54, anterior PFC (aPFC)44,45,55,56, dorsal anterior
cingulate cortex (dACC)54,55 and precuneus45,55 in metacognitive
sensitivity (meta-d′, ROC). In addition, several studies suggest that
the aPFC relates to metacognition speciﬁcally in perception-related
2-AFC tasks, whereas the precuneus is engaged speciﬁcally in
memory-related 2-AFC tasks45,55,56. This may suggest that meta-
cognitive processes engage some regions in a domain-speciﬁc
manner, while other regions are domain-general. For educational
scientists, this could mean that some domains of metacognition
may be more relevant for learning and, granted sufﬁcient plasticity
of the associated brain regions, that targeting them during
interventions may show more substantial beneﬁts. Note that
rating one’s conﬁdence and metacognitive sensitivity likely involve
additional,
peripheral
cognitive
processes
instead of
purely
metacognitive ones. These regions are therefore associated with
metacognition but not uniquely per se. Notably, a recent meta-
analysis50 suggests that domain-speciﬁc and domain-general
signals may rather share common circuitry, but that their neural
signature varies depending on the type of task or activity, showing
that domain-generality in metacognition is complex and still needs
to be better understood.
In terms of the role of metacognitive judgements on future
behaviour, one study found that brain patterns associated with
the desire for cognitive ofﬂoading (i.e., meta-control) partially
overlap with those associated with meta-knowledge (metacogni-
tive judgements of conﬁdence), suggesting that meta-control is
driven by either non-metacognitive, in addition to metacognitive,
processes or by a combination of different domain-speciﬁc meta-
knowledge processes35.
Executive function
In EF, processes such as error detection/monitoring and effort
monitoring can be related to meta-knowledge while error
correction, inhibitory control, and resource allocation can be
related to meta-control36. To activate these processes, partici-
pants are asked to perform tasks in laboratory settings such as
Flanker tasks, Stroop tasks, Demand Selection tasks and Motion
Discrimination
tasks
(Fig.
4).
Neural
correlates
of
EF
are
investigated by having subjects perform such tasks while their
brain activity is recorded with fMRI or electroencephalography
(EEG). Additionally, patients with brain lesions can be tested
against healthy participants to evaluate the functional role of the
impaired regions57.
Fig. 3
Four conﬁgurations of metacognitive sensitivity and bias
levels. The red and blue curves represent the distribution of
conﬁdence ratings for incorrect and correct trials, respectively. A
larger distance between the two curves denotes higher sensitivity.
Displacement to the left and right denote biases towards low
conﬁdence (low metacognitive bias) and high conﬁdence (high
metacognitive bias), respectively (retrieved from Fig. 1 in Fleming
and Lau46). We repeat the disclaimer of the original authors that this
ﬁgure is not a statistically accurate description of correct and
incorrect responses, which are typically not normally distributed46,47.
Fixation
Stimulus
Decision
Fixation
List 
memorisation
Decision
Car
Apple
Juice
Sweat
Hair
Dog
Chair
Face
Boat
Room
Teeth
Place
Head
Wheel
Hard
Phone
Hook
Zoo
Fair
Brown
Dog
House
Dog
House
(a)
(b)
Fig. 2
Examples of 2-AFC tasks with the addition of post-decisional conﬁdence judgement used to assess meta-knowledge. a Visual
perception task: subjects choose the box containing the most (randomly generated) dots. Subjects then rate their conﬁdence in their decision.
b Memory task: subjects learn a list of words. In the next screen, they have to identify which of two words shown was present on the list. The
subjects then rate their conﬁdence in their decision.
D.S. Fleur et al.
3
Published in partnership with The University of Queensland
npj Science of Learning (2021)  13 

In a review article on the neural basis of EF (in which they are
deﬁned as meta-control), Shimamura argues that a network of
regions composed of the aPFC, ACC, ventrolateral PFC (vlPFC) and
dlPFC is involved in the regulations of cognition30. These regions
are not only interconnected but are also intricately connected to
cortical and subcortical regions outside of the PFC. The vlPFC was
shown to play an important role in “selecting and maintaining
information in working memory”, whereas the dlPFC is involved in
“manipulating and updating information in working memory”30.
The ACC has been proposed to monitor cognitive conﬂict (e.g. in a
Stroop task or a Flanker task), and the dlPFC to regulate it58,59. In
particular, activity in the ACC in conﬂict monitoring (meta-
knowledge) seems to contribute to control of cognition (meta-
control) in the dlPFC60,61 and to “bias behavioural decision-making
toward cognitively efﬁcient tasks and strategies” (p. 356)62 . In a
recent fMRI study, subjects performed a motion discrimination
task (Fig. 4c)63. After deciding on the direction of the motion, they
were presented additional motion (i.e. post-decisional evidence)
and then were asked to rate their conﬁdence in their initial choice.
The post-decisional evidence was encoded in the activity of the
posterior medial frontal cortex (pMFC; meta-knowledge), while
lateral aPFC (meta-control) modulated the impact of this evidence
on subsequent conﬁdence rating63. Finally, results from a meta-
analysis study on cognitive control identiﬁed functional connec-
tivity between the pMFC, associated with monitoring and
informing other regions about the need for regulation, and the
lPFC that would effectively regulate cognition64.
Online vs. ofﬂine metacognition
While the processes engaged during tasks such as those used in
EF research can be considered as metacognitive in the sense that
they are higher-order functions that monitor and control lower
cognitive processes, scientists have argued that they are not
functionally equivalent to metacognitive judgements10,11,65,66.
Indeed, engaging in metacognitive judgements requires subjects
to reﬂect on past or future activities. As such, metacognitive
judgements can be considered as ofﬂine metacognitive processes.
In contrast, high-order processes involved in decision-making
tasks such as used in EF research are arguably largely made on the
ﬂy, or online, at a rapid pace and subjects do not need to reﬂect on
their actions to perform them. Hence, we propose to explicitly
distinguish online and ofﬂine processes. Other researchers have
shared a similar view and some have proposed models for
metacognition that make similar distinctions65–68. The functional
difference between online and ofﬂine metacognition is supported
by some evidence. For instance, event-related brain potential
(ERP) studies suggest that error negativities are associated with
error detection in general, whereas an increased error positivity
speciﬁcally encodes error that subjects could report upon69,70.
Furthermore, brain-imaging studies suggest that the MFC and ACC
are involved in online meta-knowledge, while the aPFC and lPFC
seem to be activated when subjects engage in more ofﬂine meta-
knowledge and meta-control, respectively63,71,72. An overview of
the different tasks can be found in Table 1 and a list of different
studies on metacognition can be found in Supplementary Table 1
(organised in terms of the type of processes investigated, the
protocols and brain measures used, along with the brain regions
identiﬁed).
Figure
5
illustrates
the
different
brain
regions
associated with meta-knowledge and meta-control, distinguishing
between what we consider to be online and ofﬂine processes. This
distinction is often not made explicitly but it will be speciﬁcally
helpful when building bridges between cognitive neuroscience
and educational sciences.
Training metacognition
There are extensive accounts in the literature of efforts to improve
EF components such as inhibitory control, attention shifting and
working memory22. While working memory does not directly
reﬂect metacognitive abilities, its training is often hypothesised to
improve general cognitive abilities and academic achievement.
However, most meta-analyses found that training methods lead
only to weak, non-lasting effects on cognitive control73–75. One
meta-analysis did ﬁnd evidence of near-transfer following EF
training in children (in particular working memory, inhibitory
control and cognitive ﬂexibility), but found no evidence of far-
transfer20. According to this study, training on one component
leads to improved abilities in that same component but not in
other EF components. Regarding adults, however, one meta-
analysis suggests that EF training in general and working memory
Table 1.
Overview of popular operationalisations of metacognition.
Online
Ofﬂine
Protocol
Discipline
CN
ES
Meta-
knowledge
Metacognitive
judgements
JOL
X
X
FOK
X
X
2-AFC +
conﬁdence
X
Self-evaluation MAI
X
Interviews
X
Awareness of
learning
Learning journals
X
Self-
monitoring
Thinking-aloud
X
Meta-
control
Strategy
selection
MAI
X
MSLQ
X
LASSI
X
Learning journals
X
Use of
strategies
Interviews
X
Thinking-aloud
X
Conﬂict
monitoring
Motion
discrimination +
additional
evidence
X
Flanker task
X
X
Stroop task
X
X
Effort
regulation
2-AFC +
Cognitive
ofﬂoading
X
Demand-
selection task
X
BRIEF
X
Inhibition
BRIEF
X
Flanker task
X
X
Shifting
Stroop task
X
X
Emotional
control
BRIEF
X
Planning
MAI
X
MSLQ
X
LASSI
X
BRIEF
X
Cognitive
ofﬂoading
Go/no-go +
setting reminders
X
Go/no-go +
desire for
reminder
X
CN cognitive neuroscience, ES educational sciences.
D.S. Fleur et al.
4
npj Science of Learning (2021)  13 
Published in partnership with The University of Queensland

training speciﬁcally may both lead to signiﬁcant near- and far-
transfer effects76. On a neural level, a meta-analysis showed that
cognitive training resulted in decreased brain activity in brain
regions associated with EF77. According to the authors, this
indicates that “training interventions reduce demands on exter-
nally focused attention” (p. 193)77.
With regards to meta-knowledge, several studies have reported
increased task-related metacognitive abilities after training. For
example, researchers found that subjects who received feedback
on their metacognitive judgements regarding a perceptual
decision-making task displayed better metacognitive accuracy,
not only in the trained task but also in an untrained memory
task78. Related, Baird and colleagues79 found that a two-week
mindfulness
meditation
training
lead
to
enhanced
meta-
knowledge in the memory domain, but not the perceptual
domain. The authors link these results to evidence of increased
grey matter density in the aPFC in meditation practitioners.
Summary
Research on metacognition in cognitive science has mainly been
studied through the lens of metacognitive judgements and EF
(speciﬁcally performance monitoring and cognitive control). Meta-
knowledge is commonly activated in subjects by asking them to rate
their conﬁdence in having successfully performed a task. A
distinction is made between metacognitive sensitivity, metacogni-
tive bias and metacognitive efﬁcacy. Monitoring and regulating
processes in EF are mainly operationalised with behavioural tasks
such as Flanker tasks, Stroop tasks, Motion Discrimination tasks
and Demand Selection tasks. In addition, metacognitive judge-
ments can be viewed as ofﬂine processes in that they require the
subject
to
reﬂect
on
her
cognition
and
develop
meta-
representations. In contrast, EF can be considered as mostly
online metacognitive processes because monitoring and regula-
tion mostly happen rapidly without the need for reﬂective
thinking.
Although there is some evidence for domain speciﬁcity, other
studies have suggested that there is a single network of regions
involved in all meta-cognitive tasks, but differentially activated in
different task contexts. Comparing research on meta-knowledge
and meta-control also suggest that some regions play a crucial
role in both knowledge and regulation (Fig. 5). We have also
identiﬁed a speciﬁc set of regions that are involved in either ofﬂine
or online meta-knowledge. The evidence in favour of metacog-
nitive training, while mixed, is interesting. In particular, research
on ofﬂine meta-knowledge training involving self-reﬂection and
metacognitive accuracy has shown some promising results. The
regions that show structural changes after training, were those
that we earlier identiﬁed as being part of the metacognition
network. EF training does seem to show far-transfer effects at least
in adults, but the relevance for everyday life activity is still unclear.
One major limitation of current research in metacognition is
ecological validity. It is unclear to what extent the operationalisations
reviewed above reﬂect real-life metacognition. For instance, are
people
who
can
accurately
judge
their
performance
on
a
behavioural task also able to accurately assess how they performed
Or
Or
Pick the direction that the
middle arrow is pointing at
Green
Green
Cue
color / word
In which direction
are the dots moving?
a
b
c
d
Fig. 4
Examples of tasks used to assess EF. a Flanker task: subjects indicate the direction to which the arrow in the middle points. b Stroop
task: subjects are presented with the name of colour printed in a colour that either matches or mismatches the name. Subjects are asked to
give the name of the written colour or the printed colour. c Motion Discrimination task: subjects have to determine in which direction the dots
are going with variating levels of noise. d Example of a Demand Selection task: in both options subjects have to switch between two tasks.
Task one, subjects determine whether the number shown is higher or lower than 5. Task two, subjects determine whether the number is odd
or even. The two options (low and high demand) differ in their degree of task switching, meaning the effort required. Subjects are allowed to
switch between the two options. Note, the type of task is solely indicated by the colour of the number and that the subjects are not explicitly
told about the difference in effort between the two options (retrieved from Fig. 1c in Froböse et al. 58).
D.S. Fleur et al.
5
Published in partnership with The University of Queensland
npj Science of Learning (2021)  13 

during an exam? Are people with high levels of error regulation and
inhibitory control able to learn more efﬁciently? Note that criticism
on the ecological validity of neurocognitive operationalisations
extends beyond metacognition research16. A solution for improving
validity may be to compare operationalisations of metacognition in
cognitive neuroscience with the ones in educational sciences, which
have shown clear links with learning in formal education. This also
applies to metacognitive training.
METACOGNITION IN EDUCATIONAL SCIENCES
Operational deﬁnitions
The most popular protocols used to measure metacognition in
educational sciences are self-report questionnaires or interviews,
learning journals and thinking-aloud protocols31,80. During inter-
views, subjects are asked to answer questions regarding hypothe-
tical situations81. In learning journals, students write about their
learning experience and their thoughts on learning82,83. In
thinking-aloud protocols, subjects are asked to verbalise their
thoughts while performing a problem-solving task80. Each of these
instruments can be used to study meta-knowledge and meta-
control. For instance, one of the most widely used questionnaires,
the Metacognitive Awareness Inventory (MAI)42, operationalises
“Flavellian” metacognition and has dedicated scales for meta-
knowledge and meta-control (also popular are the MSLQ84 and
LASSI85 which operate under SRL). The meta-knowledge scale of
the MAI operationalises knowledge of strategies (e.g., “I am aware
of what strategies I use when I study”) and self-awareness (e.g., “I am
a good judge of how well I understand something”); the meta-
control scale operationalises planning (e.g., “I set a goal before I
begin a task”) and use of learning strategies (e.g., “I summarize what
I’ve learned after I ﬁnish”). Learning journals, self-report question-
naires and interviews involve ofﬂine metacognition. Thinking
aloud, though not engaging the same degree self-reﬂection, also
involves ofﬂine metacognition in the sense that online processes
are verbalised, which necessitate ofﬂine processing (see Table 1 for
an overview and Supplementary Table 2 for more details).
More recently, methodologies borrowed from cognitive neu-
roscience have been introduced to study EF in educational
settings22,86. In particular, researchers used classic cognitive control
tasks such as the Stroop task (for a meta-analysis86). Most of the
studied components are related to meta-control and not meta-
knowledge. For instance, the BRIEF87 is a questionnaire completed
by parents and teachers which assesses different subdomains of
EF: (1) inhibition, shifting, and emotional control which can be
viewed
as
online
metacognitive
control,
and
(2)
planning,
organisation of materials, and monitoring, which can be viewed
as ofﬂine meta-control87.
Assessment of metacognition is usually compared against
metrics of academic performance such as grades or scores on
designated tasks. A recent meta-analysis reported a weak correla-
tion of self-report questionnaires and interviews with academic
performance whereas think-aloud protocols correlated highly88.
Ofﬂine meta-knowledge processes operationalised by learning
journals were found to be positively associated with academic
achievement when related to reﬂection on learning activities but
negatively associated when related to reﬂection on learning
materials, indicating that the type of reﬂection is important89. EF
have been associated with abilities in mathematics (mainly) and
reading comprehension86. However, the literature points towards
contrary directions as to what speciﬁc EF component is involved in
academic achievement. This may be due to the different groups
that were studied, to different operationalisations or to different
theoretical underpinnings for EF86. For instance, online and ofﬂine
metacognitive processes, which are not systematically distin-
guished in the literature, may play different roles in academic
achievement. Moreover, the bulk of research focussed on young
children with few studies on adolescents86 and EF may play a role
at varying extents at different stages of life.
Training metacognition
A critical question in educational sciences is that of the nature of
the relationship between metacognition and academic achieve-
ment to understand whether learning at school can be enhanced
by training metacognitive abilities. Does higher metacognition
lead to higher academic achievement? Do these features evolve in
parallel? Developmental research provides valuable insights into
the formation of metacognitive abilities that can inform training
designs in terms of what aspect of metacognition should be
supported and the age at which interventions may yield the best
results. First, meta-knowledge seems to emerge around the age of
5, meta-control around 8, and both develop over the years90, with
evidence for the development of meta-knowledge into adoles-
cence91.
Furthermore,
current
theories
propose
that
meta-
knowledge abilities are initially highly domain-dependent and
gradually become more domain-independent as knowledge and
dlPFC
lPFC
Insula
ACC
aPFC
pMFC
Parahippocampal
Gyrus
Precuneus
rlPFC
Online meta-knowledge
Online meta-control
vlPFC
rlPFC
Fig. 5
Brain regions associated with metacognition in the cognitive neuroscience literature. The regions are divided into online meta-
knowledge and meta-control, and ofﬂine meta-knowledge and meta-control following the distinctions introduced earlier. Some regions have
been reported to be related to both ofﬂine and online processes and are therefore given a striped pattern.
D.S. Fleur et al.
6
npj Science of Learning (2021)  13 
Published in partnership with The University of Queensland

experience are acquired and linked between domains32. Meta-
control is believed to evolve in a similar fashion90,92.
Common methods used to train ofﬂine metacognition are direct
instruction of metacognition, metacognitive prompts and learning
journals. In addition, research has been done on the use of (self-
directed) feedback as a means to induce self-reﬂection in students,
mainly in computer-supported settings93. Interestingly, learning
journals appear to be used for both assessing and fostering
metacognition. Metacognitive instruction consists of teaching
learners’ strategies to “activate” their metacognition. Metacognitive
prompts most often consist of text pieces that are sent at speciﬁc
times and that trigger reﬂection (ofﬂine meta-knowledge) on
learning behaviour in the form of a question, hint or reminder.
Meta-analyses have investigated the effects of direct metacog-
nitive instruction on students’ use of learning strategies and
academic outcomes18,94,95. Their ﬁndings show that metacognitive
instruction can have a positive effect on learning abilities and
achievement within a population ranging from primary schoolers
to university students. In particular, interventions lead to the
highest effect sizes when they both (i) instructed a combination of
metacognitive strategies with an emphasis on planning strategies
(ofﬂine meta-control) and (ii) “provided students with knowledge
about strategies” (ofﬂine meta-knowledge) and “illustrated the
beneﬁts of applying the trained strategies, or even stimulated
metacognitive reasoning” (p.114)18. The longer the duration of the
intervention, the more effective they were. The strongest effects
on academic performance were observed in the context of
mathematics, followed by reading and writing.
While metacognitive prompts and learning journals make up
the larger part of the literature on metacognitive training96, meta-
analyses that speciﬁcally investigate their effectiveness have yet to
be performed. Nonetheless, evidence suggests that such inter-
ventions can be successful. Researchers found that metacognitive
prompts fostered the use of metacognitive strategies (ofﬂine
meta-control)
and
that
the
combination
of
cognitive
and
metacognitive prompts improved learning outcomes97. Another
experiment showed that students who received metacognitive
prompts performed more metacognitive activities inside the
learning environment and displayed better transfer performance
immediately after the intervention98. A similar study using self-
directed prompts showed enhanced transfer performance that
was still observable 3 weeks after the intervention99.
Several studies suggest that learning journals can positively
enhance metacognition. Subjects who kept a learning journal
displayed stronger high meta-control and meta-knowledge on
learning tasks and tended to reach higher academic outcomes100–
102. However, how the learning journal is used seems to be critical;
good instructions are crucial97,103, and subjects who simply
summarise their learning activity beneﬁt less from the intervention
than subjects who reﬂect about their knowledge, learning and
learning goals104. An overview of studies using learning journals
and metacognitive prompts to train metacognition can be found
in Supplementary Table 3.
In recent years, educational neuroscience researchers have tried
to determine whether training and improvements in EF can lead
to learning facilitation and higher academic achievement. Training
may consist of having students continually perform behavioural
tasks either in the lab, at home, or at school. Current evidence in
favour of training EF is mixed, with only anecdotal evidence for
positive effects105. A meta-analysis did not show evidence for a
causal relationship between EF and academic achievement19, but
suggested that the relationship is bidirectional, meaning that the
two are “mutually supportive”106.
A recent review article has identiﬁed several gaps and short-
coming in the literature on metacognitive training96. Overall,
research in metacognitive training has been mainly invested in
developing learners’ meta-control rather than meta-knowledge.
Furthermore, most of the interventions were done in the context
of science learning. Critically, there appears to be a lack of studies
that employed randomised control designs, such that the effects
of metacognitive training intervention are often difﬁcult to
evaluate.
In
addition,
research
overwhelmingly
investigated
metacognitive prompts and learning journals in adults96, while
interventions on EF mainly focused on young children22. Lastly,
meta-analyses evaluating the effectiveness of metacognitive
training have so far focused on metacognitive instruction on
children. There is thus a clear disbalance between the meta-
analyses performed and the scope of the literature available.
An important caveat of educational sciences research is that
metacognition is not typically framed in terms of online and ofﬂine
metacognition. Therefore, it can be unclear whether protocols
operationalise online or ofﬂine processes and whether interventions
tend to beneﬁt more online or ofﬂine metacognition. There is also
confusion in terms of what processes qualify as EF and deﬁnitions
of it vary substantially86. For instance, Clements and colleagues
mention work on SRL to illustrate research in EF in relation to
academic achievement but the two spawn from different lines of
research, one rooted in metacognition and socio-cognitive theory31
and the other in the cognitive (neuro)science of decision-making. In
addition, the MSLQ, as discussed above, assesses ofﬂine metacogni-
tion along with other components relevant to SRL, whereas EF can
be mainly understood as online metacognition (see Table 1), which
on the neural level may rely on different circuitry.
Summary
Investigating ofﬂine metacognition tends to be carried out in
school settings whereas evaluating EF (e.g., Stroop task, and BRIEF)
is performed in the lab. Common to all protocols for ofﬂine
metacognition is that they consist of a form of self-report from the
learner, either during the learning activity (thinking-aloud proto-
cols) or after the learning activity (questionnaires, interviews and
learning journals). Questionnaires are popular protocols due to
how easy they are to administer but have been criticised to
provide biased evaluations of metacognitive abilities. In contrast,
learning journals evaluate the degree to which learners engage in
reﬂective thinking and may therefore be less prone to bias. Lastly,
it is unclear to what extent thinking-aloud protocols are sensitive
to online metacognitive processes, such as on-the-ﬂy error
correction and effort regulation. The strength of the relationship
between metacognitive abilities and academic achievement varies
depending on how metacognition is operationalised. Self-report
questionnaires and interviews are weakly related to achievement
whereas thinking-aloud protocols and EF are strongly related to it.
Based on the well-documented relationship between metacog-
nition and academic achievement, educational scientists hypothe-
sised that fostering metacognition may improve learning and
academic
achievement,
and
thus
performed
metacognitive
training interventions. The most prevalent training protocols are
direct metacognitive instruction, learning journals, and metacog-
nitive prompts, which aim to induce and foster ofﬂine metacog-
nitive processes such as self-reﬂection, planning and selecting
learning strategies. In addition, researchers have investigated
whether training EF, either through tasks or embedded in the
curriculum, results in higher academic proﬁciency and achieve-
ment. While a large body of evidence suggests that metacognitive
instruction, learning journals and metacognitive prompts can
successfully
improve
academic
achievement,
interventions
designed around EF training show mixed results. Future research
investigating EF training in different age categories may clarify this
situation. These various degrees of success of interventions may
indicate that ofﬂine metacognition is more easily trainable than
online metacognition and plays a more important role in
educational settings. Investigating the effects of different meth-
ods, ofﬂine and online, on the neural level, may provide
D.S. Fleur et al.
7
Published in partnership with The University of Queensland
npj Science of Learning (2021)  13 

researchers
with
insights
into
the
trainability
of
different
metacognitive processes.
DISCUSSION
In this article, we reviewed the literature on metacognition in
educational sciences and cognitive neuroscience with the aim to
investigate gaps in current research and propose ways to address
them through the exchange of insights between the two disciplines
and interdisciplinary approaches. The main aspects analysed were
operational deﬁnitions of metacognition and metacognitive train-
ing, through the lens of metacognitive knowledge and metacog-
nitive control. Our review also highlighted an additional construct in
the form of the distinction between online metacognition (on the
ﬂy and largely automatic) and ofﬂine metacognition (slower,
reﬂective and requiring meta-representations). In cognitive neu-
roscience, research has focused on metacognitive judgements
(mainly ofﬂine) and EF (mainly online). Metacognition is operatio-
nalised with tasks carried out in the lab and are mapped onto brain
functions. In contrast, research in educational sciences typically
measures metacognition in the context of learning activities, mostly
in schools and universities. More recently, EF has been studied in
educational settings to investigate its role in academic achievement
and whether training it may beneﬁt learning. Evidence on the latter
is however mixed. Regarding metacognitive training in general,
evidence from both disciplines suggests that interventions fostering
learners’ self-reﬂection and knowledge of their learning behaviour
(i.e., ofﬂine meta-knowledge) may best beneﬁt them and increase
academic achievement.
We focused on four aspects of research that could beneﬁt from
an interdisciplinary approach between the two areas: (i) validity
and reliability of research protocols, (ii) under-researched dimen-
sions of metacognition, (iii) metacognitive training, and (iv)
domain-speciﬁcity vs. domain generality of metacognitive abilities.
To tackle these issue, we propose four avenues for integrated
research: (i) investigate the degree to which different protocols
relate
to
similar
or
different
metacognitive
constructs,
(ii)
implement designs and perform experiments to identify neural
substrates necessary for ofﬂine meta-control by for example
borrowing protocols used in educational sciences, (iii) study the
effects of (ofﬂine) meta-knowledge training on the brain, and (iv)
perform developmental research in the metacognitive brain and
compare it with the existing developmental literature in educa-
tional sciences regarding the domain-generality of metacognitive
processes and metacognitive abilities.
First, neurocognitive research on metacognitive judgements
has
developed
robust
operationalisations
of
ofﬂine
meta-
knowledge. However, these operationalisations often consist of
speciﬁc tasks (e.g., 2-AFC) carried out in the lab. These tasks are
often very narrow and do not resemble the challenges and
complexities of behaviours associated with learning in schools and
universities. Thus, one may question to what extent they reﬂect
real-life metacognition, and to what extent protocols developed in
educational sciences and cognitive neuroscience actually oper-
ationalise the same components of metacognition. We propose
that comparing different protocols from both disciplines that are,
a priori, operationalising the same types of metacognitive
processes can help evaluate the ecological validity of protocols
used in cognitive neuroscience, and allow for more holistic
assessments of metacognition, provided that it is clear which
protocol assesses which construct. Degrees of correlation between
different protocols, within and between disciplines, may allow
researchers to assess to what extent they reﬂect the same
metacognitive constructs and also identify what protocols are
most appropriate to study a speciﬁc construct. For example, a
relation between meta-d′ metacognitive sensitivity in a 2-AFC task
and the meta-knowledge subscale of the MAI, would provide
external validity to the former. Moreover, educational scientists
would be provided with bias-free tools to assess metacognition.
These tools may enable researchers to further investigate to what
extent metacognitive bias, sensitivity and efﬁciency each play a
role in education settings. In contrast, a low correlation may
highlight a difference in domain between the two measures of
metacognition. For instance, metacognitive judgements in brain
research are made in isolated behaviour, and meta-d’ can thus be
viewed to reﬂect “local” metacognitive sensitivity. It is also unclear
to what extent processes involved in these decision-making tasks
cover those taking place in a learning environment. When
answering self-reported questionnaires, however, subjects make
metacognitive judgements on a large set of (learning) activities,
and the measures may thus resemble more “global” or domain-
general metacognitive sensitivity. In addition, learners in educa-
tional settings tend to receive feedback — immediate or delayed
— on their learning activities and performance, which is generally
not the case for cognitive neuroscience protocols. Therefore,
investigating metacognitive judgements in the presence of
performance or social feedback may allow researchers to better
understand the metacognitive processes at play in educational
settings. Devising a global measure of metacognition in the lab by
aggregating subjects’ metacognitive abilities in different domains
or investigating to what extent local metacognition may affect
global metacognition could improve ecological validity signiﬁ-
cantly. By investigating the neural correlates of educational
measures of metacognition, researchers may be able to better
understand to what extent the constructs studied in the two
disciplines are related. It is indeed possible that, though weakly
correlated, the meta-knowledge scale of the MAI and meta-d’
share a common neural basis.
Second, our review highlights gaps in the literature of both
disciplines regarding the research of certain types of metacogni-
tive processes. There is a lack of research in ofﬂine meta-control
(or strategic regulation of cognition) in neuroscience, whereas this
construct
is
widely
studied
in
educational
sciences.
More
speciﬁcally, while there exists research on EF related to planning
(e.g.107), common experimental designs make it hard to disen-
tangle online from ofﬂine metacognitive processes. A few studies
have implemented subject reports (e.g., awareness of error or
desire for reminders) to pin-point the neural substrates speciﬁcally
involved in ofﬂine meta-control and the current evidence points at
a role of the lPFC. More research implementing similar designs
may clarify this construct. Alternatively, researchers may exploit
educational sciences protocols, such as self-report questionnaires,
learning
journals,
metacognitive
prompts
and
feedback
to
investigate ofﬂine meta-control processes in the brain and their
relation to academic proﬁciency and achievement.
Third, there is only one study known to us on the training of
meta-knowledge in the lab78. In contrast,
meta-knowledge
training in educational sciences have been widely studied, in
particular with metacognitive prompts and learning journals,
although a systematic review would be needed to identify the
beneﬁts for learning. Relative to cognitive neuroscience, studies
suggest that ofﬂine meta-knowledge trained in and outside the
lab (i.e., metacognitive judgements and meditation, respectively)
transfer to meta-knowledge in other lab tasks. The case of
meditation is particularly interesting since meditation has been
demonstrated to beneﬁciate varied aspects of everyday life108.
Given its importance for efﬁcient regulation of cognition, training
(ofﬂine) meta-knowledge may present the largest beneﬁts to
academic achievement. Hence, it is important to investigate
development in the brain relative to meta-knowledge training.
Evidence on metacognitive training in educational sciences tends
to suggest that ofﬂine metacognition is more “plastic” and may
therefore beneﬁt learning more than online metacognition.
Furthermore, it is important to have a good understanding of
the developmental trajectory of metacognitive abilities — not
only on a behavioural level but also on a neural level — to identify
D.S. Fleur et al.
8
npj Science of Learning (2021)  13 
Published in partnership with The University of Queensland

critical periods for successful training. Doing so would also allow
researchers to investigate the potential differences in terms of
plasticity that we mention above. Currently, the developmental
trajectory of metacognition is under-studied in cognitive neu-
roscience with only one study that found an overlap between the
neural correlates of metacognition in adults and children109. On a
side note, future research could explore the potential role of
genetic factors in metacognitive abilities to better understand to
what extent and under what constraints they can be trained.
Fourth, domain-speciﬁc and domain-general aspects of metacog-
nitive processes should be further investigated. Educational scientists
have studied the development of metacognition in learners and have
concluded that metacognitive abilities are domain-speciﬁc at the
beginning (meaning that their quality depends on the type of
learning activity, like mathematics vs. writing) and progressively
evolve towards domain-general abilities as knowledge and expertise
increase.
Similarly,
neurocognitive
evidence
points
towards
a
common network for (ofﬂine) metacognitive knowledge which
engages the different regions at varying degrees depending on the
domain of the activity (i.e., perception, memory, etc.). Investigating
this network from a developmental perspective and comparing
ﬁndings with the existing behavioural literature may improve our
understanding of the metacognitive brain and link the two bodies of
evidence. It may also enable researchers to identify stages of life more
suitable for certain types of metacognitive intervention.
Received: 6 October 2020; Accepted: 9 April 2021;
REFERENCES
1. Dunlosky, J. & Metcalfe, J. Metacognition (SAGE Publications, 2008).
2. Pintrich, P. R. The role of metacognitive knowledge in learning, teaching, and
assessing. Theory Into Pract. 41, 219–225 (2002).
3. Zimmerman, B. J. Self-regulated learning and academic achievement: an over-
view. Educ. Psychol. 25, 3–17 (1990).
4. Zimmerman, B. J. & Schunk, D. H. Self-Regulated Learning and Academic
Achievement: Theoretical Perspectives (Routledge, 2001).
5. Baker, L. & Brown, A. L. Metacognitive Skills and Reading. In Handbook of
Reading Research Vol. 1 (ed. Pearson, P. D.) 353–395 (Longman, 1984).
6. Mckeown, M. G. & Beck, I. L. The role of metacognition in understanding and
supporting reading comprehension. In Handbook of Metacognition in Education
(eds Hacker, D. J., Dunlosky, J. & Graesser, A. C.) 19–37 (Routledge, 2009).
7. Desoete, A., Roeyers, H. & Buysse, A. Metacognition and mathematical problem
solving in grade 3. J. Learn. Disabil. 34, 435–447 (2001).
8. Veenman, M., Kok, R. & Blöte, A. W. The relation between intellectual and
metacognitive skills in early adolescence. Instructional Sci. 33, 193–211 (2005).
9. Harris, K. R., Graham, S., Brindle, M. & Sandmel, K. Metacognition and children’s
writing. In Handbook of metacognition in education 131–153 (Routledge, 2009).
10. Fleming, S. M. & Dolan, R. J. The neural basis of metacognitive ability. Philos.
Trans. R. Soc. B 367, 1338–1349 (2012).
11. Vaccaro, A. G. & Fleming, S. M. Thinking about thinking: a coordinate-based
meta-analysis of neuroimaging studies of metacognitive judgements. Brain
Neurosci. Adv. 2, 10.1177%2F2398212818810591 (2018).
12. Ferrari, M. What can neuroscience bring to education? Educ. Philos. Theory 43,
31–36 (2011).
13. Zadina, J. N. The emerging role of educational neuroscience in education
reform. Psicol. Educ. 21, 71–77 (2015).
14. Meulen, A., van der, Krabbendam, L. & Ruyter, Dde Educational neuroscience: its
position, aims and expectations. Br. J. Educ. Stud. 63, 229–243 (2015).
15. Varma, S., McCandliss, B. D. & Schwartz, D. L. Scientiﬁc and pragmatic challenges
for bridging education and neuroscience. Educ. Res. 37, 140–152 (2008).
16. van Atteveldt, N., van Kesteren, M. T. R., Braams, B. & Krabbendam, L. Neuroi-
maging of learning and development: improving ecological validity. Frontline
Learn. Res. 6, 186–203 (2018).
17. Hruby, G. G. Three requirements for justifying an educational neuroscience. Br. J.
Educ. Psychol. 82, 1–23 (2012).
18. Dignath, C., Buettner, G. & Langfeldt, H.-P. How can primary school students
learn self-regulated learning strategies most effectively?: A meta-analysis on
self-regulation training programmes. Educ. Res. Rev. 3, 101–129 (2008).
19. Jacob, R. & Parkinson, J. The potential for school-based interventions that target
executive function to improve academic achievement: a review. Rev. Educ. Res.
85, 512–552 (2015).
20. Kassai, R., Futo, J., Demetrovics, Z. & Takacs, Z. K. A meta-analysis of the
experimental evidence on the near- and far-transfer effects among children’s
executive function skills. Psychol. Bull. 145, 165–188 (2019).
21. Roebers, C. M. Executive function and metacognition: towards a unifying fra-
mework of cognitive self-regulation. Dev. Rev. 45, 31–51 (2017).
22. Clements, D. H., Sarama, J. & Germeroth, C. Learning executive function and
early mathematics: directions of causal relations. Early Child. Res. Q. 36, 79–90
(2016).
23. Nelson, T. O. & Narens, L. Metamemory. In Perspectives on the development of
memory and cognition (ed. R. V. Kail & J. W. Hag) 3–33 (Hillsdale, N.J.: Erlbaum, 1977).
24. Baird, J. R. Improving learning through enhanced metacognition: a classroom
study. Eur. J. Sci. Educ. 8, 263–282 (1986).
25. Flavell, J. H. & Wellman, H. M. Metamemory (1975).
26. Flavell, J. H. Metacognition and cognitive monitoring: a new area of
cognitive–developmental inquiry. Am. Psychol. 34, 906 (1979).
27. Livingston, J. A. Metacognition: An Overview. (2003).
28. Nelson, T. O. Metamemory: a theoretical framework and new ﬁndings. In Psy-
chology of Learning and Motivation Vol. 26 (ed. Bower, G. H.) 125–173 (Academic
Press, 1990).
29. Nelson, T. O. & Narens, L. Why investigate metacognition. In Metacognition: Knowing
About Knowing (eds Metcalfe, J. & Shimamura, A. P.) 1–25 (MIT Press, 1994).
30. Shimamura, A. P. A Neurocognitive approach to metacognitive monitoring and
control. In Handbook of Metamemory and Memory (eds Dunlosky, J. & Bjork, R. A.)
(Routledge, 2014).
31. Dinsmore, D. L., Alexander, P. A. & Loughlin, S. M. Focusing the conceptual lens
on metacognition, self-regulation, and self-regulated learning. Educ. Psychol.
Rev. 20, 391–409 (2008).
32. Borkowski, J. G., Chan, L. K. & Muthukrishna, N. A process-oriented model of
metacognition: links between motivation and executive functioning. In (Gregory
Schraw & James C. Impara) Issues in the Measurement of Metacognition 1–42
(Buros Institute of Mental Measurements, 2000).
33. Risko, E. F. & Gilbert, S. J. Cognitive ofﬂoading. Trends Cogn. Sci. 20, 676–688
(2016).
34. Gilbert, S. J. et al. Optimal use of reminders: metacognition, effort, and cognitive
ofﬂoading. J. Exp. Psychol. 149, 501 (2020).
35. Boldt, A. & Gilbert, S. Distinct and overlapping neural correlates of metacogni-
tive monitoring and metacognitive control. Preprint at bioRxiv https://psyarxiv.
com/3dz9b/ (2020).
36. Fernandez-Duque, D., Baird, J. A. & Posner, M. I. Executive attention and
metacognitive regulation. Conscious Cogn. 9, 288–307 (2000).
37. Baker, L., Zeliger-Kandasamy, A. & DeWyngaert, L. U. Neuroimaging evidence of
comprehension monitoring. Psihol. teme 23, 167–187 (2014).
38. Schwartz, B. L. Sources of information in metamemory: Judgments of learning
and feelings of knowing. Psychon. Bull. Rev. 1, 357–375 (1994).
39. Nelson, T. O. Metamemory, psychology of. In International Encyclopedia of the
Social & Behavioral Sciences (eds Smelser, N. J. & Baltes, P. B.) 9733–9738 (Per-
gamon, 2001).
40. Hart, J. T. Memory and the feeling-of-knowing experience. J. Educ. Psychol. 56,
208 (1965).
41. Arbuckle, T. Y. & Cuddy, L. L. Discrimination of item strength at time of pre-
sentation. J. Exp. Psychol. 81, 126 (1969).
42. Fechner, G. T. Elemente der Psychophysik (Breitkopf & Härtel, 1860).
43. Rouault, M., Seow, T., Gillan, C. M. & Fleming, S. M. Psychiatric symptom
dimensions are associated with dissociable shifts in metacognition but not task
performance. Biol. Psychiatry 84, 443–451 (2018).
44. Fleming, S. M., Weil, R. S., Nagy, Z., Dolan, R. J. & Rees, G. Relating introspective
accuracy to individual differences in brain structure. Science 329, 1541–1543
(2010).
45. McCurdy, L. Y. et al. Anatomical coupling between distinct metacognitive sys-
tems for memory and visual perception. J. Neurosci. 33, 1897–1906 (2013).
46. Fleming, S. M. & Lau, H. C. How to measure metacognition. Front. Hum. Neurosci.
8 https://doi.org/10.3389/fnhum.2014.00443 (2014).
47. Galvin, S. J., Podd, J. V., Drga, V. & Whitmore, J. Type 2 tasks in the theory of
signal detectability: discrimination between correct and incorrect decisions.
Psychon. Bull. Rev. 10, 843–876 (2003).
48. Metcalfe, J. & Schwartz, B. L. The ghost in the machine: self-reﬂective con-
sciousness and the neuroscience of metacognition. In (eds Dunlosky, J. &
Tauber, S. K.) Oxford Handbook of Metamemory 407–424 (Oxford University
Press, 2016).
49. Maniscalco, B. & Lau, H. A signal detection theoretic approach for estimating
metacognitive sensitivity from conﬁdence ratings. Conscious Cognition 21,
422–430 (2012).
D.S. Fleur et al.
9
Published in partnership with The University of Queensland
npj Science of Learning (2021)  13 

50. Rouault, M., McWilliams, A., Allen, M. G. & Fleming, S. M. Human metacognition
across domains: insights from individual differences and neuroimaging. Perso-
nal. Neurosci. 1 https://doi.org/10.1017/pen.2018.16 (2018).
51. Rounis, E., Maniscalco, B., Rothwell, J. C., Passingham, R. E. & Lau, H. Theta-burst
transcranial magnetic stimulation to the prefrontal cortex impairs metacognitive
visual awareness. Cogn. Neurosci. 1, 165–175 (2010).
52. Ye, Q., Zou, F., Lau, H., Hu, Y. & Kwok, S. C. Causal evidence for mnemonic
metacognition in human precuneus. J. Neurosci. 38, 6379–6387 (2018).
53. Fleming, S. M., Huijgen, J. & Dolan, R. J. Prefrontal contributions to metacog-
nition in perceptual decision making. J. Neurosci. 32, 6117–6125 (2012).
54. Morales, J., Lau, H. & Fleming, S. M. Domain-general and domain-speciﬁc pat-
terns of activity supporting metacognition in human prefrontal cortex. J. Neu-
rosci. 38, 3534–3546 (2018).
55. Baird, B., Smallwood, J., Gorgolewski, K. J. & Margulies, D. S. Medial and lateral
networks in anterior prefrontal cortex support metacognitive ability for memory
and perception. J. Neurosci. 33, 16657–16665 (2013).
56. Fleming, S. M., Ryu, J., Golﬁnos, J. G. & Blackmon, K. E. Domain-speciﬁc impair-
ment in metacognitive accuracy following anterior prefrontal lesions. Brain 137,
2811–2822 (2014).
57. Baldo, J. V., Shimamura, A. P., Delis, D. C., Kramer, J. & Kaplan, E. Verbal and
design ﬂuency in patients with frontal lobe lesions. J. Int. Neuropsychol. Soc. 7,
586–596 (2001).
58. Froböse, M. I. et al. Catecholaminergic modulation of the avoidance of cognitive
control. J. Exp. Psychol. Gen. 147, 1763 (2018).
59. Botvinick, M. M., Braver, T. S., Barch, D. M., Carter, C. S. & Cohen, J. D. Conﬂict
monitoring and cognitive control. Psychol. Rev. 108, 624 (2001).
60. Kerns, J. G. et al. Anterior cingulate conﬂict monitoring and adjustments in
control. Science 303, 1023–1026 (2004).
61. Yeung, N. Conﬂict monitoring and cognitive control. In The Oxford Handbook of
Cognitive Neuroscience: The Cutting Edges Vol. 2 (eds Ochsner, K. N. & Kosslyn, S.)
275–299 (Oxford University Press, 2014).
62. Botvinick, M. M. Conﬂict monitoring and decision making: reconciling two
perspectives on anterior cingulate function. Cogn. Affect. Behav. Neurosci. 7,
356–366 (2007).
63. Fleming, S. M., van der Putten, E. J. & Daw, N. D. Neural mediators of changes of
mind about perceptual decisions. Nat. Neurosci. 21, 617–624 (2018).
64. Ridderinkhof, K. R., Ullsperger, M., Crone, E. A. & Nieuwenhuis, S. The role of the
medial frontal cortex in cognitive control. Science 306, 443–447 (2004).
65. Koriat, A. The feeling of knowing: some metatheoretical implications for con-
sciousness and control. Conscious Cogn. 9, 149–171 (2000).
66. Thompson, V. A., Evans, J. & Frankish, K. Dual process theories: a metacognitive
perspective. Ariel 137, 51–43 (2009).
67. Arango-Muñoz, S. Two levels of metacognition. Philosophia 39, 71–82 (2011).
68. Shea, N. et al. Supra-personal cognitive control and metacognition. Trends Cogn.
Sci. 18, 186–193 (2014).
69. Nieuwenhuis, S., Ridderinkhof, K. R., Blom, J., Band, G. P. & Kok, A. Error-related
brain potentials are differentially related to awareness of response errors: evi-
dence from an antisaccade task. Psychophysiology 38, 752–760 (2001).
70. Overbeek, T. J., Nieuwenhuis, S. & Ridderinkhof, K. R. Dissociable components of
error processing: on the functional signiﬁcance of the Pe vis-à-vis the ERN/Ne. J.
Psychophysiol. 19, 319–329 (2005).
71. McGuire, J. T. & Botvinick, M. M. Prefrontal cortex, cognitive control, and the
registration of decision costs. Proc. Natl Acad. Sci. USA 107, 7922–7926 (2010).
72. Hester, R., Foxe, J. J., Molholm, S., Shpaner, M. & Garavan, H. Neural mechanisms
involved in error processing: a comparison of errors made with and without
awareness. Neuroimage 27, 602–608 (2005).
73. Melby-Lervåg, M. & Hulme, C. Is working memory training effective? A meta-
analytic review. Dev. Psychol. 49, 270 (2013).
74. Soveri, A., Antfolk, J., Karlsson, L., Salo, B. & Laine, M. Working memory training
revisited: a multi-level meta-analysis of n-back training studies. Psychon. Bull.
Rev. 24, 1077–1096 (2017).
75. Schwaighofer, M., Fischer, F. & Bühner, M. Does working memory training
transfer? A meta-analysis including training conditions as moderators. Educ.
Psychol. 50, 138–166 (2015).
76. Karbach, J. & Verhaeghen, P. Making working memory work: a meta-analysis of
executive-control and working memory training in older adults. Psychol. Sci. 25,
2027–2037 (2014).
77. Patel, R., Spreng, R. N. & Turner, G. R. Functional brain changes following cog-
nitive and motor skills training: a quantitative meta-analysis. Neurorehabil Neural
Repair 27, 187–199 (2013).
78. Carpenter, J. et al. Domain-general enhancements of metacognitive ability
through adaptive training. J. Exp. Psychol. 148, 51–64 (2019).
79. Baird, B., Mrazek, M. D., Phillips, D. T. & Schooler, J. W. Domain-speciﬁc
enhancement of metacognitive ability following meditation training. J. Exp.
Psychol. 143, 1972 (2014).
80. Winne, P. H. & Perry, N. E. Measuring self-regulated learning. In Handbook of Self-
Regulation (eds Boekaerts, M., Pintrich, P. R. & Zeidner, M.) Ch. 16, 531–566
(Academic Press, 2000).
81. Zimmerman, B. J. & Martinez-Pons, M. Development of a structured interview for
assessing student use of self-regulated learning strategies. Am. Educ. Res. J. 23,
614–628 (1986).
82. Park, C. Engaging students in the learning process: the learning journal. J. Geogr.
High. Educ. 27, 183–199 (2003).
83. Harrison, G. M. & Vallin, L. M. Evaluating the metacognitive awareness inven-
tory using empirical factor-structure evidence. Metacogn. Learn. 13, 15–38
(2018).
84. Pintrich, P. R., Smith, D. A. F., Garcia, T. & Mckeachie, W. J. Reliability and pre-
dictive validity of the motivated strategies for learning questionnaire (MSLQ).
Educ. Psychol. Meas. 53, 801–813 (1993).
85. Prevatt, F., Petscher, Y., Proctor, B. E., Hurst, A. & Adams, K. The revised Learning
and Study Strategies Inventory: an evaluation of competing models. Educ.
Psychol. Meas. 66, 448–458 (2006).
86. Baggetta, P. & Alexander, P. A. Conceptualization and operationalization of
executive function. Mind Brain Educ. 10, 10–33 (2016).
87. Gioia, G. A., Isquith, P. K., Guy, S. C. & Kenworthy, L. Test review behavior rating
inventory of executive function. Child Neuropsychol. 6, 235–238 (2000).
88. Ohtani, K. & Hisasaka, T. Beyond intelligence: a meta-analytic review of the
relationship among metacognition, intelligence, and academic performance.
Metacogn. Learn. 13, 179–212 (2018).
89. Dianovsky, M. T. & Wink, D. J. Student learning through journal writing in a
general education chemistry course for pre-elementary education majors. Sci.
Educ. 96, 543–565 (2012).
90. Veenman, M. V. J., Van Hout-Wolters, B. H. A. M. & Afﬂerbach, P. Metacognition
and learning: conceptual and methodological considerations. Metacogn Learn.
1, 3–14 (2006).
91. Weil, L. G. et al. The development of metacognitive ability in adolescence.
Conscious Cogn. 22, 264–271 (2013).
92. Veenman, M. & Spaans, M. A. Relation between intellectual and metacognitive
skills: Age and task differences. Learn. Individ. Differ. 15, 159–176 (2005).
93. Verbert, K. et al. Learning dashboards: an overview and future research
opportunities. Personal. Ubiquitous Comput. 18, 1499–1514 (2014).
94. Dignath, C. & Büttner, G. Components of fostering self-regulated learning
among students. A meta-analysis on intervention studies at primary and sec-
ondary school level. Metacogn. Learn. 3, 231–264 (2008).
95. Hattie, J., Biggs, J. & Purdie, N. Effects of learning skills interventions on student
learning: a meta-analysis. Rev. Educ. Res. 66, 99–136 (1996).
96. Zohar, A. & Barzilai, S. A review of research on metacognition in science edu-
cation: current and future directions. Stud. Sci. Educ. 49, 121–169 (2013).
97. Berthold, K., Nückles, M. & Renkl, A. Do learning protocols support learning
strategies and outcomes? The role of cognitive and metacognitive prompts.
Learn. Instr. 17, 564–577 (2007).
98. Bannert, M. & Mengelkamp, C. Scaffolding hypermedia learning through
metacognitive prompts. In International Handbook of Metacognition and
Learning Technologies Vol. 28 (eds Azevedo, R. & Aleven, V.) 171–186 (Springer
New York, 2013).
99. Bannert, M., Sonnenberg, C., Mengelkamp, C. & Pieger, E. Short- and long-
term effects of students’ self-directed metacognitive prompts on navigation
behavior and learning performance. Comput. Hum. Behav. 52, 293–306
(2015).
100. McCrindle, A. R. & Christensen, C. A. The impact of learning journals on meta-
cognitive and cognitive processes and learning performance. Learn. Instr. 5,
167–185 (1995).
101. Connor-Greene, P. A. Making connections: evaluating the effectiveness of
journal writing in enhancing student learning. Teach. Psychol. 27, 44–46 (2000).
102. Wong, B. Y. L., Kuperis, S., Jamieson, D., Keller, L. & Cull-Hewitt, R. Effects of
guided journal writing on students’ story understanding. J. Educ. Res. 95,
179–191 (2002).
103. Nückles, M., Schwonke, R., Berthold, K. & Renkl, A. The use of public learning
diaries in blended learning. J. Educ. Media 29, 49–66 (2004).
104. Cantrell, R. J., Fusaro, J. A. & Dougherty, E. A. Exploring the effectiveness of
journal writing on learning social studies: a comparative study. Read. Psychol. 21,
1–11 (2000).
105. Blair, C. Executive function and early childhood education. Curr. Opin. Behav. Sci.
10, 102–107 (2016).
106. Clements, D. H., Sarama, J., Unlu, F. & Layzer, C. The Efﬁcacy of an Intervention
Synthesizing Scaffolding Designed to Promote Self-Regulation with an Early
Mathematics Curriculum: Effects on Executive Function (Society for Research on
Educational Effectiveness, 2012).
107. Newman, S. D., Carpenter, P. A., Varma, S. & Just, M. A. Frontal and parietal
participation
in
problem
solving
in
the
Tower
of
London:
fMRI
and
D.S. Fleur et al.
10
npj Science of Learning (2021)  13 
Published in partnership with The University of Queensland

computational modeling of planning and high-level perception. Neuropsycho-
logia 41, 1668–1682 (2003).
108. Sedlmeier, P. et al. The psychological effects of meditation: a meta-analysis.
Psychol. Bull. 138, 1139 (2012).
109. Bellon, E., Fias, W., Ansari, D. & Smedt, B. D. The neural basis of metacognitive
monitoring during arithmetic in the developing brain. Hum. Brain Mapp. 41,
4562–4573 (2020).
ACKNOWLEDGEMENTS
We would like to thank the University of Amsterdam for supporting this research
through the Interdisciplinary Doctorate Agreement grant. W.v.d.B. is further
supported by the Jacobs Foundation, European Research Council (grant no. ERC-
2018-StG-803338), the European Union Horizon 2020 research and innovation
programme (grant no. DiGYMATEX-870578), and the Netherlands Organization for
Scientiﬁc Research (grant no. NWO-VIDI 016.Vidi.185.068).
AUTHOR CONTRIBUTIONS
D.S.F., B.B. and W.v.d.B. conceived the main conceptual idea of this review article. D.S.F.
wrote the manuscript with inputs from and under the supervision of B.B. and W.v.d.B.
COMPETING INTERESTS
The authors declare no competing interests.
ADDITIONAL INFORMATION
Supplementary information The online version contains supplementary material
available at https://doi.org/10.1038/s41539-021-00089-5.
Correspondence and requests for materials should be addressed to D.S.F.
Reprints and permission information is available at http://www.nature.com/
reprints
Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims
in published maps and institutional afﬁliations.
Open Access This article is licensed under a Creative Commons
Attribution 4.0 International License, which permits use, sharing,
adaptation, distribution and reproduction in any medium or format, as long as you give
appropriate credit to the original author(s) and the source, provide a link to the Creative
Commons license, and indicate if changes were made. The images or other third party
material in this article are included in the article’s Creative Commons license, unless
indicated otherwise in a credit line to the material. If material is not included in the
article’s Creative Commons license and your intended use is not permitted by statutory
regulation or exceeds the permitted use, you will need to obtain permission directly
from the copyright holder. To view a copy of this license, visit http://creativecommons.
org/licenses/by/4.0/.
© The Author(s) 2021
D.S. Fleur et al.
11
Published in partnership with The University of Queensland
npj Science of Learning (2021)  13 

