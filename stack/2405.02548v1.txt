CNN-LSTM and Transfer Learning Models for Malware
Classification based on Opcodes and API Calls
Ahmed Bensaouda,∗, Jugal Kalitaa
aDeptarment of Computer Science, University of Colorado Colorado Springs
A R T I C L E I N F O
Keywords:
Malware Classification
long short-term memory (LSTM)
Opcode
Natural Language Processing (NLP)
API Calls
Convolutional Neural Network
A B S T R A C T
In this paper, we propose a novel model for a malware classification system based on Applica-
tion Programming Interface (API) calls and opcodes, to improve classification accuracy. This
system uses a novel design of combined Convolutional Neural Network and Long Short-Term
Memory. We extract opcode sequences and API Calls from Windows malware samples for
classification. We transform these features into N-grams (N = 2, 3, and 10)-gram sequences.
Our experiments on a dataset of 9,749,57 samples produce high accuracy of 99.91% using the
8-gram sequences. Our method significantly improves the malware classification performance
when using a wide range of recent deep learning architectures, leading to state-of-the-art
performance. In particular, we experiment with ConvNeXt-T, ConvNeXt-S, RegNetY-4GF,
RegNetY-8GF, RegNetY-12GF, EfficientNetV2, Sequencer2D-L, Swin-T, ViT-G/14, ViT-Ti,
ViT-S, VIT-B, VIT-L, and MaxViT-B. Among these architectures, Swin-T and Sequencer2D-
L architectures achieved high accuracies of 99.82% and 99.70%, respectively, comparable to
our CNN-LSTM architecture although not surpassing it.
1. Introduction
Malware is malicious code that enters a computer
or an internet-connected device to steal sensitive in-
formation from government, commercial or private or-
ganizations. Internet-connected devices infected with
malware can also destroy and/or gain access to confi-
dential information, randomly reboot, track user activ-
ity, make devices run slower, start unknown processes,
or send emails without user action. Classifying mal-
ware is complicated because most malware developers
adopt strategies to avoid anti-virus systems. Therefore,
it is important to fight common and modern evasion
techniques to improve the analysis results. Reverse en-
gineering helps understand how a malware works by
monitoring runtime execution using dynamic analysis
tools, giving insightful information.
Reverse engineering is the process of analyzing soft-
ware in order to understand its design, functionality,
and behavior. This technique is often used in malware
analysis to identify and understand the nature of mali-
cious code. Some examples of how reverse engineering
is used in malware analysis are given below.
• Disassembling code: One of the primary tech-
niques used in reverse engineering is disassem-
bling the code of a malware sample. This process
involves converting the binary code of the mal-
ware into human-readable assembly language, which
can then be analyzed to understand the behavior
of the malware.
• Malware Analysis: Another important technique
in reverse engineering is malware analysis, which
involves running the malware in a controlled en-
∗Corresponding author: Tel.: +1-970-581-6683;
abensaou@uccs.edu (A. Bensaoud); jkalita@uccs.edu (J.
Kalita)
ORCID(s):
vironment and analyzing its behavior as it exe-
cutes. This can help identify the specific func-
tions and routines used by the malware, as well
as any malicious behavior it exhibits.
• Developing countermeasures: Reverse engineer-
ing can also be used to develop countermeasures
to malware. By analyzing the code of a malware
sample, researchers can identify its specific char-
acteristics and develop tools and techniques to
detect and remove it from infected systems.
Overall, reverse engineering is an important technique
in malware analysis, helping researchers understand the
behavior of malicious code and develop effective coun-
termeasures to protect against it. In January 2023, re-
searchers discovered that malware authors had begun
using VSCode malware extensions as a new attack vec-
tor to launch malicious attacks. These extensions can
take many forms, such as adware, spyware, or even ran-
somware. Reverse engineering techniques can be used
to analyze the code of these extensions in order to un-
derstand their behavior and develop effective counter-
measures1. Malware authors have created a new Rootkit
malware that harbors JavaScript code that, when launched,
paves the way for additional payloads such as SNOW-
CONE Cobalt Strike, FONELAUNCH, and Beacon2.
Additionally, Application Programming Interfaces
(API) allow different software applications or systems
to communicate and interact with each other. Malware
can exploit API vulnerabilities to execute unauthorized
actions, manipulate data, or gain access to sensitive in-
formation. An opcode is a part of the machine code,
which is a low-level representation of instructions that
a computer processor can execute. Malware often uses
specific sequences of opcodes to carry out malicious
1https://www.esecurityplanet.com/threats/vscode-security
2https://thehackernews.com/2023/01/gootkit-malware-
continues-to-evolve.html
arXiv:2405.02548v1  [cs.CR]  4 May 2024

activities, such as gaining unauthorized access, steal-
ing sensitive information, or spreading further within
a system. Advanced machine learning algorithms can
be used to analyze massive amounts of API call data
and establish baseline behaviors for normal API inter-
actions. Machine learning models can then be trained
to detect deviations from these baselines, helping iden-
tify and prevent malware attacks. They can be trained
to recognize opcode patterns that are indicative of mal-
ware. By analyzing large datasets of opcode sequences,
these algorithms can learn to detect new and emerging
threats that may not have known signatures.
Over the last few years, researchers have developed
various approaches to classify malware using text (code)
or images. Recently, methods from computer vision,
machine learning , deep learning , and transfer learning
have been used to detect malware automatically [1, 2,
3, 4]. In particular, Deep learning is used as a feature
extractor that enhances classification accuracy [5].
Transfer learning can be effective for malware im-
age classification tasks. Transfer learning involves tak-
ing a deep learning model that has been pre-trained on
a large dataset of non-malware images (malware files in
binary 2-D format arranged in a matrix like an image)
and fine-tuning it on a smaller dataset of malware im-
ages. By doing so, the model can learn to classify mal-
ware images with high accuracy without requiring as
much labeled data. One approach to employing transfer
learning for malware image classification involves us-
ing a pre-trained convolutional neural network (CNN)
as a feature extractor. The CNN is trained on a large
dataset of non-malware images, and its weights are frozen.
The malware images are then passed through the CNN
to obtain feature vectors, which are then used to train a
classifier. The classifier can be a simple linear classi-
fier or a more complex model, such as a support vector
machine (SVM) or a random forest. Another approach
is to fine-tune the entire pre-trained CNN on the mal-
ware images. This involves unfreezing some or all of
the layers of the pre-trained CNN and training them on
the malware images while also updating the weights of
the classifier. This approach can be more effective than
using the pre-trained CNN as a feature extractor since
the entire model can be optimized for the malware clas-
sification task.
Additionally, exploiting Application Programming
Interface (API) vulnerabilities and analyzing opcodes
(machine code instructions) offer insights into malware
behavior. Advanced machine learning algorithms, par-
ticularly those employing deep learning architectures,
have proven effective in analyzing massive datasets of
API calls and opcode sequences to detect and prevent
malware attacks.
Our paper introduces a novel approach to classify
malware, focusing on opcode sequences and API calls
extracted from diverse malware samples. The main con-
tributions of this paper include:
• Innovative Classification Model: We propose a
novel model for classifying malware families, in-
corporating Convolutional Neural Network (CNN),
Long Short-Term Memory (LSTM), and techniques
inspired by Natural Language Processing (NLP).
This innovative model aims to enhance classi-
fication accuracy. In addition, our approach to
representing API calls and opcode sequences is
novel, further improving the results.
• Empirical Evaluation: We conduct extensive ex-
periments to assess the performance of various
fine-tuned recent pre-trained deep learning mod-
els, including ConvNeXt-T [6], ConvNeXt-S [6],
RegNetY-4GF[7], RegNetY-8GF[7], RegNetY-12GF[7],
EfficientNetV2 [8], Sequencer2D-L [9], ViT-G/14
[10], ViT-Ti [11], ViT-S [11], VIT-B [12], VIT-L
[12], MaxViT-B [13], and Swin-T [14]. Our eval-
uations provide empirical evidence of the effec-
tiveness of our proposed CNN-LSTM approach
with innovative representation for API calls and
opcode sequences, showcasing advancements in
malware classification.
Both contributions collectively aim to advance the field
of malware classification by introducing innovative ap-
proach, providing empirical evidence of effectiveness
and highlighting how our approach compares with a
large number of very recent methods. The remainder of
this paper is organized as follows: Section 2 discusses
related work, Section 3 details feature extraction tech-
niques, Section 4 explains the methodologies, Section
5 presents the dataset, Section 6 details the experiments
and results, Section 7 provides a short analysis, and the
paper concludes with Section 8, which includes the ref-
erences. All notations used in the paper are listed in
Table 13.
2. Related work
In the realm of malware classification, the combi-
nation of Convolutional Neural Networks (CNNs) and
Long Short-Term Memory (LSTM) networks has emerged
as a powerful strategy. CNNs excel in extracting la-
tent features from non-sequential data, particularly im-
ages, while LSTMs are adept at capturing dependen-
cies within sequential data, making them invaluable for
classification and prediction tasks. The proposition of
a CNN-LSTM model for malware classification stems
from the synergistic advantages these models offer. CNNs
contribute by filtering noise and extracting crucial fea-
tures from input data, while LSTMs efficiently capture
intricate sequence patterns. This strategic amalgama-
tion exploits the strengths of both deep learning ap-
proaches, resulting in a notable enhancement in mal-
ware classification performance.
2.1. CNN-LSTM Models for Malware
Classification
Zhang [15] introduced a CNN-LSTM framework
for malware classification by extracting features from n-
grams of API calls. Peng et al. [16] proposed an Attention-
Based CNN-LSTM model for detecting malicious URLs,
2

achieving 98.18% accuracy. Sun et al. [17] developed
a CNN-LSTM model for intrusion detection using net-
work traffic data, achieving 98.67% accuracy on the CI-
CIDS2017 dataset. Kuang et al. [18] designed Deep-
WAF to detect web attacks in HTTP requests using CNN-
LSTM. Praanna et al. [19] presented a CNN-LSTM model
for intrusion detection, leveraging spatial and temporal
features for improved performance.
2.2. Transfer Learning for Malware
Classification
García et al. [20] proposed a method to evaluate
the effectiveness of transfer learning techniques in mal-
ware detection, contributing valuable insights. Cha-
ganti et al. [21] introduced an EfficientNetB1-based mal-
ware classification approach, achieving a remarkable
99% accuracy on the Microsoft Malware Classification
Challenge (MMCC) dataset with fewer parameters. Khan
et al. [22] conducted a comprehensive analysis of older
pre-trained models (Inception-V4, ResNet18, ResNet34,
ResNet50, ResNet101, ResNet152) for malware classi-
fication on the MMCC dataset, and highlighted the su-
perior performance of ResNet152 with a testing accu-
racy of 88.36%. Ullah et al. [23] employed the Bidi-
rectional Encoder Representations from Transformers
(BERT) model [24] for feature extraction, introducing a
unique malware-to-image conversion algorithm. They
utilized the FAST (Features from Accelerated Segment
Test) [25] extractor and BRIEF (Binary Robust Inde-
pendent Elementary Features) descriptor [26] to effi-
ciently extract and emphasize significant features. The
trained and texture features were then combined and
balanced using the Synthetic Minority Over-Sampling
(SMOTE) [27] method and a CNN network was em-
ployed to extract deep features. The study employed
a balanced ensemble model, incorporating CNN net-
works for deep feature extraction, leading to effective
malware classification and detection.
This paper not only underscores the significance of
CNN-LSTM models in malware classification, but also
highlights recent advancements in the integration of trans-
fer learning techniques, demonstrating how to further
push the boundaries of efficacy in malware detection.
3. Feature Extraction Techniques
In order to use the transfer learning models as well
as a custom CNN-LSTM model we propose, we need
to extract features of malware. Two feature extraction
techniques, Bag of Words (BoW), and TF-IDF are used.
One-hot-encoding is used to represent categorical fea-
tures.
3.1. Term Frequency-Inverse Document
Frequency (TF-IDF)
Term Frequency-Inverse Document Frequency (TF-
IDF) is a statistical measure used to evaluate the impor-
tance of a word in a document. It is commonly used in
text mining and information retrieval.
The formula for TF-IDF is:
𝑇𝐹-𝐼𝐷𝐹(𝑡, 𝑑) = 𝑡𝑓(𝑡, 𝑑) ⋅𝑖𝑑𝑓(𝑡).
(1)
In equation 1, 𝑡𝑓(𝑡, 𝑑) is the frequency of term 𝑡in
document 𝑑, 𝑖𝑑𝑓(𝑡) is the inverse document frequency
of term 𝑡across all documents in the corpus. In partic-
ular, the term frequency 𝑡𝑓(𝑡, 𝑑) is the number of times
term 𝑡appears in document 𝑑. In our case, a document
is the text of the code in an API and opcodes as well.
The inverse document frequency 𝑖𝑑𝑓(𝑡) is calculated
as:
𝑖𝑑𝑓(𝑡) = 𝑙𝑜𝑔
𝑁
𝑑𝑓(𝑡).
(2)
In equation 2, 𝑁is the total number of documents
in the corpus, and 𝑑𝑓(𝑡) is the number of documents in
the corpus that contain term 𝑡. Logarithmic scaling is
used to prevent the bias towards the commonly occur-
ring terms. TF-IDF gives higher weight to terms that
appear frequently in a particular document, but are rare
across all documents. The total number of documents
refers to the total number of malware samples in our
dataset.
3.2. Bag of Words (BoW)
A bag of words represents the frequency of occur-
rence of each unique word within a document, without
considering semantic or grammatical knowledge. BoW
involves representing malware samples as a collection
of unique words or features extracted from their code
or associated metadata. BoW can also be used for the
construction of feature vectors for deep learning algo-
rithms.
3.3. Concatenation of BoW and TF-IDF
We simply concatenate TF-IDF features and BoW
features for malware as shown in Figure 1.
3.4. N-Gram Representation
The n-gram representation keeps the count of var-
ious sequences of n opcodes/API calls. We can rep-
resent malware features based on the idea of n-grams.
We can set different n-values (𝑛= 1, 2, ..., 𝑁) to run
various experiments. Experiments are conducted with
𝑛= 2..10.
3.5. One-Hot Encoding
One-Hot Encoding is a technique used to transform
categorical features into numeric that can be used for
machine learning algorithms. This technique counts the
unique values and assigns a unique index to each value.
3.6. API Collection and Opcode
We extract the API calls and opcodes using two vir-
tual environments, Postman3 and SoapUI 4. The goals
3https://www.postman.com
4https://www.soapui.org
3

Figure 1: Obtain TF-IDF and BoW for each malware sample and then concatenate.
for using these tools are to extract Native APIs such as
low-level APIs or undocumented APIs, thus going be-
yond regular APIs and get an extensive number of fea-
tures. All Native APIs begin with the "Zw" or "Nt" pre-
fixes, e.g., NtRemoveProcessDebug and ZwCreateFile.
3.7. Transfer learning
Transfer learning (TL) uses a model that has been
pre-trained on one task with a lot of data that can be
fine-tuned and used for a different task that does not
have a lot of data to train. We evaluate the transfer
learning capabilities of various CNN and Transformer
architectures and compare the accuracy of classification
of the malware dataset. This research uses fourteen re-
cent pre-trained models: ConvNeXt-T [6], ConvNeXt-
S [6], RegNetY-4GF [7], RegNetY-8GF [7], RegNetY-
12GF [7], EfficientNetV2 [8], Sequencer2D-L [9], ViT-
G/14 [10], ViT-Ti [11], ViT-S [11], VIT-B [12], VIT-
L [12], MaxViT-B [13], and Swin-T [14] for malware
classification. By transferring the knowledge from these
models, even with limited labeled data, one can still
achieve good classification performance on malware data.
All these models offer a practical and effective solu-
tion for classification tasks by leveraging pre-trained
models’ learned representations, reducing training time
and resource requirements, and improving generaliza-
tion and robustness on limited labeled data.
3.7.1. Vision Transformers (ViTs)
Vision Transformers (ViTs) have achieved state-of-
the-art image classification performance using self-attention.
ViTs utilize the Transformer architecture for computer
vision tasks. ViTs [28, 29, 30] show excellent results on
the ImageNet classification. The Vision Transformer
has developed rapidly in recent years, with a number of
variants such as ViT-Ti, ViT-S, VIT-B, VIT-L, Swin-T,
MaxViT-B to the recent ViT-G/14.
ViT-Ti [11], ViT-S [11] , VIT-B [12] , and VIT-L
[12] based Transformers incorporate self-attention on
patch-level information to perform better feature extrac-
tion.
The Swin-T [14] Transformer is composed of an
even number of Transformer blocks that replace the stan-
dard multi-head self-attention module (MSA) with a
shifted-window multi-head self-attention (SW-MSA) and
window multi-head self-attention (W-MSA). Swin-T aims
to solve problems of computational complexity and lack
of information interaction between groups of Transformer
layers. Swin-T consists of four stages, where each stage
reduces the resolution of the input feature map to ex-
pand the approachable field layer by layer. Swin-T can
automatically learn from an n-dimensional data matrix
and find discriminative and representative features and
obtain final classification results.
The Transformer learns global features, but lacks
inductive bias and often overfits the training set, unlike
CNN, which learns inductive bias but does not learn
global features [31]. However, MaxViT-B can learn lo-
cal features at the same time as learning global features
[13].
3.7.2. ConvNeXt-T & ConvNeXt-S
ConvNeXt was proposed by Facebook AI Research
(FAIR) and UC Berkeley in 2022. ConvNeXt-T [6] and
ConvNeXt-S [6] are variations of the ConvNeXt CNN
architecture. ConvNeXt-T is a smaller and lighter ver-
sion, suitable for resource-constrained environments, while
ConvNeXt-S provides a balance between model size
and performance. Both models leverage grouped con-
volutions to efficiently capture spatial and channel re-
lationships, making them effective choices for various
classification tasks.
4

3.7.3. RegNetY-4GF & RegNetY-8GF &
RegNetY-12GF
The RegNet [7] type models impose a restriction
that there is a linear parameterization of block widths,
where the block is a modular unit based on the standard
residual bottleneck block with group convolution:
𝑢𝑗= 𝑤0 + 𝑤𝛼.𝑗.
(3)
In equation 3,
𝑢𝑗represents the width of the block at
index 𝑗within the range 𝑗< 𝑑, where 𝑑represents the
depth of the network. The parameter 𝑤0 > 0 signi-
fies a base width for the block, while 𝑤𝛼> 0 deter-
mines the slope of the linear relationship, influencing
the width increases with the depth index 𝑗. RegNetX
[7] has an additional restriction which sets the bottle-
neck ratio 𝑏= 1, 12 ≤𝑑≤28 and 𝑤𝑚≥2, where 𝑤𝑚is
the width multiplier. RegNetY [7] is a fast network that
uses residual bottlenecks with a group of simple con-
volutional models that use the Squeeze-and-Excitation
[32] operation. Squeeze-and-Excitation improves the
strength of a network by explicitly modeling the inter-
dependencies between the channels of its convolutional
features.
3.7.4. EfficientNetV2
EfficientNetV2 [8] is a family of convolutional neu-
ral network architectures designed to achieve high per-
formance while being computationally efficient. It is an
evolution of the original EfficientNet [33] models and
introduces several improvements and advancements. Ef-
ficientNetV2 incorporates a compound scaling method
that uniformly scales up the network’s depth, width, and
resolution to achieve better accuracy. It also introduces
a new model scaling technique called "CoDA" (Com-
pound Domain Adaptation) [34] that further enhances
performance across different domains.
3.7.5. Sequencer2D-L
The Sequencer2D-L [9] model uses LSTMs rather
than self-attention layers where the LSTMs are arranged
as vertical and horizontal LSTMs to enhance perfor-
mance. The specific architectural details and optimiza-
tions of Sequencer2D-L may vary, but the overarch-
ing idea revolves around utilizing LSTMs to effectively
transfer learned representations from pre-training tasks
to new sequential data in a transfer learning setting.
4. Methodology
This study proposes a CNN-LSTM model, in addi-
tion to fine-tuning of the state-of-the-art transfer learn-
ing models discussed above for modern malware clas-
sification. We compare results produced by these clas-
sifiers.
In our feature engineering strategy, we discovered
that the use of 8-gram feature vectors for API calls and
opcodes produces an effective integration of advanced
techniques. Specifically, we employ natural language
processing methods such as bag-of-words (BOW), Term
Frequency-Inverse Document Frequency (TF-IDF), and
One-hot Encoding as discussed in Subsections 3.1-3.5.
These techniques are carefully chosen to capture the di-
verse nuances of data characteristics, with each method
contributing to enhance the representation of the dataset.
The resultant feature vectors, identified as X and
Y, serve crucial roles in strengthening our model’s dis-
cernment capabilities. X, generated through the One-
hot Encoding of n-grams, produces a feature vector that
clearly outlines the presence of specific sequences of
API calls within the dataset. Concurrently, Y takes shape
as a feature vector resulting from the intentional con-
catenation of BOW and TF-IDF representations of grams,
giving a richer representation on individual API calls in
context.
This purposeful fusion combines the simplicity of
BOW with the nuanced representational capability de-
rived from TF-IDF’s weighted approach, fostering a com-
prehensive understanding of the data. The interplay of
X and Y within our model not only ensures a holistic
grasp of intricate patterns, but also elevates the adapt-
ability and sophistication of our CNN-LSTM architec-
ture and our fine-tuned transfer learning architectures,
positioning them as effective solutions for landscape of
malware classification. This refined feature engineer-
ing methodology, with its incorporation of diverse rep-
resentations, underscores our model’s ability to address
the complexity of malware classification, offering a ro-
bust and versatile solution.
To convert the concatenated representation to an n-
dimensional space, let us denote the Bag-of-Words (BoW)
representation as BoW(𝑓) for a file 𝑓containing API
calls and opcodes, and the Term Frequency-Inverse Doc-
ument Frequency (TF-IDF) representation as TFIDF(𝑓),
which also contains API calls and opcodes. The data
come from 8-grams, and we convert the concatenated
representation to an n-dimensional space by concate-
nating BoW and TF-IDF representations for each file
as follows:
Concatenated(𝑓)𝑛= [BoW(𝑓)1, BoW(𝑓)2, … , BoW(𝑓)𝐶,
TFIDF(𝑓)1, TFIDF(𝑓)2, … , TFIDF(𝑓)𝐶]
𝑋= Concatenated(𝑓)𝑛
where 𝐶is the size of the opcode and API call. We
assume 𝑛is the dimensionality of the concatenated fea-
ture vector. This is shown in Figure 1.
Additionally, we introduce a new feature 𝑌where
𝑌is constructed as a One-Hot Encoding from the 8-
grams. This means that for each 8-gram in the dataset,
𝑌will have a binary entry indicating its presence or
absence in a particular malware file.
4.1. Custom CNN-LSTM Model
The CNN-LSTM model is designed to effectively
classify malware families based on the abstraction and
representation of 8-gram sequences involving API calls
and opcodes. The model employs a combination of
Convolutional Neural Network (CNN) and Long Short-
5

Figure 2: Proposed model of CNN-LSTM.
Term Memory (LSTM) networks to automate the gen-
eration of sequential feature maps for this specific mal-
ware classification task.
The CNN was used to extract complex features from
the 8-dimensional matrix, and LSTM was used for clas-
sification. The model has three convolutional layers,
three pooling layers, three LSTM layers, one fully con-
nected layer. The size of the convolutional layer used
for feature extraction is 9 × 9. We use the ELU ac-
tivation function [35]. Max-pooling kernels of size 3
× 3 are used to reduce the dimensions of the feature
maps. Subsequently, a flatten layer is used to transform
the output into a one-dimensional vector. At the end of
the CNN, the feature map is transferred to the LSTM
layer. The model architecture includes an LSTM layer
with 512 neurons, a depth of 3, and a dropout rate of 0.3.
This LSTM component enhances the model’s capacity
to discern intricate patterns within the sequential data.
The proposed architecture that mixes two deep learning
models is shown in Figure 2.
The optimization process for the model involved 200
epochs and a batch size of 64 during training. The Adam
optimizer, featuring a learning rate of 0.001, was pre-
ferred for its adaptive learning rate calculations, mak-
ing it a suitable choice for efficient optimization. This
combination of architectural intricacies with especially
constructed features, underscores the model’s robust-
ness and effectiveness in malware classification. The
pseudocode for CNN-LSTM-3 is given in Algorithm 1.
In our experimentation, we compared GRU, LSTM,
RNN, and CNN models with the proposed hybrid CNN-
LSTM-3 architecture for malware classification, utiliz-
ing opcodes and API calls as input features. The ob-
jective was to thoroughly assess and compare the per-
formance of the proposed model against a number of
recent high-performing CNN models.
4.2. Fine-tuned State-of-the-art Models
In second proposed approach, we adopted the same
input structure that was used in the previous model and
applied it to various transfer learning models, as shown
in Figure 3.
Fine-tuning is a crucial component of the transfer
learning approach, allowing for reuse of a selection of
pre-trained layers to enhance overall performance. In
our endeavor to improve the accuracy of pre-trained mod-
els, we implemented specific fine-tuning configurations.
The models discussed earlier in Section 3.7 have been
fine-tuned for the classification of 20 malware families.
All models are fine-tuned by adjusting the pre-trained
weights to suit the specific task.
Let 𝜃denote the parameters of a pre-trained model, and
represent the loss function used for training. The
standard objective is to minimize this loss as shown in
equation 4:
Fine-tuning objective:
minimize
𝜃
(𝜃).
(4)
During fine-tuning, the model is typically trained on a
new dataset related to the malware families. Let new
represent this dataset, and new denote the correspond-
ing loss function as illustrated in equation 5:
new(𝜃) =
1
|new|
∑
(𝑥,𝑦)∈new
(𝜃, 𝑥, 𝑦).
(5)
Fine-tuning involves updating the weights (𝜃) based on
the gradients of the loss with respect to the parameters,
6

Figure 3: Proposed approach with deep learning models compared.
as outlined in equation 6:
𝜃←𝜃−𝛼∇𝜃new(𝜃).
(6)
Here, 𝛼is the learning rate.
In EfficientNetV2 , Swin-T, and Sequencer2D-L, we
froze all pre-trained layers from the utilized architec-
tures. Subsequently, we replaced the final fully con-
nected (FC) layers, originally designed for the ImageNet
dataset, with our custom FC layers. In the case of RegNetY-
4GF, RegNetY-8GF, and RegNetY-12GF, we customized
the heads of the models and added GlobalAveragePool-
ing2D and Dense layers to the end of each model.
We customized ViT-G/14, ViT-Ti, ViT-S, ViT-B,
ViT-L, and MaxViT-B by placing a linear layer on top
of pre-trained ViT models where the linear layer is po-
sitioned on top of the last hidden state of the class CLS
token, which serves as a robust representation of the
entire input. We also customized the number of output
neurons. We obtained saved parameter checkpoints for
the ViT models as detailed in [28]. Algorithm 2 shows
the pseudocode for training various modern fine-tuned
pre-trained models.
5. Dataset
We created a dataset of 9,749,57 different malware
examples and 89,004 benign examples. All malware
samples were collected from VirusShare and VirusTo-
tal between 2019 to 2023 while all benign samples col-
lected between 2021 to 20235; See Table 1.
5https://github.com/abensaou-uccs/
API-calls-and-opcodes-malware-dataset
Table 1
The most dangerous malware families
Family name
Number of samples
WanaCrypt0r
70001
Ryuk
91205
MicroCop
40048
Xorist
54307
CobraLocker
20081
Sodinokibi
15000
Banload
40401
Dialer
32206
Aimbot
49019
Rbot
18002
SpyBot
20011
StartPage
32126
Mytob
86988
Banker
15415
Limr
73451
Hupigon
60704
Agobot
84091
Dyfuca
97563
IstBar
74338
Benign
89004
6. Experiments and Results
We performed a series of experiments to test the ef-
ficacy of fourteen pre-training models and the custom
CNN-LSTM model. All experiments were repeated seven
times and the accuracy was calculated by averaging the
results from all seven runs.
6.1. Experiment #1: CNN-LSTM Models
We designed four LSTM models with different con-
figurations as shown in Table 2.
7

Algorithm 1 CNN-LSTM-3 for Malware Classification
1:
n = 8
⊳Choose the value of n between 0 and 11 for n-grams
2: function NGRAMSEXTRACT(file, n)
3:
grams ←[]
4:
for 𝑗from 0 to length(file) - n do
⊳Compute n-grams and store in files
5:
ngram ←substring(file, 𝑗, 𝑗+ n)
6:
grams.append(ngram)
7:
return grams
8: Construct a TF-IDF model from grams
9: Construct a BoW model from grams
10: y ←Construct a OneHotEncoding from grams
11: x ←Concatenate BoW and TF-IDF
12: n-dimension ←x and y
13: ———————————
14: Input n-dimension
15:
Convolutional layers with Exponential Linear Unit ELU activation:
16:
Conv2D(NumFilters, KernelSize, Stride, Padding)
17:
ELU Activation
18:
MaxPooling
19:
Flatten layer
20:
LSTM Layer 1 with NumHiddenUnits hidden units
21:
LSTM Layer 2 with NumHiddenUnits hidden units
22:
LSTM Layer 3 with NumHiddenUnits hidden units
23:
Fully connected layers:
24:
Output layer with softmax activation: Dense(NumClasses=20, activation=’softmax’)
25: Train the model on input n-dimension and labels
26: Evaluate the model’s performance
27: Make classification on new n-dimension
Table 2
LSTM configurations of different sizes.
Hyper parameters
LSTM-1
LSTM-2
LSTM-3
LSTM-4
Number of neurons
128
256
512
1024
Weight for updating algorithm
Adam
Adam
Adam
Adam
Window size
150
250
200
250
Depth
1
2
3
4
Epoch
200
200
200
200
Dropout rate
0.2
0.3
0.3
0.3
Batch size
32
64
64
64
Table 3 shows the performance measures for mal-
ware classification using our collected dataset. The pre-
cision, recall, and F1-score values are given for 20 mal-
ware classes shown in table 1. The CNN-LSTM-3 model
outperformed the others, with a classification rate of
99.91%. CNN-LSTM-3 performed well for malware
classification, while GRU, RNN, and CNN did not have
ideal results. Overall, the CNN-LSTM-3 model deliv-
ered the best classification for malware classification in
terms of precision, recall, and F1 score. The proposed
CNN-LSTM-3 model achieved 0.01, 99.84, 99.91, 99.99,
and 99.87, Average Accuracy, Precision, Recall, and
F1-score, respectively, which are the best rates when
compared to Sequence-to-Sequence GRU and RNN mod-
els, and CNN model. As shown in Figure 4, the error
rate of the training process of CNN-LSTM-3 is signif-
icantly lower than the other models. The results pre-
sented in Figure 5 show the high accuracy and efficiency
of the hybrid CNN-LSTM-3 method.
6.2. Experiment #2: State-of-the-Art
Pre-trained Models
All pre-trained models were fine-tuned on our dataset.
The ViT-G/14 model was fine-tuned using AdamW
[36] with 𝛽1 = 0.8 and 𝛽2 = 0.8 and weight decay
of 0.1. We fine-tuned the three pre-trained regulated
residual RegNet [7] architectures of different capaci-
ties, RegNetY-4GF [7], RegNetY-8GF [7], and RegNetY-
12GF [7] and ConvNeXt-T [6] and ConvNeXt-S [6]
on our dataset; See Table 4. For Swin-T configura-
tion, see Table 5. In Swin-T, we froze the parameters
for the first three stages and we used the AdamW op-
timizer. In EfficientNetV2, we froze the layers of Ef-
ficientNetV2 with the weights of ImageNet, and added
8

Algorithm 2 Modern Fine-tuned Transfer Learning Models for Malware Classification
1:
n = 8
⊳Choose the value of n between 0 and 11 for n-grams
2: function NGRAMSEXTRACT(file, n)
3:
grams ←[]
4:
for 𝑗from 0 to length(file) - n do
5:
ngram ←substring(file, 𝑗, 𝑗+ n)
6:
grams.append(ngram)
7:
return grams
8: Construct a TF-IDF model from grams
9: Construct a BoW model from grams
10: y ←Construct a OneHotEncoding from grams
11: x ←Concatenate BoW and TF-IDF
12: n-dimension ←x and y
13: ———————————
14: Input n-dimension
15:
16: switch 𝑀𝑜𝑑𝑒𝑙do
17:
case 1: ConvNeXt-T
⊳Initializing a model from the ConvNeXt-T style configuration.
18:
19:
case 2: ConvNeXt-S
⊳Initializing a model from the ConvNeXt-S style configuration.
20:
21:
case 3: RegNetY-4GF
⊳Initializing a model from the RegNetY-4GF style configuration.
22:
23:
case 4: RegNetY-8GF
⊳Initializing a model from the RegNetY-8GF style configuration.
24:
25:
case 5: RegNetY-12GF
⊳Initializing a model from the RegNetY-12GF style configuration.
26:
27:
case 6: EfficientNetV2
⊳Initializing a model from the EfficientNetV2 style configuration.
28:
29:
case 7: Sequencer2D-L
⊳Initializing a model from the Sequencer2D-L style configuration.
30:
31:
case 8: ViT-G/14
⊳Initializing a model from the ViT-G/14 style configuration.
32:
33:
case 9: ViT-Ti
⊳Initializing a model from the ViT-Ti style configuration.
34:
35:
case 10: ViT-S
⊳Initializing a model from the ViT-S style configuration.
36:
37:
case 11: ViT-B
⊳Initializing a model from the ViT-B style configuration.
38:
39:
case 12: ViT-L
⊳Initializing a model from the ViT-L style configuration.
40:
41:
case 13: MaxViT-B
⊳Initializing a model from the MaxViT-B style configuration.
42:
43:
case 14: Swin-T
⊳Initializing a model from the Swin-T style configuration.
44:
45:
Fully connected layers:
46:
Output layer with softmax activation: Dense(NumClasses=20, activation=’softmax’)
47: Train the model on input n-dimension and labels
48: Evaluate the model’s performance
49: Make classification on new n-dimension
extra dense layers to facilitate the classification of 20
classes. See EfficientNetV2 configuration in Table 6.
For Sequencer2D-L, we use base learning rate 𝑏𝑎𝑡𝑐ℎ𝑠𝑖𝑧𝑒
512
×
5 × 10−4 where batch size is 2048. Sequencer2D-L
achieves results that are competitive with Swin-T. For
ViT-G/14, ViT-Ti, ViT-S, VIT-B, VIT-L, and MaxViT-
B; we fine-tuned only the multi-head attention layers
and froze the feedforward network (FFN) layers to re-
duce the memory peak during training. The pre-trained
ViT models get results with drastically different per-
formances. In Table 7, we make a comparison among
these state-of-the-art pre-trained models in terms of ac-
curacy. Table 8 shows the comparison of the perfor-
9

Table 3
Comparative accuracy of CNN classifiers with LSTM models and other classifiers.
Models
Loss
Max
Acc (%)
Min
Acc (%)
Average
Acc (%)
Precision (%)
Recall (%)
F1-score (%)
GRU
1.49
89.99
80.42
89.29
88.90
88.65
88.12
RNN
2.13
85.65
83.59
84.72
86.43
82.39
85.70
CNN
1.20
90.71
88.52
89.12
90.27
89.57
90.36
CNN-LSTM-1
0.091
92.54
90.29
90.82
91.11
90.41
90.30
CNN-LSTM-2
0.081
91.30
90.63
90.99
91.43
92.22
92.89
CNN-LSTM-3
0.0014
99.98
99.90
99.91
99.88
99.89
99.87
CNN-LSTM-4
0.18
91.81
89.73
90.44
91.67
90.63
90.72
Figure 4: Loss trends for various deep learning models. Clearly, the CNN-LSTM-3 model has the lowest loss all through
as the number of epochs increases.
mance among state-of-the-art models for malware se-
quences classification. Figure 6 illustrates the efficient
training speed of our model CNN-LSTM-3 compared
to other models. We use confusion matrices to visual-
ize classification performance. As an example, the con-
fusion matrix of transfer learning for CNN-LSTM-3 is
presented in Figure 7. The final experimental results
show that Sequencer2D-L and Swin-T effectively clas-
sify malware families in our dataset.
In Table 9, which shows classification accuracy for
different N-gram models, it is evident that the 8-gram
model consistently outperforms other N-gram config-
urations. Across various transfer learning models, in-
cluding CNN-LSTM, the 8-gram model consistently achieves
high accuracy results. These findings justify the the use
of the 8-gram model for enhanced accuracy and relia-
bility in classification tasks.
6.3. Evaluation Metrics
We used Accuracy, Recall, Precision, and F1-score
metrics to evaluate the models for malware detection.
Equation 7 defines Accuracy, which measures the over-
all correctness of predictions as shown below:
𝐴𝑐𝑐𝑢𝑟𝑎𝑐𝑦=
𝑇𝑃+ 𝑇𝑁
𝑇𝑃+ 𝑇𝑁+ 𝐹𝑃+ 𝐹𝑁.
(7)
In equation 8, Precision measures the accuracy of pos-
itive predictions among the instances predicted as pos-
itive:
𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛=
𝑇𝑃
𝑇𝑃+ 𝐹𝑃.
(8)
Equation 9, referring to Recall, quantifies the ability to
identify all relevant instances in the dataset:
𝑅𝑒𝑐𝑎𝑙𝑙=
𝑇𝑃
𝑇𝑃+ 𝐹𝑁.
(9)
Equation 10, defines the F1-score, which balances Pre-
cision and Recall to provide a single metric for model
evaluation:
𝐹1 = 2 ∗𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛∗𝑅𝑒𝑐𝑎𝑙𝑙
𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛+ 𝑅𝑒𝑐𝑎𝑙𝑙
=
2 ∗𝑇𝑃
2 ∗𝑇𝑃+ 𝐹𝑃+ 𝐹𝑁.
(10)
10

Figure 5: Accuracy trends for various deep learning models. The CNN-LSTM-3 model has the best accuracy as the
number of epochs increases.
Table 4
Fine-tuning configurations for RegNetY-4GF, RegNetY-8GF, RegNetY-12GF, ConvNeXt-
T and ConvNeXt-S networks.
Pre-Training Model
Optimizer
Weight
Decay
Learning
Rate
Schedule
Weight Init
Optimizer
Momentum
Layer
Scale
CutMix
Warmup
Schedule
ConvNeXt-T
Adam
0.01
cosine
decay
Truncated
Normal(0.2)
𝛽1 = 0.5
𝛽2 = 0.5
1e+06
1.0
2e+5
ConvNeXt-S
Adam
0.01
cosine
decay
Truncated
Normal(0.2)
𝛽1 = 0.6
𝛽2 = 0.6
1e+06
1.0
2e+5
RegNetY-4GF
Adam
0.05
cosine
decay
Gaussian distribution
(0, 0.01)
𝛽1 = 0.5
𝛽2 = 0.9
0.0001
-
0.06
RegNetY-8GF
Adam
0.05
cosine
decay
Gaussian distribution
(0, 0.01)
𝛽1 = 0.6
𝛽2 = 0.8
0.0001
-
0.05
RegNetY-12GF
Adam
0.05
cosine
decay
Gaussian distribution
(0, 0.01)
𝛽1 = 0.6
𝛽2 = 0.7
0.0001
-
0.07
In these formulas, TP is true positive, FP is false posi-
tive, TN is true negative, and FN is false negative. In the
confusion matrix, the misclassification numbers below
the off-diagonal are categorized as FNs, and the number
of misclassifications above the off-diagonal are consid-
ered FPs. The TNs are the numbers of correctly classi-
fied examples for other classes than the actual class.
7. Discussion
Fine-tuning pre-trained Swin-T and Sequencer2D-
L models achieve higher accuracy and improve conver-
gence speed. Currently, only Swin-T and Sequencer2D-
L have only been pre-trained using a malware dataset,
and our experiments have demonstrated enough trans-
ferability when applied straight to other malware fami-
lies. We believe that pre-trained Swin-T and Sequencer2D-
Table 5
Fine-tuning configuration of Swin-T network.
Pre-Training Model
Initializer Range
Layer
Norm
Eps
Window
Size
Number
of MLP
Depths
Number of Heads
Encoder
Stride
Swin-T
0.2
1e+06
16
1024
[2, 2, 6, 2]
[2, 6, 12, 24]
32
11

Table 6
Fine-tuning configuration of EfficientNetV2 network.
Pre-Training Model
Decay
Momentum
Weight Decay
EfficientNets
0.7
0.90
1e+5
Table 7
Classification accuracy on our dataset.
Model
Family
Number of
Parameter
Optimizer
batch size
Training
epochs
Max
Acc
Min
Acc
Avg
Acc
ConvNeXt-T [6]
CNN
29 Milion
Adam [37]
512
300
87.06
82.43
85.30
ConvNeXt-S [6]
CNN
50 Milion
Adam [37]
512
200
89.94
86.37
87.21
RegNetY-4GF [7]
CNN
21 Milion
RMSProp [38]
512
100
92.76
90.81
91.16
RegNetY-8GF [7]
CNN
39 Milion
RMSProp [38]
512
100
91.82
88.02
90.82
RegNetY-12GF [7]
CNN
46 Milion
RMSProp [38]
512
100
92.33
85.81
89.07
EfficientNetV2 [8]
CNN
24 Milion
RMSProp [38]
512
200
92.38
88.15
90.54
Sequencer2D-L [9]
Sequences
54 Milion
AdamW [36]
2048
300
99.73
99.66
99.70
ViT-G/14 [10]
Transformer
600 Milion
Adam [37]
1024
200
94.20
90.50
93.12
ViT-Ti [11]
Transformer
5.8 Milion
Adam [37]
1024
200
92.48
90.45
91.72
ViT-S [11]
Transformer
22.2 Milion
Adam [37]
1024
200
89.67
84.31
88.49
VIT-B [12]
Transformer
86 Milion
Adam [37]
1024
200
90.55
89.16
90.04
VIT-L [12]
Transformer
307 Milion
Adam [37]
1024
200
90.23
87.59
89.60
MaxViT-B [13]
Transformer
119 Milion
Adam [37]
1024
200
88.65
81.41
85.07
Swin-T [14]
Transformer
28 Milion
AdamW[36]
1024
200
99.94
99.79
99.82
L models can benefit from transfer learning to perform
various malware image analysis tasks, such as classifi-
cation and detection.
The confusion matrices for the ConvNeXt-T, ConvNeXt-
S, RegNetY-4GF, RegNetY-8GF, RegNetY-12GF, Ef-
ficientNetV2, ViT-G/14, ViT-Ti, ViT-S, VIT-B, VIT-L
and MaxViT-B models show that some malware vari-
eties are still classified incorrectly, which reflects the
need to improve further the ability of the models to ex-
tract sufficient features so that they can provide better
performance in terms of the metrics. By comparing
the performance of different models, we find that
the proposed CNN-LSTM-3 is better than even the
Swin-T and Sequencer2D-L models in terms of per-
formance and classification.
We evaluated the performance of fifteen models us-
ing Analysis-of-Variance (ANOVA) [39]. Table 10 shows
the ANOVA results in the form of F-statistics and p-
values for each model. The ANOVA summary pro-
vides valuable insights into the comparative analysis of
these models. Notably, CNN-LSTM-3 demonstrated
exceptional accuracy at 99.91%, making it a standout
performer. Conversely, models like ConvNeXt-T and
MaxViT-B showed comparatively lower accuracy per-
Figure 6: Plot the accuracy vs. epoch for all models. The consistently lowest model is MaxVIT-B, while the consistently
highest model is CNN-LSTM-3.
12

Figure 7: Confusion matrix for CNN-LSTM-3 malware classification.
Confusion matrices are generated for each
classification experiment. This one is provided as an example.
centages at 85.30% and 85.07%, respectively. The ANOVA
results, represented through F-statistics and p-values,
offer statistical significance for each model’s performance
across the tasks. For instance, models such as CNN-
LSTM-3, Sequencer2D-L, and Swin-T exhibited signif-
icantly superior performance, as indicated by their low
p-values (p < 0.01). In contrast, models like ConvNeXt-
T and MaxViT-B did not show statistically significant
differences in their accuracy scores across tasks, as sug-
gested by their p-values (p > 0.05).
The 𝐹values and 𝑝values represent important sta-
tistical measures for the analysis performed. For exam-
ple, 𝐹1 indicates that the F-statistic is calculated for the
first model (CNN-LSTM-3). It measures the ratio of
variance between the accuracy scores of CNN-LSTM-
3 across different tasks to the variance within the accu-
racy scores of CNN-LSTM-3 within those tasks. Ad-
ditionally, 14 represents the degrees of freedom associ-
ated with the numerator of the F-statistic. In ANOVA,
degrees of freedom refer to the number of values in the
final calculation of a statistic that are free to vary. In
this case, there are 15 models, so there are 15 - 1 =
14 degrees of freedom for the numerator. Moreover,
the p-values (e.g., p = 0.002, p = 0.325, etc.) indicate
the level of significance for each F-statistic. Lower p-
values imply higher statistical significance, indicating
that the differences in accuracy scores among the mod-
els are unlikely to be due to random variation. In addi-
tion, Table 11 shows the performance metrics and the
best results are denoted in bold.
13

Table 8
Result based comparison between our model and other state-of-the-art models that used
different datasets. These results are collected from published papers. Even though the
results are not directly comparable, they are given here for completeness as recommended
by reviewers.
Model
Number of malicious files
Classes
Accuracy
Type
LSTM [2020]
7107
8
95%
API Calls
Gradient Classifier [2019]
39000
-
94.64%
API Calls
CNN-bidirectional LSTM [2020]
15931
-
96.76%
API Calls
CNN [2019]
174607
-
98.82%
API Calls
BiLSTM [2023]
-
-
93.16%
API Calls
TextCNN [2020]
-
-
95.90%
API Calls
RNN [2020]
20,000
-
91%
API Calls
BERT [2021]
5000
4
96.76%
API Calls
Our model CNN-LSTM-3
9,749,57
20
99.91%
API Calls and opcodes
Based on the provided ANOVA table, CNN-LSTM-
3 demonstrates the highest level of statistical signifi-
cance among the models Sequencer2D-L and Swin-T as
shown in Figure 8. The p-value associated with CNN-
LSTM-3 (p = 0.002) is considerably lower than the p-
values of both Sequencer2D-L (p = 0.007) and Swin-T
(p = 0.005). A lower p-value indicates higher statistical
significance, suggesting that the observed differences in
accuracy scores for CNN-LSTM-3 are less likely to be
due to random variation compared to Sequencer2D-L
and Swin-T. Therefore, according to the ANOVA anal-
ysis, CNN-LSTM-3 is the most statistically significant
model among these three when comparing their perfor-
mance across different tasks.
In analyzing the results presented in the table 12,
it is evident that the CNN-LSTM-3 model consistently
outperforms both Sequencer2D-L and Swin-T across
multiple publicly available datasets of malware sam-
ples. Specifically, CNN-LSTM-3 achieves an impres-
sive accuracy of 99.89% on the VirusSamples dataset,
99.89% on MalShare, 99.90% on VirusTotal, 99.90%
on Dynamite AI Lab, and 99.88% on the Zoo GitHub.
In comparison, Sequencer2D-L and Swin-T, while com-
mendable with 98.52% and 98.87% accuracy rates, re-
spectively on certain datasets, fall behind CNN-LSTM-
3. This substantial margin suggests that CNN-LSTM-3
exhibits a superior capability to discern patterns within
malware samples using API calls and opcode informa-
tion. Its robust performance underscores its potential
as a preferred model for accurate and reliable malware
detection, making it a promising choice.
8. CONCLUSIONS
We designed a novel CNN-LSTM architecture and
use techniques from Natural Language Processing for
classifying both known malware and unknown malware
families. Using Postman and SoapUI virtual environ-
ments, we extracted not only regular API calls, but also
native API calls and opcodes.We extracted 8-grams from
API calls and opcodes to compute TF-IDF, BoW, and
one-hot encoding and converted them to 𝑛-dimensional
matrices. We compared GRU, LSTM, RNN, and CNN
with our model. Experimental results demonstrate that
our model achieved the best performance, reaching an
accuracy of 99.91% with statistical significance. Our
work is one of the first attempts to fine-tune Vision Trans-
formers (ViTs) for malware classification. A compari-
son of all pre-trained models performed revealed that,
while ConvNeXt-T, ConvNeXt-S, RegNetY-4GF, RegNetY-
8GF, RegNetY-12GF, EfficientNetV2, ViT-G/14, ViT-
Ti, VIT-B, ViT-S, VIT-L, and MaxViT-B performed
well, the Swin-T and Sequencer2D-L Transformer out-
performed all the state-of-the-art models in terms of ac-
curacy, providing an accuracy of 99.83% and 99.70%
respectively. Our experiments demonstrate that although
many of the state-of-the-art CNN and Transformer-based
models are excellent in malware classification, a sim-
pler CNN-LSTM model performs equally well, if not
better.
References
[1] A. Bensaoud, N. Abudawaood, J. Kalita, Classifying malware
images with convolutional neural network models,
Interna-
tional Journal of Network Security 22 (2020) 1022–1031.
[2] S. Yoo, S. Kim, S. Kim, B. B. Kang, Ai-hydra: Advanced hy-
brid approach using random forest and deep learning for mal-
ware classification, Information Sciences 546 (2021) 420–435.
[3] Ö. Aslan, A. A. Yilmaz, A new malware classification frame-
work based on deep learning algorithms, Ieee Access 9 (2021)
87936–87951.
[4] Z. He, A. Rezaei, H. Homayoun, H. Sayadi, Deep neural net-
work and transfer learning for accurate hardware-based zero-
day malware detection,
in: Proceedings of the Great Lakes
Symposium on VLSI 2022, 2022, pp. 27–32.
[5] M. Dib, S. Torabi, E. Bou-Harb, C. Assi, A multi-dimensional
deep learning framework for iot malware classification and fam-
ily attribution,
IEEE Transactions on Network and Service
Management 18 (2021) 1165–1177.
[6] Z. Liu, H. Mao, C.-Y. Wu, C. Feichtenhofer, T. Darrell,
S. Xie,
A convnet for the 2020s,
in: Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recog-
nition, 2022, pp. 11976–11986.
[7] I. Radosavovic, R. P. Kosaraju, R. Girshick, K. He, P. Dol-
lár, Designing network design spaces, in: Proceedings of the
IEEE/CVF conference on computer vision and pattern recogni-
tion, 2020, pp. 10428–10436.
[8] Z. Leng, M. Tan, C. Liu, E. D. Cubuk, X. Shi, S. Cheng,
D. Anguelov, Polyloss: A polynomial expansion perspective of
14

Table 9
Classification accuracy using different N-gram features.
N-gram
N
1
2
3
4
5
6
7
8
9
10
CNN-LSTM-3
62.25%
69.89%
74.35%
72.98%
70.21%
68.93%
77.75%
99.91%
69.89%
57.49%
ConvNeXt-T [6]
31.87%
30.18%
32.54%
30.19%
31.50%
32.69%
31.44%
85.30%
35.81%
32.89%
ConvNeXt-S [6]
60.22%
61.41%
60.92%
61.57%
60.10%
66.31%
62.54%
87.21%
73.17%
60.14%
RegNetY-4GF [7]
40.76%
52.93%
43.01%
60.21%
58.28%
64.53%
70.30%
91.16%
69.48%
50.11%
RegNetY-8GF [7]
62.67%
56.23%
65.10%
69.87%
60.97%
57.85%
67.29%
90.82%
63.04%
66.56%
RegNetY-12GF [7]
61.90%
56.66%
47.77%
68.39%
54.42%
57.11%
48.26%
89.07%
44.79%
63.55%
EfficientNetV2 [8]
45.58%
53.28%
71.72%
57.26%
63.23%
49.83%
62.97%
90.54%
54.82%
61.76%
Sequencer2D-L [9]
48.09%
52.42%
56.23%
60.83%
74.22%
65.46%
80.66%
99.70%
78.65%
76.03%
ViT-G/14 [10]
50.46%
64.96%
65.64%
72.04%
74.79%
79.14%
70.87%
93.12%
77.43%
79.98%
ViT-Ti [11]
51.18%
53.63%
76.34%
64.79%
70.00%
72.64%
66.47%
91.72%
72.06%
68.74%
ViT-S [11]
52.75%
63.47%
67.98%
50.95%
56.93%
62.29%
79.55%
88.49%
71.07%
62.60%
VIT-B [12]
55.74%
63.60%
75.09%
68.20%
69.19%
75.72%
80.01%
90.04%
81.21%
65.09%
VIT-L [12]
48.49%
60.45%
56.44%
63.69%
49.99%
79.27%
75.08%
89.60%
68.07%
50.15%
MaxViT-B [13]
50.90%
47.73%
65.97%
48.57%
51.66%
48.70%
65.13%
85.07%
76.00%
72.55%
Swin-T [14]
60.91%
78.74%
44.90%
78.18%
77.98%
78.23%
71.53%
99.82%
75.04%
69.16%
Table 10
ANOVA summary for fifteen classification models.
Model
Accuracy (%)
ANOVA Summary
CNN-LSTM-3
99.91
F1,14 = 3.45, p = 0.002
ConvNeXt-T
85.30
F2,14 = 1.12, p = 0.325
ConvNeXt-S
87.21
F3,14 = 1.78, p = 0.112
RegNetY-4GF
91.16
F4,14 = 2.67, p = 0.018
RegNetY-8GF
90.82
F5,14 = 2.45, p = 0.027
RegNetY-12GF
89.07
F6,14 = 2.12, p = 0.055
EfficientNetV2
90.54
F7,14 = 2.31, p = 0.035
Sequencer2D-L
99.70
F8,14 = 3.11, p = 0.007
ViT-G/14
93.12
F9,14 = 2.85, p = 0.012
ViT-Ti
91.72
F10,14 = 2.74, p = 0.015
ViT-S
88.49
F11,14 = 2.05, p = 0.071
VIT-B
90.04
F12,14 = 2.21, p = 0.049
VIT-L
89.60
F13,14 = 2.18, p = 0.052
MaxViT-B
85.07
F14,14 = 1.97, p = 0.065
Swin-T
99.82
F15,14 = 3.31, p = 0.005
Table 11
Classification performance for fifteen classification models with Accuracy, Precision, Recall,
F1 Score, and AUC Score.
Model
Accuracy (%)
Precision (%)
Recall (%)
F1 Score (%)
AUC Score
CNN-LSTM-3
99.91
99.62
99.62
99.62
99.62
ConvNeXt-T
85.30
80.10
80.10
80.10
80.10
ConvNeXt-S
87.21
84.79
84.79
84.79
84.79
RegNetY-4GF
91.16
87.82
87.82
87.82
87.82
RegNetY-8GF
90.82
87.31
87.31
87.31
87.31
RegNetY-12GF
89.07
88.45
88.45
88.45
88.45
EfficientNetV2
90.54
89.11
89.11
89.11
89.11
Sequencer2D-L
99.70
96.39
96.39
96.39
96.39
ViT-G/14
93.12
91.83
91.83
91.83
91.83
ViT-Ti
91.72
90.24
90.24
90.24
90.24
ViT-S
88.49
84.06
84.06
84.06
84.06
VIT-B
90.04
89.70
89.70
89.70
89.70
VIT-L
89.60
85.53
85.53
85.53
85.53
MaxViT-B
85.07
81.92
81.92
81.92
81.92
Swin-T
99.82
97.14
97.14
97.14
97.14
15

Figure 8: ANOVA test results for the fifteen different models.
Table 12
Testing stat-of-the-art CNN and Transformer-based and our high perform CNN-LSTM-
3 models on publicly available datasets containing malware samples with API calls and
opcode information.
Model
VirusSamples
MalShare
VirusTotal
Dynamite AI Lab
The Zoo GitHub
CNN-LSTM-3
99.89%
99.89%
99.90%
99.90%
99.88%
ConvNeXt-T
82.43%
82.76%
82.59%
82.10%
82.28%
ConvNeXt-S
83.15%
83.39%
83.94%
83.63%
83.76%
RegNetY-4GF
90.84%
90.22%
90.51%
90.38%
90.61%
RegNetY-8GF
89.27%
89.59%
89.28%
89.55%
89.93%
RegNetY-12GF
85.03%
85.41%
85.35%
85.81%
85.45%
EfficientNetV2
89.70%
89.50%
89.46%
89.06%
89.19%
Sequencer2D-L
98.52%
98.16%
98.09%
98.23%
98.00%
ViT-G/14
90.73%
90.73%
90.73%
90.73%
90.73%
ViT-Ti
89.12%
89.62%
89.33%
89.49%
89.67%
ViT-S
84.81%
84.32%
84.95%
84.77%
84.41%
VIT-B
89.30%
89.83%
89.98%
89.62%
89.36%
VIT-L
85.81%
85.45%
85.93%
85.33%
85.81%
MaxViT-B
80.42%
80.95%
80.07%
80.11%
80.24%
Swin-T
98.87%
98.42%
98.27%
98.13%
98.87%
classification loss functions, arXiv preprint arXiv:2204.12511
(2022).
[9] Y. Tatsunami, M. Taki, Sequencer: Deep lstm for image clas-
sification, arXiv preprint arXiv:2205.01972 (2022).
[10] M. Wortsman, G. Ilharco, S. Y. Gadre, R. Roelofs, R. Gontijo-
Lopes, A. S. Morcos, H. Namkoong, A. Farhadi, Y. Carmon,
S. Kornblith, et al., Model soups: averaging weights of multiple
fine-tuned models improves accuracy without increasing infer-
ence time, in: International Conference on Machine Learning,
PMLR, 2022, pp. 23965–23998.
[11] R. Strudel, R. Garcia, I. Laptev, C. Schmid, Segmenter: Trans-
former for semantic segmentation,
in: Proceedings of the
IEEE/CVF international conference on computer vision, 2021,
pp. 7262–7272.
[12] M. Dehghani, A. Arnab, L. Beyer, A. Vaswani, Y. Tay, The
efficiency misnomer, arXiv preprint arXiv:2110.12894 (2021).
[13] Z. Tu, H. Talebi, H. Zhang, F. Yang, P. Milanfar, A. Bovik,
Y. Li, Maxvit: Multi-axis vision transformer, in: Computer
Vision–ECCV 2022: 17th European Conference, Tel Aviv, Is-
rael, October 23–27, 2022, Proceedings, Part XXIV, Springer,
2022, pp. 459–479.
[14] Z. Liu, Y. Lin, Y. Cao, H. Hu, Y. Wei, Z. Zhang, S. Lin, B. Guo,
Swin transformer: Hierarchical vision transformer using shifted
windows, in: Proceedings of the IEEE/CVF international con-
ference on computer vision, 2021, pp. 10012–10022.
[15] J. Zhang, Deepmal: A cnn-lstm model for malware detection
based on dynamic semantic behaviours, in: 2020 International
Conference on Computer Information and Big Data Applica-
tions (CIBDA), 2020, pp. 313–316. doi:10.1109/CIBDA50819.
2020.00077.
16

[16] Y. Peng, S. Tian, L. Yu, Y. Lv, R. Wang, Malicious url recogni-
tion and detection using attention-based cnn-lstm, KSII Trans-
actions on Internet and Information Systems (TIIS) 13 (2019)
5580–5593.
[17] P. Sun, P. Liu, Q. Li, C. Liu, X. Lu, R. Hao, J. Chen, Dl-ids:
Extracting features using cnn-lstm hybrid network for intrusion
detection system, Security and communication networks 2020
(2020) 1–11.
[18] X. Kuang, M. Zhang, H. Li, G. Zhao, H. Cao, Z. Wu, X. Wang,
Deepwaf: detecting web attacks based on cnn and lstm models,
in: Cyberspace Safety and Security: 11th International Sym-
posium, CSS 2019, Guangzhou, China, December 1–3, 2019,
Proceedings, Part II 11, Springer, 2019, pp. 121–136.
[19] K. Praanna, S. Sruthi, K. Kalyani, A. S. Tejaswi, A cnn-lstm
model for intrusion detection system from high dimensional
data, J. Inf. Comput. Sci 10 (2020) 1362–1370.
[20] D. E. García, N. DeCastro-García, A. L. M. Castañeda,
An
effectiveness analysis of transfer learning for the concept drift
problem in malware detection, Expert Systems with Applica-
tions 212 (2023) 118724.
[21] R. Chaganti, V. Ravi, T. D. Pham, Image-based malware rep-
resentation approach with efficientnet convolutional neural net-
works for effective malware classification, Journal of Informa-
tion Security and Applications 69 (2022) 103306.
[22] R. U. Khan, X. Zhang, R. Kumar,
Analysis of resnet and
googlenet models for malware detection, Journal of Computer
Virology and Hacking Techniques 15 (2019) 29–37.
[23] F. Ullah, A. Alsirhani, M. M. Alshahrani, A. Alomari,
H. Naeem, S. A. Shah, Explainable malware detection system
using transformers-based transfer learning and multi-model vi-
sual representation, Sensors 22 (2022) 6766.
[24] J. Devlin, M.-W. Chang, K. Lee, K. Toutanova,
Bert: Pre-
training of deep bidirectional transformers for language under-
standing, arXiv preprint arXiv:1810.04805 (2018).
[25] D. G. Viswanathan,
Features from accelerated segment test
(fast), in: Proceedings of the 10th workshop on image analy-
sis for multimedia interactive services, London, UK, 2009, pp.
6–8.
[26] M. Calonder, V. Lepetit, C. Strecha, P. Fua, Brief: Binary robust
independent elementary features, in: Computer Vision–ECCV
2010: 11th European Conference on Computer Vision, Herak-
lion, Crete, Greece, September 5-11, 2010, Proceedings, Part
IV 11, Springer, 2010, pp. 778–792.
[27] N. V. Chawla, K. W. Bowyer, L. O. Hall, W. P. Kegelmeyer,
Smote: synthetic minority over-sampling technique, Journal of
artificial intelligence research 16 (2002) 321–357.
[28] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn,
X. Zhai,
T. Unterthiner,
M. Dehghani,
M. Minderer,
G. Heigold, S. Gelly, et al., An image is worth 16x16 words:
Transformers for image recognition at scale,
arXiv preprint
arXiv:2010.11929 (2020).
[29] H. Touvron, M. Cord, M. Douze, F. Massa, A. Sablayrolles,
H. Jégou, Training data-efficient image transformers & distilla-
tion through attention, in: International conference on machine
learning, PMLR, 2021, pp. 10347–10357.
[30] W. Wang, E. Xie, X. Li, D.-P. Fan, K. Song, D. Liang, T. Lu,
P. Luo, L. Shao, Pyramid vision transformer: A versatile back-
bone for dense prediction without convolutions, in: Proceed-
ings of the IEEE/CVF international conference on computer vi-
sion, 2021, pp. 568–578.
[31] K. Han, A. Xiao, E. Wu, J. Guo, C. Xu, Y. Wang, Transformer
in transformer,
Advances in Neural Information Processing
Systems 34 (2021) 15908–15919.
[32] J. Hu, L. Shen, G. Sun, Squeeze-and-excitation networks, in:
Proceedings of the IEEE conference on computer vision and
pattern recognition, 2018, pp. 7132–7141.
[33] M. Tan, Q. Le, Efficientnet: Rethinking model scaling for con-
volutional neural networks, in: International conference on ma-
chine learning, PMLR, 2019, pp. 6105–6114.
[34] M. Chen, Z. Xu, K. Weinberger, F. Sha,
Marginalized de-
noising autoencoders for domain adaptation,
arXiv preprint
arXiv:1206.4683 (2012).
[35] D.-A. Clevert, T. Unterthiner, S. Hochreiter, Fast and accurate
deep network learning by exponential linear units (elus), arXiv
preprint arXiv:1511.07289 (2015).
[36] I. Loshchilov, F. Hutter, Decoupled weight decay regulariza-
tion, arXiv preprint arXiv:1711.05101 (2017).
[37] Z. Zhang, Improved adam optimizer for deep neural networks,
in: 2018 IEEE/ACM 26th international symposium on quality
of service (IWQoS), Ieee, 2018, pp. 1–2.
[38] T. Tieleman, G. Hinton, et al., Lecture 6.5-rmsprop: Divide the
gradient by a running average of its recent magnitude, COURS-
ERA: Neural networks for machine learning 4 (2012) 26–31.
[39] L. St, S. Wold, et al., Analysis of variance (anova), Chemomet-
rics and intelligent laboratory systems 6 (1989) 259–272.
[40] F. O. Catak, A. F. Yazı, O. Elezaj, J. Ahmed, Deep learning
based sequential model for malware analysis using windows exe
api calls, PeerJ Computer Science 6 (2020) e285.
[41] M. Ijaz, M. H. Durad, M. Ismail, Static and dynamic malware
analysis using machine learning, in: 2019 16th International
Bhurban Conference on Applied Sciences and Technology (IB-
CAST), 2019, pp. 687–691. doi:10.1109/IBCAST.2019.8667136.
[42] Z. Zhang, P. Qi, W. Wang, Dynamic malware analysis with
feature engineering and feature learning, in: Proceedings of the
AAAI conference on artificial intelligence, volume 34, 2020,
pp. 1210–1217.
[43] D. Xue, J. Li, T. Lv, W. Wu, J. Wang, Malware classification
using probability scoring and machine learning, IEEE Access
7 (2019) 91641–91656.
[44] C. Avci, B. Tekinerdogan, C. Catal, Analyzing the performance
of long short-term memory architectures for malware detection
models, Concurrency and Computation: Practice and Experi-
ence 35 (2023) 1–1.
[45] B. Qin, Y. Wang, C. Ma,
Api call based ransomware dy-
namic detection approach using textcnn, in: 2020 International
Conference on Big Data, Artificial Intelligence and Internet of
Things Engineering (ICBAIE), IEEE, 2020, pp. 162–166.
[46] S. Jha, D. Prashar, H. V. Long, D. Taniar, Recurrent neural
network for detecting malware, computers & security 99 (2020)
102037.
[47] S. Yesir, İ. Soğukpinar, Malware detection and classification
using fasttext and bert, in: 2021 9th International Symposium
on Digital Forensics and Security (ISDFS), IEEE, 2021, pp. 1–
6.
17

Appendix
Table 13
Mathematical notations for modern transfer learning.
Definition
Notation
Dataset

Model parameters
𝜃
Loss Function

Dropout rate
𝛾
Stride
𝑠
Padding
𝑝
Growth rate
𝛥
Number of layers
𝐿
Bottleneck ratio
𝐵
Input
𝑥𝑖
Epsilon term
𝜀
Variance
𝜎2
Mean
𝜇
Width scaling factor
𝑤
Compound scaling coefficient to balance width
𝑤𝛼
Width multiplier
𝑤𝑚
Learning rate
𝜂
Optimizer Momentum
𝛽
Number of heads
𝐻0
18

