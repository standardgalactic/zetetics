more information  - www.cambridge.org/9781107030657


Bayesian Filtering and Smoothing
Filtering and smoothing methods are used to produce an accurate estimate of the state
of a time-varying system based on multiple observational inputs (data). Interest in
these methods has exploded in recent years, with numerous applications emerging in
ﬁelds such as navigation, aerospace engineering, telecommunications, and medicine.
This compact, informal introduction for graduate students and advanced
undergraduates presents the current state-of-the-art ﬁltering and smoothing methods
in a uniﬁed Bayesian framework. Readers learn what non-linear Kalman ﬁlters and
particle ﬁlters are, how they are related, and their relative advantages and
disadvantages. They also discover how state-of-the-art Bayesian parameter estimation
methods can be combined with state-of-the-art ﬁltering and smoothing algorithms.
The book’s practical and algorithmic approach assumes only modest mathematical
prerequisites. Examples include MATLAB computations, and the numerous
end-of-chapter exercises include computational assignments. MATLAB/GNU Octave
source code is available for download at www.cambridge.org/sarkka, promoting
hands-on work with the methods.
simo s¨arkk¨a worked, from 2000 to 2010, with Nokia Ltd., Indagon Ltd., and the
Nalco Company in various industrial research projects related to telecommunications,
positioning systems, and industrial process control. Currently, he is a Senior
Researcher with the Department of Biomedical Engineering and Computational
Science at Aalto University, Finland, and Adjunct Professor with Tampere University
of Technology and Lappeenranta University of Technology. In 2011 he was a visiting
scholar with the Signal Processing and Communications Laboratory of the Department
of Engineering at the University of Cambridge. His research interests are in state and
parameter estimation in stochastic dynamic systems and, in particular, Bayesian
methods in signal processing, machine learning, and inverse problems with
applications to brain imaging, positioning systems, computer vision, and audio
signal processing. He is a Senior Member of the IEEE.

INSTITUTE OF MATHEMATICAL STATISTICS
TEXTBOOKS
Editorial Board
D. R. Cox (University of Oxford)
A. Agresti (University of Florida)
B. Hambly (University of Oxford)
S. Holmes (Stanford University)
X.-L. Meng (Harvard University)
IMS Textbooks give introductory accounts of topics of current concern suitable for
advanced courses at master’s level, for doctoral students and for individual study. They
are typically shorter than a fully developed textbook, often arising from material
created for a topical course. Lengths of 100–290 pages are envisaged. The books
typically contain exercises.

Bayesian Filtering and Smoothing
SIMO S ¨ARKK ¨A
Aalto University, Finland

cambridge university press
Cambridge, New York, Melbourne, Madrid, Cape Town,
Singapore, S˜ao Paulo, Delhi, Mexico City
Cambridge University Press
The Edinburgh Building, Cambridge CB2 8RU, UK
Published in the United States of America by Cambridge University Press, New York
www.cambridge.org
Information on this title: www.cambridge.org/9781107030657
C⃝Simo S¨arkk¨a 2013
This publication is in copyright. Subject to statutory exception
and to the provisions of relevant collective licensing agreements,
no reproduction of any part may take place without the written
permission of Cambridge University Press.
First published 2013
Printed and bound in the United Kingdom by the MPG Books Group
A catalogue record for this publication is available from the British Library
Library of Congress Cataloguing in Publication data
ISBN 978-1-107-03065-7 Hardback
ISBN 978-1-107-61928-9 Paperback
Additional resources for this publication at www.cambridge.org/sarkka
Cambridge University Press has no responsibility for the persistence or
accuracy of URLs for external or third-party internet websites referred to
in this publication, and does not guarantee that any content on such
websites is, or will remain, accurate or appropriate.

Contents
Preface
ix
Symbols and abbreviations
xiii
1
What are Bayesian ﬁltering and smoothing?
1
1.1
Applications of Bayesian ﬁltering and smoothing
1
1.2
Origins of Bayesian ﬁltering and smoothing
7
1.3
Optimal ﬁltering and smoothing as Bayesian inference
8
1.4
Algorithms for Bayesian ﬁltering and smoothing
12
1.5
Parameter estimation
14
1.6
Exercises
15
2
Bayesian inference
17
2.1
Philosophy of Bayesian inference
17
2.2
Connection to maximum likelihood estimation
17
2.3
The building blocks of Bayesian models
19
2.4
Bayesian point estimates
20
2.5
Numerical methods
22
2.6
Exercises
24
3
Batch and recursive Bayesian estimation
27
3.1
Batch linear regression
27
3.2
Recursive linear regression
29
3.3
Batch versus recursive estimation
31
3.4
Drift model for linear regression
33
3.5
State space model for linear regression with drift
36
3.6
Examples of state space models
39
3.7
Exercises
46
4
Bayesian ﬁltering equations and exact solutions
51
4.1
Probabilistic state space models
51
4.2
Bayesian ﬁltering equations
54
4.3
Kalman ﬁlter
56
v

vi
Contents
4.4
Exercises
62
5
Extended and unscented Kalman ﬁltering
64
5.1
Taylor series expansions
64
5.2
Extended Kalman ﬁlter
69
5.3
Statistical linearization
75
5.4
Statistically linearized ﬁlter
77
5.5
Unscented transform
81
5.6
Unscented Kalman ﬁlter
86
5.7
Exercises
92
6
General Gaussian ﬁltering
96
6.1
Gaussian moment matching
96
6.2
Gaussian ﬁlter
97
6.3
Gauss–Hermite integration
99
6.4
Gauss–Hermite Kalman ﬁlter
103
6.5
Spherical cubature integration
106
6.6
Cubature Kalman ﬁlter
110
6.7
Exercises
114
7
Particle ﬁltering
116
7.1
Monte Carlo approximations in Bayesian inference
116
7.2
Importance sampling
117
7.3
Sequential importance sampling
120
7.4
Sequential importance resampling
123
7.5
Rao–Blackwellized particle ﬁlter
129
7.6
Exercises
132
8
Bayesian smoothing equations and exact solutions
134
8.1
Bayesian smoothing equations
134
8.2
Rauch–Tung–Striebel smoother
135
8.3
Two-ﬁlter smoothing
139
8.4
Exercises
142
9
Extended and unscented smoothing
144
9.1
Extended Rauch–Tung–Striebel smoother
144
9.2
Statistically linearized Rauch–Tung–Striebel smoother
146
9.3
Unscented Rauch–Tung–Striebel smoother
148
9.4
Exercises
152
10
General Gaussian smoothing
154
10.1
General Gaussian Rauch–Tung–Striebel smoother
154
10.2
Gauss–Hermite Rauch–Tung–Striebel smoother
155

Contents
vii
10.3
Cubature Rauch–Tung–Striebel smoother
156
10.4
General ﬁxed-point smoother equations
159
10.5
General ﬁxed-lag smoother equations
162
10.6
Exercises
164
11
Particle smoothing
165
11.1
SIR particle smoother
165
11.2
Backward-simulation particle smoother
167
11.3
Reweighting particle smoother
169
11.4
Rao–Blackwellized particle smoothers
171
11.5
Exercises
173
12
Parameter estimation
174
12.1
Bayesian estimation of parameters in state space models
174
12.2
Computational methods for parameter estimation
177
12.3
Practical parameter estimation in state space models
185
12.4
Exercises
202
13
Epilogue
204
13.1
Which method should I choose?
204
13.2
Further topics
206
Appendix
Additional material
209
A.1
Properties of Gaussian distribution
209
A.2
Cholesky factorization and its derivative
210
A.3
Parameter derivatives for the Kalman ﬁlter
212
A.4
Parameter derivatives for the Gaussian ﬁlter
214
References
219
Index
229


Preface
The aim of this book is to give a concise introduction to non-linear Kalman
ﬁltering and smoothing, particle ﬁltering and smoothing, and to the re-
lated parameter estimation methods. Although the book is intended to be
an introduction, the mathematical ideas behind all the methods are care-
fully explained, and a mathematically inclined reader can get quite a deep
understanding of the methods by reading the book. The book is purposely
kept short for quick reading.
The book is mainly intended for advanced undergraduate and graduate
students in applied mathematics and computer science. However, the book
is suitable also for researchers and practitioners (engineers) who need a
concise introduction to the topic on a level that enables them to implement
or use the methods. The assumed background is linear algebra, vector cal-
culus, Bayesian inference, and MATLAB
R
 programming skills.
As implied by the title, the mathematical treatment of the models and
algorithms in this book is Bayesian, which means that all the results are
treated as being approximations to certain probability distributions or their
parameters. Probability distributions are used both to represent uncertain-
ties in the models and for modeling the physical randomness. The theo-
ries of non-linear ﬁltering, smoothing, and parameter estimation are for-
mulated in terms of Bayesian inference, and both the classical and recent
algorithms are derived using the same Bayesian notation and formalism.
This Bayesian approach to the topic is far from new. It was pioneered by
Stratonovich in the 1950s and 1960s – even before Kalman’s seminal arti-
cle in 1960. Thus the theory of non-linear ﬁltering has been Bayesian from
the beginning (see Jazwinski, 1970).
Chapter 1 is a general introduction to the idea and applications of
Bayesian ﬁltering and smoothing. The purpose of Chapter 2 is to brieﬂy
review the basic concepts of Bayesian inference as well as the basic
numerical methods used in Bayesian computations. Chapter 3 starts with
a step-by-step introduction to recursive Bayesian estimation via solving a
ix

x
Preface
linear regression problem in a recursive manner. The transition to Bayesian
ﬁltering and smoothing theory is explained by extending and generalizing
the problem. The ﬁrst Kalman ﬁlter of the book is also encountered in this
chapter.
The Bayesian ﬁltering theory starts in Chapter 4 where we derive the
general Bayesian ﬁltering equations and, as their special case, the cele-
brated Kalman ﬁlter. Non-linear extensions of the Kalman ﬁlter, the ex-
tended Kalman ﬁlter (EKF), the statistically linearized ﬁlter (SLF), and the
unscented Kalman ﬁlter (UKF) are presented in Chapter 5. Chapter 6 gen-
eralizes these ﬁlters into the framework of Gaussian ﬁltering. The Gauss–
Hermite Kalman ﬁlter (GHKF) and cubature Kalman ﬁlter (CKF) are then
derived from the general framework. Sequential Monte Carlo (SMC) based
particle ﬁlters (PF) are explained in Chapter 7 by starting from the basic
SIR ﬁlter and ending with Rao–Blackwellized particle ﬁlters (RBPF).
Chapter 8 starts with a derivation of the general (ﬁxed-interval)
Bayesian smoothing equations and then continues to a derivation of
the Rauch–Tung–Striebel (RTS) smoother as their special case. In that
chapter we also brieﬂy discuss two-ﬁlter smoothing. The extended RTS
smoother (ERTSS), statistically linearized RTS smoother (SLRTSS),
and the unscented RTS smoother (URTSS) are presented in Chapter 9.
The general Gaussian smoothing framework is presented in Chapter 10,
and the Gauss–Hermite RTS smoother (GHRTSS) and the cubature RTS
smoother (CRTSS) are derived as its special cases. We also discuss
Gaussian ﬁxed-point and ﬁxed-lag smoothing in the same chapter. In
Chapter 11 we start by showing how the basic SIR particle ﬁlter can be
used to approximate the smoothing solutions with a small modiﬁcation.
We then introduce the numerically better backward-simulation particle
smoother and the reweighting (or marginal) particle smoother. Finally, we
discuss the implementation of Rao–Blackwellized particle smoothers.
Chapter 12 is an introduction to parameter estimation in state space
models concentrating on optimization and expectation–maximization
(EM) based computation of maximum likelihood (ML) and maximum
a posteriori (MAP) estimates, as well as to Markov chain Monte Carlo
(MCMC) methods. We start by presenting the general methods and then
show how Kalman ﬁlters and RTS smoothers, non-linear Gaussian ﬁlters
and RTS smoothers, and ﬁnally particle ﬁlters and smoothers, can be
used to compute or approximate the quantities needed in implementation
of parameter estimation methods. This leads to, for example, classical
EM algorithms for state space models, as well as to particle EM and

Preface
xi
particle MCMC methods. We also discuss how Rao–Blackwellization can
sometimes be used to help parameter estimation.
Chapter 13 is an epilogue where we give some general advice on the
selection of different methods for different purposes. We also discuss and
give references to various technical points and related topics that are im-
portant, but did not ﬁt into this book.
Each of the chapters ends with a range of exercises, which give the
reader hands-on experience in implementing the methods and in selecting
the appropriate method for a given purpose. The MATLAB
R
 source code
needed in the exercises as well as various other material can be found on
the book’s web page at www.cambridge.org/sarkka.
This book is an outgrowth of lecture notes of courses that I gave during
the years 2009–2012 at Helsinki University of Technology, Aalto Univer-
sity, and Tampere University of Technology, Finland. Most of the text was
written while I was working at the Department of Biomedical Engineering
and Computational Science (BECS) of Aalto University (formerly Helsinki
University of Technology), but some of the text was written during my visit
to the Department of Engineering at the University of Cambridge, UK. I
am grateful to the former Centre of Excellence in Computational Complex
Systems Research of the Academy of Finland, BECS, and Aalto University
School of Science for providing me with the research funding which made
this book possible.
I would like to thank Jouko Lampinen and Aki Vehtari from BECS for
giving me the opportunity to do the research and for co-operation which led
to this book. Arno Solin, Robert Pich´e, Juha Sarmavuori, Thomas Sch¨on,
Pete Bunch, and Isambi S. Mbalawata deserve thanks for careful checking
of the book and for giving a lot of useful suggestions for improving the text.
I am also grateful to Jouni Hartikainen, Ville V¨a¨an¨anen, Heikki Haario,
and Simon Godsill for research co-operation that led to improvement of
my understanding of the topic as well as to the development of some of the
methods which now are explained in this book. I would also like to thank
Diana Gillooly from Cambridge University Press and series editor Susan
Holmes for suggesting the publication of my lecture notes in book form.
Finally, I am grateful to my wife Susanne for her support and patience
during the writing of this book.
Simo S¨arkk¨a
Vantaa, Finland


Symbols and abbreviations
General notation
a; b; c; x; t; ˛; ˇ
Scalars
a; f; s; x; y; ˛; ˇ
Vectors
A; F; S; X; Y
Matrices
A; F; S; X ; Y
Sets
A; F; S; X; Y
Spaces
Notational conventions
AT
Transpose of matrix
A1
Inverse of matrix
AT
Inverse of transpose of matrix
ŒAi
ith column of matrix A
ŒAij
Element at ith row and jth column of matrix A
jaj
Absolute value of scalar a
jAj
Determinant of matrix A
dx=dt
Time derivative of x.t/
@gi.x/
@xj
Partial derivative of gi with respect to xj
.a1; : : : ; an/
Column vector with elements a1; : : : ; an
.a1    an/
Row vector with elements a1; : : : ; an
.a1    an/T
Column vector with elements a1; : : : ; an
@g.x/
@x
Gradient (column vector) of scalar function g
@g.x/
@x
Jacobian matrix of vector valued function x ! g.x/
CovŒx
Covariance CovŒx D EŒ.x  EŒx/ .x  EŒx/T of
the random variable x
diag.a1; : : : ; an/
Diagonal matrix with diagonal values a1; : : : ; an
p
P
Matrix such that P D
p
P
p
P
T
EŒx
Expectation of x
EŒx j y
Conditional expectation of x given y
xiii

xiv
Symbols and abbreviations
R
f .x/ dx
Lebesgue integral of f .x/ over the space Rn
p.x/
Probability density of continuous random variable x or
probability of discrete random variable x
p.x j y/
Conditional probability density or conditional probabil-
ity of x given y
p.x/ / q.x/
p.x/ is proportional to q.x/, that is, there exists a con-
stant c such that p.x/ D c q.x/ for all values of x
tr A
Trace of matrix A
VarŒx
Variance VarŒx D EŒ.x  EŒx/2 of the scalar random
variable x
x  y
x is much greater than y
xi;k
ith component of vector xk
x  p.x/
Random variable x has the probability density or prob-
ability distribution p.x/
x , y
x is deﬁned to be equal to y
x  y
x is approximately equal to y
x ' y
x is assumed to be approximately equal to y
x0Wk
Set or sequence containing the vectors fx0; : : : ; xkg
Px
Time derivative of x.t/
Symbols
˛
Parameter of the unscented transform or pendulum angle
˛i
Acceptance probability in an MCMC method
N˛
Target acceptance rate in an adaptive MCMC
ˇ
Parameter of the unscented transform
ı./
Dirac delta function
ıx
Difference of x from the mean ıx D x  m
t
Sampling period
tk
Length of the time interval tk D tkC1  tk
"k
Measurement error at the time step k
"k
Vector of measurement errors at the time step k

Vector of parameters
k
Vector of parameters at the time step k
.n/
Vector of parameters at iteration n of the EM-algorithm
.i/
Vector of parameters at iteration i of the MCMC-algorithm

Candidate point in the MCMC-algorithm
OMAP
Maximum a posteriori (MAP) estimate of parameter 

Parameter of the unscented transform

Symbols and abbreviations
xv

Parameter of the unscented transform
0
Parameter of the unscented transform
00
Parameter of the unscented transform
k
Predicted mean of measurement yk in a Kalman/Gaussian
ﬁlter at the time step k
L
Mean in the linear approximation of a non-linear transform
M
Mean in the Gaussian moment matching approximation
Q
Mean in the quadratic approximation
S
Mean in the statistical linearization approximation
U
Mean in the unscented approximation
./
Importance distribution
 2
Variance
 2
i
Variance of noise component i
†
Auxiliary matrix needed in the EM-algorithm
†i
Proposal distribution covariance in the Metropolis algorithm
'k./
Energy function at the time step k
ˆ./
A function returning the lower triangular part of its argument
ˆ
An auxiliary matrix needed in the EM-algorithm

Unit Gaussian random variable
.i/
ith scalar unit sigma point

Vector of unit Gaussian random variables
.i/
ith unit sigma point vector
.i1;:::;in/
Unit sigma point in the multivariate Gauss–Hermite cubature
a
Action in decision theory, or a part of a mean vector
ao
Optimal action
a.t/
Acceleration
A
Dynamic model matrix in a linear time-invariant model, the
lower triangular Cholesky factor of a covariance matrix, the
upper left block of a covariance matrix, a coefﬁcient in sta-
tistical linearization, or an arbitrary matrix
Ak
Dynamic model matrix (i.e., transition matrix) of the jump
from step k to step k C 1
b
The lower part of a mean vector, the offset term in statistical
linearization, or an arbitrary vector
B
Lower right block of a covariance matrix, an auxiliary matrix
needed in the EM-algorithm, or an arbitrary matrix
Bj jk
Gain matrix in a ﬁxed-point or ﬁxed-lag Gaussian smoother
c
Scalar constant
C./
Cost or loss function

xvi
Symbols and abbreviations
C
The upper right block of a covariance matrix, an auxiliary ma-
trix needed in the EM-algorithm, or an arbitrary matrix
Ck
Cross-covariance matrix in a non-linear Kalman ﬁlter
CL
Cross-covariance in the linear approximation of a non-linear
transform
CM
Cross-covariance in the Gaussian moment matching approxi-
mation of a non-linear transform
CQ
Cross-covariance in the quadratic approximation
CS
Cross-covariance in the statistical linearization approximation
CU
Cross-covariance in the unscented approximation
d
Positive integer, usually dimensionality of the parameters
di
Order of a monomial
dt
Differential of time variable t
dx
Differential of vector x
D
Derivative of the Cholesky factor, an auxiliary matrix needed
in the EM-algorithm, or an arbitrary matrix
Dk
Cross-covariance matrix in a non-linear RTS smoother or an
auxiliary matrix used in derivations
ei
Unit vector in the direction of the coordinate axis i
f./
Dynamic transition function in a state space model
Fx./
Jacobian matrix of the function x ! f.x/
F
Feedback matrix of a continuous-time linear state space model
F .i/
xx./
Hessian matrix of x ! fi.x/
F Œ
An auxiliary functional needed in the derivation of the EM-
algorithm
g
Gravitation acceleration
g./
An arbitrary function
gi./
An arbitrary function
g./
An arbitrary function
g1./
Inverse function of g./
Qg./
Augmented function with elements .x; g.//
Gk
Gain matrix in an RTS smoother
Gx./
Jacobian matrix of the function x ! g.x/
G.i/
xx./
Hessian matrix of x ! gi.x/
Hp./
pth order Hermite polynomial
H
Measurement model matrix in a linear Gaussian model, or a
Hessian matrix
Hk
Measurement model matrix at the time step k in a linear Gaus-
sian model

Symbols and abbreviations
xvii
Hx./
Jacobian matrix of the function x ! h.x/
H.i/
xx./
Hessian matrix of x ! hi.x/
h./
Measurement model function in a state space model
i
Integer valued index variable
I
Identity matrix
Ii.; .n//
An integral term needed in the EM-algorithm
J./
Jacobian matrix
k
Time step number
Kk
Gain matrix of a Kalman/Gaussian ﬁlter
L
Noise coefﬁcient (i.e., dispersion) matrix of a continuous-
time linear state space model
L./
Likelihood function
m
Dimensionality of a measurement, mean of the univariate
Gaussian distribution, or the mass
m
Mean of a Gaussian distribution
Qm
Mean of an augmented random variable
mk
Mean of a Kalman/Gaussian ﬁlter at the time step k
m.i/
k
Mean of the Kalman ﬁlter in the particle i of RBPF at the
time step k
m.i/
0WT
History of means of the Kalman ﬁlter in the particle i of
RBPF
Qmk
Augmented mean at the time step k or an auxiliary vari-
able used in derivations
m
k
Predicted mean of a Kalman/Gaussian ﬁlter at the time
step k just before the measurement yk
m.i/
k
Predicted mean of the Kalman ﬁlter in the particle i of
RBPF at the time step k
Qm
k
Augmented predicted mean at the time step k
ms
k
Mean computed by a Gaussian ﬁxed-interval (RTS)
smoother for the time step k
ms;.i/
0WT
History of means of the RTS smoother in the particle i of
RBPS
mkjn
Conditional mean of xk given y1Wn
n
Positive integer, usually the dimensionality of the state
n0
Augmented state dimensionality in a non-linear transform
n00
Augmented state dimensionality in a non-linear transform
N
Positive integer, usually the number of Monte Carlo sam-
ples
N./
Gaussian distribution (i.e., normal distribution)

xviii
Symbols and abbreviations
p
Order of a Hermite polynomial
P
Variance of the univariate Gaussian distribution
P
Covariance of the Gaussian distribution
QP
Covariance of an augmented random variable
Pk
Covariance of a Kalman/Gaussian ﬁlter at the time step k
P .i/
k
Covariance of the Kalman ﬁlter in the particle i of RBPF
at the time step k
P .i/
0WT
History of covariances of the Kalman ﬁlter in the particle
i of RBPF
QPk
Augmented covariance at the time step k or an auxiliary
variable used in derivations
P 
k
Predicted covariance of a Kalman/Gaussian ﬁlter at the
time step k just before the measurement yk
QP 
k
Augmented predicted covariance at the time step k
P .i/
k
Predicted covariance of the Kalman ﬁlter in the particle i
of RBPF at the time step k
P s
k
Covariance computed by a Gaussian ﬁxed-interval (RTS)
smoother for the time step k
P s;.i/
0WT
History of covariances of the RTS smoother in the particle
i of RBPS
Pkjn
Conditional covariance of xk given y1Wn
qc
Spectral density of a white noise process
qc
i
Spectral density of component i of a white noise process
q./
Proposal distribution in the MCMC algorithm, or an arbi-
trary distribution in the derivation of the EM-algorithm
q.n/
Distribution approximation on the nth step of the EM-
algorithm
q
Gaussian random vector
qk
Gaussian process noise
Q
Variance of scalar process noise
Q.; .n//
An auxiliary function needed in the EM-algorithm
Q
Covariance of the process noise in a time-invariant model
Qk
Covariance of the process noise at the jump from step k to
k C 1
rk
Scalar Gaussian measurement noise
rk
Vector of Gaussian measurement noises
R
Variance of scalar measurement noise
R
Covariance matrix of the measurement in a time-invariant
model

Symbols and abbreviations
xix
Rk
Covariance matrix of the measurement at the time step k
R
Space of real numbers
Rn
n-dimensional space of real numbers
Rnm
Space of real n  m matrices
S
Number of backward-simulation draws
Sk
Innovation covariance of a Kalman/Gaussian ﬁlter at step k
SL
Covariance in the linear approximation of a non-linear trans-
form
SM
Covariance in the Gaussian moment matching approximation
of a non-linear transform
SQ
Covariance in the quadratic approximation of a non-linear
transform
SS
Covariance in the statistical linearization approximation of a
non-linear transform
SU
Covariance in the unscented approximation of a non-linear
transform
t
Time variable t 2 Œ0; 1/
tk
Time of the step k (usually time of the measurement yk)
T
Index of the last time step, the ﬁnal time of a time interval
Tk
Sufﬁcient statistics
u
Uniform random variable
uk
Latent (non-linear) variable in a Rao–Blackwellized particle
ﬁlter or smoother
u.i/
k
Latent variable value in particle i
u.i/
0Wk
History of latent variable values in particle i
U./
Utility function
U./
Uniform distribution
v.i/
k
Unnormalized weight in an SIR particle ﬁlter based likelihood
evaluation
vk
Innovation vector of a Kalman/Gaussian ﬁlter at step k
w.i/
Normalized weight of the particle i in importance sampling
Qw.i/
Weight of the particle i in importance sampling
w.i/
Unnormalized weight of the particle i in importance sampling
w.i/
k
Normalized weight of the particle i on step k of a particle ﬁlter
w.i/
kjn
Normalized weight of a particle smoother
wi
Weight i in a regression model
wk
Vector of weights at the time step k in a regression model
w.t/
Gaussian white noise process
W
Weight in the cubature or unscented approximation

xx
Symbols and abbreviations
Wi
ith weight in sigma-point approximation or in Gauss–
Hermite quadrature
W .m/
i
Mean weight of the unscented transform
W .m/0
i
Mean weight of the unscented transform
W .c/
i
Covariance weight of the unscented transform
W .c/0
i
Covariance weight of the unscented transform
Wi1;:::;in
Weight in multivariate Gauss–Hermite cubature
x
Scalar random variable or state, sometimes regressor vari-
able, or a generic scalar variable
x
Random variable or state
x.i/
ith Monte Carlo draw from the distribution of x
xk
State at the time step k
Qxk
Augmented state at the time step k
x0Wk
Set containing the state vectors fx0; : : : ; xkg
x.i/
0Wk
The history of the states in the particle i
Qx.j /
0WT
State trajectory simulated by a backward-simulation particle
smoother
X
Matrix of regressors
Xk
Matrix of regressors up to the time step k
X ./
Sigma point of x
QX ./
Augmented sigma point of x
X ./
k
Sigma point of the state xk
QX ./
k
Augmented sigma point of the state xk
OX ./
k
Predicted sigma point of the state xk
X ./
k
Sigma point of the predicted state xk
QX ./
k
Augmented sigma point of the predicted state xk
y
Random variable or measurement
yk
Measurement at the time step k
y1Wk
Set containing the measurement vectors fy1; : : : ; ykg
Y./
Sigma point of y
QY./
Augmented sigma point of y
OY./
k
ith predicted sigma point of the measurement yk at step k
Z
Normalization constant
Zk
Normalization constant at the time step k
1
Inﬁnity

Symbols and abbreviations
xxi
Abbreviations
ADF
Assumed density ﬁlter
AM
Adaptive Metropolis (algorithm)
AMCMC
Adaptive Markov chain Monte Carlo
AR
Autoregressive (model)
ARMA
Autoregressive moving average (model)
ASIR
Auxiliary sequential importance resampling
BS-PS
Backward-simulation particle smoother
CDKF
Central differences Kalman ﬁlter
CKF
Cubature Kalman ﬁlter
CLT
Central limit theorem
CPF
Cubature particle ﬁlter
CRLB
Cram´er–Rao lower bound
DLM
Dynamic linear model
DOT
Diffuse optical tomography
DSP
Digital signal processing
EC
Expectation correction
EEG
Electroencephalography
EKF
Extended Kalman ﬁlter
EM
Expectation–maximization
EP
Expectation propagation
ERTSS
Extended Rauch–Tung–Striebel smoother
FHKF
Fourier–Hermite Kalman ﬁlter
FHRTSS
Fourier–Hermite Rauch–Tung–Striebel smoother
fMRI
Functional magnetic resonance imaging
GHKF
Gauss–Hermite Kalman ﬁlter
GHPF
Gauss–Hermite particle ﬁlter
GHRTSS
Gauss–Hermite Rauch–Tung–Striebel smoother
GPB
Generalized pseudo-Bayesian
GPS
Global positioning system
HMC
Hamiltonian (or hybrid) Monte Carlo
HMM
Hidden Markov model
IMM
Interacting multiple model (algorithm)
INS
Inertial navigation system
IS
Importance sampling
InI
Inverse imaging
KF
Kalman ﬁlter
LMS
Least mean squares
LQG
Linear quadratic Gaussian (regulator)

xxii
Symbols and abbreviations
LS
Least squares
MA
Moving average (model)
MAP
Maximum a posteriori
MC
Monte Carlo
MCMC
Markov chain Monte Carlo
MEG
Magnetoencephalography
MH
Metropolis–Hastings
MKF
Mixture Kalman ﬁlter
ML
Maximum likelihood
MLP
Multi-layer perceptron
MMSE
Minimum mean squared error
MNE
Minimum norm estimate
MSE
Mean squared error
PF
Particle ﬁlter
PMCMC
Particle Markov chain Monte Carlo
PMMH
Particle marginal Metropolis–Hastings
PS
Particle smoother
QKF
Quadrature Kalman ﬁlter
RAM
Robust adaptive Metropolis (algorithm)
RBPF
Rao–Blackwellized particle ﬁlter
RBPS
Rao–Blackwellized particle smoother
RMSE
Root mean squared error
RTS
Rauch–Tung–Striebel
RTSS
Rauch–Tung–Striebel smoother
SDE
Stochastic differential equation
SIR
Sequential importance resampling
SIR-PS
Sequential importance resampling particle smoother
SIS
Sequential importance sampling
SLDS
Switching linear dynamic system
SLF
Statistically linearized ﬁlter
SLRTSS
Statistically linearized Rauch–Tung–Striebel smoother
SMC
Sequential Monte Carlo
TVAR
Time-varying autoregressive (model)
UKF
Unscented Kalman ﬁlter
UPF
Unscented particle ﬁlter
URTSS
Unscented Rauch–Tung–Striebel smoother
UT
Unscented transform

1
What are Bayesian ﬁltering and smoothing?
The term optimal ﬁltering traditionally refers to a class of methods that
can be used for estimating the state of a time-varying system which is indi-
rectly observed through noisy measurements. The term optimal in this con-
text refers to statistical optimality. Bayesian ﬁltering refers to the Bayesian
way of formulating optimal ﬁltering. In this book we use these terms inter-
changeably and always mean Bayesian ﬁltering.
In optimal, Bayesian, and Bayesian optimal ﬁltering the state of the sys-
tem refers to the collection of dynamic variables such as position, veloc-
ity, orientation, and angular velocity, which fully describe the system. The
noise in the measurements means that they are uncertain; even if we knew
the true system state the measurements would not be deterministic func-
tions of the state, but would have a distribution of possible values. The time
evolution of the state is modeled as a dynamic system which is perturbed
by a certain process noise. This noise is used for modeling the uncertainties
in the system dynamics. In most cases the system is not truly stochastic, but
stochasticity is used for representing the model uncertainties.
Bayesian smoothing (or optimal smoothing) is often considered to be
a class of methods within the ﬁeld of Bayesian ﬁltering. While Bayesian
ﬁlters in their basic form only compute estimates of the current state of
the system given the history of measurements, Bayesian smoothers can be
used to reconstruct states that happened before the current time. Although
the term smoothing is sometimes used in a more general sense for methods
which generate a smooth (as opposed to rough) representation of data, in
the context of Bayesian ﬁltering the term (Bayesian) smoothing has this
more deﬁnite meaning.
1.1 Applications of Bayesian ﬁltering and smoothing
Phenomena which can be modeled as time-varying systems of the above
type are very common in engineering applications. This kind of model
1

2
What are Bayesian ﬁltering and smoothing?
can be found, for example, in navigation, aerospace engineering, space en-
gineering, remote surveillance, telecommunications, physics, audio signal
processing, control engineering, ﬁnance, and many other ﬁelds. Examples
of such applications are the following.
 Global positioning system (GPS) (Kaplan, 1996) is a widely used satel-
lite navigation system, where the GPS receiver unit measures arrival
times of signals from several GPS satellites and computes its position
based on these measurements (see Figure 1.1). The GPS receiver typi-
cally uses an extended Kalman ﬁlter (EKF) or some other optimal ﬁlter-
ing algorithm1 for computing the current position and velocity such that
the measurements and the assumed dynamics (laws of physics) are taken
into account. Also the ephemeris information, which is the satellite ref-
erence information transmitted from the satellites to the GPS receivers,
is typically generated using optimal ﬁlters.
Figure 1.1 In the GPS system, the measurements are time delays
of satellite signals and the optimal ﬁlter (e.g., extended Kalman
ﬁlter, EKF) computes the position and the accurate time.
 Target tracking (Bar-Shalom et al., 2001; Crassidis and Junkins, 2004;
Challa et al., 2011) refers to the methodology where a set of sensors
such as active or passive radars, radio frequency sensors, acoustic arrays,
1 Strictly speaking, the EKF is only an approximate optimal ﬁltering algorithm, because it
uses a Taylor series based Gaussian approximation to the non-Gaussian optimal ﬁltering
solution.

1.1 Applications of Bayesian ﬁltering and smoothing
3
infrared sensors, and other types of sensors are used for determining
the position and velocity of a remote target (see Figure 1.2). When this
tracking is done continuously in time, the dynamics of the target and
measurements from the different sensors are most naturally combined
using an optimal ﬁlter or smoother. The target in this (single) target
tracking case can be, for example, a robot, a satellite, a car or an airplane.
Figure 1.2 In target tracking, a sensor (e.g., radar) generates
measurements (e.g., angle and distance measurements) of the
target, and the purpose is to determine the target trajectory.
 Multiple target tracking (Bar-Shalom and Li, 1995; Blackman and
Popoli, 1999; Stone et al., 1999; S¨arkk¨a et al., 2007b) systems are used
for remote surveillance in the cases where there are multiple targets
moving at the same time in the same geographical area (see Figure 1.3).
This introduces the concept of data association (which measurement
was from which target?) and the problem of estimating the number of
targets. Multiple target tracking systems are typically used in remote
surveillance for military purposes, but their civil applications are, for
example, monitoring of car tunnels, automatic alarm systems, and
people tracking in buildings.
 Inertial navigation (Titterton and Weston, 1997; Grewal et al., 2001)
uses inertial sensors such as accelerometers and gyroscopes for comput-
ing the position and velocity of a device such as a car, an airplane, or
a missile. When the inaccuracies in sensor measurements are taken into
account the natural way of computing the estimates is by using an op-

4
What are Bayesian ﬁltering and smoothing?
Figure 1.3 In multiple target tracking the data association
problem has to be solved, because it is impossible to know
without any additional information which target produced which
measurement.
timal ﬁlter or smoother. Also, in sensor calibration, which is typically
done in a time-varying environment, optimal ﬁlters and smoothers can
be applied.
 Integrated inertial navigation (Grewal et al., 2001; Bar-Shalom et al.,
2001) combines the good sides of unbiased but inaccurate sensors, such
as altimeters and landmark trackers, and biased but locally accurate in-
ertial sensors. A combination of these different sources of information
is most naturally performed using an optimal ﬁlter such as the extended
Kalman ﬁlter. This kind of approach was used, for example, in the guid-
ance system of the Apollo 11 lunar module (Eagle), which landed on the
moon in 1969.
 GPS/INS navigation (Grewal et al., 2001; Bar-Shalom et al., 2001) is a
form of integrated inertial navigation where the inertial navigation sys-
tem (INS) is combined with a GPS receiver unit. In a GPS/INS naviga-
tion system the short term ﬂuctuations of the GPS can be compensated
by the inertial sensors and the inertial sensor biases can be compensated
by the GPS receiver. An additional advantage of this approach is that
it is possible to temporarily switch to pure inertial navigation when the
GPS receiver is unable to compute its position (i.e., has no ﬁx) for some
reason. This happens, for example, indoors, in tunnels and in other cases

1.1 Applications of Bayesian ﬁltering and smoothing
5
when there is no direct line-of-sight between the GPS receiver and the
satellites.
 Brain imaging methods such as electroencephalography (EEG), mag-
netoencephalography (MEG), parallel functional magnetic resonance
imaging (fMRI) and diffuse optical tomography (DOT) (see Figure 1.4)
are based on reconstruction of the source ﬁeld in the brain from noisy
sensor data by using minimum norm estimates (MNE) and its variants
(Hauk, 2004; Tarantola, 2004; Kaipio and Somersalo, 2005; Lin et al.,
2006). The minimum norm solution can also be interpreted in the
Bayesian sense as a problem of estimating the ﬁeld with certain prior
structure from Gaussian observations. With that interpretation the
estimation problem becomes equivalent to a statistical inversion or
generalized Gaussian process regression problem (Tarantola, 2004;
Kaipio and Somersalo, 2005; Rasmussen and Williams, 2006; S¨arkk¨a,
2011). Including dynamical priors then leads to a linear or non-linear
spatio-temporal estimation problem, which can be solved with Kalman
ﬁlters and smoothers (see Hiltunen et al., 2011; S¨arkk¨a et al., 2012b).
The same can be done in inversion based approaches to parallel fMRI
such as inverse imaging (InI, Lin et al., 2006).
Figure 1.4 Brain imaging methods such as EEG and MEG are
based on estimating the state of the brain from sensor readings. In
dynamic case the related inversion problem can be solved with an
optimal ﬁlter or smoother.

6
What are Bayesian ﬁltering and smoothing?
 Spread of infectious diseases (Keeling and Rohani, 2007) can often
be modeled as differential equations for the number of susceptible,
infected, and recovered/dead individuals. When uncertainties are
introduced into the dynamic equations, and when the measurements are
not perfect, the estimation of the spread of the disease can be formulated
as an optimal ﬁltering problem (see, e.g., S¨arkk¨a and Sottinen, 2008).
 Biological processes (Murray, 1993) such as population growth,
predator–prey models, and several other dynamic processes in biology
can also be modeled as (stochastic) differential equations. Estimation
of the states of these processes from inaccurate measurements can be
formulated as an optimal ﬁltering and smoothing problem.
 Telecommunications is also a ﬁeld where optimal ﬁlters are tradition-
ally used. For example, optimal receivers, signal detectors, and phase
locked loops can be interpreted to contain optimal ﬁlters (Van Trees,
1968, 1971; Proakis, 2001) as components. Also the celebrated Viterbi
algorithm (Viterbi, 1967) can be seen as a method for computing the
maximum a posteriori (MAP) Bayesian smoothing solution for the un-
derlying hidden Markov model (HMM).
 Audio signal processing applications such as audio restoration (Godsill
and Rayner, 1998) and audio signal enhancement (Fong et al., 2002)
often use TVAR (time-varying autoregressive) models as the underlying
audio signal models. These kinds of model can be efﬁciently estimated
using optimal ﬁlters and smoothers.
 Stochastic optimal control (Maybeck, 1982a; Stengel, 1994) considers
control of time-varying stochastic systems. Stochastic controllers can
typically be found in, for example, airplanes, cars, and rockets. Optimal,
in addition to the statistical optimality, means that the control signal is
constructed to minimize a performance cost, such as the expected time
to reach a predeﬁned state, the amount of fuel consumed, or the average
distance from a desired position trajectory. When the state of the system
is observed through a set of sensors, as it usually is, optimal ﬁlters are
needed for reconstructing the state from them.
 Learning systems or adaptive systems can often be mathematically for-
mulated in terms of optimal ﬁlters and smoothers (Haykin, 2001) and
they have a close relationship with Bayesian non-parametric modeling,
machine learning, and neural network modeling (Bishop, 2006). Meth-
ods similar to the data association methods in multiple target tracking are
also applicable to on-line adaptive classiﬁcation (Andrieu et al., 2002).
The connection between Gaussian process regression (Rasmussen and
Williams, 2006) and optimal ﬁltering has also been recently discussed

1.2 Origins of Bayesian ﬁltering and smoothing
7
in S¨arkk¨a et al. (2007a), Hartikainen and S¨arkk¨a (2010) and S¨arkk¨a and
Hartikainen (2012).
 Physical systems which are time-varying and measured through non-
ideal sensors can sometimes be formulated as stochastic state space
models, and the time evolution of the system can be estimated using
optimal ﬁlters (Kaipio and Somersalo, 2005). These kinds of problem
are often called inverse problems (Tarantola, 2004), and optimal ﬁlters
and smoothers can be seen as the Bayesian solutions to time-varying
inverse problems.
1.2 Origins of Bayesian ﬁltering and smoothing
The roots of Bayesian analysis of time-dependent behavior are in the ﬁeld
of optimal linear ﬁltering. The idea of constructing mathematically opti-
mal recursive estimators was ﬁrst presented for linear systems due to their
mathematical simplicity, and the most natural optimality criterion in both
the mathematical and modeling points of view was the least squares op-
timality. For linear systems the optimal Bayesian solution (with minimum
mean squared error, MMSE, loss) coincides with the least squares solution,
that is, the optimal least squares solution is exactly the posterior mean.
The history of optimal ﬁltering starts from the Wiener ﬁlter (Wiener,
1950), which is a frequency domain solution to the problem of least squares
optimal ﬁltering of stationary Gaussian signals. The Wiener ﬁlter is still
important in communication applications (Proakis, 2001), digital signal
processing (Hayes, 1996) and image processing (Gonzalez and Woods,
2008). The disadvantage of the Wiener ﬁlter is that it can only be applied
to stationary signals.
The success of optimal linear ﬁltering in engineering applications is
mostly due to the seminal article of Kalman (1960b), which describes the
recursive solution to the optimal discrete-time (sampled) linear ﬁltering
problem. One reason for the success is that the Kalman ﬁlter can be un-
derstood and applied with very much lighter mathematical machinery than
the Wiener ﬁlter. Also, despite its mathematical simplicity and generality,
the Kalman ﬁlter (or actually the Kalman–Bucy ﬁlter; Kalman and Bucy,
1961) contains the Wiener ﬁlter as its limiting special case.
In the early stages of its history, the Kalman ﬁlter was soon discovered
to belong to the class of Bayesian ﬁlters (Ho and Lee, 1964; Lee, 1964;
Jazwinski, 1966, 1970). The corresponding Bayesian smoothers (Rauch,
1963; Rauch et al., 1965; Leondes et al., 1970) were also developed soon
after the invention of the Kalman ﬁlter. An interesting historical detail is

8
What are Bayesian ﬁltering and smoothing?
hidden:
_
_
_
_
xk1


xk


xkC1
_
_
_

observed:
yk1
yk
ykC1
Figure 1.5 In optimal ﬁltering and smoothing problems a
sequence of hidden states xk is indirectly observed through noisy
measurements yk:
that while Kalman and Bucy were formulating the linear theory in the
United States, Stratonovich was doing the pioneering work on the prob-
abilistic (Bayesian) approach in Russia (Stratonovich, 1968; Jazwinski,
1970).
As discussed in the book of West and Harrison (1997), in the 1960s,
Kalman ﬁlter like recursive estimators were also used in the Bayesian com-
munity and it is not clear whether the theory of Kalman ﬁltering or the
theory of dynamic linear models (DLM) came ﬁrst. Although these theo-
ries were originally derived from slightly different starting points, they are
equivalent. Because of the Kalman ﬁlter’s useful connection to the the-
ory and history of stochastic optimal control, this book approaches the
Bayesian ﬁltering problem from the Kalman ﬁltering point of view.
Although the original derivation of the Kalman ﬁlter was based on the
least squares approach, the same equations can be derived from pure prob-
abilistic Bayesian analysis. The Bayesian analysis of Kalman ﬁltering is
well covered in the classical book of Jazwinski (1970) and more recently in
the book of Bar-Shalom et al. (2001). Kalman ﬁltering, mostly because of
its least squares interpretation, has widely been used in stochastic optimal
control. A practical reason for this is that the inventor of the Kalman ﬁlter,
Rudolph E. Kalman, has also made several contributions (Kalman, 1960a)
to the theory of linear quadratic Gaussian (LQG) regulators, which are
fundamental tools of stochastic optimal control (Stengel, 1994; Maybeck,
1982a).
1.3 Optimal ﬁltering and smoothing as Bayesian inference
In mathematical terms, optimal ﬁltering and smoothing are considered to
be statistical inversion problems, where the unknown quantity is a vec-
tor valued time series fx0; x1; x2; : : :g which is observed through a set of

1.3 Optimal ﬁltering and smoothing as Bayesian inference
9
0
5
10
15
−0.25
−0.2
−0.15
−0.1
−0.05
0
0.05
0.1
0.15
0.2
0.25
Time step k
Resonator position xk
 
 
Signal
Measurement
Figure 1.6 An example of time series, which models a
discrete-time resonator. The actual resonator state (signal) is
hidden and only observed through the noisy measurements.
noisy measurements fy1; y2; : : :g as illustrated in Figure 1.5. An example
of this kind of time series is shown in Figure 1.6. The process shown is a
noisy resonator with a known angular velocity. The state xk D .xk Pxk/T
is two dimensional and consists of the position of the resonator xk and
its time derivative Pxk. The measurements yk are scalar observations of the
resonator position (signal) and they are corrupted by measurement noise.
The purpose of the statistical inversion at hand is to estimate the hid-
den states x0WT D fx0; : : : ; xT g from the observed measurements y1WT D
fy1; : : : ; yT g, which means that in the Bayesian sense we want to compute
the joint posterior distribution of all the states given all the measurements.
In principle, this can be done by a straightforward application of Bayes’
rule
p.x0WT j y1WT / D p.y1WT j x0WT / p.x0WT /
p.y1WT /
;
(1.1)
where
 p.x0WT /; is the prior distribution deﬁned by the dynamic model,
 p.y1WT j x0WT / is the likelihood model for the measurements,

10
What are Bayesian ﬁltering and smoothing?
 p.y1WT / is the normalization constant deﬁned as
p.y1WT / D
Z
p.y1WT j x0WT / p.x0WT / dx0WT :
(1.2)
Unfortunately, this full posterior formulation has the serious disadvantage
that each time we obtain a new measurement, the full posterior distribution
would have to be recomputed. This is particularly a problem in dynamic
estimation (which is exactly the problem we are solving here!), where mea-
surements are typically obtained one at a time and we would want to com-
pute the best possible estimate after each measurement. When the number
of time steps increases, the dimensionality of the full posterior distribu-
tion also increases, which means that the computational complexity of a
single time step increases. Thus eventually the computations will become
intractable, no matter how much computational power is available. With-
out additional information or restrictive approximations, there is no way of
getting over this problem in the full posterior computation.
However, the above problem only arises when we want to compute the
full posterior distribution of the states at each time step. If we are willing to
relax this a bit and be satisﬁed with selected marginal distributions of the
states, the computations become an order of magnitude lighter. To achieve
this, we also need to restrict the class of dynamic models to probabilis-
tic Markov sequences, which is not as restrictive as it may at ﬁrst seem.
The model for the states and measurements will be assumed to be of the
following type.
 An initial distribution speciﬁes the prior probability distribution p.x0/
of the hidden state x0 at the initial time step k D 0.
 A dynamic model describes the system dynamics and its uncertainties
as a Markov sequence, deﬁned in terms of the transition probability dis-
tribution p.xk j xk1/.
 A measurement model describes how the measurement yk depends
on the current state xk. This dependence is modeled by specifying the
conditional probability distribution of the measurement given the state,
which is denoted as p.yk j xk/.
Thus a general probabilistic state space model is usually written in the
following form:
x0  p.x0/;
xk  p.xk j xk1/;
yk  p.yk j xk/:
(1.3)

1.3 Optimal ﬁltering and smoothing as Bayesian inference
11
Because computing the full joint distribution of the states at all time steps is
computationally very inefﬁcient and unnecessary in real-time applications,
in Bayesian ﬁltering and smoothing the following marginal distributions
are considered instead (see Figure 1.7).
 Filtering distributions computed by the Bayesian ﬁlter are the marginal
distributions of the current state xk given the current and previous mea-
surements y1Wk D fy1; : : : ; ykg:
p.xk j y1Wk/;
k D 1; : : : ; T:
(1.4)
The result of applying the Bayesian ﬁlter to the resonator time series in
Figure 1.6 is shown in Figure 1.8.
 Prediction distributions which can be computed with the prediction step
of the Bayesian ﬁlter are the marginal distributions of the future state
xkCn, n steps after the current time step:
p.xkCn j y1Wk/;
k D 1; : : : ; T;
n D 1; 2; : : : :
(1.5)
 Smoothing distributions computed by the Bayesian smoother are the
marginal distributions of the state xk given a certain interval y1WT D
fy1; : : : ; yT g of measurements with T > k:
p.xk j y1WT /;
k D 1; : : : ; T:
(1.6)
The result of applying the Bayesian smoother to the resonator time series
is shown in Figure 1.9.
Figure 1.7 State estimation problems can be divided into optimal
prediction, ﬁltering, and smoothing depending on the time span of
the measurements available with respect to the time of the
estimated state.

12
What are Bayesian ﬁltering and smoothing?
0
5
10
15
−0.25
−0.2
−0.15
−0.1
−0.05
0
0.05
0.1
0.15
0.2
0.25
Time step k
Resonator position xk
 
 
Signal
Measurement
Filter Estimate
95% Quantile
Figure 1.8 The result of computing the ﬁltering distributions for
the discrete-time resonator model. The estimates are the means of
the ﬁltering distributions and the quantiles are the 95% quantiles
of the ﬁltering distributions.
Computing ﬁltering, prediction, and smoothing distributions require only
a constant number of computations per time step, and thus the problem of
processing arbitrarily long time series is solved.
1.4 Algorithms for Bayesian ﬁltering and smoothing
There exist a few classes of ﬁltering and smoothing problems which have
closed form solutions.
 The Kalman ﬁlter (KF) is a closed form solution to the linear Gaussian
ﬁltering problem. Due to linear Gaussian model assumptions the poste-
rior distribution is exactly Gaussian and no numerical approximations
are needed.
 The Rauch–Tung–Striebel smoother (RTSS) is the corresponding closed
form smoother for linear Gaussian state space models.
 Grid ﬁlters and smoothers are solutions to Markov models with ﬁnite
state spaces.

1.4 Algorithms for Bayesian ﬁltering and smoothing
13
0
5
10
15
−0.25
−0.2
−0.15
−0.1
−0.05
0
0.05
0.1
0.15
0.2
0.25
Time step k
Resonator position xk
 
 
Signal
Measurement
Smoother Estimate
95% Quantile
Figure 1.9 The result of computing the smoothing distributions
for the discrete-time resonator model. The estimates are the
means of the smoothing distributions and the quantiles are the
95% quantiles of the smoothing distributions.
But because the Bayesian optimal ﬁltering and smoothing equations are
generally computationally intractable, many kinds of numerical approxi-
mation methods have been developed, for example:
 The extended Kalman ﬁlter (EKF) approximates the non-linear and non-
Gaussian measurement and dynamic models by linearization, that is,
by forming a Taylor series expansion at the nominal (or maximum a
posteriori, MAP) solution. This results in a Gaussian approximation to
the ﬁltering distribution.
 The extended Rauch–Tung–Striebel smoother (ERTSS) is the approxi-
mate non-linear smoothing algorithm corresponding to EKF.
 The unscented Kalman ﬁlter (UKF) approximates the propagation
of densities through the non-linearities of measurement and noise
processes using the unscented transform. This also results in a Gaussian
approximation.
 The unscented Rauch–Tung–Striebel smoother (URTSS) is the approxi-
mate non-linear smoothing algorithm corresponding to UKF.
 Sequential Monte Carlo methods or particle ﬁlters and smoothers repre-
sent the posterior distribution as a weighted set of Monte Carlo samples.

14
What are Bayesian ﬁltering and smoothing?
 The unscented particle ﬁlter (UPF) and local linearization based particle
ﬁltering methods use UKFs and EKFs, respectively, for approximating
the optimal importance distributions in particle ﬁlters.
 Rao–Blackwellized particle ﬁlters and smoothers use closed form inte-
gration (e.g., Kalman ﬁlters and RTS smoothers) for some of the state
variables and Monte Carlo integration for others.
 Grid based approximation methods approximate the ﬁltering and
smoothing distributions as discrete distributions on a ﬁnite grid.
 Other methods also exist, for example, based on Gaussian mixtures, se-
ries expansions, describing functions, basis function expansions, expo-
nential family of distributions, variational Bayesian methods, and batch
Monte Carlo (e.g., Markov chain Monte Carlo, MCMC, methods).
1.5 Parameter estimation
In state space models of dynamic systems, there are often unknown or un-
certain parameters  which should be estimated along with the state itself.
For example, in a stochastic resonator model, the frequency of the resonator
might be unknown. Also the noise variances might be only known approx-
imately or they can be completely unknown. Although, formally, we can
always augment unknown parameters as part of the state, in practice it is
often useful to consider parameter estimation separately.
In a Bayesian setting, the proper way to estimate the parameters is by
setting a prior distribution on the parameters p./ and treating them as
additional random variables in the model. When unknown parameters are
present, the state space model in Equation (1.3) becomes
  p./;
x0  p.x0 j /;
xk  p.xk j xk1; /;
yk  p.yk j xk; /:
(1.7)
The full Bayesian solution to this problem would require the computation
of the full joint posterior distribution of states and parameters p.x0WT ;  j
y1WT /. Unfortunately, computing this joint posterior of the states and pa-
rameters is even harder than computation of the joint distribution of states
alone, and thus this task is intractable.
Fortunately, when run with ﬁxed parameters , the Bayesian ﬁlter al-
gorithm produces the sequence of distributions p.yk j y1Wk1; / for k D
1; : : : ; T as side products. Once we have these, we can form the marginal

1.6 Exercises
15
posterior distribution of parameters as follows:
p. j y1WT / / p./
TY
kD1
p.yk j y1Wk1; /;
(1.8)
where we have denoted p.y1 j y1W0; / , p.y1 j / for notational conve-
nience. When combined with the smoothing distributions, we can form all
the marginal joint distributions of states and parameters as follows:
p.xk;  j y1WT / D p.xk j y1WT ; / p. j y1WT /;
(1.9)
for k D 1; : : : ; T , where p.xk j y1WT ; / is the smoothing distribution of
the states with ﬁxed model parameters . However, we cannot compute the
full joint posterior distribution of states and parameters, which is the price
of only using a constant number of computations per time step.
Although here we use the term parameter estimation, it might some-
times be the case that we are not actually interested in the values of the pa-
rameters as such, but we just do not know the values of them. In that case
the proper Bayesian approach is to integrate out the parameters. For ex-
ample, to compute the smoothing distributions in the presence of unknown
parameters we can integrate out the parameters from the joint distribution
in Equation (1.9):
p.xk j y1WT / D
Z
p.xk;  j y1WT / d
D
Z
p.xk j y1WT ; / p. j y1WT / d:
(1.10)
Many of the Bayesian methods for parameter estimation indeed allow this
to be done (approximately). For example, by using the parameter samples
produced by a Markov chain Monte Carlo (MCMC) method, it is possible
to form a Monte Carlo approximation to the above integral.
1.6 Exercises
1.1
Find the seminal article of Kalman (1960b) from the Internet (or, e.g., from
a library) and investigate the orthogonal projections approach that is taken
in the article. How would you generalize the approach to the non-linear/non-
Gaussian case? Is it possible?
1.2
An alternative to Bayesian estimation would be to formulate the state estima-
tion problem as maximum likelihood (ML) estimation. This would amount

16
What are Bayesian ﬁltering and smoothing?
to estimating the state sequence as the ML-estimate
Ox0WT D arg max
x0WT p.y1WT j x0WT /:
(1.11)
Do you see any problem with this approach? Hint: where is the dynamic
model?
1.3
Assume that in an electronics shop the salesperson decides to give you a
chance to win a brand new GPS receiver. He lets you choose one of three
packages of which one contains the GPS receiver and two others are empty.
After you have chosen the package, the salesperson opens one of the pack-
ages that you have not chosen – and that package turns out to be empty.
He gives you a chance to switch to the other yet unopened package. Is it
advantageous for you to do that?

2
Bayesian inference
This chapter provides a brief presentation of the philosophical and math-
ematical foundations of Bayesian inference. The connections to classical
statistical inference are also brieﬂy discussed.
2.1 Philosophy of Bayesian inference
The purpose of Bayesian inference (Bernardo and Smith, 1994; Gelman
et al., 2004) is to provide a mathematical machinery that can be used for
modeling systems, where the uncertainties of the system are taken into
account and the decisions are made according to rational principles. The
tools of this machinery are the probability distributions and the rules of
probability calculus.
If we compare the so-called frequentist philosophy of statistical analysis
to Bayesian inference the difference is that in Bayesian inference the prob-
ability of an event does not mean the proportion of the event in an inﬁnite
number of trials, but the uncertainty of the event in a single trial. Because
models in Bayesian inference are formulated in terms of probability dis-
tributions, the probability axioms and computation rules of the probability
theory (see, e.g., Shiryaev, 1996) also apply in Bayesian inference.
2.2 Connection to maximum likelihood estimation
Consider a situation where we know the conditional distribution p.yk j /
of conditionally independent random variables (measurements) y1WT D
fy1; : : : ; yT g, but the parameter  2 Rd is unknown. The classical statisti-
cal method for estimating the parameter is the maximum likelihood method
(Milton and Arnold, 1995), where we maximize the joint probability of the
17

18
Bayesian inference
measurements, also called the likelihood function
L./ D
TY
kD1
p.yk j /:
(2.1)
The maximum of the likelihood function with respect to  gives the maxi-
mum likelihood estimate (ML-estimate)
O D arg max

L./:
(2.2)
The difference between the Bayesian inference and the maximum likeli-
hood method is that the starting point of Bayesian inference is to formally
consider the parameter  as a random variable. Then the posterior distribu-
tion of the parameter  can be computed by using Bayes’ rule
p. j y1WT / D p.y1WT j / p./
p.y1WT /
;
(2.3)
where p./ is the prior distribution which models the prior beliefs on the
parameter before we have seen any data, and p.y1WT / is a normalization
term which is independent of the parameter . This normalization constant
is often left out and if the measurements y1WT are conditionally independent
given , the posterior distribution of the parameter can be written as
p. j y1WT / / p./
TY
kD1
p.yk j /:
(2.4)
Because we are dealing with a distribution, we might now choose the most
probable value of the random variable, the maximum a posteriori (MAP)
estimate, which is given by the maximum of the posterior distribution.
The optimal estimate in the mean squared sense is the posterior mean of
the parameter (MMSE-estimate). There are an inﬁnite number of other
ways of choosing the point estimate from the distribution and the best way
depends on the assumed loss or cost function (or utility function). The ML-
estimate can be seen as a MAP-estimate with uniform prior p./ / 1 on
the parameter .
We can also interpret Bayesian inference as a convenient method for
including regularization terms into maximum likelihood estimation. The
basic ML-framework does not have a self-consistent method for including
regularization terms or prior information into statistical models. However,
this regularization interpretation of Bayesian inference is quite limited,
because Bayesian inference is much more than this.

2.3 The building blocks of Bayesian models
19
2.3 The building blocks of Bayesian models
The basic blocks of a Bayesian model are the prior model containing the
preliminary information on the parameter and the measurement model de-
termining the stochastic mapping from the parameter to the measurements.
Using combination rules, namely Bayes’ rule, it is possible to infer an es-
timate of the parameters from the measurements. The probability distribu-
tion of the parameters, conditional on the observed measurements, is called
the posterior distribution and it is the distribution representing the state of
knowledge about the parameters when all the information in the observed
measurements and the model is used. The predictive posterior distribution
is the distribution of new (not yet observed) measurements when all the
information in the observed measurements and the model is used.
 Prior model
The prior information consists of subjective experience based beliefs
about the possible and impossible parameter values and their relative
likelihoods before anything has been observed. The prior distribution is
a mathematical representation of this information:
p./ D information on parameter  before seeing any observations.
(2.5)
The lack of prior information can be expressed by using a non-
informative prior. The non-informative prior distribution can be selected
in various different ways (Gelman et al., 2004).
 Measurement model
Between the true parameters and the measurements there is often
a causal, but inaccurate or noisy relationship. This relationship is
mathematically modeled using the measurement model:
p.y j / D distribution of observation y given the parameters .
(2.6)
 Posterior distribution
The posterior distribution is the conditional distribution of the param-
eters given the observations. It represents the information we have af-
ter the measurement y has been obtained. It can be computed by using
Bayes’ rule
p. j y/ D p.y j / p./
p.y/
/ p.y j / p./;
(2.7)

20
Bayesian inference
where the normalization constant is given as
p.y/ D
Z
p.y j / p./ d:
(2.8)
In the case of multiple measurements y1WT , if the measurements are con-
ditionally independent, the joint likelihood of all measurements is the
product of distributions of individual measurements and the posterior
distribution is
p. j y1WT / / p./
TY
kD1
p.yk j /;
(2.9)
where the normalization term can be computed by integrating the right-
hand side over . If the random variable is discrete the integration is
replaced by summation.
 Predictive posterior distribution
The predictive posterior distribution is the distribution of new measure-
ments yT C1 given the observed measurements
p.yT C1 j y1WT / D
Z
p.yT C1 j / p. j y1WT / d:
(2.10)
Thus, after obtaining the measurements y1WT the predictive posterior dis-
tribution can be used for computing the probability distribution for mea-
surement index T C 1 which has not yet been observed.
In the case of tracking, we could imagine that the parameter is the sequence
of dynamic states of a target, where the state contains the position and ve-
locity. The measurements could be, for example, noisy distance and direc-
tion measurements produced by a radar. In this book we will divide the
parameters into two classes: the dynamic state of the system and the static
parameters of the model. But from the Bayesian estimation point of view
both the states and static parameters are unknown (random) parameters of
the system.
2.4 Bayesian point estimates
Distributions alone have no use in many practical applications; we need
ﬁnite-dimensional summaries (point estimates). This selection of a point
based on observed values of random variables is a statistical decision, and
therefore this selection procedure is most naturally formulated in terms of
statistical decision theory (Berger, 1985; Bernardo and Smith, 1994; Raiffa
and Schlaifer, 2000).

2.4 Bayesian point estimates
21
Deﬁnition 2.1 (Loss function)
A loss function or cost function C.; a/ is
a scalar valued function which determines the loss of taking the action a
when the true parameter value is . The action (or control) is the statistical
decision to be made based on the currently available information.
Instead of loss functions it is also possible to work with utility functions
U.; a/, which determine the reward from taking the action a with param-
eter values . Loss functions can be converted to utility functions and vice
versa by deﬁning U.; a/ D C.; a/.
If the value of the parameter  is not known, but the knowledge of the pa-
rameter can be expressed in terms of the posterior distribution p. j y1WT /,
then the natural choice is the action which gives the minimum (maximum)
of the expected loss (utility) (Berger, 1985)
EŒC.; a/ j y1WT  D
Z
C.; a/ p. j y1WT / d:
(2.11)
Commonly used loss functions are the following.
 Quadratic error loss. If the loss function is quadratic
C.; a/ D .  a/T.  a/;
(2.12)
then the optimal choice ao is the mean of the posterior distribution of 
ao D
Z
 p. j y1WT / d:
(2.13)
This posterior mean based estimate is often called the minimum mean
squared error (MMSE) estimate of the parameter . The quadratic loss
is the most commonly used loss function, because it is easy to handle
mathematically and because in the case of Gaussian posterior distribu-
tion the MAP estimate and the median coincide with the posterior mean.
 Absolute error loss. The loss function of the form
C.; a/ D
X
i
j	i  aij
(2.14)
is called an absolute error loss and in this case the optimal choice is the
median of the distribution (the medians of the marginal distributions in
the multi-dimensional case).
 0–1 loss. If the loss function is of the form
C.; a/ D ı.a  /;
(2.15)
where ı./ is the Dirac’s delta function, then the optimal choice is the
maximum (mode) of the posterior distribution, that is, the maximum a

22
Bayesian inference
posterior (MAP) estimate of the parameter. If the random variable  is
discrete the corresponding loss function can be deﬁned as
C.; a/ D
(
0;
if  D a;
1;
if  ¤ a:
(2.16)
2.5 Numerical methods
In principle, Bayesian inference provides the equations for computing
the posterior distributions and point estimates for any model once the
model speciﬁcation has been set up. However, the practical difﬁculty is
that computation of the integrals involved in the equations can rarely
be performed analytically and numerical methods are needed. Here we
brieﬂy describe numerical methods which are also applicable in higher-
dimensional
problems:
Gaussian
approximations,
multi-dimensional
quadratures, Monte Carlo methods, and importance sampling.
 Gaussian approximations (Gelman et al., 2004) are very common, and
in them the posterior distribution is approximated with a Gaussian dis-
tribution (see Section A.1)
p. j y1WT / ' N. j m; P/:
(2.17)
The mean m and covariance P of the Gaussian approximation can be
computed either by matching the ﬁrst two moments of the posterior dis-
tribution, or by using the mode of the distribution as the approximation
of m and by approximating P using the curvature of the posterior at the
mode. Note that above we have introduced the notation ' which here
means that the left-hand side is assumed to be approximately equal to
the right-hand side, even though we know that it will not be true in most
practical situations nor can we control the approximation error in any
practical way.
 Multi-dimensional quadrature or cubature integration methods such as
Gauss–Hermite quadrature can also be used if the dimensionality of the
integral is moderate. The idea is to deterministically form a representa-
tive set of sample points f.i/ W i D 1; : : : ; Ng (sometimes called sigma
points) and form the approximation of the integral as the weighted aver-
age
EŒg./ j y1WT  
N
X
iD1
Wi g..i//;
(2.18)

2.5 Numerical methods
23
where the numerical values of the weights Wi are determined by the
algorithm. The sample points and weights can be selected, for example,
to give exact answers for polynomials up to certain degree or to account
for the moments up to certain degree. Above we have used the notation
 to mean that the expressions are approximately equal in some suitable
limit (here N ! 1) or in some veriﬁable conditions.
 In direct Monte Carlo methods a set of N samples from the posterior
distribution is randomly drawn
.i/  p. j y1WT /;
i D 1; : : : ; N;
(2.19)
and expectation of any function g./ can be then approximated as the
sample average
EŒg./ j y1WT   1
N
X
i
g..i//:
(2.20)
Another interpretation of this is that Monte Carlo methods form an ap-
proximation of the posterior density of the form
p. j y1WT /  1
N
N
X
iD1
ı.  .i//;
(2.21)
where ı./ is the Dirac delta function. The convergence of Monte Carlo
approximation is guaranteed by the central limit theorem (CLT) (see,
e.g., Liu, 2001) and the error term is, at least in theory, under certain
ideal conditions, independent of the dimensionality of . The rule of
thumb is that the error should decrease like the square root of the number
of samples, regardless of the dimensions.
 Efﬁcient methods for generating Monte Carlo samples are the Markov
chain Monte Carlo (MCMC) methods (see, e.g., Gilks et al., 1996; Liu,
2001; Brooks et al., 2011). In MCMC methods, a Markov chain is con-
structed such that it has the target distribution as its stationary distribu-
tion. By simulating the Markov chain, samples from the target distribu-
tion can be generated.
 Importance sampling (see, e.g., Liu, 2001) is a simple algorithm for
generating weighted samples from the target distribution. The difference
between this and direct Monte Carlo sampling and MCMC is that each of
the particles has an associated weight, which corrects for the difference
between the actual target distribution and the approximate importance
distribution ./ from which the sample was drawn.

24
Bayesian inference
An importance sampling estimate can be formed by drawing N sam-
ples from the importance distribution
.i/  . j y1WT /;
i D 1; : : : ; N:
(2.22)
The importance weights are then computed as
Qw.i/ D 1
N
p..i/ j y1WT /
..i/ j y1WT /;
(2.23)
and the expectation of any function g./ can be then approximated as
EŒg./ j y1WT  
N
X
iD1
Qw.i/ g..i//;
(2.24)
or alternatively as
EŒg./ j y1WT  
PN
iD1 Qw.i/ g..i//
PN
iD1 Qw.i/
:
(2.25)
2.6 Exercises
2.1
Prove that median of distribution p.	/ minimizes the expected value of the
absolute error loss function
EŒj	  aj D
Z
j	  aj p.	/ d	:
(2.26)
2.2
Find the optimal point estimate a which minimizes the expected value of the
loss function
C.; a/ D .  a/T R .  a/;
(2.27)
where R is a positive deﬁnite matrix, and the distribution of the parameter is
  p. j y1WT /.
2.3
Assume that we have obtained T measurement pairs .xk; yk/ from the linear
regression model
yk D 	1 xk C 	2;
k D 1; 2; : : : ; T:
(2.28)
The purpose is now to derive estimates of the parameters 	1 and 	2 such that
the following error is minimized (least squares estimate):
E.	1; 	2/ D
T
X
kD1
.yk  	1 xk  	2/2:
(2.29)

Exercises
25
(a) Deﬁne y D .y1 : : : yT /T and  D .	1 	2/T. Show that the set of
Equations (2.28) can be written in matrix form as
y D X ;
with a suitably deﬁned matrix X.
(b) Write the error function in Equation (2.29) in matrix form in terms of y,
X, and .
(c) Compute the gradient of the matrix form error function and solve the
least squares estimate of the parameter  by ﬁnding the point where the
gradient is zero.
2.4
Assume that in the linear regression model above (Equation (2.28)) we set
independent Gaussian priors for the parameters 	1 and 	2 as follows:
	1  N.0; 2/;
	2  N.0; 2/;
where the variance 2 is known. The measurements yk are modeled as
yk D 	1 xk C 	2 C "k;
k D 1; 2; : : : ; T;
where the terms "k are independent Gaussian errors with mean 0 and vari-
ance 1, that is, "k  N.0; 1/. The values xk are ﬁxed and known. The poste-
rior distribution can be now written as
p. j y1; : : : ; yT /
/ exp
 
1
2
T
X
kD1
.yk  	1 xk  	2/2
!
exp

 1
22 	2
1

exp

 1
22 	2
2

:
The posterior distribution can be seen to be Gaussian and your task is to
derive its mean and covariance.
(a) Write the exponent of the posterior distribution in matrix form as in
Exercise 2.3 (in terms of y, X, , and 2).
(b) Because a Gaussian distribution is always symmetric, its mean m is at
the maximum of the distribution. Find the posterior mean by computing
the gradient of the exponent and ﬁnding where it vanishes.
(c) Find the covariance of the distribution by computing the second deriva-
tive matrix (Hessian matrix) H of the exponent. The posterior covari-
ance is then P D H1 (why?).
(d) What is the resulting posterior distribution? What is the relationship
with the least squares estimate in Exercise 2.3?

26
Bayesian inference
2.5
Implement an importance sampling based approximation for the Bayesian
linear regression problem in the above Exercise 2.4. Use a suitable Gaussian
distribution as the importance distribution for the parameters . Check that
the posterior mean and covariance (approximately) coincide with the exact
values computed in Exercise 2.4.

3
Batch and recursive Bayesian estimation
In order to understand the meaning and applicability of Bayesian ﬁltering
and its relationship to recursive estimation, it is useful to go through an
example where we solve a simple and familiar linear regression problem
in a recursive manner. After that we generalize this concept to include a
dynamic model in order to illustrate the differences in dynamic and batch
estimation.
3.1 Batch linear regression
Consider the linear regression model
yk D 	1 C 	2 tk C "k;
(3.1)
where we assume that the measurement noise is zero mean Gaussian
with a given variance "k  N.0; 2/ and the prior distribution of the
parameters  D .	1 	2/T is Gaussian with known mean and covari-
ance 
 N.m0; P0/. In the classical linear regression problem we
want to estimate the parameters  from a set of measurement data
D D f.t1; y1/; : : : ; .tT ; yT /g. The measurement data and the true linear
function used in simulation are illustrated in Figure 3.1.
In compact probabilistic notation the linear regression model can be
written as
p.yk j / D N.yk j Hk ;  2/
p./ D N. j m0; P0/;
(3.2)
where we have introduced the row vector Hk D .1 tk/ and N./ denotes
the Gaussian probability density function (see Section A.1). Note that we
denote the row vector Hk in matrix notation, because it generally is a ma-
trix (when the measurements are vector valued) and we want to avoid using
different notations for scalar and vector measurements. The likelihood of
yk is conditional on the regressors tk also (or equivalently Hk), but because
27

28
Batch and recursive Bayesian estimation
0
0.2
0.4
0.6
0.8
1
0.5
1
1.5
2
 t
 y
 
 
Measurement
True Signal
Figure 3.1 The underlying truth and the measurement data in the
simple linear regression problem.
the regressors are assumed to be known, to simplify the notation we will
not denote this dependence explicitly and from now on this dependence is
assumed to be understood from the context.
The batch solution to the linear regression problem in Equation (3.2) can
be obtained by a straightforward application of Bayes’ rule
p. j y1WT / / p./
TY
kD1
p.yk j /
D N. j m0; P0/
TY
kD1
N.yk j Hk ;  2/:
In the posterior distribution above, we assume the conditioning on tk and
Hk, but will not denote it explicitly. Thus the posterior distribution is de-
noted to be conditional on y1WT , and not on the data set D also containing
the regressor values tk. The reason for this simpliﬁcation is that the simpli-
ﬁed notation will also work in more general ﬁltering problems, where there
is no natural way of deﬁning the associated regressor variables.
Because the prior and likelihood are Gaussian, the posterior distribution
will also be Gaussian:
p. j y1WT / D N. j mT ; PT /:
(3.3)

3.2 Recursive linear regression
29
0
0.2
0.4
0.6
0.8
1
0.5
1
1.5
2
 t
 y
 
 
Measurement
True Signal
Estimate
Figure 3.2 The result of simple linear regression with a slight
regularization prior used for the regression parameters. For
simplicity, the variance was assumed to be known.
The mean and covariance can be obtained by completing the quadratic
form in the exponent, which gives:
mT D

P 1
0
C 1
 2 HT H
1  1
 2 HT y C P 1
0
m0

;
PT D

P 1
0
C 1
 2 HT H
1
;
(3.4)
where Hk D .1 tk/ and
H D
0
B@
H1
:::
HT
1
CA D
0
B@
1
t1
:::
:::
1
tT
1
CA ;
y D
0
B@
y1
:::
yT
1
CA :
(3.5)
Figure 3.2 shows the result of batch linear regression, where the posterior
mean parameter values are used as the linear regression parameters.
3.2 Recursive linear regression
A recursive solution to the regression problem (3.2) can be obtained
by assuming that we already have obtained the posterior distribution

30
Batch and recursive Bayesian estimation
conditioned on the previous measurements 1; : : : ; k  1 as follows:
p. j y1Wk1/ D N. j mk1; Pk1/:
Now assume that we have obtained a new measurement yk and we want to
compute the posterior distribution of  given the old measurements y1Wk1
and the new measurement yk. According to the model speciﬁcation the
new measurement has the likelihood
p.yk j / D N.yk j Hk ;  2/:
Using the batch version equations such that we interpret the previous pos-
terior as the prior, we can calculate the distribution
p. j y1Wk/ / p.yk j / p. j y1Wk1/
/ N. j mk; Pk/;
(3.6)
where the Gaussian distribution parameters are
mk D

P 1
k1 C 1
 2 HT
k Hk
1  1
 2 HT
k yk C P 1
k1 mk1

;
Pk D

P 1
k1 C 1
 2 HT
k Hk
1
:
(3.7)
By using the matrix inversion lemma, the covariance calculation can be
written as
Pk D Pk1  Pk1 HT
k

Hk Pk1 HT
k C  21 Hk Pk1:
By introducing temporary variables Sk and Kk the calculation of the mean
and covariance can be written in the form
Sk D Hk Pk1 HT
k C  2;
Kk D Pk1 HT
k S1
k ;
mk D mk1 C Kk Œyk  Hk mk1;
Pk D Pk1  Kk Sk KT
k:
(3.8)
Note that Sk D Hk Pk1 HT
k C  2 is scalar because the measurements are
scalar and thus no matrix inversion is required.
The equations above actually are special cases of the Kalman ﬁlter up-
date equations. Only the update part of the equations (as opposed to the
prediction and update) is required, because the estimated parameters are as-
sumed to be constant, that is, there is no stochastic dynamics model for the
parameters . Figures 3.3 and 3.4 illustrate the convergence of the means
and variances of the parameters during the recursive estimation.

3.3 Batch versus recursive estimation
31
0
0.2
0.4
0.6
0.8
1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
 t
 y
 
 
Recursive E[ θ1 ]
Batch E[ θ1 ]
Recursive E[ θ2 ]
Batch E[ θ2 ]
Figure 3.3 Convergence of the recursive linear regression
parameters means. The ﬁnal value is exactly the same as that
obtained with batch linear regression.
3.3 Batch versus recursive estimation
In this section we generalize the recursion idea used in the previous section
to general probabilistic models. The underlying idea is simply that at each
measurement we treat the posterior distribution of the previous time step
as the prior for the current time step. This way we can compute the same
solution in a recursive manner that we would obtain by direct application
of Bayes’ rule to the whole (batch) data set.
The batch Bayesian solution to a statistical estimation problem can be
formulated as follows.
1 Specify the likelihood model of measurements p.yk j / given the pa-
rameter . Typically the measurements yk are assumed to be condition-
ally independent such that
p.y1WT j / D
TY
kD1
p.yk j /:
2 The prior information about the parameter  is encoded into the prior
distribution p./.
3 The observed data set is D D f.t1; y1/; : : : ; .tT ; yT /g, or if we drop the
explicit conditioning on tk, the data is D D y1WT .

32
Batch and recursive Bayesian estimation
0
0.2
0.4
0.6
0.8
1
10
−4
10
−3
10
−2
10
−1
10
0
 t
 y
 
 
Recursive Var[ θ1 ]
Batch Var[ θ1 ]
Recursive Var[ θ2 ]
Batch Var[ θ2 ]
Figure 3.4 Convergence of the variances of linear regression
parameters plotted on logarithmic scale. As can be seen, every
measurement brings more information and the uncertainty
decreases monotonically. The ﬁnal values are the same as the
variances obtained from the batch solution.
4 The batch Bayesian solution to the statistical estimation problem can be
computed by applying Bayes’ rule:
p. j y1WT / D 1
Z p./
TY
kD1
p.yk j /;
where Z is the normalization constant
Z D
Z
p./
TY
kD1
p.yk j / d:
For example, the batch solution of the above kind to the linear regression
problem (3.2) was given by Equations (3.3) and (3.4).
The recursive Bayesian solution to the above statistical estimation prob-
lem can be formulated as follows.
1 The distribution of measurements is again modeled by the likelihood
function p.yk j / and the measurements are assumed to be condition-
ally independent.
2 In the beginning of estimation (i.e., at step 0), all the information about
the parameter  we have is contained in the prior distribution p./.

3.4 Drift model for linear regression
33
3 The measurements are assumed to be obtained one at a time, ﬁrst y1,
then y2 and so on. At each step we use the posterior distribution from
the previous time step as the current prior distribution:
p. j y1/ D 1
Z1
p.y1 j /p./;
p. j y1W2/ D 1
Z2
p.y2 j /p. j y1/;
p. j y1W3/ D 1
Z3
p.y3 j /p. j y1W2/;
:::
p. j y1WT / D
1
ZT
p.yT j /p. j y1WT 1/:
It is easy to show that the posterior distribution at the ﬁnal step above
is exactly the posterior distribution obtained by the batch solution. Also,
reordering of measurements does not change the ﬁnal solution.
For example, Equations (3.6) and (3.7) give the one step update rule for the
linear regression problem in Equation (3.2).
The recursive formulation of Bayesian estimation has many useful prop-
erties.
 The recursive solution can be considered as the on-line learning solution
to the Bayesian learning problem. That is, the information on the param-
eters is updated in an on-line manner using new pieces of information as
they arrive.
 Because each step in the recursive estimation is a full Bayesian update
step, batch Bayesian inference is a special case of recursive Bayesian
inference.
 Due to the sequential nature of estimation we can also model the effect
of time on the parameters. That is, we can model what happens to the
parameter  between the measurements – this is actually the basis of
ﬁltering theory, where time behavior is modeled by assuming the pa-
rameter to be a time-dependent stochastic process .t/.
3.4 Drift model for linear regression
Assume that we have a similar linear regression model as in Equation (3.2),
but the parameter  is allowed to perform a Gaussian random walk be-

34
Batch and recursive Bayesian estimation
tween the measurements:
p.yk j k/ D N.yk j Hk k;  2/;
p.k j k1/ D N.k j k1; Q/;
p.0/ D N.0 j m0; P0/;
(3.9)
where Q is the covariance of the random walk. Now, given the distribution
p.k1 j y1Wk1/ D N.k1 j mk1; Pk1/;
the joint distribution of k and k1 is1
p.k; k1 j y1Wk1/ D p.k j k1/ p.k1 j y1Wk1/:
The distribution of k given the measurement history up to time step k  1
can be calculated by integrating over k1:
p.k j y1Wk1/ D
Z
p.k j k1/ p.k1 j y1Wk1/ dk1:
This relationship is sometimes called the Chapman–Kolmogorov equation.
Because p.k j k1/ and p.k1 j y1Wk1/ are Gaussian, the result of the
marginalization is Gaussian,
p.k j y1Wk1/ D N.k j m
k ; P 
k /;
where
m
k D mk1;
P 
k D Pk1 C Q:
By using this as the prior distribution for the measurement likelihood
p.yk j k/ we get the parameters of the posterior distribution
p.k j y1Wk/ D N.k j mk; Pk/;
which are given by Equations (3.8), when mk1 and Pk1 are replaced by
m
k and P 
k :
Sk D Hk P 
k HT
k C  2;
Kk D P 
k HT
k S1
k ;
mk D m
k C Kk Œyk  Hk m
k ;
Pk D P 
k  Kk Sk KT
k:
(3.10)
1 Note that this formula is correct only for Markovian dynamic models, where
p.k j k1; y1Wk1/ D p.k j k1/.

3.4 Drift model for linear regression
35
0
0.5
1
1.5
2
−1.5
−1
−0.5
0
0.5
1
1.5
 t
 
 
Measurements
True Signal
Estimate
Figure 3.5 Example of tracking a sine signal with linear model
with drift, where the parameters are allowed to vary according to
the Gaussian random walk model.
This recursive computational algorithm for the time-varying linear regres-
sion weights is again a special case of the Kalman ﬁlter algorithm. Fig-
ure 3.5 shows the result of recursive estimation of a sine signal assuming a
small diagonal Gaussian drift model for the parameters.
At this point we change from the regression notation used so far into
state space model notation, which is commonly used in Kalman ﬁlter-
ing and related dynamic estimation literature. Because this notation easily
causes confusion to people who have got used to regression notation, this
point is emphasized.
 In state space notation x means the unknown state of the system, that is,
the vector of unknown parameters in the system. It is not the regressor,
covariate or input variable of the system.
 For example, the time-varying linear regression model with drift pre-
sented in this section can be transformed into the more standard state
space model notation by replacing the variable k D .	1;k 	2;k/T with
the variable xk D .x1;k x2;k/T:
p.yk j xk/ D N.yk j Hk xk;  2/;
p.xk j xk1/ D N.xk j xk1; Q/;
p.x0/ D N.x0 j m0; P0/:
(3.11)

36
Batch and recursive Bayesian estimation
From now on, the symbol  is reserved for denoting the static parameters
of the state space model. Although there is no fundamental difference be-
tween states and static parameters of the model (we can always augment
the parameters as part of the state), it is useful to treat them separately.
3.5 State space model for linear regression with drift
The linear regression model with drift in the previous section had the disad-
vantage that the covariates tk occurred explicitly in the model speciﬁcation.
The problem with this is that when we get more and more measurements,
the parameter tk grows without bound. Thus the conditioning of the prob-
lem also gets worse in time. For practical reasons it also would be desirable
to have a time-invariant model, that is, a model which is not dependent on
the absolute time, but only on the relative positions of states and measure-
ments in time.
The alternative state space formulation of the linear regression model
with drift, without using explicit covariates, can be done as follows. Let’s
denote the time difference between consecutive times as tk1 D tktk1.
The idea is that if the underlying phenomenon (signal, state, parameter) xk
was exactly linear, the difference between adjacent time points could be
written exactly as
xk  xk1 D Px tk1;
(3.12)
where Px is the derivative, which is constant in the exactly linear case. The
divergence from the exactly linear function can be modeled by assuming
that the above equation does not hold exactly, but there is a small noise
term on the right hand side. The derivative can also be assumed to perform
a small random walk and thus not be exactly constant. This model can be
written as follows:
x1;k D x1;k1 C tk1x2;k1 C q1;k1;
x2;k D x2;k1 C q2;k1;
yk D x1;k C rk;
(3.13)
where the signal is the ﬁrst components of the state, x1;k , xk, and the
derivative is the second, x2;k , Pxk. The noises are rk  N.0; 2/ and
.q2;k1; q2;k1/  N.0; Q/. The model can also be written in the form
p.yk j xk/ D N.yk j H xk;  2/;
p.xk j xk1/ D N.xk j Ak1 xk1; Q/;
(3.14)

3.5 State space model for linear regression with drift
37
where
Ak1 D
1
tk1
0
1

;
H D

1
0
	
:
With a suitable Q this model is actually equivalent to model (3.9), but in
this formulation we explicitly estimate the state of the signal (point on the
regression line) instead of the linear regression parameters.
We could now explicitly derive the recursion equations in the same
manner as we did in the previous sections. However, we can also use the
Kalman ﬁlter, which is a readily derived recursive solution to generic linear
Gaussian models of the form
p.yk j xk/ D N.yk j Hk xk; Rk/;
p.xk j xk1/ D N.xk j Ak1 xk1; Qk1/:
Our alternative linear regression model in Equation (3.13) can be seen to
be a special case of these models. The Kalman ﬁlter equations are often
expressed as prediction and update steps as follows.
1 Prediction step:
m
k D Ak1 mk1;
P 
k D Ak1 Pk1 AT
k1 C Qk1:
2 Update step:
Sk D Hk P 
k HT
k C Rk;
Kk D P 
k HT
k S1
k ;
mk D m
k C Kk Œyk  Hk m
k ;
Pk D P 
k  Kk Sk KT
k:
The result of tracking the sine signal with Kalman ﬁlter is shown in Fig-
ure 3.6. All the mean and covariance calculation equations given in this
book so far have been special cases of the above equations, including the
batch solution to the scalar measurement case (which is a one-step solu-
tion). The Kalman ﬁlter recursively computes the mean and covariance of
the posterior distributions of the form
p.xk j y1Wk/ D N.xk j mk; Pk/:
Note that the estimates of xk derived from this distribution are non-
anticipative in the sense that they are only conditional on the measure-
ments obtained before and at the time step k. However, after we have
obtained the measurements y1; : : : ; yk, we could compute estimates of

38
Batch and recursive Bayesian estimation
0
0.5
1
1.5
2
−1.5
−1
−0.5
0
0.5
1
1.5
 t
 
 
Measurements
True Signal
Estimate
Figure 3.6 Example of tracking a sine signal with Kalman ﬁlter
using the locally linear state space model. The result differs a bit
from the random walk parameter model, because of slightly
different choice of process noise. It could be made equivalent if
desired.
xk1; xk2; : : :, which are also conditional to the measurements after the
corresponding state time steps. Because more measurements and more
information is available for the estimator, these estimates can be expected
to be more accurate than the non-anticipative measurements computed by
the ﬁlter.
The above mentioned problem of computing estimates of the state
by conditioning not only on previous measurements, but also on future
measurements, is called Bayesian smoothing as already mentioned in
Section 1.3. The Bayesian smoothing solution to the linear Gaussian
state space models is given by the Rauch–Tung–Striebel (RTS) smoother.
The full Bayesian theory of smoothing will be presented in Chapter 8.
The result of tracking the sine signal with the RTS smoother is shown in
Figure 3.7.
It is also possible to predict the time behavior of the state in the future
that we have not yet measured. This procedure is called optimal prediction.
Because optimal prediction can always be done by iterating the prediction
step of the optimal ﬁlter, no specialized algorithms are needed for this.
The result of prediction of the future values of the sine signal is shown in
Figure 3.8.

3.6 Examples of state space models
39
0
0.5
1
1.5
2
−1.5
−1
−0.5
0
0.5
1
1.5
 t
 
 
Measurements
True Signal
Estimate
Figure 3.7 Example of tracking a sine signal with the
Rauch–Tung–Striebel (RTS) smoother using the locally linear
state space model. The result is much “smoother” and more
accurate than the result of the Kalman ﬁlter.
3.6 Examples of state space models
In the previous sections we saw that a simple one-dimensional linear re-
gression problem can be converted into a state space model which can
be solved using the Kalman ﬁlter. In an analogous manner, more general
linear-in-parameters models can be converted into state space models. This
is demonstrated in the following example.
Example 3.1 (Linear-in-parameters regression model I)
Consider the fol-
lowing parametric model, where g1.tk/; : : : ; gd.tk/ are some given func-
tions of time tk:
yk D w0 C w1 g1.tk/ C    C wd gd.tk/ C "k;
(3.15)
and "k is a Gaussian measurement noise. The problem of determining the
weights w0; : : : ; wd from a set of measurements f.t1; y1/; : : : ; .tT ; yT /g
can be converted into a Kalman ﬁltering problem as follows. If we deﬁne
Hk D .1 g1.tk/    gd.tk// and xk D x D .w0 w1    wd/T, we can
rewrite the model as a linear Gaussian state space model:
xk D xk1;
yk D Hk xk C "k:
(3.16)

40
Batch and recursive Bayesian estimation
0
0.5
1
1.5
2
2.5
−1.5
−1
−0.5
0
0.5
1
1.5
 t
 
 
Measurements
True Signal
Estimate
Figure 3.8 Example of prediction of a sine signal with optimal
linear predictor (the Kalman ﬁlter prediction step) using the
locally linear state space model. The prediction is a straight line
extending to inﬁnity as the model states.
Because the model is a linear Gaussian state space model, we can use
linear Kalman ﬁlter for estimating the parameters.
There is no reason why we should select the functions gi above to be
explicit functions of time. Instead, they can be functions of arbitrary re-
gressors as is illustrated in the following example.
Example 3.2 (Linear-in-parameters regression model II)
Consider the
following parametric model, where g1.s/; : : : ; gd.s/ are some given func-
tions of a regressor variable s 2 Rn:
yk D w0 C w1 g1.sk/ C    C wd gd.sk/ C "k;
(3.17)
where the weights w0; : : : ; wd are to be estimated from a set of measure-
ments f.s1; y1/; : : : ; .sT ; yT /g. Analogously to the previous example, we
can convert the problem into a linear Gaussian state space model by deﬁn-
ing Hk D .1 g1.sk/    gd.sk// and xk D x D .w0 w1    wd/T.
Linearity of the state space models in the above examples resulted from
the property that the models are linear in parameters. Generalized linear
models involving non-linear link functions will lead to non-linear state
space models, as is illustrated with the following example.

3.6 Examples of state space models
41
Example 3.3 (Generalized linear model)
An example of a generalized
linear model is
yk D g.w0 C wT sk/ C "k;
(3.18)
where g./ is some given non-linear link function and sk is a vector of
regressors. If we deﬁne the state as x D .w0; w/ and hk.x/ , g.w0 C
wT sk/, we get the following non-linear Gaussian state space model:
xk D xk1;
yk D hk.xk/ C "k:
(3.19)
Because the state space model is non-linear, instead of the linear Kalman
ﬁlter, we need to use non-linear Kalman ﬁlters such as the extended Kalman
ﬁlter (EKF) or the unscented Kalman ﬁlter (UKF) to cope with the non-
linearity.
One general class of non-linear regression models, which can be con-
verted into state space models using an analogous approach to the above,
is the multi-layer perceptron (MLP) neural networks (see, e.g., Bishop,
2006). Using a non-linear Kalman ﬁlter is indeed one way to train (to esti-
mate the parameters of) such models (Haykin, 2001). However, non-linear
regression models of this kind arise in various others contexts as well.
In digital signal processing (DSP), an important class of models is linear
signal models such as autoregressive (AR) models, moving average (MA)
models, autoregressive moving average models (ARMA) and their gener-
alizations (see, e.g., Hayes, 1996). In those models one is often interested
in performing adaptive ﬁltering, which refers to the methodology where
the parameters of the signal model are estimated from data. These kinds
of adaptive ﬁltering problem can often be formulated as Kalman ﬁltering
problems, as is illustrated in the following example.
Example 3.4 (Autoregressive (AR) model)
An autoregressive (AR) model
of order d has the form
yk D w1 yk1 C    C wd ykd C "k;
(3.20)
where "k is a white Gaussian noise process. The problem of adaptive ﬁl-
tering is to estimate the weights w1; : : : ; wd given the observed signal
y1; y2; y3; : : :. If we let Hk D .yk1    ykd/ and deﬁne the state as
xk D .w1    wd/T, we get a linear Gaussian state space model
xk D xk1;
yk D Hk xk C "k:
(3.21)

42
Batch and recursive Bayesian estimation
Thus the adaptive ﬁltering problem can be solved with a linear Kalman
ﬁlter.
The classical algorithm for an adaptive ﬁltering is called the least mean
squares (LMS) algorithm, and it can be interpreted as an approximate ver-
sion of the above Kalman ﬁlter. However, in LMS algorithms it is common
to allow the model to change in time, which in the state space context cor-
responds to setting up a dynamic model for the model parameters. This
kind of model is illustrated in the next example.
Example 3.5 (Time-varying autoregressive (TVAR) model)
In a time-
varying autoregressive (TVAR) model the weights are assumed to depend
on the time step number k as
yk D w1;k yk1 C    C wd;k ykd C "k:
(3.22)
A typical model for the time dependence of weights is the random walk
model
wi;k D wi;k1 C qi;k1;
qi;k1  N.0; Qi/;
i D 1; : : : ; d:
(3.23)
If we deﬁne the state as xk D .w1;k1    wd;k1/T, this model can be
written as a linear Gaussian state space model with process noise qk1 D
.q1;k1    qd;k1/T:
xk D xk1 C qk1;
yk D Hk xk C "k:
(3.24)
More general (TV)ARMA models can be handled similarly.
In tracking and navigation (Bar-Shalom et al., 2001) the dynamic models
are often built based on Newtonian physics and classical mechanics. This
procedure also leads to linear and non-linear state space models. In the
following example we build a simple dynamic model for a car and its
measurement process.
Example 3.6 (State space model of a car)
The dynamics of the car in 2d
.x1; x2/ are governed by Newton’s law (see Figure 3.9(a))
g.t/ D m a.t/;
(3.25)
where a.t/ is the acceleration, m is the mass of the car, and g.t/ is a vector
of (unknown) forces acting on the car. Let’s now model g.t/=m as a two-

3.6 Examples of state space models
43
g1.t/
g2.t/
(a)
.y1; y2/
(b)
Figure 3.9 Illustration of car’s (a) dynamic and (b) measurement
models. In the dynamic model, the unknown forces g1.t/ and
g2.t/ are modeled as white noise processes. The measurements
.y1; y2/ are modeled as noise corrupted observations of the car’s
position.
dimensional white random process
d2x1
dt2 D w1.t/;
d2x2
dt2 D w2.t/:
(3.26)
If we deﬁne x3.t/ D dx1= dt, x4.t/ D dx2= dt, then the model can be
written as a ﬁrst order system of differential equations
d
dt
0
BB@
x1
x2
x3
x4
1
CCA D
0
BB@
0
0
1
0
0
0
0
1
0
0
0
0
0
0
0
0
1
CCA
„
ƒ‚
…
F
0
BB@
x1
x2
x3
x4
1
CCA C
0
BB@
0
0
0
0
1
0
0
1
1
CCA
„ ƒ‚ …
L
w1
w2

:
(3.27)
In shorter matrix form this can be written as a continuous-time linear
dynamic model of the form
dx
dt D F x C L w:
If the state of the car is measured (sampled) with sampling period t
it sufﬁces to consider the state of the car only at the time instants t 2

44
Batch and recursive Bayesian estimation
f0; t; 2t; : : :g. The dynamic model can be discretized, which leads to
0
BB@
x1;k
x2;k
x3;k
x4;k
1
CCA D
0
BB@
1
0
t
0
0
1
0
t
0
0
1
0
0
0
0
1
1
CCA
„
ƒ‚
…
A
0
BB@
x1;k1
x2;k1
x3;k1
x4;k1
1
CCA C qk;
(3.28)
where qk is a discrete-time Gaussian noise process. This can be seen to be
a (discrete-time) linear dynamic model of the form
xk D A xk1 C qk1;
where xk D x.tk/, and A is the transition matrix.
Assume that the position of the car .x1; x2/ is measured and the mea-
surements are corrupted by Gaussian measurement noise .r1;k; r2;k/ (see
Figure 3.9(b)):
y1;k D x1;k C r1;k;
y2;k D x2;k C r2;k:
(3.29)
The measurement model can now be written as
yk D H xk C rk;
H D
1
0
0
0
0
1
0
0

:
(3.30)
The dynamic and measurement models of the car form a linear Gaussian
state space model
xk D A xk1 C qk1;
yk D H xk C rk;
where qk1  N.0; Q/ and rk  N.0; R/. The state of the car from the
noisy measurements can be estimated using the Kalman ﬁlter.
The above car model is a linear Gaussian state space model, because
the model was based on a linear differential equation, and the measured
quantities were linear functions of the state. However, if either the dynamic
or measurement model is non-linear, we get a non-linear state space model,
as is illustrated in the following example.
Example 3.7 (Noisy pendulum model)
The differential equation for a
simple pendulum (see Figure 3.10) with unit length and mass can be written
as
d2˛
dt2 D g sin.˛/ C w.t/;
(3.31)

3.6 Examples of state space models
45
g
w.t/
˛
Figure 3.10 Illustration of pendulum example. In addition to the
gravitation g there is an additional unknown force component
w.t/, which is modeled as white noise.
where ˛ is the angle, g is the gravitational acceleration and w.t/ is a
random noise process. This model can be converted into the following state
space model:
d
dt
x1
x2

D

x2
g sin.x1/

C
0
1

w.t/;
(3.32)
where x1 D ˛ and x2 D d˛= dt. This can be seen to be a special case of
continuous-time non-linear dynamic models of the form
dx
dt D f.x/ C L w;
(3.33)
where f.x/ is a non-linear function. We can then, for example, consider
measuring the angular position of the pendulum, which leads to the linear
Gaussian measurement model
yk D ˛.tk/ C noise:
(3.34)
However, if we measured only the horizontal position of the pendulum, we
would get a non-linear measurement model
yk D sin.˛.tk// C noise:
(3.35)
By a suitable numerical integration scheme we can convert the non-linear
dynamic model into a discrete-time non-linear dynamic model, which then

46
Batch and recursive Bayesian estimation
results in a model of the generic non-linear state space form
xk D f.xk1; qk1/;
yk D h.xk; rk/;
(3.36)
where yk is the vector of measurements, qk1  N.0; Q/, and rk 
N.0; R). Estimation of the pendulum state can be now implemented using,
for example, the extended Kalman ﬁlter (EKF), unscented Kalman ﬁlter
(UKF) or particle ﬁlter.
3.7 Exercises
3.1
In this exercise your task is to implement a simple Kalman ﬁlter using ready-
made codes and analyze the results.
(a) Download and install the EKF/UKF toolbox2 to some MATLAB R

computer. Run the following demonstrations:
demos/kf_sine_demo/kf_sine_demo.m
demos/kf_cwpa_demo/kf_cwpa_demo.m
After running them read the contents of these ﬁles and try to
understand how they have been implemented. Also read the docu-
mentation for the functions kf_predict and kf_update (type, e.g.,
“help kf_predict” in MATLAB R
).
(b) Consider the following state space model:
xk D
1
1
0
1

xk1 C qk1;
yk D

1
0
	
xk C rk;
(3.37)
where xk D .xk Pxk/T is the state, yk is the measurement, and qk 
N.0; diag.1=102; 12// and rk  N.0; 102/ are white Gaussian noise
processes.
Simulate a 100 step state sequence from the model and plot the signal
xk, signal derivative Pxk, and the simulated measurements yk. Start from
an initial state drawn from the zero-mean 2d-Gaussian distribution with
identity covariance.
(c) Use the Kalman ﬁlter for computing the state estimates mk using
MATLAB R
-code along the following lines:
m = [0;0];
% Initial mean
P = eye(2); % Initial covariance
for k = 1:100
2 The EKF/UKF toolbox is available for download on the web page
becs.aalto.fi/en/research/bayes/ekfukf/

Exercises
47
[m,P] = kf_predict(m,P,A,Q);
[m,P] = kf_update(m,P,y(k),H,R);
% Store the estimate m of state x_k here
end
(d) Plot the state estimates mk, the true states xk and measurements yk.
Compute the root mean squared error (RMSE) of using the ﬁrst com-
ponents of vectors mk as the estimates of the ﬁrst components of states
xk. Also compute the RMSE error that we would have if we used the
measurements as the estimates.
3.2
Note that the model in Exercise 2.4 can be rewritten as a linear state space
model
wk D wk1;
yk D Hk wk C "k;
where Hk D .xk 1/, w0  N.0; 2I/ and "k  N.0; 1/. The state in
the model is now wk D .	1 	2/T and the measurements are yk for k D
1; : : : ; T . Assume that the Kalman ﬁlter is used for processing the measure-
ments y1; : : : ; yT . Your task is to prove that at time step T , the mean and
covariance of wT computed by the Kalman ﬁlter are the same as the mean
and covariance of the posterior distribution computed in Exercise 2.4.
The Kalman ﬁlter equations for the above model can be written as:
Sk D Hk Pk1 HT
k C 1;
Kk D Pk1 HT
k S1
k ;
mk D mk1 C Kk .yk  Hk mk1/;
Pk D Pk1  Kk Sk KT
k:
(a) Write formulas for the posterior mean mk1 and covariance Pk1 as-
suming that they are the same as those which would be obtained if the
pairs f.xi; yi/ W i D 1; : : : ; k  1g were (batch) processed as in Ex-
ercise 2.4. Write similar equations for the mean mk and covariance Pk.
Show that the posterior means can be expressed in the form
mk1 D Pk1 XT
k1 yk1;
mk D Pk XT
k yk;
where Xk1 and yk1 have been constructed as X and y in Exercise 2.4,
except that only the pairs f.xi; yi/ W i D 1; : : : ; k  1g have been used,
and Xk and yk have been constructed similarly from pairs up to the step
k.
(b) Rewrite the expressions XT
k Xk and XT
k yk in terms of Xk1, yk1, Hk
and yk. Substitute these into the expressions of mk and Pk obtained in
(a).

48
Batch and recursive Bayesian estimation
(c) Expand the expression of the covariance Pk D Pk1  Kk Sk KT
k by
substituting the expressions for Kk and Sk. Convert it to a simpler form
by applying the matrix inversion lemma
Pk1Pk1 HT
k .Hk Pk1 HT
kC1/1 Hk Pk1 D .P 1
k1CHT
k Hk/1:
Show that this expression for Pk is equivalent to the expression in (a).
(d) Expand the expression of the mean mk D mk1 CKk .yk Hk mk1/
and show that the result is equivalent to the expression obtained in (a).
Hint: the Kalman gain can also be written as Kk D Pk HT
k.
(e) Prove by an induction argument that the mean and covariance computed
by the Kalman ﬁlter at step T is the same as the posterior mean and
covariance obtained in Exercise 2.4.
3.3
Consider the regression problem
yk D a1 sk C a2 sin.sk/ C b C "k;
k D 1; : : : ; T;
"k  N.0; R/;
a1  N.0; 2
1 /;
a2  N.0; 2
2 /;
b  N.0; 2
b /;
(3.38)
where sk 2 R are the known regressor values, R; 2
1 ; 2
2 ; 2
b are given pos-
itive constants, yk 2 R are the observed output variables, and "k are in-
dependent Gaussian measurement errors. The scalars a1, a2, and b are the
unknown parameters to be estimated. Formulate the estimation problem as a
linear Gaussian state space model.
3.4
Consider the model
xk D
d
X
iD1
ai xki C qk1;
yk D xk C "k;
(3.39)
where the values fykg are observed, qk1 and "k are independent Gaussian
noises, and the weights a1; : : : ; ad are known. The aim is to estimate the
sequence fxkg. Rewrite the problem as an estimation problem in a linear
Gaussian state space model.
3.5
Recall that the Gaussian probability density is deﬁned as
N.x j m; P/ D
1
.2 /n=2 jPj1=2 exp

1
2.x  m/T P 1 .x  m/

:
Derive the following Gaussian identities.
(a) Let x and y have the Gaussian densities
p.x/ D N.x j m; P/;
p.y j x/ D N.y j H x; R/;

Exercises
49
then the joint distribution of x and y is
x
y

 N
 m
H m

;
 P
P HT
H P
H P HT C R

and the marginal distribution of y is
y  N.H m; H P HT C R/:
Hint: use the properties of expectation EŒH xCr D H EŒxCEŒr and
CovŒH x C r D H CovŒx HT C CovŒr (if x and r are independent).
(b) Write down the explicit expression for the joint and marginal probability
densities above:
p.x; y/ D p.y j x/ p.x/ D‹
p.y/ D
Z
p.y j x/ p.x/ dx D‹
(c) If the random variables x and y have the joint Gaussian probability
density
x
y

 N
a
b

;
 A
C
CT
B

;
then the conditional density of x given y is
x j y  N.a C C B1 .y  b/; A  C B1CT/:
Hints:
 Denote inverse covariance as D D
D11
D12
DT
12
D22

and expand the
quadratic form in the Gaussian exponent.
 Compute the derivative with respect to x and set it to zero. Conclude
that due to symmetry the point where the derivative vanishes is the
mean.
 Check from a linear algebra book that the inverse of D11 is given by
the Schur complement:
D1
11 D A  C B1 CT
and that D12 can be then written as
D12 D D11 C B1:
 Find the simpliﬁed expression for the mean by applying the identities
above.
 Find the second derivative of the negative Gaussian exponent with
respect to x. Conclude that it must be the inverse conditional covari-
ance of x.

50
Batch and recursive Bayesian estimation
 Use the Schur complement expression above for computing the con-
ditional covariance.

4
Bayesian ﬁltering equations and
exact solutions
In this chapter, we derive the Bayesian ﬁltering equations, which are the
general equations for computing Bayesian ﬁltering solutions to both linear
Gaussian and non-linear/non-Gaussian state space models. We also derive
the Kalman ﬁltering equations which give the closed form solution to the
linear Gaussian Bayesian ﬁltering problem.
4.1 Probabilistic state space models
Bayesian ﬁltering is considered with state estimation in general probabilis-
tic state space models which have the following form.
Deﬁnition 4.1 (Probabilistic state space model)
A probabilistic state
space model or non-linear ﬁltering model consists of a sequence of
conditional probability distributions:
xk  p.xk j xk1/;
yk  p.yk j xk/;
(4.1)
for k D 1; 2; : : :, where
 xk 2 Rn is the state of the system at time step k,
 yk 2 Rm is the measurement at time step k,
 p.xk j xk1/ is the dynamic model which describes the stochastic dy-
namics of the system. The dynamic model can be a probability density,
a counting measure or a combination of them depending on whether the
state xk is continuous, discrete, or hybrid.
 p.yk j xk/ is the measurement model, which is the distribution of mea-
surements given the state.
The model is assumed to be Markovian, which means that it has the
following two properties.
51

52
Bayesian ﬁltering equations and exact solutions
Property 4.1 (Markov property of states)
The states fxk W k D 0; 1; 2; : : :g form a Markov sequence (or Markov
chain if the state is discrete). This Markov property means that xk (and
actually the whole future xkC1; xkC2; : : :) given xk1 is independent of
anything that has happened before the time step k  1:
p.xk j x1Wk1; y1Wk1/ D p.xk j xk1/:
(4.2)
Also the past is independent of the future given the present:
p.xk1 j xkWT ; ykWT / D p.xk1 j xk/:
(4.3)
Property 4.2 (Conditional independence of measurements)
The current measurement yk given the current state xk is conditionally
independent of the measurement and state histories:
p.yk j x1Wk; y1Wk1/ D p.yk j xk/:
(4.4)
A simple example of a Markovian sequence is the Gaussian random
walk. When this is combined with noisy measurements, we obtain the fol-
lowing example of a probabilistic state space model.
Example 4.1 (Gaussian random walk)
A Gaussian random walk model
can be written as
xk D xk1 C qk1;
qk1  N.0; Q/;
yk D xk C rk;
rk  N.0; R/;
(4.5)
where xk is the hidden state (or signal) and yk is the measurement. In
terms of probability densities the model can be written as
p.xk j xk1/ D N.xk j xk1; Q/
D
1
p2Q exp

 1
2Q.xk  xk1/2

;
p.yk j xk/ D N.yk j xk; R/
D
1
p
2R
exp

 1
2R.yk  xk/2

;
(4.6)
which is a probabilistic state space model. Example realizations of the
signal xk and measurements yk are shown in Figure 4.1. The parameter
values in the simulation were Q D R D 1.
With the Markovian assumption and the ﬁltering model (4.1), the joint
prior distribution of the states x0WT D fx0; : : : ; xT g, and the joint likeli-

4.1 Probabilistic state space models
53
0
20
40
60
80
100
−10
−8
−6
−4
−2
0
2
4
6
Time step k
 xk
 
 
Signal
Measurement
Figure 4.1 Simulated signal and measurements from the
Gaussian random walk model in Example 4.1.
hood of the measurements y1WT D fy1; : : : ; yT g are, respectively,
p.x0WT / D p.x0/
TY
kD1
p.xk j xk1/;
(4.7)
p.y1WT j x0WT / D
TY
kD1
p.yk j xk/:
(4.8)
In principle, for a given T we could simply compute the posterior distribu-
tion of the states by Bayes’ rule:
p.x0WT j y1WT / D p.y1WT j x0WT / p.x0WT /
p.y1WT /
/ p.y1WT j x0WT / p.x0WT /:
(4.9)
However, this kind of explicit usage of the full Bayes’ rule is not feasible in
real-time applications, because the number of computations per time step
increases as new observations arrive. Thus, this way we could only work
with small data sets, because if the amount of data is unbounded (as in real-
time sensing applications), then at some point of time the computations
will become intractable. To cope with real-time data we need to have an
algorithm which does a constant number of computations per time step.

54
Bayesian ﬁltering equations and exact solutions
As discussed in Section 1.3, ﬁltering distributions, prediction distribu-
tions, and smoothing distributions can be computed recursively such that
only a constant number of computations is done on each time step. For this
reason we shall not consider the full posterior computation at all, but con-
centrate on the above-mentioned distributions instead. In this and the few
following chapters, we consider computation of the ﬁltering and prediction
distributions; algorithms for computing the smoothing distributions will be
considered in later chapters.
4.2 Bayesian ﬁltering equations
The purpose of Bayesian ﬁltering is to compute the marginal posterior
distribution or ﬁltering distribution of the state xk at each time step k given
the history of the measurements up to the time step k:
p.xk j y1Wk/:
(4.10)
The fundamental equations of the Bayesian ﬁltering theory are given by
the following theorem.
Theorem 4.1 (Bayesian ﬁltering equations)
The recursive equations (the
Bayesian ﬁlter) for computing the predicted distribution p.xk j y1Wk1/
and the ﬁltering distribution p.xk j y1Wk/ at the time step k are given by
the following Bayesian ﬁltering equations.
 Initialization. The recursion starts from the prior distribution p.x0/.
 Prediction step. The predictive distribution of the state xk at the time
step k, given the dynamic model, can be computed by the Chapman–
Kolmogorov equation
p.xk j y1Wk1/ D
Z
p.xk j xk1/ p.xk1 j y1Wk1/ dxk1:
(4.11)
 Update step. Given the measurement yk at time step k the posterior
distribution of the state xk can be computed by Bayes’ rule
p.xk j y1Wk/ D 1
Zk
p.yk j xk/ p.xk j y1Wk1/;
(4.12)
where the normalization constant Zk is given as
Zk D
Z
p.yk j xk/ p.xk j y1Wk1/ dxk:
(4.13)
If some of the components of the state are discrete, the corresponding inte-
grals are replaced with summations.

4.2 Bayesian ﬁltering equations
55
Figure 4.2 Visualization of the prediction step: prediction
propagates the state distribution of the previous measurement step
through the dynamic model such that the uncertainties
(stochastics) in the dynamic model are taken into account.
(a)
(b)
Figure 4.3 Visualization of the update step: (a) prior distribution
from prediction and the likelihood of measurement just before the
update step; (b) the posterior distribution after combining the
prior and likelihood by Bayes’ rule.
Proof
The joint distribution of xk and xk1 given y1Wk1 can be computed
as
p.xk; xk1 j y1Wk1/ D p.xk j xk1; y1Wk1/ p.xk1 j y1Wk1/
D p.xk j xk1/ p.xk1 j y1Wk1/;
(4.14)

56
Bayesian ﬁltering equations and exact solutions
where the disappearance of the measurement history y1Wk1 is due to the
Markov property of the sequence fxk W k D 1; 2; : : :g. The marginal dis-
tribution of xk given y1Wk1 can be obtained by integrating the distribution
(4.14) over xk1, which gives the Chapman–Kolmogorov equation
p.xk j y1Wk1/ D
Z
p.xk j xk1/ p.xk1 j y1Wk1/ dxk1:
(4.15)
If xk1 is discrete, then the above integral is replaced with summation over
xk1. The distribution of xk given yk and y1Wk1, that is, given y1Wk, can be
computed by Bayes’ rule
p.xk j y1Wk/ D 1
Zk
p.yk j xk; y1Wk1/ p.xk j y1Wk1/
D 1
Zk
p.yk j xk/ p.xk j y1Wk1/;
(4.16)
where the normalization constant is given by Equation (4.13). The disap-
pearance of the measurement history y1Wk1 in Equation (4.16) is due to the
conditional independence of yk of the measurement history, given xk.
4.3 Kalman ﬁlter
The Kalman ﬁlter (Kalman, 1960b) is the closed form solution to the
Bayesian ﬁltering equations for the ﬁltering model, where the dynamic
and measurement models are linear Gaussian:
xk D Ak1 xk1 C qk1;
yk D Hk xk C rk;
(4.17)
where xk 2 Rn is the state, yk 2 Rm is the measurement, qk1 
N.0; Qk1/ is the process noise, rk  N.0; Rk/ is the measurement noise,
and the prior distribution is Gaussian x0  N.m0; P0/. The matrix Ak1
is the transition matrix of the dynamic model and Hk is the measurement
model matrix. In probabilistic terms the model is
p.xk j xk1/ D N.xk j Ak1 xk1; Qk1/;
p.yk j xk/ D N.yk j Hk xk; Rk/:
(4.18)
Theorem 4.2 (Kalman ﬁlter)
The Bayesian ﬁltering equations for the lin-
ear ﬁltering model (4.17) can be evaluated in closed form and the resulting

4.3 Kalman ﬁlter
57
distributions are Gaussian:
p.xk j y1Wk1/ D N.xk j m
k ; P 
k /;
p.xk j y1Wk/ D N.xk j mk; Pk/;
p.yk j y1Wk1/ D N.yk j Hkm
k ; Sk/:
(4.19)
The parameters of the distributions above can be computed with the fol-
lowing Kalman ﬁlter prediction and update steps.
 The prediction step is
m
k D Ak1 mk1;
P 
k D Ak1 Pk1 AT
k1 C Qk1:
(4.20)
 The update step is
vk D yk  Hk m
k ;
Sk D Hk P 
k HT
k C Rk;
Kk D P 
k HT
k S1
k ;
mk D m
k C Kk vk;
Pk D P 
k  Kk Sk KT
k:
(4.21)
The recursion is started from the prior mean m0 and covariance P0.
Proof
The Kalman ﬁlter equations can be derived as follows.
1 By Lemma A.1 on page 209, the joint distribution of xk and xk1 given
y1Wk1 is
p.xk1; xk j y1Wk1/
D p.xk j xk1/ p.xk1 j y1Wk1/
D N.xk j Ak1 xk1; Qk1/ N.xk1 j mk1; Pk1/
D N
xk1
xk
 ˇˇˇ m0; P 0

;
(4.22)
where
m0 D

mk1
Ak1 mk1

;
P 0 D

Pk1
Pk1 AT
k1
Ak1 Pk1
Ak1 Pk1 AT
k1 C Qk1

;
(4.23)
and the marginal distribution of xk is by Lemma A.2
p.xk j y1Wk1/ D N.xk j m
k ; P 
k /;
(4.24)

58
Bayesian ﬁltering equations and exact solutions
where
m
k D Ak1 mk1;
P 
k D Ak1 Pk1 AT
k1 C Qk1:
(4.25)
2 By Lemma A.1, the joint distribution of yk and xk is
p.xk; yk j y1Wk1/ D p.yk j xk/ p.xk j y1Wk1/
D N.yk j Hk xk; Rk/ N.xk j m
k ; P 
k /
D N
xk
yk
 ˇˇˇ m00; P 00

;
(4.26)
where
m00 D
 m
k
Hk m
k

;
P 00 D
 P 
k
P 
k HT
k
Hk P 
k
Hk P 
k HT
k C Rk

: (4.27)
3 By Lemma A.2 the conditional distribution of xk is
p.xk j yk; y1Wk1/ D p.xk j y1Wk/
D N.xk j mk; Pk/;
(4.28)
where
mk D m
k C P 
k HT
k.Hk P 
k HT
k C Rk/1Œyk  Hk m
k ;
Pk D P 
k  P 
k HT
k .Hk P 
k HT
k C Rk/1 Hk P 
k ;
(4.29)
which can be also written in the form (4.21).
The functional form of the Kalman ﬁlter equations given here is not
the only possible one. From a numerical stability point of view it would
be better to work with matrix square roots of covariances instead of plain
covariance matrices. The theory and details of implementation of this kind
of method is well covered, for example, in the book of Grewal and Andrews
(2001).
Example 4.2 (Kalman ﬁlter for a Gaussian random walk)
Assume that we
are observing measurements yk of the Gaussian random walk model given
in Example 4.1 and we want to estimate the state xk at each time step.
The information obtained up to time step k is summarized by the Gaussian
ﬁltering density
p.xk j y1Wk/ D N.xk j mk; Pk/:
(4.30)

4.3 Kalman ﬁlter
59
0
20
40
60
80
100
−10
−8
−6
−4
−2
0
2
4
6
Time step k
 xk
 
 
Signal
Measurement
Filter Estimate
95% Quantiles
Figure 4.4 Signal, measurements and the result of Kalman
ﬁltering of the Gaussian random walk in Example 4.2.
The Kalman ﬁlter prediction and update equations are now given as
m
k D mk1;
P 
k D Pk1 C Q;
mk D m
k C
P 
k
P 
k C R.yk  m
k /;
Pk D P 
k  .P 
k /2
P 
k C R:
(4.31)
The result of applying this Kalman ﬁlter to the data in Figure 4.1 is shown
in Figure 4.4.
Example 4.3 (Kalman ﬁlter for car tracking)
By discretizing the state
space model for the car in Example 3.6 we get the following linear state
space model:
xk D A xk1 C qk1;
qk1  N.0; Q/;
(4.32)
yk D H xk C rk;
rk  N.0; R/;
(4.33)
where the state is four dimensional, x D .x1; x2; x3; x4/, such that the
position of the car is .x1; x2/ and the corresponding velocities are .x3; x4/.

60
Bayesian ﬁltering equations and exact solutions
The matrices in the dynamic model are
A D
0
BB@
1
0
t
0
0
1
0
t
0
0
1
0
0
0
0
1
1
CCA ;
Q D
0
BBBB@
qc
1 t3
3
0
qc
1 t2
2
0
0
qc
2 t3
3
0
qc
2 t2
2
qc
1 t2
2
0
qc
1 t
0
0
qc
2 t2
2
0
qc
2 t
1
CCCCA
;
where qc
1 and qc
2 are the spectral densities (continuous time variances)
of the process noises in each direction. The matrices in the measurement
model are
H D
1
0
0
0
0
1
0
0

;
R D
2
1
0
0
 2
2

;
where  2
1 and  2
2 are the measurement noise variances in each position
coordinate.
 The Kalman ﬁlter prediction step now becomes the following:
m
k D
0
BB@
1
0
t
0
0
1
0
t
0
0
1
0
0
0
0
1
1
CCA mk1;
P 
k D
0
BB@
1
0
t
0
0
1
0
t
0
0
1
0
0
0
0
1
1
CCA Pk1
0
BB@
1
0
t
0
0
1
0
t
0
0
1
0
0
0
0
1
1
CCA
T
C
0
BBBB@
qc
1 t3
3
0
qc
1 t2
2
0
0
qc
2 t3
3
0
qc
2 t2
2
qc
1 t2
2
0
qc
1 t
0
0
qc
2 t2
2
0
qc
2 t
1
CCCCA
:

4.3 Kalman ﬁlter
61
−4
−2
0
2
4
6
8
10
12
−12
−10
−8
−6
−4
−2
0
2
 x1
 x2
 
 
True Trajectory
Measurements
Filter Estimate
Figure 4.5 Simulated trajectory, measurements, and the result of
the Kalman ﬁlter based car tracking in Example 4.3. The starting
point is at the top of the trajectory. The RMSE position error
based on the measurements only is 0:77 whereas the position
RMSE of the Kalman ﬁlter estimate is 0:43.
 The corresponding Kalman ﬁlter update step is
Sk D
1
0
0
0
0
1
0
0

P 
k
1
0
0
0
0
1
0
0
T
C
 2
1
0
0
 2
2

;
Kk D P 
k
1
0
0
0
0
1
0
0
T
S1
k ;
mk D m
k C Kk

yk 
1
0
0
0
0
1
0
0

m
k

;
Pk D P 
k  Kk Sk KT
k:
The result of applying this ﬁlter to simulated data is shown in Figure 4.5.
The parameter values used in the simulation were 1 D 2 D 1=2, qc
1 D
qc
2 D 1, and t D 1=10.
Although the Kalman ﬁlter can be seen as the closed form Bayesian
solution to the linear Gaussian ﬁltering problem, the original derivation of
Kalman (1960b) is based on a different principle. In his seminal article,
Kalman (1960b) derived the ﬁlter by considering orthogonal projections
on the linear manifold spanned by the measurements. A similar approach

62
Bayesian ﬁltering equations and exact solutions
is also employed in many other works concentrating on estimation in linear
systems such as in the book of Kailath et al. (2000). The advantage of
the approach is that it avoids explicit Gaussian assumptions in the noise
processes, as the Kalman ﬁlter can be seen as a more general best linear
unbiased estimator of the state. The disadvantage is that the route to non-
linear models is much less straightforward than in the present Bayesian
approach.
4.4 Exercises
4.1
Derive the Kalman ﬁlter equations for the following linear-Gaussian ﬁltering
model with non-zero-mean noises:
xk D A xk1 C qk1;
yk D H xk C rk;
(4.34)
where qk1  N.mq; Q/ and rk  N.mr; R/.
4.2
Write down the Bayesian ﬁltering equations for ﬁnite-state hidden Markov
models (HMM), that is, for models where the state only takes values from a
ﬁnite set xk 2 f1; : : : ; Nxg.
4.3
Implement the Kalman ﬁlter in Example 4.2 for the Gaussian random walk
model with MATLAB R
. Draw realizations of state and measurement se-
quences and apply the ﬁlter to it. Plot the evolution of the ﬁltering distribu-
tion.
4.4
Select a ﬁnite interval in the state space, say, x 2 Œ10; 10 and discretize
it evenly to N subintervals (e.g. N D 1000). Using a suitable numerical
approximation to the integrals in the Bayesian ﬁltering equations, implement
a ﬁnite grid approximation to the Bayesian ﬁlter for the Gaussian random
walk in Example 4.1. Verify that the result is practically the same as that of
the Kalman ﬁlter above.
4.5
Derive the stationary Kalman ﬁlter for the Gaussian random walk model.
That is, compute the limiting Kalman ﬁlter gain when k ! 1 and write
down the mean equation of the resulting constant-gain Kalman ﬁlter. Plot
the frequency response of the resulting time-invariant ﬁlter. Which type of
digital ﬁlter is it?
4.6
Consider the following dynamic model:
xk D
 
cos !
sin.!/
!
! sin.!/
cos.!/
!
xk1 C qk1;
yk D

1
0
	
xk C rk;

Exercises
63
where xk 2 R2 is the state, yk is the measurement, rk  N.0; 0:1/ is a white
Gaussian measurement noise, and qk  N.0; Q/, where
Q D
 qc !qc cos.!/ sin.!/
2!3
qc sin2.!/
2!2
qc sin2.!/
2!2
qc !Cqc cos.!/ sin.!/
2!
!
:
(4.35)
The angular velocity is ! D 1=2 and the spectral density is qc D 0:01.
The model is a discretized version of the noisy resonator model with a given
angular velocity !.
In the ﬁle1 kf_ex.m there is simulation of the dynamic model together with
a base line solution, where the measurement is directly used as the estimate
of the state component x1 and the second component x2 is computed as a
weighted average of the measurement differences.
(a) Implement the Kalman ﬁlter for the model and compare its performance
(in the RMSE sense) to the base line solution. Plot ﬁgures of the solu-
tions.
(b) Compute (numerically) the stationary Kalman ﬁlter corresponding to
the model. Test this stationary ﬁlter against the base line and Kalman
ﬁlter solutions. Plot the results and report the RMSE values for the
solutions. What is the practical difference in the stationary and non-
stationary Kalman ﬁlter solutions?
1 The MATLAB R
 ﬁles are available on this book’s web page
www.cambridge.org/sarkka/

5
Extended and unscented Kalman ﬁltering
It often happens in practical applications that the dynamic and measure-
ment models are not linear and the Kalman ﬁlter is not appropriate. How-
ever, often the ﬁltering distributions of this kind of model can be approx-
imated by Gaussian distributions. In this chapter, three types of method
for forming the Gaussian approximations are considered, the Taylor series
based extended Kalman ﬁlters (EKF), the statistical linearization based sta-
tistically linearized ﬁlters (SLF), and the unscented transform based un-
scented Kalman ﬁlters (UKF). Among these, the UKF differs from the
other ﬁlters in this section in the sense that it is not a series expansion
based method per se – even though it was originally justiﬁed by consider-
ing a series expansion of the non-linear function. Actually, the relationship
is even closer than that, because the UKF can be considered as an approx-
imation of the SLF and it converges to the EKF in a suitable parameter
limit.
5.1 Taylor series expansions
Consider the following transformation of a Gaussian random variable x
into another random variable y:
x  N.m; P/;
y D g.x/;
(5.1)
where x 2 Rn, y 2 Rm, and g W Rn ! Rm is a general non-linear
function. Formally, the probability density of the random variable y is1
(see, e.g., Gelman et al., 2004)
p.y/ D jJ.y/j N.g1.y/ j m; P/;
(5.2)
1 This actually only applies to invertible g./, but it can easily be generalized to the
non-invertible case.
64

5.1 Taylor series expansions
65
where jJ.y/j is the determinant of the Jacobian matrix of the inverse trans-
form g1.y/. However, it is not generally possible to handle this distribu-
tion directly, because it is non-Gaussian for all but linear g.
A ﬁrst order Taylor series based Gaussian approximation to the distri-
bution of y can now be formed as follows. If we let x D m C ıx, where
ıx  N.0; P/, we can form the Taylor series expansion of the function g./
as follows (provided that the function is sufﬁciently differentiable):
g.x/ D g.mCıx/  g.m/CGx.m/ ıxC
X
i
1
2ıxT G.i/
xx.m/ ıx ei C   ;
(5.3)
where Gx.m/ is the Jacobian matrix of g with elements
ŒGx.m/j;j 0 D @gj.x/
@xj 0
ˇˇˇˇˇ
xDm
;
(5.4)
and G.i/
xx.m/ is the Hessian matrix of gi./ evaluated at m:
h
G.i/
xx.m/
i
j;j 0 D @2gi.x/
@xj @xj 0
ˇˇˇˇˇ
xDm
:
(5.5)
Furthermore, ei D .0    0 1 0    0/T is a vector with 1 at position i and
all other elements zero, that is, it is the unit vector in the direction of the
coordinate axis i.
The linear approximation can be obtained by approximating the function
by the ﬁrst two terms in the Taylor series:
g.x/ ' g.m/ C Gx.m/ ıx:
(5.6)
Computing the expected value with respect to x gives:
EŒg.x/ ' EŒg.m/ C Gx.m/ ıx
D g.m/ C Gx.m/ EŒıx
D g.m/:
(5.7)

66
Extended and unscented Kalman ﬁltering
The covariance can then be approximated as
E
h
.g.x/  EŒg.x// .g.x/  EŒg.x//Ti
' E
h
.g.x/  g.m// .g.x/  g.m//Ti
' E
h
.g.m/ C Gx.m/ ıx  g.m// .g.m/ C Gx.m/ ıx  g.m//Ti
D E
h
.Gx.m/ ıx/ .Gx.m/ ıx/Ti
D Gx.m/ E

ıx ıxT
GT
x.m/
D Gx.m/ P GT
x.m/:
(5.8)
We often are also interested in the the joint covariance between the vari-
ables x and y. Approximation of the joint covariance can be achieved by
considering the augmented transformation
Qg.x/ D
 x
g.x/

:
(5.9)
The resulting mean and covariance are
EŒQg.x/ '
 m
g.m/

;
CovŒQg.x/ '

I
Gx.m/

P

I
Gx.m/
T
D

P
P GT
x.m/
Gx.m/ P
Gx.m/ P GT
x.m/

:
(5.10)
In the derivation of the extended Kalman ﬁlter equations, we need a slightly
more general transformation of the form
x  N.m; P/;
q  N.0; Q/;
y D g.x/ C q;
(5.11)
where q is independent of x. The joint distribution of x and y, as deﬁned
above, is now the same as in Equations (5.10) except that the covariance Q
is added to the lower right block of the covariance matrix of Qg./. Thus we
get the following algorithm.

5.1 Taylor series expansions
67
Algorithm 5.1 (Linear approximation of an additive transform)
The lin-
ear approximation based Gaussian approximation to the joint distribu-
tion of x and the transformed random variable y D g.x/ C q, where
x  N.m; P/ and q  N.0; Q/, is given as
x
y

 N
 m
L

;
 P
CL
CT
L
SL

;
(5.12)
where
L D g.m/;
SL D Gx.m/ P GT
x.m/ C Q;
CL D P GT
x.m/;
(5.13)
and Gx.m/ is the Jacobian matrix of g with respect to x, evaluated at
x D m, with elements
ŒGx.m/j;j 0 D @gj.x/
@xj 0
ˇˇˇˇˇ
xDm
:
(5.14)
In ﬁltering models where the process noise is not additive, we often need
to approximate transformations of the form
x  N.m; P/;
q  N.0; Q/;
y D g.x; q/;
(5.15)
where x and q are independent random variables. The mean and covariance
can now be computed by substituting the augmented vector .x; q/ for the
vector x in Equation (5.10). The joint Jacobian matrix can then be written
as Gx;q D .Gx Gq/. Here Gq is the Jacobian matrix of g./ with respect
to q and both Jacobian matrices are evaluated at x D m; q D 0. The
approximations to the mean and covariance of the augmented transform as
in Equation (5.10) are then given as
EŒQg.x; q/ ' g.m; 0/;
CovŒQg.x; q/ '

I
0
Gx.m/
Gq.m/
 P
0
0
Q
 
I
0
Gx.m/
Gq.m/
T
D

P
P GT
x.m/
Gx.m/ P
Gx.m/ P GT
x.m/ C Gq.m/ Q GT
q.m/

:
(5.16)
The approximation above can be formulated as the following algorithm.

68
Extended and unscented Kalman ﬁltering
Algorithm 5.2 (Linear approximation of a non-additive transform)
The
linear approximation based Gaussian approximation to the joint distribu-
tion of x and the transformed random variable y D g.x; q/ when x 
N.m; P/ and q  N.0; Q/ is given as
x
y

 N
 m
L

;
 P
CL
CT
L
SL

;
(5.17)
where
L D g.m/;
SL D Gx.m/ P GT
x.m/ C Gq.m/ Q GT
q.m/;
CL D P GT
x.m/;
(5.18)
Gx.m/ is the Jacobian matrix of g with respect to x, evaluated at x D
m; q D 0, with elements
ŒGx.m/j;j 0 D @gj.x; q/
@xj 0
ˇˇˇˇˇ
xDm; qD0
;
(5.19)
and Gq.m/ is the corresponding Jacobian matrix with respect to q:

Gq.m/

j;j 0 D @gj.x; q/
@qj 0
ˇˇˇˇˇ
xDm; qD0
:
(5.20)
In quadratic approximations, in addition to the ﬁrst order terms, the sec-
ond order terms in the Taylor series expansion of the non-linear function
are also retained.
Algorithm 5.3 (Quadratic approximation of an additive non-linear trans-
form)
The second order approximation is of the form
x
y

 N
 m
Q

;
 P
CQ
CT
Q
SQ

;
(5.21)
where the parameters are
Q D g.m/ C 1
2
X
i
ei tr
n
G.i/
xx.m/ P
o
;
SQ D Gx.m/ P GT
x.m/ C 1
2
X
i;i0
ei eT
i0 tr
n
G.i/
xx.m/ P G.i0/
xx .m/ P
o
;
CQ D P GT
x.m/;
(5.22)

5.2 Extended Kalman ﬁlter
69
Gx.m/ is the Jacobian matrix (5.14), and G.i/
xx.m/ is the Hessian matrix
of gi./ evaluated at m:
h
G.i/
xx.m/
i
j;j 0 D @2gi.x/
@xj @xj 0
ˇˇˇˇˇ
xDm
;
(5.23)
where ei D .0    0 1 0    0/T is a vector with 1 at position i and other
elements zero, that is, it is the unit vector in the direction of the coordinate
axis i.
5.2 Extended Kalman ﬁlter
The extended Kalman ﬁlter (EKF) (see, e.g., Jazwinski, 1970; Maybeck,
1982b; Bar-Shalom et al., 2001; Grewal and Andrews, 2001) is an exten-
sion of the Kalman ﬁlter to non-linear ﬁltering problems. If the process and
measurement noises can be assumed to be additive, the EKF model can be
written as
xk D f.xk1/ C qk1;
yk D h.xk/ C rk;
(5.24)
where xk 2 Rn is the state, yk 2 Rm is the measurement, qk1 
N.0; Qk1/ is the Gaussian process noise, rk  N.0; Rk/ is the Gaussian
measurement noise, f./ is the dynamic model function, and h./ is the
measurement model function. The functions f and h can also depend on
the step number k, but for notational convenience, this dependence has not
been explicitly denoted.
The idea of the extended Kalman ﬁlter is to use (or assume) Gaussian
approximations
p.xk j y1Wk/ ' N.xk j mk; Pk/
(5.25)
to the ﬁltering densities. In the EKF, these approximations are formed by
utilizing Taylor series approximations to the non-linearities and the result
is the following algorithm.
Algorithm 5.4 (Extended Kalman ﬁlter I)
The prediction and update
steps of the ﬁrst order additive noise extended Kalman ﬁlter (EKF) are:
 Prediction:
m
k D f.mk1/;
P 
k D Fx.mk1/ Pk1 F T
x.mk1/ C Qk1;
(5.26)

70
Extended and unscented Kalman ﬁltering
 Update:
vk D yk  h.m
k /;
Sk D Hx.m
k / P 
k HT
x.m
k / C Rk;
Kk D P 
k HT
x.m
k / S1
k ;
mk D m
k C Kk vk;
Pk D P 
k  Kk Sk KT
k:
(5.27)
Derivation
These ﬁltering equations can be derived by repeating the
same steps as in the derivation of the Kalman ﬁlter in Section 4.3 and by
applying Taylor series approximations on the appropriate steps.
1 The joint distribution of xk and xk1 is non-Gaussian, but we can form
a Gaussian approximation to it by applying the approximation Algo-
rithm 5.1 to the function
f.xk1/ C qk1;
(5.28)
which results in the Gaussian approximation
p.xk1; xk; j y1Wk1/ ' N
xk1
xk
 ˇˇˇ m0; P 0

;
(5.29)
where
m0 D
 mk1
f.mk1/

;
P 0 D
 Pk1
Pk1 F T
x
Fx Pk1
Fx Pk1 F T
x C Qk1

;
(5.30)
and the Jacobian matrix Fx of f.x/ is evaluated at x D mk1. The
approximations of the marginal mean and covariance of xk are thus
m
k D f.mk1/;
P 
k D Fx Pk1 F T
x C Qk1:
(5.31)
2 The joint distribution of yk and xk is also non-Gaussian, but we can
again approximate it by applying Algorithm 5.1 to the function
h.xk/ C rk:
(5.32)
We get the approximation
p.xk; yk j y1Wk1/ ' N
xk
yk
 ˇˇˇ m00; P 00

;
(5.33)

5.2 Extended Kalman ﬁlter
71
where
m00 D
 m
k
h.m
k /

;
P 00 D
 P 
k
P 
k HT
x
Hx P 
k
Hx P 
k HT
x C Rk

;
(5.34)
and the Jacobian matrix Hx of h.x/ is evaluated at x D m
k .
3 By Lemma A.2 the conditional distribution of xk is approximately
p.xk j yk; y1Wk1/ ' N.xk j mk; Pk/;
(5.35)
where
mk D m
k C P 
k HT
x .Hx P 
k HT
x C Rk/1 Œyk  h.m
k /;
Pk D P 
k  P 
k HT
x .Hx P 
k HT
x C Rk/1 Hx P 
k :
(5.36)
A more general non-additive noise EKF ﬁltering model can be written
as
xk D f.xk1; qk1/;
yk D h.xk; rk/;
(5.37)
where qk1  N.0; Qk1/ and rk  N.0; Rk/ are the Gaussian process
and measurement noises, respectively. Again, the functions f and h can
also depend on the step number k. The EKF algorithm for the above model
is the following.
Algorithm 5.5 (Extended Kalman ﬁlter II)
The prediction and update
steps of the (ﬁrst order) extended Kalman ﬁlter (EKF) in the non-additive
noise case are:
 Prediction:
m
k D f.mk1; 0/;
P 
k D Fx.mk1/ Pk1 F T
x.mk1/ C Fq.mk1/ Qk1 F T
q.mk1/;
(5.38)
 Update:
vk D yk  h.m
k ; 0/;
Sk D Hx.m
k / P 
k HT
x.m
k / C Hr.m
k / Rk HT
r.m
k /;
Kk D P 
k HT
x.m
k / S1
k ;
mk D m
k C Kk vk;
Pk D P 
k  Kk Sk KT
k;
(5.39)

72
Extended and unscented Kalman ﬁltering
where the matrices Fx.m/, Fq.m/, Hx.m/, and Hr.m/ are the Jacobian
matrices of f and h with respect to state and noise, with elements
ŒFx.m/j;j 0 D @fj.x; q/
@xj 0
ˇˇˇˇˇ
xDm; qD0
;
(5.40)

Fq.m/

j;j 0 D @fj.x; q/
@qj 0
ˇˇˇˇˇ
xDm; qD0
;
(5.41)
ŒHx.m/j;j 0 D @hj.x; r/
@xj 0
ˇˇˇˇˇ
xDm; rD0
;
(5.42)
ŒHr.m/j;j 0 D @hj.x; r/
@rj 0
ˇˇˇˇˇ
xDm; rD0
:
(5.43)
Derivation
These ﬁltering equations can be derived by repeating the
same steps as in the derivation of the extended Kalman ﬁlter above, but
instead of using Algorithm 5.1, we use Algorithm 5.2 for computing the
approximations.
The advantage of the EKF over other non-linear ﬁltering methods is its
relative simplicity compared to its performance. Linearization is a very
common engineering way of constructing approximations to non-linear
systems and thus it is very easy to understand and apply. A disadvan-
tage is that because it is based on a local linear approximation, it will not
work in problems with considerable non-linearities. The ﬁltering model is
also restricted in the sense that only Gaussian noise processes are allowed
and thus the model cannot contain, for example, discrete valued random
variables. The Gaussian restriction also prevents the handling of hierarchi-
cal models or other models where signiﬁcantly non-Gaussian distribution
models would be needed.
The EKF also requires the measurement model and the dynamic
model functions to be differentiable, which is a restriction. In some cases
it might also be simply impossible to compute the required Jacobian
matrices, which renders the use of the EKF impossible. Even when the
Jacobian matrices exist and could be computed, the actual computation
and programming of Jacobian matrices can be quite error prone and hard
to debug.
In the so-called second order EKF the non-linearity is approximated
by retaining the second order terms in the Taylor series expansion as in
Algorithm 5.3. The resulting algorithm is the following.

5.2 Extended Kalman ﬁlter
73
Algorithm 5.6 (Extended Kalman ﬁlter III)
The prediction and update
steps of the second order extended Kalman ﬁlter (in the additive noise case)
are:
 Prediction:
m
k D f.mk1/ C 1
2
X
i
ei tr
n
F.i/
xx.mk1/ Pk1
o
;
P 
k D Fx.mk1/ Pk1 F T
x.mk1/
C 1
2
X
i;i0
ei eT
i0 tr
n
F.i/
xx.mk1/Pk1F .i0/
xx .mk1/Pk1
o
C Qk1;
(5.44)
 Update:
vk D yk  h.m
k /  1
2
X
i
ei tr
n
H.i/
xx.m
k / P 
k
o
;
Sk D Hx.m
k / P 
k HT
x.m
k /
C 1
2
X
i;i0
ei eT
i0 tr
n
H.i/
xx.m
k / P 
k H.i0/
xx .m
k / P 
k
o
C Rk;
Kk D P 
k HT
x.m
k / S1
k ;
mk D m
k C Kk vk;
Pk D P 
k  Kk Sk KT
k;
(5.45)
where the matrices Fx.m/ and Hx.m/ are given by Equations (5.40) and
(5.42). The matrices F.i/
xx.m/ and H.i/
xx.m/ are the Hessian matrices of fi
and hi respectively:
h
F.i/
xx.m/
i
j;j 0 D @2fi.x/
@xj @xj 0
ˇˇˇˇˇ
xDm
;
(5.46)
h
H.i/
xx.m/
i
j;j 0 D @2hi.x/
@xj @xj 0
ˇˇˇˇˇ
xDm
:
(5.47)
The non-additive version can be derived in an analogous manner, but
due to its complicated appearance, it is not presented here.

74
Extended and unscented Kalman ﬁltering
0.5
1
1.5
2
2.5
3
3.5
4
4.5
−3
−2
−1
0
1
2
3
4
5
Time t
Pendulum angle x1,k
 
 
True Angle
Measurements
EKF Estimate
Figure 5.1 Simulated pendulum data and the result of tracking
the pendulum angle and angular rate with the EKF in Example
5.1. The resulting RMSE was 0:12.
Example 5.1 (Pendulum tracking with EKF)
A simple discretization of
the pendulum model in Example 3.7 leads to the following model:
x1;k
x2;k

„ ƒ‚ …
xk
D

x1;k1 C x2;k1 t
x2;k1  g sin.x1;k1/ t

„
ƒ‚
…
f.xk1/
Cqk1;
yk D sin.x1;k/
„ ƒ‚ …
h.xk/
Crk;
(5.48)
where qk1  N.0; Q/ and rk  N.0; R/ with
Q D
 
qc t3
3
qc t2
2
qc t2
2
qc t
!
;
(5.49)
and qc is the spectral density of the continuous-time process noise. The
required Jacobian matrices of f.x/ and h.x/ for the ﬁrst order EKF are:
Fx.x/ D

1
t
g cos.x1/ t
1

;
Hx.x/ D

cos.x1/
0
	
: (5.50)
An example result of applying the EKF to simulated data from the pendu-
lum model is shown in Figure 5.1. The EKF is indeed able to track the pen-
dulum angle quite well despite the non-linearity of the model. The RMSE

5.3 Statistical linearization
75
in the angle is 0:12 which is much lower than the standard deviation of the
measurement noise which was 0:32.
5.3 Statistical linearization
In the statistically linearized ﬁlter (Gelb, 1974) the ﬁrst order Taylor se-
ries approximation used in the ﬁrst order EKF is replaced by statistical
linearization. Recall the transformation problem considered in Section 5.1,
which was stated as
x  N.m; P/;
y D g.x/:
In statistical linearization we form a linear approximation to the transfor-
mation as follows:
g.x/ ' b C A ıx;
(5.51)
where ıx D x  m, such that the mean squared error is minimized:
MSE.b; A/ D EŒ.g.x/  b  A ıx/T.g.x/  b  A ıx/:
(5.52)
Setting the derivatives with respect to b and A to zero gives
b D EŒg.x/;
A D EŒg.x/ ıxT P 1:
(5.53)
In this approximation to the transform g.x/, b is now exactly the mean and
the approximate covariance is given as
EŒ.g.x/  EŒg.x// .g.x/  EŒg.x//T
' A P AT
D EŒg.x/ ıxT P 1 EŒg.x/ ıxTT:
(5.54)
We may now apply this approximation to the augmented function Qg.x/ D
.x; g.x// in Equation (5.9) of Section 5.1, where we get the approxima-
tions
EŒQg.x/ '

m
EŒg.x/

;
CovŒQg.x/ '

P
EŒg.x/ ıxTT
EŒg.x/ ıxT
EŒg.x/ ıxT P 1 EŒg.x/ ıxTT

:
(5.55)
Thus we get the following algorithm.

76
Extended and unscented Kalman ﬁltering
Algorithm 5.7 (Statistically linearized approximation of an additive trans-
form)
The statistical linearization based Gaussian approximation to the
joint distribution of x and the transformed random variable y D g.x/Cq,
where x  N.m; P/ and q  N.0; Q/, is given as
x
y

 N
m
S

;
 P
CS
CT
S
SS

;
(5.56)
where
S D EŒg.x/;
SS D EŒg.x/ ıxT P 1 EŒg.x/ ıxTT C Q;
CS D EŒg.x/ ıxTT:
(5.57)
The expectations are taken with respect to the distribution of x.
Applying the same approximation with .x; q/ in place of x we obtain
the following mean and covariance for the non-additive transform:
EŒQg.x; q/ '

m
EŒg.x; q/

;
CovŒQg.x; q/ '
0
@
P
EŒg.x; q/ ıxTT
EŒg.x; q/ ıxT
EŒg.x; q/ ıxT P 1 EŒg.x; q/ ıxTT
C EŒg.x; q/ qT Q1 EŒg.x; q/ qTT
1
A :
(5.58)
Thus we get the following algorithm for the non-additive transform.
Algorithm 5.8 (Statistically linearized approximation of a non-additive
transform)
The statistical linearization based Gaussian approximation
to the joint distribution of x and the transformed random variable y D
g.x; q/ when x  N.m; P/ and q  N.0; Q/ is given as
x
y

 N
m
S

;
 P
CS
CT
S
SS

;
(5.59)
where
S D EŒg.x; q/;
SS D EŒg.x; q/ ıxT P 1 EŒg.x; q/ ıxTT
C EŒg.x; q/ qT Q1 EŒg.x; q/ qTT;
CS D EŒg.x; q/ ıxTT:
(5.60)
The expectations are taken with respect to the variables x and q.

5.4 Statistically linearized ﬁlter
77
If the function g.x/ is differentiable, it is possible to use the follow-
ing well-known property of Gaussian random variables for simplifying the
expressions:
EŒg.x/ .x  m/T D EŒGx.x/ P;
(5.61)
where EŒ denotes the expected value with respect to x  N.m; P/, and
Gx.x/ is the Jacobian matrix of g.x/. The statistical linearization equa-
tions then reduce to the same form as Taylor series based linearization,
except that instead of the Jacobians we have the expected values of the
Jacobians (see the exercises). Algorithm 5.7 can be then written in the fol-
lowing form.
Algorithm 5.9 (Statistically linearized approximation of an additive
transform II)
The statistical linearization based Gaussian approximation
to the joint distribution of x and the transformed random variable
y D g.x/ C q, where x  N.m; P/ and q  N.0; Q/, can be written as
x
y

 N
m
S

;
 P
CS
CT
S
SS

;
(5.62)
where
S D EŒg.x/;
SS D EŒGx.x/ P EŒGx.x/T C Q;
CS D P EŒGx.x/T;
(5.63)
and Gx.x/ is the Jacobian matrix of g. The expectations are taken with
respect to the distribution of x.
Note that we actually only need to compute the expectation EŒg.x/,
because if we know the function
S.m/ D EŒg.x/;
(5.64)
where EŒ denotes the expected value with respect to N.x j m; P/, then
@S.m/
@m
D EŒGx.x/:
(5.65)
5.4 Statistically linearized ﬁlter
The statistically linearized ﬁlter (SLF) (Gelb, 1974) or quasi-linear ﬁlter
(Stengel, 1994) is a Gaussian approximation based ﬁlter which can be ap-
plied to the same kind of models as the EKF, that is, to models of the form

78
Extended and unscented Kalman ﬁltering
(5.24) or (5.37). The ﬁlter is similar to the EKF, except that statistical lin-
earizations in Algorithms 5.7, 5.8, and 5.9 are used instead of the Taylor
series approximations.
Algorithm 5.10 (Statistically linearized ﬁlter I)
The prediction and up-
date steps of the additive noise statistically linearized (Kalman) ﬁlter are:
 Prediction:
m
k D EŒf.xk1/;
P 
k D EŒf.xk1/ ıxT
k1 P 1
k1 EŒf.xk1/ ıxT
k1T C Qk1;
(5.66)
where ıxk1 D xk1mk1 and the expectations are taken with respect
to the variable xk1  N.mk1; Pk1/,
 Update:
vk D yk  EŒh.xk/;
Sk D EŒh.xk/ ı QxT
k .P 
k /1 EŒh.xk/ ı QxT
kT C Rk;
Kk D EŒh.xk/ ı QxT
kT S1
k ;
mk D m
k C Kk vk;
Pk D P 
k  Kk Sk KT
k;
(5.67)
where ı Qxk D xk  m
k and the expectations are taken with respect to
the variable xk  N.m
k ; P 
k /.
The above ﬁlter can also be rewritten using the expectations of Jacobians
by using Algorithm 5.9 instead of 5.7 (see the exercises).
Algorithm 5.11 (Statistically linearized ﬁlter II)
The prediction and up-
date steps of the non-additive statistically linearized (Kalman) ﬁlter are:
 Prediction:
m
k D EŒf.xk1; qk1/;
P 
k D EŒf.xk1; qk1/ ıxT
k1 P 1
k1 EŒf.xk1; qk1/ ıxT
k1T
C EŒf.xk1; qk1/ qT
k1 Q1
k1 EŒf.xk1; qk1/ qT
k1T;
(5.68)
where ıxk1 D xk1mk1 and the expectations are taken with respect
to the variables xk1  N.mk1; Pk1/ and qk1  N.0; Qk1/,

5.4 Statistically linearized ﬁlter
79
0.5
1
1.5
2
2.5
3
3.5
4
4.5
−3
−2
−1
0
1
2
3
4
5
Time t
Pendulum angle x1,k
 
 
True Angle
Measurements
SLF Estimate
Figure 5.2 Simulated pendulum data and the result of tracking
the pendulum angle and angular rate with the SLF in Example
5.2. The resulting RMSE was 0:11 which is slightly lower than
the error of EKF (Figure 5.1), but still practically the same.
 Update:
vk D yk  EŒh.xk; rk/;
Sk D EŒh.xk; rk/ ı QxT
k .P 
k /1 EŒh.xk; rk/ ı QxT
kT
C EŒh.xk; rk/ rT
k R1
k
EŒh.xk; rk/ rT
kT;
Kk D EŒh.xk; rk/ ı QxT
kT S1
k ;
mk D m
k C Kk vk;
Pk D P 
k  Kk Sk KT
k;
(5.69)
where ı Qxk D xk  m
k and the expectations are taken with respect to
the variables xk  N.m
k ; P 
k / and rk  N.0; Rk/.
Both of the ﬁlters above can be derived by following the derivation of
the EKF in Section 5.2 and by utilizing the statistical linearization approx-
imations instead of the linear approximations on the appropriate steps.
Example 5.2 (Pendulum tracking with SLF)
The expectations of f and
h which are required for implementation of the additive noise SLF for the

80
Extended and unscented Kalman ﬁltering
pendulum model in Example 5.2 can be computed as follows:
EŒf.x/ D

m1 C m2 t
m2  g sin.m1/ exp.P11=2/ t

;
EŒh.x/ D sin.m1/ exp.P11=2/:
(5.70)
The required cross-correlation terms are
EŒf.x/ .x  m/T D
c11
c12
c21
c22

;
(5.71)
where
c11 D P11 C t P12;
c12 D P12 C t P22;
c21 D P12  g t cos.m1/ P11 exp.P11=2/;
c22 D P22  g t cos.m1/ P12 exp.P11=2/;
(5.72)
and
EŒh.x/ .x  m/T D
cos.m1/ P11 exp.P11=2/
cos.m1/ P12 exp.P11=2/

:
(5.73)
The above computations reveal the main weakness of statistical lineariza-
tion based ﬁltering – there is no hope of computing the above expectations
when the functions are complicated. In this case we were lucky, because
the only non-linearities in the dynamic and measurement models were si-
nusoidal, for which the closed form expectations can be computed.
The result of applying the SLF to the same simulated pendulum data as
was used with the EKF in Figure 5.1 is shown in Figure 5.2. The result of
the SLF is practically the same as that of the EKF. However, the RMSE of
the SLF is slightly lower than that of the EKF.
The advantage of the SLF over the EKF is that it is a more global ap-
proximation than the EKF, because the linearization is not only based on
the local region around the mean but on a whole range of function val-
ues. The non-linearities also do not have to be differentiable. However, if
the non-linearities are differentiable, then we can use the Gaussian random
variable property (5.61) for rewriting the equations in an EKF-like form.
The clear disadvantage of the SLF over the EKF is that the expected values
of the non-linear functions have to be computed in closed form. Naturally,
it is not possible for all functions. Fortunately, the expected values involved
are of such a type that one is likely to ﬁnd many of them tabulated in older

5.5 Unscented transform
81
physics and control engineering books (see, e.g., Gelb and Vander Velde,
1968).
The statistically linearized ﬁlter (SLF) is a special case of the Fourier–
Hermite Kalman ﬁlter (FHKF), when the ﬁrst order truncation of the series
is used (Sarmavuori and S¨arkk¨a, 2012a). Many of the sigma-point methods
can also be interpreted as approximations to the Fourier–Hermite Kalman
ﬁlters and statistically linearized ﬁlters (see Van der Merwe and Wan, 2003;
S¨arkk¨a and Hartikainen, 2010b; Sarmavuori and S¨arkk¨a, 2012a).
5.5 Unscented transform
The unscented transform (UT) (Julier and Uhlmann, 1995; Julier et al.,
2000) is a relatively recent numerical method that can also be used for
approximating the joint distribution of random variables x and y deﬁned
as
x  N.m; P/;
y D g.x/:
However, the philosophy of the UT differs from linearization and statistical
linearization in the sense that it tries to directly approximate the mean and
covariance of the target distribution instead of trying to approximate the
non-linear function (Julier and Uhlmann, 1995).
The idea of the UT is to deterministically choose a ﬁxed number of
sigma points that capture the mean and covariance of the original distri-
bution of x exactly. These sigma points are then propagated through the
non-linearity, and the mean and covariance of the transformed variable are
estimated from them. Note that although the unscented transform resem-
bles Monte Carlo estimation, the approaches are signiﬁcantly different, be-
cause in the UT the sigma points are selected deterministically (Julier and
Uhlmann, 2004). The difference between linear approximation and the UT
is illustrated in Figures 5.3, 5.4, and 5.5.
The unscented transform forms the Gaussian approximation2 with the
following procedure.
2 Note that this Gaussianity assumption is one interpretation, but the unscented transform
can also be applied without the Gaussian assumption. However, because the assumption
makes Bayesian interpretation of the UT much easier, we shall use it here.

82
Extended and unscented Kalman ﬁltering
−5
0
5
−4
−2
0
2
4
(a) Original
0
2
4
−2
−1
0
1
2
(b) Transformed
Figure 5.3 Example of applying a non-linear transformation to a
random variable on the left, which results in the random variable
on the right.
−5
0
5
−4
−2
0
2
4
(a) Original
0
2
4
−2
−1
0
1
2
(b) Transformed
Figure 5.4 Illustration of the linearization based (EKF)
approximation to the transformation in Figure 5.3. The Gaussian
approximation is formed by calculating the curvature at the mean,
which results in a bad approximation further away from the mean.
The covariance of the true distribution is presented by the dashed
line and the solid line is the approximation.
1 Form a set of 2n C 1 sigma points as follows:
X .0/ D m;
X .i/ D m C
p
n C 
hp
P
i
i ;
X .iCn/ D m 
p
n C 
hp
P
i
i ;
i D 1; : : : ; n;
(5.74)

5.5 Unscented transform
83
−5
0
5
−4
−2
0
2
4
(a) Original
0
2
4
−2
−1
0
1
2
(b) Transformed
Figure 5.5 Illustration of the unscented transform based (UKF)
approximation to the transformation in Figure 5.3. The Gaussian
approximation is formed by propagating the sigma points through
the non-linearity and the mean and covariance are estimated from
the transformed sigma points. The covariance of the true
distribution is presented by the dashed line and the solid line is
the approximation.
where Œi denotes the ith column of the matrix, and  is a scaling pa-
rameter, which is deﬁned in terms of algorithm parameters ˛ and  as
follows:
 D ˛2 .n C /  n:
(5.75)
The parameters ˛ and  determine the spread of the sigma points around
the mean (Wan and Van der Merwe, 2001). The matrix square root de-
notes a matrix such that
p
P
p
P
T D P.
2 Propagate the sigma points through the non-linear function g./:
Y.i/ D g.X .i//;
i D 0; : : : ; 2n;
which results in the transformed sigma points Y.i/.
3 Estimates of the mean and covariance of the transformed variable can be
computed from the sigma points as follows:
EŒg.x/ ' U D
2n
X
iD0
W .m/
i
Y.i/;
CovŒg.x/ ' SU D
2n
X
iD0
W .c/
i
.Y.i/  U/ .Y.i/  U/T;
(5.76)

84
Extended and unscented Kalman ﬁltering
where the constant weights W .m/
i
and W .c/
i
are given as follows (Wan
and Van der Merwe, 2001):
W .m/
0
D

n C ;
W .c/
0
D

n C  C .1  ˛2 C ˇ/;
W .m/
i
D
1
2.n C /;
i D 1; : : : ; 2n;
W .c/
i
D
1
2.n C /;
i D 1; : : : ; 2n;
(5.77)
and ˇ is an additional algorithm parameter that can be used for incor-
porating prior information on the (non-Gaussian) distribution of x (Wan
and Van der Merwe, 2001).
If we apply the unscented transform to the augmented function Qg.x/ D
.x; g.x//, we simply get a set of sigma points, where the sigma points X .i/
and Y.i/ have been concatenated to the same vector. Thus, also forming the
approximation to the joint distribution x and g.x/ C q is straightforward
and the result is the following algorithm.
Algorithm 5.12 (Unscented approximation of an additive transform)
The
unscented transform based Gaussian approximation to the joint distribu-
tion of x and the transformed random variable y D g.x/ C q, where
x  N.m; P/ and q  N.0; Q/, is given as
x
y

 N
 m
U

;
 P
CU
CT
U
SU

;
(5.78)
where the submatrices can be computed as follows.
1 Form the set of 2n C 1 sigma points as follows:
X .0/ D m;
X .i/ D m C
p
n C 
hp
P
i
i ;
X .iCn/ D m 
p
n C 
hp
P
i
i ;
i D 1; : : : ; n;
(5.79)
where the parameter  is deﬁned in Equation (5.75).
2 Propagate the sigma points through the non-linear function g./:
Y.i/ D g.X .i//;
i D 0; : : : ; 2n:

5.5 Unscented transform
85
3 The submatrices are then given as:
U D
2n
X
iD0
W .m/
i
Y.i/;
SU D
2n
X
iD0
W .c/
i
.Y.i/  U/ .Y.i/  U/T C Q;
CU D
2n
X
iD0
W .c/
i
.X .i/  m/ .Y.i/  U/T;
(5.80)
where the constant weights W .m/
i
and W .c/
i
were deﬁned in Equa-
tion (5.77).
The unscented transform approximation to a transformation of the form
y D g.x; q/ can be derived by considering the augmented random variable
Qx D .x; q/ as the random variable in the transform. The resulting algorithm
is the following.
Algorithm 5.13 (Unscented approximation of a non-additive transform)
The (augmented) unscented transform based Gaussian approximation
to the joint distribution of x and the transformed random variable
y D g.x; q/ when x  N.m; P/ and q  N.0; Q/ is given as
x
y

 N
 m
U

;
 P
CU
CT
U
SU

;
(5.81)
where the sub-matrices can be computed as follows. Let the dimensionali-
ties of x and q be n and nq, respectively, and let n0 D n C nq.
1 Form the sigma points for the augmented random variable Qx D .x; q/:
QX .0/ D Qm;
QX .i/ D Qm C
p
n0 C 0
hp
QP
i
i ;
QX .iCn0/ D Qm 
p
n0 C 0
hp
QP
i
i ;
i D 1; : : : ; n0;
(5.82)
where the parameter 0 is deﬁned as in Equation (5.75), but with n
replaced by n0, and the augmented mean and covariance are deﬁned
by
Qm D
m
0

;
QP D
P
0
0
Q

:

86
Extended and unscented Kalman ﬁltering
2 Propagate the sigma points through the function:
QY.i/ D g. QX .i/;x; QX .i/;q/;
i D 0; : : : ; 2n0;
where QX .i/;x and QX .i/;q denote the parts of the augmented sigma point
i which correspond to x and q, respectively.
3 Compute the predicted mean U, the predicted covariance SU, and the
cross-covariance CU:
U D
2n0
X
iD0
W .m/0
i
QY.i/;
SU D
2n0
X
iD0
W .c/0
i
. QY.i/  U/ . QY.i/  U/T;
CU D
2n0
X
iD0
W .c/0
i
. QX .i/;x  m/ . QY.i/  U/T;
where the deﬁnitions of the weights W .m/0
i
and W .c/0
i
are the same as in
Equation (5.77), but with n replaced by n0 and  replaced by 0.
The unscented transform is a third order method in the sense that the
estimate of the mean of g./ is exact for polynomials up to order three.
That is, if g./ is indeed a multi-variate polynomial of order three, the
mean is exact. However, the covariance approximation is exact only for
ﬁrst order polynomials, because the square of a second order polynomial is
already a polynomial of order four, and the unscented transform (UT) does
not compute the exact result for fourth order polynomials. In this sense
the UT is only a ﬁrst order method. With suitable selection of parameters
( D 3n) it is possible to get some of the fourth order terms appearing in
the covariance computation right also for quadratic functions, but not all.
5.6 Unscented Kalman ﬁlter
The unscented Kalman ﬁlter (UKF) (Julier et al., 1995; Julier and
Uhlmann, 2004; Wan and Van der Merwe, 2001) is an approximate
ﬁltering algorithm that utilizes the unscented transform and can be used
for approximating the ﬁltering distributions of models having the same
form as with the EKF and the SLF, that is, models of the form (5.24) or
(5.37). As the EKF and the SLF, the UKF forms a Gaussian approximation
to the ﬁltering distribution:
p.xk j y1Wk/ ' N.xk j mk; Pk/;
(5.83)

5.6 Unscented Kalman ﬁlter
87
where mk and Pk are the mean and covariance computed by the algorithm.
Algorithm 5.14 (Unscented Kalman ﬁlter I)
In the additive form of the
unscented Kalman ﬁlter (UKF) algorithm, which can be applied to additive
models of the form (5.24), the following operations are performed at each
measurement step k D 1; 2; 3; : : :
 Prediction:
1 Form the sigma points:
X .0/
k1 D mk1;
X .i/
k1 D mk1 C
p
n C 
hp
Pk1
i
i ;
X .iCn/
k1
D mk1 
p
n C 
hp
Pk1
i
i ;
i D 1; : : : ; n;
(5.84)
where the parameter  is deﬁned in Equation (5.75).
2 Propagate the sigma points through the dynamic model:
OX .i/
k
D f.X .i/
k1/;
i D 0; : : : ; 2n:
(5.85)
3 Compute the predicted mean m
k and the predicted covariance P 
k :
m
k D
2n
X
iD0
W .m/
i
OX .i/
k ;
P 
k D
2n
X
iD0
W .c/
i
. OX .i/
k
 m
k / . OX .i/
k
 m
k /T C Qk1;
(5.86)
where the weights W .m/
i
and W .c/
i
were deﬁned in Equation (5.77).
 Update:
1 Form the sigma points:
X .0/
k
D m
k ;
X .i/
k
D m
k C
p
n C 
hq
P 
k
i
i ;
X .iCn/
k
D m
k 
p
n C 
hq
P 
k
i
i ;
i D 1; : : : ; n:
(5.87)
2 Propagate sigma points through the measurement model:
OY.i/
k
D h.X .i/
k
/;
i D 0; : : : ; 2n:
(5.88)

88
Extended and unscented Kalman ﬁltering
3 Compute the predicted mean k, the predicted covariance of the mea-
surement Sk, and the cross-covariance of the state and the measure-
ment Ck:
k D
2n
X
iD0
W .m/
i
OY.i/
k ;
Sk D
2n
X
iD0
W .c/
i
. OY.i/
k  k/ . OY.i/
k  k/T C Rk;
Ck D
2n
X
iD0
W .c/
i
.X .i/
k
 m
k / . OY.i/
k  k/T:
(5.89)
4 Compute the ﬁlter gain Kk, the ﬁltered state mean mk and the covari-
ance Pk, conditional on the measurement yk:
Kk D Ck S1
k ;
mk D m
k C Kk Œyk  k ;
Pk D P 
k  Kk Sk KT
k:
(5.90)
The ﬁltering equations above can be derived in an analogous manner to
the EKF equations, but the unscented transform based approximations are
used instead of the linear approximations.
The non-additive form of the UKF (Julier and Uhlmann, 2004) can be
derived by augmenting the process and measurement noises to the state
vector and then using the UT approximation for performing prediction and
update steps simultaneously. Alternatively, we can ﬁrst augment the state
vector with process noise, then approximate the prediction step and after
that do the same with measurement noise on the update step. The different
algorithms and ways of doing this in practice are analyzed in the article
by Wu et al. (2005). However, if we directly apply the non-additive UT
in Algorithm 5.13 separately to prediction and update steps, we get the
following algorithm.
Algorithm 5.15 (Unscented Kalman ﬁlter II)
In the augmented form of
the unscented Kalman ﬁlter (UKF) algorithm, which can be applied to non-
additive models of the form (5.37), the following operations are performed
at each measurement step k D 1; 2; 3; : : :
 Prediction:

5.6 Unscented Kalman ﬁlter
89
1 Form the sigma points for the augmented random variable
.xk1; qk1/:
QX .0/
k1 D Qmk1;
QX .i/
k1 D Qmk1 C
p
n0 C 0
q
QPk1

i
;
QX .iCn0/
k1
D Qmk1 
p
n0 C 0
q
QPk1

i
;
i D 1; : : : ; n0; (5.91)
where
Qmk1 D
mk1
0

;
QPk1 D
Pk1
0
0
Qk1

:
Here n0 D n C nq, where n is the dimensionality of the state xk1
and nq is the dimensionality of the noise qk1. The parameter 0 is
deﬁned as in Equation (5.75), but with n replaced by n0.
2 Propagate the sigma points through the dynamic model:
OX .i/
k
D f. QX .i/;x
k1 ; QX .i/;q
k1 /;
i D 0; : : : ; 2n0;
(5.92)
where QX .i/;x
k1 denotes the ﬁrst n components in QX .i/
k1 and QX .i/;q
k1 de-
notes the last nq components.
3 Compute the predicted mean m
k and the predicted covariance P 
k :
m
k D
2n
X
iD0
W .m/0
i
OX .i/
k ;
P 
k D
2n
X
iD0
W .c/0
i
. OX .i/
k
 m
k / . OX .i/
k
 m
k /T;
(5.93)
where the weights W .m/0
i
and W .c/0
i
are the same as in Equation (5.77),
but with n replaced by n0 and  by 0.
 Update:
1 Form the sigma points for the augmented random variable .xk; rk/:
QX .0/
k
D Qm
k ;
QX .i/
k
D Qm
k C
p
n00 C 00
q
QP 
k

i
;
QX .iCn00/
k
D m
k 
p
n00 C 00
q
QP 
k

i
;
i D 1; : : : ; n00;
(5.94)

90
Extended and unscented Kalman ﬁltering
where
Qm
k D
m
k
0

;
QP 
k D
P 
k
0
0
Rk

:
Here we have deﬁned n00 D n C nr, where n is the dimensionality
of the state xk and nr is the dimensionality of the noise rk. The pa-
rameter 00 is deﬁned as in Equation (5.75), but with n replaced by
n00.
2 Propagate sigma points through the measurement model:
OY.i/
k
D h. QX .i/;x
k
; QX .i/;r
k
/;
i D 0; : : : ; 2n00;
(5.95)
where QX .i/;x
k
denotes the ﬁrst n components in QX .i/
k
and QX .i/;r
k
denotes the last nr components.
3 Compute the predicted mean k, the predicted covariance of the mea-
surement Sk, and the cross-covariance of the state and the measure-
ment Ck:
k D
2n00
X
iD0
W .m/00
i
OY.i/
k ;
Sk D
2n00
X
iD0
W .c/00
i1 . OY.i/
k  k/ . OY.i/
k  k/T;
Ck D
2n00
X
iD0
W .c/00
i
.X .i/;x
k
 m
k / . OY.i/
k  k/T;
(5.96)
where the weights W .m/00
i
and W .c/00
i
are the same as in Equa-
tion (5.77), but with n replaced by n00 and  by 00.
4 Compute the ﬁlter gain Kk and the ﬁltered state mean mk and covari-
ance Pk, conditional to the measurement yk:
Kk D Ck S1
k ;
mk D m
k C Kk Œyk  k ;
Pk D P 
k  Kk Sk KT
k:
(5.97)
The advantage of the UKF over the EKF is that the UKF is not based on
a linear approximation at a single point, but uses further points in approx-
imating the non-linearity. As discussed in Julier and Uhlmann (2004), the
unscented transform is able to capture the higher order moments caused by
the non-linear transform better than Taylor series based approximations.
However, as already pointed out in the previous section, although the mean

5.6 Unscented Kalman ﬁlter
91
0.5
1
1.5
2
2.5
3
3.5
4
4.5
−3
−2
−1
0
1
2
3
4
5
Time t
Pendulum angle x1,k
 
 
True Angle
Measurements
UKF Estimate
Figure 5.6 Simulated pendulum data and the result of tracking
the pendulum described in Example 5.1 with the UKF. The
resulting RMSE was 0:11 which is the same as with the SLF
(Figure 5.2).
estimate of the UKF is exact for polynomials up to order 3, the covariance
computation is only exact for polynomials up to the ﬁrst order (as, e.g., in
the SLF). In the UKF, the dynamic and model functions are also not re-
quired to be formally differentiable nor do their Jacobian matrices need to
be computed. The advantage of the UKF over the SLF is that in the UKF
there is no need to compute any expected values in closed form, only eval-
uations of the dynamic and measurement models are needed. However, the
accuracy of the UKF cannot be expected to be as good as that of the SLF,
because the SLF uses a larger area in the approximation, whereas the UKF
only selects a ﬁxed number of points in the area. The disadvantage over the
EKF is that the UKF often requires slightly more computational operations
than the EKF.
Example 5.3 (Pendulum tracking with UKF)
The result of applying the
UKF to the pendulum model and simulated data in Example 5.1 is shown
in Figure 5.6. Unlike in the EKF and the SLF, we do not need to derive
analytical derivatives or expectations for implementing the UKF. Still the
RMSE is the same as with the SLF.

92
Extended and unscented Kalman ﬁltering
The UKF can be interpreted as belonging to a wider class of ﬁlters called
sigma-point ﬁlters (Van der Merwe and Wan, 2003), which also includes
other types of ﬁlter such as the central differences Kalman ﬁlter (CDKF),
the Gauss–Hermite Kalman ﬁlter (GHKF) and a few others (Ito and Xiong,
2000; Wu et al., 2006; Nørgaard et al., 2000; Arasaratnam and Haykin,
2009). The classiﬁcation of sigma-point methods by Van der Merwe
and Wan (2003) is based on interpreting the methods as special cases of
statistical linear regression (Lefebvre et al., 2002). Statistical linearization
is closely related to sigma-point approximations, because they both are
related to statistical linear regression (Van der Merwe and Wan, 2003).
However, it is important to note that the statistical linear regression
(Lefebvre et al., 2002) which is the basis of the sigma-point framework
(Van der Merwe and Wan, 2003) is not exactly equivalent to statistical
linearization (Gelb, 1974). Statistical linear regression can be considered
as a discrete approximation to statistical linearization.
Although at ﬁrst glance the UKF seems to be quite different from the
EKF, they are indeed very closely related. In fact, Gustafsson and Hendeby
(2012) have shown that the mean of the UKF converges to the second order
EKF in a certain limit of parameter values. In the limit the UT approxima-
tion becomes equivalent to using central difference approximations to the
ﬁrst and second derivatives, hence the result.
Sandblom and Svensson (2012) have also recently proposed a marginal-
ized transform which forms (hierarchical Bayesian) Hermite series expan-
sion based approximations to transformations of Gaussian random vari-
ables by ﬁtting the series coefﬁcients via point-wise evaluations. The re-
sulting algorithm contains the UKF (or the UT) as a special case and hence
it also reveals the close connection between the Fourier–Hermite series
based ﬁlters (Sarmavuori and S¨arkk¨a, 2012a) and the UKF.
5.7 Exercises
5.1
Consider the following non-linear state space model:
xk D xk1  0:01 sin.xk1/ C qk1;
yk D 0:5 sin.2 xk/ C rk;
(5.98)
where qk1 has a variance of 0:012 and rk has a variance of 0:02. Derive
the required derivatives for an EKF and implement the EKF for the model.
Simulate trajectories from the model, compute the RMSE values, and plot
the result.

Exercises
93
5.2
For the above model, derive the required expected values for an SLF and
implement the SLF for the model. Hint: use the imaginary part of the inverse
Fourier transform of the Gaussian distribution. Compute the RMSE values,
plot the results, and compare the performance to the EKF above.
5.3
In this exercise your task is to derive the derivative form of the statistically
linearized ﬁlter (SLF).
(a) Prove using integration by parts the following identity for a Gaussian
random variable x, differentiable non-linear function g.x/, and its Jaco-
bian matrix Gx.x/ D @g.x/=@x:
EŒg.x/ .x  m/T D EŒGx.x/ P;
(5.99)
where EŒ denotes the expected value with respect to N.x j m; P/. Hint:
@
@xN.x j m; P/ D P 1.x  m/ N.x j m; P/.
(b) Prove the following. Let
.m/ D EŒg.x/;
(5.100)
where EŒ denotes the expected value with respect to N.x j m; P/. Then
@.m/
@m
D EŒGx.x/:
(5.101)
(c) Write down the additive form of the SLF equations in an alternative
form, where you have eliminated all the cross terms of the form
EŒf.xk1/ ıxT
k1 and EŒh.xk/ ıxT
kT, using the result in (a).
(d) How can you utilize the result (b) when using the alternative form of the
SLF? Check that you get the same equations for the SLF in the previous
exercise using this alternative form of the SLF.
5.4
Implement a UKF for the model in Exercise 5.1. Plot the results and compare
the RMSE values to the EKF and the SLF.
5.5
In this exercise we consider a classical bearings only target tracking problem
which frequently arises in the context of passive sensor tracking. In this
problem there is single target in the scene and two angular sensors are used
for tracking it. The scenario is illustrated in Figure 5.7.
The state of the target at time step k consist of the position .xk; yk/ and the
velocity . Pxk; Pyk/. The dynamics of the state vector xk D .xk yk Pxk Pyk/T
are modeled with the discretized Wiener velocity model:
0
BB@
xk
yk
Pxk
Pyk
1
CCA D
0
BB@
1
0
t
0
0
1
0
t
0
0
1
0
0
0
0
1
1
CCA
0
BB@
xk1
yk1
Pxk1
Pyk1
1
CCA C qk1;

94
Extended and unscented Kalman ﬁltering
Figure 5.7 In the bearings only target tracking problem the
sensors generate angle measurements of the target, and the
purpose is to determine the target trajectory.
where qk is a zero mean Gaussian process noise with covariance
Q D
0
BB@
qc
1 t3=3
0
qc
1 t2=2
0
0
qc
2 t3=3
0
qc
2 t2=2
qc
1 t2=2
0
qc
1 t
0
0
qc
2 t2=2
0
qc
2 t
1
CCA :
In this scenario the diffusion coefﬁcients are qc
1 D qc
2 D 0:1 and the sam-
pling period is t D 0:1. The measurement model for sensor i 2 f1; 2g is
the following:
	i
k D tan1
 
yk  si
y
xk  six
!
C rk;
(5.102)
where .si
x; si
y/ is the position of the sensor i and rk  N.0; 2/ is a Gaussian
measurement noise with a standard deviation of  D 0:05 radians. At each
sampling time, which occurs ten times per second (i.e., t D 0:1), both of
the two sensors produce a measurement.
In the ﬁle angle_ex.m there is a baseline solution, which computes esti-
mates of the position from the crossing of the measurements and estimates
the velocity to be always zero. Your task is to implement an EKF for the
problem and compare the results graphically and in the RMSE sense.
(a) Implement an EKF for the bearings only target tracking problem, which
uses the non-linear measurement model (5.102) as its measurement
model function (not the crossings). Hints:
 Use the MATLAB R
 function atan2 in the measurement model in-
stead of atan to directly get an answer in the range Œ; .

Exercises
95
 The two measurements at each measurement time can be processed
one at a time, that is, you can simply perform two scalar updates
instead of a single two-dimensional measurement update.
 Start by computing the Jacobian matrix of the measurement model
function with respect to the state components. Before implementing
the ﬁlter, check by ﬁnite differences that the Jacobian matrix is cor-
rect.
(b) Compute the RMSE values and plot ﬁgures of the estimates.
5.6
Implement a UKF for the bearings only target tracking problem in Exer-
cise 5.5. Compare the performance to the EKF.

6
General Gaussian ﬁltering
Quite soon after the unscented Kalman ﬁlter (UKF) was published, Ito and
Xiong (2000) pointed out that the UKF can be considered as a special
case of so-called Gaussian ﬁlters, where the non-linear ﬁltering problem is
solved using Gaussian assumed density approximations. The generalized
framework also enables the usage of various powerful Gaussian quadra-
ture and cubature integration methods (Wu et al., 2006; Arasaratnam and
Haykin, 2009). The series expansion based ﬁlters presented in the previ-
ous sections can be seen as approximations to the general Gaussian ﬁlter.
In this section we present the Gaussian ﬁltering framework and show how
the Gauss–Hermite Kalman ﬁlter (GHKF) and the cubature Kalman ﬁlter
(CKF) can be derived as its approximations. We also show how the UKF
can be seen as a generalization of the CKF.
6.1 Gaussian moment matching
One way to unify various Gaussian approximations to non-linear trans-
forms is to reduce them to approximate computation of Gaussian integrals
of the form
Z
g.x/ N.x j m; P/ dx:
If we can compute these, a straightforward way to form the Gaussian ap-
proximation for .x; y/ is to simply match the moments of the distributions,
which gives the following algorithm.
Algorithm 6.1 (Gaussian moment matching of an additive transform)
The moment matching based Gaussian approximation to the joint distri-
bution of x and the transformed random variable y D g.x/ C q, where
x  N.m; P/ and q  N.0; Q/, is given by
x
y

 N
 m
M

;
 P
CM
CT
M
SM

;
(6.1)
96

6.2 Gaussian ﬁlter
97
where
M D
Z
g.x/ N.x j m; P/ dx;
SM D
Z
.g.x/  M/ .g.x/  M/T N.x j m; P/ dx C Q;
CM D
Z
.x  m/ .g.x/  M/T N.x j m; P/ dx:
(6.2)
It is now easy to check by substituting the linear approximation g.x/ D
g.m/ C Gx.m/ .x  m/ into the above expression that the integrals re-
duce to the linear approximations in Algorithm 5.1. The analogous thing
happens with quadratic approximations and statistical linearization. The
unscented transform can also be seen as a special case of the above algo-
rithm, as we will see in the following sections.
The non-additive version of the transform is the following.
Algorithm 6.2 (Gaussian moment matching of a non-additive transform)
The moment matching based Gaussian approximation to the joint distri-
bution of x and the transformed random variable y D g.x; q/, where
x  N.m; P/ and q  N.0; Q/, is given by
x
y

 N
 m
M

;
 P
CM
CT
M
SM

;
(6.3)
where
M D
Z
g.x; q/ N.x j m; P/ N.q j 0; Q/ dx dq;
SM D
Z
.g.x; q/  M/ .g.x; q/  M/T
 N.x j m; P/ N.q j 0; Q/ dx dq;
CM D
Z
.x  m/ .g.x; q/  M/T N.x j m; P/ N.q j 0; Q/ dx dq:
(6.4)
6.2 Gaussian ﬁlter
If we use the moment matching approximations for constructing a ﬁlter-
ing algorithm, we get the following Gaussian assumed density ﬁlter (ADF)
which is also called the Gaussian ﬁlter (Maybeck, 1982b; Ito and Xiong,

98
General Gaussian ﬁltering
2000; Wu et al., 2006). The key idea is to assume that the ﬁltering distribu-
tion is indeed Gaussian,
p.xk j y1Wk/ ' N.xk j mk; Pk/;
(6.5)
and approximate its mean mk and covariance Pk via moment matching.
Algorithm 6.3 (Gaussian ﬁlter I)
The prediction and update steps of the
additive noise Gaussian (Kalman) ﬁlter are:
 Prediction:
m
k D
Z
f.xk1/ N.xk1 j mk1; Pk1/ dxk1;
P 
k D
Z
.f.xk1/  m
k / .f.xk1/  m
k /T
 N.xk1 j mk1; Pk1/ dxk1 C Qk1:
(6.6)
 Update:
k D
Z
h.xk/ N.xk j m
k ; P 
k / dxk;
Sk D
Z
.h.xk/  k/ .h.xk/  k/T N.xk j m
k ; P 
k / dxk C Rk;
Ck D
Z
.xk  m
k / .h.xk/  k/T N.xk j m
k ; P 
k / dxk;
Kk D Ck S1
k ;
mk D m
k C Kk .yk  k/;
Pk D P 
k  Kk Sk KT
k:
(6.7)
The advantage of the moment matching formulation is that it enables the
use of many well-known numerical integration methods such as Gauss–
Hermite quadratures and cubature rules (Ito and Xiong, 2000; Wu et al.,
2006; Arasaratnam and Haykin, 2009). It is also possible to use other
methods such as the Bayes–Hermite quadrature (O’Hagan, 1991) or Monte
Carlo integration for approximating the integrals.
The Gaussian ﬁlter can be extended to non-additive noise models as
follows.
Algorithm 6.4 (Gaussian ﬁlter II)
The prediction and update steps of the
non-additive noise Gaussian (Kalman) ﬁlter are:

6.3 Gauss–Hermite integration
99
 Prediction:
m
k D
Z
f.xk1; qk1/
 N.xk1 j mk1; Pk1/ N.qk1 j 0; Qk1/ dxk1 dqk1;
P 
k D
Z
.f.xk1; qk1/  m
k / .f.xk1; qk1/  m
k /T
 N.xk1 j mk1; Pk1/ N.qk1 j 0; Qk1/ dxk1 dqk1:
(6.8)
 Update:
k D
Z
h.xk; rk/
 N.xk j m
k ; P 
k / N.rk j 0; Rk/ dxk drk;
Sk D
Z
.h.xk; rk/  k/ .h.xk; rk/  k/T
 N.xk j m
k ; P 
k / N.rk j 0; Rk/ dxk drk;
Ck D
Z
.xk  m
k / .h.xk; rk/  k/T
 N.xk j m
k ; P 
k / N.rk j 0; Rk/ dxk drk;
Kk D Ck S1
k ;
mk D m
k C Kk .yk  k/;
Pk D P 
k  Kk Sk KT
k:
(6.9)
The above general Gaussian ﬁlters are theoretical constructions rather
than practical ﬁltering algorithms. However, there exist many models for
which the required integrals can indeed be computed in closed form. But
a more practical approach is to compute them numerically. This kind of
method will be discussed in the next sections.
6.3 Gauss–Hermite integration
In the Gaussian ﬁlter (and later in the smoother) we are interested in ap-
proximating Gaussian integrals of the form
Z
g.x/ N.x j m; P/ dx
D
1
.2 /n=2 jPj1=2
Z
g.x/ exp

1
2.x  m/T P 1 .x  m/

dx;
(6.10)

100
General Gaussian ﬁltering
where g.x/ is an arbitrary function. In this section, we shall derive a
Gauss–Hermite based numerical cubature1 algorithm for computing such
integrals. The algorithm is based on direct generalization of the one-
dimensional Gauss–Hermite rule into multiple dimensions by taking the
Cartesian product of one-dimensional quadratures. The disadvantage of
the method is that the required number of evaluation points is exponential
with respect to the number of dimensions.
In its basic form, one-dimensional Gauss–Hermite quadrature integra-
tion refers to the special case of Gaussian quadratures with unit Gaussian
weight function w.x/ D N.x j 0; 1/, that is, to approximations of the form
Z 1
1
g.x/ N.x j 0; 1/ dx 
X
i
Wi g.x.i//;
(6.11)
where Wi; i D 1; : : : ; p are the weights and x.i/ are the evaluation points
or abscissas – also sometimes called sigma points. Note that the quadrature
is sometimes deﬁned in terms of the weight function exp.x2/, but here
we shall use the “probabilists’ deﬁnition” above. The two versions of the
quadrature are related by simple scaling of variables.
Obviously, there are an inﬁnite number of possible ways to select the
weights and evaluation points. In Gauss–Hermite integration, as in all
Gaussian quadratures, the weights and sigma points are chosen such that
with a polynomial integrand the approximation becomes exact. It turns
out that the polynomial order with a given number of points is maximized
if we choose the sigma points to be roots of Hermite polynomials. When
using the pth order Hermite polynomial Hp.x/, the rule will be exact for
polynomials up to order 2p  1. The required weights can be computed in
closed form (see below).
The Hermite polynomial of order p is deﬁned as (these are the so-called
“probabilists’ Hermite polynomials”):
Hp.x/ D .1/p exp.x2=2/ dp
dxp exp.x2=2/:
(6.12)
1 As one-dimensional integrals are quadratures, multi-dimensional integrals have been
traditionally called cubatures.

6.3 Gauss–Hermite integration
101
The ﬁrst few Hermite polynomials are:
H0.x/ D 1;
H1.x/ D x;
H2.x/ D x2  1;
H3.x/ D x3  3x;
H4.x/ D x4  6 x2 C 3;
(6.13)
and further polynomials can be found from the recursion
HpC1.x/ D x Hp.x/  p Hp1.x/:
(6.14)
Using the same weights and sigma points, integrals over non-unit Gaussian
weights functions N.x j m; P / can be evaluated using a simple change of
integration variable:
Z 1
1
g.x/ N.x j m; P / dx D
Z 1
1
g.P 1=2  C m/ N. j 0; 1/ d: (6.15)
Gauss–Hermite integration can be written as the following algorithm.
Algorithm 6.5 (Gauss–Hermite quadrature)
The pth order Gauss–
Hermite approximation to the one-dimensional integral
Z 1
1
g.x/ N.x j m; P / dx
(6.16)
can be computed as follows:
1 Compute the unit sigma points as the roots .i/; i D 1; : : : ; p of the Her-
mite polynomial Hp.x/. Note that we do not need to form the polynomial
and then compute its roots, but instead it is numerically more stable to
compute the roots as eigenvalues of a suitable tridiagonal matrix (Golub
and Welsch, 1969).
2 Compute the weights as
Wi D
pŠ
p2 ŒHp1..i//2 :
(6.17)
3 Approximate the integral as
Z 1
1
g.x/ N.x j m; P / dx 
p
X
iD1
Wi g.P 1=2 .i/ C m/:
(6.18)

102
General Gaussian ﬁltering
By generalizing the change of variables idea, we can form approxi-
mations to multi-dimensional integrals of the form (6.10). First let P D
p
P
p
P
T, where
p
P is the Cholesky factor of the covariance matrix P or
some other similar square root of the covariance matrix. If we deﬁne new
integration variables  by
x D m C
p
P ;
(6.19)
we get
Z
g.x/ N.x j m; P/ dx D
Z
g.m C
p
P / N. j 0; I/ d:
(6.20)
The integration over the multi-dimensional unit Gaussian distribution can
be written as an iterated integral over one-dimensional Gaussian distribu-
tions, and each of the one-dimensional integrals can be approximated with
Gauss–Hermite quadrature:
Z
g.m C
p
P / N. j 0; I/ d
D
Z
  
Z
g.m C
p
P / N.1 j 0; 1/ d1      N.n j 0; 1/ dn

X
i1;:::;in
Wi1      Wing.m C
p
P .i1;:::;in//:
(6.21)
The weights Wik; k
D
1; : : : ; n are simply the corresponding one-
dimensional Gauss–Hermite weights and .i1;:::;in/ is an n-dimensional
vector with one-dimensional unit sigma point .ik/ at element k. The
algorithm can now be written as follows.
Algorithm 6.6 (Gauss–Hermite cubature)
The pth order Gauss–Hermite
approximation to the multi-dimensional integral
Z
g.x/ N.x j m; P/ dx
(6.22)
can be computed as follows.
1 Compute the one-dimensional weights Wi; i D 1; : : : ; p and unit sigma
points .i/ as in the one-dimensional Gauss–Hermite quadrature Algo-
rithm 6.5.

6.4 Gauss–Hermite Kalman ﬁlter
103
2 Form multi-dimensional weights as the products of one-dimensional
weights:
Wi1;:::;in D Wi1      Win
D
pŠ
p2 ŒHp1..i1//2     
pŠ
p2 ŒHp1..in//2 ;
(6.23)
where each ik takes values 1; : : : ; p.
3 Form multi-dimensional unit sigma points as Cartesian product of the
one-dimensional unit sigma points:
.i1;:::;in/ D
0
B@
.i1/
:::
.in/
1
CA :
(6.24)
4 Approximate the integral as
Z
g.x/ N.x j m; P/ dx 
X
i1;:::;in
Wi1;:::;ing.m C
p
P .i1;:::;in//;
(6.25)
where
p
P is a matrix square root deﬁned by P D
p
P
p
P
T.
The pth order multi-dimensional Gauss–Hermite integration is exact for
monomials of the form xd1
1 xd2
2    xdn
n , and their arbitrary linear combina-
tions, where each of the orders di 	 2p  1. The number of sigma points
required for an n-dimensional integral with pth order rule is pn, which
quickly becomes unfeasible when the number of dimensions grows.
The Gaussian–Hermite cubature can also be seen as a sigma-point
method where the sigma points are mC
p
P .i1;:::;in/. The difference from
the unscented transform in Section 5.5 is that the sigma points and the
weights are selected differently. Figure 6.1 illustrates how sigma points
are selected in Gaussian–Hermite cubatures.
6.4 Gauss–Hermite Kalman ﬁlter
The additive form multi-dimensional Gauss–Hermite cubature based
Gauss–Hermite (Kalman) ﬁlter (GHKF) (Ito and Xiong, 2000) which is
also called the quadrature Kalman ﬁlter (QKF) (Arasaratnam et al., 2007)
can be derived by replacing the Gaussian integrals in the Gaussian ﬁlter
Algorithm 6.3 with the Gauss–Hermite approximations in Algorithm 6.6.

104
General Gaussian ﬁltering
−5
0
5
−4
−2
0
2
4
(a) Original
0
2
4
−2
−1
0
1
2
(b) Transformed
Figure 6.1 Illustration of a ﬁfth order Gauss–Hermite cubature
based approximation to a non-linear transformation. The
difference from the unscented transform (UT) illustrated in
Figure 5.5 is that we are using more sigma points and they are
placed differently. Due to the higher number of sigma points the
covariance of the transformed random variable is captured more
accurately. The covariance of the true distribution is presented by
the dashed line and the solid line is the approximation.
Algorithm 6.7 (Gauss–Hermite Kalman ﬁlter)
The additive form Gauss–
Hermite Kalman ﬁlter (GHKF) algorithm is the following.
 Prediction:
1 Form the sigma points as:
X .i1;:::;in/
k1
D mk1 C
p
Pk1 .i1;:::;in/;
i1; : : : ; in D 1; : : : ; p;
(6.26)
where the unit sigma points .i1;:::;in/ were deﬁned in Equation (6.24).
2 Propagate the sigma points through the dynamic model:
OX .i1;:::;in/
k
D f.X .i1;:::;in/
k1
/;
i1; : : : ; in D 1; : : : ; p:
(6.27)
3 Compute the predicted mean m
k and the predicted covariance P 
k :
m
k D
X
i1;:::;in
Wi1;:::;in OX .i1;:::;in/
k
;
P 
k D
X
i1;:::;in
Wi1;:::;in. OX .i1;:::;in/
k
 m
k / . OX .i1;:::;in/
k
 m
k /T C Qk1;
(6.28)

6.4 Gauss–Hermite Kalman ﬁlter
105
where the weights Wi1;:::;in were deﬁned in Equation (6.23).
 Update:
1 Form the sigma points:
X .i1;:::;in/
k
D m
k C
q
P 
k .i1;:::;in/;
i1; : : : ; in D 1; : : : ; p;
(6.29)
where the unit sigma points .i1;:::;in/ were deﬁned in Equation (6.24).
2 Propagate sigma points through the measurement model:
OY.i1;:::;in/
k
D h.X .i1;:::;in/
k
/;
i1; : : : ; in D 1; : : : ; p:
(6.30)
3 Compute the predicted mean k, the predicted covariance of the mea-
surement Sk, and the cross-covariance of the state and the measure-
ment Ck:
k D
X
i1;:::;in
Wi1;:::;in OY.i1;:::;in/
k
;
Sk D
X
i1;:::;in
Wi1;:::;in. OY.i1;:::;in/
k
 k/ . OY.i1;:::;in/
k
 k/T C Rk;
Ck D
X
i1;:::;in
Wi1;:::;in.X .i1;:::;in/
k
 m
k / . OY.i1;:::;in/
k
 k/T;
(6.31)
where the weights Wi1;:::;in were deﬁned in Equation (6.23).
4 Compute the ﬁlter gain Kk, the ﬁltered state mean mk and the covari-
ance Pk, conditional on the measurement yk:
Kk D Ck S1
k ;
mk D m
k C Kk Œyk  k ;
Pk D P 
k  Kk Sk KT
k:
(6.32)
The non-additive version can be obtained by applying the Gauss–
Hermite quadrature to the non-additive Gaussian ﬁlter Algorithm 6.4 in
a similar manner. However, due to the rapid growth of computational
requirements in state dimension the augmented form is computationally
quite heavy, because it requires roughly doubling the dimensionality of the
integration variable.
Example 6.1 (Pendulum tracking with GHKF)
The result of the GHKF
in the pendulum model in Example 5.1 is shown in Figure 6.2. The result
is the same as with the SLF and the UKF (RMSE = 0.11) which implies

106
General Gaussian ﬁltering
0.5
1
1.5
2
2.5
3
3.5
4
4.5
−3
−2
−1
0
1
2
3
4
5
Time t
Pendulum angle x1,k
 
 
True Angle
Measurements
GHKF Estimate
Figure 6.2 Simulated pendulum data and the result of tracking
the pendulum described in Example 5.1 with the GHKF. The
resulting RMSE was 0:11 which is the same as with the SLF and
the UKF.
that in this particular case the higher order approximation to the Gaussian
integrals does not really help. It is possible that the consistency and stabil-
ity properties of the ﬁlters are indeed different, but it is impossible to know
based on this single test.
6.5 Spherical cubature integration
In this section, we derive the third order spherical cubature rule, which
was popularized by Arasaratnam and Haykin (2009). However, instead of
using the derivation of Arasaratnam and Haykin (2009), we shall use the
derivation presented by Wu et al. (2006), due to its simplicity. Although
the derivation that we present here is far simpler than the alternative, it is
completely equivalent. Furthermore, the derivation presented here can be
more easily extended to more complicated spherical cubatures.
Recall from Section 6.3 that the expectation of a non-linear function over
an arbitrary Gaussian distribution N.x j m; P/ can always be transformed
into an expectation over the unit Gaussian distribution N. j 0; I/. Thus,

6.5 Spherical cubature integration
107
we can start by considering the multi-dimensional unit Gaussian integral
Z
g./ N. j 0; I/ d:
(6.33)
We now wish to form a 2n-point approximation of the form
Z
g./ N. j 0; I/ d  W
X
i
g.c u.i//;
(6.34)
where the points u.i/ belong to the symmetric set Œ1 with generator
.1; 0; : : : ; 0/ (see, e.g., Wu et al., 2006; Arasaratnam and Haykin, 2009):
Œ1 D
8
ˆˆˆˆˆ<
ˆˆˆˆˆ:
0
BBBBB@
1
0
0
:::
0
1
CCCCCA
;
0
BBBBB@
0
1
0
:::
0
1
CCCCCA
;   
0
BBBBB@
1
0
0
:::
0
1
CCCCCA
;
0
BBBBB@
0
1
0
:::
0
1
CCCCCA
;   
9
>>>>>=
>>>>>;
;
(6.35)
and W is a weight and c is a parameter yet to be determined.
Because the point set is symmetric, the rule is exact for all monomials
of the form xd1
1 xd2
2    xdn
n , if at least one of the exponents di is odd. Thus
we can construct a rule which is exact up to third degree by determining
the coefﬁcients W and c such that it is exact for selections gj./ D 1 and
gj./ D 2
j . Because the true values of the integrals are
Z
N. j 0; I/ d D 1;
Z
2
j N. j 0; I/ d D 1;
(6.36)
we get the equations
W
X
i
1 D W 2n D 1;
W
X
i
Œc u.i/
j 2 D W 2c2 D 1;
(6.37)
which have the solutions
W D 1
2n;
c D pn:
(6.38)

108
General Gaussian ﬁltering
That is, we get the following simple rule which is exact for monomials up
to third degree:
Z
g./ N. j 0; I/ d  1
2n
X
i
g.pn u.i//:
(6.39)
We can now easily extend the method to arbitrary mean and covariance by
using the change of variables in Equations (6.19) and (6.20) and the result
is the following algorithm.
Algorithm 6.8 (Spherical cubature integration)
The third order spherical
cubature approximation to the multi-dimensional integral
Z
g.x/ N.x j m; P/ dx
(6.40)
can be computed as follows.
1 Compute the unit sigma points as
.i/ D
( pn ei;
i D 1; : : : ; n;
pn ein;
i D n C 1; : : : ; 2n;
(6.41)
where ei denotes a unit vector in the direction of the coordinate axis i.
2 Approximate the integral as
Z
g.x/ N.x j m; P/ dx  1
2n
2n
X
iD1
g.m C
p
P .i//;
(6.42)
where
p
P is a matrix square root deﬁned by P D
p
P
p
P
T.
It is easy to see that the approximation above is a special case of the
unscented transform (see Section 5.5) with parameters ˛ D 1, ˇ D 0,
and  D 0. With this parameter selection the mean weight is zero and the
unscented transform is effectively a 2n-point approximation as well. The
selection of sigma points in spherical cubature integration is illustrated in
Figure 6.3.
The derivation presented by Arasaratnam and Haykin (2009) is a bit
more complicated than the derivation of Wu et al. (2006) presented above,
as it is based on converting the Gaussian integral into spherical coordi-
nates and then considering the even order monomials. However, Wu et al.
(2006) actually did not present the most useful special case given in Al-
gorithm 6.8, but instead presented the method for more general generators
Œu. The method in the above Algorithm 6.8 has the useful property that

6.5 Spherical cubature integration
109
−5
0
5
−4
−2
0
2
4
(a) Original
0
2
4
−2
−1
0
1
2
(b) Transformed
Figure 6.3 Illustration of the third order spherical cubature based
approximation to a non-linear transformation. The difference
from the unscented transform (UT) illustrated in Figure 5.5 is that
we have one sigma point fewer and the spread of the sigma points
is ﬁxed (in UT it is parametrized). The covariance of the true
distribution is presented by the dashed line and the solid line is
the approximation.
its weights are always positive, which is not always true for more general
methods (Wu et al., 2006).
We can generalize the above approach by using a 2n C 1 point approxi-
mation, where the origin is also included:
Z
g./ N. j 0; I/ d  W0 g.0/ C W
X
i
g.c u.i//:
(6.43)
We can now solve for the parameters W0, W , and c such that we get the
exact result with selections gj./ D 1 and gj./ D 2
j . The solution can
be written in the form
W0 D

n C  ;
W D
1
2.n C /;
c D
p
n C ;
(6.44)

110
General Gaussian ﬁltering
where  is a free parameter. This gives an integration rule that can be
written asZ
g.x/ N.x j m; P/ dx


n C  g.m/ C
1
2.n C /
2n
X
iD1
g.m C
p
P .i//;
(6.45)
where
.i/ D
( pn C  ei;
i D 1; : : : ; n;
pn C  ein;
i D n C 1; : : : ; 2n:
(6.46)
The rule can be seen to coincide with the original UT (Julier and Uhlmann,
1995), which corresponds to the unscented transform presented in Sec-
tion 5.5 with ˛ D 1, ˇ D 0, and where  is left as a free parameter. With
the selection  D 3n, we can also match the fourth order moments of the
distribution (Julier and Uhlmann, 1995), but with the price that when the
dimensionality n > 3, we get negative weights and approximation rules
that can sometimes be unstable. But nothing prevents us from using other
values for the parameter.
Note that “third order” here means a different thing than in the Gauss–
Hermite Kalman ﬁlter – the pth order Gauss–Hermite ﬁlter is exact for
monomials up to order 2p  1, which means that the third order GHKF is
exact for monomials up to ﬁfth order. The third order spherical cubature
rule is exact only for monomials up to third order. It is also possible to
derive symmetric rules that are exact for higher than third order. However,
this is no longer possible with a number of sigma points which is linear
O.n/ in state dimension (Wu et al., 2006; Arasaratnam and Haykin, 2009).
For example, for a ﬁfth order rule, the required number of sigma points is
proportional to n2, the state dimension squared.
As in the case of the unscented transform, being exact up to order three
only ensures that the estimate of the mean of g./ is exact for polynomials
of order three. The covariance will be exact only for polynomials up to
order one (linear functions). In this sense the third order spherical cubature
rule is actually a ﬁrst order spherical cubature rule for the covariance.
6.6 Cubature Kalman ﬁlter
When we apply the third order spherical cubature integration rule in Al-
gorithm 6.8 to the Gaussian ﬁlter equations in Algorithm 6.3, we get the
cubature Kalman ﬁlter (CKF) of Arasaratnam and Haykin (2009).

6.6 Cubature Kalman ﬁlter
111
Algorithm 6.9 (Cubature Kalman ﬁlter I)
The additive form of the cuba-
ture Kalman ﬁlter (CKF) algorithm is the following.
 Prediction:
1 Form the sigma points as:
X .i/
k1 D mk1 C
p
Pk1 .i/;
i D 1; : : : ; 2n;
(6.47)
where the unit sigma points are deﬁned as
.i/ D
( pn ei;
i D 1; : : : ; n;
pn ein;
i D n C 1; : : : ; 2n:
(6.48)
2 Propagate the sigma points through the dynamic model:
OX .i/
k
D f.X .i/
k1/;
i D 1; : : : ; 2n:
(6.49)
3 Compute the predicted mean m
k and the predicted covariance P 
k :
m
k D 1
2n
2n
X
iD1
OX .i/
k ;
P 
k D 1
2n
2n
X
iD1
. OX .i/
k
 m
k / . OX .i/
k
 m
k /T C Qk1:
(6.50)
 Update:
1 Form the sigma points:
X .i/
k
D m
k C
q
P 
k .i/;
i D 1; : : : ; 2n;
(6.51)
where the unit sigma points are deﬁned as in Equation (6.48).
2 Propagate sigma points through the measurement model:
OY.i/
k
D h.X .i/
k
/;
i D 1 : : : 2n:
(6.52)
3 Compute the predicted mean k, the predicted covariance of the
measurement Sk, and the cross-covariance of the state and the

112
General Gaussian ﬁltering
measurement Ck:
k D 1
2n
2n
X
iD1
OY.i/
k ;
Sk D 1
2n
2n
X
iD1
. OY.i/
k  k/ . OY.i/
k  k/T C Rk;
Ck D 1
2n
2n
X
iD1
.X .i/
k
 m
k / . OY.i/
k  k/T:
(6.53)
4 Compute the ﬁlter gain Kk and the ﬁltered state mean mk and covari-
ance Pk, conditional on the measurement yk:
Kk D Ck S1
k ;
mk D m
k C Kk Œyk  k ;
Pk D P 
k  Kk Sk KT
k:
(6.54)
By applying the cubature rule to the non-additive Gaussian ﬁlter in Al-
gorithm 6.4 we get the following augmented form of the cubature Kalman
ﬁlter (CKF).
Algorithm 6.10 (Cubature Kalman ﬁlter II)
The augmented non-additive
form of the cubature Kalman ﬁlter (CKF) algorithm is the following.
 Prediction:
1 Form the matrix of sigma points for the augmented random variable
.xk1; qk1/:
QX .i/
k1 D Qmk1 C
q
QPk1 .i/0;
i D 1; : : : ; 2n0;
(6.55)
where
Qmk1 D
mk1
0

;
QPk1 D
Pk1
0
0
Qk1

:
Here n0 D nCnq, where n is the dimensionality of the state xk1 and
nq is the dimensionality of the noise qk1. The unit sigma points are
deﬁned as
.i/0 D
( p
n0 ei;
i D 1; : : : ; n0;

p
n0 ein0;
i D n0 C 1; : : : ; 2n0:
(6.56)

6.6 Cubature Kalman ﬁlter
113
2 Propagate the sigma points through the dynamic model:
OX .i/
k
D f. QX .i/;x
k1 ; QX .i/;q
k1 /;
i D 1; : : : ; 2n0;
(6.57)
where QX .i/;x
k1 denotes the ﬁrst n components in QX .i/
k1 and QX .i/;q
k1 de-
notes the last nq components.
3 Compute the predicted mean m
k and the predicted covariance P 
k :
m
k D
1
2n0
2n0
X
iD1
OX .i/
k ;
P 
k D
1
2n0
2n0
X
iD1
. OX .i/
k
 m
k / . OX .i/
k
 m
k /T:
(6.58)
 Update:
1 Let n00 D n C nr, where n is the dimensionality of the state and nr is
the dimensionality of the measurement noise. Form the sigma points
for the augmented vector .xk; rk/ as follows:
QX .i/
k
D Qm
k C
q
QP 
k .i/00;
i D 1; : : : ; 2n00;
(6.59)
where
Qm
k D
m
k
0

;
QP 
k D
P 
k
0
0
Rk

:
The unit sigma points .i/00 are deﬁned as in Equation (6.56), but with
n0 replaced by n00.
2 Propagate the sigma points through the measurement model:
OY.i/
k
D h. QX .i/;x
k
; QX .i/;r
k
/;
i D 1; : : : ; 2n00;
(6.60)
where QX .i/;x
k
denotes the ﬁrst n components in QX .i/
k
and QX .i/;r
k
denotes the last nr components.
3 Compute the predicted mean k, the predicted covariance of the
measurement Sk, and the cross-covariance of the state and the

114
General Gaussian ﬁltering
measurement Ck:
k D
1
2n00
2n00
X
iD1
OY.i/
k ;
Sk D
1
2n00
2n00
X
iD1
. OY.i/
k  k/ . OY.i/
k  k/T;
Ck D
1
2n00
2n00
X
iD1
.X .i/;x
k
 m
k / . OY.i/
k  k/T:
(6.61)
4 Compute the ﬁlter gain Kk, the ﬁltered state mean mk and the covari-
ance Pk, conditional on the measurement yk:
Kk D Ck S1
k ;
mk D m
k C Kk Œyk  k ;
Pk D P 
k  Kk Sk KT
k:
(6.62)
Although in the cubature Kalman ﬁlter (CKF) literature the “third or-
der” characteristic of the cubature integration rule is often emphasized (see
Arasaratnam and Haykin, 2009), it is important to remember that in the
covariance computation, the rule is only exact for ﬁrst order polynomials.
Thus in that sense CKF is a ﬁrst order method.
Example 6.2 (Pendulum tracking with CKF)
The result of the CKF in
the pendulum model (Example 5.1) is shown in Figure 6.4. The result is
practically the same as the result of the UKF, which was to be expected,
because the CKF is just a UKF with a speciﬁc parametrization.
6.7 Exercises
6.1
Show that the selection  D 3  n in Equation (6.45) causes fourth order
terms 4
i to be integrated exactly when m D 0 and P D I. What happens to
the weights if n > 3?
6.2
Show that when the function is linear, both the unscented transform and the
spherical cubature rule give the exact result.
6.3
Show that one-dimensional Hermite polynomials are orthogonal with re-
spect to the inner product
hf; gi D
Z
f .x/ g.x/ N.x j 0; 1/ dx:
(6.63)

Exercises
115
0.5
1
1.5
2
2.5
3
3.5
4
4.5
−3
−2
−1
0
1
2
3
4
5
Time t
Pendulum angle x1,k
 
 
True Angle
Measurements
CKF Estimate
Figure 6.4 Simulated pendulum data and the result of tracking
the pendulum described in Example 5.1 with the CKF. The
resulting RMSE was 0:11 which is practically the same as the
error of the UKF. In fact, the result is practically the same as with
all the other non-linear Kalman ﬁlters encountered in this book so
far.
6.4
Show that multivariate Hermite polynomials deﬁned as
Hi1;:::;in.x/ D Hi1.x1/      Hin.xn/
(6.64)
are orthogonal with respect to the inner product
hf; gi D
Z
f .x/ g.x/ N.x j 0; I/ dx:
(6.65)
6.5
Implement a GHKF for the model in Exercise 5.1. Plot the results and com-
pare the RMSE values with the EKF, SLF, and UKF.
6.6
Implement a CKF for the model in Exercise 5.1. Plot the results and compare
the RMSE values with the other ﬁlters. Can you ﬁnd such parameter values
for the methods which cause the UKF, GHKF, and CKF methods to become
identical?
6.7
Implement a CKF for the bearings only target tracking problem in Exer-
cise 5.5. Compare the performance with the EKF and UKF.

7
Particle ﬁltering
Although in many ﬁltering problems Gaussian approximations work well,
sometimes the ﬁltering distributions can be, for example, multi-modal, or
some of the state components might be discrete, in which case Gaussian
approximations are not appropriate. In such cases sequential importance
resampling based particle ﬁlters can be a better alternative. This chapter is
concerned with particle ﬁlters, which are methods for forming Monte Carlo
approximations to the solutions of the Bayesian ﬁltering equations.
7.1 Monte Carlo approximations in Bayesian inference
In Bayesian inference, including Bayesian ﬁltering, the main inference
problem can often be reduced into computation of the following kind of
expectations over the posterior distribution:1
EŒg.x/ j y1WT  D
Z
g.x/ p.x j y1WT / dx;
(7.1)
where g W Rn ! Rm is an arbitrary function and p.x j y1WT / is the
posterior probability density of x given the measurements y1; : : : ; yT . Now
the problem is that such an integral can be evaluated in closed form only in
a few special cases and generally, numerical methods have to be used.
Monte Carlo methods provide a numerical method for calculating inte-
grals of the form (7.1). Monte Carlo refers to a general class of methods
where closed form computation of statistical quantities is replaced by draw-
ing samples from the distribution and estimating the quantities by sample
averages.
In a (perfect) Monte Carlo approximation, we draw N independent
random samples x.i/  p.x j y1WT /, i D 1; : : : ; N and estimate the
1 In this section we formally treat x as a continuous random variable with a density, but
the analogous results apply to discrete random variables.
116

7.2 Importance sampling
117
−5
0
5
−5
0
5
(a)
−5
0
5
−5
0
5
(b)
Figure 7.1 (a) Two-dimensional Gaussian distribution. (b) Monte
Carlo representation of the same Gaussian distribution.
expectation as
EŒg.x/ j y1WT   1
N
N
X
iD1
g.x.i//:
(7.2)
Thus Monte Carlo methods approximate the target distribution by a set
of samples that are distributed according to the target density. Figure 7.1
represents a two-dimensional Gaussian distribution and its Monte Carlo
representation.
The convergence of the Monte Carlo approximation is guaranteed by
the central limit theorem (CLT, see, e.g., Liu, 2001) and the error term is
O.N 1=2/, regardless of the dimensionality of x. This invariance with re-
spect to dimensionality is unique to Monte Carlo methods and makes them
superior to practically all other numerical methods when the dimensional-
ity of x is considerable. At least in theory, not necessarily in practice (see
Daum and Huang, 2003; Snyder et al., 2008).
7.2 Importance sampling
Often, in practical Bayesian models, it is not possible to obtain samples
directly from p.x j y1WT / due to its complicated functional form. In im-
portance sampling (IS) (see, e.g., Liu, 2001) we use an approximate dis-
tribution called the importance distribution .x j y1WT /, from which we
can easily draw samples. Importance sampling is based on the following
decomposition of the expectation over the posterior probability density

118
Particle ﬁltering
p.x j y1WT /:
Z
g.x/ p.x j y1WT / dx D
Z 
g.x/ p.x j y1WT /
.x j y1WT /

.x j y1WT / dx; (7.3)
where the importance density .x j y1WT / is required to be non-zero when-
ever p.x j y1WT / is non-zero, that is, the support of .x j y1WT / needs to be
greater than or equal to the support of p.x j y1WT /. As the above expres-
sion is just the expectation of the term in the brackets over the distribution
.x j y1WT /, we can form a Monte Carlo approximation to it by drawing N
samples from the importance distribution:
x.i/  .x j y1WT /;
i D 1; : : : ; N;
(7.4)
and by forming the approximation as
EŒg.x/ j y1WT   1
N
N
X
iD1
p.x.i/ j y1WT /
.x.i/ j y1WT / g.x.i//
D
N
X
iD1
Qw.i/ g.x.i//;
(7.5)
where the weights have been deﬁned as
Qw.i/ D 1
N
p.x.i/ j y1WT /
.x.i/ j y1WT /:
(7.6)
Figure 7.2 illustrates the idea of importance sampling. We sample from the
importance distribution which is an approximation to the target distribu-
tion. Because the distribution of samples is not exact, we need to correct
the approximation by associating a weight with each of the samples.
The disadvantage of this direct importance sampling is that we should
be able to evaluate p.x.i/ j y1WT / in order to use it directly. Recall that
by Bayes’ rule the evaluation of the posterior probability density can be
written as
p.x.i/ j y1WT / D p.y1WT j x.i// p.x.i//
R
p.y1WT j x/ p.x/ dx:
(7.7)
The likelihood p.y1WT j x.i// and prior terms p.x.i// are usually easy to
evaluate but often the integral in the denominator – the normalization con-
stant – cannot be computed. To overcome this problem, we can form an
importance sampling approximation to the expectation integral by also ap-
proximating the normalization constant by importance sampling. For this

7.2 Importance sampling
119
−4
−2
0
2
4
0
0.1
0.2
0.3
0.4
0.5
 x
 p(x)
 
 
Target Distribution
Importance Distribution
(a)
−4
−2
0
2
4
0
0.005
0.01
0.015
0.02
0.025
0.03
 x
Weight
(b)
Figure 7.2 (a) The importance distribution approximates the
target distribution. (b) Weights are associated with each of the
samples to correct the approximation.
purpose we can decompose the expectation integral and form the approxi-
mation as follows.
EŒg.x/ j y1WT  D
Z
g.x/ p.x j y1WT / dx
D
R
g.x/ p.y1WT j x/ p.x/ dx
R
p.y1WT j x/ p.x/ dx
D
R h
p.y1WT jx/ p.x/
.xjy1WT /
g.x/
i
.x j y1WT / dx
R h
p.y1WT jx/ p.x/
.xjy1WT /
i
.x j y1WT / dx

1
N
PN
iD1
p.y1WT jx.i// p.x.i//
.x.i/jy1WT /
g.x.i//
1
N
PN
j D1
p.y1WT jx.j // p.x.j //
.x.j /jy1WT /
D
N
X
iD1
2
4
p.y1WT jx.i// p.x.i//
.x.i/jy1WT /
PN
j D1
p.y1WT jx.j // p.x.j //
.x.j /jy1WT /
3
5
„
ƒ‚
…
w.i/
g.x.i//:
(7.8)
Thus we get the following algorithm.
Algorithm 7.1 (Importance sampling)
Given a measurement model
p.y1WT
j x/ and a prior p.x/ we can form an importance sampling
approximation to the posterior as follows.

120
Particle ﬁltering
1 Draw N samples from the importance distribution:
x.i/  .x j y1WT /;
i D 1; : : : ; N:
(7.9)
2 Compute the unnormalized weights by
w.i/ D p.y1WT j x.i// p.x.i//
.x.i/ j y1WT /
;
(7.10)
and the normalized weights by
w.i/ D
w.i/
PN
j D1 w.j / :
(7.11)
3 The approximation to the posterior expectation of g.x/ is then given as
EŒg.x/ j y1WT  
N
X
iD1
w.i/ g.x.i//:
(7.12)
The approximation to the posterior probability density formed by the
above algorithm can then be formally written as
p.x j y1WT / 
N
X
iD1
w.i/ ı.x  x.i//;
(7.13)
where ı./ is the Dirac delta function.
7.3 Sequential importance sampling
Sequential importance sampling (SIS) (see, e.g., Doucet et al., 2001) is a
sequential version of importance sampling. The SIS algorithm can be used
for generating importance sampling approximations to ﬁltering distribu-
tions of generic state space models of the form
xk  p.xk j xk1/;
yk  p.yk j xk/;
(7.14)
where xk 2 Rn is the state at time step k and yk 2 Rm is the measurement.
The state and measurements may contain both discrete and continuous
components.
The SIS algorithm uses a weighted set of particles f.w.i/
k ; x.i/
k / W i D
1; : : : ; Ng, that is, samples from an importance distribution and their
weights, for representing the ﬁltering distribution p.xk j y1Wk/ such that

7.3 Sequential importance sampling
121
at every time step k the approximation to the expectation of an arbitrary
function g./ can be calculated as the weighted sample average
EŒg.xk/ j y1Wk 
N
X
iD1
w.i/
k g.x.i/
k /:
(7.15)
Equivalently, SIS can be interpreted as forming an approximation to the
ﬁltering distribution as
p.xk j y1Wk/ 
N
X
iD1
w.i/
k ı.xk  x.i/
k /:
(7.16)
To derive the algorithm, we consider the full posterior distribution of states
x0Wk given the measurements y1Wk. By using the Markov properties of the
model, we get the following recursion for the posterior distribution:
p.x0Wk j y1Wk/ / p.yk j x0Wk; y1Wk1/ p.x0Wk j y1Wk1/
D p.yk j xk/ p.xk j x0Wk1; y1Wk1/ p.x0Wk1 j y1Wk1/
D p.yk j xk/ p.xk j xk1/ p.x0Wk1 j y1Wk1/:
(7.17)
Using a similar rationale as in the previous section, we can now construct
an importance sampling method which draws samples from a given im-
portance distribution x.i/
0Wk  .x0Wk j y1Wk/ and computes the importance
weights by
w.i/
k / p.yk j x.i/
k / p.x.i/
k j x.i/
k1/ p.x.i/
0Wk1 j y1Wk1/
.x.i/
0Wk j y1Wk/
:
(7.18)
If we form the importance distribution for the states xk recursively as fol-
lows:
.x0Wk j y1Wk/ D .xk j x0Wk1; y1Wk/ .x0Wk1 j y1Wk1/;
(7.19)
then the expression for the weights can be written as
w.i/
k / p.yk j x.i/
k / p.x.i/
k j x.i/
k1/
.x.i/
k j x.i/
0Wk1; y1Wk/
p.x.i/
0Wk1 j y1Wk1/
.x.i/
0Wk1 j y1Wk1/
:
(7.20)
Let’s now assume that we have already drawn the samples x.i/
0Wk1 from the
importance distribution .x0Wk1 j y1Wk1/ and computed the correspond-
ing importance weights w.i/
k1. We can now draw samples x.i/
0Wk from the
importance distribution .x0Wk j y1Wk/ by drawing the new state samples

122
Particle ﬁltering
for the step k as x.i/
k  .xk j x.i/
0Wk1; y1Wk/. The importance weights from
the previous step are proportional to the last term in Equation (7.20):
w.i/
k1 / p.x.i/
0Wk1 j y1Wk1/
.x.i/
0Wk1 j y1Wk1/
;
(7.21)
and thus the weights satisfy the recursion
w.i/
k
/ p.yk j x.i/
k / p.x.i/
k j x.i/
k1/
.x.i/
k j x.i/
0Wk1; y1Wk/
w.i/
k1:
(7.22)
The generic sequential importance sampling algorithm can now be de-
scribed as follows.
Algorithm 7.2 (Sequential importance sampling)
Steps of SIS are the
following:
 Draw N samples x.i/
0 from the prior
x.i/
0  p.x0/;
i D 1; : : : ; N;
(7.23)
and set w.i/
0
D 1=N, for all i D 1; : : : ; N.
 For each k D 1; : : : ; T do the following.
1 Draw samples x.i/
k from the importance distributions
x.i/
k  .xk j x.i/
0Wk1; y1Wk/;
i D 1; : : : ; N:
(7.24)
2 Calculate new weights according to
w.i/
k
/ w.i/
k1
p.yk j x.i/
k / p.x.i/
k j x.i/
k1/
.x.i/
k j x.i/
0Wk1; y1Wk/
(7.25)
and normalize them to sum to unity.
Note that it is convenient to select the importance distribution to be
Markovian in the sense that
.xk j x0Wk1; y1Wk/ D .xk j xk1; y1Wk/:
(7.26)
With this form of importance distribution we do not need to store the whole
histories x.i/
0Wk in the SIS algorithm, only the current states x.i/
k . This form is
also convenient in sequential importance resampling (SIR) discussed in the
next section, because we do not need to worry about the state histories dur-
ing the resampling step as in the SIR particle smoother (see Section 11.1).
Thus in the following section we assume that the importance distribution
has indeed been selected to have the above Markovian form.

7.4 Sequential importance resampling
123
7.4 Sequential importance resampling
One problem in the SIS algorithm described in the previous section is that
we easily encounter the situation that almost all the particles have zero
or nearly zero weights. This is called the degeneracy problem in particle
ﬁltering literature and it prevented practical applications of particle ﬁlters
for many years.
The degeneracy problem can be solved by using a resampling procedure.
It refers to a procedure where we draw N new samples from the discrete
distribution deﬁned by the weights and replace the old set of N samples
with this new set. This procedure can be be written as the following algo-
rithm:
Algorithm 7.3 (Resampling)
The resampling procedure can be described
as follows.
1 Interpret each weight w.i/
k
as the probability of obtaining the sample
index i in the set fx.i/
k
W i D 1; : : : ; Ng.
2 Draw N samples from that discrete distribution and replace the old
sample set with this new one.
3 Set all weights to the constant value w.i/
k
D 1=N.
The idea of the resampling procedure is to remove particles with very
small weights and duplicate particles with large weights. Although the
theoretical distribution represented by the weighted set of samples does
not change, resampling introduces additional variance to estimates. This
variance introduced by the resampling procedure can be reduced by proper
choice of the resampling method. The stratiﬁed resampling algorithm
(Kitagawa, 1996) is optimal in terms of variance.
Adding a resampling step to the sequential importance sampling algo-
rithm leads to sequential importance resampling (SIR)2 (Gordon et al.,
1993; Kitagawa, 1996; Doucet et al., 2001; Ristic et al., 2004), which is
the algorithm usually referred to as the particle ﬁlter. In SIR, resampling
is not usually performed at every time step, but only when it is actually
needed. One way of implementing this is to do resampling on every nth
step, where n is some predeﬁned constant. This method has the advantage
that it is unbiased. Another way, which is used here, is adaptive resampling.
In this method, the “effective” number of particles, which is estimated from
2 Sequential importance resampling is also often referred to as sampling importance
resampling or sequential importance sampling resampling.

124
Particle ﬁltering
the variance of the particle weights (Liu and Chen, 1995), is used for mon-
itoring the need for resampling. The estimate for the effective number of
particles can be computed as:
neff 
1
PN
iD1

w.i/
k
2 ;
(7.27)
where w.i/
k
is the normalized weight of particle i at the time step k (Liu
and Chen, 1995). Resampling is performed when the effective number of
particles is signiﬁcantly less than the total number of particles, for example,
neff < N=10, where N is the total number of particles.
Algorithm 7.4 (Sequential importance resampling)
The sequential im-
portance resampling (SIR) algorithm, which is also called the particle ﬁlter
(PF), is the following.
 Draw N samples x.i/
0 from the prior
x.i/
0  p.x0/;
i D 1; : : : ; N;
(7.28)
and set w.i/
0
D 1=N, for all i D 1; : : : ; N.
 For each k D 1; : : : ; T do the following:
1 Draw samples x.i/
k from the importance distributions
x.i/
k  .xk j x.i/
k1; y1Wk/;
i D 1; : : : ; N:
(7.29)
2 Calculate new weights according to
w.i/
k
/ w.i/
k1
p.yk j x.i/
k / p.x.i/
k j x.i/
k1/
.x.i/
k j x.i/
k1; y1Wk/
(7.30)
and normalize them to sum to unity.
3 If the effective number of particles (7.27) is too low, perform resam-
pling.
The SIR algorithm forms the following approximation to the ﬁltering
distribution:
p.xk j y1Wk/ 
N
X
iD1
w.i/
k ı.xk  x.i/
k /;
(7.31)

7.4 Sequential importance resampling
125
and thus the expectation of an arbitrary function g./ can be approximated
as
EŒg.xk/ j y1Wk 
N
X
iD1
w.i/
k g.x.i/
k /:
(7.32)
Performance of the SIR algorithm depends on the quality of the impor-
tance distribution ./. The importance distribution should be in such a
functional form that we can easily draw samples from it and that it is pos-
sible to evaluate the probability densities of the sample points. The optimal
importance distribution in terms of variance (see, e.g., Doucet et al., 2001;
Ristic et al., 2004) is
.xk j x0Wk1; y1Wk/ D p.xk j xk1; yk/:
(7.33)
If the optimal importance distribution cannot be directly used, importance
distributions can sometimes be obtained by local linearization where a
mixture of extended Kalman ﬁlters (EKF), unscented Kalman ﬁlters (UKF)
or other types of non-linear Kalman ﬁlter are used for forming the impor-
tance distribution (Doucet et al., 2000; Van der Merwe et al., 2001). It is
also possible to use a Metropolis–Hastings step after (or in place of) the
resampling step to smooth the resulting distribution (Van der Merwe et al.,
2001). A particle ﬁlter with UKF importance distribution is also referred
to as the unscented particle ﬁlter (UPF). Similarly, we could call a parti-
cle ﬁlter with the Gauss–Hermite Kalman ﬁlter importance distribution the
Gauss–Hermite particle ﬁlter (GHPF) and one with the cubature Kalman
ﬁlter importance distribution the cubature particle ﬁlter (CPF). However,
the use of this kind of importance distribution can also lead to the failure
of particle ﬁlter convergence and hence they should be used with extreme
care. Instead of forming the importance distribution directly by using the
Gaussian approximation provided by the EKF, UKF, or other Gaussian ﬁl-
ter it may be advisable to artiﬁcially increase the covariance of the distribu-
tion or to replace the Gaussian distribution with a Student’s t distribution
with a suitable number of degrees of freedom (see Capp´e et al., 2005).
By tuning the resampling algorithm to speciﬁc estimation problems and
possibly changing the order of weight computation and sampling, accuracy
and computational efﬁciency of the algorithm can be improved (Fearnhead
and Clifford, 2003). An important issue is that sampling is more efﬁcient
without replacement, such that duplicate samples are not stored. There is
also evidence that in some situations it is more efﬁcient to use a simple
deterministic algorithm for preserving the N most likely particles. In the
article by Punskaya et al. (2002) it is shown that in digital demodulation,

126
Particle ﬁltering
where the sampled space is discrete and the optimization criterion is the
minimum error, the deterministic algorithm performs better.
The bootstrap ﬁlter (Gordon et al., 1993) is a variation of SIR where the
dynamic model p.xk j xk1/ is used as the importance distribution. This
makes the implementation of the algorithm very easy, but due to the inefﬁ-
ciency of the importance distribution it may require a very large number of
Monte Carlo samples for accurate estimation results. In the bootstrap ﬁlter
the resampling is normally done at each time step.
Algorithm 7.5 (Bootstrap ﬁlter)
The bootstrap ﬁlter algorithm is as fol-
lows.
1 Draw a new point x.i/
k
for each point in the sample set fx.i/
k1 W i D
1; : : : ; Ng from the dynamic model:
x.i/
k  p.xk j x.i/
k1/;
i D 1; : : : ; N:
(7.34)
2 Calculate the weights
w.i/
k / p.yk j x.i/
k /;
i D 1; : : : ; N;
(7.35)
and normalize them to sum to unity.
3 Do resampling.
Another variation of sequential importance resampling is the auxiliary
SIR (ASIR) ﬁlter (Pitt and Shephard, 1999). The idea of the ASIR is to
mimic the availability of the optimal importance distribution by performing
the resampling at step k  1 using the available measurement at time k.
One problem encountered in particle ﬁltering, even when using a resam-
pling procedure, is called sample impoverishment (see, e.g., Ristic et al.,
2004). It refers to the effect that when the noise in the dynamic model is
very small, many of the particles in the particle set will turn out to have ex-
actly the same value. That is, the resampling step simply multiplies a few
(or one) particles and thus we end up having a set of identical copies of
certain high weighted particles. This problem can be diminished by using,
for example, the resample-move algorithm, regularization, or MCMC steps
(Ristic et al., 2004).
Because low noise in the dynamic model causes sample impoverish-
ment, it also implies that pure recursive estimation with particle ﬁlters
is challenging. This is because in pure recursive estimation the process
noise is formally zero and thus a basic SIR based particle ﬁlter is likely
to perform very badly. Pure recursive estimation, such as recursive esti-
mation of static parameters, can sometimes be done by applying a Rao–
Blackwellized particle ﬁlter instead of the basic SIR particle ﬁlter (see

7.4 Sequential importance resampling
127
0.5
1
1.5
2
2.5
3
3.5
4
4.5
−3
−2
−1
0
1
2
3
4
5
Time t
Pendulum angle x1,k
 
 
True Angle
Measurements
PF Estimate
Figure 7.3 Simulated pendulum data and the result of tracking
the pendulum described in Example 5.1 with a bootstrap type of
particle ﬁlter (PF) with 10 000 particles. The resulting RMSE was
0:12 which is slightly higher than the errors of most of the
Gaussian approximation based ﬁlters (the EKF had 0:12, others
0:11).
Section 12.3.5). However, the more common use of Rao–Blackwellization
is in the conditionally linear Gaussian state space models which we will
discuss in the next section.
Example 7.1 (Pendulum tracking with a particle ﬁlter)
The result of the
bootstrap ﬁlter with 10 000 particles in the pendulum model (Example 5.1)
is shown in Figure 7.3. The RMSE of 0:12 is slightly higher than with most
of the other ﬁlters – with the EKF we got an RMSE of 0:12 and with
the SLF/UKF/GHKF/CKF we got an RMSE of 0:11. This implies that in
this case the ﬁltering distribution is indeed quite well approximated with a
Gaussian distribution, and thus using a particle ﬁlter is not beneﬁcial.
In the above example the model is of the type which is suitable for
Gaussian approximation based ﬁlters and thus the particle ﬁlter produces
much the same result as they do. But often the noises in the system are not
Gaussian or there might be clutter (outlier) measurements which do not
ﬁt into the Gaussian non-linear state space modeling framework at all. In
these kinds of model, the particle ﬁlter still produces good results whereas

128
Particle ﬁltering
0.5
1
1.5
2
2.5
3
3.5
4
4.5
−3
−2
−1
0
1
2
3
4
5
Time t
Pendulum angle x1,k
 
 
True Angle
Measurements
PF Estimate
GHKF with True R
GHKF with Increased R
Figure 7.4 Simulated pendulum data in the presence of 50%
clutter (outlier) measurements and the result of tracking with a
bootstrap type of particle ﬁlter (PF) with 10 000 particles (see
Example 7.2). The resulting RMSE was 0:16. The corresponding
errors of the GHKF with no clutter model at all and the GHKF
with artiﬁcially increased noise variance were 3:60 and 0:82,
respectively.
Gaussian ﬁlters do not work at all. The next example illustrates this kind
of situation.
Example 7.2 (Cluttered pendulum tracking with a particle ﬁlter)
In this
scenario, the pendulum sensor is broken such that at each time instant it
produces clutter (a random number in the range Œ2; 2) with probability
50%. This kind of situation can be modeled by including an indicator value
(data association indicator) as part of the state, which indicates whether
the measurement is clutter or not. The result of the bootstrap ﬁlter in the
pendulum model (Example 5.1) is shown in Figure 7.4. The RMSE of 0:16
is slightly higher than in the clutter-free case. In Gaussian ﬁlters a clut-
ter model cannot be included into the system as such, but one heuristic
way to cope with it is to set the measurement noise variance high enough.
In Figure 7.4 we also show the results of a Gauss–Hermite Kalman ﬁlter
(GHKF) with no clutter model at all, and the result of a GHKF with arti-
ﬁcially increased noise variance. The RMSEs of these ﬁlters are 3:60 and
0:82, respectively, which are much higher than the RMSE of the particle

7.5 Rao–Blackwellized particle ﬁlter
129
ﬁlter. The estimate trajectories of the GHKFs also indicate that they are
having signiﬁcant trouble in estimating the state.
7.5 Rao–Blackwellized particle ﬁlter
One way of improving the efﬁciency of SIR is to use Rao–Blackwellization.
The idea of the Rao–Blackwellized particle ﬁlter (RBPF) (Akashi and
Kumamoto, 1977; Doucet et al., 2001; Ristic et al., 2004), which is also
called the mixture Kalman ﬁlter (MKF) (Chen and Liu, 2000) is that
sometimes it is possible to evaluate some of the ﬁltering equations ana-
lytically and the others with Monte Carlo sampling instead of computing
everything with pure sampling. According to the Rao–Blackwell theorem
(see, e.g., Berger, 1985) this leads to estimators with less variance than
could be obtained with pure Monte Carlo sampling. An intuitive way of
understanding this is that the marginalization replaces the ﬁnite Monte
Carlo particle set representation with an inﬁnite closed form particle set,
which is always more accurate than any ﬁnite set.
Most commonly Rao–Blackwellized particle ﬁltering refers to marginal-
ized ﬁltering of conditionally linear Gaussian models of the form
p.xk j xk1; uk1/ D N.xk j Ak1.uk1/ xk1; Qk1.uk1//;
p.yk j xk; uk/ D N.yk j Hk.uk/ xk; Rk.uk//;
p.uk j uk1/ D (any given form);
(7.36)
where xk is the state, yk is the measurement, and uk is an arbitrary latent
variable. If also the prior of xk is Gaussian, then due to the conditionally
linear Gaussian structure of the model the state variables xk can be inte-
grated out analytically and only the latent variables uk need to be sampled.
The Rao–Blackwellized particle ﬁlter uses SIR for the latent variables and
computes the conditionally Gaussian part in closed form.
To derive the ﬁltering algorithm, ﬁrst note that the full posterior distri-
bution at step k can be factored as
p.u0Wk; x0Wk j y1Wk/ D p.x0Wk j u0Wk; y1Wk/ p.u0Wk j y1Wk/;
(7.37)
where the ﬁrst term is Gaussian and computable with the Kalman ﬁlter
and RTS smoother. For the second term we get the following recursion

130
Particle ﬁltering
analogously to Equation (7.17):
p.u0Wk j y1Wk/
/ p.yk j u0Wk; y1Wk1/ p.u0Wk j y1Wk1/
D p.yk j u0Wk; y1Wk1/ p.uk j u0Wk1; y1Wk1/ p.u0Wk1 j y1Wk1/
D p.yk j u0Wk; y1Wk1/ p.uk j uk1/ p.u0Wk1 j y1Wk1/;
(7.38)
where we have used the Markovianity of uk. Now the measurements are
not conditionally independent given uk and thus the ﬁrst term differs from
the corresponding term in Equation (7.17). The ﬁrst term can be computed
by running the Kalman ﬁlter with ﬁxed u0Wk over the measurement se-
quence. The second term is just the dynamic model and the third term is
the posterior from the previous step.
If we form the importance distribution recursively as follows:
.u0Wk j y1Wk/ D .uk j u0Wk1; y1Wk/ .u0Wk1 j y1Wk1/;
(7.39)
then by following the same derivation as in Section 7.3, we get the follow-
ing recursion for the weights:
w.i/
k
/ p.yk j u.i/
0Wk1; y1Wk1/ p.u.i/
k j u.i/
k1/
.u.i/
k j u.i/
0Wk1; y1Wk/
w.i/
k1;
(7.40)
which corresponds to Equation (7.22). Thus via the above recursion we can
form an importance sampling based approximation to the marginal distri-
bution p.u0Wk j y1Wk/. But because, given u0Wk, the distribution p.x0Wk j
u0Wk; y1Wk/ is Gaussian, we can form the full posterior distribution by using
Equation (7.37). Computing the distribution jointly for the full history x0Wk
would require running both the Kalman ﬁlter and the RTS smoother over
the sequences u0Wk and y1Wk, but if we are only interested in the posterior of
the last time step xk, we only need to run the Kalman ﬁlter. The resulting
algorithm is the following.
Algorithm 7.6 (Rao–Blackwellized particle ﬁlter)
Given a sequence of
importance distributions .uk j u.i/
0Wk1; y1Wk/ and a set of weighted sam-
ples fw.i/
k1; u.i/
k1; m.i/
k1; P .i/
k1 W i D 1; : : : ; Ng, the Rao–Blackwellized
particle ﬁlter (RBPF) processes the measurement yk as follows (Doucet
et al., 2001).
1 Perform Kalman ﬁlter predictions for each of the Kalman ﬁlter means
and covariances in the particles i D 1; : : : ; N conditional on the previ-

7.5 Rao–Blackwellized particle ﬁlter
131
ously drawn latent variable values u.i/
k1:
m.i/
k
D Ak1.u.i/
k1/ m.i/
k1;
P .i/
k
D Ak1.u.i/
k1/ P .i/
k1 AT
k1.u.i/
k1/ C Qk1.u.i/
k1/:
(7.41)
2 Draw new latent variables u.i/
k for each particle in i D 1; : : : ; N from
the corresponding importance distributions:
u.i/
k  .uk j u.i/
0Wk1; y1Wk/:
(7.42)
3 Calculate new weights as follows:
w.i/
k
/ w.i/
k1
p.yk j u.i/
0Wk; y1Wk1/ p.u.i/
k j u.i/
k1/
.u.i/
k j u.i/
0Wk1; y1Wk/
;
(7.43)
where the likelihood term is the marginal measurement likelihood of the
Kalman ﬁlter
p.yk j u.i/
0Wk; y1Wk1/
D N

yk
ˇˇˇ Hk.u.i/
k / m.i/
k
; Hk.u.i/
k / P .i/
k
HT
k.u.i/
k / C Rk.u.i/
k /

(7.44)
such that the model parameters in the Kalman ﬁlter are conditioned on
the drawn latent variable value u.i/
k . Then normalize the weights to sum
to unity.
4 Perform Kalman ﬁlter updates for each of the particles conditional on
the drawn latent variables u.i/
k :
v.i/
k
D yk  Hk.u.i/
k / m
k ;
S.i/
k D Hk.u.i/
k / P .i/
k
HT
k.u.i/
k / C Rk.u.i/
k /;
K.i/
k D P .i/
k
HT
k.u.i/
k / S1
k ;
m.i/
k D m.i/
k
C K.i/
k v.i/
k ;
P .i/
k
D P .i/
k
 K.i/
k S.i/
k ŒK.i/
k T:
(7.45)
5 If the effective number of particles (7.27) is too low, perform resampling.
The Rao–Blackwellized particle ﬁlter produces for each time step k a
set of weighted samples fw.i/
k ; u.i/
k ; m.i/
k ; P .i/
k
W i D 1; : : : ; Ng such that

132
Particle ﬁltering
the expectation of a function g./ can be approximated as
EŒg.xk; uk/ j y1Wk 
N
X
iD1
w.i/
k
Z
g.xk; u.i/
k / N.xk j m.i/
k ; P .i/
k / dxk:
(7.46)
Equivalently, the RBPF can be interpreted to form an approximation to the
ﬁltering distribution as
p.xk; uk j y1Wk/ 
N
X
iD1
w.i/
k ı.uk  u.i/
k / N.xk j m.i/
k ; P .i/
k /:
(7.47)
The optimal importance distribution, that is, the importance distribution
that minimizes the variance of the importance weights in the RBPF case is
.uk j y1Wk; u.i/
0Wk1/ D p.uk j y1Wk; u.i/
0Wk1/
/ p.yk j uk; u.i/
0Wk1/ p.uk j u.i/
0Wk1; y1Wk1/: (7.48)
In general, normalizing this distribution or drawing samples from this dis-
tribution directly is not possible. But, if the latent variables uk are discrete,
we can normalize this distribution and use this optimal importance distri-
bution directly.
The class of models where Rao–Blackwellization of some linear state
components can be carried out can be extended beyond the conditionally
linear Gaussian models presented here. We can, for example, include ad-
ditional latent-variable dependent non-linear terms into the dynamic and
measurement models (Sch¨on et al., 2005). In some cases, when the ﬁlter-
ing model is not strictly Gaussian due to slight non-linearities in either the
dynamic or measurement models, it is possible to replace the exact Kalman
ﬁlter update and prediction steps in RBPF with the extended Kalman ﬁlter
(EKF), the unscented Kalman ﬁlter (UKF) prediction and update steps, or
with any other Gaussian approximation based ﬁlters (S¨arkk¨a et al., 2007b).
7.6 Exercises
7.1
Recall the following state space model from Exercise 3.1:
xk D
1
1
0
1

xk1 C qk1;
yk D

1
0
	
xk C rk;
(7.49)
where xk D .xk Pxk/T is the state, yk is the measurement, and qk 
N.0; diag.1=102; 12// and rk  N.0; 102/ are white Gaussian noise pro-
cesses.

Exercises
133
(a) Write down the Kalman ﬁlter equations for this model.
(b) Derive an expression for the optimal importance distribution for the
model:
.xk/ D p.xk j xk1; y1Wk/:
(7.50)
(c) Write pseudo-code for the corresponding particle ﬁlter algorithm (se-
quential importance resampling algorithm). Also write down the equa-
tions for the weight update.
(d) Compare the number of CPU steps (multiplications and additions)
needed by the particle ﬁlter and Kalman ﬁlter. Which implementation
would you choose for a real implementation?
7.2
Implement the bootstrap ﬁlter for the model in Exercise 5.1 and test its
performance against the non-linear Kalman ﬁlters.
7.3
Implement a sequential importance resampling ﬁlter with an EKF, UKF,
GHKF, or CKF based importance distribution for the model in Exercise 5.1.
Note that you might want to use a small non-zero covariance as the prior of
the previous step instead of plain zero to get the ﬁlters to work better.
7.4
Implement the bootstrap ﬁlter and SIR with the CKF importance distribution
for the bearings only target tracking model in Exercise 5.5. Plot the results
and compare the RMSE values to those of the non-linear Kalman ﬁlters.
7.5
Implement a Rao–Blackwellized particle ﬁlter for the following clutter
model (outlier model) :
xk D xk1 C qk1;
yk D
(
xk C rk;
if uk D 0;
rc
k;
if uk D 1;
(7.51)
where qk1  N.0; 1/, rk  N.0; 1/ and rc
k  N.0; 102/. The indicator
variables uk are modeled as independent random variables which take the
value uk D 0 with prior probability 0:9 and the value uk D 1 with prior
probability 0:1. Test the performance of the ﬁlter with simulated data and
compare the performance to a Kalman ﬁlter, where the clutter rc
k is ignored.
What is the optimal importance distribution for this model?

8
Bayesian smoothing equations and
exact solutions
So far in this book we have only considered ﬁltering algorithms which use
the measurements obtained before and at the current step for computing
the best possible estimate of the current state (and possibly future states).
However, sometimes it is also of interest to estimate states for each time
step conditional on all the measurements that we have obtained. This prob-
lem can be solved with Bayesian smoothing. In this chapter, we present
the Bayesian theory of smoothing. After that we derive the Rauch–Tung–
Striebel (RTS) smoother which is the closed form smoothing solution to
linear Gaussian models. We also brieﬂy discuss two-ﬁlter smoothers.
8.1 Bayesian smoothing equations
The purpose of Bayesian smoothing1 is to compute the marginal posterior
distribution of the state xk at the time step k after receiving the measure-
ments up to a time step T , where T > k:
p.xk j y1WT /:
(8.1)
The difference between ﬁlters and smoothers is that the Bayesian ﬁlter
computes its estimates using only the measurements obtained before and
at the time step k, but the Bayesian smoother uses also the future measure-
ments for computing its estimates. After obtaining the ﬁltering posterior
state distributions, the following theorem gives the equations for comput-
ing the marginal posterior distributions for each time step conditionally on
all the measurements up to the time step T .
Theorem 8.1 (Bayesian optimal smoothing equations)
The backward re-
cursive equations (the Bayesian smoother) for computing the smoothed
distributions p.xk j y1WT / for any k < T are given by the following
1 This deﬁnition actually applies to the ﬁxed-interval type of smoothing.
134

8.2 Rauch–Tung–Striebel smoother
135
Bayesian (ﬁxed-interval) smoothing equations (Kitagawa, 1987):
p.xkC1 j y1Wk/ D
Z
p.xkC1 j xk/ p.xk j y1Wk/ dxk;
p.xk j y1WT / D p.xk j y1Wk/
Z p.xkC1 j xk/ p.xkC1 j y1WT /
p.xkC1 j y1Wk/

dxkC1;
(8.2)
where p.xk j y1Wk/ is the ﬁltering distribution of the time step k. Note that
the term p.xkC1 j y1Wk/ is simply the predicted distribution of time step
k C 1. The integrations are replaced by summations if some of the state
components are discrete.
Proof
Due to the Markov properties the state xk is independent of ykC1WT
given xkC1, which gives p.xk j xkC1; y1WT / D p.xk j xkC1; y1Wk/. By us-
ing Bayes’ rule the distribution of xk given xkC1 and y1WT can be expressed
as
p.xk j xkC1; y1WT / D p.xk j xkC1; y1Wk/
D p.xk; xkC1 j y1Wk/
p.xkC1 j y1Wk/
D p.xkC1 j xk; y1Wk/ p.xk j y1Wk/
p.xkC1 j y1Wk/
D p.xkC1 j xk/ p.xk j y1Wk/
p.xkC1 j y1Wk/
:
(8.3)
The joint distribution of xk and xkC1 given y1WT can be now computed as
p.xk; xkC1 j y1WT / D p.xk j xkC1; y1WT / p.xkC1 j y1WT /
D p.xk j xkC1; y1Wk/ p.xkC1 j y1WT /
D p.xkC1 j xk/ p.xk j y1Wk/ p.xkC1 jy1WT /
p.xkC1 j y1Wk/
;
(8.4)
where p.xkC1 j y1WT / is the smoothed distribution of the time step k C
1. The marginal distribution of xk given y1WT is given by integration (or
summation) over xkC1 in Equation (8.4), which gives the desired result.
8.2 Rauch–Tung–Striebel smoother
The Rauch–Tung–Striebel smoother (RTSS, Rauch et al., 1965), which is
also called the Kalman smoother, can be used for computing the closed

136
Bayesian smoothing equations and exact solutions
form smoothing solution
p.xk j y1WT / D N.xk j ms
k; P s
k/
(8.5)
to the linear ﬁltering model (4.17). The difference from the solution com-
puted by the Kalman ﬁlter is that the smoothed solution is conditional on
the whole measurement data y1WT , while the ﬁltering solution is conditional
only on the measurements obtained before and at the time step k, that is,
on the measurements y1Wk.
Theorem 8.2 (RTS smoother)
The backward recursion equations for the
(ﬁxed interval) Rauch–Tung–Striebel smoother are given as
m
kC1 D Ak mk;
P 
kC1 D Ak Pk AT
k C Qk;
Gk D Pk AT
k ŒP 
kC11;
ms
k D mk C Gk Œms
kC1  m
kC1;
P s
k D Pk C Gk ŒP s
kC1  P 
kC1 GT
k;
(8.6)
where mk and Pk are the mean and covariance computed by the Kalman
ﬁlter. The recursion is started from the last time step T , with ms
T D mT and
P s
T D PT . Note that the ﬁrst two of the equations are simply the Kalman
ﬁlter prediction equations.
Proof
Similarly to the Kalman ﬁlter case, by Lemma A.1, the joint distri-
bution of xk and xkC1 given y1Wk is
p.xk; xkC1 j y1Wk/ D p.xkC1 j xk/ p.xk j y1Wk/
D N.xkC1 j Ak xk; Qk/ N.xk j mk; Pk/
D N
 xk
xkC1
 ˇˇˇ Qm1; QP1

;
(8.7)
where
Qm1 D
 mk
Ak mk

;
QP1 D
 Pk
Pk AT
k
Ak Pk
Ak Pk AT
k C Qk

:
(8.8)
Due to the Markov property of the states we have
p.xk j xkC1; y1WT / D p.xk j xkC1; y1Wk/;
(8.9)
and thus by Lemma A.2 we get the conditional distribution
p.xk j xkC1; y1WT / D p.xk j xkC1; y1Wk/
D N.xk j Qm2; QP2/;
(8.10)

8.2 Rauch–Tung–Striebel smoother
137
where
Gk D Pk AT
k .Ak Pk AT
k C Qk/1
Qm2 D mk C Gk .xkC1  Ak mk/
QP2 D Pk  Gk .Ak Pk AT
k C Qk/ GT
k:
(8.11)
The joint distribution of xk and xkC1 given all the data is
p.xkC1; xk j y1WT / D p.xk j xkC1; y1WT / p.xkC1 j y1WT /
D N.xk j Qm2; QP2/ N.xkC1 j ms
kC1; P s
kC1/
D N
xkC1
xk
 ˇˇˇ Qm3; QP3

;
(8.12)
where
Qm3 D

ms
kC1
mk C Gk .ms
kC1  Ak mk/

;
QP3 D
 P s
kC1
P s
kC1 GT
k
Gk P s
kC1
Gk P s
kC1 GT
k C QP2

:
(8.13)
Thus by Lemma A.2, the marginal distribution of xk is given as
p.xk j y1WT / D N.xk j ms
k; P s
k/;
(8.14)
where
ms
k D mk C Gk .ms
kC1  Ak mk/;
P s
k D Pk C Gk .P s
kC1  Ak Pk AT
k  Qk/ GT
k:
(8.15)
Example 8.1 (RTS smoother for Gaussian random walk)
The RTS
smoother for the random walk model given in Example 4.1 is given by the
equations
m
kC1 D mk;
P 
kC1 D Pk C Q;
ms
k D mk C
Pk
P 
kC1
.ms
kC1  m
kC1/;
P s
k D Pk C
 
Pk
P 
kC1
!2
ŒP s
kC1  P 
kC1;
(8.16)
where mk and Pk are the updated mean and covariance from the Kalman
ﬁlter in Example 4.2. The result of applying the smoother to simulated data

138
Bayesian smoothing equations and exact solutions
0
20
40
60
80
100
−10
−8
−6
−4
−2
0
2
4
6
Time step k
 xk
 
 
Filter Estimate
Smoother Estimate
Filter’s 95% Quantiles
Smoother’s 95% Quantiles
Figure 8.1 Filter and smoother estimates in the Gaussian random
walk smoothing example (Example 8.1).
is shown in Figure 8.1. The evolution of the ﬁlter and smoother variances
is illustrated in Figure 8.2.
Example 8.2 (RTS smoother for car tracking)
The backward recursion
equations required for implementing the RTS smoother for the car tracking
problem in Example 4.3 are the following:
m
kC1 D
0
BB@
1
0
t
0
0
1
0
t
0
0
1
0
0
0
0
1
1
CCA mk;
P 
kC1 D
0
BB@
1
0
t
0
0
1
0
t
0
0
1
0
0
0
0
1
1
CCA Pk
0
BB@
1
0
t
0
0
1
0
t
0
0
1
0
0
0
0
1
1
CCA
T
C
0
BBBB@
qc
1 t3
3
0
qc
1 t2
2
0
0
qc
2 t3
3
0
qc
2 t2
2
qc
1 t2
2
0
qc
1 t
0
0
qc
2 t2
2
0
qc
2 t
1
CCCCA
;

8.3 Two-ﬁlter smoothing
139
0
20
40
60
80
100
0.4
0.5
0.6
0.7
0.8
0.9
1
Time step k
Variance
 
 
Filter Variance
Smoother Variance
Figure 8.2 Filter and smoother variances in the Gaussian random
walk smoothing example (Example 8.1). The variance of the
smoother is always smaller than that of the ﬁlter. The only
exception is at the ﬁnal step, where the variances are the same.
Gk D Pk
0
BB@
1
0
t
0
0
1
0
t
0
0
1
0
0
0
0
1
1
CCA
T
ŒP 
kC11;
ms
k D mk C Gk Œms
kC1  m
kC1;
P s
k D Pk C Gk ŒP s
kC1  P 
kC1 GT
k:
The terms mk and Pk are the Kalman ﬁlter means and covariance com-
puted with the equations given in Example 4.3. It would also be possible to
store the values m
kC1 and P 
kC1 during Kalman ﬁltering to avoid recom-
putation of them in the ﬁrst two equations above. The gains Gk could be
computed already during the Kalman ﬁltering as well. The result of apply-
ing the RTS smoother to simulated data is shown in Figure 8.3.
8.3 Two-ﬁlter smoothing
An alternative approach to the RTS-style forward–backward smoothing
is the two-ﬁlter smoothing approach. Although the approach has many
advantages, unfortunately in the non-linear case it requires construction

140
Bayesian smoothing equations and exact solutions
−4
−2
0
2
4
6
8
10
12
−12
−10
−8
−6
−4
−2
0
2
 x1
 x2
 
 
True Trajectory
Measurements
Smoother Estimate
Figure 8.3 Simulated trajectory, measurements and the result of
RTS smoother based car tracking in Example 4.3. The starting
point is at the top of the trajectory. The RMSE position error
based on the measurements only is 0:77, the position RMSE of
the Kalman ﬁlter estimate is 0:43 and the error of the RTS
smoother is 0:27. It can be seen that the estimate is much
“smoother” than the result of the Kalman ﬁlter in Figure 4.5.
of artiﬁcial probability densities which ensure that the backward ﬁlter is
normalizable. Due to this challenge, in this chapter we base the smoothing
algorithms on the forward–backward smoothing approach and only brieﬂy
outline the idea of two-ﬁlter smoothing here.
The two-ﬁlter smoother formulations of Fraser and Potter (1969) and
Kitagawa (1994) are based on the following representation of the smooth-
ing distribution:
p.xk j y1Wn/ / p.xk j y1Wk1/ p.ykWn j xk/:
(8.17)
The ﬁrst term on the right is just the result of the Bayesian ﬁlter just after
prediction on the step k  1. The second term on the right can be evaluated

8.3 Two-ﬁlter smoothing
141
by using the following backward recursions:
p.ykC1Wn j xk/ D
Z
p.ykC1Wn; xkC1 j xk/ dxkC1
D
Z
p.ykC1Wn j xkC1; xk/ p.xkC1 j xk/ dxkC1
D
Z
p.ykC1Wn j xkC1/ p.xkC1 j xk/ dxkC1;
(8.18)
p.ykWn j xk/ D p.ykC1Wn; yk j xk/
D p.ykC1Wn j xk/ p.yk j ykC1Wn; xk/
D p.ykC1Wn j xk/ p.yk j xk/:
(8.19)
The classical linear two-ﬁlter smoother (Fraser and Potter, 1969) can be
derived from the general equations by assuming that we have
p.ykWn j xk/ / N.xk j mb
k; P b
k/;
(8.20)
for some mean mb
k and covariance P b
k. This results in recursions which
resemble a Kalman ﬁlter which runs backwards in time. However, it turns
out that at the initial steps of the backward recursions the distributions are
not normalizable, because the covariances P b
k are formally singular. In the
formulation of Fraser and Potter (1969) this problem is avoided by using
the so-called information ﬁlter, which is a formulation of the Kalman ﬁlter
in terms of inverses of covariance matrices instead of the plain covariances.
Unfortunately, when starting from Equations (8.18) and (8.19), it is dif-
ﬁcult to go beyond the linear case because, in the more general case, a
simple information ﬁlter formulation does not work. For example, there
is no Monte Carlo version of an information ﬁlter. It is indeed possible
to form reasonable approximations by forming backward dynamic models
by using, for example, the unscented transform (Wan and Van der Merwe,
2001), but in general this might not lead to good or valid approximations
(Briers et al., 2010). The key problem is that p.ykWn j xk/ is not generally
normalizable with respect to xk, that is, we have
R
p.ykWn j xk/ dxk D 1.
One solution to the problem was presented by Briers et al. (2010), who
proposed a generalized version of the two-ﬁlter smoothing formulas of
Kitagawa (1994). The solution is based on the introduction of artiﬁcial
probability densities f
k.xk/g such that if p.ykWn j xk/ > 0 then 
k.xk/ >
0. The backward recursions are then replaced with the following recur-

142
Bayesian smoothing equations and exact solutions
sions:
Qp.xk j ykC1Wn/ D
Z
Qp.xkC1 j ykC1Wn/ p.xkC1 j xk/ 
k.xk/

kC1.xkC1/
dxkC1;
(8.21)
Qp.xk j ykWn/ D
Qp.xk j ykC1Wn/ p.yk j xk/
R
Qp.xk j ykC1Wn/ p.yk j xk/ dxk
;
(8.22)
where Qp.xk j ykWn/ is an auxiliary probability density such that
p.ykWn j xk/ / Qp.xk j ykWn/

k.xk/
:
(8.23)
From this starting point it is possible to derive particle based smoothing
algorithms as well as other non-linear two-ﬁlter smoothers provided that
we can select the artiﬁcial probability densities suitably. For details, the
reader is referred to Briers et al. (2010).
8.4 Exercises
8.1
Derive the linear RTS smoother for the non-zero-mean noise model in Exer-
cise 4.1.
8.2
Write down the Bayesian smoothing equations for ﬁnite-state HMM
models described in Exercise 4.2 assuming that the ﬁltering distributions
p.xk j y1Wk/ have already been computed.
8.3
Implement the Gaussian random walk model smoother in Example 8.1 and
compare its performance to the corresponding Kalman ﬁlter. Plot the evolu-
tion of the smoothing distribution.
8.4
The Gaussian random walk model considered in Example 4.1 also deﬁnes
a joint Gaussian prior distribution p.x0; : : : ; xT /. The measurement model
p.y1; : : : ; yT j x0; : : : ; xT / is Gaussian as well. Construct these distribu-
tions and compute the posterior distribution p.x0; : : : ; xT j y1; : : : ; yT /.
Check numerically that the mean and the diagonal covariance entries of this
distribution exactly match the smoother means and variances.
8.5
Form a grid-based approximation to the Gaussian random walk model
smoother in the same way as was done for the ﬁltering equations in
Exercise 4.4. Verify that the result is practically the same as in the RTS
smoother above.
8.6
Write down the smoother equations for the Gaussian random walk model,
when the stationary ﬁlter is used as the ﬁlter. Note that the smoother be-
comes a stationary backward ﬁlter. Compare the performance of this sta-
tionary smoother to that of the non-stationary smoother.

Exercises
143
8.7
Implement the RTS smoother for the resonator model in Exercise 4.6. Com-
pare its RMSE performance to the ﬁltering and baseline solutions and plot
the results.

9
Extended and unscented smoothing
In this chapter we present the linearization, statistical linearization, and
unscented transform based RTS smoothers, which are based on analogous
approximations to the EKF, SLF, and UKF presented in Chapter 5. These
smoothers can be used for forming Gaussian approximations to the
Bayesian smoothing solutions for non-linear state space models.
9.1 Extended Rauch–Tung–Striebel smoother
The ﬁrst order (i.e., linearized) extended Rauch–Tung–Striebel smoother
(ERTSS) (Cox, 1964; Sage and Melsa, 1971) can be obtained from the
basic RTS smoother equations by replacing the prediction equations with
ﬁrst order approximations. Higher order extended Kalman smoothers are
also possible (see, e.g., Cox, 1964; Sage and Melsa, 1971), but only the
ﬁrst order version is presented here. The ERTSS forms (or assumes) a
Gaussian approximation to the smoothing distribution as follows:
p.xk j y1WT / ' N.xk j ms
k; P s
k/:
(9.1)
For the additive model Equation (5.24) the extended Rauch–Tung–Striebel
smoother algorithm is the following.
Algorithm 9.1 (Extended RTS smoother)
The equations for the extended
RTS smoother are
m
kC1 D f.mk/;
P 
kC1 D Fx.mk/ Pk F T
x.mk/ C Qk;
Gk D Pk F T
x.mk/ ŒP 
kC11;
ms
k D mk C Gk Œms
kC1  m
kC1;
P s
k D Pk C Gk ŒP s
kC1  P 
kC1 GT
k;
(9.2)
where the matrix Fx.mk/ is the Jacobian matrix of f.x/ evaluated at mk.
144

9.1 Extended Rauch–Tung–Striebel smoother
145
The above procedure is a recursion which can be used for computing
the smoothing distribution of time step k from the smoothing distribution
of time step k C 1. Because the smoothing distribution and ﬁltering distri-
bution of the last time step T are the same, we have ms
T D mT , P s
T D PT ,
and thus the recursion can be used for computing the smoothing distribu-
tions of all time steps by starting from the last step k D T and proceeding
backwards to the initial step k D 0.
Derivation
Assume that the ﬁltering distributions for the model (5.24)
are approximately Gaussian:
p.xk j y1Wk/ ' N.xk j mk; Pk/;
and we have already computed the means and covariance using the ex-
tended Kalman ﬁlter or a similar method. Further assume that the smooth-
ing distribution of time step k C 1 is known and approximately Gaussian
p.xkC1 j y1WT / ' N.xkC1 j ms
kC1; P s
kC1/:
As in the derivation of the prediction step of the EKF in Section 5.2, the
approximate joint distribution of xk and xkC1 given y1Wk is
p.xk; xkC1 j y1Wk/ D N
 xk
xkC1
 ˇˇˇ Qm1; QP1

;
(9.3)
where
Qm1 D
 mk
f.mk/

;
QP1 D
 Pk
Pk F T
x
Fx Pk
Fx Pk F T
x C Qk

;
(9.4)
and the Jacobian matrix Fx of f.x/ is evaluated at x D mk. By condition-
ing on xkC1 as in the RTS derivation in Section 8.2 we get
p.xk j xkC1; y1WT / D p.xk j xkC1; y1Wk/
D N.xk j Qm2; QP2/;
(9.5)
where
Gk D Pk F T
x .Fx Pk F T
x C Qk/1;
Qm2 D mk C Gk .xkC1  f.mk//;
QP2 D Pk  Gk .Fx Pk F T
x C Qk/ GT
k:
(9.6)

146
Extended and unscented smoothing
The joint distribution of xk and xkC1 given all the data is now
p.xkC1; xk j y1WT / D p.xk j xkC1; y1WT / p.xkC1 j y1WT /
D N
xkC1
xk
 ˇˇˇ Qm3; QP3

;
(9.7)
where
Qm3 D

ms
kC1
mk C Gk .ms
kC1  f.mk//

;
QP3 D
 P s
kC1
P s
kC1 GT
k
Gk P s
kC1
Gk P s
kC1 GT
k C QP2

:
(9.8)
The marginal distribution of xk is then
p.xk j y1WT / D N.xk j ms
k; P s
k/;
(9.9)
where
ms
k D mk C Gk .ms
kC1  f.mk//;
P s
k D Pk C Gk .P s
kC1  Fx Pk F T
x  Qk/ GT
k:
(9.10)
The generalization to the non-additive model (5.37) is analogous to the
ﬁltering case – we just need to replace the ﬁrst two of Equations (9.2) with
their non-additive versions as in Algorithm 5.5.
Example 9.1 (Pendulum tracking with ERTSS)
The result of applying the
ERTSS to the pendulum model in Example 5.1 is shown in Figure 9.1. The
resulting RMSE was 0:033, which is much lower than the error of the EKF
which was 0:12. It is also much lower than the errors of any other ﬁlters,
which were in the range 0:10–0:12.
9.2 Statistically linearized Rauch–Tung–Striebel smoother
The statistically linearized Rauch–Tung–Striebel smoother (SLRTSS) is
analogous to the extended Rauch–Tung–Striebel smoother, except that we
use statistical linearization instead of ordinary linearization. The statis-
tically linearized Rauch–Tung–Striebel smoother for the additive model
(5.24) is the following.

9.2 Statistically linearized Rauch–Tung–Striebel smoother
147
0.5
1
1.5
2
2.5
3
3.5
4
4.5
−3
−2
−1
0
1
2
3
4
5
Time t
Pendulum angle x1,k
 
 
True Angle
Measurements
ERTSS Estimate
Figure 9.1 Simulated pendulum data and the result of tracking
the pendulum described in Example 5.1 with the ERTSS. The
resulting RMSE is 0:033 (recall that the RMSE of the EKF was
0:12).
Algorithm 9.2 (Statistically linearized RTS smoother)
The equations for
the statistically linearized RTS smoother are
m
kC1 D EŒf.xk/;
P 
kC1 D EŒf.xk/ ıxT
k P 1
k
EŒf.xk/ ıxT
kT C Qk;
Gk D EŒf.xk/ ıxT
kT ŒP 
kC11;
ms
k D mk C Gk Œms
kC1  m
kC1;
P s
k D Pk C Gk ŒP s
kC1  P 
kC1 GT
k;
(9.11)
where the expectations are taken with respect to the ﬁltering distribution
xk  N.mk; Pk/.
The generalization to the non-additive case is also straightforward and
just amounts to replacing the ﬁrst two of Equations (9.11) with their non-
additive versions as in Algorithm 5.8. In the gain computation we then also
need to average over qk.
It is also possible to use Equation (5.61) for rewriting the cross-terms
above in terms of Jacobians of f, but this is left as an exercise to the
reader. The SLRTSS can also be considered as a ﬁrst order truncation of the

148
Extended and unscented smoothing
0.5
1
1.5
2
2.5
3
3.5
4
4.5
−3
−2
−1
0
1
2
3
4
5
Time t
Pendulum angle x1,k
 
 
True Angle
Measurements
SLRTSS Estimate
Figure 9.2 Simulated pendulum data and the result of tracking
the pendulum described in Example 5.1 with the SLRTSS. The
resulting RMSE is 0:028 which is slightly lower than the error of
the ERTSS (which was 0:033).
Fourier–Hermite Rauch–Tung–Striebel smoother (FHRTSS, Sarmavuori
and S¨arkk¨a, 2012b), where this derivative version also arises naturally.
Example 9.2 (Pendulum tracking with SLRTSS)
The result of applying
the SLRTSS to the pendulum model in Example 5.1 is shown in Figure 9.2.
The resulting RMSE error of 0:028 is slightly lower than the error of the
ERTSS which was 0:033. The error is also signiﬁcantly lower than errors
of any of the ﬁlters, which were in the range 0:10–0:12.
9.3 Unscented Rauch–Tung–Striebel smoother
The unscented Rauch–Tung–Striebel smoother (URTSS,
S¨arkk¨a, 2006;
ˇSimandl and Dun´ık, 2006; S¨arkk¨a, 2008) is a Gaussian approximation
based smoother where the non-linearity is approximated using the un-
scented transform. The smoother equations for the additive model (5.37)
are given as follows.
Algorithm 9.3 (Unscented Rauch–Tung–Striebel smoother I)
The addi-
tive form unscented RTS smoother algorithm is the following.

9.3 Unscented Rauch–Tung–Striebel smoother
149
1 Form the sigma points:
X .0/
k
D mk;
X .i/
k
D mk C
p
n C 
hp
Pk
i
i ;
X .iCn/
k
D mk 
p
n C 
hp
Pk
i
i ;
i D 1; : : : ; n;
(9.12)
where the parameter  was deﬁned in Equation (5.75).
2 Propagate the sigma points through the dynamic model:
OX .i/
kC1 D f.X .i/
k /;
i D 0; : : : ; 2n:
3 Compute the predicted mean m
kC1, the predicted covariance P 
kC1, and
the cross-covariance DkC1:
m
kC1 D
2n
X
iD0
W .m/
i
OX .i/
kC1;
P 
kC1 D
2n
X
iD0
W .c/
i
. OX .i/
kC1  m
kC1/ . OX .i/
kC1  m
kC1/T C Qk;
DkC1 D
2n
X
iD0
W .c/
i
.X .i/
k
 mk/ . OX .i/
kC1  m
kC1/T;
(9.13)
where the weights were deﬁned in Equation (5.77).
4 Compute the smoother gain Gk, the smoothed mean ms
k, and the covari-
ance P s
k as follows:
Gk D DkC1 ŒP 
kC11;
ms
k D mk C Gk .ms
kC1  m
kC1/;
P s
k D Pk C Gk .P s
kC1  P 
kC1/ GT
k:
(9.14)
The above computations are started from the ﬁltering result of the last
time step ms
T D mT , P s
T D PT and the recursion runs backwards for
k D T  1; : : : ; 0.
Derivation
Assume that the approximate means and covariances of the
ﬁltering distributions are available:
p.xk j y1Wk/ ' N.xk j mk; Pk/;
and the smoothing distribution of time step k C 1 is known and approxi-
mately Gaussian:
p.xkC1 j y1WT / ' N.xkC1 j ms
kC1; P s
kC1/:

150
Extended and unscented smoothing
An unscented transform based approximation to the optimal smoothing
solution can be derived as follows.
1 Generate an unscented transform based Gaussian approximation to the
joint distribution of xk and xkC1:
p.xk; xkC1 j y1Wk/ ' N
  xk
xkC1
 ˇˇˇˇˇ
 mk
m
kC1

;
 Pk
DkC1
DT
kC1
P 
kC1
!
:
(9.15)
This can be done by using the additive form of the unscented transfor-
mation in Algorithm 5.12 for the non-linearity xkC1 D f.xk/Cqk. This
is done in Equations (9.13).
2 Because the distribution (9.15) is Gaussian, by the computation rules of
Gaussian distributions the conditional distribution of xk is given as
p.xk j xkC1; y1WT / ' N.xk j Qm2; QP2/;
where
Gk D DkC1 ŒP 
kC11;
Qm2 D mk C Gk.xkC1  m
kC1/;
QP2 D Pk  Gk P 
kC1 GT
k:
3 The rest of the derivation is completely analogous to the derivation of
the ERTSS in Section 9.1.
The corresponding augmented version of the smoother for non-additive
models of the form (5.37) is almost the same, except that the augmented
UT in Algorithm 5.13 is used instead of the additive UT in Algorithm 5.12.
The smoother can be formulated as follows (S¨arkk¨a, 2008).
Algorithm 9.4 (Unscented Rauch–Tung–Striebel smoother II)
A single
step of the augmented form unscented RTS smoother for non-additive
models is as follows.

9.3 Unscented Rauch–Tung–Striebel smoother
151
1 Form the sigma points for the n0 D n C nq -dimensional augmented
random variable .xk; qk/:
QX .0/
k
D Qmk;
QX .i/
k
D Qmk C
p
n0 C 0
q
QPk

i
;
QX .iCn0/
k
D Qmk 
p
n0 C 0
q
QPk

i
;
i D 1; : : : ; n0;
(9.16)
where
Qmk D
mk
0

;
QPk D
Pk
0
0
Qk

:
2 Propagate the sigma points through the dynamic model:
OX .i/
kC1 D f. QX .i/;x
k
; QX .i/;q
k
/;
i D 0; : : : ; 2n0;
where QX .i/;x
k
and QX .i/;q
k
denote the parts of the augmented sigma point
i which correspond to xk and qk, respectively.
3 Compute the predicted mean m
kC1, the predicted covariance P 
kC1, and
the cross-covariance DkC1:
m
kC1 D
2n0
X
iD0
W .m/0
i
OX .i/
kC1;
P 
kC1 D
2n0
X
iD0
W .c/0
i
. OX .i/
kC1  m
kC1/ . OX .i/
kC1  m
kC1/T;
DkC1 D
2n0
X
iD0
W .c/0
i
. QX .i/;x
k
 mk/ . OX .i/
kC1  m
kC1/T;
(9.17)
where the deﬁnitions of the parameter 0 and the weights W .m/0
i
and
W .c/0
i
are the same as in Section 5.5.
4 Compute the smoother gain Gk, the smoothed mean ms
k, and the covari-
ance P s
k:
Gk D DkC1 ŒP 
kC11;
ms
k D mk C Gk

ms
kC1  m
kC1

;
P s
k D Pk C Gk

P s
kC1  P 
kC1

GT
k:
(9.18)

152
Extended and unscented smoothing
0.5
1
1.5
2
2.5
3
3.5
4
4.5
−3
−2
−1
0
1
2
3
4
5
Time t
Pendulum angle x1,k
 
 
True Angle
Measurements
URTSS Estimate
Figure 9.3 Simulated pendulum data and the result of tracking
the pendulum described in Example 5.1 with the URTSS. The
resulting RMSE is 0:028 which is the same as with the SLRTSS.
Recall that the RMSE of the UKF was 0:11.
Example 9.3 (Pendulum tracking with URTSS)
The result of applying the
URTSS to the pendulum model in Example 5.1 is shown in Figure 9.3. The
resulting RMSE is 0:028 which is the same as for the SLRTSS and lower
than that of the ETRSS which is 0:033. Thus we get the same error with the
URTSS as with statistical linearization but without needing to compute the
analytical expectations.
9.4 Exercises
9.1
Derive and implement the extended RTS smoother to the model in Exer-
cise 5.1 and compare the errors of ﬁlters and smoothers.
9.2
Write down the detailed derivation of the (additive form) statistically lin-
earized RTS smoother. You can follow the same steps as in the derivation of
the extended RTS smoother.
9.3
Derive and implement the statistically linearized RTS smoother to the model
in Exercise 5.1 and compare the errors of ﬁlters and smoothers.
9.4
In Exercise 5.3 you derived an alternative (derivative) form of the SLF. Write
down the corresponding alternative form of the SLRTS. Derive the smooth-
ing equations for the model in Exercise 9.3 above and compare the equations
that you obtain with the equations obtained in Exercise 9.3.

Exercises
153
9.5
Implement the unscented transform based RTS smoother to the model in
Exercise 5.1 and compare the errors of ﬁlters and smoothers.
9.6
Implement the RTS smoother to the bearings only target tracking problem in
Exercise 5.5. Note that even though the full model is non-linear, due to the
linear dynamic model the smoother is linear.

10
General Gaussian smoothing
As pointed out by S¨arkk¨a and Hartikainen (2010a), the unscented Rauch–
Tung–Striebel smoother (URTSS) can be considered a special case of more
general non-linear Gaussian smoothers, in the same way as the UKF is
a special case of Gaussian ﬁlters. In this chapter we present the Gauss-
ian smoother and Gauss–Hermite cubature and spherical cubature integra-
tion based approximations. We also discuss Gaussian approximation based
ﬁxed-lag and ﬁxed-point smoothers.
10.1 General Gaussian Rauch–Tung–Striebel smoother
The Gaussian moment matching described in Section 6.1 can be used in
smoothers in an analogous manner to the Gaussian ﬁlters in Section 6.2. If
we follow the extended RTS smoother derivation in Section 9.1, we get the
following algorithm (S¨arkk¨a and Hartikainen, 2010a).
Algorithm 10.1 (Gaussian RTS smoother I)
The equations of the additive
form Gaussian RTS smoother are the following:
m
kC1 D
Z
f.xk/ N.xk j mk; Pk/ dxk;
P 
kC1 D
Z
Œf.xk/  m
kC1 Œf.xk/  m
kC1T N.xk j mk; Pk/ dxk C Qk;
DkC1 D
Z
Œxk  mk Œf.xk/  m
kC1T N.xk j mk; Pk/ dxk;
Gk D DkC1 ŒP 
kC11;
ms
k D mk C Gk .ms
kC1  m
kC1/;
P s
k D Pk C Gk .P s
kC1  P 
kC1/ GT
k:
(10.1)
The integrals above can be approximated using analogous numerical
integration or analytical approximation schemes as in the ﬁltering case, that
154

10.2 Gauss–Hermite Rauch–Tung–Striebel smoother
155
is, with Gauss–Hermite cubatures (Ito and Xiong, 2000; Wu et al., 2006),
spherical cubature rules (Arasaratnam and Haykin, 2009), or with many
other numerical integration schemes. In the non-additive case the Gaussian
smoother becomes the following (S¨arkk¨a and Hartikainen, 2010a).
Algorithm 10.2 (Gaussian RTS smoother II)
The equations of the non-
additive form Gaussian RTS smoother are the following:
m
kC1 D
Z
f.xk; qk/ N.xk j mk; Pk/ N.qk j 0; Qk/ dxk dqk;
P 
kC1 D
Z
Œf.xk; qk/  m
kC1 Œf.xk; qk/  m
kC1T
 N.xk j mk; Pk/ N.qk j 0; Qk/ dxk dqk;
DkC1 D
Z
Œxk  mk Œf.xk; qk/  m
kC1T
 N.xk j mk; Pk/ N.qk j 0; Qk/ dxk dqk;
Gk D DkC1 ŒP 
kC11;
ms
k D mk C Gk .ms
kC1  m
kC1/;
P s
k D Pk C Gk .P s
kC1  P 
kC1/ GT
k:
(10.2)
As in the Gaussian ﬁltering case, the above algorithms are mainly theo-
retical, because the integrals can be solved in closed form only in special
cases.
10.2 Gauss–Hermite Rauch–Tung–Striebel smoother
By using the Gauss–Hermite cubature integration approximation from Sec-
tion 6.3 in the additive form Gaussian RTS smoother, we get the following
Gauss–Hermite Rauch–Tung–Striebel smoother (GHRTSS) algorithm.
Algorithm 10.3 (Gauss–Hermite Rauch–Tung–Striebel smoother)
The
additive form Gauss–Hermite RTS smoother algorithm is the following.
1 Form the sigma points as
X .i1;:::;in/
k
D mk C
p
Pk .i1;:::;in/;
i1; : : : ; in D 1; : : : ; p;
(10.3)
where the unit sigma points .i1;:::;in/ were deﬁned in Equation (6.24).
2 Propagate the sigma points through the dynamic model:
OX .i1;:::;in/
kC1
D f.X .i1;:::;in/
k
/;
i1; : : : ; in D 1; : : : ; p:
(10.4)

156
General Gaussian smoothing
3 Compute the predicted mean m
kC1, the predicted covariance P 
kC1, and
the cross-covariance DkC1:
m
kC1 D
X
i1;:::;in
Wi1;:::;in OX .i1;:::;in/
kC1
;
P 
kC1 D
X
i1;:::;in
Wi1;:::;in. OX .i1;:::;in/
kC1
 m
kC1/ . OX .i1;:::;in/
kC1
 m
kC1/T C Qk;
DkC1 D
X
i1;:::;in
Wi1;:::;in.X .i1;:::;in/
k
 mk/ . OX .i1;:::;in/
kC1
 m
kC1/T;
(10.5)
where the weights Wi1;:::;in were deﬁned in Equation (6.23).
4 Compute the gain Gk, mean ms
k and covariance P s
k as follows:
Gk D DkC1 ŒP 
kC11;
ms
k D mk C Gk .ms
kC1  m
kC1/;
P s
k D Pk C Gk .P s
kC1  P 
kC1/ GT
k:
(10.6)
It would also be possible to formulate a non-additive version of the
above smoother analogously, but due to unpleasant exponential compu-
tational scaling of the Gauss–Hermite cubature method in the state dimen-
sion, that extension is not very useful in practice. Recall that the state di-
mension doubles when using the non-additive transform, because we need
to integrate over the state and process noise jointly.
Example 10.1 (Pendulum tracking with GHRTSS)
The result of applying
GHRTSS to the pendulum model in Example 5.1 is shown in Figure 10.1.
The resulting RMSE error is 0:028, which is the same as what we obtained
with the SLRTS and URTSS. Recall that the error of the ERTSS was a bit
higher, 0:033. However, it seems that using the higher order integration
method does not really help much in this particular problem, as we already
concluded when comparing the performance of the GHKF to the other
ﬁlters in this same problem.
10.3 Cubature Rauch–Tung–Striebel smoother
By using the third order spherical cubature approximation (Section 6.5) to
the additive form Gaussian RTS smoother, we get the following cubature
Rauch–Tung–Striebel smoother (CRTSS) algorithm (see Arasaratnam and
Haykin, 2011).

10.3 Cubature Rauch–Tung–Striebel smoother
157
0.5
1
1.5
2
2.5
3
3.5
4
4.5
−3
−2
−1
0
1
2
3
4
5
Time t
Pendulum angle x1,k
 
 
True Angle
Measurements
GHRTSS Estimate
Figure 10.1 Simulated pendulum data and the result of tracking
the pendulum described in Example 5.1 with the GHRTSS. The
resulting RMSE is 0:028, which is the same as with the other
smoothers encountered so far (except the ERTSS which had error
0:033).
Algorithm 10.4 (Cubature Rauch–Tung–Striebel smoother I)
The addi-
tive form cubature RTS smoother algorithm is the following.
1 Form the sigma points:
X .i/
k
D mk C
p
Pk .i/;
i D 1; : : : ; 2n;
(10.7)
where the unit sigma points are deﬁned as
.i/ D
( pn ei;
i D 1; : : : ; n;
pn ein;
i D n C 1; : : : ; 2n;
(10.8)
where ei denotes a unit vector in the direction of the coordinate axis i.
2 Propagate the sigma points through the dynamic model:
OX .i/
kC1 D f.X .i/
k /;
i D 1; : : : ; 2n:

158
General Gaussian smoothing
3 Compute the predicted mean m
kC1, the predicted covariance P 
kC1, and
the cross-covariance DkC1:
m
kC1 D 1
2n
2n
X
iD1
OX .i/
kC1;
P 
kC1 D 1
2n
2n
X
iD1
. OX .i/
kC1  m
kC1/ . OX .i/
kC1  m
kC1/T C Qk;
DkC1 D 1
2n
2n
X
iD1
.X .i/
k
 mk/ . OX .i/
kC1  m
kC1/T:
(10.9)
4 Compute the gain Gk, mean ms
k and covariance P s
k as follows:
Gk D DkC1 ŒP 
kC11;
ms
k D mk C Gk .ms
kC1  m
kC1/;
P s
k D Pk C Gk .P s
kC1  P 
kC1/ GT
k:
(10.10)
By using the third order spherical cubature approximation to the non-
additive form Gaussian RTS smoother, we get the following algorithm.
Algorithm 10.5 (Cubature Rauch–Tung–Striebel smoother II)
A single
step of the augmented form cubature RTS smoother is as follows.
1 Form the sigma points for the n0 D n C nq-dimensional augmented
random variable .xk; qk/:
QX .i/
k
D Qmk C
q
QPk .i/0;
i D 1; : : : ; 2n0;
(10.11)
where
Qmk D
mk
0

;
QPk D
Pk
0
0
Qk

:
2 Propagate the sigma points through the dynamic model:
OX .i/
kC1 D f. QX .i/;x
k
; QX .i/;q
k
/;
i D 1; : : : ; 2n0;
where QX .i/;x
k
and QX.i/;q
k
denote the parts of the augmented sigma point i
which correspond to xk and qk, respectively.

10.4 General ﬁxed-point smoother equations
159
3 Compute the predicted mean m
kC1, the predicted covariance P 
kC1, and
the cross-covariance DkC1:
m
kC1 D
1
2n0
2n0
X
iD1
OX .i/
kC1;
P 
kC1 D
1
2n0
2n0
X
iD1
. OX .i/
kC1  m
kC1/ . OX .i/
kC1  m
kC1/T;
DkC1 D
1
2n0
2n0
X
iD1
. QX .i/;x
k
 mk/ . OX .i/
kC1  m
kC1/T:
(10.12)
4 Compute the gain Gk, mean ms
k, and covariance P s
k:
Gk D DkC1 ŒP 
kC11;
ms
k D mk C Gk

ms
kC1  m
kC1
	
;
P s
k D Pk C Gk

P s
kC1  P 
kC1
	
GT
k:
(10.13)
It is easy to see that the above algorithms are indeed special cases of the
URTSS methods with parameters ˛ D 1, ˇ D 0,  D 0. However, this
particular selection of parameters tends to work well in practice and due
to the simplicity of sigma-point and weight selection rules, the method is
very simple to implement.
Example 10.2 (Pendulum tracking with CRTSS)
The result of applying
the CRTSS for the pendulum model in Example 5.1 is shown in Figure 10.2.
As expected, the error 0:028 and the overall result are practically identical
to the result of the URTSS, as well as to the SLRTSS and GHRTSS.
10.4 General ﬁxed-point smoother equations
The smoother algorithms that we have considered this far have all been
ﬁxed-interval smoothing algorithms, which can be used for computing es-
timates of a ﬁxed time interval of states given the measurements on the
same interval. However, there exist a couple of other types of smoothing
problem as well.
 Fixed-point smoothing refers to a methodology which can be used for
efﬁciently computing the optimal estimate of the initial state or some
other ﬁxed-time state of a state space model, given an increasing number
of measurements after it. This kind of estimation problem arises, for
example, in estimation of the state of a spacecraft at a given point of time

160
General Gaussian smoothing
0.5
1
1.5
2
2.5
3
3.5
4
4.5
−3
−2
−1
0
1
2
3
4
5
Time t
Pendulum angle x1,k
 
 
True Angle
Measurements
CRTSS Estimate
Figure 10.2 Simulated pendulum data and the result of tracking
the pendulum described in Example 5.1 with the CRTSS. The
resulting RMSE is 0:028, which is the same as with the other
Gaussian approximation based non-linear RTS smoothers, except
the ETRSS.
in the past (Meditch, 1969) or in alignment and calibration of inertial
navigation systems (Grewal et al., 1988).
 Fixed-lag smoothing is a methodology for computing delayed estimates
of state space models given measurements up to the current time and a
constant horizon in the future. Fixed-lag smoothing can be considered
as optimal ﬁltering, where a constant delay is tolerated in the estimates.
Potential applications of ﬁxed-lag smoothing are all the problems where
optimal ﬁlters are typically applied, and where the small delay is toler-
ated. An example of such application is digital demodulation (Tam et al.,
1973).
The presentation here is based on the results presented in S¨arkk¨a and Har-
tikainen (2010a), except that the derivations are presented in a bit more
detail than in the original reference.
The general ﬁxed-interval RTS smoothers described in this book have
the property that, given the gain sequence, we only need linear operations
for performing the smoothing and, in this sense, the smoothing is a com-
pletely linear operation. The only non-linear operations in the smoother are
in the approximations of the Gaussian integrals. However, these operations

10.4 General ﬁxed-point smoother equations
161
are performed on the ﬁltering results and thus we can compute the smooth-
ing gain sequence Gk from the ﬁltering results in a causal manner. Because
of these properties we may now derive a ﬁxed-point smoother using simi-
lar methods as have been used for deriving the linear ﬁxed-point smoother
from the linear Rauch–Tung–Striebel smoother in Meditch (1969).
We will now denote the smoothing means and covariances using nota-
tion of the type mkjn and Pkjn, which refer to the mean and covariance of
the state xk, which is conditioned to the measurements y1; : : : ; yn. With
this notation, the ﬁlter estimates are mkjk, Pkjk and the RTS smoother es-
timates, which are conditioned to the measurements y1; : : : ; yT , have the
form mkjT , PkjT . The RTS smoothers have the following common recur-
sion equations:
Gk D DkC1 ŒPkC1jk1;
mkjT D mkjk C Gk

mkC1jT  mkC1jk
	
;
PkjT D Pkjk C Gk

PkC1jT  PkC1jk
	
GT
k;
(10.14)
which are indeed linear recursion equations for the smoother mean and co-
variance. Note that the gains Gk depend only on the ﬁltering results, not on
the smoother mean and covariance. Because the gains Gk are independent
of T , from Equations (10.14) we get for i D j; : : : ; k the identity
mijk  miji D GiŒmiC1jk  miC1ji:
(10.15)
Similarly, for i D j; : : : ; k  1 we have
mijk1  miji D GiŒmiC1jk1  miC1ji:
(10.16)
Subtracting these equations gives the identity
mijk  mijk1 D GiŒmiC1jk  miC1jk1:
(10.17)
By varying i from j to k  1 we get the identities
mj jk  mj jk1 D GjŒmj C1jk  mj C1jk1;
mj C1jk  mj C1jk1 D Gj C1Œmj C2jk  mj C2jk1;
:::
mk1jk  mk1jk1 D Gk1Œmkjk  mkjk1:
(10.18)
If we sequentially substitute the above equations to each other starting from
the last and proceeding to the ﬁrst, we get the equation
mj jk D mj jk1 C Bj jkŒmkjk  mkjk1;
(10.19)

162
General Gaussian smoothing
where
Bj jk D Gj      Gk1:
(10.20)
Analogously, for the covariance we get
Pj jk D Pj jk1 C Bj jkŒPkjk  Pkjk1BT
j jk:
(10.21)
Algorithm 10.6 (General Gaussian ﬁxed-point smoother)
The general
Gaussian ﬁxed-point smoother algorithm for smoothing the time point j
can be implemented by performing the following operations at each time
step k D 1; 2; 3; : : :
1 Gain computation: Compute the predicted mean mkjk1, predicted co-
variance Pkjk1 and cross-covariance Dk from the ﬁltering results. Then
compute the gain from the equation
Gk1 D Dk ŒPkjk11:
(10.22)
2 Fixed-point smoothing:
(a) If k < j, just store the ﬁltering result.
(b) If k D j, set Bj jj D I. The ﬁxed-point smoothed mean and covari-
ance on step j are equal to the ﬁltered mean and covariance mj jj
and Pj jj.
(c) If k > j, compute the smoothing gain and the ﬁxed-point smoother
mean and covariance:
Bj jk D Bj jk1Gk1;
mj jk D mj jk1 C Bj jkŒmkjk  mkjk1;
Pj jk D Pj jk1 C Bj jkŒPkjk  Pkjk1BT
j jk:
(10.23)
Because only a constant number of computations is needed on each time
step, the algorithm can be easily implemented in real time.
10.5 General ﬁxed-lag smoother equations
It is also possible to derive a general ﬁxed-lag smoother by using a similar
procedure as in the previous section. However, this approach will lead to a
numerically unstable algorithm, as we will see shortly. Let n be the number
of lags. From the ﬁxed-point smoother we get
mkn1jk D mkn1jk1
C Bkn1jkŒmkjk  mkjk1:
(10.24)

10.5 General ﬁxed-lag smoother equations
163
From the ﬁxed-interval smoother we get
mkn1jk D mkn1jkn1
C Gk1nŒmknjk  mknjkn1:
(10.25)
Equating the right-hand sides, and solving for mknjk while remembering
the identity Bknjk D G1
kn1Bkn1jk results in the smoothing equation
mknjk D mknjkn1
C G1
kn1Œmkn1jk1  mkn1jkn1
C BknjkŒmkjk  mkjk1:
(10.26)
Similarly, for covariance we get
Pknjk D Pknjkn1
C G1
kn1ŒPkn1jk1  Pkn1jkn1GT
kn1
C BknjkŒPkjk  Pkjk1BT
knjk:
(10.27)
Equations (10.26) and (10.27) can, in principle, be used for recursively
computing the ﬁxed-lag smoothing solution. The number of computations
does not depend on the lag length. This solution can be seen to be of
the same form as the ﬁxed-lag smoother given in Rauch (1963), Meditch
(1969), and Crassidis and Junkins (2004). Unfortunately, it has been shown
(Kelly and Anderson, 1971) that this form of smoother is numerically un-
stable and thus not usable in practice. However, sometimes the equations
do indeed work and can be used if the user is willing to take the risk of
potential instability.
Moore (1973) and Moore and Tam (1973) have derived stable algorithms
for optimal ﬁxed-lag smoothing by augmenting the n lagged states to a
Kalman ﬁlter. This approach ensures the stability of the algorithm. Using
certain simpliﬁcations it is possible to reduce the computations, and this
is also possible when certain types of extended Kalman ﬁlters are used
(Moore, 1973; Moore and Tam, 1973). Unfortunately, such simpliﬁcations
cannot be done in the more general case and, for example, when the un-
scented transformation (Julier et al., 1995, 2000) or a quadrature rule (Ito
and Xiong, 2000) is used, the required number of computations becomes
high, because the Cholesky factorization of the whole joint covariance of
the n lagged states would be needed in the computations. Another possi-
bility, which is employed here, is to take advantage of the fact that Rauch–
Tung–Striebel smoother equations are numerically stable and can be used
for ﬁxed-lag smoothing. The ﬁxed-lag smoothing can be efﬁciently imple-
mented by taking into account that the gain sequence needs to be evaluated

164
General Gaussian smoothing
only once, and the same gains can be used in different smoothers operating
on different intervals.
Algorithm 10.7 (General Gaussian ﬁxed-lag smoother)
Thus the general
Gaussian ﬁxed-lag smoother can be implemented by performing the fol-
lowing on each time step k D 1; 2; 3; : : :
1 Gain computation: During the Gaussian ﬁlter prediction step compute
and store the predicted mean mkjk1, predicted covariance Pkjk1 and
cross-covariance Dk. Also compute and store the smoothing gain
Gk1 D Dk ŒPkjk11:
(10.28)
2 Fixed-lag smoothing: Using the stored gain sequence, compute the
smoothing solutions for steps j D k  n; : : : ; k using the following
backward recursion, starting from the ﬁltering solution on step j D k:
mj jk D mj jj C Gj

mj C1jk  mj C1jj

;
Pj jk D Pj jj C Gj

Pj C1jk  Pj C1jj

GT
j :
(10.29)
The required number of computations per time step grows linearly with
the length of lag. Thus the computational requirements are comparable to
the algorithms presented in Moore (1973) and Moore and Tam (1973). The
algorithm deﬁned in Equations (10.26) and (10.27) would be computation-
ally more efﬁcient but, as already stated, it would be numerically unstable.
10.6 Exercises
10.1
Implement the third order spherical cubature integration based RTS
smoother for the model in Exercise 5.1 and compare the errors of the ﬁlters
and smoothers.
10.2
Implement a ﬁxed point smoother (you can choose the brand freely) for
inferring the initial state of the above model. Check that the result matches
the corresponding RTS smoother result and plot the error as a function of
time steps.

11
Particle smoothing
When smoothing solutions to non-linear/non-Gaussian problems are
sought, Gaussian approximations might not lead to accurate enough
approximations. In that case it is better to use Monte Carlo (particle)
approximations which in principle can be used for approximating arbitrary
smoothing distributions. Although the same SIR algorithm which is
used for particle ﬁltering provides an approximation to the smoothing
distribution as a by-product, it does not yet solve the problem of particle
smoothing. The challenge is that the resulting approximation tends to
be degenerate. For this reason other types of particle smoothers have
been developed and here we present the most commonly used ones, the
backward-simulation smoother and the reweighting based (marginal)
particle smoother.
11.1 SIR particle smoother
The SIR particle smoother (SIR-PS) of Kitagawa (1996) is based on direct
usage of the SIR for smoothing. Recall that in Section 7.3 we derived the
sequential importance sampling (SIS) method to approximate the full pos-
terior distribution, not just the ﬁltering distributions. We then discarded the
sample histories x.i/
0Wk1 and only kept the current states x.i/
k , because we
were interested in the ﬁltering distributions. But we can get an approxima-
tion to the smoothing distribution by keeping the full histories. To get the
smoothing solution from sequential importance resampling (SIR) we also
need to resample the state histories, not only the current states, to prevent
the resampling from breaking the state histories. The resulting algorithm is
the following.
Algorithm 11.1 (SIR particle smoother)
The direct sequential impor-
tance resampling (SIR) based smoother algorithm is the following.
165

166
Particle smoothing
 Draw N samples x.i/
0 from the prior:
x.i/
0  p.x0/;
i D 1; : : : ; N;
(11.1)
and set w.i/
0
D 1=N, for all i D 1; : : : ; N. Initialize the state histories
to contain the prior samples x.i/
0 .
 For each k D 1; : : : ; T do the following:
1 Draw N new samples x.i/
k from the importance distributions:
x.i/
k  .xk j x.i/
k1; y1Wk/;
i D 1; : : : ; N;
(11.2)
where x.i/
k1 is the k  1th (last) element in the sample history x.i/
0Wk1.
2 Calculate the new weights according to
w.i/
k
/ w.i/
k1
p.yk j x.i/
k / p.x.i/
k j x.i/
k1/
.x.i/
k j x.i/
k1; y1Wk/
(11.3)
and normalize them to sum to unity.
3 Append the samples to the state histories:
x.i/
0Wk D .x.i/
0Wk1; x.i/
k /:
(11.4)
4 If the effective number of particles (7.27) is too low, perform resam-
pling on the state histories.
The approximation to the full posterior (smoothed) distribution is (Kita-
gawa, 1996; Doucet et al., 2000)
p.x0WT j y1WT / 
N
X
iD1
w.i/
T ı.x0WT  x.i/
0WT /:
(11.5)
The approximation to the smoothed posterior distribution at time step k,
given the measurements up to the time step T > k, is
p.xk j y1WT / 
N
X
iD1
w.i/
T ı.xk  x.i/
k /;
(11.6)
where x.i/
k is the kth component in x.i/
0WT . However, if T  k the direct SIR
smoother algorithm is known to produce very degenerate approximations
(Kitagawa, 1996; Doucet et al., 2000).

11.2 Backward-simulation particle smoother
167
11.2 Backward-simulation particle smoother
A less degenerate particle smoother than the SIR particle smoother can be
obtained by reusing the ﬁltering results instead of simply storing the full
particle histories in SIR. The backward-simulation particle smoother (BS-
PS) of Godsill et al. (2004) is based on simulation of individual trajectories
backwards, starting from the last step and proceeding to the ﬁrst. The algo-
rithm is the following.
Algorithm 11.2 (Backward-simulation particle smoother)
Given the
weighted set of particles fw.i/
k ; x.i/
k
W
i D 1; : : : ; N; k D 1; : : : ; T g
representing the ﬁltering distributions:
 Choose QxT D x.i/
T with probability w.i/
T .
 For k D T  1; : : : ; 0:
1 Compute new weights by
w.i/
kjkC1 / w.i/
k p.QxkC1 j x.i/
k /:
(11.7)
2 Choose Qxk D x.i/
k with probability w.i/
kjkC1.
Derivation
Assume that we have already simulated a trajectory QxkC1WT
from the smoothing distribution. By using Equation (8.3) we get
p.xk j QxkC1; y1WT / D p.QxkC1 j xk/ p.xk j y1Wk/
p.QxkC1 j y1Wk/
D Z p.QxkC1 j xk/ p.xk j y1Wk/;
(11.8)
where Z is a normalization constant. By substituting the SIR ﬁlter approx-
imation in Equation (7.31) we get
p.xk j QxkC1; y1WT /  Z
X
i
w.i/
k p.QxkC1 j xk/ ı.xk  x.i/
k /:
(11.9)
We can now draw a sample from this distribution by sampling x.i/
k
with
probability / w.i/
k p.QxkC1 j x.i/
k /.
Given S iterations of Algorithm 11.2, resulting in sample trajectories
Qx.j /
0WT for j D 1; : : : ; S, the smoothing distribution can now be approxi-
mated as
p.x0WT j y1WT /  1
S
X
j
ı.x0WT  Qx.j /
0WT /:
(11.10)
The marginal distribution samples for a step k can be obtained by extract-
ing the kth components from the above trajectories. The computational

168
Particle smoothing
0.5
1
1.5
2
2.5
3
3.5
4
4.5
−3
−2
−1
0
1
2
3
4
5
Time t
Pendulum angle x1,k
 
 
True Angle
Measurements
PS Estimate
Figure 11.1 Simulated pendulum data and the result of
tracking the pendulum described in Example 5.1 with the
backward-simulation smoother. The resulting RMSE is 0:028
which is the same as with the non-linear Gaussian RTS smoothers
(all of them had RMSE 0:028, except the ERTSS which had
0:033). Recall that the RMSE of the bootstrap ﬁlter was 0:12 and
thus the smoother reduces the error signiﬁcantly.
complexity of the method is O.S T N/. However, the result is much less
degenerate than that of the particle smoother of Kitagawa (1996). Under
suitable conditions, it is also possible to reduce the number of computa-
tions to linear in the number of particles by implementing the backward
simulation using rejection sampling (Douc et al., 2011).
Example 11.1 (Pendulum tracking with BS-PS)
The result of applying
the backward-simulation smoother with 100 samples (with the bootstrap
ﬁlter with 10 000 samples as the ﬁlter part) to the pendulum model in
Example 5.1 is shown in Figure 11.1. The RMSE error 0:028 is smaller than
the RMSE of the ERTSS, which was 0:033, and the same as the errors of the
other Gaussian approximation based RTS smoothers, which all were 0:028.
As already concluded in Example 7.1 the use of particle approximations is
not really beneﬁcial in this particular model.
Example 11.2 (Cluttered pendulum tracking with BS-PS)
The result of
applying the backward-simulation smoother with 100 samples (with the

11.3 Reweighting particle smoother
169
0.5
1
1.5
2
2.5
3
3.5
4
4.5
−3
−2
−1
0
1
2
3
4
5
Time t
Pendulum angle x1,k
 
 
True Angle
Measurements
PS Estimate
GHRTSS with True R
GHRTSS with Increased R
Figure 11.2 Smoothing results for cluttered pendulum tracking
with particle smoother, a GHRTSS with no clutter model, and a
GHRTSS with artiﬁcially increased process noise. The RMSE
errors of the methods were 0:028, 3:36, and 0:74, respectively.
bootstrap ﬁlter with 10 000 samples as the ﬁlter part) to the cluttered
pendulum model in Example 7.2 is shown in Figure 11.2. The RMSE er-
ror of the particle smoother was 0:028. The RMSE of a GHRTSS with-
out any clutter model was 3:36 and the RMSE of a GHRTSS with artiﬁ-
cially increased measurement noise was 0:74. Thus in this case the particle
smoother gives a signiﬁcant improvement over the Gaussian approxima-
tion based smoothers.
11.3 Reweighting particle smoother
The reweighting particle smoother of H¨urzeler and Kunsch (1998) and
Doucet et al. (2000), which is also called the marginal particle smoother,
is based on computing new weights for the SIR ﬁltering particles such that
we get an approximation to the smoothing distribution.
Algorithm 11.3 (Reweighting particle smoother)
Given the weighted set
of particles fw.i/
k ; x.i/
k
W i D 1; : : : ; Ng representing the ﬁltering distribu-
tion, we can form approximations to the marginal smoothing distributions
as follows.

170
Particle smoothing
 Start by setting w.i/
T jT D w.i/
T for i D 1; : : : ; N.
 For each k D T  1; : : : ; 0 compute new weights by
w.i/
kjT D
X
j
w.j /
kC1jT
w.i/
k p.x.j /
kC1 j x.i/
k /
hP
l w.l/
k p.x.j /
kC1 j x.l/
k /
i:
(11.11)
At each step k the marginal smoothing distribution can be approximated
as
p.xk j y1WT / 
X
i
w.i/
kjT ı.xk  x.i/
k /:
(11.12)
Derivation
Assume that we have already computed the weights for the
following approximation, where the particles x.i/
kC1 are from the SIR ﬁlter:
p.xkC1 j y1WT / 
X
i
w.i/
kC1jT ı.xkC1  x.i/
kC1/:
(11.13)
The integral in the second of Equations (8.2) can be now approximated as
Z p.xkC1 j xk/ p.xkC1 j y1WT /
p.xkC1 j y1Wk/
dxkC1

Z
p.xkC1 j xk/
p.xkC1 j y1Wk/
X
i
h
w.i/
kC1jT ı.xkC1  x.i/
kC1/
i
dxkC1
D
X
i
w.i/
kC1jT
p.x.i/
kC1 j xk/
p.x.i/
kC1 j y1Wk/
:
(11.14)
By using SIR ﬁlter approximation in Equation (7.31) we get the following
approximation for the predicted distribution in the denominator:
p.xkC1 j y1Wk/ 
X
j
w.j /
k
p.xkC1 j x.j /
k /;
(11.15)
which gives
Z p.xkC1 j y1WT / p.xkC1 j xk/
p.xkC1 j y1Wk/
dxkC1

X
i
w.i/
kC1jT
p.x.i/
kC1 j xk/
hP
j w.j /
k
p.x.i/
kC1 j x.j /
k /
i:
(11.16)

11.4 Rao–Blackwellized particle smoothers
171
By substituting the SIR ﬁlter approximation and the approximation above
to the Bayesian optimal smoothing equation we get
p.xk j y1WT /
D p.xk j y1Wk/
Z p.xkC1 j xk/ p.xkC1 j y1WT /
p.xkC1 j y1Wk/

dxkC1

X
l
w.l/
k ı.xk  x.l/
k /
X
i
w.i/
kC1jT
p.x.i/
kC1 j x.l/
k /
hP
j w.j /
k
p.x.i/
kC1 j x.j /
k /
i;
(11.17)
where we can identify the weights as
w.l/
kjT D
X
i
w.i/
kC1jT
w.l/
k p.x.i/
kC1 j x.l/
k /
hP
j w.j /
k
p.x.i/
kC1 j x.j /
k /
i:
(11.18)
The computational complexity of the method is O.T N 2/, that is, the
same as of the backward-simulation smoother with S D N simulated
trajectories.
11.4 Rao–Blackwellized particle smoothers
Rao–Blackwellized particle smoothers (RBPS) can be used for computing
approximate smoothing solutions to the conditionally Gaussian models de-
ﬁned in Equation (7.36). A simple way to implement an RBPS is to store
the histories instead of the single states in the RBPF, as in the case of the
SIR particle smoother (Algorithm 11.1). The corresponding histories of the
means and the covariances are then conditional on the latent variable his-
tories u0WT . However, the means and covariances at time step k are only
conditional on the measurement histories up to k, not on the later measure-
ments. In order to correct this, RTS smoothers have to be applied to each
history of the means and the covariances.
Algorithm 11.4 (Rao–Blackwellized SIR particle smoother)
A set of
weighted samples fws;.i/
T
; us;.i/
0WT ; ms;.i/
0WT ; P s;.i/
0WT
W i D 1; : : : ; Ng representing
the smoothed distribution can be computed as follows.
1 Compute the weighted set of Rao–Blackwellized state histories
fw.i/
T ; u.i/
0WT ; m.i/
0WT ; P .i/
0WT W i D 1; : : : ; Ng
(11.19)

172
Particle smoothing
by storing histories in the Rao–Blackwellized particle ﬁlter analogously
to the SIR particle smoother in Algorithm 11.1.
2 Set
ws;.i/
T
D w.i/
T ;
us;.i/
0WT D u.i/
0WT :
(11.20)
3 Apply the RTS smoother to each of the mean and covariance histories
m.i/
0WT ; P .i/
0WT for i D 1; : : : ; N to produce the smoothed mean and covari-
ance histories ms;.i/
0WT ; P s;.i/
0WT .
The Rao–Blackwellized particle smoother in this simple form also has
the same disadvantage as the SIR particle smoother, that is, the smoothed
estimate of uk can be quite degenerate if T  k. Fortunately, the smoothed
estimates of the actual states xk can still be relatively good, because their
degeneracy is avoided by Rao–Blackwellization.
To avoid the degeneracy in estimates of uk it is possible to use
better sampling procedures for generating samples from the smoothing
distributions analogously to the plain particle smoothing. The backward-
simulation has indeed been generalized to the Rao–Blackwellized case,
but the implementation of the Rao–Blackwellized reweighting smoother
seems to be quite problematic. The Rao–Blackwellized backward-
simulation smoother (see S¨arkk¨a et al., 2012a) can be used for drawing
backward trajectories from the marginal posterior of the latent variables
uk and the posterior of the conditionally Gaussian part is obtained via
Kalman ﬁltering and RTS smoothing. Another option is to simulate
backward trajectories from the joint distribution of .xk; uk/ (Fong et al.,
2002; Lindsten, 2011). However, this approach does not really lead to
Rao–Blackwellized estimates of the smoothing distribution, because the
Gaussian part of the state is sampled as well.
It is also possible to construct approximate Rao–Blackwellized
backward-simulation smoothers by using Kim’s approximation (see Kim,
1994; Barber, 2006; S¨arkk¨a et al., 2012a)
Z
p.uk j ukC1; xkC1; y1Wk/ p.xkC1 j ukC1; y1WT / dxkC1
' p.uk j ukC1; y1Wk/:
(11.21)
The result is an algorithm where we ﬁrst apply the backward-simulation
smoother in the Algorithm 11.2 to the marginal samples of uk alone, that
is, we simply use p.ukC1 j uk/ instead of p.xkC1 j xk/ in the algo-
rithm. Given a trajectory of the non-Gaussian variable, the linear Gaussian

11.5 Exercises
173
part may be recovered with a Kalman ﬁlter and RTS smoother. However,
this procedure is only an approximation and does not lead to a true Rao–
Blackwellized Monte Carlo representation of the smoothing distribution.
11.5 Exercises
11.1
Implement the backward-simulation smoother for the model in Exer-
cise 5.1 and compare its performance to the Gaussian approximation based
smoothers.
11.2
Implement the reweighting smoother for the model in Exercise 5.1 and com-
pare its performance to the other smoothers.
11.3
Show that the latent variable sequence in conditionally Gaussian models is
not Markovian in general in the sense that
p.uk j ukC1; y1WT / ¤ p.uk j ukC1; y1Wk/
(11.22)
when T > k, and thus simple backward smoothing in uk does not lead to
the correct result.
11.4
Implement the Rao–Blackwellized SIR particle smoother for the clutter
model in Exercise 7.5.
11.5
Let’s again consider the clutter model in Exercise 7.5. Assume that you have
implemented the ﬁlter as a Rao–Blackwellized particle ﬁlter with resam-
pling at every step (thus the weights are all equal). Write down the algo-
rithm for the Kim’s approximation based backward simulation smoother for
the model. What peculiar property does the smoother have? Does this have
something to do with the property in Equation (11.22)?

12
Parameter estimation
In the previous chapters we have assumed that the parameters of the state
space model are known and only the state needs to be estimated. However,
in practical models, the parameters are unknown as well. In this chapter
we concentrate on three types of method for parameter estimation: op-
timization based methods for computing maximum a posteriori (MAP)
or maximum likelihood (ML) estimates, expectation-maximization (EM)
algorithms for computing the MAP or ML estimates, and Markov chain
Monte Carlo (MCMC) methods for generating Monte Carlo approxima-
tions of the posterior distributions. We also show how Kalman ﬁlters and
RTS smoothers, Gaussian ﬁlters and smoothers, as well as particle ﬁlters
and smoothers can be used for approximating the marginal likelihoods, pa-
rameter posteriors, and other quantities needed by the methods.
12.1 Bayesian estimation of parameters in state space models
The Bayesian way of treating unknown parameters  2 Rd is to model
them as random variables with a certain prior distribution p./. A state
space model with unknown parameters can be written in the form
  p./;
x0  p.x0 j /;
xk  p.xk j xk1; /;
yk  p.yk j xk; /:
(12.1)
A straightforward way to proceed would now be to form the full posterior
distribution via Bayes’ rule:
p.x0WT ;  j y1WT / D p.y1WT j x0WT ; / p.x0WT j / p./
p.y1WT /
;
(12.2)
174

12.1 Bayesian estimation of parameters in state space models
175
where the terms p.x0WT j / and p.y1WT j x0WT ; / can be computed as
p.x0WT j / D p.x0 j /
TY
kD1
p.xk j xk1; /;
p.y1WT j x0WT ; / D
TY
kD1
p.yk j xk; /:
If we are only interested in the parameters , the proper Bayesian way
to proceed is to integrate the states out, which gives the marginal posterior
of parameters:
p. j y1WT / D
Z
p.x0WT ;  j y1WT / dx0WT :
(12.3)
Unfortunately, computation of this high-dimensional integral is hard and
becomes even harder as we obtain more measurements. In this approach
we encounter the same computational problem as was discussed in Sec-
tions 1.3 and 4.1, which led us to consider optimal ﬁltering and smoothing
instead of the straightforward Bayesian approach. Thus it is again advanta-
geous to look at recursive, ﬁltering, and smoothing kinds of solution.
In this chapter we present methods for parameter estimation which are
based on approximating the marginal posterior distribution
p. j y1WT / / p.y1WT j / p./;
(12.4)
without explicitly forming the joint posterior distribution of the states and
parameters as in Equation (12.2). Instead, we present recursive algorithms
for direct computation of the above distribution. For linear state space mod-
els, this can be done exactly, and in non-linear and non-Gaussian models
we can use Gaussian ﬁltering or particle ﬁltering based approximations.
Once we know how to evaluate the above distribution, we can estimate the
parameters, for example, by ﬁnding their maximum a posteriori (MAP) es-
timate or by sampling from the posterior by Markov chain Monte Carlo
(MCMC) methods. If the direct evaluation of the distribution is not fea-
sible, we can use the expectation maximization (EM) algorithm for itera-
tively ﬁnding the ML or MAP estimate.
12.1.1 Parameter posterior and energy function
The difﬁcult part in Equation (12.4) is the evaluation of the marginal like-
lihood p.y1WT j /. The prior distribution can usually be selected such that

176
Parameter estimation
it is easy to evaluate. Although evaluation of the normalization constant
for the posterior distribution is a difﬁcult problem, its evaluation is usually
avoided by Bayesian computational methods and thus we do not need to
worry about it.
The key to recursive computation of the parameter posterior in state
space models is the following factorization (often called prediction error
decomposition):
p.y1WT j / D
TY
kD1
p.yk j y1Wk1; /;
(12.5)
where we have denoted p.y1 j y1W0; / , p.y1 j / for notational conve-
nience. Because each of the terms in the above product can be computed
recursively, the whole marginal likelihood can be computed recursively as
follows.
Theorem 12.1 (Recursion for marginal likelihood of parameters)
The
marginal likelihood of parameters is given by Equation (12.5), where the
terms in the product can be computed recursively as
p.yk j y1Wk1; / D
Z
p.yk j xk; / p.xk j y1Wk1; / dxk;
(12.6)
where p.yk j xk; / is the measurement model and p.xk j y1Wk1; / is
the predictive distribution of the state, which obeys the recursion
p.xk j y1Wk1; / D
Z
p.xk j xk1; / p.xk1 j y1Wk1; / dxk1
p.xk j y1Wk; / D p.yk j xk; / p.xk j y1Wk1; /
p.yk j y1Wk1; /
:
(12.7)
Note that the latter equations are just the Bayesian ﬁltering Equa-
tions (4.11) and (4.12), where we have explicitly written down the
parameter dependence.
Proof
Due to the conditional independence of the measurements (Prop-
erty 4.2) we have
p.yk; xk j y1Wk1; / D p.yk j xk; y1Wk1; / p.xk j y1Wk1; /
D p.yk j xk; / p.xk j y1Wk1; /:
(12.8)
Integrating over xk gives Equation (12.6).

12.2 Computational methods for parameter estimation
177
The marginal likelihood obtained via Theorem 12.1 can then be sub-
stituted into Equation (12.4) to give the marginal posterior distribution of
the parameters. However, instead of working with marginal likelihood or
marginal posterior explicitly, in parameter estimation, it is often convenient
to deﬁne the unnormalized negative log-posterior or energy function as fol-
lows.
Deﬁnition 12.1 (Energy function)
'T ./ D  log p.y1WT j /  log p./:
(12.9)
Remark 12.1
The deﬁnition of energy function thus implies
p. j y1WT / / exp.'T .//:
(12.10)
The energy function can be seen to obey the following simple recursion.
Theorem 12.2 (Recursion for energy function)
The energy function de-
ﬁned in Equation (12.9) can be evaluated recursively as follows.
 Start from '0.	/ D  log p./.
 At each step k D 1; 2; : : : ; T compute the following:
'k./ D 'k1./  log p.yk j y1Wk1; /;
(12.11)
where the terms p.yk j y1Wk1; / can be computed recursively by The-
orem 12.1.
Proof
The result follows from substituting Equation (12.5) into the deﬁ-
nition of the energy function in Equation (12.9) and identifying the terms
corresponding to 'k1./.
12.2 Computational methods for parameter estimation
In this section we brieﬂy go through the underlying ideas in ML and MAP
based parameter estimation, their implementation by direct optimization
and by the EM algorithm, as well as the basics of Markov chain Monte
Carlo (MCMC) methods. There exist many other parameter estimation
methods for state space models and for more general statistical models,
but here we concentrate on these, because these approaches are the most
widely used (probabilistic methods) in the state space context.

178
Parameter estimation
12.2.1 Maximum a posteriori and Laplace approximations
The maximum a posteriori (MAP) estimate is obtained by determining the
location of the maximum of the posterior distribution and using it as the
point estimate:
OMAP D arg max

Œp. j y1WT / :
(12.12)
The MAP estimate can be equivalently computed as the minimum of the
error function deﬁned in Equation (12.9):
OMAP D arg min
 Œ'T ./ ;
(12.13)
which is usually numerically more stable and easier to compute. The max-
imum likelihood (ML) estimate of the parameter is a MAP estimate with a
formally uniform prior p./ / 1.
The minimum of the energy function can be computed by using various
gradient-free or gradient based general optimization algorithms (see, e.g.,
Luenberger and Ye, 2008). However, to be able to use gradient based opti-
mization we will need to evaluate the derivatives of the energy function as
well. It is possible to ﬁnd the derivatives in basically two ways (see, e.g.,
Capp´e et al., 2005).
1 By formally differentiating the energy function recursion equations for
a particular method. This results in so-called sensitivity equations which
can be implemented as additional recursion equations computed along
with ﬁltering.
2 Using Fisher’s identity which expresses the gradient of the energy func-
tion as an expectation of the derivative of the complete data log likeli-
hood over the smoothing distribution. The advantage of this approach
over direct differentiation is that there is no need for an additional recur-
sion.
The disadvantage of the MAP-estimate is that it essentially approximates
the posterior distribution with the Dirac delta function
p. j y1WT / ' ı.  OMAP/;
(12.14)
and thus ignores the spread of the distribution completely.
It is also possible to use a Laplace approximation (Gelman et al., 2004)
which uses the second derivative (Hessian) of the energy function to form
a Gaussian approximation to the posterior distribution:
p. j y1WT / ' N. j OMAP; ŒH. OMAP/1/;
(12.15)

12.2 Computational methods for parameter estimation
179
where H. OMAP/ is the Hessian matrix evaluated at the MAP estimate. How-
ever, to implement the Laplace approximation, we need to have a method
to compute (or approximate) the second order derivatives of the energy
function.
12.2.2 Parameter inference via Markov chain Monte Carlo
Markov chain Monte Carlo (MCMC) methods (see, e.g., Liu, 2001; Brooks
et al., 2011) are a class of algorithms for drawing random variables from a
given distribution by simulating a Markov chain which has the desired dis-
tribution as its stationary distribution. The methods are particularly suited
for simulating samples from Bayesian posterior distributions p. j y1WT /,
because to implement the methods, we only need to know the unnormal-
ized posterior distribution Qp. j y1WT / D p.y1WT j / p./ or equivalently
the energy function in Equation (12.9), and knowledge of the normalization
constant of the posterior distribution is not required. The usage of MCMC
methods in the state space context has been recently discussed, for exam-
ple, by Ninness and Henriksen (2010) and Andrieu et al. (2010).
The Metropolis–Hastings (MH) algorithm is the most common type of
MCMC method. MH uses a proposal density q..i/ j .i1// for suggest-
ing new samples .i/ given the previous ones .i1/. The algorithm is the
following.
Algorithm 12.1 (Metropolis–Hastings)
The Metropolis–Hastings (MH)
algorithm consists of the following steps.
 Draw the starting point, .0/ from an arbitrary initial distribution.
 For i D 1; 2; : : : ; N do
1 Sample a candidate point  from the proposal distribution:
  q. j .i1//:
(12.16)
2 Evaluate the acceptance probability
˛i D min

1; exp.'T ..i1//  'T .// q..i1/ j /
q. j .i1//

: (12.17)
3 Generate a uniform random variable u  U.0; 1/ and set
.i/ D
(
;
if u 	 ˛i;
.i1/;
otherwise:
(12.18)

180
Parameter estimation
The Metropolis algorithm is a commonly used special case of
Metropolis–Hastings, where the proposal distribution is symmetric,
q..i1/ j .i// D q..i/ j .i1//. In this case the acceptance probability
reduces to
˛i D min
n
1; exp.'T ..i1//  'T .//
o
:
(12.19)
The choice of the proposal distribution is crucial for performance of the
Metropolis–Hastings method and ﬁnding a good one is a hard task (see,
e.g., Liu, 2001; Brooks et al., 2011). Some choices will lead to Metropolis–
Hastings methods where the samples are highly correlated, whereas with
some choices the rejection rate becomes too high.
One commonly used choice is to use Gaussian distribution as the pro-
posal distribution,
q..i/ j .i1// D N..i/ j .i1/; †i1/;
(12.20)
where †i1 is some suitable covariance matrix. The resulting algorithm
is called the random walk Metropolis algorithm, because the transition
distribution above deﬁnes a Gaussian random walk in parameter space.
With this selection of proposal distribution the challenge is now to ﬁnd a
suitable covariance matrix for the random walk.
One approach to the problem of selection of the covariance matrix is
to use adaptive Markov chain Monte Carlo (AMCMC) methods where the
covariance of the Gaussian proposal in the Metropolis algorithm is auto-
matically adapted during the MCMC run (see, e.g., Haario et al., 1999,
2001; Andrieu and Thoms, 2008; Vihola, 2012). A typical idea in AM-
CMC methods is to use the covariance of the previously generated samples
as an estimate of the actual covariance of the posterior distribution. Given
the covariance, it is possible to compute the covariance of the proposal
distribution such that it causes an acceptance rate N˛ which is optimal in
some suitable sense. For the random walk Metropolis algorithm, the opti-
mal acceptance rate in certain ideal conditions is N˛ D 0:234 (Roberts and
Rosenthal, 2001).
For example, the robust adaptive Metropolis (RAM) algorithm of Vihola
(2012) is similar to the adaptive Metropolis (AM) algorithm of Haario et al.
(2001) except that the adaptation of the covariance †i is done in a slightly
different way. The algorithm is the following.
Algorithm 12.2 (RAM algorithm)
The RAM algorithm consists of the
following steps.

12.2 Computational methods for parameter estimation
181
1 Draw .0/ from an initial distribution p0./, and initialize S0 to be the
lower-triangular Cholesky factor of the initial covariance †0.
2 Sample a candidate point by  D i1 C Si1 ri, where ri  N.0; I/.
3 Compute the acceptance probability
˛i D min f1; exp .'.i1/  './/g :
(12.21)
4 Sample a uniform random variable u from the uniform distribution
U.0; 1/.
5 If u 	 ˛i, set .i/ D . Otherwise set .i/ D .i1/.
6 Compute a lower-triangular matrix Si with positive diagonal elements
satisfying the equation
Si ST
i D Si1

I C i .˛i  N˛/ ri rT
i
jjrijj2

ST
i1;
(12.22)
where figi1 
 .0; 1 is an adaptation step size sequence decaying
to zero. Although any such sequence will do, Vihola (2012) suggests
i D i with a suitable exponent 
 2 .1=2; 1.
7 Set i  i C 1 and go to step 2 until the desired number of samples has
been generated.
Instead of the random walk Metropolis algorithm with covariance adap-
tation it is also possible to use the gradient information in the construction
of the proposal distribution. This is the idea used in the Hamiltonian Monte
Carlo (HMC) or hybrid Monte Carlo (HMC) method (Duane et al., 1987;
Neal, 2011). In HMC the proposal distribution is constructed by simulat-
ing a physical system consisting of particles moving under the inﬂuence
of a potential (the energy function) and heat bath. The gradient of the en-
ergy function enters the equations as the force caused by the potential. The
HMC method was recently applied in the state space context by Mbalawata
et al. (2013).
Another commonly used MCMC method is Gibbs’ sampling (see, e.g.,
Liu, 2001; Brooks et al., 2011), which samples components of the param-
eters one at a time from their conditional distributions given the other pa-
rameters. The advantage of this method is that no rejections are needed, the
acceptance probability is identically one. However, in order to implement
the method it is necessary to be able to generate samples from the con-
ditional distributions of parameters, which is possible only in a restricted
class of models. For various other methods the reader is referred to Brooks
et al. (2011).

182
Parameter estimation
12.2.3 Expectation maximization
The expectation-maximization (EM) algorithm is a method to iteratively
ﬁnd an ML estimate of the parameters when the direct optimization of the
posterior distribution (or equivalently, energy function) is not feasible. The
algorithm was originally introduced by Dempster et al. (1977) and applica-
tions to state space models have been discussed, for example, in Shumway
and Stoffer (1982); Roweis and Ghahramani (2001); Sch¨on et al. (2011).
Gaussian smoothing and sigma-point based approximations in an EM con-
text have also been recently discussed in V¨a¨an¨anen (2012). Although the
EM algorithm was originally an algorithm for computing ML estimates,
it can also be easily modiﬁed for computation of MAP estimates, as dis-
cussed below.
The EM algorithm is based on the result that even when we cannot
evaluate the marginal likelihood as such, we are still often able to compute
a lower bound for it as follows. Let q.x0WT / be an arbitrary probability
density over the states, then we have
log p.y1WT j /  F Œq.x0WT /; ;
(12.23)
where the functional F is deﬁned as
F Œq.x0WT /;  D
Z
q.x0WT / log p.x0WT ; y1WT j /
q.x0WT /
dx0WT :
(12.24)
The key idea behind the EM algorithm is that it is possible to maximize
the left-hand side of Equation (12.23) by iteratively maximizing the lower
bound F Œq.x0WT /; . A simple way to do that is the following iteration
(Neal and Hinton, 1999).
Algorithm 12.3 (Abstract EM)
The maximization of the lower bound in
Equation (12.24) can be done by coordinate ascend as follows.
 Start from initial guesses q.0/, .0/.
 For n D 0; 1; 2; : : : do the following steps:
1 E-step: Find q.nC1/ D arg maxq F Œq; .n/.
2 M-step: Find .nC1/ D arg max F Œq.nC1/; .
In order to implement the EM algorithm we need to be able to do the
above maximizations in practice. Fortunately, it can be shown (see, e.g.,
Neal and Hinton, 1999) that the result of the maximization at the E-step is
q.nC1/.x0WT / D p.x0WT j y1WT ; .n//:
(12.25)

12.2 Computational methods for parameter estimation
183
Plugging this into the expression of F Œq.nC1/.x0WT /;  gives
F Œq.nC1/.x0WT /; 
D
Z
p.x0WT j y1WT ; .n// log p.x0WT ; y1WT j / dx0WT

Z
p.x0WT j y1WT ; .n// log p.x0WT j y1WT ; .n// dx0WT :
(12.26)
Because the latter term does not depend on , maximizing F Œq.nC1/;  is
equivalent to maximizing the ﬁrst term above, which in the EM context is
commonly denoted as
Q.; .n// D
Z
p.x0WT j y1WT ; .n// log p.x0WT ; y1WT j / dx0WT ;
(12.27)
which is thus the expectation of the logarithm of the complete data likeli-
hood p.x0WT ; y1WT j / over the full joint posterior of the states given the
parameters .n/. The resulting algorithm is the following.
Algorithm 12.4 (EM algorithm)
The EM algorithm consists of the fol-
lowing steps.
 Start from an initial guess .0/.
 For n D 0; 1; 2; : : : do the following steps:
1 E-step: compute Q.; .n//.
2 M-step: compute .nC1/ D arg max Q.; .n//.
Due to the Markovian structure of the state space model in Equation
(12.1), the complete data log-likelihood has the form
log p.x0WT ; y1WT j /
D log p.x0 j / C
T
X
kD1
log p.xk j xk1; / C
T
X
kD1
log p.yk j xk; /:
(12.28)
The expression for Q in Equation (12.27) and thus the E-step in Algo-
rithm 12.4 now reduces to computation of (see Sch¨on et al., 2011)
Q.; .n// D I1.; .n// C I2.; .n// C I3.; .n//;
(12.29)

184
Parameter estimation
where
I1.; .n// D
Z
p.x0 j y1WT ; .n// log p.x0 j / dx0;
I2.; .n// D
T
X
kD1
Z
p.xk; xk1 j y1WT ; .n//
 log p.xk j xk1; / dxk dxk1;
I3.; .n// D
T
X
kD1
Z
p.xk j y1WT ; .n// log p.yk j xk; / dxk:
(12.30)
The above expectations are over the smoothing distribution and the key
thing is to observe that we do not need to compute expectations over the
full posterior, but only over the smoothing distributions p.xk j y1WT ; .n//
and pairwise smoothing distributions p.xk; xk1 j y1WT ; .n//. It turns out
that the required expectations can be easily (approximately) evaluated us-
ing smoother results. In the case of linear state space models we can ﬁnd
a closed form expression for the above integrals in terms of RTS smoother
results. In the non-linear case we can approximate the integrals by using
non-linear smoothers such as Gaussian smoothers. In the more general
probabilistic state space model we can use particle smoothers to approx-
imate them.
On the E-step of Algorithm 12.4 we need to maximize the expression for
Q in Equation (12.29) with respect to the parameters . In principle, we
can utilize various gradient-free and gradient based optimization methods
(see, e.g., Luenberger and Ye, 2008) for doing that, but the most useful
case occurs when we can do the maximization analytically via setting the
gradient to zero:
@Q.; .n//
@
D 0:
(12.31)
This happens, for example, when estimating the parameters of linear state
space models and in certain classes of non-linear state space models.
It turns out that we can calculate MAP estimates using the EM algorithm
by replacing p.x0WT ; y1WT j / in Equation (12.27) with p.x0WT ; y1WT ; /.
In practice, it can be implemented by maximizing Q.; .n// C log p./
at the M-step instead of the plain Q.
As a side product of the EM formulation above we also get a method
to compute the gradient of the energy function needed in gradient based
optimization for ﬁnding the MAP or ML estimates. Fisher’s identity (see,

12.3 Practical parameter estimation in state space models
185
e.g., Capp´e et al., 2005) states that if we evaluate the gradient of Q at
.n/ D , we get exactly the gradient of the marginal log-likelihood. This
implies that the gradient of the energy function can be evaluated as
@'T ./
@
D @ log p./
@
 @Q.; .n//
@
ˇˇˇˇ
.n/D
:
(12.32)
Note that here we refer to the above identity as Fisher’s identity although
the original identity is the relationship with the log marginal likelihood and
Q, not with the log posterior and Q. In any case this identity is useful in lin-
ear state space models, because it is often easier to compute and computa-
tionally lighter (Segal and Weinstein, 1989; Olsson et al., 2007). However,
in non-linear state space models it is not as useful, because the approxi-
mations involved in computation of the ﬁltering and smoothing solutions
often cause the gradient to have different approximations from the energy
function approximation implied by the same method. That is, the gradient
approximation computed with Fisher’s identity and Gaussian smoothing
might not exactly match the gradient of the energy function approximation
computed with the corresponding Gaussian ﬁlter. However, in the case of
particle ﬁlters, Fisher’s identity provides a feasible way to approximate the
gradient of the energy function.
12.3 Practical parameter estimation in state space models
In this section we discuss practical parameter estimation methods for state
space models using linear Kalman ﬁlters and RTS smoothers, Gaussian
approximation based non-linear Kalman ﬁlters and RTS smoothers, and
particle ﬁlters and smoothers. But before going to them, we outline the
simple but sometimes effective state augmentation approach.
12.3.1 State augmentation approach
Before going to more elaborate parameter estimation methods for state
space models, we recall that already in Chapter 3 we used the Kalman
ﬁlter for estimating static parameters in a regression model. The same ap-
proach can be generalized to the state augmentation approach which sim-
ply means that we augment the parameter as part of the state. For example,
let’s say that we have a non-linear model with unknown parameters :
xk D f.xk1; / C qk1;
yk D h.xk; / C rk:
(12.33)

186
Parameter estimation
We can now rewrite the model as
k D k1;
xk D f.xk1; k1/ C qk1;
yk D h.xk; k/ C rk;
(12.34)
where the dynamic model for the parameter essentially says that it is con-
stant. If we now redeﬁne the state as Qxk D .xk; k/, we get a state space
model of the form
Qxk D Qf.Qxk1/ C Qqk1;
yk D h.Qxk/ C rk;
(12.35)
which does not contain any unknown parameter anymore. The problem
in this state augmentation is the singularity of the dynamic model for the
parameter. It works well when the whole system is linear and we do not
have any approximation errors in the estimator. If the parameters appear
linearly in the system, it sometimes is a good idea to include the parameters
as part of the state. However, this might fail sometimes as well.
With approximate non-linear ﬁlters the singularity of the parameter dy-
namic model indeed causes problems. With non-linear Kalman ﬁlters the
Gaussian approximation tends to become singular which causes the ﬁlter
to diverge. As discussed in Section 7.4, particle ﬁlters have a problem with
small noises in the dynamic model because it causes sample impoverish-
ment. As the noise in the dynamic model above is exactly zero, this case is
particularly problematic for particle ﬁlters.
A common way to circumvent the problem is to introduce an artiﬁcial
noise to the dynamic model of the parameter, that is, replace k D k1
with
k D k1 C "k1;
(12.36)
where "k1 is a “small” noise process. But the problem is that we are
no longer solving the original parameter estimation problem, but another
one with a time-varying parameter. Anyway, this approach is sometimes
applicable and should be considered before jumping into more complicated
parameter estimation methods.
There is also a form of Rao–Blackwellization that sometimes helps. This
approach is discussed in Section 12.3.5 and the idea is to use a closed form
solution for the static parameter (“Rao–Blackwellize” the parameter) and
sample only the original state part. This works if the parameter appears in
the model in a suitable conjugate form.

12.3 Practical parameter estimation in state space models
187
12.3.2 Parameter estimation in linear state space models
Consider the following linear Gaussian state space model with unknown
parameters :
xk D A./ xk1 C qk1;
yk D H./ xk C rk;
(12.37)
where qk1  N.0; Q.//, rk  N.0; R.//, and x0  N.m0./; P0.//.
In the above model, for notational convenience, we have assumed that the
model matrices do not explicitly depend on time. The energy function and
thus the marginal parameter posterior for the linear Gaussian model above
can be obtained as follows.
Theorem 12.3 (Energy function for linear Gaussian model)
The recur-
sion for the energy function is given as
'k./ D 'k1./ C 1
2 log j2 Sk./j C 1
2vT
k ./ S1
k ./ vk./; (12.38)
where the terms vk./ and Sk./ are given by the Kalman ﬁlter with the
parameters ﬁxed to .
 Prediction:
m
k ./ D A./ mk1./;
P 
k ./ D A./ Pk1./ AT./ C Q./:
(12.39)
 Update:
vk./ D yk  H./ m
k ./;
Sk./ D H./ P 
k ./ HT./ C R./;
Kk./ D P 
k ./ HT./ S1
k ./;
mk./ D m
k ./ C Kk./ vk./;
Pk./ D P 
k ./  Kk./ Sk./ KT
k./:
(12.40)
Proof
The Kalman ﬁlter gives us the Gaussian predictive distribution
p.xk j y1Wk1; / D N.xk j m
k ./; P 
k .// which via Theorem 12.1
thus gives
p.yk j y1Wk1; /
D
Z
N.yk j H./ xk; R.// N.xk j m
k ./; P 
k .// dxk
D N.yk j H./ m
k ./; H./ P 
k ./ HT./ C R.//:
(12.41)
The rest follows from Theorem 12.2.

188
Parameter estimation
0
0.5
1
1.5
2
0
0.5
1
1.5
2
2.5
3
 R
 p(R | y1:T )
 
 
Posterior Distribution
True Parameter Value 
Figure 12.1 Posterior distribution of noise variance R in the
Gaussian random walk model (see Example 4.1).
Thus if we ﬁx  and run the above algorithm from '0./ D  log p./
at k D 0 to the step k D T , then the full energy function is 'T ./. That
is, the marginal posterior density at the point  can be evaluated up to a
normalization constant by Equation (12.10) as
p. j y1WT / / exp.'T .//:
Given the energy function it is now easy to implement, for example, a
Metropolis–Hastings based MCMC sampler for generating a Monte Carlo
approximation of the posterior distribution, or to use the energy function
in a gradient-free optimization for ﬁnding the ML or MAP estimates of the
parameters.
Example 12.1 (Parameter posterior for Gaussian random walk)
The pos-
terior distribution of the noise variance p.R j y1WT / for the Gaussian ran-
dom walk model in Example 4.1 is shown in Figure 12.1. A formally uni-
form prior p.R/ / 1 was assumed. The true value used in the simulation is
indeed well within the high density area of the posterior distribution. How-
ever, it can also been seen that if we computed the MAP (or equivalently
ML) estimate of the parameter, we would get a smaller value than the true
one.

12.3 Practical parameter estimation in state space models
189
In order to implement a gradient based optimization method, we need
to have the gradient of the energy function as well. One way to implement
the gradient computation is by ﬁrst differentiating the energy function ex-
pression in Theorem 12.3 term-by-term and then each of the Kalman ﬁlter
equations. This results in a recursion called sensitivity equations (Gupta
and Mehra, 1974; Capp´e et al., 2005) which can be evaluated along with the
Kalman ﬁltering computations. The equations are given in Theorem A.2 in
Section A.3. Another way to compute the gradient is by using Fisher’s iden-
tity (12.32), but before going into that, let’s take a look at the EM algorithm
for linear Gaussian models.
Recall that for implementing the EM algorithm we need to be able to
compute the expectations in Equations (12.30), which in terms requires the
knowledge of the smoothing distributions and pairwise smoothing distri-
butions. Fortunately, by Equations (8.5) and (8.12) we know that
p.xk j y1WT ; .n// D N.xk j ms
k; P s
k/;
p.xk; xk1 j y1WT ; .n//
D N
 xk
xk1
 ˇˇˇ
 ms
k
ms
k1

;

P s
k
P s
k GT
k1
Gk1 P s
k
P s
k1

;
(12.42)
where the means, covariances, and gains are computed with an RTS
smoother with the model parameters ﬁxed to .n/. Note that in the
EM algorithms appearing in the literature the cross term P s
k GT
k1 is
sometimes computed with a separate recursion (see, e.g., Shumway and
Stoffer, 1982), but in fact it is unnecessary due to the above. The required
expectations for EM in Equations (12.30) can now be computed in closed
form and the result is the following (see Shumway and Stoffer, 1982).
Theorem 12.4 (Evaluation of Q for linear Gaussian model)
The ex-
pression for Q for the linear Gaussian model in Equation (12.37) can be

190
Parameter estimation
written as
Q.; .n//
D 1
2 log j2 P0./j  T
2 log j2 Q./j  T
2 log j2 R./j
 1
2 tr
(
P 1
0 ./
h
P s
0 C .ms
0  m0.// .ms
0  m0.//Ti)
 T
2 tr
(
Q1./
h
†  C AT./  A./ CT C A./ ˆ AT./
i)
 T
2 tr
(
R1./
h
D  B HT./  H./ BT C H./ † HT./
i)
;
(12.43)
where the following quantities are computed from the results of RTS
smoothers run with parameter values .n/:
† D 1
T
T
X
kD1
P s
k C ms
k Œms
kT;
ˆ D 1
T
T
X
kD1
P s
k1 C ms
k1 Œms
k1T;
B D 1
T
T
X
kD1
yk Œms
kT;
C D 1
T
T
X
kD1
P s
k GT
k1 C ms
k Œms
k1T;
D D 1
T
T
X
kD1
yk yT
k:
(12.44)
The usefulness of the EM algorithm for linear state space models stems
from the fact that if the parameters are selected to be some of the full model
matrices (or initial mean) we can indeed perform the M-step of the EM
algorithm in closed form. The same thing happens if the parameters appear
linearly in one of the model matrices (e.g., are some subcomponents of the
matrices), but application of the EM algorithm to the estimation of the full
matrices is the classical result. By setting the gradients of @Q.; .n//=@
to zero for each  D fA; H; Q; R; P0; m0g separately, we get the following
result.

12.3 Practical parameter estimation in state space models
191
Theorem 12.5 (Maximization of Q for linear model parameters)
The
maximum  D arg max Q.; .n//, when the parameters are selected
to be one of the model parameters  2 fA; H; Q; R; P0; m0g, can be com-
puted as follows.
 When  D P0 we get
P 
0 D P s
0 C .ms
0  m0/ .ms
0  m0/T:
(12.45)
 When  D A we get
A D C ˆ1:
(12.46)
 When  D Q we get
Q D †  C AT  A CT C A ˆ AT:
(12.47)
 When  D H we get
H D B †1:
(12.48)
 When  D R we get
R D D  H BT  B HT C H † HT:
(12.49)
 Finally, the maximum with respect to the initial mean  D m0 is
m
0 D ms
0:
(12.50)
Obviously the above theorem can also be used for solving the maximum
of Q with respect to any subset of model matrices by solving the resulting
equations jointly. The EM algorithm for ﬁnding the maximum likelihood
estimates of the linear state space model parameters is now the following.
Algorithm 12.5 (EM algorithm for linear state space models)
Let  con-
tain some subset of the model parameters fA; H; Q; R; P0; m0g. We can
ﬁnd maximum likelihood estimates of them via the following iteration.
 Start from some initial guess .0/.
 For n D 0; 1; 2; : : : do the following steps.
1 E-step: Run the RTS smoother using the current parameter values
in .n/ and compute the quantities in Equation (12.44) from the
smoother results.
2 M-step: Find new parameters values by using Equations (12.45) –
(12.50) and store them in .nC1/.

192
Parameter estimation
The expression for Q.; .n// also provides an “easy gradient recipe”
(Olsson et al., 2007) for computation of the energy function gradient via
Fisher’s identity (Equation (12.32)), as it enables the computation of the
gradient without an additional recursion (sensitivity equations). The result-
ing expression is given in Theorem A.3 in Section A.3.
12.3.3 Parameter estimation with Gaussian ﬁltering and smoothing
One way to implement parameter estimation in non-linear models is by
replacing the Kalman ﬁlters and RTS smoothers used in the linear case
with their non-linear counterparts. Let’s consider parameter estimation in
models of the form
xk D f.xk1; / C qk1;
yk D h.xk; / C rk;
(12.51)
where qk1  N.0; Q.//, rk  N.0; R.//, and x0  N.m0./; P0.//.
The energy function can now be approximated with the following Gaussian
ﬁltering based algorithm.
Algorithm 12.6 (Gaussian ﬁltering based energy function)
The recursion
for the approximate energy function is
'k./ ' 'k1./ C 1
2 log j2 Sk./j C 1
2vT
k ./ S1
k ./ vk./; (12.52)
where the terms vk./ and Sk./ are given by the Gaussian ﬁlter with the
parameters ﬁxed to .
 Prediction:
m
k ./ D
Z
f.xk1; / N.xk1 j mk1./; Pk1.// dxk1;
P 
k ./ D
Z
.f.xk1; /  m
k .// .f.xk1; /  m
k .//T
 N.xk1 j mk1./; Pk1.// dxk1 C Qk1./:
(12.53)

12.3 Practical parameter estimation in state space models
193
 Update:
k./ D
Z
h.xk; / N.xk j m
k ./; P 
k .// dxk;
vk./ D yk  k./;
Sk./ D
Z
.h.xk; /  k.// .h.xk; /  k.//T
 N.xk j m
k ./; P 
k .// dxk C Rk./;
Ck./ D
Z
.xk  m
k .// .h.xk; /  k.//T
 N.xk j m
k ./; P 
k .// dxk;
Kk./ D Ck./ S1
k ./;
mk./ D m
k ./ C Kk./ vk./;
Pk./ D P 
k ./  Kk./ Sk./ KT
k./:
(12.54)
Derivation
This approximation can be derived in the same way as the
linear case in Theorem 12.3 except that Gaussian moment matching based
approximations are used instead of the true Gaussian distributions.
The above energy function can now be directly used in MCMC sampling
or in gradient-free optimization algorithms for computing ML or MAP es-
timates. However, because the energy function is based on a Gaussian ap-
proximation, the implied posterior distribution is an approximation as well
and thus the parameter estimates will be biased. The posterior distribution
approximation is also typically thinner than the true posterior distribution
and thus the uncertainty in the parameter is underestimated. This issue is
illustrated in Example 12.2.
It is also possible to compute the derivatives of the above energy func-
tion analogously to the linear case. In the case of the extended Kalman ﬁlter
(EKF), the derivatives can be easily derived by formally differentiating the
EKF equations (see Mbalawata et al., 2013). When sigma-point ﬁlters are
used, a similar approach works, but additional care is needed for compu-
tation of the derivative of the square root matrix @
p
P./=@	i arising in
the equations. The equations for computing the derivatives of the energy
function are given in Algorithm A.3.
To compute the expectations required for implementing the EM algo-
rithm, we can approximate the integrals in Equations (12.30) using the
Gaussian assumed density approximation (i.e., moment matching). The re-
sulting expression for Q is the following.

194
Parameter estimation
Algorithm 12.7 (Evaluation of Q via Gaussian smoothing)
The expres-
sion for Q for the non-linear state space model in Equation (12.51) can be
written as
Q.; .n//
' 1
2 log j2 P0./j  T
2 log j2 Q./j  T
2 log j2 R./j
 1
2 tr
(
P 1
0 ./
h
P s
0 C .ms
0  m0.// .ms
0  m0.//Ti)
 1
2
T
X
kD1
tr
˚
Q1./ E

.xk  f.xk1; // .xk  f.xk1; //T j y1WT

 1
2
T
X
kD1
tr
˚
R1./ E

.yk  h.xk; // .yk  h.xk; //T j y1WT

;
(12.55)
where the expectations are over the counterparts of the distributions in
Equations (12.42) obtained from the Gaussian smoother.
In practice, we can approximate the Gaussian smoother and Gaussian
integrals above with Taylor series approximations (EKF/ERTSS) or by
sigma-point methods such as Gauss–Hermite or spherical cubature integra-
tion or the unscented transform. The M-step for the noise parameters can
indeed be implemented analogously to the linear case in Theorem 12.5, be-
cause the maxima of the above Q with respect to the noise covariance are
simply
Q D 1
T
T
X
kD1
E

.xk  f.xk1; // .xk  f.xk1; //T j y1WT

;
R D 1
T
T
X
kD1
E

.yk  h.xk; // .yk  h.xk; //T j y1WT

:
(12.56)
The details of implementation of the M-step for other kinds of parameter
depends on the actual functional form of f and h. If the parameters appear
linearly in the functions, it is possible to ﬁnd closed form solutions for the
maxima analogously to the linear case (Theorem 12.5). Obviously, even
when analytical solutions cannot be found, it would be possible to use
iterative optimization methods inside EM. But if iterative methods need to
be used anyway, then with the same effort we can try to ﬁnd the minimum

12.3 Practical parameter estimation in state space models
195
of the energy function directly (recall that it is what EM tries to ﬁnd as
well).
Also in the non-linear case Fisher’s identity (Equation (12.32)), in prin-
ciple, gives an easy way to evaluate the gradients of the energy function.
The problem is that both the energy function and the gradient given by
Fisher’s identity are approximations, and there is no guarantee that the
approximations involved are the same. That is, the derivative given by
Fisher’s identity might not be exactly the derivative of the approximate
energy function given by the Gaussian ﬁlter. The derivation of the Fisher’s
identity based derivative expression is left as an exercise to the reader.
12.3.4 Parameter estimation via particle ﬁltering and smoothing
Particle ﬁltering can also be used for approximate evaluation of the
marginal likelihood and also the energy function needed in parameter
estimation. In the particle ﬁltering approach we can consider generic
models of the form
  p./;
x0  p.x0 j /;
xk  p.xk j xk1; /;
yk  p.yk j xk; /;
(12.57)
where  2 Rd is the unknown parameter to be estimated. The approxi-
mate evaluation of the marginal likelihood can be done with the following
modiﬁcation of the SIR particle ﬁlter (see, e.g., Andrieu et al., 2004; Creal,
2012).
Algorithm 12.8 (SIR based energy function approximation)
An approxi-
mation to the marginal likelihood of the parameters can be evaluated dur-
ing the sequential importance resampling (SIR) algorithm (particle ﬁlter),
as follows.
 Draw N samples x.i/
0 from the prior:
x.i/
0  p.x0 j /;
i D 1; : : : ; N;
(12.58)
and set w.i/
0
D 1=N, for all i D 1; : : : ; N.
 For each k D 1; : : : ; T do the following.
1 Draw samples x.i/
k from the importance distributions:
x.i/
k  .xk j x.i/
k1; y1Wk; /;
i D 1; : : : ; N:
(12.59)

196
Parameter estimation
2 Compute the following weights:
v.i/
k D p.yk j x.i/
k ; / p.x.i/
k j x.i/
k1; /
.x.i/
k j x.i/
k1; y1Wk; /
(12.60)
and compute the estimate of p.yk j y1Wk1; / as
Op.yk j y1Wk1; / D
X
i
w.i/
k1 v.i/
k :
(12.61)
3 Compute the normalized weights as
w.i/
k / w.i/
k1 v.i/
k :
(12.62)
4 If the effective number of particles (7.27) is too low, perform resam-
pling.
The approximation of the marginal likelihood of the parameters is
p.y1WT j / 
Y
k
Op.yk j y1Wk1; /;
(12.63)
and the corresponding energy function approximation is
'T ./   log p./ 
T
X
kD1
log Op.yk j y1Wk1; /:
(12.64)
The energy function approximation could also be computed recursively
during the SIR algorithm above.
The particle ﬁlter based energy function approximation can now be used,
for example, in the Metropolis–Hastings based MCMC algorithm. The re-
sult is the particle Markov chain Monte Carlo (PMCMC) method (Andrieu
et al., 2010) and, more speciﬁcally, the
particle marginal Metropolis–
Hastings (PMMH) algorithm variant of it. Although the idea of using a
particle ﬁlter based likelihood approximations in MCMC is an old and ob-
vious idea (see Andrieu et al., 2004), it was only proved recently by An-
drieu et al. (2010) that the resulting algorithm is exact in the sense that it
samples from the right distribution. Thus the result is (asymptotically) the
same as if we had used the exact energy function instead of the particle
ﬁlter based approximation in the MCMC method.
Example 12.2 (Estimation of noise variance in the pendulum model)
Fig-
ure 12.2 shows the posterior distribution approximation for the noise vari-
ance R computed with a Gaussian ﬁlter for the pendulum model in Exam-
ple 3.7. The ﬁgure also shows the histogram of samples from the PMCMC

12.3 Practical parameter estimation in state space models
197
0.05
0.1
0.15
0
10
20
30
40
50
60
70
80
90
 R
 p(R | y1:T )
 
 
PMCMC Histogram
Gaussian Filter Estimate
True Parameter Value
Figure 12.2 Posterior distribution of the noise variance R in the
pendulum model (see Example 12.2). The approximation
computed with the the Gaussian ﬁlter is thinner than the reference
result computed with the PMCMC. Thus the uncertainty in the
parameter estimate is not properly captured by the Gaussian ﬁlter
based approximation.
method which thus should approach the true posterior of the parameter. As
can be seen, the posterior distribution estimate of the Gaussian ﬁlter (ﬁfth
order Gauss–Hermite ﬁlter) is a bit thinner than the true posterior distri-
bution. That is, the uncertainty in the parameter value is underestimated.
In this case we are lucky, because the true parameter value still remains in-
side the high density area of the posterior distribution approximation, but
this might not always be the case.
In principle, it would also be possible to use the likelihood or energy
function approximation in gradient-free optimization methods for ﬁnding
MAP or ML estimates. However, this might turn out to be hard, because
even if we ﬁxed the random number generator sequence in the particle ﬁl-
ter, the likelihood function would not be continuous in  (see, e.g., Kantas
et al., 2009). This also renders the use of gradient based optimization meth-
ods impossible.
By comparing to the Rao–Blackwellized particle ﬁlter in Algorithm 7.6,
it is easy to see that the corresponding likelihood approximation can be

198
Parameter estimation
obtained by setting
v.i/
k
D p.yk j u.i/
0Wk; y1Wk1; / p.u.i/
k j u.i/
k1; /
.u.i/
k j u.i/
0Wk1; y1Wk; /
:
(12.65)
The likelihood approximation itself remains the same as in Equa-
tion (12.61):
Op.yk j y1Wk1; / D
X
i
w.i/
k1 v.i/
k :
We can also implement the EM algorithm using particle smoothing. Recall
that to implement the EM algorithm we need to evaluate Q.; .n// via
Equation (12.29) which in turn requires us to evaluate the expectations ap-
pearing in Equation (12.30). The actual form of the approximation depends
on the particle smoother that we are using. In the case of the backward-
simulation smoother we have the following simple algorithm (Wills et al.,
2013).
Algorithm 12.9 (Evaluation of Q via the backward-simulation smoother)
Assume that we have simulated S trajectories fQx.i/
0WT W i D 1; : : : ; Sg us-
ing the backward-simulation smoother in Algorithm 11.2 with parameter
values ﬁxed to .n/. Then the integrals in Equation (12.30) can be approx-
imated as
I1.; .n//  1
S
S
X
iD1
log p.Qx.i/
0 j /;
I2.; .n// 
T 1
X
kD0
1
S
S
X
iD1
log p.Qx.i/
kC1 j Qx.i/
k ; /;
I3.; .n// 
T
X
kD1
1
S
S
X
iD1
log p.yk j Qx.i/
k ; /:
(12.66)
If we are using the reweighting (or marginal) particle smoother in Algo-
rithm 11.3, the corresponding expectations can be approximated as follows
(Sch¨on et al., 2011).
Algorithm 12.10 (Evaluation of Q via the reweighting smoother)
As-
sume that we have the set of particles fx.i/
k
W k D 0; : : : ; T I i D 1; : : : ; Ng
representing the ﬁltering distribution and we have calculated the weights
fw.i/
kjT W k D 0; : : : ; T I i D 1; : : : ; Ng using Algorithm 11.3. Then we can

12.3 Practical parameter estimation in state space models
199
approximate the integrals in Equation (12.30) as follows:
I1.; .n// 
X
i
w.i/
0jT log p.x.i/
0 j /;
I2.; .n// 
T 1
X
kD0
X
i
X
j
w.j /
kC1jT w.i/
k p.x.j /
kC1 j x.i/
k ; .n//
hP
l w.l/
k p.x.j /
kC1 j x.l/
k ; .n//
i
 log p.x.j /
kC1 j x.i/
k ; /;
I3.; .n// 
T
X
kD1
X
i
w.i/
kjT log p.yk j x.i/
k ; /:
(12.67)
By differentiating the expressions in the above algorithms with respect
to , we can also get an approximation for @Q.; .n//=@. This approxi-
mation can be further used in Fisher’s identity in Equation (12.32) to give
approximations for the gradients of the energy function (Ninness et al.,
2010). For more information on this kind of approach as well as other meth-
ods for particle ﬁltering based parameter estimation, the reader is referred
to Andrieu et al. (2004), Kantas et al. (2009), and Poyiadjis et al. (2011).
12.3.5 Rao–Blackwellization of parameters
In this section we show how Rao–Blackwellization can sometimes be used
for marginalizing out the static parameters in state space models. Let’s start
by considering the following generalized version of the pendulum example
used in S¨arkk¨a (2006) and S¨arkk¨a and Sottinen (2008):
xk D f.xk1/ C qk1;
yk D h.xk/ C rk;
rk  N.0; R/;
R  Inv-2.0; R0/;
(12.68)
where qk1  N.0; Q/. This is thus the same kind of non-linear state
space model that we have already considered in this book, except that here
the measurement noise variance R is considered as unknown and given an
inverse-chi-squared prior distribution Inv-2.0; R0/.
It turns out that we can do sequential Monte Carlo sampling in this
model such that we do not need to sample the values of R. Instead, it is
enough to sample the state values and then carry the parameters of the dis-
tribution of R, conditional on the previous measurements and the histories
of samples. The idea is the following.

200
Parameter estimation
1 Assume that we have generated a set of particle histories fw.i/
k ; x.i/
0Wk W
i D 1; : : : ; Ng which approximate the full distribution of the states as
follows:
p.x0Wk1 j y1Wk1/ 
X
i
w.i/
k1 ı.x0Wk1  x.i/
0Wk1/;
(12.69)
which is thus the conventional SIR ﬁlter approximation when we store
the full sample histories (see Section 11.1). Further assume that the con-
ditional distribution of R given measurements y1Wk1 and the sampled
state history x.i/
0Wk1 is
p.R j x.i/
0Wk1; y1Wk1/ D Inv-2.R j .i/
k1; R.i/
k1/;
(12.70)
where .i/
k1; R.i/
k1 have already been computed for each i. Then we have
the following approximation for the full distribution of states and param-
eters:
p.x0Wk1; R j y1Wk1/
D p.R j x0Wk1; y1Wk1/ p.x0Wk1 j y1Wk1/

X
i
w.i/
k1 Inv-2.R j .i/
k1; R.i/
k1/ ı.x0Wk1  x.i/
0Wk1/:
(12.71)
2 Let’s now draw samples from an importance distribution:
x.i/
k  .x.i/
k j x.i/
k1; yk/:
(12.72)
3 We can now evaluate the likelihood of the measurement given x.i/
k and
the previous measurements as follows:
p.yk j x.i/
k ; y1Wk1/
D
Z
N.yk j h.x.i/
k /; R/ Inv-2.R j .i/
k1; R.i/
k1/ dR
D t.i/
k .yk j h.x.i/
k /; R.i/
k /;
(12.73)
where the parameters of the Student’s t-distribution above are
.i/
k
D .i/
k1 C 1;
R.i/
k D .i/
k1R.i/
k1 C .yk  h.x.i/
k //2
.i/
k1 C 1
:
(12.74)

12.3 Practical parameter estimation in state space models
201
This allows us to compute the next step importance weights for the SIR
algorithm as follows:
w.i/
k
/ p.yk j x.i/
k ; y1Wk1/ N.x.i/
k j f.x.i/
k1/; Q/
.x.i/
k j x.i/
k1; yk/
:
(12.75)
4 Given the measurement and the state we can further compute the condi-
tional distribution of R given y1Wk and x.i/
0Wk:
p.R j x.i/
0Wk; y1Wk/ D Inv-2.R j .i/
k ; R.i/
k /:
(12.76)
5 Now we again have a similar representation for the ﬁltering distribution
as in step 1 and we can set k  k C 1 and go back to step 1. But before
that we can also do resampling jointly for the state histories x.i/
0Wk and the
parameters .i/
k ; R.i/
k as in the conventional SIR algorithm.
In the above algorithm, we would not actually need to carry the whole
state histories in the ﬁlter, but theoretically the parameters of the inverse
chi squared distributions are indeed conditioned on the full state histories.
The procedure above is a Rao–Blackwellized particle ﬁlter where the
static parameter R has been marginalized out and is carried via its sufﬁcient
statistics .i/
k ; R.i/
k conditioned on the particle histories x.i/
0Wk and measure-
ments. In another example given in S¨arkk¨a (2006) and S¨arkk¨a and Sottinen
(2008) this procedure is used for marginalizing out the unknown popula-
tion size in a Poisson measurement model. The same idea can be used in
various other types of model.
In an abstract sense the method can be applied to a class of models of
the form
xk  p.xk j xk1; /;
yk  p.yk j xk; /;
  p./;
(12.77)
where the vector  contains the unknown static parameters. Now if the
posterior distribution of the parameters  depends only on some sufﬁcient
statistics
Tk D Tk.x1Wk; y1Wk/;
(12.78)
and if the sufﬁcient statistics are easy to update recursively, Tk  Tk1,
then sampling of the state and parameters can be performed by recursively
computing the sufﬁcient statistics conditionally on the sampled states and
the measurements analogously to the example above. The original idea of
the method seems to have appeared quite independently in Storvik (2002),

202
Parameter estimation
Fearnhead (2002), Djuric and Miguez (2002), and more recently it has been
applied to estimation of full noise covariances in state space models by
Saha et al. (2010).
A particularly useful special case, which includes the example above,
is obtained when the dynamic model is independent of the parameters .
In this case, if conditionally to the state xk the prior p./ belongs to the
conjugate family of the likelihood p.yk j xk; /, the static parameters 
can be marginalized out and only the states need to be sampled. This idea
can be extended to the time-varying case if the dynamic model has such
a form which keeps the predicted distribution of the parameter within the
conjugate family (see S¨arkk¨a and Nummenmaa, 2009).
When the static parameter appears linearly in the model we recover
a noise free version of the conditionally Gaussian Rao–Blackwellization
considered in Section 7.5 (see Sch¨on and Gustafsson, 2003). The Rao–
Blackwellized particle ﬁlter can then be seen as a time-varying extension
of this method in the conditionally linear Gaussian case.
12.4 Exercises
12.1
Implement the EM algorithm for ML estimation of the measurement noise
variance in the Gaussian random walk model considered in Examples 4.1,
4.2, and 8.1. Test the algorithm with simulated data.
12.2
Implement the algorithm for computing the energy function for the Gaussian
random walk model as well as its derivative with respect to the noise variance
(via the sensitivity equations given in Section A.3). Generate some simulated
data and use a gradient based optimization method to ﬁnd the ML estimate
of the parameter.
12.3
With the Gaussian random walk model, ﬁnd the expression for the Fisher’s
identity based derivative with respect to the noise parameter. Check numeri-
cally that it matches the expression obtained with the sensitivity equations.
12.4
Implement a random walk Metropolis based MCMC method for estimating
the noise variance in the Gaussian random walk model. Use the Kalman ﬁlter
for evaluating the energy function. For simplicity, you can assume that the
prior for the parameter has the form p.R/ / 1.
12.5
Derive the sensitivity equations for the ﬁrst order extended Kalman ﬁlter.
12.6
Derive the equation for the derivative of the energy function resulting
from differentiating the Gaussian smoothing based approximation in
Algorithm 12.7 and using Fisher’s identity (Equation (12.32)).
12.7
Compute and plot the approximate energy function obtained for the noise
variance in the model given in Exercise 5.1 by using a non-linear Kalman
ﬁlter based estimate of the energy function. You can select the ﬁlter freely.

Exercises
203
12.8
Implement a random walk Metropolis based MCMC method for estimating
the noise variance in the model given in Exercise 5.1. Use one of the non-
linear Kalman ﬁlters to approximate the energy function.
12.9
Implement a random walk Metropolis based particle MCMC method for
estimating the noise variance in the Gaussian random walk model. Use a
simple bootstrap ﬁlter as the particle ﬁlter.
12.10 Implement a random walk Metropolis based particle MCMC method for
estimating the noise variance in the model given in Exercise 5.1.

13
Epilogue
13.1 Which method should I choose?
An important question when preparing to solve a speciﬁc ﬁltering, smooth-
ing, or parameter estimation problem for state space models is: which of
the numerous methods should I choose for a particular application? Ob-
viously if the problem is linear, then the Kalman ﬁlter and RTS smoother
are natural choices – also for evaluating the quantities needed for parame-
ter estimation. But if the system is non-linear/non-Gaussian the question is
harder.
When the noises in the system can be modeled as Gaussian and the
model is of the form
xk D f.xk1/ C qk1;
yk D h.xk/ C rk;
(13.1)
where f and h are somewhat well-behaved functions, then the ﬁrst choice
would be one of the Gaussian approximation based ﬁlters and smoothers
– provided that we are working on an application and the theoretical ex-
actness of the solution is not important per se, but we are interested in
getting good estimates of the state and parameters. If theoretical exactness
is needed, then the only option is to use particle ﬁlters and smoothers (or
grid based solutions).
Among the Gaussian approximation based ﬁlters and smoothers it is al-
ways a good idea to start with an EKF and an ERTSS. These are the only
algorithms that have been used for over half a century in practical appli-
cations and there are good reasons for that – they simply work. Statistical
linearization can sometimes be used to enhance implementations of the
EKF afterwards by replacing some of the function evaluations by their ex-
pectations. Otherwise the SLF is a theoretical tool rather than a practical
ﬁltering algorithm.
204

13.1 Which method should I choose?
205
With some models the EKF and ERTSS do not work well or at all, and
in that case we can move to the sigma-point methods. The spherical cuba-
ture and unscented methods have the advantage of being computationally
quite light, but still they tend to produce very good results. However, these
methods have the problem that their error estimates might not always be
consistent with the actual errors, a problem which the EKF/ERTSS meth-
ods also tend to have. The unscented transform has more parameters to
tune for a particular problem than the spherical cubature method, which
can be an advantage or a disadvantage (recall that the cubature spherical
method is an unscented transform with a certain selection of parameters).
The Gauss–Hermite based methods tend to be more consistent in errors and
are thus more robust approximations, but have the disadvantage of having
high computational complexity. One should always remember that there
is no guarantee that using more complicated ﬁltering and smoothing algo-
rithms would actually improve the results, therefore it is a good idea to
always test the EKF and ERTSS ﬁrst. The bootstrap ﬁlter has the advan-
tage that it is very easy to implement and thus it can sometimes be used as
a reference solution when testing the performance and debugging Gaussian
approximation based ﬁlters and smoothers.
If the problem has a more complicated form which cannot be ﬁtted into
the non-linear Gaussian framework or when the Gaussian approximations
do not work for other reasons, we need to go to particle based solutions.
Because the bootstrap ﬁlter is very easy to implement, it (and probably one
of the particle smoothers) should be the ﬁrst option to test with a sufﬁ-
ciently large number of particles. However, the clear disadvantage of par-
ticle methods is the high computational load and thus it is a good idea
to check at quite an early stage if any of the states or parameters can be
marginalized out (“Rao–Blackwellized”) exactly or approximately. If this
is the case, then one should always prefer marginalization to sampling.1
The other thing to check is if it is possible to use the optimal or almost op-
timal importance distribution in the particle ﬁlter. In principle, non-linear
Gaussian approximation based ﬁlters can be used to form such importance
distributions, but this may also lead to overly heavy computational methods
as well as to convergence problems. If they are used, then it might be ad-
visable to artiﬁcially increase the ﬁlter covariances a bit or to use Student’s
t distributions instead of using the Gaussian approximations as such.
1 The rule of thumb is: use Monte Carlo sampling only as a last resort when all the other
options have failed.

206
Epilogue
When it comes to parameter estimation, it is generally a good idea to
use the same approximations in the parameter estimation method as will
be used in the ﬁnal application, assuming that the parameter estimation re-
sults will later be used in ﬁlters and smoothers to solve a state estimation
problem. Furthermore, if a single parameter estimation result (point esti-
mate) is needed anyway, ML and MAP estimates are not bad choices, but
it might be useful to check the spread of the posterior distribution of param-
eters using an MCMC method. But if the true values of the parameters are
of interest, then the combination of particle ﬁltering and MCMC is proba-
bly the safest bet. However, one should remember that estimating the true
parameters of the system is possible only in simulated scenarios and in real
applications the models used will be more or less wrong anyway. On the
other hand, we should be careful not to ruin already probably inaccurate
models with bad approximations of ﬁlters and smoothers.
13.2 Further topics
This book is mainly concerned with non-linear Kalman ﬁltering and
smoothing as well as particle ﬁltering and smoothing approaches to
Bayesian ﬁltering and smoothing, but numerous other methods exist as
well. It is impossible to list all of them, but below we try to give pointers
to some of the methods. Regarding ﬁlters and smoothers themselves, there
are also various subareas that we did not discuss and we try to give some
pointers to them as well.
First of all, one huge area that we have not mentioned at all is continu-
ous time ﬁlters and smoothers. In these methods the dynamics of the state
and sometimes the measurements as well are modeled using stochastic dif-
ferential equations (SDEs) (Øksendal, 2003). The full theory of Bayesian
ﬁltering in such models can be found in the classic book of Jazwinski
(1970) and the smoothing theory is due to Striebel (1965) and Leondes
et al. (1970). The extended Kalman type of ﬁlter approximation can be
found in the above-mentioned references as well. Extensions of unscented
Kalman ﬁlters and smoothers to the continuous-time setting can be found
in S¨arkk¨a (2006, 2007, 2010). Extensions of Gaussian ﬁlters and smoothers
to continuous-time setting have been discussed in Singer (2008); Arasarat-
nam et al. (2010); Singer (2011); S¨arkk¨a and Solin (2012); S¨arkk¨a and Sar-
mavuori (2013). Extensions of particle ﬁlters and smoothers to continuous-
time setting can be found, for example, in Crisan and Rozovskii (2011);
S¨arkk¨a and Sottinen (2008); Murray and Storkey (2011), and references
therein.

13.2 Further topics
207
There also exist various other kinds of Gaussian integration methods that
we have not presented here that could be used for constructing new kinds
of Gaussian ﬁlters and smoothers (see, e.g., O’Hagan, 1991; Nørgaard
et al., 2000; Lefebvre et al., 2002; Wu et al., 2006; S¨arkk¨a and Hartikainen,
2010b; Sandblom and Svensson, 2012). One particularly interesting ap-
proach is to approximate the non-linear functions with a Gaussian process
based non-parametric model which is ﬁtted using a ﬁnite number of sample
points (Deisenroth et al., 2009, 2012).
One useful class of discrete-time methods is the multiple model ap-
proaches such as the generalized pseudo-Bayesian methods (GPB1 and
GPB2) as well as the interacting multiple model (IMM) algorithm (Bar-
Shalom et al., 2001). These methods can be used for approximating the
Bayesian solutions to problems with a ﬁxed number of models or modes
of operation. The active mode of the system is described by a discrete la-
tent variable which is modeled as a discrete-state Markov chain. Given the
value of the latent variable, the system is (approximately) Gaussian. The
GPB1, GPB2, and IMM algorithms are based on forming a mixture of
Gaussians approximation (a bank of Kalman or extended Kalman ﬁlters)
to the Bayesian ﬁltering solutions by using moment matching.
The above-mentioned multiple model methods are also closely related to
so-called expectation correction (EC, Barber, 2006) and expectation prop-
agation (EP, Zoeter and Heskes, 2011) methods, which can also be used
for Bayesian ﬁltering and smoothing in switching linear dynamic systems
(SLDS), which is another term used for multiple mode/model problems.
These models can also be considered as special cases of the condition-
ally Gaussian models considered in the previous section and the history of
similar approximations dates back to the works of Alspach and Sorenson
(1972) and Akashi and Kumamoto (1977). The relationship between vari-
ous methods for this type of model has recently been analyzed by Barber
(2011).
When the measurement model is non-Gaussian (e.g., Student’s t), it is
sometimes possible to use variational Bayes approximations (Agamennoni
et al., 2011; Pich´e et al., 2012) to yield to tractable inference. The expec-
tation propagation (EP) algorithm (Ypma and Heskes, 2005) can also be
used for approximate inference in non-linear and non-Gaussian dynamic
systems. Both of these approaches are also closely related to the Gaus-
sian ﬁlters and smoothers considered in this book. Variational Bayesian
approximations can also be used for estimation of unknown time-varying
parameters in state space models (S¨arkk¨a and Nummenmaa, 2009).

208
Epilogue
In the multiple target tracking context there exist a number of speciﬁc
methods to cope with the problems arising there, namely, the data associa-
tion problem and an unknown numbers of targets. The classical approaches
to the multiple target tracking problem can be found in the books of Bar-
Shalom and Li (1995) and Blackman and Popoli (1999). For more recent
approaches the reader is referred to Ristic et al. (2004) and Challa et al.
(2011) (see also S¨arkk¨a et al., 2007b).
There are a number of other important topics that have had to be omitted
here. For example, the Cram´er–Rao lower bounds (CRLB, see, e.g., Ristic
et al., 2004) are theoretical lower bounds for the mean-squared error that
can be achieved with any non-linear ﬁlter in a given ﬁltering problem. We
have also omitted the observability and controllability questions of linear
and non-linear systems (see, e.g., Kailath et al., 2000; Bar-Shalom et al.,
2001), which are related to the question of whether it is possible to deter-
mine the state of a given system from the available measurements at all. A
somewhat related issue is the question that under what conditions does a
particle ﬁlter converge to the true distribution. For more details on this topic
the reader is referred to the works of Crisan and Doucet (2002) and Hu et al.
(2008, 2011). The numerical stability of linear and non-linear Kalman ﬁl-
ters and RTS smoothers can sometimes also be enhanced by using square
root versions of them. This kind of method can be found, for example, in
the works of Bierman (1977), Grewal and Andrews (2001), Van der Merwe
and Wan (2001), and Arasaratnam and Haykin (2009, 2011).

Appendix
Additional material
A.1 Properties of Gaussian distribution
Deﬁnition A.1 (Gaussian distribution)
A random variable x 2 Rn has a
Gaussian distribution with mean m 2 Rn and covariance P 2 Rnn if its
probability density has the form
N.x j m; P/ D
1
.2 /n=2 jPj1=2 exp

1
2.x  m/T P 1 .x  m/

;
(A.1)
where jPj is the determinant of the matrix P.
Lemma A.1 (Joint distribution of Gaussian variables)
If random vari-
ables x 2 Rn and y 2 Rm have the Gaussian probability distributions
x  N.m; P/;
y j x  N.H x C u; R/;
(A.2)
then the joint distribution of x; y and the marginal distribution of y are
given as
x
y

 N

m
H m C u

;
 P
P HT
H P
H P HT C R

;
y  N.H m C u; H P HT C R/:
(A.3)
Lemma A.2 (Conditional distribution of Gaussian variables)
If the ran-
dom variables x and y have the joint Gaussian probability distribution
x
y

 N
a
b

;
 A
C
CT
B

;
(A.4)
209

210
Additional material
then the marginal and conditional distributions of x and y are given as
follows:
x  N.a; A/;
y  N.b; B/;
x j y  N.a C C B1 .y  b/; A  C B1CT/;
y j x  N.b C CT A1 .x  a/; B  CT A1 C/:
(A.5)
A.2 Cholesky factorization and its derivative
The Cholesky factor of the symmetric positive deﬁnite matrix P is a lower
triangular matrix A such that
P D A AT:
(A.6)
The matrix A can be computed by the Cholesky factorization algorithm
(see, e.g., Golub and van Loan, 1996) presented below.
Algorithm A.1 (Cholesky factorization)
The Cholesky factor A of the
matrix P 2 Rnn can be computed as follows:
procedure CHOL(P)
for i  1 : : : n do
Aii D
q
Pii  P
k<i A2
ik
for j  i C 1 : : : n do
Aji D

Pji  P
k<i Ajk Aik
	
=Aii
end for
end for
return A
end procedure
The partial derivative of the Cholesky factor @A=@	 with respect to a
scalar parameters 	 can be computed using the following algorithm once
P and @P=@	 are known. The algorithm can be derived by formally differ-
entiating the Cholesky factorization algorithm equations.
Algorithm A.2 (Partial derivative of Cholesky factorization)
The partial
derivative D D @A=@	 of the Cholesky factor of P 2 Rnn with respect to
a scalar parameter 	 can be computed as follows:
procedure DCHOL(P; @P=@	)
for i  1 : : : n do
Aii  
q
Pii  P
k<i A2
ik

A.2 Cholesky factorization and its derivative
211
Dii  .@Pii=@	  P
k<i 2Dik Aik/=Aii=2
for j  i C 1 : : : n do
Aji  .Pji  P
k<i Ajk Aik/=Aii
temp  @Pji=@	  P
k<i.Djk Aik C Ajk Dik/
Dji  temp=Aii  .Dii=Aii/ Aji
end for
end for
return D
end procedure
Another way to compute the same derivative is via the following theo-
rem.
Theorem A.1 (Partial derivative of Cholesky factorization)
The partial
derivative @A=@	 of the lower triangular Cholesky factor A such that P D
A AT with respect to a scalar parameter 	 can be computed as
@A
@	 D A ˆ

A1 @P
@	 AT

;
(A.7)
where ˆ./ is a function returning the lower triangular part and half the
diagonal of the argument as follows:
ˆij.M/ D
8
ˆ<
ˆ:
Mij;
if i > j;
1
2Mij;
if i D j;
0;
if i < j:
(A.8)
Proof
We use a similar trick that was used in the derivation of the time
derivative of the Cholesky factor in Morf et al. (1978). We have
P D A AT:
(A.9)
By taking the derivative with respect to 	 we get
@P
@	 D @A
@	 AT C A @AT
@	 :
(A.10)
Multiplying from the left with A1 and from the right with AT gives
A1 @P
@	 AT D A1 @A
@	 C @AT
@	 AT:
(A.11)
Now the right-hand side is the sum of a lower triangular matrix and an
upper triangular matrix with identical diagonals. Thus we can recover

212
Additional material
A1 @A=@	 via
A1 @A
@	 D ˆ

A1 @P
@	 AT

;
(A.12)
where the function ˆ./ returns the (strictly) lower triangular part of the
argument and half of the diagonal. Multiplying from the left with A gives
the result.
A.3 Parameter derivatives for the Kalman ﬁlter
Theorem 12.3 gives the energy function (i.e., the negative logarithm of the
unnormalized posterior distribution) of the parameters for the following
linear Gaussian model:
xk D A./ xk1 C qk1;
yk D H./ xk C rk;
(A.13)
where qk1  N.0; Q.//, rk  N.0; R.//, and x0  N.m0./; P0.//.
The parameters derivatives which are needed, for example, for implement-
ing a gradient based optimization method for ﬁnding ML or MAP estimates
can be evaluated via the following sensitivity equations (Gupta and Mehra,
1974) which can be derived by termwise differentiation of the energy func-
tion and Kalman ﬁlter equations in Theorem 12.3.
Theorem A.2 (Energy function derivative for linear Gaussian model I)
The derivative of the energy function given in Theorem 12.3 can be com-
puted via the following recursion along with Kalman ﬁltering:
@'k./
@	i
D @'k1./
@	i
C 1
2 tr

S1
k ./ @Sk./
@	i

C vT
k ./ S1
k ./ @vk./
@	i
 1
2vT
k ./ S1
k ./ @Sk./
@	i
S1
k ./ vk./;
(A.14)
where on the Kalman ﬁlter prediction step we compute
@m
k ./
@	i
D @A./
@	i
mk1./ C A./ @mk1./
@	i
;
@P 
k ./
@	i
D @A./
@	i
Pk1./ AT./ C A./ @Pk1./
@	i
AT./
C A./ Pk1./ @AT./
@	i
C @Q./
@	i
;
(A.15)

A.3 Parameter derivatives for the Kalman ﬁlter
213
and on the Kalman ﬁlter update step we compute
@vk./
@	i
D @H./
@	i
m
k ./  H./ @m
k ./
@	i
;
@Sk./
@	i
D @H./
@	i
P 
k ./ HT./ C H./ @P 
k ./
@	i
HT./
C H./ P 
k ./ @HT./
@	i
C @R./
@	i
;
@Kk./
@	i
D @P 
k ./
@	i
HT./ S1
k ./ C P 
k ./ @HT./
@	i
S1
k ./
 P 
k ./ HT./ S1
k ./ @Sk./
@	i
S1
k ./;
@mk./
@	i
D @m
k ./
@	i
C @Kk./
@	i
vk./ C Kk./ @vk./
@	i
;
@Pk./
@	i
D @P 
k ./
@	i
 @Kk./
@	i
Sk./ KT
k./
 Kk./ @Sk./
@	i
KT
k./  Kk./ Sk./ @KT
k./
@	i
:
(A.16)
The recursion should be started from the initial condition @'0./=@ D
 @ log p./=@ .
Another way to compute the same derivative is by using Fisher’s identity
(Equation 12.32) together with the expression for Q in Theorem 12.4. The
result is the following.
Theorem A.3 (Energy function derivative for linear Gaussian model II)
The derivative of the energy function given in Theorem 12.3 can be com-
puted as
@'T ./
@
D @ log p./
@
 @Q.; .n//
@
ˇˇˇˇ
.n/D
;
(A.17)

214
Additional material
where
@Q.; .n//
@	i
ˇˇˇˇ
.n/D
D 1
2 tr

P 1
0
@P0
@	i

 T
2 tr

Q1 @Q
@	i

 T
2 tr

R1 @R
@	i

C 1
2 tr
(
P 1
0
@P0
@	i
P 1
0
h
P s
0 C .ms
0  m0/ .ms
0  m0/Ti)
C 1
2 tr
(
P 1
0
"
@m0
@	i
.ms
0  m0/T C .ms
0  m0/ @mT
0
@	i
#)
C T
2 tr
(
Q1 @Q
@	i
Q1 h
†  C AT  A CT C A ˆ ATi)
 T
2 tr
(
Q1
"
 C @AT
@	i
 @A
@	i
CT C @A
@	i
ˆ AT C A ˆ @AT
@	i
#)
C T
2 tr
(
R1 @R
@	i
R1 h
D  B HT  H BT C H † HTi)
 T
2 tr
(
R1
"
 B @HT
@	i
 @H
@	i
BT C @H
@	i
† HT C H † @HT
@	i
#)
;
(A.18)
where all the terms are evaluated at .
A.4 Parameter derivatives for the Gaussian ﬁlter
In this section we consider the computation of the gradient of the Gaussian
ﬁltering based energy function in Algorithm 12.6 which was considered
with models of the form
xk D f.xk1; / C qk1;
yk D h.xk; / C rk:
(A.19)
In order to compute the derivative, it is convenient to ﬁrst rewrite the ex-
pectations as expectations over unit Gaussian distributions as follows:
m
k ./ D
Z
f.xk1; / N.xk1 j mk1./; Pk1.// dxk1
D
Z
f.mk1./ C
p
Pk1./ ; / N. j 0; I/ d:
(A.20)

A.4 Parameter derivatives for the Gaussian ﬁlter
215
The derivative of this expression can now be computed as
@m
k ./
@	i
D
Z "
Fx.mk1./ C
p
Pk1./ ; /

 
@mk1./
@	i
C @
p
Pk1./
@	i

!
C @f
@	i
.mk1./ C
p
Pk1./ ; /
#
N. j 0; I/ d:
Assuming that we are using the Cholesky factorization based matrix square
root, the derivative @
p
Pk1./=@	i can be computed with Algorithm A.2
or Theorem A.1 given in Section A.2.
The above form is directly suitable for sigma-point methods, because
they are based on the same change of variables. That is, the corresponding
derivative of the sigma-point approximation will be
@m
k ./
@	i

X
j
Wj
"
Fx.mk1./ C
p
Pk1./ .j /; /

 
@mk1./
@	i
C @
p
Pk1./
@	i
.j /
!
C @f
@	i
.mk1./ C
p
Pk1./ .j /; /
#
;
(A.21)
where Wj and .j / are the weights and unit sigma points of the used sigma-
point method. A nice thing in the above expression is that it is exactly the
derivative of the sigma-point approximation to m
k ./.
The derivatives of the Gaussian ﬁltering based energy function can now
be expressed as follows.
Algorithm A.3 (Derivatives of Gaussian ﬁltering based energy function)
The recursion for the derivative of the approximate energy function is
@'k./
@	i
' @'k1./
@	i
C 1
2 tr

S1
k ./ @Sk./
@	i

C vT
k ./ S1
k ./ @vk./
@	i
 1
2vT
k ./ S1
k ./ @Sk./
@	i
S1
k ./ vk./:
(A.22)

216
Additional material
The derivatives of the prediction step are
@m
k
@	i
D
Z "
Fx

mk1 C
p
Pk1 ; 
 @mk1
@	i
C @pPk1
@	i


C @f
@	i

mk1 C
p
Pk1 ; 
 #
N. j 0; I/ d;
@P 
k
@	i
D
Z "
Fx

mk1 C
p
Pk1 ; 
 @mk1
@	i
C @pPk1
@	i


C @f
@	i

mk1 C
p
Pk1 ; 

 @m
k
@	i
#

"
f

mk1 C
p
Pk1 ; 

 m
k
#T
N. j 0; I/ d
C
Z "
f

mk1 C
p
Pk1 ; 

 m
k
#

"
Fx

mk1 C
p
Pk1 ; 
 @mk1
@	i
C @pPk1
@	i


C @f
@	i

mk1 C
p
Pk1 ; 

 @m
k
@	i
#T
N. j 0; I/ d C @Qk1
@	i
;
(A.23)
where Fx is the Jacobian matrix of x 7! f.x; /. In the above expressions
as well as in the following we have dropped the dependencies of various
terms on the parameters  to simplify the notation. The derivatives of the
update step are
@k
@	i
D
Z "
Hx

m
k C
q
P 
k ; 
  
@m
k
@	i
C @pP 
k
@	i

!
C @h
@	i

m
k C
q
P 
k ; 
 #
N. j 0; I/ d;
@vk
@	i
D @k
@	i
;
@Sk
@	i
D
Z "
Hx

m
k C
q
P 
k ; 
  
@m
k
@	i
C @pP 
k
@	i

!

A.4 Parameter derivatives for the Gaussian ﬁlter
217
C @h
@	i

m
k C
q
P 
k ; 

 @k
@	i
#

"
h

m
k C
q
P 
k ; 

 k
#T
N. j 0; I/ d
C
Z "
h

m
k C
q
P 
k ; 

 k
#

"
Hx

m
k C
q
P 
k ; 
  
@m
k
@	i
C @pP 
k
@	i

!
C @h
@	i

m
k C
q
P 
k ; 

 @k
@	i
#T
N. j 0; I/ d C @Rk
@	i
;
@Ck
@	i
D
Z (
@pP 
k
@	i

 
h

m
k C
q
P 
k ; 

 k
!T
C
q
P 
k 
"
Hx

m
k C
q
P 
k ; 
  
@m
k
@	i
C @pP 
k
@	i

!
C @h
@	i

m
k C
q
P 
k ; 

 @k
@	i
#T)
N. j 0; I/ d;
@Kk
@	i
D @Ck
@	i
S1
k
 Ck S1
k
@Sk
@	i
S1
k ;
@mk
@	i
D @m
k
@	i
C @Kk
@	i
vk C Kk
@vk
@	i
;
@Pk
@	i
D @P 
k
@	i
 @Kk
@	i
Sk KT
k  Kk
@Sk
@	i
KT
k  Kk Sk
@KT
k
@	i
;
(A.24)
where Hx is the Jacobian matrix of x 7! h.x; /. The derivatives of the
Cholesky factors can be computed with Algorithm A.2 or Theorem A.1
given in Section A.2.
The corresponding sigma-point approximations can be obtained by ap-
proximating the integrals analogously to Equation (A.21). The resulting
derivative will be exact in the sense that it is the exact derivative of the
corresponding sigma-point based approximation to the energy function.
We could also change back to the original variable, which gives, for
example, the following representation for the derivative of the predicted

218
Additional material
mean:
@m
k
@	i
D
Z "
Fx.xk1; / g.xk1; / C @f.xk1; /
@	i
#
 N.xk1 j mk1; Pk1/ dxk1;
(A.25)
where
g.xk1; /
D @mk1
@	i
C @pPk1
@	i

p
Pk1
1
.xk1  mk1/ :
(A.26)
The derivation of the full set of equations is left as an exercise to the reader.

References
Agamennoni, G., Nieto, J., and Nebot, E. 2011. An outlier-robust Kalman ﬁlter. Pages
1551–1558 of: IEEE International Conference on Robotics and Automation (ICRA).
Akashi, H. and Kumamoto, H. 1977. Random sampling approach to state estimation in
switching environments. Automatica, 13(4), 429–434.
Alspach, D. L. and Sorenson, H. W. 1972. Nonlinear Bayesian estimation using Gaus-
sian sum approximations. IEEE Transactions on Automatic Control, 17(4).
Andrieu, C., De Freitas, N., and Doucet, A. 2002. Rao-Blackwellised particle ﬁltering
via data augmentation. In: Dietterich, T. G., Becker, S., and Ghahramani, Z. (eds.),
Advances in Neural Information Processing Systems 14. MIT Press.
Andrieu, C., Doucet, A., Singh, S., and Tadic, V. 2004. Particle methods for change
detection, system identiﬁcation, and control. Proceedings of the IEEE, 92(3), 423–
438.
Andrieu, C. and Thoms, J. 2008. A tutorial on adaptive MCMC. Statistics and Com-
puting, 18(4), 343–373.
Andrieu, C., Doucet, A., and Holenstein, R. 2010. Particle Markov chain Monte Carlo
methods. The Royal Statistical Society: Series B (Statistical Methodology), 72(3),
269–342.
Arasaratnam, I. and Haykin, S. 2009. Cubature Kalman ﬁlters. IEEE Transactions on
Automatic Control, 54(6), 1254–1269.
Arasaratnam, I. and Haykin, S. 2011. Cubature Kalman smoothers. Automatica, 47(10),
2245–2250.
Arasaratnam, I., Haykin, S., and Elliott, R. J. 2007. Discrete-time nonlinear ﬁltering
algorithms using Gauss–Hermite quadrature. Proceedings of the IEEE, 95(5), 953–
977.
Arasaratnam, I., Haykin, S., and Hurd, T. R. 2010.
Cubature Kalman ﬁltering for
continuous-discrete systems: theory and simulations. IEEE Transactions on Signal
Processing, 58(10), 4977–4993.
Bar-Shalom, Y. and Li, X.-R. 1995. Multitarget-Multisensor Tracking: Principles and
Techniques. YBS Publishing.
Bar-Shalom, Y., Li, X.-R., and Kirubarajan, T. 2001. Estimation with Applications to
Tracking and Navigation. Wiley.
Barber, D. 2006. Expectation correction for smoothed inference in switching linear
dynamical systems. The Journal of Machine Learning Research, 7, 2515–2540.
219

220
References
Barber, D. 2011. Approximate inference in switching linear dynamical systems using
Gaussian mixtures. Chapter 8, pages 166–181 of: Barber, D., Cemgil, A. T., and
Chiappa, S. (eds.), Bayesian Time Series Models. Cambridge University Press.
Berger, J. O. 1985. Statistical Decision Theory and Bayesian Analysis. Springer.
Bernardo, J. M. and Smith, A. F. M. 1994. Bayesian Theory. John Wiley & Sons.
Bierman, G. J. 1977. Factorization Methods for Discrete Sequential Estimation. Aca-
demic Press.
Bishop, C. M. 2006. Pattern Recognition and Machine Learning. Springer.
Blackman, S. and Popoli, R. 1999. Design and Analysis of Modern Tracking Systems.
Artech House Radar Library.
Briers, M., Doucet, A., and Maskell, S. 2010. Smoothing algorithms for state-space
models. Annals of the Institute of Statistical Mathematics, 62(1), 61–89.
Brooks, S., Gelman, A., Jones, G. L., and Meng, X.-L. 2011. Handbook of Markov
Chain Monte Carlo. Chapman & Hall/CRC.
Capp´e, O., Moulines, E., and Ryd´en, T. 2005. Inference in Hidden Markov Models.
Springer.
Challa, S., Morelande, M. R., Muˇsicki, D., and Evans, R. J. 2011. Fundamentals of
Object Tracking. Cambridge University Press.
Chen, R. and Liu, J. S. 2000. Mixture Kalman ﬁlters. Journal of the Royal Statistical
Society: Series B (Statistical Methodology), 62(3), 493–508.
Cox, H. 1964. On the estimation of state variables and parameters for noisy dynamic
systems. IEEE Transactions on Automatic Control, 9(1), 5–12.
Crassidis, J. L. and Junkins, J. L. 2004.
Optimal Estimation of Dynamic Systems.
Chapman & Hall/CRC.
Creal, D. 2012. A survey of sequential Monte Carlo methods for economics and ﬁnance.
Econometric Reviews, 31(3), 245–296.
Crisan, D. and Doucet, A. 2002. A survey of convergence results on particle ﬁltering
for practitioners. IEEE Transactions on Signal Processing, 50(3), 736–746.
Crisan, D. and Rozovskii, B. (eds.) 2011. The Oxford Handbook of Nonlinear Filtering.
Oxford University Press.
Daum, F. and Huang, J. 2003. Curse of dimensionality and particle ﬁlters. Pages 1979–
1993 of: Proceedings of the IEEE Aerospace Conference, vol. 4.
Deisenroth, M. P., Huber, M. F., and Hanebeck, U. D. 2009. Analytic moment-based
Gaussian process ﬁltering. In: Proceedings of the 26th International Conference on
Machine Learning.
Deisenroth, M., Turner, R., Huber, M., Hanebeck, U., and Rasmussen, C. 2012. Robust
ﬁltering and smoothing with Gaussian processes. IEEE Transactions on Automatic
Control, 57(7), 1865–1871.
Dempster, A., Laird, N., and Rubin, D. 1977.
Maximum likelihood from incom-
plete data via the EM algorithm. Journal of the Royal Statistical Society: Series
B (Methodological), 39(1), 1–38.
Djuric, P. and Miguez, J. 2002. Sequential particle ﬁltering in the presence of additive
Gaussian noise with unknown parameters. Pages 1621–1624 of: IEEE International
Conference on Acoustics, Speech, and Signal Processing (ICASSP), vol. 2.
Douc, R., Garivier, A., Moulines, E., and Olsson, J. 2011. Sequential Monte Carlo
smoothing for general state space hidden Markov models. Annals of Applied Prob-
ability, 21(6), 2109–2145.

References
221
Doucet, A., Godsill, S. J., and Andrieu, C. 2000. On sequential Monte Carlo sampling
methods for Bayesian ﬁltering. Statistics and Computing, 10(3), 197–208.
Doucet, A., De Freitas, N., and Gordon, N. 2001. Sequential Monte Carlo Methods in
Practice. Springer.
Duane, S., Kennedy, A. D., Pendleton, B. J., and Roweth, D. 1987. Hybrid Monte
Carlo. Physics Letters B, 195(2), 216–222.
Fearnhead, P. 2002. Markov chain Monte Carlo, sufﬁcient statistics, and particle ﬁlters.
Journal of Computational and Graphical Statistics, 11(4), 848–862.
Fearnhead, P. and Clifford, P. 2003.
On-line inference for Hidden Markov models
via particle ﬁlters.
Journal of the Royal Statistical Society: Series B (Statistical
Methodology), 65(4), 887–899.
Fong, W., Godsill, S. J., Doucet, A., and West, M. 2002. Monte Carlo smoothing with
application to audio signal enhancement. IEEE Transactions on Signal Processing,
50(2), 438–449.
Fraser, D. and Potter, J. 1969. The optimum linear smoother as a combination of two
optimum linear ﬁlters. IEEE Transactions on Automatic Control, 14(4), 387–390.
Gelb, A. 1974. Applied Optimal Estimation. MIT Press.
Gelb, A. and Vander Velde, W. 1968. Multiple-Input Describing Functions and Non-
linear System Design. McGraw-Hill.
Gelman, A., Carlin, J. B., Stern, H. S., and Rubin, D. R. 2004. Bayesian Data Analysis.
Second edn. Chapman & Hall.
Gilks, W., Richardson, S., and Spiegelhalter, D. (eds.) 1996. Markov Chain Monte
Carlo in Practice. Chapman & Hall.
Godsill, S. J. and Rayner, P. J. 1998. Digital Audio Restoration: a Statistical Model
Based Approach. Springer-Verlag.
Godsill, S. J., Doucet, A., and West, M. 2004. Monte Carlo smoothing for nonlinear
time series. Journal of the American Statistical Association, 99(465), 156–168.
Golub, G. H. and van Loan, C. F. 1996. Matrix Computations. Third edn. The Johns
Hopkins University Press.
Golub, G. H. and Welsch, J. H. 1969. Calculation of Gauss quadrature rules. Mathe-
matics of Computation, 23(106), 221–230.
Gonzalez, R. C. and Woods, R. E. 2008. Digital Image Processing. Third edn. Prentice
Hall.
Gordon, N. J., Salmond, D. J., and Smith, A. F. M. 1993.
Novel approach to
nonlinear/non-Gaussian Bayesian state estimation. Pages 107–113 of: IEEE Pro-
ceedings on Radar and Signal Processing, vol. 140.
Grewal, M. S. and Andrews, A. P. 2001. Kalman Filtering, Theory and Practice Using
MATLAB. Wiley.
Grewal, M. S., Miyasako, R. S., and Smith, J. M. 1988. Application of ﬁxed point
smoothing to the calibration, alignment and navigation data of inertial navigation
systems. Pages 476–479 of: Position Location and Navigation Symposium.
Grewal, M. S., Weill, L. R., and Andrews, A. P. 2001. Global Positioning Systems,
Inertial Navigation and Integration. Wiley.
Gupta, N. and Mehra, R. 1974. Computational aspects of maximum likelihood es-
timation and reduction in sensitivity function calculations. IEEE Transactions on
Automatic Control, 19(6), 774–783.

222
References
Gustafsson, F. and Hendeby, G. 2012. Some relations between extended and unscented
Kalman ﬁlters. IEEE Transactions on Signal Processing, 60(2), 545–555.
Haario, H., Saksman, E., and Tamminen, J. 1999. Adaptive proposal distribution for
random walk Metropolis algorithm. Computational Statistics, 14(3), 375–395.
Haario, H., Saksman, E., and Tamminen, J. 2001. An adaptive Metropolis algorithm.
Bernoulli, 7(2), 223–242.
Hartikainen, J. and S¨arkk¨a, S. 2010. Kalman ﬁltering and smoothing solutions to tem-
poral Gaussian process regression models. Pages 379–384 of: Proceedings of IEEE
International Workshop on Machine Learning for Signal Processing (MLSP).
Hauk, O. 2004. Keep it simple: a case for using classical minimum norm estimation in
the analysis of EEG and MEG data. NeuroImage, 21(4), 1612–1621.
Hayes, M. H. 1996. Statistical Digital Signal Processing and Modeling. John Wiley &
Sons, Inc.
Haykin, S. 2001. Kalman Filtering and Neural Networks. Wiley.
Hiltunen, P., S¨arkk¨a, S., Nissil¨a, I., Lajunen, A., and Lampinen, J. 2011. State space
regularization in the nonstationary inverse problem for diffuse optical tomography.
Inverse Problems, 27, 025009.
Ho, Y. C. and Lee, R. C. K. 1964. A Bayesian approach to problems in stochastic
estimation and control. IEEE Transactions on Automatic Control, 9(4), 333–339.
Hu, X., Sch¨on, T., and Ljung, L. 2008. A basic convergence result for particle ﬁltering.
IEEE Transactions on Signal Processing, 56(4), 1337–1348.
Hu, X., Sch¨on, T., and Ljung, L. 2011.
A general convergence result for particle
ﬁltering. IEEE Transactions on Signal Processing, 59(7), 3424–3429.
H¨urzeler, M. and Kunsch, H. R. 1998. Monte Carlo approximations for general state-
space models. Journal of Computational and Graphical Statistics, 7(2), 175–193.
Ito, K. and Xiong, K. 2000. Gaussian ﬁlters for nonlinear ﬁltering problems. IEEE
Transactions on Automatic Control, 45(5), 910–927.
Jazwinski, A. H. 1966. Filtering for nonlinear dynamical systems. IEEE Transactions
on Automatic Control, 11(4), 765–766.
Jazwinski, A. H. 1970. Stochastic Processes and Filtering Theory. Academic Press.
Julier, S. J. and Uhlmann, J. K. 1995. A General Method of Approximating Nonlinear
Transformations of Probability Distributions. Tech. rept. Robotics Research Group,
Department of Engineering Science, University of Oxford.
Julier, S. J. and Uhlmann, J. K. 2004. Unscented ﬁltering and nonlinear estimation.
Proceedings of the IEEE, 92(3), 401–422.
Julier, S. J., Uhlmann, J. K., and Durrant-Whyte, H. F. 1995. A new approach for
ﬁltering nonlinear systems. Pages 1628–1632 of: Proceedings of the 1995 American
Control, Conference, Seattle, Washington.
Julier, S. J., Uhlmann, J. K., and Durrant-Whyte, H. F. 2000. A new method for the
nonlinear transformation of means and covariances in ﬁlters and estimators. IEEE
Transactions on Automatic Control, 45(3), 477–482.
Kailath, T., Sayed, A. H., and Hassibi, B. 2000. Linear Estimation. Prentice Hall.
Kaipio, J. and Somersalo, E. 2005. Statistical and Computational Inverse Problems.
Applied Mathematical Sciences, no. 160. Springer.
Kalman, R. E. 1960a. Contributions to the theory of optimal control. Boletin de la
Sociedad Matematica Mexicana, 5(1), 102–119.

References
223
Kalman, R. E. 1960b. A new approach to linear ﬁltering and prediction problems.
Transactions of the ASME, Journal of Basic Engineering, 82(1), 35–45.
Kalman, R. E. and Bucy, R. S. 1961. New results in linear ﬁltering and prediction
theory. Transactions of the ASME, Journal of Basic Engineering, 83(3), 95–108.
Kantas, N., Doucet, A., Singh, S., and Maciejowski, J. 2009. An overview of sequential
Monte Carlo methods for parameter estimation in general state-space models. In:
Proceedings IFAC Symposium on System Identiﬁcation (SYSID).
Kaplan, E. D. 1996. Understanding GPS, Principles and Applications. Artech House.
Keeling, M. and Rohani, P. 2007. Modeling Infectious Diseases in Humans and Ani-
mals. Princeton University Press.
Kelly, C. N. and Anderson, B. D. O. 1971. On the stability of ﬁxed-lag smoothing
algorithms. Journal of Franklin Institute, 291(4), 271–281.
Kim, C.-J. 1994. Dynamic linear models with Markov-switching. Journal of Econo-
metrics, 60, 1–22.
Kitagawa, G. 1987. Non-Gaussian state-space modeling of nonstationary time series.
Journal of the American Statistical Association, 82(400), 1032–1041.
Kitagawa, G. 1994. The two-ﬁlter formula for smoothing and an implementation of the
Gaussian-sum smoother. Annals of the Institute of Statistical Mathematics, 46(4),
605–623.
Kitagawa, G. 1996. Monte Carlo ﬁlter and smoother for Non-Gaussian nonlinear state
space models. Journal of Computational and Graphical Statistics, 5(1), 1–25.
Lee, R. C. K. 1964. Optimal Estimation, Identiﬁcation and Control. MIT Press.
Lefebvre, T., Bruyninckx, H., and Schutter, J. D. 2002. Comment on “A new method
for the nonlinear transformation of means and covariances in ﬁlters and estimators”
[and authors’ reply]. IEEE Transactions on Automatic Control, 47(8), 1406–1409.
Leondes, C. T., Peller, J. B., and Stear, E. B. 1970. Nonlinear smoothing theory. IEEE
Transactions on Systems Science and Cybernetics, 6(1), 63–71.
Lin, F.-H., Wald, L. L., Ahlfors, S. P., H¨am¨al¨ainen, M. S., Kwong, K. K., and Belliveau,
J. W. 2006. Dynamic magnetic resonance inverse imaging of human brain function.
Magnetic Resonance in Medicine, 56(4), 787–802.
Lindsten, F. 2011. Rao–Blackwellised Particle Methods for Inference and Identiﬁca-
tion. Licentiate’s thesis, Link¨oping University.
Liu, J. S. 2001. Monte Carlo Strategies in Scientiﬁc Computing. Springer.
Liu, J. S. and Chen, R. 1995. Blind deconvolution via sequential imputations. Journal
of the American Statistical Association, 90(430), 567–576.
Luenberger, D. G. and Ye, Y. 2008. Linear and Nonlinear Programming. Third edn.
Springer.
Maybeck, P. 1982a. Stochastic Models, Estimation and Control. Vol. 3. Academic
Press.
Maybeck, P. 1982b. Stochastic Models, Estimation and Control. Vol. 2. Academic
Press.
Mbalawata, I. S., S¨arkk¨a, S., and Haario, H. 2013. Parameter estimation in stochas-
tic differential equations with Markov chain Monte Carlo and non-linear Kalman
ﬁltering. Computational Statistics, 28(3), 1195–1223.
Meditch, J. S. 1969. Stochastic Optimal Linear Estimation and Control. McGraw-Hill.
Milton, J. S. and Arnold, J. C. 1995. Introduction to Probability and Statistics, Princi-
ples and Applications for Engineering and the Computing Sciences. McGraw-Hill.

224
References
Moore, J. B. 1973. Discrete-time ﬁxed-lag smoothing algorithms. Automatica, 9(2),
163–174.
Moore, J. B. and Tam, P. 1973. Fixed-lag smoothing of nonlinear systems with discrete
measurement. Information Sciences, 6, 151–160.
Morf, M., L´evy, B., and Kailath, T. 1978. Square-root algorithms for the continuous-
time linear least-square estimation problem. IEEE Transactions on Automatic Con-
trol, 23(5), 907–911.
Murray, J. D. 1993. Mathematical Biology. Springer.
Murray, L. and Storkey, A. 2011. Particle smoothing in continuous time: a fast approach
via density estimation. IEEE Transactions on Signal Processing, 59(3), 1017–1026.
Neal, R. M. 2011. MCMC using Hamiltonian dynamics. Chapter 5 of: Brooks, S.,
Gelman, A., Jones, G. L., and Meng, X.-L. (eds.), Handbook of Markov Chain Monte
Carlo. Chapman & Hall/CRC.
Neal, R. and Hinton, G. 1999. A view of the EM algorithm that justiﬁes incremen-
tal, sparse, and other variants. Pages 355–370 of: Jordan, M. I. (ed.), Learning in
Graphical Models. MIT Press.
Ninness, B. and Henriksen, S. 2010. Bayesian system identiﬁcation via Markov chain
Monte Carlo techniques. Automatica, 46(1), 40–51.
Ninness, B., Wills, A., and Sch¨on, T. B. 2010. Estimation of general nonlinear state-
space systems. Pages 6371–6376 of: Proceedings of the 49th IEEE Conference on
Decision and Control (CDC), Atlanta, USA.
Nørgaard, M., Poulsen, N. K., and Ravn, O. 2000. New developments in state estima-
tion for nonlinear systems. Automatica, 36(11), 1627–1638.
O’Hagan, A. 1991. Bayes-Hermite quadrature. Journal of Statistical Planning and
Inference, 29(3), 245–260.
Øksendal, B. 2003. Stochastic Differential Equations: an Introduction with Applica-
tions. Sixth edn. Springer-Verlag.
Olsson, R., Petersen, K., and Lehn-Schiøler, T. 2007. State-space models: from the EM
algorithm to a gradient approach. Neural Computation, 19(4), 1097–1111.
Pich´e, R., S¨arkk¨a, S., and Hartikainen, J. 2012. Recursive outlier-robust ﬁltering and
smoothing for nonlinear systems using the multivariate Student-t distribution. In:
Proceedings of IEEE International Workshop on Machine Learning for Signal Pro-
cessing (MLSP).
Pitt, M. K. and Shephard, N. 1999. Filtering via simulation: auxiliary particle ﬁlters.
Journal of the American Statistical Association, 94(446), 590–599.
Poyiadjis, G., Doucet, A., and Singh, S. 2011. Particle approximations of the score and
observed information matrix in state space models with application to parameter
estimation. Biometrika, 98(1), 65–80.
Proakis, J. G. 2001. Digital Communications. Fourth edn. McGraw-Hill.
Punskaya, E., Doucet, A., and Fitzgerald, W. J. 2002. On the use and misuse of particle
ﬁltering in digital communications. In: Proceedings of EUSIPCO.
Raiffa, H. and Schlaifer, R. 2000. Applied Statistical Decision Theory. John Wiley &
Sons, Wiley Classics Library.
Rasmussen, C. E. and Williams, C. K. I. 2006. Gaussian Processes for Machine Learn-
ing. MIT Press.
Rauch, H. E. 1963. Solutions to the linear smoothing problem. IEEE Transactions on
Automatic Control, 8(4), 371–372.

References
225
Rauch, H. E., Tung, F., and Striebel, C. T. 1965. Maximum likelihood estimates of
linear dynamic systems. AIAA Journal, 3(8), 1445–1450.
Ristic, B., Arulampalam, S., and Gordon, N. 2004. Beyond the Kalman Filter. Artech
House.
Roberts, G. O. and Rosenthal, J. S. 2001. Optimal scaling for various Metropolis–
Hastings algorithms. Statistical Science, 16(4), 351–367.
Roweis, S. and Ghahramani, Z. 2001. Learning nonlinear dynamical systems using
the expectation–maximization algorithm. Chapter 6, pages 175–220 of: Haykin, S.
(ed.), Kalman Filtering and Neural Networks. Wiley-Interscience.
Sage, A. P. and Melsa, J. L. 1971. Estimation Theory with Applications to Communi-
cations and Control. McGraw-Hill.
Saha, S., Ozkan, E., Gustafsson, F., and Smidl, V. 2010. Marginalized particle ﬁlters for
Bayesian estimation of Gaussian noise parameters. Pages 1–8 of: 13th Conference
on Information Fusion (FUSION).
Sandblom, F. and Svensson, L. 2012. Moment estimation using a marginalized trans-
form. IEEE Transactions on Signal Processing, 60(12), 6138–6150.
S¨arkk¨a, S. 2006. Recursive Bayesian Inference on Stochastic Differential Equations.
Doctoral dissertation, Helsinki University of Technology.
S¨arkk¨a, S. 2007. On unscented Kalman ﬁltering for state estimation of continuous-time
nonlinear systems. IEEE Transactions on Automatic Control, 52(9), 1631–1641.
S¨arkk¨a, S. 2008. Unscented Rauch-Tung-Striebel smoother. IEEE Transactions on
Automatic Control, 53(3), 845–849.
S¨arkk¨a, S. 2010.
Continuous-time and continuous-discrete-time unscented Rauch-
Tung-Striebel smoothers. Signal Processing, 90(1), 225–235.
S¨arkk¨a, S. 2011. Linear operators and stochastic partial differential equations in Gaus-
sian process regression. In: Proceedings of ICANN.
S¨arkk¨a, S. and Hartikainen, J. 2010a. On Gaussian optimal smoothing of non-linear
state space models. IEEE Transactions on Automatic Control, 55(8), 1938–1941.
S¨arkk¨a, S. and Hartikainen, J. 2010b. Sigma point methods in optimal smoothing of
non-linear stochastic state space models. Pages 184–189 of: Proceedings of IEEE
International Workshop on Machine Learning for Signal Processing (MLSP).
S¨arkk¨a, S. and Hartikainen, J. 2012. Inﬁnite-dimensional Kalman ﬁltering approach to
spatio-temporal Gaussian process regression. In: Proceedings of AISTATS 2012.
S¨arkk¨a, S. and Nummenmaa, A. 2009. Recursive noise adaptive Kalman ﬁltering by
variational Bayesian approximations.
IEEE Transactions on Automatic Control,
54(3), 596–600.
S¨arkk¨a, S. and Sarmavuori, J. 2013. Gaussian ﬁltering and smoothing for continuous-
discrete dynamic systems. Signal Processing, 93(2), 500–510.
S¨arkk¨a, S. and Solin, A. 2012. On continuous-discrete cubature Kalman ﬁltering. Pages
1210–1215 of: Proceedings of SYSID 2012.
S¨arkk¨a, S. and Sottinen, T. 2008. Application of Girsanov theorem to particle ﬁltering
of discretely observed continuous-time non-linear systems. Bayesian Analysis, 3(3),
555–584.
S¨arkk¨a, S., Vehtari, A., and Lampinen, J. 2007a. CATS benchmark time series pre-
diction by Kalman smoother with cross-validated noise density. Neurocomputing,
70(13–15), 2331–2341.

226
References
S¨arkk¨a, S., Vehtari, A., and Lampinen, J. 2007b. Rao-Blackwellized particle ﬁlter for
multiple target tracking. Information Fusion Journal, 8(1), 2–15.
S¨arkk¨a, S., Bunch, P., and Godsill, S. J. 2012a. A backward-simulation based Rao-
Blackwellized particle smoother for conditionally linear Gaussian models. Pages
506–511 of: Proceedings of SYSID 2012.
S¨arkk¨a, S., Solin, A., Nummenmaa, A., Vehtari, A., Auranen, T., Vanni, S., and Lin,
F.-H. 2012b. Dynamic retrospective ﬁltering of physiological noise in BOLD fMRI:
DRIFTER. NeuroImage, 60(2), 1517–1527.
Sarmavuori, J. and S¨arkk¨a, S. 2012a. Fourier-Hermite Kalman ﬁlter. IEEE Transactions
on Automatic Control, 57(6), 1511–1515.
Sarmavuori, J. and S¨arkk¨a, S. 2012b. Fourier-Hermite Rauch-Tung-Striebel Smoother.
In: Proceedings of EUSIPCO.
Sch¨on, T. and Gustafsson, F. 2003. Particle ﬁlters for system identiﬁcation of state-
space models linear in either parameters or states. Pages 1287–1292 of: Proceedings
of the 13th IFAC Symposium on System Identiﬁcation, Rotterdam, The Netherlands.
Sch¨on, T., Gustafsson, F., and Nordlund, P.-J. 2005. Marginalized particle ﬁlters for
mixed linear/nonlinear state-space models. IEEE Transactions on Signal Processing,
53(7), 2279–2289.
Sch¨on, T., Wills, A., and Ninness, B. 2011. System identiﬁcation of nonlinear state-
space models. Automatica, 47(1), 39–49.
Segal, M. and Weinstein, E. 1989. A new method for evaluating the log-likelihood
gradient, the Hessian, and the Fisher information matrix for linear dynamic systems.
IEEE Transactions on Information Theory, 35(3), 682–687.
Shiryaev, A. N. 1996. Probability. Springer.
Shumway, R. and Stoffer, D. 1982. An approach to time series smoothing and forecast-
ing using the EM algorithm. Journal of Time Series Analysis, 3(4), 253–264.
ˇSimandl, M. and Dun´ık, J. 2006. Design of derivative-free smoothers and predictors.
Pages 991–996 of: Preprints of the 14th IFAC Symposium on System Identiﬁcation.
Singer, H. 2008. Nonlinear continuous time modeling approaches in panel research.
Statistica Neerlandica, 62(1), 29–57.
Singer, H. 2011. Continuous-discrete state-space modeling of panel data with nonlinear
ﬁlter algorithms. AStA Advances in Statistical Analysis, 95(4), 375–413.
Snyder, C., Bengtsson, T., Bickel, P., and Anderson, J. 2008.
Obstacles to high-
dimensional particle ﬁltering. Monthly Weather Review, 136(12), 4629–4640.
Stengel, R. F. 1994. Optimal Control and Estimation. Dover.
Stone, L. D., Barlow, C. A., and Corwin, T. L. 1999. Bayesian Multiple Target Tracking.
Artech House.
Storvik, G. 2002. Particle ﬁlters in state space models with the presence of unknown
static parameters. IEEE Transactions on Signal Processing, 50(2), 281–289.
Stratonovich, R. L. 1968. Conditional Markov Processes and Their Application to the
Theory of Optimal Control. Elsevier.
Striebel, C. T. 1965. Partial differential equations for the conditional distribution of a
Markov process given noisy observations. Journal of Mathematical Analysis and
Applications, 11, 151–159.
Tam, P., Tam, D., and Moore, J. 1973. Fixed-lag demodulation of discrete noisy mea-
surements of FM signals. Automatica, 9(6), 725–729.

References
227
Tarantola, A. 2004. Inverse Problem Theory and Methods for Model Parameter Esti-
mation. SIAM.
Titterton, D. H. and Weston, J. L. 1997. Strapdown Inertial Navigation Technology.
Peter Peregrinus Ltd.
V¨a¨an¨anen, V. 2012. Gaussian Filtering and Smoothing Based Parameter Estimation in
Nonlinear Models for Sequential Data. Master’s Thesis, Aalto University.
Van der Merwe, R. and Wan, E. 2003. Sigma-point Kalman ﬁlters for probabilistic
inference in dynamic state-space models. In: Proceedings of the Workshop on Ad-
vances in Machine Learning.
Van der Merwe, R. and Wan, E. A. 2001. The square-root unscented Kalman ﬁlter for
state and parameter estimation. Pages 3461–3464 of: International Conference on
Acoustics, Speech, and Signal Processing.
Van der Merwe, R., De Freitas, N., Doucet, A., and Wan, E. 2001. The unscented par-
ticle ﬁlter. Pages 584–590 of: Advances in Neural Information Processing Systems
13.
Van Trees, H. L. 1968. Detection, Estimation, and Modulation Theory Part I. John
Wiley & Sons.
Van Trees, H. L. 1971. Detection, Estimation, and Modulation Theory Part II. John
Wiley & Sons.
Vihola, M. 2012. Robust adaptive Metropolis algorithm with coerced acceptance rate.
Statistics and Computing, 22(5), 997–1008.
Viterbi, A. J. 1967. Error bounds for convolutional codes and an asymptotically opti-
mum decoding algorithm. IEEE Transactions on Information Theory, 13(2).
Wan, E. A. and Van der Merwe, R. 2001. The unscented Kalman ﬁlter. Chapter 7 of:
Haykin, S. (ed.), Kalman Filtering and Neural Networks. Wiley.
West, M. and Harrison, J. 1997. Bayesian Forecasting and Dynamic Models. Springer-
Verlag.
Wiener, N. 1950. Extrapolation, Interpolation and Smoothing of Stationary Time Series
with Engineering Applications. John Wiley & Sons.
Wills, A., Sch¨on, T. B., Ljung, L., and Ninness, B. 2013.
Identiﬁcation of
Hammerstein–Wiener models. Automatica, 49(1), 70–81.
Wu, Y., Hu, D., Wu, M., and Hu, X. 2005. Unscented Kalman ﬁltering for additive noise
case: augmented versus nonaugmented. IEEE Signal Processing Letters, 12(5), 357–
360.
Wu, Y., Hu, D., Wu, M., and Hu, X. 2006. A numerical-integration perspective on
Gaussian ﬁlters. IEEE Transactions on Signal Processing, 54(8), 2910–2921.
Ypma, A. and Heskes, T. 2005. Novel approximations for inference in nonlinear dy-
namical systems using expectation propagation. Neurocomputing, 69(1), 85–99.
Zoeter, O. and Heskes, T. 2011. Expectation propagation and generalized EP methods
for inference in switching linear dynamical systems. Chapter 7, pages 141–165 of:
Bayesian Time Series Models. Cambridge University Press.


Index
adaptive Markov chain Monte Carlo, 180
adaptive Metropolis, 180
adaptive resampling, 123
applications
audio signal processing, 6
biological processes, 6
brain imaging, 5
Gaussian process regression, 5
global positioning system, 2
GPS/INS, 4
inertial navigation, 3
integrated inertial navigation, 4
inverse problems, 7
learning systems, 6
multiple target tracking, 3
physical systems, 7
spread of infectious diseases, 6
stochastic optimal control, 6
target tracking, 2
telecommunications, 6
backward-simulation particle smoother,
167
batch solution
general Bayesian, 31
to linear regression, 28
Bayes’ rule, 19
Bayesian estimation of parameters, 174
Bayesian ﬁlter, 54
Bayesian ﬁltering
applications, 2
as Bayesian inference, 8
equations, 54
origins, 7
Bayesian inference
building blocks, 19
connection with ML, 17
philosophy, 17
Bayesian optimal ﬁltering, see Bayesian
ﬁltering
Bayesian optimal smoothing, see
Bayesian smoothing
Bayesian smoother, 134
Bayesian smoothing
applications, 2
as Bayesian inference, 8
equations, 134
origins, 7
two-ﬁlter, 139
bootstrap ﬁlter, 126
Chapman–Kolmogorov equation, 54
Cholesky factorization
algorithm, 210
time derivative, 210
cubature integration, see spherical
cubature integration
cubature Kalman ﬁlter
additive, 111
for pendulum tracking, 114
non-additive, 112
cubature RTS smoother
additive, 157
non-additive, 158
degeneracy problem, 123
dynamic linear models, 8
dynamic model
deﬁnition, 10
of probabilistic state space model, 51
energy function, 177
derivative for linear Gaussian model,
212, 213
derivative for non-linear Gaussian
model, 215
linear Gaussian model, 187
229

230
Index
non-linear Gaussian model, 192
particle ﬁlter approximation, 195
recursion, 177
SIR based approximation, 195
expectation-maximization
algorithm, 183
as coordinate ascend, 182
backward-simulation smoother based
evaluation of Q, 198
evaluation of linear Gaussian Q, 189
evaluation of non-linear Gaussian Q,
194
for linear Gaussian models, 191
maximization of linear Gaussian Q,
191
reweighting smoother based
evaluation of Q, 198
extended Kalman ﬁlter
ﬁrst order additive, 69
ﬁrst order non-additive, 71
for pendulum tracking, 74
second order additive, 73
extended RTS smoother
additive, 144
ﬁltering distribution
deﬁnition, 54
ﬁltering model, see state space model
Fisher’s identity, 178, 185
for linear Gaussian model, 213
ﬁxed-lag smoother, 164
ﬁxed-point smoother, 162
Fourier–Hermite Kalman ﬁlter, 81
Fourier–Hermite Rauch–Tung–Striebel
smoother, 147
Gauss–Hermite cubature, 102
Gauss–Hermite Kalman ﬁlter
additive, 104
for pendulum tracking, 105
Gauss–Hermite quadrature, 22, 101
Gauss–Hermite RTS smoother
additive, 155
Gaussian approximation
deﬁnition, 22
in extended Kalman ﬁlter, 69
Gaussian assumed density ﬁlter, see
Gaussian ﬁlter
Gaussian distribution, 209
Gaussian ﬁlter
additive, 98
non-additive, 98
Gaussian ﬁxed-lag smoother, 164
Gaussian ﬁxed-point smoother, 162
Gaussian moment matching, 96, 97
Gaussian process regression, 6
Gaussian random walk, 52
for linear regression, 33
Gaussian RTS smoother
additive, 154
non-additive, 155
Hermite polynomial, 100
Hessian matrix, 65
importance sampling, 23, 119
information ﬁlter, 141
Jacobian matrix, 65
Kalman ﬁlter
basic, 56
cubature, 111, 112
extended, 69, 71, 73
for car tracking, 59
for Gaussian random walk, 58
for linear regression, 30
for linear regression with drift, 35
Gauss–Hermite, 104
Gaussian, 98
statistically linearized, 78
unscented, 87, 88
Kalman smoother, see RTS smoother
Laplace approximation, 178
least squares estimate, 24
linear approximation, 67, 68
linear quadratic Gaussian regulator, 8
linear regression, 27
linearization, see linear approximation
local linearization, 125
loss function
0–1, 21
absolute error, 21
deﬁnition, 21
quadratic error, 21
MAP-estimate, 22, 178
marginal likelihood of parameters, 176
marginalized transform, 92
Markov chain Monte Carlo, 23, 179
matrix inversion lemma, 30
measurement model

Index
231
deﬁnition, 19
joint distribution of measurements, 53
of probabilistic state space model, 51
Metropolis–Hastings, 179
ML-estimate, 18, 178
MMSE-estimate, 21
Monte Carlo method, 23, 116
non-linear transform
additive Gaussian moment matching,
96
additive linear approximation, 67
additive quadratic approximation, 68
additive statistically linearized
approximation, 76, 77
additive unscented transform
approximation, 84
non-additive Gaussian moment
matching, 97
non-additive linear approximation, 68
non-additive statistically linearized
approximation, 76
non-additive unscented transform
approximation, 85
on-line learning, 33
optimal ﬁltering, see Bayesian ﬁltering
optimal importance distribution, 125
optimal smoothing, see Bayesian
smoothing
parameter estimation
deﬁnition, 174
Gaussian random walk, 188
linear Gaussian models, 187
pendulum model, 196
via Gaussian ﬁltering and smoothing,
192
via particle ﬁltering and smoothing,
195
via Rao–Blackwellization, 199
via state augmentation, 185
particle ﬁlter
algorithm, 124
for cluttered pendulum tracking, 128
for pendulum tracking, 127
Rao–Blackwellized, 130
particle marginal Metropolis–Hastings,
196
particle Markov chain Monte Carlo, 196
particle smoother
backward-simulation, 167
Kim’s approximation, 172
marginal, 169
Rao–Blackwellized, 171
reweighting, 169
SIR, 165
posterior distribution
batch linear regression model, 29
deﬁnition, 19
joint distribution of states, 53
recursive linear regression model, 30
posterior mean, 21
prior distribution
deﬁnition, 19
joint distribution of states, 53
probabilistic notation, 27
quadratic approximation, 68
quadrature Kalman ﬁlter, see
Gauss–Hermite Kalman ﬁlter
Rao–Blackwellization of parameters, 199
Rao–Blackwellized particle ﬁlter, 130
Rao–Blackwellized particle smoother,
171
Rauch–Tung–Striebel smoother, see RTS
Smoother
recursive solution
general Bayesian, 32
to linear regression, 29
resampling, 123
reweighting particle smoother, 169
robust adaptive Metropolis, 180
RTS smoother
basic, 136
cubature, 157, 158
extended, 144
for car tracking, 138
for Gaussian random walk, 137
Gauss–Hermite, 155
Gaussian, 154, 155
statistically linearized, 147
unscented, 148, 150
sample impoverishment, 126
second order approximation, see
quadratic approximation
sensitivity equations, 178, 189
linear Gaussian model, 212
non-linear Gaussian model, 215
sequential importance resampling, 124

232
Index
sequential importance sampling, 122
SIR particle smoother, 165
spherical cubature integration
algorithm, 108
as unscented transform, 110
state augmentation, 185
state space model
autoregressive (AR) model, 41
car tracking, 42
conditional independence, 52
Gaussian random walk, 52
generalized linear model, 41
linear Gaussian, 56
linear-in-parameters regression model,
39, 40
Markov property, 52
non-linear additive Gaussian, 69
non-linear non-additive Gaussian, 71
notation, 35
pendulum tracking, 44
probabilistic, 51
time-varying autoregressive (TVAR)
model, 42
statistical decision theory, 20
statistical inversion, 5, 9
statistical linear regression, 92
statistical linearization, see statistically
linearized approximation
statistically linearized approximation, 76,
77
statistically linearized ﬁlter
additive, 78
for pendulum tracking, 79
non-additive, 78
statistically linearized RTS smoother
additive, 147
stratiﬁed resampling, 123
Taylor series, 65
time-invariant model, 36
two-ﬁlter smoothing, 139
unscented Kalman ﬁlter
additive, 87
for pendulum tracking, 91
non-additive, 88
unscented RTS smoother
additive, 148
non-additive, 150
unscented transform, 81
additive, 84
as cubature integration, 110
non-additive, 85
utility function, 21
Wiener ﬁlter, 7

