Florida State University Libraries
Electronic Theses, Treatises and Dissertations 
 The Graduate School
2005
Modeling Highway Crashes Using Bayesian
Belief Networks Technique and GIS
Thobias Sando
Follow this and additional works at the FSU Digital Library. For more information, please contact lib-ir@fsu.edu

THE FLORIDA STATE UNIVERSITY 
COLLEGE OF ENGINEERING 
 
 
MODELING HIGHWAY CRASHES USING BAYESIAN BELIEF NETWORKS 
TECHNIQUE AND GIS 
 
 
By 
THOBIAS SANDO 
 
A Dissertation submitted to the 
Department Civil & Environmental Engineering 
In Partial Fulfillment of the 
Requirement for the Degree of 
Doctor of Philosophy 
                                                      
 
                                                         Degree Awarded:
                                      Fall Semester, 2005 
 
 
 
 
 
 
 
 
 

 
ii
The Members of the Committee Approve the Dissertation of Thobias Sando, defended on 
11/01/2005. 
 
 
Renatus Mussa 
Professor Directing Dissertation 
 
Xiuwen Liu 
Outside Committee Member 
 
Lisa Spainhour 
Committee Member 
 
John Sobanjo 
Committee Member 
 
Yassir AbdelRazig 
Committee Member 
 
Approved: 
 
 
Kamal Tawfiq, Chair, Department of Civil Engineering 
 
 
Ching-Jen Chen, Dean, College of Engineering 
 
 
The Office of Graduate Studies Has Verified and Approved the Above Named 
Committee Members. 

 
iii
 
 
TABLE OF CONTENTS 
 
LIST OF TABLES..........................................................................................................VI 
LIST OF FIGURES...................................................................................................... VII 
ABSTRACT..................................................................................................................VIII 
CHAPTER 1...................................................................................................................... 1 
INTRODUCTION .......................................................................................................... 1 
Overview..................................................................................................................... 1 
Statement of the Problem............................................................................................ 2 
CHAPTER 2...................................................................................................................... 3 
LITERATURE REVIEW ............................................................................................... 3 
Definition of Crash Modeling..................................................................................... 3 
GIS in transportation engineering............................................................................... 3 
Several Case Studies of GIS being used for Crash Analysis...................................... 4 
Types of Analyses Performed by GIS ........................................................................ 6 
Intersection/Spot Analysis ...................................................................................... 6 
Segment/Strip Analysis........................................................................................... 7 
Sliding- Scale Analysis........................................................................................... 7 
Corridor Analysis.................................................................................................... 8 
Collision Density Analysis ..................................................................................... 8 
Area Analysis.......................................................................................................... 9 
Pattern Analysis ...................................................................................................... 9 
Display/Query Analysis........................................................................................ 10 
Spatial Analysis .................................................................................................... 11 
Proximity analysis................................................................................................. 11 
Cluster Analysis.................................................................................................... 12 
Crash Modeling Techniques ..................................................................................... 13 
Regression Models................................................................................................ 13 
Poisson Regression Model.................................................................................... 13 
Negative Binomial Regression Model.................................................................. 14 
Zero-Inflated Poisson Negative Binomial Regression Models............................. 14 
The Use of Regression Analysis in Crash Modeling................................................ 16 
Artificial Neural Networks ....................................................................................... 16 
Supervized learning .............................................................................................. 17 
Learning Laws ...................................................................................................... 18 
Hebb's Rule........................................................................................................... 18 
Hopfield Law ........................................................................................................ 19 
The Delta Rule...................................................................................................... 19 

 
iv
The Gradient Descent Rule................................................................................... 19 
Kohonen's Learning Law...................................................................................... 20 
Artificial networks for prediction ............................................................................. 21 
Feedforward, Back-Propagation Architecture ...................................................... 21 
Delta Bar Delta ..................................................................................................... 22 
Networks for classification – Probabilistic Neural Network.................................... 23 
Examples of uses of artificial neural networks in crash analysis.............................. 26 
Bayesian Technique.................................................................................................. 29 
Nearest Neighbor rule............................................................................................... 30 
Decision tree ............................................................................................................. 31 
Bayesian Belief Network Technique ........................................................................ 33 
Background of Bayesian Belief Networks................................................................ 34 
Overview............................................................................................................... 34 
Use of Bayesian Networks in Crash Modeling..................................................... 34 
Causal Structure.................................................................................................... 37 
Types of Bayesian Belief Networks ..................................................................... 40 
Naïve Bayes’ Belief Networks.............................................................................. 40 
Conditional Probability Bayesian Belief Networks.............................................. 41 
Representation....................................................................................................... 43 
Advantages of Bayesian Networks Over Other Representations ......................... 43 
Data Categorization/Transformation ........................................................................ 44 
Equal Interval........................................................................................................ 44 
Quantiles ............................................................................................................... 45 
Natural breaks....................................................................................................... 45 
Standard deviation ................................................................................................ 45 
CHAPTER 3.................................................................................................................... 47 
METHODOLOGY ....................................................................................................... 47 
Overview................................................................................................................... 47 
Data Collection ......................................................................................................... 47 
CAR Database....................................................................................................... 48 
RCI Database ........................................................................................................ 48 
GIS Database ........................................................................................................ 51 
High Crash Segments Database............................................................................ 51 
Attributes Selection................................................................................................... 52 
Model Selection ........................................................................................................ 53 
Construction of the Bayesian Model......................................................................... 54 
Variables used in the Model ..................................................................................... 56 
Maximum Posted Speed ....................................................................................... 56 
Pavement Condition.............................................................................................. 57 
Annual Average Daily Traffic (AADT) ............................................................... 58 
Data Reduction.......................................................................................................... 59 
Dynamic Segmentation............................................................................................. 60 
Data Categorization/Transformation ........................................................................ 60 
Data Analysis............................................................................................................ 61 
Computation Method ............................................................................................ 61 
Model Validation ...................................................................................................... 63 

 
v
CHAPTER 4.................................................................................................................... 64 
ANALYSIS OF RESULTS........................................................................................... 64 
Overview................................................................................................................... 64 
Maximum Posted Speed ....................................................................................... 71 
Section Length ...................................................................................................... 72 
Section AADT ...................................................................................................... 72 
Pavement Condition.............................................................................................. 73 
Locality ................................................................................................................. 73 
Number of Lanes................................................................................................... 74 
Number of Crashes ............................................................................................... 74 
Conditional Probabilities .......................................................................................... 75 
Node D: Pavement Condition and AADT ............................................................ 75 
Node E: Number of Lanes and AADT ................................................................. 76 
Node C:  AADT and Locality............................................................................... 77 
Node G: Number of Crashes and Maximum Speed Limit, Length, Locality, 
Number of Lanes, Pavement Condition................................................................ 78 
Prediction Accuracy.............................................................................................. 78 
Modeling of Crashes that Occurred in Six Lane Highways ..................................... 79 
Predictions................................................................................................................. 80 
Sensitivity Analysis .................................................................................................. 82 
CHAPTER 5.................................................................................................................... 89 
CONCLUSIONS AND RECOMMENDATIONS........................................................ 89 
Conclusions............................................................................................................... 89 
Overview............................................................................................................... 89 
Model Accuracy.................................................................................................... 89 
Data Incompleteness and Inaccuracy.................................................................... 90 
Loss of Information during Discretization............................................................ 91 
Strengths and weaknesses of Bayesian Belief Network method .......................... 91 
Integration of Bayesian Networks with GIS......................................................... 92 
Recommendations..................................................................................................... 92 
Variable Discretization ......................................................................................... 92 
Model Construction .............................................................................................. 93 
Recommendation for Use ..................................................................................... 93 
APPENDIX A.................................................................................................................. 95 
APPENDIX B................................................................................................................ 104 
APPENDIX C................................................................................................................ 108 
APPENDIX D................................................................................................................ 111 
APPENDIX E................................................................................................................ 120 
APPENDIX F ................................................................................................................ 168 
REFERENCES.............................................................................................................. 175 
BIOGRAPHICAL SKETCH....................................................................................... 178 

 
vi
 
 
LIST OF TABLES 
 
Table 1  Network Selector Table ...................................................................................... 22 
Table 2  Training and Testing Results for Neural Network (Chong et al., 2004) ............ 33 
Table 3  Pavement Condition Ratings .............................................................................. 58 
Table 4  Attribute Categorization ..................................................................................... 64 
Table 5  Maximum Posted Speed Categories ................................................................... 72 
Table 6  Section Length Categories.................................................................................. 72 
Table 7  Annual Average Daily Traffic Categories.......................................................... 73 
Table 8  Pavement Condition Categories.......................................................................... 73 
Table 9  Locality Categories............................................................................................. 74 
Table 10  Number of Lanes Categories ............................................................................ 74 
Table 11  Number of Crashes Categories ......................................................................... 75 
Table 12  Conditional Probability Table for Pavement Condition (D) given AADT (C) 76 
Table 13  Conditional Probability Table for Number of Lanes (F) given AADT (C)...... 77 
Table 14  Conditional Probability Table for AADT (C) given Locality (E) .................... 77 
Table 15  Probabilities of Independent Variables............................................................. 79 
Table 16  Conditional Probabilities for Nodes E and C.................................................... 79 
Table 17  Conditional Probability Table for Pavement Condition given AADT ............. 80 
Table 18  A Sample Record for Illustrating Prediction Procedure................................... 81 
Table 19  Maximum Posted Speed Limit Thresholds....................................................... 83 
Table 20  Average Annual Daily Traffic 9AADT) Thresholds........................................ 84 
Table 21  Average Annual Daily Traffic (AADT) Thresholds......................................... 85 
Table 22  Segment Length Thresholds ............................................................................. 86 
Table 23  Prediction Accuracies Observed by Changing the Number of Categories for 
AADT, Maximum Posted Speed, Pavement Condition, and Segment Length ........ 88 
Table 24  Strengths and Weaknesses of Bayesian Belief Networks................................. 92 
 

 
vii
LIST OF FIGURES 
 
Figure 1  An Example of Intersection Analysis using the radius buffer (FHWA, 2001). .. 7 
Figure 2  An Example of the Collision Density Analysis (Boose, 2001)........................... 8 
Figure 3  An Example of Area Analysis -High Accident Areas in Oahu, Hawaii (Kim, 
1996). .......................................................................................................................... 9 
Figure 4  An Example of Proximity Analysis: Traffic Congestion near gas stations may 
contribute to high collision rates (Brose, 2001)........................................................ 12 
Figure 5  An Example of the use of Cluster Analysis to show crash distributions along the 
beach in Hawaii (Kim, 1996).................................................................................... 12 
Figure 6  A Typical Artificial Neural Network Structure................................................. 17 
Figure 7  An Example Feedforward Back-propagation Network (Anderson and McNeil, 
1992). ........................................................................................................................ 23 
Figure 8  A Probabilistic Neural Network Example......................................................... 25 
Figure 9  Typical Artificial Neural Network Structure (Vogt and Bared, 1998).............. 27 
Figure 10  ANN model based on back-propagation algorithm (Musone et al., 1999). .... 28 
Figure 11  ANN models with two hidden layers (Kalyoncuoglu & Tigdemir, 2004)...... 29 
Figure 12  Decision Tree Structure................................................................................... 32 
Figure 13  Bayesian Network Structure (Simoncic, 2005)............................................... 35 
Figure 14  Bayesian Network Structure (Simoncic, 2005)............................................... 36 
Figure 15  Directed Acyclic Graph Representation of Three-Vehicle Platoon Collision 
Model (Davis and Swenson 2005)............................................................................ 38 
Figure 16  Two Simple Belief Networks (Duda et al., 2000)........................................... 39 
Figure 17   A Map showing crash Occurrence on State Maintained Roadways for year 
2002........................................................................................................................... 50 
Figure 18  Modeling Process. ........................................................................................... 54 
Figure 19  The Resulting Model Using PowerConstructor. ............................................. 55 
Figure 20  Proposed Bayesian Belief Network for Crash Prediction. .............................. 56 
Figure 21  An Example of Dynamic Segmentation Data (Cadkin, 2002). ....................... 61 
Figure 22  Map Showing Speed Categories...................................................................... 65 
Figure 23  Map Showing Roadway Length Categories.................................................... 66 
Figure 24  Map Showing Pavement Condition Categories............................................... 67 
Figure 25  Map Showing AADT Categories. ................................................................... 68 
Figure 26  Map Showing Categorized Locality................................................................ 69 
Figure 27  Map Showing Lane Categories. ...................................................................... 70 
Figure 28  Map Showing Crash Categories...................................................................... 71 
Figure 29  Bayesian Belief Network for Statewide Analysis. .......................................... 76 
Figure 30  Probability Tables for Each Node in the Model.............................................. 81 
Figure 31  Prediction Accuracy Versus Number of Categories for Maximum Posted 
Speed......................................................................................................................... 84 
Figure 32  Prediction Accuracy Versus Number of Categories for AADT...................... 85 
Figure 33  Prediction Accuracy Versus Number of Categories for Pavement Condition.86 
Figure 34  Prediction Accuracy Versus Number of Categories for Segment Length....... 87 
Figure 35  Prediction Accuracy Versus Number of Categories for Segment Length....... 88 
Figure 36  A Proposed Comprehensive Bayesian Belief Network Model ....................... 94 

 
viii
 
 
ABSTRACT 
 
Modeling traffic crashes is a complex undertaking. Previous research studies have used a 
variety of techniques to analyze crashes.  Conventionally, traffic crashes have been 
modeled using regression models.  Recently, intelligent systems have been applied in 
highway safety modeling.  Such methods include artificial neural networks, decision trees, 
nearest-neighbor rule, Bayesian methods, and clustering algorithms.  One method that has 
not been well used in analyzing highway safety data is Bayesian Belief Network 
technique.  This research investigated the use of Bayesian Belief Networks technique in 
highway safety modeling. 
 
A prediction model using Bayesian Belief Networks technique is proposed as part of the 
efforts to enhance traffic safety data analysis.  The technique takes advantage of the 
knowledge of causal relationships or statistical dependencies (or independencies) among 
the model variables.  A simple hypothetical Belief Network that comprised of six 
variables i.e., annual average daily traffic (AADT), section length, number of lanes, 
surface width, maximum posted speed limit, and number of crashes per year for each 
road segment was constructed.  The model allows for the prediction of number of crashes 
per year at a roadway segment given a set of values of each of the model variables.   
 
Geographical Information Systems (GIS) was incorporated in the model for displaying 
model results.  A stand alone GIS application was developed using MapObjects software 
package.  Programming was done in Visual Basic environment.  The final output of the 
model was the map of the roadway network showing predictions of crash category for 
each roadway section.     
 
Two different datasets were used in modeling – state roadways with a maximum number 
of lanes of 6 (subset 1) and exclusively six lane highways classified as high crash 
locations (subset 2).  The performance of the proposed model was evaluated using the 

 
ix
prediction accuracy.  The prediction accuracy is hereby defined as the percentage of the 
roadway sections whose crash occurrence was correctly predicted.  The results obtained 
in this study yielded the prediction accuracy of 68.08% and 78%, for subset 1 and 2, 
respectively.   

 
1
 
 
CHAPTER 1 
 
INTRODUCTION 
 
Overview 
 
The safety of highway travel is of paramount concern to authorities responsible for 
managing highway systems.  The determination of the locations that are more prone to 
crashes, time periods when most crashes occur, and more importantly the causes of crash 
occurrences, would be pivotal in devising solutions for mitigating highway crashes.  
Geographic Information Systems (GIS) provides utilities for designing queries and macro 
programs that query information from crash database, perform spatial analysis and 
display the results in a thematic map.  The review of previous studies indicated that 
researchers have developed GIS tools for identifying hazardous locations using spatial 
analysis of highway crashes [Kim and Levine (1996), and Sun (2003)].  These research 
studies developed tools that did not incorporate crash prediction models.  The objective 
of this research was to develop tools that would link the gap between the use of GIS for 
analyzing and displaying crashes with the use of GIS for predicting crash occurrences 
based on various environmental, road, and traffic conditions.   
 
Crash prediction models can have an expert system that uses statistical techniques to 
predict crash occurrences based on historical data.  Expert systems categories include 
artificial neural networks, artificial intelligence, and pattern recognition techniques.  This 
study employed pattern recognition techniques in creating GIS modules that could be 
used for crash prediction purposes.  The inputs of the model were extracted from 
different sets of databases including the Florida Department of Transportation (FDOT) 
Crash Analysis Reports (CARS), FDOT GIS database, and FDOT Roadway 
Characteristics Inventory (RCI) database.  The development of pattern recognition 

 
2
prediction model that is linked to GIS is a significant new contribution in the field of 
highway safety. 
 
Statement of the Problem 
 
The safety of highway travel is of paramount concern to the authorities responsible for 
managing the highway system.  GIS has been identified as a potential tool for analyzing 
crashes and identifying problem areas for consideration in future safety improvements.  
One of the important aspects in safety improvement programs is the ability to predict 
crash occurrences in geographical locations.    Previous researchers have developed GIS 
tools for analyzing and identifying hazardous locations.  GIS tools for predicting crash 
occurrences have not been developed.  This is due to the fact that researchers have not 
linked prediction techniques with GIS. GIS has so far been used for mapping crashes, 
visual determination of crash occurrence patterns, and identification of high crash spots.  
This study integrated pattern recognition techniques into GIS to enhance capabilities of 
GIS in crash modeling.  The results will help highway officials in prediction of highway 
safety pattern as different roadway conditions change.   

 
3
 
 
CHAPTER 2 
 
LITERATURE REVIEW 
 
Definition of Crash Modeling 
 
The word modeling comes from a root word ‘model’.  A model is a simplified 
representation of how something happens or works in the real world. It is a mathematical 
expression of the logical representation of the system, entity, or phenomenon, a process.  
A model uses variables and assumptions about how they are determined and interact to 
simplify the reality.  It must be able to make testable predictions of what will happen 
under new circumstances.   Modeling refers to the process of generating a model as a 
conceptual representation of some phenomenon as discussed above.  In safety analysis, 
modeling is used as an analytical tool to assist in making predictions of accident 
occurrences. 
 
The output of the model depends on the question at hand.  Common model outputs in 
crash modeling include type of the crash – fatal, injury, and property damage only, 
number of crashes, crash rate, and segment/intersection severity rating and so forth.  
Model inputs may include different environmental, traffic, and roadway variables.  This 
study involves modeling crash data using pattern recognition techniques and 
Geographical Information Systems (GIS).  
 
GIS in transportation engineering 
 
The use of GIS in transportation covers much of the broad scope of transportation, such 
as infrastructure planning, design and management, transportation safety analysis, travel 

 
4
demand analysis, traffic monitoring and control, public transit planning and operations, 
environmental impacts assessment, hazards mitigation, and intelligent transportation 
systems (ITS). Each of these applications tends to have its specific data and analysis 
requirements. For example, representing a street network as centerlines and major 
intersections may be sufficient for a transportation planning application. A traffic 
engineering application, however, may require a detailed representation of individual 
traffic lanes. Turn movements at intersections also could be critical to a traffic 
engineering study, but not to a region-wide travel demand study.  
 
Transportation applications have benefited from many of the standard GIS functions 
(query, geocoding, buffer, overlay, etc.) to support data management, analysis, and 
visualization needs. Like many other fields, transportation has developed its own unique 
analysis methods and models. Examples include shortest path and routing algorithms 
(e.g., traveling salesman problem, vehicle routing problem), spatial interaction models 
(e.g., gravity model), network flow problems (e.g., user optimal equilibrium, system 
optimal equilibrium, dynamic equilibrium), facility location problems (e.g., p-median 
problem, set covering problem, maximal covering problem, p-centers problem), travel 
demand models (e.g., the 4-step trip generation, trip distribution, modal split, and traffic 
assignment models), and land use-transportation interaction models. 
 
Several Case Studies of GIS being used for Crash Analysis 
 
Different agencies have reported using GIS for analysis of crashes.  In Wisconsin GIS is 
used for analyzing spatial distributions and densities of traffic collisions (Brose, 2001).  
Sun (2003) developed the crash analysis tool for Louisiana using GIS.  According to Sun, 
with the previous system, it was hard to identify a highway location that has: high 
frequency of a particular type of accident, for example high run-off or head-on crash 
accident rate on the two-lane highways (effect of edge line or roadway lighting), high 
right-angle collision rate caused by improper signal timing (misleading green ball for left 
turn, yellow trap, running red light) and high accident rate during a particular time period.  

 
5
Sun (2003) therefore developed the GIS tools that have the capability to evaluate crashes 
with the emphasis on: 
• Trends over time 
• Trends over space 
• Stratify by highway type and geometric design 
• Stratify by type of crash 
• Stratify by environmental conditions 
 
Prediction of crash occurrences is of interest to highway officials.  Numerous attempts 
have been made by previous research studies to identify hazardous locations based on 
scattering of crashes over geographical locations.    Zegeer (1982) defined hazardous 
highway locations as highway spots, intersections or sections with an abnormally high 
crash experience in terms of frequency, severity or rate.   The first study that used expert 
system to identify hazardous highway locations was reported by Spring and Hummer 
(1995).  The study used the capabilities of GIS, along with the detailed mapping available 
for Guilford County, North Carolina to demonstrate the use of engineering knowledge 
regarding accident causation to identify hazardous highway locations.  The study 
provided valuable information regarding both the limitations and advantages of using and 
applying GIS to crash record system.  Another application of GIS in highway safety was 
reported by Utainaromoi (1994) in the dissertation entitled “GIS Applications for 
Identifying Hazardous Locations and Evaluating Various Hazardous Location 
Algorithms”.  The study used three years of crash data from 1993 to 1995 contained in 
the Tennessee Roadway Information Management System (TRIMS) database.  
Utainaromoi developed algorithms which were integrated in GIS to evaluate five 
methods for identifying hazardous highway locations – accident frequency method, 
accident rate method, rate quality control method, accident severity methods and 
combination methods.  The study did not apply any prediction techniques other than 
conventional methods used for ranking highway locations based on crash occurrence.   
 
Geographic Information Systems (GIS) softwares provide a platform that could be used 
to display different types of information including crashes on the map.  In order to 

 
6
perform different analyses, modules are developed to work in the background.  For 
example GIS could be used for navigational purpose to determine the best route given 
certain conditions.  This is due to algorithms that are embedded in GIS to optimize an 
objective function such as time, cost, or distance.     Likewise, an appropriate technique is 
needed to be embedded in GIS to enable crash prediction in GIS.  The following sections 
discuss different techniques that have been used for crash prediction. 
 
Types of Analyses Performed by GIS 
 
GIS has the ability to perform numerous types of analyses some of which are useful in 
crash analyses.  Previous studies have reported on different GIS analyses for crash 
analyses purposes (FHWA (2001), Kim (1996), FHWA, (1999) and Falbo et. al (1991).  
The types of analyses that are applicable for crash analyses include intersection/spot 
analysis, segment analysis, cluster analysis, sliding-cale snalysis, corridor analysis, 
collision density analysis, area analysis, zonal analysis, pattern analysis, proximity 
analysis, and simple query analysis.  The following sections describe each of the 
mentioned analyses in more details. 
 
Intersection/Spot Analysis 
A safety engineer would be interested to know the intersections with the highest crash 
rates in a certain area such as the city or the county.  An intersection/spot analysis can be 
used for this purpose.  GIS presents intersections as points on a map.  In order to 
associate the crashes occurring at the intersections, crashes within a certain distance from 
the intersection, usually 100 feet are considered to be intersection crashes.  A buffer of 
100 feet radius would be created to associate all crashes occurring within a radius of 100 
feet from an intersection to the respective intersection.  The total number of crashes in 
each intersection would be summed and ranked to obtain the highest rated crash 
intersections.  The same analysis can be accomplished by using the GIS symbology tools 
by associating symbols and colors to the intersections within each range of crash rates, 
the process known as classification. The intersection/spot analysis is also termed as point 

 
7
analysis.  The intersection/spot analysis is reported by FHWA(2001), FHWA(1999) and 
Kim (1996) to mention a few.  Figure 1 shows an example of intersection/spot analysis. 
 
Figure 1  An Example of Intersection Analysis using the radius buffer (FHWA, 
2001). 
 
Segment/Strip Analysis 
While the intersection/spot analysis deals with a point, strip analysis considers crashes 
occurring along the roadway segment.  The strip analysis can be conducted to determine 
the road segments with severe crash rates.  The strip analysis can vary from the analysis 
of the whole street segment to a designated segment length such as 1 mile, 0.5 mile and 
so forth.  GIS is capable of computing and mapping crashes occurring in each selected 
segment length and provide specific symbols and colors to crashes in different segments.   
 
Sliding- Scale Analysis 
The sliding-scale analysis is reported by FHWA (2001).  The sliding- scale analysis is a 
modified GIS method used to identify roadway segments with a high crash occurrence, 
by varying the segment length. This analysis differs from the strip analysis program in 
that the analysis segment is not fixed, but rather slides along the route in an incremental 
fashion. The user defines the segment length and the increment length for analysis. The 
end result of the analysis includes a table showing the high crash locations that exceeded 

 
8
a calculated or user-defined threshold, along with a variety of summary statistics and a 
map showing these locations. 
 
Corridor Analysis 
Another variation of the segment analysis is termed as corridor analysis. The corridor 
analysis differs from both segment and sliding-scale analysis because it considers the 
whole corridor, i.e., crashes along I-75.  The corridor analysis method provides a visual 
means to locate high crash concentrations within a corridor. Using traditional methods, 
segments along a specific route could be examined (e.g., by using the sliding-scale 
analysis), but multiple routes within a corridor could not be easily linked and analyzed as 
a group. 
 
Collision Density Analysis 
Using the collision density analysis, the density of crashes can be mapped to determine 
the distribution density of crashes per area or per length (Figure 2).  The term collision 
density could be termed as number of crashes per a square area or per highway length.  
Differences in density can be represented using graduated colors with darker and lighter 
color representing higher and lower densities respectively. 
 
 
Figure 2  An Example of the Collision Density Analysis (Boose, 2001). 

 
9
 
Area Analysis 
Area analysis can be done based on various divisions such as zip codes, census tracts, 
counties, districts, zones, etc.  The area analysis can be used to provide planners with 
identifying critical zones or neighborhoods where different traffic safety problem exists 
as illustrated by Kim (1996) in Figure 3.  The area analysis enables examination of 
crashes with relationship to factors such as population, housing characteristics and other 
geographic features. 
 
 
Figure 3  An Example of Area Analysis -High Accident Areas in Oahu, Hawaii (Kim, 
1996). 
 
Pattern Analysis 
GIS can be used to observe the patterns of crashes over time.  GIS capabilities allow the 
analysis of change of crash rates with the change of other factors including land use, 
population, change in highway functional class and so forth.  Charts and graphs can also 
be attached to a map to complement GIS graphical output to understanding the crash 
patterns and their causes. 
 

 
10
Display/Query Analysis 
The primary appeal of GIS to many is the graphical capabilities. As it has been stated “a 
picture is worth a thousand words.” Maps are the pictures GIS uses to communicate 
complex spatial relationships that the human eyes and mind are capable of understanding. 
The computer makes this possible, but still, it is the GIS user that determines what data 
and spatial relationships will be analyzed and portrayed, or how the data will be 
thematically presented to its intended audience. Using the database capabilities of GIS, 
the safety engineer can query the database and have the results graphically displayed. 
This query analysis, when spoken in everyday conversation, takes on the form of a “show 
me” question, such as “Can you show me all head-on collisions that resulted in a 
fatality?” However, query analysis capabilities in GIS can also be exploited for other 
purposes, such as database automation, which might be used for error checking and 
quality control of coded data. As an example, the GIS roadway database could be queried 
automatically during the crash data entry process to verify the accuracy of speed limit and 
other crash report variables coded by an officer. 
 
For linear referenced data to be displayed in GIS, it first must be integrated with spatial 
data. GIS can integrate spatial data of various scales, resolution, and projection, although 
use of spatial data integration warrants caution on inappropriate use. 
 
Thematic mapping of highway safety data provides a macroscopic level of analysis. 
Linear and spatial data integrated into GIS can be selected, differentiated by type or class, 
and displayed thematically. The safety engineer will be able to symbolize crashes for 
thematic mapping to distinguish between crashes, such as the severity of a crash resulting 
in fatalities and non-fatalities. These simple capabilities are the most commonly used to 
quickly digest large amounts of information, such as showing high crash locations or 
showing crash histories of road segments through the use of graduated line weight 
symbolization. 
 

 
11
Spatial Analysis 
Several analytical techniques, grouped under the general heading “overlay analysis,” are 
available in GIS for spatial analysis and data integration. GIS provides tools to combine 
data, identify overlaps across data, and join the attributes of data sets together using 
feature location and feature extent as the selection criteria. Overlay techniques will 
combine spatial data in other ways, such as features that can be combined to simply add 
one spatial data set to another, or to update or replace portions of one data set with 
another data set. Overlay analysis can be used to merge spatial data by combining two or 
more spatial data sets to produce a new spatial data set where the feature attributes are a 
union of the input data sets. As an example, the safety engineer can use these spatial 
techniques to combine demographic data, such as the number of households, showing the 
average number of school age children, with road segments having crash data showing 
pedestrian-related crashes, in order to derive risk factors for the total number of 
pedestrian-related crashes relative to the total number of school age children per road 
segment, for pedestrian-to-school safety analysis. 
 
Proximity analysis 
Proximity analysis is a type of GIS query capability and a category of spatial analysis that 
represents the fundamental difference of GIS from all other information systems. 
Buffering is a means of performing this practical spatial query to determine the proximity 
of neighboring features. In GIS, buffering will locate all features within a prescribed 
distance from a point, line, or area, such as determining the number of crashes that 
occurred within 800 m (0.5 mi) of an interchange, or locating secondary crashes that 
occurred within a certain distance and time (e.g., 400 m (0.25 mi) and 30 min) of other 
crash events, although reliability of these variables may not always support this example. 
Examples of proximity analysis in highway safety are such as determination of crashes 
occurring within a certain distance from the schools, distribution of crashes occurring 
within a certain distance from the shopping centers, e.t.c.  An example of proximity 
analysis is depicted in Figure 4. 
  

 
12
 
Figure 4  An Example of Proximity Analysis: Traffic Congestion near gas stations 
may contribute to high collision rates (Brose, 2001). 
 
Cluster Analysis 
The Cluster Analysis method is used to study crashes clustered around a specific roadway 
feature, such as a bridge or railroad crossing. Figure 5 shows an example of cluster 
analysis.  Crashes are identified that fall within a given distance on all selected routes. 
Again, the output is a report that lists various summary statistics selected by the user and 
a map depicting the high crash locations.  Cluster analysis can also be used to show the 
distribution of crashes near a certain area of interest such as along the beach, in city 
centers (down town) and so forth. 
 
 
Figure 5  An Example of the use of Cluster Analysis to show crash distributions 
along the beach in Hawaii (Kim, 1996). 

 
13
 
Crash Modeling Techniques 
 
Regression Models 
Regression methods are among the oldest methods that were used for modeling highway 
crashes.  Three main regression models have been employed in crash analysis – Poisson 
Regression, Negative Binomial, and Zero-Inflated Poison and Negative Binomial 
regression models.  The following sections describe these models in details. 
 
Poisson Regression Model 
Poisson model approximates rare-event count data, such as accident occurrence.  
Consider the number of crashes occurring per year at various road sections.  Poisson 
regression model, the probability of a road section i having yi crashes per year (where yi 
is a non-negative integer) can be computed as (Washington et al., 2003): 
!
)
(
i
y
i
i
y
e
y
P
i
i μ
μ
−
=
             yi = 0, 1, 2, 3,… 
 
 
 
 
 
2.1 
Where  
P(yi) = the probability of a roadway section i having yi crashes per year, 
yi = Number of crashes per year for a given section i, 
μi= the Poisson parameter for section i, 
 
Poisson regression models are estimated by specifying the Poisson parameter μi (the 
expected number of crashes per year) as a function of explanatory variables.  The most 
common relationship between explanatory variables and the Poisson parameter is the log-
linear model, 
)
exp(
i
i
X
β
μ =
, or equivalently 
i
i
X
LN
β
μ
=
)
(
, 
where 
i
X  is a vector of explanatory variables and β  is a vector of estimable parameters.  
In this formulation, the expected number of crashes per period is given 
by
)
exp(
]
[
i
i
x
y
E
β
=
. 

 
14
Negative Binomial Regression Model 
The negative binomial model is derived by rewriting Equation xx such that, for each 
observation i, 
)
exp(
i
i
i
X
ε
β
μ
+
=
, 
 
 
 
 
 
 
 
2.2 
 
where 
)
exp( iε
is a gamma-distributed error term with mean 1 and variance 
2
α .  The 
addition of this term allows the variance to differ from the mean as below: 
2
]]
[
]
[
[
]]
[
1
][
[
)
(
i
i
i
i
i
y
E
y
E
E
y
E
y
E
y
Var
α
α
+
=
+
=
. 
 
 
2.3 
 
The Poisson regression model is regarded as a limiting model of the negative binomial 
regression model as α approaches zero, which means that the selection between these 
two models is dependent on the value ofα .  The parameter α  is often referred to as the 
overdispersion parameter. 
 
Zero-Inflated Poisson Negative Binomial Regression Models 
Washington et al. (2003) described the phenomena of zero events.  An observation of 
zero events during an observation period can arise from two qualitatively different 
conditions.  One condition may result from simply failing to observe an event during an 
observation period.  Another qualitatively different condition may result from an inability 
ever to experience an event.  The highway sections may therefore be considered in a 
zero-crash state because the likelihood of crash is so small (perhaps the expectation 
would be that a reported crash would occur once in a 100-year period).  Thus, the zero-
count state may refer to situations where the likelihood of an event occurring is extremely 
rare in comparison to the normal-count state where event occurrence is inevitable and 
follows some known count process. 
 
Two aspects of this nonqualitative distinction of the zero state are noteworthy.  First, 
there is a preponderance of zero in the data – more than would be expected under a 
Poisson process.  Second, a sampling unit is not required to be in the zero or near zero 
state reflects one of negligible probability compared to the normal state.  To address 

 
15
phenomena with zero-inflated counting processes, zero-inflated Poisson and zero-inflated 
negative binomial regression models have been developed.  The zero-inflated Poisson 
model assumes that the events, 
(
)
ny
y
y
y
Y
,...,
,
,
3
2
1
=
, are independent and the model 
is 
0
=
iy
 with probability 
(
)
)
exp(
1
i
i
i
p
p
μ
−
−
+
 
 
 
 
2.4 
y
yi =
 with probability (
)
!
)
exp(
1
y
p
y
i
i
i
μ
μ
−
−
  
 
 
 
2.5 
The ZINB regression model follows a similar formulation with events, 
(
)
ny
y
y
y
Y
,...,
,
,
3
2
1
=
, independent and 
0
=
iy
 with probability 
α
μ
α
α
1
)
1
(
1
)
1(
⎥
⎥
⎥
⎦
⎤
⎢
⎢
⎢
⎣
⎡
+
−
+
i
i
i
p
p
 
 
 
 
2.6 
y
yi =
 with probability 
⎥
⎥
⎥
⎥
⎦
⎤
⎢
⎢
⎢
⎢
⎣
⎡
Γ
−
+
Γ
−
!
)
1
(
)
1(
)
)
1
((
)
1(
1
y
u
u
y
p
y
i
i
i
α
α
α
, 
,...
3,2,1
=
iy
 
where 
[
]
i
iu
μ
α
α
+
=
)
/
1(
)
/
1(
. 
(
)
)
exp(
1
i
i
i
p
p
μ
−
−
+
 
 
With P(yi=0) = 
α
μ
α
α
ϕ
ϕ
1
)
1
(
1
)
1(
⎥
⎥
⎥
⎥
⎦
⎤
⎢
⎢
⎢
⎢
⎣
⎡
+
−
+
i
i
i
 
With P(yi=r) =
⎥
⎥
⎥
⎥
⎦
⎤
⎢
⎢
⎢
⎢
⎣
⎡
Γ
−
+
Γ
−
!
)
1
(
)
1(
)
)
1
((
)
1(
1
r
r
r
i
i
i
α
λ
λ
α
ϕ
α
, r=1, 2, 3…, n 
 
 
2.7 

 
16
Where λi= [
]
iμ
α
α
+
)
/
1(
)
/
1(
. 
 
 
The Use of Regression Analysis in Crash Modeling 
 
Conventionally, crash modeling has been conducted using regression methods.  However, 
recent research shows that regression methods suffer some undesirable statistical 
properties when applied to crash analysis, some of which have been discussed by Abdel-
Aty and Radwan (2000).  Joshua and Garber (1990) reported that sometimes regression 
analysis can not describe the relationship between crashes and model variables. To adopt 
the regression method effectively, the form of the fitting function should be defined in 
advance.  A fitting should then be carried out according to the minimum sum of squared 
errors.  Because of highly nonlinear internal relationships of variables that influence 
crash occurrences, Abdelwahab and Abdel-Aty (2001) suggested the use of Artificial 
Neural Networks (ANN) over regression methods. 
 
Artificial Neural Networks 
 
Artificial Neural Networks are relatively crude electronic models based on the neural 
structure of the brain. The brain basically learns from experience. It is natural proof that 
some problems that are beyond the scope of current computers are indeed solvable by 
small energy efficient packages. This brain modeling also promises a less technical way 
to develop machine solutions. This new approach to computing also provides a more 
graceful degradation during system overload than its more traditional counterparts. 
 
The most common neural network model is the multilayer perceptron (MLP). This type 
of neural network is known as a supervised network because it requires a desired output 
in order to learn. The goal of this type of network is to create a model that correctly maps 

 
17
the input to the output using historical data so that the model can then be used to produce 
the output when the desired output is unknown. A graphical representation of an MLP is 
shown in Figure 6.  
 
Figure 6  A Typical Artificial Neural Network Structure. 
 
Supervized learning 
The vast majority of artificial neural network solutions have been trained with 
supervision. In this mode, the actual output of a neural network is compared to the 
desired output. Weights, which are usually randomly set to begin with, are then adjusted 
by the network so that the next iteration, or cycle, will produce a closer match between 
the desired and the actual output. The learning method tries to minimize the current errors 
of all processing elements. This global error reduction is created over time by 
continuously modifying the input weights until acceptable network accuracy is reached.  
 
With supervised learning, the artificial neural network must be trained before it becomes 
useful. Training consists of presenting input and output data to the network. This data is 
often referred to as the training set. That is, for each input set provided to the system, the 
corresponding desired output set is provided as well. In most applications, actual data 
must be used. This training phase can consume a lot of time. In prototype systems, with 
inadequate processing power, learning can take weeks. This training is considered 

 
18
complete when the neural network reaches a user defined performance level. This level 
signifies that the network has achieved the desired statistical accuracy as it produces the 
required outputs for a given sequence of inputs. The weights obtained at the desired 
accuracy are then used for the application.  Some network types allow continual training, 
at a much slower rate, while in operation. This helps a network to adapt to gradually 
changing conditions.  
 
Training sets need to be fairly large to contain all the needed information if the network is 
to learn the features and relationships that are important. Not only do the sets have to be 
large but the training sessions must include a wide variety of data. If the network is 
trained just one example at a time, all the weights set so meticulously for one fact could 
be drastically altered in learning the next fact. The previous facts could be forgotten in 
learning something new. As a result, the system has to learn everything together, finding 
the best weight settings for the total set of facts. 
 
Learning Laws 
Many learning laws are in common use. Most of these laws are some sort of variation of 
the best known and oldest learning law, Hebb's Rule. Research into different learning 
functions continues as new ideas routinely show up in trade publications. Some 
researchers have the modeling of biological learning as their main objective. Others are 
experimenting with adaptations of their perceptions of how nature handles learning. 
Either way, man's understanding of how neural processing actually works is very limited. 
Learning is certainly more complex than the simplifications represented by the learning 
laws currently developed. A few of the major laws are presented as examples.  
 
Hebb's Rule 
The first, and undoubtedly the best known, learning rule was introduced by Donald Hebb. 
The description appeared in his book The Organization of Behavior in 1949. His basic 
rule is: If a neuron receives an input from another neuron, and if both are highly active 
(mathematically have the same sign), the weight between the neurons should be 
strengthened.  

 
19
Hopfield Law 
This law is similar to Hebb's rule with the exception that it specifies the magnitude of the 
strengthening or weakening. It states, "if the desired output and the input are both active 
or both inactive, increment the connection weight by the learning rate, otherwise 
decrement the weight by the learning rate."  
 
The Delta Rule 
This rule is a further variation of Hebb's Rule. It is one of the most commonly used. This 
rule is based on the simple idea of continuously modifying the strengths of the input 
connections to reduce the difference (the delta) between the desired output value and the 
actual output of a processing element. This rule changes the synaptic weights in the way 
that minimizes the mean squared error of the network. This rule is also referred to as the 
Widrow-Hoff Learning Rule and the Least Mean Square (LMS) Learning Rule.  
 
The way that the Delta Rule works is that the delta error in the output layer is 
transformed by the derivative of the transfer function and is then used in the previous 
neural layer to adjust input connection weights. In other words, this error is back-
propagated into previous layers one layer at a time. The process of back-propagating the 
network errors continues until the first layer is reached. The network type called 
Feedforward, Back-propagation derives its name from this method of computing the error 
term.  
 
When using the Delta rule, it is important to ensure that the input data set is well 
randomized. Well ordered or structured presentation of the training set can lead to a 
network which can not converge to the desired accuracy. If that happens, then the 
network is incapable of learning the problem.  
 
The Gradient Descent Rule 
This rule is similar to the Delta Rule in that the derivative of the transfer function is still 
used to modify the delta error before it is applied to the connection weights. Here, 
however, an additional proportional constant tied to the learning rate is appended to the 

 
20
final modifying factor acting upon the weight. This rule is commonly used, even though 
it converges to a point of stability very slowly.  
 
It has been shown that different learning rates for different layers of a network help the 
learning process converge faster. In these tests, the learning rates for those layers close to 
the output were set lower than those layers near the input. This is especially important for 
applications where the input data is not derived from a strong underlying model.  
 
Kohonen's Learning Law 
This procedure, developed by Teuvo Kohonen, was inspired by learning in biological 
systems. In this procedure, the processing elements compete for the opportunity to learn, 
or update their weights. The processing element with the largest output is declared the 
winner and has the capability of inhibiting its competitors as well as exciting its 
neighbors. Only the winner is permitted an output, and only the winner plus its neighbors 
are allowed to adjust their connection weights.  
 
Further, the size of the neighborhood can vary during the training period. The usual 
paradigm is to start with a larger definition of the neighborhood, and narrow in as the 
training process proceeds. Because the winning element is defined as the one that has the 
closest match to the input pattern, Kohonen networks model the distribution of the inputs. 
This is good for statistical or topological modeling of the data and is sometimes referred 
to as self-organizing maps or self-organizing topologies. 
 
Basically, most applications of neural networks fall into the following five categories:  
1. prediction  
2. classification  
3. data association  
4. data conceptualization  
5. data filtering  

 
21
 
Table 1 shows the differences between these network categories and shows which of the 
more common network topologies belong to which primary category. This chart is 
intended as a guide and is not meant to be all inclusive. While there are many other 
network derivations, this chart only includes the architectures explained within this 
section of this report. Some of these networks, which have been grouped by application, 
have been used to solve more than one type of problem. Feedforward back-propagation in 
particular has been used to solve almost all types of problems and indeed is the most 
popular for the first four categories.  The next few subsections describe these five 
network types. 
 
Artificial networks for prediction 
 
Feedforward, Back-Propagation Architecture 
The feedforward, back-propagation architecture is used more than all other combined. It 
is used in many different types of applications. This architecture has spawned a large 
class of network types with many different topologies and training methods. Its greatest 
strength is in non-linear solutions to ill-defined problems.  
 
The typical back-propagation network has an input layer, an output layer, and at least one 
hidden layer. There is no theoretical limit on the number of hidden layers but typically 
there is just one or two. Some work has been done which indicates that a minimum of 
four layers (three hidden layers plus an output layer) are required to solve problems of 
any complexity. Each layer is fully connected to the succeeding layer, as shown in Figure 
7.  
 
 
 
 
 

 
22
Table 1  Network Selector Table 
Network Type 
Networks 
Use for Network 
Prediction 
• 
Back-propagation  
• 
Delta Bar Delta  
• 
Extended Delta Bar 
Delta  
• 
Directed Random 
Search  
• 
Higher Order Neural 
Networks  
• 
Self-organizing map 
into Back-propagation  
Use input values to predict some 
output (e.g. pick the best stocks in 
the market, predict weather, identify 
people with cancer risks etc.) 
Classification 
• 
Learning Vector 
Quantization  
• 
Counter-propagation  
• 
Probabalistic Neural 
Networks  
Use input values to determine the 
classification (e.g. is the input the 
letter A, is the blob of video data a 
plane and what kind of plane is it) 
Data 
Association 
• 
Hopfield  
• 
Boltzmann Machine  
• 
Hamming Network  
• 
Bidirectional 
associative Memory  
• 
Spatial-temporal 
Pattern Recognition  
Like Classification but it also 
recognizes data that contains errors 
(e.g. not only identify the characters 
that were scanned but identify when 
the scanner isn't working properly) 
Data 
Conceptualiza
tion 
• 
Adaptive Resonance 
Network  
• 
Self Organizing Map  
Analyze the inputs so that grouping 
relationships can be inferred (e.g. 
extract from a database the names of 
those most likely to buy a particular 
product) 
Data Filtering 
• 
Recirculation  
Smooth an input signal (e.g. take the 
noise out of a telephone signal) 
 
 
Delta Bar Delta 
The Delta bar delta paradigm uses a learning method where each weight has its own self-
adapting coefficient. It also does not use the momentum factor of the back-propagation 
architecture. The remaining operations of the network, such as feedforward recall, are 
identical to the normal back-propagation architecture. Delta bar delta is a heuristic 
approach to training artificial networks. What that means is that past error values can be 
used to infer future calculated error values. Knowing the probable errors enables the 
system to take intelligence steps in adjusting the weights. However, this process is 

 
23
complicated in that empirical evidence suggests that each weight may have quite different 
effects on the overall error.  
 
 
 
Figure 7  An Example Feedforward Back-propagation Network (Anderson and 
McNeil, 1992). 
 
Networks for classification – Probabilistic Neural Network 
 
This network provides a general solution to pattern classification problems by following 
an approach developed in statistics, called Bayesian classifiers. Bayes theory, developed 
in the 1950's, takes into account the relative likelihood of events and uses a priori 
information to improve prediction. The network paradigm also uses Parzen Estimators 
which were developed to construct the probability density functions required by Bayes 
theory.  
 
The probabilistic neural network uses a supervised training set to develop distribution 
functions within a pattern layer. These functions, in the recall mode, are used to estimate 
the likelihood of an input feature vector being part of a learned category, or class. The 
learned patterns can also be combined, or weighted, with the a priori probability, also 
called the relative frequency, of each category to determine the most likely class for a 
given input vector. If the relative frequency of the categories is unknown, then all 

 
24
categories can be assumed to be equally likely and the determination of category is solely 
based on the closeness of the input feature vector to the distribution function of a class.  
An example of a probabilistic neural network is shown in the Figure 8. This network has 
three layers. The network contains an input layer which has as many elements as there are 
separable parameters needed to describe the objects to be classified. It has a pattern layer, 
which organizes the training set such that each input vector is represented by an 
individual processing element. And finally, the network contains an output layer, called 
the summation layer, which has as many processing elements as there are classes to be 
recognized. Each element in this layer combines via processing elements within the 
pattern layer which relate to the same class and prepares that category for output. 
Sometimes a fourth layer is added to normalize the input vector, if the inputs are not 
already normalized before they enter the network. As with the counter-propagation 
network, the input vector must be normalized to provide proper object separation in the 
pattern layer.  
 
As mentioned earlier, the pattern layer represents a neural implementation of a version of 
a Bayes classifier, where the class dependent probability density functions are 
approximated using a Parzen estimator. This approach provides an optimum pattern 
classifier in terms of minimizing the expected risk of wrongly classifying an object. With 
the estimator, the approach gets closer to the true underlying class density functions as 
the number of training samples increases, so long as the training set is an adequate 
representation of the class distinctions.  
 

 
25
 
Figure 8  A Probabilistic Neural Network Example. 
 
In the pattern layer, there is a processing element for each input vector in the training set. 
Normally, there are equal amounts of processing elements for each output class. 
Otherwise, one or more classes may be skewed incorrectly and the network will generate 
poor results. Each processing element in the pattern layer is trained once. An element is 
trained to generate a high output value when an input vector matches the training vector. 
The training function may include a global smoothing factor to better generalize 
classification results. In any case, the training vectors do not have to be in any special 
order in the training set, since the category of a particular vector is specified by the 
desired output of the input. The learning function simply selects the first untrained 
processing element in the correct output class and modifies its weights to match the 
training vector.  
 
The pattern layer operates competitively, where only the highest match to an input vector 
wins and generates an output. In this way, only one classification category is generated 
for any given input vector. If the input does not relate well to any patterns programmed 
into the pattern layer, no output is generated.  
 
The Parzen estimation can be added to the pattern layer to fine tune the classification of 
objects. This is done by adding the frequency of occurrence for each training pattern built 

 
26
into a processing element. Basically, the probability distribution of occurrence for each 
example in a class is multiplied into its respective training node. In this way, a more 
accurate expectation of an object is added to the features which make it recognizable as a 
class member.  
 
Training of the probabilistic neural network is much simpler than with back-propagation. 
However, the pattern layer can be quite huge if the distinction between categories is 
varied and at the same time quite similar is special areas. There are many proponents for 
this type of network, since the groundwork for optimization is founded in well known, 
classical mathematics. 
 
Examples of uses of artificial neural networks in crash analysis 
 
There are a several previous research studies that have used artificial neural networks in 
crash prediction.  Vogt and Bared (1998) presented an artificial neural network (ANN) 
concept in crash modeling.  Figure 9 shows a typical ANN structure which is composed 
of input units X1, X2, ... corresponding to independent variables (in our case, highway or 
intersection variables), a hidden layer known as the first layer, and an output layer 
(second layer) whose output units Y1, ... correspond to dependent variables (expected 
number of crashes per time period).  According to the study, the most delicate part of 
neural network modeling is generalization – the development of a model that is reliable in 
predicting future crashes.  The study also suggests that overfitting (i.e., getting weights 
for which the error is small on the training set that even random variation is accounted for) 
can be minimized by having two validation samples in addition to the training sample.  
According to Smith (1993), the dataset should be divided into three subsets: 40% for 
training, 30% to prevent overfitting, and 30% for testing. Training on the training set 
should stop at the epoch when the error computed on the second set begins to rise (the 
second set is not used for training but merely to decide when to stop training).  Then, the 
third set is used to see how well the model performs.  Cross-validation helps to optimize 
the fit in three ways: by limiting/optimizing the number of hidden units, by 

 
27
limiting/optimizing the number of iterations, and by inhibiting network use of large 
weights. 
 
 
Figure 9  Typical Artificial Neural Network Structure (Vogt and Bared, 1998). 
 
Musone et al (1999) used ANN to analyze urban crashes in the city of Milan in Italy.  
The study applied the feed-forward neural networks with a back-propagation learning 
paradigm (Figure 10).  Abdelwahab and Abdel-Aty (2001) developed ANN models to 
predict driver injury severity in traffic accidents at signalized intersections.  The study 
investigated the use of two well known neural network paradigms, the multilayer 
perceptron (MLP) and fuzzy adaptive resonance theory (ART) neural networks.  The 
MLP neural network has a better generalization performance of 65.6% and 60.4% for the 
training and testing phases, respectively.  The performance of the MLP was compared 
with an ordered logit model.  The ordered logit model was able to correctly classify only 
58.9% and 57.1% for the training and testing phases, respectively. 
  

 
28
 
Figure 10  ANN model based on back-propagation algorithm (Musone et al., 1999). 
 
Kalyonchuoglu and Tigdemir (2004) used artificial neural networks as an alternative 
approach for modeling and simulation of traffic crash data.  Variables used include age, 
gender, education, driving years, and average distance driven per day.  Different numbers 
of neurons in the hidden layer and the activation functions were changed to acquire the 
best modeling of the data.  Figure 11 shows the two hidden layers artificial neural 
network structure used by Kalyonchuoglu and Tigdemir.      

 
29
 
Figure 11  ANN models with two hidden layers (Kalyoncuoglu & Tigdemir, 2004). 
 
Artificial Neural networks (ANN) approach has the following advantages: (1) There is no 
need to assume an underlying data distribution, (2) neural networks are applicable to 
multivariate non-linear problems, and (3) the transformations of the variables are 
automated in the computational process.  However, ANN technique has several 
disadvantages including: (1) minimizing overfitting requires a great deal of 
computational effort, and (2) the individual relations between the input variables and the 
output variables are not developed by engineering judgment so that the model tends to be 
a black box without analytical basis. 
  
Bayesian Technique 
 
The Bayesian prediction technique is the probabilistic model that uses prior and posterior 
probabilities together with likelihood functions to predict the crash occurrence based on 
historical data.  Higle and Witkowski (1988) developed a method for identifying 

 
30
hazardous locations on the basis of a Bayesian analysis of crash data using crash data 
from the jurisdiction of the Pima County Department of Transportation in Tucson, 
Arizona.  The study used a two-step procedure.  In the first step, the crashes are 
aggregated across a number of sites in a defined region.  In the second step, the regional 
distribution and the crash history at a particular site are used to obtain a refined 
estimation of the probability distribution associated with the crash rate at that particular 
site.  The study assumed a Poisson distribution.  Also, Al-Masaeid (1990) developed an 
empirical Bayesian approach to estimate the expected number of crashes and the crash 
rate at a group of sites as well as at the site level.  The Bayesian technique suffers one 
major disadvantage – the probability distribution of crashes has to be assumed.  It is 
possible that crashes do not necessarily always follow a particular distribution. 
 
Nearest Neighbor rule 
 
The nearest neighbor analysis is a classification method in which the class of an unknown 
record is assigned after comparisons between the unknown record and all known records 
(training data) in data repository are made.  The degree of similarity between different 
records is determined by a function called the distance function.  Nukoolkit and Chen 
(2001) used two different distance functions – Eucledian Distance (ED) and Value 
Difference Metric (VDM) distance both combined with k-mode clustering in predicting 
whether a car crash will have either an injury or a non-injury outcome using a subset of 
Alabama interstate alcohol-related crashes of the year 2000.  The prediction errors of 
33% and 45% were observed by using ED and VDM methods, respectively.  The study 
further proposed an improved technique that combines the distance function with 
decision tree clustering which reduced the prediction error to 19%.  Hattori and 
Takahashi (1999) reported that k-nearest neighbor (k-NN) rule is effective, when the 
probability distributions of the feature variables are not known and therefore the Bayes 
decision rule can not be used.  It should be noted however that the definition of the 
distance measurement in crash variables is difficult and subjective.  The existence of 
variables which vary in form and magnitude makes it difficult to establish the distance 

 
31
function.  While some variables are continuous, others are discrete.  In addition, even 
within the continuous and discrete variable groups, the range of magnitudes and the 
number of categories differ from variable to variable.  This lessens the appropriateness of 
the nearest neighbor technique in crash prediction. 
 
Decision tree 
 
It is natural and intuitive to classify a pattern through a sequence of questions, in which 
the next question asked depends on the answer to the current question.  Because all of the 
questions can be asked in a yes/no or true/false or value (property)∈ set_of_values” style 
that does not require any notion of metric.  Such a sequence of questions is displayed in a 
decision tree pattern recognition technique, where a convention of the first or root node is 
displayed at the top, connected by successive (directional) links or branches to other 
nodes.  These are similarly connected until the terminal or leaf nodes are reached, which 
have no further links.  A decision tree structure is depicted in Figure 12. 
 
The classification of a particular pattern begins at the root node, which asks for the value 
of a particular property of the pattern.  The different links from the root node corresponds 
to the different possible values.  Based on the answer, we follow the appropriate link to a 
subsequent or descendent node.  The links must be mutually distinct and exhaustive, i.e., 
one and only one link will be followed.  The next step is to make the decision at the 
appropriate subsequent node, which can be considered the root of a subtree.  The same 
procedure is continued until a leaf node is reached, which has no further question.  Each 
leaf node bears a category label, and the test pattern is assigned the category of the leaf 
node reached.  One advantage of the decision tree technique over many other classifiers 
such as neural networks is interpretability.  It is a straight forward matter to render the 
information in such a tree as logical expressions.     
 

 
32
 
Figure 12  Decision Tree Structure. 
 
Chong et al. (2004) studied the National Automotive Sampling System General Estimate 
System automobile crash data from 1995 to 2000 and investigated the performance of 
neural networks and decision trees applied to predict drivers’ injury severity in head-on 
front impact point collisions.  The study employed a combination of backpropagation (BP) 
and conjugate gradient (CG), trying to minimize the mean square error.  The results 
indicated that the direct decision tree-based approach outperforms the direct neural 
network approach in all cases – no injury, possible injury, non-capacitating injury, 
incapacitating injury, and fatal injury.  The study further indicated that most important 
factors in fatal injury are driver’s seat belt usage, light condition of the roadway, and 
driver’s alcohol usage.  The experimental results for the different classes are also 
summarized in Table 2. 
 
 
 
 
 

 
33
Table 2  Training and Testing Results for Neural Network (Chong et al., 2004) 
Injury Class 
ANN 
DT 
 
# Hidden Neurons 
Accuracy (%) 
Accuracy (%) 
No Injury 
65 
60.45 
67.54 
Possible Injury 
65 
57.58 
64.40 
Non-incapacitating 
Injury 
75 
56.8 
60.37 
Incapacitating 
Injury 
65 
61.32 
71.38 
Fatal Injury 
42 
75.51 
89.46 
 
 
Bayesian Belief Network Technique 
 
Most of the techniques used for modeling crashes require a prior knowledge of the 
distribution of crash parameters.  Sometimes the knowledge about a distribution is not 
directly known but instead the statistical dependencies or independencies among the 
variables are known.  For example, by intuition there exist a dependency between side 
swipe crashes with the lane width, vehicle speed and severity of the crash, traffic volume 
and the crash rate, and so forth.  The dependency between crash occurrence and traffic 
factors such as AADT, geometric factors such as number of lanes, and design factors 
such as speed could be established.  The internal dependencies could then be represented 
by conditional probabilities which could be used to determine the likelihood of the 
magnitude of crashes in a particular roadway segment given certain conditions. 
 
The Bayesian Belief Network Technique is fairly new.  The technique is being researched 
in areas which have complex dependency of variables such as medical diagnostic systems, 
real-time weapons scheduling, computer processor fault diagnosis, generator monitoring 
expert system, and software troubleshooting.  Clearly, crash modeling involves complex 
relationships between the variables involved.  Bayesian belief networks are appropriate 

 
34
for modeling crashes due to the fact that the dependencies between factors are known and 
are used to construct the belief network structure.  
 
 
Background of Bayesian Belief Networks 
 
Overview 
Bayesian networks are well explained by Singh (1998).  Bayesian networks combine a 
graphical structure (with node representing the domain variables, and edges representing 
probabilistic dependencies between them) with associated conditional probabilities to 
give a rich, explicit representation of the various conditional independence and 
dependence relationships between the variables.  The local probability distributions 
associated with each variable, along with the set of conditional independence assertions 
represented in the network, can be directly combined to construct the joint probability 
distribution of the variables in the network.  This represents extensive savings, both in the 
computation of posterior probabilities of the variables of interest, given some evidence. 
 
Use of Bayesian Networks in Crash Modeling 
Literature on the use of Bayesian Belief Networks in crash modeling is limited.  A recent 
study by Marjan Simoncic (2005) constructed a Bayesian Network model of two-car 
crashes.  The study used a large road crash dataset to model the interdependence among 
the variables related to crashes and the dependence of the outcome on the relevant 
variables.  The study presented a simple example of a Bayesian network (Figure 13).  
Many factors in Figure 13 are interrelated.  The number of road casualties depends on 
how many trips car drivers took in the area and the danger level; the number of trips 
related to weather conditions and the season (e.g., summer means more vacation travel); 
season and weather are also related; the level of anger is influenced by the average speed 
of vehicles on the roads and on road conditions (e.g., a slippery road); and road 
conditions depend on the weather and season and influence the average speed and level 

 
35
of danger.  In Figures 13, nodes represent different variables in the model and links 
represent interdependence between the variables. 
 
Figure 13  Bayesian Network Structure (Simoncic, 2005). 
 
Simoncic (2005) also presented a model based on variables extracted from crash report 
dataset (Figure 14).  The study used a computer program called PowerConstructor 
(Cheng et al, 2001) to construct the network structure.  This engine constructs belief 
networks by using conditional independence (CI) tests. In general, it requires CI tests to 
the complexity of O(N4); when the attribute ordering is known, the complexity is O(N2). 
N is the number of attributes (fields).  The resulting BBN structure is shown in Figure 14.    
 

 
36
 
Figure 14  Bayesian Network Structure (Simoncic, 2005). 
 

 
37
Another similar application of causal models in modeling collisions was presented by 
Davis and Swenson (2005).  The model presents causal relationship of three vehicle 
platoon (Figure 15).  The nodes of the graph represent the model’s variables while the 
arrows indicate the presence and direction of causal dependencies.  Those nodes without 
arrows pointing toward them (such as V1) represent exogenous variables, while the others 
(such as a20) represent endogenous variables.  The acronyms in Figure 15 account for the 
following driver vehicle attributes: 
ak: acceleration 
a20: minimum deceleration for driver 2 
a30: minimum deceleration for driver 3 
vk: velocity 
hk: headway 
rk: reaction time 
uk: difference between observed and minimum deceleration 
y: collision indicator 
   
Causal Structure 
The causal structure is well illustrated by Duda et. al (2001).  Suppose we wish to 
determine the probability distribution over the variables d1, d2, …… at D in the left 
network of Figure 16 using conditional probability tables and the network topology.  We 
evaluate this by summing the full joint distribution, P(a.b.c.d), over all the variables other 
than d: 
 
∑
=
c
b
a
d
c
b
a
P
d
P
,
,
)
,
,
,
(
)
(
 
 
∑
=
c
b
a
c
d
P
b
c
P
a
b
P
a
P
,
,
)
|
(
)
|
(
)
|
(
)
(
 
 
∑
∑
∑
=
c
a
b
a
P
a
b
P
b
c
P
c
d
P
)
(
)
|
(
)
|
(
)
|
(
 
 
 
(2.8) 
 
 

 
38
 
Figure 15  Directed Acyclic Graph Representation of Three-Vehicle Platoon 
Collision Model (Davis and Swenson 2005). 
 
 
 

 
39
 
Figure 16  Two Simple Belief Networks (Duda et al., 2000). 
Where 
∑
=
a
a
P
a
b
P
b
P
)
(
)
|
(
)
(
 
∑
∑
=
a
b
a
P
a
b
P
b
c
P
c
p
)
(
)
|
(
)
|
(
)
(
  
 
 
 
 
(2.9) 
 
If we wanted the probability of a particular value of D, for instance d2, we would 
compute 
∑
=
c
b
a
d
c
b
a
P
d
P
,
,
2
2
)
,
,
,
(
)
(
 
 
 
 
 
 
(2.10) 
and proceed as above.  In either case, conditional probabilities are simple because of the 
simple linear topology of the network. 
 
Now consider computing the probabilities of the variables at H in the network with the 
loop on the right of Figure 16. 
∑
=
g
f
e
h
g
f
e
P
h
P
,
,
)
,
,
,
(
)
(
 
 
∑
=
g
f
e
g
f
h
P
e
g
P
e
f
P
e
P
,
,
)
,
|
(
)
|
(
)
|
(
)
(
 
 
∑
∑
=
e
g
f
g
f
h
P
e
g
P
e
f
P
e
P
,
)
,
|
(
)
|
(
)
|
(
)
(
 
 
 
(2.11) 
 

 
40
Types of Bayesian Belief Networks 
Bayes belief networks are more useful in the case where are given the values of some of 
the variables – the evidence – and we seek to determine some particular configuration of 
other variables.  In practice, we determine the values of several query variables (denoted 
collectively x) given the evidence of all other variables (denoted by e) by 
 
(
)
(
)
( )
(
),
,
,
/
e
x
P
e
p
e
x
p
e
x
p
α
=
=
  
 
 
 
 
(2.12) 
where α is a constant of proportionality.  
 
When the dependency relationships among the features used by a classifier are unknown, 
we generally proceed by taking the simplest assumption, names, that the features are 
conditionally independent given the category, that is, 
(
)
(
) (
).
|
|
,
|
b
x
P
a
x
P
b
a
x
p
=
 
 
 
 
 
 
(2.13) 
 
There are two basic types of Bayesian Belief Netoworks – Naïve Bayes Belief Networks 
and Conditional Probability Bayesian Belief Networks.  These two types of Bayesian 
Belief Networks are discussed next. 
 
Naïve Bayes’ Belief Networks 
This type of Bayesian Belief Networks assumes independence between variables in the 
Belief Netowork model.  Each variable is assumed to be directly related to the output 
variable.  In practice, this so-called naïve Bayes network often works quite well in 
practice, despite its manifest simplicity.  Other approaches are to assume some functional 
form of conditional probability tables. 
 
To state the general problem, let 
(
)t
n)
(
),...,
1(
ω
ω
ω =
 be a vector denoting the n 
states of nature, with 
)
(i
=
ω
taking one one of the c values 
c
ω
ω ,...,
1
.  Let 
)
(ω
P
be 
the prior probability for the n states of nature.  Let 
)
,...,
( 1
nx
x
X =
 be a matrix giving 

 
41
the n observed feature vectors, with 
ix  being the feature vector obtained when the state 
of nature was 
)
(i
ω
.  Finally, let 
)
|
(
ω
X
p
be the conditional probability density 
function for X given the tue set of states of nature ω .  Using this notation we see that the 
posterior probability of ω  is given by  
.)
(
)
|
(
)
(
)
|
(
)
(
)
(
)
|
(
)
|
(
∑
=
=
ω
ω
ω
ω
ω
ω
ω
ω
P
X
p
P
X
p
X
p
P
X
p
X
p
  
 
 
(2.14) 
 
While this provides the theoretical solution, in practice the computation of 
)
|
(
X
p ω
 
can easily prove to be an enormous task.  If each component 
)
(i
ω
 can have one of c 
values, there are 
n
c  possible values of ω  to consider.  Some simplification can be 
obtained if the distribution of the feature vector 
ix  depends only on the corresponding 
state of nature
)
(i
ω
, not on the values of the other feature vectors or the other states of 
nature.  In this case the joint density 
)
|
(
ω
X
p
 is merely the product of the component 
densities
))
(
|
(
i
x
p
i ω
: 
∏
=
=
n
i
i
i
x
p
X
p
1
)).
(
(
)
|
(
ω
ω
 
 
 
 
 
 
 
(2.15) 
 
Conditional Probability Bayesian Belief Networks 
Conditional probability Bayesian Belief Networks takes advantage of prior causal 
knowledge to construct a graphical presentation of interdependence of model variables.  
Conditional probability tables are then produces which are then used for prediction 
purposes. The quantitative parameter set theta consists of the conditional probability 
distributions p(zi/pa(Zt)) necessary to define the joint distribution p(Z1, Z2,…Zn).  
Without loss of generality, assume that the variables Z1,Z2,…Zn, are ordered such that, in 
G, 
{
}
n
i
Z
Z
Z
Z
pa
,...
,
)
(
2
1
⊆
.  Using the chain rule of probability, the joint probability 
distribution, P(Z), can be represented as follows: 
 

 
42
(
)
(
).
,...
,
,...
,
1
1
2
1
2
1
∏
=
−
=
n
i
i
n
Z
Z
Z
P
Z
Z
Z
P
 
 
 
 
 
(2.16) 
Note that the structure G unambiguously defines the parameter set θ which is necessary 
to specify the joint distribution (
)
n
Z
Z
Z
P
,...
,
2
1
, since 
(
)
(
)
(
)
i
i
i
i
Z
pa
Z
P
Z
Z
Z
Z
P
|
,...
,
|
1
2
1
=
−
 
 
 
 
 
(2.17) 
This follows directly from the encoding of conditional independence statements in the 
Bayesian network, as described above. Thus, this unique joint distribution can be written 
as 
(
)
(
)
(
)
∏
=
=
n
i
i
i
n
Z
pa
Z
P
Z
Z
Z
P
1
2
1
|
,...
,
.  
 
 
 
 
(2.18) 
 
The performance task in Bayesian networks, in general, involves arbitrary query 
answering, i.e., given some evidence about a subset of the domain variables, one is 
interested in computing the posterior probabilities of some other variables of interest. 
Thus, given a set of attributes, 
Z
Zi ⊂
 which has been instantiated to a tuple of values 
zi, the task is then to compute the posterior probability, (
)
θ.
.
|
1
1
2
G
z
Z
Z
P
=
 of a set 
of variables Z2 given the evidence Zi. 
 
Of special interest is the use of Bayesian networks as classifiers, where one is interested 
in predictions about a special target variable (the class variable).  The performance tast 
then consists of classifying instances.  The classification process involves a class variable 
C that can take on values c1, c2, …..cm, and a feature vector Z of n features that can take 
on a tuple of values denoted by {z1,z2,…zn}.  Given a case Z represented by an 
instantiation {z1,z2,….zn} of feature values, the classification tast is to determine the class 
value ci that Z falls into.  The performance of the network is measured on some set of test 
cases in terms of the classification accuracy, i.e, the percentage of test cases for which it 
predicts the class correctly. 
 

 
43
Representation 
Formally, a Bayesian network consists of a qualitative network structure G and a 
quantitative probability distribution θ over the network structure.  The qualitative 
network structure G (N, A) consists of a directed acyclic graph (DAG) of nodes N and 
arcs A, where 
N
N
A
×
⊆
.  Each node I corresponds to a discrete random variable Zi 
with finite domain 
iZ
Ω
.  The Bayesian network then represents the joint probability 
distribution P(Z)=P(z1,Z2,….Zn). 
 
Arcs in a Bayesian network represent the dependence relationships among the variables.  
An arc into node I from j represents probabilistic dependence of Zi and Zj, and is 
precisely specified using the notion of parents of a node.  The parents of Zi, pa(Zi), are 
direct predecessors of Zi in G.  A Bayesian network encodes the set of conditional 
independence assertions that render each variable Zi conditionally independent of its non-
descendants (in G), given the state of its parents, pa (Zi), in the network.  This notion of 
conditional independence of variable Zi given pa(Zj).  Other conditional independencies 
follow from these ones, and can be efficiently determined from the network structure 
using a simple graph-theoretic criterion. 
 
Advantages of Bayesian Networks Over Other Representations 
Over the past few years, Bayesian networks have become the de-facto tool of choice for 
dealing with uncertainty in knowledge based systems.  One very attractive feature of 
Bayesian networks is their ability to compactly encode joint probability distributions.  In 
addition to precisely definish the conditional distributions that constitute the joint 
distribution by means of an underlying graphical structure. 
 
The graphical structure of the Bayesian network greatly enhances the understandability of 
the model, as various relationships between the domain attributes can be simply read off 
the structure.  It is primarily this graphical structure which has made Bayesian networks 
so popular, as it can encode the causal structure of the domain being modeled.  Te ease of 
understandability of Bayesian networks is one big advantage over representations such as 
neural networks which are notoriously difficult, if not impossible to comprehend. 

 
44
 
Another major advantage of Bayesian networks is the ability to incorporate prior 
knowledge.  Prior knowledge, especially in the form of causal information, greatly 
simplifies the construction of the Bayesian network, and also enhances the 
understandability of the resultant model. 
 
Yet another advantage of Bayesian networks over most traditional approaches is their 
ability to naturally handle missing values.  As explained in Section 2.2, inference can be 
performed on Bayesian networks to update the posterior probability of any set of 
variables, given any other set of variables.  As such, it does not require every variable to 
be instantiated, and hence can easily handle missing values.  Perhaps the biggest 
advantage of Bayesian networks over other approaches is the effectiveness of their use as 
complex decision making models.  When augmented with decision and utility nodes, they 
can be easily used for decision making, such as deciding the best next action, etc. 
 
Data Categorization/Transformation 
 
Bayesian Belief Network technique requires that the continuous variables be descritized.  
There are several methods that could be used for categorization.  The following are four 
most common methods of data categorization. 
 
Equal Interval 
This classification scheme divides the range of attribute values into equal-sized subranges. 
For example, if features have attribute values ranging from 0 to 300 and you have three 
classes, each class represents a range of 100 with class ranges of 0–100, 101–200, and 
201–300. This method emphasizes the amount of an attribute value relative to other 
values.  Because there are usually fewer endpoints at the extremes, the numbers of values 
are less in the extreme classes. This option is useful to highlight changes in the extremes.  
 

 
45
Quantiles 
The range of possible values is divided into unequal-sized intervals so that the number of 
values is the same in each class. A quantile classification is well-suited to linearly 
distributed data. Because features are grouped by the number in each class, the resulting 
map can be misleading. Similar features can be placed in adjacent classes, or features 
with widely different values can be put in the same class. You can minimize this 
distortion by increasing the number of classes.  Classes at the extremes and middle have 
the same number of values. Because the intervals are generally wider at the extremes, this 
option is useful to highlight changes in the middle values of the distribution.  However, 
this method is not appropriate for Bayesian Belief Network technique because it 
automatically assigns equal probabilities for each category, hence hinders the 
contribution of the variable in prediction. 
 
Natural breaks 
Smart quantiles are used to delineate classes based on natural groupings of data values. 
Breakpoints are identified by looking for groupings and patterns inherent in the data. The 
features are divided into classes whose boundaries are set where there are relatively big 
jumps in the data values, so groups with similar values are placed in the same class. This 
is a compromise method between Equal Interval and Quantile, with unequal-sized 
intervals such as Quantile that generally get a bit wider at the extremes, but not so much 
as with the Quantile method, so there is also a decreasing number of values in the 
extreme classes. This option tries to find a balance between highlighting changes in the 
middle values and the exteme values. It is useful for datasets such as rainfall, which may 
have more than 50 percent of the records equal to zero. 
 
 
Standard deviation 
This classification scheme shows you the amount a feature's attribute value varies from 
the mean. The mean value is calculated and then generates class breaks by successively 
adding or subtracting the standard deviation from it. 
 

 
46
Among the methods discussed above, the natural break seems more suitable for 
descretizing continuous variables to be used by the Bayesian Belief Network model.  The 
equal interval does not address the determination of discriminatory thresholds.  Instead, it 
helps detect the behavior of the dataset in the extremes.  The quantile method is also not 
suitable for the Bayesian Belief Networks technique due to the fact that it divides the 
continuous data such that each class has the same number of records, hence equal 
probabilities for each event, which destroys the purpose of using conditional probabilities 
in the discriminatory function for predictions.  In the same token, standard deviation 
method is not suitable because it is more appropriate for normally distributed data. 

 
47
 
 
CHAPTER 3 
 
METHODOLOGY 
 
Overview 
 
A detailed search of literature on published and unpublished information about the use of 
GIS for safety analysis and highway safety modeling techniques was conducted.  The 
literature review resources including TRIS (Transportation Research Information 
Services), Inspect, NTIS (National Technical Information Services), General Science, 
Uncover, Wilson Applied Science & Technology, Digital Dissertation Abstracts Online, 
Cambridge Scientific Abstracts, and Science Direct Databases were used. It is 
worthwhile mentioning that most of the literatures used in the proposal stage were 
collected from the aforementioned sources. 
 
Data Collection 
 
Data collection is an important part of the research study.  There are different types of 
data collection techniques depending on type of study being conducted.  Different ways 
of collecting data include using archived data, designed experiment, survey, and 
observationally obtained data.  Due to the nature of the study, archived data sources were 
used.  Crash data is initially collected by police officers at the scene of the crash 
occurrence.  The local agencies send the crash data to the Florida Department of 
Highway Motor Vehicle (FDHMV) where the data is stored in a central repository 
database.  The data is then transmitted to the safety office of Florida Department of 
Transportation (FDOT) where it is amalgamated depending on the desired output. 
 

 
48
Four major databases were used – Crash Analysis Reporting (CAR), Roadway 
Characteristics Inventory (RCI) databases, GIS, and high crash segments databases, all 
maintained by FDOT.  Both databases are accessible through Cisco Virtual Private 
Network (VPN) Client service. VPN is a private network that is configured within a 
public network (a carrier's network or the Internet). VPNs are widely used by enterprises 
to create wide area networks (WANs) that span large geographic areas, to provide site-to-
site connections to branch offices and to allow mobile users to dial up their company 
LANs. 
 
CAR Database 
The Florida Department of Transportation uses and maintains a state mainframe database 
known as the Crash Analysis Reporting System (CAR).  The data can be queried and 
obtained in a flat comma delimited text file.  This database contains individual crash 
reports of all crashes that occurred on state maintained roadways.  Each record is 
identified by the DHSMV number.  The locations of the crashes are identified using the 
milepoint/milepost, the roadway ID of the roadway segment where the crash occurred, 
and begin and end milepost of the segments.  Attributes of the crash report together with 
other inventory data are associated to each crash. 
 
Crash data from CAR database for year 2002 was used.  Year 2002 crash data consists of 
a total of 140,861 records that occurred in state maintained roadways from the month of 
January through December in Florida.  Figure 17 shows geographical distribution of the 
crashes that occurred in state roadways in year 2002.  Figure 17 was created in ArcView 
software using roadway ID and located milepoint attributes of the crash database. 
 
RCI Database 
FDOT maintains an electronic inventory of the state highway system known as the 
Roadway Characteristics Inventory (RCI). The RCI is a computerized database of 
physical and administrative data related to the roadway networks that are maintained by 
or are of special interest to the Department. In addition to data required by the 
Department, the RCI contains other data as required for special Federal and State 

 
49
reporting obligations. The RCI is maintained by District and Central Office personnel. 
While there are other important databases maintained by the Department (several that 
contain more highly technical data such as bridge specifications, highway design, or 
pavement) the RCI remains the largest database with over one million records.  The 
database represents Florida’s road network indexed by data segments. Each data segment 
presents elements that describe that portion of the roadway in physical terms. RCI 
identifies the different roadway segments with a unique Roadway ID, with segments 
containing information on roadway Features, Characteristics and other data elements. 
 
The Florida Department of Transportation (FDOT)) is responsible for keeping current 
inventory of all its roadways. The Transportation Statistics Office (TSO) is their central 
clearinghouse and principal source for highway data collection and analysis. TSO gathers 
the majority of this data from field personnel in each of their eight districts. This highway 
infrastructure data contains the features, characteristics, and usage of highway facilities 
and services within the state and is contained in the Roadway Characteristics Inventory 
(RCI) database.  
 
The RCI system is composed of features containing one or more characteristics. For 
example, feature number 213 is Auxiliary Lanes. This feature contains three 
characteristics; lane type, number of lanes, and lane width. Each RCI Feature and its 
corresponding characteristics are listed in the RCI Handbook. The Handbook is 
distributed to each FDOT district to guide them in gathering the feature information for 
their roadways and entering the data into the RCI system. RCI data is recorded by a 
unique roadway identification number and uses a beginning milepost and ending milepost 
along the roadway to identify the location of the feature. The data format definitions of 
the variables contained in the RCI database are shown in Appendix A.  The description of 
several attributes of interest is also appended (Appendix B). 
 
 
 
 

 
50
Map of Crashes that Occured in the 
State Maintained Roadways in year 2002
µ
Legend
2002 crashes
state roads
 
Figure 17   A Map showing crash Occurrence on State Maintained Roadways for 
year 2002. 
 
 

 
51
GIS Database 
FDOT maintains GIS basemaps for all state maintained roads.  Each arc in the basemap 
contains information including the RCI roadway ID, begin milepoint, end milepoint, and 
road status; all of which are derived from RCI.  Also included on the routes is a field for 
the digitized length in miles.  This value is compared with the RCI length as part of the 
Quality Assurance (QA) process. 
 
The arcs are digitized on-screen using the 1999 USGS DOQQs and aerial photos.  Each 
arc is assigned a Roadway ID derived from RCI.  Once the arcs are attributed, a route is 
created from those arcs that comprise the roadway.  Each route is then attributed with 
more information from RCI, such as begin milepoint, end milepoint, and road status.  The 
linear accuracy of the basemap is approximately +/- 50 feet.  The tolerance required is the 
length difference between RCI and basemap to be within ¼ mile or 10% of the value.  
The RCI/GIS Basemap Checklist is utilized prior to final submission of the basemap to 
FDOT main office.   
 
High Crash Segments Database 
FDOT maintain another database called high crash segments database.  This database 
contains highway segments which are considered to have higher crash rate compared to 
other segments of similar characteristics.   
 
m
m
k
Rc
2
1
+
+
=
λ
λ
 
 
 
 
 
 
 
 
3.1 
where 
=
c
R
 critical crash rate for a particular location (crashes per million vehicles or crashes 
per million vehicle-miles, 
=
λ
average crash rate for all road locations of similar characteristics (crashes per 
million vehicles or million vehicle-miles), 

 
52
 
=
m
number of vehicles traversing a particular road section (millions of vehicle-miles) 
or number of vehicles entering a particular intersection (million vehicles) during the 
analysis period, and 
=
k
 probability factor determined by the level of statistical significance desired for 
c
R  
 
The first two terms in Equation 3.1 (also known as the Poisson rate quality formula) 
result from the normal approximation to the Poisson distribution.  The last term of the 
equation serves as a correction factor because the Poisson distribution is a discrete 
distribution, whereas the normal distribution is a continous distribution.  In order to 
create the high crash segments database, the roadway segments are analyzed in the 
increments of 0.3 mile and the value of k is computed for each segment.  Different 
criteria are used to decide on the high crash segments for rural, suburban and urban 
roadways.  For rural roadways, any 0.3 mile segment with the value of k > 95% is 
categorized as high crash segment, while for suburban and urban roadways roadways the 
computed value of k > 99% is used to classify high crash segments.  The value of k > 
99.95% is used to identify high crash segments for urban roadways. 
 
Attributes Selection 
 
Accurate prediction of crash occurrence depends on the collection and manipulation of 
crash data, including the choice of variables used in the model structure.  The variables to 
be used will be selected based on the knowledge of possible causes of crashes.  This 
included conducting a thorough literature review on the previous research studies on 
dependencies within response variables in crash models.  Intuitive engineering 
knowledge was also used to judge dependencies among variables.   
 
 
 
 

 
53
Model Selection 
 
Bayesian Belief Networks (BYNs) technique was used for crash prediction modeling. 
BYNs take advantage of the known dependencies among variables to construct the 
graphical presentation of the model.  The Bayesian Belief Networks theory is discussed 
by Duda (2001).  The basic idea in belief networks is that the problem domain is modeled 
as a set of nodes interconnected with arcs to form a directed acyclic graph. Each node 
represents a random variable, or uncertain quantity, which can take two or more possible 
values. The arcs signify the existence of direct influences between the linked variables, 
and the strength of each influence is quantified by a forward conditional probability.   
 
The belief networks were until recently a relatively obscure part of artificial intelligence 
(AI) with few commercial applications.  The use of belief networks in crash modeling is 
not reported in literature.  This is due to the fact that the technique is fairly new and this 
is the first attempt to explore the suitability of the method in crash modeling.    
 
Belief networks can be used wherever classical knowledge based systems might be used. 
Belief networks provide the following advantages, when compared with other modeling 
techniques: (1) a more modular representation of uncertain knowledge, which makes 
them easier to maintain and to adapt to different contexts and (2) a more intuitive 
knowledge representation (node and arc diagrams) for domain experts, making it easier 
for them to be involved in maintaining a system. Compared to neural networks, belief 
networks have the following advantages: (1) the expert can provide knowledge in the 
form of causal structures, (2) the network is understandable and extensible, and (3) they 
can be used easily with missing data. 
 
The modeling process is summarized in Figure 18.  Three main data sources were sought 
namely GIS (spatial database), Roadway Characteristics Inventory (RCI) database and 
Crash (CAR) Database.  Records were filtered to check for consistency in data format 
and eliminate incomplete and erroneous data.  Transformation (categorization of the 
continous variables) was then performed to produce a matrix of variables which was 

 
54
saved in a database format.  Bayesian Belief Networks technique was then used to model 
the crash data and the results were displayed in GIS.       
 
 
Figure 18  Modeling Process. 
 
Construction of the Bayesian Model 
 
The process of finding a suitable network structure could be challenging.  Simoncic 
(2005) used PowerConstructor to build a network structure when modeling two car 
crashes using Bayesian Network Model.  PowerConstructor (Cheng et al. 2001) is a 
computer program that can estimate the Bayesian Network structure if a database of cases 
is available.  Powerconstructor compares competent structures and chooses the best 
structure based on conditional independence tests.  The software is downloadable from 
the internet at http://www.cs.ualberta.ca/~jcheng/bnsoft.htm.  The data for this study was 
experimented within PowerConstructor to observe the resulting Bayesian Network.  The 
resulting model is shown in Figure 19.  The model obtained using PowerConstructor 
suggests that locality is the only factor that directly influences the number of crashes per 
year in a given roadway segment.  The model further indicates that pavement condition is 
GIS 
databases 
Roadway 
Characteristics 
Inventory (RCI) 
and Crash 
Database 
Classification 
Crash 
occurrence 
prediction 
Dataset for 
training and 
validation 
Filtering 
Data transformation 
Creating a matrix of variables 
Creating a vector of outputs 
Pattern 
Recognition 
GIS 
shapefiles 
attributes 
GIS software 
package 

 
55
an independent variable with no interdependency to any other variable.  The model also 
indicates that AADT is dependent on the number of lanes.   
 
Figure 19  The Resulting Model Using PowerConstructor. 
 
Although the algorithm of the PowerConstructor could not be obtained, clearly, the 
program learns the model structure from the data and does not include engineering 
judgment and knowledge from previous studies.  Since this kind of network is known as a 
“Belief Network”, it is important that the knowledge of transportation engineering with 
previous research be implemented in model construction. A simple hypothetical Bayesian 
networks model representing the relationship between crash occurrence and several 
factors is shown in Figure 20.  The figure consists of nodes and links.  Nodes correspond 
to different variables that are characteristic of the given domain under consideration.  
Links represent dependence between variables.  Figure 20 shows that number of crashes 
per year on a section of the road is dependent on several factors including traffic volume, 
pavement condition, number of lanes, posted maximum speed, geographical location, and 
section length.  There is interdependency between some factors.  The number of lanes 
depends on traffic volume; traffic volume is also influenced by geographical location – 
rural, urban or suburban. 

 
56
 
 
Figure 20  Proposed Bayesian Belief Network for Crash Prediction. 
 
Variables used in the Model 
 
Maximum Posted Speed 
The maximum posted speed is a speed posted on a speed limit sign to notify drivers of 
the maximum speed that is considered safe for favorable weather and visibility. It is 
intended to establish the standard in which normally cautious drivers can react safely to 
driving problems encountered on the roadway.  Properly set speed limits provide more 
uniform flow of traffic and appropriately balance risk and travel time, which results in the 
efficient use of the highway's capacity and less crashes. 
 
Maximum posted 
Speed, A 
Length, B 
Locality, F 
Surface 
width, E 
AADT, C 
Pavement 
condition, D 
Number of crashes 
per year, G 

 
57
87% of all crashes are mainly due to road user’s error, while 10% is attributed to 
imperfect roadway design and other environmental factors and 5% to vehicle defects 
(Lonero et al., 1995).  It is obvious that the increase in speed greatly increases perception 
distance (the distance traveled by the vehicle from the moment a stimulus is visible to the 
moment it is perceived by the driver) decision distance, braking distance, and physical 
impact of an accident on the body.  It is equally clear that high speed may compromise 
the control of the vehicle by the driver.  Clearly, the lower the speed limit, the lower the 
likelihood of crash occurrence. 
 
The Florida Legislature authorized the Florida Department of Transportation to establish 
speed limits on state highways up to the following maximums: 70 mph on Interstates, 65 
mph on a four-lane divided highway outside an urban area (with a population of 5,000 or 
more), and 60 mph on other state highways.  It is common traffic engineering knowledge 
that about 85 percent of all drivers travel at reasonably safe speeds for the various 
roadway conditions they encounter, regardless of speed limit signs.  This leaves 15 
percent of drivers who must be reminded of the maximum speed limit. This reminder 
must be coupled with meaningful enforcement. Based on this knowledge, a traffic 
engineering study is conducted to establish speed limits on the state highway. The 
Department uses the “85th percentile” method of determining appropriate and safe posted 
speed limits in conjunction with the maximum statute based speeds. This method is based 
on extensive nationally accepted studies and observations. By measuring the speed of 
hundreds of vehicles at various points along the roadway, traffic engineers are able to use 
data to determine a reasonable and safe maximum speed to post for all vehicles to travel. 
 
Pavement Condition 
The Condition Survey Unit conducts annual surveys of the entire State highway system 
in support of the Department's Pavement Management Program.  The data collected (in 

 
58
terms of crack, ride, and rut measurements) is used to assess the condition and 
performance of the State’s roadway as well as to predict future rehabilitation needs. 
 
This variable describes the pavement condition ratings and the type of surface put on the 
roadway. The ratings are presented from numbers 1 to 5 expressing pavement condition 
from weak condition to good condition. The judgment the pavement condition is done by 
an observer. By using AASHO Road Test PSR scores, an observer rides around the test 
tracks and rate their ride using the quantitative scale. This scale ranges from 5 (very good) 
to 0 (very poor). It generally reflects road roughness because roughness largely 
determines ride quality.  Descriptions of codes for pavement condition are shown in 
Table 3. 
 
Table 3  Pavement Condition Ratings 
Value 
Pavement Condition 
1.00-1.90 
Very poor; virtually impassable, 75% or more deteriorated 
2.00-2.90 
Poor, large potholes and deep cracks exist, discomfort even at slow speeds
3.00-3.90 
Fair, rutting, map cracking and extensive patching 
4.00-4.90 
Good, first class ride with only slight surface deterioration 
5.00 
Very good, only new or nearly new pavement 
 
Annual Average Daily Traffic (AADT) 
Hadi et al. (1995) found that sections with higher AADT levels are associated with 
higher crash frequencies for all highway types. Garber (2000) found that there is an 
increase in the crash rate as the flow per lane increased. Mouskos et al. (1999) found that 
as AADT increases the crash rate also increases. Milton and Mannering (1998) found the 
positive coefficients of AADT in the model indicating that as the number of vehicles 
through a section increases, so does the number of accidents. He explained that as the 
number of vehicles increases through a section, the exposure to potential accidents and 
number of conflicts increases. The same finding about the effect of AADT on crash rates 
was also found by Aruldhas (1998), Sawalha (2003) and Poch and Mannering (1996). 

 
59
 
Data Reduction 
 
Data extracted from the CARS, RCI and GIS database come in different formats.  Data 
from CARS database for example is in the comma delimited format with 76 attributes.  
The attributes found in CARS database are shown in Appendix C.  Crash occurrence 
based on roadway segments were extracted for each type of highway facility and then 
amalgamated using SQL computer code (Appendix D).  On the other hand RCI database 
has 123 attributes.  Data definition for each of the attributes is appended (Appendix A).  
It should be noted that statewide RCI data contains more than 100,000 records in text 
format.  The amount of data excludes the possibility of using software packages such as 
Excel in data processing because Microsoft Excel handles only 65,000 records.  CARS 
data was amalgamated to form one database which contains information about each 
individual crash, i.e., the location it occurred, with a few geometric, traffic and 
environmental conditions at the time of the crash. 
 
RCI dataset was imported into Microsoft Access where it was joined with CAR database.  
A standard SQL code was written to merge the two databases and calculate the number of 
crashes for each road segment.  The code is shown in Appendix D.  The merged database 
has all the fields from RCI database and the new field – number of crashes for each road 
segment which was formed by summing up crashes that occurred on each roadway 
segment based on roadway ID and the begin and end points. 
 
The next step of data reduction was filtering the data.  The original RCI database 
contained 227,250 records while the CAR database had 140,861 records.  A dataset was 
reduced to fields that are contained the model.  The data was futher filtered to eliminate 
the records with incomplete data.  It was also noticed that the dataset had records with the 
roadway segment lengths of as short as 0.00 mile.  Only the records with at the length of 
at least 0.041 mile were used for the analysis.  The resulting database had 44,182 records.       
 

 
60
Dynamic Segmentation 
 
Literature suggests that dynamic segmentation is the key to effective linking of 
transportation facilities to GIS (Waite and Rocco 1998).  Dynamic segmentation allows 
the user to represent events without modifying the linear feature at all.  Cadkin (2002) 
defined dynamic segmentation as the process of transforming linearly referenced data 
(commonly called events) stored in a table into a feature that can be displayed on a map 
(Figure 21).  Cadkin mentions two data requirements for performing dynamic 
segmentation.  First, each event in an event table must include an identifier and its 
measurement along a linear feature.  Second, each linear feature must have a unique 
identifier and a measurement system stored with it.  Pavement management provides an 
excellent example, with events such as widths, conditions, and the numbers of lanes 
found at different locations along a road. The linear feature representing the road would 
have to be broken into many segments in the GIS to accurately represent these events and 
then continuously segmented as changes occur with the pavement.  It should be noted 
that the procedure that was undertaken using SQL code could be done using dynamic 
segmentation.  
 
Data Categorization/Transformation 
 
Transformation of the attributes was performed due to the fact that the data are not all in 
one format.  While some attributes are nominal data (e.g. urban/rural/suburban), some 
data are continuous (e.g., pavement condition and AADT).  The transformation is 
necessary to categorize the attribute data in different ranges.  The final product of the data 
reduction process is the set of attributes in different categories.  The natural breaks 
method was used to create the initial categorization thresholds.  Trial and error method 
was used to adjust the number of categories and the thresholds until the highest prediction 
accuracy was reached. 
 

 
61
 
 
Figure 21  An Example of Dynamic Segmentation Data (Cadkin, 2002). 
 
Data Analysis 
 
Data analysis involved computation of unconditional and conditional probabilities, 
likelihood of each event given a set of model variables, prior, and posterior probabilities.  
As discussed earlier, Bayesian Belief Networks prediction method uses the posterior 
probabilities as a means of choosing the output category given several variable values.  
The method for computing posterior probabilities is discussed next. 
  
Computation Method 
Prediction in Bayesian Belief Network technique is based on the classical Bayes classifier, 
which statistically is an optimal classifier that seeks to minimize the risk of 
misclassifications.  The Bayesian computational method is well explained by Duda et. al 
(2000).  Any pattern classifier places each observed vector of data x in one of the 
predefined classes ωi; i = 1,2,…n where n is the number of possible classes in which x 

 
62
can belong.  The effectiveness of many classifiers is limited by the number of data 
elements that vector x can accomodate and the number of possible classes n.  The 
classical Bayes pattern classifier implements the Bayes conditional probability rule that 
the probability P(ωi/x) of x being in class ωi is given by  
 
)
(
)
(
)
/
(
)
x
/
(
ω
ω
ω
P
c
P
c
P
P
i
i
i
=
     
 
 
 
 
 
3.1                                     
 
where P(x/ωi) is the conditional probability of x given set ωi, P(ωi) is the probability of 
drawing data from category ωj and 
∑=
=
n
j
j
j P
P
P
1
)
(
)
/
x
(
)
(
ω
ω
ω
.  Vector x is said 
to belong to a particular category ωi if it has the highest conditional probability of being 
in this category than in other categories, i.e., P(ωi/x) > P(ωj/x).  This classifier assumes 
that the probability density function of the population from which the data were drawn is 
known a priori—this is one of the major limitations of implementing the Bayes classifier.   
 
Bayes formula can be expressed informally in English by saying that 
 
.
evidence
prior
likelihood
Posterior
×
=
 
 
 
 
 
 
3.2 
 
Bayes formula shows that by observing the value of x we can convert the prior 
probability 
)
(
j
w
P
to the a posteriori probability (or posterior) 
)
|
(
x
w
P
j
 - the 
probability of the state of nature being 
j
w  given that feature value x has been measured.  
We call 
)
|
(
j
w
x
P
the likelihood of 
j
w  with respect to x, a term chosen to indicate that, 
other things being equal, the category 
j
w  for which 
)
|
(
j
w
x
P
 is large is more likely 
to be the true category.  Notice that it is the product of the likelihood and the prior 
probability that is most important in determining the posterior probability.  The evidence 

 
63
factor, 
)
(x
P
with x can be viewed as merely a scale factor that guarantees that the 
posterior probabilities sum to one. 
 
Suppose we have two categories.  If we have an observation x for which 
)
|
(
1 x
w
P
 is 
greater than 
)
|
(
2 x
w
P
, we would naturally be inclined to decide that the crash category 
is 
1
w .  Conversely, if 
)
|
(
2 x
w
P
 is greater than 
)
|
(
1 x
w
P
, we would be inclined to 
choose 
2
w .  Input x is therefore classified by the label corresponding to the maximum 
posterior.  To classify an input x as being in class ci, the multicategory classifier decision 
requires the following condition to be satisfied: 
)
(
)
/
x
(
)
(
)
/
x
(
j
j
i
i
c
P
c
P
c
P
c
P
>
  
 
 
 
 
 
3.3                                     
 
Model Validation 
 
The Bayesian Belief Network model was validated using the cross validation technique.  
In this method a training set is divided into two sets – an estimation set (which is used to 
estimate probability models) and a validation set (which is used to evaluate the 
performance of the estimated probability models).  Cross validation helps in comparing 
the performance of the chosen models on the test/training set.   

 
64
 
 
CHAPTER 4 
 
 
ANALYSIS OF RESULTS 
 
 
Overview 
 
As mentioned earlier, six categories were used in modeling – maximum posted speed, 
section length, section AADT, Pavement Condition, Locality, and number of lanes.  The 
final attribute categories that were used for modeling are shown in Table 4.  GIS maps 
showing category distributions of each variable are shown in Figures 22 to 28.  The 
proportions of each category are discussed next. 
 
Table 4  Attribute Categorization 
Attribute 
Range 
Category 
≤ 45 
1 
Speed (mph)/A 
> 45 
2 
0.041 – 0.15 
1 
0.151 – 0.4 
2 
Segment length (miles)/B 
>0.4  
3 
< 40,000 
1 
40,000 – 60,000 
2 
Section AADT/C 
> 60,000 
3 
0 – 3.5 
1 
3.51 – 4.5 
2 
Pavement condition/D 
> 4.5 
3 
 
 
 
 

 
65
Table 4 (continued) 
<30 
1 
30 - 33 
2 
Surface width (feet)/E 
>33 
3 
Rural 
1 
Suburban 
2 
Locality/F 
Urban 
3 
= 0 for subset 1, and ≤ 15 
for subset 2  
1 
Number of crashes per 
year/G 
> 0 for subset 1, and > 15 
for subset 2 
2 
 
 
Figure 22  Map Showing Speed Categories. 

 
66
 
 
Figure 23  Map Showing Roadway Length Categories.

 
67
 
 
 
Figure 24  Map Showing Pavement Condition Categories. 
 

 
68
 
Figure 25  Map Showing AADT Categories.

 
69
 
Figure 26  Map Showing Categorized Locality. 

 
70
 
 
Figure 27  Map Showing Lane Categories. 

 
71
 
Figure 28  Map Showing Crash Categories. 
 
 
Maximum Posted Speed 
The maximum posted limits were divided into four categories.  As shown in Table 5, 
category 1 covers roadways with speed limit lower or equal to 25 mph while category 2 
contain roadways with speed limits ranging from 25 to 35 miles per hour.  Categories 3 

 
72
and 4 cover roadways with posted speed limits of 35 to 45 mph and above 45 mph, 
respectively.  The individual probabilities of each category are shown in the last column 
of Table 5.  
 
Table 5  Maximum Posted Speed Categories 
Category 
Range 
Probabilities 
1 
0 - 25 
0.00138 
2 
25 - 35 
0.0717 
3 
35  - 45 
0.24271 
4 
> 45 
0.684235 
 
Section Length 
The lengths of the roadway segments were divided in three categories.  The first 
categories contained lengths of 0.05 to 0.15 mile while the second and third categories 
comprised of ranges of 0.15 to 0.4 mile and above 0.4 mile.  The proportion of each 
length category in the dataset is shown in Table 6. 
 
Table 6  Section Length Categories 
Category 
Range 
Probabilities 
1 
0.05 - (0.15) 
0.677321 
2 
(0.15) - (0.4) 
0.214382 
3 
> (0.4) 
0.108297 
 
Section AADT 
Traffic volume (Annual Average Daily Traffic) data in the state maintained roadways 
was found to range between 250 to 142,500 vehicles per day.  Sections with AADTS less 
than 40,000 were placed in category one while sections with AADT between 40,000 to 
60,000 were placed in category two.  Sections with AADT higher than 60,000 vehicles 
were placed in category three.  Table 7 shows the proportions of each AADT category. 

 
73
 
Table 7  Annual Average Daily Traffic Categories 
Category 
Range 
Probabilities
1 
< 40000 
0.903951 
2 
40000 - 60000 
0.0623 
3 
> 60000 
0.0337 
 
Pavement Condition 
Pavement condition is rated by nominal values ranging from 1 to 5, reflecting the 
roughness of the road surface.  While the rating of 1.0 represents very poor (almost 
impassable road), the rating of 5.0 stands for very good, basically new or nearly new 
pavement.  Table 8 shows the pavement condition categories with their respective 
proportions. 
 
Table 8  Pavement Condition Categories 
Category 
Range 
Probabilities
1 
1-3.5 
0.413987 
2 
3.5-4.5 
0.476847 
3 
>4.5 
0.109166 
 
 
Locality 
Highway locality is represented as urban (U), suburban (S), or rural (R) depending on 
design and location.  A roadway is considered to be urban if its outside shoulder is curb 
and gutter.  Highways with open drainage inside city limit and urban areas are considered 
as sub-urban.  On the other hand, roadways with open drainage design outside the city 
and urban areas are considered as rural.  Table 9 shows the proportion of each roadway 
locality.   
 

 
74
Table 9  Locality Categories 
Category 
Locality 
Probabilities
R 
Rural 
0.55326 
S 
Sub-urban 
0.267207 
U 
Urban 
0.179534 
 
 
Number of Lanes 
The roadways with the maximum of six lanes were considered in this study.  The data 
was divided in six categories, each category representing the number of lanes.  Table 10 
shows the proportion of each lane category.   
 
Table 10  Number of Lanes Categories 
Category 
Probabilities 
1 
0.000435 
2 
0.517384 
3 
0.0118 
4 
0.369854 
5 
0.00593 
6 
0.0946 
 
 
Number of Crashes 
The output variable in this model was the number of crashes per year at each road 
segment.  Two crash categories were formed.  Category one consisted of segments that 
did not have crashes while category two represented segments that had at least one crash 
occurrence per year.  Table 11 shows the proportion of each crash category in the dataset. 
 
 

 
75
 
Table 11  Number of Crashes Categories    
Category 
Number of crashes 
Probabilities
1 
0 
0.648979 
2 
>=1 
0.351021 
 
Conditional Probabilities 
 
A Bayesian Belief Network (BBN) defines various variables, the dependencies between 
them, and the conditional probabilities involved in those dependencies. A BBN can use 
this information to calculate the probabilities of various possible causes being the actual 
cause of an event.  Conditional probabilities were computed based on the dependencies 
expressed in the Bayesian Belief Network Model presented in Figure 29.  It can be 
depicted from the model that there are four nodes that need conditional probability 
computation.  These are nodes C, D, E, and G. 
 
Node D: Pavement Condition and AADT 
Pavement condition at a certain road section was assumed to be partially influenced by 
the amount of traffic passing that section. Conditional probabilities for pavement 
condition (D) and AADT (C) were computed using the equation below.  The conditional 
probabilities for pavement condition (D) and AADT (D) are summarized in Table 12. 
)
(
)
(
)
|
(
C
P
D
and
C
P
C
D
P
=
  
 
 
 
 
 
 
(4.1) 
where, 
)
|
(
).
(
)
(
C
D
P
C
P
DandC
P
=
  
 
 
 
 
 
(4.2) 
 

 
76
 
Figure 29  Bayesian Belief Network for Statewide Analysis. 
 
 
Table 12  Conditional Probability Table for Pavement Condition (D) given AADT 
(C) 
 
P(D1/C) 
P(D2/C) 
P(D3/C) 
C1 
0.435018 
0.461492 
0.10349 
C2 
0.319038 
0.588912 
9.21E-02 
C3 
0.120482 
0.608434 
0.271084 
 
Node E: Number of Lanes and AADT 
It was assumed that the number of lanes in the highway is influenced by AADT among 
other factors.  Dependency relationship between the number of lanes and AADT was 
quantified by using the conditional probabilities that were computed using the equation 
below.  Table 13 presents the summary of the conditional probabilities for number of 
lanes and AADT. 
 
Maximum posted 
Speed, A 
Length, B 
Locality, F 
AADT, C 
Pavement 
condition, D 
Number of crashes 
per year, G 
Number of 
lanes, E 

 
77
  
)
(
)
(
)
|
(
C
P
CandF
P
C
F
P
=
  
 
 
 
 
 
 
(4.3) 
where, 
)
|
(
).
(
)
(
C
F
P
C
P
FandC
P
=
  
 
 
 
 
 
(4.4) 
 
Table 13  Conditional Probability Table for Number of Lanes (F) given AADT (C) 
 
P(F1/C) 
P(F2/C) 
P(F3/C) 
P(F4/C) 
P(F5/C) 
P(F6/C) 
C1 
3.24E-04 
0.604462 
1.35E-02 
0.339674 
3.33E-03 
3.87E-02 
C2 
0 
2.09E-03 
6.28E-03 
0.404812 
3.24E-02 
0.554393 
C3 
0 
0 
0 
6.02E-03 
2.41E-02 
0.96988 
 
Node C:  AADT and Locality 
It was also assumed that traffic volume is influenced by the locality of the highway 
section.  Typically urban highways have higher traffic than sub-urban highways.  
Likewise, sub-urban highways have generally higher traffic than rural highways.  The 
conditional probabilities of AADT given locality were computed using the equation 
below.  Conditional probabilities of AADT given locality are presented in Table 14. 
  
)
(
)
(
)
|
(
E
P
EandC
P
E
C
P
=
  
 
 
 
 
 
 
(4.5) 
where, 
)
|
(
).
(
)
(
E
C
P
E
P
CandE
P
=
 
 
 
 
 
 
 
(4.6) 
 
Table 14  Conditional Probability Table for AADT (C) given Locality (E) 
 
P(C1/E) 
P(C2/E) 
P(C3/E) 
C1 
0.993023 
6.98E-03 
0 
C2 
0.912692 
6.82E-02 
1.91E-02 
C3 
0.881375 
0.106268 
1.24E-02 
 

 
78
Node G: Number of Crashes and Maximum Speed Limit, Length, Locality, Number 
of Lanes, Pavement Condition 
Number of crash was the output variable.  The Bayesian model indicates that the number 
of crashes is directly influenced by five variables namely, maximum speed limit, length, 
locality, number of lanes, and pavement condition.  The conditional probabilities of node 
G were not shown in the table due to the length of the probability table. 
 
)
(
)
(
)
,
,
,
,
|
(
E
P
ndEandF
AandBandDa
P
F
E
D
B
A
G
P
=
 
 
 
(4.7) 
Where, 
)
,
,
,
|
(
.
)
|
(
).
|
(
).
|
(
).
(
).
(
).
(
)
(
E
D
B
A
G
P
C
D
P
F
C
P
C
E
P
F
P
B
P
A
P
ndEandF
AandBandDa
P
=
 (4.8) 
 
Prediction Accuracy 
The prediction accuracy of 68% was observed.  This accuracy is higher than the one 
reported by Chong et al. (2004) who investigated the performance of neural networks and 
decision trees applied to predict driver’s injury severity in head-on front impact point 
collisions.  Different class accuracies reported by Chong et al. (2004) are 60.54%, 
57.58%, and 56.8% for no injury, possible injury and non-incapacitating classes, 
respectively.  The prediction accuracy of 68% is also higher than the accuracy obtained 
by using decision tree method in the same study (Chong et al., 2004).  Chong et al. (2004) 
reported the accuracies of 67.54%, 64.40%, and 60.37% for no injury, possible injury and 
non-incapacitating crashes, respectively.  
 
After modeling crashes using statewide data for all roadway facilities, a specific analysis 
using only 6 lane highways categorized as high crash segments was done.  This was done 
in order to determine the influence of high proportion of zeros in the dataset.  High crash 
segments contain highway sections with at least one crash per year.  The following 
sections describe the analysis of six lane highways categorized as high crash segments. 

 
79
Modeling of Crashes that Occurred in Six Lane Highways 
 
Probabilities for each node of the Bayesian Belief Network were computed based on the 
frequencies of each category for all variables.  It should be noted that only the 
independent variables have individual probabilities, i.e., probabilities of having each 
category of independent variables in the dataset.  According to the model (Figure 20), 
three variables i.e., maximum posted speed limit, segment length, and locality were 
assumed to be independent of others.  Their probabilities are shown in Table 15.   
 
Table 15  Probabilities of Independent Variables 
Category P(A) 
P(B) 
P(F) 
1 
0.902535658 
0.5 
1.58E-03 
2 
0.0975 
0.315372425
0.176704 
3 
- 
0.184627575
0.821712 
 
Two variables – AADT and surface width were assumed to be statistically dependent on 
the locality – whether the road segment is in the urban, suburban or rural area.  According 
to the Bayesian network technique, conditional probabilities need to be used instead of 
individual variable probabilities.  The conditional probabilities for nodes E and C are 
shown in Table 16. 
 
Table 16  Conditional Probabilities for Nodes E and C 
 
P(E1/F) 
P(E2/F) 
P(E3/F) 
 
 
P(C1/F) 
P(C2/F) 
P(C3/F) 
F1 
1 
0 
0 
 
F1 
1 
0 
0 
F2 
0.156951 
8.97E-03 
0.8340807 
 
F2 
0.41704 
0.363229 
0.2197309 
F3 
0.116683 
0.313404 
0.5699132 
 
F3 
0.321119 
0.477338 
0.2015429 
 
Pavement condition was assumed to be dependent on AADT.  The roughness of the 
pavement is influenced by the amount of vehicles using the road.  As the traffic volume 

 
80
increases pavement deterioration is expected to be higher.  The conditional probabilities 
of the pavement condition given AADT are shown in Table 17. 
 
Table 17  Conditional Probability Table for Pavement Condition given AADT 
 
P(D1/C) 
P(D2/C) 
P(D3/C) 
C1 
0.579439 
0.28972 
0.1308411 
C2 
0.526042 
0.345486 
0.1284722 
C3 
0.445736 
0.430233 
0.124031 
 
The output variable in this model is the number of crashes per year.  In this model the 
number of crashes per year is assumed to be influenced by the posted speed limit, 
pavement condition, traffic volume, section length, and surface width.  The conditional 
probabilities of the number of crashes given the aforementioned variables are depicted in 
Table 18. 
 
Predictions 
 
Predictions of each roadway segment were computed based on the values of model 
variables in each record of the testing dataset.  Consider a sample record with the model 
variables shown in Table 18.  The first column shows the variables considered in the 
model while the second column shows the value from the RCI database.  The third 
variable depicts the category of each variable obtained at the final discretization stage. 
 
The conditional and unconditional probabilities were extracted from Figure 30 based on 
the values of categories for each variable indicated in Table 18.  The conditional and 
unconditional probabilities were then used to compute the likelihood of the prediction to 
be category 1or 2.   The likelihood of crash category 1 was computed as: 
 
P(x/ ω1)= P(A) ) × P(B) × P(F) × P( E/F)  × P( C/F)  × P( D/C) × P(G1/ABECD) 
P(x/ ω1)= 0.902 × 0.5 × 0.82 × 0.313 × 0.477 × 0.345 × 0.75  = 0.14286 

 
81
 
One the other hand, the likelihood of category 2 was computed as: 
P(x/ ω2)= P(A) ) × P(B) × P(F) × P( E/F)  × P( C/F)  × P( D/C) × P(G2/ABECD) 
P(x/ ω2)= 0.902 × 0.5 × 0.82 × 0.313 × 0.477 × 0.345 × 0.25  =  0.00476 
 
Table 18  A Sample Record for Illustrating Prediction Procedure 
Variable 
Value 
Category 
Maximum posted speed 
40 mph 
1 
Length 
0.07 mile 
1 
Locality 
Urban 
3 
Surface width 
32 feet 
2 
AADT 
45,000 
2 
Pavement Condition 
3.90 
2 
 
 
Figure 30  Probability Tables for Each Node in the Model 
 
The final computation stage is the determination of posterior probabilities for the crash 
categories.  Posterior probabilities for crash category 1 (ω1) and crash category 2 (ω2) 
were computed as: 

 
82
 
P(ω1/x)= [P(x/ ω1) × P(ω1)] ÷ [P(x/ ω1)+ P(x/ ω2)]   
P(ω2/x)= [P(x/ ω2) × P(ω2)] ÷ [P(x/ ω1)+ P(x/ ω2)] 
Where P(ω1)= P(G1)= 0.737 and P(ω2)= P(G2)= 0.262 
 
Therefore 
P(ω1/x)= [0. 14286×0.737] ÷ [0.01052+ 0.00124] = 0.8945 
P(ω2/x)= [0. 00476×0. 262]÷ [0.01052+ 0.00124] = 0.1055 
 
According to the Bayesian Network technique, the category with the maximum 
probability is assigned the label, i.e., is taken as the prediction.  Since P(ω1/x)> P(ω2/x), 
the prediction is crash category 1. 
 
 
 
 
 
 
A subset of the dataset (1200 records) was used for training while the entire dataset, i.e., 
2,430 records was used for testing the model.  The model yielded the accuracy of 78%.  
The obtained accuracy is higher than the multilayer perceptron (MLP) model proposed by 
Abdelwahab and Abdel-Aty for prediction of driver injury severity in traffic crashes at 
signalized intersections (Abdelwahab, 2001).  Abdelwahab and Abdel-Aty reported the 
accuracy of 65.6 and 60.4 percent for MLP neural network in training and testing phases, 
respectively.  The accuracy observed is slightly lower than that observed by Nukoolkit et 
al. (Nukoolkit, 2001) of 81% by using the combination of distance function with decision 
tree clustering.  However, models proposed by other studies were for prediction of injury 
or non-injury outcome of crashes.  
 
Sensitivity Analysis 
 
Sensitivity analysis is an investigation of how the performance of the model varies along 
with changes in either output or input variables.  The analysis is aimed at determining the 
response of the output of the model.  Good modeling practice requires that the modeler 
provides an evaluation of the confidence in the model by assessing the trend of the model 

 
83
accuracy with the change of a single or more variables.  In this case the threshold of one 
variable – crash category was varied to study the influence of the crash category 
threshold in the model.  Crash database for six lane highways was used for sensitivity 
analysis.  Two datasets were used – the whole database (2,432 records) and a subset of 
1,200 records. 
 
Sensitivity analysis was performed by changing the number of thresholds of the model 
variables.  The thresholds for the sensitivity analysis were created by using the natural 
breaks method of discretization.  Figure 31 was created by varying the number of 
categories of the maximum posted speed variable from 5 categories to 2 Categories. The 
data (Table 19) indicate that there was an increase of the prediction accuracy as the 
number of categories of the maximum posted speed variable as the number of categories 
increase from 2 to 5 with an exception of 3 categories at which the prediction accuracy 
decreased to 47.92%.   
 
Table 19  Maximum Posted Speed Limit Thresholds 
Threshold (mph) Number of Categories 
Prediction Accuracy 
[15,35,40,45] 
5
77.17% 
[35,40,45] 
4
47.92% 
[35,45] 
3
76.58% 
[40] 
2
76.17% 
 
While the data indicated an increase in the prediction accuracy with the increase in the 
number of categories, a different trend for the traffic volume (AADT) was observed 
(Figure 32).  The relatively low prediction accuracy (50.17%) was observed with 5 
categories (Table 20).  The prediction accuracy improved as the number of categories of 
the AADT was increased.     
 
 

 
84
40.00%
45.00%
50.00%
55.00%
60.00%
65.00%
70.00%
75.00%
80.00%
0
1
2
3
4
5
6
Number of Categories (Maximum Posted Speed)
Prediction Accuracy (%
 
Figure 31  Prediction Accuracy Versus Number of Categories for Maximum Posted 
Speed. 
 
 
Table 20  Average Annual Daily Traffic 9AADT) Thresholds 
Thresholds 
Number of Categories 
Prediction Accuracy 
[30500,42000,56000,74500] 
5
50.17%
[34500,47500,62000] 
4
76.17%
[37000,58000] 
3
77.17%
[52000] 
2
77.00%
 

 
85
40.00%
45.00%
50.00%
55.00%
60.00%
65.00%
70.00%
75.00%
80.00%
0
1
2
3
4
5
6
Number of Categories (AADT)
Prediction Accuracy (%)
 
Figure 32  Prediction Accuracy Versus Number of Categories for AADT. 
 
The trend for the pavement condition was different from the trend observed for the 
maximum posted speed and AADT.  The accuracy increased as the number of categories 
increased from 2 to 3 and then decreased when 4 categories for the pavement condition 
variable were used (Table 21).  It should be noted that there were no big jumps of the 
prediction accuracy as the number of categories were changed from 2 to 4 (Figure 33).  
The data distribution did not allow having 5 categories.   
 
Table 21  Average Annual Daily Traffic (AADT) Thresholds 
Thresholds 
Number of Categories 
Prediction Accuracy 
[3.13,3.72,4.32] 
4
77.92% 
[3.35,4.25] 
3
78.17% 
[3.70] 
2
76.92% 
 
 

 
86
 
40.00%
45.00%
50.00%
55.00%
60.00%
65.00%
70.00%
75.00%
80.00%
85.00%
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
Number of Categories (Pavement Condition)
Prediction Accuracy (%)
 
Figure 33  Prediction Accuracy Versus Number of Categories for Pavement 
Condition. 
 
Another level that was investigated was segment length.  It was observed that the 
accuracy increased with the increase in the number of categories of the segment length 
variable (Figure 34).  Table 22 shows that the accuracy increased from 71.92% to 76.67% 
as the categories were changed from 2 to 5 categories, respectively.  It is possible that 
there were loss of information as the number of the categories were decreased which 
might have attributed to the decrease in the prediction accuracy.      
 
Table 22  Segment Length Thresholds 
Thresholds 
Number of Categories 
Prediction Accuracy 
[0.19,0.42,0.77,1.42] 
5
76.67% 
[0.24,0.59,1.20] 
4
76.58% 
[0.32,0.87] 
3
76.17% 
[0.53,3.28] 
3
76.08% 

 
87
[3.28] 
2
71.92% 
 
71.00%
72.00%
73.00%
74.00%
75.00%
76.00%
77.00%
0
1
2
3
4
5
6
Number of Categories (Segment Length)
Prediction Accuracy (%)
 
Figure 34  Prediction Accuracy Versus Number of Categories for Segment Length. 
 
The last part of the sensitivity analysis was done by taking an equal number of categories 
for each of the variables that were investigated.  It should be noted that two variables, i.e., 
number of lanes and locality were not varied.  The variables whose number of categories 
was varied are the posted maximum speed, AADT, pavement condition and segment 
length.  The upward trend of the prediction accuracy was observed with the increase in 
the number of categories, with a small drop at 4 categories value (Figure 35 and Table 
23).  While this trend may be data specific, it might also explain the concept of loss of 
information caused by transformation.  The fewer the number of categories the more 
information is expected to be lost.  However, further research is needed to investigate the 
behavior of the Bayesian Belief Networks as the number of categories and thresholds 
change. 
Table 22. Continued

 
88
 
Table 23  Prediction Accuracies Observed by Changing the Number of Categories 
for AADT, Maximum Posted Speed, Pavement Condition, and Segment Length 
Number of Categories 
Prediction Accuracy 
5 
76.67% 
4 
74.75% 
3 
76.50% 
2 
71.50% 
 
71.00%
72.00%
73.00%
74.00%
75.00%
76.00%
77.00%
0
1
2
3
4
5
6
Number of Categories
 
Figure 35  Prediction Accuracy Versus Number of Categories for Segment Length. 

 
89
 
 
CHAPTER 5 
 
CONCLUSIONS AND RECOMMENDATIONS 
 
Conclusions 
 
Overview 
The objective of this research was to investigate the use of pattern recognition technique 
and Geographic Information Systems in modeling highway crashes.  Pattern recognition 
techniques utilize the patterns of data to classify the data records based on the output 
variable using discriminatory functions.  One of the methods used for discrimination is 
Bayes theorem.  The method uses posterior probability as a means of classification.  
There are several pattern recognition techniques that use Bayes theorem.  In this 
particular study, Bayesian Belief Networks (BBN) technique was used.  The method 
utilizes conditional and prior probabilities to compute posterior probabilities which are 
used for prediction purposes.    
 
Model Accuracy 
The model was tested using crash data records for year 2002.  Two different datasets 
were used – six lane roadways and all roadways.  For six lane highways, validation of the 
model was done twice: (1) using the whole dataset (2) using cross validation.  For the 
first method, a subset of the dataset (1,200 records) was used for training while the entire 
dataset, i.e., 2,430 records were used for testing the model.  For the second method, a 
subset of 1200 records was used for training while the remaining records (1,230 records) 
were used for validation.  The model was also tested using crash data for all state 
maintained roadways in the state of Florida.  A total of 22,728 records were used for 
training while 21,454 records were used for validation. 
 

 
90
The model yielded the accuracy of 78% when using six lane highways data with 1,200 
records for training and 2,430 records for validation.  The accuracy of 76.25% was 
observed for the same dataset when only 1,230 records were used for validation.  The 
obtained accuracy is higher than the multilayer perceptron (MLP) model proposed by 
Abdelwahab and Abdel-Aty for prediction of driver injury severity in traffic crashes at 
signalized intersections (4).  Abdelwahab and Abdel-Aty reported the accuracy of 65.6 
and 60.4 percent for MLP neural network in training and testing phases, respectively.  
The accuracy observed is slightly lower than that observed by Nukoolkit et al. (8) of 81% 
by using the combination of distance function with decision tree clustering.  However, 
models proposed by other studies were for prediction of injury or non-injury outcome of 
crashes.   
 
The prediction accuracy of 68% was realized by using all types of roadways for the 
whole state.  While the accuracy is expected to increase with the increase in the sample 
size, there are several reasons that might have attributed to the decrease in accuracy for 
the analysis of statewide crash data for all types of roadways.  The first reason might be 
the number of roadway segments with zero number of crashes per year.  More than 50% 
of the dataset had zero number of crashes which means there were no crashes for year 
2002 in those road segments.  On the other hand, data for six lane roadways were 
extracted from the high crash segments dataset.  The road segments for six lane highways 
had at least one crash per year.  It is also possible that inclusion of different roadway 
types such as freeways and urban streets might have contributed to the reduction of the 
accuracy as compared to the results of the analysis for six lane highways.  This is because 
different types of roadways are expected to have varied levels of safety. 
 
Data Incompleteness and Inaccuracy 
While the database used contain a comprehensive roadway attributes, data 
incompleteness and inaccuracy were observed.  Some of the data that would be useful in 
modeling such as land use, horizontal degree of curve were incomplete.  Only a few 
records had complete roadway inventory data.  In addition, some data such as surface 
width was found to be inconsistent.  While the data were fairly accurate for six lane 

 
91
highways, examination of the surface width data for different number of lanes suggested 
that the surface width data were incorrect.  Surface width was thus used for modeling the 
dataset of six lane highways only.   
 
Loss of Information during Discretization 
In order to use the Bayesian Belief Network technique, continuous variables need to be 
discretized (categorized).  The discretization, or categorization of a continuous variable is 
the process by which a continuous variable is converted into a discrete, or categorical 
variable by grouping values into two or more categories.  In principle, the discretization 
of a continuous variable will result in some loss of information.  In this study, natural 
breaks univariate method was used as an initial discretization strategy followed by trial 
and error method until the highest prediction accuracy was observed.  It is possible that 
the use of multivariate discretization strategy would reduce the loss of information caused 
by categorization, hence improve the efficiency of the model.   
 
Strengths and weaknesses of Bayesian Belief Network method 
Crash occurrences are rare and complex events which makes modeling crashes difficult. 
Many modeling techniques ranging from simple regression methods to complex 
knowledge based methods have been used in previous studies for modeling safety data. 
No single method is without weaknesses.  Several advantages of the Bayesian Belief 
Networks have been discussed.  The graphical structure makes it easy to understand the 
model.  The use of conditional and unconditional probability makes the modeling 
exercise more realistic by limiting the influence of different factors that are known not to 
possess interdependability even if the correlation shows otherwise.  Although the model 
used in this study was simple and with only a few variables, relatively high prediction 
accuracy was observed.  It is expected that with the use of a comprehensive model 
construction technique, and a sophiscated categorization technique, a more efficient and 
accurate model could be designed which will lead to a revolution in highway safety 
modeling.  Two major disadvantages of BBN technique include the need of discretization 
of continuous variables and complexity in building the graphical model especially when 

 
92
considering many variables.  A list of strengths and weaknesses of Bayesian Belief 
Networks that were realized in this study are summarized in Table 24. 
 
Table 24  Strengths and Weaknesses of Bayesian Belief Networks 
Strengths 
Weaknesses 
Does not need to assume probability 
distribution 
Selection of the best network can be a 
complicated undertaking  
It can be easily understandable because it is 
a physical model 
Possibility of loss of information due to 
disretization 
It makes use of prior knowledge of model 
variable dependability instead of letting 
statistical software decide whether there is 
dependability of variables by learning from 
the data 
When many factors are involved, the 
complexity of the network model can be 
very difficult to construct 
 
Integration of Bayesian Networks with GIS 
One of the goals of this research was to integrate pattern recognition techniques with GIS.  
As part of the research, a stand alone GIS application was developed using MapObject 
2.2 and Visual Basic 6.0.  It should be noted that a computer program that was developed 
to analyze crash data by using the Bayesian Belief Network was also written in Visual 
Basic 6.0.  The GIS program that was created imports the results of the Bayesian Belief 
Network and spatially displays the results on a map.  The computer code that was written 
in VB 6.0 is appended (Appendix F).   
 
 
Recommendations 
 
Variable Discretization 
Despite the observed good performance of the proposed Bayesian Belief Networks, 
several drawbacks were realized.  The problem of the discretization of continous 

 
93
variables arises as an issue in Bayesian Belief Network technique because conditional 
probabilities are based on discete variables.  There is a possibility of loss of important 
information due to discretization.  It is recommended that better methods of discretization 
be studied and implemented to reduce the loss of information that might be caused by 
using simple categorization methods. 
 
Model Construction 
This study used a simple hypothetical model based on traffic engineering knowledge.  
While there are computer programs for Bayesian Model construction, the resulting model 
may not be realistic.  Further study is suggested to develop methods that can be used to 
construct Belief Networks by learning from data and including restrictions and prior 
knowledge. 
 
Recommendation for Use   
While the use of Bayesian Belief Network may pose a challenge without an efficient 
discretization method, it is possible that Bayesian Belief Networks would be more 
appropriate for modeling data extracted from crash data.  Crash report data consist of 
mainly categorical data.  Some of the data contained in the crash report that could be used 
in crash modeling include vehicle type, vehicle use, injury severity, sex, alcohol/drug use, 
and race.  Contributing causes, vehicle defect, vehicle movement, type of collision, 
lightning conditions, weather conditions, road conditions at time of crash, weather, and 
traffic control are among many other categorical data included in crash reports.  It is 
therefore suggested that the Bayesian Belief Network be tested for modeling crash report 
data because most of it is categorical. 
 
Model Limitations 
The model used in this research was simplistic and considered only a few variables.  
More variables need to be considered in order to formulate the physical model which is 
close to reality.  More geometric, traffic, demographic, and environmental variables need 
to be added in the model to reflect the real interaction of variables that cause crash 
occurance.  Figure 36 shows an example of a more comprehensive model that could be 

 
94
used to improve the results of this research.  However more data sources would need to 
be sought since some of the data are not contained in the databases that were used in this 
research. 
      
 
Figure 36  A Proposed Comprehensive Bayesian Belief Network Model 
Number of 
crashes, x 
ADT, f 
Population, g 
Number of lanes, e 
Speed 
limit, a 
Shoulder width, c
Rural/urban/suburban, b 
Section Length, h 
% trucks, l 
Land use, n 
Pavement condition, m 
Lane width, d 

 
95
APPENDIX A 
RCI DATA DEFINITION 
 
 
DATE:  06/02/2005 11:56:31    DATA ROLL-OFF FOR "FREEZE BREAKS" - 
MERGE FILES 
      ****************************************************************** 
      * DCLGEN TABLE(DB2REAL.RDWTBL31)                                 * 
      *        LIBRARY(APPROD.COPYLIB(RDWTBL31))                       * 
      *        ACTION(REPLACE)                                         * 
      *        LANGUAGE(COBOL)                                         * 
      *        NAMES(RDWTBL31-)                                        * 
      *        APOST                                                   * 
      *        COLSUFFIX(YES)                                          * 
      * ... IS THE DCLGEN COMMAND THAT MADE THE FOLLOWING 
STATEMENTS   * 
      ****************************************************************** 
           EXEC SQL DECLARE RDWTBL31 TABLE 
           ( CALYEAR                        CHAR(4) NOT NULL, 
             CONTYDOT                       CHAR(2) NOT NULL, 
             RDWYID                         CHAR(8) NOT NULL, 
             ONEUPSQ                        INTEGER NOT NULL, 
             BEGSECPT                       DECIMAL(6, 3) NOT NULL, 
             ENDSECPT                       DECIMAL(6, 3) NOT NULL, 
             DBTMTKRT                       CHAR(1) NOT NULL, 
             DESDEFRT                       CHAR(1) NOT NULL, 
             DESTRKRT                       CHAR(1) NOT NULL, 
             FAHWYSYS                       CHAR(1) NOT NULL, 
             TRKROUTE                       CHAR(20) NOT NULL, 
             LOCALNAM                       CHAR(20) NOT NULL, 
             ACCESS                         CHAR(2) NOT NULL, 
             RTESGNCD                       CHAR(1) NOT NULL, 
             TYPEROAD                       CHAR(1) NOT NULL, 
             FUNCLASS                       CHAR(2) NOT NULL, 
             RDACCESS                       CHAR(1) NOT NULL, 
             TOLLROAD                       CHAR(1) NOT NULL, 
             HWYLOCAL                       CHAR(1) NOT NULL, 
             PLACECD                        CHAR(4) NOT NULL, 
             URBAREA                        CHAR(4) NOT NULL, 
             URBSIZE                        CHAR(1) NOT NULL, 
             LANDUSE                        CHAR(1) NOT NULL, 
             NOLANES                        CHAR(2) NOT NULL, 
             SURWIDTH                       CHAR(3) NOT NULL, 
             SHLDTYPE                       CHAR(1) NOT NULL, 
             SHLDTYP2                       CHAR(1) NOT NULL, 

 
96
             SHLDTYP3                       CHAR(1) NOT NULL, 
             SLDWIDTH                       DECIMAL(3, 1) NOT NULL, 
             SHLDWTH2                       DECIMAL(3, 1) NOT NULL, 
             SHLDWTH3                       DECIMAL(3, 1) NOT NULL, 
             MEDWIDTH                       CHAR(3) NOT NULL, 
             RDMEDIAN                       CHAR(2) NOT NULL, 
             ISLDTYPE                       CHAR(1) NOT NULL, 
             ISLDTYP2                       CHAR(1) NOT NULL, 
             ISLDTYP3                       CHAR(1) NOT NULL, 
             ISLDWDTH                       DECIMAL(3, 1) NOT NULL, 
             ISLDWTH2                       DECIMAL(3, 1) NOT NULL, 
             ISLDWTH3                       DECIMAL(3, 1) NOT NULL, 
             BEARING                        CHAR(11) NOT NULL, 
             HRZDGCRV                       CHAR(6) NOT NULL, 
             SUPERELE                       DECIMAL(4, 4) NOT NULL, 
             PAVECOND                       DECIMAL(3, 2) NOT NULL, 
             SURFNUM                        CHAR(2) NOT NULL, 
             FRICTCSE                       CHAR(1) NOT NULL, 
             FRICTHK                        DECIMAL(3, 2) NOT NULL, 
             SURLAYNO                       CHAR(1) NOT NULL, 
             SURLAYCD                       CHAR(4) NOT NULL, 
             SURTHKNO                       CHAR(1) NOT NULL, 
             SURTHKCD                       DECIMAL(3, 2) NOT NULL, 
             BEGSECNM                       CHAR(20) NOT NULL, 
             ENDSECNM                       CHAR(20) NOT NULL, 
             NOLGTHI                        CHAR(3) NOT NULL, 
             NOLGTLO                        CHAR(3) NOT NULL, 
             LIGHTCDE                       CHAR(1) NOT NULL, 
             INTCMBCD                       CHAR(2) NOT NULL, 
             INTDIRX                        CHAR(9) NOT NULL, 
             DIVUNDIV                       CHAR(1) NOT NULL, 
             CRRATECD                       CHAR(2) NOT NULL, 
             URSUBRUR                       CHAR(1) NOT NULL, 
             INTSDRCD                       CHAR(1) NOT NULL, 
             INTSFTYC                       CHAR(1) NOT NULL, 
             RDINTSEC                       CHAR(2) NOT NULL, 
             CROSRDNM                       CHAR(20) NOT NULL, 
             EXITNO                         CHAR(4) NOT NULL, 
             INTERCHG                       CHAR(2) NOT NULL, 
             CHKDIGIT                       CHAR(1) NOT NULL, 
             RRCROSNO                       CHAR(6) NOT NULL, 
             STAIDNO                        CHAR(6) NOT NULL, 
             BOXCULNO                       CHAR(6) NOT NULL, 
             BRIDGENO                       CHAR(6) NOT NULL, 
             FACCROSS                       CHAR(20) NOT NULL, 
             UNDPASNO                       CHAR(6) NOT NULL, 

 
97
             AVGDFACT                       DECIMAL(4, 2) NOT NULL, 
             AVGKFACT                       DECIMAL(4, 2) NOT NULL, 
             AVGTFACT                       DECIMAL(4, 2) NOT NULL, 
             SECTADT                        CHAR(6) NOT NULL, 
             ACMANCLS                       CHAR(2) NOT NULL, 
             AUXLNTYP                       CHAR(1) NOT NULL, 
             AUXLNUM                        CHAR(1) NOT NULL, 
             AUXLNWTH                       DECIMAL(4, 2) NOT NULL, 
             SIDEWALK                       DECIMAL(4, 2) NOT NULL, 
             RDSIDTYP                       CHAR(2) NOT NULL, 
             LIGHTING                       CHAR(1) NOT NULL, 
             MAINBEG                        DECIMAL(6, 3) NOT NULL, 
             MAINEND                        DECIMAL(6, 3) NOT NULL, 
             SBSECTCD                       CHAR(2) NOT NULL, 
             ATTLOCCD                       CHAR(2) NOT NULL, 
             ATTYPECD                       CHAR(2) NOT NULL, 
             VEHDIRCD                       CHAR(2) NOT NULL, 
             MAXSPEED                       CHAR(3) NOT NULL, 
             MINSPEED                       CHAR(3) NOT NULL, 
             LMTRSTRC                       CHAR(1) NOT NULL, 
             TURNMOVE                       CHAR(2) NOT NULL, 
             TYPEPARK                       CHAR(1) NOT NULL, 
             SPDLIMIT                       CHAR(2) NOT NULL, 
             SIGNALNC                       CHAR(2) NOT NULL, 
             SIGNALTP                       CHAR(2) NOT NULL, 
             SIGNALTY                       CHAR(2) NOT NULL, 
             SCHLSPED                       CHAR(2) NOT NULL, 
             STATEXPT                       CHAR(2) NOT NULL, 
             NANLIGDT                       DATE NOT NULL, 
             NALIGNID                       CHAR(8) NOT NULL, 
             NALNBGPT                       DECIMAL(6, 3) NOT NULL, 
             NALNENPT                       DECIMAL(6, 3) NOT NULL, 
             OALIGNID                       CHAR(8) NOT NULL, 
             OALNBGPT                       DECIMAL(6, 3) NOT NULL, 
             OALNENPT                       DECIMAL(6, 3) NOT NULL, 
             PCGRADE                        DECIMAL(5, 4) NOT NULL, 
             VRTCRVDR                       CHAR(1) NOT NULL, 
             SPIRANGL                       CHAR(6) NOT NULL, 
             SPIROFF                        DECIMAL(4, 2) NOT NULL, 
             DTECRETE                       DATE NOT NULL, 
             RDWY_ACTV_ID                   CHAR(8) NOT NULL, 
             BEG_SECT_ACTV_NUM              DECIMAL(6, 3) NOT NULL, 
             END_SECT_ACTV_NUM              DECIMAL(6, 3) NOT NULL, 
             RDWY_INACTV_ID                 CHAR(8) NOT NULL, 
             BEG_SECTINACTV_NUM             DECIMAL(6, 3) NOT NULL, 
             END_SECTINACTV_NUM             DECIMAL(6, 3) NOT NULL, 

 
98
             RDWY_SECT_SYS_DT               DATE NOT NULL, 
             US_RTE_NUM_ID                  CHAR(8) NOT NULL, 
             ST_RD_NUM_ID                   CHAR(8) NOT NULL, 
             RDWYSUBSECTTYP_TXT             CHAR(1) NOT NULL 
           ) END-EXEC. 
      ****************************************************************** 
      * COBOL DECLARATION FOR TABLE DB2REAL.RDWTBL31                   * 
      ****************************************************************** 
       01  DCLRDWTBL31. 
      *                       CALYEAR 
           10 RDWTBL31-CALYEAR     PIC X(4). 
      *                       CONTYDOT 
           10 RDWTBL31-CONTYDOT    PIC X(2). 
      *                       RDWYID 
           10 RDWTBL31-RDWYID      PIC X(8). 
      *                       ONEUPSQ 
           10 RDWTBL31-ONEUPSQ     PIC S9(9) USAGE COMP. 
      *                       BEGSECPT 
           10 RDWTBL31-BEGSECPT    PIC S9(3)V9(3) USAGE COMP-3. 
      *                       ENDSECPT 
           10 RDWTBL31-ENDSECPT    PIC S9(3)V9(3) USAGE COMP-3. 
      *                       DBTMTKRT 
           10 RDWTBL31-DBTMTKRT    PIC X(1). 
      *                       DESDEFRT 
           10 RDWTBL31-DESDEFRT    PIC X(1). 
      *                       DESTRKRT 
           10 RDWTBL31-DESTRKRT    PIC X(1). 
      *                       FAHWYSYS 
           10 RDWTBL31-FAHWYSYS    PIC X(1). 
      *                       TRKROUTE 
           10 RDWTBL31-TRKROUTE    PIC X(20). 
      *                       LOCALNAM 
           10 RDWTBL31-LOCALNAM    PIC X(20). 
      *                       ACCESS 
           10 RDWTBL31-ACCESS      PIC X(2). 
      *                       RTESGNCD 
           10 RDWTBL31-RTESGNCD    PIC X(1). 
      *                       TYPEROAD 
           10 RDWTBL31-TYPEROAD    PIC X(1). 
      *                       FUNCLASS 
           10 RDWTBL31-FUNCLASS    PIC X(2). 
      *                       RDACCESS 
           10 RDWTBL31-RDACCESS    PIC X(1). 
      *                       TOLLROAD 
           10 RDWTBL31-TOLLROAD    PIC X(1). 
      *                       HWYLOCAL 

 
99
           10 RDWTBL31-HWYLOCAL    PIC X(1). 
      *                       PLACECD 
           10 RDWTBL31-PLACECD     PIC X(4). 
      *                       URBAREA 
           10 RDWTBL31-URBAREA     PIC X(4). 
      *                       URBSIZE 
           10 RDWTBL31-URBSIZE     PIC X(1). 
      *                       LANDUSE 
           10 RDWTBL31-LANDUSE     PIC X(1). 
      *                       NOLANES 
           10 RDWTBL31-NOLANES     PIC X(2). 
      *                       SURWIDTH 
           10 RDWTBL31-SURWIDTH    PIC X(3). 
      *                       SHLDTYPE 
           10 RDWTBL31-SHLDTYPE    PIC X(1). 
      *                       SHLDTYP2 
           10 RDWTBL31-SHLDTYP2    PIC X(1). 
      *                       SHLDTYP3 
           10 RDWTBL31-SHLDTYP3    PIC X(1). 
      *                       SLDWIDTH 
           10 RDWTBL31-SLDWIDTH    PIC S9(2)V9(1) USAGE COMP-3. 
      *                       SHLDWTH2 
           10 RDWTBL31-SHLDWTH2    PIC S9(2)V9(1) USAGE COMP-3. 
      *                       SHLDWTH3 
           10 RDWTBL31-SHLDWTH3    PIC S9(2)V9(1) USAGE COMP-3. 
      *                       MEDWIDTH 
           10 RDWTBL31-MEDWIDTH    PIC X(3). 
      *                       RDMEDIAN 
           10 RDWTBL31-RDMEDIAN    PIC X(2). 
      *                       ISLDTYPE 
           10 RDWTBL31-ISLDTYPE    PIC X(1). 
      *                       ISLDTYP2 
           10 RDWTBL31-ISLDTYP2    PIC X(1). 
      *                       ISLDTYP3 
           10 RDWTBL31-ISLDTYP3    PIC X(1). 
      *                       ISLDWDTH 
           10 RDWTBL31-ISLDWDTH    PIC S9(2)V9(1) USAGE COMP-3. 
      *                       ISLDWTH2 
           10 RDWTBL31-ISLDWTH2    PIC S9(2)V9(1) USAGE COMP-3. 
      *                       ISLDWTH3 
           10 RDWTBL31-ISLDWTH3    PIC S9(2)V9(1) USAGE COMP-3. 
      *                       BEARING 
           10 RDWTBL31-BEARING     PIC X(11). 
      *                       HRZDGCRV 
           10 RDWTBL31-HRZDGCRV    PIC X(6). 
      *                       SUPERELE 

 
100
           10 RDWTBL31-SUPERELE    PIC SV9(4) USAGE COMP-3. 
      *                       PAVECOND 
           10 RDWTBL31-PAVECOND    PIC S9(1)V9(2) USAGE COMP-3. 
      *                       SURFNUM 
           10 RDWTBL31-SURFNUM     PIC X(2). 
      *                       FRICTCSE 
           10 RDWTBL31-FRICTCSE    PIC X(1). 
      *                       FRICTHK 
           10 RDWTBL31-FRICTHK     PIC S9(1)V9(2) USAGE COMP-3. 
      *                       SURLAYNO 
           10 RDWTBL31-SURLAYNO    PIC X(1). 
      *                       SURLAYCD 
           10 RDWTBL31-SURLAYCD    PIC X(4). 
      *                       SURTHKNO 
           10 RDWTBL31-SURTHKNO    PIC X(1). 
      *                       SURTHKCD 
           10 RDWTBL31-SURTHKCD    PIC S9(1)V9(2) USAGE COMP-3. 
      *                       BEGSECNM 
           10 RDWTBL31-BEGSECNM    PIC X(20). 
      *                       ENDSECNM 
           10 RDWTBL31-ENDSECNM    PIC X(20). 
      *                       NOLGTHI 
           10 RDWTBL31-NOLGTHI     PIC X(3). 
      *                       NOLGTLO 
           10 RDWTBL31-NOLGTLO     PIC X(3). 
      *                       LIGHTCDE 
           10 RDWTBL31-LIGHTCDE    PIC X(1). 
      *                       INTCMBCD 
           10 RDWTBL31-INTCMBCD    PIC X(2). 
      *                       INTDIRX 
           10 RDWTBL31-INTDIRX     PIC X(9). 
      *                       DIVUNDIV 
           10 RDWTBL31-DIVUNDIV    PIC X(1). 
      *                       CRRATECD 
           10 RDWTBL31-CRRATECD    PIC X(2). 
      *                       URSUBRUR 
           10 RDWTBL31-URSUBRUR    PIC X(1). 
      *                       INTSDRCD 
           10 RDWTBL31-INTSDRCD    PIC X(1). 
      *                       INTSFTYC 
           10 RDWTBL31-INTSFTYC    PIC X(1). 
      *                       RDINTSEC 
           10 RDWTBL31-RDINTSEC    PIC X(2). 
      *                       CROSRDNM 
           10 RDWTBL31-CROSRDNM    PIC X(20). 
      *                       EXITNO 

 
101
           10 RDWTBL31-EXITNO      PIC X(4). 
      *                       INTERCHG 
           10 RDWTBL31-INTERCHG    PIC X(2). 
      *                       CHKDIGIT 
           10 RDWTBL31-CHKDIGIT    PIC X(1). 
      *                       RRCROSNO 
           10 RDWTBL31-RRCROSNO    PIC X(6). 
      *                       STAIDNO 
           10 RDWTBL31-STAIDNO     PIC X(6). 
      *                       BOXCULNO 
           10 RDWTBL31-BOXCULNO    PIC X(6). 
      *                       BRIDGENO 
           10 RDWTBL31-BRIDGENO    PIC X(6). 
      *                       FACCROSS 
           10 RDWTBL31-FACCROSS    PIC X(20). 
      *                       UNDPASNO 
           10 RDWTBL31-UNDPASNO    PIC X(6). 
      *                       AVGDFACT 
           10 RDWTBL31-AVGDFACT    PIC S9(2)V9(2) USAGE COMP-3. 
      *                       AVGKFACT 
           10 RDWTBL31-AVGKFACT    PIC S9(2)V9(2) USAGE COMP-3. 
      *                       AVGTFACT 
           10 RDWTBL31-AVGTFACT    PIC S9(2)V9(2) USAGE COMP-3. 
      *                       SECTADT 
           10 RDWTBL31-SECTADT     PIC X(6). 
      *                       ACMANCLS 
           10 RDWTBL31-ACMANCLS    PIC X(2). 
      *                       AUXLNTYP 
           10 RDWTBL31-AUXLNTYP    PIC X(1). 
      *                       AUXLNUM 
           10 RDWTBL31-AUXLNUM     PIC X(1). 
      *                       AUXLNWTH 
           10 RDWTBL31-AUXLNWTH    PIC S9(2)V9(2) USAGE COMP-3. 
      *                       SIDEWALK 
           10 RDWTBL31-SIDEWALK    PIC S9(2)V9(2) USAGE COMP-3. 
      *                       RDSIDTYP 
           10 RDWTBL31-RDSIDTYP    PIC X(2). 
      *                       LIGHTING 
           10 RDWTBL31-LIGHTING    PIC X(1). 
      *                       MAINBEG 
           10 RDWTBL31-MAINBEG     PIC S9(3)V9(3) USAGE COMP-3. 
      *                       MAINEND 
           10 RDWTBL31-MAINEND     PIC S9(3)V9(3) USAGE COMP-3. 
      *                       SBSECTCD 
           10 RDWTBL31-SBSECTCD    PIC X(2). 
      *                       ATTLOCCD 

 
102
           10 RDWTBL31-ATTLOCCD    PIC X(2). 
      *                       ATTYPECD 
           10 RDWTBL31-ATTYPECD    PIC X(2). 
      *                       VEHDIRCD 
           10 RDWTBL31-VEHDIRCD    PIC X(2). 
      *                       MAXSPEED 
           10 RDWTBL31-MAXSPEED    PIC X(3). 
      *                       MINSPEED 
           10 RDWTBL31-MINSPEED    PIC X(3). 
      *                       LMTRSTRC 
           10 RDWTBL31-LMTRSTRC    PIC X(1). 
      *                       TURNMOVE 
           10 RDWTBL31-TURNMOVE    PIC X(2). 
      *                       TYPEPARK 
           10 RDWTBL31-TYPEPARK    PIC X(1). 
      *                       SPDLIMIT 
           10 RDWTBL31-SPDLIMIT    PIC X(2). 
      *                       SIGNALNC 
           10 RDWTBL31-SIGNALNC    PIC X(2). 
      *                       SIGNALTP 
           10 RDWTBL31-SIGNALTP    PIC X(2). 
      *                       SIGNALTY 
           10 RDWTBL31-SIGNALTY    PIC X(2). 
      *                       SCHLSPED 
           10 RDWTBL31-SCHLSPED    PIC X(2). 
      *                       STATEXPT 
           10 RDWTBL31-STATEXPT    PIC X(2). 
      *                       NANLIGDT 
           10 RDWTBL31-NANLIGDT    PIC X(10). 
      *                       NALIGNID 
           10 RDWTBL31-NALIGNID    PIC X(8). 
      *                       NALNBGPT 
           10 RDWTBL31-NALNBGPT    PIC S9(3)V9(3) USAGE COMP-3. 
      *                       NALNENPT 
           10 RDWTBL31-NALNENPT    PIC S9(3)V9(3) USAGE COMP-3. 
      *                       OALIGNID 
           10 RDWTBL31-OALIGNID    PIC X(8). 
      *                       OALNBGPT 
           10 RDWTBL31-OALNBGPT    PIC S9(3)V9(3) USAGE COMP-3. 
      *                       OALNENPT 
           10 RDWTBL31-OALNENPT    PIC S9(3)V9(3) USAGE COMP-3. 
      *                       PCGRADE 
           10 RDWTBL31-PCGRADE     PIC S9(1)V9(4) USAGE COMP-3. 
      *                       VRTCRVDR 
           10 RDWTBL31-VRTCRVDR    PIC X(1). 
      *                       SPIRANGL 

 
103
           10 RDWTBL31-SPIRANGL    PIC X(6). 
      *                       SPIROFF 
           10 RDWTBL31-SPIROFF     PIC S9(2)V9(2) USAGE COMP-3. 
      *                       DTECRETE 
           10 RDWTBL31-DTECRETE    PIC X(10). 
      *                       RDWY_ACTV_ID 
           10 RDWTBL31-RDWY-ACTV-ID  PIC X(8). 
      *                       BEG_SECT_ACTV_NUM 
           10 RDWTBL31-BEG-SECT-ACTV-NUM  PIC S9(3)V9(3) USAGE COMP-3. 
      *                       END_SECT_ACTV_NUM 
           10 RDWTBL31-END-SECT-ACTV-NUM  PIC S9(3)V9(3) USAGE COMP-3. 
      *                       RDWY_INACTV_ID 
           10 RDWTBL31-RDWY-INACTV-ID  PIC X(8). 
      *                       BEG_SECTINACTV_NUM 
           10 RDWTBL31-BEG-SECTINACTV-NUM  PIC S9(3)V9(3) USAGE COMP-3. 
      *                       END_SECTINACTV_NUM 
           10 RDWTBL31-END-SECTINACTV-NUM  PIC S9(3)V9(3) USAGE COMP-3. 
      *                       RDWY_SECT_SYS_DT 
           10 RDWTBL31-RDWY-SECT-SYS-DT  PIC X(10). 
      *                       US_RTE_NUM_ID 
           10 RDWTBL31-US-RTE-NUM-ID  PIC X(8). 
      *                       ST_RD_NUM_ID 
           10 RDWTBL31-ST-RD-NUM-ID  PIC X(8). 
      *                       RDWYSUBSECTTYP_TXT 
           10 RDWTBL31-RDWYSUBSECTTYP-TXT  PIC X(1). 
      ****************************************************************** 
      * THE NUMBER OF COLUMNS DESCRIBED BY THIS DECLARATION IS 123  
      ****************************************************************** 
 

 
104
 
APPENDIX B 
RCI ATTRIBUTE DESCRIPTION 
 
 
Variable Name 
Description 
Code 
Detail 
1 
ACMANCLS 
Access Management Classified Code 
  
This code is used for all driveway 
permitting and design in all major 
capacity improvements 
2 
AVGDFACT 
Roadway Section Average "D" Factor 
  
  
3 
AVGKFACT 
Roadway Section Average "K" Factor 
  
  
4 
AVGTFACT 
Roadway Section Average "T" Factor 
  
  
5 
HRZDGCRV 
Horizontal Degree of Curve 
  
  
6 
DIVUNDIV 
Divided Undivided Raised Median 
  
  
7 
ISLDTYPE 
Inside Shoulder Type 
0 
Raised Curb 
 
 
 
1 
Paved 
 
 
 
2 
Paved Warn 
 
 
 
3 
Lawn 
 
 
 
4 
Gravel/Marl 
 
 
 
5 
Dirt 
 
 
 
6 
Curb & Gutter 
 
 
 
7 
Other 
 
 
 
8 
Curb with Resfacing 
8 
ISLDWDTH 
Inside Shoulder Width  
  
Occurs only when a median is present 
9 
LANDUSE 
Prevailing Type of Land Use 
1 
Central Business District 
 
 
 
2 
High Density Business/Commercial 
 
 
 
3 
Low Density Commercial 
 
 
 
4 
High Density Residential 
 
 
 
5 
Low Density Residential 

 
105
 
 
 
6 
Other 
10 
MAXSPEED 
Maximum Posted Speed Limit 
  
  
11 
MEDWIDTH 
Highway Median Width 
  
  
12 
NOLANES 
Number of Thru Roadway Lanes 
  
  
13 
PAVECOND 
Pavement Condition  
  
  
14 
PCGRADE 
Percent of Grade 
  
  
15 
RDACCESS 
Access Control Type 
1 
Full 
 
 
 
2 
Partial 
 
 
 
3 
None 
16 
RDINTSEC 
Type of Highway Intersection 
1 
4 Leg 
 
 
 
2 
"Y" 
 
 
 
3 
"I" 
 
 
 
4 
Rotary 
 
  
  
5 
5 or more Legs 
17 
RDMEDIAN 
Roadway Median Type 
1 
Painted 
 
 
 
2 
Median Curb< 6 inches 
 
 
 
3 
Curb > 6 inches 
 
 
 
6 
Barrier wall>1.5 ft 
 
 
 
8 
Grassed 
 
 
 
12 
Painted and Guardrail 
 
 
 
13 
Painted with barrier 
 
 
 
17 
Curb < 6 in & Lawn 
 
 
 
18 
Curb > 6 in & Guardrail 
 
 
 
20 
Other 
 
 
 
22 
Curb > 6 in & Lawn 
 
 
 
26 
Lawn, Barrier & Curb < 6 inches 

 
106
 
 
 
27 
Lawn, Barrier & Curb > 6 inches 
 
 
 
28 
Canal, Ditch Etc. 
18 
SECTADT 
Sectional 
Average 
Annual 
Daily 
Traffic 
  
  
19 
SHLDTYPE 
Highway Shoulder Type 
0 
Raised Curb 
 
 
 
1 
Paved 
 
 
 
2 
Paved Warn 
 
 
 
3 
Lawn 
 
 
 
4 
Gravel/Marl 
 
 
 
5 
Valley Gutr 
 
 
 
6 
Curb & Gutter 
 
 
 
7 
Other 
 
 
 
8 
Curb with Resurfacing 
20 
SIDEWALK 
Sidewalk Width 
  
  
21 
SLDWIDTH 
Highway Shoulder Width 
  
  
22 
SPIRANGL 
Spiral Angle 
  
  
23 
SUPERELE 
Superelevation 
  
  
24 
SURWIDTH 
Thru Pavement Surface Width 
  
  
25 
TYPEPARK 
Type of Roadway Parking 
0 
Highway Type 
 
 
 
1 
No Parking 
 
 
 
2 
Curb Both 
 
 
 
3 
Angle Both 
 
 
 
4 
Curb One-sided 
 
 
 
5 
Angle Oneside 
 
 
 
6 
Curb Oneside Angle Oneside 
 
 
 
7 
None- Curbside 
 
 
 
8 
Curb-curbside 

 
107
 
 
 
9 
Angle-Curbside 
26 
URSUBRUR 
Urban, Suburban, Rural 
  
  

 
108
APPENDIX C 
CAR DATABASE ATTRIBUTES 
 
 
 
 
 
 
 

 
109
 
 
 
 
 
 

 
110
 
 

 
111
APPENDIX D 
COMPUTER CODE FOR INTEGRATING RCI AND CARS DATABASES 
 
CreateSPs.sql: Contains the batch SQL script to create the stored procedures for the 
database. 
CreateViews.sql: Contains the SQL script to create the views for the database. 
 
All SQL code is standard ANSI SQL and thus should work on any ANSI-compliant 
database management system (e.g. MS SQL Server, ORACLE, et al). 
 
SET QUOTED_IDENTIFIER ON  
GO 
SET ANSI_NULLS ON  
GO 
 
/*ALTER  PROCEDURE [dbo].[GetAllFormattedDOTCountyNumbers] AS 
SELECT CAR2002.ID 
     , FormattedDOTCountyNumber =  
         CASE  
           WHEN (CAST([DOTCountyNumber] AS int) < 10) THEN '0' + 
(CAST([DOTCountyNumber] AS varchar(3)))        
           ELSE (CAST([DOTCountyNumber] AS varchar(3))) 
         END 
FROM CAR2002; 
*/ 
 
--EXEC GetAllFormattedDOTCountyNumbers 
 
--SELECT CAR2002.ID, 
IIf(CLng([SectionNumber])<100,IIf(CLng([SectionNumber]<10),"00" & 
[SectionNumber],"0" & [SectionNumber]),[SectionNumber]) AS 
FormattedSectionNumber 
--FROM CAR2002; 
/* 
CREATE PROCEDURE [dbo].[GetAllFormattedSectionNumbers] AS 
SELECT CAR2002.ID 
     , FormattedSectionNumber =  
         CASE  
           WHEN (CAST([SectionNumber] AS int) < 100) THEN  
             CASE 
               WHEN (CAST([SectionNumber] AS int) < 10) THEN '00' + 
(CAST([SectionNumber] AS varchar(3)))        
               ELSE '0' + (CAST([SectionNumber] AS varchar(3)))        
             END   

 
112
           ELSE (CAST([SectionNumber] AS varchar(3))) 
         END 
FROM CAR2002; 
 
*/ 
 
--EXEC GetAllFormattedSectionNumbers 
 
--if exists (select * from dbo.sysobjects where id = 
object_id(N'[dbo].[GetAllFormattedSubsectionNumbers]') and OBJECTPROPERTY(id, 
N'IsProcedure') = 1) 
--drop procedure [dbo].[GetAllFormattedSubsectionNumbers] 
--GO 
/* 
CREATE PROCEDURE [dbo].[GetAllFormattedSubsectionNumbers] AS 
SELECT CAR2002.ID 
     , FormattedSubsectionNumber =  
         CASE  
           WHEN (CAST([SubsectionNumber] AS int) < 100) THEN  
             CASE 
               WHEN (CAST([SubsectionNumber] AS int) < 10) THEN '00' + 
(CAST([SubsectionNumber] AS varchar(3)))        
               ELSE '0' + (CAST([SubsectionNumber] AS varchar(3)))        
             END   
           ELSE (CAST([SubsectionNumber] AS varchar(3))) 
         END 
FROM CAR2002; 
*/ 
 
--EXEC GetAllFormattedSubsectionNumbers 
 
CREATE PROCEDURE [dbo].[spGetAllConcatenatedRdwyid] AS 
SELECT CAR2002.ID 
     , ConcatenatedRdwyid =  
         CASE  
           WHEN (CAST([DOTCountyNumber] AS int) < 10) THEN '0' + 
(CAST([DOTCountyNumber] AS varchar(3)))        
           ELSE (CAST([DOTCountyNumber] AS varchar(3))) 
         END 
     +  
         CASE  
           WHEN (CAST([SectionNumber] AS int) < 100) THEN  
             CASE 
               WHEN (CAST([SectionNumber] AS int) < 10) THEN '00' + 
(CAST([SectionNumber] AS varchar(3)))        
               ELSE '0' + (CAST([SectionNumber] AS varchar(3)))        

 
113
             END   
           ELSE (CAST([SectionNumber] AS varchar(3))) 
         END 
     + 
         CASE  
           WHEN (CAST([SubsectionNumber] AS int) < 100) THEN  
             CASE 
               WHEN (CAST([SubsectionNumber] AS int) < 10) THEN '00' + 
(CAST([SubsectionNumber] AS varchar(3)))        
               ELSE '0' + (CAST([SubsectionNumber] AS varchar(3)))        
             END   
           ELSE (CAST([SubsectionNumber] AS varchar(3))) 
         END 
FROM CAR2002 
ORDER BY CAR2002.ID; 
 
GO 
SET QUOTED_IDENTIFIER OFF  
GO 
SET ANSI_NULLS ON  
GO 
 
SET QUOTED_IDENTIFIER ON  
GO 
SET ANSI_NULLS ON  
GO 
 
CREATE  PROCEDURE [dbo].[GetAllFormattedDOTCountyNumbers] AS 
SELECT CAR2002.ID 
     , FormattedDOTCountyNumber =  
         CASE  
           WHEN (CAST([DOTCountyNumber] AS int) < 10) THEN '0' + 
(CAST([DOTCountyNumber] AS varchar(3)))        
           ELSE (CAST([DOTCountyNumber] AS varchar(3))) 
         END 
FROM CAR2002; 
 
 
GO 
SET QUOTED_IDENTIFIER OFF  
GO 
SET ANSI_NULLS ON  
GO 
 

 
114
SET QUOTED_IDENTIFIER ON  
GO 
SET ANSI_NULLS ON  
GO 
 
/*CREATE PROCEDURE [dbo].[GetAllFormattedDOTCountyNumbers] AS 
SELECT CAR2002.ID 
     , FormattedDOTCountyNumber =  
         CASE  
           WHEN (CAST([DOTCountyNumber] AS int) < 10) THEN '0' + 
(CAST([DOTCountyNumber] AS varchar(3)))        
           ELSE (CAST([DOTCountyNumber] AS varchar(3))) 
         END 
FROM CAR2002; 
*/ 
 
--EXEC GetAllFormattedDOTCountyNumbers 
 
--SELECT CAR2002.ID, 
IIf(CLng([SectionNumber])<100,IIf(CLng([SectionNumber]<10),"00" & 
[SectionNumber],"0" & [SectionNumber]),[SectionNumber]) AS 
FormattedSectionNumber 
--FROM CAR2002; 
 
CREATE PROCEDURE [dbo].[GetAllFormattedSectionNumbers] AS 
SELECT CAR2002.ID 
     , FormattedSectionNumber =  
         CASE  
           WHEN (CAST([SectionNumber] AS int) < 100) THEN  
             CASE 
               WHEN (CAST([SectionNumber] AS int) < 10) THEN '00' + 
(CAST([SectionNumber] AS varchar(3)))        
               ELSE '0' + (CAST([SectionNumber] AS varchar(3)))        
             END   
           ELSE (CAST([SectionNumber] AS varchar(3))) 
         END 
FROM CAR2002; 
 
 
GO 
SET QUOTED_IDENTIFIER OFF  
GO 
SET ANSI_NULLS ON  
GO 
 
SET QUOTED_IDENTIFIER ON  

 
115
GO 
SET ANSI_NULLS ON  
GO 
 
CREATE PROCEDURE [dbo].[GetAllFormattedSubsectionNumbers] AS 
SELECT CAR2002.ID 
     , FormattedSubsectionNumber =  
         CASE  
           WHEN (CAST([SubsectionNumber] AS int) < 100) THEN  
             CASE 
               WHEN (CAST([SubsectionNumber] AS int) < 10) THEN '00' + 
(CAST([SubsectionNumber] AS varchar(3)))        
               ELSE '0' + (CAST([SubsectionNumber] AS varchar(3)))        
             END   
           ELSE (CAST([SubsectionNumber] AS varchar(3))) 
         END 
FROM CAR2002; 
 
 
--EXEC GetAllFormattedSubsectionNumbers 
 
GO 
SET QUOTED_IDENTIFIER OFF  
GO 
SET ANSI_NULLS ON  
GO 
 
SET QUOTED_IDENTIFIER ON  
GO 
SET ANSI_NULLS OFF  
GO 
 
 
 
CREATE    PROCEDURE 
[dbo].[spGetCountOfMilePointAndAllRCIByRoadwayIdAndInMilePointRange] AS 
SELECT RCI2002.*, 
ViewCountOfMilePointByRoadwayIdAndInMilePointRange.CountOfLocatedMilePoint 
FROM RCI2002 LEFT JOIN 
ViewCountOfMilePointByRoadwayIdAndInMilePointRange ON RCI2002.ID = 
ViewCountOfMilePointByRoadwayIdAndInMilePointRange.ID; 
 
 
 

 
116
GO 
SET QUOTED_IDENTIFIER OFF  
GO 
SET ANSI_NULLS ON  
GO 
 
SET QUOTED_IDENTIFIER ON  
GO 
SET ANSI_NULLS ON  
GO 
 
CREATE  PROCEDURE 
[dbo].[spGetCountOfMilePointByRoadwayIdAndInMilePointRange] AS 
SELECT     COUNT(dbo.CAR2002.LocatedMilePoint) AS CountOfLocatedMilePoint, 
dbo.RCI2002.ID 
FROM         dbo.CAR2002 INNER JOIN 
                      dbo.RCI2002 ON dbo.CAR2002.fkrdwyid = dbo.RCI2002.rdwyid AND 
dbo.CAR2002.LocatedMilePoint >= dbo.RCI2002.begsecpt AND  
                      dbo.CAR2002.LocatedMilePoint <= dbo.RCI2002.endsecpt 
GROUP BY dbo.RCI2002.ID 
 
GO 
SET QUOTED_IDENTIFIER OFF  
GO 
SET ANSI_NULLS ON  
GO 
 
SET QUOTED_IDENTIFIER ON  
GO 
SET ANSI_NULLS ON  
GO 
 
/*CREATE PROCEDURE [dbo].[SelectCrashesByWeekday] 
                 @WeekDay nvarchar(50) 
AS 
SELECT CAR2002.* 
FROM CAR2002 
WHERE (DateName(weekday,[CrashDate]) Like @WeekDay); 
*/ 
--SELECT CAR2002.*, WeekdayName(DatePart('w',[CrashDate]),False,2) AS Expr1 
--FROM CAR2002 
--WHERE (((WeekdayName(DatePart('w',[CrashDate]),False,2)) Like [@WeekDay])); 
--EXEC SelectCrashesByWeekday @Weekday = 'Tuesday' 
/* 
CREATE PROCEDURE [dbo].[SelectCrashesByTime] 

 
117
                 @time nvarchar(50) 
AS 
SELECT CAR2002.* 
FROM CAR2002 
WHERE ((([CAR2002].[CrashTime]) Like @time));*/ 
 
--EXEC SelectCrashesByTime @time = '12:00%' 
 
CREATE PROCEDURE [dbo].[SelectCrashesByDate] 
                 @crashdate smalldatetime 
AS 
SELECT CAR2002.* 
FROM CAR2002 
WHERE (((CAR2002.CrashDate) Like crashdate)); 
 
 
GO 
SET QUOTED_IDENTIFIER OFF  
GO 
SET ANSI_NULLS ON  
GO 
 
SET QUOTED_IDENTIFIER ON  
GO 
SET ANSI_NULLS ON  
GO 
 
/*CREATE PROCEDURE [dbo].[SelectCrashesByWeekday] 
                 @WeekDay nvarchar(50) 
AS 
SELECT CAR2002.* 
FROM CAR2002 
WHERE (DateName(weekday,[CrashDate]) Like @WeekDay); 
*/ 
--SELECT CAR2002.*, WeekdayName(DatePart('w',[CrashDate]),False,2) AS Expr1 
--FROM CAR2002 
--WHERE (((WeekdayName(DatePart('w',[CrashDate]),False,2)) Like [@WeekDay])); 
--EXEC SelectCrashesByWeekday @Weekday = 'Tuesday' 
 
CREATE PROCEDURE [dbo].[SelectCrashesByTime] 
                 @time nvarchar(50) 
AS 
SELECT CAR2002.* 
FROM CAR2002 
WHERE ((([CAR2002].[CrashTime]) Like @time)); 
 

 
118
GO 
SET QUOTED_IDENTIFIER OFF  
GO 
SET ANSI_NULLS ON  
GO 
 
SET QUOTED_IDENTIFIER ON  
GO 
SET ANSI_NULLS ON  
GO 
 
CREATE PROCEDURE [dbo].[SelectCrashesByWeekday] 
                 @WeekDay nvarchar(50) 
AS 
SELECT CAR2002.* 
FROM CAR2002 
WHERE (DateName(weekday,[CrashDate]) Like @WeekDay); 
 
--SELECT CAR2002.*, WeekdayName(DatePart('w',[CrashDate]),False,2) AS Expr1 
--FROM CAR2002 
--WHERE (((WeekdayName(DatePart('w',[CrashDate]),False,2)) Like [@WeekDay])); 
 
 
GO 
SET QUOTED_IDENTIFIER OFF  
GO 
SET ANSI_NULLS ON  
GO 
 
SET QUOTED_IDENTIFIER ON  
GO 
SET ANSI_NULLS ON  
GO 
 
CREATE VIEW dbo.ViewCountOfMilePointByRoadwayIdAndInMilePointRange 
AS 
SELECT     COUNT(dbo.CAR2002.LocatedMilePoint) AS CountOfLocatedMilePoint, 
dbo.RCI2002.ID 
FROM         dbo.CAR2002 INNER JOIN 
                      dbo.RCI2002 ON dbo.CAR2002.fkrdwyid = dbo.RCI2002.rdwyid AND 
dbo.CAR2002.LocatedMilePoint >= dbo.RCI2002.begsecpt AND  
                      dbo.CAR2002.LocatedMilePoint <= dbo.RCI2002.endsecpt 
GROUP BY dbo.RCI2002.ID 
 
GO 
SET QUOTED_IDENTIFIER OFF  

 
119
GO 
SET ANSI_NULLS ON  
GO 
 
SET QUOTED_IDENTIFIER ON  
GO 
SET ANSI_NULLS ON  
GO 
 
CREATE VIEW 
dbo.ViewCountOfMilePointAndAllRCIByRoadwayIdAndInMilePointRange 
AS 
SELECT     dbo.RCI2002.*, 
dbo.ViewCountOfMilePointByRoadwayIdAndInMilePointRange.CountOfLocatedMileP
oint AS CountOfLocatedMilePoint 
FROM         dbo.RCI2002 LEFT OUTER JOIN 
                      dbo.ViewCountOfMilePointByRoadwayIdAndInMilePointRange ON 
dbo.RCI2002.ID = dbo.ViewCountOfMilePointByRoadwayIdAndInMilePointRange.ID 
 
GO 
SET QUOTED_IDENTIFIER OFF  
GO 
SET ANSI_NULLS ON  
GO 

 
120
APPENDIX E 
VISUAL BASIC CODE FOR DATA MODELING 
 
 

 
121
 
 
 
Enter Button 
Private Sub Enter_Click() 
       
    DBase.Show 'showing the databse frame 
      
End Sub 
 
Exit Button 
Private Sub Exit_Click() 
 
    End 'Closing the application 
     
End Sub 
 
 
 

 
122
 
 
Global variables 
Dim NTName As String, NPName As String, NCPName As String, P1flag As Integer, 
T2flag As Integer 
Dim NT2Name As String, NPdFName As String, T2Tflag As Integer, NpdTName As 
String 
Dim ACflag As Integer, NTflag As Integer, DBLflag As Integer 
Dim Trcnt As Double, OTName As String 
'required 
 
Dim CpCol As Collection 
 
Data Base Button 
Private Sub DataBase_Click() 

 
123
     
   ' displaying databases using "filelistbox" 
    DBList.Path = App.Path 
    DBList.Pattern = "*.mdb" 'listing only databases  with access extension 
    DBLflag = 1 
     
   End Sub 
 
Table Button 
Private Sub Tables_Click() 
     
    'Validating the data base selection 
    If DBLflag = 0 Then 'valiating the DB button 
        MsgBox "Please Click on the DataBase Button to List the Data Bases" 
        Exit Sub 
     ElseIf (DBList.ListCount = 0) Then 'valiating and informing that ther is no data base 
        MsgBox "There are no DataBase files in application folder" 
        MsgBox "Please Exit the Application" 
        Exit Sub 
    ElseIf (DBList.FileName = "") Then 'validates the table name selection 
        MsgBox " Please Select the Appropriate Data Base." 
       Exit Sub 
    Else 
        'harvesting all the table names from the data base 
        Dim tb As Crashes.m_tables 
        Set tb = New Crashes.m_tables 
                Call tb.table_List(DBList.FileName, TablesList) 
        Set tb = Nothing 
    End If 
    'validates the database and informs to select the other data base 
    If TablesList.ListCount = 0 Then 
        MsgBox "There are no Tables in the selected DataBase" 
        MsgBox "Please select other other DataBase if any...?" 
    Else 
        DBList.Enabled = False 
        DataBase.Enabled = False 
        Tables.Enabled = False 
    End If 
 
End Sub 
 
 
 
 
Fields Button 
Private Sub Field_Click() 

 
124
     
    Dim flag As Integer 
    flag = 0 
    TablesList.SelStart = 0 
    TablesList.SelLength = Len(TablesList.Text) 
    If (Format(TablesList.SelText) = "") Or (TablesList.SelText = "Table's List") Then 
        MsgBox "Please select Apropriate Table from the Table's list" 
        Exit Sub 
    Else 
        TablesList.Enabled = False 
        
        Dim tb As Crashes.m_tables 
        Set tb = New Crashes.m_tables 
                If flag = 0 Then 
                    Call tb.Fields_List(Format(DBList.FileName), Format(TablesList.SelText), 
FieldsList) 
                    flag = 1 
                     Field.Enabled = False 
                Else 
                    MsgBox "The Fields already exists" 
                End If 
        Set tb = Nothing 
   End If 
    
End Sub 
 
Clear Button 
Private Sub DBClear_Click() 
     
    DataBase.Enabled = True 
    DBList.Path = App.Path 
    DBList.Pattern = "*." 
    DBList.Enabled = True 
    Tables.Enabled = True 
    TablesList.Enabled = True 
    TablesList.Clear 
    TablesList.Text = "Table's List" 
    Field.Enabled = True 
     
    FieldsList.Enabled = True 
    FieldsList.Clear 
    FieldsList.Text = "Field's List" 
    DBLflag = 0 
 
End Sub 
 

 
125
 
Copying the Files Button 
 
Private Sub CF_Click() 
 
    CFields.AddItem FieldsList.Text 
    CFields.Text = "CFields" 
    FieldsList.Text = "Field's List" 
 
End Sub 
 
OK Button 
 
Private Sub OK_Click() 
    
 
    FieldsList.SelStart = 0 
    FieldsList.SelLength = Len(FieldsList.Text) 
    If (Format(FieldsList.SelText) = "") Or (FieldsList.SelText = "Field's List") Then 
        MsgBox "Please select Apropriate Field from the Fields's list" 
        CutPoints.Clear 
        CutPoints.Text = "CutPoints" 
        FieldsList.Text = "Field's List" 
        Exit Sub 
    ElseIf CutPoints.ListCount <> 0 And CutPoints.Text = "CutPoints" Then 
        MsgBox "Required CutPoints Entered" 
        CutPoints.Text = "CutPoints" 
        Exit Sub 
    ElseIf CutPoints.Text = "" Or CutPoints.Text = "CutPoints" Then 
        MsgBox "Please Enter Cut Points" 
        CutPoints.Text = "CutPoints" 
        Exit Sub 
   Else 'If CutPoints.ListCount <>3 Then 
        FieldsList.Enabled = False 
        CutPoints.AddItem CutPoints.Text 
        CutPoints.Text = "CutPoints" 
     
   
    End If 
 
End Sub 
 
 Second Clear Button 
 
Private Sub Clear_Click() 
 

 
126
       CutPoints.Clear 
       CutPoints.Text = "CutPoints" 
        
End Sub 
 
Transformation Button 
Private Sub Trans_Click() 
     
    Dim Tflag As Integer 
    Tflag = 0 
    FieldsList.SelStart = 0 
    FieldsList.SelLength = Len(FieldsList.Text) 
    If (Format(FieldsList.SelText) = "") Or (FieldsList.SelText = "Field's List") Then 
        MsgBox "Please select Apropriate Field from the Fields's list" 
        Tflag = 1 
        Exit Sub 
    ElseIf CutPoints.ListCount = 0 Then 
        MsgBox "Please Enter CutPoints" 
        CutPoints.Text = "CutPoints" 
        Tflag = 1 
        Exit Sub 
    ElseIf (CutPoints.ListCount < 1) Then 'Or (CutPoints.ListCount > 3) Then 
        MsgBox "Please Enter Appropriate Number of CutPoints" 
        CutPoints.Clear 
        CutPoints.Text = "CutPoints" 
         Tflag = 1 
        Exit Sub 
    End If 
  
   If Tflag = 0 Then 
    
     
        FieldsList.Enabled = False 
        Dim Tdb As Crashes.TransDB 
        Set Tdb = New Crashes.TransDB 
        Dim CF As Integer 
        Set CpCol = New Collection 
            If ACflag = 0 Then 
                If NTflag = 0 Then 
                     
                   If T2Tflag = 1 Then 
                        NT2Name 
= 
Tdb.Crt_Table(Format(DBList.FileName), 
Format(TablesList.SelText), "Transformation", "TransID") 
                        Call 
Tdb.copy_field(Format(DBList.FileName), 
Format(TablesList.SelText), NTName, CFields) 
                         

 
127
                         
                            For CF = 0 To (CFields.ListCount - 1) 
                                CpCol.Add CFields.List(CF) 
                            Next 
                            CFields.Clear 
                            CFields.Text = "CFields" 
                    Else 
                        OTName = Format(TablesList.SelText) 
                        NTName 
= 
Tdb.Crt_Table(Format(DBList.FileName), 
Format(TablesList.SelText), "Transformation", "TransID") 
                        Call 
Tdb.copy_field(Format(DBList.FileName), 
Format(TablesList.SelText), NTName, CFields) 
                         
 
                        CFields.Clear 
                        CFields.Text = "CFields" 
                    End If 
                    NTflag = 1 
                End If 
             
              If T2Tflag = 1 Then 
               Trcnt = Trcnt + 1 
                Call 
Tdb.T_Rules(Format(DBList.FileName), 
Format(TablesList.SelText), 
Format(FieldsList.SelText) & Trcnt, NT2Name, CutPoints, NFList2) 
             '  Call Tdb.T_Rules(Format(DBList.FileName), Format(TablesList.SelText), 
CStr(trcnt), NT2Name, CutPoints, NFList2) 
              Else 
              Trcnt = Trcnt + 1 
              Call 
Tdb.T_Rules(Format(DBList.FileName), 
Format(TablesList.SelText), 
Format(FieldsList.SelText) & Trcnt, NTName, CutPoints, NFList) 
              '   Call Tdb.T_Rules(Format(DBList.FileName), Format(TablesList.SelText), 
CStr(trcnt), NTName, CutPoints, NFList) 
              End If 
            End If 
             
  If T2Tflag = 0 Then 
        If IsNumeric(CutPoints.List(0)) Then 
 
            NFList.ItemData(NFList.NewIndex) = (CutPoints.ListCount + 1) 
        Else 
          
            NFList.ItemData(NFList.NewIndex) = (CutPoints.ListCount) 
        End If 
    End If 
 
                 If ACrash.Value = 1 Then 

 
128
                  'complete: 
                      MsgBox "All Transformation Calculations Completed" 
                      ACrash.Enabled = False 
                      Tables.Enabled = False 
                      OK.Enabled = False 
                      Clear.Enabled = False 
                      CutPoints.Enabled = False 
                      Trans.Enabled = False 
                      ACflag = 1 
                      If T2flag = 0 Then 
                         MsgBox "Please Proceed to Second table" 
                         Field.Enabled = True 
                         FieldsList.Clear 
                         TablesList.Enabled = True 
                         TablesList.RemoveItem (0) 
                         TablesList.Text = "Table's List" 
                         FieldsList.Enabled = True 
                         FieldsList.Text = "Field's List" 
                         CutPoints.Enabled = True 
                         CutPoints.Clear 
                         CutPoints.Text = "CutPoints" 
                         OK.Enabled = True 
                         Clear.Enabled = True 
                         Trans.Enabled = True 
                         Prob.Enabled = False 
                         Cprb.Enabled = False 
                         ACrash.Enabled = True 
                         ACrash.Value = 0 
                         ACflag = 0 
                         NTflag = 0 
                         T2Tflag = 1 
                         Trcnt = 0 
                    End If 
                   
                    Else 
                      MsgBox "Transformation Completed" 
                      CutPoints.Clear 
                      CutPoints.Text = "CutPoints" 
                      FieldsList.Enabled = True 
                    End If 
     
        Set Tdb = Nothing 
   End If 
 
End Sub 
 

 
129
 
Continue Button 
 
Private Sub Continue_Click() 
 
Dim xx As Integer 
xx = 0 
 For xx = 0 To NFList.ListCount - 1 
    DDBase.ProbList.AddItem NFList.List(xx) 
    DDBase.ProbList.ItemData(xx) = NFList.ItemData(xx) 
 
 Next 
 
  
Call 
DDBase.names(Format(DBList.FileName), 
OTName, 
NTName, 
NT2Name, 
Format(FieldsList.SelText), CutPoints, NFList2, Format(TablesList.SelText), CpCol) 
  
DDBase.Show 
 
 
End Sub 
 
 
 
Exit Button 
 
Private Sub Exit_Click() 
    Unload DBase 'unloading the database frame 
End Sub 
 
Class Modules 
Module: m_table 
 
Connection Procedure 
 
Public Function Connection(DBNAme As String) 
 
    'Declaring a connection data type and defineing databse 
    Dim v_Connection As String 
    v_Connection = "Provider=Microsoft.Jet.OLEDB.4.0;" & _ 
           "Data Source=" & App.Path & "\" & DBNAme 
     'returning the connection string 
      Connection = v_Connection 
 
End Function 

 
130
 
Procedure for Retrieving Tables 
 
Public Sub table_List(DBNAme As String, TablesList As Object) 
 
    Dim objcat As ADOX.Catalog 
    Set objcat = New ADOX.Catalog 
    Dim objtbl As ADOX.table 
    Set objtbl = New ADOX.table 
     
'getiing connection 
    objcat.ActiveConnection = Connection(DBNAme) 
     
    For Each objtbl In objcat.Tables 
          If objtbl.Type = "TABLE" Then 
            If Left(objtbl.Name, 1) <> "~" Then 
                objtbl.Properties.Refresh 
                TablesList.AddItem objtbl.Name 
            End If 
          End If 
    Next 
     
' deactivate 
    objcat.ActiveConnection = Nothing 
    Set objtbl = Nothing 
    Set objcat = Nothing 
 
End Sub 
 
 
Procedure for Retrieving Fields 
 
Public Sub Fields_List(DBNAme As String, TBName As String, FieldsList As Object) 
 
    On Error GoTo errhandler 'if no table exsists,do this 
     
     
    'declaring and initializing DB objects 
    Dim ado_conn As ADODB.Connection 
     
    Dim adoxCat As ADOX.Catalog 
    Set adoxCat = New ADOX.Catalog 
     
    Set ado_conn = New ADODB.Connection 
     
    'Selecting COnnection properties 

 
131
    ado_conn.ConnectionString = Connection(DBNAme) 
    ado_conn.CursorLocation = adUseClient 
    ado_conn.Mode = adModeRead 
 
    ado_conn.Open 
        
        
    Set adoxCat.ActiveConnection = ado_conn 
     
    Dim col As ADOX.Column 
     
    For Each col In adoxCat.Tables(TBName).Columns 
      FieldsList.AddItem col.Name 
    Next 
     
   
      ado_conn.Close 
 
      Set ado_conn = Nothing 
       
errhandler: 
    Err.Clear 
    Exit Sub 
     
 
End Sub 
 
Module: TransDB 
 
Global variables 
Dim Cflag As Integer 
 
Creating Transformation Table 
 
Public Function Crt_Table(DBNAme As String, SelTName As String, TName As String, 
PrmField As String) As String 
 
On Error GoTo errhandler 'if no table exsists,do this 
 
  'calling connection function 
  Dim Tconnection As Crashes.m_tables 
  Set Tconnection = New Crashes.m_tables 
 
 
  Dim flag As Integer 
  Dim table As String 

 
132
   
  flag = 0 
  
  'Decleraing ADOX objects 
  Dim objcat As ADOX.Catalog 
  Set objcat = New ADOX.Catalog 
   
  Dim objtbl As ADOX.table 
  Set objtbl = New ADOX.table 
   
  Dim objidx As ADOX.Index 
  Set objidx = New ADOX.Index 
   
  Dim objky As ADOX.Key 
  Set objky = New ADOX.Key 
     
  If Mid(SelTName, 4, 1) = "-" Then 
    table = Left$(SelTName, 4) & TName 
  Else 
    table = Left$(SelTName, 2) & Right$(SelTName, 1) & "-" & TName 
  End If 
    
  'getiing connection 
  objcat.ActiveConnection = Tconnection.Connection(DBNAme) 
    
  'new table name 
  objtbl.Name = table 
   
  'defining the a must field name 
  objtbl.Columns.Append PrmField, adVarWChar, 50 
  objcat.Tables.Append objtbl 
      
    flag = 1 
     
  ' deactivate 
  objcat.ActiveConnection = Nothing 
  Set objtbl = Nothing 
  Set objcat = Nothing 
  Set objidx = Nothing 
  Set objky = Nothing 
  Set TConection = Nothing 
   
  'Returning the table name 
  Crt_Table = table 
     
errhandler: 

 
133
 
  If flag = 0 Then 
    MsgBox "Transformation Table Already Exists" 
    Err.Clear 
     
    Exit Function 
  End If 
 
End Function 
 
Creating Fields in the new table 
 
Public Function Crt_Field(DBNAme As String, OrgTName As String, OrglField As 
String, RSub As String) As String 
 
'    On Error GoTo errhandler 'if no table exsists,do this 
    'calling connection function 
    Dim Tconnection As Crashes.m_tables 
    Set Tconnection = New Crashes.m_tables 
     
      
   'Decleraing ADOX objects 
     
    Dim objcat As ADOX.Catalog 
    Set objcat = New ADOX.Catalog 
    Dim objfld As ADOX.Column 
    Set objfld = New ADOX.Column 
     
'getiing connection 
    objcat.ActiveConnection = Tconnection.Connection(DBNAme) 
     
'creating field 
    If RSub = "-T" Then 
        objfld.Name = OrglField & RSub 
    ElseIf RSub = "-P" Then 
        objfld.Name = Replace(OrglField, "-T", RSub) 
   ElseIf RSub = "-GN" Then 
        objfld.Name = Replace(OrglField, "-T", RSub) & RSub 
    ElseIf RSub = "-CP" Then 
        objfld.Name = Replace(OrglField, "-T", RSub) & RSub 
    ElseIf RSub = "" Then 
        objfld.Name = OrglField 
    End If 
    objfld.Type = adVarWChar 
    objfld.DefinedSize = 50 
     

 
134
    'adding new coloumn 
    objcat.Tables(OrgTName).Columns.Append objfld 
     
    Crt_Field = Format(objfld.Name) 
     
     
' deactivate 
    objcat.ActiveConnection = Nothing 
    Set objfld = Nothing 
    Set objcat = Nothing 
    Set TConection = Nothing 
    
End Function 
 
 
 
Computing and inserting Transformation in the table 
 
Public Sub T_Rules(DBNAme As String, OrgTable As String, OrgField As String, 
NTName As String, CutPoints As Object, FList As Object) 
 
 
  Static NFName As String 
  Dim flag As Integer, flag1 As Integer, Cflag As Integer 
  flag = 0 
  flag1 = 0 
   
  NFName = Format(Crt_Field(DBNAme, NTName, OrgField, "-T")) 
  'capturing required fields for probabilities 
  FList.AddItem NFName 
  OrgField = Replace(OrgField, Right(OrgField, 1), "") 
  'calling connection function 
  Dim Tconnection As Crashes.m_tables 
  Set Tconnection = New Crashes.m_tables 
     
   
     
  'Declaring record set and ADODB properties 
  Dim ado_conn As ADODB.Connection 
  Dim ado_rset As ADODB.Recordset 
  Dim ado_rset1 As ADODB.Recordset 
  Set ado_conn = New ADODB.Connection 
  Set ado_rset = New ADODB.Recordset 
  Set ado_rset1 = New ADODB.Recordset 
   
  'Selecting COnnection properties 

 
135
  ado_conn.ConnectionString = Tconnection.Connection(DBNAme) 
  ado_conn.CursorLocation = adUseClient 
  ado_conn.Mode = adModeReadWrite 
  ado_conn.Open 
   
  'Selecting original Record set Properties 
  Set ado_rset.ActiveConnection = ado_conn 
  ado_rset.CursorLocation = adUseClient 
  ado_rset.CursorType = adOpenForwardOnly 
  ado_rset.LockType = adLockReadOnly 'adLockBatchOptimistic 
  ado_rset.Source = "SELECT [" & OrgTable & "].[" & OrgField & "]" & _ 
                    " FROM [" & OrgTable & "];" ' & ";" ' & _ 
                  '  " ORDER BY " & "[" & OrgTable & "].[" & OrgField & "]" & ";" 
  ado_rset.Open 
  If ado_rset.RecordCount = 0 Then 
    ado_rset.Fields.Refresh 
  Else 
    ado_rset.MoveFirst 
    ado_rset.Fields.Refresh 
  End If 
       
  'Selecting Record set Properties 
  Set ado_rset1.ActiveConnection = ado_conn 
  ado_rset1.CursorLocation = adUseClient 
  ado_rset1.CursorType = adOpenStatic 
  ado_rset1.LockType = adLockBatchOptimistic 
  ado_rset1.Source = "SELECT [" & NTName & "].[" & "TransID" & "]" & ", " & "[" & 
NTName & "].[" & NFName & "]" & _ 
                     " FROM [" & NTName & " ];" 
  ado_rset1.Open 
   
  'divorce the connection 
  Set ado_rset1.ActiveConnection = Nothing 
     
  If ado_rset1.RecordCount = 0 Then 
    ado_rset1.Fields.Refresh 
  Else 
    ado_rset1.MoveFirst 
    ado_rset1.Fields.Refresh 
    flag = 1 
  End If 
   
  Dim CP() As Variant 
  Dim i As Integer 
   
  Dim colCP As Collection 

 
136
     
  Set colCP = New Collection 
   
  ReDim CP(CutPoints.ListCount - 1) As Variant 
    
  For i = 0 To (CutPoints.ListCount - 1) 
    If IsNumeric(CutPoints.List(i)) Then 
       
      Call colCP.Add(CDbl(CutPoints.List(i))) 
    Else 
       
      Call colCP.Add(UCase(CStr(CutPoints.List(i)))) 
       
      flag1 = 1 
    End If 
  Next 
   
    
  Dim PKint As Double 
  Dim C As Integer 
  Dim Tcnst As Integer 
   
  Dim fldNFName As ADODB.Field 
  Dim dblOrg As Double, StrOrg As String 
  Dim v As Variant 
  Dim x As Integer 
   
  PKint = 0 
  C = 0 
   
  'calculating tTransformation Rules 
  While Not (ado_rset.EOF) 
    ' hold field in local variable so that we can work with it 
    If IsNull(ado_rset.Fields(OrgField).Value) Then 
        If IsNumeric(ado_rset.Fields(OrgField).Value) Then 
            dblOrg = 0 
        Else 
            StrOrg = "" 
        End If 
    Else 
      
        If IsNumeric(ado_rset.Fields(OrgField).Value) Then 
         dblOrg = CDbl(ado_rset.Fields(OrgField).Value) 
        Else 
          StrOrg = CStr(ado_rset.Fields(OrgField).Value) 
        End If 

 
137
    End If 
         
    Set fldNFName = ado_rset1.Fields(NFName) 
     
    If flag = 0 Then 
      ado_rset1.AddNew 
      PKint = (PKint) + 1 
      ado_rset1.Fields("TransID").Value = CDbl(PKint) 
    End If 
     
      
    If flag1 = 0 Then 
        
      If dblOrg <= colCP(1) Then 
        fldNFName.Value = 1 
     End If 
 
      x = 1 
                   
      For Each v In colCP 
        
        If x <> colCP.Count Then 
          If dblOrg > v And dblOrg <= colCP.Item(x + 1) Then 
            If v = colCP(x + 1) Then 
              Tcnst = x 
            Else 
              Tcnst = x + 1 
            End If 
            fldNFName.Value = Tcnst 
          End If 
        End If 
        x = x + 1 
      Next 
             
      If dblOrg > colCP(colCP.Count) Then 
        fldNFName.Value = (colCP.Count + 1) 
      End If 
 
 
    ElseIf flag1 = 1 Then 
      For C = 1 To colCP.Count 
       
        If StrOrg = colCP.Item(C) Then 
          fldNFName.Value = C 
        End If 
      Next 

 
138
    End If 
         
    ' ado_rset1.UpdateBatch 
    ado_rset.MoveNext 
     
    
     
    If flag = 1 Then 
      ado_rset1.MoveNext 
    End If 
  Wend 
    
  'Closing DB 
  ado_rset.Close 
  Set ado_rset = Nothing 
       
  're-marry the recordset with the connection 
  Set ado_rset1.ActiveConnection = ado_conn 
   
   
  ado_rset1.UpdateBatch 
  ado_rset1.Close 
  Set ado_rset1 = Nothing 
   
  ado_conn.Close 
  Set ado_conn = Nothing 
  Set TConection = Nothing 
 
End Sub 
 
 
Copying the fields into transformation table 
 
Public Function copy_field(CDBNAme As String, COrgTable As String, CNTName As 
String, CFields As Object) 
 
 
Static CNFName As String 
Dim Cflag As Integer, Cflag1 As Integer, x As Integer 
  Cflag = 0 
  Cflag1 = 0 
   
  
For x = 0 To (CFields.ListCount - 1) 
   
   

 
139
 
  CNFName = Format(Crt_Field(CDBNAme, CNTName, CFields.List(x), "-T")) 
 ' CFields.List(x) = "begin" 
  'CFields.List(x) = Replace(CFields.List(x), Right(CFields.List(x), 1), "") 
  'calling connection function 
  Dim Tconnection As Crashes.m_tables 
  Set Tconnection = New Crashes.m_tables 
     
   
     
  'Declaring record set and ADODB properties 
  Dim ado_conn As ADODB.Connection 
  Dim ado_rset As ADODB.Recordset 
  Dim ado_rset1 As ADODB.Recordset 
  Set ado_conn = New ADODB.Connection 
  Set ado_rset = New ADODB.Recordset 
  Set ado_rset1 = New ADODB.Recordset 
   
  'Selecting COnnection properties 
  ado_conn.ConnectionString = Tconnection.Connection(CDBNAme) 
  ado_conn.CursorLocation = adUseClient 
  ado_conn.Mode = adModeReadWrite 
  ado_conn.Open 
   
  'Selecting original Record set Properties 
  Set ado_rset.ActiveConnection = ado_conn 
  ado_rset.CursorLocation = adUseClient 
  ado_rset.CursorType = adOpenForwardOnly 
  ado_rset.LockType = adLockReadOnly 'adLockBatchOptimistic 
  ado_rset.Source = "SELECT [" & COrgTable & "].[" & CFields.List(x) & "]" & _ 
                    " FROM [" & COrgTable & "];" ' & ";" ' & _ 
                  '  " ORDER BY " & "[" & COrgTable & "].[" & CFields.List(x) & "]" & ";" 
  ado_rset.Open 
  If ado_rset.RecordCount = 0 Then 
    ado_rset.Fields.Refresh 
  Else 
    ado_rset.MoveFirst 
    ado_rset.Fields.Refresh 
  End If 
       
  'Selecting Record set Properties 
  Set ado_rset1.ActiveConnection = ado_conn 
  ado_rset1.CursorLocation = adUseClient 
  ado_rset1.CursorType = adOpenStatic 
  ado_rset1.LockType = adLockBatchOptimistic 

 
140
'  ado_rset1.Source = "SELECT [" & CNTName & "].[" & "TransID" & "]" & ", " & "[" 
& CNTName & "].[" & CNFName & "]" & _ 
'                     " FROM [" & CNTName & " ];" 
  ado_rset1.Source = "SELECT * FROM [" & CNTName & " ];" 
  ado_rset1.Open 
   
  'divorce the connection 
'  Set ado_rset1.ActiveConnection = Nothing 
     
  If ado_rset1.RecordCount = 0 Then 
    ado_rset1.Fields.Refresh 
  Else 
    ado_rset1.MoveFirst 
    ado_rset1.Fields.Refresh 
    Cflag = 1 
  End If 
   
   
   
    
  Dim CPKint As Double 
  Dim CC As Integer 
  Dim CTcnst As Integer 
   
  Dim CfldNFName As ADODB.Field 
  Dim CdblOrg As Double, CStrOrg As String 
  Dim Cv As Variant 
  Dim Cx As Integer 
   
  CPKint = 0 
  CC = 0 
   
   
  'Adding te fields 
  While Not (ado_rset.EOF) 
    ' hold field in local variable so that we can work with it 
    If IsNull(ado_rset.Fields(CFields.List(x)).Value) Then 
        If IsNumeric(ado_rset.Fields(CFields.List(x)).Value) Then 
            CdblOrg = 0 
            Cflag1 = 0 
        Else 
            CStrOrg = "" 
            Cflag1 = 1 
        End If 
    Else 
      

 
141
        If IsNumeric(ado_rset.Fields(CFields.List(x)).Value) Then 
          CdblOrg = CDbl(ado_rset.Fields(CFields.List(x)).Value) 
          Cflag1 = 0 
        Else 
          CStrOrg = CStr(ado_rset.Fields(CFields.List(x)).Value) 
          Cflag1 = 1 
        End If 
    End If 
         
    Set CfldNFName = ado_rset1.Fields(CNFName) 
     
    If Cflag = 0 Then 
      ado_rset1.AddNew 
      CPKint = (CPKint) + 1 
      ado_rset1.Fields(0).Value = CDbl(CPKint) 
    End If 
     
      
    If Cflag1 = 0 Then 
        
       
        CfldNFName.Value = CdblOrg 
      
    ElseIf Cflag1 = 1 Then 
       
          CfldNFName.Value = CStrOrg 
     
    End If 
         
    ' ado_rset1.UpdateBatch 
    ado_rset.MoveNext 
     
    
     
    If Cflag = 1 Then 
      ado_rset1.MoveNext 
    End If 
  Wend 
   
  'Closing DB 
  ado_rset.Close 
  Set ado_rset = Nothing 
       
  're-marry the recordset with the connection 
 ' Set ado_rset1.ActiveConnection = ado_conn 
   

 
142
   
  ado_rset1.UpdateBatch 
  ado_rset1.Close 
  Set ado_rset1 = Nothing 
   
  ado_conn.Close 
  Set ado_conn = Nothing 
  Set TConection = Nothing 
Next 
 
End Function 
 
 
 
 
 
 
 
 
 
 
 

 
143
 
Global variables 
Dim DDBNAme As String, TTName As String, T2TName As String, CPName As String, 
CPflag As Integer, T2FName As String 
Dim TBLName As String, DPdtName As String, DPdfName As String, CPoints As 
Object, FList As Object 
Dim R2Table As String, LtCnt As Integer, PName As String 
Dim GNLmt As Integer, GNTemp As Integer, pflag As Integer 
Dim col As Collection, CCol As Collection 
 
 
Condition Probability Button 
 
Private Sub CP_Click() 
 

 
144
  Dim Tdb As Crashes.TransDB 
  Set Tdb = New Crashes.TransDB 
'CPflag = 0 
               If CPflag = 0 Then 
                    CPName = Tdb.Crt_Table(DDBNAme, TBLName, "DepCProbabilities", 
"DepCProbID") 
                    CPflag = 1 
                End If 
                 
 Set Tdb = Nothing 
 
Dim DP As Crashes.Dep_Prob 
Set DP = New Crashes.Dep_Prob 
     
 
    'Call DP.CProb_Values(DDBNAme, TTName, CPName, PList, IntList, GNTemp) 
    Call DP.CProb_Values(DDBNAme, TTName, CPName, PList) 
 
Set DP = Nothing 
Dim i As Integer 
For i = 0 To (ProbList.ListCount - 1) 
 
ProbList.Selected(i) = False 
 
Next 
PList.Clear 
GNTemp = 0 
GNLmt = 0 
 
End Sub 
 
Probability Button 
 
Private Sub Prob2_Click() 
 
Dim Tdb As Crashes.TransDB 
  Set Tdb = New Crashes.TransDB 
'CPflag = 0 
               If pflag = 0 Then 
                    PName = Tdb.Crt_Table(DDBNAme, TBLName, "Probabilities", "ProbID") 
                    pflag = 1 
                End If 
                 
 Set Tdb = Nothing 
 
Dim DP As Crashes.Dep_Prob 

 
145
Set DP = New Crashes.Dep_Prob 
     
 
   ' Call DP.CProb_Values(DDBNAme, TTName, PName, PList, IntList, GNTemp) 
   Call DP.CProb_Values(DDBNAme, TTName, PName, PList) 
 
Set DP = Nothing 
Dim i As Integer 
For i = 0 To (ProbList.ListCount - 1) 
 
ProbList.Selected(i) = False 
 
Next 
PList.Clear 
GNTemp = 0 
GNLmt = 0 
 
 
End Sub 
 
Predictions Button 
 
Private Sub Pd_Click() 
 
        Dim Tdb As Crashes.TransDB 
        Set Tdb = New Crashes.TransDB 
        Dim DPrdb As Crashes.DepPred 
        Set DPrdb = New Crashes.DepPred 
        Dim NPdflag As Integer 
       ' NPName As String 
               If NPdflag = 0 Then 
                 DPdtName = Tdb.Crt_Table(DDBNAme, T2TName, "Predictions", "PredID") 
                 Call Tdb.copy_field(DDBNAme, T2TName, DPdtName, CCol) 
                 DPdfName = Tdb.Crt_Field(DDBNAme, DPdtName, "Actual Values", "") 
                 Call 
DPrdb.AC_Values(DDBNAme, 
R2Table, 
T2FName, 
DPdtName, 
DPdfName, CPoints) 
                    NPdflag = 1 
                End If 
   'required 
    Call DPrdb.Pred_Values(DDBNAme, T2TName, CPName, DPdtName, FList, rst, 
CPoints) 
    
   
 ' Call DPrdb.Pred_Values(DDBNAme, T2TName, "Ta1-DepCProbabilities", "Ta2-
Predictions", FList, rst, CPoints) 
            

 
146
                    Set Tdb = Nothing 
                    Set DPrdb = Nothing 
                    MsgBox "Prediction calculations completed" 
                    Pd.Enabled = False 
                     
 
End Sub 
 
Procedure for Listing Transformation Fields  
 
Private Sub ProbList_ItemCheck(Item As Integer) 
 
 
Dim x As Integer 
If ProbList.Selected(Item) = True Then 
    PList.AddItem (ProbList.List(Item)) 
    PList.ItemData(PList.NewIndex) = ProbList.ItemData(ProbList.ListIndex) 
    LtCnt = LtCnt + 1 
Else 
 For x = 0 To LtCnt - 1 
    If PList.List(x) = ProbList.List(Item) Then 
           PList.RemoveItem (x) 
            
    End If 
 Next 
End If 
 
End Sub 
 
 
Exit Button 
 
Private Sub Exit_Click() 
 
Unload DDBase 'unloading 
 
End Sub 
 
Class Modules 
Module: Dep_Prob 
 
Global Variables 
Dim a() As Integer, rcnt As Double, a1() As Integer 
Dim i As Integer, j As Integer, k As Integer, p As Integer 
Dim m As Integer, n As Integer, Lcnt As Integer, flg As Integer 

 
147
Dim PKint As Integer, Fflag As Integer, SNFList() As String 
Dim NCPFName1 As String, NCPFName2 As String, selfield As String, selint As String 
Dim ccprob() As Double, Bk_Mark As Variant, Bkflag As Integer 
Dim Trcnt As Collection, Trcnflg As Integer 
 
Generating conditional probability Numbers 
 
Public Sub CProb_Values(DBNAme As String, NTTName As String, NCPTName As 
String, NFList1 As Object) 
 
 
 Dim flg1 As Integer, temp As Integer, x As Integer 
 temp = 0 
 
 selfield = "" 
 
  Lcnt = NFList1.ListCount 
    
    ReDim SNFList(Lcnt - 1) As String 
   ReDim a1(Lcnt - 1) As Integer 
    For x = 0 To (NFList1.ListCount - 1) 
       
            SNFList(x) = NFList1.List(x) 
            a1(x) = NFList1.ItemData(x) 
    Next 
    temp = 0 
 
    For x = 0 To Lcnt - 1 
        selfield = selfield + Left(SNFList(x), 1) + Right(Replace(SNFList(x), "-T", ""), 1) 
    Next 
   
j = 1 
ReDim a(Lcnt - 1) As Integer 
For i = 0 To Lcnt - 1 
a(i) = j 
Next 
 
 
While j < (a1(Lcnt - 1) + 1) 
 
start: a(Lcnt - 1) = j 
flg = 0 
flg1 = 0 
l = 1 
'calling con prob function 
Call conprob(DBNAme, NTTName, NCPTName, selfield, NFList1) 

 
148
 
If j = a1(Lcnt - 1) Then 
    For i = 0 To Lcnt - 1 
     
        If a(i) = a1(i) Then 
         
            j = 1 
            k = Lcnt - 1 
            
           
            If a(0) > 1 And a(0) <= a1(0) Then 
         While p < Lcnt - 1 
             If a(p) < a1(p) Then 
                i = p 
             End If 
            p = p + 1 
         Wend 
            
        
    End If 
              
            
            While k >= i 
                
                If a(k) < a1(k) Then 
                  n = k 
                  flg = 1 
                End If 
           If flg = 1 Then 
                If ((n - i) > 1) And (flg1 = 0) Then 
                    temp = n 
                    flg1 = 2 
                End If 
            End If 
             If flg = 0 Then 
                  n = k - 1 
                  
             End If 
                    k = k - 1 
             Wend 
             
                  If flg = 0 And (i - 1) < 0 Then 
                  Set Trcnt = Nothing 
                    MsgBox "Calculations Completed" 
                    Exit Sub 
                  End If 

 
149
                  If flg1 = 2 Then 
                    n = temp 
                  End If 
                    celmnt (n) 
                        GoTo start 
        End If 
         
         
    Next 
End If 
j = j + 1 
Wend 
 
End Sub 
 
Private Sub celmnt(n As Integer) 
 
While (n < Lcnt) 
     
    m = a(n) 
    a(n) = m + 1 
        If a(n) = a1(n) + 1 Then 
            m = a(n) 
            a(n) = m - a1(n) 
        End If 
    n = n + 1 
         
     
Wend 
 
End Sub 
 
Comparing and harvesting the Generated values from Transformation table 
 
Private Sub conprob(DBNAme As String, NTTName As String, NCPTName As String, 
SField As String, NFList1 As Object) 
     
     
    'calling connection function 
    Dim Tconnection As Crashes.m_tables 
    Set Tconnection = New Crashes.m_tables 
     
    'declaring flags and counters 
    Dim cnt As Double, Incnt As Double 
     
    Dim ado_conn As ADODB.Connection 

 
150
    Dim fld As ADODB.Field 
    Dim ado_rset As ADODB.Recordset 
     
    Set ado_conn = New ADODB.Connection 
    Set ado_rset = New ADODB.Recordset 
     
    'Selecting COnnection properties 
    ado_conn.ConnectionString = Tconnection.Connection(DBNAme) 
     
ado_conn.CursorLocation = adUseClient 
    ado_conn.Mode = adModeReadWrite 
    ado_conn.Open 
        
    'Selecting Record set Properties 
    Set ado_rset.ActiveConnection = ado_conn 
    ado_rset.CursorLocation = adUseClient 
    ado_rset.CursorType = adOpenKeyset 
    ado_rset.LockType = adLockBatchOptimistic 
    ado_rset.Source = "SELECT * FROM [" & NTTName & " ];" 
     
    ado_rset.Open 
    ado_rset.MoveFirst 
     
    rcnt = ado_rset.RecordCount 
         
        cnt = 0 
        Incnt = 0 
        
    'cal Conpron from DB list 
    ado_rset.Fields.Refresh 
    While Not (ado_rset.EOF) 
       
 
         For i = 0 To (NFList1.ListCount - 1) 
             
                If a(Incnt) = ado_rset.Fields(NFList1.List(i)).Value Then 
                    Incnt = Incnt + 1 
                End If 
      
       Next 
         
        If Incnt = Lcnt Then 
            cnt = cnt + 1 
        End If 
            Incnt = 0 
            ado_rset.MoveNext 

 
151
         
   Wend 
   If Trcnflg = 0 Then 
      Set Trcnt = New Collection 
      Trcnflg = 1 
    End If 
   
    Call Trcnt.Add(cnt) 
        
      ado_rset.UpdateBatch 
      ado_rset.Fields.Refresh 
       
      'Closing DB 
      ado_rset.Close 
      ado_conn.Close 
      Set ado_rset = Nothing 
      Set ado_conn = Nothing 
      Set Tconnection = Nothing 
       
   
  Call cnpbtable(DBNAme, NCPTName, Trcnt, SField) 
 
End Sub 
 
 
Computing  conditional probability and Appending the conditional probability  to 
the table 
 
Private Sub cnpbtable(DBNAme As String, NCPTName As String, Trcnt As Object, 
SField As String) 
    
   On Error GoTo errhandler 'if you wantto create new table,do this 
    If Fflag = 0 Then 
        'decleraing for creating new fields 
         
        Dim TrDB As Crashes.TransDB 
        Set TrDB = New Crashes.TransDB 
         
      'try to get different field name 
           
        NCPFName1 = Format(TrDB.Crt_Field(DBNAme, NCPTName, SField, "-GN")) 
        NCPFName2 = Format(TrDB.Crt_Field(DBNAme, NCPTName, SField, "-CP")) 
        
       
           Fflag = 1 
        Set TrDB = Nothing 

 
152
    End If 
    'calling connection function 
    Dim Tconnection As Crashes.m_tables 
    Set Tconnection = New Crashes.m_tables 
 
     
     
 
Dim ind As Integer, stxt As String 
Static flag As Integer 
 
stxt = "" 
For ind = 0 To Lcnt - 1 
stxt = stxt + CStr(a(ind)) 
Next 
 
Dim ado_conn As ADODB.Connection 
    Dim fld As ADODB.Field 
    Dim ado_rset As ADODB.Recordset 
     
    Set ado_conn = New ADODB.Connection 
    Set ado_rset = New ADODB.Recordset 
     
    'Selecting COnnection properties 
    ado_conn.ConnectionString = Tconnection.Connection(DBNAme) 
    ado_conn.CursorLocation = adUseClient 
    ado_conn.Mode = adModeReadWrite 
     ado_conn.Open 
    'Selecting Record set Properties 
    Set ado_rset.ActiveConnection = ado_conn 
    ado_rset.CursorLocation = adUseClient 
    ado_rset.CursorType = adOpenKeyset 
    ado_rset.LockType = adLockBatchOptimistic 
    ado_rset.Source = "SELECT * FROM [" & NCPTName & " ];" 
     
    ado_rset.Open 
     
    
     
    If ado_rset.RecordCount = 0 Then 
      ado_rset.Fields.Refresh 
      ado_rset.AddNew 
      PKint = PKint + 1 
      ado_rset.Fields(0).Value = (PKint) 
      ado_rset.MoveFirst 
      Bk_Mark = ado_rset.Bookmark 

 
153
      Bkflag = 1 
      flag = 1 
     ElseIf flag = 1 Then 
 
            ado_rset.MoveLast 
            ado_rset.AddNew 
            PKint = PKint + 1 
            ado_rset.Fields(0).Value = (PKint) 
     
        ado_rset.Fields.Refresh 
     End If 
        If flag = 0 Then 
            ado_rset.MoveFirst 
            Bk_Mark = ado_rset.Bookmark 
            flag = 2 
        End If 
         
        If flag = 2 Then 
            ado_rset.Bookmark = Bk_Mark 
        End If 
         
        ado_rset.Fields(NCPFName1).Value = stxt 
        ado_rset.Fields(NCPFName2).Value = 0 
         
        ado_rset.UpdateBatch 
      ado_rset.Fields.Refresh 
 '*********generating probabilities 
        If a(UBound(a)) = a1(UBound(a1)) Then 
          
 
            Dim Dcprob As Double 
            Dcprob = 0 
 
            For x = 1 To Trcnt.Count 
                Dcprob = Dcprob + Trcnt.Item(x) 
                
            Next 
                                
        x = 1 
        
        If Bkflag = 1 Then 
             
            ado_rset.Bookmark = Bk_Mark 
            Bkflag = 0 
        ElseIf flag = 2 Then 
            ado_rset.Bookmark = Bk_Mark - (Trcnt.Count - 1) 

 
154
        Else 
            ado_rset.Bookmark = Bk_Mark + 1 
        End If 
         
      While Not (ado_rset.EOF) 
       
         
            If x <= Trcnt.Count Then 
            If Dcprob = 0 Then 
                ado_rset.Fields(NCPFName2).Value = CStr(Dcprob) 
            Else 
                ado_rset.Fields(NCPFName2).Value = CStr(Trcnt.Item(x) / Dcprob) 
            End If 
              
             
             Bk_Mark = ado_rset.Bookmark 
             If flag = 2 Then 
                Bk_Mark = Bk_Mark + 1 
             End If 
             x = x + 1 
            Else 
                ado_rset.Fields(NCPFName1).Value = "NULL" 
                ado_rset.Fields(NCPFName2).Value = 0 
            End If 
             
                ado_rset.MoveNext 
                 
         
       Wend 
        
         ado_rset.UpdateBatch 
         ado_rset.Fields.Refresh 
         For x = 1 To Trcnt.Count 
               Trcnt.Remove 1 
            Next 
        End If 
'********* 
        If flag = 2 And ado_rset.EOF = False Then 
             
          ado_rset.MoveNext 
           Bk_Mark = ado_rset.Bookmark 
            
        End If 
         
errhandler: 
        If (flag = 3 And ado_rset.EOF = True) Then 

 
155
      
            Err.Clear 
        
            flag = 1 
        End If 
  
       
      'Closing DB 
      ado_rset.Close 
      ado_conn.Close 
      Set ado_rset = Nothing 
      Set ado_conn = Nothing 
      Set Tconnection = Nothing 
 
End Sub 
Module: Deppred 
 
Global Variables 
Dim a() As Integer 
Dim i As Integer, j As Integer, Lcnt As Integer, LCnt1 As Integer 
Dim flg As Integer, fldflg As Integer 
Dim bkMark As Variant 
Dim FNames() As String, CPNames() As String, GNNames() As String 
 
Calculating Actual Values in Prediction table 
 
Public Sub AC_Values(DBNAme As String, OrgTable As String, OrgField As String, 
NpdT As String, NFName As String, PCutPoints As Object) 
     
    
    'calling connection function 
    Dim Tconnection As Crashes.m_tables 
    Set Tconnection = New Crashes.m_tables 
     
    Dim flag As Integer, flag1 As Integer 
    flag = 0 
    flag1 = 0 
     
    'Declaring record set and ADODB properties 
    Dim ado_conn As ADODB.Connection 
    Dim ado_rset As ADODB.Recordset 
    Dim ado_rset1 As ADODB.Recordset 
    Set ado_conn = New ADODB.Connection 
    Set ado_rset = New ADODB.Recordset 
    Set ado_rset1 = New ADODB.Recordset 

 
156
    
    'Selecting COnnection properties 
    ado_conn.ConnectionString = Tconnection.Connection(DBNAme) 
    ado_conn.CursorLocation = adUseClient 
    ado_conn.Mode = adModeReadWrite 
    ado_conn.Open 
     
    'Selecting original Record set Properties 
    Set ado_rset.ActiveConnection = ado_conn 
    ado_rset.CursorLocation = adUseClient 
    ado_rset.CursorType = adOpenForwardOnly 
    ado_rset.LockType = adLockBatchOptimistic 
    ado_rset.Source = "SELECT * FROM [" & OrgTable & "]; " 
    ado_rset.Open 
    If ado_rset.RecordCount = 0 Then 
        ado_rset.Fields.Refresh 
    Else 
        ado_rset.MoveFirst 
        ado_rset.Fields.Refresh 
    End If 
     
    'Selecting Record set Properties 
    Set ado_rset1.ActiveConnection = ado_conn 
    ado_rset1.CursorLocation = adUseClient 
    ado_rset1.CursorType = adOpenKeyset 
    ado_rset1.LockType = adLockBatchOptimistic 
    ado_rset1.Source = "SELECT * FROM [" & NpdT & " ];" 
    ado_rset1.Open 
     
    If ado_rset1.RecordCount = 0 Then 
        ado_rset1.Fields.Refresh 
    Else 
        ado_rset1.MoveFirst 
        ado_rset1.Fields.Refresh 
        flag = 1 
    End If 
    
    Dim i As Integer, CP() As Variant 
    ReDim CP(PCutPoints.ListCount - 1) As Variant 
     
     
    For i = 0 To ((PCutPoints.ListCount) - 1) 
         
        If IsNumeric(PCutPoints.List(i)) Then 
           
            CP(i) = CDbl(PCutPoints.List(i)) 

 
157
        Else 
             CP(i) = UCase(CStr(PCutPoints.List(i))) 
            flag1 = 1 
        End If 
   Next 
     Dim PKint As Double, Tcnst As Integer 
     PKint = 0 
   'calculating tTransformation Rules 
    While Not (ado_rset.EOF) 
     
        If flag = 0 Then 
            ado_rset1.AddNew 
            PKint = (PKint) + 1 
            ado_rset1.Fields(0).Value = CDbl(PKint) 
        End If 
         
        Tcnst = 1 
      If flag1 = 0 Then 
        If IsNull(ado_rset.Fields(OrgField).Value) Then 
                ado_rset.Fields(OrgField).Value = 0 
               
            End If 
            If (CDbl(ado_rset.Fields(OrgField).Value) <= CP(0)) Then 
                ado_rset1.Fields(NFName).Value = Tcnst 
            End If 
            For C = 0 To (PCutPoints.ListCount - 1) 
              If C <> (PCutPoints.ListCount - 1) Then 
                If 
(CDbl(ado_rset.Fields(OrgField).Value) 
> 
CP(C)) 
And 
(CDbl(ado_rset.Fields(OrgField).Value) <= CP(C + 1)) Then 
                    If CP(C) = CP(C + 1) Then 
                        Tcnst = C + 1 
                      Else 
                        Tcnst = C + 2 
                    End If 
                    ado_rset1.Fields(NFName).Value = Tcnst 
                End If 
              End If 
            Next 
            If CDbl(ado_rset.Fields(OrgField).Value) > CP((PCutPoints.ListCount - 1)) Then 
                ado_rset1.Fields(NFName).Value = (PCutPoints.ListCount + 1) 
            End If 
             
        ElseIf flag1 = 1 Then 
        If IsNull(ado_rset.Fields(OrgField).Value) Then 
                ado_rset.Fields(OrgField).Value = "" 
              

 
158
            End If 
            For C = 0 To (PCutPoints.ListCount - 1) 
             If CStr(ado_rset.Fields(OrgField).Value) = CP(C) Then 
                ado_rset1.Fields(NFName).Value = C + 1 
             End If 
            Next 
                     
       End If 
                 
      ado_rset1.UpdateBatch 
      ado_rset.MoveNext 
       
       If flag = 1 Then 
              ado_rset1.MoveNext 
       End If 
     
     Wend 
      'Closing DB 
       
      ado_rset.Close 
      Set ado_rset = Nothing 
  
      ado_rset1.UpdateBatch 
      ado_rset1.Close 
      Set ado_rset1 = Nothing 
    'creating other fields in  prediction table 
    Call PCrt_Field(ado_conn, NpdT, "Predictions") 
    Call PCrt_Field(ado_conn, NpdT, "IsAccurate") 
       
      ado_conn.Close 
      Set ado_conn = Nothing 
      Set TConection = Nothing 
     
End Sub 
 
Creating fields for prediction table 
 
Private Function PCrt_Field(ado_conn As ADODB.Connection, OrgTName As String, 
OrglField As String) 
 
      
   'Decleraing ADOX objects 
     
    Dim objcat As ADOX.Catalog 
    Set objcat = New ADOX.Catalog 
    Dim objfld As ADOX.Column 

 
159
    Set objfld = New ADOX.Column 
     
'getiing connection 
    objcat.ActiveConnection = ado_conn 
     
'creating field 
    
        objfld.Name = OrglField 
        objfld.Type = adVarWChar 
        objfld.DefinedSize = 50 
     
    'adding new coloumn 
    objcat.Tables(OrgTName).Columns.Append objfld 
     
     
     
     
' deactivate 
    objcat.ActiveConnection = Nothing 
    Set objfld = Nothing 
    Set objcat = Nothing 
     
    
End Function 
 
Harvesting the required Transformation from second Table 
 
Public Sub Pred_Values(DBase As String, NT2 As String, NCPT As String, NpdT As 
String, NFList22 As Object, PredOP As Object, PCList2 As Object) 
    ' declaring  for database connection 
   Dim Tconnection As Crashes.m_tables 
   Set Tconnection = New Crashes.m_tables 
     
    Dim cnt As Double, Incnt As Double 
    Dim ccprob As Double, rtemp As Integer 
    rtemp = PCList2.ListCount + 2 
' required 
    Lcnt = NFList22.ListCount 
  '  Lcnt = 7 
    ReDim a(Lcnt - 1) As Integer 
        'declaring and initializing DB objects 
         
    Dim ado_conn As ADODB.Connection 
    Dim ado_rset As ADODB.Recordset 
     
    Set ado_conn = New ADODB.Connection 

 
160
    Set ado_rset = New ADODB.Recordset 
     
    'Selecting COnnection properties 
    ado_conn.ConnectionString = Tconnection.Connection(DBase) 
    ado_conn.CursorLocation = adUseClient 
    ado_conn.Mode = adModeReadWrite 
 
    ado_conn.Open 
        
    'Selecting Record set Properties 
    Set ado_rset.ActiveConnection = ado_conn 
    ado_rset.CursorLocation = adUseClient 
    ado_rset.CursorType = adOpenKeyset 
    ado_rset.LockType = adLockBatchOptimistic 
    ado_rset.Source = "SELECT * FROM [" & NT2 & "];" 
     
    ado_rset.Open 
    ado_rset.MoveFirst 
     
 '*****start here)********* 
     'get fields list from the transformation table 
     Dim fld As ADODB.Field 
     Dim x As Integer 
     x = 0 
     For Each fld In ado_rset.Fields 
        x = x + 1 
     Next 
     x = x - 2 
    
     ReDim FNames(x) As String 
     x = 0 
     For Each fld In ado_rset.Fields 
        If Right(fld.Name, 2) = "-T" Then 
        FNames(x) = Replace(fld.Name, "-T", "") 
        x = x + 1 
        End If 
     Next 
               
    'cal Conpron from DB list 
     
    While Not (ado_rset.EOF) 
               
        For i = 0 To Lcnt - 1 
             a(i) = ado_rset.Fields(i + 1).Value 
              
        Next 

 
161
         
         
         
       Call Prob(a(), FNames(), ado_conn, PredOP, NCPT, NpdT, PCList2) 
            ado_rset.MoveNext 
         
   Wend 
        Call predvalue(rtemp, ado_conn, PredOP, NpdT, PCList2) 
      ado_rset.UpdateBatch 
      ado_rset.Fields.Refresh 
      
      'Closing DB 
      ado_rset.Close 
      ado_conn.Close 
      Set ado_rset = Nothing 
      Set ado_conn = Nothing 
       Set Tconnection = Nothing 
   
 
End Sub 
 
Procedure for computing the predictions 
 
Private Sub Prob(a() As Integer, FNames() As String, ado_conn As ADODB.Connection, 
PredOP As Object, NCPT As String, NpdT As String, NFList2 As Object) 
 
Dim predcat() As Double, Pcnt As Integer, Pcnt1 As Integer 
Dim gen As String, manp As String 
gen = "" 
manp = "" 
Pcnt1 = NFList2.ListCount 
ReDim predcat(Pcnt1) As Double 
For Pcnt = 0 To Pcnt1 
    predcat(Pcnt) = 1 
Next 
 
Dim ado_Rset2 As ADODB.Recordset 
Set ado_Rset2 = New ADODB.Recordset 
     
    'Selecting Record set Properties 
    Set ado_Rset2.ActiveConnection = ado_conn 
    ado_Rset2.CursorLocation = adUseClient 
    ado_Rset2.CursorType = adOpenKeyset 
    ado_Rset2.LockType = adLockBatchOptimistic 
    ado_Rset2.Source = "SELECT * FROM [" & NCPT & "];" 
     

 
162
    ado_Rset2.Open 
    ado_Rset2.MoveFirst 
'******get the fields from table 2************** 
    Dim fld As ADODB.Field 
      Dim x As Integer 
     x = 0 
     For Each fld In ado_Rset2.Fields 
        x = x + 1 
     Next 
     x = x - 3 
    
     ReDim CPNames(x / 2) As String 
     ReDim GNNames(x / 2) As String 
     Dim y1 As Integer 
     y1 = 0 
     x = 0 
     For Each fld In ado_Rset2.Fields 
        If (Right(fld.Name, 3) = "-CP") Then 
           CPNames(y1) = fld.Name 
           y1 = y1 + 1 
        ElseIf (Right(fld.Name, 3) = "-GN") Then 
           GNNames(x) = fld.Name 
           x = x + 1 
        End If 
            
     Next 
 
 '**********maping T-table with CP=table******** 
  
 Dim x1 As Integer, y As Integer, z As Integer, pos As Integer 
 Dim RFName As String, RFName1 As String, RFName2 As String 
 Dim RGN As String, RCP As String, b() As Integer, cnt As Integer 
 Dim temp As String, temp1 As String, temp3 As String, temp4 As String 
 Dim Cflag As Integer, Tcnt As Integer 
 Dim tempstr1 As String, tempstr2 As String 
 Dim cmp As String, cmp1 As String 
 Tcnt = 0 
 Cflag = 0 
  
 For x1 = 0 To UBound(GNNames) 
    RGN = GNNames(x1) 
    RCP = CPNames(x1) 
    cmp = "" 
    cmp1 = "" 
    tempstr1 = "" 
    tempstr2 = Replace(RGN, "-GN", "") 

 
163
    RFName = "" 
        For y = 0 To UBound(FNames) 
            tempstr1 = (Right(FNames(y), 1)) 
        If tempstr1 = Right(Left(tempstr2, 2), 1) Then 
            
            RFName = (RFName + Left(FNames(y), 1) + Right(FNames(y), 1)) 
           
            tempstr2 = Mid(tempstr2, 3, Len(tempstr2)) 
            tempstr1 = "" 
            If tempstr2 = "" Then 
           
                RFName1 = RFName + "-GN" 
                RFName2 = RFName + "-CP" 
                cnt = (((Len(RFName)) / 2) - 1) 
                
                    ReDim b(cnt) As Integer 
                
                cnt = 0 
                    For pos = 1 To (Len(RFName)) Step 2 
                        temp = Mid(RFName, pos, 2) 
                        temp1 = "" 
                        temp3 = "" 
                           For z = 0 To UBound(FNames) 
                                temp1 = (Left(FNames(z), 1) + Right(FNames(z), 1)) 
                                If temp1 = temp Then 
                                    temp3 = Mid(temp, 2, 1) 
                                        If temp3 = UBound(a) + 1 Then 
                                          gen = gen + CStr(1) 
                                          b(cnt) = 1 
                                          Cflag = 1 
                                          Tcnt = cnt 
                                          cnt = cnt + 1 
                                        Else 
                                          gen = gen + CStr(a(z)) 
                                          b(cnt) = CInt(a(z)) 
                                          cnt = cnt + 1 
                                        End If 
                                End If 
                           Next 
                    Next 
                     
            End If 
        Else 
            tempstr1 = "" 
        End If 
        If y = UBound(FNames) And tempstr2 <> "" Then 

 
164
          y = -1 
        End If 
        Next 
         
        '*******multiplying condiotnal probability****** 
         
       
            
            If 
Right(Replace((ado_Rset2.Fields(RGN).Name), 
"-GN", 
""), 
2) 
= 
(UBound(FNames) + 1) Then 
                  ado_Rset2.MoveFirst 
                For z = 0 To Pcnt1 
              '  For z = 1 To 3 
                  b(UBound(b)) = z + 1 
                  For j = 0 To UBound(b) 
                    manp = manp + CStr(b(j)) 
                  Next 
                    While Not (ado_Rset2.EOF) 
                        If ado_Rset2.Fields(RGN).Value = manp Then 
                            predcat(z) = predcat(z) * ado_Rset2.Fields(RCP).Value 
                             
                        End If 
                        ado_Rset2.MoveNext 
                    Wend 
                     manp = "" 
                     If z <= Pcnt1 Then 
                   ' If z <= 3 Then 
                    ado_Rset2.MoveFirst 
                    End If 
               Next 
            ElseIf Cflag = 1 Then 
                ado_Rset2.MoveFirst 
                For z = 0 To Pcnt1 
               ' For z = 1 To 3 
                 
                  b(Tcnt) = z + 1 
                  For j = 0 To UBound(b) 
                    manp = manp + CStr(b(j)) 
                  Next 
                    While Not (ado_Rset2.EOF) 
                        If ado_Rset2.Fields(RGN).Value = manp Then 
                            predcat(z) = predcat(z) * ado_Rset2.Fields(RCP).Value 
                          
                        End If 
                       ado_Rset2.MoveNext 
                    Wend 

 
165
                     manp = "" 
                     If z <= Pcnt1 Then 
                     
                    ado_Rset2.MoveFirst 
                    End If 
               Next 
                 
                 
             
            ElseIf Cflag = 0 Then 
             
            ado_Rset2.MoveFirst 
         While Not (ado_Rset2.EOF) 
            If ado_Rset2.Fields(RGN).Value = gen Then 
            For z = 0 To Pcnt1 
                If ado_Rset2.Fields(RCP).Value = 0 Then 
                    predcat(z) = predcat(z) * 1 
                Else 
                predcat(z) = predcat(z) * ado_Rset2.Fields(RCP).Value 
                End If 
            Next 
            End If 
            ado_Rset2.MoveNext 
        Wend 
        End If 
        gen = "" 
        ado_Rset2.MoveFirst 
        Cflag = 0 
 Next 
 '********************************************** 
  
ado_Rset2.Close 
Set ado_Rset2 = Nothing 
 
Call maxpred(predcat(), ado_conn, PredOP, NpdT, NFList2) 
 
End Sub 
 
Procedure for picking the greatest predicted value. 
 
Private Sub maxpred(predcat() As Double, ado_conn As ADODB.Connection, PredOP 
As Object, NpdT As String, NFList2 As Object) 
 
    Dim temp As Integer, temp1 As Double, z1 As Integer, Aicnt As Integer 
    Aicnt = 0 
     

 
166
    If NFList2.ListCount = 0 Then 
        temp = 1 
    Else 
     temp1 = predcat(0) 
        For z1 = 1 To NFList2.ListCount 
            If temp1 > predcat(z1) Then 
                temp1 = temp1 
 
                 temp = z1 
            Else 
                temp1 = predcat(z1) 
                temp = z1 + 1 
                Aicnt = 0 
            End If 
             
        Next 
    End If 
    
    
Call predvalue(temp, ado_conn, PredOP, NpdT, NFList2) 
     
    End Sub 
 
Appending the predicted value to the table 
 
 
Private Sub predvalue(temp As Integer, ado_conn As ADODB.Connection, PredOP As 
Object, NpdT As String, NFList3 As Object) 
    
    Dim perc As Integer, Acc As Double 
     
    Dim ado_rset3 As ADODB.Recordset 
    Set ado_rset3 = New ADODB.Recordset 
      
    'Selecting Record set Properties 
    Set ado_rset3.ActiveConnection = ado_conn 
    ado_rset3.CursorLocation = adUseClient 
    ado_rset3.CursorType = adOpenKeyset 
    ado_rset3.LockType = adLockBatchOptimistic 
    ado_rset3.Source = "SELECT * FROM [" & NpdT & "];" 
     
    ado_rset3.Open 
     
    If flg = 0 Then 'try move 
        ado_rset3.MoveFirst 
        flg = 1 

 
167
        bkMark = ado_rset3.Bookmark 
   End If 
     
            If (temp = ((NFList3.ListCount) + 2)) Then 
                    ado_rset3.MoveFirst 
                    perc = 0 
                    While Not (ado_rset3.EOF) 
                     
                        If ado_rset3.Fields(3).Value = True Then 
                            perc = perc + 1 
                        End If 
                        ado_rset3.MoveNext 
                    Wend 
                 Acc = (perc / (ado_rset3.RecordCount)) * 100 
                 PredOP.Text = FormatNumber(Acc, 2, vbTrue, vbFalse, vbTrue) 
                  
                 
            Else 
             ado_rset3.Bookmark = bkMark 
              
             ado_rset3.Fields("Predictions").Value = temp 
              
             If 
(ado_rset3.Fields("Actual 
Values").Value) 
= 
(ado_rset3.Fields("Predictions").Value) Then 
                ado_rset3.Fields("IsAccurate").Value = True 
                 
             Else 
                ado_rset3.Fields("IsAccurate").Value = False 
             End If 
                ado_rset3.MoveNext 
                If ado_rset3.EOF = False Then 
                    bkMark = ado_rset3.Bookmark 
                End If 
               
            End If 
 
      ado_rset3.UpdateBatch 
      ado_rset3.Fields.Refresh 
       
      'Closing DB 
      ado_rset3.Close 
      
 
      Set ado_rset3 = Nothing 
 
End Sub 

 
168
APPENDIX F 
VB 6 CODE FOR A STAND ALONE GIS VISUALIZATION TOOL 
 
 
 
 
Loading Front End: 
 
Private Sub Form_Load() 
'Load US highways layer. 
 
dc.Database = App.Path  'LOOKING FOR USHIGH1 IN APP.PATH.  EDIT IF 
NECESSARY. 
dc.Connect 
Set gds = dc.FindGeoDataset("county2m") 
  If gds Is Nothing Then 
    MsgBox "cannot find 'ushigh1.shp'.  Edit Form_Load" 
    Exit Sub 
  End If 
Set mlyr.GeoDataset = gds 
mlyr.Symbol.Color = moWhite 
mlyr.Symbol.Style = moTransparent 
Map1.Layers.Add mlyr 
Set dc = Nothing 

 
169
Set gds = Nothing 
Set mlyr = Nothing 
End Sub 
 
Map Selection Button: 
 
Private Sub cmd_DB_Click() 
 
    Cmd_LB.Path = App.Path 
    Cmd_LB.Pattern = "*.DBF" 
 
End Sub 
 
Display Map Button: 
 
Private Sub Cmd_Dspl_Click() 
 
 
dc.Database = App.Path  'LOOKING FOR USHIGH1 IN APP.PATH.  EDIT IF 
NECESSARY. 
dc.Connect 
Set gds = dc.FindGeoDataset(Cmd_LB.FileName) 
  If gds Is Nothing Then 
    MsgBox "cannot find required shape file.  Edit Form_Load" 
    Exit Sub 
  End If 
Set mlyr.GeoDataset = gds 
mlyr.Symbol.Color = moKhaki 
Map1.Layers.Add mlyr 
 
End Sub 
 
Field Selection Button: 
 
Private Sub Cmd_FS_Click() 
     
    Dim moField As MapObjects2.Field 
  For Each moField In Map1.Layers(Cmd_LB.FileName).Records.Fields 
    Fld.AddItem moField.Name 
  Next 
 
     
End Sub 
 
Create Legend Button: 
 

 
170
Private Sub cmdVMR_Click() 
 
'Build a ValueMapRenderer to provide line 
'symbols to the highways based on values 
'in the Roadstatus field.  All of the below 
'is hardcoded, but you can make any of it 
'flexible by using the Strings collection 
'to create a list of unique values, and/or 
'provide color selection tools to the user 
'for them to change the symbology at runtime. 
 
If Not cmdVMR.Caption = "Unsymbolize roads." Then 
 
  Dim vmr As New MapObjects2.ValueMapRenderer 
Dim Cat As Double, CI As Double, Ccat As Double, vcnt As Integer 
 
  'Make the highway legend visible 
  fraHwyLegend.Visible = True 
   
  vmr.Field = Fld.Text 
  vmr.SymbolType = moLineSymbol 
  vmr.UseDefault = True 
  vmr.ValueCount = Txt_Bx.Text 
    Cat = Txt_Bx.Text 
     
    For vcnt = 0 To 9 
        Line2(vcnt).Visible = False 
        Lable1(vcnt).Visible = False 
    Next 
     
  For CI = 0 To (vmr.ValueCount - 1) 
    Line2(CI).Visible = True 
        Lable1(CI).Visible = True 
  vmr.Value(CI) = Cat 
  vmr.Symbol(CI).Style = moSolidLine 
  vmr.Symbol(CI).Color = Line2(Cat - 1).BorderColor 'QBColor(Ccat) 'RGB(fRed, 
fGreen, fBlue) 'Line1(0).BorderColor = QBColor(4) RGB(fRed, fGreen, fBlue) 
  vmr.Symbol(CI).Size = CDbl(1.5) 'CI + 1 '(Line1(0).BorderWidth) 
   
  Cat = Cat - 1 
  Next 
 
 
  With vmr.DefaultSymbol 
    .SymbolType = moLineSymbol 
    .Style = moSolidLine 

 
171
    .Color = moLightGray 
    .Size = 1 
  End With 
   
  'Apply the renderer to the layer and redraw 
  Set Map1.Layers(Cmd_LB.FileName).Renderer = vmr 
  
  Map1.Refresh 
   
  'Change the caption of the highway line button 
  cmdVMR.Caption = "Clear Legend." 
 
 Else 
   
  'Clear the highway layer's renderer and redraw 
  Set Map1.Layers(Cmd_LB.FileName).Renderer = Nothing 
  Map1.Refresh 
 
  'Make the highway legend invisible 
  fraHwyLegend.Visible = False 
   
  'Change the caption of the highway line button 
  cmdVMR.Caption = "Create Legend." 
End If 
 
Set dc = Nothing 
Set gds = Nothing 
Set mlyr = Nothing 
 
End Sub 
 
Code on different operations after various map layers are drawn: 
 
Private Sub Map1_AfterLayerDraw(ByVal index As Integer, ByVal canceled As 
Boolean, ByVal hDC As stdole.OLE_HANDLE) 
     
'Calculate shortest screen length for 
    'highway shields 
    If Map1.Layers.Count > 1 Then 
    Dim minlength As Double 
    Dim ln As MapObjects2.Line 
     Dim lr As New MapObjects2.LabelRenderer 
     Dim pts As MapObjects2.Points 
    minlength = Map1.ToMapDistance(100 * Screen.TwipsPerPixelX) 
 
    'Select only those highways in the current extent 

 
172
    Set 
recs 
= 
Map1.Layers(Cmd_LB.FileName).SearchShape(Map1.Extent, 
moAreaIntersect, "") 
 
    'for each visible highway... 
    recs.MoveFirst 
    Do Until recs.EOF 
 
      '...get the line object itself 
      Set ln = recs.Fields("Shape").Value 
 
      'Only draw a shield if the line length on 
      'screen is greater than 20 screen pixels. 
      If ln.Length > minlength Then 
            ln.SetMeasuresAsLength 
            'Many more properties of the LabelRenderer 
            'you can set if you want to.  This is a start. 
            lr.Field = "ST_RD_NUM_" '"US_RTE_NUM" 
            lr.AllowDuplicates = False 
            lr.SplinedText = False 
             
             
           
            'Bind the LabelRenderer to the Route layer 
            Set Map1.Layers(Cmd_LB.FileName).Renderer = lr 
            Map1.Refresh 
 
      End If 
 
      recs.MoveNext 
    Loop 
   End If 
 
    If Toolbar1.Buttons(5).Value = 1 Then 
    With SymbSel 
    .SymbolType = moPointSymbol 
    .Style = moSolidLine 
    .Color = moYellow 
    End With 
 
 Call Map1.DrawShape(ptClicked, SymbSel) 
 End If 
 
End Sub 
 
 
 

 
173
 
 
Operations of Tool bar Buttons: 
 
Private Sub Map1_MouseDown(Button As Integer, Shift As Integer, X As Single, Y As 
Single) 
 
'Button Method 
If Toolbar1.Buttons(1).Value = 1 Then 
    Set Map1.Extent = Map1.TrackRectangle 
 
ElseIf Toolbar1.Buttons(2).Value = 1 Then 
    Dim rect As MapObjects2.Rectangle, flag As Integer 
    Set rect = Map1.Extent 
    rect.ScaleRectangle (1.5) 
    Set Map1.Extent = rect 
    flag = 1 
ElseIf Toolbar1.Buttons(3).Value = 1 Then 
    Map1.Pan 
ElseIf Toolbar1.Buttons(4).Value = 1 Then 
    Set Map1.Extent = Map1.FullExtent 
 
ElseIf Toolbar1.Buttons(5).Value = 1 Then 
     
  
        'Selecting the point on the road 
         
        Dim strFieldName As String 
        Dim strFieldValue As String 
        Dim i As Integer 
        Dim tol As Double 
         
         
        'Convert mouse click from control coordinates 
        'into map coordinates 
        Set ptClicked = Map1.ToMapPoint(X, Y) 
        tol = Map1.ToMapDistance(1 * Screen.TwipsPerPixelX) 
         
         
         
        'Get the record and feature the mouse clicked on 
        Set recs = Map1.Layers(Cmd_LB.FileName).SearchByDistance(ptClicked, tol, "") 
        'Set recs = Map1.Layers(Cmd_LB.FileName).Records 
            recs.MoveFirst 
        'Populate the list box 
        List1.Clear 

 
174
        If Not recs.EOF Then 
          Set tdesc = recs.TableDesc 
          For i = 0 To tdesc.FieldCount - 1 
            strFieldName = tdesc.FieldName(i) 
            strFieldValue = recs.Fields(strFieldName).ValueAsString 
            List1.AddItem strFieldName & " : " & strFieldValue 
          Next i 
        End If 
         
        Map1.Refresh 
ElseIf Toolbar1.Buttons(6).Value = 1 Then 
        Map1.RefreshLayer 0 
End If 
End Sub 
 
Clear Button: 
 
Private Sub Cmd_Clr_Click() 
    Map1.Layers.Clear 
    Fld.Clear 
    Fld.Text = "Fields" 
    Cmd_LB.Pattern = "*.zzzzz" 
    Txt_Bx.Text = "" 
End Sub 
 
Exit Button: 
 
Private Sub Cmd_Exit_Click() 
    End 
   
End Sub 
 

 
175
 
 
REFERENCES 
 
Abdel-Aty, M.A. and Radwan, E.  Modeling traffic Accident Occurrence and 
Involvement.  Accident Analysis & Prevention, (2000): Vol 32, pp. 633-642. 
 
Abdelwahab, H.T., and Abdel-Aty, M.A.  Development of Artificial Neural Network 
Models to Predict Driver Injury Severity in Traffic Accidents at Signalized Intersections.  
In Transportation Research Record 1746, (2001), TRB National Research Council, 
Washington, D.C. 
 
Al-Masaeid, H.R. (1990). Bayesian Approach to the Estimation of Expected Number of 
Accidents.  Ph.D. Dissertation, Purdue University, 1990. 
 
Aruldhas, J. Examination of Statistical Relationships between Highway Crashes and 
Highway Geometric and Operational Characteristics of Two-Lane Urban Highways. 
Ph.D. Dissertation, University Of Florida, 1998. 
 
Badard, T and Richard, D.  Using XML for the Exchange of Updating Information 
between Geographical Information Systems. Computer, Environmental and Urban 
Systems, (2001), Vol 25,  pp. 17-31. 
 
Brose, C.A. Geographic Information Systems for Spatial Analysis of Traffic Collision 
Locations in La Crosse, Wisconsin, 2001,  Saint Mary’s University of Minnesotta. 
 
Brown, B. Farley, C., and Forgues. M.  Identification of Dangerous Highway Locations: 
Results of Community Health Department Study in Quebec. In Transportation Research 
Record 1376, 1992, TRB National Research Council, Washington, D.C., pp. 78-85. 
 
Cadkin, J. Dynamic segmentation in ArcGIS.  ArcUser, July-September 2002, 52-54. 
 
Chong, M.M, A. Abraham, and M. Paorzycki. Traffic Accident Analysis Using Decision 
Trees and Neural Networks. IADIS International Conference on Applied Computing, 
(2004): Volume 2, pp. 39-42. 
 
Duda, O., and P.E. Hart. Pattern Classification (2nd Edition.), John Wiley and Sons, 
New York, 2000. 
 
Fablo, D.L., Queen, L.P. and Blinn, C.R.  Introduction to Data Analysis Using 
Geographic Information Systems, 1991, University of Minnesota. 
 

 
176
Federal Highway Administration (FHWA). GIS based crash referencing and analysis 
system, HSIS summary report. Publication No. FHWA-RD-00-081, 1999 Washington, 
DC.  
 
 
Garber, N. J. The Effect of Speed, Flow, and Geometric Characteristics on Crash Rates 
for Different Types of Virginia Highways. Virginia Transportation Council, 2000 
GIS-Based Crash Referencing and Analysis System, Highway Safety Information System, 
Publication No. FHWA-RD-99-081 February 1999. 
 
Hadi, M.A., Aruldhas. J., Chow. L. F., And Wattleworth, J. A. “Estimating Safety Effects 
Of Cross-Section Design For Various Highway Types Using Negative Binomial 
Regression”. Transportation Research Center, University Of Florida, 1995 
 
Hattori, K., and Takahashi, M.  A New Nearest-Neighbor Rule in the Pattern 
Classification Problem.  Pattern Recognition, 1999, Vol. 32, pp. 425-432. 
 
Higle, J.L., and Witkowski, J.M. Bayesian Identification of Hazardous Locations.  In 
Transportation Research Record 1185, TRB National Research Council, Washington, 
D.C., 1988. 
 
Implementation of GIS-Based Highway Safety Analyses: Bridging the Gap. U.S. 
Department of Transportation, Federal Highway Administration PUBLICATION NO. 
FHWA-RD-01-039 January 2001. 
 
Kalyoncuoglu, S.F., and Tigdemir, M.  An Alternative Approach for Modelling and 
Simlation of Traffic Data: Artificial Neural Networks.  Simulation Modeling Practice and 
Theory, 2004 Vol. 12, pp. 351-362. 
 
Kim, K., and Levine, N.  Using GIS to Improve Highway Safety.  Computer, 
Environmental and Urban Systems, 1996, Vol. 20, No. 4/5, pp. 289-302. 
 
Milton, J., and Mannering, F. The Relationship among Highway Geometrics, Traffic-
Related Elements and Motor-Vehicle Accident Frequencies. Transportation 25, 1998, pp. 
395-413 
 
Mouskos, K. C., Sun, W., and Qu. T. Impact of Access Driveways on Accident Rates At 
Multilane Highways. National Center for Transportation and Industrial Productivity, New 
Jersey Institute of Technology, 1999 
 
Musone, L. Ferrari, A., and Oneta, M. (1999).  An Analysis of urban collisions using an 
artificial intelligence model.  Accident Analysis & Prevention. Vol 31, pp. 705-718. 
 
Nukoolkit, C., Chen, H.C.  Improving Accuracy of Nearest Neighbor Algorithm in 
Highway Accident Prediction”, ANNIE ’2001 for the Proceedings of Smart Engineering 
System Design, Volume 11, pp.763-768, November 2001, St. Louis, Missouri. 
 

 
177
Poch, M., and Mannering, F. Negative Binomial Analysis of Intersection-Accident 
Frequencies. Journal of Transportation Engineering, 1996 
 
Sawalha, Z. Statistical Issues in Traffic Accident Modeling. In Proceedings of the 82th 
Annual Meeting of the Transportation Research Board, January 12-16, Washington, D.C, 
2003 
 
Smith, M. Neural Networks for Statistical Modeling.  Van Nostrand, New York, 1993. 
 
Spring, C. and Hummer, J.  Identification of Hazardous Highway Locations Using 
Knowledge-Based GIS: A Case Study. In Transportation Research Record 1497, TRB 
National Research Council, Washington, D.C., 1995. 
 
Sun, X. Identifying Highway Safety Patterns and Trends with a Crash Data Analysis 
Program. Traffic Records Forum, Denvor CO, July 2003. 
 
Troxel, L. Development of Models to Predict Injury in Roadside Accidents. Ph.D. 
Dissertation, Department of Civil and Environmental Engineering, Vanderbilt University, 
Nashville, Tennessee, 1994. 
 
Utainarumol, S.  GIS Applications for Identifying Hazardous Locations and Evaluating 
Various Hazardous Location Algorithms.  Ph.D. Dissertation. Department of Civil and 
Environmental Engineering, Vanderbilt University, Nashville, Tennessee, 1994. 
 
Vogt, A. and Bared, J.G.  Accident Models for Two-Lane Rural Roads: Segments and 
Intersections.  Publication No. FHWA-RD-98-133. October 1998. 
 
Waite, B & Rocco, A. GIS and pavement management: A concrete relationship. In 
Proceedings of the ESRI User Conference, 1998. San Diego, CA: Environmental Systems 
Research Incorporated. 
 
Zegeer, C. NCHRP Synthesis of Highway Practice 91: Highway Accident Analysis 
Systems. TRB National Research Council, Washington, D.C., 1982. 

 
178
 
 
 
 
BIOGRAPHICAL SKETCH 
 
 
Thobias Sando started his primary studies at Ukonga primary school in Dar Es Salaam, 
Tanzania in 1981 and completed standard seven in 1987.  He then joined Tambaza 
secondary school for ordinary level education from 1988 to 1991.  Mr. Sando attended 
Ilboru High School from 1992 to 1994 where he studied advanced level secondary school 
majoring in Physics, Chemistry and Mathematics. 
 
He joined the University of Dar Es Salaam in September 1995 where he pursued the 
Bachelor of Science in Civil Engineering degree where he graduated in 1999.  He then 
joined Florida State University (FSU) in the spring semester of 2001 for the Masters of 
Science in Civil Engineering degree, majoring in transportation and traffic engineering, 
and graduated in fall, 2002. He then continued with doctoral studies at FSU until fall, 
2005 where he graduated with a Ph.D in Civil Engineering.  He has been involved in 
numerous research projects in the area of transportation engineering since he joined FSU. 
 
 

