Leonie Simpson
Mir Ali Rezazadeh Baee (Eds.)
LNCS 13915
Information Security 
and Privacy
28th Australasian Conference, ACISP 2023 
Brisbane, QLD, Australia, July 5–7, 2023 
Proceedings

Lecture Notes in Computer Science
13915
Founding Editors
Gerhard Goos
Juris Hartmanis
Editorial Board Members
Elisa Bertino, Purdue University, West Lafayette, IN, USA
Wen Gao, Peking University, Beijing, China
Bernhard Steffen
, TU Dortmund University, Dortmund, Germany
Moti Yung
, Columbia University, New York, NY, USA

The series Lecture Notes in Computer Science (LNCS), including its subseries Lecture
Notes in Artiﬁcial Intelligence (LNAI) and Lecture Notes in Bioinformatics (LNBI),
has established itself as a medium for the publication of new developments in computer
science and information technology research, teaching, and education.
LNCS enjoys close cooperation with the computer science R & D community, the
series counts many renowned academics among its volume editors and paper authors, and
collaborates with prestigious societies. Its mission is to serve this international commu-
nity by providing an invaluable service, mainly focused on the publication of conference
and workshop proceedings and postproceedings. LNCS commenced publication in 1973.

Leonie Simpson · Mir Ali Rezazadeh Baee
Editors
Information Security
and Privacy
28th Australasian Conference, ACISP 2023
Brisbane, QLD, Australia, July 5–7, 2023
Proceedings

Editors
Leonie Simpson
Queensland University of Technology
Brisbane, QLD, Australia
Mir Ali Rezazadeh Baee
Queensland University of Technology
Brisbane, QLD, Australia
ISSN 0302-9743
ISSN 1611-3349 (electronic)
Lecture Notes in Computer Science
ISBN 978-3-031-35485-4
ISBN 978-3-031-35486-1 (eBook)
https://doi.org/10.1007/978-3-031-35486-1
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2023
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of
the material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation,
broadcasting, reproduction on microﬁlms or in any other physical way, and transmission or information
storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now
known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors, and the editors are safe to assume that the advice and information in this book
are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the
editors give a warranty, expressed or implied, with respect to the material contained herein or for any errors
or omissions that may have been made. The publisher remains neutral with regard to jurisdictional claims in
published maps and institutional afﬁliations.
This Springer imprint is published by the registered company Springer Nature Switzerland AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

Preface
This volume contains the refereed papers presented at the 28th Australasian Conference
on Information Security and Privacy (ACISP 2023). The conference was held on 5–7
July 2023, in Brisbane, Australia and hosted by Queensland University of Technology,
who provided excellent facilities and support.
The ACISP conference has been an annual event since 1996, and brings together
security researchers and practitioners from academia, industry and government orga-
nizations for presentation of current developments and challenges in the domain of
information security and privacy. After several years of virtual and hybrid conferences
due to the COVID pandemic restrictions, 2023 marked a return to a physical confer-
ence, with opportunities to network and socialize in addition to the formal program of
presentations.
For ACISP 2023, we made use of the EasyChair submission and reviewing software.
The Program Committee selected 27 research papers from the 87 submissions received,
following a double-blind reviewing process. Each submission received at least three
reviews, and the reviewer feedback was provided to all submitting authors. We thank
all authors of submitted papers - the high quality of the submissions made the task of
selecting a program difﬁcult.
This volume contains the revised versions of the 27 accepted papers. We express
our thanks to Springer for their continued support of ACISP, and for their help with the
conference proceedings production.
We are grateful for the efforts of the Program Committee members and external
reviewers, who applied their knowledge and expertise in reviewing submissions, par-
ticipating in discussions to determine which papers would be selected and providing
feedback to the authors. Our deepest thanks for your efforts. The ACISP-2023 Pro-
gram Committee represents both geographic and gender diversity: members were from
18 nations, and almost 35% of the committee were female. We hope future ACISP
committees will continue to progress towards gender equality.
In addition to the selected research papers, the ACISP-2023 program included four
invited talks on aspects of information security and privacy practice and research. QUT’s
Vice President (Administration) and Registrar, Leanne Harvey, spoke on the December
2022 cyber-attack on QUT. The Cyber Security CRC Research Director, Helge Janicke,
discussed security research collaboration between academia, government and industry.
The historical development of communications security capabilities in government was
outlined, and Lennon Chang (Deakin University) talked about cultural aspects of pri-
vacy. Details of their presentations do not appear in these proceedings. However, we
thank all these speakers for sharing their insight and inspiring continuing research in the
information security and privacy domains.
We acknowledge the contribution of our local organizing committee members: QUT
staff and research students in the Information Security discipline, whose efforts enabled
the smooth running of the conference. We make special mention of a former longstanding

vi
Preface
QUTstaffmember,EdDawson.EdhadalonginvolvementwithACISP,andwasinvolved
in the planning for ACISP 2023. Sadly, he passed away earlier this year. He will be greatly
missed.
July 2023
Leonie Simpson
Mir Ali Rezazadeh Baee

Organization
General Chair
Josef Pieprzyk
Commonwealth Scientiﬁc and Industrial Research
Organization, Data61, Australia
Publication Chairs
Leonie Simpson
Queensland University of Technology, Australia
Mir Ali Rezazadeh Baee
Queensland University of Technology, Australia
Program Committee Chairs
Leonie Simpson
Queensland University of Technology, Australia
Mir Ali Rezazadeh Baee
Queensland University of Technology, Australia
Program Committee Members
Cristina Alcaraz
University of Malaga, Spain
Elena Andreeva
Technische Universität Wien, Austria
Man Ho Au
University of Hong Kong, Hong Kong
Shi Bai
Florida Atlantic University, USA
Harry Bartlett
Queensland University of Technology, Australia
Lejla Batina
Radboud University, The Netherlands
Rishiraj Bhattacharyya
University of Birmingham, UK
Colin Boyd
Norwegian University of Science and Technology,
Norway
Rongmao Chen
National University of Defense Technology,
China
Chitchanok Chuengsatiansup
University of Melbourne, Australia
Amy Corman
RMIT University, Australia
Craig Costello
Microsoft Research, USA
Hui Cui
Murdoch University, Australia
Edward Dawson
Queensland University of Technology, Australia
Josep Domingo-Ferrer
Universitat Rovira i Virgili, Spain

viii
Organization
Rafael Dowsley
Monash University, Australia
Keita Emura
National Institute of Information and
Communications Technology, Japan
Ernest Foo
Grifﬁth University, Australia
Debin Gao
Singapore Management University, Singapore
Joanne Hall
RMIT University, Australia
Jinguang Han
Southeast University, China
Jingnan He
Institute of Information Engineering of Chinese
Academy of Sciences, China
Swee-Huay Heng
Multimedia University, Malaysia
Xiaolu Hou
Slovak University of Technology, Slovakia
Qiong Huang
South China Agricultural University, China
Malika Izabachène
Cosmian, France
Zahra Jadidi
Grifﬁth University, Australia
Angelos Keromytis
Georgia Institute of Technology, USA
Dan Kim
University of Queensland, Australia
Veronika Kuchta
Florida Atlantic University, USA
Fabien Laguillaumie
University of Montpellier, LIRMM, France
Hyung Tae Lee
Chung-Ang University, South Korea
Yannan Li
University of Wollongong, Australia
Yingjiu Li
University of Oregon, USA
Shengli Liu
Shanghai Jiao Tong University, China
Yuhong Liu
Santa Clara University, USA
Rongxing Lu
University of New Brunswick, Canada
Xianhui Lu
Institute of Information Engineering, CAS, China
Siqi Ma
University of New South Wales, Australia
Mitsuru Matsui
Mitsubishi Electric, Japan
Matthew McKague
Queensland University of Technology, Australia
Weizhi Meng
Technical University of Denmark, Denmark
Chris Mitchell
Royal Holloway, University of London, UK
Kirill Morozov
University of North Texas, USA
Khoa Nguyen
University of Wollongong, Australia
Lei Pan
Deakin University, Australia
Dimitrios Papadopoulos
Hong Kong University of Science and
Technology, Hong Kong
Udaya Parampalli
University of Melbourne, Australia
Josef Pieprzyk
CSIRO/Data61, Australia
Indrakshi Ray
Colorado State University, USA
Adeline Roux-Langlois
CNRS, IRISA, France
Reihaneh Safavi-Naini
University of Calgary, Canada
Amin Sakzad
Monash University, Australia
Pierangela Samarati
Università degli Studi di Milano, Italy

Organization
ix
Luisa Siniscalchi
Technical University of Denmark, Denmark
Daniel Slamanig
Austrian Institute of Technology, Austria
Jill Slay
University of South Australia, Australia
Willy Susilo
University of Wollongong, Australia
Vanessa Teague
Australian National University, Australia
Ding Wang
Nankai University, China
Huaxiong Wang
Nanyang Technological University, Singapore
Guomin Yang
Singapore Management University, Singapore
Yuval Yarom
University of Adelaide, Australia
Xun Yi
RMIT University, Australia
Quan Yuan
University of Tokyo, Japan
Tsz Hon Yuen
University of Hong Kong, Hong Kong
External Reviewers
Léo Ackermann
Kanwal Aslam Syed
Sepideh Avizheh
Syed Badruddoja
Anuhbab Baksi
Priyanka Dutta
Sabyasachi Dutta
Jonathan Eriksen
Rami Haffar
Preston Haffey
Pavol Helebrandt
Kai Hu
Ryoma Ito
Hansraj Jangir
Dingding Jia
Yinhao Jiang
Elena Kirshanova
Jiahao Liu
Jinyu Lu
Xingye Lu
Tran Ngo
Cong Peng
Octavio Pérez-Kempner
Simone Perriello
Lucas Prabel
Sebastian Ramacher
Krijn Reijnders
Partha Sarathi Roy
Syh-Yuan Tan
Sulani Thakshila
Monika Trimoska
Peng Wang
Kexin Xu
Yanhong Xu
Haiyang Xue
Xiao Yang
Liu Zhang
Yafei Zheng
Local Organizing Committee Chairs
Leonie Simpson
Queensland University of Technology, Australia
Mir Ali Rezazadeh Baee
Queensland University of Technology, Australia

Contents
Symmetric-Key Cryptography
Improved Differential Cryptanalysis on SPECK Using Plaintext Structures . . . .
3
Zhuohui Feng, Ye Luo, Chao Wang, Qianqian Yang, Zhiquan Liu,
and Ling Song
Linear Cryptanalysis and Its Variants with Fast Fourier Transformation
Technique on MPC/FHE/ZK-Friendly Fp-Based Ciphers . . . . . . . . . . . . . . . . . . . .
25
Zeyu Xu, Shiyao Chen, Meiqin Wang, and Puwen Wei
A New Correlation Cube Attack Based on Division Property . . . . . . . . . . . . . . . . .
53
Cheng Che and Tian Tian
The Triangle Differential Cryptanalysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
72
Xiaofeng Xie and Tian Tian
Key Recovery Attacks on Grain-Like Keystream Generators with Key
Injection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
89
Matthew Beighton, Harry Bartlett, Leonie Simpson,
and Kenneth Koon-Ho Wong
Related-Cipher Attacks: Applications to Ballet and ANT . . . . . . . . . . . . . . . . . . . .
109
Yongxia Mao, Wenling Wu, Yafei Zheng, and Lei Zhang
Cryptanalysis of SPEEDY . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
124
Jinliang Wang, Chao Niu, Qun Liu, Muzhou Li, Bart Preneel,
and Meiqin Wang
Reconsidering Generic Composition: The Modes A10, A11 and A12 are
Insecure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
157
Francesco Berti
Exploring Formal Methods for Cryptographic Hash Function
Implementations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
177
Nicky Mouha

xii
Contents
Public-Key Cryptography
A Tightly Secure ID-Based Signature Scheme Under DL Assumption
in AGM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
199
Jia-Chng Loh, Fuchun Guo, Willy Susilo, and Guomin Yang
Compact Password Authenticated Key Exchange from Group Actions
. . . . . . . .
220
Ren Ishibashi and Kazuki Yoneyama
Multi-key Homomorphic Secret Sharing from LWE Without Multi-key HE . . . .
248
Peiying Xu and Li-Ping Wang
Identity-Based Encryption from Lattices Using Approximate Trapdoors . . . . . . .
270
Malika Izabachène, Lucas Prabel, and Adeline Roux-Langlois
Homomorphic Signatures for Subset and Superset Mixed Predicates
and Its Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
291
Masahito Ishizaka and Kazuhide Fukushima
Adaptively Secure Identity-Based Encryption from Middle-Product
Learning with Errors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
320
Jingjing Fan, Xingye Lu, and Man Ho Au
Post-Quantum Cryptography
Quantum-Access Security of Hash-Based Signature Schemes . . . . . . . . . . . . . . . .
343
Quan Yuan, Mehdi Tibouchi, and Masayuki Abe
Tightly Secure Lattice Identity-Based Signature in the Quantum Random
Oracle Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
381
Ernest Foo and Qinyi Li
Ghidle: Efﬁcient Large-State Block Ciphers for Post-quantum Security . . . . . . . .
403
Motoki Nakahashi, Rentaro Shiba, Ravi Anand, Mostaﬁzar Rahman,
Kosei Sakamoto, Fukang Liu, and Takanori Isobe
Quantum Algorithm for Finding Impossible Differentials
and Zero-Correlation Linear Hulls of Symmetric Ciphers . . . . . . . . . . . . . . . . . . . .
431
Huiqin Chen, Yongqiang Li, Parhat Abla, Zhiran Li, Lin Jiao,
and Mingsheng Wang
Memory-Efﬁcient Quantum Information Set Decoding Algorithm . . . . . . . . . . . .
452
Naoto Kimura, Atsushi Takayasu, and Tsuyoshi Takagi

Contents
xiii
Cryptographic Protocols
CSI-SharK: CSI-FiSh with Sharing-friendly Keys . . . . . . . . . . . . . . . . . . . . . . . . . .
471
Shahla Atapoor, Karim Baghery, Daniele Cozzo, and Robi Pedersen
Practical Veriﬁable Random Function with RKA Security . . . . . . . . . . . . . . . . . . .
503
Tsz Hon Yuen, Shimin Pan, Sheng Huang, and Xiaoting Zhang
Statistically Consistent Broadcast Authenticated Encryption with Keyword
Search: Adaptive Security from Standard Assumptions . . . . . . . . . . . . . . . . . . . . . .
523
Sayantan Mukherjee
Modular Design of KEM-Based Authenticated Key Exchange . . . . . . . . . . . . . . .
553
Colin Boyd, Bor de Kock, and Lise Millerjord
Reusable, Instant and Private Payment Guarantees for Cryptocurrencies . . . . . . .
580
Akash Madhusudan, Mahdi Sedaghat, Samarth Tiwari, Kelong Cong,
and Bart Preneel
System Security
BinAlign: Alignment Padding Based Compiler Provenance Recovery . . . . . . . . .
609
Maliha Ismail, Yan Lin, DongGyun Han, and Debin Gao
Encrypted Network Trafﬁc Classiﬁcation with Higher Order Graph Neural
Network . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
630
Zulu Okonkwo, Ernest Foo, Zhe Hou, Qinyi Li, and Zahra Jadidi
Author Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
651

Symmetric-Key Cryptography

Improved Diﬀerential Cryptanalysis
on SPECK Using Plaintext Structures
Zhuohui Feng1, Ye Luo1, Chao Wang1, Qianqian Yang2,3, Zhiquan Liu1,
and Ling Song1,4(B)
1 College of Cyber Security, Jinan University, Guangzhou, China
songling.qs@gmail.com
2 State Key Laboratory of Information Security, Institute of Information
Engineering, Chinese Academy of Sciences, Beijing, China
yangqianqian@iie.ac.cn
3 School of Cyber Security, University of Chinese Academy of Sciences,
Beijing, China
4 National Joint Engineering Research Center of Network Security Detection
and Protection Technology, Jinan University, Guangzhou, China
Abstract. Plaintext structures are a commonly-used technique for
improving diﬀerential cryptanalysis. Generally, there are two types
of plaintext structures: multiple-diﬀerential structures and truncated-
diﬀerential structures. Both types have been widely used in cryptanal-
ysis of S-box-based ciphers while for SPECK, an Addition-Rotation-XOR
(ARX) cipher, the truncated-diﬀerential structure has not been used
so far. In this paper, we investigate the properties of modular addition
and propose a method to construct truncated-diﬀerential structures for
SPECK. Moreover, we show that a combination of both types of structures
is also possible for SPECK. For recovering the key of SPECK, we propose
dedicated algorithms and apply them to various diﬀerential distinguish-
ers, which helps to obtain a series of improved attacks on all variants of
SPECK. The results show that the combination of both structures helps
to improve the data and time complexity at the same time, as in the
cryptanalysis of S-box-based ciphers.
Keywords: ARX ciphers · structures · diﬀerential cryptanalysis ·
SPECK · symmetric cryptography
1
Introduction
Symmetric ciphers play a major role in providing conﬁdentiality. According to
the nonlinear operation used in the cipher, one popular category of symmetric
ciphers is S-box-based ciphers and another is ARX ciphers that are built using
only modular additions, bit rotations, and bitwise XORs. When a symmetric
cipher is designed, the only way to build conﬁdence in it is through a continuous
eﬀort to evaluate its security.
Z. Feng and Y. Luo—These authors contributed equally to this work.
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 3–24, 2023.
https://doi.org/10.1007/978-3-031-35486-1_1

4
Z. Feng et al.
There are several families of attack against symmetric ciphers. Among them,
diﬀerential cryptanalysis [4] and linear cryptanalysis [19] are the two major
ones. Many attacks can usually be divided into two parts: a distinguisher and
a key-recovery part. Speciﬁcally, a diﬀerential distinguisher constitutes a high-
probability diﬀerential in a part of a cipher, say a diﬀerential ρ →δ over Ed
as shown in Fig. 1. The key-recovery part usually involves the rounds before
and after the distinguisher, i.e., Eb and Ef in Fig. 1. The idea is to guess the
subkeys of Eb and Ef, and check if the diﬀerential ρ →δ occurs with a high
probability for Ed. If so, the key guess is likely correct. This paper focuses on
the key-recovery part.
Eb
Ed
Ef
ρ
δ
ρ′
δ′
nb
nf
Fig. 1. Overview of diﬀerential attacks
Plaintext Structures. Along with the invention of diﬀerential cryptanalysis,
structures of plaintexts are used to improve the attack. Roughly, two types of
structures were proposed and widely used in the literature. Before we recall the
two types, we deﬁne a ratio Rm/p between the number of messages and the
number of message pairs that satisfy the input diﬀerence of the distinguisher.
Then the data complexity is the product of Rm/p and the number of required
pairs satisfying the input diﬀerence.
Multiple-diﬀerential structures (Type-I) This type of plaintext structures
is applied to the case where the target cipher E = Ef ◦Ed. Without using this
type of structures, a pair costs two messages, i.e., Rm/p = 2. When this type
of structures is used, the ratio Rm/p is expected to be lower than 2. A typical
situation is that several diﬀerential trails over Ed are used simultaneously [5].
Suppose we use two trails with input diﬀerences Δ1 and Δ2. If we prepare N
pairs of plaintexts for each input diﬀerence separately, it takes 4N plaintexts
in total. However, when we pack them into structures, we can get 2 pairs for
each input diﬀerence from a structure of 4 plaintexts, resulting in Rm/p = 1.
That is to say, the use of Type-I structure helps to reduce the data complexity
and potentially the time complexity. Note, this type of structures was ﬁrst
used in the diﬀerential attack on 15-round DES [5].
Truncated-diﬀerential structures (Type-II) The second type of plaintext
structures is applied to the case where the target cipher E = Ef ◦Ed ◦Eb
or E = Ed ◦Eb, i.e., there are some rounds before the distinguisher. As
illustrated in Fig. 1, the input diﬀerence ρ of the distinguisher propagates
backward to ρ′ through Eb, where nb bits of ρ′ are active. A structure of this

Improved Diﬀerential Cryptanalysis on SPECK Using Plaintext Structures
5
type consists of 2nb plaintexts where inactive bits are constant while active
bits are traversed. Among each structure of 2nb plaintexts, about 2nb−1 out
of 22nb−1 pairs satisfy the input diﬀerence ρ of the distinguisher. In order to
have N pairs of plaintexts leading to ρ, still 2N plaintexts are needed. That
is to say, both Rm/p and the data complexity remain the same. The possible
gain is to attack more rounds or reduce the time complexity. Note, this type
of structures was used to reach a full-round diﬀerential attack on DES [6].
As a common technique, both types of plaintext structures have been widely
used in the cryptanalysis of S-box-based ciphers, e.g., [5,7]. For ARX ciphers,
Type-I structures have been used to reduce the data complexity of diﬀerential-
like attacks on a series of ARX ciphers, like Chaskey [17] and SPECK [14],
and Type-II structures have been used to mount impossible diﬀerential attacks
and truncated diﬀerential attacks on ARX ciphers, such as XTEA, TEA and
HIGHT [10,15,20]. However, to the best of our knowledge, Type-II structures
have not been applied to SPECK.
In diﬀerential cryptanalysis of ARX ciphers, extending some rounds before
the distinguisher is possible, but it may bring no beneﬁt in the general case. The
problem is that these ciphers typically have 32-bit or 64-bit words. Even though
the input diﬀerence ρ of the distinguisher may have a few active bits, full-word
subkeys of Eb have to be guessed to ensure the ρ diﬀerence. In other words,
adding rounds before the distinguisher brings no beneﬁt (compared to adding
rounds after the distinguisher). Therefore, this usually does not give eﬃcient
attacks. In this paper, we study in which case the Type-II structures can be
applied to SPECK and what beneﬁts they can bring.
SPECK. SPECK is a family of ARX ciphers which were designed in 2013 by
researchers from the U.S. National Security Agency (NSA) [3]. Its structure
is a generalized Feistel structure and it provides excellent performance in both
hardware and software. Since the design of SPECK, it has attracted intensive
cryptanalysis from the community [1,8,9,11,13,18,22,24]. Besides these classi-
cal cryptanalysis, there also exist some cryptanalysis using deep learning [2,14]
whose basis are diﬀerential characteristics. So far, diﬀerential-like cryptanalysis
is the most powerful attack against SPECK. Note that none of the previous dif-
ferential attacks employ the Type-II structures in the key-recovery attacks on
SPECK.
1.1
Our Contributions
We start with studying the diﬀerential properties of modular addition. Due to
the fact of modular addition that the lower bits of the output are aﬀected only
by the lower bits of the inputs, the diﬀerential propagation can be conﬁned to
the higher bits when the inputs have zero diﬀerence in the lower bits. We then
introduce two parameters nBIL and nFIL to denote the numbers of inactive lower
bits for the output of modular subtraction and addition, respectively. Based on
these properties of modular addition, we formalize the construction of Type-II
structures for SPECK. Moreover, we show that Type-II structures and Type-I
structures can be combined for ARX ciphers and applied to SPECK.

6
Z. Feng et al.
Further, we propose three algorithms for key recovery attacks on SPECK, i.e.,
Algorithm A, B and C, which target the cases using Type-I structures, Type-II
structures, and a combination of both, respectively. Algorithm A mainly achieves
the goal of reducing the data complexity when compared with previous attacks.
The aim of Algorithm B is to utilize Type-II structures so as to reduce the time
complexity. Algorithm C combines the ideas of Algorithm A and B and helps to
improve the data and time complexity at the same time. Note the improvement
in the time complexity is proportional to nBIL and nFIL.
In order to prepare suitable distinguishers of SPECK for these three algorithms,
we particularly search for diﬀerential trails with nBIL and nFIL as large as possible
and show them in [12]. We then mount attacks by applying the three algorithms
to newly obtained diﬀerential distinguishers. The resulting attacks on SPECK and
the previous works are presented in Table 1. More detailed results on SPECK in
this work are displayed in Table 8. The results show that the use of Type-II
structures helps to reduce the time complexity by a factor up to 215 and in
many cases, both the time and data complexity are reduced to a certain extent.
Our work shows that Type-II structures are possible for SPECK and help
to improve the time complexity in certain cases. Their application should not
be limited to standard diﬀerential cryptanalysis of SPECK. Other attacks to
which Type-II structures can be potentially applied include boomerang attacks,
diﬀerential-linear attacks, impossible diﬀerential attacks, etc.
Table 1. Comparison of our attacks on SPECK with the previous works
Variants Rounds Probability Data
Time
Memory Reference
32/64
14/22
2−30
231
263
222
[11]
14/22
2−29.47
230.47
262.47
222
[22]
14/22
2−29.37
231.75
260.99
241.91
[9]
14/22
2−27.68
230.26 260.58 236
This
15/22
2−30.39
231.39
263.39
222
[16]
15/22
2−30.39
231.39
262.25
-
[9]
48/72
15/22
2−45
246
270
222
[13]
15/22
2−44.31
245.31
269.31
222
[22]
15/22
2−43.42
244.42 270
222
This
16/22
2−46.80
247.80
271.80
222
[16]
16/22
2−45.78
246.78 271.78 222
This
48/96
16/23
2−45
246
294
222
[13]
16/23
2−44.31
245.31
293.31
222
[22]
16/23
2−43.42
244.42 294
222
This
17/23
2−46.80
247.80
295.80
222
[16]
17/23
2−45.78
246.78 295.78 222
This
(continued)

Improved Diﬀerential Cryptanalysis on SPECK Using Plaintext Structures
7
Table 1. (continued)
Variants Rounds Probability Data
Time
Memory Reference
64/96
19/26
2−62
263
295
222
[13]
19/26
2−59.30
261.88
293.34
268
This
19/26
2−60.56
261.56
293.56
222
[22]
19/26
2−58.24
260.82
292.28
268
This
64/128
20/27
2−62
263
2127
222
[13]
20/27
2−59.30
261.88
2125.34 268
This
20/27
2−60.56
261.56
2125.56
222
[22]
20/27
2−60.73
263.96
2122.69
277.19
[9]
20/27
2−58.24
260.82
2124.28
268
This
96/96
19/28
2−87
288
288
222
[13]
19/28
2−86
287
288
222
This
20/28
2−94.94
295.94
295.94
222
[22]
20/28
2−92.17
293.17
295.75
222
This
96/144
20/29
2−87
288
2136
222
[13]
20/29
2−86
287
2136
222
This
21/29
2−94.94
295.94
2143.94
222
[22]
21/29
2−92.17
293.17
2143.75 222
This
21/29
2−91.03
293.61
2143.13 299
This
128/128
22/32
2−119
2120
2120
222
[13]
22/32
2−117
2118
2120.81
222
This
23/32
2−124.35
2125.35
2125.35
222
[22]
23/32
2−121.37
2122.37 2124.95 222
This
128/192
23/33
2−119
2120
2184
222
[13]
23/33
2−117.19
2119.77 2168.35 2131
This
24/33
2−124.35
2125.35
2189.35
222
[22]
24/33
2−121.37
2123.95 2174.53 2129
This
128/256
24/34
2−119
2120
2248
222
[13]
24/34
2−117.19
2119.77 2232.35 2131
This
25/34
2−124.35
2125.35
2253.35
222
[22]
25/34
2−121.37
2123.95 2238.53 2129
This
Organization. The paper is organized as follows. In Sect. 2, we introduce some
preliminaries, including notations, and a description of SPECK. In Sect. 3, we
study the properties of modular addition and propose some propositions, based
on which Type-II structures and a combination of both types of structures can
be constructed for SPECK. In Sect. 4, we introduce three key recovery algorithms
for SPECK using diﬀerent types of structures. We apply them to all variants of
SPECK and obtain a series of improved attacks in Sect. 5. Finally, we conclude
this work in Sect. 6.

8
Z. Feng et al.
2
Preliminaries
2.1
Notations
Given an n-bit word x, we denote its ith bit for i ∈{0, 1, ..., n −1} by x[i] and
its ith bit to jth bit by x[j : i], i ≤j. Given two n-bit words x and y, we denote
by x ⊞y their addition modulo 2n, by x ⊟y their modular subtraction, by x ⊕y
the bitwise XOR operation, by x ∨y the bitwise OR operation and by x ∧y
the bitwise AND operation between them. Given an n-bit word x and a positive
integer i, we denote by x ≫i the n-bit word obtained by rotating x by i bits
to the right, and by x ≪i the word obtained by rotating x to the left.
In this paper, we denote the ith round of SPECK by Round i where i ∈
{1, 2, . . . , T}. The output of Round i is denoted by xi and yi.
2.2
Speciﬁcation of SPECK
SPECK is a family of lightweight block ciphers designed by researchers from the
U.S. National Security Agency (NSA) [3]. There are 10 variants, each of which
is characterized by its block size 2n and key size mn. Some parameters for all
variants of SPECK are speciﬁed in Table 2.
Table 2. The parameters of SPECK
block size 2n key size mn
word size n key word size m rot a rot b Rnds T
32
64
16
4
7
2
22
48
72/96
24
3/4
8
3
22/23
64
96/128
32
3/4
8
3
26/27
96
96/144
48
2/3
8
3
28/29
128
128/192/256 64
2/3/4
8
3
32/33/34
The round function of SPECK is deﬁned as:
(xi+1, yi+1) = Rki(xi, yi) = (((xi ≫a)⊞yi)⊕ki, (yi ≪b)⊕((xi ≫a)⊞yi)⊕ki),
where ki is the round key for 0 ≤i < T.
The SPECK key schedule takes an initial m-word master key (lm−2, . . . , l0, k0)
and from it generates a sequence of T round key words k0, . . . , kT −1 as follows:
li+m−1 = (ki ⊞(li ≫a)) ⊕i,
ki+1 = (ki ≪b) ⊕li+m−1, 0 ≤i < T.
From the speciﬁcation of SPECK, two simple properties can be obtained
directly.
Property 1. If the output of Round i + 1, i ≥0 is known, i.e., (xi+1, yi+1) is
known, one of the input word yi can be determined by yi = (xi+1 ⊕yi+1) ≫b.

Improved Diﬀerential Cryptanalysis on SPECK Using Plaintext Structures
9
Property 2. If m consecutive round keys of SPECK are known, i.e., ki−m, · · · , ki−1
for i > m, we can eﬃciently invert the key schedule to determine ki−m−1, · · · ,
and so on until we have the original m master key words.
Consequently, the key recovery attacks of SPECK are equivalent to recovering
m consecutive round keys.
3
Properties of Modular Addition and Structures
In this section, we give some properties of modular addition, based on which
one could construct plaintext structures for SPECK as in the cryptanalysis of
S-box-based ciphers.
3.1
Properties of Modular Addition
Given two n-bit words x and y, we let z = x⊞y where the carry word is denoted
by c. Some operation rules about the carry word c are listed as follows:
c[0] = 0,
c[i + 1] = x[i] ∧y[i] ⊕x[i] ∧c[i] ⊕y[i] ∧c[i],
i ∈{0, 1, . . . , n −2},
z[i] = x[i] ⊕y[i] ⊕c[i],
i ∈{0, 1, . . . , n −1}.
With these in mind, we look into the XOR diﬀerences of modular addition.
Let ˜x = x ⊕α, ˜y = y ⊕β, ˜z = ˜x ⊞˜y, and ˜z ⊕z = γ, where α, β and γ are
diﬀerences, as shown in Fig. 2. Let c, ˜c respectively denote the carry words of
x ⊞y, ˜x ⊞˜y and let Δc = c ⊕˜c.
Then we have
γ[i] = z[i] ⊕˜z[i] = x[i] ⊕y[i] ⊕c[i] ⊕˜x[i] ⊕˜y[i] ⊕˜c[i] = α[i] ⊕β[i] ⊕Δc[i].
Fig. 2. The diﬀerences of the modular
addition
Fig. 3. The diﬀerences of Round 2
In the following, we give three propositions of the diﬀerences of modular
addition.

10
Z. Feng et al.
Proposition 1. Let z = x ⊞y and ˜z = ˜x ⊞˜y, where α = x ⊕˜x, β = y ⊕˜y and
γ = z ⊕˜z. Given β, γ where β[j : 0] = γ[j : 0] = 0, 0 ≤j < n, then α[j : 0] = 0.
Proof. When β[0] = 0 and γ[0] = 0, we have α[0] = γ[0] ⊕β[0] ⊕Δc[0] = 0.
Therefore, Δc[1] = 0. Then when β[1] = 0, γ[1] = 0, as α[1] = γ[1] ⊕β[1] ⊕
Δc[1] = 0, we have Δc[2] = 0, and so on.
⊓⊔
Deﬁnition 1 (Backward inactive lower bits (BIL). Under the setting in
Proposition 1, α[j : 0] = 0, 0 ≤j < n. We call α[j : 0] the backward inactive
lower bits for the addition and BIL for short. Denote the length of α[j : 0] in bits
by nBIL.
Proposition 2. Let z = x ⊞y and ˜z = ˜x ⊞˜y, where α = x ⊕˜x, β = y ⊕˜y and
γ = z ⊕˜z. Given β, γ where β[j : 0] = γ[j : 0] = 0 and β[j + 1] ∨γ[j + 1] = 1,
0 ≤j < n −1, then α[j + 1] = β[j + 1] ⊕γ[j + 1] and Pr[α[u] = 1] for any
u ∈(j + 1, n) is non-zero if z and y are taken randomly (or equivalently x, y are
taken randomly).
Proof. According to Proposition 1, we have α[j : 0] = 0 and Δc[j +1] = 0. When
β[j + 1] ∨γ[j + 1] = 1, we have α[j + 1] = β[j + 1] ⊕γ[j + 1] ⊕Δc[j + 1] =
β[j+1]⊕γ[j+1]. We prove the subsequent cases by exhaustive calculation which
is shown in Table 3(a) and 3(b).
i) For u = j + 2, as β[u −1] ∨γ[u −1] = 1 and Δc[u −1] = 0, we have
Pr[Δc[u] = 0] = Pr[Δc[u] = 1] = 1
2, according to Table 3(b);
ii) For u ≥j + 3, let Pr[Δc[u −1] = 1] = p. According to Table 3(b),
a) when (β[u −1], γ[u −1])=(0,0), Pr[Δc[u] = 0] = 1 −p + 1
2p = 1 −1
2p,
Pr[Δc[u] = 1] = 1
2p > 0;
b) when (β[u −1], γ[u −1])=(0,1), Pr[Δc[u] = 0] = 1
2(1 −p) + 1
2p = 1
2,
Pr[Δc[u] = 1] = 1
2p + 1
2(1 −p) = 1
2;
c) when (β[u −1], γ[u −1])=(1,0), Pr[Δc[u] = 0] = 1
2, Pr[Δc[u] = 1] = 1
2;
d) when (β[u −1], γ[u −1])=(1,1), Pr[Δc[u] = 0] = 1
2(1 −p), Pr[Δc[u] =
1] = 1
2(1 −p) + p = 1
2 + 1
2p.
In summary, for any u ∈(j + 1, n), 0 < Pr[Δc[u] = 1] < 1. Therefore, due to
α[u] = β[u]⊕γ[u]⊕Δc[u], we will get α[u] = 0 or α[u] = 1 with certain non-zero
probability.
⊓⊔
Similarly, on the other side we have the following proposition.
Proposition 3. Let z = x ⊞y and ˜z = ˜x ⊞˜y, where α = x ⊕˜x, β = y ⊕˜y and
γ = z ⊕˜z. Given α, β where α[j : 0] = β[j : 0] = 0, 0 ≤j < n, then γ[j : 0] = 0.
Deﬁnition 2 (Forward inactive lower bits (FIL). Under the setting of
Proposition 3, γ[j : 0] = 0, 0 ≤j < n. We call γ[j : 0] the forward inactive
lower bits of the addition and FIL for short. Denote the length of γ[j : 0] in bits
by nFIL.

Improved Diﬀerential Cryptanalysis on SPECK Using Plaintext Structures
11
Table 3. All cases of diﬀerences of carry bits Δc[u] in the modular addition. (a)All
cases of β[u −1] and γ[u −1]. (b)The exhaustive calculation of Δc[u] for all possible
y[u −1], ˜y[u −1], z[u −1], ˜z[u −1], c[u −1], ˜c[u −1] where j + 1 < u.
(a)
ID β[u −1]
γ[u −1]
y[u −1],˜y[u −1]
α[u −1]
z[u −1],˜z[u −1]
Δc[u −1] = 0
Δc[u −1] = 1
1
0
0
0, 0, 0, 0
0
1
2
1, 1, 0, 0
3
0, 0, 1, 1
4
1, 1, 1, 1
5
0
1
0, 0, 0, 1
1
0
6
0, 0, 1, 0
7
1, 1, 0, 1
8
1, 1, 1, 0
9
1
0
0, 1, 0, 0
1
0
10
0, 1, 1, 1
11
1, 0, 0, 0
12
1, 0, 1, 1
13
1
1
0, 1, 0, 1
0
1
14
0, 1, 1, 0
15
1, 0, 0, 1
16
1, 0, 1, 0
(b)
ID
x[u −1], ˜x[u −1], c[u], ˜c[u], (Δc[u])
(c[u −1], ˜c[u −1])
(c[u −1], ˜c[u −1])
(c[u −1], ˜c[u −1])
(c[u −1], ˜c[u −1])
=(0, 0)
=(1, 1)
=(0, 1)
=(1, 0)
1
0, 0, 0, 0 (0)
1, 1, 1, 1 (0)
0, 1, 0, 1 (1)
1, 0, 1, 0 (1)
2
1, 1, 1, 1 (0)
0, 0, 1, 1 (0)
1, 0, 1, 1 (0)
0, 1, 1, 1 (0)
3
1, 1, 0, 0 (0)
0, 0, 0, 0 (0)
1, 0, 0, 0 (0)
0, 1, 0, 0 (0)
4
0, 0, 0, 0 (0)
1, 1, 1, 1 (0)
0, 1, 0, 1 (1)
1, 0, 1, 0 (1)
5
0, 1, 0, 0 (0)
1, 0, 1, 0 (1)
0, 0, 0, 0 (0)
1, 1, 1, 0 (1)
6
1, 0, 0, 0 (0)
0, 1, 0, 1 (1)
1, 1, 0, 1 (1)
0, 0, 0, 0 (0)
7
1, 0, 1, 0 (1)
0, 1, 1, 1 (0)
1, 1, 1, 1 (0)
0, 0, 1, 0 (1)
8
0, 1, 0, 1 (1)
1, 0, 1, 1 (0)
0, 0, 0, 1 (1)
1, 1, 1, 1 (0)
9
0, 1, 0, 1 (1)
1, 0, 1, 1 (0)
0, 0, 0, 1 (1)
1, 1, 1, 1 (0)
10
1, 0, 0, 0 (0)
0, 1, 0, 1 (1)
1, 1, 0, 1 (1)
0, 0, 0, 0 (0)
11
1, 0, 1, 0 (1)
0, 1, 1, 1 (0)
1, 1, 1, 1 (0)
0, 0, 1, 0 (1)
12
0, 1, 0, 0 (0)
1, 0, 1, 0 (1)
0, 0, 0, 0 (0)
1, 1, 1, 0 (1)
13
0, 0, 0, 0 (0)
1, 1, 1, 1 (0)
0, 1, 0, 1 (1)
1, 0, 1, 0 (1)
14
1, 1, 0, 1 (1)
0, 0, 0, 1 (1)
1, 0, 0, 1 (1)
0, 1, 0, 1 (1)
15
1, 1, 1, 0 (1)
0, 0, 1, 0 (1)
1, 0, 1, 0 (1)
0, 1, 1, 0 (1)
16
0, 0, 0, 0 (0)
1, 1, 1, 1 (0)
0, 1, 0, 1 (1)
1, 0, 1, 0 (1)

12
Z. Feng et al.
3.2
Type-II Structures for SPECK
Let us come to the key recovery part of diﬀerential attacks. Given a diﬀerential
ρ →δ of SPECK, suppose we prepend one round to it. For the modular addition
of this extra round, we still denote its diﬀerence propagation by α, β →γ, where
the diﬀerences β and γ should match the input diﬀerence of the diﬀerential.
If β and γ are some random diﬀerences, α will be regarded as random as
well. In terms of notations in Fig. 1, it leads to a large nb, i.e., a large number of
plaintext bits will be active. In contrast, if the lower bits or the least signiﬁcant
bit of β and γ are 0, we can know for sure the same number of lower bits of α
are zero as well, while its higher bits or the most signiﬁcant bit can be either 1
or 0. That is to say, for certain proper diﬀerentials, the number of active bits in
the plaintext can be small.
A common experience in diﬀerential cryptanalysis of S-box-based ciphers is
that a small nb is desirable, so it would be interesting to see the eﬀect of building
Type-II structures on the active higher bits of some input words of SPECK.
In the following, we will show how Type-II structures of SPECK can be built
by exploiting Proposition 1 and 2 and discuss the possibility of applying both
types of structures to ARX ciphers simultaneously.
Type-II Structures for SPECK. Note that the ﬁrst round of SPECK acts as a
whitening layer, so it can be covered for free. Now we consider adding two rounds
before a diﬀerential of SPECK. Suppose the input diﬀerence of the diﬀerential is
ρ = (ρL, ρR) and its probability is 2−w. Further, suppose the input diﬀerence
ρ of the diﬀerential propagates backward to (α, β) marked in Fig. 3 such that,
according to Proposition 1 and 2, α has the form
α = 0b ∗· · · ∗
  
s
c 0 · · · 0
  
n−s−1
,
where 0b indicates that the binary sequence is followed, the most signiﬁcant s
bits of α can take any possible value and c is a known constant. As for β, it can
be computed from ρ and thus is ﬁxed.
We then construct structures at the beginning of the second round. In this
situation, pairs formed from the structures will satisfy the input diﬀerence ρ of
the diﬀerential probabilistically rather than deterministically. We will show that
the required data remains the same as that in Dinur’s attacks [11].
The goal of the data collection phase is to generate pairs (x1, y1) and (x′
1, y′
1)
whose diﬀerence is (α, β). From such pairs, the diﬀerence between (x1 ⊕k0 ≫
a)⊞(y1⊕k0) and (x′
1⊕k0 ≫a)⊞(y′
1⊕k0) is expected to equal γ with probability
2−s under some unknown round keys k0. To achieve this, we could generate such
pairs using twin structures:
S = {(x1, y1)|x1[n −s −1 : 0], y1 = c1, x1[n −1 : n −s] ∈{0, 1}s},
S′ = S ⊕Δ = {(x′
1, y′
1)|(x1, y1) ∈S, x′
1[n −s −1 : 0] = x1[n −s −1 : 0] ⊕c0 · · · 0,
y′
1 = y1 ⊕β, x′
1[n −1 : n −s] ∈{0, 1}s}, where Δ = 0b0 · · · 0c0 · · · 0||β.
(1)

Improved Diﬀerential Cryptanalysis on SPECK Using Plaintext Structures
13
From such a pair of twin structures, we can generate 22s pairs of (x1, y1) and
(x′
1, y′
1), and 2s pairs are expected to lead to γ, meeting the input diﬀerence of
the distinguisher.
Suppose 2t pairs of twin structures are used. We need 2w pairs of (x1, y1)
and (x′
1, y′
1) that satisfy the input diﬀerence of the distinguisher to have at least
one right pair for the diﬀerential. Therefore, 2s+t = 2w and s + t = w. The total
data complexity for 2t pairs of twin structures is D = 2t+s+1 = 2w+1, which is
the same as that in Dinur’s attacks. This conﬁrms again that Type-II structures
do not help to reduce the data complexity. Therefore, in this paper, the purpose
of using Type-II structures is not to reduce the data complexity, but to reduce
the time complexity. This will be shown in Sect. 4.2.
3.3
Combining both Types of Structures
Recall that the use of Type-I structures helps to reduce the data complexity.
What if we use both types of structures simultaneously? Can we reduce the time
and data complexity at the same time?
Suppose we have two diﬀerentials (ρ1 →δ) and (ρ2 →δ) of the same prob-
ability for SPECK and ρ1 and ρ2 propagate back over one round to (α1, β1) and
(α2, β2), respectively, where α1 and α2 share the same number of zero bits in
the lower part. Then we choose four structures as follows:
S, S ⊕Δ1, S ⊕Δ2, S ⊕Δ1 ⊕Δ2,
(2)
where Δ1 and Δ2 are derived from (α1, β1) and (α2, β2) in a way presented in
Eq. (1). Actually, these four sets form a Type-I structure of Type-II structures.
If the size of each Type-II structure is 2s, then we can get about 2 × 2s pairs
satisfying ρ1 and about 2 × 2s pairs satisfying ρ2. Now the ratio between the
number of messages and the number of message pairs meeting one of the input
diﬀerences becomes 1, i.e., Rm/p = 1. Generally, if there are h diﬀerentials,
Rm/p =
2
h, which is much lower than 2. This shows that the combination of
both types of structures may bring beneﬁts of each together.
4
New Key Recovery Algorithms for SPECK
In this section, we propose three generic key recovery algorithms for SPECK which
respectively use Type-I structures, Type-II structures and a combination of both
types of structures. In these algorithms, we reuse the 2-round attack proposed
by Dinur in [11]. In particular, we will highlight the beneﬁt each algorithm may
bring.

14
Z. Feng et al.
4.1
Algorithm a Using Type-I Structures
input diff., single output diff.
Multiple input diff., multiple output diff.
Fig. 4. Two examples where Type-I structures can be applied
Suppose we have a set of h diﬀerentials {ρj →δ} for j = 1, · · · , h over r rounds
and the corresponding probabilities are pj where h
j=1 pj = ˆp = 2−ˆ
w, as given
in the left part of Fig. 4. Moreover, this case can also be extended to that with
multiple output diﬀerences (see the right part of Fig. 4). Suppose we have g
output diﬀerences δi, i = 1, · · · , g. Each output diﬀerence δi corresponds to hi
input diﬀerences, i.e., {ρi,j →δi} of probability pi,j for j = 1, · · · , hi. Let

i,j
pi,j = ˆp = 2−ˆ
w, H = h1 + · · · + hg.
Suppose among the H input diﬀerences ρi,js, H′ of them are linearly independent
when we treat them as binary vectors. We can attack 1+r +m rounds following
the procedure below.
For i = 1, · · · , 2t:
1. Construct a structure S of 2H′ data by taking the H′ independent input
diﬀerences ρi,j as a basis.
2. Guess the last m−2 round keys. Do partial decryptions to have intermediate
values (xr+3, yr+3).
(a) For each input diﬀerence ρi,j and each output diﬀerence δi, j = 1, · · · , hi,
i = 1, · · · , g, generate 2hi−1 × 2H′−hi pairs of (P, P ′) meeting ρi,j. For
each pair,
i. Run the 2-round attack of [11] using (Δxr+1, Δyr+1)
=
δ,
(Δxr+3, Δyr+3) and (xr+3, yr+3) and return solutions of kr+1 and
kr+2;
ii. For each returned value of kr+1 and kr+2 together with the guessed
m −2 subkeys, recover the master key and test it using trial encryp-
tions, and return it if the trial encryptions succeed.
It takes 2t × 2H′ data and let 2t × 2H′−1 × 
i,j pi,j = 1. Therefore H′ + t =
ˆw + 1. Then we can summarize the complexities of Attack A as follows.
• DA = 2 ˆ
w+1 plaintexts;
• TA = 2t × 2(m−2)n × H × 2H′−1 × 2 = cA · 2(m−2)n+ ˆ
w × H
= cA ·
2(m−2)n
1

i,j pi,j	
/H = cA·2(m−2)n· H
ˆp encryptions, where cA = 2, m = 2, 3, 4;
• MA = max{222, 2H′}.

Improved Diﬀerential Cryptanalysis on SPECK Using Plaintext Structures
15
Example. Table 4 lists some examples which demonstrate the improvement
brought by Algorithm A. In these two attacks on 14-round SPECK32/64, the
probability of all diﬀerential trails we use is 2−30. The result shows the data
complexity is reduced by using Type-I structures.
Table 4. Example of attacks using Algorithm A
Variants Split
#Trails h
g Data
Time Mem. Ref
32/64
1+9+4 1
1
1 231
263
222
[11]
1+9+4 5
5
1 228.68 263
222
Alg. A
1+9+4 15
15 6 227.09 263
222
Alg. A
Experiment. We mainly test whether we can get right pairs as expected. We
construct Type-I structures and use a 5-round distinguisher for the 10-round
SPECK32/64 attack. The experiment results demonstrate that no matter how
many right pairs we set, we can always get the expected number of right pairs.
4.2
Algorithm B Using Type-II Structures
Suppose we have a diﬀerential ρ = (ρL, ρR) →δ = (δL, δR) with probability
p = 2−w. Also, suppose the output diﬀerence δ leads to nFIL forward inactive
lower bits for the addition in the next round and the input diﬀerence results in
nBIL backward inactive lower bits for the addition in the earlier round. The goal
of Algorithm B is to attack 2 + r + (m −1) rounds for m = 3, 4.
Switch to the Counting Method. When we use Type-II structures, there
are two rounds before the distinguisher. If we guess the last m −2 round keys,
the time complexity will exceed 2mn, because we need to process more pairs
than that in Dinur’s attack. Thus, in our attack we only guess the last m −3
round keys. For Round r + 3 and Round r + 4, we can also mount the 2-round
attack to recover round keys kr+2 and kr+3. However, due to Property 2, testing
the recovered round keys using trial encryptions is possible only when we have
information of m consecutive round keys. In this case, we only have the keys of
the last m −1 consecutive rounds (or with the ﬁrst round key). This makes the
enumerating method infeasible.
A way to get around this issue is to switch to the common counting method.
The number of message pairs that meet the input diﬀerence ρ and the output
diﬀerence δ under each possible key value is recorded. The key values with the
highest counters are the likeliest right key. Thus, a shortlist of round key candi-
dates can be obtained according to the counters, which helps to give an eﬃcient
key recovery of the master key.
The Algorithm. In this algorithm, we guess the involved round key bits of k0
which are needed for verifying the input diﬀerence ρ. As the higher bits of both
k0 and k0 ≫a aﬀect the veriﬁcation, more than s = n −nBIL −1 bits of k0

16
Z. Feng et al.
are needed. In the following procedures, we guess these bits of k0 together with
kr+m if m = 4 and make counters for other involved round keys kr+2, kr+3. The
detailed procedures of Algorithm B are as follows.
1. Construct 2t pairs of twin structures (S, S′) in a way described in Eq. 1. Each
structure has 2s plaintext-ciphertext pairs, where s = n −nBIL −1.
2. Guess min{n −nBIL + a, n} bits of k0 and the full kr+m if m = 4. Do partial
encryptions and decryptions.
(a) Initialize counters for kr+2 and kr+3.
(b) For each pair of twin structures:
i. Store the data of one structure into a hash table according to the state
before the key addition of the second round and (xr+4⊕yr+4)[nFIL+b :
b] and look up the table with data from the other structure. There
will be 2s−nFIL−1 pairs of data meeting the input diﬀerence and the
(nFIL + 1)-bit ﬁxed diﬀerence.
ii. For each pair, mount the 2-round attack to recover kr+2, kr+3 and
update the counters.
(c) Select 2ℓ(e.g., l < n) candidates for kr+2, kr+3 with top counters. Guess
kr+1 and test the correctness by trial encryptions.
If we set the number of right pairs to one, then 2t ×2s ×p = 1, t+s = w, and
the data complexity is 2w+1, which is the same as that in Dinur’s attack. If we
want to have a higher success probability, we can increase the data complexity.
For the computation of success probability, we follow the formula in Selçuk’s
work [21] (see Eq. 3 of Sect. 4.3). However, for a convenient comparison of time
complexities between Algorithm B and Dinur’s attack, we simply let the data
complexity be the same (while we may trade the data for a higher success prob-
ability in concrete applications). The memory complexity for storing data and
counters is D + 22n ≈22n, and the time complexity is dominated by step (b)
and (c). Speciﬁcally,
• DB = 2w+1 plaintexts;
• TB = 2(m−3)n+min{n−nBIL+a,n}+t(2s+1+2s−nFIL−1)+2(m−2)n+min{n−nBIL+a,n}+ℓ
encryptions, m = 3, 4;
• MB = 22n for counters.
As the number of candidate keys 2ℓis ﬂexible, it is reasonable to assume the
second term of TB is not dominant. Let us focus on the ﬁrst term. We can see
that if nBIL is greater than the rotation number a, this attack is already more
eﬃcient than Dinur’s attack in terms of time complexity.
Improvement. Note that the time complexities of step (i) and (ii) are 2s+1 and
2s−nFIL−1 under each guess, respectively, which are not balanced. A strategy to
balance them is to guess fewer key bits of k0. There are three types of bits in
k0: bits used once (bits in the red lines in Fig. 5), twice (bits in the blue line in
Fig. 5) and none for verifying ρ diﬀerence. Our strategy is to guess all bits that
are used twice and partial bits that are used once. Let us analyze case by case:

Improved Diﬀerential Cryptanalysis on SPECK Using Plaintext Structures
17
Fig. 5. Guess bits of k0, where bits in the blue line are all guessed and y bits in the
red lines are guessed. (Color ﬁgure online)
• When nBIL ≥a, n−nBIL +a bits of k0 are needed. If we guess n−nBIL −a+y
bits of k0 with 0 ≤y ≤2a, we will get a (n −nBIL −2a + y −1)-bit ﬁlter, i.e.,
an (s −2a + y)-bit ﬁlter, instead of an s-bit ﬁlter. Now the time complexity
of step (ii) becomes 2s−nFIL−1+2a−y. Meanwhile, the number of guessed key
bits of k0 is reduced by 2a −y bits and the memory complexity is increased
by 22a−y.
• When nBIL < a, a full k0 is needed. If we guess n −2nBIL + y bits of k0 with
0 ≤y ≤2nBIL, we will get an (s−2nBIL+y)-bit ﬁlter, instead of an s-bit ﬁlter.
Now the time complexity of step (ii) becomes 2s−nFIL−1+2nBIL−y. Meanwhile,
the number of guessed key bits of k0 is reduced by 2nBIL −y bits and the
memory complexity is increased by 22nBIL−y.
The advantage of Algorithm B over Dinur’s attack in terms of the time
complexity is summarized in Table 5, which is denoted by ad.
Table 5. Advantage of Algorithm B
nBIL ≥a 2a ≥nFIL + 1
y = 2a −nFIL −1
ad = nBIL −a + nFIL + 1
2a < nFIL + 1
y = 0
ad = nBIL + a
nBIL < a 2nBIL ≥nFIL + 1 y = 2nBIL −nFIL −1 ad = nFIL + 1
2nBIL < nFIL + 1 y = 0
ad = 2nBIL
Example. We take the attack on SPECK128/256 as an example, as shown in
Table 6. In the attack a 19-round diﬀerential trail with probability 2−119 is used
where nBIL = 23, nFIL = 2. We mount attacks on 24 rounds using Algorithm
B and set the number of right pairs μ = 3 and let ℓ= 55 so that the success
probability is high (about 90% in the calculation). As can be seen the time
complexity is reduced by using Type-II structures and by taking nBIL, nFIL into
account.

18
Z. Feng et al.
Table 6. Example of attacks using Algorithm B
Variants Split
Prob. nBIL nFIL Data
Time
Mem. Ref
128/256
1+19+4 2−119
-
-
2120
2248
222
[13]
2+19+3 2−119
23
2
2121.58 2231.58 2131
Alg. B
Experiment. Using Algorithm B, we try to mount a 13-round attack on
SPECK32/64 with a 8-round distinguisher. The result shows that the correct key
ranks high. We set μ = 2 and the highest counter is 6. Speciﬁcally, among all
possible keys, 16 values take this count, including the correct key.
4.3
Algorithm C Using Type-I and Type-II Structures
Suppose we have g output diﬀerences δi, i = 1, · · · , g, all of which lead to at least
nFIL forward inactive lower bits for the addition in the next round. Each output
diﬀerence δi corresponds to hi input diﬀerences, i.e., ρi,j →δi of probability
pi,j for j = 1, · · · , hi. Suppose all these input diﬀerences result in at least nBIL
backward inactive lower bits for the addition in the earlier round. Let

i,j
pi,j = ˆp = 2−ˆ
w, H = h1 + · · · + hg.
Suppose among the H input diﬀerences ρi,js, H′ of them are linearly indepen-
dent. The goal is to attack 2 + r + (m −1) rounds for m = 3, 4.
The Algorithm. This algorithm is a combination of Algorithm A and B.
1. Construct 2t Type-I structures of 2H′ Type-II structures and get the cor-
responding ciphertexts. Each type-II structure has 2s plaintexts, where s =
n −nBIL −1.
2. If nBIL ≥a, guess n−nBIL −a+y bits of k0 with 0 ≤y ≤2a; otherwise, guess
n −2nBIL + y bits of k0 with 0 ≤y ≤2nBIL. Guess the full kr+m if m = 4. Do
partial encryptions and decryptions.
(a) Initialize counters for kr+2, kr+3, and 2 × min{a, nBIL} −y bits of k0.
(b) For each Type-I structure, each input diﬀerence ρi,j and each output
diﬀerence δi, i = 1, · · · , g, j = 1, · · · , hi, there are 2hi−1 × 2H′−hi pairs
of twin structures.
i. For each pair of twin structures, store the data of one structure into a
hash table according to the state before the key addition of the second
round and (xr+m ⊕yr+m)[nFIL +b : b] and look up the table with data
from the other structure. Then, when nBIL ≥a (resp. nBIL < a) there
will be 2s−nFIL−1+2a−y (resp. 2s−nFIL−1+2nBIL−y) pairs of data partly
meeting the input diﬀerence and the (nFIL + 1)-bit ﬁxed diﬀerence.
ii. For each pair of data, mount the 2-round attack to recover kr+2, kr+3;
recover other involved bits of k0 by looking up a precomputed table1
1 This precomputed table takes a small memory of 23×(2×min{a,nBIL}−y).

Improved Diﬀerential Cryptanalysis on SPECK Using Plaintext Structures
19
which is created in a way described in the improvement strategy of
Sect. 4.2. Update the counters accordingly.
(c) Select 2ℓ(e.g., ℓ< n) candidates with top counters. Guess kr+1 and test
the correctness by trial encryptions.
It takes 2t ×2H′ ×2s data. For a convenient comparison of time complexities
between Algorithm C and Dinur’s attack, we simply set the number of right pairs
to one. Then we have 2t ×2H′−1 ×2s ×
i,j pi,j = 1 and thus H′ +t+s = ˆw +1.
However, we may trade the data for a higher success probability in attacks
on concrete applications. Assume nFIL is much smaller than s, which holds in
general. Then we can summarize the complexities of Algorithm C as follows.
• DC = 2 ˆ
w+1 plaintexts;
• When nBIL ≥a, TC = 2(m−3)n+n−nBIL−a+y × (2t × H × 2H′−1 × (2s+1 +
2s−nFIL−1+2a−y) + 2n+ℓ)) encryptions for m = 3, 4.
• If 2a ≥nFIL + 1, TC = 2(m−2)n−(nBIL−a+nFIL+1) × ( H
ˆp × 2 + 2n+ℓ).
MC = 22n+nFIL+1 for counters.
• If 2a < nFIL + 1, TC = 2(m−2)n−(nBIL+a) × ( H
ˆp × 2 + 2n+ℓ).
MC = 22n+2a for counters.
• When nBIL < a, TC = 2(m−3)n+n−2nBIL+y × (2t × H × 2H′−1 × (2s+1 +
2s−nFIL−1+2nBIL−y) + 2n+ℓ)) encryptions for m = 3, 4.
• If 2nBIL ≥nFIL + 1, TC = 2(m−2)n−(nFIL+1) × ( H
ˆp × 2 + 2n+ℓ).
MC = 22n+nFIL+1 for counters.
• If 2nBIL < nFIL + 1, TC = 2(m−2)n−2nBIL × ( H
ˆp × 2 + 2n+ℓ).
MC = 22n+2nBIL for counters.
As Algorithm A, the data complexity is reduced. The total advantage of this
attack in time complexity over Dinur’s attack is the same as shown in Algorithm
B of Sect. 4.2.
Data and the Probability of Success. We can calculate the success proba-
bility using the formula in Selçuk’s work,
Ps = Φ

√μSN −Φ−1(1 −2−(nk−ℓ))
√SN + 1

,
(3)
where μ is the number of right pairs, SN is the signal-to-noise ratio, nk is the
number of key bits involved in the key recovery phase, and 2ℓis the size of the
short list of the key candidates.
Notably, to have a competitive probability of success, having one right pair
in the counting based algorithm is usually not enough. Therefore, in concrete
attack we increase the data complexity by a factor μ to μ × 2 ˆ
w+1. We typically
set μ = 3 to have a reasonable success probability. In turn, this increases the
data complexity, probably leading to a data complexity higher than that of the
Dinur’s attack.
Example. We take SPECK32/64 as an example. The best 9-round diﬀerential
trails of SPECK32 have a probability 2−30. Among them, a few have nBIL = 3,

20
Z. Feng et al.
nFIL = 3. Using Algorithm C, we set μ = 3 and let ℓ= 14. When 3 trails with
total probability 2−28.42 are used, the success probability of attack is about 66%.
When two more trails are added, the total probability of all 5 diﬀerential trails
is 2−27.68, and the success probability is about 76%. The results of these attacks
are listed in Table 7.
Table 7. Example of attacks using Algorithm C
Variants Split
#Trail(s) nBIL nFIL Data
Time
Mem. Ref
32/64
1+9+4 1
-
-
231
263
222
[11]
2+9+3 3
3
3
231
260.58 236
Alg. C
2+9+3 5
2
3
230.26 260.58 236
Alg. C
Experiment. We mount a 10-round attack on SPECK32/64 using Algorithm C.
In this experiment, we use four trails, the probability of which are all 2−13.
When we provide 214 message pairs, i.e., μ = 2, whose diﬀerences match the
input diﬀerence of the distinguisher, the results show that the highest counter
is 5 and the correct key does take this count. Among all possible keys, there are
roughly 212 candidates whose counters are more than or equal to 2.
4.4
Discussions and Extensions
In this paper, we ﬁnd a way to construct Type-II structures for SPECK. It allows
to add one more round before the diﬀerential distinguisher and leads to better
attacks in certain situations. From the application to SPECK, we can see that the
beneﬁt of Type-II structures is weakened by the nonlinearity of the key schedule
and the rotation ≫a in the round function. Thus, it is expected that the beneﬁt
of Type-II structures may vary from cipher to cipher.
Limitation of Algorithm B and C. The algorithms using Type-II structures
can be applied to SPECK variants where m = 3, 4. When m = 2, the number of
pairs to be processed 2t+2s may exceed 2mn before guessing any round key. Note
this is usually the case since t + s is close to 2n in most attacks. Therefore, our
new attack is diﬃcult to apply to the variants of SPECK with m = 2, namely,
when the key size equals the block size.
Extensions to Variants of Diﬀerential Attacks. Besides the standard dif-
ferential cryptanalysis, the new technique for constructing Type-II structures
is potentially useful in various variants of diﬀerential attacks on ARX ciphers.
Such variants include boomerang/rectangle attacks, diﬀerential-linear attacks,
impossible diﬀerential attacks, etc.
5
Applications to SPECK
In this section, we apply the three new algorithms proposed in Sect. 4 to key
recovery attacks of SPECK, where we reuse the SAT-based method [23] to search
for suitable diﬀerentials or diﬀerential trails which is brieﬂy described in [12].

Improved Diﬀerential Cryptanalysis on SPECK Using Plaintext Structures
21
5.1
Summary of Results
In this subsection, we mount key recovery attacks on SPECK by applying the
new algorithms in Sect. 4 using new diﬀerential distinguishers which are shown
in detail in [12].
The results are summarized in Table 8 where we label each distinguisher with
an ID whose details are provided in [12], and the comparison to the related works
is presented in Table 1.
Table 8. All improved attacks using our new Algorithm
Variants
Split
ID
Prob.
nBIL,nFIL
Data
Time
Mem.
Method
32/64
2+8+3
21
2−21.68
3,3
224.26
255.58
236
Alg. C
1+9+4
1
2−26.09
-
227.09
263
222
Alg. A
2+9+3
22
2−27.68
2,3
230.26
260.58
236
Alg. C
48/72
1+11+3
2
2−43.42
-
244.42
270
222
Alg. A
2+11+2
23
2−45.42
11,7
248
262
256
Alg. C
1+12+3
3
2−45.78
-
246.78
271.78
222
Alg. A
48/96
1+11+4
2
2−43.42
-
244.42
294
222
Alg. A
2+11+3
23
2−45.42
11,7
248
286
256
Alg. C
1+12+4
3
2−45.78
-
246.78
295.78
222
Alg. A
64/96
1+15+3
4
2−60
-
261
295
222
Alg. A
1+15+3
5
2−58.91
-
259.91
293.91
222
Alg. A
2+15+2
15
2−60.53
5,2
263.11
292.11
267
Alg. B
2+15+2
25
2−59.30
2,3
261.88
293.34
268
Alg. C
2+15+2
26
2−58.24
2,3
260.82
292.28
268
Alg. C
64/128
1+15+4
4
2−60
-
261
2127
222
Alg. A
1+15+4
5
2−58.91
-
259.91
2125.91
222
Alg. A
2+15+3
15
2−60.53
5,2
263.11
2124.11
267
Alg. B
2+15+3
25
2−59.30
2,3
261.88
2125.34
268
Alg. C
2+15+3
26
2−58.24
2,3
260.82
2124.28
268
Alg. C
96/96
1+16+2
6
2−86
-
287
288
222
Alg. A
1+17+2
7
2−92.17
-
293.17
295.75
222
Alg. A
96/144
1+16+3
6
2−86
-
287
2136
222
Alg. A
2+16+2
16
2−87
7,0
289.58
2136.58
297
Alg. B
2+16+2
17
2−92
15,0
294.58
2134.58
297
Alg. B
2+16+2
27
2−85.19
7,0
287.77
2137.35
297
Alg. C
1+17+3
7
2−92.17
-
293.17
2143.75
222
Alg. A
2+17+2
28
2−91.03
7,2
293.61
2143.13
299
Alg. C
128/128
1+19+2
8
2−117
-
2118
2120.81
222
Alg. A
1+20+2
9
2−121.37
-
2122.37
2124.95
222
Alg. A
128/192
1+19+3
8
2−117
-
2118
2184.81
222
Alg. A
2+19+2
19
2−119
23,2
2121.58
2167.58
2131
Alg. B
2+19+2
29
2−117.19
23,2
2119.77
2168.35
2131
Alg. C
1+20+3
9
2−121.37
-
2122.37
2188.95
222
Alg. A
2+20+2
20
2−123.17
23,0
2125.75
2173.75
2129
Alg. B
2+20+2
30
2−121.37
23,0
2123.95
2174.53
2129
Alg. C
128/256
1+19+4
8
2−117
-
2118
2248.81
222
Alg. A
2+19+3
19
2−119
23,2
2121.58
2231.58
2131
Alg. B
2+19+3
29
2−117.19
23,2
2119.77
2232.35
2131
Alg. C
1+20+4
9
2−121.37
-
2122.37
2252.95
222
Alg. A
2+20+3
20
2−123.17
23,0
2125.75
2237.75
2129
Alg. B
2+20+3
30
2−121.37
23,0
2123.95
2238.53
2129
Alg. C

22
Z. Feng et al.
Now we highlight some features of the results shown in Table 8. Algorithm A
is used to attack all variants of SPECK while Algorithm B and C are applied to
variants with m = 3, 4. We use proper diﬀerentials for reduced SPECK with the
largest number of rounds that can be attacked and for SPECK reduced to fewer
rounds, we use diﬀerential trails. When we use Algorithm B and C which are
based on the counting method, in order to have a reasonable success probability,
we set the number of right pairs to a larger value than the one used in the
enumerating method of Dinur’s attack and Algorithm A. This increases the
data complexity and the time complexity by a factor. For distinguishers with
small signal-to-noise ratio, e.g., the ones for SPECK32 and SPECK48, there is no
advantage if we use Algorithm B. As a result, Algorithm A and C, which uses
multiple trails or diﬀerentials, give better results in most cases.
Note that the results of Algorithm A achieve the goal of reducing the data
complexity when compared with previous attacks. The aims of using Algorithm B
are to make use of Type-II structure and reduce the time complexity. Algorithm
C combines the ideas of Algorithm A and B and helps to improve the data
and time complexity at the same time. However, the memory complexity of the
attacks using Algorithm B and C might be higher than the previous attacks
which use Dinur’s algorithm.
6
Conclusion
In this paper, we study the properties of modular addition and ﬁnd a method to
construct Type-II structures for SPECK. We also show that a combination of both
types of structures is possible for ARX ciphers. To demonstrate the eﬀect of these
structures, we apply them to SPECK and obtain a series of improved attacks on all
variants of SPECK. Our results conﬁrm that Type-II structures help to reduce the
time complexity and the combination of both types of structures helps to improve
the data and time complexity at the same time, as in the cryptanalysis of S-box-
based ciphers. Besides the standard diﬀerential cryptanalysis, we believe Type-
II structures can be potentially applied to other diﬀerential-like cryptanalysis
for ARX ciphers, such boomerang attacks, diﬀerential-linear attacks, impossible
attacks, etc.
Acknowledgement. The authors would like to thank anonymous reviewers for their
helpful comments and suggestions. The work of this paper was supported by the
National Natural Science Foundation of China (Grants 62022036, 62132008, 62202460).
References
1. Abed, F., List, E., Lucks, S., Wenzel, J.: Diﬀerential cryptanalysis of round-
reduced Simon and Speck. In: Cid, C., Rechberger, C. (eds.) FSE 2014. LNCS,
vol. 8540, pp. 525–545. Springer, Heidelberg (2015). https://doi.org/10.1007/978-
3-662-46706-0_27

Improved Diﬀerential Cryptanalysis on SPECK Using Plaintext Structures
23
2. Bao, Z., Guo, J., Liu, M., Ma, L., Tu, Y.: Enhancing diﬀerential-neural crypt-
analysis. In: Agrawal, S., Lin, D. (eds.) ASIACRYPT 2022. LNCS, vol. 13791, pp.
318–347. Springer, Cham (2023). https://doi.org/10.1007/978-3-031-22963-3_11
3. Beaulieu, R., Shors, D., Smith, J., Treatman-Clark, S., Weeks, B., Wingers, L.:
The SIMON and SPECK families of lightweight block ciphers. Cryptology ePrint
Archive (2013)
4. Biham, E., Shamir, A.: Diﬀerential cryptanalysis of DES-like cryptosystems. In:
Menezes, A.J., Vanstone, S.A. (eds.) CRYPTO 1990. LNCS, vol. 537, pp. 2–21.
Springer, Heidelberg (1991). https://doi.org/10.1007/3-540-38424-3_1
5. Biham, E., Shamir, A.: Diﬀerential cryptanalysis of DES-like cryptosystems. J.
Cryptol. 4(1), 3–72 (1991). https://doi.org/10.1007/BF00630563
6. Biham, E., Shamir, A.: Diﬀerential cryptanalysis of the full 16-round DES. In:
Brickell, E.F. (ed.) CRYPTO 1992. LNCS, vol. 740, pp. 487–496. Springer, Hei-
delberg (1993). https://doi.org/10.1007/3-540-48071-4_34
7. Biryukov, A., Khovratovich, D.: Related-key cryptanalysis of the full AES-192
and AES-256. In: Matsui, M. (ed.) ASIACRYPT 2009. LNCS, vol. 5912, pp. 1–18.
Springer, Heidelberg (2009). https://doi.org/10.1007/978-3-642-10366-7_1
8. Biryukov, A., Roy, A., Velichkov, V.: Diﬀerential analysis of block ciphers SIMON
and SPECK. In: Cid, C., Rechberger, C. (eds.) FSE 2014. LNCS, vol. 8540, pp.
546–570. Springer, Heidelberg (2015). https://doi.org/10.1007/978-3-662-46706-
0_28
9. Biryukov, A., dos Santos, L.C., Teh, J.S., Udovenko, A., Velichkov, V.: Meet-in-
the-ﬁlter and dynamic counting with applications to SPECK. Cryptology ePrint
Archive (2022)
10. Chen, J., Wang, M., Preneel, B.: Impossible diﬀerential cryptanalysis of the
lightweight block ciphers TEA, XTEA and HIGHT. In: Mitrokotsa, A., Vaudenay,
S. (eds.) AFRICACRYPT 2012. LNCS, vol. 7374, pp. 117–137. Springer, Heidel-
berg (2012). https://doi.org/10.1007/978-3-642-31410-0_8
11. Dinur, I.: Improved diﬀerential cryptanalysis of round-reduced SPECK. In: Joux,
A., Youssef, A. (eds.) SAC 2014. LNCS, vol. 8781, pp. 147–164. Springer, Cham
(2014). https://doi.org/10.1007/978-3-319-13051-4_9
12. Feng, Z., Luo, Y., Wang, C., Yang, Q., Liu, Z., Song, L.: Improved diﬀerential
cryptanalysis on SPECK using plaintext structures. Cryptology ePrint Archive
(2023)
13. Fu, K., Wang, M., Guo, Y., Sun, S., Hu, L.: MILP-based automatic search algo-
rithms for diﬀerential and linear trails for SPECK. In: Peyrin, T. (ed.) FSE 2016.
LNCS, vol. 9783, pp. 268–288. Springer, Heidelberg (2016). https://doi.org/10.
1007/978-3-662-52993-5_14
14. Gohr, A.: Improving attacks on round-reduced SPECK32/64 using deep learning.
In: Boldyreva, A., Micciancio, D. (eds.) CRYPTO 2019. LNCS, vol. 11693, pp.
150–179. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-26951-7_6
15. Hong, S., Hong, D., Ko, Y., Chang, D., Lee, W., Lee, S.: Diﬀerential cryptanalysis of
TEA and XTEA. In: Lim, J.-I., Lee, D.-H. (eds.) ICISC 2003. LNCS, vol. 2971, pp.
402–417. Springer, Heidelberg (2004). https://doi.org/10.1007/978-3-540-24691-
6_30
16. Lee, H., Kim, S., Kang, H., Hong, D., Sung, J., Hong, S.: Calculating the approx-
imate probability of diﬀerentials for ARX-based cipher using SAT solver. J Korea
Inst. Inf. Secur. Cryptol. 28(1), 15–24 (2018)
17. Leurent, G.: Improved diﬀerential-linear cryptanalysis of 7-round Chaskey with
partitioning. In: Fischlin, M., Coron, J.-S. (eds.) EUROCRYPT 2016. LNCS, vol.

24
Z. Feng et al.
9665, pp. 344–371. Springer, Heidelberg (2016). https://doi.org/10.1007/978-3-
662-49890-3_14
18. Liu, Z., Li, Y., Jiao, L., Wang, M.: A new method for searching optimal diﬀerential
and linear trails in ARX ciphers. IEEE Trans. Inf. Theory 67(2), 1054–1068 (2020)
19. Matsui, M., Yamagishi, A.: A new method for known plaintext attack of FEAL
cipher. In: Rueppel, R.A. (ed.) EUROCRYPT 1992. LNCS, vol. 658, pp. 81–91.
Springer, Heidelberg (1993). https://doi.org/10.1007/3-540-47555-9_7
20. Moon, D., Hwang, K., Lee, W., Lee, S., Lim, J.: Impossible diﬀerential cryptanal-
ysis of reduced round XTEA and TEA. In: Daemen, J., Rijmen, V. (eds.) FSE
2002. LNCS, vol. 2365, pp. 49–60. Springer, Heidelberg (2002). https://doi.org/10.
1007/3-540-45661-9_4
21. Selçuk, A.A.: On probability of success in linear and diﬀerential cryptanalysis. J.
Cryptol. 21(1), 131–147 (2008)
22. Song, L., Huang, Z., Yang, Q.: Automatic diﬀerential analysis of ARX block ciphers
with application to SPECK and LEA. In: Liu, J.K., Steinfeld, R. (eds.) ACISP
2016. LNCS, vol. 9723, pp. 379–394. Springer, Cham (2016). https://doi.org/10.
1007/978-3-319-40367-0_24
23. Sun, L., Wang, W., Wang, M.: Accelerating the search of diﬀerential and linear
characteristics with the SAT method. IACR Trans. Symmetric Cryptol. 269–315
(2021)
24. Wang, F., Wang, G.: Improved diﬀerential-linear attack with application to round-
reduced SPECK32/64. In: Ateniese, G., Venturi, D. (eds.) ACNS 2022. LNCS, pp.
792–808. Springer, Cham (2022). https://doi.org/10.1007/978-3-031-09234-3_39

Linear Cryptanalysis and Its Variants
with Fast Fourier Transformation
Technique on MPC/FHE/ZK-Friendly
Fp-Based Ciphers
Zeyu Xu1,2, Shiyao Chen3, Meiqin Wang1,2,4(B), and Puwen Wei1,2,4
1 Key Laboratory of Cryptologic Technology and Information Security,
Ministry of Education, Shandong University, Jinan, China
xuzeyu@mail.sdu.edu.cn, {mqwang,pwei}@sdu.edu.cn
2 School of Cyber Science and Technology, Shandong University, Qingdao, China
3 Strategic Centre for Research in Privacy-Preserving Technologies and Systems,
Nanyang Technological University, Singapore, Singapore
shiyao.chen@ntu.edu.sg
4 Quan Cheng Shandong Laboratory, Jinan, China
Abstract. The emergence of advanced cryptographic protocols has pro-
moted the developments of many applications, such as secure multi-
party computation (MPC). For this reason, new symmetric-key prim-
itives have been designed to natively support the ﬁnite ﬁeld Fp with odd
characteristic for better eﬃciencies. However, some well-studied symmet-
ric cryptanalytic methods and techniques over Fn
2 cannot be applied to
these new primitives over Fp directly. Considering less standard design
approaches adopted in these novel MPC-friendly ciphers, these proposals
are in urgent need of full investigations; generalizations of the traditional
cryptanalytic tools and techniques to Fp will also contribute to better
understand the security of these new designs.
In this paper, we ﬁrst show that the Fast Fourier Transform (FFT)
technique for the estimations of correlation, introduced by Collard et
al. at ICISC 2007, can be applied to Fp and signiﬁcantly improves
the complexity of Matsui’s Algorithm 2 over Fp. Then, we formal-
ize the diﬀerential-linear (DL) cryptanalysis to Fp. Inspired by the
diﬀerential-linear connectivity table (DLCT) introduced by Bar-On et
al. at EUROCRYPT 2019, we also include the DLCT into the consider-
ation, and ﬁnd the relation between DLCT and diﬀerential distribution
table (DDT) over Fp. Finally, we mount key recovery attacks on a ver-
sion of HADESMiMC, which is a SHARK-like MPC-friendly block cipher
proposed by Grassi et al. at EUROCRYPT 2020. We denote this version
as HADESMiMC-128 in this paper. For linear cryptanalysis with the
FFT technique, we can attack 7 rounds of HADESMiMC-128. For DL
cryptanalysis, a 7-round key recovery attack of HADESMiMC-128 is also
mounted but with better time and data complexity. It should be noted
that the attacks are still far from threatening the security of the full
14-round HADESMiMC-128.
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 25–52, 2023.
https://doi.org/10.1007/978-3-031-35486-1_2

26
Z. Xu et al.
Keywords: MPC-Friendly Block Ciphers · Linear Cryptanalysis ·
Diﬀerential-Linear Cryptanalysis · Fast Fourier Transformation ·
HADES
1
Introduction
Secure multi-party computation, fully homomorphic encryption (FHE) and zero-
knowledge (ZK) proof system have been one of the most productive lines
of research in recent years. In the context of these advanced applications,
symmetric-key primitives are still needed, but diﬀerent eﬃciency metrics, such
as the multiplicative complexity and depth, are taken into consideration. This
is because these MPC/FHE/ZK systems can be described by arithmetic oper-
ations, which are deﬁned over ﬁnite ﬁelds Fp of odd characteristic, so if one
chooses AES [22] as the underlying primitive for these protocols, the arithmetic
conversion from F2 to Fp is usually expensive and becomes the bottleneck. Natu-
rally, many dedicated symmetric-key primitives such as [2–4,28–30] are designed
to work natively over Fp for better performances. Meanwhile, these innovative
constructions and new operating ﬁelds with odd characteristic also pose some
potential threats to these primitives, from algebraic attacks [1,25] to statistical
attacks, e.g. diﬀerential and integral attacks [9]. However, linear cryptanalysis
and its variants have not got enough attention for these MPC/FHE/ZK-friendly
ciphers, only several of them carefully evaluated the resistance against linear
attacks, such as Ciminion [24] and Reinforced Concrete [29]. As is well known,
linear cryptanalysis [35] introduced by Matsui in 1993 has been one of the most
classical cryptanalytic methods for symmetric primitives. In [35], Matsui pro-
posed the partial key-recovery attack known as Algorithm 2 in the form of a
last round attack. Later, Collard et al. [19] found that Algorithm 2 could be
accelerated by using the FFT technique. Recently, by using linear cryptanalysis
with the dedicated FFT acceleration, Fl´orez-Guti´errez et al. [26,27] improved the
attacked rounds and ﬁrstly presented 28-/29-round linear key recovery attacks
on PRESENT, which has 31 total rounds and is one of the ISO/IEC stan-
dard [16] for lightweight block ciphers. Besides linear cryptanalysis combined
with advanced techniques, diﬀerent kinds of variants of linear cryptanalysis have
also been developed, including diﬀerential-linear cryptanalysis [32], multiple lin-
ear [12] and zero-correlation linear cryptanalysis [17], to name a few. From all
these developments, linear cryptanalysis and its related techniques or variants
have been shown to be very powerful tools for design or cryptanalysis of sym-
metric ciphers over Fn
2. Naturally, generalizing linear cryptanalysis to Fp is an
important task, especially for this very new designing direction that also needs
more in-depth cryptanalysis. In this vein, thanks to Baign`eres et al. [5] and Ble-
ichenbacher [13], more accurate estimations of linear correlation over Fp are pro-
vided. However, linear cryptanalysis with advanced techniques and its variants
are still in pressing need to be transformed from Fn
2 to Fp, which are expected to
be basic tools at hand for cryptographers, and facilitate the design and analysis
of these newly proposed MPC/FHE/ZK-friendly primitives.

Linear Cryptanalysis and Its Variants with Fast Fourier Transformation
27
Our Contributions. In this paper, focusing on the prime ﬁeld Fp with odd
characteristic, we study the Fast Fourier Transform technique for linear crypt-
analysis and generalize the diﬀerential-linear cryptanalysis.
FFT Technique for Linear Cryptanalysis over Fp. In order to (partially) accel-
erate the computation of key recovery attacks for linear cryptanalysis over the
prime ﬁeld, we ﬁrst extend the general framework of Matsui’s Algorithm 2 given
by Biryukov et al. [12] to Fp. Then, we prove that the FFT-based optimization
can be also integrated into Algorithm 2 over Fp to gain signiﬁcant improvement
in terms of the complexity. In a nutshell, the pk ×pk matrix D, used to store the
correlations for all pk guessed keys in Matsui’s Algorithm 2, has the same under-
lying structure of a level circulant matrix [23], which can be further diagonalized
by two k-dimensional Discrete Fourier Transform matrices F ∗, F as
D = F ∗diag(λD)F.
Finally, the time complexity of Matsui’s Algorithm 2 over Fp can be signiﬁcantly
reduced from O(p2k) to O(kpk+1).
DL Cryptanalysis and Generating DLCT with FFT over Fp. For the ﬁrst time, we
formalize the DL cryptanalysis over Fp, including the DLCT ﬁrst introduced by
Bar-On et al. [6] for ciphers over Fn
2. Then the similar convenient transformation
from DDT to DLCT is also revealed over Fp; to be speciﬁc, assuming a DLCT
of size pt ×pt, the time complexity of fast generating the DLCT from DDT with
FFT can be greatly reduced from O(p3t) to O(tp2t+1).
Applications of Linear Cryptanalysis with FFT Technique and DL Cryptanalysis
over Fp. We apply our generalized cryptanalytic tools and techniques to a version
of HADESMiMC, which is an MPC/FHE/ZK-friendly block cipher belonging to
HADES family proposed by Grassi et al. [30]. This version, which we denote
as HADESMiMC-128, has 14 rounds with 5 full S-box layers at the head/tail
and 4 partial S-box layers in the middle, denoted by 14 = (5 + 4 + 5). When
estimating the security of statistical attacks, designers only consider the full S-
box layer and not partial S-box layer. They state that no statistical attacks can
attack more than 4 = (2 + 0 + 2) rounds. Our following attacks are based on
partial S-box round, that is, 6 = (1 + 4 + 1) and 7 = (1 + 4 + 2). To mount key
recovery attacks, we ﬁrst ﬁnd a 6-round linear approximation and construct a 6-
round DL distinguisher, which are the current longest linear/DL distinguishers
of HADESMiMC-128. Then on the one hand, we demonstrate that the linear
attack can cover one more round when using the FFT technique. On the other
hand, a 7-round DL attack is performed with better data and time complexity
than the 7-round linear attack. The results of our attacks are given in Table 1.
The designers of HADESMiMC have deﬁned two security levels, one is
⌈log2 p⌉× t corresponding to the traditional symmetric scheme, and the other is
⌈log2 p⌉for MPC applications. We emphasize that our attack is on the security
level of the former, and cannot aﬀect the application of the strategy in MPC.
In addition, the experiment in this paper uses 8-bit p instead of large prime
numbers. This is due to the high complexity of the operations in the large prime

28
Z. Xu et al.
number ﬁeld, which makes the search of the distinguisher more diﬃcult. We
emphasize that the main work of this paper is to reveal the basic theory for all
p, however, the search technique for large p is incomplete, so we do not propose
corresponding experimental results.
Table 1. Summary of key recovery attacks on HADESMiMC-128.
Prime p Attack
Rounds Data
Time*
Any
Statistical [30]
4
251
Linear
6
2117.9 KP
2121.98
251
Linear + FFT
7
2123.9 KP
2124.72
251
Diﬀerential-Linear 7
2110.63 CP 2115.53
* Evaluated by encryption units (6 or 7 rounds).
KP: Known plaintext.
CP: Chosen plaintext.
Orgnization of the Paper. In Sect. 2, we review the diﬀerential and linear
cryptanalysis over Fp and describe the HADESMiMC block cipher. In Sect. 3,
we give a new application of the FFT-based technique in linear cryptanalysis
over Fp. In Sect. 4, we adapt diﬀerential-linear cryptanalysis to Fp. Two key
recovery attacks of 7-round HADESMiMC-128 are presented in Sect. 5.
2
Preliminaries
Some notations used throughout the paper are given as below.
– lower case letters(e.g. u, v, x): denote vectors in Ft
p;
– | · |: denotes the modulus of a complex number;
– u[i] or ui: denotes the i-th word of a vector u
∈
Ft
p, where u
=
(ut−1, ut−2, · · · , u0).
– u · v: denotes the inner product operation, u · v = t−1
i=0 u[i] × v[i] mod p;
– EX (h(x)): denotes the expectation of function h(x), where the independent
variable x is uniformly distributed in the domain.
2.1
Diﬀerential and Linear Cryptanalysis over Fp
Diﬀerential [11] and linear cryptanalysis [35] are the most widely used symmetric
cryptanalytic methods. For linear cryptanalysis, Baign`eres et al. [5] have devel-
oped the correlation analysis of symmetric-key primitives designed over abelian
groups, which has been used to evaluate the security of Ciminion [24] against
linear attacks. The core idea is that a character is an additive homomorphism
from Ft
p into Sp = {ω ∈C : ωp = 1}, and any character is of the form
χu(x) = e
2π√−1
p
u·x,

Linear Cryptanalysis and Its Variants with Fast Fourier Transformation
29
for some u ∈Ft
p. Now, let f : Ft
p →Fp, then its correlation [5] can be deﬁned as
cor(f) = 1
pt

x∈Ft
p
e
2π√−1
p
f(x).
When f(x) is replaced by a linear approximation, it has the following deﬁnition.
Deﬁnition 1 (Correlation over Fp [5]). Given a function F : Ft
p →Ft
p, for
a linear mask pair (u, v) where u, v ∈Ft
p, let f(x) = v · F(x) −u · x, then the
correlation of the linear approximation (u, v) of F is deﬁned as
corF (u, v) = 1
pt

x∈Ftp
χu(x)χv(F(x)) = 1
pt

x∈Ftp
e
2π√−1
p
(v·F (x)−u·x) = EX (e
2π√−1
p
f(x)).
Deﬁnition 2 (Linear Probability over Fp [5]). The linear probability of a
function F is
LP F (u, v) = |corF (u, v)|2.
Linear Probability of Linear Trail over Fp. In [5], the linear probability of
a r-round linear trail Ω = (u0, u1, · · · , ur) is given as
LP(Ω) =
r

i=1
LP(ui−1, ui).
For multipath, they also obtain the linear hull eﬀect.
Theorem 1 (Linear Hull Eﬀect over Fp [5]). Let Ω = (u0, u1, · · · , ur) be all
r-round linear trail with input/output masks u0 and ur, then we have
LP(u0, ur) =

u1,u2··· ,ur−1
LP(Ω).
Probability of Success. According to the Theorem 7 in [5], suppose that
the amount of data required for a key recovery attack using a trail with linear
probability LP is N, and α =
N
2 × LP. Then the probability of success of
ﬁnding the correct key in one attack is Ps = 1 −e−α
2 , and the keys need a
further exhaustive search accounts for e−α
2 of all guessed keys.
In the rest of the paper, we will use α as a parameter when estimating the
data complexity and success probability.
The diﬀerential probability over Fn
2 can be easily adapted to the prime ﬁeld
Fp.
Deﬁnition 3 (Diﬀerential Probability over Fp). Given a function F : Ft
p →
Ft
p, (Δin, Δout) is a diﬀerential pair for the diﬀerence of modular subtraction,
where Δin, Δout ∈Ft
p. Its diﬀerential probability is deﬁned as
DPF [Δin →Δout] = #{x ∈Ft
p|F(x) −F(x −Δin) = Δout}
pt
.

30
Z. Xu et al.
3
FFT Technique for Linear Cryptanalysis over Fp
In this section, we introduce and generalize the FFT technique for linear crypt-
analysis over Fp. We begin with the adaption of Matsui’s Algorithm 2 to the
prime ﬁeld Fp. Then, we dive into the optimizations of the time complexity of
the correlation estimations, which is inspired by Collard et al. ’s work [19].
3.1
General Framework of Matsui’s Algorithm 2 over Fp
Following the framework in [12], we ﬁrst adapt Matsui’s Algorithm 2 to the
prime ﬁeld Fp. Suppose a linear distinguisher of a cipher E over Ft
p requires
N pairs of plaintext and ciphertext for the key recovery attack. Let input and
output masks of this distinguisher be Γin and Γout respectively, and there are
k (1 ≤k < t) words of the secret key over Ft
p that need to be guessed. Note that
Matsui’s Algorithm 2 only considers one-round key recovery attack for simplicity
and can be divided into two phases as below.
Distillation Phase
– Initialize an array A of size pk.
– For each plaintext-ciphertext pair (P, C), extract k words (C[ik], · · · , C[i1])
of C ∈Ft
p for k active S-boxes, where 0 ≤i1 < · · · < ik < t. Then use C′ =
C[ik]|| · · · ||C[i1] as the index of A and update A[C′] = A[C′]+e−2π√−1
p
(Γin·P ).
Analysis Phase
– Initialize an array COR of size pk.
– Extract k words (Γout[ik], · · · , Γout[i1]) of Γout ∈Ft
p for k active S-boxes and
denote Γ ′
out = Γout[ik]|| · · · ||Γout[i1], where 0 ≤i1 < i2 < · · · < ik < t.
– Build a table D of size pk × pk. For each guessed key K′ ∈Fk
p and each
ciphertext C ∈Ft
p, we obtain C′ ∈Fk
p from C. Then the entry of D is
updated as below
D[K′, C′] = e
2π√−1
p
(Γ ′
out·S−1
k
(C′−K′)),
where S−1
k
represents the inverse of the last one-round for k active S-boxes.
– For each guessed key K′ ∈Fk
p, the experimental correlation can be evaluated
as
COR[K′] =

C′
D[K′, C′] × A[C′].
Considering the complexity of these two phases, the major cost is the gen-
erations of the table D and COR. D will be accessed pk times for each guessed
K′, which leads to the time complexity of O(pk × pk). D will be computed row
by row, and each row multiplied with A to generate COR, which leads to the
time complexity of O(pk × pk).

Linear Cryptanalysis and Its Variants with Fast Fourier Transformation
31
3.2
FFT for Correlation Estimation over Fp
In order to reduce the time complexity of the analysis phase discussed above, it
is natural to explore some optimizations for the computation of the table D and
its matrix multiplication. Inspired by the FFT technique introduced by Collard
et al. [19] for linear cryptanalysis over Fn
2, we now dedicate to study properties
of the structure of the table D and show that the FFT technique also can be
used in the case of a prime ﬁeld Fp with odd characteristic.
Firstly, we ﬁnd that the structure of the table D, also a square matrix, is
equivalent to the structure of pk × pk matrix Q with Q[i, j] = j −i, where i =
(ik−1, · · · , i0) ∈Fk
p, j = (jk−1, · · · , j0) ∈Fk
p and j−i = (jk−1−ik−1, · · · , j0−i0).
That is, D[i, j] = e
2π√−1
p
(Γ ′
out·S−1
k
(Q[i,j])). Therefore, we can assert that when a
method can decompose Q, it can also decompose D. We then introduce some
deﬁnitions and properties of the circulant matrix [23] as follows, which helps us
reveal the underlying structure of Q further.
Deﬁnition 4 (circulant [23]). A circulant matrix is a square matrix where the
elements of each row are identical to those of the previous row, but are moved
one position to the right and wrapped around.
Deﬁnition 5 (m-block circulant [23]). Let B1, B2, · · · , Bm be square matri-
ces each of order n, a m-block circulant circulant matrix with each block of size
n × n is an mn × mn matrix of the form
⎛
⎜
⎜
⎜
⎝
B1 B2 · · ·
Bm
Bm B1 · · · Bm−1
...
... ...
...
B2 B3 · · ·
B1
⎞
⎟
⎟
⎟
⎠.
Deﬁnition 6 (level circulant [23])
– A matrix is level-1 circulant with type(n) iﬀit is circulant of size n × n.
– A matrix is level-2 circulant with type(m, n) iﬀit is m-block circulant matrix
and each block is a level-1 circulant with type(n).
– A matrix is level-q circulant with type(mq, mq−1, · · · , m1) iﬀit is mq-
block circulant matrix and each block is a level-(q −1) circulant with
type(mq−1, · · · , m1).
Proposition 1. The matrix Q of order pk is a level-k circulant with type
(p, p, · · · , p)



k times
.
Proof. Consider a simple induction on k. For k = 1, Q is as below
⎛
⎜
⎜
⎜
⎝
0
1 · · · p −1
p −1 0 · · · p −2
...
... ...
...
1
2 · · ·
0
⎞
⎟
⎟
⎟
⎠,

32
Z. Xu et al.
and the claim is obvious. For k > 1, assume the claim holds for k−1, and express
Q as a block matrix of order p
Q =
⎛
⎜
⎜
⎜
⎝
Q0,0
Q0,1
· · ·
Q0,p−1
Q1,0
Q1,1
· · ·
Q1,p−1
...
...
...
...
Qp−1,0 Qp−1,1 · · · Qp−1,p−1
⎞
⎟
⎟
⎟
⎠.
Each block of Q is a square matrix of size pk−1, then for any a, b ∈Fp and
i, j ∈Fk−1
p
, we have
Qa,b[i, j] = (b, jk−2, · · · , j1) −(a, ik−2, · · · , i1) = (b −a, j −i).
Thus for any d ∈Fp, we have
Qa+d,b+d[i, j] = ((b −d) −(a −d), j −i) = (b −a, j −i) = Qa,b[i, j],
which means that Q is a block circulant with order p. As by the induction
hypothesis, Q0,0 is a level-(k −1) circulant with type (p, · · · , p)



k−1 times
. Furthermore,
we have Qa,b[i, j] = (b−a, j −i) and Q0,0[i, j] = (0, j −i), which means that each
Qa,b has the same structure as Q0,0. And thus, all blocks of Q are level-(k −1)
circulant with type (p, · · · , p)



k−1 times
, Q is a level-k circulant with type (p, p, · · · , p)



k times
.
This completes the proof.
These level circulant matrices can be decomposed by the following conclusion.
Theorem 2 ([23]). A level-q circulant Q with type (mq, mq−1, · · · , m1) is diag-
onalizable by the unitary matrix F = Fmq ⊗Fmq−1 ⊗· · · ⊗Fm1 as below
Q = F ∗diag(λQ)F,
where λQ is the vector of eigenvalues of Q, the symbol ⊗is the Kronecker product
which is deﬁned in Appendix B and Fml, 1 ≤l ≤q is the Fourier matrix of size
ml × ml deﬁned by
Fml[i, j] =
1
√ml
ωij
(0 ≤i, j ≤ml −1),
with ω = e
2π√−1
ml
. F ∗is the conjugate transpose of F, which satisﬁes FF ∗= I.
F and F ∗are the k-dimensional Discrete Fourier Transform (DFT) matrices,
and the multidimensional FFT allows us to quickly compute the matrix-vector
product with F and F ∗. The complexity of computing this product decreases
from O(m2
qm2
q−1 · · · m2
1) to O(mqmq−1 · · · m1(mq + mq−1 + · · · + m1)) [21]. As
shown in [19], diag(λQ) can be obtained by a Fourier transform
λQ = FQ[: 1]√mqmq−1 · · · m1,

Linear Cryptanalysis and Its Variants with Fast Fourier Transformation
33
where Q[: 1] is a vector deﬁned by the ﬁrst column of Q. Since D and Q have
exactly the same structure, the above conclusion is also applicable to D, just
replace Q[: 1] and λQ with D[: 1] and λD.
For the analysis phase, we only need to calculate all the values of the ﬁrst
column of D with the complexity of pk, and then we can further complete the
matrix vector multiplication of D and A. That is
DA = F ∗diag(λD)FA = p
k
2 F ∗diag(FD[:, 1])FA
which uses the FFT technique three times as below.
– Firstly, computing an FFT on A;
– Secondly, computing an FFT to obtain diag(λD) then multiplying the result-
ing vector by diag(λD) can be basically ignored;
– Thirdly, performing an FFT on the resulting vector by F ∗.
Finally, the time complexity of estimating COR = DA is 3pk(p + p + · · · + p) =
3kpk+1. Compared with pk × pk, this is a signiﬁcant acceleration.
4
Generalization of DL Cryptanalysis to Fp
DL cryptanalysis has been introduced by Langford and Hellman [32]. They ﬁnd
that if the cipher E can be decomposed as two parts E1◦E0 with high linear prob-
ability and diﬀerential probability respectively, then E1 and E0 can be combined
into an eﬃcient DL distinguisher for the whole cipher E. This attack depends on
some assumptions, such as the independence between the two parts E1 and E0.
In particular, the bias of the linear approximation in E1 is not aﬀected by the
fact that they are applied to two intermediate values which correspond to plain-
texts with a ﬁxed diﬀerence. Then, a series of works [6,8,10,14,15,18,33,34] has
been proposed to relieve the dependency and enhance the accuracy of the esti-
mation of the distinguisher. Among which the DLCT is a novel tool introduced
by Bar-On et al. [6], it shows that the cipher E can be decomposed into three
parts E1 ◦Em ◦E0, where DLCT of Em part is used to cover the dependency for
the connection. With all these dedicated researches, DL cryptanalysis has been
developed into a more mature and powerful cryptanalytic method over Fn
2. In
the following, we ﬁrst formalize the DL cryptanalysis over Fp, then show that
the construction of the DLCT over Fp also can be accelerated by using the FFT
technique.
Let E be a cipher over Ft
p that can be decomposed into E = E1 ◦Em ◦E0
and we consider these three parts separately as below.
– For E0, it has a diﬀerential Δin
p0
−→Δout with
DPE0[Δin →Δout].
– For E1, it has a linear approximation Γin
corE1
−→Γout with
corE1 = EX (e
2π√−1
p
(Γout·E1(x)−Γin·x)).

34
Z. Xu et al.
P0
P1
E0
Δin →Δout
X0
X1
Em
Δout →Γin
Y0
Y1
E1
Γin →Γout
C0
C1
Fig. 1. Diﬀerential-linear distinguisher with a middle layer.
– For Em, it has a diﬀerence-mask pair Δout
corEm
−→Γin with
corEm = EX (x0−x1=Δout)(e
2π√−1
p
(Γin·Em(x0)−Γin·Em(x1))).
The relation of these three parts for a diﬀerential-linear distinguisher is
depicted in Fig. 1. In order to distinguish the target cipher E from a random per-
mutation, the adversary can prepare enough plaintext pairs (P0, P1) such that
P0 −P1 = Δin and then check the correlation of C0 · Γout −C1 · Γout, where
(C0, C1) is the corresponding ciphertext pairs of (P0, P1). Denote the interme-
diate values between E0 and Em by (X0, X1), Em and E1 by (Y0, Y1). Now, we
consider how to evaluate the correlation of C0 · Γout −C1 · Γout over Ft
p and give
the following theorem.
Theorem 3. Assume that the three parts of the cipher E are independent from
each other, then the correlation of C0 · Γout −C1 · Γout under a diﬀerence-mask
pair (Δout, Γin) of the cipher E over Ft
p is
corΔout,Γin(C0 · Γout −C1 · Γout) = −DPE0[Δin →Δout] × corEm × cor2
E1
Proof. Under the assumption that the two parts of the cipher E are independent
from each other, we denote corΔout,Γin(C0 · Γout −C1 · Γout) as cor′ and e
2π√−1
p
as ω and have the following formula
cor′ = EX (ω(C0·Γout−C1·Γout))
= EX (ω[(C0·Γout−Y0·Γin)−(C1·Γout−Y1·Γin)+(Y0·Γin−Y1·Γin)])
= EX (ω(C0·Γout−Y0·Γin))EX (ω(Y1·Γin−C1·Γout))EX (ω(Y0·Γin−Y1·Γin))
= corE1 × corE1 × EX (ω(Y0·Γin−Y1·Γin))
= −DPE0[Δin →Δout] × EX (ω(Em(X0)·Γin−Em(X0−Δout)·Γin)) × |corE1|2
= −DPE0[Δin →Δout] × corEm × |corE1|2.
Thus, the correlation of the DL distinguisher can be derived from the corre-
sponding three parts mentioned above.

Linear Cryptanalysis and Its Variants with Fast Fourier Transformation
35
Then the calculation of linear probability of a DL distinguisher can be
obtained as below.
Corollary 1. The linear probability of C0 · Γout −C1 · Γout under a diﬀerence-
mask pair (Δout, Γin) of the cipher E over Ft
p is
LPΔout,Γin(C0 · Γout −C1 · Γout) = DP2
E0[Δin →Δout] × |corEm|2 × |corE1|4.
Proof. By Deﬁnition 2 and Theorem 3, the proof can be ended.
According to [6], the correlation of corEm is deﬁned as a diﬀerential-linear
connectivity table. We now adapt DLCT to the prime ﬁeld as follows.
Deﬁnition 7 (DLCT over Fp). Let ES : Ft
p →Ft
p be a function. The DLCT
of ES is a pt × pt table with rows corresponding to input diﬀerences of ES and
columns corresponding to output masks of ES. For a given diﬀerence-mask pair
(Δ, Γ) ∈Ft
p × Ft
p, its entry of DLCT is deﬁned as
DLCTES(Δ, Γ) ≜

x0−x1=Δ
e
2π√−1
p
(Γ ·ES(x0)−Γ ·ES(x1)).
Now for the Em part, we can use the DLCT entry to represent its correlation
by
pt × corEm = DLCTEm.
When the Em part is t parallel S-boxes, we can split the calculation of DLCTEm
into the calculation of DLCT for each S-box. For the i-th S-box Si, calculate
DLCTSi. Assuming that at least one of Δ[i] and Γ[i] is zero, we have
DLCTSi(0, Γ[i]) = DLCTSi(Δ[i], 0) = p,
Then a property of DLCT over Ft
p is that for such special Em over Ft
p, given
the complementary input diﬀerence Δ ∈Ft
p and output mask Γ ∈Ft
p, where at
most one of Δ[i] and Γ[i] is nonzero for each dimension i (0 ≤i < t), then it has
DLCTEm(Δ, Γ) = pt.
Thus, it will pass with linear probability being 1 for Em part.
4.1
Relation Between DLCT and DDT Under the FFT
Inspired by the work [6], DLCT also can be constructed eﬃciently using the
Fourier Transform over Fn
2, and we will discuss the relation between the DLCT
and DDT over Ft
p in the following.
vThe Fourier Transform of Vector Functions. Let f : Ft
p →C be a complex
valued function. The Fourier Transform of f is the function ˆf : Ft
p →C deﬁned
by
ˆf(x) = 1
pt

y∈Ft
p
f(y) × e
2π√−1
p
x·y.

36
Z. Xu et al.
The DDT. For a vectorial function S : Ft
p →Ft
p, the DDT of S is a pt × pt table
whose rows correspond to input diﬀerences of S and whose columns correspond
to output diﬀerences of S. Formally, for Δin ∈Ft
p and Δout ∈Ft
p, we have
DDT S(Δin, Δout) = #{x|S(x) −S(x −Δin) = Δout}.
It can be observed that each row of the DLCT is equal to the Fourier Trans-
form of the corresponding row of the DDT. Formally, for each Δ ∈Fp, denote
the function corresponding to the row with index Δ of the DDT by fΔ. That is,
fΔ : Ft
p →R is deﬁned by
fΔ(Δ′) = DDT S(Δ, Δ′).
Proposition 2. For any Γ ∈Ft
p, we have DLCT S(Δ, Γ) = pt × ˆ
fΔ(Γ).
Proof. By the deﬁnitions of the DLCT and of the FWT, we have
DLCT S(Δ, Γ) =

x0−x1=Δ
e
2π√−1
p
(Γ ·S(x0)−Γ ·S(x1)) =

x0−x1=Δ
e
2π√−1
p
Γ ·(S(x0)−S(x1))
=

y∈Ftp
e
2π√−1
p
Γ ·y × DDT S(Δ, y) = pt × ˆ
fΔ(Γ),
as claimed.
Therefore, in order to generate a row of DLCT, we ﬁrst need to generate
the corresponding row of DDT with the time complexity of O(pt). Proposition 2
implies that the next step is to perform the FFT on each row of DDT to obtain
the corresponding row of DLCT,
⎛
⎜
⎜
⎜
⎜
⎜
⎝
DLCT S(Δ, 0V )
DLCT S(Δ, 1V )
...
DLCT S(Δ, (pt −1)V )
⎞
⎟
⎟
⎟
⎟
⎟
⎠
= pt
⎛
⎜
⎜
⎜
⎜
⎜
⎝
ˆ
fΔ(0V )
ˆ
fΔ(1V )
...
ˆ
fΔ((pt −1)V )
⎞
⎟
⎟
⎟
⎟
⎟
⎠
= pt
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
ω0V ·0V
ω0V ·1V
· · ·
ω0V ·(pt−1)V
ω1V ·0V
ω1V ·1V
· · ·
ω1V ·(pt−1)V
...
...
...
...
ω(pt−1)V ·0V ω(pt−1)V ·1V · · · ω(pt−1)V ·(pt−1)V
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
⎛
⎜
⎜
⎜
⎜
⎜
⎝
fΔ(0V )
fΔ(1V )
...
fΔ((pt −1)V )
⎞
⎟
⎟
⎟
⎟
⎟
⎠
= p
3t
2 F
⎛
⎜
⎜
⎜
⎜
⎜
⎝
fΔ(0V )
fΔ(1V )
...
fΔ((pt −1)V )
⎞
⎟
⎟
⎟
⎟
⎟
⎠
,
where ω = e
2π√−1
p
and F is the DFT matrix in Theorem 2. For any i ∈
{0, 1, · · · , pt −1}, iV means that express i as a vector of length t in p-based
number. According to the property of F, the complexity of this step is O(tpt+1).
So the time complexity of generating the entire DLCT is O(tp2t+1). This sig-
niﬁcantly improves over the trivial generating method which requires O(p3t)
operations.

Linear Cryptanalysis and Its Variants with Fast Fourier Transformation
37
5
Applications to HADESMiMC
In this section, as applications of our generalizations of these cryptanalytic meth-
ods presented above, we concentrate on a target cipher—HADESMiMC-128.
5.1
Description of HADES
As is demonstrated in Fig. 6 (see Appendix A), a block cipher designed according
to the HADES strategy has the following three operations:
– AddRoundKey—ARK(·), it represents the addition of a round subkey to the
state.
– S-box layer—S(·), it represents the application of the S-box S with the state.
Note that the S-box will only be applied to a part of the state in the middle
rounds, which is denoted by S∗(·).
– Linear layer—MDS(·), it represents the application of the linear mixing
matrix with the state.
Under this construction, a keyed permutation HADESMiMC has been pro-
posed, it has R = 2Rf + RP rounds in total, in which 2Rf denotes the outer
rounds and RP denotes the inner rounds. For a full round Rk(·) : Ft
p →Ft
p is
deﬁned as
Rk(·) = k + M × S(·),
where t is the branch number, k ∈Ft
p is the round subkey, M ∈Ft×t
p
is an MDS
matrix generated by a Cauchy matrix, and S(·) : Ft
p →Ft
p is the non-linear layer.
Similarly, for a partial round R∗
k(·) : Ft
p →Ft
p is deﬁned as
R∗
k(·) = k + M × S∗(·).
Note that the last round does not contain the MDS matrix.
In this paper, we mainly focus on the version with the SHARK-like security.
It has t = 16, and each partial round has 1 S-box and 15 identity functions.
As for the S-box S(x) ≡x3(mod p), according to Hermite’s criterion, S is a
permutation over Fp iﬀgcd(3, p−1) = 1, thus the chosen prime p = 251. In [30],
the authors ﬁnd that not every Cauchy matrix provides the same security level
when considering algebraic attacks. But, as we only focus on statistical attacks,
we randomly select a Cauchy matrix when performing the security analysis in
this paper, which is given in Appendix A. In order to avoid confusion of names,
we temporarily denote it as HADESMiMC-128 in this paper.
Key Schedule. Let k = [k0, · · · , kt−2, kt−1] ∈Ft
p be the master key, the whiten-
ing key AK 0 ∈Ft
p in the ﬁrst round is equal to k. HADESMiMC-128 adopts a
linear key schedule as below
AK i = ˆ
M × AK i−1 + RC i,
i = 1, · · · , R.
AK i is the subkey of i-th round and RC i is the round constant, ˆ
M is a t by t
MDS matrix with M = ˆ
M allowed.

38
Z. Xu et al.
5.2
Search Models for Distinguishers over Fp
Automatic search has been widely used in the cryptanalysis of the symmetric-
key primitives over Fn
2 [31,36–38]. To construct the search models for diﬀerential
and linear mask over the prime ﬁeld Fp, we should divide the target cipher
into several basic operations ﬁrstly, then describe the exact propagation of the
diﬀerential and mask behaviors for each operation. In this paper, we utilize
the SAT/SMT [7,20] techniques for searching the distinguisher. The detailed
SAT/SMT based model for determining a lower bound of the linear probability
is described as follows. Note that each variable in the following constraints is
expressed as a bit vector. To be more precise, for a variable Γ ∈Fp, Γ can be
expressed by using ⌈log2 p⌉bits. We provide the codes in https://www.dropbox.
com/s/w1cylrp7r6s0j1y/search model linear.zip?dl=0.
Constraints Imposed by Modular Addition. The modular addition maps
(x, y) ∈F2
p to z = x + y mod p. Let Γ 1
in and Γ 2
in represent two input masks for
modular addition, the output mask is Γout. Then the approximation of modular
addition due to (Γ 1
in, Γ 2
in, Γout) is of nonzero-correlation if and only if it fulﬁlls
Γ 1
in = Γ 2
in = Γout.
Constraints Imposed by Linear Transformation. A linear transformation
with matrix representation M maps x to y = Mx. Let Γin and Γout represent
the input and output masks of x and y. Then the approximation of M due to
(Γin, Γout) is of nonzero-correlation if and only if it fulﬁlls Γin = M TΓout.
Constraints Imposed by k-Branch (k ≥3). The k-branch operation maps
x ∈Fp to (x1, · · · , xk−1) ∈Fk−1
p
with x = x1 = · · · = xk−1. Let Γin represent the
input mask for k-branch, the output masks are Γ 1
out, Γ 2
out, · · · , Γ k−1
out . Then the
approximation of k-branch due to (Γin, Γ 1
out, · · · , Γ k−1
out ) is of nonzero-correlation
if and only if it fulﬁlls Γin = Γ 1
out + Γ 2
out + · · · + Γ k−1
out .
Constraints Describing the S-Box Operation. Suppose Γin and Γout are
the input and output masks of a bijective S-box S, which is deﬁned over Fp.
All these informations are derived from the linear approximation table (LAT)
of S, which is a p × p table and ∀(Γin, Γout) ∈Fp × Fp, the LAT entry for
the pair (Γin, Γout) is LAT(Γin, Γout) = LPS(Γin, Γout), In practice, the S-box,
especially x3, has a large range. When p = 251, except for the ﬁrst row and
the ﬁrst column, the values in each row range from 2−6 to 2−26. Hence, we use
B[Γin, Γout] as an indicator to represent the linear probability and whether it is
a possible diﬀerential transition of S,

B[Γin, Γout] = ⌈−log2(LAT(Γin, Γout))⌉, LAT(Γin, Γout) ̸= 0
B[Γin, Γout] = −1,
LAT(Γin, Γout) = 0
Objective Function. Now, under the condition that B ̸= −1, we set up the
objective function to be the sum of all indicators of all S-boxes. It corresponds
to a rough estimate of the linear probability, and constraints can be added to

Linear Cryptanalysis and Its Variants with Fast Fourier Transformation
39
determine the lower bound of the distinguisher. When searching for linear dis-
tinguishers, we round the probability of S-box. Therefore, in order to obtain an
accurate linear probability, we need to calculate it again with the actual LAT.
The construction of searching diﬀerential model is similar to that of linear,
and the detailed description is in Appendix C.
5.3
Linear and Diﬀerential-Linear Distinguishers of HADESMiMC-
128
Γin,1
Γin,2
Γin,3
Γin,4
Γin,5
Γin,6
Γin,7
Fig. 2. 6-Round linear distinguisher.
6-Round Linear Distinguisher. The best linear approximation we found
reaches 6 rounds, as shown in Fig. 2. According to the linear approximation
table (LAT) of S(x) = x3 over F251, the linear probability of this approximation
is evaluated as 2−119.9.
6-Round DL Distinguisher. As shown in Fig. 3, we give a better DL distin-
guisher. The linear probability can be calculated according to Corollary 1, which
is 2−55.77.
Considering the non uniqueness of prime and MDS matrix, we also tested
other primes, such as p ∈{239, 233, 227}, and randomly select multiple MDS
matrices under each p, the results show that we can ﬁnd linear trails with similar
patterns. The experimental results are presented in Appendix D.
5.4
Linear Attacks on Round Reduced HADESMiMC-128
We now mount key recovery attacks and show that our generalizations of the
FFT technique for correlation estimations over Fp can contribute to reduce the
complexity and lead to better attacks. Before the attack, we set α = 8, then
e−α
2 = 2−5.77. In this way, the success rate of key recovery attack is Ps =
1 −e−α
2 = 98%, and the amount of data is N = 24 × LP −1.

40
Z. Xu et al.
Δin,1
Δin,2
Δin,3
Δin,4
Δin,5
Δin,6
Γout
E0
Em and E1
Fig. 3. 6-Round diﬀerential-linear distinguisher.
6-Round Key Recovery Attack. We cut out the last 5 rounds in Fig. 2 as a
new distinguisher. That is, LP(Γout,1, Γout,6) = 2−113.9. We add one full S-box
round in the head to complete the 6-round key recovery attack. The output mask
of the ﬁrst round has one active word, so we can recover the information on one
whitening key word.
According to the general framework in Sect. 3.1, the time complexity of
recover one word of the whitening key of the ﬁrst round is p × p = 215.94 one-
round encryptions. According to the α we select, the number of keys left in this
step is p×e−α
2 ≈5. Then these keys and the remaining 15 words of the whitening
key can be obtained by exhaustive search with about 5 × p15 = 2121.89 6-round
encryptions. In all, 6-round of HADES-128 can be attacked with 2117.9 known
plaintexts and 2117.9 + 2121.89 = 2121.98 6-round encryptions.
7-Round Key Recovery Attack with the FFT Technique. As shown
in Fig. 4, we adopt the 6-round linear trail as the distinguisher with
LP(Γin,1, Γin,7) = 2−119.9. One full S-box round in the tail is added to lanuch
the 7-round key recovery attack. The input mask of the 7-th round has 14 active
words, so we can recover 14 words of the subkey AK7 of the last round. It should
be noted that if we do not use the FFT technique, the time complexity required
to recover these 14 subkey words is p14 × p14 = 2223.2 > pt = 2127.54.
According to the fast algorithm given in Sect. 3.2, the time complexity of
recover 14 words of AK7 is 3 × 14 × p15 = 2124.9 one-round encryptions, which
is equivalent to 2124.9 ×
14
3×16+4 = 2123 7-round encryptions. According to the
α we select, the number of keys left in this step is p14 × e−α
2 = 2105.83. Then
these subkeys and the remaining 2-word subkey can be obtained by exhaustive
search with about 2105.83 × p2 = 2121.77 7-round encryptions. Thus, 7-round of
HADESMiMC-128 can be attacked with 2123.9 known plaintexts and 2123.9 +
2123 + 2121.77 = 2124.72 7-round encryptions.

Linear Cryptanalysis and Its Variants with Fast Fourier Transformation
41
Γin,1
Γin,7
AK7
C
S−1
14 (C
−AK7)
AK7 = AK7[1 : 10]||AK7[12 : 15]
C
= C[1 : 10]||C[12 : 15]
Fig. 4. 7-Round linear attack.
5.5
7-Round Diﬀerential-Linear Attack on HADESMiMC-128
Similar to linear attacks, the time complexity of DL attack can be roughly esti-
mated as the ratio of the guessed key amount to the linear probability of the
distinguisher. As shown in Fig. 5, we add one full S-box round (the seventh
round) after Em and E1 to form a 7-round trail, where the used DL distin-
guisher is with linear probability LP = 2−55.77. There are 13 active S-boxes in
the last round, if we guess all 13 words of the subkey AK7, this leads an invalid
attack with time complexity 255.77 × 25113 = 2159.4.
In order to reduce the complexity, we need to guess fewer subkey words. In
fact, the number of guessed subkey words is required to be less or equal than
8, due to 255.77 × p8 = 2119.54 < 2127.54. Assume that the output mask is active
at position i, then for a pair of word (C0[i], C1[i]) of a ciphertext pair (C0, C1),
we have to guess the subkey word AK7[i] to complete operation S−1(C0[i] −
AK7[i]) −S−1(C1[i] −AK7[i]). However, if the condition C0[i] = C1[i] can be
guranteed when generating ciphertext pairs, then it will return 0 directly without
guessing AK7[i] to decrypt, but this will also consume more data to satisfy the
conditions on the ciphertext pair. Fortunately, by constructing more plaintext
pairs, we can ﬁlter out enough ciphertext pairs that meet the conditions. For
example, suppose that the attack needs N plaintext pairs satisfying the input
diﬀerence. In order to guess one key word less, we need to construct pN plaintext
pairs that satisfy the input diﬀerence to ﬁlter out N ciphertext pairs that meet
the conditions. The details of the key recovery attack are listed as below.
– Set α = 32, then e−α
2 = 2−23.08, Ps = 99.99% and we need N = 2α×LP −1 =
261.77 ciphertext pairs.
– We ﬁrst guess 7 subkey words, which requires p13−7×261.77 = 2109.63 plaintext
pairs to ﬁlter out 261.77 such kind of ciphertext pairs. During the ﬁltering,
we need to perform 2109.63 comparison operations, and each operation can be
equivalent to one S-box operation. There are 3 × 16 + 4 = 52 S-boxes in the
7-round algorithm, so the time complexity of this step is 2109.63 × 1
52 = 2103.93
7-round encryptions.

42
Z. Xu et al.
– Then, we can recover 6 subkey words from these pairs. For this step, the time
complexity is 2 × 261.77 × p7 = 2118.6 parity computations. According to the
α we select, the number of keys left in this step is p7 × e−α
2 = 232.72. Then
these subkeys and the remaining 9 words of the subkey can be obtained by
exhaustive search with about 232.72 × p9 = 2104.46 7-round encryptions.
Finally, by using DL cryptanalysis, 7-round of HADESMiMC-128 can be
attacked with 2110.63 chosen plaintexts and 2110.63+2103.93+2118.6× 6
52+2104.46 =
2115.53 7-round encryptions.
Δin,1
Γout
AK7
(C0, C1)
S−1
7
(C0 −AK7) −S−1
7
(C1 −AK7)
AK7 = AK7[0 : 1]||AK7[9 : 10]||AK7[12 : 14]
C0 = C0[0 : 1]||C0[9 : 10]||C0[12 : 14]
C1 = C1[0 : 1]||C1[9 : 10]||C1[12 : 14]
C0[3 : 8] = C1[3 : 8]
Fig. 5. 7-Round diﬀerential-linear attack.
6
Conclusions
In this paper, we showed that the FFT technique for the estimations of cor-
relation can be applied to the ﬁelds with odd characteristic and signiﬁcantly
improves the complexity of Matsui’s Algorithm 2 over Fp. Then, we generalized
the DL cryptanalysis to Fp. We also included the DLCT into the generalization,
and found the relation between DLCT and DDT over Fp. Finally, as applica-
tions of the FFT-based linear attacks and DL attacks over Fp, we mounted key
recovery attacks on 7-round HADESMiMC-128.
Further Discussion. The main work of this paper is to obtain the theoretical
framework. We show the eﬀectiveness of the theory under 8-bit prime number,
and we also note that the search of the distinguisher under large prime number
is diﬃcult. Therefore, if the distinguisher search technique under large prime
numbers can be further improved, then more ciphers can be evaluated. This is
an interesting question for future research.

Linear Cryptanalysis and Its Variants with Fast Fourier Transformation
43
Acknowledgement. The authors would like to thank the anonymous reviewers
for their valuable comments and suggestions to improve the quality of the paper.
This research is supported by the National Key Research and Development Pro-
gram of China (Grant No. 2018YFA0704702), the National Natural Science Foun-
dation of China (Grant No. 62032014), the Major Basic Research Project of Natu-
ral Science Foundation of Shandong Province, China (Grant No. ZR202010220025).
Puwen Wei is partially supported by National Key R&D Program of China (Grant
No. 2022YFB2701700), Shandong Provincial Natural Science Foundation (Grant No.
ZR2020MF053). Shiyao Chen is supported by the National Research Foundation, Sin-
gapore under its Strategic Capability Research Centres Funding Initiative. Any opin-
ions, ﬁndings and conclusions or recommendations expressed in this material are those
of the author(s) and do not reﬂect the views of National Research Foundation, Singa-
pore.
A
Constructions of HADES and MDS
MDS Matrices. All MDS matrices in the HADES strategy are Cauchy matri-
ces.
Deﬁnition 8 (Cauchy Matrix). Let X
= (x1, · · · , xt) ∈Ft
p and Y
=
(y1, · · · , yt) ∈Ft
p s.t.
– ∀i ̸= j : xi ̸= xj, yi ̸= yj,
– ∀i, j ∈{1, 2, · · · t} : xi + yj ̸= 0, xi ̸= yj.
Let M be the Cauchy matrix corresponding to (X, Y ), then its entry at (i, j) is
Mi,j =
1
xi + yj
.
A Cauchy matrix is an MDS matrix.
Practical
Example.
In
the
cryptanalysis
of
a
concrete
instance
of
HADESMiMC-128 working on GF(251), we select a pair (X, Y ) randomly as
below,
X = [250, 171, 161, 235, 93, 225, 229, 123, 122, 106, 246, 43, 55, 90, 186, 39],
Y = [87, 9, 179, 81, 139, 35, 169, 61, 195, 217, 110, 125, 230, 76, 175, 248],

44
Z. Xu et al.
ARK()
ARK()
ARK()
ARK()
ARK()
ARK()
ARK()
MDS()
MDS()
MDS()
MDS()
MDS()
MDS()
Rf
RP
Rf
Fig. 6. Construction of HADES.
and get the following 16 × 16 Cauchy matrix,
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
108 157 55 91 231 96 127 205 22 43 76 83 57 164 88 188
36 152 71
1 234 145 110 66 227 11 159 106 82 188 37 127
167 220 110 223 41 73 197 225 153 168 113 208 52 233 189 224
99 215 77 112 100 185 105 106 122 5 243 76 156 205 30 66
152 32 12 88 66 151 137 207 95 234 183 38 129 101 192 53
107 59 105 178 20 28 165 208 101 46
3
71 16 246 219 225
112 193 8 234 118 58 181 103 74 121 174 39 35 172 105 10
202 116 64 16 137 224 49 236 15 110 237 167 32 111 235 228
245 23 246 183 226 8 182 203 232 174 66 188 169 161 191 135
238 227 96 200 209 162 136 248 246 129 43 138 189 40 159 39
150 63 88 109 133 159 75 130 144 148 153 228 222 99 220 94
56 140 225 83 40 177 148 70 193 28 105 127 194 135 38 182
175 51 59 24 22 53 158 132 250 12 143 152 96 23 239 140
78 71 14 160 57 249 157 128 96 130 187 244 211 62 18 176
194 121 240 204 173 92 70 188 56 180 106 205 143 137 89 203
2
68 38 228 55 173 35 123 59 201 219 75 14 227 156 7
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠

Linear Cryptanalysis and Its Variants with Fast Fourier Transformation
45
B
Kronecker Product
Deﬁnition 9 (Kronecker Product ⊗). Assume A is a matrix of size m × n
and B is a matrix of size r × s, then the Kronecker Product of A and B is a
matrix C of size mr × ns. In terms of formula :
C = A ⊗B =
⎛
⎜
⎜
⎜
⎝
a11B a12B · · · a1nB
a21B a22B · · · a2nB
...
...
...
...
am1B am2B · · · amnB
⎞
⎟
⎟
⎟
⎠
C
The Construction of Searching Diﬀerential Model
Constraints Imposed by Modular Addition. Let Δ1
in and Δ2
in represent two
input diﬀerences for modular addition, the output diﬀerence is Δout. Then the
character of modular addition due to (Δ1
in, Δ2
in, Δout) is of nonzero probability
if and only if it fulﬁlls Δ1
in + Δ2
in = Δout.
Constraints Imposed by Linear Transformation. Let column vector Δin
and Δout represent the input and output diﬀerences for linear transformation
M. Then the character of M due to (Δin, Δout) is of nonzero probability if and
only if it fulﬁlls Δout = M · Δin.
Constraints Imposed by k-Branch (k ≥3). Let Δin represent the input
diﬀerence for k-branch, the output diﬀerences are Δ1
out, Δ2
out, · · · , Δk−1
out . The
relation between these diﬀerences is Δin = Δ1
out = Δ2
out = · · · = Δk−1
out .
Then the character of k-branch due to (Δin, Δ1
out, · · · , Δk−1
out ) is of nonzero
probability if and only if it fulﬁlls Δin = Δ1
out = Δ2
out = · · · = Δk−1
out .
Constraints Describing the S-box Operation. Suppose Δin and Δout are
the input and output diﬀerences of a bijective S-box S, which is deﬁned over Fp.
Use B[Δin, Δout] as an indicator to represent whether it is a possible diﬀerential
transitions of S. When B[Δin, Δout] = 1, it means that Δin
S
−→Δout is a
possible transitions. Otherwise, it means an impossible transitions. Then, we
have the relations
⎧
⎨
⎩
B[Δin, Δout] = 1,
DDT(Δin, Δout) /∈{0, p}
B[Δin, Δout] = 0,
DDT(Δin, Δout) = p
B[Δin, Δout] = −1, DDT(Δin, Δout) = 0
Objective Function. Now, under the condition that B ̸= −1, we set up the
objective function to be the sum of all indicators of all S-boxes. It corresponds to
the number of active S-boxes, and can be added constraints to determine a lower
bound of the distinguisher. Note that in the block cipher over Fp, the S-box is
generally designed by using the power map, that is x3 and x ∈Fp. Except the
ﬁrst row and ﬁrst column for (Δin, Δout) = (0, 0), the DDT of x3 is kind of

46
Z. Xu et al.
balanced, that is, the half of the entries are 2 and just one entry is 1 in each row
and column. Thus, for any active S-box of x3, it almost has the probability 2
p.
Naturally, we can directly count the number of S-boxes of the distinguisher to
simplify the probability representation in the model for this kind of S-box.
D
Linear Trails Under Other Primes and MDS Matrices
For each p ∈{227, 233, 239}, we randomly select 4 MDS matrices.
p = 227.
– Matrix1:
X = [205, 212, 217, 137, 101, 65, 133, 199, 126, 83, 178, 158, 107, 37, 55, 216],
Y = [52, 201, 25, 146, 159, 220, 114, 66, 182, 98, 135, 47, 197, 87, 54, 169].
– Matrix2:
X = [163, 154, 18, 168, 141, 203, 217, 132, 221, 206, 55, 19, 130, 209, 72, 7],
Y = [215, 178, 148, 156, 57, 32, 15, 58, 138, 152, 118, 133, 224, 116, 60, 68].
– Matrix3:
X = [152, 161, 106, 200, 172, 60, 94, 179, 20, 160, 176, 164, 195, 50, 187, 193],
Y = [198, 91, 115, 6, 183, 217, 41, 221, 219, 22, 101, 28, 148, 9, 88, 175].
– Matrix4:
X = [226, 148, 161, 24, 91, 116, 3, 16, 222, 107, 14, 65, 102, 106, 200, 20],
Y = [174, 73, 163, 95, 58, 188, 146, 176, 205, 9, 132, 217, 155, 189, 122, 11].
(See Tables 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12 and 13).
Table 2. 6-round linear distinguisher (p = 227, matrix1) (hexadecimal representation).
Round
masks before S-boxes Γin,i
masks after S-boxes Γout,i
1
5c, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00 a4, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00
2
c9, 8e, 01, 8c, 72, 33, 3a, 71, 42, b5, b2, 78, aa, 4f, 3b, 66 c9, 8e, 01, 8c, 72, 33, 3a, 71, 42, b5, b2, 78, aa, 4f, 3b, 78
3
2a, 8a, 54, 97, 18, 9c, d3, 11, b3, 0d, 69, d5, 98, 20, 47, 67 2a, 8a, 54, 97, 18, 9c, d3, 11, b3, 0d, 69, d5, 98, 20, 47, 9e
4
df, 73, 75, ab, 34, 42, a5, e2, 7a, 3b, 36, 4e, 87, 48, b7, 67 df, 73, 75, ab, 34, 42, a5, e2, 7a, 3b, 36, 4e, 87, 48, b7, 5e
5
77, 94, c5, c6, 4a, c6, c2, 68, 04, 5a, 40, be, 31, 07, 79, bc 77, 94, c5, c6, 4a, c6, c2, 68, 04, 5a, 40, be, 31, 07, 79, e0
6
57, 19, 7b, b5, 2b, 73, bf, 40, b1, 33, ae, 87, b2, 00, 74, 77 3d, 50, 5a, 63, cf, dd, 92, 66, c4, aa, be, 3f, b1, 00, 70, 85
7
79, 3f, 81, d3, 00, 1b, 41, bc, 27, 5f, 7d, 00, a6, 1d, 16, 94
p = 233.

Linear Cryptanalysis and Its Variants with Fast Fourier Transformation
47
Table 3. 6-round linear distinguisher (p = 227, matrix2) (hexadecimal representation).
Round
masks before S-boxes Γin,i
masks after S-boxes Γout,i
1
00, 00, 00, 00, 00, 00, 00, 00, 5c, 00, 00, 00, 00, 00, 00, 00 00, 00, 00, 00, 00, 00, 00, 00, 0a, 00, 00, 00, 00, 00, 00, 00
2
ae, d2, 11, 14, 0f, 0a, b5, 70, 19, 1b, 81, 9a, aa, a2, 14, 23 ae, d2, 11, 14, 0f, 0a, b5, 70, 19, 1b, 81, 9a, aa, a2, 14, 0f
3
65, 4a, c7, b6, 58, 20, 00, b3, 7c, a2, 5a, 04, 43, 69, 8f, 96 65, 4a, c7, b6, 58, 20, 00, b3, 7c, a2, 5a, 04, 43, 69, 8f, 78
4
28, 69, 9b, c1, 9b, 46, 64, c0, 25, c9, 4d, af, 0a, ca, bb, 71 28, 69, 9b, c1, 9b, 46, 64, c0, 25, c9, 4d, af, 0a, ca, bb, 91
5
aa, 28, 8a, b6, 73, 9f, a4, 47, 0f, 1d, 37, 83, 64, 7e, de, cc aa, 28, 8a, b6, 73, 9f, a4, 47, 0f, 1d, 37, 83, 64, 7e, de, d3
6
b3, 34, 79, c1, 00, c3, af, e0, b2, 81, 96, 29, 15, 95, 94, 75 d2, 1b, d3, 8f, 00, 2c, 44, 30, 2e, 4a, 9c, d8, 6b, dd, 36, b0
7
48, 8d, a4, 39, 3a, 5c, 38, 7a, df, 57, 00, 00, 29, 02, 09, 37
Table 4. 6-round linear distinguisher (p = 227, matrix3) (hexadecimal representation).
Round
masks before S-boxes Γin,i
masks after S-boxes Γout,i
1
00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 03 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 6e
2
5d, a2, 8d, c2, 6f, b4, ab, 68, 0d, 53, 85, 42, 4b, c1, 8c, 58 5d, a2, 8d, c2, 6f, b4, ab, 68, 0d, 53, 85, 42, 4b, c1, 8c, 61
3
40, 1a, 8e, 92, 4d, 10, 67, 2c, c5, a1, 0f, 45, 6b, 3b, 3c, 33 40, 1a, 8e, 92, 4d, 10, 67, 2c, c5, a1, 0f, 45, 6b, 3b, 3c, d6
4
6a, 90, 27, 11, a4, 3b, d8, 1d, d8, 11, 62, 60, a3, 7b, 29, 00 6a, 90, 27, 11, a4, 3b, d8, 1d, d8, 11, 62, 60, a3, 7b, 29, 00
5
dd, 45, d4, 00, 12, c5, 65, 58, 17, 59, 0d, c1, 72, 8c, 28, 89 dd, 45, d4, 00, 12, c5, 65, 58, 17, 59, 0d, c1, 72, 8c, 28, 8d
6
7b, 75, e2, 85, 33, cb, 98, b1, 25, 96, 90, 3f, 44, d9, 44, 7b 5a, 4d, 1b, dc, aa, 3c, db, 29, 4c, 1c, ce, a5, 88, 60, da, 5a
7
ce, 34, c1, 15, 00, 0b, a1, 8f, 00, be, 90, 89, 1a, 9c, 2c, ca
Table 5. 6-round linear distinguisher (p = 227, matrix4) (hexadecimal representation).
Round
masks before S-boxes Γin,i
masks after S-boxes Γout,i
1
00, 00, 00, 35, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00 00, 00, 00, 02, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00
2
ce, 02, 93, 17, 7d, ae, e0, af, 6e, 7c, 2c, ad, 65, d3, 9a, 26 ce, 02, 93, 17, 7d, ae, e0, af, 6e, 7c, 2c, ad, 65, d3, 9a, b6
3
e1, 49, 46, 78, 4d, c9, 0d, 9b, 08, 8e, 4a, 97, 1c, d6, ca, 09 e1, 49, 46, 78, 4d, c9, 0d, 9b, 08, 8e, 4a, 97, 1c, d6, ca, 66
4
1e, 9b, 77, e1, 23, cb, 36, c1, ba, b8, 35, ce, b3, 42, 1a, 31 1e, 9b, 77, e1, 23, cb, 36, c1, ba, b8, 35, ce, b3, 42, 1a, 04
5
dc, 04, 9c, b0, 1b, 5d, c0, 58, b7, c9, 19, 13, 73, c4, 99, 70 dc, 04, 9c, b0, 1b, 5d, c0, 58, b7, c9, 19, 13, 73, c4, 99, e0
6
79, 4a, ae, 67, 76, 09, 2c, ab, c5, 79, 65, 6c, 95, 00, 5b, 27 9e, b1, be, 0f, c9, 72, 2f, 8a, 5f, 49, 2a, 5e, e2, 00, 2f, ab
7
55, 97, 00, 3a, 0e, 04, 20, a4, a0, 53, d8, 5f, 27, 42, 00, d0
– Matrix1:
X = [34, 80, 174, 199, 153, 19, 111, 1, 56, 150, 198, 119, 125, 60, 47, 78],
Y = [86, 196, 154, 178, 135, 219, 61, 194, 127, 170, 137, 43, 211, 68, 93, 4].
– Matrix2:
X = [81, 27, 2, 10, 213, 71, 94, 181, 62, 74, 192, 111, 139, 23, 54, 115],
Y = [183, 228, 32, 166, 126, 70, 190, 11, 6, 91, 187, 216, 66, 33, 145, 7].
– Matrix3:
X = [228, 65, 24, 172, 16, 124, 10, 197, 157, 27, 107, 44, 87, 84, 115, 92],
Y = [176, 173, 88, 139, 54, 208, 63, 15, 3, 86, 114, 83, 164, 155, 120, 82].

48
Z. Xu et al.
Table 6. 6-round linear distinguisher (p = 233, matrix1) (hexadecimal representation).
Round
masks before S-boxes Γin,i
masks after S-boxes Γout,i
1
00, 00, 00, 00, 57, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00 00, 00, 00, 00, 6f, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00
2
6B, A7, 52, AB, 39, B8, 7E, BC, 79, 83, 7C, 31, A6, 08, 2C, 84 6B, A7, 52, AB, 39, B8, 7E, BC, 79, 83, 7C, 31, A6, 08, 2C, be
3
DC, 41, 6F, A8, 18, 77, 8B, D1, 58, E7, AF, 42, 12, 38, 44, 53 DC, 41, 6F, A8, 18, 77, 8B, D1, 58, E7, AF, 42, 12, 38, 44, 23
4
35, E3, 37, DA, 26, 2A, E8, 86, 9B, 87, 09, 5A, 17, 3A, 51, 02 35, E3, 37, DA, 26, 2A, E8, 86, 9B, 87, 09, 5A, 17, 3A, 51, 80
5
12, 8E, D6, E7, 10, B6, 37, 22, 7E, 73, B3, 2A, 82, AE, 14, 07 12, 8E, D6, E7, 10, B6, 37, 22, 7E, 73, B3, 2A, 82, AE, 14, 08
6
12, 65, 7d, 78, 91, 4e, 00, ad, 2e, cf, 7f, 7a, 52, 2f, cc, 74 53, 25, 9e, aa, 29, 18, 00, 8e, 6d, 01, 2a, c1, 1a, 36, cb, 8f
7
00, 8d, 9c, 00, 05, 8c, 67, e6, 9e, d5, af, dd, 10, 16, 5c, 64
Table 7. 6-round linear distinguisher (p = 233, matrix2) (hexadecimal representation).
Round
masks before S-boxes Γin,i
masks after S-boxes Γout,i
1
00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 20, 00, 00
00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, e2, 00, 00
2
B1, 37, 8D, 2F, 24, D2, A5, 32, 19, 09, 3B, 0B, 7A, 2F, 95, 2c
B1, 37, 8D, 2F, 24, D2, A5, 32, 19, 09, 3B, 0B, 7A, 2F, 95, 97
3
5B, AF, 81, C2, 4F, 7F, D2, 35, D4, 28, 5E, 6D, 76, 8D, 1A, 5c
5B, AF, 81, C2, 4F, 7F, D2, 35, D4, 28, 5E, 6D, 76, 8D, 1A, ba
4
5F, DD, 4D, 75, 91, 8B, D5, 16, 1D, 8E, 35, 53, 8E, 6D, CF, 6f
5F, DD, 4D, 75, 91, 8B, D5, 16, 1D, 8E, 35, 53, 8E, 6D, CF, 85
5
DE, 03, 58, 01, 5B, 42, A9, 3F, 8C, AD, 7F, 74, 56, 5C, 3E, 00
DE, 03, 58, 01, 5B, 42, A9, 3F, 8C, AD, 7F, 74, 56, 5C, 3E, 00
6
bf, 96, 9d, 3a, 41, 9c, 40, 9f, df, b0, df, 1a, 1b, cf, e4, 0a
35, 96, a1, 2f, 82, 53, a6, 9b, b0, b7, b0, e8, 86, 01, 16, 1e
7
86, 39, 00, 4d, 7f, ca, cd, a6, 00, 5d, ab, 4c, 01, d1, 49, 15, 00
Table 8. 6-round linear distinguisher (p = 233, matrix3) (hexadecimal representation).
Round
masks before S-boxes Γin,i
masks after S-boxes Γout,i
1
00, 00, 00, 00, 00, 00, 00, 5a, 00, 00, 00, 00, 00, 00, 00, 00 00, 00, 00, 00, 00, 00, 00, d7, 00, 00, 00, 00, 00, 00, 00, 00
2
24, DC, 7D, A3, BB, 09, D6, E8, 10, 26, 95, D5, 70, 66, 4E, 10 24, DC, 7D, A3, BB, 09, D6, E8, 10, 26, 95, D5, 70, 66, 4E, 02
3
76, 56, E4, 9A, 60, 78, 69, 00, 3A, 4B, 96, 6A, 54, 83, 49, 83 76, 56, E4, 9A, 60, 78, 69, 00, 3A, 4B, 96, 6A, 54, 83, 49, 3e
4
21, 85, C2, 6A, B9, B6, 1B, AD, E0, D3, 6A, A6, 55, C5, 65, be 21, 85, C2, 6A, B9, B6, 1B, AD, E0, D3, 6A, A6, 55, C5, 65, e0
5
C9, A5, 78, E0, E4, 3B, 71, 0B, A5, 33, 73, 86, C2, 40, 67, 00 C9, A5, 78, E0, E4, 3B, 71, 0B, A5, 33, 73, 86, C2, 40, 67, 00
6
15, 12, 15, 31, bb, 1f, ae, 17, dd, 47, 94, 42, b2, 4f, 16, d5 cc, 93, 9f, 82, 35, 06, 97, db, 72, 09, cf, 51, c1, dc, db, 0a
7
a8, 3a, d8, 43, c6, ba, 9e, 25, a4, 36, a1, 00, 32, 88, 00, 4c
Table 9. 6-round linear distinguisher (p = 233, matrix4) (hexadecimal representation).
Round
masks before S-boxes Γin,i
masks after S-boxes Γout,i
1
00, 00, 00, 9d, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00 00, 00, 00, a1, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00
2
4B, 08, E4, 88, 12, 19, E7, 3A, 8F, A7, B4, B6, 8F, 15, 36, 69 4B, 08, E4, 88, 12, 19, E7, 3A, 8F, A7, B4, B6, 8F, 15, 36, 12
3
56, 24, 77, 71, 91, C8, 4E, 6F, 20, 25, 8B, 7C, 6D, 6D, AE, 00 56, 24, 77, 71, 91, C8, 4E, 6F, 20, 25, 8B, 7C, 6D, 6D, AE, 00
4
06, CC, D9, 06, 82, 49, D0, 15, 08, CA, AA, 13, 80, 51, 44, 3f 06, CC, D9, 06, 82, 49, D0, 15, 08, CA, AA, 13, 80, 51, 44, b7
5
2D, 05, 22, 78, 30, CD, 8B, 5E, 95, 17, A7, 0A, 70, C9, 45, 0f 2D, 05, 22, 78, 30, CD, 8B, 5E, 95, 17, A7, 0A, 70, C9, 45, c9
6
b0, 9f, 1f, 79, 8d, 38, 3b, 58, 71, a7, 63, 67, 16, 52, e6, b2 39, 9b, 3a, 89, c5, d2, 52, c0, 77, 50, ba, 7d, 39, de, d5, c1
7
16, 1b, 28, e7, 6b, a3, 3d, 43, 80, ac, 0b, c9, 74, 00, 51, 00
– Matrix4:
X = [38, 8, 88, 226, 159, 188, 165, 103, 217, 137, 129, 140, 143, 157, 231, 110],
Y = [151, 179, 200, 4, 198, 114, 187, 94, 116, 199, 168, 219, 189, 81, 180, 191].
p = 239.

Linear Cryptanalysis and Its Variants with Fast Fourier Transformation
49
– Matrix1:
X = [57, 46, 202, 32, 190, 104, 54, 174, 63, 114, 120, 27, 186, 35, 160, 115],
Y = [42, 91, 6, 44, 90, 131, 201, 164, 62, 39, 48, 70, 69, 127, 139, 158].
– Matrix2:
X = [181, 218, 128, 122, 134, 236, 96, 195, 155, 156, 68, 15, 23, 217, 28, 85],
Y = [142, 42, 130, 215, 135, 148, 93, 50, 73, 174, 186, 7, 198, 150, 210, 30].
– Matrix3:
X = [135, 34, 176, 227, 29, 22, 37, 218, 224, 119, 60, 75, 183, 214, 171, 88],
Y = [54, 225, 173, 85, 77, 137, 199, 203, 230, 27, 174, 65, 13, 131, 4, 32].
– Matrix4:
X = [86, 157, 220, 85, 59, 227, 154, 206, 50, 84, 23, 125, 64, 105, 134, 103],
Y = [217, 40, 25, 43, 193, 49, 1, 160, 46, 94, 186, 97, 108, 161, 131, 37].
Table 10. 6-round linear distinguisher (p = 239, matrix1) (hexadecimal representa-
tion).
Round
masks before S-boxes Γin,i
masks after S-boxes Γout,i
1
00, 00, 00, 00, 24, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00 00, 00, 00, 00, b5, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00
2
57, 0E, 90, EB, 72, 4A, 3C, 57, AA, 1A, 19, 0C, 60, 16, 8E, 6b 57, 0E, 90, EB, 72, 4A, 3C, 57, AA, 1A, 19, 0C, 60, 16, 8E, 47
3
15, AD, 02, AB, 69, 5D, 56, 35, 81, 88, CB, C7, 8C, D4, D5, 58 15, AD, 02, AB, 69, 5D, 56, 35, 81, 88, CB, C7, 8C, D4, D5, 6c
4
CD, 85, E9, 6A, 3E, B5, 86, A0, 9B, 33, 03, 52, C4, 18, 04, d3 CD, 85, E9, 6A, 3E, B5, 86, A0, 9B, 33, 03, 52, C4, 18, 04, 6e
5
5D, EC, 9F, E2, 24, C2, C5, 81, 3D, 9B, 67, 72, 95, B3, A9, e5 5D, EC, 9F, E2, 24, C2, C5, 81, 3D, 9B, 67, 72, 95, B3, A9, 34
6
d5, 44, 92, c1, af, af, 33, ad, 4c, 1c, 00, 72, 00, 9d, 9e, 79 8b, 3f, b8, b1, 55, 1b, bc, 09, 8e, 43, 00, 19, 00, 4d, 1d, 4a
7
b2, 27, d0, 00, 9d, e1, 79, 00, 96, 1f, 53, a4, bc, 38, 2a, 5e
Table 11. 6-round linear distinguisher (p = 239, matrix2) (hexadecimal representa-
tion).
Round
masks before S-boxes Γin,i
masks after S-boxes Γout,i
1
00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, bf, 00, 00 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 69, 00, 00
2
B1, 32, 93, BB, 4E, 30, C8, 79, 29, 64, D1, 80, 1B, 08, E9, 6f B1, 32, 93, BB, 4E, 30, C8, 79, 29, 64, D1, 80, 1B, 08, E9, 44
3
70, 7F, 0D, E3, 8E, E9, 08, 94, 20, 10, 82, 6C, 9B, EB, 7E, c7 70, 7F, 0D, E3, 8E, E9, 08, 94, 20, 10, 82, 6C, 9B, EB, 7E, 80
4
CD, 66, 0E, B9, 30, 7E, EB, 11, 69, 64, 30, A6, E0, A4, 5B, 8b CD, 66, 0E, B9, 30, 7E, EB, 11, 69, 64, 30, A6, E0, A4, 5B, 1c
5
A4, 1A, EB, 9A, DD, BB, 36, 8C, 1B, 69, 3A, 47, 0D, A9, 6D, 23 A4, 1A, EB, 9A, DD, BB, 36, 8C, 1B, 69, 3A, 47, 0D, A9, 6D, 94
6
3c, 09, b9, 16, 00, 71, 9c, 72, 00, 26, a0, a1, 49, ee, b6, 1b b8, d2, 59, 65, 00, e4, 3c, 3d, 00, 6e, 56, 59, 02, ae, ce, 98
7
8a, d5, 00, 0b, cc, 08, de, 00, 44, a2, e6, 57, 72, 9b, 65, cd

50
Z. Xu et al.
Table 12. 6-round linear distinguisher (p = 239, matrix3) (hexadecimal representa-
tion).
Round
masks before S-boxes Γin,i
masks after S-boxes Γout,i
1
01, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00 12, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00
2
DD, 57, 1F, D8, 27, A8, 51, EE, A6, A5, 81, BE, 7D, 01, 89, 69 DD, 57, 1F, D8, 27, A8, 51, EE, A6, A5, 81, BE, 7D, 01, 89, 40
3
ED, DA, 20, 86, 63, 16, 90, 24, 50, 84, 03, CA, 77, AF, 16, 57 ED, DA, 20, 86, 63, 16, 90, 24, 50, 84, 03, CA, 77, AF, 16, 1d
4
82, 99, E4, 40, A8, ED, 34, CE, BF, 25, 7F, 07, ED, 81, C3, 00 82, 99, E4, 40, A8, ED, 34, CE, BF, 25, 7F, 07, ED, 81, C3, 00
5
60, 70, 57, 10, 24, D4, 66, BB, 5B, B4, 3B, C7, B3, 28, C8, 18 60, 70, 57, 10, 24, D4, 66, BB, 5B, B4, 3B, C7, B3, 28, C8, 02
6
8d, b0, a7, a2, 00, e7, 37, 17, b9, 29, d2, 96, 7b, 10, 31, e3 40, 94, 7a, 07, 00, 7a, 5f, 53, 32, 04, a6, 67, 01, 4e, 22, 71
7
44, b2, 00, 32, 1c, 9d, a7, 2e, 01, 00, d3, 79, 24, 6c, 29, 95
Table 13. 6-round linear distinguisher (p = 239, matrix4) (hexadecimal representa-
tion).
Round
masks before S-boxes Γin,i
masks after S-boxes Γout,i
1
00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 36, 00, 00, 00, 00 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, 00, ce, 00, 00, 00, 00
2
22, CA, 76, 18, 88, 32, BA, CA, EA, 2B, 9C, 40, 1E, 74, B2, 61 22, CA, 76, 18, 88, 32, BA, CA, EA, 2B, 9C, 40, 1E, 74, B2, d6
3
A6, 15, 3A, 9E, B6, A7, 9B, 07, CC, BB, E7, 1D, 2D, 1C, DD, da A6, 15, 3A, 9E, B6, A7, 9B, 07, CC, BB, E7, 1D, 2D, 1C, DD, ce
4
ED, 4B, 9C, BF, 33, 39, 09, 97, DA, 02, CC, 6A, 14, 98, 51, 77 ED, 4B, 9C, BF, 33, 39, 09, 97, DA, 02, CC, 6A, 14, 98, 51, 98
5
C4, BE, 23, 24, 21, 0E, E5, 6E, 93, 92, ED, E1, 25, E7, 15, 85 C4, BE, 23, 24, 21, 0E, E5, 6E, 93, 92, ED, E1, 25, E7, 15, 25
6
08, b9, b1, 55, 33, 1b, a0, a6, 92, 72, 30, 00, 58, cd, 30, bc bd, 2c, 31, 38, bc, 72, 4c, c7, 51, 3d, b1, 00, 8a, 16, b1, 24
7
17, d4, 00, 6e, 42, 40, 7f, 00, ce, eb, 9c, 25, 56, a6, cd, 50
References
1. Albrecht, M.R., et al.: Algebraic cryptanalysis of STARK-friendly designs: appli-
cation to MARVELlous and MiMC. In: Galbraith, S.D., Moriai, S. (eds.) ASI-
ACRYPT 2019. LNCS, vol. 11923, pp. 371–397. Springer, Cham (2019). https://
doi.org/10.1007/978-3-030-34618-8 13
2. Albrecht, M.R., et al.: Feistel structures for MPC, and more. In: Sako, K., Schnei-
der, S., Ryan, P.Y.A. (eds.) ESORICS 2019. LNCS, vol. 11736, pp. 151–171.
Springer, Cham (2019). https://doi.org/10.1007/978-3-030-29962-0 8
3. Albrecht, M., Grassi, L., Rechberger, C., Roy, A., Tiessen, T.: MiMC: eﬃcient
encryption and cryptographic hashing with minimal multiplicative complexity. In:
Cheon, J.H., Takagi, T. (eds.) ASIACRYPT 2016. LNCS, vol. 10031, pp. 191–219.
Springer, Heidelberg (2016). https://doi.org/10.1007/978-3-662-53887-6 7
4. Aly, A., Ashur, T., Ben-Sasson, E., Dhooghe, S., Szepieniec, A.: Design of
symmetric-key primitives for advanced cryptographic protocols. IACR Trans. Sym-
metric Cryptol. 2020(3), 1–45 (2020)
5. Baign`eres, T., Stern, J., Vaudenay, S.: Linear cryptanalysis of non binary ciphers.
In: Adams, C., Miri, A., Wiener, M. (eds.) SAC 2007. LNCS, vol. 4876, pp. 184–
211. Springer, Heidelberg (2007). https://doi.org/10.1007/978-3-540-77360-3 13
6. Bar-On, A., Dunkelman, O., Keller, N., Weizman, A.: DLCT: a new tool for
diﬀerential-linear cryptanalysis. In: Ishai, Y., Rijmen, V. (eds.) EUROCRYPT
2019. LNCS, vol. 11476, pp. 313–342. Springer, Cham (2019). https://doi.org/
10.1007/978-3-030-17653-2 11
7. Barrett, C.W., Sebastiani, R., Seshia, S.A., Tinelli, C.: Satisﬁability modulo the-
ories. In: Handbook of Satisﬁability, Frontiers in Artiﬁcial Intelligence and Appli-
cations, vol. 185, pp. 825–885

Linear Cryptanalysis and Its Variants with Fast Fourier Transformation
51
8. Beierle, C., et al.: Improved diﬀerential-linear attacks with applications to ARX
ciphers. J. Cryptol. 35(4), 29 (2022)
9. Beyne, T., et al.: Out of oddity – new cryptanalytic techniques against symmetric
primitives optimized for integrity proof systems. In: Micciancio, D., Ristenpart,
T. (eds.) CRYPTO 2020. LNCS, vol. 12172, pp. 299–328. Springer, Cham (2020).
https://doi.org/10.1007/978-3-030-56877-1 11
10. Biham, E., Dunkelman, O., Keller, N.: Enhancing diﬀerential-linear cryptanalysis.
In: Zheng, Y. (ed.) ASIACRYPT 2002. LNCS, vol. 2501, pp. 254–266. Springer,
Heidelberg (2002). https://doi.org/10.1007/3-540-36178-2 16
11. Biham, E., Shamir, A.: Diﬀerential cryptanalysis of DES-like cryptosystems. J.
Cryptol. 4(1), 3–72 (1991)
12. Biryukov, A., De Canni`ere, C., Quisquater, M.: On multiple linear approxima-
tions. In: Franklin, M. (ed.) CRYPTO 2004. LNCS, vol. 3152, pp. 1–22. Springer,
Heidelberg (2004). https://doi.org/10.1007/978-3-540-28628-8 1
13. Bleichenbacher, D.: On the generation of DSA one-time keys. In: Presentation at
Cryptography Research Inc., San Francisco (2007)
14. Blondeau, C., Leander, G., Nyberg, K.: Diﬀerential-linear cryptanalysis revisited.
J. Cryptol. 30(3), 859–888 (2017)
15. Blondeau, C., Nyberg, K.: New links between diﬀerential and linear cryptanalysis.
In: Johansson, T., Nguyen, P.Q. (eds.) EUROCRYPT 2013. LNCS, vol. 7881, pp.
388–404. Springer, Heidelberg (2013). https://doi.org/10.1007/978-3-642-38348-
9 24
16. Bogdanov, A., et al.: PRESENT: an ultra-lightweight block cipher. In: Paillier,
P., Verbauwhede, I. (eds.) CHES 2007. LNCS, vol. 4727, pp. 450–466. Springer,
Heidelberg (2007). https://doi.org/10.1007/978-3-540-74735-2 31
17. Bogdanov, A., Rijmen, V.: Linear hulls with correlation zero and linear cryptanal-
ysis of block ciphers. Des. Codes Cryptogr. 70(3), 369–383 (2014)
18. Chabaud, F., Vaudenay, S.: Links between diﬀerential and linear cryptanalysis. In:
De Santis, A. (ed.) EUROCRYPT 1994. LNCS, vol. 950, pp. 356–365. Springer,
Heidelberg (1995). https://doi.org/10.1007/BFb0053450
19. Collard, B., Standaert, F.-X., Quisquater, J.-J.: Improving the time complexity of
Matsui’s linear cryptanalysis. In: Nam, K.-H., Rhee, G. (eds.) ICISC 2007. LNCS,
vol. 4817, pp. 77–88. Springer, Heidelberg (2007). https://doi.org/10.1007/978-3-
540-76788-6 7
20. Cook, S.A.: The complexity of theorem-proving procedures. In: STOC, pp. 151–
158. ACM (1971)
21. Cooley, J.W., Tukey, J.W.: An algorithm for the machine calculation of complex
Fourier series. Math. Comput. 19(90), 297–301 (1965)
22. Daemen, J., Rijmen, V.: The Design of Rijndael: AES - The Advanced Encryption
Standard. ISC, Springer, Heidelberg (2002). https://doi.org/10.1007/978-3-662-
04722-4
23. Davis, P.J.: Circulant Matrices. American Mathematical Society (2013)
24. Dobraunig, C., Grassi, L., Guinet, A., Kuijsters, D.: Ciminion: symmetric encryp-
tion based on Toﬀoli-Gates over large ﬁnite ﬁelds. In: Canteaut, A., Standaert,
F.-X. (eds.) EUROCRYPT 2021. LNCS, vol. 12697, pp. 3–34. Springer, Cham
(2021). https://doi.org/10.1007/978-3-030-77886-6 1
25. Eichlseder, M., et al.: An algebraic attack on ciphers with low-degree round func-
tions: application to full MiMC. In: Moriai, S., Wang, H. (eds.) ASIACRYPT 2020.
LNCS, vol. 12491, pp. 477–506. Springer, Cham (2020). https://doi.org/10.1007/
978-3-030-64837-4 16

52
Z. Xu et al.
26. Fl´orez-Guti´errez, A.: Optimising linear key recovery attacks with aﬃne Walsh
transform pruning. In: Agrawal, S., Lin, D. (eds.) ASIACRYPT 2022. LNCS, vol.
13794, pp. 447–476. Springer, Cham (2022). https://doi.org/10.1007/978-3-031-
22972-5 16
27. Fl´orez-Guti´errez, A., Naya-Plasencia, M.: Improving key-recovery in linear attacks:
application to 28-round PRESENT. In: Canteaut, A., Ishai, Y. (eds.) EURO-
CRYPT 2020. LNCS, vol. 12105, pp. 221–249. Springer, Cham (2020). https://
doi.org/10.1007/978-3-030-45721-1 9
28. Grassi, L., Hao, Y., Rechberger, C., Schofnegger, M., Walch, R., Wang, Q.: A new
Feistel approach meets ﬂuid-SPN: griﬃn for zero-knowledge applications. IACR
Cryptology ePrint Archive, p. 403 (2022)
29. Grassi, L., Khovratovich, D., L¨uftenegger, R., Rechberger, C., Schofnegger, M.,
Walch, R.: Reinforced concrete: a fast hash function for veriﬁable computation. In:
CCS, pp. 1323–1335. ACM (2022)
30. Grassi, L., L¨uftenegger, R., Rechberger, C., Rotaru, D., Schofnegger, M.: On a
generalization of substitution-permutation networks: the HADES design strategy.
In: Canteaut, A., Ishai, Y. (eds.) EUROCRYPT 2020. LNCS, vol. 12106, pp. 674–
704. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-45724-2 23
31. K¨olbl, S., Leander, G., Tiessen, T.: Observations on the SIMON block cipher fam-
ily. In: Gennaro, R., Robshaw, M. (eds.) CRYPTO 2015. LNCS, vol. 9215, pp.
161–185. Springer, Heidelberg (2015). https://doi.org/10.1007/978-3-662-47989-
6 8
32. Langford, S.K., Hellman, M.E.: Diﬀerential-linear cryptanalysis. In: Desmedt, Y.G.
(ed.) CRYPTO 1994. LNCS, vol. 839, pp. 17–25. Springer, Heidelberg (1994).
https://doi.org/10.1007/3-540-48658-5 3
33. Liu, Z., Gu, D., Zhang, J., Li, W.: Diﬀerential-multiple linear cryptanalysis. In:
Bao, F., Yung, M., Lin, D., Jing, J. (eds.) Inscrypt 2009. LNCS, vol. 6151, pp.
35–49. Springer, Heidelberg (2010). https://doi.org/10.1007/978-3-642-16342-5 3
34. Lu, J.: A methodology for diﬀerential-linear cryptanalysis and its applications.
Des. Codes Cryptogr. 77(1), 11–48 (2015)
35. Matsui, M.: Linear cryptanalysis method for DES cipher. In: Helleseth, T. (ed.)
EUROCRYPT 1993. LNCS, vol. 765, pp. 386–397. Springer, Heidelberg (1994).
https://doi.org/10.1007/3-540-48285-7 33
36. Mouha, N., Wang, Q., Gu, D., Preneel, B.: Diﬀerential and linear cryptanalysis
using mixed-integer linear programming. In: Wu, C.-K., Yung, M., Lin, D. (eds.)
Inscrypt 2011. LNCS, vol. 7537, pp. 57–76. Springer, Heidelberg (2012). https://
doi.org/10.1007/978-3-642-34704-7 5
37. Sun, S., et al.: Analysis of AES, SKINNY, and others with constraint programming.
IACR Trans. Symmetric Cryptol. 2017(1), 281–306 (2017)
38. Sun, S., Hu, L., Wang, P., Qiao, K., Ma, X., Song, L.: Automatic security eval-
uation and (related-key) diﬀerential characteristic search: application to SIMON,
PRESENT, LBlock, DES(L) and other bit-oriented block ciphers. In: Sarkar, P.,
Iwata, T. (eds.) ASIACRYPT 2014. LNCS, vol. 8873, pp. 158–178. Springer, Hei-
delberg (2014). https://doi.org/10.1007/978-3-662-45611-8 9

A New Correlation Cube Attack Based
on Division Property
Cheng Che1,2 and Tian Tian1(B)
1 Information Engineering University, Zhengzhou 450001, China
tiantian_d@126.com
2 State Key Laboratory of Cryptology, P. O. Box 5159, Beijing 100878, China
Abstract. Correlation cube attacks were proposed by Liu et al. at
EUROCRYPT 2018, which targeted a modern symmetric-key cryptosys-
tem based on nonlinear feedback shift registers. The main idea of cor-
relation cube attacks lies in recovering the secret key by exploiting con-
ditional correlation properties between the superpoly of a cube and a
speciﬁc set of low-degree polynomials called a basis. In this paper, we
propose a new correlation cube attack based on the division property.
The new attack expresses a given superpoly p as fg ⊕h and calculates
correlation probabilities for all possible f, where f only involves key
variables. This novel idea breaks the restriction on the basis used in the
original attack and provides more choices to ﬁnd good correlation prob-
abilities, thus making the correlation cube attack much more powerful.
Besides, the ﬁrst application of the division property to correlation cube
attacks is given, which aided by MILP modeling techniques facilitates
the search for desirable cubes. As illustrations, we apply the new corre-
lation cube attack to Trivium. For 844-round Trivium, we can recover
about 4-bit key information on average with the time complexity 245,
which could be fully veriﬁed by experiments. This is so far the best key
recovery attack for 844-round Trivium.
Keywords: Cube Attack · Division Property · Stream cipher ·
Trivium
1
Introduction
The cube attack is a powerful cryptanalytic technique against symmetric cryp-
tosystems proposed by Dinur and Shamir at Eurocrypt 2009 [1]. The attack
process of cube attacks includes preprocessing and online phases. In the pre-
processing phase, eﬀective cubes are obtained by search, and the corresponding
superpolies are recovered. In the online phase, all possible values of the cube
variables are assigned, and then the encryption oracle is queried and summed
to obtain the value of the superpolies under the real key. Finally, information
about the secret key can be revealed by solving the system of equations. It can
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 53–71, 2023.
https://doi.org/10.1007/978-3-031-35486-1_3

54
C. Che and T. Tian
be seen that the key to a successful cube attack is to search for good cubes and
recover superpolies.
Recovering Superpolies. In traditional cube attacks [1–3], attackers regard
the cryptographic algorithm as a black box and experimentally search for lin-
ear or quadratic superpolies. In [4], the conventional bit-based division property
(CBDP) was ﬁrst introduced to cube attacks on stream ciphers. For a given cube
set, Todo et al. established and solved the MILP model to identify the secret vari-
ables not involved in the superpoly. In order to improve the eﬀectiveness of the
model, some new techniques were given in [5,6]. However, neither experimental
cube attacks nor CBDP-based cube attacks can accurately recover superpolies.
In [7,8], Ye and Tian preliminarily solved this problem. Several superpolies are
recovered by recursively-expressing [7] and algebraic [8] methods, respectively,
but both methods have limitations. At Eurocrypt 2020 [9], Hao et al. proposed
the three-subset division property without unknown subsets to recover the exact
superpolies, thus successfully solving this problem. Meanwhile, Hu et al. in [10]
proposed a monomial prediction technique based on the propagation of mono-
mials. Moreover, they established the equivalence between the technique and
the three-subset division property without unknown subsets. Later, Hu et al.
[11] combined the monomial prediction technique with the recursively-expressing
method in [7] and presented a nested framework for recovering the ANFs of mas-
sive superpolies. Very recently, He et al. in [12] introduced two new techniques
on the nested framework, which allows attackers to recover the superpolies that
contain more than 500 million terms.
Searching for Cubes. As the method of recovering superpolies becomes more
and more eﬀective, another problem of cube attacks, i.e., how to select good
cubes to make a cube attack more eﬀective, is attracting more and more atten-
tion. Since a system of linear equations is quite easy to solve, linear superpolies
are most useful in a cube attack. At Asiacrypt 2021, based on the greedy strategy
and the degree evaluation method, Ye et al. in [13] proposed a new algorithm
for constructing cubes associated with linear superpolies, leading to a practical
attack against 805-round Trivium. Besides linear superpolies, some kinds of
nonlinear superpolies also useful. Later, Sun in [14] pointed out that the class of
nonlinear superpolies with independent secret variables could be easily exploited
to recover key information simply by the linearization technique, where an inde-
pendent secret variable is a variable involving in a superpoly but does not appear
in any nonlinear term of the superpoly. Consequently, Sun proposed a heuristic
method in [14] to reject cubes without independent secret variables from a preset
of candidate cubes. Using the heuristic algorithm, the author of [14] recovered
a balanced superpoly for 843-round Trivium and presented practical attacks
against 806- and 808-round Trivium. Recently, Che et al. considered that the
linear term is necessary for superpolies to contain independent secret variables.
Thus, a new framework was proposed in [15], and practical attacks against 815-
and 820-round Trivium were given. How to use other forms of balanced nonlin-
ear superpolies in cube attacks remains open, especially massive superpolies.

A New Correlation Cube Attack Based on Division Property
55
Cube Attack Variants. With the improvement of cube attacks, some enlight-
ening attack ideas are introduced and proposed. In [16], Dinur and Shamir pro-
posed dynamic cube attacks. The main idea of dynamic cube attacks is to sim-
plify the superpolies by annihilating some expressions about secret variables and
public variables. Then, attackers can determine the correctness of the guessed
values by detecting the nonrandomness of the high-order diﬀerences of the out-
put bits. Similar to the dynamic cube attack, the conditional cube attack [17]
also obtains a distinguisher by adding the conditions of the key and IV. In order
to convert this kind of attack from a weak-key distinguisher to a key recovery
attack, Liu et al. proposed the correlation cube attack in [18]. In the correlation
cube attack, the attacker recovers the secret key through the conditional correla-
tion properties between the superpoly of a cube and the annihilated conditions.
The set of annihilation conditions that can make a superpoly become zero is
called a basis.
Motivation: Although we can recover a massive superpoly, it is unclear how
a superpoly with millions of terms can be used in an attack. In [11], Hu et al.
recovered two superpolies for 844-round Trivium, and the two superpolies are
roughly balanced through experimental tests. When attacking the 844-round
Trivium, Hu et al. proposed that two linear equations could be obtained when
guessing the values of 78 variables. However, in many cases, two equations are
the same, or even both are 0, which yields that the values of two unknown
variables cannot be solved. In addition, compared with querying the encryption
oracle that calls 844-round Trivium, there is a doubt whether the complexity of
assigning 78 variables to a massive superpoly can be ignored. Therefore, before
proceeding to recover even more massive superpolies, we need to think over its
signiﬁcance in the security evaluation.
Our Contribution: In this paper, we propose a new correlation cube attack. In
the new attack, we express the superpoly p as fg ⊕h, where f only involves secret
bits. We look for the cube where h is biased. Then, we can use the correlation
between p and f to obtain the secret key information.
The critical step to correlation cube attacks is to search for good cubes. Our
cube search is inspired by the idea of basis test in [18]. We introduce the division
property into the basis test. Based on the three-subset division property without
unknown subset, we propose a modeling method for polynomials and give the
basis test based on the division property. Therefore, we could more accurately
evaluate whether the superpoly is a zero constant after adding some conditions,
which signiﬁcantly improves the power of the search.
As an illustration, we apply the attack to the well-known stream cipher Triv-
ium and obtain the best-known key recovery results for 844-round Trivium. For
844-round Trivium, we could obtain about 4-bit key information at 245 online
computation complexity. Hence, the complexity of recovering the secret key could
be reduced to about 276. The attack solves the problem that the superpolies of
high-round Trivium are too complex to use directly. As a comparison, we sum-
marize full key-recovery attacks against the round-reduced Trivium in Table 1.

56
C. Che and T. Tian
Table 1. A summary of key-recovery attacks on Trivium
Rounds #Cube Cube size Time complexity Ref
≤820
-
-
Practical
[1,2,13–15]
≤843∗
-
-
275–279.6
[4–11,14,18]
844
2
52–53
278
[11]
844
28
37–38
276
Sect. 5.2
845
2
54–55
278
[11]
846
6
51–54
279
[12]
847
2
52–53
279
[12]
848
1
52
279
[12]
∗: The highest round of Trivium with balanced superpoly is
843.
Related Work. Similar to correlation cube attacks in [18], the new correlation
cube attacks recover the key by exploiting some probabilistic equations. The
main diﬀerence between the two attacks is the perspective of viewing the super-
poly p. In the original attack, the superpoly p is decomposed into u
i=1 fi · gi,
and u is required not to be large. However, as the number of attack rounds
increases, it is diﬃcult to bound u. The new attack describes the superpoly p
as fg ⊕h and looks for h with high bias. Then, fi in the original attack can be
regarded as f in the new attack. Therefore, the new correlation cube attacks can
be considered a generalization of the original correlation cube attacks. Moreover,
due to the new perspective, we can get more and better correlations, which is
shown in the following two points.
– The original attack only veriﬁed the correlation with the elements in the
basis. In the new perspective, we will test all possible f, such as low-degree
polynomials appearing in the low round. The experimental data show that
more correlations can be obtained.
– The original attack successfully attacked 835-round Trivium. However, when
attacking 840 or more rounds, we ﬁnd that the algorithm is not always eﬃ-
cient: very few cubes pass the basis test. In comparison, using the same can-
didate cube set, the new method can ﬁnd more useful cubes.
Organization. This paper is organized as follows. Section 2 introduces nec-
essary notations and some preliminaries. The details of the new correlation
cube attacks are described in Sect. 3 and Sect. 4, and its applications to
Trivium are in Sect. 5. Finally, conclusions are drawn in Sect. 6. The source
codes of the algorithm, including some experimental data, were released at
https://github.com/LLuckyRabbit/NewCorrelationCubeAttack.
2
Preliminaries
In this section, we introduce some related concepts and deﬁnitions.

A New Correlation Cube Attack Based on Division Property
57
2.1
Boolean Functions
Let F2 be the binary ﬁeld and Fn
2 be an n-dimensional vector space over F2. An
n-variable Boolean function is a mapping from Fn
2 to F2. A Boolean function f
can be uniquely represented as a multivariable polynomial over F2,
f(x1, x2, . . . , xn) =

c=(c1,c2,...,cn)∈Fn
2
ac
n

i=1
xci
i , ac ∈F2,
which is called the algebraic normal form (ANF) of f, and n
i=1 xci
i
is called
a term of f. The algebraic degree of f is denoted by deg(f) and deﬁned as
max{wt(c)|ac ̸= 0}, where wt(c) is the Hamming Weight of c.
In particular, given a Boolean function f, we can express f in the form
of u
i=1 fi · gi, and call this form the decomposition of f on the basis G =
{g1, g2, . . . , gu}. It is clear that the basis of f is not unique.
2.2
Cube Attacks
Given a cryptographic algorithm, its output bit can be regarded as a Boolean
function in the secret variables k = (k1, k2, . . . , kn) and the public variables
v = (v1, v2 . . . , vm), expressed as f(k, v). For a randomly chosen set I =
{vi1, . . . , vid}, f(k, v) can be represented uniquely as
f(k, v) = tI · pI(k, v) ⊕qI(k, v),
where tI = vi1 · · · vid, and qI misses at least one variable in I. The basic idea of
a cube attack is that the summation of the 2d functions derived from f(k, v) by
assigning all the possible values to variables in I equals pI(k, v), that is,

(vi1,vi2,...,vid)∈Fd
2
f(k, v) = pI(k, v).
The public variables in I are called cube variables, and the polynomial pI(k, v)
is called the superpoly of the cube I. Obviously, pI(k, v) is much simpler than
f(k, v) and is expected to be obtained. Therefore, when an attacker recovers a
certain number of superpolies, he could build a system of equations on secret
variables k by inquiring about the values of all the superpolies. Then some
information about the secret variables can be achieved.
2.3
Numeric Mapping
The numeric mapping was ﬁrst introduced at CRYPTO 2017 [19], mainly used
to evaluate the degree of NFSR-based cryptosystems. Let
f(x1, x2, . . . , xn) =

c=(c1,c2,...,cn)∈Fn
2
ac
n

i=1
xci
i , ac ∈F2,

58
C. Che and T. Tian
be a Boolean function on n variables. The numeric mapping, denoted by DEG,
is deﬁned as
DEG : Bn × Zn →Z
(f, D) →max
ac ̸=0
n

i=1
cidi,
where D = (d1, d2, . . . , dn). Let di(1 ≤i ≤n) be the degree of Boolean func-
tion gi, and then DEG(f, D) is the degree evaluation of composite function
f(g1, . . . , gn). Based on the numeric mapping, the algebraic degree of output
bits and internal states of a cryptographic algorithm can be evaluated.
2.4
Correlation Cube Attacks
Correlation cube attacks were proposed by Liu et al. [18]. In the correlation cube
attack, the attacker can establish deterministic or probabilistic equations about
the secret key by using the correlation properties between the superpoly pI and
a set of low-degree decomposition basis. Correlation cube attacks mainly include
the following three steps.
a. Search for a cube I such that its superpoly pI can be decomposed into

g∈G fg · g, where g is a low-degree polynomial on key variables, and G
is called a low-degree decomposition basis.
b. For g ∈G, the correlation properties between g and pI is calculated, that is,
the probability Pr(g = pI) is calculated.
c. Query the encryption oracle and calculate the value of pI, denoted as a. Then
we have g = a is established with probability Pr(g = pI).
Compared with cube attacks, it seems that correlation cube attacks can attack
ciphers with higher rounds with cubes of smaller dimensions.
2.5
The Division Property
The division property was proposed at Eurocrypt 2015 [20], which is a new
technique to ﬁnd integral characteristics. Subsequently, the conventional bit-
based division property is introduced in [21]. At the same time, the authors of
[21] proposed the three-subset division property whose deﬁnition is as follows.
Deﬁnition 1 (Three-subset division property [21]).
Let X be a multiset
whose elements take a value of Fn
2. When the multiset X has the three-subset
division property D1n
K,L, it fulﬁlls the following conditions:

x∈X
xu =
⎧
⎨
⎩
unknown if there exists α in K s.t. u ⪰α,
1
else if there exists β in L s.t. u = β,
0
otherwise,
where u ⪰α if and only if ui ≥ki for all i and xu = n
i=1 xui
i .

A New Correlation Cube Attack Based on Division Property
59
The propagation of division property can be used to determine whether an
integral characteristic exists. However, the computation becomes unacceptable
as the number of attack rounds increases. To solve this problem, Xiang et al.
in [22] ﬁrst introduced the concept of division trails, a set of ordered vectors
describing the propagation of division property. Based on the concept of division
trails, Xiang et al. proposed to use Mixed Integer Linear Programming (MILP)
to model the conventional bit-based division property and transform the problem
into solving MILP problems. In order to model the three-subset division property
directly in cube attacks, Hao et al. proposed the three-subset division property
without unknown subset in [9].
Deﬁnition 2 (Three-subset division property without unknown subset
[9]). Let X and ˜L be two multisets whose elements take a value of Fn
2. When the
multiset X has the three-subset division property without unknown subset Γ1n
˜L , it
fulﬁlls the following conditions:

x∈X
xu =

1 if there are odd-number of u’s in ˜L,
0 otherwise,
where xu = n
i=1 xui
i .
Deﬁnition 2 is a great improvement on the three-subset division property
used in cube attacks against stream ciphers, which abandon the unknown sets in
the division property, but only describes the propagation of L set and zero set,
so as to obtain the MILP models for recovering superpolies. The propagation
rule of the three-subset division property without unknown subset is shown for
three basic operations: “copy”, “and” and “xor” in [9].
Rule 1 (copy): Let a
copy
−−−→(b1, b2) be a division trail of copy. The follow-
ing inequalities describe the propagation of the three-subset division property
without unknown subset for copy.
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
M.var ←a, b1, b2 as binary
M.con ←b1 + b2 ≥a
M.con ←a ≥b1
M.con ←a ≥b2
When the “or” operation is supported in the MILP solver, such as Gurobi, we
can simply write M.con ←a = b1 ∨b2.
Rule 2 (and): Let (a1, a2, . . . , am)
and
−−→b be a division trail of and. The follow-
ing inequalities describe the propagation of the three-subset division property
without unknown subset for and.

M.var ←a1, a2, . . . , am, b as binary
M.con ←b = ai for all i ∈{1, 2, . . . , m}

60
C. Che and T. Tian
Rule 3 (xor): Let (a1, a2, . . . , am)
xor
−−→b be a division trail of xor. The follow-
ing inequalities describe the propagation of the three-subset division property
without unknown subset for xor.

M.var ←a1, a2, . . . , am, b as binary
M.con ←b = a1 + a2 + · · · + am
In the new model, each division trail represents a term in the superpoly, so
the superpoly can be completely recovered by solving all feasible solutions in the
model.
3
A Simple Example of the New Correlation Cube
Attacks
As superpolies become increasingly massive, instead of thinking about how to
recover more massive superpolies, we should think more about how to use these
superpolies to carry out an eﬀective attack. In the new correlation cube attack, by
exploiting correlations between a superpoly and some key expressions, we could
convert a class of superpolies into a system of simple key equations avoiding the
recovery of the exact ANFs which might be very large.
Our idea is inspired by polynomials of the form p = fg. For such polynomials,
we can regard g as a black box and guess the value of f by changing the value of g
several times. Speciﬁcally, if p is constant 0 under multiple tests, it is considered
that f is likely to be 0. Similarly, if p is not constant 0, then f must be 1.
However, when attacking a well-designed cipher, it is diﬃcult to have such a
good form of superpoly. Therefore, we expand our ideas. In new attacks, we look
for cubes whose superpolies can be expressed as
p = fg ⊕h,
where f only involve secret bits and h has a high bias. We can successfully search
for superpolies of this form, which can also be used in attacks.
To demonstrate the idea of the attack, we consider a polynomial P which is
a function of the three polynomials P1, P2, and P3:
P = P1P2 ⊕P3,
where P1, P2, and P3 are polynomials over ﬁve secret variables x1, x2, x3, x4,
x5 and ﬁve public variables v1, v2, v3, v4, v5:
P1 = x1x2 ⊕x3 ⊕x4,
P2 = arbitrary dense polynomial in the 10 variables,
P3 = v2x2x3x4x5 ⊕v3x1x4 ⊕v4x2x4 ⊕v5x3x5 ⊕x2x3x4 ⊕x1x2 ⊕v3.
Since P2 is unrestricted, P is likely to behave randomly and it seems to be immune
to cube attacks. However, we observe that P3 is biased to zero under some condi-
tions. When v3 = v4 = v5 = 0, v1 and v2 take all possible combinations of 0/1,

A New Correlation Cube Attack Based on Division Property
61
and P3 has zero constant value for more than 70% secret variables. Therefore, for
70% secret variables, we have P = P1P2 under the setting of v3 = v4 = v5 = 0.
So, for this example, we can guess the value of P1 from the value of P.
However, it is hard to evaluate whether h has a high bias. If p is random
in the attack, that is, not constant after many tests, it is diﬃcult to have a
beneﬁcial correlation because it is unclear whether this randomness comes from
f · g or h. Therefore, we prefer the case where p is a constant, which can only
occur in the following two cases. In the attack, the key is restricted, so the value
of f is speciﬁc. If f is 0, the superpoly degenerates to h. If f is 1, the superpoly
is g + h. Then, for both cases, not only do we know that h has a high bias,
but we can also guess the speciﬁc value of f through the conditional probability
calculated experimentally.
4
New Correlation Cube Attacks
In this section, we propose a new correlation cube attack based on the division
property. Similar to the correlation cube attacks in [18], the attack evaluates
the correlations between the superpoly and some low-degree polynomials, and
recovers the key by solving systems of probabilistic equations. In the following,
we will give the details of the preprocessing phase.
We are inspired by the method of ﬁnding cubes with low-degree decomposi-
tion basis in the correlation cube attack in [18]. In [18], Liu et al. can ﬁnd some
cubes whose superpolies p can be decomposed into u
i=1 fi · gi, where g1, . . . , gu
are some low-degree polynomials about key variables. So, we can naturally regard
u
i=2 fi · gi as h, then
p = f1 · g1 ⊕
u

i=2
fi · gi ≜f · g ⊕h.
Since the key is ﬁxed in each attack, h is actually 
fi=1,i̸=1 gi, that is, h is
the sum of a few polynomials. We can think that g is a complex polynomial in
high-round cryptographic algorithms, such as 844-round Trivium. In particular,
when g is the product of many expressions, g will have a high bias. Since the
sum of the few biased polynomials is biased, we ﬁnd a good cube. Therefore, we
can search for desirable cubes by ﬁnding the basis in [18].
Basis Test. Since the output bits of the cryptographic algorithm are generated
iteratively, the coeﬃcients of the maximum degree terms of the cube variables
in the previous N0 rounds of state bits are likely a basis. In [18], the authors
recorded these coeﬃcients of the previous N0 rounds and annihilated them to
simplify the ANFs of output bits. Then, whether the superpoly of the cube is 0
is evaluated by numeric mapping. If the superpoly is evaluated as 0, it means
that the superpoly is reduced to 0 by annihilating these coeﬃcients. Then, these
coeﬃcients are a basis. In the following paper, we call this test a basis test based
on the numeric mapping.

62
C. Che and T. Tian
For the 844-round Trivium, we set N0 to 200 and select 2000 cubes of size
38 that contain no adjacent indexes, none of which pass the basis test based on
the numeric mapping. The imprecision of numeric mapping limits the power of
basis tests. We consider introducing the three-subset division property without
unknown subset into the basis test so that the simpliﬁed superpolies can be
accurately recovered.
Construction of the Division Property Model. Because some expressions
are annihilated in the basis test, and the division trails cannot be canceled in
the propagation, we cannot initially assign the division property of the key and
IV. Then, we consider assigning the division property in the N0 -round to avoid
the cancellation problem. Let f1, . . . , ft be the ANFs corresponding to the state
bits in the N0-round of the cryptographic algorithm. The process of assigning
the three-subset division property without unknown subset to the state bits of
the N0-round is depicted in Algorithm 1. For clarity, T(f) is used to represent
all terms in f, and var(t) is used to represent all variables in term t. We remind
the readers that, since f1, . . . , ft are obtained under the condition of a known
cube and non-cube IV with a speciﬁc assignment, it is unnecessary to consider
non-cube IV in Algorithm 1. In the Update function of Algorithm 1, we ﬁrst copy
the required variables and then model “and” and “xor” operations to represent
the division property of an ANF. Based on the function initialDP that assigns
the division property for ANFs, the basis test based on the division property is
given in Algorithm 2.
Determine Whether the Test Passes According to the Solution. In the
basis test, for a candidate cube, the MILP model can be established and solved
in lines 1–19 of Algorithm 2. Based on the three-subset division property without
unknown subset, there are two criteria to determine whether the test passes or
fails.
First Criterion: If there are solutions, that is, at least one division trail
propagates to the output bit, then the cube fails the test.
Second Criterion: If there are solutions with an odd number of trails, that
is, the superpoly has at least one term, then the cube fails the test.
By the above deﬁnitions, we can see that the ﬁrst criterion is more aggressive
but also more eﬃcient. The ﬁrst criterion only requires one feasible solution, so
we set the following parameters on Gurobi to focus on ﬁnding a feasible solution
quickly.
M.MIPFocus ←1
M.PoolSearchMode ←1
M.PoolSolutions ←1
For more on Gurobi and these parameters, readers are requested to refer to [23].
The second criterion requires the enumeration of all possible three-subset trails.

A New Correlation Cube Attack Based on Division Property
63
Algorithm 1. The division property of initial key and IV bits
1: procedure Update(MILP model M, M.var s, Boolean function f)
2:
Let count ki(i = 1, . . . , n), count vj(j = 1, . . . , m), count 1 record the number
of variables ki, vj and constant 1 in boolean function f respectively.
3:
for i = 1, . . . , n do
▷Copy the secret variables
4:
Declare var ki as count ki MILP variables of M.
5:
M.con ←ki = var ki1 ∨· · · ∨var kicount ki
6:
end for
7:
for j = 1, . . . , m do
▷Copy the public variables
8:
Declare var vj as count vj MILP variables of M.
9:
M.con ←vj = var vj1 ∨· · · ∨var vjcount vj
10:
end for
11:
Declare var 1 as count 1 MILP variables of M.
12:
Declare LinExp ←0 as a MILP linear expression of M.
13:
loc k ←0, loc v ←0, loc 1 ←0
▷Record the location of the variables used
14:
for t ∈T(f) do
▷Add the DP of the terms to the GRBLinExpr
15:
Declare temp as a MILP variable of M.
16:
M.con ←temp = var kiloc ki , loc ki ←loc ki + 1 for all ki ∈var(t)
17:
M.con ←temp = var vjloc vj , loc vj ←loc vj + 1 for all vj ∈var(t)
18:
LinExp ←LinExp + temp
19:
end for
20:
if 1 ∈T(f) then
▷Add the DP of the constant 1 to the GRBLinExpr
21:
LinExp ←LinExp + var 1loc 1, loc 1 ←loc 1 + 1
22:
end if
23:
M.con ←s = LinExp
▷Update the DP of state bits
24: end procedure
25: procedure initialDP(Cube I, Boolean function of N0 round f1, . . . , ft)
26:
Declare an empty MILP model M.
27:
Declare k as n MILP variables of M corresponding to secret variables.
28:
Declare v as m MILP variables of M corresponding to public variables.
29:
M.con ←vi = 1 for all i ∈I
30:
Declare s as t MILP variables of M corresponding to the state bits of the
N0-round.
31:
for i = 1, . . . , t do
▷Assign the DP of ANFs to the state bits
32:
Update(M, si, fi)
33:
end for
34: end procedure
If there is a high requirement for the basis test, for example, attack the algorithm
with a high number of rounds with a small dimension cube, the second criterion
should be considered. However, for many candidate cubes, it is time-consuming
to test according to the second criterion. Therefore, we use the ﬁrst criterion for
the basis test in this paper.
Computing the Probability. With the basis test based on the division prop-
erty, we could obtain some cubes with a small number of elements in the basis.
For these cubes, we are expected to ﬁnd f such that the superpoly p = f · g ⊕h,

64
C. Che and T. Tian
Algorithm 2. The basis test based on the division property
1: procedure basisTEST(Cube I, speciﬁc assignment to non-cube IV , Round N0,
Round R)
2:
Set Q to the empty set.
3:
Initialize the cryptographic algorithm.
4:
for i = 1, . . . , N0 do
5:
Compute the ANF of si and set di ←deg(si, I).
6:
Set Qi to the set of the coeﬃcients of all the terms with degree di in the
ANF of si.
7:
if di ≥1 and 1 /∈Qi then
8:
Set g = 0 for each g ∈Qi
▷Annihilate them to simplify the output
9:
Q ←Q ∪Qi
10:
end if
11:
end for
12:
Record the ANF of the state bits of the N0-round as f1, . . . , ft.
13:
Declare an empty MILP model M.
14:
initialDP(M,I,f1, . . . , ft)
▷Assign the DP to the state bits of the N0-round
15:
for i = N0 + 1, . . . , R do
16:
Update M according to round functions.
17:
end for
18:
Update M according to output functions.
19:
solve MILP model M.
20:
if pass-test then
▷Determine according to the solution
21:
return Q
22:
end if
23: end procedure
where h has a high bias. Due to the non-uniqueness of the basis, there may be
other bases with few elements for the searched cube. Thus, instead of only com-
puting correlations for superpoly p and the elements in the basis when calculating
correlations, we test all low-degree polynomials that occur at low rounds.
5
Applications
In this section, we ﬁrst brieﬂy describe the stream cipher Trivium, then apply
the new method to attack Trivium.
5.1
Description of TRIVIUM
Trivium [24] is a bit-oriented synchronous stream cipher that was one of the
eSTREAM hardware-oriented ﬁnalists. It contains three nonlinear feedback shift
registers with lengths of 93, 84, and 111, so it contains 288 internal states
recorded as s. When the Trivium algorithm is initialized, the 80-bit key variables

A New Correlation Cube Attack Based on Division Property
65
k and the 80-bit public variables v are assigned to the internal state respectively,
and the assigning method is as follows.
(s1, s2, . . . , s93) ←(k1, k2, . . . , k80, 0, . . . , 0),
(s94, s95, . . . , s177) ←(v1, v2, . . . , v80, 0, . . . , 0),
(s178, s179, . . . , s288) ←(0, . . . , 0, 1, 1, 1).
The pseudo code of the update function is given as follows.
t1 ←s66 ⊕s93 ⊕s91s92 ⊕s171
t2 ←s162 ⊕s177 ⊕s175s176 ⊕s264
t3 ←s243 ⊕s288 ⊕s286s287 ⊕s69
(s1, s2, . . . , s93) ←(t3, s1, . . . , s92)
(s94, s95, . . . , s177) ←(t1, s94, . . . , s176)
(s178, s179, . . . , s288) ←(t2, s178, . . . , s287)
After updating the internal state iteratively for 1152 rounds, Trivium starts to
output keystream bits, i.e.,
z ←s66 ⊕s93 ⊕s162 ⊕s177 ⊕s243 ⊕s288.
5.2
The Attack on 844-Round TRIVIUM
The previous highest round of Trivium with balanced superpoly is 843, and the
attacks on Trivium with 844 or more rounds are vague. Therefore, we choose
to attack 844-round Trivium.
Searching for Cubes. In [18], Liu et al. found some cubes of sizes 36 and 37,
which can be used to attack 835-round Trivium. These cubes perform better
than randomly generated ones. Therefore, we add a missing index to 13 cubes
of size 37 in [18], and we get 553 diﬀerent 38-dimensional cubes. Through the
basis test of 13 existing 37-dimensional cubes and 533 generated 38-dimensional
cubes, we obtain about 40 cubes whose superpolies, after 844 rounds, have a basis
containing at most 12 elements. Then, we modify them by randomly shifting
and changing some indexes to obtain new candidate cubes. After computations
within several days on a desktop computer, we ﬁnd more than 50 cubes whose
superpolies, after 844 rounds, have a basis containing at most 12 elements.
Because we need to guess the value of f according to whether the superpoly
is constant under diﬀerent IVs, we need free non-cube IV bits for these cubes.
We use the method in [18] to determine some free IV bits. Then, we discard
cubes with less than three free IV bits and retain 24 38-dimensional and seven
37-dimensional cubes.
Computing the Probability. In [3], an interesting observation was given that
expressions of the form ki+25ki+26 ⊕ki ⊕ki+27(0 ≤i ≤52) occur frequently in
Trivium with low rounds. Therefore, for the searched cube, we experimentally

66
C. Che and T. Tian
calculate the conditional probability of the superpoly p and elements in the set
Ω, where
Ω = {ki, 0 ≤i ≤79} ∪{ki+25ki+26 ⊕ki ⊕ki+27, 0 ≤i ≤52}
∪{ki−44ki−43 ⊕ki ⊕ki−42, 44 ≤i ≤79}.
In each test, we compute the values of the superpoly pI for 256 random keys and
at most 16 non-cube IVs for each key, and evaluate the conditional probability
Pr(f = 0|pI(key, ·) ≡0) and Pr(f = 1|pI(key, ·) ̸≡0) for a random ﬁxed key,
where g is a function in the basis of pI and pI(key, ·) denotes the superpoly
pI restricted at a ﬁxed key. We take all possible values of the free non-cube IV
bites, and otherwise we set it to 0. Once a non-zero value of pI is detected in the
experiment, we can skip the remaining non-cube IVs and test the following key.
Therefore, our experiment requires a total of 5.19 × 256 × (24 × 238 + 7 × 237) ≈
253.16 cipher operations, where 5.19 is the average number of IVs needed to be
computed for each key.
In Table 3 in Appendix, we list the useful cubes found by the experiment and
oﬀer the correlation probability. In particular, three cubes are excluded due to
their little contribution to attacks. In Table 3, we use Pr(pI ≡0) to represent
the probability that the superpoly pI is a zero constant restricted at a ﬁxed key.
In column pI ≡0 (resp., pI ̸≡0), we enumerate the polynomials that are 0
with high probability when the superpoly pI is a zero constant (resp., not a zero
constant), and the threshold of probability is 2/3 (resp., 0.65).
Recovering the Key in the Online Phase. In the online phase, we select
at most 16 free non-cube IVs to test whether the superpoly under a ﬁxed key
is zero constant. We collect the equations with high probability in set G. Then,
the expected time complexity of this phase is less than
5.19 × (23 × 238 + 5 × 237) + p−r280−r ≈245.05 + 280−2
5 r,
where r is the number of equations we choose from G to solve.
To test the eﬀect of the attack, we generate 128 new random keys and perform
the attack. Due to the limitation of the correlation property obtained by the
experimental test, we appropriately reduce the number of selection equations
to improve the attack success rate. Considering that p−r <
|G|
r

needs to be
satisﬁed, we give the strategy choice of r,
r =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
r′ −10,
if r′ ⩾20;
r′ −5,
if r′ ⩾10;
r′ −2,
if r′ ⩾4;
1,
if 3 ⩾r′ ⩾1;
where r′ is the maximum r′ such that p−r′ <
|G|
r′

. In our experiments for 128
new random keys, the average value of r is 10.14. Then, about 2
5r = 4.06 key
bits could be recovered on average, and the complexity of recovering the whole
key could be reduced to about 276. Speciﬁcally, we can recover ten equations on

A New Correlation Cube Attack Based on Division Property
67
key bits by 74 trials on average. The attack is valid for more than 70% out of 128
random keys in our experiments. As shown in Table 2, the success probability
of the attack can be increased by using smaller systems of equations or larger
probability thresholds, at the cost of more attack time.
Table 2. Success probability of the attack for 844-round Trivium
#key bits
4.06
3.88
3.61
3.18
2.83
Success rate 71.1% 77.3% 89.1% 93.0% 97.7%
Next, we give an example of the attack procedure. In the example, the time
complexity is better than the average case.
Example 1. Given that the 80-bit secret key is EB AA 8F B4 6C 8D 68 F3 28 13
in hexadecimal, where the most signiﬁcant bit is k0 and the least signiﬁcant bit
is k79. For each of the 28 cubes in Table 3, we generate at most 16 diﬀerent non-
cube IVs according to their free IV bits, then calculate whether the superpoly is
zero constant. We ﬁnd that there are 6 cubes having zero superpolies,
3, 9, 13, 17, 21, 27.
Therefore, we obtain 22 equations,
G = {f3, f4 ⊕1, f14 ⊕1, f19 ⊕1, f58, f63 ⊕1, f76, g0 ⊕1, g3, g5,
g6, g7, g15, g20, g21, g22, g23 ⊕1, g24, g33, g38, g45 ⊕1, g46}.
The equations become linear equations that are linearly independent of each
other after guessing the values of the following bits,
k25, k28, k31, k32, k40, k46, k47, k49, k59, k64, k71.
According to the strategy, r is chosen to be 13, that is, we randomly choose 13
equations to solve and enumerate the remaining keys. We repeat this step until
the correct key is found. In theory, the expected number of trials for ﬁnding the
correct solution is less than p−r ≈270. As a matter of fact, 17 equations are
true for the secret key, but f19 ⊕1, f58, g0 ⊕1, g21 and g23 ⊕1 are not true. On
average, we can obtain the correct key in
22
13

/
17
13

= 209 attempts. Therefore
we can recover the key with time complexity of 245.05 + 209 × 267 ≈274.71.
6
Conclusion
In this paper, we propose a new correlation cube attack. The new view on build-
ing correlations between a superpoly and a low degree polynomial on key vari-
ables signiﬁcantly enhance the power of correlation cube attacks. As an illustra-
tion, we apply it to the stream cipher Trivium and give the best key recovery
attacks for 844-round Trivium. As the number of initialization rounds of Triv-
ium increases, the superpolies in cube attacks becomes more and more massive. A
clear advantage of correlation cube attacks is the avoidance of solving complex
superpolies. Hence, proposing a new cube attack variant based on correlation
properties is worth working on in the future.

68
C. Che and T. Tian
Appendix: The Cubes, Equations and Probabilities
Table 3. The useful cubes in the attack on 844-round Trivium
No. cube indexes
#cube Free IV bits pI ≡0
pI ̸≡0
Pr(pI ≡0)
1
0, 2, 4, 6, 8, 9, 11, 13, 15, 17, 19,
21, 23, 26, 28, 30, 32, 34, 36, 38,
41, 43, 45, 47, 49, 51, 53, 56, 58,
60, 62, 64, 66, 68, 71, 73, 75, 79
38
1,10,76,77
f10 ⊕1, f21, f22 ⊕1, f58, f60,
g2, g4, g6, g19, g21, g26, g32,
g34, g47, h58 ⊕1, h79 ⊕1
-
0.145
2
0, 1, 2, 4, 6, 8, 11, 13, 15, 17, 19,
21, 23, 26, 28, 30, 32, 34, 36, 38,
41, 43, 45, 47, 49, 51, 53, 56, 58,
60, 62, 64, 66, 68, 71, 73, 75, 79
38
9,10,76,77
f10 ⊕1, f21, f22 ⊕1, f58, f60,
g4, g6, g12 ⊕1, g19, g21, g23,
g32, g34, h58 ⊕1, h79 ⊕1
-
0.145
3
1, 3, 5, 7, 8, 10, 12, 14, 16, 18, 20,
22, 25, 27, 29, 31, 33, 35, 37, 40,
42, 44, 46, 48, 50, 52, 55, 57, 59,
61, 63, 65, 67, 70, 72, 74, 76, 78
38
0,2,9,11
g5, g20, g22
-
0.355
4
0, 2, 4, 6, 9, 11, 13, 15, 17, 19, 21,
24, 26, 28, 30, 32, 34, 36, 39, 41,
43, 45, 47, 49, 51, 54, 56, 58, 60,
62, 64, 66, 69, 71, 73, 75, 77, 79
38
1,7,8,10
g4, g6, g15, g21
g23 ⊕1 0.387
5
0, 2, 4, 6, 8, 10, 12, 15, 17, 19, 21,
23, 25, 27, 30, 32, 34, 36, 38, 40,
42, 45, 47, 49, 51, 53, 55, 57, 60,
62, 64, 66, 68, 70, 72, 75, 77, 79
38
3,5,7
f9, f10 ⊕1, f11 ⊕1, f12, f31,
f53, f54 ⊕1, f57, f59, f65,
f76, f77 ⊕1, g15, g20, g21, g23,
g38, g40, g45 ⊕1, g48 ⊕1, h66
-
0.152
6
0, 1, 2, 4, 7, 9, 11, 13, 15, 17, 19,
22, 24, 26, 28, 30, 32, 34, 37, 39,
41, 43, 45, 47, 49, 52, 54, 56, 58,
60, 62, 64, 67, 69, 71, 73, 75, 79
38
6,8,10,77
f9, f58, g2, g4, g6, g13,
g15, g17, g19, g21, g26,
g34, g47, h58 ⊕1
-
0.176
7
0, 2, 4, 6, 9, 11, 13, 15, 17, 19, 22,
24, 26, 28, 30, 32, 34, 37, 39, 41,
43, 45, 47, 49, 52, 54, 56, 58, 60,
62, 64, 67, 69, 71, 73, 75, 77, 79
38
7,8,10,20
f58, g4, g6, g15
-
0.367
8
0, 1, 2, 4, 6, 9, 11, 13, 15, 17, 19,
22, 24, 26, 28, 30, 32, 34, 37, 39,
41, 43, 45, 47, 49, 52, 54, 56, 58,
60, 62, 64, 67, 69, 71, 73, 75, 79
38
8,10,20,77
f21, f58, g4, g6, g15, g17,
g26, g34, h49, h58 ⊕1
-
0.184
9
1, 3, 5, 7, 9, 10, 12, 14, 16, 18, 20,
22, 25, 27, 29, 31, 33, 35, 37, 40,
42, 44, 46, 48, 50, 52, 55, 57, 59,
61, 63, 65, 67, 70, 72, 74, 76, 78
38
2,8,11
-
f9
0.512
10
0, 2, 4, 7, 9, 10, 11, 13, 15, 17, 19,
22, 24, 26, 28, 30, 32, 34, 37, 39,
41, 43, 45, 47, 49, 52, 54, 56, 58,
60, 62, 64, 67, 69, 71, 73, 75, 79
38
1,5,6,8
f9, f43, f58, g2, g4, g6, g15,
g19, g21, g26, g34, h58 ⊕1
-
0.191
11
0, 1, 3, 5, 7, 9, 11, 13, 16, 18, 20,
22, 24, 26, 28, 31, 33, 35, 37, 39,
41, 43, 46, 48, 50, 52, 54, 56, 58,
61, 63, 65, 67, 69, 71, 73, 76, 78
38
2,6,79
f29 ⊕1, f42, f56, f58, f60,
f61, f67, g7, g12 ⊕1, g21,
g22, g45, h53, h68
-
0.133
12
0, 2, 4, 6, 7, 9, 11, 13, 15, 17, 19,
21, 24, 26, 28, 30, 32, 34, 36, 39,
41, 43, 45, 47, 49, 51, 54, 56, 58,
60, 62, 64, 66, 69, 71, 73, 75, 79
38
1,5,8,10
g2, g4, g6, g15, g21, g26,
g47, g51, h58 ⊕1
-
0.227
13
1, 3, 5, 6, 7, 10, 12, 14, 16, 18, 20,
22, 25, 27, 29, 31, 33, 35, 37, 40,
42, 44, 46, 48, 50, 52, 55, 57, 59,
61, 63, 65, 67, 70, 72, 74, 76, 78
38
0,8,9,11
f4 ⊕1, f14 ⊕1, f19 ⊕1, f76,
g5, g7, g20, g21, g33, g46
-
0.207
(continued)

A New Correlation Cube Attack Based on Division Property
69
Table 3. (continued)
No. cube indexes
#cube Free IV bits pI ≡0
pI ̸≡0
Pr(pI ≡0)
14
0, 1, 2, 4, 6, 9, 11, 13, 15, 17, 19,
21, 24, 26, 28, 30, 32, 34, 36, 39,
41, 43, 45, 47, 49, 51, 54, 56, 58,
60, 62, 64, 66, 69, 71, 73, 75, 79
38
8,10,76,77
g4, g6, g15, g21,
g26, g51, h58 ⊕1
-
0.301
15
0, 2, 4, 6, 8, 10, 11, 13, 15, 17, 19,
21, 23, 26, 28, 30, 32, 34, 36, 38,
41, 43, 45, 47, 49, 51, 53, 56, 58,
60, 62, 64, 66, 68, 71, 73, 75, 79
38
1,9,76,77
f21, g6, g19, g21,
g32, g47, h58 ⊕1
-
0.270
16
0, 2, 4, 7, 8, 9, 11, 13, 15, 17, 19,
22, 24, 26, 28, 30, 32, 34, 37, 39,
41, 43, 45, 47, 49, 52, 54, 56, 58,
60, 62, 64, 67, 69, 71, 73, 75, 79
38
6,10,77
g4, g6, g15
g45 ⊕1
0.422
17
0, 2, 4, 6, 8, 9, 11, 13, 15, 17, 19,
21, 24, 26, 28, 30, 32, 34, 36, 39,
41, 43, 45, 47, 49, 51, 54, 56, 58,
60, 62, 64, 66, 69, 71, 73, 75, 79
38
1,7,10,76
g6, g21
-
0.414
18
0, 2, 4, 6, 9, 10, 11, 13, 15, 17, 19,
22, 24, 26, 28, 30, 32, 34, 37, 39,
41, 43, 45, 47, 49, 52, 54, 56, 58,
60, 62, 64, 67, 69, 71, 73, 75, 79
38
1,7,8,20
f21, f58, f61, g4, g6,
g13, g15, g34, h49
-
0.227
19
0, 2, 4, 7, 9, 11, 13, 15, 17, 19, 22,
24, 26, 28, 30, 32, 34, 37, 39, 41,
43, 45, 47, 49, 52, 54, 56, 58, 60,
62, 64, 67, 69, 71, 73, 75, 77, 79
38
1,5,6,8
f58, f61, g2, g4, g6,
g13, g15, g17, g20, g21
-
0.246
20
0, 2, 4, 8, 9, 10, 11, 13, 15, 17, 19,
22, 24, 26, 28, 30, 32, 34, 37, 39,
41, 43, 45, 47, 49, 52, 54, 56, 58,
60, 62, 64, 67, 69, 71, 73, 75, 79
38
5,6,7,77
f58, g6, g15, g21,
g26, h79 ⊕1
g45 ⊕1
0.250
21
0, 2, 4, 6, 7, 9, 11, 13, 15, 17, 19,
22, 24, 26, 28, 30, 32, 34, 37, 39,
41, 43, 45, 47, 49, 52, 54, 56, 58,
60, 62, 64, 67, 69, 71, 73, 75, 79
38
1,9,10,76
f58, g6, g15, g21
g4 ⊕1g45 ⊕1 0.473
22
0, 2, 4, 6, 9, 11, 13, 15, 17, 19, 21,
24, 26, 28, 30, 32, 34, 36, 39, 41,
43, 45, 47, 49, 51, 54, 56, 58, 60,
62, 64, 66, 69, 71, 73, 75, 76, 79
38
1,9,10,76
g6, g15, g21, g34
g45 ⊕1
0.367
23
0, 2, 4, 6, 8, 11, 13, 15, 17, 19, 21,
23, 26, 28, 30, 32, 34, 36, 38, 41,
43, 45, 47, 49, 51, 53, 56, 58, 60,
62, 64, 66, 68, 71, 73, 75, 77, 79
38
1,9,10,76
g4, g6, g19, g21,
g32, g34, h58 ⊕1
-
0.250
24
0, 2, 4, 6, 8, 11, 13, 15, 17, 19, 21,
23, 26, 28, 30, 32, 34, 36, 38, 41,
43, 45, 47, 49, 51, 53, 56, 58, 60,
62, 64, 66, 68, 71, 73, 75, 79
37
1,7,8,10
f10 ⊕1, f16 ⊕1, f21, f58,
f60, g2, g4, g6, g19, g21,
g26, g34, h58 ⊕1, h79 ⊕1
-
0.137
25
0, 2, 4, 6, 9, 11, 13, 15, 17, 19, 21,
24, 26, 28, 30, 32, 34, 36, 39, 41,
43, 45, 47, 49, 51, 54, 56, 58, 60,
62, 64, 66, 69, 71, 73, 75, 79
37
1,7,8,10
f21, g4, g6, g15, g21, g26,
g51, h58 ⊕1
-
0.262
26
0, 2, 4, 6, 9, 11, 13, 15, 17, 19, 22,
24, 26, 28, 30, 32, 34, 37, 39, 41,
43, 45, 47, 49, 52, 54, 56, 58, 60,
62, 64, 67, 69, 71, 73, 75, 79
37
1,7,8,10
f55, f58, g4, g6, g15,
g21, g26, h49
-
0.191
27
1, 3, 5, 7, 10, 12, 14, 16, 18, 20,
22, 25, 27, 29, 31, 33, 35, 37, 40,
42, 44, 46, 48, 50, 52, 55, 57, 59,
61, 63, 65, 67, 70, 72, 74, 76, 78
37
0,2,6,8
f3, f14 ⊕1, f19 ⊕1, f63 ⊕1,
f76, g0 ⊕1, g3, g5, g7, g20,
g21, g22, g24, g33, g38, g46
-
0.176
28
0, 2, 4, 7, 9, 11, 13, 15, 17, 19, 22,
24, 26, 28, 30, 32, 34, 37, 39, 41,
43, 45, 47, 49, 52, 54, 56, 58, 60,
62, 64, 67, 69, 71, 73, 75, 79
37
5,6,8,10
f9, f58, g2, g4, g6,
g13, g15, g17, g19,
g21, g26, g34, h47 ⊕1
-
0.215
fi = ki, 0 ≤i ≤79
gi = ki+25 · ki+26 ⊕ki ⊕ki+27, 0 ≤i ≤52
hi = ki−44 · ki−43 ⊕ki ⊕ki−42, 44 ≤i ≤79.

70
C. Che and T. Tian
References
1. Dinur, I., Shamir, A.: Cube attacks on tweakable black box polynomials. In: Joux,
A. (ed.) EUROCRYPT 2009. LNCS, vol. 5479, pp. 278–299. Springer, Heidelberg
(2009). https://doi.org/10.1007/978-3-642-01001-9_16
2. Fouque, P.-A., Vannet, T.: Improving key recovery to 784 and 799 rounds of trivium
using optimized cube attacks. In: Moriai, S. (ed.) FSE 2013. LNCS, vol. 8424, pp.
502–517. Springer, Heidelberg (2014). https://doi.org/10.1007/978-3-662-43933-
3_26
3. Ye, C., Tian, T.: A new framework for ﬁnding nonlinear superpolies in cube attacks
against trivium-like ciphers. In: Susilo, W., Yang, G. (eds.) ACISP 2018. LNCS,
vol. 10946, pp. 172–187. Springer, Cham (2018). https://doi.org/10.1007/978-3-
319-93638-3_11
4. Todo, Y., Isobe, T., Hao, Y., Meier, W.: Cube attacks on non-blackbox polynomials
based on division property. In: Katz, J., Shacham, H. (eds.) CRYPTO 2017. LNCS,
vol. 10403, pp. 250–279. Springer, Cham (2017). https://doi.org/10.1007/978-3-
319-63697-9_9
5. Wang, Q., Hao, Y., Todo, Y., Li, C., Isobe, T., Meier, W.: Improved division prop-
erty based cube attacks exploiting algebraic properties of superpoly. In: Shacham,
H., Boldyreva, A. (eds.) CRYPTO 2018. LNCS, vol. 10991, pp. 275–305. Springer,
Cham (2018). https://doi.org/10.1007/978-3-319-96884-1_10
6. Wang, S., Hu, B., Guan, J., Zhang, K., Shi, T.: MILP-aided method of search-
ing division property using three subsets and applications. In: Galbraith, S.D.,
Moriai, S. (eds.) ASIACRYPT 2019. LNCS, vol. 11923, pp. 398–427. Springer,
Cham (2019). https://doi.org/10.1007/978-3-030-34618-8_14
7. Ye, C., Tian, T.: Revisit division property based cube attacks: key-recovery or
distinguishing attacks? IACR Trans. Symmetric Cryptol. 2019(3), 81–102 (2019)
8. Ye, C.-D., Tian, T.: Algebraic method to recover superpolies in cube attacks. IET
Inf. Secur. 14(4), 430–441 (2020)
9. Hao, Y., Leander, G., Meier, W., Todo, Y., Wang, Q.: Modeling for three-subset
division property without unknown subset. In: Canteaut, A., Ishai, Y. (eds.)
EUROCRYPT 2020. LNCS, vol. 12105, pp. 466–495. Springer, Cham (2020).
https://doi.org/10.1007/978-3-030-45721-1_17
10. Hu, K., Sun, S., Wang, M., Wang, Q.: An algebraic formulation of the division
property: revisiting degree evaluations, cube attacks, and key-independent sums.
In: Moriai, S., Wang, H. (eds.) ASIACRYPT 2020. LNCS, vol. 12491, pp. 446–476.
Springer, Cham (2020). https://doi.org/10.1007/978-3-030-64837-4_15
11. Hu, K., Sun, S., Todo, Y., Wang, M., Wang, Q.: Massive superpoly recovery
with nested monomial predictions. In: Tibouchi, M., Wang, H. (eds.) ASIACRYPT
2021. LNCS, vol. 13090, pp. 392–421. Springer, Cham (2021). https://doi.org/10.
1007/978-3-030-92062-3_14
12. He, J., Hu, K., Preneel, B., Wang, M.: Stretching cube attacks: improved methods
to recover massive superpolies. In: Agrawal, S., Lin, D. (eds.) ASIACRYPT 2022.
LNCS, vol. 13794, pp. 537–566. Springer, Cham (2022). https://doi.org/10.1007/
978-3-031-22972-5_19
13. Ye, C.-D., Tian, T.: A practical key-recovery attack on 805-round trivium. In:
Tibouchi, M., Wang, H. (eds.) ASIACRYPT 2021. LNCS, vol. 13090, pp. 187–213.
Springer, Cham (2021). https://doi.org/10.1007/978-3-030-92062-3_7
14. Sun, Y.: Automatic search of cubes for attacking stream ciphers. IACR Trans.
Symmetric Cryptol. 2021(4), 100–123 (2021)

A New Correlation Cube Attack Based on Division Property
71
15. Che, C., Tian, T.: An experimentally veriﬁed attack on 820-round trivium. In:
Deng, Y., Yung, M. (eds.) Inscrypt 2022. LNCS, vol. 13837, pp. 357–369. Springer,
Cham (2023). https://doi.org/10.1007/978-3-031-26553-2_19
16. Dinur, I., Shamir, A.: Breaking grain-128 with dynamic cube attacks. In: Joux,
A. (ed.) FSE 2011. LNCS, vol. 6733, pp. 167–187. Springer, Heidelberg (2011).
https://doi.org/10.1007/978-3-642-21702-9_10
17. Huang, S., Wang, X., Xu, G., Wang, M., Zhao, J.: Conditional cube attack
on reduced-round Keccak sponge function. In: Coron, J.-S., Nielsen, J.B. (eds.)
EUROCRYPT 2017. LNCS, vol. 10211, pp. 259–288. Springer, Cham (2017).
https://doi.org/10.1007/978-3-319-56614-6_9
18. Liu, M., Yang, J., Wang, W., Lin, D.: Correlation cube attacks: from weak-key
distinguisher to key recovery. In: Nielsen, J.B., Rijmen, V. (eds.) EUROCRYPT
2018. LNCS, vol. 10821, pp. 715–744. Springer, Cham (2018). https://doi.org/10.
1007/978-3-319-78375-8_23
19. Liu, M.: Degree evaluation of NFSR-based cryptosystems. In: Katz, J., Shacham,
H. (eds.) CRYPTO 2017. LNCS, vol. 10403, pp. 227–249. Springer, Cham (2017).
https://doi.org/10.1007/978-3-319-63697-9_8
20. Todo, Y.: Structural evaluation by generalized integral property. In: Oswald, E.,
Fischlin, M. (eds.) EUROCRYPT 2015. LNCS, vol. 9056, pp. 287–314. Springer,
Heidelberg (2015). https://doi.org/10.1007/978-3-662-46800-5_12
21. Todo, Y., Morii, M.: Bit-based division property and application to Simon family.
In: Peyrin, T. (ed.) FSE 2016. LNCS, vol. 9783, pp. 357–377. Springer, Heidelberg
(2016). https://doi.org/10.1007/978-3-662-52993-5_18
22. Xiang, Z., Zhang, W., Bao, Z., Lin, D.: Applying MILP method to searching inte-
gral distinguishers based on division property for 6 lightweight block ciphers. In:
Cheon, J.H., Takagi, T. (eds.) ASIACRYPT 2016. LNCS, vol. 10031, pp. 648–678.
Springer, Heidelberg (2016). https://doi.org/10.1007/978-3-662-53887-6_24
23. Gurobi Optimization. http://www.gurobi.com
24. De Cannière, C., Preneel, B.: Trivium. In: Robshaw, M., Billet, O. (eds.) New
Stream Cipher Designs. LNCS, vol. 4986, pp. 244–266. Springer, Heidelberg (2008).
https://doi.org/10.1007/978-3-540-68351-3_18

The Triangle Diﬀerential Cryptanalysis
Xiaofeng Xie and Tian Tian(B)
Information Engineering University,
Zhengzhou 450001, China
tiantian d@126.com
Abstract. In this paper, a new variant of diﬀerential cryptanalysis is
developed by applying the idea of the boomerang attack on the truncated
diﬀerential. We call this variant a triangle diﬀerential cryptanalysis since
it utilizes the diﬀerence of every pair in an input and output triple.
Similar to the boomerang attack, the triangle diﬀerential cryptanalysis
combines two independent truncated diﬀerential distinguishers of two
parts of a cryptosystem into a distinguisher of the whole cryptosystem.
It provides a new perspective on the diﬀerential propagation, and so it
is possible to break the limit of the traditional truncated diﬀerential.
An MILP modeling technique is also provided for the triangle diﬀeren-
tial distinguisher search against general SPN ciphers. To demonstrate
the power of this new type of diﬀerential distinguishers, we apply it to
SKINNY-64 and CRAFT. For SKINNY-64, an 11-round triangle dif-
ferential distinguisher is obtained, while the previous longest truncated
diﬀerential distinguisher is 10-round. For CRAFT, a 13-round triangle
diﬀerential distinguisher is obtained, while the previous longest trun-
cated diﬀerential distinguisher is 12-round. Besides, compared with the
best distinguishers other than the truncated diﬀerential distinguishers,
there are still some improvements on the probabilities for both SKINNY-
64 and CRAFT.
Keywords: Diﬀerential cryptanalysis · Boomerang attack · Truncated
diﬀerential · SKINNY-64 · CRAFT
1
Introduction
Diﬀerential cryptanalysis is a powerful method which is widely used in the analy-
sis against block ciphers since its proposal in 1994 [15]. The main idea of diﬀeren-
tial attacks is utilizing the propagation of diﬀerences through encryption compo-
nents to construct distinguishers with a high probability. To target diﬀerent types
of block ciphers, variants of diﬀerential attacks have been proposed. The diﬀer-
ential cryptanalysis that considers word-wise diﬀerences with high probabilities
is called the truncated diﬀerential. In some cases, the truncated diﬀerential can
oﬀer more eﬃcient distinguishers than the bit-based diﬀerential. For example,
the diﬀerential attacks against KLEIN [11,16]. Diﬀerential trails with zero prob-
ability, both for bit-wise and word-wise trails, could also be used in diﬀerential
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 72–88, 2023.
https://doi.org/10.1007/978-3-031-35486-1_4

The Triangle Diﬀerential Cryptanalysis
73
cryptanalysis, called the impossible diﬀerential. The impossible diﬀerential has
a remarkable eﬀect on AES-like ciphers since many word-wise diﬀerentials are
impossible for AES-like ciphers with low round numbers. In recent years, a new
kind of diﬀerential cryptanalysis called the mixture diﬀerential was presented in
[12], leading to a 4-round mixture diﬀerential distinguisher and the best attack
on 5-round AES [4]. Based on the 4-round mixture diﬀerential distinguisher of
AES, the ﬁrst 6-round AES distinguisher was given in [5]. To construct a long
distinguisher based on some shorter distinguishers, the boomerang attacks are
proposed. The boomerang attack is always used to combine two arbitrary dif-
ferential distinguishers [21]. For example, if there exist n-round and m-round
distinguishers with probability p and q, respectively, we can naturally construct
an (n + m)-round boomerang distinguisher whose probability is p2q2. Inspired
by the mixture diﬀerential, a variant of boomerang attack called the retracing
boomerang attack was proposed in [9]. The authors of [9] also illustrated that
the mixture diﬀerential was a special boomerang attack. According to the results
of mixture diﬀerential against AES, it can be seen that the boomerang attack is
one of the most potential cryptanalysis against AES-like ciphers.
Recently, the distinguisher search based on automatic methods has become
a prevalent issue. The Mixed-Integer Linear Programming (MILP) method is
one of the most eﬀective tools and is widely used to search distinguishers for
variants of cryptanalysis such as diﬀerential [19], integral [22], linear [10] and
meet-in-the-middle attacks [3]. Among the diﬀerential cryptanalysis we discussed
above, the MILP-based distinguisher search for the truncated diﬀerential has
already been solved in [17], leading to a series of distinguishers for SKINNY-64,
Midori64, and CRAFT. Note that the probabilities of all the truncated diﬀer-
ential distinguishers from [17] are higher than the upper bounds of the bit-wise
diﬀerential characteristics given by [2,6,7], for the same number of rounds. This
shows the importance of the truncated diﬀerential. For SKINNY-64, Midori64,
and CRAFT, the traditional truncated diﬀerential distinguishers given by [17]
is challenging to improve.
In this paper, we propose a new variant of diﬀerential cryptanalysis that
applies the idea of boomerang attacks to the truncated diﬀerential. We call this
diﬀerential cryptanalysis as “Triangle Diﬀerential”. The triangle diﬀerential uti-
lize the relationship between the relative diﬀerences of 3-tuple in the middle of
a cipher. Once we know two of the relative diﬀerences of 3-tuple, we can know
the last one. Diﬀerent from the traditional truncated diﬀerential that deduces the
diﬀerential pattern of middle states in only encryption or decryption direction,
the triangle diﬀerential deduces two of the relative diﬀerences in encryption and
decryption directions respectively. As a result, it is possible to construct longer dis-
tinguishers than the truncated diﬀerential. To illustrate the eﬀect of the triangle
diﬀerential, we applied it to SKINNY-64 and CRAFT using the MILP modeling
technique. By solving the MILP models, we get 11- and 13-round triangle diﬀer-
ential distinguishers for SKINNY-64 and CRAFT respectively. To the best of our
knowledge, the previous best truncated diﬀerential distinguishers for SKINNY-64
and CRAFT are 10- and 12-round respectively. Thus, one more round is extended
compared with the traditional truncated diﬀerential distinguishers. Considering

74
X. Xie and T. Tian
Table 1. Comparison of characteristics for SKINNY-64 in the single-tweakey model.
CP: chosen plaintexts/ACC: chosen plaintexts and adaptively-chosen ciphertexts
Distinguisher
Round Probability Data scenario Ref
Zero-correlation
10
2−60
CP
[18]
Truncated diﬀerential
10
2−40
CP
[17]
Impossible diﬀerential 11
2−60
CP
[6]
Triangle diﬀerential
11
2−56
ACC
Sect. 3
Table 2. Comparison of characteristics for CRAFT in the single-tweakey model.
CP: chosen plaintexts/ACC: chosen plaintexts and adaptively-chosen ciphertexts
Distinguisher
Round Probability Data scenario Ref
Linear hull
11
2−58.8
CP
[14]
Truncated diﬀerential 12
2−36
CP
[17]
bit-wise diﬀerential
13
2−59.4
CP
[14]
Triangle diﬀerential
13
2−56
ACC
Sect. 3
all previously best distinguishers on the two ciphers, although there is no break-
through on the number of rounds, there are improvements on the probabilities. A
summary of the known and the new distinguishers are presented in Tables 1 and 2,
where the probability of impossible diﬀerential in Table 1 means the eﬀect of the
key ﬁltering using the distinguishing, i.e., the probability that a diﬀerence falls
into the impossible diﬀerential in the random case.
This paper is organized as follows. In Sect. 2, a brief introduction to the
boomerang attacks and MILP-based truncated diﬀerential is given. Some details
of SKINNY-64 and CRAFT are also presented as preliminaries. We propose the
triangle diﬀerential in Sect. 3. In Sect. 4, we apply our new method to SKINNY-
64 and CRAFT. A discussion of the potential improvement of our technique is
given in Sect. 5. Finally, we summarize the paper in Sect. 6.
2
Background and Previous Work
The proposal of the triangle diﬀerential was inspired by the boomerang attack.
It applies the idea of boomerang attack to the truncated diﬀerential. Thus, an
introduction to boomerang attack and truncated diﬀerential is given in this
section. Moreover, a brief introduction to SKINNY-64 and CRAFT will also be
given in this section.

The Triangle Diﬀerential Cryptanalysis
75
2.1
Notation
For a block cipher F: Fn×m
2
→Fn×m
2
, let us denote a diﬀerential characteristic
by δ
F→△, and the associated diﬀerential probability is deﬁned as
Pr[δ
F→△] = |{x ∈Fn×m
2
|F(x) ⊕F(x ⊕δ) =△}|
2n×m
,
where δ, △∈Fn×m
2
. The diﬀerential characteristic δ
F→△satisfying Pr[δ
F→△] = 0
is called an impossible diﬀerential [8]. For two sets A, B ⊂Fn×m
2
, the notation
A
F→B denotes the set
{δ →△|there exists x ∈Fn×m
2
such that F(x ⊕δ) ⊕F(x) =△, δ ∈A, △∈B},
which is called a truncated diﬀerential trail of F. Let α, β ∈Fn
2. Denote α
F→β
as a kind of special truncated diﬀerential trails whose input and output sets are
subspaces which is active in the bytes indexed by {i|αi = 1} and {j|βj = 1}
respectively. Furthermore, denote the probability of α
F→β by Pr[α
F→β].
Deﬁnition 1 (Diﬀerential pattern). Let α, β ∈Fn×m
2
be two states in the
middle of a block cipher, where α = (α0, α1, . . . , αn−1), β = (β0, β1, . . . , βn−1).
Deﬁne the diﬀerential pattern of (α, β) as υ(α, β) ∈Fn
2 such that
υ(α, β)i =

1, αi ⊕βi ̸= 0,
0, αi ⊕βi = 0.
Remark 1. For p0, p1 ∈Fn×m
2
and F: Fn×m
2
→Fn×m
2
, if υ(p0, p1) = a, then
the probability that υ(c0, c1) = b is given by Pr[a
F→b], where c0 = F(p0),
c1 = F(p1).
2.2
Boomerang Attack
In 1999, Wagner proposed the boomerang attack, which shows how to combine
two independent diﬀerential distinguishers into a longer distinguisher [21]. The
framework of the boomerang attack is depicted in Fig. 1, which can be described
as the following theorem.
Theorem 1. Let E:Fn×m
2
→Fn×m
2
be the encryption function of a block cipher,
which can be decomposed into E = E1 ◦E0. Suppose there are diﬀerential dis-
tinguishers given by
Pr[δ0
E0
−→δ1] = a and Pr[δ3
E1
−→δ2] = b
where δ0, δ1, δ2, δ3 ∈Fn×m
2
. Then for p0, p1 ∈Fn×m
2
satisfying p0 ⊕p1 = δ0,
c0 = E(p0), and c1 = E(p1),
Pr[E−1(c2) ⊕E−1(c3) = δ0] = a2b2,
where c2 = c1 ⊕δ2 and c3 = c0 ⊕δ2.

76
X. Xie and T. Tian
Fig. 1. The framework of the boomerang attack
Proof. For each i = 0, 1, 2, 3, let xi = E0(pi). Since p0 ⊕p1 = δ0, Pr[x0 ⊕x1 =
δ1] = Pr[δ0
E0
−→δ1] = a. Since c0 ⊕c3 = c1 ⊕c2 = δ2, it follows that
Pr[x0 ⊕x3 = δ3] = Pr[x1 ⊕x2 = δ3] = Pr[δ3
E1
−→δ2] = b.
If x0 ⊕x3 = x1 ⊕x2 = δ3 and x0 ⊕x1 = δ1, then we have x2 ⊕x3 = x0 ⊕x1 = δ1.
Assume all these events are independent. Then
Pr[x2 ⊕x3 = δ1] = Pr[x0 ⊕x3 = δ3] · Pr[x1 ⊕x2 = δ3] · Pr[x0 ⊕x1 = δ1] = ab2.
It follows that
Pr[p2 ⊕p3 = δ0] = Pr[x2 ⊕x3 = δ1] × Pr[δ0
E0
−→δ1] = a2b2.
This completes the proof.
It can be seen that in Theorem 1 the diﬀerence of the states (x2, x3) in the
middle is deduced by the following equation
x2 ⊕x3 = (x1 ⊕x0) ⊕(x1 ⊕x2) ⊕(x0 ⊕x3),
where the diﬀerences x1 ⊕x0, x1 ⊕x2, x0 ⊕x3 are determined by two diﬀerential
characteristics of E0 and E1 respectively, which are assumed to be independent.
We note that this provides an idea to connect independent diﬀerential character-
istics into a longer one. The core idea of the triangle diﬀerential proposed in the
following paper is also connecting independent diﬀerential characteristics but in
a diﬀerent way.
2.3
Truncated Diﬀerential Search by MILP
The truncated diﬀerential attack was introduced by Knudsen in 1994 [15]. Since
it only considers word-wise diﬀerences, the propagation of diﬀerences about Sbox

The Triangle Diﬀerential Cryptanalysis
77
can be naturally ignored. Thus, it is much more suitable to analyze AES-like
ciphers with large Sboxes. Furthermore, since the search space is smaller than
the bit-wise situation, it is easier to be modeled by the automatic method. The
MILP-based truncated diﬀerential cryptanalysis was proposed by Moghaddam
et al. in 2019 [19]. An MILP model M consists of variables M.var, constraints
M.con, and an objective function M.obj. The details of constructing the MILP
model of the truncated diﬀerence can refer to [19]. The key point of the technique
is transforming the branching property of a linear layer into linear constraints
M.con. Once an MILP model is set up, an MILP solver such as Gurobi could be
employed to handle the model. For more details on Gurobi, please refer to [13].
Some results of SKINNY-64 and CRAFT given by [17] are presented in
Table 3. The longest round number of truncated diﬀerential distinguishers for
SKINNY-64 and CRAFT are 10 and 12 rounds. We repeated the experiments
given in [17] and observed that since the MILP models covered all the possi-
ble distinguishers in the framework of word-wise truncated diﬀerentials, only
if more details of the encryption components are taken into consideration the
diﬀerential-style distinguishers could possibly be improved.
Table 3. The longest truncated diﬀerential characteristics for SKINNY-64 and CRAFT
Ciphers
Round number Probability Ref.
SKINNY-64 10
2−40
[17]
CRAFT
12
2−36
[17]
2.4
SKINNY-64 and CRAFT
The internal states of SKINNY-64 and CRAFT can be viewed as a 4×4 matrix.
The round function of the two block ciphers consists of MixColumn(MC),
SubCell(SB), Add RoundKey(AK), and Cells Permutation. The nibbles in the
states of CRAFT and SKINNY-64 are expressed as
S =
⎛
⎜
⎜
⎝
s0
s1
s2
s3
s4
s5
s6
s7
s8
s9
s10 s11
s12 s13 s14 s15
⎞
⎟
⎟
⎠.
The round function of CRAFT can be written as R = SB ◦PN ◦AK ◦
MC, where PN represents the PermuteNibbles operation. The PermuteNibbles
permutes the cells of a state as follows:
(s0, . . . , s15) ←−(s15, s12, s13, s14, s10, s9, s8, s11, s6, s5, s4, s7, s1, s2, s3, s0),
and the MixColumn transforms every column by multiplying the following
matrix

78
X. Xie and T. Tian
Mc =
⎛
⎜
⎜
⎝
1 0 1 1
0 1 0 1
0 0 1 0
0 0 0 1
⎞
⎟
⎟
⎠.
The matrix Mc satisﬁes M −1
c
= Mc. It is worth noting that there is not whitening
key in CRAFT.
The round function of SKINNY-64 is R = MC ◦SC ◦AK ◦SB where SC
represents the ShiftRow operation. The ShiftRow permutes the cells of a state
as follows:
(s0, . . . , s15) ←−(s0, s1, s2, s3, s7, s4, s5, s6, s10, s11, s8, s9, s15, s12, s13, s14).
The MixColumn matrix of SKINNY-64 and its inverse matrix are
Ms =
⎛
⎜
⎜
⎝
1 0 1 1
1 0 0 0
0 1 1 0
1 0 1 0
⎞
⎟
⎟
⎠and M −1
s
=
⎛
⎜
⎜
⎝
0 1 0 0
0 1 1 1
0 1 0 1
1 0 0 1
⎞
⎟
⎟
⎠.
3
The Triangle Diﬀerential
In this section, we introduce the triangle diﬀerential and illustrate its relation
to the boomerang attack and the traditional diﬀerential. Furthermore, we will
discuss its advantage over the traditional truncated diﬀerential.
3.1
The Triangle Diﬀerential Distinguishers
Let α, β, γ ∈Fn×m
2
be three states in the middle of a block cipher. Suppose we
only know υ(α, β) and υ(β, γ). The following lemma gives a way to deduce the
diﬀerential pattern υ(α, γ) according to υ(α, β) and υ(β, γ).
Lemma 1 (Addition of diﬀerential pattern). Let α, β, γ ∈Fn×m
2
. Then
υ(α, γ)i =
⎧
⎨
⎩
0,
if υ(α, β)i = υ(β, γ)i = 0
1,
else if υ(α, β)i ̸= υ(β, γ)i,
unknown, otherwise.
Proof. If υ(α, β)i = υ(β, γ)i = 0, then it follows from αi = βi = γi that
υ(α, γ)i = 0. If υ(α, β)i = 1 and υ(β, γ)i = 0, then
αi ⊕γi = αi ⊕βi ⊕βi ⊕γi = αi ⊕βi ̸= 0,
i.e., υ(α, γ)i = 1. If υ(α, β)i = 0 and υ(β, γ)i = 1, then the result can be proved
similarly.
Remark 2. For a random triple (α, β, γ), the probability that υ(α, γ)i = 0 is
2−m in the case that υ(α, β)i = υ(β, γ)i = 1. Since this probability generally
has no inﬂuence on the distinguisher search in our applications, we ignore this
situation in the following and we simply write υ(α, γ) = υ(α, β) ∨υ(β, γ).

The Triangle Diﬀerential Cryptanalysis
79
Fig. 2. The framework of the triangle diﬀerential
Now we give the framework of the triangle diﬀerential in the following theo-
rem, which is also depicted in Fig. 2.
Theorem 2. Let E : Fn×m
2
→Fn×m
2
be an encryption function which can be
decomposed into E = E1 ◦E0. Suppose there are truncated diﬀerential charac-
teristics as follows
Pr[δ0
E0
−→δ1]
= a,
Pr[δ2
E−1
1
−→δ3]
= b,
Pr[δ1 ∨δ3
E−1
0
−→δ4] = c,
where δ0, δ1, δ2, δ3, δ4 ∈Fn
2. Then, for a plaintext pair (p0, p1) ∈Fn×m
2
× Fn×m
2
satisfying υ(p0, p1) = δ0 and the corresponding ciphertext pair c0 = E(p0), c1 =
E(p1),
Pr[υ(p0, p2) = δ4|υ(c2, c1) = δ2] = a × b × c
where c2 = E(p2).
Proof. For each 0 ≤i ≤3, let xi = E0(pi). Since υ(p0, p1) = δ0, according to
Pr[δ0
E0
−→δ1] = a, we have
υ(x0, x1) = δ1
(1)
with probability a. Similarly,
υ(x1, x2) = δ3
(2)
with probability b. If both Eq. (1) and (2) hold, according to Lemma 1 we have
υ(x0, x2) = δ1 ∨δ3.

80
X. Xie and T. Tian
Then, according to the truncated diﬀerential characteristic Pr[δ1∨δ3
E−1
0
−→δ4] = c,
we have υ(p0, p2) = δ4 with probability c. Hence, assuming that all these events
are independent, we have
Pr[υ(p0, p2) = δ4] = a × b × c.
This completes the proof.
For α ∈Fn
2, denote wt(α) as the Hamming weight of α. Thus, for the triangle
diﬀerence described in Theorem 2, wt(δ4) implies the number of active S-boxes
in the output diﬀerence. The probability that an output pair of a random per-
mutation falls into the distinguisher is Prand = 2−m×(n−wt(δ4)). To ensure that
the triangle diﬀerence can distinguish the block cipher from a pseudo-random
permutation, there must be a × b × c > Prand.
There may be a question why the triangle diﬀerential can yield a longer
distinguisher than the traditional truncated diﬀerential. Let δ0, δ1, δ2, δ3, δ4 be as
described in Theorem 2. Suppose δ4 = δ0. Since there is a truncated diﬀerential
δ0
E0
−→δ1, the truncated diﬀerential δ1
E−1
0
−→δ4 is a possible characteristic with
probability c. Moreover, the probability Pr[δ0
E0
−→δ1] = a can be very close
to 1, and the number of active Sboxes for wt(δ4) = wt(δ0) can be very small.
On the other hand, since n −wt(δ4) is large enough, if there exists a truncated
diﬀerence δ2
E−1
1
−→δ3 with a large probability b and satisfying δ3 ∧δ1 = δ1, then
the constraints a × b × c > 2−m×(n−wt(δ4)) can easily hold. In another view, a
triangle diﬀerence combines the following two truncated diﬀerences
δ2
E−1
1
−→δ3, δ1
E−1
0
−→δ0,
where δ3∧δ1 = δ1. There are many diﬀerential patterns for middle states that can
not be propagated by any truncated diﬀerential trails, i.e., some values for δ1 and
δ3 are impossible. Triangle diﬀerential provides a way to construct diﬀerential
pattern for middle states which is impossible before. Thus, we can have a larger
search space than truncated diﬀerential. After the construction of the triangle
diﬀerential distinguisher with the probability a × b × c, Algorithm 1 shows the
procedure of distinguishing a cipher E from random permutations.
Remark 3. Note that a d-diﬀerential distinguisher in the case of d = 2 [20] also
uses three texts. However, the triangle diﬀerential distinguishers are quite diﬀer-
ent from the 2-diﬀerential distinguishers. First, the triangle diﬀerential consid-
ers relative diﬀerences of three texts to each other, while the 2-diﬀerential only
considers relative diﬀerences of two texts with respect to the chosen reference
text. Second, the triangle diﬀerential considers the propagation of diﬀerences for
both forward and backward, while the 2-diﬀerential only considers one direction
(encryption or decryption).

The Triangle Diﬀerential Cryptanalysis
81
Algorithm 1. The Triangle Diﬀerential Attack Algorithm
1: Initialize a counter ctr ←0.
2: Generate (a × b × c)−1 unique pairs (P0, P1) with input diﬀerence δ0.
3: for all pairs (P0, P1) do
4:
Ask for the encryption of (P0, P1) to (C0, C1).
5:
Compute C2 = C1 ⊕δ2.
6:
Ask for the decryption of C2 to P2.
7:
if υ(C0 ⊕C2) = δ4 then
8:
Increment ctr.
9:
end if
10: end for
11: if ctr ≥1 then
12:
return This is the cipher E.
13: else
14:
return This is a random permutation.
15: end if
3.2
MILP Modeling for the Triangle Diﬀerential Distinguisher
Search
In this section, we are only concerned with the AES-like ciphers. As mentioned
before, the point of modeling the distinguisher search of the truncated diﬀerential
is how to transform the branching property of block ciphers to linear constraints
M.con. For a matrix, the branching property is deﬁned as follows.
Deﬁnition 2 (Branching property). Let M be an m × m matrix on Fm
2 ,
α, β ∈Fn×m
2
. Denote Pm(a0, a1) = Pr[υ(M·α⊕M·β) = a1|υ(α⊕β) = a0]. Deﬁne
the branching property function η of M as follows. For every (a0, a1) ∈Fm
2 ×Fm
2 ,
η(a0, a1) =

1 −Pm(a0, a1),
if Pm(a0, a1) ∈{0, 1},
−log2(Pm(a0, a1)), otherwise.
The branching property tables of Ms and Mc can refer to [17]. Beside the
encryption, the decryption of a block cipher should also be modeled to the MILP
problem. Thus, the branching property of M −1
s
and M −1
c
are also needed. Since
M −1
c
= Mc, we only present the branching property of M −1
s
, see Table 4. The
probabilities utilized in branching properties are given by reasonable approxi-
mation. Since for Ms, Mc and M −1
c
, the probability Pm(a0, a1) always close to
the values in {0, 1, 2−m, 2−2m}. We use values in {0, 1, 2−m, 2−2m} to estimate
Pm(a0, a1). This approximation has little impact on the distinguisher search.
With the branching property table, we employ Logic Friday [1] to construct a
Boolean function f(x) : F10
2 →F2 satisfying
f(x) =
1, if η(a0, a1) = x8 × 4 + x9 × 8,
0, otherwise,
where x = (x0, x1, . . . , x9), a0 = (x0, x1, x2, x3) and a1 = (x4, x5, x6, x7), thus,
x = a0||a1||(x8, x9). Transform f to the product-of-sum representation by Logic

82
X. Xie and T. Tian
Friday so that we can get the inequalities l(MC)(x, y, p0, p1) whose solution cor-
responds to the branching property, where x, y ∈F4
2, p0, p1 ∈F2.
After converting the branching property to linear constraints l(MC)(x, y,
p0, p1), we can construct an MILP model to search triangle diﬀerential distin-
guishers for N = N1+N2 round SKINNY-64 and CRAFT by Algorithm 2, which
could be easily generalized to other AES-like ciphers.
Algorithm 2. Triangle diﬀerential distinguisher search by MILP
1: for r = 0 to N1 do
2:
M.var ←(xr
0, xr
1, . . . , xr
15),
3:
M.var ←(pr
0,0, pr
1,0, pr
0,1, pr
1,1, pr
0,2, pr
1,2, pr
0,3, pr
1,3).
4: end for
5: for r = 0 to N2 do
6:
M.var ←(yr
0, yr
1, . . . , yr
15),
7:
M.var ←(pr
2,0, pr
3,0, pr
2,1, pr
3,1, pr
2,2, pr
3,2, pr
2,3, pr
3,3).
8:
M.var ←(zr
0, zr
1, . . . , zr
15),
9:
M.var ←(pr
4,0, pr
5,0, pr
4,1, pr
5,1, pr
4,2, pr
5,2, pr
4,3, pr
5,3).
10: end for
11: M.con ←15
i=0 x0
i ≥1
12: for r = 0 to N1 −1 do
13:
for i = 0 to 3 do
14:
M.con ←l(MC)(xr+1
Col(i), xr
SC(Col(i)), pr
0,i, pr
1,i)
15:
▷The notation Col(i) denotes the set {jk|sjk in the i-th column }
16:
▷The notation SC(Col(i)) denotes the set {SC(j)|j ∈Col(i)}
17:
M.con ←l(InvMC)(zr
Col(i), zr+1
SC(Col(i)), pr
4,i, pr
5,i)
18:
end for
19: end for
20: for r = 0 to N2 −1 do
21:
for i = 0 to 3 do
22:
M.con ←l(InvMC)(yr
Col(i), yr+1
SC(Col(i)), pr
2,i, pr
3,i)
23:
end for
24: end for
25: M.con ←z0 = xN1 ∧yN2
26: PT = n−1
r=0
4
i=0 4 × (pr
0,i + pr
2,i + pr
4,i) + 8 × (pr
1,i + pr
3,i + pr
5,i))
27: Prand = 4 × 15
i=0 (1 −zN1
i
)
28: M.con ←PT < Prand
29: M.obj ←Min{PT }
30: Solve M;
31: if M is feasible then
32:
return M.obj.
33: end if
4
Applications to SKINNY-64 and CRAFT
To illustrate the eﬀect of the triangle diﬀerential, we apply this new cryptanalysis
on SKINNY-64 and CRAFT in this section. Since the diﬀerence of the input and
output diﬀerences of the linear operation can be deduced from each other, the

The Triangle Diﬀerential Cryptanalysis
83
Table 4. Branching property table of M −1
s
In/out
0x0
0x1
0x2
0x3
0x4
0x5
0x6
0x7
0x8
0x9
0xa
0xb
0xc
0xd
0xe
0xf
0x0
1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0x1
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0x2
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0
0x3
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
0x4
0
0
1
0
0
0
0
0
0
0
0
0
0
0
0
0
0x5
0
0
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0x6
0
0
0
0
0
4
0
1
0
0
0
0
0
0
0
0
0x7
0
0
0
0
0
0
0
0
0
0
0
0
0
4
0
1
0x8
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
0
0x9
0
0
0
0
0
0
4
0
0
0
0
0
0
0
1
0
0xa
0
0
0
0
0
0
0
0
0
4
0
0
0
0
0
1
0xb
0
8
0
0
0
0
0
4
0
4
0
0
0
0
0
1
0xc
0
0
0
0
0
0
0
0
0
0
0
0
4
0
1
0
0xd
0
0
0
0
8
0
4
0
0
0
0
0
4
0
1
0
0xe
0
0
0
0
0
0
0
0
0
0
0
4
0
4
0
1
0xf
0
0
0
8
0
8
0
4
0
0
0
4
0
4
0
1
linear operation before the ﬁrst Sbox or after the last Sbox will be omitted when
searching the triangle diﬀerential distinguisher. We call these linear operations
an independent linear layer.
Let R = MC ◦SC ◦AK ◦SB be the round function of SKINNY-64. The
11-round encryption of SKINNY-64 without an independent linear layer can be
written as
E = SC ◦SB ◦R9 ◦MC ◦AK ◦SB.
We decompose E into E = E1 ◦E0, where
E0 = SC ◦AK ◦SB ◦R4 ◦MC ◦AK ◦SB,
E1 = SC ◦SB ◦R4 ◦MC.
Let
δ0 = (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1),
δ1 = (1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1),
δ2 = (0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0),
δ3 = (1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1),
δ4 = (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1).
By employing Gurobi to handle the distinguisher search model, we get the follow-
ing truncated diﬀerential characteristics which can be composed into a triangle
diﬀerential distinguisher.
Pr[δ0
E0
−→δ1]
= 1,
Pr[δ2
E−1
1
−→δ3]
= 2−12,
Pr[δ1 ∨δ3
E−1
0
−→δ4] = 2−44.

84
X. Xie and T. Tian
Thus, the probability of distinguisher is 2−56, while Prand = 2−m×(n−wt(δ4)) =
2−60. More details of 11 round triangle diﬀerential distinguisher of SKINNY-64
are presented in Fig. 3.
Fig. 3. The triangle diﬀerence of SKINNY-64
Denote the 13-round encryption of CRAFT without the ﬁrst linear layer as
E = R12◦SB, where R = SB◦PN ◦AK◦MC be the round function of CRAFT.
Let E0 = R8 ◦SB and E1 = R4. Thus, E = E1 ◦E0. Let
δ0 = (0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1),
δ1 = (0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0),
δ2 = (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0),
δ3 = (1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0),
δ4 = (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0).

The Triangle Diﬀerential Cryptanalysis
85
Fig. 4. The triangle diﬀerence of CRAFT

86
X. Xie and T. Tian
The following truncated diﬀerential distinguishers for E0 and E1 form a triangle
diﬀerential distinguisher.
Pr[δ0
E0
−→δ1]
= 2−32,
Pr[δ2
E−1
1
−→δ3]
= 1,
Pr[δ1 ∨δ3
E1
−→δ4] = 2−24.
Since wt(δ4) = 1, Prand = 2−m×(n−wt(δ4)) = 2−60. The probability of distnigu-
isher is 2−56 > 2−60. More details of 13 round triangle diﬀerential distinguisher
of CRAFT are presented in Fig. 4.
It is remarkable that the results of our distinguisher search for SKINNY-64
and CRAFT are both better than the best result of the truncated diﬀeren-
tial, while the longest truncated diﬀerential distinguishers of SKINNY-64 and
CRAFT is 10 and 12 round, respectively. We use the Gurobi to solve our MILP
based distinguisher search model, and the code of the experiments is presented
at https://github.com/BLOCKCIPHERS702702.
5
Further Discussion on the Improvement
In this section, we would like to discuss a potential idea to improve our method,
although it did not work in our experiments on SKINNY-64 and CRAFT.
Let E: Fn×m
2
→Fn×m
2
be the encryption of a block cipher that can be
decomposed into E = E1 ◦E0, and δ0
E0
−→δ1, δ2
E−1
1
−→δ3 be truncated diﬀerences.
For middle states x0, x1, x2 satisfying υ(x0, x1) = δ1 and υ(x1, x2) = δ3. Denote
the i-th bit of δ by δ[i]. Set δ4 = x0 ⊕x2. According to Remark 2 below Lemma
1, we treat δ4[i] = 1 if δ0[i] = δ3[i] = 1. Practically, δ4[i] = 0 holds with a small
probability in the case of δ0[i] = δ3[i] = 1, and the probability is given by
Pr[δ4[i] = 0 | δ0[i] = δ3[i] = 1] = 2−m.
It can be seen that if δ4[i] = 0, then the number of active Sboxes in the middle
state is reduced. Thus, although δ4[i] = 0 holds with a small probability when
δ0[i] = δ3[i] = 1, we still think this case might be helpful for searching distin-
guishers against certain block ciphers since more diﬀerential trails are considered
by the tradeoﬀbetween the probability and the number of active Sboxes.
6
Conclusion
In this paper, we propose a new variant of diﬀerential cryptanalysis called tri-
angle diﬀerential and illustrate this new cryptanalytic technique against block
ciphers. An MILP model is provided for the distinguisher search of triangle dif-
ferential against the general AES-like cipher. The results of our new technique
against SKINNY-64 and CRAFT imply that a triangle diﬀerential distinguisher
could be longer than a truncated diﬀerential distinguisher and also exhibit some
advantages over other kinds of distinguishers. The improvement of this technique
and applying it to other ciphers will be the subject of future research.

The Triangle Diﬀerential Cryptanalysis
87
References
1. Logic
Friday.
https://www.softpedia.com/get/Others/Home-Education/Logic-
Friday.shtml
2. Banik, S., et al.: Midori: a block cipher for low energy. In: Iwata, T., Cheon, J.H.
(eds.) ASIACRYPT 2015. LNCS, vol. 9453, pp. 411–436. Springer, Heidelberg
(2015). https://doi.org/10.1007/978-3-662-48800-3 17
3. Bao, Z., Guo, J., Shi, D., Tu, Y.: Superposition meet-in-the-middle attacks: updates
on fundamental security of AES-like hashing. In: Dodis, Y., Shrimpton, T. (eds.)
CRYPTO 2022. LNCS, vol. 13507, pp. 64–93. (2022). https://doi.org/10.1007/978-
3-031-15802-5 3
4. Bar-On, A., Dunkelman, O., Keller, N., Ronen, E., Shamir, A.: Improved key recov-
ery attacks on reduced-round AES with practical data and memory complexities.
J. Cryptol. 33(3), 1003–1043 (2020)
5. Bardeh, N.G., Rønjom, S.: The exchange attack: how to distinguish six rounds
of AES with 288.2 chosen plaintexts. In: Galbraith, S.D., Moriai, S. (eds.) ASI-
ACRYPT 2019. LNCS, vol. 11923, pp. 347–370. Springer, Cham (2019). https://
doi.org/10.1007/978-3-030-34618-8 12
6. Beierle, C., et al.: The SKINNY family of block ciphers and its low-latency variant
MANTIS. In: Robshaw, M., Katz, J. (eds.) CRYPTO 2016. LNCS, vol. 9815, pp.
123–153. Springer, Heidelberg (2016). https://doi.org/10.1007/978-3-662-53008-
5 5
7. Beierle, C., Leander, G., Moradi, A., Rasoolzadeh, S.: CRAFT: lightweight tweak-
able block cipher with eﬃcient protection against DFA attacks. IACR Trans. Sym-
metric Cryptol. 2019(1), 5–45 (2019)
8. Biham, E., Biryukov, A., Shamir, A.: Cryptanalysis of skipjack reduced to 31
rounds using impossible diﬀerentials. In: Stern, J. (ed.) EUROCRYPT 1999. LNCS,
vol. 1592, pp. 12–23. Springer, Heidelberg (1999). https://doi.org/10.1007/3-540-
48910-X 2
9. Dunkelman, O., Keller, N., Ronen, E., Shamir, A.: The retracing boomerang attack.
In: Canteaut, A., Ishai, Y. (eds.) EUROCRYPT 2020. LNCS, vol. 12105, pp. 280–
309. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-45721-1 11
10. Fu, K., Wang, M., Guo, Y., Sun, S., Hu, L.: MILP-based automatic search algo-
rithms for diﬀerential and linear trails for speck. In: Peyrin, T. (ed.) FSE 2016.
LNCS, vol. 9783, pp. 268–288. Springer, Heidelberg (2016). https://doi.org/10.
1007/978-3-662-52993-5 14
11. Gong, Z., Nikova, S., Law, Y.W.: KLEIN: a new family of lightweight block ciphers.
In: Juels, A., Paar, C. (eds.) RFIDSec 2011. LNCS, vol. 7055, pp. 1–18. Springer,
Heidelberg (2012). https://doi.org/10.1007/978-3-642-25286-0 1
12. Grassi, L.: Mixture diﬀerential cryptanalysis: a new approach to distinguishers
and attacks on round-reduced AES. IACR Trans. Symmetric Cryptol. 2018(2),
133–160 (2018)
13. Gu, Z., Rothberg, E., Bixby, R.: Gurobi optimizer. http://www.gurobi.com/
14. Hadipour, H., Sadeghi, S., Niknam, M.M., Song, L., Bagheri, N.: Comprehensive
security analysis of CRAFT. IACR Trans. Symmetric Cryptol. 2019(4), 290–317
(2019)
15. Knudsen, L.R.: Truncated and higher order diﬀerentials. In: Preneel, B. (ed.) FSE
1994. LNCS, vol. 1008, pp. 196–211. Springer, Heidelberg (1995). https://doi.org/
10.1007/3-540-60590-8 16

88
X. Xie and T. Tian
16. Lallemand, V., Naya-Plasencia, M.: Cryptanalysis of KLEIN. In: Cid, C., Rech-
berger, C. (eds.) FSE 2014. LNCS, vol. 8540, pp. 451–470. Springer, Heidelberg
(2015). https://doi.org/10.1007/978-3-662-46706-0 23
17. Moghaddam, A.E., Ahmadian, Z.: New automatic search method for truncated-
diﬀerential characteristics application to Midori, SKINNY and CRAFT. Comput.
J. 63(12), 1813–1825 (2020). https://doi.org/10.1093/comjnl/bxaa004
18. Sadeghi, S., Mohammadi, T., Bagheri, N.: Cryptanalysis of reduced round SKINNY
block cipher. IACR Trans. Symmetric Cryptol. 2018(3), 124–162 (2018)
19. Sun, S., Hu, L., Wang, P., Qiao, K., Ma, X., Song, L.: Automatic security eval-
uation and (related-key) diﬀerential characteristic search: application to SIMON,
PRESENT, LBlock, DES(L) and other bit-oriented block ciphers. In: Sarkar, P.,
Iwata, T. (eds.) ASIACRYPT 2014. LNCS, vol. 8873, pp. 158–178. Springer, Hei-
delberg (2014). https://doi.org/10.1007/978-3-662-45611-8 9
20. Tiessen, T.: Polytopic cryptanalysis. In: Fischlin, M., Coron, J.-S. (eds.) EURO-
CRYPT 2016. LNCS, vol. 9665, pp. 214–239. Springer, Heidelberg (2016). https://
doi.org/10.1007/978-3-662-49890-3 9
21. Wagner, D.: The boomerang attack. In: Knudsen, L. (ed.) FSE 1999. LNCS, vol.
1636, pp. 156–170. Springer, Heidelberg (1999). https://doi.org/10.1007/3-540-
48519-8 12
22. Xiang, Z., Zhang, W., Bao, Z., Lin, D.: Applying MILP method to searching inte-
gral distinguishers based on division property for 6 lightweight block ciphers. In:
Cheon, J.H., Takagi, T. (eds.) ASIACRYPT 2016. LNCS, vol. 10031, pp. 648–678.
Springer, Heidelberg (2016). https://doi.org/10.1007/978-3-662-53887-6 24

Key Recovery Attacks on Grain-Like
Keystream Generators with Key Injection
Matthew Beighton
, Harry Bartlett(B)
, Leonie Simpson
,
and Kenneth Koon-Ho Wong
Queensland University of Technology, Brisbane, QLD, Australia
matthew.beighton@hdr.qut.edu.au, {h.bartlett,lr.simpson}@qut.edu.au,
k45.wong@connect.qut.edu.au
Abstract. A common structure in stream ciphers makes use of linear
and nonlinear shift registers with a nonlinear output function drawing
from both registers. We refer to these as Grain-like keystream genera-
tors. A recent development in lightweight ciphers is a modiﬁcation of this
structure to include a non-volatile key register, which allows key bits to
be fed into the state update of the nonlinear register. Sprout and Plant-
let are examples of this modiﬁed structure. The authors of these ciphers
argue that including these key bits in the internal state update provides
increased security, enabling the use of reduced register sizes below the
commonly accepted rule of thumb that the state size should be at least
twice the key size.
In this paper, we analyse Plantlet and show that the security of this
design depends entirely on the choice of the output function. Speciﬁcally,
the contribution from the nonlinear register to the output function deter-
mines whether a key recovery attack is possible. We make a minor mod-
iﬁcation to Plantlet’s output function which allows the contents of the
linear register to be recovered using an algebraic attack during keystream
generation. This information then allows partial recovery of the contents
of the nonlinear register, after which the key bits and the remaining reg-
ister contents can be obtained using a guess and check approach, with a
complexity signiﬁcantly lower than exhaustive key search.
Note that our attack is not successful on the existing version of Plant-
let, though it only requires minor modiﬁcations to the ﬁlter function in
order for the attack to succeed. However, our results clearly demonstrate
that including the key in the state update during keystream genera-
tion does not increase the security of Plantlet. In fact, this feature was
exploited to recover the key during keystream generation without the
need to consider the initialisation process. This paper provides design
guidelines for choosing both suitable output functions and the register
stages used for inputs to these functions in order to resist the attacks we
applied.
Keywords: Key recovery · algebraic attack · key injection · Plantlet ·
Grain-like structures · lightweight ciphers
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 89–108, 2023.
https://doi.org/10.1007/978-3-031-35486-1_5

90
M. Beighton et al.
1
Introduction
Symmetric stream ciphers are used to provide conﬁdentiality for a range of real-
time applications. The most common type of stream cipher is the binary additive
stream cipher, where encryption and decryption are performed by XORing a
binary keystream with the plaintext or ciphertext bitstream, respectively. The
reciprocal nature of the XOR operation provides high speed encryption and
decryption processes. However, the security provided depends on the properties
of the keystream. The security of the keystream generator is therefore crucial.
The importance of secure encryption is highlighted by the recent NIST com-
petition for AEAD algorithms suitable for lightweight applications. These algo-
rithms are intended for use in applications such as the ubiquitous Internet of
Things (IoT) and require high security levels with reduced computational load
and/or component size.
Many keystream generators are based on shift registers with either a lin-
ear or nonlinear feedback function, denoted as linear feedback shift registers
(LFSRs) and nonlinear feedback shift registers (NFSRs), respectively. However,
previous work [3,6,7] has shown that shift register based ciphers are vulnerable
to algebraic attacks. In response, some contemporary keystream generators use
a combination of a NFSR and a LFSR, together with a nonlinear ﬁlter func-
tion taking inputs from both registers. We refer to these generators as “Grain-
like structures”, as the well known Grain family of stream ciphers [13–17] is
designed in this way. The combination of LFSRs and NFSRs in these structures
was intended to prevent such algebraic attacks; however, Berbain et al. [4] and
Beighton et al. [2] have demonstrated viable attacks against Grain-like structures
with particular forms of output function.
A further development, aimed at providing encryption for lightweight devices,
is to include a non-volatile key register in the cipher state. The key bits stored
in this register are then injected into the feedback of the shift registers during
operation. The ciphers Sprout [1] and Plantlet [22] both use this technique. This
introduction of key injection into Grain-like ciphers was intended to increase the
security of these ciphers, so that lightweight ciphers with smaller registers could
still provide acceptable security levels. In particular, the internal state size in
these ciphers is less than twice the key size, contradictory to the rule of thumb
from Hong and Sarkar [18] in relation to generic time-memory trade-oﬀattacks.
The authors of Sprout [1] invited further investigation of these designs fea-
turing key injection. In this paper, we therefore investigate the security provided
by Grain-like keystream generators with key injection. Speciﬁcally, we explore an
algebraic key recovery attack on Plantlet and ﬁnd that it can be successfully per-
formed with only a minor modiﬁcation to the output function and with the key
injection feature left intact. Our attack is based on the algebraic attack applied
to Grain-like structures by Beighton et al. [2]; it is applied during keystream
generation, so no knowledge of the initialisation function is required.
This paper is organised as follows: Sect. 2 provides background informa-
tion on shift register based designs. Section 3 discusses current algebraic attack
techniques. Section 4 presents our algebraic attack technique for application to

Key Recovery Attacks on Grain-Like Keystream Generators
91
Grain-like structures with key injection. We then apply our attack technique to
modiﬁed Plantlet in Sect. 5. Experimental simulations for proof of concept are
reported in Sect. 6 and discussed in Sect. 7. Conclusions are drawn in Sect. 8.
2
Preliminaries and Notation
2.1
Feedback Shift Registers
A binary feedback shift register (FSR) of length n is a set of n storage
devices called stages (r0, r1, ..., rn−1), each containing one bit, together with
a Boolean update function g. The state at any time t is deﬁned to be St, where
St = st, st+1, ..., st+(n−1), and the sequence of state bits that passes through the
register over time is denoted S; that is S = s0, s1, .., sn−1, sn, ... .
The shift registers used in the types of keystream generators we discuss in
this paper are regularly clocked Fibonacci style, as shown in Fig. 1. Thus, the
state update function takes the form:
rt+1
i
=

rt
i+1
i = 0, 1, . . . , n −2
g(r0, r1, .., rn−1)
i = n −1
If g is linear, the register is said to be a linear feedback shift register (LFSR)
and if g is nonlinear, the register is said to be a nonlinear feedback shift register
(NFSR).
A binary sequence can be generated from a FSR by applying a Boolean
function f to the state St, as shown in Fig. 1. Here, the output y = f(St) can
be a function of the contents of one or more register stages.
2.2
Filter Generators
Keystream generators where f is a function of the contents of multiple stages
are called ﬁlter generators. If f and g are both linear, the ﬁlter generator is
equivalent to another LFSR, which provides very little security to the plaintext
Fig. 1. An n-stage FSR with update function g and ﬁlter function f.

92
M. Beighton et al.
[20]. For this reason, LFSRs were traditionally ﬁltered using a nonlinear Boolean
function [19].
A keystream generator consisting of a LFSR and a nonlinear ﬁlter function
f is known as a nonlinear ﬁlter generator (NLFG) [24]. These designs have
been extensively analysed and are susceptible to numerous attacks, including
correlation attacks [10,12,21,24], algebraic attacks [6,7,9] and distinguishing
attacks [8]. The underlying LFSR provides only desirable statistical properties
for the binary sequence, while the resistance of the NLFG to cryptanalysis is
determined by the properties of the nonlinear ﬁlter function. As a single nonlinear
Boolean function cannot display high levels of all the desirable cryptographic
properties [23], choosing a ﬁlter function that resists one form of attack may
leave the keystream generator vulnerable to other attacks.
In response to the cryptanalysis of NLFGs, designs using NFSRs were pro-
posed. A linearly ﬁltered nonlinear feedback shift register (LF-NFSR) [11] has
a nonlinear update function g and a linear ﬁlter function f, and is the dual
construction of the NLFG. Berbain et al. [3] showed that LF-NFSRs are also
susceptible to algebraic attacks, resulting in initial state (and possibly secret
key) recovery. From Berbain’s results, it is clear that the properties of the ﬁlter
function used in a LF-NFSR are critical in providing resistance to a traditional
algebraic attack.
2.3
Composite Combiners and ‘Grain-Like’ Structures
Eﬀective algebraic attacks have been proposed on both NLFG and LF-NFSR
keystream generators. A more complex design incorporates both a LFSR and a
NFSR, together with a nonlinear ﬁlter function taking inputs from both registers,
as shown in Fig. 2. Keystream generators using this structure include Grain [15]
and subsequent variants of Grain [13,14,16,17]. We denote this general design as
a “Grain-like” structure. Here we consider the lengths of the NFSR and LFSR to
be the same (n). However, the approach outlined also applies in the case where
register lengths diﬀer.
Fig. 2. Grain-like structure.

Key Recovery Attacks on Grain-Like Keystream Generators
93
We denote the states of the NFSR and the LFSR at any time t as Bt and
St. The sequences of state bits that pass through the registers over time are
denoted B and S; that is B = b0, b1, .., bn−1, bn, ... and S = s0, s1, .., sn−1, sn, ....
In the case of Grain-like structures, we denote the nonlinear update function as
g, the linear update function as ℓand the ﬁlter function as f. For a Grain-like
structure, the LFSR is autonomous when producing output as all of the inputs
to ℓare from the LFSR. The NFSR is not autonomous, as the nonlinear update
function g contains one input from the LFSR.
The ﬁlter function f can be considered as the XOR sum (here denoted ‘+’)
of several diﬀerent types of monomials. That is, we consider sub-functions of f.
We deﬁne the following sub-functions, each as a sum of the terms indicated:
– LB - monomials with linear inputs from NFSR.
– LS - monomials with linear inputs from LFSR.
– fS - nonlinear monomials with inputs from LFSR only.
– fB - nonlinear monomials with inputs from NFSR only.
– fBS - nonlinear monomials with inputs from both NFSR and LFSR.
Thus, any ﬁlter function f in a Grain-like structure can be expressed as follows:
f(B, S) = LB + LS + fB + fS + fBS.
(1)
2.4
Grain-Like Structures Using Key Injection
Newer contemporary designs have been proposed which use the general Grain-
like structure, but also incorporate the secret key in the state update of the
keystream generator, as in Fig. 3. Keystream generators such as those used in
Sprout [1] and Plantlet [22] have this design. We denote this general design as
a “Grain-like structure with key injection” and use the same notation as for a
general Grain-like structure.
Fig. 3. Grain-like structure with key injection.

94
M. Beighton et al.
3
Current Algebraic Attacks
Algebraic attacks were ﬁrst introduced by Courtois and Meier [7] on ciphers
with linear feedback. The goal of an algebraic attack is to create a system of
low degree equations that relates the initial state bits of the cipher to some
observed output bits and then to solve these equations to recover the internal
state values. For a binary additive stream cipher, the output may be obtained
using a known-plaintext attack.
These attacks are performed in two phases: pre-computation and online. The
pre-computation phase builds a system of equations relating initial state bits and
output bits. In the online phase, given an observed output sequence {yt}∞
t=0, the
appropriate substitutions are performed, the system is solved and the initial
state recovered.
3.1
Algebraic Attacks on NLFGs [7]
Each output bit of a NFSR satisﬁes the equation
yt = f(St) = f(st, . . . , st+n−1)
(2)
The linear update function g of the LFSR can then be used to replace state bits
st+n−1 with the corresponding linear combination of initial state bits, keeping
the equation system of a constant degree (deg(f)) while maintaining the number
of unknown variables in the system.
In many cases, each equation in the system may be multiplied through by a
low degree multivariate function h (of degree e) to reduce the overall degree of
the system of equations [7]. If fh = 0, then h is deﬁned as an annihilator of f.
Each equation in the resulting system has the form
f(St)h(St) = yth(St).
The degree of this system will be equal to deg(fh) = d, where d < deg(f), with
n independent variables, where n is the length of the underlying LFSR. For a
more detailed explanation, the reader is referred to Courtois and Meier’s paper
[7]. Appendix A.1 provides an algorithm for this attack and also discusses data
requirements and computational complexity.
3.2
Fast Algebraic Attacks on NLFGs [6]
Fast algebraic attacks [6] signiﬁcantly reduce the complexity of the online phase
by reducing the overall degree of the system of equations below the degree of fh.
This increases the complexity of the precomputation phase; however, precompu-
tation only needs to be performed once for a particular cipher and the equation
system may then be reused in multiple online phases to recover the states of the
cipher corresponding to multiple diﬀerent keystreams.
These attacks use a concept Courtois [6] described as “double-decker equa-
tions”. These equations allow an attacker to equate an expression in terms of

Key Recovery Attacks on Grain-Like Keystream Generators
95
initial state bits only to an expression in terms of initial state bits and observed
output bits. The technique targets monomials in initial state bits only of degree
from e = deg(h) to d = deg(fh): given approximately
n
d

equations, these mono-
mials will occur in multiple equations and can be replaced by suitable linear
combinations of those equations. These linear combinations deﬁne a new system
in n unknowns, of degree e < d. This new system can be solved by linearisation,
with less computational complexity than for traditional algebraic attacks.
For a detailed explanation, the reader is referred to Courtois’ paper [6].
Appendix A.2 provides an algorithm for this attack and also discusses data
requirements and computational complexity.
3.3
Algebraic Attacks on LF-NFSRs
Initially, LF-NFSRs were considered resistant to algebraic attacks, due to the
use of a nonlinear state update function. Using the nonlinear feedback function
to derive equations for the update bits in terms of initial state bits causes the
degree of the system of equations to increase over time. However, Berbain et
al. [3] showed that it is possible to keep the degree of the system of equations
constant. This allows an algebraic attack which can recover the initial state of
the underlying NFSR (and possibly the secret key).
Berbain et al. [3] noted that the equation for the ﬁrst output bit
y0 = ℓ(s0, ..., sn−1) =
n−1

k=0
aksk,
(with ak ∈{0, 1}) implies that
sj =
j−1

k=0
aksk + y0.
where j is the highest index in the original summation for which aj = 1.
Repeating this process for all subsequent time steps allows us to express every
bit, sj+t for t ≥0, as a linear combination of output bits and initial state bits.
This produces a set of equations of the form:
sj+t =
j−1

k=0
ak+tsk+t + yt,
for t ≥0. Note that if the latter summations contain any term for which an
equation already exists, the term can be replaced by the corresponding linear
combination of initial state bits and output bits.
Appendix A.3 provides an algorithm for this attack and also discusses data
requirements and computational complexity.

96
M. Beighton et al.
3.4
Algebraic Attacks on Grain-Like Structures
After successfully applying algebraic attacks to LF-NFSRs, Berbain et al. [4]
proposed an algebraic attack on Grain-like structures where the output function
f is the XOR combination of a LF-NFSR and a NLFG. That is, adopting the
notation from Sect. 2.3, f(B, S) = LB + LS + fS.
In this case the output of the keystream generator can be expressed as
y0 = LB + LS + fS =
n−1

k=0
akbk + LS + fS.
(3)
As discussed in Sect. 3.3, an equation of the form taken by Eq. 3 can be rear-
ranged as follows:
bj =
j−1

k=0
akbk + LS + fS + y0.
Repeating this for t > 0 allows for NFSR state bits of index j or higher to be
represented as the XOR sum of:
– a linear combination of NFSR initial state bits
– a linear and nonlinear combination of LFSR initial state bits
– a linear combination of observed output bits.
A second system of equations can then be built using the nonlinear update func-
tion to the NFSR, making substitutions from the system generated by Eq. 3
where applicable. This system will be of degree at most deg(g)deg(fS). Combin-
ing the two systems results in a system of equations of degree deg(g)deg(fS) in
n + j unknown initial state bits, where n is the size of LFSR and j is the index
of the highest indexed term in LB. The success of this attack in recovering the
LFSR and NFSR initial states demonstrated that using the contents of stages in
the NFSR linearly in the output function is not suﬃcient to provide resistance to
algebraic attacks; the NFSR contents must also be ﬁltered nonlinearly in some
way.
Beighton et al. [2] proposed an algebraic attack on Grain-like structures where
the output function f is of the form f = LS +fS +fBS. They note that, by using
the idea of annihilators presented by Courtois and Meier [7], f may be multiplied
by a low degree function containing only LFSR bits that will eliminate fBS. This
function, denoted ABS, is considered as a “partial annihilator”, in as much as
ABS only annihilates certain monomials.
Multiplying f by ABS leaves an equation of the form
zABS = ABS(LS + fS),
which is an equation containing only LFSR initial state bits. Fast algebraic
attack techniques can then be applied to recover the LFSR initial state, from
which the NFSR initial state can be partially recovered.

Key Recovery Attacks on Grain-Like Keystream Generators
97
4
Our Divide and Conquer Attack on Grain-Like
Structures with Key Injection
As highlighted in Beighton et al.’s paper [2], if the ﬁlter function of a Grain-like
structure does not feature a monomial that takes inputs only from the NFSR
and does not divide any other monomial, the structure is vulnerable to a divide
and conquer attack which ﬁrst targets the LFSR in an algebraic attack and then
determines the NFSR contents.
This idea extends to the case where the secret key is used to update the
NFSR, as the LFSR still runs autonomously.
4.1
Generalised Algebraic Attack Algorithm
We present here the generalised algebraic attack for Grain-like structures with
key injection. This attack uses a divide and conquer strategy. We ﬁrst target the
LFSR and recover the LFSR initial state. The NFSR is then targeted, with par-
tial NFSR initial state recovery possible. From this point, we can simultaneously
determine the key bits and the remaining NFSR bits.
Recovering the LFSR. Consider a keystream generator that produces an
output bit at each time step by:
z = LS + fS + fBS.
(4)
That is, NFSR state bits are only used nonlinearly and only in fBS. Every
monomial in fBS will contain both NFSR bits and LFSR bits. Thus, using the
idea of annihilators presented by Courtois and Meier [7], we may multiply Eq. 4
by a low degree function containing only LFSR bits that will eliminate fBS.
We denote this function as ABS, and consider it to be a “partial annihilator”
in as much as ABS only annihilates certain monomials. Note that the degree of
the NFSR bits in fBS does not aﬀect the ability to annihilate the monomials
containing bits from the NFSR.
Therefore Eq. 4 can be rewritten as
zABS = ABS(LS + fS),
(5)
which is an equation containing only LFSR initial state bits. The degree of the
system of equations built using Eq. 5 will be at most deg(ABS) + deg(fS). Note,
however, that the right hand side of Eq. 5 contains only initial state bits from the
LFSR. This means that fast algebraic attack methods can be performed in the
precomputation phase of the attack to reduce the degree of unknown variables
in the system from deg(ABS) + deg(fS) to deg(ABS).
There are several other cases where the attack works. For convenience we
use only the simplest example here to illustrate the ﬁrst phase of the attack and
refer the reader to Beighton et al.’s paper [2] for a detailed discussion of the
other cases.

98
M. Beighton et al.
The structure of a system of equations built in this way allows for the fast
algebraic attack techniques highlighted in Sect. 3.2 to be applied. That is, given
access to approximately
n
d

bits of output (where n is the size of the LFSR
and d is the algebraic degree of the system relating LFSR initial state bits to
observable output bits), a precomputation phase can be performed that allows a
new system of equations to be built of degree e < d, where e is the degree of ABS.
This precomputation phase has a complexity of O(
n
d

log
n
d

+n
n
d

). The initial
state of the LFSR can then be recovered in the online phase of the attack by
observing approximately
n
d

bits of output with complexity O(
n
d
n
e

+
n
e
ω),
where ω is the Guassian elimination exponent ω ≈2.8.
Recovering the NFSR and the Key. Once the LFSR initial state is recov-
ered, every future LFSR state bit will be known, as the LFSR is autonomous
during keystream generation. The next stage is to recover the NFSR initial state.
In doing so, we will simultaneously recover the key.
Since the key is used to update the state of the NFSR, recovering the NFSR
state at one point in time without knowing the key is not enough to determine
the NFSR state at other points in time. As a result, the key must also be taken
into account. To begin, however, we will consider the idea of recovering the NFSR
state by itself and then expand this approach to recover both the NFSR state
and the key.
Consider the example ﬁlter function used to produce the keystream bit
z = x1 + x4x5 + x0x3 + x0x1x2 + x2x3x4x5,
(6)
where x0, x1, x2, x3 are from the LFSR and x4, x5 are from the NFSR. Since the
LFSR is known, each output bit will have the form
z = αx4x5 + β,
where α and β may be 0 or 1, respectively.
Clearly, when α = 0 no information about the initial state of the NFSR is
leaked. We must therefore utilise the case where α = 1. If z = x4x5 and z = 1,
then we know x4 = x5 = 1. Likewise if z = x4x5 + 1 and z = 0, then we
know x4 = x5 = 1. Once we have recovered these state bits, we may then look
to equations where z = x4x5 and z = 0, but for which we know either x4 or
x5 equals 1. We would then know that the unknown state bit is equal to zero.
Similarly for the case where z = x4x5 + 1 and z = 1. Continuing in this way, we
may be able to recover n consecutive bits of the NFSR.
For certain ﬁlter functions it may not be possible to recover n consecutive
state bits. In this case, the partially recovered initial state reduces the exhaustive
search required to recover the correct initial state of the NFSR. For instance,
suppose m bits of the NFSR can be recovered. This leaves 2n−m possible can-
didates for the correct NFSR initial state which, for m > 0, is better than
exhaustively searching the entire register. Each candidate can be used (together
with the known LFSR initial state) to produce output. The candidate which

Key Recovery Attacks on Grain-Like Keystream Generators
99
produces the correct output sequence can be assumed to be the correct initial
state.
As stated earlier, because the key is used to update the state of the NFSR,
recovering the state of the NFSR at a single point in time is not suﬃcient to
determine the state at any other point in time. However, as we now show, the
NFSR state recovery process discussed above may be adapted to recover the
NFSR state and the secret key simultaneously by considering a longer sequence
of NFSR bits. We consider the sequence of bits that pass through the NFSR as
the XOR of some NFSR feedback bits and the key. We thus have,
bt+n = g(Bt) + kt mod |K|
= b′
t+n + kt mod |K|.
(7)
Thus, given n+|K| consecutive NFSR state bits, the key can easily be recovered.
The goal is therefore to recover n + |K| consecutive bits of the NFSR, or to
recover as much as is possible and then exhaustively search the rest. For instance,
suppose m bits of the NFSR sequence can be recovered. This leaves 2(n+|K|)−m
possible candidates for the correct NFSR sequence which, for m > n, is better
than exhaustively searching the key. Each candidate can be used (together with
the known LFSR initial state) to produce further NFSR states and thus output.
The candidate which produces the correct output sequence can be assumed to
be the correct sequence. From the sequence the key can quickly be recovered.
5
Algebraic Attack on a Modiﬁed Version of Plantlet
We now mount an algebraic attack on adapted versions of the stream cipher
Plantlet with a modiﬁed ﬁlter function. We show that even with the key bits
used to update the NFSR state, the success of the attack is determined only by
the choice of ﬁlter function.
5.1
The Plantlet Stream Cipher
Plantlet is a contemporary stream cipher that uses a very small internal state.
The keystream generator for Plantlet consists of a LFSR and a NFSR, together
with a nonlinear Boolean function that takes inputs from both registers.
Initialisation. Plantlet takes as input a 80-bit secret key and 90-bit IV. In
initialisation, the NFSR and the LFSR are 40 bits and 60 bits in length. The
keystream generator is loaded by ﬁlling the NFSR with 40 IV bits. The remaining
50 bits of the IV are loaded into the LFSR, which is then padded with a constant.
At each time step the LFSR is updated using the linear update function ℓas
follows
st+59 = ℓ(St) = zt + st + st+14 + st+20 + st+34 + st+43 + st+54.
(8)

100
M. Beighton et al.
The NFSR is updated at each time step using the nonlinear update function g
as follows
bt+39 = g(Bt) = st + ztkt mod 80 + c4
t + bt + bt+13 + bt+19 + bt+35 + bt+39
+ bt+2bt+25 + bt+3bt+5 + bt+7bt+8 + bt+14bt+21 + bt+16bt+18
+ bt+22bt+24 + bt+26bt+32 + bt+33bt+36bt+37bt+38
+ bt+10bt+11bt+12 + bt+27bt+30bt+31,
(9)
where c4
t is the fourth least-signiﬁcant-bit of the modulo 80 counter. This counter
is public so, for convenience, it is easier to combined the XOR of the counter
variable and the key variable into one variable as follows
k′
t = kt mod 80 + c4
t.
(10)
Keystream is not produced in initialisation. Instead, the output of the ﬁlter
function is used to update the state. Output is produced using the following
ﬁlter function
zt = st+30 + bt+1 + bt+6 + bt+15 + bt+17 + bt+23 + bt+28 + bt+34 + bt+4st+6
+ st+8st+10 + st+32st+17 + st+19st+23 + bt+4st+32bt+38.
(11)
Keystream Generation. At the end of initialisation, the LFSR is increased
by one bit and the new stage is loaded with a one. Thus, in keystream generation
Plantlet consists of a 40-bit NFSR and a 61-bit LFSR. This adjustment to the
LFSR is made in order to avoid the possibility of the LFSR being initialised to
the all zero state.
The update functions used to update the state of the LFSR and the NFSR
during keystream generation are identical to those used in initialisation; however,
the output function is now used to generate keystream and so it is not used to
update the state.
5.2
Modiﬁed Version of Plantlet
We introduce a modiﬁed version of the Plantlet stream cipher, where we replace
any independent linear term taken from the NFSR by the corresponding term
in the LFSR. That is, the ﬁlter function f(B, S) remains the same, except that
monomials appearing only in LB are replaced by monomials in LS with the same
indices. Note that we denote the modiﬁed version of Plantlet by appending the
suﬃx −m.
Table 1 highlights the diﬀerences between the original and modiﬁed versions.
Table 1. Modiﬁcations to linear combinations in Plantlet.
Original linear combination
Modiﬁed linear combination
bt+1 + bt+6 + bt+15 + bt+17 + bt+23 + bt+28 + bt+34 st+1 + st+6 + st+15 + st+17 + st+23 + st+28 + st+34

Key Recovery Attacks on Grain-Like Keystream Generators
101
5.3
Stage 1: LFSR Recovery
In this section we apply the algorithm from Sect. 4. The theoretical data and
computational complexity requirements to recover the LFSR initial state is sum-
marised in Table 2. In Sect. 6, we provide experimental results for the modiﬁed
version of Plantlet.
At time t = 0 an output bit in Plantlet-m is produced as follows:
z0 =s1 + s6 + s15 + s17 + s23 + s28 + s34 + b4s6 + s8s10 + s32s17 + s19s23 + b4s32b38
Multiplying this equation by (s6 + 1)(s32 + 1) gives
(s6 + 1)(s32 + 1)z0 = s1s6s32 + s1s6 + s1s32 + s1 + s6s15s32 + s6s15 + s6s17s32
+ s6s17 + s6s23s32s19 + s6s23s32 + s6s23s19 + s6s23
+ s6s28s32 + s6s28 + s6s34s32 + s6s34 + s6s8s10s32
+ s6s8s10 + s15s32 + s15 + s17s32 + s17 + s23s32s19
+ s23s32 + s23s19 + s23 + s28s32 + s28 + s34s32
+ s34 + s8s10s32 + s8s10
(12)
where the right hand side of the equation contains only LFSR initial state bits
and is of degree 4. Thus, by observing at least
61
4

keystream bits, fast algebraic
techniques may be applied in the precomputation phase of the attack to reduce
the overall degree of the system to the degree of the left hand side (which is of
degree 2 in the unknown LFSR initial state bits) [6].
Table 2. Resource requirements for recovering the LFSR of modiﬁed Plantlet.
Precomputation phase
Degree before fast algebraic techniques 4
Complexity
O(223)
Degree after fast algebraic techniques
2
Online phase
Data
219
Complexity
O(232)
5.4
Stage 2: NFSR Recovery and Key Recovery
Once the LFSR initial state is recovered, the output function will contain only
unknown state bits from the NFSR. As described in Sect. 4.1, to be able to pre-
dict the NFSR state sequence we must know at least |NFSR| + |K| consecutive
bits of the NFSR sequence. For Plantlet, at least 40 + 80 = 120 consecutive bits
of NFSR sequence is required to predict the NFSR sequence. Note that if 120
bits of NFSR sequence is known, the key can easily be calculated. Thus, the goal
is to recover 120 bits of consecutive NFSR bits.

102
M. Beighton et al.
The data requirement for this stage will utilise the data collected for LFSR
state recovery. The computational complexity to partially recover the NFSR
sequence is considered to be negligible [4]. The number of NFSR sequence bits
recovered over a 120-bit period through application of this method is hard to
estimate and will vary depending on the particular key and IV used. However,
some guidance based on experimental results is provided in Sect. 6.2. Due to the
low computational complexity of partial NFSR sequence recovery we provide
experimental results for this in the next section.
At time t = 0 an output bit in Plantlet-m is produced by:
z0 = st+1 + st+6 + st+15 + st+17 + st+23 + st+28 + st+34 + bt+4st+6
+ st+8st+10 + st+32st+17 + st+19st+23 + bt+4st+32bt+38
This function is linear in the NFSR bit b4 and nonlinear in the NFSR bits b4
and b38. At each time step we have:
zt = αb4+t + βb4+tb38+t + ω,
where α, β and ω can be 0 or 1, respectively.
When α = 0, β = 1, and ω+z = 1, two NFSR sequence bit will be recovered.
When α = 1 and β = 0, an NFSR initial state bit will be recovered. Finally,
when α = 1, β = 1, and ω + z = 1, two NFSR sequence bits will be recovered.
This can be used for simple partial state recovery of the NFSR. The remaining
stages of the 120 NFSR sequence can then be found through exhaustive search.
An estimate of the average exhaustive search requirement for modiﬁed Plantlet
is provided in Table 3 of Sect. 6.2.
6
Experimental Simulations
We have performed computer simulations of our divide and conquer attack,
applying it to our modiﬁed version of Plantlet, to demonstrate proof of concept.
The details of the simulation setup and results are provided in the following
sections. We also provide experimental results in Sect. 6.2 for the partial NFSR
sequence recovery of Plantlet; this is possible because of the low time complexity
required to partially recover. The details for the structure of modiﬁed Plantlet
are provided in Sect. 5.
6.1
Experimental Approach
For each simulation, a random key together with random NFSR and LFSR states
were produced. Output from modiﬁed Plantlet was then produced. The attack
from Sect. 4 was then applied. The remaining NFSR sequence bits were then
exhaustively searched. Each sequence candidate was used to produce output,
which was checked against the correct output sequence. A candidate that pro-
duced the correct output was considered the correct state sequence state. Using

Key Recovery Attacks on Grain-Like Keystream Generators
103
this sequence, the key was recovered. The computed key, NFSR and LFSR was
then checked against the correct key, NFSR and LFSR.
The code used for the simulations was written using the SageMath software
package [25] and all calculations were performed using QUT’s High Performance
Computing facility. We used a single node from the cluster with an Intel Xeon
core capable of 271 TeraFlops.
6.2
Results on Modiﬁed Plantlet
In precomputation, the initial system of equations was built, the linear depen-
dency was found and the reduced system of equations was built. For modiﬁed
Plantlet, approximately 220 bits of output were used. The majority of the com-
putational complexity required for the precomputation comes from applying the
linear dependency to produce the reduced system of equations. On average, pre-
computation was completed in 10 h.
A total of 10 simulations were performed. In every simulation the full LFSR
initial state was recovered. Each simulation for the modiﬁed version required on
average 30 s to recover the LFSR initial state.
For each trial, partially recovering the required 120-bit NFSR sequence took
approximately 2.5 h. Table 3 provides a tally (across the 10 simulations) of how
many times a certain number of state bits were recovered from the NFSR
sequence. For each simulation, the full available keystream was used. That is,
the NFSR sequence was partially recovered using 219 bits of keystream. We see
from Table 3 that on average, 67 bits were recovered for the NFSR sequence.
Table 3. Distribution table for NFSR sequence bits recovered over 120-bit windows
using 100 simulations for modiﬁed Plantlet.
No. bits recovered 0 . . . 64 65 66 67 68 69 . . . 120
Frequency
0 . . . 0
1
4
2
2
1
. . . 0
The remaining 53 bits required to complete the 120-bit NFSR sequence could
then be recovered by exhaustive search and used to produce output. Recovery
of these remaining NFSR bits would then allow the key to be determined. This
portion of the simulation was not performed due to limited resources.
7
Discussion
Our experimental simulations support the theoretical model for our key recovery
attack on modiﬁed Plantlet. The pre-computation stage of the algebraic attack
is essential for recovery of the LFSR state and is the most time-consuming part
of the process, but only needs to be done once. This took ten hours in our trial.
In the online phase, a divide and conquer approach targeting the LFSR achieved

104
M. Beighton et al.
complete recovery of the LFSR state in approximately 30 s with 100% success.
Following this, we used a 120-bit sliding window on the NFSR state and partially
recovered this window; on average we recovered 67 of these 120 bits. Guessing
the remaining 53 bits and checking for consistency with observed keystream then
allowed us to recover the key bits. The complexity of this guess and determine
stage dominates the attack complexity but is clearly signiﬁcantly less complex
than exhaustive key search.
The use of key injection in the design made it possible to perform this key
recovery attack without requiring any consideration of the initialisation process.
That is, the initialisation is irrelevant to the security provision against these
algebraic attacks. In fact, security against these attacks depends solely on the
combination of the selected output function and the positions of its input bits
within the two registers. This answers the open question from [1] of whether
key injection provides increased security to enable reduced register sizes for
lightweight stream cipher designs. While this approach may help avoid time-
memory trade-oﬀattacks, the generic structure is not robust: other attacks are
possible, as we have shown.
Based on the nature of our successful attack on modiﬁed Plantlet, the fol-
lowing design guideline is seen to be important to the security of any keystream
generator which uses a Grain-like structure with key injection:
• The output function for any such cipher should contain multiple bits taken
linearly from the NFSR, with none of these bits involved in nonlinear terms
of the output function that also contain bits from the LFSR.
Note that this is precisely the feature which protects the existing version of
Plantlet from our attack. This guideline may need to be expanded if other types
of attack on this structure are also found to be successful.
The output function of Sprout is identical to that of Plantlet, so the pub-
lished version of Sprout is also protected against our attack. However, a similar
modiﬁcation of this output function would again allow our attack to recover the
initial contents of Sprout’s LFSR. But recovering the NFSR initial state and
the key is more complex for Sprout, since the key bits of Sprout are fed into
the NFSR conditionally. A quick estimate based on our experimental results for
Plantlet suggests that the exhaustive search cost after partial NFSR recovery in
this case would exceed the cost of exhaustively searching the key bits, making
this attack unviable.
8
Conclusion
In this paper, we have considered the security of keystream generators using a
Grain-like structure with key injection. From the above discussion, it is clear
that the security of keystream generators using this design depends critically on
the choice of the output function during keystream generation. Designers who
employ this design approach should pay careful attention to the combination of
the function used and the location of the input taps which feed it.

Key Recovery Attacks on Grain-Like Keystream Generators
105
Ciphers of this type were designed speciﬁcally to avoid time-memory trade-
oﬀattacks, but they are not necessarily secure against other emerging attacks,
such as the algebraic attack we have demonstrated here. In itself, this structure
cannot be considered to provide a robust generic design for lightweight keystream
generators. Indeed, the designer of a new cipher must be cautious about security
implications when adding components to existing structures and should evaluate
the modiﬁed design against all possible types of attacks.
A
Appendix: Algorithms
A.1
Algorithm for NLFG Algebraic Attack
Precomputation phase:
Step 1. Use f(S0) = y0 to relate initial state bits (s0, s1, . . . , sn−1) to observed
output bit y0.
Step 2. Multiply f by a function h (if applicable) to reduce overall degree to d.
Step 3. Clock forward using f(St) = yt to build a system of equations of constant
algebraic degree, applying the linear update as required.
Online phase:
Step 4. Substitute observed output bits {yt}∞
t=0 into the system of equations.
Step 5. Solve the system of equations by linearisation, to recover S0
=
s0, s1, . . . , sn−1.
In the online phase of this attack, the initial state of the LFSR can be recovered
if approximately
n
d

bits of output are known. The attack has a computational
complexity of O(n
n
d

+
n
d
ω), where d is the degree of the system and ω is the
Guassian elimination exponent ω ≈2.8 [7]. If the output requirement cannot
be met, it may be possible to solve the system by applying other methods for
solving simultaneous equations, such as Gr¨obner bases or the XL algorithm [5].
A.2
Algorithm for Fast Algebraic Attack
The precomputation phase is similar to a regular algebraic attack, with Step 3
replaced by three steps (3a, 3b and 3c) as follows.
Step 3a. Identify the combination of equations that will eliminate monomials of
degree e to d in the initial state bits.
Step 3b. Use this linear dependency to build a new general equation.
Step 3c. Use this general equation to build a system of equations of degree e in
the initial state bits.
The online phase is identical to the online phase of a regular algebraic attack
(but with reduced complexity).
When the Berlekamp-Massey algorithm is used to ﬁnd the linear depen-
dency, the pre-computation phase of the attack has a computational complexity

106
M. Beighton et al.
of O(
n
d

log(
n
d

)) [6]. The initial state of the LFSR can be recovered in the
online phase of the attack by observing approximately
n
d

bits of output with a
computational complexity of O(
n
d
n
e

+
n
e
ω), where d is the degree of fh, e is
the degree of h and ω ≈2.8 [6].
Note that at ﬁrst glance the online complexities for an algebraic attack and
a fast algebraic attack look similar. However, when n is much larger than d, as
is the case with registers used in practice,
n
d
ω is much larger than
n
d
n
e

and
n
e
ω. Thus, by reducing the degree from d to e, the complexity of the online
phase is drastically reduced for registers of practical size.
A.3
Algorithm for LF-NFSR Algebraic Attack
Precomputation phase:
Step 1. A system of equations is developed using the linear ﬁlter function to
represent every state bit as a linear combination of a subset of the initial state
bits and some output bits. We denote this system of equation by system L.
Step 2. A second system of equations is developed using the nonlinear update
function g to represent update bits as a nonlinear combination of a subset
of initial state bits. We denote this system by system G. Substitutions are
made for state bits in system G using system L where applicable to reduce
the number of unknown state variables while keeping the degree of system G
constant.
Step 3. The two systems are combined by aligning the equations from each
system that represent the same state bit. The resulting system contains only
initial state bits and observed output bits. We denote this system as system
L + G.
Online phase:
Step 4. Substitute observed output bits {yt}∞
t=0 into the system of equations
Step 5. Solve the system of equations by linearisation.
For certain update functions a reduction function of g, say h, may be used to
reduce the overall degree of the system. If the degree of gh is d, then the overall
system will be of degree at most d. The initial state of the LF-NFSR can be
recovered in the online phase of the attack by observing approximately
n
d

bits
of output with a computational complexity of O(n
n
d

+
n
d
ω), where d is the
degree of the system and ω ≈2.8 [3]. Note that fast algebraic techniques are not
applicable to LF-NFSRs.
References
1. Armknecht, F., Mikhalev, V.: On lightweight stream ciphers with shorter internal
states. In: Leander, G. (ed.) FSE 2015. LNCS, vol. 9054, pp. 451–470. Springer,
Heidelberg (2015). https://doi.org/10.1007/978-3-662-48116-5 22

Key Recovery Attacks on Grain-Like Keystream Generators
107
2. Beighton, M., Bartlett, H., Simpson, L., Wong, K.K.H.: Algebraic attacks on Grain-
like keystream generators. In: Park, J.H., Seo, S.H. (eds.) ICISC 2021. LNCS, vol.
13218, pp. 241–270. Springer, Cham (2022). https://doi.org/10.1007/978-3-031-
08896-4 12
3. Berbain, C., Gilbert, H., Joux, A.: Algebraic and correlation attacks against lin-
early ﬁltered non linear feedback shift registers. In: Avanzi, R.M., Keliher, L., Sica,
F. (eds.) SAC 2008. LNCS, vol. 5381, pp. 184–198. Springer, Heidelberg (2009).
https://doi.org/10.1007/978-3-642-04159-4 12
4. Berbain, C., Gilbert, H., Maximov, A.: Cryptanalysis of Grain. In: Robshaw, M.
(ed.) FSE 2006. LNCS, vol. 4047, pp. 15–29. Springer, Heidelberg (2006). https://
doi.org/10.1007/11799313 2
5. Courtois, N.T.: Higher order correlation attacks, XL algorithm and cryptanalysis
of Toyocrypt. In: Lee, P.J., Lim, C.H. (eds.) ICISC 2002. LNCS, vol. 2587, pp.
182–199. Springer, Heidelberg (2003). https://doi.org/10.1007/3-540-36552-4 13
6. Courtois, N.T.: Fast algebraic attacks on stream ciphers with linear feedback. In:
Boneh, D. (ed.) CRYPTO 2003. LNCS, vol. 2729, pp. 176–194. Springer, Heidel-
berg (2003). https://doi.org/10.1007/978-3-540-45146-4 11
7. Courtois, N.T., Meier, W.: Algebraic attacks on stream ciphers with linear feed-
back. In: Biham, E. (ed.) EUROCRYPT 2003. LNCS, vol. 2656, pp. 345–359.
Springer, Heidelberg (2003). https://doi.org/10.1007/3-540-39200-9 21
8. Englund, H., Johansson, T.: A new simple technique to attack ﬁlter generators
and related ciphers. In: Handschuh, H., Hasan, M.A. (eds.) SAC 2004. LNCS, vol.
3357, pp. 39–53. Springer, Heidelberg (2004). https://doi.org/10.1007/978-3-540-
30564-4 3
9. Faugere, J.C., Ars, G.: An algebraic cryptanalysis of nonlinear ﬁlter generators
using Gr¨obner bases. Report, INRIA (2003)
10. Forr´e, R.: A fast correlation attack on nonlinearly feedforward ﬁltered shift-register
sequences. In: Quisquater, J.-J., Vandewalle, J. (eds.) EUROCRYPT 1989. LNCS,
vol. 434, pp. 586–595. Springer, Heidelberg (1990). https://doi.org/10.1007/3-540-
46885-4 56
11. Gammel, B.M., G¨ottfert, R.: Linear ﬁltering of nonlinear shift-register sequences.
In: Ytrehus, Ø. (ed.) WCC 2005. LNCS, vol. 3969, pp. 354–370. Springer, Heidel-
berg (2006). https://doi.org/10.1007/11779360 28
12. Goli´c, J.D., Salmasizadeh, M., Simpson, L., Dawson, E.: Fast correlation attacks
on nonlinear ﬁlter generators. Inf. Process. Lett. 64(1), 37–42 (1997)
13. Hell, M., Johansson, T., Maximov, A., Meier, W.: The Grain family of stream
ciphers. In: Robshaw, M., Billet, O. (eds.) New Stream Cipher Designs. LNCS,
vol. 4986, pp. 179–190. Springer, Heidelberg (2008). https://doi.org/10.1007/978-
3-540-68351-3 14
14. Hell, M., Johansson, T., Maximov, A., Meier, W.: A stream cipher proposal: Grain-
128. In: 2006 IEEE International Symposium on Information Theory, pp. 1614–
1618. IEEE (2006)
15. Hell, M., Johansson, T., Meier, W.: Grain: a stream cipher for constrained envi-
ronments. Int. J. Wirel. Mob. Comput. 2(1), 86–93 (2005)
16. Hell, M., Johansson, T., Meier, W.: Grain-128a: a new version of Grain-128 with
optional authentication. Int. J. Wirel. Mob. Comput. 5, 48–59 (2011)
17. Hell, M., Johansson, T., Meier, W., S¨onnerup, J., Yoshida, H.: Grain-128AEAD -
a lightweight AEAD stream cipher. NIST Lightweight Cryptography Competition
(2019). https://csrc.nist.gov/Projects/lightweight-cryptography/ﬁnalists

108
M. Beighton et al.
18. Hong, J., Sarkar, P.: New applications of time memory data tradeoﬀs. In: Roy,
B. (ed.) ASIACRYPT 2005. LNCS, vol. 3788, pp. 353–372. Springer, Heidelberg
(2005). https://doi.org/10.1007/11593447 19
19. Katz, J., Menezes, A.J., Van Oorschot, P.C., Vanstone, S.A.: Handbook of Applied
Cryptography. CRC Press (1996)
20. Massey, J.: Shift-register synthesis and BCH decoding. IEEE Trans. Inf. Theory
15(1), 122–127 (1969)
21. Meier, W., Staﬀelbach, O.: Fast correlation attacks on certain stream ciphers. J.
Cryptol. 1(3), 159–176 (1989)
22. Mikhalev, V., Armknecht, F., M¨uller, C.: On ciphers that continuously access the
non-volatile key. IACR Trans. Symmetric Cryptol. 52–79 (2016)
23. Millan, W.: Analysis and design of Boolean functions for cryptographic applica-
tions. Ph.D. Thesis, Queensland University of Technology (1997)
24. Siegenthaler,
T.:
Cryptanalysts
representation
of
nonlinearly
ﬁltered
ML-
sequences. In: Pichler, F. (ed.) EUROCRYPT 1985. LNCS, vol. 219, pp. 103–110.
Springer, Heidelberg (1986). https://doi.org/10.1007/3-540-39805-8 12
25. Stein, W., Joyner, D.: Sage: system for algebra and geometry experimentation.
ACM Bull. 39(2), 61–64 (2005)

Related-Cipher Attacks: Applications
to Ballet and ANT
Yongxia Mao1,2,3, Wenling Wu1,3(B), Yafei Zheng1,2,3, and Lei Zhang1,3
1 Trusted Computing and Information Assurance Laboratory, Institute of Software
Chinese Academy of Sciences, Beijing 100190, China
{yongxia2018,wenling,zhengyafei,zhanglei}@iscas.ac.cn
2 State Key Laboratory of Cryptology, Beijing 100878, China
3 University of Chinese Academy of Sciences, Beijing 100049, China
Abstract. Quite a lot of block ciphers proposed in recent years are fam-
ilies of ciphers that conveniently support multiple block lengths and key
lengths. The essential security requirements for a family of block ciphers
are: (1) Each cipher instance from family is secure; (2) Cipher instances
do not endanger each other’s security, namely, by one or more cipher
instances, other instances cannot be predicted. However, traditional
cryptanalysis methods always assess the security of a special member
of the family cipher, such as diﬀerential cryptanalysis, linear cryptanal-
ysis, integral cryptanalysis. Related-cipher attacks focus on the security
between cipher instances. This paper researches the security of Ballet-128
and ANT-128 against related-cipher attacks. Since their key schedules
do not rely on the round number of encryption, we consider the related-
cipher attack with equivalent keys by limiting the 256-bit key space. As
a result, we recover the secret key of the full Ballet-128/128 with just one
chosen plaintext pairs and one call of Ballet-128/128 and Ballet-128/256,
which means Ballet-128 is insecure against related-cipher attack. For
ANT-128, we show that there exist at most 6-round related-cipher distin-
guishers between ANT-128/128 and ANT-128/256, and launch a 9-round
key-recovery attack on ANT-128/128 based on a 6-round related-cipher
distinguisher with the time complexity about 260.9.
Keywords: Related-cipher attack · Block cipher family · Key
schedule · Key recovery
1
Introduction
In recent years, a family of block ciphers that support multiple block lengths and
key lengths is a major feature of the newly designed block cipher. For example,
KATAN and KTANTAN [1], Simon and Speck [2], Simeck [3], and LowMC [4]
When evaluating the security of a cryptographic algorithm family, the evaluator
often only consider the security of a single algorithm member.
The essential security requirements for a family of block ciphers are: (1)
Each cipher instance of family is secure; (2) Cipher instances do not endanger
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 109–123, 2023.
https://doi.org/10.1007/978-3-031-35486-1_6

110
Y. Mao et al.
each other’s security, namely, by one or more cipher instances, neither the corre-
sponding key can be recovered, nor other instances can be predicted. Diﬀerential
analysis [5], linear analysis [6], impossible diﬀerential [7] and integral analysis [8]
etc. are all aimed at the ﬁrst security requirement of the cipher family. Attacks
focusing on the second security requirement of the cipher family are collectively
referred to as related-cipher attacks.
Diﬀerential analysis, linear analysis, impossible diﬀerential analysis, integral
analysis and meet-in-the-middle analysis [9] are traditional cryptanalysis meth-
ods for block ciphers. In terms of evaluating a cipher family, we always pay atten-
tion to the security of each algorithm instance, and regard the single member’s
security as the ability of entire cipher family against these attacks. Obviously,
it is insuﬃcient. When considering the application environments, the security
requirements of cipher families will be higher. For example, when developing
cryptographic products, developers usually implant the entire algorithm family
into the chip and call a speciﬁc one when using them; or for designing a mod-
ule that integrates multiple functions, the same underlying algorithm is used.
Therefore, the security of algorithms may aﬀect each other. If we know one of
algorithms’ secret key, the other algorithms’ or functions’ key may be predicted
correctly in the system. Under these circumstances, the whole system’s security
is not equivalent to the security of individual primitive, and we need to further
research the security impact between cryptographic algorithms. Related-cipher
attacks and related-key attacks [10] are right analysis methods focusing on the
security impact between cipher instances. Therefore, it is particularly necessary
to evaluate related-cipher attacks on the cipher families.
The early block cipher AES [11] and SQUARE [12] are also ciphers with
multiple block lengths and key sizes. Although many related research results on
AES have been published [13–15], most of them focus on the security analysis
of AES-128/128, a speciﬁc instance of AES. In 2002, Wu Hongjun [16] pro-
posed an attack on related ciphers of AES-128/128 and AES-128/256 under the
same key, and pointed out a new AES key schedule proposed at ACISP 2002
is weaker than the original one under this attack. In 2005, Jaechul Sung and
others [17] extended the key form of related-cipher attacks to “semi-equivalent
keys”, and applied this attack to the block ciphers ARIA, SC2000. Since typ-
ical related-cipher attack is more diﬃcult to apply as the diﬀerence of round
numbers becomes bigger, they combined related-cipher attack with diﬀerential
cryptanalysis, linear cryptanalysis, higher-order diﬀerential cryptanalysis and so
on, to attack SAFER++, CAST-128 and DEAL. More recently, Shao Zengyu
and Ding Lin [18] applied related-cipher attack to the stream cipher Salsa20, and
claimed that if a secret key is used in Salsa20/12 and Salsa20/8, 256-bit secret
keys can be recovered with a time complexity of 2224, and then Ding Lin [19]
further reduced the cost of this attack by changing the initial IV and repeatedly
using related-cipher attacks. This attack also can be applied to protocols. In
2004, Kohno [20] used this attack to analysis WinZIP’s encryption scheme, and
found that the encryption way may leak information about the encrypted ﬁles
when changing the cipher used in WinZip archives.

Related-Cipher Attacks: Applications to Ballet and ANT
111
Ballet [21] and ANT [22] are the participating ciphers in the National Crypto-
graphic Algorithm Design Competition (NCADC) [23] organized by the Chinese
Association for Cryptologic Research in 2018. Their block lengths/key lengths
support 128/128, 128/256, 256/256. During the competition, evaluators evalu-
ated the security of Ballet and ANT. For Ballet-128, with the help of automated
modeling technology, the eﬀective diﬀerential paths do not exceed 26 rounds, the
eﬀective linear characteristics do not exceed 25 rounds, the longest impossible
diﬀerential path and integral distinguishers are both 7 rounds, and the longest
zero-correlation linear paths is 6 rounds. With the help of SAT/SMT technique,
ANT-128 does not have eﬀective diﬀerential and linear characteristics for more
than 27 rounds, does not have integral distinguishers for more than 16 rounds
by searching bit-level division trails, and only have impossible diﬀerential routes
for up to 9 rounds and zero-correlation linear paths for up to 10 rounds can be
retrieved. The evaluation result have shown that the two cipher algorithms are
secure enough against general cryptanalysis methods.
Our Contributions. In this paper, we research the security of Ballet and ANT
against related-cipher attacks. At ﬁrst, for Ballet-128/128 and Ballet-128/256,
which are two family members of Ballet, we capture a property (Property 1)
that their round keys satisfy a relation since their key schedules are similar and
independent on total round numbers. Depending on the relation, we ﬁnd a high-
round distinguisher between Ballet-128/128 and Ballet-128/256, and then launch
a key-recovery attack on full Ballet-128/128. As a result, Ballet-128 is insecure
against related-cipher attack. Then, for ANT-128/128 and ANT-128/256, which
are two family members of ANT, we present a 6-round distinguisher between
them, launch a 9-round key-recovery attack on ANT-128/128 based on the 6-
round distinguisher, and show that the non-existence of 7-round related-cipher
distinguishers under the condition of equivalent keys.
Organization. The rest of the paper is organized as follows. Section 2 introduces
related-cipher attacks and block ciphers we will attack. Section 3 presents the
related-cipher attack against Ballet-128. Section 4 evaluates the security of ANT-
128 under the related-cipher attack. Finally, the paper ends in Sect. 5 with a
conclusion.
2
Preliminaries
In this section, we are going to recall related-cipher attack with taking SQUARE
as an example in [16], and then brieﬂy present our target block ciphers.
2.1
Related-Cipher Attack
In 2002, Wu Hongjun [16] formally introduced the concept of related-cipher
attack, and considered the related ciphers as block ciphers with the same round
function but with diﬀerent round numbers. Consider two related block ciphers

112
Y. Mao et al.
with diﬀerent round numbers, r and (r + Δr) respectively. If a key is used in
these two ciphers to encrypt the same message, the attack can be carried out on
the Δr-round cipher. For this Δr-round cipher, the plaintext is the ciphertext
of the r-round cipher and the ciphertext is that of the (r + Δr)-round cipher.
The key can be determined easily for small Δr. Taking the attack on SQUARE
with ﬂexible round number as an example.
SQUARE is a iterative block cipher. As a safety margin, the designers ﬁxed
the number of rounds to eight. However, the designers also allow conservative
users to increase the number of rounds in a straight way. Let SQUAREr and
SQUAREr+Δr be two block ciphers with encrypting r rounds and (r + Δr)
rounds.
Denote the ith round function of SQUARE as: ρ[ki] = σ[ki]◦π◦γ◦θ, where ki
is the ith round key, θ is a linear transformation, γ is a nonlinear transformation,
and π is a byte permutaion. Let cr be the ciphertext of r-round SQUARE and
cr+Δr be that of (r + Δr)-round SQUARE. If cr and cr+Δr are related to the
same plaintext P, that is, cr = ρr(P) and cr+Δr = ρr+Δr(P), (cr, cr+Δr) is
denoted as one right pair. In this case, the related-cipher attack can be applied
when Δr = 1 and Δr = 2.
For two encryption algorithms, SQUAREr and SQUAREr+Δr, the attacker
randomly choose a plaintext P, and he can know the ciphertext cr and cr+Δr
by encrypting plaintext P. It means the (r + 1)-round input and (r + Δr)-round
output of SQUAREr+Δr are known. When Δr = 1, SQUAREr+Δr is reduced
to only one round and the relation cr+1 = ρ[kr+1](cr) holds. Hence, the round
key kr+1 can be calculated by
kr+1 = (π ◦γ ◦θ(cr)) ⊕cr+1.
Furthermore, other round keys of SQUARE can be deduced due to ki = g(ki−1),
where g is the key schedule. The above attack only needs one right pair. Similarly,
if Δr = 2, the round key can be determined easily from two right pairs (cr, cr+2)
by the relation
cr+2 = ρ[kr+2] ◦ρ[kr+1](cr).
Therefore, SQUARE is insecure against related-cipher attack.
From the level of ciphers, related-cipher attack concentrates on whether there
is a potential relationship between cipher instances which contributes to leaking
key information or state information. This is exactly captured and contained
in the description of related-cipher attack in the introduction. To some extent,
related-key attack and multi-key attack [24] can be also classiﬁed into the cate-
gory of related-cipher attack, because they both research the impact of security
between cipher instances where the encryption algorithms are ﬁxed.
2.2
Target Block Ciphers
In 2018, the National Cryptographic Algorithm Design Competition was orga-
nized by the Chinese Association for Cryptologic Research, and 22 block ciphers
totally entered the ﬁrst round of candidates. A common feature of them is that

Related-Cipher Attacks: Applications to Ballet and ANT
113
they all support at least three block lengths and key lengths. Finally, uBlock
[25] and Ballet won the ﬁrst prize with their excellent security and great perfor-
mances. ANT and other two ciphers won the second prize.
Ballet. Ballet is an ARX block cipher, and supports Ballet-128/128, Ballet-
128/256, Ballet-256/256 versions. The round function consists of cyclic
shift, modular addition and XOR operation, as shown in Fig. 1, where
(Xi
0||Xi
1||Xi
2||Xi
3) denotes the ith round input and (skL
i ||skR
i ) is round keys,
i = 0, 1, · · · , r −1. Denote the round function of Ballet as F = π ◦τ ◦ρ, where
ρ is the combination of rotation, modular addition and addition, τ is the round
key addition, and π is the vector permutation. The details of these transforma-
tions are shown in Fig. 1. The last round function omits the linear permutation
operation. Encryption rounds of Ballet-128/128 and Ballet-128/256 are 46 and
48 respectively. Speciﬁc key schedules are shown in Table 1, where (rkL
i ||rkR
i )
denotes the round key of Ballet-128/256, and Xi
∗, sk∗
i , rk∗
i ∈F32
2 .
Table 1. Key Schedule of Ballet-128
Key Schedule of Ballet-128/128
Key Schedule of Ballet-128/256
Master key K = k0||k1
Master key K = k0||k1||t0||t1
For 0 ≤i < r;
For 0 ≤i < r;
(skL
i ||skR
i ) = k0;
(rkL
i ||rkR
i ) = k0;
Output (skL
i ||skR
i );
Output (rkL
i ||rkR
i );
ktemp = k1;
ttemp = t1;
k1 = k0 ⊕(k1 <<< 3) ⊕(k1 <<< 5) ⊕i; t1 = t0 ⊕(t1 <<< 7) ⊕(t1 <<< 17);
k0 = ktemp
t0 = ttemp;
ktemp = k1;
k1 = k0 ⊕(k1 <<< 3) ⊕(k1 <<< 5);
k0 = ktemp;
k1 = k1 ⊕t1 ⊕i
ANT. ANT is a Feistel-network block cipher, and supports ANT-128/128,
ANT-128/256, ANT-256/256 versions. The round function Fski is composed of
AND operation, rotation and XOR operation, as shown in Fig. 2, and can be
deﬁned as
(Li+1, Ri+1) = Fski(Li, Ri) = (G0(Li <<< 3) ⊕G1(Li <<< 16) ⊕Ri ⊕ski, Li)
where 0 ≤i < r, (3, 16) are rotation parameters, G0 and G1 are nonlinear
functions that contain two layers, with a bit level of permutation in between.
Before introducing the nonlinear functions G0 and G1, some representations are
introduced as follows:
Let n = 64. Denote x0 = x0
n−1||x0
n−2|| · · · ||x0
0 as the input of G0 or G1,
and y0 = y0
n−1||y0
n−2|| · · · ||y0
0 as the ﬁrst layer output of G0 or G1. Similarly,

114
Y. Mao et al.
denote x1 = x1
n−1||x1
n−2|| · · · ||x1
0 and y1 = y1
n−1||y1
n−2|| · · · ||y1
0 as the second
layer input and output of G0 or G1, respectively. PERM represents the bit level
of permutation in G0 or G1. The symbol ⊙represents the operation AND. A
speciﬁc description of G0 and G1 is given below.
For G0: y1 = G0(x0), where the ﬁrst layer transformation is
y0
j =

(x0
j+3 ⊙x0
j+2) ⊕x0
j, j mod 4 = 0,
x0
j,
others.
for 0 ≤j < n.
the bit permutation is
x1
P ERM(j) = y0
j ,
for 0 ≤j < n.
and the second layer transformation is
y1
j =

(x1
j+3 ⊙x1
j+2) ⊕x1
j, j mod 4 = 0,
x1
j,
others.
for 0 ≤j < n.
Similarly, for G1 : y1 = G1(x0), where the ﬁrst layer transformation is
y0
j =

(x0
j+2 ⊙x0
j+1) ⊕x0
j, j mod 4 = 1,
x0
j,
others.
for 0 ≤j < n.
the bit permutation is
x1
P ERM(j) = y0
j ,
for 0 ≤j < n.
and the second layer transformation is
y1
j =

(x1
j+2 ⊙x1
j+1) ⊕x1
j, j mod 4 = 1,
x1
j,
others.
for 0 ≤j < n.
The total round number of ANT-128/128 and ANT-128/256 are 56 and 70,
respectively. Denote 2n and 4n as cipher key sizes of ANT, and key schedules
can be described as follows.
For ANT-2n/2n, cipher key K = k2n−1|| · · · ||k0 can be divided into two
words:
K1 = k2n−1|| · · · ||kn, K0 = kn−1|| · · · ||k0.
K1||K0 works as the initial state of LFSR in Fig. 4. For diﬀerent block sizes,
inputs of operation A (as shown in Fig. 3) will be divided into 8 n/8-bit vectors
X7|| · · · ||X0. During each update of the LFSR, operation A is applied to Ki+1
for 3 times. The n-bit Ki in the register will be used as the current round key
ski. Rotation parameters are (t0, t1) = (7, 1).
For ANT-2n/4n, master key K = k4n−1|| · · · ||k0 can be divided into four
words:
K3 = k4n−1|| · · · ||k3n, K2 = k3n−1|| · · · ||k2n,
K1 = k2n−1|| · · · ||kn, K0 = kn−1|| · · · ||k0.

Related-Cipher Attacks: Applications to Ballet and ANT
115
K3||K2||K1||K0 works as the initial state of LFSR in Fig. 5. During each update
of the LFSR, operation A is applied to Ki+1 for 3 times. Rotation parameters
are (t0, t1) = (7, 1).
Fig. 1. Round function of Ballet
Fig. 2. Round function of ANT
Fig. 3. operation A
Let the cipher key be K128 = k0||k1 and K256 = K3||K2||K1||K0 for ANT-
128/128 and ANT-128/256 respectively. The ith round subkey are ski and rki,
0 ≤i < r. Then, we can get
sk0 = k0, sk1 = k1,
for i ≥2, ski = ski−2 ⊕(i −1) ⊕A3(ski−1),
rk0 = K0, rk1 = K1, rk2 = K2, rk3 = K3,
for j ≥4, rkj = rkj−4 ⊕(j −3) ⊕rkj−3 ⊕A3(rkj−1).
3
Related-Cipher Attack on Ballet
3.1
Property of Ballet-128
Ballet-128 denotes the family member of Ballet with 128-bit block length, so it
contains Ballet-128/128 and Ballet-128/256. As shown in Sect. 2, key schedules
of Ballet-128 has a common construction if we regard the role of ti generated by
the branch as an operation of a simple parameter table computed in advance.
Thus, we have the following property.

116
Y. Mao et al.
Fig. 4. Key schedule of ANT-2n/2n
Fig. 5. Key schedule of ANT-2n/4n
Property 1. Let K128 = k0||k1 denote the 128-bit master key of Ballet-128/128,
ski and rki, 0 ≤i < r, denote the ith round key of Ballet-128/128 and Ballet-
128/256 respectively. If the 256-bit master key of Ballet-128/256 is K256 =
k0||k1||t0||t1, t0, t1 ∈{(0 · · · 0), (01 · · · 01), (10 · · · 10), (1 · · · 1)}, then for j ≥0,
round keys of Ballet-128/128 and Ballet-128/256 satisfy the following relation:
rk4j = sk4j, rk4j+1 = sk4j+1, rk4j+2 = sk4j+2 ⊕t0, rk4j+3 = sk4j+3 ⊕t1. (1)
Proof. Let f(x) = (x <<< 3) ⊕(x <<< 5), g(x) = (x <<< 7) ⊕(x <<< 17).
For t0, t1 ∈{(0 · · · 0), (01 · · · 01), (10 · · · 10), (1 · · · 1)}, f(t0) = g(t0) = 0, and
f(t1) = g(t1) = 0.
According to the key schedule, when j = 0, we have
rk0 = k0 = sk0,
rk1 = k1 = sk1,
sk2 = sk0 ⊕f(sk1) ⊕0,
rk2 = rk0 ⊕f(rk1) ⊕0 ⊕t0 = sk2 ⊕t0,
sk3 = sk1 ⊕f(sk2) ⊕1,
rk3 = rk1 ⊕f(rk2) ⊕1 ⊕t1 = sk1 ⊕f(sk2) ⊕1 ⊕t1 = sk3 ⊕t1.
Suppose that, when 0 ≤j < m,
rk4j = sk4j, rk4j+1 = sk4j+1,
rk4j+2 = sk4j+2 ⊕t0, rk4j+3 = sk4j+3 ⊕t1.
are all satisﬁed. It can be proved that, when j = m, Eq. (1) holds.
rk4m = rk4m−2 ⊕f(rk4m−1) ⊕(4m −2) ⊕t0
= sk4m−2 ⊕t0 ⊕f(sk4m−1 ⊕t1) ⊕(4m −2) ⊕t0
= sk4m−2 ⊕f(sk4m−1) ⊕(4m −2) = sk4m,
rk4m+1 = rk4m−1 ⊕f(rk4m) ⊕(4m −1) ⊕t1
= sk4m−1 ⊕t1 ⊕f(sk4m) ⊕(4m −1) ⊕t1 = sk4m+1,
rk4m+2 = rk4m ⊕f(rk4m+1) ⊕4m ⊕t0
= sk4m ⊕f(sk4m+1) ⊕4m ⊕t0 = sk4m+2 ⊕t0,
rk4m+3 = rk4m+1 ⊕f(rk4m+2) ⊕(4m + 1) ⊕t1
= sk4m+1 ⊕f(sk4m+2 ⊕t0) ⊕(4m + 1) ⊕t1 = sk4m+3 ⊕t1.
In summary, for any j ≥0, Eq. (1) holds by mathematical induction.

Related-Cipher Attacks: Applications to Ballet and ANT
117
3.2
Related-Cipher Attack of Ballet-128
Assume that the 128-bit key of Ballet-128/128 is K128 = k0||k1, and the 256-
bit key of Ballet-128/256 is K256 = k0||k1||0||0. Based on Property 1, we have
ski = rki, 0 ≤i < 46. The internal state value of Ballet-128/256 is the same as
Ballet-128/128 for any plaintext. Therefore, the input state of round 47 of Ballet-
128/256 can be calculated by the ciphertext of Ballet-128/128. Next, knowing
the input and output values of the last two rounds of Ballet-128/256, we can
recover the secret round key of these two rounds (as shown in Fig. 6) based on
the round transformation.
Denote the round function of Ballet-128 as F = π ◦τ ◦ρ, similar to Sect. 2.2,
where ρ is the combination of rotation, modular addition and addition, τ is the
round key addition, and π is the vector permutation of 32-bit words. The speciﬁc
attack process is described as follows.
(1) Randomly choose a plaintext X, and query the corresponding ciphertexts
SY0||SY1||SY2||SY3 and RY0||RY1||RY2||RY3 by calling the encryption algo-
rithm of Ballet-128/128 and Ballet-128/256.
(2) Calculate ρ(SY1||SY0||SY3||SY2) = Y0||Y1||Y2||Y3, then rkL
47 = Y0 ⊕RY1,
rkR
47 = Y3 ⊕RY2.
(3) Calculate ρ−1(RY0||Y0||Y3||RY3) = Z0||Z1||Z2||Z3, then rkL
46 = Z0 ⊕SY0,
rkR
46 = Z3 ⊕SY3.
(4) Due to rk46 = rkL
46||rkR
46 and rk47 = rkL
47||rkR
47, calculate the secret key
K128 = k0||k1 by the key schedule of Ballet-128.
The time complexity of (2), (3), and (4) are both negligible. The main com-
plexity of this attack is from one call to the encryption algorithm of Ballet-
128/128 and Ballet-128/256.
Fig. 6. Key recovery attack of Ballet-128/256

118
Y. Mao et al.
This result shows that Ballet-128 is vulnerable to related-cipher attack. It is
noted that increasing the round number of Ballet-128/128 and Ballet-128/256
without changing their round number diﬀerence will not improve the ability to
resist related-cipher attacks. We suggest designers should take into the total
round number account in the key schedule of Ballet.
4
Evaluation of ANT Against Related-Cipher Attack
ANT-128 denotes the version with 128-bit block size and 128-bit or 256-bit key
size, and their round keys are generated by feedback registers with diﬀerent sizes
shown in Sect. 2. Therefore, ﬁnding the right ﬁxed round key is not very simple.
Nevertheless, we still ﬁnd a distinguisher relying on some restrictions on cipher
keys of ANT-128/256.
Property 2. There exist a 6-round related-cipher distinguisher between ANT-
128/128 and ANT-128/256, if their cipher keys satisfy K0 = k0, K1 = k1,
K2 = sk2, K3 = sk3, K0 ⊕K1 ⊕K2 = 2 and K1 ⊕K2 ⊕K3 = 6.
Proof. The proof process consists of two parts. At ﬁrst, we prove that the fol-
lowing equivalent relation holds.
ski = rki, 0 ≤i ≤5
(2)
From K0 = k0, K1 = k1, K2 = sk2, K3 = sk3, it is ture that sk0 = rk0,
sk1 = rk1, sk2 = rk2 and sk3 = rk3. Further, combined the key schedule of
ANT-128/256 and K0 ⊕K1 ⊕K2 = 2, the 4th round key can be denoted as
rk4 = rk0 ⊕1 ⊕rk1 ⊕A3(rk3) = rk2 ⊕3 ⊕A3(rk3) = sk4
Similarly, the following relation can be obtained with K1 ⊕K2 ⊕K3 = 6.
rk5 = rk1 ⊕2 ⊕rk2 ⊕A3(rk4) = rk3 ⊕4 ⊕A3(rk4) = sk5
Then, we show a 6-round related-cipher distinguisher by using the relation
(2). Let P 128
i
and P 256
j
be the ith and jth round input of ANT-128/128 and
ANT-128/256, respectively. Denote C128
i
and C256
j
as the corresponding output
with round keys ski and rkj. Without losing the generality, 0 ≤i ≤(5 + Δr)
and 0 ≤j ≤5, where Δr is a small positive integer. Fj denotes the jth round
function.
– Randomly choose a plaintext X = P 128
0
= P 256
0
, and query the corresponding
ciphertexts C128
5+Δr and C256
5
by calling the encryption algorithm of ANT-
128/128 and ANT-128/256.

Related-Cipher Attacks: Applications to Ballet and ANT
119
It is not diﬃcult to ﬁnd the ciphertext C128
5
is the same as the internal state
value of C256
5
from the context. Therefore, the (5+Δr) round ANT-128/128 will
be reduced to Δr round and the following relation holds
C128
5+Δr = F5+Δr ◦F4+Δr ◦· · · ◦F6(C256
5
)
(3)
For ANT-128/128, the subkey K6, · · · , K5+Δr can be calculated by using
Eq. (3) when Δr is enough small. In other words, the 6-round distinguisher of
related-cipher works when the cost of Δr round key recovery is available.
9-Round Key Recovery Attacks. We take Δr = 3, and launch a 9-round
related-cipher attack between ANT-128/128 and ANT-128/128, as shown in 7.
Denote the ith round input state of ANT-128/128 as Li||Ri, 0 ≤i < r. The
speciﬁc attack process is described as follows.
(1) Randomly choose a plaintext L0||R0, and query the corresponding cipher-
texts CL||CR and RCL||RCR by calling the 9-round and 6-round encryption
algorithm of ANT-128/128 and ANT-128/256, respectively. Based on Prop-
erty 2, we have L6||R6 = RCL||RCR.
(2) Guess sk6 and sk8, we have
F(L6) ⊕R6 ⊕sk6 = F(CR) ⊕CL ⊕sk8
(4)
(3) Guess sk7 and we have
F(L7) ⊕R7 ⊕L8 ⊕sk7 = 0
(5)
Since sk6 is known, L7 = F(L6) ⊕R6 ⊕sk6 is determined. R7 = L6 and
L8 = CR,
(4) Based on the key schedule of ANT-128/128, we have
sk8 = sk6 ⊕7 ⊕A3(sk7)
(6)
(5) Joint Eq. (4) and Eq. (6) to solve for the variable sk7, and combined with
Eq. (5) to solve for the variable sk6. Finally, obtain the variable sk8 based
on Eq. (6).
(6) Choose another plaintext L
′
0||R
′
0, and verify the correctness of candidates.
The time complexity of (2), (3), and (4) are both negligible. In the step
(5): calculating sk7 needs to call linear operation A and the cost is negligible,
calculating sk6 needs to call F about 264 times (about 260.9 calls to the 9-round
encryption algorithm of ANT-128/128), and calculating sk8 needs one addition
operation. Therefore, the main complexity of this attack is twice calls to the
6-round encryption algorithm of ANT-128/256, and 260.9 calls to the 9-round
encryption algorithm of ANT-128/128, and we can recover 128-bit subkeys of
ANT-128/128.

120
Y. Mao et al.
Fig. 7. Key recovery attack of ANT-128/128
Proposition 1. There exist at most 6-round related-cipher distinguishers with
equivalent keys between ANT-128/128 and ANT-128/256.
Proof. The existence has been proved in Property 2. The maximum property
can be proved by contradiction. Assume there is a 7-round related-cipher dis-
tinguisher with equivalent keys between ANT-128/128 and ANT-128/256, then
there are equal round keys up to 7 rounds.
sk0 = rk0, sk1 = rk1, sk2 = rk2, sk3 = rk3, sk4 = rk4, sk5 = rk5, sk6 = rk6.
Based on the key schedule, the following relationships can be obtained.
sk4 = sk2 ⊕3 ⊕A3(sk3), rk4 = rk0 ⊕1 ⊕rk1 ⊕A3(rk3) = sk4 ⊕sk2 ⊕sk1 ⊕sk0 ⊕2.
After simpliﬁcation, sk2 ⊕sk1 ⊕sk0 ⊕2 = 0. Similarly,
sk5 = sk3 ⊕4 ⊕A3(sk4),
rk5 = rk1 ⊕2 ⊕rk2 ⊕A3(rk4) = sk5 ⊕sk3 ⊕sk2 ⊕sk1 ⊕6.
sk6 = sk4 ⊕5 ⊕A3(sk5),
rk6 = rk2 ⊕3 ⊕rk3 ⊕A3(rk5) = sk6 ⊕sk4 ⊕sk3 ⊕sk2 ⊕6.
After simpliﬁcation, sk3 ⊕sk2 ⊕sk1 ⊕6 = 0, sk4 ⊕sk3 ⊕sk2 ⊕6 = 0.
In addition, the following equations hold.
sk4 = sk2 ⊕3 ⊕A3(sk3), sk3 = sk1 ⊕2 ⊕A3(sk2), sk2 = sk0 ⊕1 ⊕A3(sk1).

Related-Cipher Attacks: Applications to Ballet and ANT
121
Since the operate A is a linear function, the above three equations add up to
A3(6) = 4. That is, A3(6) = 0x180c060000000000. Obviously, it is a contradic-
tion. The hypothesis is wrong, and this proposition is proved.
The above result shows that the key equivalence situation can not be
extended to more than 6 rounds, and ANT-128 only has low-round related-
cipher attacks. Therefore, ANT-128 is relatively secure against related-cipher
attack under the condition of equivalent keys.
5
Conclusion
In this paper, we summarize two basic requirements for the security of a fam-
ily of ciphers against general cryptanalysis methods such as diﬀerential attack
and against related-cipher cryptanalysis, and then evaluate the related-cipher
attack on two block ciphers. The results are as follows. For Ballet-128/128,
the full cipher key can be recovered. For Ballet-128/256, the keys of type
K256 = k0||k1||0||0 can be recovered, and other types still need further research.
For ANT-128, there are only round-reduced related-cipher attacks under the
equivalent key.
The related-cipher attack applied in this paper provides a new idea for crypt-
analysis work, and also helps to provide new reference criterions for the design
and evaluation of new ciphers.
Acknowledgement. The authors would like to thank Dr Mir Ali Rezazadeh Baee
and the anonymous reviewers for their detailed and very helpful comments and sugges-
tions to improve this article. This work is supported by the National Natural Science
Foundation of China (No. 62072445).
References
1. De Canni`ere, C., Dunkelman, O., Kneˇzevi´c, M.: KATAN and KTANTAN—a family
of small and eﬃcient hardware-oriented block ciphers. In: Clavier, C., Gaj, K. (eds.)
CHES 2009. LNCS, vol. 5747, pp. 272–288. Springer, Heidelberg (2009). https://
doi.org/10.1007/978-3-642-04138-9 20
2. Beaulieu, R., Shors, D., Smith, J., et al.: The SIMON and SPECK lightweight
block ciphers. In: Proceedings of the 52nd Annual Design Automation Conference,
pp. 1–6. Association for Computing Machinery, New York (2015) . https://doi.
org/10.1145/2744769.2747946
3. Yang, G., Zhu, B., Suder, V., Aagaard, M.D., Gong, G.: The Simeck family of
lightweight block ciphers. In: G¨uneysu, T., Handschuh, H. (eds.) CHES 2015.
LNCS, vol. 9293, pp. 307–329. Springer, Heidelberg (2015). https://doi.org/10.
1007/978-3-662-48324-4 16
4. Albrecht, M.R., Rechberger, C., Schneider, T., Tiessen, T., Zohner, M.: Ciphers
for MPC and FHE. In: Oswald, E., Fischlin, M. (eds.) EUROCRYPT 2015. LNCS,
vol. 9056, pp. 430–454. Springer, Heidelberg (2015). https://doi.org/10.1007/978-
3-662-46800-5 17

122
Y. Mao et al.
5. Biham, E., Shamir, A.: Diﬀerential Cryptanalysis of the Data Encryption Standard.
Springer, New York (1993). https://doi.org/10.1007/978-1-4613-9314-6
6. Matsui, M.: Linear cryptanalysis method for DES cipher. In: Helleseth, T. (ed.)
EUROCRYPT 1993. LNCS, vol. 765, pp. 386–397. Springer, Heidelberg (1994).
https://doi.org/10.1007/3-540-48285-7 33
7. Biham, E., Biryukov, A., Shamir, A.: Cryptanalysis of skipjack reduced to 31
rounds using impossible diﬀerentials. In: Stern, J. (ed.) EUROCRYPT 1999. LNCS,
vol. 1592, pp. 12–23. Springer, Heidelberg (1999). https://doi.org/10.1007/3-540-
48910-X 2
8. Knudsen, L., Wagner, D.: Integral cryptanalysis. In: Daemen, J., Rijmen, V. (eds.)
FSE 2002. LNCS, vol. 2365, pp. 112–127. Springer, Heidelberg (2002). https://doi.
org/10.1007/3-540-45661-9 9
9. Demirci, H., Sel¸cuk, A.A.: A meet-in-the-middle attack on 8-round AES. In:
Nyberg, K. (ed.) FSE 2008. LNCS, vol. 5086, pp. 116–126. Springer, Heidelberg
(2008). https://doi.org/10.1007/978-3-540-71039-4 7
10. Biham, E.: New types of cryptanalytic attacks using related keys. J. Cryptol. 7(4),
229–246 (1994). https://doi.org/10.1007/BF00203965
11. Joan, D., Vincent, R.: The Design of Rijndael: AES: The Advanced Encryption
Standard. Information Security and Cryptography, Springer, Heidelberg (2002).
https://doi.org/10.1007/978-3-662-04722-4
12. Daemen, J., Knudsen, L., Rijmen, V.: The block cipher Square. In: Biham, E. (ed.)
FSE 1997. LNCS, vol. 1267, pp. 149–165. Springer, Heidelberg (1997). https://doi.
org/10.1007/BFb0052343
13. Ferguson, N., et al.: Improved cryptanalysis of Rijndael. In: Goos, G., Hartmanis,
J., van Leeuwen, J., Schneier, B. (eds.) FSE 2000. LNCS, vol. 1978, pp. 213–230.
Springer, Heidelberg (2001). https://doi.org/10.1007/3-540-44706-7 15
14. Mala, H., Dakhilalian, M., Rijmen, V., Modarres-Hashemi, M.: Improved impossi-
ble diﬀerential cryptanalysis of 7-round AES-128. In: Gong, G., Gupta, K.C. (eds.)
INDOCRYPT 2010. LNCS, vol. 6498, pp. 282–291. Springer, Heidelberg (2010).
https://doi.org/10.1007/978-3-642-17401-8 20
15. Derbez, P., Fouque, P.-A.: Exhausting Demirci-Sel¸cuk meet-in-the-middle attacks
against reduced-round AES. In: Moriai, S. (ed.) FSE 2013. LNCS, vol. 8424, pp.
541–560. Springer, Heidelberg (2014). https://doi.org/10.1007/978-3-662-43933-
3 28
16. Wu, H.: Related-cipher attacks. In: Deng, R., Bao, F., Zhou, J., Qing, S. (eds.)
ICICS 2002. LNCS, vol. 2513, pp. 447–455. Springer, Heidelberg (2002). https://
doi.org/10.1007/3-540-36159-6 38
17. Sung, J., Kim, J., Lee, C.: Diﬀerential related-cipher attacks on block ciphers with
ﬂexible number of rounds. Inf. Secur. Cryptol. 15(1), 77–86 (2005)
18. Shao, Z. Y., Ding, L.: Related-cipher attack on Salsa20. In: 4th International Con-
ference on Computational and Information Sciences on Proceedings, pp. 1182–1185.
IEEE, Piscataway (2012)
19. Ding, L.: Improved related-cipher attack on Salsa20 stream cipher. IEEE Access
7, 30197–30202 (2019)
20. Kohno, T.: Analysis of the WinZip encryption method. IACR Cryptology ePrint
Archive, pp. 78(2004). https://eprint.iacr.org/2004/078
21. Cui, T.T., Wang, M.Q., et al.: Ballet: a software-friendly block cipher. J. Cryptolog.
Res. 6(6), 704–712 (2019)
22. Chen, S.Y., Fan, Y.H., Fu, Y., et al.: On the design of ANT family block ciphers.
J. Cryptolog. Res. 6(6), 748–759 (2019)

Related-Cipher Attacks: Applications to Ballet and ANT
123
23. Notice of National Cryptgraphic Algorithm Design Competetion (in Chinese).
https://www.cacrnet.org.cn/site/content/259.html. Accessed 9 Feb 2023
24. Mouha, N., Luykx, A.: Multi-key security: the even-mansour construction revisited.
In: Gennaro, R., Robshaw, M. (eds.) CRYPTO 2015. LNCS, vol. 9215, pp. 209–223.
Springer, Heidelberg (2015). https://doi.org/10.1007/978-3-662-47989-6 10
25. Wu, W.L., Zhang, L., Zheng, Y., et al.: The block cipher uBlock. J. Cryptolog.
Res. 6(6), 690–703 (2019)

Cryptanalysis of SPEEDY
Jinliang Wang1,2, Chao Niu1,2, Qun Liu1,2, Muzhou Li1,2(B), Bart Preneel4,
and Meiqin Wang1,2,3
1 Key Laboratory of Cryptologic Technology and Information Security,
Ministry of Education, Shandong University, Jinan, China
{jinliangwang,niuchao,qunliu,muzhouli}@mail.sdu.edu.cn
2 School of Cyber Science and Technology, Shandong University, Qingdao, China
mqwang@sdu.edu.cn
3 Quan Cheng Shandong Laboratory, Jinan, China
4 imec-COSIC, KU Leuven, Leuven, Belgium
Bart.Preneel@esat.kuleuven.be
Abstract. SPEEDY is a family of ultra-lightweight block ciphers designed
by Leander et al. at CHES 2021. There are three recommended variants
denoted as SPEEDY-r-192 with r ∈{5, 6, 7}. All of them support the
192-bit block and the 192-bit key. The main focus during its design is
to ensure hardware-aware low latency, thus, whether it is designed to
have enough security is worth to be studied. Recently, the full-round
security of SPEEDY-7-192 is announced to be broken by Boura et al.
at EUROCRYPT 2023 under the chosen-ciphertext setting, where a
round-reduced attack on SPEEDY-6-192 is also proposed. However, no
valid attack on SPEEDY-5-192 is given due to its more restricted secu-
rity parameters. Up to now, the best key recovery attack on this variant
only covers 3 rounds proposed by Rohit et al. at AFRICACRYPT 2022.
In this paper, we give three full-round attacks on SPEEDY-7-192. Using
the divide-and-conquer strategy and other new proposed techniques, we
found a 5.5-round diﬀerential distinguisher which can be used to mount
the ﬁrst chosen-plaintext full-round key recovery attack. With a similar
strategy, we also found a 5-round linear distinguisher which leads to the
ﬁrst full-round attack under the known-plaintext setting. Meanwhile, the
5.5-round diﬀerential distinguisher also helps us slightly improve the full-
round attack in the chosen-ciphertext setting compared with the previous
result. Besides, we also present a 4-round diﬀerential attack on SPEEDY-
5-192, which is the best attack on this variant in terms of the number of
rounds so far. A faster key recovery attack covering the same rounds is
also given using a diﬀerential-linear distinguisher. Both attacks cannot
threaten the full round security of SPEEDY-5-192.
Keywords: Lightweight Cryptography · Low Latency · SPEEDY
1
Introduction
In lightweight cryptography, cryptographic primitives are required to be suit-
able for resource-constrained environments, such as low area, latency or energy
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 124–156, 2023.
https://doi.org/10.1007/978-3-031-35486-1_7

Cryptanalysis of SPEEDY
125
consumption. Therefore, it’s usually diﬃcult to design such ciphers since one has
to make trade-oﬀs between implementation eﬃciency and security. Hence, the
security of such ciphers is worth to be evaluated thoroughly.
In CHES 2021, Leander et al. proposed a family of ultra-low-latency block
ciphers named as SPEEDY [9] to resolve the problem: How to design a secure
encryption algorithm whose hardware implementation is fast. To gain such
cipher, they ﬁrst considered which type of logic gates and circuit topologies are
suitable for ultra low-latency encryption. As a result, SPEEDY adopts a lightweight
S-box, whose coordinate functions are realized as two-level NAND trees, and a
hardware-friendly linear layer. After careful combination, SPEEDY achieves lower
latency in hardware than most cryptographic primitives. SPEEDY contains three
versions SPEEDY-5-192, SPEEDY-6-192 and SPEEDY-7-192, whose number of rounds
are 5, 6, and 7, respectively. Note that, as the number of rounds decreases, the
SPEEDY cipher gains better performance in hardware implementations but has a
weak bound of security claim.
Recently, Boura et al. [5] announced that the full-round security of SPEEDY-7-
192 is broken under the chosen-ciphertext setting, where a round-reduced attack
on SPEEDY-6-192 is also proposed. However, due to the more restricted security
parameters, no valid attack on SPEEDY-5-192 is given. The best key recovery
attack on this variant only covers 3 rounds proposed by Rohit et al. [16].
In this paper, we aim to evaluate the security of SPEEDY thoroughly using dif-
ferential cryptanalysis, linear cryptanalysis and diﬀerential-linear cryptanalysis.
Proposed by Biham and Shamir in 1990, diﬀerential cryptanalysis [4] has been
an important method in evaluating the security of symmetric-key ciphers. Using
a diﬀerential distinguisher with high probability, one can recover the secret key
after adding several rounds before or/and after it. Such an attack can be mounted
only when the adversary is under the chosen-plaintext/ciphertext setting. Lin-
ear cryptanalysis [13], proposed by Matsui in 1992, only requires the adversary
under the known-plaintext setting, which is more realistic than the diﬀeren-
tial attack. It exploits the linear distinguisher with high correlation considering
the linear relation between some bits of plaintexts, ciphertexts and the secret
key. Diﬀerential-Linear cryptanalysis [8] is another chosen plaintext/ciphertext
method, which is proposed by Langford and Hellman in 1994. This method uses
a distinguisher with a high correlation that consists of a diﬀerential distinguisher
followed by a linear distinguisher. To evaluate its correlation more accurately,
Achiya and Dunkelman introduced DLCT (short for Diﬀerential Linear Con-
nectivity Table) [1] to connect the diﬀerential distinguisher and the linear one.
This method works eﬃciently on ciphers whose diﬀerential probabilities and lin-
ear correlations are very high when the distinguisher covers small rounds, but
decrease very quickly when the number of rounds increases.
1.1
Contributions
In this paper, we propose several key recovery attacks on full-round SPEEDY-7-
192 and 4-round SPEEDY-5-192 by exploiting key-recovery friendly distinguishers
constructed following the divide-and-conquer strategy. Detailed contributions
are shown as follows.

126
J. Wang et al.
Strategy of Searching Key-Recovery Friendly Diﬀerential and Linear
Trail of SPEEDY. Our searching strategy includes two parts: (a) control the prop-
agation of active pattern deduced from the input diﬀerence/mask and output
diﬀerence/mask; (b) construct long distinguishers in the divide-and-conquer way.
To fulﬁll (a), we introduce TDDT (short for truncated diﬀerential distribution
table) to show the non-randomness of S-box with bit-wise truncated diﬀerential
propagation. With this table, one can depict clearly in the searching algorithm
on how to choose input/output diﬀerences of the target distinguisher. While for
(b), we construct part of the distinguisher by concatenating two distinguishers
covering the small number of rounds. For instance, the 5.5-round distinguisher is
ﬁrst built with a 4-round distinguisher. To gain a better 4-round distinguisher,
we split it into two parts with each covering two rounds. The input diﬀerence
of the MixColumn operation in the middle is chosen to minimize the total num-
ber of activated S-boxes involved in its two neighborhood S-box layers. For the
other MixColumns contained in the 5.5-round distinguisher, no restriction on
their input diﬀerences is necessary.
Improved Key Recovery Attacks Against Full-Round SPEEDY-7-192.
By exploiting the above strategy, we gain a 5.5-round diﬀerential distinguisher,
which has a higher probability than the one found by [5]. With this diﬀerential
trail, we mount the ﬁrst chosen-plaintext attack on its full-round variant. Besides,
since it’s key-recovery-friendly, it also leads to a full-round chosen-ciphertext
attack, which requires slightly less complexities than the one proposed by [5].
Further, we also mount the ﬁrst known-plaintext 7-round linear attack with
a 5-round linear distinguisher by adopting a similar search strategy. Although
this one costs slightly higher complexities than the diﬀerential attack, it is a
known-plaintext attack which requires weaker capabilities of the adversary than
the chosen-plaintext attack required in the diﬀerential cryptanalysis. Therefore,
such linear key recovery attack is also valuable. All our attack results along with
previous published ones are summarized in Table 1.
Improved Key Recovery Attack on Round-Reduced
SPEEDY-5-192.
We also provide two attacks on 4-round SPEEDY-5-192 using diﬀerential and
diﬀerential-linear cryptanalysis, respectively. More precisely, the diﬀerential
attack is mounted with a two-round distinguisher where one round is added
at the top and bottom, respectively, while the diﬀerential-linear attack is given
by exploiting a three-round distinguisher and adding one half-round at both
sides. Note that they are the best valid attacks on it in terms of the number of
rounds.
1.2
Organization
First, we brieﬂy recall SPEEDY, as well as diﬀerential, linear and diﬀerential-
linear cryptanalysis in Sect. 2. In Sect. 3, we show how to exploit the propaga-
tion properties of SB and MC operations, and introduce the TDDT (short for

Cryptanalysis of SPEEDY
127
Table 1. Summary of valid attacks on SPEEDY-7-192 and SPEEDY-5-192. KP, CP and
CC separately denote the data collected in the known-plaintext, chosen-plaintext and
chosen-ciphertext settings. Time complexities are evaluated in encryption units, while
memory costs are evaluated in block size.
Version
Security Claim
(Data, Time)
R
Data
Time
Memory
Type
Ref
SPEEDY-7-192
(2192, 2192)
7
2187.27CC
2187.75
242
Diﬀ.
[5]
7
2186.53CC
2187.39
236
Diﬀ.
Sect. 5.1
7
2186.53CP
2187.39
2156
Diﬀ.
Sect. 5.1
7
2188.50KP 2189.41
2185.04
Linear
Sect. 5.2
SPEEDY-5-192
(264, 2128)
3
217.6CP
252.5
217.62
Integral
[16]
4
261CC
2119.69
283
Diﬀ.
Sect. 5.3
4
261CP
2105
2105
Diﬀ.-Linear
Sect. 5.4
truncated diﬀerential distribution table). Using these properties, we introduce
the automated search method oriented to key recovery for diﬀerential, linear
and diﬀerential-linear cryptanalysis in Sect. 4. Detailed attack procedures are
given in Sect. 5. Finally, we summarize our work in Sect. 6. Besides, the code for
searching distinguishers in this paper is available at the following repository:
https://github.com/Jin-liang-Wang/Cryptanalysis-of-SPEEDY.
2
Preliminaries
2.1
Brief Introduction of SPEEDY
SPEEDY [9] is a family of ultra-low latency block ciphers proposed at CHES 2021.
SPEEDY uses a 6-bit bijective S-box and can be instantiated with diﬀerent block
sizes, key sizes, and numbers of rounds. For instance, SPEEDY-r-6l is the version
of block size and key size of 6l-bits, and r is the number of iterated rounds.
The internal state of SPEEDY-r-6l can be viewed as an l × 6 rectangle array of
bits where l = 32. Following the notation of its design document [9], we use
x[i,j] to denote the bit located at row i and column j of the state x where
0 ≤i < l, 0 ≤j < 6.
The design document of SPEEDY suggests l = 32, and the number of rounds
r ∈{5, 6, 7}, which are called SPEEDY-5-192, SPEEDY-6-192, SPEEDY-7-192, respec-
tively. As for the security claim, SPEEDY-r-192 achieves 128-bit security when
iterated over r = 6 rounds and full 192-bit security when iterated over r = 7
rounds, while the r = 5 rounds variant provides 2128 time complexity and 264
data complexity. To make it clear, we denote SPEEDY-r-192 as SPEEDY in this
paper, and brieﬂy recall the cipher as follows.
Initialization. SPEEDY receives a 192-bit plaintext and initializes the inter-
nal state with a two-dimensional matrix x. Speciﬁcally, it initializes the k-th
MSB (short for the most signiﬁcant bit) into x[i,j], where k = 6i + j.

128
J. Wang et al.
Round Function. Its round function consists of ﬁve diﬀerent operations: Sub-
Box (SB), ShiftColumns (SC), MixColumns (MC), AddRoundKey (Akr) and
AddRoundConstant (Acr). A high-level overview of its round function is shown
in Fig. 1. Note that the last round function only has three operations.
SB
SC
SB
SC
MC
kj
cj
Rj with 0 ≤j < r −1
...
SB
SC
SB
kr−1
kr
Rr−1
Fig. 1. r rounds of SPEEDY block cipher.
SB is composed of 32 parallel 6-bit Sbox, where each Sbox takes the i-th row
(x[i,0], x[i,1], x[i,2], x[i,3], x[i,4], x[i,5]) as input and its output is placed in the same
row. The detail of S-box is shown in Appendix A. SC rotates the j-th column
of the state upwards by j bits. In other words, the output bit y[i,j] equals to
the input bit x[(i+j) mod 32,j]. MC also operates on each column, where seven
speciﬁcally chosen input bits are XORed as a new bit of its output, as shown in
Eq. (1). It also can be seen as multiplying each column by a cyclic matrix.
y[i,j] = x[i,j] ⊕x[i+1,j] ⊕x[i+5,j] ⊕x[i+9,j] ⊕x[i+15,j] ⊕x[i+21,j] ⊕x[i+26,j],
∀i, j. (1)
The 192-bit round key kr and 192-bit constant cr are respectively XORed with
the entire state in Akr and Acr.
Key Schedule. The 192-bit master key of SPEEDY is regarded as the ﬁrst round
key k0. Relation between the r-th round key kr and the (r + 1)-the round key
kr+1 is constructed by a bit permutation PB. To be clear, the j-th bit of kr+1
equals to the i-th bit of kr, where j ≡(7i + 1) mod 192.
2.2
Diﬀerential, Linear and Diﬀerential-Linear Crytanalysis
Diﬀerential Cryptanalysis. Diﬀerential cryptanalysis is a chosen plaintext
attack proposed by Biham and Shamir [4] in 1990. Starting from a well-chosen
diﬀerence δin, the distribution of Ek(x) ⊕Ek(x ⊕δin) is non-uniform. More pre-
cisely, there exits a speciﬁc δout such that Prx,k[Ek(x) ⊕Ek(x ⊕δin) = δout]
is signiﬁcantly higher than 2−n, where n is the block size. In order to distin-
guish a cipher with a high probability diﬀerential (δin →δout) from a random
permutation, one can collect D ciphertexts corresponding to pairs of plaintexts
(P, P ⊕δin), and compute the number of pairs following the diﬀerential:
Q = # {P : Ek(P) ⊕Ek(P ⊕δin) = δout} .
The expected value of Q for the cipher is D × Pr[δin →δout] and D × 2−n for
the random permutation. Thus, the distinguisher succeeds with high probability
when D = O(1/ Pr[δin →δout]).

Cryptanalysis of SPEEDY
129
Linear Cryptanalysis. Linear cryptanalysis, proposed by Matsui at EURO-
CRYPT 1993 [13], exploits the linear approximations of the round function in
order to obtain a biased approximation of the cipher. The linear approxima-
tion is a pair of masks (α, α′) such that the distribution of the XORed masked
plaintext and ciphertext x · α ⊕Ek(x) · α′ is biased. More precisely, we have
(| Prx[x · α ⊕Ek(x) · α′] −1
2| ≫2−n/2) for most keys k), where x · y = 
i xiyi
denotes the inner product. Then, we have the correlation which is expected to
be zero when averaged over all keys is:
Cork (α →α′) = 2Pr
x [x · α = Ek(x) · α′] −1.
Similarly, to distinguish a cipher with a biased linear approximation (α, α′)
from a random permutation, we collect D known plaintexts/ciphertexts, and
evaluate the experimental correlation:
Q = (# {P, C : P · α ⊕C · α′ = 0} −# {P, C : P · α ⊕C · α′ = 1}) /D.
The expected value Q is larger (in absolute value) for the cipher than for a
random permutation and can be observed with high probability when D =
O(Cor(α →α′)−2).
Diﬀerential-Linear Cryptanalysis.
Diﬀerential-linear cryptanalysis, pro-
posed by Langford and Hellman in 1994 [8], is a technique to combine diﬀerential
and linear cryptanalysis. Let E be a cipher which can be described as a cascade
of three subciphers, E0, Em and E1, i.e., E = E1 ◦Em ◦E0. Let δin and δout
denote the input and output diﬀerence of E0, α and α′ be the input and output
linear mask of E1. Asume that the diﬀerential trail δin −→δout in E0 is satisﬁed
with probability p, and the linear trail α −→α′ in E1 is satisﬁed with correlation
q. The correlation of δout −→α in Em is satisﬁed with
r = Cor

δout
Em
−−→α

= 2Pr
x [Em(x) · α = Em(x ⊕δout) · α] −1.
Then, the correlation of the trail δin
E
−→α′ is satisﬁed with correlation
Cor(δin
E
−→α′) = pq2r. One can collect D ciphertexts corresponding to pairs
of plaintexts (P, P ⊕δin) and evaluate the experimental correlation:
Q = (# {P : α′ · (E(P) ⊕E(P ⊕δin)) = 0)} −# {P : α′ · (E(P) ⊕E(P ⊕δin)) = 1)}) /D.
Similarly, the expected value is larger (in absolute value) for the cipher than
for a random permutation and can be observed with high probability when
D = O(Cor(δin
E
−→α′)−2).
3
Further Study on Operations of SPEEDY
In general, the extended path before and after the distinguisher determines the
number of guessed key bits, the attack rounds, and the time complexity. To

130
J. Wang et al.
control the number of active S-boxes in the extended path, we add the constraint
of the propagation through key recovery rounds and propose the concept of
TDDT (short for truncated diﬀerential distribution table). Since the security of
SPEEDY highly relies on the 6-bit S-box and the MC operation, we did in-depth
research for SB operation with the TDDT in Sect. 3.1 and for MC operation in
Sect. 3.2, respectively. With these newly observed properties, we can construct
the automated search method for the diﬀerential and linear distinguishers by
taking the key recovery into account in Sect. 4.
3.1
Truncated Diﬀerential Distribution Table
In general, the time complexity of diﬀerential cryptanalysis is aﬀected by the
number of active bits in plaintext and ciphertext. To control the number of
active bits, we limit some bits being inactive before the second SB operation to
reduce the number of active bits in plaintext, as shown in Sect. 4.
On average, each bit is limited inactive in rounds of key recovery with prob-
ability 2−1. However, we have found that in a speciﬁc S-box, e.g., the S-box of
SPEEDY, this probability is ﬂuctuate considerably. Two examples are provided in
Equations (2a) and (2b) below, although the input sets of these two situations
are both one bit inactive, the probabilities of Eqs. (2a) and (2b) are much higher
than 2−1.
**0***
SB
−−−−−−→
p=2−0.54 010000 ,
(2a)
0*****
SB
−−−−−−→
p=2−0.83 010000 ,
(2b)
where * denotes a arbitrary bit ∈{0, 1}. The probability is computed as fol-
lows. Taking Eq. (2b) as an example. The input set Δin contains 25 diﬀerences,
i.e., {0b000000,0b000001,· · · ,0b011111}. We assume that each diﬀerence in Δin
appears with equal probability. Besides, the output diﬀerence is δout = 0b010000.
Then this probability is computed by Pr(Δin
SB
−→δout) =

δin∈Δin Pr(δin
SB
−→δout)
|Δin|
.
In order to get an optimal probability in rounds of key recovery, we need to
consider how to select inactive bits. In this section, we introduce the TDDT and
show how it can select inactive bits using the automatic solver in Sect. 4.
Compared to DDT (short for diﬀerential distribution table [4]) which contains
the number of transition situations of each ﬁxed input-output diﬀerence, for a N-
bit S-box, the TDDT is a 2N ×2N table which contains the number of transition
situation from a set of input diﬀerences to a set of output diﬀerences. To clarify,
we deﬁne the following notation to represent a set of diﬀerences named bit-
string k. For an n-bit bit-string k = (k0, k1, ..., kn−1), k ∈Fn
2, we deﬁne k′ ⪯k,
if k′
i ≤ki for all i. Then, we denote BΔin/BΔout as the bit-string representation of
the input/output diﬀerence set Δin/Δout. For example, when a truncated input
diﬀerence Δin is "00*00*", the bit-string representation BΔin is 0b001001(S)1,
1 To distinguish the set of diﬀerences from the single diﬀerential, we use numbers with
subscript (S) to represent the set of diﬀerences.

Cryptanalysis of SPEEDY
131
i.e., BΔin = 0b001001(S) denotes the diﬀerential set "00*00*" which contains
diﬀerences {0b000000,0b000001,0b001000,0b001001}. Thus, we can construct
TDDT from the DDT using Algorithm 1 and the probability of the truncated
diﬀerence propagation from Δin to Δout is:
Pr(Δin
SB
−→Δout) = TDDT[BΔin][BΔout]
|Δin| · 2N
,
(3)
where N is the size of S-box and |Δin| denotes the number of input diﬀerences
δin that fulﬁlls δin ⪯Δin.
Algorithm 1: Construct TDDT
Input: S-box
Output: TDDT; // Truncated difference distribution table
1 L[i][j] ←0,(0 ≤i, j < 2N); // Initial an empty list for TDDT
2 L[0][0] ←2N; // Initialize the case 0
SB
−→0 with probability 1
3 Generate the DDT of S-box;
4 for BΔin ∈[1(S), 2N
(S)) do
5
for BΔout ∈[1(S), 2N
(S)) do
6
for δout ⪯Δout do
7
for δin ⪯Δin do
8
L[BΔin][BΔout] ←L[BΔin][BΔout] + DDT[δin][δout];
9 return L as TDDT of the S-box;
By exploiting the diﬀerential property of the transition from a set of diﬀer-
ences that are inactive in certain bits to another set of diﬀerences with diﬀerent
inactive bits, TDDT can help us make a universal search model for key recovery.
Moreover, we also consider the cases of diﬀerential propagation from the ﬁxed
input diﬀerence to a set of output diﬀerences. Then, we deﬁne FTDDT(short for
ﬁxed-input truncated diﬀerence distribution table) to describe the probability
distribution of this transition and introduce it as follows.
Fixed-Input Truncated Diﬀerence Distribution Table. As aforemen-
tioned, FTDDT contains the number of transition situations of a ﬁxed input
diﬀerence to a set of output diﬀerences. For the special case, when the input
diﬀerence is zero, the output diﬀerence must be zero, i.e., the set of output dif-
ferences Δout contains only zero diﬀerences. More precise, when δin = 0, we
have
FTDDT[0][0] = 2N
and
FTDDT[0][i] = 0, i ∈[1, 2N).
We show the construction of FTDDT in Algorithm 2. By modeling these dif-
ference distribution tables into our automated search model, we can ﬁnd a
key recovery-oriented diﬀerential which contains key recovery rounds as well

132
J. Wang et al.
as distinguishers. Time complexity of Algorithm 2 is(2N −1) · N
i=1
N
i

2i =
O(2N·log2 6), which is evaluated as the number of the look-up table operations.
Algorithm 2: Construct FTDDT
Input: S-box;
Output: FTDDT; // Fixed input/output truncated difference
distribution table
1 L[i][j] ←0, (0 ≤i, j < 2N); // Initialize an empty list for FTDDT
2 L[0][0] ←2N; // Initial the case 0
SB
−→0 with probability 1
3 Generate the DDT of S-box;
4 for δin ∈[1, 2N) do
5
for Δout ∈[1(S), 2N
(S)) do
6
for δout ⪯Δout do
7
L[δin][Δout] ←L[δin][Δout] + DDT[δin][δout];
8 return L as FTDDT of the S-box;
In summary, FTDDT shows the non-randomness of S-box with bit-wise trun-
cated diﬀerential propagation. Considering the diﬀerential propagation through
a random permutation, the ﬁxed input diﬀerence δin will propagate to the out-
put diﬀerence set Δout with probability 2−i where the number of zero bits in
BΔout is i. As mentioned before, due to the non-randomness of a speciﬁc S-box,
the probability is changed to FTDDT[δin][BΔout]/2N. In order to verify the cor-
rectness of FTDDT, we have conducted an experiment in Appendix B. With this
accurate propagation probability of diﬀerential, we can gain a better-extended
path for a key recovery attack as shown in Sect. 4.
Inverse Probability of FTDDT. During key recovery, we need to partially
encrypt (resp. decrypt) the plaintext pair (resp. ciphertext pair) to validate the
input (resp. output) of the distinguisher. To ﬁlter the good pairs of plaintext
more precisely in validating the input of the distinguisher, we utilize the inverse of
FTDDT. We denote Na as the number of active bits in Δout. For example, Na = 5
if Δout = 0b110111, i.e., **0***. Then, when considering a ﬁxed diﬀerence
δout ⪯Δout propagating to δin which is the inverse of FTDDT[δin][BΔout], the
average probability of this transition is FTDDT[δin][BΔout]/2N+Na. The proof is
shown in Appendix C. With the inverse probability of FTDDT, we will get the
more precise time complexity of the key-recovery procedure.
3.2
Diﬀerential Propagation Property of MC
The MC operation of SPEEDY generates each new bit in a column by XOR-
ing seven current bits. It also can be seen as multiplying each column by a

Cryptanalysis of SPEEDY
133
cyclic matrix M. In this section, we research the MC operation in-depth by con-
sidering the matrix M. Here we traverse all possible inputs with HW (short
for Hamming weight) from one to eight and ﬁnd that their minimum output
HW are (7, 8, 7, 8, 7, 6, 5, 4). Table 2 summarizes which choices of active diﬀeren-
tial bits are associated with these minimal output HW cases. Speciﬁcally, we use
{a0, a1, · · · } to denote that the ai-th bit of the input diﬀerence is active. More-
over, due to the property of the MC operation of SPEEDY, we rotate the array
and make the 0-th bit active to represent the rotation invariant array class. From
Table 2, we can observe that when the input HW is one, there is a minimum sum
of the input and output minimum HW. Meanwhile, when the input HW is two
and three, the minimal sum of the input and output HW is relatively small.
Table 2. Summary of active diﬀerentials yielding low output HW from M. When the
input HW is greater than 3, the cases of active bits are too large to list. We record
their number to simplify. For the input diﬀerences with diﬀerent HW, we list its output
diﬀerence which have the minimum HW.
In HW Out HW Active Bits Total HW
1
7
{0}
8
2
8
{0, 6}
10
{0, 11}
10
3
7
{0, 4, 15}
10
4
8
10 cases
12
5
7
7 cases
12
6
6
8 cases
12
7
5
8 cases
12
8
4
5 cases
12
When building the automated search model, one can utilize the property of
MC to control the diﬀusion of the diﬀerential, which can reduce the size of the
search space. In this work, we utilize a divide-and-conquer method to search
for a longer diﬀerential by dividing it into several parts. More precisely, for a
four rounds diﬀerential, we ﬁrst search several two rounds diﬀerentials with the
input diﬀerence of the last MC is of relatively low HW as in Table 2. Then, we
search the last two rounds of diﬀerential and connect them with the middle MC.
By limiting the sum of input-output HW of the middle MC, we can control the
diﬀusion of the 4-round diﬀerential, i.e. minimizing the total number of activated
S-boxes involved in the middle, and achieve a higher probability.
We note here that Boura et al. [5] proposed a diﬀerent strategy to utilize the
properties of the MC operation. In their approach, a diﬀerential is divided into
several one-round parts and they consider the case that the HW of both input
and output are small.

134
J. Wang et al.
4
Automated Search Method Oriented to Key Recovery
In this section, we introduce the automated search strategies of diﬀerential, linear
and diﬀerential-linear distinguishers against SPEEDY following the divide-and-
conquer strategy, as well as taking the key recovery procedure into consideration.
Usually, cryptanalysts perform key recovery attacks based on a strong distin-
guisher. By appending several rounds before and after the distinguisher, one can
obtain an extended path containing both distinguisher and key recovery rounds.
However, this two-step process of key recovery cannot promise optimal results
as shown in [15,18]. Therefore, automated search oriented to key recovery can
obtain better attack results. To ﬁnd such key-recovery-friendly distinguishers,
properties of SB and MC are introduced in Sect. 3 are utilized.
We implement our search algorithms using STP2, which is a solver developed
based on the SAT (short for boolean satisﬁability problem) [12]/SMT(short for
satisﬁability modulo theories) [2] problem and has been widely used in the ﬁeld
of cryptography [6,10,11,14].
4.1
Diﬀerential Search Model Against SPEEDY
Since we aim to search for distinguishers in the single-key setting, we can omit
Akr and Acr in our model. We denote Si
j as the j-th intermediate state of the
i-th round and set the ﬁrst round indexed with zero as the key recovery round.
SB
SC
SB
SC
MC
Key 
Recovery
SB
SC
SB
SC
MC
2-nd
round
SB
SC
SB
SC
MC
3-rd
round
SB
SC
SB
SC
MC
4-th
round
SB
SC
SB
SC
MC
5-th
round
SB
SC
SB
SC
MC
1-st
round
SB
SC
SB
6-th
round
0
1S
0
0
S
0
2
S
0
3S
0
4
S
1
1S
1
0
S
1
2
S
1
3S
1
4
S
2
0
S
2
1S
2
2
S
2
3S
2
4
S
3
0
S
3
1S
3
2
S
3
3S
3
4
S
4
0
S
4
1S
4
3S
4
4
S
4
2
S
5
0
S
5
1S
5
2
S
5
3S
5
4
S
6
1S
6
2
S
6
3S
6
0
S
Fig. 2. 7-round diﬀerential attack of SPEEDY.
Generally, the variable number and the size of each variable will determine
the total scale of the search model and aﬀect the complexity of solving the
SAT/SMT problem. As the number of rounds increases, the time and memory
2 https://stp.github.io/.

Cryptanalysis of SPEEDY
135
complexity of solving the problem increases exponentially. Speciﬁcally, when the
model exceeds four rounds, we cannot obtain a solution in a reasonable time
with STP in the case of SPEEDY. For obtaining a longer distinguisher, we employ
a divide-and-conquer [18] approach to search several models with a short round
to form the entire diﬀerential. As shown in Fig. 2, our automated search model
is divided into several steps. Motivated by [15], we also consider a key recovery-
oriented search model where the distinguisher rounds and key recovery rounds
are all included.
Model One: 7-Round Diﬀerential Contains 1.5-Round of Key Recov-
ery. The 7-round diﬀerential consists of 5.5-round diﬀerential distinguisher
S1
0 →S6
1 and 1.5 key recovery rounds S0
0 →S1
0, S6
1 →S6
3. For convenience,
we use backward FTDDT to represent the FTDDT of SPEEDY S-box and forward
FTDDT to represent the FTDDT of the inverse of SPEEDY S-box.
Step 1: From S1
3 to S3
4, the search strategies are as follows.
Rule 1: Model SB to comply with DDT.
Rule 2: Model each active S-box in S1
3 to comply with 2−3×2 probability.
This strategy is mainly used to limit the active S-box in the S1
3. More
precisely, we measure this trail with probability 2−6×Na × p, where Na
is the number of active S-box in S1
3 and p is the probability generated
from Rule 1 in Step 1. Indeed, Na active S-boxes imply that there will
have 2 × Na S-boxes in trail S1
0 →S1
3. Since the maximum probability
transition through the S-box is 2−3, we measure each active S-box in S1
3
with probability 2−6.
Rule 3: Constrain only one of the columns to be activated in S3
4. For the
input before MC, consider only entries with low HW from Table 2.
Step 2: From S3
4 to S6
0, the strategies to reduce search space are as follows.
Rule 1: Due to the diﬀerential must be linked, we ﬁx the input diﬀerences
as those in S3
4.
Rule 2: Model the active S-box in S6
0 to comply with a maximum probability
of 2−3.
Step 3: After running the above two steps in parallel, we obtain several four
rounds of diﬀerentials with high probability. Then, we choose the diﬀerential
whose probability is higher than 2−170 and search the corresponding last 1.5-
round diﬀerential of distinguisher and 1.5-round of key recovery as follows.
Rule 1: Model S1
0
SB
−→S1
1 and S1
2
SB
−→S1
3 to comply with DDT.
Rule 2: Model S0
1
SB−1
−→S0
0 and S6
0
SB
−→S6
1 to comply with FTDDT.
Rule 3: Constrain the active S-box in S0
1 and S6
2 less than 32.
Rule 4: Constrain the active S-box number in S0
1 less than 16.
Rule 5: Constrain the active S-box number in S6
2 more than 6.
Here, rules 3 to 5 are used to constrain the active bits to reduce the time
complexity of the key recovery phase as shown in Sect. 5.1.

136
J. Wang et al.
Step 4: Following step one to three, we can get several 5.5-round distinguishers
with 1.5-round of key recovery. Then, we choose the distinguisher with max-
imum probability and search an extended path for key recovery as shown in
Algorithm 6 (Appendix G). To reduce the time complexity, we consider the
diﬀerential rotation invariant of SPEEDY. More precisely, we use one of the 32
rotation-invariant distinguishers to implement the key recovery attack, and
the chosen one makes the lowest time complexity.
With the above four steps, we ﬁnd a diﬀerential trail with probability 2−185.53
which can be used to attack on the 7-round SPEEDY. More precisely, this trail
consists of a 5.5-round diﬀerential distinguisher with probability 2−182.49 and a
1.5-round key-recovery phase with probability 2−3.04. We illustrate it as Fig. 3.
Model Two: 4-Round Diﬀerential Contains Two Rounds of Key
Recovery. From Step 2, we can get several two rounds distinguisher from
S3
4 to S6
0. Then, we use backward FTDDT and forward FTDDT to search 2-
round of key recovery. We show this distinguisher with probability 2−59.35 in
Appendix J. For the property of linear key relation between k0 and k4, the rota-
tion invariant property does not aﬀect the time complexity when attacking the
4-round SPEEDY.
4.2
Searching Linear Distinguishers Against SPEEDY
For linear cryptanalysis, we use a similar strategy used for diﬀerential search,
which is a model oriented toward key recovery. Then, we search for a ﬁve-round
distinguisher with two rounds of key recovery by following a four-step process.
Due to the page number limit of the paper, we have placed the speciﬁcs in
Appendix D.
Finally, we found a 5-round distinguisher combined with two key recovery
rounds with correlation 2−93.01. We show the detail of the linear distinguisher
in Appendix I. In this distinguisher, the bits of k7 which is derived from k0 by
linear key schedule is 139. We reduce the guessed key bits to 185 bits in the key
recovery phase.
4.3
Searching Diﬀerential-Linear Distinguishers Against SPEEDY
Similarly, we search for distinguishers against 4-round SPEEDY. More speciﬁcally,
we search for three rounds of diﬀerential-linear distinguishers and extend half a
round forward and backward for key recovery. The detailed strategy is shown in
Appendix E.
Finally, the distinguisher is shown in Fig. 5 of Appendix F. The correlation
of this 3-round distinguisher is 2−23.095 and the probability of rounds of key-
recovery is 2−6.972. The bits of k7 deduced from k0 by linear key schedule are
29.

Cryptanalysis of SPEEDY
137
5
Key Recovery Attack Against SPEEDY
In this section, we ﬁrst implemented both diﬀerential and linear cryptanalysis
on full SPEEDY with the newly obtained distinguishers in Sect. 4. Then, the key
recovery attack against other versions of SPEEDY are also provided.
5.1
7-Round Diﬀerential Attack Against Full SPEEDY
Using the newly obtained 7-round diﬀerential containing distinguishers and key
recovery rounds, we can perform key recovery attacks on full SPEEDY. Before
the attack, we ﬁrst introduce some techniques that will be used in this section
as follows.
Deduce k0 from k7 by Linear Key Schedule. Due to the linear key sched-
ule, we can get the relationship between k0 and k7 and deduce the key bits of
k0 from k7. We call these bits of k0 deduced key bits from k7. The detailed
relationship between k0 and k7 is shown as the purple squares in Fig. 3.
Function to Sieve Possible Key Guesses. The FirstSboxSieve function
uses the key bits of k7 to deduce the six bits of each row in k0 using the linear key
schedule. After deducing the six bits of k0 from k7, we can ﬁlter the corresponding
key guessing of the plaintext pair with the zero diﬀerence in S0
1. Then, for each
plaintext pair and the corresponding six bit keys of each row, there will leave
26−d−n key guesses after sieving by the ﬁrst S-box, where d is the bit number
deduced from k7 and n is the inactive bit number after the ﬁrst S-box. We show
the details of FirstSBoxSieve in Algorithm 3. The SecondSboxSieve is used
to combine the sets Li of possible key bits in a bigger set. The function can sieve
the elements of the bigger set using the diﬀerence in S0
3. The detail is shown in
Algorithm 4.
Distinguisher with Rounds of Key Recovery. The 5.5-round diﬀerential
distinguisher is shown in Fig. 3, where the black square and the blue square
denote the active bits from S1
4 to S5
4 and the active bits from S0
3 to S1
3, respec-
tively. To distinguish the diﬀerential propagation of the key recovery round, we
use diﬀerent colors to indicate the propagation of each active bit in the extended
rounds, where the gray square indicates the active bits whose diﬀerences are
forced zero. Further, we use the shaded square to denote the bits random from
{0, 1}. Then, we use the red square to denote the active bits in S0
0 and S6
3. To
represent the bits in k0 that are derived from k7 using the linear key schedule,
we use the purple square to denote the deduced bits in k0 and the green square
to denote the guessed key bits when performing the key recovery attack. Note
that 180 key bits in k0 are involved in the key recovery attack.
The attack procedure contains three parts, i.e., data collection, key recovery
and brute force the master key.

138
J. Wang et al.
Fig. 3. Key recovery attack on 7-round SPEEDY with diﬀerential cryptanalysis. When
the output set of a FTDDT has only one single bit, it is shown as a single diﬀerence
in this ﬁgure since it has one possible case for such an output set, e.g., 0b00*000 is
shown as 0b001000 since the active diﬀerence is impossible to transit to the 0b000000
through the S-box of SPEEDY.

Cryptanalysis of SPEEDY
139
Algorithm 3: Sieving keys with the ﬁrst S-box
Input: (mi
0, mi
1); // The i-th row of the plaintext pair
Input: Δk; // The set of 6-bit keys
Input: δout; // The output difference for right pair
Output: Possible 6-bit keys for the i-th row with the corresponding
compressed internal state of pairs in S0
1;
1 function FirstSboxSieve(mi
0, mi
1, Δk,δout)
2
L ←∅;
3
for all ki ∈Δk do
4
x0 ←S-box(m0 ⊕ki);
5
x1 ←S-box(m1 ⊕ki);
6
if x0 ⊕x1 == δout then
7
Compress x0 by the active bits in δout;
8
Compress x1 by the active bits in δout;
9
L
∪
←−(x0, x1, ki);
10
if L == ∅then
11
Discard the 6-bit last round key for this (mi
0, mj
i) pair;
12
else
13
return L;
Data Collection. Consider structure S which consists of 2156 plaintexts and
for each plaintext pair P0, P1 ∈S, P0 ⊕P1 = (N, N, N, N, N, N, N, N, N, N, N,
N, N, 0, N, N, N, N, N, N, N, N, N, N, N, 0, 0, 0, 0, 0, N, N), where N denotes
any 6-bit cell. We require the oracle to encrypt those 2156 plaintexts and
collect the ciphertexts by the hash table which is indexed by the 156-bit
inactive bits in ciphertexts. From the hash table, we expect to get 2155
pairs of plaintext-ciphertext pair (P0, C0), (P1, C1) that satisfy C0 ⊕C1 =
(0, N, 0, N, 0, 0, 0, N, 0, 0, 0, 0, N, 0, 0, 0, N, 0, 0, 0, 0, 0, 0, 0, 0, N, 0, 0, 0, 0, 0, 0).
Next, we brieﬂy introduce the key recovery and brute force phases, the detail
of the pseudocode is shown in Appendix G. We use δi
in to denote the i-th row
of the input diﬀerence of the 5.5-round distinguisher.
Key Recovery. For each pair obtained from the data collection phase, we ﬁrst
use C0 ⊕C1 to deduce the 36-bit k7 from DDT. Note that, since we evaluate
the propagation probability of key-recovery rounds by FTDDT, the number of
deduced 36-bit k7 should be calculated by the inverse probability of FTDDT as
shown in Sect. 3.1. For each deduced 36-bit k7, we ﬁx the deduced keys in k0
from k7 due to the linear key schedule and guess other 144-bit k0 as follows.
Firstly, we use the early abort technique which is guessing the key-bits of
row 14,15,17 and partial encrypt to run FisrtSboxSieve. If there are no
satisﬁed key guesses to validate the output diﬀerence of the SubBox opera-
tion, we consider the 36-bit deduced k7 is wrong and discard it. If all the

140
J. Wang et al.
Algorithm 4: Sieving keys with the second S-box
Input: [Li, ..., Li+n−1]; // The sets obtained from FisrtSboxSieve or
SecondSboxSieve
Input: δout; // The output difference for right pair in S0
3
Output: The set of possible keys with the corresponding compressed internal
state of pairs in S0
3.
1 function SecondSboxSieve(mi
0, mi
1, Δk, δout)
2
L ←∅;
3
for all (xi
0, xi
1, ki) ∈Li do
4
for all (xi+n−1
0
, xi+n−1
1
, ki+n−1) ∈Li do
5
x0 ←ComActBit(xi
0, · · · xi+n−1
0
);
6
x1 ←ComActBit(xi
1, · · · xi+n−1
1
);
/* ComActBit function is used to combine the bits
propagated by the δout in (xi
t, · · · xi+n−1
t
) into xt
*/
7
y0 ←S-box(x0);
8
y1 ←S-box(x1);
9
if y0 ⊕y1 == δout then
10
key ←ki||...||ki+n−1;
11
x0 ←SaveBit(xi
0, · · · xi+n−1
0
);
12
x1 ←SaveBit(xi
1, · · · xi+n−1
1
);
/* SaveBit function is used to save the bits used in
the following algorithm
*/
13
L
∪
←−(x0, x1, key);
14
if L == ∅then
15
Discard the 6-bit last round key for this (mi
0, mj
i) pair;
16
else
17
return L;
deduced k7 are wrong, we consider this pair of plaintext-ciphertext is wrong
and discard it. Next, for each plaintext-ciphertext pair, we sieve k0 in row
11,12,13,16 with FisrtSboxSieve and partial encrypt to δ11
in with SecondS-
boxSieve. After this step, the plaintext-ciphertext pair and corresponding k0
can validate the input diﬀerence δ11
in. Similarly, we discard the deduced k7 if
there are no satisﬁed k0 guesses to validate δ11
in and discard the pair if no
deduced k7 is left. Then, we employed the same method to those deduced keys
in the row of k0 with FisrtSboxSieve and partial encrypt plaintext pairs to
δ14
in, δ15
in, δ18
in, δ19
in, δ7
in, δ5
in, δ4
in, δ3
in, δ2
in, δ1
in, δ30
in, δ29
in, δ21
in to further sieve with Sec-
ondSboxSieve.
Finally, it will leave 2135.46 pairs and 26.5 180-bit keys for each pair on aver-
age, and we will get 2141.96 candidate keys of this 180-bit master key for each
structure. Then, we use the brute force procedure to sieve the wrong candidate
keys.

Cryptanalysis of SPEEDY
141
Brute Force. For each candidate key from the key recovery procedure, we guess
the remaining 12-bit of the master key to get the complete 192-bit candidate
master key kc. Then we use a test pair (mt, ct) from encrypt oracle to check if
Ekc(mt) = ct to verify if kc is the right key.
Complexity and Success Probability. Since the memory access of storing
the ciphertexts to the hash table is negligible compared to the time for collecting
the ciphertexts, the time complexity of data collection for each structure is 2156.
Since the hash table storing 2155 pairs is very large, we treat the time to access
this table as one encryption. Further, since the 7-round SPEEDY encryption has
7 × 2 × 32 = 448 SubBox operations, the time complexity of the key recovery
phase is less than 2155 + (70 × 2155)/448 for each structure (details are shown in
Appendix H). Then, the time complexity of Brute Force phase is 2151.96 times 7-
round SPEEDY encryption for each structure. Overall, the total time complexity
of each structure is 2156 + 2155 + (70 × 2155)/448 + 2153.96 ≈2156.86 7-round
SPEEDY encryptions.
The signal-to-noise-ratio is Using 2185.53/2155 ≈230.53 structures, we can
ensure the success rate of 79.15% with 7.51-bit advantage according to [17].
Hence, the data complexity is 2186.53, the time complexity is 230.53 × 2156.86 ≈
2187.39 and the memory required is 2156.
Reducing Memory Requirement. The above attack require 2156 bits in
memory, which is too large. To obtain lower memory complexity, we can use
the chosen ciphertext attack mode and select the active 36-bit structure at the
ciphertext. After using the inactive 36 bits in the plaintext as the index, we get
235 pairs, and then one can follow the key recovery procedure used in the above
attack to obtain the right key.
5.2
7-Round Linear Attack Against Full SPEEDY
With the 5-round linear distinguisher shown in Appendix I, we compute the
attack parameter on SPEEDY-7-192 using the symbols borrowed from [7]. With the
FWT approach in [7], the time complexity is 2(ρM +ρA)2|k0|+|k7|−l07, where the
|ki| means the bit number guessed in ki, and l07 means the key bits of k7 deduced
from k0. Following the notation in [7], ρA is the cost of an addition, and ρM is the
cost of a multiplication. Assuming that two multiplications correspond to roughly
one evaluation of the cipher, we have the time complexity of key recovery phase
2186 encryptions. The memory required is 2144 +2180 +2185 ≈2185.04. According
to [17], we need 2188.50 data and the advantage a = 4 to achieve the success rate
69.12%. Finally, we exhaustively search the remaining 7 key bits. The total time
complexity of the attack is 2188.50 + 2186 + 2188 ≈2189.41.
5.3
4-Round Diﬀerential Attack Against SPEEDY.
As shown in Appendix J, we choose ciphertexts in S3
3 to make a 60-bit structure
and ﬁlter the corresponding plaintext pairs in S2
0. After running this step, it will

142
J. Wang et al.
leave
260
2

/236 ≈283 pairs. Then, we sieve the key bits of the 108-bit involved
k4 according to the 283 pairs and leave 243.692 possible k4 for each pair. Then,
for the combination of these 283 × 243.692 = 2126.692 plaintext-ciphertext pairs
and corresponding key guesses, we guess the 156-bits k0 using the method in
Sect. 5.1.
Due to the diﬀerential probability being 2−59.35 and one structure can only
provide 260 data, we construct two structures to collect the data. The data
complexity of this attack is 261, the time complexity is 2119.692 and the memory
required is 283. With above attack parameters, the success rate is 94.17%.
5.4
4-Round Diﬀerential-Linear Attack Against SPEEDY
With the distinguisher searching in Sect. 4.3, we obtain a 4-round diﬀerential-
linear attack against SPEEDY with 261 data complexity 2105 time complexity and
2105 memory requirement. The detail of this attack is shown in Appendix F.
6
Conclusion
In this paper, we ﬁrst show how to ﬁnd key-recovery friendly distinguishers for
SPEEDY by following the divide-and-conquer strategy as well as some other new
techniques. With such strategies, we found a 5.5-round diﬀerential distinguisher
which is key-recovery friendly and with higher probability than the one used
in the previous result. Using this distinguisher, we are able to mount the ﬁrst
chosen-plaintext full-round attack on SPEEDY-7-192. Besides, with the same dis-
tinguisher, we can also mount a full-round attack under the chosen-ciphertext
setting, which slightly reduces the attack complexities compared with the previ-
ous one proposed in the same setting. Meanwhile, using a similar search strategy,
we also found a 5-round linear distinguisher which leads to the ﬁrst known-
plaintext full-round attack. Although the full-round security of this variant has
recently been announced to be broken, our attacks here need a weaker abil-
ity requirement for the adversary. Besides, for SPEEDY-5-192, which requires
more restricted attack parameters, we also propose two 4-round key recovery
attacks using a diﬀerential distinguisher and a diﬀerential-linear one, respec-
tively. According to our best knowledge, both attacks are the best ones on this
variant in terms of the number of rounds. However, its full-round security is not
threatened.
Acknowledgements. The authors would like to thank the anonymous reviewers for
their valuable comments and suggestions to improve the quality of the paper. This work
is supported by the National Key Research and Development Program of China (Grant
No. 2018YFA0704702), the National Natural Science Foundation of China (Grant No.
62032014), the Major Basic Research Project of Natural Science Foundation of Shan-
dong Province, China (Grant No. ZR202010220025). The corresponding author is also
supported by Qingdao Innovation project (Grant No. QDBSH20230101008).

Cryptanalysis of SPEEDY
143
A
The 6-Bit S-Box of SPEEDY
(See Table 3).
Table 3. The 6-bit S-box of SPEEDY. All elements are expressed in hexadecimal.
x0x1
x2x3x4x5
0
1
2
3
4
5
6
7
8
9
a
b
c
d
e
f
0
08 00 09 03 38 10 29 13 0c
0d 04 07 30 01 20 23
1
1a 12 18 32 3e 16 2c 36 1c
1d 14 37 34 05 24 27
2
02 06 0b 0f
33 17 21 15 0a 1b 0e 1f
31 11 25 35
3
22 26 2a 2e 3a 1e 28 3c 2b 3b 2f
3f
39 19 2d 3d
B
Experiment to Verify the Correctness of FTDDT
In this section, we conducted an experiment to calculate the probability of prop-
agation to verify the correctness of FTDDT. For several random-chosen ﬁxed-
input diﬀerences δin, we tested the transfer probability from a single diﬀerence
δin (shown in the left-hand side of Eq. 4) to a set of diﬀerences Δout (shown in
the right-hand side of Eq. 4) in the S-box used in SPEEDY.
More precisely, we randomly choose 220 42-bit plaintexts p and denote the
number of p that satisﬁes {S-box(p) ⊕S-box(p ⊕δin) ∈Δout} as N. Then the
probability obtained from this test is N/220.
010000
SB
−→**0***
010000
SB
−→****00
010000
SB
−→0*****
001000
SB
−→00****
(4)
001000
SB
−→****00
000100
SB
−→***0**
000100
SB
−→0**0**
Our validation algorithm is written in python code and we run it on an
Intel(R) Core(TM) i7-8700 CPU. Finally, the tested probability is 2−5.9671 while
the transfer probability caculated from FTDDT is 2−5.9622. Therefore, we con-
sider that the accuracy obtained by FTDDT is veriﬁed.

144
J. Wang et al.
C
Inverse Probability of FTDDT
Theorem 1. When considering a ﬁxed diﬀerence δout ⪯Δout propagate to
δin which is the inverse of FTDDT[δin][BΔout], the average probability of this
transition is
FTDDT[δin][BΔout]/2N+Na.
Proof. Since the S-box is bijective, the inverse probability of FTDDT is equal
to the average probability of δin
SB
−→δout (averaged over all δout ∈Δout). Next,
remember that the FTDDT describes the probability of a group of diﬀerential
transition. Thus, with this probability, we can obtain the average probability
of δin
SB
−→δout, δout ⪯Δout by dividing by the size of the output diﬀerential
set |Δout|. The probability of the case δin
SB
−→Δout is FTDDT[δin][BΔout]/2N
and the number of diﬀerence in Δout is 2Na. Thus, the probability of the case
δin
SB
−→δout is FTDDT[δin][BΔout]/2n+Na on average if δout ∈Δout.
⊓⊔
D
Searching Linear Distinguishers Against SPEEDY
Since the MC operation can be seen as Γin = MT ·Γout in linear attack where Γin
is the input mask and Γout is the output mask of matrix M. Following the method
in Sect. 3.2, we get the linear mask transition properties for MC, precisely, the
correspondence between the input mask Γin and the output mask Γout of the
minimum HW.
For linear cryptanalysis, we use a similar strategy used for diﬀerential search,
which is a model oriented toward key recovery. Then, we search for a ﬁve-round
distinguisher with two rounds of key recovery by following four steps.
Step 1: We found the 4-round distinguishers from S0
3 to S5
0 using the same
method in searching diﬀerentials.
Step 2: For each of the 4-round linear distinguishers, we found the distinguishers
with two rounds of key recovery from S5
0 to S6
2 according to the following
conditions: the probability from S5
0 to S6
0 is as high as possible and after
spreading from S6
0 to S6
2 with probability one, the active S-box number in S6
2
is less than 32.
Step 3: Then, the linear mask propagates from S0
3 to S0
1 with probability one
and limits the number of active S-box at S0
1 is less than 32.
Step 4: Finally, we consider the linear rotation invariant of the 7-round distin-
guishers combined with key recovery and choose the case where the number
of bits of k7 deduced from k0 by linear key schedule is maximized.
Following step one to four, we found a 5-round distinguisher combined two
key recovery rounds with correlation 2−93.01. We show the detail of the linear
distinguisher in Appendix I. In this distinguisher, the bits of k7 which is derived
from k0 by linear key schedule is 139. We reduce the guessed key bits to 185 bits
in the key recovery phase.

Cryptanalysis of SPEEDY
145
E
Searching Diﬀerential-Linear Distinguishers Against
SPEEDY
We show the four rounds diﬀerential-linear search model in Fig. 4. More specif-
ically, we search for three rounds of diﬀerential-linear distinguishers from S0
4 to
S4
0 and extend half a round forward and backward for key recovery. Detailed
strategy is as follows.
SB
SC
MC
Key 
Recovery
SB
SC
SB
SC
MC
2-nd
round
SB
SC
SB
SC
MC
3-rd
round
SB
Key 
Recovery
SB
SC
SB
SC
MC
1-st
round
0
2
S
0
3S
0
4
S
1
1S
1
0
S
1
2
S
1
3S
1
4
S
2
0
S
2
1S
2
2
S
2
3S
2
4
S
3
0
S
3
1S
3
2
S
3
3S
3
4
S
4
0
S
4
1S
Fig. 4. 4-round diﬀerential-linear attack model of SPEEDY.
Step 1: We search the diﬀerential part contains key recovery rounds from S0
3
to S1
4, the search strategies are as follows.
Rule 1: Constrain the active bit numbers in S0
3 less than 64.
Rule 2: Model S0
3
SB−1
−→S0
2 to comply with FTDDT.
Rule 3: Model S1
0
SB
−→S1
1, S1
2
SB
−→S1
3 to comply with DDT.
Rule 4: Constrain only one bit active in S1
4.
Step 2: Meanwhile, we search the linear part contains key recovery rounds from
S3
0 to S4
0, the search strategies are as follows.
Rule 1: Constrain only one bit active in S3
0.
Rule 2: Model S3
0
SB
−→S3
1, S3
2
SB
−→S3
3 to comply with LAT (short for linear
approximation table).
Rule 2: Model the active S-box in S4
0 to comply with a maximum correlation
of 2−1.415.
Step 3: We search the connect round from S1
4 to S3
0 as follows.
Rule 1: Constrain only one bit active in S1
4 and S3
0.
Rule 2: Model S2
0
SB
−→S2
1 with backward FTDDT.
Rule 3: Model S2
2
SB
−→S2
3 to comply with LAT.
Rule 4: Constrain the diﬀerence of the i-th row in S2
2 is zero if the diﬀerence
of corresponding row in S2
2 is active.

146
J. Wang et al.
Step 4: From Step one to three, we get several distinguishers. Then, we choose
the one with the highest correlation and run an experiment for obtaining
the estimated correlation from S1
2 to S3
1. After testing 128 random keys with
230 plaintexts under a certain key, we obtained the correlation estimated as
2−8.85.
Step 5: Finally, we consider the rotation invariant property of SPEEDY such that
the bits of k7 deduced from k0 by linear key schedule are maximized.
Finally, the distinguisher is shown in Fig. 5. The correlation of this 3-round
distinguisher is 2−23.095 and the probability of rounds of key-recovery is 2−6.972.
The bits of k7 deduced from k0 by linear key schedule are 29.
F
4-Round Diﬀerential-Linear Attack Against SPEEDY
SB
SB
SC
SC
MC
MC
SB
SB
SB
SB
SC
SC
SB
SB
SC
SC
MC
MC
SB
SB
SC
SC
MC
MC
SB
SB
SC
SC
SB
SB
SC
SC
SB
SB
SC
SC
MC
MC
0
2
S
0
3
S
0
4
S
1
0
S
1
1
S
1
2
S
1
3
S
1
4
S
2
0
S
2
1
S
2
2
S
2
3
S
2
4
S
3
0
S
3
1
S
3
2
S
3
3
S
3
4
S
4
0
S
4
1
S
k0
P
C
k5
Fig. 5. Key recovery attack on 4-round SPEEDY with diﬀerential-linear cryptanalysis.
With the 3-round diﬀerential-linear distinguisher shown in Fig. 5, we can imple-
ment the diﬀerential-linear attack against 4-round SPEEDY. Firstly, we choose
the active bits in plaintext to make a 61-bit structure and obtain corresponding

Cryptanalysis of SPEEDY
147
ciphertexts. After guessing the 61-bit k0, we use Algorithm 5 to put the pairs that
can validate the input diﬀerence of the 3-round diﬀerential-linear distinguisher
into the set S. Then we recover the master key by applying the FWHT (short
for Fast Walsh-Hadamard Transform) which has already been used in [3].
Since the time complexity of the Algorithm 5 is negligible compared to those
of FWHT, we use the same computing method for our attack. Then, we choose
the advantage a = 88, use one structure to collect data, the time complexity
of this attack is 261 + 2104 + 2104 ≈2105. The data complexity is 261 and the
memory required is 261 +272 +2105 ≈2105. We denote |S| as the number of pairs
in S, according to [17] the distribution of |S| is
|S| ∼1
2N(261 · 2−6.972, 261 · 2−6.972) = N(253.028, 252.028).
Then, the success rate is
PS =
 +∞
0
P(|S| = x) · PS′(|S| = x)dx
≥P(|S| ≥253.027) · PS′(|S| = 253.027)
≈45.31%,
where PS′(|S| = n) is the success rate for this attack, if |S| = n.
Algorithm 5: Sieving pairs for diﬀerential-linear attack
Input: P; // The set of plaintexts
Input: C; // The set of ciphertexts indexed by plaintexts
Input: k; // The guessed 61-bit k0
Input: δin; // The begin of differential-linear distinguisher
Output: S; // The set of pairs can encrypt to the begin of
differential-linear distinguisher by k
1 S ←∅;
2 for p ∈P do
3
p′ ←D(E(p ⊕k) ⊕δin) ⊕k ;
/* E(·) is the function encrypt plaintext to the begin of
distinguisher
*/
/* D(·) is the decrypt function of E(·)
*/
4
c ←C[p];
5
c′ ←C[p′];
6
S
∪
←−((p, c), (p′, c′));
7 Delete duplicate pairs in S;
8 return S;

148
J. Wang et al.
G
Pseudocode of Key Recovery and Brute Force Parts
on the 2155 Pairs for Each Structure in the 7-Round
Diﬀerential Attack
Algorithm 6: Deduce key from the data set P
Input: P; // The set of 2155 pairs, each pair consist of two
plaintexts with their ciphertexts
Input: δout; // The output difference of the 5.5-round
distinguisher
Input: δi
in; // The input difference of the i-th row of
5.5-round distinguisher
Input: (mt, ct); // ct is the ciphertext of mt. At the end of
this algorithm, we use it to test if the candidate keys
are the right key.
Output: K; // The set of possible full master key
1 K ←∅;
2 for ((m0, c0), (m1, c1)) ∈P do
3
m0
0||...||m31
0 ←DividePlain(m0);
4
m0
1||...||m31
1 ←DividePlain(m1);
/* DividePlain(mi) is use to divide plaintext mi into 32
row, mj
i is the 6-bit j-th row of mi
*/
5
K7 ←Deduce the 36-bit k7 by m0 ⊕m1 and δout according to DDT;
// |K7| = 4 on average for each pair, details are shown
in Appendix H.
6
for k7 ∈K7 do
7
Deduce the k0 from k7 due to the linear key schedule;
8
For i-th row of k0, ﬁx the deduced bits and traverse other bits to
get set K0
i , i = 0, · · · , 26, 29, 30, 31;
9
L14 ←FirstSboxSieve(m14
0 , m14
1 , K0
14,0b*00*00);
10
L15 ←FirstSboxSieve(m15
0 , m15
1 , K0
15,0b**00*0);
11
L17 ←FirstSboxSieve(m17
0 , m17
1 , K0
17,0b00**00);
12
L11 ←FirstSboxSieve(m11
0 , m11
1 , K0
11,0b*000*0);
13
L12 ←FirstSboxSieve(m12
0 , m12
1 , K0
12,0b0*000*);
14
L13 ←FirstSboxSieve(m13
0 , m13
1 , K0
13,0b******);
15
L16 ←FirstSboxSieve(m16
0 , m16
1 , K0
16,0b0**00*);
16
L ←SecondSboxSieve([L11, L12, L13, L14, L15, L16], δ11
in);
17
L18 ←FirstSboxSieve(m18
0 , m18
1 , K0
18,0b*00**0);
18
L19 ←FirstSboxSieve(m19
0 , m19
1 , K0
19,0b**000*);
19
L ←SecondSboxSieve([L, L17, L18, L19], δ14
in);
20
L20 ←FirstSboxSieve(m20
0 , m20
1 , K0
20,0b0**00*);
21
L ←SecondSboxSieve([L, L20], δ15
in);

Cryptanalysis of SPEEDY
149
22
23
24
L21 ←FirstSboxSieve(m21
0 , m21
1 , K0
21,0b*0**00);
25
L22 ←FirstSboxSieve(m22
0 , m22
1 , K0
22,0b0*0**0);
26
L23 ←FirstSboxSieve(m23
0 , m23
1 , K0
23,0b00*0**);
27
L ←SecondSboxSieve([L, L21, L22, L23], δ18
in);
28
L24 ←FirstSboxSieve(m24
0 , m24
1 , K0
24,0b000*0*);
29
L ←SecondSboxSieve([L, L24], δ19
in);
30
L7 ←FirstSboxSieve(m7
0, m7
1, K0
7,0b*0****);
31
L8 ←FirstSboxSieve(m8
0, m8
1, K0
8,0b0*0***);
32
L9 ←FirstSboxSieve(m9
0, m9
1, K0
9,0b00*0**);
33
L10 ←FirstSboxSieve(m10
0 , m10
1 , K0
10,0b000*0*);
34
L ←SecondSboxSieve([L7, L8, L9, L10, L], δ7
in);
35
L5 ←FirstSboxSieve(m5
0, m5
1, K0
5,0b*****0);
36
L6 ←FirstSboxSieve(m6
0, m6
1, K0
6,0b0*****);
37
L ←SecondSboxSieve([L5, L6, L], δ5
in);
38
L4 ←FirstSboxSieve(m4
0, m4
1, K0
4,0b****00);
39
L ←SecondSboxSieve([L4, L], δ4
in);
40
L3 ←FirstSboxSieve(m3
0, m3
1, K0
3,0b***00*);
41
L ←SecondSboxSieve([L3, L], δ3
in);
42
L2 ←FirstSboxSieve(m2
0, m2
1, K0
2,0b**00**);
43
L ←SecondSboxSieve([L2, L], δ2
in);
44
L1 ←FirstSboxSieve(m1
0, m1
1, K0
1,0b*00**0);
45
L ←SecondSboxSieve([L1, L], δ1
in);
46
L30 ←FirstSboxSieve(m30
0 , m30
1 , K0
30,0b**0000);
47
L31 ←FirstSboxSieve(m31
0 , m31
1 , K0
31,0b0**000);
48
L0 ←FirstSboxSieve(m0
0, m0
1, K0
0,0b00**00);
49
L ←SecondSboxSieve([L30, L31, L0, L], δ30
in);
50
L29 ←FirstSboxSieve(m29
0 , m29
1 , K0
29,0b******);
51
L ←SecondSboxSieve([L29, L], δ29
in);
52
L25 ←FirstSboxSieve(m25
0 , m25
1 , K0
25,0b******);
53
L26 ←FirstSboxSieve(m26
0 , m26
1 , K0
26,0b******);
54
L ←SecondSboxSieve(L, L25, L26], L21);
55
for k′ ∈L do
56
for k′′ traverse unguessed 12-bit keys do
57
Combine k′ and k′′ to get the 192-bit keys k;
58
if E(mt, k) == ct then
59
K
∪
←−k;
60 return K as the set of candidate keys;

150
J. Wang et al.
H
Details for the Time Complexity of the Key Recovery
on the 2155 Pairs for Each Structure in the 7-Round
Diﬀerential Attack
In this section, we mainly consider the time of operating the Algorithm 6 in
Appendix G. In order to make it easier to understand, we show the details of
each step in Algorithm 6 in Table 4.
Position in Table 4 denotes the location in Algorithm 6, e.g., position 9
denotes the operation that generates L14 at line 9 in Algorithm 6. The ﬁltering
probability of FirstSboxSieve is determined by the number of inactive bits in
the output of the S-box, e.g., when generating the L14, the output diﬀerent set of
the S-box is 0b*00*00 so that the ﬁltering probability is 2−4 while the ﬁltering
probability of SecondSboxSieve is calculated by the inverse probability of
FTDDT.
Besides, to facilitate the calculation of the time complexity, we see the 2155
pair of each structure as a group. Then, we compute the time complexity of
each operation in Algorithm 6 in this group. More precisely, we introduce two
new parameters, i.e., the number of the remaining pairs and the number of
remaining keys for each pair. Further, for an operation with ﬁltering probability
p, the number of the remaining pairs and remaining keys before this operation is
Np and Nk, respectively. Besides, we use Na to denote the number of imported
keys in this operation. For the FisrtSboxSieve operation, Ik is the number of
keys in the input key set, e.g., |K0
14| in position 9. For the SecondSboxSieve
operation, Ia is zero. Then, the complexity of this operation for the whole group
in this operation, the remaining pairs and the remaining keys after this operation
is calculated by Algorithm 7.
In fact, the sum of the time complexity in Table 4 is about 68.8 × 2155 times
SubBox operation. Since there are other operations that have not been evaluated,
we give a generous estimate for the complexity of the key recovery phase, i.e.,
70 × 2155 times SubBox operation.
Evaluation the Number of Elements in K7. In this section, we use Si
j[k, :
] to denote the k-th line in the Si
j, i.e., the 6k-th bit to (6k + 5)-th bit of
Si
j. As shown in Fig. 3, there are only two active diﬀerences transitioning to a
set of diﬀerences through the process S6
0
SB
−→S6
1, i.e., the S6
0[3, :]
SB
−→S6
1[3, :
] (0b000010
SB
−→0b*0*000) and S6
0[6, :]
SB
−→S6
1[6, :] (0b000010
SB
−→0b000*0*).
Other active diﬀerences propagate to a single diﬀerence.
Therefore, when deducing the key bits of k7 by DDT (position 5 in Algorithm
6), on average, there is only one 6-bit partial key will be deduced for the states
k7[i, :], where i ∈{7, 2, 16, 25} since the corresponding diﬀerence in S6
2 is a spe-
ciﬁc single diﬀerence. However, k7[1, :] and k7[3, :] will have several possibilities
since the corresponding state S6
2[1, :] and S6
2[3, :] are sets of diﬀerences. Thus,
the average number of elements in K7 is determined by the average number of
deduced k7[1, :] and k7[3, :].

Cryptanalysis of SPEEDY
151
Algorithm 7: Compute parameters in Table 4.
Input: Ik: the number of imported keys in this operation.
Input: Np: the number of remaining pairs before this operation.
Input: Nk: the number of remaining keys before this operation.
Input: p: the number of remaining keys before this operation.
Output: T: time complexity of this operation.
Output: Np: the number of remaining pairs after this operation.
Output: Nk: the number of remaining keys after this operation.
1 if This operation is FirstSboxSieve then
2
T ←2 × Ik × Np;
// Each pair has two plaintexts so that need two SubBox operation
for an imported key.
3
if Ik × p ≥1 then
4
Nk ←Nk × Ik × p;
5
Np ←Np;
6
if Ik × p < 1 then
7
Nk ←Nk;
8
Np ←Np × Ik × p;
9 if This operation is SecondSboxSieve then
10
T ←2 × Nk × Np;
11
if Nk × p ≥1 then
12
Nk ←Nk × p;
13
Np ←Np;
14
if Nk × p < 1 then
15
Nk ←1;
16
Np ←Np × Nk × p;
17 return T, Np, Nk;
Note that the state S6
2[1, :] and S6
2[3, :] are propagated by S6
1[3, :] and S6
1[6, :]
while the state S6
1[i, :] is propagated by S6
0[i, :] through the S-box. Thus, we did
an in-depth study of the propagation S6
0[i, :]
SB
−→S6
0[i, :], where i ∈{3, 6}.
– In our trail, the S6
0[3, :]
SB
−→S6
0[3, :] will have two cases since the propagation
0b000010
SB
−→0b*0*000 have two possible propagations, i.e., 0b000010
SB
−→
0b100000 and 0b000010
SB
−→0b001000 (indeed, there are four cases for this
propagation, but other two cases have zero probability).
– For the same reason, the S6
0[6, :]
SB
−→S6
0[6, :] also has two cases.

152
J. Wang et al.
Above all, there are 2 × 2 = 4 possible cases for the propagation of the two
active S-boxes and each case will deduce one possible 12-bit keys for k7. Besides,
each case needs two Subox operations. Thus, the average number of elements
in K7 is and the time complexity of deducing 36-bit k7 is 4 × 2 + 4 = 12 times
SubBox operation.
Table 4. Details for the Time Complexity of Algorithm 6. The set parameter is the
output of the operation, e.g., L14 for position 9. The time complexity is measured
by the SubBox operation. Ik is the number of imported keys in this operation. Np
and Nk are the number of the remaining pairs and remaining keys after the operation
calculated by Algorithm 7.
Position set
Ik Time
complexity
Filtering
probability
Np
Nk
5
K7
–
12 × 2155
1
2155
4
9
L14 22 2158
2−4
2155
1
10
L15 22 2158
2−3
2154
1
11
L17 23 2158
2−4
2153
1
12
L11 24 2158
2−4
2153
1
13
L12 24 2158
2−4
2153
1
14
L13 23 2157
1
2153
23
15
L16 23 2157
2−3
2153
23
16
L
0
2157
2−5.54
2150.46 1
17
L18 24 2155.46
2−3
2150.46 2
18
L19 24 2155.46
2−2
2150.46 23
19
L
0
2154.46
2−6
2147.46 1
20
L20 24 2152.46
2−3
2147.46 2
21
L
0
2149.46
2−6
2142.46 1
24
L21 25 2148.46
2−3
2142.46 22
25
L22 26 2149.46
2−3
2142.46 25
26
L23 26 2149.46
2−3
2142.46 28
27
L
0
2151.46
2−6
2142.46 22
28
L24 26 2149.46
2−4
2142.46 24
29
L
0
2147.46
2−6
2140.46 1
30
L7
25 2146.46
2−1
2140.46 24
31
L8
26 2147.46
2−2
2140.46 28
32
L9
25 2146.46
2−3
2140.46 210
(continued)

Cryptanalysis of SPEEDY
153
Table 4. (continued)
Position set
Ik Time
complexity
Filtering
probability
Np
Nk
33
L10 25 2146.46
2−4
2140.46 211
34
L
0
2152.46
2−6
2140.46 25
35
L5
25 2146.46
2−1
2140.46 29
36
L6
25 2146.46
2−1
2140.46 213
37
L
0
2154.46
2−6
2140.46 27
38
L4
25 2146.46
2−2
2140.46 210
39
L
0
2151.46
2−6
2140.46 24
40
L3
25 2146.46
2−2
2140.46 27
41
L
0
2148.46
2−6
2140.46 2
42
L2
26 2147.46
2−2
2140.46 25
43
L
0
2146.46
2−6
2139.46 1
44
L1
25 2145.46
2−3
2139.46 22
45
L
0
2142.46
2−6
2135.46 1
46
L30 26 2142.46
2−4
2135.46 22
47
L31 26 2142.46
2−4
2135.46 24
48
L0
26 2142.46
2−4
2135.46 26
49
L
0
2142.46
2−6
2135.46 1
50
L29 26 2142.46
1
2135.46 26
51
L
0
2142.46
2−5.83
2135.46 20.17
52
L25 26 2142.46
1
2135.46 26.17
53
L26 26 2142.46
1
2135.46 212.17
54
L
0
2148.63
2−5.67
2135.46 26.5

154
J. Wang et al.
I
Key Recovery Attack Against 7-Round SPEEDY
with Linear Cryptanalysis
(See Fig. 6).
Fig. 6. Key recovery attack on 7-round SPEEDY with linear cryptanalysis.

Cryptanalysis of SPEEDY
155
J
Key Recovery Attack against 4-Round SPEEDY
with Diﬀerential Cryptanalysis
(See Fig. 7).
2-0.54
2-1.67
2-0.83
2-4
2-3
2-3
2-3
2-3
2-3
2-3
2-3
2-3
2-3
2-3
2-3
2-3
2-3
2-3
2-3
2-3
2-0.476
2-1.678
2-0.476
2-1.678
SB
SB
SC
SC
SB
SB
SC
SC
MC
MC
0
0
S 0
0
S
0
1
S 0
1
S
0
2
S 0
2
S
0
3
S 0
3
S
0
4
S 0
4
S
1
0
S1
0
S
1
1
S1
1
S
1
2
S1
2
S
1
3
S1
3
S
1
4
S1
4
S
SB
SB
SC
SC
SB
SB
SC
SC
MC
MC
MC
MC
2
0
S 2
0
S
2
1
S 2
1
S
2
2
S 2
2
S
2
3
S 2
3
S
2
4
S 2
4
S
3
0
S 3
0
S
3
2
S 3
2
S
3
1
S 3
1
S
3
3
S 3
3
S
SB
SB
SC
SC
SB
SB
SC
SC
SB
SB
SB
SB
SC
SC
SC
Fig. 7. Key recovery attack on 4-round SPEEDY with diﬀerential cryptanalysis.
References
1. Bar-On, A., Dunkelman, O., Keller, N., Weizman, A.: DLCT: a new tool for
diﬀerential-linear cryptanalysis. In: Ishai, Y., Rijmen, V. (eds.) EUROCRYPT
2019. LNCS, vol. 11476, pp. 313–342. Springer, Cham (2019). https://doi.org/
10.1007/978-3-030-17653-2 11
2. Barrett, C., Tinelli, C.: Satisﬁability modulo theories. In: Clarke, E., Henzinger, T.,
Veith, H., Bloem, R. (eds.) Handbook of Model Checking, pp. 305–343. Springer,
Cham (2018). https://doi.org/10.1007/978-3-319-10575-8 11
3. Beierle, C., Leander, G., Todo, Y.: Improved diﬀerential-linear attacks with appli-
cations to ARX ciphers. In: Micciancio, D., Ristenpart, T. (eds.) CRYPTO 2020,
Part III. LNCS, vol. 12172, pp. 329–358. Springer, Cham (2020). https://doi.org/
10.1007/978-3-030-56877-1 12
4. Biham, E., Shamir, A.: Diﬀerential cryptanalysis of des-like cryptosystems. J.
Cryptol. 4(1), 3–72 (1991)
5. Boura, C., David, N., Boissier, R.H., Naya-Plasencia, M.: Better steady than
speedy: full break of speedy-7-192. Cryptology ePrint Archive, Paper 2022/1351
(2022)

156
J. Wang et al.
6. Fan, Y., Li, M., Niu, C., Lu, Z., Wang, M.: Related-tweakey impossible diﬀerential
attack on reduced-round SKINNY-AEAD M1/M3. In: Galbraith, S.D. (ed.) CT-RSA
2022. LNCS, vol. 13161, pp. 247–271. Springer, Cham (2022). https://doi.org/10.
1007/978-3-030-95312-6 11
7. Fl´orez-Guti´errez, A., Naya-Plasencia, M.: Improving key-recovery in linear attacks:
application to 28-round PRESENT. In: Canteaut, A., Ishai, Y. (eds.) EURO-
CRYPT 2020. LNCS, vol. 12105, pp. 221–249. Springer, Cham (2020). https://
doi.org/10.1007/978-3-030-45721-1 9
8. Langford, S.K., Hellman, M.E.: Diﬀerential-linear cryptanalysis. In: Desmedt, Y.G.
(ed.) CRYPTO 1994. LNCS, vol. 839, pp. 17–25. Springer, Heidelberg (1994).
https://doi.org/10.1007/3-540-48658-5 3
9. Leander, G., Moos, T., Moradi, A., Rasoolzadeh, S.: The speedy family of block
ciphers - engineering an ultra low-latency cipher from gate level for secure processor
architectures. Cryptology ePrint Archive, Paper 2021/960 (2021)
10. Li, M., Hu, K., Wang, M.: Related-tweak statistical saturation cryptanalysis and
its application on QARMA. Cryptology ePrint Archive (2019)
11. Liu, Y., Wang, Q., Rijmen, V.: Automatic search of linear trails in ARX with
applications to SPECK and chaskey. In: Manulis, M., Sadeghi, A.-R., Schneider, S.
(eds.) ACNS 2016. LNCS, vol. 9696, pp. 485–499. Springer, Cham (2016). https://
doi.org/10.1007/978-3-319-39555-5 26
12. Longo, G., Zilli, M.V.: Complexity of theorem-proving procedures: some general
properties. Revue fran¸caise d’automatique inf. recherche op´e. Inf. th´eorique 8(R3),
5–18 (1974)
13. Matsui, M.: Linear cryptanalysis method for DES cipher. In: Helleseth, T. (ed.)
EUROCRYPT 1993. LNCS, vol. 765, pp. 386–397. Springer, Heidelberg (1994).
https://doi.org/10.1007/3-540-48285-7 33
14. Niu, C., Li, M., Sun, S., Wang, M.: Zero-correlation linear cryptanalysis with equal
treatment for plaintexts and tweakeys. In: Paterson, K.G. (ed.) CT-RSA 2021.
LNCS, vol. 12704, pp. 126–147. Springer, Cham (2021). https://doi.org/10.1007/
978-3-030-75539-3 6
15. Qin, L., Dong, X., Wang, X., Jia, K., Liu, Y.: Automated search oriented to
key recovery on ciphers with linear key schedule: applications to boomerangs in
SKINNY and ForkSkinny. IACR Trans. Symmetric Cryptol. 2021(2), 249–291
(2021)
16. Rohit, R., Sarkar, S.: Cryptanalysis of reduced round speedy. Cryptology ePrint
Archive (2022)
17. Sel¸cuk, A.A.: On probability of success in linear and diﬀerential cryptanalysis. J.
Cryptol. 21(1), 131–147 (2008)
18. Zhou, C., Zhang, W., Ding, T., Xiang, Z.: Improving the MILP-based security
evaluation algorithm against diﬀerential/linear cryptanalysis using a divide-and-
conquer approach. Cryptology ePrint Archive (2019)

Reconsidering Generic Composition: The
Modes A10, A11 and A12 are Insecure
Francesco Berti(B)
Bar-Ilan University, 529002 Ramat-Gan, Israel
francesco.berti@biu.ac.il
Abstract. Authenticated Encryption (AE) achieves privacy and authen-
ticity with a single scheme. It is possible to obtain an AE scheme gluing
together an encryption scheme (privacy secure) and a Message Authenti-
cation Code (authenticity secure). This approach is called generic compo-
sition and its security has been studied by Namprempre et al. [20]. They
looked into all the possible gluings of an encryption scheme with a secure
MAC to obtain a nonce-based AE-scheme. The encryption scheme is either
IV-based (that is, with an additional random input, the initialization vec-
tor [IV]) or nonce-based (with an input to be used once, the nonce). Nam-
premepre et al. assessed the security/insecurity of all possible composition
combinations except for 4 (N4, A10, A11 and A12). Berti et al. [9] showed
that N4 is insecure and that the remaining modes (A10, A11, and A12)
are either all secure or insecure.
Here, we prove that these modes are all insecure with a counter-
example.
Keywords: AE · generic composition · integrity
1
Introduction
Privacy and authenticity are two of the most important goals of cryptography.
Encryption schemes provide privacy, that is, no information about a plaintext
(except its length) can be obtained from a ciphertext encrypting it; while Mes-
sage Authentication Codes (MAC) provide authenticity, that is, it is not pos-
sible to send a message impersonating another person. Authenticated Encryp-
tion (AE) is the cryptographic primitive that provides both. In addition, AE
allows the presence of Associated Data (AD), which are data sent in clear but
authenticated. This primitive is the object of ﬂourishing research from the sem-
inal papers [3,4,24,26], with many constructions proposed, see for example [11–
13,15,23,25] and the CAESAR competition [1,7]. Moreover, there is an ongoing
NIST competition for a lightweight AE scheme [21], whose ﬁnalists have been
announced [22] and whose winner is ASCON [14]. See [16] for a survey of the
AE-literature.
F. Berti–Work done when this author was at TU Darmstadt, Germany, CAC - Applied
Cryptography.
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 157–176, 2023.
https://doi.org/10.1007/978-3-031-35486-1_8

158
F. Berti
It is possible to design an AE-scheme from scratch (as the case of OCB [25],
for example) or to combine an encryption scheme with a MAC. This second
approach is called generic composition [3].
About generic composition, the ﬁrst result is the well-known “Encrypt-then-
MAC is secure” [6,18]. Namprempre et al. [20] studied thoroughly the generic
composition problem. They realised that while the ﬁrst result [6,18] assumed
that the encryption scheme is probabilistic, the literature moved to IV-based or
nonce-based encryption schemes [17,26]. Since probabilistic encryption schemes
are hard to design, we usually use a deterministic encryption scheme and provide
the random coins needed externally with an initialization vector, the IV [2]. These
are the IV-based encryption schemes.
Unfortunately, in practice, the IV is not always sampled as it should, that is,
uniformly at random [26]. Thus, we can replace the IV with a nonce (“number
used once”). Nonce-based encryption schemes are assumed to be secure as long
as the nonce is not repeated [26].
Namprempre et al. [20] studied all possible combinations of IV-based and
nonce-based encryption schemes with prf-MACs (that is, MACs which provide a
pseudo-random tag) to obtain a nonce-based AE scheme. They proved that 164
modes are insecure, 12 secure (9 with IV-based encryption schemes and 3 with
nonce-based encryption schemes). Only 4 modes remained elusive: N4 (using a
nonce-based encryption scheme) and A10, A11, and A12 (using an IV-based),
see Fig. 1. For these modes, the security remained undecided.
Note that all these modes follow the MAC-then-Encrypt paradigm. Moreover,
N4, A11, and A12 are among the “most eﬃcient” AE-composition modes, in the
sense that they use the nonce, the AD, and the message the least possible number
of times (and there is the hope that they are secure).
Finally, their security has been proved using an additional hypothesis: the
“Knowledge-of-Tags” (KOT) [20]. However, the problem of knowing if KOT is
implied by the privacy requirement of the encryption scheme remains.
MacIV
kA
N
A
iv
MacTAG
kA
A
M
τ
M∥τ
M
EnckE
C
A10
MacIV
kA
N
A
iv
MacTAG
kA
M
τ
M∥τ
M
EnckE
C
A11
MacIV
kA
N
iv
MacTAG
kA
A
M
τ
M∥τ
M
EnckE
C
A12
N
MacTAG
kA
A
M
τ
M∥τ
M
EnckE
C
N4
Fig. 1. The modes A10, A11, A12 and N4 [20]. Note that the IV used may be sent in
clear along with the ciphertext to speed decryption.

Reconsidering Generic Composition
159
Berti et al. [9] investigated the security of these 4 modes, giving some partial
results. First, they proved that N4 is not secure, oﬀering a counterexample with
a nonce-based encryption scheme Π with “a kind of Trojan injected”. Unfor-
tunately, Π outputs ciphertexts longer than the plaintext. Second, they proved
that modes A10, A11, and A12 have the same security: from a counterexample
against any of them, we can build counterexamples against the other 2 modes.
Third, they proved that the modes A10, A11, and A12 are secure if the secure
encryption scheme has any of these two hypotheses: either “misuse-resistance”
(that is, using the same IV and diﬀerent messages, the encryption schemes still
outputs pseudorandom ciphertexts) or “message-malleability” (that is, having
the encryption of any message with a given IV iv, the adversary can correctly
encrypt all other messages with that iv). Since these two hypotheses are, in a
certain way, one the opposite of the other, it seems that these modes are secure,
but we still do not have the proof.
Our Contribution. Surprisingly, this paper proves that modes A10, A11, and
A12 are not secure in general. In particular, they do not provide authenticity.
That is, being able to encrypt messages, it is possible to produce a triple (nonce,
AD, ciphertext), (N ∗, A∗, C∗) which is fresh and valid (that is, ADec(N ∗, A∗, C∗)
does not answer “invalid”). We exhibit a counterexample: a secure ivE scheme
Π1, whose composition according to mode A12 with a secure prf-MAC, we can
forge. Using [9], we immediately extend this result to modes A10 and A11.
Π1 uses a tweakable block-cipher1 (TBC) F. If the message m is s.t. the ﬁrst
two blocks are diﬀerent, (that is, m1 ̸= m2), substantially Π1 is a TBC-based
version of CTR, that is ci = F1,i(iv) ⊕mi with the diﬀerence that the last block
(the one carrying the tag in A12) is encrypted with a slightly diﬀerent tweak,
that is, cl = F2,l(iv) ⊕mi. If the ﬁrst two message blocks are equal, instead,
we modify the encryption of the two last ciphertext blocks: the second-to-last
ciphertext block is obtained as cl−1 = F2,m3(iv) ⊕F2,m3(m1) ⊕ml−1, while the
last block is obtained as cl = F1,l(iv) ⊕ml. Further, we assume that Π1 outputs
the IV iv it uses with the ciphertext c. Π1 is IV-secure, as we prove in Theorem 1.
When mode A12 is implemented with Π1, a forgery can be created, proceed-
ing as follow: the attacker asks the encryption of a message M = M1, ..., Ml with
nonce N and AD A, obtaining iv1, C1, ..., Cl+1 (Remind that C = c = Enc(iv, m)
with m = M∥τ). Then, she asks the encryption C′ of N ′, A′, M ′, where M ′ is
one block longer than M and M ′ = iv, iv, l + 1, ...,. Our goal is to produce C∗
s.t. ADec(N ′, A, C∗) = M. From C′ it is easy to compute the correct C∗
1, ..., C∗
l ,
while to compute C∗
l+1 (the block encrypting the tag τ), we need both Cl+1 and
C′
l+1. The details are in Sect. 4.1.
Since to obtain the correct C∗
l , the adversary needs to know the IV iv used
by Π1 to produce C, a natural solution seems to use the new syntax introduced
by Bellare et al. [5]. They assumed that the decryption algorithm needs only to
know the ciphertext (and the key) to decrypt correctly (and not the IV, or the
1 Tweakable block ciphers (TBCs) were introduced by Liskov et al. [19]. They are
block-ciphers (BCs) with an additional input, the tweak, to add ﬂexibility.

160
F. Berti
nonce). Unfortunately, this simple solution does not work. In fact, we oﬀer as a
counterexample Π2, a variant of Π1, where the IV is sent as C0 = F0,0(iv).
Third, we show that, to prove that N4 is not secure, we do not need an
encryption scheme outputting ciphertexts longer than the plaintexts. We oﬀer
two counterexamples: a variant of Π1 and a variant of the scheme Π presented
in [9]. Since TBCs can be build from BCs [19], our construction can be built only
from BCs.
This work concludes the classiﬁcation of all generic composition modes (when
the encryption scheme is either nonce-based or IV-based). Moreover, we have
proved that IV-security does not imply KOT.
2
Background
Notations. We denote with {0, 1}n the set of all n-bit long strings and with
{0, 1}∗the set of all ﬁnite strings. We denote the length of the string x with |x|.
To denote that x is picked uniformly at random from the set X, we use x
$←X.
In our security games, we use adversaries, which are probabilistic algo-
rithms. An adversary A who has access to oracles O1, . . . , OT is denoted with
AO1(·),...,OT (·). A (q1, . . . , qT , t)-adversary A can do at most qi queries to oracle
Oi and runs in time bounded by t. We denote with AO1(·),...,OT (·) ⇒x the fact
that the adversary A outputs x.
2.1
Tweakable Blockciphers (TBCs)
Encryption schemes and MACs usually use (tweakable)-block ciphers to produce
the randomness they need. Formally,
Deﬁnition 1. A tweakable blockcipher (TBC) is a function F : K × T W ×
{0, 1}n →{0, 1}n s.t. ∀(k, tw) ∈K × T W, F(k, tw, ·) : {0, 1}n →{0, 1}n is a
permutation.
We use often Ftw
k (x) and Fk(tw, x) to denote F(k, tw, x). To denote the inverse
of Ftw
k (·), we use F−1,tw
k
(·). We call n the block-length of F.
We want that a TBC outputs values indistinguishable from random ones.
Formally:
Deﬁnition 2. A TBC F : K × T W × {0, 1}n →{0, 1}n is a (q, t, ϵ)-tweakable
pseudorandom permutation (tprp) if ∀(q, t)-adversary A, the following advan-
tage
Pr[AFk(·,·) ⇒1] −Pr[Af(·,·) ⇒1]
 ≤ϵ
where k
$←K and f
$←T WP. T WP is the set of all tweakable permutations
f, that is, the functions f : T W × {0, 1}n →{0, 1}n s.t. ∀tw ∈T W, f(tw, ·) :
{0, 1}n →{0, 1}n is a permutation.

Reconsidering Generic Composition
161
When the adversary, even having access also to the inverse of F, cannot distin-
guish F from f, we say that F is a strong tprp. Formally:
Deﬁnition 3. A TBC F : K × T W × {0, 1}n →{0, 1}n is a (q, t, ϵ)-strong
tweakable pseudorandom permutation (stprp) if ∀(q1, q2, t)-adversary A, the
following advantage
Pr[AFk(·,·),F−1
k (·,·) ⇒1] −Pr[Af(·,·),f−1(·,·) ⇒1]
 ≤ϵ
where k
$←K, f
$←T WP, f−1(·, ·) is the inverse of f, and q1 + q2 ≤q.
When we do not need that F is a permutation, we use the following security
deﬁnition
Deﬁnition 4. A (q, t, ϵ)-pseudorandom function (prf) is a function F : K ×
{0, 1}n′ →{0, 1}n s.t. ∀(q, t)-adversary A, the following advantage
Pr[AFk(·) ⇒1] −Pr[Af(·) ⇒1]
 ≤ϵ
where k
$←K and f
$←RF with RF is the set of all functions f which are the
functions f : {0, 1}n′ →{0, 1}n.
Note that tprp-secure implies prf-secure [17].
2.2
Encryption Schemes
Encryption schemes are the cryptographic primitive used to provide privacy. To
have security, we need that the encryption is probabilistic [17]. Often, to have
probabilistic encryption, we use a random input, called the initialization vector
(IV), or an input used only once, called a nonce. Thus, we have IV-based and
nonce-based encryption scheme. Formally:
Deﬁnition 5. An
IV-based
encryption
(ivE)
scheme
is
a
triple
Π
=
(Gen, Enc, Dec) where
– the key-generation algorithm Gen generates a key kE from the keyspace KE
(usually kE
$←K);
– the encryption algorithm Enc takes as input a key kE ∈KE, an initialization
vector (IV) iv in the IV-space (IV), and a message m in the message space
m ∈M, and outputs a string c ←Enciv
kE(m) called ciphertext;
– the decryption algorithm Dec takes as input a key kE ∈KE, an IV iv ∈IV,
and a ciphertext c ∈{0, 1}∗, and outputs either a string m ∈M or the symbol
⊥(“invalid”); we denote this with m/ ⊥←Deciv
kE(c).
We require that Enc and Dec are the “inverse” of the other. That is,
– correctness: if Enciv
kE(m) = c (when deﬁned), then, Deciv
kE(c) = m;
– tidyness: if Deciv
kE(c) = m ̸=⊥, then, Enciv
kE(m) = c.

162
F. Berti
We assume that the length of the ciphertexts does not depend on the key and on
the IV, that is, ∀m ∈M |Enciv
kE(m)| = |Enciv′
k′
E(m)| ∀kE, k′
E ∈KE, iv, iv′ ∈IV.
A nonce-based encryption scheme (nE) is deﬁned as an IV-based encryption
scheme where the IV iv is replaced with a nonce n.
To distinguish nonce from block-size, we use always capital letters for nonces,
e.g. N.
Note that syntactically, ivE and nE schemes are the same. But, their security
deﬁnitions are diﬀerent: we want that the ciphertexts are indistinguishable from
random when the IVs are randomly picked (for ivE) or used only once (for nE).
Formally:
Deﬁnition 6. An ivE encryption scheme Π = (Gen, Enc, Dec) is (q, t, ϵ)-secure
(ivE) if ∀(q, t)-adversary A, the following advantage
Pr[AEnc$
kE (·) ⇒1] −Pr[A$(·) ⇒1]
 ≤ϵ
where kE ←Gen, Enc$
kE(m), ﬁrst, randomly picks the IV, iv
$←IV and then
outputs c ←Enciv
kE(m), and $ picks (iv, c)
$←IV × {0, 1}|Enc$
kE (m)| uniformly at
random.
Note that iv is picked in the same way in both cases.
Deﬁnition 7. An nE encryption scheme Π = (Gen, Enc, Dec) is (q, t, ϵ)-secure
(nE) if ∀(q, t)-adversary A, the following advantage
Pr[AEnckE (·,·) ⇒1] −Pr[A$(·,·) ⇒1]
 ≤ϵ
where kE ←Gen, and $ picks c
$←{0, 1}|EnckE (N,m)| uniformly at random. The
adversary is not allowed to do a query on input (N, m) if she has already done
a query on input (N, m′) for m ̸= m′. That is, each nonce N is used at most
once.
For both ivE and nE-security, the adversary cannot query the decryption oracle
(or an ideal counterpart).
2.3
Message Authentication Codes (MAC)
Message authentication codes (MACs) are the cryptographic primitive used for
authenticity.
Deﬁnition 8. A MAC is a triple Π = (Gen, Mac, Vrfy) where
– the key-generation algorithm Gen generates a key kA from the keyspace KA
(usually kA
$←KA);
– the tag-generation algorithm Mac takes as input a key kA ∈KA, and a value
x in the domain space x ∈X, and outputs a string called tag τ ←MackA(x);

Reconsidering Generic Composition
163
– the veriﬁcation algorithm Vrfy takes as input a key kA ∈KA, a value x ∈
X and a tag τ, and outputs either a string ⊤(“valid”) or the symbol ⊥
(“invalid”) and we denote this with ⊤/ ⊥←VrfykA(x, τ).
We require that Mac and Vrfy are one the “inverse” of the other. That is,
– correctness: if MackA(x) = τ (when deﬁned), then, VrfykA(x, τ) = ⊤;
– tidyness: if VrfykA(x, τ) = ⊤, then, MackA(x) = τ.
The tidiness is implied, when the veriﬁcation algorithm is the most obvious: on
input (x, τ), VrfykA computes τ ′ = MackA(x) and checks if τ = τ ′.
The security deﬁnition that we use for MAC, as in [20], is not standard: we
ask that Mac is a prf. Formally,
Deﬁnition 9. A MAC Π = (Gen, Mac, Vrfy) is (q, t, ϵ)-prf secure if Mac is a
(q, t, ϵ)-prf where the key is picked according to Gen.
The standard deﬁnition (unforgeability, see [17]) is implied by this deﬁnition, but
it is not “ a suitable starting point when the goal is to create a nAE scheme ” [20].
2.4
Authenticated Encryption (AE)
Authenticated Encryption is the cryptographic primitive used to provide both
privacy and authenticity. We assume, following [24], that there is a nonce, and
there are data to be authenticated but not encrypted. They are called Associated
Data (AD).
Deﬁnition 10. A nonce-based authenticated encryption (nAE) is a triple Π =
(Gen, AEnc, ADec) where
– the key-generation algorithm Gen generates a key K from the keyspace KAE
(usually K
$←KAE);
– the encryption algorithm AEnc takes as input a key K ∈KAE, a nonce N
in the nonce-space (N), an associated data A in the associated data space
(A), and a message M in the message space M ∈MAE, and outputs a string
C ←AEncK(N, A, M) called ciphertext;
– the decryption algorithm ADec takes as input a key K ∈KAE, a nonce N ∈
N, and a ciphertext C ∈{0, 1}∗, and outputs either a string M ∈MAE or
the symbol ⊥(“invalid”); we denote this with M/ ⊥←ADecK(N, A, C).
We require that AEnc and ADec are one the “inverse” of the other. That is,
– correctness: if AEncK(N, A, M) = C (when deﬁned), then, ADecK(N, A, C) =
M;
– tidyness: if ADecK(N, A, C) = M ̸=⊥, then, AEncK(N, A, M) = C.
We assume that the length of the ciphertext does not depend on the key K,
that is, ∀(N, A, M) ∈N × A × MAE |AEncK(N, A, M)| = |AEncK′(N, A, M)|
∀K, K′ ∈KAE.

164
F. Berti
Note that, syntactically, nAE schemes are very similar to nE schemes (Deﬁni-
tion 5) with the addition of associated data.
To make the reading clearer, we use capital letters (e.g., M) for the inputs
of AEnc and ADec, while small letters (e.g., m) for the inputs of Enc, Dec, Mac,
and Vrfy. This will make the next section more accessible.
nAE schemes want to provide privacy and authenticity with the same scheme.
The following deﬁnition captures this:
Deﬁnition 11. An
nAE
encryption
scheme
Π
=
(Gen, AEnc, ADec)
is
(q1, q2, t, ϵ)-secure (nAE) if ∀(q1, q2, t)-adversary A, the following advantage
Pr[AAEncK(·,·,·),ADecK(·,·,·) ⇒1] −Pr[A$(·,·,·),⊥(·,·,·) ⇒1]
 ≤ϵ
where K ←Gen, $(N, A, M) outputs a random string with the same length as
AEncK(N, A, M), and ⊥(·, ·, ·) always outputs ⊥. The adversary is not allowed
to ask her second oracle on input (N, A, C) if she has received C as an answer
to a query to the ﬁrst oracle on input (N, A, M) for any M ∈MAE. Moreover,
the adversary cannot query her ﬁrst oracle on input (N, A, M) if she has already
queried her ﬁrst oracle on input (N, A′, M ′). That is, each nonce N is used at
most once during “encryption” (ﬁrst oracle) queries.
This notion implies that the adversary cannot ﬁnd a forgery, that is a triple
(N, A, C) which is fresh and valid, that is, (N, A, C) does not come as
answer to a previous query on input (N, A, M) [C = AEncK(N, A, M)] and
ADecK(N, A, C) ̸=⊥.
3
Generic Composition and the Elusive Generic
Composition Modes
3.1
Generic Composition
A natural way to obtain an AE scheme is to compose an encryption scheme with
a MAC [3]. This approach is the so-called generic composition. In the original
paper considering the security of the generic composition [3], the authors studied
the composition of a probabilistic encryption schemes2 with a MAC. There are
three possible composition methods: Encrypt-and-MAC, MAC-then-Encrypt, and
Encrypt-then-MAC. They proved that Encrypt-then-MAC is always secure.
Namprempre et al. [20] studied the generic composition when the encryption
scheme is either ivE or nE-based and the MAC scheme is prf-secure. For ivE-
based, the prf-MAC provides both the IV to the ivE scheme and the tag. To
prevent trivial attacks, there is the domain separation between these two calls,
that is, the IV iv is obtained from MacIV
kA, while the tag τ from MacTAG
kA . There
are three possible type compositions modes, with C = AEncK(N, A, M) with
K = (kE, kA):
2 A probabilistic encryption scheme is a triple Π = (Gen, Enc, Dec) s.t. the output of
Enc is probabilistic. For all its other requirements, see [17].

Reconsidering Generic Composition
165
E&M Encrypt-&-MAC where C = (c∥τ), c = Enciv
kE(M), iv =
MacIV
kA(N|U, A|U, M|U) and τ = MacTAG
kA (N|U, A|U, M|U). (With X|U, we
denote that the input either contains the string X or is absent).
EtM Encrypt-then-MAC, where C = (c∥τ), c = Enciv
kE(M),
iv = MacIV
kA(N|U, A|U, M|U) and τ = MacTAG
kA (N|U, A|U, C).
MtE MAC-then-Encrypt , where C = c, c = Enciv
kE(m), with m = M∥τ, iv =
MacIV
kA(N|U, A|U, M|U) and τ = MacTAG
kA (N|U, A|U, C).
These are the so called A-modes.
In general, we can suppose that the IV is public and it is sent with C. This
can speed decryption (anyway, we can check if the IV is correct). The fact that
the IV is public follows from [20]’s description.
When we compose a MAC with an nE scheme, then, we have the following
types of composition modes, C = AEncK(N, A, M) with K = (kE, kA):
E&M Encrypt-&-MAC where C = (c∥τ), c = EncN
kE(M),
τ = MacTAG
kA (N|U, A|U, M|U).
EtM Encrypt-then-MAC, where C = (c∥τ), c = EncN
kE(M), and
τ = MacTAG
kA (N|U, A|U, C).
MtE MAC-then-Encrypt , where C = c, c = EncN
kE(m), with m = M∥τ, and
τ = MacTAG
kA (N|U, A|U, C).
These are the so-called N-modes.
Note that both AEnc and Enc use the same nonce.
Thus, there are 160 possible modes when we use an ivE scheme and 20 possible
modes when we use a nE scheme.
3.2
The Four Elusive Modes: A10, A11, A12, N4
Namprempre et al. [20] were able to prove the security of 9 modes for ivE-
composition and 3 for nE-composition, and the insecurity of all others except for
4 modes, all MAC-then-Encrypt type:
A10 MtE with MACIV(N, A, U) and MACTAG(U, A, M).
A11 MtE with MACIV(N, A, U) and MACTAG(U, U, M).
A12 MtE with MACIV(N, U, U) and MACTAG(U, A, M).
N4 MtE with MACTAG(U, A, M).
We have depicted them in Fig. 1.
For decryption either the IV is sent in clear and it is checked and used for
decryption, or it is recomputed from (N, A|U).
Knowledge-of-Tag Based Security. Namprempre et al. [20] proved that modes
A10, A11, and A12 are secure if the ivE-scheme is Knowledge-of-Tag-secure
(KOT). In the KOT-experiment, “knowing a tag is captured by introducing a
plaintext extractor Ext, a deterministic algorithm that takes as input all the

166
F. Berti
inputs explicitly available to the forging adversary and outputs a string x or
⊥” [20]. Roughly speaking, a scheme is KOT-secure, if the adversary cannot “
produce a forgery that uses an old iv∗= ivj and an old m∗∥τ ∗= mi∥τi, for
which it [the adversary] does not (explicitly) know τi, and yet the extractor fails
to determine this mi∥τi. Loosely speaking if the forger wins the KOT game, it
has done so without (extractable) knowledge of the tag τi” [20]. We depict the
experiment in the extended version [8] of the paper.
It was left open the problem of whether ivE-security implies KOT.
Partial Results on These Modes [9]. At Indocrypt18, Berti et al. [9] proved
some results about these modes: 1) mode N4 is insecure (using an nE-scheme
which expands the ciphertext), 2) modes A10, A11, and A12 are either all secure
or insecure, 3) modes A10, A11, A12 are secure if the IV scheme used is either
misuse resistant or “message-malleable”. On the other hand, if the ivE scheme
used is either stateful or untidy, the modes are not secure. Here, we give some
insights into these results.
Mode N4 is Insecure. Berti et al. [9] provides a counterexample using the nE
scheme Π (detailed also in the extended version). Π has a key composed of two
components kE = (k, v∗) where k is a key for a TBC with n-bit block, and v∗is
a n-bit random string.
For the encryption Π proceeds as follow: the ﬁrst ciphertext block c0 is a
pseudorandom value, except if the nonce is 1. In this case c0 = v∗, where v∗is a
secret random value; all others ciphertext block (except the last) are computed
as ci = Fi,0
k (N)⊕mi, the last ciphertext block is computed as cl = Fl,0
k (N)⊕ml,
except if the nonce is either 1 or 2 and the second to last message block ml−1,
is v∗: in this case, cl = Fl,1
k (0) ⊕ml. That is, ml is encrypted in the same way
with both N = 1 and N = 2 in the case ml−1 = v∗.
We leave the proof that this scheme is nE-secure to the original paper [9],3 as
well with the description when the length of the message is not a multiple of n.
Observe that the ciphertext is n-bit longer than the message since there is
the block c0. We can see v∗as the trigger of a trojan which forces the same block
to be encrypted in the same way in two diﬀerent encryption queries.
The forgery against N4, when Enc is implemented with Π is straightforward:
– Authenticated encrypt (1, A, M) with M = M1, ..., Ml, obtaining C. Note
that C0 = v∗.
– Authenticated encrypt (2, A, M 1) with M 1
l−1 = v∗and |M| = |M 1|, obtaining
C1.
– The forgery is (1, A, C∗) with C∗
0 = v∗, C∗
i = Ci ⊕Mi ⊕M 1
i for i = 1, ..., l,
and C∗
l+1 = C1
l+1 [we remind that C∗
l+1 encrypts the tag in N4 when Enc is
Π]. Note that ADec(1, A, C∗) = M 1.
The forgery is correct (we leave the easy proof to the original paper).
3 The only problem is if the adversary can do an encryption query (N, m) with N = 1
and ml−1 = v∗, but this cannot happen since v∗is random and leaked only during a
query with N = 1.

Reconsidering Generic Composition
167
Equivalent Security Among Modes A10, A11 and A12. In the same paper, Berti
et al. [9] proved that modes A10, A11, and A12 are either all secure or all
insecure. First, they proved that all forgeries (except with negligible probability)
must use an IV iv and a tag τ already computed. Then, they prove that in this
case (reusing an iv and a τ) if an adversary can create a forgery against one of
these modes, she can easily create a forgery against the other two modes. The
main ingredients of this last step are these:
– A12 secure ⇒A10 secure: Since the nonce N cannot be repeated during
encryption queries, the adversary cannot distinguish if iv = MACIV
kA(N) or
iv = MACIV
kA(N, A).
– A11 secure ⇒A10 secure: Encrypt with A11 M ′ = H(A)∥M, with H a hash
function. Use an ivE scheme for A11 s.t. the encryption of H(A) is independent
from the one of M, e.g., Enc′
kE(iv, M ′) = f(kE, iv)⊕H(A)∥EnckE(iv, M), where
f is a random function f : {0, 1}2n →{0, 1}n.
– A10 secure ⇒A12 secure: We use the same idea as before, encrypting with
A12 M ′ = H(A)∥M.
– A10 secure ⇒A11 secure: We use a similar idea, but here we modify the
nonce. The nonce used for A10 is N, while for A11 is N ′ = N∥H(A).
We leave the full details to the original paper [9] and its extended version [10].
Partial Security/Unsecurity Results. Finally, in the same paper [9], the authors
proved that modes A10, A11 and A12 are secure if the ivE scheme is either
“misuse resistant” (that is, an adversary has no advantage if she can reuse
the same IV during encryption queries4) or message-malleable (that is, if an
adversary receives the decryption, diﬀerent from ⊥, of (iv, c), she can correctly
decrypt (iv, c′) ∀c′, as for example CTR, Counter mode [17]).
On the other hand, if the ivE scheme is not tidy or stateful, then the adversary
can create a forgery against modes A10, A11, and A12 when implemented with
certain ivE schemes (for the stateful case, we can use a variant of the scheme
used against N4). We leave the details to the original paper [9] and its extended
version [10].
4
The Modes A10, A11, A12 are Insecure
Now, we show that mode A12 is insecure, giving a counterexample. Thanks to [9],
this means that also modes A11 and A10 are not secure.
The ﬁrst natural idea is to start from the counterexample against N4 and try
to adapt it to the A12 case. But this is impossible because the iv is random, and
the adversary does not choose it. Thus, if too many IVs reveal v∗or for which
the last block is encrypted diﬀerently, the scheme is no more ivE-secure. On the
other hand, with too few such IVs, the forgery may be done only with negligible
probability.
Thus, we need a diﬀerent idea.
4 Note that this misuse-resistant deﬁnition is weaker then the standard one (see [26]
for the original deﬁnition), where the adversary can do also decryption queries.

168
F. Berti
4.1
Warming up - Suppose that ivE Outputs the IV
We start considering the case when the ivE scheme reveals the IV it used during
the encryption queries. Note that in mode A12, the AE scheme does not need to
reveal the IV since it can be correctly computed even by the decryption oracle
(iv = MACIV
kA(N)). But, following the original paper, we assume that the IV is
revealed. This follows also from the KOT deﬁnition [20].
Construction. We propose an ivE-scheme Π1 which is based on a TBC F and
whose key kE is the key k of the TBC.
If the message is s.t. the ﬁrst two blocks are diﬀerent, (that is, m1 ̸= m2),
substantially it is a TBC-based version of CTR, that is ci = F1,i
k (iv) ⊕mi with
the diﬀerence that the last block (the one carrying the tag in A12) is encrypted
with a slightly diﬀerent tweak, that is, cl = F2,l
k (iv) ⊕ml. Instead, if the ﬁrst
two message blocks are equal, the encryption is the same except for the two
last ciphertext blocks: the second-to-last ciphertext block is obtained as cl−1 =
F2,m3
k
(iv)⊕F2,m3
k
(m1)⊕ml−1, while the last block is obtained as cl = F1,l
k (iv)⊕ml.
The details are in Algorithm 1.
The idea is that if m1 = m2, we are encrypting the second to last block (not
the last block because it carries the tag that it is not known by an adversary,
diﬀerently from the message that she has chosen to encrypt) in a secure way.
Still, it reveals the information necessary to forge using previous encryptions.
Note that if the adversary asks for an encryption of a message M with block-
length l −1, she receives the iv used to encrypt and a ciphertext C. Now, if
she asks to encrypt a second message M ′ s.t. it has block-length l′ = l + 1,
M1 = M2 = iv, and M3 = l + 1, she receives C′, where a random iv′ is used.
Cl+1 and C′
l+1 reveal the crucial information for the forgery:
Cl+1 ⊕C′
l+1 ⊕M′
l+1 = F2,l+1
k
(iv) ⊕ml+1 ⊕F2,l+1
k
(iv′) ⊕F2,l+1
k
(iv) ⊕M′
l+1 ⊕M′
l+1 = ml+1 ⊕F2,l+1
k
(iv′)
where m = M∥τ, thus mi = Mi for i = 1, ..., l and ml+1 is the tag τ of A12.
For simplicity, we have considered the case where all message has a length
of a multiple of n with a minimum of 3n. We can easily extend Π1 to overcome
these limitations.
ivE-security of Π1. The ivE-security of Π1 is straightforward. It is easy to see
that each ciphertext block is obtained XORing at least a call to F that has never
been asked before, with the following exceptions:
– if two IVs are repeated, that is ivi = ivj;
– if ivj is equal to mi
1 with i ≤j;

Reconsidering Generic Composition
169
Algorithm 1. The ivE encryption algorithm Π1.
It uses a TBC F : K × T W × {0, 1}n →{0, 1}n with T W = {1, 2} × {0, 1}n
Gen:
– Return k
$←K
Enck(iv, m):
– Parse m = m1, ..., ml with |mi| = n
– For i = 1, ..., l −2
• ci = F1,i
k (iv) ⊕mi
– If m1 ̸= m2
• cl−1 = F1,l−1
k
(iv) ⊕ml−1
• cl = F2,l
k (iv) ⊕ml
– Else
• cl−1 = F2,m3
k
(iv) ⊕F2,m3
k
(m1) ⊕
ml−1
• cl = F1,l
k (iv) ⊕ml
– Return (iv, c) with c = (c1, ..., cl)
Deck(iv, c):
– Parse c = c1, ..., cl with |ci| = n
– For i = 1, ..., l −2
• mi = F1,i
k (iv) ⊕ci
– If m1 ̸= m2
• ml−1 = F1,l−1
k
(iv) ⊕cl−1
• ml = F2,l
k (iv) ⊕cl
– Else
• ml−1 = F2,m3
k
(iv) ⊕F2,m3
k
(m1) ⊕
cl−1
• ml = F1,l
k (iv) ⊕cl
– Return m = (m1, ..., ml)
But both conditions happen with negligible probability since the IVs are randomly
picked. Note that this the reason why there is a ﬁrst component of the tweak that
it is diﬀerent for cl (when m1 ̸= m2), and cl−1 (when m1 = m2). Formally,
Theorem 1. Let F be a (q1, t, ϵtprp)-tprp, where the block-length is n bits, then
Π1 is (q, t, ϵ)-ivE-secure with
ϵ ≤ϵtprp + (˜L + 2)(q + 1)2
2n+1
,
where q1 = L + q, with L the total number of message blocks to be encrypted,
and ˜L the maximal number of blocks in any message query.
We leave the easy proof to the extended version [8].
Forgery for A12 When the ivE-Scheme is Π1. The idea of the forgery is to ask
the encryption of a message M s.t. M1 ̸= M2 and then ask the encryption of a
message M ′ s.t. M ′
1 = M ′
2 = iv1 which is at least a block longer than M. For
the forgery, we proceed as follow:
– Ask the encryption of (N, A, M) with the message M s.t. M1 ̸= M2 and it
has l blocks. Obtain the ciphertext C = (iv, C1, ..., Cl, Cl+1). Π1 encrypts
m = M∥τ with τ = MacTAG
kA (A, M) using as IV iv = MacIV
kA(N).
– Ask the encryption of (N ′, A′, M ′) with the message M ′ s.t. M ′
1 = M ′
2 = iv,
M ′
3 = l + 1 and it has l + 1 blocks, and N ̸= N ′. Obtain the ciphertext
C′ = (iv′, C′
1, ..., C′
l, C′
l+1, C′
l+2).
– The forgery is (N ∗, A∗, C∗) with N ∗= N ′, A∗= A and C∗deﬁned as follow:
• iv∗= iv′;

170
F. Berti
• C∗
i = C′
i ⊕M ′
i ⊕Mi for i = 1, ..., l;
• C∗
l+1 = Cl+1 ⊕C′
l+1 ⊕M ′
l+1.
This is a valid forgery (encrypting M), as we formally prove in the next propo-
sition:
Proposition 1. Let Π1 be the ivE scheme deﬁned in Algorithm 1. Let MAC be
a prf-secure MAC with n-bit long output. Then the A12 composition is not nAE-
secure.
Proof. Observe that to break the nAE security (Deﬁnition 11) is enough to pro-
vide a valid forgery because, in the left world (AEnc, ADec), the answer will be
diﬀerent from the right world ($, ⊥) which is always invalid.
Now, we have to prove that the forgery just described is fresh and valid.
We use the same notation as in the previous paragraph.
The fact that (N ∗, A∗, C∗) is fresh is trivial since with nonce N ∗, we have
obtained only a ciphertext C′, which is one block longer.
For validity, we start observing that we have never repeated a nonce. Now,
we want to prove that ADec(N ∗, A∗, C∗) = M. To do this we compute ˜C =
AEnc(N ′, A, M):
– ˜iv := MACIV(N ′). Thus, ˜iv = iv′ = iv∗;
– For i = 1, ..., l −2, ˜Ci = F1,i
k (iv∗) ⊕Mi = F1,i
k (iv′) ⊕M ′
i ⊕M ′
i ⊕Mi =
C′
i ⊕M ′
i ⊕Mi (and both Mi and M ′
i are known by the adversary since she
has chosen them).
– Since M1 ̸= M2, then ˜Cl = F1,l
k (˜iv) ⊕Ml = F1,l
k (iv′) ⊕M ′
l ⊕M ′
l ⊕Ml =
C′
l ⊕M ′
l ⊕Ml (and both Mi and M ′
i are known by the adversary since she
has chosen them). Note that C′
l is the third to last ciphertext block of C′.
In fact, during the second encryption query the message encrypted by Π1 is
m′ = M ′∥τ ′ = M ′
1∥...∥M ′
l∥M ′
l+1∥τ ′.
– ˜τ = MACTAG
kA (A, M) = τ.
– ˜Cl+1 = F2,l+1
k
(˜iv)⊕˜τ = F2,l+1
k
(˜iv)⊕F2,l+1
k
(iv)⊕M ′
l+1 ⊕F2,l+1
k
(iv)⊕˜τ ⊕M ′
l+1 =
F2,l+1
k
(iv′)⊕F2,M ′
3
k
(M ′
1)⊕M ′
l+1 ⊕F2,l+1
k
(iv)⊕τ ⊕M ′
l+1 = C′
l+1 ⊕Cl+1 ⊕M ′
l+1,
since ˜iv = iv′, M ′
3 = l+1, M ′
1 = iv and M ′
l+1 is known by the adversary (since
chosen).
Thus, ˜C = C∗consequently ADec(N ∗, A∗, C∗) = ADec(N ∗, A∗, ˜C) = M.
This and
[9] proves that modes A10, A11 and A12 are not nAE-secure.
Formally,
Theorem 2. Let MAC be a prf-secure MAC. Then, there exist 3 ivE-secure ivE-
encryption schemes Π10, Π11, Π12 outputting the IV s.t. modes A10, A11 and
A12 are not nAE-secure when implemented with MAC and the corresponding Π.
Proof. For mode A12, the proof follows easily from the previous proposition,
setting Π12 := Π1 where the TBC has a block-length equal to the size of the
MAC output. The proof that Π12 is ivE-secure is in Proposition 1.

Reconsidering Generic Composition
171
For the other two cases, A10 and A11, in [9] it has been proved that a forgery
against a mode A12 composition can be extended to a forgery to a mode A10
or A11 composition(see Sect. 3.2). This proves our statement.
As a side remark, it is easy to see that if in our forgery attack we had set A′ = A,
Π1 is a good candidate as Π10 and Π11. The details are provided in the extended
version [8].
This result also proves a domain separation between ivE and KOT. Formally,
Theorem 3. ivE-secure ⇏KOT-secure.
Proof. Π1 is ivE-secure and not KOT-secure. The previous attack breaks the
KOT-deﬁnition.
4.2
Broadcasting the IV in the Ciphertext - Attack When the IV is
Hidden
In an interesting paper, Bellare et al. [5] realized that sending the nonce along
with the ciphertext can create security problems. Thus, they proposed a new
syntax (NBE2) for AE scheme where the decryption oracle needs only as input
the ciphertext and the header (and the key) to decrypt correctly.
Note that nonce-based encryption scheme and IV-based encryption scheme
are syntactically equivalent (see Sect. 2.2), thus we can use their syntax also for
ivE-scheme.
Since in the forgery attack we have presented in the previous section, we
need that the adversary knows the IV used by Π1 during the ﬁrst authenticated
encryption query, it is natural to wonder if it is enough to hide the IV used to
prevent the previous attack and prove that modes A10, A11 and A12 are secure.
Moreover, the IV is not needed to decrypt since it can be recomputed from N.
Unfortunately, this is not the case, as we prove in this section by providing
a variant of Π1, called Π2 which can be forged even if the adversary has no clue
about the IV used.
The Construction Π2. We add a block before all the ciphertext, called c0. This
block contains an encryption of the iv used (c0 = F0,0
k (iv)). Now, even if the
adversary cannot recover the iv from c0, this pseudo-random block can be used
in the forgery. Then, Π2 is equal to Π1 with the exception of cl−1 when m1 =
m2. Instead of computing cl−1 = F2,m3
k
(iv) ⊕F2,m3
k
(m1) ⊕ml−1, we compute
cl−1 = F2,m3
k
(iv) ⊕F2,m3
k
(w) ⊕ml−1, with w = F−1,(0,0)
k
(m1). Thus, with m1, we
can tell the encryption algorithm for which iv, that we do not know, we want
some information.
Note that we can create a variant for the decryption that does not need IV
as an input: Dec′. Dec′ simply computes the iv as iv = F−1,(0,0)
k
(c0) and then
proceeds as for Dec.
ivE-Security of Π2. We have only to show that the modiﬁcation that we have
done does not aﬀect security. In particular, c0 is a pseudo-random block, and we

172
F. Berti
need to use a stprp-secure F because we use F−1 during encryption, and we have
a problem if w is equal to a previous iv.
Thus, we have that
Algorithm 2. The ivE encryption algorithm Π2.
It uses a TBC F : K × T W × {0, 1}n →{0, 1}n with T W = {0, 1, 2} × {0, 1}n
Gen:
– Return k
$←K
Enck(iv, m):
– Parse m = m1, ..., ml with |mi| = n
– c0 = F0,0
k (iv)
– For i = 1, ..., l −2
• ci = F1,i
k (iv) ⊕mi
– If m1 ̸= m2
• cl−1 = F1,l−1
k
(iv) ⊕ml−1
• cl = F2,l
k (iv) ⊕ml
– Else
• w = F−1,(0,0)
k
(m1)
• cl−1 = F2,m3
k
(iv) ⊕F2,m3
k
(w) ⊕
ml−1
• cl = F1,l
k (iv) ⊕ml
– Return c = (c0, c1, ..., cl)
Deck(iv, c):
– Parse c = c0, c1, ..., cl with |ci| = n
– If c0 ̸= F0,0
k (iv)
• Return ⊥
– For i = 1, ..., l −2
• mi = F1,i
k (iv) ⊕ci
– If m1 ̸= m2
• ml−1 = F1,l−1
k
(iv) ⊕cl−1
• ml = F2,l
k (iv) ⊕cl
– Else
• w = F−1,(0,0)
k
(m1)
• ml−1 = F2,m3
k
(iv) ⊕F2,m3
k
(w) ⊕
cl−1
• ml = F1,l
k (iv) ⊕cl
– Return m = (m1, ..., ml)
Theorem 4. Let F be a (q1, t, ϵstprp)-stprp, where the block-length is n bits, then
Π2 is (q, t, ϵ)-ivE-secure with
ϵ ≤ϵstprp + (˜L + 4)(q + 1)2
2n+1
,
where q1 = L + 3q, with L the total number of message blocks to be encrypted,
and ˜L the maximal number of blocks in any message query.
We leave the easy proof to the extended version [8].
Forgery for A12 When the ivE Scheme is Π2. It is easy to extend to forgery for
mode A12 when implemented with Π1 to mode A12 implemented with Π2 as
follow:
– Ask the encryption of (N, A, M) with the message M s.t. M1 ̸= M2 and it
has l blocks. Obtain the ciphertext C = (C0, C1, ..., Cl, Cl+1).
– Ask the encryption of (N ′, A′, M ′) with the message M ′ s.t. M ′
1 = M ′
2 = C0,
M ′
3 = l + 1 and it has l + 1 blocks, and N ̸= N ′. Obtain the ciphertext
C′ = (C′
0, C′
1, ..., C′
l, C′
l+1, C′
l+2).
– The forgery is (N ∗, A∗, C∗) with N ∗= N ′, A∗= A and C∗deﬁned as follow:
• C∗
0 = C′
0;

Reconsidering Generic Composition
173
• C∗
i = C′
i ⊕M ′
i ⊕Mi for i = 1, ..., l;
• C∗
l+1 = Cl+1 ⊕C′
l+1 ⊕M ′
l+1.
This is a valid forgery (encrypting M). Formally,
Proposition 2. Let Π2 be the ivE scheme deﬁned in Algorithm 1. Let MAC
be a prf-secure MAC with n-bit long output. Then the A12 composition is not
nAE-secure.
The proof is the same as for Proposition 1 with the diﬀerence that we have
to replace in the computation of ˜Cl+1, F2,M ′
3
k
(M ′
1) with F2,M ′
3
k
(w′) where
w′ = F−1,(0,0)
k
(C∗
0) = F−1,(0,0)
k
(M ′
0) = F−1,(0,0)
k

F(0,0)
k
(iv)

= iv.
This and [9] proves that modes A10, A11 and A12 are not nAE-secure even
if the IV is not broadcast. Formally,
Theorem 5. Let MAC be a prf-secure MAC. Then, there exist 3 ivE-secure ivE-
encryption schemes Π10, Π11, Π12 s.t 1) they do not output the IV, 2) the com-
position of Πi with a prf-secure MAC according to mode A i is not nAE-secure
for i = 10, 11, 12.
The proof is the same as for Theorem 2.
Note that this attack proves that ivE-security does not imply Knowledge-of-
Tag secure.
4.3
Fixed Length nE Scheme for N4
Finally, we prove that it is unnecessary to use an nE encryption scheme whose
ciphertext is longer than plaintext to prove that N4 is not secure. We propose
two constructions: one which is a modiﬁed version of Π1 (Algorithm 1) and
another is a version of the scheme of [9].
Π3, a Variant of Π1. The ﬁrst idea is to use Π1 directly since ivE-schemes and
nE-schemes are syntactically equivalent.
Unfortunately, Π1 is not nE-secure. It is trivial to see that the condition ivi
equal to mj for j ≤i does not happen with negligible probability since the IV is
replaced with a nonce which the adversary chooses.
Thus, we modify Π1, obtaining Π3 as follows:
– the condition if m1 ̸= m2 becomes m1 ̸= m2 ∧N ̸= 2
– in the else we replace cl−1 = F2,m3
k
(iv) ⊕F2,m3
k
(m1) ⊕ml−1 with
cl−1 = F2,m3
k
(N) ⊕F2,m3
k
(1) ⊕ml−1
The idea is that we always enter in the if except when the nonce N = 2. When
we do not enter in the if, we obtain information to obtain a forgery combined
with the information given by an encryption with N = 1.
It is easy to see that Π3 is nE secure: If we do not enter in the else, Π3 is
secure. If we enter in the else we observe that cl−1 when encrypted with N = 2,

174
F. Berti
and cl when N = 1 are independently. We describe formally Π3 in the extended
version [8].
Π4 a Variant of [9]. Π4 is obtained from the nE scheme introduced in [9] with
these modiﬁcations:
– we remove v∗and c0.
– the if condition becomes if (N = 1 ∨N = 2) ∧m2 = F1,0
k (1) ⊕m1
To enter the if condition during encryption twice, it is necessary to guess F1,0
k (1)
before it is computed. We describe formally Π4 and the forgery in the extended
version [8].
5
Conclusions
We have proved that modes A10, A11, and A12 are not secure in general. This
concludes the classiﬁcation of [20].
Note that our results do not imply that all schemes obtained using mode
N4, A10, A11, and A12 composition are insecure. Instead, these modes seem
insecure only when implemented with artiﬁcial schemes, while they are secure
when implemented with “natural” schemes. But, these compositions need ad-hoc
proofs and cannot rely on general proof.
Finally, this work gives some insights into the limitation of indistinguisha-
bility from randomness. That is, having a random ciphertext encrypting the tag
may not be enough to make it not usable for forgeries.
Acknowledgements. This work was partly supported by the German Federal Min-
istry of Education and Research and the Hessen State Ministry for Higher Education,
Research and the Arts within their joint support of the National Research Center for
Applied Cybersecurity ATHENE. F. Berti was partly funded by the Israel Science
Foundation (ISF) grant 2569/21.
References
1. Abed, F., Forler, C., Lucks, S.: General classiﬁcation of the authenticated encryp-
tion schemes for the CAESAR competition. Comput. Sci. Rev. 22, 13–26 (2016).
https://doi.org/10.1016/j.cosrev.2016.07.002
2. Bellare, M., Desai, A., Jokipii, E., Rogaway, P.: A concrete security treatment of
symmetric encryption. In: 38th Annual Symposium on Foundations of Computer
Science, FOCS 1997, Miami Beach, Florida, USA, 19–22 October 1997, pp. 394–
403. IEEE Computer Society (1997). https://doi.org/10.1109/SFCS.1997.646128
3. Bellare, M., Namprempre, C.: Authenticated encryption: relations among notions
and analysis of the generic composition paradigm. In: Okamoto, T. (ed.) ASI-
ACRYPT 2000. LNCS, vol. 1976, pp. 531–545. Springer, Heidelberg (2000).
https://doi.org/10.1007/3-540-44448-3 41
4. Bellare, M., Namprempre, C.: Authenticated encryption: relations among notions
and analysis of the generic composition paradigm. J. Cryptol. 21(4), 469–491
(2008). https://doi.org/10.1007/s00145-008-9026-x

Reconsidering Generic Composition
175
5. Bellare, M., Ng, R., Tackmann, B.: Nonces are noticed: AEAD revisited. In:
Boldyreva, A., Micciancio, D. (eds.) CRYPTO 2019, Part I. LNCS, vol. 11692, pp.
235–265. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-26948-7 9
6. Bellare, M., Rogaway, P.: Encode-then-encipher encryption: how to exploit Nonces
or redundancy in plaintexts for eﬃcient cryptography. In: Okamoto, T. (ed.)
ASIACRYPT 2000. LNCS, vol. 1976, pp. 317–330. Springer, Heidelberg (2000).
https://doi.org/10.1007/3-540-44448-3 24
7. Bernstein, D.J.: Caesar call for submissions, ﬁnal. Technical report (2014). http://
competitions.cr.yp.to/caesar.html
8. Berti, F.: Reconsidering generic composition: the modes A10, A11 and A12 are
insecure, Cryptology ePrint Archive, Paper 2023/590 (2023). https://eprint.iacr.
org/2023/590
9. Berti, F., Pereira, O., Peters, T.: Reconsidering generic composition: the tag-then-
encrypt case. In: Chakraborty, D., Iwata, T. (eds.) INDOCRYPT 2018. LNCS,
vol. 11356, pp. 70–90. Springer, Cham (2018). https://doi.org/10.1007/978-3-030-
05378-9 4
10. Berti, F., Pereira, O., Peters, T.: Reconsidering generic composition: the tag-then-
encrypt case. In: IACR Cryptol. ePrint Arch., p. 991 (2018). https://eprint.iacr.
org/2018/991
11. Bertoni, G., Daemen, J., Hoﬀert, S., Peeters, M., Assche, G.V., Keer, R.V.: Far-
falle: parallel permutation-based cryptography. IACR Trans. Symmetric Cryptol.
2017(4), 1–38 (2017). https://tosc.iacr.org/index.php/ToSC/article/view/801
12. Bertoni, G., Daemen, J., Peeters, M., Van Assche, G.: Duplexing the sponge:
single-pass authenticated encryption and other applications. In: Miri, A., Vau-
denay, S. (eds.) SAC 2011. LNCS, vol. 7118, pp. 320–337. Springer, Heidelberg
(2012). https://doi.org/10.1007/978-3-642-28496-0 19
13. Bronchain, O., Momin, C., Peters, T., Standaert, F.: Improved leakage-resistant
authenticated encryption based on hardware AES coprocessors. IACR Trans. Cryp-
togr. Hardw. Embed. Syst. 2021(3), 641–676 (2021). https://doi.org/10.46586/
tches.v2021.i3.641-676
14. Dobraunig, C., Eichlseder, M., Mendel, F., Schl¨aﬀer, M.: ASCON v1.2: lightweight
authenticated encryption and hashing. J. Cryptol. 34(3), 33 (2021). https://doi.
org/10.1007/s00145-021-09398-9
15. Hoang, V.T., Krovetz, T., Rogaway, P.: Robust authenticated-encryption AEZ and
the problem that it solves. In: Oswald, E., Fischlin, M. (eds.) EUROCRYPT 2015,
Part I. LNCS, vol. 9056, pp. 15–44. Springer, Heidelberg (2015). https://doi.org/
10.1007/978-3-662-46800-5 2
16. Jimale, M.A., et al.: Authenticated encryption schemes: a systematic review. IEEE
Access 10, 14739–14766 (2022). https://doi.org/10.1109/ACCESS.2022.3147201
17. Katz, J., Lindell, Y.: Introduction to Modern Cryptography, 2nd edn. CRC
Press, Boca Raton (2014). https://www.crcpress.com/Introduction-to-Modern-
Cryptography-Second-Edition/Katz-Lindell/p/book/9781466570269
18. Krawczyk, H.: The order of encryption and authentication for protecting com-
munications (or: how secure is SSL?). In: Kilian, J. (ed.) CRYPTO 2001. LNCS,
vol. 2139, pp. 310–331. Springer, Heidelberg (2001). https://doi.org/10.1007/3-
540-44647-8 19
19. Liskov, M., Rivest, R.L., Wagner, D.: Tweakable block ciphers. In: Yung, M. (ed.)
CRYPTO 2002. LNCS, vol. 2442, pp. 31–46. Springer, Heidelberg (2002). https://
doi.org/10.1007/3-540-45708-9 3

176
F. Berti
20. Namprempre, C., Rogaway, P., Shrimpton, T.: Reconsidering generic composition.
In: Nguyen, P.Q., Oswald, E. (eds.) EUROCRYPT 2014. LNCS, vol. 8441, pp.
257–274. Springer, Heidelberg (2014). https://doi.org/10.1007/978-3-642-55220-
5 15
21. NIST: Submission requirements and evaluation criteria for the lightweight cryp-
tography standardization process. Technical report (2018). https://csrc.nist.gov/
projects/lightweight-cryptography
22. NIST: Lightweight cryptography - ﬁnalists. Technical report (2021). http://csrc.
nist.gov/Projects/lightweight-cryptography/ﬁnalists
23. Peyrin, T., Seurin, Y.: Counter-in-tweak: authenticated encryption modes for
tweakable block ciphers. In: Robshaw, M., Katz, J. (eds.) CRYPTO 2016, Part
I. LNCS, vol. 9814, pp. 33–63. Springer, Heidelberg (2016). https://doi.org/10.
1007/978-3-662-53018-4 2
24. Rogaway, P.: Authenticated-encryption with associated-data. In: Atluri, V. (ed.)
Proceedings of the 9th ACM Conference on Computer and Communications Secu-
rity, CCS 2002, Washington, DC, USA, 18–22 November 2002, pp. 98–107. ACM
(2002). https://doi.org/10.1145/586110.586125
25. Rogaway, P., Bellare, M., Black, J., Krovetz, T.: OCB: a block-cipher mode of oper-
ation for eﬃcient authenticated encryption. In: Reiter, M.K., Samarati, P. (eds.)
CCS 2001, Proceedings of the 8th ACM Conference on Computer and Communica-
tions Security, Philadelphia, Pennsylvania, USA, 6–8 November 2001, pp. 196–205.
ACM (2001). https://doi.org/10.1145/501983.502011
26. Rogaway, P., Shrimpton, T.: A provable-security treatment of the key-wrap prob-
lem. In: Vaudenay, S. (ed.) EUROCRYPT 2006. LNCS, vol. 4004, pp. 373–390.
Springer, Heidelberg (2006). https://doi.org/10.1007/11761679 23

Exploring Formal Methods
for Cryptographic Hash Function
Implementations
Nicky Mouha(B)
Strativia, Largo, MD, USA
nicky@mouha.be
Abstract. Cryptographic hash functions are used inside many applica-
tions that critically rely on their resistance against cryptanalysis attacks
and the correctness of their implementations. Nevertheless, vulnerabili-
ties in cryptographic hash function implementations can remain unno-
ticed for more than a decade, as shown by the recent discovery of a
buﬀer overﬂow in the implementation of SHA-3 in the eXtended Kec-
cak Code Package (XKCP), impacting Python, PHP, and several other
software projects. This paper explains how this buﬀer overﬂow vulner-
ability in XKCP was found. More generally, we explore the application
of formal methods to the ﬁve ﬁnalist submission packages to the NIST
SHA-3 competition, allowing us to (re-)discover vulnerabilities in the
implementations of Keccak and BLAKE, and also discover a previously
undisclosed vulnerability in the implementation of Grøstl. We also show
how the same approach rediscovers a vulnerability aﬀecting 11 out of
the 12 implemented cryptographic hash functions in Apple’s CoreCrypto
library. Our approach consists of removing certain lines of code and then
using KLEE as a tool to prove functional equivalence. We discuss the
advantages and limitations of our approach and hope that our attempt
to consolidate some earlier approaches can lead to new insights.
Keywords: SHA-3 · Hash Function · Keccak · BLAKE · Grøstl ·
CoreCrypto
1
Introduction
A (cryptographic) hash function takes a message of a variable length and turns it
into a ﬁxed-length output, known as a “hash value” or “hash.” For a hash function
to be secure, it should be computationally infeasible to invert the function for a
given hash (preimage resistance) or to ﬁnd two distinct messages that result in
the same hash (collision resistance). These properties allow the use of the hash
value in place of the message itself in a digital signature scheme, so that successful
veriﬁcation of the signature conﬁrms that the message has not been altered.
In response to the cryptanalysis attack on the SHA-1 hash function presented
at CRYPTO 2005 by Wang et al. [36], NIST decided to launch the SHA-3 com-
petition for a new hash function standard [29]. The competition was announced
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 177–195, 2023.
https://doi.org/10.1007/978-3-031-35486-1_9

178
N. Mouha
in November 2007. By October 2008, 64 entries were received, and 51 were
selected as ﬁrst-round candidates in December 2008. Fourteen of these advanced
as second-round candidates in July 2009, and the ﬁve ﬁnalists (BLAKE, Grøstl,
JH, Keccak, and Skein) were announced in December 2010. The SHA-3 compe-
tition ended in October 2012, when Keccak was declared to be the winner.
Submission packages to the SHA-3 competition were required to include refer-
ence and optimized implementations in the C programming language [27]. NIST
speciﬁed the Application Programming Interface (API) to be used (see Sect. 3)
as well as the test vectors that were required in every submission package.
As the submission packages to the SHA-3 competition were subjected to
public scrutiny, bugs were reported for several submissions in 2008 and 2009. A
systematic analysis by Forsythe and Held of Fortify Software [18] found many
bugs that commonly appear in C code, such as out-of-bounds reads, memory
leaks, and null pointer dereferences. No bugs were reported during the remainder
of the competition, and eventually, the resulting SHA-3 standard became widely
implemented in many cryptographic libraries.
However, in September 2015, the implementation on the BLAKE website
was updated with the comment: “ﬁxed a bug that gave incorrect hashes in
speciﬁc use cases” [4]. In 2018, Mouha et al. [24] rediscovered the bug using a
new testing methodology that was eventually integrated into Google’s Project
Wycheproof [10] and showed that the bug allows the collision resistance of the
hash function to be violated.
At CT-RSA 2020, Mouha and Celi [22] showed a vulnerability aﬀecting 11
out of the 12 implemented hash functions in Apple’s CoreCrypto library. The
vulnerability required invoking the implementation on inputs of at least 4 GiB,
which led to an inﬁnite loop. This vulnerability showed a limitation in NIST’s
Cryptographic Algorithm Validation Program (CAVP), which did not perform
tests on hash functions for inputs larger than 65 535 bits. To overcome this
limitation, NIST introduced the Large Data Test (LDT).
In October 2022, a vulnerability was disclosed by Mouha [31] that impacted
both the ﬁnal-round Keccak submission package and the resulting SHA-3 imple-
mentation by its designers. Depending on the speciﬁc inputs that were provided,
the vulnerability resulted in either an inﬁnite loop or a buﬀer overﬂow where
attacker-provided values are XORed into memory [23].
Our Contributions. A shortcoming of previous work on ﬁnding vulnerabili-
ties in hash function implementations is that they lack generality and clearly fall
short as new vulnerabilities keep being found that remained unnoticed for over
a decade (in spite of extensive public scrutiny). The novel contribution of this
paper is to try to overcome this problem by introducing a new approach that can
be used to ﬁnd vulnerabilities in the hash function implementations of Apple’s
CoreCrypto library, as well as in three out of the ﬁve SHA-3 ﬁnalist submissions:
BLAKE, Keccak, and Grøstl. This paper explains how the vulnerability in Kec-
cak was found. The vulnerability in Grøstl is a new contribution in this paper

Exploring Formal Methods for Cryptographic
179
that has not been reported before. Our approach involves symbolic execution to
ﬁnd bugs within seconds, whereas test vectors may take much longer to execute.
2
Background and Related Work
The NIST approach to testing cryptographic implementations dates back to
1977, with the introduction of two sets of test vectors for the Data Encryption
Standard (DES) in SP 500-20 [25]. Now known as Known Answer Tests (KATs)
or static Algorithmic Functional Tests (AFTs), the ﬁrst set of test vectors were
intended to “fully exercise the non-linear substitution tables” (S-boxes) of the
DES. The second set of test vectors, called Monte Carlo Tests (MCTs), contained
“pseudorandom data to verify that the device has not been designed just to pass
the test set”. Although originally intended to test hardware implementations,
this approach can be applied to both hardware and software and forms the basis
of NIST’s Cryptographic Algorithm Validation Program (CAVP).
Submissions to the NIST SHA-3 competition were required to include imple-
mentations in the C programming language. NIST speciﬁed an API [27] and
provided source code to generate KATs and MCTs [28]. These KATs and MCTs
helped to ensure that various implementations of the same algorithm were con-
sistent. Moreover, an interesting innovation was the inclusion of an Extremely
Long Message KAT, which provided a 1 GiB message with the goal of ensuring
that large inputs are processed correctly.
For (authenticated) encryption algorithms, the SUPERCOP [7] and BRU-
TUS [34] frameworks perform some additional tests, such as checking whether
overlapping inputs are handled correctly or whether encryption followed by
decryption returns the original plaintext.
Aumasson and Romailler introduced crypto diﬀerential fuzzing [3] which uses
a fuzzer to compare the outputs of diﬀerent cryptographic libraries and ﬁnd
discrepancies. This approach turned out to be very eﬀective, as shown by the
many bugs found by Vranken’s Cryptofuzz project [35].
Formal methods and program veriﬁcation can also be applied to hash func-
tion implementations. Chudnov et al. [15] demonstrated that the Keyed-Hash
Message Authentication Code (HMAC) implementation (using the SHA-256
hash function) of Amazon’s s2n library conforms to a formal speciﬁcation by
using Galois’s Software Analysis Workbench (SAW). The HACL∗cryptographic
library [32,38] is formally veriﬁed using the F∗veriﬁcation framework. We refer
to Protzenko and Ho [33] for an explanation of how its hash function implemen-
tations have recently been completely overhauled. Lastly, we mention Chapman
et al.’s SPARKSkein [13] as an implementation of the SHA-3 ﬁnalist Skein that
was written and veriﬁed using the SPARK [1] language and toolset.
Chapman et al. [13] pointed out a bug in the Skein submission package to
NIST. The bug involves messages of more than 264−8 bits. Although impractical,
this violates a requirement in the SHA-3 call for submissions that a candidate
algorithm (and therefore logically also a correct implementation of the algorithm)
“shall support a maximum message length of at least 264 −1 bits” [26].

180
N. Mouha
Fig. 1. An evaluation of a hash value on a message that is provided “on the ﬂy” using
any number of calls to Update() of arbitrary lengths.
Fig. 2. To prove that any number of calls to Update() with arbitrary lengths result in
a correct computation, it is suﬃcient to prove that two calls to Update() are equivalent
to one larger call to Update() on the concatenation of both inputs.
3
Cryptographic Hash Function Interfaces
An API for the SHA-3 competition was speciﬁed by NIST [27], requiring the
hashState data structure and four function calls: Init(), Update(), Final(),
and Hash(). The API was designed for 64-bit operating systems, which were
already common at the start of the SHA-3 competition.
The purpose of the hashState data structure is to contain “all information
necessary to describe the current state of the SHA-3 candidate algorithm”. It
must contain the hashbitlen variable to indicate the output size of the partic-
ular instantiation of the hash function.
The four function calls show how hashState is intended to be used:
– Init() initializes the hashState data structure.
– Once initialized, any number of calls to Update() can be made to process
parts of the message by updating hashState correspondingly. In practice,
this “incremental hashing” API oﬀers a major eﬃciency improvement if the

Exploring Formal Methods for Cryptographic
181
message is not available all at once or split over two or more non-contiguous
arrays [33, p. 9].
– Final() performs any ﬁnal processing needed on hashState to output the
hash value.
– Hash() processes the message all-at-once by calling Init(), Update(), and
Final().
Let us assume that the all-at-once computation using Init(), Update(),
and Final() is correct. Then, a suﬃcient (but not necessary) condition for the
correctness of a computation using any number of calls to Update() (as shown
in Fig. 1) is:
Condition 1. Two consecutive calls to Update() change hashState in the
same way as one call to Update() on the concatenation of both inputs.
It can be seen that Condition 1 is suﬃcient by means of a proof by contradic-
tion where the condition is applied recursively as illustrated in Fig. 2. However,
there are several cases where Condition 1 is not necessary:
– Let us denote a hashState as valid if and only if is reachable from Init()
followed by any number of calls to Update(). Then, it is not necessary that
Condition 1 holds if hashState is invalid.
– If the Final() function can return the same hash value on two distinct but
valid hashState data structures, Condition 1 is not necessary either. How-
ever, this does not seem to occur in practice, as we have only encountered
implementations where hashState uniquely represents the message processed
so far.
– In the NIST SHA-3 API, all lengths are provided in bits using a 64-bit
unsigned integer [27], and a candidate algorithm may impose a maximum
message length of 264−1 bits [26]. If this maximum message length is imposed,
Condition 1 is not necessary for a sequence of two Update() calls that exceed
the maximum message length (as the hash function may not be deﬁned in
this case).
– The NIST SHA-3 API document speciﬁes that all calls to Update() contain
data lengths (in bits) that are divisible by eight, except possibly the last call.
Therefore, for two consecutive calls to Update(), we may restrict the ﬁrst call
to a data length that is a multiple of eight bits.
In the next section, our goal will be to verify Condition 1 for a given hash
function implementation, possibly along with some preconditions to exclude the
aforementioned cases where Condition 1 is not necessary. We will remove some
lines of code: as in many previous works we are aiming for the “less ambitious
but still important goal of stating partial speciﬁcations of program behavior and
providing methodologies and tools to check their correctness” [5].
Before concluding this section, note that we will assume throughout this
paper that Init(), Update(), and Final() are called in the “correct” order.

182
N. Mouha
In practice it can be desirable to call Update() after Final(). However, as
shown by Benmocha et al. [6], this can be highly insecure for cryptographic
libraries that do not expect such usage.
4
Program Veriﬁcation Using KLEE
In this paper, we will use KLEE [11], which is a symbolic execution tool built
on top of the LLVM (Low-Level Virtual Machine) [21] compiler architecture.
Although a typical use of KLEE is to automatically generate test vectors
that achieve high code coverage, it can also be used to prove the full functional
equivalence of two implementations [11, § 5.5]. Whenever KLEE encounters an
execution branch based on a symbolic value, it will (conceptually) follow both
branches, maintaining a set of constraints called path conditions for each branch.
A downside of this approach is that the number of paths can grow very quickly.
To overcome this path explosion problem, KLEE employs a variety of strategies
to reduce the number of queries that are sent to the underlying constraint solver.
Unlike CBMC [16], which is a Bounded Model Checker for C and C++
programs, KLEE does not require a bound on the number of iterations for every
loop. The NIST SHA-3 competition required a maximum message length of at
least 264 −1 bits, and it is common to see hash functions that process the
message iteratively using a compression function that takes 512 or 1024 bits of
input. Computing the hash for such large messages is not possible in practice,
however, we will see that our approach using KLEE handles such inputs quite
quickly (and without the need for loop unwinding nor manual eﬀorts to rewrite
loops).
In the following sections, we will show how to apply KLEE to the reference
implementations of the ﬁve SHA-3 ﬁnalists, as well as to the SHA-3 implemen-
tation of XKCP and the hash functions implemented in Apple’s CoreCrypto
library. In this paper, we only provide the full source code for our KLEE exper-
iments on the JH algorithm. However. the code for all our experiments will be
made available as a software artifact.
Table 1 summarizes the runtimes for a 256-bit hash output value, except for
Keccak and SHA-3 where we will choose a rate of 1024 bits. We found that the
execution time typically does not depend on the length of the hash value. Our
experiments were performed on an Intel Core i7-1165G7 processor using KLEE
2.3 with the default STP (Simple Theorem Prover) solver [12,19].
4.1
JH
JH [37] is a hash function designed by Hongjun Wu that advanced to the ﬁnal
round of the NIST SHA-3 competition. As required for all submissions [26], JH
supports hash lengths of 224, 256, 384, and 512 bits. The message is padded to
a multiple of 512 bits and then split into 512-bit blocks which are processed by
the same compression function F8().

Exploring Formal Methods for Cryptographic
183
Table 1. KLEE runtimes (in minutes and seconds) for a rate of 1024 bits (for Kec-
cak and SHA-3) or a 256-bit hash output length (for all other hash functions). The
second column is the runtime to ﬁnd a test vector that reveals a bug (if the code is
incorrect), and the third column is the runtime to prove correctness (after patching
the implementation if there is a bug).
Implementation Buggy Correct
BLAKE
5 s
11 m 59 s
Grøstl
6 s
10 s
JH
—
50 s
Keccak
1 s
39 s
Skein
—
34 s
XKCP (SHA-3)
1 s
20 s
CoreCrypto
1 s
2 m 41 s
We provide the entire jh klee.c that we used in our experiment in Listing 1.
It contains the Update() function that is speciﬁed in jh ref.h of the JH submis-
sion package. For readability, we adjusted the indentation, and for compactness,
we removed the source code comments. The only other change that we made
to Update() is to comment out the lines involving memcpy() and F8(), as our
(partial) equivalence checking does not involve the contents of the message (only
its length), nor does it involve the implementation of the compression function
F8(). Moreover, throughout this paper we do not make any statements about
the correctness of Init(), Final(), nor Hash().
In Listing 2, we provide the Makeﬁle that uses Docker as an easy and portable
way to run KLEE on jh klee.c. It will either return a test vector that violates
Condition 1, or prove that no such test vector exists. We ﬁnd that after 50 s,
KLEE proves the (partial) consistency of the Update() function. An overview
of the execution times for all our experiments is given in Table 1.
Five lines in Listing 1 are marked with the comment // optional following
the reasoning in Sect. 3. They can be safely omitted with the only downside that
they roughly double the execution time of KLEE. However, these ﬁve lines can
be helpful to adapt the approach to other SHA-3 candidate implementations
where they may be needed.
Listing 1. Application to JH (jh klee.c).
1 #include <assert.h>
2 #include <klee/klee.h>
3
4 typedef
unsigned
char
BitSequence;
5 typedef
unsigned
long long
DataLength;
6 typedef
enum { SUCCESS = 0, FAIL = 1,
7
BAD_HASHLEN = 2 } HashReturn;
8 typedef
struct {
9
int
hashbitlen;

184
N. Mouha
10
unsigned
long long
databitlen;
11
unsigned
long long
datasize_in_buffer ;
12 } hashState;
13
14 HashReturn
Update(hashState *state , const
BitSequence
15
*data , DataLength
databitlen)
16 {
17
DataLength
index;
18
state ->databitlen += databitlen;
19
index = 0;
20
21
if ( (state -> datasize_in_buffer
> 0 ) &&
22
((state -> datasize_in_buffer +databitlen) <512) ) {
23
if ( (databitlen & 7) == 0 ) {
24
// memcpy(state ->buffer +
25
//( state -> datasize_in_buffer
>> 3), data ,
26
//64 -( state -> datasize_in_buffer
>> 3));
27
}
28
// else
memcpy(state ->buffer +
29
//
(state -> datasize_in_buffer
>> 3), data ,
30
//
64-(state -> datasize_in_buffer
>> 3)+1);
31
state -> datasize_in_buffer
+= databitlen;
32
databitlen = 0;
33
}
34
35
if ( (state -> datasize_in_buffer
> 0 ) &&
36
((state -> datasize_in_buffer +databitlen) >=512)) {
37
// memcpy(state ->buffer +
38
//
(state -> datasize_in_buffer
>> 3), data ,
39
//
64-(state -> datasize_in_buffer
>> 3) );
40
index = 64-(state -> datasize_in_buffer
>> 3);
41
databitlen = databitlen -
42
(512 - state -> datasize_in_buffer );
43
//F8(state);
44
state -> datasize_in_buffer = 0;
45
}
46
47
for ( ; databitlen
>= 512; index = index +64,
48
databitlen = databitlen - 512) {
49
// memcpy(state ->buffer , data+index , 64);
50
//F8(state);
51
}
52
53
if (databitlen > 0) {
54
//if (( databitlen & 7) == 0)
55
// memcpy(state ->buffer , data+index ,
56
//
(databitlen & 0x1ff) >> 3);
57
// else
58
// memcpy(state ->buffer , data+index ,
59
//
(( databitlen & 0x1ff) >> 3)+1);

Exploring Formal Methods for Cryptographic
185
60
state -> datasize_in_buffer = databitlen;
61
}
62
63
return(SUCCESS);
64 }
65
66 void test(int
hashbitlen) {
67
hashState s, s2;
68
DataLength
databitlen , databitlen1 , databitlen2;
69
70
klee_make_symbolic (&s, sizeof(s), "s");
71
klee_make_symbolic (&s2 , sizeof(s2), "s2");
72
klee_make_symbolic (& databitlen , sizeof(databitlen),
73
"databitlen ");
74
klee_make_symbolic (& databitlen1 , sizeof(databitlen1),
75
"databitlen1 ");
76
klee_make_symbolic (& databitlen2 , sizeof(databitlen2),
77
"databitlen2 ");
78
79
s.hashbitlen = hashbitlen;
80
s2.hashbitlen = hashbitlen;
81
82
klee_assume(s.databitlen == s2.databitlen);
83
klee_assume(s. datasize_in_buffer
==
84
s2. datasize_in_buffer );
85
klee_assume(s. datasize_in_buffer
< 512); // optional
86
klee_assume(s2. datasize_in_buffer
< 512); // optional
87
88
klee_assume(databitlen == databitlen1 + databitlen2);
89
klee_assume(databitlen
>= databitlen1); // optional
90
klee_assume(databitlen
>= databitlen2); // optional
91
klee_assume(databitlen1 % 8 == 0); // optional
92
93
Update (&s, NULL , databitlen);
94
95
Update (&s2 , NULL , databitlen1);
96
Update (&s2 , NULL , databitlen2);
97
98
if (s.databitlen != s2.databitlen)
99
klee_assert (0);
100
if (s. datasize_in_buffer
!= s2. datasize_in_buffer )
101
klee_assert (0);
102 }
103
104 int main () {
105
// test (224);
106
test (256);
107
// test (384);
108
// test (512);
109

186
N. Mouha
110
return 0;
111 }
Listing 2. Application to JH (Makefile with visible tabs for readability).
1 TARGET = jh_klee
2
3 all: $(TARGET)
4
5 $(TARGET): $(TARGET).c
6
docker run --rm -v $(CURDIR):/ home/klee/host \
7
--ulimit='stack =-1:-1' klee/klee :2.3 \
8
/tmp/llvm -110- install_O_D_A /bin/clang -I \
9
klee_src/include -emit -llvm -c -g3 -O3 \
10
host/$(TARGET).c -o host/$(TARGET).bc
11
time
docker run --rm -v $(CURDIR):/ home/klee/host \
12
--ulimit='stack =-1:-1' klee/klee :2.3 \
13
klee_build/bin/klee -exit -on -error -type=Assert \
14
host/${TARGET }.bc
15
docker run --rm -v $(CURDIR):/ home/klee/host \
16
--ulimit='stack =-1:-1' klee/klee :2.3 \
17
klee_build/bin/ktest -tool $$(docker run --rm -v \
18
$(CURDIR):/ home/klee/host --ulimit='stack =-1:-1' \
19
klee/klee :2.3 sh -c "ls \
20
host/klee -last /*. assert.err" | head -n 1 | sed \
21
's/. assert.err/. ktest /')
22
23 clean:
24
\rm -rf *.bc klee -last klee -out -*
4.2
Skein
Skein is a ﬁnal-round SHA-3 submission designed by Ferguson et al. [17]. Like
JH, its primary proposal processes the message in 512-bit blocks regardless of
the hash value length.
Although the algorithm used by Skein’s implementation to process the mes-
sage in blocks follows a completely diﬀerent approach compared to JH, the KLEE
proving harness looks quite similar with the main diﬀerence that the assertion
on datasize in buffer is replaced by an assertion on u.h.bCnt.
The execution time is even less than for JH, as KLEE only needs 34 s to
prove that there are no test vectors that violate the assertions.
4.3
BLAKE
Another ﬁnal-round SHA-3 submission is the hash function BLAKE by Aumas-
son et al. [2]. Depending on the hash length, BLAKE uses either a 512-bit or

Exploring Formal Methods for Cryptographic
187
a 1024-bit compression function. It has a datalen variable to keep track of the
number of bits in the buﬀer, similar to datasize in buffer for JH.
However, it also keeps track of a counter for the total number of message bits
processed so far. Depending on the hash length, this counter is stored either in
an array with two 32-bit unsigned integers, or an array with two 64-bit unsigned
integers.
In September 2015, the BLAKE website [4] was updated to correct a bug in all
implementations submitted during the SHA-3 competition. Using our approach,
KLEE easily rediscovers this bug in just ﬁve seconds.
More speciﬁcally, for the 256-bit hash value, it provides a test vector showing
that Update() on 384 bits followed by 512 bits results in a diﬀerent state than
a single update of 384 + 512 = 896 bits.
This is consistent with the bug conditions described by Mouha et al. [24]:
the bug occurs when an incomplete block (less than 512 bits) is followed by a
complete block (512 bits).
Using the updated code on the BLAKE website [4], we run into an obstacle
when running KLEE. It does not terminate within a reasonable amount of time,
as it suﬀers from the path explosion problem mentioned in Sect. 2.
Further analysis shows that an if-branch inside the while-loop is the culprit
of the path explosion. For the 512-bit block size, the BLAKE code is as follows:
while( databitlen >= 512 ) {
state->t32[0] += 512;
if (state->t32[0] == 0)
state->t32[1]++;
//compress32( state, data );
data += 64;
databitlen
-= 512;
}
We found that this path explosion can be avoided if the counter of the mes-
sage bits hashed so far is not stored as an array of two unsigned 32-bit variables,
but as one unsigned 64-bit variable. More speciﬁcally, we change the BLAKE
code as follows:
while( databitlen >= 512 ) {
state->t64 += 512;
//compress32( state, data );
data += 64;
databitlen
-= 512;
}
With this replacement, KLEE proves that the assertions are unreachable in
less than 12 min. Clearly, the execution time is an order of magnitude higher than
in the previous examples. It appears that this is due to the additional counter

188
N. Mouha
variable used by the BLAKE hash function. If this counter variable is removed,
the execution time of KLEE is reduced to only nine seconds.
4.4
Grøstl
We now move on to another SHA-3 ﬁnalist: Grøstl by Gauravaram et al. [20]. The
message is split into either 512-bit or 1024-bit blocks, depending on the length
of the hash value. To the best of our knowledge, no bugs have been reported for
this implementation.
In the reference implementation of Grøstl, not all loops are inside Update()
but also inside the function Transform() that does not just process one block,
but any number of complete blocks. We already notice a ﬁrst problem here: all
variables representing the message length are 64-bit integers, but the function
Transform() is declared with a parameter of the (user-deﬁned) 32-bit type u32,
resulting in an incorrect implicit cast.
As we apply our approach using KLEE, it takes six seconds to ﬁnd a second
bug. The bug is again due to the use of incorrect types: the variable index is
declared as int, which is a 32-bit datatype on 64-bit processors. However, for
suﬃciently large message inputs, the value of index overﬂows, which results in
undeﬁned behavior in the C programming language.
In Listing 3, we provide a program to demonstrate the bug. When com-
piled using gcc, the program writes a large amount of data into memory, almost
certainly resulting in a crash. It gets more interesting when we compile this
program using clang. The undeﬁned behavior causes clang to perform an opti-
mization that avoids a buﬀer overﬂow but instead outputs the same hash for two
messages of a diﬀerent length. Thereby, the implementation violates the collision
resistance property (see Sect. 1).
We searched for implementations that may be vulnerable due to this bug
but did not identify any projects or products that might be impacted. For this
reason, we did not submit a vulnerability report. The most notable use of Grøstl
that we found was as a part of the proof-of-work algorithm of the initial version
of the Monero cryptocurrency. However, the use of Grøstl there has long been
discontinued.
With the two type errors ﬁxed, proving the correctness using KLEE turned
out to be much more diﬃcult than expected. We again face a path explosion
problem, which we addressed by hard-coding the block size and rewriting a loop
that copied data byte-by-byte into a buﬀer. With these modiﬁcations, KLEE
terminated in ten seconds with a proof that the assertions are unreachable.
Listing 3. Due to undeﬁned behavior, the Grøstl bug results in a segmentation fault
when compiled using gcc, or a collision when compiled using clang (groestl bug.c).
1 #include <stdio.h>
2 #include <sys/mman.h>
3 #include "Groestl -ref.h"
4
5 int main () {

Exploring Formal Methods for Cryptographic
189
6
int
hashbitlen = 256;
7
DataLength
len1 = (1uLL <<35) + 8;
8
DataLength
len2 = 8;
9
10
BitSequence* Msg = (BitSequence *) mmap(NULL , len1/8,
11
PROT_READ , MAP_PRIVATE | MAP_ANONYMOUS , -1, 0);
12
13
BitSequence
digest [64];
14
15
printf (" Hashing %llu -bit
message ... \nHash: ", len1);
16
17
Hash(hashbitlen , Msg , len1 , digest);
18
19
for (int i = 0; i < hashbitlen /8; i++) {
20
printf ("%02x", digest[i]);
21
}
22
printf ("\n");
23
24
printf (" Hashing %llu -bit
message ... \nHash: ", len2);
25
26
Hash(hashbitlen , Msg , len2 , digest);
27
28
for (int i = 0; i < hashbitlen /8; i++) {
29
printf ("%02x", digest[i]);
30
}
31
printf ("\n");
32
33
return 0;
34 }
4.5
Keccak
The only SHA-3 ﬁnalist that we did not yet study in this paper, is the submis-
sion that won the competition: Keccak by Bertoni et al. [9]. Keccak pads the
message and splits it into blocks, which are then processed by a cryptographic
permutation. The block size, also known as the rate, has a default value of 1024
bits [9]. We will focus on this default value for now, and discuss the impact of
the block size later.
A vulnerability was reported by Mouha and assigned CVE-2022-37454 [31].
As the winner of the SHA-3 competition, the Keccak reference code is quite
widespread, and the vulnerability impacted various projects such as Python and
PHP. For the details of the vulnerability, we refer to Mouha and Celi [23]. In
this paper, we explain how the vulnerability was discovered using KLEE.
A straightforward approach using KLEE does not terminate in a reasonable
amount of time. Therefore, it can be good to rule out an inﬁnite loop in the
Keccak implementation, as this would lead KLEE to enter into an inﬁnite loop
as well.

190
N. Mouha
For while(i < databitlen) to terminate, a suﬃcient but not necessary
condition is that i advances in every loop iteration. This is easy to check by
introducing an old i variable that is initialized to i. When the variable i is
modiﬁed, we ensure that it is diﬀerent from the previous loop iteration:
if (i == old_i) klee_assert(0);
At the end of the loop, we set old i = i. With this additional code to detect
inﬁnite loops, it takes KLEE less than a second to output an assertion error. By
analyzing the test vector provided by KLEE, we can conﬁrm that we have indeed
found an inﬁnite loop. Note that this additional code is only used to allow us to
easily detect an inﬁnite loop in KLEE, the additional code is not necessary for
a correct implementation (which does not contain an inﬁnite loop).
It turns out that there is not only an input that leads to an inﬁnite loop, but
another input that causes a large amount of data to be written into memory,
leading to a segmentation fault. The details of this buﬀer overﬂow are given by
Mouha and Celi [23] and outside the scope of this paper.
The bug presents itself when there are already x bits of data in the buﬀer,
and then an Update() of 232 −x bits or more is made. Two problems can occur
in Keccak’s code below: the higher bits may be discarded due to an incorrect
cast to a 32-bit integer, and the addition may overﬂow:
partialBlock = (unsigned int) (databitlen - i);
if (partialBlock + state->bitsInQueue > state->rate)
partialBlock = state->rate - state->bitsInQueue;
We can correct this bug by rearranging the code a bit, so that partialBlock
is at most equal to the block size. In that case, a 32-bit integer suﬃces for
partialBlock:
if (databitlen - i > state->rate - state->bitsInQueue)
partialBlock = state->rate - state->bitsInQueue;
else
partialBlock = (unsigned int) (databitlen - i);
For the corrected code, KLEE requires only 39 s to prove that the assertions
cannot be violated.
Finally, we note that KLEE did not seem to terminate within a reason-
able amount of time for block sizes that are not a multiple of two. Such block
sizes were proposed during the SHA-3 competition to handle diﬀerent levels of
security. Unfortunately, it appears to be a common issue that solvers have diﬃ-
culties handling divisions by a constant that is not a power of two. KLEE has
a -solver-optimize-divides ﬂag that tries to optimize such divisions before
passing them to the solver. However, even with this ﬂag, we could not ﬁnd a way
to make KLEE terminate for block sizes that are not a multiple of two.

Exploring Formal Methods for Cryptographic
191
4.6
XKCP (SHA-3)
The eXtended Keccak Code Package (XKCP) [8] is maintained by the Keccak
team. It contains the NIST-standardized variant of the Keccak hash function.
Between the ﬁnal-round Keccak submission and the SHA-3 standard, only the
message padding is diﬀerent.
The implementation of SHA-3 in XKCP is based on the implementation of
the ﬁnal-round Keccak submission. However, it has gone through quite a bit of
refactoring. For this reason, we list XKCP’s SHA-3 as a separate implementation
in Table 1.
The same bug that impacts the ﬁnal-round Keccak submission is present in
XKCP as well, although two calls to Update() with a combined length of 232
bytes (4 GiB) rather than 232 bits (512 MiB) are required to trigger it. More-
over, it has another bug (not present in the Keccak submission) where messages
slightly below 264 bytes result in an inﬁnite loop. This is due to an overﬂow in
the comparison operation (dataByteLen >= (i + rateInBytes)), which has
been replaced by dataByteLen-i >= rateInBytes in the corrected version of
the code.
Using KLEE, it takes less than one second to provide a test vector that
triggers the bug, assuming we again augment the code to detect inﬁnite loops.
For a 1024-bit block size, KLEE requires 20 s to prove that the assertions are
unreachable.
4.7
CoreCrypto
Lastly, we would like to revisit the inﬁnite loop in Apple’s CoreCrypto library.
The vulnerability impacted 11 out of the 12 implemented hash functions and
was assigned CVE-2019-8741 [30]. For details of the bug, we refer to Mouha and
Celi [22].
The approach using KLEE is quite straightforward to implement. KLEE ﬁnds
a vulnerable test vector in less than a second for the original implementation
and can prove that the assertions are unreachable in less than three minutes for
the updated implementation.
We want to point out an interesting coincidence here. If we start from Apple
CoreCrypto’s corrected implementation of Update(), with just a little bit of
refactoring (such as replacing len by dataByteLen-i, renaming variables and
functions, and removing unneeded code), we end up with the corrected imple-
mentation of Update() that is used by XKCP. It seems that Update() is simple
enough that two teams can independently arrive at the same implementation
(up to simple refactoring), but complex enough to contain vulnerabilities that
remained undiscovered for over a decade.
5
Limitations and Discussion
After the SHA-3 competition ended in 2012, vulnerabilities were found in the
implementations of the SHA-3 ﬁnalist BLAKE in 2015 [4], in 11 out of the 12

192
N. Mouha
implemented hash functions of Apple’s CoreCrypto library in 2019 [30], and
recently in the reference implementation of the SHA-3 winner Keccak [31].
These vulnerabilities were all related to the Update() function that is used
to process the message in blocks. Nevertheless, the impact of the vulnerabilities
is quite diﬀerent. Whereas XKCP’s SHA-3 implementation contained a buﬀer
overﬂow vulnerability with the possibility of arbitrary code execution, the impact
of the vulnerability in Apple’s CoreCrypto library is limited to an inﬁnite loop.
The BLAKE vulnerability cannot be used to trigger any runtime error, however,
it can be used to violate the collision resistance property of the hash function.
This allows us to make a ﬁrst observation that approaches to avoid memory
safety problems (such as enforcing coding standards, sandboxing, or moving
away from C/C++ to safer programming languages) would be helpful, but not
suﬃcient to avoid the vulnerabilities described in this paper. We are also reaching
the limits of approaches using test vectors: the Large Data Test (LDT) can take
quite a long time to execute on a 4 GiB message to detect bugs in Apple’s
CoreCrypto library, and for the XKCP bug, a single large call to Update() does
not trigger the vulnerability (as it requires that some data is already present in
the buﬀer).
Therefore, it can be interesting to consider approaches using symbolic execu-
tion. The approach we describe in this paper using KLEE turns out to be quite
easy to deploy. We performed (partial) equivalence checking on the Update()
function with lines involving the message contents and the compression function
commented out. In a production environment, the proving harness would over-
ride these functions rather than commenting them out, so that the proofs can
be part of a continuous integration process similar to how Amazon Web Services
currently deploys CBMC [14].
Whereas approaches using large test vectors can take quite some time to
execute (especially on slow hardware), symbolic execution can ﬁnd bugs in a
few seconds or prove correctness in less than 12 min, as shown by our timings
in Table 1. This makes our approach a low-cost entry towards formal methods
and program veriﬁcation, and perhaps even a stepstone towards more rigorous
approaches used in projects such as HACL∗[32,38] or SPARKSkein [13].
Indeed, the litmus test here would be to see how easily our approach extends
to other submissions in the SHA-3 competition. We studied the implementa-
tions of all ﬁve ﬁnalists of the competition and found that we can either prove
correctness or unearth new bugs (as in the case of Grøstl, where we show how
undeﬁned behavior can violate the collision resistance of the hash function imple-
mentation). And although our approach intends to check whether two calls to
Update() are consistent with one call on the concatenation of both inputs, it
also ﬁnds bugs that can be triggered by one call to Update(), as shown by the
bugs in Grøstl and Apple’s CoreCrypto library (as they cause KLEE to enter
into an inﬁnite loop).
Lastly, although our approach was helpful to discover bugs, we stress again
that it is insuﬃcient to claim that the implementations are correct. For example,
we make no statements about potential bugs in Init(), Final(), or Hash(),

Exploring Formal Methods for Cryptographic
193
nor potential bugs in the lines of Update() that were commented out. We also
do not look into bugs related to the use of the API, such as those found by
Benmocha et al. [6].
6
Conclusion and Future Work
We revisited the implementations of the ﬁve ﬁnalists of the NIST SHA-3 compe-
tition. These had been subject to a rigorous public review process from 2008 to
2012. However, it was not until 2015 that a vulnerability was discovered in the
implementation of BLAKE, and very recently in the winning Kecak submission
using the technique that is ﬁrst described in this paper.
We showed how these bugs can be (re-)discovered in only a matter of sec-
onds, requiring only minimal eﬀort to construct a proving harness for the original
code. Moreover, we also found a vulnerability in the Grøstl submission, allow-
ing the construction of two messages that result in the same hash value when
compiled using clang. Our approach would also have discovered a bug in Apple’s
CoreCrypto library that was reported in 2019.
Our approach requires symbolic execution to check whether two Update()
calls (with some lines of code removed) are equivalent to one Update() call on
the concatenation of both inputs. To check this property, we used the KLEE
symbolic execution framework.
Unfortunately, our approach involves a bit of trial and error. In particular,
to prove that none of the assertions fail, we sometimes needed to rewrite the
code a bit to avoid that KLEE fails to terminate due to path explosion. This is a
limitation as we would ideally like to make no changes at all to the source code,
but perhaps this is an acceptable compromise to achieve the goal of (partial)
program veriﬁcation.
An interesting direction for future work is to ﬁnd a way to extend our app-
roach to Keccak and SHA-3 when the block size is not a power of two.
References
1. AdaCore, Thales: Implementation Guidance for the Adoption of SPARK (2020).
https://www.adacore.com/uploads/books/pdf/Spark-Guidance-1.2-web.pdf
2. Aumasson, J.P., Henzen, L., Meier, W., Phan, R.C.W.: SHA-3 proposal BLAKE.
submission to the NIST SHA-3 competition (round 3) (2010). https://www.
aumasson.jp/blake/blake.pdf
3. Aumasson, J.P., Romailler, Y.: Automated testing of crypto software using diﬀer-
ential fuzzing. Black Hat USA 2017 (2017). https://yolan.romailler.ch/ddl/talks/
CDF-wp BHUSA2017.pdf
4. Aumasson, J.P.: SHA-3 proposal BLAKE (2015). https://web.archive.org/web/
20150921185010/https://131002.net/blake/
5. Ball, T., Cook, B., Levin, V., Rajamani, S.K.: SLAM and static driver veriﬁer:
technology transfer of formal methods inside Microsoft. In: Boiten, E.A., Derrick,
J., Smith, G. (eds.) IFM 2004. LNCS, vol. 2999, pp. 1–20. Springer, Heidelberg
(2004). https://doi.org/10.1007/978-3-540-24756-2 1

194
N. Mouha
6. Benmocha, G., Biham, E., Perle, S.: Unintended features of APIs: cryptanalysis
of incremental HMAC. In: Dunkelman, O., Jacobson, Jr., M.J., O’Flynn, C. (eds.)
SAC 2020. LNCS, vol. 12804, pp. 301–325. Springer, Cham (2021). https://doi.
org/10.1007/978-3-030-81652-0 12
7. Bernstein, D.J., Lange, T.: eBACS: ECRYPT benchmarking of cryptographic sys-
tems (2022). https://bench.cr.yp.to
8. Bertoni, G., Daemen, J., Hoﬀert, S., Peeters, M., Assche, G.V., Keer, R.V.:
eXtended Keccak code package (2022). https://github.com/XKCP/XKCP
9. Bertoni, G., Daemen, J., Peeters, M., Assche, G.V.: The Keccak SHA-3 submission.
Submission to the NIST SHA-3 competition (round 3) (2011). https://keccak.
team/ﬁles/Keccak-submission-3.pdf
10. Bleichenbacher, D., Duong, T., Kasper, E., Nguyen, Q.: Project Wycheproof
(2019). https://github.com/google/wycheproof
11. Cadar, C., Dunbar, D., Engler, D.R.: KLEE: unassisted and automatic generation
of high-coverage tests for complex systems programs. In: Draves, R., van Renesse,
R. (eds.) OSDI 2008, pp. 209–224. USENIX Association (2008)
12. Cadar, C., Ganesh, V., Pawlowski, P.M., Dill, D.L., Engler, D.R.: EXE: automat-
ically generating inputs of death. In: Juels, A., Wright, R.N., di Vimercati, S.D.C.
(eds.) CCS 2006, pp. 322–335. ACM (2006). https://doi.org/10.1145/1180405.
1180445
13. Chapman, R., Botcazou, E., Wallenburg, A.: SPARKSkein: a formal and fast refer-
ence implementation of skein. In: Simao, A., Morgan, C. (eds.) SBMF 2011. LNCS,
vol. 7021, pp. 16–27. Springer, Heidelberg (2011). https://doi.org/10.1007/978-3-
642-25032-3 2
14. Chong, N., et al.: Code-level model checking in the software development workﬂow
at Amazon web services. Softw. Pract. Exp. 51(4), 772–797 (2021). https://doi.
org/10.1002/spe.2949
15. Chudnov, A., et al.: Continuous formal veriﬁcation of Amazon s2n. In: Chockler,
H., Weissenbacher, G. (eds.) CAV 2018. LNCS, vol. 10982, pp. 430–446. Springer,
Cham (2018). https://doi.org/10.1007/978-3-319-96142-2 26
16. Clarke, E., Kroening, D., Lerda, F.: A tool for checking ANSI-C programs. In:
Jensen, K., Podelski, A. (eds.) TACAS 2004. LNCS, vol. 2988, pp. 168–176.
Springer, Heidelberg (2004). https://doi.org/10.1007/978-3-540-24730-2 15
17. Ferguson, N., et al.: The skein hash function family. Submission to the NIST SHA-
3 competition (round 3) (2010). https://www.schneier.com/wp-content/uploads/
2015/01/skein.pdf
18. Forsythe,
J.,
Held,
D.:
NIST
SHA-3
competition
security
audit
results
(2009). https://web.archive.org/web/20120222155656if /http://blog.fortify.com/
repo/Fortify-SHA-3-Report.pdf
19. Ganesh, V., Dill, D.L.: A decision procedure for bit-vectors and arrays. In: Damm,
W., Hermanns, H. (eds.) CAV 2007. LNCS, vol. 4590, pp. 519–531. Springer, Hei-
delberg (2007). https://doi.org/10.1007/978-3-540-73368-3 52
20. Gauravaram, P., et al.: Grøstl - a SHA-3 candidate. Submission to the NIST SHA-3
competition (round 3) (2011). https://www.groestl.info/Groestl.pdf
21. Lattner, C., Adve, V.S.: LLVM: a compilation framework for lifelong program
analysis & transformation. In: CGO 2004, pp. 75–88. IEEE Computer Society
(2004). https://doi.org/10.1109/CGO.2004.1281665
22. Mouha, N., Celi, C.: Extending NIST’s CAVP testing of cryptographic hash func-
tion implementations. In: Jarecki, S. (ed.) CT-RSA 2020. LNCS, vol. 12006, pp.
129–145. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-40186-3 7

Exploring Formal Methods for Cryptographic
195
23. Mouha, N., Celi, C.: A vulnerability in implementations of SHA-3, SHAKE,
EdDSA, and other NIST-approved algorithms. In: Rosulek, M. (ed.) CT-RSA 2023.
LNCS, vol. 13871, pp. 3–28. Springer, Cham (2023). https://doi.org/10.1007/978-
3-031-30872-7 1
24. Mouha, N., Raunak, M.S., Kuhn, D.R., Kacker, R.: Finding bugs in crypto-
graphic hash function implementations. IEEE Trans. Reliab. 67(3), 870–884
(2018). https://doi.org/10.1109/TR.2018.2847247
25. National Bureau of Standards: Validating the Correctness of Hardware Implemen-
tations of the NBS Data Encryption Standard. NBS Special Publication 500-20
(1977).
https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nbsspecialpublication500-
20e1977.pdf
26. National Institute of Standards and Technology: Announcing Request for Candi-
date Algorithm Nominations for a New Cryptographic Hash Algorithm (SHA-3)
Family. 72 Fed. Reg. (2007). https://www.federalregister.gov/d/E7-21581
27. National Institute of Standards and Technology: ANSI C Cryptographic API Pro-
ﬁle for SHA-3 Candidate Algorithm Submissions (2008). https://csrc.nist.gov/
CSRC/media/Projects/Hash-Functions/documents/SHA3-C-API.pdf
28. National Institute of Standards and Technology: Description of Known Answer
Test
(KAT)
and
Monte
Carlo
Test
(MCT)
for
SHA-3
Candidate
Algo-
rithm
Submissions
(2008).
https://csrc.nist.gov/CSRC/media/Projects/Hash-
Functions/documents/SHA3-KATMCT1.pdf
29. National Institute of Standards and Technology: Hash Functions: SHA-3 Project
(2020). https://csrc.nist.gov/projects/hash-functions/sha-3-project
30. National Vulnerability Database: CVE-2019-8741 (2020). https://nvd.nist.gov/
vuln/detail/CVE-2019-8741
31. National Vulnerability Database: CVE-2022-37454 (2022). https://nvd.nist.gov/
vuln/detail/CVE-2022-37454
32. Polubelova, M., et al.: HACLxN: veriﬁed generic SIMD crypto (for all your
favourite platforms). In: Ligatti, J., Ou, X., Katz, J., Vigna, G. (eds.) CCS 2020,
pp. 899–918. ACM (2020). https://doi.org/10.1145/3372297.3423352
33. Protzenko, J., Ho, S.: Functional pearl: zero-cost, meta-programmed, dependently-
typed stateful functors in F∗. CoRR abs/2102.01644 (2021). https://arxiv.org/abs/
2102.01644
34. Saarinen, M.J.O.: BRUTUS (2016). https://github.com/mjosaarinen/brutus
35. Vranken, G.: Cryptofuzz - diﬀerential cryptography fuzzing (2022). https://github.
com/guidovranken/cryptofuzz
36. Wang, X., Yin, Y.L., Yu, H.: Finding collisions in the full SHA-1. In: Shoup, V.
(ed.) CRYPTO 2005. LNCS, vol. 3621, pp. 17–36. Springer, Heidelberg (2005).
https://doi.org/10.1007/11535218 2
37. Wu, H.: The hash function JH. Submission to the NIST SHA-3 competition (round
3) (2011). https://www3.ntu.edu.sg/home/wuhj/research/jh/jh round3.pdf
38. Zinzindohou´e, J.K., Bhargavan, K., Protzenko, J., Beurdouche, B.: HACL∗: a ver-
iﬁed modern cryptographic library. In: Thuraisingham, B., Evans, D., Malkin, T.,
Xu, D. (eds.) CCS 2017, pp. 1789–1806. ACM (2017). https://doi.org/10.1145/
3133956.3134043

Public-Key Cryptography

A Tightly Secure ID-Based Signature
Scheme Under DL Assumption in AGM
Jia-Chng Loh1(B), Fuchun Guo1, Willy Susilo1, and Guomin Yang2
1 Institute of Cybersecurity and Cryptology, School of Computing and Information
Technology, University of Wollongong, Wollongong, Australia
{jial,fuchun,wsusilo}@uow.edu.au
2 Singapore Management University, Singapore, Singapore
gmyang@smu.edu.sg
Abstract. Identity-based signatures (IBS) can be veriﬁed using the
signer identity information as the public key, and hence, there is no
need for certiﬁcate management that proves the corresponding public
key ownership. Unfortunately, none of the existing IBS schemes has
security proven as tight as the discrete logarithm (DL) problem, the
hardest problem in the cyclic group setting, under the standard EUF-
CMA security model. Recently, the introduction of proving security in
the algebraic group model (AGM), where the adversary’s computation is
algebraic, enables some ordinary signature schemes to be proven tightly
reducible under DL assumption and EUF-CMA. To date, however, it
remains unknown whether IBS schemes can also be proven as secure as
the DL problem in the AGM. Achieving tight security in IBS schemes
under standard EUF-CMA is challenging, due to the need to take extra
precautions against adaptive queries on user private keys by the adver-
sary. In this work, we show, for the ﬁrst time, an IBS scheme with tight
security under DL assumption and EUF-CMA in the AGM. The scheme
features a minimal signature size of two group elements, with a reduction
loss factor of two.
Keywords: Identity-based signatures · Provable security · Tight
reduction · Algebraic group model
1
Introduction
Identity-Based Signature with the Ideal Security. Digital signature is one
of the main cryptographic primitives to enable authenticated electronic commu-
nications [15]. However, the public key infrastructure (PKI) is necessary to pro-
vide a certiﬁcate verifying the validity of the signer’s public key in practical use.
The notion of identity-based signatures (IBS) was introduced by Shamir [37],
where the signer’s identity, such as an ID number or email address, serves as the
public key, eliminating the need for a certiﬁcate verifying the signer’s authority.
Therefore, IBS can be publicly veriﬁed via the signer’s identity. The standard
security model for IBS, namely existential unforgeability against chosen identity-
and-message attacks (EUF-CMA) [5], guarantees that it’s impossible to forge a
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 199–219, 2023.
https://doi.org/10.1007/978-3-031-35486-1_10

200
J.-C. Loh et al.
new signature on a unique message and identity pair, even if the attacker has
access to many user private keys and many signatures.
When proving the security of a cryptographic scheme, the security reduction
is tight if security loss L is a constant or a small number L ≥1. Security loss
is an important factor when it comes to deciding the concrete size of the secu-
rity parameter of a scheme in practice because we must increase the size of the
security parameter so that it compensates for the security loss, unfortunately, it
degrades the scheme eﬃciency. On the other hand, the security of a scheme is
determined by the diﬃculty of the underlying problem. The harder the problem,
the stronger the security provided by the scheme. Considering the cyclic groups
setting, it is known that the discrete logarithm (DL) problem is the hardest one
because algorithms that can solve the DL problem can be used to solve the com-
putational Diﬃe-Hellman (CDH) problem and its variants [22,28]. Therefore,
schemes with ideal security, i.e., as secure as the DL problem in the standard
EUF-CMA security model, oﬀer the strongest security assurance in the context
of cyclic groups.
There are several IBS schemes that have been proven secure under the EUF-
CMA security model and DL assumption [5,12,20,31] or CDH assumption and
its variants [3,13,23,27,33,34]. However, none of these schemes achieve the ideal
security, meaning their security cannot be tightly reduced to the DL problem
under EUF-CMA.
The Algebraic Group Model. The concept of the algebraic algorithm was
initially introduced by Boneh and Venkatesan in [9]. It has since been employed in
several studies, including those that aim to demonstrate impossibilities [1,9,10,
14,21,26,32]. The formalization of the algebraic group model (AGM) was later
carried out by Fuchsbauer, Kiltz, and Loss in [16]. In the AGM, the security
of a scheme is proven through a security reduction that demonstrates how a
probabilistic polynomial-time (PPT) adversary can compromise the scheme, by
idealizing the adversary’s computations as algebraic, yielding representations
that describe how the output group element can be generated from received
group elements.
In the EUF-CMA security model, due to the algebraic nature of the adver-
sary’s forgeries and representations, some standard signature schemes such as
BLS [8] and Schnorr [36] can be reduced in the AGM with random oracles to
extract DL solutions with an overwhelming success probability. This has been
shown in works such as [16,17], respectively. On the other hand, variants of
secure signature schemes have been analyzed in the AGM [2,4,24,25,30]. How-
ever, to date, the security of identity-based signatures (IBS) in the AGM has
not yet been studied. Hence, it is unknown whether the security of IBS schemes
can also be proven as tight as the DL problem in the AGM under EUF-CMA.
Challenge. It is not a trivial task to have tight security for IBS schemes, espe-
cially in the standard EUF-CMA security model, due to the adversary may
adaptively ask for user private keys during the query phase. Therefore, a major
challenge in achieving tight reduction for IBS under the DL assumption and
EUF-CMA is developing a reduction algorithm that can simultaneously (1)

A Tightly Secure IBS Scheme Under DL Assumption in AGM
201
respond to user private key queries and (2) extract problem solutions based
on forged signatures. However, these two tasks are often conﬂicting, if the user
private key is simulated, the forged signature is often not reducible in security
reductions.
Existing reduction techniques [11,13,20,27,34] address the ﬁrst challenge by
dividing the simulator’s handling of user identity and signature queries, resulting
in at least one target forgery with a non-simulatable user private key. If the
chosen identity of the forgery matches the target, the simulator can extract
the problem solution during the forgery phase, bypassing the second challenge.
However, this approach leads to a loose reduction due to the random selection
of the target identity and a security loss of at least q query times.
1.1
Contribution
In this work, we show, for the ﬁrst time, how to obtain a tightly secure IBS
scheme under DL assumption and EUF-CMA by adopting the algebraic adver-
sary. The contributions are summarized as follows.
We ﬁrst present a new IBS scheme, named BLS-IBS, which is extended from
the ordinary BLS signature scheme [8] to the identity-based setting. This results
in signatures consisting of only two group elements. For example, let (p, g, G) be a
bilinear group tuple in prime order p with a generator g ∈G and H1, H2 :→G be
cryptographic hash functions. The signature σID,m = (σ(1)
ID,m, σ(2)
ID,m) on identity
and message pair (ID, m) is deﬁned as
σ(1)
ID,m = dID · H2(m)r,
σ(2)
ID,m = gr,
where dID = H1(ID)x is the user private key that can be obtained based on the
BLS signatures with master secret key x ∈Zp.
To demonstrate that the security of the BLS-IBS scheme can be tightly
reduced to the DL problem, we propose a security reduction in the AGM that
addresses the two aforementioned challenges. Speciﬁcally,
– Our reduction can simulate any user private key, which enables the simula-
tor to respond to all user private key queries and signature queries without
aborting during the query phase of the EUF-CMA security game, regardless
of the identities that have been queried for signatures.
– It is possible to reduce any forgery, even if the private key of the forged identity
is simulatable. The algebraic adversary’s forgery and representations play a
crucial role in this reduction process, helping the simulator ﬁnd a solution to
the problem.
It is also worth noting that the security analysis in the AGM of BLS-IBS is
more complex than that of ordinary BLS in the AGM due to the fact that the
adversary’s forgery and representations can be classiﬁed into several cases, rather
than just two cases. In particular, we design two indistinguishable simulations
in the AGM with random oracles that can simulate any user private key and
extract DL solution with at least half of the success probability, resulting in a
tight reduction with a loss factor of two.

202
J.-C. Loh et al.
1.2
Other Related Work
IBS Schemes Under DL Assumption and EUF-CMA. The ﬁrst secure
EUF-CMA IBS scheme under DL assumption, known as Beth-IBS, was derived
from Bellare et al.’s framework [5] transformed Beth’s identiﬁcation scheme [7]
to IBS. However, due to the lack of security analysis for the Beth-IBS scheme,
Galindo and Garcia [20] proposed a new IBS scheme based on the well-known
Schnorr signature [36] in the random oracle model [6], namely Schnorr-like IBS
scheme. The Schnorr-like IBS scheme is considered the most eﬃcient IBS to date,
due to its pairing-free setting. Although its security was improved by Chatterjee
et al. [11], it is still loosely reduced to the DL problem due to the need for the
reset lemma [35], which has been proven that the resulting security loss must
suﬀer from the tightness barrier – the reduction loss cannot be tight [26].
IBS Schemes Under CDH Assumption. The ﬁrst IBS scheme without ran-
dom oracles was proposed by Paterson and Schuldt [34], based on Waters’ signa-
tures [38], and secure under the EUF-CMA and CDH assumption. Narayan and
Parampalli [29] further improved the scheme by reducing the size of the public
parameters. Unfortunately, their security reductions are not tight and the com-
putation cost is high. Recently, Yi et al. [39] proposed a new IBS scheme with a
more eﬃcient computation cost, but the reduction loss remains non-tight under
the CDH assumption.
Tightly Secure IBS Schemes Under the Strong Assumption and Weak
Security Model. Recently, Fukumitsu and Hasegawa [18,19] proposed enhance-
ments to the Galindo and Garcia’s Schnorr-like IBS [20] to design IBS schemes
with a tight security reduction. However, these two schemes are only proven
under a strong assumption, i.e., the decisional Diﬃe-Hellman assumption, and
in the weak-EUF-CMA security model [40], where the adversary is restricted
to asking for a user’s private key if the identity has already been requested for
signatures.
2
Preliminaries
2.1
Deﬁnition of Identity-Based Signatures
An identity-based signature (IBS) scheme consists of the following algorithms.
– Setup(1k): A setup algorithm that generates the master public and secret key
pair (mpk, msk) when given the security parameters 1k as input.
– Extract(mpk, msk, ID): A user private key extraction algorithm that takes
as input the master public and secret key pair (mpk, msk) and a user identity
ID, and returns the user private key dID.
– Sign(mpk, dID, m): An algorithm for generating a signature, which takes as
input the master public key mpk, user’s private key dID and message m, and
outputs a signature σID,m.
– Verify(mpk, ID, m, σID,m): An algorithm for verifying inputs (mpk, ID, m,
σID,m) which outputs either 1 for acceptance or 0 for rejection.

A Tightly Secure IBS Scheme Under DL Assumption in AGM
203
Correctness. For any user identity ID and user private key dID that is gener-
ated based on the master public and secret key pair (mpk, msk), i.e., dID ←
Extract(mpk, msk, ID), signing a message m with dID must return a correct
signature σID,m ←Sign(mpk, dID, m) that is valid on user ID, i.e., the veriﬁ-
cation holds 1 ←Verify(mpk, ID, m, σID,m).
2.2
Security of EUF-CMA for IBS
The notion of existential unforgeability against chosen identity-and-message
attacks (EUF-CMA) [5] security model for IBS schemes is deﬁned between a
challenger and an adversary as follows.
– Setup Phase: Let LE be a set of extraction queries. The challenger runs
Setup algorithm to compute a master public and secret key pair (mpk, msk).
The challenger forwards mpk to the adversary.
– Query Phase: The adversary adaptively asks for user private keys dIDi on
any identity IDi to the extraction oracle OE and signatures σIDi,mi on any
identity and message pair (IDi, mi) to the signing oracle OS.
Extraction oracle OE(IDi): On input i-th query for IDi, it ﬁrst checks
whether ⟨IDi, ·⟩∈LE exists. The challenger retrieves user private key
dIDi if it ﬁnds ⟨IDi, dIDi⟩. Otherwise, the challenger calls Extract(mpk,
msk, IDi) →dIDi algorithm and stores ⟨IDi, dIDi⟩to LE. The chal-
lenger returns dIDi.
Signing oracle OS(IDi, mi): On input i-th query for (IDi, mi), it ﬁrst checks
and retrieves dIDi if ⟨IDi, dIDi⟩∈LE exists. If (IDi, dIDi) /∈LE, the
challenger calls extraction algorithm Extract(mpk, msk, IDi) →dIDi
and stores user private key ⟨IDi, dIDi⟩to LE. At the end, the challenger
calls signing algorithm Sign(mpk, dIDi, mi) →σIDi,mi. The challenger
returns σIDi,mi.
– Forgery Phase: The adversary returns a forged signature σID∗,m∗on a
chosen identity and message pair (ID∗, m∗). The adversary wins if the veriﬁ-
cation holds Verify(mpk, ID∗, m∗, σID∗,m∗) = 1, such that ID∗has not been
queried to OE and (ID∗, m∗) has not been queried to OS.
Deﬁnition 1. An IBS scheme is (ϵ, qe, qs, t)-secure in the EUF-CMA security
model if it is infeasible that any probabilistic polynomial-time adversary who runs
in t polynomial time and makes at most qe extraction queries and qs signing
queries has an advantage at most ϵ in winning the game, where ϵ is a negligible
function of the input security parameter.
2.3
Bilinear Discrete Logarithm Problem
Let G, GT be groups of prime order p with generator g ∈G. A bilinear map
e : G × G →GT is deﬁned in the pairing group setting. The discrete logarithm
(DL) problem is to compute a ∈Zp, given a random group element ga ∈G.
Deﬁnition 2. The (ϵ, t)-DL assumption holds in G if there is no probabilistic
polynomial-time adversary who runs in t polynomial time has an advantage at
most ϵ to solve the DL problem in G.

204
J.-C. Loh et al.
2.4
The Algebraic Algorithms
Fuchsbauer, Kiltz, and Loss [16] formalized the algebraic group model (AGM),
which considers the adversary’s computation as algebraic. The deﬁnition of the
algebraic algorithm is described as follows.
Deﬁnition 3. (Algebraic Algorithm, Deﬁnition 2.1 of [16]) Suppose the adver-
sary in the security game is algebraic, and it is given (X0, X1, ..., Xn) ∈Gn+1
group elements, such that X0 = g ∈G be the group generator. Whenever the
adversary outputs Z ∈G, it also attaches a representation vector [⃗π] ∈Zn+1
p
,
where [⃗π] = (π0, π1, ..., πn) ∈Zn+1
p
, that indicates how Z is generated based on
received group elements, such that Z = n
i=0 Xπi
i .
3
The BLS-IBS Scheme
The BLS-IBS scheme is extended based on the BLS signature [8] to the identity-
based setting. The scheme’s algorithms are deﬁned as follows.
– Setup: On input security parameter 1k. Let G be the notion of groups, g ∈G
be the generator of group, p be the prime order, e : G×G →GT be a bilinear
map, where GT denotes the target group, and H1, H2 : {0, 1}∗→G be two
cryptography hash functions. It selects x ∈Z∗
p and computes X = gx. The
master public and secret key pair (mpk, msk) is returned as
mpk = (g, p, e, G, GT , H1, H2, X),
msk = x.
– Extract: On input (mpk, msk) and user identity ID ∈{0, 1}∗. It calls
H1(ID) = HID ∈G and computes user private key dID as
dID = (HID)x.
– Sign: On input (mpk, dID, m). It calls H2(m) = Hm ∈G and randomly
selects r ∈Z∗
p. The signature σID,m = (σ(1)
ID,m, σ(2)
ID,m) on (ID, m) is returned
as
σ(1)
ID,m = dID · (Hm)r,
σ(2)
ID,m = gr.
– V erify: On input (mpk, ID, m, σID,m), it checks whether or not the following
equation holds
e(σ(1)
ID,m, g) = e(HID, X) · e(Hm, σ(2)
ID,m).
Correctness. Recall that X = gx is part of mpk. The scheme is correct if the valid-
ity of signature σID,m = (σ(1)
ID,m, σ(2)
ID,m) on identity and message pair (ID, m)
generated with user private key dID holds.
e(σ(1)
ID,m, g) = e(HID, X) · e(Hm, σ(2)
ID,m)
= e(H1(ID)x · H2(m)r, g).

A Tightly Secure IBS Scheme Under DL Assumption in AGM
205
4
Security Proof
In this section, we begin by presenting the high-level security proof for the BLS-
IBS scheme in the AGM with random oracles under EUF-CMA and DL assump-
tion. Then, we detail how we design two indistinguishable simulations that can
simulate any user private key. Afterwards, we classify the algebraic adversary’s
forgery and representations into several cases and show that the simulator can
extract for problem solution in any of them. Finally, we provide full security
proof.
High-Level. Given a DL problem instance tuple (g, ga), we design two indis-
tinguishable simulations R1, R2, which control hash responses as the random
oracles. We set simulation R1 to embed ga into master public key X and every
signature randomness σ(2)
IDi,mi; or simulation R2 to embed ga into every hash
responses HIDi, Hmi – including HID∗, Hm∗. The simulation setup is detailed as
in Table 1, where all x, hIDi, hmi, u1,i, v1,i, u2,i, v2,i, si, ti, ri ∈Z∗
p are randomly
chosen. During the forgery phase, we classify the algebraic adversary’s forgery
and representations into several cases as illustrated in Fig. 1. By obtaining the
discrete logarithm of any of the embedded elements through forgery and repre-
sentations, we demonstrate that the DL problem solution can be found in either
simulation R1 or R2.
Table 1. Simulations of the BLS-IBS scheme
Elements Simulation R1
Simulation R2
X
ga
gx
HIDi
ghIDi
gau1,i+v1,i
Hmi
ghmi
gau2,i+v2,i
dIDi
gahIDi
gau1,ix+v1,ix
σ(1)
IDi,mi
ga(hIDi +hmi si)+hmi ti
ga(u1,ix+u2,iri)+v1,ix+v2,iri
σ(2)
IDi,mi
gasi+ti
gri
In the security of the BLS-IBS scheme, for some randomly chosen x, hIDi,
hmi, ri ∈Z∗
p, let X = gx, HIDi = ghIDi, Hmi = ghmi, and σ(2)
IDi,mi = gri. It is
easy to see every user private key dIDi, including that of the forged identity ID∗,
is capable of being simulated in both simulations R1 and R2. As a result, our
simulator will not abort during the query phase of the EUF-CMA security game
as it is capable of responding to any user private key query or signature query.
During the forgery phase of the security game in the AGM and EUF-CMA
security model, the algebraic adversary returns a forged signature σID∗,m∗=
(σ(1)
ID∗,m∗, σ(2)
ID∗,m∗) = ((HID∗)x·(Hm∗)r∗, gr∗) on a chosen identity and message
pair (ID∗, m∗) and its representation vectors [⃗α], [⃗β] in Zp. Speciﬁcally, for some
randomness r∗∈Z∗
p, forgery σID∗,m∗is deﬁned as
σ(1)
ID∗,m∗= ghID∗x+hm∗r∗,
σ(2)
ID∗,m∗= gr∗.

206
J.-C. Loh et al.
And forgery σID∗,m∗can also be algebraically described with the corresponding
representation vectors [⃗α], [⃗β] in Zp, such that
σ(1)
ID∗,m∗=gα0Xα1
qh1

i
(HIDi)α2,i
qh2

i
(Hmi)α3,i
qe

i
(dIDi)α4,i
qs

i
(σ(1)
ID∗,mi)α5,i(σ(2)
ID∗,mi)α6,i,
σ(2)
ID∗,m∗=gβ0Xβ1
qh1

i
(HIDi)β2,i
qh2

i
(Hmi)β3,i
qe

i
(dIDi)β4,i
qs

i
(σ(1)
ID∗,mi)β5,i(σ(2)
ID∗,mi)β6,i,
where qh1 is number of identity hash queries, qh2 is number of message hash
queries, qe is number of extraction queries, and qs is number of signing queries.
Note that since the private keys of all users can be simulated, it is possible to
exclude signatures queries for (IDi, ·) because the adversary can compute the
signatures themselves with the knowledge of the user private keys dIDi, except
for dID∗which the adversary is restricted to querying in the EUF-CMA security
model.
Using the above deﬁnitions, the simulator can derive the following two mod-
ular equations.
hID∗x + hm∗r∗= α0 + xα1 +
qh1

i
hIDiα2,i +
qh2

i
hmiα3,i+
qe

i
hIDixα4,i +
qs

i
(hID∗x + hmiri)α5,i + riα6,i,
r∗= β0 + xβ1 +
qh1

i
hIDiβ2,i +
qh2

i
hmiβ3,i+
qe

i
hIDixβ4,i +
qs

i
(hID∗x + hmiri)β5,i + riβ6,i.
By rearranging with the term x and some ri ∈[qs], they can be simpliﬁed as
hID∗x + hm∗r∗= xθ + ˆθ +
qs

i
riωαi,
(1)
r∗= xδ + ˆδ +
qs

i
riωβi,
(2)

A Tightly Secure IBS Scheme Under DL Assumption in AGM
207
where δ, ˆδ, θ, ˆθ, ωαi, ωβi∈Zp are obtained from representation vectors [⃗α], [⃗β] in
Zp and elements hIDi, hID∗, hmi, hID∗in Z∗
p. We defer the deﬁnition in the full
proof later. By using Eq. (1) and (2), we derive a new modular equation
x(hID∗+ hm∗δ −θ) +
qs

i
ri

hm∗ωβi −ωαi

= ˆθ −hm∗ˆδ.
Because the algebraic adversary is adaptive, it is necessary to analyze all the
potential outcomes of their forgeries and representations. Figure 1 provides a
diagrammatic overview of how diﬀerent cases are classiﬁed, and how either (x, ri)
or (hIDi, hmi, hID∗, hm∗) can be extracted in Z∗
p through simulation R1 or R2.
Suppose adversary behaviours A, B, C, D, A, B, C, D, as described in Fig. 1, are
classiﬁed into condition F1, F2, such that F1 : A ∨B and F2 : (A ∧B) ∧(C ∨
D ∨(C ∧D)). We see that all behaviours are captured, i.e. F1 ∨F2 = 1.
Fig. 1. A diagrammatic representation of the security proof in the AGM
Based on the deﬁnition of simulations R1, R2 as deﬁned in Table 1, we see
every element x, ri, hIDi, hmi, hID∗, hm∗has been implicitly embedded with

208
J.-C. Loh et al.
unknown DL problem solution a, and known randomness si, ti, u1,i, v1,i, u2,i, v2,i,
u∗
1, v∗
1, u∗
2, v∗
2 ∈Z∗
p. It is easy to see they are perfectly hidden from the view of
the adversary, such that
x = a,
ri = asi + ti,
hIDi = au1,i + v1,i,
hmi = au2,i + v2,i,
hID∗= au∗
1 + v∗
1,
hm∗= au∗
2 + v∗
2.
Therefore, the simulator manages to extract DL solution a as long as it obtains
any of them x, ri, hIDi, hmi, hID∗, hm∗in Z∗
p. The full proof is detailed as follows.
Theorem 1. Suppose hash functions H1, H2 are random oracles. If the DL
problem is hard, the BLS-IBS scheme is secure against the EUF-CMA in the
AGM with random oracles with a loss factor of 2.
Proof. Suppose there exists an algebraic adversary who can (t, qe, qs, ϵ)-break the
BLS-IBS scheme in the EUF-CMA model. We construct a simulator to solve the
DL problem. Given as input a problem instance (g, ga) over the pairing group
tuple PG = (p, g, e, G, GT ), the simulator controls the random oracles H1, H2
and runs the algebraic adversary in a randomly chosen simulation R1 or R2
under condition F1 and F2, respectively.
Simulation R1: Suppose the algebraic adversary returns forgery on (ID∗, m∗)
under condition F1, given the DL problem instance ga, the simulation is pro-
grammed by embedding ga to master public key X and every queried signature
element σ(2)
ID∗,mi = gri as follows.
Setup. The simulator sets X = ga. The master public key is returned mpk =
(g, p, e, G, GT , H1, H2, X).
Hash Query. At the beginning, the simulator prepares two empty sets LH1, LH2
to record all hash queries and responses as follows.
H1(IDk): On an i-th random oracle query (IDi). If ⟨IDi, HIDi, hIDi⟩∈LH1,
the simulator responds to this query following the record. Otherwise, the
simulator randomly selects hIDi ∈Zp and sets
HIDi = ghIDi .
It programs H1(IDi) = HIDi and stores ⟨IDk, HIDi, hIDi⟩into LH1.
The simulator returns H1(IDi) = HIDi.
H2(mi): On an i-th random oracle query (mi). If ⟨mi, Hmi, hmi⟩∈LH2, the
simulator responds to this query following the record. Otherwise, the
simulator randomly selects hmi ∈Zp and sets
Hmi = ghmi.
It programs H2(mi) = Hmi and stores ⟨mi, Hmi, hmi⟩into LH2. The
simulator returns H2(mi) = Hmi.

A Tightly Secure IBS Scheme Under DL Assumption in AGM
209
Query. The adversary makes extraction queries and signing queries in this phase.
The simulator prepares an empty set LE to record all queries and responses
as follows.
OE(IDi): On an i-th extraction query (IDi), the simulator checks whether
⟨IDi, dIDi⟩∈LE exits. If there is, the simulator retrieves user private
key dIDi which is based the deﬁnition as follows. Otherwise, it calls
H1(IDi) →HIDi = ghIDi , retrieves hIDi from LH1, and sets
dIDi = (ga)hIDi .
The simulator stores ⟨IDi, dIDi⟩into LE. The user private key dIDi is
returned.
Correctness. It is easy to see dIDi is a valid user private key, such that
dIDi = (ga)hIDi = H1(IDi)x.
OS(IDi, mi): On an i-th signing query (IDi, mi). It checks whether ⟨IDi,
dIDi⟩∈LE. It calls OE(IDi) →dIDi to generate fresh user private key
if it does not exist. Otherwise, it retrieves dIDi from LE. The simulator
calls H2(mi) →Hmi = ghmi and retrieves hmi from LH2, randomly
chooses si, ti ∈Zp, and sets signature σIDi,mi = (σ(1)
IDi,mi, σ(2)
IDi,mi) as
follows. Let ri = asi + ti,
σ(1)
IDi,mi = ga(hIDi+sihmi)gtihmi ,
σ(2)
IDi,mi = gri = gasi+ti.
Correctness. We see σIDi,mi is a valid signature on (IDi, mi), such that
σ(1)
IDi,mi = ga(hIDi+sihmi)gtihmi
= gahIDi ghmi(asi+ti)
= dIDi · H2(mi)ri.
Forgery. Assume the forgery is returned under condition F1. The algebraic
adversary returns a forged signature σID∗,m∗= (σ(1)
ID∗,m∗, σ(2)
ID∗,m∗) on a
chosen identity and message pair (ID∗, m∗) following the deﬁnition, such
that for some r∗∈Zp,
σ(1)
ID∗,m∗= (H∗
1)x(H∗
2)r∗
= ghID∗x+hm∗r∗,
σ(2)
ID∗,m∗= gr∗.

210
J.-C. Loh et al.
It also attaches together with some representation vectors [⃗α], [⃗β] in Zp, such
that
[⃗α] = (α0, α1, α2,1, · · · , α2,qh1, α3,1, · · · , α3,qh2, α4,1,
· · · , α4,qe, q5,1, · · · , α5,qs, α6,1, · · · , α6,qs),
[⃗β] = (β0, β1, β2,1, · · · , β2,qh1, β3,1, · · · , β3,qh2, β4,1,
· · · , β4,qe, q5,1, · · · , β5,qs, β6,1, · · · , β6,qs),
which indicates how the forgery being algebraically computed, i.e.,
σ(1)
ID∗,m∗=gα0Xα1
qh1

i
(HIDi)α2,i
qh2

i
(Hmi)α3,i
qe

i
(dIDi)α4,i
qs

i
(σ(1)
ID∗,mi)α5,i(σ(2)
ID∗,mi)α6,i,
σ(2)
ID∗,m∗=gβ0Xβ1
qh1

i
(HIDi)β2,i
qh2

i
(Hmi)β3,i
qe

i
(dIDi)β4,i
qs

i
(σ(1)
ID∗,mi)β5,i(σ(2)
ID∗,mi)β6,i.
Note that we omit signature query for any OS(IDi, ·) as the adversary may
obtain dIDi ←OE(IDi) from the extraction oracle and sign the signature
by itself. In order to simplify the above deﬁnition, let ωαi = hmiα5,i + α6,i,
and ωβi = hmiβ5,i + β6,i,
θ = α1 +
qe

i
hIDiα4,i +
qs

i
hID∗α5,i,
ˆθ = α0 +
qh1

i
hIDiα2,i +
qh2

i
hmiα3,i,
δ = β1 +
qe

i
hIDiβ4,i +
qs

i
hID∗β5,i,
ˆδ = β0 +
qh1

i
hIDiβ2,i +
qh2

i
hmiβ3,i.
Based on above deﬁnition, it is easy to see σID∗,m∗= (σ(1)
ID∗,m∗, σ(2)
ID∗,m∗)
can be simply written as follows, such that
σ(1)
ID∗,m∗= gxθ+ˆθ+qs
i
ri(ωαi),
σ(2)
ID∗,m∗= gxδ+ˆδ+qs
i
ri(ωβi),
which yields the following two modular equations
hID∗x + hm∗r∗= xθ + ˆθ +
qs

i
riωαi,
r∗= xδ + ˆδ +
qs

i
riωβi.

A Tightly Secure IBS Scheme Under DL Assumption in AGM
211
Therefore, given the forgery and representation vectors, the simulator
obtains the following modular equation by substituting r∗, such that
x(hID∗+ hm∗δ −θ) +
qs

i
ri(hm∗ωβi −ωαi) = ˆθ −hm∗ˆδ
Abort. The simulator aborts if A : hID∗+ hm∗δ −θ = 0 and B : ∀i ∈
[qs] : hm∗ωβi −ωαi = 0 hold.
Otherwise, based on above simulation deﬁnitions, where x = a and ∀i ∈[qs] :
ri = asi + ti, the simulator can solve for a under condition F1 : A ∨B, such
that behaviour A : hID∗+ hm∗δ −θ ̸= 0 or B : ∃i ∈[qs] : hm∗ωβi −ωαi ̸= 0
holds. We can ﬁnd a by computing
a =
ˆθ −hm∗ˆδ + qs
i ti(ωαi −hm∗ωβi)
hID∗+ hm∗δ −θ + qs
i si(hm∗ωβi −ωαi).
Success Probability of R1. There is no abort in the simulation as the sim-
ulator manages to respond to every extraction and signing query. By condition
F1, the simulator must obtain reducible forgery and representation as either
A : hID∗+ hm∗δ −θ ̸= 0 or B : qs
i si(hm∗ωβi −ωαi) ̸= 0 must hold. In partic-
ular, the success probability Pr[Success|R1] to extract the DL solution in R1 is
based condition F1, hence Pr[Success|R1] is described as follows.
Pr[Success|R1] = Pr[Success|F1]
= Pr[A ∨B]
= 1 −(Pr[A] ∧Pr[B])
= 3
4
Simulation R2: Suppose the algebraic adversary returns forgery on (ID∗, m∗)
under condition F2, the simulation is programmed by embedding the DL problem
instance ga to each hash query HIDi, Hmi, including HID∗, Hm∗.
Setup. The simulator randomly chooses x ∈Zp and sets X = gx. The master
public key is returned mpk = (g, p, e, G, GT , H1, H2, X).
Hash Query. The simulator prepares two empty sets LH1, LH2 to record all
queries and responses.
H1(IDi): On an i-th random oracle query (IDi). If ⟨IDi, HIDi, u1,i, v1,i⟩∈
LH1, the simulator responds to this query following the record. Other-
wise, the simulator randomly selects u1,i, v1,i ∈Zp and sets
HIDi = gau1,i+v1,i.
It programs H1(IDi) = HIDi and stores ⟨IDi, HIDi, u1,i, v1,i⟩into LH1.
The simulator returns H1(IDi) = HIDi.

212
J.-C. Loh et al.
H2(mi): On an i-th random oracle query (mi). If ⟨mi, Hmi, u2,i, v2,i⟩∈LH2,
the simulator responds to this query following the record. Otherwise, the
simulator randomly selects u2,i, v2,i ∈Zp and sets
Hmi = gau2,i+v2,i.
It programs H2(mi) = Hmi and stores ⟨mi, Hmi, u2,i, v2,i⟩into LH2. The
simulator returns H2(mi) = Hmi.
Query. Similar to the deﬁnition of R1, the adversary makes extraction queries
and signing queries in this phase. The simulator prepares an empty set LE
to record all queries and responses as follows.
OE(IDi): On an i-th extraction query (IDi), the simulator checks whether
⟨IDi, dIDi⟩∈LE exists. If there is, the simulator retrieves user private
key dIDi which is based the deﬁnition as follows. Otherwise, it calls
H1(IDi) →HIDi = gau1,i+v1,i and retrieves u1,i, v1,i ∈Zp from LH1,
and sets dIDi = gau1,ix+v1,ix. The simulator stores ⟨IDi, dIDi⟩into LE.
The user private key dIDi is returned.
Correctness. It is easy to see dIDi is a valid user private key, such that
dIDi = gau1,ix+v1,ix
= H1(IDi)x
OS(IDi, mi): On an i-th signing query (IDi, mi). It checks whether ⟨IDi,
dIDi⟩∈LE. It calls OE(IDi) →dIDi to generate fresh user private
key if it does not exist. Otherwise, it retrieves dIDi. The simulator calls
H2(mi) = Hmi = gau2,i+v2,i and retrieves u2,i, v2,i from LH2, randomly
chooses ri ∈Zp, and sets signature σIDi,mi = (σ(1)
IDi,mi, σ(2)
IDi,mi) as
follows
σ(1)
IDi,mi = ga(xu1,i+riu2,i)gxv11,i+riv2,i,
σ(2)
IDi,mi = gri.
Correctness. It is easy to verify σIDi,mi is a valid signature, such that
σ(1)
IDi,mi = ga(xu1,i+riu2,i)gxv1,i+riv2,i
= gx(au1,i+v1,i)gri(au2,i+v2,i)
= dIDi · H2(mi)ri
Forgery. Assume the forgery is returned under condition F2. The algebraic
adversary returns a forged signature σID∗,m∗= (σ(1)
ID∗,m∗, σ(2)
ID∗,m∗) on a
chosen identity and message pair (ID∗, m∗) along with the representation
vectors [⃗α], [⃗β] in Zp following the deﬁnition as in R1. Let
gθ = gα1
qe

i
(HIDi)α4,i
qs

i
(HID∗)α5,i,
gδ = gβ1
qe

i
(HIDi)β4,i
qs

i
(HID∗)β5,i,
gωαi = (Hmi)α5,igα6,i,
gωβi = (Hmi)β5,igβ6,i.

A Tightly Secure IBS Scheme Under DL Assumption in AGM
213
Abort. The simulator aborts if e(HID∗, g) e(Hm∗, gδ) ̸= e(g, gθ) holds
and there exist some i ∈[qs], such that e(Hm∗, gωβi) ̸= e(g, gωαi ).
Based on above simulation deﬁnitions, where ∀i ∈[qh1] : hIDi = au1,i + v1,i
and ∀i ∈[qh2] : hmi = au2,i + v2,i, the simuator can solve for a under
condition F2 : (A ∧B) ∧(C ∨D ∨(C ∧D)) in the following three cases. It
is worth noting that due to behaviour A ∧B, the simulator must obtains
following two equations
A : hID∗+ hm∗δ = θ
(3)
B : ∀i ∈[qs] : hm∗ωβi = ωαi
(4)
The simulator runs Case 1 if 1 ̸= g · qs
i ((Hm∗)β5,i · g−α5,i) holds.
Case 1: (A ∧B) ∧C). The simulator obtains Eq. (3): hID∗+ hm∗δ = θ
where θ = α1 + qe
i hIDiα4,i + qs
i hID∗α5,i and δ = β1 + qe
i hIDiβ4,i +
qs
i hID∗β5,i, which yields
hID∗(1 + Σqs
i (hm∗β5,i −α5,i)) =
α1 −hm∗β1 + Σqe
i hIDi(α4,i −hm∗β4,i).
Based on the deﬁnition of simulation R2, the simulator checks if ∃i ∈[qe] :
β4,i ̸= 0 or Σqs
i β5,i ̸= 0 hold. The simulator manages to derive the following
modular quadratic equation
a2Δ + aΔ′ + Δ′′ = 0,
such that Δ, Δ′, Δ′′ in Zp can be deﬁned as follows, which are computed
based on all chosen randomness u1,i, v1,i, u2,i, v2,i, u∗
1, v∗
1, u∗
2, v∗
2 ∈Z∗
p by the
simulator and received representation vectors [⃗α], [⃗β] in Zp,
Δ = Σqe
i u∗
2u1,iβ4,i + Σqs
i u∗
2u∗
1β5,i,
Δ′ = u∗
1 + u∗
2β1 + Σqe
i (u∗
2v1,iβ4,i + v∗
2u1,iβ4,i −u1,iα4,i)
+ Σqs
i (u∗
2v∗
1β5,i + v∗
2u∗
1β5,i −u∗
1α5,i),
Δ′′ = v∗
1 + v∗
2β1 −α1 + Σqe
i v1,i(v∗
2β4,i −α4,i)
+ Σqs
i v∗
1(v∗
2β5,i −α5,i).
The simulator can ﬁnd at most two solutions a0 or a1 by solving the above
modular quadratic equation. It can test for the correct solution via the given
DL problem instance ga = ga0 or ga = ga1.
Suppose the simulator obtains ∀i ∈[qe] : β4,i = 0 and Σqs
i β5,i = 0 which
implicitly sets Δ = 0. In this case, the simulator solves for a by computing
a = −v∗
1 + v∗
2β1 −α1 + Σqe
i v1,i(−α4,i) + Σqs
i v∗
1(−α5,i)
u∗
1 + u∗
2β1 + Σqe
i (−u1,iα4,i) + Σqs
i (−u∗
1α5,i)
.

214
J.-C. Loh et al.
Due to behaviour C : 1 + Σqs
i (hm∗β5,i −α5,i) ̸= 0 holds, even though
Σqs
i β5,i = 0 is set, it ensures that Σqs
i α5,i ̸= 1. While value u∗
1 remains per-
fectly hidden due to random oracles, such that hID∗= au∗
1 +v∗
1 is implicitly
set, the adversary has no advantage to reproduce u∗
1 if Σqs
i α5,i ̸= 1 holds.
Therefore, the simulator must be able to ﬁnd a as the success probability of
setting u∗
1 + u∗
2β1 + Σqe
i (−u1,iα4,i) + Σqs
i (−u∗
1α5,i) = 0 is negligible.
Otherwise, the simulator runs Case 2 if there exists at least one i in [qs]
that Hβ5,i
mi · gβ6,i ̸= 1.
Case 2: (A ∧B) ∧D). The simulator retrieves Eq. (4):∀i ∈[qs] : hm∗ωβi =
ωαi, where ωαi = hmiα5,i + α6,i and ωβi = hmiβ5,i + β6,i. Due to the
deﬁnition of simulation R2, if ∃i ∈[qs]β5,i ̸= 0 holds, the simulator must
obtain at least one modular quadratic equation
a2λ + aλ′ + λ′′ = 0,
where λ, λ′, λ′′ in Zp are computable by the simulator, such as
λ = u∗
2u2,iβ5,i
λ′ = u∗
2(v2,iβ5,i + β6,i) + u2,i(v∗
2β5,i −α5,i)
λ′′ = v∗
2(v2,iβ5,i + β6,i) −v2,iα5,i −α6,i.
The simulator can ﬁnd at most two solutions a0 or a1 by solving the above
modular quadratic equation. It can test for the correct solution via the given
DL problem instance ga = ga0 or ga = ga1. Suppose the simulator obtains
∀i ∈[qs] : β5,i = 0, which implicitly sets λ = 0. The simulator can solve for
a by computing
a = −v∗
2(β6,i) −v2,iα5,i −α6,i
u∗
2(β6,i) + u2,i(−α5,i) .
Due to behaviour D : ∃i ∈[qs] : ωβi = hmiβ5,i + β6,i ̸= 0 holds, even
though ∀i ∈[qs] : β5,i = 0 is set, it ensures that there exists at least one
β6,i ̸= 0. Again, value u∗
2 is perfectly hidden due to the random oracles, such
that hm∗= au∗
2 + v∗
2 is implicitly set, the adversary has no advantage to
reproduce u∗
2. Therefore, the simulator must be able to ﬁnd a as the success
probability to set ∀i ∈[qs] : v∗
2(β6,i) −v2,iα5,i −α6,i = 0 is negligible.
Otherwise, behaviours C ∧D must hold, and they yield following new equa-
tions
C : hm∗
qs

i
β5,i = −1 +
qs

i
α5,i
(5)
D : ∀i ∈[qs] : ωαi = hmiα5,i + α6,i = 0
(6)
The simulator runs Case 3.

A Tightly Secure IBS Scheme Under DL Assumption in AGM
215
Case 3: (A∧B)∧(C∧D). The simulator checks if qs
i β5,i ̸= 0 holds. Due
to the deﬁnition of simulation R2, the simulator retrieves Eq. (5):hm∗qs
i
β5,i = −1 + qs
i α5,i and solves for a by computing
a = −1 + qs
i (α5,i −v∗
2β5,i)
u∗
2
qs
i β5,i
.
Otherwise, qs
i β5,i ̸= 0 yields that qs
i α5,i = 1, which implies there exists
at least one non-zero α5,i ̸= 0 in [qs]. Recall that the simulator still obtains
Eq. (6):∀i ∈[qs] : ωαi = hmiα5,i + α6,i = 0. Therefore, there is at least one
solution to ﬁnd a by computing
a = −α6,i + v2,iα5,i
u2,iα5,i
.
Success Probability of R2. There is no abort in the simulation as the sim-
ulator manages to respond to every extraction and signing query. By condi-
tion F2 where the simulator obtains Eq. (3) and (4) due to behaviour A ∧B,
1 + qs
i (hm∗β5,i −α5,i) ̸= 0 due to behaviour C, ∃i ∈[qs] : qs
i β5,i ̸= 0 due to
behaviour D, and Eq. (5) and (6) due to behaviour C ∧D, the simulator must
obtain reducible forgery and representation as deﬁned in either cases, which
ensures solving for a with an overwhelming success probability. In particular,
the success probability Pr[Success|R2] to extract the DL solution in R2 is based
condition F2, hence Pr[Success|R2] is described as follows.
Pr[Success|R2] = Pr[Success|F2]
= Pr[Case 1] + Pr[Case 2] + Pr[Case 3]
= 1
4
Indistinguishable Simulations. According to both simulations R1, R2, the
simulations are correct due to the correctness of every simulated user private key
and signature holds. In addition, the simulator sets all elements with perfectly
hidden randomness. For example, master public key X = gx, hash responses
HIDi = ghIDi , Hmi = ghmi, signature randomnesses σ(2)
IDi,mi = gri. They are,
respectively, simulated as

a,
hIDi,
hmi,
asi + ti :
R1
x,
au1,i + v1,i,
au2,i + v2,i,
ri
:
R2
where a, hIDi, hmi, si, ti, x, u1,i, v1,i, u2,i, v2,i, ri ∈Z∗
p are all randomly chosen;
therefore, all elements look random and independent from the point of view of
the adversary.
Reduction Loss. The concrete security is calculated based on the success prob-
ability of the two simulations. Since the two simulations are indistinguishable,

216
J.-C. Loh et al.
the simulator randomly selects μ ∈{0, 1} and runs either one of the simulations.
We describe the success probability of extracting the DL solution as follows.
Pr[Success] = Pr[Success|R1]Pr[μ = 0] + Pr[Success|R2]Pr[μ = 1]
= 3
4(1
2) + 1
4(1
2) = 1
2
The given forgery and representations can be reducible in either one of the
simulations under the condition F1 or F2 with overwhelming success probability.
Therefore, the success probability to extract DL problem solution is at least 1
2,
which concludes that the security loss of the BLS-IBS scheme under EUF-CMA
and DL assumption is 2.
This completes the proof of Theorem 1.
⊓⊔
5
Conclusion
In this work, we achieved a breakthrough by demonstrating tight security for
IBS in the AGM. In particular, we established the security of the BLS-IBS
scheme, which is derived from BLS signatures, under the DL assumption and
EUF-CMA with random oracles in the AGM. Our security proof involves two
simulations that can simulate any user private key and signature. Although the
forgery and representations by the algebraic adversary were classiﬁed into several
cases, we were able to capture them with either of the two simulations, resulting
in a reduction loss of two. The research outcome of this paper provides valuable
insight into achieving tight security for IBS in the AGM.
Further research could examine the possibility of a pairing-free IBS scheme
that provides ideal security. The Schnorr-like IBS by Galindo and Garcia is
currently the most eﬃcient IBS without pairing, however, we identiﬁed that its
security cannot be proven tight even in the AGM as it is unable to both respond
to private key queries and extract the problem solution from any forgery in a
simulation.
Acknowledgement. We would like to thank the anonymous reviewers for their
constructive comments. Fuchun Guo was supported by ARC Future Fellowship
(FT220100046).
References
1. Abe, M., Groth, J., Ohkubo, M.: Separating short structure-preserving signatures
from non-interactive assumptions. In: Lee, D.H., Wang, X. (eds.) ASIACRYPT
2011. LNCS, vol. 7073, pp. 628–646. Springer, Heidelberg (2011). https://doi.org/
10.1007/978-3-642-25385-0_34
2. Bacho, R., Loss, J.: On the adaptive security of the threshold BLS signature
scheme. In: Proceedings of the 2022 ACM SIGSAC Conference on Computer and
Communications Security, pp. 193–207 (2022)

A Tightly Secure IBS Scheme Under DL Assumption in AGM
217
3. Barreto, P.S.L.M., Libert, B., McCullagh, N., Quisquater, J.-J.: Eﬃcient and
provably-secure identity-based signatures and signcryption from bilinear maps. In:
Roy, B. (ed.) ASIACRYPT 2005. LNCS, vol. 3788, pp. 515–532. Springer, Heidel-
berg (2005). https://doi.org/10.1007/11593447_28
4. Bellare, M., Dai, W.: Chain reductions for multi-signatures and the HBMS scheme.
In: Tibouchi, M., Wang, H. (eds.) ASIACRYPT 2021. LNCS, vol. 13093, pp. 650–
678. Springer, Cham (2021). https://doi.org/10.1007/978-3-030-92068-5_22
5. Bellare, M., Namprempre, C., Neven, G.: Security proofs for identity-based iden-
tiﬁcation and signature schemes. J. Cryptol. 22(1), 1–61 (2009)
6. Bellare, M., Rogaway, P.: Random oracles are practical: A paradigm for designing
eﬃcient protocols. In: Proceedings of the 1st ACM Conference on Computer and
Communications Security, pp. 62–73 (1993)
7. Beth, T.: Eﬃcient zero-knowledge identiﬁcation scheme for smart cards. In:
Barstow, D., et al. (eds.) EUROCRYPT 1988. LNCS, vol. 330, pp. 77–84. Springer,
Heidelberg (1988). https://doi.org/10.1007/3-540-45961-8_7
8. Boneh, D., Lynn, B., Shacham, H.: Short signatures from the Weil pairing. J.
Cryptol. 17(4), 297–319 (2004)
9. Boneh, D., Venkatesan, R.: Breaking RSA may not be equivalent to factoring.
In: Nyberg, K. (ed.) EUROCRYPT 1998. LNCS, vol. 1403, pp. 59–71. Springer,
Heidelberg (1998). https://doi.org/10.1007/BFb0054117
10. Bresson, E., Monnerat, J., Vergnaud, D.: Separation results on the “One-More”
computational problems. In: Malkin, T. (ed.) CT-RSA 2008. LNCS, vol. 4964, pp.
71–87. Springer, Heidelberg (2008). https://doi.org/10.1007/978-3-540-79263-5_5
11. Chatterjee, S., Kamath, C., Kumar, V.: Galindo-Garcia identity-based signature
revisited. In: Kwon, T., Lee, M.-K., Kwon, D. (eds.) ICISC 2012. LNCS, vol.
7839, pp. 456–471. Springer, Heidelberg (2013). https://doi.org/10.1007/978-3-
642-37682-5_32
12. Chin, J.J., Tan, S.Y., Heng, S.H., Phan, R.C.W.: Twin-schnorr: a security upgrade
for the schnorr identity-based identiﬁcation scheme. Sci. World J. 2015 (2015)
13. Choon, J.C., Hee Cheon, J.: An identity-based signature from gap Diﬃe-Hellman
groups. In: Desmedt, Y.G. (ed.) PKC 2003. LNCS, vol. 2567, pp. 18–30. Springer,
Heidelberg (2003). https://doi.org/10.1007/3-540-36288-6_2
14. Coron, J.-S.: Optimal security proofs for PSS and other signature schemes. In:
Knudsen, L.R. (ed.) EUROCRYPT 2002. LNCS, vol. 2332, pp. 272–287. Springer,
Heidelberg (2002). https://doi.org/10.1007/3-540-46035-7_18
15. Diﬃe, W., Hellman, M.: New directions in cryptography. IEEE Trans. Inf. Theory
22(6), 644–654 (1976)
16. Fuchsbauer, G., Kiltz, E., Loss, J.: The algebraic group model and its applications.
In: Shacham, H., Boldyreva, A. (eds.) CRYPTO 2018. LNCS, vol. 10992, pp. 33–62.
Springer, Cham (2018). https://doi.org/10.1007/978-3-319-96881-0_2
17. Fuchsbauer, G., Plouviez, A., Seurin, Y.: Blind Schnorr signatures and signed
ElGamal encryption in the algebraic group model. In: Canteaut, A., Ishai, Y.
(eds.) EUROCRYPT 2020. LNCS, vol. 12106, pp. 63–95. Springer, Cham (2020).
https://doi.org/10.1007/978-3-030-45724-2_3
18. Fukumitsu, M., Hasegawa, S.: A Galindo-Garcia-like identity-based signature with
tight security reduction. In: 2017 Fifth International Symposium on Computing
and Networking (CANDAR), pp. 87–93. IEEE (2017)
19. Fukumitsu, M., Hasegawa, S.: A Galindo-Garcia-like identity-based signature with
tight security reduction, revisited. In: 2018 Sixth International Symposium on
Computing and Networking (CANDAR), pp. 92–98. IEEE (2018)

218
J.-C. Loh et al.
20. Galindo, D., Garcia, F.D.: A Schnorr-like lightweight identity-based signature
scheme. In: Preneel, B. (ed.) AFRICACRYPT 2009. LNCS, vol. 5580, pp. 135–
148. Springer, Heidelberg (2009). https://doi.org/10.1007/978-3-642-02384-2_9
21. Garg, S., Bhaskar, R., Lokam, S.V.: Improved bounds on security reductions for
discrete log based signatures. In: Wagner, D. (ed.) CRYPTO 2008. LNCS, vol.
5157, pp. 93–107. Springer, Heidelberg (2008). https://doi.org/10.1007/978-3-540-
85174-5_6
22. Goh, E.J., Jarecki, S., Katz, J., Wang, N.: Eﬃcient signature schemes with tight
reductions to the Diﬃe-Hellman problems. J. Cryptol. 20(4), 493–514 (2007)
23. Hess, F.: Eﬃcient identity based signature schemes based on pairings. In: Nyberg,
K., Heys, H. (eds.) SAC 2002. LNCS, vol. 2595, pp. 310–324. Springer, Heidelberg
(2003). https://doi.org/10.1007/3-540-36492-7_20
24. Kastner, J., Loss, J., Xu, J.: On pairing-free blind signature schemes in the alge-
braic group model. In: Hanaoka, G., Shikata, J., Watanabe, Y. (eds.) PKC 2022.
LNCS, vol. 13178, pp. 468–497. Springer, Cham (2022)
25. Kılınç Alper, H., Burdges, J.: Two-round trip Schnorr multi-signatures via delin-
earized witnesses. In: Malkin, T., Peikert, C. (eds.) CRYPTO 2021. LNCS, vol.
12825, pp. 157–188. Springer, Cham (2021). https://doi.org/10.1007/978-3-030-
84242-0_7
26. Kiltz, E., Masny, D., Pan, J.: Optimal security proofs for signatures from identiﬁ-
cation schemes. In: Robshaw, M., Katz, J. (eds.) CRYPTO 2016. LNCS, vol. 9815,
pp. 33–61. Springer, Heidelberg (2016). https://doi.org/10.1007/978-3-662-53008-
5_2
27. Kurosawa, K., Heng, S.-H.: From digital signature to ID-based identiﬁca-
tion/signature. In: Bao, F., Deng, R., Zhou, J. (eds.) PKC 2004. LNCS, vol.
2947, pp. 248–261. Springer, Heidelberg (2004). https://doi.org/10.1007/978-3-
540-24632-9_18
28. Maurer, U.M., Wolf, S.: The relationship between breaking the Diﬃe-Hellman
protocol and computing discrete logarithms. SIAM J. Comput. 28(5), 1689–1721
(1999)
29. Narayan, S., Parampalli, U.: Eﬃcient identity-based signatures in the standard
model. IET Inf. Secur. 2(4), 108–118 (2008)
30. Nick, J., Ruﬃng, T., Seurin, Y.: MuSig2: simple two-round schnorr multi-
signatures. In: Malkin, T., Peikert, C. (eds.) CRYPTO 2021. LNCS, vol. 12825, pp.
189–221. Springer, Cham (2021). https://doi.org/10.1007/978-3-030-84242-0_8
31. Okamoto, T.: Provably secure and practical identiﬁcation schemes and correspond-
ing signature schemes. In: Brickell, E.F. (ed.) CRYPTO 1992. LNCS, vol. 740, pp.
31–53. Springer, Heidelberg (1993). https://doi.org/10.1007/3-540-48071-4_3
32. Paillier, P., Vergnaud, D.: Discrete-log-based signatures may not be equiva-
lent to discrete log. In: Roy, B. (ed.) ASIACRYPT 2005. LNCS, vol. 3788, pp.
1–20. Springer, Heidelberg (2005). https://doi.org/10.1007/11593447_1
33. Paterson, K.G.: Id-based signatures from pairings on elliptic curves. Electron. Lett.
38(18), 1025–1026 (2002)
34. Paterson, K.G., Schuldt, J.C.N.: Eﬃcient identity-based signatures secure in the
standard model. In: Batten, L.M., Safavi-Naini, R. (eds.) ACISP 2006. LNCS,
vol. 4058, pp. 207–222. Springer, Heidelberg (2006). https://doi.org/10.1007/
11780656_18
35. Pointcheval, D., Stern, J.: Security arguments for digital signatures and blind sig-
natures. J. Cryptol. 13(3), 361–396 (2000)

A Tightly Secure IBS Scheme Under DL Assumption in AGM
219
36. Schnorr, C.P.: Eﬃcient identiﬁcation and signatures for smart cards. In: Brassard,
G. (ed.) CRYPTO 1989. LNCS, vol. 435, pp. 239–252. Springer, New York (1990).
https://doi.org/10.1007/0-387-34805-0_22
37. Shamir, A.: Identity-based cryptosystems and signature schemes. In: Blakley, G.R.,
Chaum, D. (eds.) CRYPTO 1984. LNCS, vol. 196, pp. 47–53. Springer, Heidelberg
(1985). https://doi.org/10.1007/3-540-39568-7_5
38. Waters, B.: Eﬃcient identity-based encryption without random oracles. In: Cramer,
R. (ed.) EUROCRYPT 2005. LNCS, vol. 3494, pp. 114–127. Springer, Heidelberg
(2005). https://doi.org/10.1007/11426639_7
39. Yi, P.: An eﬃcient identity-based signature scheme with provable security. Inf. Sci.
576, 790–799 (2021)
40. Zhang, X., Liu, S., Gu, D., Liu, J.K.: A generic construction of tightly secure
signatures in the multi-user setting. Theoret. Comput. Sci. 775, 32–52 (2019)

Compact Password Authenticated Key
Exchange from Group Actions
Ren Ishibashi and Kazuki Yoneyama(B)
Ibaraki University, 4-12-1, Nakanarusawa, Hitachi, Ibaraki 316-8511, Japan
kazuki.yoneyama.sec@vc.ibaraki.ac.jp
Abstract. At ASIACRYPT 2020, Alamati et al. formalized the frame-
work of group actions for abstracting isogeny-based cryptosystems. At
CRYPTO 2022, Abdalla et al. extended the framework to represent the
quadratic twist of elliptic curves, and proposed the ﬁrst provably secure
and tightly secure one-round isogeny-based password-authenticated key
exchange (PAKE) scheme (X-GA-PAKE) by a bit-by-bit approach. How-
ever, in X-GA-PAKE, for the password length ℓ, the number of group
actions per party is 5ℓ, and the communication complexity per party
is 2ℓ, thus there is a problem in eﬃciency. In this paper, we propose
an eﬃcient one-round PAKE scheme that reduces the number of group
actions and the communication complexity compared to X-GA-PAKE. In
X-GA-PAKE, it is necessary to send/receive 2ℓelements to prevent triv-
ial attacks using twists, but in our scheme, by reducing ℓelements of
them to the number of common reference string (CRS), we can reduce
the number of group actions per party to 4ℓ+ 2|CRS| and the commu-
nication complexity per party to ℓ+ |CRS|. In addition, we show the
tight security in the one-round PAKE security model based on the same
assumptions as in X-GA-PAKE.
Keywords: password authenticated key exchange · isogenies ·
CSIDH · group actions
1
Introduction
Password authenticated key exchange (PAKE) is a cryptographic protocol to
share a common session key using a shared low-entropy secret such as a human-
memorable password among multiple parties through an unauthenticated chan-
nel such as the Internet. We focus on the 2-party PAKE. In PAKE, each party
locally keeps a shared password, and in a key exchange session, each party gener-
ates an ephemeral public key (EPK) using ephemeral secret values such as ran-
domness and sends the EPK to the other party. The session key is derived from
these values and some key derivation functions like a hash function. Ordinary
PAKE is intended to satisfy not only session key secrecy, but also oﬄine/online
dictionary attack resilience, and the provable security of PAKE schemes is for-
mulated by indistinguishability-based security models such as the BPR model [7]
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 220–247, 2023.
https://doi.org/10.1007/978-3-031-35486-1_11

Compact Password Authenticated Key Exchange from Group Actions
221
or the universal composability framework [9]. An oﬄine dictionary attack is an
attack in which the adversary obtains a message computed with a password, and
attempts to ﬁnd the password by locally testing guessed passwords. An online
dictionary attack is an attack in which the adversary actually queries the system
for guessed passwords and tries them until the system accepts them up to the
maximum number of executions. For PAKE, it is required that the adversary is
only possible to do online dictionary attacks because online dictionary attacks
can be prevented by limiting the number of password trials, but oﬄine dictionary
attacks cannot be avoided by such an operational method.
In this paper, we focus on isogeny-based PAKE schemes.
1.1
Related Work
PAKE. Known PAKE schemes are classiﬁed in contexts of the Diﬃe-Hellman-
based (DH-based) setting [4,14–16], the oblivious transfer-based (OT-based) set-
ting [8] or the hash proof system-based (HPS-based) setting [12,13,18]. These
strategies cannot be simply applied to isogeny-based PAKE due to the following
limitations: (i) There is no known method yet to randomly hash the password
into the set of supersingular elliptic curves. (ii) There is no natural ring structure
on the set of elliptic curves that can be formed by multiplying two elliptic curves.
(iii) It is not clear if the HPS from group actions [5] can be used as a building
block for PAKE. Also, as shown in [2], OT-based PAKE is ineﬃcient because
the communication complexity and the number of group actions are quite large.
Isogeny-Based PAKE. Previously, there have been several studies to con-
struct isogeny-based PAKE schemes. Isogeny-based PAKE schemes are classiﬁed
into two settings: SIDH-based [17] and CSIDH-based [11].
Terada and Yoneyama
[22] proposed a CSIDH-based PAKE scheme with
the Encrypted Key Exchange [20] approach that the sent message is encrypted
with a password as the secret key. Later, Azarderakhsh et al. [6] showed that
the Terada-Yoneyama scheme is vulnerable to man-in-the-middle and oﬄine
dictionary attacks and modifying the scheme to be secure against man-in-the-
middle attacks is hard due to the fact that the elliptic curves used in key exchange
and encrypted with the password can be identiﬁed from random strings.
On the other hand, Taraskin et al. [21], and Soukharev and Hess [19] pro-
posed SIDH-based PAKE schemes. These schemes have not been broken, but a
polynomial-time key recovery attack on SIDH [10] was found by Castryck and
Decru, which implies that SIDH-based PAKE is insecure now.
Recently, Abdalla et al. [2] extended the framework [5] of group actions
for constructing isogeny-based cryptosystems such as CSIDH to capture the
quadratic twist of elliptic curves, and proposed the ﬁrst provably secure and
tightly secure isogeny-based one-round PAKE scheme called X-GA-PAKE by a
bit-by-bit approach. However, there are two problems in X-GA-PAKE. First, the
security is proved in the model specialized for the sequential 2-pass or higher
schemes, and therefore the security is not proved as a one-round scheme. Speciﬁ-
cally, in the model, the adversary is only allowed to activate one of two parties in

222
R. Ishibashi and K. Yoneyama
a session as the initiator because the sequence of SEND queries is ﬁxed. It is desir-
able to allow the adversary to initialize both parties freely as one-round schemes.
Next, there is a problem in eﬃciency because the number of group actions and
the communication complexity per party are quite large due to sending a number
of elements proportional to the password length. It is desirable to reduce these
complexities.
1.2
Our Contribution
In this paper, we achieve a more compact isogeny-based PAKE scheme with
tight security in the one-round PAKE security model than the existing scheme
X-GA-PAKE. Our contribution is twofold.
– We propose a compact PAKE scheme. As shown in Table 1 in Sect. 4.4, in
X-GA-PAKE, it is necessary to perform 5ℓgroup actions and to send/receive
2ℓelements to prevent trivial attacks using twists for a ℓ-bit password, but
in our scheme, by reducing ℓelements of them to the number of common
reference string (CRS), we can reduce the number of group actions per party
to 4ℓ+ 2|CRS| and the communication complexity per party to ℓ+ |CRS|.
– We prove that the proposed scheme is tightly secure in the one-round PAKE
security model [1] based on the same assumptions as in X-GA-PAKE. There-
fore, the security of our scheme is guaranteed even when parties send their
messages simultaneously.
1.3
Key Technique
In X-GA-PAKE, double elements for each bit of the password are sent and
received, and three shared values can be computed by the combination of these
elements in order to provide resilience to an oﬄine dictionary attack using twists.
As a result, the number of group actions per user is 5ℓtimes, and the commu-
nication complexity per user is 2ℓgroup elements. Here, there are two essential
points to prevent the attack. The ﬁrst is to send two types of messages according
to password bits. The second is to compute three shared values, including the
normal DH-style key exchange and the key exchange with message crossing, i.e.,
it corresponds to computing gab, ga′b, and gab′ in the classical DH key exchange
between user A and user B. Thus, we propose a technique to achieve these points
in which ephemeral CRSs are generated and sent to each other instead of dou-
bling the message. Then, in the computation of the shared values using such
messages, the computation of shared values is blanched based on the password.
In this way, we reduce the number of group actions per user can be reduced to
4ℓ+2 times and the communication complexity per user to ℓ+2 group elements.
For more details, please see Sect. 4.1.

Compact Password Authenticated Key Exchange from Group Actions
223
2
Preliminaries
2.1
Notation
– For integers m and n, [m, n] denotes the set {m, m + 1, . . . , n} where m < n.
In the case of m = 1, we denote it as [n].
– For a set X, x ∈R X denotes that the element x is sampled uniformly and
randomly from the set X.
– y ←A(x1, . . . , xn) denotes that probabilistic polynomial time (PPT) adver-
sary A takes (x1, . . . , xn) as input and outputs y.
– AO denotes that A has access to oracle O.
2.2
Eﬀective Group Actions (with Twists)
Here, we recall the deﬁnition of eﬀective group actions with twists from [2],
which extends the framework [5] to build cryptographic primitives relying on
isogeny-based assumptions such as CSIDH to one with twists capability.
Deﬁnition 1 (Group Action). Let (G, ·) be a group with identity element id ∈
G, and X be a set. We say that (G, X, ⋆) for a map
⋆: G × X →X
is a group action if it satisﬁes the following properties:
1. Identity: id ⋆x = x for all x ∈X.
2. Compatibility: (g · h) ⋆x = g ⋆(h ⋆x) for all g, h ∈G and x ∈X.
In this paper, we consider group actions with ﬁnite commutative groups G.
In addition, we assume that the group action is regular which means that there
exists exactly one g ∈G satisfying y = g ⋆x for any x, y ∈X.
Deﬁnition 2 (Eﬀective Group Action). Let (G, X, ⋆) be a group action sat-
isfying the following properties:
1. The group G is ﬁnite and there exist eﬃcient (PPT) algorithms for member-
ship and equality testing, (random) sampling, group operation, and inversion.
2. The set X is ﬁnite and there exist eﬃcient algorithms for membership testing
and computing a unique representation.
3. There exists a distinguished element ˜x ∈X (called the origin) with known
representation.
4. There exists an eﬃcient algorithm to evaluate the group action, i.e., to com-
pute g ⋆x given g and x.
We say that (G, X, ⋆, ˜x) is an eﬀective group action (EGA) for above (G, X, ⋆)
and the origin ˜x ∈X.
Deﬁnition 3 (EGA with Twists). Let (G, X, ⋆) be a group action satisfying
the following properties:

224
R. Ishibashi and K. Yoneyama
1. (G, X, ⋆, ˜x) is EGA for the origin ˜x ∈X.
2. There exists an eﬃcient algorithm that given x = g ⋆˜x ∈X computes xt =
g−1 ⋆˜x.
We say that (G, X, ⋆, ˜x) is an eﬀective group action with twists (EGAT) for above
(G, X, ⋆, ˜x).
Remark 1. The instantiation of the group actions described above is provided
by isogeny-based group actions. Speciﬁcally, we can deﬁne group actions Cl(O)×
Ellk(O) →Ellk(O), where Cl(O) is the ideal class group and Ellk(O) is the
set of elliptic curves. Also, for any curve Ea = [a] ⋆E which is the form of
Ea : y2 = x3 + ax2 + x, the quadratic twists is computed as (Ea)t = E−a easily
and satisﬁes the property (Ea)t = [a]−1 ⋆E.
2.3
Assumptions of Group Actions
Here, we recall the three computational problems Group Action Strong Compu-
tational DH (GA-StCDH), Square-Inverse GA-StCDH (SqInv-GA-StCDH) [2], and
Double Simultaneous GA-StCDH (DSim-GA-StCDH) [2], to be used in the proof
of our scheme.
As a notation, GA-CDHx(y0, y1) is the computational oracle that com-
putes g0 ⋆y1 and GA-DDHx(y0, y1, z) is the decision oracle that veriﬁes
GA-CDHx(y0, y1) = z, where g0 ∈G such that y0 = g0 ⋆x. If GA-CDHx(y0, y1) =
z, it outputs 1, otherwise 0. For GA-CDH and GA-DDH, we omit the index x if
x = ˜x (e.g., GA-CDH˜x(y0, y1) = GA-CDH(y0, y1)).
Deﬁnition 4 (GA-StCDH). For any PPT adversary A, the GA-StCDH problem
requires to compute the set element (g · h) ⋆˜x based on (g ⋆˜x, h ⋆˜x) ∈X 2 given
as input. For an group action EGAT, the advantage of A is shown as follows:
AdvGA-StCDH
EGAT
(A) := Pr[(g · h) ⋆˜x ←AO(g ⋆˜x, h ⋆˜x)],
where (g, h) ∈R G2 and O is the decision oracle GA-DDH(g ⋆˜x, ·, ·).
Deﬁnition 5 (SqInv-GA-StCDH). For any PPT adversary A, the SqInv-GA-
StCDH problem requires to ﬁnd a tuple (y, y0, y1) ∈X 3 such that y0 = g2 ⋆y and
y1 = g−1 ⋆y, based on x = g ⋆˜x given as input. For an group action EGAT, the
advantage of A is shown as follows:
AdvSqInv-GA-StCDH
EGAT
(A) := Pr[(y, y0 = GA-CDHxt(x, y),
y1 = GA-CDH(xt, y)) ←AO(g ⋆˜x)],
where O is the decision oracle {GA-DDHxt(x, ·, ·), GA-DDH(x, ·, ·)}.
Remark 2. A can choose y only based on known elements based on ˜x, its input
x or xt.

Compact Password Authenticated Key Exchange from Group Actions
225
The SqInv-GA-StCDH problem is also hard against an adversary that has the
ability to compute the twists. Speciﬁcally, if A chooses y = a ⋆˜x for some a ∈G,
then it can compute y1 = a ⋆xt, but not y0 = (a · g2) ⋆˜x. If A chooses y = a ⋆x,
then it can compute y1 = a ⋆˜x, but not compute y0 = (a · g3) ⋆˜x. Also, if A
chooses y = a ⋆xt, it can compute y0 = a ⋆x, but not compute y1 = (a · g−2) ⋆˜x.
Deﬁnition 6 (DSim-GA-StCDH). For any PPT adversary A, the DSim-GA-
StCDH problem requires to ﬁnd a tuple (y, y0, y1, y2, y3) ∈X 5 such that
(y0,y1, y2, y3) =
(g−1
0
· h0 ⋆y, g−1
0
· h1 ⋆y, g−1
1
· h0 ⋆y, g−1
1
· h1 ⋆y),
based on (x0, x1, w0, w1) = (g0 ⋆˜x, g1 ⋆˜x, h0 ⋆˜x, h1 ⋆˜x) ∈X 4 given as input. For
an group action EGAT, the advantage of A is shown as follows:
AdvDSim-GA-StCDH
EGAT
(A) := | Pr[(y0 = GA-CDHx0(w0, y),
y1 = GA-CDHx0(w1, y), y2 = GA-CDHx1(w0, y),
y3 = GA-CDHx1(w1, y)) ←AO(x0, x1, w0, w1)]|,
where O is the decision oracle {GA-DDHxj(wk, y)}j,k∈{0,1}.
The DSim-GA-StCDH problem can be reduced to the SqInv-GA-StCDH prob-
lem as in [2].
3
Security Model for One-Round PAKE
In this section, we recall the security model [1] which is an extension of the BPR
model [7] to multiple test queries [3]. The security model is indistinguishability-
based, and we use the game-based pseudocode in our proof as in [2]. In addition,
the model is diﬀerent from the model used in [2] in the point that it is possible
to capture the one-round schemes. Speciﬁcally, it has only one SEND query,
allowing the adversary to query freely without being restricted to an initialized
party.
3.1
System Model and Adversarial Capacity
PAKE Setting. Parties are modeled as a PPT Turing machine. Each party is
activated by receiving an initialization message and returns a message deﬁned
by the protocol. PAKE is executed using a shared password pwUS between the
two parties U and S. Let U be the namespaces of parties, and we assume that
U and S are disjoint where (U, S) ∈U. Also, let a party P be P ∈{U, S} and an
intended peer ¯P be ¯P ∈(U, S)\P. Each party P has multiple instances πi
P and
each instance has its own state. Passwords are bit strings of length ℓand we
deﬁne the password space as PW ⊊{0, 1}ℓ.

226
R. Ishibashi and K. Yoneyama
Protocol Instances. Let EPKP be an ephemeral public key of P. An instance πt
P
is activated by an incoming message of the form (P, t, ¯P, msg), where msg =⊥.
The instance πt
P has a tuple as follows:
– e: It stores the ephemeral secret values generated in the protocol execution.
– tr: It stores the trace of the instance in the protocol execution, i.e., the mes-
sages generated by the party and received from the intended peer are stored.
The trace πt
P.tr is the form of (P, ¯P, EPKP, ⊥) or (P, ¯P, EPKP, EPK¯P).
– SK: It stores the accepted session key in the protocol execution.
– acc: It stores the status of protocol execution. As long as the instance did not
receive the last message, acc =⊥. If the instance πt
P computes the session key
SK in the protocol execution, πt
P.acc stores “true”.
To access individual components of the state, we write πt
P.{e, tr, SK, acc}.
Partnering. Partnering is deﬁned by matching conversations. Especially, the
instances πt0
U and πt1
S are partnered if
πt0
U .acc = πt1
S .acc = true and πt0
U .tr = πt1
S .tr
We deﬁne a partner predicate Partner(πt0
U , πt1
S ) which outputs 1 if the two
instances πt0
U and πt1
S are partnered, otherwise 0.
Adversary. The adversary A is modeled as a PPT turing machine, which takes
params as input and has oracle access to parties. A controls all communications
among users including the session activation. A can interfere in party P and ¯P
to execute a speciﬁc action using the following adversarial queries.
– EXECUTE(U, t0, S, t1) : This query is to compute a protocol execution between
an instance πt0
U and an instance πt1
S . The query models the behavior of passive
adversaries.
– SEND(P, t, msg) : The adversary sends an arbitrary message msg to the
instance πt
P. The msg has one of the following forms : ⊥or EPK¯P. πt
P exe-
cutes the protocol according to the given message and returns the response
to A. The query models the behavior of active adversaries.
– CORRUPT(U, S) : The adversary obtains the shared password pwUS of U
and S.
– REVEAL(P, t) : The adversary obtains the session key of the instance πt
P.
3.2
PAKE Security
For deﬁning PAKE security, we need the notion of freshness.
Freshness. Let πt1
¯P be a partner instance of πt0
P . During the security experi-
ment, we register if an instance is fresh to prevent trivial attacks. Therefore, we
deﬁne a freshness predicate Fresh(P, t0). We say that the instance πt0
P is fresh as
Fresh(P, t0) = true if the following conditions hold:

Compact Password Authenticated Key Exchange from Group Actions
227
1. πt0
P accepted.
2. πt0
P was not queried to TEST(P, t0) or REVEAL(P, t0) before.
3. πt1
¯P was not queried to TEST(¯P, t1) or REVEAL(¯P, t1) before.
4. At least one of the following conditions holds:
(a) πt0
P accepted during a query to EXECUTE(πt0
P , πt1
¯P ).
(b) A unique fresh partner instance πt1
¯P exists.
(c) No partner exists and CORRUPT(P, ·) was not queried.
The goal of the adversary A in the security experiment is to distinguish the
true session key from a random key. A makes any sequence of the above queries.
A makes the following query during the experiment.
– TEST(P, t0) : This query is a challenge query. Here, πt0
P must be fresh (i.e.,
Fresh(P, t0) = true). Depending on the challenge bit β ∈R {0, 1} chosen
before the experiment begins, it returns the challenge key. If β = 0, then it
returns the session key πt0
P .SK. Otherwise, it returns a random key SK ∈R
SK, where SK is the session key space. If TEST is queried for an instance
πt0
P , we mark an instance as tested by πt0
P .test = true.
The adversary A obtains either the session key of πt0
P or a random key with
probability 1/2 respectively. After issuing the Test query, the experiment contin-
ues until A outputs β′ as a result of guessing whether the received key is random
or not. If the guess of A is correct (i.e., β = β′), then A wins the experiment.
Deﬁnition 7 (PAKE Security). The advantage of the adversary A in the
above experiment with the PAKE scheme is deﬁned as follows.
AdvPAKE(A) := | Pr[A win] −1/2|
PAKE is considered secure if an online dictionary attack is the best threat by
the adversary. More speciﬁcally, this means that the advantage of the adversary
should be negligible close to qs/|PW| when passwords are chosen uniformly and
independently from PW, where qs is the maximum number of SEND queries
made by the adversary.
4
Our PAKE Protocol: CrsX-GA-PAKEℓ
In this section, we propose a one-round PAKE scheme (CrsX-GA-PAKEℓ) in the
random oracle model (ROM). CrsX-GA-PAKEℓis secure under the hardness of
the computational problems GA-StCDH and SqInv-GA-StCDH in the one-round
security model. The protocol of CrsX-GA-PAKEℓis shown in Fig. 2.
4.1
Construction Idea
As discussed in Sect. 1.3, we try to reduce the communication complexity and
the number of group actions of X-GA-PAKEℓshown in Fig. 1. In GA-PAKE in [2],

228
R. Ishibashi and K. Yoneyama
Public parameter : H
CRS := (x0, x1) ∈X 2
pwUS := (b1, . . . , b ) ∈{0, 1}
Party U
Party S
(u1, . . . , u ) ∈R G
(s1, . . . , s ) ∈R G
(ˆu1, . . . , ˆu ) ∈R G
(ˆs1, . . . , ˆs ) ∈R G
for i ∈[ ] :
xU
1, . . . , xU, ˆxU
1, . . . , ˆxU
−−−−−−−−−−−−−−−−−→for i ∈[ ] :
xU
i ←ui
bi
xS
i ←si
bi
ˆxU
i ←ˆui
bi
ˆxS
i ←ˆsi
bi
xS
1, . . . , xS, ˆxS
1, . . . , ˆxS
←−−−−−−−−−−−−−−−−
for i ∈[ ] :
for i ∈[ ] :
σi := (ui
S
i , ˆui
S
i , ui
ˆxS
i )
σi := (si
U
i , si
ˆxU
i , ˆsi
U
i )
SK := H(U, S, xU
1, . . . , xU, ˆxU
1, . . . , ˆxU, xS
1, . . . , xS, ˆxS
1, . . . , ˆxS, pwUS, σ1, . . . , σ )
Fig. 1. X-GA-PAKEℓ[2]
Public parameter : H
CRS := (x0, x1) ∈X 2
pwUS := (b1, . . . , b ) ∈{0, 1}
Party U
Party S
(u1, . . . , u ) ∈R G
(s1, . . . , s ) ∈R G
(ˆu0, ˆu1) ∈R G2
(ˆs0, ˆs1) ∈R G2
ˆxU
0 ←ˆu0
0
ˆxS
0 ←ˆs0
0
ˆxU
1 ←ˆu1
1
ˆxS
1 ←ˆs1
1
for i ∈[ ] :
xU
1, . . . , xU, ˆxU
0, ˆxU
1
−−−−−−−−−−−−−−→for i ∈[ ] :
xU
i ←ui
bi
xS
i ←si
bi
xS
1, . . . , xS, ˆxS
0, ˆxS
1
←−−−−−−−−−−−−−
for i ∈[ ] :
for i ∈[ ] :
σi := (ui
S
i , ˆubi
S
i , ui
ˆxS
bi)
σi := (si
U
i , si
ˆxU
bi, ˆsbi
U
i )
SK := H(U, S, xU
1, . . . , xU, ˆxU
0, ˆxU
1, xS
1, . . . , xS, ˆxS
0, ˆxS
1, pwUS, σ1, . . . , σ )
Fig. 2. CrsX-GA-PAKEℓ
it allows the adversary an oﬄine dictionary attack using twists trivially. Con-
cretely, the adversary performs group actions with twisted opponent’s messages
instead of group actions with CRS. As a result, the opponent’s ephemeral secret
values are canceled out when it computes the shared values; thus, an oﬄine
dictionary attack can be possible. Therefore, in X-GA-PAKE, sending/receiving

Compact Password Authenticated Key Exchange from Group Actions
229
double elements and making them compute three shared values prevents the
attack.
Carefully investigating the proof of X-GA-PAKE, there are two essential points
to prevent attacks using twists. The ﬁrst is to send two types of messages accord-
ing to password bits. The second is to compute three shared values, including
the normal DH-style key exchange and the key exchange with message crossing.
To achieve these points, we discover that sending messages depending on the
password length ℓtwice is not necessary. Thus, we propose a technique in which
ephemeral CRSs are generated and sent to each other instead of doubling the
message. Then, in the computation of the shared values using such messages, the
computation of shared values is blanched based on the password. In this way,
the attack using twists can be prevented by changing the timing of branching
by the password.
In the proof of CrsX-GA-PAKE, by the deﬁnition of the adversary, we need to
consider passive adversaries and active adversaries. For a passive adversary, the
adversary cannot know the password and ephemeral secret values; thus, it can
be reduced the hardness of GA-StCDH problem in which let one type of value be
output. For an active adversary, the adversary can create one party’s ephemeral
secret values on its own, and an attack using twists is possible for one type of
shared value. Thus, the hardness of DSim-GA-StCDH problem can be reduced in
which let two types of values be output simultaneously.
4.2
Protocol
Public Parameters and CRS: Let κ be a security parameter, H : {0, 1}∗→
{0, 1}κ be a hash function, (x0, x1) satisfying x0 = g0 ⋆˜x and x1 = g1 ⋆˜x be
elliptic curves with group elements g0 and g1. These are provided as part of the
public parameters and CRS.
Key Exchange: Let U and S be the parties that execute the protocol with a
shared password pwUS ∈{0, 1}ℓ.
– U chooses ephemeral secret values (u1, . . . , uℓ) ∈R Gℓand (ˆu0, ˆu1) ∈R G2, and
computes ˆxU
0 ←ˆu0 ⋆x0, ˆxU
1 ←ˆu1 ⋆x1, and xU
i ←ui ⋆xbi for i ∈[ℓ]. Then, U
sends (xU
1 , . . . , xU
ℓ, ˆxU
0 , ˆxU
1 ) to S. S executes in the same way.
– Upon receiving (xS
1, . . . , xS
ℓ, ˆxS
0, ˆxS
1), U computes σi := (ui ⋆xS
i , ˆubi ⋆xS
i , ui ⋆
ˆxS
bi) for i ∈[ℓ] and the session key SK = H(U, S, xU
1 , . . . , xU
ℓ, ˆxU
0 , ˆxU
1 , xS
1,
. . . , xS
ℓ, ˆxS
0, ˆxS
1, pwUS, σ1, . . . , σℓ).
– Upon receiving (xU
1 , . . . , xU
ℓ, ˆxU
0 , ˆxU
1 ), S computes σi := (si ⋆xU
i , si ⋆ˆxU
bi, ˆsbi ⋆
xU
i ) for i ∈[ℓ] and the session key SK = H(U, S, xU
1 , . . . , xU
ℓ, ˆxU
0 , ˆxU
1 , xS
1,
. . . , xS
ℓ, ˆxS
0, ˆxS
1, pwUS, σ1, . . . , σℓ).
4.3
Security
We show the security of the CrsX-GA-PAKEℓfor EGAT.

230
R. Ishibashi and K. Yoneyama
Theorem 1 (Security of CrsX-GA-PAKEℓ).
For any PPT adversary A
against CrsX-GA-PAKEℓthat issues at most qe EXECUTE queries and qs SEND
queries where H is modeled as a random oracle, there exist a PPT adversary B1
against GA-StCDH and a PPT adversary B2 against SqInv-GA-StCDH such that
AdvCrsX-GA-PAKEℓ(A)
≤AdvGA-StCDH
EGAT
(B1) + AdvSqInv-GA-StCDH
EGAT
(B2) +
qs
|PW| + (qs + qe)2
|G|ℓ+2
.
We show the proof of Theorem 1 in Appendix A.
Remark 3. The reduction cost of our proof is the same as the proof of
X-GA-PAKE. AdvCrsX-GA-PAKEℓ(A) is tightly reduced to AdvGA-StCDH
EGAT
(B1) +
AdvSqInv-GA-StCDH
EGAT
(B2).
qs
|PW| is inevitable in the PAKE setting due to online
dictionary attacks and (qs+qe)2
|G|ℓ+2
is negligible.
Sketch of Proof for Active Adversary. We consider the case that an active
adversary A impersonates a user and attacks, including the twist attack with
a SEND query, i.e., A can determine the EPK for one of the users by own. In
the proof, we reduce the advantage of A to the security of DSim-GA-StCDH.
Initially, the adversary B2 against DSim-GA-StCDH receives (x0, x1, w0, w1) =
(g0 ⋆˜x, g1 ⋆˜x, h0 ⋆˜x, h1 ⋆˜x) ∈X 4. First, B2 embeds x0 and x1 in the input of the
DSim-GA-StCDH problem to the CRS of the PAKE game. Second, B2 generates
messages for user U as follows:
xU
i = ui ⋆w0 = (ui · h0 · g−1
0 ) ⋆x0 = (ui · h0 · g−1
1 ) ⋆x1,
ˆxU
0 = ˆu0 ⋆w1 = (ˆu0 · h1 · g−1
0 ) ⋆x0, ˆxU
1 = ˆu1 ⋆w1 = (ˆu1 · h1 · g−1
1 ) ⋆x1,
where the value in brackets is the value used for the DH computation in the
actual protocol. For the other user S, B2 generates messages analogously using
the secret group elements si, ˆs0 and ˆs1. Finally, B2 answers the problem as
follows:
– Case 1: If A impersonates U, since B2 does not know S’s ephemeral secrets,
B2 outputs the answer using ui, ˆu0, ˆu1 and the shared values of the instance.
– Case 2: If A impersonates S, since B2 does not know U’s ephemeral secrets,
B2 outputs the answer using si, ˆs0, ˆs1 and the shared values of the instance.
We simulate in this way to prove that A cannot simultaneously derive the correct
shared values.
4.4
Comparison with Existing Scheme
We show the comparison of the eﬃciency with X-GA-PAKE in Table 1.
In X-GA-PAKE, for the password length ℓ, the number of group actions per
party is 5ℓ, and the number of sent elements per party is 2ℓ. If we use the

Compact Password Authenticated Key Exchange from Group Actions
231
Table 1. Comparison between X-GA-PAKE and our scheme
Protocol
Assumption
# of
rounds
Proved
model
# of
CRS
# of group
action
# of elements
X-GA-PAKEℓ[2]
SqInv-GA-StCDH 1
2-move
2
5ℓ
2ℓ
640
256
X-GA-PAKEt
ℓ,N [2] SqInv-GA-StCDH 1
2-move
2N−1 5ℓ/N
2ℓ/N
160
64
CrsX-GA-PAKEℓ
SqInv-GA-StCDH 1
1-round 2
4ℓ+ 2
ℓ+ 2
512
130
CrsX-GA-PAKEt
ℓ,N SqInv-GA-StCDH 1
1-round 2N−1 4ℓ/N + 2N−1 ℓ/N + 2N−1
130
40
For X-GA-PAKEt
ℓ,N and CrsX-GA-PAKEt
ℓ,N, we apply the technique of increasing the
number of CRS to 2N and dividing the length of passwords into ℓ/N, and the tech-
nique [2] of using twists in the setup, which reduce the number of CRS by half. For
concreteness, expected values for a 128-bit implementation for N = 4 are also given.
technique [2] of using twists in the setup, in our scheme, the number of group
actions per party is 4ℓ+ 2|CRS| and the number of sent elements per party is
ℓ+ 2|CRS|. The optimization technique of the block-by-block approach can be
applied to our scheme. Though when the block size is larger, the number of group
actions and sent elements of X-GA-PAKE can be smaller than our scheme, a large
number of CRS are necessary. In addition, X-GA-PAKE is the one-round scheme,
but there is no security proof for the one-round execution since the security model
is restricted to sequential executions. However, our scheme has tight security
in the one-round PAKE security model based on the same assumptions as in
X-GA-PAKE.
5
Conclusion
In this paper, we proposed an eﬃcient one-round PAKE scheme that reduces
the number of group actions and the communication complexity compared to
X-GA-PAKE. However, our scheme still depends on the password length ℓfor the
number of group actions and the communication complexity. It is a remaining
problem to construct PAKE schemes that do not depend on ℓfor these values
without compromising security.

232
R. Ishibashi and K. Yoneyama
A
Proof of Theorem 1
Proof. Let κ be a security parameter. In the PAKE security game, the maximum
number of EXECUTE query is qe and the maximum number of SEND query is
qs. Let adversary A be a PPT adversary in κ against CrsX-GA-PAKEℓ, and
we construct the adversary B1 against GA-StCDH or the adversary B2 against
SqInv-GA-StCDH using A performs the PAKE security game.
We change the interface of oracle queries and the computation of the ses-
sion key. These instances are gradually changed over seven hybrid experiments
in Figs. 3, 4, 6, 7, 8 and 9 depending on speciﬁc subcases. In the last hybrid
experiment, the session key in the test session does not contain information of
the bit b and the advantage of A is negligible close to qs/|PW|. Thus, the adver-
sary clearly only outputs a random guess. We denote these hybrid experiments
by H0, . . . , H6, and the advantage of the adversary A when participating in
experiment Hi by Adv(A, Hi).
Each game keeps the list LH that keep the queries and answers of H oracle,
the list LCOR that holds the answers of CORRUPT, and the list Le that holds
the session state and the answers of EXECUTE.
Hybrid Experiment H0: This experiment denotes the real experiment for
PAKE security and in this experiment, the environment for A is as deﬁned in the
protocol. Thus, Adv(A, H0) is the same as the advantage of the real experiment.
Hybrid Experiment H1: In the experiment H1, if the trace matches another
accepted instance, we set the ﬂag badcoll. If the ﬂag is set, SEND query returns
⊥(line 64). EXECUTE query also returns ⊥(line 28) if the trace computed in the
query collides with one of a previously accepted instance. From the diﬀerence
lemma, |Adv(A, H1) −Adv(A, H0)| ≤Pr[badcoll]. If badcoll does not set, each
instance is unique and there is at most one partner instance.
The trace of an instance πt
P consists of (U, S, xU = (xU
1 , . . . , xU
ℓ), ˆxU =
(ˆxU
0 , ˆxU
1 ), xS = (xS
1, . . . , xS
ℓ), ˆxS = (ˆxS
0, ˆxS
1)). However, the message for either
(xU, ˆxU) or (xS, ˆxS) was generated by a SEND or EXECUTE query. Thus, badcoll
can only occur if all those ℓ+ 2 set elements collide with all ℓ+ 2 set elements of
another instance. The probability that this happens for two sessions is |G−(ℓ+2)|
and the number of instances is qe + qs, and thus |Adv(A, H1) −Adv(A, H0)| ≤
Pr[badcoll] ≤(qe+qs)2
|Gℓ+2| .
Hybrid Experiment H2: In the experiment H2, We explicitly evaluate the
freshness of instances. For each instance πt
P, we add a variable πt
P.fr which is
updated during the experiment.

Compact Password Authenticated Key Exchange from Group Actions
233
Experiments H0 −H4
00 (g0, g1) ∈R G2
01 (x0, x1) := (g0
˜x, g1
˜x)
02 (LH, LCOR) := (∅, ∅)
03 badcoll := false
//H1-H4
04 β ∈R {0, 1}
05 for (U, S) ∈U × S :
06
pwUS ∈R PW
07 β ←AO(x0, x1)
08 return 1 or ⊥
EXECUTE(U, t0, S, t1)
09 if πt0
U =⊥or πt1
S =⊥
10
return ⊥
11 (b1, . . . , b ) := pwUS
//H0-H3
12 u := (u1, . . . , u ) ∈R G
13 ˆu := (ˆu0, ˆu1) ∈R G2
14 s := (s1, . . . , s ) ∈R G
15 ˆs := (ˆs0, ˆs1) ∈R G2
16 xU := (xU
1 , . . . , xU) := (u1
b1, . . . , u
b )
//H0-H3
17 ˆxU := (ˆxU
0 , ˆxU
1 ) := (ˆu0
0, ˆu1
1)
//H0-H3
18 xS := (xS
1, . . . , xS) := (s1
b1, . . . , s
b )
//H0-H3
19 ˆxS := (ˆxS
0, ˆxS
1) := (ˆs0
0, ˆs1
1)
//H0-H3
20 for i ∈[ ] :
//H0-H3
21
σi := (σi,1, σi,2, σi,3) := (ui
S
i , ˆubi
S
i , ui
ˆxS
bi)//H0-H3
22 σ := (σ1, . . . , σ )
//H0-H3
23 xU := (xU
1 , . . . , xU) := (u1
˜x, . . . , u
˜x)
//H4
24 ˆxU := (ˆxU
0 , ˆxU
1 ) := (ˆu0
˜x, ˆu1
˜x)
//H4
25 xS := (xS
1, . . . , xS) := (s1
˜x, . . . , s
˜x)
//H4
26 ˆxS := (ˆxS
0, ˆxS
1) := (ˆs0
˜x, ˆs1
˜x)
//H4
27 if ∃P ∈U ∪S, t s.t. πt
P .tr = (U, S, xU, ˆxU, xS, ˆxS)
//H1-H4
28
badcoll := true
//H1-H4
29
return ⊥
//H1-H4
30 SK := H(U, S, xU, ˆxU, xS, ˆxS, pwUS, σ)
//H0-H2
31 SK ∈R SK
//H3-H4
32 πt0
U := ((u, ˆu), (U, S, xU, ˆxU, xS, ˆxS), SK, true)
33 πt1
S := (s, (U, S, xU, ˆxU, xS, ˆxS), SK, true)
34 (πt0
U .fr, πt1
S .fr) := (true, true)
//H2-H4
35 return (U, xU, ˆxU, S, xS, ˆxS)
REVEAL(P, t)
36 if πt
P.acc = true or πt
P.test = true
37
return ⊥
38 if ∃P ∈U ∪S, t s.t. Partner(πt
P, πt
P ) = 1
and πt
P .test = true
39
return ⊥
40 if ∀(P , t ) s.t. πt
P .tr = πt
P.tr
//H2-H4
41
πt
P .fr := false
//H2-H4
42 return πt
P.SK
TEST(P, t)
43 if Fresh(πt
P) = false return ⊥
//H0-H1
44 if πt
P.fr := false return ⊥
//H2-H4
45 SK∗
0 := REVEAL(P, t)
46 if SK∗
0 =⊥return ⊥
47 SK∗
1 ∈R SK
48 πt
P.test := true
49 return K∗
β
Fig. 3. Experiments H0–H4 for the proof of Theorem 1.

234
R. Ishibashi and K. Yoneyama
SEND(P, t, msg)
50 if msg = start:
51
if πt
P =⊥return ⊥
52
(b1, . . . , b ) := pwP¯P
53
p := (p1, . . . , p ) ∈R G
54
ˆp := (ˆp0, ˆp1) ∈R G2
55
xP := (xP
1, . . . , xP) := (p1
b1, . . . , p
b )
56
ˆxP := (ˆxP
0, ˆxP
1) := (ˆp0
0, ˆp1
1)
57
πt
P := ((p, ˆp), (P, ¯P, xP, ˆxP, ⊥, ⊥), ⊥, ⊥)
58
πt
P.fr :=⊥
//H2-H4
59
return (P, xP, ˆxP)
60 else if msg = (¯P, x¯P, ˆx¯P):
61
if πt
P = ((p, ˆp), (P, ¯P, xP, ˆxP, ⊥, ⊥), ⊥, ⊥)
62
return ⊥
63
if ∃P ∈U, t s.t. πt
P .tr = (P, ¯P, xP, ˆxP, x¯P, ˆx¯P)
//H1-H4
64
badcoll := true
//H1-H4
65
return ⊥
//H1-H4
66
if ∃t s.t. πt
¯P .tr = (P, ¯P, xP, ˆxP, x¯P, ˆx¯P)
and πt
¯P .fr = true
//H2-H4
67
πt
P.fr = true
//H2-H4
68
else if (P, ¯P)
LCOR
//H2-H4
69
πt
P.fr := true
//H2-H4
70
else
//H2-H4
71
πt
P.fr := false
//H2-H4
72
(b1, . . . , b ) := pwP¯P
73
if P = U:
74
for i ∈[ ]
75
σi := (σi,1, σi,2, σi,3) := (ui
S
i , ˆubi
S
i , ui
ˆxS
bi)
76
else if P = S:
77
for i ∈[ ]
78
σi := (σi,1, σi,2, σi,3) := (si
U
i , si
ˆxU
bi, ˆsbi
U
i )
79
σ := (σ1, . . . , σ )
80
SK := H(P, ¯P, xP, ˆxP, x¯P, ˆx¯P, pwP¯P, σ)
81
πt
P := ((p, ˆp), (P, ¯P, xP, ˆxP, x¯P, ˆx¯P), SK, true)
82
return true
CORRUPT(U, S)
83 if (U, S) ∈LCOR return ⊥
84 for P ∈{U, S} :
85
if ∃t s.t. πt
P.test = true
and
P ∈U ∪S, t s.t. Partner(πt
P, πt
P ) = 1
86
return ⊥
87
∀πt
P : if
P ∈U ∪S, t s.t. Partner(πt
P, πt
P ) = 1
//H2-H4
88
πt
P.fr = false
//H2-H4
89 LCOR := LCOR ∪{(U, S)}
90 return pwUS
H(U, S, xU, ˆxU, xS, ˆxS, pw, σ)
91 if LH[U, S, xU, ˆxU, xS, ˆxS, pw, σ] = SK =⊥
92
return SK
93 LH[U, S, xU, ˆxU, xS, ˆxS, pw, σ] ∈R SK
94 return LH[U, S, xU, ˆxU, xS, ˆxS, pw, σ]
Fig. 4. Experiments H0–H4 for the proof of Theorem 1.

Compact Password Authenticated Key Exchange from Group Actions
235
We mark the variable as follows: All instances generated by an EXECUTE
query are marked as fresh (line 34). In the SEND query, we mark the instance
as fresh if the password was not corrupted yet (line 69) and there exists a fresh
partner (line 66), otherwise, we mark the instance as not fresh (line 71). If A
issues a CORRUPT query after the instance is generated, the freshness variable
is updated (line 88). Also, if the session key of an instance is revealed, this
instance and its partner instance are marked as not fresh (line 41). In the TEST
query, this freshness variable is checked (line 44). Note that these are conceptual
changes, and thus Adv(A, H2) = Adv(A, H1).
Hybrid Experiment H3: In the experiment H3, we change the way of com-
putation of SK for instances queried to EXECUTE. Instead of computing
SK ←H(U, S, xU, ˆxU, xS, ˆxS, pwUS, σ), it is changed as SK ∈R SK. We construct
adversary B1 against GA-StCDH in Fig. 5 from A in H2 or H3.
Initially, B1 takes (x, y) = (g⋆˜x, h⋆˜x) as input and can access GA-DDH(x, ·, ·).
First, B1 generates CRS as in H2, and simulates this experiment using A. For
querying to EXECUTE, B1 simulates it as follows:
For i ∈[ℓ], B1 chooses ephemeral secret values ui, ˆu0, ˆu1 and si, ˆs0, ˆs1 for
each instance. Also, B1 uses x for U’s message generation and y for S’s message
generation instead of using xbℓ. Therefore, the messages in the EXECUTE query
are generated independently of the password bits bi (lines 30 to 33). Note that
this message can be rewritten as follows:
xU
i = ui ⋆x = (ui · g) ⋆˜x = (ui · g · gbi · g−1
bi ) ⋆˜x = (ui · g · g−1
bi ) ⋆xbi,
where the value u′
i = ui · g · g−1
bi
in brackets is the secret value used for the DH
computation in the actual protocol. For the other messages, the values ˆu′
0 =
ˆu0 · g · g−1
bi , ˆu′
1 = ˆu1 · g · g−1
bi , s′
i = si · h · g−1
bi , ˆs′
0 = ˆs0 · h · g−1
bi
and ˆs′
1 = ˆs1 · h · g−1
bi
are the secret value for the DH computation. This means that shared value
σi = (σi,1, σi,2, σi,3) is implicitly computed as follows:
σi,1 = (u′
i · s′
i) ⋆xbi = ui · g · si · h · g−1
bi ⋆˜x,
σi,2 = (ˆu′
bi · s′
i) ⋆xbi = ˆubi · g · si · h · g−1
bi ⋆˜x,
σi,3 = (u′
i · ˆs′
bi) ⋆xbi = ui · g · ˆsbi · h · g−1
bi ⋆˜x.
Before choosing a session key at random, we check whether a value (U, S, xU, ˆxU,
xS, ˆxS, pwUS, σ) matching the true session key is queried to the random oracle
H (line 40 to 50). We continue to check in LH whether even one entry in σ is
computed correctly with pwUS. We can simulate as follows using the DDH oracle:
GA-CDHxbi(xU
i , xS
i ) = σi,1 ⇔GA-CDH(x, xS
i ) = (u−1
i
· gbi) ⋆σi,1,
GA-CDHxbi(ˆxU
bi, xS
i ) = σi,2 ⇔GA-CDH(x, xS
i ) = (ˆu−1
bi · gbi) ⋆σi,2,
GA-CDHxbi(xU
i , ˆxS
bi) = σi,3 ⇔GA-CDH(x, ˆxS
bi) = (u−1
i
· gbi) ⋆σi,3,
which allows us to use the restricted decision oracle GA-DDH(x, ·, ·). If even one
correct shared value exists in σ, B1 aborts the experiment and outputs (g · h) ⋆˜x

236
R. Ishibashi and K. Yoneyama
BGA-DDH(x,·,·)
1
(x, y)
EXECUTE(U, t0, S, t1)
00 (g0, g1) ∈R G2
23 if πt0
U =⊥or πt1
S =⊥
01 (x0, x1) := (g0
˜x, g1
˜x)
24
return ⊥
02 (LH, LCOR, Le) := (∅, ∅, ∅)
25 (b1, . . . , b ) := pwUS
03 badcoll := false
26 u := (u1, . . . , u ) ∈R G
04 β ∈R {0, 1}
27 ˆu := (ˆu0, ˆu1) ∈R G2
05 for (U, S) ∈U × S :
28 s := (s1, . . . , s ) ∈R G
06
pwUS ∈R PW
29 ˆs := (ˆs0, ˆs1) ∈R G2
07 β ←AO(x0, x1)
30 xU := (xU
1, . . . , xU) := (u1
)
08 Stop.
31 ˆxU := (ˆxU
0, ˆxU
1) := (ˆu0
ˆu1
)
32 xS := (xS
1, . . . , xS) := (s1
)
33 ˆxS := (ˆxS
0, ˆxS
1) := (ˆs0
ˆs1
)
34 if ∃P ∈U ∪S, t s.t. πt
P .tr = (U, S, xU, ˆxU, xS, ˆxS)
H(U, S, xU, ˆxU, xS, ˆxS, pw, σ)
35
badcoll := true
09 if ∃(u, ˆu, s, ˆs)
36
return ⊥
s.t. (U, S, xU, ˆxU, xS, ˆxS, pw, u, ˆu, s, ˆs) ∈Le
37 ∀σ s.t. (U, S, xU, ˆxU, xS, ˆxS, pwUS, σ) ∈LH
10
(b1, . . . , b ) := pwUS
38
for i ∈[ ] :
11
for i ∈[ ] :
39
(σi,1, σi,2, σi,3) := σi
12
(σi,1, σi,2, σi,3) := σi
40
if GA-DDH(x, xS
i , (u−1
i
· gbi)
i,1) = 1
13
if GA-DDH(x, xS
i , (u−1
i
· gbi)
i,1) = 1
41
Stop with (u−1
i
· s−1
i
· gbi)
i,1
14
Stop with (u−1
i
· s−1
i
· gbi)
i,1
42
if GA-DDH(x, xS
i , (ˆu−1
bi · gbi)
i,2) = 1
15
if GA-DDH(x, xS
i , (ˆu−1
bi · gbi)
i,2) = 1
43
Stop with (ˆu−1
bi · s−1
i
· gbi)
i,2
16
Stop with (ˆu−1
bi · s−1
i
· gbi)
i,2
44
if GA-DDH(x, ˆxS
bi, (u−1
i
· gbi)
i,3) = 1
17
if GA-DDH(x, ˆxS
bi, (u−1
i
· gbi)
i,3) = 1
45
Stop with (u−1
i
· ˆs−1
bi · gbi)
i,3
18
Stop with (u−1
i
· ˆs−1
bi · gbi)
i,3
46 Le := Le ∪{U, S, xU, ˆxU, xS, ˆxS, pwUS, u, ˆu, s}
19 if LH[U, S, xU, ˆxU, xS, ˆxS, pw, σ] = SK =⊥
47 SK ∈R SK
20
return SK
48 πt0
U := ((u, ˆu), (U, S, xU, ˆxU, xS), ˆxS, SK, true)
21 LH[U, S, xU, ˆxU, xS, ˆxS, pw, σ] ∈R SK
49 πt1
S := (s, (U, S, xU, ˆxU, xS, ˆxS), SK, true)
22 return LH[U, S, xU, ˆxU, xS, ˆxS, pw, σ]
50 (πt0
U .fr, πt1
S .fr) := (true, true)
51 return (U, xU, ˆxU, S, xS, ˆxS)
Fig. 5. Adversary B1 against GA-StCDH for the proof of Theorem 1. Oracles
SEND,REVEAL,CORRUPT and TEST are the same as in H3.
which is respectively given by (u−1
i
· s−1
i
· gbi) ⋆σi,1, (ˆu−1
bi · s−1
i
· gbi) ⋆σi,2 or
(u−1
i
· ˆs−1
bi · gbi) ⋆σi,3.
Otherwise, we store the ephemeral secret values ui, ˆu0, ˆu1 and si, ˆs0, ˆs1 in
Le, which is to identify relevant queries to H, together with the trace and the
password (line 46) and choose a session key uniformly at random. Especially, if
the trace and pwUS are queried with new σ to H, we can re-evaluate in the same
way as described above using the DDH oracle by retrieving the secret values from
Le (lines 13 to 18). If the oracle returns 1 for any σi, B1 aborts the experiment
and outputs (g · h) ⋆˜x which is respectively given by (u−1
i
· s−1
i
· gbi) ⋆σi,1,
(ˆu−1
bi · s−1
i
· gbi) ⋆σi,2 or (u−1
i
· ˆs−1
bi · gbi) ⋆σi,3.
Thus, since the advantage of B1 is negligible due to the GA-StCDH assump-
tion, |Adv(A, H3) −Adv(A, H2)| ≤Pr[badcoll] ≤negl.

Compact Password Authenticated Key Exchange from Group Actions
237
Experiment H5
00 (g0, g1) ∈R G2
01 (x0, x1) := (g0
˜x, g1
˜x)
02 (LH, LCOR, Ls) := (∅, ∅, ∅)
03 badcoll := false
04 β ∈R {0, 1}
05 for (U, S) ∈U × S :
06
pwUS ∈R PW
07 β ←AO(x0, x1)
08 return 1 or ⊥
EXECUTE(U, t0, S, t1)
09 if πt0
U =⊥or πt1
S =⊥: return ⊥
10 u := (u1, . . . , u ) ∈R G
11 ˆu := (ˆu0, ˆu1) ∈R G2
12 s := (s1, . . . , s ) ∈R G
13 ˆs := (ˆs0, ˆs1) ∈R G2
14 xU := (xU
1 , . . . , xU) := (u1
˜x, . . . , u
˜x)
15 ˆxU := (ˆxU
0 , ˆxU
1 ) := (ˆu0
˜x, ˆu1
˜x)
16 xS := (xS
1, . . . , xS) := (s1
˜x, . . . , s
˜x)
17 ˆxS := (ˆxS
0, ˆxS
1) := (ˆs0
˜x, ˆs1
˜x)
18 if ∃P ∈U ∪S, t s.t. πt
P .tr = (U, S, xU, ˆxU, xS)
19
return ⊥
20 SK ∈R SK
21 πt0
U := ((u, ˆu), (U, S, xU, ˆxU, xS), ˆxS, SK, true)
22 πt1
S := (s, ˆs), (U, S, xU, ˆxU, xS, ˆxS), SK, true)
23 (πt0
U .fr, πt1
S .fr) := (true, true)
24 return (U, xU, ˆxU, S, xS, ˆxS)
H(U, S, xU, ˆxU, xS, ˆxS, pw, σ)
25 if LH[U, S, xU, ˆxU, xS, ˆxS, pw, σ] = SK =⊥
26
return SK
27 (b1, . . . , b ) := pw
28 if (U, S, xU, ˆxU, xS, ˆxS) ∈Ls and pw = pwUS
29
if Ls[U, S, xU, ˆxU, xS, ˆxS] = (U, (u, ˆu), SK)
30
for i ∈[ ]:
31
σi := (ui
S
i , ˆubi
S
i , ui
ˆxS
bi)
32
σ := (σ1, . . . , σ )
33
if Ls[U, S, xU, ˆxU, xS, ˆxS] = (S, (s, ˆs), SK)
34
for i ∈[ ]:
35
σi := (si
U
i , si
ˆxU
bi, ˆsbi
U
i )
36
σ := (σ1, . . . , σ )
37
if σ = σ
38
if (U, S) ∈LCOR : return SK
39
if (U, S)
LCOR : bad := true
40 LH[U, S, xU, ˆxU, xS, ˆxS, pw, σ] ∈R SK
41 return LH[U, S, xU, ˆxU, xS, ˆxS, pw, σ]
Fig. 6. Experiment H5 for the proof of Theorem 1. REVEAL, TEST and CORRUPT are
the same as in Fig. 3 and 4.

238
R. Ishibashi and K. Yoneyama
SEND(P, t, msg)
42 if msg = start:
43
if πt
P =⊥return ⊥
44
(b1, . . . , b ) := pwP¯P
45
p := (p1, . . . , p ) ∈R G
46
ˆp := (ˆp0, ˆp1) ∈R G2
47
xP := (xP
1, . . . , xP) := (p1
b1, . . . , p
b )
48
ˆxP := (ˆxP
0, ˆxP
1) := (ˆp0
0, ˆp1
1)
49
πt
P := ((p, ˆp), (P, ¯P, xP, ˆxP, ⊥, ⊥), ⊥, ⊥)
50
πt
P.fr :=⊥
51
return (P, xP, ˆxP)
52 else if msg = (¯P, x¯P, ˆx¯P):
53
if πt
P = ((p, ˆp), (P, ¯P, xP, ˆxP, ⊥, ⊥), ⊥, ⊥)
54
return ⊥
55
if ∃P ∈U, t s.t. πt
P .tr = (P, ¯P, xP, ˆxP, x¯P, ˆx¯P)
56
return ⊥
57
if ∃t s.t. πt
¯P .tr = (P, ¯P, xP, ˆxP, x¯P, ˆx¯P)
and πt
¯P .fr = true
58
πt
P.fr = true
59
(¯P, (¯p, ˆ¯p), SK) := Ls[P, ¯P, xP, ˆxP, x¯P, ˆx¯P]
60
if ∃σ s.t. (P, ¯P, xP, ˆxP, x¯P, ˆx¯P, pwP¯P, σ) ∈LH
and (¯P = U and σi := (ui
S
i , ˆubi
S
i , ui
ˆxS
bi) ∀i ∈[ ])
∪(¯P = S and σi := (si
U
i , si
ˆxU
bi, ˆsbi
U
i ) ∀i ∈[ ])
61
bad := true
62
else if (P, ¯P)
LCOR
63
πt
P.fr := true
64
if ∃σ s.t. (P, ¯P, xP, ˆxP, x¯P, ˆx¯P, pwP¯P, σ) ∈LH
and (¯P = U and σi := (ui
S
i , ˆubi
S
i , ui
ˆxS
bi) ∀i ∈[ ])
∪(¯P = S and σi := (si
U
i , si
ˆxU
bi, ˆsbi
U
i ) ∀i ∈[ ])
65
bad := true
66
SK ∈R SK
67
Ls[P, ¯P, xP, ˆxP, x¯P, ˆx¯P] := (P, (p, ˆp), SK)
68
else
69
πt
P.fr := false
70
(b1, . . . , b ) := pwP¯P
71
if P = U:
72
for i ∈[ ]
73
σi := (σi,1, σi,2, σi,3) := (ui
S
i , ˆubi
S
i , ui
ˆxS
bi)
74
else if P = S:
75
for i ∈[ ]
76
σi := (σi,1, σi,2, σi,3) := (si
U
i , si
ˆxU
bi, ˆsbi
U
i )
77
σ := (σ1, . . . , σ )
78
SK := H(P, ¯P, xP, ˆxP, x¯P, ˆx¯P, pwP¯P, σ)
79
πt
P := ((p, ˆp), (P, ¯P, xP, ˆxP, x¯P, ˆx¯P), SK, true)
80
return true
Fig. 7. Experiment H5 for the proof of Theorem 1. REVEAL, TEST and CORRUPT are
the same as in Fig. 3 and 4.

Compact Password Authenticated Key Exchange from Group Actions
239
Hybrid Experiment H4: In the experiment H4, we remove the password from
EXECUTE query. Therefore, we use the origin ˜x instead of xbi for gererating
messages xU, ˆxU, xS and ˆxS. These values are the same distribution as in H3,
and the secret values are not used in the derivation of the session key in H3.
Thus, Adv(A, H4) = Adv(A, H3).
Hybrid Experiment H5: In this experiment in Fig. 6 and 7, we change the
way of computation of SK for all fresh instances queried to SEND (line 66).
Instead of computing SK ←H(U, S, xU, ˆxU, xS, ˆxS, pwUS, σ), it is changed as
SK ∈R SK. Here, we add an additional independent random oracle Ls which
maps the trace and SK to the secret values of U or S (line 67) to keep partner
instances consistent. Speciﬁcally, if A queries SEND for an instance of P and
there exists a fresh partner instance, we retrieve the corresponding session key
SK from Ls and assign it to the instance (line 59). For all non-fresh instances,
we compute the session key using random oracle H according to the protocol
(lines 69 to 79).
If an event that a session is fresh and there is an inconsistency between LH
and Ls occurs, we set ﬂag bad. The event happens in the following cases: (i) For
the instance which computes the session key, there exists no partner instance
and the password is not corrupted, but the correct password and σ already exist
in LH (lines 60 to 65). (ii) the random oracle H is queried on some trace that
exists in Ls together with the correct password and σ (lines 28 to 39). At this
time, if the password was corrupted and the adversary issues the correct query,
we output the session key SK stored in Ls (line 38).
When bad does not occur, there is no diﬀerence between H4 and H5. Thus,
Adv(A, H5) −Adv(A, H4) ≤Pr[H5 ⇒bad].
Hybrid Experiment H6: In this experiment H6 in Fig. 8 and 9, we remove
the password from the SEND query and generate passwords as late as possible.
Speciﬁcally, we generate the password in the case that the adversary issues a
CORRUPT query (line 21) or it has stopped with output β′ (line 07). In the
SEND query, we choose ephemeral secret values pi, ˆp0, ˆp1 uniformly at random,
and compute messages xP
i , ˆxP
0 and ˆxP
1 using the origin element ˜x (lines 46,47)
instead of xbi. Note that this message can be rewritten as follows:
xU
i = ui ⋆˜x = (ui · g−1
0 ) ⋆x0 = (ui · g−1
1 ) ⋆x1 = (ui · g−1
bi ) ⋆xbi,
and we use ˜x for generating ˆxU
0 , ˆxU
1 , xS
i , ˆxS
0 and ˆxS
1 in the same way. For all
non-fresh instances, we have to compute the actual correct session keys using
σi = (si · g−1
bi ⋆xU
i , si · g−1
bi ⋆ˆxU
bi, ˆsbi · g−1
bi ⋆xU
i ) (line 82) or σi = (ui · g−1
bi ⋆xS
i , ˆubi ·
g−1
bi ⋆xS
i , ui · g−1
bi ⋆xS
bi) (line 79). In this case, the password has already been
generated in the CORRUPT query.

240
R. Ishibashi and K. Yoneyama
Experiment H6
00 (g0, g1) ∈R G2
01 (x0, x1) := (g0
˜x, g1
˜x)
02 (LH, LCOR, Ls, Lbad) := (∅, ∅, ∅, ∅)
03 (badguess, badpw) := (false, false)
04 β ∈R {0, 1}
05 β ←AO(x0, x1)
06 for (U, S) ∈U\LCOR :
07
pwUS ∈R PW
08 if ∃pw, pw , (U, S, xU, ˆxU, xS, ˆxS, σ, σ )
s.t. (U, S, xU, ˆxU, xS, ˆxS, pw, σ) ∈Lbad
and (U, S, xU, ˆxU, xS, ˆxS, pw , σ ) ∈Lbad
09
badpw := true
10 else
11 if ∃U, S, xU, ˆxU, xS, ˆxS, σ
s.t. (U, S, xU, ˆxU, xS, ˆxS, pwUS, σ) ∈Lbad
12
badguess := true
13 return 1 or ⊥
CORRUPT(U, S)
14 if (U, S) ∈LCOR return ⊥
15 for P ∈{U, S}
16
if ∃t s.t. πt
P.test = true
and
P ∈U ∪S, t s.t. Partner(πt
P, πt
P ) = 1
17
return ⊥
18
∀πt
P : if
P ∈U ∪S, t s.t. Partner(πt
P, πt
P ) = 1
19
πt
P.fr = false
20 LCOR := LCOR ∪{(U, S)}
21 pwUS ∈R PW
22 return pwUS
H(U, S, xU, ˆxU, xS, ˆxS, pw, σ)
23 if LH[U, S, xU, ˆxU, xS, ˆxS, pw, σ] = SK =⊥
24
return SK
25 if (U, S, xU, ˆxU, xS, ˆxS) ∈Ls
26
(b1, . . . , b ) := pw
27
if Ls[U, S, xU, ˆxU, xS, ˆxS] = (U, (u, ˆu), SK)
28
for i ∈[ ]:
29
σi := (ui · g−1
bi
S
i , ˆubi · g−1
bi
S
i , ui · g−1
bi
ˆxS
bi)
30
σ := (σ1, . . . , σ )
31
if Ls[U, S, xU, ˆxU, xS, ˆxS] = (S, (s, ˆs), SK)
32
for i ∈[ ]:
33
σi := (si · g−1
bi
U
i , si · g−1
bi
ˆxU
bi, ˆsbi · g−1
bi
U
i )
34
σ := (σ1, . . . , σ )
35
if σ = σ
36
if (U, S) ∈LCOR and pw = pwUS : return SK
37
if (U, S)
LCOR
38
Lbad := Lbad ∪{U, S, xU, ˆxU, xS, ˆxS, pw, σ}
39 LH[U, S, xU, ˆxU, xS, ˆxS, pw, σ] ∈R SK
40 return LH[U, S, xU, ˆxU, xS, ˆxS, pw, σ]
Fig. 8. Experiment H6 for the proof of Theorem 1. REVEAL and TEST are the same
as in Fig. 3 and 4. EXECUTE is the same as in Fig. 6 and 7.

Compact Password Authenticated Key Exchange from Group Actions
241
SEND(P, t, msg)
41 if msg = start:
42
if πt
P =⊥return ⊥
43
(b1, . . . , b ) := pwP¯P
44
p := (p1, . . . , p ) ∈R G
45
ˆp := (ˆp0, ˆp1) ∈R G2
46
xP := (xP
1, . . . , xP) := (p1
˜x, . . . , p
˜x)
47
ˆxP := (ˆxP
0, ˆxP
1) := (ˆp0
˜x, ˆp1
˜x)
48
πt
P := ((p, ˆp), (P, ¯P, xP, ˆxP, ⊥, ⊥), ⊥, ⊥)
49
πt
P.fr :=⊥
50
return (P, xP, ˆxP)
51 else if msg = (¯P, x¯P, ˆx¯P):
52
if πt
P = ((p, ˆp), (P, ¯P, xP, ˆxP, ⊥, ⊥), ⊥, ⊥)
53
return ⊥
54
if ∃P ∈U, t s.t. πt
P .tr = (P, ¯P, xP, ˆxP, x¯P, ˆx¯P)
55
return ⊥
56
if ∃t s.t. πt
¯P .tr = (P, ¯P, xP, ˆxP, x¯P, ˆx¯P)
and πt
¯P .fr = true
57
πt
P.fr = true
58
(¯P, (¯p, ˆ¯p), SK) := Ls[P, ¯P, xP, ˆxP, x¯P, ˆx¯P]
59
else if (P, ¯P)
LCOR
60
πt
P.fr := true
61
if ∃pw, σ s.t. (P, ¯P, xP, ˆxP, x¯P, ˆx¯P, pw, σ) ∈LH
and P = U
62
(b1, . . . , b ) := pw
63
for i ∈[ ] :
64
σi := (ui · g−1
bi
S
i , ˆubi · g−1
bi
S
i , ui · g−1
bi
ˆxS
bi)
65
else if ∃pw, σ s.t. (P, ¯P, xP, ˆxP, x¯P, ˆx¯P, pw, σ) ∈LH
and P = S
66
(b1, . . . , b ) := pw
67
for i ∈[ ] :
68
σi := (si · g−1
bi
U
i , si · g−1
bi
ˆxU
bi, ˆsbi · g−1
bi
U
i )
69
σ := (σ1, . . . , σ )
70
if σ = σ
71
Lbad := Lbad ∪{P, ¯P, xP, ˆxP, x¯P, ˆx¯P, pw, σ}
72
SK ∈R SK
73
Ls[P, ¯P, xP, ˆxP, x¯P, ˆx¯P] := (P, (p, ˆp), SK)
74
else
75
πt
P.fr := false
76
(b1, . . . , b ) := pwP¯P
77
if P = U
78
for i ∈[ ] :
79
σi := (ui · g−1
bi
S
i , ˆubi · g−1
bi
S
i , ui · g−1
bi
ˆxS
bi)
80
else if P = S
81
for i ∈[ ] :
82
σi := (si · g−1
bi
U
i , si · g−1
bi
ˆxU
bi, ˆsbi · g−1
bi
U
i )
83
σ := (σ1, . . . , σ )
84
SK := H(P, ¯P, xP, ˆxP, x¯P, ˆx¯P, pwP¯P, σ)
85
πt
P := ((p, ˆp), (P, ¯P, xP, ˆxP, x¯P, ˆx¯P), SK, true)
86
return true
Fig. 9. Experiment H6 for the proof of Theorem 1. REVEAL and TEST are the same
as in Fig. 3 and 4. EXECUTE is the same as in Fig. 6 and 7.

242
R. Ishibashi and K. Yoneyama
We recall that the event bad in H5 occurs in the case that there is an
inconsistency in the querying to the random oracle H and the session key of
fresh instances. In this experiment, we split the event bad into the following
two events: (i)badpw which captures the event that there exists more than one
correct entry in LH for the same trace of a fresh instance, but the passwords are
diﬀerent. (ii) badguess which captures the event that badpw does not occur and
there exists a correct entry with the trace of a fresh instance and the correct
password in LH, where the password was not corrupted when the query to H was
issued.
In order to identify these events, we add a list Lbad. For all fresh instances
in SEND, we iterate the following for all entries in LH: We check if the given
password and σ are correct for the trace by computing the correct values σ′
dependent on the password in the same way as for non-fresh instances. If σ = σ′,
we add the entry to Lbad (lines 61 to 71). Also, we simulate the random oracle
H queried on a trace that appears in Ls in the same way. In this case, A speciﬁes
pw, thus we check whether σ is computed correctly with the pw by using pi, ˆp0, ˆp1
stored in Ls for the instance of P. If σ is correct and the instance is fresh, we
add the entry to Lbad (lines 25 to 38). In the case that the pw has been already
corrupted, we return the session key stored in Ls. When A outputs β′, we check
Lbad whether the event badpw (line 09) or the event badguess (line 12) occurred.
Note that when the ﬂag bad is set in H5, the ﬂag badguess or badpw is set
in H6, thus Pr[G5 ⇒bad] ≤Pr[G6 ⇒badpw]+Pr[G6 ⇒badguess]. We evaluate
the probability of two events. First, we evaluate the probability of badpw. We
construct adversary B2 against DSim-GA-StCDH that simulates H6 in Fig. 10
and 11.
Initially, B2 inputs (x0, x1, w0, w1), where g0, g1, h0, h1 ∈R G, x0 = g0 ⋆˜x,
x1 = g1 ⋆˜x, w0 = h0 ⋆˜x and w1 = h1 ⋆˜x. B2 also can access to the DDH oracles
GA-DDHxj(wk, ·, ·) for (j, k) ∈{0, 1}2. B2 gives A (x0, x1) as input and simulates
SEND queries as follows:
In the case of P = U, B2 chooses ephemeral secret values ui and ˆui uniformly
at random and computes as follows:
xU
i = ui ⋆w0 = (ui · h0 · g−1
0 ) ⋆x0 = (ui · h0 · g−1
1 ) ⋆x1,
ˆxU
0 = ˆu0 ⋆w1 = (ˆu0 · h1 · g−1
0 ) ⋆x0, ˆxU
1 = ˆu1 ⋆w1 = (ˆu1 · h1 · g−1
1 ) ⋆x1.
Also, in the case of P = S, B2 generates messages xS
i , ˆxS
0 and ˆxS
1 in the same way.
If the instance of S is fresh, B2 check if there exists an entry in LH that causes
the event bad. It iterates over all the pair of (pw, σ) in LH with the trace of the
instance. Speciﬁcally, it checks whether there is a correct shared value as follows:
σi,1 = GA-CDHxbi(xU
i , xS
i ) ⇔GA-CDHxbi(w0, xU
i ) = s−1
i
⋆σi,1,
σi,2 = GA-CDHxbi(ˆxU
bi, xS
i ) ⇔GA-CDHxbi(w0, ˆxU
bi) = s−1
i
⋆σi,2,
σi,3 = GA-CDHxbi(xU
i , ˆxS
bi) ⇔GA-CDHxbi(w1, xU
i ) = ˆs−1
bi ⋆σi,3,
where it simulates with the DDH oracles GA-DDHxbj (zi,1, ·, ·). If σi
=
(σi,1, σi,2, σi,3) are correct, B2 add the entry to Lbad (lines 61 to 64).

Compact Password Authenticated Key Exchange from Group Actions
243
B
{GA-DDHxj (wk,·,·)}j,k∈{0,1}
2
(x0, x1, w0, w1)
00 (LH, LCOR, Ls, Lbad) := (∅, ∅, ∅, ∅)
01 β ∈R {0, 1}
02 β ←AO(x0, x1)
03 for (U, S) ∈U\LCOR :
04
pwUS ∈R PW
05 if ∃pw, pw , (U, S, xU, ˆxU, xS, ˆxS, σ, σ )
s.t. (U, S, xU, ˆxU, xS, ˆxS, pw, σ) ∈Lbad
and (U, S, xU, ˆxU, xS, ˆxS, pw , σ ) ∈Lbad
06
(b1, . . . , b ) := pw
07
(b1, . . . , b ) := pw
08
i∗such that bi∗= bi∗
09
W.l.o.g. let bi∗= 0, bi∗= 1
10
if Ls[U, S, xU, ˆxU, xS, ˆxS] = (U, (u, ˆu), SK)
11
Stop with (xS
i∗, u−1
i∗
i∗,1, ˆu−1
bi∗
i∗,2, u−1
i∗
i∗,1, ˆu−1
bi∗
i∗,2)
12
if Ls[U, S, xU, ˆxU, xS, ˆxS] = (S, (s, ˆs), SK)
13
Stop with (xU
i∗, s−1
i∗
i∗,1, ˆs−1
bi∗
i∗,3, s−1
i∗
i∗,1, ˆs−1
bi∗
i∗,3)
H(U, S, xU, ˆxU, xS, ˆxS, pw, σ)
14 if LH[U, S, xU, ˆxU, xS, ˆxS, pw, σ] = SK =⊥
15
return SK
16 if (U, S, xU, ˆxU, xS, ˆxS) ∈Ls
17
(b1, . . . , b ) := pw
18
if Ls[U, S, xU, ˆxU, xS, ˆxS] = (U, (u, ˆu), SK)
19
if GA-DDHxbi(w0, xS
i , u−1
i
i,1) = 1 ∀i ∈[ ]
and GA-DDHxbi(w1, xS
i , ˆu−1
bi
i,2) = 1 ∀i ∈[ ]
and GA-DDHxbi(w0, ˆxS
bi, u−1
i,3) = 1 ∀i ∈[ ]
20
if (U, S)
LCOR
21
Lbad := Lbad ∪{U, S, xU, ˆxU, xS, ˆxS, pw, σ}
22
if (U, S) ∈LCOR and pw = pwUS
23
return SK
24
if Ls[U, S, xU, ˆxU, xS, ˆxS] = (S, (s, ˆs), SK)
25
if GA-DDHxbi(w0, xU
i , s−1
i
i,1) = 1 ∀i ∈[ ]
and GA-DDHxbi(w0, ˆxU
bi, s−1
i
i,2) = 1 ∀i ∈[ ]
and GA-DDHxbi(w1, xU
i , ˆs−1
bi
i,3) = 1 ∀i ∈[ ]
26
if (U, S)
LCOR
27
Lbad := Lbad ∪{U, S, xU, ˆxU, xS, ˆxS, pw, σ}
28
if (U, S) ∈LCOR and pw = pwUS
29
return SK
30 if ∃(u, ˆu) s.t. (U, S, xU, ˆxU, xS, ˆxS, pw, (u, ˆu)) ∈LH
31
(b1, . . . , b ) := pw
32
if GA-DDHxbi(w0, xS
i , u−1
i
i,1) = 1 ∀i ∈[ ]
and GA-DDHxbi(w1, xS
i , ˆu−1
bi
i,2) = 1 ∀i ∈[ ]
and GA-DDHxbi(w0, ˆxS
bi, u−1
i
i,3) = 1 ∀i ∈[ ]
33
return LH[U, S, xU, ˆxU, xS, ˆxS, pw, (u, ˆu)]
34 else if ∃(s, ˆs)
s.t. (U, S, xU, ˆxU, xS, ˆxS, pw, (s, ˆs)) ∈LH
35
(b1, . . . , b ) := pw
36
if GA-DDHxbi(w0, xU
i , s−1
i
i,1) = 1 ∀i ∈[ ]
and GA-DDHxbi(w0, ˆxU
bi, s−1
i
i,2) = 1 ∀i ∈[ ]
and GA-DDHxbi(w1, xU
i , ˆs−1
bi
i,3) = 1 ∀i ∈[ ]
37
return LH[U, S, xU, ˆxU, xS, ˆxS, pw, (s, ˆs)]
38 LH[U, S, xU, ˆxU, xS, ˆxS, pw, σ] ∈R SK
39 return LH[U, S, xU, ˆxU, xS, ˆxS, pw, σ]
Fig. 10. Adversary B2 against DSim-GA-StCDH for the proof of Theorem 1. Oracles
EXECUTE,REVEAL,CORRUPT and TEST are the same as in H5.

244
R. Ishibashi and K. Yoneyama
SEND(P, t, msg)
40 if msg = start:
41
if πt
P =⊥return ⊥
42
p := (p1, . . . , p ) ∈R G
43
ˆp := (ˆp0, ˆp1) ∈R G2
44
xP := (xP
1, . . . , xP) := (p1
0, . . . , p
0)
45
ˆxP := (ˆxP
0, ˆxP
1) := (ˆp0
1, ˆp1
1)
46
πt
P := ((p, ˆp), (P, ¯P, xP, ˆxP, ⊥, ⊥), ⊥, ⊥)
47
return (P, xP, ˆxP)
48 else if msg = (¯P, x¯P, ˆx¯P):
49
if πt
P = ((p, ˆp), (P, ¯P, xP, ˆxP, ⊥, ⊥), ⊥, ⊥) : return ⊥
50
if ∃P ∈U, t s.t. πt
P .tr = (P, ¯P, xP, ˆxP, x¯P, ˆx¯P)
51
return ⊥
52
if ∃t s.t. πt
¯P .tr = (P, ¯P, xP, ˆxP, x¯P, ˆx¯P) and πt
¯P .fr = true
53
πt
P.fr = true
54
(¯P, (¯p, ˆ¯p), SK) := Ls[P, ¯P, xP, ˆxP, x¯P, ˆx¯P]
55
else if (P, ¯P)
LCOR
56
πt
P.fr := true
57
if ∃pw, σ s.t. (P, ¯P, xP, ˆxP, x¯P, ˆx¯P, pw, σ) ∈LH and P = U
58
(b1, . . . , b ) := pw
59
if GA-DDHxbi(w0, xS
i , u−1
i
i,1) = 1 ∀i ∈[ ]
and GA-DDHxbi(w1, xS
i , ˆu−1
bi
i,2) = 1 ∀i ∈[ ]
and GA-DDHxbi(w0, ˆxS
bi, u−1
i
i,3) = 1 ∀i ∈[ ]
60
Lbad := Lbad ∪{P, ¯P, xP, ˆxP, x¯P, ˆx¯P, pw, σ}
61
else if ∃pw, σ s.t. (P, ¯P, xP, ˆxP, x¯P, ˆx¯P, pw, σ) ∈LH and P = S
62
(b1, . . . , b ) := pw
63
if GA-DDHxbi(w0, xU
i , s−1
i
i,1) = 1 ∀i ∈[ ]
and GA-DDHxbi(w0, ˆxU
bi, s−1
i
i,2) = 1 ∀i ∈[ ]
and GA-DDHxbi(w1, xU
i , ˆs−1
bi
i,3) = 1 ∀i ∈[ ]
64
Lbad := Lbad ∪{P, ¯P, xP, ˆxP, x¯P, ˆx¯P, pw, σ}
65
SK ∈R SK
66
Ls[P, ¯P, xP, ˆxP, x¯P, ˆx¯P] = (P, (p, ˆp), SK)
67
else
68
πt
P.fr := false
69
(b1, . . . , b ) := pwP¯P
70
if ∃σ s.t. (P, ¯P, xP, ˆxP, x¯P, ˆx¯P, pw, σ) ∈LH and P = U
71
and GA-DDHxbi(w0, xS
i , u−1
i
i,1) = 1 ∀i ∈[ ]
and GA-DDHxbi(w1, xS
i , ˆu−1
bi
i,2) = 1 ∀i ∈[ ]
and GA-DDHxbi(w0, ˆxS
bi, u−1
i
i,3) = 1 ∀i ∈[ ]
72
SK := LH[P, ¯P, xP, ˆxP, x¯P, ˆx¯P, pwP¯P, σ]
73
else if ∃σ s.t. (P, ¯P, xP, ˆxP, x¯P, ˆx¯P, pw, σ) ∈LH and P = S
and GA-DDHxbi(w0, xU
i , s−1
i
i,1) = 1 ∀i ∈[ ]
and GA-DDHxbi(w0, ˆxU
bi, s−1
i
i,2) = 1 ∀i ∈[ ]
and GA-DDHxbi(w1, xU
i , ˆs−1
bi
i,3) = 1 ∀i ∈[ ]
74
SK := LH[P, ¯P, xP, ˆxP, x¯P, ˆx¯P, pwP¯P, σ]
75
else
76
SK ∈R SK
77
LH[P, ¯P, xP, ˆxP, x¯P, ˆx¯P, pwP¯P, (p, ˆp)] := SK
78
πt
P := ((p, ˆp), (P, ¯P, xP, ˆxP, x¯P, ˆx¯P), SK, true)
79
return true
Fig. 11. Adversary B2 against DSim-GA-StCDH for the proof of Theorem 1. Oracles
EXECUTE,REVEAL,CORRUPT and TEST are the same as in H5.

Compact Password Authenticated Key Exchange from Group Actions
245
For non-fresh instances, B2 must compute the correct session key. B2 checks
whether a correct shared value σ exists in LH as described above. If it exists, B2
assigns SK in LH to the session key (line 72). Otherwise, it chooses a session key
at random and add a irregular entry to LH, which contains the elements (p, ˆp)
instead of the shared value σ (line 77), to patch the query to the random oracle
H later. In the same way, for the case of the instance of U, it checks σ using the
secret group elements ui, ˆu0 and ˆu1 (lines 57 to 60) as follows:
σi,1 = GA-CDHxbi(xU
i , xS
i ) ⇔GA-CDHxbi(w0, xS
i ) = u−1
i
⋆σi,1,
σi,2 = GA-CDHxbi(ˆxU
bi, xS
i ) ⇔GA-CDHxbi(w1, xS
i ) = ˆu−1
bi ⋆σi,2,
σi,3 = GA-CDHxbi(xU
i , ˆxS
bi) ⇔GA-CDHxbi(w1, ˆxS
bi) = u−1
i
⋆σi,3,
In the query to the random oracle H, if the trace is contained in Ls which
means the corresponding instance was fresh when the SEND query was issued,
B2 checks if σ is valid using the GA-DDH oracle as described above (lines 18
and 29). If the shared value σ is valid, it checks whether the instance is fresh,
i.e., the password is not corrupted. If this is the case, it adds the query to Lbad
(lines 21 and 27). Otherwise, if the password was corrupted and is speciﬁed in
the query, it returns the session key stored in Ls (lines 23 and 29). After that,
it checks whether the queried entry matches the irregular entry added to LH
in the previous SEND query for a non-fresh instance, i.e., it must return the
same session key as returned previously. Then, for the matching entry, it uses
the GA-DDH oracle to check depending on whether it is an instance of U or an
instance of S (line 32 to 36).
After A guesses the β′, B2 chooses passwords for users that have not been
CORRUPT queried. Then, it checks whether badpw occurred (lines 05 to 13).
If badpw occurs, there must be two entries in Lbad for the same trace and
diﬀerent passwords pw ̸= pw′ along with values σ and σ′, and B2 answers to
DSim-GA-StCDH using these entries as follows: First, it compares the bits of the
two password bits from the beginning, and let i∗be the ﬁrst index where the bit
values are diﬀerent, i.e., bi∗̸= b′
i∗. Then, it assumes that bi∗= 0 and b′
i∗= 1,
but it swaps pw, σ and pw′, σ′ if the assignment is diﬀerent. Next, if the entries
in Lbad are those of an instance of U, B2 retrieves the ephemeral secret values
ui∗, ˆubi∗from Ls and sets y = xS
i∗, and outputs y and
y0 = u−1
i∗⋆σi∗,1 = GA-CDHx0(u−1
i∗⋆xU
i∗, xS
i∗) = GA-CDHx0(w0, xS
i∗),
y1 = ˆu−1
bi∗⋆σi∗,2 = GA-CDHx0(ˆu−1
bi∗⋆ˆxU
bi∗, xS
i∗) = GA-CDHx0(w1, xS
i∗),
y2 = u−1
i∗⋆σ′
i∗,1 = GA-CDHx1(u−1
i∗⋆xU
i∗, xS
i∗) = GA-CDHx1(w0, xS
i∗),
y3 = ˆu−1
b′
i∗⋆σ′
i∗,2 = GA-CDHx1(ˆu−1
b′
i∗⋆ˆxU
b′
i∗, xS
i∗) = GA-CDHx1(w1, xS
i∗).

246
R. Ishibashi and K. Yoneyama
Also, if the instance is an instance of S, B2 retrieves the ephemeral secret values
si∗, ˆsbi∗from Ls and sets y = xU
i∗, and outputs y and
y0 = s−1
i∗⋆σi∗,1 = GA-CDHx0(s−1
i∗⋆xS
i∗, xU
i∗) = GA-CDHx0(w0, xU
i∗),
y1 = ˆs−1
bi∗⋆σi∗,3 = GA-CDHx0(ˆs−1
bi∗⋆ˆxS
bi∗, xU
i∗) = GA-CDHx0(w1, xU
i∗),
y2 = s−1
i∗⋆σ′
i∗,1 = GA-CDHx1(s−1
i∗⋆xS
i∗, xU
i∗) = GA-CDHx1(w0, xU
i∗),
y3 = ˆs−1
b′
i∗⋆σ′
i∗,3 = GA-CDHx1(ˆs−1
b′
i∗⋆ˆxS
b′
i∗, xU
i∗) = GA-CDHx1(w1, xU
i∗).
This concludes the analysis of badpw. Thus, if badpw occurs, B2 can solve
DSim-GA-StCDH, i.e., Pr[H6 ⇒badpw] ≤AdvDSim-GA-StCDH
EGAT
(B2).
Second, we evaluate the probability of badguess. Note that badguess occurs
only if badpw does not occur. Thus, there is only one entry in Lbad for each
instance and the size of Lbad is at most qs. All instances were generated before
the corresponding password was chosen, thus
Pr[G6 ⇒badguess] ≤
qs
|PW|.
In H6, if none of the bad events occurs, all session keys output by TEST are
perfectly randomized. This gives A no information from the Test query, therefore
Adv(A, H6) = 1
2.
⊓⊔
References
1. Abdalla, M., Benhamouda, F., MacKenzie, P.: Security of the J-PAKE password-
authenticated key exchange protocol. In: IEEE Symposium on Security and Privacy
2015, pp. 571–587 (2015)
2. Abdalla, M., Eisenhofer, T., Kiltz, E., Kunzweiler, S., Riepel, D.: Password-
authenticated key exchange from group actions. In: Dodis, Y., Shrimpton, T. (eds.)
CRYPTO 2022. LNCS, vol. 13508, pp. 699–728. Springer, Cham (2022). https://
doi.org/10.1007/978-3-031-15979-4 24
3. Abdalla, M., Fouque, P.-A., Pointcheval, D.: Password-based authenticated key
exchange in the three-party setting. In: Vaudenay, S. (ed.) PKC 2005. LNCS, vol.
3386, pp. 65–84. Springer, Heidelberg (2005). https://doi.org/10.1007/978-3-540-
30580-4 6
4. Abdalla, M., Pointcheval, D.: Simple password-based encrypted key exchange pro-
tocols. In: Menezes, A. (ed.) CT-RSA 2005. LNCS, vol. 3376, pp. 191–208. Springer,
Heidelberg (2005). https://doi.org/10.1007/978-3-540-30574-3 14
5. Alamati, N., De Feo, L., Montgomery, H., Patranabis, S.: Cryptographic group
actions and applications. In: Moriai, S., Wang, H. (eds.) ASIACRYPT 2020. LNCS,
vol. 12492, pp. 411–439. Springer, Cham (2020). https://doi.org/10.1007/978-3-
030-64834-3 14
6. Azarderakhsh, R., Jao, D., Koziel, B., LeGrow, J.T., Soukharev, V., Taraskin, O.:
How not to create an isogeny-based PAKE. In: Conti, M., Zhou, J., Casalicchio, E.,
Spognardi, A. (eds.) ACNS 2020. LNCS, vol. 12146, pp. 169–186. Springer, Cham
(2020). https://doi.org/10.1007/978-3-030-57808-4 9

Compact Password Authenticated Key Exchange from Group Actions
247
7. Bellare, M., Pointcheval, D., Rogaway, P.: Authenticated key exchange secure
against dictionary attacks. In: Preneel, B. (ed.) EUROCRYPT 2000. LNCS, vol.
1807, pp. 139–155. Springer, Heidelberg (2000). https://doi.org/10.1007/3-540-
45539-6 11
8. Canetti, R., Dachman-Soled, D., Vaikuntanathan, V., Wee, H.: Eﬃcient password
authenticated key exchange via oblivious transfer. In: Fischlin, M., Buchmann, J.,
Manulis, M. (eds.) PKC 2012. LNCS, vol. 7293, pp. 449–466. Springer, Heidelberg
(2012). https://doi.org/10.1007/978-3-642-30057-8 27
9. Canetti, R., Halevi, S., Katz, J., Lindell, Y., MacKenzie, P.: Universally com-
posable password-based key exchange. In: Cramer, R. (ed.) EUROCRYPT 2005.
LNCS, vol. 3494, pp. 404–421. Springer, Heidelberg (2005). https://doi.org/10.
1007/11426639 24
10. Castryck, W., Decru, T.: An eﬃcient key recovery attack on SIDH (preliminary
version). IACR Cryptology ePrint Archive, Report 2022/975 (2022)
11. Castryck, W., Lange, T., Martindale, C., Panny, L., Renes, J.: CSIDH: an eﬃcient
post-quantum commutative group action. In: Peyrin, T., Galbraith, S. (eds.) ASI-
ACRYPT 2018. LNCS, vol. 11274, pp. 395–427. Springer, Cham (2018). https://
doi.org/10.1007/978-3-030-03332-3 15
12. Gennaro, R., Lindell, Y.: A framework for password-based authenticated key
exchange. In: Biham, E. (ed.) EUROCRYPT 2003. LNCS, vol. 2656, pp. 524–543.
Springer, Heidelberg (2003). https://doi.org/10.1007/3-540-39200-9 33
13. Groce, A., Katz, J.: A new framework for eﬃcient password-based authenticated
key exchange. In: ACM CCS 2010, pp. 516–525 (2010)
14. Haase, B., Labrique, B.: AuCPace: eﬃcient veriﬁer-based PAKE protocol tailored
for the IIoT. IACR TCHES 2019, 1–48 (2019)
15. Hao, F., Ryan, P.: J-PAKE: Authenticated key exchange without PKI. IACR Cryp-
tology ePrint Archive, Report 2010/190 (2010)
16. Jablon, D.P.: Strong password-only authenticated key exchange. Comput. Com-
mun. Rev. 26, 5–26 (1996)
17. Jao, D., De Feo, L.: Towards quantum-resistant cryptosystems from supersingular
elliptic curve isogenies. In: Yang, B.-Y. (ed.) PQCrypto 2011. LNCS, vol. 7071, pp.
19–34. Springer, Heidelberg (2011). https://doi.org/10.1007/978-3-642-25405-5 2
18. Katz, J., Vaikuntanathan, V.: Round-optimal password-based authenticated key
exchange. In: Ishai, Y. (ed.) TCC 2011. LNCS, vol. 6597, pp. 293–310. Springer,
Heidelberg (2011). https://doi.org/10.1007/978-3-642-19571-6 18
19. Soukharev, V., Hess, B.: PQDH: A Quantum-Safe Replacement for Diﬃe-Hellman
based on SIDH. IACR Cryptology ePrint Archive, Report 2019/730 (2019)
20. Steven, M., Bellovin, Merritt, M.: Encrypted key exchange: password-based proto-
cols secure against dictionary attacks. In: IEEE Computer Society Symposium on
Research in Security and Privacy 1992, pp. 72–84 (1992)
21. Taraskin, O., Soukharev, V., Jao, D., LeGrow, J.T.: An Isogeny-Based Password-
Authenticated Key Establishment Protocol. IACR Cryptology ePrint Archive,
Report 2018/886 (2018)
22. Terada, S., Yoneyama, K.: Password-based authenticated key exchange from stan-
dard isogeny assumptions. In: Steinfeld, R., Yuen, T.H. (eds.) ProvSec 2019. LNCS,
vol. 11821, pp. 41–56. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-
31919-9 3

Multi-key Homomorphic Secret Sharing
from LWE Without Multi-key HE
Peiying Xu1,2,3 and Li-Ping Wang1,2,3(B)
1 State Key Laboratory of Information Security, Institute of Information
Engineering, CAS, Beijing, China
{xupeiying,wangliping}@iie.ac.cn
2 State Key Laboratory of Cryptology, Beijing, China
3 School of Cyber Security, University of Chinese Academy of Sciences,
Beijing, China
Abstract. Homomorphic secret sharing (HSS) allows participants to
share their private data between computing servers for the joint computa-
tion of a public function without fully homomorphic encryption. It serves
as a competitive alternative to somewhat/fully homomorphic encryption
(S/FHE) in some scenarios. However, the existing HSS schemes capable
of computing on multi-source data either only support evaluating polyno-
mials whose degrees are limited by the number of participants, or involve
relatively complex multi-key HE in their constructions. In this paper, we
introduce the formal notion of multi-key HSS, and propose a multi-key
two-server HSS scheme from LWE without multi-key HE, by leveraging
the technique of homomorphic linear combination that was previously
used to construct multi-key FHE from GSW-FHE in [18]. As a result,
our scheme supports server-aided secure computation of restricted mul-
tiplication straight-line (RMS) programs over private data from multiple
independent sources, and the number of input clients and the degree of
evaluated polynomials can be as high as a polynomial in the security
parameter. Finally, we prove the security of the multi-key HSS scheme,
and demonstrate its implementation performance.
Keywords: Homomorphic secret sharing · Learning with errors ·
Nearly linear decryption · Homomorphic linear combination
1
Introduction
Homomorphic secret sharing (HSS), ﬁrst introduced by Boyle et al. [3], enables
multiple non-interactive parties to homomorphically evaluate a public function
in the setting of secret sharing without the use of somewhat/fully homomor-
phic encryption (S/FHE) [15,16,23]. More speciﬁcally, an (n, m)-HSS scheme
allows n input clients to secretly share their private data x1, . . . , xn among m
computing servers. Each server is able to locally evaluate a partial result upon
The authors gratefully acknowledge the anonymous reviewers for their valuable com-
ments and suggestions which improved the quality of this paper.
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 248–269, 2023.
https://doi.org/10.1007/978-3-031-35486-1_12

Multi-key Homomorphic Secret Sharing from LWE Without Multi-key HE
249
the computation task, and the ﬁnal result of the distributed computation can
be reconstructed by all partial results. Over recent years, HSS schemes designed
for some speciﬁc function classes, such as branching programs and general cir-
cuits, have emerged [3,5,7,12,13,24,25]. HSS can replace S/FHE to achieve the
same functionality in some scenarios, especially in secure multi-party computa-
tion (MPC), serving as a building block of some secure computation protocols
[1,2,8,17].
An attractive application of HSS is private outsourcing computation.
Although existing HSS schemes provide low-communication solutions to data
privacy issues in such scenarios, they do not work well in the context of joint
computation among multiple independent data sources. In the latter case, a
public evaluation task is issued by an output client, involving the private data
from a set of input clients. Since traditional encryption schemes (e.g., [3,13]) or
S/FHE schemes (e.g., [12]) are required as the underlying construction of HSS
schemes, a naive solution is to replace the underlying encryption schemes with
the corresponding multi-key versions. However, this would cause the extended
HSS schemes to remain at least as complex as their underlying multi-key encryp-
tion schemes and lose competitiveness compared to S/FHE. On the other hand,
Boyle et al. [5] proposed an HSS scheme from (R)LWE without S/FHE, which
is geared towards a competitive alternative to S/FHE. But it also focuses on the
single-key setting, and no natural multi-key extension exists. The trusted setup
is required in these HSS schemes to generate and distribute the same encrypted
public key to input clients when there is more than one input client, which is
a strong trust assumption. Till now, there is not yet a multi-key HSS scheme
tailored for private outsourcing computation with multi-source data. Motivated
by this gap, we manage to provide a feasible solution without complex crypto-
graphic primitives or assumptions.
1.1
Our Contributions
In this paper, we ﬁrst propose the formal deﬁnition of multi-key homomorphic
secret sharing (MKHSS), and instantiate an n-client two-server MKHSS scheme,
which is a multi-key extension of the HSS scheme in [5]. Our contributions are
as follows:
• We propose a modiﬁed version of the Regev encryption scheme. The crucial
diﬀerences are that the gadget vector is introduced in the ciphertext and the
last component of the secret key vector of the Regev scheme is disclosed. Also,
we prove the semantic security of our modiﬁed Regev scheme.
• We apply the homomorphic linear combination in [18] to our modiﬁed Regev
encryption. Speciﬁcally, we modify the original matrix-matrix combination
used for multi-key HE construction to a new combination of the matrix-
vector form. The result is a modiﬁed algorithm that combines an arbitrary
vector v and a modiﬁed Regev ciphertext C of a vector r ∈{0, 1}m into a
new “ciphertext” Clc under the d-dimension secret key s such that either
s · Clc ≈(q/p) · r · v or s · Clc ≈(q/p) · s[d] · r · v holds, where s[d] is the d-th
component of s.

250
P. Xu and L.-P. Wang
• Utilizing the above two key components, we implement a share conversion pro-
cedure without ciphertext inﬂation, and construct an MKHSS scheme for the
evaluation of Restricted Multiplication Straight-line (RMS) programs, where
each client’s private input is independently shared and homomorphically cal-
culated between two non-colluding servers. The number of input clients and
the degree of evaluated polynomials can be as high as a polynomial in the
security parameter. Compared with HSS in [5], the extension only addition-
ally consumes tolerable resources in terms of each client’s input share and the
server’s computational times. To the best of our knowledge, this is the ﬁrst
attempt to construct multi-key HSS without using multi-key HE.
1.2
Related Work
The original (1, 2)-HSS scheme was proposed by Boyle et al. [3], which combines
a threshold version of ElGamal with linear secret sharing to allow a compact
evaluation of branching programs on input shares under the DDH assumption.
However, a non-negligible error probability was introduced into the scheme due
to the local share conversion algorithm, and could be further eased by servers
with increasing their operating times.
Subsequently, Fazio et al. [13] extended the result in [3] and further con-
structed a (1, 2)-HSS scheme for branching programs based on the circular secu-
rity of the Paillier encryption scheme. Besides, the scheme optimizes the former
work by applying the “Las Vegas”-style share conversion protocols [4] as an alter-
native, which reduces the number of repetitions required to reach a reasonable
overall error bound.
Based on the framework of HSS in [3], a (1, 2)-HSS construction from
(R)LWE without S/FHE was proposed by Boyle et al. [5] and can be instantiated
by any encryption scheme with nearly linear decryption property. Compared to
the previous DDH-based schemes [3,13], this construction supports secure eval-
uation for the class of polynomial-size branching programs with a negligible
error probability and superpolynomial-size plaintext space. Moreover, it oﬀers
cheaper homomorphic multiplications, a simpler setup procedure and no noise
growth over S/FHE-based solutions for the same program class [1,11].
Chen et al. [7] introduced a veriﬁcation process into [5] to propose a two-
server veriﬁable HSS model, which aims to ensure the correctness of evaluation
in the scenarios of outsourcing computation. Similarly, it supports the calculation
of a function with the degree as high as a polynomial in security parameter.
The above schemes [3,5,7,13] are applicable to evaluating branching pro-
grams on multiple private inputs under the two-server model. Essentially, they
are (1, 2)-HSS schemes, in other words, single-key HSS schemes. That is, the
same key is required by multiple parties to generate corresponding input shares
supporting subsequent calculations from their private data. Due to the under-
lying encryption schemes (e.g., ElGamal( [14]), Paillier( [10]), LPR( [19]) etc.)
and speciﬁc share conversion procedures involved in the construction of these
HSS schemes, there is no natural extension to multi-key HSS schemes.

Multi-key Homomorphic Secret Sharing from LWE Without Multi-key HE
251
Lai et al. [12] relied on arbitrary degree-k homomorphic encryption scheme
to construct a (1, m)-HSS scheme for evaluations of polynomials with degree
(k + 1)m −1, which mainly adopted the idea of [6]. Their construction can
be naturally extended to any (n, m)-HSS under the multi-key setting by simply
replacing the HE schemes with multi-key ones. However, the complexity of multi-
key evaluations additionally depends on the multi-key S/FHE schemes involved,
leading to no signiﬁcant advantage in terms of eﬃciency over the multi-key
S/FHE schemes. And the maximum degree of polynomials that can be evaluated
depends on the underlying encryption scheme and the number of computing
servers.
Tsaloli et al. [24] presented an instantiation of an n-client m-server multi-
plicative veriﬁable HSS scheme for multiplications of n (n ≤m) elements under
the hardness assumption of the ﬁxed inversion problem in bilinear maps. The
scheme inherently allows evaluations on data from diﬀerent sources and the cor-
rectness of results can be publicly veriﬁed. In addition, only multiplications can
be performed and hence the scheme is only available for limited application
scenarios.
Both [12] and [24] are (n, m)-HSS schemes and can inherently realize the
joint calculation of polynomials on multi-party private data without the share
generation under the common key. Nevertheless, they suﬀered from restricted
computing functions or the expensive computation overhead of high-degree poly-
nomials, resulting in their lack of ﬂexibility and being only applicable to limited
outsourcing computing scenarios.
1.3
Organization
In Sect. 2 we introduce some notations and techniques that will be used in our
construction. The formal deﬁnition of MKHSS is given in Sect. 3. Section 4 con-
tains the detailed construction and analysis of our MKHSS. In Sect. 5 we present
both implementation and performance analysis of our scheme. Finally, we draw
conclusions in Sect. 6.
2
Preliminaries
Denote with λ ∈N a security parameter, and use poly(λ) to denote any function
bounded by a polynomial in λ. Address any negligible function in λ with negl(λ).
O and ω denote asymptotic upper bound and non-asymptotically tight below
bound respectively.
Denote column-vectors by bold lower-case letters and matrices by bold upper-
case letters. For an l-dimensional vector a and i ∈{1, . . . , l}, a[i] refers to the
i-th component of a. For a distribution χ, r
$←χ means that r is chosen from χ
uniformly at random. For a real number x ∈R, by ⌊x⌉∈Z denote the element
closest to x, and by |x| refer to the length of x. For a positive integer n, [n] denotes
the set {1, . . . , n}. The inner product between two vectors is denoted by ⟨a, b⟩.
For a matrix X, X⊤denotes the transpose of X. Let A[i, ·] be the i-th row of

252
P. Xu and L.-P. Wang
the matric A and A[·, j] the j-th column. For matrices A and B, [A∥B] denotes
the concatenation of A with B. For B ∈N, deﬁne [Z]B := {x ∈Z|x ≤B}.
2.1
HSS from Encryption with Nearly Linear Decryption
Our construction of MKHSS is mainly based on the HSS scheme in [5], which
supports the calculation of RMS programs over secret shares generated under
the same key. The core technique is a public-key encryption with nearly linear
decryption, which satisﬁes two key properties: encrypts certain key-dependent
messages without the knowledge of the secret key; and distributively decrypts a
ciphertext. Here is a brief review of this scheme.
The HSS scheme is parameterized by p, q, Bsk, Bct ∈N, subject to p|q, p ≥
λω(1), q/p ≥λω(1) and Bsk, Bct ≤poly(λ). Set a ring R = Z[X]/(XN + 1).
Rq := R/qR and Rp := R/pR are two quotient rings, where N is a power of 2.
The secret key s satisﬁes ∥s∥∞≤Bsk, and the error e satisﬁes ∥e∥∞≤Bct.
Deﬁnition 1 (Encryption scheme with nearly linear decryption). Let
PKE := (PKE.Gen, PKE.Enc, PKE.Dec) be a public-key encryption scheme with
pseudorandom ciphertexts and parameterized by (p, q, d, Bsk, Bct, R). PKE sat-
isﬁes the property of nearly linear decryption if for any (pk, s) in the image of
PKE.Gen(1λ) where s is of the form (1,ˆs) for some ˆs ∈Rd−1
p
, for any message
m ∈Rp and for any ciphertext c ∈Rd
q in the image of PKE.Enc(pk, m), it
further holds ⟨s, c⟩= (q/p) · m + e mod q.
Deﬁnition 2 (KDM oracle).
Let PKE be a public-key encryption scheme
with nearly linear decryption as deﬁned above. There exists a PPT algorithm
PKE.OKDM:
– ˆci ←PKE.OKDM(pk, m, i): On input a public key pk, a value m ∈R and
a sequence number i ∈{1, . . . , d}, the algorithm computes and outputs a
ciphertext ˆci := (q/p) · m · ui + c mod q, where (pk, s) ←PKE.Gen(1λ),
c ←PKE.Enc(pk, 0) and the i-th unit vector ui ∈Rd
q.
PKE.OKDM returns the componentwise encryption of m · s without access
to the secret key, serving as a key-dependent message oracle. And the following
properties are required:
Nearly linear decryption to the message m·si: For any ciphertext ˆci ∈Rd
q
in the image of PKE.OKDM(pk, m, i), it holds that ⟨s, ˆci⟩= (q/p)·(m·si)+e
mod q.
Security: For any PPT adversary A, the advantage of A winning holds that
Advkdm−ind
PKE.OKDM,A(λ) :=

P r
⎡
⎣A(pk) = β

(pk, sk) ←P KE.Gen(1λ),
β ←{0, 1},
β′ ←AOKDM (·,·)(pk)
⎤
⎦−1
2

≤negl(λ),
where the oracle OKDM(m, i) is deﬁned as follows: if β = 0, it returns
PKE.OKDM(pk, m, i); else, it returns PKE.Enc(pk, 0).

Multi-key Homomorphic Secret Sharing from LWE Without Multi-key HE
253
Deﬁnition 3 (Distributed decryption of ciphertexts). Let PKE be a
public-key encryption scheme with nearly linear decryption as deﬁned above.
There exists a deterministic polynomial time algorithm PKE.DDec:
– ˆtb ←PKE.DDec(b ∈{0, 1}, tb, c): On input an index b ∈{0, 1}, a share
tb ∈Rd
q and a ciphertext c ∈Rd
q, the algorithm computes and outputs a
result ˆtb := ⌊(p/q) · (tb · c)⌉mod p mod q.
Lemma 1 (Distributed decryption of sums of ciphertexts [5]). Let PKE
be a public-key encryption scheme with nearly linear decryption as deﬁned above.
For all x ∈Rp, for t0, t1
$←Rd
q subject to t0+t1 = x·s mod q, for Badd ∈N, for
all messages m1, . . . , mBadd ∈Rp with m := Badd
i=1 mi, and for all ciphertexts ci
of mi with c := Badd
i=1 ci, it holds that PKE.DDec(0, t0, c)+PKE.DDec(1, t1, c) =
x · m mod q with probability of at least 1 −N · (N · Badd · ∥x∥∞· Bct · p/q + ∥x ·
m∥∞/p + p/q + 1/p) ≥1 −λ−ω(1).
2.2
RMS Programs
Next, we introduce the Restricted Multiplication Straight-line (RMS) program,
which is the computational model applied in [5]. It is a class of programs that
captures all branching programs in particular logarithmic space computations
and logarithmic depth circuits. And it can actually compute all functions.
Deﬁnition 4 (RMS programs [9]). An RMS program is an arbitrary sequence
of the ﬁrst four of the following instructions bounded by Bmax and terminates
with an output instruction:
load : Load an input ai as a memory value: bi (id, bi ←ai);
add1 : Add memory values bi and bj (id, bk ←bi + bj);
add2 : Add input values ai and aj: (id, ak ←ai + aj);
mult : Multiply memory value bi by input ai: (id, bk ←ai · bi);
output : Output memory value bk: (id, ˆOj ←bk).
All instructions above are sorted according to a unique identiﬁer id ∈Sid. During
execution, the size of an intermediate computation value at any step remains
“small” and is bounded by Bmax, i.e. ∥b∥∞≤Bmax, otherwise the program
terminates and outputs ⊥. As in [5], the maximum number of additions on input
values is also denoted by Pinp+.
3
Multi-key Two-Server Homomorphic Secret Sharing
In this section, we present the notion of multi-key homomorphic secret sharing
in plain model. Our system consists of: a set of input clients, two computing
servers and an output client. Note that our system model strictly requires that
the output client cannot play the role of the input client, especially in the context
of computations involving only two variables from two diﬀerent input clients.

254
P. Xu and L.-P. Wang
Deﬁnition 5 (Multi-key Homomorphic Secret Sharing (MKHSS)). An
n-input (1-output) 2-server multi-key homomorphic secret sharing scheme
MKHSS = (Gen, Share, Eval, Rec) for a class of programs P over Z with input
space I ⊆Z consists of the following PPT algorithms/protocols:
– (pk, sk) ←Gen(1λ): On input the security parameter 1λ, the key generation
algorithm outputs a public key pk and a secret key sk.
– (s(0)
i , s(1)
i ) ←Share(i, pk, sk, x): Given an input index i ∈[n], a public key pk,
a secret key sk, and a value x ∈I, the sharing algorithm outputs a pair of
input shares (s(0)
i , s(1)
i ).
– yb ←Eval(b, P, {s(b)
i }i∈[n], r): The server Sb executes the evaluation protocol
on inputs an index b ∈{0, 1}, a program P ∈P with n input values, the corre-
sponding tuple of shares {s(b)
i }i∈[n], and an integer r ≥2. Upon termination,
the server Sb outputs the corresponding output share yb.
– y ←Rec(y0, y1): On input a pair of output shares (y0, y1), the reconstruction
algorithm outputs the result y of the evaluation.
MKHSS should satisfy the following correctness, security and context hiding:
Correctness. The correctness of a multi-key HSS scheme ensures that the out-
puts originate from honest computing servers can be reconstructed to the accu-
rate computing results.
Deﬁnition 6 (Correctness). An n-input 2-server multi-key HSS scheme for
a class of programs P is correct if for any security parameter λ ∈N, for any n-
tuple of inputs (x1, . . . , xn) ∈In, for any program P ∈P with size |P| ≤poly(λ)
and P(x1, . . . , xn) ̸= ⊥, for any integer r ≥2, for ∀i ∈[n], (pki, ski) ←Gen(1λ)
and (s(0)
i , s(1)
i ) ←Share(i, pki, ski, xi) it holds that
Prcor
MKHSS,{xi}i∈[n],P,r(λ) := Pr[y0 + y1 = P (x1, . . . , xn)
mod r] ≥1 −negl(λ),
where yb ←Eval(b, P, {s(b)
i }i∈[n], r) for b ∈{0, 1}. The scheme is perfectly correct
if the above probability is exactly 1. Further, if there exists a polynomial θ(·), such
that |yb| ≤θ(λ), the multi-key HSS scheme is compact.
Security. The security of a multi-key HSS scheme guarantees that no informa-
tion about private inputs is disclosed to any individual server. It preserves the
privacy of input clients against computing servers.
Deﬁnition 7 (Security). An n-input 2-server multi-key HSS scheme is secure
if for any security parameter λ ∈N, there exists a negligible function negl(λ)
such that for any PPT adversary A that on input 1λ output a bit b ∈{0, 1}, and
x0, x1 ∈I, the advantage of A holds that
Advsec
MKHSS,A(λ) :=

Pr
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
A(inputb) = β

(b, x0, x1, state)
←A(1λ),
β ←{0, 1},
(pk, sk) ←
MKHSS.Gen(1λ),
(s(0)
i
, s(1)
i
) ←
MKHSS.Share
(i, pk, sk, xβ),
inputb := (state, pk, s(b)
i
)
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
−1
2

≤negl(λ).

Multi-key Homomorphic Secret Sharing from LWE Without Multi-key HE
255
Context Hiding. Context hiding assures that the output client learns nothing
beyond the result of evaluation, which preserves the privacy of input clients
against the output client. And this property makes sense for our system model,
where the output client is actually diﬀerent from the input clients.
Deﬁnition 8 (Context Hiding). An n-input 2-server multi-key HSS scheme
is context-hiding if for any security parameter λ ∈N, for any program P ∈P
with size |P| ≤poly(λ) and P(x1, . . . , xn) ̸= ⊥, there exists a negligible function
negl(λ) and a PPT simulator S such that for any PPT adversary A that on
input 1λ output x1, . . . , xn ∈I, the advantage of A holds that
Advch
MKHSS,S,A(λ) :=

Pr
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
A(inputβ) = β

(x1, . . . , xn, r, state) ←A(1λ),
β ←{0, 1},
(pki, ski) ←
MKHSS.Gen(1λ)∀i ∈[n],
ifβ = 0, (s(0)
i
, s(1)
i
) ←
MKHSS.Share
(i, pki, ski, xi)∀i ∈[n],
∧y(j)
0
←MKHSS.Eval
(j, P, {s(j)
i
}i∈[n], r)∀j ∈{0, 1};
else, (y(0)
1
, y(1)
1
) ←
S(1λ, P (x1, . . . , xn), r),
inputβ := (state, (y(0)
β
, y(1)
β
))
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
−1
2

≤negl(λ).
4
The Construction of Multi-key HSS
Inspired by [5], we now present our n-input (1-output) 2-server multi-key homo-
morphic secret sharing scheme MKHSS for a class of RMS programs P. We ﬁrst
modify the Regev encryption scheme, by which each input client generates a pair
of shares for individual private input and distributes the input shares between
two computing servers. Then by leveraging the technique of homomorphic linear
combination in [18], we show a method for the computing servers to evaluate a
function over inputs from all input clients with diﬀerent keys. Finally, the output
client reconstructs the evaluation result from partial results returned by both
servers.
4.1
The Modiﬁed Regev Encryption
To construct our multi-key HSS scheme, we present a modiﬁed version of the
standard Regev encryption [22] in which: (1) the gadget vector g⊤is introduced
in the ciphertexts, and (2) the last component of the secret key is public.
We claim that for l := ⌊log q⌋+ 1, the gadget vector g⊤= (1, 2, . . . , 2l−1)
and the function g−1 : Zq →Zl such that x ←g−1(u) is subgaussian with O(1)
and satisﬁes ⟨g, x⟩= u, as introduced in [20].
The modiﬁed Regev encryption scheme consists of the following PPT algo-
rithms MRegev = (Setup, KGen, Enc, Dec):

256
P. Xu and L.-P. Wang
– MRegev.Setup(1λ) →params: On the security parameter λ, choose the mod-
ulus value q, the lattice dimension d, the secret-key distribution χsk and the
error distribution χ. Let m = O(d log q) be the number of LWE instances.
The setup algorithm outputs params = (q, d, m, χsk, χ).
– MRegev.KGen(params) →(pk, sk): Sample A
$←Zm×(d−1)
q
, ˆs
$←χd−1
sk
and
e
$←χm. Compute b = A · ˆs + e mod q. Set s = (1,ˆs) and P = [b∥−A] ∈
Zm×d
q
. The key generation algorithm outputs a secret key sk = s and a public
key pk = (P, s[d]).
– MRegev.Enc(pk, μ, i ∈{0, 1}) →C: Given a message μ ∈Zp, if the index
i = 0, let M⊤=

μ 0 · · · 0
0 0 · · · 0

∈Z2×d
p
; else, let M⊤=

0 · · · 0 0
0 · · · 0 μ

∈Z2×d
p
.
Sample R
$←{0, 1}m×2l. The encryption algorithm outputs a ciphertext C =
P⊤R + (q/p)M ⊗g ∈Zd×2l
q
.
– MRegev.Dec(sk, C, i ∈{0, 1}) →μ: Given a ciphertext C ∈Zd×2l
q
, if the index
i = 0, set u = ⌊q
p⌋−1 mod q, and deﬁne a vector u⊤= (g−1(u), 0, · · · , 0)
∈Z2l
q ; else, set u = (⌊q
p⌋s[d])−1 mod q, and deﬁne a vector u⊤= (0, · · · , 0,
g−1(u)) ∈Z2l
q . Compute and output the decrypted message μ = sk · C · u.
Correctness of Decryption. In the case of the index i = 1, we have
μ = sk · C · u = (1, ˆs)(
	
b
−A

R + (q/p)
	
0 · · · 0 0
0 · · · 0 μ

⊤
⊗g)(0, · · · , 0, g−1(u))⊤
= e · R(0, · · · , 0, g−1(u))⊤+ (q/p)(1, ˆs)(0, · · · , 0, μ · u)⊤
≈(q/p)s[d] · μ · u
≈μ.
Also, in the case of the index i = 0, the correctness of decryption is held by the
same token.
⊓⊔
Before giving a security proof of the modiﬁed Regev encryption scheme, we
introduce the following lemma.
Lemma 2 ([22]).
Let
the
LWEn,q,χ
assumption
holds
with
params
=
{n, q, χ, m}. Then, for m = O(n log q), R
$←{0, 1}m×2l, and P as generated
above, the joint distribution (P⊤, P⊤R) is computational indistinguishable from
uniform over Zd×m
q
× Zd×2l
q
.
Then the semantic security of the above scheme is summarized in the follow-
ing theorem.
Theorem 1. The above modiﬁed Regev encryption scheme MRegevq,d,m,χsk,χ is
semantically secure if the Regevq,d−1,m,χsk,χ encryption scheme is secure.
With the limitation in space, here we give the sketch of the proof.
Proof. First, we deﬁne another encryption scheme MRegev′, where the only
diﬀerence from Regev is that its encryption algorithm MRegev′.Enc outputs

Multi-key Homomorphic Secret Sharing from LWE Without Multi-key HE
257
C = P⊤R+(q/p)M⊗g as that in MRegev.Enc. Due to the columns of P⊤R are
simply Regev encryptions of 0 for dimension d, the semantic security of MRegv′
follows directly from Lemma 2. Thus, MRegev′
q,d,χsk,χ is semantically secure if
Regevq,d,χsk,χ is.
Then we deﬁne MRegev′′, the encryption scheme which is almost the same as
MRegev′ except that: (1) its public key contains an additional vector a randomly
chosen from Zm
q , i.e. pk = (P, a); and (2) its encryption algorithm MRegev′′.Enc
outputs C = P⊤R + (q/p)M ⊗g along with C′ = a⊤R. Obviously, the distri-
bution of a⊤R is statistically indistinguishable with the uniform distribution.
Therefore, MRegev′′
q,d,m,χsk,χ is semantically secure if MRegev′
q,d−1,m,χsk,χ is.
Now suppose there exists a PPT adversary A which breaks the secu-
rity of MRegevq,d,m,χsk,χ with non-negligible advantages ϵ, another PPT adver-
sary B against the semantic security of MRegev′′
q,d,m,χsk,χ with non-negligible
advantages 1
2ϵ can be constructed as follows. The challenger C participates in
the challenge game of MRegev′′ and receives the parameters {q, d, m, χsk, χ}
along with the public key (P, a) = ([b∥−A], a) which are forwarded to A.
A chooses an arbitrary vector s′ ∈χsk and correctly yields a public key
P′ = [b+a⊤·s′∥−A∥−a] ∈Zm×d
q
. A then sends the parameters {q, d, m, χsk, χ},
P′ and s′ to B. B randomly chooses two distinct messages m0,m1 ∈Zq such that
m0 ̸= m1 and returns them to A. A transfers the two messages to C. C randomly
chooses a bit b ∈{0, 1} and encrypts mb as (C, C′) and ( ˆC, C′) by invok-
ing MRegev′′.Enc, where C = MRegev′′.Enc(P, mb, 0) = P⊤R + (q/p)Mb ⊗g,
ˆC = MRegev′′.Enc(P, mb, 1) = P⊤R + (q/p)M′
b ⊗g and C′ = a⊤R. The
ciphertexts are forwarded to B. B randomly chooses a bit b′ ∈{0, 1}, sets
C[1, ·] = C[1, ·] + s′C′ and ˆC[1, ·] = ˆC[1, ·] + s′C′. B returns C∗=

C
C′

and
ˆC∗=

ˆC −(q/p)M′
b′ ⊗g
C′ + (q/p)[0∥mb′] ⊗g

to A. Finally, B feedbacks A’s output to the
challenger.
By construction above, if b′ = b, B simulates the MRegev′′ game for A faith-
fully, i.e. the ciphertexts forwarded to A are identical to that in MRegev. Thus,
the success probability of B is identical to that of A breaking the security of
MRegev. Else, if b′ ̸= b, the probability of B winning is at least 1
2 in that the
ciphertexts obtained by A are not correctly generated. Thus,
Pr[B
wins] = Pr[B
wins|b′ = b] + Pr[B
wins|b′ ̸= b]
≥1
2 Pr[A
wins] + 1
2 × 1
2 = 1
2 × ( 1
2 + ϵ) + 1
2 × 1
2 = 1
2 + 1
2 ϵ.
Consider the security of MRegev′′, we conclude that the advantage of A winning
is negligible.
⊓⊔
4.2
The Homomorphic Linear Combination for the Modiﬁed Regev
Encryption
We leverage the idea of homomorphic linear combination for the construction of
multi-key HE in [18], which is a generalization of that in [21], to design a simi-
lar homomorphic operation for the modiﬁed Regev encryption proposed above.

258
P. Xu and L.-P. Wang
Precisely, we modify the homomorphic linear combination of matrix-matrix to
that of matrix-vector, which becomes another key component in our main con-
struction.
The polynomial-time deterministic algorithms MRegev.HLC describes the
homomorphic linear combination for the modiﬁed Regev encryption, and is
deﬁned as follows:
– MRegev.HLC({C(j)}j∈[m], v, i ∈{0, 1}) →t: On input a sequence of MRegev
ciphertexts {C(j)}j∈[m] and an arbitrary vector v ∈Zm
q , if the given index
i = 0, set v(j) = (g−1(v[j]), 0, · · · , 0) ∈Z2l
q for j ∈[m]; else, set v(j) =
(0, · · · , 0, g−1(v[j])) ∈Z2l
q for j ∈[m]. Compute t = m
j=1 C(j)v(j). The
combined output is t.
Theorem 2. For j ∈[m], let T(j) ∈Zd×2l
q
be a ciphertext of MRegev.Enc(pk,
r[j], 0) under a secret key s, and ˆT(j) ∈Zd×2l
q
be a ciphertext of MRegev.Enc(pk,
r[j], 1) under the same s, where r ∈{0, 1}m. Let tlc ←MRegev.HLC({T(j)}j∈[m],
v, 0) and ˆtlc ←MRegev.HLC({ˆT(j)}j∈[m], v, 1). Then s · tlc ≈(q/p) · r · v and
s · ˆtlc ≈(q/p) · s[d] · r · v are satisﬁed respectively.
Proof. In the case of the index i = 1, we have
s · ˆtlc = (1, ˆs) ·
m

j=1
ˆT(j)v(j)
=
m

j=1
(1, ˆs) · (P⊤R + (q/p)
	
0 · · · · · ·
0
0 · · ·
0
r[j]

⊤
⊗g)(0, · · · , 0, g−1(v[j]))⊤
=
m

j=1
eR(0, · · · , 0, g−1(v[j]))⊤+ (q/p)
m

j=1
s[d] · r[j] · v[j]
≈(q/p) · s[d] · r · v.
Similarly, the proof for the other case, i.e. the index i = 0, can be easily obtained
by the same way.
⊓⊔
4.3
Our Construction
Our construction of multi-key HSS scheme takes advantage of the idea of homo-
morphic linear combination from [18] and the nearly linear decryption property
in Regev encryption. It extends the single-key HSS in [5] to an HSS scheme
applicable to independent multi-client scenarios. Our construction supports 5
homomorphic RMS program instructions. Now we present the main construc-
tion of the multi-key HSS in details.
MKHSS.Gen(1λ):
– Invoke params ←MRegev.Setup(1λ).
– Invoke (pk, sk) ←MRegev.KGen(params) and output the key pair (pk, sk).

Multi-key Homomorphic Secret Sharing from LWE Without Multi-key HE
259
MKHSS.Share(k, pkk, skk, x):
– Parse skk = sk := (1,ˆsk) ∈Zq × Zd−1
q
and pkk = (Pk, sk[d]) := ((bk||−Ak),
sk[d]) ∈Zm×d
q
× Zq.
– Draw a PRF key Kk ←K.
– Choose ek(0)
k
←Zd
q at random. Deﬁne ek(1)
k
:= skk −ek(0)
k
mod q.
– For j ∈[d], compute c(x,j)
k
←Regev.OKDM(pkk, x, j) ∈Zd
q, where the random
vector used for j-th encryption is r(j)
k
∈{0, 1}m and ej ∈Zd
q is the j-th unit
vector. The encryption of input x is C(x)
k
= {c(x,j)
k
}j∈[d] ∈Zd×d
q
.
– For i ∈[d] and j ∈[m], invoke T(i,j)
k
←MRegev.Enc(pkk, r(i)
k [j], 0), where
R(i,j)
k
= [R(i,j′)
k
||R(i,j′′)
k
] ∈{0, 1}m×l × {0, 1}m×l is the randomly chosen
matrix used for each encryption. Also invoke ˆT(i,j)
k
←MRegev.Enc(pkk, r(i)
k [j],
1), where R(i,j′′′)
k
∈{0, 1}m×l and the random matrix used for each encryption
ˆR(i,j)
k
= [R(i,j′′′)
k
||R(i,j′)
k
].
– Obtain a pair of input shares s(b)
k
:= (ek(b)
k , Kk, C(x)
k , {T(i,j)
k
, ˆT(i,j)
k
}i∈[d],j∈[m])
for b ∈{0, 1}.
MKHSS.Eval(b, {pki}i∈[n], P, {s(b)
i }i∈[n], r):
For i ∈[n]:
– Parse pki = (Pi, si[d]) := ((bi||−Ai), si[d]) and s(b)
i
:= (ek(b)
i , Ki, C(x)
i
,
{T(k,j)
i
, ˆT(k,j)
i
}k∈[d],j∈[m]). For l ∈[m], compute z(l)
i
= 
j∈[n]\{i}(bj[l] −
bi[l])δ, where δ =
p
q 
j∈[n] (sj[d]−1). zi := (z(1)
i
, . . . , z(m)
i
) ∈Zm
q .
– For k ∈[d], invoke t(k)
i
←MRegev.HLC({T(k,j)
i
}j∈[m], zi, 0) and ˆt(k)
i
←
MRegev.HLC({ˆT(k,j)
i
}j∈[m], zi, 1).
– For j ∈[d], compute c(x,j) = c(x,j)
i
−t(j)
i
+ ˆt(j)
i . The extended input share is
C
(x) = {c(x,j)}j∈[d] ∈Zd×d
q
and the corresponding extended evaluation key
ekb = 
i∈[n] ek(b)
i .
– Parse P as a sequence of RMS operations and proceed as follows:
(1) Load upon instruction (id, C
(x)): compute t(x,j)
b
:= MRegev.DDec(b, ekb,
c(x,j)) + (1 −2b) · n
i=1 PRF(Ki, id) mod q for j ∈[d]. Then the compo-
nentwise memory value t(x)
b
:= {t(x,j)
b
}j∈[d] ∈Zd
q.
(2) Add1 upon instruction (id, t(x)
b , t(x′)
b
): compute t(x+x′)
b
←t(x)
b
+ t(x′)
b
+
(1 −2b) · n
i=1 PRF(Ki, id) mod q.
(3) Add2 upon instruction (id, C
(x), C
(x′)): compute C
(x+x′) ←C
(x) + C
(x′)
mod q.
(4) Mult upon instruction (id, t(x)
b , C
(x′)): for j ∈[d], compute t(x·x′,j)
b
:=
MRegev.DDec(b, t(x,j)
b
, c(x′,j)) + (1 −2b) · n
i=1 PRF(Ki, id) mod q. Then
the componentwise product t(x·x′)
b
:= {t(x·x′,j)
b
}j∈[d] ∈Zd
q.

260
P. Xu and L.-P. Wang
(5) Output over Zr upon instruction (id, t(x)
b ): parse t(x)
b
:= (xb,ˆt(x)
b ) for some
xb ∈Zq and ˆt(x)
b
∈Zd−1
q
. Output yb = xb
n
mod r.
MKHSS.Rec(y0, y1):
– Output the computing result of P as y = y0 + y1.
Let PRF : K × Sid →Zd
q be a pseudorandom function. The scheme is param-
eterized by module values q, p ∈N, an integer lattice dimension d, the number
of LWE instances m, and distributions χsk over Zp and χ over Z bounded by
Bsk and Berr respectively, where p|q, q/p ≥λω(1) and d, m ≤poly(λ). The noise
bound Bct ≤poly(λ). Let Binp ∈N with p/Binp ≥λω(1) and q/(Binp·p) ≥λω(1).
Theorem 3. The scheme MKHSS = (Gen, Share, Eval, Rec) given above is an n-
input 2-server multi-key homomorphic secret sharing scheme with input space
[Z]Binp for the class of RMS programs with magnitude bound Bmax, where
p/Bmax ≥λω(1) and q/(Bmax · p) ≥λω(1). More precisely, our MKHSS satisﬁes:
– Correctness. For any λ ∈N, for any x1, . . . , xn ∈[Z]Binp, for any
polynomial-sized RMS program P with P(x1, . . . , xn) ̸= ⊥and magni-
tude bound Bmax, and P has maximum number of input addition instruc-
tions Pinp+, for any integer 2
≤
r
≤
Bmax
≪
p, it holds that
Prcor
MKHSS,{xi}i∈[n],P,r(λ) ≥1 −negl(λ).
– Security. For any PPT adversary A, the advantage of A winning holds that
Advsec
MKHSS,A(λ) ≤negl(λ).
– Context Hiding. For any PPT adversary A, there exists a PPT simulator
S such that Advch
MKHSS,S,A(λ) ≤negl(λ).
Obviously, our MKHSS scheme is mainly constructed from the modiﬁed
Regev scheme with the properties of homomorphic linear combination and nearly
linear decryption. Next we give the proof of Theorem 3.
Lemma 3 (Nearly Linear Decryption for Extended Ciphertext).
Let
C
(x) = {c(x,j)}j∈[d] = {c(x,j)
k
−tk + ˆtk}j∈[d] ∈Zd×d
q
be the extended input share
which corresponds to the k-th client’s input, and ekb = 
i∈[n] ek(b)
i
∈Zd
q for
b ∈{0, 1} the corresponding extended evaluation key evaluated in MKHSS.Eval,
then we have C
(x) is a valid ciphertext satisfying nearly linear decryption under
the secret key (ek0 + ek1).
Proof. For j ∈[d],
⟨ek0 + ek1, c(x,j)⟩= ⟨

i∈[n]
(ek(0)
i
+ ek(1)
i
), c(x,j)⟩
= ⟨

i∈[n]
ski, c(x,j)
k
−t(j)
k
+ ˆt(j)
k ⟩,

Multi-key Homomorphic Secret Sharing from LWE Without Multi-key HE
261
where by Theorem 2
⟨skk, c(x,j)
k
−t(j)
k
+ ˆt(j)
k ⟩= ⟨skk, c(x,j)
k
⟩−⟨skk, t(j)
k ⟩+ ⟨skk,ˆt(j)
k ⟩
= q
p x · sk[j] + q
p (sk[d] −1) · r(j)
k
· zk + ek
can be directly deduced. Then consider for i ∈[n]\{k}
⟨ski, c(x,j)
k
−t(j)
k
+ ˆt(j)
k ⟩= ⟨ski, c(x,j)
k
⟩−⟨ski, t(j)
k ⟩+ ⟨ski,ˆt(j)
k ⟩
= q
p x · si[j] + q
p (si[d] −1) · r(j)
k
· zk + (bk −bi) · r(j)
k
+ ei,
holds due to

l∈[m]
R(j,l)
k
(g−1(v[j]), 0, · · · , 0)⊤=

l∈[m]
ˆR(j,l)
k
(0, · · · , 0, g−1(v[j]))⊤
where R(j,l)
k
= [R(j,l′)
k
||R(j,l′′)
k
] and ˆR(j,l)
k
= [R(j,l′′′)
k
||R(j,l′)
k
] as deﬁned in
MKHSS.Share and ei is a small noise for i ∈[n].
Obliviously,
⟨ek0 + ek1, c(x,j)⟩= ⟨

i∈[n]
(ek(0)
i
+ ek(1)
i
), c(x,j)⟩
=

i∈[n]
⟨ski, c(x,j)
k
−t(j)
k
+ ˆt(j)
k ⟩
= ⟨skk, c(x,j)
k
−t(j)
k
+ ˆt(j)
k ⟩+

i∈[n]\{k}
⟨ski, c(x,j)
k
−t(j)
k
+ ˆt(j)
k ⟩
= q
p x · sk[j] + q
p (sk[d] −1) · r(j)
k
· zk + ek
+

i∈[n]\{k}
( q
p x · si[j] + q
p (si[d] −1) · r(j)
k
· zk + (bk −bi) · r(j)
k
+ ei)
= q
p x ·

i∈[n]
si[j] + q
p

i∈[n]
(si[d] −1) · r(j)
k
· zk +

i∈[n]\{k}
(bk −bi) · r(j)
k
+

i∈[n]
ei
= q
p x ·

i∈[n]
si[j] +

i∈[n]\{k}
(bi −bk) · r(j)
k
+

i∈[n]\{k}
(bk −bi) · r(j)
k
+ e
= q
p x ·

i∈[n]
si[j] + e = q
p x · (ek0 + ek1)[j] + e.
That is, the extended input shares still satisfy the requirement of nearly linear
decryption under the extended evaluation key in a component-wise form. For the
simplicity of writing, we denote by ⟨ek0 + ek1, C
(x)⟩:= (q/p) · x · (ek0 + ek1) + e
the decryption (⟨ek0 + ek1, c(x,1)⟩, . . . , ⟨ek0 + ek1, c(x,d)⟩) ∈Zd
q of the matrix of
d extended ciphertexts.
⊓⊔
Correctness of MKHSS. For any λ ∈N, for all inputs x1, . . . , xn ∈[Z]Binp,
for any RMS programs P with maximum number of input addition instructions
Pinp+ and the magnitude bound Bmax, where |P| ≤poly(λ), p/Bmax ≥λω(1)
and q/(Bmax · p) ≥λω(1), for (pk, sk) ←MKHSS.Gen(1λ) and (s(0)
i , s(1)
i ) ←
MKHSS.Share(i, pk, sk, x), there exits an PPT adversary B breaking the pseudo
randomness of PRF with advantage holds at least
Prcor
MKHSS,{xi}i∈[n],P,r(λ) ≥1 −Advprf
PRF,B(λ) −(Bmax + 1)/q
−|P | · d · Pinp+ · Bmax · (Bct · p/q + Bsk/p) −|P | · d · (p/q + 1/p).

262
P. Xu and L.-P. Wang
Proof. Suppose ε0 := Prcor
MKHSS,{xi}i∈[n],P,r(λ) denotes the probability that a pro-
gram P is successfully evaluated by employing our MKHSS scheme on input
x1, . . . , xn ∈[Z]Binp. We then deﬁne ε1 := Pr1
MKHSS,{xi}i∈[n],P,r(λ) as the prob-
ability of correct evaluation, where we replace every evaluation of PRF with a
randomly chosen value r ←Zd
q. And |ε0 −ε1| ≤Advprf
PRF,B(λ) has been proved
by Boyle et al. in [5]. That is, if ε0 diﬀers signiﬁcantly from ε1, then there exits
an adversary B who can break the pseudorandomness of the PRF used in every
evaluation.
Next, a lower bound of the probability ε1 can be easily obtained according
to [5]. Speciﬁcally, if the evaluation of a program P over shares (t(x)
0 , t(x)
1 ) cor-
responds to the input value x ∈Z, there is overwhelming probability over the
choice of r ←Zd
q that the shares satisfy t(x)
0
+ t(x)
1
= x · s = (x, x · ˆs) mod q,
where s = (1,ˆs) ∈Z × Zd−1
q
. Further, for x0, x1 ∈Zq be random and y ∈Z, we
have x0 + x1 = y with probability at least 1 −(Bmax + 1)/q.
Then we show that the homomorphic evaluation of P is true, i.e. t(x)
0
+
t(x)
1
= x · s = (x, x · ˆs) mod q indeed holds. Assuming correctness of distributed
decryption holds, by Lemma 3 we have
– Load: on instruction (id, C
(x)),
t(x)
0
+ t(x)
1
= MRegev.DDec(0, ek0, C
(x)) + MRegev.DDec(1, ek1, C
(x))
= ⌊p
q · ⟨ek0 + ek1, C
(x)⟩⌉
mod q = ⌊p
q · ( q
p x · (ek0 + ek1) + e)⌉
mod q
= x · (ek0 + ek1)
mod q.
– Add1: on instruction (id, t(x)
b , t(x′)
b
) for b ∈{0, 1},
t(x+x′)
0
+ t(x+x′)
1
= t(x)
0
+ t(x′)
0
+ r + t(x)
1
+ t(x′)
1
−r
mod q
= x · (ek0 + ek1) + x′ · (ek0 + ek1)
mod q = (x + x′) · (ek0 + ek1)
mod q.
– Mult: on instruction (id, t(x)
b , c(x′)) for b ∈{0, 1},
t(x·x′)
0
+ t(x·x′)
1
= MRegev.DDec(0, t(x)
0
, C
(x′))
+ MRegev.DDec(1, t(x)
1
, C
(x′)) = ⌊p
q · ⟨t(x)
0
+ t(x)
1
, C
(x′)⟩⌉
mod q
= ⌊p
q · ( q
p x · x′ · (ek0 + ek1) + e)⌉
mod q = x · x′ · (ek0 + ek1)
mod q.
Here we put the addition of input values Add2 and the output of the memory
values Output out of consideration, because these two operations have no eﬀect
on the shares.
Throughout the execution of the above instructions, the intermediary values
x are bounded by ∥x∥∞≤Bmax and the distribution of (t(x)
0 , t(x)
1 ) is random
subject to t(x)
0 +t(x)
1
= x·s. Similar to the analysis in [5], the distribute decryption
fails with probability at most Pinp+ · Bmax · (Bct · p/q + Bsk/p) + (p/q + 1/p).
d decryptions are required for every instruction. Consider the RMS program
P with size |P|, a union bound over all d · |P| decryptions is yielded as ε1 ≥
1 −(Bmax + 1)/q −d · |P| ·Pinp+ · Bmax · (Bct · p/q + Bsk/p) −d · |P| · (p/q + 1/p).
This completes our proof of correctness.
⊓⊔

Multi-key Homomorphic Secret Sharing from LWE Without Multi-key HE
263
Security of MKHSS. The MKHSS scheme is semantically secure.
Proof. Here we employ a hybrid argument to prove the security of our MKHSS
scheme, and deﬁne 3 games in Fig. 1.
Game G0
MKHSS,A is the original MKHSS security game, corresponding to
Advsec
MKHSS,A(λ) ≤
Pr

G0
MKHSS,A(λ) = 1

−1/2
 .
Now suppose there exists a PPT adversary A which can distinguish between
games G0
MKHSS,A and G1
MKHSS,A, then another PPT adversary B that breaks the
security of MRegev can be constructed as follows. On input the public key pk
by the challenger of the MRegev security game and input (b, x0, x1, state), B
chooses β ∈{0, 1}. Then B draws K ←K and sets ek(1) = ek −ek(0) mod q
with ek, ek(0)
$←Zd
q. For j ∈[d], B computes cj ←Regev.OKDM(pk, xβ, j).
B queries Tk
j ←OMRegev(pk, ∗, 0) and ˆTk
j ←OMRegev(pk, ∗, 1) for all random
vectors rj used in executing Regev.OKDM, where j ∈[d] and k ∈[m]. Finally,
B sends pk and sb
i = (ek(b), K, {cj}j∈[d], {Tk
j , ˆTk
j }j∈[d],k∈[m]) to A. B takes the
output of A as its challenge response. If the MRegev oracle returns the encryption
with the ﬁrst component P of the public key pk, the distribution of sb
i equals that
in game G0
MKHSS,A. While if it returns the encryption with a randomly generated
public key component P′, the distribution of sb
i equals that in game G1
MKHSS,A.
Thus we have
Pr

G0
MKHSS,A(λ) = 1

−Pr

G1
MKHSS,A(λ) = 1
 ≤Advind−cpa
MRegv,A(λ).
Considering G2
MKHSS,A, the only diﬀerence from G1
MKHSS,A is that when the
adversary queries the encryption of xβ, it returns the encryption of 0 instead
of the real encryption. In this case, we can construct a PPT adversary D on
the security of Regev.OKDM from a PPT adversary C distinguishing between
G1
MKHSS,A and G2
MKHSS,A, which is quite similar to that of B above. After getting
pk, (b, x0, x1, state), β, K, ek(0) and ek(1), D chooses random vectors rj and
computes Tk
j ←MRegev.Enc(pk, rj[k], 0) and ˆTk
j ←MRegev.Enc(pk, rj[k], 1)
for all rj, where j ∈[j] and k ∈[m]. In the query phase, D queries cj ←
OKDM(pk, xβ, j) for j ∈[d]. Finally, D sends pk and sb
i to C and takes the output
of C as its. If the KDM oracle returns the real encryption of xβ, the distribution
of sb
i equals that in game G1
MKHSS,A. While if it returns the encryption of 0, the
distribution of sb
i equals that in game G2
MKHSS,A. Therefore, It holds that
Pr

G1
MKHSS,A(λ) = 1

−Pr

G2
MKHSS,A(λ) = 1
 ≤Advkdm−ind
Regev.OKDM,A(λ).
Since the view of C in G2
MKHSS,A is independent of the choice on β, we have
Pr

G2
MKHSS,A(λ) = 1

= 1/2.
According to the triangle inequality, we can put them all together and obtain
that
Pr

G0
MKHSS,A(λ) = 1

−Pr

G2
MKHSS,A(λ) = 1

≤Advind−cpa
MRegev,A(λ) + Advkdm−ind
Regev.OKDM,A(λ).

264
P. Xu and L.-P. Wang
Further, we have given the semantical security of the KDM oracle and
MRegev in Deﬁnition 2 and Theorem 1 respectively. Finally, we have
Pr

G0
MKHSS,A(λ) = 1

−1/2
 ≤negl(λ).
This completes our proof.
⊓⊔
G0
MKHSS,A:
–
(b, x0, x1, state) ←A(1λ)
–
β ←{0, 1}
–
(pk, sk) :=
((P, s[d]), s) ←MKHSS.Gen(1λ)
–
(s(0), s(1)) ←
MKHSS.Share(∗, pk, sk, xβ ),
where MKHSS.Share completely
follows that in Sec. 4.3
–
β
←A(state, pk, s(b))
–
if β
= β, return 1
–
else, return 0
G1
MKHSS,A:
–
(b, x0, x1, state) ←A(1λ)
–
β ←{0, 1}
–
(pk, sk) := ((P, s[d]), s)
←MKHSS.Gen(1λ)
–
(s(0), s(1)) ←
MKHSS.Share(∗, pk, sk, xβ ),
where MKHSS.Share follows that
in G0
MKHSS,A, except for using
P
(newly generated by
MRegev.KGen) instead of P
–
β
←A(state, pk, s(b))
–
if β
= β, return 1
–
else, return 0
G2
MKHSS,A:
–
(b, x0, x1, state) ←A(1λ)
–
β ←{0, 1}
–
(pk, sk) := ((P, s[d]), s)
←MKHSS.Gen(1λ)
–
(s(0), s(1)) ←
MKHSS.Share(∗, pk, sk, xβ ),
where MKHSS.Share follows that
in G1
MKHSS,A, except for using
Regev.Enc(P, 0) instead of
Regev.OKDM(pk, xβ , ∗)
–
β
←A(state, pk, s(b))
–
if β
= β, return 1
–
else, return 0
Fig. 1. Games deﬁned in the proof of the security of MKHSS
Context Hiding of MKHSS. The MKHSS scheme is context-hiding.
Proof. To prove the context-hiding property, we ﬁrst construct the simulator S:
On input the security parameter λ and the evaluating result of the RMS program
y = P(x1, . . . , xn) over input values x1, . . . , xn ∈[Z]Binp, S chooses y′
0 ←Zq,
and let y′
1 = y −y′
0 mod q. Finally, the simulator outputs (y′
0, y′
1), which is a
random distribution in Zq.
Consider the output (y0, y1) of MKHSS.Eval is a random distribution in Zq,
it is straightforward to know that (y0, y1) is statistically indistinguishable from
(y′
0, y′
1).
⊓⊔
Lemma 4. Assuming hardness of LWEq,d−1,m,χsk,χ, the noise bound of the above
(n, 2)-MKHSS scheme is Bct = (2m2nl + 1) · Berr.
Proof. For the extension ciphertext denoted by c(x,j) := c(x,j)
k
−t(j)
k
+ ˆt(j)
k , we
get the new noise term ek +
i∈[n]\{k} ei = e+m
j=1 eR(g−1(z[j]), 0, · · · , 0)⊤+
m
j=1 eR(0, · · · , 0, g−1(z[j]))⊤of ⟨sk, c(x,j)⟩according to Lemma 3. Since
∥e∥∞≤Berr, the noise bound Bct can be easily concluded by the maximum
of the above noise term, that is (2m2nl + 1) · Berr.
⊓⊔
5
Performance Analysis
In this section, we ﬁrst give the theoretical analysis of our MKHSS scheme from
both the client-side and the server-side costs. Then, we implement our scheme
and evaluate its performance by conducting comprehensive experiments.

Multi-key Homomorphic Secret Sharing from LWE Without Multi-key HE
265
5.1
Theoretical Analysis
We give an overview of communication and storage costs in Table 1, along with
Table 2 for an overview of computation costs on the server-side, and compare
them with the single-key HSS scheme proposed in [5].
On the Client-Side. To support multi-key evaluation, each client generates two
more sets of MRegev ciphertexts than those in [5] and adds them to input shares.
In that output shares returned by servers remain the same sizes, there is no addi-
tional computational cost added to the output client in terms of reconstruction.
On the client-side, MKHSS trades some computation and communication eﬃ-
ciency in share generation phase for richer functionality.
On the Server-Side. In the evaluation phase, the size of the extended shares
remains the same due to the use of homomorphic linear combination. Thus, the
evaluation performed by each server over the extended shares is completely iden-
tical to that in [5]. On the server-side, the costs of storage and communication of
MKHSS remain the same as those of [5], and the extra computational overhead
caused by share extension is tolerable because of the powerful computational
abilities of servers.
Comparison with [12]. The HSS scheme in [12] can support the functionality
similar to ours by using multi-key HE as its underlying building block. In the two-
server setting, to compute a k-degree polynomial, the computation complexity
of our MKHSS scheme is O(k · d2) on the server-side, as oppose to O(22
k−1
2 ) for
the construction of [12] in the fair case. To be speciﬁc, there are 2k−1 k-degree
terms to be calculated by each server for [12]. Because of costly key-switching
operations required by the underlying k−1
2 -degree HE scheme, evaluation of high
degree polynomials in [12] is apparently expensive. Furthermore, high-degree HE
schemes suﬀer from ciphertext expansion more or less. That is, the size of an
extended ciphertext at least increases linearly with the number of input clients,
which causes the time spent by the output client for decryption to reconstruct
the ﬁnal result becomes larger. In contrast, our MKHSS scheme has ﬁxed-size
extended ciphertexts, avoiding costly multi-key HE, and only a simple modular
addition is needed for reconstruction. Obviously, our MKHSS scheme gives it
more advantages in terms of high-degree polynomial evaluations. We only give
a theoretical comparison with [12], since no LWE-based multi-key homomorphic
encryption scheme compatible with its construction can be used for instantiation.
Table 1. Sizes of Input Shares/Extended Ciphertexts/Memory Values/Output Shares
input shares
(extended) ciphertexts
memory values
output shares
[5]
|K| + d + d2
d2
d
d
ours
|K| + d + (4lm + 1)d2
d2
d
d
|K| denotes PRF key size and the units of values in the table are Zq.

266
P. Xu and L.-P. Wang
Table 2. Dominant computation costs of computing servers
ciphertext extension load
add1(mem) add2(input) mult(mem −input)
[5]
−
d2 · mulq d · addq
d2 · addq
d2 · mulq
ours n · dml · mulq
d2 · mulq d · addq
d2 · addq
d2 · mulq
mulq and addq respectively denote the number of multiplication and addition over Zq.
5.2
Experimental Results
Refer to the parameter selection method in [5], we start with choosing the plain-
text bound Bmax and set r = Bmax to maximum the output space. Also, we
choose a statistical security parameter κ = 40, the number of Add2 instruc-
tions Pinp+ = 1, the noise distribution Berr = 8σ with σ = 8, and the
secret key bound Bsk = 1. We adapt the correctness of MKHSS to ensure
each multiplication has a failure probability no more than 2−κ, which means
d·Bmax·(Bct·p/q+Bsk/p) ≤2−κ should be required. We set p = d·Bmax·Bsk·2κ,
then a bound on q is given as q ≥2κ+1 ·m2 ·p·d·Bmax ·Berr ·Bsk by combining
the formula from Lemma 4.
Our experiments are conducted over a Ubuntu 20.0.4 LTS 64-bit operat-
ing system with Intel Xeon Gold 6230R 2.1 GHz×26 processors and 256 GB
of RAM. All mathematical calculations involving large integers were realized
based on the C++ libraries GMP-6.2.1 and NTL-11.5.1. And the library cymric
is used as the secure random number generator in our public-key setting. Table 3
shows the running time of 5 RMS instructions in MKHSS.Eval algorithm corre-
sponding to the diﬀerent parameters. To the best of our knowledge, this is the
ﬁrst implementation of a multi-key HSS scheme from LWE. Note that in order
to make the evaluation results plainer, we did not leverage any speedup tricks,
such as parallelism, in the implementation, which would signiﬁcantly improve
the performance. For example, we can get about a 5× improvement when multi-
threading (the number of threads is 5) is applied, making the latency for low
degree polynomial tolerable.
Table 3. The running time (in milliseconds) of 5 RMS instructions in MKHSS.Eval
Bmax d
q
p
security load
add1
add2
mult
output
2
212 2137 253
2103.3
2618.03
0.483 1848.54
2592.62
4 × 10−3
216
212 2167 268
283.74
2724.66
0.504 2037.37
2708.18
7 × 10−3
232
213 2203 285
2142.0
11202.55 0.943 7734.02
11191.72 6 × 10−3
264
213 2267 2117 2104.9
10756.25 0.942 7667.27
10694.5
4 × 10−3
2128
214 2399 2182 2143.9
63199.07 1.922 31386.75 55646.32 5 × 10−3
2256
214 2655 2310 284.6
70796.85 1.937 34906.75 69374.8
7 × 10−3

Multi-key Homomorphic Secret Sharing from LWE Without Multi-key HE
267
6
Conclusions
In this paper, we mainly focus on the construction of homomorphic secret shar-
ing in the multi-key setting. We ﬁrst propose a formal deﬁnition of multi-key
HSS in the two-server model. Then by applying the homomorphic linear combi-
nation for the modiﬁed Regev encryption to the single-key construction in [5],
we present an instantiation of multi-key HSS scheme based on LWE without
multi-key HE. It allows independent input clients to share private data between
two non-colluding servers, so that polynomials interpreted as RMS programs can
be jointly computed over these input shares. In particular, the number of input
clients and the degree of evaluated polynomials can be as high as a polynomial
in the security parameter. Besides, the security and context hiding property of
our scheme preserve the privacy of input clients against the computing servers
and the output client. In the future, we will explore the HSS construction in the
multi-server model with the threshold malicious assumption, and further reduce
the computation and communication costs of our MKHSS to meet the practical
requirements better.
References
1. Asharov, G., Jain, A., L´opez-Alt, A., Tromer, E., Vaikuntanathan, V., Wichs, D.:
Multiparty computation with low communication, computation and interaction
via threshold FHE. In: Pointcheval, D., Johansson, T. (eds.) EUROCRYPT 2012.
LNCS, vol. 7237, pp. 483–501. Springer, Heidelberg (2012). https://doi.org/10.
1007/978-3-642-29011-4 29
2. Ben-Or, M., Goldwasser, S., Wigderson, A.: Completeness theorems for non-
cryptographic fault-tolerant distributed computation (extended abstract). In: Pro-
ceedings of the 20th Annual ACM Symposium on Theory of Computing, pp. 1–10
(1988)
3. Boyle, E., Gilboa, N., Ishai, Y.: Breaking the circuit size barrier for secure com-
putation under DDH. In: Robshaw, M., Katz, J. (eds.) CRYPTO 2016. LNCS,
vol. 9814, pp. 509–539. Springer, Heidelberg (2016). https://doi.org/10.1007/978-
3-662-53018-4 19
4. Boyle, E., Gilboa, N., Ishai, Y.: Group-based secure computation: optimizing
rounds, communication, and computation. In: Coron, J.-S., Nielsen, J.B. (eds.)
EUROCRYPT 2017. LNCS, vol. 10211, pp. 163–193. Springer, Cham (2017).
https://doi.org/10.1007/978-3-319-56614-6 6
5. Boyle, E., Kohl, L., Scholl, P.: Homomorphic secret sharing from lattices without
FHE. In: Ishai, Y., Rijmen, V. (eds.) EUROCRYPT 2019. LNCS, vol. 11477, pp.
3–33. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-17656-3 1
6. Catalano, D., Fiore, D.: Using linearly-homomorphic encryption to evaluate degree-
2 functions on encrypted data. In: Proceedings of the 22nd ACM SIGSAC Confer-
ence on Computer and Communications Security, pp. 1518–1529 (2015)
7. Chen, X., Zhang, L.F.: Two-server veriﬁable homomorphic secret sharing for high-
degree polynomials. In: Susilo, W., Deng, R.H., Guo, F., Li, Y., Intan, R. (eds.)
ISC 2020. LNCS, vol. 12472, pp. 75–91. Springer, Cham (2020). https://doi.org/
10.1007/978-3-030-62974-8 5

268
P. Xu and L.-P. Wang
8. Chor, B., Gilboa, N.: Computationally private information retrieval (extended
abstract). In: Proceedings of the Twenty-Ninth Annual ACM Symposium on the
Theory of Computing, pp. 304–313 (1997)
9. Cleve, R.: Towards optimal simulations of formulas by bounded-width programs.
Comput. Complex. 1, 91–105 (1991)
10. Damg˚ard, I., Jurik, M.: A generalisation, a simpliﬁcation and some applications
of Paillier’s probabilistic public-key system. In: Kim, K. (ed.) PKC 2001. LNCS,
vol. 1992, pp. 119–136. Springer, Heidelberg (2001). https://doi.org/10.1007/3-
540-44586-2 9
11. Dodis, Y., Halevi, S., Rothblum, R.D., Wichs, D.: Spooky encryption and its appli-
cations. In: Robshaw, M., Katz, J. (eds.) CRYPTO 2016. LNCS, vol. 9816, pp. 93–
122. Springer, Heidelberg (2016). https://doi.org/10.1007/978-3-662-53015-3 4
12. Eriguchi, R., Nuida, K.: Homomorphic secret sharing for multipartite and general
adversary structures supporting parallel evaluation of low-degree polynomials. In:
Tibouchi, M., Wang, H. (eds.) ASIACRYPT 2021. LNCS, vol. 13091, pp. 191–221.
Springer, Cham (2021). https://doi.org/10.1007/978-3-030-92075-3 7
13. Fazio, N., Gennaro, R., Jafarikhah, T., Skeith, W.E.: Homomorphic secret sharing
from Paillier encryption. In: Okamoto, T., Yu, Y., Au, M.H., Li, Y. (eds.) ProvSec
2017. LNCS, vol. 10592, pp. 381–399. Springer, Cham (2017). https://doi.org/10.
1007/978-3-319-68637-0 23
14. Gamal, T.E.: A public key cryptosystem and a signature scheme based on discrete
logarithms. IEEE Trans. Inf. Theor 31(4), 469–472 (1985)
15. Gentry, C.: Fully homomorphic encryption using ideal lattices. In: Proceedings
of the 41st Annual ACM Symposium on Theory of Computing, STOC 2009, pp.
169–178 (2009)
16. Gilboa, N., Ishai, Y.: Distributed point functions and their applications. In:
Nguyen, P.Q., Oswald, E. (eds.) EUROCRYPT 2014. LNCS, vol. 8441, pp. 640–
658. Springer, Heidelberg (2014). https://doi.org/10.1007/978-3-642-55220-5 35
17. Goldreich, O., Micali, S., Wigderson, A.: How to play any mental game or A
completeness theorem for protocols with honest majority. In: Proceedings of the
19th Annual ACM Symposium on Theory of Computing, pp. 218–229 (1987)
18. Jiang, B.: Multi-key FHE without ciphertext-expansion in two-server model. Front.
Comput. Sci. 16(1), 1–8 (2022). https://doi.org/10.1007/s11704-021-0479-5
19. Lyubashevsky, V., Peikert, C., Regev, O.: A toolkit for ring-LWE cryptography.
In: Johansson, T., Nguyen, P.Q. (eds.) EUROCRYPT 2013. LNCS, vol. 7881, pp.
35–54. Springer, Heidelberg (2013). https://doi.org/10.1007/978-3-642-38348-9 3
20. Micciancio, D., Peikert, C.: Trapdoors for lattices: simpler, tighter, faster, smaller.
In: Pointcheval, D., Johansson, T. (eds.) EUROCRYPT 2012. LNCS, vol. 7237, pp.
700–718. Springer, Heidelberg (2012). https://doi.org/10.1007/978-3-642-29011-
4 41
21. Mukherjee, P., Wichs, D.: Two round multiparty computation via multi-key FHE.
In: Fischlin, M., Coron, J.-S. (eds.) EUROCRYPT 2016. LNCS, vol. 9666, pp.
735–763. Springer, Heidelberg (2016). https://doi.org/10.1007/978-3-662-49896-
5 26
22. Regev, O.: On lattices, learning with errors, random linear codes, and cryptogra-
phy. In: Proceedings of the 37th Annual ACM Symposium on Theory of Comput-
ing, pp. 84–93 (2005)
23. Rivest, R.L., Adleman, L., Dertouzos, M.L.: On data banks and privacy homomor-
phisms. Found. Secure Comput. 4(11), 169–179 (1978)

Multi-key Homomorphic Secret Sharing from LWE Without Multi-key HE
269
24. Tsaloli, G., Liang, B., Mitrokotsa, A.: Veriﬁable homomorphic secret sharing. In:
Baek, J., Susilo, W., Kim, J. (eds.) ProvSec 2018. LNCS, vol. 11192, pp. 40–55.
Springer, Cham (2018). https://doi.org/10.1007/978-3-030-01446-9 3
25. Tsaloli, G., Mitrokotsa, A.: Sum it up: veriﬁable additive homomorphic secret
sharing. In: Seo, J.H. (ed.) ICISC 2019. LNCS, vol. 11975, pp. 115–132. Springer,
Cham (2020). https://doi.org/10.1007/978-3-030-40921-0 7

Identity-Based Encryption from Lattices
Using Approximate Trapdoors
Malika Izabachène1, Lucas Prabel2(B), and Adeline Roux-Langlois3
1 Independent Scholar, Paris, France
2 Univ Rennes, CNRS, IRISA, Rennes, France
lucas.prabel@irisa.fr
3 Normandie Univ, UNICAEN, ENSICAEN, CNRS, GREYC, 14000, Caen, France
Abstract. Practical implementations of advanced lattice-based con-
structions have received much attention since the ﬁrst practical scheme
instantiated over NTRU lattices, proposed by Prest et al. (Asiacrypt
2014). They are using powerful lattice-based building blocks which allow
to build Gaussian preimage sampling and trapdoor generation eﬃciently.
In this paper, we propose two diﬀerent constructions and implementa-
tions of identity-based encryption schemes (IBE) using approximate vari-
ants of “gadget-based” trapdoors introduced by Chen et al. (Asiacrypt
2019). Both constructions are proven secure.
Our ﬁrst IBE scheme is an adaptation of the Bert et al. scheme
(PQCrypto 2021) to the approximate setting, relying on the Module-LWE
hardness assumption and making use of the Micciancio-Peikert paradigm
with approximate trapdoors. The second IBE relies on a variant of the
NTRU hardness assumption.
We provide several timings and a comparison analysis to explain our
results. The two diﬀerent instantiations give interesting trade-oﬀs in
terms of security and eﬃciency and both beneﬁt from the use of approxi-
mate trapdoors. Though our second IBE construction is less eﬃcient than
other NTRU-based IBEs, we believe our work provides useful insights into
eﬃcient advanced lattice-based constructions.
Keywords: Lattice-based cryptography · approximate trapdoors ·
Gaussian preimage sampling · module lattices · IBE
1
Introduction
Identity-based encryption (IBE) is an advanced public key encryption scheme in
which an identity, such as a username, email address, or social security number,
acts as the public key. In identity-based encryption, the sender encrypts a mes-
sage with the unique identity of the recipient, and the recipient then decrypts
Supplementary Information The online version contains supplementary material
available at https://doi.org/10.1007/978-3-031-35486-1_13.
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 270–290, 2023.
https://doi.org/10.1007/978-3-031-35486-1_13

Identity-Based Encryption from Lattices Using Approximate Trapdoors
271
the ciphertext with their private key to obtain the original message. In this way,
one party can send an encrypted message to any other party without requesting
the recipient’s public key beforehand. The pair “identity” and “associated secret
key” acts as a classical public key and secret key pair in a classical public key
encryption scheme.
The idea was to eliminate the need for a public certiﬁcate across email sys-
tems. These schemes allowed secure communication without exchanging user
keys. In [31] Shamir presented a solution for an identity-based signature scheme
but the ﬁrst IBE constructions appeared only in 2001 in [6,10] and were based
respectively on bilinear maps and quadratic residue-based assumptions. However,
these schemes were vulnerable to quantum attacks due to Shor’s algorithm.
Lattice-Based IBE Constructions. In [18], Gentry, Peikert and Vaikun-
tanathan described the ﬁrst lattice-based IBE, relying on the Dual-Regev encryp-
tion scheme. An important contribution of their work was a sampling algorithm
(known as GPV sampling) which showed how to use a short basis as a trapdoor
for generating short lattice vectors. This sampler was then used to construct
a lattice-based IBE scheme, proven adaptively secure against chosen-plaintext
attack in the random oracle model as deﬁned in [6,10]. However, the master
public key and user secret keys had large sizes in O(n2) bits. Later on, a con-
struction of a Hierarchical IBE (HIBE) scheme in the standard model was pro-
posed in [8] based on a new mechanism for users’ keys delegation. This IBE
scheme was proven secure in the selective model where the adversary needs to
target an identity beforehand. In 2010, Agrawal et al. [1] proposed a Learning
With Errors (LWE)-based IBE scheme with a trapdoor structure and with per-
formance comparable to the GPV scheme. Their construction viewed an identity
as a sequence of bits and then assigned a matrix to each bit. It used a sampling
algorithm to obtain a basis with low Gram-Schmidt norm for the master secret
key and formed a lattice family with two associated trapdoors to generate short
vectors; one for all lattices in the family and the other one for all but one.
The ﬁrst Ring-LWE based IBE scheme has been proposed by Ducas, Lyuba-
shevsky and Prest [11] (DLP-IBE), which is still considered the most eﬃcient
scheme to date due to smaller key sizes. The use of the ring variant increased eﬃ-
ciency by reducing the public key size and ciphertext size to O(n). The security
of their scheme holds in the random oracle model and is related to the NTRU
hardness assumption. An eﬃcient C implementation of the DLP-IBE scheme
and a detailed performance analysis was provided in [27]. In 2017, Campbell
and Grover introduced a HIBE scheme, called LATTE, which can be viewed
as a combination of the DLP scheme with the delegation mechanism from [8].
An optimized implementation and reﬁned analysis of LATTE, has recently been
proposed in [33].
The work from [5] constructed an IBE using the notion of gadget-based
trapdoors in the ring setting, introduced by [28]. Such trapdoors can be seen
as linear transformations mapping hard instances of cryptographic problems on
some lattices to easy instances on a lattice deﬁned by a public “gadget matrix”.
The IBE from [5] also made use of the eﬃcient Gaussian preimage sampling

272
M. Izabachène et al.
algorithms from [17] to propose an implementation of their scheme. In [4], this
IBE and its associated sampling algorithms were adapted to the module setting
and instantiated. The use of module lattices of dimension nd, where d is the
rank module, led to a more ﬂexible choice of parameters. In [32], the authors
proposed new eﬃcient gadget sampling algorithms which didn’t need ﬂoating-
point arithmetic, and as fast as the original [17] sampler.
All those constructions generally make use of dedicated trapdoors, needed
by the authority to generate the secret key of a user. In that case, building the
trapdoor and sampling particular short vectors are quite costly, and represent
the main bottleneck in the eﬃciency of such schemes. More recently, [9] intro-
duced approximate trapdoors to improve the eﬃciency of schemes built from
lattice trapdoors while keeping the same concrete security. [16] showed that
those approximate trapdoors, relying on the [28] framework, exist on a fam-
ily of NTRU lattices. Our work explores the application of those approximate
trapdoors, and in particular of this family of NTRU lattices, to more advanced
schemes where the generation of private keys in a multi-user setting is needed.
Our Contributions. Our main contribution is to provide and implement two
lattice-based IBE schemes (IBE1 and IBE2), which make use of families of
gadget-based approximate trapdoors. Our two constructions rely on the LWE
problem over modules (Module-LWE) and the inhomogeneous NTRU problem
(iNTRU) respectively. We investigate how to instantiate and parametrize the
approximate trapdoor preimage sampling over these two families of trapdoors
in a way to obtain provable and eﬃcient quantum-safe IBE schemes. The IBE1
construction is an adaptation of the identity-based encryption scheme from [1,5]
to the module setting, using approximate trapdoors. The IBE2 construction fol-
lows the same blueprint as the DLP scheme except that it makes use of iNTRU
gadget-based approximate trapdoors. As in previous IBE constructions, encryp-
tion is based on the Dual-Regev encryption scheme. We provide a complete pub-
lic and open-source C implementation1 with performance benchmarking. The
implementation is modular and makes it easy to change the building blocks of
our algorithms according to the desired properties that we want to get.
Our work explores the use of approximate trapdoors for the construction
of IBE schemes and the potential practical insights we can gain from it. We
ﬁrst adapted the construction of [4] using approximate trapdoors in our IBE1.
The error induced by the approximate setting requires changes at several levels,
either for the choice of encoding or for the sampling algorithms. As expected,
we obtain better timings for all four algorithms composing our IBE by using
approximate trapdoors rather than exact ones.
The second scheme IBE2 makes use of approximate trapdoors relying on a
variant of NTRU rather than Module-LWE. Our approach was motivated by the
fact that other eﬃcient IBEs, such as DLP and Latte, used the NTRU hardness
assumption. However, unlike us, these last two schemes used the GPV paradigm
to generate trapdoors, which signiﬁcantly changes the way their schemes are
constructed compared to ours.
1 https://github.com/lucasprabel/approx_lattice.

Identity-Based Encryption from Lattices Using Approximate Trapdoors
273
More Details on Our Implementation Choices. Our IBE1 proof relies on a sta-
tistical trapdoor instantiation. Although the size of the parameters increases
consequently, the use of approximate trapdoors allowed us to mitigate this loss
in eﬃciency induced by the use of a statistical instantiation. In order to ensure
decryption correctness, we also need to use a large modulus (see Sect. 4.1). This
leads us to perform calculations carefully on 64-bit integers, so as not to aﬀect
our scheme eﬃciency. The IBE1 also makes use of a small-norm encoding, instead
of the low-degree encoding used in [4] to ensure that the noise is still not too
large in order to decrypt. The encoding we use sets constraints on the structure
of the ring Rq which is not compatible with the NTT for polynomial multipli-
cations. Instead, we use a “partial NTT” based on [26] results, which reduces
multiplication in Rq to multiplication in smaller rings. We also have optimized
the underlying CRT representation algorithm compared to [4]. Finally, the sam-
pling algorithms have been adapted to the approximate setting. Table 2 shows
some applicable parameter sets together with their concrete bit security using
the LWE estimator from [2] with BKZ as a reduction cost model. All the algo-
rithms comprising the IBE1 over module lattices are more eﬃcient than their
exact counterpart at the same security level. This improvement concerns in par-
ticular Setup and Extract which are optimized by a factor ≈1.5. We give more
details in Sect. 4.2.
The IBE2 scheme is instantiated using gadget-based trapdoors on a family of
NTRU lattices. Table 4 provides a set of applicable parameter sets together with
their concrete bit security. The computational trapdoors instantiation lowers
the bounds on parameters required for the correctness compared to the IBE1
scheme, which allows the use of smaller moduli. For the IBE2 construction, an
identity is encoded as H(id) with H having special properties so that we are able
to respond to private key queries except for the target identity chosen by the
adversary.
Table 1. Timings comparison in ms of the diﬀerent operations of the IBE2 scheme in
this paper and in Latte [33] for diﬀerent sets of parameters.
Scheme
(n, ⌈log2(q)⌉) Security level Setup Extract Encrypt Decrypt
[33]
(1024, 24)
128
102
0.82
0.05
0.06
[33]
(2048, 25)
256
292
2.62
0.10
0.13
This paper (1024, 25)
159
3.32
5.92
1.10
0.07
This paper (2048, 25)
293
10.21
12.79
2.96
0.16
In Table 1, we provide timings comparison with the [33] IBE scheme. A more
complete and detailed comparison is given in Sect. 5.2 between our IBE2 scheme
and the [11] and [33] IBE schemes which also rely on the NTRU assumption. The
use of approximate trapdoors and of the iNTRU assumption allows to obtain
better timings for the Setup algorithm and for the Extract algorithm for some
sets of parameters. Unfortunately, we obtain an overhead for encryption which

274
M. Izabachène et al.
essentially comes from the Gaussian sampling phase. We can save a factor 3.5
using binomial samples as in [11] and [33] but there is still an overhead due to
the extra number of samples we need. We make n(2 + m) calls to the integer
Gaussian sampler while encryption in [11] and [33] makes use of 3n binomial
sampling calls, where n is the dimension of the underlying polynomial ring and
m is the size of one of the vector used in encryption. As an example, we obtain
a timing of 0.87ms for one encryption against 0.13 for [33] for a security level of
128 bits.
Organization of the Paper. The paper is structured as follows: Sect. 2 reviews
the necessary linear algebra and lattice backgrounds. The Section also presents
the notions of approximate trapdoor. Then, Sect. 4 and Sect. 5 contain a detailed
description of the two IBEs, based on the Module-LWE hardness assumption
and based on a variant of the NTRU assumption respectively. Both Sections
provide a security analysis and detailed performance results together with a
comparison of their respective analogue in terms of lattice-based building blocks
and assumptions.
2
Preliminaries
Notations. Throughout the paper, the vectors are written in lowercase bold
letters (e.g. v) and matrices in uppercase bold letters (e.g. A). We refer to their
entries with a subscript index vi, Ai,j. We denote ∥·∥and ∥·∥∞the euclidean
norm and the inﬁnity norm respectively. The norm of a vector over Zq is the
norm of the corresponding vector over Z obtained by choosing its entries in the
set {−⌊q/2⌋, . . . , ⌊q/2⌋}. The norm of a polynomial a = n−1
i=0 aiXi is the norm
of the coeﬃcients vector (a0, . . . , an−1). Finally, the norm of a matrix is the
maximum norm of its column vectors. If x is sampled from a distribution D, we
write x ←D. We denote U(S) the uniform distribution over a ﬁnite set S.
We say that a function f is negligible when f(n) = o(n−c) for all c > 0
as n →∞. An event is said to happen with overwhelming probability if its
probability of not happening is negligible. Two distributions D0 and D1 over the
same countable domain Ω are said to be statistically indistinguishable if their
statistical distance Δ(D0, D1) =
1
2

ω∈Ω |D0(ω) −D1(ω)| is negligible. Two
distributions are said to be computationally indistinguishable if no probabilistic
polynomial time algorithm can distinguish them with non-negligible advantage.
2.1
Lattices Background and Discrete Gaussian Distributions
Lattices. A lattice Λ in Rm is the set
k
i=1 λibi, λi ∈Z

of all integer linear
combinations of some linearly independent vectors B = {b1, . . . , bk} ⊂Rm. We
call k the rank of the lattice and m its dimension. When k = m, the lattice is
said to be full-rank.
Given A ∈Zn×m
q
and u ∈Zn
q , we deﬁne the following m-dimensional
q-ary lattice Λ⊥
q (A) = {x ∈Zm|Ax = 0 mod q} , and its coset Λu
q (A) =
{x ∈Zm|Ax = u mod q} .

Identity-Based Encryption from Lattices Using Approximate Trapdoors
275
Module lattices are particular lattices that have a polynomial structure.
We denote d the module rank of those lattices. When d = 1, module lattices
are in fact ideal lattices. We consider the ones that are based on the rings
R = Z[X]/⟨Xn + 1⟩and Rq = Zq[X]/⟨Xn + 1⟩, where n is a power of two and
q is prime. They are sublattices of the full lattice Rm, which is isomorphic to
the integer lattice Znm.
Gaussian Distributions. We recall that a symmetric matrix M ∈Rn×n is pos-
itive deﬁnite (resp. positive semideﬁnite) if xT Mx > 0 (resp. xT Mx ≥0) for
all nonzero x ∈Rn. In this case we write M ≻0 (resp. M ⪰0). We say that
M ⪰N when M −N ⪰0, and write M ⪰η instead of M ⪰ηIn when
η ≥0 is a real. The spherical continuous Gaussian function of center c ∈Rn
and parameter σ is deﬁned on Rn by ρc,σ(x) = exp(−π∥x−c∥2
σ2
). For a posi-
tive deﬁnite matrix Σ ∈Rn×n, we also deﬁne the (skewed) Gaussian function
ρc,
√
Σ (x) = exp(−π(x −c)T Σ−1(x −c)). Then, for a full-rank lattice Λ ⊂Zn,
we denote DΛ,σ,c (respectively DΛ,
√
Σ ,c) the spherical (resp. ellipsoid) discrete
Gaussian distribution of center c ∈Rn and parameter σ > 0, associated with
the density ρc,σ (resp. ρc,
√
Σ ).
Smoothing Parameter. The smoothing parameter of a lattice Λ, denoted ηε(Λ),
was ﬁrst introduced in [29]. Lemma 1 gives an upper bound on it.
Lemma 1 ([18, Lemma 3.1]). Let Λ ⊂Rn be a lattice with basis B, and
˜
B the Gram-Schmidt orthogonalization of B. Then, for any ε > 0, we have
ηε(Λ) ≤∥∗∥˜
B ·

ln(2n(1 + 1/ε))/π.
Gaussian Tailcut. We will use the following result to bound the euclidean norm
of vectors that follow a discrete Gaussian distribution.
Lemma 2 ([24, Lemma 4.4]). For any integer n ≥1 and reals σ > 0, t > 1,
Pr [∥x∥> tσ√n | x ←DZn,σ] < tne
n
2 (1−t2).
We call t a tailcut of the discrete Gaussian of parameter σ when a vector x
sampled from DZn,σ veriﬁes the inequality ∥x∥≤tσ√n on its euclidean norm
with overwhelming probability.
2.2
Cryptographic Problems on Lattices
We work on the rings R = Z[X]/⟨Xn +1⟩and Rq = Zq[X]/⟨Xn +1⟩, where n is
a power of two and q a prime modulus. Let us now deﬁne the hard problems on
which our constructions rely. In most practical lattice-based schemes, security is
based on structured variants of LWE rather than on LWE itself. In the Module-SIS
and Module-LWE variants, the parameter d is the rank of the module, and nd
is the dimension of the corresponding module lattice. The hardness of those
problems is proven by worst-case to average-case reductions from hard problems
on module lattices (see [22]).

276
M. Izabachène et al.
Deﬁnition 1 (Module-SISn,d,m,q,β). Given a uniform A ∈Rd×m
q
, ﬁnd a vector
x ∈Rm such that Ax = 0 mod q, and 0 < ∥x∥≤β.
Deﬁnition 2 (Decision Module-LWEn,d,q,σ). Given a uniform A
∈
Rd×m
q
and the vector bT
= sT A + eT mod q
∈Rm
q , where s ←U(Rd
q) and
e ←DRm,σ, distinguish the distribution of (A, b) from the uniform distribution
over Rd×m
q
× Rm
q .
As stated in [7], the Module-LWE problem remains hard when the short secret
s is sampled from the Gaussian distribution DRd,σ.
Note that Module-LWEn,d,q,σ with rank d = 1 corresponds to the ring version
of LWE, which will be denoted Ring-LWEn,q,σ. We deﬁne G = Id ⊗gT and its
associated lattice named the module G-lattice, for which the Module-SIS problem
is easy.
To build our second IBE, we use gadget-based trapdoors whose pseudoran-
domness is based on the inhomogeneous NTRU problem (iNTRU), a variant of
NTRU introduced in [15].
Deﬁnition 3 (iNTRUq,χ). Let k, q be integers and χ a distribution over R. The
input of the iNTRUq,χ problem is a vector a ∈Rk
q which is either taken uniform
in Rk
q or either set as a = r−1(g + e) where (r, e) is drawn from χk+1. The goal
is to decide which is the case.
In their paper, the authors from [15] showed a reduction of a matrix-variant of
iNTRU called MiNTRU from the non-standard Ring-LWE with a trapdoor oracle
access problem (more details are given in [15, Section 4.3]). The reduction can
be adapted to the iNTRU problem as well.
2.3
Encoding Identities with Full-Rank Diﬀerences
We use the notion of full-rank diﬀerences encoding (FRD) in our ﬁrst scheme,
with diﬀerent properties that the ones used in [1].
Deﬁnition 4 ([4]). An encoding with full-rank diﬀerences from the set M to a
ring R is a map H : M −→R such that:
– for any m ∈M, H(m) is invertible,
– for any m1, m2 ∈M such that m1 ̸= m2, H(m1) −H(m2) is invertible,
– H is computable in polynomial time.
As shown in [4], we construct an FRD encoding in the module setting (i.e.
over Rd×d
q
), by ﬁrst constructing one in the ring setting (i.e. over Rq). The
encodings used in our IBE scheme impose a structure on the ring Rq which
is not compatible with the Number Theoretic Transform (NTT). To speed up
polynomial multiplications and to mitigate the loss of performance due to the
inability of using the NTT, we use ideas from [26]. This method can be thought
of as a “partial NTT”. It is based on the following result.

Identity-Based Encryption from Lattices Using Approximate Trapdoors
277
Lemma 3 ([26, Corollary 1.2]). Let n ≥r > 1 be powers of 2, and q a prime
such that q ≡2r + 1 (mod 4r). Then the cyclotomic polynomial Xn + 1 factors
in Zq[X] as Xn +1 = r
i=1

Xn/r −si

, for some distinct si ∈Z∗
q such that the

Xn/r −si

are irreducible in Zq[X]. Moreover, if y ∈Zq[X]/(Xn + 1) satisﬁes
0 < ∥y∥∞< q1/r
√r , then y has an inverse in Zq[X]/(Xn + 1).
This lemma was used in [4] to build a “low-degree” FRD (the identities were
encoded as polynomials of low-degree). In our case, we construct a “small-norm”
FRD, encoding polynomials with ℓ∞-norm smaller than q1/r
2√r . We make use of
the “small-norm” FRD described in Proposition 1 rather than “low-degree” FRD
encoding so that the correctness of the decryption algorithm still holds when
using approximate trapdoors, because they introduce an additional error term
that must be bounded.
Proposition 1. Let n ≥r > 1 be powers of 2, q a prime such that q ≡2r +
1 (mod 4r) and 1 ≤D ≤
q1/r
2√r an integer. We deﬁne M = {−D, . . . , D}n \
{(0, . . . , 0)} the set of identities. Then the following map HM : M −→Rq, such
that HM(m0, . . . , mn−1) = n−1
i=0 miXi is an FRD encoding.
Proof. We have ∥HM(m)∥∞≤D < q1/r
2√r for all m because of the choice of M.
So according to Lemma 3, HM(m) is invertible. For all m1, m2 ∈M, we also
have ∥HM(m1) −HM(m2)∥∞≤2D < q1/r
√r so HM(m1) −HM(m2) is invertible.
Finally, HM is an FRD encoding.
⊓⊔
FRD on Modules. As explained in [4], FRD encoding in the module setting can
be built using an existing FRD encoding in the ring setting HM : M −→Rq
by constructing HM(m) · Id ∈Rd×d
q
for m ∈M and Id ∈Rd×d
q
is the identity
matrix.
3
Trapdoors on Lattices
The two IBE constructions make use of eﬃcient trapdoors, called gadget-
trapdoors, introduced in [28]. Such trapdoors were generalized to ideal lattices
in [21] and to module lattices in [4]. An eﬃcient instantiation of the sampling
algorithms was given in [17]. All those results allow us to eﬃciently instantiate
trapdoor generation and sampling algorithms. Having introduced the G-lattice
in the previous Section, we can now deﬁne the associated G-trapdoors.
Deﬁnition 5. A G-trapdoor for a matrix A ∈Rd×m
q
is a matrix R ∈
R(m−dk)×dk such that
A
	 R
Idk

= HG
for some invertible H ∈Rd×d
q
, called the tag of A.
The knowledge of the trapdoor R allows one to compute small vectors on
any coset of a given lattice, by sampling on the G-lattice ﬁrst, and then by using
R to map the sample to a small vector in the given lattice.

278
M. Izabachène et al.
3.1
Approximate Trapdoors for Module Lattices
As shown in [9], the gadget trapdoor proposed by Micciancio and Peikert can be
modiﬁed to an approximate trapdoor, in a way that further reduces the sizes of
the public matrix, the trapdoor and the preimage.
Deﬁnition 6 (AISISn,d,m,q,α,β). For any n, d, m, q ∈N and α, β ∈R, the
approximate inhomogeneous short integer solution problem AISISn,d,m,q,α,β is
deﬁned as follows: given A ∈Rd×m
q
, y ∈Rd
q, ﬁnd a vector x ∈Rm such that
||x|| ≤β and such that there is a vector z ∈Rd satisfying: ||z|| ≤α and
Ax = y + z mod q.
Deﬁnition 7 (Approximate Trapdoor). A string τ is called an (α, β)-
approxi mate trapdoor for a matrix A ∈Rd×m
q
if there is a probabilistic polyno-
mial time algorithm that given τ, A and any y ∈Rd
q, outputs a non-zero vector
x ∈Rm such that ||x|| ≤β and there is a vector z ∈Rd satisfying ||z|| ≤α and
Ax = y + z mod q.
In practice, we generate approximate trapdoors by dropping ℓentries corre-
sponding to the small powers of b from the gadget matrix G to get the following
matrix: F = Id ⊗f T = Id ⊗

bℓbℓ+1 bℓ+2 · · · bk−1
∈Rd×d(k−ℓ).
3.2
Module-LWE Approximate Trapdoors
In [9], the authors described the approximate trapdoor generation and the
approximate preimage sampling algorithms, adapted from [28] by making use
of the approximate gadget matrix F instead of G. Its trapdoor generation and
trapdoor preimage sampling algorithms over modules are recalled in Fig. 1 and
the result of the approximate sampling is stated in Theorem 1.
Theorem 1 ([9, Theorem 4.1]).
There exists probabilistic, polynomial time
algorithms ApproxTrapGen1(·) and ApproxSamplePre1(·) such that:
1. ApproxTrapGen1(H, σ) takes as input public parameters, a tag matrix H ∈
Rd×d and parameter σ > 0 and returns a matrix-approximate trapdoor pair
(A, R) ∈Rd×m
q
× R ¯m×ω where R coeﬃcients are drawn from a Gaussian
distribution of parameter σ over R .
2. Let A be generated with an approximate trapdoor as above. The following two
distributions are statistically indistinguishable:
{(A, x, u, y) | u ←U(Rd
q), x ←ApproxSamplePre1(A, R, 0, u, ζ), y = u −Ax mod q}
and {(A, x, u, y) | x ←DRm,ζ, y ←DRd,σ√
(b2ℓ−1)/(b2−1), u = Ax + y mod q}
for any σ ≥
√
b2 + 1 · ω(√log d) and ζ ≳
√
b2 + 1 s2
1(R)
s2d(R)ηϵ(Zdk).

Identity-Based Encryption from Lattices Using Approximate Trapdoors
279
3.3
iNTRU Approximate Trapdoors
In [16], Genise and Li introduced a family of Ring-SIS approximate trapdoors
whose pseudorandomness is based on the iNTRU problem and then showed that
the eﬃcient gadget-based trapdoor framework of [28] exists on a family of NTRU
lattices. Their trapdoor scheme enjoys small secret keys and is compatible with
applications requiring tag matrices.
In their second trapdoor scheme, the matrix
	
−eT
rI

is used as a f-trapdoor
for

1 a

=

1 r−1(f T + eT )

where (r, e) ←−χk−ℓ+1 is drawn from a distribu-
tion with small entries and f is the approximate gadget vector. They got the
following results, similar to the ones from [9].
ApproxTrapGen1(H, σ)
1.
¯
A ←U(Rd× ¯
m
q
)
2. R ←DR ¯
m×ω,σ
3. set A = [ ¯
A
HF −¯
AR ] ∈Rd×m
q
4. return (A, R)
ApproxSamplePre1(A, R, H, u, ζ)
1. sample perturbation p ←DRm,√
Σp
2. set coset v = H−1(u −Ap)
3. sample z = (zT
1 , zT
2 )T ←DΛvq (G),σg
4. set x = p +
 R
I

z2 ∈Rm
5. return x
ApproxTrapGen2(σ)
1. sample r ←−DR,σ, e ←−DRm,σ
2. set a′ = r−1(f + e) ∈Rm
3. set a = (1, a′) ∈Rm+1
q
4. set R =

−eT
rIm

∈R(m+1)×m
5. return (a, R)
ApproxSamplePre2(a, R, u, ζ)
1. sample perturbation p ←DRm+1,√
Σp
2. set coset v = (u −aT p) ∈Rq
3. sample z = (zT
1 , zT
2 )T ←DΛvq (gT ),σg
4. set x = p + Rz2 ∈Rm+1
5. return x
Fig. 1. Description of the approximate trapdoor generation and preimage sampling
algorithms based on [9] (on the left-hand side) and [16] (on the right-hand side) instan-
tiations, where the perturbation is sampled with parameter Σp = ζ2Im−σ2
g
 R
I

[ R T I ]
on the left side and Σp = ζ2Im+1 −σ2
gRRT on the right side. Both are independent
of the target u. We refer to [9,16] for more information on the iNTRU based trapdoor
generation.
Theorem 2.
Let r ←χ and eT ←χm and set the trapdoor function descrip-
tion as a =

1 a′
=

1 r−1(f + e)

∈Rm+1
q
. Let η = ηϵ(Zn×m) and
σg
= ηϵ(Λ⊥
q (gT )) ≥
√
b2 + 1 · ηϵ(Zn×m) for some ϵ ∈(0, 1) and ζ
⪰

σ2gRRT + η2Im+1. Then, the following distributions are within a max-log dis-
tance 3 log 1+ϵ
1−ϵ ≤
6ϵ
1−ϵ:
{(a, x, u, y) | u ←U(Rq), x ←ApproxSamplePre2(a, R, u, ζ), y = u −aT x ∈Rq}
and {(a, x, u, y) | x ←DRm+1,ζ, y ←DR,σe
mod q, u = aT x + y ∈Rq}
for σe = σg

(b2ℓ−1)/(b2 −1).

280
M. Izabachène et al.
4
An Approximate-IBE Scheme on Modules
The ﬁrst IBE scheme we present is the IBE scheme from [1,5] adapted to the
module setting, instantiated using the approximate trapdoors from [9]. At a high
level, the scheme will make use of the following blocks:
– The master secret key is an F -approximate trapdoor R ∈R ¯m×ω associated
with A with tag 0, with subgaussian coeﬃcients of parameter σ, with ω =
d(k −ℓ). The master public key is a tuple consisting of a uniformly random
vector u ∈Rd
q and the matrix A ∈Rd×m
q
, with m = ¯m + ω chosen as:
A =
 ¯
A −¯
AR

. Taking ¯m = d log q, we get that ¯
A is full rank with high
probability according to [7, Lemma 2.6]. Moreover, by taking σ > 4 · 4
1
nd √n,
we obtain that A is statistically close to uniform by Corollary 7.5 from [25].
– A “small-norm” FRD encoding HM as described in Sect. 2.3. This allows any-
one, with the knowledge of the master public key A, to compute a public
matrix Aid = A +
0d, ¯m
HidF 
associated with the identity id of a user.
Then, the secret key for id is an approximate short vector xid ∈Rm obtained
by using the ApproxSamplePre1 algorithm. Such a vector satisﬁes the rela-
tion Aidxid ≈u mod q. We can bound the approximate error in this relation
by using Theorem 1 and the fact that we use a small-norm FRD encoding.
– Finally, we use the Dual-Regev encryption scheme for the encryption and
decryption algorithms, taking care of the additional error which appears when
using approximate trapdoors.
4.1
Construction
We detail the ﬁrst IBE where users’ keys are deﬁned based on the approximate
preimage sampling from Theorem 1 and encryption is based on the Dual-Regev
scheme.
– Setup(1n) −→(mpk, msk):
• (A, R) ←ApproxTrapGen1(0, σ) ∈Rd×m
q
× R ¯m×w, u ←U(Rd
q);
• mpk = (A, u), msk = R.
– Extract(mpk, msk, id) −→skid x ∈Rm:
• Hid ←HM(id); Aid ←A +

0d, ¯m
HidF

∈Rd×m
q
;
• x ←ApproxSamplePre1(Aid, R, Hid, u, ζ);
– Encrypt(mpk, id, M) −→C = (b, c) ∈Rm+1
q
:
• Hid ←HM(id); Aid ←A +

0d, ¯m
HidF

∈Rd×m
q
;
• s ←DRd
q,τ, e0 ←DRm−w,τ, e1 ←DRw,γ, and e′ ←−DR,τ;
• b ←(sT Aid)T + (eT
0 | eT
1 )T and c ←sT u + e′ + ⌊q/2⌋M;
– Decrypt(skid, C) →M:
• set x = skid and compute res ←c −bT x which has integer coeﬃcients;
• for each i, if the coeﬃcient resi ∈Z is closer to ⌊q/2⌋than to 0, then
Mi = 1, otherwise Mi = 0.

Identity-Based Encryption from Lattices Using Approximate Trapdoors
281
Correctness. To use approximate trapdoors with the Dual-Regev approach, we
need to sample the LWE secret term with a small norm instead of sampling from
the uniform distribution, in order to maintain the correctness of the schemes.
Let’s write y ∈Rd
q the additional error we get by using approximate trapdoors
instead of exact ones. The correctness of the decryption holds if the error term
∥e′ −(eT
0 | eT
1 )x −sT y∥is small enough, i.e. less than ⌊q/4⌋.
res = c −bT x
= u · s + e′ + ⌊q/2⌋M −

(sT Aid)T + (eT
0 | eT
1 )T T x
= u · s + e′ + ⌊q/2⌋M −sT Aidx −(eT
0 | eT
1 )x
= u · s + e′ + ⌊q/2⌋M −sT (u + y) −(eT
0 | eT
1 )x
= e′ −(eT
0 | eT
1 )x −sT y



error term
+⌊q/2⌋M ∈R.
So we need to choose our parameters properly for the correctness of the Dual-
Regev encryption to hold. We can bound as follows the euclidean norms of the
quantities that appear in the error term:
– ∥e′∥≤tτ√n from Lemma 2.
– ∥eT
0 x0∥≤2t2τζnd from Lemma 2 and Theorem 1.
– ∥eT
1 x1∥≤t2γζnd(k −ℓ) from Lemma 2 and Theorem 1.
– ∥sT y∥≤t2τn5/2dσg
q1/r
√r

(b2ℓ−1)/(b2 −1) from Lemma 2 and Theorem 1.
By substituting these bounds, we get the following constraints:
∥e′ −(eT
0 | eT
1 )x −sT y∥≤∥e′∥+ ∥(eT
0 | eT
1 )∥+ ∥sT y∥
≤tτ√n + t2nd

ζ (2τ + γ(k −ℓ)) + τn3/2σg
q1/r
√r

(b2ℓ−1)/(b2 −1)

≤⌊q/4⌋.
Parameter Constraints. The following constraints, combined with the norms
bounds above, must be met to ensure correctness:
– The Gaussian parameter σg used for the G-sampling in the ApproxSamplePre1
algorithm must verify σg ≥
√
2b · (2b + 1) ·

log(2nw(1 + 1/ϵ))/π (see [17],
Corollary 3.1).
– The Gaussian width for preimage sampling ζ must follow the condition ζ >

(σ2g + 1)s2
1(R) + η2ε(Znm), knowing that s1(R) < 1.1σ(
√
2nd + √nw + 4.7)
with high probability (see [4], Section A.3), where s1(R) is the spectral norm
of the trapdoor R.
– The Gaussian width for approximate trapdoor generation σ must verify σ >
4·4
1
nd √n to ensure the public matrix A we use is statistically close to uniform
(see [25], Corollary 7.5).

282
M. Izabachène et al.
– We choose to set the Gaussian parameter γ of the Gaussian error e1 ∈Rw
as γ2 = σ2∥e0∥2 + 2nt2σ2τ 2.
The proof of the following Theorem 3 is standard and can be found in the
Supplementary materials, Appendix B.
Theorem 3. The IBE construction with parameters n, d, m, q, k, ℓ, σ, α, ζ, τ and
γ, chosen as in the above description, is IND-sID-CPA secure in the standard
model under the hardness of Module-LWEn,d,q,τ.
4.2
Implementation and Performance
The scheme is implemented in C, using [4] libraries, inheriting its modularity. It
relies on several basic blocks that can be swapped out: the arithmetic over Zq
and Rq, a pseudorandom number generator, and a (constant-time) sampler of
discrete Gaussian distributions over Z. To generate our speciﬁc discrete Gaus-
sian distributions, we make use of the following building blocks: an AES-based
pseudorandom number generator (implemented using AES-NI instructions for
x86 architectures), and a sampler of discrete Gaussians over Z similar to Kar-
ney’s sampler [19]. We chose this sampler as it can generate samples in constant
time, independently of the center, Gaussian parameter, and output value. All
the computations that deal with non-integers are carried out with ﬂoating-point
operations that do not involve subnormal numbers. We rely on results from [26,
Lemma 3] to reduce multiplications in Rq to polynomials multiplications in rings
of the form Zq[X]/⟨Xn+1⟩. The CRT reduction we used then allowed us to speed
up polynomial arithmetic in Rq.
To assess the security of each parameter set, we estimate the pseudorandom-
ness of the public key (corresponding to the LWE security) and the hardness of
breaking AISIS. The estimation of the LWE security is done with the LWE esti-
mator of [2] with BKZ as the reduction model. We approximate our instances by
an instance of an unstructured LWE problem in dimension nd. We follow a very
pessimistic core-SVP hardness, where the cost of a BKZ algorithm with blocksize
κ is taken to be the cost of only one call to an SVP oracle in dimension κ. For
the AISIS problem, we follow the approach of [9] which consists in computing
the smallest blocksize achieving the target root Hermite factor corresponding to
forging a signature.
Timings. As expected, the 4 algorithms are more eﬃcient for low value of d.
Concerning the Decrypt algorithm, its execution time relies mostly on the value
of n rather than d. Our timings have been obtained on an Intel i7-8650U CPU
running at 1.9 GHz, and then scaled at 4.2GHz to compare ourselves with other
schemes. We provide concrete parameters sets and the associated concrete results
in Table 2.

Identity-Based Encryption from Lattices Using Approximate Trapdoors
283
Table 2. Proposed IBE parameters for our ﬁrst construction of Sect. 4 with diﬀerent
pairs of polynomial ring dimension n and rank d, for diﬀerent moduli sizes and taking
σg = 54.9, σ = 64.1. σg is the Gaussian parameter for the G-Sampling, σ is the
Gaussian width of the trapdoor R used in the Setup algorithm and ζ is the standard
deviation for the Gaussian preimage sampling in the Extract algorithm. Timings in
columns Setup-to-Encrypt are given in ms. M −LWEn,d,q,τ denotes the concrete bit
security of the scheme.
⌈log2 q⌉(n, d)
ℓ
ζ
Setup
Extract Encrypt Decrypt
M −LWEn,d,q,τ
58
(256, 4)
0
1137729
203.52
56.88
17.69
2.72
81
58
(256, 4)
8
1068989
174.94
49.82
15.00
2.40
80
58
(256, 4)
15
1004226
152.70
41.57
12.79
2.19
78
60
(512, 3)
0
1398812
210.85
67.28
19.20
4.06
110
60
(512, 3)
8
1315427
189.35
59.33
17.13
3.80
109
60
(512, 3)
15
1236981
160.33
53.39
14.00
3.22
107
Table 3. Comparison of timings in ms of the diﬀerent operations of the IBE scheme
between this paper and [4] for parameters giving an equivalent level of security.
Scheme
(n, d)
Setup
Extract Encrypt Decrypt
[4] (ℓ= 0)
(512, 2) 123.62 45.80
13.12
2.91
[4] (ℓ= 0)
(256, 4) 234.45 67.90
17.88
2.69
This paper (ℓ= 15) (512, 2)
79.10 29.44
10.09
2.36
This paper (ℓ= 15) (256, 4) 152.70 41.57
12.79
2.19
Comparison with Related Work. We compare our IBE performance with the IBE
from [4], which corresponds to the case ℓ= 0, that is to say the use of exact
trapdoors instead of approximate ones. We observe that for a ﬁxed pair (n, d),
the larger ℓis, the better timings are. Overall, the use of approximate trapdoors
allows us to obtain better timings for all the algorithms comprising the IBE
scheme.
5
An IBE Scheme Based on the Hardness of iNTRU
In this Section, we introduce the IBE2 scheme, instantiated using gadget-based
approximate trapdoors over iNTRU trapdoors combined with the Dual-Regev
encryption scheme over modules.
We recall that m = k −ℓwhere k = ⌈logb q⌉and that the approximate
gadget vector f is deﬁned as f T =

bℓbℓ+1 bℓ+2 · · · bk−1
∈Rk−ℓ. Here, the
master public key is a vector a ∈Rm+1
q
generated with the ApproxTrapGen2
algorithm and whose pseudorandomness is based on the iNTRU problem. The
master secret key r, e ∈Rm+1 deﬁnes an f-approximate trapdoor associated
with a. An identity is mapped to an element in Rq by the use of a hash function

284
M. Izabachène et al.
modeled as a random oracle in the security proof; the secret key associated with
an identity id is an approximate short vector x ∈Rm+1.
5.1
IBE Construction Details
We detail below the four algorithms of the IBE2:
– Setup(1n) −→(mpk, msk):
• let a =

1 aT
0
T ∈Rm+1
q
and R =
	
−eT
rIm

∈R(m+1)×m output by
ApproxTrapGen2(σ); and let H : {0, 1}⋆→Rq a hash function;
• output mpk = (a, H) and msk = R.
– Extract(mpk, msk, id) →xid = x2 ∈Rm:
• deﬁne the tag hid = H(id) ∈Rq;
• sample a short preimage x = (x1, x2T )T ←ApproxSamplePre2(a, R,
hid, ζ);
– Encrypt(mpk, id, M) →C = (b, c) ∈Rm+1
q
:
• compute hid = H(id); sample s ←DR,τ, e1 ←DRm,τ, e2 ←DR,τ;
• compute b = sa0 + e1 ∈Rm
q and c = hid · s + e2 + ⌊q/2⌋M ∈Rq, where
a message is encoded as M ∈R2;
– Decrypt(xid, C) →M:
• parse xid as (x1, x2); and compute res ←c −bT x2;
• for each i, if the coeﬃcient resi ∈Z is closer to ⌊q/2⌋than to 0, Mi = 1,
otherwise Mi = 0.
Correctness. We have the following equality:
c −bT x2 = hid · s + e2 + ⌊q/2⌋M −(sa0 + e1)T x2
= s · x1 + saT
0 x2 −y · s + e2 + ⌊q/2⌋M −saT
0 x2 −eT
1 x2
= ⌊q/2⌋M + s · (x1 −y) + e2 −eT
1 x2.
Furthermore, the following bounds apply:
– ∥s · x1∥≤t2τζn from Lemma 2 and Theorem 2.
– ∥y · s∥≤t2τσg

(b2ℓ−1)/(b2 −1)n from Lemma 2 and Theorem 2.
– ∥e2∥≤tτ√n from Lemma 2.
– ∥eT
1 x2∥≤t2τζnm from Lemma 2 and Theorem 2.
By substituting these bounds, we obtain:
∥s · (x1 −y) + e2 −eT
1 x2∥≤∥s · x1∥+ ∥y · s∥+ ∥e2∥+ ∥eT
1 x2∥
≤t2τ
	
ζ (m + 1) + σg

(b2ℓ−1)/(b2 −1)

+ tτ√n
≤⌊q/4⌋.

Identity-Based Encryption from Lattices Using Approximate Trapdoors
285
Parameters Constraints. The following constraints combined with the errors
norm constraints above should be satisﬁed:
– The Gaussian parameter σg used for the G-sampling in the ApproxSamplePre2
algorithm must verify σg ≥
√
2b · (2b + 1) ·

log(2nw(1 + 1/ϵ))/π (see [17],
Corollary 3.1).
– The Gaussian width for preimage sampling ζ must follow the condition ζ >

(σ2g + 1)s2
1(R) + η2ε(Znm), where s1(R) is the spectral norm of the trapdoor
R (see [4], Section A.3).
The proof of the following is adapted from the GPV IBE proof [18,
Section 7.2] and is given in the Supplementary materials, Appendix C.
Theorem 4. Our IBE construction with parameters n, m, q, k, ℓ, σ, σg, ζ, τ and
γ is IND-sID-CPA secure in the random oracle model under the hardness of
iNTRUq,DR,σ and Ring-LWEn,q,τ.
5.2
Implementation and Performance
In [15], the authors only propose a reduction from a non-standard version of LWE
to iNTRU. Therefore, in the absence of a thorough study on the asymptotic and
practical security of the iNTRU problem, which we leave for future work, we have
chosen to estimate the security of our iNTRU instances by relying on the existing
cryptanalysis on NTRU. As explained in [15], there is a syntactic link between
NTRU and iNTRU. To the best of our knowledge, there is no known reduction
between the two problems and the analysis of the iNTRU assumption might
deserve additional study. Still, we additionally consider the practical security of
NTRU for our targetted sets of parameters and we take into account the known
cryptanalysis eﬀorts on iNTRU.
For security estimation, we follow the same approach as in [16] to assess
the concrete security of the IBE2 scheme. We determine the hardness of our
underlying lattice problem by computing the root Hermite factor, introduced in
[14]. Then, we use the following heuristic relation between the blocksize κ and
the root Hermite factor δ to ﬁnd the smallest blocksize which would break our
underlying lattice problem:
δ ≈( κ
2πe(πκ)1/κ)1/2(κ−1).
Finally, our experiments estimate the running time of the BKZ algorithm
to analyze the concrete security of the scheme. This algorithm makes use of an
oracle to solve the Shortest Vector Problem (SVP) in smaller lattices. We chose
the “Core-SVP” model introduced in [3] in the sieving regime as the SVP oracle
for the BKZ algorithm with time complexity 20.292κ+16.4 in the blocksize κ.

286
M. Izabachène et al.
Overstretched Parameters. [23] adapts the attack from [20] on iNTRU, which
applies to the parameters originally proposed for the homomorphic encryption
scheme from [15]. The attack can be performed when the modulus q is much
larger than the dimension of the associated lattices. The target iNTRU instance
has an error and secret that follow a uniform binary distribution. Following
[20] attack, [23] uses the fact that a very dense sublattice can be found in this
NTRU-like lattice, because of the overstretched regime. Relying on a lemma from
Pataki and Tural [30, Lemma 1], they can bound the volume of this sublattice
and run a BKZ-reduction which leads to a full recovery of the iNTRU secret. [12]
improves the asymptotic bound given by Kirchner and Fouque [20] by conducting
a reﬁned analysis which lowers the overstretched regime for NTRU with ternary
distribution to the value q = n2.484+o(1).
They also provide a concrete analysis, computing a bound on the modulus q
for which the attacks exploiting the overstretched regime are more eﬃcient than
standard secret key recovery attacks. The authors of [12] run experiments which
allow detecting the fatigue “point”, which separates these two regimes.
The cryptanalysis carried out by [23] and [12] can be adapted for the iNTRU
instances we consider, where the secret and the error both follow a Gaussian
distribution. [12] also consider the case where the NTRU secret distributions are
Gaussian. Indeed, in both cases, the cryptanalysis in the overstretched regime
requires performing lattice reductions on sublattices of a NTRU-like lattice, in
order to retrieve the very dense sublattice. We leave the detailed adaptation of
this attack to iNTRU and its experimental study for future work. For our concrete
parameters analysis, we took care to fall outside the range of parameters aﬀected
in the overstretched regime.
Timings. Our timings have been obtained on an Intel i7-8650U CPU running at
1.9 GHz, and then scaled at 4.2 GHz to compare ourselves with other schemes.
Results are provided in Table 4. The use of the eﬃcient gadget-based approxi-
mate trapdoor framework together with the iNTRU hardness assumption allows
us to obtain eﬃcient algorithms. The slowest of the 4 algorithms of the IBE2
scheme are the Setup and Extract algorithms, which correspond respectively
to the approximate trapdoor generation and preimage sampling phases of the
scheme. However, the Setup algorithm is usually not performed often, and the
subroutine algorithms used by Extract for sampling are really modular, leaving
the way for possible future improvements. Moreover, our Setup and Extract algo-
rithms are competitive with other NTRU-based IBE (see Table 5 and Table 6).
Comparison with Related Works. We compare the IBE2 timings with the ones
of [11] (re-implemented in [27]) and with [33], two IBE schemes whose security
is based on the NTRU hardness assumption. Our comparison experiments were
carried out using equivalent parameters sets between the diﬀerent schemes. In
particular, we have been careful to use equivalent module sizes and equivalent
noise rates when performing Gaussian Sampling.

Identity-Based Encryption from Lattices Using Approximate Trapdoors
287
Table 4. Timings of the diﬀerent operations for diﬀerent values of n, given in ms from
Setup to Decrypt.
(n, q)
⌈log2(q)⌉Setup Extract Encrypt Decrypt Bit security
(256, 1073741441)
30
1.01
2.13
0.39
0.03
64
(512, 1073741441)
30
2.12
3.79
0.74
0.06
115
(1024, 1073741441) 30
4.08
7.65
1.49
0.11
223
(256, 16777601)
25
0.78
1.66
0.23
0.02
35
(512, 16777601)
25
1.48
3.00
0.49
0.04
82
(1024, 16777601)
25
3.32
5.92
1.10
0.07
159
Table 5. Timings comparison of the diﬀerent operations of the IBE scheme between
this paper and [11] (the timings are extracted from the [27] article, scaled up to account
for CPU diﬀerences) for diﬀerent parameter sets. The timings are given in ms, except
for the Setup algorithm from [11], which is given in seconds.
Scheme
(n, ⌈log2(q)⌉) Security level Setup
Extract Encrypt Decrypt
[11]
(512, 26)
< 80
3.84s
1.77
0.10
0.05
[11]
(1024, 26)
< 192
23.93s 6.95
0.27
0.09
This paper (512, 25)
82
1.48
3.00
0.49
0.04
This paper (1024, 25)
159
3.32
5.92
1.10
0.07
Table 6. Timings comparison of the diﬀerent operations of the IBE scheme in this
paper and in [33] for diﬀerent sets of parameters in ms.
Scheme
(n, ⌈log2(q)⌉) Security level Setup Extract Encrypt Decrypt
[33]
(1024, 24)
128
102
0.82
0.05
0.06
[33]
(2048, 25)
256
292
2.62
0.10
0.13
[33]
(1024, 36)
80
165
26.4
0.08
0.09
[33]
(2048, 38)
160
643
57.8
0.16
0.18
This paper (1024, 25)
159
3.32
5.92
1.10
0.07
This paper (2048, 25)
293
10.21
12.79
2.96
0.16
This paper (1024, 30)
191
4.08
7.65
1.49
0.11
This paper (2048, 30)
412
12.51
16.03
3.89
0.23
We observe that we obtain better timings for the Setup algorithm than [11]
and [33] and for the Extract for some sets of parameters. Furthermore, our
Decrypt algorithm is slightly faster than [11]. However, the Encrypt algorithm
is less eﬃcient than theirs. The use of binomial distribution improves the tim-
ings for encryption. An improvement can be obtained in our case by using the
binomial distribution, but we need more samples in our case which still aﬀects
performance for encryption; we make n(2 + m) calls to the integer Gaussian

288
M. Izabachène et al.
sampler while encryption in [11] and [33] can make use of only 3n binomial sam-
pling calls. As in [33], our Extract algorithm is slower than the Sign algorithm
from the Falcon signature scheme [13]. Note also that for a similar security level,
Falcon can use smaller parameters than us.
We obtain an overhead in terms of parameters sizes compared to [11] and
[33], but the trapdoor generations rely on a diﬀerent paradigm. Results on public
and secret sizes are provided in Appendix D. Nonetheless, as stated in [9], the
use of approximate trapdoors instead of exact ones helps us to reduce the sizes
of the public key and signatures by up to two times. Therefore, as expected, our
obtained sizes for the master and the users’ private keys and the ciphertexts are
close to the ones of [16] whose signature scheme relies on the same paradigm as
the IBE2 scheme.
Acknowledgements. This work is supported by the ANR ASTRID project AMIRAL
(ANR-21-ASTR-0016).
References
1. Agrawal, S., Boneh, D., Boyen, X.: Eﬃcient lattice (H)IBE in the standard model.
In: Gilbert, H. (ed.) EUROCRYPT 2010. LNCS, vol. 6110, pp. 553–572. Springer,
Heidelberg (2010). https://doi.org/10.1007/978-3-642-13190-5_28
2. Albrecht, M.R., Player, R., Scott, S.: On the concrete hardness of learning with
errors. J. Math. Cryptol. 9, 169–203 (2015)
3. Alkım, E., Ducas, L., Pöppelmann, T., Schwabe, P.: Post-quantum key exchange
- a new hope. In: USENIX Security Symposium (2016)
4. Bert, P., Eberhart, G., Prabel, L., Roux-Langlois, A., Sabt, M.: Implementation of
lattice trapdoors on modules and applications. In: Cheon, J.H., Tillich, J.-P. (eds.)
PQCrypto 2021 2021. LNCS, vol. 12841, pp. 195–214. Springer, Cham (2021).
https://doi.org/10.1007/978-3-030-81293-5_11
5. Bert, P., Fouque, P., Roux-Langlois, A., Sabt, M.: Practical Implementation of
Ring-SIS/LWE Based Signature and IBE (2018)
6. Boneh, D., Franklin, M.: Identity-based encryption from the Weil pairing. In: Kil-
ian, J. (ed.) CRYPTO 2001. LNCS, vol. 2139, pp. 213–229. Springer, Heidelberg
(2001). https://doi.org/10.1007/3-540-44647-8_13
7. Boudgoust, K., Jeudy, C., Roux-Langlois, A., Wen, W.: On the hardness of module
learning with errors with short distributions. J. Cryptol. 28(1), 1 (2023)
8. Cash, D., Hofheinz, D., Kiltz, E., Peikert, C.: Bonsai trees, or how to delegate a
lattice basis. In: Gilbert, H. (ed.) EUROCRYPT 2010. LNCS, vol. 6110, pp. 523–
552. Springer, Heidelberg (2010). https://doi.org/10.1007/978-3-642-13190-5_27
9. Chen,
Y.,
Genise,
N.,
Mukherjee,
P.:
Approximate
trapdoors
for
lattices
and smaller hash-and-sign signatures. In: Galbraith, S.D., Moriai, S. (eds.) ASI-
ACRYPT 2019. LNCS, vol. 11923, pp. 3–32. Springer, Cham (2019). https://doi.
org/10.1007/978-3-030-34618-8_1
10. Cocks, C.: An identity based encryption scheme based on quadratic residues. In:
Honary, B. (ed.) Cryptography and Coding 2001. LNCS, vol. 2260, pp. 360–363.
Springer, Heidelberg (2001). https://doi.org/10.1007/3-540-45325-3_32

Identity-Based Encryption from Lattices Using Approximate Trapdoors
289
11. Ducas, L., Lyubashevsky, V., Prest, T.: Eﬃcient identity-based encryption over
NTRU lattices. In: Sarkar, P., Iwata, T. (eds.) ASIACRYPT 2014. LNCS, vol.
8874, pp. 22–41. Springer, Heidelberg (2014). https://doi.org/10.1007/978-3-662-
45608-8_2
12. Ducas, L., van Woerden, W.: NTRU fatigue: how stretched is overstretched? In:
Tibouchi, M., Wang, H. (eds.) ASIACRYPT 2021. LNCS, vol. 13093, pp. 3–32.
Springer, Cham (2021). https://doi.org/10.1007/978-3-030-92068-5_1
13. Fouque, P.-A., et al.: Fast- Fourier Lattice-based Compact Signatures over NTRU
(2017)
14. Gama, N., Nguyen, P.Q.: Predicting lattice reduction. In: Smart, N. (ed.) EURO-
CRYPT 2008. LNCS, vol. 4965, pp. 31–51. Springer, Heidelberg (2008). https://
doi.org/10.1007/978-3-540-78967-3_3
15. Genise, N., Gentry, C., Halevi, S., Li, B., Micciancio, D.: Homomorphic encryption
for ﬁnite automata. In: Galbraith, S.D., Moriai, S. (eds.) ASIACRYPT 2019. LNCS,
vol. 11922, pp. 473–502. Springer, Cham (2019). https://doi.org/10.1007/978-3-
030-34621-8_17
16. Genise, N., Li, B.: Gadget-based iNTRU lattice trapdoors. In: Bhargavan, K.,
Oswald, E., Prabhakaran, M. (eds.) INDOCRYPT 2020. LNCS, vol. 12578, pp.
601–623. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-65277-7_27
17. Genise, N., Micciancio, D.: Faster gaussian sampling for trapdoor lattices with
arbitrary modulus. In: Nielsen, J.B., Rijmen, V. (eds.) EUROCRYPT 2018. LNCS,
vol. 10820, pp. 174–203. Springer, Cham (2018). https://doi.org/10.1007/978-3-
319-78381-9_7
18. Gentry, C., Peikert, C., Vaikuntanathan, V.: Trapdoors for hard lattices and new
cryptographic constructions. In: STOC (2008)
19. Karney, C.F.F.: Sampling exactly from the normal distribution. ACM Trans. Math.
Softw. 42(1), 3:1–3:14 (2016)
20. Kirchner, P., Fouque, P.-A.: Revisiting lattice attacks on overstretched NTRU
parameters. In: Coron, J.-S., Nielsen, J.B. (eds.) EUROCRYPT 2017. LNCS,
vol. 10210, pp. 3–26. Springer, Cham (2017). https://doi.org/10.1007/978-3-319-
56620-7_1
21. Lai, R.W.F., Cheung, H.K.F., Chow, S.S.M.: Trapdoors for ideal lattices with
applications. In: Lin, D., Yung, M., Zhou, J. (eds.) Inscrypt 2014. LNCS, vol.
8957, pp. 239–256. Springer, Cham (2015). https://doi.org/10.1007/978-3-319-
16745-9_14
22. Langlois, A., Stehlé, D.: Worst-case to average-case reductions for module lattices.
DCC 75(3), 565–599 (2015)
23. Lee, C., Wallet, A.: Lattice analysis on MiNTRU problem. Cryptology ePrint
Archive, Paper 2020/230 (2020)
24. Lyubashevsky, V.: Lattice signatures without trapdoors. In: Pointcheval, D.,
Johansson, T. (eds.) EUROCRYPT 2012. LNCS, vol. 7237, pp. 738–755. Springer,
Heidelberg (2012). https://doi.org/10.1007/978-3-642-29011-4_43
25. Lyubashevsky, V., Peikert, C., Regev, O.: A toolkit for ring-LWE cryptography.
In: Johansson, T., Nguyen, P.Q. (eds.) EUROCRYPT 2013. LNCS, vol. 7881, pp.
35–54. Springer, Heidelberg (2013). https://doi.org/10.1007/978-3-642-38348-9_3
26. Lyubashevsky, V., Seiler, G.: Short, invertible elements in partially splitting cyclo-
tomic rings and applications to lattice-based zero-knowledge proofs. In: Nielsen,
J.B., Rijmen, V. (eds.) EUROCRYPT 2018. LNCS, vol. 10820, pp. 204–224.
Springer, Cham (2018). https://doi.org/10.1007/978-3-319-78381-9_8

290
M. Izabachène et al.
27. McCarthy, S., Smyth, N., O’Sullivan, E.: A practical implementation of identity-
based encryption over NTRU lattices. In: O’Neill, M. (ed.) IMACC 2017. LNCS,
vol. 10655, pp. 227–246. Springer, Cham (2017). https://doi.org/10.1007/978-3-
319-71045-7_12
28. Micciancio, D., Peikert, C.: Trapdoors for lattices: simpler, tighter, faster, smaller.
In: Pointcheval, D., Johansson, T. (eds.) EUROCRYPT 2012. LNCS, vol. 7237, pp.
700–718. Springer, Heidelberg (2012). https://doi.org/10.1007/978-3-642-29011-
4_41
29. Micciancio, D., Regev, O.: Worst-case to average-case reductions based on gaussian
measures. SIAM J. Comput. 37, 267–302 (2007)
30. Pataki, G., Tural, M.: On sublattice determinants in reduced bases. In: arXiv
preprint arXiv:0804.4014 (2008)
31. Shamir, A.: Identity-based cryptosystems and signature schemes. In: Blakley, G.R.,
Chaum, D. (eds.) CRYPTO 1984. LNCS, vol. 196, pp. 47–53. Springer, Heidelberg
(1985). https://doi.org/10.1007/3-540-39568-7_5
32. Zhang, S., Yu, Y.: Towards a Simpler Lattice Gadget Toolkit. In: Hanaoka, G.,
Shikata, J., Watanabe, Y. (eds.) Public-Key Cryptography – PKC 2022. PKC
2022. LNCS, vol. 13177, pp. 498–520. Springer, Cham (2022). https://doi.org/10.
1007/978-3-030-97121-2_18
33. Zhao, R.K., McCarthy, S., Steinfeld, R., Sakzad, A., O’Neill, M.: Quantumsafe
HIBE: does it cost a Latte? ePrint Archive (2021)

Homomorphic Signatures for Subset
and Superset Mixed Predicates and Its
Applications
Masahito Ishizaka(B) and Kazuhide Fukushima
KDDI Research, Inc., Saitama, Japan
{xma-ishizaka,ka-fukushima}@kddi.com
Abstract. In homomorphic signatures for subset predicates (HSSB),
each message (to be signed) is a set. Any signature on a set M allows
us to derive a signature on any subset M ′ ⊆M. Its superset version,
which should be called homomorphic signatures for superset predicates
(HSSP), allows us to derive a signature on any superset M ′ ⊇M. In
this paper, we propose homomorphic signatures for subset and superset
mixed predicates (HSSM) as a simple combination of HSSB and HSSP.
In HSSM, any signature on a message of a set-pair (M, W) allows us to
derive a signature on any (M ′, W ′) such that M ′ ⊆M and W ′ ⊇W. We
propose an original HSSM scheme which is unforgeable under the deci-
sional linear assumption and completely context-hiding. We show that
HSSM has various applications, which include disclosure-controllable
HSSB, disclosure-controllable redactable signatures, (key-delegatable)
superset/subset predicate signatures, and wildcarded identity-based sig-
natures.
Keywords: Homomorphic signatures for subset and superset mixed
predicates · Unforgeablity · Complete context-hiding · Decisional linear
assumption
1
Introduction
P-Homomorphic Signatures ( P-HS) [5]. In ordinary digital signatures, if a
signed massage is partially altered, its signature immediately turns invalid. In
P-HS for a predicate P : M × M →1/0, any signature on any message M
allows any user to derive a signature on any message M ′ satisfying the predi-
cate, i.e., 1 ←P(M, M ′). Strong context-hiding (SCH) [5] is a strong privacy
(or unlinkability) related security notion, which guarantees that any signature
derived from any signature which has been honestly generated distributes as
a fresh signature directly generated by the secret-key. Complete context-hiding
(CCH) [6] is a stronger notion, which guarantees that any signature derived from
any valid signature (which might have been dishonestly generated) distributes
as a signature generated by the secret-key. Redactable signatures (RS) [22] is
a subclass of P-HS. We can partially redact, i.e., black-out, a signed message
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 291–319, 2023.
https://doi.org/10.1007/978-3-031-35486-1_14

292
M. Ishizaka and K. Fukushima
while retaining validity of the signature. In append-only signatures (AOS) [17],
we can repeatedly add any message to the tail of a signed message. In quotable
signatures [5,7], we can extract any substring from a signed message.
HS for Subset Predicates (HSSB) [5,6]. HSSB is also a subclass of P-HS. Each
message is a set. Any signature on a set M derives a signature on any subset
M ′ ⊆M. Ahn et al. [5] proposed a generic SCH-secure transformation into HSSB
from attribute-based encryption (ABE) [8] satisfying a property that any secret-
key for an attribute-set A allows us to derive a perfectly re-randomized secret-
key for any subset A′ ⊆A. Attrapadung et al. [6] proposed an HSSB scheme
which is CCH-secure and unforgeable under the decisional linear (DLIN) and
q-simultaneous ﬂexible paring (SFP) assumptions w.r.t. a symmetric pairing e :
G×G →GT , built by the Groth-Sahai non-interactive witness indistinguishable
(GS NIWI) proof [15], Waters signatures [23] and Abe-Haralambiev-Ohkubo
structure-preserving signatures (AHO SPS) [3,4]. In key-generation, a signer
generates a long-term AHO key-pair. When signing a message M, the signer
generates a one-time Waters key-pair (gx, x), where x is chosen uniformly at
random from Zp, i.e., x
U
←−Zp, and g is a generator of G, then generates an
AHO signature on the Waters public-key gx. The signer generates a Waters
signature on every m ∈M, then generates GS proofs that the AHO signature is
valid and every Waters signature on m ∈M is valid.
HS for Superset Predicates (HSSP) [20]. HSSP is the superset counterpart of
HSSB. It is called history-hiding append-only signatures (H2AOS) in [20]. Any
signature on a set M derives a signature on any superset M ′ ⊇M. Libert
et al. [20] proposed a CCH-secure HSSP scheme based on the similar tech-
nique to the Attrapadung et al.’s HSSB scheme. It is built by an arbitrary SPS
scheme satisfying unforgeability against extended random messages attacks [2],
GS NIWI proof [15], and Boneh-Lynn-Shacham (BLS) signatures [11] instan-
tiated by the Waters programmable hash function HG [23]. In key-generation,
a signer generates a long-term key-pair of the SPS scheme. When the signer
signs a message W, she generates a fresh one-time BLS key-pair (Y, y), where
Y := gy with y
U
←−Zp. The signer divides the BLS secret-key y into |W| num-
ber of shares by using |W|-out-of-|W| secret sharing. Speciﬁcally, she randomly
chooses {γw ∈Zp}w∈W s.t. 
w∈W γw = y (mod p). For each w ∈W, she com-
putes (σw,1, σw,2) := (HG(w)γw, gγw) ∈G2, where σw,1 is a BLS signature on w
under the pseudo BLS public-key σw,2. The signer also generates a SPS signature
(θ1, · · · , θlsps) ∈Glsps on Y ∈G. The signer ﬁnally generates a GS proof that
(1) the SPS signature on Y is valid, (2) the BLS signature σw,1 on w under the
public-key σw,2 is valid for each w ∈W and (3) 
w∈W σw,2 = Y .
1.1
Our Contributions
HS for Subset and Superset Mixed Predicates (HSSM). We formally deﬁne HSSM
as a simple combination of HSSB and HSSP. Any signature on a message of a set-
pair (M, W) allows us to derive a signature on any (M ′, W ′) such that M ′ ⊆M

Homomorphic Signatures for Subset and Superset Mixed Predicates
293
and W ′ ⊇W. As P-HS [5,6], we deﬁne unforgeability and strong/complete
context-hiding (SCH/CCH). Unforgeability is a security notion required for any
P-HS. We emphasize the importance of SCH and CCH by using the following
example similar to an example in [12] used to emphasize the importance of
unlinkability for sanitizable signatures. Given an honestly-generated signature σ
on a set-pair (M, W), we honestly derive signatures σ1 and σ2 on (M1, W1) and
(M2, W2), respectively, then open only the derived signatures to the public. If
the HSSM scheme is SCH, both σ1 and σ2 are independent of σ and the link
between σ1 and σ2 is unseen. Otherwise, it is possible that the link is seen. In this
case, the following two types of private information are leaked, (1) M contains
at least M1 ∪M2 as a subset, and (2) every element in W1 ∩W2 is older data
than any element in W1 \(W1 ∩W2) and in W2 \(W1 ∩W2). If the HSSM scheme
is CCH, even when the signatures σ, σ1 and σ2 have been dishonestly generated,
the same security is guaranteed. Thus, CCH is more desirable. If the number
of the derived signatures is n > 2, a non-SCH HSSB scheme can cause a more
serious problem, e.g., we can guess that M contains at least n
i=1 Mi.
Our HSSM Scheme. Our HSSM scheme is a simple combination of the Attra-
padung et al.’s HSSB scheme [6] and the Libert et al.’s HSSP schemes [20]. As
the underlying SPS scheme, we use the AHO SPS scheme [3,4] with message
space G2. On signature generation, a fresh one-time Waters key-pair (X, x) and
BLS key-pair (Y, y) are generated, where X := gx and Y := gy with x, y
U
←−Zp.
An AHO signature (θ1, · · · , θ7) on (X, Y ) ∈G2 is generated. As the HSSB
scheme [6], for each m ∈M, a Waters signature (σm,1, σm,2) on m is generated.
As the HSSP scheme [20], the original BLS secret-key y ∈Zp is divided into
|W| number of shares {γw ∈Zp}w∈W by |W|-out-of-|W| secret sharing, then
for each w ∈W, a BLS signature σw,1 on w under the pseudo BLS public-key
gγw(=: σw,2) is generated. Finally, the GS proof is properly generated.
We show that HSSM has following ﬁve applications.
Application 1: Disclosure-Controllablwe (DC) HSSB. In the ordinary HSSB
[5,6], any sub-message m ∈M can be deleted anytime. For some realistic appli-
cations of HSSB, there might be a case where we would like to make some
sub-messages undeletable. For instance, HSSB can be used to prove one’s cre-
dentials. A person named Alice is given an HSSM signature on a message M
including her identiﬁable information (e.g., name, her birth date) and all of her
credentials. When she proves that she has all of the required credentials to an
organization, she might want to hide all of the unrequired credentials. In this
application, her identiﬁable information is usually not deleted in any situation.
Even in the ordinary HSSB, when and only when the original signature is gen-
erated, some sub-messages can be designated as undeletable. For instance, for a
message M = {A, B, C}, if the signer wants to make B undeletable, she produces
a special sub-message D stating that B is undeletable and signs the updated set
M ′ := M ∪{D}. This simple approach has a problem that the sub-message
D itself can be deleted. To resolve it, we prepend bit 1 to D and bit 0 to the
others, and we make an agreement in advance that every message must have one

294
M. Ishizaka and K. Fukushima
sub-message starting with bit 1. In our DCHSSB, any deletable sub-message
can be changed to undeletable anytime. The change is one-way, which means we
cannot make any undeletable sub-message deletable. If every sub-message goes
undeletable at some point, the message is ﬁnalized. We show that DCHSSB can
be transformed from HSSM. More speciﬁcally, DCHSSB is a subclass of HSSM.
From our HSSM scheme, we obtain a DCHSSB scheme secure under the DLIN
assumption. To the best of our knowledge, our DCHSSB scheme is the ﬁrst one
which is adaptively unforgeable and strongly context-hiding under the standard
assumptions.
Application 2: Disclosure-Controllable RS. In redactable signatures (RS) with
maximal number of sub-messages N ∈N, each message M is an ordered list in
the form of (m1, · · · , mn) for some n ∈[1, N], where mi ∈{0, 1}L ∪{∗}. Each
(non-redacted) sub-message mi(̸= ∗) can be changed to ∗, which means it has
been redacted, i.e., blacked out. In the ordinary RS, any (non-redacted) sub-
message can be redacted anytime. In disclosure-controllable RS (DCRS), any
sub-message which is non-redacted and redactable can be unredactable. Specif-
ically, each sub-message has one of the following three states, namely S1: not
redacted yet and redactable, S2: already redacted, and S3: not redacted yet and
unredactable. Any state only transitions from S1 to S2 or from S1 to S3. If every
sub-message goes in S2 or S3, the message is ﬁnalized. We show that DCRS can
be transformed from DCHSSB. From our DCHSSB scheme, we obtain a DCRS
scheme secure under the DLIN assumption. As our DCHSSB scheme explained
earlier, our DCRS scheme is the ﬁrst one which is adaptively unforgeable and
strongly context-hiding under the standard assumptions.
Application 3: (Key-Delegatable) Subset Predicate Signatures (SBPS). Subset
predicate signatures is the digital signature analogue of subset predicate encryp-
tion [16]. A secret-key associated with a set X ∈2{0,1}L succeeds in generating
a signature on a message associated with any superset Y ⊇X. Our SBPS has
key-delegatability, which means that a secret-key for X generates a new secret-
key for any superset X′ ⊇X. As attribute-based signatures [9,21], we deﬁne
unforgeability and signer-privacy. The latter security guarantees that any signa-
ture with a set Y has no more information about the signer’s set X than the
fact that X ⊆Y . Identity-based ring signatures (IBRS) [24] is a subclass of
SBPS because IBRS is identical to SBPS with the following two restrictions, (1)
key-delegation is not allowed and (2) cardinality of the set X is ﬁxed to 1. HSSP
can be transformed into IBRS as shown in [20]. In fact, it can be transformed
into the stronger primitive SBPS.
Application 4: (Key-Delegatable) Superset Predicate Signatures (SPPS). SPPS
is the dual primitive of SBPS. A secret-key associated with a set X ∈2{0,1}L
generates a signature associated with any subset Y ⊆X and generates another
secret-key associated with any subset X′ ⊆X. We show that SPPS can be
transformed from HSSM in a simple and eﬃcient manner. Actually, SPPS can be
transformed from a weaker primitive HSSB. However, its transformation itself is

Homomorphic Signatures for Subset and Superset Mixed Predicates
295
somewhat complicated. Moreover, if we instantiate it by any one of the existing
SCH-secure HSSB scheme, an ineﬃcient SPPS scheme whose secret-key and
signature lengths increase linearly with the message length is obtained.
Application 5: Wildcarded Identity-Based Signatures (WIBS). WIBS is the digi-
tal signatures analogue of wildcarded identity-based encryption [1]. Each secret-
key is associated with an identity X = (x1, · · · , xn) ∈({0, 1}L)n for some
L, n ∈N, and it succeeds in generating a signature associated with any wild-
carded identity Y = (y1, · · · , yn) ∈({0, 1}L ∪{∗})n s.t. yi ̸= ∗=⇒xi = yi for
all i ∈[1, n]. We show that WIBS can be transformed from HSSM eﬃciently.
Paper Organization. In Sect. 2, we explain notions used in this paper, and deﬁne
symmetric bilinear paring and some computational assumptions. In Sect. 3, we
deﬁne general P-HS, then show that HSSM is a subclass of P-HS. In Sect. 4, we
propose our HSSM schemes. In Sect. 5, we present the applications of HSSM.
2
Preliminaries
Notations. For λ ∈N, 1λ denotes a security parameter. A function f : N →R
is negligible if for every c ∈N, there exists x0 ∈N such that for every x ≥x0,
f(x) ≤x−c. We parse a binary string x ∈{0, 1}L as x[L −1]|| · · · ||x[0], where
x[i] ∈{0, 1} for all i ∈[0, L −1]. PPT is the abbreviation of probabilistic
polynomial-time. For a set A, a
U
←−A means that an element a is chosen uni-
formly at random from A. For a set A, |A| denotes its cardinality.
G takes a security parameter 1λ with λ ∈N and outputs a group description
(p, G, GT , e, g). p is a prime with length λ. G and GT are multiplicative groups
with order p. g is a generator of G. e : G × G →GT is an eﬃciently-computable
function which satisﬁes both of the following conditions, namely (1) bilinearity:
for any a, b ∈Zp, e(ga, gb) = e(g, g)ab, and (2) non-degeneracy: e(g, g) ̸= 1GT ,
where 1GT denotes the unit element of GT .
We deﬁne three computational hardness assumptions.
Deﬁnition 1. The computational Diﬃe-Hellman (CDH) assumption holds on
the group G if for every PPT A, its advantage AdvCDH
A,G(λ) := Pr[gab ←
A(g, ga, gb)] (with a, b
U
←−Zp) is negligible.
Deﬁnition 2. The
decisional
linear
(DLIN)
assumption
holds
on
the
group G if for every PPT A, its advantage AdvDLIN
A,G(λ)
:=
| Pr[1
←
A(ga, gb, gab, gbd, gc+d)]| −Pr[1 ←A(ga, gb, gab, gbd, gz)] (with a, b, c, d, z
U
←−Zp)
is negligible.
Deﬁnition 3. The q-simultaneous ﬂexible pairing (q-SFP) problem [4] rel-
ative to the group G is given gz, hz, gr, hr, a, ˜a, b,˜b
∈
G and q tuples
{(zj, rj, sj, tj, uj, vj, wj) ∈G7}q
j=1 such that for each j ∈[1, q],
e(a, ˜a) = e(gz, zj)·e(gr, rj)·e(sj, tj),
e(b,˜b) = e(hz, zj)·e(hr, uj)·e(vj, wj), (1)

296
M. Ishizaka and K. Fukushima
to ﬁnd a new tuple (z⋆, r⋆, s⋆, t⋆, u⋆, v⋆, w⋆) ∈G7 satisfying the conditions (1)
and the condition z⋆/∈{1G, z1, · · · , zq}. The q-SFP assumption holds if for any
PPT A, its advantage Advq-SFP
A,G (λ) to solve the above problem is negligible.
3
HS for Subset and Superset Mixed Predicates (HSSM)
We ﬁrstly deﬁne Homomorphic signatures for a general predicate P : M × M ×
1/0 (abbreviated as P-HS) [5], then deﬁne HS for subset and superset mixed
predicates (HSSM) as a subclass of P-HS.
Syntax. P-HS consists of the following four polynomial-time algorithms. Ver is
deterministic and the others are probabilistic.
Key-Generation KGen: This algorithm takes 1λ, then outputs a public-key pk
and a secret-key sk.
(pk, sk) ←KGen(1λ)
Signing Sig: Take a secret-key sk and a message M ∈M, then output a
signature σ.
σ ←Sig(sk, M)
Derivation Derive: Take a public-key pk, a message M, a signature σ and a
message M ′ ∈M, then output a signature σ′.
σ′ ←Derive(pk, M, σ, M ′)
Veriﬁcation Ver: Take a public-key pk, a message M ∈M and a signature σ,
then output 1 (meaning accept) or 0 (reject).
1/0 ←Ver(pk, M, σ)
Every P-HS scheme must be correct. A P-HS scheme is correct if for
any
λ
∈
N,
any
(pk, sk)
←
KGen(1λ),
any
M
∈
M
and
any
M ′
∈
M s.t. 1
←
P(M, M ′), both of the following two conditions
are
satisﬁed,
namely
(1)
1
←
Ver(pk, M, Sig(sk, M))
and
(2)
1
←
Ver(pk, M, Derive(pk, M, Sig(sk, M), M ′)).
Security. As security, we deﬁne unforgeability and context-hiding. As unforge-
ability notions, we deﬁne unforgeability (UNF) and weak unforgeability (wUNF)
with the following experiments.
ExptUNF
ΣP-HS,A(1λ):
//ExptwUNF
ΣP-HS,A
1. Generate (pk, sk) ←KGen(1λ). Initialize two tables Q, Q′ := ∅
2. (σ∗, M ∗∈M) ←ASign,Derive,Reveal(pk)
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
- Sign(M ∈M):
σ ←Sig(sk, M). Choose an unused handle h ∈H.
Q := Q ∪{(h, M, σ)}. Rtrn h
- Derive(h ∈H, M ′ ∈M):
Rtrn ⊥. Rtrn ⊥if ̸ ∃(M, σ) s.t. (h, M, σ) ∈Q ∧1 ←P(M, M ′).
σ′ ←Derive(pk, M, σ, M ′). Choose an unused handle h′ ∈H.
Q := Q ∪{(h′, M ′, σ′)}. Rtrn h′
- Reveal(h ∈H):
Rtrn ⊥if ̸ ∃(M, σ) s.t. (h, M, σ) ∈Q. Update Q′ := Q′ ∪{M}. Rtrn σ
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
3. Rtrn 1 if (1) 1 ←Ver(pk, M ∗, σ∗) and (2) 0 ←P(M, M ∗) for all M ∈Q′.
4. Rtrn 0

Homomorphic Signatures for Subset and Superset Mixed Predicates
297
In the experiment for UNF, the PPT adversary A receives an honestly generated
public-key pk, adaptively accesses three oracles, namely signing, derivation and
(signature-)revelation, then outputs a forged signature σ∗on M ∗. The grey com-
mand Rtrn ⊥. in the derivation oracle is considered only in the experiment for
wUNF, which means that the derivation oracle is useless because it always returns
⊥. UNF is deﬁned as follows and wUNF is analogously deﬁned.
Deﬁnition 4. A scheme ΣP-HS is UNF if for any λ ∈N and any PPT algorithm
A, its advantage AdvUNF
ΣP-HS,A(λ) := Pr[1 ←ExptUNF
ΣP-HS,A(1λ)] is negligible.
As privacy (or unlinkability) related security notions, we deﬁne strong context-
hiding (SCH) [5] and complete context-hiding (CCH) [6].
Deﬁnition 5. A P-HS scheme is CCH (resp. SCH) if for any λ ∈N, any
(pk, sk) ←KGen(1λ), any message M ∈M, any valid signature σ s.t. 1 ←
Ver(pk, M, σ) (resp. any honestly-generated signature σ ←Sig(sk, M)), any
message M ′ ∈M s.t. 1 ←P(M, M ′), the following two distributions are identi-
cal, namely (1) {sk, σ, Derive(pk, M, σ, M ′)} and (2) {sk, σ, Sig(sk, M ′)}.
It is obvious that, for any P-HS scheme, CCH implies SCH, and the conjunction
of SCH and wUNF implies UNF.
HSSM as a Subclass of P-HS. In HSSM, each message is a pair of sets (M, W) ∈
2{0,1}L × 2{0,1}L for an integer L ∈N. Predicate Pmixed for HSSM takes two
messages (M, W), (M ′, W ′) ∈2{0,1}L × 2{0,1}L, then outputs 1 if (1) M ′ is a
subset of M, i.e., M ′ ⊆M, and (2) W ′ is a superset of W, i.e., W ′ ⊇W.
HSSM is a simple combination of HS for subset predicates (HSSB) [5,6] and
HS for superset predicates (HSSP) originally called history-hiding append-only
signatures in [20].
4
Our HSSM Schemes
Groth-Sahai Non-Interactive Witness-Indistinguishable (GS NIWI) Proof [15].
In the GS NIWI proof system, based on a symmetric bilinear pairing e : G2 →
GT with groups G, GT whose order is a prime p, a CRS consists of three vectors
#»f 1, #»f 2, #»f 3 ∈G3, where #»f 1 = (f1, 1, g) and #»f 2 = (1, f2, g) with f1, f2 ∈G.
A commitment #»
C to an element X ∈G is given as (1, 1, X) · #»f r
1 · #»f s
2 · #»f t
3
with r, s, t
U
←−Zp. The CRS is in one of the two settings. In the perfect
soundness setting, where the vector #»f 3 is chosen outside the span of the
other vectors #»f 1 and #»f 2, any commitment is perfectly hiding. In the perfect
witness-indistinguishability(WI) setting, the CRS satisﬁes #»f 3 = #»f ξ1
1 · #»f ξ2
2 with
ξ1, ξ2 ∈Zp, and from any commitment #»
C = (f r+ξ1t
1
, f s+ξ2t
2
, X ·gr+s+t(ξ1+ξ2)) dis-
tributing identically to a ciphertext of the Boneh-Boyen-Shacham (BBS) encryp-
tion [10], the committed variable X is extracted by using β1 = logg(f1) and
β2 = logg(f2). The two settings of CRS are hard to distinguish under the deci-
sional linear (DLIN) assumption.

298
M. Ishizaka and K. Fukushima
Given n variables X1, · · · , Xn ∈G, a prover computes a commitment
#»
CXi ∈G3 to each variable Xi with randomness ri, si, ti
U
←−Zp, then com-
putes a proof for a pairing-product equation (PPE) in a general form of
n
i=1 e(Ai, Xi) · n
i=1
n
j=1 e(Xi, Xj)aij = tT with constants Ai ∈G, aij ∈Zp
and tT ∈GT . In this paper, we use only a simpler form of n
i=1 e(Ai, Xi) = tT . In
this case, the proof #»π ∈G3 is simply (n
i=1 Ari
i , n
i=1 Asi
i , n
i=1 Ati
i ). Each com-
mitment #»
CXi is publicly and perfectly re-randomized by choosing r′
i, s′
i, t′
i
U
←−Zp
then computing #»
C′
Xi := #»
CXi · #»f r′
i
1 · #»f s′
i
2 · #»f t′
i
3 . The proof #»π must be naturally
updated to #»π · (n
i=1 Ar′
i
i , n
i=1 As′
i
i , n
i=1 At′
i
i ).
Attrapadung et al.’s HSSB Scheme [6]. Their HSSB scheme is based on
the GS proof [15], Waters signatures [23] (described in Appendix 3) and
Abe-Haralambiev-Ohkubo (AHO) structure-preserving signatures (SPS) [3,4]
(described in Appendix 4). In key-generation, a signer generates a long-term
AHO key-pair. When signing a message M ∈2{0,1}L, the signer freshly gener-
ates a one-time Waters key-pair (X, x), where X := gx with x
U
←−Zp. For each
sub-message m ∈M, the signer generates a Waters signature (σm,1, σm,2) :=
(hx · HG(m)χm, gχm) ∈G2 under a public group element h ∈G and a random-
ness χm
U
←−Zp. The signer also generates an AHO signature (θ1, · · · , θ7) ∈G7
on the Waters public-key X ∈G. Finally, the signer computes GS commitments
to X, {σm,1}m∈M, θ1, θ2, θ5 ∈G, then computes GS proofs that (1) the AHO sig-
nature (θ1, · · · , θ7) on X is valid and (2) the Waters signature (σm,1, σm,2) on
m under the public-key X is valid for each m ∈M. When a public party derives
a signature on a subset M ′ ⊆M, for each deleted sub-message m ∈M \ M ′, the
commitment to σm,1, (non-committed) σm,2 and the GS proof related to this
Waters signature are deleted from the original HSSB signature, then all of the
remaining variables are perfectly re-randomized.
Libert et al.’s HSSP Scheme [20]. Libert et al.’s HSSP scheme is similar to the
Attrapadung et al.’s HSSB scheme. It is based on an arbitrary SPS scheme
satisfying unforgeability against extended random messages attacks [2], GS
NIWI proof [15], and Boneh-Lynn-Shacham (BLS) signatures [11] instantiated
by the Waters programmable hash function [23], i.e., HG. In key-generation, a
signer generates a long-term key-pair of the SPS scheme. When signing a mes-
sage W ∈2{0,1}L, the signer generates a one-time BLS key-pair (Y, y), where
Y := gy with y
U
←−Zp. The signer divides the BLS secret-key y into |W| num-
ber of shares by using |W|-out-of-|W| secret sharing1. Speciﬁcally, she uniform-
randomly chooses {γw ∈Zp}w∈W satisfying that 
w∈W γw = y (mod p). For
each w ∈W, she computes (σw,1, σw,2) := (HG(w)γw, gγw) ∈G2, where the ﬁrst
element σw,1 is a BLS signature on w under the pseudo BLS public-key σw,2. The
signer also generates a SPS signature (θ1, · · · , θlsps) ∈Glsps on Y ∈G. Finally,
the signer computes GS commitments to Y, {σw,1, σw,2}w∈W , θ1, · · · , θlsps ∈G,
then computes GS proofs that (1) the SPS signature (θ1, · · · , θlsps) on Y is
1 |W| denotes cardinality of the set W.

Homomorphic Signatures for Subset and Superset Mixed Predicates
299
valid, (2) the BLS signature σw,1 on w under the pseudo public-key σw,2 is
valid for each w ∈W and (3) 
w∈W σw,2 = Y . When a public user derives
a signature on a superset W ′ ⊇W, {γw ∈Zp}w∈W ′ s.t. 
w∈W ′ γw = 0
(mod p) are randomly chosen. For each added element w ∈W ′ \ W, we com-
pute (σw,1, σw,2) := (HG(w)γ′
w, gγ′
w) then compute GS commitments to them.
For each inherited element w ∈W ′ ∩W, we update the committed variables
σw,1, σw,2 ∈G to σw,1 · HG(w)γ′
w and σw,2 · gγ′
w, respectively. The GS proof for
the relation 
w∈W σw,2 = Y is properly updated and all of the GS commitments
and proofs are perfectly re-randomized.
4.1
Construction
Our HSSM scheme is a simple combination of the Attrapadung et al.’s HSSB
and Libert et al.’s HSSP schemes. As the underlying SPS scheme, we also use
the AHO SPS scheme [3,4] with message space G2. On signature generation,
a fresh one-time Waters and BLS key-pairs (X, x), (Y, y) are generated, where
X := gx and Y := gy with x, y
U
←−Zp. An AHO signature (θ1, · · · , θ7) on
(X, Y ) ∈G2 is generated. For each m ∈M, a Waters signature (σm,1, σm,2) on
m is generated. The original BLS secret-key y ∈Zp is divided into |W| number of
shares {γw ∈Zp}w∈W by |W|-out-of-|W| secret sharing, then for each w ∈W,
a BLS signature σw,1 on w under the pseudo BLS public-key gγw(=: σw,2) is
generated. Finally, the GS commitments and proofs are properly generated.
For any element Z ∈G, ι(Z) denotes (1, 1, Z) ∈G3. For any h, g1, g2, g3 ∈G,
E(h, (g1, g2, g3)) denotes (e(h, g1), e(h, g2), e(h, g3)) ∈G3
T . Our HSSM scheme is
formally described as follows.
KGen(1λ, L): Choose bilinear groups (G, GT ) whose order is a prime p of bit
length λ. g denotes a generator of G. Conduct the following three steps.
1. Generate the public parameter of the Waters signatures [23] by choosing
h, u′, u0, · · · , uL−1
U
←−G. The Waters programmable hash function HG :
{0, 1}L →G takes a sub-message m ∈{0, 1}L, being parsed as m[L −1] ∥
· · · ∥m[0], then outputs u′ L−1
i=0 um[i]
i
∈G.
2. Generate a key-pair (pks, sks) of the AHO SPS [3,4]. Parse it as
((gr, hr, gz, hz, g1, h1, g2, h2, A, B), (αa, αb, γz, δz, γ1, δ1, γ2, δ2)).
3. Generate a CRS f = (#»f 1, #»f 2, #»f 3) for the perfect WI setting of the GS
NIWI proof [15]. Concretely, #»f 1 := (f1, 1, g), #»f 2 := (1, f2, g) and #»f 3 :=
#»f ξ1
1 · #»f ξ2
2 · (1, 1, g)−1, where f1, f2
U
←−G and ξ1, ξ2
U
←−Zp.
Output (pk, sk), where pk := (G, GT , g, h, u′, {ui}L−1
i=0 , pks, f) and sk := sks.
Sig(sk, M ∈2{0,1}L, W ∈2{0,1}L): Firstly, conduct the following six steps.
1. Choose x, y
U
←−Zp. Let X := gx and Y := gy.
2. Generate an AHO signature σs = (θ1, · · · , θ7) on a message (X, Y ) ∈G2.
3. For each m ∈M, generate a Waters signature on m, i.e., (σm,1, σm,2) :=
(hx · HG(m)χm, gχm) with χm
U
←−Zp.

300
M. Ishizaka and K. Fukushima
4. Choose {γw ∈Zp}w∈W satisfying 
w∈W γw = y (mod p) uniformly at
random. Then for each w ∈W, compute (σw,1, σw,1) := (HG(w)γw, gγw).
5. Compute GS commitments for all of the group elements X, Y , θ1, θ2,
θ5, {σm,1}m∈M and {σw,1, σw,2}w∈W . The commitments are denoted by
#»
CX, #»
CY , #»
Cθ1, #»
Cθ2, #»
Cθ5, #»
Cσm,1, #»
Cσw,1, #»
Cσw,2, respectively. Speciﬁcally, for
each committed element Z ∈G, the commitment #»
CZ is computed as
ιG(Z) · #»f rZ
1
· #»f sZ
2
· #»f tZ
3
with rZ, sZ, tZ
U
←−Zp.
6. Compute GS proofs for all of the following PPEs.
A · e(θ3, θ4)−1 = e(gz, θ1) · e(gr, θ2) · e(g1, X) · e(g2, Y )
(2)
B · e(θ6, θ7)−1 = e(hz, θ1) · e(hr, θ5) · e(h1, X) · e(h2, Y )
(3)
e(σm,1, g) = e(X, h) · e(σm,2, HG(m)) (For each m ∈M)
(4)
e(σw,1, g) = e(σw,2, HG(w))
(For each w ∈W)
(5)
e(Y, g) =

w∈W
e(σw,2, g)
(6)
The proofs are denoted by #»π A, #»π B, #»π m, #»π w and #»π sum, respectively, and
computed as follows.
#»π A := (g
rθ1
z
g
rθ2
r
grX
1 grY
2 , g
sθ1
z
g
sθ2
r
gsX
1 gsY
2 , g
tθ1
z
g
tθ2
r
gtX
1 gtY
2 )
#»π B := (h
rθ1
z
h
rθ2
r
hrX
1 hrY
2 , h
sθ1
z
h
sθ2
r
hsX
1 hsY
2 , h
tθ1
z
h
tθ2
r
htX
1 htY
2 )
#»π m := (grσm,1 · h−rX , gsσm,1 · h−sX , gtσm,1 · h−tX )
#»π w := (grσw,1 · HG(w)−rσw,2 , gsσw,1 · HG(w)−sσw,2 , gtσw,1 · HG(w)−tσw,2 )
#»π sum := (grY −
w∈W rσw,2 , gsY −
w∈W sσw,2 , gtY −
w∈W tσw,2 )
Finally, output a signature σ which is

#»
CX, #»
CY , {#»
Cθi}i∈{1,2,5}, {θi}i∈{3,4,6,7}, #»π A, #»π B,
{#»
Cσm,1, σm,2, #»π m}m∈M, {#»
Cσw,1, #»
Cσw,2, #»π w}w∈W , #»π sum

∈G28+7|M|+9 W |
(7)
Derive(pk, (M, W), σ, (M ′, W ′)):
Parse
σ
as
(7).
Assume
that
1
←
Pmixed((M, W), (M ′, W ′)). Conduct the following six steps.
1. Re-randomize the GS commitments #»
CX, #»
CY ∈G3. For each variable
Z ∈{X, Y }, #»
C′
Z := #»
CZ · #»f r′
Z
1
· #»f s′
Z
2
· #»f t′
Z
3 , where r′
Z, s′
Z, t′
Z
U
←−Zp.
2. Randomize the AHO signature (θ1, · · · , θ7) ∈G7 in the same manner as
[3,4,6] explained in Appendix 4. Choose η2, η5, μ, ν
U
←−Zp, then
#»
C′
θ1 := #»
Cθ1 · #»f
r′
θ1
1
· #»f
s′
θ1
2
· #»f
t′
θ1
3 ,
#»
C′
θ2 := #»
Cθ2 · ιG(θη2
4 ) · #»f
r′
θ2
1
· #»f
s′
θ2
2
· #»f
t′
θ2
3 ,
θ′
3 := (θ3 · g−η2
r
)1/μ,
θ′
4 := θμ
4 ,
#»
C′
θ5 := #»
Cθ5 · ιG(θη5
7 ) · #»f
r′
θ5
1
· #»f
s′
θ5
2
· #»f
t′
θ5
3 ,
θ′
6 := (θ6 · h−η5
r
)1/ν,
θ′
7 := θν
7,

Homomorphic Signatures for Subset and Superset Mixed Predicates
301
where r′
θi, r′
θi, t′
θi
U
←−Zp for each i ∈{1, 2, 5}. The GS proofs #»π A, #»π B ∈G3
are naturally updated as follows.
#»π ′
A := #»π A · (g
r′
θ1
z
g
r′
θ2
r
gr′
X
1 gr′
Y
2 , g
s′
θ1
z
g
s′
θ2
r
gs′
X
1 gs′
Y
2 , g
t′
θ1
z g
t′
θ2
r gt′
X
1 gt′
Y
2 )
#»π ′
B := #»π B · (h
r′
θ1
z
h
r′
θ2
r
hr′
X
1 hr′
Y
2 , h
s′
θ1
z
h
s′
θ2
r
hs′
X
1 hs′
Y
2 , h
t′
θ1
z h
t′
θ2
r ht′
X
1 ht′
Y
2 )
3. For each m ∈M ′, re-randomize the Waters signature (σm,1, σm,2) ∈G.
Choose χ′
m
U
←−Zp, then compute σ′
m,2 := σm,2 ·gχ′
m and #»
C′
σm,1 := #»
Cσm,1 ·
ιG(HG(m)χ′
m)·#»f
r′
σm,1
1
·#»f
s′
σm,1
2
·#»f
t′
σm,1
3
, where r′
σm,1, s′
σm,1, t′
σm,1
U
←−Zp. The
GS proof #»π m is naturally updated to #»π ′
m := #»π m · (gr′
σm,1 · h−r′
X, gs′
σm,1 ·
h−s′
X, gt′
σm,1 · h−t′
X).
4. Choose {γ′
w ∈Zp}w∈W ′ s.t. 
w∈W ′ γ′
w = 0 (mod p) uniformly at random
from Zp.
5. For each w ∈W, re-randomize (σw,1, σw,2) ∈G2 and their commitments
#»
Cσw,1, #»
Cσw,2 ∈G3. Compute #»
C′
σw,1 := #»
Cσw,1 · ιG(HG(w)γ′
w) · #»f
r′
σw,1
1
·
#»f
s′
σw,1
2
· #»f
t′
σw,1
3
and #»
C′
σw,2 := #»
Cσw,2 ·ιG(gγ′
w)· #»f
r′
σw,2
1
· #»f
s′
σw,2
2
· #»f
t′
σw,2
3
, where
r′
σw,1, s′
σw,1, t′
σw,1
U
←−Zp. The GS proof #»π w is naturally updated to #»π ′
w :=
#»π w · (gr′
σw,1 · HG(w)−r′
σw,2 , gs′
σw,1 · HG(w)−s′
σw,2 , gt′
σw,1 · HG(w)−t′
σw,2 ).
6. For each w ∈W ′ \ W, newly generate (σw,1, σw,2) := (HG(w)γ′
w, gγ′
w).
Then generate a GS commitments #»
C′
σw,1 := ιG(HG(w)γ′
w) · #»f
r′
σw,1
1
·
#»f
s′
σw,1
2
· #»f
t′
σw,1
3
and #»
C′
σw,2 := ιG(gγ′
w) · #»f
r′
σw,2
1
· #»f
s′
σw,2
2
· #»f
t′
σw,2
3
, where
r′
σw,1, s′
σw,1, t′
σw,1, r′
σw,2, s′
σw,2, t′
σw,2
U
←−Zp. Then generate a GS proof
#»π ′
w := (gr′
σw,1 · HG(w)−r′
σw,2 , gs′
σw,1 · HG(w)−s′
σw,2 , gt′
σw,1 · HG(w)−t′
σw,2 ).
Finally, output a signature σ′ composed of all of the updated variables.
Ver(pk, (M, W), σ): Parse σ as (7). Each GS proof π ∈G3 is parsed as
(π1, π2, π3). Output 1 if and only if all of the following ﬁve equations hold.
1. ιGT (A) · e(θ3, ιG(θ4))−1 = E(gz, #»
Cθ1) · E(gr, #»
Cθ2) · E(g1, #»
CX) · E(g2, #»
CY ) ·
3
k=1 E(πA,k, #»f k)
2. ιGT (B)·e(θ6, ιG(θ7))−1 = E(hz, #»
Cθ1)·E(hr, #»
Cθ5)·E(h1, #»
CX)·E(h2, #»
CY )·
3
k=1 E(πB,k, #»f k)
3. E(g, #»
Cσm,1) = E(h, #»
CX) · E(HG(m), ιG(σm,2)) · 3
k=1 E(πm,k, #»f k)
(for each m ∈M)
4. E(g, #»
Cσw,1) = E(HG(w), #»
Cσw,2) · 3
k=1 E(πw,k, #»f k)
(for each w ∈W)
5. E(g, #»
CY ) = 
w∈W E(g, #»
Cσw,2) · 3
k=1 E(πsum,k, #»f k)
Theorem 1. Our HSSM scheme is CCH unconditionally, and wUNF under the
DLIN assumption w.r.t the group G and the q-SFP assumption, where q ∈
poly(λ) is the maximal number of times that the signing oracle can be accessed.

302
M. Ishizaka and K. Fukushima
Proof. Among various variables included in a derived signature, GS commit-
ments and proofs distribute identically to fresh ones because of the following two
facts, (1) GS NIWI proof system is perfectly WI, and (2) they are perfectly re-
randomized in the derivation algorithm. The other variables, i.e., {θi}i∈{3,4,6,7}
and {σm,2}m∈M ′, also distribute identically to fresh ones because they are per-
fectly re-randomized in the derivation algorithm. Hence, our HSSM scheme is
CCH. To prove its wUNF, we deﬁne the following 4 experiments.
Expt0: This is the standard wUNF experiment for the HSSM scheme. The forged
signature σ∗is parsed as (#»
C∗
X, #»
C∗
Y , {#»
C∗
θi}i∈{1,2,5}, {θ∗
i }i∈{3,4,6,7}, #»π ∗
A, #»π ∗
B,
{#»
C∗
σm,1, σ∗
m,2, #»π ∗
m}m∈M ∗, {#»
C∗
σw,1, #»
C∗
σw,2, #»π ∗
w}w∈W ∗, #»π ∗
sum).
Expt1: The same as Expt0 except that the GS CRS f = (#»f 1, #»f 2, #»f 3) is gen-
erated as a perfectly sound one. Speciﬁcally, #»f 1 := (f1, 1, g), #»f 2 := (1, f2, g)
and #»f 3 := #»f ξ1
1 · #»f ξ2
2 , where f1 := gφ1 and f2 := gφ2 with φ1, φ2, ξ1, ξ2
U
←−Zp.
Note that in this and later experiments, all GS commitments are perfectly
binding. From the forged GS commitments, we can extract all of the hidden
variables X∗, Y ∗, {θ∗
i }i∈{1,2,5}, {σ∗
m,1}m∈M ∗and {σ∗
w,1, σ∗
w,2}w∈W ∗by using
the BBS decryption keys (φ1, φ2). Since the forged GS proofs are perfectly
sound, the extracted variables satisfy all of the ﬁve Eqs. (2)–(6).
Expt2: For κ ∈[1, q], (Xκ, Yκ) ∈G2 denote the group elements (X, Y ) randomly
chosen on the κ-th query to the signing oracle. Expt2 is the same as Expt1
except that it aborts if ̸ ∃κ ∈[1, q] s.t. (Xκ, Yκ) = (X∗, Y ∗).
Expt3: Identical to Expt2 except that it aborts if ∃κ ∈[1, q] s.t. (Xκ, Yκ) =
(X∗, Y ∗)∧M ∗̸⊆Mκ, where Mκ is the κ-th query of M to the signing oracle.
Si denotes the event where Expti outputs 1. We obtain AdvwUNF
ΣHSSM,A,n(λ) =
Pr[S0] ≤3
i=1 | Pr[Si−1]−Pr[Si]|+Pr[S3]. Because of the following four lemmas,
the rightmost formula is negligible under the DLIN and q-SFP assumptions2.
Lemma 1 is true as shown in [6,20].
⊓⊔
Lemma 1. |Pr [S0] −Pr [S1]| is negligible under the DLIN assumption w.r.t. G.
Lemma 2. |Pr [S1] −Pr [S2]| is negligible under the q-SFP assumption.
Proof. Let Abort denote the aborting event added in Expt2. Since Expt2 is
the same as Expt1 except for the case that the aborting event occurs, Pr[S2] =
Pr[S1 ∧¬Abort]. By a basic mathematical theorem, Pr[S1] −Pr[S1 ∧¬Abort] =
Pr[S1] −Pr[S2] = Pr[S1 ∧Abort]. Let A denote a PPT adversary which makes
the event S1 ∧Abort occurs with a non-negligible probability. Let B2 denote a
PPT adversary which, by using A as black-box, attempts to win the existential
unforgeability against adaptively chosen messages attacks (EUF-CMA) experiment
(deﬁned in Appendix 1) w.r.t. the AHO SPS scheme. B2 behaves as follows.
B2 receives an honestly-generated public-key pks of the AHO scheme. B2
honestly generates a GS CRS f in the perfect soundness setting and public
parameters h, u′, u0, · · · , uL−1 of the Waters signatures. If A issues (M, W) as a
2 The CDH assumption is implied by the DLIN and q-SFP assumptions.

Homomorphic Signatures for Subset and Superset Mixed Predicates
303
query to the signing oracle, B2 generates (X, Y ) := (gx, gy) (where x, y
U
←−Zp),
then sends the message (X, Y ) as a query to the signing oracle to get an AHO
signature σs. B2 honestly generates the other elements of the HSSM signature
σ on (M, W). Since we have assumed that the event S1 ∧Abort occurs, (1)
σ∗
s is a valid AHO signature on the message (X∗, Y ∗), and (2) the message
has not been queried to the signing oracle by B2. Thus, B2 wins. It holds that
Pr[S1 ∧Abort] ≤AdvEUF-CMA
ΣAHO,B2(λ), where the right side denotes B2’s advantage in
the EUF-CMA experiment which is negligible under the q-SFP assumption.
⊓⊔
Lemma 3. |Pr [S2] −Pr [S3]| is negligible under the CDH assumption w.r.t. G.
Proof. Let Abort denote the aborting event added in Expt3. As the proof of
Lemma 2, it holds that Pr[S2] −Pr[S3] = Pr[S2 ∧Abort]. Let A denote a PPT
adversary which makes the event S2 ∧Abort occurs with a non-negligible proba-
bility. Let B3 denote a PPT adversary which, by using A as black-box, attempts
to win the EUF-CMA experiment w.r.t. the Waters scheme. B3 behaves as follows.
B3 receives honestly-generated public parameters h, u′, u0, · · · , uL−1 and a
public-key X′(:= gx′) (where x′
U
←−Zp) of the Waters signature. B3 honestly
generates a GS CRS f in the perfect soundness setting and an AHO key-pair
(pks, sks). Since we have assumed that the event S2 ∧Abort occurs, it will hold
that ∃κ ∈[1, q] s.t. (Xκ, Yκ) = (X∗, Y ∗) ∧Mκ ̸⊇M ∗. B3 guesses such an index
κ and chooses κguess
U
←−[1, q]. The guess is correct at least with probability 1/q.
B3 proceeds under an assumption that the guess is correct. If A issues (M, W)
as the κ-th query to the signing oracle, B3 considers the following two cases.
1. κ ̸= κguess: B3 honestly generates the whole HSSM signature σ oneself.
2. κ = κguess: B3 uses the given X′ ∈G as the Waters public-key. For each
m ∈M, B3 queries m ∈{0, 1}L to the signing oracle to get a Waters signature
(σm,1, σm,2). B3 honestly generates the HSSM signature σ oneself.
Since we have assumed that S2 ∧Abort occurs, (1) there exists m∗∈M ∗s.t.
m∗/∈Mκguess, (2) the Waters signature (σ∗
m∗,1, σ∗
m∗,2) on m∗is valid, and (3)
the message m∗has not been queried to the signing oracle by B3. Thus, B3
wins (under the assumption that B3’s guess κguess is correct). It holds that
Pr[S2 ∧Abort] ≤q · AdvEUF-CMA
ΣWaters,B3(λ), where AdvEUF-CMA
ΣWaters,B3(λ) is B3’s advantage
in the EUF-CMA experiment w.r.t. the Waters scheme which is negligible under
the CDH assumption. In Appendix 6, we rigorously prove that there exists a
PPT adversary B′
3 s.t. Pr[S2 ∧Abort] ≤4q · dM · (L + 1) · AdvCDH
B′
3,G(λ), where
dM ∈poly(λ) is the maximal cardinality of the set M.
⊓⊔
Lemma 4. Pr [S3] is negligible under the CDH assumption w.r.t. G.
Proof. We adopt the same proof approach as [20]. We prove that there exists a
PPT adversary B4 s.t. Pr[S3] ≤4q·dW ·(L+1)·AdvCDH
B4,G(λ), where dW ∈poly(λ)
is the maximal cardinality of the set W. Let A denote a PPT adversary which
makes the event S3 occur with a non-negligible probability. Let B4 denote a PPT
adversary which uses A to solve the CDH problem. B4 behaves as follows.

304
M. Ishizaka and K. Fukushima
Receive (g, ga, gb) as an instance of the CDH problem. Honestly generate a
key-pair (pks, sks) of the AHO scheme and a GS CRS f = (#»f 1, #»f 2, #»f 3) in the
perfect soundness setting. Then conduct the following two steps.
1. Set l := 2dW . Choose uniformly at random an integer k satisfying 0 ≤k ≤L.
Assume that l(L + 1) ≤p.
2. Let h
U
←−G. Choose x′, x0, · · · , xL−1
U
←−Zl and y′, y0, · · · , yL−1
U
←−Zp. For
an element w ∈{0, 1}L, deﬁne two functions J, K : {0, 1}L →Zp as J(w) :=
x′ +L−1
i=0 xi ·w[i]−lk and K(w) := y′ +L−1
i=0 yi ·w[i]. Set u′ := (ga)−lk+x′ ·
gy′ and ui := (ga)xi · gyi for i ∈[0, L −1]. It holds that u′ L−1
i=0 uw[i]
i
=
(ga)−lk+x′+L−1
i=0 xi·w[i] · gy′+L−1
i=0 yi·w[i] = (gb)J(w) · gK(w).
Set pk := (G, GT , g, h, u′, {ui}L−1
i=0 , pks, f) and send it to A. Since we have
assumed that the event S3 occurs, it must hold that ∃κ ∈[1, q] s.t. (Xκ, Yκ) =
(X∗, Y ∗) ∧Wκ ̸⊆W ∗. B4 guesses such an index κ by κguess
U
←−[1, q]. The guess
is correct at least with probability 1/q. B4 proceeds under an assumption that
the guess is correct. When A queries to the signing oracle, B4 behaves as follows.
Sign(M, W): Assume that this query is the κ-th query to the oracle. B4 considers
the following two cases.
1. κ ̸= κguess: B4 honestly generates the whole HSSM signature σ oneself,
then returns it to A.
2. κ = κguess: If ̸ ∃w ∈W s.t. J(w) = 0 (mod p), B4 aborts the simulation.
Otherwise, ∃w ∈W s.t. J(w) = 0 (mod p). Hereafter, such an element
w is denoted by w′. B4 sets Y := gb. For each w ∈W \ {w′}, B4 chooses
γw
U
←−Zp then computes (σw,1, σw,1) := (HG(w)γw, gγw). B4 computes
(σw′,1, σw′,2) := ((gb · g−
w∈W \{w′} γw)K(w′), gb · g−
w∈W \{w′} γw). Since
J(w′) = 0 (mod p), they distribute as (HG(w′)γw′ , gγw′ ), where γw′ :=
b−
w∈W \{w′} γw. B4 honestly generates the other elements of the HSSM
signature σ oneself, then returns σ to A.
B4 receives a forged signature σ∗sent by A. Since we have assumed that the event
S3 occurs, all of the following three conditions hold, namely (a) Y ∗= Yκguess,
(b) W ∗̸⊇Wκguess, and (c) there exist {γw ∈Zp}w∈W ∗s.t. (σ∗
w,1, σ∗
w,2) =
(HG(w)γw, gγw) for each w ∈W ∗and 
w∈W ∗γw = b. B4 aborts the simulation if
∃w ∈W ∗s.t. J(w) = 0 (mod l). Otherwise, for each w ∈W ∗, J(w) ̸= 0 (mod l),
which implies J(w) ̸= 0 (mod p). B4 computes 
w∈W ∗

σ∗
w,1
(σ∗
w,2)K(w)
	
1
J(w) =

w∈W ∗

(ga)J(w)·γw ·gK(w)·γw
gγw·K(w)
	
1
J(w) = 
w∈W ∗(ga)γw = (ga)

w∈W ∗γw = gab then
outputs it as the answer to the CDH problem.
Let SimAbort denote the event that B4 aborts the simulation. At least when
S3 has occurred and B4 has not aborted the simulation, B4 ﬁnds the correct
answer to the CDH problem. Thus, it holds AdvCDH
B4,G(λ) ≥Pr[S3 ∧¬SimAbort] =
Pr[¬SimAbort | S3] · Pr[S3], implying Pr[S3] ≤
1
Pr[¬SimAbort|S3] · AdvCDH
B4,G(λ).
We analyze the probability Pr[¬SimAbort | S3]. We deﬁne three events.

Homomorphic Signatures for Subset and Superset Mixed Predicates
305
E1: (X∗, Y ∗) = (Xκguess, Yκguess)
E2: ∃w′ ∈Wκguess s.t. w′ /∈W ∗∧J(w′) = 0 (mod p)
E3: ∀w ∈W ∗, J(w) ̸= 0 (mod l)
We obtain
Pr[¬SimAbort | S3]
= Pr[E1 ∧E2 ∧E3 | S3]
= Pr[E1 | S3] · Pr[E2 ∧E3 | S3 ∧E1]
= Pr[E1 | S3] · Pr[E2 | S3 ∧E1] · Pr[E3 | S3 ∧E1 ∧E2].
We analyze each term. Obviously, Pr[E1 | S3] ≥1/q. The second term is analyzed
as follows.
Pr[E2 | S3 ∧E1]
= Pr[J(w′) = 0
(mod p) | S3 ∧E1]
= Pr[J(w′) = 0
(mod l) | S3 ∧E1]
· Pr[J(w′) = 0
(mod p) | S3 ∧E1 ∧J(w′) = 0
(mod l)]
= 1
l
1
L + 1
The third term is as follows.
Pr[E3 | S3 ∧E1 ∧E2]
= Pr

 
w∈W ∗
J(w) ̸= 0
(mod l)
 S3 ∧E1 ∧E2

≥1 −

w∈W ∗
Pr[J(w) = 0
(mod l) | S3 ∧E1 ∧E2]
= 1 −

w∈W ∗
1
l ≥1 −dW
l
As a result, we obtain
Pr[¬SimAbort | S3] ≥1
q · 1
l ·
1
L + 1 ·

1 −dW
l

=
1
4q · dW · (L + 1)
Therefore, Pr[S3] ≤4q · dW · (L + 1) · AdvCDH
B4,G(λ).
⊓⊔
4.2
Another Construction from the DLIN Assumption Only
By replacing the AHO SPS scheme [3,4] in the above HSSM scheme with Abe et
al.’s SPS scheme [2] satisfying unforgeability against extended random messages
attacks (UF-XRMA) (deﬁned in Subsect. Appendix 1) under the DLIN assumption,
we obtain an HSSM scheme secure under the DLIN assumption only. In the

306
M. Ishizaka and K. Fukushima
Table 1. Comparison among existing HSSB/RS schemes. CH and DC mean context-
hiding and disclosure-controllability, respectively.
HSSB/RS Schemes
CH
DC
Assumption
ABC+12 [5] w. [18]
Strong
–
Subgroup Decision [19]
ALP12 [6]
Complete –
DLIN
Ours
Complete ✓
DLIN
modiﬁed HSSM scheme, the signer chooses x, y
U
←−Zp, then generates an Abe
et al.’s SPS signature (θ0, · · · , θ7) ∈G8 on a message composed of six group
elements (M1, · · · , M6) := (Cx, Cy, F x, F y, U x
1 , U y
2 ) ∈G6, where U, F, U1, U2 ∈
G are group generators. For each element in {M1, · · · , M6, θ0, · · · , θ7}, the signer
computes a GS commitment. The veriﬁcation algorithm of the Abe et al.’s SPS
scheme consists of seven PPEs. For each PPE, the signer computes a GS proof.
5
Applications
5.1
Disclosure-Controllable (DC) HSSB
In HSSB [5,6], any signature on a set M generates a signature on any subset
M ′ ⊆M. In the ordinary HSSB, any sub-message m ∈M can be deleted
anytime. We deﬁne DCHSSB that any deletable sub-message m ∈M can be
undeletable anytime. The change of deletability is one-way, which means that any
undeletable sub-message cannot be made deletable again. If every sub-message
is undeletable, the message is ﬁnalized.
DCHSSB is deﬁned as follows. Given a set M, DM(⊆M) denotes the set of
its deletable sub-messages. From a signature on M with DM, we can derive a
signature on M ′ with a set D′
M ′ of its deletable sub-messages, if M ⊆M ′ and
DM ⊇D′
M ′. Obviously, DCHSSB is a subclass of HSSM. Speciﬁcally, DCHSSB is
identical to HSSM with a restriction that any message (M, W) satisﬁes M ⊇W.
From our HSSM scheme in Subsect. 4.2, a DCHSSB scheme secure under
the DLIN assumption is derived. To the best of our knowledge, there has been
two HSSB schemes which satisfy all of the three conditions, namely C1: adap-
tively unforgeable3, C2: strongly context-hiding, and C3: secure under stan-
dard assumptions. They are the scheme by Attrapadung et al. [6] secure under
the DLIN assumption, and the scheme by Ahn et al. [5] instantiated with the
ciphertext-policy attribute-based encryption (CP-ABE) scheme [18]. Since their
disclosure-controllability have not been proven, our scheme is the ﬁrst disclosure-
controllable one satisfying all of the above three conditions. See Table 1.
3 Our unforgeability with Deﬁnition 4 is adaptive. In selective unforgeability [5], the
adversary A must choose the target message M ∗before receiving the public-key pk.

Homomorphic Signatures for Subset and Superset Mixed Predicates
307
5.2
Disclosure-Controllable Redactable Signatures (DCRS)
In redactable signatures (RS) with maximal number of sub-messages N ∈N,
each message M is an ordered list in the form of (m1, · · · , mn) for some n ∈
[1, N], where mi ∈{0, 1}L ∪{∗}. Each (non-redacted) sub-message mi(̸= ∗)
can be changed to ∗, which means it has been redacted, i.e., blacked out. RS
is a subclass of P-HS deﬁned in Sect. 3. The predicate Predact takes M and
M ′, then outputs 1 iﬀn = n′ n
i=1 mi ̸= m′
i
=⇒
m′
i = ∗, where M ′ is
parsed as (m′
1, · · · , m′
n′) for some n′ ∈[1, N]. A RS scheme (parameterized by
L and N) can be transformed from an HSSB scheme with sub-message length
L′ := L + 1 + log(N + 1) and maximal cardinality of message K := N + 1. A RS
message M = (m1, · · · , mn) is changed to an HSSB message M ′ = n
i=1{i ∥0 ∥
mi} {n + 1 ∥1 ∥1L}. Redacting mi in M is deleting the element i ∥0 ∥mi from
M ′4.
In the ordinary RS, any (non-redacted) sub-message can be redacted any-
time. In DCRS, any sub-message which is non-redacted and redactable can be
unredactable. Speciﬁcally, each sub-message has one of the following three states,
namely S1: not redacted yet and redactable, S2: already redacted, and S3: not
redacted yet and unredactable. Any state only transitions from S1 to S2 or from
S1 to S3. If every sub-message is in S2 or S3, the message is ﬁnalized.
DCRS is deﬁned as follows. Each message M = (m1, · · · , mn) is paired
with RM ⊆[1, n] which is a set of indices for redactable sub-messages in
M. The predicate Pdc-redact takes (M, RM) and (M ′, R′
M ′), then outputs 1 iﬀ
n = n′  RM ⊆R′
M ′
n
i=1 mi ̸= m′
i =⇒m′
i = ∗∧i ∈RM. Any DCHSSB scheme
can be transformed into a DCRS scheme basically in the same manner as the
above transformation from HSSB to RS. A RS message M = (m1, · · · , mn)
is changed to the above HSSB message M ′. For any i ∈RM, the element
i ∥0 ∥mi ∈M ′ is designated as an undeletable sub-message.
From our DCHSSB scheme, a DCRS scheme secure under the DLIN assump-
tion is derived. By applying the Attrapadung et al.’s HSSB scheme [5] and the
Ahn et al.’s HSSB scheme [5] instantiated with [18] to the above HSSB-to-RS
transformation, we obtain secure RS schemes. Because they are not DC, ours is
the ﬁrst DCRS satisfying the conditions C1, C2 and C3. See Table 1.
5.3
Eﬃcient Superset Predicate Signatures (SPPS)
SBPS is the digital signature analogue of subset predicate encryption [16]. SPPS
is the superset analogue of SBPS. We consider a stronger primitive in a sense
that it has key-delegatability. SPPS is a subclass of the following key-delegatable
predicate signatures (KDPS) which is formally deﬁned in Subsect. Appendix 5.
In KDPS, setup algorithm Setup, given a security parameter 1λ, generates a
public-parameter pp and master-key mk. Key-generation KGen generates a secret-
key for a key index X ∈X. Key-delegation KDel, given a secret-key for X ∈X,
4 RS with ﬁxed number of sub-messages N ∈N can be obtained in a simpler way. A
RS message M = (m1, · · · , mN) is changed to an HSSB message M ′ = n
i=1{i∥mi}.
Redacting the sub-message mi in M is just deleting the element i ∥mi from M ′.

308
M. Ishizaka and K. Fukushima
generates a secret-key for a key-index X′ ∈X s.t. a key predicate PX : X2 →
{0, 1} holds between X and X′, i.e., 1 ←PX(X, X′). Signing algorithm Sig, given
a secret-key for X ∈X, generates a signature on a message M ∈M associated
with a signature index Y ∈Y s.t. a signature predicate PY : X × Y →{0, 1}
holds, i.e., 1 ←PY(X, Y ). Veriﬁcation Ver veriﬁes a signature. As security for
KDPS, we require unforgeability and signer-privacy.
As a concrete notion of unforgeability, we deﬁne (weak) existential unforge-
ability against adaptively-chosen messages and predicate attacks, abbreviated
as EUF-CMA. We deﬁne an experiment, where a PPT adversary A receives an
honestly-generated public-parameter pp then adaptively accesses two oracles,
namely (key-)revelation and signing oracles. The former, given a key index
X ∈X, returns a secret-key for X. The latter, given message M ∈M and
signature index Y ∈Y, returns a signature on M associated with Y . A wins the
experiment if A succeeds in forging a correct signature σ∗on a message M ∗∈M
with Y ∗∈Y satisfying both of the two conditions: (1) Every X ∈X queried
to the (key-)revelation oracle satisﬁes 0 ←PY(X, Y ∗) and (2) Every ( M ∈M,
Y ∈Y) queried to the signing oracle satisﬁes (M, Y ) ̸= (M ∗, Y ∗).
Signer-privacy guarantees that any signature reveals no information about
the signer’s key index X except for the fact that it satisﬁes the signature index
Y . As a notion of signer-privacy, we deﬁne perfect signer-privacy. We deﬁne
two experiments. In the real experiment, a probabilistic algorithm A queries an
honestly-generated secret-key sk for a key index X, a message M and a signa-
ture index Y s.t. 1 ←PY(X, Y ) to a signing oracle, then receives an honestly-
generated signature σ. In the simulated experiment, A receives a signature σ
which has been generated with no information about X or sk. If both experi-
ments are hard to distinguish, the signer-privacy is satisﬁed.
SPPS is a subclass of KDPS. The message space is M := {0, 1}N for some
N ∈poly(λ). The key index space and signature index space are X := Y :=
2{0,1}L for some L ∈poly(λ). The key predicate PX, given X, X′ ∈X, outputs 1
if X′ ⊆X or 0 otherwise. The signature predicate PY, given X ∈X and Y ∈Y,
outputs 1 if Y ⊆X or 0 otherwise. A SPPS scheme is obtained from an HSSM
scheme with sub-message length max{L, N} + 1 as follows.
Setup(1λ, L, N): It generates a key-pair of the HSSM scheme, i.e., (pp, mk) ←
HSSM.KGen(1λ, max{L, N} + 1), then outputs it.
KGen(mk, X): It generates an HSSM signature sk on a message
(MX, WX) :=
 
x∈X
{0 ∥x}, ∅

,
(8)
i.e., sk ←HSSM.Sig(mk, (MX, WX)), then outputs it.
KDel(sk, X′):
sk
is
assumed
to
be
a
secret-key
for
X
∈
X.
Given
an HSSM signature sk
on (MX, WX) in (8), it derives an HSSM
signature
sk′
on
(MX′, WX′)
:=
(∪x∈X′{0 ∥x′}, ∅),
i.e.,
sk′
←
HSSM.Derive(pp, (MX, WX), sk, (MX′, WX′)), then outputs it.

Homomorphic Signatures for Subset and Superset Mixed Predicates
309
Sig(sk, Y, m): sk is assumed to be a secret-key for X ∈X. Given an HSSM
signature sk on (MX, WX) in (8), it derives an HSSM signature σ on
(MY , WY ) :=
⎛
⎝
y∈Y
{0 ∥y},

y∈Y
{0 ∥y}

{1 ∥m}
⎞
⎠,
(9)
i.e., σ ←HSSM.Derive(pp, (MX, WX), sk, (MY , WY )), then outputs it.
Ver(σ, Y, m): It veriﬁes the HSSM signature σ on (MY , WY ) in (9). It outputs
1/0 ←HSSM.Ver(pp, (MY , WY ), σ).
Theorem 2. The SPPS scheme is PRV (resp. EUF-CMA) if the HSSM scheme is
PRV (resp. SCH and wUNF).
Proof. We ﬁrstly prove PRV then EUF-CMA.
The proof of PRV is simple. The signing oracle takes a SPPS secret-key sk for
X which is an honestly-generated HSSM signature on (MX, WX) in (8), then
honestly generates a SPPS signature σ which is an HSSM signature on (MY , WY )
in (9). If the HSSM scheme is SCH, σ distributes like a fresh signature directly
generated by the HSSM secret-key and has no information about X.
For the proof of EUF-CMA, we deﬁne two experiments. Expt0 is the standard
EUF-CMA experiment w.r.t. the SPPS scheme. Expt1 is the same as Expt0 except
that on the signing oracle the signature σ is directly generated by the HSSM
secret-key mk. Speciﬁcally, the signing oracle, given Y ∈Y and m ∈M, returns
σ ←HSSM.Sig(mk, (MY , WY )) with (MY , WY ) in (9). If the HSSM scheme is
SCH, Expt1 distributes identically to Expt0. If the HSSM scheme is wUNF, any
PPT adversary A wins the experiment Expt1 only with a negligible probability.
A reduction algorithm B receives a public-key pp of the HSSM scheme, then
gives it to A. When A queries (Y ∈Y, m ∈M) to the signing oracle, B makes the
signing oracle generate an HSSM signature σ on (MY , WY ) in (9), then makes the
signature-revelation oracle reveal it. When A queries X ∈X to the key-revelation
oracle, B makes the signing oracle generate an HSSM signature sk on (MX, WX)
in (8), then makes the signature-revelation oracle reveal it. Consider a situation
where A wins. For the forged SPPS signature σ∗on m∗associated with Y ∗∈Y,
following three statements are true. Firstly, σ∗is a correct HSSM signature on
(MY ∗, WY ∗) := (
y∈Y ∗{0 ∥y}, 
y∈Y ∗{0 ∥y} {1 ∥m∗}). Secondly, for every
X queried to the key-revelation oracle, it holds that Y ∗̸⊆X, which implies
that 0 ←Pmixed((MX, WX), (MY ∗, WY ∗)). Thirdly, for every (Y, m) queried to
the signing oracle, it holds that (Y, m) ̸= (Y ∗, m∗), which implies that 0 ←
Pmixed((MY , WY ), (MY ∗, WY ∗)). Thus, if A wins, then B also wins.
⊓⊔
Let us instantiate it by our HSSM scheme secure under the q-SFP and DLIN
assumptions in Subsect. 4.1. Since its secret-key for X is an HSSM signature on
(MX, WX) in (8) with |MX| = |X| and |WX| = 0, it consists of 28 + 7|MX| +
9|WX| = 28 + 7|X| number of elements in G. Since its signature for Y is an
HSSM signature on (MY , WY ) in (9) with |MY | = |Y | and |WY | = |Y | + 1, it
consists of 28 + 7|Y | + 9(|Y | + 1) = 37 + 16|Y | group elements.

310
M. Ishizaka and K. Fukushima
In fact, SPPS can be obtained from HSSB in an ineﬃcient and somewhat
complicated manner. K denotes the maximal cardinality of X or Y . An HSSB
with sub-message length 2 + max{L, 1 + log N, log K} is needed. A SPPS secret-
key for X is an HSSB signature on a set MX := 
x∈X{00 ∥x} |X|−1
i=0
{01 ∥
i} N−1
j=0 {10∥j∥0} N−1
j=0 {10∥j∥1}. A SPPS signature on a message m ∈{0, 1}N
associated with Y is an HSSB signature on MY := 
y∈Y {00 ∥y} {01 ∥|Y | −
1} 
j∈[0,N−1]{10 ∥j ∥m[j]}. We instantiate it by our HSSM scheme in Subsect.
4.1. Its secret-key consists of 28 + 7(2|X| + 2N) + 9 · 0 = 28 + 14(|X| + N) group
elements. Its signature consists of 28 + 7(|Y | + 1 + N) + 9 · 0 = 35 + 7(|Y | + N)
group elements. Thus, its secret-key and signature lengths increase linearly with
N. To the best of our knowledge, since any existing SCH-secure HSSB scheme
has a property that its length of a signature on a set increases linearly with the
cardinality of the set, any one of them leads to a SPPS scheme with a property
that its secret-key and signature lengths increase linearly with N.
5.4
Eﬃcient Wildcarded Identity-Based Signatures (WIBS)
WIBS is the digital signatures analogue of wildcarded identity-based encryp-
tion [1]. WIBS is a subclass of the ordinary (i.e., non key-delegatable) PS.
The message space is M := {0, 1}N for some N ∈poly(λ). The key index
space is X := ({0, 1}L)n for some L, n ∈poly(λ). The signature index space is
Y := ({0, 1}L ∪{∗})n. The signature predicate PY, given X = (x1, · · · , xn) ∈X
and Y = (y1, · · · , yn) ∈Y, outputs 1 if yi ̸= ∗=⇒xi = yi for all i ∈[1, n], or
0 otherwise.
An HSSM scheme can be transformed into a WIBS scheme as follows.
Setup(1λ, L, N): It generates a key-pair of the HSSM scheme with sub-message
length max{L + log L, N} + 1, i.e., (pp, mk) ←HSSM.KGen(1λ, max{L +
log L, N} + 1), then outputs it.
KGen(mk, X): It generates an HSSM signature sk on a message (MX, WX) :=
(n
i=1{0 ∥i ∥xi}, ∅), i.e., sk ←HSSM.Sig(mk, (MX, WX)), then outputs it.
Sig(sk, Y, m): Assume that sk is a secret-key for X ∈X. Given an HSSM
signature sk on (MX, WX), it derives an HSSM signature σ on (MY , WY ) :=
(
i∈[1,n] s.t. yi̸=∗{0 ∥i ∥yi}, 
i∈[1,n] s.t. yi̸=∗{0 ∥i ∥yi} {1 ∥m}), i.e., σ ←
HSSM.Derive(pp, (MX, WX), sk, (MY , WY )), then outputs it.
Ver(σ, Y, m): It veriﬁes the HSSM signature σ on (MY , WY ). It outputs 1/0 ←
HSSM.Ver(pp, (MY , WY ), σ).
Its security is guaranteed by a theorem similar to Theorem 2. As SPPS, WIBS
can also be transformed from HSSB ineﬃciently.
5.5
Subset Predicate Signatures (SBPS)
SBPS is a subclass of KDPS. The spaces M, X and Y are deﬁned as SPPS. PX
takes X, X′ ∈X then outputs 1 iﬀX ⊆X′. PY takes X ∈X and Y ∈Y then
outputs 1 iﬀX ⊆Y .

Homomorphic Signatures for Subset and Superset Mixed Predicates
311
Identity-based ring signatures (IBRS) [24] is a subclass of SBPS. Speciﬁcally,
IBRS is identical to SBPS with the following restrictions, namely (1) there is no
key-delegation and (2) cardinality of the set X ∈X is ﬁxed to 1. As applications
of HSSP, Libert et al. [20] have mentioned only IBRS and append-only signatures
[17]. In fact, SBPS can also be considered as an application of HSSP.
SBPS is transformed from HSSP as follows. By K ∈poly(λ), we denote the
maximal cardinality of the set X ∈X or Y ∈Y.
Setup(1λ, L, N): Generate a key-pair of the HSSP scheme with sub-message
length max{L, N + log K} + 1, i.e., (pp, mk) ←HSSP.KGen(1λ, max{L, N +
log K} + 1), then output it.
KGen(mk, X): Output sk ←HSSP.Sig(mk, WX), where WX := 
x∈X{0 ∥x}.
KDel(sk, X′):
Assume
that
sk
is
a
for
X
∈
X.
Output
sk′
←
HSSP.Derive(pp, WX, sk, WX′), where WX′ := ∪x∈X′{0 ∥x′}.
Sig(sk, Y, m): Assume that sk is for X ∈X. Cardinality of the set Y is denoted
by |Y | ∈[1, K]. Output σ ←HSSP.Derive(pp, WX, sk, WY ), where WY :=

y∈Y {0 ∥y} {1 ∥m ∥|Y |}.
Ver(σ, Y, m): Output 1/0 ←HSSP.Ver(pp, WY , σ).
Appendix 1
Digital Signatures
Syntax. A digital signatures scheme consists of the following three polynomial
time algorithms. Note that Ver is deterministic and the others are probabilistic.
Key-Generation KGen: It takes a security parameter 1λ for λ ∈N, then out-
puts a public-parameter pp, public-key pk and secret-key sk. M denotes space
of messages. Assume that pp is implicitly inputted to the signing and veriﬁ-
cation algorithms.
(pp, pk, sk) ←KGen(1λ)
Siging Sig: It takes a secret-key sk and a message M ∈M, then outputs a
signature σ.
σ ←Sig(sk, M)
Veriﬁcation Ver: It takes a public-key pk, a message M ∈M and a signature
σ, then outputs 1 or 0.
1/0 ←Ver(pk, M, σ)
We require every digital signatures scheme to be correct. A scheme is correct
if for every λ ∈N, every (pp, pk, sk) ←KGen(1λ), every M ∈M, every σ ←
Sig(sk, M), it holds that 1 ←Ver(pk, M, σ).
Security. The most standard unforgeability notion for digital signatures is (weak)
existential unforgeability against chosen messages attacks (EUF-CMA) [14]. We
consider an experiment for a PPT adversary A deﬁned as follows.
ExptEUF-CMA
ΣDS,A(1λ):
//ExptEUF-CMA
ΣDS,A
(pp, pk, sk) ←KGen(1λ). Q := ∅. (M ∗∈M, σ∗) ←ASign(pp, pk)
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
- Sign(M ∈M):
σ ←Sig(sk, M). Q := Q ∪{M}. Rtrn σ
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
Rtrn 1 if 1 ←Ver(pk, M ∗, σ∗) ∧M ∗/∈Q.

312
M. Ishizaka and K. Fukushima
Deﬁnition 6. A digital signatures scheme ΣDS is EUF-CMA if for any λ ∈N and
any PPT algorithm A, its advantage AdvEUF-CMA
ΣDS,A (λ) := Pr[1 ←ExptEUF-CMA
ΣDS,A (1λ)]
is negligible.
We deﬁne the other two unforgeability notions, namely unforgeability against
random messages attacks (UF-RMA) [13] and unforgeability against extended ran-
dom messages attacks (UF-XRMA) [2]. For UF-RMA or UF-XRMA, we consider an
experiment which is the same as the one for EUF-CMA except for the signing ora-
cle. In the experiment for UF-RMA, the signing oracle takes no input and returns
a signature σ on a randomly-chosen message M(
U
←−M). In the experiment for
UF-XRMA, the signing oracle returns not only a signature σ on randomly-chosen
message M(
U
←−M) but also some information aux about the random coins used
to select M. The two notions are deﬁned analogously to EUF-CMA, cf. Deﬁnition 6.
Appendix 2
Non-interactive Witness-Indistinguishable
(NIWI) Proof
Syntax. An NIWI system for the NP relation R : {0, 1}∗×{0, 1}∗→1/0 consists
of the following 3 polynomial-time algorithms. Note that Ver is deterministic and
the others are probabilistic.
Setup Setup: It takes a security parameter 1λ for λ ∈N, then outputs a com-
mon reference string (CRS) crs.
crs ←Setup(1λ)
Proving Pro: It takes the CRS crs, a statement x ∈{0, 1}∗and a witness
w ∈{0, 1}∗, then outputs a proof π.
π ←Pro(crs, x, w)
Veriﬁcation Ver: It takes the CRS crs, a statement x ∈{0, 1}∗and a proof π,
then outputs a veriﬁcation result, which is 1 (accept) or 0 (reject).
1/0 ←Ver(crs, x, π)
We require every NIWI system to be correct. An NIWI system is correct if for
every λ ∈N, every crs ←Setup(1λ), every x ∈{0, 1}∗, every w ∈{0, 1}∗s.t.
1 ←R(x, w), and every π ←Pro(crs, x, w), it holds that 1 ←Ver(crs, x, π).
Security.
We deﬁne two security requirements, namely perfect witness-
indistinguishability (WI) and perfect witness-extractability (WE).
Deﬁnition 7. An NIWI system is perfectly witness-indistinguishable (WI), if
for every λ ∈N, every crs ←Setup(1λ), every x ∈{0, 1}∗, and every
w0, w1 ∈{0, 1}∗s.t. 1 ←R(x, wb) for each b ∈{0, 1}, Pro(crs, x, w0) distributes
identically to Pro(crs, x, w1).
Deﬁnition 8. An NIWI system is perfectly witness-extractable (WE), if for every
λ ∈N, there exist two algorithms SimSetup and Extract that satisfy both of the
following two conditions.
1. For every PPT algorithm A, AdvWE
ΣNIWI,A(λ) := | Pr[1 ←A(crs) | crs ←
Setup(1λ)] −Pr[1 ←A(crs) | (crs, ek) ←SimSetup(1λ)]| is negligible.

Homomorphic Signatures for Subset and Superset Mixed Predicates
313
2. For every PPT algorithm A,
Pr

(crs, ek) ←SimSetup(1λ); (x, π) ←A(crs);
w ←Extract(crs, ek, x, π) : 1 ←Ver(crs, x, π) ∧0 ←R(x, w)

= 0.
Appendix 3
Waters Signatures [23]
Their scheme is based on a symmetric bilinear paring e : G × G →GT with
prime order p and generator g ∈G.
KGen(1λ, L):] L
∈
N denotes bit length of a message. Generate pp
:=
(h, u′, u0, · · · , uL−1), where h, u′, u0, · · · , uL−1
U
←−G. For each message m ∈
{0, 1}L being parsed as m[L −1] ∥· · · ∥m[0], the programmable hash func-
tion HG : {0, 1}L →G takes M then outputs u′ · L−1
i=0 um[i]
i
∈G. Generate
(pk, sk) := (X, x), where X := gx with x
U
←−Zp. Output (pp, pk, sk).
Sig(sk, M): Choose r
U
←−Zp. Output σ := (hx · HG(m)r, gr).
Ver(pk, M, σ): Parse σ as (A, B). Output 1 if e(A, g) = e(X, h) · e(HG(m), B).
Output 0 otherwise.
Theorem 3. Waters signatures scheme is EUF-CMA under the CDH assumption
w.r.t. the group G.
Appendix 4
Abe-Haralambiev-Ohkubo (AHO) SPS [3,4]
Their scheme is based on a symmetric bilinear paring e : G × G →GT with
prime order p and generator g ∈G.
KGen(1λ, n): n ∈N denotes the maximal number of group elements to be signed.
Choose generators gr, hr
U
←−G. Let pp := (gr, gz).
Choose elements γz, δz, αa, αb
U
←−Zp and γi, δi
U
←−Zp for i ∈[1, n]. Compute
gz := gγz
r , hz := hδz
r , A := e(gr, gαa), B := e(hr, gαb), and gi := gδi
r and hi :=
hδi
r for i ∈[1, n]. Output (pp, pk, sk), where pk := (gz, hz, {gi, hi}n
i=1, A, B)
and sk := (αa, αb, γz, δz, {γi, δi}n
i=1).
Sig(sk, (M1, · · · , Mn)): Choose η, ρa, ρb, ωa, ωb
U
←−Zp. Compute θ1 := gη and
θ2 := gρa−γzη ·
n

i=1
M γi
i ,
θ3 := gωa
r ,
θ4 := g(αa−ρa)/ωa,
θ5 := gρb−δzη ·
n

i=1
M δi
i ,
θ6 := hωb
r ,
θ7 := g(αb−ρb)/ωb.
Output a signature σ := (θ1, · · · , θ7).

314
M. Ishizaka and K. Fukushima
Ver(pk, (M1, · · · , Mn), σ): Output 1 if both of the following two equations hold,
namely A = e(gz, θ1) · e(gr, θ2) · e(θ3, θ4) · n
i=1 e(gi, Mi) and B = e(hz, θ1) ·
e(hr, θ5) · e(θ6, θ7) · n
i=1 e(hi, Mi).
As shown in [3,4], any signature σ = (θ1, · · · , θn) can be publicly randomized
as follows. The ﬁrst element is unchanged, i.e., θ′
1 := θ1. We choose η2, η5, μ, ν
U
←−
Zp then compute
θ′
2 := θ2 · θη2
4 ,
θ′
3 := (θ3 · g−η2
r
)1/μ,
θ′
4 := θμ
4 ,
θ′
5 := θ5 · θη5
7 ,
θ′
6 := (θ6 · h−η5
r
)1/ν,
θ′
7 := θν
7.
According to [3,4], (θ′
2, θ′
3, θ′
4) ∈G3 uniformly distribute under a restriction that
e(gr, θ′
2)·e(θ′
3, θ′
4) = e(gr, θ2)·e(θ3, θ4), and (θ′
5, θ′
6, θ′
7) ∈G3 uniformly distribute
under a restriction that e(hr, θ′
5) · e(θ′
6, θ′
7) = e(hr, θ5) · e(θ6, θ7).
Theorem 4. Let q ∈poly(λ) denote the maximal number of signing queries.
The signature scheme is EUF-CMA under the q-SFP assumption.
Appendix 5
Key-Delegatable Predicate Signatures
Key-delegatable predicate signatures (KDPS) consists of the ﬁve polynomial-
time algorithms. Ver is deterministic and the others are probabilistic.
Setup Setup: It takes 1λ, then outputs a public parameter pp and master-
key mk. X, Y and M denote the space of key index, signature index and
message, respectively. Note that the other algorithms implicitly take pp as
input.
(pp, mk) ←Setup(1λ)
Key-Generation KGen: It takes mk and a key index X ∈X, then outputs a
secret-key sk.
sk ←KGen(mk, X)
Key-Delegation KDel: It takes a secret-key sk for a key index X ∈X and a
key index X′ ∈X s.t. 1 ←PX(X, X′), then outputs a secret-key sk′.
sk′ ←KDel(sk, X′)
Signing Sig: It takes a secret-key sk for a key index X ∈X, a signature index
Y ∈Y s.t. 1 ←PY(X, Y ′) and a message M ∈M, then outputs a signature
σ.
σ ←Sig(sk, Y, M)
Veriﬁcation Ver: It takes a signature σ, a signature index Y ∈Y and a mes-
sage M ∈M, then outputs 1 or 0.
1/0 ←Ver(σ, Y, M)
Every KDPS scheme must be correct. Informally the property means that every
correctly generated signature is accepted. Formally the property is deﬁned as
follows. A KDPS scheme is correct if ∀λ ∈N, ∀(pp, mk) ←Setup(1λ), ∀X ∈X,
∀sk ←KGen(mk, X), ∀X′ ∈X s.t. 1 ←PX(X, X′), ∀sk′ ←KDel(sk, X′), ∀Y ∈
Y s.t. 1 ←PY(X′, Y ), ∀M ∈M, ∀σ ←Sig(sk′, Y, M), 1 ←Ver(σ, Y, M) holds.
As security for KDPS, we require unforgeability and signer-privacy. As
a notion of unforgeability, we deﬁne (weak) existential unforgeability against
adaptively-chosen messages and predicate attack (EUF-CMA). For a PPT algo-
rithm A, we consider the following experiment.

Homomorphic Signatures for Subset and Superset Mixed Predicates
315
ExptEUF-CMA
ΣKDPS,A(1λ):
1. (pp, mk) ←Setup(1λ). (σ∗, Y ∗∈Y, M ∗∈M) ←AReveal,Sign(pp).
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
- Reveal(X ∈X): sk ←KGen(mk, X). Q := Q ∪{X}. Rtrn sk.
- Sign(X ∈X, Y ∈Y, M ∈M): sk ←KGen(mk, X). σ ←Sig(sk, M, Y ).
Q′ := Q′ ∪{(Y, M, σ)}. Rtrn σ.
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
2. Rtrn 1 if (1) 1 ←Ver(σ∗, Y ∗, M ∗), (2) ∀X ∈Q, 0 ←PY(X, Y ∗)
and (3) (Y ∗, M ∗, ·) /∈Q′.
3. Rtrn 0.
Deﬁnition 9. A KDPS scheme ΣKDPS is EUF-CMA if for every λ ∈N and
every PPT A, A’s advantage AdvEUF-CMA
ΣKDPS,A(λ) := Pr[1 ←ExptEUF-CMA
ΣKDPS,A(1λ)] is
negligible.
As a notion of signer-privacy, we deﬁne perfect signer-privacy (PRV). For a prob-
abilistic algorithm A, we consider the following two experiments.
ExptPRV
ΣKDPS,A,0(1λ): //ExptPRV
ΣKDPS,A,1
(pp, mk) ←Setup(1λ). (pp, mk, μ) ←SimSetup(1λ).
Rtrn b′ ←AReveal,Sign(pp, mk).
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
- Reveal(X ∈X):
sk ←KGen(mk, X). sk ←SimKGen(mk, μ, X). Q := Q ∪{(X, sk)}. Rtrn sk.
- Sign(X ∈X, sk, Y ∈Y, M ∈M):
Rtrn ⊥if (X, sk) /∈Q ∨0 ←PY(X, Y ).
σ ←Sig(sk, Y, M). σ ←SimSig(mk, μ, Y, M). Rtrn σ.
The latter is associated with 3 polynomial-time algorithms {SimSetup, SimKGen,
SimSig}. The grey parts are considered in the latter, but ignored in the former.
Deﬁnition 10. A KDPS scheme ΣKDPS is perfectly signer-private (PRV)
if
for
every
λ
∈
N
and
every
probabilistic
algorithm
A,
there
exist
polynomial-time algorithms {SimSetup, SimKGen, SimSig} such that A’s advan-
tage AdvPRV
ΣKDPS,A(λ) := | 1
b=0(−1)b Pr[1 ←ExptPRV
ΣKDPS,A,b(1λ)]| is 0.
Appendix 6
An Omitted Part in the Proof of Lemma 3
We prove that there exists a PPT adversary B′
3 s.t. Pr[S2 ∧Abort] ≤4q · dM ·
(L+1)·AdvCDH
B′
3,G(λ), where dM ∈poly(λ) denotes the maximal cardinality of the
set M.
Let A denote a PPT adversary which makes the event S2 ∧Abort occurs with
a non-negligible probability. Let B′
3 denote a PPT adversary which, by using A
as black-box, attempts to solve the CDH problem relative to the group G. B′
3
behaves as follows.
Receive (g, ga, gb) as an instance of the CDH problem. Honestly generate a
key-pair (pks, sks) of the AHO scheme and a GS CRS f = (#»f 1, #»f 2, #»f 3) in the
perfect soundness setting. Then conduct the following two steps.

316
M. Ishizaka and K. Fukushima
1. Set l := 2dM. Choose uniformly at random an integer k satisfying 0 ≤k ≤L.
Assume that l(L + 1) ≤p.
2. Let h := ga. Choose x′, x0, · · · , xL−1
U
←−Zl and y′, y0, · · · , yL−1
U
←−Zp. For
an element m ∈{0, 1}L, deﬁne two functions J, K : {0, 1}L →Zp as J(m) :=
x′ +L−1
i=0 xi ·m[i]−lk and K(m) := y′ +L−1
i=0 yi ·m[i]. Set u′ := (gb)−lk+x′ ·
gy′ and ui := (gb)xi · gyi for i ∈[0, L −1]. It holds that u′ L−1
i=0 um[i]
i
=
(gb)−lk+x′+L−1
i=0 xi·m[i] · gy′+L−1
i=0 yi·m[i] = (gb)J(m) · gK(m).
Set pk := (G, GT , g, h, u′, {ui}L−1
i=0 , pks, f) and send it to A. Since we have
assumed that the event S2 ∧Abort occurs, it will hold that ∃κ ∈[1, q] s.t.
(Xκ, Yκ) = (X∗, Y ∗) ∧Mκ ̸⊇M ∗. B′
3 guesses such an index κ and chooses
κguess
U
←−[1, q]. The guess is correct at least with probability 1/q. B′
3 proceeds
under an assumption that the guess is correct. When A issues a query to the
signing oracle, B′
3 behaves as follows.
Sign(M, W): Assume that this query is the κ-th query to the oracle. B′
3 considers
the following two cases.
1. κ ̸= κguess: B′
3 honestly generates the whole HSSM signature σ oneself,
then returns it to A.
2. κ = κguess: If ∃m ∈M s.t. J(m) = 0 (mod l), B′
3 aborts the
simulation. Otherwise, every m ∈M satisﬁes J(m) ̸= 0 (mod l),
which implies J(m) ̸= 0 (mod p). B′
3 sets X := gb. Then, for each
m ∈M, B′
3 behaves as follows. We have assumed that it holds that
J(m) ̸= 0 (mod p). B′
3 chooses χm
U
←−Zp, then generates (σm,1, σm,2) :=
((ga)
K(m)
J(m) (u′ L−1
i=0 um[i]
i
)χm, (ga)−
1
J(m) gχm). Let χ′
m := χm−
a
J(m). Obvi-
ously, σm,2 = gχ′
m. It holds that σm,1 = gab ·

(gb)J(m) · gK(m)−
a
J(m) ·

(gb)J(m) · gK(m)χm = gab·

(gb)J(m) · gK(m)χ′
m = hb·HG(m)χ′
m. Thus,
the Waters signature (σm,1, σm,2) correctly distributes. B′
3 honestly gen-
erates the other elements of the HSSM signature σ, then returns σ to
A.
B′
3 receives a forged signature σ∗sent by A. Since we have assumed that the
event S2 ∧Abort occurs, all of the following three conditions hold, namely (a)
X∗= Xκguess, (b) M ∗̸⊆Mκguess, and (c) for each m ∈M ∗, (σ∗
m,1, σ∗
m,2) =
(hb · HG(m)χm, gχm) with some χm ∈Zp.
The second condition (b) implies that ∃m∗∈M ∗s.t. m∗/∈Mκguess. B′
3
arbitrarily chooses a single element m∗satisfying the above condition, then
aborts the simulation if J(m∗) ̸= 0 (mod p). B′
3 computes σ∗
m∗,1/(σ∗
m∗,2)K(m∗) =
hb · HG(m∗)χm∗/(gK(m∗))χm∗= hb = gab ∈G then outputs it as the answer to
the CDH problem.
Let SimAbort denote the event that B′
3 aborts the simulation. At least when
the event S2 ∧Abort has occurred and B′
3 has not aborted the simulation, B′
3
ﬁnds the correct answer to the CDH problem. Thus, it holds that

Homomorphic Signatures for Subset and Superset Mixed Predicates
317
AdvCDH
B′
3,G(λ) ≥Pr[S2 ∧Abort ∧¬SimAbort]
= Pr[¬SimAbort | S2 ∧Abort] · Pr[S2 ∧Abort],
which implies that
Pr[S2 ∧Abort] ≤
1
Pr[¬SimAbort | S2 ∧Abort] · AdvCDH
B′
3,G(λ).
We analyze the probability Pr[¬SimAbort | S2 ∧Abort]. We deﬁne three events.
E1: (X∗, Y ∗) = (Xκguess, Yκguess)
E2: ∀m ∈Mκguess, J(m) ̸= 0 (mod l)
E3: ∃m∗∈M ∗s.t. m∗/∈Mκguess ∧J(m∗) = 0 (mod p)
We obtain
Pr[¬SimAbort | S2 ∧Abort]
= Pr[E1 ∧E2 ∧E3 | S2 ∧Abort]
= Pr[E1 | S2 ∧Abort] · Pr[E2 ∧E3 | S2 ∧Abort ∧E1]
= Pr[E1 | S2 ∧Abort] · Pr[E3 | S2 ∧Abort ∧E1] · Pr[E2 | S2 ∧Abort ∧E1 ∧E3].
We analyze each term. Obviously, Pr[E1 | S2 ∧Abort] ≥1/q. The second term is
analyzed as follows.
Pr[E3 | S2 ∧Abort ∧E1]
= Pr[J(m∗) = 0
(mod p) | S2 ∧Abort ∧E1]
= Pr[J(m∗) = 0
(mod l) | S2 ∧Abort ∧E1]
· Pr[J(m∗) = 0
(mod p) | S2 ∧Abort ∧E1 ∧J(m∗) = 0
(mod l)]
= 1
l
1
L + 1
The third term is as follows.
Pr[E2 | S2 ∧Abort ∧E1 ∧E3]
= Pr
⎡
⎣

m∈Mκguess
J(m) ̸= 0
(mod l)

S2 ∧Abort ∧E1 ∧E3
⎤
⎦
≥1 −

m∈Mκguess
Pr[J(m) = 0
(mod l) | S2 ∧Abort ∧E1 ∧E3]
= 1 −

m∈Mκguess
1
l ≥1 −dM
l
As a result, we obtain
Pr[¬SimAbort | S2 ∧Abort] ≥1
q · 1
l ·
1
L + 1 ·

1 −dM
l

=
1
4q · dM · (L + 1)
Therefore, Pr[S2 ∧Abort] ≤4q · dM · (L + 1) · AdvCDH
B′
3,G(λ).
⊓⊔

318
M. Ishizaka and K. Fukushima
References
1. Abdalla, M., Catalano, D., Dent, A.W., Malone-Lee, J., Neven, G., Smart, N.P.:
Identity-based encryption gone wild. In: Bugliesi, M., Preneel, B., Sassone, V.,
Wegener, I. (eds.) ICALP 2006. LNCS, vol. 4052, pp. 300–311. Springer, Heidelberg
(2006). https://doi.org/10.1007/11787006 26
2. Abe, M., Chase, M., David, B., Kohlweiss, M., Nishimaki, R., Ohkubo, M.:
Constant-size structure-preserving signatures: generic constructions and simple
assumptions. In: Wang, X., Sako, K. (eds.) ASIACRYPT 2012. LNCS, vol. 7658,
pp. 4–24. Springer, Heidelberg (2012). https://doi.org/10.1007/978-3-642-34961-
4 3
3. Abe, M., Fuchsbauer, G., Groth, J., Haralambiev, K., Ohkubo, M.: Structure-
preserving signatures and commitments to group elements. In: Rabin, T. (ed.)
CRYPTO 2010. LNCS, vol. 6223, pp. 209–236. Springer, Heidelberg (2010).
https://doi.org/10.1007/978-3-642-14623-7 12
4. Abe, M., Haralambiev, K., Ohkubo, M.: Signing on elements in bilinear groups for
modular protocol design. Cryptology ePrint Archive (2010)
5. Ahn, J.H., Boneh, D., Camenisch, J., Hohenberger, S., Shelat, A., Waters, B.:
Computing on authenticated data. In: Cramer, R. (ed.) TCC 2012. LNCS, vol.
7194, pp. 1–20. Springer, Heidelberg (2012). https://doi.org/10.1007/978-3-642-
28914-9 1
6. Attrapadung, N., Libert, B., Peters, T.: Computing on authenticated data: new
privacy deﬁnitions and constructions. In: Wang, X., Sako, K. (eds.) ASIACRYPT
2012. LNCS, vol. 7658, pp. 367–385. Springer, Heidelberg (2012). https://doi.org/
10.1007/978-3-642-34961-4 23
7. Attrapadung, N., Libert, B., Peters, T.: Eﬃcient completely context-hiding
quotable and linearly homomorphic signatures. In: Kurosawa, K., Hanaoka, G.
(eds.) PKC 2013. LNCS, vol. 7778, pp. 386–404. Springer, Heidelberg (2013).
https://doi.org/10.1007/978-3-642-36362-7 24
8. Bethencourt, J., Sahai, A., Waters, B.: Ciphertext-policy attribute-based encryp-
tion. In: IEEE SP 2007, pp. 321–334. IEEE (2007)
9. Bl¨omer, J., Eidens, F., Juhnke, J.: Enhanced security of attribute-based signatures.
In: Camenisch, J., Papadimitratos, P. (eds.) CANS 2018. LNCS, vol. 11124, pp.
235–255. Springer, Cham (2018). https://doi.org/10.1007/978-3-030-00434-7 12
10. Boneh, D., Boyen, X., Shacham, H.: Short group signatures. In: Franklin, M. (ed.)
CRYPTO 2004. LNCS, vol. 3152, pp. 41–55. Springer, Heidelberg (2004). https://
doi.org/10.1007/978-3-540-28628-8 3
11. Boneh, D., Lynn, B., Shacham, H.: Short signatures from the Weil pairing. In:
Boyd, C. (ed.) ASIACRYPT 2001. LNCS, vol. 2248, pp. 514–532. Springer, Hei-
delberg (2001). https://doi.org/10.1007/3-540-45682-1 30
12. Bultel, X., Lafourcade, P., Lai, R.W.F., Malavolta, G., Schr¨oder, D., Thyagara-
jan, S.A.K.: Eﬃcient invisible and Unlinkable Sanitizable signatures. In: Lin, D.,
Sako, K. (eds.) PKC 2019. LNCS, vol. 11442, pp. 159–189. Springer, Cham (2019).
https://doi.org/10.1007/978-3-030-17253-4 6
13. Even, S., Goldreich, O., Micali, S.: On-line/oﬀ-line digital signatures. J. Cryptol.
9(1), 35–67 (1996). https://doi.org/10.1007/BF02254791
14. Goldwasser, S., Micali, S., Rivest, R.L.: A digital signature scheme secure against
adaptive chosen-message attacks. SIAM J. Comput. 17(2), 281–308 (1988)
15. Groth, J., Sahai, A.: Eﬃcient non-interactive proof systems for bilinear groups.
In: Smart, N. (ed.) EUROCRYPT 2008. LNCS, vol. 4965, pp. 415–432. Springer,
Heidelberg (2008). https://doi.org/10.1007/978-3-540-78967-3 24

Homomorphic Signatures for Subset and Superset Mixed Predicates
319
16. Katz, J., Maﬀei, M., Malavolta, G., Schr¨oder, D.: Subset predicate encryption
and its applications. In: Capkun, S., Chow, S.S.M. (eds.) CANS 2017. LNCS, vol.
11261, pp. 115–134. Springer, Cham (2018). https://doi.org/10.1007/978-3-030-
02641-7 6
17. Kiltz, E., Mityagin, A., Panjwani, S., Raghavan, B.: Append-only signatures. In:
Caires, L., Italiano, G.F., Monteiro, L., Palamidessi, C., Yung, M. (eds.) ICALP
2005. LNCS, vol. 3580, pp. 434–445. Springer, Heidelberg (2005). https://doi.org/
10.1007/11523468 36
18. Lewko, A., Okamoto, T., Sahai, A., Takashima, K., Waters, B.: Fully secure
functional encryption: attribute-based encryption and (hierarchical) inner prod-
uct encryption. In: Gilbert, H. (ed.) EUROCRYPT 2010. LNCS, vol. 6110, pp.
62–91. Springer, Heidelberg (2010). https://doi.org/10.1007/978-3-642-13190-5 4
19. Lewko, A., Waters, B.: New techniques for dual system encryption and fully
secure HIBE with short ciphertexts. In: Micciancio, D. (ed.) TCC 2010. LNCS,
vol. 5978, pp. 455–479. Springer, Heidelberg (2010). https://doi.org/10.1007/978-
3-642-11799-2 27
20. Libert, B., Joye, M., Yung, M., Peters, T.: Secure eﬃcient history-hiding append-
only signatures in the standard model. In: Katz, J. (ed.) PKC 2015. LNCS, vol.
9020, pp. 450–473. Springer, Heidelberg (2015). https://doi.org/10.1007/978-3-
662-46447-2 20
21. Maji, H.K., Prabhakaran, M., Rosulek, M.: Attribute-based signatures. In: Kiayias,
A. (ed.) CT-RSA 2011. LNCS, vol. 6558, pp. 376–392. Springer, Heidelberg (2011).
https://doi.org/10.1007/978-3-642-19074-2 24
22. Steinfeld, R., Bull, L., Zheng, Y.: Content extraction signatures. In: Kim, K. (ed.)
ICISC 2001. LNCS, vol. 2288, pp. 285–304. Springer, Heidelberg (2002). https://
doi.org/10.1007/3-540-45861-1 22
23. Waters, B.: Eﬃcient identity-based encryption without random oracles. In: Cramer,
R. (ed.) EUROCRYPT 2005. LNCS, vol. 3494, pp. 114–127. Springer, Heidelberg
(2005). https://doi.org/10.1007/11426639 7
24. Zhang, F., Kim, K.: ID-based blind signature and ring signature from pairings.
In: Zheng, Y. (ed.) ASIACRYPT 2002. LNCS, vol. 2501, pp. 533–547. Springer,
Heidelberg (2002). https://doi.org/10.1007/3-540-36178-2 33

Adaptively Secure Identity-Based
Encryption from Middle-Product Learning
with Errors
Jingjing Fan1
, Xingye Lu2(B)
, and Man Ho Au2
1 University of Hong Kong, Pok Fu Lam, China
jjfan@cs.hku.hk
2 The Hong Kong Polytechnic University, Hung Hom, China
{xing-ye.lu,mhaau}@polyu.edu.hk
Abstract. Introduced in 2017, Middle-Product Learning with Errors
(MPLWE) and its variants oﬀer a way to construct cryptographic prim-
itives which preserve the eﬃciency of those based on Polynomial-LWE
(PLWE) while being at least as secure as them over a broad choice of
number ﬁelds. Based on MPLWE, a series of cryptographic schemes have
been proposed, including public key encryption (PKE), digital signature,
and identity-based encryption (IBE). In this paper, we extend this line
of research and propose a new IBE scheme that is adaptively secure in
the standard model from MPLWE. Existing IBE schemes from MPLWE
only oﬀer selective security or rely on the random oracle model. We fol-
low the blueprint of Agrawal et al. at EUROCRYPT2010 and adapt the
well-known partitioning technique to the MPLWE setting. The result-
ing scheme oﬀers similar eﬃciency to schemes based on PLWE under a
milder assumption.
Keywords: Lattice-Based Cryptography · Middle-Product LWE ·
Identity-Based Encryption
1
Introduction
Conceptualised by Shamir in 1984 [24], identity-based encryption (IBE) allows
users to use any string (e.g. email address) as the public key. However, it was not
until two decades later that the ﬁrst realization of IBE was proposed. In 2001,
Boneh and Franklin [7] and Cocks [10] proposed IBE schemes from Weil pairing
and quadratic residues for a composite modulus respectively. Both schemes are
proven secure in the random oracle model. Subsequently, [5,8] presented IBE in
the standard model oﬀering selective security, meaning that the adversaries are
required to declare the challenge identity before seeing the public parameters.
More recently, adaptively secure IBE schemes in the standard model have been
developed [6,26,27] based on the hardness of certain number-theoretic problems.
The advent of quantum computers poses a serious threat to the aforemen-
tioned schemes as quantum algorithms can eﬃciently solve the number-theoretic
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 320–340, 2023.
https://doi.org/10.1007/978-3-031-35486-1_15

Adaptively Secure IBE from MPLWE
321
problems on which they rely. To prevent attacks from quantum computers, post-
quantum cryptography is being actively investigated. Lattice-based cryptogra-
phy is one of the most important area of post-quantum cryptography. Based
on the hardness of the Short Integer Solution problem (SIS) introduced in [2]
and the Learning With Errors problem (LWE) introduced in [21], lattice-based
cryptography has led to numerous cryptographic constructions that are conjec-
tured to be hard to break even for quantum algorithms. In 2008, Gentry et al.
proposed the ﬁrst lattice-based IBE scheme [12] in the random oracle model. In
2010, Agrawal et al. [1] proposed an IBE scheme that is adaptively secure in
the standard model. Cash et al. [9] introduced a new lattice-based admissible
hash called a Bonsai tree and used it to construct a hierarchical identity-based
encryption scheme in the standard model. These IBE schemes [1,9] are both from
standard lattices and require O(ℓ) basic matrices in the master public keys, where
ℓis the length of the identity. Later, lattice-based IBE schemes with compact
master public keys were proposed. In 2016, Yamada [28] presented adaptively
secure IBE schemes with short master public keys from standard LWE. In the
same year, Katsumata and Yamada [14], proposed adaptively secure compact
IBE schemes from ring LWE. Both of these two schemes have master public
keys with around O(
√
ℓ) basic matrices (vectors). To further reduce the master
public key size, Zhang et al. [30] and Yamada [29] proposed adaptively secure
IBE from standard LWE with master public key size grows logarithmically with
the identity length. Among these compact IBE schemes, the ones from stan-
dard lattice have large master public key sizes, while those from ideal lattice
are based on RLWE problems whose hardness is relatively less well-understood.
The middle-product learning with errors (MPLWE) was proposed by Roşca et
al. [22]. It is a variant of the polynomial learning with errors (PLWE) [25] and the
ring learning with errors (RLWE) [18] problem. It exploits the middle-product
of polynomials modulo prime q. MPLWE is shown to be as secure as PLWE for
a large class of polynomials. Roşca et al. also presented an encryption scheme
from MPLWE, whose eﬃciency is similar to those based on RLWE. MPLWE
has also been used to construct other cryptographic primitives such as digi-
tal signatures [3] and ring signatures [11]. In 2019, Lombardi et al. generalized
MPLWE to degree-parameterized MPLWE [16], and showed that schemes based
on degree-parameterized MPLWE are at least as secure as those based on PLWE.
They gave a pre-image sampleable function for MPLWE (can be regarded as a
GPV [12] sampler in the MPLWE setting) and used it to construct IBE schemes
in the random oracle and standard model respectively. In 2020, Le et al. [15]
improved the IBE construction and proposed a hierarchical IBE scheme. While
these schemes [15,16] are secure in the standard model, they only oﬀer selective
security. A natural problem is, therefore, to construct adaptively secure IBE in
the standard model from MPLWE.
1.1
Our Contribution
In this paper, we focus on the construction of adaptively secure IBE based on
degree-parameterized middle-product LWE (dMPLWE) in the standard model.

322
J. Fan et al.
We follow the blueprint of [1] (which makes use of abort-resistant hash func-
tions) and adapt it to the MPLWE setting. This enables us to go from the selec-
tively secure IBE to an adaptively secure one. Compared with existing adaptively
secure IBE from ideal lattices [14,28], our dMPLWE IBE beneﬁts from the fact
that its security does not rely on the choice of the underlying ring, while enjoy-
ing similar eﬃciency. We compared our IBE scheme with existing lattice-based
adaptively secure IBE schemes in the standard model in Table 1.
Remarks. We set identity length ℓ= O(n). KY16 type 2 [14] has the smallest
master public key and ciphertext/secret key size among the existing adaptively
secure IBEs from RLWE, while the Yam17 type 2 [29] has the smallest master
public key size among the ones from standard LWE. Our scheme is the ﬁrst
and only scheme from MPLWE. At similar eﬃciency, our scheme would be more
secure compared with those from RLWE. Compared with schemes from standard
lattice, our scheme typically enjoys shorter master public key size. Also, our IBE
scheme is secure when the LWE assumption holds for 1/α = ˜O(n3) while Yam17
Type 2 [29] is secure only when LWE assumption holds with 1/α = poly(n) for
all polynomials poly(n).
Table 1. Comparison between Lattice-Base Adaptively Secure IBEs in the Standard
Model and Our Scheme
Scheme
|mpk|
|C|, |skid|
1/α for LWE
Assumption
LWE type
CHKP10 [9]
O(n2ℓlog n)
O(nℓlog n)
˜O(n1.5)
Standard LWE
ABB10 [1]
O(n2ℓlog n)
O(n log n)
˜O(n2)
Standard LWE
Yam16: Type 1 [28] O(n2ℓ
1
c log n)
O(n log n)
superpoly(n)
Standard LWE
Yam16: Type 2 [28] O(n2ℓ
1
c log n)
O(n log n)
All poly(n)
Standard LWE
KY16: Type 1 [14]
O(nℓ
1
c log n)
O(n log n)
˜O(n2c−1
2 )
RLWE
KY16: Type 2 [14]
O(nℓ
1
c )
O(n)
˜O(n2c+ 3
8 )
RLWE
ZCZ16 [30]
O(n2 log ℓlog n)
O(n log n)
Q2 ˜O(n6.5)
Standard LWE
Yam17: Type 1 [29] O(n2 log3 ℓlog n) O(n log n)
˜O(n11)
Standard LWE
Yam17: Type 2 [29] O(n2 log2 ℓlog n) O(n log n)
All poly(n)
Standard LWE
Our IBE Scheme
O(nℓlog n)
O(n log n)
˜O(n3)
MPLWE
“1/α” for LWE assumption refers to the underlying LWE assumption used in the
security reduction. ℓis the identity length. c is a ﬂexible constant (recommended to
be 2 or 3 in [14]). “All poly(n)” means that we have to assume the LWE assumption
for all polynomial. Q = poly(n) refers to the number of queries made by the adversary.
˜O(f(n)) = O(f(n) logc n) for some constant c.
1.2
Overview
To illustrate our construction, we ﬁrst provide a high-level overview. Similar to
the adaptively secure IBE schemes based on LWE/PLWE, our approach employs

Adaptively Secure IBE from MPLWE
323
a hash function, denoted as h(·), to map each user identity to a vector with poly-
nomial entries. This function enables us to associate each identity id with a pub-
lic polynomial vector [−→a |h(id)] ∈(Z<n
q
[x])t × (Z<n+d−1
q
[x])γτ × (Z<n+d−1
q
[x])γτ,
where −→a and the polynomial vectors used to compute function h served as mas-
ter public keys. The polynomial vector −→a is equipped with a trapdoor that
facilitates the sampling of −→t such that −→a · −→t = w for a given w. To extract
the secret key for a user id, the KGC utilizes the trapdoor of a to generate skid
such that [−→a |h(id)] · skid = u for a predetermined u in the master public key. To
encrypt a message, one utilizes [−→a |h(id)] and u as the public key and follows the
Dual Regev PKE [12] in the MPLWE setting.
During the proof, −→a is randomly sampled from its distribution, without a
known trapdoor, while h(·) is generated in a way such that for a large set of
identities, the output vector polynomial is equipped with a trapdoor that enables
the sampling of user secret keys. For the remaining identities, there exists no
such trapdoor. We then proceed to demonstrate that the probability that all
the key extraction query identities belong to the large set, while the challenge
identity belongs to the remaining set, is non-negligible (the argument makes use
of the aforementioned abort-resistant hash functions). Finally, we leverage the
adversary’s response in this setting to distinguish between MPLWE samples and
those uniformly distributed ones.
Paper Organization. We give preliminaries in Sect. 2. We present the trapdoor
generation and sampling algorithms in Sect. 3, followed by our construction and
security analysis in Sect. 4. Finally, we conclude our work in Sect. 5.
2
Preliminaries
2.1
Notations
We use n to denote the security parameter. We use standard big-O notation
to classify the growth of functions. We say that f(n) = ˜O(g(n)) if f(n) =
O(g(n)·logc n) for some constant c. We use poly(n) to denote a random function
f(n) = O(nc) for some constant c. We say that a function f(n) is negligible
(denoted by negl(n)) if for every polynomial p, there exists an N s.t. for all
n > N, it holds that f(n) <
1
p(n). We say that a probability is overwhelming if
it is 1 −negl(n).
2.2
Identity-Based Encryption
Syntax. An identity-based encryption(IBE) scheme usually consists of four algo-
rithms, namely (KeyGen, Extract, Enc, Dec), which run as follows:
– KeyGen(1n) →(mpk, msk): On input the security parameter 1n, generates
master public key and master secret key pair (mpk, msk).
– Extract(mpk, msk, id) →skid: On input the master public key mpk, master
secret key msk and the identity id, outputs the secret key for the identity skid.

324
J. Fan et al.
– Enc(mpk, id, m) →c: On input the master public key mpk, identity id and
message μ, outputs the ciphertext c.
– Dec(skid, c) →m: On input the secret key for the identity skid and the cipher-
text c, outputs a message m.
An IBE scheme IBE = (KeyGen, Extract, Enc, Dec) possesses correctness if for
all identities id and message m, we have Pr[Dec(skid, Enc(mpk, id, m)) = m] =
1 −negl(n) where the probability is taken with respect to the randomness of
KeyGen, Extract, Enc, and Dec.
IND-CPA Security. The adaptive IND-CPA security for an IBE scheme can
be deﬁned by the following game between adversary A and challenger C.
– Setup. Challenger C runs KeyGen(1n) →(mpk, msk) and sends mpk to adver-
sary A.
– Key Extraction Query Adversary A sends a user ID id to challenger C, C
returns skid ←Extract(mpk, msk, id).
– Challenge. Adversary A picks the challenging identity id∗and two messages
m0 and m1 on which it wishes to be challenged. If id∗has been queried in
key extraction query, C aborts and outputs ⊥. Otherwise, C tosses a coin
coin
$←−{0, 1} and sends C∗←Enc(mpk, id∗, mcoin) to A.
– Key Extraction Query. Adversary A can make further key extraction query
on identity id ̸= id∗.
– Output. A outputs a coin coin∗.
A wins the game if coin∗= coin. The advantage of A in this IND-CPA game
is deﬁned by AdvA = Pr[A wins IND-CPA game] −1
2.
Deﬁnition 1 (IND-CPA). An IBE scheme is adaptive IND-CPA secure if for
any polynomial-time adversary A, AdvIBE
A
is negligible.
2.3
Lattices and Gaussian Distributions
An n-dimensional lattice in m-dimensional Euclidean space is an additive discrete
set deﬁned as follows: Λ(b1, . . . , bn) = {n
i=1 xibi|xi ∈Z}, where b1, . . . , bn ∈
Zm are linearly independent column vectors. We say that Λ is full rank iﬀn = m.
The dual lattice of Λ, denoted as Λ∗is deﬁned as: Λ∗= {y ∈spanR(Λ)|⟨y, x⟩∈
Z, ∀x ∈Λ}. For positive integers n, q and any matrix A ∈Zn×m, let Λ⊥:=
{z ∈Zm|Az = 0 mod q}. For u ∈Zn
q s.t. ∃t ∈Zm
q
satisfying At = u, let
Λ⊥
u (A) := {z ∈Zm|Az = u mod q}, Λ⊥
u (A) = Λ⊥(A) + t.
Next, we will recap some well-known deﬁnitions concerning Gaussian distri-
bution that would be used in our proof.
Continuous Gaussian Distribution. For a positive semi-deﬁnite matrix Σ ∈
Rn×n, the continuous Gaussian distribution DΣ is the probability distribution
over Rn whose density is proportional to ρΣ(x) = exp(−πxT Σ−1x).
Discrete Gaussian Distribution. Given a countable set S ⊂Rn and s > 0,
the discrete Gaussian distribution DS,σ,c is the probability distribution over S

Adaptively Secure IBE from MPLWE
325
whose density is proportional to ρσ,c(x) := exp( −π·∥x−c∥2
σ2
). That is, for x ∈S,
DS,σ,c := ρσ,c(x)
ρσ,c(S). If c = 0, we can omit c and write DS,σ instead.
For any n-dimensional lattice Λ and real ϵ > 0, the smoothing parameter ηϵ(λ)
is deﬁned to be the smallest real s > 0 such that ρ1/s(Λ∗\ {0}) ≤ϵ [20].
Gaussian Tail Inequality. For any ϵ > 0, any σ ≥ηϵ(Z), and any t > 0, we
have Prx←DZ,σ,c[|x −c| ≥t · σ] ≤2e−πt2 · 1+ϵ
1−ϵ. In particular, for ϵ ∈(0, 1/2) and
t ≥ω(√log n), the probability that |x −c| ≥t · σ is negligible in n [12].
2.4
Polynomials, Matrices and Middle Product of Polynomials
In this paper, a vector will refer to a column vector unless otherwise stated. For
a matrix A, we will use Ai,j to denote its (i, j)-th entry. Let R be a ring. For
any d > 0 and any set S ⊂R, we let S<d[x] denote the set of polynomials in
R[x] of degree < d whose coeﬃcients are in S. For any distribution χ deﬁned
over R, let χd[x] denote the distribution on polynomials in R<d[x] where each
coeﬃcient is sampled independently according to χ.
Given a polynomial a = d−1
i=0 aixi ∈R<d[x], deﬁne the coeﬃcient vector of a
as a := (a0, · · · , ad−1)T ∈Rd and set a = (ad−1, ad−2, · · · , a1, a0)T ∈Rd. We can
see that ¯a = a. In particular, for any 0 ≤i ≤d−1, ai denoted the coeﬃcient of xi
in a. Let d ∈Zn = (d1, · · · , dn)T be an integer vector with positive coeﬃcients.
Deﬁne a column vector, called polynomial vector, −→a := (a1, · · · , an)T ∈R<d[x],
where ai is a polynomial in R[x]<di for i = 1, · · · , n.
Let d ∈Zn = (d1, · · · , dn)T be an integer vector with positive coeﬃcients and
t be a positive integer. Deﬁne polynomial matrix −→
A := [−→
a1, · · · , −→
at]T ∈Rt×<d[x],
where −→
ai is a polynomial vector in R[x]<d[x] for i = 1, · · · , t.
Then, we will deﬁne the inner product of polynomial vectors as follows.
Deﬁnition 2. Let d, k ∈Zn be integer vectors with positive coeﬃcients. Let
−→a := (a1, · · · , an)T ∈R<d[x], −→b
:= (b1, · · · , bn)T ∈R<k[x] be polynomial
vectors, where ai is a polynomial in R<di[x] for i = 1, · · · , n and where bi is a
polynomial in R<ki[x] for i = 1, · · · , n. We deﬁne the inner product of −→a and
−→b as follows: −→a · −→b := n
i=1 aibi
We will deﬁne the multiplication between polynomial vectors and polynomial
matrices as follows.
Deﬁnition 3. Let d, k ∈Zn be integer vectors with positive coeﬃcients and
t be a positive integer. Let −→
A
:= [−→
a1, · · · , −→
at]T
∈Rt×<d[x] be a polyno-
mial matrix consisting of t polynomial vectors, −→
a1, · · · , −→
ai, · · · −→
at in R<d[x]. Let
−→b := (b1, · · · , bn)T ∈R<k[x] be a polynomial vector, where bi are polynomials
in R[x]<k for i = 1, · · · , n. We deﬁne the matrix-vector multiplication between
−→
A and −→b as follows: −→
A · −→b = [−→
a1 · −→b , · · · , −→
at · −→b ]T
For a vector v ∈Rn, let ∥v∥, ∥v∥∞denote its Euclidean and sup norm
respectively. We deﬁne the largest singular value of a matrix A ∈Rm×n as
σ1(A) := max∥u∥=1∥Au∥.

326
J. Fan et al.
Lemma 1. For any matrix A ∈Rm×n, we have σ1(A) ≤√mn maxi,j|Ai,j|
Deﬁnition 4 (Tensor Product). For m1, m2, n1, n2 > 0, the tensor product
⊗: Rm1×n1 × Rm2×n2 →Rm1m2×n1n2 is deﬁned to be the map:
A⊗B =
⎡
⎢⎣
A1,1B . . . A1,nB
...
...
...
Am,1B . . . Am,nB
⎤
⎥⎦for matrix A ∈Rm1×n1 and matrix B ∈Rm2×n2.
Deﬁnition 5 ([17], Deﬁnition 6). Let R be a ring and d, k > 0 be positive
integers. For any polynomial a ∈R<k[x] of degree less than k, let Tk,d(a) denote
the matrix in R(k+d−1)×d whose ith column, for i = 1, · · · , d is given by the
coeﬃcients of xi−1 · a, listed from the lowest to the highest degree.
Lemma 2 ([17],
Lemma
7).
For
l, k, d
>
0,
a
∈
R<k[x], b
∈
R<l[x], Tk,l+d−1(a) · Tl,d(b) = Tl+k−1,d(a · b).
Lemma 3 (Noise Rerandomization [14], Lemma 1). Let q, l, m be positive
integers and r a positive real number satisfying r > max{ω(√log m), ω(√log l)}.
Let b ∈Zm
q be arbitrary and x chosen from DZm,r. Then for any V ∈Zm×l and
positive real σ > σ1(V), there exists a PPT algorithm ReRand(V, b+x, r, σ) that
outputs b′ = bV + x′ ∈Zl
q where x′ is distributed statistically close to DZl,2rσ.
For our purpose, we focus on the polynomials with poly(n)-bounded expansion
factors. One such class [17] is the family of all f = xm + h where deg(h) ≤m/2
and ∥h∥∞≤poly(n).
Deﬁnition 6 (Middle-Product [23], Deﬁnition 3.1). Let da, db, d, k be inte-
gers such that da + db −1 = d + 2k. The middle product ⊙d : R<da[x] ×
R<db[x] →R<d[x] is deﬁned to be the map: (a, b) →a ⊙b = ⌊(a·b) mod xk+d
xk
⌋=

k≤i+j≤k+d−1 (aibj)xi+j, where a = (a0, · · · ada−1) and b = (b0, · · · bdb−1) are
the coeﬃcient vectors of a and b, respectively.
Immediately from Deﬁnition 6, the middle product is commutative, i.e., a⊙d b =
b⊙d a for all polynomials a, b. Besides, the middle product also satisﬁes a “quasi-
associative” property deﬁned below in Lemma 4.
Lemma 4 ([23]). Let d, k, n > 0. For all r ∈R<k+1[x], a ∈R<n[x], s ∈
R<n+d+k−1[x], we have r ⊙d (a ⊙d+k s) = (r · a) ⊙d s.
Lemma 5 ([22], Lemma 3.2). Let d, k > 0. Let r ∈R<k+1[x] and a ∈
R<k+d[x] and b = r ⊙d a. Then b = (Tk+1,d(r))T · ¯a. In other words, we have
b = (Tk+1,d(r))T · a.
Deﬁnition 7 (Degree-Parameterized MP-LWE [16], Deﬁnition 9). Let
n > 0, q > 2, m > 0, d ∈[ n
2 ]t, and let χ be a distribution over Rq. For s ∈
Z<n−1
q
[x], we deﬁne the distribution MPq,n,d,χ(s) over Πt
i=1U(Zn−di
q
× R<di
q
[x])
as follows.

Adaptively Secure IBE from MPLWE
327
1. For each i ∈[t], sample ai
$←−Zn−di
q
[x] and sample ei ←χ<di[x]
2. Output (ai, bi := ai ⊙di s + ei) The (degree-parameterized) MP-LWE problem
consists of distinguishing between arbitrarily many samples from MPq,n,d,χ(s)
(denoted as dMPLWEq,n,d,χ(s)) and the same number of samples from
Πt
i=1U(Zn−di
q
× R<di
q
[x]) with non-negligible probability over the choice of
s
$←−Z<n−1
q
[x].
Informally speaking, dMPLWE is as hard as PLWE for a wide class of poly-
nomials. Details can be found in Theorem 2 of [16].
3
Trapdoor Generators and Related Operations
Theorem 1 ([19], Deﬁnition 5.2,Theorem 4). Let G := Ik⊗
	
1 2 . . . 2τ−1
∈
Zk×kτ
q
. Then given a matrix A ∈Zk×(m+kτ), we say that a matrix R ∈Zm×kτ
is a G-trapdoor for A if
A
	
RT |Ikτ

T = G.
(1)
And there exists an eﬃcient algorithm C(A, R, u) that operates as follows:
On input matrices A, R and a vector u, samples from DΛ⊥
u (A),σ, as long as
σ ≥ω(√log k)

7(σ1(R)2 + 1). Moreover, the running time of C is the time to
compute Rx for x ∈Zkτ plus ˜O(m + kτ).
Theorem 2 (Leftover Hash Lemma [16], Theorem 3, Lemma 11). Let
χ be a distribution over Zq and δ ∈(0, 1) be such that H∞(χ) ≥log( 1
δ ).
Deﬁne the distribution V := (−→a , h−
→
a (−→r )) over S = (Z<n
q
[x])t × Z<n+n′−1
q
[x],
where −→a = (a1, · · · , at) consists of i.i.d. samples from U(Z<n
q
[x]), and −→r =
(r1, · · · , rt) consists of i.i.d. samples from χn′[x]. Then for n′ ≤n, if δtq = o(1),
Δ(V, U(S)) = O(δ
t
2 q + δ
n′t
2 q
n+n′+1
2
). In particular, for any q = poly(n), if
δ−1 = ω(1) and n′t/n = Ω(log n), we have V ≈s U(S). Let χ := DZ,σ and
χq := χ mod q. For σ = poly(n), q = ω(σ log1/2 n), σ = ω(1), we have
H∞(χq) ≥log( σ
c ) for some constant c.
Trapdoor Generation and Preimage Sampling Algorithm. We will use
the trapdoor generation algorithm and the preimage sampling algorithm to con-
struct our sampling algorithms.
Theorem 3 (TrapGen [16], Theorem 5). Let q = poly(n) be a prime, d ∈Z,
d ≤n, dt/n = Ω(log n), σ = cℓ· ω(n log3/2 n) for some constant c, γ = ⌈log2 q⌉
and γ =
n+2d−2
d
be an integer. Then there exists a ppt algorithm TrapGen
that generates a polynomial vector −→a
= (a1, a2, · · · , at, at+1, · · · , at+γτ) ∈
(Z<n
q
[x])t × (Z<n+d−1
q
[x])γτ together with a trapdoor td that can be stored in
O(nτt) space, where −→a ≈s U((Z<n
q
[x])t × (Z<n+d−1
q
[x])γτ)

328
J. Fan et al.
Theorem 4 (SamplePre(−→a , td, u, σ) [16], Theorem 5). Let q = poly(n) be
a prime, d ≤n, dt/n = Ω(log n), σ = cℓ· ω(n log3/2 n) for some constant c,
γ = n+2d−2
d
be an integer, τ = ⌈log2 q⌉and t′ = t + γτ. Then there exists a ppt
algorithm SamplePre that on input polynomial vector −→a = (a1, a2, · · · , at, at+1,
· · · , at+γτ) with a trapdoor td and a syndrome u ∈Zn+2d−2
q
[x], outputs −→r =
(ri)t+γτ
i=1
satisfying t+γτ
i=1 ai · ri = u in ˜O(nt) time. And the output distribution
of (ri)t′
i=1 is exactly the conditional distribution (DZ2d−1,σ[x])t ×(DZd,σ[x])γτ|−→a ·
−→r = u.
After illustrating the algorithms, we would like to propose new algorithms
that would be used in our IBE scheme and security proof.
Lemma 6 (SampleLeft(−→a , td, u, σ)). Let q = poly(n) be a prime, 3d ≤n,
dt/n = Ω(log n), σ = cℓ· ω(n log3/2 n) for some constant c, γ = n+2d−2
d
be an
integer, τ = ⌈log2 q⌉and t′ = t+γτ. Then there exists a ppt algorithm SampleLeft
that on input polynomial vector −→a
= (a1, a2, · · · , at, at+1, · · · , at+γτ) with a
trapdoor td, polynomials (h1, h2, · · · , hγτ), and a syndrome u ∈Zn+2d−2
q
[x],
outputs (ri)t+2γτ
i=1
satisfying t+γτ
i=1 ai · ri + γτ
i=1 hi · ri+t+γτ = u in ˜O(nt)
time. And the output distribution of (ri) is exactly the conditional distribution
(DZ2d−1,σ[x])t × (DZd,σ[x])2γτ| t+γτ
i=1 ai · ri + γτ
i=1 hi · ri+t′ = u.
Proof. Let t′ := t + γτ and t′′ := t + 2γτ.
First, we describe SampleLeft algorithm and then prove that it outputs the right
distribution of polynomials (ri):
Chose i.i.d. samples rt′+1, rt′+2, ..., rt′′ ←(DZd,σ[x])t × (DZd,σ[x])γτ. Then
set (r1, r2, ..., rt′) ←SamplePre((a1, a2, ..., at, at+1, ..., at+γτ), td, u −γτ
i=1 hi ·
ri+t′, σ). We can see that t′
i=1 ai · ri + γτ
i=1 hi · ri+t′ = u.
Next, we are to prove that the SampleLeft algorithm outputs the right dis-
tribution of polynomials (ri).
First, according to the algorithm, for every u ∈Zn+2d−2
q
[x], we can ﬁnd
polynomials (DZ2d−1,σ[x])t × (DZd,σ[x])2γτs.t. t+γτ
i=1 ai · ri + γτ
i=1 ai · ri+t′ = u.
Let u′ = u−γτ
i=1 ai·ri+t′. According to the Leftover Hash Lemma (Theorem
2), the distribution of u′ is also U(Z<n+2d−2
q
). We have (r1, ..., rt′) generated
using SamplePre((a1, a2, ..., at, at+1, ..., at+γτ), td, u′, σ).
According to Theorem 1, we can see that the distribution of (ri)t′
i=1 is exactly
the conditional distribution (DZ2d−1,σ[x])t × (DZd,σ[x])γτ| t′
i=1 ai · ri = u′.
Since (ri)t′′
i=t′+1 are sampled i.i.d. from (DZd,σ[x])γτ, we can come to the con-
clusion that (DZ2d−1,σ[x])t × (DZd,σ[x])2γτ| t+γτ
i=1 ai · ri + γτ
i=1 hi · rt′+γτ = u.
Thus, the conditional distribution of (ri) is as claimed.
Finally, the runtime of SampleLeft is precisely the runtime of SamplePre,
which is ˜O(nt) time.
⊓⊔
Lemma 7 (SampleRight(−→b , y, −→a , −→
S , u, σ)). Let q = poly(n) be a prime,
3d ≤n, dt/n = Ω(log n), σ = cℓ· ω(n log3/2 n) for some constant c, γ = n+2d−2
d
is an integer, τ = ⌈log2 q⌉and t′ = t + γτ. Then there exists a ppt algorithm

Adaptively Secure IBE from MPLWE
329
SampleRight that on input polynomial vector −→b ∈(Z<n+d−1
q
[x])γτ, a non-zero
integer y ∈Z∗, polynomial vector −→a
= (a1, a2, · · · , at+γτ), and polynomial
matrix −→
S = (−→
s1, −→
s2, · · · , −→
st′)T where −→
sj ∈(Zd
q)t × (Zq)γτ for 1 ≤j ≤γτ and
a syndrome u ∈Zn+2d−2
q
[x], outputs polynomial vector−→r = (ri)t+2γτ
i=1
satisfying
t+γτ
i=1 ai ·ri +γτ
i=1 hi ·rt+i+γτ = u, where hi = −→
si ·−→a +−→b for i ∈[γτ] in ˜O(nt)
time. And the output distribution of (ri) is exactly the conditional distribution
(DZ2d−1,σ[x])t × (DZd,σ[x])2γτ| t+γτ
i=1 ai · ri + γτ
i=1 hi · ri+t+γτ = u′.
Proof. The proof consists of four parts. In the ﬁrst part, we give a sampling
algorithm SampleRight originated from the sampling algorithm proposed by [19].
In the second part, we prove the correctness of our SampleRight algorithm. In
the third part, we prove that the output of our algorithm follows the desired
distribution. Finally, we analyze the running time of our algorithm. Our sam-
pling algorithm is as follows. Let u′ = y−1u. Here y−1 denotes the multi-
plicative inverse of y in Zq. Set Γ(f) = [T n+d−1,d(f)| . . . |T n+d−1,d(f2τ−1)],
G =
	
Γ(1)|Γ(xd)| . . . |Γ(x(γ−1)d)

.
Let ˜A =
	
Tn,2d−1(a1)| . . . |Tn,2d−1(at)|Tn+d−1,d(at+1)| . . . |Tn+d−1,d(at+γτ)

,
˜S =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Td,d(s1,1)
. . . Td,d(s1,γτ)
...
...
...
Td,d(st,1)
. . . Td,d(st,γτ)
T1,d(st+1,t+1) . . . T1,d(st+1,γτ)
...
...
...
T1,d(st′,t+1) . . . T1,d(st′,γτ)
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
and I = Idγτ =
⎡
⎢⎣
T1,d(1) . . . T1,d(1)
...
...
...
T1,d(1) . . . T1,d(1)
⎤
⎥⎦.
We have G = Iγd ⊗[1 · · · 2τ−1] = [Tn+d−1,d(b1)| · · · |Tn+d−1,d(bγτ)]. Set A =
[˜A|˜A˜S + G] and S = [−˜ST |I]T . We can get AS = G
Here, ˜A is the Toepliz matrix corresponding to −→a , A is the Toepliz matrix
corresponding to [−→a T |−→h T ]T and −˜S is the G-trapdoor for A.
Let u′ = Tn+2d−2,1(u′) ∈Zn+2d−2
q
be the coeﬃcient vector of u′.
After that, apply the algorithm from Theorem 1 and set k = γd = n+2d−2,
we can sample e from DΛ⊥
u′(A),σ, where σ = cℓ· ω(n log3/2 n) ≥ω(

log(γd)) ·

7((γdτ((2d −1)t + dγτ)) · ℓ2 + 1) = ω(√log γd)

7(σ1( ˜S)2) + 1 for some con-
stant c.
Next, we separate e into a series of Toeplize matrices, i.e., write e as
[T2d−1,1(r1)T | · · · |T2d−1,1(rt)T |Td,1(rt+1)T | · · · |Td,1(rt+2γτ)T ]T ,
where deg(ri) =

< 2d −1
for i ∈[t]
< d
for i ∈{t + 1, · · · , t + 2γτ}.
Finally, output(r1, · · · , rt+2γτ).
In the second part of the proof, we analyze the correctness of SampleRight. By
construction, we have maxi,j| ˜Si,j| ≤ℓ. So, according to Lemma 1 and Theorem 1,
we can get σ1(˜S) ≤ℓ

γdτ((2d −1)t + dγτ) and e is sampled from DΛ⊥
u (A),σ.
Here, Theorem 1 works as k = γd = n+2d−2 ≤3n and γ = Θ(log q) = Θ(log n)
for q = poly(n).

330
J. Fan et al.
Then, as we have
A =
Tn,2d−1(a1)| . . . |Tn,2d−1(at)|Tn+d−1,d(at+1)| . . . |Tn+d−1,d(at+γτ)
. . . |Tn+d−1,d(h1)| . . . |Tn+d−1,d(hγτ)

,
by Lemma 2, we can deduce that Ae = Tn+2d−2,1(t+γτ
i=1 ai · ri + γτ
i=1 hi ·
ri+t+γτ). Therefore, e ∈Λ⊥
u′(A) iﬀt+γτ
i=1 ai · ri + γτ
i=1 hi · ri+t′ = u′.
Thirdly, we prove that r = (ri)t′+γτ
i=1
is distributed as claimed. Since AS = G
and span(G) = Zn+2d−2, we can get span(A) = Zn+2d−2. So ∀u′ ∈Zn+2d−2, ∃e∗
s.t. Ae∗= u′. Since ∀t s.t. At = u′, t + Λ⊥(A) = Λ⊥
u′(A) and DΛ⊥
u′(A),σ(x)=
ρσ(x)/ρσ(Λ⊥
u′(A)) = DΛ⊥
u′(A),σ,−t(x −t), ∀x ∈Λ⊥
u′(A), we can conclude that
DΛ⊥
u′(A),σ ≡e∗+ DΛ⊥(A),σ,−e∗.
Then, by Lemma 5.2 in [12], the distribution of e is as follows: DΛ⊥
u (A),σ ≡
e∗+ DΛ⊥(A),σ,−e∗≡D(2d−1)t+2dγτ
Z,σ
|Ae = u′. So the conditional distribution of
−→r is as claimed.
Finally, we analyze the running time of the SamplePre algorithm. The running
time of SampleRight is the time needed to calculate ˜Rx for x ∈Zγdτ
q
using
polynomial multiplication, which is O((d log d)tγτ) = ˜O(nt), as γd = O(n),
log d = O(log n) and γ = Θ(n).
⊓⊔
4
Our Middle-Product IBE
Overview of Our Construction. In our scheme, a user’s identity id =
{−1, 1}ℓcorresponds to a polynomial vector −→
hid ∈(Z<n+d−1
q
[x])γτ, which is
generated as follows: −→
hid = −→
h0 + ℓ
j=1 dj
−→
hj, where dj is the jth bit of the iden-
tity id and −→
h0, −→
h1, · · · , −→
hℓ∈(Z<n+d−1
q
[x])γτ are polynomial vectors included in
the master public key. The master public key also contains a polynomial u, and
a polynomial vector −→a ∈(Z<n
q
[x])t × (Z<n+d−1
q
[x])γτ. Here −→a along with its
trapdoor td are generated by TrapGen algorithm introduced in Theorem 3. Set
t′ = t + γτ and t′′ = t′ + γτ. The private key of a user id is a sequence of poly-
nomials (r1, r2, · · · , rt′′) satisfying t′
i=1 ai · ri + γτ
i=1 hid,i · ri+t′ = u, which can
be sampled by SampleLeft algorithm deﬁned in Lemma 6 using trapdoor td.
Let q = q(n) be prime, τ := ⌈log2q⌉, n, d, k be such that γ = n+2d−2
d
∈N
and 2d + k ≤n. Let t > 0, t′ = t + γτ, t′′ = t + γτ. Let χ := ⌊Dα·q⌉, χ1 :=
⌊Dα1·q⌉be the distributions over Z in which ϵ ←Dα·q, or ϵ1 ←Dα1·q is sampled
and then rounded to the nearest integer respectively. Let 0 < s ≤d/2 be an
integer. Let identity id = {−1, 1}ℓ, where ℓis the length of the identity id. Let
σ = cℓ·ω(n log3/2 n) for some constant c. We deﬁne an IBE scheme with message
space M = {0, 1}<k+1[x].
Key Generation KeyGen(1n) :
1. Use TrapGen to generate random polynomials (a1, . . . ,at, at+1, . . . ,at′) ←
(Z<n
q
[x])t × (Z<n+d−1
q
[x])γτ with trapdoor td, and denote it as −→a .

Adaptively Secure IBE from MPLWE
331
2. Sample −→
h0, −→
h1, . . . , −→
hℓ
$←−(Z<n+d−1
q
)γτ
3. Sample u
$←−Zn+2d−2
q
.
4. Output mpk = {−→a , −→
h0, −→
h1, . . . , −→
hℓ, u}, msk = td.
Extraction Extract(mpk, msk, id) :
1. Let −→
hid = −→
h0 + ℓ
j=1 dj
−→
hj, where dj is the jth bit of the identity id.
2. Use SampleLeft(−→a , −→
hid, td, u, σ) to generate (r1, . . ., rt′′) s.t. t′
i=0 ai ri+γτ
i=1
hid,i ri+t′ = u.
3. Output skid = (r1, · · · , rt′′)
Encryption Enc(mpk, id, m) :
1. Let −→
hid = −→
h0 + ℓ
j=1 dj
−→
hj, where dj is the jth bit of the identity id.
2. Sample p
$←−Z<n+2d+k−1
q
[x].
3. For 1 ≤i ≤t, sample ei ←χ2d+k[x], and compute ci = ai ⊙2d+k p + 2ei.
4. For t+1 ≤i ≤t′, sample ei ←χd+k+1[x], and compute ci = ai⊙d+k+1p+2ei.
5. For 1 ≤i ≤γτ, sample ei+t′ ←χd+k+1
1
[x], and compute ci+t′ = hid,i ⊙d+k+1
p + 2ei+t′.
6. Sample e0 ←χk+1, and compute c0 = m + u ⊙k+1 p + 2e0.
7. Output c = (c0, c1, · · · , ct′′).
Decryption Dec(skid, c) : Output (c0 −t′′
i=1 ci ⊙k+1 ri mod q) mod 2
Lemma 8. For α1 = (n2ℓ· ω(log
7
2 n) + 1)−1, and α = (n3ℓ2 · ω(log4 n) + 1)−1,
the scheme satisﬁes (1 −negl(n))-correctness.
Proof. We want to show that Dec(skid, Enc(mpk, id, μ)) = μ with probability
1−negl(n) over the randomness of KeyGen and Enc. Consider a random key pair
(mpk, msk), a random identity id = {−1, 1}l, let skid ←Extract(mpk, msk, id) and
compute ciphertext c = (c0, (ci)1≤i≤t′′) ←Enc(mpk, id, m).
By Lemma 4 (the quasi-associative law for middle products), we have c0 =
m+(t′
i=0 airi +γτ
i=1 hid,iri+t′)⊙k+1 p+2e′ = m+t
i=1 ri ⊙k+1 (ai ⊙2d+k p)+
t′
i=t+1 ri ⊙k+1 (ai ⊙d+k+1 p)+γτ
i=1 ri+t′ ⊙k+1 (hid,i ⊙d+k+1 p)+2e′, which leads
to the following equation c0 −t′′
i=1 ci ⊙k+1 ri = m + 2(e0 −t′′
i=1 ri ⊙k+1 ei). So
if ∥m + 2(e0 −t′′
i=1 ri ⊙k+1 ei)∥∞< q/2, Dec(skid, c) will output the message m
correctly.
Hence, to fulﬁll the proof of correctness, we are to bound the coeﬃcients of
t′′
i=1 ri ⊙k+1 ei.
The coeﬃcient of xl in ri ⊙k+1 ei is 
ω∈[0,deg(ri)]∩[l+k−deg(ei),z+k](yi)ω
(ei)l+k−ω. Applying the Gaussian tail inequality and a union bound, since
α1 > α, we can get the following bounds on ∥yi∥∞and ∥ei∥∞: Pr[∥yi∥∞>
ω((√log n)σ)] = negl(n). Pr[∥ei∥∞> ω((√log n)α1q)] = negl(n).

332
J. Fan et al.
Therefore, again by union bound, except with negl(n) probability ∥e0 −
t′′
i=1 ri ⊙k+1 ei∥∞< Kω((√log n)σ)ω((√log n)α1q) + ω((√log n)α1q) for K :=
(2d −1)t + 2γτd ≥t′′
i=1(deg(ri) + 1).
Setting α1 < (4σK · ω(log n) + 1)−1 = (n2ℓ· ω(log
7
2 n) + 1)−1, the above
is less than q/4 and thus the scheme is (1 −negl(n))-correct. In this case, α =
(n3l2 · ω(log4 n) + 1)−1.
⊓⊔
4.1
Security Proof
In this section, we will prove the security of our IBE scheme. We adapt the
partitioning technique, following the previous works [1,4,26,28,29].
Overview of Our Proof. In the proof, we will ﬁrst change the way of gen-
erating master public keys. Instead of using TrapGen algorithm to generate −→a ,
we sample −→a = (a1, · · · , at, at+1, · · · , at′)
$←−(Z<n
q
[x])t × (Z<n+d−1
q
[x])γτ. We
also sample polynomial matrices −→
S0, −→
S1, · · · , −→
Sℓwhere −→
Si = [−→
si,1, −→
si,2, · · · , −−→
si,t′]T
and −→
si,j ←(Ψ d[x])t × Ψ γτ for Ψ := U({−1, 0, 1}), j = 1, · · · , t′, along with
y = (y1, · · · , yℓ) ∈Zℓ
q and y0 = 1. After that, we will set the remaining part of
master public key as (−→
hi)ℓ
i=0 where −→
hi = −→
Si · −→a + yi
−→b . In this way −→
hid can be
written as (−→
S0 + ℓ
i=0 di
−→
Si) · −→a + (1 + ℓ
i=1 diyi)−→b . Then an abort-resistant
hash function can be deﬁned as follows: Fy(id) = y0 + ℓ
i=1 diyi. We also deﬁne
−→
Sid = −→
S0 + ℓ
i=0 di
−→
Si. For identity queries {id1, · · · , idQ} and challenge iden-
tity id∗, we further deﬁne Υ(id∗, id1, · · · , idQ) as the probability that all key
extraction queries have Fy(idi) ̸= 0 and challenge identity has Fy(id∗) = 0.
With artiﬁcial abort, we are able to argue that we have Υ(id∗, id1, · · · , idQ) non-
negligible for all possible identity queries. In our setting −→b is generated with a
trapdoor. Then we transform the polynomial vectors −→a , −→b and −→
Sid to matrices
A, B and S respectively. In the key extraction queries, we are to ﬁnd e, the
vector representation of user secret key s.t. [A|SA + Fy(id)B]e = u for the pre-
determined u in master public key. As [A|SA + Fy(id)B]
	
−ST |I

T = Fy(id)B,
when Fy(id) ̸= 0, we can sample e using the trapdoor in B by the SampleRight
algorithm. This allows us to answer the key extraction queries. For the challenge
identity id∗, we have Fy(id∗) = 0 and −→
hid = −→
Sid ·−→a . We will use MPLWE samples
as ciphertext (ci)t′
i=1 and c0−mb where mb is the challenge message. We will then
generate the remaining ciphertext (ci)t′′
i=t′+1 from (ci)t′
i=1 using the rerandom-
ization algorithm ReRand from [14]. The rest of the analysis is straightforward:
the ciphertext contains no information about b under the MPLWE assumption.
Our IBE is IND-CPA secure with the parameter setting given below.
Parameter Settings. The parameters used in our IBE are listed below.
d = Θ(n)
t = Ω(log n)
q = n4+cℓ2 · ω(log4 n)
σ = ℓ· ω(n log
3
2 n) α = (n3ℓ2 · ω(log4 n) + 1)−1 α1 = (n2ℓ· ω(log
7
2 n) + 1)−1

Adaptively Secure IBE from MPLWE
333
Deﬁnition 8 (Abort-resistant Hash Function [1]). Let H := {H : X →Y }
be a family of hash functions from X to Y where 0 ∈Y . For a set of Q + 1 in
puts ¯x = (x0, x1, · · · , xQ) ∈XQ+1, deﬁne the non-abort probability of ¯x as the
quantity α(¯x) := Pr[H(x0) = 0 ∧H(x1) ̸= 0 ∧· · · ∧H(xQ) ̸= 0] where the
probability is over the random choice of H ∈H.
We
say
that
F
is
(Q, αmin, αmax)
abort-resistant
if
for
all
¯x
=
(x0, x1, · · · , xQ) ∈XQ+1 with x0 /∈{x1, · · · , xQ}, we have α(¯x) ∈[αmin, αmax].
We will use the following abort-resistant hash function used in [1,4,13,26].
And this is the main component that enables us to go from the selectively secure
IBE in [16] to an adaptively secure one.
For a prime q, let (Zℓ
q)∗:= Zℓ
q \ {0ℓ} and deﬁne the family FWat : {Fy :
(Zl
q)∗→Zq}y∈Zℓ
q as Fy(id) := 1 + ℓ
i=1 yibi ∈Zq where id = (b1, · · · bℓ) ∈
(Zℓ
q)∗and y = (y1, · · · , yℓ) ∈Zℓ
q
In our IBE scheme, the inputs to these hash functions are in {−1, 1}ℓ. Since
{−1, 1}ℓ∈(Zℓ
q)∗:= Zℓ
q \ {0ℓ}, we will use the more general result in [1].
Lemma 9 ([1]). Let q be a prime and 0 < Q < q. Then the hash family FWat
deﬁned above is (Q, 1
q(1 −Q
q ), 1
q) abort-resistant.
Theorem 5. Assume that σ = cℓ· ω(n log3/2 n) for some constant c, dt/n =
Ω(log n), q = poly(n) is a prime number, q = Ω(α−1n1+c) and q = σ ·
ω(log1/2 n), α1 < (4σK · ω(log n) + 1)−1, and α = α1/(2
√
t′(2d + k)l) where
K := (2d −1)t + 2γτd, the IBE system is IND-CPA adaptively secure assuming
dMPLWEq,n+2d+k,d,Dα·q is hard with degree vector d = (di)t′+1
i=1 where
di =
⎧
⎪
⎨
⎪
⎩
2d + k, for 1 ≤i ≤t
d + k + 1, for t + 1 ≤i ≤t′
k + 1, for i = t′′ + 1
Proof. The proof proceeds in a sequence of games, among which the ﬁrst game
is identical to the IND-CPA adaptive game from Sect. 2.2. In the last game in
the sequence, the adversary has an advantage of zero. In Game 1, we use an
artiﬁcial abort to check if identities (id∗, id1, · · · , idQ) selected by the challenger
C satisfy our requirement where id∗is the challenge identity and (id1, · · · idQ)
are for key extraction queries. Then we change the generation of mpk such that
for id1, · · · , idQ, we are able to extract the secret key using embedded trapdoor,
while for challenge id∗there is no such trapdoor available for key extraction.
Then the dMPLWE problem is used in proving that Game 6 and Game 7 are
indistinguishable.
In each game, two values coin′, 
coin ∈{0, 1} are deﬁned. While we set coin′ = 
coin
in the ﬁrst game, these values might be diﬀerent in the later guess when artiﬁcial
abort occurs. Finally, we will deﬁne Xi be the event that coin′ = coin.
Game 0. This is the original adaptive IND-CPA security game from Sect. 2.2,
between an PPT attacker A and a challenger C.

334
J. Fan et al.
Recall that the ciphertext space is c
=
(c0, (ci)i≤t′′)
=
Zk+1
q
[x] ×
((Z2d+k
q
[x])t×(Zd+k+1
q
[x])2γτ). In the challenge phase, the challenge ciphertext is
generated using our IBE scheme by encrypting message mcoin. At the end of the
game, A outputs a guess 
coin for coin. Finally, C sets coin′ = 
coin. By deﬁnition,
we have |Pr[X0] −1
2| = |Pr[coin′ = coin] −1
2| = ϵ.
Game 1. Game 1 is identical to Game 0 except that we add an abort event at
the beginning of the game.
The challenger C picks y = (y1, · · · , yℓ) ∈Zℓ
q. We deﬁne a function Fy :
ID →Zq as follows: Fy(id) = y0 + ℓ
i=1 diyi, where di is the ith bit of identity
id and ID ∈(Zℓ
q)∗. Then C checks whether the following condition holds:
Fy(id∗) = 0 ∧Fy(id1) ̸= 0 ∧Fy(id2) ̸= 0 ∧· · · ∧Fy(idQ) ̸= 0
(2)
where id∗is the challenge identity and id1, · · · idQ are the identities for which A
has made key extraction queries. And set Υ(id∗, id1, · · · , idQ) = Pry[Fy(id∗) =
0∧Fy(id1) ̸= 0∧Fy(id2) ̸= 0∧· · ·∧Fy(idQ) ̸= 0]. Here Fy(id) is an abort-resistant
hash function.
Now C does as follows:
(I) Abort check: If (2) does not hold, C ignores the output 
coin of A, and set
coin′
$←−{0, 1}. In this case, we say that the challenger aborts. If condition
(2) holds, the challenger C sets coin′ = 
coin.
(II) Artiﬁcial abort: The artiﬁcial abort does in the same way as in [1]. With
probability Υ(id∗, id1, · · · , idQ), C ignores the output 
coin of A, and sets
coin′
$←−{0, 1}, otherwise, C sets coin′ = 
coin. Note that the abort condi-
tion is determined using the hash function Fy(·) that is independent of the
attacker’s view. For a (Q + 1)-tuple of identities I = (id∗, id1, id2, · · · , idQ),
denotes the probability that an abort (either real or artiﬁcial abort) does
not happen when A makes these queries by Υ(I). Let Υmax and Υmin be
such that Υ(I) ∈[Υmin, Υmax] for all (Q + 1) tuples of identities I.
Lemma 10. ([1], Lemma 28). For i = 0, 1, let Xi be the event that coin′ = coin
at the end of Game i. With the artiﬁcial abort, |Pr[X1] −1
2| ≥Υmin|Pr[X0] −
1
2| −1
2(Υmax −Υmin) and (Υmax −Υmin) ≤αmin|Pr[X0] −1/2|
So we can get |Pr[X1] −1
2| ≥1
2 · αmin|Pr[X0] −1
2| ≥
1
4q|Pr[X0] −1
2|.
Game 2. In Game 2, we slightly change the way that C generates the polyno-
mial vectors −→
h0, −→
h1, · · · , −→
hℓ. Instead of selecting them uniformly at random from
(Z<n+d−1
q
[x])γτ, C ﬁrst generates a polynomial vector −→b = (b1, b2, · · · , bγτ) ∈
(Z<n+d−1
q
[x])γτ s.t. bj = 2uxdv, for j = vτ + u + 1, where u ∈{0, · · · , τ −1}, v ∈
{0, · · · , γ −1}.
Let Ψ := U({−1, 0, 1}). After that the challenger picks y = (y1, · · · , yℓ) ∈Zℓ
q
as in Game 1 and y0 = 1. Then we generate polynomial matrices −→
S0, −→
S1, · · · , −→
Sℓ

Adaptively Secure IBE from MPLWE
335
where −→
Si = [−→
si,1, −→
si,2, · · · , −−→
si,t′]T and −→
si,j ←(Ψ d[x])t × Ψ γτ for j = 1, · · · , γτ.
Next, set −→
ζi = −→
Si · −→a and −→
hi = −→
Si · −→a + yi
−→b = −→
ζi + yi
−→b .
Then we will show that Game 2 is computationally indistinguishable from
Game 1, i.e. |Pr[X2] −Pr[X1]| = negl(n).
We are to show that under this construction, −→
hi ≈c U((Z<n+d−1
q
[x])γτ) for
i = 0, 1, · · · , ℓ. WLOG, we will take the polynomial vector −→
ζi as an example.
Let −→
ζi = (ζ1, ζ2, · · · , ζγτ), where (ζ1, · · · , ζγτ) ∈Zn+d−1
q
[x].
For j = 1, · · · , γτ, ζj = −→
si,j·−→a . Let −→
si,j = [s1, s2, · · · , sγτ]T . So ζj = −→
si,j·−→a =
t′
k=1 sk · ak = t
k=1 sk · ak + t′
k=t+1 sk · ak
By leftover hash lemma (Lemma 2) and our parameter setting (dt/n =
Ω(n log n)), we can get that t
k=1 sk · ak ≈s U(Zq[x]n+d−1). So (ζ1, · · · , ζγτ) ≈c
U((Zn+d−1
q
)γτ). Hence, we can get that −→
ζi
≈c U((Z<n+d−1
q
[x])γτ) for i =
0, 1, · · · , ℓ. Thus, we can get −→
hi ≈c U((Z<n+d−1
q
[x])γτ) for i = 0, 1, · · · , ℓ. There-
fore, we have |Pr[X2] −Pr[X1]| = negl(n).
Game 3. Previously, C aborts the game at the end of the game if the condition
(2) does not hold. In this game, we change the game so that the challenger aborts
as soon as the abort condition is satisﬁed. Since this is only a conceptual change,
we have Pr[X3] = Pr[X2]
Game 4. In this game, we change the way the polynomial vector −→a is chosen.
Namely, in Game 4, instead of generating −→a with trapdoor td using TrapGen,
we select −→a
$←−(Z<n
q
[x])t × (Z<n+d−1
q
[x])γτ. By Theorem 1, this only diﬀers
negligibly with game 3.
We set −→
Sid
:=
−→
S0 + ℓ
i=1 di
−→
Si. So it holds that −→
hid
=
−→
Sid · −→a +
Fy(id)−→b . Then we change the way that key extraction queries are answered.
If
Fy(id)
=
0,
it
aborts
as
the
previous
game.
Otherwise,
it
runs
SampleRight(−→b , td, Fy(id), −→a , −→
Sid, u, σ) →−→r and returns −→r to A.
In Game 3, the key −→r is sampled using SampleLeft(−→a , −→
hid, td, u, σ) →−→r . By
lemma 6, Lemma 7 and the choice of σ, the diﬀerence in the output distributions
of SampleRight and SampleLeft are negl(n)-close. So the above change only diﬀers
negligibly in the view of A. Therefore, we have |Pr[X4] −Pr[X3]| = negl(n).
Game 5. Game 5 is identical to Game 4 except for the way to generate the
challenge ciphertext.
If Fy(id∗) = 0 (i.e. if it does not abort), to create the challenge ciphertext,
we ﬁrst choose p
$←−Z<n+2d+k−1
q
[x], χ ←⌊Dα·q⌉, χ1 ←⌊Dα1·q⌉, and noise
e0, e1, e2, · · · , et′′, where ei ←χk+1 for i = 0, ei ←χ2d+k[x] for 1 ≤i ≤t,
ei ←χd+k+1[x] for t + 1 ≤i ≤t′, ei ←χd+k+1
1
[x] for t′ + 1 ≤i ≤t′′.
Next, for 1 ≤i ≤t set ci = ai ⊙2d+k p + 2ei. For t + 1 ≤i ≤t′ set
ci = ai ⊙d+k+1 p + 2ei. For t = 0, set c0 = m+u ⊙k+1 p + 2ei. For t′ + 1 ≤i ≤t′′,
WLOG, we will take cι, where t′ + 1 ≤ι ≤t′′, as an example.
Since cι = hid,ι ⊙d+k+1 p + 2eι, and hid = −→
Sid · −→a as Fy(id∗) = 0, we have
cι = hid,ι⊙d+k+1p+2eι = (t′
i=1 si·ai)⊙d+k+1p+2eι = t
i=1(si·ai)⊙d+k+1p+

336
J. Fan et al.
t′
i=t+1(si·ai)⊙d+k+1p+2eι = t
i=1 si⊙d+k+1(ai⊙2d+kp)+t′
i=t+1 si(ai⊙d+k+1
p) + 2eι, where (s1, s2, · · · , st′) are the entries on the ι-th row of the polynomial
matrix −→
Sid. The fourth equality holds by Lemma 4, and si ∈Zq for t+1 ≤i ≤t′.
Next, we set φi = ai⊙2d+kp, for 1 ≤i ≤t, φi = ai⊙d+k+1p, for t+1 ≤i ≤t′,
and use φi to represent its coeﬃcient vector. Use eι to represent the coeﬃcient
vector of eι. Then we set cι = t
i=1(Td,d+k+1(si))T φi + t′
i=t+1 siφi + 2eι. By
Lemma 5, we can see that cι = ¯cι is the coeﬃcient vector of cι. We can see that
Game 4 and Game 5 are identical. So we have Pr[X5] = Pr[X4].
Game 6. Game 6 is identical to Game 5 except for the way to generate the
challenge ciphertext.
If Fy(id∗) = 0 (i.e. if it does not abort), to create the challenge ciphertext,
we ﬁrst choose p
$←−Z<n+2d+k−1
q
[x], χ ←⌊Dα·q⌉, χ1 ←⌊Dα1·q⌉, and noise
e0, e1, e2, · · · , et′′, where ei ←χk+1 for i = 0, ei ←χ2d+k[x] for 1 ≤i ≤t,
ei ←χd+k+1[x] for t + 1 ≤i ≤t′.
Next, for 1 ≤i ≤t set ci = ai ⊙2d+k p + 2ei. For t + 1 ≤i ≤t′ set
ci = ai⊙d+k+1p+2ei. For t = 0, set c0 = mcoin+u⊙k+1p+2ei. For t′+1 ≤i ≤t′′,
WLOG, we will take cι, where t′ + 1 ≤ι ≤t′′, as an example.
First, since ci = ai ⊙2d+k p + 2ei for 1 ≤i ≤t and ci = ai ⊙d+k+1 p + 2ei,
for t + 1 ≤i ≤t′. Use ci to represent the coeﬃcient vectors.
Then, we set cι= t
i=1 ReRand((Td,d+k+1(si))T , ci, αq,
α1
2
√
t′α) + t′
i=t+1
ReRand(siId+k+1, ci, αq,
α1
2
√
t′α). Set cι to be the polynomial whose coeﬃcient
vector is cι =
¯cι. Since α1 = 2
√
t′(2d + k)ℓα,
α1
2
√
t′α > ℓ

(2d + k)d =
σ1(Td,d+k+1(si)) (the inequality holds by Lemma 1), from Lemma 3, we can
see that cι in this game is distributed statistically close to cι in Game 5. So we
have |Pr[X6] −Pr[X5]| = negl(n).
Game 7. Game 7 is identical to Game 6 except that we change the way the
ciphertexts are generated. If Fy(id∗) = 0 (i.e. if it does not abort), to create the
challenge ciphertext, we set c1, c2, · · · , ct
$←−Z2d+k
q
, and ct+1, · · · , ct′
$←−Zd+k+1
q
and t
$←−Zk+1
q
, c0 = t + mcoin. Then we generate the rest of the ciphertexts as in
Game 6. We can see that |Pr[X7] −1
2| = negl(n) as it contains no information
about the coin. Now it remains to show that |Pr[X7] −Pr[X6]| = negl(n).
As we will show in Lemma 11, assuming dMPLWEq,n+2d+k,d,Dα·q is hard
with degree vector d = (di)t′+1
i=1 where
di =
⎧
⎪
⎨
⎪
⎩
2d + k, for 1 ≤i ≤t
d + k + 1, for t + 1 ≤i ≤t′
k + 1, for i = t′′ + 1
,
i.e. |Pr[X7] −Pr[X6]| = negl(n).

Adaptively Secure IBE from MPLWE
337
Analysis. From the above, we can get
|Pr[X7] −1
2| = |Pr[X0] +
6

i=0
(Pr[Xi+1] −Pr[Xi]) −1
2|
≥|Pr[X0] −1
2| −
6

i=0
|Pr[Xi+1] −Pr[Xi]| ≥|Pr[X0] −1
2| −negl(n)
Since |Pr[X7] −1
2| = negl(n), we have |Pr[X0] −1
2| = negl(n).
Lemma 11. For any PPT adversary A, there exists another PPT adversary B
such that |Pr[X7]−Pr[X6]| ≤Adv
dMPLWEq,n+2d+k,d,Dα·q
B
. In particular, under the
dMPLWEq,n+2d+k,d,Dα·q assumption, we have |Pr[X7] −Pr[X6]| = negl(n).
Proof. Suppose A has a non-negligible advantage in distinguishing Game 6 and
7. We use A to construct an MPLWE algorithm, denoted B. Recall from Deﬁ-
nition 7 that a dMPLWE problem instance is provided as a sampling oracle O
that can be either truly random O$ or noisy pseudo-random Os for some secret
Z<n+2d+k−1
q
[x]. The simulator B uses the adversary A to distinguish between
the two, and proceeds as follows:
Instance. B requests from O and receives fresh pairs (a∗
1, w1), · · · , (a∗
t′, wt′), (u∗,
v∗), where a∗
i ∈Z<n
q
, wi ∈Z<2d+k
q
for 1 ≤i ≤t, a∗
i ∈Z<d+k+1
q
, w∗
i ∈Z<d+k+1
q
for t + 1 ≤i ≤t′, and u∗∈Zn+2d−2
q
, v∗∈Z<k+1
q
.
Setup. Construct master public key mpk as follows:
– Set ai = a∗
i for i = 1, · · · , t′.
– B picks y as in Game 1.
– Generate polynomial vectors −→
h0, · · · , −→
hℓby picking polynomial matrices −→
S0,
−→
S1, · · · , −→
Sℓand generating polynomial vector −→b as in Game 4.
– Set u = u∗.
B returns mpk to A. B picks random bit coin ←{0, 1} and keeps it secret.
Queries. When A makes a key extraction for id, B ﬁrst calculates Fy(id). It
aborts and sets coin′
$←−{0, 1} if Fy(id) = 0. Otherwise, B generates the private
key as in Game 6.
Challenge. When A makes an encryption query for the challenge identity id∗, B
ﬁrst computes Fy(id). It aborts and sets coin′
$←−{0, 1} if Fy(id) ̸= 0. Otherwise,
it proceeds as follows:
First, it computes −→
S id∗= [−→
s1, −→
s2, · · · , −→
st′]T where −→
sj ←(χd[x])t × 0γτ for
j = 1, · · · , t, −→
sj ←(χd[x])t × χγτ for j = t + 1, · · · , t′. And we can write −→
sj as
(sj,1, · · · , sj,t′).
For 1 ≤i ≤t′, set ci = wi and use ci to represent the coeﬃcient vectors. Set
c0 = v∗+mcoin. For t′+1 ≤i ≤t′′, WLOG, we will take cι, where t′+1 ≤ι ≤t′′,
as an example.

338
J. Fan et al.
Then, we set cι = t
i=1 ReRand((Td,d+k+1(sι,i))T , ci, αq,
α1
2
√
t′α) + t′
i=t+1
ReRand(sι,iId+k+1, ci, αq,
α1
2
√
t′α). And set cι to be the polynomial whose coeﬃ-
cient vector is cι. Finally, it returns (c0, (ci)t′′
i=1) to A.
Guess. At last, A outputs its guess 
coin if the abort condition has not been
satisﬁed. Then B sets coin′ = 
coin. Finally, B outputs 1 if coin = coin′ and 0
otherwise.
Analysis. We can see that B perfectly simulates the view of A in Game 6 if O =
Os and Game 7 if O = O$. Note that both games only diﬀer in the generation
of the challenge ciphertext. Furthermore, we can see that the generation of mpk,
the queries, and the challenge phase are the same in both cases. So if B is able
to distinguish between Game 6 and Game 7 with non-negligible probability, i.e.
|Pr[X6]−Pr[X7]| > negl(n), B can solve dMPLWEq,n+2d+k,d problem with non-
negligible probability. And this contradicts to Theorem 5. Therefore, |Pr[X6] −
Pr[X7]| = Adv
dMPLWEq,n+2d+k,d,Dα·q
B
= negl(n) as desired.
⊓⊔
Remark 1. We use ﬁxed constant ℓto denote the length of the identity. Picking
d, k = Θ(n), t = log(n), and α, α1, σ, q following the parameter settings. By
construction, the IBE scheme we proposed has master public key mpk of size
O(n log(n)), secret key for the identity skid and ciphertext c of size n log(n).
5
Conclusion
In this paper, we presented the ﬁrst adaptively secure IBE scheme based on
MPLWE, ﬁlling a gap in the literature as only selectively-secure IBEs from
MPLWE has been proposed previously. Our scheme inherent the typical advan-
tages of MPLWE, namely, it has comparable eﬃciency to its PLWE counterparts
while oﬀering stronger security guarantees. However, the master public key of our
scheme is larger than the state-of-the-art PLWE-based constructions. As such,
one direction for future research is to develop adaptively secure IBE schemes
with compact master keys based on MPLWE.
References
1. Agrawal, S., Boneh, D., Boyen, X.: Eﬃcient lattice (H)IBE in the standard model.
In: Gilbert, H. (ed.) EUROCRYPT 2010. LNCS, vol. 6110, pp. 553–572. Springer,
Heidelberg (2010). https://doi.org/10.1007/978-3-642-13190-5_28
2. Ajtai, M.: Generating hard instances of lattice problems (extended abstract). In:
Miller, G.L. (ed.), Proceedings of the Twenty-Eighth Annual ACM Symposium on
the Theory of Computing, Philadelphia, Pennsylvania, USA, 22–24 May 1996, pp.
99–108. ACM (1996)
3. Bai, S., et al.: MPSign: a signature from small-secret middle-product learning with
errors. In: Kiayias, A., Kohlweiss, M., Wallden, P., Zikas, V. (eds.) PKC 2020, Part
II. LNCS, vol. 12111, pp. 66–93. Springer, Cham (2020). https://doi.org/10.1007/
978-3-030-45388-6_3

Adaptively Secure IBE from MPLWE
339
4. Bellare, M., Ristenpart, T.: Simulation without the artiﬁcial abort: simpliﬁed proof
and improved concrete security for waters’ IBE scheme. In: Joux, A. (ed.) EURO-
CRYPT 2009. LNCS, vol. 5479, pp. 407–424. Springer, Heidelberg (2009). https://
doi.org/10.1007/978-3-642-01001-9_24
5. Boneh, D., Boyen, X.: Eﬃcient selective-ID secure identity-based encryption with-
out random oracles. In: Cachin, C., Camenisch, J.L. (eds.) EUROCRYPT 2004.
LNCS, vol. 3027, pp. 223–238. Springer, Heidelberg (2004). https://doi.org/10.
1007/978-3-540-24676-3_14
6. Boneh, D., Boyen, X.: Secure identity based encryption without random oracles.
In: Franklin, M. (ed.) CRYPTO 2004. LNCS, vol. 3152, pp. 443–459. Springer,
Heidelberg (2004). https://doi.org/10.1007/978-3-540-28628-8_27
7. Boneh, D., Franklin, M.: Identity-based encryption from the Weil pairing. In: Kil-
ian, J. (ed.) CRYPTO 2001. LNCS, vol. 2139, pp. 213–229. Springer, Heidelberg
(2001). https://doi.org/10.1007/3-540-44647-8_13
8. Canetti, R., Halevi, S., Katz, J.: A forward-secure public-key encryption scheme.
In: Biham, E. (ed.) EUROCRYPT 2003. LNCS, vol. 2656, pp. 255–271. Springer,
Heidelberg (2003). https://doi.org/10.1007/3-540-39200-9_16
9. Cash, D., Hofheinz, D., Kiltz, E., Peikert, C.: Bonsai trees, or how to delegate a
lattice basis. In: Gilbert, H. (ed.) EUROCRYPT 2010. LNCS, vol. 6110, pp. 523–
552. Springer, Heidelberg (2010). https://doi.org/10.1007/978-3-642-13190-5_27
10. Cocks, C.: An identity based encryption scheme based on quadratic residues. In:
Honary, B. (ed.) Cryptography and Coding 2001. LNCS, vol. 2260, pp. 360–363.
Springer, Heidelberg (2001). https://doi.org/10.1007/3-540-45325-3_32
11. Das, D., Au, M.H., Zhang, Z.: Ring signatures based on middle-product learn-
ing with errors problems. In: Buchmann, J., Nitaj, A., Rachidi, T. (eds.)
AFRICACRYPT 2019. LNCS, vol. 11627, pp. 139–156. Springer, Cham (2019).
https://doi.org/10.1007/978-3-030-23696-0_8
12. Gentry, C., Peikert, C., Vaikuntanathan, V.: Trapdoors for hard lattices and new
cryptographic constructions. In: Dwork, C. (ed.), Proceedings of the 40th Annual
ACM Symposium on Theory of Computing, Victoria, British Columbia, Canada,
17–20 May 2008, pp. 197–206. ACM (2008)
13. Hofheinz, D., Kiltz, E.: Programmable hash functions and their applications. In:
Wagner, D. (ed.) CRYPTO 2008. LNCS, vol. 5157, pp. 21–38. Springer, Heidelberg
(2008). https://doi.org/10.1007/978-3-540-85174-5_2
14. Katsumata, S., Yamada, S.: Partitioning via non-linear polynomial functions: more
compact IBEs from ideal lattices and bilinear maps. In: Cheon, J.H., Takagi, T.
(eds.) ASIACRYPT 2016, Part II. LNCS, vol. 10032, pp. 682–712. Springer, Hei-
delberg (2016). https://doi.org/10.1007/978-3-662-53890-6_23
15. Le, H.Q., Duong, D.H., Susilo, W., Pieprzyk, J.: Trapdoor delegation and HIBE
from middle-product LWE in standard model. In: Conti, M., Zhou, J., Casalic-
chio, E., Spognardi, A. (eds.) ACNS 2020, Part I. LNCS, vol. 12146, pp. 130–149.
Springer, Cham (2020). https://doi.org/10.1007/978-3-030-57808-4_7
16. Lombardi, A., Vaikuntanathan, V., Vuong, T.D.: Lattice trapdoors and IBE from
middle-product LWE. In: Hofheinz, D., Rosen, A. (eds.) TCC 2019, Part I. LNCS,
vol. 11891, pp. 24–54. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-
36030-6_2
17. Lyubashevsky, V.: Digital signatures based on the hardness of ideal lattice problems
in all rings. In: Cheon, J.H., Takagi, T. (eds.) ASIACRYPT 2016, Part II. LNCS,
vol. 10032, pp. 196–214. Springer, Heidelberg (2016). https://doi.org/10.1007/978-
3-662-53890-6_7

340
J. Fan et al.
18. Lyubashevsky, V., Peikert, C., Regev, O.: On ideal lattices and learning with errors
over rings. In: Gilbert, H. (ed.) EUROCRYPT 2010. LNCS, vol. 6110, pp. 1–23.
Springer, Heidelberg (2010). https://doi.org/10.1007/978-3-642-13190-5_1
19. Micciancio, D., Peikert, C.: Trapdoors for lattices: simpler, tighter, faster, smaller.
In: Pointcheval, D., Johansson, T. (eds.) EUROCRYPT 2012. LNCS, vol. 7237, pp.
700–718. Springer, Heidelberg (2012). https://doi.org/10.1007/978-3-642-29011-
4_41
20. Micciancio, D., Regev, O.: Worst-case to average-case reductions based on gaussian
measures. In: 45th Symposium on Foundations of Computer Science (FOCS 2004),
17–19 October 2004, Rome, Italy, Proceedings, pp. 372–381. IEEE Computer Soci-
ety (2004)
21. Regev, O.: On lattices, learning with errors, random linear codes, and cryptogra-
phy. J. ACM 56(6), 34:1–34:40 (2009)
22. Roşca, M., Sakzad, A., Stehlé, D., Steinfeld, R.: Middle-product learning with
errors. In: Katz, J., Shacham, H. (eds.) CRYPTO 2017, Part III. LNCS, vol.
10403, pp. 283–297. Springer, Cham (2017). https://doi.org/10.1007/978-3-319-
63697-9_10
23. Rosca, M., Stehlé, D., Wallet, A.: On the ring-LWE and polynomial-LWE problems.
In: Nielsen, J.B., Rijmen, V. (eds.) EUROCRYPT 2018. LNCS, vol. 10820, pp.
146–173. Springer, Cham (2018). https://doi.org/10.1007/978-3-319-78381-9_6
24. Shamir, A.: Identity-based cryptosystems and signature schemes. In: Blakley, G.R.,
Chaum, D. (eds.) CRYPTO 1984. LNCS, vol. 196, pp. 47–53. Springer, Heidelberg
(1985). https://doi.org/10.1007/3-540-39568-7_5
25. Stehlé, D., Steinfeld, R., Tanaka, K., Xagawa, K.: Eﬃcient public key encryp-
tion based on ideal lattices. In: Matsui, M. (ed.) ASIACRYPT 2009. LNCS, vol.
5912, pp. 617–635. Springer, Heidelberg (2009). https://doi.org/10.1007/978-3-
642-10366-7_36
26. Waters, B.: Eﬃcient identity-based encryption without random oracles. In: Cramer,
R. (ed.) EUROCRYPT 2005. LNCS, vol. 3494, pp. 114–127. Springer, Heidelberg
(2005). https://doi.org/10.1007/11426639_7
27. Waters, B.: Dual system encryption: realizing fully secure IBE and HIBE under
simple assumptions. In: Halevi, S. (ed.) CRYPTO 2009. LNCS, vol. 5677, pp. 619–
636. Springer, Heidelberg (2009). https://doi.org/10.1007/978-3-642-03356-8_36
28. Yamada, S.: Adaptively secure identity-based encryption from lattices with asymp-
totically shorter public parameters. In: Fischlin, M., Coron, J.-S. (eds.) EURO-
CRYPT 2016. LNCS, vol. 9666, pp. 32–62. Springer, Heidelberg (2016). https://
doi.org/10.1007/978-3-662-49896-5_2
29. Yamada, S.: Asymptotically compact adaptively secure lattice IBEs and veriﬁable
random functions via generalized partitioning techniques. In: Katz, J., Shacham,
H. (eds.) CRYPTO 2017. LNCS, vol. 10403, pp. 161–193. Springer, Cham (2017).
https://doi.org/10.1007/978-3-319-63697-9_6
30. Zhang, J., Chen, Yu., Zhang, Z.: Programmable hash functions from lattices:
short signatures and IBEs with small key sizes. In: Robshaw, M., Katz, J.
(eds.) CRYPTO 2016. LNCS, vol. 9816, pp. 303–332. Springer, Heidelberg (2016).
https://doi.org/10.1007/978-3-662-53015-3_11

Post-Quantum Cryptography

Quantum-Access Security of Hash-Based
Signature Schemes
Quan Yuan1(B), Mehdi Tibouchi2,3, and Masayuki Abe2,3
1 The University of Tokyo, Tokyo, Japan
yuanquan@g.ecc.u-tokyo.ac.jp
2 NTT Social Informatics Laboratories, Tokyo, Japan
3 Kyoto University, Kyoto, Japan
Abstract. In
post-quantum
cryptography,
hash-based
signature
schemes are attractive choices because of the weak assumptions. Most
existing hash-based signature schemes are proven secure against post-
quantum chosen message attacks (CMAs), where the adversaries are
able to execute quantum computations and classically query to the
signing oracle. In some cases, the signing oracle is also considered
quantum-accessible, meaning that the adversaries are able to send queries
with superpositions to the signing oracle. Considering this, Boneh and
Zhandry propose a stronger security notion called existential unforge-
ability under quantum chosen message attacks (EUF-qCMA). We call
it quantum-access security (or Q2 security in some literature). The
quantum-access security of practical signature schemes is lacking in
research, especially of the hash-based ones. In this paper, we analyze
the quantum-access security of hash-based signature schemes in two
directions. First, we show concrete quantum chosen message attacks (or
superposition attacks) on existing hash-based signature schemes, such as
SPHINCS and SPHINCS+. The complexity of the attacks is obviously
lower than that of optimal classical chosen message attacks, implying
that quantum chosen message attacks are more threatening than classical
ones to these schemes. Second, we propose a simple variant of SPHINCS+
and give security proof against quantum chosen message attacks. As far
as we know, it is the ﬁrst practical hash-based stateless signature scheme
against quantum chosen message attacks with concrete provable security.
Keywords: hash-based signatures · quantum security · post-quantum
cryptography · digital signatures · superposition attacks
1
Introduction
1.1
Background
Quantum-Access Security of Signature Schemes. Signature schemes [20]
are essential primitives in cryptography. In the security analysis of a signature
This work is carried out during his PhD study in Kyoto University, Japan.
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 343–380, 2023.
https://doi.org/10.1007/978-3-031-35486-1_16

344
Q. Yuan et al.
scheme, one usually considers existential unforgeability under chosen message
attacks (EUF-CMA). In this model, the adversary can query messages to a
signing oracle. After the signing queries, the adversary is required to output a
valid signature σ∗for a fresh message m∗. We say a scheme is EUF-CMA if any
polynomial-time adversary succeeds with negligible probability.
Quantum attacks on cryptographic schemes are usually classiﬁed into two
types [12,23,24]. In the ﬁrst type, the adversary can use quantum computers
to execute some oﬄine algorithms or evaluate some functions and send classical
queries to the online oracles. This is called post-quantum security (or Q1 secu-
rity in some literature). In the second type, the queries to the oracles are also in
superpositions. This is called quantum-access security (or Q2 security). In sig-
nature schemes, the above EUF-CMA security is a kind of Q1 security. In recent
years, there is a large amount of research on Q2 security of various cryptographic
primitives, including pseudorandom functions [35], message authentication codes
[10], encryption schemes [11], signature schemes [2,11,15,17] and so on.
In 2013, Boneh and Zhandry [11] propose a Q2 security notion called exis-
tential unforgeability under quantum chosen message attacks (EUF-qCMA). In
this experiment, the adversary is required to output (qs +1) forgeries for distinct
messages after qs quantum signing queries. They also show a separating exam-
ple, implying that EUF-qCMA is a strictly stronger security notion. However,
to the best of our knowledge, there is no concrete evidence to show that a Q2
attacker can be obviously stronger than a Q1 one for practical signature schemes
(although it is intuitively true).
Hash-Based Signatures. Hash-based signature (HBS) schemes are ones whose
security is solely based on secure hash functions rather than mathematical hard
problems. Because of the weak assumptions and resistance to quantum attacks,
HBS schemes are fairly competitive in post-quantum cryptography.
The ﬁrst practical stateless HBS scheme is SPHINCS [7]. It is based on
HORST (Hash to Obtain Random Subsets with Trees [31]), a few-time state-
less HBS scheme, where the number of signing operations is limited by a small
constant. A key pair of SPHINCS can issue at most 250 signatures and pro-
vide 128-bit quantum security1. So far, the state-of-art stateless HBS scheme is
SPHINCS+ [3,8], a variant using improved building blocks such as few-time sig-
natures and tweakable hash functions. It behaves better in terms of the signature
size, eﬃciency, security proof and the maximum number of signing executions
(reaching to 264). Recently, SPHINCS+ is selected as one of the NIST post-
quantum cryptography standardization.
In terms of the quantum-access security of HBS schemes, Boneh and Zhandry
[11] prove the EUF-qCMA security of Lamport’s scheme [28] and MSS [30]. The
1 In this paper, we always focus on signature schemes with security level 5 in NIST
post-quantum cryptography standardization. That is, breaking the security is at
least as hard as ﬁnding a preimage of AES-256. It implies 128-bit security, which
means that breaking the security requires about 2128 hash queries. In particular, we
focus on SPHINCS-256 and SPHINCS+-256s/256f.

Quantum-Access Security of Hash-Based Signature Schemes
345
former is a one-time HBS scheme, and the latter is a stateful one. Hopefully,
other stateful HBS schemes (such as XMSS [14]) are also EUF-qCMA since
they are essentially variants of MSS and the structures are similar. However,
when it comes to stateless schemes, the cases become diﬀerent. (The authors
proved the EUF-qCMA security of stateless MSS, but stateless MSS is far from
eﬃcient in practice.) For practical stateless HBS schemes, such as SPHINCS and
SPHINCS+, the quantum-access security still lacks research.
Note that Boneh and Zhandry [11] proposed a generic construction of EUF-
qCMA schemes from UUF-RMA (universally unforgeable under random message
attacks) schemes by introducing a hash function modeled as a quantum random
oracle. However, the construction causes large security loss, which will be espe-
cially expensive for HBS schemes, whose security are highly related to the num-
ber of issued signatures. For instance, suppose we want an EUF-qCMA scheme
such that the probability of breaking the security is under 2−10 when qs ≤210
and qH ≤230 (number of signing queries and hash computations respectively),
which is a fairly weak requirement in practice. If we use the above generic con-
struction, we need a 2117-time UU-RMA scheme with 254-bit quantum security,
which far exceeds the security of SPHINCS+.
1.2
Our Contributions
In this paper, we give positive and negative results on quantum-access security
of HBS schemes.
– First, we show some qCMAs on two HBS schemes, SPHINCS and SPHINCS+.
The complexity of our attacks is much lower than the security in the classical
setting. We thus conclude that quantum chosen message attacks are more
threatening to security than classical CMAs for the two schemes.
– Second, we propose SPHINCS-FORS, a simple variant of SPHINCS+, whose
quantum-access security can be proven. We give formal security proof and
concrete security in sense of EUF-CMA and EUF-qCMA. As far as we know,
it is the ﬁrst practical stateless HBS scheme with provable security against
qCMAs.
1.3
Main Techniques
Quantum Chosen Message Attacks on HBS Schemes. We ﬁrst give an
outline of SPHINCS and SPHINCS+. Roughly speaking, SPHINCS(+) intro-
duces a stateful signature HT and implicit 2h instances of few-time signature
key pairs (HORST in SPHINCS and FORS in SPHINCS+). HT is for signing
the public keys of the few-time signatures, and the few-time signatures are for
signing the messages. In each signing operation, it (pseudo-)randomly picks an
index idx ∈{0, 1}h and uses the few-time signature key pairs labeled idx to sign
a message. The essential idea is that the index is picked randomly, and thus, each
few-time signature key pair is not used too many times in the signing operations.

346
Q. Yuan et al.
The core idea of our attack is to obtain enough few-time signatures associ-
ated with a single index. In SPHINCS, the index is calculated by pseudorandom
functions on the message m and included as a part of the SPHINCS signature.
Although the pseudorandom functions cannot be directly evaluated by adver-
saries without the secret key, they can be evaluated by signing queries. Fix some
index idx∗∈{0, 1}h. A quantum-access adversary can search a message m∗
mapping to idx∗by Grover’s algorithm with O(2h/2) quantum queries to the
signing oracle.
Thus, our quantum chosen message attack on SPHINCS runs as follows.
First, try to obtain enough number (say r) of messages m∗
i mapping to an index
idx∗by querying the signing oracle. This requires O(r2h/2) quantum signing
queries. Then, send m∗
i (with pure states) to the signing oracle separately, and
obtain r HORST signatures associated with idx∗. This requires r signing queries.
When r is large enough, the HORST secret key associated with idx∗will be
completely revealed, and the adversary can forge a signature forany message.
Finally, generate enough SPHINCS signatures associated with index idx∗to
meet the requirement of one-more forgeries. Note that optimal classical chosen
message attacks on SPHINCS require approximately 2128 hash queries (when at
most 250 signatures are issued). The query complexity of our attacks are much
lower than that of classical attacks (see Table 1, Our Attacks (PO)).
Result 1. For some integer r, there exists a quantum chosen message attack on
SPHINCS such that
qs = O(r2h/2),
qH = O((1 −e−kr
t )−k
2 r2
h
2 ),
where qs and qH denotes the number of quantum signing queries and quantum
hash queries, respectively.
The attack on SPHINCS+ is similar. The diﬀerence is that the index of
a SPHINCS+ signature is not directly included. Instead, it is calculated by
h0(z||m), where h0 is a hash function mapping to {0, 1}h and z is a (pseudo-)
randomizer determined by the message m.2 Since z is included in the signature,
the index can be evaluated by a signing query (calculating z) and an additional
h0 query. Then, use Grover’s algorithm to ﬁnd enough FORS signatures associ-
ated with an index idx∗. Finally, to generate a forgery (m∗
i , σ∗
i ), the adversary
needs to ﬁnd a corresponding randomizer z∗
i such that h0(z∗
i ||m∗
i ) = idx∗. It
requires O(2h/2) quantum queries to h0 by using Grover’s algorithm for each
forgery. Thus, the attack on SPHINCS+ requires more hash queries than that
on SPHINCS (see Table 1, Our Attacks (PO)).
Result 2. For some integer r, there exists a quantum chosen message attack on
SPHINCS+ such that
qs = O(r2h/2),
qH = O((1 −e−r
t )−k
2 r2h).
2 SPHINCS+ has a probabilistic version where z is not determined by the message.
Our attack only works on the deterministic version of SPHINCS(+).

Quantum-Access Security of Hash-Based Signature Schemes
347
In addition, Alagic et al. [2] propose another security notion called blind
unforgeability (BU) considering quantum chosen message attacks.3. Informally,
the (quantum-accessible) signing oracle now returns ⊥for messages in a ε-
fraction blind subset of the message space, and it is infeasible to forge a signature
for a message in this blind subset. To distinguish the two, we call the previous
security model against qCMAs as PO model (Plus-one model). In our study, we
also give similar attacks on SPHINCS and SPHINCS+ in the BU model, and
the time complexity of the attacks is much lower than that in the PO model (see
Table 1, Our Attacks(BU)).
By implementing the parameters in SPHINCS [7] and SPHINCS+ v.3 [3],
we give comparisons among the attacks in the EUF-CMA model, the PO model,
and the BU model. See more details in Table 1.
Table 1. Comparisons between our qCMAs and the CMA security of SPHINCS(+),
which implies the bounds of tolerable hash queries. qs and qH denote the number of
(quantum) signing queries and quantum hash queries, respectively. For example, if the
adversary issues 243 quantum signing queries to the signing oracle and more than 243
quantum hash queries, then SPHINCS-256 will be broken in the PO model. “Small”
means that the attack only requires a polynomial number of queries.
Scheme
CMA Security Our Attack (PO) Our Attack (BU)
log qs log qH
log qs log qH
log qs log qH
SPHINCS-256 [7]
50
128
43
43
43
Small
SPHINCS+-256s [3] 64
128
48
80
43
43
SPHINCS+-256f [3]
64
128
46
80
42
42
A Provably Secure Stateless HBS Scheme Against Quantum Chosen
Message Attacks. Although we show qCMAs on SPHINCS and SPHINCS+,
the time complexity of the attacks does not imply the precise security levels of
the schemes against qCMAs. Indeed, it only implies upper bounds of the security.
We hope to construct a provably secure scheme, whose generic security against
qCMAs can be guaranteed and lower-bounded.
We start with the security analysis of few-time signature schemes, such as
HORS [31] and FORS [8]. Most the practical few-time signature schemes are
related to (variants of) subset resilient hash functions (SRH) [31,33]. Unfor-
tunately, their quantum-access security cannot be reduced to subset resilience
directly. To solve this problem, we propose a variant of subset resilience called
weak subset resilience (wSR). We ﬁnd that the EUF-qCMA security of a ran-
domized version of FORS (say rFORS, implicitly contained in SPHINCS+) can
3 The notion is proposed for message authentication codes but can also be extended
to signature schemes.

348
Q. Yuan et al.
then be reduced to wSR and some additional common security notions for hash
functions (such as multi-target collision resistance, mTCR).
Since wSR is a new notion and lack of research, the generic security needs
to be evaluated. We solve this problem by the quantum query lemma [32]. As a
result, the generic security of rFORS against r-time qCMAs can be bounded by
AdvEUF-qCMA
rFORS,r,q (A) ≤O

q2(r+1)
r2
t
k
+ q2ktr
2n

,
(1)
where q denotes the number of queries to the hash functions (modeled as random
oracles) and k, t, n are parameters. The ﬁrst term of Eq. (1) comes from the
generic security of wSR. The second one comes from mTCR and the reduction.
They are negligible when r is a small constant number. (In practice, t ≈2
√n
and k ≈√n.)
(To the best of our knowledge, there is no quantum generic security bound of
subset resilience. We also ﬁll this gap, which could be independently interesting.
For example, it immediately implies concrete security of the related few-time
HBS schemes in terms of post-quantum EUF-CMA.)
We then turn to many-time schemes. The main reason for the insecurity
against the above qCMAs is that the index is determined by the message due to
the pseudorandom functions. A natural idea to resist these attacks is to intro-
duce additional randomness into the process of choosing the index. Here, we
use a simpler approach: we directly replace the index with randomness that is
independent of the message and include it in the signature. Now, the signatures
in a quantum signing response share a common few-time signature key pair in
a signing query. The EUF-qCMA security is thus reduced to the EUF-qCMA
security of the related few-time signature scheme, rFORS, which can be bounded
by Eq. (1).
Although the new variant can avoid some qCMAs, it brings other risks. Since
the index is directly included in the signature, an adversary can arbitrarily choose
an index in the forgery. Thus, the EUF-CMA security of the new variant needs
to be re-analyzed.
Similarly, the EUF-CMA security of our new variant can be reduced to the
EUF-CMA security of rFORS. The remaining work is evaluating the EUF-CMA
security of rFORS. Indeed, the EUF-CMA security of rFORS can be tightly
reduced to a variant of subset resilience called extended Target Subset Resilience
(eTSR). Unfortunately, the generic security of eTSR cannot be (tightly) evalu-
ated by the same approach. We use the adaptive reprogramming lemma [21] to
solve this problem. The EUF-CMA security of rFORS is then bounded by
AdvEUF-CMA
rFORS,r,q(A) ≤O
 q
2n + q2
r
t
k
+ q2
2n

.
(2)
The ﬁrst two terms of Eq. (2) comes from the generic security of eTSR, and the
third one comes from mTCR.
Equipped with rFORS, the message-independent random index, and the same
HT as in SPHINCS+, we get our new variant called SPHINCS-FORS. (The name

Quantum-Access Security of Hash-Based Signature Schemes
349
is given since the framework looks like SPHINCS (not SPHINCS+) equipped
with rFORS.) The outline of the security analysis of SPHINCS-FORS is sum-
marized in Fig. 1.
wSR
-
(+mTCR)
EUF-qCMA
of rFORS
-
(+HT)
EUF-qCMA of
SPHINCS-FORS
eTSR
-
(+mTCR)
EUF-CMA
of rFORS
-
(+HT)
EUF-CMA of
SPHINCS-FORS
Hash Function
Few-time HBS
Many-time HBS
Th.3,4
Th.5
Th.4
Th.5
Th.1
Th.2
Fig. 1. The security proof sketch of SPHINCS-FORS.
Finally, the generic security of SPHINCS-FORS is evaluated as follows.
Result 3. Let the hash functions in SPHINCS-FORS be modeled as quantum
random oracles. For any adversary A, it holds that
AdvEUF-CMA
SPHINCS-FORS,qs,qH(A) ≤O

qs

qH + qs
2n
+ qH
2n/2 + q2
H
qs

r=0
p(r, qs)
r
t
k
,
AdvEUF-qCMA
SPHINCS-FORS,qs,qH (A) ≤O
 qH
2n/2 +
qs

r=0
p(r, qs) · min

q2(r+1)
H
r2
t
k
+q2
Hktr
2n
, 1

,
where p(r, qs) = min{2r(log qs−h)+h−log r!, 2h}.
For EUF-CMA security, we expect it to reach 128-bit security as SPHINCS+,
which means that for ﬁxed qs (e.g., qs = 264), AdvEUF-CMA
SPHINCS-FORS,qs,qH(A) reaches
to a constant only if qH reaches 2128. When n = 256, the dominant term is
q2
H
qs
r=0 p(r; qs)( r
t )k. We adapt the parameters such that qs
r=0 p(r, qs)( r
t )k =
2−256, and then the resulting scheme provides 128-bit security against CMA.
It is more complicated for EUF-qCMA security. The dominant term is also
the one with the summation notion, which is larger than the above one. When r
is small, min{q2(r+1)
H
( r2
t )k + q2
Hktr
2n
, 1} is negligibly small. When r becomes large,
p(r, qs) becomes negligibly small and the righthand term is always bounded by
1, so the product is still small. Thus, the sum of the products remains bounded
if the parameters are well stated.
We give instantiation of SPHINCS-FORS by adapting the parameters in
Table 2. We observe that SPHINCS-FORS has larger signature size and running
time, but can provide provable security in sense of EUF-qCMA.

350
Q. Yuan et al.
Table 2. Comparison between (deterministic) SPHINCS+ and our variants against
quantum chosen message attacks. log qH ≤a means that there exists a quantum chosen
message attack with 2a quantum hash queries. It implies an upper bound of the security
level (without security proof). log qH ≥a means that any quantum chosen message
attack requires at least 2a hash queries. It implies a lower bound of the security level
(with security proof). Note that all the schemes in this table can provide at least 128-bit
EUF-CMA security when log qs ≤64.
Scheme
Parameters
Security
Size
Provably Secure?
k
log t h
n
log qs log qH
SPHINCS+-256s
22 14
64
256 48
≤80
29272

SPHINCS-FORS v1 (Ours) 32 17
128 256 48
≥80
47072

SPHINCS+-256s∗
22 14
104 256 64
≤128
41792

SPHINCS-FORS v2 (Ours) 48 18
128 384 64
≥128
101424 
1.4
Related Work
HBS schemes have a long history that begins with Lamport’s one-time signature
scheme [28]. SPHINCS [7] is the ﬁrst practical stateless HBS using Goldreich’s
framework [19]. There are several variants of SPHINCS [5,8,26,38]. The tight
security proof is recently given in the post-quantum setting [25].
The generic security of hash functions is the core of analyzing the concrete
security of HBS schemes. There is previous work proving the post-quantum
generic security [1,21,25,27,32,36,37]. Especially, SPHINCS-family is related to
subset resilience [4,33]. In recent concurrent work, Bouaziz-Ermann and Grilo et
al. [13] shows quantum generic security of (restricted) subset resilience when the
range of the “partial” hash (say t) is strictly exponential. Unfortunately, their
proof fails since t is not large enough in a practical HBS scheme. (For instance,
their proof once causes a term of reduction loss O(t1/48), which is considered a
negligible function when t is exponential. However, t is instantiated by 214 in
SPHINCS-256s, and thus the above term cannot be ignored.)
Quantum-access security is ﬁrst considered for pseudorandom functions [35]
and then generalized to message authentication codes and signatures [10,11].
After that, other quantum-access security notions are proposed [2,18] for message
authentication codes (and they can also be extended to ﬁt signature schemes).
In particular, the blind unforgeability of Lamport’s scheme, WOTS, and GPV
signatures has been evaluated [15,29].
1.5
Organizations
In Sect. 2, we introduce the basic preliminaries and the security notions for sig-
nature schemes in the quantum-access settings. In Sect. 3, we introduce and pro-
pose the subset-resilient hash function and its variants. In Sect. 4, we introduce
hash-based signature schemes. In Sect. 5, we propose quantum-access attacks

Quantum-Access Security of Hash-Based Signature Schemes
351
on SPHINCS(+). In Sect. 6, we give generic quantum security bound for few-
time HBS and eventually construct a provably quantum-access-secure variant
of SPHINCS+. Due to the space limitation, we omit some of deﬁnitions and
security proof in this paper. See details in the full version [34].
2
Preliminaries
2.1
Basic Preliminaries
Notations. For a set X, |X| denotes the cardinality of X and x ←X means
that x is uniformly chosen from X. For integer n ∈N, denote [n] = {1, ..., n}.
We say that ϵ : N →R+ is negligible function if for every constant c > 0, there
exists Nc > 0 such that ϵ(n) < n−c holds for all n > Nc. We denote by || the
concatenation operation.
Random Oracle Model. In the (classical) random oracle model [6], a random
function H is uniformly chosen at the beginning and one can compute H by
querying the random oracle. In quantum random oracle model [9], H is quantum-
accessible, i.e., one can query 
x,y ψx,y |x, y⟩to the quantum random oracle, and
obtains 
x,y ψx,y |x, y ⊕H(x)⟩in response.
Hash Functions. In this paper, we frequently use hash functions mapping to
k (ordered) elements of set [t] (where t = 2τ for some integer τ). We can simply
sample such a function by sampling a hash function H′ : {0, 1}∗→{0, 1}k·log t,
splitting the output into k short strings of length τ, and then mapping the short
strings into integers in [t].
In the following, we denote a function H : {0, 1}∗→[t]k by H = (h1, ..., hk),
where hi : {0, 1}∗→[t] denotes the “partial” function mapping to the i-th
element of the output of H. To avoid ambiguity, we always use capital letters
(such as H) to denote a hash function and their corresponding small letters with
a subscript (such as hi) as the partial functions. For instance, in the case that
H is a hash function family mapping to [t]k, (h1, ..., hk) ←H means sampling
H ←H and letting H = (h1, ..., hk), rather than sampling k functions from H.
2.2
Security Notions for Hash-Based Signature Schemes
Let Γ = (KeyGen, Sign, Ver) be a signature scheme. SigO denotes the signing
oracle that computes Sign(sk, m) where sk is the secret key. If SigO is quantum-
accessible, say |SigO⟩, it means that
|SigO⟩:

m,t
ψm,t |m, t⟩→

m,t
ψm,t |m, t ⊕Sign(sk, m)⟩.
Especially, if Sign is probabilistic, SigO replies 
m,t ψm,t |m, t ⊕Sign(sk, m; r)⟩
with a random seed r for a query 
m,t ψm,t |m, t⟩.

352
Q. Yuan et al.
This paper focuses on hash-based signature (HBS) schemes. The security of
an HBS scheme is related to the number of hash queries from the adversary. Let
qs and qH respectively denote the maximum number of signing queries and hash
queries. The security is deﬁned as follows.
Experiment ExpEUF-CMA
Γ,qs,qH (1n, A)
(pk, sk) ←KeyGen(1n)
(m∗, σ∗) ←ASigO(pk)
If m∗has not been queried to SigO and Ver(pk, m∗, σ∗) = 1, return 1,
otherwise return 0.
Experiment ExpEUF-qCMA
Γ,qs,qH
(1n, A)
(pk, sk) ←KeyGen(1n)
{(mj, σj)}j∈[r+1] ←A|SigO⟩(pk)
If mj’s are distinct and for ∀j ∈[qs + 1], Ver(pk, mj, σj) = 1, return 1,
otherwise return 0.
Deﬁnition 1. ([11]) Let Γ be a signature scheme. We say it is existentially
unforgeable under chosen message attacks (EUF-CMA) (or quantum chosen
message attacks (EUF-qCMA)) if for all probabilistic polynomial-time adversary
A, Pr[ExpEUF-CMA
Γ,qs,qH
(1n, A)] ≤negl(n) (or Pr[ExpEUF-qCMA
Γ,qs,qH
(1n, A)] ≤negl(n))
holds, where negl is a negligible function.
In addition, we introduce a security notion called blind unforgeability [2].
Let ε : N →R≥0 be an eﬃciently computable function. Bε,n be a subset of the
message space Mn that is selected by placing each m ∈Mn independently with
probability ε(n). Deﬁne the blind signing oracle Bε,nSigO as follows:
Bε,nSigO : m →

Sign(sk, m)
(m ̸∈Bε,n),
⊥,
(otherwise).
Similarly, when Bε,nSigO is quantum-accessible, say |Bε,nSigO⟩, it maps
|Bε,nSigO⟩:

m,t
ψm,t |m, t⟩→

m,t
ψm,t |m, t ⊕Bε,nSigO(m)⟩.
Then, the experiment of blind unforgeability under quantum chosen message
attacks is as follows:
Experiment ExpBU-qCMA
Γ,qs,qH (1n, A)
(pk, sk) ←KeyGen(1n)
(m∗, σ∗) ←A|Bε,nSigO⟩(pk)
If m ∈Bε,n ∧Ver(pk, m∗, σ∗) = 1, return 1, otherwise return 0.
Remark 1. In this paper, we mainly discuss EUF-qCMA security instead of BU
except in Sect. 5.3. Apart from this subsection, we use the EUF-qCMA model in
Deﬁnition 1 to evaluate the security against qCMAs by default.
We omit the security parameter 1n in the inputs of the algorithms and exper-
iments for simplicity.

Quantum-Access Security of Hash-Based Signature Schemes
353
2.3
Toolbox
In this section, we show some useful lemmas related to quantum computations
and quantum random oracles.
Lemma 1. (Quantum query complexity lemma. [32]) Let H be a random func-
tion mapping X to Y, r be a positive integer, and R be a relation over Yr. For
any quantum adversary A which can query H at most q times, it holds that
Pr
H

x1, ..., xr are distinct ∧(H(x1), ..., H(xr)) ∈R|(x1, ..., xr) ←A|H⟩	
≤(2q + 1)2r Pr

∃π ∈Perm([r]) s.t. (yπ(1), ..., yπ(r)) ∈R|(y1, ..., yr) ←Yr

,
where Perm([r]) denotes the set of permutations of [r].
Corollary 1. Let F be an eﬃcient function esemble modeled by a quantum
random oracle. For any quantum adversary A, it holds that
AdvOW
F,q(A) ≤(2q + 1)2 · 2−n.
The next lemma show that if we perform a partial measurement in the process
of a quantum algorithm and the measurement obtains one of t outcomes, then
the ﬁnal output of the algorithm will remain unchanged with probability at least
1/t.
Lemma 2. [11] Let A be a probabilistic quantum algorithm. Let A′ be another
algorithm described as follows: A′ runs as A but pauses it at an arbitrary stage
of execution, performs a partial measurement that obtains one of t outcomes,
and then resumes A. For any x, it holds that
Pr
A′[x ←A′] ≥Pr
A [x ←A]/t.
Deﬁnition 2. [27] Let F ≜{f : {0, 1}m →{0, 1}} be the collection of all
boolean functions with input space {0, 1}m. Let λ ∈[0, 1] be a constant. Deﬁne a
family of distributions Dλ on F such that for f ←Dλ, ∀x ∈{0, 1}m, f(x) = 1
with probability λ and f(x) = 0 with probability 1 −λ.
Lemma 3. [27] Let A be an algorithm A issuing q quantum queries to f(·).
Deﬁne
AdvAvg-Searchλ
F,q
(A) ≜
Pr
f←Dλ[f(x) = 1|x ←Af].
Then, for any adversary A, it holds that
AdvAvg-Searchλ
F,q
(A) ≤8λ(q + 1)2.
Next we introduce the adaptive reprogramming lemma [21]. It shows that
if we reprogram the random oracle in some partially random records, then an
adversary is hard to tell the diﬀerence. For an oracle O : X →Y , x ∈X and
y ∈Y , denote Ox→y as an oracle that is the same as O except that it maps x to
y. The adaptive reprogramming lemma is as follows.

354
Q. Yuan et al.
Lemma 4. (Adaptive reprogramming lemma. [21]) Let X1, X2 and Y be ﬁnite
sets, O0 : X1 × X2 →Y be a random oracle and Reprob be the adaptive repro-
gramming game depicted in Fig. 2. Let A be an algorithm issuing q quantum
queries to Ob and R classical queries to Reprogram. Then, the probability of
distinguishing b is at most
| Pr[ReproA
1 = 1]| −| Pr[ReproA
0 = 1]| ≤3R
2
 q
|X1|.
Game Reprob
Reprogram(x2)
O1 := O0
(x1, y) ←X1 × Y
b′ ←A|
b⟩,
O1 := Ox1||x2→y
1
return b′
return x1
Fig. 2. Adaptive reprogramming games for b ∈{0, 1}.
Lemma 5. (Grover’s Algorithm. [22]) Let F : X →{0, 1} be a predicate map-
ping an element of set X to a bit and F −1(1) = {x : F(x) = 1} is non-empty.
Let t = |F −1(1)| > 0. There is a quantum algorithm that randomly returns
x∗∈F −1(1) with at most O(

|X|
t ) quantum queries to F.
We call the above quantum algorithm Grover’s algorithm.
3
Subset Resilience and Its Variants
Subset resilience is ﬁrst proposed in HORS [31], a few-time HBS scheme. In this
section, we give deﬁnitions of several variants and analyze their generic security.
3.1
Deﬁnitions
Deﬁnition 3. (Subset Cover. [31,33]) Let H = (h1, ...hk) be a hash func-
tion mapping {0, 1}m to [t]k and r ≥0 be an integer. We say that (r + 1)-
tuple (x, x1, ..., xr) ∈{0, 1}m(r+1) is an (r, k)-subset cover of H if it holds that
{hi(x)}i∈[k] ⊂{hi(xj)}i∈[k],j∈[r] and x ̸∈{xj}j∈[r].
Deﬁnition 4. (Restricted Subset Cover. [33]) Let H = (h1, ...hk) be a hash
function mapping {0, 1}m to [t]k and r ≥0 be an integer. We say that (r + 1)-
tuple (x, x1, ..., xr) ∈{0, 1}m(r+1) is an (r, k)-restricted subset cover of H if it
holds that x ̸∈{xj}j∈[r], and for ∀i ∈[k], hi(x) ∈{hi(xj)}j∈[r].

Quantum-Access Security of Hash-Based Signature Schemes
355
Next, we show a weaker statement called weak subset cover that is useful in
the following sections.
Deﬁnition 5. (Weak Subset Cover.) Let H = (h1, ...hk) be a hash function
mapping {0, 1}m to [t]k and r ≥0 be an integer. We say an (r + 1)-tuple
(x1, ..., xr+1) ∈{0, 1}m(r+1) is an (r, k)-weak subset cover of H if for ∀i ∈[k],
it holds that |{hi(xj)}j∈[r+1]| ≤r and xj’s are distinct. In other words, there
exists a collision in x1, ..., xr+1 w.r.t. each hi.
Corollary 2. If (x, x1, ..., xr) is an (r, k)-restricted subset cover of H, it is also
an (r, k)-weak subset cover of H.
If it is hard for any polynomial-time adversary to ﬁnd a (restricted/weak-)
subset cover, then we say that the hash function family is (restricted/weak-)
subset-resilient.
Deﬁnition 6. Let H = {H : {0, 1}m →[t]k} be a hash function family. Let A
be an adversary that takes as input H = (h1, ..., hk) ←H, runs at most q hash
queries and ﬁnally outputs (x, x1, ..., xr) ∈{0, 1}m(r+1). Deﬁne
Adv(r,k)-SR
H,q
(A) ≜Pr
H,A

{hi(x)}i∈[k] ⊂{hi(xj)}i∈[k],j∈[r] ∧x /∈{xj}j∈[r]

and
Adv(r,k)-rSR
H,q
(A) ≜Pr
H,A

∀i ∈[k], hi(x) ∈{hi(xj)}j∈[r] ∧x /∈{xj}j∈[r]

.
Let A be an adversary that takes as input H = (h1, ..., hk) ←H, runs at
most q hash queries and ﬁnally outputs (x1, ..., xr+1) ∈{0, 1}m(r+1). Deﬁne
Adv(r,k)-wSR
H,q
(A) ≜Pr
H,A

∀i ∈[k],
{hi(xj)}j∈[r+1]
 ≤r ∧x1, x2, ..., xr+1 are distinct
	
.
We say that H is a secure (r, k)(-restricted/weak) subset resilient hash func-
tion family or (r, k)-SRH(/rSRH/wSRH) if Adv(r,k)-SR
H,q
(A)/Adv(r,k)-rSR
H,q
(A)/
Adv(r,k)-wSR
H,q
(A) is negligible for any probabilistic polynomial-time quantum
adversary A.
3.2
Generic Security with Quantum Queries
Theorem 1. Let H = {H : {0, 1}m →[t]k} be a random function family and r
be a positive integer. For any quantum probabilistic polynomial-time adversary
A, it holds that
Adv(r,k)-wSR
H,q
(A) ≤(2q + 1)2(r+1)
r2
t
k
,
(3)

356
Q. Yuan et al.
Adv(r,k)-rSR
H,q
(A) ≤(2q + 1)2(r+1)(2r + 2)
r
t
k
,
(4)
and
Adv(r,k)-SR
H,q
(A) ≤(2q + 1)2(r+1)(2r + 2)
rk
t
k
.
(5)
Proof. Since H is a random function family, the success probability of adversaries
can be evaluated by Lemma 1. For i ∈[k], denote by y(i) ∈[t] the i-th element
of y.
1. (Proof of (3).)
For H = (h1, ..., hk) : {0, 1}∗→[t]k, deﬁne R1 ⊆[t]k(r+1) as follows:
R1 ≜{(y1, y2, ..., yr+1) : ∀i ∈[k],
{y(i)
j }j∈[r+1]
 ≤r}.
We analyze the size of R1. From (y1, ..., yr+1) ∈R1, for every i ∈[k], (at
least) two of y(i)
1 , ..., y(i)
r+1 are equal. Fix an i ∈[k], we can traverse all the
possible (y(i)
1 , ..., y(i)
r+1) w.r.t. i as follows:
(a) Pick a pair of indices a1, a2 from [r].
(b) Pick y ∈[t], let ya1 = ya2 = y.
(c) Traverse all possible values of y(i)
j
for all j ̸∈{a1, a2} and j ∈[r + 1].
The numbers of choices in the three steps are
r+1
2

, t and tr−1 respectively.
Thus, for all i ∈[k], the total number of possible values of (y1, ..., yr+1) ∈R1
is at most
r + 1
2

· t · tr−1
k
=
(r + 1)r
2
tr
k
≤(r2tr)k.
In addition, it is not hard to see that relation R1 is not ordered (which means
that for any π ∈Perm([r + 1]), the statement (y1, ..., yr+1) ∈R1 is equivalent
to the statement (yπ(1), ..., yπ(r+1)) ∈R1). Due to Lemma 1, we have
Adv(r,k)-wSR
H,q
(A) ≤(2q + 1)2(r+1) (r2tr)k
t(r+1)k = (2q + 1)2(r+1)
r2
t
k
,
which is what we expected.
2. (Proof of (4).)
Note that in Lemma 1, the elements in a solution have to be distinct, but
those in a restricted subset cover do not. (In a restricted subset cover, only
x ̸∈{xj}j∈[r] is demanded, and thus xj can be equal to another xj′.) We
divide a restricted subset cover into several cases.
Fix r, H and A. Recall that H = (h1, ..., hk) ←H and (x, x1, ..., xr) ←A(H).
Let 1 ≤s ≤r be some integer. Deﬁne
f(s) ≜Pr
H,A

∀i ∈[k], hi(x) ∈{hi(xj)}j∈[r] ∧x ̸∈{xj}j∈[r] ∧
{xj}j∈[r]
 = s

.

Quantum-Access Security of Hash-Based Signature Schemes
357
Then, we have
Adv(r,k)-rSR
H,q
(A) =

s∈[r]
f(s),
and
f(r) = Pr
H,A

{hi(x)}i∈[k] ⊂{hi(xj)}i∈[k],j∈[r] ∧x, x1, ..., xr are distinct

.
First, we give a bound for the case that r = s.
Lemma 6. f(r) ≤(2q + 1)2(r+1)(r + 1)( r
t )k.
Proof. For H = (h1, ..., hk) : {0, 1}∗→[t]k, deﬁne R2 ⊆[t]k(r+1) as follows:
R2 ≜

(y, y1, ..., yr) : ∀i ∈[k], y(i) ∈{y(i)
j }j∈[r]

.
Next, we analyze the size of R2. For convenience, we call the ﬁrst element of
(y, y1, ..., yr) ∈R2 as y0.
First, there are exactly tk possible values of y0. Then, for any ﬁxed y0 =
(y(1)
0 , ..., y(k)
0 ), it holds that y(i)
0
∈{y(i)
j }j∈[r] for each i ∈[k]. This implies that
y(i)
j
= y(i)
0
for some j ∈[r]. We can traverse all the possible value of (y(i)
1 , ..., y(i)
r )
for each i w.r.t. y0 by the following steps:
(a) Pick j ∈[r] and let y(i)
j
= y(i)
0 .
(b) Traversing all the possible value of y(i)
j′ for all j′ ∈[r] and j′ ̸= j.
The number of possible values of (y(i)
1 , ..., y(i)
r ) w.r.t. y0 is at most r · tr−1 for
each i. Thus, considering all i ∈[k] and traversing all possible values of y0, the
total number of (y0, y1, ..., yr) is at most
(r · tr−1)k · tk = (rtr)k.
Unlike R1, relation R2 is ordered. Deﬁne
R∗
2 ≜{(y1, ..., yr+1) : ∃π ∈Perm([r + 1]) s.t. (yπ(1), ..., yπ(r+1)) ∈R2}.
Observe that for any π ∈Perm([r]), the statement (y, y1, ..., yr) ∈R2 is equiva-
lent to the statement (y, y(π(1)), ..., yπ(r)) ∈R2. This implies that the order of R2
is only determined by the ﬁrst element. Thus, we can traverse all the possible
values of (y1, ..., yr+1) ∈R∗
2 by the following steps:
(a) Pick (y, y1, ..., yr) ∈R2.
(b) Pick j ∈[r + 1], and insert y between (j −1)-th element and the j-th
element of (y1, ..., yr). In other words, traverse (y, y1, ...yr), (y1, y, y2, ..., yr),
..., (y1, ..., yr, y).

358
Q. Yuan et al.
Thus, we have
|R∗
2| ≤(r + 1)|R2| ≤(r + 1)(rtr)k.
Due to Lemma 1, we have
f(r) ≤(2q + 1)2(r+1) (r + 1)(rtr)k
t(r+1)k
= (2q + 1)2(r+1)(r + 1)
r
t
k
.
Next, we consider the case that s < r.
If the adversary output an (r, k)-restricted subset cover (x, x1, ..., xr) such
that |{xj}j∈[r]| = s < r. Let {xj}j∈[r] = {x′
j′}j′∈[s] after reordering. Then, it is
not hard to see that (x, x′
1, ..., x′
s) is an (s, k)-restricted cover and all the elements
are distinct. The probability of this event is also bounded by Lemma 6. That is,
for all 1 ≤s ≤r it holds that
f(s) ≤(2q + 1)2(s+1)(s + 1)
s
t
k
≤(2q + 1)2(s+1)(r + 1)
r
t
k
.
Thus, we have
Adv(r,k)-rSR
H,q
(A) =

s∈[r]
(2q + 1)2(s+1)(r + 1)
r
t
k
≤(2q + 1)2(r+1)(2r + 2)
r
t
k
.
3. (Proof of (5).)
Similarly, ﬁx r, H, A. For s ∈[r], we deﬁne
g(s) ≜Pr
H,A

x /∈{x1, ..., xr} ∧{hi(x)}i∈[k] ⊂{hi(xj)}i∈[k],j∈[r] ∧
{xj}j∈[r]
 = s
	
,
and thus
Adv(r,k)-SR
H,q
(A) =

s∈[r]
g(s).
As above, we ﬁrst consider the case that s = r.
For H = (h1, ..., hk) : {0, 1}∗→[t]k, deﬁne R3 ⊆[t]k(r+1) as follows:
R3 ≜{(y, y1, ..., yr) : {y(i)}i∈[k] ⊆{y(i)
j }i∈[k],j∈[r]}.
We divide R3 into k subsets R3,1, ..., R3,k, where, for m ∈[k],
R3,m ≜{((y, y1, ..., yr) ∈R3 :
{y(i)}i∈[k]
 = m}.
Observe that R3,m’s are disjoint and that R3 = 
m∈[k] R3,m. More precisely,
the statement (y, y1, ..., yr) ∈R3,m implies that {y(i)}i∈[k] contains exactly m
elements in [t], and {y(i)
j }i∈[k],j∈[r] covers them. Since there are at most rk
elements in set {y(i)
j }i∈[k],j∈[r], there are rk “chances” to cover the m target
elements. We can traverse all the elements of R3,m by the following steps:
(a) Pick m distinct elements x1, ..., xm from [t]. Let X = {x1, ..., xm}.
The number of choices in this step is
 t
m

.

Quantum-Access Security of Hash-Based Signature Schemes
359
(b) Pick y(1), ..., y(k) from Xk such that {y(i)}i∈[k] = X.
This step is equivalent to the experiment of putting k diﬀerent balls into
m diﬀerent bins such that there is at least one ball in each bin. The
number of choices is
 k
m

· m!, where
 k
m

denotes Stirling number of the
second kind.
(c) Next, we require that {y(i)
j }i∈[k],j∈[r] covers X = {y(i)}i∈[k]. Since |X| =
m, we only need to choose m elements of {y(i)
j }i∈[k],j∈[r], make them equal
to a permutation of X, and do not have any demand for the remaining
(rk −m) elements.
The number of choices in the two substeps are
rk
m

and m! respectively.
(d) Finally, since the remaining (rk −m) elements have no demand, traverse
all the possible y(i)
j
that have not been assigned in the above steps.
The number of choices in this step is t(rk−m).
To sum up, the total number of elements in R3,m is
|R3,m| =
 t
m
 k
m

· m! ·
rk
m

· m! · trk−m
≤tm
m! ·
 k
m

· m! ·
rk
m

· m! · trk−m
=
 k
m

·
rk
m

· m! · trk
=
 k
m

· (rk)m · trk,
where (·)m denotes the falling factorial:
(x)m = x · (x −1) · ... · (x −m + 1).
Thus, we have
|R3| =
k

m=1
|R3,m| ≤
k

m=1
 k
m

· (rk)m · trk = (rk)k · trk,
where the last equality uses the fact that k
m=1
 k
m

(x)m = xk.
Similar to R2, we deﬁne
R∗
3 ≜{(y1, ..., yr+1) : ∃π ∈Perm([r + 1]) s.t. (yπ(1), ..., yπ(r+1)) ∈R3},
and then we have
|R∗
3| ≤(r + 1)|R3| ≤(r + 1)(rk)k · trk.
Due to Lemma 1, we have
g(r) ≤(2q + 1)2(r+1) (r + 1)(rk)k · trk
t(r+1)k
= (2q + 1)2(r+1)(r + 1)
rk
t
k
,

360
Q. Yuan et al.
and for s ∈[r],
g(s) ≤(2q + 1)2(s+1)(s + 1)
sk
t
k
≤(2q + 1)2(s+1)(r + 1)
rk
t
k
.
Thus,
Adv(r,k)-SR
H,q
(A) =

s∈[r]
(2q + 1)2(s+1)(r + 1)
rk
t
k
≤(2q + 1)2(r+1)(2r + 2)
rk
t
k
.
3.3
Target Subset Resilience
Target subset resilience (TSR) [31] is a variant of subset resilience. In (r, k)-TSR
experiment, the adversary is given a hash function H = (h1, ..., hk) and r random
targets x1, ...xr. Then, the adversary is required to output a single element x
such that {hi(x)}i∈[k] ⊂{hi(xj)}i∈[k],j∈[r]. It is not hard to see that (r, k)-TSR
is a weaker notion than (r, k)-SR.
In this section we propose a target version of restricted subset resilience,
which is called extended target subset resilience (eTSR). Unlike TSR, the adver-
sary in eTSR can adaptively control the target to some extent. In detail, the
adversary is able to adaptively query a (classical) oracle Box. For a query
xj, Box randomly chooses zj ∈{0, 1}n and returns (zj, H(zj||xj)). After r
queries, the adversary is required to output (x, z) such that for each i ∈[k],
hi(z||x) ∈{hi(zj||xj)}j∈[r] and (x, z) ̸∈{(xj, zj)}j∈[r] hold. Note that (r, k)-
eTSR is a weaker notion than than (r, k)-rSR.
Deﬁnition 7. (Extended Target Subset Resilience.) Let H = {H = (h1, ..., hk) :
{0, 1}m+n →[t]k} be a hash function family. Let ABox be an adversary that
queries Box at most r times, computes H at most q times and then outputs
(x, z) ∈{0, 1}m+n. Deﬁne
Adv(r,k)-eTSR
H,q
(A) ≜
Pr
Box,H,A

∀i ∈[k], hi(z||x) ∈{hi(zj||xj)}j∈[r] ∧(x, z) ̸∈{(xj, zj)}j∈[r]

.
We say that hash function family H is an (r, k)-extended target-subset-resilient
hash function family ((r, k)-eTSRH) if Adv(r,k)-eTSR
H,q
(A) is negligible for any prob-
abilistic polynomial-time quantum adversary A.
Here we model H as a quantum-accessible H : {0, 1}m+n →[t]k and h1, ..., hk :
{0, 1}m+n →[t] be the partial oracle. Then, the experiment of eTSR is depicted
as Game 0 in Fig. 3.
Theorem 2. Let H be modeled as a quantum-accessible random oracle H and r
be a positive integer. For any quantum probabilistic polynomial-time adversary
A, it holds that
Adv(r,k)-eTSR
H,q
(A) ≤3r
2

q + r + 1
2n
+ 8(q + r + 2)2
r
t
k
.

Quantum-Access Security of Hash-Based Signature Schemes
361
Game 0
Box(xj)
(x, z) ←A|H⟩,Box ()
zj ←{0, 1}n
if ∀i ∈[k], hi(z||x) ∈{hi(zj||xj)}j∈[r]
return (zj, H(zj||xj))
if (x, z)
{
∉
(xj, zj)}j∈[r] return 1
return 0
Game 1
Box’(xj)
(x, z) ←A|H⟩,Box’ ()
zj ←{0, 1}n
if ∀i ∈[k], hi(z||x) ∈{y(i)
j }j∈[r]
yj := y(1)
j ||...||y(k)
j
←[t]k
if (x, z)
{
∉
(xj, zj)}j∈[r] return 1
H := Hzj||xj→yj
return 0
return (zj, yj)
Fig. 3. Hybrid arguments in the proof of Theorem 2.
Proof. We use the technique in the security proof of (multi-target) extended
collision resistance in [21,27]. We prove this theorem by showing the following
games:
– Game 0 is the original experiment of eTSR.
– Game 1 diﬀers from Game 0 in that Box is replaced by Box’. Every time
A queries xj to the oracle Box’, Box’ randomly picks zj, randomly chooses
y(1)
j , ..., y(k)
j
∈[t] and reprograms hi(zj||xj) := y(i)
j
for each i ∈[k]. (In other
words, it reprograms H(zj||xj) := yj = y(1)
j ||...||y(k)
j
.) Then, it returns (zj, yj)
to the adversary. See details in Fig. 3.
Next, we show that the probabilities of Game 0 and Game 1 are negligible
close by Lemma 4. If not, the adversary A can be used to distinguish Repro0
and Repro1 in Fig. 2. In Game 0, H is simulated by O0 and Box is simulated
by Reprogram0 with additional classical query to O0. In Game 1, Box’ is
simulated by Reprogram1 with additional classical query to O1. In total, it
issues (q + r + 1) queries to Ob (q for simulating H, r for simulating Box/Box’
and 1 for the ﬁnal veriﬁcation). Due to Lemma 4, we have
| Pr[Game 0] −Pr[Game 1]| ≤3r
2

q + r + 1
2n
.
(6)
– In Game 1, the adversary outputs (x, z) such that for all i ∈[k], hi(z||x) is
covered by {y(i)
j }j∈[r]. Deﬁne S = {y(1)
a1 ||...||y(k)
ak }(a1,...,ak)∈[r]k. In other words,
S contains all y = y(1)||...||y(k) where y(i) ∈{y(i)
j }j∈[r] for each i. Thus, the
adversary is to output (x, z) such that H(z||x) ∈S and (x, z) is not equal to
any (xj, zj).
Note that |S| ≤rk. Without loss of generality, we suppose |S| = rk. (If
|S| < rk, the success probability is obviously smaller. Here our purpose is to

362
Q. Yuan et al.
ﬁnd an upper bound of the probability.) Reorder S = {y′
1, ..., y′
rk}.
Next, we use an adversary succeeding in Game 1 to construct a reduction
breaking Avg-Searchλ in Lemma 3.
Let f ←Dλ : {0, 1}m+n →{0, 1} and λ = ( r
t )k. Let I : {0, 1}m+n →[rk] and
g : {0, 1}m+n →[t]k\S be random functions. Construct ˜H : {0, 1}m+n →[t]k
as follows: for any (z||x) ∈{0, 1}m+n, deﬁne:
˜H(z||x) =
⎧
⎪
⎨
⎪
⎩
yj,
x = xj ∧z = zj,
y′
I(z||x),
f(z||x) = 1,
g(x),
otherwise.
Note that the outputs of ˜H distributes uniformly. Thus, an adversary in
Game 2 ﬁnds (x, z) such that f(z||x) = 1. Due to Lemma 3, we have
Pr[Game 1] ≤8(q + r + 1 + 1)2
r
t
k
= 8(q + r + 2)
r
t
k
.
(7)
From Eq. (6) and (7), we complete the proof.
4
Hash-Based Signature Schemes
In this section, we introduce two practical stateless HBS schemes, SPHINCS [7]
and SPHINCS+ [8]. Due to the complicated constructions, we follow the algo-
rithmic descriptions in [16] by treating the building blocks as black boxes. Brieﬂy
speaking, SPHINCS(+) introduces a stateful HBS with hypertrees (denoted by
HT) and a few-time HBS. We ﬁrst introduce the two building blocks and then
the schemes.
4.1
Building Blocks – Few-Time HBS Schemes
In this section, we introduce few-time HBS schemes, which are used as building
blocks in SPHINCS and SPHINCS+.
The ﬁrst is Hash to Obtain Random Subsets (HORS) [31]. The outline of
HORS is as follows. In the key generation algorithm, it picks a one-way function
f : {0, 1}l(n) →{0, 1}n and an (r, k)-subset-resilient function H = (h1, ..., hk) :
{0, 1}m →[t]k. Then, it picks t random strings s1, ..., st from {0, 1}l(n) and
computes yj = f(sj) for each j ∈[t]. Let (s1, ..., st) be the secret key and
(y1, ..., yt) be the public key. In the signing algorithm, it reveals k elements from
{sj}j∈[t] determined by H(m). Due to (r, k)-subset resilience of H, it is hard to
ﬁnd a message m∗such that the secret values in the corresponding signature are
covered by r (classical) queries to the signing oracle. The formal description is
depicted in Fig. 4.
SPHINCS [7] introduces a variant of HORS called HORST (HORS with
trees). HORST compresses the public key with a (bitmarked) hash tree, and
thus the signature needs to contain the corresponding authentication path. This

Quantum-Access Security of Hash-Based Signature Schemes
363
HORS.KeyGen(1λ)
F ←
n, H = (h1, ..., hk) ←
.
for j ∈[t], sj ←{0, 1}l(n), yj = f(sj)
Y = (y1, ..., yt), S = (s1, ..., st)
pk = (Y, f, H), sk = (S, f, H).
return (pk, sk).
HORS.Sig(sk, m)
Parse S = (s1, ..., st) and H = (h1, ..., hk)
for i ∈[k], xi = shi(m).
return σ = (x1, ..., xk).
HORS.Ver(pk, m, σ)
Parse σ = (x1, ..., xk) and H = (h1, ..., hk).
if for i ∈[k], yhi(m) = f(xi) return 1
return 0
Fig. 4. Construction of Hash to Obtain Subsets (HORS).
operation does not hurt the security except that it requires a second-preimage-
resistant hash function.
Furthermore, SPHINCS+ [8] introduces an improvement of HORST, which is
called FORS (Forest of Random Subsets). The main diﬀerences between HORST
and FORS are as follows. First, the key generation algorithm picks kt random
strings from {0, 1}l(n) (rather than t strings) and divides them into k groups of t
strings. In the signing algorithm, instead of revealing k elements from t strings,
FORS reveals one element from each group. Second, FORS uses a tweakable
hash function F instead of the one-way function f, where the tweaks are the
indices of the strings. Third, instead of using bitmarked hash functions in the
hash tree, FORS uses a tweakable hash function Th in generating hash trees,
where the tweaks are the addresses of the nodes. Finally, since there are k hash
trees in FORS, it compresses the k roots by calling Th and denotes the value as
the public key4.
In FORS, the message is not hashed. The signing algorithm directly splits
the message m into k digits with size log t and then proceeds with the following
steps. Thus, the scheme is not EUF-CMA secure. (One can forge a signature on
message m1||m2 given signatures on m1||m∗
2 and m∗
1||m2.) In practice, FORS
has to be used on hashed messages to achieve EUF-CMA. We call FORS with
integrated hashing as simpliﬁed FORS (sFORS).
4 See formal deﬁnitions of tweakable hash functions and hash trees in the full version
[34].

364
Q. Yuan et al.
sFORS.KeyGen(1λ)
H = (h1, ..., hk) ←
for (i, j) ∈[k] × [t], si,j ←{0, 1}l(n), yi,j = F((i, j), si,j)
for i ∈[k], yi ←TreeGen(Th, t, (yi,1, ..., yi,t)).
y0 = Th(0, (y1, ...yk)), S = (s1,1, ..., sk,t)
pk = (y0, H), sk = (S, H).
return (pk, sk).
sFORS.Sig(sk, m)
Parse S = (s1,1, ..., sk,t) and H = (h1, ..., hk)
for i ∈[k], xi = si,hi(m).
for (i, j) ∈[k] × [t], yi,j = F((i, j), si,j).
for i ∈[k], πi ←TreeProv(Th, t, (yi,1, ..., yi,t), hi(m))
return σ = (x1, ..., xk, π1, ..., πk).
sFORS.pkFromSig(m, σ, H)
Parse σ = (x1, ..., xk, π1, ..., πk) and H = (h1, ..., hk).
for i ∈[k], yi ←TreeVer(Th, t, hi(m), F((i, j), xi), πi).
return y′
0 = Th(0, (y1, ..., yk))
sFORS.Ver(pk, m, σ)
Parse pk = (y0, H)
return [[sFORS.pkFromSig(m, σ, H) = y0]]
Fig. 5. Construction of Simpliﬁed FORS.
In SPHINCS+ [8], sFORS is never directly used. In each signing operation,
it introduces a (pseudo-)randomizer z. The message is then hashed with z, and
z is included in the signature. It results in a new scheme that achieves higher bit
security. We call it randomized FORS (rFORS). The formal constructions are
depicted in Fig. 5 and 6.

Quantum-Access Security of Hash-Based Signature Schemes
365
rFORS.KeyGen(1λ)
(pk, sk) ←sFORS.KeyGen(1λ)
k ←{0, 1}n
return (pk, (sk, k)).
rFORS.Sig((sk, k), m)
z = PRF(k, m)
σ ←sFORS.Sig(sk′, z||m)
return (z, σ).
rFORS.pkFromSig(m, (z, σ), H)
return sFORS.pkFromSig(z||m, σ, H)
rFORS.Ver(pk, m, (z, σ))
Parse pk = (y0, H)
return [[rFORS.pkFromSig(m, (z, σ), H) = y0]]
Fig. 6. Construction of Randomized FORS.
4.2
Building Block – HT: The hypertree
HT is another building block in SPHINCS-like structure. It behaves as a stateful
signature scheme, where the signing and veriﬁcation algorithms additionally take
as input a state st ∈ST. Note that the state space is of polynomial size. The
syntax is deﬁned as follows.
Deﬁnition 8. A hyper tree signature scheme HT = (HT.KeyGen, HT.Sign,
HT.Ver) consists of three polynomial-time algorithms along with an associated
message space M = {Mn} and a state space ST such that:
– The key generation algorithm KeyGen takes as input the security parameter
1n. It outputs a pair of keys (pk, sk).
– For security parameter n, the signing algorithm Sign takes as input a secret
key sk, a message m ∈Mn and a state st ∈ST. It outputs a signature σ.
– For security parameter n, the veriﬁcation algorithm Ver takes as input a public
key pk, a message m ∈Mn, a signature σ and a state st ∈ST. It outputs a
bit b.
For any (pk, sk) ←KeyGen(1n), m ∈Mn, st ∈ST and σ ←Sign(sk, m, st),
it holds that Ver(pk, m, σ, st) = 1.
Although SPHINCS and SPHINCS+ use diﬀerent HT, the security notions
for HT are the same and implicitly contained in [7,8]. The security is a stateful
version of existential unforgeability under non-adaptive chosen message attacks.

366
Q. Yuan et al.
We call it existential unforgeability under non-adaptive chosen message attacks
with states (EUF-sNACMA). In detail, the security experiment is deﬁned as
follows.
Experiment ExpEUF-sNACMA
HT,qs,qH
(A = (A1, A2))
(pk, sk) ←KeyGen(1n)
({(mi, sti)}i∈[qs], S) ←A1()
If sti are not distinct, return 0
For i ∈[qs], σi ←Sign(sk, mi, sti)
(m∗, σ∗, st∗) ←A2(pk, S, {σi}i∈[qs])
If st∗= stj for some j ∧m∗̸= mj ∧Ver(pk, m∗, σ∗, st∗) = 1, return 1,
otherwise return 0.
Remark 2. In this paper, we do not depict the detailed construction of HT in
SPHINCS or SPHINCS+, since we always use it as a black box. We only care
about the security.
4.3
SPHINCS and SPHINCS+
SPHINCS and SPHINCS+ are practical stateless HBS schemes built from the
above two blocks. In each signing execution, the signer ﬁrst pseudorandomly
picks a state from ST in HT, which authenticates the public key of the few-
time HBS. A signature contains (1) a few-time signature of the message, (2)
an HT signature of the public key of the corresponding few-time HBS, and (3)
a (pseudo-)randomizer. Note that in SPHINCS and its variants, the few-time
signatures are never explicitly veriﬁed. Instead, it uses pkFromSig to recover the
public key from the message and signature. The security of HT guarantees that
only the real public key can be veriﬁed in the next steps.
In SPHINCS, the few-time signature scheme is HORST (HORS with trees), a
variant of HORS. It compresses the HORS public key by a Merkle tree structure,
and the compressed public key can be generated by an algorithm pkFromSig
from the message and the signature. In this section, we also use HORS.Sig and
HORS.pkFromSig to denote the algorithms of HORS with trees.
The outlines of SPHINCS and SPHINCS+ are depicted in Fig. 7. The main
diﬀerences are the choices of few-time signature schemes and the ways to pick
the index. In particular, the index of SPHINCS+ is calculated by a hash value
of the message and the randomizer. Thus, it is not directly contained in the
signature.
Remark 3. The scheme in Fig. 7 is the deterministic version of SPHINCS+. It
can be converted into a probabilistic version by adding a random salt to the
input of PRFmsg. In this paper, we mainly focus on the deterministic version and
will discuss the probabilistic version in Sect. 6.2.

Quantum-Access Security of Hash-Based Signature Schemes
367
SPHINCS.KeyGen
SPHINCS+.KeyGen
Output
Output
SPHINCS.Sig
SPHINCS+.Sig
return
return
SPHINCS.Ver
SPHINCS+.Ver
return
return
Fig. 7. The framework of SPHINCS and SPHINCS+.
5
Quantum Chosen Message Attacks on SPHINCS(+)
In this section, we propose quantum chosen attacks on SPHINCS(+). The time
complexity (quantiﬁed with the number of signing queries and hash computa-
tions required in the attack) is much lower than the optimal chosen message
attacks.
5.1
Quantum Chosen Message Attacks on SPHINCS
Let qs be the number of signing queries. The optimal attack requires approxi-
mately 2128 hash queries to break the EUF-CMA security of SPHINCS-256 when
qs = 250. Approximately the same number of hash queries are needed to break
the EUF-CMA security of SPHINCS+-256s when qs = 264. Our attack shows
that if the signing oracle is quantum-accessible, the security will be lower.
In SPHINCS, idx = PRFidx(skseed, PRFmsg(skseed, m)). Fix skseed and let
f(m) = PRFidx(skseed, PRFmsg(skseed, m)) be the function mapping m to idx.
Since idx is a part of the signature, f can be computed by querying the signing
oracle. By using Grover’s algorithm, one can search a message m mapping to
any index after O(2h/2) queries to the signing oracle.
Note that any index authenticates a key pair of the few-time signature
scheme. By repeating the above steps r times, one can obtain r message-signature
pairs w.r.t. the same few-time signature key pair. If the secret key of the few-time
signature is used too many times, the security level will be degraded rapidly.
The formal description of the attack on SPHINCS is as follows:

368
Q. Yuan et al.
1. Denote f(m) = PRFidx(skseed, PRFmsg(skseed, m)) be the function that maps
the message m to the index idx ∈{0, 1}h. Randomly pick idx∗∈{0, 1}h, and
denote predicate F(m) = 1 iﬀf(m) = idx∗. Here, f and F are quantum-
computable by querying the signing oracle |SigO⟩since |SigO⟩maps
m, 0h
to |m, f(m)⟩by discarding the signature register except the index part.
2. Run Grover’s algorithm on F(m). It returns a random m such that F(m) = 1.
It implies a HORS signature labeled by idx∗. This requires O(2h/2) quantum
queries to the signing oracle.5
3. Repeat the previous step r times. This requires O(r2h/2) quantum queries to
the signing oracle.6 Let S be the set of labels of which the preimages have
appeared in the HORS signatures. In other words, let m(1), ..., m(r) be the
outputs of the Grover’s algorithm and z(j) be the pseudorandomness z in the
signature of m(j), then S = {hi(z(j)||m(j))}i∈[k],j∈[r].
Note that for each sj, the probability of appearing in a HORS signature is
k/t. The probability of appearing in r random signatures is 1 −(1 −k/t)r.
Thus, the expectation of |S| is
E[|S|] =

1 −

1 −k
t
r
· t ≥(1 −e−kr
t ) · t,
where the inequality comes from (1 −x)α ≤e−αx.
4. Denote function G(z||m) = 1 iﬀ{hi(z||m)}i∈[k] ⊂S. Run Grover’s algorithm
on G. It outputs z∗||m∗whose corresponding preimages have appeared in the
HORS signatures. The expected number of quantum hash queries in this step
is
O
 t
|S|
k
= O((1 −e
kr
t )−k
2 ).
5. Note that the signing oracle has been queried qs = O(r2h/2) times. The
attacker needs to return at least (qs+1) forgeries. Step 4 needs to be repeated
(qs + 1 −r) times. (It is unnecessary to compute σHT for the new forgeries
since all the forgeries share a common σHT.) The total number of hash queries
is
qH = O(qs + 1 −r) · O((1 −e−kr
t )−k
2 ) = O((1 −e−kr
t )−k
2 · r2
h
2 ).
5 In this paper, we always use O(·) to describe the (upper-bound) number of queries
due to the implement of Grover’s algorithm. Note that Grover’s search could fail
in the case that the number of preimages is unknown (we only know the expected
number). It can be solved by repeating it constant times [25]. Since the repetition
only causes (at most) a constant factor on the time complexity, we ignore its eﬀect
and only focus on the complexity related to the parameters of SPHINCS(+) and r.
6 We require the r results be distinct. It can be guaranteed by a simple modiﬁcation.
Let i ∈[r] and f (i)(m) = f(Ci||m), where Ci denotes the binary expression of i.
Deﬁne F (i)(m) = 1 iﬀf (i)(m) = idx∗and run Grover’s algorithm on F (i) for each
i ∈[r] instead. Thus, the results have distinct preﬁx of length ⌈log r⌉.

Quantum-Access Security of Hash-Based Signature Schemes
369
In SPHINCS-256, k = 32, t = 216 and h = 60. When r = 210, qs and qH are
approximately 240 and 261, respectively. When r = 214, qs reaches 243 and qH
decreases to 243 as well. It is much lower than the level of EUF-CMA security,
where qs = 250, and qH is expected to be 2128.
5.2
Quantum Chosen Message Attacks on SPHINCS+
In SPHINCS+, the index is not directly contained in the signature. Instead, the
index is computed by idx = h0(z||m), where z is a (pseudo-)randomizer and
part of the signature. It is not a big issue since we can modify the condition on
Grover’s algorithm to ﬁnd a malicious randomizer z mapping to our malicious
index. In this section, we simply denote by H the hash computation of h0 and
(h1, ..., hk). (In practice, h0 and (h1, ..., hk) are parts of a function H.)
Our attack on SPHINCS+ is as follows:
1. Let z(m) be the function mapping from m to the corresponding z (which can
be evaluated by a signing query). For some idx∗∈{0, 1}h, denote predicate
F(m) = 1 iﬀh0(z(m)||m) = idx∗. Similarly, F is quantum-computable by
querying |SigO⟩and a quantum query to h0.
2. Run Grover’s algorithm on F(m). It outputs a random m such that F(m) = 1.
It implies a sFORS signature labeled by idx∗. This requires O(2h/2) quantum
queries to the signing oracle and O(2h/2) quantum queries to h0.
3. Repeat the previous step r times. This requires O(r2h/2) quantum queries
to the signing oracle. For i ∈[k], let Si be the set of labels of which the
preimages have appeared in the i-th tree of sFORS signatures. In other words,
Si = {hi(z(m(j))||m(j))}j∈[r].
For each si,j, the probability of appearing in an sFORS signature is 1/t. The
probability of appearing in r random signatures is 1 −(1 −1/t)r. Thus, the
expectation of |Si| is
E[|Si|] =

1 −

1 −1
t
r
· t ≥(1 −e−r
t ) · t,
and thus
E

 
i∈[k]
|Si|

≥(1 −e−r
t )k · tk.
4. Denote function G(z||m) = 1 iﬀ∀i ∈[k], hi(z||m) ∈Si∧h0(z||m) = idx∗. Run
Grover’s algorithm on G. It outputs z∗||m∗whose corresponding preimages
have appeared in sFORS signatures. The expected number of quantum hash
queries in this step is
O

2h · tk

i∈[k] |Si|

= O((1 −e−r
t )−k
2 · 2
h
2 ).

370
Q. Yuan et al.
5. The signing oracle has been queried qs = O(r2h/2) times. The forgery needs
to contain at least (qs + 1) forgeries. Step 4 needs to be repeated (qs + 1 −r)
times. The total number of hash queries is
qH = O(r2
h
2 ) + O(qs + 1 −r) · O((1 −e−r
t )−k
2 · 2
h
2 ) = O((1 −e−r
t )−k
2 · r2h).
In SPHINCS+-256s, k = 22, t = 214 and h = 64. When r = 216, qs and
qH are approximately 248 and 280, respectively. It is also lower than the level of
EUF-CMA security, where qs = 264 and qH is expected to be 2128.
Remark 4. In a quantum algorithm, it may be problematic to maintain a quan-
tum state with large quantum memory (especially for HBS schemes due to the
large size of signatures). However, it is not an big issue since our attacks only
need the index idx (or the randomizer z) in the iterations of Grover’s algorithm,
and main parts of the quantum responses can be discarded.
5.3
Attacks in the BU Model
Note that in the above attacks, the adversary has had the ability to forge a
signature for any message before the ﬁnal step. Thus, if we use the BU model
instead, the adversary only need to forge one signature for a message in Bε,n,
and the large number of computations in the ﬁnal step can be saved.
In the following, we omit the parameter n and use Bϵ to denote Bϵ,n. The
strategy of attacking SPHINCS in the BU model is as follows.
1. Denote f(m) = PRFidx(skseed, PRFmsg(skseed, m)) be the function that maps
the message m to the index idx ∈{0, 1}h. For some idx∗∈{0, 1}h, denote
predicate F(m) = 1 iﬀf(m) = idx∗and m /∈Bε. Here, F is quantum-
computable by querying the signing oracle BεSigO.
2. Run Grover’s algorithm on F(m). This requires O

2h
1−ε

queries to BεSigO.
3. Repeat the last step r times and denote S as above. The expectation of |S|
is also (1 −e−kr
t ) · t.
4. Denote predicate F ′(m) = 1 iﬀBεSigO(m) = ⊥. It outputs a message m∗∈
Bε. This requires approximately O(ε−1/2) signing queries.
5. Denote function G(z) = 1 iﬀ{hi(z||m∗)}i∈[k] ⊂S. Run Grover’s algorithm
on G. It outputs z∗such that the preimages corresponding to (z∗, m∗) have
appeared in S. The expected number of quantum hash queries in this step is
also O((1 −e
kr
t )−k
2 ).
Then the adversary successfully generates a forgery σ∗= (idx∗, z∗, σ∗
HT,
σ∗
HORS) for m∗∈Bε, where σ∗
HT is obtained by an additional signing query
and σ∗
HORS is obtained by S.
The total number of required (quantum) queries is respectively
qs = O(r2
h
2 (1 −ε)−1
2 ) + O(ε−1
2 ),
qH = O((1 −e−kr
t )−k
2 ).

Quantum-Access Security of Hash-Based Signature Schemes
371
Note that qs is slightly larger than the original attack (increased by a polynomial
√ε) and qH decreases to 1/r2h/2 of the original one.
The above attack also works on SPHINCS+, but we have another one that
requires less queries. The main idea is similar. First, we ﬁnd a message m∗in
the blind region. Then, to sign a message for m∗, we need an sFORS signature
associated with some index idx∗. Note that the sFORS signature includes k
elements. We directly use Grover’s algorithm to search k messages (outside of
the blind region) that respectively map to the k target elements. It can be done
by quantum signing queries. Finally, the sFORS signature of m∗is covered by
the k signatures, and a forgery is generated. The attack is as follows.
1. Find m∗such that BεSigO(m∗) = ⊥. This requires O(ε−1
2 ) quantum hash
queries to BεSigO.
2. Pick z∗∈{0, 1}n and let idx∗= h0(z∗||m∗). Let function z(m) be the map
from m to the corresponding z. For i ∈[k], denote predicate Fi(m) = 1 iﬀ
(1) z(m) ̸= ⊥, (2) h0(z(m)||m) = idx∗, and (3) hi(z(m)||m) = hi(z∗||m∗). Fi
is quantum-computable by querying BεSigO and a quantum query to h0, hi.
Run Grover’s algorithm on Fi. The expected number of Fi computations is
O(

(1 −ε)−1 · 2h · t).
3. After that, the secret values in sFORS signature on m∗is covered the k
signatures. A forgery is then generated.
In total, the number of required (quantum) queries is respectively
qs = O(k2
h+log t
2
(1 −ε)−1
2 ) + O(ε−1
2 ),
qH = O(k2
h+log t
2
(1 −ε)−1
2 ).
With the parameters in SPHINCS+-256s, qs and qH are both approximately
243, which is lower than our attack in the PO model.
The concrete complexity of our attacks is summarized in Table 1.
6
SPHINCS-FORS: A Provably Secure HBS Scheme
Against Quantum Chosen Message Attacks
In this section, we propose a simple variant of SPHINCS+ with provable security
in the sense of EUF-qCMA.
6.1
Generic Security of Few-Time HBS Schemes
As a preparatory work, we begin with the security of the few-time HBS schemes,
which are used as building blocks in SPHINCS(+). To the best of our knowledge,
no quantum generic security bound is given before this work (even in the sense
of EUF-CMA). We ﬁll the gap with the following theorems.
Theorem 3. Let the hash functions in HORS and sFORS be modeled as quan-
tum random oracles. It holds that
AdvEUF-CMA
HORS,r,q (A) ≤O

q2(r+1)
rk
t
k
+ q2kt
2n

,

372
Q. Yuan et al.
AdvEUF-CMA
sFORS,r,q(A) ≤O

q2(r+1)
r
t
k
+ q2
2n

,
AdvEUF-qCMA
sFORS,r,q (A) ≤O

q2(r+1)
r2
t
k
+ q2ktr
2n

.
Since the EUF-CMA security of HORS (and FORS) is reduced to (restricted)
subset resilience and (variants of) preimage resistance [31,33], the EUF-CMA
security bounds are directly implied from Theorem 1.
We show the proof sketch of the EUF-qCMA security in particular. We
reduce the EUF-qCMA security to weak subset resilience and (variants) of preim-
age resistance, following the idea of the security proof of Lamport’s scheme in
[11]. Assume H is weak subset-resilient and the adversary eventually outputs
forgeries for (distinct) m1, ..., mr+1. There must exists some i∗∈[k] such that
hi∗(m1), ..., hi∗(mr+1) are distinct. As a hybird argument, we measure the values
of hi∗in the signing queries7. After the measurement, the signing oracle will only
return one of the preimages at position i∗in each signing query, but the adver-
sary is required to output one more of them, which can be used to break preimage
resistance. From Lemma 2, each partial measurement only causes security loss of
t, a polynomial number. Since the partial measurements are performed r times,
a constant number, the overall security loss is still polynomial. See details in the
full version [34].
Theorem 4. Let the hash functions in rFORS be modeled as quantum random
oracles. It holds that
AdvEUF-CMA
rFORS,r,q(A) ≤O
 q
2n + q2
r
t
k
+ q2
2n

,
AdvEUF-qCMA
rFORS,r,q (A) ≤O

q2(r+1)
r2
t
k
+ q2ktr
2n

.
The EUF-CMA security can be simply reduced to target subset resilience,
while the EUF-qCMA security is immediately implied from Theorem 3. See
details in the full version [34].
6.2
Discussion: How to Avoid Quantum Attacks?
We then discuss how to construct a many-time signature scheme with provable
security equipped with above few-time HBS schemes.
In the attacks in Sect. 5, the key idea is to search messages that map to a
single index idx∗. The search is done by iteratively running a function F in
Grover’s algorithm. A simple improvement to avoid these attacks is making F
randomized. That is, in each signing operation, the signer adds a random nonce
7 We cannot learn from the ﬁnal forgeries about which i∗should be targeted, since the
measurements should be performed on-line. Instead, we guess it from [k] initially.

Quantum-Access Security of Hash-Based Signature Schemes
373
in calculating the pseudorandomness z = PRFmsg(skseed, m). It is indeed the
probabilistic version of SPHINCS+ [8]. Note that the nonce does not aﬀect the
security reduction of EUF-CMA, but does aﬀect the EUF-qCMA security.
Unfortunately, we cannot give a security proof of EUF-qCMA security for the
above variants, even if the random nonce is well sampled. Note that the security
under quantum chosen message attacks of SPHINCS(+) is more complicated for
the following reasons. First, in the classical setting, a response of the signing
query contains only one few-time signature. Since idx may diﬀer in superpo-
sitions in the quantum-access setting, a quantum SPHINCS(+) signature may
contain many few-time signatures for multiple key pairs. This multi-instance
case exceeds the discussion in Sect. 6.1. Second, a quantum SPHINCS(+) signa-
ture may also contain a large number of HT signatures σHT in superpositions.
It makes the analysis even more complicated.
So how do we construct a provably secure hash-based signature scheme under
qCMAs? Our solution is simple. The ﬁrst step is to make each signing response
only contain few-time signatures related to one key pair. For this purpose, we
make the index of the few-time signature independent to the message. In each
signing query, the signing algorithm randomly picks a leaf from {0, 1}h instead of
running the pseudorandom function on the message. Since the randomness of a
signing query is global, the resulting signatures in superpositions share common
randomness and thus a common idx, implying a common few-time signature
key pair. In addition, note that σHT is the signature on the few-time signature
public key. Since all superpositions share a common public key, the resulting
σHT is also identical in all superpositions. The security is then reduced to the
quantum-access security of the few-time signature scheme in the single-instance
case, which has been evaluated in Sect. 6.1.
This variant can avoid the above attacks since the index is independent of the
message. However, note that the random index needs to be directly contained in
the signature, so an adversary can arbitrarily choose an index in the forgeries.
It causes lower security than SPHINCS+, especially in the EUF-CMA model.
Thus, the classical security also needs re-analyzed.
In the next subsection, we present SPHINCS-FORS, a variant of SPHINCS+
that follows the approach and provides provable EUF-qCMA security.
6.3
SPHINCS-FORS
Construction 1. Let PRFseed : {0, 1}n × {0, 1}h →{0, 1}n be a pseudorandom
function, and rFORS and HT be depicted in the full version [34]. SPHINCS-
FORS is depicted in Fig. 8.
The diﬀerence from SPHINCS+ is as follows:
– The strategies for choosing the index are diﬀerent. In SPHINCS-FORS, the
index is truly random in {0, 1}h while in SPHINCS+ it is pseudorandom
related to m. The random index is directly contained in the resulting signa-
ture.

374
Q. Yuan et al.
SPHINCS-FORS.KeyGen(1λ)
skseed ←{0, 1}n,
(pkHT, skHT) ←HT.KeyGen(1λ)
sk = (skseed, skHT), pk = pkHT
Output (pk, sk).
SPHINCS-FORS.Sig(sk, m)
idx ←{0, 1}h
sidx = PRFseed(skseed, idx)
(pkFORS , skFORS ) ←rFORS.KeyGen(1λ; sidx)
(z, σFORS ) ←rFORS.Sig(skFORS , m)
σHT ←HT.Sig(skHT, pkFORS , idx)
return (idx, z, σHT, σFORS ).
SPHINCS-FORS.Ver(pk, m, (idx, z, σHT, σFORS ))
pkFORS ←rFORS.pkFromSig(m, (z, σFORS ))
return HT.Ver(pkHT, pkFORS , σHT, idx)
Fig. 8. The framework of SPHINCS-FORS
– In SPHINCS-FORS, we use rFORS as the few-time signature. A minor dif-
ference is that in SPHINCS+, the (pseudo-)randomizer z is calculated by a
global function PRFmsg(skseed, m) while in SPHINCS-FORS, skseed diﬀers in
diﬀerent indices.
6.4
Security Analysis
In this subsection, we analyze the security of SPHINCS-FORS under (quantum)
chosen message attacks.
At ﬁrst, we need to evaluate the security for HT. As we use the same HT as
SPHINCS+ and its (EUF-sNACMA) security has been evaluated in [8,25], we
omit the formal analysis of HT. The success probability of breaking the security
is at most O(qH · 2−n/2), where qH denotes the number of hash queries.
For a signature scheme Γ, let InSec∗
Γ,r,qH(ξ) be the maximum of Adv∗
Γ,r,qH(A)
for all ξ-time adversary A and ∗∈{EUF-CMA, EUF-qCMA, EUF-sNACMA}. The
security of SPHINCS-FORS is proven as follows.
Theorem 5. For any ξ-time adversary A, it holds that
Adv∗
SPHINCS-FORS,qs,qH(A) ≤InSecEUF-sNACMA
HT,2h,qH
(ξ) + InSecInd-PRF
PRFseed,2h(ξ)
+
qs

r=0
p(r, qs) · InSec∗
rFORS,r,qH(ξ),
where p(r, qs) = min{2r(log qs−h)+h−log r!, 2h} and ∗∈{EUF-CMA, EUF-qCMA}.

Quantum-Access Security of Hash-Based Signature Schemes
375
Proof. We only show the proof for EUF-qCMA security here. The proof for
EUF-CMA security is very similar and thus omitted.
As mentioned in Sect. 6.2, all the signatures contained in a response from
the signing oracle share a common index and thus a common rFORS key pair.
In each superposition, idx and σHT are identical. The only “quantum part’ of a
response is (z, σFORS), the signature of rFORS. It implies that the EUF-qCMA
security of SPHINCS-FORS is reduced to the EUF-qCMA security of rFORS
and the classical security of HT.
The statement can be proven by the following hybrid arguments.
– Game 0 is the original EUF-qCMA experiment of SPHINCS-FORS.
– Game 1 diﬀers from Game 0 in that, in the signing oracle, sidx is calculated
by TRF(idx) where TRF : {0, 1}h →{0, 1}λ is a truly random function. If the
success probability diﬀers, it implies a reduction distinguishing PRFseed and
TRF. Note that there are at most 2h calls to PRF. We have
| Pr[Game 1] −Pr[Game 0]| ≤InSecInd-PRF
PRFseed,2h(ξ).
– Game 2 diﬀers from Game 1 as follows. After A outputs (qs + 1)
message-signature pairs, check whether there exists a forgery (m∗, Σ∗) =
(m∗, (idx∗, z, σ∗
FORS, σ∗
HT)) such that pk∗
FORS ̸= pkFORS, where pk∗
FORS ←
rFORS.pkFromSig(m∗, (z, σ∗
FORS)),
sidx∗
=
TRF(idx∗)
and
pkFORS
←
rFORS.KeyGen(1n; sidx∗). If so, it returns 0.
Game 2 diﬀers from Game 1 only if the adversary generates a HT signa-
ture for a “fake” pk∗
FORS which is not consistent to the real one. It implies a
reduction attacking the EUF-sNACMA security of HT. At the beginning, the
reduction generates the rFORS public keys w.r.t. all the indices in {0, 1}h and
sends them with the corresponding indices to the challenger. Then, it obtains
the HT signatures and the public key pkHT from the challenger. When sign-
ing a message m from the adversary, it picks a random idx ∈{0, 1}h, gen-
erates the corresponding rFORS signature (z, σFORS). Then, it replies with
(idx, z, σFORS) and the corresponding σHT from the challenger. Finally, the
adversary outputs a pk∗
FORS that is diﬀerent from the real one. It implies a
forgery of HT with state idx∗. We have
Pr[Game 1] ≤Pr[Game 2] + AdvEUF
HT,2h,qH-sNACMA(A).
In Game 2, the adversary wins only if it generates (qs + 1) rFORS forgeries
(of multiple instances) after qs signing queries. Note that in each signing
query, the signing oracle picks one idx ∈{0, 1}h and signs the message by the
rFORS key pair associated with idx. Due to the pigeonhole principle, there
must exist a special idx∗∈{0, 1}h that has been used r times in signing
queries and is used at least (r + 1) times in the forgeries for some r ≥0.
– Game 3 diﬀers from Game 2 in that it guesses idx′ ∈{0, 1}h at the begin-
ning of the experiment and outputs 0 if idx′ ̸= idx∗. We have
Pr[Game 2] ≤2h · Pr[Game 3].

376
Q. Yuan et al.
– In Game 3, A wins if it generates (r + 1) forgeries for the rFORS key pair
associated with idx′ conditioned that it is chosen r times in qs signing queries.
It breaks the EUF-qCMA security of rFORS with r signing queries. In addi-
tion, let Er be the event that a leaf is chosen r times. The probability of Er
is
qs
r

(1 −2−h)qs−r(2−h)r < 2r(log qs−h)−log r!. Thus, we have
Pr[Game 3] =
qs

r=0
Pr[Game 3|Er] · Pr[Er]
≤
qs

r=0
InSecEUF
F ORS,r,qH-qCMA(ξ) · min{2r(log qs−h)−log r!, 1}.
This completes the proof.
From Theorem 4 and 5, we have
Corollary 3. Let the hash functions in SPHINCS-FORS be modeled as quantum
random oracles. It holds that
AdvEUF-qCMA
SPHINCS-FORS,qs,qH (A) ≤O
 qH
2n/2 +
qs

r=0
p(r, qs) · min

q2(r+1)
H
r2
t
k
+q2
Hktr
2n
, 1

,
(8)
AdvEUF-CMA
SPHINCS-FORS,qs,qH(A) ≤O

qs

qH + qs
2n
+ qH
2n/2 + q2
H
qs

r=0
p(r, qs)
r
t
k
.
(9)
Note that here the term caused by adaptive reprogramming is O

qs

qH+qs
2n

rather than qs
r=0 p(r, qs) · 3r
2

qH+r+1
2n
. It is because that the random oracle is
reprogrammed at most qs times in the reduction. For the same reason the terms
caused by SM-TCR, SM-DSPR and Ind-PRF are gathered to O(qH · 2−n/2).
6.5
Concrete Security
As a variant of SPHINCS+, SPHINCS-FORS is expected to reach (at least) the
same security level as SPHINCS+. However, we note that the EUF-CMA security
level of SPHINCS-FORS is lower than SPHINCS+ with the same parameters.
It is because of the diﬀerent strategies of choosing the index. Since the index is
directly contained in the signature (just like what SPHINCS does), the adversary
is able to arbitrarily choose a target index to forge a signature. In the full version
[34], we show a concrete attack on SPHINCS-FORS, implying the diﬀerence in
security levels with SPHINCS+.
Thus, we need to increase some parameters to reach the same level as
SPHINCS+ in the sense of EUF-CMA, and meanwhile provide provable security
in the sense of EUF-qCMA. As a result, the signature size and running time will
become larger.
We give two instances with diﬀerent parameters and security levels. See
details of the parameters in Table 2.

Quantum-Access Security of Hash-Based Signature Schemes
377
– As is observed in Sect. 5.2, (deterministic) SPHINCS+-256s can provide at
most 80-bit quantum-access security when qs = 248. By adapting the param-
eters k, t, and h, we result in SPHINCS-FORS v1 that can provide at least
80-bit security in the sense of provable quantum-access security.
– If we directly increase h in SPHINCS+-256s to 104, say SPHINCS+-256s∗,
it can provide at most 128-bit quantum-access security (due to our attacks)
when qs = 264. On the other hand, by adapting the parameters, we result in
SPHINCS-FORS v2 that can provide at least 128-bit security.
7
Conclusion and Open Questions
This paper analyzes the quantum-access security of HBS schemes in two direc-
tions. First, we show quantum chosen message attacks (or superposition attacks)
on stateless HBS schemes, such as SPHINCS and SPHINCS+. The time complex-
ity of the quantum chosen message attacks is lower than the optimal attacks in
the classical setting. Next, we propose a variant of SPHINCS+ called SPHINCS-
FORS. It is a provably secure HBS scheme against quantum chosen message
attacks. As far as we know, it is the ﬁrst practical HBS scheme with provable
security against quantum chosen message attacks.
Note that our attacks do not work on the probabilistic version of SPHINCS+.
Since there is no security proof, it is an open question whether probabilistic
SPHINCS+ is secure against quantum chosen message attacks. In addition, our
security bound of SPHINCS-FORS against quantum chosen message attacks is
possibly non-tight. It shows a lower bound of the security, but we are not aware
of any concrete attacks that reach this bound. It is also an open question whether
we can get a tighter bound or if there exists a better attack.
Acknowledgement. We would like to thank Tsuyoshi Takagi for valuable sugges-
tions and anonymous reviewers of ACISP 2023 for helpful comments. Quan Yuan is
supported by JST CREST Grant Number JPMJCR2113, Japan.
References
1. Aaronson, S., Shi, Y.: Quantum lower bounds for the collision and the element
distinctness problems. J. ACM 51(4), 595–605 (2004)
2. Alagic, G., Majenz, C., Russell, A., Song, F.: Quantum-access-secure message
authentication via blind-unforgeability. In: Canteaut, A., Ishai, Y. (eds.) EURO-
CRYPT 2020. LNCS, vol. 12107, pp. 788–817. Springer, Cham (2020). https://doi.
org/10.1007/978-3-030-45727-3_27
3. Aumasson, J.-P., et al.: SPHINCS+ - submission to the NIST post-quantum
project, vol. 3 (2020)
4. Aumasson, J.-P., Endignoux, G.: Clarifying the subset-resilience problem. Cryp-
tology ePrint Archive, Report 2017/909 (2017)
5. Aumasson, J.-P., Endignoux, G.: Improving stateless hash-based signatures. In:
Smart, N.P. (ed.) CT-RSA 2018. LNCS, vol. 10808, pp. 219–242. Springer, Cham
(2018). https://doi.org/10.1007/978-3-319-76953-0_12

378
Q. Yuan et al.
6. Bellare, M., Rogaway, P.: Random oracles are practical: a paradigm for designing
eﬃcient protocols. In: Proceedings of the 1st ACM Conference on Computer and
Communications Security, pp. 62–73 (1993)
7. Bernstein, D.J., et al.: SPHINCS: practical stateless hash-based signatures. In:
Oswald, E., Fischlin, M. (eds.) EUROCRYPT 2015. LNCS, vol. 9056, pp. 368–
397. Springer, Heidelberg (2015). https://doi.org/10.1007/978-3-662-46800-5_15
8. Bernstein, D.J., Hülsing, A., Kölbl, S., Niederhagen, R., Rijneveld, J., Schwabe, P.:
The SPHINCS+ signature framework. In: Proceedings of the 2019 ACM SIGSAC
Conference on Computer and Communications Security, pp. 2129–2146. Associa-
tion for Computing Machinery (2019)
9. Boneh, D., Dagdelen, Ö., Fischlin, M., Lehmann, A., Schaﬀner, C., Zhandry, M.:
Random oracles in a quantum world. In: Lee, D.H., Wang, X. (eds.) ASIACRYPT
2011. LNCS, vol. 7073, pp. 41–69. Springer, Heidelberg (2011). https://doi.org/10.
1007/978-3-642-25385-0_3
10. Boneh, D., Zhandry, M.: Quantum-secure message authentication codes. In:
Johansson, T., Nguyen, P.Q. (eds.) EUROCRYPT 2013. LNCS, vol. 7881, pp.
592–608. Springer, Heidelberg (2013). https://doi.org/10.1007/978-3-642-38348-
9_35
11. Boneh, D., Zhandry, M.: Secure signatures and chosen ciphertext security in a
quantum computing world. In: Canetti, R., Garay, J.A. (eds.) CRYPTO 2013.
LNCS, vol. 8043, pp. 361–379. Springer, Heidelberg (2013). https://doi.org/10.
1007/978-3-642-40084-1_21
12. Bonnetain, X., Hosoyamada, A., Naya-Plasencia, M., Sasaki, Yu., Schrottenloher,
A.: Quantum attacks without superposition queries: the oﬄine Simon’s algorithm.
In: Galbraith, S.D., Moriai, S. (eds.) ASIACRYPT 2019. LNCS, vol. 11921, pp.
552–583. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-34578-5_20
13. Bouaziz-Ermann, S., Grilo, A.B., Vergnaud, D.: Quantum security of subset cover
problems. Cryptology ePrint Archive: Report 2022/1714 (2022)
14. Buchmann, J., Dahmen, E., Hülsing, A.: XMSS - a practical forward secure sig-
nature scheme based on minimal security assumptions. In: Yang, B.-Y. (ed.)
PQCrypto 2011. LNCS, vol. 7071, pp. 117–129. Springer, Heidelberg (2011).
https://doi.org/10.1007/978-3-642-25405-5_8
15. Chatterjee, R., Chung, K.M., Liang, X., Malavolta, G.: A note on the post-quantum
security of (ring) signatures. In: Hanaoka, G., Shikata, J., Watanabe, Y. (eds.)
Public-Key Cryptography (PKC 2022). LNCS, vol. 13178, pp. 407–436. Springer,
Cham (2022). https://doi.org/10.1007/978-3-030-97131-1_14
16. Cremers, C., Düzlü, S., Fiedler, R., Fischlin, M., Janson, C.: Buﬃng signature
schemes beyond unforgeability and the case of post-quantum signatures. In: 2021
IEEE Symposium on Security and Privacy (SP), pp. 1696–1714. IEEE (2021)
17. Gagliardoni, T., Hülsing, A., Schaﬀner, C.: Semantic security and indistinguisha-
bility in the quantum world. In: Robshaw, M., Katz, J. (eds.) CRYPTO 2016.
LNCS, vol. 9816, pp. 60–89. Springer, Heidelberg (2016). https://doi.org/10.1007/
978-3-662-53015-3_3
18. Garg, S., Yuen, H., Zhandry, M.: New security notions and feasibility results for
authentication of quantum data. In: Katz, J., Shacham, H. (eds.) CRYPTO 2017.
LNCS, vol. 10402, pp. 342–371. Springer, Cham (2017). https://doi.org/10.1007/
978-3-319-63715-0_12
19. Goldreich, O.: Foundations of Cryptography: Basic Applications, vol. 2. Camp-
bridge University Press, Cambridge, UK (2004)
20. Goldwasser, S., Micali, S., Rivest, R.L.: A digital signature scheme secure against
adaptive chosen-message attacks. SIAM J. Comput. 17(2), 281–308 (1988)

Quantum-Access Security of Hash-Based Signature Schemes
379
21. Grilo, A.B., Hövelmanns, K., Hülsing, A., Majenz, C.: Tight adaptive reprogram-
ming in the QROM. In: Tibouchi, M., Wang, H. (eds.) ASIACRYPT 2021. LNCS,
vol. 13090, pp. 637–667. Springer, Cham (2021). https://doi.org/10.1007/978-3-
030-92062-3_22
22. Grover, L.K.: A fast quantum mechanical algorithm for database search. In: Pro-
ceedings of the Twenty-Eighth Annual ACM Symposium on Theory of Computing,
pp. 212–219 (1996)
23. Hosoyamada, A., Iwata, T.: 4-round Luby-Rackoﬀconstruction is a qPRP. In:
Galbraith, S.D., Moriai, S. (eds.) ASIACRYPT 2019. LNCS, vol. 11921, pp. 145–
174. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-34578-5_6
24. Hosoyamada, A., Sasaki, Yu.: Cryptanalysis against symmetric-key schemes with
online classical queries and oﬄine quantum computations. In: Smart, N.P. (ed.)
CT-RSA 2018. LNCS, vol. 10808, pp. 198–218. Springer, Cham (2018). https://
doi.org/10.1007/978-3-319-76953-0_11
25. Hülsing, A., Kudinov, M.: Recovering the tight security proof of SPHINCS+. In:
Agrawal, S., Lin, D. (eds.) Advances in Cryptology (ASIACRYPT 2022). LNCS,
vol. 13794, pp. 3–33. Springer, Cham (2022). https://doi.org/10.1007/978-3-031-
22972-5_1
26. Hülsing, A., Rijneveld, J., Schwabe, P.: ARMed SPHINCS. In: Cheng, C.-M.,
Chung, K.-M., Persiano, G., Yang, B.-Y. (eds.) PKC 2016. LNCS, vol. 9614, pp.
446–470. Springer, Heidelberg (2016). https://doi.org/10.1007/978-3-662-49384-
7_17
27. Hülsing, A., Rijneveld, J., Song, F.: Mitigating multi-target attacks in hash-based
signatures. In: Cheng, C.-M., Chung, K.-M., Persiano, G., Yang, B.-Y. (eds.) PKC
2016. LNCS, vol. 9614, pp. 387–416. Springer, Heidelberg (2016). https://doi.org/
10.1007/978-3-662-49384-7_15
28. Lamport, L.: Constructing digital signatures from a one way function. Technical
report, Technical Report SRI-CSL-98, SRI International Computer Science Labo-
ratory (1979)
29. Majenz, C., Manfouo, C.M., Ozols, M.: Quantum-access security of the Winternitz
one-time signature scheme. In: 2nd Conference on Information-Theoretic Cryptog-
raphy (ITC 2021), vol. 199, pp. 21:1–21:22. Schloss Dagstuhl - Leibniz-Zentrum
für Informatik (2021)
30. Merkle, R.C.: A certiﬁed digital signature. In: Brassard, G. (ed.) CRYPTO 1989.
LNCS, vol. 435, pp. 218–238. Springer, New York (1990). https://doi.org/10.1007/
0-387-34805-0_21
31. Reyzin, L., Reyzin, N.: Better than BiBa: short one-time signatures with fast sign-
ing and verifying. In: Batten, L., Seberry, J. (eds.) ACISP 2002. LNCS, vol. 2384,
pp. 144–153. Springer, Heidelberg (2002). https://doi.org/10.1007/3-540-45450-
0_11
32. Yamakawa, T., Zhandry, M.: Classical vs quantum random oracles. In: Canteaut,
A., Standaert, F.-X. (eds.) EUROCRYPT 2021. LNCS, vol. 12697, pp. 568–597.
Springer, Cham (2021). https://doi.org/10.1007/978-3-030-77886-6_20
33. Yuan, Q., Tibouchi, M., Abe, M.: On subset-resilient hash function families. Des.
Codes Cryptogr. 90, 719–758 (2022). https://doi.org/10.1007/s10623-022-01008-4
34. Yuan, Q., Tibouchi, M., Abe, M.: Quantum-access security of hash-based signature
schemes. Cryptology ePrint Archive, Report 2023/556 (2022)
35. Zhandry, M.: How to construct quantum random functions. In: 2012 IEEE 53rd
Annual Symposium on Foundations of Computer Science, pp. 679–687 (2012)
36. Zhandry, M.: A note on the quantum collision and set equality problems. Quantum
Inf. Comput. 15(7–8), 557–567 (2015)

380
Q. Yuan et al.
37. Zhandry, M.: How to record quantum queries, and applications to quantum indif-
ferentiability. In: Boldyreva, A., Micciancio, D. (eds.) CRYPTO 2019. LNCS, vol.
11693, pp. 239–268. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-
26951-7_9
38. Zhang, K., Cui, H., Yu, Y.: SPHINCS-α: a compact stateless hash-based signature
scheme. Cryptology ePrint Archive: Report 2022/59 (2022)

Tightly Secure Lattice Identity-Based
Signature in the Quantum Random
Oracle Model
Ernest Foo and Qinyi Li(B)
Griﬃth University, Brisbane, Australia
qinyi.li@griffith.edu.au
Abstract. We present a quantumly secure identity-based signature
scheme based on the standard short integer solution problem, featur-
ing tight security reductions in the quantum and classic random oracle
models. The scheme has short signatures. Each signature contains a sin-
gle lattice vector plus a single bit. Compared to the existing tightly
secure, short lattice identity-based signature schemes by Pan and Wag-
ner (PQCrypto’21), our scheme has a shorter signature size (around 30%
shorter), stronger unforgeability, relies on a weaker assumption, and has
detailed proof in the quantum random oracle model.
Keywords: Identity-based signature · strong unforgeability · lattice ·
quantum random oracle model
1
Introduction
Designing cryptographic schemes often follows a reductionist approach. More
speciﬁcally, a cryptographic scheme is constructed along with a security theo-
rem, stating that in some pre-deﬁned security model, a t-time adversary who
breaks the cryptographic scheme with probability ϵ can be turned into a t′-time
algorithm that solves some computational problem with probability ϵ′ ≥ϵ/θ
with θ ≥1 and t ≈t′. If the problem is believed hard, ϵ′ would be very small
(or negligible in the security parameter in the asymptotic sense), making ϵ small
too. As a result, the cryptographic scheme is unlikely broken. The factor θ mea-
sures the tightness of the reductionist proof. We say a reduction is tight if θ is
a small constant and a cryptographic scheme with a tight security reduction is
tightly secure. Tight security reduction is an attractive feature, with which, the
cryptographic scheme can be implemented with smaller parameters (e.g., key
sizes) to reach the same security level ϵ, leading to better eﬃciency.
Many cryptographic schemes have tight reductions. Among them, only a
few tightly secure cryptographic schemes rely on quantum-immune assumptions,
e.g., computational assumptions from high-dimensional lattices [2–4,6,15,16].
Following the recent works of Pan and Wagner, [15,16], we focus on quantumly
secure identity-based signature (IBS) schemes with short signatures and tight
Authors are ordered alphabetically.
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 381–402, 2023.
https://doi.org/10.1007/978-3-031-35486-1_17

382
E. Foo and Q. Li
security reductions from (believed) quantumly intractable lattice problems. Here
“short signature” means a signature contains a constant number of non-zero
lattice vectors. Under the umbrella of identity-based cryptography [20], IBS eases
the issue of authenticating public keys and may replace PKI systems in small
domains.
An IBS scheme has a master public key Mpk and a master private key Msk.
The scheme allows using an arbitrary string id, called identity, as a user’s public
key. Messages are signed by a private key Skid, extracted using Msk and the iden-
tity id. Verifying the signatures produced by Skid is done publicly using Mpk, id.
The standard security for IBS is existential unforgeability under chosen-identity
and chosen-message attacks. This security notion is deﬁned via a security game.
In the security game, the adversary can make key extraction queries to request
private keys for any identities of its choice. The adversary can also make signing
queries to request signatures on identity/message pairs. Finally, the adversary
breaks the IBS scheme if it comes up with a valid message/signature pair (m∗, σ∗)
under a challenge identity id∗provided the adversary has not obtained Skid∗and
a valid signature on m∗under id∗. To get tight security, a reductionist proof is
required with the following two probabilities are constants close to 1:
1. the probability of successfully replying all key extraction and signing queries.
2. the probability that the adversary’s forgery can be exploited to solve the
underlying computational problem.
While post-quantum IBS schemes can be obtained from diﬀerent approaches
(e.g., via hierarchical identity-based encryption schemes, identiﬁcation schemes,
and generically from normal digital signature schemes), the ones with short
signatures and tight security are rare: the lattice-based IBS schemes by Pan and
Wagner [15,16] are the only schemes proposed to date.
Pan and Wagner obtained their IBS scheme in two steps. First, a weakly
secure lattice IBS scheme is built based on lattice trapdoor delegation tech-
niques [1,5]. The IBS scheme is weakly secure in the sense that the key extrac-
tion queries and signing queries must be committed before seeing the master
public key. Second, two generic transforms are devised that tightly convert the
weakly secure IBS scheme into IBS schemes with standard security. The IBS
schemes by Pan and Wagner [15,16] fall short in several aspects. Firstly, they
lack detailed security proofs in the quantum random oracle model (QROM),
which are desirable for post-quantum cryptographic schemes [3]1. QROM secu-
rity proofs model cryptographic hash functions as truly random functions called
quantum-accessible random oracles. It is assumed that a quantum adversary can
access these random oracles via superpositions and obtains the output quantum
states.
Secondly, the generic transforms devised in [15] add extra overhead to sig-
natures and may complicate security analysis. More speciﬁcally, the standard-
model transform introduced in [15,16] adds two randomnesses of lattice-based
1 The authors sketch a QROM proof. Combined with their standard model transform,
the resulting IBS may be proved tightly secure in the QROM. However, a detailed
QROM proof remains missing.

Tightly Secure Lattice Identity-Based Signature
383
chameleon hashing [5] and two security-parameter-sized pre-images of crypto-
graphic hashing, respectively, to each signature from the weakly secure IBS
scheme. The added overhead, especially the lattice-based chameleon hashing
randomnesses, is certainly not negligible (please refer to Sect. 1.4 for details.).
Meanwhile, the random-oracle-model transform does require extra analysis in
the QROM due to the extra random oracles. No QROM analysis is provided to
the random-oracle-model transform in [15].
We note that Lee et al. [12] show that the generic certiﬁcation approach
gives tightly secure IBS schemes using a digital signature scheme that is tightly
secure in the multi-user setting with adaptive corruption [7]. The only known
such signature scheme, due to Pan and Wagner [17], needs the signature to
contain a public key with size quadratic in the security parameter (see Table 8,
[17]), resulting in IBS scheme no longer having short signatures.
In summary, the current state motivates constructing simple, more eﬃcient,
short post-quantum IBS schemes with tight security reductions in the QROM.
1.1
Our Contributions
We construct a quantumly secure IBS scheme with short signatures and a tight
security reduction, improving the schemes from [15,16]. We give a detailed tight
reductionist proof, which reduces the hardness of the standard short integer
solution (SIS) problem to the strong unforgeability2 of the IBS scheme in the
quantum random oracle model (QROM). QROM security proofs model cryp-
tographic hash functions as truly random functions called quantum-accessible
random oracles. It is assumed that a quantum adversary can access these ran-
dom oracles via superpositions and obtains the output quantum states.
Our IBS scheme is also provably and tightly secure in the classic random
oracle model. The proof is similar to the QROM proof, and we give the proof
sketch in Sect. 5. Like the IBS schemes from [15], our IBS scheme can be adapted
to lattices over polynomial rings with the potential beneﬁt of having shorter key
sizes. This comes from the fact that the integer lattice tools that we use (e.g.,
lattice trapdoor delegation and preimage samplings) are all adaptable to lattices
over polynomial rings [13].
1.2
Our Techniques
We give an overview of the tightly secure lattice-based IBS scheme by Pan and
Wagner [15,16], referred to as the PW scheme. The PW scheme is constructed
in two steps. A weakly and tightly secure IBS scheme is constructed ﬁrst. In the
security proof of the scheme, the adversary has to announce its key extraction
queries and signing queries before seeing the public key. The master public key of
the scheme contains a matrix A ∈Zn×m
q
and two hash functions H1 : {0, 1}∗→
2 Strong unforgeability stipulates that even with a signature of the message, the adver-
sary still cannot derive a new signature on that message. Unforgeability prevents the
adversary from producing a new message and its valid signature.

384
E. Foo and Q. Li
Zn×m
q
and H2 : {0, 1}∗→Zn×m
q
modelled as random oracles. The master private
key is a trapdoor matrix R that eﬃciently solves the SIS problem deﬁned by A.
A private key for identity id is a short lattice basis Tid for the matrix [A|H(id)],
obtained by the master secret key R via lattice trapdoor delegation [1,5,13]. To
sign a message m with identity id, a short Gaussian vector d is computed using
Tid such that [A|H1(id)|H2(id, m)]d = 0. In the security proof, the random
oracles H1 and H2 are programmed using the adversary’s committed queries,
ensuring all queries can be answered without failure, making the proof tight.
Second, two generic transforms are designed to tightly lift the weakly secure
scheme into fully secure IBS schemes.
Our scheme achieves tight security very diﬀerently. We use the Katz-Wang
random-bit technique [10] and the properties of preimage-samplable functions
(PSF) [6]. The master public key contains a matrix A and two hash functions
H1 : {0, 1}∗→Zn×m
q
and H2 : {0, 1}∗→Zn
q , which are modelled as (quantum)
random oracles. Given an identity id, a random bit b ∈{0, 1} is selected. The
identity key Skid := (Rid||b, b) where Rid||b is a lattice trapdoor for the matrix
[A|H1(id||b)] and ’||’ denotes string concatenation. A signature on the identity
id and message m is σ := (d, b) where d is a short Gaussian vector d such that
[A|H1(id||b)]d = H2(id||m), and b is the bit value attached to the private key
Skid. Here d is produced via preimage sampling [1,6,13]. We stress that in the
real scheme, both keys Skid := (Rid||b, b) and Skid := (Rid||1−b, 1 −b) can be
constructed using Msk, but only one of them is given.
Making the change on H2(id||m) from the PW scheme for our scheme has
positive eﬀects. First, a signature of our scheme contains a vector of a lattice
with a smaller dimension (smaller by n log q). This makes our signature size 25%
to 30% shorter than those from [15]. Second, a shorter signature size allows a
weaker SIS assumption (since the security proof can extract better SIS problem
solutions). Third, it enables stronger unforgeability. We compare our scheme
with the IBS schemes in [15,16] in Sect. 1.4.
Our scheme is not subject to the technical diﬃculty of using the Katz-Wang
random-bit technique for tightly secure IBS mentioned by Pan and Wagner [15].
This is because such a technical diﬃculty stems from using the random-bit tech-
nique to partition both the identity space and the message space. In contrast,
our scheme only partitions the identity space.
1.3
Overview of Our Security Proof
We sketch the security reductionist proof in the ROM to show our ideas. For
simplicity, we assume that identical adversarial queries will receive the same
reply in the security reduction. For example, making a key extraction query on
the identity id twice will receive the same identity key. In our full scheme, we use
the standard technique, i.e., (hash-based) pseudo-random functions, to maintain
such consistency without making the scheme stateful.
The reduction starts with a SIS problem instance deﬁned by a random matrix
A ∈Zn×m
q
and uses A to simulate the public parameters to the hypothetical IBS
adversary. For each identity id, the reduction selects a random bit μ ∈{0, 1}.

Tightly Secure Lattice Identity-Based Signature
385
The random oracle query id||b to H1 is answered by programming H1(id||b) in a
way that H1(id||b) is uniformly random, and [A|H(id||b)] has a lattice trapdoor
if b = μ but has no lattice trapdoors if b = 1 −μ.
Given a key extraction query on the identity id, the reduction programs the
random oracle output H1(id||μ) and uses the trapdoor to get the identity key
Skid||μ. It is crucial that μ looks random to the adversary given Skid||μ. Note,
the reduction cannot produce the other key Skid||1−μ. Only one of the two keys
is given in the real scheme. To answer a signing query on message m identity
id, the reduction returns a stored signature if it already exists. Otherwise, the
reduction programs H2(id||m) as follows.
1. Select a random bit b and get H1(id||b) by calling the random oracle H1.
2. Sample a Gaussian vector d, program H2(id||m) as [A|H1(id||b)]d, and return
(d, b) as the signature.
We do the same to answer the random oracle queries to H2. Given a query id||m
to H2, the above steps are performed to program H2(id||m) and then store the
signature for future queries. Applying the regularity argument from [6], H2(id||m)
is distributed statistically close to the uniform distribution over Zn
q . The signa-
ture is distributed as if it was generated correctly using one of the (unknown)
identity keys, either Skid = (Rid||μ, μ) or Skid = (Rid||1−μ, 1 −μ), as required.
Thus, security reduction can always answer signing queries.
Finally, the security reduction exploits the adversary’s forged signature, e.g.,
σ∗= (d∗, δ∗), on the identity id∗and message m∗where d∗is of low-norm and
[A|H1(id||δ∗)]d∗= H2(id∗||m∗). We assume a query H2(id∗||m∗) is made before
the forgery is produced (without querying H2(id∗||m∗), σ∗will be valid with
negligible probability). Recall that id∗is associated with a random value μ∗, the
reduction can produce the identity key for id∗and δ∗when δ∗= μ∗, and can
use the forgery when δ∗= 1 −μ∗. To exploit such a forgery, we need:
1. The internal states used to program H2(id∗||m∗), i.e., the value b∗, d such
that [A|H1(id∗||b∗)]d →H2(id∗||m∗).
2. The internal states used to simulate H1(id||b∗).
3. Crucially, μ∗and δ∗that satisfy b∗= 1 −μ∗and δ∗= 1 −μ∗.
We argue that identity-associated bit μ∗remains from the adversary’s view.
First, the adversary cannot make a key extraction query on id∗. So, it cannot
obtain μ∗from Skid∗. Moreover, μ∗is not leaked via the signing queries since
(id∗, m∗) is not allowed to ask for a signature. And, according to the reduction,
the signing query on (id∗, m ̸= m∗) only gets a random b∗from the signature,
which is independent of μ∗. Meanwhile, μ∗is not used anywhere else in the
reduction. Thus, the conditions b∗= 1 −μ∗and δ∗= 1 −μ∗are met with a
probability of 1/4. So, the reduction solves the SIS problem with a probability
close to ϵ/4, making the reduction tight.
To prove the security in the QROM, we follow the works by Boneh et al. [3]
and Katsumata et al. [9]. We carefully maintain the internal states to make the
proof historic-free, meaning that the random oracle query responses are made
without looking up previously generated values and states.

386
E. Foo and Q. Li
1.4
Comparison
We compare our scheme with the only known tightly secure and short lattice IBS
schemes by Pan and Wagner [15,16] in Table 1. The IBS schemes from [15] are
constructed by applying the two generic transforms to the weakly secure PW
IBS scheme. The ﬁrst transform does not require random oracles. It uses the
lattice chameleon hash function [5]. The second one is in the ROM. We denote
the IBS schemes obtained via the ﬁrst and second transforms by PW’21-I and
PW’21-II, respectively. The comparison shows that our IBS scheme outperforms
essentially in all aspects, including relying on a weaker SIS assumption, enjoying
shorter key and signature sizes, and achieving stronger unforgeability.
Table 1. Comparison among tightly secure and short IBS schemes from latices
Schemes
SIS param. β |Mpk|
|Signature|
Strongly
Unforgeable
Proof in
QROM
PW’21-I [15]
˜
O(n2.5)
(2nm + 2λ) × VZq 3 × VZm + 2 × VZw NO
YES
PW’21-II [16]
˜
O(n2.5)
nm × VZq
2 × VZm+w + 4λ
NO
NO
This work
˜
O(n1.5)
nm × VZq
1 × VZm+w + 1 bit
YES
YES
Let λ be the security parameter. The parameters n, m, q, w := n⌈log q⌉are
standard in the context of lattice-based cryptography [13]. The three schemes in
Table 1 are set with the same n, m, q. The parameter β represents the strength of
the underlying SIS problem. The larger β becomes, the easier the SIS problem
becomes; hence, the less secure the scheme becomes.3 The ˜O notation hides
the logarithmic factors. Table 1 shows that our scheme uses a more diﬁcult SIS
problem, which is equivalent to saying that our scheme relies on a weaker SIS
assumption.
We remark that the sizes of the master private key Msk and the identity
key Skid of the schemes are respectively dominated by the size of the lattice
trapdoor matrices in Zm×w and ∈Z(m+w)×w. In addition, our scheme’s mas-
ter private and private identity keys, respectively contain two and one double-
security-parameter-sized random binary strings. Since we are working on the
(quantum) random oracle model, these random strings can be eﬃciently and
deterministically generated by hash-based pseudorandom functions (see Lemma
2) using Msk and Skid and barely aﬀect the tightness of the reductions. There-
fore, the schemes have essentially the same sizes in master private and identity
keys.
The size of the master public key and signature are denoted by |Mpk| and
|Signature|, respectively. VZq and VZℓrepresent the size of a Zq-vector and a
Zℓ-vector, respectively.4 The quantity 2λ × VZq appeared under |Mpk| is from
3 The parameter β for PW’21-I and PW’21-II are from Sect. 4, [15].
4 For the IBS schemes, the eﬀect of the Gaussian variances of signatures on signature
size is rather limited as the distributions are centred at zero.

Tightly Secure Lattice Identity-Based Signature
387
the lattice-based chameleon hash function [5] used by the transform for PW’21-
I. For a message m ∈{0, 1}ℓand a randomness r ∈Zm, The chameleon hash
function is deﬁned as CHF(m; r) := Br+Cm where B ∈Zn×m
q
and C ∈Zn×ℓ
q
.
The chameleon hash function takes at least 2λ-bit inputs for λ-bit security due
to the quantum algorithm Grover’s search [8]. So, we set ℓ= 2λ. The signature
of PW’21-II has two random strings that are input to the random oracles. To
ensure λ-bit security, the strings are at least 2λ bits long due to Grover’s search.
PW’21-I and PW’21-II are not strongly unforgeable as multiplying a sig-
nature vector by a small constant, say 2, will likely result in a valid signature
vector. Finally, after the publication of [16] was updated with a sketched security
proof of PW’21-I in the QROM. No QROM proof is given to PW’21-II.
2
Preliminaries
We denote the security parameter by λ. poly(λ) represents any polynomial in
λ. We denote by negl(n) any negligible function in n. We use the standard
asymptotic notations O(·), ω(·), and Ω(·). We use bold lowercase letters (e.g. a)
to denote vectors and bold capital letters (e.g. A) to denote matrices. For an
integer q ≥2, let Zq be the ring of integers modulo q. We denote by [A|B] the
concatenation of A and B. We denote by ∥x∥the ℓ2 norm of a vector x. s1(X)
denotes the spectrum norm of the matrix R, i.e., s1(R) = max∥u∥=1 ∥Xu∥.
If X is some distribution, we denote by x ←X a sample x drawn according
to the distribution X. We denote by x ←U(X) drawing a sample x uniformly at
random from a ﬁnite set X. Let X and Y be two random variables taking values
in some ﬁnite set S. We say random variables (or distributions) are statistically
close or negl(λ)-close if their statistical distance, Δ(X, Y ) := 1
2

s∈S | Pr[X =
s] −Pr[Y = s]| is negligible in the security parameter λ.
2.1
Quantum Computation
We follow a series of existing works [3,9,11,19] about cryptography in QROM to
give a brief overview of quantum computation. A n qubits state |ψ⟩is expressed
as 
x∈{0,1}n αx|x⟩∈C2n where {αx}x∈{0,1}n satisﬁes 
x∈{0,1}n |αx|2 = 1 is a
set of complex numbers. {|x⟩}x∈{0,1}n is called an orthonormal computational
basis. An n-qubit state |ψ⟩can be measured using the computational basis, The
measurement results in a classic bit string x ∈{0, 1}n with probability |αx|2
and after the measurement, the state becomes |x⟩. An evolution of quantum
state can be described by a unitary matrix U, which transforms |x⟩to U|x⟩.
A quantum algorithm is composed of quantum evolutions described by unitary
matrices and measurements. Given any classicly computatble function f, there
exists an unitary matrix Uf such that Uf|x, y⟩= |x, f(x) ⊕y⟩. The running
time of a quantum algorithm A is deﬁned as the number of universal gates and
measurements required for running A.

388
E. Foo and Q. Li
The quantum random oracle model (QROM) is an idealised model in which
a cryptographic hash function is modelled as a truly random function that can
be accessed publicly and quantumly. In the security proof in the QROM, a ran-
dom function H : X →Y is selected uniformly at random at the beginning of
the security experiment (or security games). Every entity involved in the exper-
iment is given access to an oracle, which given a state 
x,y αx,y|x, y⟩returns

x,y αx,y|x, H(x) ⊕y⟩. In the QROM, one query to the oracle is counted as
one unit of time. As mentioned in [9], one random function H can be used to
implement n random functions for n quantum (and classical) random oracles: for
integer 0 ≤i ≤n −1, the i-th random function is deﬁned as Hi(x) := H(i||x).
We need the following two lemmas due to Boneh et al. [3] and Saito et al. [19].
Lemma 1. Let ϵ > 0. Say A is a quantum algorithm that makes Q quantum
oracle queries. Suppose that we draw the oracle O from two distributions. The
ﬁrst is the random oracle distribution. The second is the distribution of oracles
where the value of the oracle at each input x is identically and independently
distributed by some distribution D whose statistical distance is within ϵ from
uniform. Then the statistical distance between the distributions of outputs of A
with each oracle is at most 4Q2√ϵ.
Lemma 2. Let λ be the security parameter. Let ℓbe a positive integer. Let
H : {0, 1}ℓ× X →Y and H′ : X →Y be two independent random oracles. If an
unbounded time adversary A who is given quantum access to H and H′ makes
at most QH queries to to H, then for k ←U({0, 1})ℓwe have
Pr[A|H⟩,|H(k,·)⟩(1λ) = 1] −Pr[A|H⟩,|H′⟩(1λ) = 1]
 ≤2QH · 2−ℓ/2
According to Saito et al., [19], the above lemma also applies to the ROM, i.e.,
H and H′ are classic random oracles.
2.2
Lattices and Discrete Gaussians
Deﬁnition 1. For a positive integer q (later to be prime), a matrix A ∈Zn×m
q
,
deﬁne
Λ⊥
q (A) := {y ∈Zm s.t. Ay = 0
(mod q)}
as the m-dimensional full-rank integer lattices and
Λu
q (A) := {e ∈Zm : Ae = u
(mod q)}
for u ∈Zn
q as the shift of Λ⊥
q (A).
Deﬁnition 2. Let m ∈Z be a positive integer and Λ ⊆Zm. For any real vector
c ∈Rm and positive parameter σ ∈R, ∀y ∈Λ, the discrete Gaussian distribution
over Λ with centre 0 and parameter σ is deﬁned by DΛ,σ = ρσ(y)
ρσ(Λ) where ρσ(x) =
exp

−π∥x∥2/σ2
is the Gaussian function and ρσ(Λ) = 
x∈Λ ρσ(x).

Tightly Secure Lattice Identity-Based Signature
389
Lemma 3. (Special case of Lemma 2.9, [13]). Let n, m be positive integers,
and R ←Dn×m
Z,s
. There is a constant C ≈1/
√
2π such that for any t ≥0,
s1(R) ≤C · s · (√n + √m + t) except with probability at most 2 exp(−πt2).
Lemma 4. (Lemma 4.4 of [14]). For any lattice Λ ⊆Zn, and reals 0 < ϵ < 1,
r ≥ω(√log n), we have Prx∼DΛ,r,c [∥x∥> r√n] ≤1+ϵ
1−ϵ · 2−n.
Lemma 5. For any n-dimensional lattice Λ ⊆Zn, positive ϵ < 1/3, and s ≥
ω(√log n), and for every x ∈Λ, the min-entropy H∞(DΛ,s) ≥n −1.
2.3
Lattice Trapdoors
Let k = ⌈log q⌉, g⊺= (1, 2, 4, . . . , 2k−1). Deﬁne the n-by-nk gadget matrix as
G = [g⊺⊗In] =
⎡
⎢⎢⎢⎣
g⊺
g⊺
...
g⊺
⎤
⎥⎥⎥⎦∈Zn×nk
q
.
We recall the several lemmas that relates to the lattice trapdoor techniques. The
lemma is a direct implication of Theorem 4.1.
Lemma 6. There is a p.p.t algorithm SampleR(m, k, s) that takes as input s ≥
(√log n), and samples from a distribution statistically close to Dk
Zm,s.
Let n, m, q, k be positive integers, where m ≥2n log q + ω(√log n). Let
w = ⌈n log q⌉, r = ω(√log n). The ﬁrst lemmas below are from Algorithm 1,
Algorithm 3, and Algorithm 4 of [13]. The last lemma is from Proposition 5.1,
[6].
Lemma 7. There is a p.p.t algorithm TrapGen(1n, 1m, q) returns a matrix A =
[ ¯A| ¯AR + HG] ∈Zn×m
q
for ¯A ∈Zn×(m−w)
q
and invertible H ∈Zn×n
q
such that
A’s distribution is statistically close to U(Zn×m
q
) and the matrix R’s distribution
is statistically close to D(m−w)×w
Z,r
. R is called a G-trapdoor of A.
Lemma 8. There is a p.p.t algorithm SampleD(A, R, U, s) takes as input a
Zn×m
q
-matrix A along with its G-trapdoor R, a vector U ∈Zn×k
q
and s ≥
ω(√log n) · s1(R), and returns a vector d ∈Zm which has a distribution statis-
tically close to Dk
Zm,r conditioned on Ad = U (mod q), i.e., DΛU
q (A),s.
Lemma 9. There is a p.p.t algorithm DelTrap(A, R, A′, H, s′) takes as input
a Zn×m
q
-matrix A, a G-trapdoor R of A, a Zn×w
q
-matrix A′, and a Gaussian
parameter s′ where s′ ≥ω(√log n) · s1(R), and outputs a matrix R′ whose
distribution is statistically close to Dw
Zm,s′ conditioned on A′ = AR′ + HG.
Lemma 10. For A ←U(Zn×m
q
) and e ←DZm,s with any s ≥ω(√log n), the
distribution of Ae mod q is statistically close to U(Zn
q ). Furthermore, for a ﬁxed
u ∈Zn
q , the distribution of e ←DZm,s given Ae = u mod q is DΛu
q (A),s.

390
E. Foo and Q. Li
Our construction uses a special cases of Lemma 7 and Lemma 9 by setting the
matrix H ∈Zn×n
q
as the identity matrix, i.e., In. Throughout this paper, we make
the randomness used by the above algorithms explicit when needed and separate
them from the primary inputs by semicolons. For example, SampleR(m, k, s; φ),
SampleD(A, R, U, s; ϕ) and DelTrap(A, R , A′, H,s; ψ), where φ, ϕ, and ψ denote
the randomness used by these algorithms.
2.4
Short Integer Solution (SIS) Problem
Deﬁnition 3. Let λ be the security parameter. The advantage of an algorithm
A that solves the SISn,q,m,β problem, deﬁned as,
AdvSISn,q,m,β
A
(λ) := Pr [A(A, β) →e ̸= 0 : Ae = 0 mod q ∧∥e∥≤β]
where A ←U(Zn×m
q
), We say (t, ϵ)-SISn,q,m,β assumption holds if for all t-time
algorithms A, AdvSISn,q,m,β
A
(λ) ≤ϵ.
Our IBS scheme uses the SISn,q,m,β problem with prime q and β = ˜O(n3/2),
which is far from being reached by the known classic and quantum algorithms.
We refer to Sect. 2.1, [18] for detailed discussions.
2.5
Identity-Based Signatures
Let λ be the security parameter. An identity-based signature (IBS) scheme IBS
consists of four probabilistic polynomial time (p.p.t) algorithms.
– Setup(1λ) returns a master public key Mpk and a master private key Msk.
– Ext(Mpk, Msk, id) generates an identity private key Skid.
– Sig(Mpk, Skid, id, m) returns a signature σ on a message m and identity id.
– Ver(Mpk, id, m, σ) returns 1, indicating the signature σ is valid for the message
m from a signer whose identity is id, or 0, otherwise.
We require for standard correctness, i.e., for all (Mpk, Msk) ←Setup(1λ), Skid ←
Ext(Mpk, Msk, id),
Pr [Ver(Mpk, id, m, Sig(Mpk, Skid, id, m) = 1] ≥1 −negl(λ)
where negl(λ) is negligible in λ.
We recall the strong existential unforgeability under the chosen-identity
attack and the chosen-message attack (SEUF-ID-CMA) for IBS. The notion is
strong in the sense that no adversary can forge a signature on a message-identity
pair from which the adversary has seen valid signatures. A weaker unforgeability
notion (EUF-ID-CMA) as considered in [15] only requires that a forgery cannot
be produced for a message-identity pair that have not been signed.

Tightly Secure Lattice Identity-Based Signature
391
Experiment Expseuf
IBS,A(λ):
1. Lid ←∅, Lσ ←∅
2. (Mpk, Msk) ←Setup(1λ)
3. (id∗, m∗, σ∗) ←AOExt(),OSig(),RO()(Mpk)
4. If id∗∈Lid, return 0
5. If (id∗, m∗, σ∗) ∈Lσ, return 0
6. Return Ver(Mpk, id∗, m∗, σ∗)
Oracle RO():
Quantum or classic random oracle(s)
Oracle OExt(id):
1. Return Skid ←Ext(Mpk, Msk, id)
2. Lid = {id} ∪Lid
Oracle OSig(id, m):
1. Skid ←Ext(Mpk, Msk, id)
2. Return σ ←Sig(Mpk, Skid, id, m)
3. Lσ = {id, m, σ} ∪Lσ
Fig. 1. SEUF-ID-CMA Security Experiment
Deﬁnition 4. Consider the security experiment (game) deﬁned in 1. We say
that an IBS scheme IBS is (t, QExt, QSig, ϵ)-SEUF-ID-CMA secure if for any t-
time adversary A that makes at most QExt (key extraction) queries to the oracle
OExt() and at most QSig (signing) queries to the oracle OSig(), we have
Advseuf
IBS,A(λ) := Pr[Expseuf
IBS,A(λ) = 1] ≤ϵ
where the probability is over the randomness of A and the IBS scheme.
3
Our IBS Scheme
We provide our IBS scheme Σ in Fig. 2. The scheme uses the following global
parameters and cryptographic hash functions:
– Gadget matrix G’s column dimension w := n⌈log q⌉.
– Dimension m ≥2n log q + ω(√log n) for using Lemma 9.
– Gaussian parameter r = ω(√log n) for the algorithm TrapGen.
– Gaussian parameter s = O(√w) · ω(√log n) for algorithm DelTrap.
– Gaussian parameter s′ = O(w) · ω(√log n)2 for algorithm SampleD.
– Identity space {0, 1}ℓid and message space {0, 1}ℓm for ℓid, ℓm.
– ℓs and ℓs′, the randomness bit lengths of DelTrap and SampleD, respectively.
– Cryptographic hash functions modelled as (quantum) random oracles:
• H1 : {0, 1}ℓ× {0, 1}ℓid →{0, 1}, H2 : {0, 1}ℓ× {0, 1}ℓid{0, 1}ℓs,
H3 : {0, 1}ℓ× {0, 1}ℓid+ℓm →{0, 1}ℓs′
• H1 : {0, 1}ℓid+1 →Zn×w
q
, H2 : {0, 1}ℓid+ℓm →Zn
q
In the scheme, each user (with identity id) also chooses and keeps a secret
random string kid ←U({0, 1}ℓ) for signing. H1(k1, ·), H2(k2, ·) and H3(kid, ·) are
used to make the signing and key extraction processes deterministic, i.e., if the
same message and identity are submitted for signing (resp. key extraction), the
same signature (resp. identity key) will be returned.

392
E. Foo and Q. Li
Setup(1λ):
1. (A, R) ←TrapGen(1n, 1m, q)
2. k1, k2 ←U({0, 1} )
3. Return Mpk := A, Msk := {R, k1, k2}
Sig(Mpk, Skid, id, m):
*User id keeps a secret kid ←U({0, 1} )
1. Parse Skid = (Rid||b, b)
2. u ←H2(id||m)
3. Aid||b ←H1(id||b), Fid||b := [A|Aid||b]
4. ϕ ←H3(kid, id||m)
5. d ←SampleD(Fid||b, Rid||b, u, s ; ϕ)
6. Return σ := (σ1, σ2) = (d, b)
Ext(Mpk, Msk, id):
1. b ←H1(k1, id), ψ ←H2(k2, id)
2. Aid||b ←H1(id||b)
3. Rid||b ←DelTrap(A, R, Aid||b, In, s; ψ)
4. Return Skid := (Rid||b, b)
Ver(Mpk, id, σ, m):
1. Parse σ := (d, b)
2. u ←H2(id||m)
3. Return 0 if [A|H1(id||b)]d = u
4. Return 0 if
d > s √m + w
5. Return 1
Fig. 2. The Proposed IBS Scheme
Correctness. We show that Ver(Mpk, id, m, Sig(Mpk, Skid, id, m) = 1 happens with
all but negligible probability. By Lemma 8, Sig(Mpk, Skid, id, m) returns a signa-
ture σ := (d, b) where d distributes statistically close to Dm+w
Z,s′ , conditioned on
[A|H1(id||b)]d = H2(id||m). So, step 3 of the algorithm Ver(Mpk, id, σ, m) returns
0 with negligible probability. Meanwhile, by Lemma 4, ∥d∥≤s′√m + w with
all but negligible probability, which proves that Ver(Mpk, id, σ, m) returns 1, i.e.,
accepts the correctly generated signature, with all but negligible probability.
4
Security Proof in the Quantum Random Oracle Model
Theorem 1. Let H1, H2, H1, H2, H3 be random oracles that may be quantumly
accessible. If (t, ϵ)-SISn,q,m,β assumption holds with β = O(w3/2)·ω(√log n)2, the
IBS scheme Σ is (t′, QExt, QSig, 4ϵ+negl(λ))-SEUF-ID-CMA secure for arbitrary
QExt, QSig, and any t′ ≤t +O(QH1 +QH2)·poly(λ) where QH1 and QH2 are the
number of quantum random oracle queries to
H1⟩and
H2⟩, respectively.
We split our security proof into two steps. First, we devise a stateful version
of our original IBS scheme Σ shown in Fig. 2, denoted by Σ′, which preserves
the security from Σ. Then, we reduce the hardness of SISa,q,n,β problem to the
SEUF-ID-CMA security of the stateful IBS scheme Σ′.
4.1
Security Reduction from IBS Scheme Σ′ to IBS Scheme Σ
The stateful scheme, as described in Fig. 3, removes H1, H2, H3, and uses internal
states to make consistent replies to repeated key extracting and signing queries.
The (pseudo)random values produced by H1, H2, H3 in the original scheme are
instead sampled uniformly at random from the corresponding sets.
Considering the SEUF-ID-CMA security experiment (Fig. 1), it is clear that
in both the original IBS scheme Σ and the stateful IBS scheme Σ′, the same
query id to OExt is responded by the same identity key, and the same query

Tightly Secure Lattice Identity-Based Signature
393
Setup(1λ):
1. (A, R) ←TrapGen(1n, 1m, q)
2. Return Mpk := A, Msk := R
*Each signer initialises sets LSig, LSk ←∅
Sig(Mpk, Skid, m):
1. Return σ if (id, m, σ) ∈LSig
2. Parse Skid = (Rid||b, b)
3. u ←H2(id||m)
4. Aid||b ←H1(id||b), Fid||b := [A|Aid||b]
5. ϕ ←U({0, 1} s )
6. d ←SampleD(Fid||b, Rid||b, u, s ; ϕ)
7. LSig ←{(id, m, σ)} ∪LSig
8. Return σ := (σ1, σ2) := (d, b)
Ext(Mpk, Msk, id):
1. Return Skid if (id, Skid) ∈LSk
2. b ←U({0, 1}), ψ ←U({0, 1} s)
3. Aid||b ←H1(id||b)
4. Rid||b ←DelTrap(A, R, Aid||b, s; ψ)
5. LSk ←{(id, Skid)} ∪LSk
6. Return Skid := (Rid||b, b)
Ver(Mpk, id, σ, m):
1. Parse σ := (d, b)
2. u ←H2(id||m)
3. Return 0 if [A|H1(id||b)]d = u
4. Return 0 if
d
> s √m + w
5. Return 1
Fig. 3. The Stateful IBS Scheme Σ′
(id, m) to OSig is responded with the same signature value σ. Therefore, the
views of the adversary A to Σ and Σ′ are identical except how b ∈{0, 1} and
the randomness for SampleD and DelTrap are generated, i.e., generated using
H1, H2, H3 versus generated uniformly at random. We note that queries to OSig
trigger queries to H1(k1, ·), and queries to OExt trigger queries to H2(k2, ·) and
H3(k3, ·)5. By Lemma 2 and union bound, a simple reduction shows
|Advseuf
Σ,A(λ) −Advseuf
Σ′,A(λ)| ≤2(2QExt + QSig) · 2−ℓ/2
(1)
which is negligible in λ for polynomial ℓ(in λ), QExt and QSig. The reduction
runs in time nearly the same as the run time of the adversary against Σ plus
the time taken to simulate the parameters of Σ, which is polynomial in λ.
4.2
The Security of IBS Scheme Σ′
Proof. Assume there is a t-time SEUF-ID-CMA adversary who makes at
most
QH1
and
QH2
queries,
respectively
to
H1⟩
and
H2⟩
and
has
advantage Advseuf
Σ′,A(λ) in breaking the IBS Scheme Σ′. We use algorithm
SampleR(k1, k2, s; coin) whose output distribution is statistically close to Dk2
Zk1,s.
coin denotes the randomness: when k1 = m, k2 = w, |coin| = ℓc; when
k1 = m + w, k2 = 1, |coin| = ℓc′.
We proceed with a sequence of security games deﬁned in Fig. 4. Three pro-
cedures can describe each security game: Initialisation (deﬁned in Fig. 5), Setup
(deﬁned in Fig. 6), and Ver. Each security game has four oracles: the key extrac-
tion oracle OExt (deﬁned in Fig. 10), the signing oracle OSig (deﬁned in Fig. 9);
and two quantum random oracles
H1⟩,
H2⟩(deﬁned in Fig. 7 and Fig. 8, respec-
tively). Ver is identical to the veriﬁcation algorithm given in Fig. 2 and is kept
the same across all games. The process Initialisation is included in the proof
where random functions are set as random oracles accessed by the participants.
Let Si be the event that the ith security game returns a well-deﬁned value
1. The ﬁrst security game G0 runs the stateful IBS scheme Σ′ according to the
5 The adversary does not have direct oracle access to H1(k1, ·), H2(k2, ·) and H3(k3, ·).

394
E. Foo and Q. Li
Gi for i = 0, 1, ..., 5:
1. Initialising Lid ←∅, Lσ ←∅
2. (Mpk, Msk) ←Setup(1λ)
3. (id∗, m∗, σ∗) ←AOExt,OSig,|H1 ,|H2 (Mpk)
4. If id∗∈Lid, return 0
5. If (id∗, m∗, σ∗) ∈Lσ, return 0
6. Return Ver(Mpk, id∗, m∗, σ∗)
Initialisation:
Initialising quantum random oracle(s);
Procedure Setup(1λ):
As
Oracles H1 ():
Quan
Oracle H2 ():
Quan
Oracle OExt(id):
As
Oracle OSig(id, m):
As
Fig. 4. Security games Gi for proofs in QROM
Initialisation in G0:
1. H1 ←U(
: {0, 1} id+1 →Zn×w
q
)
2. H2 ←U(
: {0, 1} id+ m →Zn
q )
Initialisation in G1:
1. H2 ←U(
: {0, 1} id+ m →Zn
q )
2. H ←U(
: {0, 1} id →{0, 1})
3.
ˆ
H ←U(
: {0, 1} id →{0, 1} c)
Initialisation in Gi for i = 2, 3, 4, 5:
1. H ←U(
: {0, 1} id →{0, 1})
2.
ˆ
H ←U(
: {0, 1} id →{0, 1} c)
3. H
←U(
: {0, 1} id+ m →{0, 1})
4.
˜
H ←U(
: {0, 1} id+ m →{0, 1} c )
Fig. 5. Functions for implementing quantum random oracles in Gi
SEUF-ID-CMA security experiment (Fig. 1). In the QROM, cryptographic hash
functions H1 and H2 are initialised as truly random functions and maintained
by the reduction. By our hypothesis, we have
Advseuf
Σ′,A(λ) := Pr[Expseuf
Σ′,A(λ) = 1] = Pr[S0]
(2)
Game G1 changes how H1 is simulated, as shown in Fig. 5 and Fig. 7. In
particular, in G1 a random function, ˆH is selected to produce the randomness
for the algorithm SampleR. A random function H′ is selected to help simulate
H1. According to the speciﬁcation of H1 for G1 from Fig. 7, we have
H1(id||b) :=

ASampleR(m, w, s; ˆH(id)||b) + G,
if b = H′(id)
ASampleR(m, w, s; ˆH(id)||b),
otherwise
Using Lemma 10 with the facts that matrix A’s column dimension m ≥2n log q+
ω(√log n) and parameter s ≥ω(√log n), ASampleR(m, w, s; ˆH(id)||b), and thus,
H1(id||b) are distributed negl′
1(λ)-close to U(Zn×w
q
). Since H1 is queried QH1
times. Using Lemma 1, we have for some negligible function negl1(λ)
Setup(1λ) in Gi for i = 0, 1, 2, 3, 4:
1. (A, R) ←TrapGen(1n, 1m, q)
2. LSig, LSk ←∅
3. Return Mpk := A, Msk := {R, k1, k2}
Setup(1λ) in G5:
1. A ←U(Zn×m
q
)
2. LSig, LSk ←∅
3. Return Mpk := A, Msk :=
Fig. 6. Setup for the Gi

Tightly Secure Lattice Identity-Based Signature
395
Oracle H1 (·) in G0,:
1. On input superposition
id,b,y αid,b,y id||b, y , return
id,b,y αid,b,y id||b, H1(id||b) ⊕y
Oracle H1 (·) in Gi for i = 1, 2, 3, 4, 5:
Set Rid||b ←SampleR(m, w, s; ˆ
H(id||b))
H1 as:
H1(id||b) :=
ARid||b + G,
if b = H (id)
ARid||b,
otherwise
1. On input superposition
id,b,y, αid,b,y id||b, y , return
id,b,y αid,b,y id||b, H1(id||b) ⊕y
Fig. 7. |H1⟩for game Gi
Oracle H2 (·) in Gi for i = 0, 1:
1. On input superposition
id,m,y αid,m,y id||m, y , return
id,m,y αid,m,y id||m, H2(id||m) ⊕y
Oracle H2 (·) in Gi for i = 2, 3, 4, 5:
Set δ ←H (id||m) and
H2 as:
H2(id||m) := [A|H1(id||δ)]SampleR(m + w, 1, s ; ˜
H(id||m))
1. On input superposition
id,m,y αid,m,y id||m, y , return
id,m,y αid,m,y id||m, H2(id||m) ⊕y
Fig. 8.
H2⟩for game Gi
| Pr[S1] −Pr[S0]| ≤4Q2
H1

negl′
1(λ) ≤negl1(λ)
(3)
G2 changes how H2 is simulated. Two random functions are initialised, as
shown in Fig. 5. H′′ : {0, 1}ℓid+ℓm →{0, 1}) is used to specify the bit value that
appears in the signature of (id, m). ˜H : {0, 1}ℓid+ℓm →{0, 1}ℓc′ maps bit strings
of length ℓid + ℓm into ℓc′-bit randomnesses for SampleR. According to Fig. 8,
H2(id||m) := [A|H1(id||δ)]SampleR(m + w, 1, s′; ˜H(id||m))
where δ ←H′′(id||m). Since H1 is properly simulated (i.e., its output distribution
is statistically close to U(Zn×m
q
)), and SampleR(m+w, 1, s′; ˜H(id||m)) distributes
statistically close to DZm,s′ where s′ ≥ω(√log n), by Lemma 10, H2(id||m) is
distributed negl′
2(λ)-close to U(Zn
q ). Using Lemma 1, for some negligible negl2(λ)
| Pr[S2] −Pr[S1]| ≤4Q2
H2

negl′
2(λ) ≤negl2(λ)
(4)

396
E. Foo and Q. Li
OSig(id, m) in Gi for i = 0, 1, 2:
1. Return σ if (id, m, σ) ∈LSig
2. Skid||b ←OExt(id) := Skid = (Rid||b, b)
3. u ←H2(id||m)
4. Aid||b ←H1(id||b), Fid||b := [A|Aid||b]
5. ϕ ←U({0, 1} s )
6. d ←SampleD(Fid||b, Rid||b, u, s ; ϕ)
7. LSig ←{(id, m, σ)} ∪LSig
8. Return σ := (σ1, σ2) := (d, b)
9. Lσ
(id, m, σ)
Lσ
OSig(id, m) in Gi for i = 3, 4, 5:
1. Return σ if (id, m, σ) ∈LSig
2. δ ←H (id||m)
3. d ←SampleR(m + w, 1, s; ˜
H(id||m))
4. LSig ←{(id, m, σ)} ∪LSig
5. Return σ := (σ1, σ2) = (d, δ)
6. Lσ ←{(id, m, σ)} ∪Lσ
Fig. 9. Oracle OSig() for game Gi
OExt(id) in Gi for i = 0, 1, 2, 3:
1. Return Skid if (id, Skid) ∈LSk
2. b ←U({0, 1}), ψ ←U({0, 1} s)
3. Aid||b ←H1(id||b)
4. Rid||b ←DelTrap(A, R, Aid||b, s; ψ)
5. Return Skid := (Rid||b, b)
6. LSk ←{(id, Skid)} ∪LSk
7. Lid
id
Lid
OExt(id) in G4, G5:
1. Return Skid if (id, Skid) ∈LSk
2. b ←H (id)
3. Rid||b ←SampleR(m, w, s; ˆ
H(id||b)
4. Return Skid := (Rid||b, b)
5. LSk ←{(id, Skid)} ∪LSk
6. Lid ←{id} ∪Lid
Fig. 10. Oracle OExt() for game Gi
G3 changes OSig, as speciﬁed in Fig. 96. Assume the signature of (id, m) is
σ := (d, b). In G2, b is uniformly random. In G3, δ ←H′′(id||m) for random
function H′′. So, b is distributed identically to δ. In G2, according to Lemma 8,
the vector d ←SampleD([A|Aid||b], Rid||b, H2(id||m), s′) has a distribution sta-
tistically close to DZm+w,s′ conditioned on [A|H1(id||b)]d = H2(id||m). In G3,
d ←SampleR(m + w, 1, s; ˜H(id||m)). By Lemma 10, d has a distribution statis-
tically close to DZm+w,s′. Also, H2(id||m) := [A|H1(id||δ)]d where δ is uniformly
random, as b. So, the distribution of (d, b) in G2 and the distribution of (d, δ)
are negligibly close. So, for some negligible negl3(λ)
| Pr[S3] −Pr[S2]| ≤negl3(λ)
(5)
G4 changes how OExt works, as speciﬁed in Fig. 10. Recall that for OExt
in G3, the bit value b is uniformly random. For OExt in G4, b ←H′(id).
Since H′ is truly random and not accessible to the adversary, the distribu-
tions of b in G3, G4 are identical. Moreover, in G3, for ﬁxed Aid||b, Rid||b is
sampled according to DelTrap(A, R, Aid||b, s), i.e., Rid||b has a distribution that
is statistically close to Dw
Zm,s, conditioned on Aid||b = ARid||b + G. As per
Lemma 9, Rid||b has a distribution statistically close to D
Λ
Aid||b−G
q
(A),s. In G4,
Rid||b ←SampleR(m, w, s; ˆH(id||b) which distributes statistically close to Dw
Zm,s.
Meanwhile, according to the simulation of H1, H1(id||b) = H1(id||H′(id)) :=
6 We note that in Fig. 9 the lists LSig and Lσ are identical, both storing signed mes-
sages, the corresponding identities and signatures. LSig is part of the signing algo-
rithm (to make signing stateful), and the security games maintain Lσ.

Tightly Secure Lattice Identity-Based Signature
397
Aid||b = ARid||b + G. As per Lemma 10, the distributions of Rid||b in G3 and G4
are negl4(λ)-close for some negl4(λ).
| Pr[S4] −Pr[S3]| ≤negl4(λ)
(6)
G5 changes how Setup works, as showed by Fig. 6. In particular, the public
matrix A ←U(Zn×m
q
) and Msk is set empty. By Lemma 7, A’s distributions
in G4 and G5 are negl5(λ)-close for some negligible negl5(λ). Note that the
adversary A is not given Msk in G4 and G5, we conclude that
| Pr[S5] −Pr[S4]| ≤negl5(λ)
(7)
We construct an eﬃcient algorithm B that solves the SIS problem. B receives
a random matrix A ∈Zn×m
q
which is a SISn,q,m,β problem instance. B runs
G5 with the adversary A (the algorithm maintains all procedures and random
oracles as per the speciﬁcation of G5). If G5 outputs 0, B aborts. If G5 outputs
1, i.e., the event S5 happens, A must have outputted (id∗, m∗, σ∗) /∈Lσ (i.e.,
σ∗is not produced by OSig(id∗, m∗)) such that Ver(Mpk, id∗, m∗, σ∗) = 1 where
id∗/∈Lid, assume σ∗:= (σ∗
1, σ∗
2) = (d∗∈Zm+w, b∗∈{0, 1}) and d∗=

d∗
1
d∗
2

with
d∗
1 ∈Zm and d∗
2 ∈Zw. B does:
1. Compute μ∗←H′(id∗), δ∗←H′′(id∗||m∗), and abort if b∗̸= 1 −μ∗or
δ∗̸= 1 −μ∗; Otherwise
2. Return e = [Im|R∗](d −d∗) where R∗= SampleR(m, w, s; ˆH(id∗||H′(id∗)))
as the SIS solution.
The following three lemmas demonstrate that with a probability close to 1/4, e
is a valid SIS solution, i.e., Ae = 0, e ̸= 0 and ∥e∥≤β.
Lemma 11. The event b∗= 1 −μ∗= δ∗happens with probability 1/4.
Proof. In G5, the only oracles that may give A the information about H′(id∗) are
H1 and OExt. As shown in the proof of the inequality 3, the output distribution of
H1 is statistically close to U(Zn×w
q
). So, H1 leaks no information about H′(id∗).
Moreover, id∗is not allowed to query OExt as per the SEUF-ID-CMA deﬁnition.
So, μ∗= H′(id∗) remains random from A’s view. Similarly, the only oracles may
leak information about δ∗= H′′(id∗||m∗) are H2 and OSig. However, we have
proved that the output distribution of H2 is statistically close to U(Zn
q ), and
bears no information about H′′(id∗||m∗). Also, (id∗, m∗) is not allowed to query
OSig as per the deﬁnition of SEUF-ID-CMA. Hence, δ∗remains random from
A’s view, and, 1 −b∗= μ∗= 1 −δ∗happens with probability 1/4.
⊓⊔
Lemma 12. Provided the condition b∗= 1 −μ∗= δ∗holds, Ae = 0.
Proof. As the forged signature σ∗= (d∗, b∗) is valid, we must have
[A|H1(id∗||b∗)]d∗= H2(id∗||m∗).

398
E. Foo and Q. Li
According to the simulation of H2 in G5 (i.e., Fig. 8),
[A|H1(id∗||δ∗)]d = H2(id∗||m∗)
where δ∗←H′′(id∗||m∗) and d = SampleR(m + w, 1, s′; ˜H(id∗||m∗)). If b∗=
1 −μ∗= δ∗, according to the simulation of H1 in G5 (i.e., Fig. 7), H1(id∗||b∗) =
H1(id∗||δ∗) = AR∗where R∗= SampleR(m, w, s; ˆH(id∗||1−μ∗)). Consequently,
we obtain [A|AR∗](d −d∗) = 0 and thus Ae = 0.
⊓⊔
Lemma 13. Let e be constructed as above. We have e ̸= 0 and ∥e∥≤β where
β = O(w3/2) · ω(√log n)2 with all but negligible probability.
Proof. To show that ∥e∥≤β, we have
∥e∥≤∥(d1 −d∗
1)∥+ s1(Rid∗||b∗) · ∥d2 −d∗
2∥
≤2s′√m + (C · s(√m + √w)) · 2s′√w
≤O(w3/2) · ω(

log n)2 = β
To show e ̸= 0 w.h.p. Let d =

d1
d2

where d1 ∈Zm, b2 ∈Zw. We consider the
following cases:
– x = d2 −d∗
2 = 0: In this case, y = d1 −d∗
1 ̸= 0. If A has queried (id∗, m∗)
to OSig and received (d, δ∗) = (d, b∗) as the answer (note this is consistent
with the simulation of OSig), we must have d ̸= d∗and thus, e ̸= 0.
– y = d1 −d∗
1 ̸= 0: In this case, y must have a non-zero coordinate. W.l.o.g,
assume last coordinate of y, y is non-zero. Then, e can be written as e =
x + r∗y + v where r∗is the last column of R∗, v ∈Zm depends on R∗’s
remaining columns and y’s remaining coordinates. Note, R∗(also r∗) is not
given to the adversary A. The only information about r∗that A can get
is via H1(id∗||b∗) = AR∗. By Lemma 10, H1(id∗||b∗) is statistically close
to U(Zn×w
q
) w.h.p. So, conditioned on H1(id∗||b∗) = AR∗, r∗is distributed
negligibly close to DZm,s. By Lemma 5, r∗has min-entropy ≥m−1. So, e ̸= 0
with probability 1 −2−(m−1) = 1 −negl′
6(λ) for some negligible negl′
6(λ).
⊓⊔
Let E be the event that the algorithm B solves the SIS problem challenge.
Combining Lemma 12, Lemma 13 and Lemma 11 leads to
Pr[E] = Pr[E|S5] Pr[S5] + Pr[E|¬S5] Pr[¬S5]
≥Pr[E|S5] Pr[S5] = 1
4(1 −negl′
6(λ)) Pr[S5]
= 1
4 Pr[S5] −negl′
6(λ) · Pr[S5]
Note that Pr[E] ≤AdvSISn,q,m,β
A
(λ). Thus,
Pr[S5] ≤4 · AdvSISn,q,m,β
B
(λ) + negl6(λ)
(8)

Tightly Secure Lattice Identity-Based Signature
399
for negligible negl6(λ) = 4 · negl′
6(λ) · Pr[S5]. Putting the inequalities 2, 3, 4, 5,
6, 7, and 8 together, we have
Advseuf
Σ′,A(λ) ≤4 · AdvSISn,q,m,β
B
(λ) + negl′(λ)
where negl′(λ) upper bounds the negligible terms 6
i=1 negli(λ). This concludes
the SEUF-ID-CMA security proof for the scheme Σ′.
⊓⊔
4.3
The Security of IBS Scheme Σ
Proof. Combining the proofs from Sect. 4.1 and Sect. 4.2 results in
Advseuf
Σ,A(λ) ≤2(QExt + QSig) · 2−ℓ/2 + Advseuf
Σ′,A(λ)
≤4 · AdvSISn,q,m,β
B
(λ) + negl(λ)
where the negligible negl(λ) upper bounds negl′(λ)+2(QExt+QSig)·2−ℓ/2. Let the
running time of the attacker A and the time used by simulations in the proofs
be t′ and t. t is bounded by t′ + (QH1 + QH2) · poly(λ) as proof simulations run
A as a subroutine and the extra computations of the simulation can be done in
polynomial time.
⊓⊔
5
Security Proof (Sketch) in the Random Oracle Model
Theorem 2. Let H1, H2, H1, H2, H3 be random oracles. If (t, ϵ)-SISn,q,m,β
assumption holds with β = O(w3/2)ω(√log n)2, the IBS scheme Σ is (t′, QExt,
QSig, 4ϵ + negl(λ))-SEUF-ID-CMA secure for t′ ≤t + O(QH1 + QH2) · poly(λ)
where QH1 and QH2 are the numbers of random oracle queries to
H1⟩and
H2⟩.
Proof (Sketch). The theorem states the security of our IBS scheme in the classic
ROM. We sketch the security proof due to the similarity to the QROM proof.
Similar to the QROM proof, we ﬁrst reduce the SEUF-ID-CMA security of the
IBS scheme Σ (Fig. 2) to the stateful IBS scheme Σ′ deﬁned in Fig. 3. This step
replaces the random oracles H1, H2, H3 by internal states, and uses Lemma 2 to
get inequality 1, showing the security gap between Σ and Σ′ is negligible.
Then, we construct a tight reduction B in Fig. 11 that converts the adversary
A’s advantage agaisnt the stateful IBS scheme Σ′ to its advantage in solving the
SIS problem. On receiving the SIS challenge A ∈Zn×m
q
, B runs the sub-routines
SetupB, SigB, ExtB, and maintains the random oracles H1, H2 to simulate the
IBS scheme Σ′ perfectly. Finally, it uses the sub-routine SolB to extract the SIS
problem solution e. Like the proof in the QROM, the factor 4 in the security
loss comes from requiring the condition μ∗= 1 −b∗= 1 −δ∗holds.
Finally, similar to the QROM proof, the running time of the ﬁrst-step reduc-
tion is nearly the same as the corresponding adversary, and the running time of
the reduction B’s running time t is bounded by t′ + (QH1 + QH2) · poly(λ) where
t′ is the running time against the statful IBS scheme Σ′.
⊓⊔

400
E. Foo and Q. Li
The algorithm B(A):
Input: A ∈Zn×m
q
Goal: Find e = 0 s.t. Ae = 0 mod q,
e
β
1. L1, L2, Lid, Lσ ←∅
2. (Mpk, Msk) ←SetupB(1λ)
3. (id∗, m∗, σ∗) ←AExtB(),SigB(),H1,H2(Mpk, st)
4. If id∗∈Lid or (id∗, m∗, σ∗) ∈Lσ, return ⊥
5. If Ver(Mpk, id∗, m∗, σ∗) = 0, return ⊥
6. Return SolB(id∗, m∗, σ∗)
Sub-routine SetupB(1λ)
1. LSig, LSk ←∅a
2. Return Mpk := A, Msk := ∅
Random oracle H1(id||b)
1. If (id||b, μ, Rid||b, Aid||b) ∈L1, return Aid||b
2. μ ←U({0, 1}), Rid||b, Rid||1−b ←Dm×w
Z,s
3. Aid||μ ←ARid||μ + G, Aid||1−μ ←ARid||1−μ
b
4. L1
←
L1 ∪{(id||b, μ, Rid||b, Aid||b),
(id||1 −
b, μ, Rid||1−b, Aid||1−b)}.
5. Return Aid||b ∈Zm×w
q
a Fig. 11, the lists LSig and Lσ are identical.
LSig is part of the signing algorithm and Lσ
is maintained by the security games.
b G is equipped by Aid||b when μ = b.
Random oracle H2(id||m)
1. If (id||m, b, d, u) ∈L2, return u
2. δ ←U({0, 1}), Aid||δ ←H1(id||δ)
3. d ←Dm+w
Z,s
, u ←[A|Aid||δ]d
4. L2 ←L2 ∪{(id||m, δ, d, u)}
Sub-routine SigB(id, m)
1. Return σ if (id, m, σ) ∈LSig
2. u ←H2(id||m)
3. Identify (id||m, b, d, u) ∈L2
4. LSig ←{(id, m, σ)} ∪LSig
5. Return σ := (d, b)
6. Lσ ←Lσ ∪{(id, m, σ)}
Sub-routine ExtB(id)
1. Return Skid if (id, Skid) ∈LSk
2. b ←U({0, 1})
3. Aid||b ←H1(id||b)
4. Identify (id||μ, μ, Rid||b, Aid||b) ∈L1
5. Return Skid := (Rid||μ, μ)
6. LSk ←{(id, Skid)} ∪LSk
7. Lid ←Lid ∪{id}
Sub-routine SolB(id∗, m∗, σ∗)
1. σ∗:= (d∗, b∗)
2. Identify (id∗||m∗, δ∗, d, u) ∈L2,
(id∗||b∗, μ∗, R∗
id||b, Aid∗||b∗) ∈L1
3. Return ⊥if b∗= μ∗or δ∗= μ∗;
4. Return e ←[Im|R∗
id∗||b∗] · (d −d∗)
Fig. 11. Reduction to SIS in Random Oracle Model
6
Conclusion
We have presented a short lattice IBS scheme. We proved, in detail, that the
scheme is strongly existentially unforgeable under the chosen-identity attack
and the chosen-message attack based on the standard SIS problem with a tight
security reduction in the QROM and ROM. Our scheme outperforms the existing
schemes with shorter signatures and a stronger unforgeability and relying on
weaker SIS assumptions. We leave constructing a short and tightly quantum-
secure IBS scheme in the plain model as a future research question.
References
1. Agrawal, S., Boneh, D., Boyen, X.: Eﬃcient lattice (H)IBE in the standard model.
In: Gilbert, H. (ed.) EUROCRYPT 2010. LNCS, vol. 6110, pp. 553–572. Springer,
Heidelberg (2010). https://doi.org/10.1007/978-3-642-13190-5 28
2. Blazy, O., Kakvi, S.A., Kiltz, E., Pan, J.: Tightly-secure signatures from chameleon
hash functions. In: Katz, J. (ed.) PKC 2015. LNCS, vol. 9020, pp. 256–279.
Springer, Heidelberg (2015). https://doi.org/10.1007/978-3-662-46447-2 12
3. Boneh, D., Dagdelen, ¨O., Fischlin, M., Lehmann, A., Schaﬀner, C., Zhandry, M.:
Random oracles in a quantum world. In: Lee, D.H., Wang, X. (eds.) ASIACRYPT
2011. LNCS, vol. 7073, pp. 41–69. Springer, Heidelberg (2011). https://doi.org/10.
1007/978-3-642-25385-0 3

Tightly Secure Lattice Identity-Based Signature
401
4. Boyen, X., Li, Q.: Towards tightly secure lattice short signature and id-based
encryption. In: Cheon, J.H., Takagi, T. (eds.) ASIACRYPT 2016. LNCS, vol.
10032, pp. 404–434. Springer, Heidelberg (2016). https://doi.org/10.1007/978-3-
662-53890-6 14
5. Cash, D., Hofheinz, D., Kiltz, E., Peikert, C.: Bonsai trees, or how to delegate a
lattice basis. J. Cryptol. 25(4), 601–639 (2012)
6. Gentry, C., Peikert, C., Vaikuntanathan, V.: Trapdoors for hard lattices and new
cryptographic constructions. In: STOC 2008, pp. 197–206 ACM (2008)
7. Gjøsteen, K., Jager, T.: Practical and tightly-secure digital signatures and authen-
ticated key exchange. In: Shacham, H., Boldyreva, A. (eds.) CRYPTO 2018. LNCS,
vol. 10992, pp. 95–125. Springer, Cham (2018). https://doi.org/10.1007/978-3-319-
96881-0 4
8. Grover, L.K.: A fast quantum mechanical algorithm for database search. In: STOC
1996, pp. 212–219, ACM (1996)
9. Katsumata, S., Yamada, S., Yamakawa, T.: Tighter security proofs for GPV-IBE
in the quantum random oracle model. In: Peyrin, T., Galbraith, S. (eds.) ASI-
ACRYPT 2018. LNCS, vol. 11273, pp. 253–282. Springer, Cham (2018). https://
doi.org/10.1007/978-3-030-03329-3 9
10. Katz, J., Wang, N.: Eﬃciency improvements for signature schemes with tight secu-
rity reductions. In: CCS 2003, pp. 155–164, ACM (2003)
11. Kuchta, V., Sakzad, A., Stehl´e, D., Steinfeld, R., Sun, S.-F.: Measure-rewind-
measure: tighter quantum random oracle model proofs for one-way to hiding and
CCA security. In: Canteaut, A., Ishai, Y. (eds.) EUROCRYPT 2020. LNCS, vol.
12107, pp. 703–728. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-
45727-3 24
12. Lee, Y., Park, J.H., Lee, K., Lee, D.H.: Tight security for the generic construction
of identity-based signature (in the multi-instance setting). Theor. Comput. Sci.
847, 122–133 (2020)
13. Micciancio, D., Peikert, C.: Trapdoors for lattices: simpler, tighter, faster, smaller.
In: Pointcheval, D., Johansson, T. (eds.) EUROCRYPT 2012. LNCS, vol. 7237, pp.
700–718. Springer, Heidelberg (2012). https://doi.org/10.1007/978-3-642-29011-
4 41
14. Micciancio, D., Regev, O.: Worst-case to average-case reductions based on Gaussian
measures. SIAM J. Comput. 37(1), 267–302 (2007)
15. Pan, J., Wagner, B.: Short identity-based signatures with tight security from lat-
tices. In: Cheon, J.H., Tillich, J.-P. (eds.) PQCrypto 2021. LNCS, vol. 12841, pp.
360–379. Springer, Cham (2021). https://doi.org/10.1007/978-3-030-81293-5 19
16. Pan, J., Wagner, B.: Short identity-based signatures with tight security from lat-
tices. Cryptology ePrint Archive, Report 2021/970 (2021). https://eprint.iacr.org/
2021/970
17. Pan, J., Wagner, B.: Lattice-based signatures with tight adaptive corruptions and
more. In: Hanaoka, G., Shikata, J., Watanabe, Y. (eds.) Public-Key Cryptography
(PKC 2022). LNCS, vol. 13178, pp. 347–378. Springer, Cham (2022). https://doi.
org/10.1007/978-3-030-97131-1 12
18. Peikert, C.: A decade of lattice cryptography. Found. Trends Theor. Comput. Sci.
10(4), 283–424 (2016)

402
E. Foo and Q. Li
19. Saito, T., Xagawa, K., Yamakawa, T.: Tightly-secure key-encapsulation mechanism
in the quantum random oracle model. In: Nielsen, J.B., Rijmen, V. (eds.) EURO-
CRYPT 2018. LNCS, vol. 10822, pp. 520–551. Springer, Cham (2018). https://doi.
org/10.1007/978-3-319-78372-7 17
20. Shamir, A.: Identity-based cryptosystems and signature schemes. In: Blakley, G.R.,
Chaum, D. (eds.) CRYPTO 1984. LNCS, vol. 196, pp. 47–53. Springer, Heidelberg
(1985). https://doi.org/10.1007/3-540-39568-7 5

Ghidle: Eﬃcient Large-State Block
Ciphers for Post-quantum Security
Motoki Nakahashi1, Rentaro Shiba2(B), Ravi Anand1, Mostaﬁzar Rahman1,
Kosei Sakamoto1, Fukang Liu1, and Takanori Isobe1
1 University of Hyogo, Kobe, Japan
takanori.isobe@ai.u-hyogo.ac.jp
2 Mitsubishi Electric Corporation, Kamakura, Japan
shiba.rentaro@dc.mitsubishielectric.co.jp
Abstract. In this paper we propose a new family of highly eﬃcient
and quantum secure AES-based block cipher dubbed Ghidle, which sup-
ports a key size of 256 bits and a state size of 256 or 512 bits. The
large state size implies a “bigger birthday bound” security when these
are embedded in modes of operation. Ghidle achieves high eﬃciency in
both the encryption and the decryption by taking advantage of three
consecutive executions of AES rounds in AES-NI, while Pholkos, which
is an existing quantum-secure block cipher, is designed to be fast for
only encryption performance due to the limitation of two consecutive
executions of AES rounds. We run benchmarks of Ghidle on x86( 64)
and arm64 environments and compare their performance with Pholkos.
In our performance evaluation on modern x86 processors, the decryp-
tion of Ghidle-512 outperforms that of Pholkos-512 by about 54% while
the encryption performance remains the same. We also evaluate the per-
formance on mobile devices with arm64-based processors and the result
shows that Ghidle-256 outperforms Pholkos-256 by about 32% for decryp-
tion while the encryption remains almost the same. Furthermore, Ghidle-
512 outperforms Pholkos-512 by about 21% and 53% for both encryption
and decryption, respectively.
Keywords: AES-NI · wide-block encryption · post-quantum
cryptography
1
Introduction
1.1
Background
Security Requirements for Block Ciphers. In recent years, a lot of eﬀort has
been devoted to the development and practical applications of quantum com-
puters. Along with this, the impact of quantum computers on the security of
cryptographic primitives is also being studied. Symmetric cryptography is not
as signiﬁcantly aﬀected by quantum computers as asymmetric cryptography, but
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 403–430, 2023.
https://doi.org/10.1007/978-3-031-35486-1_18

404
M. Nakahashi et al.
some quantum algorithms can substantially reduce the complexity of the anal-
ysis. Indeed, the 3GPP standardization organization also recognizes the pos-
sible impacts of quantum computing on symmetric cryptography for 5G and
beyond 5G.
For instance, Grover’s algorithm [22] can be applied to exhaustively search
the k-bit key of symmetric ciphers to quadratically speed up the search com-
plexity from O(2k) to O(2k/2). Doubling the key of existing symmetric ciphers
is a useful heuristic, especially against Grover’s search algorithm, but its practi-
cal impact remains to be understood better. Nevertheless, a key size of at least
256-bit is a minimum requirement for 128-bit security in quantum setting [16].
In addition, block size should also be carefully speciﬁed in order to obtain
eﬀective security against quantum adversaries. Modes of operation or authenti-
cated encryptions based on a n-bit block cipher provide security up to birthday
bound O(2n/2). For block ciphers with smaller state sizes, such as 64 bits, this
might lead to practical attacks. While 128-bit block ciphers will not be aﬀected
as of now, in the future with the increase in computing powers of the adversaries
and the rise of quantum computers, even 128-bit block ciphers might not be safe.
A similar argument has also been presented in [7] and a possible solution put
forward was to design ciphers with at least 256-bit blocks and keys - heavyweight
ciphers - which would then provide a “bigger birthday bound” security. Based
on these facts, we believe block ciphers require a key as well as a state size of at
least 256-bits.
Performance Requirements for Block Ciphers. Furthermore, the block ciphers
that ensure post-quantum security must be designed to be used in the future
when quantum computers become widespread. In such a future, computer hard-
ware will have higher computing speeds and network communication systems like
Beyond 5G/6G will have much lower latency, which may require block ciphers
to have even lower latency than today.
Previous Attempts. As eﬃcient quantum-secure block ciphers, Saturnin [15] and
Pholkos [14] were proposed.
Saturnin is a lightweight block cipher for NIST lightweight cryptography com-
petition. Saturnin is eﬃcient in resource-constrained environments, but it is not
suitable for the software implementation on environments with high-end pro-
cessors such as x86( 64) and arm64 because of the absence of support for the
nibble-wise operations underlying operations of the Saturnin round.
On the other hand, Pholkos [14] is dedicated to high-end processors such as
x86 and arm64. Pholkos uses the AES round function and the SIMD-friendly
shuﬄe operation. In modern x86 processors, the encryption of Pholkos is highly
eﬃcient due to the availability of SIMD and instructions dedicated to AES such
as AES-NI instructions. However, the decryption is not eﬃcient because more
instructions than the encryption is required. Besides, in arm64, the encryption
and the decryption have the same performance but the number of instructions
required to implement both of them increases signiﬁcantly compared to the x86
implementation.

Ghidle: Eﬃcient Large-State Block Ciphers for Post-quantum Security
405
1.2
Motivation
At present, no block cipher has been proposed that satisﬁes the following two
requirements: (1) Quantum security, namely at least 256-bit key and 256-bits
block size. (2) High performance on software for both encryption and decryption
performance. Our aim in this paper is to propose block ciphers that satisfy both
requirements. Pholkos and Saturnin satisfy the ﬁrst requirement, but not the
second.
In [1,31], it is shown that some modes of operation such as CBC and XTS,
and OCB2 authenticated encryption can ensure the IND-qCPA security [12] if
the internal block ciphers are secure against poly-time quantum attacks. Since no
poly-time quantum attack on Pholkos has been proposed and it corresponds to
the “quantum secure PRF” deﬁned in [1,31], it can provide IND-qCPA security
for such modes. However, the decryption of these modes requires the decryption
function of the internal block cipher. Since Pholkos decryption takes about twice
as much time as the encryption, its use in these modes may cause non-negligible
latency in the decryption process. Therefore, proposing a secure block cipher
that is eﬃcient in both the encryption and the decryption is required for using
modes of operation such as CBC and XTS on quantum computers in a secure
and eﬃcient manner.
1.3
Our Contribution
In this study, we design large-state block ciphers called Ghidle for post-quantum
security by inheriting the design principle of Pholkos. Speciﬁcally, in this study,
for designing Ghidle, we explore how to construct AES-based block ciphers that
can provide security and high encryption performance without sacriﬁcing the
decryption performance.
The construction of Ghidle is based on the three consecutive AES rounds
and an involutive binary matrix instead of the two consecutive AES rounds
and a word-wise shuﬄe which are employed in Pholkos and other AES-based
primitives. The constructions of Ghidle ensures that the number of instructions
required for encryption and decryption in x86 is the same, which contributes
to equalizing the performance in both directions. In the security evaluation, we
show that Ghidle is suﬃciently secure against several classical attacks. In addition,
Ghidle has a key size of 256 bits, thereby making it 128-bit secure against key
search using Grover’s algorithm. Moreover, the large state size of 256 or 512 bits
also provides a “bigger birthday bound” security.
Finally, the performance evaluation shows the high eﬃciency of Ghidle. We
experiment with CPUs of Intel’s 10–12 generation in our performance evaluation.
As a result, the decryption of the 512-bit block variant Ghidle-512 outperforms
Pholkos-512 by about 54%, while the encryption performance remains mostly
the same as Pholkos-512. (The 256-bit block variant Ghidle-256 out performs
Pholkosby 33% in decryption performance, but performance, whereas the encryp-
tion performance is worse than Pholkos-256, a 256-bit block variant of Pholkos.)
Furthermore, the AES round functions that compose Ghidle are accounted for the

406
M. Nakahashi et al.
exclusive one for the last round compared to Pholkos. This accelerates the perfor-
mance of Ghidle even in arm64 where two instructions are required to represent
the normal AES round function. Our performance evaluation on mobile devices
with arm64-based processors shows that Ghidle-256 outperforms Pholkos-256 by
about 32% for decryption, while the encryption performance remains mostly the
same as Pholkos-256. And remarkably, Ghidle-512 outperforms Pholkos-512 by
about 21% and 53% for both the encryption and the decryption, respectively.
2
Preliminaries
2.1
AES-NI and SIMD Instructions
Most modern processors support instruction set for SIMD (Single Instruc-
tion/Multiple Data) which can perform operations vector-wise using data stored
in dedicated registers. This allows arithmetic/bitwise operations in parallel and
complicated operations like data shuﬄing to be performed with a single instruc-
tion. One of the most famous complex operations that can be eﬃciently imple-
mented with SIMD instructions is the processing of the most dominant block
cipher AES. An instruction set for eﬃcient AES implementation, AES-NI (AES
New Instructions set) is supported on most modern x86 processors. AES-NI
includes AESENC to perform the round function of the encryption, AESEN-
CLAST for the ﬁnal round, AESDEC to perform the round function of the decryp-
tion, AESIMC to perform the inverse MixColumns, and instructions to support
the round key generation. Let ShiftRows, SubBytes, MixColumns, AddRound-
Key be SR, SB, MC, AKthe operation of four instructions, AESENC, AESDEC,
AESENCLAST and AESDECLAST are expressed as following:
AESENC = AK ◦MC ◦SB ◦SR
(1)
AESENCLAST = AK ◦SB ◦SR
(2)
AESDEC = AK ◦MC−1 ◦SB−1 ◦SR−1
(3)
AESDECLAST = AK ◦SB−1 ◦SR−1
(4)
The performance of these instructions in modern processors has evolved. Speciﬁ-
cally, In Intel 10th generation and later, the latency of AESENC which was previ-
ously 4 is now 3. In addition, since an extra execution port for micro-operations
generated from AESENC has added, the throughput which was previously 1 is
now 0.5. As a result 6 AESENC can be executed at latency 5 by pipelining.
Processors of arm64 also support AES instructions in NEON instruction
set, although its speciﬁcation diﬀers from instructions in AES-NI. There are
four types of AES instructions belonging to NEON: AESE, AESMC, AESD, and
AESIMC. AESE and AESD are basically identical to AESENCLAST and AESDE-
CLAST in AES-NI, respectively, except that AK is executed in the beginning
instead of the end. AESMC and AESIMC are instructions that execute MC and
MC−1, respectively.
In the rest of this paper, the AES instructions introduced in this section refer
to the instructions themselves and the functions that perform the operations
realized by those instructions.

Ghidle: Eﬃcient Large-State Block Ciphers for Post-quantum Security
407
(a) Basic construction of 256-bit
variants
(b) Basic construction of 512-bit variants
Fig. 1. Basic constructions of AES-NI-based primitives with SPN structure
2.2
Large-State Cryptographic Primitives Based on AES-NI
This subsection brieﬂy describes several AES-based primitives that are optimized
for implementation by AES instructions.
SPN Primitives. As AES-based primitives with SPN structure, Pholkos [14],
Haraka v2 [29] and AESQ [11] are proposed. Pholkos [14] is a family of eﬃ-
cient tweakable block ciphers. Pholkos has a key size of 256 bits, a state size of
256/512/1024 bits, and it is designed to have resistance against Grover’s exhaus-
tive search and beyond birthday security. Thus, Pholkos claims 128-bit security
even in the quantum setting. The round function is an instantiation of Fig. 1
which employs the word-wise shuﬄe that can be realized by PBLENDD instruc-
tions on x86. Haraka v2 and AESQ also employ the basic construction shown in
Fig. 1, albeit the word-shuﬄe is diﬀerent for each of them.
Simpira v2. Simpira v2 [23] is a family of Feistel permutations that is proposed
for general-purpose use. Simpira v2 however claims only 128-bit security, even
for variants with state sizes of 256-bits or larger. Besides, in [30] Kuwakado and
Morii have shown that the Even-Mansour construction, underlying construction
of Simpira v2 block cipher is vulnerable to a quantum attack using Simon’s
algorithm.
3
Design Rationale
In this section, we explain our target constructions and their requirements. In
the later part of this paper, the part of the AES-based primitives with SPN
structure that executes AES instructions is denoted as the AES layer, and the
part that executes instructions other than AES instructions is denoted as the
linear layer.
Our target constructions are AES-based permutations with SPN structure
since it generally requires fewer rounds than Feistel structure to provide suﬃcient
security. To ﬁnd constructions where both the encryption and the decryption are
eﬃcient and there is no gap between their performance, we employ the following
two techniques.

408
M. Nakahashi et al.
Fig. 2. The diﬀerence of the number of instructions between the encryption and decryp-
tion
3.1
The AES Layer: Three Consecutive AES Rounds
Problems of Two Consecutive AES Instructions for Decryption. In
the case where the AES layer of the encryption is implemented on x86 with two
consecutive AESENC, one AESDECLAST, one AESIMC and one XOR instruction
are needed to perform the inverse of operations by a single AESENC. Namely, the
implementation of the AES layer which consists of two consecutive AES requires
the execution of a total of six instructions. Figure 2 indicates why the diﬀerence
in the number of instructions arises between the encryption and the decryption.
Although this number can be reduced to ﬁve by incorporating the second MC−1
into the key scheduling function, the number of instructions required for the
decryption is still twice the number of instructions required for the encryption.
Therefore, the performance of decryption which requires more instructions is
lower than the encryption.
Three Consecutive AES Instructions. To keep the performance symme-
try between the encryption and decryption, we propose three consecutive AES
instructions consisting of not only AESENC but also AESENCLAST as the AES
layer, while existing schemes such as Pholkos, Haraka v2, AESQ and Simpira
v2 utilize only AESENC instruction. In particular, we clarify the following four
requirements for the AES layer to minimize the overhead of the decryption.
Requirement 1. AESENC should not be executed twice in consecutive order.
As we mentioned above, the decryption of two consecutive AESENC requires
AESIMC and XOR instructions in addition to AESDEC. This makes the number
of instructions required to implement the decryption more than the encryption.
Requirement 2. The third AES instruction executed in the AES layer is lim-
ited to AESENCLAST and must not be added to the secret key.

Ghidle: Eﬃcient Large-State Block Ciphers for Post-quantum Security
409
The inverse of an AESENC requires an AESDECLAST and a XOR. Also, applying
the secret key to the third AES instruction in the AES layer requires extra XOR
before the ﬁrst AES instruction in the decryption. To avoid using additional
XOR, we have to limit AESENCLAST in the third AES instruction in the AES
layer.
Requirement 3. The round key is not given as the second argument to AES-
ENC.
Adding the round key to AESENC requires AESIMC. Therefore, the round key is
not added in AESENC but only in AESENCLAST.
Requirement 4. At least one AESENC must be used.
AESENC is required to increase the diﬀusion within each 128-bit state. Without
this operation, full diﬀusion is never achieved. Therefore, at least one AESENCis
essential.
Optimal AES Layers. There are only two combinations of three consecu-
tive AES rounds satisfying all requirements described in Sect. 3.1. Let AESENC,
AESENCLAST, AESDEC and AESDECLAST be two-variable functions which take
128-bit data x as the ﬁrst argument and round key k as the second argument.
Using Eqs. (1)–(4), the functions which represent the two combinations can be
expressed as the following two functions: Fγ and Fδ can also be expressed as
Fγ(x, k) = AESENCLAST(AESENCLAST(AESENC(x, 0), k), 0),
Fδ(x, k) = AESENCLAST(AESENC(AESENCLAST(x, k), 0), 0).
And their inverse are
F −1
γ (x, k) = AESDECLAST(AESDEC(AESDECLAST(x, k), 0), 0).
F −1
δ
(x, k) = AESDECLAST(AESDECLAST(AESDEC(x, 0), k), 0),
We employ these two functions: Fγ and Fδ in the round function of new family of
block ciphers Ghidle that we propose in the next section to increase the security
against Yoyo-type attacks (details are discussed in Sect. 5.6).
3.2
Linear Layer: SIMD-Friendly Involutional Matrix
Problems
of
Shuﬄe
Instruction.
Shuﬄe instructions in Haraka v2,
Pholkos and AESQ can perform complex data transfers with a small number
of instructions. For instance, in x86, Haraka v2 , Pholkos and AESQ use PUN-
PCK{L,H}DQ, PBLENDD and PSHUFD, respectively. The shuﬄe layer can be
implemented eﬃciently in environments where these SIMD instructions are avail-
able. In particular, PUNPCK{L,H}DQ and PBLENDD are less ﬂexible in terms
of generality than PSHUFD, which allows users to set the index of the target
permutation, but they can extract speciﬁc elements from two xmm registers and

410
M. Nakahashi et al.
store them in a single xmm register with a latency of only one cycle. This can pro-
vide the implementation of fast shuﬄing operations, but these instructions also
have some drawbacks. Especially, for PUNPCK{L,H}DQ, the instructions for the
inverse operation do not exist in x86. Therefore, this instruction causes an asym-
metry in the number of instructions required for the shuﬄe layer between the
encryption and the decryption, and it is not suitable for the cipher we intended
to design in this study.
For instance, implementing the forward shuﬄe for Haraka v2, which is imple-
mented by PUNPCK{L,H}DQ requires 2 and 8 instructions for Haraka-256 and
Haraka-512, respectively. On the contrary, implementing the reverse shuﬄe
requires 4 PUNPCK{L,H}DQ for Haraka-256 and 8 PUNPCK{L,H}DQ instruc-
tions and 6 PSHUFD for Haraka-512. Note that Haraka v2 was proposed as a
hash function, so it is not discussed by the designers.
On the other hand, PBLENDD of Pholkos does not cause such asymmetry of
the number of instructions. However, the shuﬄe by PBLENDD causes implemen-
tation problems on arm64, the shuﬄe of Pholkos-256 can be implemented with
only two TRN instructions, whereas the shuﬄe of Pholkos-512 shuﬄe requires 10
instructions. Furthermore, the 10 instructions consists of 6 TRN and 4 EXT which
increases the number of cycles for throughput by using two distinct instructions.
Moreover, even in x86 processors, the shuﬄe of Pholkos-512 requires 8 instruc-
tions. This relatively large number of instructions leaves room for improvement.
Involutory Binary Matrix. Instead of the shuﬄe operations, we employ an
involutory binary matrix multiplication for the linear layer. As an involutory
binary matrix, we utilize the one used in a family of lightweight block cipher
Midori [2]. Let (x0, x1, x2, x3)T be the input and (y0, y1, y2, y3)T be the output
(each element is a 128-bit subblock), the matrix multiplication can be expressed
as:
⎛
⎜
⎜
⎝
y0
y1
y2
y3
⎞
⎟
⎟
⎠=
⎛
⎜
⎜
⎝
0 1 1 1
1 0 1 1
1 1 0 1
1 1 1 0
⎞
⎟
⎟
⎠
⎛
⎜
⎜
⎝
x0
x1
x2
x3
⎞
⎟
⎟
⎠.
(5)
The branch number of this matrix is 4. Therefore, at least four of the input and
output subblocks are diﬀerentially active. In 512-bit block ciphers, this operation
can be implemented by 6 XOR instructions while we regard 1 word as a 128-bit
data chunk whereas the shuﬄe operation used in Haraka v2 and Pholkos requires
8 instructions. In addition, this matrix has an involution property, its inverse
operation is the same as the forward.
Even if we apply this matrix to 256-bit block ciphers by regarding 1 word as
a 64-bit data chunk, this matrix can be implemented 4 PUNPCK{L,H}DQ and
3 XOR instructions. Indeed, for 256-bit block ciphers, shuﬄe of Haraka v2 and
Pholkos requires fewer instructions than this binary matrix. However, the binary
matrix can oﬀer higher security than the simple word-wise shuﬄe operations.
Even in the NEON implementation, this matrix for 512-bit block ciphers can

Ghidle: Eﬃcient Large-State Block Ciphers for Post-quantum Security
411
Table 1. Required instructions for shuﬄe of 256-bit block on x86
Haraka v2 shuf.
Pholkos shuf. Matrix (Eq. (5))
Enc. 2 PUNPCK{L,H}DQ 2 PBLENDD
4 PUNPCK{L,H}DQ+ 3 XOR
Dec
4 PUNPCK{L,H}DQ
Table 2. Required instructions for shuﬄe of 512-bit block on x86
Haraka v2 shuf.
Pholkos shuf. Matrix (Eq. (5))
Enc. 8 PUNPCK{L,H}DQ
8 PBLENDD
6 XOR
Dec
8 PUNPCK{L,H}DQ+ 6 PSHUFD
be implemented using only 6 XOR instructions. For 256-bit block ciphers, this
matrix can be implemented with 2 EXT instructions and 3 XOR instructions.
Table 1 and Table 2 summarize the required instructions for shuﬄe and binary
matrix of 256-bit block ciphers and 512-bit block cipher, respectively. We also
give a summary of the required instructions on arm64 in Table 3.
4
Ghidle: New AES-NI-Based Block Ciphers
4.1
Speciﬁcation
Ghidle is a block cipher family consisting of Ghidle-256 with the block size of 256
bits and Ghidle-512 with the block size of 512 bits. Both variants use a 256-bit
secret key. The round function and the key scheduling function are shown in
Fig. 3 and pseudo codes are shown in Algorithm 1. The round function iterates
between 1 ≤r ≤R, while The key scheduling function iterates between 0 ≤
r ≤R for generating keys for whitening in addition to round keys. Let the
round key of the r-th round be kr. Note that the value of kr is kr = kr
0||kr
1
for Ghidle-256 and kr = kr
0||kr
1||kr
2|||kr
3 for Ghidle-512. For the whitening, k0 is
XORed to the plaintext x0 to generate the initial state x1, and kR+1 is XORed
to the state after the ﬁnal round xR+1. We set the number of rounds R for
Ghidle-256 and Ghidle-512 to 7 and 8, respectively, based on the security analysis
which is described in detail in the next section.
The round function consists of the AES-based function Fγ and Fδ and a
binary matrix multiplication θ256 or θ512. The input is divided into two 128-
bit substates for Ghidle-256 and four 128-bit substates for Ghidle-512. For each
variant, half of the total substates are input to Fγ and the rest to Fδ in their
AES layer. This construction of using two distinct functions contributes to the
improvement of the security against yoyo attacks. (The details are given in
Sect. 6.) The output of the AES layer is multiplied by the matrix of (5) to
perform mixing between the substates. In this process, the matrix multiplica-
tion is performed over GF(264) and GF(2128) for Ghidle-256 and Ghidle-512,
respectively. Thus, θ256 takes two 128-bit substates as the input and divides

412
M. Nakahashi et al.
Table 3. Required instructions for shuﬄe on arm64
Haraka v2 shuf. Pholkos shuf.
Matrix (Eq. (5))
256-bit, Enc./Dec. 2 ZIP
2 TRN
2 EXT + 3 XOR
512-bit, Enc./Dec. 8 ZIP
6 TRN + 4 EXT 6 XOR
(a) Ghidle-256
(b) Ghidle-512
Fig. 3. The round function of Ghidle
each 128-bit value into two 64-bit values for the matrix multiplication. While
θ512 takes four substates as the input vector and directly used it for the matrix
multiplication. Besides, the round key is applied at the second execution and the
ﬁrst execution of the round function AESENCLAST in Fγ and Fδ, respectively.
The round keys are generated by the key scheduling function shown in Fig. 4.
Let k0
0||k0
1 be the master key. Then, it is used as the input for Ghidle-256 key
scheduling. Although the master key is 256 bits, the input to Ghidle-512 key
scheduling is 512 bits. By expanding the master key, we set the input of the
Ghidle-512 key scheduling to k0
0||k0
1||k0
2||k0
3 where k0
2 = k0
0 and k0
3 = k0
1. πunpack in
the key scheduling function of Ghidle-256 is the same as the shuﬄe of Haraka-256.
Let the input of πunpack be z0|| . . . ||z7 where each zi (i = 0 . . . 7) is 32-bit word,
πunpack can be expressed as:
πunpack : z0|| . . . ||z7 →z0||z4||z1||z5||z2||z6||z3||z7
The key scheduling function uses round constants (c2r, c2r+1) for Ghidle-256 and
(c4r, c4r+1, c4r+2, c4r+3) for Ghidle-512. These constants are derived from the frac-
tion part of π.
cj = LSB128((π −3) << 128(j + 1)), ∀j = 0, . . . , 35
where j is the LSB128 is a function that extracts the least signiﬁcant 128 bits of
the integer portion of the argument.
The decryption can be computed by simply changing Fγ and Fδ to their
inverse functions, and reversing the order of the round keys to be added.

Ghidle: Eﬃcient Large-State Block Ciphers for Post-quantum Security
413
Algorithm 1. Ghidle Encryption & Key Scheduling
1: procedure Ghidle256Encrypt(PlainText, SecretKey)
2:
x0
0||x0
1 ←PlainText
3:
{k0, · · · , kR+1} ←KeyGen256(SecretKey)
4:
k0
0||k0
1 ←k0
5:
{x1
0, x1
1} ←{x0
0 ⊕k0
0, x0
1 ⊕k0
1}
6:
for r = 1, · · · , R do
7:
kr
0||kr
1 ←kr
8:
if r < R then
9:
{xr+1
0
, xr+1
1
} ←θ256(Fγ(xr
s, kr
0), Fδ(xr
s, kr
1))
10:
else
11:
{xr+1
0
, xr+1
1
} ←{Fγ(xr
s, kr
0), Fδ(xr
s, kr
1)}
12:
end if
13:
end for
14:
kR+1
0
||kR+1
1
←kR+1
15:
CipherText ←(xR+1
0
⊕kR+1
0
)||(x1 ⊕kR+1
1
)
16:
return CipherText
17: end procedure
18:
19: procedure Ghidle512Encrypt(PlainText, SecretKey)
20:
x0
0||x0
1||x0
2||x0
3 ←PlainText
21:
{k0, · · · , kR+1} ←KeyGen512(SecretKey)
22:
k0
0||k0
1||k0
2||k0
3 ←k0
23:
{x1
0, x1
1, x1
2, x1
3} ←{x0
0 ⊕k0
0, x0
1 ⊕k0
1, x0
2 ⊕k0
2, x0
3 ⊕k0
3}
24:
for r = 1, · · · , R do
25:
kr
0||kr
1||kr
2||kr
3 ←kr
26:
if r < R then
27:
{xr+1
0
, xr+1
1
, xr+1
2
, xr+1
3
} ←θ512(Fγ(xr
0, kr
0), Fδ(xr
1, kr
1), Fγ(xr
2, kr
2), Fδ(xr
3, kr
3))
28:
else
29:
{xr+1
0
, xr+1
1
, xr+1
2
, xr+1
3
} ←{Fγ(xr
0, kr
0), Fδ(xr
1, kr
1), Fγ(xr
2, kr
2), Fδ(xr
3, kr
3)}
30:
end if
31:
end for
32:
kR+1
0
||kR+1
1
||kR+1
2
||kR+1
3
←kR+1
33:
CipherText ←(xR+1
0
⊕kR+1
0
)||(xR+1
1
⊕kR+1
1
)||(xR+1
2
⊕kR+1
2
)||(xR+1
3
⊕kR+1
3
)
34:
return CipherText
35: end procedure
36:
37: procedure KeyGen256(SecretKey)
38:
k0 ←SecretKey
39:
for r = 0, · · · , R do
40:
kr+1 ←πunpack(kr)
41:
end for
42:
return {k0, · · · , kR+1}
43: end procedure
44:
45: procedure KeyGen512(SecretKey)
46:
k0 ←SecretKey
47:
for r = 0, · · · , R do
48:
kr
0||kr
1||kr
2||kr
3 ←kr
49:
{kr+1
0
, kr+1
1
, kr+1
2
, kr+1
3
} ←θ512(kr
0, kr
1, kr
2, kr
3)
50:
kr+1 ←kr+1
0
||kr+1
1
||kr+1
2
||kr+1
3
51:
end for
52:
return {k0, · · · , kR+1}
53: end procedure

414
M. Nakahashi et al.
(a) Ghidle-256
(b) Ghidle-512
Fig. 4. The key scheduling function of Ghidle
4.2
Claimed Security
For both variant of Ghidle, we claim 256-bit and 128-bit security in classical and
quantum setting, respectively, where the available data complexity of Ghidle-
256 and Ghidle-512 for each key is limited to 2128 and 2256, which comes from
the bigger birthday bounds of each variants for mode of operation.
5
Security Evaluation
In this section, we evaluate the security against diﬀerential/linear, truncate dif-
ferential, impossible-diﬀerential, integral attacks, boomerang, Rectangle, Yoyo,
mixuture diﬀerential and DS-Meet-in-the-middle attacks for Ghidle as well as
quantum attacks.
5.1
Diﬀerential and Linear Cryptanalysis
Diﬀerential/linear attacks are the most basic attacks on block ciphers. In
this paper, we employed the MILP (Mixed-Integer Linear Programming)-based
method proposed in [32] for the evaluation. As a result, the lower bound of active
S-boxes of Ghidle-256 and Ghidle-512 reach 27 in 2 rounds and 51 in 3 rounds,
respectively. Since the diﬀerential/linear probability of AES S-box is 2−6 and
available data complexity of Ghidle-256 and Ghidle-512 for each key is limited
to 2128 and 2256, Ghidle-256 and Ghidle-512 are secure against diﬀerential/linear
attacks after 2 and 3 rounds, respectively.
5.2
Truncated Diﬀerential Cryptanalysis
The notion of truncated diﬀerential cryptanalysis was introduced by Knud-
sen [27] in which instead of concrete values, patterns of diﬀerences (zero or
non-zero) are considered. In our analysis, 3-round Ghidle-256 a truncated dif-
ferential trail can be constructed with probability 2−96 × (2−16)4 = 2−160. For
Ghidle-512, we can extend the deterministic truncated diﬀerential of 3-round by
prepending one round at the beginning. As a result, we can construct the 4-round
trail for Ghidle-512 with probability 2−96 × 2−32 × 2−32 × (2−16)4 = 2−224.

Ghidle: Eﬃcient Large-State Block Ciphers for Post-quantum Security
415
5.3
Impossible-Diﬀerential Cryptanalysis
Impossible-diﬀerential cryptanalysis [9,26] exploits the diﬀerences holding with
probability 0 (impossible diﬀerences). For both Ghidle-256 and Ghidle-512, our
MILP-aided search veriﬁed that there is no byte-wise impossible diﬀerential in
the case where only one byte is active in each of the input and output. As a
result, we ﬁnd 4 and 5-round impossible diﬀerentials on Ghidle-256 and Ghidle-
512, respectively. However, due to the limitation of available data, these dis-
tinguishers can not be directly used for attacks on Ghidle-256 and Ghidle-512,
because it requires around 2256−8 and 2512−8 pairs in which there is no diﬀerence
except one byte to mount distinguishing attacks. We believe that Ghidle-256 and
Ghidle-512 are secure against these types of attacks after 4 and 5 rounds at worst
under the data limitation, respectively.
5.4
Integral Cryptanalysis
Integral attacks [17,28] use a set of plaintexts, which has a constant value at some
bit while the other part takes all possible values. We use the MILP-based method
proposed by Xiang [36], and then we search the case where only one input byte
is constant, and the remaining bytes are active, to estimate the upper bounds of
the number of rounds for integral distinguisher for Ghidle-256 and Ghidle-512. As
a result, we ﬁnd 2 and 3-round integral distinguishers on Ghidle-256 and Ghidle-
512, respectively. Besides, as available data complexity is limited to 2128 and
2256, Ghidle-256 and Ghidle-512 are secure against integral attacks after 2 and 3
rounds, respectively.
5.5
Boomerang and Rectangle Attack
In boomerang cryptanalysis, a primitive E is considered as E1 ◦E0 and two
independent diﬀerential trails through sub-cipher E0 and E1 are combined to
ﬁnd boomerang quartet through E [35]. In particular, if there is a diﬀerential
trail α →β with probability p through E0 and a diﬀerential trail γ →δ with
probability q through E1, then a boomerang quartet can be found with probabil-
ity p2q2. In our analysis, in the secret key-setting, boomerang distinguisher can
exist for 2-round and 3-round of Ghidle (both variants) with probability 2−72
and 2−396 respectively.
Rectangle attack [10,25] convert the setting of boomerang attack from adap-
tive chosen plaintext/ciphertext to chosen plaintext at the expense of reducing
the probability of ﬁnding quartets. The notion of the attack is quite similar to
the boomerang, in which two shorter trails are combined to ﬁnd a trail over
large number of rounds. If the primitive E is an n-bit block cipher, then using
the rectangle attack a quartet can be found with probability 2−n−1p2q2 which
ensures that the possibility of ﬁnding a quartet is much lower than using the
boomerang attack. For 2-round Ghidle-256 and Ghidle-512, a right quartet can
be found using this attack with probability 2−329 and 2−585, respectively.

416
M. Nakahashi et al.
5.6
Yoyo Attack
In the Yoyo attack [8], initially a pair of plaintexts is chosen that satisﬁes a
certain property. Words are swapped between the corresponding ciphertexts of
these plaintexts and the resulting ciphertexts are decrypted to obtain a new pair
of plaintext. It is expected that the new pair should also possess the same prop-
erty as the initial one. Rønjom et al. extended the Yoyo attack for SPN ciphers
and devised a deterministic distinguisher for generalized 2-round SPN [33]. Saha
et al. adapted the result on 2-round SPN to devise a probabilistic distinguisher
for 9-round AESQ permutation [34]. Both of these attacks exploit the underly-
ing megasbox (cf. [18]). Note that, as both Fγ and Fδ are used in the round
function, the MC operations are not applied at the same position in the sub-
states. This, in turn, allows restricting the span of megasbox to just one round.
For 2-round Ghidle-256, a deterministic distinguisher can be devised whereas a
probabilistic distinguishing attack can be mounted on 2-round Ghidle-512. The
(data, time, memory) complexity of the attacks on 2-round Ghidle-512 is (227.41,
227.41, negligible). For more details on the attack, refer to [34, Algorithm 3].
In [33], the notion of impossible diﬀerential yoyo distinguisher is introduced
for 3-round SPN. However, this distinguisher is not a generic one and depends
highly on the linear layer. In [3], this strategy is adapted to mount distinguish-
ing attacks on 9-round ForkAES. Similar type of attack can also be mounted on
Ghidle-512. If the operations till initial AESENC in each substates are omitted,
then 3-round Ghidle-512 can be considered as a 3-round SPN where the megas-
boxes correspond to the substitution layer. Thus an impossible diﬀerential yoyo
distinguisher can be devised for 3-round Ghidle-512 (without the initial AESENC)
with (2252.4, 2252.4, negligible) complexity.
5.7
Mixture Diﬀerential Cryptanalysis
In mixture diﬀerential [20] it is shown that ciphertext diﬀerence produced by
a pair of plaintexts and their mixture (new plaintext pair is produced by swap-
ping some words between the original ones) counterpart are related to each other.
Initially it was deterministic in nature and was used to devise 4-round determin-
istic distinguisher on AES. Later, a probabilistic version of this technique was
also proposed in 2019 [21]. Some other variants of mixture diﬀerential are also
proposed which are also probabilistic [4–6].
If AESENCLAST ◦AESENC of the initial Fγ and AESENC ◦AESENCLAST
of the initial Fδ are omitted, then the deterministic mixture diﬀerential attack
of [20], can be adapted for 2-round Ghidle-256 and Ghidle-512. However, due to
the binary matrix multiplication operation and positional diﬀerence of MC in Fγ
and Fδ, the probabilistic mixture diﬀerential attacks can not be directly adapted
to our construction.
5.8
DS-Meet-in-the-Middle Attacks
The DS-MITM technique [19] is a powerful attack on AES. In this attack, the aim
is to determine a set of possible sequences of values. Speciﬁcally, by traversing

Ghidle: Eﬃcient Large-State Block Ciphers for Post-quantum Security
417
one input byte and setting other input bytes as random constants, after 4 rounds
of AES, there exists a byte whose values only depend on 25 guessed bytes. In
other words, under the input set, there are at most (28)25 possible sequences of
28 = 256 values for this byte. However, for a random permutation, the number
of sequences is (28)256. Therefore, the time complexity of this distinguisher is
28×25+8 = 2208 and the data complexity is only 28. We performed similar analysis
for Ghidle-256 and could only found a distinguisher for 3 rounds. In addition, we
can append 1 round for the key recovery. Hence, the security margin is 3 rounds
for Ghidle-256. For Ghidle-512, we also found a DS-MitM distinguisher for up to
4 rounds and could append 1 round for the key recovery. Therefore, the security
margin is also 3 rounds for Ghidle-512.
5.9
Quantum Attacks
For block ciphers with a key of size k, a quantum adversary can perform an
exhaustive key search using Grover’s algorithm in time approximately 2k/2. For
Ghidle, it will require approximately 2128 iterations, for both 256 and 512-bit
variants.
Considering that the design of Ghidle consists of the operations of AES, we
believe the quantum attacks on AES would be best suited for Ghidle. One of the
complete quantum security analysis of AES was presented in [13]. The quantum
DS-MITM attack on AES in [13] reaches 8-rounds in the case where the key
size is double of the state size. For Ghidle-512, in the classical settings there
exists a DS-MITM distinguisher for up to 4 rounds and 1 more round could be
appended for key recovery. Due to the binary matrix multiplication operation
and positional diﬀerence of MC in Fγ and Fδ, we believe the quantum security
margin will still be almost similar to that of the classical security margin and full
round Ghidle-512 should be safe from the quantum DS-MITM attack. We know
that the quantum diﬀerential and linear attacks enjoys quadratic speed up [24].
From the lower bounds on the number of active S-boxes computed in Table 7, we
believe Ghidle-256 and Ghidle-512 are secure against quantum diﬀerential attacks
after 3 and 4 rounds respectively. These results show that, for now, the full round
Ghidle is quantum secure.
6
Performance Evaluation
In this section, we evaluate software performance of Ghidle-256 and Ghidle-512 on
x86 and latest arm64-based processors. Our evaluations use the available source
code at GitHub1 to evaluate the cycle counters, i.e., cycles per byte (cpb), in
the target primitives.
All our evaluations in x86 were performed on the following environments: the
Ice Lake platform has an Intel(R) Core(TM) i7-1068NG7 CPU @ 2.30 GHz; the
Tiger Lake platform has an Intel(R) Core(TM) i7-1165G7 CPU @ 2.80 GHz; the
1 https://github.com/seb-m/cycles.

418
M. Nakahashi et al.
Table 4. Benchmarks for single block encryption/decryption of 256-bit ciphers (all
values are given as cpb), where BC and TBC mean block cipher and tweakable block
cipher, respectively
Primitive
Security Ice Lake
Tiger Lake Alder Lake
Enc
Dec
Enc
Dec
Enc
Dec
Ghidle-256 (BC)
256 bits 3.79 3.85 3.79 3.84 3.83 3.85
Pholkos-256 (TBC) 256 bits 2.40
5.76
2.40
5.74
2.37
5.71
Table 5. Benchmarks for single block encryption/decryption of 512-bit ciphers (all
values are given as cpb)
Algorithm
Security Ice Lake
Tiger Lake Alder Lake
Enc
Dec
Enc
Dec
Enc
Dec
Ghidle-512 (BC)
256 bits 2.00 1.99 2.00 1.99 1.95 1.98
Pholkos-512 (TBC) 256 bits 2.00
4.29
2.00
4.28
2.02
4.30
Alder Lake platform has an Intel(R) Core(TM) i9-12900K CPU @ 3.20 GHz on
a performance-core (P-core) and 2.40 GHz on an eﬃcient-core (E-core); with the
Turbo Boost technology disabled oﬀfor all our evaluations. We note here that
the P-core has been speciﬁed on the Alder Lake platform.
For the evaluation in arm64, we use three up-to-date mobile devices with
arm64-based processors: Google Pixel 7, Apple iPhone 14, and iPad Pro.
Although the details of the CPU of the iPhone/iPad Pro are not publicly avail-
able, Tensor2, the CPU of the Pixel 7, is reported to be equipped with two
Cortex-X1 cores, two Cortex-A76 cores, and four Cortex-A55 cores. All instances
of Ghidle and Pholkos are implemented in C with intrinsic functions.
6.1
Performance on X86
We ran benchmarks on Ghidle and Pholkos [14], and compare their performance.
Although Haraka v2 has similar construction to Ghidle and Pholkos, we exclude
Haraka v2 from our evaluation because it is proposed as a hash function, not
a block cipher. In all evaluations on x86, we measure the cycle per byte for
single block encryption/decryption by iterating 1.25E8 times the execution of
the target algorithm and taking the average cycle per byte.
The results are shown in Table 4 and 5. We ﬁnd that Ghidle-256 and Ghidle-
512 are equally fast in the encryption and decryption performances as we aim
for it in this paper. The decryption speed of Ghidle-256 and Ghidle-512 are about
33% and 53% faster than Pholkos-256 and Pholkos-512, respectively. On the
encryption speed, Ghidle-512 is almost same as Pholkos-512, while that of Ghidle-
256 is slightly slower than Pholkos-256.

Ghidle: Eﬃcient Large-State Block Ciphers for Post-quantum Security
419
Saturnin claims 3.5 cpb performance on x86 in the proposed paper [15]. How-
ever, to reach the claimed performance of 3.5 cpb, 8 instances must be executed
in parallel by bit-slice manner. Therefore, it can be concluded that Ghidle is more
suitable for x86 environments than Saturnin.
6.2
Performance on Arm64
We ran the benchmark also on arm64. In all evaluations on arm64, we measure
the average gigabit per second required to process one block when processing a
suﬃciently large number of blocks in parallel.
The result of the measurements is shown in Table 6. As a result, the decryp-
tion of Ghidle-256 outperforms Pholkos-256 by about 32%, while the encryption
performance of Ghidle-256 is almost the same as Pholkos-256. On the other hand,
both the encryption and decryption of Ghidle-512 outperform Pholkos-512 by
about 21% and 53%, respectively.
This result can be attributed to the small number of required instructions for
the NEON implementation. The total number of the AES round execution which
can not be parallelized in Ghidle-256 and Ghidle-512 are 24 and 21(#rounds ×
3), respectively. On the other hand, in Pholkos-256 and Pholkos-512, at least 16
and 20 AES round execution can not be parallelized. Since the AES round in the
NEON implementation requires two distinct instructions: AESE and AESMC, the
number of required instructions for execution of the AES round increased up to
twice. That is to say, the number of instructions for consecutive AES rounds of
Pholkos-256 and Pholkos-512 are 32 and 40, respectively, in arm64. On the other
hand, 2/3 of the AES rounds in Ghidle are the last round function which can
be implemented by only AESE. Therefore, the increase in the number of instruc-
tions is moderate in the arm64 transplant. Since 1/3 of the total AES rounds
corresponding to the AESENC of x86 in Ghidle and the NEON implementations
requires two instructions for its representation, the number of AES rounds that
can not be parallelized in the NEON implementation of Ghidle is obtained by
(1 + 1/3) × (number of AES rounds that can not be parallelized).
As a result, the number of instructions for consecutive AES executions of
Ghidle-256 and Ghidle-512 increases only up to 32 and 28, respectively. Thus, the
number of AES instructions for Ghidle-512 fewer than that of Pholkos-512, while
the number of AES instructions for Pholkos-256 and Ghidle-256 is identical. In
addition, the number of instructions for the shuﬄe layer of Ghidle-512 is fewer
than that of Pholkos-512, which further reduced the number of execution cycles
of Ghidle-512 compared to Pholkos-512. These facts contribute to the advantage
of Ghidle as shown in the results.

420
M. Nakahashi et al.
Table 6. Benchmarks on the Pixel 7, iPhone 14, and iPad Pro (all values are given as
Gbps).
Algorithm
Pixel 7
iPhone 14
iPad Pro
Enc
Dec
Enc
Dec
Enc
Dec
Ghidle-256
18.40 12.76 32.08 24.71 34.64 26.72
Pholkos-256 18.24
8.66
34.83
19.80
37.22
21.41
Ghidle-512
12.54 15.15 24.53 27.58 26.62 29.76
Pholkos-512 9.89
6.98
19.98
13.67
21.47
14.75
7
Conclusion
In this paper, we proposed a new family of block ciphers called Ghidle which
can ensure post-quantum security. The construction solves the performance gap
between the encryption and decryption on AES instructions-enabled environ-
ments that is observed in existing AES-NI-based cryptographic primitives with
the SPN structure. The result of the performance evaluation shows that Ghi-
dle has the same encryption and decryption speed on x86. The result also shows
that Ghidle-512 outperform Pholkos-512 by about 54% in the decryption, while
the encryption of Ghidle-512 is mostly the same as Pholkos-512. Besides, our
performance evaluation on mobile devices with arm64-based processors shows
that Ghidle-256 outperforms Pholkos-256 by about 32% for decryption while
the encryption remains as high performance as Pholkos-256. Remarkably, Ghidle-
512 outperforms Pholkos-512 by about 21% and 53% for both encryption and
decryption, respectively.
Acknowledgments. Takanori Isobe is supported by JST, PRESTO Grant Number
JPMJPR2031. This research was in part conducted under a contract of “Research and
development on new generation cryptography for secure wireless communication ser-
vices” among “Research and Development for Expansion of Radio Wave Resources
(JPJ000254)”, which was supported by the Ministry of Internal Aﬀairs and Communi-
cations, Japan. This result is also obtained from the commissioned research (No.05801)
by National Institute of Information and Communications Technology (NICT), Japan.

Ghidle: Eﬃcient Large-State Block Ciphers for Post-quantum Security
421
Appendix
Lower Bounds on the Number of Active S-Boxes
Table 7 shows lower bounds on the number of active S-boxes for each round of
Ghidle.
Table 7. Lower bounds of the number of active S-boxes for diﬀerential/linear attacks.
Round Number
1 2
3
4
5
6
7
Min. # of AS (Ghidle-256) 6 27 51 87
101 119 145
Min. # of AS (Ghidle-512) 6 27 51 105 147 168 204
Integral Distinguisher
Table 8 shows detailed integral distinguishers of Ghidle. A, B, and C represent
active byte, constant, and balanced byte, respectively.
Table 8. Integral distinguisher on Ghidle-256 and Ghidle-512
Cipher
Integral distinguisher
Ghidle-256 In: (CAAAAAAAAAAAAAAA, AAAAAAAAAAAAAAAA)
Out: (BBBBBBBBBBBBBBBB, BBBBBBBBBBBBBBBB)
Ghidle-512 In: (CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA, AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA)
Out: (BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB, BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB)
Impossible Diﬀerential Distinguishers
Figure 5 and 6 show impossible diﬀerential distinguishers of the 4-round Ghidle-
256 and 5-round Ghidle-512, respectively. Table 9 show the input and output of
the impossible diﬀerentials in byte-wise representation.
Table 9. Impossible diﬀerential distinguisher on Ghidle-256 and Ghidle-512
Cipher
Round
Impossible diﬀerential
Ghidle-256
4
In:(1000000000000000, 0000000000000000)
Out:(0000000000000000, 1000000000000000)
Ghidle-512
5
In:(1000000000000000, 0000000000000000, 0000000000000000, 0000000000000000)
Out:(0000000000000000, 1000000000000000, 0000000000000000, 0000000000000000)

422
M. Nakahashi et al.
Fig. 5. Impossible diﬀerential distinguisher of the 4-round Ghidle-256

Ghidle: Eﬃcient Large-State Block Ciphers for Post-quantum Security
423
Fig. 6. Impossible diﬀerential distinguisher of the 5-round Ghidle-512

424
M. Nakahashi et al.
Yoyo Attacks
(a)
MegaSbox
of
Ghidle-256
(b) MegaSbox of Ghidle-512
Fig. 7. MegaSbox of Ghidle. The
bytes corresponds to a single megasbox for each
variant of Ghidle. For Ghidle-512, megasbox starting from the ﬁrst inverse diagonal is
shown. There are three more megasboxes corresponding to the three remaining inverse
diagonals. In Ghidle-256, there are two parallel megasboxes. (Color ﬁgure online)
The megasbox of Ghidle is shown in Fig. 7. Here, we show that more number
of rounds can be penetrated using yoyo attack if only one of Fγ or Fδ is used
in the round function of Ghidle. The underlying megasbox for the case when
round function is comprised of only Fγ is shown in Fig. 8. Attacks similar to the
ones in [34] can be mounted on 4-round Ghidle-256 and 4-round Ghidle-512 in
the secret-key setting by exploiting the underlying megasbox. The (data, time,
memory) complexity of the attacks on Ghidle-256 and Ghidle-512 are (229, 229,
negligible) and (226.41, 226.41, negligible) respectively. Impossible diﬀerential yoyo
distinguishing attack [33] can also be mounted on Ghidle-512. If the initial AES-
ENC is omitted, then 6-round Ghidle-512 can be considered as a 3-round SPN

Ghidle: Eﬃcient Large-State Block Ciphers for Post-quantum Security
425
(a) MegaSbox of Ghidle-
256
(b) MegaSbox of Ghidle-512
Fig. 8. MegaSbox of Ghidle when only Fγ is used in the round function. The
bytes
corresponds to a single megasbox for each variant of Ghidle. For Ghidle-512, megasbox
starting from the ﬁrst inverse diagonal is shown. There are three more megasboxes
corresponding to the three remaining inverse diagonals. In Ghidle-256, there are two
parallel megasboxes. (Color ﬁgure online)

426
M. Nakahashi et al.
(a) Truncated diﬀerential trail of 3-round
Ghidle-512
(b) Truncated diﬀerential trail of
3-round Ghidle-256
Fig. 9. Truncated diﬀerential trails of Ghidle

Ghidle: Eﬃcient Large-State Block Ciphers for Post-quantum Security
427
Fig. 10. One round truncated diﬀerential trail of Ghidle-512 that can be prepended to
3-round deterministic trail.

428
M. Nakahashi et al.
where the megasboxes correspond to the substitution layer. Thus a impossible
diﬀerential yoyo distinguisher can be devised for 6-round Ghidle-512 (without
the initial AESENC) with (2252.4, 2252.4, negligible) complexity.
Truncated Diﬀerential Trails
The deterministic truncated diﬀerential trail of 3-round Ghidle-512 is shown
in Fig. 9a. The trail can be extended by prepending one round at the begin-
ning as shown in Fig. 10. The bytes with similar pattern after the last AESEN-
CLAST operation are required to hold the same value which can occur with prob-
ability 28 × 2−8 × 2−8 × 2−8 = 2−16 for three randomly generated bytes. Hence,
the overall probability of the 4-round trail is 2−96×2−32×2−32×(2−16)4 = 2−224.
Similarly, for 3-round Ghidle-256 a truncated diﬀerential trail can be constructed
with probability 2−96 × (2−16)4 = 2−160.
References
1. Anand, M.V., Targhi, E.E., Tabia, G.N., Unruh, D.: Post-quantum security of
the CBC, CFB, OFB, CTR, and XTS modes of operation. In: Takagi, T. (ed.)
PQCrypto 2016. LNCS, vol. 9606, pp. 44–63. Springer, Cham (2016). https://doi.
org/10.1007/978-3-319-29360-8 4
2. Banik, S., et al.: Midori: a block cipher for low energy. In: Iwata, T., Cheon, J.H.
(eds.) ASIACRYPT 2015. LNCS, vol. 9453, pp. 411–436. Springer, Heidelberg
(2015). https://doi.org/10.1007/978-3-662-48800-3 17
3. Banik, S., et al.: Cryptanalysis of ForkAES. In: Deng, R.H., Gauthier-Uma˜na, V.,
Ochoa, M., Yung, M. (eds.) ACNS 2019. LNCS, vol. 11464, pp. 43–63. Springer,
Cham (2019). https://doi.org/10.1007/978-3-030-21568-2 3
4. Bardeh, N.G.: A key-independent distinguisher for 6-round AES in an adaptive
setting. Cryptology ePrint Archive, Paper 2019/945 (2019)
5. Bardeh, N.G., Rønjom, S.: The exchange attack: how to distinguish six rounds
of AES with 288.2 chosen plaintexts. In: Galbraith, S.D., Moriai, S. (eds.) ASI-
ACRYPT 2019. LNCS, vol. 11923, pp. 347–370. Springer, Cham (2019). https://
doi.org/10.1007/978-3-030-34618-8 12
6. Bardeh, N.G., Rønjom, S.: Practical attacks on reduced-round AES. In: Buchmann,
J., Nitaj, A., Rachidi, T. (eds.) AFRICACRYPT 2019. LNCS, vol. 11627, pp. 297–
310. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-23696-0 15
7. Bernstein, D.J.: Some challenges in heavyweight cipher design. In: Dagstuhl Semi-
nar on Symmetric Encryption, Dagstuhl, Germany, vol. 15 (2016)
8. Biham, E., Biryukov, A., Dunkelman, O., Richardson, E., Shamir, A.: Initial
observations on skipjack: cryptanalysis of skipjack-3XOR. In: Tavares, S., Meijer,
H. (eds.) SAC 1998. LNCS, vol. 1556, pp. 362–375. Springer, Heidelberg (1999).
https://doi.org/10.1007/3-540-48892-8 27
9. Biham, E., Biryukov, A., Shamir, A.: Cryptanalysis of skipjack reduced to 31
rounds using impossible diﬀerentials. J. Cryptol. 18(4), 291–311 (2005)
10. Biham, E., Dunkelman, O., Keller, N.: The rectangle attack — rectangling the
serpent. In: Pﬁtzmann, B. (ed.) EUROCRYPT 2001. LNCS, vol. 2045, pp. 340–
357. Springer, Heidelberg (2001). https://doi.org/10.1007/3-540-44987-6 21

Ghidle: Eﬃcient Large-State Block Ciphers for Post-quantum Security
429
11. Biryukov, A., Khovratovich, D.: PAEQ: parallelizable permutation-based authen-
ticated encryption. In: Chow, S.S.M., Camenisch, J., Hui, L.C.K., Yiu, S.M. (eds.)
ISC 2014. LNCS, vol. 8783, pp. 72–89. Springer, Cham (2014). https://doi.org/10.
1007/978-3-319-13257-0 5
12. Boneh, D., Zhandry, M.: Secure signatures and chosen ciphertext security in a
quantum computing world. In: Canetti, R., Garay, J.A. (eds.) CRYPTO 2013.
LNCS, vol. 8043, pp. 361–379. Springer, Heidelberg (2013). https://doi.org/10.
1007/978-3-642-40084-1 21
13. Bonnetain, X., Naya-Plasencia, M., Schrottenloher, A.: Quantum security analysis
of AES. IACR Trans. Symmetric Cryptol. 2019(2), 55–93 (2019)
14. Bossert, J., List, E., Lucks, S., Schmitz, S.: Pholkos – eﬃcient large-state tweakable
block ciphers from the AES round function. In: Galbraith, S.D. (ed.) CT-RSA 2022.
LNCS, vol. 13161, pp. 511–536. Springer, Cham (2022). https://doi.org/10.1007/
978-3-030-95312-6 21
15. Canteaut, A., et al.: Saturnin: a suite of lightweight symmetric algorithms for post-
quantum security. IACR Trans. Symmetric Cryptol. 2020(S1), 160–207 (2020)
16. Chen, L., et al.: Report on post-quantum cryptography, vol. 12. US Department
of Commerce, National Institute of Standards and Technology (2016)
17. Daemen, J., Knudsen, L., Rijmen, V.: The block cipher Square. In: Biham, E. (ed.)
FSE 1997. LNCS, vol. 1267, pp. 149–165. Springer, Heidelberg (1997). https://doi.
org/10.1007/BFb0052343
18. Daemen, J., Lamberger, M., Pramstaller, N., Rijmen, V., Vercauteren, F.: Com-
putational aspects of the expected diﬀerential probability of 4-round AES and
AES-like ciphers. Computing 85(1–2), 85–104 (2009)
19. Demirci, H., Sel¸cuk, A.A.: A meet-in-the-middle attack on 8-round AES. In:
Nyberg, K. (ed.) FSE 2008. LNCS, vol. 5086, pp. 116–126. Springer, Heidelberg
(2008). https://doi.org/10.1007/978-3-540-71039-4 7
20. Grassi, L.: Mixture diﬀerential cryptanalysis: a new approach to distinguishers
and attacks on round-reduced AES. IACR Trans. Symmetric Cryptol. 2018(2),
133–160 (2018)
21. Grassi, L.: Probabilistic mixture diﬀerential cryptanalysis on round-reduced AES.
In: Paterson, K.G., Stebila, D. (eds.) SAC 2019. LNCS, vol. 11959, pp. 53–84.
Springer, Cham (2020). https://doi.org/10.1007/978-3-030-38471-5 3
22. Grover, L.K.: A fast quantum mechanical algorithm for database search. In: Miller,
G.L. (ed.) Proceedings of the Twenty-Eighth Annual ACM Symposium on the
Theory of Computing, Philadelphia, Pennsylvania, USA, 22–24 May 1996, pp. 212–
219. ACM (1996)
23. Gueron, S., Mouha, N.: Simpira v2: a family of eﬃcient permutations using the
AES round function. In: Cheon, J.H., Takagi, T. (eds.) ASIACRYPT 2016. LNCS,
vol. 10031, pp. 95–125. Springer, Heidelberg (2016). https://doi.org/10.1007/978-
3-662-53887-6 4
24. Kaplan, M., Leurent, G., Leverrier, A., Naya-Plasencia, M.: Quantum diﬀerential
and linear cryptanalysis. IACR Trans. Symmetric Cryptol. 2016(1), 71–94 (2016)
25. Kelsey, J., Kohno, T., Schneier, B.: Ampliﬁed boomerang attacks against reduced-
round MARS and serpent. In: Goos, G., Hartmanis, J., van Leeuwen, J., Schneier,
B. (eds.) FSE 2000. LNCS, vol. 1978, pp. 75–93. Springer, Heidelberg (2001).
https://doi.org/10.1007/3-540-44706-7 6
26. Knudsen, L.: Deal - a 128-bit block cipher. In: NIST AES Proposal (1998)
27. Knudsen, L.R.: Truncated and higher order diﬀerentials. In: Preneel, B. (ed.) FSE
1994. LNCS, vol. 1008, pp. 196–211. Springer, Heidelberg (1995). https://doi.org/
10.1007/3-540-60590-8 16

430
M. Nakahashi et al.
28. Knudsen, L., Wagner, D.: Integral cryptanalysis. In: Daemen, J., Rijmen, V. (eds.)
FSE 2002. LNCS, vol. 2365, pp. 112–127. Springer, Heidelberg (2002). https://doi.
org/10.1007/3-540-45661-9 9
29. K¨olbl, S., Lauridsen, M.M., Mendel, F., Rechberger, C.: Haraka v2 - eﬃcient short-
input hashing for post-quantum applications. IACR Trans. Symmetric Cryptol.
2016(2), 1–29 (2016)
30. Kuwakado, H., Morii, M.: Security on the quantum-type even-mansour cipher. In:
ISITA, pp. 312–316. IEEE (2012)
31. Maram, V., Masny, D., Patranabis, S., Raghuraman, S.: On the quantum security
of OCB. IACR Trans. Symmetric Cryptol. 2022(2), 379–414 (2022)
32. Mouha, N., Wang, Q., Gu, D., Preneel, B.: Diﬀerential and linear cryptanalysis
using mixed-integer linear programming. In: Wu, C.-K., Yung, M., Lin, D. (eds.)
Inscrypt 2011. LNCS, vol. 7537, pp. 57–76. Springer, Heidelberg (2012). https://
doi.org/10.1007/978-3-642-34704-7 5
33. Rønjom, S., Bardeh, N.G., Helleseth, T.: Yoyo tricks with AES. In: Takagi, T.,
Peyrin, T. (eds.) ASIACRYPT 2017. LNCS, vol. 10624, pp. 217–243. Springer,
Cham (2017). https://doi.org/10.1007/978-3-319-70694-8 8
34. Saha, D., Rahman, M., Paul, G.: New Yoyo tricks with AES-based permutations.
IACR Trans. Symmetric Cryptol. 2018(4), 102–127 (2018)
35. Wagner, D.: The boomerang attack. In: Knudsen, L. (ed.) FSE 1999. LNCS, vol.
1636, pp. 156–170. Springer, Heidelberg (1999). https://doi.org/10.1007/3-540-
48519-8 12
36. Xiang, Z., Zhang, W., Bao, Z., Lin, D.: Applying MILP method to searching inte-
gral distinguishers based on division property for 6 lightweight block ciphers. In:
Cheon, J.H., Takagi, T. (eds.) ASIACRYPT 2016. LNCS, vol. 10031, pp. 648–678.
Springer, Heidelberg (2016). https://doi.org/10.1007/978-3-662-53887-6 24

Quantum Algorithm for Finding
Impossible Diﬀerentials
and Zero-Correlation Linear Hulls
of Symmetric Ciphers
Huiqin Chen1,4
, Yongqiang Li1,4(B)
, Parhat Abla2, Zhiran Li1,4, Lin Jiao3,
and Mingsheng Wang1,4
1 Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China
{chenhuiqin,liyongqiang,wangmingsheng}@iie.ac.cn
2 School of Software, South China Normal University, Guangzhou, China
parhat@m.scnu.edu.cn
3 State Key Laboratory of Cryptology, Beijing, China
4 School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China
Abstract. In this paper, we present quantum algorithms for ﬁnding
impossible diﬀerentials and zero-correlation linear hulls, which are dis-
tinguishers for the two powerful attacks against symmetric ciphers of
impossible diﬀerential attack and zero-correlation linear attack. Com-
pared to classical methods, the proposed quantum algorithms possess
many advantages. Firstly, our quantum algorithm for ﬁnding impossible
diﬀerentials obtains the input and output diﬀerences by solving linear
equation systems instead of searching in a limited space; Secondly, our
quantum algorithm for zero-correlation linear hulls can investigate the
key schedule’s eﬀect; Thirdly, the only computation cost of our algo-
rithms is solving linear equation systems, and the size of the systems is
not increasing as the round number increases.
The core idea of our method is to use the Berstein-Vazirani algorithm
to ﬁnd 1-linear structures of Boolean functions. We check the validity
of the proposed quantum algorithm with the SIMON block cipher fam-
ily and RC5 block cipher. We show that the proposed algorithms can
discover some 11-round, 12-round, 13-round, 16-round, and 19-round
impossible diﬀerentials and zero-correlation linear hulls of SIMON cipher
when considering the key schedules and 2.5-round impossible diﬀerential
of RC5 when considering the round subkeys.
Keywords: Quantum algorithm · Berstein-Vazirani algorithm · Linear
structure · Impossible diﬀerential · Zero-correlation linear hull
1
Introduction
In recent years, there has been substantial research on quantum computers -
machines that exploit quantum mechanical phenomena to solve mathematical
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 431–451, 2023.
https://doi.org/10.1007/978-3-031-35486-1_19

432
H. Chen et al.
problems that are diﬃcult or intractable for conventional computers. If large-
scale quantum computers are ever built, they will threaten many of the cryp-
tosystems currently in use, hence seriously compromising digital communica-
tions’ conﬁdentiality and integrity on the Internet and elsewhere.
As for symmetric cryptography, the most general result is Grover’s algorithm
[20], which can get an n-bit key with O(2n/2) quantum search. Then doubling
the key length is a choice to resist this quantum exhaustive search attack. For
example, the European PQCRYPTO project recommends using AES with 256-
bit keys to provide 128-bit quantum security [14], and the 3GPP standardiza-
tion organization requires increasing the security level to 256-bit key lengths for
the 5G system [37]. With the rapid development of quantum technologies, it is
essential to investigate more accurate cryptanalysis methods with quantum com-
putation, giving a comprehensive understanding of the eﬀectiveness of quantum
computation in symmetric cryptography.
The most widely used algorithm is Simon’s algorithm, which can ﬁnd the
unknown period of a Boolean function in linear time [10,40]. Many pioneer
works apply Simon’s algorithm in cryptography by using the hidden periods
of various symmetric primitives. With this approach, Kuwakado and Morii ﬁrst
showed that the three-round Feistel network could be distinguished from random
permutations [29]. Then they also proved that the Even-Mansour cipher could
be broken [30]. Hosoyamada and Aoki [21] showed that the quantum-related
key attack could also be applied in polynomial time with quantum computa-
tion. By combining Grover’s algorithm and Simon’s algorithm, Leander and May
showed that FX-construction could be broken with the same time complexity
as Grover’s original algorithm [31]. Bonnetain et al. proposed oﬄine Simon’s
algorithm, which improves signiﬁcantly over the Grover-meets-Simon algorithm
[6]. Recently, Bonnetain et al. broke many parallelizable MACs using Simon’s
algorithm and the new technique of quantum linearization [7].
Besides symmetric ciphers, the quantum computation can also aﬀect the
analysis of hash functions, MACs, and authenticated encryptions. Kaplan et al.
showed that the most widely used modes of operation for authentication and
authenticated encryption could be broken with Simon’s algorithm [26]. Santoli
and Schaﬀner also independently investigated this [38]. As for an n-bit hash
function, Brassard et al. showed that collisions could be found with a query
complexity of O(2n/3) with the BHT algorithm [11]. Hosoyamada and Sasaki
gave more dedicated quantum collision attacks [23]. They showed that diﬀeren-
tial trails with a lower probability that cannot use in the classical setting might
also lead to a collision attack in the quantum setting. Avoiding using large quan-
tum random access memories (qRAMs), Dong et al. made an improvement by
performing a quantum rebound attack based on diﬀerentials with non-full active
super S-boxes to be searched with MILP-based method [17]. Recently, Hosoya-
mada and Sasaki have developed a dedicated quantum collision attack on SHA-
256 and SHA-512, which can attack more steps than classical attacks [24].
In the present paper, we also aim to investigate the security evaluation of
symmetric ciphers in the quantum setting. Unlike asymmetric algorithms, the
security evaluation of symmetric ciphers relies on the resistance to known crypt-

Quantum Algorithm for Finding Impossible Diﬀerentials
433
analysis methods, such as diﬀerential cryptanalysis [4], linear cryptanalysis [34],
impossible diﬀerential cryptanalysis [3], zero-correlation cryptanalysis [5]. As
for these attacks, the ﬁrst step is to ﬁnd a property that can distinguish the
target cipher from random permutations. Such a property is usually called a
distinguisher. For example, it needs to ﬁnd an impossible diﬀerential or a zero-
correlation linear hull before implementing an impossible diﬀerential or zero-
correlation attack.
Nowadays, ﬁnding distinguishers of various cryptanalysis of symmetric
ciphers classically has transitioned from manual analysis to automatic analy-
sis based on the Mixed Integer Linear Programming (MILP) technique and the
Boolean Satisﬁability Problem (SAT) solvers. At the dawn of the quantum era,
it is also of signiﬁcant importance to investigate how to ﬁnd distinguishers of
symmetric ciphers with quantum computation. However, for the current known
cryptanalysis methods of symmetric ciphers, there is a lack of research on ﬁnd-
ing their distinguishers quantumly, although there are already works diverted
to present dedicated analysis. Kaplan et al. investigated the quantum version of
diﬀerential attack and linear attack and gave some examples of applications on
ciphers LAC and KLEIN [27]. Zhou et al. also gave the quantum version of the
diﬀerential attack based on the quantum minimum/maximum-ﬁnding algorithm
[45]. Hosoyamada and Sasaki showed that quantum Demirci and Selçuk (DS)
meet-in-the-middle attacks could speed up signiﬁcantly with quantum comput-
ers, and they applied this attack to 6-round generic Feistel constructions [22].
Using details of AES S-box diﬀerential property, Bonnetain et al. gave the ﬁrst
quantum DS-meet-in-the-middle attack on 8 rounds of AES-256 [8]. Bonnetain
et al. further investigated quantum slide attacks [9]. It should note that besides
attacks, some quantum distinguishers are also given in [9]. Dong et al. gave
quantum advanced slide attacks [16]. Dunkelman et al. investigated quantum
Time/Memory/Data tradeoﬀattacks and further improved Hellman’s tradeoﬀ
curve [19]. Most of these works usually use quantum computation to reduce time
complexity compared with classical analysis but do not focus on ﬁnding distin-
guishers. Especially, [15] investigate impossible diﬀerential attacks and improve
the complexity of the sieving phase by the quantum technique.
Our Contributions. In the present paper, we present quantum algorithms for
ﬁnding impossible diﬀerentials and zero-correlation linear hulls, which is the
distinguisher for the impossible diﬀerential attack and zero-correlation linear
attack. The core idea is to use a quantum algorithm to ﬁnd linear structures of
Boolean functions.
Note that the descriptions of the encryption algorithm, the decryption algo-
rithm, and the key schedule algorithm are clearly known to attackers. With these
descriptions, attackers can build the quantum circuits of a cipher’s encryption,
decryption, and key schedule in the quantum setting. We do not investigate the
approach to give the quantum circuit of block ciphers in the present paper.
We use the quantum algorithm to ﬁnd linear structures of Boolean functions
and the “miss-in-the-middle” approach to ﬁnd quantumly impossible diﬀerentials
of symmetric ciphers. More precisely, we show that by ﬁnding 1-linear structures
of the XOR of the i-th components of the r1-round encryption (from the 0-th

434
H. Chen et al.
round to the r1-th round) and r2-round decryption (from the (r1 + r2)-th round
to the r1-th round), one can obtain an (r1 + r2)-round impossible diﬀerential.
Compared to classical methods, the proposed quantum algorithm can investigate
the details of all nonlinear functions and the eﬀect of key schedules. Furthermore,
the proposed quantum algorithm obtains an impossible diﬀerential’s input and
output diﬀerences by solving linear equations systems. In contrast, the input
and output diﬀerences always need to be searched in a limited space for classical
methods. Xie and Yang also proposed a quantum algorithm to ﬁnd impossible
diﬀerentials [44], and we show that our algorithm can ﬁnd longer distinguishers
than their method.
Furthermore, we prove that if there exists a vector c, such that it is an l-linear
structure of the i-th component of r1-round decryption (from the r1-th round to
the 0-th round), and it is also the (l ⊕1)-linear structure of the j-th component
of r2-round encryption (from the r1-th round to the (r1 + r2)-th round), then
(ei, ej) is an (r1 + r2)-round zero-correlation linear hulls. On the basis of this
result and the quantum algorithm for ﬁnding linear structures, we propose a
quantum algorithm for ﬁnding zero-correlation linear hulls of symmetric ciphers.
The quantum algorithm can investigate the details of all nonlinear functions.
Moreover, for the ﬁrst time, the eﬀect of key schedules in ﬁnding distinguishers
of zero-correlation linear attacks can be investigated.
To make it more clear, we present a comparison of our quantum algorithm
and classical methods in Table 1.
Table 1. Comparisons with classical methods for ﬁnding IDs a /ZCs b
Methods
Features
Properties
of
Nonlinear
functions
Data-
dependent
operations
Key
Schedule
Problems
need to
solve
input and
output
diﬀerence
Ref.
U-method,
UID-
method
IDs and
ZCs
NO
NO
NO
/
Searching
[28,33]
WW-
method
IDs and
ZCs
NO
NO
NO
linear
equations
system
Searching
[39,43]
MILP-
based
method
IDs and
ZCs
small
S-boxes
(≤6-bits)
NO
NO
optimize
problems
Searching
[13]
SAT-based
method
IDs and
ZCs
big S-boxes
(8,9-bits)
YES
YES
Nonlinear
equations
system
Searching
[25]
Quantum
algorithm
IDs and
ZCs
any
nonlinear
functions
YES
YES
linear
equations
system
Solving
linear
equations/
Searching
Sect.3
Sect.4
aIDs: Impossible Diﬀerentials
bZCs: Zero Correlation Linear Hulls

Quantum Algorithm for Finding Impossible Diﬀerentials
435
We check the validity of the proposed quantum algorithm with the SIMON
block cipher family and the RC5 block cipher. We can verify that the pro-
posed quantum algorithm can discover some 11-round, 12-round, 13-round, 16-
round, and 19-round impossible diﬀerentials and zero-correlation linear hulls
of SIMON32/64, SIMON48/72, SIMON64/96, SIMON96/96, SIMON128/128
when considering the key schedules, and 2.5-round impossible diﬀerentials of
RC5 when considering the inﬂuence of round subkeys. The veriﬁcation means
that the round number of distinguishers of SIMON and RC5 found by quantum
algorithms is at least equal to the round number of distinguishers of SIMON
and RC5 found by classic methods. However, since we can not implement the
proposed quantum algorithms in reality, we do not make sure whether they can
ﬁnd longer distinguishers than classic methods.
The paper is organized as follows. In Sect. 2, we give some preliminaries of the
paper, including notations used, some basic results of linear structures of Boolean
functions, the Bernstein-Vazirani Algorithm, and the quantum algorithm to ﬁnd
linear structures of Boolean functions. In Sect. 3, we give a quantum algorithm
for ﬁnding impossible diﬀerentials and check the algorithm’s validity with appli-
cations to SIMON and RC5. In Sect. 4, we give a quantum algorithm for ﬁnding
zero-correlation linear hulls and check the algorithm’s validity with applications
to SIMON. A short conclusion is given in Sect. 5.
2
Preliminaries
2.1
Notations
The following notations are used in the present paper. Throughout the paper,
we use ⊕to denote the bitwise XOR of two vectors or XOR of two bits.
– F2 = {0, 1}: the ﬁnite ﬁeld with 2 elements.
– Fn
2: the vectors space over F2 with dimension n.
– Bn: the set of all Boolean functions from Fn
2 to F2.
– ei: the vector such that the i-th position equals 1, and other positions equal
0. For example, e1 = [1, 0, 0, . . . , 0]. Specially, ei,j = ei ⊕ej.
2.2
Linear Structures of Boolean Functions
The following deﬁnitions and results are well-known in Boolean functions, and
one can refer to [12] for a comprehensive survey of Boolean functions.
Deﬁnition 1. We say a ∈Fn
2 is a linear structure of a Boolean function f ∈Bn,
if
f(x ⊕a) ⊕f(x) = f(a) ⊕f(0)
holds for all x ∈Fn.
Denote the set of all the linear structures of f as Uf. It is easy to see that Uf is
a linear subspace of Fn
2. More speciﬁcally, let U i
f be the set of all linear structures
with f(a) ⊕f(0) = i, that is, U i
f = {a ∈Fn
2|f(x ⊕a) ⊕f(x) = i for all x ∈Fn
2},

436
H. Chen et al.
and U i
f is usually called the set of i-linear structures of f, i = 0, 1. It is obvious
that Uf = U 0
f ∪U 1
f . Let Di
f,a = {x ∈Fn
2|f(x ⊕a) ⊕f(x) = i}. Then it is easy to
see that a ∈Fn
2 is an i-linear structure of f if and only if Di
f,a = Fn
2.
Deﬁnition 2. For a Boolean function f ∈Bn, the Walsh spectrum is deﬁned as
Sf(ω) = 1
2n

x∈Fn
2
(−1)f(x)⊕ω·x,
where ω · x = ω1x1 ⊕· · · ⊕ωnxn is the usual inner product.
For the Walsh spectrum, Parseval’s relation is well known.
Lemma 1 (Parseval’s relation).
For a Boolean function f ∈Bn, we have

ω∈Fn
2
S2
f(ω) = 1.
Moreover, we introduce some results in the following, which play a vital role
in the analysis of the linear structures of block ciphers using the Bernstein-
Vazirani algorithm [2]. The proof of Lemma 2 and Lemma 3 can be obtained by
consulting [18].
Lemma 2. [18] For any a ∈Fn
2, i ∈F2 and any Boolean function f ∈Bn, the
following equality holds

ω∈Fn
2 , ω·a=i
S2
f(ω) =
|Di
f,a|
2n
,
where | · | means the number of elements in the set.
Lemma 3. [18] For any Boolean function f ∈Bn , let Nf = {ω ∈Fn
2 | Sf(ω) ̸=
0}. Then, for any i ∈F2, the set of the i-linear structure of f equals {a ∈Fn
2 |
ω · a = i, for all ω ∈Nf}.
2.3
The Bernstein-Vazirani Algorithm
We do not introduce basic deﬁnitions of quantum computation here, and one
can refer to the book [35] for fundamental knowledge. The Bernstein-Vazirani
algorithm [2] can ﬁnd the algebraic normal form of a linear Boolean function f(x)
with only one query on the superposition 
x∈Fn
2
1
√
2n |x⟩. For a linear Boolean
function f(x) ∈Bn, there exists exactly one α = (a1, . . . , an) ∈Fn
2, such that
f(x) = α · x = n
i=1 aixi. Then the Bernstein-Vazirani algorithm can ﬁnd α =
(a1, . . . , an) with probability 1.
In the following, we give a brief introduction to the Bernstein-Vazirani algo-
rithm. The illustration of the Bernstein-Vazirani algorithm is given in Fig. 1,
where
– |ψ0⟩= |0⟩n |1⟩;
– |ψ1⟩= 
x∈Fn
2
|x⟩
√
2n
|0⟩−|1⟩
√
2
;

Quantum Algorithm for Finding Impossible Diﬀerentials
437
Fig. 1. Illustration of the Bernstein-Vazirani Algorithm
– |ψ2⟩= 
x∈Fn
2
|x⟩(−1)f(x)
√
2n
|0⟩−|1⟩
√
2
;
– |ψ3⟩= 
z∈Fn
2 (
x∈Fn
2
(−1)f(x)⊕x·z
2n
) |z⟩|0⟩−|1⟩
√
2
;
– |ψ4⟩= 
z∈Fn
2 |α⟩|0⟩−|1⟩
√
2
.
This means we can get the constant α with probability 1 after measuring the
ﬁrst n qubits of |ψ3⟩.
2.4
Finding Linear Structures of Boolean Functions
with the Bernstein-Vazirani Algorithm
As shown in [32,44], one can use the Bernstein-Vazirani algorithm to ﬁnd linear
structures of Boolean functions. As for a Boolean function f ∈Bn, one can also
apply the circuit of the Bernstein-Vazirani algorithm as above. Then the |ψ3⟩
can be rewritten as follows:
|ψ3⟩=

z∈Fn
2
(Sf(z)) |z⟩|0⟩−|1⟩
√
2
.
Hence, the measurement on the ﬁrst n qubits will output a value z with prob-
ability S2
f(z), which means one can always obtain a value in Nf. Repetition of
this procedure many times results in many elements of Nf, which contains a
basis for the dual space of U 0
f with extremely high probability. Note that U 0
f is
a subspace of Fn
2 and U 1
f = {b ⊕x | x ∈U 0
f } for some b ∈Fn
2. Then according
to Lemma 3, one can get the set of i-linear structure of f by solving the linear
system of ω · a = i for all ω ∈Nf.
Theorem 1. [32,44] Suppose α ∈Fn
2 is an i-linear structure of a Boolean func-
tion f ∈Bn. Then Algorithm 1 returns α except a negligible probability.

438
H. Chen et al.
Algorithm 1: A quantum algorithm for ﬁnding linear structures of
Boolean functions
The oracle access of f(x) is given;
Let p(n) be an arbitrary polynomial function of n, and initialize H := Φ;
for j = 1 to p(n) do
Run Bernstein-Vazirani algorithm on f, and obtain a n-bit output
ω = (ω1, ..., ωn) ∈Nf;
Let H = H ∪{ω} ;
Let Si = {x ∈Fn
2 | ω · x = i, ∀ω ∈H}, i = 0, 1;
if S0 = {0} and S1 = ∅then
return “No”;
else
return S0 and S1;
3
A New Quantum Algorithm for Finding Impossible
Diﬀerentials and Its Application to SIMON and RC5
Let Enck(x) be an n-bit block cipher with primitive key k ∈Fm
2 , and Encr
k(x) =
Ekr ◦Ekr−1 ◦· · ·◦Ek1(x) be the r-round encryption of x under the primitive key k,
where ki, 1 ≤i ≤r are round keys deriving by the key schedule algorithm under
the primitive key k. Similarly, Decr
k(x) denotes the corresponding decryption
circuit of Encr
k(x), that is, Decr
k(Encr
k(x)) = x. A pair (Δx, Δy) ∈F2n
2 , where
Δx ̸= 0, Δy ̸= 0, is called an r-round impossible diﬀerential of Enck(x) if
Encr
k(x ⊕Δx) ⊕Encr
k(x) = Δy
does not hold for any x ∈Fn
2 and k ∈Fm
2 .
3.1
A New Quantum Algorithm for Finding Impossible Diﬀerentials
The Idea of Our Approach. We use the idea of “miss-in-the-middle”, which is
widely used to ﬁnd impossible diﬀerential distinguishers of block ciphers. To get
an impossible diﬀerential of Encr
k(x), we divide it into the composition of r1-th
round encryption and r2-th round encryption, i.e. Encr
k(x) = Encr2
k ◦Encr1
k (x),
where r = r1 + r2. Let Fk(x, y) = Encr1
k (x) ⊕Decr2
k (y), and deﬁne the i-th
component function of Fk(x, y) as
fi(x, y, k) = Fk[i](x, y) = Encr1
k [i](x) ⊕Decr2
k [i](y), 1 ≤i ≤n.
We call (a, b, 0) ∈F2n
2
a non-trivial 1-linear structures of fi(x, y, k) if (a, b, 0) is
a 1-linear structure of fi(x, y, k) and a ̸= 0, b ̸= 0.
In the following result, we show that impossible diﬀerentials can be obtained
by ﬁnding non-trivial 1-linear structures of fi(x, y, k).

Quantum Algorithm for Finding Impossible Diﬀerentials
439
Lemma 4. Let Enck(x) be a block cipher. If there exists 1 ≤i ≤n, such that
fi(x, y, k) := Encr1
k [i](x) ⊕Decr2
k [i](y)
has a non-trivial 1-linear structure (a, b, 0), then (a, b) is a (r1+r2)-round impos-
sible diﬀerential of Enck(x).
Proof. Suppose (a, b, 0) is a non-trivial 1-linear structure of fi(x, y, k). Then a ̸=
0 and b ̸= 0, and we need to prove that the equation Encr
k(x) ⊕Encr
k(x ⊕a) = b
does not hold for any x ∈Fn
2 and k ∈Fm
2 .
Note that Encr
k(x) = Encr2
k ◦Encr1
k (x), then the above equation is equivalent
to Encr2
k ◦Encr1
k (x⊕a) = Encr2
k ◦Encr1
k (x)⊕b. By composing Decr2
k (x), we get
Encr1
k (x ⊕a) = Decr2
k (Encr2
k ◦Encr1
k (x) ⊕b). Let y = Encr2
k ◦Encr1
k (x). Then
Encr1
k (x) = Decr2
k (y) and hence we have
Encr1
k (x ⊕a) ⊕Encr1
k (x) = Decr2
k (y ⊕b) ⊕Decr2
k (y).
(1)
However, since (a, b, 0) is a nontrivial 1-linear structure of fi(x, y, k), then
1 = fi(x, y, k) ⊕fi(x ⊕a, y ⊕b, k)
= Encr1
k [i](x) ⊕Decr2
k [i](y) ⊕Encr1
k [i](x ⊕a) ⊕Decr2
k [i](y ⊕b)
for all x, y ∈Fn
2, k ∈Fm
2 . This means equality (1) does not hold for any x, y ∈Fn
2
and k ∈Fm
2 . Therefore, (a, b) is an (r1 + r2)-round impossible diﬀerential of
Enck(x) and we complete the proof.
⊓⊔
Furthermore, 1-linear structures of Enck[i](x) ⊕Deck[i](y), 1 ≤i ≤n can
be found by Algorithm 1. More precisely, the quantum algorithm for ﬁnding
impossible diﬀerentials is given in Algorithm 2.
Algorithm 2: A quantum algorithm to ﬁnd impossible diﬀerentials
Given r = r1 + r2, and the quantum circuit of Encr1
k (x) ⊕Decr2
k (y);
Let p(n) be a polynomial function of n;
for i = 1 to n do
Let H := ∅;
for p = 1 to p(2n) do
Run BV algorithm on Encr1
k [i](x) ⊕Decr2
k [i](y) to get a
(2n + m)-bit output
ω = (w1, · · · , w2n, · · · , w2n+m) ∈NEncr1
k [i](x)⊕Decr2
k [i](y);
Let H = H ∪{(w1, · · · , w2n)};
Solve the system of linear equations to get
S1 = {(x, y) ∈F2n
2
| x ̸= 0 and y ̸= 0 and (x, y) · ω = 1, ∀ω ∈H};
if S1 ̸= ∅then
return S1
i ;
return “No”;
About the Quantum Circuit of Encr1
k [i](x) ⊕Decr2
k [i](y). Note that the
description of the encryption algorithm, the decryption algorithm, and the key

440
H. Chen et al.
schedule are clearly known to attackers. Then an attacker can get the quan-
tum circuit of the block cipher Enck(x), and hence the quantum circuit of
Encr1
k [i](x) ⊕Decr2
k [i](y) for 1 ≤i ≤n, where x, y ∈(Fn
2)2, k ∈Fm
2
are all
seen as variables.
About the Computing Complexity of Algorithm 2. Excepting the quan-
tum circuit cost of Encr1
k [i](x) ⊕Decr2
k [i](y), the only computing cost in Algo-
rithm 2 is that the complexity of solving the system of linear equations
⎡
⎢⎢⎢⎣
w1,1, · · · , w1,n, w1,n+1, · · · , w1,2n
w2,1, · · · , w2,n, w2,n+1, · · · , w2,2n
...
wt,1, · · · , wt,n, wt,n+1, · · · , wt,2n
⎤
⎥⎥⎥⎦·
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
x1
...
xn
y1
...
yn
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
1
...
1
1
...
1
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
where t = p(n) is the number of ω that we get after the inner iteration of
Algorithm 2. The complexity of solving one system of linear equations as above
is approximate O(8n3), and we need to solve n diﬀerent systems as above. Then
the total computation complexity of ﬁnding r-round impossible diﬀerentials of a
block cipher is about O(8rn4) since we need to run Algorithm 2 for every pair
(r1, r −r1), 1 ≤r1 ≤r −1.
About Success Probability. Algorithm 2 can ﬁnd nontrivial 1-linear struc-
tures of fi(x, y, k) := Enck[i]r1(x) ⊕Decr2
k [i](y). According to Theorem 1, if
fi(x, y, k) has a nontrivial 1-linear structure, then by running Algorithm 2, we
can get a nontrivial 1-linear structure except a negligible probability. The we
have the following result.
Theorem 2. Suppose (a, b, 0) is a nontrivial 1-linear structure of Enck[i]r1(x)⊕
Decr2
k [i](y) for some 1 ≤i ≤n. Then Algorithm 2 returns an r-round impossible
diﬀerential (a, b) of the block cipher Enck(x) except a negligible probability.
Comparison with Classical Methods. In the classical setting, besides man-
ual analysis, many methods studied how to get impossible diﬀerentials automat-
ically, such as the U-method [28], the UID-method [33], the WW-method [43].
However, these methods can not consider the details of S-boxes. With the Mixed
Integer Linear Programming (MILP) method, the diﬀerence property of small
S-box and modular can be characterized, which means MILP-based methods can
investigate small S-boxes’ details and ARX ciphers [13,39]. However, the above
methods are all based on the propagation of the diﬀerences and can not evaluate
the eﬀect of key schedules in the single-key setting. Hu et al. solved this prob-
lem by using the propagation of states and then solved the system of equations
Encr
k(x) ⊕Encr
k(x ⊕a) = b with SAT solvers directly [25].
We give comparisons with classical methods mentioned above in Table 1.
Firstly, the biggest advantage of our quantum algorithm is that the input dif-
ference and output diﬀerence are obtained by solving linear equations systems.

Quantum Algorithm for Finding Impossible Diﬀerentials
441
In contrast, all classical methods need to search the input and output diﬀer-
ences in limited spaces. Secondly, our quantum algorithm can also investigate
the details of nonlinear functions of any size, investigate data-dependent oper-
ations, and investigate the eﬀect of key schedules. Furthermore, our algorithm
achieves all these advantages only with the computation cost of solving linear
equations systems. Thus, our quantum algorithm surpasses all classical methods
in the quantum setting.
Comparison with the Previous Quantum Algorithm. Xie and Yang pre-
sented an algorithm for identifying impossible diﬀerentials based on the quan-
tum algorithm by ﬁnding linear structures of Boolean functions [44]. Their idea
is directly applying Algorithm 1 to the components of Encr
k(x). If a nontrivial
i-linear structure a of the j-th component Encr
k(x) is obtained, then it holds
Encr
k[j](x)⊕Encr
k[j](x⊕a) = i for all x ∈Fn
2, k ∈Fm
2 . Therefore, for any vector
b ∈Fn
2 with b[j] = i ⊕1, Encr
k[j](x) ⊕Encr
k[j](x ⊕a) = b does not hold for all x
and k. Hence (a, b) is an r-round impossible diﬀerential.
It is intuitively that our approach ﬁnds longer round impossible diﬀerentials
than Xie and Yang’s approach since our approach is to ﬁnd contradictions in
the middle. For the block cipher Enck(x), suppose r is the longest round of
impossible diﬀerentials that ﬁnds with the algorithm in [44], i.e., we can ﬁnd
r-round i-linear structure of Encr
k[j](x). Moreover, suppose the cipher Enck(x)
achieve full diﬀusion after r′ rounds. Then we can ﬁnd (i ⊕1)-linear structures
of Decr′−l
k
[j](x) for some 1 ≤l ≤r′ −1 with high probability, and hence we
can get a (r + r′ −l)-round impossible diﬀerential of Enck(x). Note that our
algorithm can detect the later (r + r′ −l)-round impossible diﬀerential, which
means we can ﬁnd the longer impossible diﬀerential distinguisher than Xie and
Yang’s method. In particular, we verify this by the application to the SIMON
block cipher family in the present paper.
3.2
Application to SIMON
SIMON is a family of lightweight block ciphers designed by the NSA in 2013
[1]. It is a Feistel cipher with 2n-bit state, where n = 16, 24, 32, 48 and 64.
SIMON2n/mn denotes a SIMON cipher with block size 2n bits and key size mn
bits, where m = 2, 3, 4. In this section, we will show that by applying Algorithm
2 to SIMON, we can ﬁnd the longest impossible diﬀerentials of SIMON in the
quantum setting. Firstly, we give a method to check whether a given vector
c ∈Fn
2 is a i-linear structure of a Boolean function f(x) ∈Bn with SAT solvers,
i = 0, 1.
About the Technique of Checking Linear Structures of Boolean Func-
tions. We use the approach in [25] to check whether a given vector is a linear
structure of a block cipher. For a given block cipher Enck(x), a given vector
c ∈Fn
2, the round number r and the output position j, we can model the follow-
ing system of equations
Encr
k[j](x) ⊕Encr
k[j](x ⊕c) = i

442
H. Chen et al.
in CVC format according to the propagation of states and the key schedule, and
we save the corresponding statements as a ﬁle. Then we use STP, an openly
available solver of the SMT problem, to solve the above problem. The STP will
return “Valid” when the problem has no solution. Otherwise, it will return a
solution to the problem. Thus if the above equation does not have solutions,
then c is a (i ⊕1)-linear structure of Enck[j](x).
We have the following result by applying the technique of checking linear
structures to SIMON32. The proof is given in Appendix A.
Proposition 1. Suppose the round keys are random and independent. Then
every component of the r-th round output of SIMON32 does not have linear
structures for r ≥7.
The above result means that if we apply Xie and Yang’s method to SIMON32,
we can only ﬁnd impossible diﬀerentials of SIMON32 as long as 6 rounds. How-
ever, the longest impossible diﬀerentials of SIMON32 is 11 rounds [42]. Therefore,
the purpose of Algorithm 2 is to remedy the failure mentioned above.
Note that we can not apply Algorithm 2 directly in reality. Instead, we can
verify that the longest impossible diﬀerentials of SIMON can be found by using
Algorithm 2. With the method for checking linear structures of Boolean functions
mentioned above, we can check that for some r-round impossible diﬀerentials
(a, b) of SIMON, there exist r1 and r2 such that (a, b, 0) is a non-trivial 1-linear
structure of Encr1
k [j](x) ⊕Decr2
k [j](y) for 1 ≤j ≤n, r1 + r2 = r. Therefore, we
can obtain (a, b) is an r-round impossible diﬀerential of SIMON using Algorithm
2 in the quantum setting.
SIMON32/64. The longest known impossible diﬀerentials of SIMON32 are 11
rounds. The 11-round impossible diﬀerentials (e32, e7), (e32, e9), (e32, e7,9) are
applied in [42] to analysis SIMON32. We can check that
Enc5
k[i](x) ⊕Enc5
k[i](x ⊕e32) ⊕Dec6
k[i](y) ⊕Dec6
k[i](y ⊕e9) = 0
does not have solutions for (x, y, k) ∈F2n+m
2
when considering the key schedule,
where i ∈{1, 8}. This means (e32, e9, 0) is a non-trivial 1-linear structure of
Enc5
k[i](x) ⊕Dec6
k[i](y), i = 1, 8.
Besides, it can also check that (e32, e7,9, 0) is a non-trivial 1-linear structure
of Enc5
k[8](x) ⊕Dec6
k[8](y) and (e32, e7, 0) is a non-trivial 1-linear structure of
Enc5
k[i](x) ⊕Dec6
k[i](y), i = 8, 15. Therefore, our quantum algorithm, i.e. Algo-
rithm 2, can ﬁnd the above impossible diﬀerentials.
In the same way, we can verify that the longest impossible diﬀerentials of
SIMON48/72, SIMON64/96, SIMON96/96, and SIMON128/128 can be found
using Algorithm 2, which is shown in Table 2.
3.3
Application to RC5
RC5, proposed by Rivest in 1994 [36], is an iterative cipher with 1 ≤r ≤255
(r = 12 being the value originally suggested). The design is based on a kind of

Quantum Algorithm for Finding Impossible Diﬀerentials
443
Table 2. The impossible diﬀerentials found by Algorithm 2 for SIMON
Ciphers
Previous results
Non-trivial 1-linear structure
DR IDs
(a, b, 0)
fi(x, y, k)
SIMON48/72
12
(e48, e1)
(e48, e1, 0)
Enc6
k[1](x) ⊕Dec6
k[1](y)
(e48, e1,18)
(e48, e1,18, 0)
(e48, e1,22)
(e48, e1,22, 0)
(e48, e1,18,22)
(e48, e1,18,22, 0)
SIMON64/96
13
(e33, e8)
(e33, e8, 0)
Enc7
k[32](x) ⊕Dec6
k[32](y)
SIMON96/96
16
(e94, e1)
(e94, e1, 0)
Enc9
k[47](x) ⊕Dec7
k[47](y)
SIMON128/128
19
(e65, e2)
(e65, e2, 0)
Enc11
k [2](x) ⊕Dec8
k[2](y)
-DR: The longest impossible diﬀerentials that we have known for the cipher.
-IDs: The input and output diﬀerence of the known impossible diﬀerential.
-fi(x, y, k) := Encr1
k [i](x) ⊕Decr2
k [i](y), which is deﬁned in Lemma 4.
Feistel network, where one round can be split into two Feistel-like halves, each
of which consists of XOR, variable rotation, and modular addition.
Previous Results. Since the variable rotation operation of RC5 highly depends
on the value of the state, it cannot be handled by the previous automatic search
model until an automatic search tool for the impossible diﬀerentials by consid-
ering the propagation of states was proposed in [25]. In their work, they proved
that the longest impossible diﬀerentials of RC5 is 2.5-round and listed 12 impos-
sible diﬀerentials for RC5-32.
Our Results. According to the longest known impossible diﬀerentials of RC5,
the 2.5-round impossible diﬀerentials (ei,i+16, e17), 1 ≤i ≤12 are applied to
analysis RC5-32. Similarly to the technique in Sect. 3.2, we can check that
Enc1
k[j](x) ⊕Enc1
k[j](x ⊕ei,i+16) ⊕Dec1.5
k [j](y) ⊕Dec1.5
k [j](y ⊕e17) = 0
does not have solutions for (x, y, k) ∈F2n+m
2
when considering the inﬂuence of
round subkeys, where 1 ≤i ≤12 and 1 ≤j ≤16. For example, it means that
(ei,i+16, e17, 0) is a non-trivial 1-linear structure of
Enc1
k[j](x) ⊕Dec1.5
k [j](y), 1 ≤j ≤16,
when (e12,28, e17) is an impossible diﬀerential of RC5. Therefore, we can ﬁnd the
longest impossible diﬀerentials of RC5 by applying Algorithm 2.
4
A Quantum Algorithm for Finding Zero-Correlation
Linear Hulls and Its Application to SIMON
Zero-correlation analysis is introduced by Bogdanov and Rijmen in [5]. For
the round function E of the block cipher Enck(x), a linear correlation of
E, which is denoted by CE(u, v), is deﬁned as CE(u, v)
=
Sv·E(u)
=
1
2n

x∈Fn
2 (−1)v·E(x)⊕u·x. A linear trail U = (u0, u1, . . . , ur) is the concatenation

444
H. Chen et al.
of r correlation of round function, and the correlation of linear trail is deﬁned as
CU = 
r
i=1 CE(ui−1, ui). For α, β ∈Fn
2, the linear hull of Encr
k(x) is deﬁned as
C(α, β) =

U:u0=α,ur=β
CU.
(α, β) is called an r-round zero-correlation linear hull of Enck(x) if C(α, β) = 0.
4.1
A Quantum Algorithm to Find Zero-Correlation Linear Hulls
In this subsection, we propose a quantum algorithm for ﬁnding zero-correlation
linear hulls of symmetric ciphers. Firstly, we have the following result. which is
helpful for identifying zero-correlation linear hulls with the quantum algorithm.
Lemma 5. Let F(x) = F2(F1(x)). If U i
F2[j2] ∩U i⊕1
F −1
1
[j1] ̸= ∅for some i ∈F2,
then (ej1, ej2) is a zero-correlation linear hull of F(x).
Proof. Suppose that there exist i ∈F2 and 0 ≤j2, j1 ≤n −1 such that U i
F2[j2] ∩
U i⊕1
F −1
1
[j1] ̸= ∅. Let c ∈U i
F2[j2] ∩U i⊕1
F −1
1
[j1]. Then F2[j2](x) ⊕F2[j2](x ⊕c) = i and
F −1
1
[j1](x) ⊕F −1
1
[j1](x ⊕c) = i ⊕1. According to Lemma 2, we have

ω·c=i
S2
F2[j2](ω) =
|Di
F2[j2],c|
2n
= 1, and

ω·c=i⊕1
S2
F −1
1
[j1](ω) =
|Di⊕1
F −1
1
[j1],c|
2n
= 1.
Then according to Parseval’s relation (Lemma 1), it holds that

ω·c=i⊕1
S2
F2[j2](ω) = 0, and

ω·c=i
S2
F −1
1
[j1](ω) = 0,
from which we get that CF2(ω, ej2) = 0 when c · ω = i ⊕1, and CF −1
1 (ω, ej1) =
0 when c · ω = i. Furthermore, note that
CF −1
1 (ω, ej1) =

x∈Fn
2
(−1)ej1·F −1
1
(x)⊕ω·x =

x∈Fn
2
(−1)ω·F1(x)⊕ej1·x = CF1(ej1, ω).
Then for the linear hull (ej2, ej1) of F(x), it can be computed as
C(ej1, ej2) =

ω∈Fn
2
CF1(ej1, ω)CF2(ω, ej2) =

ω∈Fn
2
CF −1
1
(ω, ej1)CF2(ω, ej2)
=

ω∈Fn
2 :c·ω=i
CF −1
1
(ω, ej1)CF2(ω, ej2) +

ω∈Fn
2 :c·ω=i⊕1
CF −1
1
(ω, ej1)CF2(ω, ej2)
=

ω∈Fn
2 :c·ω=i
0 × CF2(ω, ej2) +

ω∈Fn
2 :c·ω=i⊕1
CF −1
1
(ω, ej1) × 0
= 0.
This means that (ej2, ej1) is a zero-correlation linear hull of F(x) = F2(F1(x)),
and we complete the proof.
⊓⊔

Quantum Algorithm for Finding Impossible Diﬀerentials
445
The Idea of our Algorithm. Let Enck(x) be a symmetric cipher, and let
r, r1, r2 be integers with r = r1 +r2. The idea of ﬁnding r-round zero-correlation
linear hulls of Enck(x) is as follows. Writing Encr
k(x) = Encr2
k ◦Encr1
k (x),
similar to Algorithm 1, using the Bernstein-Vazirani algorithm, we can ﬁnd linear
structure sets U l
Decr1
k [i](x) and U l⊕1
Encr2
k [j](x) for each 1 ≤i, j ≤n respectively. If
∃c ∈U l
Decr1
k [i](x) ∩U l⊕1
Encr2
k [j](x)
for some l ∈F2, then according to Lemma 5, we can get an r-round zero-
correlation of Enck(x). Our quantum algorithm for ﬁnding zero-correlation linear
hulls is given in Algorithm 3.
Similarly to Theorem 2, it is easy to get Theorem 3 according to Theorem 1
and Lemma 5.
Algorithm 3: A quantum algorithm for zero-correlation linear hulls
Given r = r1 + r2, the oracle access of Encr2
k (x1, . . . , xn), Decr1
k (y1, . . . , yn);
Let p(n) be an arbitrary polynomial function of n;
for j1 = 1, 2, . . . , n do
Let H1 = ∅;
for i = 1, 2, . . . , p(n) do
Run BV algorithm on Encr2
k [j1](x), and obtain a (n + m)-bit output
ω ∈NEncr2
k [j1];
Let H1 = H1 ∪{(ω1, · · · , ωn)};
Solve the systems of linear equations to get
S0
j1 = {x ∈Fn
2 | x · ω = 0, ∀ω ∈H1};
S1
j1 = {x ∈Fn
2 | x · ω = 1, ∀ω ∈H1};
if Sl
j1 ̸= ∅for some l ∈{0, 1} then
for j2 = 1, 2, . . . , n do
set H2 := ∅;
for p = 1 to p(n) do
Run BV algorithm on Decr1
k [j2](x) to get a (n + m)-bit ourput
ω ∈NDecr1
k [j2];
Let H2 = H2 ∪{(ω1, · · · , ωn)};
Solve the systems of linear equations to get
Sl⊕1
j2
= {x ∈Fn
2 | x · ω = l ⊕1, ∀ω ∈H2};
if Sl
j1 ∩Sj2 ̸= ∅then
Return (ej1, ej2)
Return “No” ;
Theorem 3. Suppose U l
Decr1
k [j1](x)∩U l⊕1
Encr2
k [j2](x) = ∅. Then Algorithm 3 returns
an r-round zero-correlation linear hull (ej1, ej2) of the block cipher Encr
k(x)
except a negligible probability.

446
H. Chen et al.
Proof. Let c ∈U l
Decr1
k [j1](x)∩U l⊕1
Encr2
k [j2](x). Then according to Lemma 5, (ej1, ej2)
is a zero-correlation linear hull of Er1+r2
k
(x). According to Theorem 1, the vector
c can by found in U l
Decr1
k [j1](x) and UEncr2
k [j2](x) except a negligible probability.
Thus Algorithm 3 returns (ej1, ej2) except a negligible probability.
⊓⊔
Comparison with the Classical Methods. First of all, the quantum algo-
rithm for ﬁnding zero-correlation linear hulls can investigate the details of non-
linear functions with any size and the eﬀect of the key schedule. Second, the
quantum algorithm can achieve these advantages with the computational cost
of solving linear equation systems. Furthermore, the size of linear equations
systems does not increase as the round number increase. While in the classi-
cal setting, the problems that need to be solved are becoming more and more
complex with the increase of round numbers. The comparison with the classical
methods mentioned above is shown in Table 1. Therefore, the quantum algorithm
also surpasses classical methods.
4.2
Application to SIMON
Apply the above approach to the SIMON block cipher family. We can verify
that some longest known zero-correlation distinguishers can be obtained with
the quantum algorithm.
SIMON32/64. The longest known zero-correlation linear hull of SIMON32 is 11
rounds. In [41,42], it is shown that (e16, e25) is a 11-round zero-correlation linear
hull of SIMON32. We can check that for c = e8, Enc5
k[25](x)⊕Enc5
k[25](x⊕c) =
0, and Dec6
k[16](x)⊕Dec6
k[16](x⊕c) = 1 holds for all x ∈F32
2 and k ∈F64
2 , which
means
c = e8 ∈U 1
Dec6
k[16](x) ∩U 0
Enc5
k[25](x).
Furthermore, we also have
e24 ∈U 1
Dec5
k[16](x) ∩U 0
Enc6
k[25](x),
e1 ∈U 0
Dec6
k[16](x) ∩U 1
Enc5
k[25](x), e17 ∈U 0
Dec5
k[16](x) ∩U 1
Enc6
k[25](x).
Then by running Algorithm 3, we can obtain that (e16, e25) is a zero-correlation
linear hull of SIMON32/64 when considering the key schedule.
In the same way, we can verify that the longest zero-correlation linear hulls of
SIMON48/72, SIMON64/96, SIMON96/96, and SIMON128/128 can be found
using Algorithm 3, which is shown in Table 3.

Quantum Algorithm for Finding Impossible Diﬀerentials
447
Table 3. The zero-correlation linear hulls found by Algorithm 3 for SIMON
Ciphers
Previous results U i
F2[j2] ∩U i⊕1
F −1
1
[j1]
DR ZCLHs
SIMON48/72
12
(e24, e47)
c = e47 ∈U 0
Dec6
k[24](x) ∩U 1
Enc6
k[47](x)
SIMON64/96
13
(e32, e57)
c = e1 ∈U 0
Dec8
k[32](x) ∩U 1
Enc5
k[57](x)
c = e33 ∈U 0
Dec7
k[32](x) ∩U 1
Enc6
k[57](x).
SIMON96/96
16
(e48, e93)
c = e47 ∈U 0
Dec10
k [48](x) ∩U 1
Enc6
k[93](x)
c = e95 ∈U 0
Dec9
k[48](x) ∩U 1
Enc7
k[93](x).
SIMON128/128 19
(e64, e127)
c = e63 ∈U 0
Dec12
k [64](x) ∩U 1
Enc7
k[127](x)
c = e127 ∈U 0
Dec11
k [64](x) ∩U 1
Enc8
k[127](x)
c = e64 ∈U 1
Dec8
k[64](x) ∩U 0
Enc11
k [127](x)
c = e128 ∈U 1
Dec7
k[64](x) ∩U 0
Enc12
k [127](x)
- ZCLHs: The input and output mask of the known zero-correlation linear
hulls.
-U i
F2[j2] ∩U i⊕1
F −1
1
[j1]: According to Lemma 5, if c ∈U i
F2[j2] ∩U i⊕1
F −1
1
[j1] for some
i ∈F2, then (ej1, ej2) is a zero-correlation linear hull of F(x).
5
Conclusion
In the present paper, we propose new quantum algorithms for ﬁnding impossi-
ble diﬀerentials and zero-correlation linear hulls of block ciphers. Compared to
classical methods, the only computational cost of the quantum algorithm is the
solution of linear equation systems, and the size of the linear equation systems
does not increase as the number of rounds increases. Furthermore, the proposed
quantum algorithm obtains the input and output diﬀerences of an impossible
diﬀerential by solving linear equations systems instead of searching in limited
spaces like classical methods.
We provide the SIMON block cipher family and RC5 as examples in the paper
to verify our quantum algorithm’s validity and eﬀectiveness. We show that the
quantum algorithms can ﬁnd some longest known impossible diﬀerentials and
zero-correlation linear hulls of SIMON block cipher when considering the key
schedules. In addition, we verify the 2.5-round impossible diﬀerential of RC5
when considering the key round subkeys with our quantum algorithm. Other
symmetric ciphers can also be applied and tried later. Our original intention is
to develop a good quantum-based tool for ﬁnding distinguishers of symmetric
ciphers that can be used when a large number of the spread of quantum com-
puters are achieved. We will continue to follow up and hope that more quantum
algorithms will be developed to ﬁnd other known, or newly even better, crypt-
analysis methods’ distinguisher. This will be very helpful for the design and
security evaluation of symmetric ciphers in quantum time.

448
H. Chen et al.
Acknowledgements. The authors are grateful to the anonymous reviewers for their
insightful comments. This work was supported partly by the National Key Research
and Development Program of China (Grant No. 2022YFF0604702).
A
Proof of Proposition 1
Proof. We prove this based on the propagation of diﬀerence. Remember that
the round function of SIMON is F(x) = ((S1(x)) ∧(S8(x))) ⊕(S2(x)), and one
round transformation is
(Li, Ri) →(Ri ⊕F(Li) ⊕Ki, Li),
where Ki is the i-th round key.
For an input diﬀerence a ∈F16
2 of SIMON32, we denote the output diﬀerence
set as ΔF (a) = {F(x) ⊕F(x ⊕a) | x ∈F16
2 }. For 1 ≤i ≤16, if v[i] is a constant
for all v ∈ΔF (a), then we call i a determinant position of ΔF (a). Otherwise, i is
called an indeterminant position of ΔF (a), and we use the variable X to denote
the value. Then ΔF (a) can be represented by a vector. For example,
ΔF (e1) = [0, 0, 0, 0, 0, 0, 0, 0, X, 0, 0, 0, 0, 0, 1, X].
Note that for i ∈F2, we always have X ⊕i = X, X ∧i = X. Then for an
input diﬀerence vector a of F(x), we can get the output diﬀerence vector ΔF (a)
according to the following diﬀerence equation
F(x) ⊕F(x ⊕a) = S1(a) ∧S8(x) ⊕S8(a) ∧S1(x) ⊕F(a).
Thus for a given pair (a0, b0) ∈F32
2 , we can compute (ai+1, bi+1) for i ≥0
recursively via
(ai+1, bi+1) := (ΔF (ai) ⊕bi, ai),
until all positions in (ai+1, bi+1) become X.
At last, for a0 ∈F16
2 , we do not need to search all b0 ∈F16
2 . Note that
(a1, b1) = (ΔF (a0) ⊕b0, a0), and X ⊕i = X for i ∈F2. Then we only need to
search b0 in the following set
Sb0
a0 := {v | v[i] ∈F2 for i ∈Sc
a0; v[i] := X for i ∈SX
a0},
where Sc
a0 = {1 ≤i ≤16 | i is a determinant position of ΔF (a0)}, and SX
a0 =
{1 ≤i ≤16 | i is a un-determinant position of ΔF (a0)}. This means if ΔF (a0)
has k determinant positions, then we only need to search 2k b0, which reduce
the search space greatly.
With the above approach, we search all a0 ∈F16
2
and b0 ∈Sb0
a0. There are
(a0, b0) such that the 6-round output has determinant positions, which means
that there exists 1 ≤i ≤32, such that the i-th component of the 6-round output
of SIMON32 has linear structures. However, for all a0 ∈F16
2 and b0 ∈Sb0
a0, every
position of the corresponding 7-round output becomes X. This result means all
the 7-round output components of SIMN32 do not have linear structures. Then
we complete the proof.
⊓⊔

Quantum Algorithm for Finding Impossible Diﬀerentials
449
References
1. Beaulieu, R., Shors, D., Smith, J., Treatman-Clark, S., Weeks, B., Wingers, L.:
The SIMON and SPECK families of lightweight block ciphers. cryptology eprint
archive (2013)
2. Bernstein, E., Vazirani, U.: Quantum complexity theory. SIAM J. Comput. 26(5),
1411–1473 (1997). https://doi.org/10.1137/S0097539796300921
3. Biham, E., Biryukov, A., Shamir, A.: Cryptanalysis of skipjack reduced to 31
rounds using impossible diﬀerentials. J. Cryptol. 18(4), 291–311 (2005). https://
doi.org/10.1007/s00145-005-0129-3
4. Biham, E., Shamir, A.: Diﬀerential cryptanalysis of DES-like cryptosystems. J.
Cryptol. 4(1), 3–72 (1991). https://doi.org/10.1007/BF00630563
5. Bogdanov, A., Rijmen, V.: Linear hulls with correlation zero and linear cryptanal-
ysis of block ciphers. Des. Codes Crypt. 70(3), 369–383 (2012). https://doi.org/
10.1007/s10623-012-9697-z
6. Bonnetain, X., Hosoyamada, A., Naya-Plasencia, M., Sasaki, Yu., Schrottenloher,
A.: Quantum attacks without superposition queries: the oﬄine Simon’s algorithm.
In: Galbraith, S.D., Moriai, S. (eds.) ASIACRYPT 2019. LNCS, vol. 11921, pp.
552–583. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-34578-5_20
7. Bonnetain, X., Leurent, G., Naya-Plasencia, M., Schrottenloher, A.: Quantum lin-
earization attacks. In: Tibouchi, M., Wang, H. (eds.) ASIACRYPT 2021. LNCS,
vol. 13090, pp. 422–452. Springer, Cham (2021). https://doi.org/10.1007/978-3-
030-92062-3_15
8. Bonnetain, X., Naya-Plasencia, M., Schrottenloher, A.: Quantum security analysis
of AES. IACR Trans. Symmetric Cryptol. 2019(2), 55–93 (2019). https://doi.org/
10.13154/tosc.v2019.i2.55-93
9. Bonnetain, X., Naya-Plasencia, M., Schrottenloher, A.: On quantum slide attacks.
In: Paterson, K.G., Stebila, D. (eds.) SAC 2019. LNCS, vol. 11959, pp. 492–519.
Springer, Cham (2020). https://doi.org/10.1007/978-3-030-38471-5_20
10. Brassard, G., Hoyer, P.: An exact quantum polynomial-time algorithm for Simon’s
problem. In: Proceedings of the Fifth Israeli Symposium on Theory of Computing
and Systems, pp. 12–23. IEEE (1997). https://doi.org/10.1109/ISTCS.1997.595153
11. Brassard, G., HØyer, P., Tapp, A.: Quantum cryptanalysis of hash and claw-free
functions. In: Lucchesi, C.L., Moura, A.V. (eds.) LATIN 1998. LNCS, vol. 1380,
pp. 163–169. Springer, Heidelberg (1998). https://doi.org/10.1007/BFb0054319
12. Carlet, C.: Boolean Functions for Cryptography and Coding Theory. Cambridge
University Press, Cambridge (2021). https://doi.org/10.1017/9781108606806
13. Cui, T., Chen, S., Jia, K., Fu, K., Wang, M.: New automatic search tool for impos-
sible diﬀerentials and zero-correlation linear approximations. Cryptology ePrint
Archive (2016). http://eprint.iacr.org/2016/689
14. Daniel, A., Lejla, B., et al.: Initial recommendations of long-term secure post-
quantum systems. PQCRYPTO. EU. Horizon 2020 (2015)
15. David, N., Naya-Plasencia, M.: Quantum impossible diﬀerential attack. Applica-
tions to CLEFIA, AES and SKINNY. Master’s thesis, MPRI (2019). https://hal.
inria.fr/hal-02424410
16. Dong, X., Dong, B., Wang, X.: Quantum attacks on some Feistel block ciphers.
Des. Codes Crypt. 88(6), 1179–1203 (2020). https://doi.org/10.1007/s10623-020-
00741-y
17. Dong, X., Sun, S., Shi, D., Gao, F., Wang, X., Hu, L.: Quantum collision attacks
on AES-like hashing with low quantum random access memories. In: Moriai, S.,

450
H. Chen et al.
Wang, H. (eds.) ASIACRYPT 2020. LNCS, vol. 12492, pp. 727–757. Springer,
Cham (2020). https://doi.org/10.1007/978-3-030-64834-3_25
18. Dubuc, S.: Characterization of linear structures. Des. Codes Crypt. 22(1), 33–45
(2001)
19. Dunkelman, O., Keller, N., Ronen, E., Shamir, A.: Quantum time/memory/data
tradeoﬀattacks. Cryptology ePrint Archive, Report 2021/1561 (2021). https://ia.
cr/2021/1561
20. Grover, L.K.: A fast quantum mechanical algorithm for database search. In: Pro-
ceedings of the Twenty-Eighth Annual ACM symposium on Theory of computing,
pp. 212–219 (1996). https://doi.org/10.1145/237814.237866
21. Hosoyamada, A., Aoki, K.: On quantum related-key attacks on iterated Even-
Mansour ciphers. IEICE Trans. Fundam. Electron. Commun. Comput. Sci. 102(1),
27–34 (2019). https://doi.org/10.1587/transfun.E102.A.27
22. Hosoyamada, A., Sasaki, Yu.: Quantum demiric-selçuk meet-in-the-middle attacks:
applications to 6-round generic Feistel constructions. In: Catalano, D., De Prisco,
R. (eds.) SCN 2018. LNCS, vol. 11035, pp. 386–403. Springer, Cham (2018).
https://doi.org/10.1007/978-3-319-98113-0_21
23. Hosoyamada, A., Sasaki, Yu.: Finding hash collisions with quantum computers by
using diﬀerential trails with smaller probability than birthday bound. In: Canteaut,
A., Ishai, Y. (eds.) EUROCRYPT 2020. LNCS, Part II, vol. 12106, pp. 249–279.
Springer, Cham (2020). https://doi.org/10.1007/978-3-030-45724-2_9
24. Hosoyamada, A., Sasaki, Yu.: Quantum collision attacks on reduced SHA-256 and
SHA-512. In: Malkin, T., Peikert, C. (eds.) CRYPTO 2021. LNCS, vol. 12825, pp.
616–646. Springer, Cham (2021). https://doi.org/10.1007/978-3-030-84242-0_22
25. Hu, X., Li, Y., Jiao, L., Tian, S., Wang, M.: Mind the propagation of states. In:
Moriai, S., Wang, H. (eds.) ASIACRYPT 2020. LNCS, vol. 12491, pp. 415–445.
Springer, Cham (2020). https://doi.org/10.1007/978-3-030-64837-4_14
26. Kaplan, M., Leurent, G., Leverrier, A., Naya-Plasencia, M.: Breaking symmetric
cryptosystems using quantum period ﬁnding. In: Robshaw, M., Katz, J. (eds.)
CRYPTO 2016. LNCS, Part II, vol. 9815, pp. 207–237. Springer, Heidelberg (2016).
https://doi.org/10.1007/978-3-662-53008-5_8
27. Kaplan, M., Leurent, G., Leverrier, A., Naya-Plasencia, M.: Quantum diﬀerential
and linear cryptanalysis. IACR Trans. Symmetric Cryptol. 2016(1), 71–94 (2016).
https://doi.org/10.13154/tosc.v2016.i1.71-94
28. Kim, J., Hong, S., Sung, J., Lee, S., Lim, J., Sung, S.: Impossible diﬀerential
cryptanalysis for block cipher structures. In: Johansson, T., Maitra, S. (eds.)
INDOCRYPT 2003. LNCS, vol. 2904, pp. 82–96. Springer, Heidelberg (2003).
https://doi.org/10.1007/978-3-540-24582-7_6
29. Kuwakado, H., Morii, M.: Quantum distinguisher between the 3-round Feistel
cipher and the random permutation. In: 2010 IEEE International Symposium on
Information Theory, pp. 2682–2685. IEEE (2010). https://doi.org/10.1109/ISIT.
2010.5513654
30. Kuwakado, H., Morii, M.: Security on the quantum-type Even-Mansour cipher. In:
2012 International Symposium on Information Theory and its Applications, pp.
312–316. IEEE (2012)
31. Leander, G., May, A.: Grover meets Simon – quantumly attacking the FX-
construction. In: Takagi, T., Peyrin, T. (eds.) ASIACRYPT 2017. LNCS, vol.
10625, pp. 161–178. Springer, Cham (2017). https://doi.org/10.1007/978-3-319-
70697-9_6

Quantum Algorithm for Finding Impossible Diﬀerentials
451
32. Li, H., Yang, L.: A quantum algorithm to approximate the linear structures of
Boolean functions. Math. Struct. Comput. Sci. 28(1), 1–13 (2018). https://doi.
org/10.1017/S0960129516000013
33. Luo, Y., Lai, X., Wu, Z., Gong, G.: A uniﬁed method for ﬁnding impossible diﬀer-
entials of block cipher structures. Inf. Sci. 263, 211–220 (2014). https://doi.org/
10.1016/j.ins.2013.08.051
34. Matsui, M.: Linear cryptanalysis method for DES cipher. In: Helleseth, T. (ed.)
EUROCRYPT 1993. LNCS, vol. 765, pp. 386–397. Springer, Heidelberg (1994).
https://doi.org/10.1007/3-540-48285-7_33
35. Nielsen, M.A., Chuang, I.L.: Quantum Computation and Quantum Information:
10th Anniversary Edition. Cambridge University Press, Cambridge (2010). https://
doi.org/10.1017/CBO9780511976667
36. Rivest, R.L.: The RC5 encryption algorithm. In: Preneel, B. (ed.) FSE 1994. LNCS,
vol. 1008, pp. 86–96. Springer, Heidelberg (1995). https://doi.org/10.1007/3-540-
60590-8_7
37. SA3, G.: Tr 33.841 study on supporting 256-bit algorithms for 5g (2018).
https://portal.3gpp.org/desktopmodules/Speciﬁcations/SpeciﬁcationDetails.
aspx?speciﬁcationId=3422
38. Santoli, T., Schaﬀner, C.: Using Simon’s algorithm to attack symmetric-key cryp-
tographic primitives (2017). arXiv. 1603.07856, https://doi.org/10.26421/QIC17.
1-2-4
39. Sasaki, Yu., Todo, Y.: New Impossible Diﬀerential Search Tool from Design and
Cryptanalysis Aspects. In: Coron, J.-S., Nielsen, J.B. (eds.) EUROCRYPT 2017.
LNCS, Part III, vol. 10212, pp. 185–215. Springer, Cham (2017). https://doi.org/
10.1007/978-3-319-56617-7_7
40. Simon, D.R.: On the power of quantum computation. SIAM J. Comput. 26(5),
1474–1483 (1997)
41. Sun, L., Fu, K., Wang, M.: Improved zero-correlation cryptanalysis on SIMON. In:
Lin, D., Wang, X.F., Yung, M. (eds.) Inscrypt 2015. LNCS, vol. 9589, pp. 125–143.
Springer, Cham (2016). https://doi.org/10.1007/978-3-319-38898-4_8
42. Wang, Q., Liu, Z., Varıcı, K., Sasaki, Yu., Rijmen, V., Todo, Y.: Cryptanaly-
sis of reduced-round SIMON32 and SIMON48. In: Meier, W., Mukhopadhyay, D.
(eds.) INDOCRYPT 2014. LNCS, vol. 8885, pp. 143–160. Springer, Cham (2014).
https://doi.org/10.1007/978-3-319-13039-2_9
43. Wu, S., Wang, M.: Automatic search of truncated impossible diﬀerentials for word-
oriented block ciphers. In: Galbraith, S., Nandi, M. (eds.) INDOCRYPT 2012.
LNCS, vol. 7668, pp. 283–302. Springer, Heidelberg (2012). https://doi.org/10.
1007/978-3-642-34931-7_17
44. Xie, H., Yang, L.: Using Bernstein–Vazirani algorithm to attack block ciphers. Des.
Codes Crypt. 87(5), 1161–1182 (2018). https://doi.org/10.1007/s10623-018-0510-
5
45. Zhou, Q., Lu, S., Zhang, Z., Sun, J.: Quantum diﬀerential cryptanalysis. Quant.
Inf. Proc. 14, 2101–2109 (2015). https://doi.org/10.1007/s11416-021-00395-x

Memory-Eﬃcient Quantum Information
Set Decoding Algorithm
Naoto Kimura1, Atsushi Takayasu1,2(B)
, and Tsuyoshi Takagi1
1 Graduate School of Information Science and Technology,
The University of Tokyo, Tokyo, Japan
{kimura-naoto077,takayasu-a,takagi}@g.ecc.u-tokyo.ac.jp
2 National Institute of Advanced Industrial Science and Technology, Tokyo, Japan
Abstract. Code-based cryptography is a candidate for post-quantum
cryptography and the security of code-based cryptosystems relate to
the hardness of the syndrome decoding problem. The Information Set
Decoding (ISD) algorithm initiated by Prange is a typical method for
solving the syndrome decoding problem. Various methods have been
proposed that make use of exponentially large lists to accelerate the
ISD algorithm. Furthermore, Bernstein (PQCrypto 2010) and Kachigar
and Tillich (PQCrypto 2017) applied Grover’s algorithm and quantum
walks to obtain quantum ISD algorithms that are much faster than their
classical ones. These quantum ISD algorithms also require exponentially
large lists as the classical algorithms, and they must be kept in quan-
tum states. In this paper, we propose a new quantum ISD algorithm
by combining Both and May’s classical ISD algorithm (PQcrypto 2018),
Grover’s algorithm, and Kirshanova’s quantum walk (PQCrypto 2018).
The proposed algorithm keeps an exponentially large list in the quantum
state just like the existing quantum ISD algorithms, but the list size is
much smaller. Although the proposed algorithm is slower than the exist-
ing algorithms when there is suﬃcient quantum memory, it is fastest
when the amount of quantum memory is limited. Due to the property,
we believe that our algorithm will be the fastest ISD algorithm in actual
quantum computing since large-scale quantum computers seem hard to
realize.
Keywords: code-based cryptography · syndrome decoding problem ·
information set decoding · quantum algorithm
1
Introduction
1.1
Background
Due to the invention of Shor’s quantum algorithm [27] RSA and elliptic curve
cryptosystems can be broken in polynomial time by a quantum computer. It is
an urgent issue to develop practical post-quantum cryptographic schemes before
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 452–468, 2023.
https://doi.org/10.1007/978-3-031-35486-1_20

Memory-Eﬃcient Quantum Information Set Decoding Algorithm
453
a large-scale general-purpose quantum computer is realized. Based on the situ-
ation, NIST is already working on the post-quantum cryptography standardiza-
tion project [23].
Code-based cryptography (e.g., [21,22]) is a candidate of post-quantum cryp-
tography. Indeed, Classic McElice, BIKE, and HQC are listed as Round 4 Can-
didates of the NIST standardization project [24]. The security of code-based
schemes relates to the computational hardness of the syndrome decoding prob-
lem. Here, the syndrome decoding problem is that given a parity check matrix
H ∈F(n−k)×n
2
, syndrome vector s ∈Fn−k
2
, and integer w, the solution is a vector
e ∈Fn
2 that satisﬁes He = s and the Hamming weight of e is w. In order to
make practical use of code-based schemes, it is necessary to properly evaluate
the hardness of the syndrome decoding problem. In 1962, Prange [25] proposed
the Information Set Decoding (ISD) algorithm for solving the syndrome decod-
ing problem. Prange’s ISD algorithm (Prange) can solve the syndrome decoding
problem in time exponential in n and the space complexity polynomial in n.
After the proposal of Prange, faster ISD algorithms have been proposed by
Stern (Stern) [28], May et al. (MMT) [19], Becker et al. (BJMM) [2], May and Oze-
rov (MO) [20], and Both and May1 (BM17 [5] and BM18 [4,6]). These algorithms
accelerate Prange by storing exponentially many vectors in lists. Therefore, as
opposed to Prange, the space complexities of these faster variants are expo-
nential in n. For example, Prange runs in time2 
O(20.1207n), while the BJMM
algorithm runs in time 
O(20.1020n) and space 
O(20.0728n). Moreover, MO, BM17,
and BM18 are faster than BJMM. The fastest BM18 runs in time 
O(20.0885n) and
space 
O(20.0736n). Although the exponential memory may become a bottleneck
in practice [7], these improvement should be theoretically interesting. Esser and
Bellini [10] proposed a syndrome decoding simulator to estimate the running
time of known ISD algorithms with limited memory.
Furthermore, it is known that these “classical” ISD algorithms are combined
with quantum algorithms such as Grover’s algorithm [14] and quantum walks
to obtain “quantum” ISD algorithms. Bernstein [3] proposed a quantum Prange
that runs in time 
O(20.060350n). Similarly, Kachigar and Tillich [15] proposed
a quantum ISD algorithm for Stern, MMT, and BJMM. Among them, quantum
BJMM which is the fastest quantum ISD algorithm runs in time 
O(20.058660n) and
space 
O(20.023413n). Kirshanova [16] claimed that the classical BM17, which is
faster than the classical BJMM, is hard to get quantum speed-up.
Compared with the case of classical ISD algorithms, exponential memory is a
critical problem for quantum ISD algorithms. Indeed, the number of qubits in the
current state-of-the-art physical realization of quantum computers is still ≈100.
To understand the situation more accurately, we brieﬂy recall the practical real-
ization of Shor’s algorithm. Shor’s algorithm is an eﬃcient factorizing algorithm
since it can factor composite numbers N = pq in time O(log3 N). Moreover,
1 See also [9,11] as the follow-up works of the algorithms.
2 We note that the syndrome decoding problem which we study in this paper is full
distance decoding.

454
N. Kimura et al.
the algorithm requires only ≈2 log N qubits. In contrast, the largest compos-
ite number on which physical implementations of Shor’s algorithm worked is
21 = 3 × 7 [1]. The authors [1] also reported that factoring 35 = 5 × 7 is still
infeasible. Although the number of qubits is not the only bottleneck of this
experiment, quantum computers we will have in the future may only be able
to handle the small number of qubits. Therefore, taking into account the prac-
tical implementation possibilities on quantum computers, the improvement of
quantum ISD algorithms with limited space complexity should be an important
research topic. Esser et al. [12] studied the problem and proposed a hybrid ISD
algorithm; however, the work only focuses on Prange.
1.2
Our Contribution
In this paper, we propose a quantum ISD algorithm that is a quantum variant of
BM18 [6] by combining with Grover’s algorithm [14] and Kirshanova’s quantum
walk [16]. The algorithm runs in time 
O(20.059809n) and space 
O(20.0014901n).
Unfortunately, the proposed algorithm is slower than quantum BJMM. On the
other hand, the proposed algorithm requires much less space. We analyze the
minimum time complexities of quantum Prange, Stern, MMT, BJMM when the
amount of space complexity is limited. Then, the quantum BJMM which is the
fastest among known quantum ISD algorithms runs in time 
O(20.060027n) if it
can use space only 
O(20.0014901n). Moreover, we ﬁnd that the proposed algorithm
is the fastest when the space complexity is bounded by 
O(20.0028250n).
1.3
Overview
Due to the explanation so far, keen readers may have the following two questions:
(1) Why do our proposed algorithm is faster than the other quantum ISD algo-
rithms only when the space complexity is limited although the classical BM18
is faster than the other classical ISD algorithms without the restrictions?
(2) How can we construct a quantum variant of BM18 although Kirshanova
claimed that BM18 seems diﬃcult to get quantum speed-up?
The high-level answer is that the proposed algorithm is not a fully quantized
variant of BM18, but its partially quantized variant. Most ISD algorithms start
by preparing 2d lists and search the solution of the syndrome decoding problem,
where each list is a set of vectors. In each step with 2d−d′ lists of the depth d′,
the algorithm updates them to 2d−d′−1 lists of the depth d′ + 1. Finally, the
algorithm searches the solution by combining two lists with the depth d −1.
Brieﬂy speaking, the improvements of classical ISD algorithms so far are due
to the analysis of the number of depth d and the speed-up of updating lists in
each step. BM18 sets the depth d = 4 and makes use of MO’s nearest neighbor
search [20] to accelerate the update.
Kirshanova [16] proposed a quantum walk algorithm for the nearest neighbor
search. Thus, it seems that we can construct a quantum variant of BM18. However,

Memory-Eﬃcient Quantum Information Set Decoding Algorithm
455
the approach becomes less eﬃcient if the depth is large such as d = 4 of BM18 due
to the property of Kirshanova’s quantum walk. To avoid the issue, we construct a
partially quantized variant of BM18. Our proposed algorithm uses four lists of the
depth d = 23. To update the four lists to two lists, we do not use Kirshanova’s
quantum walk but update them classically. We use Kirshanova’s quantum walk
only when we search for the solution of the syndrome decoding problem from
the two lists. In other words, our proposed algorithm does not make use of the
full advantage of BM18. That is why the proposed algorithm improved the other
quantum ISD algorithms only when the space complexity is limited. In contrast,
since we use Kirshanova’s quantum walk only for depth one, we can avoid the
concern claimed by Kirshanova [16] and achieve the quantum speed-up.
1.4
Roadmap
In Sects. 2 and 3, we review the overviews of the classical and quantum ISD
algorithms, respectively. In Sect. 4, we propose our quantum ISD algorithm. In
Sect. 5, we compare our proposed ISD algorithm and the other quantum ISD
algorithms.
Notation. F2 represents a ﬁnite ﬁeld with an order of 2. Let lowercase bold
letters (e.g., e) and uppercase bold letters (e.g., H) denote column vectors and
matrices, respectively. Let e⊤and H⊤denote the transposes of e and H, respec-
tively. Let 0n denote an n-dimensional zero vector. Let Im denote an identity
matrix of the size m × m. For two matrices H1 ∈Fm×n1
2
and H2 ∈Fm×n2
2
, let
(H1 | A2) ∈Fm×(n1+n2)
2
denote their concatenation. For a vector e, let wt(e)
denote the Hamming weight of e. For two vectors e1 and e2 with the same
dimension, let dt(e1, e2) denote the Hamming distance between e1 and e2. For
a function f(n), we use the notation 
O(f(n))) = O(f(n) · (log2 f(n))m) for a
constant m. For a ﬁnite set L, let |L| denote the number of elements in L and let
a
$←−L denote a sampling of a from L uniformly at random. For a real number
x such that 0 ≤x ≤1, let H2(x) := −x log2 x −(1 −x) log2(1 −x) denote the
binary entropy function. Throughout the paper, we set 0 log2 0 = 0. For a real
vector p ∈[0, 1]m such that m
i=1 pi = 1, let H(p) := −m
i=1 pi log2 pi denote
the entropy function.
2
Classical Information Sed Decoding Algorithm
In this section, we review the classical ISD algorithms. We ﬁrst review the def-
inition of the syndrome decoding problem. Then, we review the original ISD
algorithm Prange and summarize the known techniques to accelerate Prange.
3 The depth d = 2 is not an optimized value. If we use the larger d, we may be
able to obtain the faster quantum ISD algorithms. However, we cannot analyze the
time complexity of larger d ≥3 since the numerical analysis of the computational
complexity requires huge time due to more parameters that should be optimized.

456
N. Kimura et al.
2.1
Syndrome Decoding Problem
We ﬁrst review the notion of a linear code, parity check matrix, and syn-
drome. The k-dimensional subspace C on Fn
2 with the minimum distance
d := min {dt(x, y) | x, y ∈C, x ̸= y} is called a binary [n, k, d]-linear code. For
a binary [n, k, d]-linear code, there is a parity check matrix H ∈F(n−k)×n
2
sat-
isfying C = {x ∈Fn
2 | Hx = 0n−k}. For a parity check matrix H ∈F(n−k)×n
2
and vector x ∈Fn
2, s = Hx ∈Fn−k
2
is called a syndrome of x. The task of the
syndrome decoding problem with (H, s, n, k, w) is given a parity check matrix
H ∈F(n−k)×n
2
, syndrome s ∈Fn−k
2
, and integer w ∈N, and ﬁnding a vector
e ∈Fn
2 satisfying
s = He
and
wt(e) = w.
In this paper, we assume that there is at least one solution. Moreover, we study
the case when w = d ≤n · H2
−1(1 −k/n) holds called full distance decoding,
where H2
−1(·) is the inverse function of H2(·). Here, we obtain the value by the
Gilbert-Varshamov bound k/n = 1 −H2(w/n) for n →∞.
The time and space complexity of the ISD algorithm are expressed as 
O(2tn)
and 
O(2sn), respectively, with two constants t and s by ignoring poly(n) factors.
If the space complexity is polynomial in n, we simply write s = 0. The com-
plexity of the ISD algorithm is analyzed in the average case. We use T(ΘISD)
to denote the time complexity of the ISD algorithm, where ΘISD is the set of
all parameters of the ISD algorithm other than n, k, w. Here, all the parameters
in ΘISD are independent of k. To compare each ISD algorithm, the time com-
plexity is determined by maxk,w minΘISD T(ΘISD), where the space complexity
is analyzed by using the same k, w, and ΘISD.
2.2
Basic Information Set Decoding Algorithm: Prange
We provide an overview of Prange. To be precise, the description and analysis
are based on Lee and Brickell [17]. Given (H, s, n, k, w), Prange ﬁrst samples a
permutation matrix P
$←−Fn×n
2
, then ﬁnds a vector ˜e ∈Fn
2 so that P˜e is the
solution of the syndrome decoding problem. When we can ﬁnd a solution with
the permutation matrix P, we say that P is appropriate. Speciﬁcally, Prange
with a parameter4 p ∈{0, . . . , w} consists of the following two steps:
(Step 1: Randomizing a Parity Check Matrix) Sample a permutation matrix
P
$←−Fn×n
2
and set
H := HP.
If there is no singular matrix T ∈F(n−k)×(n−k)
2
such that
T H = ( Q | In−k)
4 To be precise, the original Prange ﬁxes the parameter to p = 0.

Memory-Eﬃcient Quantum Information Set Decoding Algorithm
457
with some matrix Q ∈F(n−k)×k
2
, start the Step 1 from the beginning. Oth-
erwise, set ˜s = Ts.
(Step 2: Finding a Solution) For all
k
p

vectors ˜e′ ∈Fk
2 such that wt(˜e′) = p,
compute
˜e′′ = Q˜e′ + ˜s = Q˜e′ + Ts.
If there is no vector ˜e′′ satisfying wt(˜e′′) = w−p, go back to Step 1. Otherwise,
output
e = P(˜e′ | ˜e′′).
Correctness. Here, we check that the vector e output by Prange is a correct
solution. Due to the deﬁnitions and conditions of H, T, ˜e, and ˜e′′, it holds that
THe = T H(˜e′ | ˜e′′) = ( Q | In−k)(˜e′ | ˜e′′) = Q˜e′ + ˜e′′ = Ts.
Since T is non-singular, it holds that
H(˜e′ | ˜e′′) = H(P(˜e′ | ˜e′′)) = s.
Thanks to the fact that P is a permutation matrix and the conditions of the
Hamming weight wt(˜e′) = p and wt(˜e′′) = w −p in Step 2, it holds that
wt(e) = wt(˜e′) + wt(˜e′′) = w.
Therefore, the vector e is the correct solution of the syndrome decoding problem.
Computational Cost. The average computational cost of Prange is a product
of the expected number of iterations for sampling an appropriate permutation
matrix P and the computational cost of each iteration. The computational cost
of Step 1 is polynomial and that of Step 2 is 
O
k
p

that denotes the number of
vectors ˜e′ satisfying wt(˜e′) = p. Next, we analyze the expected number of iter-
ations. Observe that P−1 is a permutation matrix satisfying (˜e′ | ˜e′′) = P−1e.
When we assume that ˜e′ and ˜e′′ are uniformly random vectors in Fk
2 and Fn−k
2
satisfying wt(˜e′) = p and wt(˜e′′) = w−p, respectively, there are
k
p
n−k
w−p

appro-
priate matrices P. In contrast, there are
n
w

vectors ˜e that are permutations of
e such that wt(e) = w. Thus, the probability P(p) for sampling an appropri-
ate permutation matrix P under the parameter p is P(p) =
k
p
n−k
w−p
n
w
−1.
In other words, the expected number of iterations for sampling an appropriate
permutation matrix P is P(p)−1. Therefore, the average computational cost of
Prange is 
O

P(p)−1 ·
k
p

. When we use the notations ck := k/n, cw := w/n,
and cp := p/n and the approximation
n
r

= 
O(2n·H2(r/n)), the average compu-
tational cost of Prange is

O

P(p)−1 ·
k
p
		
= 
O

n −k
w −p
	−1
·
n
w
	
= 
O

2tPrange(p)·n
,

458
N. Kimura et al.
where
tPrange := H2(cw) −(1 −ck)H2
cw −cp
1 −ck
	
.
Finally,
we
numerically
optimize
the
parameters
ck, cw, cp
and
obtain
maxk minp tPrange(0) = 0.1207.
2.3
Advanced Information Set Decoding Algorithms
Among several techniques to improve Prange, we brieﬂy review Stern’s tech-
nique, MMT’s representation technique, and MO’s nearest neighbor search that are
used by BM18.
Stern ’s Technique. As we observed above, the computational complexity of the
ISD algorithm is expressed as the product of the number of iterations and the
search time. Stern [28] (and its improved variants [8,13]) which may be combined
with [26] used a list storing exponentially many vectors and speeds up the ISD
algorithm by increasing the number of iterations but signiﬁcantly reducing the
search time of each iteration. The technique has also been used by subsequent
works with some modiﬁcations. As a brief explanation, Stern ﬁrst samples a
permutation matrix5 P in Step 1 and searches for ˜e′ as in Prange. Unlike Prange,
instead of searching for ˜e′ from the whole space Fk
2, Stern introduced additional
constraints of the Hamming weights on ˜e′
1 and ˜e′
2 and reduce the search space
of ˜e′. As a result, Stern runs in time 
O(20.1166n) that is faster than Prange. In
contrast, Stern requires a list of the size 
O(20.0312n) to search for ˜e′ eﬃciently.
Representation Technique. MMT [19] is based on Stern and divide ˜e′ into four
sub-vectors. MMT runs in time 
O(20.1116n) with a list of the size 
O(20.0541n).
BJMM [2] is also based on Stern and divide ˜e′ into eight sub-vectors. Furthermore,
BJMM used a representation technique that increases the search space of ˜e′ and
reduces the number of iterations. For a vector v ∈Fn satisfying wt(v) = w, we
call a pair of vectors (v1, v2) ∈(Fn
2)2 a representation of v if v1 and v2, where
the right sub-vector of v1 and left sub-vector of v2 are zero vectors, satisfy
wt(v1) = wt(v2) = w′ ≥w/2 and v = v1 + v2. See Fig. 1 that illustrates the
overview of the representation. There are
 w
w/2

n−w
w′−w/2

representations (v1, v2)
of v satisfying wt(v) = w. The number of representations are larger than the
search space with the simple division v = (v1 | v2). As a result, BJMM runs in
time 
O(20.1020n) with a list of the size 
O(20.0738n).
Nearest Neighbor Search. BM18 [4,6] utilized MO’s γ-nearest neighbor search algo-
rithm [20] that solves the following problem.
Deﬁnition 1 (γ-Nearest Neighbor Search [4,20]). Given two lists L1 and
L2 with elements taken uniformly at random from Fn
2 and satisfying |L1|, |L2| ≤
2λn. Let ℓbe an integer such that 1 ≤ℓ≤n. For a ﬁxed integer 0 ≤ℓ′ ≤n −ℓ,
5 To be precise, the condition of P is not the same as that of Prange.

Memory-Eﬃcient Quantum Information Set Decoding Algorithm
459
Fig. 1. (v1, v2) which is the representation of v
let (x)ℓ= (xℓ′+1, . . . , xℓ′+ℓ) ∈Fℓ
2 denote a sub-vector of x = (x1, . . . , xn) ∈Fn
2.
The task of the (γ, ℓ)-NN problem is ﬁnding all but negligible fraction of the pairs
(x1, x2) ∈L1 × L2 satisfying dt((x1)ℓ, (x2)ℓ) ≤γn for some 0 ≤γ ≤n/2.
MO’s γ-nearest neighbor search algorithm6 can solve the problem in average
time 
O(2n·τNN(λ,δ,γ)). Here, it holds that
τNN(λ, δ, γ) = τ
λ
δ , γ
δ
	
· δ
if it holds that
1
2 · τ
λ
δ , γ
δ
	
< λ
δ < 1 −H2
 γ
2δ

,
τNN(λ, δ, γ) = min {τ1, τ2} ,
where
δ := ℓ
n,
τ(λ, γ) := (1 −γ)

1 −H2
H2
−1(1 −λ) −γ/2
1 −γ
		
,
τ1 = 2λ,
τ2 = max

H2
 γ
2δ

δ + λ, 2λ + H2
γ
δ

δ −δ

.
Thanks to the MO’s algorithm, BM18 runs in time 
O(20.0982n) with a list of the
size 
O(20.0717n).
3
Quantum Information Set Decoding Algorithm
In this section, we summarize an overview of the quantum ISD algorithms. We ﬁrst
review Grover’s algorithm [14] and the quantum walk [16,18]. Then, we review the
quantum ISD algorithm and summarize the computational complexity.
6 To be precise, MO’s proposed γ-nearest neighbor search algorithm [20] does not work
for arbitrary parameters. In such cases, we use other algorithms for solving the
problem. See [4] for the detail.

460
N. Kimura et al.
Grover’s Algorithm. Let E be a ﬁnite set. Given a function f : E →{0, 1},
Grover’s algorithm [14] ﬁnds x ∈E satisfying f(x) = 1. Let ε denote a proportion
of x ∈E satisfying f(x) = 1. Let Tf denote a time for computing f(x). Grover’s
algorithm ﬁnds a solution in average time O(Tf/√ε).
Quantum Walk. Let V and E denote sets of vertices and edges of a d-regular
undirected connected graph G = (V, E), respectively. Here, we say that an undi-
rected graph G is d-regular if all vertices of G has the same degree d. The quan-
tum walk is given G = (V, E) and M ⊂V , then ﬁnding x ∈M. Let TS, TU, and
TC denote the time for constructing G, updating the step of a random walk, and
checking whether x ∈M holds, respectively. Let ε denote a proportion of x ∈V
satisfying x ∈M. Let A denote an adjacency matrix of G and δ denote a spectral
gap of M := (1/d)A, where M denotes a probability matrix in the Markov chain
due to the equal probability of a point on G moving to other adjacent vertices.
Here, the spectral gap is δ := 1−maxλ̸=1 |λ|, where λ is an eigenvalue of M. The
quantum walk runs in time O

TS + 1/√ε ·

(1/
√
δ)F · TU + TC

, where δ > 0
if the Markov chain is acyclic.
Next, we review the notion of a Johnson Graph.
Deﬁnition 2 (Johnson Graph). Let n and r denote integers satisfying r ≤n.
For a list L such that |L| = n, we call graph J(n, r) = (V, E) satisfying the
following three conditions a Johnson graph:
– J(n, r) is undirected.
– Vertices of J(n, r) are subsets of L of the size r. In other words, it holds that
V = {S ⊂L : |S| = r}.
– There is an edge between two vertices S and S′ iﬀ|S ∩S′| = r −1, i.e.,
E = {(S, S′) : |S ∩S′| = r −1}.
Since Johnson graph J(n, r) is an n(n −r)-regular undirected connected graph,
the quantum walk is applicable and a spectral gap of the graph is n/(r(n −r)).
Next, we explain the direct product of the Johnson graph.
Deﬁnition 3 (Direct Product of Johnson Graphs). Let n, r be natural
numbers satisfying r ≤n, and suppose that we are given two Johnson graphs
J(n, r) = (V, E) and J′(n, r) = (V ′, E′). In this case, the direct product J(n, r)×
J′(n, r) is determined by the following (1) and (2) (the same applies to the direct
product of three or more Johnson graphs).
(1) The vertex S is the source of V × V ′. That is, the vertex set is
{(v1, v2) : (v1, v2) ∈V × V ′}.
(2) Let (S1, S2), (S′
1, S′
2)
∈
V × V ′, S
:=
(S1, S2),S′
:=
(S′
1, S′
2). S, S′
is connected by an edge if and only if it satisﬁes “S1
=
S′
1 and
S′
∈
E′” or “S2
=
S′
2 and S
∈
E”. That is, the edge set is
{(S, S′) : (S1 = S′
1 ∧S′ ∈E′) ∨(S2 = S′
2 ∧S ∈E)}.
The direct product of k-Johnson graphs J1(n, r)×· · ·×Jk(n, r) is a connected
undirected graph that is r(n −r)-regular, and its spectral gap δ satisﬁes δ ≤
n/(kr(n −r)).

Memory-Eﬃcient Quantum Information Set Decoding Algorithm
461
Finally, we describe Kirshanova’s quantum walk [16] and its computational
complexity. The algorithm is given the lists L1, L2 ⊂Fn
2 and γ ∈[0, 1/2], then
check whether there exists v1 ∈L1, v2 ∈L2 satisfying dt(v1, v2) = γn. The
average time and space computations of this algorithm are both expressed as

O(2(1−H(p(α,β,γ)+H(q(γ))·n)) [16]. Here, p(α, β, γ) and q(γ) are elements in [0, 1]8
and [0, 1]4, respectively. Let ai and bi denote i-th elements of p(α, β, γ) and p(γ),
respectively, where
a1 = a2 = 1
2 −γ + β + α
4
,
a3 = a4 = γ + β −α
4
,
a5 = a6 = γ + α −β
4
,
a7 = a8 = β + α −γ
4
,
b1 = b2 = 1 −γ
2
,
b3 = b4 = γ
2 .
Here, α, β ∈[0, 1] are parameters such that α = H−1(1 −log2 r), β = H−1(1 −
(3/4) log2 r) by setting the parameter of Johnson graph L1, L2 as r = |L1 ∪L2|
2
3 .
Quantum ISD Algorithm. The quantum walk and the ISD algorithm are
related by the k-list partial sum problem. The k-list subproblem is that, given k-
lists L1, . . . , Lk on Fn
2 with equal number of elements and a function g : L1×. . .×
Lk →{0, 1}, ﬁnding (v1, . . . , vk) ∈L1×· · ·×Lk such that g(v1, . . . , vk) = 1. The
existing ISD algorithms after Prange reduce the amount of time computation by
solving the k-list partial sum problem. By performing a quantum walk on the
direct product of the Johnson graph J1(n, r)×· · ·×Jk(n, r), which is deﬁned by
L1, . . . , Lk and a natural number r that is less than or equal to n, we can obtain
O

TS + (1/

r/n)k · ((1/√r) · TU + TC)

in average time. Note that we assume
n ≥r following the previous study [16], and since k is a constant, we use the
approximation δ ≈1/r.
The ISD algorithm is a random choice algorithm for the permutation matrix
P
$←−Fn×n
2
, and the algorithm must be run until a solution is found. We deﬁne
the function f : Fn×n
2
→{0, 1} of Grover’s algorithm as f(P) = 1 if P is appro-
priate and f(P) = 0 otherwise. Then, we can reduce the time complexity of the
ISD algorithm by using Grover’s algorithm. In other words, Grover’s algorithm
enables us to achieve quadratic speed-up for ﬁnding a good permutation matrix
P. Moreover, we can use quantum walk to search the solution e and construct
Grover’s algorithm.
Computational Cost. When we set Tf as the computational cost to operate
a function f (the computational cost of each trial of the ISD algorithm) and
set P as the probability that a permutation matrix P ←Fn×n
2
is appropriate,
the time complexity of the quantum ISD algorithm is expressed as O(Tf/
√
P).
Bernstein [3] used Grover’s algorithm and developed the quantum Prange with
the time complexity 
O(20.060350n) and space complexity that is polynomial in
n. Kachiga and Tillich [15] applied Grover’s algorithm and the quantum walk
to Stern, MMT, and BJMM. The quantum Stern (resp. MMT, BJMM) runs in time

462
N. Kimura et al.

O(20.059697n) (resp. 
O(20.059037n), 
O(20.058660n)) with space 
O(20.0077375n) (resp.

O(20.015574n), 
O(20.023413n)).
4
Our Proposed Algorithm
In this section, we propose a quantum ISD algorithm that is a half quantumized
variant of BM18. Our proposed algorithm utilizes Grover’s algorithm and the
quantum walk as the other quantum ISD algorithms [3,15]. We explain how to
construct the function f. At ﬁrst, we set seven parameters
p1, p2 ∈{0, . . . , w} ,
ℓ1, ℓ2 ∈{0, . . . , n −k} ,
w(1)
1 , w(2)
1
∈{0, . . . , ℓ1} ,
w(2)
2
∈{0, . . . , ℓ2} ,
with the following four conditions:
(a) p1 ≥p2/2,
(b) ℓ1 + ℓ2 = n −k,
(c) w(1)
1
≥w(2)
1 /2,
(d) w(2)
1
+ w(2)
2
= w −p2,
and the inequality
 p2
p2/2
	 k −p2
p1 −p2/2
	
≥2ℓ1 ·

 w(2)
1
w(2)
1 /2
	
ℓ1 −w(2)
1
w(1)
1
−w(1)
1 /2
	−1
(used in [4, Lemma 5.1]). The function f consists of the following four steps:
(Step 2-1: Elementary Operation) We apply elementary row operations to a
matrix HP and obtain ( Q | In−k), where Q ∈F(n−k)×k
2
. If we can obtain a
matrix of the desired form, there is a non-singular matrix T ∈F(n−k)×(n−k)
2
satisfying
THP = ( Q | In−k).
We set
˜s := Ts.
Step 2-2: Constructing Lists) We construct four lists
• L(0)
1
= {(˜e(0)
1 , Q˜e(0)
1 ) ∈Fk/2
2
× 0k/2 × Fn−k
2
| wt(˜e(0)
1 ) = p1/2},
• L(0)
2
= {(˜e(0)
2 , Q˜e(0)
2 ) ∈0k/2 × Fk/2
2
× Fn−k
2
| wt(˜e(0)
2 ) = p1/2},
• L(0)
3
= {(˜e(0)
3 , Q˜e(0)
3 ) ∈Fk/2
2
× 0k/2 × Fn−k
2
| wt(˜e(0)
3 ) = p1/2},
• L(0)
4
= {(˜e(0)
4 , Q˜e(0)
4
+ ˜s) ∈0k/2 × Fk/2
2
× Fn−k
2
| wt(˜e(0)
4 ) = p1/2}.

Memory-Eﬃcient Quantum Information Set Decoding Algorithm
463
Fig. 2. Overview for constructing ˜e(1)
1
from ˜e(0)
1
and ˜e(0)
2
in the Step 2–3
We further prepare two empty lists L(1)
1
and L(1)
2 . For all n-dimensional vec-
tors in these lists, we divide them into three blocks as the ﬁrst k, middle ℓ1,
and last ℓ2 = n −k −ℓ1 coordinates. For a list L(0)
1 , we use ( Q˜e(0)
1 )ℓ1 and
( Q˜e(0)
1 )ℓ2 to denote the middle block and last block of list vectors, respec-
tively. We also use the same notations for the other lists.
(Step 2–3: Merging Lists) For the tuples of lists (L(0)
1 , L(0)
2 ) and (L(0)
3 , L(0)
4 ), we
apply the classical (w(1)
1 /n, ℓ1)-NN algorithm to the middle ℓ1 coordinates
and obtain two lists
• L(1)
1
=

(˜e(1)
1 , Q˜e(1)
1 ) ∈Fk
2 × Fn−k
2

wt(˜e(1)
1 ) = p1,
wt(( Q˜e(1)
1 )ℓ1) = w(1)
1

,
• L(1)
2
=

(˜e(1)
2 , Q˜e(1)
2
+ ˜s) ∈Fk
2 × Fn−k
2

wt(˜e(1)
2 ) = p1,
wt(( Q˜e(1)
2
+ ˜s)ℓ1) = w(1)
1

.
Figure 2 illustrates the overview for constructing ˜e(1)
1 .
(Step 2–4: Search via Quantum Walk) For the tuple of lists (L(1)
1 , L(1)
2 ) and
(L(1)
1 , L(1)
2 ), we apply the Kirshanova’s quantum walk (w(2)
2 /n, ℓ2)-NN algo-
rithm to the last ℓ2 coordinates and obtain the list
• L(2) =

(˜e′, ˜e′′) ∈Fk
2 × Fn−k
2
 ˜e′′ = Q˜e′ + ˜s, wt((˜e′′)ℓ2) = w(2)
2

.
We deﬁne f(P) = 1 if there is a vector (˜e′, ˜e′′) ∈L(2) such that wt(˜e′) = p2
and wt((˜e′′)ℓ1) = w(2)
1 , and f(P) = 0 otherwise. Figure 3 illustrates the
overview for constructing ˜e′.
Correctness. Since we deﬁned ˜e(0)
1 , ˜e(0)
3
∈Fk/2
2
×0k/2 and ˜e(0)
2 , ˜e(0)
4
∈0k/2 ×Fk/2
2
in Step 2-2, it holds that wt(˜e(1)
1 ) = wt(˜e(1)
2 ) = p1 in Step 2–3. Due to the
condition (d), it holds that wt(˜e′′) = wt((˜e′′)ℓ1) + wt((˜e′′)ℓ2) = w(2)
1
+ w(2)
2
=
w −p2 in Step 2–4. By following the same argument as in Sect. 2, e = P(˜e′ | ˜e′′)
is the correct solution of the syndrome decoding problem.

464
N. Kimura et al.
Fig. 3. Overview for constructing ˜e′, ˜e′′ from ˜e(1)
1
and ˜e(1)
2
in the Step 2–4
Computational Cost. We evaluate the computational cost of the proposed ISD
algorithm. The time complexity T1 for evaluating the function f in Step 2-1
is polynomial in n, and the time complexity for the other steps become the
following T2, T3, T4:
Step 2-2: As the case of the classical BM18 [4,6], it holds that T2 = 
O(S0), where
S0 :=
 k/2
p1/2
	
.
Step 2–3: As the case of the classical BM18 [4,6], we assume that Q˜e(1)
1
and
Q˜e(1) + Ts are distributed over Fn−k
2
uniformly at random. Then, it holds
that
T3 = 
O

2τNN((log2 S0)/n,ℓ1/n,w(1)
1
/n)·n
.
Step 2–4: Based on Kirshanova’s result [16], it holds that
T4 = 
O(2(1−H(p(α,β,γ))+H(q(γ)))·n),
where
S1 :=
 k
p1
	 ℓ1
w(1)
1
	
2−ℓ1,
r := S
2
3
1 ,
α := H−1 
1 −log2(r1/ℓ2)

,
β := H−1

1 −3
4 log2(r1/ℓ2)
	
,
γ := w(2)
2
ℓ2
.
Here, we use the notations deﬁned in Sect. 3.
By deﬁnition, the time complexity for evaluating the function f is roughly
Tf ≈max {T1, T2, T3, T4} .

Memory-Eﬃcient Quantum Information Set Decoding Algorithm
465
As the case of the classical BM18 [4,6], the probability that a permutation matrix
P
$←−Fn×n
2
becomes appropriate is
P =
 k
p2
	 ℓ1
w(2)
1
	 ℓ2
w(2)
2
	n
w
	−1
.
The total time complexity of the proposed algorithm is O(Tf/
√
P).
Next, we evaluate the space complexity of the proposed algorithm. In the
Step 1 and Step 2-1, the space complexity is polynomial in n. As the case of the
classical BM18 [4,6], the space complexities in the Steps 2 and 3 are 
O(S0) and

O(S1), respectively. Based on Kirshanova’s result [16], the space complexity in
the Step 4 is 
O(2(1−H(p(α,β,γ))+H(q(γ)))·n), where we use the values of α, β, γ as
analyzed above.
As we discussed in Sect. 2, when we use the notations 
O(2tn) and 
O(2sn)
to denote the time and space complexities to run the proposed algorithm, it
holds that t = p · max{t1, t2, t3}, s = max{s1, s2}. As we claimed in Sect. 2, we
set w = n · H2
−1(1 −k/n) and use the approximation
n
r

= 
O(2n·H2(r/n)) by
following previous works. When we use the notation cx := x/n for each parameter
x, we have
p = ck · H2
cp2
ck
	
+ cℓ1 · H2
cw(2)
1
cℓ1
	
+ cℓ2 · H2
cw(2)
2
cℓ2
	
−H2(cw),
t1 = ck · H2
cp1
ck
	
,
t2 = τNN

ck · H2
cp1
ck
	
, cℓ1, cw(1)
1
	
,
t3 = 1 −H(p(α, β, γ)) + H(q(γ))),
s1 = ck · H2
cp1
ck
	
,
s2 = ck · H2
cp2
ck
	
+ cℓ1 · H2
cw(1)1
cℓ1
	
−ℓ1.
We numerically analyze the parameters to minimize the time complexity.
When we set
ck = 0.454,
cw = 0.125869,
cp1 = 0.000238090,
cp2 = 0.000475004,
cℓ1 = 0.00150036,
cℓ2 = 0.544500,
cw(1)
1
= 0.00000552440,
cw(1) = 0.0000107316,
cw(2) = 0.125384,
we have the time complexity 
O(20.059809n) and space complexity 
O(20.0014901n),
while the classical BM18 has the time complexity 
O(20.0982n) and space complex-
ity 
O(20.0717n).

466
N. Kimura et al.
Fig. 4. Comparison of the time/space complexity of the quantum ISD algorithms
5
Comparison
As we discussed in Sect. 4, the proposed algorithm runs in time 
O(20.059809n) with
the space 
O(20.0014901n). However, as we discussed in Sect. 3, the quantum Stern,
MMT, and BJMM run in time 
O(20.059697n), 
O(20.059037n), and 
O(20.058660n) with
the space 
O(20.0077375n), 
O(20.015574n), and 
O(20.023413n), respectively. Thus,
the proposed algorithm is slower than the known ones when we focus on the
minimum time complexity with suﬃcient space. Nevertheless, we believe that
the proposed algorithm is valuable since it requires less space complexity. To
justify the claim, we analyze parameters to minimize time complexity of each
algorithm when the space complexity is limited. Figure 4 shows the comparison
of the results.7 Here, the × marks indicate the points, where the time complexity
did not decrease even if we allow larger space complexity. As the ﬁgure indicates,
the proposed algorithm is the fastest when the space complexity is limited. In
particular, when the space complexity is limited by 
O(20.001490n), the proposed
algorithm is the fastest ISD algorithm.
Acknowledgement. This
work
was
partially
supported
by
JSPS
KAKENHI
Grant Number 19K20267 and 21H03440, Japan, and JST CREST Grant Number
JPMJCR2113, Japan.
References
1. Amico, M., Saleem, Z.H., Kumph, M.: Experimental study of Shor’s factoring
algorithm using the IBM Q experience. Phys. Rev. A 100, 012305 (2019)
7 Kirshanova proposed other quantum variants of Stern (Sect. 4 of [16]) that run in
time 
O(20.059922n) (resp. 
O(20.059922n)) with space 
O(20.00897n) (resp. 
O(20.00808n)).
Although we tried to ﬁnd the optimized parameters to obtain the computational
complexity via brute force search, we could not ﬁnd them. Thus, we do not compare
our result with these algorithms.

Memory-Eﬃcient Quantum Information Set Decoding Algorithm
467
2. Becker, A., Joux, A., May, A., Meurer, A.: Decoding random binary linear codes
in 2n/20: How 1 + 1 = 0 improves information set decoding. In: Pointcheval, D.,
Johansson, T. (eds.) EUROCRYPT 2012. LNCS, vol. 7237, pp. 520–536. Springer,
Heidelberg (2012). https://doi.org/10.1007/978-3-642-29011-4 31
3. Bernstein, D.J.: Grover vs. McEliece. In: Sendrier, N. (ed.) PQCrypto 2010. LNCS,
vol. 6061, pp. 73–80. Springer, Heidelberg (2010). https://doi.org/10.1007/978-3-
642-12929-2 6
4. Both, L.: Solvin k-list problems and their impact on information set decoding.
Ph.D. thesis, Ruhr University Bochum, Germany (2018)
5. Both, L., May, A.: Optimizing BJMM with nearest neighbors : full decoding in
22n/21 and MCEliece security. In: The Tenth International Workshop on Coding
and Cryptography (WCC2017) (2017)
6. Both, L., May, A.: Decoding linear codes with high error rate and its impact
for LPN security. In: Lange, T., Steinwandt, R. (eds.) PQCrypto 2018. LNCS,
vol. 10786, pp. 25–46. Springer, Cham (2018). https://doi.org/10.1007/978-3-319-
79063-3 2
7. Carrier, K., Debris-Alazard, T., Meyer-Hilﬁger, C., Tillich, J.: Statistical decod-
ing 2.0: reducing decoding to LPN. In: Agrawal, S., Lin, D. (eds.) Advances in
Cryptology - ASIACRYPT 2022–28th International Conference on the Theory and
Application of Cryptology and Information Security. Lecture Notes in Computer
Science, vol. 13794, pp. 477–507. Springer (2022). https://doi.org/10.1007/978-3-
031-22972-5 17
8. Dumer, I.: On minimum distance decoding of linear codes. In: Proceedings of the
5th Joint Soviet-Swedish International Workshop Information Theory, pp. 50–52
(1991)
9. Esser, A.: Revisiting nearest-neighbor-based information set decoding. IACR Cryp-
tol. ePrint Arch, 1328 (2022)
10. Esser, A., Bellini, E.: Syndrome decoding estimator. In: Hanaoka, G., Shikata, J.,
Watanabe, Y. (eds.) Public-Key Cryptography - PKC 2022–25th IACR Interna-
tional Conference on Practice and Theory of Public-Key Cryptography, Proceed-
ings, Part I. Lecture Notes in Computer Science, vol. 13177, pp. 112–141. Springer
(2022). https://doi.org/10.1007/978-3-030-97121-2 5
11. Esser, A., May, A., Zweydinger, F.: Mceliece needs a break - solving mceliece-1284
and quasi-cyclic-2918 with modern ISD. In: Dunkelman, O., Dziembowski, S. (eds.)
Advances in Cryptology - EUROCRYPT 2022–41st Annual International Confer-
ence on the Theory and Applications of Cryptographic Techniques, Proceedings,
Part III. Lecture Notes in Computer Science, vol. 13277, pp. 433–457. Springer
(2022). https://doi.org/10.1007/978-3-031-07082-2 16
12. Esser, A., Ramos-Calderer, S., Bellini, E., Latorre, J.I., Manzano, M.: Hybrid
decoding - classical-quantum trade-oﬀs for information set decoding. In: Cheon,
J.H., Johansson, T. (eds.) Post-Quantum Cryptography - 13th International Work-
shop, PQCrypto 2022, Proceedings. Lecture Notes in Computer Science, vol. 13512,
pp. 3–23. Springer (2022). https://doi.org/10.1007/978-3-031-17234-2 1
13. Finiasz, M., Sendrier, N.: Security bounds for the design of code-based cryp-
tosystems. In: Matsui, M. (ed.) ASIACRYPT 2009. LNCS, vol. 5912, pp. 88–105.
Springer, Heidelberg (2009). https://doi.org/10.1007/978-3-642-10366-7 6
14. Grover, L.K.: A fast quantum mechanical algorithm for database search. In: Miller,
G.L. (ed.) Proceedings of the Twenty-Eighth Annual ACM Symposium on the
Theory of Computing. pp. 212–219. ACM (1996)

468
N. Kimura et al.
15. Kachigar, G., Tillich, J.-P.: Quantum information set decoding algorithms. In:
Lange, T., Takagi, T. (eds.) PQCrypto 2017. LNCS, vol. 10346, pp. 69–89. Springer,
Cham (2017). https://doi.org/10.1007/978-3-319-59879-6 5
16. Kirshanova, E.: Improved quantum information set decoding. In: Lange, T., Stein-
wandt, R. (eds.) PQCrypto 2018. LNCS, vol. 10786, pp. 507–527. Springer, Cham
(2018). https://doi.org/10.1007/978-3-319-79063-3 24
17. Lee, P.J., Brickell, E.F.: An observation on the security of McEliece’s public-key
cryptosystem. In: Barstow, D., Brauer, W., Brinch Hansen, P., Gries, D., Luckham,
D., Moler, C., Pnueli, A., Seegm¨uller, G., Stoer, J., Wirth, N., G¨unther, C.G. (eds.)
EUROCRYPT 1988. LNCS, vol. 330, pp. 275–280. Springer, Heidelberg (1988).
https://doi.org/10.1007/3-540-45961-8 25
18. Magniez, F., Nayak, A., Roland, J., Santha, M.: Search via quantum walk. SIAM
J. Comput. 40(1), 142–164 (2011)
19. May, A., Meurer, A., Thomae, E.: Decoding random linear codes in ˜O(20.054n).
In: Lee, D.H., Wang, X. (eds.) ASIACRYPT 2011. LNCS, vol. 7073, pp. 107–124.
Springer, Heidelberg (2011). https://doi.org/10.1007/978-3-642-25385-0 6
20. May, A., Ozerov, I.: On computing nearest neighbors with applications to decoding
of binary linear codes. In: Oswald, E., Fischlin, M. (eds.) EUROCRYPT 2015.
LNCS, vol. 9056, pp. 203–228. Springer, Heidelberg (2015). https://doi.org/10.
1007/978-3-662-46800-5 9
21. McEliece, R.J.: A public-key cryptosystem based on algebraic coding theory. Deep
Space Netw. Prog. Rep. 44, 114–116 (1978)
22. Niederreiter, H.: Knapsack-type cryptosystems and algebraic coding theory. Probl.
Control Inf. Theory 15(2), 159–166 (1986)
23. NIST. https://csrc.nist.gov/Projects/post-quantum-cryptography/post-quantum-
cryptography-standardization/Call-for-Proposals
24. NIST. https://csrc.nist.gov/Projects/post-quantum-cryptography/round-4-submi
ssions
25. Prange, E.: The use of information sets in decoding cyclic codes. IRE Trans. Inf.
Theory 8(5), 5–9 (1962)
26. Schroeppel, R., Shamir, A.: A T = O(2n/2), s = O(2n/4) algorithm for certain
NP-complete problems. SIAM J. Comput. 10(3), 456–464 (1981)
27. Shor, P.W.: Algorithms for quantum computation: discrete logarithms and factor-
ing. In: 35th Annual Symposium on Foundations of Computer Science, pp. 124–134.
IEEE Computer Society (1994)
28. Stern, J.: A method for ﬁnding codewords of small weight. In: Cohen, G.D., Wolf-
mann, J. (eds.) Coding Theory and Applications, 3rd International Colloquium,
Proceedings. Lecture Notes in Computer Science, vol. 388, pp. 106–113. Springer,
Berlin (1988). https://doi.org/10.1007/BFb0019850

Cryptographic Protocols

CSI-SharK: CSI-FiSh
with Sharing-friendly Keys
Shahla Atapoor1
, Karim Baghery1(B)
, Daniele Cozzo1,2
,
and Robi Pedersen1
1 imec-COSIC, KU Leuven, Leuven, Belgium
{shahla.atapoor,karim.baghery,daniele.cozzo,robi.pedersen}@kuleuven.be
2 IMDEA Software Institute, Madrid, Spain
daniele.cozzo@imdea.org
Abstract. CSI-FiSh is one of the most eﬃcient isogeny-based signa-
ture schemes, which is proven to be secure in the Quantum Random
Oracle Model (QROM). However, there is a bottleneck in CSI-FiSh in
the threshold setting, which is that its public key needs to be gener-
ated by using k −1 secret keys. This leads to very ineﬃcient threshold
key generation protocols and also forces the parties to store k −1 secret
shares. We present CSI-SharK, a new variant of CSI-FiSh that has more
Sharing-friendly Keys and is as eﬃcient as the original scheme. This is
accomplished by modifying the public key of the ID protocol, used in
the original CSI-FiSh, to the equal length Structured Public Key (SPK),
generated by a single secret key, and then proving that the modiﬁed
ID protocol and the resulting signature scheme remain secure in the
QROM. We translate existing CSI-FiSh-based threshold signatures and
Distributed Key Generation (DKG) protocols to the CSI-SharK setting.
We ﬁnd that DKG schemes based on CSI-SharK outperform the state-of-
the-art actively secure DKG protocols from the literature by a factor of
about 3, while also strongly reducing the communication cost between
the parties. We also uncover and discuss a ﬂaw in the key generation
of the actively secure CSI-FiSh based threshold signature Sashimi, that
can prevent parties from signing. Finally, we discuss how (distributed)
key generation and signature schemes in the isogeny setting are strongly
parallelizable and we show that by using C independent CPU threads,
the total runtime of such schemes can basically be reduced by a factor
C. As multiple threads are standard in modern CPU architecture, this
parallelizability is a strong incentive towards using isogeny-based (dis-
tributed) key generation and signature schemes in practical scenarios.
Keywords: Isogeny-based cryptography · DKG · Threshold Schemes ·
CSIDH
1
Introduction
Following Shor’s attack [33] on the Factoring and Discrete Logarithm (DL)
problems, researchers started exploring post-quantum cryptographic techniques
to construct primitives and protocols that can be secure in the presence of
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 471–502, 2023.
https://doi.org/10.1007/978-3-031-35486-1_21

472
S. Atapoor et al.
quantum adversaries. One of these areas is isogeny-based cryptography, which
was initially proposed by Couveignes [11] and by Rostovtsev and Stolbunov [30,
36]. These proposals use hardness assumptions based on isogenies between ordi-
nary elliptic curves, but were strongly weakened by the quantum attack of Childs,
Jao and Soukarev [10] a few years later. Later proposals by Jao and De Feo [24]
(SIDH) and Castryck et al. [8] (CSIDH) use supersingular elliptic curves instead
of ordinary ones. While the attack by Childs et al. is still applicable to the latter,
the authors of [8] managed to push the secure parameter set back into practical
sizes. SIDH on the other hand was recently broken by a diﬀerent attack, designed
by Castryck and Decru [7] and further improved in subsequent works [25,29].
These attacks do not apply to CSIDH-based schemes.
Based on CSIDH, two signature schemes called SeaSign [15] and CSI-FiSh [4]
have been proposed. The basic version of both these signature schemes are
based on the same ID protocol that was introduced in [30] and both papers
discuss extending the public keys in order to reduce the soundness error rate
by using multiple secret keys. To allow this extension, the underlying lan-
guage in the ID protocol is changed, and a witness for the Multi-Target Group
Action Inverse Problem (MT-GAIP) [4,15] is proven. The fundamental diﬀerence
between SeaSign and CSI-FiSh is that in the latter, the authors have performed
a record computation of the underlying ideal-class group, which allows uniform
sampling and canonical representations of ideals. As a result, unlike SeaSign,
CSI-FiSh does not need to rely on rejection sampling and was therefore one of
the ﬁrst practical signature scheme based on isogenies, with signing times just
below 3 s in the basic version of the scheme and a signature size of 1.8 KB. With
an extended public key, signing can even be done in a few hundred milliseconds
(Table 3 in [4]). Other practical isogeny-based signature schemes include [22,39]
and later [16]. Recently, Baghery, Cozzo and Pedersen [2] presented a new exten-
sion of the basic ID protocol used in CSI-FiSh. They extend the public key to a
Structured Public Key (SPK), which is generated using a single secret key and
a set of public integers. This allows working with a larger challenge space and
eﬃciently proving the actual witness, rather than the diﬀerences of two curves,
as in MT-GAIP. However, to extract the single secret key, they require a Trusted
Third Party (TTP) to generate the keys. Furthermore, to prove the security of
their ID protocol, they rely on a new computational assumption, so-called Ck-
Vectorization Problem with Auxiliary Inputs (Ck-VPwAI, see Deﬁnition 3.2),
which its hardness recently was analysed in [19].
By virtue of its ﬂexibility, CSI-FiSh is used as the base scheme to build var-
ious isogeny-based protocols, such as threshold signatures [12,17], lossy signa-
tures [20], and forward secure ones [32]. Due to a wide range of applications (e.g.
in blockchain), Threshold Signature Schemes (TSSs) have received more atten-
tion in recent years. Such schemes allow distributing the secret key into shares
among multiple parties or devices, such that only a set of authorized parties can
jointly sign a message to produce a single signature. Key recovery attacks on TSSs
require more eﬀort than the non-threshold ones, as the adversary has to attack
more than one device or party simultaneously. A large amount of eﬀort has been
put on constructing threshold versions of classic schemes based on discrete log-

CSI-SharK: CSI-FiSh with Sharing-friendly Keys
473
arithms and RSA. Most of these schemes could be integrated with a Distributed
Key Generation (DKG) protocol, which was initially proposed by Pedersen in [27].
A secure version of it along with robustness guarantees was proposed by Gennaro
et al. [23]. On the other hand, research on threshold isogeny-based signatures is
very young. In 2020, De Feo and Meyer [17] proposed a threshold version of CSI-
FiSh using Shamir secret sharing. The protocol is almost as eﬃcient as a CSI-FiSh
signature but only passively secure. Cozzo and Smart [12] then proposed Sashimi,
the ﬁrst actively secure threshold signature scheme with abort based on CSI-FiSh,
that uses replicated secret sharing. Sashimi uses Zero-Knowledge (ZK) proofs to
achieve active security, resulting in the rather elevated signing times of around
5 min for two parties. The cost of their DKG step is even higher, but was not esti-
mated by the authors. Later, Beullens et al. proposed CSI-RAShi [3], an actively
secure DKG protocol for CSI-FiSh using Shamir secret sharing. By introducing a
new primitive called piecewise veriﬁable proofs, the authors manage to reduce the
cost of generating public keys to about 18 s per party. Still, Sashimi [12] as well as
CSI-RAShi [3], when used for extended public keys, remain quite ineﬃcient to be
used in practice.
1.1
Our Contributions and Techniques
CSI-SharK Signature Scheme. As our initial contribution, we present CSI-SharK
in Sect. 3, a new variant of CSI-FiSh [4] that has more Sharing-friendly Keys.
To this end, we slightly modify the ID protocol used in CSI-FiSh [4] and then
prove that the modiﬁed ID protocol and the resulting signature scheme remain
secure in the QROM. Our main modiﬁcation is to change the public key of
CSI-FiSh to a SPK, (E0, E1 = [c1 · sk]E0, · · · , Ek−1 = [ck−1 · sk]E0), which is
generated using a single secret key sk and k −1 public integers c1, · · · , ck−1,
instead of using k −1 distinct secret keys. Then we prove that the modiﬁed
ID protocol is special sound for the language of MT-GAIP, and Honest-Veriﬁer
Zero-Knowledge (HVZK) for the language of Ck-VPwAI. Roughly speaking, the
modiﬁed ID protocol achieves to the best of the two ID protocols presented in [4]
and [2]. In comparison with [4], the modiﬁed ID protocol has only a single secret
key but needs to rely on an additional hardness assumption. In comparison with
the one proposed in [2], it does not require a TTP, but only proves knowledge of a
witness for the MT-GAIP, which is suﬃcient for building a signature scheme. We
turn the modiﬁed ID protocol into a signature scheme in the standard manner
using the Fiat–Shamir transform [21]. Our results and analysis show that, due
to having a SPK and a single secret key, CSI-SharK is a suitable replacement for
CSI-FiSh and achieves the same eﬃciency as the original scheme, without the
need of storing multiple secret keys. The real advantage of CSI-SharK however
manifests itself when it is used to build threshold schemes, which can be much
more eﬃcient than in the CSI-FiSh setting.
Threshold Schemes. As a next contribution, we show how to distribute key gen-
eration schemes and signatures using structured public keys. To this end, we
ﬁrst review the state-of-the-art DKG schemes, i.e. the passively secure scheme by

474
S. Atapoor et al.
De Feo and Meyer [17], as well as the actively secure Sashimi [12] and CSI-
RAShi [3]. We notice that there is a ﬂaw in the current description of the DKG
protocol in Sashimi that can lead to an attack, which could allow an adversary to
prevent an honest party from using its share to sign. We then describe a version
of Sashimi that we use as an actively secure full-threshold signature scheme with
abort, preventing the attack. Finally, we discuss optimizations of these state-of-
the-art schemes to act as a baseline for comparison with our proposed schemes.
Then, in Sect. 5, we show how using structured public keys decreases the over-
all computational and communication cost of DKG protocols. We then describe
ways to further reduce the computational cost of these protocols. The ﬁnal pro-
tocols have a computational cost decreased by about a factor 3, when compared
to the most optimal implementations without a SPK, while furthermore reduc-
ing the communication cost between the diﬀerent parties by a signiﬁcant factor,
which depends on the public key size. In the full version [1], we also discuss how to
translate the signatures from [3,12,17] to our setting. We note that the computa-
tional cost of the signing algorithm is not decreased by using SPKs, but generally
threshold protocols based on CSI-SharK (e.g. threshold signatures) are more eﬃ-
cient and we also discuss some optimizations that are applicable to both settings.
Parallel Computations in Isogeny-Based Schemes. Due to the round-robin com-
putational structure in isogeny-based threshold schemes, the total latency of dis-
tributed protocols can be huge. Because of this issue, based on the estimations
done in Sashimi [12], signing could take about 5 min with two parties. As the ﬁnal
contribution, presented in Sect. 6, we observe that many of the computations in
Table 1. Comparison of our proposed CSI-SharK-based key generation schemes and
the existing ones based on CSI-FiSh, for n parties, a public key with k −1 elliptic
curves and a security parameter λ. Next to displaying the number of necessary secret
sharings (Sec. Shar.), we present the leading term in the computational cost of the
public key generation (PKGen) in terms of group actions as well as the leading term
in communication cost per party (Comm.) in bits (we assume k ≫n). The latter two
mainly depend on the parameters k, n and λ, as well as log p, the size of the underlying
prime ﬁeld Fp. We further display the hardness assumptions underlying the security
of the diﬀerent schemes. These assumptions are formally introduced in Sect. 2 and
Sect. 3. TTP: Trusted Third Party, DKG: Distributed Key Generation, SSS: Shamir
Secret Sharing, FT: Full-Threshold secret sharing.
(Distributed) Key Generation Schemes from Isogenies
[17]
Section 5.1 Sashimi [12]
Section 5.2
CSI-RAShi [3]
Section 5.3
Adversary:
Passive
Passive
Active
Active
Active
Active
TTP
k −1 SSS
TTP
1 SSS
DKG
k −1 FT
DKG
1 FT
DKG
k −1 SSS
DKG
1 SSS
k −1
k −1
5knλ
n(k + 2
√
k)λ
4knλ
n(k + 2
√
k)λ
Setup by:
Sec. Shar.:
PKGen:
Comm.:
1
2k log p
1
2 log p
kλ log p
(k + 1
2
√
kλ) log p kλ(8n + log p) (k + 1
2
√
kλ) log p
Hardness
Assumpt.:
MT-GAIP,
P-DDHA
MT-GAIP,
P-DDHA,
Ck-VPwAI
MT-GAIP,
dGAIP
MT-GAIP,
dGAIP,
Ck-VPwAI
MT-GAIP,
dGAIP
MT-GAIP,
Ck-dGAIP,
Ck-VPwAI

CSI-SharK: CSI-FiSh with Sharing-friendly Keys
475
both non-threshold and threshold signatures built from isogenies are paralleliz-
able. In light of this observation, we propose a general parallel execution strategy
to be used in the cases that one (as in CSI-FiSh or CSI-SharK) or multiple par-
ties (as in TSSs or DKG protocols) need to compute multiple independent elliptic
curves, e.g. [x1]E0, . . . , [xr]E0. For the single party case, the computation simply
uses the diﬀerent cores (or threads) of a multi-core CPU to compute a subset of
curves, while in the multi-party case, diﬀerent parties further can run their com-
putations in parallel. Using the proposed strategy and several optimizations, we
could signiﬁcantly reduce the runtimes of CSI-SharK, CSI-FiSh, and their thresh-
old variants, making them quite practical. We give an overview of the overall com-
plexities in Table 1.
2
Preliminaries
In this section, we brieﬂy review secret sharing schemes, commitment schemes
and isogeny-based cryptography. For an introduction to sigma protocol and
(threshold) signatures, we refer the reader to the full version of paper [1].
Secret Sharing Schemes. We deﬁne an (n, t)-threshold access structure as a
set consisting of n players, where each player holds shares of a secret, so that
any subset of t or more players can reconstruct this secret. We assume that all
players are Probabilistic Polynomial Time (PPT) Turing machines. We revisit
two well known ways for realizing a (n, t)-threshold access structure that we
will use in our distributed signature schemes, namely the Shamir Secret Sharing
(SSS) scheme [31] and the Full-Threshold Secret Sharing (Full-TSS) scheme.
Unlike the traditional versions that are deﬁned over a prime ﬁeld, we will use
them over an integer ring ZN.
Shamir Secret Sharing. In (n, t)-Shamir secret sharing, a common polynomial
f(x) ∈ZN[x] of degree t −1 is chosen, such that the secret s is set to be its
constant term, i.e. s = f(0). Each party Pi for i ∈{1, · · · , n} is assigned the
secret share si = f(i) Then any subset S ⊂{1, . . . , n} of at least t parties can
reconstruct the secret s via Lagrange interpolation by computing s = f(0) =

i∈S si · LS
0,i, where
LS
0,i := 
j∈S\{i}
j
j−i
(mod N),
are Lagrange basis polynomials evaluated at 0. Any subset of less than t parties
are not able to ﬁnd s = f(0), as this is information-theoretically hidden, even
given t −1 shares. Since we will be working over the ring ZN with N composite,
the diﬀerence j −i of any two elements in i, j ∈S must be invertible modulo N.
If q is the smallest prime factor of N, it is enough to require that n < q.
Full-Threshold Secret Sharing. In a Full-TSS, a secret s ∈ZN is additively shared
among P1, . . . , Pn. Speciﬁcally, each party Pi holds a random share si ∈ZN such
that s = s1 + · · · + sn mod N. Clearly, all parties are required to recover the
secret s and thus a Full-TSS realizes a (n, n)-threshold access structure. Since
the shares are random, up to n−1 parties cannot get any information about the
secret s, as the remaining share information-theoretically hides it.

476
S. Atapoor et al.
Init: Given (Init, Pi, B) from all parties, this initializes a commitment functionality
from party Pi to the parties in B. This is shown with Fi,B
Commit, if B is a singleton
set B = {j} then we write Fi,j
Commit, and if B = P \ {i} then we write FPi
Commit.
Commit: On input of (Commit, id, data) from parties Pi and (Commit, id, ⊥) from
all parties in B the functionality stores (id, ⊥).
Open: On input of (Commit, id) from all players in B∪{i} the functionality retrieves
the entry (id, data) and returns data to all parties in B.
Fig. 1. The Functionality FCommit
Commitment Schemes. In our protocols, we assume parties have access to
a commitment functionality FCommit, which allows one party to commit, and
later open the value to a set of parties. We assume the opened value is only
available to the targeted receivers and is sent over a secure communication
channel. The description of FCommit is provided in Fig. 1, which can be easily
implemented in the random oracle model. This gives the commitment properties
such as extractability and equivocability that are crucial for our security proofs.
Isogeny-Based Cryptography. Isogenies are rational maps between two ellip-
tic curves ϕ : E →E′, that are also homomorphisms with respect to the natural
group structure of E and E′ [14,35]. For simplicity, we introduce isogenies as an
abstract cryptographic concept in this section and focus only on the high-level
ideas that allow us to build cryptographic protocols on top of them. For a more
thorough introduction, we refer the reader to [8] and [14].
Isogeny computations can be abstracted as a group G acting freely and tran-
sitively on a set E [11]. In the case relevant to this work, E denotes the set of
supersingular elliptic curves over a ﬁnite ﬁeld Fp where p is a large prime. G
denotes the ideal-class group Cl(O), where O is an order of the quadratic imag-
inary ﬁeld Q(√−p), isomorphic to the Fp-rational endomorphism ring EndFp(E)
elliptic curves E ∈E. Isogenies are uniquely deﬁned through the kernels of the
ideals in O. Throughout this work, we assume that the class group, as well as
a generating ideal g of it are known. In that case, we can deﬁne this group
action as [·] : ZN ×E →E, where N is the size of the class group; asymptotically
N ≈√p [8,34]. As an example for the group action, we could identify the isogeny
ϕ : E →E′ with some element a ∈ZN, such that E′ = [a]E holds. This means
that the separable part of the isogeny ϕ has the kernel 
α∈ga ker α. Note that
[a]([b]E) = [a+b]E. In cryptographic settings, this group action comes equipped
with some hardness assumptions, that are also diﬃcult for quantum computers.
Deﬁnition 2.1 (Group action inverse problem (GAIP) [8,15]).
Given
two supersingular elliptic curves E, E′ ∈E over the same ﬁnite ﬁeld Fp and with
EndFp (E) ≃EndFp (E′) ≃O, ﬁnd a ∈ZN, such that E′ = [a]E.
Deﬁnition 2.2 (Decisional GAIP [3,37]).
Given a triple ([a]E, [b]E, [c]E),
where E ∈E, with the same Fp-rational endomorphism ring, decide whether
[c]E = [a + b]E or not.

CSI-SharK: CSI-FiSh with Sharing-friendly Keys
477
KeyGen(1sec): Given E0, the secret and public key are generated as follows:
1. For i = 1, . . . , k −1, sample ai ←ZN and compute Ei = [ai]E0.
2. Return sk = (a1 . . . , ak−1), pk = (E0, . . . , Ek−1).
Sign(sk, m): To sign a message m, the signer performs
1. For i = 1, . . . , tS: sample bi ←ZN, and set Ebi = [bi]E0.
2. Set (d1, . . . , dtS) = H(Eb1, . . . , EbtS ∥m).
3. For i = 1, . . . , tS: set ri = bi −sign(di)a|di| (mod N).
4. Return {(ri, di)}tS
i=1.
Verify({(ri, di)}tS
i=1, m, pk): To verify a signature {(ri, di)}tS
i=1 on m, one performs:
1. For i = 1, . . . , tS: compute E′
bi = [ri]Edi.
2. (d′
1, . . . , d′
tS) = H(E′
b1, . . . , E′
btS ∥m).
3. If (d1, . . . , dtS) = (d′
1, . . . , d′
tS) then return valid, else output invalid.
Fig. 2. CSI-FiSh Signature Scheme [4].
Isogenies are eﬃciently computable, but hard to invert. As such, they are
a powerful tool to build post-quantum cryptographic protocols. One of these
schemes is the isogeny-based signature scheme CSI-FiSh proposed by Beullens,
Kleinjung and Vercauteren [4]. The basic version of CSI-FiSh is based on an ID
protocol with binary challenges initially proposed in [37]. CSI-FiSh starts with
the special elliptic curve E0 : y2 = x3 + x. Public keys are created with the
action of an element a ∈ZN on E0. The owner of the public key E = [a]E0
proves knowledge of the secret key a by a standard binary sigma protocol. This
is then turned into a signature scheme using the Fiat–Shamir heuristic [21].
Note that the class group enjoys a symmetry around the elliptic curve E0, as
the elliptic curve [−a]E0 is Fp-isomorphic to the quadratic twist of [a]E0, a map
that is easily computable without any extra information. As a result, we can
implicitly include the twist in the public key and extend the challenge space to
{−1, 0, 1}, so that the soundness error rate is reduced to 1
3.
To further reduce the number of repetitions needed to achieve a security
level of 2sec, the authors of [4] used a technique proposed in [15] and enlarged
the public key by using multiple secret keys (a1, . . . , ak−1) and an extended
public-key of the k −1 associated elements. The resulting number of repetitions
is tS = ⌈sec log2k−1 2⌉, although one can reduce tS a little bit by choosing a
‘slow’ hash function. We present the CSI-FiSh in Fig. 2. Note that H : {0, 1}⋆→
{−(k−1), . . . , k−1}tS⌈log(2k−1)⌉represents a hash function modeled as a random
oracle. We simply denote the twist of a curve Ea as E−a.
The extension of the
public key in this way leads to a change in the underlying language, and the
prover now must prove that it knows a secret s ∈ZN such that Ej = [s]Ei for
some pair of elliptic curves appearing in the public key list. As a result, CSI-FiSh
relies on the hardness of a multi-target version of GAIP, called MT-GAIP.
Deﬁnition 2.3 (MT-GAIP [4,15]).
Given k supersingular elliptic curves
E0, E1, . . . , Ek ∈E over Fp with the same Fp-rational endomorphism ring, ﬁnd
a ∈ZN, such that Ei = [a]Ej for some i, j ∈{0, . . . , k} with i ̸= j.

478
S. Atapoor et al.
CSI-FiSh is sEUF-CMA secure in the QROM under the MT-GAIP assump-
tion [4]. For later reference, we also introduce the Power-Decision Diﬃe-Hellman
(Power-DDHA) assumption deﬁned in [17], which is used in some of our schemes.
Deﬁnition 2.4 (Power-DDHA). Given an element E ∈E and a ∈ZN. The
a-Power-DDHA problem is: given (a, E, [s]E, F), where s is uniformly sampled
from ZN and where F ∈E, either sampled from the uniform distribution on E
or F = [as]E, decide which distribution F is drawn from.
For details on the quantum security of CSIDH-based schemes, see [6,8,9,28].
3
CSI-FiSh with Structured Public Keys
In this section, we revisit a diﬀerent way of extending the public key (of the ID
protocol) used in CSI-FiSh, where instead of sampling a total of k −1 diﬀerent
secrets a1, . . . , ak−1, we use k −1 diﬀerent multiples of the same secret key a
to generate the public key. The idea to build such an ID protocol for proving
the knowledge of a was ﬁrst proposed by Baghery et al. [2], but needed a TTP
to generate the public key in order to guarantee the correct structure. Such a
structured public key (SPK) consists of an integer set Ck−1 = {c0 = 0, c1 =
1, c2, . . . , ck−1} and a set of elliptic curves1 {Ei = [cia]E0}i=0,...,k−1. In their
ID protocol, to ensure extractability of the witness modulo a composite number
N, the integer set Ck−1 has to be an exceptional set [5,13], as deﬁned below.
When E0 is the same special base curve as in CSI-FiSh, the authors further
introduce the notation of superexceptional sets [2]. The latter case is referred to
as a symmetric hard homogeneous space.
Deﬁnition 3.1 ((Super-)Exceptional set).
An exceptional set modulo N
is a set Ck−1 = {c0, . . . , ck−1} ⊆ZN, where the pairwise diﬀerence ci −cj of all
elements ci ̸= cj is invertible modulo N. A superexceptional set modulo N is an
exceptional set Ck−1 = {c0, . . . , ck−1}, where also the pairwise sum ci + cj of all
elements ci, cj (including ci = cj) is invertible modulo N.
The hardness of obtaining the secret key from a structured public key relies on
the following computational problem which is deﬁned in [2].
Deﬁnition 3.2 ((c0, c1, · · · , ck−1)-Vectorization Problem with Auxiliary
Inputs
(Ck−1-VPwAI)).
Given an element E
∈
E
and the pairs
(ci, [cix]E)k−1
i=1 , where Ck−1 = {c0 = 0, c1 = 1, c2, . . . , ck−1} is an exceptional
set, ﬁnd x ∈ZN.
The ID protocol of Baghery et al. [2] is designed to allow the prover to eﬃciently
prove the knowledge of the secret key a, while relying on the fact that the public
key indeed has the desired structure. The authors of [2] solve this problem by
letting either a TTP generate these keys, or alternatively by relying on compu-
tationally rather heavy well-formedness proofs for proving the correctness of the
key generation. We refer to the original source for more details.
1
For simplicity, we include E0 in the public-key. Note that [0] simply denotes the
neutral element of the group action.

CSI-SharK: CSI-FiSh with Sharing-friendly Keys
479
Setup: Given E0, sample a public (super)exceptional set Ck−1
=
{c1
=
1, c2, · · · , ck−1}; Sample a ←ZN and for i = 1, . . . , k −1 set Ei = [cia]E0;
Output (Ck−1, E0, E1, . . . , Ek−1).
Prover: Given (a, (Ck−1, E0, · · · , Ek−1)) the prover samples b ←ZN, and sends
Eb = [b]E0 to the veriﬁer.
Veriﬁer: Given (Ck−1, E0, · · · , Ek−1) and Eb the veriﬁer samples a random chal-
lenge d ←{0, . . . , k −1} and sends it to the prover.
Prover: Given (a, Ck−1, d) the prover computes r = b −cd · a mod N and sends it
to the veriﬁer.
Veriﬁer: Given ((Ck−1, E0, · · · , Ek−1), Eb) and r, return Eb
?= [r]Ed.
Fig. 3. The Modiﬁed Identiﬁcation Protocol with Structured Public Keys.
3.1
The Modiﬁed Identiﬁcation Protocol
In this section, we construct an ID protocol that achieves the best of the two ID
protocols constructed in [2] and [4]. The protocol of [2] uses structured public
keys and soundness relies on the Ck−1-VPwAI (Deﬁnition 3.2), while the protocol
from [4] uses non-structured (extended) public keys and soundness relies on
MT-GAIP. Note that in order to guarantee that the public keys in the former
actually have the correct structure, the scheme either relies on trusted third
parties generating the keys or on heavy proofs of well-formedness.
The idea behind our new ID protocol is to work with structured public keys,
but nevertheless base the soundness of the protocol on MT-GAIP. The advantage
of relying on MT-GAIP, rather than on Ck−1-VPwAI for soundness, is that we
do not need a TTP, or heavy proofs of well-formedness, to generate the public
keys. The SPK thus becomes a perk for the prover rather than a requirement
for the protocol. The idea is simple, yet powerful: the prover ﬁrst samples a
secret key a ←ZN and a public (super-)exceptional set Ck−1 = {c0 = 0, c1 =
1, c2, · · · , ck−1}, then generates and publishes the SPK (E0, E1, . . . , Ek−1), where
Ei = [cia]E0 for i = 1 . . . , k −1. Next, instead of proving knowledge of a witness
a ∈ZN for Ck−1-VPwAI, i.e. the secret key underlying the SPK, as done in [2]
and requiring the public key to be well-formed, the prover proves a witness for
MT-GAIP, i.e. that it knows a secret s ∈ZN such that Ej = [s]Ei for some pair
of elliptic curves appearing in the public key, as in [4]. This prevents the prover
from cheating, even if the public key would not actually be correctly structured.
In the case where the public key would indeed be correctly structured, knowing
a witness to the MT-GAIP instance also allows to extract a witness for Ck−1-
VPwAI. With this, we have circumvented the need to prove well-formedness
of the SPK, a main shortcoming of the protocol in [2]. In comparison to the
protocol in [4], our ID protocol has the advantage, that it only needs a single
public key to be stored, independent of the size of the public key.
Interestingly, our new ID protocol is HVZK assuming that Ck−1-VPwAI is
hard. Figure 3 summarizes the resulting ID protocol.

480
S. Atapoor et al.
Note that similar to the ID protocol used in CSI-FiSh, the key generation can
be done by the prover. Therefore a malicious prover might choose to publish a
public key that is not structured. However, based on MT-GAIP, without knowing
s, it would be still hard for an adversarial prover to prove that it knows s ∈ZN
such that Ej = [s]Ei for some pair of elliptic curves in the public key. On
the other hand, relying on the Ck−1-VPwAI from Deﬁnition 3.2, we know that
obtaining a from an honestly generated SPK is computationally hard. As a result,
there is no real reason for the prover to generate its public key maliciously. In
fact, due to several eﬃciency reasons that we will discuss in later sections, the
prover is rather incentivized to sample the public key honestly.
Theorem 3.1. The ID protocol presented in Fig. 3 is complete, special sound
with soundness error rate 1
k for the language of MT-GAIP (Deﬁnition 2.3), and
HVZK for the language of Ck−1-VPwAI (Deﬁnition 3.2).
Proof. The proof is analogous to the security proofs of the ID protocols discussed
in [4] and [2]. However, similar to the ID protocol proposed in [2], we additionally
rely on the hardness of Ck−1-VPwAI [2], but without the need for a TTP.
Completeness. The honest prover knows the secret a for the public key {Ei =
[cia]E0}i=0,...,k−1, where Ck−1 = {c0 = 0, c1 = 1, c2, · · · , ck−1} is a public (super-
)
exceptional set. The honest veriﬁer checks if Eb
?= [r]Ed. For an honestly gener-
ated proof, it holds that [r]Ed = [b −cda]Ed = [b −cda][cda]E0 = [b]E0 = Eb.
Honest-Veriﬁer Zero-Knowledge. We construct a simulator that acts as fol-
lows: given the honestly sampled d, it samples r randomly from ZN; then sets
Eb = [r]Ed and returns the transcript (Eb, d, r). In both the real and the sim-
ulated transcripts, r and Eb are sampled uniformly at random, yielding indis-
tinguishable distributions. Note that relying on the Ck−1-VPwAI, obtaining the
secret key a from an honestly generated SPK is computationally hard.
Special Soundness. Given two valid transcripts of the Σ-protocol, an eﬃcient
extraction algorithm extracts a witness as follows: Let (Eb, d, r) and (Eb, d′, r′) be
two acceptable transcripts of the protocol, where d ̸= d′, consequently r ̸= r′ (for
non-zero a). From the veriﬁcation equation, one can conclude that [r]Ed = [r′]Ed′
and consequently Ed = [r′ −r]Ed′, which allows the extractor to obtain r′ −r
as a solution to the MT-GAIP.
⊓⊔
Remark 3.1. Note that the ID protocol used in CSI-Fish [4] is special sound
and HVZK for the language of MT-GAIP, and under a trusted key generation
the ID protocol proposed in [2] is special sound and HVZK for the language of
Ck−1-VPwAI. The issue with the former is that it requires k −1 independent
secret keys, and the concern with the later is that it needs a TTP to generate
the keys. Our ID protocol achieves to the best of both, as it has a single secret
key, and does not require a TTP, while relying on both assumptions.

CSI-SharK: CSI-FiSh with Sharing-friendly Keys
481
KeyGen(1n): Given E0, the secret key and public are generated as follows:
1. Sample a ←ZN;
2. Generate a public (super)exceptional set Ck−1 = {c1 = 1, c2, · · · , ck−1};
3. Given E0, for each ci ∈Ck−1 set Ei = [cia]E0.
4. Return sk = a, pk = (E0, E1, . . . , Ek−1).
Sign(sk, m): To sign a message m, the signer performs
1. For i = 1, 2, . . . , tS: sample bi ←ZN, and set Ebi = [bi]E0.
2. Set (d1, . . . , dtS) = H(Eb1, . . . , EbtS ∥m).
3. For i = 1, 2, . . . , tS: set ri = bi −cdi · a (mod N).
4. Return {(ri, di)}tS
i=1.
Verify({(ri, di)}t
i=1, m, pk): To verify a signature {(ri, di)}tS
i=1 on m, one performs:
1. For i = 1, 2, . . . , tS: compute E′
bi = [ri]Edi.
2. (d′
1, d′
2, . . . , d′
tS) = H(E′
b1, . . . , E′
btS ∥m).
3. If (d1, d2, . . . , dtS) = (d′
1, d′
2, · · · , d′
tS) then return valid, else output invalid.
Fig. 4. CSI-SharK Signature Scheme.
3.2
NIZK Argument and Signature Scheme
Our ID protocol from Fig. 3 can be transformed into a non-interactive zero-
knowledge argument or a signature scheme in the standard ways using the Fiat–
Shamir transform [21]. To this end, we introduce the hash function H : {0, 1}∗→
{0, 1}tS⌈log2 k⌉, modelled as a random oracle, where tS denotes the number of rep-
etitions needed in the protocol. For simplicity, we will only present the resulting
signature. The NIZK argument can be constructed with a similar technique, and
its security can be proven in a similar way as in Lemma 3.1 in [2]. We present our
signature scheme in Fig. 4, and call it CSI-SharK, which stands for CSI-FiSh
with Sharing-friendly Keys.
Theorem 3.2. Under MT-GAIP (Deﬁnition 2.3) and Ck−1-VPwAI (Deﬁni-
tion 3.2), when H is modelled as a (quantum) random oracle, then the CSI-SharK
signature scheme described in Fig. 4 is sEUF-CMA secure.
Proof. From the security of the resulting NIZK argument (similar to Lemma 3.2
in [2]), we know that the modiﬁed ID protocol has special soundness and unique
responses. Then, by Theorem 25 in [18], it is a quantum argument of knowledge.
Moreover, since the modiﬁed protocol has λ bits of min-entropy, from Theorem
22 of [18], this shows that the CSI-SharK obtained via Fiat–Shamir is sEUF-
CMA in the QROM.
⊓⊔
Optimizations and Eﬃciency. Our basis protocol has a soundness error rate
1
k. By choosing the unique base curve E0 we can again increase this to a sound-
ness error rate of
1
2k−1 by also using the twists. This implies that we need
tS = ⌈sec log2k−1 2⌉protocol repetitions to reach a desired target soundness
error of 2−sec. To guarantee that the protocol is still HVZK and the SPK does
not reveal any information about the secret key, we need to restrict Ck−1 to

482
S. Atapoor et al.
superexceptional sets. As a result, the runtimes of our protocols are exactly the
same as the respective versions from [4] or [2]. The same holds for the public-key
and proof or signature sizes.
3.3
Proof of Commitments and Well-Formedness of SPK
In our actively secure distributed protocols, to guarantee that the parties follow
the protocol, they are asked to commit to their secret shares and prove knowledge
of the committed value. Furthermore, the parties will be required to prove that
they indeed act with their committed secret value on some given elliptic curve
to prove the correctness of generating/updating the SPK. More precisely, each
party will need to prove knowledge of a witness s to the following language,
which we deﬁne for arbitrary j and a public (super)exceptional set Cj with
integer elements {c1 = 1, c2, · · · , cj}.
Lj :=
⎧
⎪
⎨
⎪
⎩
	
(F0, F ′
0, E1, E′
1, . . . , Ej, E′
j, Cj := {c1 = 1, c2, · · · , cj}), s

:
(F ′
0 = [s]F0)  	j
i=1 (E′
i = [cis]Ei)

⎫
⎪
⎬
⎪
⎭
.
(1)
In other words, since we set c1 = 1, then the prover would need to prove in a
zero-knowledge manner that it knows a unique witness s for
– an instance of the GAIP, when j = 0.
– two simultaneous instances of the GAIP, when j = 1.
– an instance for conjunction of the GAIP and Ck−1-VPwAI, when j = k −1.
The ﬁrst item can be proven using the basic ID protocol from CSI-FiSh [4],
while for the next two items we use the techniques of conjunctive Σ-protocols. We
ZK.P1((F0, F ′
0, E1, E′
1, . . . , Ej, E′
j), {c1 = 1, c2, · · · , cj}): The prover does:
1. b ←ZN; Set ˆF0 ←[b]F0.
2. For i = 1, . . . , j compute ˆEi ←[cib]Ei. Output ( ˆF0, ˆE1, . . . , ˆEj).
ZK.V1(F0, F ′
0, ˆF0, E1, E′
1, ˆE1, . . . , Ej, E′
j, ˆEj): The veriﬁer acts as below:
1. If Ei ̸= E0 for any i ∈{1, . . . , j} then sample d ←{0, 1} and output it.
2. Else sample d ←{−1, 0, 1} and output it.
ZK.P2((F0, F ′
0, ˆF0, E1, E′
1, ˆE1, . . . , Ej, E′
j, ˆEj), d, s): Given d, the prover computes
r ←b −d · s mod N, and outputs r.
ZK.V2((F0, F ′
0, ˆF0, E1, E′
1, ˆE1, . . . , Ej, E′
j, ˆEj), {c1 = 1, c2, · · · cj}, d, r): The
veriﬁer
returns 1 if all the following checks pass, and otherwise returns 0.
1. If d = −1 return

[r]F ′
0
t = ˆF0

∧j
i=1

[cir]E′
i
t = ˆEi

.
2. If d = 0 return

[r]F0 = ˆF0

∧j
i=1

[cir]Ei = ˆEi

.
3. If d = 1 return
[r]F ′
0 = ˆF0
j
i=1
[cir]E′
i = ˆEi .
Fig. 5. The HVZK Argument for Proving the Commitment and the Well-formedness
of Structured Public Keys

CSI-SharK: CSI-FiSh with Sharing-friendly Keys
483
present the underlying Σ-protocol in Fig. 5, which is obtained by the conjunction
of the basic ID protocol with the well-formedness proof for structured public
keys, presented in Section 5.1 of [2]. The resulting Σ-protocol can be considered
as an extension of the Σ-protocol presented in Figure 7 of [12], to work with
structured public keys. We also note that since in a structured public key c1 = 1,
these two proofs coincide in the cases j = 0 and j = 1. Similar to [12], we consider
two variants of the presented Σ-protocol, one when F0 = E1 = . . . = Ej = E0
which we call the Special case, and the other when this condition does not hold,
which is called the General case. Next, we prove the security of the presented
Σ-protocol.
Theorem 3.3. The interactive argument in Fig. 5 is correct, has soundness
error rate 1
2 in the General case and soundness error rate 1
3 in the Special case,
and is computational HVZK for the language Lj assuming GAIP and Cj-VPwAI.
Proof. The proof is given in the full version of paper [1].
⊓⊔
Soundness Error Rate. The above theorem showed that the basic interactive
argument has soundness error rate 1/2 in the General case and 1/3 in the Special
case. Therefore, to achieve a target soundness error rate 2−sec for a given security
parameter sec, we need to repeat the protocol sec (resp. ⌈sec log3 2⌉) times.
Making the Protocol Non-interactive. The Σ-protocol in Fig. 5 is an HVZK
public coin interactive argument and can be turned into a NIZK argument in
the standard manner using a hash function G : {0, 1}∗→{0, 1}sec in the General
case, or G : {0, 1}∗→{−1, 0, 1}⌈sec log3 2⌉in the Special case. Using a ‘slow’ hash
function for G, as in the case of CSI-FiSh, which is 2h times slower than a normal
hash function, we can reduce the number of repetitions to tGeneral
ZK
= sec −h or
tSpecial
ZK
= ⌈(sec −h) log3 2⌉, respectively.2 In the resulting NIZK argument, we
denote the prover and veriﬁer by NIZK.P and NIZK.V .
Both the prover and the veriﬁer need to compute a total of (j + 1)tZK group
actions throughout this protocol, ignoring the cost of the other operations, as
they are negligible in comparison to group action computations. The output size
of the proof is composed of the hash output and the responses. The former has a
size of approximately tGeneral
ZK
bits (log2 3tSpecial
ZK
≈tGeneral
ZK
), while the latter consists
of tZK elements from ZN, depending on either the Special or the General case. It
is interesting to note that the proof size does not depend on j.
Lemma 3.1. The two algorithms NIZK.P
and NIZK.V
constitute a non-
interactive zero-knowledge quantum proof of knowledge in the quantum random
oracle model.
Proof. Since the group action is free [8,11], our schemes have superlogarithmic
collision entropy as deﬁned in [38] and unique responses as deﬁned in [18]. Using
2 As an example, we can choose h = 16 for sec = 128 as is done in [2] and [4]. This
gives tGeneral
ZK
= 112 for the General case and tSpecial
ZK
= 71 for the Special case.

484
S. Atapoor et al.
the results from Theorem 3.3, [38] implies ZK against quantum attackers while
[18], along with a challenge space superpolynomial in sec implies that our pro-
tocol is a quantum proof of knowledge.
⊓⊔
4
Key Generation Based on CSI-FiSh
In this section, we review the current isogeny-based key generation protocols for
generating the public key of CSI-FiSh. In particular, we look at the key genera-
tion of two threshold signature schemes presented in [12,17], and a Distributed
Key Generation (DKG) protocol presented in [3]. We also discuss their extension
to larger public keys in the same manner as is needed to extend e.g. CSI-FiSh [4].
We also show that the actively secure threshold signature scheme Sashimi
proposed by Cozzo and Smart [12], in its general form for Replicated Secret
Sharing (RSS), has a security ﬂaw in the key generation. We present a sample
attack that ends up giving an honest party a wrong share after the key generation
step, without the party realizing. As such, the honest party is rendered unable
to sign, resulting in incorrect signatures, even if the signing protocol is correctly
executed. We will therefore only focus on the full-threshold version of Sashimi,
which is immune to the described attack.
KeyGen: Given E0, a TTP acts as follows:
1. For i = 1, . . . , k −1, sample secrets si ←ZN and use Shamir secret sharing
to split the shares si into subshares si,j for j = 1, . . . , n.
2. Distribute s1,j, . . . , sk−1,j privately to party Pj.
3. Output the public key pk := (E0, . . . , Ek−1), where Ei = [si]E0.
Fig. 6. The key generation protocol of De Feo and Meyer’s TSS [17].
At the end, we also discuss some optimizations to the DKG protocols, which
allow parties to stagger the computations so as to minimize the idle time in the
distributed protocol and thus optimize the overall runtime. This approach was
brieﬂy mentioned in [17] and we show that it can also be used in the actively
secure case by staggering the zero-knowledge proofs needed for active security.
We end each subsection by giving the optimal runtime for n parties by using this
type of public key extension and also give an estimate of the communication costs
between the parties. The sequential runtimes are simply expressed in terms of
group actions. Regarding the communication costs, we note that elliptic curves
over ﬁnite ﬁelds in the CSIDH setting can be expressed with a single parameter
of size log p. As N = #Cl(O) ≈√p, elements in ZN can be expressed with
approximately 1
2 log p bits. Finally, we choose sec = 1
4 log p.3
3 Choosing the security parameter this high is meant to reﬂect the classical security
of CSIDH-based protocols against meet-in-the-middle attacks, cf. [8] and sources
therein for more details.

CSI-SharK: CSI-FiSh with Sharing-friendly Keys
485
4.1
Key Generation of a Passively Secure TSS
De Feo and Meyer [17] presented the ﬁrst TSS based on isogenies using Shamir
secret sharing. Their TSS uses CSI-FiSh to generate distributed signatures and
is proven to be secure against passive adversaries. The key generation step is
done by a TTP called the dealer, who generates a secret key and splits it into
shares using Shamir secret sharing (SSS). These shares are distributed securely
to the parties and the public key is also computed by the dealer. In Fig. 6, we
present this protocol in the case where we have to generate k −1 secret elements
as for the case of an extended public key. At the end of this protocol, each party
Pj will hold a share si,j of each secret key si. We also present the description of
the signing protocol in the full version of paper [1].
Cost. It is clear that the TTP has to generate k −1 secrets and distribute a
total of n(k−1) subshares to the diﬀerent players. The TTP is left with creating
the public key through the computation of k −1 group actions.
4.2
Full-Threshold Sashimi
The Original Sashimi Protocol. While the TSS from the last subsection
achieves passive security and requires a TTP to perform the key generation,
Input: The ﬁxed elliptic curve E0, a set of parties Q, a secret shared element s ∈ZN
held via a full threshold sharing, i.e. P ∈Q holds sP such that s = 
P ∈Q sP .
Output: [s]E0
1. Deﬁne an ordering the players in Q = {P1, . . . , Pt}.
2. Each party Pj initialises an instance of FCommit; call it F
Pj
Commit.
3. For j = 1, . . . , t
- EPj ←[sPj]E0; π1
Pj ←NIZK.P((E0, EPj), sPj).
- The parties call F
Pj
Commit where Pj submits input (Commit, idPj, (EPj, π1
Pj))
and all other parties input (Commit, idPj, ⊥)
4. For j = 1, . . . , t
- The parties execute F
Pj
Commit with input (Open, idPj) and abort if F
Pj
Commit
returns abort.
- For all Pj ̸= Pi party Pj executes NIZK.V ((E0, EPi), π1
Pi) and aborts if the
veriﬁcation algorithm fails.
5. E0 ←E0.
6. For j = 1, . . . , t do
- Party Pj computes Ej ←[sPj]Ej−1
- π2
Pj ←NIZK.P((E0, EPj, Ej−1, Ej), sPj).
- Broadcast (Ej, π2
Pj) to all players.
- All players execute NIZK.V ((E0, EPj, Ej−1, Ej), π2
Pj) and abort if the veri-
ﬁcation algorithm fails.
7. Return Et.
Fig. 7. Group Action Computation for a Full Threshold Secret Sharing [12].

486
S. Atapoor et al.
Sashimi [12] aims to achieve active security and uses a Pseudo-Random Secret
Sharing (PRSS) to generate a replicated secret sharing. Figure 8 describes the
algorithms underlying Sashimi, as presented in [12], using Fig. 7 as a subroutine.
During the key generation the parties ﬁrst run an instance of FRand.PRSS()
and form a secret sharing ⟨ai⟩of each secret key ai (we refer the reader to the
original paper for more details on FRand.PRSS() and the protocol that implements
it). For RSS, each party holds multiple shares and the same share belongs to
multiple parties (except for the special case of full-threshold where each party
holds exactly one share of the secret). Then the parties agree on a qualiﬁed
set Q and turn the RSS ⟨ai⟩into a full-threshold secret sharing over Q by
properly re-arranging the shares and adding them together. This means that
each party P ∈Q holds a single share ai,P for each key, which is the sum of
some (possibly all) the previous shares. The formal way to pass from a replicated
to full-threshold is explained in the original paper (Section 2.2 of [12]).
After the sharing phase the parties engage in the GrpAction protocol for
generating the public key elements E1, . . . , Ek−1. Within GrpAction, each party
in Q ﬁrst commits to its shares ai,P and attaches a proof of knowledge. Then
it commits to this data using a RO-based commitment scheme and sends the
commitment to the other parties. After the successful veriﬁcation of the proofs,
the parties start a round-robin protocol and compute the public keys Ei by using
their committed secret shares. Again, the parties give a proof to ensure that they
are updating the public key using the same value they committed to earlier.
KeyGen: To generate a distributed key we execute:
1. Call FRand.Init().
2. For i ∈[1, . . . , k −1] do
(a) ⟨ai⟩←FRand.PRSS().
(b) Ei ←GrpAction(E0, Q, ⟨ai⟩) for some qualiﬁed set Q. If this protocol
aborts, then abort.
3. Output ⟨a1⟩, . . . , ⟨ak−1⟩and E1, . . . , Ek−1.
Sign(m, ⟨s⟩): For a set of qualiﬁed parties Q to sign a message m they execute:
1. Write Q = {P1, . . . , Pt} ⊂P.
2. For i = 1, . . . , tS
(a) Party Pj generates bi,j ←ZN, so as to form a full threshold sharing [bi]
over the t parties.
(b) The parties execute E′
i ←GrpAction(E0, Q, [bi]).
3. The parties locally compute (c1, . . . , ctS) ←H(E′
1∥. . . ∥E′
tS∥m).
4. For i = 1, . . . , tS party Pj computes ri,j ←bi,j −sign(ci)·
ΨQ(B)=Pj a|ci|,B.
5. The parties broadcast their values ri,j and locally compute ri ←t
j=1 ri,j.
6. Output {(ri, ci)}tS
i=1.
Fig. 8. The Distributed Key Generation and Signing Protocols of Sashimi [12].

CSI-SharK: CSI-FiSh with Sharing-friendly Keys
487
The NIZK proofs inside GrpAction protocol are given for the language
Lj :=
 
(F0, F ′
0, E1, E′
1, . . . , Ej, E′
j), s

: (F ′
0 = [s]F0)  	j
i=1 (E′
i = [s]Ei)


,
for the cases that j = 0 and j = 1. For these two cases, this language exactly
coincides with the language introduced in Eq. (1). As a result, the protocol
presented in Fig. 5 also coincides with the one proposed in [12], when j = 0, 1.
A Security Flaw in Sashimi. Unfortunately, the ZK proofs inside GrpAction
are not enough to guarantee that the parties follow the protocol. A malicious
party can deviate from the key generation protocol in such a way, that another
(honest) party might not be able to sign anymore and such that after the key
generation, the produced signature will not pass the ﬁnal veriﬁcation, even if all
parties behave honestly in the signing protocol.
The issue arises from the fact that in the key generation phase, after obtaining
the secret shares ⟨ai⟩from the PRSS protocol, each party in Q has to commit
to ai,P which is the sum of some of its replicated shares. In particular it might
not commit to the single shares they got from the PRSS. Malicious parties could
simply commit to a diﬀerent secret value than their original secret share and
generate a NIZK proof and pass the veriﬁcation, thus eﬀectively changing the
“correct” share. Note that this problem only regards the adversarial shares that
are also held by an honest party. The full-threshold case, where each party only
holds a single share of the secret, is not aﬀected by this issue. As a possible
countermeasure, in the public key generation the parties in Q need to commit to
all the shares they got from the PRSS and consistency checks need to be done
by all the parties, not just those in Q.
A Sample Attack. Suppose that we have a (3, 2)-threshold access structure done
with a RSS scheme. Then, we have a secret x deﬁned as x = x1 + x2 + x3, such
that P1 obtains {x2, x3}, P2 obtains {x1, x3}, and P3 gets {x1, x2}. Assume wlog
that P1 is the corrupt party and that the qualiﬁed set in the key generation step is
Q = {P1, P2}. Suppose that the parties agree on re-arranging the shares so that
in the GrpAction protocol P1 enters xP1 := x2 +x3 and P2 enters xP2 := x1. If P1
now enters an arbitrary value y instead of xP1, then this would not be detected.
This is because P1 only commits to y and not to x2 and x3 individually, therefore
there is no way for P2 and P3 to check this. As a result, the ﬁnal secret key would
be x′ = x1 + y rather than x = x1 + x2 + x3, so the ﬁnal public key would be
E′
i = [x1 + y]E0 instead of Ei = [x1 + x2 + x3]E0. As a result, in the threshold
signing protocol, even if both parties of a qualiﬁed set {P2, P3} behave honestly
and follow the protocol, the resulting signature cannot be successfully veriﬁed
under the public key E′
i, as it is signed with the secret key x = x1 + x2 + x3.
In current design of the protocol, this attack cannot be detected by the other
parties, because there is no check inside the GrpAction protocol to ensure that the
parties commit to the same secret shares sampled in the secret-sharing phase.
An Actively Secure Full-TSS from Sashimi. Here we present a slightly
modiﬁed, simpler version of Sashimi for the special case of full-threshold access

488
S. Atapoor et al.
structure. The signing protocol of the full-threshold version is same as original
scheme (shown in Fig. 8), while the full-threshold key generation protocol is
described in Fig. 9. The new key generation protocol is a full-threshold k-MT-
GAIP generation protocol, since it can generally be used to sample a k length
MT-GAIP instance in a full-threshold manner. The security proof of the full-
threshold version follows in Sashimi [12] but is specialized to the full-threshold
case. For completeness we give the proof in the full version of paper [1]. Next,
we discuss the eﬃciency of the resulting full-threshold DKG protocol.
Cost. We express the protocol cost in terms of Group Actions (GAs) and con-
sider the other computational costs as negligible in comparison.
In step 4, all parties compute k−1 GAs, k−1 times execute the ZK argument
in Fig. 5 with j = 0, and then verify each other’s proofs in step 5. This can be
done by all parties in parallel and results in a total cost of (k −1)(1 + ntSpecial
ZK
)
GAs, since we are in the Special case. In step 7, each party ﬁrst computes k −1
elliptic curves, runs k −1 times the ZK argument in Fig. 5 with j = 1, and then
all other players can verify this proof in parallel. Because of the round-robin
Input: The ﬁxed elliptic curve E0 and a set Q of n parties.
Output: ([s1]E0, . . . , [sk−1]E0)
1. Parties individually sample k −1 secrets si ∈ZN shared between the parties,
where Pj ∈Q holds s1,j, . . . , sk−1,j such that si = 
Pj∈Q si,j.
2. Deﬁne an ordering the players in Q = {P1, . . . , Pn}.
3. Each party Pj initialises an instance of FCommit; call it F
Pj
Commit.
4. For i = 1, . . . , k −1, each party Pj executes
- Ei,Pj ←[si,j]E0.
- π1
i,j ←NIZK.P((E0, Ei,Pj), si,j).
(Run the argument in Figure 5 for j = 0)
- Use F
Pj
Commit where Pj submits input (Commit, idPj, (Ei,Pj, π1
i,j)) and all other
parties input (Commit, idPj, ⊥)
5. For i = 1, . . . , k −1
- The parties execute F
Pj
Commit with input (Open, idPj) and abort if F
Pj
Commit
returns abort.
- All other players execute NIZK.V ((E0, Ei,Pj), π1
i,j) and abort if the veriﬁca-
tion algorithm fails.
6. E0
1 ←E0, E0
2 ←E0, · · · , E0
k−1 ←E0.
7. For j = 1, . . . , n
- Party Pj computes Ej
1 ←[s1,j]Ej−1
1
, · · · , Ej
k−1 ←[sk−1,j]Ej−1
k−1.
- For i = 1, . . . , k −1, compute π2
i,j ←NIZK.P((E0, Ei,Pj, Ej−1
i
, Ej
i ), si,j).
(Run the argument in Figure 5 for j = 1)
- Broadcast (Ej
1, Ej
2, · · · , Ej
k−1, π2
1,j, . . . , π2
k−1,j) to all players.
- For i = 1, . . . , k −1, all other players execute NIZK.V (E0, Ei,Pj, Ej−1
i
, Ej
i )
and abort if the veriﬁcation algorithm fails.
8. Return (En
1 , En
2 , . . . , En
k−1) = ([s1]E0, [s2]E0, · · · , [sk−1]E0).
Fig. 9. Full-threshold k-MT-GAIP distributed key generation protocol.

CSI-SharK: CSI-FiSh with Sharing-friendly Keys
489
structure, this is repeated sequentially for all players, i.e. n times. Note that
since (E0
1, E1
i ) = (E0, Ei,Pj), P1 does not need to compute anything in this step.
The full sequential cost of each party’s round in step 7 (except for P1) amounts
to 2(k −1)tGeneral
ZK
GA for the proof, and another 2(k −1)tGeneral
ZK
GA for the
veriﬁcation, which can be done by all other players in parallel. We end up with a
total naive cost of (k −1)(n+ntSpecial
ZK
+4(n−1)tGeneral
ZK
) GA for the full protocol.
The runtime of step 7 can however be improved by using an idea similar to the
staggering approach mentioned in [17], but where the players stagger the NIZK
proofs and veriﬁcations. The idea is that at step j, party Pj computes its k −1
elliptic curves and then builds π1,j (while the other players are idle). As soon
as this proof is ﬁnished, this proof is broadcast and Pj starts computing π2,j.
At the same time, all other players verify π1,j, which takes the same amount of
computational eﬀort as building the proof. This continues until all players have
ﬁnally veriﬁed πk−1,j in the last step (where Pj is idle). It is easy to see, that
the round of Pj has a total sequential cost k −1 + 2ktGeneral
ZK
GA. We ﬁnally end
up with a total sequential cost of
n(k −1)(1 + tSpecial
ZK
) + (n −1)2ktGeneral
ZK
(2)
for the entire protocol.
For the communication cost, we see that both in step 4 and 7, each party
publishes k−1 elliptic curves and proofs. We can bound the total communication
output per player by (k −1) (10 + log p) 1
4 log p.4
4.3
CSI-RAShi: A Distributed Key Generation Protocol
In [3], Beullens et al. proposed a DKG protocol based on Shamir’s secret shar-
ing [31] called CSI-RAShi, that allows a set of parties to generate a public key
E1 = [a]E0 in a distributed manner, with a being their shared secret. Since
Pedersen commitments [27] do not exist as such in the isogeny setting, they can
not be used for parties to verify the correctness of their shares. As a way out,
the authors introduce Piecewise Veriﬁable Proofs (PVP), which allow parties to
prove and verify correctness of their collective and individual shares using ZK
proofs in a much faster way than the naive approach. PVPs are a major contri-
bution of [3], however we skip their deﬁnition here, as our later improvements are
mainly related to CSI-RAShi’s bottleneck, which are standard ZK proofs needed
in the public-key computation step. We also refer to the original source for the
details about the complaint-disqualiﬁcation mechanisms between the players. In
Fig. 10, we present CSI-RAShi extended to generating k −1 keys. We also call it
Shamir k-MT-GAIP generation protocol, as it can be used to sample a k length
MT-GAIP instance based on Shamir secret sharing. We note that by simply
using one key, we recover the original version from [3].
4 In order get this compact formula, we are ignoring the parameter h of the slow hash
function, as well as the gain resulting from the Special case. As such, this formula
represents an upper bound of the total communication per player.

490
S. Atapoor et al.
Input: An elliptic curve E0, a set {P1, . . . , Pn} of n parties.
Output: A public key ([a1]E0, . . . , [ak−1]E0)
Veriﬁable Secret Sharing:
1. For i = 1, . . . , k −1, each player Pj samples a degree t −1 polynomial f (j)
i
(x)
with coeﬃcients from ZN, as well as a uniformly random elliptic curve R(j)
i
and
computes R′(j)
i
= [f (j)
i
(0)]R(j)
i . Then, each player constructs a PVP
π(j)
i
= (˜π(j)
i
, π(j)
i,1 , . . . , π(j)
i,n)
which includes a main proof ˜π(i)
i
as well as individual proof pieces π(j)
i,l for each
other player Pl. Finally, each player publishes the main part ((R(j)
i , R′(j)
i
), ˜π(j)
i
)
and sends (f (j)
i
(l), π(j)
i,l ) privately to Pl. The main proof ˜π(j)
i
allows to verify the
statement R′(j)
i
= [f (j)
i
(0)]R(j)
i , while a proof piece π(i)
j
allows a player to verify
correctness of their share f (j)
i
(l).
2. For i = 1, . . . , k −1, each player Pj veriﬁes all the proofs ˜π(l)
i
and π(l)
i,j of all
other players Pl with respect to their statements. Whenever a proof fails, players
broadcast complaints and the interaction of the concerned players are scrutinized
by the other players. This might result in the disqualiﬁcation of players that
didn’t follow the protocol properly (see [3] for more details).
3. In the end, all the honest players agree on the same set of qualiﬁed players
Q ⊂{1, . . . , n}. At this point the joint secret keys are implicitly deﬁned as ai =

j∈Q f (j)
i
(0). Each party Pj derives their share of ai as ai,j = 
l∈Q f (l)
i (j).
Computing the Public Key:
Set F 0
1 ←E0, . . . , F 0
k−1 ←E0.
4. For j = 1, . . . , n, in a round-robin way, Pj computes
F j
1 ←[f (j)(0)]F j−1
1
, . . . , F j
k−1 ←[f (j)(0)]F j−1
k−1, then builds the proofs
π′(j)
i
←NIZK.P(R(j)
i , R′(j)
i
, F i
j−1, F i
j ),
by running the argument in Figure 5 for j = 1.
5. These proofs are veriﬁed by all parties. Whenever a proof fails, parties again
scrutinize the interaction and can disqualify malicious players. In the honest
majority setting, parties can even reconstruct missing information if needed, so
that the public key implicitly deﬁned by point 3.
6. In the end, the parties return their public key
(F |Q|
1
, F |Q|
2
, . . . , F |Q|
k−1) = ([a1]E0, [a2]E0, . . . , [ak−1]E0) .
Fig. 10. The DKG Protocol CSI-RAShi [3] for an Extended Public Key.
Cost. The runtime of CSI-RAShi is very similar to the DKG of Sashimi. A
major diﬀerence is that in the VSS step, the parties ﬁrst compute k −1 elliptic
curves R(j)
i
and build their proofs using PVPs. The cost of the PVP is dominated
by the main proof (e.g. ˜π(j)
i ) which costs tGeneral
ZK
. Adding n −1 veriﬁcations for
each such proof, the VSS ends up costing (k −1)(2 + ntGeneral
ZK
) sequential group
actions. Steps 4 and 5 amount to the same cost as step 6 of the Sashimi group

CSI-SharK: CSI-FiSh with Sharing-friendly Keys
491
action, i.e. 2(k−1)tGeneral
ZK
per proof and again per veriﬁcation. The diﬀerence with
the protocol in Fig. 9 is that party P1 also has to run these proofs. Finally, we
end up with a total naive cost of (k −1)(2+n+5ntGeneral
ZK
).5 By again staggering
the proofs and veriﬁcations, as described in the Sashimi DKG, we can further
reduce the sequential cost of steps 4 and 5. Optimally, we end up with a total
sequential cost of
(n + 2)(k −1) + ntGeneral
ZK
(3k −1) .
(3)
For the communication cost, in the ﬁrst step, each party publishes 2(k −1)
elliptic curves and k −1 main proofs of the PVPs, then sends k −1 shares and
proof pieces to each of the n−1 other players. In step 4, each party further pub-
lishes k −1 curves and proofs. After some arithmetic,6 the total communication
output per player can be expressed as 1
4 log p(k −1)(8n + 17 + log p).
5
Key Generation Based on CSI-SharK
Next, we revisit the key generation protocols based on CSI-FiSh (given in Sect. 4)
and show, that by using SPKs (as used in CSI-SharK) instead of standard
extended public keys (as used in CSI-FiSh), the cost of these DKG protocols
is reduced to a lower cost than current optimal cases (discussed in Sect. 4).
This gain mainly arises from the fact, that the VSS steps need to be performed
for a single key only, and during the DKG the k −1 independent NIZK proofs
can be replaced with a single proof of Fig. 5 with j = k −1. We then discuss
optimizations to the sequential cost of the protocol, which allows us to even fur-
ther reduce the cost of these protocols by optimally splitting these larger proofs
into chunks and staggering them. We note that this approach works when using
(multiples of) the same secret key in these protocols, which happens in the SPK
case.
5.1
Structured Key Generation in a Passively Secure TSS
Figure 11 presents a passively secure DKG protocol, based on the protocol
from [17], which uses the SPKs. For the associated signing protocol we refer
to [1].
5
In [3], another optimization is discussed which reduces the dominant term from
5ntGeneral
ZK
to 4ntGeneral
ZK
. This is achievable by parties already starting to create their
own proofs in their idle time. This could also be used in Sashimi, but only has a
minor eﬀect when combined with staggering. We choose to omit it here for simplicity,
given that staggering will reduce the dominant term to 3ntGeneral
ZK
in either case.
6 Using the description in [3], the communication content in a PVP is composed of a
main proof of sec(4(n + 1) + log N) bits and 2(n + 1) proof shares, each of sec bits,
resulting in a total of sec(6(n + 1) + log N).

492
S. Atapoor et al.
Theorem 5.1. Under the Power-DDHA and Ck−1-VPwAI assumptions, the
protocol in Fig. 11 is correct and simulatable.
Proof. The proof is completely analogous to the proof of Theorem 1 in [17].
⊓⊔
Computational Cost. We can see that the TTP computes pk using k −1
group actions. While this is the same number of computations as in Sect. 4.1,
the TTP in this case only has to generate a single secret and distribute n shares
of these secrets, reducing the communication by a factor k −1.
5.2
Structured Sashimi
In Fig. 12, we present a new variant of the full-threshold DKG protocol presented
in Fig. 9, that can be used to generate a SPK. Similar to the previous case, as
this protocol can be used to sample a Ck-VPwAI instance in a full-threshold
fashion, we call it full-threshold Ck-VPwAI generation protocol. To achieve active
security, parties compute NIZK proofs for the language from Eq. (1) for the cases
j = 0 and j = k −1.
In the full version of paper [1], we also introduce a full-threshold signature
scheme based on this DKG protocol, which is a variant of the signing algorithm
in Sashimi. We further prove the security of the DKG and the signature scheme
against active adversaries in the full version [1].
Computational Cost. We can see that steps 5 and 6 of Fig. 12 have a total
cost of 1 + ntSpecial
ZK
, as all steps can be done in parallel by all players. Step 8
consists of each player computing k−1 isogenies and then building a NIZK proof
for j = k −1, which is then veriﬁed in parallel by all other players. Each such
step therefore costs (k −1)(1 + 2tGeneral
ZK
). The exception is player P1, which has
already computed EPj = E1
1 and therefore can exclude it from the NIZK proof.
Furthermore, the proofs and veriﬁcation of P1’s step are in the Special case, so
we end up with the total cost of
(n −2)tSpecial
ZK
+ (k −1)(n + 2tSpecial
ZK
+ (n −1)2tGeneral
ZK
) .
(4)
We note that the dominant term in this equation scales with 2nktGeneral
ZK
, which
is already lower than the cost of the protocol reviewed in Sect. 4.2.
KeyGen: Given E0, a TTP acts as follows:
1. Sample a secret s ←ZN and deﬁne a (super)exceptional set Ck−1 = {c1 =
1, c2, . . . , ck−1}.
2. Use SSS to split s into subshares sj for j = 1, . . . , n and distribute sj
privately to party Pj.
3. Output the public key pk := (E0, . . . , Ek−1), where Ei = [cis]E0.
Fig. 11. Passive distributed key generation protocol with structured public key.

CSI-SharK: CSI-FiSh with Sharing-friendly Keys
493
Input: The ﬁxed elliptic curve E0 and a set Q of n parties.
Output: [s]E0, [c2s]E0, · · · , [ck−1s]E0
1. Parties agree on a super-exceptional set Ck−1 = {c1 = 1, c2, . . . , ck−1}.
2. Parties individually sample a secret sj ∈ZN, such that s = 
Pj∈Q sj.
3. Deﬁne an ordering the players in Q = {P1, . . . , Pn}.
4. Each party Pj initialises an instance of FCommit; call it F
Pj
Commit.
5. Each party Pj computes
- EPj ←[sj]E0.
- π1
j ←NIZK.P((E0, EPj), sj).
(Run the argument in Fig. 5 for j = 0)
All parties call F
Pj
Commit where Pj submits input (Commit, idPj, (EPj, π1
j )) and all
other parties input (Commit, idPj, ⊥)
6. For j = 1, . . . , n
- The parties execute F
Pj
Commit with input (Open, idPj) and abort if F
Pj
Commit
returns abort.
- For all Pi ̸= Pj, party Pi executes NIZK.V ((E0, EPj), π1
j ) and aborts if the
veriﬁcation algorithm fails.
7. E0
1 ←E0, E0
2 ←E0, · · · , E0
k−1 ←E0.
8. For j = 1, . . . , n do
- Party Pj computes
Ej
1 ←[sj]Ej−1
1
, Ej
2 ←[c2sj]Ej−1
2
, · · · , Ej
k−1 ←[ck−1sj]Ej−1
k−1,
π2
j ←NIZK.P((E0, EPj, Ej−1
1
, Ej
1, · · · , Ej−1
k−1, Ej
k−1), Ck−1, sj).
- Broadcast (Ej
1, Ej
2, · · · , Ej
k−1, π2
j ) to all players.
- All players execute NIZK.V ((E0, EPj, Ej−1
1
, Ej
1, . . . , Ej−1
k−1, Ej
k−1), Ck−1, π2
j )
and abort if the veriﬁcation algorithm fails.
9. Return ([s]E0, [c2s]E0, · · · , [ck−1s]E0) = (En
1 , En
2 , · · · , En
k−1).
Fig. 12. Full-threshold Ck-VPwAI Generation Protocol.
We can however further optimize step 8 for k > 2. Currently, each player
computes the full proof with j = k −1, while other players wait, then this proof
is veriﬁed while the prover waits. Instead, we can subdivide the one full proof
of k −1 elements into r smaller proofs of j = ⌈k−1
r ⌉elements. The idea is to
stagger these smaller proofs and veriﬁcations steps as was done in Sect. 4.2.
While the proving party computes the ﬁrst proof, the other players are idle.
After ﬁnishing this proof, it is published, and the proving player computes its
second proof while the other players verify the ﬁrst one. This is repeated r times.
In the last round, the other parties verify the rth proof, while the prover is idle.
As such, there is a big overlap between the computations of the prover and the
veriﬁers, reducing the overall idle time. Assuming for simplicity that r divides
k −1, it is clear that each of the proofs should contain the pair (E0, EPj) as the

494
S. Atapoor et al.
reference curves, as well as k−1
r
other curves, which should be proven to have
been computed correctly. Given the staggered approach, we end up with a total
of r + 1 proof-veriﬁcation cycles, where each costs
 k−1
r
+ 1

tZK group actions.
By assuming the prover has already precomputed the (E0, EPj) part of its ﬁrst
proof, as explained above, we can reduce the cost of the ﬁrst cycle to k−1
r tZK
group actions. Including the costs of the elliptic curve computations, this yields
a total of k −1 + k−1
r tZK + r
 k−1
r
+ 1

tZK sequential group actions per round.
It is clear that this cost is minimized for r =
√
k −1. We end up with a cost per
round-robin step of k −1 +

(
√
k −1 + 1)2 −1

tZK for players P2, . . . , Pn.
We are left with establishing the cost of P1’s round. Again, P1 only needs
to compute k −2 curves and consequently prove correctness of these k −2
elements. Using the same process as before we end up with an optimal r′ =
√
k −2, i.e. we have a total of
√
k −2+1 cycles with proofs/veriﬁcations of cost
(
√
k −2+1)tSpecial
ZK
per cycle. Adding the cost of step 5, we end up with the total
sequential cost of the DKG protocol of:7
T DKG(n, k, sec) = n(k −1) +
	
n + (
√
k −2 + 1)2
tSpecial
ZK
+ (n −1)
	
(
√
k −1 + 1)2 −1

tGeneral
ZK
.
(5)
The cost in Eq. (4) is dominated by the term 2kntGeneral
ZK
, while here, this term
is reduced to n(k + 2
√
k)tGeneral
ZK
. For large k, this gives another improvement by
almost a factor of 2.
It is easy to see that our protocol also strongly reduces the communication
cost needed between the parties. First of all, by using only one secret instead
of k −1, we reduce the communication cost of the VSS step by a factor k −1.
Similarly, in the public-key computation step, we reduce the number of proofs
from k −1 to
√
k −1 per player, and even to 1 in the non-optimized case.
Only the number of elliptic curves published in the public-key computation
step stays constant, when compared to the non-structured case. Expressed in
bits, we ﬁnd 1
4 log p (4k + 7n + 7 + log p) in the case with one single proof and
1
4 log p

4k + 7n + 6 + 1
2 log p + (
√
k −1 + 1)(1 + 1
2 log p)

in the optimized case,
as the communication output per player. It is easy to see that asymptotically
for large k, both these cases yield a gain factor of 1
4(10 + log p), when compared
to the protocol in Sect. 4.2.
7 Note that Eq. (5) is slightly simpliﬁed, since in general, the square roots within this
equation are not integers. If e.g.
√
k −1 is not an integer, we construct r = ⌈
√
k −1⌉
proofs, each of size at most ⌈x
r ⌉. This means that we can substitute the terms of
type (√x + 1)2 by the term (⌈√x⌉+ 1)(⌈
x
⌈√x⌉⌉+ 1) (where e.g. x ∈{k −1, k −2})
in order to upper bound the actual cost.

CSI-SharK: CSI-FiSh with Sharing-friendly Keys
495
Input: An elliptic curve E0, a set {P1, . . . , Pn} of n parties.
Output: A public key ([a]E0, [c2a]E0, · · · , [ck−1a]E0)
Veriﬁable Secret Sharing:
1. Each player Pi, for i = 1, . . . , n, samples a degree t −1 polynomial f (i)(x)
with coeﬃcients from ZN, as well as a uniformly random elliptic curve R(i) and
computes R′(i) = [f (i)(0)]R(i). Then, each player constructs a PVP
π(i) = (˜π(i), π(i)
1 , . . . , π(i)
n )
which includes a main proof ˜π(i) as well as individual proof pieces π(i)
j
for each
other player Pj. Finally, each player publishes the main part ((R(i), R′(i)), ˜π(i))
and sends (f (i)(j), π(i)
j ) privately to Pj. The main proof ˜π(i) allows verifying the
statement R′(i) = [f (i)(0)]R(i), while a proof piece π(i)
j
allows a player to verify
the correctness of their share f (i)(j).
2. Now, each player Pj veriﬁes all the proofs ˜π(i) and π(i)
j
of all other players with
respect to their statements. Whenever a proof fails, players broadcast complaints
and the interaction of the concerned players are scrutinized by the other players.
This might result in the disqualiﬁcation of players that didn’t follow the protocol.
3. In the end, all the honest players agree on the same set of qualiﬁed players
Q ⊂{1, . . . , n}. At this point the joint secret key is implicitly deﬁned as a =

i∈Q f (i)(0). Each party Pj derives their share of a as aj = 
i∈Q f (i)(j).
Computing the Structured Public Key:
4. Parties agree on a super-exceptional set Ck−1 = {c1 = 1, c2, . . . , ck−1}.
5. In a round-robin way, the qualiﬁed players compute
F 1
i ←[f (i)(0)]F 1
i−1, F 2
i ←[c2f (i)(0)]F 2
i−1, . . . , F k−1
i
←[ck−1f (i)(0)]F k−1
i−1 ,
where F 1
0 = · · · = F k−1
0
= E0. At each step, player Pi publishes the proof
π′(i) ←NIZK.P((R(i), R′(i), F 1
i−1, F 1
i , . . . , F k−1
i−1 , F k−1
i
, Ck−1), f (i)(0)),
by running the NIZK argument in Fig. 5 for j = k −1.
6. This proof is veriﬁed by all parties. Whenever a proof fails, parties again scruti-
nize the interaction and can disqualify malicious players. In the honest majority
setting, parties can even reconstruct missing information if needed, so that the
public key is implicitly deﬁned by point 3.
7. In the end, the parties return their structured public key
(F 1
|Q|, F 2
|Q|, . . . , F k−1
|Q| ) = ([a]E0, [c2a]E0, . . . , [ck−1a]E0) .
Fig. 13. Shamir Ck-VPwAI Generation Protocol.
5.3
Structured CSI-RAShi
We conclude this section by presenting a CSI-RAShi-based DKG protocol for an
SPK in Fig. 13. The protocol is called Shamir Ck-VPwAI generation protocol, as
it can also be used to sample a Ck-VPwAI instance in a fully distributed manner
using Shamir secret sharing. We also present an actively secure TSS based this
DKG in the full version of paper [1].

496
S. Atapoor et al.
Theorem 5.2. The protocol of Fig. 13 satisﬁes the consistency requirement,
assuming GAIP and Ck−1-VPwAI and satisﬁes the secrecy requirement, further
assuming the Ck−1-Decisional GAIP.
Proof. The proof is given in the full version of paper [1].
⊓⊔
Computational Cost. In contrast to the extension with multiple secret keys,
the SPK extension in Fig. 13 requires only a single execution of the VSS step,
instead of k −1 repetitions, and so it is independent of the public key size.
The cost of this step is 2 + ntGeneral
ZK
group actions. Furthermore, parties do not
have to repeat separate ZK proofs multiple times, but can rather compute one
big proof for all k −1 elements. This results in a cost per round-robin step of
(k −1)(1 + 2tGeneral
ZK
), resulting in the total sequential cost of
2 + ntGeneral
ZK
+ n(k −1)(1 + 2tGeneral
ZK
)
(6)
for the entire protocol. It is easy to see that the dominant term scales with
2nktGeneral
ZK
, which is lower than the cost of the protocol in Sect. 4.3. We can
improve this cost by using the staggering approach described in Sect. 5.2, in
which we split the main proof into
√
k −1 smaller proofs of size approximately
√
k −1. A diﬀerence to the cost established in that section is again that P1 is
not in the Special case and has to compute k −1 curves (as opposed to k −2 in
Fig. 12). We end up with the ﬁnal cost
2 + n(k −1) + tGeneral
ZK
	
n(
√
k −1 + 1)2 + 1

.
(7)
The dominating term in CSI-RAShi scales as 3nktGeneral
ZK
, while using structured
keys can reduce this to n(k+2
√
k)tGeneral
ZK
. For large k, this gives an improvement
of almost a factor 3.
Again, we note that our scheme reduces the communication cost in the
VSS by a factor k −1, as only a single PVP is needed. Similarly, in the
public-key computation step, we reduce the number of proofs from k −1
to
√
k −1 per player, or 1 in the non-optimized case, while the number of
published curves stays k −1. For the case with a single proof, we ﬁnd the
total cost of 1
4 log p (4k + 6n + 10 + log p), while in the optimized case, we ﬁnd
1
4 log p(4k + 6n + 9 + (
√
k −1 + 1)(1 + 1
2 log p)), as the communication output
per player.
For asymptotically large k, in comparison to the non-structured case, we get
a gain factor of the communication of 1
4(8n + 17 + log p), when compared to
Sect. 4.3. We note that the gain increases with the number of parties. This is
due to the fact that the size of the PVPs depends on the number of players.
6
Parallel Executions and Performances
Next, we discuss the beneﬁts of parties having multiple CPU threads at their
disposal when executing isogeny-based signatures and NIZK proofs. Given the

CSI-SharK: CSI-FiSh with Sharing-friendly Keys
497
fact that multi-core CPUs are standard, we want to consider their impact on
the schemes presented in this work. As observed in all threshold protocols, to
compute a curve [x]E0, where x is shared among multiple parties, having to
adopt a sequential round-robin communication structure between the parties
seems to be an unavoidable fact. However, we observe that in the cases that we
need to compute more than one curve, e.g. [x1]E0, . . . , [xk−1]E0, be it either as
a single party (as in the CSI-FiSh or CSI-SharK) or by several parties (as in the
threshold variants of them or DKG protocols), these computations are in general
independent of each other and can therefore very easily be parallelized.
In the case of non-threshold protocols, where only one party runs the algo-
rithm, the parallelization can be done using diﬀerent threads (or cores) of a
CPU. Namely, each thread of the CPU can compute a subset of these curves,
and will ﬁnish the total computation considerably faster than the consecutive
approach described in the original CSI-FiSh [4] and its follow-up schemes [3,12].
As an example, assuming a party has C independently accessible threads, they
can compute a CSI-SharK (or CSI-FiSh) signature for the consecutive cost of
⌈tS/C⌉group actions instead of the full tS, because of the independence of the
commitments. In the full version of paper [1], we show the impact of parallelizing
signature schemes in this way. We observe that using 8 cores with a public key
of size k = 2 (64 B) already allows for signing and verifying as fast as using a
public key of size k = 212 + 1 (256 KB) with a single core.
In the case of threshold protocols, the same idea can be applied to NIZK
arguments, such as the one in Fig. 5, reducing the proof cost from (j + 1)tZK
to (j + 1)⌈tZK/C⌉group actions. Since all commitments can be independently
computed, and the j individual commitments are parallelizable, we can further
reduce this to ⌈(j + 1)tZK/C⌉group actions, eﬀectively reducing the sequential
costs of our algorithms by a factor C, up to some constant terms. Furthermore,
while parties are still forced to adopt a sequential structure due to the round
robins, they can however run multiple such round-robins in parallel to ﬁll up
the idle time. This was already observed in [17] for passively secure threshold
protocols. Here we extend this idea to actively secure threshold case, where
parties also need to generate ZK proofs and verify the proofs of other parties.
In Table 2, we present estimates of the performances of our actively secure
threshold signature schemes based on CSI-SharK for diﬀerent parameter sets.
We compare our schemes with the DKGs from [3,12] and the signature scheme
from [12]. For these estimates, we use the formulas established throughout this
work, including the results for signatures from [1]. We compare them to the
original time complexity formulas from the relevant sources. We use the (conser-
vative) approximate cost of 40 ms per group action that can be expected when
combining the benchmarks presented in [4] with the optimizations from [26] on a
3.5 GHz processor [8]. The table indicates that SPKs give a strong performance
beneﬁt, even when compared to the most optimal case without structured keys.
Since multiple threads are standard in modern CPU architecture, our results
show that isogeny-based signature and threshold schemes become quite practical
by virtue of the parallelizability of their computations. For instance, 3 parties,

498
S. Atapoor et al.
Table 2. Comparison of computational and communication cost for diﬀerent instances
of the full-threshold Sashimi DKG (upper table) and CSI-RAShi (lower table) for the
CSIDH-512 parameter set. We compare both schemes in the CSI-FiSh (extended public
key) and CSI-SharK cases (structured public key) for diﬀerent public key sizes k −1.
We compare naive implementations (as presented in their original paper or by simply
using structured public keys) and optimized (staggered) implementations, as discussed
in Sect. 4 and Sect. 5. We also indicate the communication cost (output per party)
for each of these cases. We note that the communication costs in the CSI-FiSh case
do not change when using the staggering optimization, while it does so in the CSI-
SharK setting. In the full-threshold case, we further indicate the signature cost, as
established in [1]. For completeness, we also compare secret key sizes |sk| per party in
the CSI-FiSh and CSI-SharK cases in the lower table. Runtimes are estimated based
on the conservative estimate that a group action computation takes 40 ms. For better
readability, some communication cost and secret key size entries are omitted in the
tables, as they are simply the same results as in the block above.
Full-
CSI-FiSh
CSI-SharK
Threshold k −1
naive
staggered
comm.
naive
staggered
Signing
Case
[12]
(Sec. 4)
(Sec. 5)
(Sec. 5)
App. of [1]
24
17 min
10 min
131 kB
7.3 min
9.1 kB
5.5 min
21 kB
12 min
28
4.5 h
2.6 h
2.0 MB
1.9 h
24 kB
65 min
84 kB
7.2 min
3 parties
each with
1 core
212
73 h
42 h
33 MB
31 h
264 kB
16 h
517 kB
4.5 min
24
67 s
38 s
27 s
21 s
47 s
28
18 min
10 min
7 min
4 min
28 s
3 parties
each with
16 cores
212
4.8 h
2.6 h
1.9 h
60 min
18 s
24
3.1 min
1.8 min
80 s
60 s
147 s
28
50 min
28 min
21 min
12 min
94 s
8 parties
each with
16 cores
212
13 h
7.4 h
5.6 h
2.9 h
87 s
Shamir
CSI-FiSh
CSI-SharK
secret
k −1
naive
staggered
comm.
|sk|
naive
staggered
|sk|
sharing
[3]
(Sec. 4)
(Sec. 5)
(Sec. 5)
24
18 min
13 min
138 kB
512 B
8.5 min
9.5 kB
6.5 min
26 kB
32 B
28
4.7 h
3.3 h
2.1 MB
8 kB
2.2 h
25 kB
65 min
89 kB
32 B
3 parties
each with
1 core
212
76 h
53 h
34 MB
128 kB
35 h
265 kB
18 h
522 kB
32 B
24
69 s
48 s
32 s
24 s
28
18 min
13 min
8.2 min
4.7 min
3 parties
each with
16 cores
212
4.9 h
3.3 h
2.2 h
68 min
24
2.9 min
2.1 min
148 kB
85 s
10 kB
65 s
26 kB
28
47 min
33 min
2.3 MB
22 min
25 kB
12 min
89 kB
8 parties
each with
16 cores
212
12 h
8.8 h
36 MB
5.8 h
265 kB
3.0 h
522 kB
each with 16 cores, could sign in 28 s by using a 16 KB large public key, while
8 parties would need 94 s with the same parameters. Key generation in these
settings can be done in a few minutes and veriﬁcation will take 40 ms. We note
that by using the optimizations from the full version [1], the runtime of our
signature is about twice as fast as the naive approach presented in [12]. This is
independent of the public key structure and is readily applicable to signature
schemes without structured public keys as well, such as [12].

CSI-SharK: CSI-FiSh with Sharing-friendly Keys
499
7
Conclusion
We presented CSI-SharK as a new variant of CSI-FiSh [4], that allows one to
build more eﬃcient distributed protocols than those based on CSI-FiSh. CSI-
SharK is based on a modiﬁed version of the Σ-protocol underlying CSI-FiSh [4].
A key diﬀerence between CSI-SharK and CSI-FiSh is that CSI-SharK uses SPKs,
as recently introduced in [2]. At the cost of an additional computational assump-
tion, CSI-SharK improves CSI-FiSh in a number of ways. Public keys with k −1
elliptic curves are now generated using a single secret, instead of k −1, which
means that only one secret needs to be generated and stored, independent of the
public key size. This is most noticeable in distributed key generation protocols,
where secrets are further split into parts and distributed among the parties.
The heavy zero-knowledge proofs in current state-of-the-art protocols can be
strongly reduced in numbers and even merged, when working with structured
public keys. This reduces even the most optimal implementations by a factor 3
and the communication cost by a much greater factor, e.g. up to 130 for Sashimi
and about 132 + 3
4n for CSI-RAShi, where n is the number of parties.
While these results make threshold schemes in the isogeny setting much
more practical, we further presented a general strategy for parallel computa-
tions, exploiting the independence of commitments in zero-knowledge proofs and
signature schemes. We show that by parallelizing computations, isogeny-based
threshold (and non-threshold) signatures become truly practical and competitive
in the post-quantum realm.
As an independent contribution, we revealed a ﬂaw in the DKG protocol of
Sashimi, which can allow an honest party to end up with a wrong share after
the protocol, thus preventing it from generating correct signatures, even after a
correctly executed signing protocol.
We think that the very design of the CSI-SharK public keys, its Σ-protocol
and some of our proposed structured DKG protocols can oﬀer many advantages
for diﬀerent applications and hope that the structure may be further exploited
to design more practical isogeny-based cryptographic primitives.
Acknowledgments. We would like to thank Prof. Nigel Smart for his valuable com-
ments. This work has been supported in part by the Defense Advanced Research
Projects Agency (DARPA) under contract No. HR001120C0085, by the FWO under
an Odysseus project GOH9718N, by the European Research Council (ERC) under
the European Union’s Horizon 2020 research and innovation programme (Grant agree-
ment No. 101020788 - Adv-ERC-ISOCRYPT), by CyberSecurity Research Flanders
with reference number VR20192203, by the European Research Council (ERC) under
the European Union’s Horizon 2020 research and innovation program under project
PICOCRYPT (grant agreement No. 101001283), by the Spanish Government under
project PRODIGY (TED2021-132464B-I00), and by the Madrid Regional Government
under project BLOQUES (S2018/TCS-4339). The last two projects are co-funded by
European Union EIE, and Next Generation EU/PRTR funds.
Any opinions, ﬁndings and conclusions or recommendations expressed in this mate-
rial are those of the author(s) and do not necessarily reﬂect the views of the ERC,
DARPA, the US Government, the Spanish Government, Cyber Security Research

500
S. Atapoor et al.
Flanders or the FWO. The U.S. Government is authorized to reproduce and distribute
reprints for governmental purposes notwithstanding any copyright annotation therein.
References
1. Atapoor, S., Baghery, K., Cozzo, D., Pedersen, R.: CSI-SharK: CSI-FiSh with
sharing-friendly keys. Cryptology ePrint Archive, Report 2022/1189 (2022).
https://eprint.iacr.org/2022/1189
2. Baghery, K., Cozzo, D., Pedersen, R.: An isogeny-based ID protocol using struc-
tured public keys. In: Paterson, M.B. (ed.) IMACC 2021. LNCS, vol. 13129, pp.
179–197. Springer, Cham (2021). https://doi.org/10.1007/978-3-030-92641-0 9
3. Beullens, W., Disson, L., Pedersen, R., Vercauteren, F.: CSI-RAShi: distributed key
generation for CSIDH. In: Cheon, J.H., Tillich, J.-P. (eds.) PQCrypto 2021 2021.
LNCS, vol. 12841, pp. 257–276. Springer, Cham (2021). https://doi.org/10.1007/
978-3-030-81293-5 14
4. Beullens, W., Kleinjung, T., Vercauteren, F.: CSI-FiSh: eﬃcient isogeny based
signatures through class group computations. In: Galbraith, S.D., Moriai, S.
(eds.) ASIACRYPT 2019. LNCS, vol. 11921, pp. 227–247. Springer, Cham (2019).
https://doi.org/10.1007/978-3-030-34578-5 9
5. Bishnoi, A., Clark, P.L., Potukuchi, A., Schmitt, J.R.: On zeros of a polynomial in
a ﬁnite grid. Comb. Probab. Comput. 27(3), 310–333 (2018)
6. Bonnetain, X., Schrottenloher, A.: Quantum security analysis of CSIDH. In: Can-
teaut, A., Ishai, Y. (eds.) EUROCRYPT 2020. LNCS, vol. 12106, pp. 493–522.
Springer, Cham (2020). https://doi.org/10.1007/978-3-030-45724-2 17
7. Castryck, W., Decru, T.: An eﬃcient key recovery attack on SIDH (preliminary
version) (2022). https://ia.cr/2022/975
8. Castryck, W., Lange, T., Martindale, C., Panny, L., Renes, J.: CSIDH: an eﬃcient
post-quantum commutative group action. In: Peyrin, T., Galbraith, S. (eds.) ASI-
ACRYPT 2018. LNCS, vol. 11274, pp. 395–427. Springer, Cham (2018). https://
doi.org/10.1007/978-3-030-03332-3 15
9. Ch´avez-Saab, J., Chi-Dom´ınguez, J.J., Jaques, S., Rodr´ıguez-Henr´ıquez, F.: The
Sqale of CSIDH: Square-root V´elu quantum-resistant isogeny action with low expo-
nents. Technical report, Cryptology ePrint Archive, Report 2020/1520, 2020 (2020)
10. Childs, A., Jao, D., Soukharev, V.: Constructing elliptic curve isogenies in quantum
Subexponential time. J. Math. Cryptol. 8(1), 1–29 (2014)
11. Couveignes, J.M.: Hard homogeneous spaces. IACR Cryptol. ePrint Arch. 2006,
291 (2006)
12. Cozzo, D., Smart, N.P.: Sashimi: cutting up CSI-FiSh secret keys to produce
an actively secure distributed signing protocol. In: Ding, J., Tillich, J.-P. (eds.)
PQCrypto 2020. LNCS, vol. 12100, pp. 169–186. Springer, Cham (2020). https://
doi.org/10.1007/978-3-030-44223-1 10
13. Dalskov, A., Lee, E., Soria-Vazquez, E.: Circuit amortization friendly Encod-
ingsand their application to statistically secure multiparty computation. In: Moriai,
S., Wang, H. (eds.) ASIACRYPT 2020. LNCS, vol. 12493, pp. 213–243. Springer,
Cham (2020). https://doi.org/10.1007/978-3-030-64840-4 8
14. De
Feo,
L.:
Mathematics
of
isogeny
based
cryptography.
arXiv
preprint:
arXiv:1711.04062 (2017)
15. De Feo, L., Galbraith, S.D.: SeaSign: compact isogeny signatures from class group
actions. In: Ishai, Y., Rijmen, V. (eds.) EUROCRYPT 2019. LNCS, vol. 11478, pp.
759–789. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-17659-4 26

CSI-SharK: CSI-FiSh with Sharing-friendly Keys
501
16. De Feo, L., Kohel, D., Leroux, A., Petit, C., Wesolowski, B.: SQISign: compact
post-quantum signatures from quaternions and isogenies. In: Moriai, S., Wang, H.
(eds.) ASIACRYPT 2020. LNCS, vol. 12491, pp. 64–93. Springer, Cham (2020).
https://doi.org/10.1007/978-3-030-64837-4 3
17. De Feo, L., Meyer, M.: Threshold schemes from isogeny assumptions. In: Kiayias,
A., Kohlweiss, M., Wallden, P., Zikas, V. (eds.) PKC 2020. LNCS, vol. 12111, pp.
187–212. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-45388-6 7
18. Don, J., Fehr, S., Majenz, C., Schaﬀner, C.: Security of the Fiat-Shamir transfor-
mation in the quantum random-oracle model. In: Boldyreva, A., Micciancio, D.
(eds.) CRYPTO 2019. LNCS, vol. 11693, pp. 356–383. Springer, Cham (2019).
https://doi.org/10.1007/978-3-030-26951-7 13
19. Duman, J., Hartmann, D., Kiltz, E., Kunzweiler, S., Lehmann, J., Riepel, D.:
Generic models for group actions. Cryptology ePrint Archive, Report 2023/186
(2023). https://eprint.iacr.org/2023/186
20. El Kaafarani, A., Katsumata, S., Pintore, F.: Lossy CSI-FiSh: eﬃcient signature
scheme with tight reduction to decisional CSIDH-512. In: Kiayias, A., Kohlweiss,
M., Wallden, P., Zikas, V. (eds.) PKC 2020. LNCS, vol. 12111, pp. 157–186.
Springer, Cham (2020). https://doi.org/10.1007/978-3-030-45388-6 6
21. Fiat, A., Shamir, A.: How to prove yourself: practical solutions to identiﬁcation and
signature problems. In: Odlyzko, A.M. (ed.) CRYPTO 1986. LNCS, vol. 263, pp.
186–194. Springer, Heidelberg (1987). https://doi.org/10.1007/3-540-47721-7 12
22. Galbraith, S.D., Petit, C., Silva, J.: Identiﬁcation protocols and signature schemes
based on Supersingular isogeny problems. In: Takagi, T., Peyrin, T. (eds.) ASI-
ACRYPT 2017. LNCS, vol. 10624, pp. 3–33. Springer, Cham (2017). https://doi.
org/10.1007/978-3-319-70694-8 1
23. Gennaro, R., Jarecki, S., Krawczyk, H., Rabin, T.: Secure distributed key genera-
tion for discrete-log based cryptosystems. J. Cryptol. 20(1), 51–83 (2007)
24. Jao, D., De Feo, L.: Towards quantum-resistant cryptosystems from Supersingular
elliptic curve isogenies. In: Yang, B.-Y. (ed.) PQCrypto 2011. LNCS, vol. 7071, pp.
19–34. Springer, Heidelberg (2011). https://doi.org/10.1007/978-3-642-25405-5 2
25. Maino, L., Martindale, C.: An attack on SIDH with arbitrary starting curve (2022).
https://ia.cr/2022/1026
26. Meyer, M., Reith, S.: A faster way to the CSIDH. In: Chakraborty, D., Iwata, T.
(eds.) INDOCRYPT 2018. LNCS, vol. 11356, pp. 137–152. Springer, Cham (2018).
https://doi.org/10.1007/978-3-030-05378-9 8
27. Pedersen, T.P.: Non-interactive and information-theoretic secure veriﬁable secret
sharing. In: Feigenbaum, J. (ed.) CRYPTO 1991. LNCS, vol. 576, pp. 129–140.
Springer, Heidelberg (1992). https://doi.org/10.1007/3-540-46766-1 9
28. Peikert, C.: He gives C-sieves on the CSIDH. In: Canteaut, A., Ishai, Y. (eds.)
EUROCRYPT 2020. LNCS, vol. 12106, pp. 463–492. Springer, Cham (2020).
https://doi.org/10.1007/978-3-030-45724-2 16
29. Robert, D.: Breaking SIDH in polynomial time (2022). https://ia.cr/2022/1038
30. Rostovtsev, A., Stolbunov, A.: Public-key cryptosystem based on isogenies. IACR
Cryptol. ePrint Arch. 2006, 145 (2006)
31. Shamir, A.: How to share a secret. Commun. ACM 22(11), 612–613 (1979)
32. Shaw, S., Dutta, R.: Identiﬁcation scheme and forward-secure signature in identity-
based setting from isogenies. In: Huang, Q., Yu, Yu. (eds.) ProvSec 2021. LNCS,
vol. 13059, pp. 309–326. Springer, Cham (2021). https://doi.org/10.1007/978-3-
030-90402-9 17

502
S. Atapoor et al.
33. Shor, P.W.: Algorithms for quantum computation: Discrete logarithms and factor-
ing. In: Proceedings of the 35th Annual Symposium on Foundations of Computer
Science, pp. 124–134 (1994)
34. Siegel, C.: ¨Uber die classenzahl quadratischer zahlk¨orper. Acta Arith 1(1), 83–86
(1935)
35. Silverman, J.H.: The Arithmetic of Elliptic Curves, vol. 106. Springer, Berlin (2009)
36. Stolbunov, A.: Constructing public-key cryptographic schemes based on class group
action on a set of isogenous elliptic curves. Adv. Math. Commun. 4(2), 215 (2010)
37. Stolbunov, A.: Cryptographic schemes based on isogenies (2012)
38. Unruh, D.: Post-quantum security of Fiat-Shamir. In: Takagi, T., Peyrin, T. (eds.)
ASIACRYPT 2017. LNCS, vol. 10624, pp. 65–95. Springer, Cham (2017). https://
doi.org/10.1007/978-3-319-70694-8 3
39. Yoo, Y., Azarderakhsh, R., Jalali, A., Jao, D., Soukharev, V.: A post-quantum
digital signature scheme based on supersingular isogenies. In: Kiayias, A. (ed.) FC
2017. LNCS, vol. 10322, pp. 163–181. Springer, Cham (2017). https://doi.org/10.
1007/978-3-319-70972-7 9

Practical Veriﬁable Random Function
with RKA Security
Tsz Hon Yuen1(B)
, Shimin Pan1
, Sheng Huang1, and Xiaoting Zhang2
1 University of Hong Kong, Hong Kong, China
{thyuen,smpan}@cs.hku.hk, vicw0ng@connect.hku.hk
2 Nanjing University, Nanjing, China
Abstract. A veriﬁable random function (VRF) allows the generation of
a random number with publicly veriﬁable proof, showing that the ran-
dom number is honestly generated. The practical VRF used in real-world
applications considers the security of uniqueness, pseudorandomness, and
unpredictability under malicious key generation. In this paper, we pro-
pose the security model of related-key attack to VRF for capturing attacks
like tampering attacks. We propose a new construction of VRF that sat-
isﬁes the RKA security together with the existing security requirements.
We implement our VRF construction and demonstrate that our scheme
is practical for real-world applications.
Keywords: VRF · Veriﬁable random function · universal
composability
1
Introduction
Veriﬁable random function (VRF), introduced by Micali, Rabin, and Vadhan
(FOCS’99), is the public-key equivalent of the pseudorandom function (PRF).
A private key sk and a seed value X are passed to a VRF. The VRF outputs a
random number Y = Fsk(X) along with a proof π. Anyone can validate if Y is
a random number by using a public key pk, the proof π, and the seed X.
VRF is essential in decentralized applications because its tamper-proof
ensures that the results cannot be manipulated and thus guarantees fair out-
comes. Most random number generators do not produce a random number that
can be cryptographically veriﬁed, leaving them vulnerable to manipulation and
hence limiting their use cases. VRF, however, by guaranteeing the security of
random numbers, supports a wide range of uses such as DNSSEC protocol [25],
resettable zero-knowledge proof [23], non-interactive lottery systems [8], and
consensus algorithm in blockchain [7,9,13,14].
1.1
Applications of VRF
Currently, the most widely adopted VRF is the EC-VRF [25], which is based on
elliptic curves. Suppose that the public key vk = gsk for some generator g of the
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 503–522, 2023.
https://doi.org/10.1007/978-3-031-35486-1_22

504
T. H. Yuen et al.
elliptic curve. The VRF outputs Y = H(X)sk, where H is a collision-resistant
hash function. The proof π is a classical zero-knowledge proof of the equivalent
of discrete logarithm between logg pk and logH(X) Y . EC-VRF was originally
proposed for the DNSSEC protocol [25]. EC-VRF is currently being standardized
by CRFG [15]. Several layer-1 blockchains, including Algorand [14], Cardano [9]
and Polkadot [7], use VRF in their consensus mechanisms to randomly select
block producers.
Apart from the consensus algorithm, smart contract developers also require
a source of randomness for their applications. The smart contract itself can-
not generate a unique random number across diﬀerent nodes in the distributed
network. Chainlink provides smart contracts with a secure implementation of
EC-VRF [25], of which the VRF [10] is being used as a secure source of on-
chain randomness across the Web3 ecosystem, including GameFi, DeFi, and
NFT projects.
The consensus algorithm in DFINITY [17] uses a VRF output that is the
hash value of a threshold version of the BLS signature. They consider a case
where the secret key sk is distributed among n parties by secret sharing. These
parties generate partial BLS signatures. Once the system obtains t shares of
partial signatures, the threshold BLS signature can be recovered to calculate
Y . The proof π includes t shares of partial BLS signatures, and each partial
signature can be validated by a pairing computation.
1.2
Motivation: Stronger Security for VRF
Two security requirements for VRF are deﬁned, namely uniqueness and pseudo-
randomness. Since VRF is used in many blockchain applications and aﬀects the
security of digital assets worth billions of dollars, VRF is currently deﬁned with
a strong security model.
Roughly speaking, the security model of uniqueness means that no adver-
sary can output a seed X and two pairs (Y0, π0) and (Y1, π1) which are both
valid with respect to an adversarially chosen veriﬁcation key vk. The security
model of pseudorandomness means that an attacker, seeing a number of VRF
outputs and proofs for adversarially chosen inputs under an honestly generated
key pair, cannot distinguish the output of the VRF on a new (also adversari-
ally chosen) input from a random string. Alternatively, [9] proposed a Universal
Composable (UC) security model of VRF with unpredictability under malicious
key generation.
Related Key Attack. A related-key attack (RKA) means that an adversary
can observe the outcome of a cryptosystem under a modiﬁed key (i.e., related
key) and then breaks the system. RKA attacks can model tampering attacks on
the secret key.
The earliest discussion on RKA mainly focused on the security of block
ciphers and pseudorandom functions (PRFs) [1,4]. For the RKA-security of PRF,
an adversary attempts to break the pseudorandomness of PRF with several secret
keys satisfying some known relation. It is natural to ask if it is possible to con-
struct a VRF with security against related key attacks. Since VRF is widely used

Practical Veriﬁable Random Function with RKA Security
505
in blockchain applications, it is realistic to consider its security under tampering
attacks.
In this paper, we consider the RKA security of VRF using the formalization
of RKA security in the public key cryptosystem. The adversary is allowed to
query a related-key deriving function φ and a seed X to an oracle, and obtain
the VRF output Y ′ = Fφ(sk)(X) and its proof π′ of the queried seed X under the
related key φ(sk). The RKA security requires that the adversary cannot break
the pseudorandomness even when given access to the oracle.
1.3
High Level Idea
We observe that EC-VRF cannot achieve RKA security for pseudorandomness,
with respect to additive relation. Recall that in EC-VRF evaluation with a
related secret key sk + Δ, the corresponding output of Y ′ = H(X)sk+Δ. The
adversary can calculate Y ′/H(X)Δ and breaks the pseudorandomness. The lin-
ear structure of EC-VRF makes it diﬃcult to achieve RKA security for pseudo-
randomness.
In order to achieve RKA security for pseudorandomness, we ﬁrst try to mod-
ify the pairing-based VRF proposed by Dodis and Yampolskiy [11]:
Y = ˆe(g, g)
1
sk+H(X) .
The corresponding proof is π = g
1
sk+H(X) and it can be checked by Y = ˆe(g, π)
and ˆe(pk · gH(X), π). Although it seems that it can achieve the RKA security,
[9, section 3.2] mentioned that [11] cannot achieve Universal Composable (UC)
security of unpredictability under malicious key generation. An adversary that
maliciously generates keys can skew the output distribution.
Alternative, we ﬁrst try to deﬁne
U = X
1
sk ,
Y = H0(X, U).
Deﬁne ρ as a NIZK proof for sk such that U = X
1
sk and vk = gsk. The proof
π = (U, ρ). We try to achieve the RKA security by the exponent
1
sk, and the
UC unpredictability by using the hash H0 as in [9]. Although this scheme seems
to be secure, we cannot simulate the evaluation oracle for pseudorandomness
without the knowledge of sk.
In order to complete the security proof, we deﬁne
U = H1(vk, X)
1
sk ,
Y = H0(X, U).
We model the hash function H1 as a random oracle to simulate the security
proof of pseudorandomness. The extra input vk is added to H1 to handle the
simulation of H1 under diﬀerent keys (both honestly and maliciously generated
keys) in the UC security model. The ﬁnal obstacle is to have an eﬃcient NIZK
proof of sk such that U = g
1
sk and vk = gsk. We cannot simply use the proof of
the equality of discrete logarithm as in the existing schemes. In this paper, we
give an eﬃcient proof of inversion relation, inspired from the Bulletproof [6].

506
T. H. Yuen et al.
1.4
Our Contributions
We deﬁne the ﬁrst RKA security model for VRF and propose the ﬁrst VRF
scheme that achieves the standard security requirement of uniqueness, pseudo-
randomness, and also the RKA security for pseudorandomness. Furthermore, our
scheme also has UC security of unpredictability under malicious key generation.
Our construction is very practical and the eﬃciency is close to the existing EC-
VRF used in many blockchain applications. Since our scheme provides a higher
level of security, it can be applied to many practical applications.
2
Preliminaries
2.1
Veriﬁable Random Function
We deﬁne the veriﬁable random function (VRF) in this section. A VRF function
family F(·)(·) : {0, 1}l(λ) →{0, 1}ℓ(λ) involves 4 algorithms (ParamGen, KeyGen,
Eval, Verify).
– ParamGen(λ) →pp takes input a security parameter λ and outputs a system
public parameters pp.
– KeyGen(pp) →(vk, sk) takes input pp and outputs a veriﬁcation key vk and
a secret key sk.
– Eval(sk, X) →(Y, π) takes input a seed X ∈{0, 1}l(λ) and a secret key sk to
generate an output Y = Fsk(X) and a proof π.
– Verify(vk, X, Y, π) →{0, 1} checks the correctness of generated output Y with
the help of the seed X, the veriﬁcation key vk and the proof π.
Related Works of VRF. There are a number of key breakthroughs in the
academic research of VRFs. Dodis and Yampolskiy [11] gave a compact VRF
from pairing with shorter proofs and keys. Liang et al. [22] proposed a VRF from
a multilinear map. Bitansky [5] and Goyal et al. [16] gave a generic construction
of VRF from non-interactive witness-indistinguishable proof. Recently, Esgin
et al. [12] proposed a lattice-based VRF with applications to the blockchain.
Badertscher et al. [2] proved the UC security of EC-VRF and proposed a batch
veriﬁcation for EC-VRF.
Another line of work is to construct VRF with exponentially-large input
spaces. Hohenberger and Waters [19] gave a VRF under a non-interactive com-
plexity assumption. Jager [20] gave a VRF from a weaker assumption. Hofheinz
and Jager [18] improved the VRF by using a non-interactive constant-size
assumption. Yamada [27] proposed VRFs with either short proof or short keys.
Rosie [26] constructed a VRF with a shorter key. Kohl [21] presented a VRF
which supports an exponential-sized input space, achieves full adaptive security
based on a non-interactive constant-size assumption and its proofs consist of
only a logarithmic number of group elements for inputs of arbitrary polynomial
length. Recently, Niehues [24] gave a VRF with tight security reduction to a
non-interactive q-type assumption.

Practical Veriﬁable Random Function with RKA Security
507
2.2
Assumptions
Deﬁnition 1 (Discrete logarithm (DL) assumption). For any probabilistic
polynomial time A and an ECC group G with order p = p(λ),
Pr [A(g, gx) = x] ≤negl(λ) ,
where x
$←−Zp.
Deﬁnition 2 (Computational Diﬃe-Hellman (CDH) assumption). For
any probabilistic polynomial time A and an ECC group G with order p = p(λ),
Pr

A(g, ga, gb) = gab
≤negl(λ) ,
where a, b
$←−Zp.
Deﬁnition 3 (Decisional Diﬃe-Hellman (DDH) assumption). For any
probabilistic polynomial time A and an ECC group G with order p = p(λ),
Pr

A(g, ga, gb, gab) = 1

−Pr

A(g, ga, gb, h) = 1
 ≤negl(λ) ,
where a, b
$←−Zp and h
$←−G.
Deﬁnition 4 (Decisional q-Diﬃe-Hellman inversion (q-DHI) assump-
tion). For any probabilistic polynomial time A and an ECC group G with order
p = p(λ),

Pr

A(g, gx, . . . , gxq, gx−1) = 1

−Pr

A(g, gx, . . . , gxq, h) = 1


≤negl(λ) ,
where x
$←−Zp, h
$←−G.
2.3
Zero-Knowledge Proof
A zero-knowledge argument is always a tuple of algorithms (Setup, P, V). Setup
takes 1λ as input; P and V take s and t as inputs respectively; the interactive
proof between P and V outputs ⟨P(s), V(t)⟩= b where b ∈{0, 1}, and we denote
the interactive transcript as tr ←⟨P(s), V(t)⟩. For honest P, s = (pp, x, w)
contains public parameter pp, ZK statement x and ZK witness w, and honest
V takes t = (pp, x). The malicious P∗takes auxiliary input aux, which is not
predeﬁned.
Deﬁnition 5 (Interactive argument of knowledge). An algorithm tuple
(Setup, P, V) is called interactive argument of knowledge for a relation R when
it fulﬁlls perfect completeness and computational witness-extended emulation.
Perfect completeness. For any unbounded adversary A
Pr

(x, w) /∈R or
⟨P(x, w), V(x)⟩= 1

pp ←Setup(λ)
(x, w) ←A(pp)

= 1.

508
T. H. Yuen et al.
Computational witness-extended emulation. For all deterministic polynomial
time P∗, there exists an expected polynomial time algorithm ε such that for every
adversary A1 and A2,

Pr
⎡
⎢⎣A1(tr) = 1

pp ←Setup(λ)
(x, aux) ←A2(pp)
tr ←⟨P∗(aux), V(pp, x)⟩
⎤
⎥⎦−
Pr
⎡
⎢⎣
A1(tr) = 1 and
tr is accepting ⇒(x, w) ∈R

pp ←Setup(λ)
(x, aux) ←A2(pp)
(tr, w) ←εO(pp, x)
⎤
⎥⎦

≤κ,
where κ = κ(λ) is the knowledge error rate and the oracle is given by O =
⟨P∗(pp, x, aux), V(pp, x)⟩. The emulation allows the rewind of the oracle with
fresh randomness.
Deﬁnition 6 (Perfect honest-veriﬁer zero-knowledge). There exists a
probabilistic polynomial time simulator S such that for all adversaries A1 and
A2, the probability diﬀerence between
Pr
⎡
⎢⎣
A1(tr) = 1
and (x, w) ∈R

pp ←Setup(λ)
(x, w, ρ) ←A2(pp)
tr ←⟨P(pp, x, w), V(pp, x, ρ)⟩
⎤
⎥⎦
and
Pr
⎡
⎢⎣
A1(tr) = 1
and (x, w) ∈R

pp ←Setup(λ)
(x, w, ρ) ←A2(pp)
tr ←S(pp, x, ρ)
⎤
⎥⎦
is negligible where ρ is the randomness used by V.
3
Security Models of VRF
A VRF is required to have the security properties of provability, uniqueness and
pseudorandomness.
Provability.
For all pp ←ParamGen(1λ), (vk, sk) ←KeyGen(pp), for all X ∈
{0, 1}l(λ) and (Y, π) ←Eval(sk, X), we have Verify(vk, X, Y, π) = 1.
3.1
Uniqueness
The model of unconditional full uniqueness means that there is no unbound
adversary that can output a veriﬁcation key vk, a seed X, and two output pairs
(Y0, π0) and (Y1, π1) which can pass the veriﬁcation, with Y0 ̸= Y1.
Deﬁnition 7 (Unconditional full uniqueness). There does not exist (vk, X,
Y0, π0, Y1, π1) such that Verify(vk, X, Y0, π0) = 1 and Verify(vk, X, Y1, π1) = 1
with Y0 ̸= Y1.

Practical Veriﬁable Random Function with RKA Security
509
Fig. 1. Computational Uniqueness.
Fig. 2. Pseudorandomness. The modiﬁcations for Φ-RKA security are in underline.
We deﬁne the model of computational uniqueness used by Esgin et al.
[12] in Fig. 1. We deﬁne the advantage of an adversary A as AdvUni
A (λ) =
Pr[ExpUni
A (λ) →1].
Deﬁnition 8 (Computational uniqueness). A VRF scheme has computa-
tional uniqueness if for any PPT A, AdvUni
A (λ) is negligible in λ.
We note that the model of computational uniqueness used by Ganesh et al.
[13] is stronger than the one by Esgin et al. [12], in which the public parameters
can also be chosen by the adversary.
Computational trusted uniqueness was deﬁned similarly in [25], except that
the veriﬁcation key vk is honestly generated and is given to the adversary. The
model in [25] did not provide any oracle access to sk.
3.2
Pseudorandomness
We deﬁne the model of computational uniqueness used by Esgin et al. [12] in Fig. 2.
We deﬁne the advantage of an adversary A as AdvPR
A (λ) = | Pr[ExpPR
A (λ) →1]−1
2|.

510
T. H. Yuen et al.
Deﬁnition 9 (Pseudorandomness). A VRF scheme has pseudorandomness
if for any PPT A, AdvPR
A (λ) is negligible in λ.
3.3
RKA Security for Pseudorandomness
We deﬁne the related-key security for VRF. Since the adversary knows the secret
key in the model of unconditional full uniqueness and computational uniqueness,
we do not need to deﬁne RKA models for them. We note that it is possible to
deﬁne the RKA security model for computational trusted uniqueness in [25], but
it is out of scope for this paper.
In this paper, we deﬁne the RKA security model for pseudorandomness.
Deﬁne Φ as the class of related key derivation functions, such as additive function,
multiplicative function, polynomial, etc. The adversary can ask the Eval oracle
with any function φ ∈Φ. The oracle will return the output of Eval using the
key φ(sk). The modiﬁcations of the pseudorandomness model are shown in red
colour in Fig. 2. We deﬁne the advantage of an adversary A as AdvPR,Φ-RKA
A
(λ) =
| Pr[ExpPR,Φ-RKA
A
(λ) →1] −1
2|.
Deﬁnition 10 (Φ-RKA Pseudorandomness) A VRF scheme has Φ-RKA
pseudorandomness if for any PPT A, AdvPR,Φ-RKA
A
(λ) is negligible in λ.
In this paper, we will use the selective security model for the related-key
attack. It means that at the beginning of the security game (before line 1 in
Fig. 2), the adversary has to ﬁrst output all oracle queries (Xi, φi) that he will
ask. During the game, the adversary is allowed to query in any arbitrary order.
The deﬁnition of selective Φ-RKA pseudorandomness can be deﬁned similarly.
4
Building Block: Proof of Inversion Relation
As discussed in the introduction, our VRF construction requires a non-
interactive zero-knowledge (NIZK) proof of an (exponent) inversion relation.
We observed that the Bulletproof [6] provides a NIZK proof for inner product
relation, i.e., knowing vectors a and b such that a·b = c for some public constant
c. We simplify the Bulletproof in a way that we want to prove the knowledge of
γ and 1/γ (in the exponent) that γ · 1/γ = 1.
4.1
ZK Proof of Inversion Relation
We give a (non-interactive) zero-knowledge proof of knowledge of the language:
L = {γ : Γ = gγ ∧Θ = h1/γ}.
The construction is given in Algorithm 1.

Practical Veriﬁable Random Function with RKA Security
511
Algorithm 1: ZK Proof for language L
1 Procedure Setup(λ):
2
pick a generator ˜g, ˜h ←s G;
3
deﬁne H2 : {0, 1}∗→Zp;
4
return param = (˜g, ˜h, H2);
5 Procedure Prove(param, (g, h, Γ, Θ), γ):
// Prove in ZK that logg Γ · logh Θ = 1
// Commit Phase
6
α, β ←s Zp;
7
S1 = gα, S2 = hβ;
8
Deﬁne polynomial l(X) = α + γ · X, r(X) = β + 1
γ · X;
9
Compute polynomial t(X) = l(X) · r(X) := t0 + t1X + t2X2;
// i.e., t0 = αβ, t1 = α
γ + β · γ, t2 = 1
10
τ0, τ1 ←s Zp;
11
T0 = ˜gt0˜hτ0, T1 = ˜gt1˜hτ1;
// Challenge Phase
12
x = H2(g, h, Γ, Θ, S1, S2, T0, T1);
// Response Phase
13
zτ = τ1x + τ0, zl = l(x), zr = r(x);
14
return π = (zτ, zl, zr, x, T1);
15 Procedure Verify(param, (g, h, Γ, Θ), π):
16
Compute T0 = ˜gzl·zr−x2˜hzτ T −x
1
, S1 = gzlΓ −x, S2 = hzr · Θ−x;
17
if x = H2(g, h, Γ, Θ, S1, S2, T0, T1), return 1 ;
18
else return 0;
Theorem 1. Algorithm 1 fulﬁlls computational witness-extended emulation if
the DL assumption holds.
Proof. We consider the prover and the veriﬁer to run the protocol with a ran-
dom challenge. If the transcript outputs rejection, the emulator simply outputs
the transcript. Otherwise, the emulator rewinds the process until getting three
diﬀerent transcripts of accepting.
Observe that the following equation always holds for all accepting transcripts.
˜gzl·zr˜hzτ = T0T x
1 ˜gx2,
(1)
S1 = gzlΓ −x,
(2)
S2 = hzrΘ−x.
(3)
Suppose we have three transcripts of xi and (zl,i, zr,i, zτ,i) for i ∈[1, 3]. Find
νi such that 3
i=1 νi = 1, 3
i=1 νixi = 0 and 3
i=1 νix2
i
= 0. Then we
could compute

512
T. H. Yuen et al.
α′ =
3

i=1
νizl,i such that S1 = gα′,
β′ =
3

i=1
νizr,i such that S2 = gβ′,
τ ′
0 =
3

i=1
νizτ,i,
t′
0 =
3

i=1
νizl,izr,i such that T0 = ˜gt′
0˜hτ ′
0.
Similarly, we can ﬁnd μi such that 3
i=1 μi = 0, 3
i=1 μixi = 1 and
3
i=1 μix2
i = 0 and set t′
1 and τ ′
1 as the following.
τ ′
1 =
3

i=1
μizτ,i,
t′
1 =
3

i=1
μizl,izr,i such that T1 = ˜gt′
1˜hτ ′
1.
Denote γ′ = zl,i−α′
xi
and δ′ = zr,i−β′
xi
. By Eq. 2 and 3, we have:
Γ = (gzl,iS−1
1 )1/xi = g(zl,i−α′)/xi = gγ′,
Θ = (hzr,iS−1
2 )1/xi = g(zr,i−β′)/xi = gδ′.
Putting the value of T0 and T1 into Eq. 1, we can see that if zl,i · zr,i ̸=
t′
0 + t′
1xi + x2
i , it breaks the discrete logarithm of ˜g and ˜h. If not, we substitute
the value of zl,i = γ′xi + α′ and zr,i = δ′xi + β′ into it and get:
(γ′xi + α′) · (δ′xi + β′) = ˜t0 + ˜t1xi + x2
i .
Since this equation is a degree two polynomial and it holds for all x1, x2, x3, it
implies that γ′ · δ′ = 1. Hence it implies that Γ = gγ′ and Θ = h1/γ′.
Theorem 2. Algorithm 1 is zero-knowledge in the random oracle model.
Proof. The simulator picks some random zl, zr, zτ, x, y ∈Zp and T1 ∈G. It com-
putes T0 = ˜gzl·zr˜hzτ ˜g−x2T −x
1
, S1 = gzlΓ −x and S2 = hzr · Θ−x. The simulator
sets x = H2(g, h, Γ, Θ, S1, S2, T0, T1) in the random oracle model.
4.2
Batch Veriﬁcation
Similar to the Bulletproof [6], our NIZK proof allows batch veriﬁcation when mul-
tiple proofs are veriﬁed. For example, an Algorand node running the blockchain
consensus algorithm may need to verify 1000 VRF proofs in parallel. Batch
veriﬁcation can saves the running time of computing exponentiation when the
generators only depend on the public parameters. Batch veriﬁcation is based on
the observation that checking gx = 1 ∧gy = 1 can be validated by selecting a

Practical Veriﬁable Random Function with RKA Security
513
random scalar α from Zp and checking gαx+y = 1. With overwhelming proba-
bility, the latter equation implies that gx = 1 ∧gy = 1 but the latter is more
eﬃcient to compute.
In order to speed up veriﬁcation, we need to change the proof π to a slightly
longer proof π′ = (zτ, zl, zr, x, T0, T1). To verify a single proof, the veriﬁer ﬁrst
computes S1, S2 and runs x = H2(g, h, Γ, Θ, S1, S2, T0, T1). Now the veriﬁer
needs to check
T0 = ˜gzl·zr−x2˜hzτ T −x
1
.
We use an index j to represent diﬀerent proofs π′
j = (zτ,j, zl,j, zr,j, xj, T0,j, T1,j).
To batch verify diﬀerent proofs, the veriﬁer picks random αj ∈Zp and checks if

j
T0,j
αj = ˜g

j(zl,j·zr,j−x2
j)˜h

j zτ,j 
j
T −xj
1,j .
The total number of exponentiation is reduced from 3N to 2N + 2 for N proofs.
This speedup comes at a price of sending an extra T0,j in each proof.
Finally, we also note that the veriﬁer and the prover can use fast ﬁxed-base
exponentiation with precomputation to speed-up all the multi-exponentiations
(i.e., the computation of T0 for the veriﬁer and the computation of T0, T1 for the
prover).
5
Our VRF Construction
We propose a new veriﬁable random function (VRF). Suppose that the public key
vk = gsk. The verifable random function computes Fsk(a) = H0(a, H1(vk, a)
1
sk ),
where H0, H1 are secure hash functions. The VRF is described in Algorithm 2.
5.1
Standard Security
The provability is straightforward.
Theorem 3. Our VRF Protocol has computational uniqueness if the underlying
NIZK proof has computational witness-extended emulation.
Proof. If the adversary A can output (vk, X, Y0, π0, Y1, π1) such that A wins the
game, we ﬁrst have Verify(vk, X, Y0, π0) = 1. Denote πi = (Ui, ρi) for i = 0, 1. The
witness-extended emulation property of the NIZK proof ρ0 implies that there
exists γ0 such that vk = gγ0 and U0 = H1(vk, X)1/γ0. Similarly for ρ1, there
exists γ1 such that vk = gγ1 and U1 = H1(vk, X)1/γ1. It implies that γ0 = γ1
and hence U0 = U1 As a result, Y0 = H0(X, U0) = H0(X, U1) = Y1. It reaches a
contradiction that A wins the game with Y0 ̸= Y1.
Theorem 4. Our VRF Protocol has pseudorandomness if the DDH assump-
tion holds in the random oracle model and the underlying NIZK proof is zero-
knowledge.

514
T. H. Yuen et al.
Algorithm 2: VRF Protocol
1 Procedure ParamGen(λ):
2
pick a generator g ←s G;
3
deﬁne H0 : {0, 1}l(λ) × G →{0, 1}ℓ(λ);
4
deﬁne H1 : G × {0, 1}l(λ) →G;
5
It runs param′ ←Setup(λ);
6
return pp = (g, H0, H1, param′);
7 Procedure KeyGen(pp):
8
sk ←s Zp;
9
vk = gsk;
10
return (vk, sk);
11 Procedure Eval(sk, X):
12
U = H1(vk, X)
1
sk ;
13
ρ ←Prove(param′, (g, H1(vk, X), vk, U), sk);
14
Y = H0(X, U);
15
return (Y, π = (U, ρ));
16 Procedure Verify(vk, X, Y, π):
17
parse π = (U, ρ);
18
if Verify(param′, (g, H1(vk, X), vk, U), ρ) = 1 and Y = H0(X, U), return 1;
19
else return 0;
Proof. Setup. The algorithm B is given the Divisible Decision Diﬃe-Hellman
(DDDH) instance (g, ga, gb, T) and decides if T = gb/a. Note that the DDDH
problem is proved to be equivalent to the DDH problem in [3]. B sets vk = ga.
B runs param′ ←Setup(λ) and gives pp = (g, H0, H1, param′) and vk to the
adversary A.
Oracle Simulation.
– H0 oracle: on input a new pair (Xi, Ui), it returns a random Yi ∈{0, 1}ℓ(λ).
– H1 oracle: on input a new (vk, Xi), it picks a random γi ∈Zp and returns
(ga)γi. Except for one time, it returns gb.
– Eval oracle: on input Xj, it retrieves the corresponding value γj from the H1
oracle query. If the output was gb, B declares failure and exits. Otherwise
it computes U = gγj and Y = H0(Xj, U). B uses the simulator of the zero-
knowledge proof to generate ρ and returns (Y, π = (U, ρ)).
Challenge. A returns a challenge seed X∗. B retrieves the corresponding value
from the H1 oracle query. If the output was not gb, B declares failure and exits.
Otherwise, U ∗= T and Y ∗= H0(X∗, U ∗). Hence B returns Y ∗to A.
Output. Finally A outputs its guess b′. If b′ = 1, the B outputs that T = ¯g
b
a .
If b′ = 0, the B outputs that T is randomly chosen from G.
We can see that the success probability of the simulation is 1/qH, where qH
is the number of oracle queries to the H1 oracle.

Practical Veriﬁable Random Function with RKA Security
515
5.2
ΦLin-RKA Security
Next we show that our VRF protocol is secure against RKA attack, with respect
to the class of Linear function ΦLin, where for all φ ∈ΦLin:
φ(x) = x + C,
for some C ∈Zp.
Theorem 5. Our VRF protocol has pseudorandomness against selective ΦLin-
RKA attack if the decisional q-DHI assumption holds in the random oracle model
and the underlying NIZK proof is zero-knowledge, where q −1 is the number of
oracle query to the Eval oracle.
Proof. Suppose that the Eval oracle input ( ˜Xi, φi) are given to the simulator B
are the beginning of the game, where φi(x) := x+Ci for i ∈[1, q−1]. We exclude
the identity function with Ci = 0 mod p here since it is already captured by the
standard Eval oracle.
Setup.
The
algorithm
B
is
given
the
decisional
q-DHI
instance
(¯g, ¯ga, . . . , ¯gaq, T) and decides if T = ¯g1/a. B (implicitly) deﬁnes sk = a and
deﬁnes a polynomial P(sk) = q−1
i=1 (sk + Ci) := q−1
i=0 Aiai for some coeﬃcients
Ai ∈Zp. B sets:
g = ¯gP (sk) =
q−1

i=0
(¯gai)Ai,
vk = gsk = ¯gaP (a) =
q

i=1
(¯gai)Ai−1.
B runs param′ ←Setup(λ). and gives pp = (g, H0, H1, param′) and vk to the
adversary A.
Oracle Simulation.
– H0 oracle: on input a new pair (Xi, Ui), it returns a random Yi ∈{0, 1}ℓ(λ).
– H1 oracle: on input a new (vk, Xi), it picks a random γi ∈Zp and returns
(ga)γi. Except for one time, it picks a random γ∗∈Zp and returns gγ∗.
– Eval oracle: on input (Xi, φi), we have the following cases:
1. φi is the identity map and H1(vk, Xi) = (ga)γi. Then B sets U = gγi
and Y = H0(Xi, U). B uses the simulator of the zero-knowledge proof to
generate ρ and returns (Y, π = (U, ρ)).
2. φi(x) = x + Ci and H1(vk, Xi) = (ga)γi. B computes
U = g
aγi
φi(sk) = ¯g
aγi·P (sk)
sk+Ci .
Since P(sk) is divisible by sk + Ci, the value of U can be computed from
the decisional q-DHI instance. B uses the simulator of the zero-knowledge
proof to generate ρ and returns (Y = H0(Xi, U), π = (U, ρ)).
3. φi is the identity map and H1(vk, Xi) = gγ∗. B declares failure and exits.

516
T. H. Yuen et al.
4. φi(x) = x + Ci and H1(vk, Xi) = gγ∗. B computes
U = g
γ∗
φi(sk) = ¯g
γ∗·P (sk)
sk+Ci .
Since P(sk) is divisible by sk + Ci, the value of U can be computed from
the decisional q-DHI instance. B uses the simulator of the zero-knowledge
proof to generate ρ and returns (Y = H0(Xi, U), π = (U, ρ)).
Challenge. A returns a challenge seed X∗. B retrieves the corresponding
value from the H1 oracle query. If the hash value is not gγ∗, B declares failure
and exits. Otherwise, deﬁne coeﬃcients B−1, B0, B1, ..., Bq−2 ∈Zp such that:
γ∗· P(sk)
a
= γ∗· q−1
i=1 (a + Ci)
a
:=
q−2

i=0
Biai + B−1
a .
Note that B−1 ̸= 0 since Ci ̸= 0. We have:
U0 = H1(vk, X∗)
1
sk = ¯g
γ∗·P (sk)
a
=
q−2

i=0
(¯gai)Bi · ¯g
B−1
a .
Hence B sets U ∗= q−2
i=0 (¯gai)Bi · T B−1 and returns Y ∗= H0(X∗, U ∗) to A.
Output. Finally A outputs its guess b′. If b′ = 0, the B outputs that T = ¯g
1
a .
If b′ = 1, the B outputs that T is randomly chosen from G.
We can see that the success probability of the simulation is at least
1
q2
H (qH −
qE), qH is the number of oracle query to the H1 oracle, and qE is the number of
oracle query to the Eval oracle.
5.3
UC Security of Unpredictability Under Malicious Key
Generation
David et. al. [9] deﬁned the security requirement of unpredictability under mali-
cious key generation, which is essential for their blockchain consensus algorithm.
It cannot be implied by the previous game-based deﬁnition of pseudorandom-
ness. A UC deﬁnition of VRF capturing unpredictability under malicious key
generation is deﬁned by [9] and is shown in Fig. 3. Esgin et al. [12] deﬁned a
game-based version called unbiasability. A slightly weaker UC functionality of
VRF was given in [2].
In this paper, we proved the security of our VRF under the UC security
model of unpredictability in [9], because VRFs are widely used in blockchain
consensus algorithms and they are mostly proved in the UC security model.
Theorem 6. Our VRF construction realizes FVRF in the random oracle model
assuming the CDH problem.
Proof. We describe a simulator S that controls the random oracles H0, H1 and
operates in the following manner.

Practical Veriﬁable Random Function with RKA Security
517
Fig. 3. Functionality FVRF
1. Upon receiving a message (KeyGen, sid, Ui) from FVRF, a new value vk = gk is
selected for a random k and S inserts (Ui, vk) in its internal registry of keys;
in case the key exists already, S returns fail and terminate. It returns to FVRF
the message (VeriﬁcationKey, sid, Ui, vk).
2. Upon receiving a message (EvalProof, sid, Ui, X) from FVRF, this is matched
to the veriﬁcation key vk of Ui and is checked whether X has been queried
before. In such a case, the value U that corresponds to X in the table for vk is
recovered. In case X was not queried before, it is checked whether H1(vk, X)
is deﬁned. In such case the entry (base, vk, X, γ, h1) is recovered, the value
U is set to gγ and the triple (vk, X, U) is stored for future reference. In
case the value H1(vk, X) is undeﬁned S selects γ at random from Zp, stores
(base, vk, X, γ, h1 = vkγ) and sets H1(vk, X) = h1.
Subsequently random values x, zτ, zl, zr ∈Zp and T1 ∈G are selected by S.
S computes T0 = ˜gzl·zr˜hzτ ˜g−x2T −x
1
, S1 = gzlvk−x, S2 = H1(vk, X)zr · U −x.
The pair ((g, H1(v, X), vk, U, S1, S2, T0, T1), x) is inserted to the table of the

518
T. H. Yuen et al.
Table 1. Security of practical VRF schemes and their assumptions. RO stands for the
random oracle model. × means insecure.
Uniqueness Pseudorandomness UC Security of Unpredictability
RKA Pseudorandomness
EC-VRF [25]
RO
DDH + RO
(CDH + RO using model in [2]) ×
[9]
CDH + RO
×
This paper
DL + RO
DDH + RO
CDH + RO
q-DHI + RO
random oracle H0. In case this is not feasible (because that would make
the table inconsistent), S outputs fail and terminates. Finally, π is set to
(U, ρ = (zτ, zl, zr, x, T1)) and the message (Eval, sid, X, π) is returned to FVRF.
3. Upon receiving (Verify, sid, X, Y, π, vk′) from FVRF, parse π as (U ′, ρ′) and
verify the proof ρ′ as a proof of logg(vk′) = 1/ logH1(vk,X)(U ′), to obtain a
bit b. Now observe that (base, vk′, X, γ, h1) must be recorded, and set b′ =
((U ′)1/γ = g) ∧(H0(X, U) = Y ). If b ̸= b′ output fail and terminate. In any
other case, return (Veriﬁed, sid, X, Y, π, vk′) to FVRF.
4. Upon receiving a query (vk, X) for the random oracle H1, select γ ∈Zp at
random, store (base, vk, X, γ, h1 = vkγ) and return h1.
5. Upon receiving a query for the random oracle H0 of the form (X, U), and the
value (base, vk, X, γ, h1) is stored previously, S performs the following. First,
if (g, U, vk, h1) is a CDH tuple (via checking if U = gγ) and vk is not regis-
tered as a public-key it registers (KeyGen, sid, vk) with FVRF. Then it submits
(Eval, sid, vk, m) to the FVRF. If FVRF ignores the request S terminates with
fail. Else it obtains the response Y which is set as the random oracle output
to the query (X, U). In case (base, vk, X, γ, h1) is not stored, then perform
the step that corresponds to the query H1(vk, X) above and repeats the cur-
rent step. Other queries to H0 are handled by returning random elements of
{0, 1}ℓ(λ).
We observe that unless S outputs fail, the simulation is perfect. We next
argue that the probability of output failure is negligible. S outputs fail in the
case that FVRF ignores a request (Eval, sid, vk, X). This means that the key vk
is registered with an honest party that has not evaluated X. It follows that the
event an adversary that produces such U can be turned into a solver for the
Diﬃe-Hellman Inversion (DHI) problem. Note that the DHI problem is proved
to be equivalent to the CDH problem in [3]. The other cases where S produces
fail, speciﬁcally, step 1, 2 and 3 can be easily seen to be negligible probability
events.
Then, we can build an attacker against the DHI assumption as follows. Let
(g, ga) deﬁne an instance of the DHI problem. We run the above simulator S
against the given adversary by choosing one of the honest users at random and
setting its vk = ga.
For H1 query with (vk = ga, X), select γ ∈Zp at random, store (base, vk =
ga, X, γ, h1 = vkγ) and return h1. Except for one time with input (vk = ga, X),
select γ∗∈Zp at random, store (base, vk = ga, X, γ∗, h∗
1 = gγ∗) and return h∗
1.

Practical Veriﬁable Random Function with RKA Security
519
If S fails in step 5, it means that S receives a query (X, U). If H1(vk∗, X) = h∗
1
(with probability at least 1/qH1, where qH1 is the number of oracle queries to
H1), S fails when (g, U, ga, gγ∗) is a CDH tuple, i.e., U = gγ∗/a. Then S returns
U 1/γ∗as the solution to the DHI problem.
6
Analysis and Implementation
Security. We ﬁrst compare the security of the practical VRF schemes EC-VRF
[25], the VRF in [9] and our scheme in Table 1. We note that the construction of
[9] is very similar to EC-VRF (applying another hash function over the EC-VRF
output with the seed X). Hence, the uniqueness and pseudorandomness of [9]
should be similar to that of EC-VRF.
For the recent lattice-based VRF [12], they achieve pseudorandomness (under
the MLWE assumption, in the random oracle model), computational uniqueless
(under the MSIS assumption, in the random oracle model), and unbiasability
(the game-based version of unpredicatability) in the random oracle model. Their
lattice-based VRF has the limitation of generating a limited number k of VRF
outputs only for a single key pair. In their concrete parameter setting, they set
k = 1, 3, 5 only. Hence, we do not include their scheme for direct comparison.
Eﬃciency. The running time of EC-VRF and the VRF in [9] are very similar
due to the similarity of their constructions. Hence, we only compare EC-VRF
with our scheme in the eﬃciency analysis and the implementation part. In EC-
VRF, the running time of Eval is dominated by two exponentiations in G. The
running time of Verify is dominated by four exponentiations in G.
In our VRF, the running time of Eval is dominated by seven exponentiations
in G. The running time of Verify is dominated by seven exponentiations in G.
The running time for veriﬁcation is more important for blockchain consensus
algorithms. We did not implement the batch veriﬁcation in our implementation.
As discussed in Sect. 4.2, our NIZK proof allows batch veriﬁcation when mul-
tiple VRFs are veriﬁed. In [6], a single veriﬁcation takes 3.9ms, while a batch
veriﬁcation of 64 proofs takes 1.9ms per proof. The running time of Verify can
be further sped up by applying such a batch veriﬁcation technique.
Implementation. We implement EC-VRF and our scheme in a virtual machine
with Ryzen 5800H CPU @ 3.2 GHz, and 4 GB memory. They are both written
in Rust using Curve25519. The source code of our implementation has been
updated to GitHub1. After 1000 repetitions, the average running time for Eval
and Verify time of EC-VRF are 0.17 ms and 0.22 ms respectively. The average
running time for Eval and Verify time of our scheme are 1.025 ms and 1.049 ms
respectively. Our scheme is slower because of the larger number of exponentia-
tion, the computation of modular inverse, and two more hash function compu-
tations. We note that our scheme is still very eﬃcient with a running time of
about 1 ms, oﬀers a higher level of security, and can be further optimized by
using batch veriﬁcation. Algorand’s mainnet currently employs over 1000 nodes
1 https://github.com/rka-vrf/rka-vrf.

520
T. H. Yuen et al.
which runs a VRF protocol for the consensus algorithms. The veriﬁcation time
for 1000 VRF takes around 1 s even if we do not use batch veriﬁcation. It is less
than the block generation time of 5 s in Algorand.
7
Conclusion
In this paper, we present a new VRF scheme that is secure against the standard
deﬁnition of uniqueness, pseudorandomness, and UC security of unpredictabil-
ity under malicious key generation. We deﬁne the ﬁrst security model of RKA
security against pseudorandomness for VRF. We show that our construction is
also secure under this strong model. Our scheme is practical and can be used in
real-world applications like the blockchain.
References
1. Abdalla, M., Benhamouda, F., Passel`egue, A., Paterson, K.G.: Related-key security
for pseudorandom functions beyond the linear barrier. In: Garay, J.A., Gennaro,
R. (eds.) CRYPTO 2014. LNCS, vol. 8616, pp. 77–94. Springer, Heidelberg (2014).
https://doi.org/10.1007/978-3-662-44371-2 5
2. Badertscher, C., Gaˇzi, P., Querejeta-Azurmendi, I., Russell, A.: On uc-secure
range extension and batch veriﬁcation for ecvrf. Cryptology ePrint Archive, Paper
2022/1045 (2022). https://eprint.iacr.org/2022/1045. To appear in ESORICS 2022
3. Bao, F., Deng, R.H., Zhu, H.F.: Variations of diﬃe-hellman problem. In: Qing, S.,
Gollmann, D., Zhou, J. (eds.) ICICS 2003. LNCS, vol. 2836, pp. 301–312. Springer,
Heidelberg (2003). https://doi.org/10.1007/978-3-540-39927-8 28
4. Bellare, M., Kohno, T.: A theoretical treatment of related-key attacks: RKA-PRPs,
RKA-PRFs, and applications. In: Biham, E. (ed.) EUROCRYPT 2003. LNCS,
vol. 2656, pp. 491–506. Springer, Heidelberg (2003). https://doi.org/10.1007/3-
540-39200-9 31
5. Bitansky,
N.:
Veriﬁable
random
functions
from
non-interactive
witness-
indistinguishable proofs. In: Kalai, Y., Reyzin, L. (eds.) TCC 2017. LNCS, vol.
10678, pp. 567–594. Springer, Cham (2017). https://doi.org/10.1007/978-3-319-
70503-3 19
6. B¨unz, B., Bootle, J., Boneh, D., Poelstra, A., Wuille, P., Maxwell, G.: Bulletproofs:
short proofs for conﬁdential transactions and more. In: IEEE SP 2018, pp. 315–334.
IEEE Computer Society (2018)
7. Burdges, J., et al.: Overview of polkadot and its design considerations. Cryptology
ePrint Archive, Paper 2020/641 (2020). https://eprint.iacr.org/2020/641
8. Chow, S.S.M., Hui, L.C.K., Yiu, S.M., Chow, K.P.: An e-Lottery scheme using ver-
iﬁable random function. In: Gervasi, O., et al. (eds.) ICCSA 2005. LNCS, vol. 3482,
pp. 651–660. Springer, Heidelberg (2005). https://doi.org/10.1007/11424857 72
9. David, B., Gaˇzi, P., Kiayias, A., Russell, A.: Ouroboros praos: an adaptively-secure,
semi-synchronous proof-of-stake blockchain. In: Nielsen, J.B., Rijmen, V. (eds.)
EUROCRYPT 2018. LNCS, vol. 10821, pp. 66–98. Springer, Cham (2018). https://
doi.org/10.1007/978-3-319-78375-8 3

Practical Veriﬁable Random Function with RKA Security
521
10. Docs, C.: Introduction to chainlink vrf (2020). https://docs.chain.link/docs/
chainlink-vrf/#overview
11. Dodis, Y., Yampolskiy, A.: A veriﬁable random function with short proofs and
keys. In: Vaudenay, S. (ed.) PKC 2005. LNCS, vol. 3386, pp. 416–431. Springer,
Heidelberg (2005). https://doi.org/10.1007/978-3-540-30580-4 28
12. Esgin, M.F., et al.: Practical post-quantum few-time veriﬁable random function
with applications to algorand. In: Borisov, N., Diaz, C. (eds.) FC 2021. LNCS, vol.
12675, pp. 560–578. Springer, Heidelberg (2021). https://doi.org/10.1007/978-3-
662-64331-0 29
13. Ganesh, C., Orlandi, C., Tschudi, D.: Proof-of-stake protocols for privacy-aware
blockchains. In: Ishai, Y., Rijmen, V. (eds.) EUROCRYPT 2019. LNCS, vol. 11476,
pp. 690–719. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-17653-
2 23
14. Gilad, Y., Hemo, R., Micali, S., Vlachos, G., Zeldovich, N.: Algorand: scaling byzan-
tine agreements for cryptocurrencies. In: SOSP 2017, pp. 51–68. ACM (2017)
15. Goldberg, S., Reyzin, L., Papadopoulos, D., Vˇcel´ak, J.: Veriﬁable random func-
tions (VRFs). Internet-Draft draft-irtf-cfrg-vrf-15, Internet Engineering Task Force
(2022). https://datatracker.ietf.org/doc/draft-irtf-cfrg-vrf/15/. work in Progress
16. Goyal, R., Hohenberger, S., Koppula, V., Waters, B.: A generic approach to con-
structing and proving veriﬁable random functions. In: Kalai, Y., Reyzin, L. (eds.)
TCC 2017. LNCS, vol. 10678, pp. 537–566. Springer, Cham (2017). https://doi.
org/10.1007/978-3-319-70503-3 18
17. Hanke, T., Movahedi, M., Williams, D.: DFINITY technology overview series, con-
sensus system. CoRR abs/1805.04548 (2018). http://arxiv.org/abs/1805.04548
18. Hofheinz, D., Jager, T.: Veriﬁable random functions from standard assumptions.
In: Kushilevitz, E., Malkin, T. (eds.) TCC 2016. LNCS, vol. 9562, pp. 336–362.
Springer, Heidelberg (2016). https://doi.org/10.1007/978-3-662-49096-9 14
19. Hohenberger, S., Waters, B.: Constructing veriﬁable random functions with large
input spaces. In: Gilbert, H. (ed.) EUROCRYPT 2010. LNCS, vol. 6110, pp. 656–
672. Springer, Heidelberg (2010). https://doi.org/10.1007/978-3-642-13190-5 33
20. Jager, T.: Veriﬁable random functions from weaker assumptions. In: Dodis, Y.,
Nielsen, J.B. (eds.) TCC 2015. LNCS, vol. 9015, pp. 121–143. Springer, Heidelberg
(2015). https://doi.org/10.1007/978-3-662-46497-7 5
21. Kohl, L.: Hunting and gathering – veriﬁable random functions from standard
assumptions with short proofs. In: Lin, D., Sako, K. (eds.) PKC 2019. LNCS,
vol. 11443, pp. 408–437. Springer, Cham (2019). https://doi.org/10.1007/978-3-
030-17259-6 14
22. Liang, B., Li, H., Chang, J.: Veriﬁable random functions from (Leveled) multilinear
maps. In: Reiter, M., Naccache, D. (eds.) CANS 2015. LNCS, vol. 9476, pp. 129–
143. Springer, Cham (2015). https://doi.org/10.1007/978-3-319-26823-1 10
23. Micali, S., Reyzin, L.: Soundness in the public-key model. In: Kilian, J. (ed.)
CRYPTO 2001. LNCS, vol. 2139, pp. 542–565. Springer, Heidelberg (2001).
https://doi.org/10.1007/3-540-44647-8 32
24. Niehues, D.: Veriﬁable random functions with optimal tightness. In: Garay, J.A.
(ed.) PKC 2021. LNCS, vol. 12711, pp. 61–91. Springer, Cham (2021). https://doi.
org/10.1007/978-3-030-75248-4 3
25. Papadopoulos, D., et al.: Making nsec5 practical for dnssec. Cryptology ePrint
Archive, Paper 2017/099 (2017). https://eprint.iacr.org/2017/099

522
T. H. Yuen et al.
26. Ro¸sie, R.: Adaptive-secure VRFs with shorter keys from static assumptions. In:
Camenisch, J., Papadimitratos, P. (eds.) CANS 2018. LNCS, vol. 11124, pp. 440–
459. Springer, Cham (2018). https://doi.org/10.1007/978-3-030-00434-7 22
27. Yamada, S.: Asymptotically compact adaptively secure lattice IBEs and veriﬁable
random functions via generalized partitioning techniques. In: Katz, J., Shacham,
H. (eds.) CRYPTO 2017. LNCS, vol. 10403, pp. 161–193. Springer, Cham (2017).
https://doi.org/10.1007/978-3-319-63697-9 6

Statistically Consistent
Broadcast Authenticated Encryption
with Keyword Search
Adaptive Security from Standard Assumptions
Sayantan Mukherjee(B)
Department of Computer Science and Engineering,
Indian Institute of Technology, Jammu, India
csayantan.mukherjee@gmail.com
Abstract. Searchable Encryption (SE) allows users to perform a key-
word search over encrypted documents. In Eurocrypt’04, Boneh et al.
introduced Public-key Encryption with Keyword Search (PEKS). Broad-
cast Encryption with Keyword Search (BEKS) is a natural progression to
allow some amount of access control. Unfortunately, PEKS and BEKS
suﬀer from keyword-guessing attacks (KGA). In the case of KGA, an
adversary guesses the keyword encoded in a trapdoor by creating a
ciphertext on a sequence of keywords of its choice and testing them
against the trapdoor. In ACISP’21, Liu et al. introduced a variant of
BEKS called Broadcast Authenticated Encryption with Keyword Search
(BAEKS), which tried to mitigate KGA in BEKS. This construction did
not argue consistency and achieved weaker security in the random oracle
model.
In this work, we ﬁrst introduce the notion of consistency for BAEKS
and introduce security models much stronger than those of Liu et al.
We propose a new statistically-consistent construction of BAEKS in the
standard model that achieves security in the newly introduced models.
Our proposal is proven adaptively secure under the well-studied bilat-
eral Matrix Diﬃe-Hellman Assumption and still achieves asymptotic eﬃ-
ciency similar to that of Liu et al.
1
Introduction
With the advent of new technologies, third-party cloud storage, and network
bandwidth are becoming more accessible. One now can store the data in the
cloud and download them as and when required. All user in this setting puts
unsubstantiated trust on the third-party server. A realistic user might encrypt
the data to achieve access control. Broadcast encryption (BE) [5] has already
been found to be useful to restrict the unprivileges. However, BE does not sup-
port searching on encrypted data.
Boneh et al. [6] kickstarted the study of public key encryption with keyword
search (PEKS). It was followed by seminal works such as [1,8]. Being public key
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 523–552, 2023.
https://doi.org/10.1007/978-3-031-35486-1_23

524
S. Mukherjee
encryptions, all of these schemes were vulnerable to keyword guessing attacks
[9,23]. Two possible directions to thwart key guessing attack were explored:
– Restrict searching capability: This line of work studied designated-tester
PEKS [3,14,16]. Here, Test uses the tester’s secret key.
– Restrict encryption capability: This line of work studied public key authen-
ticated encryption with keyword search (PAEKS) [12,18,21]. Here, Encrypt
uses the sender’s secret key.
Among the two, recently introduced PAEKS seems to be the more realistic and
is therefore getting much attention of late. PAEKS allows a sender to encrypt
a keyword for a particular receiver. Supporting several users to perform a key-
word search in the encrypted domain has been studied for a long time [2,7]. All
the existing works have tried to combine broadcast encryption (BE) with PEKS.
Unfortunately, neither of these works withstand the dreaded key guessing attack.
In ACISP 2021, Liu et al. [20] extended the PAEKS primitive towards supporting
multiple receivers. In particular, they introduced the notion of broadcast authen-
ticated encryption with keyword search (BAEKS) to allow a sender to encrypt a
keyword for multiple receivers. They also have proposed security games to model
(some) real-world vulnerabilities. Despite being the trendsetter, [20] suﬀers mul-
tiple shortcomings. To name a few, [20] was only proven non-adaptively secure
in the random oracle model where the challenger would choose the challenge
receiver/sender. Moreover, they did not consider sender privacy, and no formal
arguments for anonymity and trapdoor anonymity were provided. On top of
that, [20] does not comment about its consistency [1] despite being a searchable
encryption.
1.1
Our Contribution
Liu et al. [20] introduced the notion of broadcast authenticated encryption with
keyword search and proposed security models. They introduced four security
models two for trapdoor security and two for ciphertext security. We ﬁrst observe
some unnatural restrictions in all of their security models. We further note that
they did neither consider the security of the sender information, which is usually
another essential anonymity requirement, nor did they provide any argument on
the consistency of their construction.
Thus, We propose a novel deﬁnition of consistency for the BAEKS primitive,
which improved upon the consistency deﬁnition of PAEKS [13]. We also propose
two security models, one to capture trapdoor security and one for ciphertext secu-
rity, where both consider hiding the keyword, the sender information, and the
receiver(s) information simultaneously. Our security models allow user public key
queries not allowed in [20]. We believe, these new security deﬁnitions would serve
as a good reference for BAEKS which in a way generalizes PAEKS. Then we give
a new statistically-consistent construction of broadcast authenticated encryption
with keyword search BaEKS. While proving statistical consistency, we introduce
a novel technique over the existing techniques [1,13]. Our construction achieves

Statistically Consistent Broadcast Authenticated Encryption
525
adaptive ciphertext security and trapdoor security in the standard model under
standard assumptions.
1.2
Technical Overview
We start from the BEKS construction of [10] even though there are some glaring
diﬀerences between their achievements and our requirements. [10] encoded a
keyword and receiver set pair (ω, R) via a merge of Boneh-Boyen Hash (BB-
Hash) [4] and Gentry-Waters hash [17]. In particular, (ω, R) pair was encoded
as (wn+1ω + 
i∈R wi) where w1, . . . , wn captures users and wn+1 is used to
compute the BB-Hash [4]. To encode the (ω, R) pair in the trapdoor, [10] has
to encode all w1 to wn one by one. They needed R to be given in plain for the
decryption. To summarise, [10] (i) supports only polynomial many users whose
keys are generated by a central authority, (ii) does not provide trapdoor privacy,
(iii) does not hide receiver information, (iv) does not consider sender anonymity.
We start by encoding the sender information S by wn+1; this results in a
hash that encodes the triple (S, ω, R). However, this encoding hides ω and S
from an adversary but still leaks R. To address this, we split this encoding to
|R| many BB-Hash [4]arriving at {(wSω + wR)}R∈R to encode (S, ω, R). This
encoding not only hides R but also allows each user U to choose their own wU
removing the necessity of a central authority.
To encode a triplet of the sender, keyword, and receiver information (S, ˜ω, R)
in a trapdoor, we remove some parts from the encoding of [10]. Precisely, we keep
only the BB-Hash of (S, ˜ω, R) i.e. (wS˜ω +wR). Informally speaking, the BB-Hash
(wS˜ω + wR) in trapdoor allows us to test the match with BB-Hash (wSω + wRi)
in ciphertext quite naturally and also hides all of (S, ˜ω, R).
We now focus on instantiation. [10] did not provide trapdoor privacy and,
therefore, could aﬀord to use the asymmetric structure of Jutla-Roy [19]. We
follow Chen et al. [11] to make the ciphertexts and the trapdoors.
1.3
Organization of the Paper
In Sect. 2, we discuss some basic notations and descriptions of mathematical
tools. We deﬁne broadcast authenticated encryption with keyword search and its
security in Sect. 3. Then in Sect. 4, we propose a new construction BaEKS along
with a security proof and present a comparison with the state of the art in
Sect. 5. Finally, we conclude the paper in Sect. 6. We revisit the security models
of [20] in Appendix A.
2
Mathematical Tools and Preliminaries
Notations. For a, b ∈N such that a ≤b, we often use [a, b] to denote {a, . . . , b}
and write [b] := [1, b]. For a set D, we write x ← D to denote x is sampled uni-
formly at random from D. The abbreviation ppt stands for probabilistic polyno-
mial time. The small-case bold letters s denote a column vector, and large-case
bold letters S =

sij

(i,j)∈I×J to denote a matrix of appropriate size.

526
S. Mukherjee
2.1
Mathematical Tools and Hardness Assumptions
2.1.1
Bilinear Pairing
Let G1, G2, GT are groups of order p which is a large prime number. We consider
an eﬃciently computable and non-degenerate bilinear pairing e : G1 × G2 →GT
where ∀g1 ∈G1, g2 ∈G2, e(ga
1, gb
2) = e(g1, g2)ab for any a, b ∈Zp. We use type-
3 bilinear pairing in this work where G1 and G2 have no known isomorphism.
We deﬁne ABSGen as the group generator that generates the type-3 bilinear
pairing description. Precisely, G = (p, G1, G2, GT, g1, g2) ← ABSGen(1λ) such
that G1, G2, GT are cyclic groups of prime order p where G1 = ⟨g1⟩and G2 =
⟨g2⟩. We denote ga
s by as [15] for any a ∈Zp and s ∈{1, 2, T}. For A = (aij) ∈
Zβ×α
p
, for s ∈{1, 2} we denote
As =
⎛
⎜
⎝
ga11
s
. . . ga1α
s
...
...
...
g
aβ1
s
. . . g
aβα
s
⎞
⎟
⎠∈Gβ×α
s
.
Deﬁnition 1. Let m, k ∈N, such that m > k. We call Dm,k a matrix distribu-
tion if it outputs a matrix M ∈Zm×k
p
of full rank k in polynomial time (w.l.o.g.
we assume the ﬁrst k rows of M ←Dm,k form an invertible matrix). We write
Dk = Dk+1,k.
2.1.2
Bilateral Matrix Diﬃe-Hellman Assumption
For all adversary A, its advantage against the bilateral matrix Diﬃe-Hellman
problem is deﬁned as Advbil-Dℓ,k-matDH
A,G
(λ) =
| Pr[A(U1 , Ux1 , U2 , Ux2) = 1] −Pr[A(U1 , z1 , U2 , z2) = 1]|
where U ←Dℓ,k, x ← Zk
p and z ← Zℓ
p. The bil-Dℓ,k-matDH assumption states
that Advbil-Dℓ,k-matDH
A,G
(λ) is negligible in λ for all ppt adversary A.
3
Broadcast Authenticated Encryption with Keyword
Search
A BAEKS scheme BaEKS is deﬁned by a tuple of ﬁve ppt algorithms
(Setup, KeyGen, SrchEnc, Trapdoor, Test) as following.
3.1
Deﬁnition
– Setup(1λ): It takes the security parameter 1λ and publishes params pp.
– KeyGen(pp): It takes the public parameter pp as input, and outputs public-
private key pair (pk, sk). It keeps sk secret and publishes pk.
– SrchEnc(pp, skS, ω, pkR): It takes pp, a sender secret key skS, a keyword ω
and public-keys pkR = {pkR1, . . . , pkRℓ} of a set of receivers R = {R1, . . . , Rℓ}
where ℓ= poly(λ). It outputs a ciphertext Ct ∈CT .
– Trapdoor(pp, pkS, ˜ω, skR): It takes pp, a sender public key pkS, a keyword ˜ω
and a receiver secret key skR. It outputs a trapdoor Tr ∈T .
– Test(Tr, Ct): It takes Tr and Ct as input, and outputs 0/1.

Statistically Consistent Broadcast Authenticated Encryption
527
Correctness. For any security parameter 1λ, any sender S ∈U, any receiver set
R ⊂U such that pkR = (pkU)U∈R, any keyword ω ∈KW such that if R ∈R,
Pr[Test(Trapdoor(pkS, ω, skR), SrchEnc(skS, ω, pkR)) = 1] = 1 −neg(λ)
where the probability is taken over pp ←Setup(1λ) and (skU, pkU) ←KeyGen(pp)
for all the users U ∈R ⊔{S}.
Informally speaking, if (S = S)∧(˜ω = ω)∧(R ∈R), we say the key-attributes
(S, ˜ω, R) match the ciphertext-attributes (S, ω, R). If Test(Tr, Ct) →1, we say
the trapdoor Tr matches the ciphertext Ct.
Consistency. We give a new deﬁnition of consistency that extends the con-
sistency deﬁnition of PAEKS [13]. Let BaEKS = (Setup, KeyGen, SrchEnc,
Trapdoor, Test) be a BAEKS scheme. We deﬁne the following experiment:
pp ←Setup(1λ)
(pki, ski) ←KeyGen(pp, i) for i ∈R0 ∪R1 ∪{S0, S1, R0, R1}
(ω0, ω1, i, j) ←A

(pkt)t∈R0∪R1∪{S0,S1,R0,R1}
	
s.t. ω0, ω1 ∈KW ∧distinct i, j ∈{0, 1} ∧((Si, ωi, Ri) does not match (Sj, ωj, Rj))
Ct ←SrchEnc(skSi, ωi, pkRi)
Tr ←Trapdoor(pkSj, ωj, skRj)
If Test(Tr, Ct) = 1, Output 1 or 0 Otherwise.
3.2
System Model
We assume a trusted third party generates the system params pp. This is a one-
time procedure. Following this, any user U can generate its own public-private
key pairs (pkU, skU). To compute a searchable ciphertext of a keyword ω for a
set of users (called receiver-set R = {R1, . . . , Rℓ}), a user (called sender S) ﬁrst
collects the receivers’ public keys pkR = {pkR1, . . . , pkRℓ}. S then encrypts the
keyword ω to Ct running SrchEnc on its own secret key skS. Any user can compute
the trapdoor Tr for a keyword ˜ω of interest with its own secret key skR and a
sender’s public key pkS, and send Tr to the cloud server for a search query. The
cloud server can test on Ct and Tr without knowing neither the sender’s identity
nor the receiver’s identity. A document will be returned if all the followings hold:
the underlying keywords are the same (ω = ˜ω), the trapdoor Tr is for querying
the content from the sender S (i.e. S = S) rather than other senders, and the
receiver R is one of the target receivers (i.e. R ∈R) of the searchable ciphertext
Ct. On a glance, this system model will look quite diﬀerent from that of [20] as we
do not consider KGC running KeyGen for all users unlike in [20]. A careful look
at [20] shows that in a BAEKS, KGC does not create/hold any master secret key
and therefore keeping it online throughout the protocol is unnecessary. Thus, we
use it only one-time to generate the system parameters at the starting. From
that point onward every user can generate its own key pairs. This allows us to
be extremely ﬂexible and scalable in terms of user joining. Note that, similar

528
S. Mukherjee
to [20], no predetermined universal keyword set is demanded and any keyword
could be encrypted or searched, thereby increasing the system scalability and
ﬂexibility further.
The above description naturally leads to the threat models we consider.
Firstly we want a ciphertext hides sender information, receiver-set information
and the keyword that it encrypts. We also want a trapdoor should hide sender
information, receiver information and the keyword that it encodes. To put it
more formally, we want the semi-honest cloud server (or any other unauthorized
users) which tests a ciphertext and a trapdoor for match should not learn any
information about the user-information and keyword encoded in the ciphertext
and in the trapdoor. In the next section, we introduce formal security models to
capture these threat models. To attain non-triviality, adversaries in our security
are restricted by natural restrictions. As per our knowledge, our security models
given next considered modeling such strong adversaries for the ﬁrst time.
3.3
Security Model
We highlight some shortcomings of the security models in [20]. We follow this
with new security models for BAEKS.
1. The notion of consistency [1] is quite standard requirement for a searchable
encryption. However, [20] did not show the level of consistency it achieved.
2. All the four security games of [20] are (somewhat) non-adaptive. More pre-
cisely, the users (sender and receiver(s)) involved in the challenge are set
before any trapdoor queries.
3. All the four security games of [20] are (somewhat) one-way. More precisely,
the users (sender and receiver(s)) involved in the challenge are chosen by the
experiment.
4. All four security games of [20] restrict queries (for both ciphertexts and trap-
doors) on the chosen users only.
5. The trapdoor privacy was further weakened to allow deterministic trapdoors.
6. Both ciphertext anonymity and trapdoor anonymity in [20] are very weak as
they consider receiver privacy alone, but the privacy of the sender was never
considered.
7. Moreover, [20] did not provide any argument for neither ciphertext anonymity
nor for trapdoor anonymity.
For completeness, we provide the descriptions of the security models of [20]
verbatim in Appendix A. A savvy reader might want to corroborate the above
shortcomings with the games recalled over there.
Adaptive Security Model. Our new security models address the shortcomings
mentioned above. Firstly, we deﬁne two security models where one captures
ciphertext security while the other captures trapdoors’ security. We emphasize
that both security models capture adaptive semi-honest adversaries. The trap-
door security aims to hide the sender information, the receiver information, and
the keyword encoded in the trapdoor, and the ciphertext security aims to hide
the same information encrypted in the ciphertext.

Statistically Consistent Broadcast Authenticated Encryption
529
Trapdoor Security.
A BAEKS scheme BaEKS satisﬁes trapdoor security
(trap-cpa) if for all ppt adversary A, Advtrap-cpa
A,BaEKS(λ) = neg(λ) where
Advtrap-cpa
A,BaEKS(λ) = | Pr[Exptrap-cpa
BaEKS (1λ, 0, A) = 1] −Pr[Exptrap-cpa
BaEKS (1λ, 1, A) = 1]|
where Exptrap-cpa
BaEKS (1λ, b, A) is deﬁned in Fig. 1.
OCt is an oracle that on input (pkS, ω, pkR) outputs Encrypt(pp, skS, ω, pkR)
after storing {(pkS, ω, pkR)}R∈R in QCt; OTr is an oracle that on input (pkS, ω, pkR)
outputs Trapdoor(pp, pkS, ω, skR) after storing (pkS, ω, pkR) in QTr; Opk is an
oracle that on input j outputs KeyGen(pp, j) after storing (j, pkj) in Qpk. We
implicitly assume pkj has been queried before making a trapdoor or a ciphertext
query or the challenge involving user j.
Fig. 1. Experiment trap-cpa
Fig. 2. Experiment ct-cpa
Ciphertext Security.
A BAEKS scheme BaEKS satisﬁes ciphertext security
(ct-cpa) if for all ppt adversary A, Advct-cpa
A,BaEKS(λ) = neg(λ) for
Advct-cpa
A,BaEKS(λ) = | Pr[Expct-cpa
BaEKS(1λ, 0, A) = 1] −Pr[Expct-cpa
BaEKS(1λ, 1, A) = 1]|
where Expct-cpa
BaEKS(1λ, b, A) is deﬁned in Fig. 2. The oracle OCt, OTr, Opk in Fig. 2
are deﬁned the same as they were in the case of Fig. 1.
4
A Construction of Broadcast Authenticated Encryption
with Keyword Search
As we explained in Introduction, BaEKS below deﬁnes a ciphertext using |R|
many Boneh-Boyen Hash (U⊤
S · ˜ω +V⊤
R )A where USA is sender’s secret key and
VRA is receiver’s public key and deﬁnes a trapdoor as a Boneh-Boyen [4] secret
key αααR + (US · ˜ω + VR)B as a hash proof system where USB is sender’s public
key and αααR, VRB are receiver’s secret key. Test essentially checks if any of the
|R| ciphertext components matches with the given trapdoor.

530
S. Mukherjee
– Setup(1λ):
1. Sample A, B ← Dk.
2. Publish pp = (A1 , A2 , B1 , B2).
– KeyGen(pp, j):
1. Sample αααj ← Z(k+1)
p
.
2. Sample Uj, Vj ← Z(k+1)×(k+1)
p
.
3. Set skj = (αααj2 ,

U⊤
j A

1 , VjB2).
4. Publish pkj = (

ααα⊤
j A

T , UjB2 ,

V⊤
j A

1).
– SrchEnc(pp, skS, ω, pkR):
1. Let pkR = (pkR1, . . . , pkRℓ) where R = (R1, . . . , Rℓ).
2. Sample s ← Zk
p and a random permutation τ : [ℓ] →[ℓ].
3. Compute ct0 = As1, ct1,j
=

(ω · U⊤
S + V⊤
Rτ(j))As

1 and κj
=

ααα⊤
Rτ(j)As

T for all j ∈[ℓ].
4. Output Ct = (ct0, (ct1,1, κ1), . . . , (ct1,ℓ, κℓ)).
– Trapdoor(pp, pkS, ˜ω, skR):
1. Sample r ← Zk
p.
2. Compute tr0 = Br2, tr1 =

αααR + (˜ω · US + VR)Br

2.
3. Output Tr = (tr0, tr1).
– Test(Tr, Ct):
1. Let Ct = (ct0, (ct1,1, κ1), . . . , (ct1,ℓ, κℓ)).
2. Parse Tr = (tr0, tr1).
Output =

1
If e(ct0, tr1) = κj · e(ct1,j, tr0), ∃j ∈[ℓ]
0
Otherwise
.
Correctness. Suppose, S = S, ˜ω = ω and R ∈R = {R1, . . . , Rℓ} for
– Ct = (ct0, (ct1,1, κ1), . . . , (ct1,ℓ, κℓ)) ←SrchEnc(pp, skS, ω, pkR)
– Tr = (tr0, tr1) ←Trapdoor(pp, pkS, ˜ω, skR),
A = e(ct0, tr1) = e(As1 , αααR + (ω · US + VR)Br2)
=

ααα⊤
R As

T·e(

(ω · U⊤
S + V⊤
R )As

1 , Br2)
B = κj·e(ct1,j, tr0) =

ααα⊤
Rτ(j)As

T·e(

(˜ω · U⊤
S + V⊤
Rτ(j))As

1 , Br2)
A
B =

(ααα⊤
R −ααα⊤
Rτ(j))As

T·

r⊤B⊤(ω · U⊤
S −˜ω · U⊤
S + V⊤
R −V⊤
Rτ(j))As

T
Since, S = S, ˜ω = ω and R ∈R (∃j ∈[ℓ], R = Rτ(j)), Pr[A = B] = 1.

Statistically Consistent Broadcast Authenticated Encryption
531
Consistency. Informally speaking, we need to show that for distinct i, j ∈{0, 1},
if Sj ̸= Si or if ωj ̸= ωi or if Rj /∈Ri for adversarially chosen keywords ωj, ωi ∈
KW, a trapdoor Trj ←Trapdoor(pkSj, ωj, skRj) matches a ciphertext Cti ←
SrchEnc(skSi, ωi, pkRi) with only negligible probability. We emphasize that this
holds even against statistical adversary that is given public keys of the senders
and the receivers.
Proof Sketch. Observe that adversary A gets params pp
=
(A1 , A2 ,
B1 , B2). A also gets the public keys for

(pkt)t∈R0∪R1∪{S0,S1,R0,R1}

. It
therefore has access to pkt = (

ααα⊤
t A

T , UtB2 ,

V⊤
t A

1) where αααt ←
Z(k+1)
p
, Ut, Vt
←
Z(k+1)×(k+1)
p
are sampled uniformly at random by the
experiment for all t ∈R0 ∪R1 ∪{S0, S1, R0, R1}. We show that, given all
these information, there is enough entropy in the corresponding secret keys

(skt)t∈R0∪R1∪{S0,S1,R0,R1}

to show that the best A can do is to guess despite
A being an unbounded adversary.
□
To formulate our argument, we sample Ut = Ut + utT and Vt = Vt + vtT
for Ut, Vt, T ← Z(k+1)×(k+1)
p
, ut, vt ← Zp for all t ∈R0 ∪R1 ∪{S0, S1, R0, R1}.
Since, Ut and Vt are uniformly random, Ut and Vt are uniformly random for all
t ∈R0 ∪R1 ∪{S0, S1, R0, R1}. Thus, for all t ∈R0 ∪R1 ∪{S0, S1, R0, R1}, pkt are
properly distributed and do not leak any information about the corresponding ut
and vt. We sample r ← Zk
p. The trapdoor Trj is now Trj = (tr[j]
0 = Br2 , tr[j]
1 =

αααRj + (ωj · USj + VRj)Br + (ωjuSj + vRj) TBr

2). On the other hand, Cti =
(ct[i]
0 , (ct[i]
1,l, κ[i]
l )l∈[ℓ]) for Ri = {R[i]
1 , . . . , R[i]
ℓ}, a random permutation τ : [ℓ] →[ℓ]
and s ← Zk
p such that,
ct[i]
0 = As1
ct[i]
1,l =

(ωi · USi + V⊤
R[i]
τ(l))As + (ωiuSi + vR[i]
τ(l)) T⊤As
	
1
κ[i]
l
=

ααα⊤
R[i]
τ(l)As

T
.
We now focus at the boxed part of the above equations. Let σl = (ωiuSi +
vR[i]
τ(l)) for all l ∈[ℓ] and σℓ+1 = (ωjuSj + vRj).
Case-1 Consider the case Sj ̸= Si.
⎡
⎢⎢⎢⎣
σ1
σ2
...
σℓ+1
⎤
⎥⎥⎥⎦
(ℓ+1)×1
=
⎡
⎢⎢⎢⎢⎢⎣
ωi 0 1 0 · · · 0 0
ωi 0 0 1 · · · 0 0
...
...
...
... ... ...
...
ωi 0 0 0 · · · 1 0
0 ωj 0 0 · · · 0 1
⎤
⎥⎥⎥⎥⎥⎦
(ℓ+1)×(ℓ+3)
×
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
uSi
uSj
vR[i]
τ(1)
vR[i]
τ(2)
...
vR[i]
τ(ℓ)
vRj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
(ℓ+3)×1

532
S. Mukherjee
The above relation between σ1, . . . , σℓ+1 is represented as a system of the
linear equation where the linear transformation has rank (ℓ+ 1). Since,
uSi, uSj, vR[i]
τ(1), . . . , vR[i]
τ(ℓ), vRj are sampled uniformly at random, σ1, . . . , σℓ+1
are too independent and uniformly random.
Case-2 Consider the case Sj = Si ∧ωj ̸= ωi.
⎡
⎢⎢⎢⎣
σ1
σ2
...
σℓ+1
⎤
⎥⎥⎥⎦
(ℓ+1)×1
=
⎡
⎢⎢⎢⎢⎢⎣
ωi 1 0 · · · 0 0
ωi 0 1 · · · 0 0
...
...
... ... ...
...
ωi 0 0 · · · 1 0
ωj 0 0 · · · 0 1
⎤
⎥⎥⎥⎥⎥⎦
(ℓ+1)×(ℓ+2)
×
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
uSi
vR[i]
τ(1)
vR[i]
τ(2)
...
vR[i]
τ(ℓ)
vRj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
(ℓ+2)×1
The above relation between σ1, . . . , σℓ+1 is represented as a system of the
linear equation where the linear transformation has rank (ℓ+ 1). Since,
uSi, vR[i]
τ(1), . . . , vR[i]
τ(ℓ), vRj are sampled uniformly at random, σ1, . . . , σℓ+1 are
too independent and uniformly random.
Case-3 Consider the case Sj = Si ∧ωj = ωi ∧Rj /∈Ri.
⎡
⎢⎢⎢⎣
σ1
σ2
...
σℓ+1
⎤
⎥⎥⎥⎦
(ℓ+1)×1
=
⎡
⎢⎢⎢⎢⎢⎣
ωi 1 0 · · · 0 0
ωi 0 1 · · · 0 0
...
...
... ... ...
...
ωi 0 0 · · · 1 0
ωi 0 0 · · · 0 1
⎤
⎥⎥⎥⎥⎥⎦
(ℓ+1)×(ℓ+2)
×
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
uSi
vR[i]
τ(1)
vR[i]
τ(2)
...
vR[i]
τ(ℓ)
vRj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
(ℓ+2)×1
The above relation between σ1, . . . , σℓ+1 is represented as a system of the
linear equation where the linear transformation has rank (ℓ+ 1). Since,
uSi, vR[i]
τ(1), . . . , vR[i]
τ(ℓ), vRj are sampled uniformly at random, σ1, . . . , σℓ+1 are
too independent and uniformly random.
In other words, σ1, . . . , σℓ+1 are completely uncorelated and as a result Cti and
Trj considered in the consistency game does not match except with negligible
probability.
Security. Next, we argue that our construction BaEKS is adaptively secure.
Theorem 1. If the bil-Dk-matDH Assumption holds in G, then BaEKS is a
trap-cpa-secure BAEKS scheme. Precisely, for any ppt adversary A that breaks
BaEKS in the trap-cpa model making at most q trapdoor queries, at most Q
encryption requests and at most ˜Q public key requests, there exists a ppt algo-
rithm B such that,
Advtrap-cpa
A,BaEKS(λ) ≤(2Q + 1) · Advbil-Dk-matDH
B,G
(λ).

Statistically Consistent Broadcast Authenticated Encryption
533
Theorem 2. If the bil-Dk-matDH Assumption holds in G, then BaEKS is a
ct-cpa-secure BAEKS scheme. Precisely, for any ppt adversary A that breaks
BaEKS in the ct-cpa model making at most q trapdoor queries, at most Q encryp-
tion requests and at most ˜Q public key requests, there exists a ppt algorithm B
such that,
Advct-cpa
A,BaEKS(λ) ≤(2q + 1) · Advbil-Dk-matDH
B,G
(λ).
4.1
Trapdoor Security
Proof of Theorem 1. We give the proof via a hybrid argument similar to the
dual system proof technique [22]. In this proof technique, the ciphertexts and
challenge trapdoors can be of two kinds: (i) normal and (ii) semi-functional.
Note that a semi-functional trapdoor cannot match a semi-functional ciphertext
even if they encode matching attributes.
We informally describe the sequence of games here. Game0 is the real secu-
rity game where the challenge trapdoor, all the queried ciphertexts, and trap-
doors are normal. The challenge trapdoor is made semi-functional in Game1.
Following subsequence of games (Game2,i,1, Game2,i,2, Game2,i,3)i∈[Q] make the
queried ciphertexts semi-functional. In particular, in Game2,i,j the ith ciphertext
is type-j semi-functional. Finally, in Game3, we replace the challenge trapdoor
Tr∗
0 = (tr[0]
0 , tr[0]
1 ) by independent random choices. Note that, we denote Game1
by Game2,0 as well. The indistinguishability of Game0 and Game3 is proven via
the sequence of games mentioned in Table 1.
Table 1. Outline of the proof strategy
Games
Diﬀerence from
Indistinguishability
Previous Game
from Previous Game under Assumption
Game0
–
–
Game1
challenge trapdoor Tr∗
0 is semi-functional
Lemma 1
bil-Dk-matDH
Game2,i,1 ith ciphertext is type-1 semi-functional
Lemma 2
bil-Dk-matDH
Game2,i,2 ith ciphertext is type-2 semi-functional
Lemma 3
information theoretic
Game2,i,3 ith ciphertext is type-3 semi-functional
Lemma 4
bil-Dk-matDH
Game3
challenge trapdoor Tr∗
0 is random
Lemma 5
information theoretic
4.1.1
Semi-functional Algorithms
– sfSrchEnc(pp, skS, ω, skR): Let skR = {skR1, . . . , skRℓ}. Choose s ← Zk
p,
	u1, . . . , 	uℓ, 	s ← Zp and b⊥← Zk+1
p
such that b⊥⊤B = 0. Compute the
semi-functional ciphertext Ct = (ct0, (ct1,j, κj)j∈[ℓ]) as follows:
• ct0 =

As + δb⊥	s

1,
• ct1,j =

νb⊥	uj + (ω · U⊤
S + V⊤
Rτ(j))(As + δb⊥	s)

1,

534
S. Mukherjee
• κj =

ααα⊤
Rτ(j)(As + δb⊥	s)

T,
where if (ν = 0, δ = 1), Ct is a type-1 semi-functional ciphertext; if (ν =
1, δ = 1), Ct is a type-2 semi-functional ciphertext; and if (ν = 1, δ = 0), Ct
is a type-3 semi-functional ciphertext.
– sfTrapdoor(pp, skS, ˜ω, skR): Choose r ← Zk
p, 	r ← Zp and a⊥← Zk+1
p
such
that a⊥⊤A = 0. Compute the semi-functional trapdoor Tr = (tr0, tr1) as
follows.
(tr0, tr1) =

Br + a⊥	r

2 ,

αααR + (˜ω · US + VR)(Br + a⊥	r)

2

.
4.1.2
Sequence of Games
Lemma 1. (Game0 to Game1) For any ppt adversary A that makes at most
q trapdoor queries, at most Q encryption requests, and at most ˜Q public key
requests; there exists a ppt adversary B such that,
|AdvGame0
A
(λ) −AdvGame1
A
(λ)| ≤Advbil-Dk-matDH
B
.
Lemma 2. (Game2,i−1,3 to Game2,i,1) For any ppt adversary A making at most
q trapdoor queries, at most Q encryption requests, and at most ˜Q public key
requests; there exists a ppt adversary B such that,
|AdvGame2,i−1,3
A
(λ) −AdvGame2,i,1
A
(λ)| ≤Advbil-Dk-matDH
B
.
Lemma 3. (Game2,i,1 to Game2,i,2) For any adversary A,
|AdvGame2,i,1
A
(λ) −AdvGame2,i,2
A
(λ)| = 0.
Lemma 4. (Game2,i,2 to Game2,i,3) For any ppt adversary A that makes at
most q trapdoor queries, at most Q encryption requests, and at most ˜Q public
key requests; there exists a ppt adversary B such that,
|AdvGame2,i,2
A
(λ) −AdvGame2,i,3
A
(λ)| ≤Advbil-Dk-matDH
B
.
Lemma 5. (Game2,Q,3 to Game3) For any adversary A,
|AdvGame2,Q,3
A
(λ) −AdvGame3
A
(λ)| = 0.
Lemma 6. (Game3) For any adversary A, |AdvGame3
A
(λ)| = 0.
4.1.3
Proof of Games
Proof of Lemma 1. B receives a bil-Dk-matDH problem instance (N1 ,
y1 , N2 , y2), where y = Nz or y ← Zk+1
p
.
– Setup: B samples b ← {0, 1}, A ←Dk and a⊥← Zk+1
p
such that a⊥⊤A = 0.
It publishes pp = (A1 , A2 , N1 , N2).

Statistically Consistent Broadcast Authenticated Encryption
535
– Query Phase-I: A makes following queries–
• Opk(j): B samples αααj ← Zk+1
p
, Uj, Vj ← Z(k+1)×(k+1)
p
. It returns pkj =
(

ααα⊤
j

T , UjN2 ,

V⊤
j A

1).
• OTr(pkS, ˜ω, pkR): B samples r ← Zk
p. It outputs Tr = (tr0, tr1), where
tr0 = Nr2 , tr1 =

αααR + (˜ω · US + VR)Nr

2.
• OCt(pkS, ω, pkR): B samples s ← Zk
p, deﬁnes a random permutation τ :
[ℓ] →[ℓ] for pkR = {pkR1, . . . , pkRℓ}. It outputs Ct = (ct0, (ct1,j, κj)j∈[ℓ])
where
ct0 = As1 , ct1,j =

(ω · U⊤
S + V⊤
Rτ(j))As

1 , κj =

ααα⊤
Rτ(j)As

T .
– Challenge: A makes a challenge on (pkS∗, ˜ω∗, pkR∗). B computes Tr∗
0 =
(tr[0]
0 , tr[0]
1 ) where tr[0]
0 = y2 and tr[0]
1 =

αααR∗+ (˜ω∗US∗+ VR∗)y

2 and sam-
ples Tr∗
1 ← T . It returns Tr∗
b to A.
– Query Phase-II: Same as Query Phase-I.
– Guess: B forwards b′ that is output by A.
It is easy to see that if y = Nz, Tr∗
0 is normal; and if y ← Zk+1
p
, Tr∗
0 is semi-
functional.
□
Proof of Lemma 2. B receives a bil-Dk-matDH problem instance (M1 ,
z1 , M2 , z2), where z = My or z ← Zk+1
p
.
– Setup: B samples b ← {0, 1}, B ←Dk and b⊥← Zk+1
p
such that b⊥⊤B = 0.
It publishes pp = (M1 , M2 , B1 , B2).
– Query Phase-I: A makes following queries–
• Opk(j): B samples αααj ← Zk+1
p
, Uj, Vj ← Z(k+1)×(k+1)
p
. It returns pkj =
(

ααα⊤
j

T , UjB2 ,

V⊤
j M

1).
• OTr(pkS, ˜ω, pkR): B samples r ← Zk
p. It outputs Tr = (tr0, tr1), where
tr0 = Br2 , tr1 =

αααR + (˜ω · US + VR)Br

2.
• OCt(pkS, ω, pkR): On tth query, B ﬁrst samples a random permutation
τ : [ℓ] →[ℓ] for pkR = {pkR1, . . . , pkRℓ} and does the following:
−t > i: It samples s ← Zk
p to output Ct = (ct0, (ct1,j, κj)j∈[ℓ]):
ct0 = Ms1 , ct1,j =

(ω · U⊤
S + V⊤
Rτ(j))Ms

1 , κj =

ααα⊤
Rτ(j)Ms

T .
−t < i: To output Ct = (ct0, (ct1,j, κj)j∈[ℓ]), it samples s, 	ui,1, . . . , 	ui,ℓ←
Zk
p:
ct0 =Ms1 ,ct1,j =

b⊥ui,j +(ω · U⊤
S + V⊤
Rτ(j))Ms

1 ,κj =

ααα⊤
Rτ(j)Ms

T .

536
S. Mukherjee
−t = i: It outputs Ct = (ct0, (ct1,j, κj)j∈[ℓ]) where
ct0 = z1 , ct1,j =

(ω · U⊤
S + V⊤
Rτ(j))z

1 , κj =

ααα⊤
Rτ(j)z

T .
– Challenge: A makes a challenge on (pkS∗, ˜ω∗, pkR∗). B computes Tr∗
0 =
(tr[0]
0 , tr[0]
1 ) where tr[0]
0
= r2 and tr[0]
1
=

αααR∗+ (˜ω∗US∗+ VR∗)r

2 for
r ← Zk+1
p
and samples Tr∗
1 ← T . It returns Tr∗
b to A.
– Query Phase-II: Same as Query Phase-I.
– Guess: B forwards b′ that is output by A.
It is easy to see that if z = Ny, the ith ciphertext response Ct is normal; and if
z ← Zk+1
p
, the ith ciphertext response Ct is semi-functional.
□
Proof of Lemma 3. Recall that, the challenge trapdoor Tr∗
0 encodes (S∗, ˜ω∗, R∗)
that does not match (S, ω, R) encoded in the ith ciphertext Cti. We here
argue that, the joint distributions of {pp, PK, Cti, Tr∗
0} if Cti is a type-1 semi-
functional ciphertext is identical to the joint distributions of {pp, PK, Cti, Tr∗
0}
if Cti is a type-2 semi-functional ciphertext where pp ←Setup(1λ), PK =
{pkj}j∈R∪{S,R∗,S∗} for (pkj, skj) ←KeyGen(pp, j) and Tr∗
0 = (tr[0]
0 , tr[0]
1 ) ←
sfTrapdoor(skS∗, ˜ω∗, skR∗) is a semi-functional trapdoor.
We sample A, B ←Dk and a⊥, b⊥← Zk+1
p
such that a⊥⊤A = b⊥⊤B = 0
but μ = a⊥⊤b⊥̸= 0. We sample Uj, Vj diﬀerently for any user j. In particular,
we deﬁne Uj = Uj + ujμ−1a⊥b⊥⊤and Vj = Vj + vjμ−1a⊥b⊥⊤for Uj, Vj ←
Z(k+1)×(k+1)
p
and uj, vj ← Zp. Observe from the following equations that pkj
stays the same for all user j.
U⊤
j A = U
⊤
j A
UjB = UjB
V⊤
j A = V
⊤
j A
VjB = VjB
U⊤
j b⊥= U
⊤
j b⊥+ ujμ−1b⊥(a⊥⊤b⊥) = U
⊤
j b⊥+ ujb⊥
Uja⊥= Uja⊥+ ujμ−1a⊥(b⊥⊤a⊥) = Ujb⊥+ uja⊥
V⊤
j b⊥= V
⊤
j b⊥+ vjμ−1b⊥(a⊥⊤b⊥) = V
⊤
j b⊥+ vjb⊥
Vja⊥= Vja⊥+ vjμ−1a⊥(b⊥⊤a⊥) = Vja⊥+ vja⊥
The challenge trapdoor is now Tr∗
0 = (tr[0]
0 , tr[0]
1 ):
tr[0]
0
=

Br + a⊥r

2
tr[0]
1
=

αααR∗+ (˜ω∗· US∗+ VR∗)(Br + a⊥r) + (˜ω∗uS∗+ vR∗) a⊥r

2
On the other hand, Cti = (ct0, (ct1,j, κj)j∈[ℓ]) for |R| = ℓand a random
permutation τ : [ℓ] →[ℓ] where in both the games, ct0 =

As + b⊥	s

1 and
κj =

ααα⊤
Rτ(j)(As + b⊥	s)

T for s ← Zk
p, 	s ← Zp. We now note ct1,j of Cti in
both games.
ct1,j =
⎧
⎪
⎪
⎨
⎪
⎪
⎩

(ω · US+V⊤
Rτ(j))(As+b⊥s) + (ωuS+vRτ(j)) b⊥s

1
in Game2,i,1

b⊥ui,j +(ω · US+V⊤
Rτ(j))(As+b⊥s)+ (ωuS+vRτ(j)) b⊥s

1
in Game2,i,2

Statistically Consistent Broadcast Authenticated Encryption
537
We focus on the boxed-parts of (ct1,j)j∈[ℓ] and tr[0]
1
above. We argue that

σj = (ωuS + vRτ(j))

j∈[ℓ] and σℓ+1 = (˜ω∗uS∗+ vR∗) are uniformly random
and independently distributed. This ensures that b⊥	ui,j are hidden in ct1,j
of Game2,i,2 ensuring type-1 and type-2 semi-functional ciphertexts are indis-
tinguishable even given the challenge semi-functional trapdoor. We show this
independence next while expressing (σi)i∈[ℓ+1] as a system of linear equations:
Case-1 Consider the case S∗̸= S. (Wlog we also consider ˜ω∗= ω and vR∗=
vRτ(j) for some j ∈[ℓ].)
⎡
⎢⎢⎢⎣
σ1
σ2
...
σℓ+1
⎤
⎥⎥⎥⎦
(ℓ+1)×1
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
ω 0 1 0 · · ·
0
· · · 0
ω 0 0 1 · · ·
0
· · · 0
...
...
...
... ...
...
... ...
ω 0 0 0 · · ·
1
· · · 0
...
...
...
... ...
...
... ...
ω 0 0 0 · · ·
0
· · · 1
0 ˜ω∗0 0 · · ·
1
↑
τ(j)th
· · · 0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
(ℓ+1)×(ℓ+2)
×
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
uS
uS∗
vRτ(1)
vRτ(2)
...
vRτ(j)
...
vRτ(ℓ)
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
(ℓ+2)×1
The above relation between σ1, . . . , σℓ+1 is represented as a system of the
linear equation where the linear transformation has rank (ℓ+ 1). Since,
uS, uS∗, vRτ(1), . . . , vRτ(ℓ) are sampled uniformly at random, σ1, . . . , σℓ+1 are
too independent and uniformly random.
Case-2 Consider the case S∗= S ∧˜ω∗̸= ω. Wlog we consider vR∗= vRτ(j) for
some j ∈[ℓ].
⎡
⎢⎢⎢⎣
σ1
σ2
...
σℓ+1
⎤
⎥⎥⎥⎦
(ℓ+1)×1
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
ω 1 0 · · ·
0
· · · 0
ω 0 1 · · ·
0
· · · 0
...
...
... ...
...
... ...
ω 0 0 · · ·
1
· · · 0
...
...
... ...
...
... ...
ω 0 0 · · ·
0
· · · 1
˜ω∗0 0 · · ·
1
↑
τ(j)th
· · · 0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
(ℓ+1)×(ℓ+1)
×
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
uS
vRτ(1)
vRτ(2)
...
vRτ(j)
...
vRτ(ℓ)
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
(ℓ+1)×1
The above relation between σ1, . . . , σℓ+1 is represented as a system of
the linear equation where the linear transformation has rank (ℓ+ 1).
Since, uS, vRτ(1), . . . , vRτ(ℓ) are sampled uniformly at random and ˜ω∗̸= ω,
σ1, . . . , σℓ+1 are also independent and uniformly random.

538
S. Mukherjee
Case-3 Consider the case S∗= S∧˜ω∗= ω∧R∗/∈R. So, we consider vR∗̸= vRτ(j)
for all j ∈[ℓ].
⎡
⎢⎢⎢⎣
σ1
σ2
...
σℓ+1
⎤
⎥⎥⎥⎦
(ℓ+1)×1
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
ω 1 0 · · ·
0
· · · 0 0
ω 0 1 · · ·
0
· · · 0 0
...
...
... ...
...
... ...
...
ω 0 0 · · ·
1
· · · 0 0
...
...
... ...
...
... ...
...
ω 0 0 · · ·
0
· · · 1 0
ω 0 0 · · ·
0
↑
τ(j)th
· · · 0 1
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
(ℓ+1)×(ℓ+2)
×
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
uS
vRτ(1)
vRτ(2)
...
vRτ(j)
...
vRτ(ℓ)
vR∗
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
(ℓ+2)×1
The above relation between σ1, . . . , σℓ+1 is represented as a system of the
linear equation where the linear transformation has rank (ℓ+ 1). Since,
uS, vRτ(1), . . . , vRτ(ℓ), vR∗are sampled uniformly at random, σ1, . . . , σℓ+1 are
also independent and uniformly random.
This naturally ensures that b⊥	ui,j are hidden in ct1,j of Game2,i,2. Thus,
Game2,i,1 and Game2,i,2 are identically distributed.
□
Proof of Lemma 4. Same as Proof of Lemma 2.
□
Proof of Lemma 5. We make a conceptual change here.
– Setup: We sample b ← {0, 1}, A, B ← Dk and a⊥, b⊥← Zk+1
p
such that
a⊥⊤A = b⊥⊤B = 0. We publish pp = (A1 , A2 , B1 , B2).
– Query Phase-I:
• Opk(j): We sample αααj
←
Z(k+1)
p
, Uj, Vj
←
Z(k+1)×(k+1)
p
to set
skj
=
(αααj2 ,

U⊤
j A

1 , VjB2) and publish pkj
=
(

ααα⊤
j A

T ,
UjB2 ,

V⊤
j A

1).
• OTr(pkS, ˜ω, pkR): We sample r ← Zk
p and reply with trapdoor Tr =
(tr0, tr1), where
tr0 = Br2 , tr1 =

αααR + (˜ω · US + VR)Br

2 .
• OCt(pkS, ω, pkR): On ith query, we sample s ← Zk
p and ui,j ← Zk+1
p
for
j ∈[|R|]. We output Ct = (ct0, (ct1,j, κj)j∈[|R|]) where,
ct0 = As1 , ct1,j =

ui,j + V⊤
Rτ(j)As

1 , κ =

ααα⊤
Rτ(j)As

T .
– Challenge: Given the challenge (pkS∗, ˜ω∗, pkR∗), we sample r ← Zk
p, z ←
Zk+1
p
and 	r ∈Zp. Then we return Tr∗
0 = (tr[0]
0 , tr[0]
1 ) where,
tr0 =

Br + a⊥	r

2 , tr1 =

αααR∗+ z + VR∗(Br + a⊥	r)

2 .

Statistically Consistent Broadcast Authenticated Encryption
539
– Query Phase-II: Same as Query Phase-I.
We ﬁrst argue that the modiﬁed ciphertexts are distributed the same way as in
Game2,Q,3. For that, we argue that U⊤
S As + b⊥	ui,j is uniformly random. To see
this, we left multiply them with

B⊤
a⊥⊤

. Then,

B⊤
a⊥⊤

· (U⊤
S As + b⊥	ui,j) =

B⊤U⊤
S As
a⊥⊤U⊤
S As + a⊥⊤b⊥	ui,j

such that a⊥⊤b⊥	ui,j is an uniformly random value. As

B⊤
a⊥⊤

spans the space,
U⊤
S As + b⊥⊤	ui,j is uniformly random. Therefore replacing this with uniformly
random ui,j is invisible to A.
Now we argue that, US∗(Br+a⊥	r) in tr[0]
1 of Game2,Q,3 is uniformly random.
Observe that two mutually exclusive situations can happen that is exhaustive.
1. No ciphertext query involved S∗: US∗is completely hidden from A.
2. If S∗was used for ciphertext queries: U⊤
S∗A is completely hidden in the cipher-
texts by above argument.
Thus, A only gets US∗B from pkS∗and any trapdoor query made on S∗. As a⊥
is outside the span of B, US∗(Br+a⊥	r) is independent from pkS∗. As US∗(Br+
a⊥	r) is independent from US∗B, we replace it by z ← Zk+1
p
.
□
Proof of Lemma 6. Finally, we state that AdvGame3
A
(λ) = 0. This is because, z is
a uniformly random vector that hides VR∗(Br + a⊥	r) in tr[0]
1 .
□
4.2
Ciphertext Security
Proof of Theorem 2. The proof is done via a hybrid argument similar to the
dual system proof technique [22]. In this proof technique, both the challenge
ciphertexts and the queried trapdoors can be of two kinds: (i) normal and (ii)
semi-functional. Note that a semi-functional trapdoor cannot match a semi-
functional ciphertext even if they encode matching attributes.
We informally describe the sequence of games here. Game0 is the real security
game where the challenge ciphertext, all the queried trapdoors, and ciphertexts
are normal. The challenge ciphertext is made semi-functional in Game1. Follow-
ing subsequence of games (Game2,i,1, Game2,i,2, Game2,i,3)i∈[q] make the queried
trapdoors semi-functional. In particular, in Game2,i,j the ith trapdoor is type-j
semi-functional. In Game3, we replace the challenge (κ[0]
j )j∈[|R|] by independent
random choices. Finally, in Game4, we replace the challenge (ct[0]
1,j)j∈[|R|] by inde-
pendent random choices. Note that, we denote Game1 by Game2,0 as well. The
indistinguishability of Game0 and Game4 is proven via the sequence of games
mentioned in Table 2.

540
S. Mukherjee
Table 2. Outline of the proof strategy
Games
Diﬀerence from
Indistinguishability
Previous Game
from Previous Game under Assumption
Game0
-
-
Game1
challenge ciphertext Ct∗
0 is semi-functional
Lemma 7
bil-Dk-matDH
Game2,i,1 ith trapdoor is type-1 semi-functional
Lemma 8
bil-Dk-matDH
Game2,i,2 ith trapdoor is type-2 semi-functional
Lemma 9
information theoretic
Game2,i,3 ith trapdoor is type-3 semi-functional
Lemma 10
bil-Dk-matDH
Game3
challenge (κ[0]
j )j∈[|R|] are random
Lemma 11
information theoretic
Game4
challenge (ct[0]
1,j)j∈[|R|] are random
Lemma 12
information theoretic
Similar to the proof of Theorem 1, we argue the indistinguishability of Game0
and Game4 via a sequence of games overviewed in Table 2. Next, we give the
semi-functional algorithms we would need in the proof.
4.2.1
Semi-functional Algorithms
– sfSrchEnc(pp, skS, ω, skR): Let skR = {skR1, . . . , skRℓ}. Choose s ← Zk
p, 	s ←
Zp and b⊥← Zk+1
p
such that b⊥⊤B = 0. Compute the semi-functional
ciphertext Ct = (ct0, (ct1,j, κj)j∈[ℓ]) as follows:
• ct0 =

As + b⊥	s

1,
• ct1,j =

(ω · U⊤
S + V⊤
Rτ(j))(As + b⊥	s)

1,
• κj =

ααα⊤
Rτ(j)(As + b⊥	s)

T.
– sfTrapdoor(pp, skS, ˜ω, skR): Choose r ← Zk
p, δR, 	v, 	r ← Zp and a⊥← Zk+1
p
such that a⊥⊤A = 0. Compute the semi-functional trapdoors as Tr =
(tr0, tr1) as follows.
(tr0, tr1)=

Br + μa⊥r

2 ,

αααR+νa⊥δR+νa⊥v+(˜ω · US+VR)(Br + μa⊥r)

2

.
where if (ν = 0, μ = 1), Tr is a type-1 semi-functional trapdoor; if (ν = 1, μ =
1), Tr is a type-2 semi-functional trapdoor; and if (ν = 1, μ = 0), Tr is a
type-3 semi-functional trapdoor.
4.2.2
Sequence of Games
Lemma 7. (Game0 to Game1) For any ppt adversary A that makes at most
q trapdoor queries, at most Q encryption requests, and at most ˜Q public key
requests; there exists a ppt adversary B such that,
|AdvGame0
A
(λ) −AdvGame1
A
(λ)| ≤Advbil-Dk-matDH
B
.

Statistically Consistent Broadcast Authenticated Encryption
541
Lemma 8. (Game2,i−1,3 to Game2,i,1) For any ppt adversary A that makes at
most q trapdoor queries, at most Q encryption requests, and at most ˜Q public
key requests; there exists a ppt adversary B such that,
|AdvGame2,i−1,3
A
(λ) −AdvGame2,i,1
A
(λ)| ≤Advbil-Dk-matDH
B
.
Lemma 9. (Game2,i,1 to Game2,i,2) For any adversary A,
|AdvGame2,i,1
A
(λ) −AdvGame2,i,2
A
(λ)| = 0.
Lemma 10. (Game2,i,2 to Game2,i,3) For any ppt adversary A that makes at
most q trapdoor queries, at most Q encryption requests, and at most ˜Q public
key requests; there exists a ppt adversary B such that,
|AdvGame2,i,2
A
(λ) −AdvGame2,i,3
A
(λ)| ≤Advbil-Dk-matDH
B
.
Lemma 11. (Game2,q,3 to Game3) For any adversary A,
|AdvGame2,q,3
A
(λ) −AdvGame3
A
(λ)| = 0.
Lemma 12. (Game3 to Game4) For any adversary A,
|AdvGame3
A
(λ) −AdvGame4
A
(λ)| = 0.
Lemma 13. (Game4) For any adversary A, |AdvGame4
A
(λ)| = 0.
4.2.3
Proof of Games
Proof of Lemma 7. B receives a bil-Dk-matDH problem instance (M1 ,
z1 , M2 , z2), where z = My or z ← Zk+1
p
.
– Setup: B samples b ← {0, 1}, B ←Dk and b⊥← Zk+1
p
such that b⊥⊤B = 0.
It publishes pp = (M1 , M2 , B1 , B2).
– Query Phase-I: A makes following queries–
• Opk(j): B samples αααj ← Zk+1
p
, Uj, Vj ← Z(k+1)×(k+1)
p
. It returns pkj =
(

ααα⊤
j

T , UjB2 ,

V⊤
j M

1).
• OCt(pkS, ω, pkR): Let pkR = {pkR1, . . . , pkRℓ}. B samples a random per-
mutation τ : [ℓ] →[ℓ] and s ← Zk
p to output Ct = (ct0, (ct1,j, κj)j∈[ℓ])
where ct0 = Ms1, ct1,j =

(ω · U⊤
S + V⊤
Rτ(j))Ms

1, κj =

ααα⊤
Rτ(j)Ms

T.
• OTr(pkS, ˜ω, pkR): B samples r ← Zk
p. It outputs Tr = (tr0, tr1), where
tr0 = Br2 , tr1 =

αααR + (˜ω · US + VR)Br

2.
– Challenge: A makes a challenge on (pkS∗, ω∗, pkR∗) where pkR∗
=
{pkR∗
1, . . . , pkR∗
ℓ}. B deﬁnes a random permutation τ : [ℓ] →[ℓ] to compute
Ct∗
0 = (ct0, (ct[0]
1,j, κ[0]
j )j∈[ℓ]) where
ct0 = z1 , ct[0]
1,j =

(ω∗· U⊤
S∗+ V⊤
R∗
τ(j))z

1 , κ[0]
j
=

ααα⊤
R∗
τ(j)z

T .
B also samples Ct∗
1 ← CT and returns Ct∗
b to A.

542
S. Mukherjee
– Query Phase-II: Same as Query Phase-I.
– Guess: B forwards b′ that is output by A.
It is easy to see that if z = My, Ct∗
0 is normal; and if z ← Zk+1
p
, Ct∗
0 is semi-
functional.
□
Proof of Lemma 8. B receives a bil-Dk-matDH problem instance (N1 ,
y1 , N2 , y2), where y = Nz or y ← Zk+1
p
.
– Setup: B samples b ← {0, 1}, A ←Dk and a⊥← Zk+1
p
such that a⊥⊤A = 0.
It publishes pp = (A1 , A2 , N1 , N2).
– Query Phase-I: A makes following queries–
• Opk(j): B samples αααj ← Zk+1
p
, Uj, Vj ← Z(k+1)×(k+1)
p
. It returns pkj =
(

ααα⊤
j

T , UjN2 ,

V⊤
j A

1).
• OCt(pkS, ω, pkR): Let pkR = {pkR1, . . . , pkRℓ}. B samples a random per-
mutation τ : [ℓ] →[ℓ] and s ← Zk
p. It outputs Ct = (ct0, (ct1,j, κj)j∈[ℓ])
where
ct0 = As1 , ct1,j =

(ω · U⊤
S + V⊤
Rτ(j))As

1 , κj =

ααα⊤
Rτ(j)As

T .
• OTr(pkS, ˜ω, pkR): On tth trapdoor query, B does the following:
−t > i: B samples r ← Zk
p. It outputs Tr = (tr0, tr1), where tr0 =
Nr2 , tr1 =

αααR + (˜ω · US + VR)Nr

2.
−t < i: It samples r ← Zk
p and δR, 	vt ← Zp to output Tr = (tr0, tr1),
where
tr0 = Nr2 , tr1 =

αααR + a⊥δR + a⊥	vt + (˜ω · US + VR)Nr

2 .
−t = i: It outputs Tr = (tr0, tr1) where
tr0 = y2 , tr1 =

αααR + (˜ω · US + VR)y

2 .
– Challenge: A makes a challenge on (pkS∗, ω∗, pkR∗) where pkR∗
=
{pkR∗
1, . . . , pkR∗
ℓ}. B samples a random permutation τ : [ℓ] →[ℓ] and s ←
Zk+1
p
. It then computes Ct = (ct0, (ct1,j, κj)j∈[ℓ]) where
ct0 = s1 , ct1,j =

(ω∗· U⊤
S∗+ V⊤
R∗
τ(j))s

1 , κj =

ααα⊤
R∗
τ(j)s

T .
B also samples Ct∗
1 ← CT and returns Ct∗
b to A.
– Query Phase-II: Same as Query Phase-I.
– Guess: B forwards b′ that is output by A.
It is easy to see that if y = Nz, the ith trapdoor response Tr is normal; and if
y ← Zk+1
p
, the ith trapdoor response Tr is semi-functional.
□

Statistically Consistent Broadcast Authenticated Encryption
543
Proof of Lemma 9. Recall that, the challenge ciphertext Ct∗
0 encodes (S∗, ω∗, R∗)
and the ith trapdoor Tri encodes (S, ˜ω, R). We here argue that, the joint distribu-
tions of {pp, PK, Tri, Ct∗
0} if Tri is a type-1 semi-functional trapdoor is identical
to the joint distributions of {pp, PK, Tri, Ct∗
0} if Tri is a type-2 semi-functional
trapdoor where pp ←Setup(1λ), PK = {pkj}j∈R∗∪{S∗,R,S} for (pkj, skj) ←
KeyGen(pp, j) and Ct∗
0 = (ct0, (ct[0]
1,j, κ[0]
j )j∈[ℓ]) ←SFEncrypt(skS∗, ω∗, skR∗) is
a semi-functional ciphertext for skR∗= {skR∗
1, . . . , skR∗
ℓ}.
We sample A, B ←Dk and a⊥, b⊥← Zk+1
p
such that a⊥⊤A = b⊥⊤B = 0
but η = a⊥⊤b⊥̸= 0. Now we sample Uj, Vj in a diﬀerent way for any user j. In
particular, we deﬁne Uj = Uj + ujη−1a⊥b⊥⊤and Vj = Vj + vjη−1a⊥b⊥⊤for
Uj, Vj ← Z(k+1)×(k+1)
p
and uj, vj ← Zp. Observe from the following equations
pkj stays the same for all user j.
U⊤
j A = U
⊤
j A
UjB = UjB
V⊤
j A = V
⊤
j A
VjB = VjB
U⊤
j b⊥= U
⊤
j b⊥+ ujη−1b⊥(a⊥⊤b⊥) = U
⊤
j b⊥+ ujb⊥
Uja⊥= Uja⊥+ ujη−1a⊥(b⊥⊤a⊥) = Ujb⊥+ uja⊥
V⊤
j b⊥= V
⊤
j b⊥+ vjη−1b⊥(a⊥⊤b⊥) = V
⊤
j b⊥+ vjb⊥
Vja⊥= Vja⊥+ vjη−1a⊥(b⊥⊤a⊥) = Vja⊥+ vja⊥
The challenge ciphertext is Ct∗
0 = (ct0, (ct[0]
1,j, κ[0]
j )j∈[ℓ]) for |R| = ℓand the
random permutation τ : [ℓ] →[ℓ] such that ct0 =

As + b⊥	s

1,
ct[0]
1,j =

(ω∗· U
⊤
S∗+ V
⊤
R∗
τ(j))(As + b⊥s)+ (ω∗uS∗+vR∗
τ(j))b⊥s

2
κ[0]
j
=

ααα⊤
R∗
τ(j)(As + b⊥s)

T
On the other hand, Tri
= (tr0, tr1) where in both the games, tr0
=

Br + a⊥	r

1 for r ← Zk
p and 	r, δR, 	vi ← Zp. We now note tr1 of Tri in the
both the games down.
tr1 =
⎧
⎪
⎪
⎨
⎪
⎪
⎩

αααR+(˜ω · US+VR)(Br+a⊥r)+ (˜ωuS+vR)a⊥r

1
in Game2,i,1

αααR+a⊥δR+a⊥vi+(˜ω · US+VR)(Br+a⊥r) + (˜ωuS+vR)a⊥r

1
in Game2,i,2
We focus on the boxed-parts of (ct[0]
1,j)j∈[ℓ] and tr1 above. We argue that

σj = (ω∗uS∗+ vR∗
τ(j))b⊥	s

j∈[ℓ] and σℓ+1 = (˜ωuS + vR)a⊥	r are uniformly ran-
dom and independently distributed. This will naturally ensure that (a⊥δR+a⊥	vi)
is hidden in tr1 of Game2,i,2 ensuring type-1 and type-2 semi-functional trapdoors
are indistinguishable even given the challenge semi-functional ciphertext. We
show this independence by explaining (σi)i∈[ℓ+1] as a system of linear equations
for following mutually exclusive and exhaustive cases:

544
S. Mukherjee
Case-1 Consider the case S∗̸= S. (Wlog we also consider ω∗= ˜ω and vR = vR∗
τ(j)
for some j ∈[ℓ].)
⎡
⎢⎢⎢⎣
σ1
σ2
...
σℓ+1
⎤
⎥⎥⎥⎦
(ℓ+1)×1
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
ω∗0 1 0 · · ·
0
· · · 0
ω∗0 0 1 · · ·
0
· · · 0
...
...
...
... ...
...
... ...
ω∗0 0 0 · · ·
1
· · · 0
...
...
...
... ...
...
... ...
ω∗0 0 0 · · ·
0
· · · 1
0 ˜ω 0 0 · · ·
1
↑
τ(j)th
· · · 0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
(ℓ+1)×(ℓ+2)
×
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
uS∗
uS
vR∗
τ(1)
vR∗
τ(2)
...
vR∗
τ(j)
...
vR∗
τ(ℓ)
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
(ℓ+2)×1
The above relation between σ1, . . . , σℓ+1 is represented as a system of the
linear equation where the linear transformation has rank (ℓ+ 1). Since,
uS∗, uS, vR∗
τ(1), . . . , vR∗
τ(ℓ) are sampled uniformly at random, σ1, . . . , σℓ+1 are
too independent and uniformly random.
Case-2 Consider the case S∗= S ∧ω∗̸= ˜ω. Wlog we consider vR = vR∗
τ(j) for
some j ∈[ℓ].
⎡
⎢⎢⎢⎣
σ1
σ2
...
σℓ+1
⎤
⎥⎥⎥⎦
(ℓ+1)×1
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
ω∗1 0 · · ·
0
· · · 0
ω∗0 1 · · ·
0
· · · 0
...
...
... ...
...
... ...
ω∗0 0 · · ·
1
· · · 0
...
...
... ...
...
... ...
ω∗0 0 · · ·
0
· · · 1
˜ω 0 0 · · ·
1
↑
τ(j)th
· · · 0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
(ℓ+1)×(ℓ+1)
×
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
uS
vR∗
τ(1)
vR∗
τ(2)
...
vR∗
τ(j)
...
vR∗
τ(ℓ)
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
(ℓ+1)×1
The above relation between σ1, . . . , σℓ+1 is represented as a system of
the linear equation where the linear transformation has rank (ℓ+ 1).
Since, uS, vR∗
τ(1), . . . , vR∗
τ(ℓ) are sampled uniformly at random and ω∗̸= ˜ω,
σ1, . . . , σℓ+1 are also independent and uniformly random.
Case-3 Consider the case S∗= S∧ω∗= ˜ω ∧R /∈R∗. So, we consider vR ̸= vR∗
τ(j)
for all j ∈[ℓ].
⎡
⎢⎢⎢⎣
σ1
σ2
...
σℓ+1
⎤
⎥⎥⎥⎦
(ℓ+1)×1
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
ω∗1 0 · · ·
0
· · · 0 0
ω∗0 1 · · ·
0
· · · 0 0
...
...
... ...
...
... ...
...
ω∗0 0 · · ·
1
· · · 0 0
...
...
... ...
...
... ...
...
ω∗0 0 · · ·
0
· · · 1 0
ω∗0 0 · · ·
0
↑
τ(j)th
· · · 0 1
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
(ℓ+1)×(ℓ+2)
×
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
uS
vR∗
τ(1)
vR∗
τ(2)
...
vR∗
τ(j)
...
vR∗
τ(ℓ)
vR
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
(ℓ+2)×1

Statistically Consistent Broadcast Authenticated Encryption
545
The above relation between σ1, . . . , σℓ+1 is represented as a system of the
linear equation where the linear transformation has rank (ℓ+ 1). Since,
uS, vR∗
τ(1), . . . , vR∗
τ(ℓ), vR are sampled uniformly at random, σ1, . . . , σℓ+1 are
also independent and uniformly random.
This naturally ensures that a⊥	vi are hidden in tr1 of Game2,i,2. Thus, Game2,i,1
and Game2,i,2 are identically distributed.
□
Proof of Lemma 10. Same as Proof of Lemma 8.
□
Proof of Lemma 11. We make a conceptual change here.
– Setup: We sample b ← {0, 1}, A, B ← Dk and a⊥, b⊥← Zk+1
p
such that
a⊥⊤A = b⊥⊤B = 0. We publish pp = (A1 , A2 , B1 , B2).
– Query Phase-I:
• Opk(j): We sample αααj ← Z(k+1)
p
, δj ← Zp, Uj, Vj ← Z(k+1)×(k+1)
p
to set
skj = (

αααj + a⊥δj

2 ,

U⊤
j A

1 , VjB2) and publish pkj = (

ααα⊤
j A

T ,
UjB2 ,

V⊤
j A

1).
• OCt(pkS, ω, pkR):
Let
pkR
=
{pkR1, . . . , pkRℓ}.
To
return
Ct
=
(ct0, (ct1,j, κj)j∈[ℓ]), we sample a random permutation τ : [ℓ] →[ℓ],
s ← Zk
p.
ct0 = As1 , ct1,j =

(ωU⊤
S + V⊤
Rτ(j))As

1 , κj =

ααα⊤
Rτ(j)As

T .
• OTr(pkS, ˜ω, pkR): On ith query, we sample r ← Zk
p and δR, 	vi ← Zp. We
output the trapdoor Tr = (tr0, tr1), where
tr0 = Br2 , tr1 =

αααR + a⊥δR + a⊥	vi + (˜ω · US + VR)Br

2 .
– Challenge: Given the challenge (pkS∗, ω∗, pkR∗) for pkR∗
=
{pkR∗
1,
. . . , pkR∗
ℓ}, we sample a random permutation τ : [ℓ] →[ℓ], s ← Zk
p and
	s ∈Zp. Then we compute Ct∗
0 = (ct0, (ct[0]
1,j, κ[0]
j )j∈[ℓ]) where,
ct0 =

As + b⊥s

1
ct[0]
1,j =

(ω∗U⊤
S∗+V⊤
R∗
τ(j))(As + b⊥s)

1
κ[0]
j =

(ααα⊤
R∗
τ(j) +a⊥⊤δR∗
τ(j))(As+b⊥s)

T =

ααα⊤
R∗
τ(j)(As+b⊥s)+δR∗
τ(j)a⊥⊤b⊥s

T .
We sample Ct∗
1 ← CT and return Ct∗
b to A.
– Query Phase-II: Same as Query Phase-I.
Observe that for all j ∈[ℓ], κ[0]
j
=

ααα⊤
R∗
τ(j)(As + b⊥	s) + δR∗
τ(j)a⊥⊤b⊥	s

T. Since
a⊥⊤b⊥̸= 0, 	s ̸= 0, δR∗
1, . . . , δR∗
ℓare chosen uniformly at random, δR∗
τ(j)a⊥⊤b⊥	s
is a uniformly random element for all j ∈[ℓ]. Thus, κ[0]
j
for all j ∈[ℓ] of Ct∗
0 are
uniformly random.
□

546
S. Mukherjee
Proof of Lemma 12. We make a conceptual change here.
– Setup: We sample b ← {0, 1}, A, B ← Dk and a⊥, b⊥← Zk+1
p
such that
a⊥⊤A = b⊥⊤B = 0. We publish pp = (A1 , A2 , B1 , B2).
– Query Phase-I:
• Opk(j): We sample αααj
←
Z(k+1)
p
, Uj, Vj
←
Z(k+1)×(k+1)
p
to set
skj
=
(αααj2 ,

U⊤
j A

1 , VjB2) and publish pkj
=
(

ααα⊤
j A

T ,
UjB2 ,

V⊤
j A

1).
• OCt(pkS, ω, pkR):
Let
pkR
=
{pkR1, . . . , pkRℓ}.
To
return
Ct
=
(ct0, (ct1,j, κj)j∈[ℓ]), we sample a random permutation τ : [ℓ] →[ℓ],
s ← Zk
p where,
ct0 = As1 , ct1,j =

(ωU⊤
S + V⊤
Rτ(j))As

1 , κj =

ααα⊤
Rτ(j)As

T .
• OTr(pkS, ˜ω, pkR): On ith query, we sample r ← Zk
p and vi ← Zk+1
p
. We
output the trapdoor Tr = (tr0, tr1), where
tr0 = Br2 , tr1 =

αααR + ˜ω · USBr + vi

2 .
– Challenge: Given the challenge (pkS∗, ω∗, pkR∗) for pkR∗
=
{pkR∗
1,
. . . , pkR∗
ℓ}, we sample a random permutation τ : [ℓ] →[ℓ], s ← Zk
p and
	s ∈Zp. Then we compute Ct∗
0 = (ct0, (ct[0]
1,j, κ[0]
j )j∈[ℓ]) where,
ct0 =

As + b⊥	s

1 , ct[0]
1,j =

ω∗U⊤
S∗(As + b⊥	s) + zj

1 , κ[0]
j
← GT.
We sample Ct∗
1 ← CT and return Ct∗
b to A.
– Query Phase-II: Same as Query Phase-I.
We ﬁrst argue that the modiﬁed trapdoors are distributed the same way as
they were in Game3. For that, we argue that VRBr + a⊥	vi is uniformly random.
To see this, we left multiply this with

A⊤
b⊥⊤

. Then,

A⊤
b⊥⊤

· (VRBr + a⊥	vi) =

A⊤VRBr
b⊥⊤VRBr + b⊥⊤a⊥	vi

such that b⊥⊤a⊥	vi is an uniformly random value. As

A⊤
b⊥⊤

spans the space,
VRBr+a⊥	vi is uniformly random. Therefore replacing this with uniformly ran-
dom vi is invisible to A.
Then we argue that, for all j ∈[ℓ], VR∗
τ(j)(As + b⊥	s) in ct[0]
1,j of Game3 are
uniformly random. Now, two mutual exclusive situations can happen that are
exhaustive for all j ∈[ℓ],

Statistically Consistent Broadcast Authenticated Encryption
547
1. No trapdoor query involved R∗
τ(j): VR∗
τ(j) are completely hidden from A.
2. If R∗
τ(j) was used for trapdoor queries: VR∗
τ(j)B are completely hidden in the
trapdoors by above argument.
Thus, A only gets V⊤
R∗
τ(j)A from pkR∗
τ(j) and any ciphertext query made on R∗
τ(j).
As b⊥is outside the span of A, V⊤
R∗
τ(j)(As + b⊥	s) is independent from pkR∗
τ(j).
As V⊤
R∗
τ(j)(As + b⊥	s) for all j ∈[ℓ] are independent from V⊤
R∗
τ(j)A, we replace
them by zj ← Zk+1
p
.
□
Proof of Lemma 13. Finally, we state that AdvGame4
A
(λ) = 0. This is because, all
{zj}j∈[ℓ] are uniformly random vectors that hide ω∗· U⊤
S∗(As + b⊥	s) in ct[0]
1,j. □
5
Comparison
We compare our construction with the state of the art [20]. The primary diﬀer-
ence between the two schemes is use of Random Oracle model. We reiterate that
our construction is a standard model construction and does not use assumptions
like hash functions are random.
Functionally both the schemes are quite similar except the shortcomings of
the security models in [20] that we mention in Sect. 3.3. We also mention here
we do not need KGC to stay online throughout and users can generate their own
key-pairs unlike [20].
Tables 3 and 4 provide comparisons of computation cost and communica-
tion overheads. Here, ℓdenotes the size of the privileged set and k is a con-
stant that determines the level of security bil-Dk-matDH assumption provides.
In the following two tables, |Zp| refers to the element size of ﬁeld Zp, |G| (resp.
|G1|, |G2|, |GT|) captures bit-length representation of any element from G (resp.
G1, G2, GT). As exponentiation and pairings dominate the execution time, we
focus on them. Ge refers to exponentiation, Gp refers to pairing.
Table 3. Computation Cost Comparison
SrchEnc
Trapdoor Test
[20] (2ℓ+ 5)Ge + ℓGp
Ge + Gp
(ℓ+ 4)Ge + 2Gp
Our
(2ℓ+ 1)kGe + ℓGp 2kGe
(ℓ+ 1)Gp
Table 4. Communication Complexity Comparison
pp
pki
ski
Ct
Tr
[20] 4|G|
|G|
|Zp|
|Zp| + (ℓ+ 2)|G|
|Zp|
Our
2(k + 1)k|G1|
(k + 1)k|G1|
(k + 1)k|G1|
(ℓ+ 1)(k + 1)|G1| 2(k + 1)|G2|
+2(k + 1)k|G2| +(k + 1)k|G2| +(k + 1)k|G2| +ℓ|GT|
+k|GT|
+(k + 1)|GT|

548
S. Mukherjee
Note that, |Ct| can be further improved by using a universal hash function
that maps GT →Zp. In that case, |Ct| = (ℓ+ 1)(k + 1)|G1| + ℓZp.
From the above two tables (Tables 3 and 4) we see that both the construc-
tions achieve eﬃciency similar asymptotically. However, in concrete terms, ours
look a bit shabby. That being said, we must reiterate that our construction is
instantiated in type-3 settings whereas [20] achieves the construction is less eﬃ-
cient type-1 settings and therefore, a concrete comparison is diﬃcult. We believe
the stronger security guarantees of our construction without hampering the eﬃ-
ciency argues its utility quite convincingly.
6
Conclusion
This paper revamps existing BAEKS security models of [20] to consider cipher-
text and trapdoor security from the lens of sender, receiver, and keyword privacy.
We further propose a consistency deﬁnition for BAEKS. Following this, we pro-
pose a new statistically consistent construction of BAEKS which we prove to
be secure in the standard model. More precisely, our novel BAEKS construc-
tion achieves adaptive security (in terms of both ciphertext security and trap-
door security) under the standard assumption bilateral Matrix Diﬃe-Hellman
(bil-Dk-matDH). Interestingly, our construction still achieves asymptotic eﬃ-
ciency similar to that of [20]. For future work, one might aim for a new construc-
tion that achieves more robust security in the presence of malicious adversaries.
A
Security Models of [20]
In [20], Liu et al. introduced broadcast authenticated encryption with keyword
search (BAEKS) as an extension of public-key authenticated encryption with
keyword search (PAEKS) [18]. To capture the challenges in case of this new
primitive, [20] introduced several security games. We reproduce the games from
[20] next for completeness. They introduced four security games– two games to
capture the security of trapdoors and two to capture the security of ciphertexts.
Trapdoor Privacy. Informally, trapdoor privacy captures trapdoors do not leak
the keywords encoded. The formal security game next is reproduced verbatim
from [20].
– Setup: Given security parameter, the challenger C sends the public parameter
pp, the challenge sender’s public key (pkS∗) and the challenge receiver’s public
key (pkR∗) to the adversary A.
– Query Phase-I:
• Hash Queries: C responds to hash queries with random numbers.
• Ciphertext Query: Given a keyword ω, a receiver set’s public keys R =
{pkR1, . . . , pkRℓ}, C computes a ciphertext w.r.t skS∗, ω and R and returns
it to A.

Statistically Consistent Broadcast Authenticated Encryption
549
• Trapdoor Query: Given a keyword ˜ω, a sender’s public key pkS, a chosen
public key pkRi ∈R, it computes a trapdoor Tr w.r.t. pkS, ˜ω and pkRi,
returns it to A.
– Challenge: A chooses two keywords (˜ω∗
0, ˜ω∗
1) such that (˜ω∗
0, R) and (˜ω∗
1, R)
have not been queried for ciphertexts where pkR∗∈R, and (˜ω∗
0, pkS∗)
and (˜ω∗
1, pkS∗) have not been queried for trapdoors and sends them to C.
C randomly chooses a bit b ← {0, 1} and provides A with a trapdoor
Tr∗←Trapdoor(pkS∗, ˜ω∗
b, skR∗) and returns it to A.
– Query Phase-II: Similar to Query Phase-I maintaining natural restric-
tions.
– Guess: A guesses a bit b′ and wins if b = b′.
Ciphertext Indistinguishability. Informally, ciphertext indistinguishability cap-
tures ciphertexts do not leak the keywords encoded. The formal security game
is as follows.
– Setup: Given security parameter, the challenger C sends the public parameter
pp, the challenge sender’s public key (pkS∗) and the challenge receiver’s set
public key (R∗= {pkR∗
1, . . . , pkR∗
ℓ}) to the adversary A.
– Query Phase-I:
• Hash Queries: C responds to hash queries with random numbers.
• Ciphertext Query: Given a keyword ω, a receiver set’s public keys R =
{pkR1, . . . , pkRℓ}, C computes a ciphertext w.r.t skS∗, ω and R and returns
it to A.
• Trapdoor Query: Given a keyword ˜ω, a sender’s public key pkS, a chosen
public key pkRi ∈R, it computes a trapdoor Tr w.r.t. pkS, ˜ω and skRi,
returns it to A.
– Challenge: A chooses two keywords (ω∗
0, ω∗
1) such that (ω∗
0, pkS∗) and
(ω∗
1, pkS∗) have not been queried for trapdoors and sends them to C. C
randomly chooses a bit b ← {0, 1} and provides A with a ciphertext
Ct∗←SrchEnc(skS∗, ω∗
b, R∗) and returns it to A.
– Query Phase-II: Similar to Query Phase-I maintaining natural restric-
tions.
– Guess: The adversary guesses a bit b′ and wins if b = b′.
Anonymity. Informally, anonymity captures ciphertexts do not leak the receiver
set encoded. The formal security game is as follows.
– Setup: Given security parameter, the challenger C sends the public parameter
pp, the challenge sender’s public key (pkS∗) and the challenge receiver’s set
public key (R∗
0 = {pkR∗
0, pkR∗
2, . . . , pkR∗
ℓ}), (R∗
1 = {pkR∗
1, pkR∗
2, . . . , pkR∗
ℓ}) to
the adversary A.
– Query Phase-I:
• Hash Queries: C responds to hash queries with random numbers.
• Ciphertext Query: Given a keyword ω, a receiver set’s public keys R =
{pkR1, . . . , pkRℓ}, C computes a ciphertext w.r.t skS∗, ω and R and returns
it to A.

550
S. Mukherjee
• Trapdoor Query: Given a keyword ˜ω, a sender’s public key pkS, a chosen
public key from {pkR0, pkR1}, it computes a trapdoor Tr w.r.t. pkS, ˜ω and
pkRi for i ∈{0, 1}, returns it to A.
– Challenge: A chooses a keyword ω∗such that (ω∗, pkS∗) has not been queried
for trapdoors and sends them to C. C randomly chooses a bit b ← {0, 1} and
provides A with Ct∗←SrchEnc(skS∗, ω∗, R∗
b) and returns it to A.
– Query Phase-II: Similar to Query Phase-I maintaining natural restric-
tions.
– Guess: The adversary guesses a bit b′ and wins if b = b′.
Trapdoor Anonymity. Informally, trapdoor anonymity captures trapdoors do not
leak the receiver information encoded. The formal security game is as follows.
– Setup: Given security parameter, the challenger C sends the public parameter
pp, the challenge sender’s public key (pkS∗) and two challenge receiver’s public
key (pkR∗
0, pkR∗
1) to the adversary A.
– Query Phase-I:
• Hash Queries: C responds to hash queries with random numbers.
• Ciphertext Query: Given a keyword ω, a receiver set’s public keys R =
{pkR1, . . . , pkRℓ}, C computes a ciphertext w.r.t skS∗, ω and R and returns
it to A.
• Trapdoor Query: Given a keyword ˜ω, a sender’s public key pkS, a chosen
public key from {pkR0, pkR1}, it computes a trapdoor Tr w.r.t. pkS, ˜ω and
pkRi for i ∈{0, 1}, returns it to A.
– Challenge: A chooses a keyword ˜ω∗such that (˜ω∗
0, pkS∗) has not been
queried for trapdoors and (˜ω∗, R) has not been queried for ciphertexts where
R∗
0, R∗
1 have diﬀerent inclusion relationships with R, and sends them to C.
C randomly chooses a bit b ← {0, 1} and provides A with a trapdoor
Tr∗←Trapdoor(pkS∗, ˜ω∗, skR∗
b ) and returns it to A.
– Query Phase-II: Similar to Query Phase-I maintaining natural restric-
tions.
– Guess: A guesses a bit b′ and wins if b = b′.
References
1. Abdalla, M., et al.: Searchable encryption revisited: consistency properties, relation
to anonymous IBE, and extensions. J. Cryptol. 21(3), 350–391 (2007). https://doi.
org/10.1007/s00145-007-9006-6
2. Attrapadung, N., Furukawa, J., Imai, H.: Forward-secure and searchable broadcast
encryption with short ciphertexts and private keys. In: Lai, X., Chen, K. (eds.)
ASIACRYPT 2006. LNCS, vol. 4284, pp. 161–177. Springer, Heidelberg (2006).
https://doi.org/10.1007/11935230_11
3. Baek, J., Safavi-Naini, R., Susilo, W.: Public key encryption with keyword
search revisited. In: Gervasi, O., Murgante, B., Laganà, A., Taniar, D., Mun, Y.,
Gavrilova, M.L. (eds.) ICCSA 2008. LNCS, vol. 5072, pp. 1249–1259. Springer,
Heidelberg (2008). https://doi.org/10.1007/978-3-540-69839-5_96

Statistically Consistent Broadcast Authenticated Encryption
551
4. Boneh, D., Boyen, X.: Eﬃcient selective-id secure identity-based encryption with-
out random oracles. In: Cachin, C., Camenisch, J.L. (eds.) EUROCRYPT 2004.
LNCS, vol. 3027, pp. 223–238. Springer, Heidelberg (2004). https://doi.org/10.
1007/978-3-540-24676-3_14
5. Boneh, D., Boyen, X., Goh, E.-J.: Hierarchical identity based encryption with
constant size ciphertext. In: Cramer, R. (ed.) EUROCRYPT 2005. LNCS, vol. 3494,
pp. 440–456. Springer, Heidelberg (2005). https://doi.org/10.1007/11426639_26
6. Boneh, D., Di Crescenzo, G., Ostrovsky, R., Persiano, G.: Public key encryption
with keyword search. In: Cachin, C., Camenisch, J.L. (eds.) EUROCRYPT 2004.
LNCS, vol. 3027, pp. 506–522. Springer, Heidelberg (2004). https://doi.org/10.
1007/978-3-540-24676-3_30
7. Boneh, D., Gentry, C., Waters, B.: Collusion resistant broadcast encryption with
short ciphertexts and private keys. In: Shoup, V. (ed.) CRYPTO 2005. LNCS,
vol. 3621, pp. 258–275. Springer, Heidelberg (2005). https://doi.org/10.1007/
11535218_16
8. Boneh, D., Waters, B.: Conjunctive, subset, and range queries on encrypted data.
In: Vadhan, S.P. (ed.) TCC 2007. LNCS, vol. 4392, pp. 535–554. Springer, Heidel-
berg (2007). https://doi.org/10.1007/978-3-540-70936-7_29
9. Byun, J.W., Rhee, H.S., Park, H.-A., Lee, D.H.: Oﬀ-line keyword guessing attacks
on recent keyword search schemes over encrypted data. In: Jonker, W., Petković,
M. (eds.) SDM 2006. LNCS, vol. 4165, pp. 75–83. Springer, Heidelberg (2006).
https://doi.org/10.1007/11844662_6
10. Chatterjee, S., Mukherjee, S.: Keyword search meets membership testing: adaptive
security from SXDH. In: Chakraborty, D., Iwata, T. (eds.) INDOCRYPT 2018.
LNCS, vol. 11356, pp. 21–43. Springer, Cham (2018). https://doi.org/10.1007/
978-3-030-05378-9_2
11. Chen, J., Gay, R., Wee, H.: Improved dual system ABE in prime-order groups
via predicate encodings. In: Oswald, E., Fischlin, M. (eds.) EUROCRYPT 2015.
LNCS, vol. 9057, pp. 595–624. Springer, Heidelberg (2015). https://doi.org/10.
1007/978-3-662-46803-6_20
12. Chi, T., Qin, B., Zheng, D.: An eﬃcient searchable public-key authenticated
encryption for cloud-assisted medical internet of things. Wirel. Commun. Mobile
Comput. 2020, 8816172 (2020). https://doi.org/10.1155/2020/8816172
13. Emura, K.: Generic construction of public-key authenticated encryption with key-
word search revisited: stronger security and eﬃcient construction. In: ASIA Public-
Key Cryptography Workshop. pp. 39–49. APKC ’22, Association for Computing
Machinery, New York, NY, USA (2022). https://doi.org/10.1145/3494105.3526237
14. Emura, K., Miyaji, A., Rahman, M.S., Omote, K.: Generic constructions of secure-
channel free searchable encryption with adaptive security. Secur. Commun. Netw.
8(8), 1547–1560 (2015). https://doi.org/10.1002/sec.1103
15. Escala, A., Herold, G., Kiltz, E., Ràfols, C., Villar, J.: An algebraic framework for
diﬃe–hellman assumptions. J. Cryptol. 30(1), 242–288 (2015). https://doi.org/10.
1007/s00145-015-9220-6
16. Fang, L., Susilo, W., Ge, C., Wang, J.: A secure channel free public key encryption
with keyword search scheme without random oracle. In: Garay, J.A., Miyaji, A.,
Otsuka, A. (eds.) CANS 2009. LNCS, vol. 5888, pp. 248–258. Springer, Heidelberg
(2009). https://doi.org/10.1007/978-3-642-10433-6_16
17. Gentry, C., Waters, B.: Adaptive security in broadcast encryption systems (with
short ciphertexts). In: Joux, A. (ed.) EUROCRYPT 2009. LNCS, vol. 5479, pp.
171–188. Springer, Heidelberg (2009). https://doi.org/10.1007/978-3-642-01001-
9_10

552
S. Mukherjee
18. Huang, Q., Li, H.: An eﬃcient public-key searchable encryption scheme secure
against inside keyword guessing attacks. Inf. Sci. 403–404, 1–14 (2017). https://
doi.org/10.1016/j.ins.2017.03.038, https://www.sciencedirect.com/science/article/
pii/S0020025516321090
19. Jutla, C.S., Roy, A.: Shorter quasi-adaptive NIZK proofs for linear subspaces. J.
Cryptol. 30(4), 1116–1156 (2016). https://doi.org/10.1007/s00145-016-9243-7
20. Liu, X., He, K., Yang, G., Susilo, W., Tonien, J., Huang, Q.: Broadcast authen-
ticated encryption with keyword search. In: Baek, J., Ruj, S. (eds.) ACISP 2021.
LNCS, vol. 13083, pp. 193–213. Springer, Cham (2021). https://doi.org/10.1007/
978-3-030-90567-5_10
21. Pan, X., Li, F.: Public-key authenticated encryption with keyword search achieving
both multi-ciphertext and multi-trapdoor indistinguishability. J. Syst. Architect.
115, 102075 (2021). https://doi.org/10.1016/j.sysarc.2021.102075, https://www.
sciencedirect.com/science/article/pii/S1383762121000643
22. Waters, B.: Dual system encryption: realizing fully secure IBE and HIBE under
simple assumptions. In: Halevi, S. (ed.) CRYPTO 2009. LNCS, vol. 5677, pp. 619–
636. Springer, Heidelberg (2009). https://doi.org/10.1007/978-3-642-03356-8_36
23. Yau, W.-C., Heng, S.-H., Goi, B.-M.: Oﬀ-line keyword guessing attacks on recent
public key encryption with keyword search schemes. In: Rong, C., Jaatun, M.G.,
Sandnes, F.E., Yang, L.T., Ma, J. (eds.) ATC 2008. LNCS, vol. 5060, pp. 100–105.
Springer, Heidelberg (2008). https://doi.org/10.1007/978-3-540-69295-9_10

Modular Design of KEM-Based
Authenticated Key Exchange
Colin Boyd, Bor de Kock(B), and Lise Millerjord
NTNU – Norwegian University of Science and Technology, Trondheim, Norway
{colin.boyd,bor.dekock,lise.millerjord}@ntnu.no
Abstract. A key encapsulation mechanism (KEM) is a basic building
block for key exchange which must be combined with long-term keys in
order to achieve authenticated key exchange (AKE). Although several
KEM-based AKE protocols have been proposed, KEM-based modular
building blocks are not available. We provide a KEM-based authenticator
and a KEM-based protocol in the Authenticated Links model (AM), in
the terminology of Canetti and Krawczyk (2001). Using these building
blocks we achieve a set of generic AKE protocols. By instantiating these
with post quantum primitives we are able to propose several new post-
quantum secure AKE protocols.
1
Introduction
Authenticated key exchange (AKE) is a fundamental tool for establishing secure
communications. An important component in the design of AKE protocols is
Diﬃe–Hellman (DH) key exchange, due to its versatility and potential for pro-
viding security properties such as forward secrecy. Today many real-world AKE
protocols are based on DH implementations, typically in elliptic curve groups;
examples include TLS, IPSec, WireGuard and the generic Noise Framework.
The looming threat of quantum computers has brought about an increasingly
pressing need to ﬁnd post-quantum secure replacements for DH, which itself
is well known to be broken by Shor’s quantum algorithm for ﬁnding discrete
logarithms [5]. In the absence of many promising candidates for a post-quantum
secure direct DH replacement, designs for post-quantum AKE have tended to
make use of key encapsulation mechanisms (KEM). This approach aligns well
with the research literature where many post-quantum candidate KEMs have
been proposed and also with the prominent NIST post-quantum cryptography
competition [1] which requests primitives of only two types, namely a KEM or
a digital signature. Although DH can be framed as a KEM, DH has special
properties which prevent KEMs from being used as a drop-in replacement for
DH. For example, DH has the property that two parties can generate their DH
Boyd and Millerjord are supported by the Research Council of Norway under Project
No. 288545. Author list in alphabetical order; see https://www.ams.org/profession/
leaders/culture/CultureStatement04.pdf. A full version of this work is available on the
IACR ePrint Archive under number 2023/167 [8].
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 553–579, 2023.
https://doi.org/10.1007/978-3-031-35486-1_24

554
C. Boyd et al.
shares completely independently; this cannot be achieved in general with KEMs,
but rather one party must wait for the other party’s input.
Achieving the authenticated part of AKE has traditionally been done by
applying a digital signature scheme on the messages of a key exchange protocol,
but authentication can also be achieved in diﬀerent ways, which can be advanta-
geous for several reasons: for instance to achieve a speed-up or use less memory,
as other works have demonstrated [23].
Although in 2022 the NIST competition for post-quantum secure cryptog-
raphy (PQ or PQ-crypto) has led to the standardization of several signature
schemes, only one KEM was standardized along with an open call for more
schemes to be proposed [1]. To achieve authentication without depending on
this one scheme is a desirable property. One of the main motivations for our
work is to be ﬂexible in the use of cryptographic primitives so that as the secu-
rity of post-quantum KEMs or signatures becomes better understood, and as
new primitives are designed, it is easy to swap in and out diﬀerent ones.
1.1
Modular Design of AKE
Over the past decade, several key exchange protocols using post-quantum can-
didate KEMs have been proposed, both authenticated [13] and unauthenti-
cated [7,14,22]. Some of these protocols have been proposed based on speciﬁc
KEM constructions and the security proofs (where available) relate to speciﬁc
computational assumptions. These are essential constructions for instantiating
protocols using abstract primitives, but when using speciﬁc constructions as the
basis of security for AKE there is a loss of cryptographic agility. Our goal in this
work is to design generic AKE protocols where we can be as ﬂexible as possible
with regard to choice of speciﬁc KEM instantiations and how they are used.
Our protocol designs are based on the modular approach of Bellare, Canetti
and Krawczyk [3,17] (hereafter referred to as BCK98) and Canetti and Krawczyk
[9] (hereafter referred to as CK01). This approach entails deﬁning protocols
which are secure in a world which is ideally authenticated and then compiling
these protocols with authenticators to achieve protocols secure in a world where
adversaries completely control the network. A brief introduction to this modular
approach is given in Sect. 2.2.
A signiﬁcant beneﬁt of the modular approach is the ability to “mix-and-
match” diﬀerent components and to use diﬀerent concrete instances of the same
component within one protocol instantiation. This leads to a plethora of diﬀerent
concrete protocols with varying performance characteristics.
We remark that there already exist several protocol designs which are generic
in the sense that they can use any speciﬁc (secure) instance of diﬀerent cryp-
tographic primitives such as non-interactive key exchange (NIKE), signatures
and/or KEMs [4,15,19]. However, such designs do not allow generic mixing of
diﬀerent generic primitives as can be done with the modular approach. For exam-
ple, the modular approach can be used to replace a digital signature authenti-
cation method which a MAC-based method in the case that a pre-shared key is
available in a particular application.

Modular Design of KEM-Based Authenticated Key Exchange
555
1.2
Contributions
We regard the following as the main contributions of this paper:
1. We develop a new KEM-based authenticator and prove its security as a valid
authenticator in the CK01 deﬁnition, relying on the established CCA-security
deﬁnition for KEMs.
2. We frame the well-known method of using an ephemeral KEM as a DH
replacement as a protocol in the authenticated-links model (AM) of CK01
and prove its security in that model, relying on the established CPA-security
deﬁnition for KEMs.
3. We derive eﬃcient and secure generic AKE protocols which can be instan-
tiated with any appropriately secure KEMs and also matched with other
primitives such as signatures. Some of these generic protocols are completely
new, allowing new instantiations of concrete protocols.
1.3
Related Work
In 2017, De Saint Guilhem, Smart and Warinschi [12] presented a generic trans-
formation to convert any two-round forward-secret, but only passively secure,
key agreement protocol into a three-round authenticated key agreement proto-
col. Recognising the value of avoiding signatures for authentication in the post-
quantum setting, their transformation makes use of generic CCA-secure public
key encryption and a secure MAC. While the approach of De Saint Guilhem et
al. has clear parallels with ours, they rely on encryption rather than the often
more eﬃcient notion of KEMs. Moreover, they do not allow mixing of diﬀerent
authentication methods as we do, nor provide KEM-based concrete passively
secure protocols. Furthermore, their proofs require a key derivation function
modelled as a random oracle. Interestingly, they dismiss the CK01 modular app-
roach stating that it necessarily results in increased number of rounds; below we
will explain why this is not the case.
Several recent works show that KEM-based approaches are suitable for
replacing signatures in real-world applications. The KEMTLS protocol of
Schwabe, Stebila and Wiggers [23] is for instance a complete reworking of the
TLS 1.3 handshake without using signatures, showing that this would in theory
require only half the bandwidth compared to a classical approach—with addi-
tional improvements to be gained if the public keys are exchanged in advance
[24]. Some of these theoretical improvements turned out to be less impactful
when looking at a real-world implementation [10].
Using KEM as a building block for AKE is also done in some other purpose-
speciﬁc works: examples of this include Post-Quantum Noise [2], FSXY [15]
and Post-Quantum WireGuard [18]. These are generic in the sense that any
suitable KEMs can be used, but they do not allow the ﬂexibility of diﬀerent
authenticators that we obtain. Speciﬁcally, they do not provide re-usable and
interchangable components for passive security and for authentication.
There exist many formal security models for AKE, amongst which several are
incomparable [11] in the sense that any one model is often neither stronger nor

556
C. Boyd et al.
weaker than another. The modular approach that we use [9] achieves security
in the well-established model known widely as the CK-model. This encompasses
fundamental security properties of session key indistinguishability against active
attackers who can obtain non-target session keys and adaptively corrupt non-
target parties. Forward secrecy is also captured. This model can be adapted [21]
if other security properties, such as ephemeral key leakage, are desirable.
2
Background
The main goal of this section is to present the background necessary to under-
stand the modular approach of (Bellare), Canetti and Krawczyk [3,9]. This
includes our method to optimise, in a rigorous way, protocols obtained through
the approach.
2.1
Standard Deﬁnitions
We make use of standard deﬁnitions such as KEM, MAC, signatures etc. These
can be found in, for example, the textbook of Katz and Lindell [20].
Deﬁnition 1. A key encapsulation mechanism (KEM) is a tuple of PPT algo-
rithms (Gen, Encap, Decap) such that:
1. The key generation algorithm Gen takes the security parameter 1n and outputs
a public-/private-key pair (sk, pk): (sk, pk) ←Gen(1n).
2. The encapsulation algorithm Encap takes as input a public key pk. It outputs
a ciphertext c and a key k ∈{0, 1}l(n): (c, k) ←Encap(pk).
3. The deterministic decapsulation algorithm Decap takes as input a private key
sk and a ciphertext c, and outputs a key k or the special symbol ⊥denoting
failure: k ←Decap(sk, c).
We require correctness from the KEM: If (sk, pk) ←Gen(1n) and (c, k) ←
Encappk(1n), and k′ ←Decapsk(c), then k′ = k except with negligible probability.
Furthermore we show the CPA (resp. CCA) indistinguishability experi-
ment(s) for KEMs.
Deﬁnition 2. The CPA resp. CCA indistinguishability experiment proceeds as
follows:
1. The key generation algorithm is run: (pk, sk) ←Gen(1n).
2. The encapsulation algorithm is run: (c, k) ←Encap(pk), with k ∈{0, 1}n.
3. A uniform bit b ∈{0, 1} is chosen. If b = 0, set k′ = k. Otherwise, if b = 1,
choose a uniform k′ ∈{0, 1}n.
4. The experiments outputs (pk, c, k′) to A.

Modular Design of KEM-Based Authenticated Key Exchange
557
A is also given access to a decapsulation oracle, Decapsk(·), but cannot
query the decapsulation oracle on the ciphertext c.
5. A outputs a bit b′. If b′ = b, A wins and the experiment outputs 1. Otherwise,
A loses and the experiment outputs 0.
The advantage of the adversary A in the CPA CCA experiment is deﬁned
to be:
Adv
CPA CCA
KEM
(A) = 2 · |Pr [b′ = b] −1/2| .
Deﬁnition 3. A message authentication code or MAC consists of three proba-
bilistic polynomial-time algorithms (Gen, Mac, MacVer) such that:
1. The key-generation algorithm Gen takes as input the security parameter 1n
and outputs a key k with |k| ≥n.
2. The tag-generation algorithm Mac takes as input a key k and a message
m ∈{0, 1}∗, and outputs a tag t. Since this algorithm may be randomized, we
write this as t ←Mack(m).
3. The deterministic veriﬁcation algorithm MacVer takes as input a key k, a
message m and a tag t. It outputs a bit b, with b = 1 meaning valid and b = 0
meaning invalid. We write this as b := MacVerk(m, t).
It is required that for every n, every key k and output by Gen(1n) and every
m ∈{0, 1}, it holds that MacVerk(m, Mac(m)) = 1.
Deﬁnition 4. The existential unforgeability under chosen message attacks
(EUF-CMA ) experiment for MAC(Gen, Mac, MacVer) proceeds as follows:
1. A key is generated: k ←Gen(1n).
2. The adversary A gets oracle access to Mack(·). Let Q be the set of all queries
A made to the oracle. The adversary eventually outputs (m, t).
3. A wins if and only if
(a) MacVerk(m, t) = 1, and
(b) m /∈Q.
In that case the experiment outputs 1. Otherwise, the experiment outputs 0.
The advantage of the adversary A in the EUF-CMA experiment is deﬁned to be:
AdvEUF-CMA
MAC
(A) = Pr

GEUF-CMA
MAC
(A) = 1

.
Deﬁnition 5. A (digital) signature scheme is a tuple of three PTT-algorithms
(Gen, Sign, SigVer) such that:
1. The key generation algorithm Gen takes the security parameter 1n and outputs
a public-/private-key pair (sk, pk): (sk, pk) ←Gen(1n).
2. The signing algorithm Sign takes as input a private key sk and a message m
from some message space (that may depend on pk). It outputs the signature
σ and we write this as σ ←Signsk(m).

558
C. Boyd et al.
3. The deterministic veriﬁcation algorithm SigVer takes as input a public key
pk, a message m and a signature σ. It outputs a bit b, with b = 1 meaning
valid and b = 0 meaning invalid. We write this as b := SigVerpk(m, σ).
We require correctness from the scheme: If (sk, pk) ←Gen(1n) then, except with
negligible probability, SigVerpk(m, Signsk(m)) = 1.
For brevity we often denote the key generation algorithms from the various
primitives as Gen(), omitting the security parameter.
2.2
Canetti–Krawczyk Modular Design
The modular approach, arising originally in a 1998 paper of Bellare, Canetti and
Krawczyk [3], is to ﬁrst deﬁne protocols secure against a limited adversary which
can then be promoted to protocols secure against a realistic adversary using a
generic compiler. In the authenticated links model (AM) the adversary is not per-
mitted to fabricate messages, but can otherwise control the network and deliver
messages out of order or to diﬀerent parties from those intended. Compilers, or
authenticators, can be applied to messages in an AM protocol to obtain proto-
cols in the unauthenticated links model (UM) where the adversary can alter or
fabricate messages limited only by the available computational power.
In both the UM and AM, adversaries control the execution of protocols by
initiating parties and then invoking parties with available queries, including with
message inputs. (In Sect. 2.4 we describe the available adversarial queries.) Par-
ties respond to input messages by following the protocol deﬁnition and to other
queries as deﬁned by the query. Each party computes local output which is
available to the adversary. The local output includes protocol decisions, such
as whether a message is accepted (see Sect. 2.4 for details).
Bellare et al. [3] provide a theorem showing that a secure protocol, ΠAM, in
the AM maps to a secure protocol in the UM, ΠUM, if the mapping is deﬁned by
a valid authenticator. An authenticator is valid if an observer, or distinguisher, is
unable to distinguish between the world where an adversary A is interacting with
the ΠAM and the world where an adversary U is interacting with the protocol
ΠUM. This is captured in the notion of protocol emulation in Deﬁnition 7.
Deﬁnition 6. The AM-UM distinguishing experiment, GAM-UM-dist
ΠAM-ΠUM (D) proceeds
as follows: (1) A uniform bit b ∈{0, 1} is chosen. If b = 0, D will interact with
A and the AM protocol ΠAM. Otherwise, if b = 1, D will interact with U and the
UM protocol ΠUM. (2) To conclude the experiment, D will halt and output b′.
(3) The experiment will output 1 if and only if b = b′. We deﬁne the advantage
of the distinguisher D to be
AdvAM-UM-dist
ΠAM-ΠUM (D) = 2 ·
Pr

GAM-UM-dist
ΠAM-ΠUM (D) = 1

−1
2
 .
Deﬁnition 7. Let ΠUM and ΠAM be protocols in the UM and AM models respec-
tively. We say that ΠUM ϵ-emulates ΠAM in unauthenticated networks if for any

Modular Design of KEM-Based Authenticated Key Exchange
559
UM-adversary U interacting with ΠUM, there exists an AM-adversary A inter-
acting with ΠAM such that for any distinguisher D playing the AM-UM distin-
guishing game, AdvAM-UM-dist
ΠAM-ΠUM (D) ≤ϵ.
An authenticator is a speciﬁc type of protocol compiler transforming one protocol
into another. The modularity of the approach relies on the observation that an
authenticator will actually preserve protocol security as we will see in Sect. 2.4.
Deﬁnition 8 ([3]). An authenticator is a compiler, C, that takes an AM pro-
tocol ΠAM as input and outputs a UM protocol ΠUM, such that ΠUM emulates
ΠAM.
2.3
MT-authenticators
Deﬁning an authenticator for any protocol, regardless of the number of messages,
seems at ﬁrst a diﬃcult problem. To deal with this, BCK98 [3] deﬁne a simpler
notion of an MT-authenticator, designed to authenticate a single arbitrary mes-
sage. They also showed that repeated use of a valid MT-authenticator is a valid
authenticator, so that protocol messages can be treated separately.
A bit more formally we deﬁne MT as a message transmission protocol in
authenticated networks that works as follows: when Pi is activated with (Pj, m),
party Pi sends the message (Pi, Pj, m) to party Pj and outputs “Pi sent m to Pj”.
Upon receiving (Pi, Pj, m), Pj outputs “Pj received m from Pi”. Note that the
quoted outputs are local outputs of the parties and are critical in proving proper
emulation; however, when we later show compiled protocols we omit mention of
these local outputs.
An MT-authenticator, λ, is a protocol that emulates MT in unauthenti-
cated networks. Given a sequence of MT-authenticators, Λ = (λ1, λ2, . . . , λt),
the derived protocol compiler, CΛ, uses the next MT-authenticator to authen-
ticate the next message. More precisely, given a protocol Π in the AM with t
messages, m1, m2, . . . , mt the protocol Π′ = CΛ(Π) in the UM is deﬁned as
follows. For each message, mk, sent in Π, λk is run to send the same message
from the same initiator to the same recipient. Whenever a party, Pj, outputs
“Pj received m from Pi” in λk, then Π is activated at Pj with message mk from
Pi. If Λ is a sequence of t MT-authenticators then CΛ is an authenticator. We
restate this in Theorem 1 and give a sketch of the proof, which is given in full
in [3].
Theorem 1 ([3]). Let Λ = (λ1, λ2, . . . , λt) be a sequence of t MT-authenticators
so that each λk ϵ-emulates MT. Then the compiler, CΛ, will be an authenticator
such that for any protocol Π in the AM, CΛ(Π) (t · ϵ)-emulates Π in the UM.
Proof. Let Π be an AM protocol. Let U be a UM-adversary interacting with
CΛ(Π). A runs U on a simulated interaction. Action requests from U to parties
in the UM can be mimiced by A in the AM and A relays its results back to U.
The only problem with the simulation could occur in the case that U speciﬁes
that a message is received by some party Pj from some party Pi in the UM, but

560
C. Boyd et al.
Fig. 1. Bob authenticates message m from Alice.
that message is not in the set of messages waiting for delivery in the AM. But
this can happen with probability bounded by ϵ. Such an event could occur for
any of the t messages and so the probability that the simulation is correct is at
least (1 −ϵ)t ≥1 −t · ϵ. Finally, any observer will be able to distinguish between
the run of Π in the AM and CΛ(Π) in the UM with advantage at most ϵ′ = t · ϵ.
Note that although we have assumed that each MT-authenticator has the
same security level ϵ, the theorem is still true if the MT-authenticators have
diﬀerent security levels ϵ1, ϵ2, . . . , ϵt and we take ϵ = maxk(ϵk). In the cases we
are interested in, we will always have t = 2.
An example of an MT-authenticator is the encryption-based authenticator [3]
shown in Fig. 1, where NB denotes a nonce and (eA, dA) an encryption-decryption
keypair. This is a valid MT-authenticator as long as the public key encryption
used is CCA-secure and the MAC is secure. The protocol can be optimized in
various ways, as we will show later.
There exist several other MT-authenticators deﬁned in the literature includ-
ing signature-based [3], MAC-based [9] and password-based [17]. We show, in
compressed form, the signature-based MT-authenticator later (Fig. 8). The mod-
ular approach allows combination of any MT-authenticator together with any
AM-protocol, resulting in automatically secure UM protocols. Therefore adding
any new building block, either an MT-authenticator or an AM-protocol, results
in several new protocols of potential interest.
2.4
SK-security
SK-security is the AKE security notion of CK01 [9], capturing session key indis-
tinguishability and correctness of the protocol. To deﬁne this notion we need to
state the capabilities of the adversary and the indistinguishability experiment.
Each protocol run at a party A is associated with a session identiﬁer s. In the AM
the value s is an input at the start of a run to the initiator party. Later we will see
that session identiﬁers can be replaced by protocol messages as long as parties
can verify that no incomplete sessions between the same parties have the same
session identiﬁer. The state of a session consists of the following information:

Modular Design of KEM-Based Authenticated Key Exchange
561
– status – whether or not the session is complete, aborted, or still in progress;
– any ephemeral key material needed to complete the protocol;
– the session key, sk, if the protocol is completed and has not expired.
The global state of a party may include long-term authentication keys
pk A, sk A. As in most AKE models, we do not explicitly model distribution of
long-term keys. Furthermore, we assume that long-term public keys are imme-
diately available to any party that needs them. This may be too strong an
assumption in some real-world protocols, such as TLS, and we remark further
on this issue when we examine concrete protocols in Sect. 5.
Deﬁnition 9 (Matching sessions [9]). The two sessions (A, B, s, role) and
(A′, B′, s′, role′) are matching if A = B′, B = A′ and s = s′.
The adversary may issue the following queries, subject to certain restrictions we
will see later.
– NewSession(A, B, s, r): the adversary issues the NewSession query to party
A, specifying its intended partner B, the session identiﬁer1 s, and the role r
(initiator or responder) of A in the session. A will follow the protocol deﬁnition
and may return an output message intended for B.
– Send(A, B, m): represents activation of A by an incoming message m (possibly
including a session identiﬁer) from party B. A will follow the protocol and may
reject, accept, or return an output message intended for B.
– Corrupt(A): the adversary learns the whole state of A including any long-term
keys. The corruption event is recorded in the local output of A. Subsequently
A can never be activated but the adversary can take the role of A in the
protocol.
– RevealKey(A, B, s): the adversary learns the session key accepted in the session
s by A with partner B, if it exists. The reveal event is recorded in the local
output of A.
– RevealState(A, B, s): the adversary learns the state information associated
with session s at A, such as ephemeral keys. The reveal state event is recorded
in the local output of A.
– Expire(A, B, s): if there is a completed session s at A with B then any session
key associated with that session is deleted from the memory of A. The Expire
event is recorded in the local output of A.
– Test(A, B, s): this query can be asked only once and can only be made to a
completed session s at A with partner B. Furthermore there cannot have been
any of the following queries made: RevealKey(A, B, s) or RevealState(A, B, s)
or Corrupt(A) or Corrupt(B). If the bit b speciﬁed by the challenger is b = 1
then the session key is returned. Otherwise b = 0 and a random key from the
keyspace are returned.
Now we are in a position to deﬁne the SK-security experiment.
1 We remark that instantiation of session identiﬁers diﬀers between the models. In UM,
s can be blank as the session identiﬁer need not be determined by the adversary.

562
C. Boyd et al.
Deﬁnition 10. The key indistinguishability experiment, GKey-Ind
Π
(A) is deﬁned
as follows: (1) The challenger chooses a random bit b needed to deﬁne the Test
query response. (2) The challenger initialises n parties and any long-term keys.
(3) A may issue queries as deﬁned above. (4) Eventually A halts and outputs
a bit b′ to indicate its guess for b, based on the response to the Test query. The
experiment outputs 1 if and only if b′ = b.
Deﬁnition 11. A key exchange protocol Π is ϵ −SK-secure if the following
holds for any adversary A:
– two honest parties (i.e. uncorrupted parties who faithfully execute the protocol
instructions) completing matching sessions of the protocol Π will output the
same key, except with negligible probability, and
– the advantage of the adversary U in the key indistinguishability experiment
is: AdvKey-Ind
Π
(A) = 2 · |Pr [b′ = b] −1/2| ≤ϵ.
The ﬁnal step needed to bring the modular approach together is to show that
emulation preserves SK-security. This was proven in CK01 and we re-state and
re-prove it as Theorem 2 including concrete bounds. Note that using emulation
of an ideal key exchange process as a deﬁnition of security, the original idea of
BCK98, results in too strong a deﬁnition to allow some well-known protocols to
be proven secure [9, Appendix A].
Theorem 2 ([9]). Let Π be an ϵ−SK-secure protocol in the AM with t messages.
Let CΛ be the compiler based on MT-authenticators λ1, λ2, . . . , λt such that for
any protocol Π in the AM, CΛ(Π) α-emulates Π in the UM. Then protocol
Π′ = CΛ(Π) is an ϵ′ −SK-secure protocol in the UM with ϵ′ = ϵ + α.
Proof. Assume to the contrary that there exists a UM adversary U that has
advantage ϵ′ in the UM. Using U, we build an AM adversary, A, playing the
game of Deﬁnition 10. When A receives its setup information consisting of system
parameters and public keys from its challenger, A sends the same information to
U. Then A invokes U and mimics its behaviour in the AM, using its challenger
to respond to the action requests when any party is exposed.
When U sends a message to a party Pj from a party Pi in the UM, A sends
the same message between the same parties in the AM. The emulation will be
perfect unless U successfully sends a message m to some party Pj from Pi but
m was never sent by Pi. In this case we will say that U made a forgery and we
let forge be the event that a forgery happens at any time during the run of U.
If forge occurs then A will abort the simulation and return a random bit to
its challenger. Note that this also deﬁnes a distinguisher D which will always win
in the case that forge occurs. If forge does not occur then at some point U will
ask its Test query for a session s. A then announces session s for its own Test
query in the AM, receives a real or random key, and returns it to U. Eventually
U will halt and output its bit which A copies as its response. In this case, A
wins whenever U wins.

Modular Design of KEM-Based Authenticated Key Exchange
563
Pr[A wins] = Pr[A wins|forge] · Pr[forge] + Pr[A wins|¬forge] · Pr[¬forge]
= 1/2 · Pr[forge] + Pr[B wins] · (1 −Pr[forge])
≥Pr[B wins] −1/2 · Pr[forge]
We also implicitly deﬁned a distinguisher, D, which wins when forge occurs or
wins with probability at least 1/2 when forge does not occur: Pr[D wins] ≥
Pr[forge]/2 + 1/2. Putting this together we get:
AdvKey-Ind
Π′
(U) ≤AdvKey-Ind
Π
(A) + AdvAM-UM-dist
Π−Π′
(D).
2.5
Optimising the UM Protocol
Simple application of an MT-authenticator to each message of an SK-secure AM
protocol results in an SK-secure UM protocol as proven in Theorem 2. However,
such a protocol is far from optimal. The most obvious drawback is that a two-
message protocol, such as Diﬃe–Hellman, compiles to a six-message protocol.
The obvious way to optimise such a protocol is to “piggyback” messages going
in the same direction. The resulting protocol may be secure, but formally this
process may break the security proof because it may alter the order of the
local output of the parties, allowing trivial distinguishability outputs of the AM
protocol from the outputs of the compiled UM protocol [17].
Because of such issues, the modular approach of CK01 has been criticised
[12] for not achieving eﬃcient protocols. There is some truth in such criticisms—
for example, when using signature- or encryption-based authenticators it is not
possible to achieve secure 2-message AKE protocols which are often seen in
the literature. Fortunately, rigorous optimisations are not diﬃcult to achieve,
typically resulting in 3-message protocols as eﬃcient as real-world protocols.
Indeed, 3-message AKE protocols are necessary in any case to achieve desirable
security properties such as mutual entity authentication or key conﬁrmation.
Hitchcock et al. [17] designed a general technique for altering message order-
ing in a security-preserving way. This involved deﬁning an intermediate model
between the AM and UM, which they call the hybrid model. Rather than use this
more comprehensive approach, here we apply simple techniques to allow optimi-
sation of the number of messages and re-use message components as session iden-
tiﬁers. Consequently, the drawbacks of practical application of authenticators are
removed resulting in generic protocols as eﬃcient as standalone protocols.
Compressed Authenticators. The ﬁrst step is to compress the authenticator
to remove redundant elements. Notice that use of the authenticator in Fig. 1
expands each message m from the AM into three messages in the UM. However,
sending m in all three messages is not actually needed (to achieve security), so
we can simplify the encryption-based authenticator into a compressed version
shown in Fig. 2. It is not hard to see [3,17] that removal of the repeated m
ﬁelds does not aﬀect the security of the MT-authenticator. Depending on the

564
C. Boyd et al.
Fig. 2. Compressed version of MT-authenticator in Fig. 1.
application scenario, the version in Fig. 1 may remain appropriate. The version
in Fig. 2 is useful in a situation where Bob knows that some message, as yet
unknown, will be authentically received from Alice; this case typically occurs in
AKE protocols. Later we will see that to apply optimisation it is important that
the ﬁrst message in Fig. 2 is independent of the message to be authenticated, so
that it can be generated and sent early in the protocol.
Session Identiﬁers. In the original formulation of CK01, session identiﬁers are
sent in each protocol run in the AM. These must be unique for each active
protocol run between the same parties, but it is not deﬁned how they should be
obtained in practice. Although the only property required of session identiﬁers is
uniqueness, a natural way of obtaining them is to use random values chosen by
each party; in that case the probability that session identiﬁers are not unique is
negligible. In practice it may not be a burden for each party to ensure that there
are no other incomplete sessions with the same identiﬁer so that uniqueness is
unconditionally guaranteed.
We assume that higher communication layers will provide a mechanism to
ensure that messages get delivered to the correct session. They can also be
explicitly added to the protocol messages if desired.
3
KEM-Based Building Blocks
This section deﬁnes and proves security for the basic KEM-based MT-
authenticator and AM protocol, which will be brought together in Sect. 4 as
components in deﬁning generic eﬃcient KEM-based AKE.
3.1
KEM-Based MT-authenticator
Figure 3 illustrates our KEM-based MT-authenticator. The construction is closely
related to the encryption-based authenticator of BCK98.

Modular Design of KEM-Based Authenticated Key Exchange
565
Fig. 3. KEM-based MT-authenticator, λKEM: Bob authenticates m from Alice.
Next we give a theorem that λKEM is secure, meaning that it emulates MT
in unauthenticated networks, as long as the KEM used achieves CCA security.
The proof of Theorem 3 follows the proof strategy of Bellare et al. [3, Prop. 5]
for their encryption-based authenticator. The complete proof is given in the full
version [8].
Theorem 3. The KEM-based MT-authenticator, λKEM, in Fig. 3, when instan-
tiated with a CCA-secure KEM and a secure MAC scheme, ϵ-emulates protocol
MT in unauthenticated networks such that ϵ ≤l · (AdvCCA
KEM(D) + AdvEUF-CMA
MAC
(F))
where l = n2
P × nM, nP is the number of parties that run the protocol and nM
is the maximum number of challenge messages that can be sent by any party.
Now that λKEM is proven to be an MT-authenticator we can invoke Theorem 2
to conclude that λKEM can be used to authenticate messages in an SK-secure
AM protocol and results in a SK-secure UM protocol. In order to optimise the
resulting protocol we will want to use a compressed version of the authenticator
(see Sect. 2.5) as shown in Fig. 4.
Fig. 4. λKEM, the compressed KEM-based MT-authenticator.

566
C. Boyd et al.
Fig. 5. KEM-based protocol with any CPA-secure KEM (see Deﬁnition 2).
The security proof for the compressed authenticator is identical to the proof
for the full authenticator since the only diﬀerence is the deletion of plaintext
messages in the UM which are ignored in the security proof.
Corollary 1. Theorem 3 still holds if the authenticator in Fig. 3 is replaced by
the compressed KEM-based MT-authenticator, λKEM, in Fig. 4.
3.2
KEM-Based AM Protocol
In Fig. 5 we present a KEM-based protocol Π that is SK-secure in the AM. The
protocol is a generalisation of the basic Diﬃe–Hellman AM protocol of CK01 [9].
We assume that a setup with parameters for the KEM is known already to all
parties. The initiator A will be invoked by the NewSession(A, B, s, r) query and
responds with a new ephemeral KEM public key pk e. Upon receipt of (pk e, s)
the responder encapsulates a new session key sk in c, and returns it to party A.
Theorem 4. Let A be an adversary against the SK-security of protocol Π shown
in Fig. 5. Let A interact with at most q sessions of Π for each pair of parties.
Let n be the maximum number of parties involved in the protocol run. Then the
advantage of A can be bounded by: AdvSK
Π (A) ≤n2q · AdvCPA
KEM(B).
The proof of Theorem 4 is in the full version [8].
4
Generic KEM-Based AKE Protocols
With the building blocks from Sect. 3 we now apply MT-authenticators to AM
protocols and optimise them to obtain protocols which are both SK-secure in
the realistic UM security model and eﬃcient in comparison with other protocols
in the literature. There is no restriction to apply the new MT-authenticator in
Fig. 4 only to the new AM protocol in Fig. 5; the authenticator can be applied to
any SK-secure AM protocol and any authenticator can be applied to the KEM-
based AM protocol. Furthermore, we may apply diﬀerent MT-authenticators to
each of the messages in an AM protocol [17, Theorem 6] resulting in yet more
ways to construct diﬀerent secure protocols.

Modular Design of KEM-Based Authenticated Key Exchange
567
Fig. 6. Generic 4-message protocol obtained by compiling the KEM-based AM protocol
with the compressed KEM-based MT-authenticator.
Due to our ﬁeld’s focus on post-quantum security in recent years, we empha-
sise KEM-based and signature-based components in this section, allowing us to
apply any of the primitives from the NIST competition library. We illustrate
this usage with several diﬀerent examples in this section, applying both our
new KEM-based authenticator and the existing signature-based authenticator
to achieve a variety of protocols. Another example, also with potential for post-
quantum security, is to apply the MAC-based authenticator of CK01 to our
KEM-based AM protocol. This results in a protocol suitable for pre-shared key
environments which is a common scenario, for example in TLS and IPSec. Details
of a MAC-based generic protocol construction are available in Appendix 3.
4.1
Compiled KEM-Based Protocol and Optimization
We start with the AM-secure protocol from Fig. 5 and then apply the compiler
consisting of application of the compressed MT-authenticator to each of its two
messages. This leads to the 4-message protocol of Fig. 6.

568
C. Boyd et al.
Fig. 7. Optimised UM protocol from the KEM-based AM protocol and the KEM-based
MT-authenticator.
Messages 1 and 2 are the result of applying the compressed MT-authenticator
to authenticate the ephemeral public key pk e generated by Alice. Messages 3 and
4 are the result of applying the compressed MT-authenticator to authenticate
the encapsulated shared key c∗generated by Bob. The diﬀerence between m1
and m′
1 (resp. m2 and m′
2) in Fig. 6 is that both players have their own version
of s—the MAC veriﬁes the integrity of both the message and the session.
To optimise the 4-message protocol in Fig. 6 we take four simple steps: (1)
The messages that were numbered 2 and 3 will be sent in parallel as a new
message with number 2. This does not change the order or contents of any
messages. (2) The session identiﬁer, s, will be constructed by the parties as part
of the protocol, instead of taking it as an external input to the protocol. Recall
that the only requirements on s are to be unique between the parties amongst
any incomplete protocol session between the two parties. We choose s = c1 ∥c2
where c1 and c2 are the (randomised) encapsulations (ciphertexts) generated
by each party. (3) Repeated message ﬁelds and ﬁelds previously generated by
message receivers are removed from messages. (4) The protocol parties are re-
labelled so that Alice becomes the protocol initiator. Combining all of these steps
we obtain the optimised protocol shown in Fig. 7.
As far as we are aware, the precise protocol of Fig. 7 is new in the literature.
There are several existing protocols also aimed at achieving AKE based only on
KEMs [15,18,23] or encryption [12]. Several of these are motivated by the desire
to avoid signatures, which tend to suﬀer eﬃciency disadvantages compared with
KEMs in the post-quantum examples from the NIST competition. The security

Modular Design of KEM-Based Authenticated Key Exchange
569
Fig. 8. λSign, a compressed signature-based MT-authenticator.
varies between of each these protocols. For example, the FSXY protocol [15]
provides security against ephemeral key leakage whereas KEMTLS [23], like the
protocol of Fig. 7, lacks this property. On the other hand, our protocol does allow
state reveals from non-target sessions. KEMTLS is also designed to provide only
one-way (server) authentication. Making a judgement on which of these protocols
is “better” is therefore diﬃcult since it depends on the security requirements and
implementation details. In Sect. 5 we compare eﬃciency using concrete KEMs
and signature schemes to get a better feel for the relative eﬃciencies.
4.2
Generic Protocols Using Signatures
We now look at two further generic protocols which we can obtain by using
signatures in combination with our KEM-based AM protocol. We will need to
apply the compressed signature-based authenticator shown in Fig. 8.
The authenticator λSign is derived from the authenticator of BCK98 by remov-
ing the unnecessary message components in exactly the same way as for the
encryption- and KEM-based authenticators. As before, the existing proof that
the full authenticator is a valid MT-authenticator [3] still holds.
The optimised protocol for the KEM-based AM protocol compiled with the
signature-based authenticator is shown in Fig. 9. The optimisation follows the
same process as described in Sect. 4.1. Although more general, the resulting
protocol has much in common with the signed Diﬃe–Hellman protocol which
has been widely known and deployed for many years and is today the usual
AKE in the latest version of TLS (though with only one-sided authentication).
We have another way to authenticate the KEM-based AM protocol, namely
to authenticate its two messages with diﬀerent MT-authenticators. As far as we
are aware there are no examples of such a protocol in the existing literature.
There can be practical usages, for example when signatures are very expensive
to generate but very cheap to verify. In such a case, when a powerful server
authenticates its AM message it can shift computation away from a lightweight
client by using the signature-based authenticator, while the client can avoid
generating signatures by using a diﬀerent KEM-based authenticator. In Fig. 10
we show the optimised protocol using the KEM-based authenticator for the

570
C. Boyd et al.
Fig. 9. Optimised UM protocol from the KEM-based AM protocol and the signature-
based MT-authenticator.
ﬁrst message and the signature-based authenticator for the second message. A
mirror protocol results from using the two authenticators the other way around.
For completeness this optimised protocol is given as Fig. 13 in Appendix 2.
5
Concrete Post-quantum Secure AKE Protocols
In the previous section we have presented optimised generic AKE protocols which
will be secure as long as the KEM, signature and MAC primitives are instantiated
with secure instances. Even restricting to a handful of currently best-trusted
post-quantum primitives, this leads to hundreds of potential concrete protocols,
bearing in mind that we have shown that diﬀerent KEMs and signatures can
be mixed in the same protocol and observing that the generic protocols are
not symmetric between initiator and responder. The question of whether the
concrete instantiated protocols are practical in terms of computational eﬃciency
and message size is a natural one.
5.1
Computational Cost
To give an impression of the computational costs of our new protocols we sum-
marize the number of public key operations needed in each of our optimised
protocols in the upper part of Table 1. The lower part of the same table includes
the number of similar operations for some prominent existing protocols.

Modular Design of KEM-Based Authenticated Key Exchange
571
Fig. 10. Optimised UM protocol from the KEM-based AM protocol and the KEM-
based MT-authenticator used for the ﬁrst message, and the signature-based MT-
authenticator for the second message.
Table 1. The number of public key operations for ours and existing protocols.
Initiator
Responder
Gene Encap Decap Sign SigVer Gene Encap Decap Sign SigVer
Figure 7. KEM/KEM
0
2
1
0
0
1
1
2
0
0
Figure 9. Sig/Sig
0
1
0
1
1
1
1
0
1
1
Figure 10. KEM/Sig
0
2
0
1
0
1
0
2
0
1
Figure 11. Sig/KEM
0
1
1
0
1
1
1
1
1
0
Figure 13. MAC/MAC 0
1
0
0
0
1
0
1
0
0
TLS 1.3a
1
0
1
0
1
0
1
0
1
0
KEMTLSb [23]
1
1
1
0
0
0
1
1
0
0
KEMTLS-pdk [24]
1
1
2
0
0
0
2
1
0
0
PQ-WireGuard [18]
1
1
2
0
0
0
2
1
0
0
SSW17c [12]
1
1d
2
0
0
0
2
1
0
0
a Using Diﬃe-Hellman as an ephemeral KEM. Unilateral authentication
b Unilateral authentication
c Assuming that our KEM-based AM protocol is used as the base protocol.
d Encryption is needed in the full protocol, not encapsulation
All of the protocols in Table 1 use three passes and three rounds. However,
they do not all have the same goals or assumptions. TLS and KEMTLS only
aim for server-side authentication while our protocol in Fig. 13 assumes pre-
shared keys. PQ-WireGuard [18] is a variant of the WireGuard protocol using

572
C. Boyd et al.
only KEMs. Its design is based on the FSXY protocol [15]. All of the protocols
in the lower half of Table 1 use only KEMs, both for authentication and key
exchange. When comparing with our KEM-only protocol of Fig. 7 we see that
the main computational eﬀort is the same as in the three bottom protocols which
are all KEM-only protocols. We conclude that our protocols are comparable in
computation to existing ones. Another diﬀerence between the various protocols is
on which side most computations are performed, e.g. in Fig. 10 the initiator Alice
encapsulates twice while Bob performs computationally heavier decapsulations
and generation of the ephemeral key.
The most obvious diﬀerence between the upper and lower part of the table is
that our designs have the responder generating the ephemeral KEM key while all
existing protocols shown give this task to the initiating party. We do not believe
that either option is inherently better, rather it depends on the relative costs
of generation, encapsulation and decapsulation of the instantiating ephemeral
KEM. For some well-known KEMs (Table 3a), key generation is far more costly
than encapsulation or decapsulation. To minimise the overall protocol cost to
both parties it seems better to use an algorithm with more uniform cost for the
three KEM operations, but if it is desired to reduce the cost of one party at the
expense of the other then diﬀerent algorithms can be better.
It can be argued that implementation is most eﬃcient when the same concrete
KEM is used for all three of the KEM instances in the all-KEM protocols. This
should be true at least with regard to the codebase needed in any implementa-
tion. However, this may not be the case when it comes to counting computation
cycles. Recall that the AM protocol includes generation of an ephemeral public
key, while the long-term keys are generated only once before the protocol runs.
Therefore it can make sense to use a KEM with an eﬃcient key generation algo-
rithm for the ephemeral KEM, and a diﬀerent one with a much less eﬃcient key
generation algorithm for the KEM using the long-term keys. PQ-WireGuard [18]
does exactly this, using Classic McEliece for the long-term KEM and a variant
of Saber for the ephemeral KEM. The size of its public key (Table 3a) shows why
using Classic McEliece for the ephemeral KEM seems to be a bad idea.
Current known post-quantum signatures tend to be computationally less eﬃ-
cient than KEM constructions (Table 3b) where signing is much more expensive
than decapsulation in known algorithms. It is therefore natural that KEM-based
authentication currently is seen favourably. This can change in the future, and
the NIST focus on new post-quantum signature proposals may well lead to more
eﬃcient post-quantum secure signature algorithms. To our knowledge, there is
no analog to our KEM/Sig or Sig/KEM protocols in the literature, neither are
we aware of post-quantum proposals for the pre-shared key case.
5.2
Communications Cost
In Table 2 we take an inventory of the message ﬁelds in each of our abstract
protocols. Due to the optimisation techniques explained earlier, the number of
ﬁelds sent and received by each party is three in all cases. Informally, at least,
this is a minimum since the ephemeral public key needs to communicated and

Modular Design of KEM-Based Authenticated Key Exchange
573
Table 2. What comprises the messages sent in each protocol.
Message 1 Message 2
Message 3
Figure 7. KEM/KEM
ct
pk, ct, MAC ct, MAC
Figure 9. Sig/Sig
N
pk, N, σ
ct, σ
Figure 10. KEM/Sig
ct
pk, N, MAC
pk, MAC
Figure 11. Sig/KEM
N
pk, σ, ct
ct, MAC
Figure 13. MAC/MAC N
pk, N, MAC
ct, MAC
then used in the response, and each of these two messages must be authenticated
using a fresh value chosen by the other party.
The size of these ﬁelds depends on the parameters of the concrete primi-
tives chosen. In July 2022, NIST announced a ﬁrst list of selected candidates
as a result of its Post-Quantum Cryptography competition [1], pointing out
CRYSTALS-Kyber as their selected KEM and CRYSTALS-Dilithium as their
selected signature algorithm. Using the real-world eﬃciency of the Kyber KEM
and the Dilithium signature scheme, in Tables 3a and 3b and naively adding up
these numbers, all messages in our Fig. 10 protocol would be under 5 kB for
Kyber-1024, which deﬁnitely is practical. Another look at the ephemeral public
key sizes in Table 3a shows why the choice of Saber in PQ-WireGuard [18] is an
obvious one. We note that before its recent demise, SIKE looked an even more
promising candidate to minimise the ephemeral key size.
Just as for computation eﬃciency, currently accepted post-quantum secure
signature candidates do not look attractive for communications eﬃciency as
shown in Table 3b. To minimise signature size FALCON is a better choice than
Dilithium, but requires a trade-oﬀwith computation.
We reiterate that Table 2 assumes that authentic long-term public keys are
available to all parties by some external channel. This ﬁts some real-world pro-
tocols (such as WireGuard) but not others (such as TLS). Post-quantum signa-
tures used to certify the long-term public keys can be chosen independently of
other concrete choices in the protocol. This choice will obviously aﬀect both the
computation for each party and the size of the protocol messages. Although reg-
istration of public keys can avoid use of post-quantum signatures [16], it seems
necessary to use signatures to achieve usual certiﬁcate properties.
6
Conclusion and Future Work
As summarized in Sect. 1.2, the main contributions of this work are the new
KEM-based authenticator and corresponding security proof, the new proofs in
the AM-model and the derivation of several new generic AKE protocols. We
hope that the ﬂexibility of protocol designs can be useful in ﬁtting AKE pro-
tocols to diﬀerent application use cases and that as new concrete KEMs and
signature schemes are developed the generic protocols will yield new and inter-
esting instantiations. Some of the ways to extend the work are the following.

574
C. Boyd et al.
– Adding additional security properties; for example, application of the twisted-
PRF trick [15] can likely be added to an AM-protocol to secure against
ephemeral leakage.
– Check whether use of hybid-KEMs (secure against conventional adversaries
based on traditional assumptions and secure against post-quantum adver-
saries based on new assumptions) can be usefully applied to obtain hybrid-
secure AKE [6].
– Since the modular approach does not naturally lead to tight reductions, it
would be useful to improve on this, although in the end it may be necessary
to complement new protocol designs obtained from the modular approach
with a monolithic proof in a stronger model for some concrete protocol.
– Applying an authenticator just to one message (from a two-message AM pro-
tocol) will allow for unilateral authentication such as is common in TLS. The
security and eﬃciency of such a generic protocol deserves analysis.
– Real-world implementations of the generic protocols is also left to future
work—obviously this would be a prerequisite for future adaptation, and give
us a more concrete comparison of their eﬃciency in the real world.
Appendix 1: ETSI Tables
Tables 3a and 3b present the computational eﬃciency of various KEMs and sig-
natures from the NIST competition. The ﬁgures are taken from two recent
reports from ETSI [25,26]. They are not intended as deﬁnitive eﬃciency
comparisons—indeed some of the ﬁgures have already been improved upon—
but rather to illustrate typical ballpark ﬁgures and highlight the big variation
between many of the existing proposals.
We ﬁnd it interesting to remark on a major diﬀerence regarding the sym-
metry of the computation requirements between Diﬃe–Hellman and the AM
protocol (Fig. 5) which can be regarded as a generalisation. The computational
requirements for Diﬃe–Hellman are the same for both initiator and responder.
In the AM protocol the initiator runs Gen and Decap while the responder runs
only Encap. Of itself this is not signiﬁcant, since Encap really has two purposes:
to generate the new key for the responder and to generate the encapsulation for
the initiator. Thus in the Diﬃe–Hellman case the cost of Encap is the same as
the cost of Gen plus the cost of Decap. However, in all the examples in Table 3a
this is nowhere close to being true. Indeed Encap is always signiﬁcantly cheaper
than Gen plus Decap, which may be important when deciding which party take
the role of initiator in a protocol run.

Modular Design of KEM-Based Authenticated Key Exchange
575
Table 3. Confusion matrix of one of the folds for the ﬁnal classiﬁcation of DGCNN-
MS-T-W, with W = 150
(a) The eﬃciency of various KEMs [25].
NIST security
Gen
Encap
Decap
pk
ct
category
mceliece348864
36641040
44 350 134 745 261120
128
1
mceliece460896
117067765 117 782 271 694 524160
188
3
KYBER512
33856
45 200
59 088
800
768
1
KYBER1024
73544
97 324 115 332
1568 1568
3
ntruhps2048677
309216
83 519
59 729
930
930
1
ntruhps4096821
431667
98 809
75 384
1230 1230
3
LightSaber
45152
49 948
47 852
672
736
1
Saber
66727
79 064
76 612
992 1088
3
(b) The eﬃciency of various signature schemes [26].
NIST security
Sign
SigVer
σ
category
Dilithium-3
269 000 118 000 3293
3
Dilithium-5
429 000 179 000 4595
5
FALCON-512
386 678
82 340
666
1
FALCON-1025 789 564 168 498 1280
5
Appendix 2: Optimised KEM-Based UM Protocol with
SIG/KEM Authentication
We give here in Fig. 11 an optimized protocol using the signature-based authen-
ticator for the ﬁrst message and the KEM-based authenticator for the second.
This is reversed from the protocol in Fig. 10.
Appendix 3: MAC-Based MT-Authenticator
Canetti and Krawczyk [9] present also a MAC-based MT-authenticator (interest-
ingly described only in compressed form) as shown in Fig. 12. This authenticator
can be useful in scenarios where pre-shared keys exist such as in many use-cases
of TLS with lightweight entities and also in session resumption in the latest TLS
1.3 version.
Since MACs are expected to remain secure in the post-quantum setting it
makes sense to combine this authenticator with our KEM-based AM protocol to
obtain a post-quantum secure AKE protocol suitable for pre-shared key appli-
cations. Figure 13 show the resulting optimised protocol.

576
C. Boyd et al.
Fig. 11. Optimised UM protocol from the KEM-based AM protocol and the signature-
based MT-authenticator used for authenticating the ﬁrst message, and the kem-based
MT-authenticator authenticating the second message.
Fig. 12. λMAC, a compressed MAC-based MT-authenticator with shared key k.

Modular Design of KEM-Based Authenticated Key Exchange
577
Fig. 13. Optimised UM protocol from the KEM-based AM protocol and the MAC-
based MT-authenticator.
References
1. Alagic, G., et al.: Status report on the third round of the NIST post-quantum cryp-
tography standardization process. Technical report, National Institute of Standards
and Technology (2022). https://csrc.nist.gov/publications/detail/nistir/8413/ﬁnal
2. Angel, Y., Dowling, B., H¨ulsing, A., Schwabe, P., Weber, F.: Post quantum
noise. Cryptology ePrint Archive, Report 2022/539 (2022). https://eprint.iacr.org/
2022/539
3. Bellare, M., Canetti, R., Krawczyk, H.: A modular approach to the design and
analysis of authentication and key exchange protocols (extended abstract). In:
30th ACM STOC, pp. 419–428. ACM Press (1998)
4. Bergsma, F., Jager, T., Schwenk, J.: One-round key exchange with strong security:
an eﬃcient and generic construction in the standard model. In: Katz, J. (ed.) PKC
2015. LNCS, vol. 9020, pp. 477–494. Springer, Heidelberg (2015). https://doi.org/
10.1007/978-3-662-46447-2 21
5. Bernstein, D.J., Lange, T.: Post-quantum cryptography. Nature 549(7671), 188–
194 (2017)
6. Bindel, N., Brendel, J., Fischlin, M., Goncalves, B., Stebila, D.: Hybrid key encap-
sulation mechanisms and authenticated key exchange. In: Ding, J., Steinwandt, R.
(eds.) PQCrypto 2019. LNCS, vol. 11505, pp. 206–226. Springer, Cham (2019).
https://doi.org/10.1007/978-3-030-25510-7 12
7. Bos, J.W., et al.: Frodo: take oﬀthe ring! Practical, quantum-secure key exchange
from LWE. In: Weippl, E.R., Katzenbeisser, S., Kruegel, C., Myers, A.C., Halevi,
S. (eds.) ACM CCS 2016, pp. 1006–1018. ACM Press (2016)
8. Boyd, C., de Kock, B., Millerjord, L.: Modular design of KEM-based authenticated
key exchange. Cryptology ePrint Archive, Paper 2023/167 (2023). https://eprint.
iacr.org/2023/167

578
C. Boyd et al.
9. Canetti, R., Krawczyk, H.: Analysis of key-exchange protocols and their use for
building secure channels. In: Pﬁtzmann, B. (ed.) EUROCRYPT 2001. LNCS, vol.
2045, pp. 453–474. Springer, Heidelberg (2001). https://doi.org/10.1007/3-540-
44987-6 28
10. Celi, S., et al.: Implementing and measuring KEMTLS. Cryptology ePrint Archive,
Report 2021/1019 (2021). https://eprint.iacr.org/2021/1019
11. Cremers,
C.:
Examining
indistinguishability-based
security
models
for
key
exchange protocols: the case of CK, CK-HMQV, and eCK. In: Cheung, B.S.N.,
Hui, L.C.K., Sandhu, R.S., Wong, D.S. (eds.) ASIACCS 2011, pp. 80–91. ACM
Press (2011)
12. de Saint Guilhem, C., Smart, N.P., Warinschi, B.: Generic forward-secure key
agreement without signatures. In: Nguyen, P., Zhou, J. (eds.) ISC 2017. LNCS,
vol. 10599, pp. 114–133. Springer, Cham (2017). https://doi.org/10.1007/978-3-
319-69659-1 7
13. Ding, J., Alsayigh, S., Lancrenon, J., RV, S., Snook, M.: Provably secure pass-
word authenticated key exchange based on RLWE for the post-quantum world.
In: Handschuh, H. (ed.) CT-RSA 2017. LNCS, vol. 10159, pp. 183–204. Springer,
Cham (2017). https://doi.org/10.1007/978-3-319-52153-4 11
14. Ding, J., Xie, X., Lin, X.: A simple provably secure key exchange scheme based
on the learning with errors problem. Cryptology ePrint Archive, Paper 2012/688
(2012). https://eprint.iacr.org/2012/688
15. Fujioka, A., Suzuki, K., Xagawa, K., Yoneyama, K.: Strongly secure authenticated
key exchange from factoring, codes, and lattices. In: Fischlin, M., Buchmann, J.,
Manulis, M. (eds.) PKC 2012. LNCS, vol. 7293, pp. 467–484. Springer, Heidelberg
(2012). https://doi.org/10.1007/978-3-642-30057-8 28
16. G¨uneysu, T., Hodges, P., Land, G., Ounsworth, M., Stebila, D., Zaverucha, G.:
Proof-of-possession for KEM certiﬁcates using veriﬁable generation. Cryptology
ePrint Archive, Report 2022/703 (2022). https://eprint.iacr.org/2022/703
17. Hitchcock, Y., Boyd, C., Nieto, J.M.G.: Modular proofs for key exchange: rigor-
ous optimizations in the Canetti-Krawczyk model. Appl. Algebra Eng. Commun.
Comput. 16(6), 405–438 (2006)
18. H¨ulsing, A., Ning, K.-C., Schwabe, P., Weber, F., Zimmermann, P.R.: Post-
quantum WireGuard. Cryptology ePrint Archive, Report 2020/379 (2020).
https://eprint.iacr.org/2020/379
19. Jager,
T.,
Kiltz,
E.,
Riepel,
D.,
Sch¨age,
S.:
Tightly-secure
authenticated
key exchange, revisited. In: Canteaut, A., Standaert, F.-X. (eds.) EUROCRYPT
2021. LNCS, vol. 12696, pp. 117–146. Springer, Cham (2021). https://doi.org/10.
1007/978-3-030-77870-5 5
20. Katz, J., Lindell, Y.: Introduction to Modern Cryptography, 2nd edn. CRC Press,
Boca Raton (2014)
21. Krawczyk, H.: HMQV: a high-performance secure Diﬃe-Hellman protocol. In:
Shoup, V. (ed.) CRYPTO 2005. LNCS, vol. 3621, pp. 546–566. Springer, Hei-
delberg (2005). https://doi.org/10.1007/11535218 33
22. Peikert, C.: A decade of lattice cryptography. Cryptology ePrint Archive, Paper
2015/939 (2015). https://eprint.iacr.org/2015/939
23. Schwabe, P., Stebila, D., Wiggers, T.: Post-quantum TLS without handshake sig-
natures. In: Ligatti, J., Ou, X., Katz, J., Vigna, G. (eds.) ACM CCS 2020, pp.
1461–1480. ACM Press (2020)

Modular Design of KEM-Based Authenticated Key Exchange
579
24. Schwabe, P., Stebila, D., Wiggers, T.: More eﬃcient post-quantum KEMTLS
with pre-distributed public keys. In: Bertino, E., Shulman, H., Waidner, M. (eds.)
ESORICS 2021. LNCS, vol. 12972, pp. 3–22. Springer, Cham (2021). https://doi.
org/10.1007/978-3-030-88418-5 1
25. ETSI Technical Committee Cyber Security. Quantum-safe public-key encryption
and key encapsulation. ETSI TR 103823, ETSI (2021)
26. ETSI Technical Committee Cyber Security. Quantum-safe signatures. ETSI TR
103616, ETSI (2021)

Reusable, Instant and Private Payment
Guarantees for Cryptocurrencies
Akash Madhusudan1(B)
, Mahdi Sedaghat1
, Samarth Tiwari2
,
Kelong Cong1
, and Bart Preneel1
1 imec-COSIC, KU Leuven, Leuven, Belgium
{akash.madhusudan,ssedagha,kelong.cong,bart.preneel}@esat.kuleuven.be
2 Centrum Wiskunde & Informatica, Amsterdam, The Netherlands
samarth.tiwari@cwi.nl
Abstract. Despite oﬀering numerous advantages, public decentralized
cryptocurrencies such as Bitcoin suﬀer from scalability issues such as
high transaction latency and low throughput. The vast array of so-called
Layer-2 solutions tackling the scalability problem focus on throughput,
and consider latency as a secondary objective. However, in the context
of retail payments, instant ﬁnality of transactions is arguably a more
pressing concern, besides the overarching concern for privacy.
In this paper, we provide an overlay network that allows privacy-
friendly low latency payments in a retail market. Our approach follows
that of a recent work called Snappy, which achieved low latency but
exposed identities of customers and their transaction histories. Our con-
struction ensures this data is kept private, while providing merchants
with protection against double-spending attacks. Although our system
is still based upon customers registering with a collateral, crucially this
collateral is reusable over time.
The technical novelty of our work comes from randomness-reusable
threshold encryption (RRTE), a cryptographic primitive we designed
speciﬁcally for the following features: our construction provably guar-
antees payments to merchants, preserves the secret identity of honest
customers and prevents their transactions from being linked. We also
present an implementation of our construction, showing its capacity for
fast global payments in a retail setting with a delay of less than 1 s.
1
Introduction
Public decentralized cryptocurrencies such as Bitcoin and Ethereum oﬀer
increased transparency and avoid trust in a central party. However, these advan-
tages come at the cost of performance, rendering them unﬁt for high throughput,
real-time applications. The throughput of cryptocurrencies is orders of mag-
nitude lower than that of traditional payment service providers such as Visa.
Further, transactions require time before being considered ﬁnal: the convention
has been to wait for 6 conﬁrmations or approximately an hour. For this reason,
securely improving throughput and transaction conﬁrmation latency (hereon
referred to as latency) of public cryptocurrencies is a major area of research.
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 580–605, 2023.
https://doi.org/10.1007/978-3-031-35486-1_25

Reusable, Instant and Private Payment Guarantees for Cryptocurrencies
581
Layer-2 solutions tackle these constraints by oﬄoading some elements
of transactions oﬀ-chain [25]. However, these solutions focus on maximizing
throughput and not on minimizing latency, which is dealt with as a sec-
ondary objective. Rollups, an increasingly popular solution in both industry
and academia alike, increase the transaction throughput of Ethereum up to 100
times compared to its current throughput [7,11,20]. Yet, their latency matches
that of the underlying blockchain. Payment Channel Networks (PCNs), another
popular scaling solution, allow for arbitrarily many transactions on their network
at the cost of a constant number of on-chain transactions, thereby drastically
increasing throughput and reducing transaction fees. Yet, there are various fac-
tors negatively impacting the latency of PCN transactions, such as liveness of
intermediate nodes [18], and the route discovery mechanisms [33]. Retail pay-
ments is a scenario where instant ﬁnality (hereon referred to as fast payments) is
of the utmost importance; waiting an hour for a coﬀee is not an option. Addition-
ally, retail payments are usually unilateral, i.e., from customers to merchants.
An acknowledged problem with PCNs is channel depletion i.e., repeated use of
channels in the same direction results in depleted channels, prohibiting further
payments in the same direction [4]. Unilateral retail transactions only aggra-
vate this issue. Similarly, by updating its layer-1, Ethereum 2.0 has increased its
transaction throughput signiﬁcantly. However, latency still takes ∼14 min [21].
This suggests a decoupling of two performance measures, namely throughput
and latency, which need to be tackled separately.
Hence, collateral reusability and fast payments become interesting properties
for solutions that perform retail payments with cryptocurrencies. Snappy is a fast
on-chain payment system designed for a retail environment, where payers can
assure payees of their ability to pay for a certain commodity [29]. Payees are pro-
tected from double-spending at rates much faster than the underlying blockchain
while allowing collaterals to be reused. In order to work, Snappy depends on a set
of statekeepers responsible for proactively detecting double-spending attempts
in the system. These statekeepers have access to all transactions made by the
customer, either by simply querying the blockchain or locally logging them when
they receive it. Thus, their system suﬀers from privacy issues and all transac-
tions involving the same payer can be linked together by third parties, such as,
the statekeepers. The general demand for greater privacy becomes even more
relevant in the retail context. For instance, the retail giant Target was able to
deduce the pregnancy of a teenager even before her own parents found out [27].
Such unfortunate leaks can be prevented, if merchants are unable to link cus-
tomers’ various purchases. Hence, there is a need for a solution that has the
following properties:
P1. Instant payments with double-spending protection that is much faster than
the underlying blockchain (fast payments).
P2. Prevents third parties in the system from being able to link diﬀerent trans-
actions involving the same honest payer (transaction unlinkability).
P3. Privacy for honest customers is provided eﬃciently without incurring
latency constraints of payments (eﬃcient privacy).

582
A. Madhusudan et al.
P4. Honest payers do not need to replenish their collaterals (reusability).
At ICDCS’21, Ng et al. [31] proposed LDSP that adds privacy to Snappy.
LDSP achieves P1, P2 and P3; however, at the cost of reusable collaterals (P4).
Thus, previous works either trade-oﬀprivacy in order to achieve fast payments
with collateral reusability or vice-versa.
Our Contributions. In this paper, we provide a new overlay network that ful-
ﬁlls all aforementioned properties. To the best of our knowledge, we are the ﬁrst
to simultaneously achieve the combination of properties (P1–4) in a payment
system utilised in a retail context. Our contributions may be split into three as
follows:
Private Low Latency Double-Spending Protection. We provide an overlay network
capable of providing payees protection from double-spent transactions much
faster than the underlying blockchain. No party in the system is able to link
diﬀerent transactions involving the same honest payer, nor do these privacy
guarantees adversely aﬀect latency of transactions. Customer collaterals are also
reusable, so that customers can repeatedly guarantee payments over time.
Formal Security Analysis. We formally prove that our construction preserves the
secret identity of honest customers (anonymity) and disables anyone from linking
their transactions (unlinkability), yet at the same time guarantees payment to
the merchants (payment certainty).
Implementation and Evaluation. We implement our construction and show that
it allows for fast global retail payments with a delay of less than 1 s.
Outline. The rest of this paper is organized as follows: Sect. 2 gives an overview
of our construction, its participants and how they interact. Section 3 formally
describes our construction, its threat model and proves how our construction
satisﬁes its security requirements. Section 4 depicts an eﬃcient instantiation of
our construction and lists the cryptographic primitives used in detail. In Sect. 5
we evaluate the performance of this instantiation while focusing on latency. In
Sect. 6 we discuss our limitations and point out the diﬀerences our construction
has when compared to similar state-of-the-art research and ﬁnally in Sect. 7 we
conclude our paper.
2
Our Construction
2.1
Our Solution
The strawman solution shown in the full version [28] depicts the diﬃculty of a
straightforward solution in achieving P1–4.
While designing a solution that fulﬁlls all aforementioned properties, we faced
two challenges. First, our construction must utilize a proactive double-spending
protection mechanism that is able to selectively reveal information of dishonest
parties while still keeping all information about honest parties private. Second,

Reusable, Instant and Private Payment Guarantees for Cryptocurrencies
583
since the payment latency needs to be low, we must enable payers to prove
vital information privately yet very eﬃciently. We address the ﬁrst challenge
by proposing a novel variant of threshold encryptions, which we hereon refer
to as randomness-reusable threshold encryptions (RRTE) that has the unique
property of revealing the plaintext if two ciphertexts are encrypted using the
same randomness. We use RRTE in combination with Pseudo-Random Functions
(PRF) such that the statekeepers are able to proactively protect from double-
spend attempts without having knowledge of any transaction details; yet, are still
able to reveal vital information in the case of double-spent transactions. The sec-
ond challenge is addressed by a combination of Threshold Structure-Preserving
Signatures (TSPS) [16] and Non-Interactive Zero-Knowledge Proofs (NIZKs).
The compatibility of TSPS with eﬃcient NIZKs enables a payer to prove vital
information to payees in our system in zero-knowledge, without impacting the
latency of transactions.
Participants. First, in order to explain the interplay of these cryptographic
primitives that solve the aforementioned challenges and fulﬁll P1–4, we intro-
duce the participants of our construction. Similar to Snappy, our participants
include: (1) customers willing to purchase products/services using their cryp-
tocurrencies while expecting low latency; (2) an established consortium of mer-
chants willing to accept cryptocurrency payments and (3) statekeepers who are
selected from the merchant consortium. Additionally, we also include a group
of authorities trusted for registration of users and veriﬁcation of collaterals.
Although authorities have greater power during the setup of our network, they do
not have any access to future transactions between a customer and a merchant.
For more discussion on these trust assumptions see Sect. 6.
Interaction of Participants. In our construction, the participants function
as follows; each customer in our systems owns collateral(s), which is uniquely
linked to a secret PRF key(s). This secret PRF key is signed by the group
of authorities by utilizing TSPS once they verify its existence on the arbiter
smart contract. The PRF is used in combination with our RRTE to set up our
double-spending protection. By using this signed secret PRF key, each customer
generates a randomness, which they then use in combination with the public
key of target merchant to encrypt their secret identity. For encryption we use
RRTE, that reveals the secret identity of a malicious customer (plaintext) when
they double-spend. More precisely, double-spending in our system amounts to
certifying multiple transactions with the same collateral, by which RRTE reveals
the dishonest customer’s identity. Thus, our construction fulﬁlls P1 by enabling
any statekeeper who receives two ciphertexts that are encrypted using the same
randomness to catch double-spending and reveal the identity of the perpetrator.
However, honest customers who only certify one transaction per collateral remain
unaﬀected; hence, also fulﬁlling P2.
Next, the customer needs to convince the target merchant about the existence
of their collateral. However, they must do this without revealing any identifying
details. To achieve this, we utilize TSPS and NIZKs. The payment guarantee
is an indirect proof of collateral by proving knowledge of the TSPS provided

584
A. Madhusudan et al.
to them by the authorities. In case of a double-spend attempt, this payment
guarantee is suﬃcient for the merchant to be reimbursed. This can be done
eﬃciently by eﬃcient proof systems fulﬁlling P3.
Fig. 1. Timeline of a transaction.
Finally, our construction also allows a customer to reuse their collaterals after
a certain time interval in order to achieve P4. As illustrated in Fig. 1, a collateral
is considered locked for the time period between the customer sending a pay-
ment guarantee to the merchant and the actual conﬁrmation of their blockchain
transaction. However, after the conﬁrmation of a blockchain transaction, the
customer’s collateral can be reused. Note that this is similar to the execution
of a multi-hop payment on PCNs, that rely on Hashed-Time-Locked-Contracts,
locking up the collateral for a similar time period [1,33]. Thus, using a collateral
twice in quick succession is treated as a double-spend and can be detected, but
it may be reused once the locking period of the collateral has elapsed.
Construction Overview. Figure 2 illustrates our construction. In order to
explain our construction, we assume an established set of authorities and a ﬁxed
merchant consortium. The payment protocol between a customer and a mer-
chant has oﬀ-chain and on-chain components that have been depicted in Fig. 2
with dotted and solid arrows respectively. The protocol proceeds as follows:
Fig. 2. Our construction.
1) The customer begins by registering themselves with a set of authorities.
2) The customer deposits a collateral in the smart contract, controlled by this set

Reusable, Instant and Private Payment Guarantees for Cryptocurrencies
585
of authorities. 3) Once the deposit is conﬁrmed on the blockchain, the customer
requests a collateral certiﬁcation, which is necessary to generate payment guar-
antees for merchants. 4) Upon receiving the certiﬁcation request of the customer,
the authorities check the smart contract to conﬁrm if the customer deposited
a collateral. 5) The authorities provide the customer with a signed collateral
certiﬁcation. 6a) During a transaction in the retail market, the customer makes
a payment to the target merchant using the underlying cryptocurrency. This is
done by sending a payment to the merchant through the smart contract. 6b) The
customer simultaneously generates an encrypted payment guarantee by using
the collateral certiﬁcation and sends this to the target merchant along with the
transaction identiﬁer of their cryptocurrency payment. 7) The target merchant
forwards this encrypted payment guarantee to the statekeepers who individu-
ally conﬁrm that it is not a double-spend attempt. The statekeepers compare
the received guarantee with each guarantee they received within a ﬁxed time
period. If none of these comparisons reveal the plaintext, i.e., secret identity of
the customer, they are guaranteed about its uniqueness. Note that this veriﬁca-
tion can be done by utilizing our proposed RRTE and does not require knowing
a customer’s identity. 8) Each statekeeper returns a signed payment guarantee
to the merchant. 9) If a majority of the statekeepers return a conﬁrmation, the
merchant aggregates these signatures and accepts the payment guarantee and
provides the customer with necessary services/products.
Double-Spending. Double-spending in our construction means a scenario
where the customer is malicious and wants to double-spend their payment guar-
antee, i.e., use the same collateral to promise payments to two distinct merchants.
In this case, when the statekeepers receive these guarantees from two distinct
merchants, they are able to combine them and reveal the secret identity of the
cheating customer. Along with this identity, a secret to the customer’s collateral
is also revealed. This secret is used by the victim merchant for remuneration.
This is depicted in Fig. 3.
More details about how RRTE enables statekeepers to reveal the secret iden-
tity of a malicious customer are given in its formal deﬁnition in Sect. 4.
Fig. 3. Proactive double-spending detection.
Limitations. Although we address the privacy shortcomings of Snappy’s design,
our construction still inherits some of its other limitations, such as, the large

586
A. Madhusudan et al.
collateral requirement for statekeepers and inadequately deﬁned user incentives.
To be speciﬁc, we also require the merchants to deposit collaterals in order
to play the role of statekeepers fairly. We also assume that the amount of a
customer’s deposit is ﬁxed. The assumption of a ﬁxed set of merchants is also
an additional concern, since it does not allow for any merchant churn in the
protocol. However, in this paper we do not attempt to address these concerns.
A more thorough discussion about these shortcomings is given in Sect. 6.
3
Preliminaries and Formal Construction
Throughout this paper, we let the security parameter of the scheme to be λ
with unary representation of 1λ, and negl(λ) denotes a negligible function. We
use x ←$ X to denote that x is sampled uniformly from the set X. [n] denotes
the set of integers in the range of 1 to n. For clarity, the secret values in our
construction are represented with a hat operator (e.g., ˆsk) and masked values
are represented with the notation x′ for the value x.
Threat Model. Our construction is designed to resist active adversaries that
can corrupt a set of customers, merchants (which are also statekeepers) and
authorities. To be precise, an adversary can only corrupt a minority of author-
ities during the initialization phase. During the processing of transactions, the
adversary can corrupt all but one customers, and a minority of merchants.
Network Assumptions. We assume the existence of secure and reliable communi-
cation channels so that parties receive messages sent by honest parties eventually.
The honest merchants/statekeepers are also assumed to be live and responsive,
for the veriﬁcation of transactions. We do not expect the customers to be online,
unless they need to transact with a merchant. The underlying blockchain is
assumed to be persistent and live and the adversary cannot inﬂuence the con-
sensus mechanism.
Beyond the Threat Model. Let us mention a few considerations that are outside
the scope of our model. Firstly, we consider protocol-level privacy, and not the
privacy of the underlying blockchain. We do not consider side-channel attacks,
such as metadata-level attacks on communication channels. Finally, the selection
of authorities is also orthogonal to our work. One possibility is to choose them
from the set of reputable merchants in the consortium, and have them shuﬄed
periodically to ensure a majority of authorities always remain honest.
We would also like to note that weaker assumptions of trust or liveness
are possible without compromising security. However, we select a simple set of
assumptions, following those of Snappy, in order to focus on the privacy aspect
instead of system-level optimizations.
Formal Construction. Our construction builds on Pseudo-Random Function
(PRF), Non-Interactive Zero-Knowledge (NIZK) arguments, Digital Signatures
(DS), Threshold Structure-Preserving Signatures (TSPS), Commitments (CO),
and a novel randomness-reusable Threshold Encryption (RRTE). We list the

Reusable, Instant and Private Payment Guarantees for Cryptocurrencies
587
formal deﬁnition and the security properties in the full version [28] and out-
line the scheme in Algorithm 1 for a relation RL over three main NP-languages
L := (L1, L2, L3). The list of master public keys, mpk, is considered as an implicit
input for all algorithms except the parameter generation algorithm (PGen). Addi-
tionally, all algorithms are PPT unless otherwise speciﬁed. We now formalise the
functions in the Algorithm 1. All functions are split based on when they happen
in our construction and are formalized as follows:
Bootstrapping Phase as Depicted in Fig. 2:
– PGen(1λ, RL) takes λ in its unary representation and relation RL as inputs
and returns the master public key mpk.
– AuKeyGen(AU) is executed by AU that returns ( ˆ
sgkai, vkai) for i ∈[n] along
with a global veriﬁcation key vka. AU[ ˆ
sgkai, vkai, vka]n
i=1 represents the list
of credentials for AU.
– MKeyGen(Mm) is executed by merchant Mm ∈M in order to join the net-
work. It initially generates a pair of signing/veriﬁcation keys ( ˆ
sgkbm, vkbm)
and returns a tuple ( ˆ
sgkbm, vkbm, pkbm =⊥). The list of keys belonging to the
group of merchants is recorded in M[ ˆ
sgkbi, vkbi]ℓ
i=1.
– MRegister(AU[ ˆ
sgkai]t
i=1, M[vkbi]ℓ
i=1) is executed by any subset of AU of size at
least t to register the merchants who deposit a collateral to join the merchant
consortium and assign them a public key pkbm. For each merchant Mm ∈M,
it takes the secret signing key of the authorities AU[ ˆ
sgkai] for 1 ≤i ≤t, and
returns public key pkbm as output. After this phase, the list of parameters for
the mth merchant can be updated as M[ ˆ
sgkbm, vkbm, pkbm].
– CuKeyGen(Cn) is executed by the customers, that for each customer Cn ∈C,
a Pseudo-ID generator function (PID) generates an initial secret key ˆskcn and
its corresponding public key pkcn. It returns a tuple of (pkcn, ˆskcn, ˆ
certcn =⊥)
with a NIZK proof π1 to prove that the relation RL1 fulﬁlls. The list of
customers’ keys are kept in C[ ˆskci, pkci, ˆ
certci =⊥]k
i=1.
Protocol as Depicted in Fig. 2:
– CuRegister(AU[ ˆ
sgkai]t
i=1, C[pkcn], π1) is depicted in step 1 of Fig. 2. It is exe-
cuted by any subset of AU of size at least t to certify the public key pkcn of
a customer Cn corresponds to some secret value ˆskcn under the relation RL1.
Once the customer Cn is registered by the authorities, it receives a certiﬁcate
ˆ
certcn and it updates C[pkcn, ˆskcn, ˆ
certcn].
– CuCreate(C[ ˆskcn, ˆ
certcn]) is depicted in step 2–3 of Fig. 2. It is executed by
the customer to request for certiﬁcation of their collateral. A successfully
registered customer Cn, with certiﬁcate
ˆ
certcn ̸=⊥, can deposit collaterals in
the smart contract. For each deposit j in the smart contract, the customer
samples a random value kj from a uniform distribution KPRF in a way that
the deposit is not directly linkable to the customer. Then it returns a tuple
CL[ˆkj, k′
j, ⊥] as an uncertiﬁed collateral along with a proof π2 depicting the
fact that the relation RL2 fulﬁlls.

588
A. Madhusudan et al.
Algorithm 1: Our Construction.
Function PGen(1λ, RL):
( ⃗
crs, ˆ⃗ts, ˆ⃗te) ←ZK.K ⃗
crs(1λ, RL)
(pp) ←T SPS.Setup(1λ)
return mpk := (pp, ⃗
crs)
Function AuKeyGen(AU):
( ˆ⃗
sgka, ⃗vka, vka) ←
T SPS.KGen(mpk, n, t)
return (AU[ ˆ
sgkai, vkai, vka]n
i=1)
Function MKeyGen(Mm):
( ˆ
sgkbm, vkbm) ←DS.KGen(pp)
return (M[ ˆ
sgkbm, vkbm])
Function
MRegister(AU[ ˆ
sgkai]t
i=1, M[vkbi]ℓ
i=1):
for j ∈range(ℓ) do
(pkbj, pkb) ←
RRT E.KGen(mpk, ℓ, t, 2)
return (M[pkbi]ℓ
i=1, pkb)
Function CuKeyGen(Cn):
ˆskcn := PID(Cn) ∈Z∗
p
sk′
cn ←CO.Com(pp, ˆskcn)
pkcn := (sk′
cn, M1, M2) ←
iDHH(sk′
cn, ˆskcn)
x1 = (pkcn)
ˆw1 = ( ˆskcn)
π1 ←ZK.P(RL1, ⃗
crs, x1, ˆw1)
return (C[pkcn, ˆskcn], π1)
Function
CuRegister(AU[ ˆ
sgkai]t
i=1, C[pkcn], π1):
if ZK.Vf(RL1, ⃗
crs, x1, π1) = 1 then
( ˆ
certcn) ←
T SPS.Sign(AU[ ˆ
sgkai]t
i=1, pkcn)
return (C[ ˆ
certcn])
Function CuCreate(C[ ˆskcn, ˆ
certcn]):
ˆkj ←PRF.KGen(pp)
k′
j ←CO.Com(pp, ˆkj)
Mj := (k′
j, M1, M2) ←iDHH(k′
j, kj)
x2 = (k′
j)
ˆw2 = (ˆkj, ˆskcn, ˆ
certcn)
π2 ←ZK.P(RL2, ⃗
crs, x2, ˆw2)
return (CL[ˆkj, Mj], C[cert′
cn], π2)
Function AuCreate(AU[ ˆ
sgkai, vka]t
i=1,
C[cert′
cn], CL[ˆkj, k′
j], π2):
if ZK.Vf(RL2, ⃗
crs, x2, π2) = 1 then
( ˆ
certj) ←
T SPS.ParSign(AU[ ˆ
sgkai]t
i=1, Mj)
return (CL[ ˆ
certj])
Function Spend(C[ ˆ
certcn, ˆskcn],
CL[ˆkj, ˆ
certj], M[pkbm], t):
(rt) ←PRFˆkj (t)
Rt := e(rt, h) ▷h is the generator of G2.
Ctm ←RRT E.Enc(pkbm, ˆskcn; rt)
ˆw3 = ( ˆ
certj, ˆkj, rt, ˆskcn)
x3 = (Rt, Ctm, t)
π3 ←ZK.P(RL3, ⃗
crs, x3, ˆw3)
return (T [π3, x3, TxID])
Function Vf(M[pkbm], T [π3, x3, TxID], t):
if ZK.Vf(RL3, ⃗
crs, x3, π3) = 1 then
for i ∈StK do
if Rt ̸∈Li then
(σRt,i) ←DS.Sign( ˆ
sgkbi, Rt)
if DS.Vf(vkbi, σRt,i) = 1 ∧|σRt| ≥
(|StK|/2) + 1 then
return 1
Function RevealID(Ctm, Ctm′, v):
( ˆskcn) ←RRT E.Dec(Ctm, Ctm′, v)
return (skcn)
– AuCreate(AU[ ˆ
sgkai]t
i=1, C[cert′
cn], CL[ˆkj, k′
j], π2) is depicted in step 4–5 of
Fig. 2. It is executed by a group of authorities AU of size at least t. It takes
the authorities’ secret signing keys ( ˆ
sgkai), an indexed DH message space of
PRF key and a NIZK proof π2 as inputs. To create a certiﬁed collateral, it
checks the validity of the proof π2 and whether this collateral exists in the
smart contract, and returns certiﬁcate
ˆ
certj as output. The list of parameters
for each collateral is kept by CL[ˆkj, k
′
j, ˆ
certj].
– Spend(C[ ˆskcn, ˆ
certcn], CL[ˆkj, ˆ
certj], M[pkbm], t) is depicted in step 6a and 6b
of Fig. 2. It is executed by a customer Cn ∈C who performs a payment to

Reusable, Instant and Private Payment Guarantees for Cryptocurrencies
589
the merchant Mm ∈M using the underlying cryptocurrency of their choice
at time t. The registered customer uses a certiﬁed collateral CL[ ˆkj, ˆ
certj] to
provide a payment guarantee to the merchant Mm. The payment made by the
customer is always bounded by a publicly known collateral amount. It returns
the transaction details as a list of parameters T [x3, π3, TxID], which contains
a pair of instance and proof (x3, π3), along with a set of auxiliary data Rt.
This function is executed in parallel with an on-chain payment. In particular,
the customer must ﬁrst sign and broadcast an on-chain transaction Tx, and
then include its identiﬁer (TxID) in the payment guarantee of Spend. The
TxID could have diﬀerent formats depending on the underlying blockchain.1
– Vf(M[pkbm], T [πm, xm, TxID], t) is depicted in step 7–9 of Fig. 2. The mer-
chant Mm ∈M executes it to check the validity of a received payment guar-
antee. Once the proof is veriﬁed successfully by merchant Mm along with the
majority of statekeepers, StK, conﬁrmation that they have not seen a similar
payment guarantee in the current epoch (by providing their signatures), the
merchant veriﬁes their individual signatures and aggregates them. Once the
aggregation is complete, and if TxID speciﬁes the merchant’s address as the
receiver of funds, the merchant provides the items/services to the customer
without waiting for the transaction conﬁrmation of the customer’s original
payment on the blockchain. If the proof veriﬁcation fails, or the majority of
statekeepers do not conﬁrm the guarantee, or the on-chain transaction speci-
ﬁes the wrong receiver address, the merchant rejects the payment guarantee.
Double-Spend Detection as Depicted in Fig. 3:
– RevealID(Ctm, Ctm′, v) is a deterministic algorithm that takes two ciphertexts
Ctm and Ctm′ generated under the public key of two distinct merchants Mm
and Mm′ and returns the plaintext, i.e., the identity of the customer and the
secret to their collateral to redeem it. This ID, skcn, is no longer hidden and
can be used by AU to blacklist the cheating customer and its collateral(s)
can be used to remunerate the victim merchant.
3.1
NIZK Languages
In the proposed generic construction in Algorithm 1 we rely on three languages
for the NIZK systems, described below.
– Language L1: Used to prove the correct formation of the customers’ public
key pkcn, based on the knowledge of secret key ˆskcn. We depict this language
formally below, which is used during CuKeyGen(Cn).
L1 = NIZK

( ˆskcn) | sk′
cn := CO.Com( ˆskcn)

1 For a public blockchain such as Bitcoin or Ethereum, TxID could be the hash of a
transaction (H[Tx]); for an anonymous blockchain like Zcash, it could be the viewing
key of the transaction that enables the merchant to check if he is the receiver of the
shielded transaction [19].

590
A. Madhusudan et al.
– Language L2: Used to prove eligibility to request a collateral by deriving
certiﬁcate fulﬁllment. This language is used during CuCreate(C[ ˆ
certcn]).
L2 = NIZK

(ˆkj, ˆskcn, ˆ
certcn) |k′
j := CO.Com(ˆkj), ˆkj ∈KPRF, T SPS.Vf(pkcn, ˆ
certcn) = 1

– Language L3: Used to prove the possession of a valid collateral, correctness
of PRF evaluation algorithm and RRTE’s ciphertext. This language is used
during Spend(C[ ˆskcn, ˆ
certcn], CL[ˆkj, ˆ
certj], M[pkbm], t).
L3 = NIZK

( ˆ
certj, ˆkj, rt, ˆskcn) | rt ←PRFˆkj(t), Rt := e(rt, h),
Ctm := RRT E.Enc(pkbm, ˆskcn; rt), T SPS.Vf(Mj, ˆ
certj) = 1

3.2
Security Analysis
Next we formally deﬁne the two main security requirements for our construction,
namely (1) Anonymity of honest customers and unlinkability of payment guar-
antees, and (2) Payment certainty for honest merchants. Note that the AllGen(.)
algorithm (see Fig. 4) generates all system setup parameters at once. In the
described deﬁnitions, it is implicitly assumed that there exists a PPT adversary
A who has access to the following oracles provided by the challenger B:
– Oracle OAuCorrupt(Aui): By calling this oracle under the input Aui, A can
corrupt Aui and receive its internal states. The set of corrupted authorities
is denoted by AU′ and we have |AU′| < t.
– Oracle OCuCorrupt(.): Adversary A can corrupt any customer Cn ∈C by query-
ing this oracle, and receive its uncertiﬁed secret key ˆskcn.
– Oracle OColCorrupt(.): A can corrupt at most qD collaterals CLj ∈CL to
receive their uncertiﬁed secret value ˆkj. The list of corrupted collaterals is
represented by CL′.
– Oracle OMCorrupt(.): Adversary A can corrupt a minority set of merchants
(statekeepers) like Mm ∈M and receives its pair of public key pkbm and
secret signing key
ˆ
sgkbm. The list of corrupted merchants is denoted by M′
s.t. we have, |M′| < |stk|/2.
– Oracle ORevoke(.): Adversary A can revoke at most qR certiﬁed collaterals
CLj ∈CL and redeem the deposited money.
– Oracle OSpend(.): A can make at most qS payment guarantees created by any
arbitrary non-corrupted customer to any non-corrupted merchant.
Deﬁnition 1 (Payment
Unlinkability
and
Anonymity).
This con-
struction preserves the anonymity of honest customers and provides unlink-
ability of payment guarantees, if no PPT adversary A by getting access
to OAuCorrupt, OCuCorrupt, OMCorrupt, OSpend oracles, OANON in short, and with
advantage of AdvANON
A
(λ, β) = 2

(ExpANON
A
(1λ, β) = 1) −1/2

, has a non-
negligible chance of winning the experiment described in Fig. 4, i.e. we have,
AdvANON
A
(λ, β = 0) −AdvANON
A
(λ, β = 1)
 ≤negl(λ).

Reusable, Instant and Private Payment Guarantees for Cryptocurrencies
591
Fig. 4. Security Games.
Deﬁnition 2 (Payment Certainty).
This construction provides payment
certainty (PC) if no transaction τ is approved with a non-negligible advan-
tage s.t. qS + qR + τ
>
qD. No PPT adversary A
with access to
OAuCorrupt, OCuCorrupt, OColCorrupt, ORevoke, OSpend oracles, OPC in short, can win the
experiment described in Fig. 4 with a non-negligible advantage in λ and we can
write, AdvP C
A (λ) := Pr[ExpP C
A (1λ) = 1] ≤negl(λ).
As a consequence of payment unlinkability and anonymity, no PPT adversary
can expose any information about the transaction such as the identity of honest
customers or be able to link it to any other transaction made by the customer.
As a consequence of payment certainty, no entity, not even after colluding with a
group of participants, can transfer and/or revoke more money than the amount
deposited. Finally, any system satisfying both these deﬁnitions simultaneously
reveals the identity of a malicious customer attempting to use one collateral to
pay multiple merchants at the same time.
Theorem 1. The proposed generic construction in Algorithm 1 satisﬁes the
unlinkability and anonymity of payment guarantees as deﬁned in Deﬁnition 1.
Proof. For each payment request, the customer should transfer a tuple
T [π, x, Rt, H(Tx)] where Rt is the auxiliary data at time slot t to convince
the merchant and the group of statekeepers about the uniqueness of a col-
lateral. Under the existence of a privacy-preserving blockchain TxID does not
reveal any information beyond the validity of the transaction and it protects
the anonymity of the costumers. In this case, to prove that our construction pre-
serves the anonymity of honest customers and provides unlinkability of payments

592
A. Madhusudan et al.
we show that no PPT adversary, A, by providing two pair of challenge secret
keys/collateral keys ( ˆsk
∗
0, ˆk∗
0) and ( ˆsk
∗
1, ˆk∗
1), can distinguish between (π0, x0, Rt,0)
and (π1, x1, Rt,1) as the output of the spending algorithm. This property is guar-
anteed because of the following main security properties for the given primitives:
Zero-Knowledge property of the given NIZK proof system, computationally hid-
ing property of the given commitment scheme, static-semantically secure prop-
erty of the given randomness-reusable threshold encryption in bilinear groups
and also the weak robustness of the given PRF.
Let the hybrid Hβ
be the case where the Anonymity
experiment,
ExpANON
A
(λ, β) is run for β = {0, 1}. In this case, we form a sequence of hybrids
and show that each of the successive hybrids are computationally indistinguish-
able from the preceding ones.
– Hybrid Hβ
1 : In this game, we assume the existence of an eﬃcient simulator
Sim and then modify the previous hybrid, Hβ, by generating the challenge
NIZK proof πβ via the simulation algorithm, π′
β ←ZK.Sim( ⃗crs, ˆ⃗ts, xβ).
The Zero-Knowledge property of NIZK arguments guarantees that this experi-
ment is indistinguishable from the one for Hβ and we can write Hβ
1 ≈λ Hβ.
– Hybrid H2
β: In this game, we modify Hβ
1 s.t. for generating the index id the
challenger commits ˆsk
∗
1−β instead of ˆsk
∗
β.
According to the hiding property of the given commitment scheme, this experi-
ment is indistinguishable from H1
β and we can write, Hβ
2 ≈λ Hβ
1 .
– Hybrid H: In this game, we modify H2
β by assuming the challenger runs the
RRTE encryption algorithm under the message m1−β instead of mβ.
According to the Static Semantic Security property of the proposed randomness-
reusable Threshold encryption, this experiment is indistinguishable from H2
β. To
be more concrete, A cannot distinguish between Ctβ and Ct1−β as long as no
twin ciphertext is generated even if the proofs are simulated. Thereby we have,
H0 ≈λ H1
0 ≈λ H2
0 ≈λ H ≈λ H1
1 ≈λ H2
1 ≈λ H1.
To conclude this security property for the proposed construction, based on
the weakly robust property of the given PRF, it is straightforward to demon-
strate that the output of a PRF under two distinct keys is computationally
indistinguishable and no PPT adversary can distinguish Rt,0 and Rt,1.
⊓⊔
Theorem 2. The proposed generic construction in Algorithm 1 satisﬁes the pay-
ment certainty of payment guarantees as deﬁned in Deﬁnition 2.
Proof. We prove this security property by contradiction and for the simplicity
we avoid the hat notion for the secret parameters. Let there is a PPT adversary
A that can break the payment certainty of the scheme and pass the veriﬁcation
phase without meeting at least of the following cases.

Reusable, Instant and Private Payment Guarantees for Cryptocurrencies
593
– Case 1. The adversary A can forge a valid payment guarantee, T .
– Case 2. The adversary A can forge a valid aggregated signature σRt s.t.
|σRt| ≥(|StK|/2) + 1.
By relying on the existence of a weakly-robust PRF, a Knowledge
Sound NIZK argument, an existentially unforgeable TSPS construction we
show that the success probablity of adversary in “Case
1” is negligi-
ble. Thus having played a sequence of indistinguishable games between
BPRF
WR (1λ), BTSPS
EUF-CiMA(1λ), BNIZK
KS
(1λ) and a PPT adversary A, we gradually turn
the payment certainty security game into the security features of the underlying
primitives.
– Game G0: In the ﬁrst security game, let A forms a challenge transaction τ ∗
such that  Lc + τ ∗> colA return a valid pair (π∗, x∗) with a non-negligible
advantage ϵ. By contradiction, we assume A can win this game with a non-
negligible advantage ϵ and we can write, AdvPC
A (λ) = Pr[A Wins G0] ≥ϵ.
– Game G1: In this game, we modify G0 such that we assume the existence
of an eﬃcient extractor Ext(.). In this case, there exists an extractor that
takes the extraction trapdoor ˆ⃗te and the received challenge tuple (π∗, π∗
j , x∗)
as inputs, and returns the corresponding witness (w∗) ←Ext(⃗te, x∗, π∗) s.t.
w∗=

cert∗, μ∗, sk∗
c, r∗
t , (M ∗
j , k∗)

. To be more precise, the extractor ﬁrst
extracts the indexed DH message M ∗
j
:= (id∗
j, M ∗
j1, M ∗
j2), and then can
extracts the secret PRF key k∗from the proof (π∗
j ) as a proof to show the
well-formedness of the index id∗
j. The indistinguishability of G0 and G1 can be
proven via the Knowledge Extraction property of NIZK arguments. This prop-
erty guarantees the existence of the deﬁned extractor under non-falsiﬁable
assumptions and we can write, AdvPC
A (λ) = Pr[A Wins G0] ≈Pr[A Wins G1]
and this advantage consequently depends on two possible cases,
Pr[A Wins G1] = Pr[A Wins G1 : (w∗, x∗) ∈RL] + Pr[A Wins G1 : (w∗, x∗) ̸∈RL].
The probability of an adversary in the latter case can be bounded by the
advantage a NIZK’s knowledge soundness.
AdvPC
A (λ) ≤Pr[A Wins G1 : (w∗, x∗) ∈RL] + AdvNIZK
Bks
(λ).
Under the assumption that the given NIZK is KS, the adversary A can win
the game when the event of (w∗, x∗) ∈RL occurs.
– Game G2: The challenger for the payment certainty security game can mod-
ify G1 to an attacker against the weakly-robust PRF security game. The
intended key k∗is either a valid key k∗∈K s.t. it is not corrupted by the
adversary, i.e. k∗̸∈CL′ or it is generated under a random key k∗̸∈K. The
latter case will be bounded by the advantage of BPRF
WR (1λ) attacker, then we
can write,
Pr[A Wins G2] = Pr[A Wins G2 : k∗∈K ∧k∗̸∈CL′]+
Pr[A Wins G2 : k∗̸∈K] ≤Pr[A Wins G2 : k∗∈K ∧k∗̸∈CL′] + AdvPRF
BWR(λ).

594
A. Madhusudan et al.
– Game G3: This is the game G2, except for a valid pair of witness and state-
ment in RL and a fresh and not queried PRF key, one can reduce it to a
forgery attack for the underlying TSPS scheme. More speciﬁcally, if k∗∈K
and not corrupted before then the challenger can generate its iDH message
format M ∗
j . Lets the set of authorities indices that are queried before to get
a certiﬁcate by the adversary is denoted by S(⋆,M ∗
j2). If |S(⋆,M ∗
j2) ∪AU′| < t,
BTSPS
EUF-CiMA(1λ) returns the pair (M ∗
j , cert∗) as a valid forgery for the deﬁned
threshold EUF-CiMA security game in Def. [16, 4.3]. Thus, we can write,
AdvPC
A (λ) ≤AdvNIZK
Bks
(λ) + AdvPRF
BWR (λ) + Pr[A Wins G3 : |S(⋆,M ∗
j2) ∪AU′| < t]
+ Pr[A Wins G3 : |S(⋆,M ∗
j2) ∪AU′| ≥t] ≤AdvNIZK
Bks
(λ)
+ AdvPRF
BWR (λ) + AdvTSPS
BEUF-CiMA(λ) + Pr[A Wins G3 : |S(⋆,M ∗
j2) ∪AU′| ≥t].
Since it is assumed that the adversary A should provide a fresh and not
queried collateral, the probability of the event, “A Wins G3 ∧|S(⋆,M ∗
j2) ∪AU′| ≥
t”, is equal to zero. Then we can write,
AdvPC
A (λ) ≤AdvNIZK
Bks
(λ) + AdvPRF
BWR (λ) + AdvTSPS
BEUF-CiMA(λ).
Similarly to demonstrate that the probability of Case 2 is negligible we rely
on the unforgeability of the given aggregatable digital signature. If the adversary
A be able to forge a valid aggregated signature for a majority of the statekeepers
then as it is assumed it only can corrupt at most |M′| < |StK|/2, then we can
form an eﬃcient algorithm BDS
EUF-CMA(1λ) to break the EUF-CMA property of
the underlying DS scheme. Then we can write:
AdvPC
A (λ) ≤AdvNIZK
Bks
(λ) + AdvPRF
BWR (λ) + AdvTSPS
BEUF-CiMA(λ) + AdvDS
BEUF-CMA(λ).
Thus, as long as the underlying primitives are knowledge sound, weakly
robust and existentially unforgeable then we can conclude the theorem.
⊓⊔
4
An Eﬃcient Instantiation
In this section, we specify the concrete cryptographic primitives used to instanti-
ate our construction. With the exception of RRTE, which is our novel construc-
tion, we refer formal deﬁnitions of primitives and their security properties to the
full version [28]. We would like to stress the modularity of our construction. The
below tools are used in a black box manner and can be replaced by superior
tools that future research will inevitably develop.

Reusable, Instant and Private Payment Guarantees for Cryptocurrencies
595
4.1
Randomness-Reusable Threshold Encryption
(ℓ, t, k)-RRTE is a new observation on threshold encryption (TE) schemes (see
the full version [28] for the deﬁnition) and enables plaintext conﬁdentiality as
long as less than k number of ciphertexts with the same randomness is generated.
Once a data owner issues at least k supplementary ciphertexts, it is publicly
retrievable and everybody can blind out the encrypted data. We formulate this
primitive for compatibility with the rest of our system, but it is worth noting
that the underlying idea is similar to oﬄine double spending detection used in
e-cash schemes.
Deﬁnition 3 (Randomness-Reusable Threshold Encryption).
For a
given public parameters pp and security parameter λ, a (ℓ, t, k)-RRTE, Ψ RRTE,
over the message space M and ciphertext space C consists of three main PPT
algorithms deﬁned as follows:
– ( ⃗pk, pk) ←RRT E.KGen(pp, ℓ, t, k): Key generation is a probabilistic and dis-
tributed algorithm that takes pp along with three integers ℓ, t, k ∈poly(λ) as
inputs. It then returns a vector of public key ⃗pk of size ℓand a general public
key pk as outputs.
– (Ctj, v) ←RRT E.Enc(pp, pk, m, pkj): The encryption algorithm as a proba-
bilistic algorithm takes pp, global public key pk, a message m ∈M along with
a public key pkj as inputs. It returns ciphertext Ctj ∈C associated with the
recipient j ∈R and an auxiliary value v as outputs.
– (⊥, m) ←RRT E.Dec(pp, {Ctj}j∈K, v): The decryption algorithm takes pp,
a set of ciphertexts {Ctj}j∈K along with an auxiliary value v as inputs. If
|K| ≥k, it returns m ∈M, else it responds by ⊥.
Note that in the full version [28] we elaborate more on the security require-
ments and then we propose an eﬃcient construction based on threshold ElGamal
encryptions.
4.2
Pseudo-Random Function
We utilise a weakly-robust PRF proposed by Dodis and Yampolskiy [17] in order
to make customers’ collaterals reusable. This PRF enables us to deﬁne a time
of payment, i.e. x in PRFk(x) = g1/(k+x) function and prove the validity of
operations, eﬃciently. This ensures that a customer always has to input the
time of payment, which is then veriﬁed by a receiving merchant. By utilizing
this property and its combination with RRTE, as discussed in Sect. 1, we can
block a customer from reusing the same collateral for a pre-deﬁned time period.
4.3
Digital Signature Schemes
We require two types of signatures, one for the authorities and another for the
statekeepers. These signatures need non-overlapping properties which we detail
below.

596
A. Madhusudan et al.
– Threshold Structure-Preserving Signatures [16]. There are two reasons to use
the TSPS scheme proposed by Crites et al. Firstly, like any other digital
signature, it provides authentication, such that no entity except the qualiﬁed
authorities can issue collateral proofs. Secondly, due to its threshold nature,
TSPS enables our construction to rely on an honest majority (authorities)
instead of a central trusted party.
– BLS Signatures [8]. BLS Signatures are eﬃciently aggregatable, and thus
they are useful in our setting. A statekeeper must validate payment requests
from various merchants, and they do so using BLS signatures. For a victim
merchant to redeem user collateral from the smart contract, they may ﬁrst
aggregate the signatures allowing for a shorter interaction.
4.4
Commitment Scheme
In our construction, we use the Pedersen commitment scheme [32] due to the
following reasons; ﬁrstly, the TSPS construction is deﬁned over the indexed DH
message spaces (see the full version for the exact deﬁnition) and each secret PRF
key needs to get an index. Hence, these commitments are used to the secret scalar
PRF keys as an index. Secondly, the hiding property of such commitments masks
the secret PRF keys used in our construction. In addition, the binding property
of Pedersen commitments ensures the unforgeability of these secret PRF keys.
Finally, Pedersen commitments are compatible with discrete logarithm-based
proofs like original Sigma protocols and enables customers to eﬃciently prove
knowledge of these committed values.
4.5
NIZK Proofs
To instantiate the described NP-relations in Sect. 3.1, we utilize three main proof
systems: Sigma protocols [34], range-proofs [10] and GS proof systems [24] (see
the full version). Sigma protocols are an eﬃcient choice as the main proof system
in our implementation; we use the Fiat-Shamir heuristic [22] to make then non-
interactive. Range-proofs enable us to prove that a hidden value lies in a range
interval. GS proof systems are useful as they are secure in the standard model and
support a straight-line extraction of the witnesses. Additionally, the instantiation
of these proofs does not require any trusted setup and can be batched: this
enables an eﬃcient veriﬁcation [26].
5
Performance Analysis
In this section, we demonstrate the performance of our system. Based on the
application, the costs incurred in each phase are divided into two parts, termed
“oﬄine phase” and “online phase”. The former includes the parameter genera-
tion, key generation and registration functions. The latter is solely responsible
for spending and veriﬁcation and is the main focus of this evaluation.

Reusable, Instant and Private Payment Guarantees for Cryptocurrencies
597
Fig. 5. Experimental setup. Dotted lines and shapes represent parties and workload
that do not aﬀect the leftmost customer or the leftmost merchant. Our experiment only
considers the solid lines and shapes. From the perspective of the leftmost client and
the leftmost merchant, this is equivalent to running the full system. While statekeepers
are the same as merchants, we make these two sets distinct for clarity.
Our experimental setup is similar to the one in Snappy. Namely, we distribute
various parties in diﬀerent regions around the world and measure the end to
end latency of transactions2. Speciﬁcally, our implementation uses the Charm-
Crypto framework [15], a Python library for Pairing-based Cryptography and
obtained the benchmarks on four AWS EC2 instances. The scenario we consider
is similar to the one in Snappy. Namely, merchants, customers and statekeepers
are globally distributed in four diﬀerent locations and we create 1 000 tps in
order to measure the average time it takes for one transaction to complete.
Since transactions are distributed to many merchants and the merchants run
independently, it is possible to create an equivalent scenario and only consider
the work needed for one merchant. Consider the workload from the perspective
of a single statekeeper: its workload depends on transactions that are passing
through all other merchants. To accurately estimate the workload of a single
statekeeper, we injecting artiﬁcial veriﬁcation requests to it. Our scenario is
summarized in Fig. 5.
All our EC2 instances had the same computational conﬁguration, i.e., an
Ubuntu Server 20.04 LTS (HVM) with an Intel (R) Xeon(R) CPU @ 2.50 GHz
and 16 GB of memory. We apply the Barreto-Naehrig (BN254) curve (also known
as type F groups), y2 = x3+b with embedding curve degree 12 [3]. In this pairing
group, the base ﬁeld order is 256 bits.
2 The open-source implementation can be found in this repository.

598
A. Madhusudan et al.
Fig. 6. Latency comparison. Total transaction time for 1000 tx per second vs the
number of statekeepers.
Latency. As illustrated in Fig. 6, the latency for each transaction grows lin-
early with the number of statekeepers verifying this transaction (depicted with
the orange line). During our evaluations, we noticed that the time required for
a customer to generate and send a payment guarantee (depicted with the red
line) is mostly constant, i.e., ∼240 ms. However, in the case of 40 statekeep-
ers, our construction allows a customer and merchant to successfully transact
within ∼550 milliseconds (ms). In contrast, in the case of 200 statekeepers, a
transaction takes ∼1.3 seconds (s). Hence, the time required to guarantee a pay-
ment to merchants in our construction is bounded by the set of statekeepers. A
direct comparison with Snappy is not possible for two reasons; ﬁrstly, the evalu-
ation of Snappy only considers the time taken for payment approval, i.e., it does
not consider the time spent on customer-merchant interaction. Secondly, their
simulation code is not freely available. A standalone analysis shows that our con-
struction provides privacy against statekeepers without impacting the latency of
payments. Greater number of statekeepers provides more robustness and better
protection against double-spends, but requires stronger liveness assumptions on
top of increasing the latency. We ﬁnd 120 statekeepers to be an optimal trade-oﬀ
of these factors, ultimately leading to latency lower than 1 s.
Smart Contract Cost. The transition between states happens depending on
the function calls on the smart contract. For simplicity, we describe here only
the functionality of the smart contract focusing on one customer and multiple
merchants. We refer to our smart contract as AuthSC, an entity is referred to
as ex where x = c or m for customer or merchant respectively. The underlying
ledger is referred to as LSC and an entity’s account on that ledger is referred to
as Accx
L where x = c or m respectively. The private ledger of the merchants is
referred to as Bullm, since it behaves like a bulletin board. AuthSC has seven
states as follows:
init: AuthSC is deployed. ec can now deposit funds (colc). If so, then change
state to ready. Else do not change state.
ready: ec successfully registers by depositing colc in AuthSC. If colc is available
in AuthSC, change state to pay. Else do not change state.

Reusable, Instant and Private Payment Guarantees for Cryptocurrencies
599
pay: If ec has made payment (paymi), change state to reclaimm. Else do not
change state.
reclaimm: Check Bullm for double-spends from ec. If double-spend present,
use secret to reclaim paymi and change state to withdraw. If no double-spend
found until actual payment received, change state to reclaimc.
reclaimc: If 1 day has passed since paymi, reclaim paymi and add it to colc.
Then, change state to withdraw. Else do not change state.
withdraw: If ec wants to exit the system and the state is withdraw or ready,
send money from AuthSC to Accc
L and change state to exit. If ew wants to
exit the system and the state is withdraw, send money from AuthSC to Accw
L
and change state to exit. Else do not change state.
exit: Remove ex from AuthSC and change state to init.
Table 1 lists the gas fees of executing various functions of our system. In the
ﬁrst column, we mention the amount of base gas fee, and then we express it as a
proportion of minimum gas fee of a transaction. The minimum gas fee is set to
21 000 GWei, which is also the amount of gas that standard on-chain payments
require. Note that the table reﬂects the fees users can expect to pay, although
the actual amount also depends on the so-called priority fee which depends on
the current traﬃc in the Ethereum transaction market. More information about
the costs incurred due to our SC is given in Sect. 6.
Table 1. Costs of transactions on our smart contract deployed on Ethereum, and the
cost as a proportion of a standard transaction Δ = 21 000.
Function Customer reg. Pay
Merchant reg. Reclaim Withdraw Bal.
Gas
107 400
44 055 54 317
34 972
22 352
×Δ
5.1
2.09
2.59
1.65
1.06
6
Discussion
6.1
Collateral Reusability
This property can be understood by comparing to PCNs such as Lightning [33],
Raiden [30]. Our work is similar to PCNs since we are both reliant on collaterals
for guaranteeing security of transactions. PCNs enable quick and cheap trans-
actions over established channels between parties (routes), but suﬀer from route
availability issues in case any involved party is unresponsive. They are capital
dependent, since each channel in a path must individually have suﬃcient capital
to route a certain transaction [25].
The main point of diﬀerence between our work and PCNs is the suitability
for supporting retail markets. The capital locked into a payment channel is only
suitable for a speciﬁc kind of payments, while our collaterals allow customers to

600
A. Madhusudan et al.
pay any merchant in the system. This is because PCNs aren’t designed to tackle
the unilateral nature of payments in retail markets. The funds locked in a channel
deplete quickly, and hence their capability to act as intermediaries decreases [29].
Although fund rebalancing techniques [4] exist to mitigate channel depletion,
they require a user to have multiple channels and are ineﬀective for managing
unilateral payments. Rebalancing is generally not possible for a user that only
employs their channels for payments and not for getting paid. Our protocol is
tailor made to this economic environment, and so we believe it supplements
PCNs, rather than directly competing with them.
6.2
Trust Assumptions
There is a general trade-oﬀbetween the eﬃciency and privacy of a ﬁnancial sys-
tem and the level of trust assumed between participants. For instance, a trusted
central entity can eﬃciently set up a digital currency system, as evidenced by
Chaumian e-cash. Measures of transaction latency and throughput thrive at
the high cost of trust in the central authority. On the other end, decentralized
blockchains achieve functional but slow ﬁnancial systems without requiring trust
in any single party.
The performance of our construction is based on a set of trust assumptions.
Our architecture is semi-decentralized in the sense that we rely on an honest
majority of authorities to initialize our construction. This is similar to the app-
roach of LDSP [31] with the crucial distinction that our authorities do not play
any role in our payment protocol. The merchants and statekeepers have greater
power to punish dishonest customers by conﬁscating their collateral. Yet, we
allow an honest majority of merchants to do so only against customers who
attempt to double-spend, not honest customers. Moreover, the design is per-
missionless in that cryptocurrency holders can freely participate as customers.
Considering the general trade-oﬀbetween centrality, trust, performance and eﬃ-
ciency, we consider our setup to lie in a “sweet spot” where balance is achieved
through cryptographic innovations. We call for further cryptographic innovations
and welcome research into even more trustless, robust and secure systems.
A similar trade-oﬀhas been observed in PCN, a promising scalability solution
for cryptocurrencies, by Avarikioti et al. [2], who suggest that PCN are more
stable and eﬃcient when centralized structures are present. In an empirical sur-
vey, Zabka et al. [35] observe the rising centrality in the Lightning Network as
the capacity and capabilities of Lightning grew over time.
6.3
Privacy
The main idea underlying our private double-spending protection, goes all the
way back to the e-cash schemes introduced by Chaum [14]. The approach of real-
izing oﬄine payments while detecting double-spending, known as the Chaum-
Fiat-Naor (CFN) approach was adopted and improved by several following e-
cash systems [5,9,12,13,23]. The existing plethora of literature has made several

Reusable, Instant and Private Payment Guarantees for Cryptocurrencies
601
improvements to Chaum’s e-cash, however, all work with centrally issued cur-
rency and mostly rely on a custodian bank to catch double-spending. Our work
is also an application of the CFN approach, with the major diﬀerence of build-
ing upon decentralized cryptocurrencies for safely reducing latency, instead of
building an entire e-cash scheme from the ground up. When compared to double-
spend detection techniques in e-cash (for instance the one recently used in [6]),
our novel RRTE is more eﬃcient in terms of communication rounds, allows the
deposited collaterals to be reused and by default enables anyone to track double-
spends.
However, on-chain privacy is derived from the underlying blockchain, and
is the highest level of privacy that one can hope to achieve at the protocol
level. In other words, implementing our overlay on a completely de-anonymized
and public blockchain cannot make the payments private, since the underlying
blockchain will reveal private data no matter how secure the protocol. Similarly,
developing on top of private blockchains such as Monero doesn’t directly solve
the privacy issues of earlier works that allowed transactions of the same user to
be linked. In this way, the question of blockchain-level privacy is relevant yet
orthogonal to our work. While Snappy claims that future improvements such as
deployment on privacy-preserving blockchains that support privacy-preserving
SC will enable their construction to provide on-chain privacy, that is not true.
A detailed explanation is given in Sect. 2 of the full version [28].
6.4
On-Chain Transaction Fees
The transaction fees in our system diﬀer from conventional fees since the cus-
tomer pays the merchant indirectly through a smart contract (SC). This is neces-
sary to prevent an on-chain double-spend by a malicious customer. By on-chain
double-spend, we mean to distinguish between a double-spend attempt of cus-
tomer collateral, and a double-spend on the underlying blockchain itself. Even if
a malicious customer can inﬂuence miners and induce a blockchain double-spend,
the SC-based transaction is able to remunerate the aﬀected merchant. Simply
put, the SC can escrow the funds until suﬃcient conﬁrmations of on-chain pay-
ment have been found. We stick to the convention of 6 succeeding blocks after
said transaction. As discussed in Sect. 5, executing payment through our SC
incurs twice the on-chain transaction fees of a standard on-chain Ethereum pay-
ment. There is an additional fee incurred by the merchant during withdrawal
of payments, but this is far less frequent than the former. Nevertheless, it is
desirable to construct a more cost eﬃcient yet secure system for direct customer
to merchant payments.
A potential ﬁx could be to encode speciﬁc spend conditions for user collater-
als. To be precise, any merchant can move the collateral by providing evidence of
a conﬂicting transaction on the blockchain. This could be implemented via a pay-
ment guarantee to said merchant, along with on-chain evidence of a conﬂicting
payment. We leave this implementation, along with other possible optimizations
of fees, for future work.

602
A. Madhusudan et al.
6.5
Incentives of Involved Parties
This work deals with the cryptographic challenges of achieving privacy while
reducing latency of cryptocurrency payments. Our focus is admittedly myopic,
as we overlook practical aspects of incentives. For instance, we refer to authori-
ties that register merchants and customers, but these authorities lack a concrete
incentive to fulﬁl this role honestly. As an initial and arbitrary choice, we selected
a subset of involved merchants to play this role of authorities, while requiring
an honest majority of authorities. It is unclear who should be playing this role,
and what their incentives should be. Could we perhaps allocate a small fee per
merchant to authority? Or automatically grant a fraction of collaterals conﬁs-
cated from dishonest users? Or even eliminate this issue entirely by building
more advanced cryptography so that our overlay can be set up even without
their existence?
Similarly, we lack a clear explanation of incentives for statekeepers. A basic
solution would be to allocate a certain fraction of each transaction value to the
statekeepers; however, this still needs to be properly analyzed in order to conﬁrm
if such an incentive is suﬃcient.
7
Conclusion
In this paper, we present a new overlay network for instant conﬁrmation of cryp-
tocurrency transactions, that also maintains anonymity of users and unlinkability
of their transactions. On the one hand, it allows merchants in a retail system
to safely accept fast payments without risk of double-spending. On the other,
dishonest customers who attempt to double-spend get their identities exposed
and their collateral conﬁscated to reimburse the merchants. Honest customers,
however, are able to reuse their collaterals.
To this end, we designed a novel randomness-reusable threshold scheme, that
enables participants to audit the payments in the network and reveal the identity
of malicious customer who perform double-spending. This threshold encryption
scheme maintains the privacy of honest customers who do not attempt to double-
spend. We provide a formal proof of security with respect to three main features
namely customers’ anonymity, unlinkability of transactions and payment cer-
tainty for merchants. We motivate our choice of cryptographic primitives and
eﬃciently implement them. Our evaluation shows that our construction allows
for fast global payments with a delay of less than 1 s.
Acknowledgment. We would like to thank Svetla Nikova, Philipp Jovanovic, Chris-
tian Badertscher and Daniel Slamanig for the helpful discussions and the anony-
mous reviewers for their valuable comments. Akash Madhusudan, Mahdi Sedaghat
and Bart Preneel were supported in part by the Flemish Government through the
FWO SBO project SNIPPET S007619, the Research Council KU Leuven C1 on Secu-
rity and Privacy for Cyber-Physical Systems and the Internet of Things with contract
number C16/15/058 and by CyberSecurity Research Flanders with reference number
VR20192203. Samarth Tiwari was supported by ERC Starting Grant QIP–805241.

Reusable, Instant and Private Payment Guarantees for Cryptocurrencies
603
Kelong Cong was supported by the Defense Advanced Research Projects Agency
(DARPA) and Space and Naval Warfare Systems Center, Paciﬁc (SSC Paciﬁc) under
contract No. FA8750-19-C-0502. Any opinions, ﬁndings and conclusions or recommen-
dations expressed in this material are those of the author(s) and do not necessarily
reﬂect the views of the DARPA, the US Government, Cyber Security Research Flan-
ders or the FWO. The U.S. Government is authorized to reproduce and distribute
reprints for governmental purposes notwithstanding any copyright annotation therein.
References
1. Aumayr, L., Abbaszadeh, K., Maﬀei, M.: Thora: Atomic and privacy-preserving
multi-channel updates. IACR Cryptol. ePrint Arch. 317 (2022). https://eprint.iacr.
org/2022/317
2. Avarikioti, Z., Heimbach, L., Wang, Y., Wattenhofer, R.: ride the lightning: the
game theory of payment channels. In: Bonneau, J., Heninger, N. (eds.) FC 2020.
LNCS, vol. 12059, pp. 264–283. Springer, Cham (2020). https://doi.org/10.1007/
978-3-030-51280-4 15
3. Barreto, P.S.L.M., Naehrig, M.: Pairing-friendly elliptic curves of prime order. In:
Preneel, B., Tavares, S. (eds.) SAC 2005. LNCS, vol. 3897, pp. 319–331. Springer,
Heidelberg (2006). https://doi.org/10.1007/11693383 22
4. Avarikioti, Z., Pietrzak, K., Salem, I., Schmid, S., Tiwari, S., Yeo, M.: HIDE &
SEEK: privacy-preserving rebalancing on payment channel networks. Cryptology
ePrint Archive, Report 2021/1401 (2021). https://eprint.iacr.org/2021/1401
5. Baldimtsi, F., Chase, M., Fuchsbauer, G., Kohlweiss, M.: Anonymous transferable
E-cash. In: Katz, J. (ed.) PKC 2015. LNCS, vol. 9020, pp. 101–124. Springer,
Heidelberg (2015). https://doi.org/10.1007/978-3-662-46447-2 5
6. Bauer, B., Fuchsbauer, G., Qian, C.: Transferable E-cash: a cleaner model and the
ﬁrst practical instantiation. In: Garay, J.A. (ed.) PKC 2021. LNCS, vol. 12711, pp.
559–590. Springer, Cham (2021). https://doi.org/10.1007/978-3-030-75248-4 20
7. Benmeleh, Y.: Blockchain ﬁrm starkware valued at $2 billion in funding round
(2021). https://www.bloomberg.com
8. Boneh, D., Lynn, B., Shacham, H.: Short signatures from the Weil pairing. J.
Cryptol. 17(4), 297–319 (2004). https://doi.org/10.1007/s00145-004-0314-9
9. Brands, S.: Untraceable oﬀ-line cash in wallet with observers. In: Stinson, D.R.
(ed.) CRYPTO 1993. LNCS, vol. 773, pp. 302–318. Springer, Heidelberg (1994).
https://doi.org/10.1007/3-540-48329-2 26
10. B¨unz, B., Bootle, J., Boneh, D., Poelstra, A., Wuille, P., Maxwell, G.: Bulletproofs:
short proofs for conﬁdential transactions and more. In: 2018 IEEE Symposium on
Security and Privacy, pp. 315–334. IEEE Computer Society Press (2018). https://
doi.org/10.1109/SP.2018.00020
11. Buterin, V.: An incomplete guide to rollups (2021). https://vitalik.ca/general/
2021/01/05/rollup.html
12. Camenisch, J., Hohenberger, S., Lysyanskaya, A.: Compact E-cash. In: Cramer,
R. (ed.) EUROCRYPT 2005. LNCS, vol. 3494, pp. 302–321. Springer, Heidelberg
(2005). https://doi.org/10.1007/11426639 18
13. Canard, S., Gouget, A.: Multiple denominations in E-cash with compact trans-
action data. In: Sion, R. (ed.) FC 2010. LNCS, vol. 6052, pp. 82–97. Springer,
Heidelberg (2010). https://doi.org/10.1007/978-3-642-14577-3 9

604
A. Madhusudan et al.
14. Chaum, D.: Blind signatures for untraceable payments. In: Chaum, D., Rivest,
R.L., Sherman, A.T. (eds.) CRYPTO 1982, pp. 199–203. Plenum Press, New York
(1982)
15. Joseph, A.A., et al.: Charm: a framework for rapidly prototyping cryptosystems. J.
Cryptograph. Eng. 3, 111–12 (2013). https://doi.org/10.1007/s13389-013-0057-3
16. Crites, E., Kohlweiss, M., Preneel, B., Sedaghat, M., Slamanig, D.: Thresh-
old structure-preserving signatures. Cryptology ePrint Archive, Paper 2022/839
(2022). https://eprint.iacr.org/2022/839
17. Dodis, Y., Yampolskiy, A.: A veriﬁable random function with short proofs and
keys. In: Vaudenay, S. (ed.) PKC 2005. LNCS, vol. 3386, pp. 416–431. Springer,
Heidelberg (2005). https://doi.org/10.1007/978-3-540-30580-4 28
18. Dziembowski, S., Eckey, L., Faust, S., Malinowski, D.: Perun: virtual payment
hubs over cryptocurrencies. In: 2019 IEEE Symposium on Security and Privacy,
pp. 106–123. IEEE Computer Society Press (2019). https://doi.org/10.1109/SP.
2019.00020
19. Electric Coin Company: Explaining viewing keys. https://electriccoin.co/blog/
explaining-viewing-keys/. Accessed 13 Feb 2023
20. Ethereum.org: Layer 2 rollups (2021). https://ethereum.org/en/developers/docs/
scaling/layer-2-rollups/
21. ethos.dev: The beacon chain ethereum 2.0 explainer you need to read ﬁrst. https://
ethos.dev/beacon-chain. Accessed 13 Feb 2023
22. Fiat, A., Shamir, A.: How to prove yourself: practical solutions to identiﬁcation and
signature problems. In: Odlyzko, A.M. (ed.) CRYPTO 1986. LNCS, vol. 263, pp.
186–194. Springer, Heidelberg (1987). https://doi.org/10.1007/3-540-47721-7 12
23. Frankel, Y., Tsiounis, Y., Yung, M.: “Indirect discourse proofs”: achieving eﬃ-
cient fair oﬀ-line e-cash. In: Kim, K., Matsumoto, T. (eds.) ASIACRYPT 1996.
LNCS, vol. 1163, pp. 286–300. Springer, Heidelberg (1996). https://doi.org/10.
1007/BFb0034855
24. Groth, J., Sahai, A.: Eﬃcient non-interactive proof systems for bilinear groups.
In: Smart, N. (ed.) EUROCRYPT 2008. LNCS, vol. 4965, pp. 415–432. Springer,
Heidelberg (2008). https://doi.org/10.1007/978-3-540-78967-3 24
25. Gudgeon, L., Moreno-Sanchez, P., Roos, S., McCorry, P., Gervais, A.: SoK: layer-
two blockchain protocols. In: Bonneau, J., Heninger, N. (eds.) FC 2020. LNCS,
vol. 12059, pp. 201–226. Springer, Cham (2020). https://doi.org/10.1007/978-3-
030-51280-4 12
26. Herold, G., Hoﬀmann, M., Klooß, M., R`afols, C., Rupp, A.: New techniques for
structural batch veriﬁcation in bilinear groups with applications to Groth-Sahai
proofs. In: Thuraisingham, B.M., Evans, D., Malkin, T., Xu, D. (eds.) ACM CCS
2017, pp. 1547–1564. ACM Press (2017). https://doi.org/10.1145/3133956.3134068
27. Hill, K.: How target ﬁgured out a teen girl was pregnant before her father did.
https://www.forbes.com/sites/kashmirhill/2012/02/16/how-target-ﬁgured-out-
a-teen-girl-was-pregnant-before-her-father-did/?sh=53d927356668. Accessed 30
Aug 2022
28. Madhusudan, A., Sedaghat, M., Tiwari, S., Cong, K., Preneel, B.: Reusable, instant
and private payment guarantees for cryptocurrencies. Cryptology ePrint Archive,
Paper 2023/583 (2023). https://eprint.iacr.org/2023/583
29. Mavroudis, V., W¨ust, K., Dhar, A., Kostiainen, K., Capkun, S.: Snappy: fast on-
chain payments with practical collaterals. In: NDSS 2020. The Internet Society
(2020)
30. Network, Raiden: What is the raiden network (2019). https://raiden.network/101.
html

Reusable, Instant and Private Payment Guarantees for Cryptocurrencies
605
31. Ng, L.K.L., Chow, S.S.M., Wong, D.P.H., Woo, A.P.Y.: LDSP: shopping with
cryptocurrency privately and quickly under leadership. In: 2021 IEEE 41st Inter-
national Conference on Distributed Computing Systems (ICDCS), pp. 261–271
(2021). https://doi.org/10.1109/ICDCS51616.2021.00033
32. Pedersen, T.P.: Non-interactive and information-theoretic secure veriﬁable secret
sharing. In: Feigenbaum, J. (ed.) CRYPTO 1991. LNCS, vol. 576, pp. 129–140.
Springer, Heidelberg (1992). https://doi.org/10.1007/3-540-46766-1 9
33. Poon, J., Dryja, T.: The Bitcoin lightning network: scalable oﬀ-chain instant pay-
ments (2016). https://lightning.network/lightning-network-paper.pdf
34. Schnorr, C.P.: Eﬃcient identiﬁcation and signatures for smart cards. In: Brassard,
G. (ed.) CRYPTO 1989. LNCS, vol. 435, pp. 239–252. Springer, New York (1990).
https://doi.org/10.1007/0-387-34805-0 22
35. Zabka, P., Foerster, K.T., Schmid, S., Decker, C.: A centrality analysis of the
lightning network (2022). https://doi.org/10.48550/ARXIV.2201.07746, https://
arxiv.org/abs/2201.07746

System Security

BinAlign: Alignment Padding Based
Compiler Provenance Recovery
Maliha Ismail1(B), Yan Lin2, DongGyun Han3, and Debin Gao1
1 Singapore Management University, Singapore, Singapore
{malihai.2020,dbgao}@smu.edu.sg
2 College of Cyber Security, Jinan University, Guangzhou, China
yanlin@jnu.edu.cn
3 Royal Holloway, University of London, London, UK
DongGyun.Han@rhul.ac.uk
Abstract. Compiler provenance is signiﬁcant in investigating the
source-level indicators of binary code, like development-environment,
source compiler, and optimization settings. Not only does compiler prove-
nance analysis have important security applications in malware and vul-
nerability analysis, but it is also very challenging to extract useful arti-
facts from binary when high-level language constructs are missing. Pre-
vious works applied machine-learning techniques to predict the source
compiler of binaries. However, most of the work is done on the binaries
compiled on Linux operating system. We highlight the importance and
need to explore Windows compilers and the complicated binaries com-
piled on the latest versions of these compilers. Therefore, we construct a
large dataset of real-world binaries compiled with four major compilers
on Windows and four most common optimization settings. The com-
plexity of the optimized programs leads us to identify speciﬁc patterns
in the binaries that contribute to source compiler and speciﬁc optimiza-
tion level. To address these observations, we propose an improved model
based upon the state-of-the-art, and incorporate streamlined alignment
padding features in the existing model. Thus, our improved model learns
alignment instructions from binary code of portable executables and
libraries using the attention mechanism. We conduct an extensive exper-
imentation on a dataset of 296,169 unique and complex binary code
generated from C/C++ applications. Our ﬁndings demonstrate that our
proposed model signiﬁcantly outperforms the state-of-the-art in accu-
rately predicting the source compiler and optimization ﬂag for complex
compiled code.
Keywords: compiler provenance · alignment padding · Windows
binaries · binary code similarity
1
Introduction
Microsoft Windows, which is currently the most dominant desktop operating sys-
tem, commands a substantial market share.1 However, it is also one of the most
1 https://gs.statcounter.com/os-market-share/desktop/worldwide (Windows).
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 609–629, 2023.
https://doi.org/10.1007/978-3-031-35486-1_26

610
M. Ismail et al.
targeted platforms for malicious activities by hackers and attackers. Statista2
reports that 91% of newly developed ransomware in 2022 is intended to target
Windows operating system. As a result, security analysts and researchers are
interested to unleash all those methods that can aid in identifying the charac-
teristics of binary code available in the wild.
When compiling a C/C++ source application, several ﬂags are passed to
the compiler, signaling the developer’s intention to either keep or drop some
information or to modify the original code in a more optimized version. The
executable binary does not need to have knowledge of the compilation ﬂags once
it is compiled, as this information is no more required to execute the binary.
However, these ﬂags are useful during analysis to investigate whether a ﬁle was
compiled with a speciﬁc ﬂag that could expose vulnerabilities [7,32]. They are
also useful, when compiler-optimization-speciﬁc security policies are applied on
applications at the binary level for eﬃcient CFI enforcement [17,18]. Thus, the
security policies are applied varyingly for diﬀerent compiler-optimization set-
tings. Compiler provenance answers fundamental questions of malware anal-
ysis and software forensics, to know whether binaries are generated by similar
toolchains [5,6,12,16,25,28–31]. It also aids the development of binary tools and
analysis capabilities targeted at speciﬁc compilers or source languages [7,28,32].
Furthermore, the source compiler, version and development environment of bina-
ries are amongst the most fundamental artifacts required for analysis at binary
level.
Several studies have been conducted to develop techniques for compiler
provenance analysis, which aim to identify source compilers and optimiza-
tion ﬂags [11,12,14,20,21,26,34,40]. However, the accuracy of these techniques
may reduce due to the continuous developments in modern C/C++ optimizing
compilers. Thus, with the advent of latest optimization strategies and newer
Intel architectural extensions, the compiler provenance analysis approaches may
become outdated [10,23]. While previous research into compiler provenance anal-
ysis techniques [5,25,28,30,31,33] demonstrate high accuracy and promising
results, the study of compiler provenance on Windows platform is limited. Thus,
we analyze the binaries compiled with Windows compilers and found signiﬁcant
patterns that could be a good indicator of the compiler and optimization levels.
Alignment padding [10,23] is a prominent feature of Windows binaries gen-
erated by modern compilers as it aligns the addresses for faster memory access
and prevents processor faults. Since compilers optimize the code for either speed
or size, their choice of instructions and preference for keeping data in the data
section or in-line within the code determines the variation of alignment padding
among compilers at diﬀerent optimization settings. What makes the alignment
padding interesting is the form and number of bytes emitted by the compiler
with respect to the optimization [10,23]. Therefore, we identiﬁed four distin-
guishing patterns of alignment padding and integrate them into state-of-the-art
model for learning and classifying the source compiler and optimization level.
2 https://www.statista.com/statistics/701020/major-operating-systems-targeted-by-
ransomware/.

BinAlign: Alignment Padding Based Compiler Provenance Recovery
611
With this observation, we propose BinAlign that leverages alignment padding
in the binary code to help predict source compiler and optimization ﬂags of the
compiled code with improved accuracy. Thus, we train our proposed model to
map the alignment padding in order to classify source compiler and optimization
ﬂag of the target binaries. The classiﬁcation task identiﬁes the toolchain used to
generate unknown binaries and produces information that is required by binary
analysis tools (i.e., for CFI enforcement and security patching) [17]. Thus, in
order to evaluate the performance of o-glassesX [25] and our improved model,
we mainly focus on answering the following research questions:
– RQ1. How eﬀective is BinAlign in identifying the source compiler of a binary?
– RQ2. How eﬀective is BinAlign in identifying two- (i.e., Od/O0 and Ox/O3)
and four-level3 (i.e., Od/O0, O1, O2 and Ox/O3) of compiler optimization
settings?
– RQ3. How eﬀective is BinAlign in identifying the joint source compiler and
optimization settings?
Hence, we base our study on a set of 296,169 real-world binaries compiled
with four major compilers, i.e., Microsoft Visual C++ (MSVC) [1], Clang-cl
(Clangcl)4, Intel C Compiler (ICC)5, and Minimalist GNU Compiler Collection
for Windows (MinGW) [2], in two- and four-level of varying compiler optimiza-
tion settings. We achieved an overall f-measure (F1) of 0.978 when predicting
the source compiler among four compilers and two compiler optimization levels.
The main contributions of our paper are as follows:
– An in-depth study on compiler provenance of binary code: We inves-
tigate the characteristics of Windows binaries with the perspective of align-
ment bytes generated by modern compilers at four levels of compiler opti-
mization settings.
– Alignment padding based compiler provenance model: We propose an
improved convolutional neural network (CNN) that learns the special char-
acteristics of alignment padding in the binaries and results in an improved
performance.
– Generality of our approach: In order to evaluate the applicability of our
method, we gather a collection of benign and malicious software binaries
from real-world applications, compiled using diﬀerent versions of the MSVC
compiler. This helps us enhance the precision of our approach when analyzing
complex and obfuscated malware binaries.
3 For MSVC, Clangcl and ICC compilers, the optimization levels Od and Ox refer
to none and extreme level of optimization. However, for the MinGW compiler, the
corresponding optimization levels are O0 and O3, respectively.
4 https://clang.llvm.org/docs/MSVCCompatibility.html (Clangcl with MSVC).
5 https://support.alfasoft.com/hc/en-us/articles/360002874938 (Intel compatibility
with MSVC).

612
M. Ismail et al.
Table 1. Alignment padding frequently found in common sections of the PE binary
Category
Section Content
Paddings
Code section
.text
Executable code
INT3, NOP
Data Sections .data
Read-write initialized data ZERO, DB
.pdata
Exception information
ZERO, DB
.rdata
Read-only initialized data
ZERO, DB
.idata
Import tables
none
2
Background and Related Work
2.1
Alignment Padding
In this section, we revisit the alignment padding generated by compilers in the
binaries for aligning code and data. The term Alignment padding is referred to
as the padding code placed as trailing sequence next to a control-ﬂow transfer,
or padding bytes at speciﬁc locations to align data and instructions in the binary
(See Footnote 5). Alignment padding consists of an opcode and optionally an
operand, similar to binary instructions on any architecture or platform [3].
Alignment Padding in PE Sections. Portable executable (PE) is a ﬁle for-
mat for executables, object code, and dynamic link libraries (DLLs) on Win-
dows. Table 1 shows the sections commonly found in a PE binary and the
types of alignment padding6 that are most frequently found in each section.
As described in Microsoft developer documentation [1], each section consists
of diﬀerent types of program data. The .text section contains executable code,
while the data sections maintain data to execute the binary (i.e., .data, .pdata,
.rdata, and .idata). Alignment padding is found in both the .text and data
sections except for the .idata section, which contains the import directory and
import address table (IAT). Table 2 shows the placement of four major types of
alignment padding and ﬁller instructions in the binary.
2.2
Machine Learning Approaches for Compiler Provenance
This section revisits the previous research conducted on compiler provenance and
introduces the relevance of alignment padding for provenance recovery. Previous
works utilized machine learning (ML) methods to perform compiler provenance
recovery, since signature-based7,8 methods depend on signatures database [9]
to report the source compiler. On the other hand, ML-based methods learn the
compiler-speciﬁc patterns and features to predict the source compiler of previ-
ously unseen binaries. Rosenblum et al. [30] were the ﬁrst to extract syntactic and
6 We use the instructions to represent alignment padding except ZERO as the type of
alignment padding.
7 https://github.com/horsicq/Detect-It-Easy.
8 https://www.aldeid.com/wiki/PEiD.

BinAlign: Alignment Padding Based Compiler Provenance Recovery
613
Table 2. Types of alignment padding in the binary code
# Align Purpose
Usage
1
NOP
Program execution continues
with the next instruction
Function-entry alignment in ICC and
MinGW
2
INT3
Single-byte instruction for
setting breakpoints for the
debugger
Function-entry alignment in MSVC,
Clangcl, ICC
3
DB
Reserve space for data
Data alignment in .text and data
sections for MSVC, Clangcl, ICC,
whereas data alignment in data
sections only for MinGW
4
ZERO
ADD instruction with zero
opcode and zero operand
Align code and data; may also update
memory location, set carry, overﬂow,
and zero ﬂags
5
Filler Pseudo NOPs
MOV RAX,RAX; LEA RBX,[RBX+0]; XCHG
RAX,RAX
structural features from the binaries based on instruction idioms and graphlets.
This work was followed by Chaki et al. [6], Xue et al. [39], and Rahimian et al. [27]
that used various machine learning classiﬁers to identify similar chunks of code
in the binary. Moreover, the past works [20,21,26,30,31,33,34] used binary-level
control ﬂow features and functions to predict program provenance. More recent
works such as Ding et al. [8] proposed an Asm2Vec model for assembly code
learning based on functions.
Although, past research acknowledged the alignment padding patterns in
the binary [4,31,36,37], the signiﬁcance of these patterns in relevance to pro-
gram provenance has not been considered earlier. Rosenblum et al. [31] named
the alignment bytes as gaps within the functions, whereas Andriesse et al. [4]
considered these patterns as inline data within the code. Wang et al. [36,37]
corroborated the reassembly of binary, while considering the memory alignment
of data and function pointers. While considering all the past eﬀorts, the com-
piler provenance recovery models [20,21,26,30,33,34] that take the control-ﬂow
features of the binary ignore the alignment padding that lie outside the control
ﬂow graph of the program such as function-entry and loop-entry alignment.
In this work, we chose o-glassesX [25] as our evaluation baseline for compiler
provenance recovery leveraging alignment padding. This is because o-glassesX
is state-of-the-art model with 97% accuracy, while utilizing short binary code
from C/C++ object ﬁles. However, on recent compiler versions and a complex
set of binaries, o-glassesX does not maintain to achieve the claimed accuracy.
Therefore, we propose BinAlign to predict the source compiler and optimization
level with better prediction accuracy.

614
M. Ismail et al.
2.3
o-glassesX Architecture
This section brieﬂy explains the architecture of our baseline, o-glassesX. It uses
natural language processing (NLP) techniques called the attention mechanism
with convolutional neural network (CNN) to capture the characteristics of a sin-
gle instruction by multiple local receptive ﬁelds [25]. The input unit of CNN is the
local receptive ﬁeld (i.e., kernel), whereas the output unit is the volume of kernel
size (K), depth, and stride (S) length. The depth of the CNN refers to the number
of ﬁlters, whereas stride is the step size of the kernel when traversing the width
and height of the input binary image. In the preprocessing stage, o-glassesX
disassembles binary into 128-bit ﬁxed length instructions padded with zeros to
construct a 2048-bit sequence of 16 instructions. The underlying architecture of
neural network comprises the following CNN layers:
– The ﬁrst layer takes 2048 bits of binary code as input. Each unit is a single-
dimension 128-unit kernel, with stride length of 128 and depth of 96.
– The second layer is the positional encoding layer with 256 ﬁlters to a 16 × 96
input volume with a stride of 1. This layer captures the relationship between
two adjacent instructions. The instructions in positional feed-forward network
(PFFN) in Transformer are arranged into two dimensions by setting the stride
and kernel size to 1.
– The third, fourth and ﬁfth layers correspond to attention, batch normaliza-
tion and fully connected layers with K nodes as output classes to classify the
network, respectively. RELU is the activation function in each intermediate
layer, whereas the ﬁnal layer uses softmax for classiﬁcation. In the model’s
back-propagation algorithm, the stochastic gradient descent (SGD) method
is used to minimize the error function [25].
3
Motivation
Our motivation for this study is the observation of alignment paddings and
their placement in the binary with respect to diﬀerent compilers and opti-
mization settings. To motivate the idea of leveraging alignment padding for
compiler provenance recovery, we analyze the binary code of the function
sqlite3 str vappendf compiled with three compilers and optimization settings,
and see if the corresponding alignment padding presents unique patterns. List-
ing 1 shows diﬀerent snippets of the binary code disassembled at the entry of a
variadic function in sqlite3 C application.
SQLITE_API void sqlite3_str_vappendf(sqlite3_str *pAccum, const char
*fmt, va_list ap) {...}
From Listing 1, our ﬁrst observation is that MSVC and Clangcl compilers prefer
to insert INT3 bytes at the entry of a function, whereas ICC emits NOP in-place
of INT3 for the function-entry alignment. In this particular example, the align-
ment padding at the function-entry in O2 and Ox does not diﬀerentiate from

BinAlign: Alignment Padding Based Compiler Provenance Recovery
615
each other. This is because the compilers will only generate diﬀerent binary code
in the corresponding optimization levels, when there exist duplicate copies of
constant data elements and function deﬁnitions in the binary.9 To demonstrate
the frequency of alignment padding in binaries, we look at another example
among the complex set of C projects in our database (i.e., openssl), as listed
in Table 3. Here, we observe that the alignment padding in O2 and O3 vary in the
MinGW compiler as compared to the other three compilers. This is because the
MinGW compiler in O3 applies aggressive optimization strategies, like function
inlining and loop unrolling, as compared to O2.
Moreover, the frequency of alignment in .text section highlights that INT3
is the most frequently used alignment padding for the functions compiled with
MSVC and Clangcl compilers. The reason is due to the fact that compilers emit
INT3 instruction as debugger trap to gracefully handle the execution in case of
an exception (See Footnote 9). In contrast, MinGW compiler utilizes a larger
number of NOPs for aligning the optimized instructions.
Interestingly, we found that DB and ZERO are frequently emitted alignment
bytes in the data sections of compiled binaries at higher optimization levels.
Therefore, to favor the small size of optimized binaries, compilers allocate data
sections for alignment padding and emit reduced code in the .text section,
respectively. Overall, all compilers emit frequent ZERO alignment padding in the
data sections of the binaries, including the end-of-section alignment padding (See
Footnote 9). Thus, we can say that there is a signiﬁcant variation of alignment
padding found in the binaries compiled with various compilers and at diﬀerent
optimization settings on Windows. Therefore, to achieve the best possible per-
formance, it is a common practice for compilers to enforce natural alignment
of both data and code [2,22]. However, the compiler’s strategy for alignment
9 https://docs.microsoft.com/en-us/cpp/build/reference/compiler-options-listed-
alphabetically?view=msvc-160.

616
M. Ismail et al.
Table 3. Number of Alignment padding bytes in the .text and .data sections of
openssl application, compiled with four compilers at four optimization levels.
Section
.text
.data
Padding
Opt
MSVC
ICC
Clangcl
MinGW
MSVC
ICC
Clangcl
MinGW
#NOP
Od/O0
52
648
140
12,109
156
67
85
124
O1
15
564
70
6,630
126
90
75
124
O2
433
871
597
25,499
142
99
56
127
Ox/O3
433
871
597
26,481
142
99
56
138
#DB
Od/O0
264
0
1,419
15
2,710
2,594
3,635
2,665
O1
58
0
1,347
16
1,855
1,829
2,129
2,685
O2
269
98
2,644
14
1,817
3,825
2,092
2,656
Ox/O3
269
98
2,644
16
1,817
3,825
2,092
4,260
#INT3
Od/O0
3,438
117
15,146
0
47
48
55
64
O1
671
144
12,156
0
49
66
50
66
O2
2,608
188
14,125
0
58
53
62
51
Ox/O3
2,608
188
14,125
0
58
53
62
69
#ZERO
Od/O0
164
0
2
9
11,726
15,388
14,710
17,477
O1
150
0
6
9
13,646
16,422
13,322
17,492
O2
222
9,682
4
9
12,454
18,714
11,120
17,283
Ox/O3
222
9,682
4
9
12,454
18,714
11,120
16,263
padding varies from platform to platform. Thus, to compare Windows and Linux,
Windows specify additional alignment options to align the sections and pages
of PEs and DLLs on a 4K-byte boundary (See Footnote 9). Whereas, the sec-
tions on Linux are aligned on a 4-byte boundary [22,23]. These speciﬁcations
are additional to the data alignment for optimized code constructs and trans-
fer operations [22,35]. It is worth noting here that ELF x86-64 ABI does not
require the virtual and physical address to be page-aligned. Though diﬀerent
from Linux, the alignment padding on Windows shows interesting patterns in
the compiled binary, which is signiﬁcant for compiler provenance. We thus high-
light the importance of alignment padding on Windows and demonstrate that it
is more useful for compiler provenance.
4
Compiler Provenance Recovery Model
In Sect. 3, we saw that diﬀerent compilers and optimization levels emit unique
signatures in the binary code compiled with diﬀerent settings. In this section,
we review the state-of-the-art deep learning model, o-glassesX and present our
enhanced model, BinAlign. A deep neural network trained completely on data
without domain knowledge might be non-explainable [38], whereas a system
based entirely on expert knowledge may have limitations due to insuﬃcient infer-
ence logic [28]. Xu et al. [38] state that adding node embeddings to control ﬂow
graph (CFG) of binary functions enhance the performance of the underlying
binary similarity model. With this background, we improve the existing com-
piler provenance model, o-glassesX, and embed expert knowledge of alignment
padding into the CNN based deep learning model.

BinAlign: Alignment Padding Based Compiler Provenance Recovery
617
Fig. 1. Design overview of BinAlign and improved BinAlign architecture
4.1
BinAlign
The architecture of BinAlign is illustrated in Fig. 1. BinAlign follows the same
approach as o-glassesX for classifying the binary instructions into diﬀerent
classes of compiler provenance. It is thus composed of the following three major
components,10 i.e., 1) binary slicing, 2) padding tokenization, 3) CNN. The neu-
ral network consists of the following core layers, i.e., i) positional encoding, ii)
attention block, iii) batch normalization, and iv) fully connected layer.
The input to the network is a sequence of 128-bit ﬁxed-length instructions
that are embedded with alignment padding information. Thus, binary instruc-
tions are read in the form of image vector encodings. An image vector is a
numerical representation of the binary in which each pixel is represented by a
value of either 0 or 1.
To incorporate alignment padding in the underlying CNN architecture, we
slice the binary code and detect patterns associated with alignment padding.
We then categorize the alignment padding instructions into diﬀerent groups and
assign them the corresponding tokens (denoted by TOK), as shown at lines 6, 8,
10, and 12 of Algorithm 1. Thus, we encode the tokens along with the instructions
and input the vectors into positional encoding layer preceding the attention layer
of BinAlign. Following the approach in previous work [24], we pad all instructions
with zeros to make them a uniform 16-byte length. Additionally, our approach
considers all variations of the NOP instruction (as outlined in Table 4) to be
incorporated into the model.
After tokenization, the positional encoding layer of BinAlign captures the
relationship between two adjacent instructions. Thus, the positional encodings
are learnt by the attention layer that utilizes self-attention to generate weights
and focuses on a portion of the input information to classify binary sequences.
Finally, the output of the attention block is passed through batch normalization
layer to stabilize the network. Thus, the ﬁnal layer of CNN (i.e., the fully con-
nected layer) classiﬁes the network into various output classes. RELU [25] is the
activation function in each intermediate layer, whereas the ﬁnal layer uses soft-
max for classiﬁcation. In the model’s back-propagation algorithm, the stochastic
gradient descent (SGD) [25] method is used to minimize the error function.
10 The improvements (i.e., additional layers and optimization algorithm) marked with
* in Fig. 1, belong to the improved BinAlign design.

618
M. Ismail et al.
Algorithm 1. Binary Slicing and Instruction Tokenization
1: procedure FetchAlignmentPaddings(bnry)
2:
foreach Insn in binaryCode
3:
if instruction == AlignmentPadding then
4:
Do foreach {Insn} in the AlignmentPadding
5:
if opcodensn == DATA then
6:
Assign TOK of “DB” instructions
7:
else if opcodensn == ZERO then
8:
Assign TOK of “ZERO” instructions
9:
else if opcodensn == INT3 then
10:
Assign TOK of “CC” instructions
11:
else if opcodensn == NOP then
12:
Assign TOK of “NOP” instructions
13:
else if instruction ∈Filler then
14:
Assign TOK of “Filler” instructions
15:
else if instruction ∈non-Alignment then
16:
Assign TOK of “non-padding” instruction
Table 4. Multi-byte NOP alignment padding
Opcode Operand
no. of Bytes Hex representation
NOP
<no operand>
1
90
NOP
<no operand>
2
6690
NOP
WORD [RAX+RAX+0x0]
9
660f1f840000000000
NOP
WORD [RAX+RAX+0x0]
10
662e0f1f840000000000
NOP
DWORD [RAX]
3
0f1f00
NOP
DWORD [RAX+0x0]
4
0f1f4000
NOP
DWORD [RAX+RAX+0x0] 5
0f1f440000
4.2
Improved BinAlign
Due to our added attributes in the form of alignment padding tokens (see Fig. 1)
in the existing model [25], we need to enhance the underlying architecture with
additional layers. This is because the alignment padding is not uniformly dis-
tributed in the binary. For example, at one point the compiler may align the end-
of-section with a large number of recurring padding bytes, whereas at another
location, a multi-byte instruction may be generated to enforce the instruction
alignment. In Table 5, we present nine scenarios in which the compilers emit
alignment padding at diﬀerent locations in the binary. Therefore, it becomes
necessary for BinAlign to include additional layers in the underlying architec-
ture to enhance its performance. Thus, we add maxpooling, dropout and adam
optimizer to enhance the basic architecture of BinAlign and name it as the
improved BinAlign as shown in Fig. 1. We brieﬂy explain the additional layers
and optimization in this section.

BinAlign: Alignment Padding Based Compiler Provenance Recovery
619
Table 5. Nine scenarios when compilers emits alignment padding at diﬀerent locations
in the binary with respect to optimization
# Placement in
Binary
Purpose and Location
Impact of Optimization
Align type
1
Data interleaved in
Code
inline data in .text
section
increase with optimization
DB
2
Import Functions
before a branch
instruction
decrease with optimization
NOP
3
Exception handling
(EH) functions
aligned jump tables
less in MSVC & Clangcl,
intense in ICC at O2, Oxa
NOP
4
Intrinsic functions
compiler’s inlined
functions
expansion of function vary
with compiler family &
optimization [19]
NOP, DB
5
Function-entry
alignment
before subroutine or
EH function
align code and data
INT3, NOP
6
Common Runtime
(CRT) routines
handcoded assembly
routines
intense use of CRT at higher
optimization
ZERO, DB
7
End-of-segment
alignment
PE sections are
aligned
decrease with higher
optimization
ZERO, DB
8
Vector operations
128-bit multimedia
operands are aligned
MMX and SSE (XMM)
instructions aligned at 16
Byte address
NOP, DB
9
Branch Alignment
align branch target to
a multiple of 16
increase with optimization
NOP
a https://support.alfasoft.com/hc/en-us/articles/360002874938 (Intel compatibility with
MSVC).
(1) Pooling [15] is a regularization technique that reduces overﬁtting, whereas
max pooling decreases the computational cost by reducing the number of
parameters to learn the features. We add a max-pooling layer after the con-
volution layer to extract shallow features from binary code with K as 96,
and stride length as 128. Thus, pooling assists deep learning architectures
to reduce computational cost caused by the dimensionality reduction prob-
lem [15].
(2) Dropout [15] assists the neural network in achieving high-quality perfor-
mance on the test set and prevents the model from overﬁtting. We apply
dropout to the fully connected layer of the neural network. Thus, by utilizing
max-pooling and dropout, we aim to achieve the stochastic pooling in terms
of activation picking, inspired by dropout regularization approach [15]. Here,
we add a dropout layer with a rate of 0.5.
(3) Adam optimization [13] is an extension to classical stochastic gradient
descent (SGD) to update network weights iteratively based on training data.
SGD algorithm maintains a single learning rate (i.e., α) for weight updates
which does not change during training. It has two more extensions, i.e., Ada-
Grad [41] and RMSProp [41] and Adam optimizer combines the beneﬁts of
both extensions of SGD. Thus, in order to optimize for better accuracy,

620
M. Ismail et al.
we replace SGD with Adam optimizer having following parameters, i.e., a)
α as the coeﬃcient for learning rate is set to 0.001, b) β1 and β2 as the
exponential decay rates are set to 0.9 and 0.999, respectively, and c) ε is
initialized as 1e−08. Thus, we train the improved BinAlign model over all
the unoptimized and optimized binaries to learn the source compiler and
optimization level classiﬁcation. Similar to o-glassesX, we parse the binaries
with distorm311 disassembler and get x86-64 assembly instructions.
5
Experimental Design
In this section, we explain our experimental design to evaluate the precision (P),
recall (R) and f-measure (F1) of inferring the source compiler, and optimization
level for o-glassesX, BinAlign (i.e., state-of-the-art with alignment padding), and
improved BinAlign (i.e., state-of-the-art with alignment padding and additional
layers in the CNN architecture). Hence, our evaluation is performed on a server
machine having Ubuntu 22.04.1 LTS OS with 3.5 GHz and upto 64 CPU core
processors with 132 GB RAM and 4 GeForce RTX2080 Ti GPUs having 12GB
of memory. We thus perform experimentation on a large collection of binaries
compiled with latest compilers on Windows, as they implement modern compiler
optimization strategies. Here it is worth mentioning that we are not replicating
the experiments in the o-glassesX paper. We therefore, focus on compiler prove-
nance inference in x86-64 architecture for benign code and x86 for malicious
code. The dataset is compiled from a set of 457 well-known C/C++ open-source
projects using four commonly used compilers, i.e., MSVC-19, Clangcl-10, ICC-
2021 and MinGW-10.
For the ground truth, we record the source compiler and optimization
level label and compile all application in release build with debugging symbols
enabled. Since, the debug information is present in separate PDB ﬁles that pro-
vide us information about the function-entry addresses, we study the diﬀerences
in the alignment padding at the function start locations using the information
extracted from the symbols. However, it is worth noting here that all tasks of
provenance recovery training and inference are performed on the stripped bina-
ries.
We therefore generate a diverse set of binaries that range in size from a
few kilobytes to 40 megabytes. For each project, we build dependent libraries
and programs separately. Further details regarding some of the projects in our
dataset can be found in Table 6. Hence, we publish our compiled dataset and
program source code for further study and research12 (Table 7).
11 https://pypi.org/project/distorm3.
12 https://github.com/mali-arf/binalign comp.

BinAlign: Alignment Padding Based Compiler Provenance Recovery
621
Table 6. The selected C/C++ projects from Github in our dataset
Project
Description
ogg-vorbis
audio encoder/decoder for lossy compression
cmake
a cross-platform, open-source build system generator
curl
library for data transfer with url syntax
doxygen
document generation tool from annotated C++ sources
eigen
C++ template library for linear algebra, matrices, vectors, numerical solvers, etc.
gﬂags
C++ library with command-line ﬂags for strings, etc.
glm
C++ openGL Mathematics library for graphics
glog
C++ google logging (glog) module
libevent
a library that provides asynchronous event notiﬁcations
llvm
an open source compiler and toolchain
onednn
oneAPI deep neural network library optimized for Intel and Xe architectures
opencl
Open Computing Language for heterogeneous platforms like CPUs, GPUs, etc.
openssl
library to secure communications over computer networks against eavesdropping
Microsoft lib
C++ Standard Template Library (STL) for MSVC toolset and Visual Studio IDE
sqlite
a relational database management system contained in a C library
vtk
an image processing, 3D graphics, volume rendering, and visualization toolkit
zlib
data compression library used in gzip ﬁle compression programs
Table 7. The number of compiled binaries
in our dataset
Compiler
Version
number of binaries
Od/O0
O1
O2
Ox/O3
MSVC
19.28.29
28,359
23,201
21,982
32,705
Clangcl
10.0.0
18,834
9,938
11,512
19,354
ICC
2021.1.2
14,475
10,193
11,816
14,798
MinGW
10.3.0
22,606
17,573
16,325
22,498
Total
84,274
60,905
61,635
89,355
We collect C/C++ applications
in
our
dataset
comprising
of
a
large number of stars and widely
used in binary analysis research.
We, then construct a dataset of
296,169 binaries compiled with four
major compiler optimization settings
(see Sect. 5).
Thus, we ﬁne-tune the evalua-
tion models to get best results from o-glassesX, BinAlign and Improved
BinAlign. o-glassesX utilizes four main hyperparameters that are tuned to
achieve the best results in each model. Therefore, all models achieve the best
average accuracy at the same hyperparameter setting with i) batch size as 1000,
ii) instruction length as 64, iii) sample size as 100,000, and, iv) epoch as 50.
Hence, we used 4-fold cross-validation to perform training and testing of data
for four tasks, i.e., source compiler inference, compiler optimization inference,
and joint source compiler with two and four levels of compiler optimization
inference, respectively. The average results on the compiler provenance tasks are
shown in Tables 8, 9, 10 and 11.
6
Results
In this section, we present our experimental results in the form of answers to the
RQs discussed in Sect. 1. To ensure a fair comparison with previous research, we

622
M. Ismail et al.
calculate the average test results for each model in order to draw conclusions
about the source compiler, optimization levels, and joint source compiler and
optimization levels.
6.1
RQ1. How Eﬀective is BinAlign in Identifying the Source
Compiler of Binaries?
Table 8 measures our models’ recall (R), precision (P) and f-measure (F1)
while inferring the source compiler for the three models. Overall, our improved
BinAlign model shows increased performance while inferring the source compiler
of the test binaries. One of the reasons for improved performance on MSVC com-
piled binaries is the inference of NOP bytes to align the data for compiler-speciﬁc
intrinsic functions. Which the model learns to correctly infer the compiler spe-
ciﬁc alignment. Similarly, for ICC compiled binaries, the improved BinAlign
performs much better than o-glassesX for classifying the NOP bytes embedded
before every CALL to the internal compiler functions.
6.2
RQ2. How Eﬀective is BinAlign in Identifying the Compiler
Optimization Level of a Binary?
Tables 9a and 9b present the results on the classiﬁcation of the two- and four-
level of compiler optimizations, respectively. The results of the two-level opti-
mization inference task, as presented in Table 9a, demonstrate that the improved
BinAlign model can accurately determine the optimization level of the most opti-
mized binaries, with a level of precision that is almost as high as that for the
unoptimized binaries. However, Table 9b shows that the least correctly inferred
compiler optimization setting for BinAlign is O2. This is because of an opti-
mization strategy that is followed by the compilers to maintain a single copy for
the common data and functions in the binary (i.e., COMDAT (See Footnote 9)).
The optimization conﬁnes the alignment padding, thereby aﬀecting the inference
of the highly optimized binaries.
However, the improved BinAlign demonstrates a relatively higher accuracy
in inferring class labels for O1 and Ox optimized binaries. This can be attributed
to the optimization strategy employed by compilers on Windows, which gener-
ates separate copies of aligned functions and data with multiple deﬁnitions at
the Ox optimization level. Conversely, the code generated by the O1 optimiza-
tion level remains consistent across all compilers. This consistency arises because
compilers tend to reserve most of the alignment padding in the data sections,
which favors the reduced size of the binary code. Overall, our evaluation results
show that optimizations performed by compilers generate variant and complex
code, making it diﬃcult for the compiler prediction neural network based models
to learn the consistent patterns. However, the improved BinAlign signiﬁcantly
improves the existing state-of-the-art model in recovering the compiler optimiza-
tion inference of real-world binaries.

BinAlign: Alignment Padding Based Compiler Provenance Recovery
623
Table 8. The result of source compiler inference
Compiler
o-glassesX
BinAlign
Improved BinAlign
R
P
F1
R
P
F1
R
P
F1
MSVC
0.9729 0.9797 0.9763 0.9953 0.9934 0.9943 0.9938 0.9972 0.9955
Clangcl
0.9465 0.9470 0.9467 0.9787 0.9809 0.9798 0.9739 0.9890 0.9814
ICC
0.9662 0.9697 0.9679 0.9890 0.9907 0.9899 0.9944 0.9862 0.9903
MinGW
0.9216 0.8988 0.9100 0.9643 0.9613 0.9628 0.9812 0.9646 0.9728
Overall
0.9576 0.9576 0.9576 0.9850 0.9850 0.9850 0.9873 0.9873 0.9873
Table 9. The result of two and four levels of compiler optimization level inference
(a) Two-level compiler optimization inference (i.e., Od/O0 and Ox/O3)
o-glassesX
BinAlign
Improved BinAlign
Opt
R
P
F1
R
P
F1
R
P
F1
Od/O0
0.9783
0.9736
0.9764
0.9888
0.9896
0.9892
0.9914
0.9902
0.9908
Ox/O3
0.9696
0.9750
0.9723
0.9883
0.9874
0.9879
0.9890
0.9903
0.9897
Overall
0.9739
0.9743
0.9743
0.9886
0.9886
0.9886
0.9902
0.9902
0.9902
(b) Four-level compiler optimization inference (i.e., Od/O0, O1, O2, Ox/O3)
o-glassesX
BinAlign
Improved BinAlign
Opt
R
P
F1
R
P
F1
R
P
F1
Od/O0
0.9839
0.9838
0.9838
0.9873
0.9885
0.9879
0.9915
0.9874
0.9894
O1
0.7365
0.7275
0.7320
0.7313
0.8078
0.7676
0.8002
0.8375
0.8184
O2
0.6971
0.6011
0.6456
0.6316
0.6701
0.6503
0.8248
0.8217
0.8232
Ox/O3
0.6371
0.6276
0.6323
0.7198
0.8714
0.7884
0.7495
0.9083
0.8213
Overall
0.7678
0.7472
0.7562
0.7730
0.8298
0.7995
0.8318
0.8811
0.8547
Table 10. Inference of joint source compiler with two levels of compiler optimization
Compiler-opt
o-glassesX
BinAlign
Improved BinAlign
R
P
F1
R
P
F1
R
P
F1
MSVC-Od
0.9667
0.9643
0.9655
0.9886
0.9743
0.9814
0.9991
0.9925
0.9958
MSVC-Ox
0.9357
0.9535
0.9445
0.9651
0.9795
0.9722
0.9735
0.9808
0.9772
Clangcl-Od
0.9779
0.9744
0.9761
0.9885
0.9888
0.9886
0.9985
0.9998
0.9992
Clangcl-Ox
0.9088
0.9212
0.9150
0.9599
0.9508
0.9553
0.9508
0.9618
0.9563
ICC-Od
0.9831
0.9905
0.9868
0.9945
0.9971
0.9958
0.9932
0.9995
0.9963
ICC-Ox
0.9519
0.9423
0.9471
0.9777
0.9840
0.9808
0.9732
0.9815
0.9773
MinGW-O0
0.9711
0.9668
0.9690
0.9949
0.9868
0.9908
0.9993
0.9942
0.9967
MinGW-O3
0.8438
0.7975
0.8200
0.9085
0.9164
0.9124
0.9367
0.9194
0.9279
Overall
0.9515
0.9515
0.9515
0.9772
0.9772
0.9772
0.9781
0.9787
0.9785

624
M. Ismail et al.
Table 11. Inference of joint source compiler with four levels of compiler optimization
Compile-opt
o-glassesX
BinAlign
Improved BinAlign
R
P
F1
R
P
F1
R
P
F1
MSVC-Od
0.9715
0.9695
0.9705
0.9874
0.9718
0.9795
0.9826
0.9737
0.9781
MSVC-O1
0.7692
0.6615
0.7113
0.7732
0.7961
0.7845
0.8880
0.7986
0.8409
MSVC-O2
0.4995
0.2488
0.3322
0.5806
0.0845
0.1476
0.5223
0.3005
0.3816
MSVC-Ox
0.7109
0.8602
0.7784
0.7113
0.9127
0.7995
0.7458
0.8791
0.8070
Clangcl-Od
0.9810
0.9808
0.9809
0.9883
0.9850
0.9866
0.9932
0.9816
0.9874
Clangcl-O1
0.6215
0.4529
0.5240
0.7532
0.5485
0.6348
0.7721
0.6354
0.6971
Clangcl-O2
0.3373
0.0696
0.1154
0.6477
0.5503
0.5951
0.6515
0.7314
0.6892
Clangcl-Ox
0.7392
0.8892
0.8073
0.6126
0.7292
0.6658
0.7023
0.6501
0.6752
ICC-Od
0.9888
0.9929
0.9909
0.9950
0.9943
0.9947
0.9941
0.9979
0.9960
ICC-O1
0.7487
0.5993
0.6657
0.7614
0.7666
0.7640
0.8759
0.8062
0.8396
ICC-O2
0.3853
0.1187
0.1815
0.6586
0.0890
0.1568
0.4455
0.2701
0.3363
ICC-Ox
0.7158
0.8959
0.7958
0.7243
0.9367
0.8169
0.7468
0.8624
0.8005
MinGW-O0
0.9782
0.9764
0.9773
0.9833
0.9917
0.9875
0.9928
0.9868
0.9898
MinGW-O1
0.9466
0.9372
0.9419
0.9736
0.9464
0.9598
0.9640
0.9678
0.9659
MinGW-O2
0.6356
0.6345
0.6351
0.6123
0.7067
0.6561
0.7051
0.7541
0.7287
MinGW-O3
0.6363
0.6250
0.6306
0.6373
0.5674
0.6003
0.7715
0.6957
0.7316
Overall
0.7422
0.6979
0.7053
0.7869
0.7385
0.7357
0.8077
0.7806
0.7896
6.3
RQ3. How Eﬀective is BinAlign in Identifying the Joint Source
Compiler and Optimization Level of a Windows Binary?
Tables 10 and 11 show the performance of three compiler provenance models,
while predicting the joint source compiler and optimization level of the compiled
binaries with two and four levels of optimization, respectively. For the two-
level joint source compiler and optimization level inference as shown in Table 10,
our improved BinAlign performs the best on compiler provenance recovery of
MSVC and ICC compiled binaries with better inference on unoptimized binaries
as compared to the highly optimized ones.
Moreover, from the results we can see that the neural network models do not
perform perfectly well, while inferring the joint source compiler and optimization
level, speciﬁcally for MSVC and ICC compiled test binaries, at O2 optimization
level. This is because, one of the challenges for deep learning model is the highly
optimized code and the inter-procedural optimization in optimized binaries.
Furthermore, it is observed that neural network models perform relatively
better when the binaries are compiled with either unoptimized settings or with
the most-aggressive optimization settings using MSVC and ICC compilers. This
may be attributed to the fact that modern C/C++ compilers provide support
for advanced vector extension (AVX) architecture, which generates over-aligned
instructions, thus leading to improved performance (See Footnote 5). Also, our

BinAlign: Alignment Padding Based Compiler Provenance Recovery
625
test set instances comprise of instructions operating on ﬂoating point data, for
which the ICC compiler emits alignment padding in the form of DB bytes to align
the instructions and data for vector operations.
On the other hand, for unoptimized binaries, the improved BinAlign model
learns the alignment padding patterns comparatively well, as the instructions are
padded with DB 90 and DB 0CC in the .text section of the compiled binaries,
whereas DB 0 in the data sections, respectively. One of the signiﬁcant character-
istics of the deep learning CNN models is their higher performance and better
accuracy for the zero-padded data bytes [15]. Hence, from our evaluation results
of joint prediction of source compiler and optimization level, we conclude that
the improved BinAlign recovers the compiler provenance of Clangcl, and MSVC
compiled binaries with a relatively better score as compared to other compilers.
6.4
Malware Case Study
To illustrate the generality of our approach for compiler provenance inference
of real-world malware, we compile 113 C/C++ source code of Win32 malware
downloaded from theZoo13 repository. Since the malware source uses the core
Windows APIs which are incompatible with Clangcl, ICC and MinGW com-
pilers, we therefore compile the projects on three diﬀerent versions of MSVC
compiler, i.e., VS2015, VS2017 and VS2019, at four diﬀerent optimization lev-
els. Thus, we train our models on 64-bit benign programs and 32-bit malicious
programs and test the models on malicious binaries only. The benign programs
belong to the same set of programs as mentioned in Sect. 5, however for the
current evaluation we compile them with MSVC compiler and perform testing
with three diﬀerent versions of the MSVC compiler.
Tables 12 and 13 present the malware families and the distribution of our
malware dataset, respectively. In our dataset, we gather seven diﬀerent fami-
lies of malware programs in C/C++ language as shown in Table 12. The mal-
ware programs are then compiled with three versions of MSVC compiler in four
diﬀerent optimization settings as shown in Table 13, with the most successful
compilation in version 2019 that supports the most APIs. Table 14a shows the
overall classiﬁcation result of compiler version prediction and compiler optimiza-
tion prediction of our malware dataset. Hence, our results demonstrate that the
improved BinAlign outperforms other models in predicting the compiler version
of malware binaries. This is because adversaries may introduce binary padding to
add junk data in the code and change the on-disk representation of the binaries.
Here, we acknowledge that despite the obfuscation implemented in a smaller
set of malicious binaries as compared to a larger set of benign programs, our
improved model is able to predict compiler version and optimization level with
a promising score.
13 https://github.com/ytisf/theZoo.

626
M. Ismail et al.
Table 12. The number and types of bina-
ries belonging to diﬀerent families of mal-
ware.
Family
Malware Type
#bins
Dexter
Point of Sales Trojan
1
Rovnix
Bootkit
1
Carberp
Botnet
36
BJWJ
Banking Trojan
6
Anti Rapport Banking Trojan
11
Trochilus
Remote Access Trojan 40
ZeroAccess
Rootkit
18
Total
113
Table 13. The number of malware
binaries successfully compiled with
three
diﬀerent
versions
of
MSVC
compiler and at four diﬀerent opti-
mization levels.
Opt
VS2019 VS2017 VS2015 Total
Od
17
8
8
33
O1
13
5
5
23
O2
21
10
4
35
Ox
14
4
4
22
Total 65
27
21
113
Table 14. Compiler, version and optimization level inference of malware and custom
aligned binaries
(a) Compiler version and optimization level inference of malware binaries
Version
Opt
Metrics
o-glassesX
BinAlign
Improved BinAlign
o-glassesX
BinAlign
Improved BinAlign
P
0.8540
0.8713
0.9160
0.8718
0.8825
0.9287
R
0.8548
0.8729
0.9170
0.8740
0.8827
0.9295
F1
0.8542
0.8719
0.9162
0.8722
0.8822
0.9290
(b) Compiler and optimization level inference of custom-aligned binaries
Compiler
Opt
Metrics
o-glassesX
BinAlign
Improved BinAlign
o-glassesX
BinAlign
Improved BinAlign
P
0.7923
0.8280
0.8557
0.6892
0.7708
0.7950
R
0.7927
0.8294
0.8548
0.6729
0.7709
0.7920
F1
0.7925
0.8287
0.8552
0.6811
0.7709
0.7935
6.5
Custom Alignment Padding
Considering a scenario when software developers or malware authors intention-
ally modify the compiler’s default alignment settings, we conduct a case study
comprising the binaries that enforce custom alignment padding in the com-
piled binaries. For that, we perform an extensive study of the compiler options
that support aligning data within sections, structures, data packing and section
alignment. Hence, we found that MSVC (See Footnote 9), Clangcl and ICC
support four major alignment settings, deﬁned as, i) ALIGN, ii) FILEALIGN, iii)
Zc:alignedNew, and iv) Zp16. These options correspond to the section align-
ment in linear address space, alignment of sections to the output ﬁle, alignment
of dynamically-allocated data and the packing of structure member alignment,
respectively. On the other hand, MinGW compiler supports alignment of c++17
data standard, aligning data for functions, labels, jumps, and loops, respectively.
Here, the compiler options to achieve the respective alignment is -faligned-new,
-falign-functions, -falign-jumps, -falign-labels, and -falign-loops,

BinAlign: Alignment Padding Based Compiler Provenance Recovery
627
respectively [2]. Thus, we train the models with custom alignment of 8192 bytes
for all the alignment options discussed above.
Therefore, to evaluate our models on custom-aligned compiled binaries, we
train the compiler provenance models with, i) default alignment compiler set-
tings, and ii) custom-alignment padding on the same dataset as evaluated
in Sect. 6.1 to 6.3. We then test our trained models with custom-aligned binary
code to measure their evaluation performance. Therefore, we utilize 70% of our
total compiled data for training, while 30% of the custom-aligned binaries for
testing. Hence, our evaluation results show that the improved BinAlign infers
the source compiler and compiler optimization level of custom-aligned compiled
binaries with a fairly decent score as shown in Table 14b.
7
Limitation
We evaluate BinAlign only on the selected options of custom alignment padding
provided by the compiler. However, the alignment options in MinGW compiler
(for example) for aligning data in C++17 standard, functions, loops, jumps and
labels have a long range from 22 to 216. Hence, it would be interesting to assign
labels to the diﬀerently padded binary code with varying alignment padding set-
tings. We thus leave this as the future work. Additionally, this work can further
be extended to incorporate the architecture-speciﬁc alignment padding [2].
8
Conclusion
In this work, we evaluate the state-of-the-art compiler provenance recov-
ery model, o-glassesX and propose BinAlign that incorporates compiler-
optimization-speciﬁc domain knowledge into the existing model. Thus, by learn-
ing the alignment padding in the binary code, our model infers the source com-
piler and optimization level over a diverse set of real-world binaries including
64-bit benign and 32-bit malware binaries. We thus believe that newer patterns
of instructions for alignment padding may be explored to enhance the com-
piler provenance analysis. Moreover, this work can be extended to incorporate
additional ﬁller instructions to enhance the performance of compiler provenance
analysis in optimized binaries.
Finally, we sincerely thank the authors of o-glassesX (Otsubo et al.) for
providing us with the replication package along with the necessary guidance.
References
1. Microsoft
Visual
C++.
https://visualstudio.microsoft.com/vs/features/
cplusplus/. Accessed 23 Apr 2023
2. MinGW-w64 compiler (2023). https://www.mingw-w64.org/. Accessed 20 Apr
2023

628
M. Ismail et al.
3. Andriesse, D.: Practical Binary Analysis: Build Your Own Linux Tools for Binary
Instrumentation, Analysis, and Disassembly (2018). https://books.google.com.sg/
books?id=laWgswEACAAJ
4. Andriesse, D., Chen, X., van der Veen, V., Slowinska, A., Bos, H.: An in-depth
analysis of disassembly on full-scale x86/x64 binaries. In: 25th USENIX Security
Symposium (2016)
5. Benoit, T., Marion, J.Y., Bardin, S.: Binary level toolchain provenance identiﬁ-
cation with graph neural networks. In: 2021 IEEE International Conference on
Software Analysis, Evolution and Reengineering (SANER) (2021)
6. Chaki, S., Cohen, C., Gurﬁnkel, A.: Supervised learning for provenance-similarity
of binaries. In: Proceedings of the 17th ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining, pp. 15–23 (2011)
7. Cifuentes, C., Gough, K.J.: Decompilation of binary programs. Softw. Pract. Expe-
rience 25(7), 811–829 (1995)
8. Ding, S.H., Fung, B.C., Charland, P.: Asm2Vec: boosting static representation
robustness for binary clone search against code obfuscation and compiler opti-
mization. In: 2019 IEEE Symposium on Security and Privacy (SP), pp. 472–489.
IEEE (2019)
9. Eagle, C.: The IDA Pro Book: The Unoﬃcial Guide to the World’s Most Popular
Disassembler. No Starch Press, USA (2011)
10. Grune, D., Van Reeuwijk, K., Bal, H.E., Jacobs, C.J., Langendoen, K.: Modern
Compiler Design. Springer, Heidelberg (2012)
11. Ji, Y., Cui, L., Huang, H.H.: BugGraph: diﬀerentiating source-binary code simi-
larity with graph triplet-loss network, pp. 702–715. ACM, New York (2021)
12. Ji, Y., Cui, L., Huang, H.H.: Vestige: identifying binary code provenance for
vulnerability detection. In: Sako, K., Tippenhauer, N.O. (eds.) ACNS 2021. LNCS,
vol. 12727, pp. 287–310. Springer, Cham (2021). https://doi.org/10.1007/978-3-
030-78375-4 12
13. Kingma, D.P., Ba, J.: Adam: a method for stochastic optimization. arXiv preprint
arXiv:1412.6980 (2014)
14. Koo, H., Park, S., Choi, D., Kim, T.: Semantic-aware binary code representation
with BERT. arXiv preprint arXiv:2106.05478 (2021)
15. Krizhevsky, A., Sutskever, I., Hinton, G.E.: ImageNet classiﬁcation with deep con-
volutional neural networks. Commun. ACM 60(6), 84–90 (2017)
16. Kruegel, C., Kirda, E., Mutz, D., Robertson, W., Vigna, G.: Polymorphic worm
detection using structural information of executables. In: Valdes, A., Zamboni,
D. (eds.) RAID 2005. LNCS, vol. 3858, pp. 207–226. Springer, Heidelberg (2006).
https://doi.org/10.1007/11663812 11
17. Lin, Y., Gao, D.: When function signature recovery meets compiler optimization.
In: 2021 IEEE Symposium on Security and Privacy (SP), pp. 36–52. IEEE (2021)
18. Lin, Y., Gao, D., Lo, D.: Resil: revivifying function signature inference using deep
learning with domain-speciﬁc knowledge. In: Proceedings of the Twelfth ACM
Conference on Data and Application Security and Privacy, pp. 107–118 (2022)
19. Lopes, B.C., Auler, R.: LLVM: Building a Modern Compiler Infrastructure (2020)
20. Massarelli, L., Di Luna, G.A., Petroni, F., Querzoni, L., Baldoni, R.: Investigating
graph embedding neural networks with unsupervised features extraction for binary
analysis. In: Proceedings of the 2nd Workshop on Binary Analysis Research (BAR)
(2019)
21. Massarelli, L., Di Luna, G.A., Petroni, F., Baldoni, R., Querzoni, L.: SAFE: self-
attentive function embeddings for binary similarity. In: Perdisci, R., Maurice, C.,

BinAlign: Alignment Padding Based Compiler Provenance Recovery
629
Giacinto, G., Almgren, M. (eds.) DIMVA 2019. LNCS, vol. 11543, pp. 309–329.
Springer, Cham (2019). https://doi.org/10.1007/978-3-030-22038-9 15
22. Mitchell, M., Oldham, J., Samuel, A.: Advanced Linux Programming. New Riders,
Berkeley (2001)
23. Muchnick, S., et al.: Advanced Compiler Design Implementation. Morgan Kauf-
mann (1997)
24. Otsubo, Y., Otsuka, A., Mimura, M., Sakaki, T.: o-glasses: visualizing x86 code
from binary using a 1D-CNN. IEEE Access 8, 31753–31763 (2020)
25. Otsubo, Y., Otsuka, A., Mimura, M., Sakaki, T., Ukegawa, H.: o-glassesx: compiler
provenance recovery with attention mechanism from a short code fragment. In:
Proceedings of the 3rd Workshop on Binary Analysis Research (2020)
26. Pizzolotto, D., Inoue, K.: Identifying compiler and optimization options from
binary code using deep learning approaches. In: 2020 IEEE International Con-
ference on Software Maintenance and Evolution (ICSME) (2020)
27. Rahimian, A., Nouh, L., Mouheb, D., Huang, H.: Binary code ﬁngerprinting for
cybersecurity
28. Rahimian, A., Shirani, P., Alrbaee, S., Wang, L., Debbabi, M.: Bincomp: A strat-
iﬁed approach to compiler provenance attribution. In: Digital Investigation, the
Proceedings of the Fifteenth Annual DFRWS Conference (2015)
29. Ramshaw, M.J.: Establishing malware attribution and binary provenance using
multicompilation techniques (2017). https://www.osti.gov/biblio/1390004
30. Rosenblum, N., Miller, B.P., Zhu, X.: Recovering the toolchain provenance of
binary code. In: Proceedings of the 2011 International Symposium on Software
Testing and Analysis, ISSTA 2011 (2011)
31. Rosenblum, N.E., Miller, B.P., Zhu, X.: Extracting compiler provenance from pro-
gram binaries. In: Proceedings of the 9th ACM SIGPLAN-SIGSOFT Workshop
on Program Analysis for Software Tools and Engineering, PASTE 2010 (2010)
32. Rosenblum, N.E., Zhu, X., Miller, B.P., Hunt, K.: Learning to analyze binary
computer code. In: AAAI, pp. 798–804 (2008)
33. Shirani, P., Wang, L., Debbabi, M.: Binshape: scalable and robust binary library
function identiﬁcation using function shape. In: Detection of Intrusions and Mal-
ware, and Vulnerability Assessment (2017)
34. Tian, Z., Huang, Y., Xie, B., Chen, Y., Chen, L., Wu, D.: Fine-grained compiler
identiﬁcation with sequence-oriented neural modeling. IEEE Access 9, 49160–49175
(2021)
35. TIS Committee: Executable and Linking Format (ELF) Speciﬁcation (1995).
https://refspecs.linuxfoundation/elf/elf.pdf
36. Wang, R., et al.: RAMBLR: making reassembly great again. In: NDSS (2017)
37. Wang, S., Wang, P., Wu, D.: Reassembleable disassembling. In: 24th USENIX
Security Symposium, Washington D.C., pp. 627–642 (2015)
38. Xu, X., Liu, C., Feng, Q., Yin, H., Song, L., Song, D.: Neural network-based graph
embedding for cross-platform binary code similarity detection. In: Proceedings of
the 2017 ACM SIGSAC, pp. 363–376 (2017)
39. Xue, H., Sun, S., Venkataramani, G., Lan, T.: Machine learning-based analysis of
program binaries: a comprehensive study. IEEE Access 7, 65889–65912 (2019)
40. Yang, S., Shi, Z., Zhang, G., Li, M., Ma, Y., Sun, L.: Understand code style: eﬃcient
CNN-based compiler optimization recognition system. In: 2019 IEEE International
Conference on Communications (ICC), ICC 2019 (2019)
41. Zou, F., Shen, L., Jie, Z., Zhang, W., Liu, W.: A suﬃcient condition for conver-
gences of Adam and RMSProp. In: Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, pp. 11127–11135 (2019)

Encrypted Network Traﬃc Classiﬁcation
with Higher Order Graph Neural
Network
Zulu Okonkwo(B), Ernest Foo, Zhe Hou, Qinyi Li, and Zahra Jadidi
Griﬃth University, Gold Cost, Australia
{z.okonkwo,e.foo,z.hou,qinyi.li,z.jadidi}@griffith.edu.au
Abstract. Encryption protects internet users’ data security and pri-
vacy but makes network traﬃc classiﬁcation a much harder problem.
Network traﬃc classiﬁcation is essential for identifying and predicting
user behaviour which is important for the overall task of network man-
agement. Deep learning methods used to tackle this problem have pro-
duced promising results. However, the conditions on which these exper-
iments are carried out raise questions about their eﬀectiveness when
applied in the real world. We tackle this problem by modelling net-
work traﬃc as graphs and applying deep learning for classiﬁcation. We
design a graph classiﬁer based on higher order graph neural network
with the aim of optimum generalisation. To demonstrate the robustness
of our model, we cross validate it on the ISCXVPN and USTC-TFC
datasets with varying input speciﬁcations. We use our model to demon-
strate the impact of network data truncation on traﬃc classiﬁcation
and deﬁne benchmarks for input speciﬁcations. Our best results outper-
form the state-of-the-art in terms of generalisation strength. Our tool is
available online (https://github.com/zuluokonkwo/Encrypted-Network-
Traﬃc-Classiﬁcation-with-Higher-Order-Graph-Neural-Network).
Keywords: Graph Neural Network · Encrypted Network Traﬃc ·
Classiﬁcation · Network Security · Deep Learning
1
Introduction
In the design of network security systems, the core aim is an accurate clas-
siﬁcation of network traﬃc by the security apparatus [2]. Traditional network
security involves combining various layers of security in a defence-in-depth app-
roach. Each layer plays a role with the overall aim of controlling what data enters
or exits the network. Encryption aids security by strengthening privacy amongst
communicating channels, leading to its wide adoption across the internet. Over
94% of Google’s traﬃc now runs over TLS or SSL [3]. While improving privacy
over the internet, encryption has created new attack surfaces for bad actors to
traverse unnoticed in and out of networks. Due to the sophisticated nature of
encryption algorithms, security systems struggle to accurately classify network
traﬃc. Recently, a new wave of encrypted attacks has spread across the internet,
c
⃝The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 630–650, 2023.
https://doi.org/10.1007/978-3-031-35486-1_27

Encrypted Network Traﬃc Classiﬁcation with Graph Neural Network
631
with the rise of cyber physical systems(CPS) and internet of things (IoT) cyber
threats over encrypted channels saw a 132% increase in 2022, and malware over
HTTPS continues to rise [1].
Machine learning (ML) and Deep Learning (DL) based methods have experi-
enced huge success in the overall task of network traﬃc classiﬁcation. However,
their results are questionable because of underlining issues. State-of-the-art ML
based classiﬁers [2,4–6] have more emphasis on the model design stage while
testing on a small set of data and not paying much attention to the data process-
ing/feature extraction stage. This process yields good but questionable results
as the generalisation capability of the model isn’t guaranteed. State-of-the-art
Graph neural networks (GNN) based designs [15,22] are built with low-order
GNNs. This method utilises node locality for classiﬁcation tasks, not taking
advantage of higher-order information that has proven to preserve structural
embeddings necessary for graph classiﬁcation.
The imbalanced nature of network traﬃc datasets is a concern for ML/DL
based classiﬁers; training with imbalanced data directly impacts a model’s per-
formance. Results produced with such datasets are biased towards the majority
classes. State-of-the-art classiﬁers [4–6] utilised imbalanced datasets for their
training process not clearly stating how this issue is contained. DL/ML classi-
ﬁers deal with a lot of parameters that increase during model training to enable
the network generalise optimally. An increase in parameters also accounts for an
increased tendency of an over-ﬁtting model. State-of-the-art classiﬁers [4–6,22]
use dropout to deal with this tendency. Research by Garbin et al. [8] advised
that dropouts be used with caution and when in doubt batch normalisation be
used instead. Garbin et al. [8] also advised that dropouts be used with diﬀerent
rates to ﬁnd the optimum spot which yields the best accuracy. Cross-validating
and training a model across a range of datasets is a way to show a model is
not overﬁtting. Network traﬃc is dynamic and varies in size. The number and
sizes of packets in a traﬃc session vary for diﬀerent applications. For ML/DL
classiﬁcation approaches, deﬁning input speciﬁcations is a requirement for mod-
els. Therefore, deﬁning input sizes that yield the best results when variable-size
inputs cannot be used is important. State-of-the-art classiﬁers [4,6] truncate net-
work input during training. A trade-oﬀof such should be backed with a clear
explanation or leverage DL methods that can perform computation on variable-
sized inputs.
In this paper, we design an encrypted traﬃc classiﬁer based on a higher-
order graph neural network. Our design is based on a GNN blueprint by Morris
et al. [21] that preserves structural information necessary for graph classiﬁca-
tion. We test our model on two datasets with diﬀerent input speciﬁcations to
investigate which is optimum for the task of encrypted traﬃc classiﬁcation. Our
model can be applied to the network layer of CPS, IoT and smart critical infras-
tructures to identify traﬃc that pose risks to the systems. In our training phase,
we implement a weighted random sampler that ensures every class is well rep-
resented, making our model unbiased towards any class. We perform stratiﬁed
cross validation across our dataset with a fold of 5 to ensure our results are

632
Z. Okonkwo et al.
as realistic as possible. Our model demonstrated better generalisation strength
when compared to state-of-the-art that used the same dataset. Our best results
for the VPN-dataset are above 97% across all evaluation metrics which is bet-
ter than the compared literature. For the non-VPN dataset our best results are
above 87% for all evaluation metrics. For the Benign and Malware classes of the
USTC-TFC dataset, we achieve well over 95% for all evaluation metrics. Our
contributions can be itemized as follows:
– Development of a higher order GNN-based model that can identify and clas-
sify encrypted network traﬃc with optimum generalisation strength.
– Improved the feature extraction process for encrypted traﬃc to better repre-
sent and show relationship of traﬃc ﬂows.
– Evaluate the impacts of data truncation and padding for encrypted network
traﬃc classiﬁcation at the data-link layer (L2) and sessions layer (L5).
The rest of this paper is structured as follows: In Sect. 2, we introduce the
preliminaries that lay foundations to our data processing and model design. In
Sect. 3, we introduce our GNN-based classiﬁer and deﬁne the data processing
methodology. In Sect. 4, we evaluate our model on the ISCXVPN and USTC-
TFC datasets. We also discuss the results gotten from our experiments and
conduct a comparative analysis with state-of-the-art models. In Sect. 5, we high-
light some related papers and discuss gaps which our paper addressed. In Sect. 6,
we conclude the work and highlight future directions.
2
Preliminaries
The advancements in neural networks for tasks like pattern recognition, image
classiﬁcation, and predictive analytics have made them valuable tools for
researchers in tackling complex issues. They excel in uncovering hidden pat-
terns in data that can be plotted on a plane but struggle with non-euclidean
data [9]. This has led to the development of Geometric Deep Learning to better
handle such data. Graphs, which are non-euclidean representations of entities
and their relationships, can eﬀectively show connections between two or more
elements. They are versatile, as they can be used to model anything, and are
particularly useful for modelling non-euclidean network data, which contains
a wealth of information. To fully harness its potential, it must be represented
formally.
2.1
Graph Neural Network
A simple graph G consists of a non-empty ﬁnite set V (G) of elements called
nodes (or vertices), and a ﬁnite set E(G) of distinct unordered pairs of distinct
elements of V (G) called edges. Mathematically, a graph G is deﬁned by Eq. 1 as:
G = V E,
(1)
where V is the vertex set and E is the edge set. For example, a visual rep-
resentation of a graph G, with vertex set V (G) = {a, b, c, d} and edge set
E(G) = {ab, ac, bc, cd} is shown in Fig. 1.

Encrypted Network Traﬃc Classiﬁcation with Graph Neural Network
633
Fig. 1. An example graph.
In Fig. 1, we assume every vertex possesses a
feature that deﬁnes itself called vertex or node
attributes. Graph neural network (GNN) falls under
the branch of geometric deep learning, a type
of deep learning for emerging methods aiming to
generalise deep learning models to non-euclidean
domains mainly graphs and manifolds [9]. Early GNN methods were generated
with the main goal of constructing a generalisation of CNN architecture on non-
euclidean domains. In neural networks, activations are received from preceding
layers in order to propagate features to succeeding layers. This is deﬁned in Eq. 2
as:
H[l+1] = σ(W [l]H[l] + b[l]),
(2)
where H[l+1] is the feature representation at layer [l+1], σ is a non-linear activa-
tion function, W [l] is the weight at the lth layer, H[l] is the feature representation
at the lth layer and b[l] is the bias at the lth layer. Kipf et al. [10] deﬁned a Graph
Convolution Network (GCN) propagation rule by taking into consideration the
adjacency matrix. The adjacency matrix in graph theory shows how nodes are
connected to each other. This helps nodes learn information about their neigh-
bours during forward propagation. The adjacency matrix forward propagation
can be deﬁned in Eq. 3 as (we eliminate the bias b for simplicity):
H[l+1] = σ(W [l]H[l]A∗).
(3)
H[norm] = D−1AH.
(4)
H[norm] = D−1 ˜AH.
(4a)
H[norm] = D−1
2 ˜AD−1
2 H.
(4b)
H(l+1) = σ( ˜D−1
2 ˜A ˜D−1
2 HlW l).
(5)
The A∗in Eq. 3 represents the normalised adjacency matrix, normalisation pre-
vents numerical instabilities like vanishing and exploding gradients. Matrix nor-
malisation is the dot product of the inverse of the degree matrix, D−1 with
the adjacency matrix, A and the node features H as shown in Eq. 4. By imple-
menting a self-loop, a node takes into account its own feature during forward
propagation. Setting the diagonal elements of an adjacency matrix to 1 imple-
ments self-loops, ˜A represents the reﬁned adjacency matrix in Eq. 4a. Due to
varying node degrees, higher degrees nodes tend to dominate. Kipf et al. [10]
suggest symmetric normalisation to reduce this dominance in Eq. 4b. After nor-
malizing A with its degree matrix and enforcing self-loop by adding the identity
matrix. We get the ﬁnal equation for forward propagation in GCN as Eq. 5, σ
represents a nonlinear activation function like ReLU or Tanh used during neural
network computation.
GNN’s evaluation and analysis have been more empirical than theoretical,
making the entire process seem like a black box. Morris et al. [21] tried to give

634
Z. Okonkwo et al.
clarity to this issue by relating GNN operations to the Weisfeiler-Leman graph
isomorphism heuristic (1-WL). They show that GNNs possess the same expres-
siveness as the 1-WL in terms of distinguishing non-isomorphic graphs. Meaning
that both algorithms have the same imperfections. They propose a higher-order
generalisation of GNNs called k-GNNs which can capture structural information
not visible at the node level. In k-GNNs, messaging passing is between sub-graph
structures rather than just nodes. Let V (G)a be a sub-graph of V (G) and b be
a set of nodes in V (G)a. The neighbourhood of b is deﬁned below.
N(b) = {t ⊂[V (G)]a s.t. |b ∩t |= a −1} ,
(6)
Basically, the local neighbourhood NL(b) consists of all elements in the set t ⊂
N(b) such that (v, w) ∈E(G) for unique v ∈b\t and unique w ∈t\b. The local
propagation formula of feature vectors for layer ℓ> 0 becomes:
f (ℓ)
a, L(s) = σ
⎛
⎝f (ℓ−1)
a, L (s) · W (t)
1
+

u∈NL(s)
f (ℓ−1)
a, L (u) · W (ℓ)
2
⎞
⎠,
(7)
where f (ℓ−1)
a, L (s) represents the feature vector of the set of nodes s at layer
t −1. The aggregation of the local neighbourhood set of s represented by u
is [
u∈NL(s) f (ℓ−1)
a, L (u)]. For simplicity, Eq. 7 is denoted as:
x′
i = W1xi + W2

j∈N(i)
ej,i · xj,
(8)
where W1 and W2 are trainable weight parameters of the GNN, Xi signiﬁes
the feature vectors of set of nodes i. 
j∈N(i) denotes the aggregation of the
local neighbourhoods of i denoted by j. The edge weight of the local neighbour
is denoted by ej,i and xj signiﬁes the feature vector of the neighbours. A non-
linear function such as ReLU is utilised during computation.
2.2
Pooling
Pooling is popular for dimensionality reduction in convolutional-based systems.
In this process, the dimension of the feature map is reduced while retaining useful
information and eliminating irrelevant information from the input data. Pooling
reduces the complexity of upper layers and simpliﬁes computation by reducing
the weight parameters. It also controls over-ﬁtting to a reasonable extent.
Global Mean Pooling.
This method of pooling was introduced by Yann
LeCun [11]. It returns batch-wise graph-level-outputs by averaging node fea-
tures across the node dimension. The output for a single graph Gi is computed
by:
ri = 1
Ni
Ni

n=1
xn
(9)

Encrypted Network Traﬃc Classiﬁcation with Graph Neural Network
635
Fig. 2. Condensed graph after top-K pooling. Nodes are dropped after every pooling
layer making neighbourhood computation for generating graph embedding easier.
Global Max Pooling. The max pooling [12] method simply passes to the next
layer the maximum value within a group of R activations. It returns batch-
wise graph-level-outputs by taking the channel-wise maximum across the node
dimension. The output for a single graph Gi is computed by:
ri =
Ni
max
n=1 xn
(10)
For Eqs. 9 and 10, x represents the node feature matrix.
Top-k Pooling. This is a sort-based method for dimensionality reduction. A pro-
jection vector [13] is used to score nodes and only nodes with TopK scores along
with related edges are retained. This is an important part of our model design as
we perform TopK pooling at every layer to get the optimum embedding for net-
work graph classiﬁcation. Assuming we have a graph G with vertex set V (G) =
{a, b, c, d, e, f, g, h, i, j} and edge set E(G) = {ab, bc, cd, de, ef, fg, gh, hi, ij}, we
also assume G is undirected. A visual representation of G is shown in Fig. 2. Sup-
pose we want to train a NN model to get optimum embedding that best deﬁnes
graphs similar to G. Applying top-K pooling will cause our graph to drop some
nodes, as demonstrated in Fig. 2.
It is crucial to note that the nodes carried forward are mathematically and
not arbitrarily determined. A measure of how much information is retained after
node feature vectors xi are projected in the direction of the vector p determines
which nodes are dropped and preserved.
3
Proposed Model
In this section, we ﬁrst describe the process used in generating our network traﬃc
graphs then deﬁne the model used for classiﬁcation.

636
Z. Okonkwo et al.
3.1
Data Processing
Traﬃc sessions show bidirectional ﬂows of communication between two or more
parties; this makes it a better way of describing packet relationships for classiﬁca-
tion. Wang et al. demonstrated this [4]. Network communications are processed
as packet capture ﬁles (pcap or pcapng) for analysis. After collecting packet
capture ﬁles, we split them into sessions with an open-source tool called split-
Cap. Packet capture ﬁles with pcapng extension are converted to “.pcap” ﬁles
before splitting occurs. An open-source tool “LibCap” is used to achieve this.
The next phase deals with the removal of unwanted information. Network traf-
ﬁc data is collected at the data-link layer that carries information about their
physical interfaces. Information contained in the Ethernet header is stripped oﬀ
as it is not useful for classiﬁcation and can be spoofed by attackers. Network
or ﬂow data like IP addresses and port numbers are not used as features. This
restriction forces the model to utilise only the encrypted traﬃc for classiﬁcation.
At the network layer, the source and destination IP addresses of every packet
are masked as they can inﬂuence the learning process of the model and can also
be easily manipulated by bad actors. At the transport layer, TCP and UDP are
used. Since these protocols have diﬀerent connection orientations with diﬀerent
header sizes (TCP = 20 and UDP = 8), we pad UDP headers with zeros to match
TCP. Since our main aim is to classify encrypted traﬃc we limit our features
to information that can’t be easily manipulated. Pcap ﬁles are then converted
to their raw byte format. The maximum transmission unit (MTU) of a packet
is 1500 bytes, to maximize information, we extract all packet info and convert
it to raw bytes. Where a packet is not up to the MTU, padding is applied. By
doing this, every packet has a length of 1500. Next, we normalise every byte to
fall within the range of 0–1 by converting every byte to decimal and dividing by
255. Although we conduct tests with diﬀerent MTU and session sizes, this initial
data processing method is the basis for our experiment.
3.2
Model Description
Graph Data Extraction and Creation. The next phase deals with deﬁning
and extracting graph information from the pre-processed ﬁles. Since network
traﬃc is collected over time, it can be represented as time series information.
Traﬃc sessions are also represented as a back-and-forth exchange over time.
Pang et al. [14] generated chained graph structures to represent traﬃc sessions.
Each packet in a session is modelled as a node or vertex, and the edge shows
the chronological (time) relationship between packets. Peng et al. [20] conducted
experiments to ﬁnd the number of packets most eﬀective for traﬃc identiﬁca-
tion. Their experiment [20] showed the ﬁrst ﬁve-to-seven packets are optimal for
classiﬁcation. We extend this number to ten and extract the ﬁrst ten packets
per session, we choose ten to ensure suﬃcient exchange of encrypted application
data after the completion of the TLS handshake process which is usually three
round trips making six packets in Wireshark. A session with ten packets will
be modelled as a graph with ten nodes, the edges are bidirectionally connected

Encrypted Network Traﬃc Classiﬁcation with Graph Neural Network
637
Fig. 3. Graph representation of traﬃc session
to their adjacent preceding and succeeding nodes. The entire session is labelled
with the application traﬃc it conveys. Figure 3 demonstrates the structure of
our traﬃc session graph; our network traﬃc can be represented mathematically
as a path graph. To create network graphs, we extract the following information
from the pre-processed pcap ﬁles. The extracted information is classiﬁed into
four ﬁles, each ﬁle consisting of mappings as follows:
Node attributes ﬁle: Node information is extracted from the packet, and
every node is mapped to its attribute which has an initial feature length of
1500. Nodes represent packets and attributes are packet contents (raw byte).
Edge ﬁle: The edge information shows the relationship between nodes in a
graph. In the edge ﬁle, source nodes are mapped to destination nodes. This
preserves the chronological relationship of traﬃc sessions.
Graph to Label ﬁle: After assigning labels to sessions, we extract this mapping
of sessions (graphs) and their corresponding class label.
Node to Graph ﬁle: As packets belong to particular sessions, we extract this
mapping of packets (nodes) and sessions (graphs).
The ﬁles are used to create labelled graphs, every graph has nodes with attributes
(raw byte) and time series relationships represented by edges.
Architecture. Our architecture as described in Fig. 4, consists of two major
parts, the learner and the categorizer. The learner consists of ﬁve sub-layers, each
sub-layer comprising of a GraphConv or k−GNN layer as described by Morris
et al., in [21], not be confused with the Graph Convolution layer deﬁned by Kipf
et al., in [10]. For simplicity, we refer to the k−GNN as GraphConv for the rest
of this literature. The next layer is a batch normalisation layer followed by a
top-K pooling layer. The aim of the learner is to produce optimum embedding
used for classiﬁcation.
GraphConv [21] is based on a localised higher-order approximation of the
Weisfeiler-Leman graph isomorphism heuristic with the propagation rule deﬁned
in Eq. 8. This is in contrast to the basic convolutional ﬁlter which allows weight
sharing (by means of a ﬁlter with a ﬁxed kernel size sliding over an input).
Convolution in spatial domains recognises similar features irrespective of their

638
Z. Okonkwo et al.
Fig. 4. Proposed encrypted network traﬃc classiﬁer. Our model consists of two major
parts that work independently. The learner, which focuses on generating graph embed-
dings, and the categorizer which classiﬁes the embedding to its label. The learner con-
sists of ﬁve sub-layers, each sub-layer with three internal layers (a GraphConv, batch
normalisation and top-k polling layer). The graphconv layer leverages sub-graphs rather
than nodes information to perform computation, thereby utilising higher order details
of graphs capable of preserving structural info. The number 128 above the internal
layers signiﬁes its input and output channel size. The input and output channel sizes
remain the same for all sub-layers to deal with the issue of information loss. It is
important to note that the input graph reduces in size after every sub-layer, the top-K
pooling layer makes this possible. Every sub-layer produces an output which is the
concatenated form of its global mean pool and global max pool values, GMP⊕GAP.
The ﬁve sub-layers produce ﬁve embeddings which are concatenated and fed to the
categorizer. The symbol ⊕between the learner and categorizer signiﬁes the concatena-
tion function. The number behind and in front of the categorizer’s dense layer signiﬁes
its input and output channel size. The categorizer takes the concatenated embedding
from the learner, passes it through a series of dense layers and ﬁnally classiﬁes it. The
ﬁnal layer is a softmax classiﬁer which assigns a label to the input graph.
spatial location. Graphs on the other hand do not have a deﬁned spatial concept.
Hence, Kipf et al. [10] utilises spectral graph convolution to lay the mathemati-
cal foundation for propagation. Although graph convolution works optimally for
node classiﬁcation, we utilise its potency for the entire graph classiﬁcation. The
model accepts graphs of dimensions n × m, the ﬁrst GraphConv layer maps
the input feature to an output channel of 128 neurons. The selection of this

Encrypted Network Traﬃc Classiﬁcation with Graph Neural Network
639
neuron size is based on ease of computation and experiments carried out dur-
ing this work, literature like [14,15] also use similar sizes. Every GraphConv
layer contains 128 neurons. We keep this number constant for all sub-layers in
our learner because we extract optimal graph embedding after every sub-layer,
since we implement another layer for dimensionality reduction, generating proper
embedding becomes key. During our experiments, we realise that a reduction
in feature length negatively impacts classiﬁcation accuracy, a phenomena that
occurs in all conducted experiments. This shows that constant reduction of the
input and output channel during the learning stage will also impact accuracy. To
deal with this issue of loss of information we keep the channel sizes constant and
implement dimensionality reduction with a top-K pooling layer. This way, node
features deﬁning the graphs are well represented before pooling. The non-linear
function used is the Rectiﬁed Linear Unit (ReLU).
Following the GraphConv is the batch normalisation (BN) layer. Normal-
isation is an important aspect of our whole process and it is implemented at
the data processing and model training level. We introduce this layer to deal
with the internal covariate shift. BN layers standardise the mean and variance
of each unit in order to stabilise learning, making the gradients more predictive
and increasing convergence time. We utilise BN to achieve a stable distribution
of activation values during the training process, hence, it is introduced after the
non-linearity. BN layers have also been proven to reduce over-ﬁtting in convolu-
tional NN. Garbin et al. [8] in an experiment found BN layers a better choice to
improve accuracy and advised BN layers to be considered as an initial means to
deal with over-ﬁtting before other methods.
The next layer is the top-K pooling layer, as described in Sect. 2.2 the aim of
this layer is overall dimensionality reduction of graphs. We employ this method
because of the irregular sizes of network packets per session, during data process-
ing we noticed some sessions with over 50 packets. Similar to pooling in CNN,
top-K pooling reduces the number of nodes in the input graph every time it is
used. The nature of our graphs demands a way to optimise feature propagation
for ease of computation. Hence, we apply a top-K pooling layer to make our
model robust. We still perform more experiments with the truncated network
sessions for impact analysis. The Top-K pooling layer uses a trainable projection
vector [13] to select top-K nodes for the next layer. Dimensionality reduction is
also implemented to deal with over-smoothness in our model. Over-smoothing is
a phenomenon where GNN performance gradually reduces with increasing lay-
ers, this occurs when node embedding becomes similar the GNN does not seem
to learn anything new. Sadowski et al. [16] demonstrated how dimensionality
reduction alleviates this issue.
To get embeddings for graph classiﬁcation, we compute the global mean
pooling and global max pooling after every sub-layer. This embedding is con-
catenated for every sub-layer of the learner, we end up with ﬁve embeddings,
one per sub-layer of our learner. The ﬁve embeddings are concatenated and fed
to the categorizer.

640
Z. Okonkwo et al.
The categorizer consists of two sub-layers and a softmax classiﬁer. The cat-
egorizer can be seen as a simple feed-forward NN with three linear or dense
layers. The concatenated embeddings from the learner are fed to the catego-
rizer which then predicts the label of the graph based on learned parameters.
Since the output of the learner is of dimension 2 × 128, the ﬁrst sub-layer of
the categorizer has an input channel of 256 and an output channel of 128. We
introduce a dropout layer with a probability of 0.5 to tackle over-ﬁtting. The
second sub-layer has an input channel of 128 and an output channel of 64, we
also implement a dropout layer with the same probability here. The ﬁnal layer
has an input channel of 64 and an output channel equal to the total number of
labels. Each with a probability that deﬁnes how well a graph ﬁts the label, this
is achieved with a softmax classiﬁer.
4
Evaluation
To validate the robustness of our model, we subject it to a series of tests with a
range of datasets. The evaluation process is divided into four sections as follows.
The dataset, here we give an in-depth description of the dataset and why we
choose it for evaluation. In the experimental methodology section, we explicitly
deﬁne the processes and types of experiments conducted, the parameters with
respect to the model training and testing phase are also deﬁned. In Sect. 4.3
we discuss the results of our experiments and ﬁnally compare our results with
state-of-the-art.
4.1
Datasets
The VPN-nonVPN dataset (ISCXVPN2016) [17] captures real traﬃc of users
Alice and Bob created to use services (applications) described in Table 1. Seven
traﬃc classes are captured for VPN and non-VPN (at the time of dataset col-
lection the P2P class of the non-VPN traﬃc was removed from the repository).
The VPN-nonVPN dataset [17] is one of the most popular datasets for encrypted
traﬃc classiﬁcation tasks, making it suitable for comparative analysis. Reviewed
Table 1. VPN-nonVPN Dataset Summary
Traﬃc
Content
Web Browsing Firefox and Chrome
Email
SMPTS, POP3S and IMAPS
Chat
ICQ, AIM, Skype, Gmailchat, Facebook and Hangouts
Streaming
Vimeo, Youtube and Spotify
File Transfer
Skype, FTPS and SFTP
VoIP
Facebook, Skype and Hangouts voice calls
P2P
Vimeo, Youtube and Spotify

Encrypted Network Traﬃc Classiﬁcation with Graph Neural Network
641
Table 2. USTC-TFC2016 Dataset Summary
Traﬃc
Content
Benign
BitTorrent, Facetime, FTP, Gmail, MySQL, Outlook, Skype,
SMB, Weibo, WorldOfWarcraft
Malware Cridex, Geodo, Htbot, Miuref, Neris, Nsis-ay, Shifu, Tinba,
Virut, Zeus
literature like [4,15] utilised this dataset for their analysis. The dataset is in
.pcap and .pcapng format and 28 GB in size.
The USTC-TFC2016 dataset [18] consists of two parts, the malware class and
benign class. The malware class consists of ten types of malware traﬃc collected
from public websites in a real network environment. The benign class consists
of ten types of normal traﬃc collected using a professional traﬃc simulation
equipment. This dataset is popular for traﬃc classiﬁcation tasks and suitable
for comparative analysis. The dataset is in pcap format and 3.71GB in size.
Table 2 gives a summary of the USTC-TFC2016 dataset.
4.2
Experimental Methodology
To explicitly demonstrate our contribution and prove the robustness of our
model, we conduct experiments using the datasets deﬁned in Sect. 4.1. The
VPN-nonVPN dataset is split so separate experiments are carried out on the
VPN traﬃc and NonVPN traﬃc. For the USTC-TFC dataset, separate exper-
iments are conducted on the benign and malware traﬃc respectively. Network
graphs are created from traﬃc sessions. The traﬃc session distribution for the
VPN non-VPN dataset is described in Table 3. Real-world datasets are naturally
imbalanced, and classiﬁers have to incorporate augmentation techniques during
training. The USTC-TFC dataset has an abundance of samples, so we extracted
2000 sessions per application.
The diﬀerent input parameter sizes for our experiments are deﬁned in Table 4.
For every input parameter, we process the datasets as required and conduct
experiments. For the ﬁrst experiment, we truncate at the sessions layer, making
every session and resulting graph have a ﬁxed number of packets (nodes). For
the second experiment, truncation isn’t applied, the number of nodes per graph
varies as packets per session vary. For experiment three, we truncate the data-
link and session layer. We slash the packet size by almost half the MTU, ending
Table 3. VPN-nonVPN dataset sessions sample distribution
Class
Chat Email File
P2P Stream VoIP
VPN
4029
298
1020 477
659
11985
non-VPN 6523
7312
276
–
445
1781

642
Z. Okonkwo et al.
Table 4. Input Graph Speciﬁcations
Experiment Nodes per graph
Node attribute size
1
10 nodes (ﬁxed)
1500
2
Variable (not ﬁxed) 1500
3
10 nodes (ﬁxed)
784
4
Variable (not ﬁxed) 784
up with 784 bytes per packet and also keeping the sessions ﬁxed at 10 packets
per session. The choice of 784 is motivated by literature that utilise images
from network traﬃc [6,19] to address the classiﬁcation problem. Zou et al. [6]
proved that network images of size 784 bytes are eﬀective for traﬃc classiﬁcation,
and are more lightweight than 1500 bytes. Wang et al. [19] generated network
traﬃc images and used only the ﬁrst 784 bytes to get ﬁxed sized input for
their CNN model. For experiment four, truncation is applied only at the data-
link layer with packet sizes slashed down to 784 bytes.The ﬁrst experiment lays
the foundation for comparative analysis while demonstrating the generalisation
strength of our model. Other experiments are conducted for impact analysis of
variable length input (data truncation) on encrypted network traﬃc classiﬁcation
and to demonstrate the model generalisation strength.
Training Speciﬁcation. The following speciﬁcations are used for developing,
training and testing. The PyTorch geometric library with a python 3.9.13 back-
end is used to generate the graphs, build, train and test our model. The hardware
speciﬁcation is a Linux dell 5.15.0-56-generic server, the processor is a 12th Gen
Intel(R) Core(TM) i9-12900, 125 GB of physical RAM and a NVIDIA RTX
A4000 GPU.
During the training process, weighted random sampling is implemented to
deal with the imbalanced nature of the VPN Non-VPN dataset. Weighted ran-
dom sampling ensures minority classes are properly represented during the train-
ing process. For all experiments, we split our datasets into two, 80% for training
and 20% for testing. The hyper-parameters of the model are as follows: batch
size is 256, the number of epochs is 500 for regular training and 200 during cross
validation. The Adam optimizer is used to improve the categorical cross-entropy
loss function with a learning rate of 0.0003, and the decay rate is 0.00001. We
used the same training speciﬁcations for all experiments. We evaluate our model
using the four standard classiﬁcation metrics namely, Precision, Recall, f1Score
and Accuracy.
Test for Over-Fitting. The increase in parameters during training can cause neu-
ral networks to adapt so much to a particular data that it performs poorly when
unseen data is introduced. Ensuring a model does not overﬁt is a crucial aspect
of neural network training. To demonstrate the generalisation of our model, we

Encrypted Network Traﬃc Classiﬁcation with Graph Neural Network
643
subject it to a cross-validation test. For this test, we perform stratiﬁed cross-
validation on our model with the dataset. Our choice of stratiﬁed cross-validation
is motivated by the imbalanced nature of the dataset, and we need to ensure
that classes are well represented during training. We use the same training spec-
iﬁcation as Sect. 4.2 with few modiﬁcations. We split the data set into 5 folds
and reduce the epoch to 200 to limit the tendency of the model adapting to the
training data.
4.3
Results
A total of 12 experiments are conducted with our model on two datasets. Four
experiments on the VPN and four on the non-VPN traﬃc of the ISCXVPN
dataset. Two experiments on the benign and two on the malware traﬃc of
the USTC-TFC dataset. To validate our results, we perform stratiﬁed cross-
validation with a fold of 5 on the dataset.
Table 5 shows the classiﬁcation of VPN traﬃc. Our model yields its best
result in the ﬁrst experiment when truncation is applied at the session layer
and padding at the data-link layer. The model generalises optimally for the
ﬁrst three experiments but struggles in the last experiment when truncation
is applied only at the data-link layer. For experiments 2 and 4 we use graphs
with variable vertex cardinality for classiﬁcation. The results demonstrate that
geometric deep learning, like other DL methods, thrives when the input size is
ﬁxed. In situations where the input parameter sizes vary, such as in experiment
4, a compensation to improve accuracy should be well-deﬁned node attributes
of an adequate size.
Table 6 shows very similar results to Table 5 for the non-VPN traﬃc clas-
siﬁcation task. The best result is achieved in the ﬁrst experiment. Applying
Table 5. VPN Traﬃc classiﬁcation result
Input Spec
Metric
Chat
Email
File
Stream P2P
VoIP
Accuracy
10nodes/1500 Precision 0.9738 0.9672 0.9069 0.8993
0.9877 0.9850 0.9784
Recall
0.9595 0.9363 0.8685 0.9921
0.9877 0.9891
F1score
0.9666 0.9516 0.8873 0.9434
0.9877 0.9871
v-nodes/1500
Precision 0.9831 0.8983 0.6916 0.7484
0.9444 0.9867 0.9437
Recall
0.9509 0.8413 0.9181 0.8406
0.9533 0.9512
F1score
0.9409 0.8689 0.7889 0.7918
0.9488 0.9687
10nodes/784
Precision 0.9674 0.8955 0.7103 0.8529
0.9700 0.9838 0.9548
Recall
0.9601 0.9231 0.8861 0.8722
0.9417 0.9648
F1score
0.9637 0.9091 0.7885 0.8625
0.9557 0.9742
v-nodes/784
Precision 0.2273 0.1908 0.2559 0.5215
0.3333 0.7080 0.4312
Recall
0.4065 0.3906 0.4645 0.6693
0.6790 0.4168
F1score
0.2916 0.2564 0.3300 0.5862
0.4472 0.5247

644
Z. Okonkwo et al.
Table 6. non-VPN Traﬃc classiﬁcation result
Input Spec
Metric
Chat
Email
File
Stream VoIP
Accuracy
10nodes/1500 Precision 0.8683 0.8389 0.9412 1.000
1.000
0.8707
Recall
0.8139 0.8881 0.9412 0.9867
0.9745
F1score
0.8402 0.8586 0.9412 0.9933
0.9871
v-nodes/1500
Precision 0.8279 0.6483 0.6667 0.8493
0.8697 0.7160
Recall
0.4345 0.9241 0.7568 0.8732
0.8566
F1score
0.5699 0.7620 0.7089 0.8611
0.8631
10nodes/784
Precision 0.6823 0.5266 0.8182 0.7719
0.8392 0.5859
Recall
0.2465 0.9023 0.7660 0.7333
0.5604
F1score
0.3622 0.6650 0.7912 0.7521
0.6720
v-nodes/784
Precision 0.5852 0.5516 0.2400 0.4017
0.5736 0.5435
Recall
0.2469 0.7662 0.6000 0.6026
0.6632
F1score
0.3473 0.6414 0.3429 0.4821
0.6151
truncation at the data-link layer yields the worst result. Notice how the model
struggles to classify the chat and email traﬃc across all experiments. This is
attributed to poor distinction of applications within network sessions. In our
work, every session has a label that deﬁnes its traﬃc class. It is possible to have
multiple application leveraging the same session or have a case of tunnelling
where packets are wrapped inside packets. Our model does not pay attention to
this dynamics rather it focuses on distinguishing a particular traﬃc session by
labelling it. The imbalanced nature of the traﬃc also contributes a great deal
to this confusion. Figures 5 and 6 show the confusion matrix for the VPN and
Non-VPN traﬃc of the ISCXVPN dataset.
Figure 7 shows the confusion matrix for the benign class of the USTC-TFC
dataset. With a balanced dataset, our model perfectly classiﬁes six applications
for the ﬁrst experiment and classiﬁes ﬁve applications perfectly when the feature
vector is slashed by almost half. As demonstrated in Fig. 8 our model shows
powerful generalisation strength for the malware class of the USTC-TFC dataset.
We get very similar results for both experiments regardless of data truncation.
This time we test to see the best feature length for optimum generalisation.
Hence, we keep the nodes length ﬁxed at 10 while varying the attribute size. Our
model maintains an accuracy of over 90% after we slash the feature vector by
almost half. For other evaluation metrics, our model again maintains accuracies
of over 90%. The experiments proved that an increase in features size while
keeping vertex cardinality ﬁxed, improves generalisation strength. Table 7 shows
the overall performance of our model after all 12 experiments are carried out.
4.4
Performance Comparison
We compare our best results with state-of-the-art results that use the same
dataset and a similar data processing approach. For VPN classiﬁcation, our

Encrypted Network Traﬃc Classiﬁcation with Graph Neural Network
645
Fig. 5. Confusion matrix for VPN dataset
Fig. 6. Confusion matrix for non-VPN dataset
Fig. 7. Confusion matrix for USTC-TFC Benign Traﬃc
model generalises optimally with approximately the same value across all evalu-
ation metrics. Our model maintains an accuracy that doesn’t fall below 97%, an
occurrence not demonstrated by state-of-the-art models. The results of compared
literature remained unstable for diﬀerent evaluation metrics (Table 8).

646
Z. Okonkwo et al.
Fig. 8. Confusion matrix for USTC-TFC Malware Traﬃc
Table 7. Overall Performance Summary
Dataset
Input Spec
Precision Recall
F1Score Accuracy
VPN
10nodes/1500 0.9749
0.9748 0.9747
0.9748
10nodes/784
0.9586
0.9548 0.9561
0.9548
v-nodes/1500
0.9494
0.9437 0.9455
0.9437
v-nodes/784
0.5543
0.4312 0.4587
0.4312
non-VPN 10nodes/1500 0.8722
0.8707 0.8706
0.8707
10nodes/784
0.6398
0.5859 0.5466
0.5859
v-nodes/1500
0.7505
0.7160 0.6978
0.7160
v-nodes/784
0.5588
0.5434 0.5144
0.5435
Benign
10nodes/1500 0.9830
0.9831 0.9831
0.9830
10nodes/784
0.9177
0.9030 0.8983
0.9030
Malware
10nodes/1500 0.9655
0.9655 0.9655
0.9655
10nodes/784
0.6578
0.9573 0.9575
0.9573
For the task of non-VPN classiﬁcation, we obtain similar results to the com-
pared literature. Our model still demonstrates optimum generalisation strength
producing accuracies that do not fall below 87%. Gil et al. [17] using ﬂow-based
features got a precision score of 90.6% on the non-VPN dataset. While this
result is impressive, applications share similar ﬂow-based features which can
impact classiﬁcation. Huoh et al. [15] GNN-based classiﬁer performed well for
both tasks; their model does not generalise optimally for VPN classiﬁcation.
Comparatively, Song et al. [23] achieved the closest accuracy to our work; they
used text-based CNN for classiﬁcation. This closeness in results can be attributed
to “sense of locality”. GNNs and CNNs utilise locality relationships for the clas-
siﬁcation tasks. While GNNs can be built with higher order capability to perform

Encrypted Network Traﬃc Classiﬁcation with Graph Neural Network
647
Table 8. Performance Comparison
Dataset
Metric
DeepPacket
(GAE) [5]
Gil et
al.
[17]
Song et
al. [23]
1DCNN [4]
Huoh et
al. [15]
k-
NN. [24]
Our
work
VPN
Precision 0.97
0.89
95.2
0.949
0.913
–
0.9748
Recall
0.80
–
97.2
0.973
0.940
–
0.9784
F 1Score
0.97
–
96.1
–
0.926
–
0.9747
Accuracy –
–
–
–
–
0.94
0.9748
non-VPN Precision 0.87
0.906
87.6
0.855
0.882
–
0.8722
Recall
0.88
–
87.3
0.858
0.866
–
0.8707
F 1Score
0.87
–
87.5
–
0.871
–
0.8706
Accuracy –
–
–
–
0.8707
better, results from both methods should not be far apart. Most state-of-the-art
models avoid the use of accuracy as a metric for evaluation. This is a normal
occurrence when the utilised dataset is imbalanced. The accuracy of classiﬁer on
imbalanced dataset does not depict the true nature of the model’s performance
as minority classes can negatively impact accuracy. For our work, we consider
all four evaluation metric (including accuracy) as in the real world, dataset is
mostly imbalanced.
5
Related Work
Deep learning methods have been immensely applied to the task of traﬃc classi-
ﬁcation, recurrent(RNN) and convolutional neural networks (CNN) [7] account
for the most usage. In analysing network traﬃc, the data processing stage is cru-
cial to the overall process. A common practice by state-of-the-art literature [4–6]
is utilising raw packet bytes for classiﬁcation. Extracted byte information is pro-
cessed to have a ﬁxed length as this is a requirement for most deep learning
approaches. Data truncation is applied, and inputs are fed to the network for
classiﬁcation. The model is left with the task of making sense of the truncated
input. While reviewed state-of-the-art models provide good accuracy, it is impor-
tant to note that generalisation isn’t guaranteed as information lost during data
processing is necessary for classiﬁcation.
Geometric deep learning is an emerging concept that generalise neural net-
works to non-euclidean domains. Graphs are a visual way to demonstrate rela-
tionships between two or more entities. Since network data exists in non-
euclidean space, they can be represented as graphs. Unlike RNN and CNN,
GNN can perform computation on variable-sized inputs. Huoh et al. [15] applied
GNN to traﬃc classiﬁcation, they conduct a range of experiments which pro-
duced good results. When they use raw bytes for classiﬁcation, they experience
signiﬁcant drop in accuracy. Their design does not utilise structural information
necessary for graph classiﬁcation. GNNs rely on message passing to propagate
information across nodes, this propagation method performs well for the task of
node classiﬁcation. To classify the entire graph, a stronger propagation function
is necessary. Shen et al. [22] used GNN to distinguish decentralised application.

648
Z. Okonkwo et al.
They design simple traﬃc dispersion graphs representing applications then use
GNN for classiﬁcation. They achieve promising results, attributed to the sim-
plistic nature of their graphs. When network traﬃc sessions are modelled as
variable sized inputs, the tendency of having graphs with huge vertex cardinal-
ity increases. In such scenarios, the task of graph classiﬁcation demands higher
order GNNs that generate optimum embedding for graph classiﬁcation.
A process not demonstrated by the reviewed literature is deﬁning the impact
of lost information on a model’s performance. The practice of truncating network
packet data leads to loss of classiﬁcation information, discarding information
impacts the generalisation strength of classiﬁers and should be analysed before
implemented. Literature that utilise GNN for the task of classiﬁcation failed
to utilise the potential of graphs by taking advantage of structural details for
graph classiﬁcation. The imbalance nature of dataset should always be taken
into consideration during training to produce model that generalise optimally.
6
Conclusion
This work presents a higher order GNN for the task of encrypted traﬃc classi-
ﬁcation. We build on theoretical foundations that relates the short fall of basic
GNN to that of the Weisfeiler-Leman graph isomorphism. We observe that tra-
ditional machine learning and deep learning based methods demands ﬁxed sized
input for classiﬁcation. This requirement causes information discarding during
data processing leading to ordinary representations of traﬃc data. As graphs are
a powerful way to demonstrate relationships between entities, we model traﬃc
session as graphs. Nodes represents packets and edges deﬁne chronological rela-
tionship between nodes. We harness this expressive nature of graphs to model
network traﬃc with diﬀerent input speciﬁcations, deﬁning a baseline data pro-
cessing method that conforms to state-of-the-art. The selected datasets are based
on popularity within the research domain, and their suitability for comparative
analysis. Our Proposed model which consist of two major parts is capable of
preserving vertex and structural information of graphs suitable for classiﬁca-
tion. In training our model we consider the imbalance nature of network data
and deﬁne ways to curb its ripple eﬀect. When compared to state-of-the art,
our model demonstrates optimum generalisation strength on all dataset across
all experiment conducted. We conduct further test to determine the impact of
truncation on traﬃc classiﬁcation. Based on the evaluation metric from series of
test, our model’s overall aim was achieved. Higher order graphs proved suitable
for the task of encrypted network traﬃc classiﬁcation. In improving the current
work, the focus needs to shift from the classiﬁcation stage to feature extraction
stage. To harness the full potential of GNN, ﬁned grained graph structures need
to be developed, as graphs can be spectral or spatial in nature. A hybrid of
both methods for feature representation can aid classiﬁcation. An extension of
the current method to restricted network contexts, such as IoT, IIoT or CPS is
important. Finally, unknown traﬃc classiﬁcation should be explored.

Encrypted Network Traﬃc Classiﬁcation with Graph Neural Network
649
References
1. SonicWall 2022 SonicWall Cyber Threat Report: Cyberattacks Climb Due to Seis-
mic Shift in Geopolitical Landscape (SonicWall, 2022)
2. Zhang, J., Chen, X., Xiang, Y., Zhou, W., Wu, J.: Robust network traﬃc classiﬁ-
cation. IEEE/ACM Trans. Netw. 23, 1257–1270 (2014)
3. Google Google Transparency Report, HTTPS encryption on the web (2023).
https://transparencyreport.google.com/https/overview?hl=en
4. Wang, W., Zhu, M., Wang, J., Zeng, X., Yang, Z.: End-to-end encrypted traﬃc
classiﬁcation with one-dimensional convolution neural networks. In: IEEE Interna-
tional Conference on Intelligence and Security Informatics (ISI), pp. 43–48 (2017)
5. Lotfollahi, M., Jafari Siavoshani, M., Shirali Hossein Zade, R., Saberian, M.: Deep
packet: a novel approach for encrypted traﬃc classiﬁcation using deep learning.
Soft Comput. 24, 1999–2012 (2020)
6. Zou, Z., Ge, J., Zheng, H., Wu, Y., Han, C., Yao, Z.: Encrypted traﬃc classiﬁcation
with a convolutional long short-term memory neural network. In: IEEE 20th Inter-
national Conference on High Performance Computing And Communications; IEEE
16th International Conference on Smart City; IEEE 4th International Conference
On Data Science And Systems (HPCC/SmartCity/DSS), pp. 329–334 (2018)
7. Okonkwo, Z., Foo, E., Li, Q., Hou, Z.: A CNN based encrypted network traﬃc
classiﬁer. Aust. Comput. Sci. Week 2022, 74–83 (2022)
8. Garbin, C., Zhu, X., Marques, O.: Dropout vs. batch normalization: an empirical
study of their impact to deep learning. Multimed. Tools Appl. 79, 12777–12815
(2020)
9. Bronstein, M., Bruna, J., LeCun, Y., Szlam, A., Vandergheynst, P.: Geometric
deep learning: going beyond Euclidean data. IEEE Signal Process. Mag. 34, 18–42
(2017)
10. Kipf, T., Welling, M.: Semi-supervised classiﬁcation with graph convolutional net-
works. ArXiv Preprint ArXiv:1609.02907 (2016)
11. LeCun, Y., Bottou, L., Bengio, Y., Haﬀner, P.: Gradient-based learning applied to
document recognition. Proc. IEEE 86, 2278–2324 (1998)
12. LeCun, Y., Kavukcuoglu, K., Farabet, C.: Convolutional networks and applications
in vision. In: Proceedings of 2010 IEEE International Symposium on Circuits and
Systems, pp. 253–256 (2010)
13. Gao, H., Ji, S.: Graph U-nets. In: International Conference on Machine Learning,
pp. 2083–2092 (2019)
14. Pang, B., Fu, Y., Ren, S., Wang, Y., Liao, Q., Jia, Y.: CGNN: traﬃc classiﬁcation
with graph neural network. ArXiv Preprint ArXiv:2110.09726 (2021)
15. Huoh, T., Luo, Y., Li, P., Zhang, T.: Flow-based encrypted network traﬃc classiﬁ-
cation with graph neural networks. IEEE Trans. Netw. Serv. Manage. 1–1 (2022).
https://doi.org/10.1109/TNSM.2022.3227500
16. Sadowski, K., Szarmach, M., Mattia, E.: Dimensionality reduction meets message
passing for graph node embeddings. ArXiv Preprint ArXiv:2202.00408 (2022)
17. Draper-Gil, G., Lashkari, A., Mamun, M., Ghorbani, A.: Characterization of
encrypted and VPN traﬃc using time-related. In: The 2nd International Confer-
ence on Information Systems Security and Privacy (ICISSP), pp. 407–414 (2016)
18. CTU-University
The
Stratosphere
IPS
Project
Dataset
(2016).
https://
stratosphereips.org/category/dataset.html
19. Wang, W., Zhu, M., Zeng, X., Ye, X., Sheng, Y.: Malware traﬃc classiﬁcation using
convolutional neural network for representation learning. In: 2017 International
Conference on Information Networking (ICOIN), pp. 712–717 (2017)

650
Z. Okonkwo et al.
20. Peng, L., Yang, B., Chen, Y., Wu, T.: How many packets are most eﬀective for
early stage traﬃc identiﬁcation: an experimental study. China Commun. 11, 183–
193 (2014)
21. Morris, C., et al.: Weisfeiler and leman go neural: higher-order graph neural net-
works. CoRR. abs/1810.02244 (2018). http://arxiv.org/abs/1810.02244
22. Shen, M., Zhang, J., Zhu, L., Xu, K., Du, X.: Accurate decentralized application
identiﬁcation via encrypted traﬃc analysis using graph neural networks. IEEE
Trans. Inf. Forensics Secur. 16, 2367–2380 (2021)
23. Song, M., Ran, J., Li, S.: Encrypted traﬃc classiﬁcation based on text convolution
neural networks. In: 2019 IEEE 7th International Conference on Computer Science
and Network Technology (ICCSNT), pp. 432–436 (2019)
24. Yamansavascilar, B., Guvensan, M., Yavuz, A., Karsligil, M.: Application identi-
ﬁcation via network traﬃc classiﬁcation. 2017 International Conference on Com-
puting, Networking and Communications (ICNC), pp. 843–848 (2017)

Author Index
A
Abe, Masayuki
343
Abla, Parhat
431
Anand, Ravi
403
Atapoor, Shahla
471
Au, Man Ho
320
B
Baghery, Karim
471
Bartlett, Harry
89
Beighton, Matthew
89
Berti, Francesco
157
Boyd, Colin
553
C
Che, Cheng
53
Chen, Huiqin
431
Chen, Shiyao
25
Cong, Kelong
580
Cozzo, Daniele
471
D
de Kock, Bor
553
F
Fan, Jingjing
320
Feng, Zhuohui
3
Foo, Ernest
381, 630
Fukushima, Kazuhide
291
G
Gao, Debin
609
Guo, Fuchun
199
H
Han, DongGyun
609
Hou, Zhe
630
Huang, Sheng
503
I
Ishibashi, Ren
220
Ishizaka, Masahito
291
Ismail, Maliha
609
Isobe, Takanori
403
Izabachène, Malika
270
J
Jadidi, Zahra
630
Jiao, Lin
431
K
Kimura, Naoto
452
L
Li, Muzhou
124
Li, Qinyi
381, 630
Li, Yongqiang
431
Li, Zhiran
431
Lin, Yan
609
Liu, Fukang
403
Liu, Qun
124
Liu, Zhiquan
3
Loh, Jia-Chng
199
Lu, Xingye
320
Luo, Ye
3
M
Madhusudan, Akash
580
Mao, Yongxia
109
Millerjord, Lise
553
Mouha, Nicky
177
Mukherjee, Sayantan
523
N
Nakahashi, Motoki
403
Niu, Chao
124
O
Okonkwo, Zulu
630
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2023
L. Simpson and M. A. Rezazadeh Baee (Eds.): ACISP 2023, LNCS 13915, pp. 651–652, 2023.
https://doi.org/10.1007/978-3-031-35486-1

652
Author Index
P
Pan, Shimin
503
Pedersen, Robi
471
Prabel, Lucas
270
Preneel, Bart
124, 580
R
Rahman, Mostaﬁzar
403
Roux-Langlois, Adeline
270
S
Sakamoto, Kosei
403
Sedaghat, Mahdi
580
Shiba, Rentaro
403
Simpson, Leonie
89
Song, Ling
3
Susilo, Willy
199
T
Takagi, Tsuyoshi
452
Takayasu, Atsushi
452
Tian, Tian
53, 72
Tibouchi, Mehdi
343
Tiwari, Samarth
580
W
Wang, Chao
3
Wang, Jinliang
124
Wang, Li-Ping
248
Wang, Meiqin
25, 124
Wang, Mingsheng
431
Wei, Puwen
25
Wong, Kenneth Koon-Ho
89
Wu, Wenling
109
X
Xie, Xiaofeng
72
Xu, Peiying
248
Xu, Zeyu
25
Y
Yang, Guomin
199
Yang, Qianqian
3
Yoneyama, Kazuki
220
Yuan, Quan
343
Yuen, Tsz Hon
503
Z
Zhang, Lei
109
Zhang, Xiaoting
503
Zheng, Yafei
109

