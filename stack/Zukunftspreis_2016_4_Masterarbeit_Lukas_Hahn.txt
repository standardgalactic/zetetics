Universit¨at Ulm
Fakult¨at f¨ur Mathematik und
Wirtschaftswissenschaften
A Bayesian Multi-Population
Mortality Projection Model
Masterarbeit
in Wirtschaftsmathematik
vorgelegt von
Lukas Josef Hahn
am 17. Dezember 2014
Gutachter
Jun.-Prof. Dr. Marcus C. Christiansen
Prof. Dr. Hans-Joachim Zwiesler

Acknowledgements
I would like to express my sincere gratitude to my supervisor Jun.-Professor Dr Marcus
C. Christiansen for the support and guidance at all stages of this work. His invaluable ad-
vice and insightful questions throughout the term improved this thesis signiﬁcantly. My
thanks are further extended to my second reader Professor Dr Hans-Joachim Zwiesler,
whose assistance during my studies at Ulm University meant a constant enrichment to
my performance in general and the ﬁnal outcome of this work in particular. I thank
all other members of the Faculty of Mathematics and Economics of the University of
Ulm and the Institute of Financial and Actuarial Mathematics in Ulm who helped me in
preparation of this thesis, most notably Dr Jan-Philipp Schmidt and Dr Matthias B¨orger.
This work has partly been performed during my time at the Department of Statistics
and Actuarial Science of the University of Waterloo in Waterloo, Ontario. I gratefully
acknowledge the warm hospitality and ﬁnancial support during this time. Special thanks
are given to my program coordinator Mary Lou Dufton for always providing me with a
professional work environment and my supervisor Professor Dr Shoja’eddin Chenouri,
whose fruitful comments on statistics and general scientiﬁc work have ultimately had a
positive impact on this work. I warmly thank the entire team behind the Human Mortal-
ity Database (2014) for excellent datasets on mortality, which have become fundamental
for the development of the model presented in this thesis. Further thanks are given to
Talanx-Stiftung (Talanx foundation) within the Stifterverband f¨ur die Deutsche Wis-
senschaft. Their funding supported me during an extensive time of my graduate studies.
Lastly, and most importantly, I wish to thank my parents, Dr Angela and Norbert Hahn,
and my signiﬁcant other, Jared Best, for their constant care and encouragement. This
work would clearly not have been possible without them.
ii

Contents
Contents
vi
List of Acronyms
vii
List of Figures
ix
List of Countries
x
List of Symbols
xii
1
Introduction
1
1.1
Mortality Forecasts for Several Populations . . . . . . . . . . . . . . . . .
1
1.2
A Brief Literature Overview . . . . . . . . . . . . . . . . . . . . . . . . .
2
1.3
Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.4
Outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
2
Literature on Mortality Forecast Modelling
7
2.1
Deﬁnitions of Mortality . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
2.2
Stochastic Models for Mortality Projection . . . . . . . . . . . . . . . . .
9
2.2.1
The Lee-Carter Model . . . . . . . . . . . . . . . . . . . . . . . .
9
2.2.2
The Cairns-Blake-Dowd Model
. . . . . . . . . . . . . . . . . . .
12
2.3
Simultaneous Mortality Projections for Several Populations . . . . . . . .
13
2.3.1
The Augmented Common Factor Model
. . . . . . . . . . . . . .
13
2.3.2
Models for Two Populations . . . . . . . . . . . . . . . . . . . . .
14
2.3.3
Further Models . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17
2.4
Bayesian Models for Mortality Forecasting . . . . . . . . . . . . . . . . .
18
2.4.1
Bayesian Approaches to the Lee-Carter Framework
. . . . . . . .
18
2.4.2
The Bayesian Mortality Model for Two Populations . . . . . . . .
20
iii

Contents
3
The Bayesian Multi-Population Mortality Projection Model
22
3.1
Model Targets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
3.1.1
Limitations in Existing Models
. . . . . . . . . . . . . . . . . . .
23
3.1.2
Beneﬁts of the New Model . . . . . . . . . . . . . . . . . . . . . .
25
3.2
Model Speciﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
3.2.1
The Cairns-Blake-Dowd Approach . . . . . . . . . . . . . . . . . .
27
3.2.2
The Vector Error Correction Model . . . . . . . . . . . . . . . . .
30
3.3
Bayesian Estimation
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
33
3.3.1
Likelihood for the Underlying Data . . . . . . . . . . . . . . . . .
34
3.3.2
Prior Distributions . . . . . . . . . . . . . . . . . . . . . . . . . .
36
3.3.3
Posterior Distributions . . . . . . . . . . . . . . . . . . . . . . . .
40
3.3.4
Weighted Posterior . . . . . . . . . . . . . . . . . . . . . . . . . .
48
3.4
Bayesian Forecasting . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
50
3.5
Model Summary
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
52
4
Case Studies in European Mortality Forecasting
55
4.1
Case Study 1: The Big Five . . . . . . . . . . . . . . . . . . . . . . . . .
56
4.1.1
Model Equations . . . . . . . . . . . . . . . . . . . . . . . . . . .
58
4.1.2
Choice of Priors . . . . . . . . . . . . . . . . . . . . . . . . . . . .
59
4.1.3
Initialisation of the Algorithm and Starting Values
. . . . . . . .
60
4.1.4
Convergence Diagnostics . . . . . . . . . . . . . . . . . . . . . . .
63
4.1.5
Posterior Predictive Checking . . . . . . . . . . . . . . . . . . . .
74
4.1.6
External Validation . . . . . . . . . . . . . . . . . . . . . . . . . .
80
4.1.7
Change of Calibration Period to 1981–2009 . . . . . . . . . . . . .
85
4.1.8
Joint Posterior Predictive Distribution
. . . . . . . . . . . . . . . 102
4.1.9
Comparison of Diﬀerent Model Set-ups . . . . . . . . . . . . . . . 108
4.1.10 Comparison of Bayesian and Maximum-Likelihood Estimation . . 110
4.2
Case Study 2: Central European Countries . . . . . . . . . . . . . . . . . 112
5
Conclusion
123
5.1
Summary and Outcome
. . . . . . . . . . . . . . . . . . . . . . . . . . . 123
5.2
Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
iv

Contents
APPENDICES
127
A Bayesian Statistics
128
A.1 Pragmatic Comparison of Frequentist and Bayesian Statistics . . . . . . . 128
A.2 Bayesian Inference
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
A.3 Hierarchical Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132
A.4 Model Diagnostics
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134
B Markov Chain Monte Carlo
138
B.1 Markov Chain Theory
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
B.2 Gibbs Sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
B.3 Metropolis-Hastings Sampling . . . . . . . . . . . . . . . . . . . . . . . . 143
B.4 Convergence Diagnostics . . . . . . . . . . . . . . . . . . . . . . . . . . . 145
C Vector Error Correction Models
148
C.1 The Vector Autoregressive Model . . . . . . . . . . . . . . . . . . . . . . 149
C.2 Cointegration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
C.3 Vector Error Correction Models . . . . . . . . . . . . . . . . . . . . . . . 154
C.4 Frequentist Estimation and Forecasting . . . . . . . . . . . . . . . . . . . 157
C.5 Bayesian Estimation and Forecasting . . . . . . . . . . . . . . . . . . . . 165
C.6 Goodness-of-Fit Diagnostics . . . . . . . . . . . . . . . . . . . . . . . . . 170
D Further Mathematical and Probabilistic Preliminaries
174
D.1 The Generalised Gamma Function . . . . . . . . . . . . . . . . . . . . . . 174
D.2 Deﬁnitions in Matrix Algebra
. . . . . . . . . . . . . . . . . . . . . . . . 175
D.3 Matrix-Valued Distributions . . . . . . . . . . . . . . . . . . . . . . . . . 175
E
Numerical Details on the Markov Chain Monte Carlo Algorithm
178
E.1
Computation of the Acceptance Probability
. . . . . . . . . . . . . . . . 178
E.2
General Formulae . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179
E.3
Expressions under Single-Component Metropolis-Hastings
. . . . . . . . 184
F
The R Package bmpmp
189
F.1
The Function create.data
. . . . . . . . . . . . . . . . . . . . . . . . . 190
F.2
The Function bmpmp.estimation . . . . . . . . . . . . . . . . . . . . . . 195
F.3
The Function bmpmp.estimation.continue . . . . . . . . . . . . . . . . 203
v

Contents
F.4
The Function bmpmp.plots
. . . . . . . . . . . . . . . . . . . . . . . . . 206
F.5
The Function ml.estimation.plots . . . . . . . . . . . . . . . . . . . . 212
References
217
vi

List of Acronyms
AR
autoregressive
ARMA
Autoregressive Moving Average
BMPMP
Bayesian Multi-Population Mortality Projection
CBD
Cairns-Blake-Dowd
iid
independent and identically distributed
LC
Lee-Carter
MA
moving average
MCMC
Markov Chain Monte Carlo
ML
maximum-likelihood
VAR
Vector Autoregressive
VARMA
Vector Autoregressive Moving Average
VECM
Vector Error Correction Model
w.l.o.g.
without loss of generality
vii

List of Figures
3.1
The Bayesian Multi-Population Mortality Projection Model . . . . . . . .
53
4.1
Map of the Big Five
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
57
4.2
Starting values for K . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
61
4.3
Convergence diagnostics for Ω. . . . . . . . . . . . . . . . . . . . . . . .
65
4.4
Convergence diagnostics for Ω−1 . . . . . . . . . . . . . . . . . . . . . . .
66
4.5
Convergence diagnostics for Π = αβ′
. . . . . . . . . . . . . . . . . . . .
67
4.6
Convergence diagnostics for φ . . . . . . . . . . . . . . . . . . . . . . . .
68
4.7
Convergence diagnostics for Γ = Γ1 . . . . . . . . . . . . . . . . . . . . .
69
4.8
Convergence diagnostics for κ20
. . . . . . . . . . . . . . . . . . . . . . .
70
4.9
Convergence diagnostics for κ40
. . . . . . . . . . . . . . . . . . . . . . .
71
4.10 Posterior predictive checking for K
. . . . . . . . . . . . . . . . . . . . .
75
4.11 Posterior predictive checking for ηxpgt for the age of 60
. . . . . . . . . .
76
4.12 Posterior predictive checking for ηxpgt for the age of 80
. . . . . . . . . .
77
4.13 External validation for K . . . . . . . . . . . . . . . . . . . . . . . . . . .
82
4.14 External validation for ηxpgt for the age of 60 . . . . . . . . . . . . . . . .
83
4.15 External validation for ηxpgt for the age of 80 . . . . . . . . . . . . . . . .
84
4.16 Starting values for K . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
86
4.17 Convergence diagnostics for Ω. . . . . . . . . . . . . . . . . . . . . . . .
87
4.18 Convergence diagnostics for Ω−1 . . . . . . . . . . . . . . . . . . . . . . .
88
4.19 Convergence diagnostics for Π = αβ′
. . . . . . . . . . . . . . . . . . . .
89
4.20 Convergence diagnostics for φ . . . . . . . . . . . . . . . . . . . . . . . .
90
4.21 Convergence diagnostics for Γ = Γ1 . . . . . . . . . . . . . . . . . . . . .
91
4.22 Convergence diagnostics for κ15
. . . . . . . . . . . . . . . . . . . . . . .
92
4.23 Convergence diagnostics for κ29
. . . . . . . . . . . . . . . . . . . . . . .
93
4.24 Posterior predictive checking for K
. . . . . . . . . . . . . . . . . . . . .
94
4.25 Posterior predictive checking for ηxpgt for the age of 60
. . . . . . . . . .
95
viii

List of Figures
4.26 Posterior predictive checking for ηxpgt for the age of 80
. . . . . . . . . .
96
4.27 External validation for K . . . . . . . . . . . . . . . . . . . . . . . . . . .
97
4.28 External validation for ηxpgt for the age of 60 . . . . . . . . . . . . . . . .
98
4.29 External validation for ηxpgt for the age of 80 . . . . . . . . . . . . . . . .
99
4.30 Correlation matrix for κt at the year of 2050 . . . . . . . . . . . . . . . . 103
4.31 Correlation matrix for κt at the year of 2100 . . . . . . . . . . . . . . . . 104
4.32 External validation for ηxpgt for the ages of 60 and 80 at years 2050 and
2100 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
4.33 Diﬀerences in ηxpgt for diﬀerent populations p of males for the age of 80 . 106
4.34 Comparison of posterior predictive ηxpgt for 60-year-old Italian males for
diﬀerent choices of cointegration and lag orders
. . . . . . . . . . . . . . 109
4.35 Comparison of Bayesian posterior predictive and maximum-likelihood es-
timates for ηxpgt for 60-year-old Italian males . . . . . . . . . . . . . . . . 111
4.36 Map of the ﬁve Central European countries in case study 2 . . . . . . . . 113
4.37 Starting values for K . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
4.38 Posterior predictive checking for K
. . . . . . . . . . . . . . . . . . . . . 115
4.39 Posterior predictive checking for ηxpgt for the age of 60
. . . . . . . . . . 116
4.40 Posterior predictive checking for ηxpgt for the age of 80
. . . . . . . . . . 117
4.41 External validation for K . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
4.42 External validation for ηxpgt for the age of 60 . . . . . . . . . . . . . . . . 119
4.43 External validation for ηxpgt for the age of 80 . . . . . . . . . . . . . . . . 120
ix

List of Countries
The following countries are considered in the case studies in Chapter 4, ordered by their
abbreviations through the corresponding Internet top-level domains (i.e. ISO 3166-1
alpha-2 codes with speciﬁc replacement of GB by UK for the United Kingdom). Com-
ments on territorial coverage are made w.r.t. the maximum time horizon for respective
analyses in this work.
AT
Austria
Today’s territory remained unchanged throughout the time
horizon.
CZ
Czech Republic
Today’s territory of the Czech Republic, i.e. the Czech lands
within Czechoslovakia before 1993 (also known as the Czech
Socialist Republic between 1968–1990 and the Czech Repub-
lic between 1990–1993) and the independent Czech Republic
since 1993 after the dissolution of Czechoslovakia.
DE
Germany
German data are restricted to the dataset for the population
in the territory of former West Germany (i.e. the Federal Re-
public of Germany until 1990 and the old states within the
re-uniﬁed Federal Republic of Germany since then), i.e. ex-
cluding East Germany (i.e. the German Democratic Republic
until 1990 and the new states within the re-uniﬁed Federal
Republic of Germany since then), due to diﬀerent patterns in
mortality in a divided Germany and even after re-uniﬁcation.
The current Internet top-level domain DE for the entire re-
public is conveniently used to denote the territory of former
West Germany. All case studies involve data for West Ger-
many only, but this exact speciﬁcation is usually dropped
and the population is referred to Germany for simplicity.
x

List of Countries
ES
Spain
Today’s territory of Spain consisting of the Iberian mainland,
the Balearic and Canary islands, and the North African ex-
claves Ceuta and Melilla. The territory remained unchanged
throughout the time horizon.
FR
France
Today’s territory of France consisting of Metropolitan France
(France m´etropolitaine) only, i.e. the data include European
mainland France with all its islands in the Atlantic Ocean,
the English Channel and the Mediterranean Sea (including
Corsica), but exclude Overseas France, i.e. all overseas de-
partments (Guadeloupe, Guyane, Martinique, R´eunion) and
all overseas territories and collectivities (including New Cale-
donia and French Polynesia).
The territory remained un-
changed throughout the time horizon.
HU
Hungary
Today’s territory remained unchanged throughout the time
horizon.
IT
Italy
Today’s territory remained unchanged throughout the time
horizon.
PL
Poland
Today’s territory remained unchanged throughout the time
horizon.
UK
United Kingdom
Today’s territory of the United Kingdom consisting of the
four countries England, Scotland, Wales, and Northern Ire-
land only, i.e. the data include the island of Great Britain
and the British north-eastern part of the island of Ireland,
but exclude the Kingdom’s fourteen overseas territories and
the three Crown Dependencies of Guernsey, Jersey, and the
Isle of Man, which are not part of the United Kingdom. The
territory remained unchanged throughout the time horizon.
xi

List of Symbols
The following symbols are deﬁned as in Chapters 3 and 4. They may be deﬁned diﬀer-
ently elsewhere in this work.
a
Acceptance probability in Metropolis-Hastings algorithm
A
m × m positive deﬁnite constant matrix in the prior for the VECM
measuring uncertainty in Ω
α
Loading matrix in the VECM containing weights for cointegration re-
lationships of dimension m × r with full rank r
β
Cointegration matrix in the VECM containing cointegration relation-
ships with dimension m × r with full rank r
βl
Lower block matrix of dimension m −r × r for β in the normal lineari-
sation β = (Ir, β′
l)′
c
m × r matrix (Ir, 0r×m−r)′
cMH
Tuning parameter for ΣMH
cr
Normalising constant in the prior for the VECM
c⊥
m × m −r matrix (0m−r×r, Im−r)′
Cov
Covariance matrix
Γ
m × (k −1)m matrix (Γ1, . . . , Γk−1)
Γi
m × m AR parameter matrix for lag i in the VECM
Γ
Positive real Gamma function as deﬁned in Deﬁnition D.1
Γb
Generalised Gamma function as deﬁned in Deﬁnition D.1
d
Number of constants in the VECM for the deterministic trend, equals
one in the BMPMP model
diag
Block matrix with elements on the diagonal and zeros elsewhere
Dt
d-dimensional constant of deterministic trends in the VECM, equals
the scalar one in the BMPMP model
Dxpt
Observed number of deaths for age x, population p at calendar year t
xii

List of Symbols
Dxpgt
Observed number of deaths for age x, gender g, population p at calen-
dar year t
D
Set of Dxpt (or Dxpgt) for all x, p, t (and g) with p ̸= p∗
Dt
Set of Dxpt (or Dxpgt) for all x, p (and g) with p ̸= p∗for calendar year
t
∆K
m × T −k matrix ∆K = (∆κk+1, . . . , ∆κT)
∆κt
m-dimensional vector κt −κt−1
exp
Exponential function
E
Expectation
Expt
Exposure-to-risk for age x, population p at calendar year t
Expgt
Exposure-to-risk for age x, gender g, population p at calendar year t
E
Set of Expt (or Expgt) for all x, p, t (and g) with p ̸= p∗
Et
Set of Expt (or Expgt) for all x, p (and g) with p ̸= p∗for calendar year
t
ε
m × T −k matrix (εk+1, . . . , εT)
εt
m-dimensional iid multivariate normal error terms in the VECM with
zero mean and covariance matrix Ωfor calendar year t
f
Probability density function or superscript denoting females
fA
Tuning function for choice of A in the empirical Bayes approach
g
Index or superscript for gender
ηxpt
Linear predictor, i.e. right-hand side, of CBD model for age x, popu-
lation p at calendar year t
ηxpgt
Linear predictor, i.e. right-hand side, of CBD model for age x, popu-
lation p, gender g at calendar year t
H
Set of hyperparameters {φ, Γ, α, β, Ω}
i
Index or iteration step
Im
m × m identity matrix
IWa
a-dimensional Inverse Wishart distribution as deﬁned in Deﬁnition D.7
k
Lag order in the VECM
K1
m × T −k matrix (κk, . . . , κT−1)
K2

(∆κ′
k, . . . , ∆κ′
2)′ ,
 ∆κ′
k+1, . . . , ∆κ′
3
′ , . . . ,
 ∆κ′
T−1, . . . , ∆κ′
T−k+1
′
of
dimension (k −1)m × T −k
K
Set of parameters κt for t = 1, . . . , T
xiii

List of Symbols
K−t
Set of parameters κs for s = 1, . . . , t −1, t + 1, . . . , T
κt
m-dimensional time series vector (κ0
t, κx
t , κp1
t , κp2
t , . . . ) for calendar year
t
κ0
t
Intercept in CBD model for calendar year t
κg
t
Main eﬀect for gender g in CBD model for calendar year t
κp
t
Main eﬀect for population p in CBD model for calendar year t
κpg
t
Interaction for population p and gender g in CBD model for calendar
year t
κx
t
Main eﬀect for age per one unit increase in x in CBD model for calendar
year t
κx2
t
Main eﬀect for quadratic age per one unit increase in x in CBD model
for calendar year t
κxg
t
Interaction for gender g and age per one unit increase in x in CBD
model for calendar year t
κx2g
t
Interaction for gender g and quadratic age per one unit increase in x
in CBD model for calendar year t
κxp
t
Interaction for population p and age per one unit increase in x in CBD
model for calendar year t
κx2p
t
Interaction for population p and quadratic age per one unit increase
in x in CBD model for calendar year t
log
Natural logarithm
L
Likelihood function
λA
Tuning factor for fA under the choice fA(M) = (λ2
Am2
ij)ij for square
matrices M = (mij)ij
λα
Constant in the prior for the VECM measuring uncertainty in α
λb
Constant in the prior for the VECM measuring baseline uncertainty in
Γ
λl
Constant in the prior for the VECM measuring lag-dependent shrink-
age in Γ
m
Dimension of VECM, i.e. number of parameters in CBD model, or
superscript denoting males
mxpt
Central death rate for age x, population p at calendar year t
mxpgt
Central death rate for age x, population p, gender g at calendar year t
min
Minimum function
xiv

List of Symbols
MNa×b
Matrix-Normal distribution of dimension a × b as deﬁned in Deﬁnition
D.4
Mta×b
Matrix-t distribution of dimension a × b as deﬁned in Deﬁnition D.5
µt
Prior mean vector for κt | k for t = 1, . . . , k
np
Number of populations
N
Number of iterations in MCMC algorithm
Nm
m-variate normal distribution
p
Index or superscript for population
p∗
Index or superscript for reference population (overall sample)
P
Probability measure in the underlying (known but unspeciﬁed) prob-
ability space
P
List of populations
Poi
Poisson distribution
Π
Matrix product αβ′ in the VECM of dimension m × m and rank r
q
Constant in prior for the VECM measuring uncertainty in Ω
qxpt
Mortality rate for age x, population p at calendar year t
qxpgt
Mortality rate for age x, population p, gender g at calendar year t
r
Cointegration rank, i.e. r = rk(Π) = rk(α) = rk(β)
rk
Rank of a matrix
s
Index for calendar years
ΣMH
m × m covariance matrix for Metropolis-Hastings proposals, for sim-
plicity ΣMH = cMHA
Σ
Prior covariance matrix for κt | k for all t = 1, . . . , k if Σ1 = · · · = Σk
Σt
Prior covariance matrix for κt | k for t = 1, . . . , k
t
Index for calendar years
tr
Trace function, i.e. sum of all diagonal elements of a square matrix
T
Number of calendar years
φ
m × d parameter matrix in the VECM for deterministic trends, m-
dimensional vector of ones in the BMPMP model
Φ
m × T −k matrix (φ, . . . , φ)
U
Uniform distribution
Var
Variance
VAR(k)
Vector Autoregressive Model of order k
vec
Vectorisation operator as deﬁned in Deﬁnition D.2
xv

List of Symbols
w
Posterior weight
Wa
a-dimensional Wishart distribution as deﬁned in Deﬁnition D.6
x
Index for age
x0
Minimum age for CBD model
Ω
m × m positive deﬁnite covariance matrix for all εt
bΩ
estimate for Ωbased on a maximum-likelihood approach
ΩΓ
m(k −1)×m(k −1) positive deﬁnite component matrix for the covari-
ance matrix of Γ with block matrices ΩΓ1, . . . , ΩΓk−1 on its diagonal
ΩΓi
m×m positive deﬁnite component matrix λ2
bi−2λlIm for the covariance
matrix of Γi
0a×b
a × b zero matrix
′
Transpose of a matrix
⊗
Matrix Kronecker product as deﬁned in Deﬁnition D.3
(i)
Superscript denoting realisation in iteration step i of Metropolis-
Hastings algorithm
∗
Superscript denoting proposal in Metropolis-Hastings algorithm
xvi

1 Introduction
1.1 Mortality Forecasts for Several Populations
Aside from the obvious interest in life expectancies in the myriad of sociological or med-
ical studies, mortality projections have always been an important feature in actuarial
science. Valid mortality forecasts are fundamental for pension funds or life insurers,
among many other ﬁnancial institutions, to correctly price annuities, pension plans or
life insurances, and to hedge against losses due to longevity risk. Usage of population-
speciﬁc mortality rates through life tables for the calculation of annuities can be traced
back to the 17th century. Several deterministic mortality laws, which are still popular
to this day, were established during the 19th and 20th centuries, in particular the promi-
nent Gompertz law for the force of mortality by Gompertz (1825). The late 20th century
introduced stochasticity in mortality projection models to account for the general un-
certainty associated with systematic and unsystematic risks, i.e. the possibility of errors
due to the random nature of mortality events, sampling of historical mortality data,
assumptions on continuous mortality measures, modelling approaches, estimation and,
in particular, the forecasting techniques and uncertainty about future developments. In
this context, the Lee-Carter (LC) model by Lee and Carter (1992) has without doubt
evolved into one of the state-of-the-art models and motivated several other approaches
comprising stochastic mortality projections. The opportunity of measuring uncertainty
in longevity through quantiles and conﬁdence intervals are vital features in actuarial
applications.
Due to fast-paced and progressively increasing globalisation, mortality patterns for dif-
ferent populations in the Western world have been observed to assimilate over the last
decades; see the discussion by Wilson (2001) for instance. Economic development, med-
ical innovations, and international migration cause mortality rates of formerly more
1

1 Introduction
isolated populations of developed countries to converge. As a consequence, such mortal-
ity patterns are by far not independent and it has become increasingly clear that even
mortality forecasts for individual populations should be modelled based on all available
data that contain necessary information. Joint mortality projections shall eliminate bi-
ological implausibilities, such as divergent behaviour resulting from individual mortality
forecasts, and, due to the increase in available data, improve their statistical properties,
particularly for the estimates of uncertainty. It is noteworthy, however, that sudden
short-term discrepancies between similar populations are not uncommon as observed in
Europe during the early 1990s. Findings in this work further suggest that the assimila-
tion process is less pronounced than commonly stated. Despite their popularity in recent
literature, prior convergence hypotheses in design stages of projection models seem to
underestimate this complexity.
In addition to the direct eﬀects of globalisation on supra-national mortality patterns,
there has been a growing interest in learning about the particular dependencies between
populations. Life insurers, pension funds, and other investors are stakeholders in globally
organised ﬁnancial markets. For example, life insurance portfolios may consist of con-
tracts negotiated in diﬀerent countries, which are priced individually based on national
mortality data. From the global risk management point of view, however, worst-case
scenarios require mortality projections which take into account the joint movement of
mortality rates and, notably, the risk associated with universal shocks on longevity. Sim-
ilar arguments apply to the common task of modelling mortality in a speciﬁed portfolio
of populations in possibly diﬀerent lines of business, which may substantially diﬀer from
macro-economic mortality data for the entire population due to adverse selection. In
these instances, data quality may be substantially lower than what is observed for the
parent population. Again, borrowing the strength from data of other populations in-
corporates quantiﬁcation of dependence and improves the statistical properties of the
forecasts.
1.2 A Brief Literature Overview
Current literature on actuarial mortality forecasting for developed countries, speciﬁcally
since the mid 2000s, has shifted its focus on multi-population mortality projection mod-
2

1 Introduction
els due to the aforementioned reasons. Their principal aims are an unbiased measure-
ment of expected mortality and its associated uncertainty. The latter should quantify
biologically plausible assimilation of longevity, dependencies between the individual pop-
ulations, and the statistical improvements due to the increase in available data. Several
contributions to this speciﬁc problem have been made, already leading to a variety of
model approaches, most of which seek to extend successfully proven stochastic single-
population models.
Mortality forecasting for single populations under inclusion of stochasticity ﬁnds its ori-
gin in the seminal paper by Lee and Carter (1992), who model logarithmic mortality rates
through an additive model. Besides a deterministic basic pattern for the log-mortality
over all ages under consideration, a bilinear term accounts for changes in this pattern
over time, weighted diﬀerently for distinct ages. Uncertainty about the randomness in
mortality is introduced through addition of homoskedastic random noise components
with expectation zero, independent for each pair of age and time. The time-dependent
changes in mortality patterns are forecast with time series models to construct conﬁ-
dence boundaries for future outcomes in the log-mortality. Much work on the LC model
has been done ever since. Several authors postulate a Poisson distribution for the num-
ber of deaths to establish maximum-likelihood (ML) estimation, thereby allowing the
random errors to be heteroskedastic, see Brouhns et al. (2002) for instance. Under dif-
ferent distribution assumptions, Czado et al. (2005) and Pedroza (2006) use Bayesian
statistics for parameter estimation to avoid incoherence within the two-step calibration
of the baseline model and the time series forecasts. Other important extensions are the
inclusion of cohort eﬀects by Renshaw and Haberman (2006) or overdispersion by, e.g.,
Delwarde et al. (2007).
The Cairns-Blake-Dowd (CBD) model by Cairns et al. (2006) contributes the main al-
ternative to the LC approach in general stochastic mortality forecasting. Motivated by
linear patterns in plots of the logits of observed mortality rates for older people versus
age, a Binomial regression with parameters for the intercept and slope is applied with
the mortality rates for each calendar year. In a similar manner as before, the bivariate
time series of intercept and slope coeﬃcients is forecast into the future. The evolution
of the intercept describes general improvements in mortality rates, whereas the change
in the slope determines diﬀerences in the beneﬁts for distinct age groups. The ﬂexibility
3

1 Introduction
of adjustments in the linear predictor and the well-understood behaviour of generalised
linear models has lead to further modiﬁcations of this approach, too, such as inclusion
of eﬀects for cohorts or quadratic patterns in the mortality logit proﬁles. A comparison
of a wide range of diﬀerent CBD models and the LC approach is provided by Cairns
et al. (2009).
Multi-population mortality forecasting in the stochastic framework dates back to the
seminal work by Li and Lee (2005). Their augmented common factor model is an exten-
sion of the LC model for several countries with country-speciﬁc baseline patterns and
additional bilinear terms for each country, which describe individual deviations from
the main evolution. Jarner and Kryger (2011), Dowd et al. (2011), and Cairns et al.
(2011b) consider models with only two populations, in which time series forecasts are re-
alised w.r.t. the diﬀerences in the mortality trends between a population of interest and
a larger reference population to ensure a non-divergent behaviour. Zhou et al. (2012)
apply multivariate time series models to the bivariate time series of model parameters
for two general populations, which is extended to the case of an arbitrary number of
populations by Ntamjokouen et al. (2014). Inclusion of country-speciﬁc covariates as
explanatory variables is considered by Reichmuth and Sarferaz (2008). Other models do
not build upon the LC framework. For example, Biatat and Currie (2010) use P-splines
to model diﬀerences in mortality, but do not project mortality rates into the future, and
Ah˘can et al. (2014) replicate a population of interest by mixing other populations. It is
noteworthy that the literature in actuarial science has seen further approaches that focus
on projections of insured amounts rather than the number of deaths, and death-speciﬁc
models have been in the focus of medical research.
However, despite all possible advances in the works outlined above, a general framework
that addresses all problems with mortality projection, as outlined in Section 1.1, has not
yet been developed. Such models are generally restricted to a certain maximum number
of populations or their nested structures, and are not always as ﬂexible as necessary to
be suﬃciently practicable.
4

1 Introduction
1.3 Objectives
This work provides contribution to the scientiﬁc area of multi-population mortality pro-
jection through a model proposal, which addresses the challenge of biologically plausible
joint forecasts of dependent populations in a globalised world. After an extensive litera-
ture review on stochastic mortality prediction models for single and multiple populations,
the proposed model is derived, deﬁned, and applied. In light of beneﬁts and limitations
of the reviewed models, the approach is based on a ﬂexible augmented version of the CBD
model for higher ages in an arbitrary number of populations. It comprises a hierarchical
set-up, in which the model parameters of the CBD model are forecast using a Vector
Error Correction Model (VECM), a speciﬁc representation of the multivariate Vector
Autoregressive (VAR) model. Dependencies between diﬀerent parameters, and hence
between diﬀerent populations, and biological plausibility in future mortality forces are
accounted for not only by cross-correlation terms, but also by additional quantiﬁcation
of cointegration, i.e. common stable trends in the long-run. Application of the universal
VECM further removes restrictions on the type of populations that can be analysed.
Along with the model formulation, further attention is devoted to parameter estima-
tion given historical data and incorporation of the diﬀerent types of uncertainty risks
in the model. In addition to the model design, which already accounts for the random
nature in mortality, the measurement of other sources of risks in the future develop-
ments of mortality is a main objective, and a Bayesian approach is established. The
corresponding philosophy of postulating randomness for the unknown parameters leads
to quantiﬁcation of the future predictions via probabilistic distributions, which imme-
diately yield Bayesian credibility regions for mortality forecasts. Moreover, by its very
nature, Bayesian statistics aims to detect the characterising properties of such underly-
ing distributions rather than determination of each individual parameter value. Since
for any but the smallest number of populations, frequentist estimation methods such as
ML lead to singularities in the estimating equations, the Bayesian approach is indeed
necessary in this high-dimensional framework to forecast the mortality of an arbitrary
and desired number of populations. Further advantages of the Bayesian approach are
the reduction of inconsistency in parameter estimation between both levels in the hier-
archical set-up and an implicit smoothing of mortality rates.
5

1 Introduction
To keep the model both parsimonious and ﬂexible, extra parameters for cohort eﬀects
will not be included. The Bayesian approach to this model is outlined in detail and a
Markov Chain Monte Carlo (MCMC) algorithm for numerical estimation is derived. A
corresponding routine in the statistical programme language R is made available. Nec-
essary mathematical and probabilistic preliminaries, especially on Bayesian statistics,
MCMC theory and multivariate time series analysis, are provided. The model is cali-
brated with data of diﬀerent European countries to assess the quality of mortality pre-
dictions. Statistical diagnostic tools and comparisons with univariate projections from
individual models and frequentist estimation are conducted in the course of two case
studies. Core interest lies in careful discussions on how the model performs regarding
the desired properties in stochastic mortality forecasting.
1.4 Outline
The work is outlined as follows. Chapter 2 gives a detailed introduction into stochastic
mortality forecasting for multiple populations by ﬁrst introducing standard terminology
on mortality and the general framework of stochastic models even for single populations.
By explaining existing models in more detail, this chapter motivates both the general
need for new multi-population projection models to address the required objectives and
the particular modelling choices in the remainder of the work. In Chapter 3, the model
is carefully established and the Bayesian estimation procedure is derived, along with a
numerical MCMC algorithm and the computation of mortality forecasts based on these
results. The model is applied with several European countries via two case studies in
Chapter 4. The model ﬁt and the convergence of the MCMC algorithm are analysed
and results are compared to univariate and frequentist mortality forecasting procedures.
Chapter 5 concludes with a discussion. The Appendix gives background information for
a general understanding of Bayesian statistics, MCMC techniques, and the VECM, as
well as further technical details where necessary. It further introduces the R package to
run the MCMC algorithm along with numerical details.
6

2 Literature on Mortality Forecast
Modelling
Dating back to the ﬁrst life tables in the 17th century or the ﬁrst laws of mortality pro-
posed by de Moivre (1725) and Gompertz (1825), the analysis of mortality has always
been in the focus of researchers from diverse scientiﬁc ﬁelds such as medicine, sociology,
and economics. In particular, mortality forecasts are of great importance as they heav-
ily inﬂuence socio-economic decisions. Any calculations w.r.t. public pension and health
care systems build upon projected mortality rates. A broad literature has emerged dur-
ing the last decades in which various models and projection tools have been suggested.
Since the beginning of the 21st century, multi-population as well as Bayesian models
have been proposed by several authors. This chapter gives an overview of the stochastic
models from recent years, which have evolved into benchmark models in modern mor-
tality forecasting, and a deep insight into simultaneous analysis of several populations
and Bayesian approaches to mortality estimation. After deﬁning central measures of
mortality in Section 2.1, the subsequent section describes the milestones in stochastic
mortality projections and their extensions in detail. Section 2.3 provides descriptions
for multi-population models, and Section 2.4 ﬁnally introduces the diﬀerent applications
using the Bayesian paradigm.
2.1 Deﬁnitions of Mortality
When it comes to studies on mortality, a variety of quantities exists whose notation and
terminology are not always consistent throughout the literature. Besides minor changes
in subscripts, this work uses the same standardised notation as in the comparison of
several stochastic models by Cairns et al. (2009). It is worth mentioning that variables
in any other cited literature should be read carefully in order to avoid confusion with def-
7

2 Literature on Mortality Forecast Modelling
initions. The interested reader is referred to Pitacco et al. (2009) for a general overview
of mortality measures.
In terms of estimating and forecasting mortality in a certain population, the central
quantity of interest is the force of mortality, denoted by µxt, where x ≥0 is some real-
valued age and t ≥0 is a point in time. For ﬁxed x and t, it expresses the instantaneous
probability of immediate death for an individual aged exactly x at time t, and as a
function in age it contains all information of mortality behaviour in the sample under
consideration at time t. The force of mortality corresponds to the hazard function known
from survival analysis when x and t increase at the same pace given an initial age x0 at
starting point t0. Typically, µxt is not directly observable, since mortality data are not
recorded on a continuous scale.
In contrast, another important measure of mortality, the central death rate, accounts for
deaths during a time frame rather than at an exact point in time. It is deﬁned as
mxt := Expected number of deaths during calendar year t aged ⌊x⌋last birthday
Average population during calendar year t aged ⌊x⌋last birthday
,
where ⌊x⌋is the greatest integer not exceeding x ≥0 and the calendar year t ∈N is
meant to be the time interval [t, t + 1). The average population size in the denomina-
tor is usually estimated by the population size in the middle of the calendar year or,
to be more precise, the total time lived in calendar year t by people aged ⌊x⌋at their
last birthday. The latter estimate is often referred to as the exposure-to-risk Ext. The
expected number of deaths is naturally approximated by the observed number of deaths
Dxt in the population under consideration. The resulting estimate Dxt/Ext for the cen-
tral death rate mxt is called the crude death rate for x in t.
Finally, a third quantity is the so-called mortality rate qxt, which is the probability of
dying within calendar year t for an individual aged exactly x at the point in time t.
In order to obtain results for the force of mortality from discrete observations, it is
common to impose the assumption that µxt remains constant over each year of integer
8

2 Literature on Mortality Forecast Modelling
age and over each calendar year, i.e.
µxt = µx+∆x,t+∆t
for all 0 ≤∆x < 1 and 0 ≤∆t < 1, see, e.g., Cairns et al. (2009) or Pitacco et al.
(2009). They derive that the force of mortality equals the corresponding central death
rate and, indeed, the ML estimate for µxt is then the crude death rate. Further, it is
shown that the relationship
qxt = 1 −exp (−mxt)
(2.1)
holds for any integer-valued x and t, what they regard an accurate approximation for
the mortality rate. This work adopts the assumption of a constant force of mortality
and its implications.
2.2 Stochastic Models for Mortality Projection
Besides a variety of deterministic models which extrapolate historical mortality trends
into the future (see, e.g., Pitacco et al. (2009)), stochastic models have become popular
for mortality forecasting purposes since the early 1990s.
Such approaches share the
advantage of including the random nature of mortality through underlying probability
assumptions. As a consequence, not only point estimates but also conﬁdence intervals
for mortality forecasts can be established. Furthermore, these approaches are designed
to fulﬁl standard criteria in mortality modelling such as consistency with historical data,
biologically reasonable long-run dynamics or robustness, as outlined in detail by Cairns
et al. (2008). This section describes the two main models within this framework and
a selection of extensions to these. For a thorough comparison of stochastic mortality
models, the reader is referred to the papers by Booth and Tickle (2008), Cairns et al.
(2009) and Haberman and Renshaw (2011).
2.2.1 The Lee-Carter Model
In recent years, the LC model, ﬁrst introduced by Lee and Carter (1992), has evolved
into the main approach for mortality estimation and forecasting. This stochastic model
9

2 Literature on Mortality Forecast Modelling
describes the central death rate mxt at some age x by the log-bilinear form
log (mxt) = αx + βxκt + εxt
(2.2)
with parameters αx, βx, κt and error terms εxt. As a function in age only, αx describes the
basic pattern of mxt averaged over time. Conversely, κt is a function in t and expresses
the overall evolution of mortality over time. These changes to the underlying mortality
scheme are weighted for the diﬀerent ages through the proﬁle in βx. Lee and Carter
(1992) set up the constraints P
x βx = 1 and P
t κt = 0 in order to achieve uniqueness
in the bilinear term. They ﬁnally assume the random ﬂuctuations εxt to be independent
with zero mean and variance σ2
ε > 0. For annual mortality data, Lee and Carter (1992)
estimate the parameters by least-squares, using the ﬁrst-rank approximation from a
singular value decomposition of a suitable matrix to deal with the non-linearity in the
parameters. Denoting the estimates by bαx, bβx, bκt, typically improvements in mortality
are detected in that the function bκt exhibits a negative trend. Stochastic forecasts for
the development in mortality are obtained by applying time series models with these
estimates. Lee and Carter (1992) propose a random walk with drift for modelling bκt.
Point estimates and conﬁdence intervals are then obtained for the future evolution in
mortality by using Box-Jenkins approaches (see, e.g., Box et al. (2013)). As a conse-
quence, substituting the remaining parameter estimates in (2.2) and setting the error
terms to zero leads to point and interval projections for the expected log-scaled central
death rate in the future.
Since the inﬂuential work by Lee and Carter (1992), several extensions to the model
in (2.2) have been discussed, one of which is an ML estimation procedure suggested
by Wilmoth (1993) and Alho (2000). Due to ﬁndings by Brillinger (1986), they argue
that for some age x and time t, the according number of deaths Dxt is independent and
approximately Poisson distributed with mean mxtExt, i.e.
Dxt ∼Poi (mxtExt)
for all x and t. Then ML estimation becomes possible for αx, βx, κt using the relation
log (mxt) = αx + βxκt, i.e. the LC approach as in (2.2) but dropping the additive error
term. Due to the work by Brouhns et al. (2002), who apply this technique to Belgian
10

2 Literature on Mortality Forecast Modelling
mortality data, the approach is usually referred to as the Poisson log-bilinear model. By
excluding εxt from the model equation, random ﬂuctuations around the logarithm of the
central death rate are no longer assumed homoskedastic. This is regarded advantageous
since the variance in observed log (mxt) diﬀers between younger and older ages, where
relative variability w.r.t. the exposure-to-risk is the highest for old ages due to low sam-
ple sizes. Delwarde et al. (2007) generalise the ML approach by replacing the Poisson
distribution with the two-parametric Negative Binomial distribution to account for pos-
sible overdispersion in the number of deaths, as do Renshaw and Haberman (2003b,c,
2006) through an overdispersed Poisson formulation.
Another major extension of the LC model is the inclusion of cohort eﬀects as suggested
by Renshaw and Haberman (2006). It was discovered that the pure LC model is not
able to successfully ﬁt certain datasets such as mortality data from England and Wales,
see Renshaw and Haberman (2003a). The goodness-of-ﬁt can be signiﬁcantly increased
when for integer-valued age x and calendar year t the cohort eﬀect of the corresponding
birth year t −x is taken into account through an additive term γt−x, i.e.
log (mxt) = αx + β(1)
x κt + β(2)
x γt−x
with some distribution assumption on the log-death rates and additional constraints
to the new parameters. The resulting model is sometimes referred to as the Renshaw-
Haberman model, particularly when comparing to simple age-period-cohort eﬀect models
of the form log (mxt) = αx + κt + γt−x. Many further modiﬁcations of the LC model can
be found in the literature – see, e.g., Lee (2000) or de Jong and Tickle (2006) –, but will
not be discussed here.
Despite its overall success, the LC framework has also been criticised taking into consid-
eration the model criteria by Cairns et al. (2008). For example, as Cairns et al. (2009,
2011a) point out, the quantiﬁcation of mortality improvements through only one factor
κt implies perfect correlation among the changes of central death rates for all ages, and
the proﬁle βx may not be smooth. The correlation structure remains simple even for the
Renshaw-Haberman model, for which additional problems with robustness are detected.
The shortcomings in the LC model and its extensions have therefore ultimately led to
various other attempts to project mortality or death rates.
11

2 Literature on Mortality Forecast Modelling
2.2.2 The Cairns-Blake-Dowd Model
With their study on mortality data of the United Kingdom, Cairns et al. (2006) con-
tribute another major approach to stochastic mortality forecasting in addition to the
LC model. Based on empirical ﬁndings, in this two-factor model, named CBD model
after its inventors, the core assumption is that for some ﬁxed time t ≥0 and suﬃciently
high ages x, the logits of the probabilities qxt increase approximately linearly in age.
Therefore, they adapt a Binomial generalised linear regression1 for each t, i.e.
log

qxt
1 −qxt

= κ(1)
t
+ κ(2)
t x,
x ≥x0
(2.3)
with x0 being a lower bound for the ages under consideration. The identiﬁable param-
eters κ(1)
t
and κ(2)
t
are estimated via standard ML methods. Then, similar to the LC
approach, the estimates bκ(1)
t
and bκ(2)
t
are regarded as a bivariate stochastic process, which
is again modelled using time series techniques. The ﬁrst marginal time series, bκ(1)
t , gives
the intercepts in all regression equations, thereby describing the general development
in mortality for all ages. As before, this time series usually declines. The second time
series, bκ(2)
t , measures changes in the slopes. When some age groups beneﬁt more than
others from improvement in mortality rates, this aﬀects the slope. For example, bκ(2)
t
ex-
hibits an increasing trend if younger age groups show faster reduction in mortality than
the older age groups do. Hence, the two-factor approach in (2.3) allows for imperfect
correlation in changes of mortality rates as distinct from the LC model. This is also
advantageous as the CBD model is able to smooth not only the mortality development
over time but also the age proﬁle, which is often neglected in standard LC models. On
the other side, forecasting the bivariate time series

bκ(1)
t , bκ(2)
t

, which ﬁnally leads to pro-
jections in the logit of mortality rates, becomes more complex than in the univariate case.
For mortality data of the United States, Cairns et al. (2009) ﬁnd that the plot of es-
timated log (qxt/ (1 −qxt)) against age x reveals some curvature.
In such cases they
suggest to incorporate a quadratic term in (2.3) along with an own set of parameters
1Note that the CBD model is not necessarily a logistic regression model as the successes and failures
describing the mortality rates qxt might not be directly observable. In particular, in this work only
the number of deaths Dxt (successes) and exposure-to-risk Ext (number of trials) will be available
such that qxt must be further linked to the underlying data through (2.1).
The resulting link
function mxt 7→log (exp(mxt) −1) diﬀers from the logit link so that the more general terminology
of Binomial generalised linear regression is used.
12

2 Literature on Mortality Forecast Modelling
κ(3)
t . Pitacco et al. (2009), however, point out that the behaviour of the third time series
may not be clear and modelling becomes complicated. Nonetheless, the ﬂexible set-up of
the CBD model indeed allows for further modiﬁcations such as additional cohort eﬀects,
see Cairns et al. (2009) for a thorough comparison of diﬀerent designs. The CBD model
is generally found to be more adjustable with a solid ﬁt, but is only appropriate for the
analysis of high ages.
2.3 Simultaneous Mortality Projections for Several
Populations
So far, accuracy of the aforementioned stochastic models and their modiﬁcations have
been assessed for a wide range of mostly developed countries, commonly stratiﬁed for
both genders. However, models are usually ﬁtted separately to distinct populations and
forecasts from each individual model are ﬁnally compared – see, e.g., Macdonald et al.
(1998), Tuljapurkar et al. (2000) or Booth et al. (2006). Li and Lee (2005) argue that
information provided by the interaction within a group of countries is lost when the
mortality of one of these countries is modelled individually. Basic patterns in mortality
are expected to be consistent among similar countries, and due to globalisation eﬀects
diﬀerences should vanish over time. Incorporation of such transnational inﬂuences should
lead to improvements in projections compared to individual studies. Similar arguments
are quoted when males and females are separately modelled, or subpopulations, e.g.
members of a pension fund in a certain country, shall be compared to the corresponding
parent population. This section summarises contribution in recent literature to the topic
of joint analyses of more than one population. It should be noted that there also exist
various models for simultaneous estimation of other mortality-related quantities such as
life expectancy, see Oeppen and Vaupel (2002) for instance.
2.3.1 The Augmented Common Factor Model
Li and Lee (2005) suggest a three-step procedure to mutually model several populations
that builds on the LC approach. First, the ordinary model in (2.2) is run for the entire
sample comprising all, say, countries. The parameters κt and βx determine the over-
all development of mortality and according proﬁle of age-speciﬁc weights, respectively.
13

2 Literature on Mortality Forecast Modelling
In a second step, the averaged transnational death rate patterns, given by αx, are re-
placed by individual patterns αxp for each country p. Estimates for these proﬁles are
the country-speciﬁc logarithms of central death rates averaged over time. Finally, the
remaining residuals are described by a second bilinear term βxpκpt, which now depends
on the population via the subscript p and enters the model as an additive term. For
ﬁxed p, the corresponding κpt reveals diﬀerences in mortality evolution w.r.t. the overall
development, and βxp gives population-speciﬁc weights for ages concerning these devia-
tions. By analogy to the standard estimation in the LC model, Li and Lee (2005) apply
a singular value decomposition to ﬁnd least-squares estimates. Summarising, the ﬁnal
model, which they call the augmented common factor model, is given by
log (mxpt) = αxp + βxκt + βxpκpt + εxpt
with independent and homoskedastic error terms εxpt. The authors restrict the model
to those countries, whose diﬀerences from the overall mortality tend towards a constant
level in the long-run. When the estimates for κpt cannot be satisfactorily modelled by a
random walk without drift or an autoregressive (AR) model, they exclude population p
from the analysis. Although it is crucial to avoid divergent behaviour in death rates that
does not seem plausible, ignoring certain countries may violate the statistical validity of
the model, comparable to omitting unwanted observations such as outliers in statistical
models in general. The augmented common factor model is even more inappropriate
for modelling a group of countries which show some uncommon death rate patterns.
For example, Li and Lee (2005) are not able to capture the observations from Bulgaria,
Hungary, and Russia, which is debatable because similar countries like the Czech Re-
public or Lithuania ﬁt to the approach. Since the estimates bκpt must be inspected for
each population p separately, the augmented common factor model does not serve as a
practical framework for a large number of populations.
2.3.2 Models for Two Populations
Based on ﬁndings by Booth et al. (2006) that countries with small population sizes
appear more diﬃcult to forecast, Jarner and Kryger (2011) propose analyses of small
samples along with large, so-called reference populations containing the small sample as
a subpopulation. In their model, which they call the spread adjusted international trend
14

2 Literature on Mortality Forecast Modelling
model due to application in an international context, they use time series methods to
forecast both mortality trends of the reference population and deviations from the overall
trend in the subpopulation. These deviations, referred to as the spread, are modelled in
a regression equation, where explanatory variables comprise linear and quadratic eﬀects
of age. The time series of parameter estimates are assumed stationary in order to avoid
divergent behaviour in mortality evolution and, in particular, a multivariate ﬁrst-order
VAR model with zero mean is used. In their application to mortality data of 19 devel-
oped countries with Denmark serving as subpopulation, Jarner and Kryger (2011) show
that the assumption of stationarity is indeed fulﬁlled, implying that Danish mortality
rates converge to those of the reference population in the long-run. However, the authors
also note that there is no guarantee for this assumption to hold and there may be need
for more suitable models when data suggest permanent variability in diﬀerences. In
light of the previous section, it is not clear whether the model would lead to satisfactory
results when countries like Bulgaria, which cannot be adequately captured in Li and Lee
(2005), were included into the analysis. Even if the spread adjusted international trend
model can be extended to allow for more than one subpopulation, it may not be a good
framework for an analysis of a wider range of countries.
The gravity model by Dowd et al. (2011) contributes an approach rather similar to the
spread adjusted international trend model. The authors also focus on the case where
one population signiﬁcantly exceeds another in size, and it is assumed that interest lies
in modelling the smaller population. This is done with the help of the larger population,
because both are again believed to behave similarly for biological and socio-economic
reasons and statistical properties gain from the increased sample size. By setting up
age-period-cohort models for both populations, respectively, the common trend is ob-
tained via a bivariate time series model for the time-dependent parameters governing
the mortality evolution for each population over time. In the equation for the small
population’s innovations in mortality evolution, the process features an additive term to
quantify the diﬀerence between the parameters of both populations. The corresponding
coeﬃcient measures the eﬀect of this diﬀerence in a way that in case of large deviations,
the time series for the small population is forced to move to the level of the time series
for the large population. This mean reversion for the small population becomes stronger
the more the levels of the univariate series diﬀer. The eﬀect is comparable to gravity
between a planet and its orbit, thereby giving the model its name. As before, this ap-
15

2 Literature on Mortality Forecast Modelling
proach excludes divergence between the two populations in the design stage and beneﬁts
from statistical properties through a larger sample for the originally small population
of interest, but – again – particular interest lies in one, say, country only and the time
series models need to be assessed carefully. It is noteworthy that this approach implic-
itly postulates a cointegration relationship between the two univariate processes with
a predetermined cointegration vector and a loading factor for the submissive population.
Cairns et al. (2011b) set up a mortality projection model for two populations in which
parameters are estimated via Bayesian methods. This framework is also designed for
modelling a subpopulation with mean-reverting spreads relative to a dominant reference
population. This model is described in more detail in the next section, which is entirely
devoted to Bayesian models in mortality projections. Zhou et al. (2012) show that it
is not always clear which of the small and large populations is the dominant one. Mo-
tivated by the above studies, they extend the two-population approach via application
of VAR models in plain and VECM form to include symmetric rather than one-sided
cross-correlations into the model equations. Hence, as an advantage over the previous
models, there is no speciﬁc need for a distinction between dominant and submissive
populations. As before, non-divergence conditions are incorporated into the VAR model
through parameter constraints and into the VECM through the cointegration term with
a pre-speciﬁed cointegration relationship. Estimation is conducted via ML and compar-
ison of goodness-of-ﬁt checks indicates that the VECM gives the most reasonable results.
Another approach, which makes use of larger datasets to improve the ﬁt for small pop-
ulations of interest, is given by Plat (2009). Using a reference population, the model is
designed for the speciﬁc problem of forecasting the insured amount rather than the pure
number of deaths in a portfolio of, say, pension funds, and is therefore not considered. In
the context of hedging such insurance portfolios, Li and Hardy (2011) compare several
extensions of the LC model for two populations, one of which allows for cointegration
in a bivariate time series model for κt. Several other two-population models, e.g. by Lin
et al. (2013) and Zhou et al. (2013), have been suggested in an actuarial context, but
are not discussed in detail here. A general alternative to bivariate mortality projection
models is proposed by Ah˘can et al. (2014). Here the main motivation is that the small
population has an insuﬃcient sample size for statistical analyses. A pool of larger refer-
ence populations is mixed in an optimal way to replicate the population of interest, and
16

2 Literature on Mortality Forecast Modelling
this suﬃciently large counterpart is then projected via standard models as described in
Section 2.2. All the models in this section have in common that only two populations
can be forecast and, as seen with most of the applications in the respective studies,
their use is restricted to cases where interest lies in a single subpopulation rather than
dependencies between several populations.
2.3.3 Further Models
Some other contributions on joint analyses of mortality in several populations have been
made. Building upon the work by Zhou et al. (2012), Ntamjokouen et al. (2014) apply
the VAR model and the VECM to more than two populations. Their application with
both genders in nine Canadian provinces give mixed results in that the VECM seems
the most appropriate model, but lacks goodness-of-ﬁt notably for males. Due to the
brevity of their discussion, the analysis, however, must be considered insuﬃcient for
general conclusions on the appropriateness of the VECM. Biatat and Currie (2010)
use P-splines to detect similarities and diﬀerences between mortality rates of diﬀerent
countries or between males and females. Their analysis, however, is not dedicated to
mortality projections into the future and therefore not described in detail here.
In
comparison, B¨orger and Aleksic (2011) do make projections on future mortality trends
using a stochastic model on mortality improvements rather than rates. It is assumed
that the logarithm of annual changes in mortality rates is given by an additive set
of parameters for the variables age, period, and cohort. For distinct populations, the
parameters are estimated individually and, for projection purposes, diﬀerent techniques
must be applied to the estimates.
The principal component of this approach is the
forecast of the period parameters, and since a direct methodology does not seem obvious,
B¨orger and Aleksic (2011) derive future values for these parameters by forecasting the
life expectancies of the populations under consideration. The authors argue that such a
forecast is generally easier than immediate predictions of the mortality improvements,
but this method in turn requires a couple of assumptions on the development of life
expectancy, which depend on the populations under consideration and raise diﬃculties
on their own. The model is thus applied to Western European countries with large
population sizes only, thereby inhibiting this approach from being a general framework
for joint analyses of a wide range of countries.
17

2 Literature on Mortality Forecast Modelling
2.4 Bayesian Models for Mortality Forecasting
The models in the previous sections have in common that they principally build upon a
two-level hierarchical structure. First, the main model equation expresses the quantity
of interest, i.e. a transformation of the mortality rate, in terms of parameters. Then
the estimated parameters in this equation are forecast into the future by standard time
series models. Since in each of the discussed approaches both submodels are estimated
separately, the link between the response variable and the model’s underlying dynamic
processes may become spurious.
Czado et al. (2005) warn against incoherence that
these two-step procedures may account for. Moreover, forecasts based on the frequentist
Box-Jenkins approaches in the second model stage typically exhibit elliptical conﬁdence
boundaries with stable long-term conﬁdence regions, which appears to be unrealistic
given the naturally increasing uncertainty about future developments in medicine, econ-
omy, and sociology.
In order to avoid such shortcomings, Cairns et al. (2011b) propose to combine both
steps into one estimation procedure, which improves consistency within the set of pa-
rameters. They indicate that a likelihood-based single-step estimation method could be
applied. However, due to its natural inclusion of uncertainty in the parameters, Cairns
et al. (2011b) and also Czado et al. (2005) prefer Bayesian inference over frequentist
estimation. As stated by Czado et al. (2005), another reason is that the prior belief
of mortality rates behaving smooth across ages and time can be integrated into the
model framework. When data support this assumption, estimated mortality rates will
be smooth, too, thereby making crucial smoothing methods obsolete. The remainder of
this section outlines the literature on Bayesian models in mortality forecasting.
2.4.1 Bayesian Approaches to the Lee-Carter Framework
Czado et al. (2005) are the ﬁrst authors who apply Bayesian statistics to the frame-
work of the LC model. The underlying model is the Poisson log-bilinear model from
Section 2.2.1 ﬁrst introduced by Brouhns et al. (2002). The authors combine the two
stages in the LC approach, i.e. the estimation of period eﬀects along with their age
proﬁles and the calibration of an underlying dynamic model for the period eﬀects, into
one single step. Contrary to the general model, they assume a ﬁrst-order AR model
18

2 Literature on Mortality Forecast Modelling
rather than a random walk with drift for κt. As mentioned earlier, in combination with
the Bayesian methodology this allows for the advantage of smoothing the data within
the estimation procedure. Finally, standard priors are used for the unknown hyper-
parameters in the AR(1) model. In their application to data of French males, Czado
et al. (2005) show that their mortality projections are somewhat more pessimistic, but
in general they closely agree with frequentist forecasts. Parameter uncertainty for future
forecasts leads to wider credibility bands, which always include the frequentist estimates.
Similar conclusions can be found for the example of US-American males in Pedroza
(2006). Here, the Bayesian paradigm is directly applied with the original LC model, i.e.
with normally distributed error terms and a random walk with drift for the dynamics
process. The ﬁndings of wider credibility intervals in both studies suggest that predic-
tion errors in the frequentist version of the LC model are not able to cover all sources of
uncertainty. Lee and Carter (1992) themselves suppose in their original work that the
ﬂuctuation in the dynamics process accounts for most uncertainty in the ﬁnal conﬁdence
bands. Hence, due to Pedroza (2006), Bayesian models are more suitable in mortality
projection as they include all diﬀerent sources of estimation and prediction errors. Fi-
nally, Kogure et al. (2009) compare both models by Czado et al. (2005) and Pedroza
(2006) and some variations via application to data of Japanese males. They conclude
that in each model framework, a time series with stochastic trend for κt performs best,
whereas no appropriate results for the diﬀerences between the normality and Poisson
assumptions can be drawn.
Reichmuth and Sarferaz (2008) provide another Bayesian mortality projection model.
Also building on the LC approach, they modify the original model extensively in that
they allow for several covariates, e.g. macroeconomic quantities, in addition to the la-
tent variables κt. Furthermore, they employ time series models not only for the time-
dependent parameters but also for the age parameters to achieve smoothness across
ages. With their application to mortality for males in the United States, they conclude
that covariates can improve forecasts. As seen in the previous studies, Reichmuth and
Sarferaz (2008) also stress the Bayesian property of incorporating all diﬀerent sources
of prediction error. Likewise, the model by Girosi and King (2008) is worth mentioning
as it also includes covariates in a Bayesian model. However, the methodology strongly
diﬀers from what Lee and Carter (1992) propose, and mortality rates are analysed by
19

2 Literature on Mortality Forecast Modelling
cause of death. Therefore, this model as well as other approaches with cause-speciﬁc
parameters in medical contexts, see e.g. Bray (2002), are not discussed in detail here.
2.4.2 The Bayesian Mortality Model for Two Populations
The Bayesian mortality model for two populations by Cairns et al. (2011b) is the ﬁrst
approach that combines both Bayesian methodology and simultaneous estimation pro-
cedures for more than one population. The model is restricted to two populations, which
may be distinct or nested. The authors make use of a simple age-period-cohort model,
i.e. an additive model with own parameters for each of the age, period, and cohort ef-
fects, to keep the focus on the Bayesian approach. Similar to Jarner and Kryger (2011)
and Dowd et al. (2011), there is a reference population which is modelled ﬁrst, where
for the other population the spread in central death rates is analysed. The desired be-
haviour of non-divergence in the long-run between both populations is accounted for by
using mean-reverting processes for the underlying dynamics. The set of such models
ranges from random walks to AR models of up to second order. Note that the eﬀect on
sudden shocks or short-term estrangements has not become clear yet when, instead of
data-driven techniques, convergence is postulated in the model’s design stage, as done
in this and other previously mentioned approaches.
Even if Cairns et al. (2011b) apply mostly non-informative priors, the large number of
parameters requires various distribution families, including the Inverse Wishart, Beta,
Gamma, and Gumbel distributions. According to the authors, the model therefore re-
mains sensitive towards the assumptions in the prior distributions and results must be
treated carefully. Apart from this, Cairns et al. (2011b), however, show that the Bayesian
methodology strongly helps in estimating diﬀerent populations jointly, smoothing the
ﬁtted data, and being consistent in the projections. This underlines the appropriateness
of Bayesian approaches in mortality forecasting of more than one population.
Up to this point, as far as I am aware, there is no Bayesian approach for more than two
populations in the framework of stochastic mortality models described in this chapter. It
is worth noticing that Raftery et al. (2013) introduce Bayesian estimation in a stochastic
extension of the so far deterministic mortality projection model by the United Nations.
Using a hierarchical model on innovations in life expectancy, parameters are country-
20

2 Literature on Mortality Forecast Modelling
speciﬁc but follow a common distribution with global hyperparameters, i.e. inference is
based on the aggregate of all information. The Bayesian hierarchy guarantees a certain
degree of coherence, but this approach is far less concerned about common trends or
dependencies between countries because forecasts are still made individually without
any quantiﬁcation of correlation.
21

3 The Bayesian Multi-Population
Mortality Projection Model
As seen in the previous chapter, many achievements have been made in multi-population
mortality projection modelling within the last years. As a consequence, diﬀerent models
allow for a rich set of possibilities in mortality forecasting. Nonetheless, the discussion
has revealed that, in practice, each model has its own limitations. In order to overcome
these shortcomings, a new model is proposed in this chapter. Based on ﬁndings in the
literature review in Chapter 2, it features the Bayesian paradigm to capture both pa-
rameter uncertainty and all sources of prediction errors. Furthermore, the focus is laid
on a ﬂexible framework using the CBD model, allowing for an arbitrary number and
an arbitrary selection of populations. Accordingly, in the remainder of this thesis, the
suggested model is referred to as the Bayesian Multi-Population Mortality Projection
(BMPMP) model. It should be stressed that – as far as I am aware – no such model
approach is found in literature, i.e. the work in this thesis provides substantial contri-
bution to stochastic mortality forecasting. In particular, for the ﬁrst time, the CBD
model is applied in the multi-population framework, and the Bayesian paradigm has not
yet been used for the CBD model or a mortality model with more than two popula-
tions either. This chapter describes the BMPMP model in full detail and is organised
as follows. The ﬁrst section addresses the targets for the new model, motivated by a
summary of shortcomings in established approaches. The actual model itself is deﬁned
and explained in detail in Section 3.2. Next, Bayesian estimation and forecasting of the
model are presented in Sections 3.3 and 3.4, respectively. Section 3.5 summarises the
BMPMP model.
22

3 The Bayesian Multi-Population Mortality Projection Model
3.1 Model Targets
The main objective of the BMPMP model is to stochastically forecast mortality rates for
high ages of an arbitrary number of populations. It must provide biologically plausible
joint predictions for ﬂexible selections of populations. Uncertainty of future mortality
rates and their inter-dependencies shall be coherently quantiﬁed through probability
distributions. The BMPMP model addresses its main targets through a combination of
diﬀerent approaches in model design, estimation, and forecasting.
3.1.1 Limitations in Existing Models
To fulﬁl these targets, a new model is necessary. Clearly, both the LC and CBD frame-
works as well as age-period-cohort models have been successfully proven to be state-
of-the-art in stochastic mortality forecasting. While the ﬁrst two approaches bring the
advantage of interaction between time-dependent improvements in mortality and their
age-dependent weights – and, hence, a principally better ﬁt to historical data over age-
period-cohort models –, it is not necessarily clear which one of the LC and CBD models
is more suitable. A major disadvantage in the LC methodology is a possible lack in
the model ﬁt through an implicit perfect correlation in mortality improvements among
diﬀerent ages. Additionally, the lack of smoothness in the age proﬁles and their non-
identiﬁability w.r.t. time-dependent quantities may cause undesired results. The CBD
model addresses all these issues through its formulation as a generalised linear regression,
but is only applicable with ages above a minimum threshold of at least 40 years. Prob-
lems with a possible lack of ﬁt in CBD models can be reduced by including a quadratic
age eﬀect on mortality rates. The necessity of forecasting the additional coeﬃcient time
series will not be an extra burden in an already multivariate model, when several pop-
ulations need to be analysed. If the modeller is interested in high ages only, which is a
reasonable assumption in the context of many life insurance or other ﬁnancial products,
the CBD model serves as solid foundation in stochastic mortality projections.
Up to this point, the discussion has focussed on the fundamental properties of the
aforementioned mortality projection models w.r.t. the performance in their intended
scope of application: forecasting a single population.
However, the introduction of
this work stressed the increasing necessity to jointly forecast diﬀerent populations to
23

3 The Bayesian Multi-Population Mortality Projection Model
capture common trends and dependencies. Chapter 2 reviewed the extensions of the
LC framework and other approaches to address this task of multi-population forecasts.
However, it turned out that joint prediction models are far less elaborate.
Indeed,
existing models for projections of several populations are limited by at least one of the
following:
• The model is only applicable to a limited number of populations.
• The model design requires determination of dominant and sub-populations.
• Its assumptions exclude certain populations or combinations of populations, e.g.
due to unwanted interaction behaviour in the long-run or the need for a parent
population for at least one of the other populations.
• Underlying dynamics processes must be analysed individually, preventing the frame-
work from universal usage.
• Model forecasts have stable long-run conﬁdence boundaries, which are unreason-
able considering the increase in uncertainty and risks of regime changes in the
future.
• Desired biological plausibility in forecasts is hypothesised in the model design and
does not necessarily stem from historical data.
• Populations to be modelled must have a high quality in mortality data and the
model may require further explanatory covariates.
• The model requires forecasts of other mortality quantities, which are themselves
not easy to handle with.
• The model is not designed for mortality projections.
Based on these points, no such sophisticated tool as in the univariate case to forecast
an arbitrary number of possibly heterogeneous populations exists. Consequently, this
motivates the BMPMP model. The subsequent section is then devoted to how the model
is designed to provide the desired framework in multi-population forecasting, which shall
overcome the aforementioned shortcomings.
24

3 The Bayesian Multi-Population Mortality Projection Model
3.1.2 Beneﬁts of the New Model
Through the ﬂexibility of a generalised linear regression design known from the CBD
framework, the BMPMP model allows to jointly forecast an arbitrary number of more
than two populations at once. Diﬀerences between the distinct populations are accounted
for by speciﬁc main and interaction eﬀects in the linear predictor. This distinguishes
the new approach from the vast majority of projection models, as they are designed
to project the spread between only two populations. The Binomial generalised linear
regression further allows for simple interpretation and adjustments of the main model
equation. The model is only applicable with ages exceeding a minimum threshold of 40
or so years, but has the advantage of immediate smoothing across ages. For an improved
model ﬁt, the numbers of deaths are assumed to follow a Poisson distribution.
It is somewhat diﬃcult to collect consistent explanatory variables on all populations,
particularly when they are not national but portfolio-speciﬁc. It is further non-trivial to
project such covariates into the future, which means that such approach cannot be con-
sidered universal frameworks. Similar arguments apply to models for which forecasts of
other mortality quantities have to be made. By contrast, the BMPMP model is ﬂexible
regarding the requirements w.r.t. the available data. For any population to be included
in the model, it suﬃces to have data on the observed number of deaths and estimates
for the exposure-to-risk for all ages and calendar years under consideration.
The BMPMP model further employs a VECM for the projection of the underlying
dynamics processes. Through its cross-correlation, cointegration, and AR terms, this
data-driven time series model is designed to capture dependencies even between less
connected populations. In contrast to the augmented common factor model by Li and
Lee (2005), which too allows for an unlimited number of populations, the BMPMP model
intends to overcome the problems seen for certain Eastern European countries, whose
long-run behaviour could not be reasonably forecast into the future. Not only must Li
and Lee (2005) exclude certain countries from their analysis, but they further need to
speciﬁcally investigate the marginal time series for all individual countries. The VECM
is more suitable for mortality projection of multiple arbitrary populations, because the
multivariate set-up makes such individual analyses obsolete.
25

3 The Bayesian Multi-Population Mortality Projection Model
Following the arguments in many of the cited studies concerning multi-population fore-
casting, unwanted long-run interactions are given when mortality rates of diﬀerent popu-
lations diverge over time. However, even if it is biologically plausible that mortality rates
converge or keep constant diﬀerences over time, some divergent behaviour, at least in the
short-run, has been observed for several countries in recent years, e.g. in Eastern Europe
in the early 1990s. Furthermore, diseases, natural catastrophes, and wars on the one
hand, as well as medical innovations and improvement on the other, have always caused
random shocks with long-term eﬀects on mortality in certain populations. The multi-
variate VECM approach allows for random shocks via Gaussian noise while maintaining
a non-divergent long-run behaviour through inclusion of an error correction term. This
accounts for cointegration between the univariate time series, i.e. linear combinations of
several populations forming stationary processes, whose information is lost in less data-
driven techniques. Notably, with a deterministic non-divergence hypothesis, as used in
other cited approaches, random shocks might be systematically discounted. Estimation
of the error correction term is driven by the data without formulating any restrictive
hypotheses in order to achieve biological plausibility. Finally, the VECM is also moti-
vated by Zhou et al. (2012), as it avoids any pre-determination of dominant populations.
Motivated by the studies described in Section 2.4, which have proved successful in captur-
ing a variety of systematic and unsystematic risks, e.g. the purely random nature as well
as parameter and prediction uncertainty, the BMPMP model is estimated via Bayesian
statistics. This technique as such makes the approach less sensitive towards deviations
from the Poisson assumption on the number of deaths through possible overdispersion or
omission of cohort eﬀects. A likelihood-based frequentist procedure would again require
a two-step estimation method, where the CBD model is estimated ﬁrst, and then the
VECM is applied with the resulting parameters. This study refrains from this approach,
because frequentist parameter estimates are expected less coherent.
The quantiﬁcation of future uncertainty in the frequentist LC and CBD frameworks
can additionally be criticised for their typically elliptical behaviour, meaning that after
a short time of increasing variability, the conﬁdence boundaries remain stable around
the best estimates. These characteristics are not desirable, as uncertainty w.r.t. future
projection should naturally increase continuously with time to express the diminishing
impact of today’s and past developments on the far-away future. It will be apparent
26

3 The Bayesian Multi-Population Mortality Projection Model
from the case studies in Chapter 4 that the cointegration term in the BMPMP model
introduces more reasonable credibility bands of linearly increasing uncertainty.
As a ﬁnal note, a principal advantage of Bayesian estimation is its ability to handle large
datasets and to deliver solid distributions on global parameters if models are not parsi-
monious or even over-parametrised. Due to the high-dimensionality in multi-population
mortality modelling, the BMPMP model would be restricted to a very small and hence
undesired number of populations with frequentist approaches, even for a relatively large
history of observed mortality data.
3.2 Model Speciﬁcation
By analogy to other stochastic mortality prediction models, the BMPMP model con-
sists of two hierarchical submodels. First, for each calendar year, the state variable is
modelled, which in this instance is done via the CBD approach. Following, the second
step is the projection of obtained model parameters into the future via the VECM. This
section fully describes and motivates both speciﬁcations in the model.
3.2.1 The Cairns-Blake-Dowd Approach
In order to employ the CBD model on the underlying state variables in a multi-population
context, the linear predictor in the regression equation of the original approach must be
amended. To begin with, the CBD model with quadratic term for the age eﬀect and
minimum age x0 is considered, i.e.
log

qxt
1 −qxt

= κ1
t + κ2
t(x −¯x) + κ3
t((x −¯x)2 −bσ2),
x ≥x0,
(3.1)
where Cairns et al. (2009) motivate the quadratic pattern by ﬁndings on U.S. data.
Here, the age x is centred by the average ¯x = n−1
a
P
i xi, where na is the total number
of diﬀerent ages xi under consideration. Similarly, bσ2 = n−1
a
P
i(xi −¯x)2 is the variance
of the ages. It is worth mentioning that for the sake of simplicity and ﬂexibility, the
model does not include additional parameters for, say, cohort eﬀects as proposed by
Cairns et al. (2009). If deviations caused by cohort eﬀects systematically exceed the
pure random noise and cannot be captured by the quantiﬁcation of diﬀerent sources of
27

3 The Bayesian Multi-Population Mortality Projection Model
uncertainty in the Bayesian methodology, an extension of the model, which does include
explicit cohort parameters, is of course possible. Regarding the minimum age x0, this
value should generally not fall below the age of 40. For lower age groups, the linearity
assumption on the logits of mortality rates does generally not hold. In particular, the
CBD approach is not designed to ﬁt the so-called accident bump. However, for many
applications in insurance science, the analysis of mortality rates for people aged 40 or
more is suﬃcient, since life or health insurance contracts are usually concluded just be-
fore that age. The CBD framework is often applied with values like x0 = 50 or x0 = 60
for a better performance, see Cairns et al. (2009) for instance.
So far, for a ﬁxed calendar year t, the according mortality rate only depends on age
through a linear and quadratic term. The BMPMP model additionally assumes that
both the intercept and age eﬀects vary between diﬀerent populations. Mathematically,
these amendments are integrated into the Binomial regression via main eﬀects on the
one, and interactions with the age terms on the other hand. Let np ∈N be the number
of diﬀerent populations for which mortality projections shall be derived. Taking into
consideration the model targets, one assumes without loss of generality (w.l.o.g.) that
np > 1. For some population p with speciﬁc mortality rate qxpt in calendar years t,
model (3.1) is then extended as follows:
log

qxpt
1 −qxpt

= κ0
t + κp
t + (κx
t + κxp
t ) (x −¯x)
+

κx2
t + κx2p
t
  (x −¯x)2 −bσ2
,
x ≥x0.
(3.2)
Notation has slightly changed in order to achieve consistent subscripts for the param-
eters. As x refers to age in this study, the former parameters κ1
t, κ2
t, κ3
t are denoted κ0
t
for the intercept and κx
t , κx2
t
for the linear and quadratic age terms, respectively. The
new population parameters are consistently referred to through the subscript p. The
main eﬀect for population p is κp
t, and κxp
t , κx2p
t
are the interactions with the linear and
quadratic terms for age, respectively.
Since there are parameters for each population, a reference population is needed to
avoid identiﬁability problems. Typically, in most statistical models, one certain pop-
ulation acts as reference by setting the according parameters to zero. Similar to the
28

3 The Bayesian Multi-Population Mortality Projection Model
LC approach, one can also set some constraints, e.g. Pnp
p=1 κp
t = 0 for all t. However,
note that this formula implies that all populations are equally weighted, while parame-
ters should be weighted according to population sizes when realistic weights are desired.
As an alternative, the BMPMP model uses the overall sample p∗, inferred from the
individual populations by simple addition of death and exposure counts, as reference
population. Consequently, the population parameters measure the diﬀerences from av-
erage mortality. The BMPMP model then becomes easily interpretable and, for a large
number of populations, generally more robust due to the borrowing-strength principle.
With the reference population being the overall sample, the number of parameters in-
creases to 3 (np + 1). It is worth mentioning that the CBD equation can be interpreted
hierarchically. For the reference population p∗, it holds that
log

qxp∗t
1 −qxp∗t

= κ0
t + κx
t (x −¯x) + κx2
t
 (x −¯x)2 −bσ2
,
x ≥x0,
(3.3)
and, therefore, the intercept and age parameters can be estimated directly from the
sum of all populations. In a second step, equation (3.2) is applied with each individual
population, given the parameters from (3.3). Throughout this work, the model is set up
by this hierarchical structure.
Model (3.2) is a general framework for np diﬀerent populations that do not overlap. Even
if the model could be applied with populations that are nested, one should then adjust
the linear predictor to avoid incoherence through collinearity. A typical example, which
is discussed in the case studies in Chapter 4, is the comparison of males and females in
several countries. Denoting by p a particular country, for which the term population is
adopted, the new dimension of two genders must be integrated separately, e.g. through
a subscript g. When a main eﬀect and ﬁrst-order interactions with both the age and
country eﬀects are included, the model becomes
log

qxpgt
1 −qxpgt

= κ0
t + κp
t + κg
t + κpg
t + (κx
t + κxp
t + κxg
t ) (x −¯x)
+

κx2
t + κx2p
t
+ κx2g
t
  (x −¯x)2 −bσ2
,
x ≥x0,
(3.4)
where new parameters are labelled by g and their interpretation is straightforward.
With subgroups, the overall samples of both genders are considered ﬁrst, i.e. the main
29

3 The Bayesian Multi-Population Mortality Projection Model
gender and gender-age interaction eﬀects are estimated from the reference population.
Consequently, interactions of gender with individual populations follow in the second
step along with the population-speciﬁc main and age eﬀects.
With np populations,
the number of parameters is then 4np + 6. For a general number of subgroups within
the populations or an alternative consideration of interaction eﬀects, the well-known
generalised linear regression approach allows for easy adjustments.
3.2.2 The Vector Error Correction Model
The aim of the second stage in the BMPMP model is to forecast the parameters from
the CBD model w.r.t. time. In the standard version of the CBD model as in (3.1),
one obtains a three-dimensional time series, in which univariate time series contain the
intercepts and both linear and quadratic age eﬀects. The model is usually forecast via
Box-Jenkins approaches, e.g. by applying VAR models or, for the sake of convenience,
univariate time series models to each marginal parameter type. However, due to the
extensively increased number of parameters in the BMPMP model, special care must be
devoted to the choice of the time series model for forecasts. The general framework of
standard Vector Autoregressive Moving Average (VARMA) models in the Box-Jenkins
methodology still remains one of the most reasonable choices due to Wold’s Decomposi-
tion Theorem, as reviewed in Appendix C.1.
Based on ﬁndings of mortality forecast models in the literature, it can be expected
that the intercept and main age eﬀects show a trend-stationary behaviour over time.
Assuming that all other population- or subgroup-speciﬁc parameters are not of higher
integration order, it seems plausible to concentrate on multivariate time series models for
the ﬁrst diﬀerences. Motivated by fundamental results in multivariate time series given
in Appendix C, under regular conditions such as non-explosive behaviour, a ﬁnite VAR
representation without moving average (MA) terms is a reasonable approach. However,
ﬁrst-order diﬀerencing in VAR models is substantially diﬀerent from what is known from
the univariate case of AR models. Starting with a VAR model of lag order k, which
includes non-stationary time series, the reverse characteristic polynomial for unit root
detection is now a matrix-valued function. Whereas in the univariate case, the number
of unit roots reveals the order of integration, the multivariate case allows the marginal
time series to have integration order strictly less than the number of unit roots. In this
30

3 The Bayesian Multi-Population Mortality Projection Model
case, the unsophisticated technique of marginally diﬀerencing the univariate time series
of the CBD parameters can distort possible stationarity of long-run relationships among
the marginals. As explained in Appendix C.2 in more detail, marginal time series may
not be stationary, although linear combinations of them can still be. Such time series are
said to be cointegrated. In particular, combinations of the intercept and the main eﬀect
for females or between diﬀerent populations-speciﬁc parameters are expected to have
a stable equilibrium. In Appendix C.3, it is shown that information on cointegration
in a VAR model carries over to a singular matrix, which is obtained by evaluation of
the characteristic polynomial at 1. It is derived how diﬀerencing the vector-valued time
series indeed leaves this matrix – which will later be denoted as Π – as an additional pa-
rameter in the equation for ﬁrst diﬀerences, in contrast to loosing this information when
marginally diﬀerencing the individual time series. The resulting model of correct ﬁrst
diﬀerences is the VECM, and starting with this representation of a VAR model is always
a valuable approach, as described in Appendix C.3. The analysis of cointegrated VAR
models goes back to a series of pioneering papers, starting with the work by Granger
(1981), and further exploration by Engle and Granger (1987) with much contribution
from several authors in the years thereafter. Most notably, Johansen (1988, 1991) and
Johansen and Juselius (1990, 1992) develop an ML estimation framework, referred to
as the Johansen procedure, which is widely used nowadays. A thorough overview on
the VECM can be found in Johansen (1995) and L¨utkepohl (2007), for instance. Ap-
pendix C reviews all necessary preliminaries.
Mathematically, the VECM can be deﬁned in diﬀerent but equivalent formulations. In
the following, the transitory version of the cointegrated VAR is described, where for the
alternative long-run speciﬁcation, the reader is referred to the appendix or the literature
cited above. Let K be the multivariate time series of all unknown parameters with values
κt = (κ0
t, κx
t , κp1
t , κp2
t , . . . ) for t = 1, . . . , T, with T being the number of calendar years
for which CBD models are run. With m ∈N one denotes the dimension of the time
series, which automatically coincides with the number of parameters in each CBD model
from the previous section. The according time series of ﬁrst-order diﬀerences κt −κt−1
is of length T −1 and denoted by ∆κt. The VECM of order k ∈N with initial values
31

3 The Bayesian Multi-Population Mortality Projection Model
κ1, . . . , κk is
∆κt = φDt +
k−1
X
i=1
Γi∆κt−i + αβ′κt−1 + εt,
t = k + 1, . . . , T,
(3.5)
or, equivalently,
κt = φDt +
k−1
X
i=1
Γi∆κt−i + (Im + αβ′) κt−1 + εt,
t = k + 1, . . . , T,
(3.6)
with Im being the m × m identity matrix. The error terms εt are independent and iden-
tically distributed (iid) multivariate normal distributed with zero mean and covariance
matrix Ω∈Rm×m. A vector of time-varying constants Dt with some ﬁxed dimension
d ∈N enables the user to include deterministic, e.g. linear or seasonal, trends. This
inﬂuence is measured by the according parameter matrix φ ∈Rm×d. For the BMPMP
model, the VECM with time-consistent Dt = 1 and d = 1 is applied. Further parameters
are the k −1 AR coeﬃcient matrices Γi ∈Rm×m, which describe the impact of recent
changes in κ on the current diﬀerence. Adjustment of k obviously leads to diﬀerent
time horizons, and, in particular, the VECM of order 2 is second-order Markovian and
excludes any history before the previous change in the time series. Finally, the cointegra-
tion term is of special interest, as the current change ∆κt also depends on the according
starting point κt−1 through the parameter matrix Π := αβ′ ∈Rm×m, which is assumed
to have rank r ∈{0, 1, . . . , m}. The matrix Π is decomposed into the matrices α and
β, which are both of dimension m × r with full rank r. For β, the upper r × r block
matrix is assumed to be the identity matrix such that a unique representation of Π is
obtained. The decomposition of Π allows for the following interpretations. First, β′κt−1
represents a new r-dimensional time series containing diﬀerent linear combinations of
the univariate time series in κ. The VECM assumes that these univariate time series are
stationary; therefore, the original time series is said to be cointegrated of rank r. Second,
the parameters in α then explain to what extent these derivations of the current level
in κ govern ∆κt. It is worth mentioning that, similar to the order k, the cointegration
rank r is generally not known and must be additionally estimated.
32

3 The Bayesian Multi-Population Mortality Projection Model
It is convenient to formulate the model in (3.5) with Dt = 1 and d = 1 in the compact
matrix form
∆K = Φ + ΓK2 + αβ′K1 + ε
(3.7)
with m × T −k matrices Φ = (φ, . . . , φ), ∆K = (∆κk+1, . . . , ∆κT), K1 = (κk, . . . , κT−1),
ε = (εk+1, . . . , εT), an m × (k −1)m matrix Γ = (Γ1, . . . , Γk−1), and a (k −1)m × T −k
matrix
K2 =

(∆κ′
k, . . . , ∆κ′
2)′ ,
 ∆κ′
k+1, . . . , ∆κ′
3
′ , . . . ,
 ∆κ′
T−1, . . . , ∆κ′
T−k+1
′
.
In this representation, the t-th columns of both matrices on the left- and right-hand side
belong to the vectorised form of the VECM at time t. Model equation (3.7) is less in-
terpretable than the previous one; however, it is more useful w.r.t. theoretical results in
Bayesian statistics. The set of underlying hyperparameters {φ, Γ, α, β, Ω} is abbreviated
by H for convenience. The decomposition of β is written as β = (Ir, β′
l)′ with the lower
block matrix βl ∈R(m−r)×r. Under this so-called linear normalisation, one can write
β = c + c⊥βl with c = (Ir, 0r×m−r)′ ∈Rm×r and c⊥= (0m−r×r, Im−r)′ ∈Rm×(m−r).
Summarising, models (3.4) and (3.5) establish the BMPMP approach introduced in this
study.
Bayesian methods are used to estimate all parameters in both models; they
will be explained in the following section. The only exceptions are the lag order and the
cointegration rank, which are assumed to be known beforehand. The according variables
k and r are left open such that the analyst can specify the quality ﬁt through two single
adjustment parameters.
3.3 Bayesian Estimation
Similar to other approaches in mortality forecasting, the BMPMP model consists of two
model equations. In the ﬁrst stage, mortality data are modelled separately for each
calendar year, where the second stage introduces the time dimension in that parame-
ters are regarded realisations from stochastic processes. Whereas ML methods usually
estimate the parameters subsequently, the Bayesian approach allows for a one-step esti-
mation method, which has positive impact on coherence between parameters. Diﬀerent
33

3 The Bayesian Multi-Population Mortality Projection Model
sources of risk, due to pure randomness, estimation errors, or future regime changes, are
speciﬁcally accounted for by the likelihood, prior distributions, and posterior predictive
methods, respectively. This section describes the Bayesian estimation procedure for the
BMPMP model in detail. First, the likelihood for the underlying mortality data as well
as the prior distributions for all parameters of the previous section are determined. Then
the posterior distributions with according simulation algorithms are derived. For this
section, the reader is expected to bring a broad understanding of principals in Bayesian
methodology. Otherwise, Appendix A provides a suﬃcient introduction to this topic
based on the standard textbook by Gelman et al. (2013).
3.3.1 Likelihood for the Underlying Data
Following Appendix A, Bayes’ Theorem plays a central role in Bayesian estimation.
Prior distributions for model parameters are updated to posterior distributions through
information of the underlying observations, which in this context are the number of
deaths and according exposure-to-risk for all ages, populations, and calendar years under
consideration. The typical notation from the previous chapter is expanded w.r.t. the
additional population dimension, i.e. as Dxpt and Expt are denoted the number of deaths
and the exposure-to-risk for age x, population p, and calendar year t. Due to the common
assumption of a constant force of mortality as in Cairns et al. (2009), it is then assumed
that
Dxpt ∼Poi (mxptExpt) ,
thereby following the arguments of Czado et al. (2005) that a Poisson distribution best
expresses the natural mortality behaviour. From (2.1) it follows that
Dxpt ∼Poi (−log (1 −qxpt) Expt) .
(3.8)
As usual, the numbers of deaths are furthermore assumed independent between diﬀerent
ages, populations, and calendar years. It is worth mentioning that (3.8) is additionally
assumed to hold for the reference population p∗with some sample mortality rate qxp∗t,
number of deaths Dxp∗t = P
p̸=p∗Dxpt and exposure-to-risk Exp∗t = P
p̸=p∗Expt. Inde-
pendence is still assumed to hold for diﬀerent ages and calendar years; however, there is
clearly a strong dependence on the individual subpopulations. The mortality rate qxpt
34

3 The Bayesian Multi-Population Mortality Projection Model
is the response variable in the CBD model, and some algebra gives that
qxpt =
exp (ηxpt)
1 + exp (ηxpt),
where ηxpt denotes the linear predictor, i.e. the right-hand side of equation (3.2). Sub-
stituting this expression into (3.8) reveals
Dxpt ∼Poi (log (1 + exp(ηxpt)) Expt)
and leads to the likelihood
L (K | Dxpt, Expt)
= P (Dxpt | K, Expt)
=
1
Dxpt! (mxptExpt)Dxpt exp (−mxptExpt)
= EDxpt
xpt
Dxpt! [log (1 + exp(ηxpt))]Dxpt exp (−log (1 + exp(ηxpt)) Expt)
∝[log (1 + exp(ηxpt))]Dxpt (1 + exp (ηxpt))−Expt ,
where L indeed depends on K through the linear predictor ηxpt. Let now
D = {Dxpt ∀x, p, t, p ̸= p∗},
E = {Expt ∀x, p, t, p ̸= p∗}
be the sets of all individually observed data for the numbers of deaths and exposure-to-
risk, respectively. Since all Dxpt in D are mutually independent, one can also write more
compactly
L (K | D, E)
= P (D | K, E)
=
Y
x
Y
p
Y
t
P (Dxpt | K, Expt)
∝
Y
x
Y
p
Y
t

[log (1 + exp(ηxpt))]Dxpt (1 + exp (ηxpt))−Expt
.
35

3 The Bayesian Multi-Population Mortality Projection Model
3.3.2 Prior Distributions
Apart from the ﬁrst k calendar years, prior distributions for the parameters K in the
CBD equations are iteratively given by the dynamics process, i.e.
κt | κt−k, . . . , κt−1, H, k, r ∼Nm
 
φ +
k−1
X
i=1
Γi∆κt−i + (Im + αβ′) κt−1, Ω
!
for t = k + 1, . . . , T, where Nm denotes the m-variate normal distribution. The pa-
rameters κ1, . . . , κk require own prior distributions, as there are not suﬃciently many
preceding values available for the AR part. For all values but the ﬁrst, a possible choice
would be the above normal prior based on the VECM representation restricted to the
available history. However, the missing information on history in these cases alter the
conditional assumptions and interpretation, which may introduce bias. To avoid such
problems, for the ﬁrst k values, an m-variate normal distribution with ﬁxed mean vectors
µt and m × m covariance matrices Σt, respectively, i.e.
κt | k ∼Nm (µt, Σt) ,
t = 1, . . . , k,
(3.9)
is suggested. Ideally, these moments are determined based on prior beliefs or experience.
If this is not possible, mean and variance can be estimated from the underlying data.
Due to similar magnitudes in variability, it is reasonable to use one constant covariance
matrix Σ = Σ1 = · · · = Σk. However, even if such a so-called empirical Bayes approach
is practicable, it should be noted that, in general, data should not inﬂuence the prior
assumptions on the distributions of parameters due to the Bayesian paradigm.
Regarding the hyperparameters φ, Γ, α, β, Ωof the underlying dynamics process, priors
for the VECM are needed. Since the cointegration parameters α and β multiplicatively
aﬀect one another, Bayesian analysis is not straightforward. Several approaches have
been suggested since the 1990s, which aim to overcome possible problems with inconsis-
tency as well as local and global identiﬁcation issues. Particular attention must be given
to the choice of the prior for the cointegration term, as supposedly non-informative priors
turn out to distribute probability mass in an unreasonable way in the so-called cointegra-
tion space, i.e. the space spanned by the columns of β. However, a well-deﬁned uniform
prior over this space is introduced via the Grassman approach due to Villani (2005). The
36

3 The Bayesian Multi-Population Mortality Projection Model
BMPMP model incorporates the prior by Warne (2006), a slightly generalised version of
the standard Grassman prior by Villani (2005). The remainder of this section is devoted
to the speciﬁc formulation of this prior and its marginal distributions in the context of
the BMPMP model. Appendix C.5 provides a detailed discussion of Bayesian techniques
and their challenges in the context of the VECM. It particularly motivates the Grassman
approach through a discussion of theoretical background on cointegration spaces. For
an even more general overview on diﬀerent Bayesian approaches to cointegration and
the Grassman approach, the reader is referred to Koop et al. (2006) and Villani (2005),
respectively.
The general reference prior due to Warne (2006) is
f (φ, Γ, α, β, Ω| k, r)
= cr |Ω|−(m+q+r+1)/2 exp

−1
2 tr

Ω−1

A + 1
λ2
α
αβ′βα′

f (Γ | Ω, k)
(3.10)
with constants λα > 0, q ≥m, and a positive deﬁnite matrix A ∈Rm×m, and applies
to the hyperparameters given that the lag order k and cointegration rank r are ﬁxed.
Here, tr (M) denotes the trace of a quadratic matrix M, i.e. the sum over all diagonal
elements. The normalising constant cr is
cr = |A|q/2
Γr (m)
Γm (q) Γr (r)
2−qm/2π−m(m−1)/4
(2πλ2
α)mr/2 π(m−r)r/2,
where Γb (a) for a, b ∈N0 with a ≥b is a generalised form of the Gamma function as
deﬁned in Deﬁnition D.1. It is worth mentioning that f is an improper density function,
as it remains constant for diﬀerent values for φ. When the marginal prior for Γ | Ω, k is
chosen to be constant, too, (3.10) yields the original reference prior by Villani (2005).
This work adopts the generalisation by Warne (2006), who deﬁnes a proper distribution
for f (Γ | Ω, k) in a similar manner as the classical Minnesota prior for AR terms in
VAR models. For constants λb, λl > 0, deﬁne the diagonal m(k −1) × m(k −1) matrix
ΩΓ = diag
 ΩΓ1, . . . , ΩΓk−1

through the k −1 block matrices
ΩΓi = λ2
b
i2λl Im,
i = 1, . . . , k −1,
37

3 The Bayesian Multi-Population Mortality Projection Model
of dimension m × m, respectively. Then Warne (2006) lets Γ | Ωbe Matrix-Normal
distributed with
Γ | Ω, k ∼MNm(k−1)×m (0, ΩΓ, Ω) ,
(3.11)
see Deﬁnition D.4. As outlined in the appendix, it holds for the vectorisation of Γ | Ω
that
vec (Γ) | Ω, k ∼Nm2(k−1) (0, Ω⊗ΩΓ) ,
where vec(·) and ⊗are the vectorisation and Kronecker matrix product operators deﬁned
in Appendix D.2. Obviously, Γ is conditionally independent of α, β, φ given Ω, r, k. The
generalisation by Warne (2006) hence does not distort the results by Villani (2005) for
f (Γ | Ω) = 1 and, consequently, for the marginal distribution of Ω, it follows that
Ω∼IWm (A, q) ,
where IWm denotes the Inverse Wishart distribution, see Deﬁnition D.7. In Bayesian
methodology, it is common to formulate probabilistic statements about variance param-
eters by their inverse, the so-called precision, i.e. Ω−1 has the conjugate m-dimensional
Wishart prior from Deﬁnition D.6 with parameters A and q. Moreover, for the proﬁle
matrix α, the conditionally marginal prior is Matrix-normal with
α | β, Ω, r ∼MNm×r

0, λ2
aΩ, (β′β)−1
or, equivalently,
vec (α) | β, Ω, r ∼Nmr

0, (β′β)−1 ⊗λ2
αΩ

.
For the lower block matrix βl of β = (Ir, β′
l)′, it further holds that
βl | r ∼Mt(m−r)×r (0, Im−r, Ir, 0) ,
where Mt denotes the Matrix-t distribution as in Deﬁnition D.5. In addition to these
marginal results derived by Villani (2005), it is shown by Warne (2006) that the marginal
38

3 The Bayesian Multi-Population Mortality Projection Model
prior for Γ is also Matrix-t distributed with
Γ ∼Mtm×m(k−1)
 0, A−1, ΩΓ, q −m

.
The marginal distributions show that the constants A and q determine the prior for
Ωand α. For q ≥m + 2, Villani (2005) shows that E (Ω) = (1/ (q −m −1)) A, and
hence, for given A, the uncertainty about unexplained variability in the model decreases
in q, because the expected error covariance matrix converges to the zero matrix. The
constant λα aﬀects the uncertainty of α, since its columns have zero mean and covari-
ance matrices λ2
α E (Ω). A larger value therefore implies larger uncertainty. Since the
magnitude of this covariance matrix depends on the expected value of Ω, Villani (2005)
suggests to determine A and q ﬁrst and to adjust λα in a second step. For the prior
assumptions on Ω, the analyst needs to quantify the expected variances and, to be more
informative, also covariances for the latent time series a priori, which will generally be
hard to conceive. It is hence practicable to use an empirical Bayes approach based on
an ML estimate such as A = fA(bΩ), where fA is a tuning function for the modeller, and
bΩcan be the empirical covariance matrix of the time series in levels or, if there is too
much variability, the corresponding covariance matrix for the time series in diﬀerences.
A particular choice could be fA(M) = (λ2
Am2
ij)ij for a square matrix M = (mij)ij with
some tuning factor λA > 0. In either case, one should use the minimum value q = m+2
for maximum uncertainty in order to reduce the eﬀect of such an improper data-driven
technique. Another choice for the ﬁrst two constants, found in the literature, is A = 0
and q = 0, which yields an uninformative diﬀuse marginal prior for Ω.
In light of
the Minnesota prior for AR coeﬃcients, the remaining constants λb and λl determine
the uncertainty in the parameters Γ1, . . . , Γk−1, because Warne (2006) shows that it is
E(Γ) = 0 for q ≥m + 1 and Cov(vec(Γ)) = ΩΓ ⊗E(Ω) for q ≥m + 2. The uncertainty
in Γ is hence driven by ΩΓi for i = 1, . . . , k −1, whose overall magnitude is given by the
baseline constant λb for given E(Ω), whereas the lag constant λl measures the shrinkage
towards the zero covariance matrix and, hence, to more certainty about vanishing AR
coeﬃcients with increasing order. Due to the dependence on the expected value of Ω,
these two constants should be determined along with λα. For parsimony in the model,
the chosen prior for Γ | Ωimplies conditional independence between the diﬀerent Γi, but
through inclusion of further constants, the prior could be even more generalised to allow
for dependence between the AR matrices. The above prior and its parametrisation are
39

3 The Bayesian Multi-Population Mortality Projection Model
motivated and interpreted in more detail by Villani (2005) and Warne (2006).
As a ﬁnal note, the prior for H has so far been conditional on ﬁxed values for k and
r.
As outlined in Appendix C.4, it is common to determine these values in a ﬁrst
step using, e.g., information criteria or subsequent hypothesis tests.
In a Bayesian
framework, k and r should also be considered random and chosen based on a posterior
distribution that is driven by the data and prior beliefs. Since both constants aﬀect
the number of hyperparameters in H, direct evaluation of these values along with all
other hyperparameters is diﬃcult. Villani (2005) assumes that the lag order k is either
known or determined via fore-run Bayesian approaches – see the paper for references.
The cointegration rank r can also be pre-determined through an individual Bayesian
analysis, but Villani (2005) shows how to compute posterior probabilities for r replacing
the prior in (3.10) by
f (φ, Γ, α, β, Ω| k) = f (φ, Γ, α, β, Ω| k, r) f (r | k)
with a prior f (r | k) over all possible cointegration ranks r = 0, 1, . . . , m. The approach
requires computation of the marginal likelihoods P(D | E, r) for all r = 0, . . . , m, and
apart from the cases r = 0 and r = m, these distributions can only be approximated via
the MCMC results under corresponding speciﬁcation of r. Using a joint prior f(k, r)
instead of f (r | k), Warne (2006) extends this approach to posterior evaluation of all
possible pairs (k, r), which additionally requires numerical evaluation of the marginal
likelihoods P(D | E, k, r).
Due to the high-dimensionality of the time series under
consideration, such approaches are not yet feasible in reasonable time. In fact, possible
values for k are principally restricted to 0 or 1, since operations regarding the matrix Γ
become intractable. For simplicity, the value of r will also be assumed known, although
a posterior analysis as outlined in the above references is possible when the model is
estimated parallel for diﬀerent r.
3.3.3 Posterior Distributions
The aim of the Bayesian estimation procedure for the BMPMP model is to identify joint
posterior distributions for the parameters K and the hyperparameters H. Due to the
complexity in both the prior distributions and likelihood, no closed-form results on joint
40

3 The Bayesian Multi-Population Mortality Projection Model
posterior distributions can be derived. However, MCMC methods are applied in the
context of the BMPMP model in order to approximate the distribution. As described
in Appendix B in more detail, the general idea is to run sampling algorithms, which it-
eratively simulate new realisations of the posterior distribution for the parameters. For
the BMPMP model, both the Gibbs and Metropolis-Hastings algorithms from Appen-
dices B.2 and B.3 are used. Due to the high-dimensional complexity in the BMPMP
model, emphasis must be given to a careful empirical diagnosis of convergence to the
desired limiting distribution in the Markov chain, see Appendix B.4 for details.
First, simulation of the hyperparameters in H is examined. In the Bayesian VECM esti-
mation via the Grassman approach by Villani (2005) and its extension by Warne (2006),
it is possible to derive marginal posterior distributions for each hyperparameter given
all other parameters. The existence of full conditional distributions therefore allows for
applying the Gibbs sampler. In each step i, one has to simulate from the following
distributions given the current realisations for the other parameters. Beginning with the
outcomes from the last step i −1, denoted by the respective superscripts, each hyper-
parameter is visited individually, and a new realisation with superscript i is simulated.
For hyperparameters that have already been visited, the new state of the chain is used
in the successive simulations of other hyperparameters. For theoretical and practical
details of Gibbs sampling, the reader is referred to Appendix B.2.
To begin with, the new realisation Ω(i) for Ωis drawn from the marginal posterior
distribution
Ω| φ(i−1), Γ(i−1), α(i−1), β(i−1), K(i−1), k, r ∼IWm

S(i)
Ω, nΩ

,
where
S(i)
Ω= ε(i−1)ε(i−1)′ + A +
 1/λ2
α

α(i−1)β(i−1)′β(i−1)α(i−1)′ + Γ(i−1)Ω−1
Γ Γ(i−1)′,
nΩ= T −k + q + r + m(k −1),
ε(i−1) = (∆K)(i−1) −Φ(i−1) −Γ(i−1)K(i−1)
2
−α(i−1)β(i−1)′K(i−1)
1
.
41

3 The Bayesian Multi-Population Mortality Projection Model
Next, φ(i) is drawn through simulation of
φ | Ω(i), Γ(i−1), α(i−1), β(i−1), K(i−1), k, r ∼Nm

µ(i)
φ , Ω(i)
,
where
µ(i)
φ =
T
X
t=k+1
 
∆κ(i−1)
t
−
k−1
X
j=1
Γ(i−1)
j
∆κ(i−1)
t−j
−α(i−1)β(i−1)′κ(i−1)
t−1
!
is the vector resulting from row-wise summation over the matrix
(∆K)(i−1) −Γ(i−1)K(i−1)
2
−α(i−1)β(i−1)′K(i−1)
1
.
The i-th realisation for Γ is simulated from a Matrix-normal distribution, which can be
expressed through the vectorisation operator in terms of a multivariate normal distribu-
tion. In particular,
vec (Γ) | Ω(i), φ(i), α(i−1), β(i−1), K(i−1), k, r ∼Nm2(k−1)

µ(i)
Γ , Σ(i)
Γ

,
where
µ(i)
Γ = vec

(∆K)(i−1) −Φ(i) −α(i−1)β(i−1)′K(i−1)
1

K(i−1)′
2
×

K(i−1)
2
K(i−1)′
2
+ Ω−1
Γ
−1
and
Σ(i)
Γ =

K(i−1)
2
K(i−1)′
2
+ Ω−1
Γ
−1
⊗Ω(i).
The new value for α is obtained through its vectorised form via
vec (α) | Ω(i), φ(i), Γ(i), β(i−1), K(i−1), k, r ∼Nmr
 µ(i)
α , Σ(i)
α

,
42

3 The Bayesian Multi-Population Mortality Projection Model
where
µ(i)
α = vec
"
(∆K)(i−1) −Φ(i) −Γ(i)K(i−1)
2

K(i−1)′
1
β(i−1)
×

β(i−1)′

K(i−1)
1
K(i−1)′
1
+ 1
λ2
α
Im

β(i−1)
−1#
and
Σ(i)
α =

β(i−1)′

K(i−1)
1
K(i−1)′
1
+ 1
λ2
α
Im

β(i−1)
−1
⊗Ω(i).
Finally, the vectorised lower block matrix vec (βl) has the conditional posterior distri-
bution
vec (βl) | Ω(i), φ(i), Γ(i), α(i), K(i−1), k, r ∼Nr(m−r)

µ(i)
βl , Σ(i)
βl

,
where
µ(i)
βl = Σ(i)
βl (Ir ⊗c⊥)′ 
Σ(i)
β
−1 
µ(i)
β −vec (c)

,
Σ(i)
βl =

(Ir ⊗c⊥)′ 
Σ(i)
β
−1
(Ir ⊗c⊥)
−1
,
µ(i)
β = Σ(i)
β vec

K(i−1)
1

(∆K)(i−1) −Φ(i) −Γ(i)K(i−1)
2
′  Ω(i)−1 α(i)

,
Σ(i)
β =

α(i)′  Ω(i)−1 α(i)
⊗

K(i−1)
1
K(i−1)′
1
+ 1
λ2
α
Im
−1
.
Now all ﬁve hyperparameters are updated, where for Γ, α, and β, the stacked vectors
must be rearranged into matrix format again. The conditional posteriors require sim-
ulations from the Inverse Wishart and the multivariate Normal distributions, both of
which are easily available in statistical standard software.
43

3 The Bayesian Multi-Population Mortality Projection Model
With the new states for the hyperparameters at hand, in the second step, the old reali-
sations for the parameters in K(i−1) must be replaced. Due to the dependencies between
diﬀerent κt resulting from the underlying dynamics process, full conditionals cannot be
derived for these parameters, making the Gibbs sampler intractable. Consequently, the
Metropolis-Hastings algorithm is applied with the parameters from the CBD model. The
remainder of this section derives the particular algorithm in the context of the BMPMP
model, where general theoretical and practical details on Metropolis-Hastings sampling
are reviewed in Appendix B.3. For a ﬁxed calendar year t ∈{1, . . . , T}, let
K−t = {κ1, . . . , κt−1, κt+1, . . . , κT} ,
Dt = {Dxpt ∀x, p, p ̸= p∗} ,
Et = {Expt ∀x, p, p ̸= p∗} .
From Bayes’ Theorem it then follows that
f (κt | D, E, H, K−t, k, r) ∝f (D | E, K, k, r) f (κt | H, K−t, k, r) .
Due to (3.8), the underlying data Dt for one calendar year t depend on the mortality
rate qxpt only, which itself is purely described by κt. Using the mutual independence of
the numbers of deaths among diﬀerent calendar years, it holds for the likelihood – when
interpreted as a function in κt – that
f (D | E, K, k, r)
∝f (Dt | Et, Kt, k, r)
∝
Y
x
Y
p
[log (1 + exp(ηxpt))]Dxpt (1 + exp (ηxpt))−Expt ,
where dependence on κt is captured by ηxpt. For the conditional distribution of κt |
H, K−t, k, r, it follows from the VECM representation that κt with t > k depends only
on the k preceding values through κt = φ + (Im + αβ′)κt−1 + Pk−1
i=1 Γi∆κt−i + εt. Of
course, no preceding values but marginal priors are given for κ1, . . . , κk. The conditional
44

3 The Bayesian Multi-Population Mortality Projection Model
distribution for any κt can be most generally written as
f (κt | H, K−t, k, r)
= f (K, H, k, r)
f (K−t, H, k, r)
∝f (K, H, k, r)
∝f (K | H, k, r)
= f (κT | K−T, H, k, r) f (K−T, H, k, r)
= f (κT | K−T, H, k, r) f (κT−1 | κ1, . . . , κT−2, H, k, r) f (κ1, . . . , κT−2, H, k, r)
= . . .
=
TY
s=k+1
f (κs | κ1, . . . , κs−1, H, k, r) f (κ1, . . . , κk, H, k, r)
∝
TY
s=k+1
f (κs | κs−k, . . . , κs−1, H, k, r)
k
Y
s=1
f (κs) .
Using the residuals εs = κs −φ−(Im + αβ′) κs−1 −Pk−1
i=1 Γi∆κs−i, s = k +1, . . . , T, from
this general result it follows
f (κt | H, K−t, k, r) ∝
k+t
Y
s=k+1
f (κs | κs−k, . . . , κs−1, H, k, r) f (κt)
∝exp
 
−1
2
 k+t
X
s=k+1
ε′
sΩ−1εs + (κt −µt)′ Σ−1
t
(κt −µt)
!!
for t = 1, . . . , k,
f (κt | H, K−t, k, r) ∝
k+t
Y
s=t
f (κs | κs−k, . . . , κs−1, H, k, r)
∝exp
 
−1
2
k+t
X
s=t
ε′
sΩ−1εs
!
45

3 The Bayesian Multi-Population Mortality Projection Model
for t = k + 1, . . . , T −k, and
f (κt | H, K−t, k, r) ∝
TY
s=t
f (κs | κs−k, . . . , κs−1, H, k, r)
∝exp
 
−1
2
T
X
s=t
ε′
sΩ−1εs
!
for t = T −k + 1, . . . , T. Combining the results for the likelihood and the conditional
distribution ﬁnally leads to
f (κt | D, E, H, K−t, k, r)
∝exp
"X
x
X
p
[Dxpt log (log (1 + exp(ηxpt))) −Expt log (1 + exp(ηxpt))]
#
×























exp
 
−1
2
 k+t
X
s=k+1
ε′
sΩ−1εs + (κt −µt)′ Σ−1
t
(κt −µt)
!!
,
t ≤k
exp
 
−1
2
k+t
X
s=t
ε′
sΩ−1εs
!
,
k < t ≤T −k
exp
 
−1
2
T
X
s=t
ε′
sΩ−1εs
!
,
t > T −k
.
As mentioned earlier, the constants Σ1, . . . , Σk may equal one constant covariance matrix
Σ. Direct sampling from this distribution is not straightforward, hence the Gibbs sampler
is not available for updating the CBD parameters. Instead, the Metropolis-Hastings
sampling is applied, where at step i, the algorithm walks through all calendar years t as
follows.
• Generate a candidate
κ∗
t ∼Nm

κ(i−1)
t
, ΣMH

(3.12)
with positive deﬁnite covariance matrix ΣMH, which is known beforehand or de-
termined within the burn-in period of the MCMC algorithm.
46

3 The Bayesian Multi-Population Mortality Projection Model
• Compute the acceptance probability
a

κ(i−1)
t
, κ∗
t

= min


1,
f

κ∗
t | D, E, H(i), K(i−1/i)
−t
, k, r

f

κ(i−1)
t
| D, E, H(i), K(i−1/i)
−t
, k, r



.
Note that the fraction is computable since the unknown proportionality factors
cancel out. The updates are made conditional on
K(i−1/i)
−t
=
n
κ(i)
1 , . . . , κ(i)
t−1, κ(i−1)
t+1 , . . . , κ(i−1)
T
o
of all other parameter realisations from the last or, if already updated in step
i, from the current iteration, as well as conditional on the fresh values H(i) =

φ(i), α(i), β(i), Γ(i), Ω(i)	
for the hyperparameters.
Details are provided in Ap-
pendix E.2.
• Generate a random probability u ∼U ([0, 1)).
If u ≤a

κ(i−1)
t
, κ∗
t

then set
κ(i)
t
= κ∗
t, otherwise let κ(i)
t
= κ(i−1)
t
.
If m is large, the Metropolis-Hastings algorithm may work ineﬃciently due to poor
multivariate proposals κ∗
t, which result in low acceptance rates. In order to increase
the number of movements in the Markov chain, it is suggested to split the parameters
κ∗
t into single or groups of elements, for which the algorithm is then applied individ-
ually. This simpliﬁcation is known as single-component Metropolis-Hastings algorithm,
see Gilks (2005) for instance. In addition, as discussed in Appendix E.3, it is numeri-
cally advantageous. The covariance matrix ΣMH for the proposal distribution may be
chosen as a diagonal matrix with one unique entry or, due to diﬀerent magnitudes in the
univariate time series, may depend on the diﬀerent parameters. A well-working choice
is to set ΣMH = cMHA, for which the diﬀerent magnitudes are captured by the constant
A, and tuning of the acceptance rates is further achieved through manipulation of the
factor cMH. The single-component Metropolis-Hastings algorithm simply extracts the
diagonal entries as marginal variances.
Initial values for K in the MCMC algorithm are their corresponding ML estimates from
the CBD model, such that convergence can be expected to be reached faster with a much
shorter burn-in period. Note that the CBD model is a Binomial generalised linear re-
47

3 The Bayesian Multi-Population Mortality Projection Model
gression with Dxpt events out of Expt trials and link function mxpt 7→log (exp(mxpt) −1),
comprising the logit link for qxpt as in (3.2) and the relation between qxpt and mxpt given
by (2.1). For the hyperparameters, reasonable starting values are A for Ωas well as the
m × r matrix (Ir, 0r×m−r)′ for β. Furthermore, it is set Γ(0) = 0 ∈Rm×(k−1)m, α(0) = 0 ∈
Rm×r and φ(0) = 0 ∈Rm.
As a summary, an MCMC method, which combines both the Gibbs and the Metropolis-
Hastings algorithms, is applied with Bayesian parameter estimation in the BMPMP
model. Implementation is straightforward, whereas this procedure may be time-con-
suming when the number of populations becomes large. Following Geweke (1996), the
Gibbs sampling technique for the hyperparameters of the VECM, based on the reference
prior by Villani (2005), meets the minimum conditions to guarantee theoretical conver-
gence. Due to the normality assumption in the VECM and the normality of the proposal
values for the parameters K, ergodicity can further be established for the Metropolis-
Hastings algorithm using statements on suﬃcient conditions as in Robert and Casella
(2004). Despite the theoretical results, whether or not practical convergence has hap-
pened must be assessed by the results from the procedure as outlined in Appendix B.4.
An example follows in the next chapter.
3.3.4 Weighted Posterior
In case of large values for the time horizon T or the number of populations np, a very large
amount of observations is supposed to be ﬁtted by a comparably easy model framework.
Low magnitudes for both the likelihood and priors for the time series parameters cause
the posterior distribution for K to be almost degenerate, i.e. probability mass for some
κt is highly concentrated around one point with vanishing variance. This result stems
from the simplifying model assumptions, e.g. Poisson distributed numbers of deaths and
the VECM structure for the time series, which do not allow for ﬂexibility in case of
overdispersion, model misspeciﬁcation, and data anomalies. Considering posterior pre-
dictive forecasting based on the marginal posterior distribution for the hyperparameters,
as described in the next section, a degenerated posterior for K is not of major concern.
Therefore, in the course of the case studies conducted in Chapter 4, the amendments
proposed in this section will not be of further interest. However, in case a valid ap-
proximation of this posterior is desired for the calibration window, several techniques
48

3 The Bayesian Multi-Population Mortality Projection Model
are available in the literature, for example the inclusion of independent and Gamma
distributed nuisance parameters θxpt with mean 1, such that Dxpt ∼Poi(Exptqxptθxpt).
This results in a simple Poisson-Gamma two-stage model, in which the random factors
measure unexplained variability not covered by the systematic part Exptqxpt. Such ap-
proaches are well-known in diﬀerent statistical applications, for instance see Wakeﬁeld
(2007) for a review on random eﬀects models in spatial data analysis.
A disadvantage of two-stage models in this Bayesian framework is the large number
of additional parameters that have to be estimated. Motivated by work on weighted
likelihood approaches in Bayesian inference, see Agostinelli and Greco (2012) or Newton
and Raftery (1994), one can down-weight the posteriors by an exponent w ∈(0, 1] chosen
by the modeller, i.e. instead of f (κt | D, E, H, K−t, k, r) sample from
cwf (κt | D, E, H, K−t, k, r)w ∝f (D | E, K, k, r)w f (κt | H, K−t, k, r)w
(3.13)
with normalising constant cw, which only depends on w and need not be known, as
it cancels out in the Metropolis-Hastings algorithm.
This naturally leads to higher
variability in the posterior distribution, because large values for f are down-weighted
and values smaller than 1 are increased. Thereby, variances larger than what is observed
by the pure model and likelihood speciﬁcation, can be accommodated. A motivating
example is a nominal normal posterior with mean µ and variance σ2.
It is easy to
see that taking the density to power w ∈(0, 1] leads again to the normal distribution
with same mean and variance σ2/w ≥σ2. One can think of w as a weight for both
the likelihood and the prior: it expresses the certainty w.r.t. these model speciﬁcations
compared to a uniform distribution for the data Dxpt over the range of, say, [0, Expt],
and a non-informative prior for κt, because the posterior is proportional to the product
of the term on the right-hand side of (3.13) and (Q
x,p,t E−1
xpt)1−w · 11−w. The result of
incorporating w is an easy way to introduce ﬂexibility to the model framework, which
allows for a wide enough parameter space for the time series parameters K. Only one
additional parameter must be pre-selected by the analyst, capturing the prior belief
about certainty w.r.t. model assumptions and, hence, following the Bayesian paradigm.
Finally, it is easy to see that for the BMPMP model, the modiﬁcation of the posterior
49

3 The Bayesian Multi-Population Mortality Projection Model
carries through all calculations and leads to the acceptance probability
a

κ(i−1)
t
, κ∗
t

= min


1, exp(w)
f

κ∗
t | D, E, H(i), K(i−1/i)
−t
, k, r

f

κ(i−1)
t
| D, E, H(i), K(i−1/i)
−t
, k, r



.
3.4 Bayesian Forecasting
Once a suﬃciently large sample of the posterior distribution is simulated, the estimated
parameters are used to forecast the mortality rates of the underlying populations into the
future. In many real-life examples, the mortality and crude death rates exhibit certain
random noise, which makes a precise short-term prediction rather diﬃcult. However, the
incorporation of ﬁrst-order AR components and the cointegration terms is expected to
lead to global estimation of the dependency structure between the marginal time series.
This allows for comparably sophisticated forecasts in the long-run as will be seen in the
application of the BMPMP model in the subsequent chapter. Due to the complexity
of the parameters and their joint distribution, forecasts are based on simulation rather
than analytical computations.
Besides the prediction of future values, i.e. the main goal of this model, the following
forecast procedure can also be applied for model validation. In the latter case, following
Appendix A.3, the posterior distribution of the hyperparameters is used to predict the
time series over the calendar years, whose observations were used as the training dataset.
For a good model ﬁt, the probabilistic behaviour of the resulting forecast should natu-
rally coincide with what was observed from the original data. Of course, this procedure
tends to overﬁt the data, since the model parameters are estimated to exactly ﬁt the
particularly observed paths. More sophisticated model validation tools can be applied,
such as division of the observed data into two independent training and test sets, to
reduce the impact of overﬁtting.
Mortality rates are forecast via prediction of the VECM model parameters K into the
future and ﬁnal computation of qxpt via the corresponding CBD equation from Sec-
tion 3.2.1. Although one speciﬁc calendar year serves as starting point, no exact initial
value for the VECM is given. First, crude death rates are subject to random noise due
to measurement errors and natural ﬂuctuations, and second – and even more important
50

3 The Bayesian Multi-Population Mortality Projection Model
– the time series representation in K is latent and must be estimated. For the purpose
of easy model forecasts, one could simply use the ML estimate for the parameters in the
CBD model of the corresponding calendar year, i.e. κT when predictions start with the
last observed mortality data. In light of the entire Bayesian philosophy, however, it is
preferred to use the already realised posterior sample for the corresponding parameter
κT as a distribution for the starting value. The uncertainty in both death rates and
latent time series representation is then inherently integrated. Particular improvement
in expressing uncertainty is seen for the very ﬁrst years of predictions due to the auto-
correlation in K.
For any realised starting value of the time series, a set of all diﬀerent hyperparameters
is drawn from the joint posterior distribution. Following the normal assumption of the
VECM, the entire time series can be successively generated through realisations of the
m-dimensional normal distribution, where mean and covariance matrix are determined
by the previous step and the hyperparameters. Simulation of the hyperparameters is
easily done by random sampling from the corresponding joint MCMC sample, given that
the Markov chain has converged and a pseudo-independent sample is obtained, eventu-
ally after deleting a suﬃciently large burn-in period. Due to the Ergodic Theorem, the
simplest way to do so is to walk through the entire path of the realised Markov chain and
to use the hyperparameter values H(i) =

φ(i), α(i), β(i), Γ(i), Ω(i)	
at each stage i for the
time series simulation. As the number of MCMC steps is already large, one simulation
of the time series for each set of hyperparameters naturally leads to a sample size for
the predicted values of the same size, but several simulations of the VECM per realised
set of hyperparameters are of course possible, too.
Having obtained the forecasts over a pre-determined time span, particular interest with
this model then lies in the joint distributions of the estimated mortality rates. In com-
parison to marginal or low-dimensional mortality forecast models, the BMPMP model
has its speciﬁc strength in detection of future dependencies between diﬀerent popu-
lations. Furthermore, due to the normal assumption in the VECM, simulation is even
straightforward when certain scenarios for some of the marginal time series are assumed.
If there is a strong prior assumption of the, say, overall development of mortality, an
according deterministic sample path for the intercept can be postulated. Such assump-
tions are reasonable when other scientiﬁc studies forecast a general trend much better
51

3 The Bayesian Multi-Population Mortality Projection Model
than the BMPMP approach based on biological and social factors. The BMPMP model
can then be used to predict the marginal inﬂuences of the global development on the
individual populations. Since the multivariate normal distribution in the VECM im-
plies normal conditional distributions, simulation of the remaining time series is done
in the same manner as before, and the resulting eﬀects on the mortality rates can be
interpreted w.r.t. the given assumptions on the global mortality progression. In par-
ticular, if κt = (κ(1)′
t
, κ(2)′
t
)′ is divided into an m1-dimensional sub-vector κ(1)
t
and an
m2-dimensional κ(2)
t
with m = m1 + m2, one makes use of the fact that κ(1)
t
| κ(2)
t
= k(2)
t
is m2-variate normal distributed with mean
φ(1) +
 (Im1, 0) + α(1)β′
κt−1 +
k−1
X
i=1
Γ(1)
i ∆κt−i
+ Ω12Ω−1
22
 
k(2)
t
−φ(2) −
 (0, Im2) + α(2)β′
κt−1 −
k−1
X
i=1
Γ(2)
i ∆κt−i
!
and variance
Ω11 −Ω12Ω−1
22 Ω21,
where (Im1, 0) ∈Rm1×m, (0, Im2) ∈Rm2×m, φ = (φ(1)′, φ(2)′)′ with φ(1) ∈Rm1, φ(2) ∈
Rm2, α = (α(1)′, α(2)′)′ with α(1) ∈Rm1×r, α(2) ∈Rm2×r, Γi = (Γ(1)′
i
, Γ(2)′
i
)′ with Γ(1)
i
∈
Rm1×m, Γ(2)
i
∈Rm2×m for all i = 1, . . . , k −1, and
Ω=
 
Ω11
Ω12
Ω21
Ω22
!
with Ω11 ∈Rm1×m1, Ω12 = Ω′
21 ∈Rm1×m2, Ω22 ∈Rm2×m2.
Note that a scenario-
dependent forecast will not be further discussed in this work.
3.5 Model Summary
Figure 3.1 summarises the BMPMP model.
52

3 The Bayesian Multi-Population Mortality Projection Model
Figure 3.1: The Bayesian Multi-Population Mortality Projection Model
Data
Observed number of deaths: D = {Dxpt ∀x, p, t, p ̸= p∗}
Exposure-to-risk: E = {Expt ∀x, p, t, p ̸= p∗}
Likelihood
Dxpt ∼Poi (−log (1 −qxpt) Expt)
Cairns-Blake-Dowd Model
log

qxpt
1 −qxpt

= κ0
t + κp
t + (κx
t + κxp
t ) (x −¯x) +

κx2
t + κx2p
t
  (x −¯x)2 −ˆσ2
,
x ≥x0, t = 1, . . . , T
Parameters
K = {κ1, . . . , κT} with κt =
 κ0
t, κx
t , κp1
t , κp2
t , . . .

Vector Error Correction Model
∆κt = φDt +
k−1
X
i=1
Γi∆κt−i + αβ′κt−1 + εt,
t = k + 1, . . . , T
Prior for κ1, . . . , κk
κt | k ∼Nm (µt, Σt)
µt, t = 1, . . . , k
Σt, t = 1, . . . , k
Σ
Prior for κk+1, . . . , κT
κt | κt−k, . . . , κt−1, φ, Γ, α, β, Ω, k, r
∼Nm
 
φ +
k−1
X
i=1
Γi∆κt−i + (Im + αβ′) κt−1, Ω
!
Hyperparameters
H = {φ, Γ, α, β, Ω}
Prior
f (φ, Γ, α, β, Ω| k, r) as in (3.10)
A
λA
fA
q
λα
λb
λl
k
r
ΣMH
cMH
x0
T
Prior Set-up
Prior Set-up
Calibration
Model Speciﬁcation
Tuning
53

3 The Bayesian Multi-Population Mortality Projection Model
The Bayesian estimation algorithm at iteration i is summarised a follows.
• Gibbs sampler for the hyperparameters: Simulate from
Ω| φ(i−1), Γ(i−1), α(i−1), β(i−1), K(i−1), k, r ∼IWm

S(i)
Ω, nΩ

,
φ | Ω(i), Γ(i−1), α(i−1), β(i−1), K(i−1), k, r ∼Nm

µ(i)
φ , Ω(i)
,
vec (Γ) | Ω(i), φ(i), α(i−1), β(i−1), K(i−1), k, r ∼Nm2(k−1)

µ(i)
Γ , Σ(i)
Γ

,
vec (α) | Ω(i), φ(i), Γ(i), β(i−1), K(i−1), k, r ∼Nmr
 µ(i)
α , Σ(i)
α

,
vec (βl) | Ω(i), φ(i), Γ(i), α(i), K(i−1), k, r ∼Nr(m−r)

µ(i)
βl , Σ(i)
βl

,
with parameters as given in Section 3.3.3.
• Metropolis-Hastings sampler for the parameter κt:
– Simulate κ∗
t ∼Nm

κ(i−1)
t
, ΣMH

.
– Compute
a

κ(i−1)
t
, κ∗
t

= min


1, exp(w)
f

κ∗
t | D, E, H(i), K(i−1/i)
−t
, k, r

f

κ(i−1)
t
| D, E, H(i), K(i−1/i)
−t
, k, r



.
– Generate u ∼U ([0, 1)). If u ≤a

κ(i−1)
t
, κ∗
t

then set κ(i)
t
= κ∗
t, otherwise let
κ(i)
t
= κ(i−1)
t
.
54

4 Case Studies in European Mortality
Forecasting
In this chapter, the BMPMP model is calibrated with mortality data of diﬀerent Eu-
ropean countries to assess the model’s ability to fulﬁl the desired targets outlined in
Section 3.1. Particular attention is devoted to investigate the ﬂexibility to model an ar-
bitrary number of arbitrary populations. In both sections of this chapter, the BMPMP
model is applied with gender-speciﬁc mortality rates of ﬁve European countries, respec-
tively. This number clearly exceeds the restriction of only two populations for most of
the existing multi-population mortality projection models, but remains small enough for
illustration purposes. While Section 4.1 comprises a standard example with data from
commonly investigated Western European countries, a selection of Central European
countries, which could not be satisfactorily modelled in the augmented common factor
model by Li and Lee (2005), is included in Section 4.2. Besides discussion of the choice
of priors, convergence diagnostics of the MCMC algorithm, and general goodness-of-ﬁt
analyses, the main focus lies on diagnostic assessment and interpretation of the output
taking into consideration the multi-population context, including a comparison of the
joint forecast with results from univariate Bayesian CBD models for each country. Fur-
thermore, the second distinct feature of the BMPMP model, the Bayesian paradigm, is
compared to its frequentist counterpart where possible, i.e. only for such model speciﬁ-
cations, for which the high-dimensional maximisation problem is non-singular.
All data in this chapter are obtained through the Human Mortality Database (2014),
available at http://www.mortality.org, from the underlying data sources referenced
therein. The Human Mortality Database provides a rich set of mortality-related ﬁgures
for a wide range of mostly developed countries. Original data are collected from the na-
tional statistical bureaus or institutes. For each country, the observed number of deaths
Dxgt and the corresponding exposure-to-risk Exgt are available for both genders g = m, f,
55

4 Case Studies in European Mortality Forecasting
where m and f denote male and female, respectively, for all ages x = 0, 1, . . . , 109 and
all remaining ages, denoted by 110+. All data will be taken as provided by the Hu-
man Mortality Database (2014) and considered absolutely comparable. In particular,
diﬀerences in data quality and methodologies of how the data were derived or handling
changes of territorial claims will not be discussed in this work – the interested reader is
referred to the list of all considered countries in the preface of this work for details on
the territorial coverage and the documentation in the Human Mortality Database (2014)
for further information. The time horizon for t is country-speciﬁc and varies between
a decade and hundreds of years. For most countries, the post-war period is suﬃciently
covered such that the BMPMP model can be at least calibrated for the last 60 or so years.
For all the following case studies, numerical results are obtained through the author’s
bmpmp package in the freely available statistical programming software R. It is designed
for ﬂexible and eﬃcient estimation and output of the BMPMP model for joint forecasts
of diﬀerent countries with distinction of both genders.
The routines in the package
allow the modeller to create required datasets using the data from the Human Mortality
Database (2014), to calibrate and to forecast the BMPMP model, and to automatically
obtain important graphical output for the analysis. Further tools, such as ML estimation,
are available for comparison purposes. The bmpmp package is available upon request to
the author and described in detail in Appendix F.
4.1 Case Study 1: The Big Five
In this section, the BMPMP model is calibrated with gender-speciﬁc data on the so-
called Big Five, i.e. the ﬁve largest countries in Western Europe: France, Germany,
Italy, Spain, and the United Kingdom. See Figure 4.1 for a map. Due to diﬀerent pat-
terns in mortality because of diﬀerences in social, economic, and medical circumstances
in a divided Germany until re-uniﬁcation and even thereafter, the data for Germany
are restricted to the population of West Germany (i.e. the then Federal Republic of
Germany) until 1990 and the corresponding territory (i.e. the old states within the re-
uniﬁed Federal Republic of Germany) since then, but referred to simply as Germany
for convenience. For all other countries, see the information in the preface on details of
territorial coverage. In order to interpret country-speciﬁc parameters as deviations from
56

4 Case Studies in European Mortality Forecasting
Figure 4.1: Map of the Big Five
Shown in green are the so-called Big Five, i.e. the ﬁve largest countries in Western Europe: France (FR), Germany (DE,
data only for West Germany in this case study), Italy (IT), Spain (ES), and the United Kingdom (UK), within Europe.
For details on territorial coverage for these ﬁve countries, see the list of countries in the preface.
DE
FR
ES
IT
UK
57

4 Case Studies in European Mortality Forecasting
the average mortality in all considered countries, the overall sample is used as reference
and sometimes loosely called European population. The ages under consideration are
restricted to the interval [40, 100]. Data availability diﬀers for the countries under con-
sideration. The combined sample of all countries is available from 1956 to 2009. The
model is calibrated w.r.t. the time horizon from 1956 to 1995. The remaining data are
used for external out-of-sample validation. Due to regime changes within this calibration
period, in the latter course of this case study, the model is estimated based on data from
1981–2009 and forecast until the year of 2100.
4.1.1 Model Equations
Following the gender-speciﬁc equation in (3.4), the CBD equation in the BMPMP model
for this case study is set up as follows:
log

qxpgt
1 −qxpgt

= κ0
t + κp
t + κg
t + κpg
t + (κx
t + κxp
t + κxg
t ) (x −x0)
+

κx2
t + κx2p
t
+ κx2g
t

(x −x0)2,
x ≥x0,
(4.1)
with t = 1, . . . , 40 representing the years 1956, . . . , 1995, x = 40, . . . , 100, g = m, f,
and p ∈P = {DE, ES, FR, IT, UK, EU}, where the countries are abbreviated by their
Internet top-level domains1, and p∗= EU stands for the overall sample of all countries.
In contrast to the common equations in Section 3.2.1, this case study centres the age
variables at x0 = 40 instead of the average ¯x and uses bσ2 = 0, i.e. the reference for the
quadratic age parameters is the absolute squared diﬀerences w.r.t. the age of 40 rather
than the excess of the empirical variance in age. For uniqueness in parametrisation, it
is assumed that κEU
t
= κm
t = κEU,m
t
= κx,EU
t
= κx2,EU
t
= κx,m
t
= κx2,m
t
= 0 for all t. There
are ﬁve populations with 61 age groups for both genders in each of the 40 calendar years,
i.e. the dataset consists of 24,400 entries. On the other hand, for each calendar year, the
CBD equation adds one intercept, one main eﬀect for gender, two main eﬀects for age
(for the linear and quadratic terms, respectively), and ﬁve main eﬀects for the countries.
In addition, second-order interactions between age, gender, and population include fur-
ther 17 parameters. Therefore, one ends up with 26 parameters in each CBD equation,
1ISO 3166-1 alpha-2 codes with speciﬁc replacement of GB by UK for the United Kingdom: DE –
Germany (restricted to the territory of former West Germany), ES – Spain, FR – France, IT – Italy,
UK – United Kingdom.
58

4 Case Studies in European Mortality Forecasting
i.e. 1,040 parameters in total. The CBD stage in the BMPMP model in this example
is indeed parsimonious with a parameter-to-data quota of 4.3%. Note that individual
CBD models for all ten populations, comprised of all ﬁve countries and both genders,
would actually require 1,200 parameters.
The VECM equation is then given as outlined in Section 3.2.2 with the linear normali-
sation for β. The lag order is chosen to be k = 2 to allow for one AR parameter in the
VECM representation. For numerical eﬃciency, the lag order is not further increased, as
any additional AR coeﬃcient matrix introduces 262 = 676 additional parameters. For
the cointegration rank, the choice of r = 5 corresponds to the prior belief of at most ﬁve
stationary linear combinations of the marginal time series, respectively. The number of
parameters in the VECM becomes 26 for φ, 130 for α and 105 for β, 676 for Γ1, and
26(26+1)/2 = 351 for Ωdue to symmetry, i.e. 1,104 in total. The number of parameters
in both stages of the BMPMP model is of similar magnitude, and the VECM param-
eters may even exceed the CBD parameters.
Hence, frequentist estimation becomes
problematic or, as seen with this example, impossible. The alternative of independent
models would see a much lower number of parameters, but neglect any quantiﬁcation
of dependencies. Although the remainder of this case study mainly focuses on this par-
ticular speciﬁcation of the model with k = 2 and r = 5, due to the diﬃculty of even
presenting such high-dimensional results for one model estimation, comments on other
model speciﬁcations will be made w.r.t. results from calibration of model set-ups by all
combinations of k = 1, 2 and r = 0, 1, 5 in Section 4.1.9.
4.1.2 Choice of Priors
Starting with the constants for the hyperparameters in the VECM, the values for
A, q, λα, λb are set as follows. For the expected covariance matrix, the empirical Bayes
approach with A = fA(bΩ) is applied. Here, bΩis the empirical covariance matrix of the
time series in diﬀerences, which is tuned by fA(M) = (λ2
Am2
ij)ij for M = (mij)ij with
λA =
√
10. If this choice of A becomes numerically singular, its oﬀ-diagonal elements
are set to zero. The choice of q = m + 2 for maximum uncertainty is made to reduce
the impact of the empirical Bayes approach. The value for λα is chosen to be one such
that α has covariance matrix E(Ω). Finally, it is λb = 5 to increase uncertainty in Γ1.
For the case k = 1, this parameter is not required, and for any choice of k, there is at
59

4 Case Studies in European Mortality Forecasting
most only one lag for Γ, so that in this case study no determination of λl as shrinkage
factor is required.
The CBD parameters for the ﬁrst two calendar years, which are not immediately mod-
elled through the VECM, require additional priors for their marginal distributions.
Again, an empirical Bayes approach is used, in which µ1 and µ2 equal the ML esti-
mates of the CBD parameters of the ﬁrst two years in levels. The covariance matrices
Σ1 and Σ2 are set equal to A. For the models with k = 1, the prior choices are only
made for µ1 and Σ1.
4.1.3 Initialisation of the Algorithm and Starting Values
In this example, the single-component version of the Metropolis-Hastings algorithm is
applied. The proposal covariance matrix is set to be ΣMH = cMHA with tuning factor
cMH = 10 to achieve higher acceptance rates by increasing the innovation steps. The
single-component algorithm only requires the diagonal entries of ΣMH for the marginal
proposals.
Finally, initial values for the CBD parameters are the respective ML es-
timates on the Binomial generalised linear regression with events Dxpgt out of Expgt
trials and link function mxpgt 7→log (exp(mxpgt) −1), and the starting values for the
hyperparameters are chosen as outlined in Section 3.3.3. The MCMC algorithm is run
for a total of N = 1,000,000 iterations subject to thinning by a factor of 100, i.e. only
every 100-th iteration is stored to reduce memory space for the high-dimensional output.
The starting values for K are plotted in Figure 4.2 for a general understanding in model
interpretation.
The upper six plots show the ML estimates of the intercept and all
gender- and age-related main and interaction eﬀects as time series for t = 1, . . . , 40.
The remaining lower plots show the main eﬀects of the distinct populations as well as
their interactions with gender and age. Since the values of each of the latter types of
parameters are directly comparable with each other, as they represent deviations from
the overall reference population, the plots for each parameter category contain the ac-
cording time series for all populations p.
The intercept, which is to be interpreted as the logit mortality rate of a 40-year-old male
in the reference population, clearly exhibits the negative trend known from studies on
60

4 Case Studies in European Mortality Forecasting
Figure 4.2: Starting values for K
Shown are the ML estimates κ(0)
t
of the CBD parameters as time series in t for 1956, . . . , 1995.
1960
1970
1980
1990
-6.1
-6.0
-5.9
-5.8
-5.7
(a) Intercept κ0(0)
t
1960
1970
1980
1990
-0.75
-0.70
-0.65
-0.60
(b) Gender eﬀect for females κf(0)
t
1960
1970
1980
1990
0.090
0.095
0.100
0.105
(c) Linear age eﬀect κx(0)
t
1960
1970
1980
1990
-2e-04
-1e-04
0e+00
1e-04
(d) Quadratic age eﬀect κx2(0)
t
1960
1970
1980
1990
-0.010
-0.005
0.000
(e) Gender and linear age interactions κxf(0)
t
1960
1970
1980
1990
0.00015
0.00020
0.00025
0.00030
0.00035
0.00040
0.00045
(f) Gender and quadratic age interactions κx2f(0)
t
1960
1970
1980
1990
-0.2
-0.1
0.0
0.1
0.2
0.3
0.4
DE
DE
DE
DE
ES
ES
ES
ES
FR
FR
FR
FR
IT
IT
IT
IT
UK
UK
UK
UK
EU
EU
EU
EU
(g) Main country eﬀects κp(0)
t
1960
1970
1980
1990
-0.10
-0.05
0.00
0.05
0.10 DE
DE
DE
DE
ES
ES
ES
ES
FR
FR
FR
FR
IT
IT
IT
IT
UK
UK
UK
UK
EU
EU
EU
EU
(h) Gender and country interactions κpf(0)
t
1960
1970
1980
1990
-0.03
-0.02
-0.01
0.00
0.01
0.02
DE
DE
DE
DE
ES
ES
ES
ES
FR
FR
FR
FR
IT
IT
IT
IT
UK
UK
UK
UK
EU
EU
EU
EU
(i) Linear age and country interactions κpx(0)
t
1960
1970
1980
1990
-4e-04
-2e-04
0e+00
2e-04
4e-04
DE
DE
DE
DE
ES
ES
ES
ES
FR
FR
FR
FRIT
IT
IT
IT
UK
UK
UK
UK
EU
EU
EU
EU
(j) Quadratic age and country interactions κpx2(0)
t
61

4 Case Studies in European Mortality Forecasting
mortality in developed countries cited in Chapter 2. Moreover, the increased pace of
mortality improvements seen for the second half of the calibration period is consistent
with applications of the standard CBD model, see Cairns et al. (2006) for instance, and
suggests that model calibration may be eventually improved by shifting the beginning
of the time horizon to the late 1970s. The negative values in the time series for the
eﬀect of females reﬂect the biological fact of lower mortality among women, where the
exact values have to be interpreted for females aged 40 in the reference population on
the logit scale. The 1970s clearly mark a time of even further improvements in mortality
for females in this age group on top of the general pattern given by the intercept.
While identifying a regime change for the age-related parameters around the year of
1970 with opposite movements beforehand, since then the linear age eﬀect declines, and
the quadratic eﬀect becomes stronger. The interactions with gender remain merely sta-
ble over time since 1970, so that above eﬀects are apparent for both genders with a
constantly more quadratic curve for females. The linear and quadratic age eﬀects are
multiplied by values between 0–60 and 0–3600, respectively, and thus the magnitudes
of the time series must be interpreted accordingly. Furthermore, interpretation of these
parameters must be done simultaneously, indicating that in addition to the general im-
provement via the intercept, the linearity in the logits of mortality rates gets lost over
time in favour of a quadratic curve. As a result, the middle age groups experience a
larger extent of mortality improvement compared to low age groups around 40 years
and high age groups around 100 years. Quadratic eﬀects were found to be signiﬁcant
with data from males of the United States by Cairns et al. (2006), but an important
consequence of this ﬁnding for European data is that quadratic patterns in the logits of
mortality rates seem to be present for other populations in the developed world. Since
the eﬀect of quadratic age patterns seems to become more important over time, this
suggests that mortality prediction models in the CBD framework with only linear age
eﬀects may be too simplistic in the description of age-dependent mortality improvements.
Finally, the country-speciﬁc plots describe their deviations from the overall population.
For each country, its four speciﬁc time series adjust the intercept κ0(0)
t
and the main
eﬀects for gender and age, i.e. κf(0)
t
, κx(0)
t
, κx2(0)
t
. Vanishingly small values for Germany,
which is the largest country in terms of population among all ﬁve, indicate that it is
well-represented by the reference population. In contrast, for 40-year-old males, French
62

4 Case Studies in European Mortality Forecasting
mortality is constantly higher, while Spanish mortality uses to be lower until 1990. Rel-
ative improvements for Italy and the United Kingdom emerge towards the end of the
calibration window. Eﬀects for females are opposite, i.e. compared to the overall refer-
ence, there is a constantly larger gap between French men and women and a historically
smaller gap for Germany, Italy, and Spain. For the United Kingdom, the speciﬁc trend of
men catching up with women is outstanding. The two last plots reveal that French mor-
tality data exhibit the strongest quadratic pattern throughout the time horizon among
all ﬁve countries, while the logits of mortality rates for the United Kingdom are still
linear. Interestingly, the country-speciﬁc deviations from the reference population do
not seem to converge over the calibration period. Hypotheses of convergence stated a
priori, as known from other models, are questioned by the BMPMP model in favour of
this data-driven approach.
The marginal time series in Figure 4.2 are obviously non-stationary, but can be justiﬁed
to be trend-stationary when analysing plots of their ﬁrst diﬀerences (not shown). Direct
comparison of the main linear and quadratic age eﬀects or comparison of such time series
with their respective interactions with gender – just to name a few – reveal a strong
correlation among many of the marginal time series. It is evident that a joint time series
approach, which in the BMPMP model is given by the VECM, is vital and suggests that
estimation of the covariance matrix Ωis of major importance. Even more, the strong
correlation further motivates the choice of this model, because linear combinations of
diﬀerent marginal time series in levels, e.g. κx(0)
t
−κx2(0)
t
or κxf(0)
t
−κx2f(0)
t
, seem to be
indeed stationary.
4.1.4 Convergence Diagnostics
Before performing any type of statistical inference, the BMPMP model and the out-
put of its MCMC algorithm must be diagnosed for validity. The aim of the MCMC
procedure is to approximate the posterior distribution of the model parameters by an
extensive sample of pseudo-independent realisations. Although theoretical ergodicity
could be established for the BMPMP model, it must be veriﬁed that the Markov chain
indeed converged to this limiting distribution within the given iterations, and that the
sample is suﬃciently large for the Ergodic Theorem to make autocorrelation negligible.
Failure in obtaining the correct posterior distribution falsiﬁes results from the statistical
63

4 Case Studies in European Mortality Forecasting
analysis. However, as far as the purpose of mortality forecasts with the BMPMP model
is concerned, primary focus must be devoted to the marginal posterior distribution of
the set of hyperparameters. Bayesian forecasting is equivalent to obtaining the posterior
predictive distribution of future values of the CBD parameters through posterior sam-
pling of the hyperparameters only, rather than sampling from the posterior distribution
of the given CBD parameters.
While referring to Appendix B.4 for a general introduction to diﬀerent concepts of con-
vergence diagnostics in the MCMC framework, the convergence analysis in this case
study is mainly based on graphical assessment of the marginal parameter distributions.
Two of the most important tools, plots of the paths of marginal parameters w.r.t. the
MCMC iterations as well as plots of the current ergodic means versus the iteration in-
dex, will be displayed in detail. However, convergence of the marginal distribution can
only indicate that the joint distribution of all parameters and hyperparameters might
have reached its equilibrium. The total number of more than 2,000 parameters and
hyperparameters makes the Markov chain such high-dimensional that convergence of
the joint distribution is practically impossible to verify. Moreover, this high number
allows the discussion of only selected convergence diagnostics plots as an explanatory
representation of the full set of parameters. As mentioned earlier, results in this section
are presented for the model with k = 2 and r = 5, noting that plots for the ﬁve other
model set-ups, which cannot be shown in this work, generally display the same behaviour.
The following seven ﬁgures, i.e. Figures 4.3 to 4.9, show paths of every 100-th iteration for
selected marginal hyperparameters and parameters (left panels) and the corresponding
evaluation of ergodic means (right panels). As typical in Bayesian analysis, convergence
for the covariance matrix Ω, analysed in Figure 4.3, is additionally diagnosed for the
precision Ω−1 in order to better assess the stability of equilibriums, see Figure 4.4. For
the analysis of convergence in the cointegration space, immediate parameters of the
matrix Π = αβ′ instead of entries in both sub-parameters are plotted in Figure 4.5.
Remaining plots are given for the hyperparameters φ and Γ = Γ1 in Figures 4.6 and 4.7,
respectively. On the ﬁrst hierarchy level, i.e. for the CBD parameters K, Figures 4.8
and 4.9 depict convergence diagnoses for selected entries of κ20 (i.e. the time series at
calendar year 1975) and κ40 (i.e. the time series at calendar year 1995), respectively.
64

4 Case Studies in European Mortality Forecasting
Figure 4.3: Convergence diagnostics for Ω
Left panel: Realised marginal paths of selected entries of Ωafter running the MCMC algorithm with N = 1,000,000
iterations subject to thinning by a factor of 100. Right panel: Corresponding evolution of the ergodic means.
Indices: Indices in VECM refer to the following marginal time series: 1 – κ0
t , 2 – κf
t , 4 – κx2
t , 7 – κDE
t
.
0
2000
4000
6000
8000
10000
2e-04
4e-04
6e-04
8e-04
(a) MCMC path for Ω11
0
2000
4000
6000
8000
10000
0.00030
0.00032
0.00034
0.00036
(b) Cumulative plot of ergodic mean for Ω11
0
2000
4000
6000
8000
10000
-5e-04
-4e-04
-3e-04
-2e-04
-1e-04
0e+00
(c) MCMC path for Ω21
0
2000
4000
6000
8000
10000
-0.00016
-0.00015
-0.00014
-0.00013
-0.00012
-0.00011
(d) Cumulative plot of ergodic mean for Ω21
0
2000
4000
6000
8000
10000
-2e-07
0e+00
2e-07
4e-07
6e-07
8e-07
(e) MCMC path for Ω41
0
2000
4000
6000
8000
10000
5.0e-08
1.0e-07
1.5e-07
2.0e-07
(f) Cumulative plot of ergodic mean for Ω41
0
2000
4000
6000
8000
10000
5.0e-10
1.0e-09
1.5e-09
2.0e-09
2.5e-09
(g) MCMC path for Ω44
0
2000
4000
6000
8000
10000
8.50e-10
9.00e-10
9.50e-10
1.00e-09
1.05e-09
(h) Cumulative plot of ergodic mean for Ω44
0
2000
4000
6000
8000
10000
1e-04
2e-04
3e-04
4e-04
5e-04
6e-04
(i) MCMC path for Ω77
0
2000
4000
6000
8000
10000
0.00016
0.00017
0.00018
0.00019
0.00020
0.00021
0.00022
(j) Cumulative plot of ergodic mean for Ω77
65

4 Case Studies in European Mortality Forecasting
Figure 4.4: Convergence diagnostics for Ω−1
Left panel: Realised marginal paths of selected entries of Ω−1 after running the MCMC algorithm with N = 1,000,000
iterations subject to thinning by a factor of 100. Right panel: Corresponding evolution of the ergodic means.
Indices: Indices in VECM refer to the following marginal time series: 1 – κ0
t , 2 – κf
t , 4 – κx2
t , 7 – κDE
t
.
0
2000
4000
6000
8000
10000
0e+00
1e+07
2e+07
3e+07
4e+07
(a) MCMC path for Ω−1
11
0
2000
4000
6000
8000
10000
6.0e+06
8.0e+06
1.0e+07
1.2e+07
1.4e+07
1.6e+07
(b) Cumulative plot of ergodic mean for Ω−1
11
0
2000
4000
6000
8000
10000
-3e+07
-2e+07
-1e+07
0e+00
1e+07
2e+07
(c) MCMC path for Ω−1
21
0
2000
4000
6000
8000
10000
0e+00
2e+06
4e+06
6e+06
(d) Cumulative plot of ergodic mean for Ω−1
21
0
2000
4000
6000
8000
10000
-2.0e+11
-1.5e+11
-1.0e+11
-5.0e+10
0.0e+00
5.0e+10
(e) MCMC path for Ω−1
41
0
2000
4000
6000
8000
10000
-2e+10
-1e+10
0e+00
1e+10
2e+10
(f) Cumulative plot of ergodic mean for Ω−1
41
0
2000
4000
6000
8000
10000
0.0e+00
5.0e+14
1.0e+15
1.5e+15
2.0e+15
2.5e+15
(g) MCMC path for Ω−1
44
0
2000
4000
6000
8000
10000
0e+00
2e+14
4e+14
6e+14
8e+14
(h) Cumulative plot of ergodic mean for Ω−1
44
0
2000
4000
6000
8000
10000
5.0e+07
1.0e+08
1.5e+08
(i) MCMC path for Ω−1
77
0
2000
4000
6000
8000
10000
3e+07
4e+07
5e+07
6e+07
(j) Cumulative plot of ergodic mean for Ω−1
77
66

4 Case Studies in European Mortality Forecasting
Figure 4.5: Convergence diagnostics for Π = αβ′
Left panel: Realised marginal paths of selected entries of Π after running the MCMC algorithm with N = 1,000,000
iterations subject to thinning by a factor of 100. Right panel: Corresponding evolution of the ergodic means.
Indices: Indices in VECM refer to the following marginal time series: 1 – κ0
t , 2 – κf
t , 4 – κx2
t , 7 – κDE
t
.
0
2000
4000
6000
8000
10000
-0.04
-0.02
0.00
0.02
(a) MCMC path for Π11
0
2000
4000
6000
8000
10000
-0.008
-0.006
-0.004
-0.002
0.000
(b) Cumulative plot of ergodic mean for Π11
0
2000
4000
6000
8000
10000
-0.04
-0.02
0.00
0.02
(c) MCMC path for Π21
0
2000
4000
6000
8000
10000
-0.007
-0.006
-0.005
-0.004
-0.003
-0.002
(d) Cumulative plot of ergodic mean for Π21
0
2000
4000
6000
8000
10000
-5e-05
0e+00
5e-05
(e) MCMC path for Π41
0
2000
4000
6000
8000
10000
-1e-05
-5e-06
0e+00
5e-06
(f) Cumulative plot of ergodic mean for Π41
0
2000
4000
6000
8000
10000
-5e-05
0e+00
5e-05
(g) MCMC path for Π44
0
2000
4000
6000
8000
10000
-1e-05
-8e-06
-6e-06
-4e-06
-2e-06
0e+00
2e-06
4e-06
(h) Cumulative plot of ergodic mean for Π44
0
2000
4000
6000
8000
10000
-0.03
-0.02
-0.01
0.00
0.01
0.02
0.03
(i) MCMC path for Π77
0
2000
4000
6000
8000
10000
-0.008
-0.007
-0.006
-0.005
-0.004
-0.003
-0.002
-0.001
(j) Cumulative plot of ergodic mean for Π77
67

4 Case Studies in European Mortality Forecasting
Figure 4.6: Convergence diagnostics for φ
Left panel: Realised marginal paths of selected entries of φ after running the MCMC algorithm with N = 1,000,000
iterations subject to thinning by a factor of 100. Right panel: Corresponding evolution of the ergodic means.
Indices: Indices in VECM refer to the following marginal time series: 1 – κ0
t , 2 – κf
t , 4 – κx2
t , 7 – κDE
t
, 17 – κx,DE
t
.
0
2000
4000
6000
8000
10000
-0.2
-0.1
0.0
0.1
0.2
(a) MCMC path for φ1
0
2000
4000
6000
8000
10000
-0.05
-0.04
-0.03
-0.02
-0.01
(b) Cumulative plot of ergodic mean for φ1
0
2000
4000
6000
8000
10000
-0.2
-0.1
0.0
0.1
0.2
(c) MCMC path for φ2
0
2000
4000
6000
8000
10000
-0.045
-0.040
-0.035
-0.030
-0.025
-0.020
-0.015
(d) Cumulative plot of ergodic mean for φ2
0
2000
4000
6000
8000
10000
-4e-04
-2e-04
0e+00
2e-04
4e-04
(e) MCMC path for φ4
0
2000
4000
6000
8000
10000
-6e-05
-4e-05
-2e-05
0e+00
2e-05
4e-05
6e-05
(f) Cumulative plot of ergodic mean for φ4
0
2000
4000
6000
8000
10000
-0.10
-0.05
0.00
0.05
0.10
0.15
(g) MCMC path for φ7
0
2000
4000
6000
8000
10000
0.01
0.02
0.03
0.04
(h) Cumulative plot of ergodic mean for φ7
0
2000
4000
6000
8000
10000
-0.010
-0.005
0.000
0.005
(i) MCMC path for φ17
0
2000
4000
6000
8000
10000
-0.0020
-0.0015
-0.0010
-0.0005
0.0000
0.0005
(j) Cumulative plot of ergodic mean for φ17
68

4 Case Studies in European Mortality Forecasting
Figure 4.7: Convergence diagnostics for Γ = Γ1
Left panel: Realised marginal paths of selected entries of Γ after running the MCMC algorithm with N = 1,000,000
iterations subject to thinning by a factor of 100. Right panel: Corresponding evolution of the ergodic means.
Indices: Indices in VECM refer to the following marginal time series: 1 – κ0
t , 2 – κf
t , 4 – κx2
t , 7 – κDE
t
.
0
2000
4000
6000
8000
10000
-0.3
-0.2
-0.1
0.0
0.1
0.2
0.3
(a) MCMC path for Γ11
0
2000
4000
6000
8000
10000
-0.04
-0.03
-0.02
-0.01
0.00
0.01
(b) Cumulative plot of ergodic mean for Γ11
0
2000
4000
6000
8000
10000
-0.2
-0.1
0.0
0.1
0.2
0.3
0.4
(c) MCMC path for Γ21
0
2000
4000
6000
8000
10000
-0.02
0.00
0.02
0.04
0.06
(d) Cumulative plot of ergodic mean for Γ21
0
2000
4000
6000
8000
10000
-6e-04
-4e-04
-2e-04
0e+00
2e-04
4e-04
(e) MCMC path for Γ41
0
2000
4000
6000
8000
10000
-0.00015
-0.00010
-0.00005
0.00000
0.00005
0.00010
(f) Cumulative plot of ergodic mean for Γ41
0
2000
4000
6000
8000
10000
-6e-04
-4e-04
-2e-04
0e+00
2e-04
4e-04
6e-04
(g) MCMC path for Γ44
0
2000
4000
6000
8000
10000
-5e-05
0e+00
5e-05
1e-04
(h) Cumulative plot of ergodic mean for Γ44
0
2000
4000
6000
8000
10000
-0.3
-0.2
-0.1
0.0
0.1
(i) MCMC path for Γ77
0
2000
4000
6000
8000
10000
-0.08
-0.07
-0.06
-0.05
-0.04
(j) Cumulative plot of ergodic mean for Γ77
69

4 Case Studies in European Mortality Forecasting
Figure 4.8: Convergence diagnostics for κ20
Left panel: Realised marginal paths of selected entries of κ20 after running the MCMC algorithm with N = 1,000,000
iterations subject to thinning by a factor of 100. Right panel: Corresponding evolution of the ergodic means.
0
2000
4000
6000
8000
10000
-5.880
-5.875
-5.870
-5.865
-5.860
-5.855
(a) MCMC path for κ0
20
0
2000
4000
6000
8000
10000
-5.876
-5.874
-5.872
-5.870
-5.868
-5.866
(b) Cumulative plot of ergodic mean for κ0
20
0
2000
4000
6000
8000
10000
-0.704
-0.702
-0.700
-0.698
-0.696
-0.694
-0.692
-0.690
(c) MCMC path for κf
20
0
2000
4000
6000
8000
10000
-0.700
-0.699
-0.698
-0.697
(d) Cumulative plot of ergodic mean for κf
20
0
2000
4000
6000
8000
10000
-7.5e-05
-7.0e-05
-6.5e-05
-6.0e-05
-5.5e-05
(e) MCMC path for κx2
20
0
2000
4000
6000
8000
10000
-7.5e-05
-7.0e-05
-6.5e-05
(f) Cumulative plot of ergodic mean for κx2
20
0
2000
4000
6000
8000
10000
0.020
0.025
0.030
(g) MCMC path for κDE
20
0
2000
4000
6000
8000
10000
0.0265
0.0270
0.0275
0.0280
0.0285
(h) Cumulative plot of ergodic mean for κDE
20
0
2000
4000
6000
8000
10000
0.0011
0.0012
0.0013
0.0014
(i) MCMC path for κx,DE
20
0
2000
4000
6000
8000
10000
0.00114
0.00116
0.00118
0.00120
0.00122
(j) Cumulative plot of ergodic mean for κx,DE
20
70

4 Case Studies in European Mortality Forecasting
Figure 4.9: Convergence diagnostics for κ40
Left panel: Realised marginal paths of selected entries of κ40 after running the MCMC algorithm with N = 1,000,000
iterations subject to thinning by a factor of 100. Right panel: Corresponding evolution of the ergodic means.
0
2000
4000
6000
8000
10000
-6.175
-6.170
-6.165
-6.160
-6.155
(a) MCMC path for κ0
40
0
2000
4000
6000
8000
10000
-6.175
-6.170
-6.165
-6.160
(b) Cumulative plot of ergodic mean for κ0
40
0
2000
4000
6000
8000
10000
-0.715
-0.710
-0.705
(c) MCMC path for κf
40
0
2000
4000
6000
8000
10000
-0.712
-0.710
-0.708
-0.706
-0.704
-0.702
(d) Cumulative plot of ergodic mean for κf
40
0
2000
4000
6000
8000
10000
0.000165
0.000170
0.000175
0.000180
0.000185
0.000190
(e) MCMC path for κx2
40
0
2000
4000
6000
8000
10000
0.000170
0.000175
0.000180
(f) Cumulative plot of ergodic mean for κx2
40
0
2000
4000
6000
8000
10000
0.048
0.050
0.052
0.054
0.056
0.058
(g) MCMC path for κDE
40
0
2000
4000
6000
8000
10000
0.0515
0.0520
0.0525
0.0530
(h) Cumulative plot of ergodic mean for κDE
40
0
2000
4000
6000
8000
10000
0.00050
0.00055
0.00060
0.00065
(i) MCMC path for κx,DE
40
0
2000
4000
6000
8000
10000
0.00056
0.00057
0.00058
0.00059
(j) Cumulative plot of ergodic mean for κx,DE
40
71

4 Case Studies in European Mortality Forecasting
The graphical assessment of convergence among the hyperparameters starts with the
plots shown in Figures 4.5 to 4.7. The left panels in each of the ﬁgures indicate that all
marginal time series start within the range of the eventual posterior distributions, and
no serial autocorrelation or changes in variability seem to be present after thinning. Due
to the large amount of noise, the right panels are evaluated for a better understanding
of stability and determination of burn-in periods. In general, all marginal hyperparam-
eters seem to have suﬃciently converged, see for example Π77, or nearly converged as
for, e.g., Γ21, where a slow upward movement of the ergodic mean seems to be still
ongoing. A sample of the Markov chain after a burn-in period of, say, 500,000 values
would already give a promisingly good approximation of the marginal posterior distri-
butions. The length of such a sample can further be expected to yield a reasonably valid
approximation of the joint posterior distribution; however, a longer run of the MCMC
algorithm would naturally be favourable. Plots of selected entries in Ω, as shown in Fig-
ure 4.3, draw a similar picture, but with increasing concern regarding insuﬃcient length
of the Markov chain to exhibit undoubted convergence. In particular, corresponding
plots for Ω−1 in Figure 4.4 such as for, e.g., Ω−1
44 reveal the necessity for more iterations
to establish full convergence and larger samples to compensate the higher magnitudes of
serial autocorrelation and changes in variability. With the purpose of illustrating several
examples in this work, this MCMC algorithm is not further conducted, and a burn-in
period of 750,000 values will be used in the later course of this case study to obtain
rough approximations of the posterior distribution of all hyperparameters. However,
the MCMC estimation should be run far longer to obtain precise results in any real-life
application, since joint convergence in this high-dimensional set-up intuitively requires
even more time to be reached. Plots for various other selected marginal hyperparameters
and parameters for all choices of k and r were also analysed by the author supporting
previous conclusions, but cannot be discussed here in detail.
With the choice of a burn-in period of 750,000 iterations, in addition to the previously
discussed graphical output for each hyperparameter, the pivotal comparison of ergodic
means
¯ta −¯tb
q
d
Var(¯ta −¯tb)
72

4 Case Studies in European Mortality Forecasting
is computed as explained in Appendix B.4, where ¯ta and ¯tb denote the sample means at
the iterations 750,000–850,000 and 900,000–1,000,000 after thinning, respectively. Based
on plots of the autocorrelation functions (not shown), the thinned samples of the hyper-
parameters are satisfactorily pseudo-independent such that the variance of the diﬀerence
in sample means is estimated via the sum of variance estimators for iid sample means.
The more hyperparameters have already converged, the lower are the rejection rates
under the approximate standard normal distribution. The null hypothesis of conver-
gence is rejected for 46.4% of the entries of Ω, 69.2% for Ω−1, 0.6% for Π, 15.4% for φ,
and 5.9% for Γ on a nominal conﬁdence level of α∗= 2.47 · 10−5, chosen such that the
Bonferroni method yields a global type I error rate of α = 0.05. These numbers support
previous ﬁndings in that a longer MCMC run is required for the Markov chain to reach
an equilibrium for all entries in the covariance matrix and, to some extent, φ. Rejection
rates for the hyperparameters Π and Γ do not lead to evidence against convergence.
The hierarchical structure of the BMPMP model naturally requires an extensively long
duration for the posterior sample to yield a suﬃcient sample for the parameters in the
CBD model.
Hence, turning to the convergence plots for K in Figures 4.8 and 4.9,
it is not surprising to see less satisfying results than what was observed for the hy-
perparameters.
Obvious ongoing trends indicate that the Markov chain has not yet
converged for the majority of parameters. This is supported by a rejection of the null
hypothesis of convergence for 89.3% of parameters in K when applying above test with
α∗= 4.93 · 10−5. The plots for κf
20 further warn against false conclusions from the pos-
sibility of long-lasting metastability. In addition, the dependence in the simultaneous
Bayesian estimation of the VECM let starting values be out of range and lead to higher
autocorrelation. Altogether, the analysis of these and similar plots for other parameters
and model set-ups clearly shows that the full posterior distribution for the joint set of
H and K is not yet available. In conclusion, the marginal posterior distribution of the
set of hyperparameters may be aﬀected through the simultaneousness of the estimation
procedure. However, previous results regarding H remain fruitful in that this study can
work with a rough approximation. More importantly, a suﬃciently large sample ob-
tained in a reasonably long run of the MCMC algorithm can at least give a true sample
of the marginal posterior distribution for the set of hyperparameters. Indeed, for the
desired purpose of the BMPMP model, namely forecasting mortality trends into the
future, the hierarchical design of the model only requires the posterior distribution of
73

4 Case Studies in European Mortality Forecasting
H to be able to simulate the posterior predictive distribution of K for future calendar
years. By way of contrast, the immediate marginal posterior distribution of κ1, . . . , κ40,
on which the model is calibrated, need not be known in Bayesian hierarchical modelling.
Non-convergence of the CBD parameters and, even more, the fact that convergence may
not be reached in computationally feasible time is hence negligible, as long as conver-
gence for the hyperparameters can be well-justiﬁed, which in turn appears viable.
Note that the convergence diagnostics for K already show that the posterior distribution
will not include its starting values, i.e. the ML estimates of the CBD model. This is in
line with ﬁndings by Czado et al. (2005) on their Bayesian modelling approach of the LC
model and results from the diﬀerent estimation methodologies: whereas the hierarchical
framework is estimated simultaneously in Bayesian statistics, the frequentist estimates
stem from a sequential procedure with the potential risk of incoherent results.
4.1.5 Posterior Predictive Checking
Under the conclusion that the MCMC algorithm yields at least a rough, if not good,
approximation of the hyperparameters in H, the BMPMP model itself must now be
checked for the general ability to ﬁt the observed data in D and E well. If there is
evidence of lack of ﬁt, estimators for model parameters are biased, and any inference,
particularly forecasts of mortality into the future, is invalid. Diagnostics of goodness-of-
ﬁt in this Bayesian framework is done via posterior predictive checking, which comprises
comparison of the observed quantities and the posterior distribution of replicated values
through graphical tools or computation of Bayesian discrepancy tests and corresponding
p-values. A general overview on diagnostic quantiﬁcation techniques in Bayesian statis-
tics is given in Appendix A.4.
As the Bayesian version of standard internal prediction validation, the hyperparameters
H are ﬁrst simulated from their posterior distribution, i.e. values are sampled from
the MCMC output after discarding the burn-in period.
In the following, the entity
of all 2,500 thinned realisations after the burn-in period is used. Then, starting with
analogously sampled realisations from the posterior of κ1 and κ2, for each realisation of
H, the parameters in K are simulated via the VECM, thereby giving a sample of the
posterior predictive distribution of the CBD parameters over the calibration period.
74

4 Case Studies in European Mortality Forecasting
Figure 4.10: Posterior predictive checking for K
Shown are fancharts of selected marginal posterior predictive distributions for κt as time series in t for 1956, . . . , 1995
based on the MCMC output with N = 1,000,000, burn-in length of 750,000, and thinning factor 100. The
country-speciﬁc parameters are illustrated for the example of Spain. 90%, 95%, 99%, and 100% credibility intervals are
given by solid, dashed, dotted, and limiting lines, respectively. Red lines denote ML estimates (starting values).
1960
1970
1980
1990
-7.5
-7.0
-6.5
-6.0
-5.5
(a) Intercept κ0
t
1960
1970
1980
1990
-1.0
-0.5
0.0
0.5
(b) Gender eﬀect for females κf
t
1960
1970
1980
1990
0.02
0.04
0.06
0.08
0.10
0.12
0.14
(c) Linear age eﬀect κx
t
1960
1970
1980
1990
-0.0010
-0.0005
0.0000
0.0005
0.0010
0.0015
(d) Quadratic age eﬀect κx2
t
1960
1970
1980
1990
-0.06
-0.04
-0.02
0.00
0.02
0.04
(e) Gender and linear age interactions κxf
t
1960
1970
1980
1990
-5e-04
0e+00
5e-04
1e-03
(f) Gender and quadratic age interactions κx2f
t
1960
1970
1980
1990
-1.0
-0.5
0.0
0.5
1.0
(g) Main country eﬀects κES
t
1960
1970
1980
1990
-0.6
-0.4
-0.2
0.0
0.2
(h) Gender and country interactions κES,f
t
1960
1970
1980
1990
-0.10
-0.05
0.00
0.05
(i) Linear age and country interactions κES,x
t
1960
1970
1980
1990
-0.0010
-0.0005
0.0000
0.0005
0.0010
0.0015
(j) Quadratic age and country interactions κES,x2
t
75

4 Case Studies in European Mortality Forecasting
Figure 4.11: Posterior predictive checking for ηxpgt for the age of 60
Shown are fancharts of marginal posterior predictive distributions for ηxpgt with x = 60 for all countries p (by rows) and
both genders g (by columns) as time series in t for 1956, . . . , 1995 based on the MCMC output with N = 1,000,000,
burn-in length of 750,000, and thinning factor 100. 90%, 95%, 99%, and 100% credibility intervals are given by solid,
dashed, dotted, and limiting lines, respectively. Green lines denote crude estimates from observed data.
1960
1970
1980
1990
-5.5
-5.0
-4.5
-4.0
-3.5
(a) German males
1960
1970
1980
1990
-6.0
-5.5
-5.0
-4.5
(b) German females
1960
1970
1980
1990
-6.0
-5.5
-5.0
-4.5
-4.0
-3.5
-3.0
(c) Spanish males
1960
1970
1980
1990
-6.5
-6.0
-5.5
-5.0
-4.5
-4.0
(d) Spanish females
1960
1970
1980
1990
-6.0
-5.5
-5.0
-4.5
-4.0
-3.5
-3.0
(e) French males
1960
1970
1980
1990
-6.5
-6.0
-5.5
-5.0
-4.5
-4.0
(f) French females
1960
1970
1980
1990
-6
-5
-4
-3
(g) Italian males
1960
1970
1980
1990
-7.0
-6.5
-6.0
-5.5
-5.0
-4.5
-4.0
(h) Italian females
1960
1970
1980
1990
-5.5
-5.0
-4.5
-4.0
-3.5
(i) British males
1960
1970
1980
1990
-5.5
-5.0
-4.5
(j) British females
76

4 Case Studies in European Mortality Forecasting
Figure 4.12: Posterior predictive checking for ηxpgt for the age of 80
Shown are fancharts of marginal posterior predictive distributions for ηxpgt with x = 80 for all countries p (by rows) and
both genders g (by columns) as time series in t for 1956, . . . , 1995 based on the MCMC output with N = 1,000,000,
burn-in length of 750,000, and thinning factor 100. 90%, 95%, 99%, and 100% credibility intervals are given by solid,
dashed, dotted, and limiting lines, respectively. Green lines denote crude estimates from observed data.
1960
1970
1980
1990
-4.0
-3.5
-3.0
-2.5
-2.0
-1.5
-1.0
(a) German males
1960
1970
1980
1990
-4.5
-4.0
-3.5
-3.0
-2.5
-2.0
-1.5
(b) German females
1960
1970
1980
1990
-4
-3
-2
-1
(c) Spanish males
1960
1970
1980
1990
-5
-4
-3
-2
(d) Spanish females
1960
1970
1980
1990
-5
-4
-3
-2
-1
(e) French males
1960
1970
1980
1990
-5.0
-4.5
-4.0
-3.5
-3.0
-2.5
-2.0
(f) French females
1960
1970
1980
1990
-5
-4
-3
-2
-1
(g) Italian males
1960
1970
1980
1990
-6
-5
-4
-3
-2
(h) Italian females
1960
1970
1980
1990
-3.5
-3.0
-2.5
-2.0
-1.5
(i) British males
1960
1970
1980
1990
-4.0
-3.5
-3.0
-2.5
-2.0
(j) British females
77

4 Case Studies in European Mortality Forecasting
Figure 4.10 shows the evaluation of selected marginal time series in K.
Since these
parameters are latent, their posterior predictive distribution is checked for inclusion of
the ML estimates, i.e. their starting values, which is the case on high credibility lev-
els. In Figures 4.11 and 4.12, the resulting linear predictors ηxpgt as time series in t
are compared to their crude estimates from the raw data for each combination of all
ﬁve countries and both genders for the ﬁxed values of x = 60 and x = 80, i.e. the
ages 60 and 80. The graphical output clearly shows a very close agreement between
the observed data and the medians of the posterior distributions. A major deviation
can only be detected for British 60-year-old females, where the observed data are still
found to lie within the pointwise 90% credibility interval. In fact, as the nominal credi-
bility intervals for the posterior distribution appear to be wider than what they should
be, based on the comparison with the crude estimates, these results exhibit a notice-
able magnitude of optimism, which is commonly observed in internal validation analyses.
Although in the literature on other Bayesian mortality prediction models, the analysis
of model ﬁt is restricted to the assessment of graphical and tabular MCMC output, it
is good statistical practice to conduct quantitative goodness-of-ﬁt tests to assess the
appropriateness of the chosen model. For example, since the sum of all mutually inde-
pendent Dxpgt is again Poisson distributed with the mean being the sum of all individual
means, the standardised residual for the overall death count, i.e.
T(D, E, K) =
P100
x=40
P
p∈P
P
g∈{m,f}
P40
t=1 (Dxpgt −log (1 + exp(ηxpgt)) Expgt)
qP100
x=40
P
p∈P
P
g∈{m,f}
P40
t=1 log (1 + exp(ηxpgt)) Expgt
,
is used as a summary test statistic. For each set of posterior predictive values K, it is
evaluated at the observed number of deaths and exposure-to-risk. The reference distribu-
tion is the posterior distribution of this test statistic obtained by replacing the observed
Dxpgt by their posterior predictive realisations Drep
xpgt. The Bayesian posterior predictive
p-value corresponds to the posterior probability of observing more extreme outcomes
for the replicated than for the historical data, i.e. P(T(Drep, E, K) ≥T(D, E, K) | D, E).
Indeed, the p-value is computed to be 0.41 and, hence, not close to either extreme value
0 or 1. On the other hand, conducting this test with the immediate posterior values
for K leads to a p-value of 0.95, indicating lack of ﬁt when the model’s main goal was
estimation of historical values. In fact, Czado et al. (2005) point out that any type of –
78

4 Case Studies in European Mortality Forecasting
what they call – “robust”, i.e. hierarchical and parsimonious, mortality projection model
generally shows a poor ﬁt. Due to the large sample size of 5 · 2 · 61 · 40 = 24,400 death
counts, it is not surprising to see statistical tests leading to rejection of the comparably
simplistic two-level hierarchical BMPMP model with its simplifying Poisson assump-
tion. For further illustration, the general omnibus test from (A.1) in Appendix A.4 is
computed, which in this case study becomes
T(D, E, K) =
100
X
x=40
X
p∈P
X
g∈{m,f}
40
X
t=1
(Dxpgt −E(Dxpgt | Expgt, K))2
Var(Dxpgt | Expgt, K)
=
100
X
x=40
X
p∈P
X
g∈{m,f}
40
X
t=1
(Dxpgt −log (1 + exp(ηxpgt)) Expgt)2
log (1 + exp(ηxpgt)) Expgt
,
using the properties of the Poisson distribution. Plugging in the posterior predictive or
immediate posterior values K, this classical goodness-of-ﬁt test statistic is evaluated at
the observed number of deaths and, to obtain the reference distribution, at the poste-
rior predictive realisations for Dxpgt. The Bayesian p-value corresponds to the posterior
excess probability of T(Drep, E, K) compared to T(D, E, K) and turns out to be zero for
either choice of K, i.e. the omnibus test yields the strongest evidence possible against
the BMPMP model. However, based on the previously discussed graphical output, by
similarity to other models in mortality forecasting, it is concluded that the statistical
evidence against the model should not be used to rule out its obvious ability to produce
realistic stochastic mortality forecasts.
The previous discussion yields a Bayesian posterior check for the entity of the BMPMP
model. Since the marginal posterior distribution of the parameters K was used in par-
ticular cases, it can be further understood as a speciﬁc check of the CBD model. It
may be of additional interest to the analyst how the VECM, i.e. the second stage in
the two-level hierarchy, performs on its own. However, model diagnostics, in light of
the well-understood techniques described in Appendix A.4 for the separate VECM, can-
not be performed, since the underlying data are the latent parameters from the CBD
model and subject to change. Classical statistical tests on residual autocovariance or
the normality of the white noise, such as the Portmanteau, Lagrange-Multiplier, and
Lomnicki-Jarque-Bera tests described in Appendix C.6, are hence not available for pos-
terior predictive checking, as the data do not remain ﬁxed. However, to get some insight
79

4 Case Studies in European Mortality Forecasting
in the performance of the VECM, the joint posterior distribution for the residual auto-
and cross-correlation matrix is derived from the full joint distribution on both H and
K. A good model ﬁt would lead to posterior residual autocorrelations scattering around
zero, but the analysis (not shown) reveals that marginal posterior distributions for these
values usually do not contain zero. This indication of lack of ﬁt is not regarded con-
clusive due to the latent behaviour of K, its non-convergence in the MCMC algorithm,
and the general problems with robust mortality prediction models. Details and further
investigation of the VECM is therefore omitted here.
4.1.6 External Validation
With the choice of the calibration window 1956–1995, an out-of-sample dataset with
death counts for the years 1996–2009 is available, such that the goodness of forecasting
of the BMPMP model can be assessed through the Bayesian counterpart of external
validation, thereby eliminating the optimism seen in the results from the previous sec-
tion. For illustration purposes, the forecast period is further extended until 2014. Again,
the posterior predictive distribution for the future values κt, t = 41, . . . , 59, is derived
through sampling realisations from the posterior for H and subsequent simulation of κt
using the VECM. The posterior distribution for the hyperparameters is approximated
with the same MCMC output as before. Starting values for the time series at the now
initial years 1994 and 1995 are drawn from the posterior distribution of (κ39, κ40). Fig-
ure 4.13 shows the evaluation of the marginal time series from Figure 4.10 until 2014,
along with its ML estimates over the calibration period for comparison. Figures 4.14
and 4.15 depict the resulting linear predictors ηxpgt as time series in t with the same
choices for x as before. Here, for all plots, both the historical and future crude estimates
until 2009 from the raw data are given for evaluation of the goodness of prediction.
The plots in Figure 4.13 display a generally well-behaving forecast nature for the latent
time series in K. Historical trends are found to continue over the years 1996–2014 with
linearly increasing credibility bands, i.e. a continuously growing domain for the proba-
bility mass of all parameters to account for future uncertainties. The slopes of future
realisations in plots for, e.g., the intercept (a), linear age eﬀects (c), and the parameters
for Spain (g–j) reveal that the Bayesian estimates do not prolong the most current trend,
but rather exhibit all kinds of developments that the time series has experienced over
80

4 Case Studies in European Mortality Forecasting
the calibration period. For example, the pace of decline for the time series of κES,f
t
in
(h) seems to be lower than what would be expected based on the development over the
course of the most recent twenty years. The smaller magnitude of the slope is explained
by the stable, if not increasing, pattern of the time series for the years 1956–1975. These
results signalise the apparently speciﬁc feature of the BMPMP model to be strongly
inﬂuenced by the entire calibration period. Strong sensitivity towards the calibration
period is a common concern found for most stochastic mortality projection models; see
Cairns et al. (2009) for a general survey on models in the LC and CBD frameworks. As
a consequence, the time before the regime change, discovered in the discussion regarding
the starting values in Section 4.1.3, should be excluded for an improvement in mortality
projections.
Figures 4.14 and 4.15 show that the linear predictors ηxpgt for both ages x = 60 and
x = 80 carry over the characteristics of the forecasts for the marginal time series in K.
The linearly increasing fans in all plots correspond to the desired nature of continuously
growing uncertainty in future mortality predictions. The overly optimistic credibility
bands in the internal validation have become more realistic such that their width is
indeed required to cover crude estimates in most of the cases; for instance, see the plots
for German females with a noticeable amount of noise within the 90% credibility interval.
However, except for Spain and France, mortality rates for males are overestimated for
Germany, Italy, and – most notably – the United Kingdom, where crude estimates of
the linear predictor for x = 60 lie outside the lower 90% credibility boundary. Forecast
properties of the linear predictors resemble the previous ﬁnding for the marginal time
series regarding the sensitivity towards the calibration period. The increased pace in the
decline of linear predictors seen for the aforementioned countries suggest a calibration
period that excludes the years until 1980. It is noteworthy, however, that the BMPMP
model is still capable to capture major changes in population-speciﬁc mortality trends
through its tails, an important feature for the model’s prediction quality, particularly
when future outcomes are indeed unknown.
81

4 Case Studies in European Mortality Forecasting
Figure 4.13: External validation for K
Shown are fancharts of selected marginal posterior predictive distributions for future κt as time series in t for
1996, . . . , 2014, along with ML estimates for κt for 1956, . . . , 1995 for the same MCMC output as in Figure 4.10. The
country-speciﬁc parameters are illustrated for the example of Spain. 90%, 95%, 99%, and 100% credibility intervals are
given by solid, dashed, dotted, and limiting lines, respectively.
1960
1970
1980
1990
2000
2010
-6.8
-6.6
-6.4
-6.2
-6.0
-5.8
(a) Intercept κ0
t
1960
1970
1980
1990
2000
2010
-1.0
-0.9
-0.8
-0.7
-0.6
-0.5
-0.4
(b) Gender eﬀect for females κf
t
1960
1970
1980
1990
2000
2010
0.05
0.06
0.07
0.08
0.09
0.10
0.11
(c) Linear age eﬀect κx
t
1960
1970
1980
1990
2000
2010
-2e-04
0e+00
2e-04
4e-04
6e-04
8e-04
1e-03
(d) Quadratic age eﬀect κx2
t
1960
1970
1980
1990
2000
2010
-0.03
-0.02
-0.01
0.00
0.01
(e) Gender and linear age interactions κxf
t
1960
1970
1980
1990
2000
2010
0e+00
2e-04
4e-04
6e-04
(f) Gender and quadratic age interactions κx2f
t
1960
1970
1980
1990
2000
2010
-0.2
0.0
0.2
0.4
0.6
(g) Main country eﬀects κES
t
1960
1970
1980
1990
2000
2010
-0.25
-0.20
-0.15
-0.10
-0.05
0.00
0.05
(h) Gender and country interactions κES,f
t
1960
1970
1980
1990
2000
2010
-0.04
-0.03
-0.02
-0.01
0.00
0.01
(i) Linear age and country interactions κES,x
t
1960
1970
1980
1990
2000
2010
-2e-04
0e+00
2e-04
4e-04
6e-04
8e-04
(j) Quadratic age and country interactions κES,x2
t
82

4 Case Studies in European Mortality Forecasting
Figure 4.14: External validation for ηxpgt for the age of 60
Shown are fancharts of marginal posterior predictive distributions for future ηxpgt with x = 60 for all countries p (by
rows) and both genders g (by columns) as time series in t for 1996, . . . , 2014, along with crude estimates for ηxpgt for
1956, . . . , 2009 from observed data (green lines) for the same MCMC output as in Figure 4.11. 90%, 95%, 99%, and
100% credibility intervals are given by solid, dashed, dotted, and limiting lines, respectively.
1960
1970
1980
1990
2000
2010
-5.2
-5.0
-4.8
-4.6
-4.4
-4.2
-4.0
-3.8
(a) German males
1960
1970
1980
1990
2000
2010
-5.5
-5.0
-4.5
(b) German females
1960
1970
1980
1990
2000
2010
-5.5
-5.0
-4.5
-4.0
(c) Spanish males
1960
1970
1980
1990
2000
2010
-6.5
-6.0
-5.5
-5.0
-4.5
(d) Spanish females
1960
1970
1980
1990
2000
2010
-5.0
-4.5
-4.0
(e) French males
1960
1970
1980
1990
2000
2010
-6.0
-5.5
-5.0
-4.5
(f) French females
1960
1970
1980
1990
2000
2010
-5.5
-5.0
-4.5
-4.0
(g) Italian males
1960
1970
1980
1990
2000
2010
-6.0
-5.5
-5.0
-4.5
(h) Italian females
1960
1970
1980
1990
2000
2010
-5.2
-5.0
-4.8
-4.6
-4.4
-4.2
-4.0
-3.8
(i) British males
1960
1970
1980
1990
2000
2010
-5.6
-5.4
-5.2
-5.0
-4.8
-4.6
-4.4
(j) British females
83

4 Case Studies in European Mortality Forecasting
Figure 4.15: External validation for ηxpgt for the age of 80
Shown are fancharts of marginal posterior predictive distributions for future ηxpgt with x = 80 for all countries p (by
rows) and both genders g (by columns) as time series in t for 1996, . . . , 2014, along with crude estimates for ηxpgt for
1956, . . . , 2009 from observed data (green lines) for the same MCMC output as in Figure 4.12. 90%, 95%, 99%, and
100% credibility intervals are given by solid, dashed, dotted, and limiting lines, respectively.
1960
1970
1980
1990
2000
2010
-3.2
-3.0
-2.8
-2.6
-2.4
-2.2
-2.0
(a) German males
1960
1970
1980
1990
2000
2010
-3.5
-3.0
-2.5
-2.0
(b) German females
1960
1970
1980
1990
2000
2010
-3.5
-3.0
-2.5
-2.0
(c) Spanish males
1960
1970
1980
1990
2000
2010
-4.0
-3.5
-3.0
-2.5
-2.0
(d) Spanish females
1960
1970
1980
1990
2000
2010
-3.5
-3.0
-2.5
-2.0
(e) French males
1960
1970
1980
1990
2000
2010
-4.0
-3.5
-3.0
-2.5
(f) French females
1960
1970
1980
1990
2000
2010
-3.5
-3.0
-2.5
-2.0
(g) Italian males
1960
1970
1980
1990
2000
2010
-4.0
-3.5
-3.0
-2.5
-2.0
(h) Italian females
1960
1970
1980
1990
2000
2010
-3.2
-3.0
-2.8
-2.6
-2.4
-2.2
-2.0
(i) British males
1960
1970
1980
1990
2000
2010
-3.5
-3.0
-2.5
(j) British females
84

4 Case Studies in European Mortality Forecasting
4.1.7 Change of Calibration Period to 1981–2009
The previous sections have shown that the MCMC algorithm has not fully converged
for the CBD parameters and, to minor extent, for the hyperparameters in H, and that
statistical tests lead to rejection of a good model ﬁt. However, based on the posterior
predictive distribution for simulated future mortality rates, the BMPMP model with
rough posterior approximations for the hyperparameters produces good prediction re-
sults with the desired properties of quantifying a linearly increasing trend in uncertainty.
As common in stochastic mortality prediction, sensitivity towards the choice of the cal-
ibration period was discovered, such that in the particular example above, it appears
reasonable to restrict the calibration window to the years after 1980. For a suﬃciently
long history and for the most current application of mortality forecasts, the calibration
window is chosen to be 1981–2009, i.e. including most recent data. Further details of the
BMPMP model’s outcome will be discussed in the course of the updated model. Prior
to this, convergence and model diagnostics will be concisely re-evaluated.
Figures 4.16 to 4.29 contain the plots from the previous discussion replicated for the
model in (4.1) with t = 1, . . . , 29, representing the calibration window 1981–2009. All
convergence plots depict the same hyperparameters from before, and for the CBD pa-
rameter level, the selected marginal MCMC output is made for κ15 and κ29. Since data
are only available up to the end of the calibration period, i.e. the calendar year 2009,
external validation cannot be performed. However, plots of forecast until the year of
2100 are provided for a qualitative assessment of the model’s future mortality predictions.
The starting values in Figure 4.16 reveal that, contrary to the previous discussion, no
global regime change took place during the years 1981–2009.
A point of reverse in
the British and, to some minore extent, Spanish parameters at the early 1990s clearly
explain why, in the earlier model, mortality predictions for these countries deviated from
the best prediction given by the distribution’s mean or median. More importantly, the
quantiﬁcation of population-speciﬁc deviations from the mean mortality development in
the BMPMP model reveals that a convergent behaviour cannot be claimed for the period
of 1981–2009.
By contrast, diﬀerences remain rather stable or even diverge slightly.
This result is in favour of the BMPMP model, which does not state any convergence
hypotheses explicitly, but lets the data speak for themselves.
85

4 Case Studies in European Mortality Forecasting
Figure 4.16: Starting values for K
Shown are the ML estimates κ(0)
t
of the CBD parameters as time series in t for 1981, . . . , 2009.
1980
1985
1990
1995
2000
2005
2010
-6.3
-6.2
-6.1
-6.0
(a) Intercept κ0(0)
t
1980
1985
1990
1995
2000
2005
2010
-0.75
-0.70
-0.65
(b) Gender eﬀect for females κf(0)
t
1980
1985
1990
1995
2000
2005
2010
0.075
0.080
0.085
0.090
0.095
(c) Linear age eﬀect κx(0)
t
1980
1985
1990
1995
2000
2005
2010
0e+00
1e-04
2e-04
3e-04
4e-04
(d) Quadratic age eﬀect κx2(0)
t
1980
1985
1990
1995
2000
2005
2010
-0.0105
-0.0100
-0.0095
-0.0090
-0.0085
-0.0080
-0.0075
-0.0070
(e) Gender and linear age interactions κxf(0)
t
1980
1985
1990
1995
2000
2005
2010
0.00028
0.00030
0.00032
0.00034
0.00036
0.00038
(f) Gender and quadratic age interactions κx2f(0)
t
1980
1985
1990
1995
2000
2005
2010
-0.4
-0.2
0.0
0.2
0.4
DE
DE
DE
DE
ES
ES
ES
ES
FR
FR
FR
FR
IT
IT
IT
IT
UK
UK
UK
UK
EU
EU
EU
EU
(g) Main country eﬀects κp(0)
t
1980
1985
1990
1995
2000
2005
2010
-0.10
-0.05
0.00
0.05
0.10
DE
DE
DE
DEES
ES
ES
ES
FR
FR
FR
FR
IT
IT
IT
IT
UK
UK
UK
UK
EU
EU
EU
EU
(h) Gender and country interactions κpf(0)
t
1980
1985
1990
1995
2000
2005
2010
-0.03
-0.02
-0.01
0.00
0.01
0.02
DE
DE
DE
DEES
ES
ES
ES
FR
FR
FR
FR
IT
IT
IT
IT
UK
UK
UK
UK
EU
EU
EU
EU
(i) Linear age and country interactions κpx(0)
t
1980
1985
1990
1995
2000
2005
2010
-4e-04
-2e-04
0e+00
2e-04
4e-04
DE
DE
DE
DEES
ES
ES
ES
FR
FR
FR
FR
IT
IT
IT
IT
UK
UK
UK
UK
EU
EU
EU
EU
(j) Quadratic age and country interactions κpx2(0)
t
86

4 Case Studies in European Mortality Forecasting
Figure 4.17: Convergence diagnostics for Ω
Left panel: Realised marginal paths of selected entries of Ωafter running the MCMC algorithm with N = 1,000,000
iterations subject to thinning by a factor of 100. Right panel: Corresponding evolution of the ergodic means.
Indices: Indices in VECM refer to the following marginal time series: 1 – κ0
t , 2 – κf
t , 4 – κx2
t , 7 – κDE
t
.
0
2000
4000
6000
8000
10000
1e-04
2e-04
3e-04
4e-04
5e-04
6e-04
7e-04
(a) MCMC path for Ω11
0
2000
4000
6000
8000
10000
0.00019
0.00020
0.00021
0.00022
0.00023
(b) Cumulative plot of ergodic mean for Ω11
0
2000
4000
6000
8000
10000
-6e-04
-5e-04
-4e-04
-3e-04
-2e-04
-1e-04
0e+00
(c) MCMC path for Ω21
0
2000
4000
6000
8000
10000
-0.00014
-0.00013
-0.00012
-0.00011
-0.00010
-0.00009
-0.00008
(d) Cumulative plot of ergodic mean for Ω21
0
2000
4000
6000
8000
10000
2e-07
4e-07
6e-07
8e-07
(e) MCMC path for Ω41
0
2000
4000
6000
8000
10000
2.3e-07
2.4e-07
2.5e-07
2.6e-07
2.7e-07
2.8e-07
2.9e-07
(f) Cumulative plot of ergodic mean for Ω41
0
2000
4000
6000
8000
10000
2.0e-10
4.0e-10
6.0e-10
8.0e-10
1.0e-09
1.2e-09
(g) MCMC path for Ω44
0
2000
4000
6000
8000
10000
3.7e-10
3.8e-10
3.9e-10
4.0e-10
4.1e-10
4.2e-10
4.3e-10
(h) Cumulative plot of ergodic mean for Ω44
0
2000
4000
6000
8000
10000
1e-04
2e-04
3e-04
4e-04
5e-04
(i) MCMC path for Ω77
0
2000
4000
6000
8000
10000
0.00015
0.00016
0.00017
0.00018
0.00019
0.00020
(j) Cumulative plot of ergodic mean for Ω77
87

4 Case Studies in European Mortality Forecasting
Figure 4.18: Convergence diagnostics for Ω−1
Left panel: Realised marginal paths of selected entries of Ω−1 after running the MCMC algorithm with N = 1,000,000
iterations subject to thinning by a factor of 100. Right panel: Corresponding evolution of the ergodic means.
Indices: Indices in VECM refer to the following marginal time series: 1 – κ0
t , 2 – κf
t , 4 – κx2
t , 7 – κDE
t
.
0
2000
4000
6000
8000
10000
5.0e+07
1.0e+08
1.5e+08
2.0e+08
2.5e+08
3.0e+08
3.5e+08
(a) MCMC path for Ω−1
11
0
2000
4000
6000
8000
10000
2.0e+07
4.0e+07
6.0e+07
8.0e+07
1.0e+08
1.2e+08
1.4e+08
(b) Cumulative plot of ergodic mean for Ω−1
11
0
2000
4000
6000
8000
10000
-1.5e+08
-1.0e+08
-5.0e+07
0.0e+00
5.0e+07
1.0e+08
(c) MCMC path for Ω−1
21
0
2000
4000
6000
8000
10000
-4e+07
-3e+07
-2e+07
-1e+07
0e+00
1e+07
2e+07
(d) Cumulative plot of ergodic mean for Ω−1
21
0
2000
4000
6000
8000
10000
-1e+12
-8e+11
-6e+11
-4e+11
-2e+11
0e+00
(e) MCMC path for Ω−1
41
0
2000
4000
6000
8000
10000
-2.5e+11
-2.0e+11
-1.5e+11
-1.0e+11
-5.0e+10
(f) Cumulative plot of ergodic mean for Ω−1
41
0
2000
4000
6000
8000
10000
0.0e+00
2.0e+15
4.0e+15
6.0e+15
8.0e+15
1.0e+16
1.2e+16
(g) MCMC path for Ω−1
44
0
2000
4000
6000
8000
10000
0e+00
1e+15
2e+15
3e+15
4e+15
(h) Cumulative plot of ergodic mean for Ω−1
44
0
2000
4000
6000
8000
10000
5.0e+07
1.0e+08
1.5e+08
2.0e+08
2.5e+08
3.0e+08
3.5e+08
(i) MCMC path for Ω−1
77
0
2000
4000
6000
8000
10000
4.0e+07
6.0e+07
8.0e+07
1.0e+08
1.2e+08
(j) Cumulative plot of ergodic mean for Ω−1
77
88

4 Case Studies in European Mortality Forecasting
Figure 4.19: Convergence diagnostics for Π = αβ′
Left panel: Realised marginal paths of selected entries of Π after running the MCMC algorithm with N = 1,000,000
iterations subject to thinning by a factor of 100. Right panel: Corresponding evolution of the ergodic means.
Indices: Indices in VECM refer to the following marginal time series: 1 – κ0
t , 2 – κf
t , 4 – κx2
t , 7 – κDE
t
.
0
2000
4000
6000
8000
10000
-0.03
-0.02
-0.01
0.00
0.01
0.02
0.03
(a) MCMC path for Π11
0
2000
4000
6000
8000
10000
-0.002
-0.001
0.000
0.001
0.002
0.003
(b) Cumulative plot of ergodic mean for Π11
0
2000
4000
6000
8000
10000
-0.03
-0.02
-0.01
0.00
0.01
0.02
0.03
(c) MCMC path for Π21
0
2000
4000
6000
8000
10000
-0.006
-0.004
-0.002
0.000
(d) Cumulative plot of ergodic mean for Π21
0
2000
4000
6000
8000
10000
-4e-05
-2e-05
0e+00
2e-05
4e-05
(e) MCMC path for Π41
0
2000
4000
6000
8000
10000
-4e-06
-2e-06
0e+00
2e-06
4e-06
6e-06
(f) Cumulative plot of ergodic mean for Π41
0
2000
4000
6000
8000
10000
-4e-05
-2e-05
0e+00
2e-05
4e-05
(g) MCMC path for Π44
0
2000
4000
6000
8000
10000
-2.0e-05
-1.5e-05
-1.0e-05
-5.0e-06
0.0e+00
(h) Cumulative plot of ergodic mean for Π44
0
2000
4000
6000
8000
10000
-0.03
-0.02
-0.01
0.00
0.01
0.02
0.03
(i) MCMC path for Π77
0
2000
4000
6000
8000
10000
-0.003
-0.002
-0.001
0.000
0.001
(j) Cumulative plot of ergodic mean for Π77
89

4 Case Studies in European Mortality Forecasting
Figure 4.20: Convergence diagnostics for φ
Left panel: Realised marginal paths of selected entries of φ after running the MCMC algorithm with N = 1,000,000
iterations subject to thinning by a factor of 100. Right panel: Corresponding evolution of the ergodic means.
Indices: Indices in VECM refer to the following marginal time series: 1 – κ0
t , 2 – κf
t , 4 – κx2
t , 7 – κDE
t
, 17 – κx,DE
t
.
0
2000
4000
6000
8000
10000
-0.2
-0.1
0.0
0.1
(a) MCMC path for φ1
0
2000
4000
6000
8000
10000
-0.030
-0.025
-0.020
-0.015
-0.010
-0.005
0.000
0.005
(b) Cumulative plot of ergodic mean for φ1
0
2000
4000
6000
8000
10000
-0.2
-0.1
0.0
0.1
0.2
(c) MCMC path for φ2
0
2000
4000
6000
8000
10000
-0.03
-0.02
-0.01
0.00
0.01
(d) Cumulative plot of ergodic mean for φ2
0
2000
4000
6000
8000
10000
-2e-04
-1e-04
0e+00
1e-04
2e-04
3e-04
(e) MCMC path for φ4
0
2000
4000
6000
8000
10000
-1e-05
0e+00
1e-05
2e-05
3e-05
4e-05
(f) Cumulative plot of ergodic mean for φ4
0
2000
4000
6000
8000
10000
-0.15
-0.10
-0.05
0.00
0.05
0.10
0.15
(g) MCMC path for φ7
0
2000
4000
6000
8000
10000
-0.015
-0.010
-0.005
0.000
0.005
0.010
0.015
(h) Cumulative plot of ergodic mean for φ7
0
2000
4000
6000
8000
10000
-0.010
-0.005
0.000
0.005
(i) MCMC path for φ17
0
2000
4000
6000
8000
10000
-5e-04
0e+00
5e-04
1e-03
(j) Cumulative plot of ergodic mean for φ17
90

4 Case Studies in European Mortality Forecasting
Figure 4.21: Convergence diagnostics for Γ = Γ1
Left panel: Realised marginal paths of selected entries of Γ after running the MCMC algorithm with N = 1,000,000
iterations subject to thinning by a factor of 100. Right panel: Corresponding evolution of the ergodic means.
Indices: Indices in VECM refer to the following marginal time series: 1 – κ0
t , 2 – κf
t , 4 – κx2
t , 7 – κDE
t
.
0
2000
4000
6000
8000
10000
-0.3
-0.2
-0.1
0.0
0.1
0.2
(a) MCMC path for Γ11
0
2000
4000
6000
8000
10000
-0.08
-0.06
-0.04
-0.02
0.00
0.02
0.04
(b) Cumulative plot of ergodic mean for Γ11
0
2000
4000
6000
8000
10000
-0.3
-0.2
-0.1
0.0
0.1
0.2
0.3
(c) MCMC path for Γ21
0
2000
4000
6000
8000
10000
-0.06
-0.04
-0.02
0.00
0.02
(d) Cumulative plot of ergodic mean for Γ21
0
2000
4000
6000
8000
10000
-4e-04
-2e-04
0e+00
2e-04
(e) MCMC path for Γ41
0
2000
4000
6000
8000
10000
-0.00015
-0.00010
-0.00005
0.00000
(f) Cumulative plot of ergodic mean for Γ41
0
2000
4000
6000
8000
10000
-4e-04
-2e-04
0e+00
2e-04
4e-04
(g) MCMC path for Γ44
0
2000
4000
6000
8000
10000
-6e-05
-5e-05
-4e-05
-3e-05
-2e-05
-1e-05
0e+00
(h) Cumulative plot of ergodic mean for Γ44
0
2000
4000
6000
8000
10000
-0.3
-0.2
-0.1
0.0
0.1
0.2
(i) MCMC path for Γ77
0
2000
4000
6000
8000
10000
-0.14
-0.12
-0.10
-0.08
-0.06
-0.04
(j) Cumulative plot of ergodic mean for Γ77
91

4 Case Studies in European Mortality Forecasting
Figure 4.22: Convergence diagnostics for κ15
Left panel: Realised marginal paths of selected entries of κ15 after running the MCMC algorithm with N = 1,000,000
iterations subject to thinning by a factor of 100. Right panel: Corresponding evolution of the ergodic means.
0
2000
4000
6000
8000
10000
-6.180
-6.178
-6.176
-6.174
-6.172
(a) MCMC path for κ0
15
0
2000
4000
6000
8000
10000
-6.179
-6.178
-6.177
-6.176
-6.175
-6.174
-6.173
(b) Cumulative plot of ergodic mean for κ0
15
0
2000
4000
6000
8000
10000
-0.708
-0.706
-0.704
-0.702
-0.700
(c) MCMC path for κf
15
0
2000
4000
6000
8000
10000
-0.705
-0.704
-0.703
-0.702
-0.701
-0.700
(d) Cumulative plot of ergodic mean for κf
15
0
2000
4000
6000
8000
10000
0.000167
0.000168
0.000169
0.000170
(e) MCMC path for κx2
15
0
2000
4000
6000
8000
10000
0.0001665
0.0001670
0.0001675
0.0001680
(f) Cumulative plot of ergodic mean for κx2
15
0
2000
4000
6000
8000
10000
0.045
0.050
0.055
(g) MCMC path for κDE
15
0
2000
4000
6000
8000
10000
0.048
0.050
0.052
0.054
(h) Cumulative plot of ergodic mean for κDE
15
0
2000
4000
6000
8000
10000
5e-04
6e-04
7e-04
8e-04
(i) MCMC path for κx,DE
15
0
2000
4000
6000
8000
10000
0.00050
0.00055
0.00060
0.00065
0.00070
(j) Cumulative plot of ergodic mean for κx,DE
15
92

4 Case Studies in European Mortality Forecasting
Figure 4.23: Convergence diagnostics for κ29
Left panel: Realised marginal paths of selected entries of κ29 after running the MCMC algorithm with N = 1,000,000
iterations subject to thinning by a factor of 100. Right panel: Corresponding evolution of the ergodic means.
0
2000
4000
6000
8000
10000
-6.388
-6.386
-6.384
-6.382
-6.380
-6.378
(a) MCMC path for κ0
29
0
2000
4000
6000
8000
10000
-6.385
-6.384
-6.383
-6.382
-6.381
-6.380
(b) Cumulative plot of ergodic mean for κ0
29
0
2000
4000
6000
8000
10000
-0.632
-0.630
-0.628
-0.626
-0.624
(c) MCMC path for κf
29
0
2000
4000
6000
8000
10000
-0.629
-0.628
-0.627
-0.626
-0.625
-0.624
-0.623
(d) Cumulative plot of ergodic mean for κf
29
0
2000
4000
6000
8000
10000
0.000466
0.000468
0.000470
0.000472
0.000474
0.000476
(e) MCMC path for κx2
29
0
2000
4000
6000
8000
10000
0.000467
0.000468
0.000469
0.000470
0.000471
0.000472
(f) Cumulative plot of ergodic mean for κx2
29
0
2000
4000
6000
8000
10000
-0.026
-0.024
-0.022
-0.020
-0.018
-0.016
(g) MCMC path for κDE
29
0
2000
4000
6000
8000
10000
-0.021
-0.020
-0.019
-0.018
-0.017
(h) Cumulative plot of ergodic mean for κDE
29
0
2000
4000
6000
8000
10000
0.00395
0.00400
0.00405
0.00410
(i) MCMC path for κx,DE
29
0
2000
4000
6000
8000
10000
0.00394
0.00396
0.00398
0.00400
0.00402
0.00404
(j) Cumulative plot of ergodic mean for κx,DE
29
93

4 Case Studies in European Mortality Forecasting
Figure 4.24: Posterior predictive checking for K
Shown are fancharts of selected marginal posterior predictive distributions for κt as time series in t for 1981, . . . , 2009
based on the MCMC output with N = 1,000,000, burn-in length of 750,000, and thinning factor 100. The
country-speciﬁc parameters are illustrated for the example of Spain. 90%, 95%, 99%, and 100% credibility intervals are
given by solid, dashed, dotted, and limiting lines, respectively. Red lines denote ML estimates (starting values).
1980
1985
1990
1995
2000
2005
2010
-6.8
-6.6
-6.4
-6.2
-6.0
(a) Intercept κ0
t
1980
1985
1990
1995
2000
2005
2010
-1.2
-1.0
-0.8
-0.6
-0.4
-0.2
0.0
(b) Gender eﬀect for females κf
t
1980
1985
1990
1995
2000
2005
2010
0.05
0.06
0.07
0.08
0.09
0.10
0.11
(c) Linear age eﬀect κx
t
1980
1985
1990
1995
2000
2005
2010
0e+00
5e-04
1e-03
(d) Quadratic age eﬀect κx2
t
1980
1985
1990
1995
2000
2005
2010
-0.04
-0.02
0.00
0.02
(e) Gender and linear age interactions κxf
t
1980
1985
1990
1995
2000
2005
2010
0e+00
2e-04
4e-04
6e-04
(f) Gender and quadratic age interactions κx2f
t
1980
1985
1990
1995
2000
2005
2010
-0.5
0.0
0.5
(g) Main country eﬀects κES
t
1980
1985
1990
1995
2000
2005
2010
-0.2
-0.1
0.0
0.1
(h) Gender and country interactions κES,f
t
1980
1985
1990
1995
2000
2005
2010
-0.04
-0.02
0.00
0.02
0.04
(i) Linear age and country interactions κES,x
t
1980
1985
1990
1995
2000
2005
2010
-6e-04
-4e-04
-2e-04
0e+00
2e-04
4e-04
6e-04
(j) Quadratic age and country interactions κES,x2
t
94

4 Case Studies in European Mortality Forecasting
Figure 4.25: Posterior predictive checking for ηxpgt for the age of 60
Shown are fancharts of marginal posterior predictive distributions for ηxpgt with x = 60 for all countries p (by rows) and
both genders g (by columns) as time series in t for 1981, . . . , 2009 based on the MCMC output with N = 1,000,000,
burn-in length of 750,000, and thinning factor 100. 90%, 95%, 99%, and 100% credibility intervals are given by solid,
dashed, dotted, and limiting lines, respectively. Green lines denote crude estimates from observed data.
1980
1985
1990
1995
2000
2005
2010
-5.0
-4.8
-4.6
-4.4
-4.2
-4.0
(a) German males
1980
1985
1990
1995
2000
2005
2010
-5.6
-5.4
-5.2
-5.0
-4.8
(b) German females
1980
1985
1990
1995
2000
2005
2010
-5.2
-5.0
-4.8
-4.6
-4.4
-4.2
(c) Spanish males
1980
1985
1990
1995
2000
2005
2010
-6.0
-5.8
-5.6
-5.4
-5.2
-5.0
(d) Spanish females
1980
1985
1990
1995
2000
2005
2010
-5.0
-4.8
-4.6
-4.4
-4.2
-4.0
(e) French males
1980
1985
1990
1995
2000
2005
2010
-6.0
-5.8
-5.6
-5.4
-5.2
-5.0
(f) French females
1980
1985
1990
1995
2000
2005
2010
-5.4
-5.2
-5.0
-4.8
-4.6
-4.4
-4.2
-4.0
(g) Italian males
1980
1985
1990
1995
2000
2005
2010
-6.0
-5.8
-5.6
-5.4
-5.2
-5.0
-4.8
(h) Italian females
1980
1985
1990
1995
2000
2005
2010
-5.0
-4.8
-4.6
-4.4
-4.2
-4.0
(i) British males
1980
1985
1990
1995
2000
2005
2010
-5.6
-5.4
-5.2
-5.0
-4.8
-4.6
(j) British females
95

4 Case Studies in European Mortality Forecasting
Figure 4.26: Posterior predictive checking for ηxpgt for the age of 80
Shown are fancharts of marginal posterior predictive distributions for ηxpgt with x = 80 for all countries p (by rows) and
both genders g (by columns) as time series in t for 1981, . . . , 2009 based on the MCMC output with N = 1,000,000,
burn-in length of 750,000, and thinning factor 100. 90%, 95%, 99%, and 100% credibility intervals are given by solid,
dashed, dotted, and limiting lines, respectively. Green lines denote crude estimates from observed data.
1980
1985
1990
1995
2000
2005
2010
-3.2
-3.0
-2.8
-2.6
-2.4
-2.2
-2.0
(a) German males
1980
1985
1990
1995
2000
2005
2010
-3.8
-3.6
-3.4
-3.2
-3.0
-2.8
-2.6
-2.4
(b) German females
1980
1985
1990
1995
2000
2005
2010
-3.5
-3.0
-2.5
-2.0
(c) Spanish males
1980
1985
1990
1995
2000
2005
2010
-4.5
-4.0
-3.5
-3.0
-2.5
(d) Spanish females
1980
1985
1990
1995
2000
2005
2010
-3.5
-3.0
-2.5
-2.0
(e) French males
1980
1985
1990
1995
2000
2005
2010
-4.0
-3.5
-3.0
-2.5
(f) French females
1980
1985
1990
1995
2000
2005
2010
-3.5
-3.0
-2.5
-2.0
(g) Italian males
1980
1985
1990
1995
2000
2005
2010
-4.5
-4.0
-3.5
-3.0
-2.5
-2.0
(h) Italian females
1980
1985
1990
1995
2000
2005
2010
-3.5
-3.0
-2.5
-2.0
(i) British males
1980
1985
1990
1995
2000
2005
2010
-3.5
-3.0
-2.5
(j) British females
96

4 Case Studies in European Mortality Forecasting
Figure 4.27: External validation for K
Shown are fancharts of selected marginal posterior predictive distributions for future κt as time series in t for
2010, . . . , 2100, along with ML estimates for κt for 1981, . . . , 2009 for the same MCMC output as in Figure 4.24. The
country-speciﬁc parameters are illustrated for the example of Spain. 90%, 95%, 99%, and 100% credibility intervals are
given by solid, dashed, dotted, and limiting lines, respectively.
1980 2000 2020 2040 2060 2080 2100
-14
-12
-10
-8
-6
(a) Intercept κ0
t
1980 2000 2020 2040 2060 2080 2100
-2
0
2
4
6
8
(b) Gender eﬀect for females κf
t
1980 2000 2020 2040 2060 2080 2100
-0.2
-0.1
0.0
0.1
0.2
(c) Linear age eﬀect κx
t
1980 2000 2020 2040 2060 2080 2100
-0.004
-0.002
0.000
0.002
0.004
0.006
(d) Quadratic age eﬀect κx2
t
1980 2000 2020 2040 2060 2080 2100
-0.3
-0.2
-0.1
0.0
0.1
0.2
(e) Gender and linear age interactions κxf
t
1980 2000 2020 2040 2060 2080 2100
-0.002
0.000
0.002
0.004
(f) Gender and quadratic age interactions κx2f
t
1980 2000 2020 2040 2060 2080 2100
-8
-6
-4
-2
0
2
4
(g) Main country eﬀects κES
t
1980 2000 2020 2040 2060 2080 2100
-2.0
-1.5
-1.0
-0.5
0.0
0.5
1.0
(h) Gender and country interactions κES,f
t
1980 2000 2020 2040 2060 2080 2100
-0.2
0.0
0.2
0.4
0.6
(i) Linear age and country interactions κES,x
t
1980 2000 2020 2040 2060 2080 2100
-0.010
-0.008
-0.006
-0.004
-0.002
0.000
0.002
0.004
(j) Quadratic age and country interactions κES,x2
t
97

4 Case Studies in European Mortality Forecasting
Figure 4.28: External validation for ηxpgt for the age of 60
Shown are fancharts of marginal posterior predictive distributions for future ηxpgt with x = 60 for all countries p (by
rows) and both genders g (by columns) as time series in t for 2010, . . . , 2100, along with crude estimates for ηxpgt for
1981, . . . , 2009 from observed data (green lines) for the same MCMC output as in Figure 4.25. 90%, 95%, 99%, and
100% credibility intervals are given by solid, dashed, dotted, and limiting lines, respectively.
1980 2000 2020 2040 2060 2080 2100
-12
-10
-8
-6
-4
(a) German males
1980 2000 2020 2040 2060 2080 2100
-10
-9
-8
-7
-6
-5
-4
(b) German females
1980 2000 2020 2040 2060 2080 2100
-12
-10
-8
-6
-4
(c) Spanish males
1980 2000 2020 2040 2060 2080 2100
-12
-10
-8
-6
(d) Spanish females
1980 2000 2020 2040 2060 2080 2100
-10
-9
-8
-7
-6
-5
-4
(e) French males
1980 2000 2020 2040 2060 2080 2100
-10
-8
-6
-4
-2
(f) French females
1980 2000 2020 2040 2060 2080 2100
-14
-12
-10
-8
-6
-4
(g) Italian males
1980 2000 2020 2040 2060 2080 2100
-14
-12
-10
-8
-6
(h) Italian females
1980 2000 2020 2040 2060 2080 2100
-12
-10
-8
-6
-4
(i) British males
1980 2000 2020 2040 2060 2080 2100
-10
-8
-6
-4
(j) British females
98

4 Case Studies in European Mortality Forecasting
Figure 4.29: External validation for ηxpgt for the age of 80
Shown are fancharts of marginal posterior predictive distributions for future ηxpgt with x = 80 for all countries p (by
rows) and both genders g (by columns) as time series in t for 2010, . . . , 2100, along with crude estimates for ηxpgt for
1981, . . . , 2009 from observed data (green lines) for the same MCMC output as in Figure 4.26. 90%, 95%, 99%, and
100% credibility intervals are given by solid, dashed, dotted, and limiting lines, respectively.
1980 2000 2020 2040 2060 2080 2100
-12
-10
-8
-6
-4
-2
(a) German males
1980 2000 2020 2040 2060 2080 2100
-10
-8
-6
-4
-2
0
(b) German females
1980 2000 2020 2040 2060 2080 2100
-15
-10
-5
0
(c) Spanish males
1980 2000 2020 2040 2060 2080 2100
-15
-10
-5
0
(d) Spanish females
1980 2000 2020 2040 2060 2080 2100
-10
-5
0
(e) French males
1980 2000 2020 2040 2060 2080 2100
-15
-10
-5
0
(f) French females
1980 2000 2020 2040 2060 2080 2100
-15
-10
-5
0
(g) Italian males
1980 2000 2020 2040 2060 2080 2100
-15
-10
-5
0
(h) Italian females
1980 2000 2020 2040 2060 2080 2100
-15
-10
-5
0
(i) British males
1980 2000 2020 2040 2060 2080 2100
-15
-10
-5
0
(j) British females
99

4 Case Studies in European Mortality Forecasting
The convergence plots in Figures 4.17 to 4.21 for the hyperparameters, and in Fig-
ures 4.22 and 4.23 for the parameters, lead to the same conclusions as before. In the
ﬁrst case, an approximation of the posterior distribution based on the thinned sample
after 750,000 burn-in iterations appears reasonable good, although the MCMC algo-
rithm should be run for longer to reach ultimate convergence, notably for Ωand the
undiagnosed joint distribution. Convergence to a stationary distribution has not yet
been reached for the CBD parameters.
Internal validation is performed in Figures 4.24 to 4.26. The ML estimates are included
in the 90% credibility intervals obtained from simulation of the time series over the
calibration window, and generally line up with the medians of the posterior predictive
distribution. While internal forecasts of the linear predictor at the age of 80 draw the
overly optimistic picture as before, counterparts for the age of 60 are less sophisticating.
Here, the width of the credibility intervals is rather realistic over the entire course of
simulation, as obvious from the plots for, e.g., German males and females (a–b). More
concerning, however, are results from plots of Spanish and British females, among others,
which show that the posterior predictive distribution may not include crude estimates of
ηxpgt based on observed data for the ﬁrst twenty years. For these countries, changes in
the trend are detected from the plots of country-speciﬁc age parameters in Figure 4.16,
which cannot be captured by their corresponding posterior predictive medians in Fig-
ure 4.24. In fact, the bad performance is due to substantial diﬀerences between the
crude values of the initial years 1981 and 1982 and their posterior predictive values of
κ1 and κ2 with their ML estimates as prior means. An increase of the prior variance
or even a non-informative prior might improve results, but the principal reliance of the
forecasts on the posterior predictive distribution of K, which was shown to suﬀer from
the commonly observed lack of ﬁt in mortality prediction models, seems to be a more
substantial problem. For now, it is concluded that the BMPMP model may lack ﬁt
for early years of the forecasting period, and future work should be devoted to improve
starting values of mortality predictions. However, from a biological point of view, the
country-speciﬁc deviation parameters are expected to stay within some certain range.
Future regime changes of such parameters should be captured by the growing long-term
variance in the posterior predictive distribution, as indeed seen in all aforementioned
cases.
100

4 Case Studies in European Mortality Forecasting
Finally, Figures 4.24 to 4.26 depict predictions of selected marginal CBD parameters and
their corresponding linear predictors for the unknown logits of mortality rates until 2100.
The linear and symmetric increase of uncertainty over a short forecast period of only a
couple of decades turns into a quadratic and skewed pattern in the long-run, notably
after around 50 years. Based on the output in Figure 4.24, best estimates given by the
medians of posterior predictive distributions prolong linear trends in the individual CBD
parameters. For example, an ongoing linear decline of linear predictors for 40-year-old
men in the reference population, known from the period 1981–2009, is anticipated. The
diﬀerence between men and women for this age group is expected to remain constant
or to diminish slowly. The projected medians for the age-related parameters suggest
a sustainable transmission from the rather linear pattern of mortality rates versus age
towards a merely and, in fact, pure quadratic eﬀect in the year of 2100 without major
diﬀerences between both genders. Medians for population-speciﬁc eﬀects, exemplarily
shown for Spain, stay closely around zero with a slightly declining trend for Spain over
the entire course of the forecast period.
On the subject of the uncertainty in the parameter estimates, the posterior predictive
distribution of the intercept allows the mortality improvements for a 40-year-old male
to reduce in pace or to worsen to a level known from the early 1980s, at the year of 2100
on a credibility level of 95%. More probability mass is devoted to the lower tail of the
distribution, i.e. deviations to a faster improvement in mortality are stronger. Here, 95%
credibility intervals allow the speed in mortality improvements to increase by a factor of
up to eight. As such, the Bayesian approach with its easily quantiﬁable uncertainty in
long-term mortality improvements replaces the elliptical forecasts of conﬁdence intervals
in common frequentist approaches by a wider variety of scenarios. With regards to the
rapid and sudden improvement in mortality rates observed for the 20th century, it is a
desired feature of the model’s 100-year-span prediction to cover potentially biologically
plausible changes due to unforeseen medical, social, and economic events. Interpretation
of the remaining parameters in Figure 4.24 should not be done marginally, because the
analogy of evolution in credibility bands suggests a strong correlation between future
paths such that extreme outcomes aﬀect each other. This is additionally supported by
the consistency of individual population- and gender-speciﬁc fancharts in Figures 4.25
and 4.26, in which extreme outcomes for the parameters seem to coincide. Median fore-
casts extend the linear decline of the linear predictors over the calibration window into
101

4 Case Studies in European Mortality Forecasting
the future. Posterior predictive distributions are generally skewed to the left, making
faster improvements in mortality more likely than slower or even deteriorating changes.
The similarity in future developments, e.g. the diminishing diﬀerences between both
genders, and distributions for the year 2100, which principally cover the same range of
possible values, indicate that population-speciﬁc mortality rates wander jointly rather
than independently. A discussion of the joint distribution of future predictions is specif-
ically undertaken in the following section.
4.1.8 Joint Posterior Predictive Distribution
In this section, the ability to jointly forecast mortality rates for an arbitrary number of
populations is assessed for this case study. As outlined earlier, certain marginal time se-
ries in K show strong correlation. Hence, in Bayesian forecasting, this correlation should
be observed for the future realisations of the CBD parameters. Figures 4.30 and 4.31
visualise the correlation matrices for the posterior predictive distribution of the vector
κt for the years 2050 and 2100, respectively. Strong or almost perfect correlation exists
between the six main population-independent parameters for intercept, gender, and age
eﬀects. For example, negative correlation is strong for the pairs intercept and gender,
linear age and quadratic age, and the linear and quadratic age interactions with gender.
Such dependencies are easily interpretable as cancellation eﬀects, if one gender or age
group beneﬁts from major mortality improvements only. Similar conclusions are drawn
for the many other correlations between these parameters. For the population-speciﬁc
parameters, high correlation is rather sparse, indicating that shocks within national
mortality data are connected to a limited extent. Whereas the population-speciﬁc main
and gender eﬀects do not exhibit much correlation among themselves, the analogous
correlation structure between main and age eﬀects is apparent. A notable feature is the
consistent joint behaviour for predicted K when going from 2050 to 2100 with a slightly
increasing magnitude in correlations, particularly for British parameters. Some other
strong covariances are scattered, whereas remaining correlation is less distinct.
The
latter ﬁnding suggests that parameter matrices in the VECM could be thinned out in
future work to reduce complexity in such high-dimensional models.
102

4 Case Studies in European Mortality Forecasting
Figure 4.30: Correlation matrix for κt at the year of 2050
Shown are the bivariate correlations of all marginal posterior predictive distributions for future κt with t for 2050 for the
MCMC output with N = 1,000,000, burn-in length of 750,000, and thinning factor 100. Blue and red circles denote
positive and negative correlation, respectively. The magnitude of the absolute correlation is given by both the circle size
and colour intensity.
Order of parameters: Following the six population-independent parameters κ0
t , κf
t , κx
t , κx2
t , κx,f
t
, κx2,f
t
, country-speciﬁc
parameters are given blockwise for their main eﬀects, gender interactions, linear age interactions, and quadratic age
interactions, respectively, each of which ordered by DE, ES, FR, IT, UK.
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
κ0
t
κf
t
κx
t
κx2
t
κx,f
t
κx2,f
t
κDE
t
κES
t
κFR
t
κIT
t
κUK
t
κDE,f
t
κES,f
t
κFR,f
t
κIT,f
t
κUK,f
t
κDE,x
t
κES,x
t
κFR,x
t
κIT,x
t
κUK,x
t
κDE,x2
t
κES,x2
t
κFR,x2
t
κIT,x2
t
κUK,x2
t
103

4 Case Studies in European Mortality Forecasting
Figure 4.31: Correlation matrix for κt at the year of 2100
Shown are the bivariate correlations of all marginal posterior predictive distributions for future κt with t for 2100 for the
MCMC output with N = 1,000,000, burn-in length of 750,000, and thinning factor 100. Blue and red circles denote
positive and negative correlation, respectively. The magnitude of the absolute correlation is given by both the circle size
and colour intensity.
Order of parameters: Following the six population-independent parameters κ0
t , κf
t , κx
t , κx2
t , κx,f
t
, κx2,f
t
, country-speciﬁc
parameters are given blockwise for their main eﬀects, gender interactions, linear age interactions, and quadratic age
interactions, respectively, each of which ordered by DE, ES, FR, IT, UK.
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
κ0
t
κf
t
κx
t
κx2
t
κx,f
t
κx2,f
t
κDE
t
κES
t
κFR
t
κIT
t
κUK
t
κDE,f
t
κES,f
t
κFR,f
t
κIT,f
t
κUK,f
t
κDE,x
t
κES,x
t
κFR,x
t
κIT,x
t
κUK,x
t
κDE,x2
t
κES,x2
t
κFR,x2
t
κIT,x2
t
κUK,x2
t
104

4 Case Studies in European Mortality Forecasting
Figure 4.32: External validation for ηxpgt for the ages of 60 and 80 at years 2050 and
2100
Shown are the bivariate correlations of all population-speciﬁc posterior predictive distributions for future ηxpgt with
x = 60 and x = 80 (by columns) and t for 2050 and 2100 (by rows) for the MCMC output with N = 1,000,000, burn-in
length of 750,000, and thinning factor 100. Blue circles denote positive correlation, and its magnitude is given by both
the circle size and colour intensity.
Order of parameters: Male and female populations are given in two blocks, each of which ordered by DE, ES, FR, IT,
UK.
−1 −0.8−0.6−0.4−0.2 0
0.2 0.4 0.6 0.8
1
m,DE
m,ES
m,FR
m,IT
m,UK
f,DE
f,ES
f,FR
f,IT
f,UK
(a) ηxpgt for age 60 and year 2050
−1 −0.8−0.6−0.4−0.2 0
0.2 0.4 0.6 0.8
1
m,DE
m,ES
m,FR
m,IT
m,UK
f,DE
f,ES
f,FR
f,IT
f,UK
(b) ηxpgt for age 80 and year 2050
−1 −0.8−0.6−0.4−0.2 0
0.2 0.4 0.6 0.8
1
m,DE
m,ES
m,FR
m,IT
m,UK
f,DE
f,ES
f,FR
f,IT
f,UK
(c) ηxpgt for age 60 and year 2100
−1 −0.8−0.6−0.4−0.2 0
0.2 0.4 0.6 0.8
1
m,DE
m,ES
m,FR
m,IT
m,UK
f,DE
f,ES
f,FR
f,IT
f,UK
(d) ηxpgt for age 80 and year 2100
105

4 Case Studies in European Mortality Forecasting
Figure 4.33: Diﬀerences in ηxpgt for diﬀerent populations p of males for the age of 80
Shown are fancharts of marginal posterior predictive distributions for future diﬀerences in ηxpgt with g = m and x = 80
for selected pairs of countries p (by rows) in both joint and individual BMPMP models (by columns) as time series in t
for 2010, . . . , 2100, along with crude estimates for the diﬀerences in ηxpgt for 1981, . . . , 2009 from observed data (green
lines) for the MCMC output with N = 1,000,000, burn-in length of 750,000, and thinning factor 100. 90%, 95%, 99%,
and 100% credibility intervals are given by solid, dashed, dotted, and limiting lines, respectively.
Left panel: The joint BMPMP model for all ﬁve countries DE, ES, IT, FR, UK with k = 2 and r = 5. Right panel:
Combined output from ﬁve individual BMPMP models for each country with the six main CBD parameters only and
k = 2 and r = 1, respectively. The MCMC algorithm is run with the same length, burn-in period, and thinning.
1980 2000 2020 2040 2060 2080 2100
-4
-2
0
2
4
6
8
(a) DE–ES in joint BMPMP model
1980 2000 2020 2040 2060 2080 2100
-10
0
10
20
30
(b) DE–ES in individual BMPMP models
1980 2000 2020 2040 2060 2080 2100
-2
0
2
4
(c) DE–FR in joint BMPMP model
1980 2000 2020 2040 2060 2080 2100
-5
0
5
10
(d) DE–FR in individual BMPMP models
1980 2000 2020 2040 2060 2080 2100
-4
-2
0
2
4
6
8
(e) DE–IT in joint BMPMP model
1980 2000 2020 2040 2060 2080 2100
-5
0
5
10
(f) DE–IT in individual BMPMP models
1980 2000 2020 2040 2060 2080 2100
-4
-2
0
2
4
6
(g) DE–UK in joint BMPMP model
1980 2000 2020 2040 2060 2080 2100
-4
-2
0
2
4
(h) DE–UK in individual BMPMP models
106

4 Case Studies in European Mortality Forecasting
Figure 4.32 shows visualisations of the correlation matrices for ηxpgt at all combinations
of ﬁxed ages 60 and 80 and ﬁxed years 2050 and 2100. Correlations are assessed be-
tween all ten strata composed by the ﬁve countries and both genders. Note that the
dependencies between diﬀerent age groups need not be assessed due to the design of the
BMPMP model. The plots show that the model indeed exhibits the desired property
of projecting highly positive correlations between the individual populations into the
future. As expected, the magnitude is highest for both genders within the same country.
In this case study, mortality rates further appear to have a stronger correlation between
the countries for higher ages. While any combination of populations has a minimum
correlation coeﬃcient of 0.5 for the age of 80, these dependencies may even vanish for
the age of 60; see German and Spanish females, for instance. Surprisingly, diﬀerences
between 2050 and 2100 are negligible.
Despite the discussion of the aforementioned plots, the BMPMP model’s outcome needs
to be compared to corresponding results from independent univariate projection models
in order to fully assess the distinct feature of joint mortality rate projections for an
arbitrary number of populations. If the BMPMP model is able to quantify a biologically
anticipated stability in mortality patterns, or to describe dependencies between the in-
dividual populations, then the result of the joint modelling approach should generally
diﬀer from combined results of independent marginal models. For a fair comparison, the
principal framework of the univariate models must coincide with the BMPMP model,
apart from the change in the number of populations. Consequently, each individual pop-
ulation is modelled via the CBD approach as in (4.1) without any population-speciﬁc
eﬀects, i.e. the linear predictor only consists of the intercept, the gender-related main
eﬀect, and the linear and quadratic eﬀects for age. The number of parameters decreases
to six including interaction terms. The parameters are again forecast through a VECM,
which is now far less high-dimensional than in the multi-population case. The lag order
is kept constant at k = 2, and the cointegration rank is chosen to be r = 1 for each inde-
pendent model. Apart from the latter speciﬁcation, Bayesian estimation with the same
prior assumptions and MCMC approximation of the posterior distribution is applied to
avoid any other methodological diﬀerences between the univariate and multivariate cases.
Since the individual models for all ﬁve countries are independent, replicated plots as
in Figure 4.32 (not shown) only exhibit correlation between both genders within each
107

4 Case Studies in European Mortality Forecasting
nation. However, to quantify the extent to which the joint modelling approach leads to
more biological plausibility, the predictions must be analysed for convergent or divergent
behaviour rather than simple correlation. Fancharts of posterior predictive distributions
for diﬀerences in selected linear predictors for males are plotted over the forecasting
period for both the joint and the independent modelling approaches in Figure 4.33. Al-
though credibility bands remain narrow for several decades, it is noteworthy that even for
the joint modelling approach, the stochastic model design cannot prevent a considerable
spread between linear predictors of two diﬀerent countries. Median predictions, however,
do forecast anticipated non-divergence of marginal mortality rates. A comparison of re-
sults from both models reveals that even the independent models do not seem principally
implausible, as their best estimates suggest a stable and non-divergent future, too. How-
ever, except for the diﬀerence between German and British males, credibility intervals
are usually much wider – up to a doubling in size. Thus, the joint modelling approach of
the newly introduced BMPMP model leads to substantial reduction in overly conserva-
tive and unreasonable credibility regions from combined single-population models. The
case study greatly supports the usage of the joint forecasts.
4.1.9 Comparison of Diﬀerent Model Set-ups
In this section, the BMPMP model of mortality projections for the Big Five over the
calibration period 1981–2009 is compared for diﬀerent choices in the VECM speciﬁca-
tions. The six model set-ups under consideration are comprised of all combinations of
the values k = 1, 2 and r = 0, 1, 5 for the lag and cointegration order, respectively. Each
model’s posterior distribution is approximated by the MCMC output of N = 1,000,000
iterations subject to a thinning factor of 100, and after discarding a burn-in period
of 750,000 iterations. Convergence and model diagnostics are all analogous to previous
ﬁndings. Most notably, a rough approximation can only be achieved for the hyperparam-
eters, and convergence for the CBD parameters is not satisfying. A detailed discussion
on such diagnostic measurements is omitted here for convenience. Note that a detailed
sensitivity analysis w.r.t. the choice of priors is not provided within this discussion and
left open for future work.
A comparison of all six model speciﬁcations is conducted via qualitative assessment of
diﬀerences in posterior predictive forecasts over the window 2010–2100.
Figure 4.34
108

4 Case Studies in European Mortality Forecasting
Figure 4.34: Comparison of posterior predictive ηxpgt for 60-year-old Italian males for
diﬀerent choices of cointegration and lag orders
Shown are fancharts of marginal posterior predictive distributions for future ηxpgt with x = 60, p = IT, g = m for
BMPMP models speciﬁed through diﬀerent cointegration orders r = 0, 1, 5 (by rows) and lag orders k = 1, 2 (by
columns) as time series in t for 2010, . . . , 2100, along with crude estimates for ηxpgt for 1981, . . . , 2009 from observed
data (green lines) for the respective MCMC outputs with N = 1,000,000, burn-in length of 750,000, and thinning factor
100. 90%, 95%, 99%, and 100% credibility intervals are given by solid, dashed, dotted, and limiting lines, respectively.
1980 2000 2020 2040 2060 2080 2100
-8
-7
-6
-5
-4
(a) BMPMP model with r = 0 and k = 1
1980 2000 2020 2040 2060 2080 2100
-9
-8
-7
-6
-5
-4
(b) BMPMP model with r = 0 and k = 2
1980 2000 2020 2040 2060 2080 2100
-9
-8
-7
-6
-5
-4
(c) BMPMP model with r = 1 and k = 1
1980 2000 2020 2040 2060 2080 2100
-9
-8
-7
-6
-5
-4
(d) BMPMP model with r = 1 and k = 2
1980 2000 2020 2040 2060 2080 2100
-14
-12
-10
-8
-6
-4
(e) BMPMP model with r = 5 and k = 1
1980 2000 2020 2040 2060 2080 2100
-14
-12
-10
-8
-6
-4
(f) BMPMP model with r = 5 and k = 2
109

4 Case Studies in European Mortality Forecasting
shows posterior mortality projections at the example of 60-year-old Italian males. The
cointegration order r has the signiﬁcant eﬀect of increasing both the variability and left-
skewness in the posterior predictive distributions of the long-term forecasts for the linear
predictors. Whereas best estimates given through median values are stable throughout
all set-ups, the choice of r = 0 or r = 1 yields an elliptical uncertainty pattern, known
from standard frequentist and single-population models in the literature on stochastic
mortality predictions. Credibility intervals remain narrow and symmetric over the entire
course of the prediction window. Notably, the posterior predictive distribution at the
year of 2100 is of similar nature than what is observed for the year 2050. Therefore,
increasing uncertainty about future developments in medicine, economy, and society
over such long time spans is neglected. In contrast, the plots for r = 5 reveal that the
inclusion of more cointegrating relationships in the VECM leads to increasing variability
over time, with a shift of probability mass towards a possible slowdown and, to a larger
extent, fast-pace mortality improvements. Such results not only underline the distinct
feature of a more complex and principally more realistic uncertainty structure, but also
the analyst’s ability to express prior beliefs through the choice of r. Apart from eﬀects
on the 1% tails when r = 0, the lag order k, however, appears to have no visible eﬀect
on the BMPMP model’s performance, so that the joint modelling approach without AR
features appears adequate. Summarising, the robustness for r > 0 suggests the usage of
the BMPMP model with k = 1 and, implicitly, a large reduction in computation time.
4.1.10 Comparison of Bayesian and Maximum-Likelihood
Estimation
In this case study, in which mortality rates of ﬁve diﬀerent countries stratiﬁed by two
genders are to be forecast based on a calibration window of around 30 years, the Bayesian
methodology is essential, when k = 2, to overcome the problem of over-parametrisation.
Flexibility in model speciﬁcation is therefore strongly limited. Due to the vanishing
importance of AR terms in the VECM, as seen in the previous section, this case study
only allows a comparison of Bayesian and frequentist estimation procedures with the
choice of k = 1. Note, however, that with increasing number of populations, even the
Markovian version of the BMPMP model becomes over-parametrised and frequentist
approaches cannot be established.
110

4 Case Studies in European Mortality Forecasting
Figure 4.35: Comparison of Bayesian posterior predictive and maximum-likelihood esti-
mates for ηxpgt for 60-year-old Italian males
Shown are fancharts of marginal posterior predictive distributions for future ηxpgt with x = 60, p = IT, g = m for
BMPMP models with lag order k = 1 and both cointegration ranks r = 1, 5 as time series in t for 2010, . . . , 2100, along
with ML forecasts (red lines) and crude estimates for ηxpgt for 1981, . . . , 2009 from observed data (green lines) for the
respective MCMC outputs with N = 1,000,000, burn-in length of 750,000, and thinning factor 100. 90%, 95%, 99%, and
100% credibility intervals for the Bayesian estimates are given by solid, dashed, dotted, and limiting lines, respectively.
Analogous line types are used for the 90%, 95%, and 99% conﬁdence intervals for the frequentist estimates.
1980
2000
2020
2040
2060
2080
2100
-9
-8
-7
-6
-5
-4
(a) BMPMP model with r = 1
1980
2000
2020
2040
2060
2080
2100
-14
-12
-10
-8
-6
-4
(b) BMPMP model with r = 5
111

4 Case Studies in European Mortality Forecasting
In the following, frequentist forecasts are computed via subsequent ML estimation of
the CBD model, i.e. the previously used starting values, and the VECM with Gaussian
white noise, as outlined in Appendix C.4. Least-squares estimation, which is addition-
ally described in the appendix, will not be considered here.
Figure 4.35 shows the
forecasts for the BMPMP models with k = 1 and r = 1, 5, known from Figure 4.34,
with superimposed conﬁdence intervals from ML estimation. Obviously, the frequentist
approach fails for the model with ﬁve cointegration relationships in that the time series
and, consequently, the linear predictors ηxpgt explode for all populations. A natural ex-
planation is that with 612 VECM parameters for 728 latent observations, ML estimation
– although mathematically possible – becomes highly unstable with an ill-conditioned
maximisation problem. Valid ML results for the case of r = 1 and for other case studies
(not shown) support this theory. As also discovered for other examples, the ﬁrst plot
shows that when frequentist estimation is doable and well-conditioned, best estimates
are close to the median values of the posterior predictive distributions from Bayesian
estimation. Conﬁdence intervals are narrower than their credibility counterparts and
closest for the choice of r = 0. In general, they are completely contained in the cor-
responding credibility bands and less sophisticating than the Bayesian outcome w.r.t.
uncertainty patterns. In conclusion, ML estimation is not available for the BMPMP
model in most but the smallest applications, and, if it is, problems with its robustness
and plausibility still speak for the Bayesian approach.
4.2 Case Study 2: Central European Countries
This case study applies the gender-speciﬁc model in (4.1) for the age interval [40,100]
and calibration window of 1981–2009 to the ﬁve Central European countries of Austria
(AT), the Czech Republic (CZ), Germany2 (DE), Hungary (HU), and Poland (PL), as
shown in Figure 4.36. These countries are selected to combine populations which in
the augmented common factor model by Li and Lee (2005) could either be modelled –
both as members of the so-called low-mortality group (i.e. Austria and Germany) or as
members of the remaining out-of-group sample (i.e. the Czech Republic) – or had to
be abandoned due to an explosive behaviour in the marginal ﬁrst-order AR time series
model (i.e. Hungary). The remaining country Poland was not analysed in this study.
2As before, German data are restricted to the territory of former West Germany for consistency
purposes.
112

4 Case Studies in European Mortality Forecasting
Figure 4.36: Map of the ﬁve Central European countries in case study 2
Shown in green are the ﬁve Central European countries of the second case study: Austria (AT), the Czech Republic
(CZ), Germany (DE, data only for West Germany in this case study), Hungary (HU), and Poland (PL), within Europe.
For details on territorial coverage for these ﬁve countries, see the list of countries in the preface.
AT
CZ
DE
HU
PL
113

4 Case Studies in European Mortality Forecasting
Figure 4.37: Starting values for K
Shown are the ML estimates κ(0)
t
of the CBD parameters as time series in t for 1981, . . . , 2009.
1980
1985
1990
1995
2000
2005
2010
-5.90
-5.85
-5.80
-5.75
-5.70
-5.65
-5.60
(a) Intercept κ0(0)
t
1980
1985
1990
1995
2000
2005
2010
-0.96
-0.94
-0.92
-0.90
-0.88
-0.86
-0.84
(b) Gender eﬀect for females κf(0)
t
1980
1985
1990
1995
2000
2005
2010
0.070
0.075
0.080
0.085
0.090
(c) Linear age eﬀect κx(0)
t
1980
1985
1990
1995
2000
2005
2010
0.00000
0.00005
0.00010
0.00015
0.00020
0.00025
0.00030
0.00035
(d) Quadratic age eﬀect κx2(0)
t
1980
1985
1990
1995
2000
2005
2010
-0.003
-0.002
-0.001
0.000
0.001
0.002
0.003
(e) Gender and linear age interactions κxf(0)
t
1980
1985
1990
1995
2000
2005
2010
0.00022
0.00024
0.00026
0.00028
0.00030
0.00032
(f) Gender and quadratic age interactions κx2f(0)
t
1980
1985
1990
1995
2000
2005
2010
-0.4
-0.2
0.0
0.2
0.4
0.6
0.8
AT
AT
AT
ATCZ
CZ
CZ
CZ
DE
DE
DE
DE
HU
HU
HU
HU
PL
PL
PL
PL
EU
EU
EU
EU
(g) Main country eﬀects κp(0)
t
1980
1985
1990
1995
2000
2005
2010
-0.05
0.00
0.05
AT
AT
AT
ATCZ
CZ
CZ
CZ
DE
DE
DE
DE
HU
HU
HU
HU
PL
PL
PL
PL
EU
EU
EU
EU
(h) Gender and country interactions κpf(0)
t
1980
1985
1990
1995
2000
2005
2010
-0.02
-0.01
0.00
0.01
AT
AT
AT
AT
CZ
CZ
CZ
CZ
DE
DE
DE
DE
HU
HU
HU
HU
PL
PL
PL
PL
EU
EU
EU
EU
(i) Linear age and country interactions κpx(0)
t
1980
1985
1990
1995
2000
2005
2010
-2e-04
-1e-04
0e+00
1e-04
2e-04
AT
AT
AT
AT
CZ
CZ
CZ
CZ
DE
DE
DE
DE
HU
HU
HU
HU
PL
PL
PL
PL
EU
EU
EU
EU
(j) Quadratic age and country interactions κpx2(0)
t
114

4 Case Studies in European Mortality Forecasting
Figure 4.38: Posterior predictive checking for K
Shown are fancharts of selected marginal posterior predictive distributions for κt as time series in t for 1981, . . . , 2009
based on the MCMC output with N = 1,000,000, burn-in length of 750,000, and thinning factor 100. The
country-speciﬁc parameters are illustrated for the example of Hungary. 90%, 95%, 99%, and 100% credibility intervals
are given by solid, dashed, dotted, and limiting lines, respectively. Red lines denote ML estimates (starting values).
1980
1985
1990
1995
2000
2005
2010
-6.5
-6.0
-5.5
-5.0
(a) Intercept κ0
t
1980
1985
1990
1995
2000
2005
2010
-1.6
-1.4
-1.2
-1.0
-0.8
-0.6
-0.4
-0.2
(b) Gender eﬀect for females κf
t
1980
1985
1990
1995
2000
2005
2010
0.02
0.04
0.06
0.08
0.10
(c) Linear age eﬀect κx
t
1980
1985
1990
1995
2000
2005
2010
-4e-04
-2e-04
0e+00
2e-04
4e-04
6e-04
8e-04
1e-03
(d) Quadratic age eﬀect κx2
t
1980
1985
1990
1995
2000
2005
2010
-0.04
-0.02
0.00
0.02
(e) Gender and linear age interactions κxf
t
1980
1985
1990
1995
2000
2005
2010
-2e-04
0e+00
2e-04
4e-04
6e-04
8e-04
1e-03
(f) Gender and quadratic age interactions κx2f
t
1980
1985
1990
1995
2000
2005
2010
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
(g) Main country eﬀects κHU
t
1980
1985
1990
1995
2000
2005
2010
-0.2
-0.1
0.0
0.1
0.2
0.3
(h) Gender and country interactions κHU,f
t
1980
1985
1990
1995
2000
2005
2010
-0.05
0.00
0.05
0.10
(i) Linear age and country interactions κHU,x
t
1980
1985
1990
1995
2000
2005
2010
-0.0020
-0.0015
-0.0010
-0.0005
0.0000
0.0005
(j) Quadratic age and country interactions κHU,x2
t
115

4 Case Studies in European Mortality Forecasting
Figure 4.39: Posterior predictive checking for ηxpgt for the age of 60
Shown are fancharts of marginal posterior predictive distributions for ηxpgt with x = 60 for all countries p (by rows) and
both genders g (by columns) as time series in t for 1981, . . . , 2009 based on the MCMC output with N = 1,000,000,
burn-in length of 750,000, and thinning factor 100. 90%, 95%, 99%, and 100% credibility intervals are given by solid,
dashed, dotted, and limiting lines, respectively. Green lines denote crude estimates from observed data.
1980
1985
1990
1995
2000
2005
2010
-5.2
-5.0
-4.8
-4.6
-4.4
-4.2
-4.0
(a) Austrian males
1980
1985
1990
1995
2000
2005
2010
-6.0
-5.8
-5.6
-5.4
-5.2
-5.0
-4.8
(b) Austrian females
1980
1985
1990
1995
2000
2005
2010
-4.5
-4.0
-3.5
(c) Czech males
1980
1985
1990
1995
2000
2005
2010
-5.4
-5.2
-5.0
-4.8
-4.6
-4.4
(d) Czech females
1980
1985
1990
1995
2000
2005
2010
-5.0
-4.8
-4.6
-4.4
-4.2
-4.0
(e) German males
1980
1985
1990
1995
2000
2005
2010
-5.8
-5.6
-5.4
-5.2
-5.0
-4.8
(f) German females
1980
1985
1990
1995
2000
2005
2010
-4.5
-4.0
-3.5
(g) Hungarian males
1980
1985
1990
1995
2000
2005
2010
-5.2
-5.0
-4.8
-4.6
-4.4
-4.2
(h) Hungarian females
1980
1985
1990
1995
2000
2005
2010
-4.5
-4.0
-3.5
(i) Polish males
1980
1985
1990
1995
2000
2005
2010
-5.4
-5.2
-5.0
-4.8
-4.6
-4.4
-4.2
(j) Polish females
116

4 Case Studies in European Mortality Forecasting
Figure 4.40: Posterior predictive checking for ηxpgt for the age of 80
Shown are fancharts of marginal posterior predictive distributions for ηxpgt with x = 80 for all countries p (by rows) and
both genders g (by columns) as time series in t for 1981, . . . , 2009 based on the MCMC output with N = 1,000,000,
burn-in length of 750,000, and thinning factor 100. 90%, 95%, 99%, and 100% credibility intervals are given by solid,
dashed, dotted, and limiting lines, respectively. Green lines denote crude estimates from observed data.
1980
1985
1990
1995
2000
2005
2010
-3.4
-3.2
-3.0
-2.8
-2.6
-2.4
-2.2
-2.0
(a) Austrian males
1980
1985
1990
1995
2000
2005
2010
-3.8
-3.6
-3.4
-3.2
-3.0
-2.8
-2.6
-2.4
(b) Austrian females
1980
1985
1990
1995
2000
2005
2010
-3.0
-2.5
-2.0
-1.5
(c) Czech males
1980
1985
1990
1995
2000
2005
2010
-3.4
-3.2
-3.0
-2.8
-2.6
-2.4
-2.2
-2.0
(d) Czech females
1980
1985
1990
1995
2000
2005
2010
-3.0
-2.5
-2.0
(e) German males
1980
1985
1990
1995
2000
2005
2010
-3.5
-3.0
-2.5
(f) German females
1980
1985
1990
1995
2000
2005
2010
-3.0
-2.5
-2.0
-1.5
(g) Hungarian males
1980
1985
1990
1995
2000
2005
2010
-3.4
-3.2
-3.0
-2.8
-2.6
-2.4
-2.2
-2.0
(h) Hungarian females
1980
1985
1990
1995
2000
2005
2010
-3.0
-2.5
-2.0
(i) Polish males
1980
1985
1990
1995
2000
2005
2010
-3.5
-3.0
-2.5
(j) Polish females
117

4 Case Studies in European Mortality Forecasting
Figure 4.41: External validation for K
Shown are fancharts of selected marginal posterior predictive distributions for future κt as time series in t for
2010, . . . , 2100, along with ML estimates for κt for 1981, . . . , 2009 for the same MCMC output as in Figure 4.38. The
country-speciﬁc parameters are illustrated for the example of Hungary. 90%, 95%, 99%, and 100% credibility intervals
are given by solid, dashed, dotted, and limiting lines, respectively.
1980 2000 2020 2040 2060 2080 2100
-12
-10
-8
-6
-4
(a) Intercept κ0
t
1980 2000 2020 2040 2060 2080 2100
-3
-2
-1
0
1
2
(b) Gender eﬀect for females κf
t
1980 2000 2020 2040 2060 2080 2100
-0.2
-0.1
0.0
0.1
0.2
(c) Linear age eﬀect κx
t
1980 2000 2020 2040 2060 2080 2100
-0.002
0.000
0.002
0.004
(d) Quadratic age eﬀect κx2
t
1980 2000 2020 2040 2060 2080 2100
-0.20
-0.15
-0.10
-0.05
0.00
0.05
0.10
(e) Gender and linear age interactions κxf
t
1980 2000 2020 2040 2060 2080 2100
-0.001
0.000
0.001
0.002
0.003
(f) Gender and quadratic age interactions κx2f
t
1980 2000 2020 2040 2060 2080 2100
-10
-5
0
5
(g) Main country eﬀects κHU
t
1980 2000 2020 2040 2060 2080 2100
-1.0
-0.5
0.0
0.5
1.0
(h) Gender and country interactions κHU,f
t
1980 2000 2020 2040 2060 2080 2100
-0.2
0.0
0.2
0.4
0.6
(i) Linear age and country interactions κHU,x
t
1980 2000 2020 2040 2060 2080 2100
-0.010
-0.008
-0.006
-0.004
-0.002
0.000
0.002
(j) Quadratic age and country interactions κHU,x2
t
118

4 Case Studies in European Mortality Forecasting
Figure 4.42: External validation for ηxpgt for the age of 60
Shown are fancharts of marginal posterior predictive distributions for future ηxpgt with x = 60 for all countries p (by
rows) and both genders g (by columns) as time series in t for 2010, . . . , 2100, along with ML forecasts (red lines) and
crude estimates from observed data (green lines) for the same MCMC output as in Figure 4.39. 90%, 95%, 99%, and
100% credibility and conﬁdence intervals are given by solid, dashed, dotted, and limiting lines, respectively.
1980 2000 2020 2040 2060 2080 2100
-10
-9
-8
-7
-6
-5
-4
(a) Austrian males
1980 2000 2020 2040 2060 2080 2100
-11
-10
-9
-8
-7
-6
-5
(b) Austrian females
1980 2000 2020 2040 2060 2080 2100
-12
-10
-8
-6
-4
(c) Czech males
1980 2000 2020 2040 2060 2080 2100
-12
-10
-8
-6
(d) Czech females
1980 2000 2020 2040 2060 2080 2100
-10
-9
-8
-7
-6
-5
-4
(e) German males
1980 2000 2020 2040 2060 2080 2100
-10
-9
-8
-7
-6
-5
(f) German females
1980 2000 2020 2040 2060 2080 2100
-10
-8
-6
-4
-2
(g) Hungarian males
1980 2000 2020 2040 2060 2080 2100
-9
-8
-7
-6
-5
-4
-3
(h) Hungarian females
1980 2000 2020 2040 2060 2080 2100
-8
-6
-4
-2
(i) Polish males
1980 2000 2020 2040 2060 2080 2100
-10
-8
-6
-4
(j) Polish females
119

4 Case Studies in European Mortality Forecasting
Figure 4.43: External validation for ηxpgt for the age of 80
Shown are fancharts of marginal posterior predictive distributions for future ηxpgt with x = 80 for all countries p (by
rows) and both genders g (by columns) as time series in t for 2010, . . . , 2100, along with ML forecasts (red lines) and
crude estimates from observed data (green lines) for the same MCMC output as in Figure 4.40. 90%, 95%, 99%, and
100% credibility and conﬁdence intervals are given by solid, dashed, dotted, and limiting lines, respectively.
1980 2000 2020 2040 2060 2080 2100
-9
-8
-7
-6
-5
-4
-3
-2
(a) Austrian males
1980 2000 2020 2040 2060 2080 2100
-9
-8
-7
-6
-5
-4
-3
(b) Austrian females
1980 2000 2020 2040 2060 2080 2100
-10
-8
-6
-4
-2
(c) Czech males
1980 2000 2020 2040 2060 2080 2100
-10
-8
-6
-4
-2
(d) Czech females
1980 2000 2020 2040 2060 2080 2100
-8
-6
-4
-2
(e) German males
1980 2000 2020 2040 2060 2080 2100
-8
-7
-6
-5
-4
-3
(f) German females
1980 2000 2020 2040 2060 2080 2100
-8
-6
-4
-2
(g) Hungarian males
1980 2000 2020 2040 2060 2080 2100
-8
-6
-4
-2
(h) Hungarian females
1980 2000 2020 2040 2060 2080 2100
-8
-6
-4
-2
(i) Polish males
1980 2000 2020 2040 2060 2080 2100
-12
-10
-8
-6
-4
-2
(j) Polish females
120

4 Case Studies in European Mortality Forecasting
With all priors chosen as in Section 4.1.2 and the algorithm run as outlined in Sec-
tion 4.1.3, diﬀerent speciﬁcations for k and r are compared, and the choice of one for
both the lag and cointegration orders is concluded to yield a parsimonious and well-
ﬁtting model. Figures 4.37 to 4.43 show the starting values and posterior predictive
distribution plots for both internal and external validation, including comparison with
ML estimation. The outcomes will be assessed in the remainder of this section. Con-
vergence plots depict a very similar behaviour as those investigated in the previous case
study, and are therefore omitted here for convenience.
The starting values in Figure 4.37 somewhat diﬀer from the last case study, particularly
for the intercept and main gender eﬀect. When interpreting the combined evolution,
the shift from ﬁve Western to ﬁve Central European countries leads to a negative shock
in mortality improvement for men around the year of 1990. This bump, i.e. a sudden
increase in logits of mortality rates around 1990 before turning to a fast-paced negative
trend, is observed for most Central and Eastern European countries, and is often argued
to be an eﬀect of the fall of the Iron Curtain. While population-speciﬁc parameters
for Austria, the Czech Republic, and Germany remain merely stable, the time series for
Hungary and Poland indicate some regime changes and should hence be treated carefully.
Internal validation in Figures 4.38 to 4.40 is as satisfying as before and does not indicate
additional problems with mixing low- and high-mortality countries. ML estimates and
crude mortality rates are generally included in the plotted credibility intervals. Strong
deviations from the posterior predictive distribution for 60-year-old males of the Eastern
European countries in the ﬁrst half of the calibration window were visible and discussed
in the previous case study and no unique feature in this application. Moreover, compar-
ison of forecasts for German data, which are particularly modelled in both case studies,
reveals no substantial diﬀerences in their quality and, if any, then a slight improvement.
Hence the model appears robust w.r.t. the homogeneity in underlying data.
Rather surprisingly, external validation in Figures 4.41 to 4.43 lead to narrower credibil-
ity intervals for German mortality predictions than what was previously observed. An
explanation might be that, in the ﬁrst case study, German data were implicitly trained
on more similar countries and that their characteristics, e.g. in variability, were correctly
incorporated into German forecasts. The current case study combines rather diﬀerent
mortality patterns and eﬀectively leads to a minor extent of information loss. This ex-
121

4 Case Studies in European Mortality Forecasting
planation would motivate the increase in the number of population in joint forecasts
using the BMPMP model.
Apart from the comparison of German data, the external validation plots clearly show
reasonable fancharts for the country-speciﬁc forecasts. A qualitative diﬀerence exists
between Austrian, Czech, and German data on the one hand, and Hungarian and Polish
data on the other. The ﬁrst-mentioned countries depict a strong negative trend, whereas
the remaining countries devote more probability mass to a slower pace or even deterio-
rating outcomes. A comparison to individual models is not conducted for this case study,
but it can be gathered from the analysis in Section 4.1 that the joint model approach is
naturally superior to isolated forecasts. What is still done, however, is the comparison
of the Bayesian forecasts with their ML counterparts, given by the superimposed red
lines in the last to ﬁgures. Frequentist conﬁdence intervals can either be much narrower
than Bayesian credibility intervals or, what is observed in most instances, depict best
estimates that substantially diﬀer from the posterior predictive median values by gener-
ally being too conservative, which seems far less plausible.
To summarise, the BMPMP model yields a ﬂexible and robust approach to model even
unconventional combinations of populations in an easily interpretable way.
122

5 Conclusion
In light of modern challenges in stochastic mortality forecasting, the BMPMP model, a
Bayesian approach in the multi-population framework, was derived, deﬁned, and applied
in this work. This concluding chapter summarises the model’s characteristics, advan-
tages, and limitations based on theoretical and empirical ﬁndings in Chapters 3 and 4
and addresses potential or even necessary future work.
5.1 Summary and Outcome
In this thesis, the BMPMP model was established to allow for mortality projections
of high ages in a globalised world with particular focus on modelling inter-population
dependencies and associated uncertainties. The detailed literature review in Chapter 2
revealed that the interest in such approaches has already led to a variety of attempts.
However, due to the complexity in high-dimensional forecasting models, an ultimate
state-of-the-art technique does not seem to have evolved yet. In fact, the literature re-
view could indeed be used to postulate an extensive list of limitations in existing models.
The BMPMP model was designed to address such problems to provide a concrete tool
for improved joint mortality forecasts and a substantial contribution to other future
work. It has a two-level hierarchical structure, which is known from most other models
and has been successfully established in modern stochastic mortality forecasting. Here,
the CBD model is used as framework for observed mortality rates and the VECM is
the data-driven technique to project today’s patterns into the future. Most notably,
the approach diﬀers from existing model by combining such a ﬂexible, easily applicable,
and interpretable multi-population model with the non-frequentist paradigm of Bayesian
statistics to assure a well-conditioned estimation procedure, biological plausibility, and
quantiﬁcation of uncertainty – as speciﬁcally expressed via the model’s name. The key
outcomes of the BMPMP model are:
123

5 Conclusion
• The BMPMP model is a ﬂexible multi-population mortality projection model,
which is not generally restricted to a certain number or type of populations.
• Its hierarchical structure with forecasts of CBD parameters and corresponding lin-
ear predictors as immediate output lead to an easy, but also detailed, interpretation
and analysis. It can be further extended or adjusted for speciﬁc needs.
• The Bayesian approach has two important consequences. On the one hand, in con-
trast to frequentist estimation, it guarantees well-conditioned long-term mortality
projections based on comparably short calibration periods. On the other hand, it
results in posterior distributions of future model parameters and mortality rates,
which are fruitful for coherent quantiﬁcation of risks and dependencies.
• The empirical analyses of the BMPMP model point towards success in biologically
plausible quantiﬁcation of the interaction between diﬀerent populations through
completely data-driven techniques rather than postulated convergence assump-
tions. As a consequence, unforeseen possibilities of acceleration or deceleration in
mortality improvements are intentionally included.
• Comparison of diﬀerent model speciﬁcations indicated robustness of the model
w.r.t. the lag order in the VECM and the possibility of adjusting the uncertainty
in mortality predictions via the cointegration rank.
• The empirical case studies for the BMPMP model ﬁnally stressed the growing
importance of quadratic age eﬀects and diminishing country-speciﬁc diﬀerences
between both genders in general mortality forecasting.
It can therefore be claimed that the BMPMP model generally fulﬁls the desired out-
comes, which initially motivated its derivation.
However, the empirical case studies
could only give limited insight into the model’s characteristics. In particular, analyses of
biological plausibility and dependencies were restricted to assessment of a few graphical
outputs and cannot draw a conclusive picture. Moreover, despite the apparently valid
forecasts in both case studies, the MCMC algorithm for the Bayesian estimation of the
model parameters did not fully converge. Although approximations of the posteriors for
the hyperparameters by the marginal output yielded satisfying results in this work, they
should not be considered to be ultimately suﬃcient. As a drawback, full convergence
124

5 Conclusion
is numerically expensive and requires unwanted computation time, but the model’s ro-
bustness w.r.t. the lag order indicates that calibration for the cost-eﬃcient case of k = 1
suﬃces. It must further be kept in mind that the CBD model approach does not give the
option to model mortality rates for ages below 40. As common in stochastic mortality
forecasting, the BMPMP model was also detected to be sensitive towards the calibration
window.
However, considering all of the challenges that the model addresses, it still appears to be
a strong tool for future applications with high ages, whose ﬂexibility possibly outperforms
many of the cited alternatives. Its universal set-up further yields a promising framework
for future extensions. The beneﬁts through joint forecasts and the Bayesian paradigm
can be expected to be applied with other approaches to provide reasonable mortality
forecasts. Most importantly, due to the implementation in the statistical software R and
its inherent ﬂexibility, the BMPMP model is immediately available to the interested
reader and ready for own applications.
5.2 Future Work
This work deﬁned a completely new model and thoroughly discussed its application in
two diﬀerent case studies. Although much insight could be provided, this work is limited
in what had to be analysed for a full assessment of the BMPMP model. For an improved
understanding of the model, empirical outcomes need to be studied for a larger variety
of applications and longer-lasting MCMC algorithms that have indeed fully converged.
Here, based on ﬁndings in Chapter 4, focus can be laid on model speciﬁcations with lag
order k = 1, because the model appears to be robust against the lack of AR compo-
nents while reducing its dimensionality signiﬁcantly through omission of m-dimensional
parameter square matrices. Computation time decreases quadratically and might guar-
antee this framework to become more convenient.
Furthermore, no sensitivity analysis of the prior choices for the constants introduced in
Section 3.3.2 has so far been conducted. It is necessary to infer the eﬀects of changes in
such values to further assess the model’s robustness and to get a clearer picture of how
the analyst can set-up the model a priori based on their needs. Similarly, a discussion of
125

5 Conclusion
the performance with given deterministic scenarios as outlined in Section 3.4 would give
deeper insight into the model’s advantages. The qualitative assessment of the model’s
ability to project plausible results in a globalised world needs to be extended to a more
quantitative and general analysis. The sensitivity towards the calibration period can
be addressed speciﬁcally and used for future development of this approach. Based on
the ﬁndings in the empirical case studies, future work can further be undertaken to
widen the model’s short-term credibility bands and to reduce its high-dimensionality by
thinning out unnecessary parameters in the parameter matrices. Of course, to bend the
bow to the very introduction to this work, an application of the mortality outcomes in
an actuarial context, as common in the cited literature, needs to be done for assessment
of the model’s applicability to quantify beneﬁts of the improved knowledge of risks and
dependencies when pricing of life insurances and pension funds. Summarising, with the
positive results in this work, the analysis of the BMPMP model has just begun.
126

APPENDICES
127

A Bayesian Statistics
Through substantial growth in computer eﬃciency during the last decades, computer-
intensive numerical techniques have become more and more popular. Bayesian statistics,
named after Thomas Bayes (1702–1761), is a prominent example among these methods
and provides a notable alternative to standard methodologies in statistical data analy-
sis. In the presence of Bayesian statistics, the well-established approaches for drawing
conclusions about unknown quantities from numerical data, which build upon hypoth-
esis testing and conﬁdence intervals, are commonly referred to as frequentist inference.
It emphasises the interpretation of results as probabilistic statements about inﬁnite se-
quences of the experiment under consideration. Since Bayesian and frequentist inferences
diﬀer in their basic philosophies, the core features of both paradigms are reviewed in
Section A.1. Details on the actual inference conducted in a Bayesian framework are
presented in Section A.2. Sections A.3 and A.4 are particularly devoted to hierarchical
approaches and model diagnostics in the Bayesian context, respectively. The discussion
in the entire section is mainly based on the excellent standard textbook on Bayesian
statistics by Gelman et al. (2013), which is recommended for a thorough review on this
topic.
A.1 Pragmatic Comparison of Frequentist and Bayesian
Statistics
Given a probabilistic model for all observed quantities in an underlying scientiﬁc prob-
lem, in frequentist estimation any unknown model parameter θ is generally assumed
constant. The rationale is that even if a parameter cannot be observed, there exists one
true value and randomness stems from natural deviations of anything unknown when
experiments are repeated. The fundamental measure of such uncertainty is captured
by probability, which in frequentist’s terms is thought of as the relative frequency of an
128

A Bayesian Statistics
event in a very long, theoretically inﬁnite, sequence of the same experiment, conducted
independently of each other. Probabilistic statements in this classical framework have
to be interpreted in terms of future experiments and not, as usually but falsely done,
in terms of the currently observed data. For example, a 100p% conﬁdence interval in-
cludes the true but unknown value θ with conﬁdence p ∈(0, 1), as it is a realisation
of a random interval containing the true value with probability p in the limit of re-
peated experiments. However, the realised interval cannot be stated as a ﬁxed range
in which the unknown parameter lies with probability p, although it generally serves as
good approximation and is hence interpreted as such for convenience. Similarly, given
a statistic to test a null hypothesis H0 related to the problem, the corresponding fre-
quentist p-value is not the probability that H0 is true, as it is commonly said to be,
but the probability of observing a result at least as extreme for the outcome under the
null distribution in a sequence of similar inferences. It is natural to use the p-value as
a measure of inconsistency between the data and the hypothesis, but it does not tell
anything about the likelihood of H0 being true. A more detailed review on frequentist
interpretations in light of Bayesian statistics can be found in Dobson and Barnett (2008).
Conversely, the Bayesian approach makes use of an alternative paradigm, in which prob-
ability statements are applied with both observed and unobserved quantities, i.e. the
sampled data and the parameters of interest. A consequence is that uncertainty is quan-
tiﬁed explicitly through probability, which is the key philosophy in Bayesian statistics.
Gelman et al. (2013) describe this methodology in three steps. First, a joint probabil-
ity model for the data y and parameters θ is postulated based on scientiﬁc knowledge
of the underlying problem, eventually including dependence on additional explanatory
variables. After collecting sample data, the conditional probability distribution of the
parameters of interest given the observed data is derived. Inference is based on this
posterior distribution as it combines the general probabilistic assumption on θ, referred
to as the prior distribution, and what is learned from the data under the full model.
The third step comprises tools for analysing the model ﬁt and sensitivity towards model
assumptions. Since the model is set up via a full probability approach, any probabilistic
statements can be immediately interpreted as such in a common sense without relating it
to a sequence of independent repetitions. A 100p% probability interval then expresses a
range for the quantity of interest with coverage probability p and a p-value is interpreted
as the probability of replicated data being more extreme than observed data evaluated
129

A Bayesian Statistics
under a speciﬁed test statistic. Besides the advantages of common-sense interpretation,
Bayesian statistics is said to be appealing due to a reduced impact of overparametrisa-
tion, in particular when using hierarchical models, in which the number of parameters
may even exceed the number of data points. Generally, the freedom of a full probability
model for all quantities enables the analyst to model complex problems by models which
are not restricted to be too simplistic. More details on hierarchical models are given
in Section A.3, whereas for a general overview on the usage of Bayesian inference the
reader is referred to Gelman et al. (2013).
A.2 Bayesian Inference
Given the probability distribution for the parameters of interest and one set of realised
data, the consequence of Bayesian statistics is that the posterior distribution for θ,
on which all inference is based on, depends on the observed values, which reverses the
conditioning of probabilistic statements known from frequentist approaches. Conditional
on the given data, the posterior is given by p(θ | y) = p(θ, y)/p(y), which depends on θ
only through the postulated full probability model p(θ, y). For the sake of simpliﬁcation
in notation, any dependence on covariates is dropped in this chapter.
Noting that
p(θ, y) = p(y | θ)p(θ) is the product of the sampling distribution p(y | θ) and the prior
distribution p(θ), the posterior distribution is ultimately obtained via the well-known
Bayes’ rule, i.e.
p(θ | y) = p(y | θ)p(θ)
p(y)
.
The normalising constant p(y) =
R
p(y | θ)p(θ)dθ, which is evaluated as a sum in case
of discrete θ, is considered constant for the given realisation of the data and Bayesians
usually limit their attention to the non-normalised posterior
p(θ | y) ∝p(y | θ)p(θ),
which summarises the key tasks in Bayesian inference: formulating an appropriate prob-
ability model, usually done by breaking down the problem into ﬁnding suitable sampling
and prior distributions, and computation of the posterior distribution. Since the data
are considered the ﬁxed outcome of one experiment, p(y | θ) is read as a function in θ for
130

A Bayesian Statistics
ﬁxed y and called the likelihood. Bayesian inference hence follows the so-called likelihood
principle such that identical inference is obtained for θ if the underlying probability
models share the same likelihood functions for given y.
If statistical conclusions about the unobservable parameters are the aim of Bayesian
data analysis, posterior distributions are the main tools to use. Of course, Bayesian
methodology is also useful for predictive inference, i.e. probabilistic statements about
observable quantities, for which the sampled data y constitute one realisation. Before
this sample is collected, the probability distribution for the unknown data is given by the
normalising constant p(y), which can be computed by integrating over both the likelihood
and the prior, as stated above. Gelman et al. (2013) call this marginal distribution the
prior predictive distribution to emphasise the independence of previous observations and
the fact that y is observable. After data y have been collected, the additional information
leads to the posterior predictive distribution for the random quantity ˜y, which stands for
further observable but yet unknown outcomes of the same quantity that generated y. It
is computed as
p(˜y | y) =
Z
p(˜y, θ | y)dθ
=
Z
p(˜y | θ, y)p(θ | y)dθ
=
Z
p(˜y | θ)p(θ | y)dθ,
i.e. the average of the likelihood weighted by the posterior distribution for θ. The last
equality follows from the conditional independence of ˜y and y given θ. Apart from the
purpose of predictive inference, the posterior predictive distribution is a fundamental
tool in model diagnostics, as further discussed in Section A.4.
Critics in favour of frequentist statistics often state the dependence on the rather sub-
jective choice of a prior distribution and the comparably diﬃcult derivation of the pos-
terior distribution.
Whereas the latter problem has signiﬁcantly decreased over the
last decades with availability of computer-intensive numerical methods, mainly MCMC
procedures which are presented in Appendix B, Gelman et al. (2013) point out that
scientiﬁc reasoning must be applied even for speciﬁcation of the likelihood, i.e. also in
131

A Bayesian Statistics
frequentist methodology. In particular, assumptions such as a speciﬁc error distribution
in a regression model can be similarly subjective as the choice of the prior for underlying
unknown quantities. Statistical inference relies to large extent on the chosen model, and
the speciﬁcation of a prior distribution can be seen as part of the process of scientiﬁc
judgement on which model to choose. Moreover, accuracy of prior assumptions and the
corresponding sensitivity of posterior results can be similarly examined as it has to be
done in frequentist models. In practice, prior distributions are speciﬁed using informa-
tion which is already at hand, e.g. opinions from experts or results from previous studies.
In this case, the prior distribution is called informative and, analogously, the prior is
called non-informative if it does not contain any information based on prior beliefs.
Prior distributions are referred to as conjugate, if the posterior distribution remains in
the same family, i.e. the observed data only update the underlying parameters of the
distribution. Conjugate priors are convenient in that they oﬀer analytic solutions for
the posterior distributions and are often chosen for convenience, but their necessity has
decreased through improvements in the numerical computation of posteriors. It is worth
mentioning that prior distributions need not be proper per se, i.e. they may not integrate
to one. Such diﬀuse priors, e.g. an unbounded uniform prior, which are useful options
for non-informative priors, can still lead to proper posteriors and Bayesian inference is
hence possible.
A.3 Hierarchical Models
Due to inclusion of a full probability model for both data and parameters in the Bayesian
framework, this methodology makes it particularly easy to use models whose parameters
reﬂect a high level of dependence on each other. With decompositions of joint distri-
butions by p(θ1, θ2) = p(θ1 | θ2)p(θ2), it is natural to express such complex models in
a hierarchical fashion. Depending on the scientiﬁc context, the parameters θ may be
modelled to follow a distribution with another set of unobservable parameters φ, the
so-called hyperparameters, which are of own interest to the modeller. The data y are
considered independent of φ given the parameters θ. The joint probability distribution
can then be simply written as
p(y, θ, φ) = p(y | θ, φ)p(θ, φ) = p(y | θ)p(θ | φ)p(φ).
132

A Bayesian Statistics
One sees that the joint prior distribution for θ and φ is now given by p(θ, φ) = p(θ | φ)p(φ)
and the according non-normalised posterior is
p(θ, φ | y) ∝p(θ, φ)p(y | φ, θ) = p(θ, φ)p(y | θ).
The formulation of the more complex model results in speciﬁcation of a prior for φ
rather than θ. With an increasing number of levels in the model, prior information
on the hyperparameters becomes less available, and non-informative prior distributions
must be employed. Common choices are diﬀuse priors, which allow for maximum ﬂexi-
bility, but the posterior distribution must be carefully analysed, either analytically or by
inspection of the resulting variation, in order to verify that it is a proper distribution.
Predictive inference and model diagnostics can now be based on diﬀerent versions of
the posterior predictive distribution. Assume that θ = (θ1, . . . , θJ)′ comprises several
parameters for mutually exclusive blocks of data, and the individual θj’s are realisations
from a superpopulation whose distribution is governed by φ. The posterior predictive
distribution should be computed solely based on the inference made for a single θj, if
further outcomes ˜y are to be predicted for the j-th block. Predictions of future values
˜y for an entirely diﬀerent block refer to a posterior predictive distribution depending on
future values θj, which are themselves ﬁrst drawn from the superpopulation based on
the posterior for φ.
Hierarchical models are useful when latent values in θ should be analysed in more de-
tail or when the nature of the scientiﬁc problem calls for such complex dependencies.
For example, count data are often modelled using the Poisson distribution for ease in
calculation and interpretation. However, data may exhibit overdispersion, i.e. the ob-
served variance exceeds the theoretical variance of the model, which in this case would
coincide with the mean. Modelling the Poisson parameter via, say, the two-parametric
Gamma distribution allows mean and variance to disagree. In particular, Gelman et al.
(2013) describe how hierarchical models with more parameters than actual data points
can be used for valid inference in Bayesian statistics. They also stress that ignorance
of hierarchical structure that is seen in the data, generally leads to failure in ﬁtting
large datasets, when there are only few parameters in the non-hierarchical model, or to
overﬁtting, if the number of parameters is too large.
133

A Bayesian Statistics
A.4 Model Diagnostics
As mentioned earlier, Gelman et al. (2013) characterise Bayesian data analysis in three
steps. The ﬁrst two steps, choice of a suitable probability model for all quantities and
computation of the posterior, were outlined in Section A.2. The third step encompasses
assessment of model ﬁt, which will be discussed in what follows.
Determination of
the underlying likelihood and prior distribution is based on scientiﬁc knowledge, which
may be limited so that assumptions are not accurate and the resulting poor model will
yield biased inference. Therefore, it is crucial for any statistical analysis to check the
outcome of a model for adequacy in ﬁt and plausibility w.r.t. the purpose of the analysis.
Conceptually, model diagnostics in Bayesian statistics are very similar to standard meth-
ods in the frequentist framework. The main approach is to compare theoretical values
under the resulting model with observed data. External validation is one of the most use-
ful tools, especially for the purpose of prediction: fresh data on y are collected through
further sampling or experiments and their characteristics are compared to the theoretical
counterparts from the posterior predictive distribution. This is usually done via quanti-
tative summaries, e.g. empirical averages and theoretical posterior means or nominal and
true coverage probabilities of Bayesian probability intervals should agree, respectively.
However, collection of new data is often not feasible or even impossible, and one has
to turn to internal validation, also called posterior predictive checking, instead. Here,
one checks whether the already observed data y appear plausible under the posterior
predictive distribution
p(yrep | y) =
Z
p(yrep | θ)p(θ | y)dθ.
In practice, one simulates suﬃciently many realisations of the parameter θ from p(θ | y)
and for each outcome, a sample yrep of the same size as the original dataset is generated
from p(yrep | θ). The notation yrep is used to indicate that these data are obtained under
the very same conditions as y, whereas the previously used ˜y may also denote values
from other experiments or depending on other underlying covariates. Note that for hier-
archical models, an appropriate choice for the posterior predictive distribution should be
made, as outlined in the previous section. Various numerical and graphical techniques
for comparison of observed and simulated values are possible. One may display all data
134

A Bayesian Statistics
for several replications if the dataset is rather small. Computation and plotting of sum-
mary statistics such as mean values or quantiles over all replicates and the observed
data, respectively, is more suitable for large datasets. An alternative is the computation
and visualisation of Bayesian residuals, which will not be further discussed in this work.
For more details on graphical tools for posterior predictive checks, the reader is again
referred to Gelman et al. (2013). It is worth mentioning that for prediction purposes,
advanced internal diagnostics such as cross-validation can be easily adopted, of course.
Although qualitative examination of predicted and observed data gives much insight into
the accuracy of the ﬁt, it is desirable and scientiﬁc practice to base the ﬁnal conclusion
of whether a model is appropriate or not, on well-deﬁned quantitative decision rules,
such as hypothesis test statistics in frequentist analysis. Gelman et al. (2013) deﬁne the
Bayesian equivalent T(y, θ), which can be any suitable scalar summary of parameters
and data, as discrepancy measure. If such a measure only depends on the data, i.e.
T(y, θ) = T(y) for all θ, one speaks of a test statistic. Decision rules are quantiﬁed in
terms of p-values, i.e. tail-area probabilities of the discrepancy measure. In analogy to
frequentist statistics, the classical p-value for a test statistic T(y) with a ﬁxed value for
the parameter θ is deﬁned as
pC = P(T(yrep) ≥T(y) | θ),
i.e. the probability of observing replicated data at least as extreme as the sampled
data given the speciﬁed value θ. The deﬁnition makes use of the fact that T(yrep |
y, θ) = T(yrep | θ). The value θ is either chosen to be a null value, which is tested for
plausibility, or a substituted point estimate, e.g. an ML estimate in frequentist analysis,
when the model accuracy is to be assessed. In contrast to the classical approach, the
posterior predictive p-value for model ﬁt, going back to the inﬂuential work by Rubin
(1984), uses the inferred posterior distribution for θ to compare replicated data under
the posterior predictive distribution with observed data. Since the randomness in θ is
inherently accounted for, there is no need for pre-speciﬁed values for θ to be kept ﬁxed
such that the discrepancy measure T(y, θ) can indeed be a function of both the data
and the parameters. The Bayesian p-value for T(y, θ) is given by the probability under
(θ, yrep) given y, i.e. the joint posterior and posterior predictive distribution given the
data, that the test quantity evaluated at the posterior pair (θ, yrep) exceeds its outcome
135

A Bayesian Statistics
for θ combined with the observed sample y, i.e.
pB = P(T(yrep, θ) ≥T(y, θ) | y)
=
Z Z
IT(yrep,θ)≥T(y,θ) p(yrep | θ) p(θ | y) dyrep dθ
with indicator function I, again noting that p(yrep | θ, y) = p(yrep | θ). The formula
implies that Bayesian p-values can be conveniently computed by ﬁrst simulating from
the posterior distribution for θ and subsequent generation of corresponding predictive
values using p(yrep | θ). The resulting realisations are draws from the joint distribution
p(yrep, θ | y) and the p-value is estimated by the fraction of simulations for which the
inequality holds. Graphical visualisation of p-value computation is of additional help in
model assessment compared to a single numerical output. In case of test statistics, his-
tograms for the posterior distribution of T(yrep) depict the tail-area probability w.r.t. the
observed threshold T(y). For discrepancy measures that also depend on θ, histograms
for the posterior diﬀerence T(yrep, θ) −T(y, θ) should include 0 if the model provides a
good ﬁt, and scatterplots of posterior T(yrep, θ) versus posterior T(y, θ) show the p-value
as proportion of points in the upper half of the ﬁrst quadrant. Indeed, Gelman et al.
(2013) recommend to base any conclusions about the ﬁt of a model not only on the single
p-value but also on assessment of the magnitude of discrepancy detected in the plots.
Generally, a p-value close to 0 or 1 indicates possibly severe discrepancy between the
model and the observed data. It can be directly interpreted as the posterior probability
of seeing the observed sample in replicated data and is as such a measure of statistical
signiﬁcance, however even in Bayesian analysis it cannot be stated as the probability of
the model being true given the data.
There is no general guideline for the choice of the discrepancy measure, because it
depends on the scientiﬁc problem how well a summarising scalar can measure discrepancy
between observed and simulated data. Common practice is to account for features which
are not primarily addressed by the full probability model in order to avoid optimistic
results. Therefore, in most examples one would rather use summary statistics of less
interest such as the rank of a sample rather than, say, the mean value or, by their very
deﬁnition, analysis of the residuals to account for remaining uncertainty.
Generally,
ﬁnding meaningful discrepancy quantities is far easier in Bayesian statistics compared
136

A Bayesian Statistics
to the construction of pivotal frequentist test statistics. Besides such particular tests,
Gelman et al. (2013) suggest omnibus tests, i.e. tests on comparison of explained and
unexplained variance, as additional model checks. For an observed sample with values
yi, i = 1, . . . , n, important examples are the χ2 discrepancy quantity
T(y, θ) =
n
X
i=1
(yi −E(yi | θ))2
Var(yi | θ)
(A.1)
or the deviance given by T(y, θ) = −2 log(p(y | θ)).
In frequentist analysis, plug-
ging in null values θ0 for certain hypotheses yields hypothesis tests with statistics
T(y) = T(y, θ0). It is possible to use such test statistics for the replicated data yrep
in posterior predictive model checks, too. Similarly, by plugging in a point estimate
bθ(y) into (A.1), e.g. an ML estimate, one obtains a classical χ2 goodness-of-ﬁt test
T(y) = T(y, bθ(y)). Although in Bayesian model diagnostics one could compute T(yrep)
based on the replicated data and their corresponding estimate bθ(yrep), Gelman et al.
(2013) recommend applying the discrepancy measure T(y, θ) with the posterior out-
comes for θ directly, because this type of inference does not require any computational
burden in parameter estimation. The reference distribution for the Bayesian omnibus
test is immediately given through the distribution of T(yrep, θ) based on the posterior
predictive simulations yrep.
Note that the previous discussion was solely devoted to goodness-of-ﬁt analyses for one
given model. An elaborate theory has been developed on the important diagnostic tool
of model comparisons and sensitivity analysis. In particular, the deviance information
criterion as Bayesian extension of the Akaike and Bayesian information criteria, de-
veloped by Spiegelhalter et al. (2002), is a strong tool to test diﬀerent models against
each other by taking into account both the model’s ﬁt and complexity. Since model
comparisons are not discussed in this work, the reader is referred to the aforementioned
literature for further information.
137

B Markov Chain Monte Carlo
Although Bayesian inference is traced back to work by Thomas Bayes (1702–1761) and
Pierre-Simon Laplace (1749–1821), see e.g. Stigler (1986), its usage has been denied to
all but the simplest problems for which the theoretical posterior distribution for the pa-
rameters could be derived. In more complex problems, the normalising constant in the
product of prior and likelihood, which is necessary for a well-deﬁned density or probabil-
ity mass function, could not be analytically computed. As a result, prior distributions
had to be chosen to be conjugate w.r.t. the likelihood in order to meet computational
feasibility rather than any scientiﬁc reasoning. With the fast increase in computational
power, however, Bayesian statistics has seen a dramatic growth. The innovations in
numerical mathematics now allow for feasible approximations of posterior distributions
for general choices of priors, even in high-dimensional and hierarchical problems. In
particular, history of modern Bayesian statistics is closely connected to the development
of MCMC. Rather surprisingly, MCMC algorithms solve the diﬃcult problem of simu-
lation from a complex distribution, which is only known up to a normalising factor and
not suitable to generate from by plain Monte Carlo methods, by another complex tool:
the construction of a correspondingly high-dimensional discrete-time Markov chain with
continuous state space for the parameters of interest. Well-known algorithms have been
developed, for which the resulting Markov chain has the theoretical posterior distribution
as a stationary distribution. Although the existence of a unique limiting distribution,
which in this case would be the posterior, cannot be proven in most applications due
to the implicit complexity – which in fact requires the use of MCMC –, this procedure
has become undoubtedly successful. This appendix provides a review on general Markov
chain theory in Section B.1 and introduces the two main sampling algorithms, the Gibbs
and Metropolis-Hastings samplers, in Sections B.2 and B.3. Section B.4 concludes with
comments on convergence diagnostics. The review builds upon the excellent discussions
by Robert and Casella (2004) and Gamerman and Lopes (2006) on MCMC and by Meyn
and Tweedie (2009) on the theory of Markov chains with continuous state spaces.
138

B Markov Chain Monte Carlo
B.1 Markov Chain Theory
The purpose of MCMC in Bayesian statistics is to construct a Markov chain, whose state
space equals the parameter space, and which converges to a unique limiting distribution,
which coincides with the posterior distribution. Since parameter spaces are generally
of continuous nature, the well-known theory on discrete-space Markov chains must be
expanded correspondingly. It is worth mentioning that the index set, which represents
the iteration steps in the algorithm, is still discrete such that the term Markov chain is
indeed appropriate.
Let S ⊆Rd be the possibly continuous parameter space for the d-dimensional parameter
vector of interest in a probability model, and let B(S) be the set of all Borel sets on S.
A transition kernel is a function P : S × B(S) →[0, 1] for which P(x, ·) is a probability
measure on S for all x ∈S, and P(·, A) is measurable for all A ∈B(S). For such P,
the corresponding Markov chain with state space S is deﬁned as the discrete stochastic
process X := {X(n) : n ∈N0} with the Markov property, i.e. the transition probabilities
fulﬁl
P
 X(n+1) ∈A | X(n) = xn, . . . , X(1) = x1, X(0) = x0

= P
 X(n+1) ∈A | X(n) = xn

=
Z
A
P(xn, dx)
for all n ∈N0, x0, x1, . . . , xn ∈S, A ∈B(S). The Markov chain is homogeneous if the
distribution of X(n1), . . . , X(nk) | X(n0) equals the distribution of X(n1−n0), . . . , X(nk−n0) |
X(0) for all k ∈N and n0, n1, . . . , nk ∈N0 with n0 ≤n1 ≤· · · ≤nk, i.e. it is invariant
w.r.t. shifts in the index. For n ∈N, the n-step transition kernel P (n) : S ×B(S) →[0, 1]
is then recursively given by P (n) = P for n = 1 and
P (n)(x, A) =
Z
S
P (n−1)(y, A)P(x, dy),
x ∈S, A ∈B(S)
for n > 1. If π(0) denotes the probability measure on S for the initial state, one obtains
π(n) =
R
S P (n)(x, ·)π(0)(dx) as the distribution of the state of X(n).
In order to deﬁne stationary and limiting distributions for Markov chains with contin-
uous state spaces, let π be a probability measure on S. Then π is called a stationary
139

B Markov Chain Monte Carlo
distribution for the Markov chain X with transition kernel P if
π(A) =
Z
S
P(x, A)π(dx)
for all A ∈B(S). The deﬁnition shows that once the current state’s distribution of
X is equal to π, all future states are also distributed according to π, and X has
reached an equilibrium.
However, a Markov chain may have several stationary dis-
tributions. In MCMC, one is interested whether X has a unique stationary distribu-
tion to which the Markov chain will ultimately converge. Denoting the total variation
norm between two probability measures ξ1 and ξ2 as a measure of dissimilarity by
∥ξ1 −ξ2∥:= supA∈B(S) |ξ1(A) −ξ2(A)|, the limiting distribution of X with transition
kernel P and initial state distribution π(0) is the unique probability measure π which
fulﬁls
lim
n→∞
π(n) −π
 = 0,
if this limit exists.
The following attributes of a Markov chain are important for the broad theory on nec-
essary and suﬃcient characteristics for the existence of stationary and limiting distribu-
tions. A Markov chain is said to be π-irreducible if π is a probability measure on S and
for all A ∈B(S) with π(A) > 0, it holds that there is a non-zero probability of X reaching
A in ﬁnitely many steps for any initial state1. In an informal way, irreducibility assures
that it does not matter how the Markov chain is initialised, to guarantee that all non-
trivial sets under π can be reached. It can be shown that a π-irreducible Markov chain
has the unique stationary distribution π. A stronger assumption is the Harris-recurrence
named after the American mathematician Theodore Harris (1919–2005), which extends
irreducibility to inﬁnitely many visits of non-trivial sets under π given any starting value.
A π-irreducible Markov chain is Harris-recurrent if for every A ∈B(S) with π(A) > 0,
the number of visits P∞
n=1 I(X(n) ∈A | X(0) = x) given any x ∈S equals inﬁnity, π-
1To be precise, Markov chain theory w.r.t. continuous state spaces deﬁnes π-irreducibility for general
measures on S rather than probability measures. For this review, it suﬃces to focus on the interesting
case of probability measures; however, the terminology is directly restricted to this special case and
looses some of its generality. For the very exact deﬁnitions of irreducibility and other terms, the
reader is referred to the literature referenced in this section.
140

B Markov Chain Monte Carlo
almost surely. The third important property is aperiodicity, i.e. the non-existence of any
deterministic transition pattern which, for example, could allow an alternating sequence
of stationary distributions without a well-deﬁned limit. A π-irreducible Markov chain is
called periodic if there is a d ∈N with d > 1 and a sequence of non-empty and disjoint
sets E0, E1, . . . , Ed−1 ∈B(S) with π(∪d−1
i=0 Ei) = 1 such that for all i = 0, 1, . . . , d −1, it
holds that P(x, E(i+1) mod d) = 1 for all x ∈Ei. The Markov chain is aperiodic if it is
not periodic. The previous conditions are conveniently summarised under the the term
of ergodicity. A Markov chain X with stationary distribution π is ergodic if it is π-
irreducibly, Harris-recurrent, and aperiodic. It can be shown that for an ergodic Markov
chain with stationary distribution π and arbitrary initial state, the limiting distribution
exists and is given by π. It is worth mentioning that in contrast to discrete-space Markov
chains, the existence of a stationary distribution is a necessary condition rather than
the result of irreducibility, recurrence and aperiodicity. Note also that no statements are
made here regarding the pace of convergence, for which the reader is referred to Robert
and Casella (2004), for instance.
For a stochastic process, ergodicity can be informally stated as the property that after
convergence, the distribution of state occupancy over time agrees with the state dis-
tribution at a ﬁxed point in time. This is the desired attribute of a Markov chain in
MCMC, because the sample of realised values should approximate the unknown limiting
distribution, which in Bayesian inference represents the posterior. The interpretation is
due to the Ergodic Theorem, a version of the law of large numbers for dependent reali-
sations of a Markov chain. For a Markov chain X and a function t: S →R, deﬁne the
ergodic mean of t(X) after n ∈N steps via ¯tn := Pn
i=1 t
 X(i)
/n and the expected value
of t(X) under π as Eπ(t(X)) :=
R
S t(x)π(dx). The Ergodic Theorem states that if X
is π-irreducible and Harris-recurrent with stationary distribution π and Eπ(t(X)) < ∞,
then
lim
n→∞¯tn = Eπ(t(X)).
There are also central limit theorems applied with Markov chains for the quantity ¯tn,
which require stronger assumptions on the Markov chain, for which the reader is referred
to Robert and Casella (2004).
141

B Markov Chain Monte Carlo
B.2 Gibbs Sampling
While named after the American physicist Josiah Willard Gibbs (1839–1903) due to
an application with the Gibbs distribution in mechanical statistics, the Gibbs sampler
was developed by Geman and Geman (1984) to become one of the two main sampling
approaches to construct a Markov chain in MCMC. Let π be the posterior distribution
of the parameter θ = (θ1, . . . , θd)′ ∈S ⊆Rd, which is to be estimated. For simplicity in
notiﬁcation, the general dependence on the data y in the Bayesian context is dropped.
The necessity of MCMC implies that π is unknown or its simulation is intractable. The
Gibbs sampler assumes that the so-called full conditionals of π are known and easy to
simulate from, i.e. for each j = 1, . . . , d, the full conditional probability πj(θj | θ−j) =:
πj(θ−j) of θj given all other parameters θ−j := {θ1, . . . , θj−1, θj+1, . . . , θd} is available.
Beginning with a starting value θ(0) for the parameter θ, in each iteration step n, all
entries θj are successively visited and simulated according to the full conditionals, where
for all other parameters current realisations are used. More speciﬁcally, in iteration step
n, the following algorithm is run:
θ(n)
1
∼π1

θ(n−1)
2
, . . . , θ(n−1)
d

,
θ(n)
2
∼π2

θ(n)
1 , θ(n−1)
3
, . . . , θ(n−1)
d

,
...
θ(n)
j
∼πj

θ(n)
1 , . . . , θ(n)
j−1, θ(n−1)
j+1 , . . . , θ(n−1)
d

,
...
θ(n)
d
∼πd

θ(n)
1 , . . . , θ(n)
d−1

.
The distribution of θj is hence determined via the realisations θ(n)
1 , . . . , θ(n)
j−1, which have
already been sampled in the current iteration, and the realisations θ(n−1)
j+1 , . . . , θ(n−1)
g
from
the previous step for those parameters, which have not yet been visited. This entire pro-
cedure is repeated until a suﬃciently large sample of values for θ is established.
It is easy to see that the ultimate outcome {θ(n)} yields the path of a homogeneous
Markov chain with the parameter space S as state space. Theory on the Gibbs sampler
reveals that the distribution π for θ is indeed a stationary distribution for the underly-
142

B Markov Chain Monte Carlo
ing Markov chain. This statement is the theoretical foundation for the Gibbs sampler,
because if a limiting distribution for {θ(n)} exists, it must agree with the then unique
stationary equilibrium, and the Markov chain will converge to the posterior. The suﬃ-
cient condition of ergodicity for the existence of a limiting distribution, however, need
not be true for the resulting Markov chain and must be proven individually for each
π. Since MCMC is principally applied to simulate from complex distributions, estab-
lishing ergodicity is far from trivial. The interested reader is referred to Robert and
Casella (2004) for more details on suﬃcient conditions for ergodicity of a Markov chain
obtained through Gibbs sampling. In practice, modellers simply apply the algorithm
and empirically check for convergence based on the realised path, see Section B.4. If an
equilibrium has been reached, it is accepted as the posterior distribution, and a large
number of simulations from the chain provides a discrete pseudo-independent approxi-
mation of the theoretical distribution.
Due to its computational eﬃciency, the Gibbs sampler is a favourable MCMC technique
with typically fast convergence. The knowledge of the full conditionals can be further
used for consistent continuous estimators of the density for π. Several amendments of the
standard algorithm above have been proposed in the literature to improve computational
eﬃciency, speed of convergence, or methods for statistical inference on π. Details are
discussed by Robert and Casella (2004). The drawbacks of Gibbs sampling lie in the
assumption on the knowledge of all full conditionals, which requires possibly diﬃcult
analytical groundwork and may not be met in many applications.
B.3 Metropolis-Hastings Sampling
If full conditional distributions are not available or not feasible to simulate from, ap-
plication of the Gibbs sampler is not possible. In this case, the most useful alternative
is the Metropolis-Hastings sampler, a proposal-and-rejection type algorithm named af-
ter Nicholas Constantine Metropolis (1915–1999) and W. Keith Hastings (*1930). A
special case of this sampling procedure, the Metropolis sampler, was ﬁrst described by
Metropolis et al. (1953) to simulate molecules in chemical liquids via the Boltzmann dis-
tribution. Hastings (1970) extended this algorithm, which resulted in the more general
Metropolis-Hastings sampler. Since the full conditionals need not be known, the mini-
143

B Markov Chain Monte Carlo
mal requirements on π make this sampling algorithm widely applicable, but convergence
is typically slower.
In the Metropolis-Hastings algorithm, the ultimate Markov chain {θ(n)}, which should
converge against π, is constructed to have a transition kernel of the form P(x, dy) =
α(x, y)q(x, dy) for x ̸= y, where α: S×S →[0, 1], q: S×B(S) →R+, and q(x, ·) is a prob-
ability measure for all x ∈S. If the current state of the Markov chain is x, the transition
probability function is decomposed into a proposal density q(x, ·) and the probability
α(x, ·), which can be thought of as the acceptance rate for the suggested new state. For
the Metropolis-Hastings sampler, the analyst deﬁnes proposal distributions q(x, ·), which
are known up to a constant or at least symmetric, i.e. q(x, dy) = q(y, dx), and which are
easy to simulate from. The algorithm only requires the minimal assumption on π that
for all x, y ∈S, the ratio π(dy)/q(x, dy) is known up to a constant independent of x,
which is particularly useful when π has a normalising constant that cannot be computed.
With this ratio, the so-called Metropolis-Hastings acceptance probability
α(x, y) = min

1, π(dy)q(y, dx)
π(dx)q(x, dy)

(B.1)
for all x, y ∈S with π(dx)q(x, dy) > 0 is well-deﬁned. With an initial value θ(0) in
the support of π, the n-th step of the Metropolis-Hastings algorithm starts with the
simulation of a proposal value θ∗∼q(θ(n−1), dθ) based on the current state θ(n−1). With
probability α
 θ(n−1), θ∗
, it is accepted as new state θ(n); otherwise the Markov chain
remains at θ(n−1), i.e.
θ(n) :=



θ∗,
U ≤α
 θ(n−1), θ∗
θ(n−1),
U > α
 θ(n−1), θ∗ ,
where U ∼U([0, 1)) is independent of θ∗, and α(θ(n−1), θ∗) is given by (B.1). The pro-
posal is always accepted if π(dθ∗)/q(θ(n−1), θ∗) increases w.r.t. π(dθ(n−1))/q(θ∗, θ(n−1))
and, interestingly, may be still adopted with positive probability in the other case. In
many applications, q is chosen to be symmetric such that the Metropolis-Hastings ac-
ceptance probability reduces to the likelihood ratio α(x, y) = min{1, π(dy)/π(dx)}.
The resulting Markov chain is homogeneous with transition kernel given by P(x, dy) =
144

B Markov Chain Monte Carlo
α(x, y)q(x, dy) and stationary distribution π. As with the Gibbs sampler, this result
expresses the main motivation behind this algorithm, because the Markov chain will
converge against π if a limiting distribution exists. Again, suﬃcient conditions for the
existence of such a limit cannot be claimed in general due to the dependence on π and
q; however, ergodicity is easier to establish at the design stage through the analyst’s
freedom in the choice of the proposal distribution, see Robert and Casella (2004). De-
tailed discussions are also given for special cases of the universal algorithm above, for
example when the proposal distribution q(x, dy) = q(dy) is independent of the current
state, or – as in the original Metropolis sampler – it is a symmetric distribution centred
at the current value. While the Gibbs sampler requires more groundwork on analytical
expressions of the full conditionals, the Metropolis-Hastings sampler requires so-called
tuning, a careful analysis of the outcome to assess the performance of the chosen pro-
posal distribution q. If the range of proposals is chosen to be very close to the current
value, innovations in the path of the Markov chain are small and many iterations are
necessary to achieve a good level of mixing w.r.t. π. On the other hand, the opposite
extreme of a rather uninformative q may lead to many proposals outside the range of π
and the number of accepted proposals can be vanishingly small so that the chain stays
in the current state for a long time. Both scenarios imply slow convergence and, after
reaching stationarity, low mixing such that many steps of the algorithm are required. In
these cases, the proposal distribution must be tuned to achieve a good balance between
the acceptance rate and the variability in the path of the Markov chain.
B.4 Convergence Diagnostics
Once a sample path of a Markov chain {θ(n)} has been created via any of the above
MCMC procedures, convergence diagnostics must be conducted to assess the validity of
the ergodic sample as a pseudo-independent sample of the posterior distribution π. Such
diagnostics aim to justify the existence of a unique limiting distribution (if this could
not be established a priori via theoretical arguments) and, if so, whether and when the
actual equilibrium has been reached. The latter implies detection of the burn-in period,
i.e. the time which is required for the sample path to leave its initial set-up and reach
the stable support of π. The iterations within the burn-in period must be discarded for
the ergodic sample to be meaningful. Moreover, convergence diagnostics tools play the
145

B Markov Chain Monte Carlo
central role in tuning of Metropolis-Hastings algorithms.
There exist both theoretical and empirical approaches for convergence diagnosis in the
literature on MCMC. However, theoretical tools suﬀer from the reliance on the true
distribution π, which in MCMC applications is often not fully known or too complex
to work with analytically. As a consequence, convergence diagnostics are generally only
based on empirical approaches for realised paths of the Markov chain, although statistical
errors prevent them from being correct with absolute certainty. Most commonly, an
informal graphical analysis is conducted, which includes some of the following:
• Plots of the paths of the marginal components θ(n)
j
versus the iterations n to check
for an equilibrium after a possible burn-in period.
• Scatterplots of the empirical bivariate distribution for θi and θj with i ̸= j, taken
over time, to check for an equilibrium with extreme observations only stemming
from a burn-in period.
• Plots of the paths of the marginal ergodic means and variances for θ(0)
j , . . . , θ(n)
j
versus the iterations n to check for convergence against a constant value.
• If available, plots of the marginal distributions after rejection of a potential burn-in
period for several diﬀerent initialisations θ(0) of the algorithm to check for identical
distributions.
Convergence plots give much insight into the behaviour of the Markov chain and point
out possible ﬂaws in the algorithm. Analyses, however, have to be done carefully, be-
cause a stationary behaviour in a realised path that is hypothesised to be the limit, may
only be due to what is usually referred to as metastability, i.e. a temporal equilibrium
caused by pure chance or the existence of several stationary distributions. Moreover,
inference for the convergence of a multidimensional quantity can be biased since only
marginal information is used.
More formal techniques have been proposed over the last decades to overcome the ten-
dency of subjectivity in assessing graphical output. For a function t: S →R, Raftery
and Lewis (1992) suggest to compute the burn-in length and the subsequent number
of required iterations to estimate conﬁdence boundaries for t(θ) with pre-speciﬁed con-
ﬁdence level and error tolerance. Robert and Casella (2004) point out that, with this
146

B Markov Chain Monte Carlo
method, convergence is only analysed for the conﬁdence boundaries rather than the en-
tire Markov chain. Another approach is derived from common time series analysis. If
the sample path is believed to have reached an equilibrium, ergodic sample averages can
be computed for diﬀerent windows at the beginning and end of the path, respectively.
Under the hypothesis of convergence of the Markov chain, both empirical means should
be similar. In fact, denoting by ¯ta and ¯tb the versions of the average ¯t = P
i t(θ(i))/n at
both windows, respectively, for simultaneously increasing sample sizes the distribution
of the pivotal quantity
¯ta −¯tb
q
d
Var(¯ta −¯tb)
converges to the standard normal distribution. Values of large absolute magnitude indi-
cate a lack of convergence, though small values do not necessarily guarantee convergence.
Note that the variance estimator must be chosen to account for the fact that the re-
alisations θ(i) are identically distributed but not independent. Geweke (1991) employs
spectral time series analysis to estimate the sample’s variance, in which case the test
is also referred to as Geweke’s diagnostics. Alternatively, the MCMC output can be
suﬃciently thinned to eliminate serial autocorrelation, and the test is applied to the
resulting pseudo-independent sample. Then the variance is estimated via the sum of
plain variance estimators for the pseudo-independent sample means ¯ta and ¯tb. If several
paths of Markov chains with diﬀerent, preferably overdispersed, initialisations are avail-
able, convergence to a common equilibrium can be assessed via the estimated variances
between and within paths. If convergence has not been reached, the individual paths
are still inﬂuenced by their initial values. The ergodic means for the diﬀerent paths
show a wide spread between each other, and the sample variance of such ergodic means
overestimates the true variance. Conversely, the average of ergodic variances within each
path underestimates the true variance, because the Markov chains have not yet traversed
their burn-in range to the support of the equilibrium. A numerical output is given by
the proportional comparison of the two diﬀerent estimates for the variance. It is far
from one if there is disagreement between the various paths, but formal hypothesis tests
are not available. For more information on these and further methods, see the review
by Robert and Casella (2004).
147

C Vector Error Correction Models
In this appendix, the VECM, a well-known approach in multivariate time series analysis,
is presented. The VECM is an extension of the VAR model, which itself is the vector-
valued equivalent to standard AR approaches in time series analysis. While multiple
time series can be modelled simultaneously in VAR models with due regard being given
to serial cross-correlation of current and past multi-dimensional values, the VECM ad-
ditionally accounts for long-term equilibriums between the single time series, i.e. there
exists a linear combination of the diﬀerent time series which is stationary, whereas the
marginal time series may be non-stationary. This so-called cointegration can often be
observed between diﬀerent macroeconomic measures such as stock market indices or
prices for commodities and ﬁnancial products. Indeed, the VECM was developed in
the context of ﬁnancial econometrics, mainly by a series of pioneering papers, starting
with the work by Granger (1981) and further exploration in the famous seminal paper
by Engle and Granger (1987) with much contribution from several authors in the years
thereafter. Most notably, Johansen (1988, 1991) and Johansen and Juselius (1990, 1992)
developed an ML estimation framework, sometimes loosely referred to as the Johansen
procedure, which is widely used nowadays. A thorough overview on the VECM can be
found in L¨utkepohl (2007) and Johansen (1995), for instance, which the following discus-
sion is mainly based on. The reader is expected to bring general knowledge of common
time series analysis as it can be found in many standard textbooks, for example in Box
et al. (2013) or Brockwell and Davis (2009). Detailed coverage of general multivariate
time series analysis is provided in the books by L¨utkepohl (2007) and Reinsel (2003).
The remainder of this appendix is organised as follows. VAR processes and the concept
of cointegration are reviewed in Sections C.1 and C.2, respectively, before introducing
the VECM in Section C.3. Sections C.4 and C.5 describe both frequentist and Bayesian
estimation techniques, and Section C.6 summarises model diagnostics for the VECM.
148

C Vector Error Correction Models
C.1 The Vector Autoregressive Model
In the following, let {xt, t = 1, . . . , T} be a multivariate time series of dimension m ∈N,
i.e. xt ∈Rm for each t = 1, . . . , T. The time series {xt} is an m-dimensional VAR process
of order k ∈N, denoted as xt ∼VAR(k), if it is deﬁned by the equations
xt = φDt +
k
X
i=1
Aixt−i + εt,
t = k + 1, . . . , T
(C.1)
with initial values x1, . . . , xk and m-dimensional white noise εt, i.e. E(εt) = 0, E(εtε′
t) =
Ωfor all t = k + 1, . . . , T, and E(εtε′
s) = 0 for all s ̸= t, where Ω∈Rm×m is a positive
deﬁnite covariance matrix. For this work, it will suﬃce to think of εt as Gaussian white
noise, i.e. the special case of iid errors εt ∼Nm(0, Ω). A vector of possibly time-varying
constants Dt with some ﬁxed dimension d ∈N enables the user to include deterministic,
e.g. linear or seasonal, trends. This inﬂuence is measured by the according parameter
matrix φ ∈Rm×d. Further parameters are the k AR coeﬃcient matrices Ai ∈Rm×m,
which describe the impact of recent values in xt on the current outcome. Adjustment
of the so-called order k leads to diﬀerent time horizons for the serial autocorrelation,
i.e. xt is conditionally independent of xt−k−1 and previous terms given the intermediate
outcomes xt−k, . . . , xt−1. Note that in the deﬁnition of the VAR model, it is implicitly
assumed that k is the maximum value for which Ak ̸= 0.
For a given set of parameters, the solution of the system in (C.1) can be stated in terms
of the initial values of {xt} and the independent error terms εt, t = k + 1, . . . , T, see
Theorem 2.1 in Johansen (1995). The reverse characteristic polynomial of this process
is given by
A(z) = Im −
k
X
i=1
Aizi,
z ∈C,
where Im is the m × m identity matrix. Denoting by B the backshift operator, deﬁned
through the operation Bxt = xt−1, the reverse characteristic polynomial obviously sat-
isﬁes A(B)xt = φDt + εt for the VAR(k) process deﬁned in (C.1). Let |A(z)| denote the
determinant of A(z). If Dt is bounded by a polynomial in t, and if |A(z)| ̸= 0 for all z
with |z| ≤1, i.e. the VAR process does not have explosive or seasonal roots, then the
149

C Vector Error Correction Models
process yt := xt −E(xt) is said to be stable, and, in this case, {xt} can be expressed as
an MA process via
xt =
∞
X
i=0
Ci(εt−i + φDt−i) = C0(B)(εt + φDt),
where the coeﬃcient matrices Ci are given by C0(z) = P∞
i=0 Cizi = A(z)−1 for |z| < 1+δ
for some δ > 0, and can be solved for recursively. Stability is the required property of
any time series to enable statistical analyses, since if {yt} is stable, then it is also sta-
tionary1 with zero mean, i.e. it holds that E(yt) = 0 and that E(yty′
t−h) = γ(h) depends
on h ∈N0 only for all t. Often, stability and stationarity are used interchangeably,
although a stationary process need not be stable, and, in the literature, the condition
|A(z)| ̸= 0 for |z| ≤1 is not only referred to a stability but also as stationarity condition.
Note that the VAR(k) model is a special case of the more general family of VARMA
models, which are also discussed by L¨utkepohl (2007) as well as Box et al. (2013) and
Brockwell and Davis (2009). In analogy to the univariate case, the representation of
stationary multivariate time series through VARMA models is motivated by Wold’s De-
composition Theorem due to Wold (1938). It states that any stationary process can be
represented as the sum of two uncorrelated processes, one of which is a purely determin-
istic AR process and the other one has an MA representation, both having a possibly
inﬁnite order. In particular, if the deterministic part only consists of a mean term, Wold’s
Theorem states that the process has a pure MA representation. As a consequence, if
the MA coeﬃcients Ci are absolutely convergent, and the limit C0(z) = P∞
i=0 Cizi is
invertible for all z with |z| ≤1 such that C0(z)−1 can be expressed as a convergent series
A(z) = Im −P∞
i=0 Aizi, then {xt} is a VAR process of possibly inﬁnite order with coef-
ﬁcient matrices Ai. The absolute convergence of A(z) implies convergence of Ai to the
zero matrix and therefore a reasonable approximation by a ﬁnite order VAR(k) model for
suﬃciently large k ∈N. This result is the core motivation behind VAR models, because
it guarantees the usefulness of this approach for many eventually stationary time series
after possible transformations to account for deterministic components other than the
1This work adopts the convention in time series analysis that stationarity refers to weak or wide-sense
stationarity of time-invariant means and covariances. Other deﬁnitions, such as strict stationarity
of time-invariant joint distributions of vectors consisting of consecutive variables of the time series,
are not discussed here.
150

C Vector Error Correction Models
mean. Note that in the deﬁnition of the VAR model through (C.1), deterministic trends
or seasonal patterns can be naturally included through φDt. L¨utkepohl (2007) reviews
computation of the so-called Yule-Walker equations for the derivation of autocovariance
functions and least-squares estimators for the model parameters, ML estimation under
Gaussian white noise, determination of the lag length k, forecasting and checks of model
adequacy, among many more detailed topics.
C.2 Cointegration
The previous section showed that the VAR model is appropriate for stationary time
series with deterministic components, which can be modelled via φDt. Obviously, many
observed time series data will not meet such restrictive assumptions, for example time
series with stochastic trends, heteroskedastic covariances, or periodic patterns with time-
varying coeﬃcients. Of particular interest in this work are time series models for stochas-
tic trends, a feature observed in many real-life applications that can be accounted for
by applying the already established methodology to transformed quantities of the un-
derlying data. This section summarises approaches in the analysis of multivariate time
series with stochastic trends. For the many other possible complications with observed
time series, the interested reader is referred to the previously cited literature.
As with univariate time series, a time series is non-stationary when |A(z)| = 0 for some
z with |z| ≤1, i.e. the reverse characteristic polynomial has roots inside or on the edge
of the unit disk. If for a univariate time series at least one root is strictly inside the
unit disk, the time series is explosive in that its variance diverges with exponential rate.
Although fruitful for analyses of, say, bacterial growth, in statistical time series appli-
cations, such models are usually considered unreasonable, and attention is devoted to
the borderline case, when |A(z)| = 0 for |z| ≤1 implies |z| = 1. If, in particular, the
only root on the unit circle is the so-called unit root z = 1 and all other roots still fulﬁl
|z| > 1, the behaviour is similar to that of a random walk, which is exactly the AR(1)
model with its only root being the unit root. In contrast to explosive time series, such
processes are characterised by linearly increasing variances and asymptotic correlation of
one for large lags. Moreover, trends are linear if there is no superimposed deterministic
trend. Although of interest in applications with periodic data, the case of roots on the
151

C Vector Error Correction Models
unit circle other than the unit root z = 1 is not discussed here.
For the moment, let {xt, t = 1, . . . , T} be a univariate AR process without deterministic
components, which has d ∈N unit roots with all other roots being outside the unit disk.
Note that then A(z) = α(z)(1 −z)d, where α(z) is the characteristic polynomial of a
stable process, because all its roots are now outside the unit disk. Hence, the process
{xt}, given through A(B)xt = εt, can be written as
α(B)(1 −B)dxt = εt,
and it can be seen that the process yt := ∆dxt := (1 −B)dxt, which is the original
time series diﬀerenced d times, is stationary. Noting that xt = ((1 −B)−1)dyt with
(1 −B)−1 = P∞
i=0 Bi, the original time series xt is obtained by summing – or, in other
words, integrating – d times the stationary time series yt. Hence, the process is called
integrated 2 of order d, commonly denoted as xt ∼I(d). For consistency, a stationary
time series is then sometimes denoted as xt ∼I(0).
Now consider the general case of an m-dimensional VAR(k) process {xt} with A(z) =
Im −Pk
i=1 Aizi and without deterministic components, i.e.
A(B)xt = εt.
The adjugate matrix of A(B) is the matrix adj(A(B)) for which A(B) adj(A(B)) =
|A(B)|Im. Multiplying by adj(A(B)) from the left gives the alternative representation
|A(B)|xt = adj(A(B))εt.
(C.2)
Since it can be shown that |A(z)| is a characteristic polynomial, |A(B)| is a univariate
polynomial in the backshift operator, i.e. the left-hand side of (C.2) is an m-dimensional
vector of univariate AR processes with identical AR operators. By deﬁnition of the
adjugate matrix, the right-hand side of (C.2) is an m-dimensional MA process of ﬁ-
nite order.As in the univariate case, the AR operator |A(B)| is tested for unit roots,
2Note that in the general setting of Autoregressive Moving Average (ARMA) models, any process is
called integrated of order d if it can be characterised as a stationary and invertible ARMA model
after diﬀerencing d times.
152

C Vector Error Correction Models
where w.l.o.g. the case of roots with |z| ≤1 but z ̸= 1 is neglected. Again, if the AR
operator consists of d unit roots with all other roots being outside the unit disk, then
|A(B)| = α(B)(1 −B)d for some polynomial α with α(z) ̸= 0 for |z| ≤1, and the vector
∆dxt of d times marginally diﬀerenced time series is an m-dimensional stationary process.
L¨utkepohl (2007) points out that d is an upper bound for the integration order of each
marginal time series. In particular, all components may be integrated with orders strictly
less than d, and such orders may also vary. Moreover, if one allows {xt} to be VAR(k)
with deterministic trend vector φDt, the component-wise diﬀerencing technique can lead
to a stable representation α(B)∆dxt = adj(A(B))εt without deterministic trends in the
marginals, i.e. the underlying deterministic relations between the marginal time series in
xt are cancelled out. See the cited reference for simple examples. As a consequence of the
latter ﬁnding, considering marginal time series as I(d) processes and diﬀerencing them
individually can distort the structure of the multivariate time series, and therefore leads
to loss of information on the relationship between the components. As Box et al. (2013)
point out, dealing with non-stationarity becomes substantially diﬀerent and more com-
plicated in the multivariate case when the marginal time series share common stochastic
trends. In this situation, the individual time series x1t, . . . , xmt in xt = (x1t, . . . , xmt)′
are integrated of possibly diﬀerent orders, but wander jointly by satisfying a linear com-
bination β′xt = Pm
i=1 βixit, which itself is stationary with zero mean. If the maximum
order of integration among the marginals is d, and the process zt := β′xt fulﬁls β ̸= 0
and zt ∼I(d−b), then the multivariate process {xt} of integrated univariate time series
is called cointegrated of order (d, b), written as xt ∼C(d, b), with cointegrating vector β.
Cointegration can be interpreted as a deterministic long-run equilibrium β′xt = 0, su-
perimposed by stochastic but stable deviations through a univariate stationary process.
Such noisy equilibriums are often observed between macroeconomic quantities. With the
foregoing deﬁnition, one can think of xt being of integration order d itself, since ∆dxt is
stable but ∆d−1xt is not, although the order of integration for certain marginals may be
less than d. This clearly simpliﬁes terminology, but must be understood carefully when
analysing and interpreting the individual components. Moreover, note that the cointe-
gration vector β is not unique. Not only is cβ a cointegrating vector for any constant
c ̸= 0, but also several linearly independent cointegrating vectors β1, . . . , βr may exist
for a given cointegrated process.
153

C Vector Error Correction Models
C.3 Vector Error Correction Models
In the following, the special case of xt ∼C(1, 1) is considered, i.e. the marginals are
xit ∼I(0) or xit ∼I(1) for all i = 1, . . . , m, with the latter holding for at least one i,
and there exists at least one non-trivial linear combination zt ∼I(0) of xit, i = 1, . . . , m.
If xt ∼VAR(k) without deterministic components, then
xt =
k
X
i=1
Aixt−i + εt,
t = k + 1, . . . , T,
and |A(z)| has, say, d unit roots, where all other roots lie outside the unit disk. In
particular, it follows that |A(1)| = |Im −Pk
i=1 Ai| = 0, and so the m-dimensional square
matrix
Π := −
 
Im −
k
X
i=1
Ai
!
must be singular. Let r := rk(Π) be the rank of Π. Since Π is singular, it holds that
r < m. Also, suppose w.l.o.g. that r > 0, because for r = 0 the terms including Π would
simply vanish in the following discussion. Then there exists a decomposition Π = αβ′
with α and β both being non-zero m × r matrices of rank r. Diﬀerencing xt once yields
∆xt = xt −xt−1
=
k
X
i=1
Aixt−i + εt −xt−1
= −Imxt−1 + A1xt−1 +
k
X
i=2
Aixt−i + εt
= −Imxt−1 + A1xt−1 + A2xt−1 + · · · + Akxt−1 +
k
X
i=2
Ai(xt−i −xt−1) + εt
= Πxt−1 −A2∆xt−1 +
k
X
i=3
Ai(xt−i −xt−2 −∆xt−1) + εt
= Πxt−1 −
k
X
i=2
Ai∆xt−1 +
k
X
i=3
Ai(xt−i −xt−2) + εt
154

C Vector Error Correction Models
and hence, by induction,
∆xt = Πxt−1 −
k
X
i=2
Ai∆xt−1 −
k
X
i=3
Ai∆xt−2 −· · · −Ak∆xt−k+1 + εt
= αβ′xt−1 +
k−1
X
i=1
Γi∆xt−i + εt
(C.3)
with Γi := Pk
j=i+1 Aj for i = 1, . . . , k −1. Since, by assumption, the diﬀerenced time
series {∆xt−k+1, . . . , ∆xt−1, ∆xt} and εt are stationary processes, rearranging of (C.3)
reveals that the term αβ′xt−1 as a linear combination of stationary processes is sta-
tionary itself.
Multiplication of αβ′xt−1 by a matrix from the left does not distort
stationarity, and the special case of multiplication by (α′α)−1α′ reveals that even β′xt−1
is a vector of r diﬀerent stationary processes, which hence must be the cointegrating
long-run relationships. Therefore, β is called cointegration matrix and consists of the r
cointegrating vectors, given by its columns. The loading matrix α then consists of m
rows, each measuring the eﬀect of the long-run equilibriums on the corresponding time
series through a weighted sum. The rank r of Π can be interpreted as the number of
linearly independent equilibrium relationships between the univariate marginals, and is
often called the cointegration rank. Since Π = αβ′ = αQQ−1β′ = ˜α˜β′ with ˜α := αQ
and ˜β := β(Q−1)′ for every regular matrix Q ∈Rr×r, the decomposition of Π is not
unique, which corresponds to the non-uniqueness of representations for the individual
cointegrating equations. Identiﬁability can be obtained by imposing restrictions on α or
β, and most commonly one sets β = (Ir, β′
l)′ for some lower block matrix βl ∈R(m−r)×r.
This constraint is often referred to as linear normalisation.
The VAR(k) model for {xt} written as in (C.3) is referred to as the VECM representa-
tion. More precisely, this model equation is called the transitory version of the VECM,
compared to the equivalent long-run speciﬁcation
∆xt =
k−1
X
i=1
˜Γi∆xt−i + αβ′xt−k + εt,
t = k + 1, . . . , T
with coeﬃcients ˜Γi := −(Im −Pi
j=1 Aj) for i = 1, . . . , k −1. This work adopts the
transitory speciﬁcation of the VECM, because Π can be conveniently interpreted as the
155

C Vector Error Correction Models
error correction eﬀect on the previous observation rather than the outcome at a possibly
large lag k. Again, it is worth emphasising that although the maximum integrating or-
der of each univariate time series is at most 1, a VAR(k −1) representation for the ﬁrst
diﬀerences in {xt} would eliminate the cointegration term αβ′xt−1 and, hence, would
not contain the full information of the VAR(k) process {xt} as derived in (C.3). In par-
ticular, the derivation above reveals that a cointegrated process does not yield a VAR
representation for the ﬁrst diﬀerences of the original time series. Starting from a VECM
representation, however, is a valuable approach, as one obtains a stationary VAR(k −1)
process for the ﬁrst diﬀerences if r = 0 or, equivalently, Π = 0, and a stationary VAR(k)
process for the integrated time series if r = m, because a full rank m implies that Π is
regular such that |A(1)| ̸= 0, which means that {xt} has no unit roots.
As a ﬁnal step, the VECM presentation in (C.3) can be extended by an additional
term φDt for deterministic trends. Since Dt is time-dependent, it can be easily used to
incorporate constant means or any linear, quadratic, or higher order trend. The resulting
VECM
∆xt = φDt + αβ′xt−1 +
k−1
X
i=1
Γi∆xt−i + εt,
t = k + 1, . . . , T
(C.4)
is unrestrictive in the deterministic component. L¨utkepohl (2007) shows that if each
φDt can be decomposed into a sum with one addend being of the form −αβ′µ0, then
this latter term can be absorbed as intercepts into the cointegration relations such that
the process {β′xt} has constant mean µ0 ∈Rm. Similarly, parts of a linear trend in {xt}
can be absorbed into an expanded error correction term, representing linear trends in
the cointegrating relationships, whereas remaining time-invariant addends of φDt would
generate linear trends in the marginal time series. In this work, the focus is limited
to the unrestrictive speciﬁcation without exploring the nature of deterministic compo-
nents in more detail. The reader is referred to Johansen (1995) for a thorough discussion.
By analogy to the MA representation of any VAR(k) process, under minimum conditions
on the parameters and initial values in the VECM, the process {xt} can be represented as
a function in the white noise variables εk+1, . . . , εt and the initial values x1, . . . , xk. More
speciﬁcally, xt is decomposed into m −r stochastic trends, represented by a weighted
156

C Vector Error Correction Models
sum of m random walks that determine the long-run behaviour of xt, an I(0) process
denoting the disequilibrium error, as well as terms for the initial values and deterministic
components. This result is known as the Granger Representation Theorem3, see The-
orem 4.2 in Johansen (1995), which is of particular importance in deriving asymptotic
properties of parameter estimators.
Based on the ﬁndings with regard to Wold’s Theorem, this work focuses on the VECM
as the direct extension of the generally applicable VAR model through the error correc-
tion term. Note, however, that the broader class of VARMA models contains stochastic
processes, which cannot be represented through pure VAR equations. If such processes
are not stationary, they may be modelled as integrated time series and, again, possible
cointegration for long-run relationships between the marginal time series must be taken
into account. The generalisation of the VECM to cointegrated VARMA models is dis-
cussed by L¨utkepohl (2007) and the references therein, but not further considered here.
Note also that the concept of cointegration, which was introduced in multivariate time
series through the work by Granger (1981) and Engle and Granger (1987), is closely
connected to the idea of even earlier developed error correction models, which were de-
signed to overcome spurious correlation in hitherto used linear regression approaches.
Besides the above derivation of the VECM, L¨utkepohl (2007) motivates this model by
extension of error correction models by time series concepts. A general survey on error
correction models can be found in, e.g., Salmon (1982).
C.4 Frequentist Estimation and Forecasting
Estimation of the VECM becomes more complicated than for a VAR speciﬁcation, be-
cause in addition to the order k, the cointegration rank r is generally unknown and must
be estimated. As a result, asymptotic behaviour for the estimators is diﬀerent from what
is known for the stationary VAR(k) model. The starting point for the general estimation
3As Hansen (2005) points out, the famous Granger Representation Theorem in this form is due to
Johansen (1991), but should not be confused with the same-titled theorem proven by Engle and
Granger (1987), which makes statements about the existence of an error correction representation
for a process with stationary and invertible VARMA speciﬁcations for its ﬁrst diﬀerence and coin-
tegrating relationships.
157

C Vector Error Correction Models
of a VECM speciﬁcation is the simpliﬁed version
∆xt = αβ′xt−1 + εt,
t = 2, . . . , T
with initial value x1, standard white noise for the error terms, no deterministic compo-
nents, and a lag order of k = 1 for the VAR model, i.e. the innovation process does not
have any AR components. Unknown parameters that have to be estimated, are the coin-
tegration rank r and the matrices α, β, as well as the variance and covariance terms for
the error terms. The estimation procedure will be generalised later for an arbitrary lag k.
For the following estimators, it is assumed that a sample of time series data x2, . . . , xT
and the initial value x1 are observed.
Given that the cointegration rank r and the
covariance matrix Ωfor the white noise are known with r ̸= 0, the unrestricted least-
squares estimator is given by
bΠ :=
 T
X
t=2
∆xtx′
t−1
!  T
X
t=2
xt−1x′
t−1
!−1
,
(C.5)
and L¨utkepohl (2007) shows that this is an unbiased and asymptotically normal esti-
mator.
In particular, denoting by vec and ⊗the vectorisation operator and Matrix
Kronecker product from Deﬁnitions D.2 and D.3, respectively, it holds that
√
T −1 vec

bΠ −Π

d−→Nm2(0, β Cov(zt, zt−1)−1β′ ⊗Ω),
where zt := (β, α⊥)′xt for some t ∈{2, . . . , T} with an orthogonal complement α⊥
of α, i.e. an m × m −r matrix of full column rank with α′α⊥= 0.
The matrix
β Cov(zt, zt−1)−1β′ can be consistently estimated via
 
(T −1)−1
T
X
t=2
xt−1x′
t−1
!−1
.
When Ωis unknown, the usual residual covariance matrix yields a consistent estimator
for Ωand allows for t-tests on individual entries in bΠ. However, more general Wald tests
with more ﬂexible restrictions suﬀer from singularities in the limiting distribution, and
must be treated diﬀerently, see L¨utkepohl (2007).
158

C Vector Error Correction Models
With the linear parametrisation β = (Ir, β′
l)′ for some βl ∈R(m−r)×r, the estimators for
α and β are derived in a two-step procedure. Noting that under this normalisation the
ﬁrst r columns of Π = αβ′ are equal to α, a consistent estimator bα for this matrix is
given by the corresponding columns in bΠ as in (C.5). Then the estimated generalised
least-squares estimator for βl is deﬁned through
bβ′
l :=

bα′bΩ−1bα
−1
bα′bΩ−1
 T
X
t=2

∆xt −bαx(1)
t−1

x(2)′
t−1
!  T
X
t=2
x(2)
t−1x(2)′
t−1
!−1
,
where xt =

x(1)′
t
, x(2)′
t
′
with r-dimensional x(1)
t
and (m −r)-dimensional x(2)
t , and bΩ
is the consistent residual covariance matrix estimator for Ω. Asymptotic normality can
be established for this estimator as well, and it brings the advantage of asymptotic χ2
distributions for Wald tests.
Under the additional assumption of Gaussian white noise, the normal distribution on
εt can be used to establish ML estimation.
The maximisation problem of the (log)
likelihood is equivalent to a determinant minimisation problem, which can be solved by
an eigen-decomposition of the matrix
 T
X
t=2
xt−1x′
t−1
!−1/2  T
X
t=2
xt−1∆x′
t
!  T
X
t=2
∆xt∆x′
t
!  T
X
t=2
∆xtx′
t−1
!  T
X
t=2
xt−1x′
t−1
!−1/2
.
Denoting the orthonormal eigenvectors of this matrix by v1, . . . , vm, where the indices
correspond to the eigenvalues λ1 ≥· · · ≥λm, the ML estimator is eΠ := eαeβ′ with
eβ := (v1, . . . , vr)′
 T
X
t=2
xt−1x′
t−1
!−1/2
,
eα :=
 T
X
t=2
∆xtx′
t−1eβ
!  T
X
t=2
eβ′xt−1x′
t−1eβ
!−1
.
The ML estimator has the same asymptotic properties as the unrestricted least-squares
estimator bΠ. Estimators for the normal linearisation are obtained by multiplication of
eβ with the inverse of its own upper r × r block matrix, which yields

Ir, eβ′
l
′
, and by
substitution of eβ in the second formula to obtain the corresponding estimator for α.
159

C Vector Error Correction Models
Again, asymptotic properties correspond to those found for the estimated generalised
least-squares estimator.
The previously mentioned residual covariance matrix is estimated as
bΩ:= (T −1)−1
T
X
t=2

∆xt −bΠxt−1
 
∆xt −bΠxt−1
′
,
where bΠ can be any of the above estimators for Π. Simple versions of the above estima-
tors for the special case of r = 0 are speciﬁcally derived by L¨utkepohl (2007).
For the general case of k AR lags, i.e. for the VECM of the form
∆xt = αβ′xt−1 +
k−1
X
i=1
Γi∆xt−i + εt,
t = k + 1, . . . , T
with initial values x1, . . . , xk, each of the above estimators can be generalised. With the
compact matrix formulation already known from Section 3.2.2, the model can be written
as
∆X = αβ′X1 + ΓX2 + ε
with m×T−k matrices ∆X = (∆xk+1, . . . , ∆xT), X1 = (xk, . . . , xT−1), ε = (εk+1, . . . , εT),
an m × (k −1)m matrix Γ = (Γ1, . . . , Γk−1), and a (k −1)m × T −k matrix
X2 =

(∆x′
k, . . . , ∆x′
2)′ ,
 ∆x′
k+1, . . . , ∆x′
3
′ , . . . ,
 ∆x′
T−1, . . . , ∆x′
T−k+1
′
.
The consistent and asymptotically normal unrestricted least-squares estimator can be
shown to be

bΠ, bΓ

:= (∆XX′
1, ∆XX′
2)
 
X1X′
1
X1X′
2
X2X′
1
X2X′
2
!−1
with consistent estimator for the covariance matrix
bΩ:= (T −(m + 1)k)−1 
∆X −bΠX1 −bΓX2
 
∆X −bΠX1 −bΓX2
′
.
160

C Vector Error Correction Models
Remarks w.r.t. t and Wald tests made for the unrestricted least-squares estimator in the
case without AR components apply here, too. Now, let
M = IT−k −X′
2(X2X′
2)−1X2,
R0 = ∆XM,
R1 = X1M,
and split R1 = (R(1)′
1 , R(2)′
1 )′ into block matrices with r and m −r rows, respectively.
By analogy to the previous case, under linear normalisation the estimated generalised
least-squares estimator for βl is
bβ′
l :=

bα′bΩ−1bα
−1
bα′bΩ−1 
R0 −bαR(1)
1

R(2)′
1

R(2)
1 R(2)′
1
−1
,
when bΠ, bΓ, bΩare given through the unrestricted least-squares estimation above and bα
equals the ﬁrst r rows of bΠ. Its asymptotic behaviour corresponds to the simple case
where k = 1.
Under iid εt ∼Nm (0, Ω), the previous ML estimator can be generalised for an arbitrary
lag order k. With above deﬁnitions of M, R0, R1 and the matrices Sij = RiR′
j/(T −
k) for i, j = 0, 1, (log) likelihood maximisation can again be achieved through an
eigen-decomposition.
Let λ1 ≥· · · ≥λm be the ordered eigenvalues of the matrix
S−1/2
11
S10S−1
00 S01S−1/2
11
with corresponding orthonormal eigenvectors v1, . . . , vm. The ML
estimator is then given by eΠ := eαeβ′ with
eβ′ := (v1, . . . , vr)′S−1/2
11
,
eα := S01eβ

eβ′S11eβ
−1
.
The corresponding estimators for Γ and Ωare
eΓ :=

∆X −eΠX1

X′
2 (X2X′
2)−1 ,
eΩ:= (T −k)−1 
∆X −eΠX1 −eΓX2
 
∆X −eΠX1 −eΓX2
′
.
All estimators are consistent and asymptotically normal with the same limiting distri-
161

C Vector Error Correction Models
bution as the least-squares estimator, and eΩis asymptotically independent of all other
parameter estimators. For an identiﬁable decomposition of eΠ, the same technique as for
the case of k = 1 leads to the ML estimator of βl and corresponding α under the linear
normalisation. Again, the asymptotic distribution coincides with that of the estimated
generalised least-squares estimator. As before, special formulae for the case of r = 0 are
again derived in L¨utkepohl (2007).
Generalisation of the already introduced estimators through inclusion of deterministic
components is straightforward. Consider the unrestrictive speciﬁcation of the VECM in
(C.4) with deterministic component Dt and corresponding parameters φ. The compact
representation of the VECM introduced in this section remains valid if Γ and X2 are
replaced by
Γ = (Γ1, . . . , Γk−1, φ) ,
X2 =
 ∆x′
k, . . . , ∆x′
2, D′
k+1
′ , . . . ,
 ∆x′
T−1, . . . , ∆x′
T−k+1, D′
T
′
.
L¨utkepohl (2007) shows that with above notation, both least-squares and ML estima-
tors are given by their previous formulae. Asymptotic behaviour remains principally the
same, too.
Once all parameters, including the covariance matrix in the VECM representation, are
estimated, it is possible to return to the VAR formulation in (C.1) for prediction pur-
poses. For the AR parameters A1, . . . , Ak in levels, it holds that A1 = Im + Π if k = 1,
and
A1 = Im + Π + Γ1,
Ai = Γi −Γi−1,
i = 2, . . . , k −1,
Ak = −Γk−1
otherwise. Being linear transformations of Γ and Π, consistent and asymptotic normal
estimators bA1, . . . , bAk are obtained by replacing Γ and Π by their least-squares or ML
estimators.
The estimators bΩand, if applicable, bφ can be directly carried forward.
Consequently, for h ∈N, the h-step forecasts for the time series in levels are then
162

C Vector Error Correction Models
recursively given through
bxT+h = bφDT+h +
k
X
i=1
bAibxT+h−i,
where bxt = xt for all t ≤T. Under the assumption of future iid Gaussian white noise
with covariance matrix Ω, the forecast errors xT+h −bxT+h are multivariate normal with
zero mean and a covariance matrix that is estimated by
bΩh :=
h−1
X
i=0
bCibΩbC′
i,
where bCi := Pi
j=1 bCi−j bAj for i = 1, . . . , h −1 can be solved for recursively with start-
ing value bC0 = Im and bAj = 0 for j > k. With this result, conﬁdence intervals for
individual components or conﬁdence regions for the multivariate h-step forecast become
computable. For simultaneous conﬁdence intervals for several components, inﬂation of
type I errors must be dealt with via the, say, Bonferroni method.
All above approaches rely on the assumption that both the lag order and cointegration
rank are known, which will be unreasonable in most applications. As it is the case for
the lag order k in any AR model, the rank, too, has to be determined in a prior step, and
estimation is conducted as described before based on this ﬁnding. Since a VECM with
k −1 lags can be written as an equivalent VAR(k) model, lag order selection is adopted
from the general VAR framework and applied with the latter representation. For the
VECM representation, the number of lags is reduced by one such that the VAR(k)
process need not be analysed for k = 0. As known from univariate AR processes, the
value of k may be estimated through diﬀerent approaches.
A common strategy in-
volves consecutive Wald or likelihood-ratio tests. Starting with a predetermined upper
bound K for k, by decreasing the possible lag order k by 1, one tests Ak = 0 versus
Ak ̸= 0 | AK = · · · = Ak+1 = 0 until no rejection occurs. Due to the signiﬁcant increase of
type I errors in multiple testing schemes with the complicated determination of a correct
nominal signiﬁcance level, a popular alternative is so-called information criteria. The ﬁ-
nal prediction error criterion by Akaike (1969) is recommended if forecasting is the main
purpose, as it chooses the lag order such that the mean prediction error is minimised.
The Akaike information criterion, also due to Akaike (1974), the Bayesian or Schwarz
163

C Vector Error Correction Models
information criterion due to Schwarz (1978), as well as the Hannan-Quinn information
criterion by Hannan and Quinn (1979) are prominent alternatives. L¨utkepohl (2007)
deﬁnes each of these criteria and discusses pro and cons in terms of diﬀerent sample sizes.
Since the lag order selection is done with aid of the VAR representation, it can be
conveniently conducted without knowledge of the number of cointegration relationships,
whence it is typical to derive the lag order ﬁrst and the cointegration rank subsequently.
Although information criteria for rank determination can be found in the literature,
here it is common to apply consecutive likelihood-ratio tests under the assumption of
Gaussian white noise. As mentioned earlier, the maximised (log) likelihoods are obtained
by minimisation of a determinant, which for a VECM without deterministic components
is the product of the previously deﬁned eigenvalues λ1, . . . , λm. For a test of H0 : rk(Π) =
r0 against H1 : r0 < rk(Π) ≤r1 with pre-speciﬁed integers r0 < r1, the likelihood-ratio
test statistic becomes
λLR(r0, r1) := −(T −k)
r1
X
i=r0+1
log(1 −λi).
In situations with more complex VECM representations, e.g. with linear trends, the test
statistic remains the same but with eigenvalues of a correspondingly generalised matrix
given in L¨utkepohl (2007). Two particular choices for r1 w.r.t. r0 are of main interest:
with r1 = m, the null value r0 is tested against any other possible rank exceeding r0,
called the trace test, and with r1 = r0 + 1, one obtains the maximum eigenvalue test in
which the null value is only tested against the next higher value. Tabulated percentage
points for the asymptotic non-standard distributions are given by Johansen (1995), for
instance. The strategy for rank determination, often explicitly referred to as the Jo-
hansen procedure, is to start with r0 = 0 and to test it against higher alternatives. The
cointegration rank of r0 is accepted if H0 cannot be rejected, otherwise the test is carried
forward to r0 = 1. The proposal is increased until the test cannot be rejected for the
ﬁrst time, and the according value for r0 determines r. If the resulting cointegration
rank turns out to be either 0 or m, one concludes that a VAR model in ﬁrst diﬀerences
or a stationary VAR model for the original variables is appropriate, respectively. The
strategy allows for both the trace or maximum eigenvalue tests, and power analyses show
that none of these tests is generally preferable over the other. It is noteworthy that,
164

C Vector Error Correction Models
despite the fact that the Johansen procedure is still the most common practice in fre-
quentist analysis, some authors have criticised inconsistency problems in the estimation
of r and proposed alternatives, see, e.g., Chao and Phillips (1999).
C.5 Bayesian Estimation and Forecasting
Following the arguments in Appendix A, Bayesian estimation of VAR(k) models in gen-
eral and, in particular, in VECM representation has evolved an interesting alternative
to least-squares and ML approaches as described above. As before, for parameter esti-
mation, the lag order k is generally assumed known or determined in advance. In a fully
Bayesian framework, this may be done as outlined by Villani (2001). However, whereas
pioneering work in the Bayesian estimation of VECM also requires a ﬁxed value for the
cointegration rank, as it is the case in all frequentist techniques, modern approaches
incorporate the determination of r in the general parameter estimation. Their outcomes
can be regarded highly advantageous since incoherence in this step is diminished. A
short overview on diﬀerent Bayesian estimation procedures is given in the remainder of
this section.
Starting with a general VAR(k) model as in (C.1) but without deterministic compo-
nents, Bayesian estimation of A1, . . . , Ak is often done via a multivariate normal prior
for the stacked vector vec(A1, . . . , Ak) of all columns of all individual AR parameter
matrices with pre-determined mean µA ∈Rkm2 and covariance matrix VA ∈Rkm2×km2.
The likelihood is chosen based on Gaussian error terms with zero mean and covariance
matrix Ωthat is assumed known for the moment. L¨utkepohl (2007) derives the pos-
terior distribution for vec(A1, . . . , Ak), which is again multivariate normal. The exact
form of the posterior depends on the choice of the hyperparameters µA and VA. Most
commonly, the mean value µA is set to zero to reﬂect weak belief that AR correlation
is signiﬁcant. The covariance matrix VA is typically chosen to be a diagonal matrix in
order to reﬂect prior independence between all entries within and between the matrices
A1, . . . , Ak. Using a suitable version for stable processes of the so-called Minnesota or
Litterman prior by Doan et al. (1984) and Litterman (1986), the diagonal elements of
165

C Vector Error Correction Models
VA are given by
vijl =









λ
l
2
,
i = j
λθσi
lσj
2
,
i ̸= j
for i, j = 1, . . . , m and l = 1, . . . , k, where vijl is the diagonal element in VA referring
to the entry (i, j) in Al. The hyperparameters become the prior standard deviation
λ > 0 for all diagonal entries in A1 and a tuning parameter θ ∈(0, 1). The entries
σi, i = 1, . . . , m, represent the square roots of the diagonal elements of Ω, still assumed
to be known for the moment. The hyperparameter λ determines the general uncertainty
in the parameters in vec(A1, . . . , Ak) and the tuning parameter θ represents the reduc-
tion of uncertainty for the oﬀ-diagonal elements, as they are believed to be closer to 0.
Also, the variance and covariance terms for the entries in A1, . . . , Ak decrease with in-
creasing lags, because AR terms for higher orders are believed to be less signiﬁcant than
for smaller orders. The ratio σ2
i /σ2
j is a normalisation factor to take into account the
diﬀerences in residual variability. As a ﬁnal note, for the Bayesian estimation in a proper
VAR(k) model, the error variance Ωis generally not known and, in strict Bayesian philos-
ophy, priors for its elements must be included in the analysis. However, since this would
highly complicate the computation of the posterior distribution for all variables, usually
an empirical Bayes approach is entertained in which Ωis replaced by its least-squared
or ML estimator. Also, priors may be adjusted to allow for deterministic trends in (C.1).
The Bayesian methodology becomes far more complicated with regards to models in
VECM form. Not only is the cointegration rank to be additionally estimated, but also
the determination of Π = αβ′ reveals a non-linear estimation task with possible iden-
tiﬁcation problems. Due to these restrictions, L¨utkepohl (2007) points out that many
modellers circumnavigate these challenges by setting up the model in VAR(k) form and
estimating its parameters via the, e.g., original Minnesota prior as described by Doan
et al. (1984) and Litterman (1986), thereby ignoring the fact that the individual time
series may be cointegrated. In contrast to the previously discussed modiﬁcation of the
Minnesota prior, the original version for possibly integrated multivariate AR processes
is still multivariate normal with zero mean for almost all parameters, except for the
means of the diagonal elements for the ﬁrst lag coeﬃcient matrix. These are set equal
166

C Vector Error Correction Models
to one to express the prior belief of having m individually integrated time series, i.e. m
independent random walks. The variance for the normal prior is still chosen as outlined
above and allows for uncertainty about the simple assumption of independent random
walks. Alternatives to the Minnesota prior are found in the literature of the early 1990s,
for example see DeJong (1992), who applies a non-informative prior for A1, . . . , Ak in
the VAR(k) representation. Since these models, however, do not include the concept of
cointegration and bear the risk of undesired changes in the prior when transforming the
VAR(k) model into the VECM representation for cointegration analysis, the speciﬁca-
tion of priors for VAR(k) models has become less important in favour of more elaborate
techniques, which are reviewed in the excellent survey paper by Koop et al. (2006).
With the pioneering work on Bayesian cointegration during the mid-1990s, mainly by
Bauwens and Lubrano (1993), Geweke (1996), and Kleibergen and van Dijk (1994), fo-
cus in estimation of model parameters has been shifted to the VECM representation
directly. These approaches have in common that a cointegration rank r is determined
and ﬁxed a priori such that the dimension of α and β is known. For suitable informative
priors, the full conditionals for these and all the other parameters can be derived, and
hence the posterior can be eﬃciently approximated through Gibbs sampling. The most
prominent example is the work by Geweke (1996), who considers the linear normali-
sation β = (Ir, β′
l)′ and chooses normal priors for α, βl, φ, Γ1, . . . , Γk−1 and an Inverse
Wishart prior for Ω. The uncertainty about the cointegration rank can be incorporated
into the estimation procedure by carrying out the analysis for every possible value of
r and applying Bayesian model selection techniques to the results. However, problems
with these approaches exist. Koop et al. (2006) point out that, while the behaviour of
standard priors are well-understood in linear estimation, the reduced rank restriction
introduces a non-linear estimation problem of Π = αβ′, for which the posterior proper-
ties of standard priors are not known. Furthermore, the exact form of α depends on the
normalisation of β, which makes a suitable prior choice rather diﬃcult. Strachan and
Dijk (2004) give an example of inconsistency for the linear normalisation with a diﬀuse
prior for βl, whose posterior in turn states that such a parametrisation, although spec-
iﬁed as such due to prior beliefs, is unlikely. Kleibergen and van Dijk (1994) also ﬁnd
local non-identiﬁcation problems for certain values of α, leading to improper posteriors
for βl when its prior is improper. Therefore, posterior moments need not exist and the
Gibbs sampler may not converge.
167

C Vector Error Correction Models
Due to these shortcomings with early approaches in direct Bayesian cointegration analy-
sis, these models – although intuitive and convenient – have not become particularly pop-
ular. The late 1990s and the years thereafter have seen much further work on Bayesian
estimation within the VECM framework, most notably the concept of estimating the
so-called cointegration space spanned by the columns of β. Other modern approaches
include the use of Jeﬀreys’ prior, named after Jeﬀreys (1998) and ﬁrst discussed by
Kleibergen and van Dijk (1994), and the embedding model, also introduced by Kleiber-
gen and van Dijk (1994), which nests the VECM as a special case. The general idea and
many of the extensions in later years by several authors, as well as problems with these
approaches, are reviewed by Koop et al. (2006) and will not be further discussed here.
The line of research with the cointegration space, referred to as the Grassman approach,
is applied in this work and presented in detail. The following summary is adopted from
Koop et al. (2006) and Villani (2005).
The Grassman approach goes back to the seminal work by Villani (2000) and was further
developed by Villani (2005), Strachan (2003), Strachan and Inder (2004), and Strachan
and Dijk (2004). The principal idea is to avoid problems arising from the lack of global
identiﬁcation in the product of Π = αβ′ through direct estimation of the cointegration
space for β ∈Rm×r with full column rank, i.e. sp(β) := {αβ′ : α ∈Rm×r, rk(α) = r}, the
only uniquely estimable quantity given the data. In Bayesian methodology, it follows
that the analyst has to specify a prior for all possible outcomes of this quantity of inter-
est rather than for the individual parameters α and β. A diﬀuse prior then distributes
all probability mass uniformly over the support of the cointegration space. The appeal
of this approach becomes apparent from a result shown by Strachan and Inder (2004)
that such a desired non-informative prior belief would not yield a non-informative but
an undesired informative prior for βl in the linear normalisation.
For illustration purposes of the Grassman approach, consider the simple example of
m = 2 and r = 1, i.e. there are two individually non-stationary processes which share a
stationary cointegration relationship. Then β is a 2×1 vector, which can be depicted as
an arrow starting at the origin in a two-dimensional coordinate system. The cointegra-
tion space for one true vector β is the inﬁnite line through the origin containing the arrow
corresponding to β. A prior must distribute the probability mass over the support of all
lines through the origin in this coordinate system. In this simple example, this is easily
168

C Vector Error Correction Models
doable by introducing polar coordinates through β = (cos θ, sin θ)′ with θ ∈[−π/2, π/2).
Implicitly, the length of β is w.l.o.g. constrained to unity. A non-informative prior for
the support of the cointegration space is hence equivalent to a uniform prior for θ over
its support. A more complex example is the case for m = 3 and r = 2, in which the
cointegration space is a two-dimensional plane in a three-dimensional coordinate system,
spanned by two linearly independent cointegration vectors given by the columns of the
3 × 2 matrix β, and the support are all such planes through the origin. Generally, the
cointegration space is an r-dimensional hyperplane in the m-dimensional space. Due to
the restriction of linear independence between diﬀerent cointegration vectors, priors in
such higher dimensions cannot be simply expressed by distributions over marginal angles
for the individual vectors. However, there exist unique distributions over the so-called
Grassman manifolds, which are equivalent to any chosen prior over the support of the
cointegration space. The Grassman manifold Gm,r is the set of all r-dimensional hyper-
planes in the m-dimensional space. Obviously, the cointegration space sp(β) must be an
element of Gm,r. A non-informative distribution over the support for all cointegration
spaces is naturally given by a uniform distribution over Gm,r. For practical purposes,
these abstract distributions can be again transformed to more convenient representa-
tions, e.g. for βl, if the normal linearisation is chosen. Villani (2000, 2005) shows that
a diﬀuse prior on the cointegration space equals a Matrix-t distribution on βl in this
parametrisation. Strachan and Dijk (2004) and Strachan and Inder (2004) discuss pos-
sible disadvantages of the linear normalisation and propose alternative and more general
approaches, which work directly with the Grassman manifolds without identiﬁcation re-
strictions on β, but the generally convenient discussion of the linear normalisation as in
Villani (2005) is considered suﬃcient for this work. For more information on the general
estimation procedure w.r.t. Grassman manifolds and, for example, informative priors on
the cointegration space, the interested reader is referred to the above cited literature and
to, e.g., James (1954) for a general review on this well-understood ﬁeld of mathematics.
Note that, so far, the Grassman approach has only been concerned with the estimation
of β through more abstract quantities. Villani (2005) uses a joint prior for the cointegra-
tion space and all remaining parameters. In particular, the priors for φ, Γ1, . . . , Γk−1 turn
out to be non-informative in his work. Motivated by the Bayesian analysis of VAR(k)
processes, Warne (2006) extends this approach to apply a Minnesota-like prior with
Γ1, . . . , Γk−1. The priors for the cointegration space are further speciﬁed in terms of βl
169

C Vector Error Correction Models
under the linear normalisation. As a result, in both studies, an eﬃcient Gibbs sampling
algorithm becomes available. Note that when the order of the individual time series is
chosen such that the last m −r series are not cointegrated solely among themselves,
then the analysis based on this prior is invariant to the normalisation. The exact form
of the priors and the resulting posterior distributions are presented in Section 3.3. An-
other main advantage of the approach by Villani (2005) is the possibility of computing
a consistent posterior distribution for the cointegration rank r. Consequently, only the
lag order k must be speciﬁed a priori, whereas the inconsistency of a pre-speciﬁed value
for r, as seen in many other Bayesian and frequentist approaches, can be eliminated.
Alternatively, if the inconsistency between lag order determination and parameter es-
timation becomes problematic, joint posterior distributions for both k and r can be
derived through the extension by Warne (2006).
As a ﬁnal note, Bayesian predictions of the time series are obtained through simulation
of the VECM parameters from their posterior distribution, which is obtained via Gibbs
sampling. For each set of realised parameters, the h-step forecast is simulated using
the normality of the white noise in the VECM formulation. The necessary initial values
xT−k+1, . . . , xT can be their observed values for simplicity or, to be more accurate, draws
from their posterior predictive distribution.
C.6 Goodness-of-Fit Diagnostics
This section provides a short overview on tools for diagnostics to assess how the model
ﬁts the data. Quantitative and qualitative goodness-of-ﬁt checks constitute an impor-
tant step in any statistical analysis. Model diagnostics in the VECM adopt many tools
for VAR models, which are multivariate extensions of well-known diagnostics in the
univariate case. Most importantly, residuals should be checked for remaining autocor-
relation, unexplained by the model, and non-normality when assuming Gaussian white
noise. Residual checks for whiteness are of less concern when the model’s main objective
is forecasting, and when predictions perform reasonably well. The following review on
main techniques is again based on L¨utkepohl (2007), who assumes parameter estima-
tion to be done via the frequentist approaches outlined in Appendix C.4. In Bayesian
frameworks, the tests are applied with techniques from Appendix A.4.
170

C Vector Error Correction Models
The estimated residuals for the VECM in (C.4) are deﬁned as
bεt := ∆xt −bφDt −bαbβ′xt−1 −
k−1
X
i=1
bΓi∆xt−i
for all t = k+1, . . . , T, where bα and bβ are the unrestricted least-squares or ML estimators
for the general case of k lags, along with the corresponding frequentist estimators for all
other parameters. The residual autocovariances for any lag h ∈{0, 1, . . . , T −k −1} are
computed as
bCh :=
1
T −k
T
X
t=k+1+h
bεtbε′
t−h.
The residual autocorrelations are then given by bRh = bD−1 bCh bD−1 for h = 0, 1, . . . , T −
k −1, where bD is a diagonal matrix with its entries being the square roots of the diago-
nal elements of bC0. L¨utkepohl (2007) derives asymptotic normality for both the residual
autocovariance and autocorrelation terms under minimum conditions. Plots of the es-
timated autocorrelation and cross-correlation versus the lag indices for each marginal
time series, along with empirical conﬁdence bounds, give a rough check of signiﬁcance in
the residual autocorrelation. Estimates, which exceed approximate bounds for, say, 95%
conﬁdence intervals, indicate a lack of ﬁt and give insight in how to adjust the model.
More quantitative checks are available through formal hypothesis tests known from stan-
dard time series analysis. Br¨uggemann (2004) shows that the well-known Portmanteau
test in the VECM framework has the statistic
Qh := (T −k)
h
X
i=1
tr

bC′
i bC−1
0
bCi bC−1
0

with some pre-speciﬁed h ∈{1, . . . , T −k −1} to test H0 : R1 = · · · = Rh = 0 against
H1 : Ri ̸= 0 for some i. Here, tr (M) denotes the trace of a quadratic matrix M, i.e. the
sum over all diagonal elements. Under H0, for suﬃciently large h, the statistic has an
asymptotic χ2 distribution with hm2 −m2(k −1)−mr degrees of freedom. The limiting
distribution for the Portmanteau test is obtained when both the sample size and h go to
inﬁnity. This test is hence not suitable to test the signiﬁcance of residual autocorrelation
of low order. Modiﬁed versions of the test statistic exist to account for this shortcoming.
171

C Vector Error Correction Models
The Lagrange Multiplier or Breusch-Godfrey test due to Breusch (1978) and Godfrey
(1978) is an alternative procedure to test for residual autocorrelation of a pre-speciﬁed,
preferably small lag order h. Here it is assumed that the error terms follow a VAR(h)
model, i.e.
εt = Λ1εt−1 + · · · + Λhεt−h + δt
with white noise δt. The null hypothesis of no residual autocorrelation corresponds to
H0 : Λ1 = · · · = Λh = 0 versus H1 : Λi ̸= 0 for some i. The Lagrange Multiplier test
statistic is then derived as the statistic for a score test on the auxiliary regression model
bεt = bφDt + bαbβ′xt−1 +
k−1
X
i=1
bΓi∆xt−i + Λ1bεt−1 + · · · + Λhbεt−h + δt
for t = k + 1, . . . , T, where bεt = 0 for t ≤k, which L¨utkepohl (2007) shows to be
λLM := (T −k)bc′
hbΩc(h)−1bch,
where bch := vec( bC1, . . . , bCh) and bΩc(h) := 1/(T −k)

bE bE′ −bEX′ (XX′)−1 X bE′
⊗
bΩ, with bΩas before, and the following quantities by analogy to the compact matrix
formulation from Appendix C.4 for the VECM representation,
Xt =
 1, x′
t, . . . , x′
t−k+1
′ ,
t = k, . . . , T −1,
X = (Xk, . . . , XT−1) ,
Fi = (0T−k×i, IT−k)′ (IT−k, 0T−k×i) ,
i = 1, . . . , h,
F = (F1, . . . , Fh) ,
bε = (bεk+1, . . . , bεT) ,
bE = (Ih ⊗bε) F ′.
Under the same minimum conditions as for the Portmanteau test, the asymptotic dis-
tribution for λLM is χ2(hm2).
Particular interest in goodness-of-ﬁt is devoted to the normality of the residuals if a
Gaussian distribution was assumed for the error terms. Rejection of normality indicates
172

C Vector Error Correction Models
misspeciﬁcation of the likelihood and, hence, of all statistical inference for the model.
A common way to test the residuals for normality is to check whether their skewness
and kurtosis, i.e. the third and fourth moments, equal the theoretical values of zero and
three, respectively. Such a test, the Lomnicki-Jarque-Bera test due to Jarque and Bera
(1987) and Lomnicki (1961), is available for the univariate case and can be extended to
the multivariate case of VAR models, including the VECM speciﬁcation. For iid error
terms εt ∼Nm(0, Ω), one obtains wt = (w1t, . . . , wmt)′ := P −1εt ∼Nm(0, Im), where P
is a matrix fulﬁlling PP ′ = Ω, and hence E(w3
it) = 0 and E(w4
it) = 3 for all i = 1, . . . , m.
Substituting the error terms by the estimated residuals, the test statistics for the null
hypotheses of E( bw3
it) = 0 and E( bw4
it) = 3 are asymptotically χ2(m)-distributed pivotal
quantities of the vectors of empirical third and fourth moments for these standardised
residual terms, see L¨utkepohl (2007) for exact deﬁnitions. Rejection of either of the null
hypotheses indicates problems with the normality assumption, where, for small sample
sizes, the test should be understood as a rough check only. Further tests in assessment
of the ﬁt of a VECM are derived for checks of structural changes within the time series
over time, since the statistical inference and forecasts rely on the time invariance of
parameters. The interested reader is referred to L¨utkepohl (2007) for more information.
173

D Further Mathematical and
Probabilistic Preliminaries
D.1 The Generalised Gamma Function
The following deﬁnition introduces a generalisation of the Gamma function as used in
the normalising constant of the Grassman prior in (3.10). For simplicity, the function’s
support is restricted to the case of natural numbers. More information on generalised
Gamma functions can be found in, e.g., James (1964).
Deﬁnition D.1 (Generalised Gamma Function). Let b ∈N0. Then the Generalised
Gamma function Γb is deﬁned for all a ∈N0 with a ≥b through Γb (a) := 1 if b = 0, and
Γb (a) :=
bY
i=1
Γ
a −i + 1
2

if b > 0, where Γ (·) is the (positive real) Gamma function given by
Γ (t) =
Z ∞
0
xt−1 exp(−x) dx,
t > 0.
In particular, since (a −i + 1)/2 is a multiple of 1/2 for all a, b ∈N and i ∈{1, . . . , b},
it follows from the basic properties of the standard Gamma function that
Γ
a −i + 1
2

=









a −i −1
2

!,
a −i
2
/∈N
(a −i)!
2a−i   a−i
2

!
√π,
a −i
2
∈N
.
174

D Further Mathematical and Probabilistic Preliminaries
D.2 Deﬁnitions in Matrix Algebra
In probabilistic matrix algebra, it is convenient to transform matrices into vectors in
order to make use of well-known multivariate distributions instead of rather uncommon
matrix-valued distributions.
Deﬁnition D.2 (Vectorisation Operator). Let M = (m1 · · · mb) ∈Ra×b be a matrix with
b columns m1, . . . , mb ∈Ra. The vectorisation (or vector or column stacking) operator
vec: Ra×b →Rab transforms the matrix M into the vector vec (M) := (m′
1, . . . , m′
b)′
of length ab by stacking together all columns from left to right. The vector vec (M) is
usually referred to as the vectorised or vectorisation of M.
When random matrices are transformed into random vectors, corresponding covariance
matrices must be changed accordingly. The following notation is useful.
Deﬁnition D.3 (Matrix Kronecker Product). For matrices M1 ∈Ra1×b1, with elements
mij for i = 1, . . . , a1 and j = 1, . . . , b1, and M2 ∈Ra2×b2, deﬁne their Matrix Kronecker
product as
M1 ⊗M2 :=






m11M2
m12M2
· · ·
m1b1M2
m21M2
m22M2
· · ·
m2b1M2
...
...
...
...
ma11M2
ma12M2
· · ·
ma1b1M2






∈Ra1a2×b1b2.
Then ⊗is called the Matrix Kronecker product operator.
For more information, see, e.g., Neudecker (1968).
D.3 Matrix-Valued Distributions
When dealing with multivariate problems in Bayesian applications, it becomes necessary
to simulate from matrix-valued distributions for the covariance matrices. The following
distributions are generalisations of the Normal, t and χ2 distributions.
A generalisation of the normal distribution for matrix-valued random variables is the
Matrix-Normal distribution.
175

D Further Mathematical and Probabilistic Preliminaries
Deﬁnition D.4 (Matrix-Normal Distribution). A random matrix X ∈Ra×b is Matrix-
Normal distributed with parameter matrices M ∈Ra×b, U ∈Ra×a, V ∈Rb×b, the latter
two being positive deﬁnite, denoted by X ∼MNa×b(M, U, V ), if X has the density
f (X) =
1
(2π)ab/2 |V |a/2 |U|b/2 exp

−1
2 tr

V −1(X −M)′U −1(X −M)

.
Note that with the vector operator and Matrix Kronecker product from Deﬁnitions D.2
and D.3, X ∼MNa×b(M, U, V ) is equivalent to vec(X) ∼Nab(vec(M), V ⊗U), i.e. the
vectorised X can be conveniently expresses through a multivariate vector-valued nor-
mal distribution. For more information on the Matrix-Normal distribution, see Dawid
(1981), for instance.
In analogy to univariate and multivariate normal distributions, a shift to t-distributions
is required when variance components are not known but sampled. In matrix-valued
probability theory, this analogue is the Matrix-t distribution.
Deﬁnition D.5 (Matrix-t Distribution). A random matrix X ∈Ra×b is Matrix-t dis-
tributed with parameters µ ∈Ra×b, P ∈Ra×a, Q ∈Rb×b, the latter two being positive
deﬁnite, and n ≥0, denoted by X ∼Mta×b(µ, P, Q, n), if X has the density
f (X) = Γb (n + a + b −1) |P|b/2
Γb (n + b −1) πab/2 |Q|a/2
Ib + Q−1 (X −µ)′ P (X −µ)
−(n+a+b−1)/2 .
More information on the Matrix-t distribution can be found in Box and Tiao (2011), for
instance.
The Wishart distribution, named after Wishart (1928), generalises the χ2 distribution to
matrix-valued random variables. It has become popular, since in Bayesian methodology,
it is a conjugate prior for the precision, i.e. the inverse of the covariance matrix, given a
multivariate normal distributed random vector. In this case, the covariance matrix itself
is said to be Inverse Wishart distributed.
Deﬁnition D.6 (Wishart Distribution). A positive deﬁnite random matrix X ∈Ra×a
is Wishart distributed with positive deﬁnite scale matrix V ∈Ra×a and n ≥a degrees of
176

D Further Mathematical and Probabilistic Preliminaries
freedom, denoted by X ∼Wa(V, n), if X has the density
f (X) =
|X|(n−a−1)/2
2na/2πa(a−1)/4Γa (n) |V |n/2 exp

−1
2 tr
 V −1X

.
The Wishart distribution is motivated as distribution for the precision, because for iid
yi ∼Na(0, V ), i = 1, . . . , n, it follows that the scatter matrix X = (y1 · · · yn)(y1 · · · yn)′ ∈
Ra×a is Wishart distributed with parameters V and n.
Deﬁnition D.7 (Inverse Wishart Distribution). A positive deﬁnite random matrix X ∈
Ra×a is Inverse Wishart distributed with positive deﬁnite scale matrix S ∈Ra×a and
degrees of freedom n ≥a, denoted by IWa (S, n), if X has the density
f (X) =
|S|n/2
2na/2πa(a−1)/4Γa (n) |X|−(n+a+1)/2 exp

−1
2 tr
 A−1X

.
The mean of X is E(X) = S/(n −a −1) if n > a + 1. If X ∼Wa(V, n), then X−1 ∼
IWa(V −1, n). See Zellner (1971) for more properties such as variance formulae.
177

E Numerical Details on the Markov
Chain Monte Carlo Algorithm
E.1 Computation of the Acceptance Probability
In the Metropolis-Hastings step for updates of κt, the acceptance probability
a

κ(i−1)
t
, κ∗
t

= min


1,
f

κ∗
t | D, E, H(i), K(i−1/i)
−t
, k, r

f

κ(i−1)
t
| D, E, H(i), K(i−1/i)
−t
, k, r



.
must be computed in each iteration step i, where κ∗
t denotes the proposal value. Here,
H(i) =

φ(i), α(i), β(i), Γ(i), Ω(i)	
denotes the set of hyperparameters, which have been
already updated at step i via the Gibbs sampler. The expression
K(i−1/i)
−t
=
n
κ(i)
1 , . . . , κ(i)
t−1, κ(i−1)
t+1 , . . . , κ(i−1)
T
o
comprises the latest updated realisations of all other parameters. In Section 3.3.3, it
was derived that the posterior density for some κt is of the form
f (κt | D, E, H, K−t, k, r) ∝exp (Lt + Pt)
with the likelihood-driven component
Lt =
X
x
X
p
[Dxpt log (log (1 + exp(ηxpt))) −Expt log (1 + exp(ηxpt))]
178

E Numerical Details on the Markov Chain Monte Carlo Algorithm
and prior-driven component
Pt =























−1
2
 k+t
X
s=k+1
ε′
sΩ−1εs + (κt −µt)′ Σ−1
t
(κt −µt)
!
,
t ≤k
−1
2
k+t
X
s=t
ε′
sΩ−1εs,
k < t ≤T −k
−1
2
T
X
s=t
ε′
sΩ−1εs,
t > T −k
.
The proportionality factors can be neglected in the evaluation of the acceptance proba-
bility as they cancel out. The following sections provide formulae for the numerical eval-
uation of the acceptance probability both under standard as well as single-component
Metropolis-Hastings algorithms.
E.2 General Formulae
Let η(i−1)
xpt
and η∗
xpt denote the linear predictor from the right-hand side of equation (3.2)
when plugging in κ(i−1)
t
and κ∗
t, respectively. Furthermore, for s = k + 1, . . . , k + t if
t ≤k, and for s = t, . . . , min{k + t, T} if t > k, deﬁne
ε(i−1/i)
s
= κ(i−1)
s
−φ(i) −
 Im + α(i)β(i)′
κ(i−1/i)
s−1
−
k−1
X
j=1
Γ(i)
j ∆κ(i−1/i)
s−j
where
κ(i−1/i)
s−1
=



κ(i)
t−1,
s = t
κ(i−1)
s−1 ,
s > t
,
∆κ(i−1/i)
s−j
=









κ(i)
s−j −κ(i)
s−j−1,
s −j < t
κ(i−1)
t
−κ(i)
t−1,
s −j = t
κ(i−1)
s−j −κ(i−1)
s−j−1,
s −j > t
.
179

E Numerical Details on the Markov Chain Monte Carlo Algorithm
Replacing κ(i−1)
t
by κ∗
t leads to the residuals
ε∗
k+1 = ε(i−1/i)
k+1
+ Γ(i)
k−1

κ∗
1 −κ(i−1)
1

if t = 1,
ε∗
s = ε(i−1/i)
s
−

Γ(i)
s−t −Γ(i)
s−t−1
 
κ∗
t −κ(i−1)
t

,
s = k + 1, . . . , k + t −1,
ε∗
k+t = ε(i−1/i)
k+t
+ Γ(i)
k−1

κ∗
t −κ(i−1)
t

if t = 2, . . . , k −1,
ε∗
k+1 = ε(i−1/i)
k+1
−

Im + α(i)β(i)′ + Γ(i)
1
 
κ∗
k −κ(i−1)
k

,
ε∗
s = ε(i−1/i)
s
−

Γ(i)
s−k −Γ(i)
s−k−1
 
κ∗
k −κ(i−1)
k

,
s = k + 2, . . . , 2k −1,
ε∗
2k = ε(i−1/i)
2k
+ Γ(i)
k−1

κ∗
k −κ(i−1)
k

if t = k,
ε∗
t = ε(i−1/i)
t
+ κ∗
t −κ(i−1)
t
,
ε∗
t+1 = ε(i−1/i)
t+1
−

Im + α(i)β(i)′ + Γ(i)
1
 
κ∗
t −κ(i−1)
t

,
ε∗
s = ε(i−1/i)
s
−

Γ(i)
s−t −Γ(i)
s−t−1
 
κ∗
t −κ(i−1)
t

,
s = t + 2, . . . , k + t −1,
ε∗
k+t = ε(i−1/i)
k+t
+ Γ(i)
k−1

κ∗
t −κ(i−1)
t

if t = k + 1, . . . , T −k,
ε∗
t = ε(i−1/i)
t
+ κ∗
t −κ(i−1)
t
,
ε∗
t+1 = ε(i−1/i)
t+1
−

Im + α(i)β(i)′ + Γ(i)
1
 
κ∗
t −κ(i−1)
t

,
ε∗
s = ε(i−1/i)
s
−

Γ(i)
s−t −Γ(i)
s−t−1
 
κ∗
t −κ(i−1)
t

,
s = t + 2, . . . , T,
if t = T −k + 1, . . . , T −2,
ε∗
T−1 = ε(i−1/i)
T−1
+ κ∗
T−1 −κ(i−1)
T−1 ,
ε∗
T = ε(i−1/i)
T
−

Im + α(i)β(i)′ + Γ(i)
1
 
κ∗
T−1 −κ(i−1)
T−1

180

E Numerical Details on the Markov Chain Monte Carlo Algorithm
if t = T −1, and
ε∗
T = ε(i−1/i)
T
+ κ∗
T −κ(i−1)
T
if t = T. Note that for all cases to be well-deﬁned, it is assumed that k < T/2 + 1.
Evaluation of the acceptance probability w.r.t. κ(i−1)
t
and κ∗
t gives
a

κ(i−1)
t
, κ∗
t

= min
n
1, exp

∆L(i−1/∗)
t
+ ∆P (i−1/∗)
t
o
(E.1)
with
∆L(i−1/∗)
t
=
X
x
X
p
Dxpt
h
log
 log
 1 + exp
 η∗
xpt

−log

log

1 + exp

η(i−1)
xpt
i
+
X
x
X
p
Expt
h
log

1 + exp

η(i−1)
xpt

−log
 1 + exp
 η∗
xpt
i
and
∆P (i−1/∗)
t
=























1
2
" k+t
X
s=k+1

ε(i−1)′
s
 Ω(i)−1 ε(i−1)
s
−ε∗′
s
 Ω(i)−1 ε∗
s

+ ζ(i−1/∗)
t
#
,
t ≤k
1
2
k+t
X
s=t

ε(i−1)′
s
 Ω(i)−1 ε(i−1)
s
−ε∗′
s
 Ω(i)−1 ε∗
s

,
k < t ≤T −k
1
2
T
X
s=t

ε(i−1)′
s
 Ω(i)−1 ε(i−1)
s
−ε∗′
s
 Ω(i)−1 ε∗
s

,
t > T −k
,
where
ζ(i−1/∗)
t
=

κ(i−1)
t
−µt
′
Σ−1
t

κ(i−1)
t
−µt

−(κ∗
t −µt)′ Σ−1
t
(κ∗
t −µt)
for t = 1, . . . , k, and the residuals ε∗
s are chosen for t as outlined above. Using that
a′Ma −(a + b)′ M (a + b) = −(a′Mb + b′Ma + b′Mb) = −(2a′Mb + b′Mb)
181

E Numerical Details on the Markov Chain Monte Carlo Algorithm
for a symmetric matrix M ∈Rn×n and vectors a, b ∈Rn, it can be further deduced that
∆P (i−1/∗)
1
= −

κ(i−1)
1
−µ1
′
Σ−1
1

κ∗
1 −κ(i−1)
1

−1
2

κ∗
1 −κ(i−1)
1
′
Σ−1
1

κ∗
1 −κ(i−1)
1

−ε(i−1)′
k+1

Ω(i)−1
Γ(i)
k−1

κ∗
1 −κ(i−1)
1

−1
2

κ∗
1 −κ(i−1)
1
′
Γ(i)′
k−1

Ω(i)−1
Γ(i)
k−1

κ∗
1 −κ(i−1)
1

if t = 1,
∆P (i−1/∗)
t
= −

κ(i−1)
t
−µt
′
Σ−1
t

κ∗
t −κ(i−1)
t

−1
2

κ∗
t −κ(i−1)
t
′
Σ−1
t

κ∗
t −κ(i−1)
t

+
k+t−1
X
s=k+1
ε(i−1)′
s

Ω(i)−1 
Γ(i)
s−t −Γ(i)
s−t−1
 
κ∗
t −κ(i−1)
t

−1
2
k+t−1
X
s=k+1

κ∗
t −κ(i−1)
t
′ 
Γ(i)
s−t −Γ(i)
s−t−1
′ 
Ω(i)−1 
Γ(i)
s−t −Γ(i)
s−t−1
 
κ∗
t −κ(i−1)
t

−ε(i−1)′
k+t

Ω(i)−1
Γ(i)
k−1

κ∗
t −κ(i−1)
t

−1
2

κ∗
t −κ(i−1)
t
′
Γ(i)′
k−1

Ω(i)−1
Γ(i)
k−1

κ∗
t −κ(i−1)
t

if t = 2, . . . , k −1,
∆P (i−1/∗)
k
= −

κ(i−1)
k
−µk
′
Σ−1
k

κ∗
k −κ(i−1)
k

−1
2

κ∗
k −κ(i−1)
k
′
Σ−1
k

κ∗
k −κ(i−1)
k

+ ε(i−1)′
k+1

Ω(i)−1 
Im + α(i)β(i)′ + Γ(i)
1
 
κ∗
k −κ(i−1)
k

−1
2

κ∗
k −κ(i−1)
k
′ 
Im + α(i)β(i)′ + Γ(i)
1
′ 
Ω(i)−1 
Im + α(i)β(i)′ + Γ(i)
1
 
κ∗
k −κ(i−1)
k

+
2k−1
X
s=k+2
ε(i−1)′
s

Ω(i)−1 
Γ(i)
s−k −Γ(i)
s−k−1
 
κ∗
k −κ(i−1)
k

−1
2
2k−1
X
s=k+2

κ∗
k −κ(i−1)
k
′ 
Γ(i)
s−k −Γ(i)
s−k−1
′ 
Ω(i)−1 
Γ(i)
s−k −Γ(i)
s−k−1
 
κ∗
k −κ(i−1)
k

−ε(i−1)′
2k

Ω(i)−1
Γ(i)
k−1

κ∗
k −κ(i−1)
k

−1
2

κ∗
k −κ(i−1)
k
′
Γ(i)′
k−1

Ω(i)−1
Γ(i)
k−1

κ∗
k −κ(i−1)
k

182

E Numerical Details on the Markov Chain Monte Carlo Algorithm
if t = k,
∆P (i−1/∗)
t
= −ε(i−1)′
t

Ω(i)−1 
κ∗
t −κ(i−1)
t

−1
2

κ∗
t −κ(i−1)
t
′ 
Ω(i)−1 
κ∗
t −κ(i−1)
t

+ ε(i−1)′
t+1

Ω(i)−1 
Im + α(i)β(i)′ + Γ(i)
1
 
κ∗
t −κ(i−1)
t

−1
2

κ∗
t −κ(i−1)
t
′ 
Im + α(i)β(i)′ + Γ(i)
1
′ 
Ω(i)−1 
Im + α(i)β(i)′ + Γ(i)
1
 
κ∗
t −κ(i−1)
t

+
k+t−1
X
s=t+2
ε(i−1)′
s

Ω(i)−1 
Γ(i)
s−t −Γ(i)
s−t−1
 
κ∗
t −κ(i−1)
t

−1
2
k+t−1
X
s=t+2

κ∗
t −κ(i−1)
t
′ 
Γ(i)
s−t −Γ(i)
s−t−1
′ 
Ω(i)−1 
Γ(i)
s−t −Γ(i)
s−t−1
 
κ∗
t −κ(i−1)
t

−ε(i−1)′
k+t

Ω(i)−1
Γ(i)
k−1

κ∗
t −κ(i−1)
t

−1
2

κ∗
t −κ(i−1)
t
′
Γ(i)′
k−1

Ω(i)−1
Γ(i)
k−1

κ∗
t −κ(i−1)
t

if t = k + 1, . . . , T −k,
∆P (i−1/∗)
t
= −ε(i−1)′
t

Ω(i)−1 
κ∗
t −κ(i−1)
t

−1
2

κ∗
t −κ(i−1)
t
′ 
Ω(i)−1 
κ∗
t −κ(i−1)
t

+ ε(i−1)′
t+1

Ω(i)−1 
Im + α(i)β(i)′ + Γ(i)
1
 
κ∗
t −κ(i−1)
t

−1
2

κ∗
t −κ(i−1)
t
′ 
Im + α(i)β(i)′ + Γ(i)
1
′ 
Ω(i)−1 
Im + α(i)β(i)′ + Γ(i)
1
 
κ∗
t −κ(i−1)
t

+
T
X
s=t+2
ε(i−1)′
s

Ω(i)−1 
Γ(i)
s−t −Γ(i)
s−t−1
 
κ∗
t −κ(i−1)
t

−1
2
T
X
s=t+2

κ∗
t −κ(i−1)
t
′ 
Γ(i)
s−t −Γ(i)
s−t−1
′ 
Ω(i)−1 
Γ(i)
s−t −Γ(i)
s−t−1
 
κ∗
t −κ(i−1)
t

if t = T −k + 1, . . . , T −2,
∆P (i−1/∗)
T −1
= −ε(i−1)′
T −1

Ω(i)−1 
κ∗
T −1 −κ(i−1)
T −1

−1
2

κ∗
T −1 −κ(i−1)
T −1
′ 
Ω(i)−1 
κ∗
T −1 −κ(i−1)
T −1

+ ε(i−1)′
T

Ω(i)−1 
Im + α(i)β(i)′ + Γ(i)
1
 
κ∗
T −1 −κ(i−1)
T −1

−1
2

κ∗
T −1 −κ(i−1)
T −1
′ 
Im + α(i)β(i)′ + Γ(i)
1
′ 
Ω(i)−1 
Im + α(i)β(i)′ + Γ(i)
1
 
κ∗
T −1 −κ(i−1)
T −1

183

E Numerical Details on the Markov Chain Monte Carlo Algorithm
if t = T −1, and
∆P (i−1/∗)
T
= −ε(i−1)′
T

Ω(i)−1 
κ∗
T −κ(i−1)
T

−1
2

κ∗
T −κ(i−1)
T
′ 
Ω(i)−1 
κ∗
T −κ(i−1)
T

for t = T. For numerical eﬃciency, the following terms should be computed once at the
beginning as they occur often, but do not change in the course of the Metropolis-Hastings
algorithm:
•
 Ω(i)−1 Γ(i)
k−1
• Γ(i)′
k−1
 Ω(i)−1 Γ(i)
k−1
•
 Ω(i)−1 
Γ(i)
j −Γ(i)
j−1

for j = 2, . . . , k −1
•

Γ(i)
j −Γ(i)
j−1
′  Ω(i)−1 
Γ(i)
j −Γ(i)
j−1

for j = 2, . . . , k −1
•
 Ω(i)−1 
Im + α(i)β(i)′ + Γ(i)
1

•

Im + α(i)β(i)′ + Γ(i)
1
′  Ω(i)−1 
Im + α(i)β(i)′ + Γ(i)
1

E.3 Expressions under Single-Component
Metropolis-Hastings
As a special case of the procedure in the previous section, assume that for a given cal-
endar year t ∈{1, . . . , T}, each component of κt is visited and updated individually. In
particular, at iteration step i in the Metropolis-Hastings algorithm, the random vector
κ∗
t is not simulated once from an m-dimensional normal distribution. Instead, for each
component j = 1, . . . , m, a univariate proposal value for the j-th entry of κt is simulated
from a one-dimensional normal distribution with the corresponding marginal mean and
variance parameters. Updates of the components are done individually, i.e. for each j,
the acceptance probability is computed and a realisation of a uniform random variable
is simulated. As a consequence, during each iteration i, the Metropolis-Hastings step
is now conducted mT instead of T times. However, simulation of proposal values has
become a univariate process, and acceptance rates generally increase, because more plau-
sible components will not be rejected as often as before, when other components caused
the proposed vector to be less likely. Note that with this procedure, the proposals for
184

E Numerical Details on the Markov Chain Monte Carlo Algorithm
diﬀerent components in κt become independent. For more information on the tuning
eﬀects of this algorithm, the reader is referred to Gilks (2005).
For the following discussion, assume that j ∈{1, . . . , m} is arbitrary but ﬁxed. A new
proposal for the j-th component of κt is simulated from a normal distribution with mean
being the j-th component of κ(i−1)
t
and variance being the entry (j, j) of ΣMH. Let δ
be the diﬀerence of the realised value and the mean, i.e. the current value for the j-th
component. Then in the vector notation as before, where κ(i−1)
t
is now implicitly assumed
to consist of the i-th values for components 1, . . . , j −1 and (i −1)-th components for
j, . . . , m, one can write
κ∗
t = κ(i−1)
t
+ δej,
where ej = (0, . . . , 0, 1, 0, . . . , 0)′ is the canonical vector having entry 1 at j-th position.
Hence, in the results from Section E.2, the terms κ∗
t −κ(i−1)
t
can be replaced by δej.
Noting that δ can be factored out as a scalar, the remaining multiplication of matrices
with ej from the right simply leaves their j-th columns, and one similarly gets the entry
(j, j) when multiplying with ej from both sides. Denoting by subscripts j and jj the j-th
column and the entry (j, j) of a matrix, the formulae for the prior-driven term ∆P (i−1/∗)
t
in (E.1) then simplify to
∆P (i−1/∗)
1
= −δ

κ(i−1)
1
−µ1
′  Σ−1
1

j + 1
2δ
 Σ−1
1

jj
+ε(i−1)′
k+1
 Ω(i)−1 Γ(i)
k−1

j + 1
2δ

Γ(i)′
k−1
 Ω(i)−1 Γ(i)
k−1

jj

185

E Numerical Details on the Markov Chain Monte Carlo Algorithm
if t = 1,
∆P (i−1/∗)
t
= −δ

κ(i−1)
t
−µt
′  Σ−1
t

j + 1
2δ
 Σ−1
t

jj
−
k+t−1
X
s=k+1
ε(i−1)′
s
 Ω(i)−1 
Γ(i)
s−t −Γ(i)
s−t−1

j
+ 1
2δ
k+t−1
X
s=k+1

Γ(i)
s−t −Γ(i)
s−t−1
′  Ω(i)−1 
Γ(i)
s−t −Γ(i)
s−t−1

jj
+ ε(i−1)′
k+t
 Ω(i)−1 Γ(i)
k−1

j
+1
2δ

Γ(i)′
k−1
 Ω(i)−1 Γ(i)
k−1

jj

if t = 2, . . . , k −1,
∆P (i−1/∗)
k
= −δ

κ(i−1)
k
−µk
′  Σ−1
k

j + 1
2δ
 Σ−1
k

jj
−ε(i−1)′
k+1
 Ω(i)−1 
Im + α(i)β(i)′ + Γ(i)
1

j
+ 1
2δ

Im + α(i)β(i)′ + Γ(i)
1
′  Ω(i)−1 
Im + α(i)β(i)′ + Γ(i)
1

jj
−
2k−1
X
s=k+2
ε(i−1)′
s
 Ω(i)−1 
Γ(i)
s−k −Γ(i)
s−k−1

j
+ 1
2δ
2k−1
X
s=k+2

Γ(i)
s−k −Γ(i)
s−k−1
′  Ω(i)−1 
Γ(i)
s−k −Γ(i)
s−k−1

jj
+ ε(i−1)′
2k
 Ω(i)−1 Γ(i)
k−1

j
+1
2δ

Γ(i)′
k−1
 Ω(i)−1 Γ(i)
k−1

jj

186

E Numerical Details on the Markov Chain Monte Carlo Algorithm
if t = k,
∆P (i−1/∗)
t
= −δ

ε(i−1)′
t
 Ω(i)−1
j
+ 1
2δ
 Ω(i)−1
jj
−ε(i−1)′
t+1
 Ω(i)−1 
Im + α(i)β(i)′ + Γ(i)
1

j
+ 1
2δ

Im + α(i)β(i)′ + Γ(i)
1
′  Ω(i)−1 
Im + α(i)β(i)′ + Γ(i)
1

jj
−
k+t−1
X
s=t+2
ε(i−1)′
s
 Ω(i)−1 
Γ(i)
s−t −Γ(i)
s−t−1

j
+ 1
2δ
k+t−1
X
s=t+2

Γ(i)
s−t −Γ(i)
s−t−1
′  Ω(i)−1 
Γ(i)
s−t −Γ(i)
s−t−1

jj
+ ε(i−1)′
k+t
 Ω(i)−1 Γ(i)
k−1

j
+1
2δ

Γ(i)′
k−1
 Ω(i)−1 Γ(i)
k−1

jj

if t = k + 1, . . . , T −k,
∆P (i−1/∗)
t
= −δ

ε(i−1)′
t
 Ω(i)−1
j
+ 1
2δ
 Ω(i)−1
jj
−ε(i−1)′
t+1
 Ω(i)−1 
Im + α(i)β(i)′ + Γ(i)
1

j
+ 1
2δ

Im + α(i)β(i)′ + Γ(i)
1
′  Ω(i)−1 
Im + α(i)β(i)′ + Γ(i)
1

jj
−
T
X
s=t+2
ε(i−1)′
s
 Ω(i)−1 
Γ(i)
s−t −Γ(i)
s−t−1

j
+1
2δ
T
X
s=t+2

Γ(i)
s−t −Γ(i)
s−t−1
′  Ω(i)−1 
Γ(i)
s−t −Γ(i)
s−t−1

jj
#
187

E Numerical Details on the Markov Chain Monte Carlo Algorithm
if t = T −k + 1, . . . , T −2,
∆P (i−1/∗)
T−1
= −δ

ε(i−1)′
T−1
 Ω(i)−1
j
+ 1
2δ
 Ω(i)−1
jj
−ε(i−1)′
T
 Ω(i)−1 
Im + α(i)β(i)′ + Γ(i)
1

j
+1
2δ

Im + α(i)β(i)′ + Γ(i)
1
′  Ω(i)−1 
Im + α(i)β(i)′ + Γ(i)
1

jj
#
if t = T −1, and
∆P (i−1/∗)
T
= −δ

ε(i−1)′
T
 Ω(i)−1
j
+ 1
2δ
 Ω(i)−1
jj

if t = T.
Further note that for such j ∈{1, . . . , m}, which correspond to global parameters that
are not speciﬁc for a certain population p, the likelihood-driven term is conveniently
computed for the average population p∗only. This minimises the computational eﬀort
in the computation of the acceptance probability without any loss of information.
188

F The R Package bmpmp
This appendix introduces the R package bmpmp for ﬂexible and eﬃcient estimation and
creation of output of the BMPMP model.
The package is speciﬁcally designed for
joint forecasts of diﬀerent countries with distinction of both genders. It consists of the
following ﬁve main functions, which will be described in more detail in the respective
sections F.1 to F.5.
• create.data reads country-speciﬁc observed numbers of deaths Dxgt and exposure-
to-risk Exgt for both genders as provided by the Human Mortality Database (2014)
and creates one input data ﬁle for the estimation procedure of the BMPMP model.
• bmpmp.estimation runs the MCMC algorithm for the BMPMP model using the
input data ﬁle created by create.data and the modeller’s choices for the prior
distributions.
• bmpmp.estimation.continue continues the MCMC algorithm for the BMPMP
model with the same input data and prior distributions, when output has already
been created by bmpmp.estimation (or bmpmp.estimation.continue).
• bmpmp.plots constructs posterior distribution, convergence, validation, and fore-
cast plots for the output from bmpmp.estimation
• ml.estimation.plots estimates the CBD model and VECM equations in the
BMPMP model via ML (if not over-parametrised), using input data ﬁles created
by create.data and bmpmp.estimation, and constructs forecast plots.
It is noteworthy that, although the term BMPMP model is used throughout this ap-
pendix, the R package allows all functions to be applied for the case of univariate single-
country mortality forecasts.
189

F The R Package bmpmp
F.1 The Function create.data
Description
create.data reads country-speciﬁc observed numbers of deaths Dxgt and exposure-to-
risk Exgt for both genders as provided by the Human Mortality Database (2014) and
creates one input data ﬁle for the estimation procedure of the BMPMP model.
Usage
create.data(x min = 40, x max = 100, t min = 1956, t max = 2009,
countries, name overall = "Total",
death files, exposure files,
output directory = paste(getwd(),"/output/", sep = ""))
Arguments
x min
The minimum age x0 for the model.
Must be a scalar in N0.
Default is 40.
x max
The maximum age for the model. Must be a scalar in N exceeding
x min but not exceeding the maximum possible age in the input
data. Default is 100.
t min
The minimum calendar year for the calibration period. Must be
a scalar in N chosen such that calibration period is covered by all
input data. Default is 1956.
t max
The maximum calendar year for the calibration period. Must be
a scalar in N exceeding t min and chosen such that calibration
period is covered by all input data. Default is 2009.
countries
The names (or any other identiﬁcation) of the countries which
shall be analysed. Must be a character object in case of one sin-
gle country and a vector with character entries in case of several
countries.
name overall
Character object with the name (or any other identiﬁcation) for
the reference population, i.e. the overall population consisting of
all countries under consideration. Only required if several coun-
tries are to be analysed. Default is "Total".
190

F The R Package bmpmp
death files
Character object/vector containing the location paths of the input
data ﬁle(s) in txt format for the observed numbers of deaths.
Must be of the same length as countries and match in order.
See ‘Details’ for the required input format.
exposure files
Character object/vector containing the full paths of the input data
ﬁle(s) in txt format for the exposure-to-risk. Must be of the same
length as countries and match in order. See ‘Details’ for the
required input format.
output directory Character object specifying the directory for the output data
ﬁle input data.RData.
Must end with /".
Default is
paste(getwd(),"/output/", sep = "")), i.e. a folder called
output in the current workspace. For the current workspace sim-
ply set output directory = "/".
Details
The routine extracts the required observations from the individual input data ﬁles for the
calibration window deﬁned through the parameters x min, x max, t min, t max. Data
for both genders of each country are stored, and in case of several countries, the refer-
ence population of all males in all countries is derived. Furthermore, other important
quantities, such as the dimension of the corresponding time series for the VECM, are
computed. While the routine is running, status messages are provided.
For death files and exposure files, each of the vector entries (or the object itself in
case of one country) must be a character specifying the full path of the corresponding
input data ﬁle (either full path or starting from the current workspace). The input data
ﬁles must be the 1x1 Deaths and 1x1 Exposure-to-Risk txt ﬁles provided by the Human
Mortality Database (2014), available at http://www.mortality.org under Complete
Data Series (Period data) for each country1. As an example for the observed number of
deaths in Ireland (eﬀective 24 September 2014), the input data ﬁle’s header should look
like the following.
1Note that when certain ﬁles have entries . to denote missing data, as found for Belgium for the years
1914–1918, they must be replaced by 0.00 for the routine to work.
191

F The R Package bmpmp
deaths ireland.txt
1
Ireland, Deaths 1x1
Last modified: 12-Nov-2010, MPv5 May07
2
3
Year
Age
Female
Male
Total
4
1950
0
1246.00
1676.00
2922.00
5
1950
1
101.00
142.00
243.00
6
1950
2
60.00
73.00
133.00
7
1950
3
52.00
59.00
111.00
8
1950
4
48.00
45.00
93.00
9
1950
5
39.00
30.00
69.00
10
1950
6
22.00
18.00
40.00
11
1950
7
23.00
34.00
57.00
12
1950
8
18.00
30.00
48.00
13
1950
9
11.00
17.00
28.00
14
1950
10
21.00
18.00
39.00
Value
The routine does not return but saves the output as a list in input data.RData in the
output directory as required by the function bmpmp.estimation for estimation of the
BMPMP model for the speciﬁed input data.
The function load can be used to read the list into the current workspace. It consists
of the following components.
age levels
A vector containing all ages under consideration from x min to
x max.
calendar years
A vector containing all calendar years under consideration from
t min to t max.
countries
The input object countries in case of one country or the vector
countries extended by name overall otherwise.
x min
The supplied value for x min.
x max
The supplied value for x max.
C
The number of countries including the reference population (will
equal one in case of one country).
T
The number of calendar years of the calibration window.
192

F The R Package bmpmp
M
The number of ages of the calibration window.
m
The dimension of the multivariate time series for the VECM.
D m
In case of one country: A matrix containing all observed number
of deaths for males for all ages (given by rows) and calendar years
(given by columns). In case of several countries: A list containing
all observed numbers of deaths for males for all countries (given
by list entries), ages (given by respective rows), and calendar years
(given by respective columns).
D f
In case of one country: A matrix containing all observed number of
deaths for females for all ages (given by rows) and calendar years
(given by columns). In case of several countries: A list containing
all observed numbers of deaths for females for all countries (given
by list entries), ages (given by respective rows), and calendar years
(given by respective columns).
E m
In case of one country: A matrix containing all exposure-to-risk
for males for all ages (given by rows) and calendar years (given
by columns). In case of several countries: A list containing all
exposure-to-risk for males for all countries (given by list entries),
ages (given by respective rows), and calendar years (given by re-
spective columns).
E f
In case of one country: A matrix containing all exposure-to-risk
for females for all ages (given by rows) and calendar years (given
by columns). In case of several countries: A list containing all
exposure-to-risk for females for all countries (given by list entries),
ages (given by respective rows), and calendar years (given by re-
spective columns).
logit Q m
In case of one country: A matrix containing all observed logits
for mortality rates under assumption (2.1) for males for all ages
(given by rows) and calendar years (given by columns). In case of
several countries: A list containing all observed logits of mortality
rates under assumption (2.1) for males for all countries (given by
list entries), ages (given by respective rows), and calendar years
(given by respective columns).
193

F The R Package bmpmp
logit Q f
In case of one country: A matrix containing all observed logits
for mortality rates under assumption (2.1) for females for all ages
(given by rows) and calendar years (given by columns). In case of
several countries: A list containing all observed logits of mortality
rates under assumption (2.1) for females for all countries (given by
list entries), ages (given by respective rows), and calendar years
(given by respective columns).
own col
An object (if one country) or vector (if several countries) of char-
acters deﬁning colours for graphical output.
death files
The supplied object/vector for death files.
exposure files
The supplied object/vector for exposure files.
Examples
### Example for Big Five as in Section 4.1
# Set workspace first
# Save input data from http://www.mortality.org
# under the following paths
death_files <- c("input_data\\deaths_west_germany.txt",
"input_data\\deaths_spain.txt",
"input_data\\deaths_france.txt",
"input_data\\deaths_italy.txt",
"input_data\\deaths_united_kingdom.txt")
exposure_files <- c("input_data\\exposure-to-risk_west_germany.txt",
"input_data\\exposure-to-risk_spain.txt",
"input_data\\exposure-to-risk_france.txt",
"input_data\\exposure-to-risk_italy.txt",
"input_data\\exposure-to-risk_united_kingdom.txt")
# Give corresponding names for countries and reference population
countries <- c("DE","ES","FR","IT","UK")
name_overall <- "EU"
194

F The R Package bmpmp
# Set output directory for combined dataset (folder must exist)
output_directory <- paste(getwd(),"/output/", sep = "")
# Define calibration window
x_min <- 40
x_max <- 100
t_min <- 1956
t_max <- 1995
# Run function
create.data(x_min = x_min, x_max = x_max, t_min = t_min, t_max = t_max,
countries, name_overall, death_files, exposure_files,
output_directory = paste(getwd(),"/output/", sep = ""))
### End example
F.2 The Function bmpmp.estimation
Description
bmpmp.estimation runs the MCMC algorithm for the BMPMP model using the input
data ﬁle created by create.data and the modeller’s choices for the prior distributions.
Usage
bmpmp.estimation(N = 1000000, thinning = 100, save = 2000,
output directory = paste(getwd(),"/output/", sep = ""),
cbd plots = TRUE, cbd plots directory = "cbd plots/",
titles = TRUE, tikz format = FALSE,
k = 2, r = 1, w = 1, lambda A = 1, lambda alpha = 1,
lambda b = 5, lambda l = 1, mhc = 1)
Arguments
195

F The R Package bmpmp
N
Number of iterations N for the MCMC algorithm.
Must be a
scalar in N0. Default is 1,000,000. If N is chosen to be zero, the
routine will only initialise all quantities for the MCMC algorithm.
thinning
Thinning factor for the MCMC algorithm if N > 0, i.e. every
thinning-th iteration is stored. Must be a positive divisor of N.
Default is 100.
save
Number of iterations for which intermediate results subject to
thinning should be stored if N > 0. Must be a positive divisor of
N and a multiple of thinning. Default is 2,000.
output directory Character object specifying the directory for both the input data
ﬁle input data.RData created through the routine create.data
and the output data ﬁles initial.RData, constants.RData
and, if N > 0, bmpmp.RData.
Must end with /".
Default
is paste(getwd(),"/output/", sep = "")), i.e. a folder called
output in the current workspace. For the current workspace sim-
ply set output directory = "/".
cbd plots
Logical value indicating whether starting values for the CBD
model, i.e. its ML estimates, should be plotted. Default is TRUE.
cbd plots
directory
Character object specifying the directory within the output di-
rectory given through output directory for plots of the starting
values for the CBD model if cbd plots = TRUE. Must end with
/".
Default is "cbd plots/", i.e. a folder called cbd plots in
the output directory. For the output directory itself simply set
cbd plots directory = "/".
titles
Logical value if cbd plots = TRUE, indicating whether main and
axis titles should be included in the graphical output for the start-
ing values. Default is TRUE.
tikz format
Logical value if cbd plots = TRUE, indicating whether the output
for the starting values should not be graphs stored in pdf format
as by default, but ﬁles in tikz format to allow easy inclusion of
graphs in LATEX documents. Default is FALSE.
k
Lag order k in the VAR model representation, i.e. the lag order
for the VECM is k −1. Must be a scalar in N. Default is 2.
196

F The R Package bmpmp
r
Cointegration rank r in the VECM. Must be a scalar in N0. De-
fault is 1.
w
Posterior weight w for the likelihood and prior in the Metropolis-
Hastings algorithm. Must be a scalar in (0, 1]. Default is 1, i.e.
the original Metropolis-Hastings algorithm.
lambda A
Tuning factor λA in the tuning function fA for the determination
of A. Must be a scalar exceeding 0. Default is 1. See ‘Details’ for
information on the initialisation of A.
lambda alpha
Constant λα for the prior of α.
Must be a scalar exceeding 0.
Default is 1.
lambda b
Baseline constant λb for the overall magnitude of variance in the
prior of Γ if k > 1. Must be a scalar exceeding 0. Default is 5.
lambda l
Lag constant λb for the shrinkage in variance with increasing order
in the prior of Γ if k > 2. Must be a scalar exceeding 0. Default
is 1.
mhc
Tuning constant cMH for the Metropolis-Hastings proposal vari-
ance ΣMH. Must be a scalar exceeding 0. Default is 1. See ‘Details’
for information on the initialisation of ΣMH.
Details
The routine initialises and, if N > 0, runs the Bayesian estimation algorithm for the
BMPMP model with the data supplied through input data.RData in the output direc-
tory. When there is more than one country to be analysed, the exact equation for the
CBD model applied in this function is given by
log

qxpgt
1 −qxpgt

= κ0
t + κp
t + κg
t + κpg
t + (κx
t + κxp
t + κxg
t ) (x −x0)
+

κx2
t + κx2p
t
+ κx2g
t

(x −x0)2,
x ≥x0,
with t, x, p running through the calendar years, ages, and populations (including the
reference population) speciﬁed in input data.RData, and g denoting the eﬀects for
females compared to males. The minimum age x0 coincides with x min. In case of only
one country, the above model is applied with all population-speciﬁc parameters set equal
to zero.
197

F The R Package bmpmp
For the Metropolis-Hastings algorithm within the estimation procedure, the single-
component method is applied. The starting values are the ML estimates for the CBD
parameters, A for Ω, and zero matrices or vectors for all other hyperparameters. The
matrix A is initialised through A = fA(bΩ), where fA(M) = (λ2
Am2
ij)ij for a square ma-
trix M = (mij)ij with λA as speciﬁed in lambda A, and bΩis the empirical covariance
matrix of the time series in diﬀerences. If this choice of A becomes numerically singu-
lar, its oﬀ-diagonal elements are set to zero. The constant q is automatically given by
m + 2, where m is the dimension of the time series, stored in m in input data.RData.
All other prior constants λα, λb, λl can be directly selected by the modeller through
lambda alpha, lambda b, lambda l.
The constants µt and Σt for the priors regard-
ing the ﬁrst k CBD parameters are automatically determined through an empirical
Bayes approach, i.e. µ1, . . . , µk are chosen to be the corresponding ML estimates and
Σ1 = · · · = Σk = A. The Metropolis-Hastings proposal variances are chosen to be the
diagonal elements of ΣMH = cMHA, where cMH can be determined by the user through
mhc. The function further allows for the choice of a posterior weight in w.
Since the required number of iterations N must be chosen to be large in general, suf-
ﬁciently high thinning and a low value for save must be selected to guarantee enough
data allocation space within the R workspace and to reduce the necessary storage space
for the output.
If cbd plots = TRUE, the routine will construct plots of the starting values in pdf or
tikz format, stored in the folder speciﬁed through cbd plots directory.
The function bmpmp.estimation requires the MCMCpack package if N > 0 and the
tikzDevice package if tikzformat = TRUE. While the routine is running, status mes-
sages are provided. The routine automatically sets seeds for reproducible output. Error
messages will be given for improper choices of k and r w.r.t. the latent dimension and
horizon of the time series. Note that the choice of r = 0 corresponds to a stationary
VAR(k) model for the time series in levels, where r = m corresponds to a stationary
VAR(k −1) model for the time series in diﬀerences.
Value
The routine does not return but saves the output as lists in the ﬁles initial.RData,
198

F The R Package bmpmp
constants.RData, and bmpmp.RData in the output directory as required by the function
bmpmp.plots for graphical outputs for the analysis of the BMPMP model.
The function load can be used to read any of the lists into the current workspace. The
list initial.RData consists of the following components.
data
An m × T −k matrix containing the multivariate time series in
levels (without the k initial values).
The marginal time series
(given by the rows) are ordered as follows: κ0, κg, κx, κx2, κxg, κx2g,
all κp in the order of countries, then all κpg, all κxp, and all κx2p
in the same order, respectively. In case of the analysis of one single
country, data consists of the ﬁrst six time series only.
delta x
An m × T −k −1 matrix containing the multivariate time series
given in data in diﬀerences.
Z 0
The m × T −k matrix ∆K = (∆κk+1, . . . , ∆κT) in the compact
matrix form for the VECM.
Z 1
The m × T −k matrix K1 = (κk, . . . , κT−1) in the compact matrix
form for the VECM.
Z 2
The (k−1)m×T−k matrix K2 with entries
 ∆κ′
T−1, . . . , ∆κ′
T−k+1
′
in the compact matrix form for the VECM.
Omega
The initial value for Ω.
Omega inverse
The inverse of the initial value of Ω.
Phi
The initial value for φ.
Gamma
The initial value for Γ.
alpha
The initial value for α.
beta
The initial value for β.
Psi
The initial value for βl.
The list constants.RData consists of the following components.
C
The number of countries including the reference population (will
equal one in case of one country).
T
The number of calendar years of the calibration window.
M
The number of ages of the calibration window.
199

F The R Package bmpmp
k
The lag order k in the VAR model representation, i.e. the lag order
for the VECM is k −1.
r
The cointegration rank r in the VECM.
m
The dimension of the multivariate time series for the VECM.
d
The dimension of the deterministic parameters in the VECM,
which is one by default.
D t
The matrix of time-varying coeﬃcients for the deterministic pa-
rameters in the VECM, i.e. a 1 × T matrix of ones.
D 0
The last T −k columns of D t.
lambda alpha
The constant λα.
A
The constant matrix A.
Sigma inverse
The inverse of ΩΓ.
mu
A matrix (or vector if k = 1) consisting of µ1, . . . , µk.
B inverse
The inverse of Σ = Σ1 = · · · = Σk = A.
mhc
The tuning constant cMH for the Metropolis-Hastings proposal
variance ΣMH.
w
The posterior weight w for the likelihood and prior in the
Metropolis-Hastings algorithm.
n Omega
The value nΩ= T −k + q + r + m(k −1).
c
The matrix c = (Ir, 0r×m−r)′.
c orthogonal
The matrix c⊥= (0m−r×r, Im−r)′.
H
The matrix H = Ir ⊗c⊥.
h
The vector h = vec(H).
age levels
A vector containing all ages under consideration from x min to
x max.
In case of N > 0, the list bmpmp.RData consists of the following components.
mcmc
A list, whose i-th entry is a list containing all values of the quan-
tities in initial.RData for the i-th iteration (after thinning).
200

F The R Package bmpmp
eta
A list, whose i-th entry is a list with two entries. In case of several
countries, the ﬁrst entry is a list with T−k entries, whose t-th entry
is a matrix of the linear predictors for all male populations at t-th
calendar year realised at the i-th iteration (after thinning), where
the rows indicate the countries as given in countries (with the
last row being the reference population) and the columns indicate
the ages as given in age levels. In case of a single country, the
ﬁrst entry is a list with T −k entries, whose t-th entry is a vector of
the linear predictors for the male population at t-th calendar year
realised at the i-th iteration (after thinning), where the entries
indicate the ages as given in age levels. The second entry of i-th
entry of eta is the corresponding list of all female linear predictors,
arranged in the analogous way.
N thinned
The number of iterations after thinning.
In the alternative case of N = 0, the list bmpmp.RData consists of the following compo-
nents.
mcmc
A list of one entry, which is a list containing all values of the
quantities in initial.RData.
eta
A list of one entry, which is a list with two entries. In case of several
countries, the ﬁrst entry is a list with T −k entries, whose t-th
entry is a matrix of the linear predictors for all male populations
at t-th calendar year realised for the initial values, where the rows
indicate the countries as given in countries (with the last row
being the reference population) and the columns indicate the ages
as given in age levels. In case of a single country, the ﬁrst entry
is a list with T −k entries, whose t-th entry is a vector of the linear
predictors for the male population at t-th calendar year realised
for the initial values, where the entries indicate the ages as given
in age levels. The second entry of the single entry of eta is the
corresponding list of all female linear predictors, arranged in the
analogous way.
N thinned
The number zero.
201

F The R Package bmpmp
In case of N > 0, additional output ﬁles are the intermediate results for each incre-
ment of save iterations, which are automatically contained in bmpmp.RData. Their lists
are set up as in the case of bmpmp.RData, where the entries are called mcmc thinned,
eta thinned, number thinned.
Finally, if cbd plots = TRUE, the routine saves graphical output in pdf or tikz format
as outlined under ‘Details’.
Examples
### Example for Big Five as in Section 4.1
### (Example for create.data continued)
# Required package (must be installed)
library(MCMCpack) # (will also be loaded within the function)
# Set workspace first and create input_data.RData through create.data()
# Set output directory as before
output_directory <- paste(getwd(),"/output/", sep = "")
# Set directory for CBD plots within the output directory
# (folder must exist)
cbd_plots_directory <- "cbd_plots/"
cbd_plots <- TRUE
titles <- TRUE
tikz_format <- FALSE
# Setup of model
k <- 2
r <- 5
w <- 1
lambda_A <- sqrt(10)
lambda_alpha <- 1
lambda_b <- 5
202

F The R Package bmpmp
lambda_l <- 1
# (not required)
mhc <- 10
# Setup algorithm
N <- 1000000
thinning <- 100
save <- 1000
# Run function
bmpmp.estimation(N = N, thinning = thinning, save = save,
output_directory = output_directory,
cbd_plots = cbd_plots,
cbd_plots_directory = cbd_plots_directory,
titles = titles, tikz_format = tikz_format,
k = k, r = r, w = w, lambda_A = lambda_A,
lambda_alpha = lambda_alpha,
lambda_b = lambda_b, lambda_l = lambda_l, mhc = mhc)
### End example
F.3 The Function bmpmp.estimation.continue
Description
bmpmp.estimation.continue continues the MCMC algorithm for the BMPMP model
with the same input data and prior distributions, when output of bmpmp.estimation
(or bmpmp.estimation.continue) has already been created.
Usage
bmpmp.estimation.continue(N = 2000000, thinning = 100, save = 2000,
output directory
= paste(getwd(),"/output/", sep = ""))
Arguments
203

F The R Package bmpmp
N
Number of iterations N for the entire MCMC algorithm, i.e. the
ﬁnal number of iterations including previously obtained results.
Must be a scalar in N exceeding Nprev, i.e. the number of itera-
tions before thinning used in bmpmp.estimation (or the last call
of bmpmp.estimation.continue). Default is 2,000,000.
thinning
Thinning factor for the new section of the MCMC algorithm, i.e.
every thinning-th iteration in the current part of the MCMC
algorithm is stored. Must be a positive divisor of the additional
number of iterations N −Nprev. Default is 100.
save
Number of iterations for which intermediate results subject to
thinning should be stored in the new section of the MCMC al-
gorithm. Must be a positive divisor of the additional number of
iterations N −Nprev and a multiple of thinning. Default is 2,000.
output directory Character object specifying the directory for the input data
ﬁles input data.RData, constants.RData, as well as the pre-
vious
results
in
bmpmp.RData
created
through
the
routine
bmpmp.estimation (or bmpmp.estimation.continue), and the
new output data ﬁle, which will override the existing bmpmp.RData.
Must end with /". Default is paste(getwd(),"/output/", sep
= "")), i.e. a folder called output in the current workspace. For
the current workspace simply set output directory = "/".
Details
The routine continues the Bayesian estimation algorithm for the same BMPMP model as
in the previously used bmpmp.estimation (or bmpmp.estimation.continue). In partic-
ular, the same input data and choices for the prior distributions given in the respective
ﬁles in the output directory are used. The routine carries forward the previous results as
stored in bmpmp.RData and resumes the MCMC algorithm with the realisation for the
last iteration therein. New realisations are combined with the already given iterations
such that the output comprises the entire output of the algorithm. As a special case,
bmpmp.estimation.continue starts the MCMC algorithm in case bmpmp.estimation
was used for initialisation only, i.e. with N begin zero.
The function bmpmp.estimation.continue requires the MCMCpack package. While the
204

F The R Package bmpmp
routine is running, status messages are provided. The routine automatically sets seeds
for reproducible output (even if next time bmpmp.estimation was used for all iterations
at once). Notes made in the ‘Details’ section for the function bmpmp.estimation re-
garding the parameters N, thinning, and save apply here, too.
Value
The routine does not return but saves the output as a list in bmpmp.RData, thereby
overriding the already existing ﬁle. The function load can be used to read any of the
lists into the current workspace. As for the output of bmpmp.estimation, it consists of
the following entries.
mcmc
A list, whose i-th entry is a list containing all values of the quan-
tities in initial.RData for the i-th iteration (after thinning) of
the entire MCMC algorithm.
eta
A list, whose i-th entry is a list with two entries. In case of sev-
eral countries, the ﬁrst entry is a list with T −k entries, whose
t-th entry is a matrix of the linear predictors for all male popu-
lations at t-th calendar year realised at the i-th iteration (after
thinning) of the entire MCMC algorithm, where the rows indicate
the countries as given in countries (with the last row being the
reference population) and the columns indicate the ages as given
in age levels. In case of a single country, the ﬁrst entry is a list
with T −k entries, whose t-th entry is a vector of the linear pre-
dictors for the male population at t-th calendar year realised at
the i-th iteration (after thinning) of the entire MCMC algorithm,
where the entries indicate the ages as given in age levels. The
second entry of i-th entry of eta is the corresponding list of all
female linear predictors, arranged in the analogous way.
N thinned
The number of iterations after thinning for the entire MCMC al-
gorithm.
Additional output ﬁles are the intermediate results for each increment of save iterations
for the new realisations, which are automatically contained in bmpmp.RData. Their lists
are set up as in the case of bmpmp.RData, where the entries are called mcmc thinned,
205

F The R Package bmpmp
eta thinned, number thinned.
Examples
### Example for bmpmp.estimation continued
# Required package (must be installed)
library(MCMCpack) # (will also be loaded within the function)
# Set workspace first and create input_data.RData through create.data()
# and constants.RData and bmpmp.RData through bmpmp.estimation()
# Set output directory as before
output_directory <- paste(getwd(),"/output/", sep = "")
# Setup 100,000 additional realisations for the algorithm
N <- 500000 # (previous value was N = 400,000)
thinning <- 100
save <- 2000
# Run function
bmpmp.estimation.continue(N = N, thinning = thinning, save = save,
output_directory = output_directory)
### End example
F.4 The Function bmpmp.plots
Description
bmpmp.plots constructs posterior distribution, convergence, validation, and forecast
plots for the output from bmpmp.estimation.
Usage
bmpmp.plots(burn in = 0, year = 1980, age = 60,
forecast begin = 2000, forecast end = 2050,
206

F The R Package bmpmp
output directory = paste(getwd(),"/output/", sep = ""),
distribution plots directory = "distribution plots/",
convergence plots directory = "convergence plots/",
validation plots directory = "validation plots/",
forecast plots directory = "forecast plots/",
titles = TRUE, tikz format = FALSE)
Arguments
burn in
Length of burn-in period, i.e. the number of initial realisations
(after thinning) in the MCMC algorithm that should be discarded.
Must be a scalar in N0 smaller than N thinned in bmpmp.RData.
Default is 0.
year
The ﬁxed reference calendar year for posterior distribution and
validation plots of the logit of mortality rates (linear predic-
tors) versus age levels. Must be an entry in calendar years in
input data.RData. Default is 1980.
age
The ﬁxed age for posterior distribution, validation, and forecast
plots of the logit of mortality rates (linear predictors) versus calen-
dar years. Must be an entry in age levels in input data.RData.
Default is 60.
forecast begin
Calendar year, for which the forecast period should begin. Must
be a scalar in N exceeding tmin + k but not larger than tmax +
1, where tmin and tmax are the input parameters t min and
t max from create.data, and k is the chosen lag order k for
bmpmp.estimation. Default is 2000.
forecast end
Calendar year, for which the forecast period should end. Must be
a scalar in N exceeding forecast begin. Default is 2050.
output directory Character object specifying the directory for both input data ﬁles
input data.RData created through the routine create.data and
bmpmp.RData created through bmpmp.estimation. Must end with
/". Default is paste(getwd(),"/output/", sep = "")), i.e. a
folder called output in the current workspace. For the current
workspace simply set output directory = "/".
207

F The R Package bmpmp
distribution
plots
directory
Character object specifying the directory within the output di-
rectory given through output directory for posterior distribu-
tion plots of hyperparameters and parameters.
Must end with
/".
Default is "distribution plots/", i.e. a folder called
distribution plots in the output directory. For the output di-
rectory itself simply set distribution plots directory = "/".
convergence
plots
directory
Character object specifying the directory within the output di-
rectory given through output directory for MCMC conver-
gence plots of hyperparameters and parameters.
Must end
with /". Default is "convergence plots/", i.e. a folder called
convergence plots in the output directory. For the output di-
rectory itself simply set convergence plots directory = "/".
validation plots
directory
Character object specifying the directory within the output direc-
tory given through output directory for internal validation plots
of hyperparameters and parameters. Must end with /". Default
is "validation plots/", i.e. a folder called validation plots in
the output directory. For the output directory itself simply set
validation plots directory = "/".
forecast plots
directory
Character object specifying the directory within the output di-
rectory given through output directory for forecast (external
validation) plots of hyperparameters and parameters. Must end
with /".
Default is "forecast plots/", i.e. a folder called
forecast plots in the output directory. For the output direc-
tory itself simply set forecast plots directory = "/".
titles
Logical value indicating whether main and axis titles should be
included in the graphical output. Default is TRUE.
tikz format
Logical value indicating whether the output should not be graphs
stored in pdf format as by default, but ﬁles in tikz format to allow
easy inclusion of graphs in LATEX documents. Default is FALSE.
Details
The routine will construct the following plots in pdf or tikz format, stored in the
respectively speciﬁed folders, for the output in bmpmp.RData and input data.RData,
constructed through the functions bmpmp.estimation and create.data, respectively.
208

F The R Package bmpmp
• Posterior distribution plots: (a) Marginal time series plots for all CBD parameters,
showing fancharts for the posterior realisations of the time series for all iterations
after the burn-in period (after thinning), their pointwise 90%, 95%, 99%, and 100%
credibility intervals (solid, dashed, dotted, limiting), and their starting values given
by the corresponding ML estimates (solid red). The ﬁles are named after the cor-
responding parameters. (b) Plots of the logit of mortality rates (linear predictors)
versus calendar years of the calibration period for all countries and genders for
the ﬁxed reference age given through age. Shown are fancharts for the posterior
realisations of the linear predictors for all iterations after the burn-in period (after
thinning), their pointwise 90%, 95%, 99%, and 100% credibility intervals (solid,
dashed, dotted, limiting), their starting values given by the corresponding ML
estimates (solid red), and the logits of the observed mortality rates under the as-
sumption of piecewise constant forces of mortality (solid green). The ﬁles’ names
start with linear predictor and indicate the respective gender and country. (c)
Plots of the logit of mortality rates (linear predictors) versus age levels of the cal-
ibration window for all countries and genders for the ﬁxed reference calendar year
given through year. Shown are fancharts for the posterior realisations of the linear
predictors for all iterations after the burn-in period (after thinning), their pointwise
90%, 95%, 99%, and 100% credibility intervals (solid, dashed, dotted, limiting),
their starting values given by the corresponding ML estimates (solid red), and the
logits of the observed mortality rates under the assumption of piecewise constant
forces of mortality (solid green). The ﬁles’ names start with mortality rate and
indicate the respective gender and country.
• MCMC convergence plots: Marginal scatterplots for all hyperparameters and pa-
rameters versus iterations after thinning (starting with initial values, i.e. the burn-
in period is shown). For the covariance matrices Ω(i) and the cointegration hy-
perparameters α(i) and β(i), the precision matrices
 Ω(i)−1 and the cointegration
matrices Π(i) = α(i)β(i)′ are also plotted. The ﬁles are named after the name of
the corresponding parameter or hyperparameter and their respective subscripts
denoting the vector’s or matrix’s entry.
• Internal validation plots: (a) Marginal time series plots for all CBD parameters
over the calibration period, showing fancharts for the marginal realisations of the
VECM for each realisation of the posterior distribution for the hyperparameters
209

F The R Package bmpmp
after the burn-in period (after thinning) using the prior distribution for the ﬁrst
k values, their pointwise 90%, 95%, 99%, and 100% credibility intervals (solid,
dashed, dotted, limiting), and their starting values given by the corresponding ML
estimates (solid red). The ﬁles are named after the corresponding parameters.
(b) Plots of the logit of mortality rates (linear predictors) versus calendar years
of the calibration period for all countries and genders for the ﬁxed reference age
given through age. Shown are fancharts for the simulated realisations of the linear
predictors, their pointwise 90%, 95%, 99%, and 100% credibility intervals (solid,
dashed, dotted, limiting), their starting values given by the corresponding ML
estimates (solid red), and the logits of the observed mortality rates under the
assumption of piecewise constant forces of mortality (solid green). The ﬁles’ names
start with linear predictor and indicate the respective gender and country. (c)
Plots of the logit of mortality rates (linear predictors) versus age levels of the
calibration window for all countries and genders for the ﬁxed reference calendar
year given through year. Shown are fancharts for the simulated realisations of the
linear predictors, their pointwise 90%, 95%, 99%, and 100% credibility intervals
(solid, dashed, dotted, limiting), their starting values given by the corresponding
ML estimates (solid red), and the logits of the observed mortality rates under the
assumption of piecewise constant forces of mortality (solid green). The ﬁles’ names
start with mortality rate and indicate the respective gender and country.
• Forecast (external validation) plots: (a) Marginal time series plots for all CBD pa-
rameters over the calibration and forecast period deﬁned through forecast begin
and forecast end, showing the initial values for the calibration period until the
begin of the forecast period and, thereafter, fancharts for the marginal realisations
of the VECM for each realisation of the posterior distribution for the hyperpa-
rameters after the burn-in period (after thinning), using the posterior distribution
for the preceding k values, and their pointwise 90%, 95%, 99%, and 100% cred-
ibility intervals (solid, dashed, dotted, limiting). The ﬁles are named after the
corresponding parameters. (b) Plots of the logit of mortality rates (linear predic-
tors) versus calendar years of the calibration and forecast period for all countries
and genders for the ﬁxed reference age given through age. Shown are fancharts
for the simulated realisations of the linear predictors for the forecast period, their
pointwise 90%, 95%, 99%, and 100% credibility intervals (solid, dashed, dotted,
210

F The R Package bmpmp
limiting), and the logits of the observed mortality rates under the assumption of
piecewise constant forces of mortality for the entire calibration period (solid green).
The ﬁles’ names start with linear predictor and indicate the respective gender
and country. (c) Plots of the logit of mortality rates (linear predictors) versus age
levels of the calibration window for all countries and genders for the ﬁnal calendar
year of the forecast period given through forecast end. Shown are fancharts for
the simulated realisations of the linear predictors in solid black, their pointwise
90%, 95%, 99%, and 100% credibility intervals (solid, dashed, dotted, limiting),
and the logits of the observed mortality rates under the assumption of piecewise
constant forces of mortality for the last calendar year of the calibration period as
comparison (solid green). The ﬁles’ names start with mortality rate and indicate
the respective gender and country.
The function bmpmp.plots requires the fanplot package and, if tikzformat = TRUE,
the tikzDevice package. While the routine is running, status messages are provided.
The routine automatically sets seeds for reproducible output. If bmpmp.RData has been
initialised with the choice of N = 0, no plots can be created, and an error message will
be provided.
Value
The routine does not return any values, but saves graphical output in pdf or tikz for-
mat as outlined under ‘Details’.
Examples
### Example for Big Five as in Section 4.1
### (Example for bmpmp.estimation continued)
# Set workspace first and create input_data.RData through create.data()
# and bmpmp.RData through bmpmp.estimation()
# Set output directory as before
output_directory <- paste(getwd(),"/output/", sep = "")
# Set directories for output plots within the output directory
# (folders must exist)
211

F The R Package bmpmp
distribution_plots_directory = "distribution_plots/"
convergence_plots_directory = "convergence_plots/"
validation_plots_directory = "validation_plots/"
forecast_plots_directory = "forecast_plots/"
# Setup for output graphs
burn_in <- 7500 # (after thinning, i.e. 750000 iterations in total)
year <- 1980
age <- 60
forecast_begin <- 1996
forecast_end <- 2014
titles <- TRUE
tikz_format <- FALSE
# Run function
bmpmp.plots(burn_in = burn_in, year = year, age = age,
forecast_begin = forecast_begin,
forecast_end = forecast_end,
output_directory = output_directory,
distribution_plots_directory = distribution_plots_directory,
convergence_plots_directory = convergence_plots_directory,
validation_plots_directory = validation_plots_directory,
forecast_plots_directory = forecast_plots_directory,
titles = titles, tikz_format = tikz_format)
### End example
F.5 The Function ml.estimation.plots
Description
ml.estimation.plots estimates the CBD model and VECM equations in the BMPMP
model via ML (if not over-parametrised), using input data ﬁles created by create.data
and bmpmp.estimation, and constructs forecast plots.
212

F The R Package bmpmp
Usage
ml.estimation.plots(forecast begin = 2000, forecast end = 2050,
age = 60, output directory
= paste(getwd(),"/output/", sep = ""),
ml forecast plots directory = "ml forecast plots/",
titles = TRUE, tikz format = FALSE)
Arguments
forecast begin
Calendar year, for which the forecast period should begin. Must
be a scalar in N exceeding tmin + k but not larger than tmax +
1, where tmin and tmax are the input parameters t min and
t max for create.data and k is the chosen lag order k for
bmpmp.estimation. Default is 2000.
forecast end
Calendar year, for which the forecast period should end. Must be
a scalar in N exceeding forecast begin. Default is 2050.
age
The ﬁxed age for the forecast plots of the logit of mortality rates
(linear predictors) versus calendar years.
Must be an entry in
age levels in input data.RData. Default is 60.
output directory Character object specifying the directory for the input data ﬁles
input data.RData, constants.RData and initial.RData. Must
end with /".
Default is paste(getwd(),"/output/", sep =
"")), i.e. a folder called output in the current workspace. For
the current workspace simply set output directory = "/".
ml forecast
plots
directory
Character object specifying the directory within the output di-
rectory given through output directory for forecast (external
validation) plots of hyperparameters and parameters. Must end
with /".
Default is "ml forecast plots/", i.e. a folder called
ml forecast plots in the output directory. For the output di-
rectory itself simply set ml forecast plots directory = "/".
titles
Logical value indicating whether main and axis titles should be
included in the graphical output. Default is TRUE.
213

F The R Package bmpmp
tikz format
Logical value indicating whether the output should not be graphs
stored in pdf format as by default, but ﬁles in tikz format to allow
easy inclusion of graphs in LATEX documents. Default is FALSE.
Details
Given the input data through input data.RData, the initial values via initial.RData,
and the constants through constants.RData (where the latter two ﬁles can be con-
veniently created using bmpmp.estimation with the choice of N = 0), the routine es-
timates both the CBD model and the VECM as deﬁned in the BMPMP model for
bmpmp.estimation via ML in a two-step procedure known from classical LC or CBD
models. First, the CBD model is estimated via standard ML procedures known from
Binomial generalised regression (i.e. the starting values for the Bayesian estimation). In
a second step, the VECM is estimated via the ML techniques outlined in Appendix C.4.
Note that ML estimation will not be available for many applications, as the number
of hyperparameters in the VECM soon exceeds the number of latent parameters in the
CBD model. In particular, only a very small number of countries will allow for a lag
order k greater than one. In case of singularities in the ML procedure, respective error
messages will be provided.
ml.forecast.plots further provides the following forecast (external validation) plots
in pdf or tikz format, stored in the folder given by ml forecast plots directory:
(a) Marginal time series plots for all CBD parameters over the calibration and forecast
period deﬁned through forecast begin and forecast end, showing the ML point es-
timates for the calibration period until the begin of the forecast period and, thereafter,
the ML forecasts of the VECM consisting of the pointwise estimates (solid black), and
the pointwise 2.5% and 97.5% conﬁdence limits (dashed cyan). The ﬁles are named after
the corresponding parameters. (b) Plots of the logit of mortality rates (linear predictors)
versus calendar years of the calibration and forecast period for all countries and genders
for the ﬁxed reference age given through age. Shown are the ML point estimates for the
calibration period until the begin of the forecast period and, thereafter, the ML forecasts
consisting of the pointwise estimates (solid black), and the pointwise 2.5% and 97.5%
conﬁdence limits (dashed cyan) along with the logits of the observed mortality rates
under the assumption of piecewise constant forces of mortality for the entire calibration
period (solid green). The ﬁles’ names start with linear predictor and indicate the
214

F The R Package bmpmp
respective gender and country. (c) Plots of the logit of mortality rates (linear predic-
tors) versus age levels of the calibration window for all countries and genders for the
ﬁnal calendar year of the forecast period given through forecast end. Shown are the
ML forecast point estimates of the linear predictors in solid black and their pointwise
2.5% and 97.5% conﬁdence limits (dashed cyan) along with the logits of the observed
mortality rates under the assumption of piecewise constant forces of mortality for the
last calendar year of the calibration period as comparison (solid green). The ﬁles’ names
start with mortality rate and indicate the respective gender and country.
The function ml.forecast.plots requires the expm package and, if tikzformat =
TRUE, the tikzDevice package. While the routine is running, status messages are pro-
vided.
Value
The routine does not return any values, but saves graphical output in pdf or tikz for-
mat as outlined under ‘Details’.
Examples
### Example for Big Five as in Section 4.1
### (Example for bmpmp.estimation continued)
# Required package (must be installed)
library(expm) # (will also be loaded within the function)
# Set workspace first and create input_data.RData through create.data()
# and constants.RData
# and bmpmp.RData through bmpmp.estimation() (e.g. with N=0)
# Set output directory as before
output_directory <- paste(getwd(),"/output/", sep = "")
# Set directory for output graphs (folder must exist)
ml_forecast_plots_directory <- "ml_forecast_plots/"
215

F The R Package bmpmp
# Setup for output graphs with forecast period as before
age <- 60
forecast_begin <- 1996
forecast_end <- 2014
titles <- TRUE
tikz_format <- FALSE
# Run function
ml.estimation.plots(forecast_begin = forecast_begin,
forecast_end = forecast_end, age = age,
output_directory = output_directory,
ml_forecast_plots_directory
= ml_forecast_plots_directory,
titles = titles, tikz_format = tikz_format)
### End example
216

References
Agostinelli, C. and Greco, L. (2012). Weighted likelihood in Bayesian inference. In
Proceedings of 46th Scientiﬁc Meeting of the Italian Statistical Society, Sapienza Uni-
versity of Rome, Rome, Italy.
Ah˘can, A., Medved, D., Olivieri, A., and Pitacco, E. (2014). Forecasting mortality for
small populations by mixing mortality data. Insurance: Mathematics and Economics,
54:12–27.
Akaike, H. (1969). Fitting autoregressive models for prediction. Annals of the Institute
of Statistical Mathematics, 21(1):243–247.
Akaike, H. (1974). A new look at the statistical model identiﬁcation. IEEE Transactions
on Automatic Control, 19(6):716–723.
Alho, J. M. (2000). Discussion of Lee (2000). North American Actuarial Journal, 4(1):91–
93.
Bauwens, L. and Lubrano, M. (1993). Identiﬁcation restrictions and posterior densities
in cointegrated Gaussian VAR systems. In Fomby, T. and Hill, R. C. (Eds.), Advances
in Econometrics, Vol. 11b. JAI Press, Greenwich, Connecticut.
Biatat, V. D. and Currie, I. D. (2010). Joint models for classiﬁcation and comparison
of mortality in diﬀerent countries. In Proceedings of 25rd International Workshop on
Statistical Modelling, 89–94, University of Glasgow, Glasgow, Scotland.
Booth, H., Hyndman, R. J., Tickle, L., and De Jong, P. (2006). Lee-Carter mortality
forecasting: A multi-country comparison of variants and extensions. Demographic
Research, 15(9):289–310.
Booth, H. and Tickle, L. (2008).
Mortality modelling and forecasting: A review of
methods. Annals of Actuarial Science, 3(1–2):3–43.
217

References
B¨orger, M. and Aleksic, M.-C. (2011). Coherent projections of age, period, and co-
hort dependent mortality improvements. Preprint Series, Faculty of Mathematics and
Economics, University of Ulm, Ulm, Germany.
Box, G. E., Jenkins, G. M., and Reinsel, G. C. (2013). Time Series Analysis: Forecasting
and Control, Fourth Edition. Wiley Series in Probability and Statistics. John Wiley
& Sons, Hoboken, New Jersey.
Box, G. E. and Tiao, G. C. (2011). Bayesian Inference in Statistical Analysis, Vol. 40
of Wiley Classics Library. John Wiley & Sons, Hoboken, New Jersey.
Bray, I. (2002). Application of Markov chain Monte Carlo methods to projecting cancer
incidence and mortality. Journal of the Royal Statistical Society: Series C (Applied
Statistics), 51(2):151–164.
Breusch, T. S. (1978). Testing for autocorrelation in dynamic linear models. Australian
Economic Papers, 17(31):334–355.
Brillinger, D. R. (1986). The natural variability of vital rates and associated statistics.
Biometrics, 42:693–734.
Brockwell, P. J. and Davis, R. A. (2009). Time Series: Theory and Methods, Second
Edition. Springer Series in Statistics. Springer, New York, New York.
Brouhns, N., Denuit, M., and Vermunt, J. K. (2002). A Poisson log-bilinear regression
approach to the construction of projected lifetables.
Insurance: Mathematics and
Economics, 31(3):373–393.
Br¨uggemann, R. (2004).
Model Reduction Methods for Vector Autoregressive Pro-
cesses, Vol. 536 of Lecture Notes in Economics and Mathematical Systems. Springer,
Berlin/Heidelberg, Germany.
Cairns, A. J., Blake, D., and Dowd, K. (2006).
A two-factor model for stochastic
mortality with parameter uncertainty: Theory and calibration. Journal of Risk and
Insurance, 73(4):687–718.
Cairns, A. J., Blake, D., and Dowd, K. (2008). Modelling and management of mortality
risk: A review. Scandinavian Actuarial Journal, 2008(2–3):79–113.
218

References
Cairns, A. J., Blake, D., Dowd, K., Coughlan, G. D., Epstein, D., and Khalaf-Allah, M.
(2011a). Mortality density forecasts: An analysis of six stochastic mortality models.
Insurance: Mathematics and Economics, 48(3):355–367.
Cairns, A. J., Blake, D., Dowd, K., Coughlan, G. D., Epstein, D., Ong, A., and Bale-
vich, I. (2009). A quantitative comparison of stochastic mortality models using data
from England and Wales and the United States. North American Actuarial Journal,
13(1):1–35.
Cairns, A. J., Blake, D., Dowd, K., Coughlan, G. D., and Khalaf-Allah, M. (2011b).
Bayesian stochastic mortality modelling for two populations. Astin Bulletin, 41(1):29–
59.
Chao, J. C. and Phillips, P. C. (1999). Model selection in partially nonstationary vec-
tor autoregressive processes with reduced rank structure. Journal of Econometrics,
91(2):227–271.
Czado, C., Delwarde, A., and Denuit, M. (2005). Bayesian Poisson log-bilinear mortality
projections. Insurance: Mathematics and Economics, 36(3):260–284.
Dawid, A. P. (1981). Some matrix-variate distribution theory: Notational considerations
and a Bayesian application. Biometrika, 68(1):265–274.
de Jong, P. and Tickle, L. (2006). Extending Lee–Carter mortality forecasting. Mathe-
matical Population Studies, 13(1):1–18.
de Moivre, A. (1725). Annuities upon Lives: Or, the Valuation of Annuities upon any
Number of Lives, as also, of Reversions to which is added, an Appendix Concerning
the Expectations of Life, and Probabilities of Survivorship. Published by Pearson, W.,
London, England.
DeJong, D. N. (1992). Co-integration and trend-stationarity in macroeconomic time
series: Evidence from the likelihood function. Journal of Econometrics, 52(3):347–
370.
Delwarde, A., Denuit, M., and Partrat, C. (2007). Negative Binomial version of the
Lee–Carter model for mortality forecasting. Applied Stochastic Models in Business
and Industry, 23(5):385–401.
219

References
Doan, T., Litterman, R., and Sims, C. (1984). Forecasting and conditional projection
using realistic prior distributions. Econometric Reviews, 3(1):1–100.
Dobson, A. J. and Barnett, A. G. (2008). An Introduction to Generalized Linear Models,
Third Edition.
Texts in Statistical Science. Chapman & Hall/CRC, Boca Raton,
Florida.
Dowd, K., Cairns, A. J., Blake, D., Coughlan, G. D., and Khalaf-Allah, M. (2011). A
gravity model of mortality rates for two related populations. North American Actuarial
Journal, 15(2):334–356.
Engle, R. F. and Granger, C. W. (1987). Co-integration and error correction: Repre-
sentation, estimation, and testing. Econometrica, 55(2):251–276.
Gamerman, D. and Lopes, H. F. (2006). Markov Chain Monte Carlo: Stochastic Simu-
lation for Bayesian Inference, Second Edition. Texts in Statistical Science. Chapman
& Hall/CRC, Boca Raton, Florida.
Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., and Rubin, D. B.
(2013). Bayesian Data Analysis, Third Edition. Texts in Statistical Science. Chapman
& Hall/CRC, Boca Raton, Florida.
Geman, S. and Geman, D. (1984). Stochastic relaxation, Gibbs distributions, and the
Bayesian restoration of images. IEEE Transactions on Pattern Analysis and Machine
Intelligence, 6(6):721–741.
Geweke, J. (1991). Evaluating the accuracy of sampling-based approaches to the calcu-
lation of posterior moments. In Bernardo, J., Berger, J., Dawid, A., and Smith, A.
(Eds.), Proceedings of the Fourth Valencia International Meeting, Vol. 4 of Bayesian
Statistics, 169–193. Oxford University Press, Oxford, England.
Geweke, J. (1996). Bayesian reduced rank regression in econometrics. Journal of Econo-
metrics, 75(1):121–146.
Gilks, W. R. (2005).
Markov chain Monte Carlo.
In Armitage, P. and Colton, T.
(Eds.), Encyclopedia of Biostatistics, Second Edition. John Wiley & Sons, Chichester,
England.
220

References
Girosi, F. and King, G. (2008). Demographic Forecasting. Princeton University Press,
Princeton, New Jersey.
Godfrey, L. G. (1978). Testing for higher order serial correlation in regression equations
when the regressors include lagged dependent variables. Econometrica, 46(6):1303–
1310.
Gompertz, B. (1825). On the nature of the function expressive of the law of human mor-
tality, and on a new mode of determining the value of life contingencies. Philosophical
Transactions of the Royal Society of London, 115:513–583.
Granger, C. W. (1981). Some properties of time series data and their use in econometric
model speciﬁcation. Journal of Econometrics, 16(1):121–130.
Haberman, S. and Renshaw, A. (2011). A comparative study of parametric mortality
projection models. Insurance: Mathematics and Economics, 48(1):35–55.
Hannan, E. J. and Quinn, B. G. (1979). The determination of the order of an autoregres-
sion. Journal of the Royal Statistical Society. Series B (Methodological), 41(2):190–
195.
Hansen, P. R. (2005). Granger’s Representation Theorem: A closed-form expression for
I(1) processes. The Econometrics Journal, 8(1):23–38.
Hastings, W. K. (1970). Monte Carlo sampling methods using Markov chains and their
applications. Biometrika, 57(1):97–109.
Human Mortality Database (2014). University of California, Berkeley, California, and
Max Planck Institute for Demographic Research, Rostock, Germany. Available at
http://www.mortality.org or http://www.humanmortality.de (data downloaded
on 24 September 2014).
James, A. T. (1954).
Normal multivariate analysis and the orthogonal group.
The
Annals of Mathematical Statistics, 25(1):40–75.
James, A. T. (1964). Distributions of matrix variates and latent roots derived from
normal samples. The Annals of Mathematical Statistics, 35(2):475–501.
221

References
Jarner, S. F. and Kryger, E. M. (2011). Modelling adult mortality in small populations:
The SAINT model. Astin Bulletin, 41(2):377–418.
Jarque, C. M. and Bera, A. K. (1987). A test for normality of observations and regres-
sion residuals. International Statistical Review/Revue Internationale de Statistique,
55(2):163–172.
Jeﬀreys, H. (1998). The Theory of Probability, Third Edition. Oxford University Press,
Oxford, England.
Johansen, S. (1988). Statistical analysis of cointegration vectors. Journal of Economic
Dynamics and Control, 12(2):231–254.
Johansen, S. (1991). Estimation and hypothesis testing of cointegration vectors in Gaus-
sian vector autoregressive models. Econometrica, 59(6):1551–1580.
Johansen, S. (1995). Likelihood-Based Inference in Cointegrated Vector Autoregressive
Models. Advanced Texts in Econometrics. Oxford University Press, Oxford, England.
Johansen, S. and Juselius, K. (1990). Maximum likelihood estimation and inference
on cointegration – with applications to the demand for money. Oxford Bulletin of
Economics and Statistics, 52(2):169–210.
Johansen, S. and Juselius, K. (1992). Testing structural hypotheses in a multivariate
cointegration analysis of the PPP and the UIP for UK. Journal of Econometrics,
53(1):211–244.
Kleibergen, F. and van Dijk, H. K. (1994). On the shape of the likelihood/posterior in
cointegration models. Econometric Theory, 10(3–4):514–551.
Kogure, A., Kitsukawa, K., and Kurachi, Y. (2009). A Bayesian comparison of models for
changing mortalities toward evaluating longevity risk in Japan. Asia-Paciﬁc Journal
of Risk and Insurance, 3(2):1–21.
Koop, G., Strachan, R. W., Van Dijk, H., and Villani, M. (2006). Bayesian approaches
to cointegration. In Mills, T. C. and Patterson, K. D. (Eds.), Econometric Theory,
Vol. 1 of Palgrave Handbook on Econometrics, 871–898. Palgrave Macmillan, New
York, New York.
222

References
Lee, R. (2000). The Lee-Carter method for forecasting mortality, with various extensions
and applications. North American Actuarial Journal, 4(1):80–91.
Lee, R. D. and Carter, L. R. (1992). Modeling and forecasting US mortality. Journal of
the American Statistical Association, 87(419):659–671.
Li, J. S.-H. and Hardy, M. R. (2011). Measuring basis risk in longevity hedges. North
American Actuarial Journal, 15(2):177–200.
Li, N. and Lee, R. (2005). Coherent mortality forecasts for a group of populations: An
extension of the Lee-Carter method. Demography, 42(3):575–594.
Lin, Y., Liu, S., and Yu, J. (2013). Pricing mortality securities with correlated mortality
indexes. Journal of Risk and Insurance, 80(4):921–948.
Litterman, R. B. (1986). Forecasting with Bayesian vector autoregressions – ﬁve years
of experience. Journal of Business & Economic Statistics, 4(1):25–38.
Lomnicki, Z. (1961). Tests for departure from normality in the case of linear stochastic
processes. Metrika, 4(1):37–62.
L¨utkepohl, H. (2007). New Introduction to Multiple Time Series Analysis. Springer,
Berlin/Heidelberg, Germany.
Macdonald, A., Cairns, A., Gwilt, P., and Miller, K. (1998). An international comparison
of recent trends in population mortality. British Actuarial Journal, 4(1):3–141.
Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., and Teller, E.
(1953). Equation of state calculations by fast computing machines. The Journal of
Chemical Physics, 21(6):1087–1092.
Meyn, S. P. and Tweedie, R. L. (2009). Markov Chains and Stochastic Stability, Second
Edition. Cambridge University Press, Cambridge, England.
Neudecker, H. (1968). The Kronecker matrix product and some of its applications in
econometrics. Statistica Neerlandica, 22(1):69–82.
Newton, M. A. and Raftery, A. E. (1994). Approximate Bayesian inference with the
weighted likelihood bootstrap.
Journal of the Royal Statistical Society. Series B
(Methodological), 56(1):3–48.
223

References
Ntamjokouen, A., Haberman, S., and Consigli, G. (2014). A multivariate approach to
project the long run relationship between mortality indices for Canadian provinces. In
Perna, C. and Sibillo, M. (Eds.), Mathematical and Statistical Methods for Actuarial
Sciences and Finance, 153–161. Springer International Publishing, Cham, Switzer-
land.
Oeppen, J. and Vaupel, J. W. (2002).
Broken limits to life expectancy.
Science,
296(5570):1029–1031.
Pedroza, C. (2006). A Bayesian forecasting model: Predicting US male mortality. Bio-
statistics, 7(4):530–550.
Pitacco, E., Denuit, M., Haberman, S., and Olivieri, A. (2009). Modelling Longevity
Dynamics for Pensions and Annuity Business. Oxford University Press, Oxford, Eng-
land.
Plat, R. (2009). Stochastic portfolio speciﬁc mortality and the quantiﬁcation of mortality
basis risk. Insurance: Mathematics and Economics, 45(1):123–132.
Raftery, A. E., Chunn, J. L., Gerland, P., and ˇSevˇc´ıkov´a, H. (2013). Bayesian proba-
bilistic projections of life expectancy for all countries. Demography, 50(3):777–801.
Raftery, A. E. and Lewis, S. (1992). How many iterations in the Gibbs sampler?
In
Bernardo, J., Berger, J., Dawid, A., and Smith, A. (Eds.), Proceedings of the Fourth
Valencia International Meeting, Vol. 4 of Bayesian Statistics, 763–773. Oxford Uni-
versity Press, Oxford, England.
Reichmuth, W. H. and Sarferaz, S. (2008). Bayesian demographic modeling and fore-
casting: An application to US mortality. Discussion Paper of Sonderforschungsbereich
649 (Economic Risk), Humboldt-Universit¨at zu Berlin, Berlin, Germany.
Reinsel, G. C. (2003). Elements of Multivariate Time Series Analysis, Second Edition.
Springer, New York, New York.
Renshaw, A. E. and Haberman, S. (2003a). Lee–Carter mortality forecasting: A parallel
generalized linear modelling approach for England and Wales mortality projections.
Journal of the Royal Statistical Society: Series C (Applied Statistics), 52(1):119–137.
224

References
Renshaw, A. E. and Haberman, S. (2003b). Lee–Carter mortality forecasting with age-
speciﬁc enhancement. Insurance: Mathematics and Economics, 33(2):255–272.
Renshaw, A. E. and Haberman, S. (2003c). On the forecasting of mortality reduction
factors. Insurance: Mathematics and Economics, 32(3):379–401.
Renshaw, A. E. and Haberman, S. (2006).
A cohort-based extension to the Lee–
Carter model for mortality reduction factors. Insurance: Mathematics and Economics,
38(3):556–570.
Robert, C. P. and Casella, G. (2004). Monte Carlo Statistical Methods, Second Edition.
Springer Texts in Statistics. Springer, New York, New York.
Rubin, D. B. (1984). Bayesianly justiﬁable and relevant frequency calculations for the
applies statistician. The Annals of Statistics, 12(4):1151–1172.
Salmon, M. (1982). Error correction mechanisms. The Economic Journal, 92(367):615–
629.
Schwarz, G. (1978). Estimating the dimension of a model. The Annals of Statistics,
6(2):461–464.
Spiegelhalter, D. J., Best, N. G., Carlin, B. P., and Van Der Linde, A. (2002). Bayesian
measures of model complexity and ﬁt. Journal of the Royal Statistical Society: Series
B (Statistical Methodology), 64(4):583–639.
Stigler, S. M. (1986). The History of Statistics: The Measurement of Uncertainty before
1900. Harvard University Press, Cambridge, Massachusetts.
Strachan, R. W. (2003). Valid Bayesian estimation of the cointegrating error correction
model. Journal of Business & Economic Statistics, 21(1):185–195.
Strachan, R. W. and Dijk, H. K. (2004). Valuing structure, model uncertainty and model
averaging in vector autoregressive processes. Econometric Institute Report, Erasmus
University Rotterdam, Rotterdam, Netherlands.
Strachan, R. W. and Inder, B. (2004). Bayesian analysis of the error correction model.
Journal of Econometrics, 123(2):307–325.
225

References
Tuljapurkar, S., Li, N., and Boe, C. (2000). A universal pattern of mortality decline in
the G7 countries. Nature, 405(6788):789–792.
Villani, M. (2000). Aspects of Bayesian Cointegration. PhD thesis, Stockholm University.
Villani, M. (2001). Fractional Bayesian lag length inference in multivariate autoregressive
processes. Journal of Time Series Analysis, 22(1):67–86.
Villani, M. (2005). Bayesian reference analysis of cointegration. Econometric Theory,
21(2):326–357.
Wakeﬁeld, J. (2007). Disease mapping and spatial regression with count data. Biostatis-
tics, 8(2):158–183.
Warne, A. (2006). Bayesian inference in cointegrated VAR models with applications to
the demand for euro area M3. Working Paper Series of the European Central Bank,
692:1–41.
Wilmoth, J. R. (1993). Computational methods for ﬁtting and extrapolating the Lee-
Carter model of mortality change.
Technical report, Department of Demography,
University of California, Berkeley, California.
Wilson, C. (2001). On the scale of global demographic convergence 1950–2000. Popula-
tion and Development Review, 27(1):155–171.
Wishart, J. (1928). The generalised product moment distribution in samples from a
normal multivariate population. Biometrika, 32–52.
Wold, H. (1938). A Study in the Analysis of Stationary Time Series. Almqvist and
Wiksells, Stockholm, Sweden.
Zellner, A. (1971). An Introduction to Bayesian Inference in Econometrics. Wiley Series
in Probability and Mathematical Statistics: Applied Probability and Statistics. John
Wiley & Sons, New York, New York.
Zhou, R., Li, J. S.-H., and Tan, K. S. (2013). Pricing standardized mortality securiti-
zations: A two-population model with transitory jump eﬀects. Journal of Risk and
Insurance, 80(3):733–774.
226

References
Zhou, R., Wang, Y., Kaufhold, K., Li, J., and Tan, K. (2012). Modeling mortality of
multiple populations with vector error correction models: Applications to Solvency
II. Submitted for publication.
227

Ehrenw¨ortliche Erkl¨arung
Ich erkl¨are hiermit ehrenw¨ortlich, dass ich die vorliegende Arbeit selbstst¨andig angefer-
tigt habe; die aus fremden Quellen direkt oder indirekt ¨ubernommenen Gedanken sind
als solche kenntlich gemacht. Die Arbeit wurde bisher keiner anderen Pr¨ufungsbeh¨orde
vorgelegt und auch noch nicht ver¨oﬀentlicht.
Ich bin mir bewusst, dass eine unwahre Erkl¨arung rechtliche Folgen haben wird.
Ulm, den 17. Dezember 2014
(Unterschrift)
228

