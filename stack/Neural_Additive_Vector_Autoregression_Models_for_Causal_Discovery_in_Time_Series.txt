Neural Additive Vector Autoregression Models
for Causal Discovery in Time Series
Bart Bussmann1, Jannes Nys1, and Steven Latr´e1
IDLab, University of Antwerp - imec, Antwerpen, Belgium
{firstname.lastname}@uantwerpen.be
Abstract Causal structure discovery in complex dynamical systems is
an important challenge for many scientiﬁc domains. Although data from
(interventional) experiments is usually limited, large amounts of obser-
vational time series data sets are usually available. Current methods that
learn causal structure from time series often assume linear relationships.
Hence, they may fail in realistic settings that contain nonlinear relations
between the variables. We propose Neural Additive Vector Autoregres-
sion (NAVAR) models, a neural approach to causal structure learning
that can discover nonlinear relationships. We train deep neural networks
that extract the (additive) Granger causal inﬂuences from the time evo-
lution in multi-variate time series. The method achieves state-of-the-art
results on various benchmark data sets for causal discovery, while pro-
viding clear interpretations of the mapped causal relations.
Keywords: Causal Discovery · Time Series · Deep Learning
1
Introduction
Discovering mechanisms and causal structures is an important challenge for
many scientiﬁc domains. Randomized control trials may not always be feasi-
ble, practical or ethical, such as in the domain of climate sciences and genetics.
Therefore, when no interventional data is available, we are forced to rely on
observational data only.
In dynamical systems, the arrow of time simpliﬁes the analysis of possible
causal interactions in the sense that we can assume that only preceding signals
are a potential cause of the current observations. A common approach is to test
time-lagged causal associations in the framework of Granger causality [11]. These
methods often model the time-dependence via linear causal relationships, with
Vector AutoRegression (VAR) models as the most common approach.
Even though there is extensive literature on nonlinear causal discovery (e.g.
[18, 32]) relatively few others (e.g. [33, 15]) have harnessed the power of deep
learning for causal discovery in time series. These methods operate within the
Granger causality framework and use deep neural networks to model the time
dependencies and interactions between the variables. In principle, deep learning
approaches make it possible to model causal relationships, even when they are

2
B. Bussmann et al.
nonlinear. While these methods have a high degree of expressiveness, this ﬂexi-
bility comes at a cost: interpretation of the causal relations learned by black-box
methods is hindered, while this is essentially the goal of causal structure learn-
ing. To overcome this, these methods learn to set certain input weights to zero,
which they interpret as an absence of Granger Causality.
In this work, we propose the Neural Additive Vector Autoregression (NAVAR)
model to resolve this problem. NAVAR assumes an additive structure, where the
predictions depend linearly on independent nonlinear functions of the individual
input variables. We model these nonlinear functions using neural networks. In
comparison to other works using Granger causality for causal discovery in time
series, our work diﬀers in the following ways:
1. Compared to common linear methods, our method can easily capture (highly)
nonlinear relations.
2. While being able to model nonlinear relations, NAVAR maintains a clear
interpretation of the causal dependencies between pairs of variables. In con-
trast to other deep learning methods that resort to feature importance meth-
ods, NAVAR uses the interpretational power of additive models to discover
Granger causal relationships.
3. By using an additive model of learned transformations of the input variables,
our model allows not only for the discovery of causal relationships between
pairs of time series but also inspection of the functional form of these causal
dependencies. Thanks to the additive structure, we can inspect the direct
contribution of every input variable to every output variable.
4. The additive structure allows us to score and rank causal relations. Since we
can compute the direct contribution of each input variable to each output
variable independently, the variability of these contributions can be used as
evidence for the existence of a causal link.
The rest of this paper is structured as follows: Section 2 introduces the
Granger causality framework and VAR models. In Section 3 we generalize this
notion to the additive nonlinear case and introduce NAVAR models that can
estimate Granger causality using neural networks. In Section 4 we evaluate the
performance of NAVAR on various benchmarks and compare it to existing meth-
ods. Finally, in Section 5 we discuss related work and in Section 6 we conclude
and discuss directions for future work.
2
Granger Causality and the VAR Model
Let X1:T = {X(1)
1:T , X(2)
1:T , .., X(N)
1:T } be a multivariate time series with N variables
and T time steps. Our goal is to discover the causal relations between this set
of time series. (Pairwise) Granger causality is one of the classical frameworks to
discover causal relationships between time series. In this framework, we model
the time series as:
X(i)
t
= gi(X(1)
<t , ..., X(N)
<t ) + ηi
t
(1)

Neural Additive Vector Autoregression for Causal Discovery in Time Series
3
where X(i)
<t = X(i)
1:t−1 denotes the past of X(i), and and ηt is an independent
noise vector. A variable X(i) is said to Granger cause another variable X(j) if
the past of the set of all (input) variables {X(1)
<t , ..., X(i)
<t, ..., X(N)
<t } allows for
better predictions for X(j)
t
compared to the same set where the past of X(i) is
not included: {X(1)
<t , ..., X(i−1)
<t
, X(i+1)
<t
, ..., X(N)
<t }. Granger causality approaches
assume causal suﬃciency. We refer to the directed graph with the variables X(i)
as vertices, and links representing Granger causality between two variables as
the Granger causal graph.
In the VAR framework, the time series X(j)
t
is assumed to be a linear com-
bination of all past values (up to some maximum lag K) and independent noise
term. This means that every value X(j)
t
can be modeled as:
X(j)
t
= βj +
N
X
i=1
K
X
k=1
[Ak]ijX(i)
t−k + ηj
t
(2)
Where Ak is a N × N time-invariant matrix which identiﬁes the interaction
between the variables, β is a N-dimensional bias vector, and ηt is an independent
noise vector with zero mean. A common approach to infer which pairs of variables
are not Granger causal is to identify i and j for which [Ak]ij = 0 for all time
lags k = 1, ..., K.
3
NAVAR: Neural Additive Vector AutoRegression
The idea underlying the linear VAR model is simple and it can be surprisingly
eﬀective. For instance, in the NeurIPS 2019 Causality for Climate competition,
the winners used four variations based on the standard linear VAR model [35].
However, a limitation of the VAR model is that it can only model linear interac-
tions. Guided by the success and reliability of VAR models for Granger-causal
discovery, in this work, we generalize the VAR model to allow for nonlinear
additive relationships between variables:
X(j)
t
= βj +
N
X
i=1
f ij(X(i)
t−K:t−1) + ηj
t
(3)
Here, f ij is a nonlinear function describing the relationship between the past
K values of X(i) on the current value of X(j). Note that the VAR model is
the special case where f ij is linear. We can identify Granger causality in the
following way: if variable X(i) is not a Granger cause of another variable X(j)
then f ij is invariant to the values of X(i)
t−K:t−1. In other words, if f ij is a constant
function of all values X(i)
t−K:t−1, then X(i) is not a Granger cause of X(j).
The choice of this additive model is built on the following assumption. In
many practical applications, the functional dependence of a variable X(i)
t
on
the history of a variable X(i)
<t is complex, with e.g. nonlinear functions across
multiple time lags. However, dependencies on multiple time series can usually

4
B. Bussmann et al.
be well approximated by additive models. Therefore, we introduce an additive
structure for the contributions stemming from the diﬀerent variables, but do not
impose an additive restriction to contributions from diﬀerent time lags.
We choose to use deep neural networks (DNN) to model the nonlinear func-
tion f ij. In our method, dubbed Neural Additive Vector AutoRegression (NAVAR),
we train separate models on the past of each variable to predict its contribution
to the value of all variables at the next time step. In particular, at every time
step t, we pass the past values of a variable X(i) to a neural network f with N
output nodes to compute its contribution to all other variables X(j):
ci→j
t
= [fθi(X(i)
t−K:t−1)]j
(4)
The function [fθi]j is the jth output of the neural network f with parameters
θi. A graphical overview of the method can be found in Figure 1. In principle,
one can choose a wide variety of neural networks for f, e.g. Multi-Layered Per-
ceptrons (MLP), Recurrent Neural Networks (RNN), and Convolutional Neural
Networks (CNN). In our experiments, we consider MLPs and LSTMs [10] to
demonstrate the concept, since the additive structure is key to its success. In
the LSTM version of our model, single time steps of a variable are sequentially
passed to the networks, and thus the networks predict the contributions based
only on Xt−1 and its recurrent hidden states (in contrast to K inputs to the
MLP). Therefore, the size of the LSTM network does not increase for larger lags
and is thus particularly scalable to longer lags. Although these backbones al-
Figure 1. Graphical representation of the NAVAR model with MLPs. For every time
step t and every variable X(i), we compute a nonlinear combination of its past X(i)
t−K:t−1
(with a maximum time lag K) as the contribution to every other variable. To compute
the estimate of X(j)
t
, all contributions ci→j
t
are summed.

Neural Additive Vector Autoregression for Causal Discovery in Time Series
5
ready outperform the state of the art, we envision that more complex backbone
architectures for f could potentially further increase performance.
The resulting prediction for X(j) at time t is the sum of all its incoming
contributions:
ˆX(j)
t
= βj +
N
X
i=1
ci→j
t
(5)
We choose this additive structure of neural networks as it is a natural exten-
sion of the VAR framework with nonlinearities (see Equation 3) and it allows
us to uncover the causal links from X(i) to X(j) by inspecting the direct contri-
butions ci→j
t
. Granger causality requires us to estimate the predictions for X(j)
t
when the past of X(i) is not included, which in our framework can be directly
obtained by ignoring the corresponding contribution ci→j
t
in equation (5). This
is a key feature of our method that allows it to be scalable: we avoid the ne-
cessity to perform multiple ﬁts of a neural network, such as a ﬁt including and
excluding the past of variable X(i), when testing the predictive power due to
X(i) (see the discussion in Related Work).
The regression networks are trained using the MSE loss function. We intro-
duce an l1 penalty to the contributions ci→j
t
in order to promote sparsity in the
resulting causal link structure. Assuming that large causal networks will have a
similar number of causes per variable compared to smaller networks, we choose
to penalize the sum of the absolute value of received contributions per variable
instead of the mean contribution size. This results in the following loss function
for the predictions at a time step t:
Lt(β, θ) = 1
N
N
X
j=1
 
βj +
N
X
i=1
[fθi(X(i)
t−K:t−1)]j −X(j)
t
!2
+ λ
N
N
X
i,j=1
[fθi(X(i)
t−K:t−1)]j
(6)
Furthermore, we add a weight decay term to the loss with coeﬃcient µ.
In order to make the contributions comparable, every individual time series is
normalized such that it has mean zero and standard deviation one before train-
ing. After training the networks, we deduce the causal links from the variability
of the contributions in equation (4). The rationale to reconstruct the Granger
causal graph is that if a certain variable has a large causal inﬂuence on another
variable, then it will send a large variety of contributions over the course of time.
However, if a variable X(i) is not a Granger cause of another variable X(j) then
f ij is a constant function, because X(j) is invariant to the values of X(i)
t−K:t−1.
To score a potential causal link X(i) →X(j) with the trained neural network,
we therefore compute the standard deviation of the set of contributions ci→j
t
for
all t ∈{K + 1, T}:
score(i →j) = σ({ci→j
K+1, ci→j
K+2, ..., ci→j
T
})
(7)

6
B. Bussmann et al.
In all of our experiments, we use the ReLU activation function and the Adam
optimizer [16] to train our networks. Our implementation of NAVAR and code to
reproduce the experiments can be found at: https://github.com/bartbussmann/NAVAR
4
Experiments
4.1
Interpretable Contributions
First, we investigate the ability of our model to learn interpretable nonlinear
causal dependencies on a toy dataset. We construct the dataset with three vari-
ables (N = 3) and 4000 time steps (T = 4000) based on the following SCM:
X(1)
t
= cos(X(2)
t−1) + tanh(X(3)
t−1) + η1
t
X(2)
t
= 0.35 · X(2)
t−1 + X(3)
t−1 + η2
t
X(3)
t
=
0.5 · X(1)
t−1
 + sin(2X(2)
t−1) + η3
t
where ηi
t ∼N(0, 1) for i = 1, 2, 3.
We train a NAVAR (MLP) model on this dataset and investigate the learned
contributions between pairs of variables. In Figure 2 we ﬁnd that the model has
learned contributions that are similar to the ground truth causal relationship.
Furthermore, we ﬁnd that for the pairs of variables that are not Granger causal,
the learned contribution function has very little variability. This illustrates that
our rationale for using the standard deviation of the learned contributions as
measure for Granger causal inﬂuence is appropriate.
Next, we investigate how to interpret the contributions when the underlying
data contains nonlinear interactions across multiple time lags. To this end, we
construct a second synthetic dataset with two variables (N = 2) and 4000 time
steps (T = 4000) based on the following structural causal model:
Figure 2. The learned contributions between pairs of variables in our synthetic dataset.
The learned contribution functions closely reﬂect the true causal inﬂuence, showing the
power of NAVAR models in both Granger causal discovery and interpretability. The
causality score from Equation (7) is given for each potential link. The scores of true
causal relationships are presented in boldface.

Neural Additive Vector Autoregression for Causal Discovery in Time Series
7
Figure 3. Left Panel: NAVAR discovers coupled nonlinearities within time series across
multiple lags. Contributions are shown for diﬀerent K to study the time lag (by masking
the input of the ﬁtted model at higher lags). The diagonal represents learned contribu-
tions that perfectly predict the target variable. At lags with true causal relationships,
the standard deviation of the contribution increases and the mean squared error (dis-
tance to the diagonal) decreases. Right panel: change in causal score from Equation
(7) when including K lags, with respect to the case of including K −1 lags. For cY →X,
we observe a high causal score contribution at K = 3, 4, 5, while for cX→Y we observe
high scores at K = 2, 4, both in agreement with the underlying SCM in Equation (8).
Xt = cos(Yt−3 + Yt−4 + Yt−5) + η1
t
Yt = Xt−2 · Xt−4 + η2
t
(8)
where ηi
t ∼N(0, 0.1) for i = 1, 2
We train a NAVAR (MLP) model with a maximum lag K = 8. Although
we do not enforce interpretable additive contributions of individual time lags
and thus cannot extract the isolated causal inﬂuence of individual time lags, we
can still investigate the eﬀect of leaving time lags out. Therefore, we mask the
input of the ﬁtted model from a certain maximum time lag. In Figure 3 three
observations can be made: (1) after adding a lag with a true causal link the
standard deviation of the contribution increases signiﬁcantly, which motivated
the use of our score function; (2) for time lags with a true causal link the mean
squared error decreases; (3) for time lags without a true causal relationship
neither of these change signiﬁcantly, showing that the model did not pick up on
spurious contributions (i.e. correlations). We point out that the above analysis
is made feasible due to the additive structure which allows us to study pairs
of variables in isolation from other contributions, and the sparsity penalty that
forces the model to consider mostly direct causes.
4.2
CauseMe - Earth Sciences Data
We evaluate our algorithm on various datasets on the CauseMe platform [19].
The CauseMe platform provides benchmark datasets to assess and compare the
performance of causal discovery methods. The available benchmarks contain

8
B. Bussmann et al.
both datasets generated from synthetic models mimicking real challenges, as
well as real-world data sets in the earth sciences where the causal structure
is known with high conﬁdence. The datasets vary in dimensionality, complex-
ity, and sophistication, and come with various challenges that are common in
real datasets, such as autocorrelation, nonlinearities, chaotic dynamics, extreme
events, nonstationarity, and measurement errors [29]. On the platform, users
have registered over 80 methods for Granger cause discovery.
We compare our methods with four baseline methods implemented by the
platform, namely: VAR [31], Adaptive LASSO [37], PCMCI [28], and FullCI
[30]. The VAR and Adaptive Lasso methods are both linear regression methods,
where the latter consists of computing several Lasso regressions with iterative
feature re-weighting. PCMCI and FullCI are constraint-based methods and per-
form conditional independence tests. Both of these algorithms come with three
diﬀerent independence tests, namely the linear ParCorr test and the nonlinear
GPDC and CMI tests. For these methods, we report the results of the best scor-
ing independence test. Furthermore, we compare NAVAR with SLARAC and
SELVAR [35], the two algorithms that won the NeurIPS 2019 Causality for Cli-
mate competition. SLARAC ﬁts a VAR model on bootstrap samples of the data,
each time choosing a random number of lags to include, whereas SELVAR selects
edges employing a hill-climbing procedure based on the leave-one-out residual
sum of squares of a VAR model.
Every experiment (e.g. Climate, with N=40, T=250) consists of 200 datasets.
For every experiment, we tune our hyperparameters (hidden units, batch size,
learning rate, contribution penalty coeﬃcient λ, and weight decay µ) on the ﬁrst
ﬁve datasets, of which we use the ﬁrst 80% for training and the ﬁnal 20% for
Table 1. Average AUROC on various datasets of the CauseMe platform. Performance
of the baseline methods Adaptive LASSO, PCMCI, and FullCI are not available for
the hybrid and real-world datasets. For each dataset, we provide the total number of
time steps T and the number of variables N. Datasets with purely linear dynamics are
indicated by an asterisk. Models with the highest AUROC are indicated in boldface.
Nonlinear VAR
Climate* Weather
River
N = 3
N = 5
N = 10 N = 20 N = 40
N = 10
N = 12
T = 300 T = 300 T = 300 T = 300 T = 250 T = 2000 T = 4600
NAVAR (MLP)
0.86
0.86
0.89
0.89
0.80
0.89
0.94
NAVAR (LSTM) 0.85
0.84
0.84
0.81
0.80
0.89
0.94
SELVAR
0.88
0.86
0.86
0.85
0.81
0.90
0.87
SLARAC
0.74
0.76
0.78
0.78
0.95
0.95
0.93
VAR
0.72
0.69
0.68
0.66
0.80
0.79
0.71
Ad. LASSO
0.82
0.79
0.79
0.78
-
-
-
PCMCI
0.85
0.82
0.83
0.82
-
-
-
FullCI
0.83
0.81
0.81
0.82
-
-
-

Neural Additive Vector Autoregression for Causal Discovery in Time Series
9
validation. The optimal hyperparameters are tabulated in Appendix A1. We set
the maximum lag parameter K based on information provided by CauseMe, and
train on every dataset for 5000 epochs. The AUROC scores are calculated by
the CauseMe platform, where self-links are ignored.
We run our method on the synthetic nonlinear VAR dataset, the hybrid cli-
mate and weather dataset, and the real-world river run-oﬀdataset. The results
in Table 1 show that NAVAR (MLP) models outperform the other methods
on most of the nonlinear VAR datasets. Interestingly, where the performance
of most methods declines as the number of variables N increases, the perfor-
mance of NAVAR (MLP) does not decrease. Noting the relative poor perfor-
mance of SLARAC on the nonlinear VAR dataset compared to its performance
on the linear climate dataset, we conclude that this algorithm is very well suited
for discovering exactly linear relationships. Although NAVAR models might be
slightly too ﬂexible for linear datasets, it outperforms the other methods on
the real-world river run-oﬀdataset. This strengthens our intuition that many
real-world processes can be modeled by an additive combination of nonlinear
functions.
4.3
DREAM3 - Gene Expression Data
Next, we evaluate our algorithm on the DREAM3 dataset, a simulated gene ex-
pression dataset [27]. The benchmark consists of ﬁve diﬀerent datasets of E.Coli
and yeast gene networks, each consisting of N = 100 variables. For every dataset,
46 time series are available, but every time series consists of only T = 21 time
steps. We compare NAVAR to other neural approaches to Granger causality,
namely componentwise-MLP (cMLP) and componentwise-LSTM (cLSTM) [33],
Temporal Causal Discovery Framework (TCDF) [20], and (economy) Statistical
Recurrent Units ((e)SRU) [15] (see Related Work).
1 Appendices and code can be found at https://github.com/bartbussmann/NAVAR
Table 2. Average AUROC on the DREAM3 gene expression dataset. Neural methods
are indicated with an asterisk, and their scores are obtained from [15]. Models with
the highest AUROC are indicated in boldface.
Model
E.Coli 1 E.Coli 2 Yeast 1 Yeast 2 Yeast 3
NAVAR (MLP)*
0.696
0.649
0.681
0.601
0.594
NAVAR (LSTM)* 0.715
0.682
0.695
0.599
0.597
cMLP*
0.644
0.568
0.585
0.506
0.528
cLSTM*
0.629
0.609
0.579
0.519
0.555
TCDF*
0.614
0.647
0.581
0.556
0.557
SRU*
0.657
0.666
0.617
0.575
0.550
eSRU*
0.660
0.629
0.627
0.557
0.550
SELVAR
0.551
0.536
0.556
0.516
0.534
SLARAC
0.580
0.509
0.526
0.503
0.494

10
B. Bussmann et al.
Similar to the models in [15], we assume a maximum lag of 2 for the MLP
models and use 10 hidden units per layer. We calculate the AUROC by increasing
a threshold over the causal score, where self-links are ignored in the calculation.
The hyperparameters are tuned using a 80/20% training/validation split, where
we train on the ﬁrst 80% of timesteps, and select the hyperparameters with lowest
mean squared error on the ﬁnal 20% time steps. The selected hyperparameters
are reported in Appendix A. The hyperparameters of the other neural models
are tuned in tantamount manner and can be found in [15, Appendix G]. We
report the average AUROC over 100 diﬀerent runs of the NAVAR model.
The results in Table 2 show that using deep learning to extract causal struc-
ture in time series is a non-trivial task. Our method, however, obtains the best
result on all datasets. Since both the MLP and LSTM backbone outperform the
other methods, we believe this is due to the imposed structure of our architec-
ture, where the direct contributions of a variable form a more reliable indicator
for causality than the methods that rely entirely on induced sparseness in the
weight matrices, such as in cMLP, cLSTM, and (e)SRU. Furthermore, using
permutation importance with neural networks, as in the TCDF model, is known
to generate misleading conclusions [12]. The large diﬀerence in performance be-
tween NAVAR (MLP) and NAVAR (LSTM) on the E.Coli datasets, demonstrate
the beneﬁts of exploring diﬀerent backbones for diﬀerent applications.
The linear methods are consistently outperformed by all neural methods on
this dataset, which clearly indicates the importance of nonlinearity in causal
structure discovery. On top of that, we also immediately obtain interpretable
predictions, as shown in Figure
4, where we show an example of the learned
Figure 4. Example of three learned contributions to gene 0 of E.Coli 1 of the DREAM3
dataset. The original data (blue) are normalized. The ﬁnal prediction is computed by
summing the contributions from all genes.

Neural Additive Vector Autoregression for Causal Discovery in Time Series
11
causal contributions in the E.Coli 1 gene network. The model captures that the
mNRA levels of gene 0 are mostly inﬂuenced by the past mNRA levels of this
gene itself. However, at the end of the time series, as the levels of gene 0 go
down, the inﬂuence from gene 1 and 14 pushes the gene 0 levels further down.
5
Related work
5.1
Neural Methods to Causal Structure Learning
Recently, there has been a rise in interest in applying deep learning to causal
structure learning, especially within the framework of Structural Causal Models
(SCM) [22, 25]. Research in larger graphs was limited due to a combinatori-
ally intractable search space of possible causal graphs. A key ingredient to the
solution was presented by Zheng et al. [36], who formulated structure learn-
ing as a continuous optimization problem. One of the key advantages of using
neural networks is that one can combine the structure learning objective and
the prediction objective into a single optimization problem. Other methods that
explore this avenue are [17], which extends the [36] method to nonlinear func-
tions modeled by neural networks, while still imposing acyclicity in the causal
network. Here, causal links are approximated by neural network paths. Bengio
et al. [4] and Ke et al. [14] use a meta-learning transfer objective to identify
causal structures from interventional data. The structural learning objective is
optimized by varying mask variables that represent the presence/missing of a
causal link. Kalainathan et al. [13] explore the use of generative models and
adversarial learning to reconstruct the causal graph.
5.2
Causal Structure Learning for Time Series Data
Since there is a direct connection between diﬀerential equations and structural
causal models [6], the functioning of many complex dynamical systems can be un-
derstood in terms of causal relationships. Therefore, there has been considerable
research devoted to discovering causal relationships in time series. Discovering
causal relationships in these temporal settings is more straightforward than in iid
data, in the sense that we can use the time-order to establish the directionality
of a causal relationship. Approaches that leverage this assumption exist in many
variations, such as non-parametric [3, 8], model-based [18, 23], constraint-based
[30], and information theoretic [21] approaches.
Despite the broad range of research in Granger causality in time series, only
limited research has applied the representational power of deep learning to this
task. A possible reason for this is that the main challenge in causal structure
learning is that the ﬁnal product is the interpretation of the dependencies be-
tween the variables, which are directly related to the causal connections. How-
ever, interpretation is known to be the Achilles heel of black-box tools such as
deep learning.
Other works that do use neural networks, such as [34, 9, 1], ﬁrst focused
on a brute force approach to estimate feature importance, where the Granger

12
B. Bussmann et al.
causal link i →j is estimated by the predictive power of a model for X(j)
t
that
includes the past of all variables, compared to a similar model where the past of
the variable X(i) is excluded from the input. However, such an approach is not
scalable when the number of variables increases.
The Temporal Causal Discovery Framework (TCDF) [20] uses a attention-
based (causal) convolutional neural network. They consider attention scores and
introduce permutation importance to identify causal links in an additional causal
validation step. Most similar to our work, Tank et al. [33] proposed a neu-
ral Granger causal model by using sparse component-wise MLPs (cMLP) and
LSTMs (cLSTM). This approach induces sparsity on the causal links by using
a hierarchical group regularization. Khanna and Tan [15] use (economical) Sta-
tistical Recurrent Units to model the Granger causal dependencies, in a similar
vein to the cLSTMs of [33]. Both methods use proximal gradient descent with
line search to obtain interpretable results. Proximal optimization is necessary to
induce exact zeros in the weight matrices of the ﬁrst layer. Exact zeros are then
interpreted as a missing Granger causal link.
In contrast, we do not limit the input features of our model, but instead,
enforce interpretability directly into the architecture of our neural network by
restricting the function class to produce additive features. This helps in ex-
tracting the correct causal relationships between variables, as we can directly
regularize the causal summary graph instead of individual input features. Since
every prediction is a sum of scalar contributions from the other variables, dis-
entangling the eﬀect of the diﬀerent inputs becomes trivial and causal inﬂuence
can be deduced intuitively.
5.3
Neural networks as Generalised Additive Models
In this work, we restrict the structure of the network in order to ﬁnd the Granger
causes of each time series. In particular, our model can be viewed as a Generalized
Additive Model (GAM). In the general case, a GAM takes the form:
g(E[y]) = β + f1(x1) + f2(x2) + .. + fn(xn)
(9)
One of the main advantages of using GAMs is that the models are consid-
erably more interpretable than many black-box methods since the individual
contributions are disentangled and evident. The beneﬁt of assuming additive
models was studied in [7, 24], but not in the context of neural networks or time
series.
The use of deep learning to represent the functions fi in equation (9) was
ﬁrst explored in [26] under the name Generalized Additive Neural Networks
(GANNs). For a long time after, this avenue has not been explored further.
Interestingly, however, in parallel to this work Agarwal et al. [2] explored the
power of Neural Additive Models (NAM) as a predictive model for tabular data
with mixed data types. Agarwal et al. [2] introduced exp-centered hidden units
(ExU) to allow neural networks to easily approximate ‘jumpy functions’, which
is necessary when considering tabular data.

Neural Additive Vector Autoregression for Causal Discovery in Time Series
13
6
Discussion
We presented a neural additive extension to the autoregression framework for
(Granger) causal discovery in time series, which we call NAVAR models. The
choice of this architecture was guided by the success of VAR models in this con-
text as well as by generalised additive methods as a natural extension to linear
methods. We showed that neural additive models have the power to discover
nonlinear relationships between time series, while they can still provide an in-
tuitive interpretation of the learned causal interactions. Despite the fact that
NAVAR does not account for higher-order interaction terms, benchmarks over
a variety of datasets show that NAVAR models are more reliable than existing
methods in uncovering the causal structure.
There are many interesting directions for future research. We have shown
that NAVAR models already work with MLPs and LSTMs as backbone, but
we can easily imagine more complex architectures, such as (dilated) CNNs and
Transformers. Furthermore, it could be interesting to investigate bayesian neu-
ral networks in order to evaluate the uncertainty of a found causal model. Fi-
nally, important future work could be improvements to the model that explic-
itly account for unobserved confounders, non-stationarity, and contemporaneous
causes.
Acknowledgements This project has received funding from the European
Union’s Horizon 2020 research and innovation programme under the Marie Sk lodowska-
Curie grant agreement No 813114.
References
[1] Zahra Abbasvandi and Ali Motie Nasrabadi.
A self-organized recurrent
neural network for estimating the eﬀective connectivity and its application
to eeg data. Computers in biology and medicine, 110:93–107, 2019.
[2] Rishabh Agarwal, Nicholas Frosst, Xuezhou Zhang, Rich Caruana, and Ge-
oﬀrey E Hinton. Neural additive models: Interpretable machine learning
with neural nets. arXiv preprint arXiv:2004.13912, 2020.
[3] Ehung Baek and William Brock. A general test for nonlinear granger causal-
ity: Bivariate model. Iowa State University and University of Wisconsin at
Madison Working Paper, 1992.
[4] Yoshua Bengio, Tristan Deleu, Nasim Rahaman, Rosemary Ke, S´ebastien
Lachapelle, Olexa Bilaniuk, Anirudh Goyal, and Christopher Pal. A meta-
transfer objective for learning to disentangle causal mechanisms.
arXiv
preprint arXiv:1901.10912, 2019.
[5] James S Bergstra, R´emi Bardenet, Yoshua Bengio, and Bal´azs K´egl. Algo-
rithms for hyper-parameter optimization. In Advances in neural information
processing systems, pages 2546–2554, 2011.
[6] Stephan Bongers and Joris M Mooij.
From random diﬀerential equa-
tions to structural causal models: The stochastic case.
arXiv preprint
arXiv:1803.08784, 2018.

14
B. Bussmann et al.
[7] Peter B¨uhlmann, Jonas Peters, Jan Ernest, et al. Cam: Causal additive
models, high-dimensional order search and penalized regression. The Annals
of Statistics, 42(6):2526–2556, 2014.
[8] Yonghong Chen, Steven L Bressler, and Mingzhou Ding. Frequency decom-
position of conditional granger causality and application to multivariate
neural ﬁeld potential data. Journal of neuroscience methods, 150(2):228–
237, 2006.
[9] Andrea Duggento, Maria Guerrisi, and Nicola Toschi. Echo state network
models for nonlinear granger causality. bioRxiv, page 651679, 2019.
[10] Felix A Gers, J¨urgen Schmidhuber, and Fred Cummins. Learning to for-
get: Continual prediction with lstm. Neural computation, 12(10):2451–2471,
2000.
[11] Clive WJ Granger. Investigating causal relations by econometric models and
cross-spectral methods. Econometrica: journal of the Econometric Society,
pages 424–438, 1969.
[12] Giles Hooker and Lucas Mentch. Please stop permuting features: An expla-
nation and alternatives. arXiv preprint arXiv:1905.03151, 2019.
[13] Diviyan Kalainathan, Olivier Goudet, Isabelle Guyon, David Lopez-Paz,
and Mich`ele Sebag. Sam: Structural agnostic model, causal discovery and
penalized adversarial learning. arXiv preprint arXiv:1803.04929, 2018.
[14] Nan Rosemary Ke, Olexa Bilaniuk, Anirudh Goyal, Stefan Bauer, Hugo
Larochelle, Chris Pal, and Yoshua Bengio. Learning neural causal models
from unknown interventions. arXiv preprint arXiv:1910.01075, 2019.
[15] Saurabh Khanna and Vincent YF Tan. Economy statistical recurrent units
for inferring nonlinear granger causality. arXiv preprint arXiv:1911.09879,
2019.
[16] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic opti-
mization. arXiv preprint arXiv:1412.6980, 2014.
[17] S´ebastien Lachapelle, Philippe Brouillard, Tristan Deleu, and Simon
Lacoste-Julien.
Gradient-based neural dag learning.
arXiv preprint
arXiv:1906.02226, 2019.
[18] Daniele Marinazzo, Wei Liao, Huafu Chen, and Sebastiano Stramaglia. Non-
linear connectivity by granger causality. Neuroimage, 58(2):330–338, 2011.
[19] J Mu˜noz-Mar´ı, G Mateo, J Runge, and G Camps-Valls. Causeme: An online
system for benchmarking causal discovery methods. In preparation., 2020.
[20] Meike Nauta, Doina Bucur, and Christin Seifert. Causal discovery with
attention-based convolutional neural networks.
Machine Learning and
Knowledge Extraction, 1(1):312–340, 2019.
[21] Angeliki Papana, Catherine Kyrtsou, Dimitris Kugiumtzis, and Cees Diks.
Detecting causality in non-stationary time series using partial symbolic
transfer entropy: evidence in ﬁnancial data. Computational economics, 47
(3):341–365, 2016.
[22] Judea Pearl. Causal diagrams for empirical research. Biometrika, 82(4):
669–688, 1995.
[23] Jonas Peters, Dominik Janzing, and Bernhard Sch¨olkopf. Causal inference
on time series using restricted structural equation models.
Advances in
Neural Information Processing Systems, 26:154–162, 2013.

Neural Additive Vector Autoregression for Causal Discovery in Time Series
15
[24] Jonas Peters, Joris M Mooij, Dominik Janzing, and Bernhard Sch¨olkopf.
Causal discovery with continuous additive noise models. The Journal of
Machine Learning Research, 15(1):2009–2053, 2014.
[25] Jonas Peters, Dominik Janzing, and Bernhard Sch¨olkopf. Elements of causal
inference: foundations and learning algorithms. MIT press, 2017.
[26] William JE Potts. Generalized additive neural networks. In Proceedings of
the ﬁfth ACM SIGKDD international conference on Knowledge discovery
and data mining, pages 194–200, 1999.
[27] Robert J Prill, Daniel Marbach, Julio Saez-Rodriguez, Peter K Sorger,
Leonidas G Alexopoulos, Xiaowei Xue, Neil D Clarke, Gregoire Altan-
Bonnet, and Gustavo Stolovitzky. Towards a rigorous assessment of systems
biology models: the dream3 challenges. PloS one, 5(2), 2010.
[28] Jakob Runge. Causal network reconstruction from time series: From the-
oretical assumptions to practical estimation. Chaos: An Interdisciplinary
Journal of Nonlinear Science, 28(7):075310, 2018.
[29] Jakob Runge, Sebastian Bathiany, Erik Bollt, Gustau Camps-Valls, Dim
Coumou, Ethan Deyle, Clark Glymour, Marlene Kretschmer, Miguel D Ma-
hecha, Jordi Mu˜noz-Mar´ı, et al. Inferring causation from time series in earth
system sciences. Nature communications, 10(1):1–13, 2019.
[30] Jakob Runge, Peer Nowack, Marlene Kretschmer, Seth Flaxman, and Dino
Sejdinovic. Detecting and quantifying causal associations in large nonlinear
time series datasets. Science Advances, 5(11):eaau4996, 2019.
[31] Skipper Seabold and Josef Perktold. Statsmodels: Econometric and statis-
tical modeling with python. In Proceedings of the 9th Python in Science
Conference, volume 57, page 61. Scipy, 2010.
[32] Klaas Enno Stephan, Lars Kasper, Lee M Harrison, Jean Daunizeau, Han-
neke EM den Ouden, Michael Breakspear, and Karl J Friston. Nonlinear
dynamic causal models for fmri. Neuroimage, 42(2):649–662, 2008.
[33] Alex Tank, Ian Covert, Nicholas Foti, Ali Shojaie, and Emily Fox. Neural
granger causality for nonlinear time series. stat, 1050:16, 2018.
[34] Yueming Wang, Kang Lin, Yu Qi, Qi Lian, Shaozhe Feng, Zhaohui Wu,
and Gang Pan.
Estimating brain connectivity with varying-length time
lags using a recurrent neural network. IEEE Transactions on Biomedical
Engineering, 65(9):1953–1963, 2018.
[35] Sebastian Weichwald, Martin E Jakobsen, Phillip B Mogensen, Lasse Pe-
tersen, Nikolaj Thams, and Gherardo Varando. Causal structure learning
from time series: Large regression coeﬃcients may predict causal links better
in practice than small p-values. arXiv preprint arXiv:2002.09573, 2020.
[36] Xun Zheng, Bryon Aragam, Pradeep K Ravikumar, and Eric P Xing. Dags
with no tears: Continuous optimization for structure learning. In Advances
in Neural Information Processing Systems, pages 9472–9483, 2018.
[37] Hui Zou.
The adaptive lasso and its oracle properties.
Journal of the
American statistical association, 101(476):1418–1429, 2006.

