A fast and scalable computational framework for large-scale and
high-dimensional Bayesian optimal experimental design
Keyi Wu, Peng Chen, Omar Ghattas
Abstract
We develop a fast and scalable computational framework to solve large-scale and high-dimensional
Bayesian optimal experimental design problems. In particular, we consider the problem of optimal
observation sensor placement for Bayesian inference of high-dimensional parameters governed by
partial diﬀerential equations (PDEs), which is formulated as an optimization problem that seeks
to maximize an expected information gain (EIG). Such optimization problems are particularly
challenging due to the curse of dimensionality for high-dimensional parameters and the expensive
solution of large-scale PDEs. To address these challenges, we exploit two essential properties of
such problems: (1) the low-rank structure of the Jacobian of the parameter-to-observable map to
extract the intrinsically low-dimensional data-informed subspace, and (2) the high correlation of
the approximate EIGs by a series of approximations to reduce the number of PDE solves. Based
on these properties, we propose an eﬃcient oﬄine-online decomposition for the optimization prob-
lem: an oﬄine stage of computing all the quantities that require a limited number of PDE solves
independent of parameter and data dimensions, which is the dominant cost, and an online stage
of optimizing sensor placement that does not require any PDE solve. For the online optimization,
we propose a swapping greedy algorithm that ﬁrst construct an initial set of sensors using leverage
scores and then swap the chosen sensors with other candidates until certain convergence criteria are
met. We demonstrate the eﬃciency and scalability of the proposed computational framework by
a linear inverse problem of inferring the initial condition for an advection-diﬀusion equation, and
a nonlinear inverse problem of inferring the diﬀusion coeﬃcient of a log-normal diﬀusion equation,
with both the parameter and data dimensions ranging from a few tens to a few thousands.
Keywords: optimal experimental design, Bayesian inverse problems, expected information gain,
swapping greedy algorithm, low-rank approximation, oﬄine-online decomposition
1
Introduction
In mathematical modeling and computational simulation in many scientiﬁc and engineering ﬁelds,
uncertainties are ubiquitous, which may arise from model coeﬃcients, initial or boundary conditions,
external loads, computational geometries, etc. It is crucial to quantify and reduce such uncertain-
ties for more accurate and reliable computational prediction and model-based system optimization.
Bayesian inference provides an optimal framework for quantifying the uncertainties with suitable prior
probability distribution based on domain knowledge or expert belief, and reducing the uncertainties
characterized by their posterior probability distribution through fusing noisy experimental or observa-
tional data with the model using Bayes’ rule. However, it is challenging to acquire enough data if the
experiment is expensive or time consuming. In this situation, only a limited number of data can be
acquired given budget or time constraint. How to design the experiment such that the limited data
can reduce the uncertainties as much as possible becomes very important, which is the central task of
optimal experimental design (OED) [9, 3, 2, 34, 35, 4, 42, 23, 10, 27, 28, 29, 8, 7].
OED problems can be generally formulated as minimizing or maximizing certain criterion that rep-
resents the uncertainty, e.g., the trace (A-optimality) or determinant (D-optimality) of the posterior
1
arXiv:2010.15196v1  [math.NA]  28 Oct 2020

covariance. In the Bayesian framework, a common choice is an expected information gain (EIG), where
the information gain is measured by a Kullback–Leibler divergence between the posterior distribution
and the prior distribution, and the expected value is taken as an average of this measure at all realiza-
tions of the data. Consequently, two integrals are involved in evaluating the EIG, one with respect to
the posterior distribution and the other with respect to the data distribution. Several computational
challenges are faced to evaluate the EIG, which includes: (1) evaluation of the double integrals with
one involving integration with respect to the posterior distribution may require a large number of
samples from the posterior distribution, especially if the uncertain parameters are high-dimensional;
(2) the parameter-to-observable map at each sample is expensive to evaluate so only a limited number
of map evaluation can be aﬀorded, which is often the case when the map evaluation involves solution
of large-scale models, e.g., represented by partial diﬀerential equations. For example, in underground
ﬂuid ﬂow one needs to infer the inﬁnite-dimensional permeability ﬁeld from observation of the ﬂuid
velocity or pressure at some locations, or in contaminant diﬀusion and transportation one needs to
infer its source or inﬁnite-dimensional initial concentration ﬁeld from observation of the concentration
at certain locations and time instances. Both of the examples feature large-scale models with high-
dimensional parameters after (high-ﬁdelity) discretization. Moreover, when the space for the possible
experimental design is also high-dimensional, e.g., the number of candidate sensor locations for the
observation is high, one faces the challenge of solving high-dimensional optimization problems, i.e.,
maximizing the EIG with respect to the high-dimensional design variable.
Related Work. OED problems with the above computational challenges have attracted increas-
ing attention in recent years. An inﬁnite-dimensional version of Kullback-Leibler divergence involved
in the EIG is studied in [2]. For linear problems, i.e., the parameter-to-observation map is linear in
the parameter, the EIG is equivalent to the D-optimal design, which measures the log-determinant
of the prior-covariance preconditioned misﬁt Hessian, whose computation depends on its dominant
eigenvalues. The fast decay of the eigenvalues has been proven for some model problems and nu-
merically demonstrated for many others [15, 16, 4, 5, 3, 23, 40, 30, 42, 18, 6, 21, 19, 22, 20]. Based
on this property, eﬃcient methods have been developed to evaluate D-optimal criterion for inﬁnite-
dimensional Bayesian linear problems [42, 43]. In [6], the authors exploited this property and proposed
a gradient-based optimization method for D-optimal experimental design, which was extended in [10]
for goal-oriented optimal design of experiments. For nonlinear problems, a direct statistical estimator
of EIG is double-loop Monte Carlo(DLMC) [12], which approximates the EIG via inner and outer
Monte Carlo sample average approximations (double loops). Both loops need to generate a large num-
ber of samples requiring multiple PDE solves for each sample. The authors of [34, 35] proposed to
approximate the EIG with Laplace approximations, which involve numerous inverse problem solves and
eigenvalue decomposition of prior-preconditioned misﬁt Hessian. The optimal design is obtained by an
exhaustive search over a prespeciﬁed set of experimental scenarios. Polynomial chaos expansion was
employed in [27, 28, 29] as a surrogate for the expensive PDE model, which is however not suitable for
solving OED problems with high-dimensional parameters. The authors of [32] introduced a Bayesian
methodology for optimal sensor placement with D-optimal criterion for quasi-linear problems and used
a greedy algorithm to sequentially select observation locations. [46] presented a scalable framework for
sensor placement for PDE problems with Laplace approximation and investigated two criteria (total
ﬂow variance and A-optimal design) with a sparsity-inducing approach and a sum-up rounding ap-
proach to ﬁnd the optimal design. Both approaches ﬁrst relax the binary constraints to continuous
function constraints to solve the easier continuous optimization problem, and then induce the integer
solution. [36] considered problems of sensor placement for signal reconstruction in a scalable framework
with D-optimal criterion and compared the accuracy and eﬃciency between convex optimization and
QR pivoting (greedy method) to ﬁnd the optimal design. The author of [38] proposed a formulation
of optimal sensor placement problem with Laplace method to approximate the expected information
gain, and introduced a sequential sensor searching algorithm to ﬁnd the optimal sensors. However, in
2

all these papers, many expensive PDEs have to be solved in each optimization iteration, either the
greedy algorithms to sequentially add sensors or the optimization algorithms to simultaneously update
sensors, which may lead to prohibitively large number of expensive PDEs to solve, especially when the
parameter dimension or the data dimension is big.
Contributions. To address the computational challenges for Bayesian OED problems of maxi-
mizing EIG with large-scale models and high-dimensional parameters, we propose a fast and scalable
computational framework, fast in that only a limited number of the large-scale models are solved,
scalable in that the computational complexity is independent of both the parameter dimension and
the data dimension. These advantages are made possible by (1) using a sequence of approximation
of the posterior including Laplace approximation, low-rank approximation of the posterior covariance,
replacement of the design dependent MAP point for the Laplace approximation by a ﬁxed MAP point
and a prior sample point, (2) exploiting an eﬃcient oﬄine-online decomposition of the computation,
oﬄine solving all the large-scale models and online solving the model-independent optimization prob-
lem, (3) proposing a swapping greedy algorithm used in the online stage to ﬁnd the optimal design
whose computational complexity depends only on the dimension of the subspace informed by the data,
not on the nominal parameter and data dimensions. More speciﬁcally, for linear problems where maxi-
mizing the EIG is equivalent to minimizing the D-optimality, we derive a new approximate form of the
D-optimal criterion for which each evaluation of diﬀerent designs does not involve any PDE solves. We
introduce a swapping greedy algorithm that exploit the dominant data subspace information quantiﬁed
by the Jacobian of the parameter-to-observable map to search for an optimal design. For nonlinear
problems, we use Laplace approximation and exploit the high correlation of the approximate EIGs
with the Laplace approximation centered at diﬀerent points. Moreover, we propose an eﬃcient oﬄine-
online decomposition of the optimization problem where the key information is extracted in the oﬄine
stage by solving a limited number of PDEs, which is then used in the online stage to ﬁnd the op-
timal design by the swapping greedy algorithm. We demonstrate the eﬀectiveness and scalability of
our computational framework by two numerical experiments, a linear inverse problem of inferring the
initial condition for an advection-diﬀusion equation, and a nonlinear inverse problem of inferring the
diﬀusion coeﬃcient of a log-normal diﬀusion equation, with both the parameter and data dimensions
ranging from a few tens to a few thousands.
Paper overview. In Section 2, we review inﬁnite-dimensional Bayesian inverse problem with ﬁnite-
element discretization. We also review the expected information gain optimal criterion, including the
speciﬁc formulation for sensor placement problems. In Section 3, we present the optimal experimental
design problem for Bayesian linear inverse problems and its discretization to ﬁnite dimensions. We
propose an eﬃcient approach to evaluate the criterion and introduce a swapping greedy algorithm to
search for an optimal design. In Section 4, we introduce the optimal experimental design problem for
nonlinear model with Laplace approximation and its discretization to ﬁnite dimension. We formulate
a new framework with several further approximations, and extend our greedy algorithm into this
framework. Section 5 presents our numerical results for both linear and nonlinear Bayesian inverse
problems, followed by the last Section 6 for conclusions.
2
Bayesian optimal experimental design
In this section, we present a general formulation Bayesian inverse problem for an abstract forward
model and an inﬁnite-dimensional parameter ﬁeld, which is discretized by ﬁnite element approximation
to be ﬁnite dimensional. We present the optimal experimental design problem as an optimal selection
of the sensor locations among candidate sensor locations, based on a commonly used design criterion—
expected information gain.
3

2.1
Bayesian inverse problem
We consider a forward model presented in an abstract form as
R(u, m) = 0
in V′,
(1)
where u is the state variable in a separable Banach space V with its dual V′ deﬁned in a physical
domain D ⊂Rnx with Lipschitz boundary ∂D, where nx = 1, 2, 3; m is the parameter ﬁeld to be
inferred, which is assumed to live in a Hilbert space M deﬁned in D; R(·, ·) : V × M →V′ represents
the strong form of the forward model, whose weak form can be written as: ﬁnd u ∈V such that
r(u, m, v) := V⟨v, R(u, m)⟩V′ = 0
∀v ∈V,
(2)
where V⟨·, ·⟩V′ denotes the duality pairing.
The data model with additive Gaussian noise is given as
y = B(u) + ϵ,
(3)
where B : V →Rny is an observation operator that maps the state variable to the data y ∈Y = Rny at
ny observation points, corrupted with an additive Gaussian noise ϵ ∼N(0, Γn) with symmetric positive
deﬁnite covariance matrix Γn ∈Rny×ny. For notational convenience, we denote the parameter-to-
observable map F as
F(m) = B(u(m)).
(4)
We consider that m has a Gaussian prior measure µpr = N(mpr, Cpr) with mean mpr ∈M and
covariance operator Cpr : M →M′ from M to its dual M′, which is a strictly positive self-adjoint
operator of trace class. In particular, we use Cpr = A−α for suﬃciently large α > 0, such that 2α > nx,
to guarantee that Cpr is of trace class, where A is an elliptic diﬀerential operator equipped with homo-
geneous Neumann boundary condition along the boundary ∂D [40]. This choice of prior guarantees a
bounded pointwise variance and a well-posed inﬁnite-dimensional Bayesian inverse problem.
Under the assumption of Gaussian noise for ϵ, the likelihood function πlike(y|m) satisﬁes
πlike(y|m) ∝exp(−Φ(m, y)),
(5)
where the potential Φ(m, y) is deﬁned as
Φ(m, y) := 1
2 ∥F(m) −y∥2
Γ−1
n ,
(6)
where ||v||2
Γ−1
n
= vT Γ−1
n v for any mathbfv ∈Rny. By Bayes’ rule, the posterior measure µpost(m|y)
of the parameter m conditioned on the observation data y is given by the Radon-Nikodym derivative
as
dµpost(m|y)
dµpr(m)
= 1
Z πlike(y|m),
(7)
where Z is a normalization constant given by
Z =
Z
M
πlike(y|m)dµpr(m).
(8)
2.2
Discretization of the Bayesian inverse problem
The parameter ﬁeld m ∈M in the Hilbert space M is inﬁnite-dimensional. For computational
purpose, we use a ﬁnite element discretization to approximate it in a subspace Mn ⊂M of dimension
n, which is spanned by piecewise continuous Lagrange polynomial basis functions {φj}n
j=1 deﬁned over
4

a mesh with elements of size h and vertices {xj}n
j=1, such that φj(xi) = δij, i, j = 1, . . . , n, where δij
denote the Kronecker delta. The approximation of the parameter m ∈M in Mn, denoted as mh, can
be expressed as
mh =
n
X
j=1
mjφj.
(9)
Here we denote m = (m1, . . . , mn)T ∈Rn as the coeﬃcient vector of mh.
Let M denote the ﬁnite element mass matrix whose entries are given by
Mij =
Z
D
φi(x)φj(x)dx, i, j = 1, . . . , n.
(10)
Let A denote the ﬁnite element matrix corresponding to the elliptic diﬀerential operator A, i.e.,
Aij =
Z
D
M′⟨Aφj(x), φi(x)⟩Mdx,
i, j = 1, . . . , n.
(11)
With the speciﬁcation of the parameter α = 2, which satisﬁes 2α > d for d ≤3, we obtain a discrete
covariance matrix Γpr corresponding to the covariance operator Cpr, given by
Γpr = A−1MA−1.
(12)
Then, the prior density for the coeﬃcient vector m, which we also call discrete parameter, is given by
πpr(m) ∝exp

−1
2||m −mpr||2
Γ−1
pr

,
(13)
where mpr ∈Rn is the coeﬃcient vector of the approximation of the prior mean mpr in the ﬁnite
element space Mn. Correspondingly, the posterior density of the discrete parameter m follows the
Bayes’ rule
πpost(m|y) = 1
Z πlike(y|m)πpr(m),
(14)
where πlike(y|m) is the likelihood function for the discrete parameter m given by
πlike(y|m) ∝exp (−Φ(m, y)) ,
(15)
with the potential
Φ(m, y) = 1
2||F(m) −y||2
Γ−1
n ,
(16)
where F : Rn →Rny denotes the discrete parameter-to-observable map corresponding to (4), which
involves the solution of the forward model (2) by a ﬁnite element discretization in a subspace Vnu ⊂V
spanned by basis functions {ψj}nu
j=1, in which, the ﬁnite element state uh = Pnu
j=1 ujψj with coeﬃcient
vector u = (u1, . . . , unu)T .
2.3
Expected information gain
To measure the information gained from the observation data, diﬀerent information criteria have
been used, e.g., A-optimal or D-optimal criterion, which uses the trace or determinant of the covariance
of the posterior [1]. Here we choose to use an expected information gain (EIG), which is the Kullback–
Leibler (KL) divergence between the posterior and the prior averaged over all data realizations. The
KL divergence, denoted as DKL, also known as the information gain, is used to measure the information
gained from data y, which is deﬁned as
DKL(µpost(·|y)∥µpr) :=
Z
H
ln
dµpost(m|y)
dµpr(m)

dµpost(m|y).
(17)
5

The EIG, denoted as Ψ, takes all possible realizations of the data y ∈Y into account, which is
deﬁned as
Ψ := Ey [DKL(µpost(·|y)∥µpr)]
=
Z
Y
DKL(µpost(·|y)∥µpr) π(y) dy
=
Z
Y
Z
H
DKL(µpost(·|y)∥µpr) πlike(y|m) dµpr(m) dy
=
Z
H
Z
Y
DKL(µpost(·|y)∥µpr) πlike(y|m) dy dµpr(m),
(18)
where π(y) in the second equality is the density of the data y, which follows a Gaussian distribu-
tion N(F(m), Γn) conditioned on the parameter m, i.e., π(y) = πlike(y|m) dµpr(m) which is used in
the third equality. The fourth equality is obtained by switching the order of integration under the
assumption that DKL(µpost(·|y)∥µpr) is integrable by Fubini theorem. An eﬃcient evaluation of the
KL divergence in is presented in Sections 3 and 4 for linear and nonlinear Bayesian inverse problems,
respectively.
2.4
Optimal experimental design for sensor placement
We consider a sensor placement problem in which we have a set of candidate sensor locations
{xi}d
i=1 in the physical domain D, among which we need to choose r locations (due to limited budget)
to place the sensors for data collection. To represent the selection, we use a design matrix W, which is
a boolean matrix W ∈Rr×d such that Wij = 1 if the i-th sensor is placed at the j-th candidate sensor
location, i.e.,
W ∈W :=


W ∈Rr×d : Wij ∈{0, 1},
d
X
j=1
Wij = 1,
r
X
i=1
Wij ∈{0, 1}


.
(19)
We consider the case of uncorrelated observation noises with covariance matrix
Γd
n = diag(σ2
1, . . . , σ2
d)
(20)
at d candidate sensor locations, where σ2
j indicates the noise level at the j-th candidate sensor location.
By Bd we denote the observation operator at all d candidate sensor locations. For a speciﬁc design
W, we have the observation operator B = WBd, so that the EIG Ψ(W) depends on the design matrix
through the observation operator B. To this end, the optimal experimental design problem can be
formulated as: ﬁnd an optimal design matrix W ∈W such that
W = arg max
W ∈W
Ψ(W).
(21)
3
Linear Bayesian inverse problems
We consider linear Bayesian inverse problems in this section, where the parameter-to-observable
map F(m) is linear with respect to the parameter m. In the following, we present an explicit form
of the EIG for the linear inverse problem, derive an optimization problem that can be divided into
an “oﬄine” phase of computing the expensive part that involves solution of the forward model and
an “online” phase of optimization with respect to the design matrix, which is free from solving the
forward model, and introduce two greedy algorithms for the online phase of optimization.
6

3.1
Expected information gain
Given a Gaussian prior measure µpr = N (mpr, Cpr), for a linear parameter-to-observable map F,
the posterior measure µpost is also Gaussian, µpost = N (mpost, Cpost), with
Cpost = (F∗Γ−1
n F + C−1
pr )−1,
mpost = Cpost(F∗Γ−1
n y + C−1
pr mpr),
(22)
where F∗is the adjoint of F. For the Gaussian prior and posterior, we have a closed form for the KL
divergence deﬁned in (17) as [2]
DKL(µpost∥µpr) = 1
2
h
logdet

I + e
Hm

−tr(C
1
2
postHmC
1
2
post) + ∥mpost −mpr∥2
C−1
pr
i
.
(23)
Here e
Hm = C
1
2pr Hm C
1
2pr is a prior-preconditioned data misﬁt Hessian, and Hm = F∗Γ−1
n F is the Hessian
of the potential Φ(m, y). The term logdet

I + e
Hm

is the logarithm of the determinant of I + e
Hm,
and tr(C
1
2
postHmC
1
2
post) is the trace of C
1
2
postHmC
1
2
post. Moreover, it is shown in [1] that the EIG is simply
Ψ = 1
2 logdet

I + e
Hm

.
(24)
By the discretization in Section 2.2, we obtain the discrete Gaussian posterior measure N(mpost, Γpost)
with covariance and mean
Γpost = (FT Γ−1
n F + Γ−1
pr )−1,
mpost = Γpost(FT Γ−1
n y + Γ−1
pr mpr).
(25)
where FT ∈Rny×n is the discrete linear parameter-to-observable map and FT is its transpose. Let
Hm = FT Γ−1
n F, and eHm = Γ
1
2prHmΓ
1
2pr with the discrete prior covariance Γpr, we obtain a discrete
EIG corresponding to (24) as
Ψ = 1
2 logdet

I + eHm

.
(26)
When the dimension of the discrete parameter m becomes large, and the discrete parameter-to-
observable map F involves the inverse of some large-scale discrete diﬀerential operator, it is compu-
tationally prohibitive to compute eHm in (26). However, by the blessing of the common ill-posedness
of high-dimensional inverse problems, i.e., the data only eﬀectively infer a low-dimensional subspace
of the high-dimensional parameter space, which is depicted by a fast decay of the eigenvalues of the
Hessian eHm, we can compute a low-rank approximation of the Hessian (with certain transformation)
as detailed in next section.
3.2
Low rank approximation
For the design problem deﬁned in section 2.4, we denote Fd as the discretized parameter-to-
observable map at all the d candidate sensor locations. Then for a speciﬁc design W, we have
F = WFd
and FT = FT
d W T .
(27)
We present an eﬃcient approximation of the discrete EIG given in (26) and establish an error estimate
for the approximation. To start, we need the following results, which are proven in [6] for Proposition
3.1 and in [41] for Proposition 3.2.
Proposition 3.1. Let A, B ∈Cn×n be Hermitian positive semideﬁnite with A ≥B, then
0 ≤log det(I + A) −log det(I + B) ≤log det(I + A −B).
(28)
7

Proposition 3.2. Let A and B be matrices of size m × n and n × m respectively, then
det(In×n + BA) = det(Im×m + AB),
(29)
which is known as Weinstein-Aronszajn identity.
Theorem 3.3. Let Hd := ˆFd Γpr ˆFT
d ∈Rd×d with ˆFd = (Γd
n)−1
2 Fd, where Γd
n is deﬁned in (20). We
compute a low-rank decomposition of Hd as
ˆHd = UkΣkU T
k ,
(30)
where (Σk, Uk) represent the k dominant eigenpairs, with Σk = diag(λ1, . . . , λk) for eigenvalues λ1 ≥
· · · ≥λk. Moreover, let ˆΨ denote an approximate EIG deﬁned as
ˆΨ(W) := 1
2 logdet

Ir×r + W ˆHdW T 
.
(31)
Then we have
0 ≤Ψ(W) −ˆΨ(W) ≤1
2
d
X
i=k+1
log(1 + λi),
(32)
where λk+1, . . . , λd are the remaining eigenvalues of Hd.
Proof. For the deﬁnition of eHm = Γ
1
2prFT Γ−1
n FΓ
1
2pr, we ﬁrst denote ˆF = Γ
−1
2
n
F. Then using (27) we
have
ˆF = Γ
−1
2
n
WFd = W(Γd
n)−1
2 Fd = W ˆFd.
(33)
We can write the form of EIG in (26) as
Ψ(W) = 1
2 logdet

In×n + Γ
1
2prFT Γ−1
n FΓ
1
2pr

= 1
2 logdet

In×n + Γ
1
2pr ˆFT ˆFΓ
1
2pr

= 1
2 logdet

In×n + Γ
1
2pr ˆFT
d W T W ˆFd Γ
1
2pr

,
(34)
where in the second equality we use the relation (27).
By the Weinstein-Aronszajn identity (29), we have
Ψ(W) = 1
2 logdet

Ir×r + W ˆFd Γ
1
2prΓ
1
2pr ˆFT
d W T 
(35)
= 1
2 logdet
 Ir×r + WHdW T 
,
(36)
where in the second equality we use the deﬁnition of Hd. We denote the eigenvalue decomposition of
Hd as
Hd = UkΣkU T
k + U⊥Σ⊥U T
⊥,
(37)
where (Σk, Uk) represent the k dominant eigenpairs, and (Σ⊥, U⊥) represent the remaining d −k
eigenpairs. Then by deﬁnition of the EIG approximation ˆΨ(W) in (31), we have
Ψ(W) −ˆΨ(W) = 1
2 logdet
 Ir×r + WHdW T 
−1
2 logdet

Ir×r + W ˆHdW T 
≤1
2 logdet

Ir×r + WHdW T −W ˆHdW T 
= 1
2 logdet
 Ir×r + WU⊥Σ⊥U T
⊥W T 
= 1
2 logdet

Ir×r + WU⊥Σ1/2
⊥Σ1/2
⊥U T
⊥W T 
= 1
2 logdet

I(d−r)×(d−r) + Σ1/2
⊥U T
⊥W T WU⊥Σ1/2
⊥

,
(38)
8

where we use Proposition 3.1 for the inequality, and Proposition 3.2 for the last equality. By deﬁnition
of the design matrix W in (19), we have that W T W ∈Rd×d is a square diagonal matrix with r diagonal
entries as one and the others zero, which satisﬁes W T W ≤Id×d. Consequently, we have
Ψ(W) −ˆΨ(W) ≤1
2 logdet

I(d−r)×(d−r) + Σ1/2
⊥U T
⊥U⊥Σ1/2
⊥

= 1
2 logdet
 I(d−r)×(d−r) + Σ⊥

,
(39)
where we use the orthonormality U T
⊥U⊥= I(d−r)×(d−r) for the eigenvectors in the equality.
This
concludes the upper bound for Ψ(W) −ˆΨ(W). The lower bound in (32) is implied by Proposition 3.1
and Hd ≥ˆHd.
The Hessian Hd is a large dense matrix which usually has a rapidly-decaying spectrum. The low-
rank approximation (30) can be eﬃciently computed by a randomized singular-value-decomposition(SVD)
algorithm. It is a ﬂexible and robust method that only requires Hessian action in a limited number
(O(k + p)) of given directions instead of forming the full Hessian matrix [25], particularly useful for
the large-scale problems, see Algorithm 1.
Algorithm 1: Randomized SVD to compute (30)
1: Generate i.i.d. Gaussian matrix Ω∈Rd×(k+p) with an oversampling parameter p very small (e.g.,
p = 10).
2: Compute Y = HdΩ.
3: Compute the QR factorization Y = QR satisfying QT Q = I.
4: Compute B = QT HdQ.
5: Solve an eigenvalue problem for B such that B = ZΣZT .
6: Form Uk = QZ[1 : k] and Σk = Σ[1 : k, 1 : k].
We can see that it is a matrix-free eigen-solver with both step 2 and 4 requires O(k+p) independent
Hessian-vector products. Each Hessian-vector product involves a pair of forward and adjoint PDE
solves. For many problems, the rank k is independent of the parameter dimension and data dimension.
Therefore, the dominant computational cost, i.e., the number of PDE solves is independent of the
parameter dimension and data dimension.
Once the low-rank approximation (30) is computed, the approximate EIG in (31) does not involve
solution of the forward model. In the online stage, we only need to ﬁnd a design matrix W such that
W = arg max
W ∈W
ˆΨ(W).
(40)
3.3
Greedy algorithms
The problem (40) can also be treated as the optimization of set functions under cardinality con-
straint set as each design matrix W represent a choice of subset of candidate sensor location . The set
functions usually exhibit properties such as submodularity(Deﬁnition 3.4) that allow for eﬃcient opti-
mization methods[24]. It is well-know that the log-determinant function is a submodular function[26]
with the deﬁnition of submodularity given as follows.
Deﬁnition 3.4. Let f be a set function on V, i.e ., f : 2V →R. Then f is submodular if for every
A, B ⊂V with A ⊂B and every v ∈V \ B, we have f(A ∪{v}) −f(A) ≥f(B ∪{v}) −f(B).
Submodularity is a useful property of set functions with deep theoretical results and applications
in combinational optimization and machine learning[11, 33, 45, 37]. The problem of submodular func-
tion maximization is a classic NP-hard problem. A general approach of solving it with cardinality
constraints is a greedy algorithm. A celebrated result by [37] proves that greedy algorithms can pro-
vide a good approximation to the optimal solution of the NP-hard optimization problem despite its
simplicity.
9

The standard greedy algorithm has theoretical guarantees for maximizing submodular functions. Re-
cently, there are some investigations on the theoretical support for its performance for non-submodular
functions. The greedy algorithm enjoys strong empirical performance and provides near-optimal so-
lutions in practice for many submodular and non-submodular functions as shown in [13, 31]. Yet the
repeated function evaluations required to compute object function in each greedy step may comprise
a large computational cost if each function evaluation is expensive.
The following Algorithm 2 is the standard greedy algorithm that starting with the empty set S0, during
each iteration t, the element maximizing the function is added to the chosen sensor set St. We denote
it as standard greedy algorithm here.
Algorithm 2: A standard greedy algorithm
1: Input: Uk, Σk in (30), a set S of d candidate sensors, a budget of r sensors to place, an initial set S0 = ∅.
2: for t = 1, . . . , r do
3:
v∗←arg maxv∈S\St−1 ˆΨ(v), where ˆΨ(v) := 1
2 logdet
 I + WvUkΣkU T
k W T
v

,
for the design matrix Wv corresponding to the sensor set St−1 ∪{v}.
4:
St ←St−1 ∪{v∗}
5: end for
6: Output: optimal sensor choice Sr
We can see with each sensor selection, we apply W on the eigenvector matrix Uk to actually select
the rows of Uk, which can be treated as a row-selection problem to ﬁnd a subset of rows that captures Uk
as much as possible. This quantity has a nature interpretation in terms of statistical leverage(Deﬁnition
3.5)[39] and it has been used extensively to identify “outlying”, or we can say in our problem, more
“informative” data point[17, 31]. If we employ this leverage score as a bias toward more “informative”
rows, which then provide a “nice” starting point for the selection in greedy algorithm[14].
Deﬁnition 3.5. Let Uk ∈Rd×k contain the eigenvectors corresponding to the k dominant eigenvalues
of a d × d symmetric matrix A with rank(A) ≥k. Then the (rank-k) leverage score of the i-th row of
A is deﬁnes as lk
i = ∥[Uk]i,:∥2 for i = 1, · · · , n where [Uk]i,: denotes the i-th row of Uk.
Instead of choosing the sensors one-by-one as in Algorithm 2, we use the leverage score information
from Uk as a criterion to select the sensors. We ﬁrst choose the r rows that have the top-r leverage
scores of Uk as the initial sensor set S0. At each iteration t = 1, . . . , r, we swap the t-th sensor in St
with one from S \ St that maximizes the leverage score. Then we set the resulting sensor set Sr as S0
and repeat the whole process of swapping sensors until it converges that no sensor is changed. We call
it swapping greedy algorithm.
Algorithm 3: A swapping greedy algorithm
1: Input: Uk, Σk in (30), a set S of d candidate sensors, a budget of r sensors to place.
2: Compute the initial guess sensor set S∗= {s1, . . . , sr} ⊂S based on leverage scores of Uk. S0 = {∅}.
3: while S∗̸= S0 do
4:
S0 ←S∗.
5:
for t = 1, . . . , r do
6:
v∗←arg maxv∈{st}∪(S\St−1) ˆΨ(W) = 1
2 logdet
 I + WvUkΣkU T
k W T
v

,
Wv is the design matrix for the sensor choice St−1 \ {st} ∪{v}.
7:
St ←(St−1 \ {st}) ∪{v∗}.
8:
end for
9:
S∗←Sr.
10: end while
11: Output: optimal sensor choice S∗.
10

4
Nonlinear Bayesian inverse problems
We consider Bayesian nonlinear inverse problem in this section, where the parameter-to-observable
map F(m) is nonlinear with respect to the parameter. For such problems we do not have the data-
independent EIG as in (24), and need to use a data-averaged KL divergence by a sample average
approximation as
Ψ ≈1
Ns
Ns
X
i=1
DKL(µpost(·|yi)∥µpr),
(41)
where the data yi are given by
yi = F(mi) + εi,
(42)
with Ns i.i.d. samples mi ∼µpr and εi ∼N(0, Γn), i = 1, . . . , Ns. This involves the critical challenges
of (1) computation of the posterior for each data realization, (2) an high-dimensional integral for
the KL divergence, and, (3) a complex and implicit dependence of the EIG on the design matrix
through the solution of the Bayesian nonlinear inverse problem. To tackle these challenges, beyond
the low-rank approximation of the Hessian introduced in last section, we propose a sequence of further
approximations including (1) Laplace approximation of the posterior for each data realization, which
leads to an eﬃcient computation of the posterior, (2) an approximation of a varying MAP point for
each conﬁguration of the sensors by a ﬁxed MAP point obtained with data from all candidate sensors,
which prevents solution of the nonlinear inverse problems at each conﬁguration of the sensors, and, (3)
an approximation of the ﬁxed MAP point by the synthetic sample drawn from the prior, which further
gets rid of ﬁnding the MAP point for the nonlinear inverse problem. We demonstrate the accuracy
and eﬃciency of the proposed approximations and employ them in the greedy algorithms for scalable
and eﬃcient optimization of the design matrix.
4.1
Laplace approximation
Laplace approximation (LA) seeks an approximation of the nonlinear Bayesian posterior µpost for
given data y by a Gaussian distribution µpost ≈µLA
post, with the mean given by the MAP point mmap
as
mmap := argmin
m∈H
1
2∥F(m) −y∥2
Γ−1
n
+ 1
2∥m −mpr∥2
C−1
pr ,
(43)
and the covariance Cpost is given by
C−1
post := Hm(mmap) + C−1
pr ,
(44)
where Hm(mmap) is the Hessian of the misﬁt term 1
2∥F(m)−y∥2
Γ−1
n
w.r.t. the parameter m, evaluated at
the MAP point mmap. For eﬃcient computation of the EIG, we employ a Gauss–Newton approximation
of the Hessian as (with slight abuse of notation)
Hm(mmap) := J ∗(mmap) Γ−1
n J (mmap),
(45)
where J (mmap) is the Jacobian of the parameter-to-observable map F(m) w.r.t. m evaluated at mmap,
i.e.,
J (mmap) := ∇mF(m)|m=mmap.
(46)
By the Laplace approximation of the posterior, similar to (23), the analytical form of the KL divergence
is given as
DKL(µLA
post∥µpr) = 1
2
h
logdet

I + e
Hm

−tr(C
1
2
postHmC
1
2
post) + ∥mmap −mpr∥2
C−1
pr
i
,
(47)
11

where e
Hm = C
1
2pr Hm C
1
2pr. By a ﬁnite dimensional discretization as presented in Section 2.2, we obtain
the discrete Laplace approximation with mean mmap as the coeﬃcient vector of mmap, and the inverse
of the covariance matrix
Γ−1
post = Hm(mmap) + Γ−1
pr = JT (mmap)Γ−1
n J(mmap) + Γ−1
pr ,
(48)
where J is the discretization of the Jacobian J in (46), whose eﬃcient computation is deferred to
Section 4.6. Moreover, we have the discrete KL divergence corresponding to (47) given by (with slight
abuse of notation)
DKL(µLA
post∥µpr) = 1
2
h
logdet

I + eHm(mmap)

−tr(Γ
1
2
postHm(mmap)Γ
1
2
post) + ∥mmap −mpr∥2
Γ−1
pr
i
,
(49)
where eHm(mmap) is the prior-preconditioned Hessian given by
eHm(mmap) = Γ
1
2prHm(mmap)Γ
1
2pr.
(50)
4.2
Low rank approximation
By the Laplace approximation of the Bayesian posterior at each given data yi, i = 1, . . . , Ns, we
can compute the EIG similar to that for the linear inverse problem by ﬁrst computing a low rank
approximation of the prior-preconditioned Hessian (50). More speciﬁcally, we need to compute the
eigenvalues of eHm at the MAP points mi
map for each i = 1, . . . , Ns. Let Jd denote the Jacobian at all
d candidate sensor locations evaluated at mi
map, then we have
J = WJd
and
JT = JT
d W T .
(51)
As in Theorem 3.3, by introducing ˆJd = (Γd
n)−1
2 Jd, we have
eHm = Γ
1
2prJT
d W T Γ−1
n WJdΓ
1
2pr = Γ
1
2prˆJT
d W T W ˆJdΓ
1
2pr.
(52)
To compute the eigenvalues of eHm, we use the following result.
Proposition 4.1. Let A and B be matrices of size m × n and n × m respectively, then AB and BA
have the same non-zero eigenvalues.
Proof. Let v be an eigenvector of BA corresponding to some eigenvalue λ ̸= 0, then
(AB)Av = A(BA)v = λAv.
(53)
Since λ ̸= 0, Av is an eigenvector of AB corresponding to eigenvalue λ. Thus non-zeros eigenvalues of
BA are also eigenvalues of AB. Then switching the roles of A and B above, we can see that non-zero
eigenvalues of AB are also eigenvalues of BA.
By Proposition 4.1, the eigenvalues of eHm are the same as the eigenvalues of WHdW T , where
Hd = ˆJdΓprˆJT
d ≈ˆHd = UkΣkU T
k ,
(54)
where the low rank approximation ˆHd can be eﬃciently computed by the randomized Algorithm 1.
Therefore, the eigenvalues of eHm can be eﬃciently computed by ﬁrst forming a small matrix W ˆHdW T
of size r × r, and then computing the eigenvalues of W ˆHdW T . Note that both the MAP point mi
map
and the Hessian Hm depend on the design matrix W, with the former depending on W through the
optimization problem (43), and the latter through its deﬁnition in (48), where the Jacobian J depends
12

on the design matrix. As a result, the eigenvalues of eHm depends on W. With these eigenvalues, we
obtain the approximations for the quantities in (49) as [44]
logdet

I + eHm(mi
map)

≈
r
X
j=1
ln(1 + λi
j(W))
and
tr(Γ
1
2
postHm(mi
map)Γ
1
2
post) ≈
r
X
j=1
λi
j(W)
1 + λi
j(W),
(55)
which leads to a Laplace approximation (with Gauss–Newton Hessian and low rank approximation) of
the EIG (41) as
ˆΨ(W) = 1
Ns
Ns
X
i=1
1
2


r
X
j=1
 
ln(1 + λi
j(W)) −
λi
j(W)
1 + λi
j(W)
!
+ ∥mi
map(W) −mpr∥2
Γ−1
pr

.
(56)
4.3
Fixed MAP point approximation
To evaluate the Laplace approximation of the EIG in (56) for each design matrix W, one has to
solve the optimization problem (43) for the MAP point mi
map(W) at each data yi, i = 1, . . . , Ns, which
is typically very expensive. Rather than solving the optimization problem for each design W and each
data yi, we consider the MAP point mi
map(Wall) at data yi observed from all candidate sensors Wall,
which is ﬁxed with respect to the design W. Consequently, the eigenvalues λi
j of the Hessian only
depend on W through the Jacobian J, not on the MAP point. With such a ﬁxed MAP approximation,
we can deﬁne the approximate EIG as
˜Ψ := 1
Ns
Ns
X
i=1
1
2


ki
X
j=1
 
ln(1 + λi
j(W)) −
λi
j(W)
1 + λi
j(W)
!
+ ∥mi
map(Wall) −mpr∥2
Γ−1
pr

.
(57)
Since ∥mi
map(Wall) −mpr∥2
Γ−1
pr is independent of W, maximizing ˜Ψ is equivalent to maximizing
˜ψ := 1
Ns
Ns
X
i=1
1
2


ki
X
j=1
 
ln(1 + λi
j(W)) −
λi
j(W)
1 + λi
j(W)
!
.
(58)
4.4
Prior sample point approximation
With the ﬁxed MAP point approximation, one still needs to solve the optimization problem (43)
to generate the MAP points mi
map(Wall) from the observation data yi, i = 1, . . . , Ns. Note that the
observation data yi in (42) is provided by ﬁrst solving the forward model at a sample mi randomly
drawn from the prior, and then extracting the observation from all the candidate sensors. As the
number of candidate sensors becomes big, we expect that the ﬁxed MAP point mi
map(Wall) can recover
or come close to the prior sample mi if the inverse problem is not severally ill-posed, which provides
a rational to replace the ﬁxed MAP point mi
map(Wall) by the prior sample mi. By this prior sample
point approximation, one can completely get rid of solving the optimization problem (43).
13

4.5
Greedy algorithms
To this end, we present the standard and swapping greedy algorithms for nonlinear Bayesian inverse
problems with all the above approximations taken into account.
Algorithm 4: A standard greedy algorithm
1: Input: data {yi}Ns
i=1 generated from the prior samples {mi}Ns
i=1, d candidates set S, r budget, initial set
S0 = ∅.
2: for i = 1, . . . , Ns do
3:
Form Hd = ˆJd(mi)ΓprˆJT
d (mi).
4:
Compute Hd ≈U i
kΣi
k(U i
k)T by Algorithm 1.
5: end for
6: for t = 1,. . . ,r do
7:
v∗←arg maxv∈S\St−1 ˜ψ(y, W, {U i
k, Σi
k}Ns
i=1),
Wv is the design matrix for the sensor choice St−1 ∪{v}.
8:
St ←St−1 ∪{v∗}.
9: end for
10: Output: optimal sensor choice Sr.
Algorithm 5: A swapping greedy algorithm
1: Input: data {yi}Ns
i=1 generated from the prior samples {mi}Ns
i=1, d candidates set S, r budget.
2: for i = 1, . . . , Ns do
3:
Form Hd = ˆJd(mi)ΓprˆJT
d (mi).
4:
Compute Hd ≈U i
kΣi
k(U i
k)T by Algorithm 1.
5: end for
6: Compute the initial guess sensor choice S∗= {s1, . . . , sr} ⊂S based on leverage scores of PNs
i=1 U i
k.
S0 = {∅}.
7: while S∗̸= S0 do
8:
S0 ←S∗
9:
for t = 1,. . . ,r do
10:
v∗←arg maxv∈{st}∪(S\St−1) ˜ψ(y, W, {U i
k, Σi
k}Ns
i=1),
Wv is the design matrix for the sensor choice St−1 \ {st} ∪{v}.
11:
St ←(St−1 \ {st}) ∪{v∗}.
12:
end for
S∗←Sr.
13: end while
14: Output: optimal sensor choice S∗.
4.6
Computation and complexity
In this section, we present the computation involved in ﬁnding the MAP point in (43) and in the
low rank approximation (54), which requires PDE solves and takes the dominant computational cost.
We also present a comparison of computational complexity for diﬀerent approximations introduced
above.
4.6.1
Finding the MAP point
In the computation of the MAP point, one needs to solve an optimization problem.
We use
an inexact Newton-CG method, which requires the computation of the action of the Hessian of the
objective (43) in a given direction ˆm, evaluated at a point m, which can be formally written as
H(m) ˆm = (∇2
mΦ(m, y) + C−1
pr ) ˆm.
(59)
14

The second term can be evaluated by (12) as
C−1
pr ˆm = Γ−1
pr ˆm = AM−1A ˆm,
(60)
which requires solve of a linear system with mass matrix M. The ﬁrst term of (59) can be evaluated by
a Lagrangian multiplier method. The potential Φ(m, y) can be explicitly written as Φ(u) = 1
2||B(u) −
y||2
Γ−1
n
by slight abuse of notation. We introduce the Lagrangian
L(u, m, v) = Φ(u) + r(u, m, v),
(61)
where v is the Lagrangian multiplier, r(u, m, v) is the weak form of the forward PDE (2). By taking
variation of L w.r.t. v as zero, we obtain the forward problem (2), which can be equivalently written
as: ﬁnd u ∈V such that
⟨˜v, ∂vr(u, m, v)⟩= 0
∀˜v ∈V.
(62)
By taking variation of L w.r.t. u as zero, we obtain the adjoint problem: ﬁnd v ∈V such that
⟨˜u, ∂ur(u, m, v)⟩= −⟨˜u, ∂uΦ(u)⟩
∀˜u ∈V.
(63)
where ⟨˜u, ∂uΦ(u)⟩= (B(u) −y)T Γ−1
n B(˜u). The the gradient of Φ w.r.t. m can be evaluated as
⟨˜m, ∇mΦ(m, y)⟩= ⟨˜m, ∂mL(u, m, v)⟩= ⟨˜m, ∂mr(u, m, v)⟩.
(64)
To compute the Hessian action ∇2
mΦ ˆm, we introduce another Lagrangian by taking the constrains
(62), (63), and (64) into account as
LH(u, m, v, ˆu, ˆm, ˆv) = ⟨ˆm, ∂mr(u, m, v)⟩+ ⟨ˆv, ∂vr(u, m, v)⟩+ ⟨ˆu, ∂ur(u, m, v) + ∂uΦ(u)⟩,
(65)
where ˆu and ˆv are the Lagrangian multipliers. By taking variation of LH w.r.t. v as zero, we obtain
the incremental forward problem: ﬁnd ˆu ∈V such that
⟨˜v, ∂uvr ˆu⟩= −⟨˜v, ∂mvr ˆm⟩
∀˜v ∈V,
(66)
where ∂uvr : V →V′ and ∂mvr : M →V′ are the linear operators. By taking variation of LH w.r.t. u
as zero, we obtain the incremental adjoint problem: ﬁnd ˆv ∈V such that
⟨˜u, ∂vur ˆv⟩= −⟨˜u, ∂mur ˆm⟩−⟨˜u, ∂uur ˆu⟩−⟨˜u, ∂uuΦ ˆu⟩
∀˜u ∈V,
(67)
where ∂vur : V →V′, ∂mur : M →V′, and ∂uur : V →V′ are linear operators, and ⟨˜u, ∂uuΦ ˆu⟩=
B(ˆu)T Γ−1
n B(˜u). To this end, the Hessian action ∇2
mΦ ˆm can be evaluated as
⟨˜m, ∇2
mΦ ˆm⟩= ⟨˜m, ∂mLH ˆm⟩= ⟨˜m, ∂mmr ˆm + ∂vmr ˆv + ∂umr ˆu⟩,
(68)
where ∂mmr : M →M′, ∂vmr : V →M′, and ∂umr : V →M′ are linear operators. Therefore, at m,
after solving one forward problem (63) and one adjoint problem (62), the Hessian action ∇2
mΦ ˆm at
each ˆm requires solution of one incremental forward problem (66) and one incremental adjoint problem
(67), i.e., two linearized PDE solves. We solve all the above PDEs by a ﬁnite element method in the
subspace Vnu ⊂V, and Mn ⊂M.
4.6.2
Low rank approximation
In the computation of the low rank approximation (54) by Algorithm 1, we need to perform the
actions HdΩand HdQ, where Hd is deﬁned in (54). We present the computation of the action Hdˆz
in a direction ˆz ∈Rd. By deﬁnition, we have
Hdˆz = ˆJdΓprˆJT
d ˆz = (Γd
n)−1
2 JdΓprJT
d (Γd
n)−1
2 ˆz = (Γd
n)−1
2 JdA−1MA−1JT
d (Γd
n)−1
2 ˆz,
(69)
15

which involves the computation of the actions of the Jacobian Jd and its transpose JT
d , and two solves of
a linear system with stiﬀness matrix A. We ﬁrst consider the action of JT
d z in direction z = (Γd
n)−1
2 ˆz.
By deﬁnition of the Jacobian in (46) and F(m) = Bd(u(m)), we have JT
d z = (∇mu(m))T BT
d z, where
the j-th column (Bd)j = Bd(ψj) ∈Rd for the basis functions {ψj}nu
j=1 in approximating the state
u = Pnu
j=1 ujψj, and u = (u1, . . . , unu)T ∈Rnu is the coeﬃcient vector. By taking the gradient of the
forward problem in the form (62) w.r.t. m, and noting that u depends on m, we have
0 = ⟨˜v, ∂vur ∇mu(m) + ∂vmr⟩
∀v ∈V.
(70)
Let Rvu and Rvm denote the matrices corresponding to the ﬁnite element discretization of ∂vur and
∂vmr above, respectively, we formally obtain
∇mu(m) = −R−1
vu Rvm,
(71)
so that JT
d z can be evaluated by solving the linear system RT
vuw = BT
d z for w ∈Rnu, which has
the same matrix RT
vu = Ruv as in the discrete incremental forward problem (66), and perform-
ing the matrix-vector product −RT
vmw.
Similarly the Jacobian action Jdn = Bd∇mu(m)n for
n = A−1MA−1JT
d z can be evaluated by ﬁrst performing the matrix-vector product Rvmn, then
solving the linear system Rvuw = Rvmn for w ∈Rnu, which has the same matrix Rvu as in the
discrete incremental adjoint problem (67), and ﬁnally performing the matrix-vector product −Bdw.
In summary, after solving one forward problem (63) for u and one adjoint problem (62) for v, each
action Hdˆz consists of solving four linearized PDEs, one with matrix Rvu, one with Ruv, and two
with A.
4.6.3
Computational complexity
Suppose we need to evaluate the approximate KL divergence (41) at each of the Ns training data
{yi}Ns
i=1 for Nkl times, each time corresponding to a diﬀerent choice of the sensor location to ﬁnd the
optimal design by the greedy algorithms. Assume that to ﬁnd the MAP point for each training data,
we need Nnt Newton iterations and Ncg CG iterations for each Newton iteration in average. Then
in total we need Nkl × Ns × Nnt × Ncg times Hessian action (59) to compute the exact MAP points,
Ns × Nnt × Ncg times to compute the ﬁxed MAP points, 0 times if the prior points are used. Assume
that in average the rank k with oversampling factor p = 10 is used in the low rank approximation by
Algorithm 1. Then in total we need Nkl ×Ns ×2(k +p) times Hessian action (69) for the case of exact
MAP point, Ns × 2(k + p) times for the case of ﬁxed MAP point, and Ns × 2(k + p) times for case of
prior point. We summarize the computational complexity in terms of Hessian action in the following
table.
Table 1: Computational complexity in terms of the number of Hessian actions (59) for ﬁnding MAP
point and (69) for low rank approximation. Ns: # data, Nkl: # EIG evaluations, Nnt: # Newton
iterations, Ncg: # CG iterations, k: # rank of the low rank approximation (54), p: an oversampling
factor in Algorithm 1.
# Hessian action
exact MAP point
ﬁxed MAP point
prior sample point
Finding MAP point
(by Newton-CG)
Nkl × Ns × Nnt × Ncg
Ns × Nnt × Ncg
0
Low-rank approximation
(by RSVD Algorithm 1)
Nkl × Ns × 2(k + p)
Ns × 2(k + p)
Ns × 2(k + p)
16

5
Numerical results
In this section, we present OED for both a linear and a nonlinear Bayesian inverse problems to
demonstrate the eﬃcacy and eﬃciency of the proposed approximations and the greedy algorithm, as
well as the scalability of our method w.r.t. the number of training data points, the number of candidate
sensors, and the parameter dimension.
5.1
A linear Bayesian inverse problem
In this example, we consider inversion of the initial condition of an advection-diﬀusion problem
given pointwise observation of the state at certain sensor locations and certain times. The forward
problem is given by
ut −k∆u + v · ∇u = 0 in D × (0, T),
u(·, 0) = m in D,
k∇u · n = 0 on ∂D × (0, T),
(72)
where D ⊂R2 is an open and bounded domain with boundary ∂D depicted in Figure 1. k > 0 is the
diﬀusion coeﬃcient and T > 0 is the ﬁnal time. In our numerical experiment, we choose k = 0.001.
The velocity ﬁeld v ∈R2 is obtained by solving the following steady-state Navier–Stokes equation with
the side walls driving the ﬂow:
−1
Re∆v + ∇q + v · ∇v = 0 in D,
∇· v = 0 in D,
v = g on ∂D,
(73)
where q represents the pressure ﬁeld, the Reynolds number Re = 50. The Dirichlet boundary data
g ∈R2 is prescribed as g = (0, 1) on the left wall of the domain, g = (0, −1) on the right wall, and
g = (0, 0) elsewhere.
Figure 1: The computational domain D for two dimensional problem is [0, 1]2 with two rectangular
blocks ([0.25, 0.5] × [0.15, 0.4], [0.6, 0.75] × [0.6, 0.85]) removed. Left: velocity ﬁeld v. Right: initial
condition mtrue.
We use Galerkin ﬁnite element method with piecewise linear elements for spatial discretization of the
forward and adjoint problems, which results in n = 2023 spatial degrees of freedom for the parameter
17

m and state variable u. We use implicit Euler method for temporal discretization with Nt = 40 time
steps for the ﬁnal time T = 4. We consider a Gaussian prior µpr = N(mpr, Cpr) for the parameter m.
The covariance Cpr = A−2 is given by the square of the inverse of diﬀerential operator A = −γ∆+ δI
with Laplacian ∆and identity I, equipped with Robin boundary condition γ∇m·n+βm on ∂D, where
γ, δ > 0 control the correlation length and variance of the prior distribution. The Robin coeﬃcient
β is chosen as in ?? to reduce boundary artifacts. For our numerical test, we choose mpr = 0.25,
γ = 1, δ = 8, and set a “true” initial condition mtrue = min(0.5, exp(−100 ∥x −[0.35, 0.7]∥2), as shown
in Figure 1, to generate the observation data at the ﬁnal time, as shown in Figure 2.
In the ﬁrst test, we use a small number of candidate sensors and compare the design obtained
by the greedy algorithms with the optimal design by brutal force search to show the eﬃcacy of the
greedy algorithms.
Speciﬁcally, we use a grid of d = 9 candidate sensor locations {xi}9
i=0 (xi ∈
9 candidate sensor locations
0.0
0.1
0.2
0.3
0.4
0.5
75 candidate sensor locations
0.0
0.1
0.2
0.3
0.4
0.5
Figure 2: The state ﬁeld at time T = 4 obtained by solving (72) at the initial condition in Figure 1.
Left: 9 candidate observation locations. Right: 75 candidate observation locations.
{0.2, 0.55, 0.8}×{0.25, 0.5, 0.75}) as shown in Figure 2 (left) with the goal of choosing r = 2, 3, 4, 5, 6, 7, 8
sensors at the ﬁnial time. We run the two greedy algorithms, Algorithm 2 and Algorithm 3, as well as
a brutal force search of all possible designs (
9!
r!(9−r)!) to ﬁnd the optimal design. In the evaluation of
the approximate EIG (31), we do not need the low-rank approximation of Hd here as in Theorem 3.3
since it is a small (9 × 9) matrix that we can easily compute by solving 9 incremental forward and 9
incremental adjoint problems in directions ej of dimension 9 with the j-th element as one and other
as zeros, j = 1, . . . , 9. The values of the approximate EIG by the two algorithms and at all possible
designs are shown in Figure 3 (left), which are also shown in Table 4 for a closer comparison.
We can see for r = 2, 3, 5, 6, 7, 8, the swapping greedy algorithm ﬁnds the optimal design for all r
but r = 4 with the second best. While the standard greedy algorithm ﬁnds the optimal for r = 3, 4, 8,
the second best for r = 6, 7, the third for r = 2, and the ﬁfth for r = 5. Although the optimal design
are not found in all cases, the the values of the approximate EIG of the chosen ones by the two greedy
algorithms are really close to the optimal.
In the second test, we consider a grid of d = 75 candidate sensor locations as shown in Figure
2 (right) with the goal of choosing r = 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60 sensor locations. We
compute the low rank approximation (30) with the eigenvalues displayed in Figure 4, which decays
rapidly, by over ﬁve orders of magnitude for the 75 eigenvalues. We randomly draw 200 diﬀerent
designs from the candidate sensors and compute their approximate EIG and compare them with the
ones chosen by two greedy algorithms as shown in Figure 3 (right), from which we can see that
both greedy algorithms ﬁnd the designs better than all the random choices, and the new swapping
greedy algorithm we propose always gives higher (better) or at least equal values as shown in Table 3.
18

2
3
4
5
6
7
8
number of sensors r
15
20
25
30
35
40
45
50
= 1
2logdet(I + WHdWT)
9 candidate sensors
swapping greedy choice
standard greedy choice
all combination of choices
10
20
30
40
50
60
number of sensors r
40
60
80
100
120
= 1
2logdet(I + WHdWT)
75 candidate sensors
swapping greedy choice
standard greedy choice
random choices
Figure 3: Approximate EIG ˆΨ at the design chosen by the standard greedy algorithm, the swapping
greedy algorithm and at the optimal design, with the ranking of greedy choices among all the possible
designs in the bracket.
Table 2: Approximate EIG ˆΨ at the design chosen by the standard greedy algorithm, the swapping
greedy algorithm and at the optimal design, with the ranking of greedy choices among all the possible
designs in the bracket.
r
2
3
4
5
6
7
8
standard
greedy
16.2236(#3)
23.1065(#5)
29.9306(#1)
35.7619(#1)
40.8833(#2)
45.2398(#2)
49.4098(#1)
swapping
greedy
16.2528(#1)
23.2767(#1)
29.8067(#2)
35.7619(#1)
40.9675(#1)
45.3347(#1)
49.4098(#1)
optimal
choice
16.2528
23.2767
29.9306
35.7619
40.9675
45.3347
49.4098
Moreover, the advantage of our swapping greedy algorithm can also be illustrated by reduced pointwise
Table 3: Approximate EIG ˆΨ at the design chosen by the standard greedy algorithm and the swapping
greedy algorithm.
r
5
10
15
20
25
standard
greedy
38.0898
66.4687
87.7688
99.7733
107.2547
swapping
greedy
38.1207
67.2216
87.9203
100.2188
108.2906
r
30
35
40
50
60
standard
greedy
112.6066
117.1837
120.9787
126.9114
130.9548
swapping
greedy
114.0506
118.0523
121.4332
126.9114
130.9821
19

0
10
20
30
40
50
60
70
i
10
3
10
2
10
1
100
101
102
eigenvalues
Figure 4: Decay of the eigenvalues of Hessian ˆHd in (30).
posterior variance in Figure 5 compared to the standard greedy algorithm, and two random designs
with the same number of sensors.
Figure 5: Pointwise variance of the posterior at designs chosen by swapping greedy algorithm, the
standard greedy algorithm, and two random designs with 10 sensors. The brighter region corresponds
to larger variance.
Compared with the optimal design chosen by swapping greedy algorithm, the
standard greedy algorithm and the two random designs lead to 7%, 30%, 53% increase in the averaged
variance respectively.
5.2
A nonlinear Bayesian inverse problem
In this problem we consider a log-normal diﬀusion forward model as follows
−∇· (exp(m)∇u) = f in D
u = g on ΓD
exp(m)∇u · n = h on ΓN
,
(74)
where D ⊂R2 is an open, bounded domain with suﬃciently smooth boundary Γ = ΓD ∪ΓN with
Dirichlet and Neumann boundaries ΓD ∩ΓN = ∅and data g ∈H1/2(Γd) and h ∈L2(ΓN) respectively.
20

The state variable u ∈Vg = {v ∈H1(D) : v|ΓD = g}. f ∈L2(D) is a source term. We consider
a Gaussian prior for the parameter m ∈H1(D), i.e., m ∼µpr = N(mpr, Cpr) with mean mpr and
covariance Cpr = A−2, where A is a diﬀerential operator given by
Am =
(
−γ∇· (Θ∇m) + δm
in D
Θ∇m · n + βm
on ∂D
,
where β ≈√γδ is the optimal Robin coeﬃcient derived in ?? to minimize boundary artifacts and Θ
is an symmetric positive deﬁnite and anisotropic matrix of the form
Θ =

θ1 sin(α)2
(θ1 −θ2) sin(α) cos(α)
(θ1 −θ2) sin(α) cos(α)
θ2 cos(α)2

.
In our numerical experiment, we set prior mean as zero, γ = 0.04, δ = 0.2, θ1 = 2, θ2 = 0.5, α = π/4.
For the forward problem, we consider the domain D = (0, 1) × (0, 1), no source term (i.e., f = 0)
and no normal ﬂux on ΓN = {0, 1} × (0, 1), i.e., imposing the homogeneous Neumann condition
exp(m)∇u · n = 0. The Dirichlet boundary ΓD = (0, 1) × {0, 1} with boundary condition u = 1 on
(0, 1)×{1} and u = 0 on (0, 1)×{0}. We draw a sample from the prior and use it as “true” parameter
ﬁeld mtrue as shown Figure 6 (left). We use quadratic ﬁnite elements for the discretization of the state
and adjoint variables, and use linear elements for the parameter. The degrees of freedom for the state
and parameter are nu = 4225 and n = 1089, respectively.
True Parameter
4
2
0
2
4
Prior mean
4
2
0
2
4
Figure 6: Left: The synthetic “true” parameter ﬁeld. Right: The mean of the prior distribution.
5.2.1
Eﬀectiveness of approximations
To reduce the computational cost for the nonlinear inverse problems, we introduced the Laplace
approximation with low-rank decomposition, ﬁxed MAP point approximation, and prior sample point
approximation in Section 4. To investigate their eﬀectiveness, we consider their (sample) correlation
at the same design. A high correlation (with correlation coeﬃcient close to 1) of the approximate EIG
values by two diﬀerent approximations implies that the optimal design obtained by one approximation
is likely close to optimal for the other approximation.
In the test, we use the grid of d = 81 candidate sensor locations as shown in Figure 7 (right) with
the goal of choosing r = 10 sensor locations. We generate 200 random designs, and compute the EIG
of each design by a double-loop Monte Carlo (DLMC) method as the reference. Then we compute their
approximate EIG by the Laplace approximation (LA-EIG) and its further approximation with ﬁxed
21

9 candidate sensor locations
0.0
0.2
0.4
0.6
0.8
1.0
81 candidate sensor locations
0.0
0.2
0.4
0.6
0.8
1.0
Figure 7: The state ﬁeld at the “true” parameter and two set of candidate observation locations.
map point shown in Figure 8 (left). We can see that the correlation between DLMC-EIG and LA-EIG
is 0.9752, and the maximum of DLMC-EIG is also the maximum of LA-EIG. The correlation between
DLMC-EIG and LA-EIG with ﬁxed map point is 0.9453, and the maximum of LA-EIG with ﬁxed map
point is the second maximum of DLMC-EIG. Although it is not the maximum, but it gives almost the
same EIG value as the maximum. We can observe closely about the relation between LA-EIG and
LA-EIG with ﬁxed MAP point in Figure 8 (middle) with a correlation 0.9525, and that their optimal
choices have almost the same LA-EIG values. Figure 8 (right) illustrates the correlation between ˜ψ
computed with ﬁxed MAP point and with prior sample at which to evaluate Hessian. We can see close
to 1 correlation, and that the optimal choices by the ﬁxed map point and the prior sample point are
the same.
5.2.2
Numerical results
We ﬁrst use a grid of d = 9 candidate sensor locations with the goal of choosing r = 2, 3, 4, 5, 6, 7, 8.
As we can see in Figure 9 (left), the standard greedy and swapping greedy algorithms give the same
optimal design for all the cases and they are the actual optimal one among all possible choices for
r = 2, 3, 5, 8, second best for r = 4, 7, and third for r = 6. We remark that by evaluating the Hessian
at the prior sample point, the computational cost is signiﬁcantly reduced as analyzed in Section 4.6.
Despite that the optimal choice by the approximation might not be the optimal for LA-EIG, we can
still ﬁnd the ones close to the best in all the cases.
Then we consider 81 candidate sensor locations shown in Figure 7 (right). We randomly draw
200 diﬀerent designs from the candidate sensors and compute their LA-EIG, and compare them with
LA-EIG of the choices by two greedy algorithms. Figure 9 (right) illustrates that the design chosen
by both greedy algorithms are much better than all the random choices, and the swapping greedy
algorithm is mostly better or equal to the standard greedy algorithm. To illustrate the stability of our
method, we compare the greedy choices with 200 random designs with increasing number of training
data Ns and increasing number of candidate sensor locations d (data dimension) in Figure 10. We
can see that the swapping greedy algorithm can always ﬁnd better designs than the standard greedy
algorithm, and much better than the random choices.
5.2.3
Scalability
As analyzed in Section 4.6, the computational complexity in terms of the number of PDE solves
critically depends on the rank r in the low-rank approximation of the Hessian ˆHd. We investigate its
22

12
13
14
15
16
17
EIG
12
14
16
18
20
22
24
26
LA-EIG
LA-EIG,corr=0.9752
LA-EIG with fix map point,corr=0.9453
12
13
14
15
16
LA-EIG
23
24
25
26
LA-EIG with fixed map point
corr=0.9525
optimal choice of LA-EIG
optimal choice of LA-EIG with fixed point
8.0
8.5
9.0
9.5
10.0
10.5
11.0
11.5
12.0
 with fixed map point
8.0
8.5
9.0
9.5
10.0
10.5
11.0
11.5
12.0
 with prior point
corr =0.999
optimal choice
Figure 8: Correlation between EIG and its approximations. Each blue or red point represents one
random design of 10 sensors among 81 candidates. Left: DLMC-EIG vs LA-EIG and LA-EIG with
ﬁxed MAP point approximation. Middle: LA-EIG and LA-EIG with ﬁxed MAP point approximation.
Right: LA-EIG with ﬁxed MAP point approximation vs LA-EIG with prior sample point approxima-
tion.
2
3
4
5
6
7
8
number of sensors r
4
6
8
10
12
14
16
Laplace-approximated EIG
9 candidate sensors
swapping greedy choice
standard greedy choice
all combination of choices
10
20
30
40
50
60
number of sensors r
10
20
30
40
50
60
70
Laplace-approximated EIG
81 candidate sensors
swapping greedy choice
standard greedy choice
200 random choices
Figure 9: Laplace approximate EIG with increasing number of sensors out of 9 (left) and 81 (right)
candidates. Blue ﬁlled area represents the probability of ˆΨ for all the designs with lines at the minimum,
maximum and median.
dependence on the parameter dimension and data dimension (the number of candidate sensor loca-
tions). The decay of the eigenvalues of the Hessian are shown in Figure 11 with increasing parameter
dimension and data dimension. From the similar decay of the eigenvalues in the left part of the ﬁgure,
we can conclude that our algorithm is (strongly) scalable with respect to the parameter dimension in
achieving the same information with the same number of sensors, while from the similar decay rate
23

Table 4: Approximate EIG ˆΨ at the design chosen by the standard greedy algorithm, the swapping
greedy algorithm and at the optimal design, with the ranking of greedy choices among all the possible
designs in the bracket.
r
2
3
4
5
6
7
8
standard
greedy
6.5563(#1)
8.8113(#1)
10.5916(#2)
12.4633(#1)
13.8670(#3)
15.2979(#2)
16.3798(#1)
swapping
greedy
6.5563(#1)
8.8113(#1)
10.5916(#2)
12.4633(#1)
13.8670(#3)
15.2979(#2)
16.3798(#1)
optimal
choice
6.5563
8.8113
10.7776
12.4633
14.1259
15.3501
16.3798
0
10
20
30
40
50
60
number of training data Ns
7
8
9
10
11
12
13
14
Laplace-approximated EIG
81 candidate sensors
swapping greedy choice
standard greedy choice
200 random choices
101
102
103
number of candidate sensor locations d
7
8
9
10
11
12
13
14
15
Laplace-approximated EIG
swapping greedy choice
standard greedy choice
200 random choices
Figure 10: LA-EIG for choosing 5 sensors at optimal (by the swapping and standard greedy algorithms)
and random designs with increasing number of training data (left) and increasing number of candidates
(right). Blue ﬁlled area represents the probability of ˆΨ for 200 random designs.
of the eigenvalues in the right part of the ﬁgure, we conclude that it is (weekly) scalable with respect
to the data dimension in achieving the sample percentage of information with the same number of
sensors.
6
Conclusion
We have developed a computational framework for optimal experimental design of inﬁnite-dimensional
Bayesian inverse problem governed by PDE. Our method exploits low-rank structure of the prior-
preconditioned data misﬁt Hessian, dominant data subspace information from the Jacobian of parameter-
to-observable map, laplace approximation of nonlinear Bayesian posterior. We reduce the computa-
tional cost of number of PDE solves to a limited number of PDE solves oﬄine. The numerical tests
of linear advection-diﬀusion problem and nonlinear poison problem illustrate the eﬀectiveness and
scalability of our methods. Our limitation lies on the assumption of Gaussian prior and Gaussian
additive noise, the series of approximations for nonlinear problems in sacriﬁce for cheap computation,
and the nature of greedy algorithm. Some future work remains: (i) extension to nonlinear problems
that laplace method cannot provide a good approximation such as helmholtz equations. (ii) theoreti-
cal guarantees of swapping greedy algorithms. (iii) adaptively determine the number of sensor needed
24

0
10
20
30
40
50
60
i
10
3
10
1
101
103
105
eigenvalues
parameter dimension n = 81
parameter dimension n = 289
parameter dimension n = 1089
parameter dimension n = 4225
100
101
i
10
1
101
103
105
107
eigenvalues
number of candidate sensor locations d = 16
number of candidate sensor locations d = 64
number of candidate sensor locations d = 256
number of candidate sensor locations d = 1024
number of candidate sensor locations d = 4096
Figure 11: Left: eigenvalues with increasing parameter dimension. Right: eigenvalues with increasing
number of candidate sensor locations. Multiple lines with the same color represent diﬀerent training
data cases.
rather than a ﬁxed number.
References
[1] A. Alexanderian, P.J. Gloor, and O. Ghattas. On Bayesian A-and D-optimal experimental designs
in inﬁnite dimensions. Bayesian Analysis, 2015.
[2] Alen Alexanderian, Philip J. Gloor, and Omar Ghattas. On Bayesian A-and D-optimal experi-
mental designs in inﬁnite dimensions. Bayesian Analysis, 11(3):671–695, 2016.
[3] Alen Alexanderian, Noemi Petra, Georg Stadler, and Omar Ghattas. A-optimal design of experi-
ments for inﬁnite-dimensional Bayesian linear inverse problems with regularized ℓ0-sparsiﬁcation.
SIAM Journal on Scientiﬁc Computing, 36(5):A2122–A2148, 2014.
[4] Alen Alexanderian, Noemi Petra, Georg Stadler, and Omar Ghattas. A fast and scalable method
for A-optimal design of experiments for inﬁnite-dimensional Bayesian nonlinear inverse problems.
SIAM Journal on Scientiﬁc Computing, 38(1):A243–A272, 2016.
[5] Alen Alexanderian, Noemi Petra, Georg Stadler, and Omar Ghattas. Mean-variance risk-averse
optimal control of systems governed by PDEs with random parameter ﬁelds using quadratic
approximations. SIAM/ASA Journal on Uncertainty Quantiﬁcation, 5(1):1166–1192, 2017. arXiv
preprint arXiv:1602.07592.
[6] Alen Alexanderian and Arvind K. Saibaba.
Eﬃcient D-optimal design of experiments for
inﬁnite-dimensional Bayesian linear inverse problems. SIAM Journal on Scientiﬁc Computing,
40(5):A2956–A2985, 2018.
[7] Nicole Aretz-Nellesen, Peng Chen, Martin A. Grepl, and Karen Veroy. A-optimal experimental
design for hyper-parameterized linear Bayesian inverse problems. Numerical Mathematics and
Advanced Applications ENUMATH 2020, 2020.
[8] Nicole Aretz-Nellesen, Martin A Grepl, and Karen Veroy. 3D-VAR for parameterized partial dif-
ferential equations: a certiﬁed reduced basis approach. Advances in Computational Mathematics,
45(5-6):2369–2400, 2019.
[9] Anthony C. Atkinson and Alexander N. Donev. Optimum Experimental Designs. Oxford, 1992.
25

[10] Ahmed Attia, Alen Alexanderian, and Arvind K Saibaba. Goal-oriented optimal design of exper-
iments for large-scale bayesian linear inverse problems. Inverse Problems, 34(9):095009, 2018.
[11] Francis Bach et al. Learning with submodular functions: A convex optimization perspective.
Foundations and Trends® in Machine Learning, 6(2-3):145–373, 2013.
[12] Joakim Beck, Ben Mansour Dia, Luis F.R. Espath, Quan Long, and Ra´ul Tempone. Fast bayesian
experimental design: Laplace-based importance sampling for the expected information gain. Com-
puter Methods in Applied Mechanics and Engineering, 334:523 – 553, 2018.
[13] Andrew An Bian, Joachim M Buhmann, Andreas Krause, and Sebastian Tschiatschek. Guarantees
for greedy maximization of non-submodular functions with applications. In Proceedings of the 34th
International Conference on Machine Learning-Volume 70, pages 498–507. JMLR. org, 2017.
[14] Christos Boutsidis, Michael W. Mahoney, and Petros Drineas. An improved approximation algo-
rithm for the column subset selection problem. CoRR, abs/0812.4293, 2008.
[15] Tan Bui-Thanh and Omar Ghattas. Analysis of the Hessian for inverse scattering problems. Part
I: Inverse shape scattering of acoustic waves. Inverse Problems, 28(5):055001, 2012.
[16] Tan Bui-Thanh, Omar Ghattas, James Martin, and Georg Stadler. A computational framework
for inﬁnite-dimensional Bayesian inverse problems Part I: The linearized case, with application to
global seismic inversion. SIAM Journal on Scientiﬁc Computing, 35(6):A2494–A2523, 2013.
[17] Samprit Chatterjee and Ali S Hadi. Sensitivity analysis in linear regression, volume 327. John
Wiley & Sons, 2009.
[18] P. Chen, U. Villa, and O. Ghattas.
Hessian-based adaptive sparse quadrature for inﬁnite-
dimensional Bayesian inverse problems. Computer Methods in Applied Mechanics and Engineering,
327:147–172, 2017.
[19] Peng Chen and Omar Ghattas. Hessian-based sampling for high-dimensional model reduction.
International Journal for Uncertainty Quantiﬁcation, 9(2), 2019.
[20] Peng Chen and Omar Ghattas. Projected Stein Variational Gradient Descent. arXiv preprint
arXiv:2002.03469, 2020.
[21] Peng Chen, Umberto Villa, and Omar Ghattas. Taylor approximation and variance reduction for
PDE-constrained optimal control under uncertainty. Journal of Computational Physics, 385:163–
186, 2019.
[22] Peng Chen, Keyi Wu, Joshua Chen, Thomas O’Leary-Roseberry, and Omar Ghattas. Projected
Stein variational Newton: A fast and scalable Bayesian inference method in high dimensions.
Advances in Neural Information Processing Systems, 2019.
[23] Benjamin Crestel, Alen Alexanderian, Georg Stadler, and Omar Ghattas. A-optimal encoding
weights for nonlinear inverse problems, with application to the Helmholtz inverse problem. Inverse
Problems, 33(7):074008, 2017.
[24] Satoru Fujishige. Submodular functions and optimization. In Annals of Discrete Mathematics,
volume Vol:58. Elsevier, 2005.
[25] Nathan Halko, Per Gunnar Martinsson, and Joel A. Tropp. Finding structure with randomness:
Probabilistic algorithms for constructing approximate matrix decompositions.
SIAM Review,
53(2):217–288, 2011.
26

[26] Insu Han, Prabhanjan Kambadur, Kyoungsoo Park, and Jinwoo Shin. Faster greedy map inference
for determinantal point processes. In Proceedings of the 34th International Conference on Machine
Learning-Volume 70, pages 1384–1393. JMLR. org, 2017.
[27] Xun Huan and Youssef M. Marzouk. Simulation-based optimal Bayesian experimental design for
nonlinear systems. Journal of Computational Physics, 232(1):288–317, 2013.
[28] Xun Huan and Youssef M. Marzouk. Gradient-based stochastic optimization methods in Bayesian
experimental design. International Journal for Uncertainty Quantiﬁcation, 4(6):479–510, 2014.
[29] Xun Huan and Youssef M Marzouk. Sequential Bayesian optimal experimental design via approx-
imate dynamic programming. arXiv preprint arXiv:1604.08320, 2016.
[30] Tobin Isaac, Noemi Petra, Georg Stadler, and Omar Ghattas. Scalable and eﬃcient algorithms for
the propagation of uncertainty from data through inference to prediction for large-scale problems,
with application to ﬂow of the Antarctic ice sheet. Journal of Computational Physics, 296:348–368,
September 2015.
[31] Jayanth Jagalur-Mohan and Youssef Marzouk. Batch greedy maximization of non-submodular
functions: Guarantees and applications to experimental design. arXiv preprint arXiv:2006.04554,
2020.
[32] M R Khodja, M D Prange, and H A Djikpesse. Guided Bayesian optimal experimental design.
Inverse Problems, 26(5):055008, apr 2010.
[33] Andreas Krause and Daniel Golovin. Submodular function maximization. In Tractability: Prac-
tical Approaches to Hard Problems, pages 71–104. Cambridge University Press, 2014.
[34] Quan Long, Mohammad Motamed, and Ra´ul Tempone.
Fast Bayesian optimal experimental
design for seismic source inversion. Computer Methods in Applied Mechanics and Engineering,
291:123 – 145, 2015.
[35] Quan Long, Marco Scavino, Ra´ul Tempone, and Suojin Wang.
Fast estimation of expected
information gains for Bayesian experimental designs based on Laplace approximations. Computer
Methods in Applied Mechanics and Engineering, 259:24–39, 2013.
[36] K. Manohar, B. W. Brunton, J. N. Kutz, and S. L. Brunton. Data-driven sparse sensor place-
ment for reconstruction: Demonstrating the beneﬁts of exploiting known patterns. IEEE Control
Systems Magazine, 38(3):63–86, June 2018.
[37] George Nemhauser, Laurence Wolsey, and M. Fisher. An analysis of approximations for maximiz-
ing submodular set functionsˆai. Mathematical Programming, 14:265–294, 12 1978.
[38] Costas Papadimitriou. Optimal sensor placement for parametric identiﬁcation of structural sys-
tems. Journal of Sound and Vibration, 278:923–947, 12 2004.
[39] Dimitris Papailiopoulos, Anastasios Kyrillidis, and Christos Boutsidis.
Provable deterministic
leverage score sampling. In Proceedings of the 20th ACM SIGKDD international conference on
Knowledge discovery and data mining, pages 997–1006, 2014.
[40] Noemi Petra, James Martin, Georg Stadler, and Omar Ghattas. A computational framework for
inﬁnite-dimensional Bayesian inverse problems: Part II. Stochastic Newton MCMC with applica-
tion to ice sheet inverse problems. SIAM Journal on Scientiﬁc Computing, 36(4):A1525–A1555,
2014.
27

[41] Constantine Pozrikidis. An introduction to grids, graphs, and networks. Oxford University Press,
2014.
[42] Arvind K Saibaba, Alen Alexanderian, and Ilse CF Ipsen. Randomized matrix-free trace and
log-determinant estimators. Numerische Mathematik, 137(2):353–395, 2017.
[43] Arvind K Saibaba and Peter K Kitanidis. Fast computation of uncertainty quantiﬁcation measures
in the geostatistical approach to solve inverse problems. Advances in Water Resources, 82:124–138,
2015.
[44] U. Villa, N. Petra, and O. Ghattas. hIPPYlib: An extensible software framework for large-scale
deterministic and Bayesian inversion. Journal of Open Source Software, 3(30):940, 2018.
[45] Kai Wei, Rishabh Iyer, and JeﬀBilmes. Submodularity in data subset selection and active learning.
In Francis Bach and David Blei, editors, Proceedings of the 32nd International Conference on
Machine Learning, volume 37 of Proceedings of Machine Learning Research, pages 1954–1963,
Lille, France, 07–09 Jul 2015. PMLR.
[46] Jing Yu, Victor M. Zavala, and Mihai Anitescu. A scalable design of experiments framework for
optimal sensor placement. Journal of Process Control, 67:44 – 55, 2018. Big Data: Data Science
for Process Control and Operations.
28

